\section{Related Work}
\paratitle{Knowledge Graph Question Answering.}
% 传统的方法通过通过嵌入空间表示实体和关系，设计特殊的模型架构如Key Value Memory Networks，seq2seq models如LSTM-based,T5-based在大语言模型之后，基于LLM强大推理能力，涌现出不同的能够基于LLM进行知识图谱问答的方法。一些致力于通过大模型时代的方法增强对于图谱结构的理解，例如\citet{ji-etal-2024-retrieval}利用COT\cite{wei2022chain}通过中间推理步骤增强图谱知识推理能力。TOG\cite{sun2023think} leverages LLM as an agent participating in KG reasoning. StructGPT,Interactive-KBQA通过将与图谱交互的函数作为交互界面，实现迭代的基于图谱的对话.\citet{jiang2024kg}则把LLM视为Agent智能体，通过Agent与环境交互达到图谱理解的目的。
% Following the advent of LLMs, diverse methods have emerged for knowledge graph question answering, leveraging the powerful reasoning capabilities of LLMs.一些基于prompt的方法例如\citet{kb-binder}通过few-shot样例，使得模型生成正确的s-expression并执行，Graph-CoT~\cite{jin-etal-2024-graph}通过COT来鼓励模型在图谱上进行多次思考推理，ToG\cite{sun2023think} explore related entities and relations on KGs iteratively based on LLMs reasoning. Other methods, such as \citet{jiang-etal-2023-structgpt}and \citet{xiong-etal-2024-interactive}, enable iterative KG-based operation by integrating pre-defined functions as interaction interface. Similarly, \citet{jiang2024kg} treat LLMs as intelligent agents, 通过KG reasoning program构造instruction data to fine-tune the base LLM.
Traditional methods represent entities and relations within an embedding space, leveraging specifically designed model architectures such as Key-Value Memory Networks\cite{miller-etal-2016-key,das-etal-2017-question}, as well as seq2seq frameworks like LSTM-based~\cite{sun-etal-2018-open} and T5-based~\cite{shu-etal-2022-tiara} networks. Recently, leveraging the powerful reasoning capabilities of LLMs, diverse methods have emerged for knowledge graph question answering. Prompt-based approaches, such as KB-BINDER~\cite{kb-binder}, uses few-shot examples to guide the model in generating credible logical forms. Graph-CoT \cite{jin-etal-2024-graph} incorporates Chain-of-Thought (CoT) reasoning to encourage multi-step reasoning over KGs. ToG \cite{sun2023think} iteratively explores related entities and relations on KGs based on LLM-driven reasoning.

Other methods, such as \citet{jiang-etal-2023-structgpt} and \citet{xiong-etal-2024-interactive}, enable iterative KG-based operations by integrating pre-defined functions as an interaction interface. Similarly, \citet{jiang2024kg} treat LLMs as intelligent agents, generating instruction data through KG reasoning programs for fine-tuning the base LLM. In contrast to these prompt-based approaches, we employ an end-to-end training framework, wherein distinct instruction tasks are explicitly defined during the data collection phase while simultaneously enabling procedural reasoning during the inference stage. 
%不同于这些prompt-based methods,我们设计了一套end-to-end训练框架，在训练阶段通过分别定义instructio任务，使得在推理阶段模型实现自动的流程推理。 and perform reasoning based on the retrieved knowledge
% In the era of large language models (LLMs), many methods have been developed that leverage prompts to harness the powerful reasoning capabilities of LLMs for knowledge graph (KG) applications. 

% Some approaches aim to enhance the understanding of graph structures by leveraging LLM-era methodologies. For instance, \citet{ji-etal-2024-retrieval} utilize Chain-of-Thought (CoT) reasoning \cite{wei2022chain} to improve KG reasoning by incorporating intermediate reasoning steps. TOG \cite{sun2023think} leverages LLMs as agents actively participating in KG reasoning.

% Other methods, such as StructGPT and Interactive-KBQA, enable iterative KG-based dialogue by integrating graph-interacting functions as part of the interaction interface. Similarly, \citet{jiang2024kg} treat LLMs as intelligent agents, where the agent interacts with its environment to achieve an understanding of the KG.
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{latex/pics/P4.pdf}
    \caption{The overall framework of \model. Given an input query, the trained generator model \mgen iteratively performs knowledge retrieval over the structual graph based on the retrieval token. Subsequently, the retrieved knowledge undergoes processes of critique and reflection, where implausible information is filtered. The iterative procedure culminates in the generation of an answer. \model exhibits strong interpretability when applied to structured graph. As demonstrated in the example, the step-by-step reasoning path is organized in the lower half.}
    \label{fig:Self-graph}
    % \vspace{-0.3cm}
\end{figure*}
\paratitle{RAG with Knowledge Graph.} Retrieval-Augmented Generation combines retrieved external knowledge with LLMs for improved task performance, incorporating domain-specific information to ensure factuality and credibility~\cite{guu2020retrieval}.
% \citet{jiang-etal-2023-active}uses a prediction of the upcoming sentence to adaptively retrieve passages. Self-RAG~\cite{asai2023selfrag}通过reflection tokens学习按要求检索。在知识图谱领域，检索主要聚焦在图数据库而不是文本库中，这需要额外考虑文本间的相互关系和图中的结构化信息。GNN-RAG结合GNN和RAG检索reasoning paths，TIARA~\cite{shu-etal-2022-tiara},Chatkbqa~\cite{luo-etal-2024-chatkbqa}在图谱中通过检索实体和关系，生成更可靠的logical forms. \citet{ji-etal-2024-retrieval} enhances the retrieval capabilities of KGs via CoT reasoning.
FLARE~\cite{jiang-etal-2023-active} predicts upcoming sentences to adaptively retrieve relevant passages. Self-RAG~\cite{asai2023selfrag} learns to retrival on-demand guided by reflection tokens. OneGen further unifies retrieval and generation in one model. In the context of knowledge graphs, retrieval focuses primarily on graph databases rather than text corpora, necessitating additional consideration of relationships between texts and the structural information inside. GNN-RAG~\cite{mavromatis2024gnn} integrate Graph Neural Networks (GNNs) with RAG to retrieve reasoning paths. TIARA~\cite{shu-etal-2022-tiara} and ChatKBQA~\cite{luo-etal-2024-chatkbqa} enhance the generation of reliable logical forms by retrieving entities and relations from knowledge graphs. HyKGE~\cite{jiang2024hykge} leverages LLMs to explore feasible directions within medical knowledge graphs. Furthermore, \citet{ji-etal-2024-retrieval} advances the retrieval capabilities via CoT reasoning.
% 不管是哪类方法，基于图谱的精准检索能力都是进行问答所必须的。有许多相关的工作旨在优化基于图谱的检索能力。

% 我们对此进行了复杂度分析
% 假设
% \begin{algorithm}
% \caption{\model Workflow}\label{alg:self_reward inference}
% \begin{algorithmic}[1]
% \State {\bf Input:} input $x$ and preceding generation $y_{<t}$
% \State{\bf Output:} next output segment $y_t$
% \State \mgen predicts \ret~given $(x,y_{<t})$
% \If{\ret~== \textcolor{myred}{\texttt{[Relation Retrieval]}}}
%     \State $\hat{y_t}$ = $\mathcal{M}(x, y_{<t})$
%     \Comment{\textcolor{blue}{Hypo-Generator}}
%     \State Retrieve relevant graph relationship $\mathbf{R}$ using \mret given $(x,y_{t-1}, \hat{y_t})$ 
%     \State \mgen predicts \crel for each $r \in \mathbf{R}$ 
%     % \State \mgen predicts \crel given $x, d$ and $y_{t}$ given $x,d, y_{<t}$ for each $r \in \mathbf{R}$ \Comment{\textcolor{blue}{Generate}}
%     % \State Rank $y_t$ based on \crel, \cgr, \cuse 
% \EndIf
% \If{\ret~== \textcolor{myred}{\texttt{[Entity Retrieval]}}}
%     \State Retrieve entities $\mathbf{E}$ based on the relevant relationship $r' \in \mathbf{R}$
%     \State \mgen predicts \crel for each $e \in \mathbf{E}$ and \cre given $\{x, y_{<t}\}$
% \EndIf
% \If{\ret~== \textcolor{myred}{\texttt{[No Retrieval]}}}
%  \State \mgen predicts \cre given $x, d$ and $y_{t}$ given $x,d, y_{<t}$ for each $e \in \mathbf{E}$ 
%  \State \mgen predicts [Utility]
%  \EndIf

% % \Else
% %     \State $\mathcal{M}_{gen}$ predicts $y_t$ given $x$ \Comment{\textcolor{blue}{Generate} }

% \end{algorithmic}\label{algo:inference}
% \end{algorithm}

%