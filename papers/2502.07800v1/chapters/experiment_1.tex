% ADD THIS HEADER TO ALL NEW CHAPTER FILES FOR SUBFILES SUPPORT

% Allow independent compilation of this section for efficiency
\documentclass[../CLthesis.tex]{subfiles}

% Add the graphics path for subfiles support
\graphicspath{{\subfix{../images/}}}

% END OF SUBFILES HEADER

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% START OF DOCUMENT: Every chapter can be compiled separately
\begin{document}

\chapter{Experiment 1: Machine Learning Benchmarks}%
% \label{chap:experiment_1}
\refstepcounter{experiment}  % This increments the counter
\label{exp:\theexperiment}
Based on annotated recording files, we extracted the onset and duration of each annotated syllable. In this experiment, we engineered different feature representations for each neuron in each annotated syllable, and used these features for syllable classification. This experiment aimed to establish the baseline performance on the classification of different syllables, identifying hub neurons, and investigating how neural information is integrated by the model through time.

\section{Methods}
\subsection{Feature Extraction}
\subsubsection{Single Neuron Level}
We first evaluated the predictive power of each neuron. For each neuron, we calculated firing rates during the entire syllable production. For each neuron, we trained classifiers using its firing rate.

\subsubsection{Neuron Population Level}
We analyzed the predictive ability of neurons on a population level to investigate the correlation and interaction between neurons in classification tasks. We used three types of feature representations. For each representation, we created a feature vector of length $75$, which is equal to the number of neurons. Each element in the feature vector corresponds to one neuron's activity. Each feature representation was independently evaluated using basic classifiers.

The first representation is the total number of spikes of the neuron per syllable. The second representation is the mean firing rate of the neuron per syllable. The third representation is Term Frequency-Inverse Document Frequency (TF-IDF). The TF-IDF indices were calculated by treating each neuron as an individual word and each annotated syllable as a document. Thus, the total number of firing during an annotated syllable sample served as the number of occurrences of the word in the document.

\subsection{Models and Evaluation}
For each of the feature representations above, we trained Support Vector Machine (SVM), Random Forest (RF) and eXtreme Gradient Boosting (XGBoost) classifiers. We evaluated the accuracy of each model for each feature representation. Then, we used three methods to evaluate the feature importance and interaction between neurons. The first is the built-in feature importance visualization method in RF, which identifies key contributing neurons. The second uses SHapley Additive exPlanations (SHAP) \citep{Lundberg2017-oo} values to identify the most important neurons for each syllable. The third is using SHAP interactive values to visualize pairwise interactions between neurons and find potential hub neurons. We first plotted a heatmap for all neurons and then picked top 10 interactive pairs and plotted them on a segment of Neuropixel. We also computed the spike rate correlation for comparison with SHAP interaction patterns. For the second and third methods, SHAP values were calculated using TreeSHAP for XGBoost models only. TreeSHAP is computationally efficient but does not support SVM or RF.

\subsection{Neural Information Integration}
Building upon our previous classification experiments, we conducted two analyses using SVM and population level mean firing rates to further investigate temporal relationships in our data.  

The first analysis quantifies how different temporal segments contribute to classification performance. We performed a parameter sweep to analyze the accuracy of SVM trained on mean firing rates across different time periods. In this parameter sweep:
\begin{itemize}
    \item Window start points vary from $-200.0$\,ms to $-12.5$\,ms
    \item Window end point increments by $2.5$\,ms, until it reaches $100.0$\,ms
\end{itemize}
For instance, the initial window would be $[-200.0$\,ms, $-197.5$\,ms$]$, and the decoding accuracy using this data is stored. The second window would be $[-200.0$\,ms, $-195.0$\,ms$]$, the accuracy is stored again. The window increases until it reaches $[-200.0$\,ms, $100.0$\,ms$]$, where the accuracy is stored, and the second round starts with $[-175.0$\,ms, $-172.5$\,ms$]$, and increases until $[-175.0$\,ms, $100.0$\,ms$]$, etc.

The second analysis aimed to reveal spatially and temporally important patterns of information encoding in the neural population. To achieve this, another window sweep was done to extract fixed $20$\,ms windows between $-150$\,ms and $50$\,ms.

\section{Results}
\subsection{Classification Accuracy}
Table~\ref{tab:classification_results} shows the results of classification accuracy across different feature and models.
\begin{table}[H]
   \centering
   \begin{tabular}{lccc}
       \toprule
       Feature Type & SVM (\%) & RF (\%) & XGBoost (\%)\\
       \midrule
       (Single Neuron) Mean Firing Rate & 39.0 & 66.8 & 64.2 \\
       (Neuron Population) Total Spike Counts & 91.5 & 89.6 & 96.2 \\
       (Neuron Population) Mean Firing Rates & 77.3 & 91.7 & 91.2 \\
       (Neuron Population) TF-IDF & 80.0 & 81.7 & 77.7 \\
       \bottomrule
   \end{tabular}
   \caption{Classification accuracy}
   \label{tab:classification_results}
\end{table}

\newpage
\subsection{Single Neuron Mean Firing Rate}
From Figure~\ref{fig:single_neuron_results}, we can observe that neurons located at depths of $2000$--$3000\,\mu m$ have higher accuracies than the rest, but the overall variation across neurons of different depth remains small. The result from SVM suggests that the information is not encoded at single neuron level, and the decoding requires population level activity patterns. In the figure, each horizontal bar represents the classification accuracy using only that neuron's firing rate as the predictor. The accuracy is also encoded by the color. Color and length were used together to separate the neurons recorded at the same depth. The x-axis shows the distance of each neuron to the tip of the Neuropixels probe in $\mu m$.
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{images/accuracy_across_neurons.pdf}
  \caption{Classification accuracy using single neuron firing rates}
  \label{fig:single_neuron_results}
\end{figure}

\newpage
\subsection{Neuron Population Total Spike Counts}
All classifiers achieved high classification accuracy using total spike counts for each syllable. However, this performance should be interpreted with caution. Some neurons exhibit consistent firing patterns, and may encode temporal information more than syllable-specific features. Since each syllable differs in duration, the result of classification using total spike counts may also reflect temporal characteristics across syllables of different lengths instead of syllable-specific neural activities. Figure~\ref{fig:total_visualization} shows the feature importance, and how the most important neurons in Figure~\ref{fig:rf_total} are aligned with the total spike counts shown in \ref{fig:spike_count}. This suggests that the RF simply learns the syllable length instead of focusing on genuine neural patterns.
\begin{figure}[H]
  \centering
  \begin{subfigure}{0.45\textwidth}
      \includegraphics[width=\textwidth,height=1.5\textwidth]{images/feature_importance_across_neurons.pdf}
      \caption{RF Feature Importance}
      \label{fig:rf_total}
  \end{subfigure}
  \begin{subfigure}{0.45\textwidth}
      \includegraphics[width=\textwidth,height=1.5\textwidth]{images/total_spike_count_across_neurons.pdf}
      \caption{Total Spike Counts}
      \label{fig:spike_count}
  \end{subfigure}

  \caption{Evaluation of total spike counts}
  \label{fig:total_visualization}
\end{figure}

\subsection{Neuron Population Mean Firing Rates}
SVM achieved 77.3\,\% accuracy while RF reached 91.7\,\% accuracy using mean firing rates. Figure~\ref{fig:rf_feature_importance} shows the importance of each neuron during the classification task in an RF model. Darker red indicates higher contribution to the correct classification.
\begin{figure}[H]
   \centering
   \begin{minipage}{0.45\textwidth}
      \centering
      \includegraphics[width=\textwidth]{images/result_RF_firing_frequency.pdf}
      \caption{RF feature importance\\\phantom{Figure 1.3: }Mean firing rates}
      \label{fig:rf_feature_importance}
   \end{minipage}
   \hfill
   \begin{minipage}{0.45\textwidth}
      \centering
      \includegraphics[width=\textwidth]{images/result_RF_TF-IDF.pdf}
      \caption{RF feature importance\\\phantom{Figure 1.3: }TF-IDF}
      \label{fig:tfidf_feature_importance}
   \end{minipage}
\end{figure}

\subsection{TF-IDF}
SVM achieved 80.0\,\% accuracy and RF achieved 81.7\,\% using TF-IDF as feature representations. Figure~\ref{fig:tfidf_feature_importance} visualizes the feature importance from the RF model. 

\subsection{SHAP Analysis}
XGBoost classifier achieved a 91.2\,\% accuracy. The result of XGBoost is visualized using SHAP visualizations to investigate the interaction between neurons. Figure~\ref{fig:shap} visualizes feature importance for each syllable using SHAP values. Higher SHAP values (darker red) indicate stronger positive contribution to the classification of specific syllables. The visualization shows distinct patterns of neuronal contributions to the correct identification of each syllable. Noteworthy the neuron N$6$ at depth $2960\,\mu m$ plays the most critical role among the classification of all syllables. 
\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{images/shap_values_across_neurons.pdf}
   \caption{SHAP visualization of neuron importance for classification}
   \label{fig:shap}     
\end{figure}

\subsection{SHAP Interaction Analysis}
Figure~\ref{fig:correlation} shows the correlation coefficients between neuron firing rates. Neurons N$1$($3380$)--N$12$ ($2720\,\mu m$) and N$49$($2320$)--N$56$($2180\,\mu m$) show opposite firing patterns compared to other neurons during syllable production. 

Figure~\ref{fig:shap_interaction} shows a heatmap of the relationship between the neurons calculated from SHAP interaction values. The neurons were inversely ranked by the depth to probe tip. A positive SHAP interaction value in red suggests that when both neurons are active, they contribute more to the syllable classification than the sum of individual contributions. A negative SHAP interaction value in blue suggests that when both neurons are active, their total contribution is less than the sum of their individual contributions. This could result from redundant information encoding, or potential inhibition effect from inhibitory interneurons. We can observe from the figure that Neuron $6$ serves as a hub neuron. When it is active, it can either enhance (red dots) or suppress (blue dots) the contributions of other neurons to syllable classification, depending on the specific neural states. The depth of all neurons can be found in the appendix \ref{tab:neuron_depths}.

The two figures show certain shared spectral patterns on the distribution of less correlated neurons (in gray). Additionally, Figure~\ref{fig:neuropixel} visualizes the interaction of top 10 pairs of important neurons (called Features in the SHAP package) on a Neuropixels probe. The colored step lines indicate the interaction conditions between neurons. In the figure, N$6$ actively interacts with N$8$ and negatively interacts with N$56$. N$6$ and N$8$ are roughly located on the edge of LMAN, while N$56$ is roughly located at area X. 

\begin{figure}[H]
   \centering
   \begin{subfigure}{\textwidth}
      \centering
      \includegraphics[height=0.45\textheight]{images/feature_correlation.pdf}
      \caption{Correlation coefficients between 75 neurons}
      \label{fig:correlation}
   \end{subfigure}
   
   \begin{subfigure}{\textwidth}
      \centering
      \includegraphics[height=0.45\textheight]{images/SHAP_interaction.pdf}
      \caption{SHAP visualization of interactions between neurons}
      \label{fig:shap_interaction}
   \end{subfigure}
   \caption{Neural correlation and interaction analysis}
   \label{fig:all_neurons}
\end{figure}

\begin{figure}[H]
   \centering
   \includegraphics[width=\textwidth]{images/neuron_interactions.pdf}
   \caption{Top 10 interactive pairs plotted on a Neuropixels probe}
   \label{fig:neuropixel}     
\end{figure}

\newpage
\subsection{Neural Information Integration} 
Figure~\ref{fig:temporal_accuracy} shows the decoding accuracy using the mean firing rates of neuron population using a basic SVM.\footnote{Individual plots of each onset is included in Appendix~\ref{appendix:integration}} 
\begin{figure}[H]
 \centering
 % Full width for horizontal plot
 \includegraphics[width=\textwidth]{images/accuracy_vs_time.pdf}
 \caption{Classification accuracy}
 \label{fig:temporal_accuracy}
\end{figure}

Each colored line indicates how classification accuracy evolves when integrating neural activity from a specific starting point. The transparency indicates the total length of windows used for classification. For instance, the purple line starts at $-200$\,ms. It collects the spikes every $5$\,ms, and uses these spikes to do classification. The first point in the purple line at $-195$\,ms indicates the classification accuracy using spikes collected during $[-200\,\text{ms}, -195\,\text{ms}]$. Then it collects the spikes during $[-200\,\text{ms}, -190\,\text{ms}]$, and the accuracy is reflected by the value of the purple line at $-190$\,ms.

On the other hand, highest classification accuracies occur at $-20$\,ms. Colored lines starting at $-12.5$\,ms show very low accuracy, which indicates that there are homogeneous activities in all syllables around the syllable onset. Based on this observation and inspired by Multivariate Pattern Analysis in EEG, we did the second analysis. 

In the second analysis, we binned the firing counts into $2.5$\,ms windows in the range $[-150\,\text{ms}, 30\,\text{ms}]$ and use these as input features to an RF model. Figure~\ref{fig:random_windows} visualizes the feature importance. There are occasionally dark red dots between $[-50\,\text{ms}, -25\,\text{ms}]$ before the onsets, indicating these time windows contain relatively more important information for correct identification of syllables.

\begin{figure}[H]
 \centering
 \includegraphics[width=0.6\textwidth]{images/result_RF_random_400.png}
 \caption{Classification performance in different random time windows}
 \label{fig:random_windows}
\end{figure}

\newpage
\section{Discussion}
\subsection{Baseline Methods and Interpretation}
Our benchmark results show that the mean firing rates can be used to classify different syllables of zebra finches. A fair baseline can be established by passing mean firing rates on a neuron population level to SVM, yielding an accuracy of 77.3\,\%. RF and XGBoost have better results, but may come from brute force ensemble averaging rather than understanding true data patterns. Individual neurons show some predictive power, and the population level features suggest that the syllable is mostly encoded at the population level. In addition, TF-IDF is a useful metric and yields a high classification accuracy. SHAP analysis revealed two findings: syllable-specific patterns in neural activity, and neuron interactions. The analysis identified important neuron hubs, and visualized possible relationships between neurons in LMAN and area X. 

\subsection{Information Encoded in LMAN Activity}
The first neural information integration analysis suggests that LMAN activity at $-20$\,ms is the most informative for syllable classification. The second analysis showed that during $[-50\,\text{ms}, -25\,\text{ms}]$, the LMAN activity is the most informative for the vocalization of different syllables. These temporal relationships align well with previous findings of LMAN's pre-motor activity during syllable production. Previous studies have reported LMAN pre-onset bursts occurring at $[-60\,\text{ms}, -10\,\text{ms}]$ \citep{Kojima2018-rw}, $[-42\,\text{ms}, -20\,\text{ms}]$ \citep{Giret2014-kx}, and $-50$\,ms \citep{Kao2005-cl}.

\subsection{Future Direction}
The results indicated LMAN activities contain important timing-specific information around syllable onset. A systematic temporal windows analysis could reveal more precise patterns of information encoding in LMAN. The SHAP interaction analysis and the information integration analysis can be applied to data from HVC and RA, enabling visualization of information flow and integration between AFP and Motor Pathway. The method could also be used on simultaneously recorded data from Area X and DLM to investigate the GABAergic projection from Area X to DLM. These analyses would advance our understanding on how Motor Pathway and AFP coordinate and contribute to motor output from a machine learning perspective.
% self-defined macro: include bibliography even when compiling a single chapter
\subfilebibliography
\end{document}
