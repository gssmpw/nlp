\pdfoutput=1

\documentclass[11pt]{article}

\usepackage{acl}

\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage[most]{tcolorbox}
\usepackage{forest}
\usepackage{xcolor}
\usepackage{xspace}

\newcommand{\ra}{$\rightarrow$\xspace}
\newcommand{\mean}[1]{\textsc{#1}}
\newcommand{\word}[1]{\textit{#1}}

\begin{document}

\title{LLMs as a synthesis\\ between symbolic and continuous approaches to language}

\author{Gemma Boleda\\
  Universitat Pompeu Fabra / ICREA\\
  gemma.boleda@upf.edu\\}

\maketitle

\begin{abstract}
  Since the middle of the 20th century, a fierce battle is being fought between symbolic and continuous approaches to language and cognition.
  The success of deep learning models, and LLMs in particular, has been alternatively taken as showing that the continuous camp has won, or dismissed as an irrelevant engineering development.
  However, in this position paper I argue that deep learning models for language
  actually represent a synthesis between the two traditions.
  This is because 1)~deep learning architectures allow for both continuous/distributed and
  symbolic/discrete-like representations and computations; 2)~models trained on language make use this flexibility.
  In particular, I review recent research in mechanistic interpretability that showcases how a substantial part of morphosyntactic knowledge is encoded in a near-discrete fashion in LLMs.
  This line of research suggests that different behaviors arise in an emergent fashion, and
  models flexibly alternate between the two modes (and everything in between) as needed.
  This is possibly one of
  the main reasons for their wild success; and it is also what makes them particularly interesting for the study of language and cognition.
  Is it time for peace?
\end{abstract}

\input{cleaned_intro}

\input{cleaned_how-discrete-is-language}

\input{cleaned_content}

\section*{Limitations}

I am aware that my definition of what counts as near-discreteness in LLMs is, ironically, fuzzy.
I think that, given the present state of the art (mechanistic interpretation of deep learning models is still in its infancy), the best I can do is offer an initial definition and many examples of the kind of behavior that I think provides support for my position.
Delineating the role of quasi-symbolic language processing in LLMs more precisely is an exciting avenue for further work.

\section*{Acknowledgments}
Thank you to Marco Baroni for discussion and feedback on earlier drafts, and to the COLT research group for being a great environment to write this paper in.
I used Generative AI to assist with latex formatting in the preparation of this paper.

\bibliography{main}

\appendix

\end{document}

\typeout{get arXiv to do 4 passes: Label(s) may have changed. Rerun}
