\section{Experimental Setup and Results}
\label{sec:results}
\vspace{-2mm}
\noindent
% \blueHL{\sout{In this section, we delve into our experimental setup, covering the process of data generation and pre-processing. Additionally, we present details on model training and validation procedures. Finally, we present the efficacy of our sizing assistant in predicting device sizes with some unseen circuit performance specifications.}}
% \bluefn{Can delete this without much loss of continuity, if we need to save space. \textbf{OK}} SSS_NOTE

\subsection{Data generation and preprocessing}

\noindent
To demonstrate the efficacy of our framework, we employ three distinct OTA topologies: five-transistor OTA (5T-OTA), current-mirror OTA (CM-OTA), and two-stage OTA (2S-OTA), each implemented using a 65nm technology node. In Fig.~\ref{fig:schemas}, we show the OTA schematics along with matching constraints under consideration. For clarity in our demonstration, we focus on three performance metrics: gain, 3dB-bandwidth (BW), and unity-gain frequency (UGF), and aim to meet the given performance specifications.
 
Table~\ref{tab:dataset} shows the range of different specifications for the OTAs considered for our training set. We assume that the length of all the devices in a circuit is set to 180nm with a load capacitor $C_L$ of 500fF for all the topologies. To ensure reliable model analysis, we start with precise data generation for each OTA topology using OCEAN scripting. This involves the following steps:
\begin{itemize}
    \item Generating multiple designs with varying transistor sizes by nested sweeps of widths ranging from 0.7$\mu$m to 50$\mu$m.
    \item Enforcing matching constraints for active load current mirror (CM), and differential pair (DP).
    \item Sweeping the DC voltage to determine the input common-mode range (ICMR) of the designs.
    \item Ensuring that the CMs operate in the strong inversion region while the DPs function in the weak inversion region.
    % \bluefn{(1)~Strange choice of words -- what is ``irrelevant''? It either meets specs or it does not. How can it be irrelevant? \textbf{Can I use ``invalid'' ? Cause, I am using ICMR just for filtering out the OTAs which can practically function for a valid input common mode voltage range.} (2)~If you use ICMR as a spec, why isn't it ever reported in your results? \textbf{I am not using ICMR as a SPEC}} SSS_NOTE
    \item Filtering out designs that falls out of the predefined specification range for the dataset outlined in Table~\ref{tab:dataset}.
    \item Capturing the device parameters -- specifically, $g_m, g_{ds}$, $C_{ds}$, and $C_{gs}$ -- for the final legal designs.
\end{itemize}

% \bluefn{What does ``inadequate'' mean? Elaborate. \textbf{I think ``functional'' would be better. The circuits which have a valid ICMR,  and giving out practically useful gain, BW, UGF, are choosen}} SSS_NOTE

\begin{figure}[t]
    \centering
    \subfloat[]{
        \includegraphics[width=19.5mm, bb = 0 0 100 110]{fig/5tota.pdf}
    }
    \hspace{-2mm} % Adjust spacing between subfigures
    \subfloat[]{
        \includegraphics[width=30.5mm, bb = 0 0 200 110]{fig/cmota.pdf}
    }
    \hspace{-1mm} % Adjust spacing between subfigures
    \subfloat[]{
        \includegraphics[width=29mm, bb = 0 0 160 110]{fig/2sota.pdf}
    }
    
    \caption{Schematic of (a) 5T-OTA, (b) CM-OTA, and (c) 2S-OTA.}
    \label{fig:schemas}
    \vspace{-0.2cm}
\end{figure}

Next, we focus on generating appropriate DP-SFG paths for each circuit topology. Table~\ref{tab:dataset} shows the number of sequential paths for each topology. The DP-SFGs are small and the cost of path enumeration is small; for more complex examples, if the number of paths grows large, it is possible to devise other string representations of the DP-SFG.
Finally, in the preprocessing stage, we generate two sets of sequential data, one each for the encoder and the decoder.
% \bluefn{\textbf{***I think at this stage SEQUENTIAL DATA makes more sense***} Is the use of ``sequential paths'' confusing? You are talking about a sequence of tokens that feeds the transformer. The paths are not tokens. Maybe use some other term instead of ``sequential paths''?}
\begin{itemize}
    \item The sequential data at the encoder comprises DP-SFG paths that maintain consistency across all designs within a specific topology. It also includes performance metrics for each design, encompassing gain, BW, and UGF parameters, associated with each unique set of transistor sizes.
    \item The sequential data at the decoder covers the same DP-SFG paths, but with device parameters replaced by values obtained during data generation. These values are unique to each design, aligning with the performance metrics in the encoder sequence.
\end{itemize}

\begin{table}[t]
    \caption{Dataset information.}
    \centering
    % \begin{tabular}{|>{\centering\arraybackslash}m{1.1cm}|>{\centering\arraybackslash}m{1cm}|>{\centering\arraybackslash}m{1.3cm}|>{\centering\arraybackslash}m{1.2cm}|>{\centering\arraybackslash}m{1cm}|>{\centering\arraybackslash}m{0.7cm}|}
    \resizebox{1\linewidth}{!}{\begin{tabular}{|l|c|c|c|c|c|}
        \hline
        \textbf{Topology} & \makecell{\textbf{Gain}\\\textbf{(dB)} \\\textit{min-max}} & \makecell{\textbf{3dB bandwidth}\\\textbf{(MHz)} \\\textit{min-max}} & \makecell{\textbf{UGF} \\\textbf{(MHz)} \\\textit{min-max}}& \makecell{\textbf{\#forward} \\\textbf{paths}} & \textbf{\#cycles} \\
        \hline
        5T-OTA & 18 -- 23 &  7 -- 54 & 80 -- 871  &  9 & 4  \\
        \hline
        CM-OTA & 19 -- 25 & 17.5 -- 86 & 57 -- 1185 & 26 & 5  \\
        \hline
        2S-OTA & 28 -- 54 & 0.01 -- 0.32 & 1.8 -- 370  &  2 & 11 \\
        \hline
    \end{tabular}}
    \label{tab:dataset}
    \vspace{-5mm}
\end{table}


We train a single transformer model that works across all three OTA topologies. By considering all performance criteria and all DP-SFG paths, we convey complete information about each circuit to the transformer. Our dataset comprises 17,000 designs for 5T-OTA, 25,000 designs for CM-OTA, and 8,000 designs for 2S-OTA, each with a different set of transistor sizes. This diverse dataset trains the model across multiple design specification requirements.


% \begin{table}[t]
%     \vspace{-0.2cm}
%     \caption{Dataset Information}
%     \centering
%     \begin{tabular}{|>{\centering\arraybackslash}p{1.1cm}|>{\centering\arraybackslash}p{0.9cm}|>{\centering\arraybackslash}p{0.7cm}|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|>{\centering\arraybackslash}p{0.5cm}|}
%         \hline
%         \multirow{2}{*}{\textbf{Topology}} & \multirow{2}{*}{\textbf{Forward}} & \multirow{2}{*}{\textbf{Cycles}} & \multicolumn{2}{c|}{\makecell{\textbf{Gain}\\\textbf{(dB)}}} & \multicolumn{2}{c|}{\makecell{\textbf{Bandwidth}\\\textbf{(MHz)}}} & \multicolumn{2}{c|}{\makecell{\textbf{UGF} \\\textbf{(MHz)}}}\\
%         \cline{4-9}
%          & \textbf{paths} &  & \textbf{Min} & \textbf{Max} & \textbf{Min} & \textbf{Max} & \textbf{Min} & \textbf{Max} \\
%         \hline
%         5T-OTA & 9 & 4 & 18 & 29 & 7 & 54 & 80 & 871\\
%         \hline
%         CM-OTA & 26 & 5 & 20 & 32 & 59 & 86 & 57 & 1185\\
%         \hline
%         2S-OTA & 2 & 11 & 30 & 52 & 13 & 32 & 18 & 370\\
%         \hline
%     \end{tabular}
%     \label{tab:DP-SFG}
% \end{table}

\subsection{Training and validation}

% \redfn{CK: The number of paths in a more complex circuit could be very large? How do we propose to handle it? \textbf{Since, the inferencing is quite fast, the overall process will still be fast. But, yes the size of the dataset is proportional to number of paths in DPSFG. {\em Added text below Table 1. Please check blueHL.}YES MAKES SENSE}}

\noindent
For our experiments, we employ an Nvidia L40S GPU equipped with 45GB of memory. The dataset is split into an 80:20 ratio for training and validation across each OTA topology. We train a single model using datasets from all three topologies for 40 epochs, employing an adaptive learning rate strategy with the Adam optimizer, beginning with an initial learning rate of $10^{-4}$. Subsequently, our framework is validated against unseen performance specifications across all three OTA topologies. For a given topology and performance specifications, the validation phase rapidly predicts a sequence of tokens corresponding to circuit parameters.The transformer takes in the encoder sequences list and predicts output sequences containing the device parameter values that satisfy the specifications. This is followed by the LUT-based estimator that translates the predicted device parameters to transistor widths. 

% In the subsequent subsection, we comprehensively analyze each aspect of our framework's performance.

\begin{figure}[t]
\vspace{-4mm}
\centering
\subfloat[]{
  \includegraphics[width=0.49\linewidth, bb = 0 0 1100 1000]{fig/scatter.pdf}
}
\hspace{-0.4cm}
\subfloat[]{
  \includegraphics[width=0.49\linewidth, bb = 0 0 1100 1000]{fig/gSCATTER.pdf}
}
% \vspace{-2mm}
\caption{For 5T-OTA: Scatter plots showing comparisons between predicted and simulation-based device parameters (a) $g_m$ and (b) $g_{ds}$.}
\label{fig:plots}
\vspace{-5mm}
\end{figure}

\subsection{Performance of the framework}

\noindent
We conduct comprehensive performance evaluations to assess the effectiveness of the transformer model and LUT-based width estimator for each OTA topology. Our method sizes 100 unique designs per topology, each with distinct performance specifications not included in the training set. For each specification, the transformer model predicts the key device parameters, which are then converted to transistor sizes using the LUT-based method. The performance of the final design is validated through Spectre simulation of the sized OTA circuit for each topology. Additionally, we ensure the optimized devices operate in the desired region of operation. 


\begin{table}[b]
    \vspace{-4mm}
    \centering
    % First table
    \begin{minipage}{\linewidth}
        \centering
        \caption{\centering Correlation coefficient of device parameters between validation data and model outputs for the 5T-OTA.}
        \resizebox{1\linewidth}{!}{
            \begin{tabular}{|>{\centering\arraybackslash}p{0.9cm}|>{\centering\arraybackslash}p{2.3cm}|c|c|c|c|}
                \hline
                \multirow{2}{*}{\makecell{\textbf{MOS} \\ \textbf{devices}}} & \multirow{2}{*}{\makecell{\textbf{Transistor} \\ \textbf{information}}} & \multicolumn{4}{c|}{\makecell{\textbf{Correlation coefficient}}} \\ \cline{3-6}
                & & \textbf{$g_m$} & \textbf{$g_{ds}$} & \textbf{$C_{ds}$} & \textbf{$C_{gs}$} \\
                \hline
                M1/M2 & Active load & 0.982 & 0.993 & 0.962 & 0.964 \\ \cline{1-6} 
                M3/M4 & DP & 0.999 & 0.991 & 0.997 & 0.998 \\ \cline{1-6} 
                M5 & Tail MOS & 0.999 & 0.997 & 0.997 & 0.997 \\ \cline{1-6} 
                \hline
            \end{tabular}
        }
        \label{tab:5t_corr}
    \end{minipage}
    
    \vspace{1mm} % Space between tables

    % Second table
    \begin{minipage}{\linewidth}
        \centering
        \caption{\centering Comparison of optimized design performance with target specifications for the 5T-OTA}
        \resizebox{1\linewidth}{!}{
            \begin{tabular}{|c|c|c|c|c|c|}
                \hline
                \multicolumn{2}{|c|}{\textbf{Gain (dB)}} & \multicolumn{2}{c|}{\makecell{\textbf{UGF (MHz)}}} & \multicolumn{2}{c|}{\makecell{\textbf{3dB bandwidth (MHz)}}} \\ \cline{1-6}
                \makecell{\textbf{Target}} & \makecell{\textbf{Optimized}} & \makecell{\textbf{Target}} & \makecell{\textbf{Optimized}} & \makecell{\textbf{Target}} & \makecell{\textbf{Optimized}} \\
                \hline
                20.13 & 20.6 & 118.78 & 144.64 & 11.38 & 13.33 \\ \cline{1-6} 
                21.23 & 21.37 & 181.25 & 185.38 & 15.31 & 15.49 \\ \cline{1-6} 
                22.78 & 22.79 & 281.75 & 288.54 & 20.18 & 20.48 \\ \cline{1-6} 
                \hline
            \end{tabular}
        }
        \label{tab:5t_specs}
    \end{minipage}

    % \vspace{-2mm}
\end{table}

\noindent
\textbf{5T-OTA}
The 5T-OTA topology includes a matched active current-mirror load (M1/M2), a differential pair (M3/M4), and a tail transistor (M5), all requiring precise sizing to meet performance targets. We assess the prediction accuracy of the transformer by correlating predicted device parameters with SPICE-based validation results. Fig.~\ref{fig:plots} shows a strong correlation between predicted \(g_{m}\) and \(g_{ds}\) values and their SPICE counterparts along the 45Â° line,
% , where we use single variable for matched transistors, 
and Table~\ref{tab:5t_corr} summarizes the correlation coefficients of all the parameters, highlighting model accuracy. We show the results of applying the transformer model for three sets of unseen target specifications in Table~\ref{tab:5t_specs}: the optimized circuit can be seen to meet all requirements.



\noindent
\textbf{CM-OTA}
The CM-OTA topology incorporates a differential input stage, succeeded by three current mirror loads. A total of nine devices require sizing in this configuration. The correlation coefficient between the device parameters predicted by the transformer model and the SPICE-based validation data are shown in Table~\ref{tab:cmota_corr} and display high accuracy. Finally, Table~\ref{tab:cmota_specs} delineates the target specifications for three randomly selected designs from the validation set. As in the case of the 5T-OTA, the output of the transformer yields optimized circuits that meet all performance requirements. 

\begin{table}[t]
    \centering
    % \vspace{-2mm}
    % First table
    \begin{minipage}{\linewidth}
        \centering
        \caption{\centering Correlation coefficient of device parameters between validation data and model outputs for the CM-OTA.}
        \resizebox{1\linewidth}{!}{
            \begin{tabular}{|>{\centering\arraybackslash}p{0.9cm}|>{\centering\arraybackslash}p{2.3cm}|c|c|c|c|}
                \hline
                \multirow{2}{*}{\makecell{\textbf{MOS} \\ \textbf{devices}}} & \multirow{2}{*}{\makecell{\textbf{Transistor} \\ \textbf{information}}} & \multicolumn{4}{c|}{\makecell{\textbf{Correlation coefficient}}} \\ \cline{3-6}
                & & \textbf{$g_m$} & \textbf{$g_{ds}$} & \textbf{$C_{ds}$} & \textbf{$C_{gs}$} \\
                \hline
                M1/M2 & Matched CM load & 0.811 & 0.838 & 0.871 & 0.875 \\ \cline{1-6}
                M3/M4 & DP & 0.798 & 0.683 & 0.878 & 0.883 \\ \cline{1-6} 
                M5 & Tail MOS & 0.817 & 0.867 & 0.601 & 0.760 \\ \cline{1-6} 
                M6/M7 & Matched CM load & 0.893 & 0.803 & 0.881 & 0.895 \\ \cline{1-6} 
                M8/M9 & Matched CM load & 0.912 & 0.914 & 0.891 & 0.892 \\ \cline{1-6} 
                \hline
            \end{tabular}
        }
        \label{tab:cmota_corr}
    \end{minipage}
    
    \vspace{0.5mm} % Space between tables

    % Second table
    \begin{minipage}{\linewidth}
        \centering
        \caption{\centering Comparison of optimized design performance with target specifications for the CM-OTA}
        \resizebox{1\linewidth}{!}{
            \begin{tabular}{|c|c|c|c|c|c|}
                \hline
                \multicolumn{2}{|c|}{\textbf{Gain (dB)}} & \multicolumn{2}{c|}{\makecell{\textbf{UGF (MHz)}}} & \multicolumn{2}{c|}{\makecell{\textbf{3dB bandwidth (MHz)}}} \\ \cline{1-6}
                \makecell{\textbf{Target}} & \makecell{\textbf{Optimized}} & \makecell{\textbf{Target}} & \makecell{\textbf{Optimized}} & \makecell{\textbf{Target}} & \makecell{\textbf{Optimized}} \\
                \hline
                20.83 & 21.99 & 345.9 & 475.74 & 30.84 & 37.65 \\ \cline{1-6} 
                21.55 & 23.25 & 247.98 & 408.11 & 20.15 & 27.48 \\ \cline{1-6} 
                23.8 & 24.3 & 1033.77 & 1478.5 & 71.47 & 104.24 \\ \cline{1-6} 
                \hline
            \end{tabular}
        }
        \label{tab:cmota_specs}
    \end{minipage}

    \vspace{-4mm}
\end{table}



\noindent
\textbf{2S-OTA}
The 2S-OTA topology includes a 5T-OTA in the first stage, followed by a common source amplifier comprising seven devices. Table~\ref{tab:2sota_corr} provides a summary of the correlation coefficient between the device parameters predicted by the transformer model and those generated by SPICE, thereby affirming the accuracy of the model. Furthermore, Table~\ref{tab:2sota_specs} presents the target specifications for three randomly selected designs from the validation set. Again, the transformer delivers optimized circuits that meet all specifications.

\begin{table}[b]
    \centering
    \vspace{-4mm}
    % First table
    \hspace*{-0.03\linewidth}
    \begin{minipage}{1.0\linewidth}
        \centering
        \caption{\centering Correlation coefficient of device parameters between validation data and model outputs for the 2S-OTA.}
        \resizebox{1\linewidth}{!}{
            \begin{tabular}{|>{\centering\arraybackslash}p{0.9cm}|>{\centering\arraybackslash}p{2.3cm}|c|c|c|c|}
                \hline
                \multirow{2}{*}{\makecell{\textbf{MOS} \\ \textbf{devices}}} & \multirow{2}{*}{\makecell{\textbf{Transistor} \\ \textbf{information}}} & \multicolumn{4}{c|}{\makecell{\textbf{Correlation coefficient}}} \\ \cline{3-6}
                & & \textbf{$g_m$} & \textbf{$g_{ds}$} & \textbf{$C_{ds}$} & \textbf{$C_{gs}$} \\
                \hline
                M1/M2 & 1\textsuperscript{st} stage active load & 0.942 & 0.936 & 0.876 & 0.879 \\ \cline{1-6}
                M3/M4 & 1\textsuperscript{st} stage DP & 0.988 & 0.945 & 0.913 & 0.915 \\ \cline{1-6} 
                M5 & 1\textsuperscript{st} stage tail MOS & 0.928 & 0.989 & 0.918 & 0.922 \\ \cline{1-6} 
                M6 & 2\textsuperscript{nd} stage tail MOS & 0.856 & 0.881 & 0.843 & 0.798 \\ \cline{1-6} 
                M7 & 2\textsuperscript{nd} stage CS & 0.892 & 0.887 & 0.785 & 0.880 \\ 
                \hline
            \end{tabular}
        }
        \label{tab:2sota_corr}
    \end{minipage}
    
    % \vspace{0.5mm} % Space between tables

    % Second table
    \begin{minipage}{\linewidth}
        \centering
        \caption{\centering Comparison of optimized design performance with target specifications for the 2S-OTA}
        \resizebox{1\linewidth}{!}{
            \begin{tabular}{|c|c|c|c|c|c|}
                \hline
                 \multicolumn{2}{|c|}{\textbf{Gain (dB)}} & \multicolumn{2}{c|}{\makecell{\textbf{UGF (MHz)}}} & \multicolumn{2}{c|}{\makecell{\textbf{3dB bandwidth (kHz)}}} \\ \cline{1-6}
                \makecell{\textbf{Target}} & \makecell{\textbf{Optimized}} & \makecell{\textbf{Target}} & \makecell{\textbf{Optimized}} & \makecell{\textbf{Target}} & \makecell{\textbf{Optimized}} \\
                \hline
                43.6 & 45.61 & 13.33 & 13.4 & 90 & 140 \\ \cline{1-6} 
                47.17 & 47.93 & 11.09 & 11.77 & 80 & 90 \\ \cline{1-6} 
                55.19 & 46.04 & 9.42 & 10.11 & 60 & 91 \\ 
                \hline
            \end{tabular}
        }
        \label{tab:2sota_specs}
    \end{minipage}

    \vspace{-2mm}
\end{table}



From the correlation coefficient analysis, we observe that in some cases the coefficients can be relatively lower (e.g., $<$0.8). These cases correspond to scenarios where the corresponding parameter does not impact the performance metrics significantly, while the other parameter has a more dominant influence. This behavior is attributed to the attention mechanism of the transformer which weights the importance of different parameters based on their level of influence on the performance specifications. As a result, the contributions of less impactful parameters may be overshadowed, leading to a lower correlation coefficient in those specific cases. 

% \bluefn{When I read this entire results section, all I see in the text is ``5T-OTA'': you don't even mention the other OTAs. If the reviewer is in a hurry, s/he will think you really have only done 5T-OTAs. Need to write this better to bring out the other two OTA types. Your paper is already weak because of the simplicity of the circuits (compare with any of the other papers on OTA sizing, which show much more complex circuits). Don't shoot yourself in the foot even further.}









\noindent
%\redHL{~{\em 2) LUT-based transistor width estimation.} For each OTA topology,\bluefn{List them by name so that the reader does not just see ``5T OTA'' in the results section.} we use our approach to determine the transistor sizes for 100 distinct performance specifications that are unseen in the training set. For each set of performance specifications, the transformer model predicts the circuit parameters, which are translated to transistor sizes using the LUT-based method. We report the performance of the design based on a Spectre simulation of the sized OTA circuit. Table~\ref{tab:specs} shows the list of target specs and obtained specs\bluefn{No! You don't \underline{obtain} a spec. See earlier comment. \textbf{FIXED}} for three designs from the validation set for each topology. \textbf{IN MY OPINION, WE DON'T NEED THIS RED PART ANYMORE}}



\begin{table}[t]
    % \vspace{-0.2cm}
    \caption{Runtime analysis of training and inferencing stages.} 
    % \blueHL{This table is poorly explained. You never say anywhere that you run 100 designs. I have changed 95 to 95/100, etc., to make this more obvious in the paper, but you also need to say this in the text.  Please read the paper adversarially, from the point of view of the reviewer. Right now, there are many items that will provoke instant rejection from the reviewer, and you have not bothered to try and address these. I've caught what I could, but I am sure there are other issues because I am starting from almost zero. \textbf{NOTED}}}
    \centering
    \resizebox{1\linewidth}{!}{\begin{tabular}{|c|c|c|c|c|c|c|c|}
        \hline
        \multirow{2}{*}{\makecell{\textbf{OTA} \\ \textbf{topology}}} & \multirow{2}{*}{\makecell{\textbf{One-time} \\\textbf{training} \\\textbf{duration}}}  & \multicolumn{2}{l|}{\makecell{\textbf{Single iteration}}} & \multicolumn{3}{l|}{\makecell{\textbf{Multiple iterations}}} \\ \cline{3-7}
        & & \makecell{\textbf{\#designs}\\ \textbf{optimized}} & \makecell{\textbf{Average} \\\textbf{time}} & \makecell{\textbf{\#designs} \\ \textbf{optimized}} &  \makecell{\textbf{Average} \\\textbf{time}} & \makecell{\textbf{Average}\\\textbf{\#iterations}} \\
        \hline
        5T-OTA & 8.5h  & 95/100 & 37s & 5/100 & 111s & 3\\
        \hline
        CM-OTA & 22h  & 98/100 & 46s & 2/100 & 230s & 5\\
        \hline
        2S-OTA & 11h & 90/100 & 36s & 10/100 & 180s & 5\\
        \hline
    \end{tabular}}
    \label{tab:runtime}
    \vspace{-5mm}
\end{table}

% \vspace{-2mm}

\subsection{Runtime analysis}
\noindent
Table~\ref{tab:runtime} provides a detailed runtime analysis, including both the one-time SPICE-based training duration and the average runtime per design optimization by the trained model. The reported runtime encompasses the entire process, from sequence inference by the trained transformer model (taking approximately 0.5s per sequence)
% -- where each sequence takes approximately 0.5 seconds -- 
to the LUT-based estimation and subsequent SPICE simulation verification. 
In cases where performance criteria are not fully met due to minor prediction inaccuracies, a ``copilot'' mode is activated, performing iterative refinements with progressively tighter specifications to introduce a design margin that compensates for errors. This ensures that all design specifications are ultimately satisfied, typically requiring only a few additional iterations, thereby balancing model accuracy with computational efficiency to achieve reliable design convergence. The runtime ranges from just above 30s to just under four minutes, significantly lower than competing methods.
% \vspace{-2mm}

\subsection{Qualitative comparison with prior approaches.}

\noindent
Table~\ref{tab:comparison} compares our approach for OTA sizing with prior methods, including simulated annealing (SA)~\cite{gielen_90}, particle swarm optimization (PSO)~\cite{vural_12}, graph convolutional network-based RL (GCN-RL)~\cite{Wang_2020}, weighted expected improvement-based Bayesian optimization (WEIBO)~\cite{lyu_18}, and differential evolutionary (DE) algorithm~\cite{liu_09}.
% \redfn{You never answered my question re. comparing against~\cite{budak_21}.\textbf{I haven not included ~\cite{budak_21}, because, firstly its RL, and it needs SPICE in the loop for convergence. Although it has significantly reduced the no. of simulations, it still needs $>100$ SPICE simulations. If I want to compare with this, I have to show the exact no. of SPICE Simulations required for our topologies. } {\em (1)~I don't understand your logic here. Have you shown the exact number of SPICE simulations for any of the methods in Table~\ref{tab:comparison}? I don't see it. So, why talk about the number for~\cite{budak_21}? \textbf{By looking at the numbers that Budak and rest of the papers have shown in their comparison, the number of simulations in ~\cite{budak_21} is way less than the rest of all the papers. Not only that, the previous papers using stochastic methods don't even have 100\% success rate. So in summary, Budak paper ~\cite{budak_21} is a close competitor and to beat that, solid number is necessary}. {\em If you need 3-5 iterations (as shown in your table), you need 3-5 SPICE simulations, right? If so, why is a paper with 100 simulations a ``close competitor''?} \textbf{Because their circuits are more complicated. They may not need 100 simulations for 5T OTA. So, its hard to claim that.} {\em OK, I buy your argument. Let's leave it out.} RESOLVED. OK(2)~Also -- I just noticed that you \underline{never} refer to Table~\ref{tab:comparison} anywhere in the paper!! Please double-check that all figures and tables are cited at least once in the text of the paper. It is pointless to drop in a table without citing it in the paper. This section needs a clear pointer to the table (which I have now added in the first sentence).} \textbf{Even I am surprised with this ignorance of mine. I mentioned it initially, but later was rephrasing and deleted it somehow. I checked the rest of the paper for all the figures and tables, and they all are cited at their designated sections.} RESOLVED}

We utilize various metrics for comparison. \textit{SPICE simulation dependency} gauges the reliance on costly simulations for convergence: lower dependence indicates greater efficiency. \textit{Sizing accuracy} measures how well the approach satisfies all design specifications.
% \textit{Optimization efficiency} captures the trade-off between resource usage and the ability to find optimal designs, while sizing accuracy evaluates how reliably each method determines correct transistor sizes.
% \redfn{What is your basis for saying this method is high? You never evaluate whether the sizing is performed at low area or power -- so what is your metric for deciding that this is true? \textbf{I probably thought about this metric in the wrong way. I thought of it as a function of the performance of the optimized design and computational cost for the optimization.} {\em So how did you think about it? What is your basis for saying that the optimization efficiency is high? Can you use a different term that captures what you were trying to say?} \textbf{I feel like this metric is kind of redundant now. We have SPICE simulation dependency metric and Convergence cost, which pretty much covers this metric as well.} {\em I am ok with removing this row of the table.} RESOLVED (from my end).} 
\textit{Runtime} reflects the time required to reach a solution, and \textit{memory utilization} pertains to the amount of memory resources consumed during the optimization process.
% \redHL{\sout{resource usage} runtime}.
% \redfn{Unclear what a ``resource'' is in this context. \textbf{Time and memory due to SPICE simulations} {\em How is this different from ``SPICE simulation dependency'' which seems to already cover this issue?} \textbf{I thought of mentioning this explicitly because at the end overall sizing duration is the most important factor in favor of us.} {\em Can we maybe focus just on runtime and skip memory (which is harder to quantify anyway)? If so, could this row by ``Runtime'' and then you could list it as hours/days/... for others and 0.5s for us. Again, there is the issue of more complicated circuits -- not sure if it makes it hard to use their numbers directly?} \textbf{Prof, I don't think using their numbers would work. } {\em OK. Can we still change it to ``runtime'' or are you trying to say something different?}\textbf{We can definitely use ``runtime''} {\em OK, please make that change. It feels more concrete and is in line with our claims.} RESOLVED OK} 
% \redfn{I had provided feedback on this table, but it is not clear if it was read. There is no change to the table, and I see no email explaining why this form is better. You should not ignore my feedback. If you disagree, that's ok -- but make an argument against what I am saying rather than just ignoring my feedback and throwing it in the trash. \textbf{Prof, I considered your feedback and included the modified comparison by using the terms "Moderate to low", "Very slow" just to distinguish between two "High" and "High" which I did previously. Unfortunately reporting approx no. of SPICE simulations may raise questions. Cause in that case we have to tell about our implementation of the other approaches and then check for no. of simulations for our OTA topologies.} {\em OK, this is a reasonable argument. But you need to make such arguments to me, not unilaterally make decisions without consultation. Your logic is right in this case, but there may be other cases when it is not. We cannot have decisions without discussion.} \textbf{Yes Prof. I totally agree. } RESOLVED} 
Our approach, using a trained transformer model with precomputed LUTs, significantly reduces SPICE simulation dependency -- achieving over 90\% of sizing without simulations -- while improving accuracy and reducing runtime from hours to seconds, positioning it as a highly efficient solution.
% \redfn{One more thing: what is the difference between the last two rows -- runtime and computational cost? And also ``convergence speed''? All seem to be very similar. \textbf{Computational cost mean the total memory utilization due to Simulations } That is not obvious. Maybe use the terms you mean -- e.g., memory, runtime, etc.? I don't think the average reader will understand computational cost == runtime. \textbf{Should I use just ``Memory'' or ``Memory utilization or requirement''?} Either is ok. Maybe ``Memory utilization'' is ok. RESOLVED.}
% \redfn{I don't really see the relationship between the table and these statements. You connect it directly to ``SPICE simulation dependency'' but I don't see any of the other keywords in column 1 of the table. \textbf{I connect to SPICE simulation dependency, convergence speed, and computational cost, because those are the only metrics which are in favor of us, which I have shown in BOLD in the table} {\em Yes, but this text does not use any of those terms. If you want to connect it to the table, use the same terms in the text.} RESOLVED}

% \blueHL{Many comments on the table: (1)~When you say that the training cost is ``High'' in all cases -- is it equally high? Can you be more quantitative by reporting the number of hours? \textbf{I will think about this} (2)~Unclear how ``Handle layout parasitics'' is a yes for us -- we also work on a schematic.  I don't see anything in your paper about handling layout parasitic. \textbf{We haven't demonstrated that, but from principle, the way we use DPSFG, will allow inclusion of more R's and C's into the graph} (3)~``90\% SPICE-independent sizing'' is poorly stated and will not convey what you want to say.  Can you report the number of SPICE simulations instead? Similarly, ``SPICE-based convergence'' is a poor descriptor and the reader will have no idea what you are saying. The footnote clarifies it a bit, but you can put some effort into making yourself more clear in the table too. (4)~``Sizing duration'' sounds amateurish.  Something like ``Runtime of the sizer'' would be better.}

\begin{table}[ht]
    \centering
    \vspace{-2mm}
    \caption{Qualitative comparison with prior sizing approaches. }
    % \redHL{Why are some items bf and others not? If we are trying to bf our approach, why is sizing accuracy = high not in bf?} \textbf{Because, its high for others also, so nothing special in our method.}}
    \resizebox{1\linewidth}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        \makecell{\textbf{Sizing method}} & \makecell{\cite{gielen_90}} & 
        \makecell{\cite{vural_12}} &
        \makecell{\cite{Wang_2020}} &
        \makecell{\cite{lyu_18}} &  
         \makecell{\cite{liu_09}} &
         \makecell{\textbf{Our approach}}
         \\
        \hline
        \textbf{Algorithm} & SA & PSO & \makecell{GCN \\ + RL} & WEIBO & DE & \makecell{Transformer \\ + LUT } \\
        \hline
        \makecell{\textbf{SPICE simulation} \\ \textbf{dependency}} & \makecell{Very high} & \makecell{Very high} & \makecell{Low to \\ moderate}& \makecell{High} &  \makecell{Very high} & \makecell{\textbf{Very low\textsuperscript{*}}}\\
        % \hline
        % \makecell{\textbf{Optimization} \\ \textbf{efficiency}} & \makecell{Moderate \\ to low} & \makecell{Moderate \\ to low} & Moderate &  High & High & High\\
        \hline
        \makecell{\textbf{Sizing accuracy}}& Variable & \makecell{Moderate \\ to high}& High & High & High & \makecell{ High}\\
        \hline
        \makecell{\textbf{Runtime}} & \makecell{Very slow}& \makecell{Very slow}& \makecell{Moderate}& \makecell{Moderate}  & \makecell{Slow}& \makecell{\textbf{Very fast}} \\
        \hline
        \makecell{ \textbf{Memory} \\ \textbf{utilization}} & Moderate & Moderate & \makecell{Moderate \\ to high}& \makecell{High} & \makecell{Very high} & \makecell{\textbf{Moderate} \\ \textbf{to low}}\\
        
        
        \hline
    \end{tabular}}
    \label{tab:comparison}
    \scriptsize\textsuperscript{*} $>$90\% of sizing is performed without SPICE simulations, as shown in Table~\ref{tab:runtime}.
    \vspace{-3mm}
\end{table}





% %Original
% \begin{table}[ht]
%     \centering
%     \vspace{-1mm}
%     \caption{Qualitative comparison with prior sizing approaches.}
%     \resizebox{1\linewidth}{!}{
%     \begin{tabular}{|c|c|c|c|c|c|c|}
%         \hline
%         \makecell{\textbf{Sizing method}} & \makecell{\cite{gielen_90}} & \makecell{\cite{liu_09}} &  
%         \makecell{\cite{vural_12}} & \makecell{\cite{lyu_18}} &
%         \makecell{\cite{Wang_2020}} & \makecell{\textbf{Our} \\ \textbf{approach}}
%          \\
%         \hline
%         \textbf{Algorithm} & SA & DE & PSO & WEIBO & \makecell{GCN \\ + RL} & \makecell{Transformer \\ + LUT } \\
%         \hline
%         \makecell{\textbf{SPICE simulation} \\ \textbf{dependency}} & \makecell{Very \\ high} & \makecell{Very \\ high} & \makecell{Very \\ high} &  \makecell{High} & \makecell{Low to \\ moderate}& \makecell{\textbf{Very} \\ \textbf{low\textsuperscript{*}}}\\
%         % \hline
%         % \makecell{\textbf{Optimization} \\ \textbf{efficiency}} & \makecell{Moderate \\ to low} & \makecell{Moderate \\ to low} & Moderate &  High & High & High\\
%         \hline
%         \makecell{\textbf{Sizing accuracy}}& Variable & High & \makecell{Moderate \\ to high} & High & High & \makecell{ High}\\
%         \hline
%         \makecell{\textbf{Runtime}} & \makecell{Very \\ slow}& \makecell{Slow}& \makecell{Very \\ slow}  & \makecell{Moderate} & \makecell{Moderate} & \makecell{\textbf{Very} \\ \textbf{fast}} \\
%         \hline
%         \makecell{ \textbf{Memory} \\ \textbf{utilization}} & Moderate & \makecell{Very \\ high} & Moderate & High & \makecell{Moderate \\ to high} & \makecell{\textbf{Moderate} \\ \textbf{to low}}\\
        
        
%         \hline
%     \end{tabular}}
%     \label{tab:comparison}
%     \scriptsize\textsuperscript{*}$ >90\%$ of sizing is done without SPICE simulations, as shown in Table~\ref{tab:runtime}.
%     % \vspace{-4.5mm}
% \end{table}


% \redfn{\textbf{**FIXED**}The table has numerous problems: (1)~``next few iterations'' is not a scientific statement. How many iterations? (2)~What is the criterion for tightening the specifications? (3)~Presentation issues: (a)~1st (informal usage) $\rightarrow$ first; (b)~No. $\rightarrow$ number (this is also pointed out elewhere); (c)~Successfully sized designs $\rightarrow$ Number of designs that meet all specifications}









