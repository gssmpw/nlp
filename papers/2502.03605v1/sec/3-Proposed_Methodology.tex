\section{Proposed Methodology}
\label{sec:sizing_framework}

\subsection{Overview of the solution}

\noindent
We leverage transformer models to capture the complex relationships between device attributes and circuit performance. We conceptualize the transistor sizing problem as a language translation task, where the input sequence consists of a DP-SFG representation for an OTA circuit, together with performance specifications. The transformer model generates an enhanced DP-SFG representation with the device characteristics necessary to meet the specifications.

\begin{figure}[b]
  \vspace{-5mm}
  \centering
  \includegraphics[width=0.85\linewidth,bb=0 0 295 180]{fig/Toplevel.pdf} % Replace example-image with your image file
  % \vspace{-0.5cm}
  \caption{Overall sizing flow using our transformer-based method.}
  \label{fig:toplevel}
  % \vspace{-2mm}
\end{figure}

Fig.~\ref{fig:toplevel} illustrates the workflow of our framework, with four stages. Stage I performs preprocessing, generating the DP-SFG from the circuit netlist.  The DP-SFG and the designer-specified performance constraints are then tokenized into a combined sequence. Next, in Stage II, a transformer model processes these tokens to predict circuit parameters that meet performance specifications; these are then translated to individual device widths in Stage III using the precomputed LUTs and a $g_m/I_d$ methodology. Finally, in Stage~IV, the performance of the predicted sized circuit is verified using SPICE simulation. In a vast majority of cases, we will show that the performance criteria are satisfied; if not, the designer is brought into the loop to provide tighter specifications, and procedure is reinvoked so that the original specifications are met. The remainder of this section discusses the detailed implementation of each stage.

% \input{sec/DPSFG_pseudocode}
\vspace{-2mm}
\subsection{Circuit-to-sequence mapping using the DP-SFG}
\label{sec:dp-sfg}


\noindent
The procedure for creating the DP-SFG formalizes the approach in~\cite{schmid_18,schmid_yt}. We use the running example of an active inductor circuit, whose DP-SFG is shown in Fig.~\ref{fig:DP-SFG_ex}(b) to illustrate the method.


\noindent
\textbf{Step 0: Initial bookkeeping and node initialization}
The algorithm begins with initializing the vertex (or node) set $V$, and initializing data structures for fast access to connectivity information between circuit components (RCs, transistors, etc.) from the netlist. 

\noindent
\textbf{Step 1: Insertion of auxiliary nodes.} 
For nodes that are not connected to voltage sources, we create auxiliary voltage sources. These sources are described by $V = z I$, where $z$ is the driving point impedance (DPI) at the node, i.e., the the inverse sum of all conductances connected to the node. In Fig.~\ref{fig:DP-SFG_ex}, auxiliary sources are added at nodes~1 and~2. The sources replicate node voltages without introducing additional current into the circuit.  This establishes relationships $V_1 = z_1 I_1 $ and $V_2 = z_2 I_2$, where 
\begin{equation}
z_1 = \frac{1}{sC+sC_{\textit{ds}}+sC_{\textit{gs}}+g_{\textit{ds}}}, \; \;
z_2 = \frac{1}{sC+sC_{\textit{gs}}+G}
\end{equation}

\noindent
\textbf{Step 2: Adding branches due to passive components.} Next, we add the edges associated with passive components. We consider how each terminal connects to auxiliary sources. If a terminal connects to an auxiliary source, we connect it to the auxiliary node of the other terminal using its admittance as the edge weight. If neither terminal connects to an auxiliary source, we connect them with an edge using the admittance of the component. In Fig.~\ref{fig:DP-SFG_ex}, the terminals of capacitor \( C \) are both connected to auxiliary sources carrying currents \( I_1=s(C + C_{\textit{gs}}) V_2 \) and \( I_2=s(C + C_{\textit{gs}}) V_1 \) through the associated edges.

\noindent
\textbf{Step 3: Adding branches due to transistor transconductances.} 
The voltage at each terminal of a transistor influences its drain current. Based on these terminal voltages, we establish connections that directly or indirectly affect the auxiliary node currents. In the example of Fig.~\ref{fig:DP-SFG_ex}, if $V_1$ increases, the drain current $I_d$ increases, and hence current flowing to $I_1$ decreases in the opposite direction. This is reflected by setting the weight on the branch from $V_1$ to $I_1$ to $-g_m$. Similarly, the branch $V_2$ to $I_1$ has weight $+g_m$, reflecting the positive dependence of drain current $I_d$ with $V_2$. 

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\linewidth, bb=0 0 240 170]{fig/dpsfg_seq.pdf} % Replace example-image with your image file
  \caption{\textbf{Input:} DP-SFG paths with desired performance specifications, \textbf{Output:} Predicted sequences with device parameter values.}
  \label{fig:seq}
  \vspace{-0.4cm}
\end{figure}

At the end of Step~3, we obtain the final DP-SFG in Fig.~\ref{fig:DP-SFG_ex}(b) for the active inductor circuit. We will encode such a DP-SFG into sequential data that encapsulates the functionality of the circuit as well as the parameters of circuit components, including parasitics. This sequence representation is provided as an input to the transformer and is eventually used to size transistors in the circuit. We utilize the NetworkX Python package to process the final DP-SFG. This approach utilizes Johnson's algorithm ($O(V^2 \log V + VE)$ complexity) to identify all cycles, and the depth-first search algorithm ($O(V + E)$ complexity) to find all forward paths, where $V$ represents the number of nodes and $E$ represents the number of edges in the graph. 
For our running example, Fig.~\ref{fig:seq} shows the sequences obtained from the DPSFG. Specifically, the path outlined by red dotted rectangle represents the forward path between input and output nodes, while the blue and green outlined paths denote the cycles.
% \bluefn{(1)~This does not make sense. There are no paths in this figure: the paths are in Fig. 2.  \textbf{FIXED} Additionally, ``blue/green/red marked paths'' does not make sense because the paths are only outlined with a dotted rectangle, not ``marked'' by these colors. \textbf{FIXED} See change to next paragraph for the specs, and please change this accordingly. (2)~The blue path in Fig. 2 does not seem to correspond to the path shown with the blue dotted rectangle that you reference here, which is supposed to be a forward path between input and output nodes -- that path is a cycle.  Same for the path marked by the green dotted rectangle in Fig. 2. Are they supposed to be related? If so, please make consistent. And if not, please change because it is confusing. \textbf{FIXED}} SSS_NOTE

















\ignore{
\noindent
\textbf{Step 0: Initial bookkeeping and node initialization (lines~\ref{algo1:init_begin} to~\ref{algo1:init_end})}
The algorithm begins with initializing the vertex set $V$,
and initializing data structures for fast access to connectivity information between circuit components (RCs, transistors, etc.) from the netlist. 

\noindent
\textbf{Step 1: Insertion of auxiliary nodes (lines~\ref{algo1:step1_begin} to~\ref{algo1:step1_end})} 
Following the DP-SFG construction procedure in~\cite{schmid_18}, for nodes that are not connected to voltage sources, we create auxiliary voltage sources. These sources are described by $V = z I$, where $z$ is the driving point impedance (DPI) at the node, i.e., the
the inverse sum of all conductances connected to the node. In Fig.~\ref{fig:DP-SFG_ex}, auxiliary sources are added at nodes~1 and~2. The sources replicate node voltages without introducing additional current into the circuit. 
 
\redHL{CK: I haven't checked the math as it is due today. This is the part I worry about. Also SFG fomulations apply to only "linearizable" circuits like an op-amp. We should say something about handling general non-linearities. You could say that usually there is linear model lurking somewhere by transformation for example a PLL in phase domain. For others, this could used for studying stability by perturbation around a steady state which can be modeled linearly.}
This establishes relationships $V_1 = z_1 I_1 $ and $V_2 = z_2 I_2$, where 

\begin{equation}
z_1 = \frac{1}{sC+sC_{\textit{ds}}+g_{\textit{ds}}}, \; \;
z_2 = \frac{1}{sC+G}
\end{equation}

\noindent
\textbf{Step 2: Adding branches due to passive components and external sources (lines~\ref{algo1:step2_begin} to~\ref{algo1:step2_end})} Next, we add the edges due to passive components. We consider how each terminal connects to auxiliary sources. If a terminal connects to an auxiliary source, we connect it to the auxiliary node of the other terminal using the admittance of the component as the edge weight. If neither terminal connects to an auxiliary source, we connect them with an edge using the admittance of the component. In Fig.~\ref{fig:DP-SFG_ex}, both terminals of capacitor \( C \) are connected to auxiliary sources, allowing currents \( I_2 = (sC) V_1 \) and \( I_1 = (sC) V_2 \) to flow through the edges.


\noindent
\textbf{Step 3: Adding branches due to transistor transconductance (lines~\ref{algo1:step3_begin} to~\ref{algo1:step3_end})} 
In this step, we analyze the impact of the transistor transconductance. The voltage at each terminal of a transistor influences its drain current. Based on these terminal voltages, we establish connections that directly or indirectly affect the auxiliary node currents. In the example of Fig.~\ref{fig:DP-SFG_ex}, if $V_1$ increases, the drain current $I_d$ increases, and hence current flowing to $I_1$ decreases. Due to this the weight on the branch from $V_1$ to $I_1$ is set to $-g_m$. Similarly, the branch $V_2$ to $I_1$ has weight $+g_m$, reflecting the positive dependence of drain current $I_d$ with $V_2$. 

\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{fig/DPSFG_paths.pdf} % Replace example-image with your image file
  \vspace{-0.5cm}
  \caption{Sequential paths of DP-SFG, Performance specifications, and transformer predicted sequence with device parameters}
  \label{fig:seq}
  \vspace{-0.4cm}
\end{figure}

At the end of Step~3, we obtain the final DP-SFG in Fig.~\ref{fig:DP-SFG_ex}(b) for the active inductor circuit. We will encode such a DP-SFG into sequential data that encapsulates the functionality of the circuit as well as the parameters of circuit components, including parasitics. This sequence representation is provided as an input to the transformer and is eventually used to size transistors in the circuit. We utilize the NetworkX Python package to process the final DP-SFG. This approach utilizes Johnson's algorithm ($O(V^2 \log V + VE)$ complexity) to identify all cycles and the depth-first search algorithm ($O(V + E)$ complexity) to find all forward paths, where $V$ represents the number of nodes and $E$ represents the number of edges in the graph.

For our running example, the sequence is derived from the paths 
marked in the DP-SFG in Fig.~\ref{fig:seq}.
Specifically, the blue marked path represents the forward path between input and output nodes, while the red and green marked paths denote the cycles. 
}

\subsection{Implementation of the transformer}

\noindent
\textbf{Transformer inputs.} The transformer model comprehends the interdependencies between device parameters and circuit performance metrics. We frame the paths by concatenating the nodes and edge weights from the DPSFG for every forward path and loop. The transformer takes in the list of paths extracted from the DP-SFG, each augmented with the desired set of specifications outlined by the black dotted rectangle in Fig.~\ref{fig:seq}. The transformer acts on the sequences and predicts the device parameters $g_m$, $g_{ds}$, $C_{ds}$, and $C_{gs}$ which will satisfy the desired specifications.


\noindent
\textbf{Overall transformer architecture.}
We implement the transformer in Python, leveraging the PyTorch library. The architecture of the transformer model closely resembles the one proposed by~\cite{vaswani_17}, with minor modifications. We use a 720-dimensional input embedding with 12 heads of parallel attention layers, while keeping the rest of the parameters unchanged.

\noindent
\textbf{Tokenization and byte-pair encoding}.
Tokenization is a crucial step for optimizing transformer efficacy. It breaks down a long sequence into smaller entities called tokens. Unlike in traditional NLP, where individual words and sub-words are treated as tokens, we use specific groups of individual characters such as the key device parameters $g_m, g_{ds}$, $C_{ds}$, $C_{gs}$, edge weights, and the names of the transistors, as tokens that convey necessary information about the circuit. 

For our problem, character-level tokenization (CLT), where each character is treated as a single token, is found to lead to long sequence lengths, i.e., a large number of tokens within a single sequence, resulting in computational inefficiency.
To overcome this problem, we employ the byte-pair encoding (BPE) approach~\cite{rico_16}.
This approach iteratively combines the most frequently occurring tokens (bytes) into a single token,
and dynamically adapts the vocabulary of the training data to capturing a common group of characters conveying essential information. By applying BPE, we achieve a 3.77$\times$ compression of the sequence lengths compared to the use of CLT, 
% \bluefn{Compared to what baseline? CLT? This is meaningless without stating the baseline. \textbf{FIXED}} 
leading to substantial savings in training time and memory requirements.

To demonstrate tokenization and for an actual DP-SFG path, we choose a partial path of a five-transistor operational transconductance amplifier (5T-OTA). The results of CLT and BPE are:
% character-level tokenization $(A)$ and BPE $(B)$.

\noindent
% \textit{Character-level encoding:} Character-level coding treats every single character as an independent individual token, as shown below:\\ 
CLT: \textcolor{white}{\sethlcolor{blue}\hl{3}\sethlcolor{red}\hl{2} \sethlcolor{orange}\hl{g}\sethlcolor{teal}\hl{m}\sethlcolor{violet}\hl{P}\sethlcolor{brown}\hl{1} \sethlcolor{red}\hl{-}\sethlcolor{pink}\hl{1}\sethlcolor{gray}\hl{6}
\sethlcolor{blue}\hl{1}\sethlcolor{black}\hl{/}\sethlcolor{cyan}\hl{(}\sethlcolor{orange}\hl{g}\sethlcolor{lightgray}\hl{d}\sethlcolor{blue}\hl{s}\sethlcolor{teal}\hl{M}\sethlcolor{purple}\hl{0}\sethlcolor{pink}\hl{+}\sethlcolor{magenta}\hl{s}\sethlcolor{teal}\hl{C}\sethlcolor{lightgray}\hl{d}\sethlcolor{brown}\hl{s}\sethlcolor{red}\hl{M}\sethlcolor{blue}\hl{0}\sethlcolor{pink}\hl{+}\sethlcolor{gray}\hl{s}\sethlcolor{black}\hl{C}\sethlcolor{lightgray}\hl{d}\sethlcolor{orange}\hl{s}\sethlcolor{violet}\hl{P}\sethlcolor{blue}\hl{1}\sethlcolor{pink}\hl{+}\sethlcolor{orange}\hl{g}\sethlcolor{teal}\hl{m}\sethlcolor{violet}\hl{P}\sethlcolor{blue}\hl{1}\sethlcolor{cyan}\hl{)}} 

% \textcolor{white}{\sethlcolor{blue}\hl{32} \sethlcolor{orange}\hl{gmP1} \sethlcolor{red}\hl{-16}
% \sethlcolor{blue}\hl{1/(}\sethlcolor{orange}\hl{gdsM0}\sethlcolor{pink}\hl{+}\sethlcolor{lightgray}\hl{s}\sethlcolor{teal}\hl{CdsM0}\sethlcolor{pink}\hl{+}\sethlcolor{lightgray}\hl{s}\sethlcolor{black}\hl{CdsP1}\sethlcolor{pink}\hl{+}\sethlcolor{orange}\hl{gmP1}\sethlcolor{cyan}\hl{)}} 


\noindent
BPE: 
% \textcolor{white}{\sethlcolor{blue}\hl{3}\sethlcolor{pink}\hl{2}\sethlcolor{pink} \hl{2}\sethlcolor{orange}\hl{.}\sethlcolor{violet}\hl{5}\sethlcolor{black}\hl{m}\sethlcolor{magenta}\hl{S}\sethlcolor{orange}\hl{P}\sethlcolor{cyan}\hl{1} \sethlcolor{red}\hl{-}\sethlcolor{cyan}\hl{1}\sethlcolor{brown}\hl{6}
% \sethlcolor{cyan}\hl{1}\sethlcolor{orange}\hl{/}\sethlcolor{red}\hl{(}\sethlcolor{violet}\hl{5}\sethlcolor{black}\hl{6}\sethlcolor{cyan}\hl{7}\sethlcolor{teal}\hl{u}\sethlcolor{magenta}\hl{S}\sethlcolor{violet}\hl{M}\sethlcolor{olive}\hl{0}\sethlcolor{pink}\hl{+}\sethlcolor{magenta}\hl{s}\sethlcolor{olive}\hl{0}\sethlcolor{orange}\hl{.}\sethlcolor{cyan}\hl{7}\sethlcolor{black}\hl{a}\sethlcolor{red}\hl{F}\sethlcolor{teal}\hl{M}\sethlcolor{olive}\hl{0}\sethlcolor{pink}\hl{+}\sethlcolor{magenta}\hl{s}\sethlcolor{violet}\hl{5}\sethlcolor{red}\hl{4}\sethlcolor{gray}\hl{1}\sethlcolor{black}\hl{a}\sethlcolor{red}\hl{F}\sethlcolor{darkgray}\hl{P}\sethlcolor{cyan}\hl{1}\sethlcolor{pink}\hl{+}\sethlcolor{pink}\hl{2}\sethlcolor{orange}\hl{.}\sethlcolor{violet}\hl{5}\sethlcolor{black}\hl{m}\sethlcolor{magenta}\hl{S}\sethlcolor{orange}\hl{P}\sethlcolor{cyan}\hl{1}\sethlcolor{purple}} 
\textcolor{white}{\sethlcolor{blue}\hl{32}\sethlcolor{pink} \hl{2}\sethlcolor{orange}\hl{.}\sethlcolor{violet}\hl{5}\sethlcolor{black}\hl{mS}\sethlcolor{orange}\hl{P1} \sethlcolor{red}\hl{-16}
\sethlcolor{blue}\hl{1/(}\sethlcolor{violet}\hl{5}\sethlcolor{black}\hl{6}\sethlcolor{cyan}\hl{7}\sethlcolor{orange}\hl{uS}\sethlcolor{violet}\hl{M0}\sethlcolor{pink}\hl{+}\sethlcolor{magenta}\hl{s}\sethlcolor{pink}\hl{0}\sethlcolor{violet}\hl{.}\sethlcolor{cyan}\hl{7}\sethlcolor{black}\hl{aF}\sethlcolor{teal}\hl{M0}\sethlcolor{pink}\hl{+}\sethlcolor{gray}\hl{s}\sethlcolor{violet}\hl{5}\sethlcolor{red}\hl{4}\sethlcolor{gray}\hl{1}\sethlcolor{black}\hl{aF}\sethlcolor{darkgray}\hl{P1}\sethlcolor{pink}\hl{+}\sethlcolor{pink}\hl{2}\sethlcolor{orange}\hl{.}\sethlcolor{violet}\hl{5}\sethlcolor{black}\hl{mS}\sethlcolor{orange}\hl{P1}} 

% \hfill--$(B)$

\noindent
The CLT sequence colors each neighboring character differently, denoting the tokenization of each unique character. However, CLT cannot easily comprehend the relation to device parameters or device names. The BPE approach overcomes this by iteratively combining frequently-occurring tokens. For example, BPE combines tokens such as
gmP1, gdsM0, and CdsM0 to represent $g_m$ of transistor P1, and $g_{ds}$ and $C_{ds}$ of transistor M0, respectively. Similarly, character-level tokens for the units of circuit parameters (e.g., ``mS'' or ``aF'') are combined into tokens of multiple characters. However, all purely numeric strings are left uncombined, as shown in the BPE sequence. For instance, for the value 2.5mS, which corresponds to the $g_m$ of transistor P1, the tokens representing 2.5 are maintained as character-level tokens, enabling the transformer to predict each digit relative to performance metrics independently, but the two character-level tokens for ``mS'' are combined into a single token. This restricted BPE representation thus enables the transformer model to better comprehend circuit relationships, as compared with CLT.





\noindent
\textbf{Loss Function.}
To enhance the learning of device parameter prediction from specified inputs, we utilize a weighted cross-entropy loss function for the transformer. Each token is treated as a separate class, with the loss function assigning greater importance to classes critical for accurate predictions. We focus on tokens representing numerical values of device characteristics (e.g., $g_m$, $g_{ds}$, $C_{ds}$, and $C_{gs}$), ensuring they receive more attention during training. This approach allows the transformer to grasp the significance of these characteristics and their impact on performance. Our experiments compared unweighted and weighted loss functions with varying weights, revealing that applying a 20\% increased weight on the numerical tokens yielded optimal performance.


\vspace{-0.02cm}
\subsection{Translating circuit parameters to device widths}
\label{sec:precomputedLUTs}

\noindent
After the trained transformer predicts the values of circuit parameters, they must be transformed to device widths. 
In this section, we describe a methodology 
% that uses the LUT from Section~\ref{sec:LUT} 
for this purpose.

\subsubsection{\textbf{Device characterization}}

In older technologies, the square-law model for MOS transistors could be used to perform a translation between circuit parameters and transistor widths, but square-law behavior is inadequate for capturing the complexities of modern MOS transistor models. In this work, we use a precomputed lookup table (LUT) that rapidly performs the mapping to device sizes while incorporating the complexities of advanced MOS models.

\begin{figure}[t]
% \vspace{-0.4cm}
\centering
\includegraphics[height=3cm, , bb=0 0 210 100]{fig/lut_fig_new.pdf}
% \vspace{-0.55cm}
\caption{LUT generation and characterization.}
\label{fig:lutgen}
\vspace{-5mm}
\end{figure}

The LUT is indexed by the $V_{gs}$, $V_{ds}$, and length $L$ of the transistor, and provides five outputs: the drain current ($I_d$), transconductance ($g_m$), drain-source conductance ($g_{ds}$), drain-source capacitance ($C_{ds}$), and gate-source capacitance ($C_{gs}$) all computed per unit transistor width. The entries of the LUT are computed by performing a nested DC sweep simulation across the input indices for the MOSFET with a specific reference width, $W_{ref}$, as shown in Fig.~\ref{fig:lutgen}, and for each input combination, the five outputs are recorded. Since the five quantities all vary linearly with the width of the transistor, we store their corresponding values per unit width. 
% Empirically, we see that the impact of $V_{sb}$ is small enough
% \bluefn{For my info: over what range of $V_{sb}$ have you done this, and why is that sufficient? \textbf{I chose the range between (0 - $V_{dd}/3$), this is due to having around three mosfets b/n $V_{dd}$ and ground in our circuits. For example, in the 5T OTA the $V_{sb}$ for the DP is non-zero since the source is sitting on top of the tail mosfet, and the voltage (Vds) across the tail mos is usually $<$vdd/3}} SSS_NOTE
% that it can be neglected, and therefore we set $V_{sb} = 0$ in the sweeps used to create the LUT. 
The LUT stores the vector-valued function
% \vspace{-2mm}
\begin{align}
[I_d \;\; g_m \;\; g_{ds} \;\; C_{ds} \;\; C_{gs}] = f(V_{gs}, V_{ds})
\end{align}

We have constructed a lookup table for a 65nm technology with a reference transistor width of 700nm, with $V_{gs}$ and $V_{ds}$ values ranging from 0--1.2V with a 60mV step. Given the relatively coarse granularity of data points in the LUT, we have implemented cubic spline interpolation to enhance accuracy at intermediate values. These LUT granularity, together with interpolation, ensures that it provides accurate predictions, and yet has a reasonable size.  

Our methodology uses this LUT, together with the $g_m/I_d$ methodology~\cite{silviera_96,jespers_17}, to translate circuit parameters predicted by the transformer to transistor widths. The cornerstone of this methodology relies on the inherent width independence of the ratio $g_m/I_d$ to estimate the unknown device width: this makes it feasible to use an LUT characterized for a reference width $W_{ref}$. 





\ignore{
The device characterization stage involves studying how transistor small signal parameters vary with the device size and external voltages applied between the terminals: gate-to-source voltage ($V_{gs}$), drain-to-source voltage ($V_{ds}$), and source-to-bulk voltage ($V_{sb}$). This analysis explores the relationship between the DoFs and output parameters such as drain current $I_d$, $g_m$, $g_{ds}$, and $C_{ds}$. 
\begin{align}
I_d, g_m, g_{ds}, C_{ds}, \dots & \Rightarrow f(V_{gs}, V_{ds}, V_{sb}, L, W)
\end{align}
\begin{equation}
I_d  = \mu_nC_{ox}\frac{W}{L} \times f(V_{gs},V_{ds},V_{sb})
\label{eq:width_indp}
\end{equation}
From equation \eqref{eq:width_indp}, it is evident that the drain current ($Id$) exhibits a linearly proportional relationship with the width (W). This relationship holds for the quadratic behavior of the $I_d$ both in the linear and saturation regions. It is also generally acceptable for other parameters, i.e., $g_m$, $g_{ds}$, $C_{ds}$. Although there may be slight deviations in practical scenarios, these can usually be overlooked for simplification~\cite{jespers_17}.

Our method primarily focuses on $V_{gs}$ and $V_{ds}$, and $L$ with the assumption of a fixed $V_{sb}$ value of zero; this assumption gives a reasonably accurate approximation, reducing analysis to a model with three degrees of freedom: $f(V_{ds}, V_{gs}, L)$. We constructed a lookup table with a reference width of $700nm$ based on $V_{gs}$ and $V_{ds}$ values ranging from $0$ to $1.2V$ with a $60mV$ step, and five lengths starting from $100nm$ to $180nm$ with $20nm$ step. These chosen values ensure that the LUT remains reasonably sized for efficient lookup operations.  

Given the relatively coarse granularity of our data points in the LUT, we implemented cubic spline interpolation to enhance accuracy when retrieving values from the lookup table.
}

\subsubsection{\textbf{Width estimation}} 

The width estimation process uses the recorded LUT and transformer-predicted MOSFET parameters to compute the optimal width. The pseudocode for the algorithm employed is presented in Algorithm~\ref{algo:width_estimation}. 
After initialization on line~\ref{algo2:init}, the input is converted to the desired $g_m/I_d$ ratio.  Lines~\ref{algo2:while_begin}--\ref{algo2:while_end} iterate over the LUT to find the $W$ that matches the transformer-supplied parameters. Specifically, line~\ref{algo2:gmId} finds the value of $V_{gs}$ at which the $g_m/I_d$ ratio is met. For this value, lines~\ref{algo2:wcalc_begin}--\ref{algo2:wcalc_end} determine candidate values of $W$, $w_1, \cdots, w_5$, by ratioing $I_d^{in}$, $g_m^p$, $g_{ds}^p$, $C_{ds}^p$, and $C_{gs}^p$, respectively, with the corresponding LUT outputs. We iterate over $V_{ds}$ until $w_1, \cdots, w_5$ are as close as possible. Line~\ref{algo2:while_end} takes a step in this direction using the empirically chosen factor $\alpha = 10^{-4}$. The iterations continue until the candidate width values converge.



\ignore{
\\
\noindent\textbf{Step 1: Operating points calculation} (lines 5 to 11), using the parameters obtained from the transformer, i.e., $g_m^p$ and $I_d$ the $g_m/I_d$ operating point is calculated. Then in lines 7 to 11, the $g_m$ and $I_d$ values are read from the table with initial $V_{ds}$ and $L$, as a function of $V_{gs}$. $V_{gs}$ value that satisfies the calculated $g_m/I_d$ operating point is then obtained from the ratio of the $V_{gs}$ dependent $g_m$ and $I_d$ functions.  

\noindent\textbf{Step 2: Reading parameters as a function of $V_{ds}$} (line 12), by treating these parameters as a function of $V_{ds}$ we eliminate dependency on the initial guess $V_{ds}$ value, which unlike the $g_m/I_d$, significantly affect the other four parameters.

\noindent\textbf{Step 3: Normalization of parameters} (line 13) Based on the width proportionality property stated in equation \eqref{eq:width_indp} the parameters are made to be width independent by normalizing them with $W_{ref}$.

\noindent\textbf{Step 4: Calculating width and the total cost} (lines 14 to 17) next, the widths corresponding to each transformer-predicted parameter are calculated. These widths are used to determine the total cost, defined as the total deviation of the computed widths as a function of $V_{ds}$. Our objective is to find a width value that ensures the predicted parameters. Therefore, the minimum point of the cost function, where most widths align, is taken as the minimum cost.

\noindent\textbf{Step 5: Iterate until optimal accuracy is achieved}, the difference, $\Delta$, between the minimum cost obtained from the above step and the previous cost. The iteration continues until the cost no longer improves, which is controlled by a minimum value, $\epsilon$. Alongside this process, the $V_{ds}$ value is also updated with the direction determined by the sign of $\Delta$ and the magnitude by another variable, $\alpha$. Here $\alpha$ and $\epsilon$ are user-defined parameters; their values are obtained by manually tuning them using the training dataset as a reference to assess the convergence behavior. In the experiment, we observe that the loop converges rapidly for a wide range of $\alpha$ and $\epsilon$ values. Empirically, we find the choice $\alpha = 0.01$, $\epsilon = 1$x$10^{-8}$ to be effective.

Finally, once the loop is done the $V_{ds}$ value that minimizes the cost function is identified as the optimal drain-to-source voltage, $V_{ds}^*$, of the MOSFET resulting in the desired parameters. The optimal width $W^*$ can then be obtained from one of the width functions defined in lines 14 to 17 evaluated at the optimum $V_{ds}$ value.
}

\input{sec/WE_pseudocode}
    

\subsection{SPICE verification and margin allocation}

\noindent
Finally, we perform just one SPICE simulation to verify compliance with all specifications. If any specification deviates from the requirements, the model modifies the specifications and repeats the inference step to obtain a new set of device sizes. For example, if the gain of the sized OTA is 10\% below the desired value, the model iteratively tightens the specifications to accommodate this 10\% difference in the gain requirement until all specifications are satisfied.
% \bluefn{Do you also do this if the performance is much better than the specification? You would reduce the power/area by using smaller device sizes.  Also: why don't you report power/area anywhere? \textbf{No, I don't do this if the performance is much better than the specifications. However, doing this is very much possible. But, its not guaranteed that reducing size will bring down the performance closer to the specifications.}}SSS_NOTE