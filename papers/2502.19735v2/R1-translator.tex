% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage[most]{tcolorbox}
\newtcolorbox{mybox}[1][]{
breakable,
  arc=1mm,
  boxrule=1pt,
  colback=yellow!14,
  colframe=black!80,
  fonttitle=\bfseries,
  title=#1,
  left=1mm,
  right=1mm,
  top=1mm,
  bottom=1mm
}
% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{booktabs}

\usepackage{multirow}
\usepackage{microtype}
\usepackage{graphicx}
% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
\usepackage{amsmath}
%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{marvosym}
\makeatletter
\def\thanks#1{\protected@xdef\@thanks{\@thanks
        \protect\footnotetext{#1}}}
\makeatother
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{R1-T1: Fully Incentivizing Translation Capability in LLMs via Reasoning Learning}

\author{Minggui He$^{1}$, Yilun Liu$^{1 \scalebox{1.05}{\Letter}}$\thanks{\scalebox{1.15}{\Letter} ~\ Corresponding author. (liuyilun3@huawei.com)}, Shimin Tao$^1$, Yuanchang Luo$^1$, Hongyong Zeng$^1$,\\
\textbf{Chang Su$^1$, Li Zhang$^1$, Hongxia Ma$^1$, Daimeng Wei$^1$,}\\
\textbf{Weibin Meng$^1$, Hao Yang$^1$, Boxing Chen$^{2}$, Osamu Yoshie$^{3}$} \\
$^1$ Huawei, China \\ 
$^2$ Huawei Canada, Canada \\ 
$^3$ Waseda University, Japan \\
\texttt{heminggui@huawei.com, liuyilun3@huawei.com}
} 

\begin{document}
\maketitle


\begin{figure*}[t!]
 \centering  
    \includegraphics[width=1\linewidth]{case_study.png}
 \caption{Illustration on the self-evolution of R1-T1's reasoning process in translation during reinforcement learning.}
\label{fig1}
\end{figure*}



\begin{abstract}
Despite recent breakthroughs in reasoning-enhanced large language models (LLMs) like DeepSeek-R1, incorporating inference-time reasoning into machine translation (MT), where human translators naturally employ structured, multi-layered reasoning chain-of-thoughts (CoTs), is yet underexplored. Existing methods either design a fixed CoT tailored for a specific MT sub-task (\emph{e.g.}, literature translation), or rely on synthesizing CoTs unaligned with humans, limiting their adaptability to diverse translation scenarios. This paper introduces R1-Translator (R1-T1), a novel framework to achieve inference-time reasoning for general MT via reinforcement learning (RL) with human-aligned CoTs comprising six common patterns. Our approach pioneers three innovations: (1) extending reasoning-based translation beyond MT sub-tasks to six languages and diverse tasks (\emph{e.g.}, legal/medical domain adaptation, idiom resolution); (2) formalizing six expert-curated CoT templates that mirror hybrid human strategies like context-aware paraphrasing and back translation; and (3) enabling self-evolving CoT discovery through RL. Experimental results indicate a steady translation performance improvement in 11 languages and 40 translation directions on Flores-101 test set, especially on the languages unseen from training.

\end{abstract}

\section{Introduction}
\label{sec:introduction}

\input{introduction.tex}

\section{Related Work}
\label{sec:relatedWork}

\input{related_work.tex}

\section{Methodology}
\label{sec:method}

\input{method.tex}

\section{Experiment}
\label{sec:exp}

\input{experiment.tex}

\section{Conclusion}
\input{conclusion.tex}

\bibliography{R1-translator}

\appendix


\input{Appendices}



\end{document}
