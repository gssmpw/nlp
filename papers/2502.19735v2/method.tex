To incentivize reasoning capabilities of LLM-based translators, in Section~\ref{sec:Parallel Corpus}, we begin by preparing a seed dataset of parallel corpus that is necessary for general translation abilities across various domains, sub-tasks and languages. In Section~\ref{sec:CotTemplate}, we introduce our translation CoT templates that integrates six strategies often used in human expert translation experience. These complex CoTs serve as a mean to inject prior reasoning knowledge into the LLM, enabling the model to better align with human thinking processes. In Section~\ref{sec:build cot dataset}, we discuss how the CoT templates are incorporated into the seed dataset of parallel corpus, so that the model can learn from instantiated reasoning process with real translation examples. In Section~\ref{sec: Translation Reasoning Learning}, we discuss the implementation of translation reasoning learning, including a self-evolving mechanism to further enhance the model's understanding of reasoning-based MT, ultimately improving performance on general MT tasks.

\subsection{Construction of MT Reasoning Dataset}

\subsubsection{Collection of Parallel Corpus as Seed Dataset}\label{sec:Parallel Corpus}

Our seed dataset comprises 2k parallel translation pairs carefully sampled from a diverse range of real-world open-source MT datasets\footnote{\url{https://machinetranslate.org/wmt}}\footnote{\url{https://www.un.org/dgacm/zh/content/uncorpus/}}\footnote{\url{https://huggingface.co/datasets/joefox/newstest-2017-2019-ru_zh/tree/main}}\footnote{\url{https://www.jizhi-dataset.top/index/category/detail/15}}, ensuring essential coverage in terms of token length distribution, domain knowledge, and translation languages. For the length of each translation pair, we consider pairs of both sentence-level and paragraph-level, covering the majority of common translation scenarios. As illustrated in Fig.~\ref{fig_token}, the token length distribution of our seed dataset primarily ranges from 10 to 1200 tokens, consistent with several authoritative MT benchmarks\cite{banon2020paracrawl, goyal2022flores}.

For domain diversity, we select a wide variety of content types, including news (\emph{i.e.}, WMT corpus~\cite{kocmi2024findings}), literature, and specialized texts that require domain-specific terminology. This ensures that our dataset addresses various translation challenges across different fields. For language coverage in the training set, we focus on six major languages—Russian (ru), French (fr), German (de), Japanese (ja), Chinese (zh), and English (en)—chosen for their large speaker populations, the linguistic similarities and cross-linguistic relationships between them~\cite{bojar-etal-2018-findings}. From the open-source datasets described above, 20 translation directions within the six languages are distinguished. For each direction, 100 parallel pairs are randomly sampled, leading to a total of 2k parallel pairs. 


\begin{figure}[htbp]
   \includegraphics[width=1.1\linewidth]{fig1.png}
 \caption{The token length distribution of our seed dataset comprising 2k parallel translation pairs.}
\label{fig_token}
\end{figure}


\subsubsection{Human-aligned Translation CoT Templates}\label{sec:CotTemplate}

\paragraph{Reasoning strategies in Human Translation} In the pursuit of mimicking human reasoning process in manual translation, we propose a framework that incorporate reasoning process into the plain MT seed dataset. As shown in Fig. \ref{fig_framework}, our framework first employs six reasoning strategies frequently utilized by human translators as guidance, then abstracts them into two basic reasoning modules. The goal is to convert these human reasoning strategies into systematic and generalized CoT templates for translation. The six strategies are outlined below:

\begin{figure*}[t!]
 \centering  
    \includegraphics[width=1\linewidth]{framework.png}
 \caption{Illustration on the construction of translation CoT dataset and training of R1-T1.}
\label{fig_framework}
\end{figure*}


(1) \textit{Hierarchical Translation:} It reflects the human expert practice of breaking down complex sentences or passages into smaller, more manageable components. By first identifying the key elements of the source text, the model can then translate each segment with a clearer understanding of the overall structure and meaning. This process helps prevent errors that may arise from translating without considering the broader context.

(2) \textit{Triangulation Translation:} This method (also called relay translation~\cite{ringmar2012relay}) uses an intermediate (pivot) language to translate between linguistically or culturally distant languages~\cite{guyot2018translating}. When direct translation is challenging, the source text is first translated into the pivot language and then into the target language. This helps bridge gaps in grammar, vocabulary, or cultural context, ensuring a more accurate and nuanced final translation. It emphasizes the role of intermediary steps in achieving high-quality translations, especially for complex or culturally rich texts.


(3) \textit{Back Translation:} A process where a translated sentence is re-translated into the original language to identify inconsistencies or errors~\cite{brislin2001back}. This helps refine the translation by detecting possible flaws and improving fluency.

(4) \textit{Context-aware Translation:} This strategy is useful since it focuses on understanding the broader context (\emph{e.g.}, paragraph or document) in which a phrase or sentence appears~\cite{cabezas2023use,almanna2015contextualizing}, enabling the translation of idiomatic expressions, cultural nuances, and domain-specific terms with higher fidelity.

(5) \textit{Translation Explanation:} Human translators often explain why they select one translation option over another, especially when multiple interpretations are possible~\cite{buhler2002translation}. This explanation can help identify potential issues in the translation process and ensure that the translated text aligns more closely with the intended meaning of the source.

(6) \textit{Structural Transformation:} Structural transformation refers to the step-by-step adjustments made in the sentence structure when translating between languages with different syntactic norms. For example, when translating from English to languages like Japanese or German, human may need to restructure the sentence to ensure it adheres to the grammatical conventions of the target language. It not only accurate but also syntactically appropriate for the target language.

\paragraph{Construction of CoT Templates with human strategies}

Besides the above reasoning strategies, as DRT~\cite{jiaan2024drt} observed, when conducting translation, human translators typically prioritize on extracting key information, such as important keywords and phrases from the source text.  This ensures that the primary translation subject is clearly identified. Then, multiple translation strategies can be actively employed considering different target languages, domains, and complexity levels. This hierarchical approach of information extraction followed by strategy application is key to human-like reasoning in translation. To enable LLMs to replicate this process, we construct two reasoning modules when building translation CoT templates:

a. \textit{Information Extraction:} In the first reasoning step, the model extracts the main translation subject and key linguistic elements from the source text. This serves to identify the core meaning of the text, which is critical for accurate translation. The extraction process can be seen as analogous to the human translator’s practice of identifying key terms and understanding the context before translating.

b. \textit{{Strategy Selection:}} In the next step, the model employs a set of predefined translation strategies depending on the identified translation subject and context. The choice of strategy—whether hierarchical translation, back translation, or another approach—depends on the characteristics of the source text (\emph{e.g.}, syntactic complexity, domain specificity). This module aims to guide the LLM through a series of decision points, allowing it to adaptively apply the most appropriate translation strategy at each stage. 

By combining the two modules with the six strategies, we manually created 6 translation CoT templates, displayed in Appendix~\ref{sec:appendix B}. All templates are carefully calibrated by language experts in case of inaccuracy or redundancy.

\subsubsection{Incorporating CoTs into Parallel Corpus}\label{sec:build cot dataset}
With the calibrated template, we use advanced LLMs to generate instantiated translation CoTs for each sample within our seed dataset, leading to a total of 2k parallel pairs with translation CoTs. Each sample contains a source sentence $W_{src}$ and a target sentence $W_{tgt}$, along with a reasoning trajectory revealing how the target translation reference is obtained step-by-step from the source sentence. 

Specifically, during the construction of reasoning trajectory, we employed a multi-step refinement process from a multi-agent review to mitigate hallucinations in the data (the used prompt is provided in Appendix~\ref{sec:appendix A}). This iterative process can be represented as

\begin{align} \label{eq1}
\begin{split}
P(s) : Temp &\Rightarrow \langle W_{src}, W_{tgt} \rangle\Rightarrow \langle T_0, f_0, a_0 \rangle \\
         &\Rightarrow \dots \Rightarrow \langle T_i, f_i, a_i \rangle. 
\end{split}
\end{align} 


In Eq.~\eqref{eq1}, \( T_i \) represents the CoT template at step \( i \), \( a_i \) is the generated answer and \( f_i \) is the confidence score for generated answer at step \( i \). Here, Confidence score is the Comet~\cite{rei-etal-2020-comet} with reference translation. With the answer quality feedback at different step's templates, it results in a refined reasoning template.



\subsection{Translation Reasoning Learning}  \label{sec: Translation Reasoning Learning}

Our reasoning learning method involves three primary components, each addressing a critical aspect of enhancing translation capabilities in language models:

\subsubsection{SFT with Reasoning Dataset}  
This section outlines how to utilize our CoT dataset to fine-tune the model directly on reasoning-based translation tasks. This fine-tuning process establishes a foundational layer of reasoning capability that is critical for the subsequent phases of learning. By training the model to handle structured reasoning tasks, we enable it to internalize essential translation strategies that will be refined in later stages.

\subsubsection{Self-Evolving with Reinforcement Learning}  
This part introduces a self-evolving mechanism that allows the model to progressively refine its reasoning skills over time through reinforcement learning. This iterative process facilitates the continuous enhancement of the model's translation performance, ensuring that it not only learns from its immediate outputs but also adapts based on long-term feedback.

\paragraph{Reward Modeling}  
To effectively guide the model's reasoning and translation quality, we have devised a reward modeling system that incorporates two distinct types of rewards: Format Reward and Answer Reward. These rewards are designed to align the model's output with the desired reasoning format and translation quality, allowing for targeted refinements based on specific performance criteria.

\textit{(1) Format Reward:} This reward encourages the model to adhere to a structured response format. We employ regular expression extraction to ensure the model places its reasoning process within the `<think></think>` tags and provides its final translation inside the `<answer></answer>` tags. The format reward score (S$_{format}$) is computed as follows:

\begin{equation} \label{eq2}
  S_{\text{format}} = 
\begin{cases} 
1 & \text{if format is correct} \\
0 & \text{if format is incorrect}
\end{cases}  
\end{equation}



This design ensures that the model’s output is both readable and logically structured, crucial for subsequent reasoning steps.

\textit{(2) Answer Reward:} The answer reward evaluates the translation quality in the model's output. To objectively assess the translation results, we adopt COMET~\cite{rei-etal-2020-comet} as the evaluation metric, which compares the model’s translation against a reference translation. However, we encountered several challenges with directly using COMET scores:

  \begin{itemize}
    \item When the COMET score is lower than the format reward, the model (or actor) may output an incorrect format to avoid receiving the lowest possible score, leading to suboptimal behavior.
    \item The continuous nature of COMET’s reward signal may cause instability in gradient updates, resulting in slower convergence and potential performance degradation during training.
  \end{itemize}

To address these issues, the answer score is computed as follows:

\begin{equation}\label{eq3}
      R(x) = 
  \begin{cases}
  0  & \text{if } x \leq 0 \\
  round(x,3)  & \text{if } x > 0
  \end{cases}
\end{equation}


This discretization helps mitigate instability and encourages more controlled behavior from the model.

\paragraph{Reinforcement Learning Strategy}  
For the reinforcement learning phase, we adopt a modified version of the REINFORCE++ algorithm~\cite{Hu2025REINFORCEAS}, which has been shown to be effective in optimizing models with complex, continuous reward structures. The core idea of REINFORCE++ is to refine the model’s reasoning over multiple iterations, gradually improving its ability to generate high-quality translations. The following equation describes our adaptation of the REINFORCE++ algorithm:

\begin{equation}\label{eq4}
    \Delta \theta_t = \alpha \left( R(x_t) - \hat{R} \right) \nabla \log P(x_t|\theta),
\end{equation}


where \( \alpha \) represents the learning rate, \( R(x_t) \) is the reward signal, and \( \hat{R} \) is the baseline reward estimate.

