\paragraph{Prompting}
Chain-of-thought (CoT) prompting represents a fundamental approach to accessing and utilizing LLMs' stored knowledge through intermediate reasoning steps. While zero-shot CoT \cite{kojima2022large} demonstrates LLMs' ability to access implicit knowledge without examples, few-shot CoT \cite{wei2022chain} requires explicit knowledge demonstrations. \citet{zhang2022automatic} proposed automating the construction of knowledge demonstrations, reducing manual effort while maintaining knowledge fidelity. Recent work has explored structuring knowledge representation in prompting through programs \cite{chen2023program}, knowledge graphs \cite{besta2024graph}, and tabular formats \cite{ziqi-lu-2023-tab}. Our work focuses on making knowledge utilization explicit in free-text reasoning chains, providing a transparent view of how LLMs access and apply their stored knowledge.

\paragraph{Problem Decomposition in LLMs}
\begin{comment}
Research has shown that decomposing complex knowledge tasks into smaller units enhances LLMs' knowledge utilization capabilities \cite{shridhar2022automatic}. The Least-to-Most prompting approach \cite{zhou2022least} structures knowledge application by sequentially decomposing problems into manageable knowledge components, offering improved transparency compared to zero-shot CoT. Tab-CoT \cite{ziqi-lu-2023-tab} employs a tabular format to organize knowledge application steps, enhancing the visibility of knowledge flow, though it often requires domain-specific knowledge engineering. IAO prompting differs by autonomously decomposing knowledge application while explicitly tracking knowledge flow through input-action-output sequences, enabling better verification of knowledge utilization at each step.    
\end{comment}

Decomposing complex knowledge tasks into smaller units enhances LLMs' knowledge utilization capabilities \cite{shridhar2022automatic}. The Least-to-Most (L2M) prompting approach \cite{zhou2022least} improves reasoning by sequentially solving simpler sub-problems incrementally from least to most complex. Similarly, the Plan-and-Solve framework \cite{wang2023plan} first generates a high-level plan outlining the solution path before solving the problem step by step, enhancing zero-shot chain-of-thought reasoning. Tab-CoT \cite{ziqi-lu-2023-tab} organizes knowledge application steps in a tabular format to enhance visibility of knowledge flow but often requires domain-specific engineering. IAO prompting differs by autonomously decomposing knowledge application while explicitly tracking knowledge flow through input-action-output sequences, enabling better verification of knowledge utilization at each step.

\paragraph{Knowledge Verification in LLMs}
Ensuring factual accuracy and verifying knowledge application in LLMs remains a critical challenge. Early research focused on specific domains, such as dialogue systems \cite{shuster2021retrieval} and question-answering tasks \cite{kadavath2022language,kandpal2023large}. Recent work has expanded to broader verification challenges, particularly addressing the challenge of long-tail knowledge \cite{kandpal2023large} and developing methods to assess when LLM outputs can be trusted \cite{mallen2022not}. Of particular relevance to our work is the emergence of self-verification approaches, exemplified by \cite{manakul2023selfcheckgpt}, which enable zero-shot detection of hallucinations without external knowledge sources. Our IAO approach complements these verification efforts by providing a structured framework that makes knowledge application steps explicit and independently verifiable, helping to identify potential knowledge gaps or misapplications at each reasoning step. Unlike previous works that focus on post-hoc verification or external knowledge sources, IAO enforces verification during the reasoning process itself through its structured input-action-output format, making the knowledge flow transparent and checkable in real-time as the model generates its response.