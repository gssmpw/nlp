\section{CONCLUSIONS}
In this paper, we address the key challenges of deploying VLN models on robots with low viewpoints in continuous environments. Using the Xiaomi Cyberdog as a case study, we examine the discrepancy between human commands and the robotâ€™s limited visual input, focusing on the restricted field of view due to its low camera height. Our analysis highlights significant performance gaps caused by differences in human and robot perspectives and the limitations of monocular sensors. To address these issues, we reconstruct panoramic inputs, enhance waypoint prediction, and develop an information-gathering strategy to improve navigation performance. Our results demonstrate that bridging the visual gap between human and robot perspectives is crucial for improving the generalization and performance of VLN models.

% In this paper, we address key challenges faced by VLN tasks when deployed on robots with a low line of sight in continuous environments. Using the Xiaomi Cyberdog as an example, we explore the discrepancy between human-generated commands and the robot's constrained visual input, with a particular emphasis on the limited field of view due to the robot's low camera height. Our analysis reveals significant performance gaps arising from the difference in visual viewpoints between humans and robots and the limitations of monocular sensors in capturing panoramic observations. To mitigate these issues, we reconstruct panoramic visual inputs for the robot, train a more powerful waypoint predictor, and develop an information gathering strategy to enhance navigation performance. Our results demonstrate that addressing the visual and perceptual gap between human and robot viewpoints is critical to improving the generalization and performance of VLN models.