The premise that extending inference time enhances the quality of language model outputs finds support in cognitive science. Human deliberation, often associated with System 2 thinking, is linked to improved decision-making capabilities~\cite{lawson2020comparing}. Mirroring this, numerous computational strategies have been developed to scale inference within Large Language Models (LLMs). Prompt-based methods like Chain-of-Thought (CoT)~\cite{cot_paper} and critique-then-generate approaches~\cite{ankner2024critiqueoutloudrewardmodels} are prominent examples. Other iterative refinement methods like ReAct~\cite{yao2023reactsynergizingreasoningacting}, Self-Refine~\cite{madaan2024self}, and Reflexion, which incorporate feedback and reflection, also improve inference quality. Even simpler strategies, capitalizing on the stochastic nature of LLM decoding that generate multiple responses and select among them, such as self-consistency~\cite{wang2023selfconsistencyimproveschainthought}, have shown efficacy that scales well across multiple orders of magnitude of inference compute~\cite{brown2024largelanguagemonkeysscaling}. 

However, the assumption of monotonic improvement with increased inference calls is not guaranteed to hold. As argued by Chen et al.~\cite{chen2024more}, repeated sampling may lead to convergence towards the most probable, but not necessarily the optimal, solution. This is particularly pertinent for challenging instances where the probability of a correct answer is below chance (i.e., $<0.5$).

In this work, we introduce a complementary approach, called Recursive INference Scaling (RINS), which can be integrated with other techniques.. RINS identifies a specific form of model recursion as an effective inference scaling strategy, demonstrating significant performance gains over various other recursive architectures, including the Repeat All Over (RAO) strategy identified by~\citet{liu2024mobilellm} as state-of-the-art for mobile LLMs. 

Recursion is a form of parameter sharing, a technique that has been explored for a while. Illustrative examples include Universal Transformers~\cite{dehghani2019universaltransformers} and ALBERT~\cite{lan2020albertlitebertselfsupervised}. Despite their innovative design, their scaling exponents were smaller than in the vanilla transformer~\citep{tay2022scaling} so they failed to subsume it~\citep{tay2022efficienttransformerssurvey}. RINS, by contrast, improves both the scaling exponents and asymptotic performance limits. 

We hypothesize that the efficacy of RINS in language tasks stems from its exploitation of language's self-similarity~\cite{alabdulmohsin2024fractalpatternsilluminatesuccess}, since the recursive block in RINS is a form of scale-invariant decoding (see Appendix~\ref{app:selfsim} for further discussion). One evidence for this is the fact that RINS does not help in the pure vision domain, but it can still improve performance in multimodal systems that also process language, such as contrastive models. We obtain significant performance gains in SigLIP, for example.