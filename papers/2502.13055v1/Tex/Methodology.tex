
\section{Methodology}
This section outlines the core components of our framework, LAMD, and how they cooperate to detect and understand Android malware efficiently.

\subsection{Overall Architecture}
The LAMD framework is designed to extract essential functionalities and their contextual information, enabling LLMs to generate both detection and reasoning results. It consists of two key components: (1) Key Context Extraction and (2) Tier-wise Code Reasoning, detailed as follows:
\begin{itemize}
    \item \textbf{Key Context Extraction}: This module identifies suspicious APIs as seed points and analyzes their control and data dependencies within the application. It provides a structured representation of key program behaviors by pruning the calling relationships of potentially malicious interactions.
    \item \textbf{Tier-wise Code Reasoning}: To preserve contextual integrity while managing token limitations, LAMD employs a tiered reasoning strategy. It processes information at three levels—function, API, and APK—where the output of each tier informs the next. To mitigate error propagation, factual consistency verification is applied at the first tier.
\end{itemize}
Figure~\ref{fig:arch} shows the pipeline of our framework. Overall, the raw input to LAMD consists of APK files, from which suspicious APIs and their sliced contexts are extracted as the input for LLMs. The malicious behavior of the application is then determined through three tiers of code reasoning.

\subsection{Key Context Extraction}
\subsubsection{Suspicious API Collection}
Malware exploits system vulnerabilities or API permissions to steal data, manipulate resources, or maintain persistence. Many attacks rely on sensitive API calls to implement malicious behaviors. We perform static analysis on APKs to extract suspicious APIs as key context to identify malware. Let $\mathcal{A} = \{a_1, a_2, \ldots, a_n\}$ be the set of all API calls in an APK. A subset $\mathcal{A}_{sus} \subset \mathcal{A}$ is deemed suspicious if it interacts with sensitive components, executes malware-associated operations or exposes sensitive data. These APIs fall into two categories:
\begin{itemize}
    \item \textit{Sensitive data access APIs}: Many apps handle sensitive data, but assessing developer trustworthiness is challenging. Monitoring APIs accessing such data is crucial. Smartphone OSs enforce permission-based access control, requiring declared permissions for some APIs, while others, like \verb|getPrimaryClip()|, bypass enforcement. Therefore, an API $a_i$ falls into this category if it either: (1) requires explicit permissions for access control, or (2) grants direct access to sensitive user data without permission enforcement.
    \item \textit{Sensitive data transmission APIs}: Monitoring potential data exfiltration channels is critical, as malware often exploits these APIs—commonly referred to as sink APIs—to transmit sensitive information to external entities. An API $a_j$ is classified as suspicious if it facilitates the transfer of sensitive data to an external environment.
\end{itemize}

To extract suspicious APIs, we leverage publicly available knowledge based on PScout~\cite{pscout}, SuSi~\cite{susi} and Flowdroid~\cite{flowdroid} to label them. In a real-world setting, not every application contains suspicious APIs. These samples should be treated individually, where traditional learning-based malware detectors also struggle to handle~\cite{he2022msdroid}.


\subsubsection{Backward Program Slicing}
% While extracting suspicious APIs is helpful, analyzing them in isolation often fails to reveal their contextual behavior. For example, a messaging app legitimately uses \verb|sendTextMessage()|, while malware may exploit it to send premium-rate SMS without user consent. To capture behavioral intent, we extract functions invoking suspicious APIs and filter out unrelated parts. Specifically, for each API $a_i \in \mathcal{A}_{sus}$, we locate the calling function $f_i$, and construct its control flow graph (CFG), $G = <N, E>$, to prepare for analysis dependency relationships, where each node $n \in N$ is either a basic block or a single instruction, and edges $(e_1, e_2) \in E$ define control flow. CFGs can be large and may include irrelevant instructions. To refine them, we apply backward slicing, isolating only instructions affecting the suspicious API invocation. 

Extracting suspicious APIs is useful, but analyzing them in isolation often obscures their context. For instance, while \verb|sendTextMessage()| is legitimate in messaging apps, malware may exploit it for premium-rate SMS. To capture intent, we extract functions invoking suspicious APIs and refine their control flow graphs (CFGs), $G = <N, E>$, where nodes $n \in N$ represent basic blocks or instructions, and edges $(e_1, e_2) \in E$ define control flow. Since CFGs can be large and noisy, we apply backward slicing~\cite{slicing} to isolate instructions affecting the API invocation. A slice $S$ is defined by a slicing criterion $C = <s, V>$ where $s$ is the statement invoking $a_i$ and $V$ includes all parameters. We classify relevant variables as: (1) \textit{Direct relevant variables}: Variables' values can affect variable $v \in V$ of $a_i$  (2) \textit{Indirect relevant variables}: Variables in branch statements whose value affects invocation of $a_i$. The backward slicing is to select the set of instructions in $\mathcal{P}$ that directly or indirectly affect the execution or parameters of $a_i$. The backward slicing algorithm consists of two steps to ensure completeness in complex branch structures:
\begin{itemize}
    \item \textbf{Variable retrieval}: Identify all variables contributing to the parameters (and internal states) used by the suspicious API and store them in a candidate set.
    \item \textbf{Slices extraction}: Append instructions related to variables collected in the first step.
\end{itemize}

After slicing, we generate sliced CFGs for each sensitive API, preserving essential control flow and statements. Notably, If undeclared variables remain in a sliced function, inter-procedural backward slicing is recursively applied to its callers until all variables are resolved. The details of slicing algorithm are shown in Appendix~\ref{slicing}.

\subsection{Tier-wise Code Reasoning}
Code reasoning involves analyzing and interpreting code to understand its behavior, identify potential threats, and generate meaningful explanations. We propose a three-tier reasoning strategy that refines APK behavior analysis from fine- to coarse-grained levels, enhancing both prediction accuracy and interpretability. This hierarchical approach improves malicious component identification, mitigates LLM token-length limitations, and captures structural and invocation semantics through separable reasoning, ensuring a more effective and scalable malware detection framework.

% The detailed prompts used in each stage are provided in Appendix~\ref{prompt}.



\subsubsection{Tier 1: Function Behavior Summarization}
In the previous stage, several functions invoking suspicious APIs are extracted and sliced to maintain the related context. Each sliced CFG of the function is fed to LLM to capture low-level code patterns and functionalities. 



\subsubsection{Tier 2: API Intent Awareness}
The context of a specific API is typically determined by a series of functions. Beyond function invocation relationships, it is crucial to examine how inter-function associations influence the API's intent. Due to diverse contexts, an API may appear in multiple Function Call Graphs (FCGs). For instance, \verb|getDeviceId()| is benign when used solely for local logging but becomes malicious when invoked within \verb|sendImeiToServer()|, where it exfiltrates the IMEI to a remote server. Therefore, at this mid-tier, all functions associated with a suspicious API are structured into multiple FCGs to analyze its overall intent. Each node in an FCG is represented by the generated function summary in tier 1. 
%, each reflecting a different intent

\begin{tcolorbox}[title=Tier 1: Function Behavior Summarization Prompt, 
left=2pt, % Adds 10pt space on the left
right=2pt, % Adds 10pt space on the right
top=3pt, % Adds 5pt space above the box
bottom=3pt, % Adds 5pt space below the box
fonttitle=\small,colback=gray!20, colframe=black, colbacktitle=black, coltitle=white, sharp corners, fontupper=\small, fontlower=\small, before upper=\raggedright, before lower=\raggedright]
You are a cybersecurity expert specializing in Android malware analysis. Analyze the provided control flow graph including instructions related to sensitive API calls in detail.

Control Flow Graph: $\{CFG\_content\}$
\end{tcolorbox}

\begin{tcolorbox}[title=Tier 2: API Intent Awareness Prompt, 
left=2pt, % Adds 10pt space on the left
right=2pt, % Adds 10pt space on the right
top=3pt, % Adds 5pt space above the box
bottom=3pt, % Adds 5pt space below the box
fonttitle=\small,colback=gray!20, colframe=black, colbacktitle=black, coltitle=white, sharp corners, fontupper=\small, fontlower=\small, before upper=\raggedright, before lower=\raggedright]
You are a cybersecurity expert specializing in Android malware analysis. Analyze the main functionality and behavior of the provided sensitive API based on the function call graphs and a summary of each function's behavior.

API name: $\{API\ name\}$ \\
API type: $\{access/transfer\}$\\
for $i$-th Function Call Graph: \\
\makebox[2em]{} FCG: $\{FCG\_content\}$ \\
\makebox[2em]{} $\{function\_name\} \{function\_summary\}$ 
\end{tcolorbox}



\subsubsection{Tier 3: APK Maliciousness Judgement}
After extracting intents from suspicious APIs in an APK, LLMs assess its maliciousness and justify their decision. and generate Indicators of Compromise (IoCs), summarizing sensitive data access, external transmissions, and anomalous behavior to enhance transparency and trust.

% summarizing sensitive data access, external transmissions, and anomalous control flow or permission requests, enhancing transparency and user trust.


\begin{tcolorbox}[title=Tier 3: APK Maliciousness Judgement Prompt, 
left=2pt, % Adds 10pt space on the left
right=2pt, % Adds 10pt space on the right
top=3pt, % Adds 5pt space above the box
bottom=3pt, % Adds 5pt space below the box
fonttitle=\small,colback=gray!20, colframe=black, colbacktitle=black, coltitle=white, sharp corners, fontupper=\small, fontlower=\small, before upper=\raggedright, before lower=\raggedright]
You are a cybersecurity expert specializing in Android malware analysis. Determine whether the application is MALWARE or BENIGN, citing indicators of compromise, evidence, and malicious patterns if present. Give a final prediction and key findings of your analysis.

for $i$-th API: \\
\makebox[2em]{}API name: $\{API\ name\}$ \\
\makebox[2em]{}API type: $\{access/transfer\}$\\
\makebox[2em]{}API intent: $\{API\ summary\}$
\end{tcolorbox}

% After getting intents of suspicious APIs in the specific APK, LLMs can review them to identify whether the APK is malicious or not and provide users with the basis of the determination. 

\subsubsection{Factual Consistency Verification}
Generating behavior summaries with LLMs risks hallucinations~\cite{nature24hallucinations}, producing facts inconsistent with instructions. To prevent error accumulation, we verify function-level summaries before higher-tier reasoning, leveraging their limited dependencies and concise structure.

Building on factual consistency verification~\cite{cloze, factasking}, we design a structured template to capture data dependencies in sliced CFGs. To enhance inference, we prompt the LLM to select corresponding data relationships from the input function based on specific definitions. We define five dependencies: variable-to-API interactions (direct, transitive, conditional) and inter-variable relationships (parallel, derived). The former tracks how variables influence API execution via assignments, call chains, and control flow, while the latter captures joint computation and derivation. Loop dependencies are excluded, as Soot expands loops when analysing binary code. Appendix~\ref{datadependency} details these dependencies. For consistency verification, we integrate an in-context learning-based prompt with function summarization, querying the LLM to extract dependencies in the format: $<dependencies\ type>:<variable\ names>$.


\begin{tcolorbox}[title=Factual Consistency Verification Prompt, 
left=2pt, % Adds 10pt space on the left
right=2pt, % Adds 10pt space on the right
top=3pt, % Adds 5pt space above the box
bottom=3pt, % Adds 5pt space below the box
fonttitle=\small,
colback=gray!20, colframe=black, colbacktitle=black, coltitle=white, sharp corners, fontupper=\small, fontlower=\small, before upper=\raggedright, before lower=\raggedright]
The provided control flow graph represents a slice of the function, identifying variable relationships for each statement leading to the final invocation statement that invokes $\{function\_name\}$. The output should follow the template: $\{template\}$

Control Flow Graph: $\{CFG\_content\}$ 

There are FIVE types of relationships: \\
1. Direct: Variables used directly as function parameters.\\
\textit{Example}: $invoke r1.method(r2) \rightarrow {r1, r2}$ \\
2. Transitive: Variables whose values flow through assignments but are not directly used in the invocation. \\
\textit{Example}: $r2 = r3.getValue()$; \\
$invoke r1.method(r2) \rightarrow {r3}$ \\
...
\end{tcolorbox}

To evaluate the reliability of generated summaries, we propose a Data Relationship Coverage (DRC) metric:
\begin{equation}
DRC = \frac{\#\{\text{correctly completed dependencies}\}}{\#\{\text{all selected dependencies}\}}.
\end{equation}

A summary is considered factually consistent if the LLM accurately reconstructs variable dependencies, i.e., $DRC \ge \theta$, where $\theta$ is a reliability threshold. Otherwise, the summary is revised to mitigate inaccuracies.

% \subsubsection{Application Maliciousness Reasoning}
% In this stage, we collect suspicious API summaries for each APK and feed them into the LLM to produce a final holistic analysis. This process enables APK-level classification, where the LLM synthesizes API-level insights to determine whether the APK is benign or malicious. Additionally, the LLM generates Indicators of Compromise (IoCs), providing a concise explanation that highlights accessed sensitive data, external transmissions, and unusual control flow or permission requests, improving transparency and fostering user trust. 





