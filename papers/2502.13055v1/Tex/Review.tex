\section{Related Work}
This section reviews conventional Android malware detection, their real-world limitations, and recent advances in LLM-powered Android malware detection, situating our work in this evolving field.
% This section examines conventional Android malware detection methods, highlighting their real-world limitations and challenges. We also discuss recent advances in LLM-powered Android malware reasoning,  positioning our work within this emerging research direction.


\subsection{Learning-based Android Malware Detection}
Learning-based Android malware detectors leverage machine learning or deep learning models to automatically learn patterns from features extracted by static or dynamic analysis, enhancing scalability and adaptability~\cite{unraveling}. Due to the high cost of dynamic analysis, most models rely on static feature extraction through reverse engineering~\cite{Arpdrebin, Grossedeepdrebin}. Despite advancements, these models struggle with concept drift, where evolving malware variants degrade performance in real-world deployments~\cite{transcend, transcending}. Current works try to mitigate it, some of them focus on exploring robust features~\cite{scrr,damo,svm_ce,apigraph} and others leverage continual learning~\cite{continuous, tesseract,malware_evolution_update} or active learning~\cite{droidevolver, online_mal} to let models adapt to new distribution. However, these methods either target to specific feature space~\cite{scrr} or introduce high retraining overhead and the risk of label poisoning~\cite{recda, labelless}. An additional challenge is explainability, which is critical for security analysis. Existing methods primarily use feature attribution techniques, providing importance scores without generating human-readable behavioral analysis~\cite{finer, belaid}. To address these limitations, researchers are increasingly exploring LLM-based approaches, which leverage extensive external knowledge and reasoning capabilities to improve malware detection and analysis~\cite{code_explain,code_explain_2}.

\begin{figure*}[t]
    \centering
    \setlength{\abovecaptionskip}{0cm}
    \includegraphics[width=1.0\linewidth]{Figure/LLMarch.pdf}
    \caption{The workflow of LAMD. Suspicious APIs are identified via predefined rules (Step 1), and their calling functions with control flow graphs are extracted through static analysis. A customized backward slicing technique refines relevant instructions, preserving potential malicious intent (Step 2). In the code reasoning phase, the structured control flow graph, function relationships, and suspicious APIs form hierarchical tiers for malware detection and human-readable explanations (Steps 3-6). Factual consistency verification ensures first-tier summary reliability, mitigating hallucination (Step 4).}
    \label{fig:arch}
\end{figure*}


\subsection{LLM-powered Malware Detection}
% Large Language Models (LLMs) have gained traction in security applications such as 

LLMs are increasingly used in security tasks like code analysis~\cite{code_sum}, vulnerability detection~\cite{llm4vuln,llm4vuln_bench}, and malware classification~\cite{llm_syscall}. Unlike traditional learning-based models, LLMs offer zero-shot inference capabilities, enabling them to generalize beyond predefined training data and feature spaces~\cite{large_zero,toolformer}. This adaptability leads researchers to explore LLMs for malware detection and analysis, demonstrating their potential in security tasks. However, most studies focus on relatively simple malware ecosystems, such as npm packages~\cite{npm_malware}, PowerShell scripts~\cite{raconteur}, Linux binaries~\cite{llm_syscall}, and JavaScript-based threats~\cite{tactics}.

Initial attempts at LLM-based Android malware detection are limited. Walton \textit{et al.}~\cite{malware_exploring} proposed a hierarchical approach, analyzing decompiled code at the function, class, and package levels. However, the lack of filtering mechanisms allows benign code to obscure malicious patterns, reducing detection accuracy and increasing computational costs. Even with a balanced 200-sample dataset, their best prompt only achieved 75\% accuracy. Zhao \textit{et al.}~\cite{apppoet} relies on predefined feature spaces (Drebin~\cite{Arpdrebin}) to generate feature summaries instead of analyzing raw code. These summaries are then embedded and fed into a deep neural network (DNN) for training and detection. While focusing on the feature's name is efficient, it lacks structural and invocation insights. Additionally, as a learning-based method, it also inherits generalization issues and dataset bias influences of conventional models. These limitations highlight the need for a framework that leverages LLMs effectively in real-world Android malware detection, which integrates both structural and semantic context.

% The limitations of existing approaches drive us to explore a framework enabling LLMs to detect and analyze Android malware by integrating structural and semantic context in real-world scenarios.

% Research on Android malware detection with LLMs remains limited, primarily addressing explanation and detection. 


% LLM applications in the Android malware domain remain limited, primarily addressing explanation and detection. Explanation-based approaches guide LLMs to generate analysis, while they need external labels to help LLMs identify malicious behaviors.

% Explanation-based approaches guide LLMs to generate analysis using malware labels~\cite{malware_exploring,malware_decisioncentric}, while detection-oriented methods convert traditional features (e.g., Drebin~\cite{Arpdrebin}) into embeddings for classification~\cite{apppoet}.
% % , while it still struggles with generalizability in dynamic environments due to their dependence on training data. 
% However, these methods struggle with generalizability in dynamic environments due to their reliance on training data.
% Additionally, Androidâ€™s complex architecture and extensive codebase constrain existing approaches, which rely on predefined feature sets rather than raw code analysis. 
% These limitations prevent LLMs from effectively capturing API interactions, program dependencies, and functional intent. 
% % This limitation motivates us 
% Therefore, our motivation is to explore a framework that enables LLMs to reason about Android malware by integrating structural and semantic context, allowing for more comprehensive detection and perception of malicious behaviors in real-world scenarios.


% However, due to the high structural complexity and extensive code length of Android applications, existing methods primarily rely on predefined feature spaces rather than analyzing raw code directly. This limitation prevents LLM from fully leveraging its inference capabilities for comprehensive Android malware detection and behavioral analysis due to underdeveloped dynamic API interactions, program dependencies, and functional intent. It motivates us to explore a framework that enables LLMs to reason about Android malware by incorporating structural and semantic context, allowing for a more comprehensive and interpretable analysis of malicious behaviors.
