\section{Methodology}
This section outlines the core components of our framework, LAMD, and how they cooperate to detect and understand Android malware efficiently.

\subsection{Overall Architecture}
The LAMD framework is designed to extract essential functionalities and their contextual information, enabling LLMs to generate both detection and reasoning results. It consists of two key components: (1) Key Context Extraction and (2) Tier-wise Code Reasoning, detailed as follows:
\begin{itemize}
    \item \textbf{Key Context Extraction}: This module identifies suspicious APIs as seed points and analyzes their control and data dependencies within the application. Constructing call relationships that encapsulate potentially malicious interactions, provides a structured representation of critical program behaviors.
    \item \textbf{Tier-wise Code Reasoning}: To preserve contextual integrity while managing token limitations, LAMD employs a tiered reasoning strategy. It processes information at three levels—function, API, and APK—where each tier’s output informs the next. To mitigate error propagation, factual consistency verification is applied at the first tier.
\end{itemize}
Figure~\ref{fig:arch} shows the pipeline of our framework. Overall, the raw input to LAMD is the APK files, after which the suspicious APIs and their sliced contexts are extracted as the input to LLMs. Then the malicious behavior of the application is determined by three tiers of code reasoning.

\subsection{Key Context Extraction}
\subsubsection{Suspicious API Collection}
Malware exploits system vulnerabilities or API permissions to steal data, manipulate resources, or maintain persistence. Many attacks rely on sensitive API calls to implement malicious behaviors. We perform static analysis on APKs to extract suspicious APIs as key context to identify malware. Let $\mathcal{A} = \{a_1, a_2, \ldots, a_n\}$ be the set of all API calls in an APK. A subset $\mathcal{A}_{sus} \subset \mathcal{A}$ is deemed suspicious if it interacts with sensitive components, executes malware-associated operations or exposes sensitive data. These APIs fall into two categories:
\begin{itemize}
    \item \textit{Sensitive data access APIs}: While many apps handle sensitive data, assessing developer trustworthiness is challenging. Smartphone OSs implement permission-based access control, requiring declared permissions in the APK manifest for APIs enforcing permission checks. Additionally, Some APIs, like \verb|getPrimaryClip()| (clipboard access), bypass permission enforcement. An API $a_i$ falls into this category if it either: (1) requires explicit permissions for access control, or (2) grants direct access to sensitive user data without permission enforcement.
    \item \textit{Sensitive data transmission APIs}: Monitoring potential data exfiltration channels is critical, as malware often exploits these APIs—commonly referred to as sink APIs—to transmit sensitive information to external entities. An API $a_j$ is classified as suspicious if it facilitates the transfer of sensitive data to an external environment.
\end{itemize}

To extract suspicious APIs, we leverage publicly available knowledge based on PScout~\cite{pscout}, SuSi~\cite{susi} and Flowdroid~\cite{flowdroid} to label them. In a real-world setting, not every application contains suspicious APIs. These samples should be treated individually, where traditional learning-based malware detectors also struggle to handle~\cite{he2022msdroid}.


\subsubsection{Backward Program Pruning}
While extracting suspicious APIs is helpful, analyzing them in isolation often fails to reveal their contextual behavior. For example, a messaging app legitimately uses \verb|sendTextMessage()|, while malware may exploit it to send premium-rate SMS without user consent. To capture behavioral intent, we extract functions invoking suspicious APIs and filter out unrelated parts. Specifically, for each API $a_i \in \mathcal{A}_{sus}$, we locate the calling function $f_i$, and construct its control flow graph (CFG), $G = <N, E>$, to prepare for analysis dependency relationships, where each node $n \in N$ is either a basic block or a single instruction, and edges $(e_1, e_2) \in E$ define control flow. CFGs can be large and may include irrelevant instructions. To refine them, we apply backward slicing, isolating only instructions affecting the suspicious API invocation. A slice $S$ is defined by a slicing criterion $C = <s, V>$ where $s$ is the statement invoking $a_i$ and $V$ includes all parameters. We classify relevant variables as: (1) \textit{Direct relevant variables}: Variables' values can affect variable $v \in V$ of $a_i$  (2) \textit{Indirect relevant variables}: Variables in branch statements whose value affects invocation of $a_i$. The backward slicing is to select the set of instructions in $\mathcal{P}$ that directly or indirectly affect the execution or parameters of $a_i$. The backward slicing algorithm consists of two steps to ensure completeness in complex branch structures:
\begin{itemize}
    \item \textbf{Variable retrieval}: Identify all variables contributing to the parameters (and internal states) used by the suspicious API and store them in a candidate set.
    \item \textbf{Slices extraction}: Append instructions related to variables collected in the first step.
\end{itemize}

After slicing, we generate sliced CFGs for each sensitive API, preserving essential control flow and statements. Notably, If undeclared variables remain in a sliced function, inter-procedural backward slicing is recursively applied to its callers until all variables are resolved. The details of slicing algorithm are shown in Appendix~\ref{slicing}.

\subsection{Tier-wise Code Reasoning}
After detecting suspicious APIs and surrounding instructions, we apply a three-tier summarization strategy, refining APK behavior analysis from fine- to coarse-grained levels. This hierarchical approach improves malicious component identification while addressing LLM token-length constraints through separable reasoning. 

% The detailed prompts used in each stage are provided in Appendix~\ref{prompt}.

\begin{tcolorbox}[title=Tier 1: Function Behavior Summarization Prompt, colback=gray!20, colframe=black, colbacktitle=black, coltitle=white, sharp corners, fontupper=\small, fontlower=\small, before upper=\raggedright, before lower=\raggedright]
You are a cybersecurity expert specializing in Android malware analysis. Analyze the provided control flow graph including instructions related to sensitive API calls in detail.

Control Flow Graph: $\{CFG\_content\}$
\end{tcolorbox}

\subsubsection{Tier 1: Function Behavior Summarization}
In the previous stage, several functions invoking suspicious APIs are extracted and sliced to maintain the related context. Each sliced CFG of the function is fed to LLM to capture low-level code patterns and functionalities. 



\subsubsection{Tier 2: API Intent Awareness}
The context of a specific API is typically determined by a series of functions. Beyond function invocation relationships, it is crucial to examine how inter-function associations influence the API's intent. Due to diverse contexts, an API may appear in multiple Function Call Graphs (FCGs), each reflecting a different intent. For instance, \verb|getDeviceId()| is benign when used solely for local logging but becomes malicious when invoked within \verb|sendImeiToServer()|, where it exfiltrates the IMEI to a remote server. Therefore, at this mid-tier, all functions associated with a suspicious API are structured into multiple FCGs to analyze its overall intent. Each node in an FCG is represented by the function summary generated in the previous step. 

\begin{tcolorbox}[title=Tier 2: API Intent Awareness Prompt, colback=gray!20, colframe=black, colbacktitle=black, coltitle=white, sharp corners, fontupper=\small, fontlower=\small, before upper=\raggedright, before lower=\raggedright]
You are a cybersecurity expert specializing in Android malware analysis. Analyze the main functionality and behavior of the provided sensitive API based on all the function call graphs and a summary of the behavior of each function.

API name: $\{API\ name\}$ \\
API type: $\{access/transfer\}$\\
for $i$-th Function Call Graph: \\
\makebox[2em]{} FCG: $\{FCG\_content\}$ \\
\makebox[2em]{} $\{function\_name\} \{function\_summary\}$ 
\end{tcolorbox}



\subsubsection{Tier 3: APK Maliciousness Judgement}
After extracting intents from suspicious APIs in an APK, LLMs assess its maliciousness and justify their decision. They also generate Indicators of Compromise (IoCs), summarizing sensitive data access, external transmissions, and anomalous control flow or permission requests, enhancing transparency and user trust.


\begin{tcolorbox}[title=Tier 3: APK Maliciousness Judgement Prompt, colback=gray!20, colframe=black, colbacktitle=black, coltitle=white, sharp corners, fontupper=\small, fontlower=\small, before upper=\raggedright, before lower=\raggedright]
You are a cybersecurity expert specializing in Android malware analysis. Determine whether the application is MALWARE or BENIGN, citing indicators of compromise, evidence, and malicious patterns if present. Give a final prediction and key findings of your analysis.

for $i$-th API: \\
\makebox[2em]{}API name: $\{API\ name\}$ \\
\makebox[2em]{}API type: $\{access/transfer\}$\\
\makebox[2em]{}API intent: $\{API\ summary\}$
\end{tcolorbox}

% After getting intents of suspicious APIs in the specific APK, LLMs can review them to identify whether the APK is malicious or not and provide users with the basis of the determination. 

\subsubsection{Factual Consistency Checking}
Generating behavior summaries with LLMs risks hallucinations~\cite{nature24hallucinations}, producing facts inconsistent with instructions. To prevent error accumulation, we verify function-level summaries before higher-tier reasoning, leveraging their limited dependencies and concise structure.

Building on factual consistency verification~\cite{cloze, factasking}, we design a structured template to capture data dependencies in sliced CFGs. To enhance inference, we prompt the LLM to select corresponding data relationships from the input function based on specific definitions. We define five dependencies: variable-to-API interactions (direct, transitive, conditional) and inter-variable relationships (parallel, derived). The former tracks how variables influence API execution via assignments, call chains, and control flow, while the latter captures joint computation and derivation. Loop dependencies are excluded, as Soot expands loops when converting binary code to IR (Appendix~\ref{app:dataset}). Appendix~\ref{app:dataset} details these dependencies. For consistency verification, we integrate an in-context learning-based prompt with function summarization, querying the LLM to extract dependencies in the format: $<dependencies\ type>:<variable\ names>$.


\begin{tcolorbox}[title=Factual Consistency Verification Prompt, colback=gray!20, colframe=black, colbacktitle=black, coltitle=white, sharp corners, fontupper=\small, fontlower=\small, before upper=\raggedright, before lower=\raggedright]
The provided control flow graph represents a slice of the function, identifying variable relationships for each statement leading to the final invocation statement that invokes $\{function\_name\}$. The output should follow the template: $\{template\}$

Control Flow Graph: $\{CFG\_content\}$ 

There are FIVE types of relationships: \\
1. Direct: Variables used directly as function parameters.\\
\textit{Example}: $invoke r1.method(r2) \rightarrow {r1, r2}$ \\
2. Transitive: Variables whose values flow through assignments but are not directly used in the invocation. \\
\textit{Example}: $r2 = r3.getValue()$; \\
$invoke r1.method(r2) \rightarrow {r3}$ \\
...
\end{tcolorbox}

To evaluate the reliability of generated summaries, we propose a Data Relationship Coverage (DRC) metric:
\begin{equation}
DRC = \frac{\#\{\text{correctly completed dependencies}\}}{\#\{\text{all selected dependencies}\}}.
\end{equation}

A summary is considered factually consistent if the LLM accurately reconstructs variable dependencies, i.e., $DRC \ge \theta$, where $\theta$ is a reliability threshold. Otherwise, the summary is revised to mitigate inaccuracies.

% \subsubsection{Application Maliciousness Reasoning}
% In this stage, we collect suspicious API summaries for each APK and feed them into the LLM to produce a final holistic analysis. This process enables APK-level classification, where the LLM synthesizes API-level insights to determine whether the APK is benign or malicious. Additionally, the LLM generates Indicators of Compromise (IoCs), providing a concise explanation that highlights accessed sensitive data, external transmissions, and unusual control flow or permission requests, improving transparency and fostering user trust. 





