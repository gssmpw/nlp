\section{Related Work}
In this section, we review conventional Android malware detection approaches, highlighting their real-world limitations and challenges. Additionally, we discuss recent advancements in LLM-powered malware reasoning, positioning our work within this emerging research direction.

\subsection{Learning-based Android Malware Detection}
Android malware detection methods fall into two main categories: rule-based and learning-based approaches. Rule-based methods rely on manually crafted signatures, making them ineffective against obfuscation and zero-day malware~\cite{unraveling}. 
Learning-based methods use static or dynamic analysis to extract predefined features, enabling automated detection. Due to the high cost of dynamic analysis, most models rely on static feature extraction through reverse engineering~\cite{Arpdrebin, Grossedeepdrebin}. Despite advancements, these models struggle with concept drift, where evolving malware variants degrade performance in real-world deployments~\cite{transcend, transcending}. Current works try to mitigate it, some of them focus on exploring robust features~\cite{scrr,damo,svm_ce,apigraph} and others leverage continual learning~\cite{continuous, tesseract,malware_evolution_update} or active learning~\cite{droidevolver, online_mal} to let models adapt to new distribution. However, these methods either target to specific feature space or introduce high retraining overhead and the risk of label poisoning~\cite{recda, labelless}. An additional challenge is explainability, which is critical for security analysis. Existing methods primarily use feature attribution techniques, providing importance scores without generating human-readable behavioral analysis~\cite{finer, belaid}. Therefore, the need for explainable and adaptable detection mechanisms has motivated the exploration of LLM-based approaches, which leverage extensive external knowledge and reasoning capabilities to improve malware analysis~\cite{code_explain,code_explain_2}.


\subsection{LLM-powered Malware Reasoning}
Large Language Models (LLMs) have recently gained traction in security applications, including code analysis~\cite{code_sum}, vulnerability detection~\cite{llm4vuln,llm4vuln_bench}, and malware classification~\cite{llm_syscall}. Unlike traditional machine learning models, LLMs possess zero-shot inference capabilities, allowing them to generalize beyond predefined training data and feature spaces~\cite{large_zero,toolformer}. This adaptability has led researchers to explore LLMs for malware detection and explanation, demonstrating their potential effectiveness in security tasks. Most existing studies focus on relatively simple malware ecosystems, such as npm packages~\cite{npm_malware}, PowerShell scripts~\cite{raconteur}, Linux binaries~\cite{llm_syscall}, and JavaScript-based threats~\cite{tactics}. 

Limited efforts have focused on Android malware, primarily in explanation and detection. The former provides a label as guidance to let LLMs generate analysis~\cite{malware_exploring,malware_decisioncentric}. The latter integrates LLMs into malware detection tasks by leveraging their semantic understanding. For instance, some approaches use LLMs to summarize features extracted from existing datasets (e.g., Drebin) and convert them into embeddings for classification~\cite{apppoet}, while it still struggles with generalizability in dynamic environments. Additionally, due to Androidâ€™s complex structure and large codebase, existing approaches rely on predefined feature spaces instead of raw code analysis, limiting LLMs' ability to capture API interaction contexts, program dependencies, and functional intent. This limitation motivates us to explore a framework that enables LLMs to reason about Android malware by integrating structural and semantic context, allowing for more comprehensive detection and perception of malicious behaviors in real-world scenarios.


% However, due to the high structural complexity and extensive code length of Android applications, existing methods primarily rely on predefined feature spaces rather than analyzing raw code directly. This limitation prevents LLM from fully leveraging its inference capabilities for comprehensive Android malware detection and behavioral analysis due to underdeveloped dynamic API interactions, program dependencies, and functional intent. It motivates us to explore a framework that enables LLMs to reason about Android malware by incorporating structural and semantic context, allowing for a more comprehensive and interpretable analysis of malicious behaviors.
 