

\begin{table}[t]
\centering
\caption{Results of Data Leakage in SE Benchmarks (Python). \#Auto represents the number of potential duplicate pairs identified by MinHash+LSH, while \#Manual denotes the number of true duplicate pairs labeled by developers.}
\label{tab:main_results_py}
\scalebox{0.8}{
\rotatebox{0}{
\begin{tabular}{llrrrrr}
\hline
\textbf{Benchmark} & \textbf{Task(s)} & \textbf{Size} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}\#Auto\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}\#Manual\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Leaked\\ Count\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}Leaked\\ Ratio\end{tabular}}} \\ \hline
APPS~\cite{hendrycks2021measuring} & Code Generation & 10k & 240 & 193 & 108 & \cellcolor{red!21.6} 10.8\% \\
BigCodeBench\textit{-py}~\cite{zhuo2024bigcodebench} & Code Generation & 1.14k & 0 & 0 & 0 & 0\% \\
BioCoder~\cite{BioCoder} & Code Generation & 207 & 1 & 0 & 0 & 0\% \\
BugsInPy~\cite{BugsInPy} & Program Repair & 501 & 322 & 56 & 55 & \cellcolor{red!22} 11.0\% \\
CanItEdit~\cite{CanItEdit} & Code Editing & 105 & 0 & 0 & 0 & 0\% \\
ClassEval~\cite{ClassEval} & Code Generation & 100 & 0 & 0 & 0 & 0\% \\
CodeBenchGen~\cite{CodeBenchGen} & Code Generation & 1.93k & 0 & 0 & 0 & 0\% \\
CodeEditorBench\textit{-debug-py}~\cite{CodeEditorBench}  & Code Editing & 356 & 93 & 92 & 38 & \cellcolor{red!21.4} 10.7\% \\
CodeEditorBench\textit{-polish-py}~\cite{CodeEditorBench} & Code Editing & 413 & 1 & 1 & 1 & \cellcolor{red!0.4} 0.2\% \\
CodeEditorBench\textit{-switch-py}~\cite{CodeEditorBench}  & Code Editing & 488 & 115 & 103 & 35 & \cellcolor{red!14.4} 7.2\% \\
CodeEditorBench\textit{-translate-py}~\cite{CodeEditorBench}  & Code Translation & 709 & 0 & 0 & 0 & 0\% \\
CodeReview\textit{-py}~\cite{CodeReview} & Code Review & 2.9k & 0 & 0 & 0 & 0\% \\
CodeReviewNew\textit{-py}~\cite{CodeReviewNew} & Code Review & 2.15k & 3 & 1 & 1 & \cellcolor{red!0.1} 0.05\% \\
CodeScope\textit{-py}~\cite{Codescope} & Code Generation & 400 & 0 & 0 & 0 & 0\% \\
CoNala\textit{-curated}~\cite{CoNala} & Code Generation & 2.88k & 1 & 1 & 1 & \cellcolor{red!0.06} 0.03\% \\
ConDefects~\cite{Condefects} & Program Repair & 2.86k & 205 & 8 & 8 & \cellcolor{red!0.6} 0.3\% \\
DebugBench\textit{-py}~\cite{DebugBench} & Debugging & 4.25k & 2 & 1 & 1 & \cellcolor{red!0.04} 0.02\% \\
DS-1000~\cite{DS-1000} & Code Generation & 1k & 0 & 0 & 0 & 0\% \\
EvoCodeBench~\cite{EvoCodeBench} & Code Generation & 275 & 21 & 18 & 18 & \cellcolor{red!13} 6.5\% \\
G-TransEval\textit{-py}~\cite{G-TransEval} & Code Translation & 400 & 0 & 0 & 0 & 0\% \\
HumanEval~\cite{codex} & Code Generation & 164 & 3 & 3 & 3 & \cellcolor{red!3.6} 1.8\% \\
LiveCodeBench\textit{-code-generation}~\cite{LiveCodeBench}  & Code Generation & 511 & 0 & 0 & 0 & 0\% \\
LiveCodeBench\textit{-execution}~\cite{LiveCodeBench}  & Code Execution & 479 & 0 & 0 & 0 & 0\% \\
LiveCodeBench\textit{-test-generation}~\cite{LiveCodeBench} & \begin{tabular}[c]{@{}l@{}}Test Output \\ Prediction\end{tabular} & 442 & 0 & 0 & 0 & 0\% \\
MBPP~\cite{MBPP_1} & Code Generation & 974 & 4 & 4 & 4 & \cellcolor{red!0.8} 0.4\% \\
Mconala\textit{-es}~\cite{MCoNaLa} & Code Generation & 341 & 0 & 0 & 0 & 0\% \\
Mconala\textit{-ja}~\cite{MCoNaLa} & Code Generation & 210 & 1 & 0 & 0 & 0\% \\
Mconala\textit{-ru}~\cite{MCoNaLa} & Code Generation & 345 & 30 & 1 & 1 & \cellcolor{red!0.6} 0.3\% \\
Mercury~\cite{Mercury} & Code Generation & 1.89k & 12 & 12 & 10 & \cellcolor{red!1} 0.5\% \\
PythonSaga~\cite{PythonSaga} & Code Generation & 185 & 0 & 0 & 0 & 0\% \\
QuixBugs~\cite{QuixBugs} & Program Repair & 40 & 84 & 84 & 40 & \cellcolor{red!100} \textbf{100.0\%} \\
Refactory~\cite{Refactory} & Program Repair & 4.39k & 198 & 7 & 7 & \cellcolor{red!0.4} 0.2\% \\
SecurityEval~\cite{SecurityEval} & Secure Code Gene. & 121 & 2 & 2 & 2 & \cellcolor{red!3.4} 1.7\% \\
SVEN\textit{-py}~\cite{SVEN} & Secure Code Gene. & 28 & 0 & 0 & 0 & 0\% \\
SWE-Bench~\cite{SWE-bench} & Issue Fix & 2.52k & 2175 & 221 & 220 & \cellcolor{red!17.4} 8.7\% \\
SWE-Bench\textit{-verified}~\cite{SWE-bench-verified}  & Issue Fix & 500 & 59 & 53 & 53 & \cellcolor{red!21.2} 10.6\% \\ \hline
\textbf{Average} & - & - & - & - & - & 4.8\% \\
\bottomrule
\end{tabular}
}} \vspace{-0.4cm}
\end{table}