
In this section, we first present the overall results of the data leakage detection analysis. Following that, we provide detailed results and answers to each research question (RQ).



\vspace{0.2cm}
\noindent
\textbf{Overall Results.}
Before diving into the specific RQs, we first present an overview of the experimental results. The selected LLM's pre-training datasets consist of 12M samples for Python, 20M samples for Java, and 14M samples for C/C++. In comparison, the diverse SE benchmarks we studied collectively comprise 46k samples for Python, 42k samples for Java, and 21k samples for C/C++.
To investigate potential data leakage, each SE benchmark sample was compared against all pre-training data samples for its corresponding programming language. This process resulted in an astounding total of over 1.7 trillion comparisons. The sheer scale of this computational effort highlights the complexity and resource-intensive nature of studying data leakage regarding LLMs. 


From an overall perspective, as depicted in Figure~\ref{fig:data_review}, only 2\% of the benchmark samples from all the SE benchmarks studied were flagged by the automated tool MinHash+LSH as potentially forming at least one duplicate pair with the pre-training data of StarCoder. Moreover, of the pairs flagged by MinHash+LSH, 28\% were confirmed as duplicates after manual labeling, while the remaining 72\% were determined not to be duplicates.

Next, we will discuss the detailed results and answers to each RQ.

\input{sec/RQ1}

\input{sec/RQ2}

\input{sec/RQ3}


\input{sec/RQ4}