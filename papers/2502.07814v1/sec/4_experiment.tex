\section{Experiments}

\subsection{Datasets}
\textbf{ERA5.} ERA5~\cite{hersbach2020era5} is a global meteorological reanalysis dataset provided by the European Centre for Medium-Range Weather Forecasting (ECMWF), encompassing data since 1979. 
Its atmospheric variables are derived from atmospheric data collected at 37 different altitude levels, and it also includes several variables that represent Earth surface meteorological information. 
The entire grid comprises 721 latitude and 1440 longitude grid points. 
In our experiment, we selected four surface-level variables for the global: $U_{10}$, $V_{10}$, $T_{2M}$, and $MSL$. 
All four variables exhibit a correlation with human activities.
The specific meanings and units of these variables are outlined in \cref{tab:dataset}. 

\noindent\textbf{GridSat.} GridSat~\cite{skofronick2015global} dataset is a comprehensive series of satellite data products provided by the National Environmental Satellite, Data, and Information Service (NESDIS) of the National Oceanic and Atmospheric Administration (NOAA).  
GridSat dataset is primarily based on Earth observation data acquired from NOAA's geostationary satellite. 
These data within the GridSat collection are routinely employed in meteorological analyses and climatological studies for the estimation of cloud cover and surface temperature, thereby contributing to a more accurate representation of atmospheric variables. 
Among the multitude of variables within this dataset, we have selected three specific parameters: IrWin\_CDR, Irwin\_VZA\_Adj, and IrWVP. 
The detailed information of these variables are illustrated in \cref{tab:dataset}.
% The detailed information and respective units of these variables are illustrated in \cref{tab:dataset}.

\begin{table}[t]
\centering
\caption{Variable information of ERA5 and GridSat datasets.}
\vspace{-0.3cm}
\resizebox{\linewidth}{!}{
\begin{tabular}{c|c c c c}
    \toprule[1pt]
     Dataset&Variable&Abbrev.&Unit&ECMWF\;ID\\
    \midrule
    \multirow{4}{*}{ERA5}
    &U-component of Wind at 10m&$U_{10}$&$m/s$&165\\
    &V-component of Wind at 10m&$V_{10}$&$m/s$&166\\
    &2-Meter Temperature&$T_{2M}$&$K$&167\\
    &Mean Sea Level Pressure&$MSL$&$10^2Pa$&151\\
    \midrule
    \multirow{3}{*}{GridSat}
    &Infrared Window Channel Data Record&IrWin\_CDR&$K$&-\\
    &Viewing Zenith Angle Adjusted&Irwin\_VZA\_Adj&$K$&-\\
    &Integrated Water Vapor Path&IrWVP&kg/$m^2$&-\\
    \bottomrule[1pt]

  \end{tabular}
  }
 \label{tab:dataset}
\vspace{-0.4cm}
\end{table}


\begin{figure*}[t]
    \centering
\includegraphics[width=\linewidth]{Figures/comparison.pdf}
\vspace{-1cm}
    \caption{
Visualization comparison of different interpolation-based and diffusion-based downscaling results in various time stamps. 
We use different colors to distinguish various variables. 
Our SGD generates downscaling ERA5 maps with faithful details from ERA5 $1^{\circ}$. }
    \label{fig:comparison}
\vspace{-0.4cm}
\end{figure*}


\begin{table}[t]\small
  \centering
  \caption{Station-level downscaling results for $U_{10}$, $V_{10}$, $T_{2M}$ and $MSL$ of various methods. }
  \vspace{-0.3cm}
  \label{tab:main}
  \resizebox{\linewidth}{!}{
  \begin{tabular}{c|c c |c c |c c |c c }
    \toprule[1pt]
     \multirow{2}{*}{Methods}&\multicolumn{2}{c|}{$U_{10}$}&\multicolumn{2}{c|}{$V_{10}$}&\multicolumn{2}{c|}{$T_{2m}$}&\multicolumn{2}{c}{$MSL$}\\
     \cmidrule(lr){2-9}
     
    &MSE&MAE&MSE&MAE&MSE&MAE&MSE&MAE\\
    \midrule
ERA5 $1^{\circ} $  & 53.18 & 5.95 & 38.51 & \textbf{4.95} & 216.27 & 11.39 & 470.06 & 15.78 \\
Bilinear  & 56.55 & 6.16 & 37.94 & 5.03 & 198.40 & 11.26 & 464.51 & 16.05 \\
Bicubic  & 55.74 & 6.11 & \textbf{37.88} & 4.98 & 201.03 & 11.15 & 458.82 & 15.97 \\
DGP~\cite{pan2021exploiting}  & 97.02 & 7.96 & 47.52 & 5.07 & 214.58 & 11.94 & 529.72 & 18.54 \\
GDP~\cite{fei2023generative}  & 94.99 & 7.85 & 40.17 & 5.04 & 190.11 & 10.82 & 511.71 & 18.14 \\
DDNM~\cite{wang2022zero}  & 52.08 & 5.94 & 42.17 & 5.65 & 193.24 & 11.77 & 396.58 & 15.12 \\
SwinRDM~\cite{chen2023swinrdm}& 53.18 & 5.95 & \textbf{38.51} & \textbf{4.95} & 216.27 & 11.39 & 470.06 & 15.78 \\
Ref-SR~\cite{huang2022task}& 62.72 & 6.15 & 43.12 & 5.17 & 195.42 & 11.02 & 395.42 & 15.10 \\
$C^2$-Matching~\cite{jiang2021robust}& 65.12 & 6.02 & 44.57 & 5.41 & 200.17 & 11.36 & 410.72 & 15.32 \\
HyperDS~\cite{liu2024observation}& 53.72 & 6.01 & 41.37 & 5.26 & 191.83 & 10.87 & 384.72 & 14.72 \\
\midrule
SGD& \textbf{51.65} & \textbf{5.84} & 39.82 & 5.05 & \textbf{187.69} & \textbf{10.63} & \textbf{374.39} & \textbf{14.49} \\
    \bottomrule[1pt]

  \end{tabular}
  }
\vspace{-0.5cm}
\end{table}

\begin{table*}[t]\small
  \centering
  \caption{Ablation study regarding the effectiveness of the cross attention module (CA) and pre-trained encoder (PE). }
  \vspace{-0.3cm}
  \label{tab:ablation_training}
  \resizebox{0.9\linewidth}{!}{
  \begin{tabular}{c|c c|c c|c c|c c|c c}
    \toprule[1pt]
     \multirow{2}{*}{Methods} &\multicolumn{2}{c}{ Module}&\multicolumn{2}{|c|}{$U_{10}$}&\multicolumn{2}{c|}{$V_{10}$}&\multicolumn{2}{c|}{$T_{2M}$}&\multicolumn{2}{c}{$MSL$}\\
     \cmidrule(lr){2-3}
     \cmidrule(lr){4-11}

    &{CA}&{PE}&{MSE}&{MAE}&{MSE}&{MAE}&{MSE}&{MAE}&{MSE}&{MAE}\\
    \midrule
    {\small Unconditional DDPM Based SGD}&\XSolidBrush&\XSolidBrush&75.3985&6.9324&46.9961&5.4979&210.1230&11.2656&589.2316&18.7626\\
    {\small Conditional DDPM Based SGD}&\Checkmark&\XSolidBrush&58.3419&6.2400&45.2718&5.3794&207.4618&11.2806&397.2393&15.2934\\
    \midrule
    {\small SGD with Pre-trained Encoder}&\Checkmark&\Checkmark&\textbf{51.6512}&\textbf{5.8440}&\textbf{39.8189}&\textbf{5.0479}&\textbf{187.6857}&\textbf{10.6311}&\textbf{373.3909}&\textbf{14.4917}\\
    \bottomrule[1pt]

  \end{tabular}
}
\vspace{-0.3cm}
\end{table*}

\begin{table*}[t]\footnotesize
  \centering
  \caption{Ablation study regarding the downscaling results guided by different distance functions during the sampling process. }
  \vspace{-0.3cm}
  \label{tab:ablation_guidance}
  \resizebox{0.9\linewidth}{!}{
  \begin{tabular}{c|c c|c c|c c|c c|c c}
    \toprule[1pt]
     \multirow{2}{*}{Methods} &\multicolumn{2}{c}{ Guidance}&\multicolumn{2}{|c|}{$U_{10}$}&\multicolumn{2}{c|}{$V_{10}$}&\multicolumn{2}{c|}{$T_{2M}$}&\multicolumn{2}{c}{$MSL$}\\
     \cmidrule(lr){2-3}
     \cmidrule(lr){4-11}

    &{ERA5}&{Station}&{MSE}&{MAE}&{MSE}&{MAE}&{MSE}&{MAE}&{MSE}&{MAE}\\
    \midrule
    {\small ERA5 Guided SGD}&\Checkmark&\XSolidBrush&63.32&6.55&45.84&5.39&198.14&10.91&427.25&15.52\\
    {\small Station Guided SGD}&\XSolidBrush&\Checkmark&\textbf{43.58}&\textbf{5.52}&\textbf{39.21}&\textbf{4.98}&203.51&11.22&415.76&16.57\\
    {\small ERA5 + Station Guided SGD}&\Checkmark&\Checkmark&48.78&5.64&41.43&5.15&\textbf{194.66}&\textbf{10.67}&\textbf{374.56}&\textbf{14.27}\\
    \bottomrule[1pt]

  \end{tabular}
  }
\vspace{-0.5cm}
\end{table*}


\begin{figure}[t]
    \centering
\includegraphics[width=\linewidth]{Figures/guidance_5.pdf}
    \vspace{-1.0cm}
    \caption{
Visualization comparison between totally using station observation as guidance and both integrating ERA5 and station observation as guidance. 
The former has a smaller MAE loss with the station observation, while the latter has more faithful details. 
As for MAE difference, the darker color of the observation station means the MAE bias is smaller. 
}
    \label{fig:guidance}
\vspace{-0.5cm}
\end{figure}

\begin{figure*}[t]
    \centering
\includegraphics[width=\linewidth]{Figures/distance_function_7.pdf}
\vspace{-1cm}
    \caption{Visualization comparison of SGD downscaling to station-scale employing various distance functions, where the coloration of each observation station signifies the MAE loss between the downscaled results and their corresponding observed values. }
    \label{fig:distance_function}
\vspace{-0.5cm}
\end{figure*}


\subsection{Implementation Details}
We have trained SGD on the ERA5 reanalysis dataset and the GridSat satellite observation maps for approximately 200,000 steps. 
The temporal intervals of the samples within both the ERA5 and GridSat datasets are 6 hours. 
We have selected the data from 2010 to 2021 as the training set, the entirety of the 2022 data as the validation set, and the first 6 months of 2023 as the test set.
The ERA5 maps employed in the training encompass four channels, each with a shape of $720\times1440$, while the GridSat maps feature three channels, each channel have a shape of $2000\times5143$. 
All the training task are conducted on NVIDIA A100 80GB GPU. 
For the training process, SGD is optimized using AdamW with $\beta_1=0.9$ and $\beta_2=0.999$ in 16-bit precision with loss scaling, while keeping 32-bit weights, Exponential Moving Average (EMA), and optimizer state. 
The pre-trained encoder module employs the mean squared error as its loss function during training, undergoing the process for 100 epochs. 
During the sampling phase, we utilize the same UNet structure as in the training process of conditional DDPM and employ an identical noise schedule. 
The kernel size used for simulating upscaling is $9\times9$ and the variance $\beta_t$ we utilize undergoes a linear increase from $\beta_1=10^{-4}$ to $\beta_T=0.02$. 

\subsection{Evaluation Metrics}
To compare the performance disparities between the proposed SGD and other interpolation-based and diffusion-based downscaling methodologies, we employ the interpolation of ERA5 reanalysis maps into station scale to validate the efficacy of our model. 
These compared methods leverage interpolation to extract meteorological state variables from ERA5 maps at the scale of observation stations. 
Specifically, we utilize the \textit{grid\_sample} function from the PyTorch to directly interpolate ERA5 maps with resolutions of $1^{\circ}$ and $0.25^{\circ}$, which is based on the absolute latitude and longitude positions of global stations from the Weather5k dataset~\cite{han2024weather}, which is a large-scale time series forecasting dataset containing weather data from 5,672 weather stations worldwide.  
We select MAE loss and MSE loss to quantify the inherent bias between the ERA5 maps derived from various downscaling methods and station observations. 

\subsection{Main Results}
% In this subsection, we conduct a downscaled maps visual comparison of the proposed SGD with other methods and a metric comparison within the inherent bias of generated ERA5 meteorological state variables at the scale of observation stations. 
In this section, we conduct qualitative comparisons on downscaled maps with other methods and quantitative comparisons within the inherent bias of generated ERA5 meteorological state variables at the scale of observation stations. 
The interpolation-based methods encompass bilinear and bicubic interpolation, while the diffusion-based methods include GDP~\cite{fei2023generative}, and DDNM~\cite{wang2022zero}. 
As depicted in ~\cref{tab:main}, when performing station-level downscaling evaluation, SGD surpasses existing methods in terms of both MAE and MSE metrics across variables $U_{10}$, $T_{2M}$ and $MSL$. 
% As depicted in ~\cref{tab:main}, when evaluated on the test set of the ERA5 dataset with a time interval of six hours, SGD surpasses existing methods in terms of both MAE and MSE metrics across variables $U_{10}$, $T_{2M}$ and $MSL$. 
Compared to ERA5 $1^{\circ}$, SGD presents a prominent enhancement in the T2M and MSL variables.
% at the observation station metrics. 
This reflects that employing the brightness temperature data from GridSat as conditioned input enables SGD to yield downscaling results that exhibit a smaller bias and greater accuracy in temperature and other variables, which is closely aligned with actual values. 
The downscaling results also show an improvement in metrics compared to ERA5 $1^{\circ}$ and $0.25^{\circ}$. 
The metrics comparison demonstrates that the downscaling results generated by SGD exhibit a reduced bias with the observation values from global stations. 
~\cref{fig:comparison} presents the qualitative comparison of the downscaling results produced by SGD and other methods. 
It is shown that SGD generates ERA5 maps at a scale of $6.25km$ with more faithful details, validating its adeptness in capturing and restoring intricate details during the downscaling process. 

\subsection{Station Observations as Additional Guidance}
\label{distance_function}
Within the sampling process, SGD incorporates ERA5 maps as a guiding framework, thereby enabling the generation of downscaling results containing faithful details. 
The guided sampling is achieved through the utilization of a distance function to evaluate the disparity between the maps upscaled by optimizable convolution kernels and the low-resolution ERA5 maps. 
One feasible approach involves harnessing the MSE loss between the two maps. 
Nevertheless, it is also needed to ensure that the downscaling outcomes of SGD on the Weather5k observations align more closely with the actual atmospheric conditions, 
% we experimented with various different configurations of the distance function. 
As illustrated in ~\cref{tab:ablation_guidance}, integrating the MAE loss of the SGD downscaling maps at the observation stations in the distance loss yields superior metrics and reduced disparities across multiple variables in SGD. 

It is noteworthy that employing solely the bias of the observation station as the distance function for SGD can bring the variables at the stations closer to the actual observations. 
However, this approach may introduce discrepancies in local regions at the overall downscaling results when compared to ERA5, as shown in ~\cref{fig:guidance}. 
Therefore, to seek a balance between the faithful details and reducing the observation bias, we incorporated both factors into the distance function and conducted comparative analyses across various weight relationships. 
~\cref{fig:distance_function} presents the SGD downscaling results under various settings of the distance function, as well as the inherent biases in meteorological state variables within ERA5 maps as observed at various observation stations. 
As depicted in ~\cref{fig:distance_function}, the incorporation of the observation station loss within the distance function facilitates the generation of high-resolution ERA5 maps that exhibit a smaller MSE loss relative to the true observational results at most stations. 

\subsection{Ablation Study}
\label{ablation_study}
\textbf{The Effectiveness of the Conditional GridSat Maps.} 
To assess the effectiveness of incorporating GridSat satellite observations on the diffusion model of SGD, we conducted an ablation study comparing the model to its unconditional counterpart. 
The unconditional diffusion model solely incorporates ERA5 maps into its training without GridSat as conditions.
% integrating conditions from GridSat. 
As shown in \cref{tab:ablation_training}, the conditional diffusion model (SGD) demonstrates a superior downscaling performance across all metrics compared to the unconditional diffusion model. 

\noindent \textbf{The Effectiveness of the Pre-trained GridSat Encoder.} 
Before performing feature fusion on GridSat maps, SGD utilizes an encoder to extract its features. 
We conduct experiments on whether this GridSat encoder is pre-trained.
% with pre-training the encoder before the training of the conditional diffusion model, aiming to enhance the feature extraction capability of GridSat encoder.
% performance of the encoder module during the training process. 
% We incorporated the weight of the pre-trained encoder into the training process and compared the SGD results obtained with and without those improvement. 
As depicted in \cref{tab:ablation_training}, SGD equipped with the pre-trained encoder showcases enhancements in various variables compared to its counterpart without the pre-trained GridSat encoder. 
This validates the efficacy of the pre-trained encoder in facilitating the SGD's ability to more effectively extract features from GridSat maps. 

