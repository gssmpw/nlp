\section{Pre-trained Encoder}
Before utilizing cross attention for feature fusion, SGD necessitates the extraction of features from GridSat maps by an encoder. 
The pre-trained encoder aims to enhance the feature extraction capabilities of SGD and its downscaling performance. 
The pre-trained module comprises two components: the encoder and a decoder of symmetric structure. 
The former is utilize to extracte features from GridSat maps into latent space, while the latter aims to reconstruct the encoder's outputs. 
The encoder module consists of several convolutional layers, employing $3\times 3$ convolutional kernels with a padding of 1, elevating the GridSat maps' channel count to 64. Similarly, the decoder also encompasses convolutional layers, responsible for the reconstruction of the extracted features, the detailed structure is shown in \cref{fig:app_feature}. 
The training objective is to minimize the MSE loss between the input GridSat maps and the output maps post-decoder, with the total training epochs approximating 100. 

\begin{figure}[t]
    \centering
\includegraphics[width=\linewidth]{Figures/app_feature_2.pdf}
    % \vspace{-1.6cm}
    \caption{Overall architecture of the encoder and decoder modules used in SGD. }
    \label{fig:app_feature}
% \vspace{-0.5cm}
\end{figure}