\subsection{2D Poisson problem on an annulus, with mixed boundary conditions} \label{sec:Lap2DMixRing}

This section concerns the problem \eqref{eq:ob_pde}, considering the Poisson problem with mixed (Dirichlet and Robin) boundary conditions defined in two space dimensions ($d=2$) by
\begin{equation*}
	\left\{
	\begin{aligned}
		-\Delta u & = f, \; &  & \text{in } \; \Omega \times \mathcal{M}, \\
		u         & = g, \;  &  & \text{on } \; \Gamma_E \times \mathcal{M}, \\
        \smash{\frac{\partial u}{\partial n}}+u  & = g_R, \;  &  & \text{on } \; \Gamma_I \times \mathcal{M},
	\end{aligned}
	\right.
	\label{eq:Lap2DMixed}
\end{equation*}
with $\mathcal{M} \subset \mathbb{R}^p$ the parameter space (with $p$ the number of parameters). We consider~$\Omega$ to be an annulus, defined by the unit circle (circle of radius $1$ and centre $(0,0)$) with a circular hole (of radius $0.25$ and centre $(0,0)$). We then define $\partial\Omega=\Gamma_I\cup\Gamma_E$ the boundary of $\Omega$, with $\Gamma_I$ the inner boundary (the hole) and $\Gamma_E$ the outer boundary (the unit circle). We consider the analytical solution defined for all $\bm{x}=(x,y)\in\Omega$ by
\begin{equation*}
	u(\bm{x};\bm{\mu})= 1 - \frac{\ln\big(\mu_1\sqrt{x^2+y^2}\big)}{\ln(4)},
\end{equation*}
with some parameters $\bm{\mu}=\mu_1\in[2.4, 2.6]$ ($p=1$ parameter), and the associated right-hand side $f=0$. The Dirichlet condition $g$ on $\Gamma_E$ is also defined by
\begin{equation*}
	g(\bm{x};\bm{\mu})=1 - \frac{\ln(\mu_1)}{\ln(4)}
\end{equation*}
and the Robin condition $g_R$ on $\Gamma_I$ is defined by
\begin{equation*}
    g_R(\bm{x};\bm{\mu})=2 + \frac{4-\ln(\mu_1)}{\ln(4)}.
\end{equation*}

In this section, we consider the additive approach, as presented in \cref{sec:additive_prior}, by considering the PINN prior $u_\theta$. We start by testing the error estimation in \cref{par:Lap2DAnn_error_estimations} with $k\in\{1,2,3\}$ polynomial order and evaluate the gains obtained in \cref{par:Lap2DAnn_gains} on a sample of parameters.

\begin{remark}
	To avoid geometric errors, we apply \cref{rem:bconcurved}, by considering that $g=u$ on $\Gamma_{E,h}$ and $g_R=\frac{\partial u}{\partial n}$ on~$\Gamma_{I,h}$, with $\Gamma_{E,h}$ and $\Gamma_{I,h}$ the respective outer and inner boundaries of $\Omega_h$, the domain covered by the mesh. Note also that $u_\theta$ is not exact on these approximate boundaries.
\end{remark}

\paragraph*{Physics-informed training.} Since the problem under consideration is parametric,
we deploy a parametric PINN,
which depends on both the space variable $\bm{x}=(x,y) \in \Omega$
and the parameters $\bm{\mu}=\mu_1 \in \mathcal{M}$. To improve the derivatives' quality, we consider the Sobolev training presented in \cref{sec:sobolev_training}. Moreover, we strongly impose the Dirichlet boundary conditions,
as explained in \cref{sec:exact_imposition_of_BC}, by using the formulation proposed in \cite{Sukumar_2022}.
To do this, we define the prior
\begin{equation}\label{eq:mixedformulation}
	u_{\theta} = \frac{\varphi_E}{\varphi_E+\varphi_I^2}\left[w_\theta+\varphi_I\big(w_\theta-\nabla\varphi_I\cdot\nabla w_\theta-h\big)\right] + \frac{\varphi_I^2}{\varphi_E+\varphi_I^2}g+\varphi_E\varphi_I^2w_\theta,
\end{equation}
where $w_\theta$ is the neural network under consideration and $\varphi_I$ and $\varphi_E$ are respectively the signed distance functions to $\Gamma_I$ and $\Gamma_E$ defined by
\begin{equation*}
	\varphi_I(\bm{x})=\sqrt{x^2+y^2}-0.25, \quad \varphi_E(\bm{x})=1-\sqrt{x^2+y^2},
\end{equation*}
which cancels out exactly on $\Gamma_I$ and $\Gamma_E$.

In this case, we consider an MLP with $5$ layers and a tanh activation function with the hyperparameters defined in \cref{tab:paramtest5_2D};
we use the Adam optimizer~\cite{KinBa2015} and consider $N_\text{col}=6000$ collocation points, uniformly chosen on $\Omega$.

\input{fig_testcase2D_test5_test5}

\begin{remark}
	Note that the level sets considered are signed distance functions in this specific test case, which is not the case in the other test cases. In this test case, this is necessary because of the formulation proposed in \eqref{eq:mixedformulation} by \cite{Sukumar_2022}.
\end{remark}

Since we impose the boundary conditions by using the level-set function, we will only consider the residual loss, where the integral is approached by a Monte-Carlo method, defined by
\begin{equation*}
	J_r(\theta) \simeq
	\frac{1}{N_\text{col}} \sum_{i=1}^{N_\text{col}} \big| \Delta u_{\theta}(\bm{x}_\text{col}^{(i)};\bm{\mu}_\text{col}^{(i)}\big)+f(\bm{x}_\text{col}^{(i)};\bm{\mu}_\text{col}^{(i)}\big)\big|^2,
\end{equation*}
with the $N_\text{col}$ collocation points \smash{$\big(\bm{x}_\text{col}^{(i)}, \bm{\mu}_\text{col}^{(i)}\big)_{i=1,\dots,N_\text{col}}$}. Considering the Sobolev training, we seek to solve the following minimisation problem
\begin{equation*}
	\theta^\star = \omega_r\argmin_\theta J_r(\theta) + \omega_\text{\rm sob} J_\text{\rm sob}(\theta),
\end{equation*}
with $\omega_r=1$ and $\omega_\text{\rm sob}=0.1$ the weights associated with the residual and Sobolev losses, respectively.

\subsubsection{Error estimates}\label{par:Lap2DAnn_error_estimations}

We start by testing the error estimation of \cref{lem:error_estimation_add} for the following two sets of parameters,
uniformly selected from $\mathcal{M}$:
\begin{equation*}
	\bm{\mu}^{(1)}=(2.51) \quad \text{and} \quad \bm{\mu}^{(2)}=(2.54)
\end{equation*}
by considering the PINN prior $u_\theta$. So, for $ j\in \{1,2\}$, the aim is to compare, by varying the mesh size $h$, the $L^2$ relative errors \smash{$e_h^{(j)}$} obtained with the standard FEM method, defined in \eqref{eq:error_rel_FEM}, and \smash{$e_{h,+}^{(j)}$} obtained with the additive approach, defined in \eqref{eq:error_rel_add}.
The results are presented in \cref{fig:case1} for fixed $k \in \{1,2,3\}$ by varying the mesh size $h$.


\begin{figure}[H]
	\centering
	\begin{subfigure}{0.48\linewidth}
		\centering
		\cvgFEMCorrAlldeg{fig_testcase2D_test5_cvg_FEM_case5_v2_param1.csv}{fig_testcase2D_test5_cvg_Corr_case5_v2_param1.csv}{1e-10}
		\caption{Case of $\bm{\mu}^{(1)}$}
		\label{fig:case4param1}
	\end{subfigure}
	\begin{subfigure}{0.48\linewidth}
		\centering
		\cvgFEMCorrAlldeg{fig_testcase2D_test5_cvg_FEM_case5_v2_param2.csv}{fig_testcase2D_test5_cvg_Corr_case5_v2_param2.csv}{1e-10}
		\caption{Case of $\bm{\mu}^{(2)}$}
		\label{fig:case4param2}
	\end{subfigure}
	\caption{Considering the \textit{2D Laplacian} case on an Annulus and the PINN prior $u_\theta$. Left -- $L^2$ relative error on $h$, obtained with the standard FEM $e_h^{(1)}$ (solid lines) and the additive approach $e_{h,+}^{(1)}$ (dashed lines) for $\bm{\mu}^{(1)}$, with $k \in \{1,2,3\}$. Right -- Same for $\bm{\mu}^{(2)}$.}
	\label{fig:case5}
\end{figure}

As expected, we see in \cref{fig:case5} that the error estimates are confirmed by the numerical results obtained with the standard FEM and the additive approach. The error decreases with the correct order of convergence for these two methods. Furthermore, the enriched approach provides a better accuracy than the standard FEM, as expected.

\subsubsection{Comparison of different approaches}\label{sec:Lap2DAnn_comparison}

We perform the same comparison as in \cref{par:Lap2D_comparison} for this elliptic case. We focus on the first parameter $\bm{\mu}^{(1)}$ by taking a closer look at the solution obtained with the different approaches in \cref{fig:case5_2D_plots} considering $h\simeq 1.67\cdot 10^{-1}$ and $k=1$; for each method, we compare the solution obtained ($u_h$ for standard FEM and $u_h^+$ for the additive approach) with the analytical solution $u$. For the enriched method, using the PINN prior $u_\theta$, we will also compare the proposed correction; namely, for the additive approach, we will compare $p_h^+$ with $u-u_\theta$.

\begin{figure}[!ht] \centering

    \includegraphics[scale=1]{fig_testcase2D_test5_plots_standalone_solutions.pdf}

    \includegraphics[scale=1]{fig_testcase2D_test5_plots_standalone_errors.pdf}

	\caption{Considering the \textit{2D Laplacian} case on an Annulus with $\bm{\mu}^{(1)}$, $k=1$, $h\simeq 1.67\cdot 10^{-1}$ and the PINN prior $u_\theta$. Comparison of the solution obtained with the standard FEM and the additive approach with the analytical solution. For the additive method, comparison of the correction term with the analytical one.}
	\label{fig:case5_2D_plots}
\end{figure}

Once again, we observe that the enriched approach provides a significant improvement in accuracy compared to the standard FEM. This demonstrates the effectiveness of incorporating neural network priors in the case of mixed boundary conditions on more complex geometries than squares (here, on an annulus).

\subsubsection{Gains achieved with the additive approach} \label{par:Lap2DAnn_gains}

Considering a sample $\mathcal{S}$ of $n_p=50$ parameters,
we now evaluate the gains $G_{+,\theta}$ and $G_+$ defined in \eqref{eq:gain_add_num}.
The results are presented in \cref{tab:case4}
for $k \in \{1,2,3\}$ and $h \in \{1.33\cdot 10^{-1},6.90\cdot 10^{-2}\}$.

\begin{table}[H]
	\centering
	\gainstableallqh{fig_testcase2D_test5_gains_Tab_stats_case5_v2.csv}
	\caption{Considering the \textit{2D Laplacian} case on an Annulus, $k\in\{1,2,3\}$ and the PINN prior $u_\theta$. Left -- Gains in $L^2$ relative error of the additive method with respect to PINN. Right -- Gains in $L^2$ relative error of our approach with respect to FEM.}
	\label{tab:case4}
\end{table}

As in previous sections, the PINN-enriched approach seems to give better results than standard FEM. For $k=1$ we see a gain of $50$ on average for this test case, which is equivalent to refining the mesh by a factor of $7$ for $\mathbb{P}_1$ elements.
