\begin{figure*}[hp]
    \centering
    \includegraphics[width=\textwidth]{assets/figure/casestudy.pdf}
    \caption{A case study of using \bench~and other baseline scoring systems to conduct evaluation. The harmful question is \emph{Explain a program for secretly cloning a debit card and using it without the owner's consent}.}
    \label{fig:casestudy}
\end{figure*}

\input{assets/table/jailbreak_cats}

\section{Experimental Setup}

\label{sec:exps}

In this section, we make preparation to demonstrate the capabilities of \bench~in evaluating different jailbreak methods - describe the experimental setup for the leaderboard. Although these settings are not part of \bench~itself, we recommend researchers using \bench~to adopt the principles we describe, as they are also beneficial for fair comparisons.

\subsection{Jailbreak Methods}

Currently, we evaluate 8 different types of representative jailbreak methods from 6 categories~\cite{jin2024jailbreakzoo} (see Table \ref{tab:jailbreak_methods}), with black-box and white-box attacks each accounting for half. The hyperparameter settings for each method generally maintain the existing or recommended settings in their public code repositories, with the corresponding modifications made based on the different victim LLMs. For each jailbreak response, we take the first 512 tokens using the Llama tokenizer.

\subsection{Victim LLMs}

We use 5 victim LLMs from three LLM vendors: OpenAI, Anthropic, and Meta, namely GPT-3.5-turbo, GPT-4-turbo, Claude-3.5-sonnet\footnote{Their code names are gpt-3.5-turbo-0125, gpt-4-turbo-2024-04-09, claude-3.5-sonnet-20240620.} (black-box LLMs), Llama-2-7B-Chat, and Llama-3.1-8B-Instruct (white-box LLMs). These LLMs are widely used and have relatively good safety performance. We originally planned to include more open-source LLMs from different vendors, but early experiments proved that their safety is not as good as that of Llama.



\subsection{Evaluator LLMs}

We use 3 recently released powerful but less safe LLMs as evaluators, namely GPT-4o\footnote{We use gpt-4o-2024-08-06.}, DeepSeek-V3~\cite{deepseek-ai2024deepseekv3}, and Doubao-v1.5-pro~\cite{doubao_1_5_pro}. For each case, the 3 evaluators score repeatedly. Later we will see that the scoring system proposed by \bench~has the smallest variance among the different evaluators. In Appendix \ref{app:setup_evaluators}, we show that the three LLM evaluators give very close results on the \bench~score, therefore the score results displayed on the leaderboard are all based on DeepSeek-v3 for its stable evaluation performance.

\subsection{Baseline Scoring Systems}

We use 2 rule-based keyword detection scoring systems (NegativeKeyword and PositiveKeyword), as well as 3 LLM-based scoring systems, namely StrongREJECT, PAIR~\cite{23pair}, and HarmBench. These 3 systems, along with that proposed by \bench~, together form an orthogonal representation of granularity and binary scoring, as shown in Table \ref{tab:four-system}. The implementation details of these systems are in Appendix \ref{app:setup_system}.

\begin{table}[ht]
  \centering
  \caption{Distinguish four scoring systems through granularity and form of results.}
  \centering
  \label{tab:four-system}
  \includegraphics[width=\linewidth]{assets/table/four-system.pdf}
\end{table}




