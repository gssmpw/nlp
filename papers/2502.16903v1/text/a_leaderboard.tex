\section{Jailbreak Leaderboard}
\label{sec:leaderboard}

\input{assets/table/leaderboard}

We use the proposed \bench~to evaluate 8 jailbreak methods mentioned and report their results on the core set averaged by victim LLMs (see Table \ref{tab:core-leaderboard}) and averaged by harmful topics (see Table \ref{tab:core-topic}), as well as the results of all available harmful topics for each victim LLM on the additional set (see Table \ref{tab:additional-leaderboard}).

From the results, we find that the threat of jailbreak attacks is weaker than previously assumed if the current evaluation paradigm is continued. Many jailbreak methods have been reported to achieve an ASR of exceeding 90\% or even reaching 100\% in prior benchmarks. However, under the evaluation framework of \bench, the generated harmful content is often incomplete or lacks key entities or functions, leading to lower scores. This suggests that previous benchmarks may overestimate the ASR of jailbreak methods and, consequently, exaggerate the actual safety risks posed by them. There are also cases of underestimation. For example, the jailbreak responses caused by DeepInception and MultiJail often contain a lot of irrelevant information, which can interfere with LLM-based scoring systems in making decisions based on their subjective perceptions, leading to lower scores. However, \bench~effectively identifies the harmful information within them and provides a relatively fair score. We provide a case study for this situation; see Figure \ref{fig:casestudy}.

In addition, we suggest that researchers investigate the specific vulnerabilities revealed by their attacks deeply, as the effectiveness of jailbreak methods varies across LLMs and harmful topics. Some LLMs, such as Claude-3.5-Sonnet, appear to be more resistant to jailbreak attacks than others. This raises the question of whether many jailbreak methods exploit specific vulnerabilities in particular LLMs rather than employing generalizable attack strategies. Future research on jailbreak attacks should provide transparency regarding which LLMs their methods are most effective against. Some topics, such as general copyright or political participation, can significantly more easily bypass safety mechanisms by jailbreak attacks. In contrast, topics related to pornographic information or terrorism are almost immune to jailbreak attempts. This difference may arise from strict laws and regulations that affect LLM training data. We encourage jailbreak researchers to use \bench~for comprehensive evaluation; if a method successfully bypasses safety guardrails on inherently difficult topics, it indicates greater capability. 



