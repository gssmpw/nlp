\begin{table*}[hp]
\centering
\caption{The description of jailbreak methods involved in our experiments.}
\label{tab:jailbreak_methods}
\begin{threeparttable}
\footnotesize
\renewcommand{\arraystretch}{1.2}
\setlength{\tabcolsep}{0.9\tabcolsep}
\setlength{\defaultaddspace}{0.7\defaultaddspace} %
% \rowcolors{2}{white}{gray!12}
\centering
\begin{tabular}{>{\raggedright}m{3.5cm}m{5cm}p{4.5cm}}
\toprule
\textbf{Jailbreak Category} & \textbf{Description} & \textbf{Typical Methods} \\
\toprule
Gradient based & Exploit the gradients of the model to adjust inputs, creating prompts that compel LLMs to produce harmful responses. & \textcolor{blue}{\textbf{AutoDAN}}$^\dag$, \textcolor{blue}{\textbf{GCG}}$^\dag$, AmpleGCG$^\dag$ \\
\midrule
Rule based & Decompose and redirect malicious prompts through predefined rules to evade detection. & \textcolor{blue}{\textbf{MultiJail}}$^*$, Drattack$^*$, CipherChat$^*$ \\
\midrule
Evolutionary based & Generate adversarial prompts utilizing genetic algorithms and evolutionary strategies. & \textcolor{blue}{\textbf{GPTFuzzer}}$^*$, \textcolor{blue}{\textbf{DRA}}$^*$, FuzzLLM$^*$ \\
\midrule
Multi-Agent based & Implement cooperation of multiple LLMs to iteratively refine and enhance jailbreak prompts. & PAIR$^*$, TAP$^*$, GUARD$^*$ \\
\midrule
Demonstration based & Craft specific, static system prompts to direct LLM responses. & \textcolor{blue}{\textbf{DeepInception}}$^*$, \textcolor{blue}{\textbf{FSJ}}$^\dag$, DAN$^*$ \\
\midrule
Rep-Engineering based & Modify the intermediate representation of the LLM during reasoning to make the LLM's safety mechanism fail. & \textcolor{blue}{\textbf{SCAV}}$^\dag$, RepE$^\dag$, JRE$^\dag$ \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\item \textbf{\textcolor{blue}{Highlighted}} methods means being evaluated in our paper currently.
\item $\dag$ only white-box access; $*$ black-box access.
\end{tablenotes}
\end{threeparttable}%
\end{table*}