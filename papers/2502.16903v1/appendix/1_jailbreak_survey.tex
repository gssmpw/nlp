\section{Survey of Jailbreak and Evaluations}
\label{app:jb_methods}

To understand the current state of evaluation frameworks for jailbreak attacks, we add the latest category of representation engineering-based (Rep-Engineering) attacks to the existing 5 categories of attack methods based on~\citet{jin2024jailbreakzoo}, and investigate 35 jailbreak methods from these 6 categories. 

Our investigation focuses on the harmful question datasets and the scoring systems they use to evaluate their jailbreak methods. The results in Table \ref{tab:jailbreak-methods-no-victim} show that, despite the increasing number of recent works on LLM-based scoring systems and the introduction of new harmful question datasets, most work still uses AdvBench and NegativeKeyword for evaluation. We speculate that this is due to the fact that previous research predominantly uses this configuration, forcing newly proposed studies to align with them for easier cross-work comparison. Therefore, when proposing new benchmarks that include datasets and scoring systems, it is crucial to provide more comprehensive results for jailbreak methods for comparison. Additionally, most work involves labeling with GPT or Finetuned-LLM; however, the LLMs employed are inconsistent, including various models such as Vicuna-13B, GPT-3.5, GPT-4, and GPT-4o-mini, etc., highlighting the need for a scoring system agnostic to judge models.

\input{assets/table/app_jailbreak_survey}