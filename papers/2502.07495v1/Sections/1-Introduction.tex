\section{Introduction}

Network stream mining is a cornerstone of modern computer networking, underpinning critical tasks such as DDoS victim detection \cite{poseidon, jaqen}, load balancing \cite{conga, silkroad}, congestion control \cite{hpcc}, and traffic engineering \cite{hedera, aasclepius}. As network scale and traffic volumes continue to grow, ensuring efficient and accurate stream mining at scale becomes increasingly challenging. In response, sketches \cite{bloomfilter, cmsketch, cusketch, csketch} have gained traction for their compact nature and ability to provide small-yet-bounded error under stringent memory constraints, making them well-suited for large-scale network stream mining scenarios.




Despite their appeal, existing sketch solutions often struggle to maintain acceptable error rates in the face of massive-scale networks and highly skewed traffic distributions \cite{cusketch, imcdc}. In practice, a small fraction of large flows typically accounts for the majority of total traffic volume, while many small flows remain numerous yet contribute only modestly. A representative example is the Count-Min Sketch (CMS) \cite{cmsketch}, which updates and queries counters based on hashed flow IDs. Although CMS is simple and memory-efficient, it faces a fundamental trade-off: counters sized for small flows undercount the large ones, while counters sized for large flows waste memory on the many small ones. Consequently, CMS cannot accurately capture the minority of large flows without significantly inflating overall memory usage.




To address skewness, recent works have proposed splitting large and small flows into distinct data structures, typically a key-value (KV) table for large flows combined with a compact sketch for smaller ones \cite{elasticsketch, nitrosketch, nze-sketch, bitsense}. This approach reduces collisions among different flow sizes and avoids over-allocating memory for small flows. However, a major drawback remains unresolved: when a new flow arrives, it is difficult to know immediately if it will turn into a large flow or stay small. Meanwhile, learning-based sketches attempt to predict flow size directly, hoping to bypass dynamic flow classification. LCMS \cite{lcmsketch}, for instance, trains a model to estimate whether a flow will be large, then updates either the KV table or CMS accordingly. Although this can reduce collisions when the prediction is correct, it often suffers from real-world accuracy issues and transfers poorly to dynamic network environments. Meta-sketch \cite{metasketch} takes a different route by learning the distribution of flow sizes rather than explicitly splitting flows into large and small. However, its training overhead is notably high, limiting its deployment in real-world scenarios. Other learning-based methods have explored optimizing hashing or query processing \cite{mlsketch, bertsimas2021frequency}, but they tend to share similar drawbacks -- either relying heavily on ID-size correlations or incurring significant training cost. As a result, these approaches still struggle to handle unpredictable traffic shifts while maintaining low error rates and manageable resource usage.



In this paper, we propose \alg{}, a new sketch algorithm that adapts to skewed network traffic by combining a two-tier data structure with an LLM-powered real-time flow classifier. Our key insight is that leveraging the full packet header -- beyond just the flow ID -- enables more accurate predictions of future flow sizes. By incorporating these additional header fields, \alg{} effectively infers whether a newly arriving flow is likely to become large or remain small, without relying on weak correlations between flow IDs and sizes. \alg{}’s design centers on two main techniques:


\bbb{Technique 1: Two-tier data structure.}
%
\alg{}’s data structure features two tiers: a \textit{heavy part} for large flows and a \textit{light part} for small flows. This design more effectively handles skewed distributions by reducing collisions that typically arise when large and small flows share the same counters. By tracking large flows in a dedicated space, \alg{} captures their sizes more accurately while preventing overflow in counters designated for small flows. Meanwhile, a compact sketch records small flows, limiting memory overhead. To determine whether a flow should be considered large, we rely on a real-time classifier. We also implement a simple \textit{lock flag} mechanism to retain historical classification results and prevent genuinely large flows from being evicted prematurely.



\bbb{Technique 2: LLM-powered flow classifier.}
%
\alg{} employs a \textit{flow classifier} built on a Large Language Model (LLM) adapted for network traffic. We embed each packet header (excluding specific IP addresses to avoid overfitting) into a token sequence and feed it into the model. Instead of imposing a hard threshold for labeling flows as large or small, the classifier employs a soft-label strategy: the model outputs a continuous value in \([0,1]\). Flows that are significantly larger than the threshold receive labels near 1, while those that are considerably smaller receive labels near 0. In between, flows whose predicted sizes fall near the threshold are assigned intermediate values (e.g., 0.4–0.6), capturing the inherent uncertainty and thus mitigating errors associated with borderline misclassifications, thereby improving overall accuracy of the sketch. By integrating these real-time predictions with the two-tier data structure, \alg{} can more reliably track large flows while keeping memory usage low.




We demonstrate the versatility of \alg{} through three representative network stream mining tasks: flow size query, heavy hitter query, and hierarchical heavy hitter (HHH) query. We implement \alg{} in Python and conduct extensive experiments on three real-world datasets. Experimental results show that \alg{} achieves, on average, a \textit{\(7.5\times\) improvement in accuracy} over state-of-the-art methods. All related source code is publicly available on GitHub \footnote{\url{https://github.com/LLM-Sketch/LLM-Sketch}}.
