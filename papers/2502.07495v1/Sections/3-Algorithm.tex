\section{The \alg{} Algorithm}


In this section, we first propose the data structure and operations of \alg{}. Then we present how the flow classifier is designed. After that, we describe the application of \alg{}.


\subsection{Data Structure and Operations}


\bbb{Data structure:}
%
As shown in Figure~\ref{fig:workflow}, the data structure of \alg{} consists of three parts: a heavy part, a light part, and a flow classifier.
%
The heavy part is a key-value (KV) table with \(w_h\) buckets. Each bucket contains \(d_h\) cells, and each cell records a flow, including its flow ID \(f\) and flow size \(\hat{n}\). The heavy part is also associated with a hash function \(h(.) (1 \leqslant h(.) \leqslant w_h)\), which maps flows to buckets.
%
The light part is a CMS, which maintains the sizes of small flows using small counters (e.g., 8-bit) to save memory.
%
The flow classifier is a model that infers whether an incoming packet belongs to a large flow or a small flow. Its design is detailed in Section \ref{sec:alg:model}. Ideally, large flows are recorded in the heavy part, whereas the light part is used only for small flows.


\begin{figure}[!ht]
    \centering  
    \includegraphics[width=\linewidth]{Figures/workflow.pdf}
    \caption{Workflow of \alg{}.}
    \label{fig:workflow}
\end{figure}


\bbb{Insertion:}
%
When inserting a packet of flow \(f\), \alg{} locates the mapped bucket \(B[h(f)]\) using the hash function \(h\). There are three cases:


\textit{Case 1:} If \(f\) is already recorded in \(B[h(f)]\), \alg{} simply increments its flow size by 1.


\textit{Case 2:} If \(f\) is not in \(B[h(f)]\) and there is an empty cell, \alg{} inserts \((f, 1)\) into that cell.


\textit{Case 3:} If \(f\) is not in \(B[h(f)]\) and all cells in the bucket are full, \alg{} uses the flow classifier to predict whether \(f\) is a large flow or a small flow. Based on the classifier’s output, there are two sub-cases:
%
1) If \(f\) is a large flow, let \(f_{min}\) be the flow with the minimum flow size in \(B[h(f)]\). \alg{} evicts \(f_{min}\) from the bucket, inserts it into the light part, and then inserts \((f, 1)\) into \(B[h(f)]\).
%
2) If \(f\) is a small flow, \alg{} directly inserts \(f\) into the light part.


\bbb{Query:}
%
When querying the size of a flow \(f\), \alg{} first checks if \(f\) is in the heavy part. If so, it reports the recorded flow size; otherwise, it reports the result from the light part.


\begin{figure}[!ht]
    \centering  
    \includegraphics[width=0.8\linewidth]{Figures/example.pdf}
    \caption{An example of \alg{}.}
    \label{fig:example}
\end{figure}




\textit{Example 1:} Figure~\ref{fig:example} illustrates the different cases in the insertion process of \alg{}.
%
When inserting a packet of flow \(f1\), \alg{} computes the hash function \(h\) to locate bucket \(B1\). Since \(f1\) is already recorded in \(B1\), \alg{} simply increments its flow size by 1.


\textit{Example 2:} When inserting a packet of \(f2\), \alg{} locates bucket \(B2\). Since \(B2\) has an empty cell, \alg{} inserts \((f2, 1)\) into that cell.


\textit{Example 3:} When inserting a packet of \(f5\), \alg{} locates bucket \(B3\). Since \(B3\) is full, \alg{} uses the flow classifier to predict that \(f5\) is a small flow and therefore inserts \((f5, 1)\) into the light part.


\textit{Example 4:} When inserting a packet of \(f8\), \alg{} locates bucket \(B4\). Since \(B4\) is full, \alg{} predicts \(f8\) as a large flow. \alg{} then evicts the flow with the minimum flow size (i.e., \(f7\)) from \(B4\), inserts \((f8, 1)\) into \(B4\), and inserts \(f7\) into the light part.






\bbb{Optimization: Large-flow Locking.}
%
In the insertion process described above, if a hash collision occurs, \alg{} evicts the flow with the smallest recorded size. Although this approach generally works well, it may inadvertently evict newly arrived flows that are actually large but have not yet accumulated a significant size. To address this issue, we introduce a \textit{lock flag} in each cell of the heavy part. This flag tracks how often a flow is predicted to be large, thereby reducing the likelihood of evicting flows that were previously identified as large, even if their current size is still small.


\textit{Lock flag update:}
%
Whenever a packet is inserted and its flow is (re)classified, we update the lock flag based on the classifier’s prediction and the flow’s recorded size.
%
Let \(\hat{y} \in \{0, 1\}\) be the predicted label for this packet, where \(\hat{y} = 1\) indicates large flow and \(\hat{y} = 0\) indicates small flow.
%
Recall that \(\hat{n}\) represents the flow's recorded size.
%
Then the lock flag \(L \in \{0, 1\}\) is updated as follows:
%
\[
L \leftarrow
\begin{cases} 
1, & \text{w.p. } \frac{L \cdot \hat{n} + \hat{y}}{\hat{n} + 1},\\
0, & \text{otherwise}.
\end{cases}
\]
%
This rule can be viewed as an unbiased estimator of the fraction of times the flow is predicted to be large, accumulated over its updates (See Theorem~\ref{theorem:flag}). If \(L = 1\) after the update, we treat the flow as large and therefore lock it. Otherwise, if \(L = 0\), it is more likely to be a small flow and can be safely evicted if necessary.


\textit{Eviction policy:}
%
When a hash collision occurs and \alg{} needs to evict a flow from a full bucket, it first checks whether any flows in that bucket have \(L = 0\). 1) If there is at least one unlocked flow (\(L = 0\)), \alg{} evicts tthe one with the smallest size among them. 2) If all flows in the bucket are locked (\(L = 1\)), \alg{} must evict the flow with the minimum size regardless of its lock flag. Although the latter scenario should be rare, it can still occur due to the classification errors or the probabilistic nature of the lock flag update.






\subsection{Model Design}
\label{sec:alg:model}


We choose to adapt a Large Language Model (LLM) as our flow classifier due to its ability to capture complex patterns in packet headers. By leveraging an LLM, we can process each packet header in a contextual manner, enabling the classifier to learn nuanced relationships that simpler models might overlook. Furthermore, the inherent flexibility of LLMs makes them well-suited for handling packet headers of varying lengths and formats.




\bbb{Embedding:}
Since the raw packet header data cannot be directly interpreted by a language model, we introduce an embedding layer that transforms the packet headers into token embeddings. Specifically, we treat the packet header as a binary string and segment it into two-byte chunks, each serving as a token for the embedding layer. This approach circumvents the need for a cumbersome, field-by-field parsing.
% 
In practice, to prevent overfitting to specific IP addresses, we remove the source and destination IP fields before feeding the remaining header data into the model. Consequently, the classifier focuses on more generalizable features—such as transport-layer information—rather than memorizing particular endpoints in the training data.




\bbb{Objective Function:}
% 
A straightforward strategy might be to define a hard threshold \( T \) (e.g., 64) to classify flows as large (\( \geqslant T \)) or small (\( < T \)) categories. However, directly optimizing for a strict binary cutoff can lead to the following issues:

\begin{itemize}[leftmargin=*]
    \item Flows near the threshold (e.g., those with sizes 60-70) often share similar characteristics, making a single sharp boundary somewhat arbitrary.

    \item Misclassifying flows near the threshold has relatively little impact on the overall sketch accuracy, so aggressively fitting a binary boundary can introduce unnecessary complexity.
\end{itemize}


To address these concerns, we adopt a \textit{soft-label approach} that smooths the discrete large-versus-small boundary. Concretely, we assign a label to each flow based on
%
\[
\text{label} = \sigma \Bigl(a \bigl((\log(n) - \log(T) \bigr)\Bigr),
\]
%
where \(n\) is the flow size, \(T\) is the threshold, \(\sigma(\cdot)\) is the sigmoid function, and \(a\) is a scaling parameter. This design has several advantages:


\begin{itemize}[leftmargin=*]
\item Continuity: Rather than a hard 0/1 label, flows receive labels in the continuous range \((0, 1)\), enabling a smooth transition around the threshold.

\item Reduced sensitivity: Flows that are significantly larger than \(T\) yield labels near 1, while those much smaller than \(T\) yield labels near 0. Flows in the ambiguous region around \(T\) hover near 0.5, making misclassifications less punitive.

\item Smoother optimization: Training as a regression task on these soft labels typically exhibits more stable convergence than a strict classification objective.
\end{itemize}



In practice, this soft-label mechanism helps the classifier learn a nuanced notion of flow size, rather than fixating on a single, potentially noisy threshold. Large flows (e.g., above 1,000) naturally produce labels close to 1, whereas small flows (e.g., below 5) produce labels close to 0. Flows near \(T\) fall around 0.5, diminishing the adverse impact of uncertain classifications. Consequently, the classifier achieves better overall performance and adaptability across diverse network environments.




\input{Sections/3.1-Application}
