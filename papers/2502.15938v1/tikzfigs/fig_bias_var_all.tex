\begin{figure}[th]
\centering

\begin{subfigure}[t]{0.32\textwidth}
  \centering
\input{tikzfigs/fig_bias_var_balance.1x.lowtpp.tex}
\vspace{-0.1cm}
\caption{$\constant$, fewer steps (low TPP)\label{fig:const_low}}
\end{subfigure}%
\hfill
\begin{subfigure}[t]{0.65\textwidth}
  \centering
\input{tikzfigs/fig_bias_var_balance.1x.hightpp.tex}
\vspace{-0.1cm}
\caption{$\constant$, many steps (high TPP)\label{fig:const_high}}
\end{subfigure}

\vspace{0.2cm} % Space between the rows

\noindent

\begin{subfigure}[t]{0.32\textwidth}
  \centering
\input{tikzfigs/fig_bias_var_balance.d2z.lowtpp.tex}
\vspace{-0.1cm}
\caption{$\dtoz$, fewer steps (low TPP)\label{fig:dtoz_low}}
\end{subfigure}%
\hfill
\begin{subfigure}[t]{0.65\textwidth}
  \centering
\input{tikzfigs/fig_bias_var_balance.d2z.hightpp.tex}
\vspace{-0.1cm}
\caption{$\dtoz$, many steps (high TPP)\label{fig:dtoz_high}}
\end{subfigure}

\caption{\textbf{Bias \& variance in LLM pre-training}: as training
  duration increases (higher TPP), the importance of variance
  reduction --- and having a lower LR --- increases.  With no decay
  ($\constant$, \ref{fig:const_low}, \ref{fig:const_high}), the
  optimal peak LR must drop significantly lower, neglecting bias
  reduction.  With $\dtoz$ (\ref{fig:dtoz_low}, \ref{fig:dtoz_high}),
  periods of bias and variance reduction can both be enjoyed without
  large shifts in peak LR.\label{fig:bias_var_all}}
\end{figure}
