\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{pdffigs/batch-isoStep_curves.sep_batches.617M.pdf}
  \mbox{}
  \vspace{-4mm}
  \mbox{}
  \caption{\textbf{Comparison across batch sizes (iso-step)} (610M):
    %
    Different batch sizes, $B$, but all trained for \emph{11752 steps}
    (not iso-FLOP, smaller batches see fewer TPP).  In contrast,
    \cref{fig:maxlr_isotppbatches} and appendix
    \cref{fig:maxlr_isotppbatches_sep_batches} instead keep \emph{TPP}
    constant. $\dtoz$ remains superior in the iso-Step context.  More
    interestingly, here the optimal LR actually \emph{increases} as
    batches --- and, correspondingly, the \emph{datasets} --- increase
    in size.\label{fig:maxlr_isostepbatches}}
\end{figure}
