\section{3D Hallucination}
\label{sec::system}
In this section, we first validate the existence of significant hallucination issues in the current popular 3D-LLMs on the 3D captioning task using traditional object-centric method which is used in image hallucination evaluate. We then define 3D hallucinations and compare them with the multimodal hallucinations defined in previous works.

\subsection{Simple Evaluation Based on Traditional Detection Methods}
% \begin{table}[H]
%     \centering
%    \resizebox{1.0\linewidth}{!}{ \begin{tabular}{c|c|c|c|c|c}
%     \toprule
%      & Precision & Recall & F1Score & Rouge & Meteor \\
%     \hline
%     ll3da & 36.36 & 16.67 & 22.86	& 25.87 & 14.98 \\
%     3dllm & 22.97 & 8.20 & 10.92 & 9.94 & 4.37  \\
%     \bottomrule
%     \end{tabular}}
%     \label{table:num_agents}
%     \caption{Evaluate Result of Sota 3D-LLM}
% \end{table}
\begin{table}[H]
    \centering
   \resizebox{1.0\linewidth}{!}{ \begin{tabular}{cccccc}
    \toprule
     & Precision & Recall & F1Score & Rouge & Meteor \\
    \midrule
    ll3da & 36.36 & 16.67 & 22.86 & 25.87 & 14.98 \\
    3D-LLM & 22.97 & 8.20  & 10.92 & 9.94  & 4.37  \\
    \bottomrule
    \end{tabular}}
    \caption{Evaluate Result of Sota 3D-LLM}
    \label{table:hallucinatiovalid}
\end{table}
First, we evaluate whether existing 3D-LLMs are affected by object hallucinations in tasks where it is relatively easier compare with relation hallucinations. Here, we use traditional object hallucination definitaion in image-text area which defines object hallucinations as situations where the items described in the model's output do not exist in the real scene. If the object described by 3D-LLM mismatch with the ground truth, we consider that a hallucination has occurred. Formally, we define \( A \) as the set of items output by the model, and \( B \) as the set of items present in the real scene. The evaluation metric can be defined as:
% \setlength{\abovedisplayskip}{8pt} 
% \setlength{\belowdisplayskip}{8pt}
 \begin{align}
      Precision= \frac{|A \cap B|}{|A|} 
\end{align}
 % \vspace{-5pt}
 \begin{equation}
      Recall= \frac{|A \cap B|}{|B|} 
 \end{equation}
 
To validate that existing 3D models suffer from significant object hallucinations, we select two representative 3D models : ll3da and 3D-LLM for evaluation. We use the metric defined above. The results are presented in Table \ref{table:hallucinatiovalid}. As we can see, both models perform badly and exhibit significant hallucination issues in the object description task. To better illustrate the evaluation of hallucinations, we present our evaluation of LL3DA on the description task as a Recall-Precision plot, as shown in Fig. \ref{fig:hallucination_eva}. The image is divided into the bottom-left corner and the top-right corner. The bottom-left corner indicates that the model struggles with hallucinations in the object description task, while the top-right corner demonstrates that the model performs well.  It can be observed that most of the samples are concentrated in the lower-left corner of the plot, which reflects the presence of severe hallucinations in the majority of examples produced by the current state-of-the-art models.

\begin{figure}[H]
\begin{center}
\begin{minipage}{0.9\linewidth}
% \centering
    \includegraphics[width=1.0\linewidth]{figs_evaluation/PRF_scatter_2d_ll3da.jpg}
     \caption{Object hallucination evaluation for 3D LLMs. Precision measures the proportion of described objects that exist in the scene, while recall represents the proportion of scene objects that are described.}
     \label{fig:hallucination_eva}
\end{minipage}
\end{center}
\end{figure}
\subsection{3D Hallucination Definition}

\subsubsection{Modality Difference}
Previous work on hallucinations has primarily focused on text and image modalities, as well as their interactions. Since the main difference between 3D-LLMs and earlier vision-based large models lies in the input modalities, we approach the analysis and comparison of the three types of hallucinations from the perspective of input modalities.
As shown in Table \ref{table:Different_modality}, unlike text-based LLMs and text-image-based LVLMs, 3D-LLMs primarily use text and point cloud modalities as inputs, which brings extra depth information.

\begin{table}[h]
\centering
\Large
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{ccccccc}
\toprule
\multirow{3}{*}{Model Type} & 
\multicolumn{3}{c}{Input Modality} &
\multicolumn{3}{c}{Modality Conflict} \\ \cmidrule(lr){2-7}
& Text    & Vision   & Depth   & Knowledge Conflict & Text-Image Conflict & Scene Conflict \\ \midrule
\multirow{1}{*}{LLM} & \checkmark & \xmark  & \xmark  & \checkmark & \xmark & \xmark \\
\multirow{1}{*}{LVLM} & \checkmark & \checkmark & \xmark & \checkmark & \checkmark & \xmark  \\
\multirow{1}{*}{3D-LLM} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark  \\
\bottomrule
\end{tabular}}
\caption{Modality Difference}
\label{table:Different_modality}
\end{table}

\begin{table}[h]
\centering
\Large
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{ccccccc}
\toprule
\multirow{3}{*}{Model Type} & 
\multicolumn{3}{c}{Object Hallucination} &
\multicolumn{3}{c}{Relation Hallucination} \\ \cmidrule(lr){2-7}
&Color & Shape & Size & Abstract& Relative & Accurate \\ \midrule
\multirow{1}{*}{Text Hallucination} & \checkmark & \xmark  & \xmark  & \checkmark & \xmark & \xmark \\
\multirow{1}{*}{Image Hallucination} & \checkmark & \checkmark & \xmark & \checkmark & \checkmark & \xmark  \\
\multirow{1}{*}{3D Hallucination} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark  \\
\bottomrule
\end{tabular}}
\caption{Classification of Hallucinations}
\label{table:classification}
\end{table}

The uniqueness of the input modalities leads to differences in the interactions between modalities. In text hallucinations, conflicts only arise between different textual knowledge, i.e., knowledge conflicts, which are also presented in LVLMs and 3D-LLMs, as both are built on LLMs. In image hallucinations, conflicts occur between textual and visual information. However, in 3D hallucinations, the depth information leads to conflicts where 3D-LLMs generates fictitious spatial relationships within the scene. We refer to this phenomenon as \textbf{scene conflict}.

\subsubsection{Hallucination Definition}

To define hallucination types appeared in scene conflict more concretely and accurately, we abstract the 3D scene into objects and relationships, thus defining two types of hallucinations: \textbf{Object hallucinations} and \textbf{Relation hallucinations}. We present the classification in Table \ref{table:classification}.

Object hallucinations are primarily related to the attributes of objects, such as color, shape, and size. Among these attributes, \textbf{size attribute} requires accurate depth information for proper evaluation, making this a hallucination type unique to 3D scenes. Formally, we use \(H_{obj}\) to represent object hallucination, \(S\) to represent the attributes set. \(Attr^{i}_{true} \in S\) represents the real object's attribute. \(Attr^{i}_{pred}\) represents the attributes in the prediction of 3D-LLM. 

\begin{equation}
    H_{obj} = S[Attr^{i}_{true} \neq Attr^{i}_{pred}]
\end{equation}


Relation hallucinations, on the other hand, are primarily concerned with the relationships between objects.
Among these relations, \textbf{Abstract relationship hallucinations} refer to the functional relationships between objects. \textbf{Relative positional relationships} refer to broader postion relationships, such as left-right orientation, which can usually be inferred from a given view. However, because a single view lacks depth information, precise positional relationships, such as "hanging" or "standing on," cannot be determined. In 3D scene, we can deduce \textbf{accurate spatial relations} among objects. Formally, we use \(O_i\) and \(O_j\) to represent two objects, use \(\stackrel{rel}{\longrightarrow}\) to represent relationship between two objects, use \(\stackrel{pred}{\longrightarrow}\) to represent predicted relationship. The we can define relation hallucination as:

\begin{equation}
    O_i \stackrel{rel}{\longrightarrow} O_j \neq O_i \stackrel{pred}{\longrightarrow} O_j
\end{equation}
