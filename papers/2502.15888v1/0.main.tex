% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\usepackage{graphicx} %
% \urlstyle{rm} %
% \def\UrlFont{\rm}  %
\usepackage{natbib}  %
\usepackage{caption} %
\usepackage{algorithm}
\usepackage{listings}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[outdir=./]{epstopdf}
\usepackage{enumitem}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{subfloat}
\usepackage{newfloat}
\usepackage{graphicx}
\usepackage{svg} % svg
\usepackage[normalem]{ulem}
\usepackage{framed}
\usepackage{mdframed}
\usepackage{xcolor}
\usepackage{lipsum}
\usepackage{float}
\usepackage{hyperref}
\usepackage{amssymb}  % For checkmarks and crosses
\usepackage{geometry} % To adjust page margins
\definecolor{shadecolor}{gray}{0.9}

\DeclareMathOperator*{\argmax}{arg\,max}
\newlist{todolist}{itemize}{2}
\setlist[todolist]{label=$\square$}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\done}{\rlap{$\square$}{\raisebox{2pt}{\large\hspace{1pt}\cmark}}\hspace{-2.5pt}}
\newcommand{\wontfix}{\rlap{$\square$}{\large\hspace{1pt}\xmark}}

\newcommand{\quanming}[1]{{\color{blue} \textbf{QM}. #1}}
\newcommand{\yong}[1]{{\color{red} \textbf{Yong}: #1}}
\newcommand{\gao}[1]{{\color{pink} \textbf{Gao}: #1}}
\newcommand{\chen}[1]{{\color{red} \textbf{Chen}: #1}}
\newcommand{\chenf}[1]{\footnote{+chen+:#1}}
\newcommand{\yongrevised}[1]{{\color{pink} \textbf{Yong}: #1}}
\newcommand{\req}[1]{\textcolor{black}{#1}}
\newcommand{\rev}[1]{#1}
\newcommand{\yantex}[1]{{\color{black} \textbf{Yan}: #1}}
\newcommand{\yanf}[1]{\footnote{+yanf+:#1}}
\newcommand{\reviewf}[1]{\footnote{\color{blue}+rev+:#1}}


\newtheorem{mdefinition}{Definition}

\newtheorem{problem}{Problem}
\newcommand{\para}[1]{{\vspace{4pt} \bf \noindent #1 \hspace{0pt}}}

\setlength{\belowcaptionskip}{-0.1cm} 

\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline  \\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline \\\arraybackslash\hspace{0pt}}m{#1}}


\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}
}


% \copyrightyear{2023}
% \acmYear{2023}
% \setcopyright{acmlicensed}
% \acmConference[WWW '24] {The Web Conference}{May 13--17, 2024}{Singapore}
% \acmBooktitle{Proceedings of The Web Conference 2024 (WWW '24), May 13--17, 2024, Singapore}
% \acmPrice{15.00}
% \acmISBN{979-8-4007-0103-0/23/08}
% \acmDOI{10.1145/XXXXXX.XXXXXX}
% \acmDOI{10.1145/3580305.3599322}

% \settopmatter{printacmref=true}

% \linespread{0.97}


% \copyrightyear{2024}
% \acmYear{2024}
% \setcopyright{acmcopyright}\acmConference[KDD'24]{Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}{August 25--29, 2024}{Barcelona, Spain}
% \acmBooktitle{Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'24), Barcelona, Spain}

% \author{Nian Li, Chen Gao, Yong Li, Qingmin Liao\\
% Tsinghua University\\
% \texttt{linian21@mails.tsinghua.edu.cn, \{chgao96, liyong07, liaoqm\}@tsinghua.edu.cn}}
% \author{Nian Li, Chen Gao, Yong Li, Qingmin Liao}
% \affiliation{Tsinghua University}
% \email{linian21@mails.tsinghua.edu.cn, {chgao96, liyong07, liaoqm}@tsinghua.edu.cn}

% \orcid{0000-0003-4689-2289}
% \affiliation{
%   \institution{Shenzhen International Graduate School, Tsinghua University}
%   \city{Shenzhen}
%   \country{China}
% }

% \author{Chen Gao}
% \authornote{Corresponding author (chgao96@gmail.com).}
% \author{Yong Li}
% \affiliation{%
%   \institution{Department of Electronic Engineering, Tsinghua University}
%   \city{Beijing}
%   \country{China}
% }
% \author{Qingmin Liao}
% \affiliation{
%   \institution{Shenzhen International Graduate School, Tsinghua University}
%   \city{Shenzhen}
%   \country{China}
% }
% \renewcommand{\shortauthors}{Wen, et. al.}
%\renewcommand{\shortauthors}{Efficient and Joint Hyperparameter and Architecture Search for Collaborative Filtering}
% \makeatletter
% \def\@copyrightspace{\relax}
% \makeatother
% \settopmatter{printacmref=false}
% \setlength{\abovedisplayskip}{5pt}    % 调整所有公式上方的间距
% \setlength{\belowdisplayskip}{5pt}

\title{Understanding and Evaluating Hallucinations in 3D Visual Language Models}
\author{
    Ruiying Peng\thanks{Co-first author.}, 
    Kaiyuan Li\footnotemark[1],  % 共享相同的标注
    Weichen Zhang, 
    Chen Gao, 
    Xinlei Chen, 
    Yong Li \\ 
    Tsinghua University
}
\begin{document}
\maketitle
\begin{abstract}
% With the rapid development of large language models, they have demonstrated impressive performance in fields such as reasoning and question answering. 
Recently, 3D-LLMs, which combine point-cloud encoders with large models, have been proposed to tackle complex tasks in embodied intelligence and scene understanding. In addition to showing promising results on 3D tasks, we found that they are significantly affected by hallucinations. For instance, they may generate objects that do not exist in the scene or produce incorrect relationships between objects. To investigate this issue, this work presents the first systematic study of hallucinations in 3D-LLMs. We begin by quickly evaluating hallucinations in several representative 3D-LLMs and reveal that they are all significantly affected by hallucinations. We then define hallucinations in 3D scenes and, through a detailed analysis of datasets, uncover the underlying causes of these hallucinations. We find three main causes: (1) Uneven frequency distribution of objects in the dataset. (2) Strong correlations between objects. (3) Limited diversity in object attributes. Additionally, we propose new evaluation metrics for hallucinations, including Random Point Cloud Pair and Opposite Question Evaluations, to assess whether the model generates responses based on visual information and aligns it with the text's meaning.









 
\end{abstract}

% \keywords{Macroeconomic Simulation; Large Language Models; Agent-based Modeling}

% \maketitle

% This work pioneers the integration of LLMs into macroeconomic simulations, bridging fields, and enhancing realism, promising to reshape our understanding of global economies.



% \begin{CCSXML}
% <ccs2012>
%    <concept>
%        <concept_id>10010405.10010455.10010460</concept_id>
%        <concept_desc>Applied computing~Economics</concept_desc>
%        <concept_significance>300</concept_significance>
%        </concept>
%    <concept>
%        <concept_id>10010147.10010341</concept_id>
%        <concept_desc>Computing methodologies~Modeling and simulation</concept_desc>
%        <concept_significance>300</concept_significance>
%        </concept>
%  </ccs2012>
% \end{CCSXML}

% \ccsdesc[300]{Applied computing~Economics}
% \ccsdesc[300]{Computing methodologies~Modeling and simulation}

% \begin{CCSXML}
% <ccs2012>
% <concept>
% <concept_id>10002951.10003317.10003331.10003271</concept_id>
% <concept_desc>Information systems~Recommender Systems</concept_desc>
% <concept_significance>500</concept_significance>
% </concept>
% </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Data Science~Recommender Systems}
% \ccsdesc[500]{Information systems~Recommender systems}
% \keywords{Economic Simulation; Large Language Models; Web and Economics}
% \keywords{Recommendation System; Collaborative Filtering; Automated Machine Learning}
%\settopmatter{printfolios=true} % add pages
% \textcolor{blue}{
% TO DO
% \begin{itemize}[leftmargin=*]
%     \item Intervention Experiments
%     \item Adjust all the figures for aesthetics
%     \item Reorganize System, LLM agents, and Experiments to ensure clear logic and add details to supplementary materials
%     \item Add AI-Economist~(MLP) as additional baseline~(Codes for training and simulation have been prepared)
% \end{itemize}
% }

% \textcolor{blue}{Framework:
% \begin{itemize}[leftmargin=*]
%     \item Intro
%     \item Related Work
%         \begin{enumerate}
%             \item Economic simulation
%             \item LLM agents
%         \end{enumerate}
%     \item System Overview
%     \item Methodology
%         \begin{enumerate}
%             \item Environment (with basic verification on the environment)
%             \item Agent Design
%         \end{enumerate}
%     \item Results
%         \begin{enumerate}
%             \item Basic Macroeconomic Observations
%             \item Comparison on the utility between LLM agent and baseline
%             \item Comparison on the robustness between LLM agent and baseline
%             \item Study on intervention strategy
%             \item Case study on LLM-agent's decision-making ability
%         \end{enumerate}
%     \item Conclusion and Future works
% \end{itemize}
% }


\input{1.intro}
\input{2.related}
\input{3.system}
\input{4.method}
\input{5.exp}
% \input{2.related}


\section{Conclusion}\label{sec::conclusion}
This study classifies 3D hallucinations and evaluates the severity of hallucinations in the large-scale point cloud models 3DLLM and LL3DA through description and QA tasks. By analyzing hallucination rates across datasets, we identify that high object frequency, strong correlations, and attribute singularity contribute to hallucinations. We explore whether models rely on visual information, but current tasks and metrics only measure text similarity to ground truth. To address this, we design two experiments and define hallucinations based on the results. Our findings show that models struggle to answer contextually accurate questions and align spatial relationships with visual concepts.

% In this study, we classify 3D hallucinations and conduct evaluation experiments on the large-scale point cloud models 3DLLM and LL3DA. These experiments assess the severity of hallucinations in both description and QA tasks. By analyzing the hallucination rates in relation to dataset distributions, we identify that high object frequency, strong object correlations, and the singularity of object attributes contribute to the occurrence of hallucinations. We aim to explore whether the models respond based on visual information. However, current tasks and evaluation metrics only measure the similarity between the generated text responses and the ground truth. To address this, we design two experiments and propose a definition of hallucinations based on the experimental findings. The results reveal that the models exhibit significant issues, such as failing to answer questions in accordance with the scene context and struggling to align textual expressions of spatial relationships with visual concepts.



% \clearpage

\section{Limitations}

In this study, we provide a detailed classification of hallucination types specifically for the QA task. Each QA pair is classified to detect corresponding hallucinations. However, for the description task and other long-text tasks, no specific approach is proposed to detect the types of hallucinations present in the generated answers. This limitation means that our evaluation only demonstrates the significant hallucination issues within 3D point cloud models, and uses different types of short QA pairs to explore the following questions: 1) Which types of questions are more likely to induce hallucinations in the model? 2) How does the dataset distribution impact the occurrence of hallucinations in the model?

Furthermore, we identify that models are particularly prone to attribute hallucinations and investigate the relationship between dataset distribution and hallucination rates. Regarding spatial relationship hallucinations, our experiments only reveal that the models lack understanding of spatial relationships, but do not explain why the models perform worse on spatial relationship-related questions compared to other question types.

Third, in our experiments designed to explore whether the models answer based on visual information or rely on textual inputs alone, the results indicate that the current dataset is overly simple and highly regular, which allows the models to disregard visual information in favor of answering based on text alone. However, we do not provide insights into why the models do not incorporate point cloud information in their responses from an architectural perspective.

Finally, we utilize GPT-4 to generate a new annotated dataset, which, compared to manual annotation, may contain some minor errors. Although we have discussed hallucination issues in 3D large language models and highlighted the problem of models not responding based on point cloud data, this should not be interpreted as a pessimistic view of the development of 3D language models. On the contrary, we aim to identify the reasons behind their suboptimal performance, such as the dataset distribution issues discussed in this paper. We hope that our work can provide new insights and ideas for further improving the performance of 3D large language models.




% \bibliographystyle{ACM-Reference-Format}
% % % \balance
% % % \bibliographystyle{plain}
\bibliography{bibliography}
% \nobalance

% \nobalance 

% \appendix
% \input{6.appendix}


% \nobalance 

\end{document}
