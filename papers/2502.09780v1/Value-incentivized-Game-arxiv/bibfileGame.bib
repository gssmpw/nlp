@article{rafailov2024r,
  title={From $ r $ to $ Q\^{}* $: Your Language Model is Secretly a Q-Function},
  author={Rafailov, Rafael and Hejna, Joey and Park, Ryan and Finn, Chelsea},
  journal={arXiv preprint arXiv:2404.12358},
  year={2024}
}

@article{yang2024asymptotics,
  title={Asymptotics of language model alignment},
  author={Yang, Joy Qiping and Salamatian, Salman and Sun, Ziteng and Suresh, Ananda Theertha and Beirami, Ahmad},
  journal={arXiv preprint arXiv:2404.01730},
  year={2024}
}

@inproceedings{song2022can,
  title={When Can We Learn General-Sum {M}arkov Games with a Large Number of Players Sample-Efficiently?},
  author={Song, Ziang and Mei, Song and Bai, Yu},
  booktitle={International Conference on Learning Representations},
  year={2022} 
}

@inproceedings{huang2022towards,
  title={Towards General Function Approximation in Zero-Sum {M}arkov Games},
  author={Huang, Baihe and Lee, Jason D and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{sessa2022efficient,
  title={Efficient model-based multi-agent reinforcement learning via optimistic equilibrium computation},
  author={Sessa, Pier Giuseppe and Kamgarpour, Maryam and Krause, Andreas},
  booktitle={International Conference on Machine Learning},
  pages={19580--19597},
  year={2022},
  organization={PMLR}
}

@article{russo2018tutorial,
  title={A tutorial on Thompson sampling},
  author={Russo, Daniel J and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={1},
  pages={1--96},
  year={2018},
  publisher={Now Publishers, Inc.}
}

@article{mao2023provably,
  title={Provably efficient reinforcement learning in decentralized general-sum {M}arkov games},
  author={Mao, Weichao and Ba{\c{s}}ar, Tamer},
  journal={Dynamic Games and Applications},
  volume={13},
  number={1},
  pages={165--186},
  year={2023},
  publisher={Springer}
}

 
@inproceedings{cai2024near,
  title={Near-optimal policy optimization for correlated equilibrium in general-sum {M}arkov games},
  author={Cai, Yang and Luo, Haipeng and Wei, Chen-Yu and Zheng, Weiqiang},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3889--3897},
  year={2024},
  organization={PMLR}
}

@article{zhang2022policy,
  title={Policy optimization for {M}arkov games: Unified framework and faster convergence},
  author={Zhang, Runyu and Liu, Qinghua and Wang, Huan and Xiong, Caiming and Li, Na and Bai, Yu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21886--21899},
  year={2022}
}

@article{zhan2023policy,
  title={Policy mirror descent for regularized reinforcement learning: A generalized framework with linear convergence},
  author={Zhan, Wenhao and Cen, Shicong and Huang, Baihe and Chen, Yuxin and Lee, Jason D and Chi, Yuejie},
  journal={SIAM Journal on Optimization},
  volume={33},
  number={2},
  pages={1061--1091},
  year={2023},
  publisher={SIAM}
}

@inproceedings{erez2023regret,
  title={Regret minimization and convergence to equilibria in general-sum {M}arkov games},
  author={Erez, Liad and Lancewicki, Tal and Sherman, Uri and Koren, Tomer and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={9343--9373},
  year={2023},
  organization={PMLR}
}

@inproceedings{cen2023faster,
  title={Faster Last-iterate Convergence of Policy Optimization in Zero-Sum Markov Games},
  author={Cen, Shicong and Chi, Yuejie and Du, Simon Shaolei and Xiao, Lin},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}


@article{mckelvey1995quantal,
  title={Quantal response equilibria for normal form games},
  author={McKelvey, Richard D and Palfrey, Thomas R},
  journal={Games and economic behavior},
  volume={10},
  number={1},
  pages={6--38},
  year={1995},
  publisher={Elsevier}
}

@article{shapley1953stochastic,
  title={Stochastic games},
  author={Shapley, Lloyd S},
  journal={Proceedings of the National Academy of Sciences},
  volume={39},
  number={10},
  pages={1095--1100},
  year={1953},
  publisher={National Acad Sciences}
}

@article{daskalakis2009complexity,
  title={The complexity of computing a {N}ash equilibrium},
  author={Daskalakis, Constantinos and Goldberg, Paul W and Papadimitriou, Christos H},
  journal={Communications of the ACM},
  volume={52},
  number={2},
  pages={89--97},
  year={2009},
  publisher={ACM New York, NY, USA}
}

@article{wei2020linear,
  title={Linear last-iterate convergence in constrained saddle-point optimization},
  author={Wei, Chen-Yu and Lee, Chung-Wei and Zhang, Mengxiao and Luo, Haipeng},
  journal={arXiv preprint arXiv:2006.09517},
  year={2020}
}

@article{zhang2024iterative,
  title={Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning},
  author={Zhang, Yuheng and Yu, Dian and Peng, Baolin and Song, Linfeng and Tian, Ye and Huo, Mingyue and Jiang, Nan and Mi, Haitao and Yu, Dong},
  journal={arXiv preprint arXiv:2407.00617},
  year={2024}
}

@inproceedings{he2023nearly,
  title={Nearly minimax optimal reinforcement learning for linear {M}arkov decision processes},
  author={He, Jiafan and Zhao, Heyang and Zhou, Dongruo and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={12790--12822},
  year={2023},
  organization={PMLR}
}

@inproceedings{li2022minimax,
  title={Minimax-optimal multi-agent RL in Markov games with a generative model},
  author={Li, Gen and Chi, Yuejie and Wei, Yuting and Chen, Yuxin},
  booktitle={Proceedings of the 36th International Conference on Neural Information Processing Systems},
  pages={15353--15367},
  year={2022}
}

@inproceedings{agarwal2023vo,
  title={VO$Q$L: Towards Optimal Regret in Model-free {RL} with Nonlinear Function Approximation},
  author={Agarwal, Alekh and Jin, Yujia and Zhang, Tong},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={987--1063},
  year={2023},
  organization={PMLR}
}


@article{rosset2024direct,
  title={Direct nash optimization: Teaching language models to self-improve with general preferences},
  author={Rosset, Corby and Cheng, Ching-An and Mitra, Arindam and Santacroce, Michael and Awadallah, Ahmed and Xie, Tengyang},
  journal={arXiv preprint arXiv:2404.03715},
  year={2024}
}

@article{zeng2024token,
  title={Token-level Direct Preference Optimization},
  author={Zeng, Yongcheng and Liu, Guoqing and Ma, Weiyu and Yang, Ning and Zhang, Haifeng and Wang, Jun},
  journal={arXiv preprint arXiv:2404.11999},
  year={2024}
}

@article{zhong2024dpo,
  title={Dpo meets ppo: Reinforced token optimization for rlhf},
  author={Zhong, Han and Feng, Guhao and Xiong, Wei and Zhao, Li and He, Di and Bian, Jiang and Wang, Liwei},
  journal={arXiv preprint arXiv:2404.18922},
  year={2024}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@book{ziebart2010modeling,
  title={Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
  author={Ziebart, Brian D},
  year={2010},
  publisher={Carnegie Mellon University}
}

@article{meng2024simpo,
  title={SimPO: Simple Preference Optimization with a Reference-Free Reward},
  author={Meng, Yu and Xia, Mengzhou and Chen, Danqi},
  journal={arXiv preprint arXiv:2405.14734},
  year={2024}
}

@book{beck2017first,
  title={First-order methods in optimization},
  author={Beck, Amir},
  year={2017},
  publisher={SIAM}
}

 @article{cen2022fast,
  title={Fast global convergence of natural policy gradient methods with entropy regularization},
  author={Cen, Shicong and Cheng, Chen and Chen, Yuxin and Wei, Yuting and Chi, Yuejie},
  journal={Operations Research},
  volume={70},
  number={4},
  pages={2563--2578},
  year={2022},
  publisher={INFORMS}
}

@article{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{jiang2021towards,
  title={Towards automatic evaluation of dialog systems: A model-free off-policy evaluation approach},
  author={Jiang, Haoming and Dai, Bo and Yang, Mengjiao and Zhao, Tuo and Wei, Wei},
  journal={arXiv preprint arXiv:2102.10242},
  year={2021}
}

@article{cen2024beyond,
  title={Beyond Expectations: Learning with Stochastic Dominance Made Practical},
  author={Cen, Shicong and Mei, Jincheng and Dai, Hanjun and Schuurmans, Dale and Chi, Yuejie and Dai, Bo},
  journal={arXiv preprint arXiv:2402.02698},
  year={2024}
}

@article{swamy2024minimaximalist,
  title={A minimaximalist approach to reinforcement learning from human feedback},
  author={Swamy, Gokul and Dann, Christoph and Kidambi, Rahul and Wu, Zhiwei Steven and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2401.04056},
  year={2024}
}

@book{facchinei2003finite,
  title={Finite-dimensional variational inequalities and complementarity problems},
  author={Facchinei, Francisco and Pang, Jong-Shi},
  year={2003},
  publisher={Springer}
}

@article{korpelevich1976extragradient,
  title={The extragradient method for finding saddle points and other problems},
  author={Korpelevich, Galina M},
  journal={Matecon},
  volume={12},
  pages={747--756},
  year={1976}
}

@article{popov1980,
  title={A modification of the Arrow–Hurwicz method for search of saddle points},
  author={Popov, Leonid Denisovich},
  journal={Mathematical Notes of the Academy of Sciences of the USSR, 28(5):845–848},
  year={1980}
}

@article{huang2021unifying,
  title={A unifying framework of accelerated first-order approach to strongly monotone variational inequalities},
  author={Huang, Kevin and Zhang, Shuzhong},
  journal={arXiv preprint arXiv:2103.15270},
  year={2021}
}

@article{mertikopoulos2018stochastic,
  title={Stochastic mirror descent dynamics and their convergence in monotone variational inequalities},
  author={Mertikopoulos, Panayotis and Staudigl, Mathias},
  journal={Journal of optimization theory and applications},
  volume={179},
  number={3},
  pages={838--867},
  year={2018},
  publisher={Springer}
}

@article{munos2023nash,
  title={Nash learning from human feedback},
  author={Munos, R{\'e}mi and Valko, Michal and Calandriello, Daniele and Azar, Mohammad Gheshlaghi and Rowland, Mark and Guo, Zhaohan Daniel and Tang, Yunhao and Geist, Matthieu and Mesnard, Thomas and Michi, Andrea and others},
  journal={arXiv preprint arXiv:2312.00886},
  year={2023}
}

@article{nash1950non,
  title={Non-cooperative games},
  author={Nash, John F},
  year={1950},
  publisher={Princeton University Princeton}
}

@article{cen2021fast,
  title={Fast policy extragradient methods for competitive games with entropy regularization},
  author={Cen, Shicong and Wei, Yuting and Chi, Yuejie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27952--27964},
  year={2021}
}

@article{cen2024fast,
  title={Fast Policy Extragradient Methods for Competitive Games with Entropy Regularization},
  author={Cen, Shicong and Wei, Yuting and Chi, Yuejie},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={4},
  pages={1--48},
  year={2024}
}

@article{sokota2022unified,
  title={A unified approach to reinforcement learning, quantal response equilibria, and two-player zero-sum games},
  author={Sokota, Samuel and D'Orazio, Ryan and Kolter, J Zico and Loizou, Nicolas and Lanctot, Marc and Mitliagkas, Ioannis and Brown, Noam and Kroer, Christian},
  journal={arXiv preprint arXiv:2206.05825},
  year={2022}
}

 

@inproceedings{pattathil2023symmetric,
  title={Symmetric (optimistic) natural policy gradient for multi-agent learning with parameter convergence},
  author={Pattathil, Sarath and Zhang, Kaiqing and Ozdaglar, Asuman},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={5641--5685},
  year={2023},
  organization={PMLR}
}

@article{gui2024bonbon,
  title={BoNBoN Alignment for Large Language Models and the Sweetness of Best-of-n Sampling},
  author={Gui, Lin and G{\^a}rbacea, Cristina and Veitch, Victor},
  journal={arXiv preprint arXiv:2406.00832},
  year={2024}
}

@article{wu2024self,
  title={Self-play preference optimization for language model alignment},
  author={Wu, Yue and Sun, Zhiqing and Yuan, Huizhuo and Ji, Kaixuan and Yang, Yiming and Gu, Quanquan},
  journal={arXiv preprint arXiv:2405.00675},
  year={2024}
}

@article{gorbatovski2024learn,
  title={Learn your reference model for real good alignment},
  author={Gorbatovski, Alexey and Shaposhnikov, Boris and Malakhov, Alexey and Surnachev, Nikita and Aksenov, Yaroslav and Maksimov, Ian and Balagansky, Nikita and Gavrilov, Daniil},
  journal={arXiv preprint arXiv:2404.09656},
  year={2024}
}

@article{bauschke2003bregman,
  title={Bregman monotone optimization algorithms},
  author={Bauschke, Heinz H and Borwein, Jonathan M and Combettes, Patrick L},
  journal={SIAM Journal on control and optimization},
  volume={42},
  number={2},
  pages={596--636},
  year={2003},
  publisher={SIAM}
}

@article{lan2023policy,
  title={Policy mirror descent for reinforcement learning: Linear convergence, new sampling complexity, and generalized problem classes},
  author={Lan, Guanghui},
  journal={Mathematical programming},
  volume={198},
  number={1},
  pages={1059--1106},
  year={2023},
  publisher={Springer}
}

@book{vershynin2018high,
  title={High-dimensional probability: An introduction with applications in data science},
  author={Vershynin, Roman},
  volume={47},
  year={2018},
  publisher={Cambridge university press}
}

@article{klochkov2021stability,
  title={Stability and Deviation Optimal Risk Bounds with Convergence Rate $ O (1/n) $},
  author={Klochkov, Yegor and Zhivotovskiy, Nikita},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5065--5076},
  year={2021}
}

@article{dong2023raft,
  title={Raft: Reward ranked finetuning for generative foundation model alignment},
  author={Dong, Hanze and Xiong, Wei and Goyal, Deepanshu and Zhang, Yihan and Chow, Winnie and Pan, Rui and Diao, Shizhe and Zhang, Jipeng and Shum, Kashun and Zhang, Tong},
  journal={arXiv preprint arXiv:2304.06767},
  year={2023}
}

@article{team2024gemma,
  title={Gemma: Open models based on gemini research and technology},
  author={Team, Gemma and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  journal={arXiv preprint arXiv:2403.08295},
  year={2024}
}

@article{sessa2024bondaligningllmsbestofn,
  title={Bond: Aligning llms with best-of-n distillation},
  author={Sessa, Pier Giuseppe and Dadashi, Robert and Hussenot, L{\'e}onard and Ferret, Johan and Vieillard, Nino and Ram{\'e}, Alexandre and Shariari, Bobak and Perrin, Sarah and Friesen, Abe and Cideron, Geoffrey and others},
  journal={arXiv preprint arXiv:2407.14622},
  year={2024}
}


@inproceedings{yuan2023linear,
  title={Linear convergence of natural policy gradient methods with log-linear policies},
  author={Yuan, Rui and Du, Simon S and Gower, Robert M and Lazaric, Alessandro and Xiao, Lin},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@inproceedings{munos2003error,
  title={Error bounds for approximate policy iteration},
  author={Munos, R{\'e}mi},
  booktitle={ICML},
  volume={3},
  pages={560--567},
  year={2003},
  organization={Citeseer}
}

@inproceedings{munos2005error,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  booktitle={Proceedings of the National Conference on Artificial Intelligence},
  volume={20},
  pages={1006},
  year={2005},
  organization={Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999}
}


@article{munos2008finite,
  title={Finite-Time Bounds for Fitted Value Iteration.},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={5},
  year={2008}
}

@article{bousquet2002stability,
  title={Stability and generalization},
  author={Bousquet, Olivier and Elisseeff, Andr{\'e}},
  journal={The Journal of Machine Learning Research},
  volume={2},
  pages={499--526},
  year={2002},
  publisher={JMLR. org}
}

@article{liu2022loss,
  title={Loss landscapes and optimization in over-parameterized non-linear systems and neural networks},
  author={Liu, Chaoyue and Zhu, Libin and Belkin, Mikhail},
  journal={Applied and Computational Harmonic Analysis},
  volume={59},
  pages={85--116},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{kang2022sharper,
  title={Sharper Utility Bounds for Differentially Private Models: Smooth and Non-smooth},
  author={Kang, Yilin and Liu, Yong and Li, Jian and Wang, Weiping},
  booktitle={Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
  pages={951--961},
  year={2022}
}

@inproceedings{charles2018stability,
  title={Stability and generalization of learning algorithms that converge to global optima},
  author={Charles, Zachary and Papailiopoulos, Dimitris},
  booktitle={International conference on machine learning},
  pages={745--754},
  year={2018},
  organization={PMLR}
}

@inproceedings{karimi2016linear,
  title={Linear convergence of gradient and proximal-gradient methods under the polyak-{\l}ojasiewicz condition},
  author={Karimi, Hamed and Nutini, Julie and Schmidt, Mark},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2016, Riva del Garda, Italy, September 19-23, 2016, Proceedings, Part I 16},
  pages={795--811},
  year={2016},
  organization={Springer}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{beirami2024theoretical,
  title={Theoretical guarantees on the best-of-n alignment policy},
  author={Beirami, Ahmad and Agarwal, Alekh and Berant, Jonathan and D'Amour, Alexander and Eisenstein, Jacob and Nagpal, Chirag and Suresh, Ananda Theertha},
  journal={arXiv preprint arXiv:2401.01879},
  year={2024}
}

@article{eisenstein2023helping,
  title={Helping or herding? reward model ensembles mitigate but do not eliminate reward hacking},
  author={Eisenstein, Jacob and Nagpal, Chirag and Agarwal, Alekh and Beirami, Ahmad and D'Amour, Alex and Dvijotham, DJ and Fisch, Adam and Heller, Katherine and Pfohl, Stephen and Ramachandran, Deepak and others},
  journal={arXiv preprint arXiv:2312.09244},
  year={2023}
}

@inproceedings{gao2023scaling,
  title={Scaling laws for reward model overoptimization},
  author={Gao, Leo and Schulman, John and Hilton, Jacob},
  booktitle={International Conference on Machine Learning},
  pages={10835--10866},
  year={2023},
  organization={PMLR}
}

@article{wang2024transforming,
  title={Transforming and Combining Rewards for Aligning Large Language Models},
  author={Wang, Zihao and Nagpal, Chirag and Berant, Jonathan and Eisenstein, Jacob and D'Amour, Alex and Koyejo, Sanmi and Veitch, Victor},
  journal={arXiv preprint arXiv:2402.00742},
  year={2024}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}



@inproceedings{yang2023federated,
  title={Federated natural policy gradient and actor critic methods for multi-task reinforcement learning},
  author={Yang, Tong and Cen, Shicong and Wei, Yuting and Chen, Yuxin and Chi, Yuejie},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}


@article{yang2024context,
  title={In-Context Learning with Representations: Contextual Generalization of Trained Transformers},
  author={Yang, Tong and Huang, Yu and Liang, Yingbin and Chi, Yuejie},
  journal={arXiv preprint arXiv:2408.10147},
  year={2024}
}

@article{wu2024convergence,
  title={On the convergence of encoder-only shallow transformers},
  author={Wu, Yongtao and Liu, Fanghui and Chrysos, Grigorios and Cevher, Volkan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{gutmann2010noise,
  title={Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author={Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={297--304},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{amini2024variational,
  title={Variational best-of-n alignment},
  author={Amini, Afra and Vieira, Tim and Cotterell, Ryan},
  journal={arXiv preprint arXiv:2407.06057},
  year={2024}
}

@article{stampacchia1964formes,
author = {Stampacchia, Guido},
title = {Formes Bilineaires Coercitives Sur Les Ensembles Convexes},
journal = {Acad\'emie des Sciences de Paris},
volume = {258},
pages = {4413--4416},
year = {1964}
}

@article{yang2022solving,
  title={Solving constrained variational inequalities via a first-order interior point-based method},
  author={Yang, Tong and Jordan, Michael I and Chavdarova, Tatjana},
  journal={arXiv preprint arXiv:2206.10575},
  year={2022}
}

@inproceedings{chavdarova2024primal,
  title={A Primal-Dual Approach to Solving Variational Inequalities with General Constraints},
  author={Chavdarova, Tatjana and Yang, Tong and Pagliardini, Matteo and Jordan, Michael},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@article{nakano2021webgpt,
  title={Webgpt: Browser-assisted question-answering with human feedback},
  author={Nakano, Reiichiro and Hilton, Jacob and Balaji, Suchir and Wu, Jeff and Ouyang, Long and Kim, Christina and Hesse, Christopher and Jain, Shantanu and Kosaraju, Vineet and Saunders, William and others},
  journal={arXiv preprint arXiv:2112.09332},
  year={2021}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{ibarz2018reward,
  title={Reward learning from human preferences and demonstrations in atari},
  author={Ibarz, Borja and Leike, Jan and Pohlen, Tobias and Irving, Geoffrey and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{leike2018scalable,
  title={Scalable agent alignment via reward modeling: a research direction},
  author={Leike, Jan and Krueger, David and Everitt, Tom and Martic, Miljan and Maini, Vishal and Legg, Shane},
  journal={arXiv preprint arXiv:1811.07871},
  year={2018}
}

@article{bahdanau2018learning,
  title={Learning to understand goal specifications by modelling reward},
  author={Bahdanau, Dzmitry and Hill, Felix and Leike, Jan and Hughes, Edward and Hosseini, Arian and Kohli, Pushmeet and Grefenstette, Edward},
  journal={arXiv preprint arXiv:1806.01946},
  year={2018}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{achiam2023gpt,
  title={GPT-4 technical report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{askell2021general,
  title={A general language assistant as a laboratory for alignment},
  author={Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and DasSarma, Nova and others},
  journal={arXiv preprint arXiv:2112.00861},
  year={2021}
}


@article{cen2024value,
  title={Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF},
  author={Cen, Shicong and Mei, Jincheng and Goshvadi, Katayoon and Dai, Hanjun and Yang, Tong and Yang, Sherry and Schuurmans, Dale and Chi, Yuejie and Dai, Bo},
  journal={arXiv preprint arXiv:2405.19320},
  year={2024}
}

@article{yuan2023rrhf,
  title={Rrhf: Rank responses to align language models with human feedback without tears},
  author={Yuan, Zheng and Yuan, Hongyi and Tan, Chuanqi and Wang, Wei and Huang, Songfang and Huang, Fei},
  journal={arXiv preprint arXiv:2304.05302},
  year={2023}
}

@article{tang2024generalized,
  title={Generalized preference optimization: A unified approach to offline alignment},
  author={Tang, Yunhao and Guo, Zhaohan Daniel and Zheng, Zeyu and Calandriello, Daniele and Munos, R{\'e}mi and Rowland, Mark and Richemond, Pierre Harvey and Valko, Michal and Pires, Bernardo {\'A}vila and Piot, Bilal},
  journal={arXiv preprint arXiv:2402.05749},
  year={2024}
}

@article{zhao2023slic,
  title={Slic-hf: Sequence likelihood calibration with human feedback},
  author={Zhao, Yao and Joshi, Rishabh and Liu, Tianqi and Khalman, Misha and Saleh, Mohammad and Liu, Peter J},
  journal={arXiv preprint arXiv:2305.10425},
  year={2023}
}

@article{ethayarajh2024kto,
  title={Kto: Model alignment as prospect theoretic optimization},
  author={Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe},
  journal={arXiv preprint arXiv:2402.01306},
  year={2024}
}

@article{xu2024contrastive,
  title={Contrastive preference optimization: Pushing the boundaries of llm performance in machine translation},
  author={Xu, Haoran and Sharaf, Amr and Chen, Yunmo and Tan, Weiting and Shen, Lingfeng and Van Durme, Benjamin and Murray, Kenton and Kim, Young Jin},
  journal={arXiv preprint arXiv:2401.08417},
  year={2024}
}

@inproceedings{azar2024general,
  title={A general theoretical paradigm to understand learning from human preferences},
  author={Azar, Mohammad Gheshlaghi and Guo, Zhaohan Daniel and Piot, Bilal and Munos, Remi and Rowland, Mark and Valko, Michal and Calandriello, Daniele},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4447--4455},
  year={2024},
  organization={PMLR}
}

@article{jiang2023llm,
  title={Llm-blender: Ensembling large language models with pairwise ranking and generative fusion},
  author={Jiang, Dongfu and Ren, Xiang and Lin, Bill Yuchen},
  journal={arXiv preprint arXiv:2306.02561},
  year={2023}
}

@article{cui2023ultrafeedback,
  title={Ultrafeedback: Boosting language models with high-quality feedback},
  author={Cui, Ganqu and Yuan, Lifan and Ding, Ning and Yao, Guanming and Zhu, Wei and Ni, Yuan and Xie, Guotong and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2310.01377},
  year={2023}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{zellers2019hellaswag,
  title={Hellaswag: Can a machine really finish your sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  journal={arXiv preprint arXiv:1905.07830},
  year={2019}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{dubois2024alpacafarm,
  title={Alpacafarm: A simulation framework for methods that learn from human feedback},
  author={Dubois, Yann and Li, Chen Xuechen and Taori, Rohan and Zhang, Tianyi and Gulrajani, Ishaan and Ba, Jimmy and Guestrin, Carlos and Liang, Percy S and Hashimoto, Tatsunori B},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@article{gao2024rebel,
  title={Rebel: Reinforcement learning via regressing relative rewards},
  author={Gao, Zhaolin and Chang, Jonathan D and Zhan, Wenhao and Oertell, Owen and Swamy, Gokul and Brantley, Kiant{\'e} and Joachims, Thorsten and Bagnell, J Andrew and Lee, Jason D and Sun, Wen},
  journal={arXiv preprint arXiv:2404.16767},
  year={2024}
}

@article{huang2024correcting,
  title={Correcting the mythos of kl-regularization: Direct alignment without overparameterization via chi-squared preference optimization},
  author={Huang, Audrey and Zhan, Wenhao and Xie, Tengyang and Lee, Jason D and Sun, Wen and Krishnamurthy, Akshay and Foster, Dylan J},
  journal={arXiv preprint arXiv:2407.13399},
  year={2024}
}

@article{yang2024faster,
  title={Faster WIND: Accelerating Iterative Best-of-$ N $ Distillation for LLM Alignment},
  author={Yang, Tong and Mei, Jincheng and Dai, Hanjun and Wen, Zixin and Cen, Shicong and Schuurmans, Dale and Chi, Yuejie and Dai, Bo},
  journal={arXiv preprint arXiv:2410.20727},
  year={2024}
}

@inproceedings{mete2021reward,
  title={Reward biased maximum likelihood estimation for reinforcement learning},
  author={Mete, Akshay and Singh, Rahul and Liu, Xi and Kumar, PR},
  booktitle={Learning for Dynamics and Control},
  pages={815--827},
  year={2021},
  organization={PMLR}
}

@article{liu2024maximize,
  title={Maximize to explore: One objective function fusing estimation, planning, and exploration},
  author={Liu, Zhihan and Lu, Miao and Xiong, Wei and Zhong, Han and Hu, Hao and Zhang, Shenao and Zheng, Sirui and Yang, Zhuoran and Wang, Zhaoran},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{cheng2024self,
  title={Self-playing Adversarial Language Game Enhances LLM Reasoning},
  author={Cheng, Pengyu and Hu, Tianhao and Xu, Han and Zhang, Zhisong and Dai, Yong and Han, Lei and Du, Nan},
  journal={arXiv preprint arXiv:2404.10642},
  year={2024}
}

@article{li2024ganprompt,
  title={GANPrompt: Enhancing Robustness in LLM-Based Recommendations with GAN-Enhanced Diversity Prompts},
  author={Li, Xinyu and Zhao, Chuang and Zhao, Hongke and Wu, Likang and HE, Ming},
  journal={arXiv preprint arXiv:2408.09671},
  year={2024}
}

@article{hubinger2023conditioning,
  title={Conditioning predictive models: Risks and strategies},
  author={Hubinger, Evan and Jermyn, Adam and Treutlein, Johannes and Hudson, Rubi and Woolverton, Kate},
  journal={arXiv preprint arXiv:2302.00805},
  year={2023}
}

@article{khan2024debating,
  title={Debating with more persuasive llms leads to more truthful answers},
  author={Khan, Akbir and Hughes, John and Valentine, Dan and Ruis, Laura and Sachan, Kshitij and Radhakrishnan, Ansh and Grefenstette, Edward and Bowman, Samuel R and Rockt{\"a}schel, Tim and Perez, Ethan},
  journal={arXiv preprint arXiv:2402.06782},
  year={2024}
}

@article{freedman1975tail,
  title={On tail probabilities for martingales},
  author={Freedman, David A},
  journal={the Annals of Probability},
  pages={100--118},
  year={1975},
  publisher={JSTOR}
}

@article{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={2826--2836},
  year={2021},
  organization={PMLR}
}

@inproceedings{o2021matrix,
  title={Matrix games with bandit feedback},
  author={O’Donoghue, Brendan and Lattimore, Tor and Osband, Ian},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={279--289},
  year={2021},
  organization={PMLR}
}



@book{wainwright2019high,
  title={High-dimensional statistics: A non-asymptotic viewpoint},
  author={Wainwright, Martin J},
  volume={48},
  year={2019},
  publisher={Cambridge university press}
}

@article{jin2021bellman,
  title={Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13406--13418},
  year={2021}
}

@inproceedings{liu2022welfare,
  title={Welfare maximization in competitive equilibrium: Reinforcement learning for markov exchange economy},
  author={Liu, Zhihan and Lu, Miao and Wang, Zhaoran and Jordan, Michael and Yang, Zhuoran},
  booktitle={International Conference on Machine Learning},
  pages={13870--13911},
  year={2022},
  organization={PMLR}
}

@inproceedings{jin2022power,
  title={The power of exploiter: Provable multi-agent rl in large state spaces},
  author={Jin, Chi and Liu, Qinghua and Yu, Tiancheng},
  booktitle={International Conference on Machine Learning},
  pages={10251--10279},
  year={2022},
  organization={PMLR}
}

@inproceedings{mei2020global,
  title={On the global convergence rates of softmax policy gradient methods},
  author={Mei, Jincheng and Xiao, Chenjun and Szepesvari, Csaba and Schuurmans, Dale},
  booktitle={International conference on machine learning},
  pages={6820--6829},
  year={2020},
  organization={PMLR}
}

 

@article{aumann1987correlated,
  title={Correlated equilibrium as an expression of Bayesian rationality},
  author={Aumann, Robert J},
  journal={Econometrica: Journal of the Econometric Society},
  pages={1--18},
  year={1987},
  publisher={JSTOR}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on learning theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@inproceedings{ayoub2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  pages={463--474},
  year={2020},
  organization={PMLR}
}

@inproceedings{modi2020sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2010--2020},
  year={2020},
  organization={PMLR}
}

@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}


@inproceedings{cui2023breaking,
  title={Breaking the curse of multiagents in a large state space: Rl in markov games with independent linear function approximation},
  author={Cui, Qiwen and Zhang, Kaiqing and Du, Simon},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={2651--2652},
  year={2023},
  organization={PMLR}
}

@inproceedings{zhou2021nearly,
  title={Nearly minimax optimal reinforcement learning for linear mixture markov decision processes},
  author={Zhou, Dongruo and Gu, Quanquan and Szepesvari, Csaba},
  booktitle={Conference on Learning Theory},
  pages={4532--4576},
  year={2021},
  organization={PMLR}
}

@article{cheng2004notes,
  title={Notes on equilibria in symmetric games},
  author={Cheng, Shih-Fen and Reeves, Daniel M and Vorobeychik, Yevgeniy and Wellman, Michael P},
  year={2004},
  publisher={GTDT}
}

@inproceedings{liu2020exploration,
  title={Exploration through reward biasing: Reward-biased maximum likelihood estimation for stochastic multi-armed bandits},
  author={Liu, Xi and Hsieh, Ping-Chun and Hung, Yu Heng and Bhattacharya, Anirban and Kumar, P},
  booktitle={International Conference on Machine Learning},
  pages={6248--6258},
  year={2020},
  organization={PMLR}
}

@inproceedings{melo2008analysis,
  title={An analysis of reinforcement learning with function approximation},
  author={Melo, Francisco S and Meyn, Sean P and Ribeiro, M Isabel},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={664--671},
  year={2008}
}

@article{wang2019optimism,
  title={Optimism in reinforcement learning with generalized linear function approximation},
  author={Wang, Yining and Wang, Ruosong and Du, Simon S and Krishnamurthy, Akshay},
  journal={arXiv preprint arXiv:1912.04136},
  year={2019}
}

@inproceedings{yang2019sample,
  title={Sample-optimal parametric q-learning using linearly additive features},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International conference on machine learning},
  pages={6995--7004},
  year={2019},
  organization={PMLR}
}


@inproceedings{zanette2020frequentist,
  title={Frequentist regret bounds for randomized least-squares value iteration},
  author={Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1954--1964},
  year={2020},
  organization={PMLR}
}

@article{yang2020provably,
  title={Provably efficient reinforcement learning with kernel and neural function approximations},
  author={Yang, Zhuoran and Jin, Chi and Wang, Zhaoran and Wang, Mengdi and Jordan, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13903--13916},
  year={2020}
}

@inproceedings{xie2020learning,
  title={Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium},
  author={Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={Conference on learning theory},
  pages={3674--3682},
  year={2020},
  organization={PMLR}
}

@inproceedings{chen2022almost,
  title={Almost optimal algorithms for two-player zero-sum linear mixture {M}arkov games},
  author={Chen, Zixiang and Zhou, Dongruo and Gu, Quanquan},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={227--261},
  year={2022},
  organization={PMLR}
}

@inproceedings{jia2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Jia, Zeyu and Yang, Lin and Szepesvari, Csaba and Wang, Mengdi},
  booktitle={Learning for Dynamics and Control},
  pages={666--686},
  year={2020},
  organization={PMLR}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{shi2022pessimistic,
  title={Pessimistic q-learning for offline reinforcement learning: Towards optimal sample complexity},
  author={Shi, Laixi and Li, Gen and Wei, Yuting and Chen, Yuxin and Chi, Yuejie},
  booktitle={International conference on machine learning},
  pages={19967--20025},
  year={2022},
  organization={PMLR}
}

@article{gawlikowski2023survey,
  title={A survey of uncertainty in deep neural networks},
  author={Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and others},
  journal={Artificial Intelligence Review},
  volume={56},
  number={Suppl 1},
  pages={1513--1589},
  year={2023},
  publisher={Springer}
}

@article{kumar1982new,
  title={A new family of optimal adaptive controllers for Markov chains},
  author={Kumar, P and Becker, A},
  journal={IEEE Transactions on Automatic Control},
  volume={27},
  number={1},
  pages={137--146},
  year={1982},
  publisher={IEEE}
}

@inproceedings{hung2021reward,
  title={Reward-biased maximum likelihood estimation for linear stochastic bandits},
  author={Hung, Yu-Heng and Hsieh, Ping-Chun and Liu, Xi and Kumar, PR},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={9},
  pages={7874--7882},
  year={2021}
}

@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@inproceedings{mertikopoulos2018cycles,
  title={Cycles in adversarial regularized learning},
  author={Mertikopoulos, Panayotis and Papadimitriou, Christos and Piliouras, Georgios},
  booktitle={Proceedings of the twenty-ninth annual ACM-SIAM symposium on discrete algorithms},
  pages={2703--2717},
  year={2018},
  organization={SIAM}
}

@incollection{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine learning proceedings 1994},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}

@article{daskalakis2018last,
  title={Last-iterate convergence: Zero-sum games and constrained min-max optimization},
  author={Daskalakis, Constantinos and Panageas, Ioannis},
  journal={arXiv preprint arXiv:1807.04252},
  year={2018}
}


@article{lai1987adaptive,
  title={Adaptive treatment allocation and the multi-armed bandit problem},
  author={Lai, Tze Leung},
  journal={The annals of statistics},
  pages={1091--1114},
  year={1987},
  publisher={JSTOR}
}
@inproceedings{bouneffouf2016finite,
  title={Finite-time analysis of the multi-armed bandit problem with known trend},
  author={Bouneffouf, Djallel},
  booktitle={2016 IEEE Congress on Evolutionary Computation (CEC)},
  pages={2543--2549},
  year={2016},
  organization={IEEE}
}

@article{o2021variational,
  title={Variational bayesian reinforcement learning with regret bounds},
  author={O'Donoghue, Brendan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={28208--28221},
  year={2021}
}

@inproceedings{liu2021sharp,
  title={A sharp analysis of model-based reinforcement learning with self-play},
  author={Liu, Qinghua and Yu, Tiancheng and Bai, Yu and Jin, Chi},
  booktitle={International Conference on Machine Learning},
  pages={7001--7010},
  year={2021},
  organization={PMLR}
}

@article{bai2021sample,
  title={Sample-efficient learning of stackelberg equilibria in general-sum games},
  author={Bai, Yu and Jin, Chi and Wang, Huan and Xiong, Caiming},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={25799--25811},
  year={2021}
}

@article{song2021can,
  title={When can we learn general-sum Markov games with a large number of players sample-efficiently?},
  author={Song, Ziang and Mei, Song and Bai, Yu},
  journal={arXiv preprint arXiv:2110.04184},
  year={2021}
}

@article{jin2021v,
  title={V-Learning--A Simple, Efficient, Decentralized Algorithm for Multiagent RL},
  author={Jin, Chi and Liu, Qinghua and Wang, Yuanhao and Yu, Tiancheng},
  journal={arXiv preprint arXiv:2110.14555},
  year={2021}
}


@inproceedings{wang2023breaking,
  title={Breaking the curse of multiagency: Provably efficient decentralized multi-agent rl with function approximation},
  author={Wang, Yuanhao and Liu, Qinghua and Bai, Yu and Jin, Chi},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={2793--2848},
  year={2023},
  organization={PMLR}
}

@article{dai2024refined,
  title={Refined sample complexity for markov games with independent linear function approximation},
  author={Dai, Yan and Cui, Qiwen and Du, Simon S},
  journal={arXiv preprint arXiv:2402.07082},
  year={2024}
}

@article{ni2022representation,
  title={Representation learning for general-sum low-rank markov games},
  author={Ni, Chengzhuo and Song, Yuda and Zhang, Xuezhou and Jin, Chi and Wang, Mengdi},
  journal={arXiv preprint arXiv:2210.16976},
  year={2022}
}

@article{busoniu2008comprehensive,
  title={A comprehensive survey of multiagent reinforcement learning},
  author={Busoniu, Lucian and Babuska, Robert and De Schutter, Bart},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={38},
  number={2},
  pages={156--172},
  year={2008},
  publisher={IEEE}
}

@article{xu2014reinforcement,
  title={Reinforcement learning algorithms with function approximation: Recent advances and applications},
  author={Xu, Xin and Zuo, Lei and Huang, Zhenhua},
  journal={Information sciences},
  volume={261},
  pages={1--31},
  year={2014},
  publisher={Elsevier}
}

@inproceedings{dani2008stochastic,
  title={Stochastic Linear Optimization under Bandit Feedback.},
  author={Dani, Varsha and Hayes, Thomas P and Kakade, Sham M},
  booktitle={COLT},
  volume={2},
  pages={3},
  year={2008}
}