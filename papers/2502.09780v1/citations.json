[
  {
    "index": 0,
    "papers": [
      {
        "key": "mertikopoulos2018cycles",
        "author": "Mertikopoulos, Panayotis and Papadimitriou, Christos and Piliouras, Georgios",
        "title": "Cycles in adversarial regularized learning"
      },
      {
        "key": "shapley1953stochastic",
        "author": "Shapley, Lloyd S",
        "title": "Stochastic games"
      },
      {
        "key": "daskalakis2018last",
        "author": "Daskalakis, Constantinos and Panageas, Ioannis",
        "title": "Last-iterate convergence: Zero-sum games and constrained min-max optimization"
      },
      {
        "key": "wei2020linear",
        "author": "Wei, Chen-Yu and Lee, Chung-Wei and Zhang, Mengxiao and Luo, Haipeng",
        "title": "Linear last-iterate convergence in constrained saddle-point optimization"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "cen2021fast",
        "author": "Cen, Shicong and Wei, Yuting and Chi, Yuejie",
        "title": "Fast policy extragradient methods for competitive games with entropy regularization"
      },
      {
        "key": "zhan2023policy",
        "author": "Zhan, Wenhao and Cen, Shicong and Huang, Baihe and Chen, Yuxin and Lee, Jason D and Chi, Yuejie",
        "title": "Policy mirror descent for regularized reinforcement learning: A generalized framework with linear convergence"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "o2021matrix",
        "author": "O\u2019Donoghue, Brendan and Lattimore, Tor and Osband, Ian",
        "title": "Matrix games with bandit feedback"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "lai1987adaptive",
        "author": "Lai, Tze Leung",
        "title": "Adaptive treatment allocation and the multi-armed bandit problem"
      },
      {
        "key": "bouneffouf2016finite",
        "author": "Bouneffouf, Djallel",
        "title": "Finite-time analysis of the multi-armed bandit problem with known trend"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "o2021variational",
        "author": "O'Donoghue, Brendan",
        "title": "Variational bayesian reinforcement learning with regret bounds"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "russo2018tutorial",
        "author": "Russo, Daniel J and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng and others",
        "title": "A tutorial on Thompson sampling"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "littman1994markov",
        "author": "Littman, Michael L",
        "title": "Markov games as a framework for multi-agent reinforcement learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "liu2021sharp",
        "author": "Liu, Qinghua and Yu, Tiancheng and Bai, Yu and Jin, Chi",
        "title": "A sharp analysis of model-based reinforcement learning with self-play"
      },
      {
        "key": "bai2021sample",
        "author": "Bai, Yu and Jin, Chi and Wang, Huan and Xiong, Caiming",
        "title": "Sample-efficient learning of stackelberg equilibria in general-sum games"
      },
      {
        "key": "mao2023provably",
        "author": "Mao, Weichao and Ba{\\c{s}}ar, Tamer",
        "title": "Provably efficient reinforcement learning in decentralized general-sum {M}arkov games"
      },
      {
        "key": "song2021can",
        "author": "Song, Ziang and Mei, Song and Bai, Yu",
        "title": "When can we learn general-sum Markov games with a large number of players sample-efficiently?"
      },
      {
        "key": "jin2021v",
        "author": "Jin, Chi and Liu, Qinghua and Wang, Yuanhao and Yu, Tiancheng",
        "title": "V-Learning--A Simple, Efficient, Decentralized Algorithm for Multiagent RL"
      },
      {
        "key": "li2022minimax",
        "author": "Li, Gen and Chi, Yuejie and Wei, Yuting and Chen, Yuxin",
        "title": "Minimax-optimal multi-agent RL in Markov games with a generative model"
      },
      {
        "key": "sessa2022efficient",
        "author": "Sessa, Pier Giuseppe and Kamgarpour, Maryam and Krause, Andreas",
        "title": "Efficient model-based multi-agent reinforcement learning via optimistic equilibrium computation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "erez2023regret",
        "author": "Erez, Liad and Lancewicki, Tal and Sherman, Uri and Koren, Tomer and Mansour, Yishay",
        "title": "Regret minimization and convergence to equilibria in general-sum {M}arkov games"
      },
      {
        "key": "zhang2022policy",
        "author": "Zhang, Runyu and Liu, Qinghua and Wang, Huan and Xiong, Caiming and Li, Na and Bai, Yu",
        "title": "Policy optimization for {M}arkov games: Unified framework and faster convergence"
      },
      {
        "key": "cen2023faster",
        "author": "Cen, Shicong and Chi, Yuejie and Du, Simon Shaolei and Xiao, Lin",
        "title": "Faster Last-iterate Convergence of Policy Optimization in Zero-Sum Markov Games"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "ayoub2020model",
        "author": "Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin",
        "title": "Model-based reinforcement learning with value-targeted regression"
      },
      {
        "key": "chen2022almost",
        "author": "Chen, Zixiang and Zhou, Dongruo and Gu, Quanquan",
        "title": "Almost optimal algorithms for two-player zero-sum linear mixture {M}arkov games"
      },
      {
        "key": "modi2020sample",
        "author": "Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder",
        "title": "Sample complexity of reinforcement learning using linearly combined model ensembles"
      },
      {
        "key": "jia2020model",
        "author": "Jia, Zeyu and Yang, Lin and Szepesvari, Csaba and Wang, Mengdi",
        "title": "Model-based reinforcement learning with value-targeted regression"
      },
      {
        "key": "chen2022almost",
        "author": "Chen, Zixiang and Zhou, Dongruo and Gu, Quanquan",
        "title": "Almost optimal algorithms for two-player zero-sum linear mixture {M}arkov games"
      },
      {
        "key": "liu2024maximize",
        "author": "Liu, Zhihan and Lu, Miao and Xiong, Wei and Zhong, Han and Hu, Hao and Zhang, Shenao and Zheng, Sirui and Yang, Zhuoran and Wang, Zhaoran",
        "title": "Maximize to explore: One objective function fusing estimation, planning, and exploration"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "jin2020provably",
        "author": "Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I",
        "title": "Provably efficient reinforcement learning with linear function approximation"
      },
      {
        "key": "wang2019optimism",
        "author": "Wang, Yining and Wang, Ruosong and Du, Simon S and Krishnamurthy, Akshay",
        "title": "Optimism in reinforcement learning with generalized linear function approximation"
      },
      {
        "key": "yang2019sample",
        "author": "Yang, Lin and Wang, Mengdi",
        "title": "Sample-optimal parametric q-learning using linearly additive features"
      },
      {
        "key": "xie2020learning",
        "author": "Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran",
        "title": "Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "chen2022almost",
        "author": "Chen, Zixiang and Zhou, Dongruo and Gu, Quanquan",
        "title": "Almost optimal algorithms for two-player zero-sum linear mixture {M}arkov games"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "ni2022representation",
        "author": "Ni, Chengzhuo and Song, Yuda and Zhang, Xuezhou and Jin, Chi and Wang, Mengdi",
        "title": "Representation learning for general-sum low-rank markov games"
      },
      {
        "key": "huang2022towards",
        "author": "Huang, Baihe and Lee, Jason D and Wang, Zhaoran and Yang, Zhuoran",
        "title": "Towards General Function Approximation in Zero-Sum {M}arkov Games"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "cui2023breaking",
        "author": "Cui, Qiwen and Zhang, Kaiqing and Du, Simon",
        "title": "Breaking the curse of multiagents in a large state space: Rl in markov games with independent linear function approximation"
      },
      {
        "key": "wang2023breaking",
        "author": "Wang, Yuanhao and Liu, Qinghua and Bai, Yu and Jin, Chi",
        "title": "Breaking the curse of multiagency: Provably efficient decentralized multi-agent rl with function approximation"
      },
      {
        "key": "dai2024refined",
        "author": "Dai, Yan and Cui, Qiwen and Du, Simon S",
        "title": "Refined sample complexity for markov games with independent linear function approximation"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "jin2018q",
        "author": "Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I",
        "title": "Is Q-learning provably efficient?"
      },
      {
        "key": "agarwal2023vo",
        "author": "Agarwal, Alekh and Jin, Yujia and Zhang, Tong",
        "title": "VO$Q$L: Towards Optimal Regret in Model-free {RL} with Nonlinear Function Approximation"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "gawlikowski2023survey",
        "author": "Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and others",
        "title": "A survey of uncertainty in deep neural networks"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "russo2018tutorial",
        "author": "Russo, Daniel J and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng and others",
        "title": "A tutorial on Thompson sampling"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "kumar1982new",
        "author": "Kumar, P and Becker, A",
        "title": "A new family of optimal adaptive controllers for Markov chains"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "liu2020exploration",
        "author": "Liu, Xi and Hsieh, Ping-Chun and Hung, Yu Heng and Bhattacharya, Anirban and Kumar, P",
        "title": "Exploration through reward biasing: Reward-biased maximum likelihood estimation for stochastic multi-armed bandits"
      },
      {
        "key": "hung2021reward",
        "author": "Hung, Yu-Heng and Hsieh, Ping-Chun and Liu, Xi and Kumar, PR",
        "title": "Reward-biased maximum likelihood estimation for linear stochastic bandits"
      },
      {
        "key": "cen2024value",
        "author": "Cen, Shicong and Mei, Jincheng and Goshvadi, Katayoon and Dai, Hanjun and Yang, Tong and Yang, Sherry and Schuurmans, Dale and Chi, Yuejie and Dai, Bo",
        "title": "Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "mete2021reward",
        "author": "Mete, Akshay and Singh, Rahul and Liu, Xi and Kumar, PR",
        "title": "Reward biased maximum likelihood estimation for reinforcement learning"
      },
      {
        "key": "liu2024maximize",
        "author": "Liu, Zhihan and Lu, Miao and Xiong, Wei and Zhong, Han and Hu, Hao and Zhang, Shenao and Zheng, Sirui and Yang, Zhuoran and Wang, Zhaoran",
        "title": "Maximize to explore: One objective function fusing estimation, planning, and exploration"
      }
    ]
  }
]