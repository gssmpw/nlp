@inproceedings{agarwal2023vo,
  title={VO$Q$L: Towards Optimal Regret in Model-free {RL} with Nonlinear Function Approximation},
  author={Agarwal, Alekh and Jin, Yujia and Zhang, Tong},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={987--1063},
  year={2023},
  organization={PMLR}
}

@inproceedings{ayoub2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  pages={463--474},
  year={2020},
  organization={PMLR}
}

@article{bai2021sample,
  title={Sample-efficient learning of stackelberg equilibria in general-sum games},
  author={Bai, Yu and Jin, Chi and Wang, Huan and Xiong, Caiming},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={25799--25811},
  year={2021}
}

@inproceedings{bouneffouf2016finite,
  title={Finite-time analysis of the multi-armed bandit problem with known trend},
  author={Bouneffouf, Djallel},
  booktitle={2016 IEEE Congress on Evolutionary Computation (CEC)},
  pages={2543--2549},
  year={2016},
  organization={IEEE}
}

@article{cen2021fast,
  title={Fast policy extragradient methods for competitive games with entropy regularization},
  author={Cen, Shicong and Wei, Yuting and Chi, Yuejie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27952--27964},
  year={2021}
}

@inproceedings{cen2023faster,
  title={Faster Last-iterate Convergence of Policy Optimization in Zero-Sum Markov Games},
  author={Cen, Shicong and Chi, Yuejie and Du, Simon Shaolei and Xiao, Lin},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{cen2024value,
  title={Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF},
  author={Cen, Shicong and Mei, Jincheng and Goshvadi, Katayoon and Dai, Hanjun and Yang, Tong and Yang, Sherry and Schuurmans, Dale and Chi, Yuejie and Dai, Bo},
  journal={arXiv preprint arXiv:2405.19320},
  year={2024}
}

@inproceedings{chen2022almost,
  title={Almost optimal algorithms for two-player zero-sum linear mixture {M}arkov games},
  author={Chen, Zixiang and Zhou, Dongruo and Gu, Quanquan},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={227--261},
  year={2022},
  organization={PMLR}
}

@inproceedings{cui2023breaking,
  title={Breaking the curse of multiagents in a large state space: Rl in markov games with independent linear function approximation},
  author={Cui, Qiwen and Zhang, Kaiqing and Du, Simon},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={2651--2652},
  year={2023},
  organization={PMLR}
}

@article{dai2024refined,
  title={Refined sample complexity for markov games with independent linear function approximation},
  author={Dai, Yan and Cui, Qiwen and Du, Simon S},
  journal={arXiv preprint arXiv:2402.07082},
  year={2024}
}

@article{daskalakis2018last,
  title={Last-iterate convergence: Zero-sum games and constrained min-max optimization},
  author={Daskalakis, Constantinos and Panageas, Ioannis},
  journal={arXiv preprint arXiv:1807.04252},
  year={2018}
}

@inproceedings{erez2023regret,
  title={Regret minimization and convergence to equilibria in general-sum {M}arkov games},
  author={Erez, Liad and Lancewicki, Tal and Sherman, Uri and Koren, Tomer and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={9343--9373},
  year={2023},
  organization={PMLR}
}

@article{gawlikowski2023survey,
  title={A survey of uncertainty in deep neural networks},
  author={Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and others},
  journal={Artificial Intelligence Review},
  volume={56},
  number={Suppl 1},
  pages={1513--1589},
  year={2023},
  publisher={Springer}
}

@inproceedings{huang2022towards,
  title={Towards General Function Approximation in Zero-Sum {M}arkov Games},
  author={Huang, Baihe and Lee, Jason D and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{hung2021reward,
  title={Reward-biased maximum likelihood estimation for linear stochastic bandits},
  author={Hung, Yu-Heng and Hsieh, Ping-Chun and Liu, Xi and Kumar, PR},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={9},
  pages={7874--7882},
  year={2021}
}

@inproceedings{jia2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Jia, Zeyu and Yang, Lin and Szepesvari, Csaba and Wang, Mengdi},
  booktitle={Learning for Dynamics and Control},
  pages={666--686},
  year={2020},
  organization={PMLR}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on learning theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@article{jin2021v,
  title={V-Learning--A Simple, Efficient, Decentralized Algorithm for Multiagent RL},
  author={Jin, Chi and Liu, Qinghua and Wang, Yuanhao and Yu, Tiancheng},
  journal={arXiv preprint arXiv:2110.14555},
  year={2021}
}

@article{kumar1982new,
  title={A new family of optimal adaptive controllers for Markov chains},
  author={Kumar, P and Becker, A},
  journal={IEEE Transactions on Automatic Control},
  volume={27},
  number={1},
  pages={137--146},
  year={1982},
  publisher={IEEE}
}

@article{lai1987adaptive,
  title={Adaptive treatment allocation and the multi-armed bandit problem},
  author={Lai, Tze Leung},
  journal={The annals of statistics},
  pages={1091--1114},
  year={1987},
  publisher={JSTOR}
}

@inproceedings{li2022minimax,
  title={Minimax-optimal multi-agent RL in Markov games with a generative model},
  author={Li, Gen and Chi, Yuejie and Wei, Yuting and Chen, Yuxin},
  booktitle={Proceedings of the 36th International Conference on Neural Information Processing Systems},
  pages={15353--15367},
  year={2022}
}

@incollection{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine learning proceedings 1994},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}

@inproceedings{liu2020exploration,
  title={Exploration through reward biasing: Reward-biased maximum likelihood estimation for stochastic multi-armed bandits},
  author={Liu, Xi and Hsieh, Ping-Chun and Hung, Yu Heng and Bhattacharya, Anirban and Kumar, P},
  booktitle={International Conference on Machine Learning},
  pages={6248--6258},
  year={2020},
  organization={PMLR}
}

@inproceedings{liu2021sharp,
  title={A sharp analysis of model-based reinforcement learning with self-play},
  author={Liu, Qinghua and Yu, Tiancheng and Bai, Yu and Jin, Chi},
  booktitle={International Conference on Machine Learning},
  pages={7001--7010},
  year={2021},
  organization={PMLR}
}

@article{liu2024maximize,
  title={Maximize to explore: One objective function fusing estimation, planning, and exploration},
  author={Liu, Zhihan and Lu, Miao and Xiong, Wei and Zhong, Han and Hu, Hao and Zhang, Shenao and Zheng, Sirui and Yang, Zhuoran and Wang, Zhaoran},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{mao2023provably,
  title={Provably efficient reinforcement learning in decentralized general-sum {M}arkov games},
  author={Mao, Weichao and Ba{\c{s}}ar, Tamer},
  journal={Dynamic Games and Applications},
  volume={13},
  number={1},
  pages={165--186},
  year={2023},
  publisher={Springer}
}

@inproceedings{mertikopoulos2018cycles,
  title={Cycles in adversarial regularized learning},
  author={Mertikopoulos, Panayotis and Papadimitriou, Christos and Piliouras, Georgios},
  booktitle={Proceedings of the twenty-ninth annual ACM-SIAM symposium on discrete algorithms},
  pages={2703--2717},
  year={2018},
  organization={SIAM}
}

@inproceedings{mete2021reward,
  title={Reward biased maximum likelihood estimation for reinforcement learning},
  author={Mete, Akshay and Singh, Rahul and Liu, Xi and Kumar, PR},
  booktitle={Learning for Dynamics and Control},
  pages={815--827},
  year={2021},
  organization={PMLR}
}

@inproceedings{modi2020sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2010--2020},
  year={2020},
  organization={PMLR}
}

@article{ni2022representation,
  title={Representation learning for general-sum low-rank markov games},
  author={Ni, Chengzhuo and Song, Yuda and Zhang, Xuezhou and Jin, Chi and Wang, Mengdi},
  journal={arXiv preprint arXiv:2210.16976},
  year={2022}
}

@inproceedings{o2021matrix,
  title={Matrix games with bandit feedback},
  author={Oâ€™Donoghue, Brendan and Lattimore, Tor and Osband, Ian},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={279--289},
  year={2021},
  organization={PMLR}
}

@article{o2021variational,
  title={Variational bayesian reinforcement learning with regret bounds},
  author={O'Donoghue, Brendan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={28208--28221},
  year={2021}
}

@article{russo2018tutorial,
  title={A tutorial on Thompson sampling},
  author={Russo, Daniel J and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={1},
  pages={1--96},
  year={2018},
  publisher={Now Publishers, Inc.}
}

@inproceedings{sessa2022efficient,
  title={Efficient model-based multi-agent reinforcement learning via optimistic equilibrium computation},
  author={Sessa, Pier Giuseppe and Kamgarpour, Maryam and Krause, Andreas},
  booktitle={International Conference on Machine Learning},
  pages={19580--19597},
  year={2022},
  organization={PMLR}
}

@article{shapley1953stochastic,
  title={Stochastic games},
  author={Shapley, Lloyd S},
  journal={Proceedings of the National Academy of Sciences},
  volume={39},
  number={10},
  pages={1095--1100},
  year={1953},
  publisher={National Acad Sciences}
}

@article{song2021can,
  title={When can we learn general-sum Markov games with a large number of players sample-efficiently?},
  author={Song, Ziang and Mei, Song and Bai, Yu},
  journal={arXiv preprint arXiv:2110.04184},
  year={2021}
}

@article{wang2019optimism,
  title={Optimism in reinforcement learning with generalized linear function approximation},
  author={Wang, Yining and Wang, Ruosong and Du, Simon S and Krishnamurthy, Akshay},
  journal={arXiv preprint arXiv:1912.04136},
  year={2019}
}

@inproceedings{wang2023breaking,
  title={Breaking the curse of multiagency: Provably efficient decentralized multi-agent rl with function approximation},
  author={Wang, Yuanhao and Liu, Qinghua and Bai, Yu and Jin, Chi},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={2793--2848},
  year={2023},
  organization={PMLR}
}

@article{wei2020linear,
  title={Linear last-iterate convergence in constrained saddle-point optimization},
  author={Wei, Chen-Yu and Lee, Chung-Wei and Zhang, Mengxiao and Luo, Haipeng},
  journal={arXiv preprint arXiv:2006.09517},
  year={2020}
}

@inproceedings{xie2020learning,
  title={Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium},
  author={Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={Conference on learning theory},
  pages={3674--3682},
  year={2020},
  organization={PMLR}
}

@inproceedings{yang2019sample,
  title={Sample-optimal parametric q-learning using linearly additive features},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International conference on machine learning},
  pages={6995--7004},
  year={2019},
  organization={PMLR}
}

@article{zhan2023policy,
  title={Policy mirror descent for regularized reinforcement learning: A generalized framework with linear convergence},
  author={Zhan, Wenhao and Cen, Shicong and Huang, Baihe and Chen, Yuxin and Lee, Jason D and Chi, Yuejie},
  journal={SIAM Journal on Optimization},
  volume={33},
  number={2},
  pages={1061--1091},
  year={2023},
  publisher={SIAM}
}

@article{zhang2022policy,
  title={Policy optimization for {M}arkov games: Unified framework and faster convergence},
  author={Zhang, Runyu and Liu, Qinghua and Wang, Huan and Xiong, Caiming and Li, Na and Bai, Yu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21886--21899},
  year={2022}
}

