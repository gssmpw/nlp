\section{Related Work}
Automated theorem proving has gained prominence in artificial intelligence____, yet its application remains largely restricted to relatively simple mathematical problems and struggles with proving more complex statements. Data scarcity and its uneven distribution across different mathematical domains is a key challenge.


Among the largest publicly available datasets in AI4Maths, Numina____ contains 860K competition-level math problems with solutions following the Chain of Thought (CoT)____ reasoning paradigm. In contrast, Mathlib____, the community-maintained Lean formal mathematics dataset, provides a rigorously structured repository spanning algebra, number theory, and combinatorics. However, both datasets rely heavily on manual formalization, leading to limited coverage and uneven representation across specialized mathematical fields.

To address the limitations of data scarcity, researchers have explored automated theorem generation____. In recent years, theorem generation  techniques based on neural networks and LLMs have emerged as a promising direction, opening up new possibilities for both theorem generation and automated proving ____.
Existing approaches leverage various strategies for theorem generation: INT____ integrates inequalities to construct new theorems, Leandojo____ retrieves and synthesizes formal statements from Mathlib, and MetaGen____ transplants proof trees while employing reinforcement learning to align theorem generation with human reasoning. Meanwhile, another class of generators relies on LLMs to assist in theorem generation. Specifically, these models are often employed as premise selectors to identify key reasoning steps or to iteratively sample from existing theorems, generating new ones that adhere to specific rules____. Furthermore, the PACT method____ extracts data from theorems and generates nine distinct language modeling tasks, enabling data augmentation within the Lean theorem prover.  
 

However, most existing theorem generators expand datasets by extracting sub-theorems from complete theorems or synthesizing new ones. Against this backdrop, we combine
LLMs’ broad knowledge coverage with RL’s exploration-driven capabilities to conduct tactic prediction research based on our manually constructed benchmark, \textit{LeanComb}.
Our goal is to generate high-quality, novel theorems that contribute to developing data resources in specialized mathematical fields while advancing the capabilities of automated theorem-proving systems.