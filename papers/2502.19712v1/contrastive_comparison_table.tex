\begin{table}[t]
    \centering
    \adjustbox{max width=\columnwidth}{
    \begin{tabular}{l|cccc|cc|cc}
        \toprule
         & \multicolumn{4}{c}{MSMARCO} & \multicolumn{2}{c}{SciFact} & \multicolumn{2}{c}{FiQA} \\
        \cmidrule(lr){2-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9}
         & \multicolumn{2}{c}{DL19} & \multicolumn{2}{c}{DL20} &  &  &  &  \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5}
         & NDCG & Recall & NDCG & Recall & NDCG & Recall & NDCG & Recall \\
        \midrule
        BGE & 70.2 & 60.9 & 67.7 & 71.5$\dagger$ & 74.1 & 96.7 & 40.6$\dagger$ & 74.2 \\
        + FT with contrastive loss & 68.6 & 61.0 & 66.8 & 70.8 & 72.1 & 96.0 & 39.5 & 70.7 \\
        + FT with listwise loss & \textbf{71.8} & \textbf{63.6} & \textbf{69.7} & 75.1 & \textbf{76.3} & \textbf{97.0} & \textbf{44.8} & \textbf{75.9}  \\
        + FT with combined loss & \textbf{71.8} & 63.0 & \textbf{69.7} & \textbf{75.5} & 76.2 & \textbf{97.0} & 44.3 & 75.8  \\
        \midrule
        GTE & \textbf{71.9} & 62.1$\dagger$ & 71.5 & 69.8$\dagger$ & 75.5 & 97.3 & 48.7 & \textbf{81.7} \\
        + FT with contrastive loss & 71.5 & 62.6 & 67.8 & 69.8 & 71.2 & 95.5 & 45.1 & 77.1 \\
        + FT with listwise loss & \textbf{72.3} & 64.7 & \textbf{72.6} & \textbf{73.8} & 75.4 & \textbf{97.7} & 48.5 & 80.2 \\
        + FT with combined loss & 71.8 & \textbf{65.6} & \textbf{72.6} & 73.3 & \textbf{76.3} & \textbf{97.7} & \textbf{49.5} & 81.4 \\
        \midrule
        Arctic & \textbf{74.4} & 64.7 & 72.1 & 74.2 & 70.5$\dagger$ & 94.8 & 42.5$\dagger$ & 74.8 \\
        + FT with contrastive loss & 72.2 & 64.3 & 71.9 & 73.1 & 69.1 & 94.9 & 41.8 & 73.0 \\
        + FT with listwise loss & \textbf{74.4} & \textbf{67.4} & \textbf{73.6} & 75.0 & 73.2 & \textbf{96.0} & 45.2 & \textbf{75.9} \\
        + FT with combined loss & 74.3 & 67.2 & \textbf{73.6} & \textbf{75.4} & \textbf{73.6} & 95.7 & \textbf{45.5} & \textbf{75.9} \\
        \midrule
        E5-unsupervised & 56.3$\dagger$ & 52.6$\dagger$ & 54.6$\dagger$ & 62.1$\dagger$ & 74.3 & \textbf{98.7} & 40.1$\dagger$ & 71.8$\dagger$ \\
        + FT with contrastive loss & 67.9 & 61.7 & 68.2 & 71.7 & 72.3 & 95.0 & 40.5 & 73.8 \\
        + FT with listwise loss & 69.9 & \textbf{63.7} & 72.7 & 74.3 & 76.2 & 96.7 & 44.0 & 75.5 \\
        + FT with combined loss & \textbf{72.4} & 63.3 & \textbf{73.2} & \textbf{75.2} & \textbf{76.3} & 97.0 & \textbf{45.4} & \textbf{77.0} \\
        \bottomrule
    \end{tabular}
    }
    \caption{NDCG@10 and Recall@100 for the original and fine-tuned (FT) models, examining the effect of the training loss. A $\dagger$ indicates a significant difference between the original and FT model with the combined loss, based on a one-sided, paired t-test $(p < 0.05)$, with Holm--Bonferroni correction across all datasets and metrics for each model's results. Best scores for each model are bolded.}
    \label{tab:loss_results}
\end{table}
