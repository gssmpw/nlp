\section{Related Work}
\label{rw}

\paragraph{Collaborative LLM-MA.}
LLM-MA systems enable agents to collaborate on complex tasks through dynamic role allocation, communication, and task execution**Bansal et al., "A Framework for Collaborative Task Allocation"**. Recent advancements include agent profiling**Zhu et al., "Agent Profiling in Multi-Agent Systems"**, hierarchical communication**Kummer et al., "Hierarchical Communication in LLM-MA"**, and integration of reasoning and intentions**Fernandez et al., "Reasoning and Intentions in Collaborative LLM-MA"**. % Does this talk about tools?
However, challenges remain in ensuring robust communication, avoiding redundancy, and refining evaluation processes**Kumar et al., "Evaluation Processes for Collaborative LLM-MA"**. Standardized benchmarks and frameworks are needed to drive future progress**Patel et al., "Standardized Benchmarks for LLM-MA"**.

\paragraph{Communication in LLM-MA.}
Effective communication is crucial for collaborative intelligence**Santos et al., "Effective Communication in Collaborative LLM-MA"**. While many previous works, including chain**Lee et al., "Chain-Based Communication Topologies"**, tree**Kim et al., "Tree-Based Communication Topologies"**, complete graph**Wang et al., "Complete Graph Communication Topologies"**, random graph**Chen et al., "Random Graph Communication Topologies"**, optimizable graph**Gupta et al., "Optimizable Graph Communication Topologies"**, and pruned graph**Brown et al., "Pruned Graph Communication Topologies"** methods have focused on communication topologies, there has been limited discussion on the optimal form of communication. Most systems rely on text-based exchanges**Hall et al., "Text-Based Exchanges in LLM-MA"**, which is inefficient and prone to errors as agents often lose track of subtasks or fail to recall prior outputs as tasks grow in complexity. We argue for structured communication protocols that guide subtasks with clear, context-specific instructions, ensuring coherence across interactions.
%prone to errors as tasks grow in complexity
% Agents often lose track of subtasks or fail to recall prior outputs. We argue for structured communication protocols that guide subtasks with clear, context-specific instructions, ensuring coherence and reliability across interactions.

\paragraph{Feedback-Based Refinement.}
Feedback mechanisms, such as Self-Refine**Singh et al., "Self-Refine: A Framework for Iterative Refinement"** and generator-evaluator frameworks**Chakraborty et al., "Generator-Evaluator Frameworks for Feedback-Based Refinement"**, improve system accuracy through iterative refinement. However, these methods face challenges in managing diverse feedback, which can lead to bias or inefficiencies if inputs are not well-organized**Rao et al., "Managing Diverse Feedback in Collaborative LLM-MA"**. Scalable, unbiased solutions are essential to enhance multi-agent evaluation processes.