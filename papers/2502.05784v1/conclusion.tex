\section*{Conclusion and Discussion}
We established an improved PoC for MFLD that accelerates optimization speed in \citet{nitanda2024improved,chewi2024uniform} while achieving the same particle complexity $O(1/N)$. We then translated this result into model approximation error bounds, and derived a PoC-based model ensemble method with an empirical verification. Moreover, we substantiated its applicability to fine-tuning language models using LoRA.

One limitation of our theory is that it cannot explain the asymptotic behavior as $\lambda \to 0$. This is also the case in previous work since the optimization speed essentially slows down exponentially, which is inevitable in general as discussed in the literature. However, there might be room to tighten the particle approximation term $\frac{B}{\lambda N}$ with respect to $\lambda$ in the model approximation bounds. This term arises from the KL-divergence, which essentially controls the correlation among particles, as seen in the proof of Proposition \ref{prop:pw_model_approximation}. However, KL-divergence may be excessive for this purpose. Therefore, one interesting future direction is to utilize a PoC with respect to a smaller metric that alleviates the dependence on $\lambda$.