\section{Experiments} \label{sec:experiments}
We verify the validity of our theoretical results, by conducting numerical experiments on synthetic data in both classification and regression settings using mean-field neural networks. Finally, we further substantiate the applicability of our method on LoRA training of language models. 

\begin{table*}[th]
    \centering
    \caption{Accuracy comparison of LoRA and PoC-based merging for finetuning Llama models.}
    \label{table:LoRA_comparison}
    \begin{footnotesize}
    \begin{tabular}{ccccccccccc}
        \toprule
        \textbf{Model} & \textbf{Method} & \textbf{SIQA} & \textbf{PIQA} & \textbf{WinoGrande} & \textbf{OBQA} & \textbf{ARC-c} & \textbf{ARC-e} & \textbf{BoolQ} & \textbf{HellaSwag} & \textbf{Ave.} \\
        \midrule
        \multirow{2}{*}{\begin{tabular}{c}Llama2\\7B\end{tabular}} 
            & LoRA (best) & $79.48$ & $82.43$ & $81.77$ & $80.60$ & $67.75$ & $80.47$ & $70.37$ & $86.67$ & $78.69$ \\
            & \textbf{PoC merge}     & $81.17$ & $84.60$ & $85.16$ & $86.60$ & $72.53$ & $86.62$ & $72.45$ & $92.79$ & $82.74$ \\
        \midrule
        \multirow{2}{*}{\begin{tabular}{c}Llama3\\8B\end{tabular}}
            & LoRA (best) & $81.22$ & $89.50$ & $86.74$ & $86.00$ & $79.86$ & $90.53$ & $72.91$ & $95.34$ & $85.26$ \\
            & \textbf{PoC merge}    & $82.04$ & $89.39$ & $89.27$ & $89.20$ & $83.28$ & $92.30$ & $76.33$ & $96.58$ & $87.30$ \\
        \bottomrule
    \end{tabular}
    \end{footnotesize}
\end{table*}

\subsection{Mean-field neural networks}
 To demonstrate Theorem \ref{theorem:uniform_approximation_multiple_mfld}, we compute the log sup norm between the ouptuts of an (approximately) infinite width network and a merged network, both trained using noisy gradient descent. A finite-width approximation of the mean-field neural network is employed with $N=N_\infty$ while the merged network is obtained by merging $M$ different networks of $N$ neurons each. This is repeated across various values of $N$ and $M$.  See Appendix \ref{subsec:pseudocode} for more details about our methodology. 

\paragraph{Classification setting} We consider the binary classification of $n$ data points generated along the perimeters of two concentric circles with radius $r_\text{inner}$ and $r_\text{outer}$, where labels are assigned according to the circle a data point belongs to. 

\paragraph{Regression setting} We consider regression on the $k$ multi-index problem. Each input sample $z_i = \left(z_i^1, \dots, z_i^d \right)\in \bR^d$ is generated uniformly within a $d$-dimensional hypersphere of radius $r$. Let $g: \bR^d \rightarrow \bR$ be a link function, then $y_i = g(z_i) = \frac{1}{k}\sum^k_{j=1} \tanh (z_i^j) \in \bR$, where $k \leq d, k \in \bR$.

\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{experiment_results.png}}
\caption{Heat maps of sup norm (in log-scale) between $N_\infty$ and merged networks when varying $M$ and $N$.}  %\AN{Move this sentence "We see ..." to the main text. The caption just describes what this graph represents and how to see it if necessary.}
\label{fig:experiments_regression}
\end{center}
\vskip -0.2in
\end{figure}

From Figure \ref{fig:experiments_regression}, we see that the merged networks converge towards the mean-field limit as $M$ and $N$ increase. This aligns with our theoretical findings which suggests that the sup norm of the approximation error decreases when more particles are added (ensembling in our experimental set-up) or increasing the ensemble size. See Appendix \ref{subsec:additional_experiments} for supplementary experiments.

\subsection{LoRA for finetuning language models}
Beyond the scope of the theory, we empirically verify the applicability of our ensemble technique to finetuning language models using LoRA. Given a pre-trained parameter $W_0 \in \bR^{k\times d}$ of a linear layer, LoRA introduces low-rank matrices $\vA \in \bR^{N\times d}$ and $\vB \in \bR^{k\times N}$, and represents the fine-tuned parameter as $W_0 + \gamma \Delta W = W_0 + \gamma \vB\vA~(\gamma > 0)$. Then, only $\vA$ and $\vB$ are optimized, leaving $W_0$ frozen. Using the expression $\vA^\top = (a^1,\ldots,a^N)~(a^i \in \bR^d)$ and $\vB=(b^1,\ldots,b^N)~(b^i \in \bR^k)$, we can reformalize LoRA parameter $\gamma\vB\vA$ with $\gamma=1/N$ as the MFNN: $\bR^d \ni z \to \frac{1}{N}\sum_{i=1}^N h((a^i,b^i),z) \in \bR^k$ where $h((a^i,b^i),z) = b^ia^{i\top} z$. Therefore, we can apply PoC-based model ensemble for LoRA parameters. Note that the ensemble model is reduced to a single $(k\times d)$-matrix $\Delta W$ due to the linearity of the activation function, and therefore it does not require additional memory and time for inference. 

We use commonsense reasoning datasets \cite{hu2023llm}: SIQA, PIQA, WinoGrande, OBQA, ARC-c, ARC-e, BoolQ, and HellaSwag, and use language models: Llama2-7B \cite{touvron2023llama} and Llama3-8B \cite{dubey2024llama}. We first optimize the multiple LoRA parameters $\{(\vA_j,\vB_j)\}_{j=1}^M$ using noisy AdamW where $\sqrt{2 \lambda \eta_k} \xi_k~(\textrm{step-size}~\eta_k,~\textrm{standard Gaussian noise}~\xi_k)$ is added to each parameter update of AdamW \cite{loshchilovdecoupled}. Then, we merge them into $\Delta W = \frac{1}{MN}\sum_{i,j}b^i_j a^{i\top}_j\in \bR^{k\times d}$. Hyperparameters are set to $N=32, M=8, \lambda=10^{-5}$ and the number of epochs is $3$. In Table \ref{table:LoRA_comparison}, we compare the accuracy of the merged parameter with the base parmeters of LoRA. For LoRA, the table presents the best result achieved among eight different LoRA parameters based on the average accuracy across all datasets. For both models, we observed that PoC-based model merging significantly improves the finetuning performance. We also verify the performance using one-epoch training to examine the effect of Gaussian noise in parameter updates. See Appendix \ref{subsec:experiments_extra_lora} for more details.
