\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}

\usepackage[table]{xcolor} % 引入xcolor宏包，并开启table选项
\usepackage[most]{tcolorbox}
\usepackage{booktabs} % for professional tables
\usepackage{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage[accepted]{icml2025}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{xspace}
\usepackage{bm}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{algorithmic}
\input{math_commands.tex}
\usepackage[capitalize,noabbrev]{cleveref}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \theoremstyle{plain}
% % \newtheorem{theorem}{Theorem}[section]
% \newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
% \theoremstyle{definition}
% \newtheorem{definition}[theorem]{Definition}
% \newtheorem{assumption}[theorem]{Assumption}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \usepackage{mdframed}
% \usepackage[subfigure]{tocloft}
\theoremstyle{plain}
\definecolor{theoremcolor}{rgb}{0.94, 0.94, 0.94}
\definecolor{examplecolor}{rgb}{1, 1, 1.0}
%\mdfsetup{backgroundcolor=theoremcolor, linewidth=0pt}
%\newmdtheoremenv[linewidth=0pt,innerleftmargin=1pt,innerrightmargin=1pt]{proposition}{Proposition}
%\newmdtheoremenv[linewidth=0pt,innerleftmargin=0pt,innerrightmargin=0pt,backgroundcolor=examplecolor]{example}{Example}
%\newmdtheoremenv{corollary}{Corollary}
%\newmdtheoremenv[linewidth=0pt,innerleftmargin=1pt,innerrightmargin=1pt]{theorem}{Theorem}
%\newmdtheoremenv[linewidth=0pt,innerleftmargin=1pt,innerrightmargin=1pt]{lemma}{Lemma}
%\theoremstyle{definition}
%\newmdtheoremenv[linewidth=0pt,innerleftmargin=1pt,innerrightmargin=1pt]{definition}{Definition}
%\newmdtheoremenv[linewidth=0pt,innerleftmargin=1pt,innerrightmargin=1pt]{assumption}{Assumption}
%\theoremstyle{remark}
%\newtheorem{remark}[theorem]{Remark}

\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{assumption}{Assumption}
\newtheorem{lemma}{Lemma}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
% \usepackage[textsize=tiny]{todonotes}
% \usepackage[toc,page,header]{appendix}
% \usepackage{minitoc}
% \setlength{\cftbeforesecskip}{10pt}
% \renewcommand{\contentsname}{Table of Contents}
% \newcommand\blfootnote[1]{%
%   \begingroup
%   \renewcommand\thefootnote{}\footnote{#1}%
%   \addtocounter{footnote}{-1}%
%   \endgroup
% }

% \usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

\usepackage{colortbl}
\usepackage[most]{tcolorbox}
\input{notions}
\usepackage{multirow}
\newtcolorbox[auto counter, number freestyle={\noexpand\arabic{\tcbcounter}}]{promptbox}[2][]{%
    enhanced,
    % breakable, % Fix bug for the unexpected break
    colback=blue!5!white,
    colframe=black!75!white,
    title=Prompt~\thetcbcounter: #2,
    #1
}

\icmltitlerunning{Bridging Internal Probability and Self-Consistency for Effective and Efficient LLM Reasoning}

\begin{document}
\twocolumn[

\icmltitle{Bridging Internal Probability and Self-Consistency for \\ Effective and Efficient LLM Reasoning}

% \icmlsetsymbol{equal}{*}
\begin{icmlauthorlist}
\icmlauthor{Zhi Zhou}{njucs}
\icmlauthor{Yuhao Tan}{njucs}
\icmlauthor{Zenan Li}{njucs}
\icmlauthor{Yuan Yao}{njucs}
\icmlauthor{Lan-Zhe Guo}{njucs,njusz}
\icmlauthor{Xiaoxing Ma}{njucs}
\icmlauthor{Yu-Feng Li}{njucs,njuai}
\end{icmlauthorlist}
\icmlaffiliation{njucs}{National Key Laboratory for Novel Software Technology, Nanjing University}
\icmlaffiliation{njuai}{School of Artificial Intelligence, Nanjing University}
\icmlaffiliation{njusz}{School of Intelligence Science and Technology, Nanjing University}
\icmlcorrespondingauthor{Xiaoxing Ma}{xxm@nju.edu.cn}
\icmlcorrespondingauthor{Yu-Feng Li}{liyf@nju.edu.cn}

\icmlkeywords{Large Language Model, Self Consistency, Math Reasoning, Code Generation}
\vskip 0.3in
]
\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
    Recent advancements in large language models (LLMs) have demonstrated remarkable reasoning capabilities. However, single-shot inference often yields unreliable results for complex reasoning tasks, leading researchers to explore multiple reasoning paths through methods such as perplexity and self-consistency.
    In this paper, we present the first theoretical error decomposition analysis of these techniques, breaking down their error into estimation error and model error. Our analysis reveals a fundamental trade-off: perplexity methods suffer from substantial model error due to the absence of a proper consistency function, while self-consistency exhibits high estimation error due to a slow error convergence rate. 
    To overcome these limitations, we propose \emph{\textbf{R}easoning-Pruning \textbf{P}erplexity \textbf{C}onsistency} (\RPC). This approach combines \emph{Perplexity Consistency}, which seamlessly integrates LLM perplexity with self-consistency, and \emph{Reasoning Pruning}, which eliminates low-probability reasoning paths to effectively prevent the degeneration of estimation error reduction.
    Theoretical analysis demonstrates that \RPC not only accelerates the convergence rate of estimation error to an exponential level but also holds strong potential for further reducing model error. 
    Extensive empirical evaluations on seven benchmark datasets confirm that \RPC can significantly improve reasoning performance, sample efficiency, and confidence reliability.
\end{abstract}

\input{sections/introduction}

\input{sections/030_formulation}

\input{sections/040_method.tex}

\input{sections/050_experiments.tex}

\input{sections/relatedwork.tex}

\input{sections/060_conclusion.tex}

\section*{Impact Statement}
This work advances the efficiency and effectiveness of LLM reasoning with multiple reasoning paths.  
Our method can benefit various applications requiring reliable artificial intelligence reasoning, such as mathematical problem-solving and code generation. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.

\bibliography{ref}
\bibliographystyle{icml2025}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\section{Theoretical Results}

\input{sections/073_appendix_error.tex}
\input{sections/070_appendix.tex}
\input{sections/072_appendix_methods.tex}
\input{sections/074_appendix_settings.tex}
\input{sections/071_appendix_experiments.tex}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
