\begin{figure*}[t]
    \begin{center}
        \includegraphics[width=0.9\linewidth]{figures/Framework.pdf}
        \caption{Illustration of the \RPC approach. The \emph{Reasoning Pruning} filters out low-probability answers, while the \emph{Perplexity Consistency} incorporates LLM probabilities into the self-consistency framework, resulting in faster convergence of estimation error.}
        \label{fig:framework}
    \end{center}
    \vskip -0.2in
\end{figure*}

\section{Methodology}
\label{sec:method}

Based on our theoretical and empirical analysis, we propose a new method called \emph{Reasoning-Pruning Perplexity Consistency} (\RPC). 
Specifically, we first integrate internal LLM probability into the self-consistency framework, paving the way for a confidence estimation function called \emph{Perplexity Consistency} (\PC). 
This function utilizes LLM probabilities to reduce estimation error more efficiently while maintaining a low model error.
Our further analysis guides the design of a new \emph{Reasoning Pruning} (\RP) module that addresses the limitations of \PC by filtering out reasoning paths with low probabilities.
\autoref{fig:framework} shows the overall framework.

\subsection{Perplexity Consistency}

To improve the efficiency of estimation error reduction, we propose \PC, which directly leverages the LLM's prediction probability like \PP, obtaining the benefit of an exponential convergent rate; 
and also applies the consistency function of \SC, to minimize the model error.
Formally, for the unique set of $n$ sampled reasoning paths $\mathcal{R} = \{\tilde{t}_1, \dots, \tilde{t}_n\}$, the estimated probability of the answer is
\begin{equation*}
\begin{aligned}
\hat{p}^{(\PC)}(\hat{y} \,|\, x) = \sum_{\tilde{t} \in \mathcal{R}} \I[g(\tilde{t}) = \hat{y}] p(\tilde{t} \,|\, x),
\end{aligned}
\end{equation*}
which calculates the cumulative probability of all unique reasoning paths whose answer is $\hat{y}$.
Therefore, the mean squared error of \PC is
\begin{equation*}
    \begin{aligned}
      \mathcal{E}(\hat{p}^{(\PC)}) = \E_{\tilde{t}_i \sim p(t \,|\, x)} \big[( \hat{p}^{(\PC)}(\hat{y} \,|\, x) - \I[\hat{y} = y] )^2 \big]. 
\end{aligned}
\end{equation*}
        
Now, we present the following theorem, which explores the reasoning error decomposition of \PC.

\begin{theorem}[\PC Reasoning Error Decomposition] \label{thm:thm1}
Assume that $k = |\{\tilde{t} \mid g(\tilde{t}) = \hat{y}\}|$ and define $\alpha := 1 - \frac{1}{k} p(\hat{y} \,|\, x)$. 
Then, the reasoning error $\mathcal{E}(\hat{p}^{(\PC)})$ of \PC can be divided into two components:
\begin{equation*}
    \begin{aligned}
      \mathcal{E}(\hat{p}^{(\PC)}) 
      = & \underbrace{ \alpha^n p(\hat{y} \,|\, x) \big(2\I[\hat{y}=y] - (1 + \alpha^n) p(\hat{y} \,|\, x) \big) }_{\text{Estimation Error}} \\
        & \qquad + \underbrace{\left( p(\hat{y} \,|\, x) - \I[\hat{y}_i = y] \right )^2}_{\text{Model Error}}. \\
    \end{aligned}
\end{equation*}
\end{theorem}
\begin{remark} 
The proof is presented in Appendix~\ref{app:thm1}. 
The theorem states that \PC successfully fuses the strengths of \PP and \SC: it achieves the same level of model error as \SC while ensuring the same convergence rate as \PP in the estimation error.
Particularly, the convergence rate can be computed as $\alpha^n p(\hat{y}\,|\, x) = (1 - \frac{1}{k} p(\hat{y} \,|\, x))^{n}p(\hat{y}\,|\, x)$. 
\end{remark}

The convergence rate is primarily influenced by the magnitude of $p(\hat{y} \,|\, x)$. In most scenarios, it remains exponential, facilitating rapid estimation error reduction.
However, when $p(\hat{y} \,|\, x) \to 0$ and $np(\hat{y} \,|\, x) \ll 1$, we only have $\alpha^n \to \frac{1}{1 + n p(\hat{y} \,|\, x)}$~\citep{kozma2021useful}, resulting in the convergence rate unexpectedly degenerating to a linear result.

\subsection{Reasoning Pruning}

Our analysis of the convergence rate in estimation error suggests some possibility for further improving the estimation error reduction efficiency.
Specifically, the rate degenerates when $p(\hat{y} \,|\, x)$ is too small.
Therefore, we propose directly pruning these low-probability answers instead of sampling, called by \emph{Reasoning Pruning} (\RP).

Reasoning pruning essentially aims to set $\hat{p}(\hat{y} \,|\, x) = 0$, i.e., when the cumulative probability of all its corresponding reasoning paths are very low, 
making the estimation error vanish. 
Although pruning low-probability answers can boost the efficiency of estimation error reduction, it also induces a level of model error. 
In other words, it may ignore some correct answers of low probability, thus implicitly degrading the performance of LLM reasoning.  

Ideally, if we know the probability $p(y \,|\, x)$ that the LLM can generate the correct answer, the optimal threshold for pruning should be $\tau = p(y \,|\, x)$. In this case, one can obtain not only an exponential convergence rate but also a significant reduction in model error, as all incorrect answers $\hat{y}$ satisfying $p(\hat{y} \,|\, x) < \tau$ are eliminated. However, to obtain this optimal error reduction, two challenges need to be resolved: (1) we only have an estimate of $p(\hat{y} \,|\, x)$ since the accurate value is unknown; and (2) we cannot know the ground-truth probability $p(y \,|\, x)$, making the threshold difficult to determine. 

For the first problem, we propose directly pruning reasoning paths instead of answers in \RP, with the following theorem. 
\begin{theorem} [Effectiveness of Reasoning Path Pruning]\label{thm:thm2}
Assume that the optimal threshold $\tau = p(y \,|\, x)$, and let $\hat{k} = |\{\tilde{t}_i \mid g(\tilde{t}_i) = \hat{y}, i=1,\dots,n\}|$, which refers to the size of samples whose answer is $\hat{y}$. 
Hence, \RP achieves the optimal error reduction with at least the probability 
\begin{equation*}
1 - \exp\Big(-{2\hat{k}k^2} (1 - \frac{\tau}{1 - \alpha})^2\Big).
\end{equation*}
\end{theorem}
\begin{remark}
The proof is included in Appendix~\ref{app:thm2}. 
The theorem provides a guarantee that \RP can achieve the optimal error reduction for each given problem $(x, y)$ at a high probability. 
Note that the optimal error reduction not only boosts the estimation error reduction efficiency but also effectively reduces the model error, thus improving the final reasoning capability of LLMs.
\end{remark}

The remaining problem is determining the optimal threshold for reasoning path removal. 
To achieve this goal, we develop an automated strategy. 
Inspired by open-set recognition~\citep{Bendale16openmax}, we model the probability distribution of $\Omega_1$ and $\Omega_2$ as a mixture of two Weibull distributions, representing high and low probability regions.

Elaborately, we define the PDF of mixture distribution as: 
\begin{equation*} \label{eq:weibull-mix}
    f(x) = w_1 f_{\text{W}}(x; k_1, \lambda_1) + w_2 f_{\text{W}}(x; k_2, \lambda_2), 
\end{equation*}
where the Weibull PDF~\citep{weibull1951statistical} is defined as $f_{\text{W}}(x; k, \lambda) = \frac{k}{\lambda}\left ( \frac{x}{\lambda}\right ) ^{k-1} \exp{\left ( -(\frac{x}{\lambda})^k\right )}$.
We use the maximum likelihood estimation methods to estimate the parameters, i.e., $(k_1, \lambda_1)$, $(k_2, \lambda_2)$, $w_1$, and $w_2$ on the probability distribution of all sampled reasoning paths for each reasoning problem. 
We assume that $\text{Weibull}(k_1, \lambda_1)$ is the high probability distribution and $\text{Weibull}(k_2, \lambda_2)$ is the low probability distribution. Then, the probability of reasoning path $\hat{t}$ being in the high probability distribution is derived by 
\begin{equation*}
    P_{\text{High}}(x) = \frac{w_1 f_{\text{W}}(x; k_1, \lambda_1)}{w_1 f_{\text{W}}(x; k_1, \lambda_1) + w_2 f_{\text{W}}(x; k_2, \lambda_2)}. 
    \label{eq:weibull-prob}
\end{equation*}
where $x$ is the value of LLM internal probability. 

Then, we remove sampled reasoning paths $\tilde{t}$ satisfying $P_{\text{High}}(\hat{p}(\tilde{t}\,|\,x)) < 0.5$, which more likely to be in the low probability distribution. Moreover, to ensure the algorithm's stability when $n$ is limited, we employ the Truncated Mean method~\citep{marazzi1999truncated}, retaining outputs with a probability greater than the overall mean. This prevents the removal of too many reasoning paths due to potential inaccurate estimation of the mixture distribution. 

Overall, we apply the \emph{Reasoning Pruning} to all sampled reasoning paths $\tilde{t}_1, \dots, \tilde{t}_n$ for removing low probability reasoning paths and then compute the confidence based on \emph{Perplexity Consistency}, forming our proposed \underline{\textbf{R}}easoning-pruning \underline{\textbf{P}}erplexity \underline{\textbf{C}}onsistency confidence (\RPC). The pseudo-code is shown in Algorithm~\ref{alg:rpc} in Appendix~\ref{sec:appendix-rpc}.

