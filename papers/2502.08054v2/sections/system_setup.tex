\section{Task and System Setup}
\textbf{Task description.} 
\label{sec:task_desc}
This work tackles bimanual occluded grasping problems.
Occluded grasping refers to the inability to execute a desired grasp pose due to collisions between the robot and its environment. 


In order to grasp a target object given a desired grasp pose that is occluded, one arm is needed to prevent the object from moving, while the dominant arm attempts to reorient and grasp the object.
In this work, the left robot arm (dominant arm) always attempts to grasp a target object while the right arm (non-dominant arm) stabilises the object to assist the left arm.
We leave dynamic role assignment of left and right arms to future work, similar to~\cite{grannen2023stabilize}.
Moreover, the gripper of the left arm autonomously closes at the end of each episode to grasp the target object, and the left end-effector moves upward to lift the object.

We formulate two distinct Markov Decision Processes (MDP) for the occluded grasping task.
The first MDP is fully observable and defined by a tuple $\mathcal{M}_{1} = (\mathcal{S}_{1}, \mathcal{A}, \mathcal{R}, \gamma, \mathcal{P}_{1})$, where $\mathcal{S}$ is the state space, $\mathcal{A}$ is the action space, $\mathcal{R}$ is the reward function, $\gamma$ is a discount factor, and $\mathcal{P}$ is the environment dynamics.
The second MDP is partially observable, a POMDP, and defined by a tuple $\mathcal{M}_{2} = (\mathcal{S}_{2}, \mathcal{O}_{2}, \mathcal{A}, \mathcal{R}, \gamma, \mathcal{P}_{2})$, where $\mathcal{O}$ is the observation space which includes point clouds.
The state-based teacher constraint and grasping policies are trained in simulation under the MDP $\mathcal{M}_{1}$.
On the other hand, the vision-based student constraint and grasping policies are evaluated in the simulated and real-world environments under the MDP $\mathcal{M}_{2}$.
The RL policy is trained to maximise the cumulative reward $\sum_{t=0}^{T-1}\gamma^{t} \mathcal{r}(\mathbf{s}_{t}, \mathbf{a}_{t})$ where $r \in \mathcal{R}$.

\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{figures/system_setup.pdf}
    \caption{\textbf{Real-world system setup.}  The system comprises two Kinova Gen3 robotic arms mounted perpendicularly to the main body. Each arm is equipped with a Robotiq 2F-85 gripper. To enhance grasping performance, the grippers are fitted with soft fingertips~\cite{chi2024universalmanipulationinterfaceinthewild} instead of the standard ones. Visual observations are captured using a third-person RealSense L515 camera positioned in front of the robot.}
    \label{fig:real-world_sys}
    \vspace{-0.5cm}
\end{figure}


\textbf{Action Space}
The teacher and student policies share the same action space.
A grasping policy that controls the left arm outputs six-dimensional delta poses, including translations and rotations represented in axis-angle format.
As described in Section~\ref{sec:task_desc}, the robot autonomously closes the left gripper at the end of the episode.
Thus, the gasping policy does not include a discrete action for closing and opening the gripper.
A constraint policy for the right arm produces a six-dimensional absolute pose for the right end-effector.
As in prior work~\cite{shao2020learning}, the constraint policy focuses on the x-y plane, given that the constrained end-effector is typically positioned on the table.
Thus, the first two dimensions correspond to the $x$ and $y$ coordinates of the end-effector, while the remaining four define its orientation as a quaternion.
For the baseline RL policy that jointly controls both arms, the policy outputs 12-dimensional delta poses. 
The first six dimensions correspond to the delta actions for the left arm, while the remaining six dimensions are allocated to the right arm.




\textbf{Real-World Setup.}
We design a system for bimanual occluded grasping as shown in Fig.~\ref{fig:real-world_sys}.
The system consists of two Kinova Gen3 arms with Robotq 2F-85 grippers.
The robot arms are perpendicularly attached to a body.
Instead of the original rigid fingertips attached to the Robotiq 2F-85 grippers, deformable fingertips~\cite{chi2024universal} designed for a more secure grip are used.
An L515 Realsense camera, with known extrinsic parameters, serves as the third-person camera and provides point clouds to vision-based student policies.
To control a robot, we use a hybrid task and joint space impedance controller~\cite{kim2019model}.

\textbf{Simulation Setup.}
Isaac Sim~\cite{IsaacDeveloper} is used to train teacher policies for the occluded grasping task.
To train policies, $48$ objects selected from the Google Scanned Objects dataset~\cite{downs2022googlescannedobjectshighquality} are spawned into the environment (see Figure~\ref{fig:training_objects}).
The trained teacher policies are distilled to student policies that take as input point cloud observations obtained from a third-person camera.
We use an operational space controller~\cite{khatib1987unified} to control robot arms.
Further information regarding the simulation setup can be found in Appendix~\ref{appendix:teacher}.






