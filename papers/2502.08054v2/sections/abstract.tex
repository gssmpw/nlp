\begin{abstract}
This paper addresses the challenge of \emph{occluded} robot grasping, i.e. grasping in situations where the desired grasp poses are kinematically infeasible due to environmental constraints such as surface collisions.
Traditional robot manipulation approaches struggle with the complexity of non-prehensile or bimanual strategies commonly used by humans in these circumstances.
State-of-the-art reinforcement learning (RL) methods are unsuitable due to the inherent complexity of the task.
In contrast, learning from demonstration requires collecting a significant number of expert demonstrations, which is often infeasible.
Instead, inspired by human bimanual manipulation strategies, where two hands coordinate to stabilise and reorient objects, we focus on a bimanual robotic setup to tackle this challenge.
In particular, we introduce Constraint-based Manipulation for Bimanual Occluded Grasping (\ourmethod), a learning-based approach which leverages two coordinated policies: a constraint policy trained using self-supervised datasets to generate stabilising poses and a grasping policy trained using RL that reorients and grasps the target object.
A key contribution lies in value function-guided policy coordination. 
Specifically, during RL training for the grasping policy, the constraint policy's output is refined through gradients from a jointly trained value function, improving bimanual coordination and task performance.
Lastly, \ourmethod~employs teacher-student policy distillation to effectively deploy point cloud-based policies in real-world environments.
Empirical evaluations demonstrate that \ourmethod~significantly improves task success rates compared to competitive baseline approaches, with successful generalisation to unseen objects in both simulated and real-world environments.



\end{abstract}



