\section{Related Work}
\subsection{Task-oriented Human-Robot Communication}


Task-oriented communication between humans and robots is becoming increasingly important, especially in the context of end-user robot programming. Natural language programming allows non-expert users to specify robot tasks through verbal instructions ____. This approach enables users to communicate complex task requirements and specify reusable programs through multi-turn dialogues ____, making it a fundamental aspect of end-user robot programming ____.

The integration of artificial intelligence with natural language programming is considered a key method for future household robots and intelligent agents to provide personalized services ____. 
Through natural dialogue, this approach enables untrained users without programming knowledge to define reusable robot programs that align with their practical needs.
Recent advancements in large language models (LLMs) 
____ have further accelerated developments in this field. Several studies have explored how LLM capabilities can support end-users in defining robot tasks using natural language ____. 
However, specifying robot tasks based on natural language descriptions of desired program outcomes still poses challenges due to the abstraction gap between natural language and program code ____.
Recent advancements in LLM-based end-user programming have investigated structured and visualized “intermediate-level” representations to address the abstraction gap ____.

LLM-based end-user development (EUD) transforms programming into a collaborative and iterative communication process ____.
Effective communication between users and robots often requires a continuous cycle of ``intention expression → result feedback → intention adjustment'' to complete task specification ____. This process typically integrates multiple modalities to provide user feedback and represent program or task context ____, or supports users in expressing intentions through multimodal interactions ____. Furthermore, human-like multimodal interactions have been explored to facilitate task communication between users and robots ____.



In light of these advancements and the challenges inherent in LLM-based EUD systems, there is an opportunity to enhance verbal programming. This motivates us to draw inspiration from human-to-human verbal communication and explore natural, intuitive interactions that leverage large language models to improve the usability of verbal programming.



 
\subsection{Visual Aids in Human-Robot Communication}



Screens on robots serve an important function in enhancing communication by displaying facial expressions and complementing voice interactions ____. Beyond expressive functions, screens also facilitate the communication of complex messages, yet their integration with verbal communication remains an area requiring further exploration.

Currently, the way touch screens are used in service robots has led to their perception as mere “screen bearers”, diminishing the sense of rich interaction with an autonomous agent.
In most cases, they are employed as a means to circumvent the current limitations of full speech interaction while also providing an effective way to enable complex interactions ____. 
However, balancing this with other interaction modalities is important to maintain a rich interaction experience. The consistency between voice interactions and graphical user interfaces is crucial for improving system usability and user satisfaction ____, making it easier for users to understand and operate the system.
Research indicates that providing graphical feedback during dialogues significantly enhances user comprehension of the robot’s responses and intentions ____.

Visual media can support task communication through various forms, including robot-mounted screens, external display devices, and extended reality (XR) interfaces ____. Additionally, external objects and gestures can serve as references to assist in task communication, enhancing naturalness and comprehension ____. 
Some researchers have explored projection techniques that allow robots to visualize task information on physical objects in the environment ____. 
Compared to single-modality interactions, interactions with robots that exhibit natural multimodal expression provide a more engaging and intuitive communication experience ____. 
Drawing inspiration from human-to-human interaction patterns has proven effective in refining robot communication strategies ____. Since human-AI agent communication is inherently dialogic, requiring iterative exchanges to refine intent expression, the selection of interaction modalities should be contextually adapted to different scenarios ____.





\subsection{LLM-driven Dynamic UI Generation}

Recent work has demonstrated that large language models can serve as intermediaries for multimodal interfaces, enabling both understanding and generation beyond purely natural language content. For example, in graphical user interfaces, LLMs can interpret the semantics and structure of UIs ____ and generate UI designs ____, demonstrating their potential in processing and generating non-linguistic visual representations.

Furthermore, the world knowledge and in-context learning capabilities of LLMs ____ enable the dynamic generation of multimodal interactions tailored to the context on the fly. For instance, GenEM ____ utilizes LLMs to flexibly generate and adapt robot expressive behaviors based on natural language instructions and user preferences. Similarly, SiSCo ____ showcases the ability of LLMs to synthesize both natural language and visual signals adaptively for efficient collaboration. In the context of end-user programming, Cocobo ____ illustrates how LLMs can dynamically translate between natural language and visual programming representations.

Unlike traditional rule-based or template-based approaches, these LLM-based methods show the potential for adaptive contextual understanding and immediate generation across multiple modalities. This motivates our exploration of leveraging LLMs to dynamically generate visual aids for task-oriented communication between humans and robots.







\begin{figure*}
  \centering
  \includegraphics[width=\textwidth]{figures/mapDraw.jpg}
  \caption{Sample maps drawn by participants during the formative study, showing how they used visual elements to represent and communicate spatial tasks through annotations, paths, and markers.}
  \Description{The figure displays a collection of hand-drawn maps created by study participants during the formative study. Each map shows how participants used different visual elements like arrows, circles, text labels, and color coding to represent spatial tasks and communicate their understanding of task requirements.}
  \label{fig:paper map}
\end{figure*}