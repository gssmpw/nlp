\section{Related Work}
\subsection{Human decision-making system}

Human decision-making system is a complex interplay between intuitive and deliberative processes. \citet{haidt2001emotional} suggested that human judgments, particularly moral ones, are dominantly driven by intuitive processes, with reasoning often serving as a post hoc justification. \citet{kahneman2002maps} further elaborated on this dual-process theory, distinguishing between System 1 (fast, automatic, and intuitive) and System 2 (slow, effortful, and analytical) processes. System 1 dominates most everyday decision \citep{evans2008dual} and enables humans to make rapid decisions, often relying on efficient heuristics, but can introduce biases \citep{gigerenzer2011heuristic}. This heuristics can be intuition \citep{evans2008dual} or emotion \citep{slovic2007affect}.
These works highlight that human decision-making is not purely rational but deeply influenced by intuition, emotion, and heuristics.
In this paper, we suppose that artificial systems may also have a similar mechanism with humans.

\subsection{Machine decision-making system and their bias}

DNN inference mechanism has been widely studied, mostly focusing on their hierarchical behavior. \citet{zeiler2014visualizing} demonstrated that DNNs behave as sequential feature extractors, with earlier layers capturing low-level features such as edges and textures, and deeper layers focusing on more complex patterns and object parts. Similarly, the information bottleneck theory \citep{tishby2015deep,michael2018information_bottleneck} explains that earlier layers compress the input by removing redundant features, while later layers focus on prediction. While these approaches provide valuable insights for DNN inference, they assume unified and consistent behavior regardless of input properties.

Recent research highlights that DNNs are inherently biased or rely on ``shortcuts'' \citep{geirhos2020shortcut}, namely, DNNs prefers simpler features (\eg, color or texture) over more complex ones (\eg, shape) \citep{geirhos2018stylized_imagenet}.
Although an architectural difference can make a minor change \citep{brendel2019bagnet,bahng2019rebias,naseer2021intriguing}, as shown by \citet{scimeca2022shortcut}, these biases exist regardless of the network architecture. Furthermore, certain cues (\eg, color) are preferred to other more complex ones (\eg, shape), highlighting that DNNs are inherently more likely to be biased toward features that are computationally simpler.
This paper supposes that this preference behaves similarly to ``fast heuristics'' in DNNs, enabling efficient but potentially error-prone decision-making during early inference stages.