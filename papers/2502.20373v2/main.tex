\documentclass[aps,prl,showpacs,twocolumn,nofootinbib,preprintnumbers]{revtex4-2}
\usepackage{bbm}
\usepackage{mathrsfs}
\usepackage{epsfig}
\usepackage{soul,xcolor}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage[figuresright]{rotating}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{dcolumn}
\usepackage{physics}
\usepackage{float}
\usepackage{bm}
\usepackage{physics}
\usepackage{verbatim}
\usepackage{braket}
\usepackage[normalem]{ulem}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{setspace}
\setlength{\skip\footins}{20pt}
\usepackage{lipsum}
\setlength{\skiptext}{10pt}
\setlength{\skiprule}{5pt}
\usepackage[colorlinks,linkcolor=blue,anchorcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}

\newcommand{\Input}{\item[\textbf{Input:}]}
\newcommand{\Output}{\item[\textbf{Output:}]}
\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}




\begin{document}

\title{Hamiltonian Learning at Heisenberg Limit for Hybrid Quantum Systems}
\author{Lixing Zhang$^{1}$, Ze-Xun Lin$^{2}$, Prineha Narang$^{2,3}$, Di Luo$^{3,*}$}

\affiliation{$^{1}$\mbox{Department of Chemistry and Biochemistry, University of California Los Angeles, Los Angeles, CA 90095, USA}\\
$^{2}$\mbox{Division of Physical Sciences, College of Letters and Science, University
of California, Los Angeles, 90095, California, USA}\\
$^{3}$\mbox{Department of Electrical and Computer Engineering, University of California Los Angeles, Los Angeles, CA 90095, USA} \\
}
\begin{abstract}
Hybrid quantum systems with different particle species are fundamental in quantum materials and quantum information science. In this work, we demonstrate that Hamiltonian learning in hybrid spin-boson systems can achieve the Heisenberg limit. Specifically, we establish a rigorous theoretical framework proving that, given access to an unknown hybrid Hamiltonian system, our algorithm can estimate the Hamiltonian coupling parameters up to root mean square error (RMSE) $\epsilon$ with a total evolution time scaling as $T \sim \mathcal{O}(\epsilon^{-1})$ using only $\mathcal{O}({\rm polylog}(\epsilon^{-1}))$ measurements. Furthermore, it remains robust against small state preparation and measurement (SPAM) errors. In addition, we also provide an alternative algorithm based on distributed quantum sensing, which significantly reduces the maximum evolution time per measurement. To validate our method, we apply it to the generalized Dicke model for Hamiltonian learning and the spin-boson model for spectrum learning, demonstrating its efficiency in practical quantum systems. These results provide a scalable and robust framework for precision quantum sensing and Hamiltonian characterization in hybrid quantum platforms.
\end{abstract}


\maketitle


\textit{Introduction---.} The study of hybrid quantum systems of different particle species is essential for both understanding fundamental interactions in nature and advancing quantum engineering.
In condensed matter physics, electron-phonon interaction historically played a pivotal role in the breakthrough understanding of BCS superconductivity~\cite{bardeen1957theory}. More broadly, fermion interactions with gauge bosons have been a unifying theme in quantum field theory~\cite{feynman2018space,schwinger1951theory,yang1954conservation}. In particular, (2+1)-dimensional quantum electrodynamics (QED$_3$) provides valuable insights into the cavity-enhanced fractional quantum Hall effect~\cite{FQHE}, topological quantum matter~\cite{TI}, and quantum spin liquids~\cite{savary2016quantum}.
In quantum information science, hybrid quantum systems facilitate information transfer between superconducting qubits and infrared photons in quantum transduction~\cite{QT} and enable long-distance communication via optical fiber-based quantum networks~\cite{Metro_scale}. Recently, hybrid qauntum computing platforms based on Rydberg atoms, ion traps, and superconducting qubit-oscillator~\cite{GKP, HybridQC1, HybridQC2} have emerged, providing novel avenues for fault-tolerant quantum simulation and algorithmic advancements.\blfootnote{*Email: ~\url{diluo@ucla.edu}}


To bridge theory and experiment, the characterization of Hamiltonian is crucial, which helps to derive accurate theoretical models~\cite{HL1}, calibrate quantum devices~\cite{HL2}, and design error-mitigation algorithms~\cite{HL3}. This necessity has led to the field of Hamiltonian learning, which reconstructs a quantum systemâ€™s Hamiltonian from experimental measurements. According to the central limit theorem,  achieving a root-mean-square error (RMSE) of $\epsilon$ in any measured quantities requires a scaling of $\mathcal{O}(\epsilon^{-2})$  in total evolution time and number of measurements, defining the standard quantum limit (SQL). On the other hand, as predicted by the uncertainty principle, the optimal scaling in total evolution time is $\mathcal{O}(\epsilon^{-1})$, known as the Heisenberg limit. Recently, Heisenberg limit hamiltonian learning is achieved for qubit systems~\cite{Hsin2023,Ainesh2024,Hu2025} and further generalized to bosonic and fermionic hamiltonians~\cite{Haoya2023,Arjun2024}. Despite the above advancement, efficient learning for hybrid Hamiltonians remains an open challenge. The coupling between discrete and continuous degrees of freedom (DOFs) in hybrid systems leads to complex dynamic phenomena across different parameter regimes. However, the fundamental asymmetry between discrete states and continuous modes presents significant theoretical and computational hurdles, as traditional methods struggle to capture both quantization and infinite-dimensional dynamics. Even for the simplest hybrid system, a general solution was elusive until~\cite{Rabi}, highlighting the greater complexity of hybrid Hamiltonian learning.

\begin{figure*}[t]
\centerline{\includegraphics[width=180mm]{flowchart.png}}
\caption{Hybrid Quantum systems Hamiltonian learning. Left panel: Schematic of the learning protocol presented in this work. Right panel: Properties and applications of the main algorithm. }

\label{flowchart}
\end{figure*}

In this paper, we present the first algorithm that learns hybrid Hamiltonians of spin-boson at the Heisenberg limit. In learning all Hamiltonian coefficients to an RMSE of $\epsilon$, the proposed algorithm only uses $\mathcal{O}(\epsilon^{-1})$ total evolution time and $\mathcal{O}({\rm polylog}(\epsilon^{-1}))$ measurements, while maintaining robustness against small state preparation and measurement (SPAM) errors. Besides the main algorithm, we also provide an alternative scheme based on distributed quantum sensing (DQS), which significantly reduces the maximum evolution time per measurement. We numerically verify the scaling of our approaches and provide concrete examples that demonstrate its applicability in circuit-QED devices and spectrum learning problems.

\textit{Hybrid Hamiltonian learning}---We consider Hamiltonian that has the following form:
\begin{eqnarray}\label{gen_H}
{\hat H} = {\hat H}_{\rm spin} + {\hat H}_{\rm boson} + {\hat H}_{\rm int}
\end{eqnarray}
where ${\hat H}_{\rm spin} = \sum_a \xi_a \hat{E}_a$, ${\hat H}_{\rm boson} = \sum_n \omega_n {\hat b}_n^\dagger {\hat b}_n$ and ${\hat H}_{\rm int} = \sum_{n,a} \lambda_a^n \hat{E}_a({\hat b}_n^\dagger + {\hat b}_n)$. ${\hat b}_n^\dagger ({\hat b}_n)$ is the creation (annihilation) operator for the $n^{th}$ bosonic mode. $\hat{E}_{a}$ is a multi-qubit Pauli string. Here, spin part of ${\hat H}_{\rm int}$ are assumed to be $k$-local, i. e. $|{\rm supp}(E_{a})| \le k$. For example, a 5-qubit spin Hamiltonian with $k = 3$, $\hat{E}_{a}$ could be $XIZYI$. 





The algorithm proposed in this work achieves the following properties:
\begin{theorem}\label{th1}
Given a unitary dynamics access to arbitrary Hamiltonian in the form of Eq.~(\ref{gen_H}), there is an algorithm $\mathcal{A}$ that can estimate $\xi_a$, $\lambda_a^n$ and $\omega_n$ up to a RMSE $\epsilon$ such that:
\begin{enumerate}
  \item $\mathcal{A}$ takes a total evolution time of $T \sim \mathcal{O}(\epsilon^{-1})$ to measure all of the coefficients.
  \item $\mathcal{A}$ uses $\mathcal{O}({\rm polylog(\epsilon^{-1}) )}$ measurements to learn all of the coefficients.
  \item $\mathcal{A}$ is robust under small SPAM error.
\end{enumerate}
\end{theorem}
To achieve Theorem~\ref{th1}, we first cancel ${\hat H}_{\rm int}$ via random unitary transformation (RUT). This allow us to learn ${\hat H}_{\rm spin}$ and ${\hat H}_{\rm boson}$ independently. Compared to~\cite{Hsin2023}, our algorithm for ${\hat H}_{\rm spin}$ works without the low-intersection assumption, making it scalable for general $k$-local spin Hamiltonians. To learn ${\hat H}_{\rm int}$, we use the learnt coefficients of ${\hat H}_{\rm boson}$ as input (the error induced by doing this can be suppressed~\cite{supmat}) to reshape the total Hamiltonian as a displacement channel. Homodyne measurement on the momentum quadrature of the resulting coherent state creates a quantum signal that grows linearly over time with a fixed variance. This achieves the Heisenberg limit. Implementing the robust frequency estimation (RFE)\cite{Haoya2023} on the quantum signal reduces the number of measurements to $\mathcal{O}({\rm polylog(\epsilon^{-1}) )}$, while making the algorithm robust under small SPAM error. We further develop an alternative scheme based on distributed quantum sensing (DQS) to ${\hat H}_{\rm int}$ that also achieves the Heisenberg limit, but with lower maximum evolution time. The general scheme of our approach is provided in Fig.~\ref{flowchart} with a detailed pseudo-code in the Supplementary Materials~\cite{supmat}.



\textit{Learning pure spin and boson coefficients}--- We begin by introducing the learning protocols for terms that only include pure spin or boson operators, which are characterized by  $\xi_a$ and $\omega_n$. A key algorithm we used is RUT, which reshape ${\hat H}$ by inserting random unitary sequence $\mathbb{U}(\boldsymbol \theta) = \prod_j U_j(\theta_j)$ between $R$ segments of $e^{-i{\hat H}\tau}$ ($\tau \equiv t/R$, and $\boldsymbol\theta \equiv (\theta_1, \theta_2, ..., \theta_j)$.). By sampling $\theta_j$ from independent uniform distribution $\mathcal{U}_j$ for each insertion, the effective Hamiltonian can be approximated as: $\hat{\mathcal H} = V({\boldsymbol \theta})^{-1}\int d{\boldsymbol\theta} \mathbb{U}^\dagger {\hat H} \mathbb{U}$, where $V({\boldsymbol \theta})^{-1}$ is the volumn of sampling domain. The form of $\hat{\mathcal H}$ depends on the choice of $\mathbb{U}$ used, which allows us to reshape ${\hat H}$. Readers are referred to~\cite{supmat} for technical details regarding RUT.


To cancel ${\hat H}_{\rm int}$, we reshape ${\hat H}$ with $\mathbb{U}^{(1)} \equiv \prod_n^{N_b} e^{-i \theta {\hat b}_n^\dagger {\hat b}_n}$ ($\theta \sim \mathcal{U}(0, 2\pi)$, where $N_b$ is the total number of bosonic mode. The application of $\mathbb{U}^{(1)}$ introduces $e^{\pm i\theta}$ phase to ${\hat b}_n^\dagger$(${\hat b}_n$), leading to the following effective Hamiltonian:
\begin{eqnarray}\label{Eff_H1}
\hat{\mathcal H}^{(1)} = \sum_a \xi_a \hat{E}_a +\sum_n \omega_n {\hat b}_n^\dagger {\hat b}_n
\end{eqnarray}
where the spin and bosonic DOFs are decoupled. This allows us to learn $\xi_a$ and $\omega_n$ separately.

(i.) To learn $\xi_a$, we begin by select a specific Pauli string ${\hat E}_{b}$ such that $|{\rm supp}({\hat E}_{b})| = k$. We construct a unitary sequence $\mathbb{U}_b^{(2)} = \prod_{j}^{N_q} U_j$ ($N_q$ is the number of qubit), where the  $1-$qubit unitary $U_j$ takes the form of:
\begin{eqnarray}\label{pauli random}
U_{j}= 
    \begin{cases}
        e^{-i\theta_{j}\mathcal{P}_j^{b}} & \text{if } j \in {\rm supp}({\hat E}_{b})\\
        e^{-i\theta_{j}\mathcal{P}_j }e^{-i\phi_j\mathcal{P}_j^\prime} & \text{if } j \not\in {\rm supp}({\hat E}_{b})
    \end{cases}
\end{eqnarray}
Here, $\mathcal{P}_j^{b}$ refers to the $j^{th}$ operator of Pauli string $E_{b}$. For example, let $E_{b} = ZIX$, $\mathcal{P}_{j=1}^{b} = Z$, $\mathcal{P}_{j=2}^{b} = I$ and $\mathcal{P}_{j=3}^{b} = X$. $\mathcal{P}_j$ and $\mathcal{P}_j^{\prime}$ are arbitrary Pauli operators satisfying $[\mathcal{P}_j, \mathcal{P}_j^{\prime}] \neq 0$. Reshaping $\hat{\mathcal H}^{(1)}$ with $\mathbb{U}_b^{(2)}$ gives the following effective spin Hamiltonian:
\begin{eqnarray}\label{Eff_Spin_H1}
\hat{\mathcal H}_{\rm S}^{(2)} &=& \sum_{s: {\hat E}_s \in S_{b}} \xi_s {\hat E}_s
\end{eqnarray}
where ${\hat E}_s$ is a Pauli string that is in set $S_{b} \equiv \left\{\prod_{ i \in \mathrm{supp}({\hat E}_{b})} \mathcal{P}_i^s \;\middle|\; \mathcal{P}_i^s \in \{ \mathcal{P}_i^{s}, \mathcal{I} \} \right\}$. $\xi_s$ is the corresponding coefficient of ${\hat E}_s$ in $\hat{\mathcal H}^{(1)}$. $S_{b}$ is generated by replacing any operators in ${\hat E}_{b}$ by identity. Therefore, all elements in $S_{b}$ commute. For example, if $E_{b} = ZIX$, the corresponding $S_{b}$ can be written as: $\left\{ZIX, ZII, IIX, III\right\}$. The above reshaping process harnesses the commutation relationship of Pauli operators (for example, $e^{iX\theta}Ye^{-X\theta} = {\rm cos}(2\theta)Y - {\rm sin}(2\theta)Z$) . This induces a $e^{\pm i2\theta}$ phase to any Pauli string that is not in $S_{b}$. Therefore, $\theta_{j}$ and $\phi_{j}$ should be sampled from independent uniform distribution to avoid phase interference. 

As $|{\rm supp}({\hat E}_{b})| = k$ by selection, the number of terms in $\hat{\mathcal H}_{\rm S}^{(2)}$ is $|S_{b}| = 2^k$ . These terms can be simultaneously diagonalized by the eigenstate of ${\hat E}_{b}$, which we label as $\ket{E_{b}}_l$. As each Pauli operator has two eigenstates, index $l$ runs up to $2^k$. For a Pauli string ${\hat E}_s \in S_b$, we denote the corresponding eigenvalue of $\ket{E_{b}}_l$ as $\gamma_l^s$, such that ${\hat E}_s\ket{E_{b}}_l = \gamma_l^s \ket{E_{b}}_l$. $\gamma_l^s$ can only take the value of $\pm 1$. For example, if $E_{b} = ZIX$, let $\ket{E_{b}}_l = \ket{0}_1 \otimes \ket{-}_3$, the corresponding $\gamma_l^s$ for elements in $S_{b}$ are, in order, $\left\{-1, +1, -1, +1\right\}$. As $\hat{\mathcal H}_{\rm S}^{(2)}$ sums up all ${\hat E}_s \in S_b$, the eigenvalue of $\ket{E_{b}}_l$ with respect to $\hat{\mathcal H}_{\rm S}^{(2)}$ can be written as: $\Xi_{b,l} = \sum_s \gamma_l^s \xi_s$. This allows us to implement the robust phase estimation (RPE)~\cite{Shelby2015} to learn $\Xi_{b,l}$ at Heisenberg limit. As $\ket{{\hat E}_{b}}_l$ and $\gamma_l^s$ are known by selecting a specific $E_b$, looping over all possible $l$ yields $2^{k}$ linear equations (LE). Solving these LEs simultaneously generates all $\xi_s$ such that ${\hat E}_s \in S_{b}$. This procedure should be repeated for all ${\hat E}_{b}$ that satisfies $|{\rm supp}({\hat E}_{b})| = k$. For a general $k-$local spin Hamiltonian, the number ${\hat E}_{b}$ is $3^kC_{N_q}^k$, which remains manageable assuming $k \sim \mathcal{O}(1)$.  Note that the above procedures can be parallelized on different devices, as all ${\hat E}_{b}$ and $\ket{{\hat E}_{b}}_l$ can be determined knowing $k$ and $N_q$. 

(ii) The learning of $\omega_{n}$ is rather straightforward, as the bosonic part of $\hat{\mathcal H}^{(1)}$ is a free-field Hamiltonian. We initialize the bosonic state on a coherent state with displacement $\alpha = |\alpha| e^{ir}$. The homodyne measurement on both the displacement and momentum quadrature of the $n^{th}$ bosonic mode allows us to construct a complex signal $\mathcal{Z} = \langle {\hat X}_n\rangle + i \langle {\hat P}_n\rangle$ with ${\rm arg}(\mathcal{Z}) = (\omega_{n} +r)t$. This allows us to implement robust frequency estimation (RFE)\cite{Haoya2023}, which learns $\omega_{n}$ at Heisenberg limit. Note that the above process can be performed to all bosonic simultaneously by preparing a multi-mode coherent state.

\textit{Learning spin-boson couplings}.--- Now we proceed to the learning protocols for terms that contain a mixture of spin and boson operators, which are characterized by $\lambda_a^n$. Continuing the previous section, we assume estimations ${\tilde\omega}_n$ have been obtained with small error. Starting from Eq.~\ref{gen_H}, to bypass complex spin-boson interaction while retaining the coupling coefficients, we wish to reshape the spin-part of ${\hat H}_{\rm int}$ into a Hamiltonian with known eigenstates. This can be achieved by reshaping ${\hat H}$ with the same unitary sequence $\mathbb{U}_b^{(2)}$, since the spin-part of ${\hat H}_{\rm int}$ shares the same interaction structure as ${\hat H}_{\rm spin}$. The resulting effective Hamiltonian is given by:
\begin{eqnarray}\label{Eff_H2}
\hat{\mathcal H}^{(2)}_{\rm SB} = \sum_n^{N_b}\Big\{\sum_{s: {\hat E}_s \in S_{b}} [\xi_s + \lambda_s^n({\hat b}_{n}^\dagger + {\hat b}_{n}) ] {\hat E}_s + \omega_n {\hat b}_n^\dagger {\hat b}_n \Big\} \nonumber \\
\end{eqnarray}
where all ${\hat E}_s$ can be diagonalized simultaneously by $\ket{{\hat E}_{b}}_l$ ($l$ represents one of the $2^k$ eigenstates of ${\hat E}_{b}$). By initializing the spin-part of the wavefunction on $\ket{E_{b}}_l$, ${\hat E}_s$ in the above Hamiltonian can be replaced with their corresponding eigenvalues, leaving an effective bosonic Hamiltonian in the form of a series of displaced harmonic oscillators. This allows us to derive~\cite{supmat} an analytical formula for the time evolution of bosonic vacuum states:
\begin{eqnarray}\label{displacement}
\ket{\Psi_{\rm B}(t)}_l =  \prod_n^{N_b}{\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\omega_{n}}(e^{i\omega_{n} t} - 1)) \ket{\bf 0} 
\end{eqnarray}
where $\Lambda_{b,l}^n \equiv \sum_s \gamma_{l}^s \lambda_{s}^n$ is the eigenvalue of $\ket{E_{b}}_l$ with respect to the spin-part of ${\hat H}_{int}$, and $\ket{\bf 0} = \ket{\rm vac}^{\otimes N_b}$ is the multi-mode bosonic vacuum state. ${\hat D}_{n}(\alpha) \equiv e^{\alpha {\hat b}_{n}^\dagger - \alpha^\ast {\hat b}_{n}}$ is the displacement operator of the $n^{th}$ bosonic mode. Starting from Eq.~\ref{displacement}, we provide two solutions to learn $\lambda_{s}^n$ at Heisenberg limit, based on Trotterization technique and distributed quantum sensing method respectively:

(i): Trotter-based scheme. The trotter-based scheme cancel out $\omega_{n}$ via trotterization. We construct a unitary sequence $\mathbb{U}^{(3)}= \sum_n e^{i {\tilde \omega}_{n} {\hat b}_{n}^\dagger  {\hat b}_{n} \tau}$ using the estimated ${\tilde \omega}_{n}$ from the previous section. $\mathbb{U}^{(3)}$ is inserted at the end of every repetitive unitary cycles in RUT, such that the actual state without approximation is:
\begin{eqnarray}\label{insert}
\ket{\Psi_{\rm SB}(t)}_{l} = \prod_i^R \Big[[\mathbb{U}^{(2)}_b({\boldsymbol \theta_i})]^\dagger e^{-i{\hat H}\tau}\mathbb{U}^{(2)}_b({\boldsymbol \theta_i}) \mathbb{U}^{(3)}\Big] \ket{E_{b}}_l \ket{\boldsymbol{0}} \nonumber\\ 
\end{eqnarray}
where ${\boldsymbol \theta_i}$ represents all $\theta$ that parametrize $\mathbb{U}^{(2)}$. Note that $\mathbb{U}^{(3)}$ is not $\theta$ dependent. In the limit $R \rightarrow \infty$, the above equation effectively cancels the term $\sum_n \omega_{n} {\hat b}_{n}^\dagger  {\hat b}_{n}$ in $\hat{\mathcal H}^{(2)}_{\rm SB}$. The time evolution of the state in this case can be derived by taking the limit $\omega_{n} \rightarrow 0$ in Eq.~\ref{displacement}, which gives: $\ket{\Psi_{\rm B^*}(t)}_l = \prod_n^{N_b}{\hat D}_{n}(i\Lambda_{b,l}^n t) \ket{\bf 0}$. The homodyne measurement of the momentum quadrature of $\ket{\Psi_{\rm B^*}(t)}_l$ yields $\mathbb{E}[\langle \hat P_n \rangle] = \sqrt{2}\Lambda_{b,l}^n t$ with ${\rm Var}[\langle \hat P_n \rangle] = 1$. This result follows from the fact that a coherent state always satisfies the minimal uncertainty, which achieves the Heisenberg limit in learning $\Lambda_{b,l}^n$. Looping over all possible $l$ generates all $\lambda_s^n$ with ${\hat E}_s \in S_b$, same as the learning protocol for $\xi_s$. One might be tempted to use $\langle \hat P_n \rangle/\sqrt{2}t$ as the estimator of $\Lambda_{b,l}^n$ . However, doing so would lead to a $\mathcal{O}(\epsilon^{-2})$ scaling in the number of measurements. To improve this, we construct a signal $\mathcal{Z} = e^{-i \langle \hat P_n \rangle}$ via post-processing\cite{supmat}, which allows us to implement RFE\cite{Haoya2023}, achieving a $\mathcal{O}({\rm polylog(\epsilon^{-1}) )}$ scaling with respect to the number of measurements.

\begin{figure}[t]
\centering
\centerline{\includegraphics[width=90mm]{Trotter_error.png}}
\caption{Estimation error scaling at different $\tau$. The presented data is averaged over $100$ independent runs. Ideal error refers to $\epsilon = 1/2T$, which is derived from Eq.~\ref{displacement}. For GDM, the target parameter is $\lambda_{XXI}$. For SBM, the target parameter is $\lambda_X^{n=1}$.}
\label{Trotter_error}
\end{figure}

\begin{figure}[t]
\centering
\centerline{\includegraphics[width=90mm]{RPE_error.png}}
\caption{Estimation error scaling with SPAM error. For GDM, the target parameter is $\lambda_{XXI}$. For SBM, the target parameter is $\lambda_X^{n=1}$. 6 time points are selected in the $2^{\mathfrak K}$ fold space to implement RFE.}
\label{RPE_error}
\end{figure}

(ii): Distributed quantum sensing scheme. Starting from Eq.~\ref{displacement}, the Heisenberg limit can also be reached by changing the initial bosonic state. By preparing $W$ copies of the unknown Hamiltonian, an entangled squeezed state can be prepared via a balanced beam splitter\cite{Quntao2018}:
\begin{eqnarray}\label{multimode_entangled}
\ket{\Psi_{\rm B}^{\rm ent}(0)} &=& \prod_n^{N_b}{\rm exp}[\frac{1}{2}(z^\ast {\hat B}_{n}^2 - z {\hat B}_{n}^{\dagger 2})] \ket{\boldsymbol 0}
\end{eqnarray}
where ${\hat B}_n \equiv \sum_{w=1}^{W} {\hat b_{n, w}} / \sqrt{W}$ is the entangled annihilation operator of bosonic mode $n$. Eq.~\ref{displacement} is derived under the assumption that the initial bosonic state is the vacuum. However, as the bosonic part of $\hat{\mathcal H}^{(2)}_{\rm SB}$ contains no quadratic terms, $e^{-i\hat{\mathcal H}^{(2)}_{\rm SB}t}$ can still be treated as a pure displacement channel if the bosonic wavefunction is initialized on $\ket{\Psi_b(0)}_{\rm ent}$~\cite{supmat}. We choose ${\tilde{\mathcal X}}_n \equiv \sum_{w=1}^W \langle{\hat X_{n, w}}\rangle/W$ as the displacement estimator. At $t = \pi/{\tilde \omega}_{n}$, we have $\mathbb{E}[{\tilde{\mathcal X}}_n] = -4 \Lambda_{b,l}^n/\omega_{n}$, and the RMSE of $\hat X_{n, w}$ is\cite{Quntao2018}:
\begin{eqnarray}\label{DQS}
\epsilon({\tilde{\mathcal X}}_n) = \sqrt{\Big(\frac{1}{4W(\sqrt{1+N_{\rm pt}} + \sqrt{N_{\rm pt}})^2}\Big)} \nonumber \\
\end{eqnarray}
where $N_{\rm pt} = {\rm sinh}^2(|z|)$ is the total photon number. The sum of evolution time across all entangled copies $T$ is equal to $W\pi/\omega_{n}$. If the mean photon number per node $n_{\rm pt} \equiv N_{\rm pt}/W$ is fixed, we have $\epsilon({\tilde{\mathcal X}}_n) \sim \mathcal{O}(W^{-1})$. Therefore, we have $\epsilon({\tilde{\mathcal X}}_n) \sim \mathcal{O}(T^{-1})$, which reaches the Heisenberg limit. 

Comparing the above two schemes, the former requires only $\mathcal{O}({\rm polylog(\epsilon^{-1}) )}$ number of measurements, in contrast to the $\mathcal{O}(\epsilon^{-1})$ scaling of the latter. However, the $\mathcal{O}({\rm polylog(\epsilon^{-1}) )}$ scaling of the former relies on the implementation of RFE, which requires time sampling over
$2^{\mathfrak{K}}-$fold space. This necessitates a significantly higher number of gate applied to suppress errors induced during RUT compared to the latter, which  require only a maximum evolution time of $\pi/{\tilde \omega}_{n}$. Nevertheless, both schemes achieve the Heisenberg limit. 

\textit{Numerical experiments}.---We demonstrate the application of our algorithm on two classes of models: a generalized Dicke model (GDM)and a spin-boson model (SBM). The Hamiltonian of GDM is given by:
\begin{eqnarray}
{\hat H}_{\rm GDM} =  \sum_{a}[ \xi_a + \lambda_a ({\hat b}^\dagger + {\hat b}) ]{\hat E}_a + \omega {\hat b}^\dagger{\hat b}
\end{eqnarray}
where ${\hat E}_a \in \Big\{\mathcal{P}\mathcal{P}I, \mathcal{P}I\mathcal{P}, I\mathcal{P}\mathcal{P} | \mathcal{P} \in \{X,Y,Z\}\Big\}$ is a 3-qubit Pauli string. We set $\omega = 1$, $\xi_{a}$  and $\lambda_a$ are uniformly sampled from $\mathcal{U}(0.5, 1.5)$ and $\mathcal{U}(0.01, 0.03)$, respectively. The GDM describes the coupling between a inhomogeneous Heisenberg spin chain and a single bosonic mode, which provides the theoretical description for a range of quantum devices and algorithms~\cite{liu2024hybrid, safavi2018verification}. For SBM, we have:
\begin{eqnarray}\label{SBM}
{\hat H}_{\rm SBM} =  \sum_{a}[ \xi_a + \sum_n^{N_b} \lambda_a^n ({\hat b}^\dagger + {\hat b}) ]E_a + \sum_n^{N_b}\omega_n {\hat b}_n^\dagger{\hat b}_n
\end{eqnarray}
where ${\hat E}_a \in \{X, Y, Z\}$ is a 1-qubit pauli operator. $\xi_a \sim \mathcal{U}(0.5, 1.5)$. $\lambda_a^n = \kappa_a \Lambda_n$ with $\kappa_a$ sampled from $\mathcal{U}(0.5, 1.5)$. $\Lambda_n$ and $\omega_n$ are generated by discretizing Eq.~\ref{Jw}. SBM describes a non-markovian dissipation of a single qubit mediated via a bosonic bath, which is crucial for the simulation of decoherence~\cite{magazzu2018probing} and quantum phase transition~\cite{de2020quantum}. 
 


\begin{figure}[t]
\centerline{\includegraphics[width=80mm]{spec_learning.png}}
\caption{Learning the spectral density function of SBM. (a) Relative error of the estimation generated from the DQS-based scheme. (b) The value of $\lambda_X^{n}$ across all bosonic modes, showing the shape of the discrete spectral density $J(\omega)$. For the parameter used: $W = 1000$ and $n_{pt} = 1$.}
\label{Spectral_learning}
\end{figure}

In Fig.~\ref{Trotter_error}, to demonstrate the error scaling induced by RUT, we plot the total evolution time against mean estimation error, which is obtained by averaging 100 numerical experiments. The time step $\tau \equiv t/R$ is changed across different lines. We observe that as $tau$ decreases, the error induced by RUT gradually aligns with the ideal error (gray line). Further numerical experiment shows that the trace distance between the ideal and actual state follows $||\Delta \rho ||_1 \propto t/\sqrt{R}$~\cite{supmat}. 

In Fig.~\ref{RPE_error}, we demonstrate the robustness of our algorithm against SPAM error using the trotter-based scheme. A small Gaussian noise is added into measurements, and $6$ time points are sampled in $2^\mathfrak{K}-$fold space to implement RFE. We observe that the estimation error maintains a Heisenberg scaling despite the presence of noise.

In Fig.~\ref{Spectral_learning}, we demonstrate the learning of unknown bosonic spectrum. The spectral density function, describing a cavity mode coupled to a dissipative bosonic heat bath~\cite{Spec_den}, takes the form of:
\begin{eqnarray}\label{Jw}
J(\omega) = \sum_n (\Lambda_n)^2 \delta(\omega-\omega_n) = \frac{\eta \omega}{(\omega^2-\Omega^2)^2 + \gamma^2 \omega^2} \nonumber \\
\end{eqnarray}
where $\eta = 0.01$, $\gamma = 1$ and $\Omega = 2$. $\Lambda_n$ and $\omega_n$ are generated by discretizing $J(\omega)$~\cite{supmat}. Using the DQS-based scheme, we reconstruct the spectral density function by looping over all discrete bosonic modes. The simulation is performed with $W = 1000$ and $n_{pt} = 1$. The spectral density is recovered within $0.2\%$ error, showcasing the applicability of our algorithm in spectrum learning.


\textit{Discussion}.---In this work, we establish a robust and efficient foundation for hybrid Hamiltonian learning. Our protocol reaches the golden-standard: Heisenberg limit $T \sim \mathcal{O}(\epsilon^{-1})$, in learning all Hamiltonian coefficients. It only requires $\mathcal{O}({\rm polylog}(\epsilon^{-1}))$ measurements while remaining robust under small SPAM error. In learning pure spin and boson coefficients, our algorithm operates without relying on the low-intersection approximation. In learning spin-boson coupling coefficients, we propose two schemes: Trotter-based scheme and DQS-based scheme. The former employs RFE, achieving the Heisenberg limit using only $\mathcal{O}({\rm polylog}(\epsilon^{-1}))$. The latter utilizes quantum entanglement, requiring a significantly shorter maximum evolution time, making it particularly well-suited for detecting transient couplings. Our work opens up a number of exciting future directions, such as extension to non-Markovian environments where memory effects play a crucial role in hybrid system dynamics. Additionally, adapting the protocol for real-time Hamiltonian tracking could enable its application in quantum sensing and feedback control in noisy intermediate-scale quantum (NISQ) devices.


\textit{Acknowledgement}.---The authors thank Yu Tong and Yukai Wang for valuable discussion. This work used computational and storage services associated with the Hoffman2 Cluster which is operated by the UCLA Office of Advanced Research Computingâ€™s Research Technology Group.


\bibliography{main}

\bibliographystyle{apsrev4-1}


\appendix 


\clearpage

\onecolumngrid
\begin{center}
	\noindent\textbf{Supplementary Material}
	\bigskip
		
	\noindent\textbf{\large{}}
\end{center}




\onecolumngrid

\section{Random Unitary Tranformations}
Here, we provide detailed description of the random unitary transformation (RUT) algorithm. Let ${\hat H}$ be arbitrary Hamiltonian, and $\tau \equiv t/R$, we have:
\begin{eqnarray}\label{sup_insert}
e^{-i{\hat H}^{(R)}t} = \prod_{i}^{R}{\mathbb U}^\dagger(\boldsymbol \theta_i) e^{-i{\hat H}\tau} {\mathbb U}(\boldsymbol \theta_i) \approx   {\rm exp}[-it \sum_{i=1}^{R}{\mathbb U}^\dagger(\boldsymbol \theta_i){\hat H}{\mathbb U}(\boldsymbol \theta_i)] \approx  {\rm exp}[-\frac{it}{ V(\boldsymbol{\theta})}\int_{\Omega} d{\boldsymbol{\theta}} {\mathbb U}^\dagger(\boldsymbol \theta){\hat H}{\mathbb U}(\boldsymbol \theta)
\end{eqnarray}
where ${\boldsymbol{\theta}} \equiv (\theta_1, \theta_2, ..., \theta_j)$ represents all $\theta_j$ that parameterize the unitary sequence ${\mathbb U}$. $\theta_j$ are sampled from independent uniform distribution $\mathcal{U}_j$, and $\Omega$ is the sampling domain of $\boldsymbol{\theta}$ with volume $V(\boldsymbol{\theta})$. We define the effective Hamiltonian at the limit $R \rightarrow \infty$:
\begin{eqnarray}
\hat{\mathcal H} \equiv {\hat H}^{(R=\infty)} = 
\frac{1}{V(\boldsymbol{\theta}) }\int d{\boldsymbol{\theta}} {\mathbb U}^\dagger(\boldsymbol \theta){\hat H}{\mathbb U}(\boldsymbol \theta)
 \end{eqnarray}
However, when $R \neq \infty$, deviation occurs between ${\hat H}^{(R)}$ and $\hat{\mathcal H}$. The deviation can be contributed to two types of error. At the first approximation sign in Eq.~\ref{sup_insert}, trotter error is introduced as the commutator $[{\mathbb U}(\boldsymbol{\theta}_{i1}),{\mathbb U}(\boldsymbol{\theta}_{i2})] \neq 0$. At the second approximation sign in Eq.~\ref{sup_insert}, Monte-Carlo error is introduced by approximating the continuous integral with a finite number of samples. However, when $R \rightarrow \infty$, the both of the errors vanish.

By choosing different forms of ${\mathbb U}(\boldsymbol \theta)$, different terms in ${\hat H}$ can be integrated out in $\hat{\mathcal H}$ based on their symmetry. In the manuscript, the first unitary sequence used in the reshaping process is $\mathbb{U}^{(1)} = \prod_n^{N_b} e^{-i \theta {\hat b}_n^\dagger {\hat b}_n}$. The reshaping mechanism of $\mathbb{U}^{(1)}$ relies on the following equation~\cite{Haoya2023}:
\begin{eqnarray}\label{boson random}
e^{i \theta {\hat b}_n^\dagger {\hat b}_n} {\hat b_n} e^{-i \theta {\hat b}_n^\dagger {\hat b}_n} = e^{-i\theta}{\hat b_n},~~~ e^{i \theta {\hat b}_n^\dagger {\hat b}_n^\dagger} {\hat b_n} e^{-i \theta {\hat b}_n^\dagger {\hat b}_n} = e^{i\theta}{\hat b_n}
\end{eqnarray}
which be derived by applying $e^{i \theta {\hat b}_n^\dagger {\hat b}_n} {\hat b_n} e^{-i \theta {\hat b}_n^\dagger {\hat b}_n}$ on arbitrary fock state $\ket{n}$. For example, for ${\hat b}_n$ we have:
\begin{eqnarray}
e^{i \theta {\hat b}_n^\dagger {\hat b}_n} {\hat b_n} e^{-i \theta {\hat b}_n^\dagger {\hat b}_n}\ket{m} = e^{i \theta (m-1)}\sqrt{m}e^{-i \theta m}\ket{m-1} = e^{-i\theta}\sqrt{m}\ket{m-1}  = e^{-i\theta}{\hat b}_n\ket{m}
\end{eqnarray}
If we choose $\theta$ from uniform distribution $\mathcal{U}(0,2\pi)$, terms in ${\hat H}$ that contains ${\hat b}_n$ or ${\hat b}_n^\dagger$ will be canceled out, as $\int_0^{2\pi} e^{\pm i \theta} d\theta = 0$.

The second unitary used in the manuscript is:
\begin{eqnarray}
\mathbb{U}^{(2)}_b = \prod_{j}^{N_q} U_j~~{\rm with}~~ U_{j}= 
    \begin{cases}
        e^{-i\theta_{j}\mathcal{P}_j^{b}} & \text{if } j \in {\rm supp}({\hat E}_{b})\\
        e^{-i\theta_{j}\mathcal{P}_j }e^{-i\phi_j\mathcal{P}_j^\prime} & \text{if } j \not\in {\rm supp}({\hat E}_{b})
    \end{cases}
\end{eqnarray}
where ${\hat E}_b$ is a pre-selected Pauli string with $|{\rm supp}({\hat E}_{b})| = k$. $\mathcal{P}_j^{b}$ refers to the $j^{th}$ operator of Pauli string $E_{b}$. $\mathcal{P}_j$ and $\mathcal{P}_j^{\prime}$ are arbitrary Pauli operators satisfying $[\mathcal{P}_j, \mathcal{P}_j^{\prime}] \neq 0$.  The reshaping mechanism of $\mathbb{U}^{(2)}_b$ relies on the commutation relationship of Pauli operators. Consider the action of $e^{-i\theta_{j}\mathcal{P}_j^{b}}$ on an arbitrary Pauli operator $\mathcal{P}_j$, we have:
\begin{eqnarray}\label{pauli random}
e^{i\theta_{j}\mathcal{P}_j^{b}} \mathcal{P}_j e^{-i\theta_{j}\mathcal{P}_j^{b}} = 
    \begin{cases}
        [e^{2i\theta_j}(\mathcal{P}_j + \epsilon \mathcal{P}_j^{\prime}) + e^{-2i\theta_j}(\mathcal{P}_j - \epsilon \mathcal{P}_j^{\prime})]/2 & \text{if } \mathcal{P}_j^{b} \neq  \mathcal{P}_j\\
        \mathcal{P}_j^{b} & \text{if } \mathcal{P}_j^{b} =  \mathcal{P}_j
    \end{cases}
\end{eqnarray}
where $\epsilon \equiv \epsilon({\mathcal{P}_j^b, \mathcal{P}_j, \mathcal{P}_j^{\prime}})$ is the Levi-Civita symbol, where we choose $\{\mathcal{P}_j^b, = 1; \mathcal{P}_j = 2; \mathcal{P}_j^{\prime} = 3\}$. Again, let $\theta_j \sim \mathcal{U}_j(0, \pi)$, any terms in $\hat H$ that contains $\mathcal{P}_j$ will be canceled out unless $\mathcal{P}_j^b =  \mathcal{P}_j$. Therefore, the collective behavior of $U_j$ acting on an arbitrary Pauli string ${\hat E}_a$ can be concluded as:
\begin{enumerate}
  \item If $j \in {\rm supp}({\hat E}_{b})$ and  $\mathcal{P}_j^a = \mathcal{P}_j^{b}/ \mathcal{I}$, ${\hat E}_a$ is kept as $U_j^\dagger \mathcal{P}_j^a U_j = \mathcal{P}_j^a$. 
  \item If $j \in {\rm supp}({\hat E}_{b})$ and  $\mathcal{P}_j^a \neq \mathcal{P}_j^{b}/ \mathcal{I}$, ${\hat E}_a$ is canceled due to the extra phase factor.
  \item If $j \not\in {\rm supp}({\hat E}_{b})$, ${\hat E}_a$ is canceled unless $\mathcal{P}_j^a = \mathcal{I}$
\end{enumerate}
As $\mathbb{U}^{(2)}_b$ includes $U_{j}$ across all qubits, reshaping the spin-part of $\hat{\mathcal H}^{(1)}$ with leads $\mathbb{U}^{(2)}_b$ to $\hat{\mathcal H}_{\rm S}^{(2)}$, where only Pauli strings in set $S_b$ are kept in the effective Hamiltonian.

\section{Estimation error propagation}
As described in the manuscript, we use ${\tilde \omega}_n$ as the input of the trotter-based scheme and DQS-based scheme. However, ${\tilde \omega}_n$ deviates from its actual value $\omega_n$ by $\epsilon({ \omega}_n)$, which leads to the propagation of error in our learning protocol. Here, we prove that this error can be suppressed while maintaining the Heisenberg limit. The effective time evolution of the bosonic wavefunction is: 
\begin{eqnarray}\label{sup_displacement}
\ket{\Psi_{\rm B}(t)}_l =  \prod_n{\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\omega_{n}}(e^{i\omega_{n} t} - 1)) \ket{\bf 0} 
\end{eqnarray}
For the DQS-based scheme, we measure the entangled wavefunction at $t = \pi/{\tilde \omega}_n$. Start from Eq.~\ref{Supp_Entangled_displacement}, we swap $t$ with $\pi/{\tilde \omega}_n$. Taylor expansion on error term leads to:
\begin{eqnarray}
\ket{\Psi_{\rm B}^{\rm ent}(\pi/{\tilde \omega}_n)}_l &=&  \prod_n{\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\omega_{n}}(e^{i\pi \omega_n/{\tilde \omega}_n} - 1)) S_{n}^{(W)}(e^{2i\pi \omega_n/{\tilde \omega}_n}z) \ket{\bf 0}  \nonumber \\
&=&  \prod_n{\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\omega_{n}}(-2+e^{i\pi \epsilon({ \omega}_n)/{\tilde \omega}_n} )) S_{n}^{(W)}(e^{2i\pi \epsilon({ \omega}_n)/{\tilde \omega}_n}z)\ket{\bf 0} \nonumber \\
&=&  \prod_n{\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\omega_{n}}(-2+\mathcal{O}[\epsilon({ \omega}_n)])) S_{n}^{(W)}(z+\mathcal{O}[\epsilon({ \omega}_n)])\ket{\bf 0} \nonumber \\
\end{eqnarray}
where ${\hat S}_{n}^{(W)} \equiv {\rm exp}[\frac{1}{2}(z^\ast {\hat B}_{n}^2 - z {\hat B}_{n}^{\dagger 2})]$ is the entangled squeezing operator with ${\hat B}_n \equiv \sum_{w=1}^{W} {\hat b_{n, w}} / \sqrt{W}$.  As error in squeezing parameter does not affect the mean value of displacement, choosing ${\tilde{\mathcal X}}_n \equiv \sum_{w=1}^W \langle{\hat X_{n, w}}\rangle/W$ as the displacement estimator leads to
\begin{eqnarray}
\mathbb{E}[{\tilde{\mathcal X}}_n] &=& -\frac{4\Lambda_{b,l}^n}{\omega_n} + \mathcal{O}[\epsilon({ \omega}_n)]
\end{eqnarray}
where $\mathcal{O}[\epsilon({ \omega}_n)]$ is a biased error. according to the error propagation formula we have:
\begin{eqnarray}
{\rm Var}[\Lambda_{b,l}^n] &=& \frac{\omega_n^2({\rm Var}[{\tilde{\mathcal X}}_n] + \mathcal{O}[\epsilon({ \omega}_n)^2])}{16} - \frac{[\Lambda_{b,l}^{n}]^2{\rm Var}[\omega_n]}{\omega_n^2} \nonumber \\
\end{eqnarray}
As can be seen from Eq.~\ref{DQS}, the error in the squeezing parameter only affects the overhead of the scaling as long as $n_{\rm pt}$ is fixed. Therefore ${\rm Var}[{\tilde{\mathcal X}}_n] \sim \mathcal{O}(T^{-2})$. Moreover, as $\epsilon({ \omega}_n) \sim \mathcal{O}(T^{-1})$, we can conclude that ${\rm Var}[\Lambda_{b,l}^n] \sim \mathcal{O}(T^{-2})$. Therefore, $\epsilon(\Lambda_{b,l}^n) \sim \mathcal{O}(T^{-1})$, which achieves the Heisenberg limit.

For the trotter-based scheme, we insert $\mathbb{U}^{(3)}$ during the reshaping process to cancel $\omega_n$. After canceling $\omega_n$ with ${\tilde \omega}_n$, the error $\epsilon({ \omega}_n)$ can be analyzed by swapping $\omega_n$ with $\epsilon({ \omega}_n) = |{\omega}_n - {\tilde \omega}_n|$ in Eq.~\ref{sup_displacement}. Taylor expansion of the error term leads to:
\begin{eqnarray}
\ket{\Psi_{\rm B^\ast}(t)}_l &=&  \prod_n{\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\epsilon({ \omega}_n)}(e^{i\epsilon({ \omega}_n) t} - 1)) \ket{\bf 0} \nonumber \\
&=&\prod_n{\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\epsilon({ \omega}_n)}(i\epsilon({ \omega}_n) t + \mathcal{R}_2[\epsilon(\omega_n)]) \ket{\bf 0} \nonumber \\
&=&\prod_n{\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\epsilon({ \omega}_n)}(i\epsilon({ \omega}_n) t + \mathcal{R}_2[\epsilon(\omega_n)]) \ket{\bf 0} \nonumber \\
&=& \prod_n{\hat D}_{n}(i\Lambda_{b,l}^n t + \frac{\Lambda_{b,l}^n\mathcal{R}_2[\epsilon({ \omega}_n)]}{\epsilon({ \omega}_n)}) \ket{\bf 0}
\end{eqnarray}
where $\mathcal{R}_2[\epsilon({ \omega}_n)]$ is the remainder for the first-order taylor expansion. As $\mathcal{R}_2[\epsilon({ \omega}_n)] \sim \mathcal{O}[\epsilon({ \omega}_n)^2]$, we have $\frac{\Lambda_{b,l}^n\mathcal{R}_2[\epsilon({ \omega}_n)]}{\epsilon({ \omega}_n)} \sim \mathcal{O}[\epsilon({ \omega}_n)^1]$. The homodyne measurement on the momentum quadrature is $\langle \hat P_n \rangle = \sqrt{2}\Lambda_{b,l}^n t + \frac{\Lambda_{b,l}^n\mathcal{R}_2[\epsilon({ \omega}_n)]}{\epsilon({ \omega}_n)}$, which includes the error introduced by ${\tilde \omega}_n$. However, RFE tolerates a maximum failure probability $\delta_{\rm max}$ inherently\cite{Haoya2023}. Suppose the maximum evolution time used in RFE is $2^\mathfrak{K^\ast}$, as long as $\frac{\Lambda_{b,l}^n\mathcal{R}_2[\epsilon({ \omega}_n)]}{\epsilon({ \omega}_n)} \le \delta_{\rm max}(\mathfrak{K^\ast})$ at $t = 2^\mathfrak{K^\ast}$, RFE can be successfully implemented. Although higher $\epsilon({ \omega}_n)$ would decrease the SPAM error tolerance of the trotter-based scheme, it still achieves the Heisenberg limit.

\section{Extraction of $\Xi_{b,l}$ using robust phase estimation}
The general Hamiltonian considered in this paper is:
\begin{eqnarray}\label{sup_genH}
{\hat H} = {\hat H}_{\rm spin} + {\hat H}_{\rm boson} + {\hat H}_{\rm int}
\end{eqnarray}
where ${\hat H}_{\rm spin} = \sum_a \xi_a E_a$, ${\hat H}_{b} = \sum_n \omega_n {\hat b}_n^\dagger {\hat b}_n$ and ${\hat H}_{\rm int} = \sum_{n,a} \lambda_a^n E_a({\hat b}_n^\dagger + {\hat b}_n)$.  ${\hat H}_{\rm spin}$ and the spin part of ${\hat H}_{\rm int}$ are considered to be general $k-$local spin Hamiltonians. Therefore, summation over $a$ goes up to $4^k{{N_q}\choose{k}}$. Among them, there are at most $3^k{{N_q}\choose{k}}$ terms with their support equalt to $k$. Therefore, the number of ${\hat E}_{b}$ allowed given $k$ and $N_q$ is $3^k{{N_q}\choose{k}}$. For each ${\hat E}_{b}$, the number of eigenstates is $2^k$, as each pauli operator has two eigenstates, each with eigenvalue $\pm 1$. We label the eigenstates of ${\hat E}_{b}$ as $\ket{E_{b}}_l$. 

Here, we first demonstrate the extraction of $\Xi_{b, l}$ using the robust phase estimation (RPE)~\cite{Shelby2015}. Reshaping ${\hat H}$ with  $\mathbb{U}^{(1)}$ and $\mathbb{U}_b^{(2)}$ gives $\hat{\mathcal H}^{(2)}_{\rm SB}$, which takes the form of:
\begin{eqnarray}\label{Eff_Spin_H1}
\hat{\mathcal H}^{(2)}_{\rm SB} = \sum_n^{N_b}\Big\{\sum_{s: {\hat E}_s \in S_{b}} [\xi_s + \lambda_s^n({\hat b}_{n}^\dagger + {\hat b}_{n}) ] {\hat E}_s + \omega_n {\hat b}_n^\dagger {\hat b}_n \Big\} \nonumber ,~~{\rm where}~~ S_{b} = \left\{ \prod_{ i \in \mathrm{supp}({\hat E}_{b})} \mathcal{P}_i^s \;\middle|\; \mathcal{P}_i^s \in \{ \mathcal{P}_i^{b}, \mathcal{I} \} \right\}
\end{eqnarray}
The eigenvalue of $\ket{{\hat E}_{b}}_l$ with respect to $\hat{\mathcal H}^{(2)}_{\rm SB}$ is equal to $\Xi_{b,l} \equiv \sum_s \gamma_l^s \xi_s$, where $\gamma_l^s$ is the eigenvalue of $\ket{{\hat E}_{b}}_l$ with respect to to ${\hat E}_s$. To implement RPE, we follow~\cite{Hsin2023} and prepare two entangled states that are linear combinations of a pair of $\ket{{\hat E}_{b}}_l$: 
\begin{eqnarray}\label{sup_RPE_state}
\ket{{\Psi}_{\rm ent}^{1}} = \frac{1}{\sqrt{2}}(\ket{{\hat E}_{b}^{l_1}} + \ket{{\hat E}_{b}^{l_2}}) ,~~~\ket{{\Psi}_{\rm ent}^{2}} = \frac{1}{\sqrt{2}}(\ket{{\hat E}_{b}^{l_1}} + i\ket{{\hat E}_{b}^{l_2}})
\end{eqnarray}

Evolving $\ket{{\Psi}_{\rm ent}^{1}}$ and $\ket{{\Psi}_{\rm ent}^{2}}$ in time allows us to measure the phase difference between them. Let $\Delta \Xi \equiv \Xi_{b, l1} - \Xi_{b, l2}$, we have:
\begin{eqnarray}
\bra{{\Psi}_{\rm ent}^{1}}  e^{-it \hat{\mathcal H}^{(2)}_{\rm SB}} \ket{{\Psi}_{\rm ent}^{1}} = \frac{1 + {\rm cos}(\Delta \Xi t)}{2}, ~~~\bra{{\Psi}_{\rm ent}^{2}}  e^{-it \hat{\mathcal H}^{(2)}_{\rm SB}} \ket{{\Psi}_{\rm ent}^{2}} = \frac{1 + {\rm sin}(\Delta \Xi t)}{2}
\end{eqnarray}
which allows direct implementation of RPE to find $\Delta \Xi$ at Heisenberg limit. Repeating this procedure for all pairs of $\ket{{\hat E}_{b}}_l$ allows us to solve for all $\Xi_{b, l}$ simultaneously.

\section{Proof of the applicability of robust frequency estimation}
To implement RFE for the trotter-based scheme, we construct a signal $\mathcal{Z}(t) = e^{-i \langle \hat P_n \rangle}$, where $\mathbb{E}[\langle \hat P_n \rangle] = \sqrt{2}{\Lambda}_{b,l}^n t$ with ${\rm Var}[\langle \hat P_n \rangle] = 1$.  To prove that RFE can be applied, signal $\mathcal{Z}$ must satisfy the following conditions~\cite{Haoya2023}(we removed the extra phase $f(t)$ in $\mathcal{Z}(t)$):
\begin{enumerate}
  \item $|\mathcal{Z}(t)| = 1$ 
  \item $|\mathcal{Z}(t) - e^{-i\mathbb{E}[\langle \hat P_n \rangle]}| \le \eta$ with probability at least 1-$\delta$
  \item Generating such $\mathcal{Z}(t)$ requires a evolution time of $\mathcal{O}[t( {\rm log}(\delta^{-1})]$
\end{enumerate}
As the first condition is straightforward, we here prove that the second and the third condition are satisfied. Firstly, consider a failure probability $\delta$ such that ${\Pr}(|\langle \hat P_n \rangle - \mathbb{E}[\langle \hat P_n \rangle]|\ge \eta) = \delta$. Assume $\langle \hat P_n \rangle$ follows a normal distribution with $\mu = \mathbb{E}[\langle \hat P_n \rangle]$ and $\sigma^2 = 1/M$, where $M$ is the number of measurement (as a result of central limit theorem), we have:
\begin{eqnarray}
\delta &=& {\Pr}(|\langle \hat P_n \rangle - \mathbb{E}[\langle \hat P_n \rangle]|\ge \eta)  \nonumber \\
&=& 2{\Pr}(X \ge \eta\sqrt{M})  \nonumber \\
&=& 2\mathcal{Q}(\eta \sqrt{M}) \le 2e^{-\eta^2M/2}
\end{eqnarray}
where $X = \sqrt{M}(\langle \hat P_n \rangle - \mathbb{E}[\langle \hat P_n \rangle])$ is the standard normal variable. $\mathcal{Q}(x)$ is the Q-function. In the last line we have used the Chernoff bound for Q-function. Inverse the above equation gives: $M \le \frac{2{\rm ln}(10)}{\eta^2}{\rm log}(\frac{2}{\delta})$. If a evolution time $t$ is required for a measurement, then the total evolution time to have ${\Pr}(|\langle \hat P_n \rangle - \mathbb{E}[\langle \hat P_n \rangle]|\ge \eta) = \delta$ is $t\frac{2{\rm ln}(10)}{\eta^2}{\rm log}(\frac{2}{\delta}) = \mathcal{O}[t( {\rm log}(\delta^{-1})]$. If $M$ is large, we can assume $\langle \hat P_n \rangle \approx\mathbb{E}[\langle \hat P_n \rangle]$, which gives:
\begin{eqnarray}
|\mathcal{Z}(t) - e^{-i\mathbb{E}[\langle \hat P_n \rangle]}| &=& |e^{-i(\langle \hat P_n \rangle)}-e^{-i(\mathbb{E}[\langle \hat P_n \rangle])}| \nonumber\\
&=& |e^{-i(\langle \hat P_n \rangle-\mathbb{E}[\langle \hat P_n \rangle])}-1| \nonumber \\
&\approx& |-i(\langle \hat P_n \rangle-\mathbb{E}[\langle \hat P_n \rangle])| \nonumber \\
&=&|\langle \hat P_n \rangle-\mathbb{E}[\langle \hat P_n \rangle]| \le \eta
\end{eqnarray}
Therefore, generate a signal $\mathcal{Z}(t)$ that satisfies ${\rm Pr}(|\mathcal{Z}(t) - e^{-i\mathbb{E}[\langle \hat P_n \rangle]}| \le \eta) = 1-\delta$ would take a total evolution time of $\mathcal{O}[t( {\rm log}(\delta^{-1})]$, which proves the applicability of RFE in the trotter-based scheme. Implementing RFE allows us to obtain $\sqrt{2}{\Lambda}_{b,l}^n$, and therefore ${\Lambda}_{b,l}^n$ at Heisenberg limit.

\section{Solving Hamiltonian coefficients with linear equations}

Now that all $\Lambda_{b, l}^n$ and $\Xi_{b, l}$ are obtained, we wish to find the Hamiltonian coefficients $\lambda_s^n$ and $\xi_s$. As the form of ${\hat E}_b$ is pre-determined, $\gamma_l^s$, which refers to the eigenvalue of $\ket{{\hat E}_{b}}_l$ with respect to ${\hat E}_s$, are also determined. As discussed in the manuscript, $s$ indexes the elements in $S_b$, which goes up to $2^k$ as $|S_b| = 2^k$. Similarly, $l$ indexes the ${\hat E}_b$ eigenstates, which also goes up to $2^k$. For a specific Pauli string ${\hat E}_b$, let $C_l = \Lambda_{b, l}^n$ or $\Xi_{b, l}$, and $c_l = \lambda_s^n$ or $\xi_s$, respectively. Looping over all $s$ and $l$ gives:
\begin{eqnarray}
\begin{bmatrix}
\gamma_{1}^{1} & \gamma_{1}^{2} & ... & \gamma_{1}^{2^k} \\
\gamma_{2}^{1} & \gamma_{2}^{2} & ... & \gamma_{2^k}^{2^k} \\
\vdots & \vdots & \vdots & \vdots\\
\gamma_{2^k}^{1} & \gamma_{2^k}^{2} &  ... & \gamma_{2^k}^{2^k}
\end{bmatrix}
\begin{bmatrix}
c_1 \\
c_2 \\
\vdots \\
c_{2^k}
\end{bmatrix}
=
\begin{bmatrix}
C_1 \\
C_2 \\
\vdots \\
C_{2^k}
\end{bmatrix}.
\end{eqnarray}
where each row corresponds to index $s$, and each column corresponds to index $l$. Here, $\gamma_l^s$ forms an orthogonal basis set $\{-1, +1\}^k$, which makes the square matrix on the left hand side of the equation orthogonal. This allows us to find $c_l$ given all the $C_l$ without propagating the error.

\section{Deviation from effective dynamics}
Due to the finiteness of $R$ in experiment, the actual dynamic deviates from the ideal one due to trotter error and Monte-Carlo error. This deviation is quantitatively described by $||\Delta \rho||_1 = || {\hat H}^{(R)} - {\hat H}^{(\infty)}||_1$, which is the trace distance between the ideal density matrix and the actual one. $||\Delta \rho||_1$ can be written as:
\begin{eqnarray}
|| \Delta \rho ||_1 &=& || e^{-i\hat{\mathcal H} t }\rho(0)e^{i\hat{\mathcal H} t } - Q_R \rho(0) Q_R^\dagger ||_1 
\end{eqnarray}
where $\rho(0)$ is the density matrix of the system at $t=0$. $Q_N$ represents the unitary sequence inserted during the reshaping process. $\hat{\mathcal H}$ is the effective Hamiltonian. By definition, $e^{-i\hat{\mathcal H}t} = Q_{\infty}$. The form of $Q_P$ varies from learning one term to another. In general, $Q_P$ takes the form of:
\begin{eqnarray}
Q_R = \prod_{i=1}^R [\mathbb{U}^{\rm left}(\boldsymbol \theta_i)]^\dagger e^{-i{\hat H}\tau}\mathbb{U}^{\rm right}(\boldsymbol \theta_i)
\end{eqnarray}
where ${\hat H}$ is the general Hamiltonian in Eq.~\ref{sup_genH}. Note that $\mathbb{U}^{\rm left} = \mathbb{U}^{\rm right}$ is true for all parts of our algorithm, except for the trotter-based scheme in learning the spin-boson coupling coefficients, where ${\mathbb U}^{(3)}$ is only included in $\mathbb{U}^{\rm right}$

When $\mathbb{U}^{\rm left} = \mathbb{U}^{\rm right}$, proof process in~\cite{Haoya2023} can be implemented on the premise of the following equations:
\begin{eqnarray}\label{Sup_Hphi}
|| {\hat H} \ket{\Psi} ||_2 \sim \mathcal{O}(1), ~~~ || {\hat H}^2 \ket{\Psi} ||_2 \sim \mathcal{O}(1)
\end{eqnarray}
where $\ket{\Psi} = \ket{\Psi_{\rm S}} \otimes \ket{\Psi_{\rm B}}$ is any state that could appear during the actual time evolution. To prove Eq.~\ref{Sup_Hphi}, we have: 
\begin{eqnarray}
&&|| {\hat H} \ket{\Psi} ||_2 \nonumber \\
&&= ||\Big[{\hat H}_{\rm spin} + {\hat H}_{\rm boson} + {\hat H}_{\rm int} ] \Big] \ket{\Psi} ||_2 \nonumber \\
&&\le  \sum_a \Big\{\xi_a||{\hat E}_a \ket{\Psi_s} ||_2 +  \sum_n^{N_b}\Big[\lambda_a^n|| [{\hat E}_a \ket{\Psi_s} ||_2 \cdot ||({\hat b}_n^\dagger + {\hat b}_n) \ket{\Psi_b}||_2 + \omega_n || {\hat b}_n^\dagger {\hat b}_n  \ket{\Psi_b} ||_2\Big] \Big \} \nonumber \\
&&\le N_q^k {\rm max}\{\xi_a\} + N_b \Big[N_q^k  {\rm max}\{\lambda_a^n\} \sqrt{2|\alpha|^2 + 2{\rm Re}(\alpha^2) + 1} + {\rm max}\{ \omega_n \} |\alpha|^2\Big] \nonumber \\
&&\le N_b N_q^k {\rm max}\{|\alpha|\}^2 {\rm max}\{ \xi_a, \lambda_a^n, \omega_n \}
\end{eqnarray}
Note that we have approximated $\ket{\Psi_{\rm B}}$ as a coherent state. Since in the above equation, all variables scale with $\mathcal{O}(1)$ ($\alpha$ only scales with time in the trotter-based scheme, which is not considered here), we conclude $|| {\hat H} \ket{\Psi} ||_2 \sim \mathcal{O}(1)$. Similarly, for $|| {\hat H}^2 \ket{\Psi} ||_2$, the number of term is squared in comparison to $|| {\hat H} \ket{\Psi} ||_2$. For the term with the largest norm, due to the presence of $({\hat b}_n^\dagger {\hat b}_n)^2$ in ${\hat H}^2$ , the maximum coefficient induced by bosonic operators is given by ${\rm max}\{ |\alpha_n| \}^4$. Similarly, the maximum coefficient induced by spin operators is given by $[{\rm max}\{ |\lambda_s^a|, |\lambda_n^a|, |\omega_n| \}]^2$. Therefore, the following upper bound is established:
\begin{eqnarray}
|| {\hat H}^2 \ket{\Psi} ||_2 &&\le [N_b N_q^k {\rm max}\{|\alpha|\}^2 {\rm max}\{ \xi_a, \lambda_a^n, \omega_n \}]^2
\end{eqnarray}
which remains bounded by $\mathcal{O}(1)$. This allows us to confirms Eq.~\ref{sup_Hphi}, thereby applying the same methodology as in~\cite{Haoya2023} to establish the upper bound for $||\Delta \rho||_1$, which scales as $\mathcal{O}(t^2/R)$.

\begin{figure}[t]
\centerline{\includegraphics[width=120mm]{trace_distance.png}}
\caption{The variance and mean value of trace distance $||\Delta \rho||_1$ are plotted against $\tau$ and $R\tau = t$}
\label{trace_distance}
\end{figure}

However, the above proof fails for the trotter-based scheme in learning spin-boson coupling terms, where $\mathbb{U}^{\rm left} = \mathbb{U}^{\rm right}$. The failure can be attributed to two reasons: 1. The ideal bosonic state is a coherent state with $\alpha \sim \mathcal{O}(t)$. 2. Insering of $\mathbb{U}^{(3)}$ introduces a constant error in the first-order term of $||\Delta \rho||_1$, which fails to prove $||\Delta \rho||_1 \rightarrow 0$ when $R \rightarrow \infty$. Therefore, to quantify the deviation scaling in this case, we numerically plot ${\rm Mean}[|| \Delta \rho ||_1]$ and ${\rm Var}[|| \Delta \rho ||_1]$ with respect to $\tau$ and $t$ in Fig.~\ref{trace_distance}. 1000 sets of $Q_R$ are generated for each subplots to ensure convergence. In the left subplot, $t$ is held constant while $\tau$ is choosen from $10^-4$ to  $10^-3$. Similarly, in the right subplot, $\tau$ is kept at $10^-3$ while $t$ is choosen from $0$ to $10$.  It is observed that ${\rm Mean}[|| \Delta \rho ||_1] \propto \sqrt{{\rm Var}[|| \Delta \rho ||_1]} \propto \sqrt{t}$ at constant $\tau$, and ${\rm Mean}[|| \Delta \rho ||_1] \propto \sqrt{{\rm Var}[|| \Delta \rho ||_1]} \propto \sqrt{\tau}$ at constant $t$. Therefore, the following conclusion can be drawn:
 \begin{eqnarray}
{\rm Mean}[|| \Delta \rho ||_1] \propto \sqrt{{\rm Var}[|| \Delta \rho ||_1]}   \propto \sqrt{t\tau} = t/\sqrt{R}
 \end{eqnarray}




\section{Derivation for Eq.~\ref{displacement}}
Here, we provide detailed derivation for Eq.~\ref{displacement} in the manuscript. The form of $\hat{\mathcal H}_{\rm SB}^{(2)}$ can be found from Eq.~\ref{Eff_Spin_H1}. If the wavefunction is initialized on $\ket{{\hat E}_b}_l\otimes\ket{\boldsymbol 0}$, the effective time evolution can be written as: 
\begin{eqnarray}
\ket{\Psi_{\rm B}(t)}_l &=& e^{-i \hat{\mathcal H}_{\rm SB}^{(2)}} \ket{{\hat E}_b}_l\ket{\boldsymbol 0} \nonumber \\
&=& \prod_n e^{-i[\Xi_{b,l} + \Lambda_{b,l}^n(\hat{b}_n^\dagger + \hat{b}_n) + \omega_n\hat{b}_n^\dagger\hat{b}_n ]} \ket{\boldsymbol 0}
\end{eqnarray}
where bosonic modes can separated. We define the effective bosonic Hamiltonian of the $n^{th}$ mode as:
\begin{eqnarray}
\hat{\mathcal H}_{\rm B}^{(2)} \equiv \prod_n[\Lambda_{b,l}^n(\hat{b}_n^\dagger + \hat{b}_n) + \omega_n\hat{b}_n^\dagger\hat{b}_n]
\end{eqnarray}
where the global phase $\Xi_{b,l}$ is omitted. To obtain the analytical formula in Eq.~\ref{displacement}, we explore the resolution of identity and insert $\prod_n{\hat D}_{n}^\dagger(\Lambda_{b,l}^n/\omega_{n}){\hat D}_{n}(\Lambda_{b,l}^n/\omega_{n})$, which yields:
\begin{eqnarray}\label{displacement_transformation}
\ket{\Psi_B(t)}_l &=& \prod_n[{\hat D}_{n}^\dagger(\frac{\Lambda_{b,l}^n}{\omega_{n}}){\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\omega_{n}})]e^{-i \hat{\mathcal H}_{\rm b}^{(2)}} \prod_{n^\prime}{\hat D}_{n}^\dagger(\frac{\Lambda_{b,l}^{n^\prime}}{\omega_{n^\prime}}){\hat D}_{n^\prime}(\frac{\Lambda_{b,l}^{n^\prime}}{\omega_{n^\prime}}) \ket{\boldsymbol 0} \nonumber \\
& = & \prod_n{\hat D}_{n}^\dagger(\frac{\Lambda_{b,l}^n}{\omega_{n}}) e^{-i \hat{\mathcal H}^{(n)}_{\rm b}t} \ket{\frac{\Lambda_{b,l}^n}{\omega_{n}}}
\end{eqnarray}
where:
\begin{eqnarray}
\hat{\mathcal H}^{(n)}_{\rm B} &=& {\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\omega_{n}}) \Big[ \frac{\Lambda_{b,l}^n}{\omega_{n}} + \frac{\Lambda_{b,l}^n}{\omega_{n}}({\hat b}_{n}^\dagger + {\hat b}_{n})+ \omega_n {\hat b}_n^\dagger {\hat b}_n \Big] {\hat D}^\dagger_{n}(\frac{\Lambda_{b,l}^n}{\omega_{n}}) \nonumber \\
&=&   \sum_n\Big\{\Lambda_{b,l}^n - \frac{[\Lambda_{b,l}^n]^2}{\omega_{n}} + \omega_n {\hat b}_n^\dagger {\hat b}_n \Big\}
\end{eqnarray}
which is a free-field Hamiltonian. As the time evolution of coherent state according to a free-field Hamiltonian is known analytically, starting from Eq.~\ref{displacement_transformation} we have:
\begin{eqnarray}
\ket{\Psi_{\rm B}(t)}_l &=& \prod_n{\hat D}_{n}^\dagger(\frac{\Lambda_{b,l}^n}{\omega_{n}}) e^{-it \hat{\mathcal H}^{(n)}_{\rm b}} \ket{\frac{\Lambda_{b,l}^n}{\omega_{n}}}  \nonumber \\
&=& \prod_n{\hat D}_{n}^\dagger(\frac{\Lambda_{b,l}^n}{\omega_{n}}) \ket{e^{i\omega_{n}t}(\frac{\Lambda_{b,l}^n}{\omega_{n}})}  \nonumber \\
&=& \prod_n\ket{\frac{\Lambda_{b,l}^n}{\omega_{n}}(e^{i\omega_{n}t} - 1)} 
\end{eqnarray}
which produces Eq.~\ref{displacement} in the manuscript. 

In the DQS-based scheme, we initialize the state on the entangled squeezed state $\ket{\Psi_b(0)}_{\rm ent} = \prod_n{\hat S}_{n}^{(W)}(z)\ket{\boldsymbol 0}$. Similar to Eq.~\ref{displacement_transformation}, the time evolution of $\ket{\Psi_b(0)}_{\rm ent}$ can be written as:
\begin{eqnarray}\label{Supp_Entangled_displacement}
\ket{\Psi_{\rm B}^{\rm ent}(t)} & = & \prod_n{\hat D}_{n}^\dagger(\frac{\Lambda_{b,l}^n}{\omega_{n}}) e^{-it \hat{\mathcal H}^{(n)}_{\rm b}} {\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\omega_{n}}) S_{n}^{(W)}(z)\ket{\boldsymbol 0} \nonumber \\
& = & \prod_n{\hat D}_{n}^\dagger(\frac{\Lambda_{b,l}^n}{\omega_{n}}) \Big[ e^{-it \hat{\mathcal H}^{(n)}_{\rm b}} {\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\omega_{n}}) e^{it \hat{\mathcal H}^{(n)}_{\rm b}}\Big]  \Big[e^{-it \hat{\mathcal H}^{(n)}_{\rm b}} S_{n}^{(W)}(z) e^{it \hat{\mathcal H}^{(n)}_{\rm b}}\Big]  e^{-it \hat{\mathcal H}^{(n)}_{\rm b}} \ket{\boldsymbol 0} \nonumber \\
& = & \prod_n{\hat D}_{n}^\dagger(\frac{\Lambda_{b,l}^n}{\omega_{n}}) {\hat D}_{n}(e^{i\omega_{n} t}\frac{\Lambda_{b,l}^n}{\omega_{n}}) S_{n}^{(W)}(e^{2i\omega_{n} t}z) \ket{\tilde 0} \nonumber \\
& = & \prod_n{\hat D}_{n}(\frac{\Lambda_{b,l}^n}{\omega_{n}}(e^{i\omega_{n} t} - 1)) S_{n}^{(W)}(e^{2i\omega_{n} t}z) \ket{\boldsymbol 0}
\end{eqnarray}
which is a displaced squeezed state that is entangled across all $W$ copies of systems. For the $n^{th}$ mode, at $t = \pi/\omega_{n}$, we have :
\begin{eqnarray}
\ket{\Psi_{{\rm B}, n}^{\rm ent}(\frac{\pi}{\omega_{n}})} = {\hat D}_{n}(-\frac{2\Lambda_{b,l}^n}{\omega_{m}}) S_{n}^{(W)}(z) \ket{\boldsymbol 0}
\end{eqnarray}
Therefore, the effect of $e^{-i\hat{\mathcal H}_{\rm SB}^{(2)}\pi/\omega_{m}}$ is equivalent to a field quadrature displacement operator with $\alpha = -\frac{2\Lambda_{b,l}^n}{\omega_{n}}$, which enables the implementation of DQS in~\cite{Quntao2018} to measure $\Lambda_{b,l}^n$ at Heisenberg limit.






\section{Discretization of spectral density function}
The spectral density function used in the numerical example is:
\begin{eqnarray}\label{sup_Jw}
J(\omega) = \sum_n (\Lambda_n)^2 \delta(\omega-\omega_n) = \frac{\eta \omega}{(\omega^2-\Omega^2)^2 + \gamma^2 \omega^2} \nonumber \\
\end{eqnarray}
To obtain $\Lambda_n$ and $\omega_n$ from $J(\omega)$, we first discretize the frequency domain $[0, \omega_{\rm cut}]$ (we use $\omega_{\rm cut} = 4$ in this work) into $N_b$ intervals $[\omega_{n^\prime}, \omega_{n^\prime +1}]$, where $n^\prime = 0, 1, ..., N_b - 1$. Integrating $J(\omega)$ via a coarse-grain method gives:
\begin{eqnarray}
(\Lambda_n)^2 = \int_{\omega_{k^\prime}}^{\omega_{k^\prime}+1} d\omega J(\omega),~~~~~~~\omega_n = \Big[\int_{\omega_{k^\prime}}^{\omega_{k^\prime}+1} d\omega J(\omega)\omega\Big]/(\Lambda_n)^2
\end{eqnarray}
which allows us to find $\Lambda_n$ and $\omega_n$ numerically.







\section{Pseudocode for Hamiltonian learning of hybrid quantum systems}
To present a more accessible description of the protocol introduced in the manuscript, we restate the algorithm in the format of pseudocode. Five functions are used in the pseudocode below: $\texttt{RUT}$ takes a Hamiltonian and a unitary sequence as inputs and return the reshaped Hamiltonian according to Eq.~\ref{sup_insert}. $\texttt{RPE}$, $\texttt{RFE}$ and $\texttt{DQS}$ takes a Hamiltonian (or a displacement channel), an initial state, and a target accuracy as inputs and return the learnt parameters. Readers are referred to ~\cite{Shelby2015}, ~\cite{Haoya2023}, and ~\cite{Quntao2018} for more information. $\texttt{SolveLE}$ takes a column array and a coefficient array and return the solution to the corresponding linear equation.

\begin{algorithm}
\caption{Learning pure spin and boson coefficients}
\KwIn{Unknown Hamiltonian $\hat H$, $k$, $N_q$, $N_b$, and target accuracy $\epsilon$
}
\KwOut{Estimation ${\tilde \xi}_a$, ${\tilde \omega}_n$}
Eb\_list $\leftarrow$ [All possible $\hat E_b$ with $|{\rm supp}(\hat {\hat E}_b)| = k$]\\
Construct $\mathbb{U}^{(1)}$ \\
$\hat{\mathcal H}^{(1)}$ $\leftarrow$ RUT($\hat H$, $\mathbb{U}^{(1)}$) \\
b\_states $\leftarrow$ $\prod_n D_n(\alpha) \ket{\boldsymbol{0}}$  \\
\For{$n$ \textbf{in} $1\colon N_b$}{
    ${\tilde \omega}_n$ $\leftarrow$ RFE($\hat{\mathcal H}^{(1)}$, b\_states, $\epsilon$)\\
}
\For{${\hat E}_b$ \textbf{in} \rm{Eb\_list}}{
    Construct $\mathbb{U}^{(2)}_b$ \\
    $\hat{\mathcal H}^{(2)}_s$ $\leftarrow$ RUT($\hat{\mathcal H}^{(1)}$, $\mathbb{U}^{(2)}_b$)\\
    Es\_list $\leftarrow$ [All elements in $S_b$] \\
    El\_list  $\leftarrow$ [All possible eigenstates of ${\hat E}_b$] \\
    ElPair\_list  $\leftarrow$ [All possible pairs of $\ket{E_b}_l$] \\
    \For{\rm{$\ket{E_b}_l$} \textbf{in} \rm{El\_list}}{
        \For{${\hat E}_s$ \textbf{in} \rm{Es\_list}}{
            Gamma\_list $\leftarrow$ Calculate $\gamma_s^l$ \\
        }

    }
    \For{\rm{ElPair} \textbf{in} \rm{ElPair\_list}}{
        s\_state $\leftarrow$  construct initial states with Eq.~\ref{sup_RPE_state}\\
        Phase\_list $\leftarrow$ RPE($\hat{\mathcal H}_{\rm S}^{(2)}$, s\_state, $\epsilon$)\\
        coeff\_list$\leftarrow$ [coefficients of ${\tilde \Xi}_{b,l}$ in Phase\_diff]\\
    }
    ${\tilde \Xi}_{b,l}$ $\leftarrow$ SolveLE(Phase\_list, coeff\_list) \\
    ${\tilde \xi}_a$ $\leftarrow$ SolveLE(All ${\tilde \Xi}_{b,l}$, Gamma\_list)\\

}
\label{algo:pure}
\end{algorithm}

\begin{algorithm}
\caption{Trotter-based scheme}
\KwIn{Unknown Hamiltonian $\hat H$, $k$, $N_q$, $N_b$, ${\tilde \omega}_n$ and target accuracy $\epsilon$}
\KwOut{Estimation ${\tilde \lambda}_a^n$}
Eb\_list $\leftarrow$ [All possible $\hat E_b$ with $|{\rm supp}(\hat {\hat E}_b)| = k$]\\
\For{${\hat E}_b$ \textbf{in} \rm{Eb\_list}}{
    Construct $\mathbb{U}^{(2)}_b$ \\
    $\hat{\mathcal H}_{\rm SB}^{(2)}$ $\leftarrow$ RUT($\hat H$, $\mathbb{U}^{(2)}$) \\
    Es\_list $\leftarrow$ [All elements in $S_b$] \\
    El\_list  $\leftarrow$ [All possible eigenstates of ${\hat E}_b$] \\
    \For{\rm{$\ket{E_b}_l$} \textbf{in} \rm{El\_list}}{
        \For{${\hat E}_s$ \textbf{in} \rm{Es\_list}}{
            Gamma\_list $\leftarrow$ Calculate $\gamma_s^l$ \\
        }

    }
    \For{\rm{$\ket{E_b}_l$} \textbf{in} \rm{El\_list}}{
        $\hat{\mathcal H}^{(n)}_b$ $\leftarrow$ Insert $\mathbb{U}^{(3)}$ following Eq.~\ref{insert}\\
        b\_states $\leftarrow$ $\ket{\boldsymbol{0}} = \ket{\rm vac}^{\otimes N_b}$ \\
        \For{$n$ \textbf{in} $1\colon N_b$}{
            $\Lambda_{b,l}^n$ $\leftarrow$ RFE($\hat{\mathcal H}^{(n)}_b$, b\_states, $\epsilon$)\\
        }
    }
    ${\tilde \lambda}_a^n$ $\leftarrow$ SolveLE($\Lambda_{b,l}^n$, Gamma\_list)\\
}
\label{algo:trotter}
\end{algorithm}

\begin{algorithm}
\caption{DQS-based scheme}
\KwIn{Unknown Hamiltonian $\hat H$, $k$, $N_q$, $N_b$, ${\tilde \omega}_n$, $z$, $W$ and target accuracy $\epsilon$}
\KwOut{Estimation ${\tilde \lambda}_a^n$}
Eb\_list $\leftarrow$ [All possible $\hat E_b$ with $|{\rm supp}(\hat {\hat E}_b)| = k$]\\
\For{${\hat E}_b$ \textbf{in} \rm{Eb\_list}}{
    Construct $\mathbb{U}^{(2)}_b$ \\
    $\hat{\mathcal H}_{\rm SB}^{(2)}$ $\leftarrow$ RUT($\hat H$, $\mathbb{U}^{(2)}$) \\
    Es\_list $\leftarrow$ [All elements in $S_b$] \\
    El\_list  $\leftarrow$ [All possible eigenstates of ${\hat E}_b$] \\
    \For{\rm{$\ket{E_b}_l$} \textbf{in} \rm{El\_list}}{
        \For{${\hat E}_s$ \textbf{in} \rm{Es\_list}}{
            Gamma\_list $\leftarrow$ Calculate $\gamma_s^l$ \\
        }

    }
    \For{\rm{$\ket{E_b}_l$} \textbf{in} \rm{El\_list}}{
        b\_states $\leftarrow$ construct an entangled state with $z$ and $W$ from Eq.~\ref{multimode_entangled} \\
        \For{$n$ \textbf{in} $1\colon N_b$}{
            $t^\ast$ $\leftarrow$ $\pi/ {\tilde \omega}_n$ \\
            $D$ $\leftarrow$ $e^{-i\hat{\mathcal H}_{\rm SB}^{(2)} t^\ast}$\\
            $\Lambda_{b,l}^n$ $\leftarrow$ DQS($D$, b\_states, $\epsilon$)\\

        }
    }
    ${\tilde \lambda}_a^n$ $\leftarrow$ SolveLE($\Lambda_{b,l}^n$, Gamma\_list)\\
}
    
\label{algo:trotter}
\end{algorithm}






\end{document}








