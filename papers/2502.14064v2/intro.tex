\section{Introduction}
\label{sec:intro}
Each year, over 40 million magnetic resonance imaging (MRI) scans are performed in the United States, an average of 107.5 scans per 1,000 persons~\cite{oecd_mri_units_2023,shah2023review}. Globally, the annual total of MRI scans ranges between 100 to 150 million~\cite{mri_number_worldwide}. 
%The increasing usage of MRI and the diversification of tasks bring new challenges to radiology residents, who are often required to make diagnoses in a short amount of time. Recent literature indicates that the National Resident Matching Program (NRMP) in the United States only offers 35,752 radiology residency positions through 2023~\cite{deng2023us}. With the current volume of medical imaging and the limited number of radiology residency positions, the burden on residents is undoubtedly enormous~\cite{blankemeier2024merlin}. 
This has led to a growing demand for automated analysis tools~\cite{https://doi.org/10.1002/mp.16844}. In recent years, Foundation Model (FM)-driven image analysis has shown significant advancements. However, these foundation models have primarily been tailored for general computer vision tasks and are trained on numerous natural image datasets to acquire general representations applicable to a wide range of data~\cite{Caron_2021_ICCV,he2022masked,oquab2023dinov2}. They can then be fine-tuned for various specific downstream tasks, leading to significant enhancements in performance across different applications. This paradigm shift has also been widely adopted in clinical modalities (including 2D and 3D data), which has demonstrated notable improvements~\cite{moor2023foundation,chen2024towards,Zhao2024,Safari_2024}.

\begin{figure}[t] 
	\centering
	\includegraphics[width=\textwidth]{overview.pdf}
	\caption{\textbf{Overview of Triad training and evaluation.} a. Triad pre-training strategy. Triad implements the reconstruction task based on autoencoders and uses L1 loss for optimization. Imaging descriptions are embedded into vector space to form a distribution, which serves as a supervisory signal to constrain the distribution of visual modalities using Log-ratio loss~\cite{kim2019deep}. The two losses are optimized simultaneously in a multi-task manner. Triad is then evaluated across within-domain tasks and out-of-domain tasks. These include within-domain 3D MRI segmentation, classification, and registration tasks (tasks b, c, and d). And unseen 3D CT/MRI segmentation, classification, and registration tasks (tasks e, f, and g).}
	\label{fig:overview} 
\end{figure}
\begin{figure}[!h] 
	\centering
	\includegraphics[width=\textwidth]{maindataset.pdf}
	\caption{\textbf{An overview of the Triad-131K pre-training dataset.} a. Describes the name and scale distribution of each dataset in Triad-131K. b. We compare the parameter scale and data scale used by Triad and existing foundation models, and it is obvious that Triad  surpasses the existing models on both scales. c. Shows examples of visual volumetric modality and textual modality in Triad-131K. d. Shows the dataset scale distribution of three organs: brain, breast, and prostate.}
	\label{fig:maindataset} 
\end{figure}


Currently, the potential of foundational models specifically for 3D MRI remains largely unexplored. There are two key limitations:
Firstly, although previous general medical foundation models assert the capability to generalize to 3D MRI, substantial differences in imaging principles, signal characteristics, and data distribution between other modalities and MRI may hinder their practical performance and generalizability in MRI-specific applications~\cite{perez2021torchio,cardoso2022monai,https://doi.org/10.1002/mp.17675}. For instance, notable general medical foundation models~\cite{wu2024voco,li2024well,tang2022self} have predominantly been pre-trained on 3D computed tomography (CT). Although some foundation models leverage mixed modalities during the pre-training phase, including MRI, CT, positron emission tomography, and microscopy~\cite{ye2024continual,gao2024training,isensee2021nnu}, there is extreme data imbalance across the imaging modalities. For example, MedCoSS~\cite{ye2024continual} relied on only 3,000 MRI scans, compared to 10,000 CT scans.
Secondly, while there have been attempts to develop 3D MRI-specific foundation models, these efforts have typically focused on data from a single organ~\cite{cox2024brainsegfounder, kim2023empirical}, primarily emphasizing on T1- (T1-w) and T2-weighted (T2-w) images while overlooking the additional information of other MRI sequences. For instance, Brainsegfounder~\cite{cox2024brainsegfounder} uses brain T1-w and T2-w images from approximately 80,000 healthy subjects for pre-training, followed by self-supervised fine-tuning on specific downstream datasets. Moreover, text-based reports~\cite{blankemeier2024merlin,zhang2024generalist}, which are commonly employed as auxiliary information in 3D CT pre-trained models, are often lacking for 3D MRI data, further limiting the development of comprehensive models.
Therefore, the main challenge in building a general 3D MRI vision foundation model is collecting and curating a sufficiently large and diverse dataset. This dataset must cover a wide range of imaging modalities and hardware specifications to ensure the robustness and generalizability of the model.

To address the above limitations, we introduce Triad${^\ddagger}$\footnote[0]{${\ddagger}$ In philosophy, a Triad refers to three closely related and inseparable elements. Here, it means that the vision foundation model trained on data from three organs can robustly generalize to downstream tasks involving other modalities and organs.}, a training strategy and general vision foundation model for 3D MRI. Triad is  trained on a large-scale dataset of 131,170 3D MRI derived from 19,721 patients across 36 clinical datasets. This comprehensive dataset, termed TriadMR-131K, encompasses a wide range of 3D MRI data from three organs: breast, brain, and prostate. It includes various imaging modalities such as  T1-w, T2-w, fluid-attenuated inversion recovery (FLAIR), diffusion-weighted imaging (DWI), functional MRI (fMRI), dynamic contrast-enhanced MRI (DCE-MRI).
As illustrated in Fig. \ref{fig:maindataset} (c), we have assigned an imaging description to each MRI volume, detailing the imaging modality and associated device parameters, which adds semantics across organs.
During pre-training, we adopt a widely used autoencoder architecture to learn robust representations from this extensive and diverse dataset. In addition, we leverage organ-independent imaging descriptions to constrain the semantic distribution of visual modalities. We pre-train encoders with varying parameter sizes (ranging from 31M to 11.8B) to accommodate downstream tasks of different scales.
During fine-tuning, we demonstrate our model's versatility by replacing the decoder with task-specific adapters tailored for various 3D MRI applications. These adapters include linear classifiers for disease diagnosis, convolutional decoders for organ/tumor segmentation, and upsampling decoders for recovering deformation fields in registration tasks.
Furthermore, we extend Triad to downstream tasks involving unseen 3D CT and MRI, which we refer to as out-of-domain tasks. Our findings indicate that by combining Triad with different adapters, we not only achieve state-of-the-art performance on various within-domain tasks but also significantly outperform baselines on multiple out-of-domain tasks.
These results highlight Triad's adaptability to downstream tasks, demonstrating its potential as a versatile and efficient tool for diverse clinical applications. This adaptability could pave the way for improving the performance of various clinical tasks applied to 3D MRI.
