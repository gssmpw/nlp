\section{Results}

We present results from 25 downstream datasets across three types of evaluation tasks and two data modality settings. These downstream tasks are categorized into within-domain and out-of-domain tasks.
Within-domain downstream tasks utilize the same data modalities and structures as those in the pre-training phase, including brain, breast, and prostate MRI. These tasks assess whether Triad has successfully learned structural and modality representations during pre-training, thereby improving performance on related tasks.
Conversely, out-of-domain downstream tasks involve data modalities or organs different from those in the pre-training stage, such as liver CT or atrial MRI. These tasks evaluate whether the knowledge acquired by Triad during pre-training can be effectively transferred to and applied in new modalities or structures.
Based on these two data modality settings, we evaluate three task types: 3D structure/tumor segmentation (Fig. \ref{fig:seg_enc_dec} and Fig. \ref{fig:seg_withoutdomain}), organ/cancer classification (Fig. \ref{fig:cls}), and 3D medical image registration (Fig. \ref{fig:registration}).

\begin{figure}[!ht] 
	\centering
	\includegraphics[width=0.95\textwidth]{seg_enc_dec.pdf}
	\caption{\textbf{Study on within-domain 3D tumor segmentation.} a. Image segmentation with encoder-decoder architecture by loading the weights of Triad. b. We compare the performance of Scratch, VoCo-SSL and Triad on 5 within-domain datasets based on 3 architectures: Swin-B/L/H. c. We select the nnUNet and Swin-Transformer-Base architectures, along with 3 different weight-loading strategies, and analyze their cross-effects on performance across 5 within-domain datasets. d. Consistent with the setting in subfig. c., the radar chart of each category shows the overall advantage of Triad in tumor segmentation. }
	\label{fig:seg_enc_dec} 
\end{figure}

\subsection{3D organ/tumor segmentation}

We first evaluated the effectiveness of Triad on 3D organ/tumor segmentation. As shown in Fig. \ref{fig:seg_enc_dec} (a), we initialize the encoder with the parameters learned during pre-training, while the decoder is randomly initialized.
We evaluate Triad on 17 extensive 3D MRI and CT semantic segmentation datasets, including five MRI datasets for within-domain tasks: BraTS21\citep{baid2021rsna}, MSD\citep{antonelli2022medical}-BrainTumour, BreastDM\citep{zhao2023breastdm}, Prostate158\citep{adams2022prostate158}, and MSD-Prostate; and 12 datasets covering different organs or modalities for out-of-domain tasks: MM-WHS-MRI\citep{zhuang2018multivariate}, ATLAS-MRI\citep{quinton2023tumour}, Abdomen 1K\citep{ma2021abdomenct}, Kipa22\citep{he2021meta}, MSD-Pancreas, MSD-Liver, MSD-Heart, MSD-Hippocampus, MSD-Lung, MSD-HepaticVessel, MSD-Spleen, and MSD-Colon.
We use the Dice Similarity Coefficient (DSC) as the primary evaluation metric, consistent with public benchmarks.

\subsubsection{Influence of model parameter scale on model performance}

It is widely believed that increasing model parameters enhances the performance of downstream tasks in foundation models~\citep{oquab2023dinov2,chen2024towards,ghesu2022contrastive,amadou2024echoapex}. This trend has been observed in various domains, including natural images~\citep{oquab2023dinov2}, x-ray~\citep{ghesu2022contrastive}, and other medical imaging modalities\citep{chen2024towards,amadou2024echoapex}.
However, some studies have reported contradictory findings, particularly in 3D CT imaging\citep{wu2024voco} and vision language models~\citep{shi2025we,mei2024bigger}. In this study, we quantitatively analyze the scaling behavior of Triad pre-training. We conduct a series of experiments with varying model architectures to systematically evaluate their impact on performance.

We specifically select the widely used SwinUNETR architecture~\citep{he2023swinunetr}. The SwinUNETR encoder utilizes different variants of Swin Transformer~\citep{dosovitskiy2020image}, including Swin-B (Base), Swin-L (Large), and Swin-H (Huge).
We evaluate the impact of model parameter scaling on the within-domain 3D tumor segmentation task and compare it with Scratch and VoCo-SSL~\citep{wu2024voco}. VoCo-SSL is a vision foundation model pre-trained on 160K 3D CT scans using a self-supervised model distillation scheme and is considered state-of-the-art in 3D medical imaging. Scratch denotes training from scratch without using any pre-trained weights.

As shown in Fig. \ref{fig:seg_enc_dec} b (1) - b (5), the average DSC reported by Swin-B-Scratch across the five datasets is 77.76\%. In comparison, Swin-B-VoCo-SSL achieves an average DSC of 79.31\% (\textcolor{blue}{+1.55\%}), while Swin-B-Triad achieves 79.66\% (\textcolor{blue}{+1.90\%}).
These results indicate that pre-training the upstream encoder can markedly enhance the performance of downstream tasks. This finding is consistent with previous studies\citep{wu2024voco,amadou2024echoapex}. Notably, Swin-B-Triad outperforms Swin-B-VoCo-SSL by \textcolor{blue}{+0.35\%}, which can be attributed to Triad's use of MRI data for pre-training, whereas VoCo-SSL is pre-trained on CT data. This suggests that greater alignment between the data modalities of upstream and downstream models leads to improved downstream performance.
A key finding across 15 experiments comparing the Swin-B/L/H architectures is that 11 of these experiments indicate that increasing the size of model parameter does not consistently lead to performance improvements. This observation aligns with findings from VoCo-SSL\citep{wu2024voco}. A possible explanation is that excessive model parameters may lead to overfitting on small downstream datasets. Even with robust initial parameters from the upstream pre-trained model, downstream performance may still be adversely affected by overfitting.



\subsubsection{Within-domain 3D tumor segmentation}

The upstream 3D MRI data used for pre-training is derived from three organs: the brain, breast, and prostate. Consequently, the downstream within-domain 3D tumor segmentation task employs data from the same modality and organs to evaluate performance, assessing whether Triad has effectively learned structural and modality representations during pre-training.
Specifically, we select two brain datasets: BraTS21~\citep{baid2021rsna} and MSD-BrainTumour~\citep{antonelli2022medical}, one breast dataset: BreastDM~\citep{zhao2023breastdm}, and two prostate datasets: MSD-Prostate~\citep{antonelli2022medical} and Prostate158~\citep{adams2022prostate158}.
We employ two widely used network architectures: nnUNet~\cite{isensee2021nnu} and SwinUNETR (Swin-B).

The nnUNet-Scratch achieves an average DSC of 79.68\%, whereas nnUNet-Triad improved this to 81.13\%, marking an increase of \textcolor{blue}{1.45\%}. Considering the performance of the Swin-B encoder under the three initialization settings discussed earlier, it is evident that pre-trained parameters consistently outperform random initialization, regardless of the model structure (nnUNet or SwinUNETR) or the pre-training strategy (VoCo-SSL or Triad) employed.
Furthermore, the results indicate that nnUNet generally outperforms SwinUNETR in segmentation tasks. A radar chart presenting DSC for each category in Fig. \ref{fig:seg_enc_dec} (d). This chart demonstrates that Triad excels in segmenting fine-grained tumors.
For example, the BraTS21 Tumor Core represents the core region of the tumor, which serves as the primary therapeutic target and excludes the edema area. The BraTS21 Enhancing Tumor represents the actively invasive tumor and serves as a key indicator of tumor grade and recurrence. Notably, Triad outperforms Swin-B-VoCo by \textcolor{blue}{+2.08\%} and \textcolor{blue}{+1.38\%} in both categories.

\begin{figure}[!ht] 
	\centering
	\includegraphics[width=0.95\textwidth]{seg_withoutdomain.pdf}
	\caption{\textbf{Study on out-of-domain organ/tumor segmentation.} a. We select the nnUNet and Swin-Transformer-B architectures, along with three different weight loading strategies, and analyze their cross-effects on performance across six MSD CT datasets. b. Consistent with the setting of subfig. a., the radar chart shows the performance comparison of each category in MM-WHS-MRI, ATLAS-MRI, and MSD-Liver. c. Consistent with the setting of subfig. a., the radar chart shows the performance comparison of each category in Abdoman 1K, Kipa22, and MSD-Pancreas.}
	\label{fig:seg_withoutdomain} 
\end{figure}

\subsubsection{Out-of-domain organ/tumor segmentation}

We further assess whether the knowledge acquired by Triad during pre-training can be effectively transferred to and applied to other organs or a different imaging modality.
To achieve this, we select four MRI datasets from other organs: MSD-Heart, MSD-Liver, MM-WHS-MRI~\citep{zhuang2018multivariate}, and ATLAS-MRI~\citep{quinton2023tumour}. Additionally, we incorporated eight CT datasets: MSD-Hippocampus, MSD-Lung, MSD-Pancreas, MSD-HepaticVessel, MSD-Spleen, MSD-Colon, Abdomen 1K~\citep{ma2021abdomenct}, and Kipa22~\citep{he2021meta}.
We continue to use the nnUNet and SwinUNETR (Swin-B) architectures and employ three parameter initialization methods: training from scratch, VoCo-SSL, and Triad.

As shown in Fig. \ref{fig:seg_withoutdomain} (a), an interesting observation is that, when using the Swin-B architecture, the three initialization methods rank in performance as follows: VoCo (77.14\%) > Scratch (74.34\%) > Triad (73.09\%)\footnote{We report the average DSC of experiments (1)-(6).}.
We also observed that VoCo-SSL was pre-trained on CT data containing more than 16 organs or tumors, covering the organs used in experiments (1)-(6). We believe this is the primary reason for its superior performance.
Therefore, we conclude that \textbf{pre-training maximizes performance when the data modality and organ of upstream and downstream tasks are consistent.}
Nevertheless, compared to both VoCo-SSL and training from scratch, nnUNet-Triad achieved an improvement of \textcolor{blue}{+2.02\%}, demonstrating that Triad can effectively generalize to other data modalities and organs.
Fig. \ref{fig:seg_withoutdomain} (b) and (c) present radar charts for each class on both CT and MRI datasets. Notably, marked improvements are observed in tumor segmentation rather than organs.
For example, on MSD-Liver Cancer, nnUNet-Triad outperforms nnUNet-Scratch by \textcolor{blue}{+14.77\%}, while Swin-B-Triad surpasses Swin-B-Scratch by \textcolor{blue}{+17.97\%}.


\subsection{Organ/cancer classification}

We next evaluate the performance of Triad on organ and cancer classification tasks.
As shown in Fig. \ref{fig:cls} (a), we initialize the encoder with the parameters learned during pre-training, apply an average pooling operation to the output of its final layer, and pass the resulting features through a two-layer linear classifier to predict the probability distribution of the categories.
We evaluate Triad on five widely recognized 3D CT and MRI classification datasets, including two MRI datasets for within-domain classification: ADNI~\cite{jack2008alzheimer} and BreastDM~\cite{zhao2023breastdm}; two CT datasets for out-of-domain classification: OrganMNIST3D~\cite{yang2023medmnist} and LUNA16~\cite{setio2017validation}; and one additional MRI dataset for out-of-domain classification: LLD-MMRI~\cite{lou2024sdrformer}.
We use classification accuracy (Acc) as the primary evaluation metric.



\subsubsection{Within-domain organ/cancer classification}

As shown in Fig. \ref{fig:cls} (c), we compare two architectures, 3D UNet and Swin-B, using four initialization methods: training from scratch, SwinUNETR~\cite{cao2022swin}, VoCo-SSL, and Triad.
We observe that on both the ADNI and BreastDM datasets, Swin-B-Scratch achieves an average accuracy that is \textcolor{blue}{+4.25\%} higher than 3D UNet-Scratch. A similar trend is observed in the LLD-MMRI and OrganMNIST3D datasets.
The only exception is the LUNA16 dataset, where 3D UNet-Scratch achieves an accuracy that is \textcolor{blue}{+0.73\%} higher than Swin-B-Scratch.
These findings provide strong evidence that the Swin-B architecture is better suited for classification tasks.

Next, we compare the impact of three different pre-trained models on downstream performance.
SwinUNETR is pre-trained on approximately 5K CT volumes, whereas VoCo-SSL utilizes 160K CT volumes. According to the reported accuracy, VoCo-SSL achieves an average accuracy that is \textcolor{blue}{+1.37\%} higher than SwinUNETR.
Triad is pre-trained on 131K MR volumes and achieves an average accuracy that is \textcolor{blue}{+1.52\%} higher than VoCo-SSL.
These results indicate that both the modality and scale of pre-training data positively impact downstream performance.


\begin{figure}[!ht] 
	\centering
	\includegraphics[width=0.99\textwidth]{cls.pdf}
	\caption{\textbf{Study on organ/cancer classification.} a. We use an encoder loaded with Triad weights and a two-layer linear classifier for classification tasks. b. Confusion matrices of the 5 datasets when using Swin-B-Triad as the encoder. The meaning of each category number is shown in Table \ref{table:t2}. c. We select the 3D UNet and Swin-Transformer-Base architectures, along with 3 different weight loading strategies, and analyze their cross-effects on performance across 5 CT/MRI datasets. d. Consistent with the setting of subfig. c., we plot the ROC curve of each scheme on 4 datasets.}
	\label{fig:cls} 
\end{figure}


\begin{figure}[!t] 
	\centering
	\includegraphics[width=0.81\textwidth]{regristation.pdf}
	\caption{\textbf{Study on 3D medical image registration.} a. We adopt the TransMorph architecture, use Swin-Transformer Large as the encoder, and load the pre-trained weights of Scratch, Triad, and VoCo-SSL for regristation task. The bar chart on the right shows the average dice scores of the 3 weight loading methods on the 3 datasets. b. Under the setting of subfig. a., the visualization results of various registration methods in the IXI dataset. c. We adopt the SwinUNETR architecture, use Swin-Transformer Base as the encoder. The bar chart on the right shows the average dice scores of the 5 weight loading methods on the 2 datasets. d. Under the setting of subfig. c., the visualization results of various registration methods in the OASIS dataset. e. Under the setting of subfig. a., boxplots with Dice scores of various registration methods in the abdomen IXI dataset.}
	\label{fig:registration} 
\end{figure}


\subsubsection{Out-of-domain organ/cancer classification}
As illustrated in Fig. \ref{fig:cls} (c), Triad achieves the highest performance in the organ classification task and ranks second in both lung nodule and liver lesion classification tasks.
Notably, Triad still outperforms training from scratch by \textcolor{blue}{+1.02\%}, demonstrating its effectiveness in generalizing across diverse imaging modalities and organ types.
Furthermore, we provide the confusion matrix~\cite{heydarian2022mlcm} for Swin-B-Triad across the five datasets.
Fig. \ref{fig:cls} b (1) shows that when Swin-B-Triad is applied to an out-of-domain classification task with a highly imbalanced category distribution, the model struggles to classify minority classes accurately.
In the OrganMNIST3D classification task, Triad fails to distinguish categories 1–4 accurately.
These findings suggest that while pre-trained parameters enhance overall downstream performance, addressing challenges such as data imbalance and hard example mining may require specialized sampling strategies or model architectures.
Additionally, we present the ROC curves for four datasets in Fig. \ref{fig:cls} (d).
The ROC curves of all pre-trained models exhibit significant overlap, whereas models trained from scratch show markedly inferior performance, particularly on OrganMNIST3D and ADNI.

\subsection{3D medical image registration}

Finally, we evaluate the performance of Triad on the 3D medical image registration task.
As illustrated in Fig. \ref{fig:registration} (a) and (c), we explore two different parameter initialization strategies.
In Fig. \ref{fig:registration} (a), we employ the TransMorph~\citep{chen2022transmorph} architecture with a Swin-Transformer-L encoder, initializing it with pre-trained weights from Triad and VoCo-SSL.
In Fig. \ref{fig:registration} (c), we use the Swin-UNETR~\citep{hatamizadeh2021swin} architecture with a Swin-Transformer-B encoder, initializing it with pre-trained weights from Triad, VoCo-SSL, SuPreM, and SwinUNETR.
The decoder remains unchanged from the original method and is randomly initialized.
We evaluate Triad on three widely recognized 3D MRI registration datasets, including two brain datasets for within-domain registration: IXI~\cite{Brain-Development_IXI_2019} and OASIS~\cite{krentzel2023clem}, as well as one cardiac dataset for out-of-domain registration: ACDC~\cite{bernard2018deep}.
We use the Dice Similarity Coefficient (DSC) as the primary evaluation metric and report the best results after fine-tuning for 200 epochs.

\subsubsection{Comparison of pre-training strategies in TransMorph and SwinUNETR for 3D medical image registration}

Fig. \ref{fig:registration} (a) illustrates a bar chart depicting the DSCs for each dataset. TransMorph-Scratch achieves average DSCs of 73.76\%, 86.79\%, and 74.81\% on IXI, OASIS, and ACDC, respectively.
When employed Triad pre-trained weights, the DSCs are 73.91\% (\textcolor{blue}{+0.15\%}) on IXI and 86.92\% (\textcolor{blue}{+0.13\%}) on OASIS, but decrease to 74.57\% (\textcolor{red}{-0.24\%}) on ACDC.
Similarly, VoCo-SSL pre-training results in DSCs of 73.44\% (\textcolor{red}{-0.32\%}), 86.98\% (\textcolor{blue}{+0.19\%}), and 74.72\% (\textcolor{red}{-0.09\%}) on IXI, OASIS, and ACDC, respectively.
The performance of TransMorph under these three initialization strategies indicates that pre-trained parameters do not consistently yield improvements over random initialization in 3D medical image registration.
This observation applies to both within-domain (IXI, OASIS) and out-of-domain (ACDC) tasks, with some cases even exhibiting marginal performance declines.

Fig. \ref{fig:registration} (c) presents DSC performance under the SwinUNETR architecture, comparing five initialization strategies: Scratch, SwinUNETR, SuPreM, VoCo-SSL, and Triad.
Specifically, Swin-B-Scratch achieves DSCs of 72.60\% on IXI and 81.80\% on OASIS.
Swin-B-VoCo achieves DSC scores of 73.60\% (\textcolor{blue}{+1.00\%}) on IXI and 84.40\% (\textcolor{blue}{+2.60\%}) on OASIS.
Notably, Triad proves to be the most effective pre-training method, achieving DSC scores of 73.70\% (\textcolor{blue}{+1.10\%}) on IXI and 88.70\% (\textcolor{blue}{+6.90\%}) on OASIS.
These improvements are particularly pronounced on the OASIS dataset, where Triad outperforms other initialization methods by a significant margin.

By integrating these findings with the TransMorph results in Fig. \ref{fig:registration} (a), we observe that partially loading encoder weights, as done in TransMorph, while randomly initializing the remaining parameters, may introduce inconsistencies, potentially limiting the benefits of pre-training.
In contrast, SwinUNETR employs a fully pre-trained encoder, thereby eliminating random initialization in that module. This allows the network to leverage pre-trained features more effectively, leading to substantial improvements in 3D medical image registration.

\subsubsection{Impact of initialization method on registration performance}

Fig. \ref{fig:registration} (b) presents the visualization results for the IXI dataset using the TransMorph architecture.
Regardless of the initialization method used for fine-tuning, the observed  improvements in the mask appear similar, with no substantial enhancements detected.
In contrast, Fig. \ref{fig:registration} (d) presents the visualization of the OASIS dataset using the SwinUNETR architecture, where improvements in the mask (indicated by the red arrow) are noticeable.
These visualizations provide intuitive evidence supporting our previous assertion that incomplete pretraining initialization of the encoder may lead to model confusion.

Furthermore, Fig. \ref{fig:registration} (e) depicts the DSC distributions for the IXI dataset.
SwinUNETR initialized with Triad weights achieves the highest registration performance across most organs, including the thalamus, cerebral white matter, cerebellar white matter, pallidum, caudate, lateral ventricle, hippocampus, third ventricle, fourth ventricle, and amygdala.
Notably, this superior performance can be attributed to the inclusion of abundant 3D MRI brain organ data in the upstream pretraining tasks.
Regardless of the initialization weights, the DSC and registration performance for the choroid plexus remains low, likely due to its complex anatomical attachments to surrounding structures and its diffuse morphological characteristics.

