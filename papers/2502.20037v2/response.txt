\section{Related Work}
\label{sec_works}
\subsection{Transparent Depth Completion}
Transparent object depth reconstruction is an active research area employing  various devices such as optical cameras and depth sensors. Some works also introduce additional sensors to complete the depth maps. Existing works can be categorized based on the observation views into multi-view and single-view depth reconstruction.

Multi-view depth reconstruction methods often rely on Neural Radiance Fields (NeRF), which can accurately reconstruct the scene geometry. For instance, Kondo et al., "Dex-NeRF: A Learning-Based Framework for Depth Map Reconstruction and Transparent Object Grasping in Complex Scenes" ____, while Park et al., "Evo-NeRF: A Sequential Method for Transparent Object Grasping" ____.
Other works like Zhang et al., "StereoPose: Using Stereo Images for Transparent Object Pose and Depth Estimation", also rely on multi-view observation ____.
In single-view depth reconstruction, the first algorithm, Lin et al., "ClearGrasp: Reconstructing Depth Maps of Transparent Objects with a Neural Network" ____, uses a neural network on synthetic RGB-D datasets to reconstruct depth maps of transparent objects ____. Subsequently, researchers use realistic data instead of synthetic data to train a more robust model. Among these, Liu et al., "TransCG: A Model Employing a U-Net Architecture for Transparent Object Depth Completion", has achieved a best performance _____. Some fusion solutions are included in single-view parts. Liang et al., "Polarized-CNN: Combining Polarization and RGB-D Cameras to Search and Grasp Transparent Targets" combine a polarization camera with an RGB-D camera to search and grasp the transparent targets ____. Chen et al., "TaTa: Integrating Camera and Tactile Sensors for Robotic Object Exploration and Grasping" integrate the camera with tactile sensors and can even grasp tiny glass fragments after exploration by a robotic arm ____.

A common limitation of these works is that they almost rely on vision, which may degrade in challenging conditions such as dim light, resulting in lower grasp accuracy. For these additional sensors, the fusion algorithm does not naturally integrate with visual information. To address this, we propose using mmWave radar as a supplementary sensor to provide complementary information for reconstructing the transparent object shape from RGB-D images.

\subsection{Radar Sensing and Imaging}
Radar technology, widely applied in daily life, can be classified into three main types: array signal processing for object sensing ____, point cloud generation for object detection ____, and SAR for shape imaging ____.

Array signal processing, based on antenna arrays, is extensively used for radar-based sensing and tracking. For example, Kim et al., "Mtrack: An Indoor Human Sensing System Using Beamforming Technology" uses beamforming technology to localize multiple moving humans ____. Point cloud radars are popular for autonomous driving. Wang et al., "MILLIPOINT: A Millimeter-Wave Radar System for Surrounding Object Detection and Enhanced Driving Safety" uses point clouds to detect surrounding objects and enhance driving safety ____. Chen et al., "RCVNet: A Feature Fusion Approach Integrating Radar Point Clouds with Visual Images for Bird Damage Detection in Power Tower Areas" employed a feature fusion approach, integrating radar point clouds with visual images, to enable the accurate detection of bird damage in power tower areas ____.

For SAR imaging applications, Huang et al., "UWBMap: A Multi-Radar System for Indoor Mapping and Floor Plan Construction under Smoking Conditions" uses a multi-radar system for indoor mapping and floor plan construction, and it can operate under smoking conditions____. Li et al., "SiWa: A Network-Based Method for SAR Image Generation to Detect Pipes and Wires in Concrete Walls" is another radar imaging work that uses a network to generate SAR images to detect pipes and wires in concrete walls ____. Lee et al., "MIMO-SAR: A High-Resolution SAR Imaging System Using Stepping Motors for Point-to-Point Scanning" uses stepping motors to control radars’ point-to-point scanning, and it has achieved high resolution SAR imaging for security checking ____.

These three methods have their own advantages and limitations in radar perception. Array signal processing can only locate the target’s position without obtaining its shape details. The sparsity of radar point clouds makes shape reconstruction challenging. SAR imaging can provide geometric shape information to supplement the missing depth data. Therefore, we uses SAR technology to obtain radar images of transparent object, and signal calibration is necessary to improve the radar imaging performance.