\section{Conclusions}

In this work, we have shown the efficacy of a generative AI model---guaranteed conditional diffusion (GCD)---for scientific data compression. In contrast to traditional video, scientific data comprise blocks of tensors and therefore we designed GCD to work in this setting. GCD has three modules: (i) the standard 2D diffusion architecture with U-Net to learn each denoising stage, (ii) an encoder which compresses 3D blocks, produces latent variables, and acts as the conditioning information, and (iii) a post-processing tensor correction network which provides error bound guarantees at each compression ratio. Results on two applications---a climate dataset (E3SM) and a CFD dataset (S3D)---demonstrate that GCD is better or competitive with SZ---a standard lossy scientific data compression method and convolutional autoencoders. Future work will center on four aspects which are expected to further improve GCD: (i) a full adaptation to blocks and hyper-blocks of tensors, (ii) the use of a scale hyperprior approach for quantization, (iii) incorporation of attention within U-Net, and (iv) fast decoding via distillation. We eventually expect GCD and its variants to be a popular third paradigm for data compression, taking its place alongside super-resolution and transform-based paradigms.