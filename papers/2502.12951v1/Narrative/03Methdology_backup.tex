\section{Methodology}

We propose a compression pipeline---Guaranteed Conditional Diffusion with Tensor Correction (GCDTC)---for lossy scientific data compression. The framework consists of three steps: (i) conditional diffusion, (ii) tensor correction, and (iii) error guarantee. Our approach leverages conditional generation of diffusion models \cite{Yang2023cd}, where compressed images guide the reverse diffusion process. In our framework, we introduce 3D block conditioning with 2D diffusion models. An overview of our conditional diffusion model is described in Figure~\ref{fig:overview}. Since scientific data have underlying temporal and spatial correlations, they must be addressed for effective data reduction. We first divide the entire dataset into 3D blocks and compress them to get codecs. Then, we use 2D slices of the compressed blocks for conditional generation. There is no advantage in using 3D diffusion models, as spatiotemporal correlations are already addressed by 3D block compression. After the conditional diffusion (CD) model is trained, the reconstructed output of the CD model is further enhanced by a tensor correction network followed by a error guaranteeing process. In this section, we briefly discuss the background of diffusion models and then describe our framework.


\subsection{Background}
%\paragraph{\textbf{Diffusion models}}
\subsubsection{Diffusion models} are a class of hierarchical latent variable models that generate data by iteratively reversing a sequence of noise-adding transformations \cite{Sohl2015,Song2019,Ho2020,Song2021}. These models define a joint distribution over data $\boldsymbol{x}_0$ and latent variables $\boldsymbol{x}_{1:T}$, where the latter represents intermediate noisy versions of the data. The generative process starts from a latent representation drawn from a simple prior (e.g., Gaussian noise) and progressively refines it to produce structured data, such as images.

The forward process $q$ systematically adds noise to the data through a series of Markovian transitions, eroding structure until the data becomes nearly indistinguishable from pure noise:
\begin{equation}\label{eq:forward}
    q\left(\boldsymbol{x}_t|\boldsymbol{x}_{t-1}\right)=\mathcal{N}\left(\boldsymbol{x}_t|\sqrt{1-\beta_t}\boldsymbol{x}_{t-1},\beta_t\boldsymbol{\mathrm{I}}\right),
\end{equation}
where $\beta_t$ is a predefined or learned noise schedule. The reverse process $p_\theta$ uses a neural network to iteratively recover the data by predicting the denoised states:
\begin{equation}\label{eq:reverse}
    p_\theta\left(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t\right)=\mathcal{N}\left(\boldsymbol{x}_{t-1}|M_\theta\left(\boldsymbol{x}_t,t\right),\beta_t\boldsymbol{\mathrm{I}}\right).
\end{equation}

The reverse process is trained to approximate the true denoising transitions by minimizing a noise-prediction objective. Specifically, the model predicts the added noise $\epsilon$ for a given noisy sample $\boldsymbol{x}_t$, and the loss function is defined as:
\begin{equation}\label{eq:ddpm_loss}
    L\left(\theta,\boldsymbol{x}_0\right)=\mathbb{E}\left\|\epsilon-\epsilon_\theta\left(\boldsymbol{x}_t, t\right)\right\|^2,
\end{equation}
where $\boldsymbol{x}_t$ is constructed as $\boldsymbol{x}_t=\sqrt{\Bar{\alpha}_t}\boldsymbol{x}_0+\sqrt{1-\Bar{\alpha}_t}\epsilon$, $\alpha_t=1-\beta_t$, and $\Bar{\alpha}_t=\prod_{s=1}^t\left(\alpha_s\right)$. By leveraging this objective, the model learns to reverse the forward process and restore data from noise effectively.

For sampling, the reverse process can follow a stochastic trajectory, as in Denoising Diffusion Probabilistic Models (DDPMs) \cite{Ho2020}, or a deterministic path, as in Denoising Diffusion Implicit Models (DDIMs) \cite{Song2021}. The deterministic approach enables faster generation while retaining high-quality results, making it practical for tasks where efficiency is critical.


%\paragraph{\textbf{Conditional diffusion models for compression}}
\subsubsection{Conditional diffusion models for compression}
extend diffusion models to lossy data compression by leveraging conditional generation \cite{Yang2023cd}. In this framework, an image $\boldsymbol{x}_0$ is compressed into a set of latent representations $\boldsymbol{z}$ using an entropy-optimized quantization process. These latent variables are then used as conditioning inputs to guide the reverse diffusion process:
\begin{equation}\label{eq:cd_reverse}
    p_\theta\left(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t, \boldsymbol{z}\right)=\mathcal{N}\left(\boldsymbol{x}_{t-1}|M_\theta\left(\boldsymbol{x}_t, \boldsymbol{z}, t\right),\beta_t\boldsymbol{\mathrm{I}}\right).
\end{equation}
Here, $\boldsymbol{z}$ captures content information about an image, while the reverse diffusion process reconstructs finer texture details progressively. This approach combines the advantages of learned image compression approaches \cite{Balle2017,Balle2018,Minnen2018} with the generative capabilities of diffusion models to propose a new paradigm in lossy image compression. The model is trained using a similar objective to the DDPM loss function in~\eqref{eq:ddpm_loss}, but with an added conditioning mechanism for $\boldsymbol{z}$,
\begin{equation}\label{eq:cd_loss}
    L\left(\boldsymbol{x}_0|\boldsymbol{z}\right)=\mathbb{E}\left\|\epsilon-\epsilon_\theta\left(\boldsymbol{x}_t,\boldsymbol{z}, t\right)\right\|^2=\frac{\Bar{\alpha}_t}{1-\Bar{\alpha}_t}\mathbb{E}\left\|\boldsymbol{x}_0-\mathcal{X}_\theta\left(\boldsymbol{x}_t,\boldsymbol{z}, t\right)\right\|^2,
\end{equation}
where $\mathcal{X}$-prediction, denoted $\mathcal{X}_\theta$, is an equivalent alternative of the noise-based loss function and directly learns to reconstruct $\boldsymbol{x}_0$ instead of the noise $\epsilon$. At test time, the latent variable $\boldsymbol{z}$ is entropy-decoded, and denoising U-Net conditionally reconstructs the image $\boldsymbol{x}_0$ with the iterative reverse process. The sampling process in \cite{Yang2023cd} follows the DDIM's sampling method \cite{Song2021} with either a deterministic way with zero noise or a stochastic noise drawn from a normal distribution. This conditional setup allows the model to work suitably for compression, not generation.


\subsection{3D Conditional Diffusion Model for Scientific Data Compression}

Our approach is developed upon the conditional diffusion model \cite{Yang2023cd}, where latent information $\boldsymbol{z}$ guides the reverse diffusion process for 2D image compression. We extend the conditional diffusion model to 3D scientific data compression, which is a mixture of a 3D block encoder and a conditional 2D denoising U-Net as described in Figure~\ref{fig:cd_model}.
\vspace{-0.4cm}
\subsubsection{Training.}
We first divide the entire dataset into a set of 3D tensors. The tensors are mapped into latent variable $\boldsymbol{z}$ and converted into 3D embedding $\boldsymbol{z}^e$. In the diffusion process, we follow the same method of the DDPM in \eqref{eq:forward} to get the 2D noisy slice $\boldsymbol{x}_{i,t}$ at the stage $t$. Using the slice of the latent embedding $\boldsymbol{z}_i^e$, we modify the conditional reverse diffusion process in \eqref{eq:cd_reverse} as
\begin{equation}\label{eq:our_reverse}
    p_\theta\left(\boldsymbol{x}_{i,t-1}|\boldsymbol{x}_{i,t}, \boldsymbol{z}_i^e\right)=\mathcal{N}\left(\boldsymbol{x}_{i,t-1}|M_\theta\left(\boldsymbol{x}_{i,t}, \boldsymbol{z}_i^e, t\right),\beta_t\boldsymbol{\mathrm{I}}\right).
\end{equation}
Like in \eqref{eq:cd_loss}, our model is trained to estimate the noise,
\begin{equation}\label{eq:our_loss}
    L\left(\boldsymbol{x}_{i,0}|\boldsymbol{z}_i^e\right)=\mathbb{E}\left\|\epsilon-\epsilon_\theta\left(\boldsymbol{x}_{i,t},\boldsymbol{z}_i^e, t\right)\right\|^2.
\end{equation}
With the diffusion stage embeddings, the 2D denoising decoder and 3D latent embeddings are trained in an end-to-end manner.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{Figures/CD_Model.pdf}
    \caption{A visualization of our 3D conditional diffusion model. We obtain 3D embedding $\boldsymbol{z}^e$ from the tensor block $\boldsymbol{x}$ to effectively address spatiotemporal correlations in scientific datasets. If the tensor block size is $D\times H\times W$, the first dimension of $\boldsymbol{z}^e$ must be equal to $D$. This is because we incorporate 2D diffusion and the $i^\mathrm{th}$ slice $\boldsymbol{z}_i^e$ is used to condition the denoising decoder. Hence, the decoder learns to predict the 2D noise at the diffusion stage $t$ of each 2D slice $\boldsymbol{x}_i$ in $\boldsymbol{x}$. Architecture details are described in Appendix.}\label{fig:cd_model}
    \vspace{-0.4cm}
\end{figure}

%\paragraph{\textbf{Quantization and Decoding.}}

\subsubsection{Quantization and Decoding.}
After the model is trained, we quantize and entropy-encode $\boldsymbol{z}$ using scalar quantization followed by Huffman encoding. Each value $z$ in $\boldsymbol{z}$ is rounded by $\left\lfloor \frac{b}{a}z\right\rfloor$, where $b$ is a power of 10 and $a$ determines the quantization bin size. Then, all the integers are Huffman-encoded to produce compressed codecs. In learned image compression \cite{Balle2017,Balle2018,Minnen2018}, a prior $p\left(\boldsymbol{z}\right)$ is modeled as an additional neural network to include quantization and entropy coding for end-to-end learning. We don't incorporate hyper-prior networks because of (1) additional steps in our framework that complement the output of the CD model and (2) reducing the model complexity.

At decoding time, we entropy-decode and dequantize the compressed codecs and produce latent embeddings. The denoising decoder reconstructs the data deterministically with $\boldsymbol{x}_{i,T}=\boldsymbol{0}$. We reconstruct a 3D tensor $\hat{\boldsymbol{x}}_0$ using ancestral sampling for each 2D slice $\boldsymbol{x}_{i}$ in $\boldsymbol{x}_0$. We follow the DDPM's sampling method,
\begin{equation}
    \boldsymbol{x}_{i,t-1}=\frac{1}{\sqrt{\alpha_t}}\left(\boldsymbol{x}_{i,t}-\frac{1-\alpha_t}{\sqrt{1-\Bar{\alpha}_t}}\epsilon_\theta\left(\boldsymbol{x}_{i,t},\boldsymbol{z}_i^e, t\right)\right).
\end{equation}


\subsection{Tensor Correction and Error Guarantee}\label{subsec:tc_eg}
In lossy scientific data compression, the maximum distortion of reconstructed raw data or primary data (PD) is required to be bounded by a user-specific error target due to reliable post-analysis. For this reason, error-bounded lossy compression is dominant in this field. These techniques are developed upon several methods based on prediction (SZ \cite{SZ3}), transformation (ZFP \cite{ZFP2}), and wavelet decomposition (MGARD \cite{MGARD_3} and SPERR \cite{SPERR}). To provide guaranteed reconstruction, we first enhance the output of the CD model and then correct tensors.
\vspace{-0.6cm}
\subsubsection{Tensor Correction.}
We incorporate a tensor correction (TC) network proposed in \cite{JL-S3D_arxiv}. The TC network is trained using reconstructed tensors obtained from the CD model, and it is an ``overcomplete'' feedforward network to learn a reverse mapping from the reconstructed tensor $\hat{\boldsymbol{x}}$ to the original tensor $\boldsymbol{x}$. In our TC network, we use tensors along the perpendicular direction to 2D slices in the CD model. The TC network reproduces the enhanced reconstructed dataset $\hat{X}$.
%\paragraph{\textbf{Error Guarantee.}}
\subsubsection{Error Guarantee.}
We utilize a post-processing method to control a maximum error distortion according to a pre-specified error bound \cite{JL-GAE,JL-S3D_arxiv}. We first divide the original and reconstructed datasets into small blocks ($\{\boldsymbol{b}\}_{i=1}^N$ and $\{\hat{\boldsymbol{b}}\}_{i=1}^N$) to bound errors on this small region. We perform PCA on the residual set $\{\boldsymbol{b}-\hat{\boldsymbol{b}}\}_{i=1}^N$ to get a global basis $U$. The error guarantee step is a selective process. For each block $\boldsymbol{b}$ that exceeds the error bound $\tau$ ($\|\boldsymbol{b}-\hat{\boldsymbol{b}}\|_{2}> \tau$), we draw coefficients by projecting its residual onto the subspace spanned by the basis $U$,
\begin{equation}
    \boldsymbol{c}=U^T\left(\boldsymbol{b}-\hat{\boldsymbol{b}}\right).
\end{equation}
The coefficient $\boldsymbol{c}$ is quantized using log-based scalar quantization \cite{JL-S3D_arxiv}. We dequantize the coefficient and sort its entries according to their contribution to the $\ell_2$ error of $\hat{\boldsymbol{b}}$. We select the optimal subset $\boldsymbol{c}_s$ in $\boldsymbol{c}$ and its corresponding basis set $U_s$ to satisfy the target error bound. The final corrected block $\Tilde{\boldsymbol{b}}$ is
\begin{equation}
    \Tilde{\boldsymbol{b}}=\hat{\boldsymbol{b}}+U_{s}\boldsymbol{c}_{s}.
\end{equation}
The selected coefficients and basis indices are encoded using Huffman encoding. In our framework, the compressed codecs include all the encoded data of latent variables in the CD model and selected coefficients with their indices. We also consider all the models, PCA basis, and dictionaries of entropy coding for compression costs. Otherwise, we can use an extremely large machine that is even larger than the given scientific dataset, and can do overfitting to produce ideal results. This is because scientific datasets are domain-specific, unlike natural image compression.