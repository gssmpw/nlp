% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{placeins}
\begin{document}
%
\title{Guaranteed Conditional Diffusion: 3D Block-based Models for Scientific Data Compression}
%
\titlerunning{Guaranteed Conditional Diffusion Models}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
% \author{Anonymous Author(s)}
\author{Jaemoon Lee \and
Xiao Li \and
Liangji Zhu \and
Sanjay Ranka 
\and Anand Rangarajan}
\authorrunning{J. Lee et al.}

% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
% \institute{}
\institute{University of Florida, Gainesville FL 32611, USA}
% \email{\{j.lee1,xiao.li,zhu.liangji\}@ufl.edu, \{ranka,anand\}@cise.ufl.edu}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
%Lossy scientific data compression has recently emerged as an important area due to the tremendous amounts of data generated by scientific applications in high-performance computing (HPC).
This paper proposes a new compression paradigm---Guaranteed Conditional Diffusion with Tensor Correction (GCDTC)---for lossy scientific data compression. The framework is based on recent conditional diffusion (CD) generative models, and it consists of a conditional diffusion model, tensor correction, and error guarantee. Our diffusion model is a mixture of 3D conditioning and 2D denoising U-Net. The approach leverages a 3D block-based compressing module to address spatiotemporal correlations in structured scientific data. Then, the reverse diffusion process for 2D spatial data is conditioned on the ``slices'' of content latent variables produced by the compressing module. After training, the denoising decoder reconstructs the data with zero noise and content latent variables, and thus it is entirely deterministic.
The reconstructed outputs of the CD model are further post-processed by our tensor correction and error guarantee steps to control and ensure a maximum error distortion, which is an inevitable requirement in lossy scientific data compression. %In the tensor correction step, the reconstructed data of the CD model is enhanced at a tensor level by an overcomplete feedforward neural network, which is a learned mapping from the reconstructed tensors to the original tensors. Then, the error guarantee step ensures a maximum reconstruction error. We apply principal component analysis (PCA) to the residual between the original data and reconstructed data, which yields a basis matrix. The basis is then used to project the residual of each instance whose distortion ``exceeds'' a specified error bound. The optimal subset of the projected coefficients is selected for bounded error distortion.
Our experiments involving two datasets generated by climate and chemical combustion simulations show that our framework outperforms standard convolutional autoencoders and yields competitive compression quality with an existing scientific data compression algorithm.


\keywords{Conditional Diffusion \and Tensor Correction  \and Error Guarantee \and Scientific Data Compression.}
\end{abstract}
%
%
%

\input{Narrative/01Introduction}
\input{Narrative/02RelatedWork}
\input{Narrative/03Methodology}
\input{Narrative/04Experiments}
\input{Narrative/05Conclusion}




\begin{credits}
\subsubsection{\ackname} This work was partially supported by DOE RAPIDS2 DE-SC0021320 and DOE DE-SC0022265.

\subsubsection{\discintname}
The authors have no competing interests to declare that are relevant to the content of this article.
%It is now necessary to declare any competing interests or to specifically state that the authors have no competing interests. Please place the statement with a bold run-in heading in small font size beneath the (optional) acknowledgments\footnote{If EquinOCS, our proceedings submission system, is used, then the disclaimer can be provided directly in the system.}, for example: The authors have no competing interests to declare that are relevant to the content of this article. Or: Author A has received research grants from Company W. Author B has received a speaker honorarium from Company X and owns stock in Company Y. Author C is a member of committee Z.
\end{credits}

\input{Narrative/06Appendix}


%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{ref}
%

\end{document}
