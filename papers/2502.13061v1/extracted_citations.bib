@inproceedings{Anderson2017up-down, title={Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering}, ISSN={2575-7075}, DOI={10.1109/CVPR.2018.00636}, booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei}, year={2018}, month={Jun}, pages={6077–6086} }

@INPROCEEDINGS{Burbi_2023_Issues,
  author={Burbi, Giovanni and Baldrati, Alberto and Agnolucci, Lorenzo and Bertini, Marco and Del Bimbo, Alberto},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, 
  title={Mapping Memes to Words for Multimodal Hateful Meme Classification}, 
  year={2023},
  volume={},
  number={},
  pages={2824-2828},
  keywords={Training;Adaptation models;Visualization;Computer vision;Codes;Conferences;Computational modeling;Textual inversion;CLIP;Hateful Memes Challenge;HMC;Vision and Language;Hate speech detection;HarMeme},
  doi={10.1109/ICCVW60793.2023.00303}}

@inproceedings{Cao_2023_ProCap,
author = {Cao, Rui and Hee, Ming Shan and Kuek, Adriel and Chong, Wen-Haw and Lee, Roy Ka-Wei and Jiang, Jing},
title = {Pro-Cap: Leveraging a Frozen Vision-Language Model for Hateful Meme Detection},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
url = {https://doi.org/10.1145/3581783.3612498},
doi = {10.1145/3581783.3612498},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {5244–5252},
numpages = {9},
keywords = {memes, multimodal, semantic extraction},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@article{Flamingo22, title={Flamingo: a Visual Language Model for Few-Shot Learning}, volume={35}, journal={Advances in Neural Information Processing Systems}, author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina and Monteiro, Marianne and Menick, Jacob L. and Borgeaud, Sebastian and Brock, Andy and Nematzadeh, Aida and Sharifzadeh, Sahand and Bińkowski, Mikołaj and Barreira, Ricardo and Vinyals, Oriol and Zisserman, Andrew and Simonyan, Karén}, year={2022}, month={Dec}, pages={23716–23736}, language={en}, url={https://openreview.net/forum?id=EbMuimAbPbs}}

@inproceedings{Hee2024BridgeModality, address={Miami, Florida, USA}, title={Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning}, url={https://aclanthology.org/2024.emnlp-main.445/}, DOI={10.18653/v1/2024.emnlp-main.445},booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing}, publisher={Association for Computational Linguistics}, author={Hee, Ming Shan and Kumaresan, Aditi and Lee, Roy Ka-Wei}, editor={Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung}, year={2024}, month=nov, pages={7785–7799} }

@inproceedings{Hu_2024_VPD, address={Seattle, WA, USA}, title={Visual Program Distillation: Distilling Tools and Programmatic Reasoning into Vision-Language Models}, rights={https://doi.org/10.15223/policy-029}, ISBN={979-8-3503-5300-6}, url={https://ieeexplore.ieee.org/document/10655837/}, DOI={10.1109/CVPR52733.2024.00916},  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, publisher={IEEE}, author={Hu, Yushi and Stretcu, Otilia and Lu, Chun-Ta and Viswanathan, Krishnamurthy and Hata, Kenji and Luo, Enming and Krishna, Ranjay and Fuxman, Ariel}, year={2024}, month=jun, pages={9590–9601}, language={en} }

@inproceedings{Huang_LowResourceLMMAgentHatefulMeme_2024, address={Miami, Florida, USA}, title={Towards Low-Resource Harmful Meme Detection with LMM Agents}, url={https://aclanthology.org/2024.emnlp-main.136}, booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing}, publisher={Association for Computational Linguistics}, author={Huang, Jianzhao and Lin, Hongzhan and Ziyan, Liu and Luo, Ziyang and Chen, Guang and Ma, Jing}, editor={Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung}, year={2024}, month=nov, pages={2269–2293} }

@inproceedings{Ji2024CapAlign, address={Singapore Singapore}, title={CapAlign: Improving Cross Modal Alignment via Informative Captioning for Harmful Meme Detection}, ISBN={979-8-4007-0171-9}, url={https://dl.acm.org/doi/10.1145/3589334.3648146}, DOI={10.1145/3589334.3648146}, booktitle={Proceedings of the ACM Web Conference 2024}, publisher={ACM}, author={Ji, Junhui and Lin, Xuanrui and Naseem, Usman}, year={2024}, month=may, pages={4585–4594}, language={en} }

@article{KielaFBHMC2020, title={The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes}, url={http://arxiv.org/abs/2005.04790}, note={arXiv:2005.04790 [cs]}, number={arXiv:2005.04790}, publisher={arXiv}, author={Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Ringshia, Pratik and Testuggine, Davide}, year={2021}, month={Apr} }

@inproceedings{KumarHateClip2022,
    title = "Hate-{CLIP}per: Multimodal Hateful Meme Classification based on Cross-modal Interaction of {CLIP} Features",
    author = "Kumar, Gokul Karthik  and
      Nandakumar, Karthik",
    booktitle = "Proceedings of the Second Workshop on NLP for Positive Impact (NLP4PI)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.nlp4pi-1.20",
    doi = "10.18653/v1/2022.nlp4pi-1.20",
    pages = "171--183",
}

@article{LippeHMFramework2020, title={A Multimodal Framework for the Detection of Hateful Memes}, url={http://arxiv.org/abs/2012.12871}, note={arXiv:2012.12871 [cs]}, number={arXiv:2012.12871}, publisher={arXiv}, author={Lippe, Phillip and Holla, Nithin and Chandra, Shantanu and Rajamanickam, Santhosh and Antoniou, Georgios and Shutova, Ekaterina and Yannakoudakis, Helen}, year={2020}, month={Dec} }

@inproceedings{PramanickMomenta2021, address={Punta Cana, Dominican Republic}, title={MOMENTA: A Multimodal Framework for Detecting Harmful Memes and Their Targets}, url={https://aclanthology.org/2021.findings-emnlp.379}, DOI={10.18653/v1/2021.findings-emnlp.379}, booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021}, publisher={Association for Computational Linguistics}, author={Pramanick, Shraman and Sharma, Shivam and Dimitrov, Dimitar and Akhtar, Md. Shad and Nakov, Preslav and Chakraborty, Tanmoy}, year={2021}, month={Nov}, pages={4439–4455} }

@inproceedings{RGCL2024Mei,
  title = "Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning",
  author = "Mei, Jingbiao  and
    Chen, Jinghong  and
    Lin, Weizhe  and
    Byrne, Bill  and
    Tomalin, Marcus",
  editor = "Ku, Lun-Wei  and
    Martins, Andre  and
    Srikumar, Vivek",
  booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  month = aug,
  year = "2024",
  address = "Bangkok, Thailand",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2024.acl-long.291",
  doi = "10.18653/v1/2024.acl-long.291",
  pages = "5333--5347"
}

@article{RizaHMC3rd2020, title={Detecting Hate Speech in Memes Using Multimodal Deep Learning Approaches: Prize-winning solution to Hateful Memes Challenge}, url={http://arxiv.org/abs/2012.12975}, DOI={10.48550/arXiv.2012.12975}, note={arXiv:2012.12975 [cs]}, number={arXiv:2012.12975}, publisher={arXiv}, author={Velioglu, Riza and Rose, Jewgeni}, year={2020}, month={Dec} }

@article{RonHMC1st2020, title={Enhance Multimodal Transformer With External Label And In-Domain Pretrain: Hateful Meme Challenge Winning Solution}, url={http://arxiv.org/abs/2012.08290}, DOI={10.48550/arXiv.2012.08290}, note={arXiv:2012.08290 [cs]}, number={arXiv:2012.08290}, publisher={arXiv}, author={Zhu, Ron}, year={2020}, month={Dec} }

@inproceedings{Shah2024memeclip_pridemm, address={Miami, Florida, USA}, title={MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification}, url={https://aclanthology.org/2024.emnlp-main.959/}, DOI={10.18653/v1/2024.emnlp-main.959}, booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing}, publisher={Association for Computational Linguistics}, author={Shah, Siddhant Bikram and Shiwakoti, Shuvam and Chaudhary, Maheep and Wang, Haohan}, editor={Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung}, year={2024}, month=nov, pages={17320–17332} }

@inbook{Uniter2019, address={Cham}, series={Lecture Notes in Computer Science}, title={UNITER: UNiversal Image-TExt Representation Learning}, volume={12375}, ISBN={978-3-030-58576-1}, url={https://link.springer.com/10.1007/978-3-030-58577-8_7}, DOI={10.1007/978-3-030-58577-8_7}, booktitle={Computer Vision – ECCV 2020}, publisher={Springer International Publishing}, author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing}, editor={Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael}, year={2020}, pages={104–120}, collection={Lecture Notes in Computer Science}, language={en} }

@article{VilioHMC2nd2020, title={Vilio: State-of-the-art Visio-Linguistic Models applied to Hateful Memes}, url={http://arxiv.org/abs/2012.07788}, DOI={10.48550/arXiv.2012.07788}, note={arXiv:2012.07788 [cs]}, number={arXiv:2012.07788}, publisher={arXiv}, author={Muennighoff, Niklas}, year={2020}, month={Dec} }

@inproceedings{caoPromptHate2022,
    title = "Prompting for Multimodal Hateful Meme Classification",
    author = "Cao, Rui  and
      Lee, Roy Ka-Wei  and
      Chong, Wen-Haw  and
      Jiang, Jing",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.22",
    doi = "10.18653/v1/2022.emnlp-main.22",
    pages = "321--332",
}

@inproceedings{clip2021, title={Learning Transferable Visual Models From Natural Language Supervision}, ISSN={2640-3498}, url={https://proceedings.mlr.press/v139/radford21a.html}, booktitle={Proceedings of the 38th International Conference on Machine Learning}, publisher={PMLR}, author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya}, year={2021}, month={Jul}, pages={8748–8763}, language={en} }

@inproceedings{fater_RCNN_2015,
 author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
 url = {https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf},
 volume = {28},
 year = {2015}
}

@inbook{li2020oscar, address={Cham}, series={Lecture Notes in Computer Science}, title={Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks}, volume={12375}, ISBN={978-3-030-58576-1}, url={https://link.springer.com/10.1007/978-3-030-58577-8_8}, DOI={10.1007/978-3-030-58577-8_8}, booktitle={Computer Vision – ECCV 2020}, publisher={Springer International Publishing}, author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and Choi, Yejin and Gao, Jianfeng}, editor={Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael}, year={2020}, pages={121–137}, collection={Lecture Notes in Computer Science}, language={en} }

@inproceedings{vinVL2021, title={VinVL: Revisiting Visual Representations in Vision-Language Models}, url={https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_VinVL_Revisiting_Visual_Representations_in_Vision-Language_Models_CVPR_2021_paper.html}, author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng}, year={2021}, pages={5579–5588}, language={en} }

