\section{Related Work}
\label{sec:relatedwork}
\subsection{Dataset Discovery} 
Dataset discovery has been widely studied in the data management community____, with table search  as the primary application. 
% A prevalent line  is query-driven discovery that aims to search for the tables from data lakes or large open data repositories, according to a user's query.  
% Earlier studies____ aim to find web tables related to the given keywords with the help of metadata. 
The main sub-tasks of table search are joinable table search and table union search.
% When given a query table for search, the main sub-tasks are joinable table search and table union search.

\textbf{Joinable table search.}
To support joinable table search, most studies____ focus on equi-join and utilize syntactic similarity measures to determine joinanility between columns. 
% Aurum____ and D3L____ use Jaccard distance, while LSH Ensemble____ and Josie____ adopt Jaccard set containment to alleviate the bias to shorter columns. Some recent studies extend the equi-join to correlated table discovery____ or n-ary joins____.
% These methods do not consider semantics of columns.
To take semantics into consideration, PEXESO____ proposes a semantic joinability measure, and designs a cell-level exact algorithm under this measure using word embeddings. To enhance efficiency, the following column-level solutions, such as DeepJoin____ and WarpGate____, perform coarser computation at column-level to approximate the results of cell-level solutions. However, the effectiveness is poor due to the suboptimal column embeddings. In contrast, our $\textsf{Snoopy}$ is an effective column-level framework powered by the proxy-column-based column embeddings.
Recent works____ on semantic overlap set search are related to join discovery, but adopt a different semantic overlap (join) measure from the previous studies____ and ours. 
OmniMatch____, a concurrent work with ours, detects both equi-joins and fuzzy-joins by combining multiple similarity measures. However, it views join discovery as an offline procedure____, unlike online procedures where high efficiency is a crucial demand.


\textbf{Table union search.} The goal of table union search is to find tables that can be unioned with the query table to extend it with tuples. TUS____ defines table union search based on attribute unionability, and formalizes three probabilistic models to describe how unionable attributes are
generated from different domains.
D3L____ further adds in measures that include formatting similarity and attribute names. SANTOS____
% and Starmie____ consider the relationships between columns and achieve better accuracy.
considers the relationships between columns and uses a knowledge base to identify  unionable tables. Starmie____ extends the notion of capturing binary relationships to use the context of the table to determine union-ability. 
 
 





% \noindent\textbf{Joinable table search.} 
% % \subsection{Joinable Table Search}
% To find joinable tables from large table repositories or data lakes, most studies____ focus on equi-join and utilize syntactic similarity metrics to measure joinability between columns. Aurum____ and D3L____ use Jaccard distance as the similarity measure. Since Jaccard similarity has a bias to shorter columns, solutions based on Jaccard set containment____ have been proposed.
% % , which are more robust under different cardinalities.
% Some recent studies extend the requirement of column joinability, such as the Join-Correlation Search____ which aims to find joinable and correlated tables, and MATE____ which aims to find n-ary joinable tables.
% To take semantics into consideration, PEXESO____, the first semantically joinable table search solution, uses word embeddings to capture the semantics of cell values as multi-dimensional vectors, and finds tables that can be fuzzy joined using similarity predicates.




% All the studies above, however, exclude the semantic-joinable tables, and would miss substantial join opportunities. To take semantics into consideration, PEXESO____, the first semantically joinable table search solution, uses word embeddings to capture the semantics of cell values as multi-dimensional vectors, and finds tables that can be fuzzy joined using similarity predicates. Although the pivot-based index and filtering techniques are adopted to accelerate the search procedure, the efficiency is still limited due to the complex cell-level similarity computations. By contrast, the column-level solutions perform coarser computation at the column level, improving efficiency by transforming the entire column to a fixed-dimensional embedding.
% To the best of our knowledge, DeepJoin____ and WarpGate____ are the only existing column-level methods.
% DeepJoin____ encodes each column via the pre-trained language models. WarpGate____ suggests using the pre-trained table embedding models____ to encode columns. 
% The main shortcoming of existing column-level methods is the sub-optimal column representation derived by transformer-based column encoders. 
% Our work falls into the column-level category, but differs
% from existing methods mainly in the column representation, i.e., we design a novel column representation for effective and efficient joinable table search via the the proposed pivot columns.

% \vspace{1mm}
\subsection{Table Representation}
% \subsection{Table Representation}
Many researchers are exploring how to represent tabular data (i.e., structured data) with neural models____. Due to the huge success in natural language processing (NLP), pre-trained language models (e.g., BERT____, SBERT____, E5-base____, etc.) have been widely applied to represent different levels of tabular data, including entity matching (row-level)____, column type annotation (column-level)____, etc. To model the row-and-column structure as well as integrate the heterogeneous information from different components of tables, transformer-based table embedding models have been proposed, such as TURL____, TaBERT____, TAPAS____, etc. These models are based on Transformer architecture, and thus, enforce a length limit to token sequences (e.g. 512) due to the high computational complexity of the self-attention mechanism____. In contrast, our proposed column representation is size unlimited, which can well handle the long columns in the real table repositories.

% \textbf{Pivot-based techniques.} The pivot (proxy) concept has been widely used in diverse fields, such as representation learning____, data management in metric spaces____, etc. In the field  of representation learning, proxies represent the classes of data points and are used to better represent the objects in continuous spaces ____, improve the model generalization____, etc. In the field  of metric spaces, to reduce the number of distance computations and accelerate the similarity search, pivot-based filtering and indexing techniques____ have been proposed to pre-compute and store distances from every object in the metric space to a set of so-called pivots, and then utilize these distances to prune unqualified objects during search. 
% To improve the effectiveness of pivot-based techiniques in metric space,
% various pivot selection methods____ have been proposed.
% % For example, Farthest First Traversal (FFT)____ iteratively identifies a new pivot, which is the farthest from the current pivot set, and utilizes it to expand the existing pivot set. PCA for Pivot Selection (PCA)____ performs dimensionality reduction to select high-quality pivots, based on the FFT.
% For more information on pivot selection, please refer to the survey____. Although these pivot selection methods can be easily extended to select pivot columns in our problem, we provide a novel perspective to regard pivot columns as learnable parameters. We show that our learning-based method can achieve better performance than the traditional pivot selection strategies via experimental validation in Section~\ref{sec:exp_ablation}. 

\subsection{Contrastive Learning}
Contrastive learning____ (CL) is a discriminative approach that aims to pull similar samples closer and push apart dissimilar ones in the embedding space, and has achieved huge success in diverse domains.
In data discovery and preparation, CL is an effective method for learning high-quality data representations. Pylon____ and Starmie____ leverage CL to learn column representations for table discovery. Ember____  enables a general keyless join operator by constructing an index populated with task-specific embeddings via CL. Sudowoodo____ applies CL to learn entity, column, and cell representations to address multiple tasks in data preparation. Instead of directly learning the data items, in this paper, we leverage CL to learn proxy column matrices, which are then used to derive column representations efficiently. In contrast to the standard CL that requires a strict binary separation of the training pairs into similar and dissimilar samples, RINCE____ first proposes a new mechanism that preserves a ranked ordering of positive samples. Inspired by that, we incorporate rank awareness into the pivot column matrix learning process, focusing on designing a data generation method to synthesize ranked joinable columns to enable rank-aware CL.