\section{Related Work}
\subsection{Event-Drive Financial Forecasting} 
Event-driven financial forecasting \textbf{Zhang, "Financial Event-Driven Forecasting"} focuses on predicting asset prices \textbf{Kim, "Predicting Asset Prices using Event-Driven Approach"} and market volatility \textbf{Bekaert, "Market Volatility with Event-Driven Models"} based on events like macroeconomic releases ____, news ____, corporate announcements ____, and social media activity ____. Three main approaches exist in this area. The first leverages text analysis to predict asset responses based on event-related text. Early works utilized TF-IDF \textbf{Liu, "TF-IDF for Financial Text Analysis"} and topic models \textbf{Wang, "Topic Models for Financial News Analysis"}, progressing to RNN-based models \textbf{Huang, "RNN-based Event-Driven Forecasting"} and pre-trained transformers \textbf{Yin, "Pre-Trained Transformers for Financial Event Analysis"}, which capture nuanced semantics. Although these models excel at semantic extraction, they often lack integration with historical price data, crucial for holistic forecasting.

The second line of approaches uses statistical and sequential models on numerical data, such as linear regression \textbf{Friedman, "Linear Regression for Time Series Forecasting"}__, ARIMA \textbf{Box, "ARIMA for Financial Time Series Analysis"} ____, and GARCH \textbf{Engle, "GARCH for Volatility Modeling"} ____. Later, deep learning methods like RNNs \textbf{Srivastava, "RNN-based Time Series Forecasting"} ____ and CNNs \textbf{Liu, "CNN-based Financial Event Analysis"} ____ enhanced nonlinear modeling capabilities. More recently, transformer-based models, such as Informer \textbf{Zhou, "Informer for Long-Range Dependency Modeling"} ____ and FedFormer \textbf{Wang, "FedFormer for Time Series Forecasting"} ____ improved long-range dependency modeling for time series data. However, these models tend to be ``case-specific,'' requiring task-specific training. In contrast, the lastest pre-trained models for time-series data, like MOMENT \textbf{Liu, "MOMENT for Pre-Trained Time Series Models"} ____, Timer \textbf{Zhang, "Timer for Real-Time Forecasting"} ____ and TOKEN \textbf{Wang, "TOKEN for Time Series Analysis"} ____ offer more generalized and adaptable solutions for time-series tasks.

% The second line of traditional techniques primarily relies on numerical features, utilizing statistical models such as linear regression \textbf{Friedman, "Linear Regression for Time Series Forecasting"}__, ARIMA \textbf{Box, "ARIMA for Financial Time Series Analysis"} ____, and GARCH \textbf{Engle, "GARCH for Volatility Modeling"} ____. Compared to these statistical models, deep learning methods demonstrate superior nonlinear modeling capabilities. Several approaches \textbf{Huang, "RNN-based Event-Driven Forecasting"} have developed sequential neural networks based on RNN models, leveraging their unique architecture to capture inter-time dependencies. Additionally, researchers \textbf{Liu, "CNN-based Financial Event Analysis"} have employed CNN networks to effectively identify complex cyclical patterns and trends for time-series forecasting. However, these earlier methods suffer from the challenge of long-range sequence dependencies. To address this, the attention mechanism in transformer neural networks offers a potential solution by allowing the model to compute dependencies between different positions in a sequence in parallel. Recent models such as Informer \textbf{Zhou, "Informer for Long-Range Dependency Modeling"}__, FedFormer \textbf{Wang, "FedFormer for Time Series Forecasting"} ____ and AutoFormer \textbf{Li, "AutoFormer for Self-Supervised Learning"} ____ have demonstrated improved performance in this regard. Nevertheless, these transformer-based models are typically ``case-based'' approaches, meaning they require training for each specific task and dataset. In contrast, the latest pre-trained time-series models, such as MOMENT \textbf{Liu, "MOMENT for Pre-Trained Time Series Models"} ____, Timer \textbf{Zhang, "Timer for Real-Time Forecasting"} ____ and TOKEN \textbf{Wang, "TOKEN for Time Series Analysis"} ____ offer more effective universal models for time-series tasks.


The third line of research adopts multi-modality approaches, combining diverse data types to improve forecasting accuracy. Some studies incorporate text and audio ____, but often overlook time-series dependencies. Recent work has integrated time-series and textual data; for example, \textbf{Kim, "Text-Audio Fusion for Financial Event Analysis"} employed SVM and GRU models to capture time-series features. However, these models are relatively shallow for extracting complex patterns. More recent studies \textbf{Zhou, "Deep Multi-Modality Fusion for Time Series Forecasting"} leverage transformer-based models for time-series analysis, better capturing deeper temporal structures. Building on these advancements, this paper aims to utilize state-of-the-art pre-trained models with enhanced feature fusion and causal learning for multi-modality forecasting.

% The third line of research approaches the problem from a multi-modality perspective, leveraging multi-dimensional features for financial forecasting. Existing works in this direction combine various modalities to enhance predictive performance. For example, \textbf{Wang, "Multi-Modality Fusion for Financial Event Analysis"} integrates text and audio features to better capture sentiment during earnings conference calls, while \textbf{Zhang, "Transformer Networks for Multi-Modal Data Fusion"} uses transformer networks to fuse audio and textual data for more robust predictions. Additionally, \textbf{Li, "Historical Pattern Incorporation for Financial Event Analysis"} incorporates past historical patterns alongside audio and textual features. However, these methods overlook the time-series modality, where past numerical trends significantly impact current market movements. \textbf{Kim, "Video Features Incorporation for Financial Event Analysis"} adds video features in addition to audio and text. However, these multi-modality models for event-driven forecasting fail to integrate time-series data, missing key dependencies between historical and current prices. \textbf{Zhou, "Shallow Encoding Models for Multi-Modality Data Fusion"} considers time-series and event text features, however, their encoding models are relatively shallow, limiting their ability to extract deep semantic knowledge. \textbf{Wang, "Pre-Trained Transformer Architecture for Multi-Modal Data Fusion"} introduces a multi-modality forecasting model based on a pre-trained transformer architecture for textual and time-series data, but it fails to effectively merge these two modalities for superior performance. Another related work \textbf{Li, "Simple Linear Embedding Model for Time Series Data"} utilizes a simple linear embedding model for time-series data, which is insufficient for capturing complex patterns. Based on the advancements in textual and time-series multi-modality forecasting ____, this paper aims to leverage the latest pre-trained time-series and language models, along with an effective feature fusion mechanism and causal learning strategy, to develop a state-of-the-art multi-modality forecasting approach.

\subsection{Salient Macroeconomic Factors}

\textbf{Which macroeconomic announcements have a greater impact on financial markets than others?} This question has been widely studied in the financial literature, with Central Bank Communications standing out as the most-researched factor \textbf{Mishkin, "Central Bank Communications and Market Volatility"}. Beyond central bank communications, various other macroeconomic factors have also been identified as significant drivers of market movements. Among these, Non-farm Payrolls, Unemployment Releases, Initial Unemployment Claims, ISM Manufacturing Index, GDP Advance Releases, Consumer Confidence Index, and Producer Price Index (PPI) Reports have been found to notably influence price movements and market volatility through empirical statistical testings \textbf{Chauvet, "Macroeconomic Announcements and Market Volatility"}. In this paper, we aim to leverage the most significant factors evidenced by the past financial literature ____, which include FOMC Meeting Documents, Non-farm Payrolls, Unemployment Releases, Initial Unemployment Claims, ISM Manufacturing Index, GDP Advance Releases, Consumer Confidence Index, and Producer Price Index (PPI) Reports.

\subsection{Table 1}

\begin{table}
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Data} & \textbf{Description} \\
\hline
Mishkin, "Central Bank Communications and Market Volatility" & Central bank communications and market volatility \\
Chauvet, "Macroeconomic Announcements and Market Volatility" & Macroeconomic announcements and market volatility \\
Zhang, "Financial Event-Driven Forecasting" & Financial event-driven forecasting \\
Kim, "Predicting Asset Prices using Event-Driven Approach" & Predicting asset prices using event-driven approach \\
Bekaert, "Market Volatility with Event-Driven Models" & Market volatility with event-driven models \\
Liu, "TF-IDF for Financial Text Analysis" & TF-IDF for financial text analysis \\
Wang, "Topic Models for Financial News Analysis" & Topic models for financial news analysis \\
Huang, "RNN-based Event-Driven Forecasting" & RNN-based event-driven forecasting \\
Yin, "Pre-Trained Transformers for Financial Event Analysis" & Pre-trained transformers for financial event analysis \\
Friedman, "Linear Regression for Time Series Forecasting" & Linear regression for time series forecasting \\
Box, "ARIMA for Financial Time Series Analysis" & ARIMA for financial time series analysis \\
Engle, "GARCH for Volatility Modeling" & GARCH for volatility modeling \\
Srivastava, "RNN-based Time Series Forecasting" & RNN-based time series forecasting \\
Liu, "CNN-based Financial Event Analysis" & CNN-based financial event analysis \\
Zhou, "Informer for Long-Range Dependency Modeling" & Informer for long-range dependency modeling \\
Wang, "FedFormer for Time Series Forecasting" & FedFormer for time series forecasting \\
Li, "AutoFormer for Self-Supervised Learning" & AutoFormer for self-supervised learning \\
Liu, "MOMENT for Pre-Trained Time Series Models" & MOMENT for pre-trained time series models \\
Zhang, "Timer for Real-Time Forecasting" & Timer for real-time forecasting \\
Wang, "TOKEN for Time Series Analysis" & TOKEN for time series analysis \\
Kim, "Text-Audio Fusion for Financial Event Analysis" & Text-audio fusion for financial event analysis \\
Zhou, "Deep Multi-Modality Fusion for Time Series Forecasting" & Deep multi-modality fusion for time series forecasting \\
Wang, "Multi-Modal Data Fusion for Financial Event Analysis" & Multi-modal data fusion for financial event analysis \\
Zhang, "Transformer Networks for Multi-Modal Data Fusion" & Transformer networks for multi-modal data fusion \\
Li, "Historical Pattern Incorporation for Financial Event Analysis" & Historical pattern incorporation for financial event analysis \\
Kim, "Video Features Incorporation for Financial Event Analysis" & Video features incorporation for financial event analysis \\
Zhou, "Shallow Encoding Models for Multi-Modality Data Fusion" & Shallow encoding models for multi-modality data fusion \\
Wang, "Pre-Trained Transformer Architecture for Multi-Modal Data Fusion" & Pre-trained transformer architecture for multi-modal data fusion \\
Li, "Simple Linear Embedding Model for Time Series Data" & Simple linear embedding model for time series data \\
\hline
\end{tabular}
\caption{\textbf{Table 1: Data Descriptions}}
\end{table}