\section{Impact of the Prior Probability}
\label{sec:impact_of_prior_prob}
Multiple-choice questions are standard for evaluating a language model's natural language understanding. The model solves each question based on the probability {\small $P(Choice|Prompt)$} — the likelihood of generating a particular choice $Choice$ given the prompt $Prompt$. The predicted answer is the choice with the highest probability, and the number of correctly predicted answers determines accuracy. This section explores how {\small $P(Choice)$}, the prior probability, affects model performance when calculating {\small $P(Choice|Prompt)$}. 
%We also investigate how varying the answer choices affects the model's accuracy.

\begin{table*}[!t]
    \centering
    \caption{The percentage of cases in which the log prior probability difference exceeds the PMI difference for each dataset. A high percentage value indicates that the model's decision is primarily driven by the prior probability difference, indicating limited influence from the prompt.}
    \vspace{-0.2\baselineskip} % ACL Only
    \label{tab:comp_results}
    \resizebox{0.95\linewidth}{!}{%
    \begin{tabular}{c|r|r|r|r|r|r|r|r}
        \hline
        & \textbf{Hellaswag} & \textbf{PiQA} & \textbf{ARC-e} & \textbf{ARC-c} & \textbf{LogiQA} & \textbf{RACE} & \textbf{SciQ} & \textbf{MMLU} \\
        \hline
        \hline
        OPT-125M & 72.14\% & 78.62\% & 53.03\% & 58.62\% & 50.69\% & 55.22\% & 33.90\% & 96.39\% \\
        OPT-350M & 72.13\% & 79.38\% & 51.43\% & 54.61\% & 50.23\% & 55.50\% & 29.40\% & 81.74\% \\
        OPT-1.3B & 70.33\% & 76.17\% & 48.57\% & 53.67\% & 49.16\% & 56.08\% & 26.70\% & 15.23\% \\
        OPT-2.7B & 69.40\% & 76.33\% & 49.41\% & 55.63\% & 49.46\% & 53.68\% & 25.30\% & 13.33\% \\
        OPT-6.7B & 67.96\% & 74.65\% & 45.88\% & 52.22\% & 51.61\% & 53.30\% & 20.70\% & 29.56\% \\
        \hline
        Mistral-7B & 60.35\% & 64.25\% & 27.15\% & 37.37\% & 46.85\% & 47.94\% & 7.80\% & 13.05\% \\
        Gemma-7B & 75.60\% & 80.63\% & 56.99\% & 56.57\% & 48.39\% & 57.61\% & 48.30\% & 14.72\% \\
        LLaMA3.1-8B & 65.26\% & 71.82\% & 37.25\% & 44.71\% & 49.00\% & 48.80\% & 16.50\% & 15.95\% \\
        \hline
    \end{tabular}
    }
\end{table*}

% We divide {\small $P(Choice|Prompt)$} into two components: 
We decompose {\small $P(Choice|Prompt)$} by multiplying and dividing by {\small $P(Choice)$}, leading to two components:
{\small $P(Choice)$} determined independently of the prompt and {\small $\dfrac{P(Choice|Prompt)}{P(Choice)}$} influenced by the prompt. This allows us to express {\small $P(Choice|Prompt)$} as a product of the two components: 

\begin{small}
\begin{equation}
\label{eq:p(x|y)}
\begin{array}{l}
P(Choice|Prompt) \\[5pt]
\quad \quad = P(Choice) \cdot \dfrac{P(Choice|Prompt)}{P(Choice)}.
\end{array}
\end{equation}
\end{small}
{\small $P(Choice)$} represents the probability of generating a choice $Choice$ without any prompt, which we refer to as \textit{prior probability}. On the other hand, {\small $\dfrac{P(Choice|Prompt)}{P(Choice)}$} indicates how much the prompt $Prompt$ affects the probability of generating the choice $Choice$. It is equivalent to the exponential of the \textit{Pointwise Mutual Information (PMI)}, $\log{\frac{P(Choice|Prompt)}{P(Choice)}}$~\cite{pmi}. We analyze the two components for each choice across various benchmarks to understand how the choices influence the model's final decision.



% \subsection{Prior Probability vs. PMI}
% \subsection{Effects of Prior Probability and PMI}
% \label{sec:comparision_pp_vs_pmi}
% \sloppy
We investigate which of the two components influences the model's final decision more.  We focus on two choices,  $C_1$ with the highest value of {\small $P(Choice|Prompt)$}  and $C_2$ with the second highest, among all choices.  We compare them by calculating {\small $\log{P(C_1|Prompt)}-\log{P(C_2|Prompt)}$}. By taking the logarithm of both sides of Equation~\eqref{eq:p(x|y)}, we express {\small $\log{P(Choice|Prompt)}$} as the sum of the log prior probability and the PMI:
\begin{small}
\[
%\begin{*equation}
%\label{eq:logp(x|y)}
\begin{array}{l}
\log P(Choice|Prompt) \\
\quad \quad = \log P(Choice) + \log \dfrac{P(Choice|Prompt)}{P(Choice)}.
\end{array}
%\end{*equation}
\]
\end{small}
Then, we calculate $\log{P(C_1|Prompt)} - \log{P(C_2|Prompt)}$ using the differences in log prior probabilities and PMIs between $C_1$ and $C_2$ as follows:

\begin{small}
\[
%\begin{*equation}
%\label{eq:logp(c1)}
\begin{array}{l}
\log{P(C_1|Prompt)} - \log{P(C_2|Prompt)} \\[5pt]
\; = (\log P(C_1) - \log P(C_2)) \\[5pt]
\; \; + \left(\log \dfrac{P(C_1|Prompt)}{P(C_1)} - \log \dfrac{P(C_2|Prompt)}{P(C_2)}\right)\\[10pt]
\; = (\log P(C_1) - \log P(C_2)) \\[5pt]
\; \;  + (\mbox{PMI}(C_1,Prompt) - \mbox{PMI}(C_2,Prompt)).
\end{array}
%\end{*equation}
\]
\end{small}

Suppose the final decision is primarily driven by differences in prior probability between the two choices. In that case, we expect the difference of the log prior probabilities to exceed that of the PMI values as follows:

\begin{small}
\[
%\begin{equation}
\begin{array}{l}
(\log{P(C_1)} - \log{P(C_2)})\\[5pt]
\quad > (\mbox{PMI}(C_1,Prompt) - \mbox{PMI}(C_2,Prompt)).
\end{array}
%\label{eq:choice_ratio_comparison}
%\end{equation}
\]
\end{small}
Otherwise, we expect the difference in the PMI values to be higher. To analyze whether the model's final decision is more influenced by the prior probability or exponential of PMI, we calculate the percentage of cases where the difference of the log prior probabilities exceeds the difference of the PMI  values across various benchmarks. A higher percentage indicates that the model's final choice is primarily influenced by the prior probability, implying that the prompt has a limited impact on the final decision. 

The experiment is performed across eight multiple-choice tasks~\citep{welbl2017crowdsourcing, lai2017race, hendrycks2020measuring, liu2021logiqa} including Hellaswag~\citep{hellaswag}, PiQA~\citep{bisk2020piqa}, and ARC (easy and challenge)~\citep{clark2018think} using four different language models: OPT with five different sizes(125M, 350M, 1.3B, 2.7B, and 6.7B)~\citep{zhang2022opt}, LLaMA3.1-8B~\citep{dubey2024llama}, Mistral-7B(version 0.3)~\citep{jiang2024mixtral}, and Gemma-7B~\citep{team2024gemma}. We employ the instruction-tuned versions of LLaMA3.1, Mistral, and Gemma. The benchmarks used are briefly described in Appendix~\ref{sec:app-benchmark}. All results are measured under the zero-shot setting using Language Model Evaluation Harness~\citep{eval-harness}. The results are summarized in Table~\ref{tab:comp_results}. 

% \begin{table*}[!t]
% \centering
% \caption{Model performance before and after altering the choices. \textbf{Orig} refers to the performance before altering the choices, \textbf{Modified} refers to the performance after replacing the choice with the smallest {\small $P(Choice|Prompt)$} value by "Hi."}
% \resizebox{\linewidth}{!}{%
% \begin{tabular}{l|ccc|ccc|ccc}
% \hline
% \multirow{2}{*}{Model} & \multicolumn{3}{|c|}{\textbf{Hellaswag}} & \multicolumn{3}{|c|}{\textbf{Arc-e}} & \multicolumn{3}{|c}{\textbf{SciQ}} \\
% \cline{2-10} & Orig & Modified & Orig - Modified & Orig & Modified & Orig - Modified & Orig & Modified & Orig - Modified  \\
% \hline
% \hline
% Mistral-7B   & 64.73\%  & 3.97\% & -60.76\%    & 84.30\%  & 71.51\% & -12.79\%   & 96.30\%  & 95.80\% & -0.50\%   \\
% Gemma-7B     & 55.97\%  & 3.65\% & -52.32\%    & 75.72\%  & 61.70\% & -14.02\%   & 95.40\%  & 93.80\% & -1.60\%   \\
% LLaMA3.1-8B    & 59.05\%  & 3.66\% & -55.39\%    & 81.78\%  & 65.70\% & -16.08\%   & 96.60\%  & 96.20\% & -0.40\%   \\
% \hline
% \end{tabular}
% }
% \label{table:accuracy_metrics}
% \end{table*}

\begin{figure*}[!t]
   \centering
   \includegraphics[width=0.95\linewidth]{figure/2_acc_norm_example.pdf}
   % \vspace*{-1\baselineskip}
   \caption{Comparison of log probabilities for Hellaswag choices options based on their length. We use instruction-tuned LLaMA3.1-8B.}
\label{fig:len_prob_distribution}
\end{figure*}


When a model lacks sufficient language understanding capability, the probabilities of choices are generated independently of the prompt, i.e., {\small $P(Choice|Prompt)=P(Choice)$}, leading to higher percentages in Table~\ref{tab:comp_results}. For the OPT model, as the model size increases, we observe that the percentage decreases for most benchmarks in general, leading to improved language understanding. On the other hand, for the models Mistral-7B, Gemma-7B, and LLaMA3.1-8B, where instruction tuning has been applied to significantly enhance the downstream task performance~\citep{ouyang2022training, rafailov2024direct}, up to 80\% of choices are still determined by the prior probability difference. This reinforces the assertion that, in many cases, the prior probability plays a significant role in determining the model's overall performance. 

{To provide a concrete example for better understanding, we include an experiment in the Appendix\hbox{~\ref{sec:hi_experiment}} that measures how the model’s decision changes when we add a choice, "Hi", which has a high prior probability but is irrelevant to the prompt, to MCQ benchmarks.}

% \subsection{Effects of Altering Choices}

% \hl{To further investigate the impact of {\small $P(Choice)$} on the model performance, we modify the choices for each problem and examine how these changes affect the model performance. 
% We append the sentence "Hi" as the answer choice in each question. The sentence "Hi" appears frequently in various text data, resulting in a high prior probability \mbox{$P(\text{"Hi"})$}. However, since choices like "Hi" are unrelated to the prompt, the model's performance should remain stable if it truly relies on prompt understanding rather than \mbox{{\small $P(Choice)$}} alone. If such a choice affects the model's decisions, this would indicate that \mbox{\small $P(Choice)$} plays a significant role in the model's decision-making. We expect that appending a choice with a high prior probability, such as "Hi," will lead to cases where the model incorrectly selects this option over the correct one. To verify it, we perform an experiment using three instruction-tuned language models: Mistral-7B(version 0.3), Gemma-7B, and LLaMA3.1-8B, with three downstream tasks: Hellaswag, Arc-easy, and SciQ. The results are summarized in Table\mbox{~\ref{table:accuracy_metrics}}.}

% \begin{table}[ht]
% \centering
% \caption{\hl{The rate of answer change in the model's final decision on choices when the additional choice "Hi" is introduced.}}
% \vspace{-0.5\baselineskip} % ACL Only
% \resizebox{0.95\linewidth}{!}{%
% \begin{tabular}{l|c|c|c}
% \hline
% \multirow{2}{*}{Model} & \textbf{Hellaswag} & \textbf{Arc-e} & \textbf{SciQ} \\
% \cline{2-4} & Rate & Rate & Rate \\
% \hline
% \hline
% Mistral-7B   & 94.90\%    & 19.19\%   &0.80\%   \\
% Gemma-7B     & 94.88\%    & 25.25\%   & 2.20\%   \\
% LLaMA3.1-8B    & 95.10\%    & 24.20\%   & 0.90\%   \\
% \hline
% \end{tabular}
% }
% \label{table:accuracy_metrics}
% \end{table}

% \hl{Table\mbox{~\ref{table:accuracy_metrics}} shows that the model's final choice decisions are affected across all benchmarks when the additional choice is introduced. For SciQ, the effect is relatively minor, with the rate of answer change in the model's final decision ranging from 0.8\% to 2.2\%. 
% % {\bf === what is the answer change rate ===} 
% The log prior probability difference has less impact on performance than the PMI difference. However, in the case of Hellaswag, 94.88\% to 95.10\% of the model's decisions are changed due to the addition of the choice, demonstrating how significantly the prior probability difference can influence the model's decisions. The results demonstrate that \mbox{\small $P(Choice)$} substantially affects model performance depending on the benchmark.}