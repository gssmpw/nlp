
\section{The Proposed Metric, ANPMI}
We observed that due to the imbalance in {\small $P(Choice)$}, accurately assessing a model's language comprehension ability in multiple-choice tasks is challenging. While carefully constructing answer choices could address this issue, designing choices that prevent {\small $  P(Choice)$} imbalance across all language models is impractical. Thus, we propose a normalized PMI metric, \textit{Asymmetric NPMI (ANPMI)} to evaluate the model performance in multiple-choice tasks. It is defined as follows:   

\begin{small}
\begin{equation}
\begin{array}{l}
\mbox{ANPMI}(Choice,Prompt) \\[5pt]
\quad \quad \quad \quad = \dfrac{\mbox{PMI}(Choice,Prompt)}{-\log{P(Choice)}}.
\end{array}
\label{eq:anpmi}
\end{equation}
\end{small}
It mitigates the influence of the {\small $P(Choice)$} imbalance, offering a more reliable indicator of a model's understanding of the prompt.

\begin{figure*}[!t]
   \centering
   \includegraphics[width=0.95\linewidth]{figure/3_new_metrics.pdf}
   \vspace*{-0.5\baselineskip}
   \caption{Comparison of the existing metrics and ANPMI for three different choice options, A, B and C.  
   % {\bf === what are the red arrows? ===}
   {To ensure a fair and accurate evaluation, the positions of the dotted lines and gray lines must be consistent across all choices.}} 
   % {\bf === remove "Q:Does ... for a fair comparison?" ===} {\bf == value of "the" metric ===}
   % {\bf === Hard to compare Fairly ==> Unfair comparison, Enable Fair comparison ==> Fair comparison, Q:Can we fairly determine which arrow is pointing higher? ==>  Q:Can we fairly determine which arrow points higher? ===} 
   % {\bf === Q:Can we fairly determine which arrow is pointing higher?, I do not understand this ===} 
   % {\bf === do not capitalize the explanation such as "Value of Mteric w Prompt" except the first char ===}
   % The value of {\small $P(Choice| Prompt)$} differs depending on choices when no prompt is given. Furthermore, PMI has a different theoretical maximum value depending on the choice. Normalizing by the length and NPMI mitigates this difference but does not eliminate it due to their incorrect assumptions. ANMPI, on the other hand, always has the same value for all cases independent of the prompt.} {\bf === Theoretical min/ ... value of metric ==> ... value of the metric}
\label{fig:metric_comparison}
\end{figure*}

Ideally, the following requirements should be met by an assessment metric to measure a model's true language comprehension capability:
\begin{itemize}
\item In the absence of a prompt, the model should assign equal probabilities to each choice option of a question, indicating that the prompt is essential for answering it. 
\item The maximum and minimum values for the metric for selecting choices should remain consistent across the choices. 
A fair comparison between choices becomes difficult if a certain choice yields a disproportionately high or low value. 
\end{itemize}

Theoretically, PMI meets the first requirement for accurately assessing a model's language comprehension ability. However, it does not satisfy the second requirement (discussed in Section~\ref{sec:metric_mi}). PMI may yield different maximum values depending on the choice. 

{NPMI normalizes PMI under the assumption that \hbox{\small $P(Choice,Prompt) = P(Prompt,Choice)$}. However, this assumption does not hold in the language model, making it an unsuitable normalization method.}
% The maximum possible PMI value is {\small $  -\log{P(Choice)}$} when a prompt {\small $  Prompt$} exists. As a result, each choice has a different maximum possible value based on its prior probability.
To overcome this, we propose ANPMI (Asymmetric NPMI) that {divides} PMI by {\small $  -\log P(Choice)$} for the evaluation metric.
% \hl{Here, normalization involves dividing PMI by {\small $-\log P(\text{Choice})$}, as explained earlier in the context of NPMI, rather than subtracting it.} 
% It yields a value from 1 to {\small $  -\infty$} regardless of the choice, thus satisfying the second requirement for fair and accurate evaluation. 

% In language models, since \( P(y) P(x|y) = P(y, x) \neq P(x, y) \), the value of \( P(y) \) is not related to the maximum possible value of \( \text{PMI}_{\text{LM}}(x, y) \). This is because, in a language model, $y$ is not a subset of $x + y$. Unlike traditional probability distributions, a language model generates text sequentiallyâ€”given $x$, it can only predict what comes next, not what came before. Therefore, when normalizing $ \text{PMI}_{\text{LM}}$, inequality~\ref{eq:ieq_2} doesn't need to be considered. Consequently, Unlike NPMI, which divides PMI by {\small $  -\log P(Choice, Prompt)$}, ANPMI divides PMI by {\small $  -\log P(Choice)$}.
% to consider the inherent asymmetry in {\small $ P(Choice, Prompt)$} when computed with a language model.

{Let \hbox{$x$} be \hbox{$Choice$}, and \hbox{$y$} be \hbox{$Prompt$}. Then, from Equation\hbox{~\ref{eq:pmi_lm}} and Equation\hbox{~\ref{eq:ieq_1}}, we can say,}
\begin{small}
\[
%\begin{equation}
\begin{array}{l}
\text{PMI}_{\text{LM}}(x, y) = \log \dfrac{P(x, y)}{P(x) P(y)} \\ 
= \log \dfrac{P(x | y)}{P(x)} \le -\log P(x)
\end{array}
%\end{equation}
\]
\end{small}
{However, since \hbox{$x+y$} is not a subset of \hbox{$y$}, Equation\hbox{~\ref{eq:ieq_2}} does not hold, meaning \hbox{$\text{PMI}_{\text{LM}}(x, y)$} is not bounded by \hbox{$P(y)$}.} {If \hbox{$x + y$} is a subset of \hbox{$y$}, the following relation holds:}
\begin{small}
\[ P(y)P(x|y)=P(x,y)=P(y+x) \]
\end{small}
{However, \hbox{$P(x|y)$} represents the probability of generating \hbox{$x$} given \hbox{$y$} in a language model. This leads to:}
\begin{small}
\[ P(y) P(x|y) = P(y,x) \neq P(x, y) = P(y+x) \]
\end{small}
{As a result, $\text{PMI}_{\text{LM}}(x, y)$ is only bounded by $P(x)$. Thus, dividing by {\small $-\log  P(Choice)$} ensures that ANMPI takes a value from 1 to {\small $  -\infty$} regardless of the choice, satisfying the second requirement for fair and accurate evaluation. 

Figure\hbox{~\ref{fig:metric_comparison}} illustrates how these characteristics distinguish ANPMI from existing metrics.} 
% {\bf === explain Figure here in detail. It is hard to understand. ===}
{Dotted lines indicate values calculated without a prompt, while the heads of arrows represent values after a prompt is provided. The solid gray lines denote the theoretical minimum and maximum values. The red arrows are the arrows pointing to the highest place. The length of the arrow indicates the difference in metric values before and after a prompt is provided for each choice. The length is critical in assessing the model's understanding of the prompt. Additionally, the two essential conditions for accurately measuring the model's understanding, as mentioned earlier:}
\begin{itemize}
\item { The positions of the dashed lines (i.e., values calculated without a prompt) across choices must be the same.}
\item {The positions of the gray solid lines (the maximum and minimum values) across choices must also be the same.}
\end{itemize} 
{Conditional probability and length-normalized conditional probability fail to satisfy the first condition, as shown in Figure \hbox{~\ref{fig:metric_comparison}} (a) Choice B, where the positions of the dashed lines differ. PMI and NPMI do not satisfy the second condition, as shown in Figure\hbox{~\ref{fig:metric_comparison}} (a) Choice C, where the positions of the gray solid lines differ. In contrast, as shown in Figure\hbox{~\ref{fig:metric_comparison}} (b), ANPMI ensures that the dashed lines and the gray solid lines remain consistent across all choices, satisfying the two necessary conditions for accurately assessing a model's understanding of a prompt.}

% Unlike NPMI, ANPMI normalizes by P(x) instead.

% From Equation~\ref{eq:pmi_lm}, we find,

% \begin{small}
% \begin{equation}
% \begin{array}{l}
% \mbox{PMI}_{LM}(Choice, Prompt) \\
% = \log \dfrac{P(Choice|Prompt)}{P(Choice)} \le - \log P(Choice).
% \end{array}
% \end{equation}
% \end{small}

% Therefore, dividing by {\small $-\log  P(Choice)$} ensures that ANMPI taks a value from 1 to {\small $  -\infty$} regardless of the choice, thus satisfying the second requirement for fair and accurate evaluation. 

% Thus, the maximum of PMI in a language model is {\small $-\log  P(Choice)$}, not {\small $-\log P(Choice, Prompt)$}, which is why ANPMI normalizes PMI using {\small $-\log P(Choice)$} to account for the asymmetry.

% Specifically, in language models, {\small $  P(Choice, Prompt) \neq P(Prompt, Choice)$}, which makes normalization by {\small $  -\log P(Choice)$} more appropriate. {\bf === I do not understand this ====}

% When {\small $ P(Choice, Prompt) = P(Prompt, Choice)$}, PMI satisfies the following relationship:
% \begin{small}
% \begin{equation} 
% \begin{array}{l}
% \mbox{PMI}(Choice, Prompt) \\
% \quad = \log \frac{P(Choice, Prompt)}{P(Choice)P(Prompt)} \\
% \quad = \log \frac{P(Choice|Prompt)}{P(Choice)} \\
% \quad = \log \frac{P(Prompt|Choice)}{P(Prompt)}.    
% \end{array}
% \end{equation}
% \end{small}

% In this symmetric case, we find, 
% \begin{small}
% \[ \log \frac{P(Choice|Prompt)}{P(Choice)} \le -\log P(Choice) \] 
% \end{small}
% and 
% \begin{small}
% \[\log \frac{P(Prompt|Choice)}{P(Prompt)} \le -\log P(Prompt)\]
% \end{small}
% This means,
% \begin{small}
% \[
% \begin{array}{l}
% \max(\mbox{PMI}(Choice, Prompt)) \\
% \quad = \min(-\log P(Choice), -\log P(Prompt)).
% \end{array}
% \]
% \end{small}
% Normalization by {\small $  -\log P(Choice, Prompt)$} ensures the maximum value 1 because,
% \begin{small}
% \[ -\log P(Choice) < -\log P(Choice, Prompt)\]
% \end{small}
% and 
% \begin{small}
% \[ -\log P(Prompt) < -\log P(Choice, Prompt). \] 
% \end{small}

% However, in the case of language models, {\small $  P(x,y)$} represents the probability of generating the sentence {\small $  y + x$}, leading to {\small $  P(x, y) \neq P(y, x)$}. Thus, PMI in language models satisfies the following relationship:
% \begin{equation}
% \small
% \mbox{PMI}_{LM}(x, y) = \log \frac{P(x|y)}{P(x)} \neq \log \frac{P(y|x)}{P(y)}.
% \end{equation}

% As a result, the maximum value of {\small $ \mbox{PMI}(Choice, Prompt)$} is limited by {\small $  -\log P(Choice)$}, which is why ANPMI normalizes PMI using {\small $-\log P(Choice)$} to account for the asymmetry.