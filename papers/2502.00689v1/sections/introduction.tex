
The IoT-Together \cite{spalazzese2023shaping}, a Mixed-Initiative Paradigm \cite{horvitz1999principles} promotes collaboration between users and intelligent IoT systems, where both actively shape and co-generate IoT solutions. This paradigm helps users explore suitable options for their needs and preferences, especially in dynamic, underspecified IoT systems. For example, in a Smart City scenario, a tourist arrives without a plan and, through collaboration with the system, identifies an itinerary that matches their preferences. The paradigm encompasses several key aspects. First, it recognizes that user goals may be unclear or evolve over time, allowing users to express their goals and preferences dynamically, such as finding activities in a smart city or indicating a preference for walking. Second, it establishes an initial interaction point, typically via smartphone or totem, where users can define their needs, setting the stage for ongoing collaboration. Third, the paradigm supports dynamic, real-time IoT system generation that adapts to user's evolving needs. Finally, it emphasizes the need for designing systems that can clearly explain actions and recommendations, helping users make informed decisions without feeling overwhelmed.


While the IoT-Together Paradigm offers a conceptual framework, realizing key components such as dynamic goal understanding and system generation presents significant challenges. Large Language Models (LLMs) offer promising capabilities in addressing these challenges, particularly due to their adept natural language understanding and structured knowledge extraction abilities, which are essential for implementing the paradigm's core aspects of natural interaction and facilitate dynamic system adaptation\cite{he2024doespromptformattingimpact}. Also, existing IoT frameworks often rely on pre-defined service catalogs, limiting their ability to adapt dynamically when user goals require services not already implemented\cite{7479556}. To this end, we propose an LLM-powered architecture that enables dynamic goal derivation from user interactions and runtime service generation based on available IoT definitions and data schemas. This ensures that new services are only generated when corresponding sensor data and service descriptions are present, grounding the system's adaptability in its existing context. Fig.~\ref{fig:initial-interaction-diagram} demonstrates our realized approach, showing how the system engages in structured dialogue with users to understand their needs, processes these inputs through LLM-powered components, and generates appropriate IoT solutionsâ€”a concrete implementation of the interaction framework that was conceptually proposed in the original paradigm.





Our architecture implements these capabilities through dynamic goal extraction from natural language user queries, real-time service composition based on available IoT definitions, and adaptive service generation that aligns with both user preferences and system constraints. To validate our approach, we present a smart city case study centered in Hyderabad. The evaluation employs a multi-agent simulation framework and a user study. We assess system performance through multiple dimensions: (1)~service identification accuracy (2)~code generation quality and (3)~system efficiency through token consumption and latency measurements. The evaluation demonstrates the system's capability to identify user needs along with the generation of appropriate services based on their needs while maintaining efficiency in both service generation and overall application composition.