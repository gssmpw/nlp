



Recent advances in adaptive systems and human-centric computing have produced notable approaches for managing IoT environments. Mayer et al. \cite{7444198} propose a semantic technology-based framework for user goal modeling, while Abughazala et al. \cite{abughazala2021human} combine Agent-Based Modeling with architectural techniques to translate human interactions into actionable configurations. De Sanctis et al. \cite{de2021user} developed a multi-level self-adaptation approach driven by users at run-time. Moghaddam et al. \cite{moghaddam2023user} introduce an emotion-aware framework optimizing QoE and QoS through Model-Free Reinforcement Learning, and Yigitbas et al. \cite{yigitbas2020integrated} contribute a model-driven development approach using domain-specific languages for context modeling. 
Qian et al.\cite{7479556} proposed MobiGoal, a framework using a runtime goal model to adaptively schedule user goals and execute tasks. While MobiGoal defines goals during design-time to guide application development and runtime execution, our approach allows user goals to emerge dynamically at runtime without requiring users to understand the goal model. Recent advances in Large Language Models (LLMs) have opened new possibilities for bridging human intent and system adaptation. While traditional program synthesis focused on predefined approaches \cite{DBLP:journals/corr/RaghothamanU14}, modern LLMs like GPT-4 \cite{jiang2024selfplanningcodegenerationlarge}\cite{he2024doespromptformattingimpact} and DeepSeek-V2 \cite{deepseekai2024deepseekv2strongeconomicalefficient} demonstrate proficiency in understanding user intent and generating functional code, enabling systems to dynamically interpret and adapt to user goals through natural language interaction.
Further, significant progress in multi-agent \cite{wu2023autogenenablingnextgenllm} work which provide mechanisms for agents to share context, negotiate goals, and collectively adapt to changing environments.
While existing human-centric IoT systems often rely on predefined adaptation mechanisms, our work introduces a novel architecture integrating large language models (LLMs) to enable real-time service adaptation through natural language interactions. Inspired by Spalazzese et al.'s \cite{spalazzese2023shaping} Mixed-Initiative paradigm of collaborative goal refinement, we extend IoT system capabilities by incorporating LLM-based components for dynamic runtime adaptation. By combining natural language processing, sensor data integration, and runtime adaptability, our approach advances flexible, user-centric solutions for evolving IoT environments.