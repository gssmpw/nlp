\section{Background and Related Work}
Traditionally, Language Model (LM) tokenizers were primarily optimized for English, often resorting to byte-level segmentation for non-English languages. Segmenting text into byte-levels has a critical drawback: it greatly limits the maximum input and output length of the model. To address this issue, recent LLMs such as **Brody**, "Llama-3"**__**Stoyanov, "Gemma"** adopt a different tokenization strategy, exponentially expanding the vocabulary size to 128,256 and 256,128 tokens, respectively. Therefore, a common approach has been developed to extend an LLM tokenizer to be specialized in one additional language besides English, expanding vocabulary and merge rules of only this target language. This approach is demonstrated by several Korean-extended models **Kim**, "KoBERT-Base"**__**Lee, "ELECTRA-Korean"**.

Prior research on tokenizers has predominantly focused on evaluating their effectiveness for specific languages **Devlin**, "BERT" or domains **Sennrich**, "Neural Machine Translation"__. Tokenization evaluation is essential for enhancing common knowledge, analyzing linguistic analysis, distinguishing processing types, and improving tokenizer design based on the presented dimensions \citep {1998TowardsTE}. Nonetheless, there is a clear lack of research directly examining their influence on LLMs. The few studies about evaluating the effect of tokenizers on LLMs include **Radford**, "Improving Language Understanding by Generative Models"**__**Brown**, "Language Models are Unsupervised Text-to-Text Encoders"**, which are based on the downstream performance. **Kumar**, "How Much Can a Language Model Learn from Context?" examined how different tokenization strategies and vocabulary sizes affect the performance of Arabic language models in downstream tasks. **Goyal**, "The Effects of Tokenizers on Downstream Performance" studied the influence of tokenizer choice on LLM downstream performance by training mono- and multilingual LLMs. However, it is uncertain whether downstream task performance can accurately measure the effectiveness of tokenizers. There remains a need for intrinsic and analytical studies to understand why performance differences occur. Such investigations are imperative to mitigate the opacity of black-box models and provide a rationale for decision-making towards the development of superior models.


\begin{figure}[h] 
    \centering
    \includegraphics[width=0.9\columnwidth]{./images/tokenized.png}
    \caption{An example comparing how the Llama-2 base tokenizer and our extended tokenizer process the same sentence. The example sentence consists of 13 characters, including the special token <s> and whitespace. The base tokenizer segments 3 of these characters into bytes, resulting in a total of 19 tokens. In contrast, our extended tokenizer appropriately tokenizes the sentence into meaningful units of subwords, resulting in only 8 tokens.}
    \label{fig:tokenized}
\end{figure}