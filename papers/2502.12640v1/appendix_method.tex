


\section{Methodological Details}\label{app:method}


In this part, we further complement the introduction of the RecDreamer. Appendix~\ref{app:method_classifier} presents the detailed architecture of the pose classifier.~\ref{app:method_recfunc} provides a more detailed derivation of the approximation discussed in Sec.~\ref{method:recdreamer}, and an explanation of the EMA update process. In~\ref{app:method_others}, we present the precise implementation details of RecDreamer. Lastly, the proof of the main theorems is given in~\ref{app:method_theorem}.



\subsection{Pose Classifier}\label{app:method_classifier}
\subsubsection{Overview}
The classification of pose typically involves two key points: when shapes of input and template images are similar (front and back), texture information is usually used for differentiation. Conversely, when shapes are different (left, center, and right), attention must be given to the features' positions. 

As introduced in Sec.~\ref{method:recdreamer}, the classifier mimics an ``AND gate'' structure, combining texture similarity and orientational similarity between the input and template for computation. Here, texture similarity mainly distinguishes the front and back of objects, while orientational similarity differentiates the three 2D orientations (left, center, and right). 

Texture similarity is obtained by calculating the cosine similarity between global features (\ie, $[cls]$ token) derived from the input and template images. However, orientational similarity cannot be easily derived from pretrained feature extractors, as they often use image augmentation techniques (like flipping) during training, leading to similar global features for left and right orientations. To address this issue, we propose the most matching patch distance to measure orientational similarity. The overall process is illustrated in Fig.~\ref{fig:app_method_classifier} and formulation is detailed in Appendix~\ref{app:pc_arch}.


\subsubsection{Architecture}\label{app:pc_arch}
Assume that we have a feature extractor $\mathcal{F}(\cdot)$ that maps an image to the feature space. Given the height $h$ and width $w$ of the features, we denote the global feature and patch features of an input image $\boldsymbol{x} \in \mathbb{R}^d$ as $\boldsymbol{f}_{cls} \in \mathbb{R}^{f}$ and $\boldsymbol{f}_{pat} \in \mathbb{R}^{h\times w\times f}$, \ie, $\boldsymbol{f}_{cls}, \boldsymbol{f}_{pat} = \mathcal{F}(\boldsymbol{x})$. The features of template images $\{\boldsymbol{x}^i | 0 \leq i < n_p\}$ are given by $\{\boldsymbol{f}_{cls}^i | 0 \leq i < n_p\}$, $\{\boldsymbol{f}_{pat}^i | 0 \leq i < n_p\}$, where $n_p$ is the number of the pose categories. To calculate the texture similarity, we directly calculate the cosine similarity $cos(\cdot, \cdot)$ between the global input features and the template features as follows:
\begin{equation}\label{eq:cls_tex}
    \begin{gathered}
 \boldsymbol{s}_{tex} = \{s_{tex}^i | 0 \leq i < n_p\}, \\
 s_{tex}^i = cos(\boldsymbol{f}_{cls}, \boldsymbol{f}_{cls}^i).
    \end{gathered}
\end{equation}
In \Eqref{eq:cls_tex}, we consolidate the per-class texture similarity scores (scalars) $s_{tex}^i$ into a vector representation $\boldsymbol{s}_{tex}$ to streamline notation.

To calculate the orientation similarity, we propose the matching patch distance to evaluate the orientation discrepancy between the input and output images. To concentrate on the main subject, we introduce the binary mask (the calculation of binary mask is introduced in Appendix~\ref{app:pc_seg}) of both input and template images, denoted as $\boldsymbol{b}$ and $\{\boldsymbol{b}^i | 0 \leq i < n_p\}$, where $\boldsymbol{b} \in \mathbb{R}^{h \times w \times 1}$. We also distribute a coordinate map for the input and template images based on the binary masks to mark the relevant coordinate, denoted as $\boldsymbol{m}$ and $\boldsymbol{m}^i$. To be specified, the leftmost pixel of the subject is assigned with a value $-0.5$ and the rightmost as $0.5$, where the value of intermediate pixels between the leftmost and rightmost are interpolated from $-0.5$ to $0.5$.




We denote the patch features by $\boldsymbol{f}_{pat}$ and $\boldsymbol{f}_{pat}^i$, the binary masks by $\boldsymbol{b}$ and $\boldsymbol{b}_{pat}^i$, and the coordinate maps by $\boldsymbol{m}$ and $\boldsymbol{m}_{pat}^i$. At a specific patch coordinate $u = (x, y)$, these quantities are written as $(\boldsymbol{f}_u, \boldsymbol{f}_u^i)$, $(b_u, b_u^i)$, and $(m_u, m_u^i)$, respectively. For subject patches (that is, coordinates where the binary mask is 1), we collect the corresponding features and coordinates into the sets $\hat{\boldsymbol{f}}_{pat} = \{\boldsymbol{f}_u \mid b_u = 1\}$ and $\hat{\boldsymbol{m}} = \{m_u \mid b_u = 1\}$. Similarly, for template images, we denote these sets by $\hat{\boldsymbol{f}}_{pat}^i$ and $\hat{\boldsymbol{m}}^i$.






For the input image, the similarities between the foreground patch $\hat{\boldsymbol{f}}_{pat, u}$ and the template patch $\hat{\boldsymbol{f}}_{pat, u'}^i$ is accessed by calculating the L2-norm, \ie, $s_{u, u'}= 1 - \sigma_{\tau_{pat}}(\|\hat{\boldsymbol{f}}_{pat, u} - \hat{\boldsymbol{f}}_{pat, u'}^i\|_2)$, where $\sigma_{\tau_{pat}}(\cdot)$ is a softmax function with temperature. Then, the mean distance between the input and the template is computed by traversing all the patches of the input image and the template image, and we use the negative of the distance to indicate the similarity of orientation:
\begin{equation}\label{eq:cls_pose}
    \begin{gathered}
 \boldsymbol{s}_{ori} = \{s_{ori}^i | 0 \leq i < n_p\}, \\
 s^i_{ori} = 1 - \frac{1}{\|u\|\|u'\|}\sum_{u}\sum_{u'} s_{u,u'}\|\hat{m}_u-\hat{m}_{u'}^i\|.
    \end{gathered}
\end{equation}
Finally, we compute the final probability $\boldsymbol{s}_{pose}$ by:
\begin{equation}
 \boldsymbol{s}_{pose} = \sigma_{\tau_{pose}}(\boldsymbol{s}_{tex} \otimes \boldsymbol{s}_{ori}).
\end{equation}
Here, $\sigma_{\tau_{pose}}(\cdot)$ is a softmax function and $\otimes$ signifies element-wise multiplication. In Fig.~\ref{fig:app_method_demo}, we demonstrate the distance calculation between a single pixel $u$ from the input image and the pixels $\{u'\}$ in the templates.

\input{figure/fig_classifier_mpd.tex}

\subsubsection{Foreground Mask Segmentation}\label{app:pc_seg}

To segment the foreground subject, we follow DINOv2~\citep{oquab2023dinov2, darcet2023vision} and apply a Principle Component Analysis (PCA)~\citep{abdi2010principal} to the patch features $\{\boldsymbol{f}_{pat}^i | 0 \leq i < n_p\}$. The PCA algorithm reduces the dimensions of the patch from $\mathbb{R}^{h \times w \times f}$ to $\mathbb{R}^{h \times w \times f'}$, where $f'$ is a small number. We use the first component along the feature channel dimension, as the basis for foreground segmentation. However, since it's unclear whether $>0$ corresponds to the subject or $<0$ does after PCA, we introduce the cross-attention feature map from Stable Diffusion~\citep{rombach2022high} for guidance. Concretely, we encode the template image into latent space and use the cross-attention features of the image and prompt at different time steps to obtain the subject area. Subsequently, based on the cross-attention feature map, we can infer whether the positive or negative value of PCA's first component stands for foreground. Note that we do not use cross-attention directly as a segmentation map because this method is more complex and not suitable for efficient segmentation during training. Instead, using PCA for segmentation is a lightweight approach that does not affect training efficiency.



\subsubsection{Implementation of Pose Classifier}

To minimize the impact on efficiency, we employ the feature extractor ``dinov2\_vits14''. We resize the classifier features to a size $h=w=16$. The temperature for patch-wise similarity $\tau_{pat}$ is set to $0.01$, while the temperature for pose in~\Eqref{eq:cls_pose} is set to $0.05$ to enhance the distinction between categories. When implementing the classifier (calculating PCA parameters), we apply data augmentations (random noise, random affine, random grayscale, and color jitter) to the template images to achieve robust foreground-background segmentation and classification.

\subsection{Calculation of the rectification function}\label{app:method_recfunc}
\textbf{Approximation of $p(c | \boldsymbol{x}_t, y)$.} In Sec.~\ref{method:recdreamer}, we have demonstrated the approximation of $p(c | \boldsymbol{x}_t, y)$. By expanding the derivation of Eq.~7 of DPS~\citep{chung2022diffusion} to a conditional form, we have:
\begin{equation}\label{eq:dps_pcxt}
    \begin{aligned}
 p(c | \boldsymbol{x}_t, y) &= \int p(\boldsymbol{x}_0|\boldsymbol{x}_t,y) p(c|\boldsymbol{x}_0,\boldsymbol{x}_t,y) d \boldsymbol{x}_0 \\
        &= \int p(\boldsymbol{x}_0|\boldsymbol{x}_t,y) p(c|\boldsymbol{x}_0,y) d \boldsymbol{x}_0 \\
        &= \mathbb{E}_{\boldsymbol{x}_0{\sim}p(\boldsymbol{x}_0|\boldsymbol{x}_t,y)}p(c|\boldsymbol{x}_0, y).
    \end{aligned}
\end{equation}
Note that we follow DPS's assumption that pose $c$ is independent to $\boldsymbol{x}_t$.~\Eqref{eq:dps_pcxt} is approximated by exchanging the calculation of expectation and $p(c|\boldsymbol{x}_0, y)$, \ie, $p(c | \boldsymbol{x}_t, y) \approx p(c|\hat{\boldsymbol{x}}_0, y)$, where $\hat{\boldsymbol{x}}_0 = \mathbb{E}_{\boldsymbol{x}_0{\sim}p(\boldsymbol{x}_0|\boldsymbol{x}_t,y)} [\boldsymbol{x}_0] $. By Tweedie's formula, $\hat{\boldsymbol{x}}_0 \approx \left(\boldsymbol{x}_t-\sigma_t\epsilon_{pretrain}(\boldsymbol{x}_t, t, y)\right)/\alpha_t$.

\textbf{Estimate of $p_t(c | y)$.} Another term, $p_t(c | y)$, represents the expectation of $p(c | \boldsymbol{x}_t, y)$ over $\boldsymbol{x}_t$. To estimate $p_t(c | y)$, we employ an exponential moving average (EMA) to iteratively update this term with the values of $p(c | \boldsymbol{x}_t, y)$ during training. Since $p_t(c | y)$ is time-dependent, each time step in the diffusion model requires a corresponding EMA value. However, updating the EMA at each iteration only occurs with a probability of 1/1000, which does not accurately track the current distribution. Fortunately, we observe that the empirical discrete pose probability of $p_t(\bar{c} | y)$ for adjacent time steps are nearly identical (e.g., $p_1(\bar{c} | y)$ and $p_2(\bar{c} | y)$ are almost the same). As a result, the EMA values across multiple time steps can be unified within intervals to enhance efficiency. We denote the number of intervals as $n_t$, and the number of steps within each interval, $n_s$, is calculated as $n_s = T / n_t$, where $T$ is the training step of DDPM. We maintain a list of EMA values for different intervals, $\{v_{ema}^i\}_{i=0}^{n_t}$. The EMA version of the pose probability, $\bar{p}_t(\bar{c}|y)$, is then given by $\bar{p}_t(\bar{c}|y) = v_{ema}^{i=\lfloor t/n_s \rfloor}$. The update of the EMA follows the update rate $\alpha_{ema}$, as described in the following:

\begin{equation}
 \bar{p}_t(\bar{c}|y) \leftarrow \alpha_{ema}p_{\xi}(\bar{c}|\boldsymbol{x}_t, y) + (1 - \alpha_{ema})\bar{p}_t(\bar{c}|y)
\end{equation}

Empirically, given $T=1000$ is the total steps, we set $n_t=10$ and $n_s=100$. $\alpha_{ema}$ is set to satisfy that the previous $n_{ema}$ samples has total EMA weights greater than $0.9$.






\subsection{Other Implementations}\label{app:method_others}
Additionally, we implement other tricks to ensure the effectiveness of gradient updates at different time steps.


\textbf{Gradient norm.} The optimization dynamics of uniform score distillation present a fundamental challenge: the framework simultaneously processes two conflicting gradient signals (classifier gradients and denoiser gradients) with inherent magnitude disparity. Through empirical measurement, we observe that classifier gradients for rendered images $\boldsymbol{x}_0$ exhibit substantially higher magnitudes compared to denoiser gradients. To resolve this optimization instability, we implement gradient norm alignment - specifically constraining the L2 norm of the classifier gradient to match the denoiser gradient norm. This normalization strategy ensures balanced parameter updates while preserving relative gradient directions.


\textbf{Time scheduler.} Furthermore, we utilized a back-and-forth (BNF) time scheduler. The time scheduler constrains the sampling interval for each iteration. Assuming the number of intervals for BNF is denoted as $n_i$, we divide the total number of iterations into $2n_i$ intervals. For the first $n_i$ intervals, the sampled time steps are expanded from $[T*0.98, T - (T / n_i)]$ to $[T*0.98, T*0.02]$. For the last $n_i$ intervals, the sampled time steps are reduced from $[T*0.98, T*0.02]$ to $[(T / n_i), T*0.02]$. Typically, we set $n_i=2$ for one particle optimization. 

\textbf{Three-stage optimization.} Similar to VSD, we use a three-stage optimization paradigm. For the first stage, we train the Instant-NGP~\citep{muller2022instant} using USD for $15k$ iters. In the second stage, we use SDS for geometric refinement for $15k$ iters. In the third stage, we optimize the texture with USD for $15k$ iters.

\textbf{Auxiliary prompts.}
Our method is essentially reweighting the subdistribution of a prior distribution, so in the proof of Lemma~\ref{lm:weight} we assume that $p(c) > 0$. To ensure this condition holds, we augment the original prompt with phrases like ``from side view, from back view.'' to introduce additional pose information. While these auxiliary prompts may not create a perfectly balanced distribution, they guarantee that $p(c) > 0$ by incorporating multiple viewpoints. Our algorithm then adjusts this distribution to achieve uniformity. It is important to note that our use of directional text differs fundamentally from prior work. Previous research has primarily employed directional text for conditional generation, aiming to constrain the model to produce content that strictly aligns with the provided text. In contrast, our approach leverages directional prompts to expand the model’s distribution, allowing it to capture a more diverse range of information.


\subsection{Proof of Main Theorem}\label{app:method_theorem}
\subsubsection{Proof of Theorem~\ref{thm:rpx}}
Since two marginal distributions $p(\boldsymbol{x})$ and $p(c)$ are involved, we first study their joint distribution $p(\boldsymbol{x},c)$. We introduce the weighting function $w(c)$ to correct $p(\boldsymbol{x},c)$ so that the rectified marginal distribution obeys the target distribution $f(c)$. The rectified joint distribution is given by the following lemma.

\begin{lemma}\label{lm:weight}
 Given the original joint distribution $p(\boldsymbol{x}, c)$, where $p(c)$ is the marginal distribution of $c$, and $p(c) \neq 0$, and a target marginal distribution $f(c)$, we can rectify $p(c)$ to $f(c)$ by introducing a weighting function $w(c) = \frac{f(c)}{p(c)}$. The corrected joint distribution $\tilde{p}(\boldsymbol{x}, c)$ is then given by:
    \begin{equation}\label{eq:rjoint}
 \tilde{p}(\boldsymbol{x}, c) = w(c) p(\boldsymbol{x}, c) = \frac{f(c)}{p(c)} p(\boldsymbol{x}, c).
    \end{equation}
\end{lemma}

\begin{proof}[Proof of Lemma~\ref{lm:weight}]
 To adjust the marginal distribution $p(c)$ to the target distribution $f(c)$, we apply a weighting function $w(c)$ to the original joint distribution following importance sampling. The new joint density is given by:
    \begin{equation}
 \tilde{p}(\boldsymbol{x}, c) = w(c) p(\boldsymbol{x}, c).
    \end{equation}
 The marginal distribution of $c$ under $\tilde{p}(\boldsymbol{x}, c)$ is:
    \begin{equation}
 \tilde{p}(c) = \int \tilde{p}(\boldsymbol{x}, c) d\boldsymbol{x} = \int w(c) p(\boldsymbol{x}, c) d\boldsymbol{x} = w(c) p(c).
    \end{equation}
 To satisfy $\tilde{p}(c) = f(c)$, we set $w(c) = \frac{f(c)}{p(c)}$. Substituting this into the expression for $\tilde{p}(\boldsymbol{x}, c)$ gives~\Eqref{eq:rjoint}. Since $f(c)$, $p(c)$, and $p(\boldsymbol{x}, c)$ are non-negative, $\tilde{p}(\boldsymbol{x}, c) \geq 0$. To validate normalization, we compute:
    \begin{equation}
        \int \int \tilde{p}(\boldsymbol{x}, c) d\boldsymbol{x} dc = \int \frac{f(c)}{p(c)} \left( \int p(\boldsymbol{x}) p(c | \boldsymbol{x}) d\boldsymbol{x} \right) dc = 1.
    \end{equation}
 This confirms that $\tilde{p}(\boldsymbol{x}, c)$ is a valid probability distribution, which completes the proof.
\end{proof}

Below we provide proof of Theorem~\ref{thm:rpx}.

\begin{proof}[Proof of Theorem~\ref{thm:rpx}]
According to Lemma~\ref{lm:weight}, the rectified joint distribution $\tilde{p}(\boldsymbol{x}, c)$ satisfies that the marginal distribution $\tilde{p}(c)=f(c)$. The rectified data density $\tilde{p}(\boldsymbol{x})$ is obtained by marginalizing $\tilde{p}(\boldsymbol{x}, c)$ over $c$ as follow:
    \begin{equation}
 \tilde{p}(\boldsymbol{x})=\int \tilde{p}(\boldsymbol{x},c) dc=\int\frac{f(c)}{p(c)}p(\boldsymbol{x})p(c|\boldsymbol{x}) dc=p(\boldsymbol{x})\int\frac{f(c)}{p(c)}p(c|\boldsymbol{x}) dc
    \end{equation}
 This completes the derivation of $\tilde{p}(\boldsymbol{x})$.
\end{proof}


\subsubsection{Corollary of Theorem~\ref{thm:rpx}}

We generalize the conclusions of Theorem~\ref{thm:rpx} to conditional distributions as follows.

\begin{corollary}\label{cr:rpx_cond}

For the conditional case, we can extend the result to $\tilde{p}(\boldsymbol{x}|y)$ as:
    \begin{equation}
 \tilde{p}(\boldsymbol{x}|y) = p(\boldsymbol{x}|y) \int \frac{f(c|y)}{p(c|y)} p(c | \boldsymbol{x}, y) dc.
    \end{equation}
 This follows directly from the general form by conditioning on $y$.
\end{corollary}

\begin{proof}[Proof of Corollary~\ref{cr:rpx_cond}]
 Analogous to Lemma~\ref{lm:weight}, we aim to rectify the conditional marginal distribution $p(c|y)$ to the target distribution $f(c|y)$. By $\tilde{p}(c|y) = \int p(c,\boldsymbol{x}|y) dx = w(c|y)p(c|y) = f(c|y)$, we derive $w(c|y)=\frac{f(c|y)}{p(c|y)}$. The rectified distribution $\tilde{p}(\boldsymbol{x}|y)$ is then expressed by integrating over $c$ as follows:
    \begin{equation}
 \tilde{p}(\boldsymbol{x}|y) = \int \tilde{p}(c,\boldsymbol{x}|y) dc=\int\frac{f(c|y)}{p(c|y)}p(c, \boldsymbol{x}|y) dc=p(\boldsymbol{x}|y) \int \frac{f(c|y)}{p(c|y)} p(c|\boldsymbol{x},y) dc.
    \end{equation}
 This completes the derivation of $\tilde{p}(\boldsymbol{x}|y)$.
\end{proof}





\subsubsection{Proof of Theorem~\ref{thm:rpx0t_cond}}
We provide the proof for deriving the rectified density for different time steps.
\begin{remark}
 Our primary objective is to obtain the rectified density at $t=0$, i.e., $\tilde{p}_0(\boldsymbol{x}_0 \mid y)$, without imposing a uniform distribution across all other noise states. Consequently, for any $t>0$, the density $\tilde{p}_t(\boldsymbol{x}_t|y)$ should be derived from a transition from $\tilde{p}_t(\boldsymbol{x}_0|y)$, as detailed in the following proof.
\end{remark}


\begin{proof}[Proof of Theorem~\ref{thm:rpx0t_cond}]
 First, we consider the $t=0$. According to Corollary~\ref{cr:rpx_cond}, we have:
\begin{equation}\label{eq:rpx0_cond}
 \tilde{p}_0(\boldsymbol{x}_0|y) = p_0(\boldsymbol{x}_0|y) \int \frac{f(c|y)}{p_0(c|y)} p(c | \boldsymbol{x}_0, y) dc.
\end{equation}
For any $t \in [1, T]$, the probability of noisy images is given by:
\begin{equation}\label{eq:rpx1t_cond}
    \begin{aligned}
        \tilde{p}_t(\boldsymbol{x}_t|y) &= \int\tilde{p}_0(\boldsymbol{x}_0|y)p_{t0}(\boldsymbol{x}_t|\boldsymbol{x}_0)d\boldsymbol{x}_0 \\
        &= \int \left[\int f(c|y) p(\boldsymbol{x}_0|c, y)dc\right]p_{t0}(\boldsymbol{x}_t|\boldsymbol{x}_0)d\boldsymbol{x}_0 \\
        &\overset{(a)}{=} \int f(c|y) \left[\int p(\boldsymbol{x}_0|c, y) p_{t0}(\boldsymbol{x}_t|\boldsymbol{x}_0) d \boldsymbol{x}_0\right] dc \\
        &\overset{(b)}{=} \int f(c|y) \left[\int p(\boldsymbol{x}_0|c, y) p_{t0}(\boldsymbol{x}_t|\boldsymbol{x}_0, c, y) d \boldsymbol{x}_0\right] dc \\
        &= \int f(c|y) \left[\int p(\boldsymbol{x}_t, \boldsymbol{x}_0|c, y)d \boldsymbol{x}_0\right] dc \\
        &= \int f(c|y)p(\boldsymbol{x}_t|c, y) dc \\
        &= p_t(\boldsymbol{x}_t|y) \int \frac{f(c|y)}{p_t(c|y)} p(c | \boldsymbol{x}_t, y) dc,
    \end{aligned}
\end{equation}
where (a) is according to Fubini's theorem, (b) is based on the that the forward process proceeds according to the original scheme, unaffected by text or pose conditions. By combining \eqref{eq:rpx0_cond} and \eqref{eq:rpx1t_cond}, we conclude that for any $t \in [0, T]$, \eqref{eq:rpx0t_cond} holds, completing the proof.
\end{proof}





\subsubsection{Proof of Corollary~\ref{cr:usd_gradient}}
This corollary directly follows from Theorem 2 as proposed by VSD~\citep{wang2024prolificdreamer}.
\begin{proof}
Theorem~2 by VSD establishes that the update rule for each particle $\theta_\tau$ at ODE time $\tau$ within a Wasserstein gradient flow is given by:
\begin{equation}\label{eq:vsd_update}
 \frac{\mathrm{d}\theta_\tau}{\mathrm{d}\tau}=\mathbb{E}_{t,\boldsymbol{\epsilon},c}\left[\sigma_t\omega(t)\left(\nabla_{\boldsymbol{x}_t}\log p_t(\boldsymbol{x}_t|y^c)-\nabla_{\boldsymbol{x}_t}\log q_t^{\mu_\tau}(\boldsymbol{x}_t|c,y)\right)\frac{\partial\boldsymbol{g}(\theta_\tau,c)}{\partial\theta_\tau}\right].
\end{equation}
In the case of rectified distribution, the update rule is modified as follows:
\begin{equation}\label{eq:usd_update}
 \frac{\mathrm{d}\theta_\tau}{\mathrm{d}\tau}=\mathbb{E}_{t,\boldsymbol{\epsilon},c}\left[\sigma_t\omega(t)\left(\nabla_{\boldsymbol{x}_t}\log \tilde{p}_t(\boldsymbol{x}_t|y)-\nabla_{\boldsymbol{x}_t}\log q_t^{\mu_\tau}(\boldsymbol{x}_t|c,y)\right)\frac{\partial\boldsymbol{g}(\theta_\tau,c)}{\partial\theta_\tau}\right],
\end{equation}
which can be further simplified as:

\begin{equation}
    \begin{aligned}
        \frac{d\theta_\tau}{d\tau}
        &= \mathbb{E}_{t,\boldsymbol{\epsilon},c}\left[
            \sigma_t\omega(t)\left(\nabla_{\boldsymbol{x}_t}\log \left[ p(\boldsymbol{x}_t|y) r(\boldsymbol{x}_t|y) \right]-\nabla_{\boldsymbol{x}_t}\log q_t^{\mu_\tau}(\boldsymbol{x}_t|c,y)\right)\frac{\partial\boldsymbol{g}(\theta_\tau,c)}{\partial\theta_\tau}\right] \\
        &= \mathbb{E}_{t,\boldsymbol{\epsilon},c}\left[
            \sigma_t\omega(t)\left(\nabla_{\boldsymbol{x}_t}\log p(\boldsymbol{x}_t|y) -\nabla_{\boldsymbol{x}_t}\log q_t^{\mu_\tau}(\boldsymbol{x}_t|c,y) + \nabla_{\boldsymbol{x}_t}\log r(\boldsymbol{x}_t|y) \right)\frac{\partial\boldsymbol{g}(\theta_\tau,c)}{\partial\theta_\tau}\right] \\
        &= \mathbb{E}_{t,\boldsymbol{\epsilon},c}\left[
            \omega(t)\left(\boldsymbol{\epsilon}_\phi(\boldsymbol{x}_t,t,c,y)-\boldsymbol{\epsilon}_\text{pretrain}(\boldsymbol{x}_t,t,y)\right)\frac{\partial\boldsymbol{g}(\theta_\tau,c)}{\partial\theta_\tau} + \omega(t)\frac{\sigma_t}{\alpha_t}\nabla_{\theta_\tau}\log r(\boldsymbol{x}_t|y)\right]. \\
    \end{aligned}
\end{equation}
Therefore, $\theta^{(i)}$ can be update by $\theta^{(i)}\leftarrow\theta^{(i)}-\eta\nabla_\theta\mathcal{L}_\text{USD}(\theta^{(i)})$, where:
\begin{equation}
    \begin{gathered}
        \nabla_\theta\mathcal{L}_\text{USD} = \nabla_\theta \mathcal{L}_\text{VSD}^\prime(\theta) - \mathbb{E}_{t,\boldsymbol{\epsilon},c}\left[\omega(t)\frac{\sigma_t}{\alpha_t}\nabla_{\theta}\log r(\boldsymbol{x}_t|y)\right], \\
        \nabla_\theta\mathcal{L}_\text{VSD}^\prime = \mathbb{E}_{t,\boldsymbol{\epsilon},c}\left[\omega(t)\left(\boldsymbol{\epsilon}_\text{pretrain}(\boldsymbol{x}_t,t,y)-\boldsymbol{\epsilon}_\phi(\boldsymbol{x}_t,t,c,y)\right)\frac{\partial\boldsymbol{g}(\theta,c)}{\partial\theta}\right].
    \end{gathered}
\end{equation}
Proof complete.

\end{proof}











