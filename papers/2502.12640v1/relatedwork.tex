\section{Related Works}
\subsection{Diffusion Models for Text-to-Image Generation}
A major challenge in text-to-image generation using diffusion models~\citep{yu2024beyond, liu2024drag, xu2024dreamanime} is guiding the generative process to reflect the input text accurately. A widely adopted solution is classifier-free guidance (CFG,~\cite{ho2022classifier}), which eliminates the need for external classifiers by training a unified model for both unconditional and conditional image generation. During inference, CFG achieves conditional generation by interpolating between the conditional and unconditional scores, effectively guiding the model to match the input text. This method has shown significant success in various text-to-image tasks~\citep{balaji2022ediff, nichol2021glide, ramesh2022hierarchical}. Models like DALLÂ·E 2 and Stable Diffusion~\citep{rombach2022high} have demonstrated exceptional capabilities in producing diverse and complex images, with promising extensions into text-to-3D generation.

\subsection{Text-to-3D Generation}
Recent advances in text-to-3D generation can be broadly divided into two main approaches. The first approach focuses on directly learning 3D asset distributions from large-scale datasets such as Objaverse~\citep{deitke2023objaverse}. Notable models within this category include GET3D~\citep{gao2022get3d}, Point-E~\citep{nichol2022point}, Shap-E~\citep{jun2023shap}, CLAY~\citep{zhang2024clay}, and MeshGPT~\citep{siddiqui2024meshgpt}, all of which leverage extensive 3D data to generate accurate 3D models.

The second approach relies on 2D priors~\citep{jiang2023diffuse3d} for generating 3D models. Techniques like score distillation are foundational here, as exemplified by DreamFusion/SJC~\citep{poole2022dreamfusion, wang2023score} and ProlificDreamer~\citep{wang2024prolificdreamer}.

Building on these baselines, researchers continue to improve visual quality. Classifier Score Distillation~\citep{yu2023text} reframes the fundamental approach by treating classifier-free guidance as the central mechanism rather than a supplementary component, enabling more realistic synthesis. Noise-Free Score Distillation~\citep{katzir2023noise} addresses the over-smoothing problem by eliminating unnecessary noise terms, allowing for effective generation at standard guidance scales. SteinDreamer~\citep{wang2023steindreamer} introduces Stein's identity to reduce gradient variance in score distillation for faster and higher-quality generation. LucidDreamer~\citep{liang2024luciddreamer} tackles the over-smoothing challenge differently by combining interval score matching with 3D Gaussian Splatting~\citep{kerbl20233d} and deterministic diffusion paths. Most recently, SDS-Bridge~\citep{mcallister2024rethinking} enhances the entire pipeline by introducing calibrated sampling based on optimal transport theory and improved distribution estimates.

A separate line of research focuses on improving geometric quality. Magic3D~\citep{lin2023magic3d} enhances output resolution by first generating a coarse 3D hashgrid and subsequently refining it into a mesh. Fantasia3D~\citep{chen2023fantasia3d} introduces hybrid scene representations and spatially varying BRDF~\citep{united1977geometrical} for realistic modeling. Other models, such as Dreamtime~\citep{huang2023dreamtime} and HiFA~\citep{zhu2023hifa}, concentrate on optimizing time-step sampling to improve texture stability and geometric consistency.


\subsection{Alleviating the Multi-Face Janus Problem}
One of the key challenges when extending text-to-image priors to 3D is the Multi-Face Janus problem, where inconsistencies arise in 3D geometries, especially for objects with multiple faces. To address this,~\citet{yi2023gaussiandreamer} and~\citet{ma2023geodream} introduce pretrained shape generators that provide geometric priors. DreamCraft3D~\citep{sun2023dreamcraft3d} tackles the challenge through a hierarchical framework, combining view-dependent diffusion with Bootstrapped Score Distillation to separate geometry and texture optimization. MVDream~\citep{shi2023mvdream} introduces a dedicated multi-view diffusion model that bridges 2D and 3D domains, enabling few-shot learning from 2D examples. JointDreamer~\citep{jiang2025jointdreamer} presents Joint Score Distillation with view-aware models as energy functions to ensure coherence by explicitly modeling cross-view relationships. While these methods effectively handle diverse scenarios, certain complex text descriptions can still pose challenges due to inherent limitations in pretrained generators and multi-view generative models.

Beyond introducing basic geometric priors, several methods have aimed to improve control over pose prompts. Debiased-SDS~\citep{hong2023debiasing} tackles text bias by removing words that conflict with pose descriptions, while Perp-Neg~\citep{armandpour2023re} proposes a perpendicular gradient sampling technique to remove undesired attributes from negative prompts. Other works have sought to address pose bias in pretrained models by altering the approximation distribution through pose sampling or entropy constraints.

DreamControl~\citep{huang2024dreamcontrol} approaches the pose bias issue by employing adaptive viewpoint sampling, which adjusts the rendering pose distribution to better mimic the inherent biases of the model. Additionally, ESD~\citep{wang2024taming} demonstrates that the score distillation process degenerates into maximum-likelihood seeking, and proposes an entropic term to introduce diversity across different views, helping to prevent repetitive patterns in 3D generation.