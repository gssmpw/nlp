\section{Background}
In this section, we provide a brief overview of diffusion models, conditional guidance techniques, and text-to-3D generation using score distillation. We follow the notation conventions introduced in VSD~\citep{wang2024prolificdreamer}.

\subsection{Diffusion Models}
Diffusion models~\citep{sohl2015deep, ho2020denoising, song2020score} are latent variable models that simulate a diffusion process to model the data distribution $\boldsymbol{x}_0 \sim q_0(\boldsymbol{x}_0)$. These models consist of a forward process $q$, which progressively adds Gaussian noise to the data, and a reverse process $p$, which denoises the data to recover the original distribution.

In the forward process, noise is iteratively added through transitions $q_t(\boldsymbol{x}_t|\boldsymbol{x}_{t-1})$. This allows the posterior distribution $q_t(\boldsymbol{x}_t|\boldsymbol{x}_0) = \mathcal{N}(\alpha_t \boldsymbol{x}_0, \sigma_t^2 \boldsymbol{I})$ to be computed, where $\alpha_t$ and $\sigma_t$ are time-dependent hyperparameters. The marginal distribution $q_t(\boldsymbol{x}_t)$ is derived by integrating over the data distribution:
\begin{equation}
q_t(\boldsymbol{x}_t) = \int q_t(\boldsymbol{x}_t|\boldsymbol{x}_0)q_0(\boldsymbol{x}_0)\,d\boldsymbol{x}_0.
\end{equation}

The reverse process begins with a standard Gaussian distribution, $p_T(\boldsymbol{x}_T) = \mathcal{N}(\boldsymbol{0}, \boldsymbol{I})$, and removes the noise through transitions $p_t(\boldsymbol{x}_t|\boldsymbol{x}_{t+1}) = q_t(\boldsymbol{x}_t|\boldsymbol{x}_{t+1}, \boldsymbol{x}_0 = \hat{\boldsymbol{x}}_0)$, where $\hat{\boldsymbol{x}}_0$ is an estimate of the clean data. Instead of predicting $\hat{\boldsymbol{x}}_0$ directly,~\citet{ho2020denoising} proposed optimizing a noise estimator $\epsilon_\phi(\boldsymbol{x}_t, t)$ by minimizing the following loss function:
\begin{equation}
    \mathcal{L}_{\mathrm{Diff}}(\phi) = \mathbb{E}_{\boldsymbol{x}_0 \sim q_0(\boldsymbol{x}_0), t \sim \mathcal{U}[0,T], \boldsymbol{\epsilon} \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{I})} \left[ \omega(t)\|\epsilon_\phi(\alpha_t \boldsymbol{x}_0 + \sigma_t \boldsymbol{\epsilon}) - \boldsymbol{\epsilon}\|_2^2 \right],
\end{equation}
where $\omega(t)$ is a time-dependent weighting function. The noise predictor $\epsilon_\phi(\boldsymbol{x}_t, t)$ can be viewed as a linear transformation of the score function: $\epsilon_\phi(\boldsymbol{x}_t, t) = -\sigma_t s_\phi(\boldsymbol{x}_t, t)$.

\subsection{Text-to-3D Generation with Score Distillation}
To enable text-to-3D generation using a text-to-image prior,~\citet{poole2022dreamfusion} proposed aligning the distribution of rendered images from an optimizable 3D representation $\theta$ with the text-to-image distribution $p_t(\boldsymbol{x}_t|y)$ generated by a pretrained diffusion model. Let $\Theta$ represent the space of scene parameters, $\mathbb{R}^c$ the space of poses, and $\mathbb{R}^d$ the space of images. Given a pose $c$ and a differentiable renderer $\boldsymbol{g}(\cdot, \cdot): \Theta \times \mathbb{R}^c \rightarrow \mathbb{R}^d$, the distribution of the rendered image is computed through the forward process:
\begin{equation}
q^\theta_t(\boldsymbol{x}_t|c) = \int q^\theta_t(\boldsymbol{x}_0|c) q_t(\boldsymbol{x}_t|\boldsymbol{x}_0) d\boldsymbol{x}_0,
\end{equation}
where $\boldsymbol{x}_0 = \boldsymbol{g}(\theta, c)$ is the rendered image. The 3D representation $\theta$ is then optimized using a weighted probability density distillation loss:
\begin{equation}\label{eq:sds_kl}
    \min_{\theta \in \Theta} \mathcal{L}_{\mathrm{SDS}}(\theta) = \mathbb{E}_{t, c} \left[ \left( \frac{\sigma_t}{\alpha_t} \right) \omega(t) D_{\mathrm{KL}}(q_t^\theta(\boldsymbol{x}_t|c) \parallel p_t(\boldsymbol{x}_t|y^c)) \right],
\end{equation}
where $\boldsymbol{x}_t = \alpha_t \boldsymbol{g}(\theta, c) + \sigma_t \boldsymbol{\epsilon}$, and $y^c$ is a text prompt corresponding to the pose. Since $q^\theta_0(\boldsymbol{x}_0|c)$ is a Dirac distribution $q^\theta_0(\boldsymbol{x}_0|c) = \delta(\boldsymbol{x}_0 - \boldsymbol{g}(\theta, c))$~\citep{wang2024taming}, the gradient of \eqref{eq:sds_kl} can be simplified through reparameterization~\citep{ho2020denoising} as:
\begin{equation}\label{eq:sds_grad}
    \nabla_\theta \mathcal{L}_{\mathrm{SDS}}(\theta) = \mathbb{E}_{t, \boldsymbol{\epsilon}, c} \left[ \omega(t) \left( \epsilon_{\text{pretrain}}(\boldsymbol{x}_t, t, y^c) - \boldsymbol{\epsilon} \right) \frac{\partial \boldsymbol{g}(\theta, c)}{\partial \theta} \right],
\end{equation}
where $\epsilon \sim \mathcal{N}(0, I)$ and $\epsilon_{\text{pretrain}}$ is the pretrained diffusion denoiser. During optimization, \eqref{eq:sds_grad} often results in mode-seeking behavior toward the text-to-image distribution $p_t(\boldsymbol{x}_t|y^c)$, which causes over-smoothness and over-saturation in the generated 3D scene.

To address these issues,~\citet{wang2024prolificdreamer} expanded the point estimate of 3D parameters into a more expressive distribution $\mu(\theta|y)$ by introducing multiple particles $\{\theta^i\}_{i=1}^n$. This extends the simple Gaussian distribution $q^\theta_t(\boldsymbol{x}_t|c)$ in SDS to a more complex distribution:
\begin{equation}
q^\mu_t(\boldsymbol{x}_t|c, y) = \int q^\mu_0(\boldsymbol{x}_0|c, y) p_{t0}(\boldsymbol{x}_t|\boldsymbol{x}_0) d \boldsymbol{x}_0.
\end{equation}
The distribution $\mu$ is then optimized using a variational score distillation (VSD) objective:
\begin{equation}
    \mu^* = \arg\min_\mu \mathbb{E}_{t, c} \left[ \left( \frac{\sigma_t}{\alpha_t} \right) \omega(t) D_{\mathrm{KL}}(q_t^\mu(\boldsymbol{x}_t|c, y) \parallel p_t(\boldsymbol{x}_t|y^c)) \right].
\end{equation}

To solve this, VSD employs particle-based variational inference~\citep{chen2018unified, liu2016stein} and fine-tunes an additional U-Net~\citep{ronneberger2015u}, $\epsilon_\phi$, using LoRA~\citep{hu2021lora}. The fine-tuning is formulated as:
\begin{equation}\label{eq:vsd_lora}
    \min_\phi \sum_{i=1}^n \mathbb{E}_{t \sim \mathcal{U}[0, T], \boldsymbol{\epsilon} \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{I}), c \sim p(c)} \left[ \| \epsilon_\phi(\alpha_t \boldsymbol{g}(\theta^{(i)}, c) + \sigma_t \boldsymbol{\epsilon}, t, c, y) - \boldsymbol{\epsilon} \|_2^2 \right].
\end{equation}
Finally, the gradient for each particle $\theta^i$ is computed as:
\begin{equation}
    \nabla_\theta \mathcal{L}_{\mathrm{VSD}}(\theta) = \mathbb{E}_{t, \boldsymbol{\epsilon}, c} \left[ \omega(t) \left( \epsilon_{\mathrm{pretrain}}(\boldsymbol{x}_t, t, y^c) - \epsilon_\phi(\boldsymbol{x}_t, t, c, y) \right) \frac{\partial \boldsymbol{g}(\theta, c)}{\partial \theta} \right].
\end{equation} 