
\section{Discussion on Limitations and Future Works}\label{app:ext_pose}
\input{figure/fig_bias.tex}
\input{figure/fig_demo_future.tex}
This discussion examines our work's boundaries while identifying promising paths for subsequent research. We identify several key limitations and opportunities for advancement.

A primary limitation of this work is generation speed. The bottleneck lies in the U-Net~\citep{ronneberger2015u} gradient back-propagation introduced by the rectifier function, which requires further optimization. Future research could explore methods to effectively bypass U-Net gradient back-propagation or develop a score-free optimization framework similar to MicroDreamer~\citep{chen2024microdreamer}.


Another significant challenge concerns 3D consistency of localized features. While USD eliminates bias in the overall data distribution, its reliance on the score distillation algorithm, which lacks explicit geometric consistency supervision, can lead to geometrically inconsistent content, potentially limiting practical applications. Addressing this limitation requires incorporating multi-perspective supervision during generation. Notably, the special case discussed in Appendix~\ref{app:main_exps_control} demonstrates a potential supervision mechanism for score distillation that warrants further investigation.


Beyond current technical limitations, we propose new directions for control-based synthesis that expand on cross-modal approaches (see Appendix~\ref{app:main_exps_cross}). For instance, Fig.~\ref{fig:app_demo_future} demonstrates an experiment using an imaginative prompt. As shown in Fig.~\ref{fig:app_demo_future}(a), the 3D generative model Tripo AI v2\footnote{https://lumalabs.ai/genie} captures basic geometric elements effectively, but still faces challenges when interpreting more abstract or imaginative descriptions (\ie, ``pixelated costume'' and ``pixelated surfboard'') due to its 3D modeling constraints. In contrast, our approach leverages selected Tripo AI renderings for pose control (Fig.~\ref{fig:app_demo_future}(a)), resulting in a more accurate prancing effect that better matches the text description, as demonstrated in Fig.~\ref{fig:app_demo_future}(b). While our model is trained from scratch and may lack geometric refinement, fine-tuning it from a geometrically consistent base model~\citep{zheng2024learning} can yield results that excel in both geometric accuracy and textural detail.


Finally, highlighting the versatility of our approach, our USD algorithm demonstrates considerable extensibility beyond pose classification and 3D generation. Fig.~\ref{fig:app_bias} showcases its application in addressing gender distribution bias in image generation using the CLIP~\citep{radford2021learning} classifier, enabling independent control over gender representation. This adaptability suggests that USD could be applied to address other forms of algorithmic bias with different classifier architectures.





