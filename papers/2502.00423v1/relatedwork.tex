\section{Related Works}
\label{sec:related-works}

Our work intersects online stochastic contextual bandits, statistical learning, and decision-making under latent heterogeneity. We review the most relevant literature and distinguish our contributions.

\smallskip
\noindent
\textbf{Online Stochastic Contextual Bandits.}
The bandit problem has been extensively studied across computer science, operations, and statistics \citep{li2019dimension, russo2020simple,chen2021multi, russo2022satisficing, si2023distributionally,simchi2023regret,ren2024dynamic,tang2024stochastic,chen2025express}; see \cite{lattimore2020bandit} for a comprehensive review. Contextual bandits incorporate additional information to predict action quality \citep{auer2002using,dani2008stochastic,li2010contextual,chu2011contextual,ji2022risk}. While adversarial settings achieve $\bigO{d\sqrt{T}}$ regret \citep{abbasi2011improved}, stochastic settings --- suitable for applications like news recommendation and clinical trials --- can improve bounds dependent on $T$ from $\sqrt{T}$ to $\log(T)$ for homogeneous bandits.

In low dimensions, \cite{goldenshluger2013linear} achieved $\bigO{d^3\log(T)}$ regret, though this becomes unfavorable as the dimension increases. For high-dimensional settings with sparsity $s$ ($s \ll d$), several approaches have emerged: \cite{bastani2020online}'s LASSO bandit achieved $\bigO{K s^2 \log^2(dT)}$; %with a $\bigO{s^2\log(d)\log(T)}$ exploration stage; 
\cite{wang2024online}'s MCP-based method improved this to $\bigO{Ks^2(s+\log d)\log T}$; and \cite{kim2019doubly}'s doubly-robust approach reached $\bigO{s\log(dT)\sqrt{T}}$; %with $\bigO{\sqrt{T\log(dT)\log(T)}}$ exploration. 
%These methods require known sparsity $s$. 
In contrast, \cite{oh2020sparsity}'s sparse-agnostic approach achieves %$\bigO{s^2\log(d) + s\sqrt{T\log(dT)}}$, improvable to 
$\bigO{\sqrt{sT\log(dT)}}$ under restricted eigenvalue conditions. 
%\cite{ariu2020thresholded}'s Threshold LASSO achieves $\bigO{\log(d) + \sqrt{T\log(T)}}$, reducible to $\bigO{\log(d) + \log(T)}$ under margin conditions.

All of the aforementioned papers work within the classic model of stochastic bandits, which does not address the widely encountered setting of latent heterogeneity in business and economics. Under latent heterogeneity, these algorithms will obtain biased estimation due to the misspecified single linear expectation, incurring non-negligible regret at each decision point and thus linear expected regret over time.
In contrast, our proposed latent heterogeneous bandit model explicitly incorporates an unobservable subgroup structure. Our specially designed algorithm learns both the latent groups and the true parameters for each group. 
%During the decision-making stage, group membership is predicted and the optimal policy for the respective group is applied. Our analysis differentiates between two types of regrets based on different oracle comparisons. The "strong regret," measured against an oracle with perfect knowledge of customer memberships under the binomial distribution, remains non-sub-linear due to inherent uncertainty in group classification. In contrast, the "regular regret," compared against an oracle aware only of deterministic components, achieves $\bigO{\sqrt{Ts\log(d)}}$. We establish the minimax lower bounds for both regret types, demonstrating the optimality of our proposed heterogeneous algorithm.

Recent work has applied the bandits to various management problems, including newsvendor problems \citep{keskin2023nonstationary}, dynamic pricing \citep{keskin2017chasing,chen2019dynamic,keskin2021dynamic,chen2019welfare,chen2021nonparametric,den2022dynamic,bastani2022meta,keskin2022data,chen2024dynamic,li2024dynamic}, joint advertising and assortment \citep{gao2021assortment,gurkan2023dynamic}, resource allocation \citep{dong2024value}, inventory control \citep{che2024stochastic,qin2023sailing}, sub-exponential rewards \citep{yuan2021marrying}, sourcing \citep{tang2024online}, network revenue management \citep{chen2023network}, and smart order routing \citep{ji2022risk}. These works operate within the classic bandit framework and do not consider latent heterogeneity. Our proposed latent heterogeneous bandits framework can be incorporated into these decision scenarios. It is of great interest to explore the effect of latent heterogeneity of the customer population on various decision scenarios and to develop efficient methods or strategies to overcome the challenge of latent heterogeneity. We leave those for future work.

\smallskip
\noindent
\textbf{Statistical learning with Latent heterogeneity.}
In linear regression settings, researchers have explored two major approaches to latent heterogeneity. The non-parametric approach employs grouping penalization on pairwise differences \citep{shen2010grouping,ke2013homogeneity,ma2017concave}, avoiding distributional assumptions but limiting predictive capabilities for new samples. For prediction-oriented tasks, mixture-model-based approaches have shown greater promise. Key developments include: rigorous EM algorithm guarantees for symmetric mixed linear regressions (MLR) where the mixing proportion is known to be $1/2$ \citep{balakrishnan2017statistical}, efficient fixed-parameter algorithms \citep{li2018learning}, computational-statistical tradeoffs \citep{fan2018curse}, improved EM convergence analysis \citep{mclachlan2019finite,klusowski2019estimating}, robust estimation under corruptions \citep{shen2019iterative}, high-dimensional MLR with unknown but constant mixing proportions \citep{zhang2020estimation}, and convergence analysis for federated learning \citep{su2024global, niu2024collaborative}. Our model \eqref{eqn:hetero-f} and \eqref{eqn:hetero-status} extends this literature by addressing variable mixing proportions in high-dimensional MLR, a previously unexplored challenge.

\smallskip
\noindent
\textbf{Decision with Heterogeneity.}
Research addressing learning and decision-making with heterogeneity remains relatively sparse. Notable work spans several domains: personalized dynamic pricing with high-dimensional features and heterogeneous elasticity \citep{ban2021personalized}; regime-switching bandits with temporal heterogeneity \citep{cao2019nearly,zhou2021regime}; and convergence analysis of Langevin diffusion under mixture distributions \citep{dong2022spectral}, where multiple density components can significantly impact sampling efficiency. In sequential decision settings, recent work has explored policy evaluation and optimization with latent heterogeneity in reinforcement learning \citep{chen2024reinforcement,bian2024off}. However, these approaches focus primarily on multi-stage aspects of reinforcement learning, leaving unexplored the fundamental challenge that latent heterogeneity poses to the exploration-exploitation trade-off. Our work addresses this gap through the lens of the bandit problemâ€”essentially a one-step reinforcement learning.