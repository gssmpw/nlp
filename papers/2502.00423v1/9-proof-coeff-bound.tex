
%!TEX root = 0-main.tex

\section{Proof of Theorem \ref{thm:coeff-bound-hd}} \label{sec:proof-coeff-bound}

The EM algorithm is essentially an alternating maximization method, which alternatively optimizes between the identification of hidden labels $\{g_i\}$ and the estimation of parameter $\bgamma=(\btheta, \bbeta_1, \bbeta_2)$.
In the $\tau$-th episode, we utilize $N_{\tau-1} = n_02^{\tau - 1}$ samples from the previous episode. 
%We let $N=N_{\tau-1}$ and drop the index $\tau$ in this section since we are considering only one episode $\tau$. 
In the $(t+1)$-th iteration of the EM-algorithm, we have i.i.d samples in the set $\calI_{\tau-1}^{(t+1)}$ of size $n_{\tau}=N_{\tau-1}/t_{\tau, \max}$.

By the sub-Gaussianity of $\bx_i$, $\bz_i$, and $\epsilon_i$, there exist a constant $C$ such that \[\EE\left[(\bx_i^{\top}\bv)^{m}\right] \leq C^m \sigma_{x}^mm^{m/2}, \quad \EE[\epsilon_{i}^m]\leq C^m \sigma^mm^{m/2},
\text{ and } 
\PP\paren{\abs{\bz_i^{\top}\bv} \leq \mu} < 2e^{-\frac{\mu^2}{2\sigma^2_{z}}},\] 
for all non-negative integers $m$ and all $\bv$ such that $\norm{\bv}_2=1$, where $\sigma_x$, $\sigma_z$, and $\sigma$ are the sub-Gaussian parameters of $\bx_i$, $\bz_i$, and $\epsilon_i$, respectively. Let $\eta_x =\sigma_x/\sigma$. Moreover, we further define that $\delta_{\bgamma}^{(\tau, 0)}=\begin{cases}
	\delta_{0}, & \text{if } \tau=1;\\
	 \sqrt{\frac{s\log d \log n_0}{n_0}}, & \text{if } \tau \geq 2,\end{cases}$
where $\delta_{0}=c_1\min\big\{\xi, 1-\xi, \norm{\bbeta_1^*-\bbeta_2^*}_2\big\}$. We will show that, there exists a constant $\oC$ such that, by letting $\kappa<(2\oC^2)^{-1}$ and $\widetilde\kappa=\oC^2\kappa<1/2$, we have the following theorem, which is a more detailed version of Theorem $\ref{thm:coeff-bound-hd}$:

\begin{theorem}\label{thm:1-detailed}
	Suppose Assumptions \ref{A1}--\ref{A4} hold with the constants  $c_1$, $c_2$ that satisfy $c_2  \geq \max\left\{1/(2^{1/4}\sigma_x), 256MC^2\sigma_x\eta_x/\kappa, 384C^2\sigma_x^2M/\sqrt{\kappa}\right\}$ and $c_1 \leq \min\{1/4M, 2/\mu_0\}$, where $\mu_0$ is defined by $\mu_0= \sqrt{2}\sigma_z\sqrt{\log\paren{\frac{2144C^4\sigma_x^4c_2^2}{\kappa}}}$. Furthermore,  assume that $\sqrt{\frac{s^2\log d\log n_0}{n_0}} =o(1)$. Let $\left(\hat{\btheta}^{(\tau)},\hat{\bbeta}_{1}^{(\tau)},\hat{\bbeta}_{2}^{(\tau)}\right)=\left(\btheta^{(\tau,t_{\tau, \max})},\bbeta^{(\tau, t_{\tau, \max})}_{1},\bbeta^{(\tau, t_{\tau, \max})}_{2}\right)$ be the output of Algorithm \ref{alg:em} in the $\tau$-th episode. By letting the number of iterations $t_{\tau, \max} \asymp \log n_0$ for $\tau=1$ and $t_{\tau, \max} \asymp 1$  for $\tau \geq 2$ and choosing \[\lambda_{n_{\tau}}^{(t+1)}=\frac{2\oC(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}\sqrt{\frac{\log d}{n_{\tau}}}+\frac{\oC\kappa(2\widetilde\kappa)^{t}}{\sqrt{s}}\delta_{\bgamma}^{(\tau, 0)}, \]
	we have
	\begin{equation}
		\norm{\hat{\bbeta}_{1} - \bbeta_{1}^*}_2 + \norm{\hat{\bbeta}_{2} - \bbeta_{2}^*}_2 + \norm{\hat{\btheta} - \btheta^*}_2
		\lesssim \frac{1}{\kappa(1-2\widetilde\kappa)}\sqrt{\frac{s\log d\log n_0}{N_{\tau-1}}}, 
	\end{equation}
	and
	\begin{equation}
		\norm{\hat{\bbeta}_{1} - \bbeta_{1}^*}_1 + \norm{\hat{\bbeta}_{2} - \bbeta_{2}^*}_1 + \norm{\hat{\btheta} - \btheta^*}_1
		\lesssim   \frac{1}{\kappa(1-2\widetilde\kappa)}\sqrt{\frac{s^2\log d\log n_0}{N_{\tau-1}}},
	\end{equation}
	with probability at least $1-\frac{c\log^3 n_0}{\max^2\{N_{\tau-1}, d\}}$ for some constant $c$.
\end{theorem}

We temporarily drop the index $\tau$ in $N_{\tau-1}$, $n_{\tau}$, $\cI_{\tau-1}^{(t)}$, $t_{\tau, \max}$, $\omega_i^{(\tau, t)}$, $\bgamma^{(\tau, t)}$, and $\lambda_{n_{\tau}}^{(t)}$ when we are considering a single episode $\tau$. 
 The overall objective function $Q_n$ in the M-Step is the sum of the single-observation objective functions, that is, 
\begin{equation}
    Q_n(\bgamma \cond \bgamma^{(t)})
    \; := \; 
    \sum_{i \in \calI^{(t+1)}}\EE\brackets{ \ell\paren{\bx_i, y_i, \bz_i, g_i; \bgamma} \cond \bx_i, y_i, \bz_i; \bgamma^{(t)}}.
\end{equation}
For clearness, we replace $i \in \calI^{(t+1)}$ with $\sum_{i=1}^{n}$ when there is no ambiguity.
Simple calculation yields that 
\begin{align}\label{eqn:Qn}
    Q_n(\bgamma \cond \bgamma^{(t)})
    & = 
   \frac{1}{n} \sum_{i=1}^{n} \left[\omega_i^{(t)}\cdot \paren{ \log p(\bz_i^\top\btheta)-
    \frac{(y_i - \bx_i^\top\bbeta_1)^2 }{2\sigma^2 }} \right.   \\
    &\quad +
    \left. (1- \omega_i^{(t)}) \cdot \paren{\log(1-p(\bz_i^\top\btheta)) -
    \frac{(y_i - \bx_i^\top\bbeta_2)^2}{2\sigma^2}} \right]  \nonumber \\
   & = -  \frac{1}{2n} \sum_{i=1}^{n} \omega_i^{(t)} \cdot  \frac{(y_i - \bx_i^\top\bbeta_1)^2 }{\sigma^2} - \frac{1}{2n} \sum_{i=1}^{n} (1- \omega_i^{(t)}) \cdot \frac{(y_i - \bx_i^\top\bbeta_2)^2 }{\sigma^2}  \nonumber   \\
   & \quad + \frac{1}{n} \sum_{i=1}^{n}\left[ \omega_i^{(t)} \cdot \log p(\bz_i^\top\btheta) + (1- \omega_i^{(t)}) \cdot \log(1-p(\bz_i^\top\btheta))\right]  \nonumber 
\end{align}
where $\omega_i^{(t)} = \omega_i(\bgamma^{(t)}) = \omega(\bx_i, y_i, \bz_i ; \bgamma^{(t)})$ is defined by
\[
\omega(\bx, y, \bz ; \bgamma) 
= \frac{p(\bz^\top\btheta) \cdot
	    \phi\paren{\frac{y - \bx^\top\bbeta_1}{\sigma}}}{p(\bz^\top\btheta) \cdot \phi\paren{\frac{y - \bx^\top\bbeta_1}{\sigma}} 
	    + \paren{1-p(\bz^\top\btheta)} \cdot \phi\paren{\frac{y - \bx^\top\bbeta_2}{\sigma}}}.
\]
Let 
\begin{equation} %\label{eqn:Qn123}
\begin{aligned}
    Q_{n1}(\bbeta_1 \cond \bgamma^{(t)}) & =  \frac{1}{2n} \sum_{i=1}^{n} \omega_i^{(t)}\cdot  \frac{(y_i - \bx_i^\top\bbeta_1)^2 }{\sigma^2}, \\
    Q_{n2}(\bbeta_2 \cond \bgamma^{(t)}) & =  \frac{1}{2n} \sum_{i=1}^{n} (1- \omega_i^{(t)}) \cdot \frac{(y_i - \bx_i^\top\bbeta_2)^2 }{\sigma^2}, \quad\text{and}\quad \\
    Q_{n3}(\btheta \cond \bgamma^{(t)}) & = - \frac{1}{n} \sum_{i=1}^{n} \paren{ \omega_i^{(t)} \cdot \log p(\bz_i^\top\btheta) + (1- \omega_i^{(t)}) \cdot \log(1-p(\bz_i^\top\btheta)) }.
\end{aligned}
\end{equation}
Then, in the $(t+1)$-th iteration, the M-step is implemented as 
\begin{align}
    \bbeta_1^{(t+1)} & := \underset{\bbeta_1}{\arg\min} \;  Q_{n1}\paren{\bbeta_1 \cond \bgamma^{(t)}}  
    + \lambda_n^{(t)} \norm{\bbeta_1}_1,  \label{eqn:beta-1-opt}\\
    \bbeta_2^{(t+1)} & := \underset{\bbeta_2}{\arg\min} \; Q_{n2}\paren{\bbeta_2 \cond \bgamma^{(t)}}  
    + \lambda_n^{(t)} \norm{\bbeta_2}_1,  \label{eqn:beta-2-opt} \\
    \btheta^{(t+1)} & := \underset{\btheta}{\arg\min} \; Q_{n3}\paren{\btheta \cond \bgamma^{(t)}} 
    + \lambda_n^{(t)} \norm{\btheta}_1.  \label{eqn:theta-opt}
\end{align}

%Given a suitable initialization, the proposed EM algorithm then proceeds by iterating between the E-step and the M-step, which is summarized in the Algorithm \ref{alg:em-bandit}.

To prove Theorem \ref{thm:1-detailed}, we first present Lemmas \ref{thm:lemma-expectation} and \ref{thm:lemma-sample} on iterative estimation bounds. Let $\omega_i^* = \omega_i(\bgamma^*) = \omega(\bx_i, y_i, \bz_i ; \bgamma^*)$.

\begin{lemma}[Population EM iterates]  
\label{thm:lemma-expectation}
Assume Assumptions (A1) and (A4) hold.  For any constant $\kappa>0$ and any constants $c_1, c_2$ satisfying the requirements in Theorem \ref{thm:1-detailed}, 
if $\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2 \le c_1 \min\braces{\xi, (1-\xi), \norm{\bbeta_1^*-\bbeta_2^*}_2}$ and $\norm{\bbeta_1^*-\bbeta_2^*}_2 > c_2$, then we have
\begin{align*}
    \abs{ \EE[\omega_i^{(t)} ] 
        - \EE[\omega_i^*] }  
    & \le \kappa \cdot \paren{\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}, 
    \\
    \norm{ \EE[ \omega_i^{(t)} \bx_i ( \bx_i^\top \bbeta_1^* - y_i) ] 
        - \EE[ \omega_i^* \bx_i ( \bx_i^\top \bbeta_1^* - y_i) ] }_2  
    & \le \kappa \cdot \paren{\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}, 
    \\
    \norm{ \EE[ ( \omega_i^{(t)} - p(\bz_i^\top\btheta^{*}) ) \bz_i ] 
       - \EE[ (\omega_i^* - p(\bz_i^\top\btheta^{*}) ) \bz_i ] }_2
    & \le  \kappa \cdot \paren{\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}. 
\end{align*}
\end{lemma}
\noindent Proof of Lemma \ref{thm:lemma-expectation} is provided in Section \ref{sec:proof-lemma-expectation}. 

\begin{lemma}[Sample EM iterates]  \label{thm:lemma-sample}
Under the assumptions of Theorem \ref{thm:coeff-bound-hd}, suppose that $\bgamma^{(t)}$ is independent with $\{\bx_i, y_i, \bz_i\}$'s, then there exists some constant $C > 0$, such that, with probability at least $1 - \frac{4}{\max\{n, d\}^2}$,  
\begin{align*}
\norm{ \frac{1}{n}\sum_{i=1}^n \left[\omega_i^{(t)} \bx_i ( \bx_i^\top \bbeta_1^* - y_i) \right] 
    - \EE\left[ \omega_i^{(t)} \bx_i ( \bx_i^\top \bbeta_1^* - y_i) \right] }_\infty 
& \le  C \sqrt{ \frac{\log \max\{n, d\}}{n} },  \\
\norm{  \frac{1}{n}\sum_{i=1}^n \left[( \omega_i^{(t)} - p(\bz_i^\top\btheta^{*}) ) \bz_i \right]
    - \EE\left[ (\omega_i^{(t)} - p(\bz_i^\top\btheta^{*}) ) \bz_i \right] }_\infty
& \le C \sqrt{ \frac{\log \max\{n, d\}}{n} }.
\end{align*}
\end{lemma}
\noindent Proof of Lemma \ref{thm:lemma-sample} is provided in Section \ref{sec:proof-lemma-sample}. 

\medskip

\noindent In Steps 1 and 2 in the following proof, we use $\hat{\bbeta_1}$, $\hat{\bbeta_2}$, $\hat{\btheta}$, $\lambda$ to denote $\bbeta_1^{(t+1)}$, $\bbeta_2^{(t+1)}$,  $\btheta^{(t+1)}$, and $\lambda_n^{(t+1)}$ for simplicity. Also, we suppose that $\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2 \le c_1 \min\braces{\xi, (1-\xi), \norm{\bbeta_1^*-\bbeta_2^*}_2}$, which is satisfied with $t=0$ and will be shown by induction in Step 3.

\noindent
\textbf{STEP 1. Sample EM iterative bounds for $\bbeta_1$ and $\bbeta_2$.} We make use of the definition of \eqref{eqn:beta-1-opt} and \eqref{eqn:beta-2-opt} and a decomposition of the main objective function $Q_{n1}$ as follows.
\begin{align}
Q_{n1}\paren{{\bbeta_1^*} \cond \bgamma^{(t)}} - Q_{n1}\paren{\hat\bbeta_1 \cond \bgamma^{(t)}}
& = \frac{1}{n}\angles{\sum_{i=1}^{n}\omega_i^{(t)}\paren{y_i-\bx_i^\top\bbeta_1^*} \bx_i,\; \hat\bbeta_1-\bbeta_1^*} \nonumber\\
& - \paren{\hat\bbeta_1-\bbeta_1^*}^\top 
\paren{\frac{1}{2n}\sum_{i=1}^n\omega_i^{(t)}\bx_i\bx_i^\top}
\paren{\hat\bbeta_1-\bbeta_1^*}. \label{eqn:Qn-decomp}
\end{align}
By \eqref{eqn:beta-1-opt}, we have
\begin{equation} \label{eqn:Qn-diff-lb-1}
\lambda\paren{\norm{\hat\bbeta_1}_1-\norm{\bbeta_1^*}_1} 
\le Q_{n1}\paren{{\bbeta_1^*} \cond \bgamma^{(t)}} - Q_{n1}\paren{\hat\bbeta_1 \cond \bgamma^{(t)}}.
\end{equation}

Combine \eqref{eqn:Qn-decomp} and \eqref{eqn:Qn-diff-lb-1}, we have
\begin{equation}
\begin{aligned}
&\quad  \paren{\hat\bbeta_1-\bbeta_1^*}^\top 
\paren{\frac{1}{2n}\sum_{i=1}^n\omega_i^{(t)}\bx_i^\top\bx_i}
\paren{\hat\bbeta_1-\bbeta_1^*} \\
&\le 
\frac{1}{n}\angles{\sum_{i=1}^{n}\omega_i^{(t)}\paren{y_i-\bx_i^\top\bbeta_1^*} \bx_i,\; \hat\bbeta_1-\bbeta_1^*} - \lambda\paren{\norm{\hat\bbeta_1}_1-\norm{\bbeta_1^*}_1}.
\end{aligned}
\end{equation}
Applying the decomposition (where we use  $\EE\brackets{\omega_i^*\paren{y_i-\bx_i^\top\bbeta_1^*} \bx_i}=0$, which is implied by the fact that $(\btheta, \bbeta_1^*, \bbeta_2^*)$ is the minimizer of the population likelihood)
\begin{align*}
&\quad \angles{\frac{1}{n}\sum_{i=1}^{n}\omega_i^{(t)}\paren{y_i-\bx_i^\top\bbeta_1^*} \bx_i,\; \hat\bbeta_1-\bbeta_1^*} \\
& \le \abs{\angles{\frac{1}{n}\sum_{i=1}^{n}\omega_i^{(t)}\paren{y_i-\bx_i^\top\bbeta_1^*} \bx_i - \EE\brackets{\omega_i^{(t)}\paren{y_i-\bx_i^\top\bbeta_1^*} \bx_i},\; \hat\bbeta_1-\bbeta_1^*}} \\
& ~~~ + \abs{\angles{\EE\brackets{\omega_i^{(t)}\paren{y_i-\bx_i^\top\bbeta_1^*} \bx_i} - \EE\brackets{\omega_i^*\paren{y_i-\bx_i^\top\bbeta_1^*} \bx_i},\; \hat\bbeta_1-\bbeta_1^*}} \nonumber
\end{align*} 
and Lemmas \ref{thm:lemma-expectation} and \ref{thm:lemma-sample}, we obtain, with probability at least $1-2/\max\{n, d\}^2$, 
\begin{equation} \label{eqn:Qn-diff-ub}
\begin{aligned}
& \angles{\frac{1}{n}\sum_{i=1}^{n}\omega_i^{(t)}\paren{y_i-\bx_i^\top\bbeta_1^*} \bx_i,\; \hat\bbeta_1-\bbeta_1^*} \\
& \le  
C \sqrt{\frac{\log \max\{n, d\} }{ n}}\cdot\norm{\hat\bbeta_1-\bbeta_1^*}_1 
+ \kappa\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}\cdot\norm{\hat\bbeta_1-\bbeta_1^*}_2. 
\end{aligned}
\end{equation}

\begin{lemma} \label{thm:diff-L1-Bound}
Let $S = {\rm supp}(\bbeta_1^*)$ and $s=|S|$. When \[\lambda\ge 3C\sqrt{\frac{\log \max\{d, n\}}{ n}} + \frac{\kappa}{\sqrt{s}}\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2},\] we have
\begin{equation}
\norm{ \hat\bbeta_1 - \bbeta_1^*}_1 \leq 5\sqrt{s}\norm{ \hat\bbeta_1 - \bbeta_1^*}_2. 
\end{equation}
\end{lemma}
\begin{proof}{Proof of Lemma \ref{thm:diff-L1-Bound}}
Let $\bu = \hat\bbeta_1 - \bbeta_1^*$. Combining the inequality from the definition of each iterates
\begin{equation} 
\lambda\paren{\norm{\hat\bbeta_1}_1-\norm{\bbeta_1^*}_1} 
\le Q_{n1}\paren{{\bbeta_1^*} \cond \bgamma^{(t)}} - Q_{n1}\paren{\hat\bbeta_1 \cond \bgamma^{(t)}} 
\end{equation}
and the inequality that
\begin{equation*}
\norm{\hat\bbeta_1}_1-\norm{\bbeta_1^*}_1 
\ge \norm{\bbeta_1^* + \bu_{S^C}}_1 - \norm{\bu_{S}}_1-\norm{\bbeta_1^*}_1
= \norm{\bu_{S^C}}_1 - \norm{\bu_{S}}_1,
\end{equation*}
we obtain
\begin{equation} \label{eqn:Qn-diff-lb}
\lambda\paren{\norm{\bu_{S^C}}_1 - \norm{\bu_{S}}_1}
\le 
Q_{n1}\paren{{\bbeta_1^*} \cond \bgamma^{(t)}} - Q_{n1}\paren{\hat\bbeta_1 \cond \bgamma^{(t)}}.
\end{equation}
Combining \eqref{eqn:Qn-decomp}, \eqref{eqn:Qn-diff-ub} and \eqref{eqn:Qn-diff-lb}, we have 
\begin{align*}
\lambda\paren{\norm{\bu_{S^C}}_1 - \norm{\bu_{S}}_1}
& \le Q_{n1}\paren{{\bbeta_1^*} \cond \bgamma^{(t)}} - Q_{n1}\paren{\hat\bbeta_1 \cond \bgamma^{(t)}} \\
& \le \frac{1}{n}\angles{\sum_{i=1}^{n}\omega_i^{(t)}\paren{y_i-\bx_i^\top\bbeta_1^*} \bx_i,\; \hat\bbeta_1-\bbeta_1^*} \\
& \le 
C \sqrt{\frac{\log \max\{d, n\}} {n}}\cdot\norm{\bu}_1 \\
&\quad + \frac{\kappa}{\sqrt{s}}\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}\cdot\sqrt{s}\norm{\bu}_2. 
\end{align*} 
Let \[\lambda\ge 3C\sqrt{\frac{\log \max\{d, n\}}{ n}} + \frac{\kappa}{\sqrt{s}}\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2},\] we have
% \begin{equation*}
% \norm{\bu_{S^C}}_1 - \norm{\bu_{S}}_1 \le 1/3 (\norm{\bu_{S^C}}_1 + \norm{\bu_{S}}_1) + \sqrt{s}\norm{\bu}_2. 
% \end{equation*}
\begin{equation*}
\norm{\bu_{S^C}}_1 \le 2\norm{\bu_{S}}_1 + 3/2\sqrt{s}\norm{\bu}_2 \le 4\sqrt{s}\norm{\bu}_2,
\end{equation*}
and hence $\norm{\bu} \leq \norm{\bu_{S}}_1+\norm{\bu_{S^c}}_1 \leq 5\sqrt{s}\norm{\bu}_2$. \hfill\qed
\end{proof}

Then, applying Lemma \ref{thm:diff-L1-Bound} to \eqref{eqn:Qn-diff-ub}, we have
\begin{equation}
\begin{aligned}
&\quad  \paren{\hat\bbeta_1-\bbeta_1^*}^\top 
\paren{\frac{1}{2n}\sum_{i=1}^n\omega_i^{(t)}\bx_i^\top\bx_i}
\paren{\hat\bbeta_1-\bbeta_1^*} \label{eqn:Q1n-2nd-mm-ub}\\
& \lesssim \sqrt{\frac{s\log \max\{d, n\}} {n}}\cdot\norm{\hat\bbeta_1-\bbeta_1^*}_2
+ \kappa\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}\cdot\norm{\hat\bbeta_1-\bbeta_1^*}_2  \\
&\quad + \lambda\sqrt{s}\norm{\hat\bbeta_1-\bbeta_1^*}_2. \nonumber
\end{aligned}
\end{equation}
Second, we establish a lower bound of the second-order term. 
Assumption (A1) ensures that $p(\bz_i^{\top}\btheta^*) \in (\xi, 1-\xi)$. By Hoeffding's inequality and Lemma \ref{thm:lemma-expectation}, 
%when $\norm{\bbeta_1^{(t)} - \bbeta^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2 \le ...$, 
we have, with probability at least $1-\frac{2}{\max\{d, n\}^2}$,  \[\abs{\frac{1}{n}\sum_{i=1}^{n}\omega_i^{(t)}-\EE[\omega_i^*]} \leq \sqrt{\frac{\log \max \{d, n\}}{n}} + \kappa \paren{\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}.\]
Since $\paren{\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2} \leq c_1 \min\{\xi, 1-\xi\}$, by taking $\kappa$ sufficiently small, we have $\abs{\frac{1}{n}\sum_{i=1}^{n}\omega_i^{(t)}-\EE[\omega_i^*]} \leq \frac{1}{2} \min\{\xi, 1-\xi\}$ with probability at least $1-\frac{2}{\max\{d, n\}^2}$. Since $\EE[\omega_i^*] = \EE[p(\bz_i^{\top}\btheta^*)] \geq \xi$,  we have that $\frac{1}{n}\sum_{i=1}^{n}\omega_i^{(t)} \geq \frac{\xi}{2}$, and thus $n_{a}:=\sum_{i=1}^n\bbone\braces{\omega_i^{(t)} \ge \frac{\xi}{4}} \ge \frac{\xi}{4}n$. (Otherwise, $\frac{1}{n}\sum_{i=1}^{n}\omega_i^{(t)} \leq \frac{\xi}{4}+ \frac{\xi}{4}(1- \frac{\xi}{4}) < \xi/2$.) %, with probability approaching one. 
As a result, 
\begin{align}
& \paren{\hat\bbeta_1-\bbeta_1^*}^\top 
\paren{\frac{1}{2n}\sum_{i=1}^n\omega_i^{(t)}\bx_i\bx_i^\top}
\paren{\hat\bbeta_1-\bbeta_1^*} 
%= \frac{1}{2n}\sum_{i=1}^n\omega_i^{(t)}\paren{\bx_i^\top\paren{\hat\bbeta_1-\bbeta_1^*}}^2
\nonumber\\
& \ge \frac{\xi}{8}(\hat\bbeta_1-\bbeta_1^*)^{\top}\cdot \frac{1}{n}\sum_{\omega_i^{(t)} \geq \xi/4} \paren{\bx_i\bx_i^\top} (\hat\bbeta_1-\bbeta_1^*)\nonumber\\
& \ge \frac{\xi^2}{32M} \norm{\hat\bbeta_1-\bbeta_1^*}_2^2 +  \frac{\xi}{8}(\hat\bbeta_1-\bbeta_1^*)^{\top}\cdot \frac{1}{n}\left[\sum_{\omega_i^{(t)} \geq \xi/4} \big(\bx_i\bx_i^\top-\EE[\bx_i\bx_i^{\top}]\big)\right] (\hat\bbeta_1-\bbeta_1^*) \nonumber\\
& \ge \frac{\xi^2}{64M} \norm{\hat\bbeta_1-\bbeta_1^*}_2^2, \label{eqn:Q1n-2nd-mm-lb}
\end{align}
where we use the standard result that $\frac{1}{n_a}\left\|\sum_{\omega_i^{(t)} \geq \xi/4} \big(\bx_i\bx_i^\top-\EE[\bx_i\bx_i^{\top}]\big)\right\|_{\max} \lesssim \sqrt{\frac{\log \max\{n_a, d\}}{n_a}}$ with probability at least $1-2\max\{n_a, d\}^{-2}$, the result in Lemma  \ref{thm:diff-L1-Bound}, and the assumption that $s\sqrt{\frac{\log \max \{n, d\}}{n}}=o(1)$.
Combining \eqref{eqn:Q1n-2nd-mm-ub} and \eqref{eqn:Q1n-2nd-mm-lb}, we have with probability at least $1-c_0\max\{n, d\}^{-2}$, 
\begin{equation} \label{eqn:beta1-one-iter}
\norm{\hat\bbeta_1-\bbeta_1^*}_2 
\lesssim    
\sqrt{s \log  \max\{d, n\} / n}
+ \kappa\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}
+ \lambda\sqrt{s},
\end{equation}
for some constant $c_0>0$.
Similarly, we obtain that with with probability at least $1-c_0\max\{n, d\}^{-2}$,
\begin{equation}\label{eqn:beta2-one-iter}
\norm{\hat\bbeta_2-\bbeta_2^*}_2
\lesssim \sqrt{s \log  \max\{d, n\} / n}
+ \kappa\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}
+ \lambda\sqrt{s}.
\end{equation}

\medskip
\noindent
\textbf{STEP 2. Sample EM iterative bounds for $\btheta$.} 
We make use of the definition of \eqref{eqn:theta-opt}. 
Let $\bu = \hat\btheta$ and $S = {\rm supp}(\btheta^*)$.
Firstly, by the definition of estimator, we have that 
\begin{equation} \label{eqn:Qn3-diff-lb}
\lambda\paren{\norm{\hat\btheta}_1 - \norm{\btheta^*}_1} 
\le 
Q_{n3}\paren{\btheta^* \cond \bgamma^{(t)}} - Q_{n3}\paren{\hat\btheta \cond \bgamma^{(t)}} 
\end{equation}
In addition, we have
\begin{align}
Q_{n3}\paren{\hat\btheta \cond \bgamma^{(t)}}
- Q_{n3}\paren{{\btheta^*} \cond \bgamma^{(t)}}
& = 
- \frac{1}{n} \sum_{i=1}^{n} \paren{ \omega_i^{(t)} \cdot \log p(\bz_i^\top\hat\btheta) + (1- \omega_i^{(t)}) \cdot \log(1-p(\bz_i^\top\hat\btheta)) } \nonumber\\
& + \frac{1}{n} \sum_{i=1}^{n} \paren{ \omega_i^{(t)} \cdot \log p(\bz_i^\top\btheta^*) + (1- \omega_i^{(t)}) \cdot \log(1-p(\bz_i^\top\btheta^*)) } \nonumber\\
& = \angles{-\frac{1}{n} \sum_{i=1}^{n} \paren{\omega_i^{(t)}- p(\bz_i^\top\btheta^*)}\bz_i, \; (\hat\btheta-\btheta^*) } \nonumber\\
& + (\hat\btheta-\btheta^*)^\top \paren{\frac{1}{n} \sum_{i=1}^{n}p(\bz_i^\top\btheta')(1-p(\bz_i^\top\btheta'))\bz_i\bz_i^\top} (\hat\btheta-\btheta^*), \label{eqn:Qn3-decomp}
\end{align}
for some $\btheta'$ between $\hat\btheta$ and $\btheta^*$. 
Thus, we have
\begin{align*}
&\quad (\hat\btheta-\btheta^*)^\top \paren{\frac{1}{n} \sum_{i=1}^{n}p(\bz_i^\top\btheta')(1-p(\bz_i^\top\btheta'))\bz_i\bz_i^\top} (\hat\btheta-\btheta^*)\\
& \le \abs{\angles{-\frac{1}{n} \sum_{i=1}^{n} \paren{\omega_i^{(t)}- p(\bz_i^\top\btheta^*)}\bz_i, \; (\hat\btheta-\btheta^*) }} + \lambda \paren{\norm{\btheta^*}_1 - \norm{\hat\btheta}_1}  \\
& \le \abs{\angles{\frac{1}{n} \sum_{i=1}^{n} (\omega_i^{(t)}- p(\bz_i^\top\btheta^*))\bz_i - \EE\brackets{(\omega_i^{(t)}- p(\bz_i^\top\btheta^*))\bz_i}, \; (\hat\btheta-\btheta^*) }} \\
& + \abs{\angles{\EE\brackets{(\omega_i^{(t)}- p(\bz_i^\top\btheta^*))\bz_i} - \EE\brackets{(\omega_i^*- p(\bz_i^\top\btheta^*))\bz_i}, \; (\hat\btheta-\btheta^*) }}  + \lambda \paren{\norm{\btheta^*}_1 - \norm{\hat\btheta}_1} . 
\end{align*}
Applying Lemmas \ref{thm:lemma-expectation} and \ref{thm:lemma-sample}, we have
\begin{align*}
&  \abs{\angles{-\frac{1}{n} \sum_{i=1}^{n} \paren{\omega_i^{(t)}- p(\bz_i^\top\btheta^*)}\bz_i, \; (\hat\btheta-\btheta^*) }}  \\
& \le 
C \sqrt{\log \max\{d,n\} / n}\cdot\norm{\hat\btheta-\btheta^*}_1 
+ \kappa\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}\cdot\norm{\hat\btheta-\btheta^*}_2.
\end{align*}
Similar to Lemma \ref{thm:diff-L1-Bound}, by taking $\lambda > 3C\sqrt{\frac{\log \max\{d,n\}}{ n}} + \frac{\kappa}{\sqrt{s}}\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}$, it holds that
\begin{equation}\label{eqn:Q3n-2nd-mm-upper}
	\begin{aligned}
		& (\hat\btheta-\btheta^*)^\top \paren{\frac{1}{n} \sum_{i=1}^{n}p(\bz_i^\top\btheta')(1-p(\bz_i^\top\btheta'))\bz_i\bz_i^\top} (\hat\btheta-\btheta^*)\\
		& \le 
		\angles{-\frac{1}{n} \sum_{i=1}^{n} \paren{\omega_i^{(t)}-\log p(\bz_i^\top\btheta^*)}\bz_i, \; (\hat\btheta-\btheta^*) } + \lambda \paren{\norm{\hat\btheta}_1 - \norm{\btheta^*}_1} \\
		& \le 
		C \sqrt{\frac{s \log \max\{d,n\} }{ n}}\cdot\norm{\hat\btheta-\btheta^*}_2 
		+ \kappa\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}\cdot\norm{\hat\btheta-\btheta^*}_2 \\
		&\quad + \sqrt{s}\lambda \norm{\hat\btheta - \btheta^*}_2.
	\end{aligned}
\end{equation}

At the same time, similar to Step 1, we have $\frac{1}{n}\sum_{i=1}^{n}p(\bz_i^\top\btheta')(1-p(\bz_i^\top\btheta'))\ge\xi^2/8$ for any $\btheta'$ between $\hat\btheta$ and $\btheta^*$, with probability at least $1-c_0\max\{n, d\}^{-2}$, and hence
\[\sum_{i=1}^{n}\bbone\braces{(\bz_i^\top\btheta')(1-p(\bz_i^\top\btheta')) \geq \frac{\xi^2}{16}} \geq \frac{\xi^2}{4}n.\]
Then, we have 
\begin{equation} \label{eqn:Q3n-2nd-mm-lower}
(\hat\btheta-\btheta^*)^\top \paren{\frac{1}{n} \sum_{i=1}^{n}p(\bz_i^\top\btheta')(1-p(\bz_i^\top\btheta'))\bz_i\bz_i^\top} (\hat\btheta-\btheta^*)
\ge (\xi^4/64M) \norm{\hat\btheta-\btheta^*}_2^2.
\end{equation}
Combining \eqref{eqn:Q3n-2nd-mm-upper} and \eqref{eqn:Q3n-2nd-mm-lower}, we have with probability at least $1-c_0\max\{n, d\}^{-2}$, 
\begin{equation}\label{eqn:theta-one-iter}
\norm{\hat\btheta-\btheta^*}_2^2 
\lesssim    
 \sqrt{s \log \max\{d,n\} / n}
+ \kappa\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}
+ 
\lambda\sqrt{s}.
\end{equation}

\medskip
\noindent
\textbf{STEP 3. Proof by induction.}
Combining \eqref{eqn:beta1-one-iter},  \eqref{eqn:beta2-one-iter}, and \eqref{eqn:theta-one-iter}, we have that, with probability at least $1-c\max\{n, d\}^{-2}$
\begin{equation}\label{eq:cgamma}
	\begin{aligned}
		&\norm{\bbeta^{(t+1)}_1 - \bbeta_1^*}_2 + \norm{\bbeta^{(t+1)}_2 - \bbeta_2^*}_2 + \norm{\btheta^{(t+1)} - \btheta^*}_2 \\
		&\leq C_{\gamma} \brackets{
			\sqrt{s \log \max\{d,n\} / n} 
			+ \kappa\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2}
			+ 
			\lambda_n^{(t+1)}\sqrt{s}}, 
	\end{aligned}
\end{equation}

when
\begin{equation*}
\lambda^{(t+1)}_n \ge C_\lambda \sqrt{\log \max\{d,n\} / n} + \kappa/\sqrt{s}\cdot\paren{\norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2},
\end{equation*}
for some absolute constants $c$, $C_{\gamma}$ and $C_{\lambda}$. Let $\oC: = \max\braces{C_{\lambda}, C_{\gamma}, 1}$, choose $\kappa<(2\oC^2)^{-1}$,  let $\widetilde\kappa:=\oC^2\kappa<1/2$, and define
\[\delta_{\bgamma}^{(t)}:=  \norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2.\]

We will show by induction that, by choosing 
\[\lambda_n^{(t+1)}=\frac{2\oC(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}\sqrt{\frac{\log \max\{d,n\}}{n}}+\frac{\oC\kappa(2\widetilde\kappa)^{t}}{\sqrt{s}}\delta_{\bgamma}^{(0)}, \]
it holds that
\[\delta_{\bgamma}^{(t)} \leq \frac{2(1-(2\widetilde\kappa)^{t+1})}{\kappa(1-2\widetilde\kappa)}\sqrt{\frac{s\log \max\{d,n\}}{n}}+(2\widetilde\kappa)^t\delta_{\bgamma}^{(0)}, \]
and 
\[\lambda_n^{(t+1)} \geq C_\lambda\sqrt{\frac{\log \max\{d,n\}}{n}} + \frac{\kappa}{\sqrt{s}}\delta_{\bgamma}^{(t)}.\]

The case $t=0$ is trivial. Assume that the above two inequalities are true for $t$. Consider $t+1$. By \eqref{eq:cgamma}, we have
\begin{align*}
	\delta_{\bgamma}^{(t+1)} 
	&\leq \oC \brackets{1+\frac{2(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}+\frac{2\oC(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}}\sqrt{\frac{s\log \max\{d,n\}}{n}} +\paren{\oC\kappa+\oC^2\kappa}(2\widetilde{\kappa})^t\delta_{\bgamma}^{(0)}\\
	& \leq \frac{1}{\kappa} \brackets{\oC\kappa+\frac{2\oC\kappa(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}+\frac{2\oC^2\kappa(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}}\sqrt{\frac{s\log \max\{d,n\}}{n}}+(2\widetilde{\kappa})^{t+1}\delta_{\bgamma}^{(0)}\\
	& \leq \frac{1}{\kappa} \brackets{2+\frac{2\widetilde\kappa(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}+\frac{2\widetilde\kappa(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}}\sqrt{\frac{s\log \max\{d,n\}}{n}}+(2\widetilde{\kappa})^{t+1}\delta_{\bgamma}^{(0)}\\
	&\leq\frac{2(1-(2\widetilde\kappa)^{t+2})}{\kappa(1-2\widetilde\kappa)}\sqrt{\frac{s\log \max\{d,n\}}{n}}+(2\widetilde{\kappa})^{t+1}\delta_{\bgamma}^{(0)}.
\end{align*}
Furthermore,
\begin{align*}
	&\quad C_\lambda\sqrt{\frac{\log \max\{d,n\}}{n}} + \frac{\kappa}{\sqrt{s}}\delta_{\bgamma}^{(t+1)}\\
	& \leq  \brackets{\oC+\oC\kappa+\frac{2\oC\kappa(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}+\frac{2\oC^2\kappa(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}}\sqrt{\frac{\log \max\{d,n\}}{n}}+\frac{\kappa}{\sqrt{s}}(2\widetilde{\kappa})^{t+1}\delta_{\bgamma}^{(0)}\\
	& \leq \brackets{2\oC+\frac{2\oC^3\kappa(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}+\frac{2\oC^3\kappa(1-(2\widetilde\kappa)^{t+1})}{1-2\widetilde\kappa}}\sqrt{\frac{\log \max\{d,n\}}{n}}+\frac{\kappa}{\sqrt{s}}(2\widetilde{\kappa})^{t+1}\delta_{\bgamma}^{(0)}	\leq\lambda_{n}^{(t+2)}.
\end{align*}
 
Therefore, we have shown that
\begin{equation*}
	\begin{aligned}
&\quad \norm{\bbeta_1^{(t)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t)} - \bbeta_2^*}_2 + \norm{\btheta^{(t)} - \btheta^*}_2 \\
& \leq
(2\widetilde\kappa)^t\cdot\paren{\norm{\bbeta_1^{(0)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(0)} - \bbeta_2^*}_2 + \norm{\btheta^{(0)} - \btheta^*}_2}
+ \frac{2}{\kappa(1-2\widetilde\kappa)}\sqrt{\frac{s\log \max\{d,n\}}{n}}.
	\end{aligned}
\end{equation*}

 Since we focus on the high-dimensional setting where $\log N_{\tau-1}  \lesssim \log d$ for all $\tau$, we replace $\log\max\{d, n\}$ with  $\log d$ from now on. Recall that we use sample splitting $n_{\tau}=N_{\tau-1}/t_{\tau, \max}$ to make sure the solutions obtained in each iteration are independent with each other (which satisfies the assumption of Lemma \ref{thm:lemma-sample}). When $\tau=1$, we have $N_0=n_0$ and  $\delta_{\gamma}^{(0)}\leq \delta_{0}$. Hence,  by taking $t_{1, \max} \asymp \frac{1}{2\log(1/2\tilde{\kappa})}\log (n_0)$, we obtain 
\[
\norm{\hat{\bbeta}_1^{(1)} - \bbeta_1^*}_2 + \norm{\hbbeta_2^{(1)} - \bbeta_2^*}_2 + \norm{\hbtheta^{(1)} - \btheta^*}_2  \lesssim \sqrt{\frac{s\log d \log n_0}{n_0}},
\]
with probability at least $1-ct_{1,\max}^3 / \max\{n_0, d\}^2$.
For $\tau=2$, the initials $\bgamma^{(2, 0)}=\hat{\bgamma}^{(1)}$, and thus $\delta_0^{(2, 0)}\lesssim \sqrt{\frac{s \log d \log n_0}{n_0}}$. By taking $t_{2, \max} \asymp \log(\sqrt{2})/\log(1/(2\tilde{\kappa}))$, which is a constant, we obtain
 \[
 \norm{\hat{\bbeta}_1^{(2)} - \bbeta_1^*}_2 + \norm{\hbbeta_2^{(2)} - \bbeta_2^*}_2 + \norm{\hbtheta^{(2)} - \btheta^*}_2  \lesssim \sqrt{\frac{s\log d \log n_0}{2n_0}} = \sqrt{\frac{s\log d \log n_0}{N_1}}.
 \]
 The same argument shows that, for all $\tau \geq 2$, by taking $t_{\tau, \max} \asymp \log(\sqrt{2})/\log(1/(2\tilde{\kappa}))$,
  \[
 \norm{\hat{\bbeta}_1^{(\tau)} - \bbeta_1^*}_2 + \norm{\hbbeta_2^{(\tau)} - \bbeta_2^*}_2 + \norm{\hbtheta^{(\tau)} - \btheta^*}_2  \lesssim \sqrt{\frac{s\log d \log n_0}{N_{\tau-1}}},
 \]
 with probability at least $1-c t_{\tau, \max}^3 / \max\{N_{\tau-1}, d\}^2$.
%\begin{equation*}
%\begin{aligned}
%&\quad 	\norm{\bbeta_1^{(t_{\max})} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t_{\max})} - \bbeta_2^*}_2 + \norm{\btheta^{(t_{\max})} - \btheta^*}_2 \\
%&	\leq
%	(2\widetilde\kappa)^{t_{\max}}\cdot\paren{\norm{\bbeta_1^{(0)} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(0)} - \bbeta_2^*}_2 + \norm{\btheta^{(0)} - \btheta^*}_2}
%	+ \frac{2}{\kappa(1-2\widetilde\kappa)}\sqrt{\frac{s\log \max\{d,N_{\tau-1}\}}{N_{\tau-1}/t_{\max}}},
%	\end{aligned}
%\end{equation*}
%where $N_{\tau-1}$ is the sample size of the $\tau$-th episode. 
%By taking the number of iteration $t_{\max} \asymp \log N_{\tau-1}$ , it holds that 
%\[	(2\widetilde\kappa)^{t_{\max}}\cdot\paren{\norm{\bbeta_1^{(0)} - \bbeta_1^*}_2+\norm{\bbeta_2^{(0)} - \bbeta_2^*}_2+\norm{\btheta^{(0)} - \btheta^*}_2} \lesssim \sqrt{\frac{s\log d \log N_{\tau-1}}{N_{\tau-1}}}, \]
%and thus we obtain that
%\[
%\norm{\bbeta_1^{(t_{\max})} - \bbeta_1^*}_2 + \norm{\bbeta_2^{(t_{\max})} - \bbeta_2^*}_2 + \norm{\btheta^{(t_{\max})} - \btheta^*}_2
%\lesssim
%\sqrt{\frac{s\log \max\{d,N_{\tau-1}\} \log N_{\tau-1}}{N_{\tau-1}}},
%\]
% with probability at least $1-c\log^3 N_{\tau-1} \max\{N_{\tau-1}, d\}^{-2}$ for some constant $c$.
  By Lemma \ref{thm:diff-L1-Bound}, we also have that
$$
 	\norm{\hbbeta_1^{(\tau)} - \bbeta_1^*}_1 + \norm{\hbbeta_2^{(\tau)} - \bbeta_2^*}_1 + \norm{\hbtheta^{(\tau)} - \btheta^*}_1
 	\lesssim
 	\sqrt{\frac{s^2\log d \log n_0}{N_{\tau-1}}},
$$ which concludes the proof of Theorem \ref{thm:1-detailed}.
% Finally, since we focus on the high-dimensional setting where $\log N_{\tau-1}  \lesssim \log d$ for all $\tau$, we have $\log\max\{d, N_{\tau-1}\} \lesssim \log d$, 




