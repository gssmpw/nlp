
% Vendors can use patient attributes, such as sex, age, height, and weight, to condition image generation, since they are more easily collected or modeled based on real populations, even those with no existing image data.
% However, synthesizing full virtual patients poses significant challenges.
% It is necessary to maintain global consistency with conditioning attributes as well as anatomical correctness over the full body, but volumetric image synthesis of full patients is memory intensive.


% Conditional image synthesis is defined by the ability to generate realistic images from a specific patient cohort, enabling \emph{in silico} imaging trials of AI algorithms that estimate their performance in real clinical trials on the same population (Fig.~\ref{fig:overview-synth}).
% This is an invaluable capability for institutions looking to adopt the latest advances in precision medicine, for regulators aiming to standardize approval pipelines for AI, as well as for researchers seeking to improve their algorithms.
% Before purchasing an AI-equipped imaging system, for instance, an institution could generate synthetic images based on its own medical records, conducting an \emph{in silico} trial of the new system that informs the purchasing decision and allows the institution to anticipate its effect on current practice. On the other end of the development cycle, researchers can use \emph{in silico} imaging trials to identify algorithmic vulnerabilities, for instance because a crucial sub-population is under-represented in the training set, thereby avoiding failed submissions to regulators or patient-facing failures after deployment. Armed with detailed knowledge about which combinations of patient attributes lead to deteriorated performance, researchers can augment real training data with synthetic images in a targeted manner to rectify the imbalance and drive forward ongoing development.

% It's an unsolved problem: People have tried to do this. How broad do we want to go here? Let's structure a little bit. We are discussing conditioning image generation on attributes to facilitate algorithm validation. There are two pieces there: realistic CT synthesis and medical algorithm validation with synthetic data. Let's take those in order, starting with validating algorithms with synthetic data, which is likely to be the first sticking point.
% We do want to look at medical image synthesis for training AI algorithms, so that we can cite DeepDRR, SyntheX, and all our other
% Mathias: We don't want it to seem like this has been done before at all. Yes, medical image synthesis has been used for this purpose before, but what's the novelty? What's new in this approach?
% Conditional image synthesis represents a major step forward in the use of synthetic medical images for evaluating AI algorithm performance.

% Until now, synthetic medical image generation has lacked the combination of realism and control that is necessary for \emph{in silico} imaging trials of AI algorithms.
% One prominent source of synthetic medical images are virtual patient phantoms, which range from stylized combinations of geometric primitives to statistical atlases based on patient populations.\cite{peng2022review, abadi2020virtual} In combination with physics-based imaging simulations, these can be used to synthesize medical images from various imaging modalities,\cite{killeen2023insilico, abadi2020virtual} including CT,\cite{segars2008realistic, badal2009accelerating, maier2013conrad} MRI,\cite{buoso2023mrxcat} PET and SPECT,\cite{herraiz2024mcgpu} ultrasound, mammography,\cite{aldo2018evaluation, badal2021mammography} and X-ray.\cite{unberathopen} A major limitation of virtual patient phantoms is the lack of intra-organ heterogeneous details,\cite{amirrajab2020xcat} leading to various strategies for texturing or otherwise adding detail to virtual phantoms and simulated images.\cite{abadi2020virtual} This can be done through proceduraly generated textures\cite{bakic2003mammogram} or disease models\cite{hoe2006simulation, zhang2007simulating} on a per-organ basis, or through image-to-image translation models using deep learning.\cite{chang2020development, amirrajab2020xcat} While virtual patient phantoms have enabled \emph{in silico} trials of AI algorithms,\cite{lowther2018investigation, tushar2022virtual} they \todo{fundamentally represent an untethering of patient-based image characteristics from the attributes used for conditioning.}

% Broadly, machine learning-based methods for CT image synthesis have been gradually maturing. They include image-to-image translation models for bringing phantom,\cite{tushar2022virtual} MR,\cite{han2017mr, lei2019mri, pan2023synthetic, bahrami2021comparison} and CBCT\cite{chen2020synthetic, peng2024cbct, fu2024energy} images into the patient CT domain, which can augment existing data for training downstream algorithms. Purely generative models have also been proposed,\cite{sorin2020creating} which can be conditioned on attributes like disease presence.\cite{jiang2020covid} Denoising diffusion probabilistic models\cite{ho2020denoising} significantly advanced the quality of CT image synthesis over previous generative models,\cite{khader2023denoising, txurio20203diffusion, pan20232d} enabling fine-grained control based on organ segmentations.\cite{konz2024anatomically} When combined with statistical shape models to produce these segmentations, such models can in theory provide a pathway toward conditional image synthesis for \emph{in silico} trials on unseen populations. However, they \todo{still represent a fundamental decoupling of the attributes used to condition images, which are available from medical records, and the visually and anatomically realistic images ultimately generated.}
% We contend that the ability to finely control the attributes of generated data, including properties which can only be confirmed by generating full-body images, is the next step in transitioning synthetic data from an augmentation to training data pipelines, which are ultimately tested on real data, to being a realistic testbed for algorithm performance that reflects real populations.

% Virtual patient phantoms, which can be voxelized to create CT images from a range of desired attributes, have provided researchers with data to ``quantitatively evaluate and improve imaging instrumentation, data acquisition, techniques, and image reconstruction and processing methods which can lead to improved image quality and more accurate clinical dianosis.''\cite{segars2008realistic} They range from stylized phantoms handcrafted from geometric primitives to realistic deformable atlases with finely controllable attributes.\cite{peng2022review}
% The XCAT phantoms, for example, have been used to forecast algorithm performance for COVID-19 diagnosis from chest CTs, correctly predicting failures when evaluated outside the source institution.\cite{tushar2022virtual}
% They have also been used for validating cardiac MRI tracking algorithms,\cite{lowther2018investigation} and they can be made more realistic using image-to-image generative models.\cite{amirrajab2020xcat}
% However, a major limitation of the XCAT phantoms, as well as other phantoms based on deformable shape atlases, is ``the lack of intra-organ anatomical details and textures,'' since all organs are defined as homogeneous materials within their respective surface shape models.\cite{amirrajab2020xcat}

% Crucially, this paper from Duke did not show that the virtual phantoms reproduce good results from the model, and they don't allow you to model populations in a randomized way that reflects real distributions, only different imaging zmodality-level choices.
% Much of the related work exploring generative AI for medical image synthesis focuses on augmenting training data for downstream algorithms, which are then evaluated on real data.\cite{chen2022generative}
% \todo{Review methods for CT/MRI generative modeling here, but emphasize that no one is using these to evaluate algorithm failure due to population shift}
% Medical image synthesis can be an effective data source for evaluating AI algorithm performance. \dots Medical image synthesis has also been used as an effective alternative to real data collection for training downstream algorithms. (simulation vs generative modeling)
% Then we look at augmenting/replacing training data with synthetic images?
% Medical image synthesis has played a prominent role in AI training and testing, ranging from the generation of  been proposed as an alternative to real data collection for the purpose of training algorithms. \todo{background on such models, SyntheX, GANs, diffusion, etc.}

% \section{A Full-body Generative Model for \textit{In Silico} CT Imaging Trials}

% % Here's our solution: both a model and a demonstration, in a precisely controlled setting, that full-body image synthesis can serve this purpose.
% The key capability introduced in this work is the generation of realistic, full-body CT images conditioned on high-level attributes, including sex, age, height, and weight. These attributes are easier to obtain than medical images, since they are routinely recorded during primary care and can be deidentified more easily than images. Even if they are not available, they can often be estimated based on public health data, \eg. the census. Using these attributes as a conditioning signal, we train a latent denoising diffusion model with a stacked VQ-GAN autoencoder backbone. \todo{more description of model}
% Our results find that these images are realistic in terms of both appearance and anatomy, comparable to other state-of-the-art CT image synthesis models. At the same time, because the generated images are full-body, their alignment with the conditioning attributes of sex, height, and weight can be directly verified. The alignment with respect to age can be estimated based on distributions of estimated bone density, which declines over time. On its own, this is a valuable capability for creating synthetic patient models in a finely controlled manner.

% For conducting \emph{in silico} imaging trials, the key question is whether conditioning on high-level patient attributes can generate synthetic image datasets that allow downstream algorithms to perform similarly to how they would on the corresponding real data. Can we anticipate real-world algorithm failures before they happen by testing on synthetic datasets? Using the aforementioned conditional model, we generate synthetic patient cohorts for evaluating downstream algorithms for body composition measurement, an important task for tailoring interventions to patients' unique metabolic profiles, which can differ markedly even among individuals with the same age, height, and weight.\cite{lemos2017current}

% \newpage

% % It's an interesting problem:
% In the emerging ecosystem of precision healthcare, access to medical image datasets from specific patient cohorts is crucial for developing and validating machine learning and artificial intelligence (ML/AI) algorithms. These algorithms can improve medical decision making \cite{ozsahin2020review, murugesan2022a, mohammadi2024deep} and support opportunistic disease screening \cite{pickhardt2013opportunistic, jang2019opportunistic,eng2021automated, oh2024evaluation}, but they rely on large scale image datasets with corresponding annotations for training, such as organ segmentation maps or disease indicators. Medical data are often difficult to obtain with sufficient quality and volume for training, due to the cost of collection and annotation.
% Moreover, medical datasets exhibit institution- or device-specific attributes, such as patient demographics or imaging protocol.
% Recent research on AI/ML model auditing has demonstrated fairness/bias concerns~\cite{Gichoya2022ReadingRace, Seyyed-Kalantari2021-aj, Seyyed-Kalantari2021-fa, Glocker2022-st, Henry_Hinnefeld2018-vi,pavlak2023data, beheshtian2022generalizability, bachina2023coarse, garin2023medical, morcos2023applying, li2023sex}, shortcut learning~\cite{winkler2019association, winkler2021association, nauta2021uncovering, jabbour2020deep, degrave2021ai,pavlak2023data, yi2022deep}, and lack of generalization or robustness~\cite{o2022evaluating,pavlak2023data, santomartino2024evaluating}.
% \emph{These failure modes are fundamentally similar}, because DNN performance deteriorates significantly when applied to sample distributions outside the training domain.
% The ability to finely control patient cohort sampling, therefore, would be invaluable for ensuring adequate representation of all relevant attributes in a dataset for ML/AI applications, firstly as a data source for training robust models and second, for evaluating model robustness on unseen populations.

% % Here's a more specific problem, which solves the above: gen AI-based cohort sampling, and it's an unsolved problem.
% \textbf{Synthetic cohorts} are collections of virtual patient models sampled from a desired distribution that support medical image generation. They provide realistic synthetic data without ethical restrictions \cite{khorchani2022sasc, pan20232d, txurio2023diffusion, khader2023denoising, cho2024medisyn}, and can support a range of annotations and specified attributes, including organ segmentations \cite{konz2024anatomically} and disease presence \cite{toda2021synthetic, jiang2020covid, zingarinim3dsynth}. Early works on learning-based medical image synthesis leveraged generative adversarial networks (GANs)~\cite{goodfellow2014generative} and CycleGANs~\cite{zhu2017unpaired} to augment existing data during the training process \cite{toda2021synthetic, han2017mr, lei2019mri}. With the advent of generative diffusion models \cite{ho2020denoising, rombach2022high}, these efforts have matured in terms of realism and capability \cite{kazerouni2023diffusion, ho2020denoising, rombach2022high, esser2020taming}, raising the possibility of fully sythetic cohorts for many applications that would otherwise require real data. However, existing generative medical image models are so far constrained in terms of supported anatomy \cite{khader2023denoising}, dimension \cite{txurio2023diffusion}, or conditioning capabilities \cite{2024addressing}. Txurio  \etal~\cite{txurio2023diffusion} first demonstrated that diffusion probabilistic models were a more viable approach to medical image synthesis than GANs, as measured in terms of the Frechet Inception Distance (FID) for CT image slices. Further work expanded diffusion-based models to 3D by conditioning image generation on adjacent slices \cite{han2023medgen3d, cho2024medisyn} or using 3D convolutions, conditioned on segmentation \cite{dorjsembe2023conditional, jiang2023cola, zingarinim3dsynth}. In one sense, conditioning on 3D segmentations is a desirable capability, because it enables tight control over models' generative process. On the other, it requires valid anatomical segmentations either from real images or from a statistical model based on real images, \eg. \cite{segars2018application}. This is an extra step that may be undesirable when there are no such data available from the desired cohort.

% % Here's our solution
% \emph{Our goal is to support synthetic patient cohorts of high-quality, full-body CT images and organ segmentations, conditioned on desired patient characteristics.}
% Existing approaches in this area focus on specific anatomical regions, such as the brain or abdomen \tocite{}, which are appropriate for specific downstream tasks. There is, however, an unmet need for full-body medical image synthesis, which can support imaging studies and downstream applications on varied anatomy as well as the whole body.
% Conditioning image generation on desired patient characteristics is necessary in order to support synthetic patient cohort generation directly.
% In this work, we focus on demographic characteristics, including sex, height, weight, age, and race, which are routinely included in electronic medical records.
% Using a dataset of \todo{798} full-body CT scans and meta-data from the New Mexico Descedent Image Database (NMDID) \cite{edgar2020new}, we propose a novel 3D denoising diffusion architecture capable of generating CT images conditioned on specific patient characteristics, using classifier-free conditioning on a latent representation of the full body. These images are sufficiently realistic to support multi-organ segmentation by TotalSegmentator~\cite{wasserthal2023totalsegmentator}, a multi-organ segmentation model trained on real images, and they can be generated \emph{ex nihilo}, \ie without any input images or segmentations, so as to support highly scalable cohort sampling.

% Our proposed model, contends directly with several unique challenges of conditional full-body CT image synthesis. The most immediate challenge is how to contend with the significant memory requirements for processing full-body CT images while maintaining global consistency. Rather than processing individual slices, we first encode 3D image patches using a stack of vector quantized generative adversarial networks (VQ-GAN) with a total $16\times$ compression. These patchwise latent codes are concatenated to form a full body latent space, on which a 3D-UNet-based diffusion network can be trained. In training the decoder, we introduce a novel dual-contrast reconstruction loss that ensures low-contrast soft tissue structure receive as much weight during training as high-contrast bony structures. To ensure the anatomical validity of sampled images, we train an additional VQ-GAN to represent a reduced segmentation map, thereby enabling our network to sample from the latent \emph{joint distribution} of CT and segmentations. Thus, our network generates a segmentation to go alongside each CT, and we further demonstrate that this step enables successful, independent segmentation by TotalSegmentator~\cite{wasserthal2023totalsegmentator}. \todo{We further compare our work to existing methods in terms of image realism.}

% To enable synthetic cohort generation, we train our model to support classifier-free conditioning based on demographic characteristics, following \cite{ho2022classifier}. Using the meta-data included in the NMDID dataset, we support specification of patient sex, height, weight, weight, age, and race. However, because NMDID is heavily biased toward older, white populations, we focus our evaluation primarily on the empirically verifiable properties of sex, height, and weight, evaluating whether synthetic CTs generated with TotalSynthesizer align with the desired distribution based on TotalSegmentator-derived metrics, such as the presence of sex organs or the weight as calculated based on an organ-specific density map computed from TotalSegmentator.


% Challenges we faced and how we deal with them
% - Not conditioning on the segmentation means global anatomical structure is difficult.
% - Full-body 3D images are big.
% - Soft tissue structures are low-contrast.
% -

% It's an unsolved problem: The txurio method is 2d only and not conditioned.
%
% Txurio is 2D only
% medisyn is text-conditioned, uses a latent diffusion model, with a 3D unet VAE. Limited in terms of resolution and size.
% Zingarinim injects desired perturbations into existing

% \todo{\cite{eng2021artificial}}

% Rather than collecting images retrospectively from a real-world institution,
% They are attractive as an alternative to real data collection, circumventing ethical and logistical constraints of working with patient data, and can provide certain annotations for ``free,'' depending on the representational power of the underlying algorithm. Recently, generative AI models have been used for conditional medical image synthesis, \eg. based on text descriptions \todo{cite}, that would enable large scale sampling from synthetic patient cohorts of chest X-rays \cite{} and histopathology slides \cite{}.
% \todo{Discuss the limited research into CT/MRI synthesis, and how it falls short in generating full body samples}


% % conclude second paragraph with this.
% The goal of this paper is to generate high quality full-body CT images and organ segmentations from synthetic patient cohorts using conditional generative models.


% % It's an unsolved problem: need to be able to condition full-body generation based on desired attributes, generating CTs with corresponding multi-organ segmentations.
% Generative modeling of medical images has received increasing attention as the associated algorithms and computational resources have matured \cite{kazerouni2023diffusion, kebaili20243d, txurio2023diffusion, cho2024medisyn, zingarinim3dsynth, dorjsembe2023conditional, han2023medgen3d, jiang2023cola}.

% \subsection{Related Work}
% \label{sec:related-work}

% \paragraph{Validation of medical image analysis algorithms}
% Bringing AI into clinical practice.

% \citep{kanbar2022implementation} discusses bringing AI algorithms into clinical practice: where are we now and what's needed in the future. Yeah, but mostly about NLP, so this isn't that useful.

% \citep{ramwala2024establishing}

% \paragraph{Image translation}
% A large body of work has considered CT image synthesis via image-to-image translation.

% % MRI to CT
% \cite{han2017mr} goes from MRI to CT using U-Net architecture, for registration and DRR methods.

% \cite{lei2019mri} uses CycleGANs to synthesize CTs based on MRI, allowing MRI to be used for dose calculation in radiotherapy.

% \cite{bahrami2021comparison} MR to CT translation review

% \cite{pan2024synthetic} MR to CT using 3D diffusion

% % CBCT to CT
% \cite{chen2020synthetic} goes from CBCT to CT, so that algorithms trained on CT can be used intra-operatively, using a U-Net architecture

% \cite{peng2024cbct} CBCT to CT, using denoising diffusion models to enable organ segmentation and dose calculation during radiotherapy.

% \cite{fu2024energy} CBCT to CT using energy-guided diffusion models

% % Review of sCT in radiotherapy
% \cite{spadea2021deep} reviews sCT for radiotherapy applications

% % Adding contrast, conditional
% \cite{kim2018contrast} generates contrast-enhanced CT from PET/CT images, using a conditional GAN.

% \paragraph{Medical Image Synthesis}
% \cite{jiang2020covid} generates CT images with a conditional GAN that have COVID-19

% \cite{pan20232d} uses a diffusion model with a Swin-transformer backbone to create 2D chest X-rays, heart MRI slices, pelvic CT slices, and abodmen CT slices, evaluated in terms of authenticity, quality, and diversity using Turing assessments conducted by 3 medical physicists.

% \cite{sorin2020creating} systematic review in this area.

% % Using Diffusion
% \cite{konz2024anatomically} controlling the anatomy of the generated images using segmentation-guided diffusion

% \cite{txurio2023diffusion} uses diffusion models to generate abdominal CT images, but only in 2D, and evaluate in terms of Frechet Inception Distance

% \cite{khader2023denoising} using 3D diffusion models to synthesize MRi and CT images, quantitatively evaluated by two radiologists in terms of ``realistic image appearance,'' ``anatomical correctness,'' and ``consistency between slices.'' Also demonstrates value for downstream task, for breast segmentation models.


% Then talk about what we've done.
Our framework aims to support virtual clinical trials of AI models in precision medicine.
We therefore introduce a single model for conditional CT image synthesis that is \begin{inlistalpha}
  \item\label{itm:real} realistic,
  \item\label{itm:full} full-body, and
  \item\label{itm:cond} conditioned on high-level patient attributes.
\end{inlistalpha}.
Image realism \ref{itm:real} ensures that observed changes in model performance are due. to the modeled population shifts and not any domain gap between the real and the synthetic. It consists of both low-level visual fidelity, as measured by perceptual metrics such as the Frechet Inception Distance (FID), and high-level anatomical consistency, as measured by a multi-organ segmentation model trained on real images, \ie, TotalSegmentator\cite{wasserthal2023totalsegmentator}.
Given that, the ability to synthesize volumetric, full-body images \ref{itm:full} guarantees that the generative model itself does not become a black box.
Using independent segmentations of the synthesized images, patient-specific measurements of the output image enable independent verification of the generative model's fidelity to conditioning parameters, such as height and weight (see Section~\ref{sec:alignment}).
Additional quantities important for precision medicine, such as body fat percentage, muscle mass, average bone density, \etc, can be estimated directly from the image and independent segmentation (see Section~\ref{sec:body-measures}).
Synthesizing full-body images is challenging, though, due to the memory utilization of generative ML models\cite{guo2024maisi} and the need for anatomical consistency over the full image.\cite{hamamci2023generatect}
Important related work addresses this issue by conditioning generation of a CT image $\mathbf{x}$ on a multi-organ segmentation $\mathbf{y}$,\cite{guo2024maisi} such as can be obtained from a virtual patient phantom.\cite{abadi2020virtual} This reduces the complexity of the learning problem since $P(\mathbf{x}|\mathbf{y})$ is constrained by the detailed organ segmentation. To support more flexible sampling, though, we set out to learn the joint distribution $P(\mathbf{x},\mathbf{y}|\mathbf{a})$, where $\mathbf{a}$ describes patient attributes (sex, age, height, and weight), while still ensuring anatomical consistency with $\mathbf{y}$.
This is accomplished through a latent diffusion model with stacked auto-encoders, a novel loss function for CT image synthesis, and off-classifier conditioning.
Separate encoders and decoders are trained for CT images and segmentations, with the diffusion model learning the joint distribution.
% The model is validated in terms of its visual realism in comparison with state-of-the-art methods trained on far more data; its anatomical consistency based on third-party segmentation of the CT image alone; and fidelity to the conditioning signal.
Finally, we demonstrate the value of this generative model for detecting changes in performance in AI models, using two tasks in precision medicine where a simulated population shift resulted in performance degradation.
