% Please download the latest anthology.bib from
%
% http://aclweb.org/anthology/anthology.bib.gz
@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}


@inproceedings{vaswani2017attention,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam M. Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  booktitle={Neural Information Processing Systems},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:13756489}
}


@article{dabre2020survey,
  title={A survey of multilingual neural machine translation},
  author={Dabre, Raj and Chu, Chenhui and Kunchukuttan, Anoop},
  journal={ACM Computing Surveys (CSUR)},
  volume={53},
  number={5},
  pages={1--38},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{dabre2021indicbart,
  title={IndicBART: A pre-trained model for indic natural language generation},
  author={Dabre, Raj and Shrotriya, Himani and Kunchukuttan, Anoop and Puduppully, Ratish and Khapra, Mitesh M and Kumar, Pratyush},
  journal={arXiv preprint arXiv:2109.02903},
  year={2021}
}

@inproceedings{gao2018image,
  title={Image captioning with scene-graph based semantic concepts},
  author={Gao, Lizhao and Wang, Bo and Wang, Wenmin},
  booktitle={Proceedings of the 2018 10th international conference on machine learning and computing},
  pages={225--229},
  year={2018}
}

@inproceedings{yao2018exploring,
  title={Exploring visual relationship for image captioning},
  author={Yao, Ting and Pan, Yingwei and Li, Yehao and Mei, Tao},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={684--699},
  year={2018}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@article{lecun1989backpropagation,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

@article{caglayan2016multimodal,
  title={Multimodal attention for neural machine translation},
  author={Caglayan, Ozan and Barrault, Lo{\"\i}c and Bougares, Fethi},
  journal={arXiv preprint arXiv:1609.03976},
  year={2016}
}

@article{cho2014learning,
  title={Learning Phrase Representations using RNN Encoder--Decoder for Statistical Machine Translation},
  author={Cho, Kyunghyun},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@inproceedings{yao2020multimodal,
  title={Multimodal transformer for multimodal machine translation},
  author={Yao, Shaowei and Wan, Xiaojun},
  booktitle={Proceedings of the 58th annual meeting of the association for computational linguistics},
  pages={4346--4350},
  year={2020}
}

@article{guo2023layer,
  title={Layer-level progressive transformer with modality difference awareness for multi-modal neural machine translation},
  author={Guo, Junjun and Ye, Junjie and Xiang, Yan and Yu, Zhengtao},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2023},
  publisher={IEEE}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2023}
}

@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{zhai2023sigmoid,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11975--11986},
  year={2023}
}

@article{laurenccon2024matters,
  title={What matters when building vision-language models?},
  author={Lauren{\c{c}}on, Hugo and Tronchon, L{\'e}o and Cord, Matthieu and Sanh, Victor},
  journal={arXiv preprint arXiv:2405.02246},
  year={2024}
}

@article{laurenccon2024building,
  title={Building and better understanding vision-language models: insights and future directions},
  author={Lauren{\c{c}}on, Hugo and Marafioti, Andr{\'e}s and Sanh, Victor and Tronchon, L{\'e}o},
  journal={arXiv preprint arXiv:2408.12637},
  year={2024}
}

@article{wang2023cogvlm,
  title={Cogvlm: Visual expert for pretrained language models},
  author={Wang, Weihan and Lv, Qingsong and Yu, Wenmeng and Hong, Wenyi and Qi, Ji and Wang, Yan and Ji, Junhui and Yang, Zhuoyi and Zhao, Lei and Song, Xixuan and others},
  journal={arXiv preprint arXiv:2311.03079},
  year={2023}
}

 2024. https://mistral.ai/news/mixtral-8x22b/

@inproceedings{chen2021captioning,
  title={Captioning transformer with scene graph guiding},
  author={Chen, Haishun and Wang, Ying and Yang, Xin and Li, Jie},
  booktitle={2021 IEEE international conference on image processing (ICIP)},
  pages={2538--2542},
  year={2021},
  organization={IEEE}
}

@article{show2015tell,
  title={Tell: Neural image caption generation with visual attention kelvin xu},
  author={Show, Attend},
  journal={Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, Yoshua Bengio arXiv (2015-02-10) https://arxiv. org/abs/1502.03044 v3},
  year={2015}
}


@inproceedings{cho-etal-2014-learning,
    title = "Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation",
    author = {Cho, Kyunghyun  and
      van Merri{\"e}nboer, Bart  and
      Gulcehre, Caglar  and
      Bahdanau, Dzmitry  and
      Bougares, Fethi  and
      Schwenk, Holger  and
      Bengio, Yoshua},
    editor = "Moschitti, Alessandro  and
      Pang, Bo  and
      Daelemans, Walter",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1179",
    doi = "10.3115/v1/D14-1179",
    pages = "1724--1734",
}

@article{fan2021beyond,
  title={Beyond english-centric multilingual machine translation},
  author={Fan, Angela and Bhosale, Shruti and Schwenk, Holger and Ma, Zhiyi and El-Kishky, Ahmed and Goyal, Siddharth and Baines, Mandeep and Celebi, Onur and Wenzek, Guillaume and Chaudhary, Vishrav and others},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={107},
  pages={1--48},
  year={2021}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}

@article{abdulmumin2022hausa,
  title={Hausa visual genome: A dataset for multi-modal English to Hausa machine translation},
  author={Abdulmumin, Idris and Dash, Satya Ranjan and Dawud, Musa Abdullahi and Parida, Shantipriya and Muhammad, Shamsuddeen Hassan and Ahmad, Ibrahim Sa'id and Panda, Subhadarshi and Bojar, Ond{\v{r}}ej and Galadanci, Bashir Shehu and Bello, Bello Shehu},
  journal={arXiv preprint arXiv:2205.01133},
  year={2022}
}



@inproceedings{isozaki2010automatic,
  title={Automatic evaluation of translation quality for distant language pairs},
  author={Isozaki, Hideki and Hirao, Tsutomu and Duh, Kevin and Sudoh, Katsuhito and Tsukada, Hajime},
  booktitle={Proceedings of the 2010 conference on empirical methods in natural language processing},
  pages={944--952},
  year={2010}
}


@article{banchs2015adequacy,
  title={Adequacy--fluency metrics: Evaluating mt in the continuous space model framework},
  author={Banchs, Rafael E and D’Haro, Luis F and Li, Haizhou},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={23},
  number={3},
  pages={472--482},
  year={2015},
  publisher={IEEE}
}


@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}


@article{tong2024cambrian,
  title={Cambrian-1: A fully open, vision-centric exploration of multimodal llms},
  author={Tong, Shengbang and Brown, Ellis and Wu, Penghao and Woo, Sanghyun and Middepogu, Manoj and Akula, Sai Charitha and Yang, Jihan and Yang, Shusheng and Iyer, Adithya and Pan, Xichen and others},
  journal={arXiv preprint arXiv:2406.16860},
  year={2024}
}

@article{team2024krutrim,
  title={Krutrim {LLM}: Multilingual Foundational Model for over a Billion People},
  author={Aditya Kallappa and Palash Kamble and Abhinav Ravi and Akshat Patidar and Vinayak Dhruv and Deepak Kumar and Raghav Awasthi and Arveti Manjunath and Shubham Agarwal and Kumar Ashish and Gautam Bhargava and Chandra Khatri and Krutrim Team},
  journal={arXiv preprint arXiv:2502.09642},
  year={2024}
}

@misc{kallappa2025krutrim,
    title={Krutrim LLM: Multilingual Foundational Model for over a Billion People},
    author={Aditya Kallappa and Palash Kamble and Abhinav Ravi and Akshat Patidar and Vinayak Dhruv and Deepak Kumar and Raghav Awasthi and Arveti Manjunath and Shubham Agarwal and Kumar Ashish and Gautam Bhargava and Chandra Khatri},
    year={2025},
    eprint={2502.09642},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@proceedings{wat-2023-asian,
    title = "Proceedings of the 10th Workshop on Asian Translation",
    editor = "Nakazawa, Toshiaki  and
      Kinugawa, Kazutaka  and
      Mino, Hideya  and
      Goto, Isao  and
      Dabre, Raj  and
      Higashiyama, Shohei  and
      Parida, Shantipriya  and
      Morishita, Makoto  and
      Bojar, Ondrej  and
      Eriguchi, Akiko  and
      Oda, Yusuke  and
      Eriguchi, Akiko  and
      Chu, Chenhui  and
      Kurohashi, Sadao",
    month = sep,
    year = "2023",
    address = "Macau SAR, China",
    publisher = "Asia-Pacific Association for Machine Translation",
    url = "https://aclanthology.org/2023.wat-1.0",
}


@proceedings{wat-2022-asian,
    title = "Proceedings of the 9th Workshop on Asian Translation",
    editor = "Nakazawa, Toshiaki  and
      Kinugawa, Kazutaka  and
      Mino, Hideya  and
      Goto, Isao  and
      Dabre, Raj  and
      Higashiyama, Shohei  and
      Parida, Shantipriya  and
      Morishita, Makoto  and
      Bojar, Ondrej  and
      Eriguchi, Akiko  and
      Oda, Yusuke  and
      Eriguchi, Akiko  and
      Chu, Chenhui  and
      others",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Conference on Computational Linguistics",
    url = "https://aclanthology.org/2022.wat-1.0",
}

@proceedings{wat-2021-asian,
    title = "Proceedings of the 8th Workshop on Asian Translation (WAT2021)",
    editor = "Nakazawa, Toshiaki  and
      Nakayama, Hideki  and
      Goto, Isao  and
      Mino, Hideya  and
      Ding, Chenchen  and
      Dabre, Raj  and
      Kunchukuttan, Anoop  and
      Higashiyama, Shohei  and
      Manabe, Hiroshi  and
      Pa, Win Pa  and
      Parida, Shantipriya  and
      Bojar, Ond{\v{r}}ej  and
      Chu, Chenhui  and
      Eriguchi, Akiko  and
      Abe, Kaori  and
      Oda, Yusuke  and
      Sudoh, Katsuhito  and
      Kurohashi, Sadao  and
      Bhattacharyya, Pushpak",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.wat-1.0",
}

@proceedings{wat-2020-asian,
    title = "Proceedings of the 7th Workshop on Asian Translation",
    editor = "Nakazawa, Toshiaki  and
      Nakayama, Hideki  and
      Ding, Chenchen  and
      Dabre, Raj  and
      Kunchukuttan, Anoop  and
      Pa, Win Pa  and
      Bojar, Ond{\v{r}}ej  and
      Parida, Shantipriya  and
      Goto, Isao  and
      Mino, Hidaya  and
      Manabe, Hiroshi  and
      Sudoh, Katsuhito  and
      Kurohashi, Sadao  and
      Bhattacharyya, Pushpak",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.wat-1.0",
}

@inproceedings{nakazawa2019proceedings,
  title={Proceedings of the 6th Workshop on Asian Translation},
  author={Nakazawa, Toshiaki and Ding, Chenchen and Dabre, Raj and Kunchukuttan, Anoop and Doi, Nobushige and Oda, Yusuke and Bojar, Ond{\v{r}}ej and Parida, Shantipriya and Goto, Isao and Mino, Hidaya},
  booktitle={Proceedings of the 6th Workshop on Asian Translation},
  year={2019}
}


@inproceedings{varghese2024yolov8,
  title={YOLOv8: A Novel Object Detection Algorithm with Enhanced Performance and Robustness},
  author={Varghese, Rejin and Sambath, M},
  booktitle={2024 International Conference on Advances in Data Engineering and Intelligent Computing Systems (ADICS)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}


@article{xue2024xgen,
  title={xGen-MM (BLIP-3): A Family of Open Large Multimodal Models},
  author={Xue, Le and Shu, Manli and Awadalla, Anas and Wang, Jun and Yan, An and Purushwalkam, Senthil and Zhou, Honglu and Prabhu, Viraj and Dai, Yutong and Ryoo, Michael S and others},
  journal={arXiv preprint arXiv:2408.08872},
  year={2024}
}

@article{team2024chameleon,
  title={Chameleon: Mixed-modal early-fusion foundation models},
  author={Team Chameleon},
  journal={arXiv preprint arXiv:2405.09818},
  year={2024}
}

@article{team2024gemma,
  title={Gemma: Open models based on gemini research and technology},
  author={Gemma, Team and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  journal={arXiv preprint arXiv:2403.08295},
  year={2024}
}


@inproceedings{lu2024unified,
  title={Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision Language Audio and Action},
  author={Lu, Jiasen and Clark, Christopher and Lee, Sangho and Zhang, Zichen and Khosla, Savya and Marten, Ryan and Hoiem, Derek and Kembhavi, Aniruddha},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26439--26455},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Gemini, Team and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}


@misc{gala2024airavata,
      title={Airavata: Introducing Hindi Instruction-tuned LLM}, 
      author={Jay Gala and Thanmay Jayakumar and Jaavid Aktar Husain and Aswanth Kumar M and Mohammed Safi Ur Rahman Khan and Diptesh Kanojia and Ratish Puduppully and Mitesh M. Khapra and Raj Dabre and Rudra Murthy and Anoop Kunchukuttan},
      year={2024},
      eprint={2401.15006},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{balachandran2023tamilllama,
      title={Tamil-Llama: A New Tamil Language Model Based on Llama 2}, 
      author={Abhinand Balachandran},
      year={2023},
      eprint={2311.05845},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{NavarasaTeluguLLMLabs,
title={Navarsa: Indic LLMs based on Gemmma},
author={Telugu Labs},
      year={2023}

}

@misc{kohli2023building,
      title={Building a Llama2-finetuned LLM for Odia Language Utilizing Domain Knowledge Instruction Set}, 
      author={Guneet Singh Kohli and Shantipriya Parida and Sambit Sekhar and Samirit Saha and Nipun B Nair and Parul Agarwal and Sonal Khosla and Kusumlata Patiyal and Debasish Dhal},
      year={2023},
      eprint={2312.12624},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}



@article{bendale2024sutra,
  title={SUTRA: Scalable Multilingual Language Model Architecture},
  author={Bendale, Abhijit and Sapienza, Michael and Ripplinger, Steven and Gibbs, Simon and Lee, Jaewon and Mistry, Pranav},
  journal={arXiv preprint arXiv:2405.06694},
  year={2024}
}


@article{konstas2017neural,
  title={Neural amr: Sequence-to-sequence models for parsing and generation},
  author={Konstas, Ioannis and Iyer, Srinivasan and Yatskar, Mark and Choi, Yejin and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1704.08381},
  year={2017}
}

@article{li2015diversity,
  title={A diversity-promoting objective function for neural conversation models},
  author={Li, Jiwei and Galley, Michel and Brockett, Chris and Gao, Jianfeng and Dolan, Bill},
  journal={arXiv preprint arXiv:1510.03055},
  year={2015}
}

@article{sennrich2015improving,
  title={Improving neural machine translation models with monolingual data},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1511.06709},
  year={2015}
}

@article{lu2024deepseek,
  title={Deepseek-vl: towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Sun, Yaofeng and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024}
}

@article{costa2022no,
  title={No language left behind: Scaling human-centered machine translation},
  author={Costa-juss{\`a}, Marta R and Cross, James and {\c{C}}elebi, Onur and Elbayad, Maha and Heafield, Kenneth and Heffernan, Kevin and Kalbassi, Elahe and Lam, Janice and Licht, Daniel and Maillard, Jean and others},
  journal={arXiv preprint arXiv:2207.04672},
  year={2022}
}

@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, M},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}

@article{rodriguez2023starvector,
  title={Starvector: Generating scalable vector graphics code from images},
  author={Rodriguez, Juan A and Agarwal, Shubham and Laradji, Issam H and Rodriguez, Pau and Vazquez, David and Pal, Christopher and Pedersoli, Marco},
  journal={arXiv preprint arXiv:2312.11556},
  year={2023}
}

@article{agarwal2018char2char,
  title={Char2char generation with reranking for the e2e nlg challenge},
  author={Agarwal, Shubham and Dymetman, Marc and Gaussier, Eric},
  journal={arXiv preprint arXiv:1811.05826},
  year={2018}
}


@inproceedings{graca-etal-2019-generalizing,
    title = "Generalizing Back-Translation in Neural Machine Translation",
    author = "Gra{\c{c}}a, Miguel  and
      Kim, Yunsu  and
      Schamper, Julian  and
      Khadivi, Shahram  and
      Ney, Hermann",
    editor = "Bojar, Ond{\v{r}}ej  and
      Chatterjee, Rajen  and
      Federmann, Christian  and
      Fishel, Mark  and
      Graham, Yvette  and
      Haddow, Barry  and
      Huck, Matthias  and
      Yepes, Antonio Jimeno  and
      Koehn, Philipp  and
      Martins, Andr{\'e}  and
      Monz, Christof  and
      Negri, Matteo  and
      N{\'e}v{\'e}ol, Aur{\'e}lie  and
      Neves, Mariana  and
      Post, Matt  and
      Turchi, Marco  and
      Verspoor, Karin",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-5205",
    doi = "10.18653/v1/W19-5205",
    pages = "45--52"}

@article{edunov2018understanding,
  title={Understanding Back-Translation at Scale},
  author={Edunov, Sergey},
  journal={arXiv preprint arXiv:1808.09381},
  year={2018}
}


@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@article{gala2023indictrans,
title={IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages},
author={Jay Gala and Pranjal A Chitale and A K Raghavan and Varun Gumma and Sumanth Doddapaneni and Aswanth Kumar M and Janki Atul Nawale and Anupama Sujatha and Ratish Puduppully and Vivek Raghavan and Pratyush Kumar and Mitesh M Khapra and Raj Dabre and Anoop Kunchukuttan},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=vfT4YuzAYA}
}


@article{maaz2024palo,
  title={PALO: A Polyglot Large Multimodal Model for 5B People},
  author={Maaz, Muhammad and Rasheed, Hanoona and Shaker, Abdelrahman and Khan, Salman and Cholakal, Hisham and Anwer, Rao M and Baldwin, Tim and Felsberg, Michael and Khan, Fahad S},
  journal={arXiv preprint arXiv:2402.14818},
  year={2024}
}


%%%% Grounding


@article{rainie2012photos,
  title={Photos and videos as social currency online},
  author={Rainie, Lee and Brenner, Joanna and Purcell, Kristen},
  journal={Pew Internet \& American Life Project},
  url={https://www.pewresearch.org/internet/wp-content/uploads/sites/9/media/Files/Reports/2012/PIP_OnlineLifeinPictures_PDF.pdf},
  year={2012}
}

@inproceedings{hu2014we,
  title={What we instagram: A first analysis of instagram photo content and user types},
  author={Hu, Yuheng and Manikonda, Lydia and Kambhampati, Subbarao},
  booktitle={8th International Conference on Weblogs and Social Media, ICWSM 2014},
  year={2014},
  url={http://149.169.27.83/instagram-icwsm.pdf}
}

@inproceedings{specia2016shared,
  title={A shared task on multimodal machine translation and crosslingual image description},
  author={Specia, Lucia and Frank, Stella and Sima’an, Khalil and Elliott, Desmond},
  booktitle={Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers},
  pages={543--553},
  url={https://www.aclweb.org/anthology/W16-2346/},
  year={2016}
}

@article{elliott2016multi30k,
  title={Multi30k: Multilingual english-german image descriptions},
  author={Elliott, Desmond and Frank, Stella and Sima'an, Khalil and Specia, Lucia},
  journal={arXiv preprint arXiv:1605.00459},
  year={2016}
}

@inproceedings{caglayan2020simultaneous,
  title={Simultaneous Machine Translation with Visual Context},
  author={Caglayan, Ozan and Ive, Julia and Haralampieva, Veneta and Madhyastha, Pranava and Barrault, Lo{\"\i}c and Specia, Lucia},
  booktitle={CoRR abs/2009.07310},
  url={https://arxiv.org/pdf/2009.07310.pdf},
  year={2020}
}

@inproceedings{van2019task,
  title={On task effects in {NLG} corpus elicitation: A replication study using mixed effects modeling},
  author={van Miltenburg, Emiel and van de Kerkhof, Merel and Koolen, Ruud and Goudbeek, Martijn and Krahmer, Emiel},
  booktitle={INLG},
  url={https://www.aclweb.org/anthology/W19-8649/},
  year={2019}
}


@article{harnad1990symbol,
  title={The symbol grounding problem},
  author={Harnad, Stevan},
  journal={Physica D: Nonlinear Phenomena},
  year={1990},
  url={https://www.southampton.ac.uk/~harnad/Papers/Harnad/harnad90.sgproblem.html},
  publisher={Elsevier}
}

@incollection{harnad2003minds,
  title={Minds, machines and Turing},
  author={Harnad, Stevan},
  booktitle={The Turing Test},
  pages={253--273},
  year={2003},
  publisher={Springer}
}

@book{fodor1975language,
  title={The language of thought},
  author={Fodor, Jerry A},
  volume={5},
  year={1975},
  publisher={Harvard university press}
}

@incollection{harnad2005cognize,
  title={To cognize is to categorize: Cognition is categorization},
  author={Harnad, Stevan},
  booktitle={Handbook of categorization in cognitive science},
  pages={21--54},
  year={2005},
  publisher={Elsevier}
}

@article{bisk2020experience,
  title={Experience grounds language},
  author={Bisk, Yonatan and Holtzman, Ari and Thomason, Jesse and Andreas, Jacob and Bengio, Yoshua and Chai, Joyce and Lapata, Mirella and Lazaridou, Angeliki and May, Jonathan and Nisnevich, Aleksandr and others},
  journal={CoRR abs/2004.10151},
  url={https://arxiv.org/abs/2004.10151},
  year={2020}
}

@inproceedings{mooney2008learning,
  title={Learning to connect language and perception},
  author={Mooney, Raymond J},
  booktitle={AAAI},
  url={https://www.aaai.org/Papers/AAAI/2008/AAAI08-271.pdf},
  year={2008}
}


@article{li2022vision,
  title={On vision features in multimodal machine translation},
  author={Li, Bei and Lv, Chuanhao and Zhou, Zefan and Zhou, Tao and Xiao, Tong and Ma, Anxiang and Zhu, JingBo},
  journal={arXiv preprint arXiv:2203.09173},
  year={2022}
}

@inproceedings{wu-etal-2021-good,
    title = "Good for Misconceived Reasons: An Empirical Revisiting on the Need for Visual Context in Multimodal Machine Translation",
    author = "Wu, Zhiyong  and
      Kong, Lingpeng  and
      Bi, Wei  and
      Li, Xiang  and
      Kao, Ben",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "ACL",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.480",
    doi = "10.18653/v1/2021.acl-long.480",
    pages = "6153--6166"}


@inproceedings{lala2018sheffield,
  title={Sheffield submissions for WMT18 multimodal translation shared task},
  author={Lala, Chiraag and Madhyastha, Pranava Swaroop and Scarton, Carolina and Specia, Lucia},
  booktitle={Proceedings of the Third Conference on Machine Translation: Shared Task Papers},
  pages={624--631},
  year={2018}
}

@article{gronroos2018memad,
  title={The MeMAD submission to the WMT18 multimodal translation task},
  author={Gr{\"o}nroos, Stig-Arne and Huet, Benoit and Kurimo, Mikko and Laaksonen, Jorma and Merialdo, Bernard and Pham, Phu and Sj{\"o}berg, Mats and Sulubacak, Umut and Tiedemann, J{\"o}rg and Troncy, Raphael and others},
  journal={arXiv preprint arXiv:1808.10802},
  year={2018}
}


@inproceedings{elliott-kadar-2017-imagination,
    title = "Imagination Improves Multimodal Translation",
    author = "Elliott, Desmond  and
      K{\'a}d{\'a}r, {\'A}kos",
    editor = "Kondrak, Greg  and
      Watanabe, Taro",
    booktitle = "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = nov,
    year = "2017",
    address = "Taipei, Taiwan",
    publisher = "Asian Federation of Natural Language Processing",
    url = "https://aclanthology.org/I17-1014",
    pages = "130--141"}


@inproceedings{delbrouck-dupont-2017-empirical,
    title = "An empirical study on the effectiveness of images in Multimodal Neural Machine Translation",
    author = "Delbrouck, Jean-Benoit  and
      Dupont, St{\'e}phane",
    editor = "Palmer, Martha  and
      Hwa, Rebecca  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1095",
    doi = "10.18653/v1/D17-1095",
    pages = "910--919"}

@inproceedings{calixto-liu-2017-incorporating,
    title = "Incorporating Global Visual Features into Attention-based Neural Machine Translation.",
    author = "Calixto, Iacer  and
      Liu, Qun",
    editor = "Palmer, Martha  and
      Hwa, Rebecca  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1105",
    doi = "10.18653/v1/D17-1105",
    pages = "992--1003"}



@article{gain2021iitp,
  title={IITP at WAT 2021: System description for English-Hindi multimodal translation task},
  author={Gain, Baban and Bandyopadhyay, Dibyanayan and Ekbal, Asif},
  journal={arXiv preprint arXiv:2107.01656},
  year={2021}
}

@article{gupta2021vita,
  title={ViTA: Visual-linguistic translation by aligning object tags},
  author={Gupta, Kshitij and Gautam, Devansh and Mamidi, Radhika},
  journal={arXiv preprint arXiv:2106.00250},
  year={2021}
}

@article{parida2022silo,
  title={Silo NLP's Participation at WAT2022},
  author={Parida, Shantipriya and Panda, Subhadarshi and Gr{\"o}nroos, Stig-Arne and Granroth-Wilding, Mark and Koistinen, Mika},
  journal={arXiv preprint arXiv:2208.01296},
  year={2022}
}

@inproceedings{dash2023bits,
  title={BITS-P at WAT 2023: Improving Indic Language Multimodal Translation by Image Augmentation using Diffusion Models},
  author={Dash, Amulya and Gupta, Hrithik Raj and Sharma, Yashvardhan},
  booktitle={Proceedings of the 10th Workshop on Asian Translation},
  pages={41--45},
  year={2023}
}

@inproceedings{shahid2023odiagenai,
  title={OdiaGenAI’s Participation at WAT2023},
  author={Shahid, Sk and Kohli, Guneet Singh and Sekhar, Sambit and Dhal, Debasish and Sharma, Adit and Kushwaha, Shubhendra and Parida, Shantipriya and Gr{\"o}nroos, Stig-Arne and Dash, Satya Ranjan},
  booktitle={Proceedings of the 10th Workshop on Asian Translation},
  pages={46--52},
  year={2023}
}

@inproceedings{buck2014n,
  title={N-gram Counts and Language Models from the Common Crawl.},
  author={Buck, Christian and Heafield, Kenneth and Van Ooyen, Bas},
  booktitle={LREC},
  volume={2},
  pages={4},
  year={2014}
}

@article{penedo2023refinedweb,
  title={The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only},
  author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal={arXiv preprint arXiv:2306.01116},
  year={2023}
}

@inproceedings{girshick2015fast,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1440--1448},
  year={2015}
}

@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}



@article{li2023video,
  title={Video-Helpful Multimodal Machine Translation},
  author={Li, Yihang and Shimizu, Shuichiro and Chu, Chenhui and Kurohashi, Sadao and Li, Wei},
  journal={arXiv preprint arXiv:2310.20201},
  year={2023}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}


@article{zhai2023investigating,
  title={Investigating the catastrophic forgetting in multimodal large language models},
  author={Zhai, Yuexiang and Tong, Shengbang and Li, Xiao and Cai, Mu and Qu, Qing and Lee, Yong Jae and Ma, Yi},
  journal={arXiv preprint arXiv:2309.10313},
  year={2023}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International conference on machine learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{biderman2024lora,
  title={Lora learns less and forgets less},
  author={Biderman, Dan and Ortiz, Jose Gonzalez and Portes, Jacob and Paul, Mansheej and Greengard, Philip and Jennings, Connor and King, Daniel and Havens, Sam and Chiley, Vitaliy and Frankle, Jonathan and others},
  journal={arXiv preprint arXiv:2405.09673},
  year={2024}
}

@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{jaegle2021perceiver,
  title={Perceiver: General perception with iterative attention},
  author={Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle={International conference on machine learning},
  pages={4651--4664},
  year={2021},
  organization={PMLR}
}

@article{alexey2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.11929},
  url={https://api.semanticscholar.org/CorpusID:225039882}
}



@article{singh2024indicgenbench,
  title={IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages},
  author={Singh, Harman and Gupta, Nitish and Bharadwaj, Shikhar and Tewari, Dinesh and Talukdar, Partha},
  journal={arXiv preprint arXiv:2404.16816},
  year={2024}
}

@article{ahuja2023mega,
  title={Mega: Multilingual evaluation of generative ai},
  author={Ahuja, Kabir and Diddee, Harshita and Hada, Rishav and Ochieng, Millicent and Ramesh, Krithika and Jain, Prachi and Nambi, Akshay and Ganu, Tanuja and Segal, Sameer and Axmed, Maxamed and others},
  journal={arXiv preprint arXiv:2303.12528},
  year={2023}
}

@misc{zhai2023sigmoidlosslanguageimage,
      title={Sigmoid Loss for Language Image Pre-Training}, 
      author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
      year={2023},
      eprint={2303.15343},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2303.15343}, 
}


@article{li2023evaluating,
  title={Evaluating object hallucination in large vision-language models},
  author={Li, Yifan and Du, Yifan and Zhou, Kun and Wang, Jinpeng and Zhao, Wayne Xin and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2305.10355},
  year={2023}
}

@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@article{fu2023mme,
  title={{MME}: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and Qin, Yulei and Zhang, Mengdan and Lin, Xu and Yang, Jinrui and Zheng, Xiawu and Li, Ke and Sun, Xing and others},
  journal={arXiv preprint arXiv:2306.13394},
  year={2023}
}

@article{yu2023mm,
  title={{MM-VET}: Evaluating large multimodal models for integrated capabilities},
  author={Yu, Weihao and Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Liu, Zicheng and Wang, Xinchao and Wang, Lijuan},
  journal={arXiv preprint arXiv:2308.02490},
  year={2023}
}

@inproceedings{hudson2019gqa,
  title={{GQA}: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6700--6709},
  year={2019}
}

@inproceedings{gurari2018vizwiz,
  title={Vizwiz grand challenge: Answering visual questions from blind people},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3608--3617},
  year={2018}
}

@inproceedings{singh2019towards,
  title={Towards vqa models that can read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8317--8326},
  year={2019}
}


@article{scao2022language,
  title={What language model to train if you have one million gpu hours?},
  author={Scao, Teven Le and Wang, Thomas and Hesslow, Daniel and Saulnier, Lucile and Bekman, Stas and Bari, M Saiful and Biderman, Stella and Elsahar, Hady and Muennighoff, Niklas and Phang, Jason and others},
  journal={arXiv preprint arXiv:2210.15424},
  year={2022}
}


@article{chen2023sharegpt4v,
            title={ShareGPT4V: Improving Large Multi-Modal Models with Better Captions},
            author={Chen, Lin and Li, Jisong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
            journal={arXiv preprint arXiv:2311.12793},
            year={2023}
          }

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{beyer2024paligemma,
  title={Paligemma: A versatile 3b vlm for transfer},
  author={Beyer, Lucas and Steiner, Andreas and Pinto, Andr{\'e} Susano and Kolesnikov, Alexander and Wang, Xiao and Salz, Daniel and Neumann, Maxim and Alabdulmohsin, Ibrahim and Tschannen, Michael and Bugliarello, Emanuele and others},
  journal={arXiv preprint arXiv:2407.07726},
  year={2024}
}

@inproceedings{xiao2024florence,
  title={Florence-2: Advancing a unified representation for a variety of vision tasks},
  author={Xiao, Bin and Wu, Haiping and Xu, Weijian and Dai, Xiyang and Hu, Houdong and Lu, Yumao and Zeng, Michael and Liu, Ce and Yuan, Lu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4818--4829},
  year={2024}
}

@article{chen2022pali,
  title={Pali: A jointly-scaled multilingual language-image model},
  author={Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Piergiovanni, AJ and Padlewski, Piotr and Salz, Daniel and Goodman, Sebastian and Grycner, Adam and Mustafa, Basil and Beyer, Lucas and others},
  journal={arXiv preprint arXiv:2209.06794},
  year={2022}
}

@article{chen2024far,
  title={How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={arXiv preprint arXiv:2404.16821},
  year={2024}
}


@article{bai2023qwen,
  title={{Qwen-VL}: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}


@article{abdin2024phi,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Jacobs, Sam Ade and Awan, Ammar Ahmad and Aneja, Jyoti and Awadallah, Ahmed and Awadalla, Hany and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Behl, Harkirat and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}


@article{laurenccon2024unlocking,
  title={Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset},
  author={Lauren{\c{c}}on, Hugo and Tronchon, L{\'e}o and Sanh, Victor},
  journal={arXiv preprint arXiv:2403.09029},
  year={2024}
}

@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  volume={2},
  number={3},
  pages={6},
  year={2023}
}