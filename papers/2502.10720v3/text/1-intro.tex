 %% ----------------------------------------------------------------------------
% BIWI SA/MA thesis template
%
% Created 09/29/2006 by Andreas Ess
% Extended 13/02/2009 by Jan Lesniak - jlesniak@vision.ee.ethz.ch
%% ----------------------------------------------------------------------------


\chapter{Introduction}
% Give an introduction to the topic you have worked on:

% \begin{itemize}
%  \item \textit{What is the rationale for your work?} Give a sufficient description of the problem, e.g. with a general description of the problem setting, narrowing down to the particular problem you have been working on in your thesis. Allow the reader to understand the problem setting. 
%  \item \textit{What is the scope of your work?} Given the above background, state briefly the focus of the work, what and how you did.
%  \item \textit{How is your thesis organized?} It helps the reader to pick the interesting points by providing a small text or graph which outlines the organization of the thesis. The structure given in this document shows how the general structuring shall look like. However, you may fuse chapters or change their names according to the requirements of your thesis.
% \end{itemize}


% \section{Focus of this Work}

% \section{Thesis Organization}

Accurately parsing input images under uncommon visual conditions is a required ability for safe autonomous driving systems. Thus, semantic segmentation datasets under various adverse conditions are required, especially at nighttime. However, most well-known autonomous driving datasets such as the Cityscapes dataset~\cite{Cordts2016Cityscapes} and KITTI dataset~\cite{Geiger2012CVPR} are mostly under normal conditions (clear daytime image with high illumination and low exposure time). Though several recent works, including Oxford RobotCar dataset~\cite{RCDRTKArXiv}, BDD100K~\cite{bdd100k} dataset and ACDC dataset~\cite{SDV21ACDC}, have been focusing on creating datasets under nighttime conditions, there are still obvious limitations and gaps. For example, the Oxford RobotCar does not contain any semantic annotations and thus is not capable for training a segmentation network. BDD100K dataset contains a large number of nighttime images; however, only 345 of them can be used for the task of semantic segmentation. ACDC dataset contains 4006 adverse condition images in which 1006 of them are in the nighttime; it still shows a drastic drop in the accuracy of semantic scene understanding at nighttime compared to other conditions for both segmentation algorithms~\cite{2016_deeplab, deeplabv3plus2018, fu2019danet, Lin_2017_RefineNet, 2015_SFSU, SunXLW19} and domain adaptation methods~\cite{2019_bdl, luo2019Taking, SDHV18, Tsai_adaptseg_2018, vu2018advent, Wang_2020_CVPR, 2020_fda}. What makes things even worse is the increased difficulty in the semantic annotation of real nighttime images due to their low quality, which leads to annotation errors that have a negative impact on the quality of models trained on such data. An alternative approach for semantic nighttime scene understanding is via the generation of partially synthetic nighttime data. Specifically, individuals can obtain images captured during the daytime, which is less noisy and relatively easier to annotate, then transform these images to nighttime through style transfer~\cite{2015_style, 2016_style}. Subsequently, annotations on daytime images can be directly used to the synthesized nighttime images, given that the underlying semantic content remains consistent. However, style transfer falls short in generating realistic results due to its inability to account for factors such as changes in illumination that occur from day to night and the complicated geometry and variations in light sources. In this thesis, we propose the NPSim, an alternative approach for generating partially synthetic nighttime images via monocular inverse rendering and ray tracing. 

Our proposed method NPSim aims to generate photo-realistic nighttime images based on clear daytime images and their corresponding standard semantic annotations. Importantly, we also utilize light source annotations as additional input. Different from previous works that used style transformation~\cite{CycleGAN2017}, 2D~\cite{Punnappurath_2022_CVPR} or implicit representation such as NeRF~\cite{mildenhall2020nerf}, NPSim focuses on the fundamentals of scene lighting, using traditional rendering method ray tracing to produce realistic nighttime images by restoring the object orientation, material characteristics, and light sources based on the input image. It leverages the explicit representation by reconstructing scene mesh from a given RGB image. To preserve more accurate geometric information, we propose Geometry Mesh Reconstruction component: We first utilize an off-the-shelf depth and normal estimation model to predict the initial depth map and normal map. Then we use predicted depth to reconstruct the scene mesh and refine it using a normal-guided optimization-based method. Besides, our proposed NPSim considers real-world light sources to generate realistic nighttime images. In the Realistic Nighttime Scene Relighting component, we employ ray tracing to generate nighttime visuals by considering geometric scene mesh from previous steps, material attributes, and authentic light sources from the real world. Our probabilistic light source activation also has the potential to activate different light source combinations, generating multiple nighttime images based on one single input image.

In summary, the contributions of our work are:
\begin{itemize}
\setlength{\itemsep}{1mm}
\setlength{\parskip}{0pt}
    \item A dataset of inactive light sources and the corresponding light source dataset, containing strength and chromaticity tuples (\mysecref{sec:data_prep}).
    \item A physically-based day-to-night simulation pipeline that contains a Geometry Mesh Reconstruction component (\mysecref{sec:gmr}, \mysecref{sec:drk}, \mysecref{sec:mpk}) and a Realistic Nighttime Scene Relighting component (\mysecref{sec:rnsr}).
\end{itemize}
In the experiment, our method can achieve better geometry reconstruction compared with previous works~\cite{hu2021worldsheet, zhang2022simbar}. Additionally, we show that our method can be generalized to other autonomous driving datasets such as the Cityscapes dataset~\cite{Cordts2016Cityscapes} and the BDD100K dataset~\cite{bdd100k} for the task of mesh reconstruction. The structure of the thesis is as follows: We first describe methods we used for data collection, then we introduce our day-to-night transformation method NPSim. In the end, we present the results of the Geometric Mesh Reconstruction component and testing plans for the entire data generation pipeline.