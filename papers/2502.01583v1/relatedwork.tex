\section{Related work}
\label{sec:related}

% % these have been covered in the intro, so I commented it 
% \paragraph{Spectral estimators for single-index models.}
% Our work builds on a line of works on spectral estimators for single-index models. 

\paragraph{Multi-index models.}
Several approaches have been proposed to perform statistical inference in multi-index models, including 
structural adaption via maximum minimization \cite{dalalyan2008new}, 
projection pursuit regression \cite{yuan2011identifiability},
techniques from compressed sensing 
\cite{fornasier2012learning}, and the estimation of score functions
\cite{babichev2018slice}. 
Polynomial link function are considered in \citet{andoni2014learning,Chen_Meka}, with the latter work proposing a spectral warm start that requires a sample size $ n \gtrsim d (\log(d))^{\deg(q)} $, where $\deg(q)$ denotes the degree of the link. The area has witnessed a renewed interest in recent years, due to the connection of multi-index models with two-layer neural networks, and a quickly growing line of work has focused on the performance of gradient-based methods. In particular, sample complexity bounds for gradient descent and SQ lower bounds are provided by \citet{damian2022neural} when the link function is polynomial and by  \citet{Oko_GAM} when the multi-index model is given by the sum of single-index models. 
\citet{abbe2022merged,abbe2023sgd} introduce the concept of leap complexity and show that a certain class of staircase functions can be learned via one-pass stochastic gradient descent (SGD) with $n = \Theta(d)$ samples. The leap exponent also appears in \cite{MIM_GF} as the time required by gradient flow to escape a saddle point. 
A deterministic equivalent of the SGD dynamics is proved in \citet{collins2024hitting}.  
\citet{Ren_Lee} provides an algorithm that recovers orthogonal multi-index models with a sample complexity matching the information exponent 
\cite{arous2021online}. 
We note that none of these methods is able to pin-point exactly the sample complexity required to recover a multi-index model, which constitutes the focus of our work and is achieved via the class of spectral methods reviewed below.


\paragraph{Spectral estimators.} The idea behind spectral methods finds its root in \cite{Li2} where it was first developed in the low-dimensional regime with $d$ fixed and $n$ large. 
Spectral estimators have since been applied to a variety of problems in statistical inference, including community detection \cite{abbe2017community}, clustering \cite{ng2001spectral}, angular synchronization \cite{singer2011angular}, principal component analysis (PCA) \cite{Mont_Venk_AOS} and tensor estimation \cite{MR_tensor_PCA}. 
 In the setting of Gaussian design and proportional scaling between $n$ and $d$, the precise asymptotic performance of spectral methods for single-index models is characterized in \cite{lu2020phase} by random matrix theoretic means. 
 The optimal weak recovery threshold and optimal asymptotic performance (in terms of overlap) are  identified in \citet{mondelli-montanari-2018-fundamental} and \cite{Luo_Alghamdi_Lu}, respectively. 
 The above results are extended in \cite{dudeja-2020-rigorous-analysis} to subsampled Haar designs where $ A = \matrix{a_1, & \cdots, & a_n}^\top \in \bbR^{n\times d} $ is obtained by truncating a random orthogonal matrix, and in \cite{Zhang_COLT} to correlated Gaussian designs where the $ a_i $'s are i.i.d.\ Gaussian with a given covariance. Rotationally invariant designs are considered in \cite{maillard2022construction}, which conjectures the form of the optimal spectral estimator using a linearization of AMP and the analysis of the Bethe Hessian. Such conjecture is partly addressed by \citet{Zhang_COLT}, when the covariance of the $a_i$'s is rotationally invariant. 
  We note that, in the single-index case, optimal spectral methods match computational thresholds obtained from the stability of AMP \cite{mondelli-montanari-2018-fundamental,Zhang_COLT} and, in special cases, information-theoretic thresholds as well \cite{mondelli-montanari-2018-fundamental}. An optimally-designed spectral estimator is able to meet the information-theoretic limits of weak recovery also for a class of heteroscedastic PCA problems \cite{MatrixDenoising}. Most closely related to our setting is \cite{mixed-zmv-arxiv}: the authors 
 consider mixtures of single-index models 
 with independent signals and provide precise asymptotics for spectral estimators by using a mix of tools from random matrix theory and the theory of AMP. In contrast, our approach is purely random matrix theoretic, and it allows us to handle a general class of multi-index models with arbitrary correlation among the signals.