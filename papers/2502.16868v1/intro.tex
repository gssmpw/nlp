

\section{Introduction}
\label{sec:intro}

We study real-world investigative tasks that require iterative exploration and synthesis of large unstructured data corpora. We refer to this challenge as \textbf{Progressive Document Investigation} (\problem), an iterative process of identifying a focal topic, refining a relevant dataset, and ultimately generating high-quality reports, summaries, or recommendations.
A motivating example of \problem~ is the literature survey process in academic research. Researchers start with a topic of interest, identify a few seed papers, and conduct iterative rounds of investigation: skimming key elements (e.g., ``abstract'', ``challenges'', ``solutions''), following references to additional papers, and expanding the set of relevant works. After collecting a sufficient corpus, they then synthesize their findings into a structured survey report -- often by grouping papers by shared characteristics (e.g., addressing similar challenges or proposing similar solutions).



\eat{
While RAG-based solutions can efficiently retrieve short, context-relevant snippets for question answering, they struggle to maintain consistency and organization when applied to large-scale, multi-step explorations. Existing AI agent systems, on the other hand, risk error propagation across extensive pipelines, especially if they are expected to autonomously parse and link large collections of unstructured data in real time. Moreover, both methods typically provide limited support for iterative user oversight and curation, which researchers often prefer to ensure accuracy and control.
}

The advent of Large language models (LLMs)~\cite{gpt4o} have shown impressive potentials for handling \problem, in particular with techniques like Retrieval-Augmented Generation (RAG)~\cite{lewis2021rag} and autonomous AI agents~\cite{han2024agent}. While these methods excel at single-document queries and conversational workflows, they fall short for solving \problem. %RAG-based solutions often struggle to maintain consistency and organization when applied to large-scale, multi-step explorations. Existing AI agent systems, on the other hand, risk error propagation across extensive pipelines.
%While RAG-based solutions can efficiently retrieve short, context-relevant snippets for question answering,
RAG-based solutions often struggle to maintain consistency and organization when applied to large-scale, multi-step explorations. Existing AI agent systems, on the other hand, risk error propagation across extensive pipelines, especially if they are expected to autonomously parse and link large collections of unstructured data.
Moreover, both methods typically provide limited support for iterative user oversight and curation, which researchers often prefer to ensure accuracy and control.

\begin{figure*}[t]
  \centering
  \includegraphics[width=0.8\linewidth,height=8cm]{figures/graphy.pdf}
  \caption{The design and demo case of literature survey of \sys.}
  \label{fig:graphy}
  \vspace*{-1em}
\end{figure*}

To address these gaps, we propose \sys, an end-to-end platform that streamlines the \problem~ workflow.
We adopt the property graph model for the need of iterative exploration in \problem.
Drawing inspiration from business intelligence (BI) systems~\cite{gray1996datacube}, we introduce \fact~ and \dimension~ nodes, analogous to \fact~ and \dimension~ tables in BI. Here, \fact~ nodes represent the primary entities of interest, while \dimension~ nodes capture supplementary information. In a literature-survey context, each paper functions as a \fact~ node (henceforth they are used interchangeably), and its extracted contents, such as ``abstract'', ``challenges'', and ``solutions'', serve as \dimension~ nodes. Although our demonstration centers on the literature-survey scenario, \sys~is broadly applicable; in \refsec{others}, we briefly illustrate its potential in financial use cases.

\reffig{graphy} provides an overview of \sys, which consists of two main roles: the offline \scrapper~ and the online \surveyor.

\stitle{Offline \scrapper}.
%The \scrapper~ automatically fetches and organizes documents into a graph structure by identifying \fact~ nodes,
%namely papers, and their \dimension~ nodes.
The \scrapper allows users to implement the \inspector~ abstraction to direct the extraction of specific
\dimensions~ from each document, often leveraging LLMs.
This step transforms an unstructured document into a structured \fact~ node%\footnote{We assume each document corresponds to one \fact~ node, though future work may handle more complex mappings.}
linked to predefined \dimension~ nodes. It simulates how a human researcher would skim a document, pinpointing aspects such as abstract, challenges, and solutions. Additionally, a \navigator~ abstraction defines how \fact~ nodes are connected, enabling the retrieval of related items for progressive exploration. For instance, an Arxiv~\cite{arxiv} \navigator~ automatically fetches and downloads research papers from this open-source repository.

%Unlike conventional BI systems, we allow \fact~ nodes to connect with one another, creating a flexible graph that supports progressive, in-depth exploration. The \scrapper~ consists of an

Because both the extracted data from the \inspector~ and the linked data from the \navigator~ are relatively stable, we run the \scrapper~ offline. Upon completion, it produces a graph of \fact~ nodes, \dimension~ nodes, and their interconnecting edges, which can be imported into a standard graph database (e.g., GraphScope Interactive~\cite{graphscope}).

\stitle{Online \surveyor}.
Designing a user-friendly \surveyor~ on top of graph databases poses two key challenges. First, unlike SQL, graph query languages are less familiar to users. Second, graph exploration can become unwieldy, particularly with “supernodes,” which have extremely large numbers of connections.  We address these challenges with the \explorer, which is the main interface for navigating the graph and selecting papers of interest. As shown in \reffig{graphy}, it offers a convenient \search~ module to initiate exploration. Users can iteratively move from one set of nodes to their neighbors (referenced papers), with Cypher operations (e.g., \neighborquery) seamlessly integrated into a UI interface inspired by BI toolkits~\cite{polaris}. To avoid overwhelming users, \explorer~ employ histograms and top-k selectors to allow users filter out neighbors of interests.

Eventually, users can proceed to the \generator~ module, which leverages LLMs for creating reports from the papers selected in the \explorer. Users specify the report’s focus (e.g., challenges, solutions), and the \generator~ leverages \fact and relevant \dimension~ nodes to draft a mind map. After reviewing and refining, the system produces a coherent, structured report that mimics a human researcher’s synthesis process. The final document can be exported in various formats (e.g., PDF, LaTeX) to facilitate academic writing.


In this paper, we demonstrate how \sys~ can streamline the literature-survey process. Specifically:

\begin{itemize}
\item \textbf{Data Extraction and Linking:}
With a predefined workflow, we demonstrate how the \scrapper~ employs the \inspector~ to extract \fact~ and \dimension~ nodes from research papers, and how the \navigator~ automatically expands from a set of seed papers to their cited references.%, fetching and downloading additional PDFs from Arxiv~\cite{arxiv}.

\item \textbf{Paper Exploration:}
Using a pre-scrapped graph containing approximately 50,000 papers, 250,000 \dimension~ nodes, and 160,000 references among the papers, we demonstrate how users can effectively utilize the \explorer~ interface to progressively search for papers of interest, simulating the process of literature survey. %During this process, advanced tools such as histogram view and top-k selector will be showcased, enabling users to identify and focus on the most relevant neighbors, streamlining their exploration and discovery.

\item \textbf{Report Generation:}
We demonstrate how the \generator~ collects essential information from the selected papers and creates mind maps in line with users’ intentions. We then showcase its capability to transform these mind maps into a well-structured report, which users can download in formats including PDF and TeX.
\end{itemize}

We have open-sourced both the \sys~ codebase and the pre-scrapped research graph~\cite{opensource}.
The approximate cost of scrapping the research graph using the QWen-plus model~\cite{tongyi} is \$600.
