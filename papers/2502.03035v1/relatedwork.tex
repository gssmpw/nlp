\section{Related Work}
\label{sec:relworks}

\textbf{Reinforcement Learning in Legged Robots.}
In recent years, reinforcement learning (RL) has gained traction in legged robots' control and locomotion tasks~\cite{strudel2020learningcombineprimitiveskills, tang2020learningagilelocomotionadversarial}. Some deep-learning-based RL methods are proposed to improve quadrupedal robots' stability across diverse terrains through combined simulated and real-world training~\cite{A2022ReinforcementLB}. In this work, we utilize the Proximal Policy Optimization (PPO) algorithm provided by Legged Gym for RL-based control of legged robots. Our approach focuses on enhancing locomotion control by reconstructing the Actor model, improving performance in complex environments.

\begin{figure*}
  \centering
  \includegraphics[width=0.95\linewidth]{imgs/workflow.pdf}
  \vspace{-2mm}
  \caption{UMC system for transformer-based Actor-Model Architecture. \( K \) is the number of encoder layers. For more details of the architecture, please refer to \cref{sec:umcframework}.}
  \vspace{-5mm}
  \label{fig:trf_model}
\end{figure*}


\textbf{Self-recovering Robots.}
In recent years, self-recovering robots have attracted significant interest in robotics research~\cite{1044017, Guan2015FaultSF, 9249654}. As robotics technology matures, enabling legged robots to adapt to joint damage has become increasingly critical. However, few studies address this directly, and existing approaches often lack generalization, require excessive training data, or complex maintenance with conflicting strategies~\cite{kume2017mapbasedmultipolicyreinforcementlearning, nagabandi2019learningadaptdynamicrealworld, raileanu2020fastadaptationpolicydynamicsvalue, YangGANARL, ChenFADM, guo2023decentralizedmotorskilllearning}. Therefore, we aim to address as much damage as possible through one universal policy, providing insights for future research on this topic.


\textbf{Transformer Models in Robotics}
Transformers have gained sufficient popularity in various domains, including natural language processing~\cite{vaswani2023attentionneed}, computer vision~\cite{dosovitskiy2021imageworth16x16words,qi2022high}, and are now being explored in robotic control due to their ability to model sequential dependencies and capture complex long-range relationships in data. Recent studies have also demonstrated the effectiveness of transformer-based architectures in the robotics field~\cite{chen2021decisiontransformerreinforcementlearning, kurin2021bodycagerolemorphology,gupta2022metamorphlearninguniversalcontrollers,hong2022structureaware, radosavovic2024humanoidlocomotiontokenprediction,wan2024vint}, and our work is inspired by one such recent study called BodyTransformer~\cite{sferrazza2024bodytransformerleveragingrobot}. However, due to distinct focuses, BodyTransformer performs terribly under various damaged scenarios, while our methods could significantly resolve such problems.