%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
%\usepackage{hyperref}
\usepackage[pagebackref=true,breaklinks,colorlinks,citecolor=blue,linkcolor=blue,urlcolor=blue,hypertexnames=false]{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{colortbl}%
\newcommand{\myrowcolour}{\rowcolor[gray]{0.925}}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

% self-introduced pkgs
\usepackage{paralist}
\usepackage{subcaption}  % 用于子图
\usepackage{caption} % 用于标题和子标题
\usepackage{mathptmx} % 更现代的 Times 字体包
\usepackage{enumitem}
\usepackage{algorithm}
%\usepackage{algpseudocode}
\usepackage{colortbl} % 需要这个包来给背景上色
\usepackage{xcolor} % 需要这个包来定义颜色
\usepackage[most]{tcolorbox} 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{UMC: Unified Resilient Controller for Legged Robots with Joint Malfunctions}

\begin{document}

\twocolumn[
\icmltitle{UMC: A Unified Approach for Resilient Control of Legged Robots Across
Masked Malfunction Training}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Yu Qiu}{scu}
\icmlauthor{Xin Lin}{scu}
\icmlauthor{Jingbo Wang}{shai}
\icmlauthor{Xiangtai Li}{ntu}
\icmlauthor{Lu Qi}{whu,insta360}
\icmlauthor{Ming-Hsuan Yang}{ucm}
\end{icmlauthorlist}

\icmlaffiliation{scu}{Sichuan University}
\icmlaffiliation{shai}{Shanghai AI Lab,}
\icmlaffiliation{ntu}{Nanyang Technological University}
\icmlaffiliation{insta360}{Insta360 Research}
\icmlaffiliation{whu}{Wuhan University}
\icmlaffiliation{ucm}{University of California, Merced}

\icmlcorrespondingauthor{Lu Qi}{qqlu1992@gmail.com}

% \begin{icmlauthorlist}
% \icmlauthor{Firstname1 Lastname1}{equal,yyy}
% \icmlauthor{Firstname2 Lastname2}{equal,yyy,comp}
% \icmlauthor{Firstname3 Lastname3}{comp}
% \icmlauthor{Firstname4 Lastname4}{sch}
% \icmlauthor{Firstname5 Lastname5}{yyy}
% \icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
% \icmlauthor{Firstname7 Lastname7}{comp}
% %\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
% %\icmlauthor{}{sch}
% %\icmlauthor{}{sch}
% \end{icmlauthorlist}

% \icmlaffiliation{yyy}{Department of XXX, University of YYY, Location, Country}
% \icmlaffiliation{comp}{Company Name, Location, Country}
% \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

% \icmlcorrespondingauthor{Firstname1 Lastname1}{first1.last1@xxx.edu}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Embodied AI, Deep Learning, Robotics, ICML}

\vskip 0.3in
]

\newcommand{\ql}[1]{\textcolor{cyan}{#1}}
\newcommand{\cm}[1]{\textcolor{red}{#1}}
\newcommand{\lx}[1]{\textcolor{green}{#1}}
\newcommand{\yq}[1]{\textcolor{blue}{#1}}

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
\printAffiliationsAndNotice{} % otherwise use the standard text.

\begin{abstract}
% The adaptability to joint damage is essential for legged robots operating autonomously in unpredictable environments such as search-and-rescue missions. However, few previous works specifically targeted the challenges of joint damage adaptation. And those existing approaches, such as multi-policy and meta-learning frameworks, often suffer from limitations such as high training costs, limited generalization across various damage types, complex maintenance, etc. 

% Existing works based on multi-policy or meta-learning frameworks for legged robots often struggle with robustness when operating autonomously in unpredictable environments. 
Adaptation to unpredictable damages is crucial for autonomous legged robots, yet existing methods based on multi-policy or meta-learning frameworks face challenges like limited generalization and complex maintenance. To address this issue, we first analyze and summarize eight different types of damage scenarios, including sensor failures and joint malfunctions. Then, we propose a novel, model-free, two-stage training framework, \textbf{U}nified \textbf{M}alfunction \textbf{C}ontroller (UMC), which incorporates a masking mechanism to enhance damage resilience. Specifically, the model is initially trained with normal environments to ensure robust performance under standard conditions. In the second stage, we use masks to prevent the legged robot from relying on malfunctioning limbs, enabling adaptive gait and movement adjustments upon malfunction. Experimental results demonstrate that our approach improves the task completion capability by an average of 36\% for the transformer and 39\% for the MLP across three locomotion tasks. The source code and trained models will be made available to the public.



% Inspired by the remarkable ability of humans and animals to adjust their movements and rely on unaffected joints to complete tasks despite partial impairments, we are here to introduce UMC, a \textbf{U}nified \textbf{M}alfunction \textbf{C}ontroller. UMC is a novel, model-free, two-stage training framework with a masking mechanism for enhanced damage resilience. 

% Initially, models are trained on normal data to ensure robust performance under standard conditions. We then proposed eight different damaged situations, such as sensor failures and motor malfunctions, and applied transfer learning to these models on this custom damage dataset. We utilized masks to prevent the legged robot from learning from damaged limbs and enable them to adjust their gaits and movements when malfunction happens. Experimental results show that our method improves task completion ability by an average of 36\% for the Transformer and 39\% for the MLP across the three locomotion tasks, with falling chances reduced to 5.36\% (a 30\% reduction) for the Transformer and 6.67\% (a 37\% reduction) for the MLP.
\end{abstract}


\section{Introduction}
\label{sec:intro}

\begin{figure*}[ht]
  \centering
  \includegraphics[width=0.95\linewidth]{imgs/teaser.pdf}
  \caption{Qualitative and Quantitative Comparison of Our UMC Framework with Baselines and a SOTA Method. 
  %This figure demonstrates the average performance of five different methods across Unitree-H1, Unitree-G1, and A1-Walk from Parkour~\cite{zhuang2023robot} tasks under eight damaged conditions. 
  `Trf' is the transformer, `NM' represents the baseline normal training (trained without damaged situations), and `UMC' is our method. `BodyTrf' is the abbreviation of BodyTransformer~\cite{sferrazza2024bodytransformerleveragingrobot}, also a baseline structure. `Failure Rate' refers to the proportion of robots that fall during their actions, and `3 Units Reached' refers to the percentage of robots that are still able to move a distance of 3 units after the added damage. (a) presents the qualitative comparison for the humanoid robot task, while (b) depicts it for the quadruped task. The last comparison set in (b) shows the qualitative comparison between our UMC framework and the SOTA method proposed in \cite{hou2024multitasklearningactivefaulttolerant}.}
  \label{fig:teaser}
  \vspace{-4mm}
\end{figure*}

% \begin{figure*}[ht]
%     \centering
%     \begin{minipage}[b]{0.7\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{imgs/teaser1.pdf}
%         \caption{11}
%         \label{fig:left_image}
%     \end{minipage}%
%     \hfill
%     \begin{minipage}[b]{0.3\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{imgs/teaser1.pdf}
%         \caption{22}
%         \label{fig:right_image}
%     \end{minipage}
% \end{figure*}


%\begin{figure}
%   \centering
%   \includegraphics[width=0.9\linewidth]{imgs/teaser2.pdf}
%   \caption{Comparison of overall performance for Transformer- and MLP-based structures. In this figure, we averaged the performance across three different robot locomotion tasks on five distance metrics (moving an additional 1 to 5 units) and one falling chance metric to assess the robot's post-damage mobility under five methods. (For the illustrations of abbreviations, please refer to \cref{fig:teaser1}}
%   \label{fig:teaser2}
% \end{figure}

% Part One BG
Legged robots have witnessed significant advancement due to their flexibility and adaptability in various scenarios. 
% With unique mobility, they navigate challenging environments effectively, resulting in them increasingly being deployed in diverse applications, such as search and rescue \cite{wensing2022optimizationbasedcontroldynamiclegged, Hutter2017ANYmalT, Bellicoso2018AdvancesIR}.
%Most current research focuses on network designs based on observational signals and self-states. However, these robots often struggle with robustness, particularly when issues arise in their joints or limbs. This is a critical problem, as human intervention might be impractical or even impossible in certain situations. For example, in disaster recovery, a search-and-rescue robot navigating through rubble could suffer joint malfunctions from debris, where external assistance would be unsafe or unfeasible. Thus, enhancing legged robots' capacity to manage such failures autonomously is essential for effective deployment in real-world applications.
%
Most current research focuses on the network design based on observational signals and self-states. 
%
However, they ignore robustness, particularly when their joints or limbs malfunction. 
%
This is a critical issue, as human intervention is impractical or even impossible in certain situations~\cite{Hutter2017ANYmalT, Bellicoso2018AdvancesIR, wensing2022optimizationbasedcontroldynamiclegged}. 
%
For example, in disaster recovery scenarios, a search-and-rescue robot navigating through rubble may experience joint failures caused by debris, making external assistance unsafe or impractical. 
%
Therefore, enhancing the performance of legged robots in such failures is essential for their effective deployment in real-world applications.

% In both animals and humans, the ability to adapt and compensate for joint or limb injuries is a remarkable survival mechanism~\cite{Cully_2015}. When a joint or limb becomes damaged, these beings can consciously avoid using the affected parts and rely on other, healthier parts of their bodies to accomplish tasks~\cite{Cully_2015}. For instance, if a human suffers an ankle injury, they might adjust their gait, using crutches or shifting weight to the uninjured leg. Similarly, many animals can modify their movement patterns to navigate obstacles or hunt, etc.

% As legged robots become increasingly integrated into diverse fields, such as search and rescue, they are exposed to a growing number of unpredictable factors, which can result in various kinds of joint, motor and other failures~\cite{Kaushik2010}. Hence, the challenge of maintaining optimal functionality becomes more apparent. In such situations, human intervention may be impractical or even impossible. For instance, in a disaster recovery scenario, a search-and-rescue robot navigating through rubble could experience joint malfunctions due to debris, where external assistance is not feasible for the sake of our own safety. Consequently, the ability for legged robots to autonomously manage these failures is essential in real-world applications.

Some studies address the problem above by employing multi-policy and data augmentation strategies~\cite{kume2017mapbasedmultipolicyreinforcementlearning, YangGANARL, hou2024multitasklearningactivefaulttolerant} or leveraging meta-learning approaches~\cite{nagabandi2019learningadaptdynamicrealworld, raileanu2020fastadaptationpolicydynamicsvalue, guo2023decentralizedmotorskilllearning, 10598356} to enable robots to adapt to specific situations.
%~\cite{nagabandi2019learningadaptdynamicrealworld, raileanu2020fastadaptationpolicydynamicsvalue, guo2023decentralizedmotorskilllearning} employ 
%data augmentation strategies, such as using predefined rules~\cite{kume2017mapbasedmultipolicyreinforcementlearning} or generative models~\cite{YangGANARL}, to simulate malfunction scenarios. These approaches often include designing separate modules or applying meta-learning~\cite{nagabandi2019learningadaptdynamicrealworld,raileanu2020fastadaptationpolicydynamicsvalue} to adjust trajectories~\cite{ChenFADM} for specific situations~\cite{guo2023decentralizedmotorskilllearning}. 
%
However, these methods raise concerns about their complex maintenance, generalization to various damaged conditions, and adaptability as well as performance in situations where conditions differ from the training environment. 
% \yq{[YQ: We could note our UMC's superiority in this in our proportion ablation(eg: We exclude sensor-failure damage in training set but the result shows that robots could still perform well given the sensor-failures)]}. 
%
In Figure~\ref{fig:teaser}(b), we show that existing methods that are trained in specific damage settings exhibit many failures on both the humanoid and the quadruped robot in more open-world test settings. 
% \yq{[YuQiu: Plz leave this comment here! Need to add the results of more baseline results!.]}

% \yq{Besides, the visual comparison in \cref{fig:teaser}(a) and (b) shows that normal, vanilla one-stage training methods exhibit a lot of falls in both the humanoid robot and the quadruped robot in consecutive frames, whereas our two-stage approach demonstrates strong robustness, with smooth and stable motion. 
%
% In \cref{fig:teaser}(c), the qualitative performance of the baseline architecture shows that robots trained under normal conditions alone fail to adapt their motion strategies when encountering damaged limbs, resulting in falling, instability, and immobility. 
%
% In contrast, robots trained with our \yq{\textbf{U}nified \textbf{M}alfunction \textbf{C}ontroller (UMC)} architecture are capable of detecting anomalous damage during operation and promptly adjusting their strategies to maintain steady progress. 
%

% The radar charts on the right demonstrate that our framework strongly enhances the robot's task success rate and completion. \textcolor{red}{YQ: Do we need to include the name UMC in this paragraph? Or just introduce the UMC concept in the following paragraph?}

%However, these methods still struggle to account for all possible unexpected scenarios like diverse damage types and degrees, resulting in suboptimal robustness and generalization for robotic systems.

% Several previous works have tried to tackle this problem, yet problems still exist in these methods. For instance, ~\cite{YangGANARL} employs GANs to simulate various joint damages, enhancing the training dataset for improved robustness. ~\cite{kume2017mapbasedmultipolicyreinforcementlearning} uses multiple policies to address diverse situations. ~\cite{ChenFADM} follows a Model Predictive Control (MPC) framework to optimize feasible actions to mitigate trajectory deviations caused by joint motor failures. ~\cite{guo2023decentralizedmotorskilllearning} allows for fault tolerance by grouping motors by different limbs, and set decentralized goals for each limb. Another notable perspective focuses on fast adaption to the new environment settings with meta-learning\cite{nagabandi2019learningadaptdynamicrealworld,raileanu2020fastadaptationpolicydynamicsvalue}.

% However, to sum up, these algorithms either fail to consider a wide variety of damage types and proposed a generalized solution, tremendously increase the demand for training data to cope with various malfunctions, or complicates maintenance due to potential conflicts among strategies. To be specific, ~\cite{guo2023decentralizedmotorskilllearning} did not test whether their functions still work when damage occurs on multiple limbs, and the cost for decentralization analysis and training would be high. In \cite{nagabandi2019learningadaptdynamicrealworld,raileanu2020fastadaptationpolicydynamicsvalue}, it is knotty to preemptively prepare datasets capturing diverse damage types and combinations across various joint combinations for meta-training to calculate different dynamics for each situation. Furthermore, we cannot ascertain whether methods \cite{nagabandi2019learningadaptdynamicrealworld,raileanu2020fastadaptationpolicydynamicsvalue} should both consider and include in the training set the situations where, for example, joint range of motion is restricted but exhibits varying joint postures when constrained. After all, when legged robots are in motion, it is uncertain when joint malfunctions may occur. Most importantly, in the case of a quadruped robot for instance, the difficulty of continuing to walk varies greatly between scenarios where a leg is stuck in an elevated position and when it is constrained in a normal downward-facing posture.


% Similarly, methods like ~\cite{YangGANARL} exhibit comparable limitations, with its experiments restricted to only two damage scenarios: (1) a complete inability to adjust joint angles, and (2) joints operating randomly. Furthermore, the approach in ~\cite{kume2017mapbasedmultipolicyreinforcementlearning} mandates training distinct policies to address a variety of environmental conditions. This requirement not only escalates training costs but also imposes a significant dependency on the controller’s capacity to regulate the model under dynamic real-world conditions adaptively. Therefore, in complex and realistic scenarios, accounting for both diverse damage types and varying degrees of severity remains crucial.

% Part Three Our Work (Remeber to delete-Dai Xiu Gai)
We formulate the problem of improving the robustness of diverse malfunctions in both data summarizing and pipeline designing. 
%
First, we systematically analyze multiple scenarios and categorize them into eight types, focusing on sensor-only failures, detectable joint damage, and undetectable joint damage. 
%
Each joint-damaged scenario includes tailored responses for specific impairments, such as restricted range of motion, reduced motor force, and limited linear velocity. 
%
Then, we propose a \textbf{U}nified \textbf{M}alfunction \textbf{C}ontroller (UMC), which is a simple but effective model-free approach employing a masking strategy to regularize the action network within two-stage training. 
%
% Model-free refers to a reinforcement learning approach that does not rely on a model of the environment’s dynamics but instead learns the optimal policy or value function directly through interaction with the environment. Furthermore, UMC can be applied generically to both Transformer-based and MLP-based architectures.
%It applies to both Transformer- and MLP-based architectures. 

% \yq{
Specifically, our UMC has a damage detection module and base structure that can generate joint-specific actions from original observation inputs representing each joint's position, velocity, and action information. 
%
The damage detection module receives the original observation input sequences and outputs two tensors, including a masked observation tensor that zeroes out the signals of the damaged joints from the original observation and a masking matrix among various joints.
%
The base structure includes a tokenizer, mask encoder, and detokenizer, where the tokenizer and detokenizer perform the transformation between the observation tensor and a sequence of action tokens.
%
% A three-bit damage detection sequence is then appended to the processed inputs before the tokenizer maps them into embeddings compatible with the transformer encoder. 
%
% The encoder extracts features from the embeddings, \cm{focusing solely on healthy joints}, and outputs an action feature, which the detokenizer processes to produce final action outputs for each joint. 
%
The mask encoder is flexible to both transformer and MLP modules. It teaches the robot to act without damaged joints' information.
%
Based on the above architecture, UMC is first pre-trained on normal scenarios and then fine-tuned using collected damage scenarios, ensuring robust behaviour in both normal and damaged conditions.
% With the masking mechanism, we adopt different strategies on diverse architectures. 
% We adopt different masking mechanism strategies on Transformer and MLP architecture, respectively.
% In the Transformer model, inputs—including base observation, joint observations, and fault signals—are tokenized and processed with \yq{two masking operations}. In the MLP model, the base observation for the faulty joint is directly masked by setting its value to zero, while the fault signal is explicitly set to one. 
%
% \cm{We also evaluated the feasibility of our UMC framework with an MLP-based architecture.}
%Some performance results are shown in Figure \ref{fig:teaser1}, which demonstrates the excellent generalization capability of our UMC.

% develop UMC, a \textbf{U}nified \textbf{M}alfunction \textbf{C}ontroller that is robust to diverse malfunctions and adaptable to various network designs. 
% To achieve this, we address the problem from both data and pipeline aspects. 
% First, we systematically analyze multiple scenarios and categorize them into eight types when collecting training data, with a focus on sensor-only failures, detectable joint damage, and undetectable joint damage. Each joint-damaged scenario includes tailored responses for specific impairments, such as restricted range of motion, reduced motor force, and limited linear velocity.

% Then, we propose a novel model-free approach employing a masking strategy to regularize the action network, which applies to both Transformer- and MLP-based architectures. Specifically, our method follows a two-stage pipeline: pretraining the network on complete, normal scenarios to ensure that robots learn effective behaviors under healthy conditions and then fine-tuning it on collected damage scenarios to enhance robustness. For the masking mechanism, we adopt different strategies on different architectures. In the Transformer model, inputs—including base observation, joint observations, and fault signals—are tokenized and processed with masked attention. In the MLP model, the base observation for the faulty joint is directly masked by setting its value to zero, while the fault signal is explicitly set to one.

% Although simple, as shown in \cref{fig:teaser1} and \cref{fig:teaser2}, our method demonstrates significant improvements across multiple tasks, including the H1 and G1 tasks of Unitree and the A1 walking task in Parkour. \cref{fig:teaser2} shows that our method improves task completion ability by 36\% for the Transformer and 39\% for the MLP, with falling chances reduced to 5.36\% (30\% reduction) for the Transformer and 6.67\% (37\% reduction) for the MLP. To the best of our knowledge, we are the first to employ a masking strategy in training to enhance the robustness of legged robots without requiring prior knowledge of joint or limb malfunctions during inference.

% In this paper, we draw inspiration from the inherent flexibility that animals and humans exhibit in responding to unexpected situations, presenting a novel model-free methodology that significantly increases a robot's chances of task completion despite experiencing various types of damage to multiple joints. To the best of our knowledge, our approach represents the first attempt to tackle the challenge of partial joint malfunctions in legged robots by combining systematic training with a mask mechanism tailored for fault scenarios. To be specific, we first pre-trained models on complete normal situations to ensure that robots are able to learn how to act under normal and healthy settings. Second, we developed a formula for constructing damaged training datasets. We then performed transfer learning by further training the pretrained model from the first step on this damaged dataset. We use the mask mechanism to prevent those malfunctioning DOFs to provide wrong information, and let robots learn to act with the rest ones. The damage dataset includes four distinct failure cases: 1) sensor failures, 2) joint malfunctions (where both sensors and joints experience malfunctions), 3) undetected joint malfunctions (where sensors provide normal observations but the joint is partially damaged), and 4) normal settings without damage. We compare our method on two different model architectures: a Multi-Layer Perceptron (MLP) and a Transformer-based model. Both models are designed to account for fault conditions through the use of masking mechanisms. In the Transformer model, different input groups (base observation, joint observations, and fault signals) are tokenized and processed with a masked attention mechanism to handle joint failures. The MLP model, on the other hand, directly masks the observation input corresponding to the faulty joint by setting its value to zero, while the fault signal is explicitly set to one. By incorporating these masking mechanisms, both models are able to learn effective policies that allow robots to adapt to various joint failures during task execution.

Compared to baselines, our approach reduces the average fail rates by 30\% and 37\% with the base structure of the transformer and the MLP on three locomotion tasks, as shown in \cref{fig:teaser}(c). Furthermore, \cref{tab:sotacomp} demonstrates that our method achieves a 26.8\% improvement in overall task completion rate compared to a state-of-the-art (SOTA) approach in~\cite{hou2024multitasklearningactivefaulttolerant}. Those extensive experiments show the effectiveness and robustness of our UMC framework. 
% \cm{[YQ: Do we need textbf for the statistics?]}


The main contributions of our work are:

\begin{compactitem}
    \item We systematically classify eight distinct failure scenarios, focusing primarily on sensor-only failures, detectable joint damage, and undetectable joint damage. For each scenario involving joint damage, we provide a detailed analysis of the corresponding tailored responses to specific impairments, such as restricted range of motion, reduced motor force, and limited linear velocity.
    
    \item We propose a UMC framework, a two-stage training pipeline that integrates standard pretraining on normal data with fine-tuning on custom damage training environments. The UMC incorporates a masking mechanism to address joint malfunctions and is compatible with both transformer-based and MLP-based action networks.
    
    \item Extensive experiments across three tasks demonstrate the robustness of our method under all eight damage conditions. Furthermore, our approach does not require prior knowledge of joint or limb malfunctions during inference, ensuring its strong adaptability in real-world applications. 
    % \yq{YQ: During inference, the same damaged joint combinations will inevitably appear (like joint 2,4 damaged in both inference and training stage, but the whole set is different). Also during training, all damage are added to one joint, yet during inference, one damage is added to one joint at one time. Can we still say that we \textcolor{red}{does not require prior knowledge} here?} 
\end{compactitem}

% 1)  \textbf{A Novel Two-Stage Training Framework with Mask Mechanism}. 

% 2)  \textbf{Malfunction Designs}. To address various damage types that legged robots might encounter, we analyzed and proposed eight distinct scenarios, focusing on cases of sensor-only failure, detectable joint damage, and undetectable joint damage. Each joint-damaged scenario includes tailored responses for different joint impairments, such as restricted range of motion, reduced motor force, and limited linear velocity.

% 3) \textbf{Comparative Evaluation and Malfunction Designs}. We proposed a novel metric to effectively evaluate task performance, using it to analyze the performance of different methods on Unitree H1, G1 tasks, and Parkour A1-Walk~\cite{zhuang2023robot} tasks. We also conduct our method on two structures: MLP and Transformer. Experiment results show that our method outperforms both standard training and BodyTransformer~\cite{sferrazza2024bodytransformerleveragingrobot}, a state-of-the-art model, across all eight damage conditions.

\vspace{-2mm}
\section{Related Work}
\label{sec:relworks}

\textbf{Reinforcement Learning in Legged Robots.}
In recent years, reinforcement learning (RL) has gained traction in legged robots' control and locomotion tasks~\cite{strudel2020learningcombineprimitiveskills, tang2020learningagilelocomotionadversarial}. Some deep-learning-based RL methods are proposed to improve quadrupedal robots' stability across diverse terrains through combined simulated and real-world training~\cite{A2022ReinforcementLB}. In this work, we utilize the Proximal Policy Optimization (PPO) algorithm provided by Legged Gym for RL-based control of legged robots. Our approach focuses on enhancing locomotion control by reconstructing the Actor model, improving performance in complex environments.

\begin{figure*}
  \centering
  \includegraphics[width=0.95\linewidth]{imgs/workflow.pdf}
  \vspace{-2mm}
  \caption{UMC system for transformer-based Actor-Model Architecture. \( K \) is the number of encoder layers. For more details of the architecture, please refer to \cref{sec:umcframework}.}
  \vspace{-5mm}
  \label{fig:trf_model}
\end{figure*}


\textbf{Self-recovering Robots.}
In recent years, self-recovering robots have attracted significant interest in robotics research~\cite{1044017, Guan2015FaultSF, 9249654}. As robotics technology matures, enabling legged robots to adapt to joint damage has become increasingly critical. However, few studies address this directly, and existing approaches often lack generalization, require excessive training data, or complex maintenance with conflicting strategies~\cite{kume2017mapbasedmultipolicyreinforcementlearning, nagabandi2019learningadaptdynamicrealworld, raileanu2020fastadaptationpolicydynamicsvalue, YangGANARL, ChenFADM, guo2023decentralizedmotorskilllearning}. Therefore, we aim to address as much damage as possible through one universal policy, providing insights for future research on this topic.


\textbf{Transformer Models in Robotics}
Transformers have gained sufficient popularity in various domains, including natural language processing~\cite{vaswani2023attentionneed}, computer vision~\cite{dosovitskiy2021imageworth16x16words,qi2022high}, and are now being explored in robotic control due to their ability to model sequential dependencies and capture complex long-range relationships in data. Recent studies have also demonstrated the effectiveness of transformer-based architectures in the robotics field~\cite{chen2021decisiontransformerreinforcementlearning, kurin2021bodycagerolemorphology,gupta2022metamorphlearninguniversalcontrollers,hong2022structureaware, radosavovic2024humanoidlocomotiontokenprediction,wan2024vint}, and our work is inspired by one such recent study called BodyTransformer~\cite{sferrazza2024bodytransformerleveragingrobot}. However, due to distinct focuses, BodyTransformer performs terribly under various damaged scenarios, while our methods could significantly resolve such problems.



\section{Method}
\label{sec:methods}

\begin{table}[t]
    \caption{Eight Damage Scenarios for Legged Robots. For `Sensor Status', `Damaged' means that the sensors cannot return correct observation readings, and `Functional' means that the sensors are well-functioned. `ROM' is the abbreviation of `range of motion'.}
    \vspace{-2mm}
    \centering
    \footnotesize
    \begin{tabular}{ccc}
        \toprule
        \textbf{Scenario} & \textbf{Sensor Status} & \textbf{Joint Damage Type} \\
        \midrule
        1 & Damaged & None \\
        2 & Damaged & ROM Restriction \\
        3 & Damaged & Reduced Motor Force \\
        4 & Damaged & Limited Linear Velocity \\
        5 & Functional & ROM Restriction \\
        6 & Functional & Reduced Motor Force \\
        7 & Functional & Limited Linear Velocity \\
        8 & Functional & None \\
        \bottomrule
    \end{tabular}
    \vspace{-6mm}
    \label{tab:damage_scenarios}
\end{table}

% \cm{Here, we only illustrate the framework. Actually, we should include both setting and framework.}
%
We aim to design a unified policy that enables the robot to complete tasks within various damage conditions.
%
We explore the robustness of legged robots by systematically analyzing various damage factors and proposing a unified malfunction controller (UMC) to address them.
%
First, we thoroughly summarize eight types of malfunctions given the reliability of sensors and joints. 
%
Sensors provide feedback on the robot's internal state through three key information inputs: position, velocity, and force of joint action. 
%
Sensor damage refers to blockage of only these inputs, whereas joint damage indicates a failure in the functionality of an actual joint.
%
On the other hand, damage related to the joint can be divided into a restricted range of motion, reduced motor force, and limited linear velocity. 
%
More details will be introduced in \cref{sec:mal}.
% \ql{The UMC.}
% In this work, we introduced UMC, a \textbf{U}nified \textbf{M}alfunction \textbf{C}ontroller.
%

For the method, our proposed UMC is a model-free system that is highly robust to various damage factors within a unified framework. 
%
Specifically, our design adopts a two-stage training pipeline with a masking mechanism and is compatible with both the transformer and the MLP structure.
% While previous studies have failed to propose an algorithm robust enough to handle various types of damage effectively, we leverage the mask mechanism combined with our proposed two-stage training approach to enable legged robots, particularly in walking tasks, to perform tremendously better under diverse damage conditions. 
%
The masking mechanism used during training ensures that the network automatically ignores anomalous signals, allowing the trained policy to adapt to multiple types of damage. 
%
Meanwhile, the two-stage training pipeline retains the network’s ability to handle standard scenarios effectively.
% Our work represents the first attempt to solve such problems with a mask mechanism. Using a two-stage framework, we evaluate our method on two widely used structures: MLP and Transformer. 
%
% \ql{Whereas, the two-stage training .}
%
% First, we train the models on a completely normal dataset to ensure that they can perform well in normal situations (with no damage).
%
% Next, we developed a malfunction dataset which consists of various situations of damage, different combinations of the malfunctioning joints, and normal settings. 
%
% Then, we apply transfer learning on the malfunction dataset by utilizing the models trained in the first stage under normal conditions. 
%
% During the second stage, we mask the inputs corresponding to the damaged parts in the second malfunction dataset, enabling the models to learn how to complete tasks using the remaining functional limbs.

In the following subsections, we first systematically analyze the various damage factors. 
%
Then, we will introduce the design of the UMC system, including the baseline framework, masking mechanism, and two-stage training pipeline.

% \begin{figure}
%   \centering
%   \includegraphics[width=1.0\linewidth]{imgs/mlp_structure.pdf}
%   \caption{UMC Framework for MLP-based Actor-Model Architecture.}
%   \label{fig:mlp_structure}
% \end{figure}

% \subsection{Malfunction Settings}
% \label{sec:mal}
% \cm{QL: Please decrease most of the sentences. For the three types, they are combinations of sensors and actors (01, 10, 11). From my side, you can use a table to list the eight types alongside the damaged type of actors. And then, just introduce the three types of joint damage with short sentences.}

% Since extensive prior research has focused on self-diagnose\cite{Guan2015FaultSF,quamar2024reviewfaultdiagnosisfaulttolerant}, we concentrate on proposing and conceptualizing various damage types and devising methods to address them. 
% %
% For a figure demonstration of these damages, please refer to the Appendix. 
% %
% Here, we aim to consider as many types of potential damage that legged robots might encounter as possible:

% i) We considered cases where only the sensor is damaged, while the corresponding joint itself remains intact. 
% %
% This scenario represents cases where the joint functions normally but fails to return data to the central controller due to sensor failure. 
% %
% For such cases, the observation input of the affected joint should be reset back to a default value of zero due to no detected signals.

% ii) We addressed scenarios where the joint is damaged and the damage is detectable. 
% %
% Here, we maintain the observation input of the affected joint as a default zero. 
% %
% This is because when the joint is damaged, its sensor is similarly likely to fail and only shows default zero due to no signal being detected and transmitted.
% %
% Moreover, there is no guarantee that even if these sensors are currently available, the data transmitted by them would be accurate and unaffected~\cite{quamar2024reviewfaultdiagnosisfaulttolerant}, or could always be available during the joint damage. 
% %
% Therefore, we assume a worst-case scenario where, whenever damage is detected, the system resets the observation input value for the corresponding joint to the default zero. 
% %
% We also considered three joint damage types, which will be discussed later.

% iii) We also considered extreme conditions where the joint is damaged but the damage is undetectable. In such instances, since the damage is not detected, the sensor must still be capable of transmitting accurate data (otherwise, anomalies or damage could be inferred from the sensor input\cite{signalfault,quamar2024reviewfaultdiagnosisfaulttolerant}). For these cases, we allow the sensor to continue transmitting accurate data and similarly account for three types of joint damage.

% Next, we detail the three categories of joint damage we considered:

% i) \textbf{Range of motion restriction}: This is the most common and intuitive type of damage. For example, during robot operation, a joint might get influenced by external or internal factors, and would either passively or actively limit its range of movement to a narrow range.

% ii) \textbf{Reduced joint motor force output}: This is also a common damage situation, might occur when the motor wears or suffers physical damages, which in turn affects its ability to generate force.

% iii) \textbf{Limited joint linear velocity}: In this scenario, the robot's movement may be impaired due to an inability to coordinate postures effectively, preventing proper locomotion. This might happen since prolonged operation can lead to excessive heat buildup in the motors or electronic components, activating thermal protection mechanisms that limit the joint speed to prevent overheating and potential damage.

% In summary, we have considered a total of eight damage scenarios, including the normal condition. These scenarios are:

% i) Only sensor damage; ii) Joint damage (range of motion restriction) with sensor failure; iii) Joint damage (reduced motor force) with sensor failure; iv) Joint damage (limited linear velocity) with sensor failure; v) Joint damage (range of motion restriction) with functioning sensor; vi) Joint damage (reduced motor force) with functioning sensor; vii) Joint damage (limited linear velocity) with functioning sensor; viii) Normal condition.

% We will further explain how to address and manage these scenarios in the following parts of this section.

\subsection{Malfunction Settings}
\label{sec:mal}

Compared to previous works that focused on self-diagnosis~\cite{Guan2015FaultSF,quamar2024reviewfaultdiagnosisfaulttolerant} or only tested limited damage types~\cite{YangGANARL}, we allow for as many different damage scenarios as possible, reflecting a wider range of real-world conditions, as shown in Table~\ref{tab:damage_scenarios}. 
%
% For the sensor, we only consider two kinds of status, including `Damaged' and `Functional'.  The `Damaged' means that the sensors cannot return correct observation readings due to a malfunction and will only return 0. `Functional' means that the sensors are well-functioning and can return correct observation readings.
For the sensor, we consider two kinds of statuses: `Damaged' and `Functional'.
%
The `Damaged' status indicates that the sensor cannot provide correct observation readings due to a malfunction and will only return a value of 0.
%
The `Functional' status indicates that the sensor operates correctly and can return accurate observation readings.

%
Furthermore, we have three categories of joint damage: range of motion restriction, reduced motor force, and limited linear velocity.
%
The range of motion restriction refers to the situation in which the joint's range of movement is limited due to external or internal factors. 
%
The reduced motor force occurs when the motor force output decreases due to wear or physical damage.
%
The limited linear velocity occurs when the joint speed is restricted, often triggered by overheating and thermal protection mechanisms.
% we \ql{enumerate} potential damages of legged robots.



% As shown in \cref{tab:damage_scenarios}, we consider three joint damage types:

% 1. \textbf{ROM (Range of Motion) Restriction}: The joint's movement range is limited due to external or internal factors.
% 2. \textbf{Reduced Motor Force Output}: The motor's force output decreases due to wear or physical damage.
% 3. \textbf{Limited Joint Linear Velocity}: The joint speed is restricted, often triggered by overheating and thermal protection mechanisms.

For more details about our malfunction setting, please check our Appendix.
% \yq{Yu Qiu: Appendix needs refinement!}

% We will further explain how to address and manage these scenarios in the following parts of this section.




\subsection{UMC Framework}
\label{sec:umcframework}
Given the original joint observation inputs \( O = \{o_1, \dots, o_N\} \in 
\mathbb{R}^{N \times 3} \) that represent the position, velocity, and action information for the $N$ single degree-of-freedom (DOF) joints, we aim to output the next action instruction $A \in \mathbb{R}^{N \times 1}$ for each joint.
%
Then, $A$ is converted into a torque sequence which is applied as forces to each corresponding joint (DOF). 
%
This allows the robot to execute its next movement.
%
Since each joint has a single DOF, its position can be fully represented by a single scalar value, inherently making the position component one-dimensional.
%

Our UMC controller employs an actor-critic framework, a standard reinforcement learning strategy, for training.
% based on the Proximal Policy Optimization (PPO) algorithm \cite{schulman2017proximalpolicyoptimizationalgorithms}. 
% PPO is a widely used reinforcement learning algorithm that updates the policy in a stable and efficient manner by clipping policy updates within a trust region. 
% The total loss function in PPO is defined as:
% \begin{equation}
% \mathcal{L} = \mathcal{L}_{\text{surrogate}} + \lambda_{1} \cdot \mathcal{L}_{\text{value}} + \lambda_{2} \cdot \mathcal{L}_{\text{entropy}},
% \end{equation}
% where $\lambda_{1}$ and $\lambda_{2}$ denote weight parameters. \(\mathcal{L}_{\text{surrogate}}\) is illustrated in \cref{eq:surrogate}, \(\mathcal{L}_{\text{value}}\) is illustrated in \cref{eq:value}, and \(\mathcal{L}_{\text{entropy}}\) is an entropy regularization to encourage exploration. Gradient clipping is also applied to ensure stability during training.
%
As shown in \cref{fig:trf_model}, the actor model takes \( O \) as input and outputs \( A \), representing the robot's next action. 
%
The critic strategy, which has the same base architecture as the actor, evaluates action behaviour using proximal policy optimization (PPO). 
%
During inference, we only use the actor model to output a series of actions.
%
% \cm{Compar}
In our work, we focus on the actor model, leaving the critic strategy unchanged. This is because the critic needs to operate from a global perspective to accurately evaluate the actor's actions, so it will receive correct sensor signal values and does not require any mask-related modules.

% but excludes masking and damage detection mechanisms \cm{[QL: What's the damage detection?] 
 % [Yu: Will]}. 

% \cm{Add a pa}

% In the following subsections, we will introduce the actor model, which integrates a masking mechanism with two-stage training, followed by a brief description of the critic strategy. For clarity, we use the transformer structure as the baseline design of our actor model and subsequently explain how to modify it into an MLP structure.

\subsubsection{Actor Model}
\label{sec:actormodel}
%
For clarity, we consider the transformer structure as our base design for the UMC framework. We note in \cref{sec:MLPUMC} that UMC can be easily extended to the pure MLP network.

For the actor model, as shown in \cref{fig:trf_model}, we have a damage detection module and a base structure.
%
The damage detection module ensures that information from damaged joints does not interfere with that from functional joints.
%
The base structure consists of three main components: a tokenizer, a mask encoder, and a detokenizer. 
% \yq{This setting is similarly adopted by BodyTransformer\cite{sferrazza2024bodytransformerleveragingrobot}.}
%
% The tokenizer and \ql{detokenizer} conduct transformation between \ql{joint observation} and a sequence of tokens. \cm{[QL: ????]} 
The tokenizer and detokenizer perform the transformation between the joint observation, a sequence of tokens and the action sequence, enabling seamless encoding and decoding processes.
%
Our core contribution lies in the design of a mask encoder along with mask strategy in two-stage training.
%
This design can capture dependencies and refine input representations using only the embeddings of well-functioning joints.
% \yq{YuQiu: For this red sentence, is it OK to say that our core contribution lies in the encoder? Because, actually, we almost have changed nothing to this encoder, the whole usage and two-stage training should be the core}.
%
% Finally, the detokenizer maps the refined joint representations back to the action space.}


\noindent \textbf{Damage Detection Module.}
At first, \( O \) would be processed by \( \Gamma \), a damage detection module, to generate some information used in the base structure.
%
% As shown in \cref{eq:dmgdetect}, \( \Gamma \) identifies joint failures of \( O \) and applies two mask operations: one to eliminate the observation of damaged joints, transforming \( O \) into \( O' \), and another to encode the information of the failure into a masking matrix \(M  \in \mathbb{R}^{(N+1) \times (N+1)}\), which is used in the attention mechanism during training. 
As shown in \cref{eq:dmgdetect}, \( \Gamma \) identifies joint failures in \( O \) and outputs two masking-related sequences.
%
\begin{equation}
V, M = \Gamma(O).
\label{eq:dmgdetect}
\end{equation}
%
The first output \( V  = \{v_1, \dots, v_N\} \in 
\mathbb{R}^{N \times 3} \) is transformed from \( O \) with its damaged joints being masked. 
%
Specifically, these damaged joints' observation inputs are zeroed out in \( O \) to effectively block its influence during all the following processes. 
%
For example, the $o_1$ in $O$ would be changed to zero vector and becomes $v_1$ if the first joint is damaged.
%
The second output \( M \in \mathbb{R}^{(N+1) \times (N+1)} \) is a masking matrix that encodes the failure information, which is added to the attention mechanism during training. 
%
Specifically, \( \Gamma \) sets all the positions corresponding to the damaged joints in \( M \) from zero to \( -\infty \). 
%
More details of \( M \) are delineated in \cref{sec:maskstrategy}.
%
% \cm{[QL: do not understand the dimension consistency.]}
%
% Moreover, an additional set of three bits \( F \in \{-1, 1\}^{1 \times 3} \) is appended to the original joint observation inputs \( O' \), indicating \yq{whether} potential malfunctions or irregularities in the robot's joints have been identified. 


\noindent \textbf{Base Structure.}
% The Transformer model's architecture is modified primarily in its observation tokenizer, as illustrated in \cref{fig:trf_model}. 
%
Our base structure follows a vanilla transformer design with a tokenizer, detokenizer, and mask encoder which consists of several stacked attention blocks.
%
% At first, \( O \) would be processed by \( \Gamma \), a damage detection module. 
%
% As shown in \cref{eq:dmgdetect}, \( \Gamma \) identifies joint malfunctions from \( O \) and applies two mask operations: one to eliminate the observation of damaged joints, transforming \( O \) into \( O' \), and another to encode the information of the malfunction into a masking matrix \(M  \in \mathbb{R}^{(N+1) \times (N+1)}\), which is used in the attention mechanism during training. 
Based on $V$, an additional sequence \( F \in \{-1, 1\}^{1 \times 3} \) is concatenated, forming the input of the tokenizer \( O'  \in \mathbb{R}^{(N+1) \times 3} \).
%
$F$ indicates whether potential malfunctions or irregularities in the robot's joints (not sensors) have been identified.
%
To ensure robustness, the dim of $F$ is three instead of one to prevent a single point of failure from causing complete system errors.
%
Once a joint malfunction is detected, the values in \( F\) would change from all -1 to all 1.
%
% Details of this process will be later delineated in the `Masking Strategy' paragraph. 

The \( O'\) is then processed by a tokenizer \( \Phi \), producing the joint embedding $E \in \mathbb{R}^{(N+1) \times D}$, where \( D\) is the embedding dimension.
%
\( \Phi \) applies projection and positional encoding operations for each joint, transforming \( O' \) into a format that corresponds to the input requirements of the mask encoder. 
%
Specifically, the projection operation consists of a set of linear layers, each of which maps an element in  \( O' \) into a higher-dimensional embedding space, while positional encoding uses a learnable embedding layer to encode each joint's position in the sequence.
%
Besides, this projection operation also ensures that the output embeddings corresponding to individual joints remain disentangled, preventing further interference between the joints and allowing flexible adaptation during masking.
\begin{equation}
E = \Phi(O').
\end{equation}


% Each joint's observation input and the damage signal bits are independently mapped into unique embedding sequences of dimension $d$, resulting in a transformed tensor $E \in \mathbb{R}^{(N+1) \times d}$. 
%


$E$ is then passed through a mask encoder $\Omega$. $\Omega$ consists of several stacked attention blocks where each block has a multi-head self-attention and feed-forward network module.
\begin{equation}
R = \Omega(E),
\end{equation}
where $R \in \mathbb{R}^{(N+1) \times D}$.
%

% \cm{[QL: Please explain why (N+1) $->$ N. What's this process?]} The number of the sequences is reduced from \( (N+1) \) to \( N \) because the additional dimension for damage signals is only used for context and is excluded from the final action-related process.
%

Finally, the action feature $R$ is processed by the detokenizer $\Theta$. $\Theta$ is a mapping layer designed to project \( R \) back to the action space. 
%
It consists of a set of linear layers, each corresponding to a specific joint. These layers independently map the feature representation of each joint in $R$ to the respective action outputs, yielding the final action sequence $A \in \mathbb{R}^{N \times 1}$. 
%
The number of the sequences is reduced from \( (N+1) \) to \( N \) because the additional dimension for the damage detection signals is only used for context during \( \Omega \) and is thus excluded from the final action-related process \(\Theta\).
\begin{equation}
A = \Theta(R).
\end{equation}
%
% \noindent \textbf{Masking Strategy.}
\subsubsection{Masking Strategy}
\label{sec:maskstrategy}
% \textcolor{red}{YQ: This section I want to detail the process of the second masking operation in \( \Gamma\). Will it be better to put this section into the \( \Gamma\) paragraph?}

We add \( M \in \mathbb{R}^{(N+1) \times (N+1)} \) into the self-attention module of the attention block, where $N$ is the number of joint observation embeddings in \( E\), and the addition one refers to the damage detection embedding in \( E\).
% \cm{YQ: Need to adjust my statement? Umm, I somehow feel a little bit weird here but I just do not know how to fix it.}
%
This masking operation ensures that, after the softmax operation, the attention weights for the damaged joints become negligible, thereby excluding them from further contribution during the attention calculation. 
%
For example, the first attention block could be written as a formula below:
%
\begin{equation}
Output = \text{Softmax}\left(\frac{\mathbf{Q(E)} \mathbf{K(E)}^T}{\sqrt{d_k}} + M\right) \mathbf{V(E)},
\label{eq:attention}
\end{equation}
where \( \mathbf{Q(E)} \), \( \mathbf{K(E)} \), and \( \mathbf{V(E)} \) are the query, key, and value matrices derived from \( E \), and \( d_k \) is the dimensionality of the \( \mathbf{Q(E)} \) and \( \mathbf{K(E)} \).
%
The masking matrix \( M \) serves to block the positions corresponding to malfunctioning joints.




% 
% Furthermore, the spatial relationships between connected joints are preserved through parameter sharing in their embedding layers. \cm{[QL: Please explain this. Do not understand. What's the relationship to masking strategy?]} This design enables spatially adjacent joints to share information effectively, even in the presence of masked inputs. Consequently, the Transformer model dynamically adapts its control strategy by leveraging information from undamaged joints, ensuring robust and flexible behaviour under varying conditions.

\noindent \textbf{Training Loss.}
The training loss consists of both actor and critic losses. Additionally, an entropy regularization term is included to promote exploration. This term encourages the agent to maintain a diverse set of actions and avoid premature convergence to suboptimal policies. Together, these components guide the optimization of both the policy and value functions.


The total loss function in PPO is defined as:
\begin{equation}
\mathbb{L} = \mathbb{L}_{\text{surrogate}} + \lambda_{1} \cdot \mathbb{L}_{\text{value}} + \lambda_{2} \cdot \mathbb{L}_{\text{entropy}},
\end{equation}
where $\lambda_{1}$ and $\lambda_{2}$ denote weight parameters. The $\mathbb{L}_{\text{surrogate}}$, $\mathbb{L}_{\text{value}}$ and $\mathbb{L}_{\text{entropy}}$ are the loss of policy surrogate, value function, and entropy regularization, respectively.

Please refer to our appendix for more details of those losses that are not the key points of our work.
%

% \paragraph{Training Loss}
% \ql{In our training loss, we have two parts including actor loss and other losses brought by critic strategy.} 
% \cm{[QL: I think we can merge actor loss and critic strategy. Please merge them in this subsection.]}

% \paragraph{Actor Loss}  
% The actor model is trained using the clipped surrogate loss, which ensures that the updated policy does not deviate too much from the old policy:
% \begin{equation}
% \mathcal{L}_{\text{surrogate}} = -\mathbb{E}_t \left[\min\left(r_t \cdot A_t, \text{clip}(r_t, 1-\epsilon, 1+\epsilon) \cdot A_t \right)\right],
% \label{eq:surrogate}
% \end{equation}
% where \(t\) is timestep index within a trajectory. \( r_t = \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{\text{old}}}(a_t|s_t)} \) is the probability ratio between the new policy \( \pi_\theta \) and the old policy \( \pi_{\theta_{\text{old}}} \), \( \epsilon \) is the clipping parameter to limit updates, and \( A_t \) is the advantage estimate, which is computed as:
% \begin{equation}
% A_t = \sum_{k=0}^{\infty} (\gamma \lambda)^k \delta_{t+k},
% \label{eq:advantage}
% \end{equation}
% where $\gamma$ is the discount factor, $\lambda$ is the Generalized Advantage Estimation parameter, and $\delta_t = r_t + \gamma V(s_{t+1}) - V(s_t)$ is the temporal difference residual, with $r_t$ as the immediate reward, $V(s_t)$ as the value function at state $s_t$, and $V(s_{t+1})$ as the value at the next state $s_{t+1}$.

% \subsubsection{Critic Strategy}
% The Critic model shares its fundamental architecture with the Actor model, excluding the masking mechanism and damage detection signals, ensuring that it objectively reflects the environment's true state.

% \paragraph{Value Function Loss}  
% The critic model is trained using the value function loss, which minimizes the error between the predicted value \( V(s_t) \) and the target return \( R_t \):
% \begin{equation}
% \begin{split}
% \mathcal{L}_{\text{value}} = \mathbb{E}_t \big[ & \max\big((V(s_t) - R_t)^2, \\
% & \text{clip}(V(s_t), V_{\text{old}}(s_t) - \epsilon, V_{\text{old}}(s_t) + \epsilon) - R_t)^2\big)\big],
% \end{split}
% \label{eq:value}
% \end{equation}
% where \( V_{\text{old}}(s_t) \) is the value function from the previous iteration, and \( \epsilon \) is the clipping threshold to stabilize training.



% \ql{\subsubsection{Critic Strategy}}
% In this work, we use \textbf{Proximal Policy Optimization (PPO)} \cite{schulman2017proximalpolicyoptimizationalgorithms}, a widely used reinforcement learning algorithm, to optimize the robot control policy. PPO is designed to update the policy in a stable and efficient manner by clipping policy updates within a trust region. The total loss function consists of three main components, and all the hyperparameters follow the default settings of the \textbf{Parkour Gym}\cite{zhuang2023robot}:

% \paragraph{Clipped Surrogate Loss}  
% The clipped surrogate loss ensures that the updated policy does not deviate too much from the old policy. It is defined as:
% \begin{equation}
% \mathcal{L}_{\text{clip}} = -\mathbb{E}_t \left[\min\left(r_t \cdot A_t, \text{clip}(r_t, 1-\epsilon, 1+\epsilon) \cdot A_t \right)\right],
% \label{eq:clipped_objective}
% \end{equation}
% where $r_t = \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{\text{old}}}(a_t|s_t)}$ is the probability ratio between the new policy $\pi_\theta$ and the old policy $\pi_{\theta_{\text{old}}}$, $\epsilon$ is the clipping parameter to limit updates, and $A_t$ is the advantage estimate, which is computed as:
% \begin{equation}
% A_t = \sum_{k=0}^{\infty} (\gamma \lambda)^k \delta_{t+k},
% \label{eq:advantage}
% \end{equation}
% where $\gamma$ is the discount factor, $\lambda$ is the Generalized Advantage Estimation parameter, and $\delta_t = r_t + \gamma V(s_{t+1}) - V(s_t)$ is the temporal difference residual, with $r_t$ as the immediate reward, $V(s_t)$ as the value function at state $s_t$, and $V(s_{t+1})$ as the value at the next state $s_{t+1}$.

% \paragraph{Value Function Loss}  
% The value function loss minimizes the error between the predicted value $V(s_t)$ and the target return $R_t$:
% \begin{equation}
% \begin{split}
% \mathcal{L}_{\text{value}} = \mathbb{E}_t \big[ & \max\big((V(s_t) - R_t)^2, \\
% & \text{clip}(V(s_t), V_{\text{old}}(s_t) - \epsilon, V_{\text{old}}(s_t) + \epsilon) - R_t)^2\big)\big],
% \end{split}
% \end{equation}
% where $R_t$ is the cumulative return, $V_{\text{old}}(s_t)$ is the value function from the previous iteration, and $\epsilon$ is the clipping threshold to stabilize training.

% \paragraph{Entropy Regularization}  
% To encourage exploration, an entropy regularization term is added:
% \begin{equation}
% \mathcal{L}_{\text{entropy}} = -\mathbb{E}_t [\mathcal{H}(\pi(s_t))],
% \end{equation}
% where $\mathcal{H}(\pi(s_t))$ is the entropy of the policy distribution $\pi(s_t)$, and $\pi(a|s_t)$ is the probability of taking action $a$ in state $s_t$.

% \paragraph{Total Loss Function}  
% The overall loss function is a weighted sum of the above components:
% \begin{equation}
% \mathcal{L} = \mathcal{L}_{\text{clip}} + \lambda_{1} \cdot \mathcal{L}_{\text{value}} + \lambda_{2} \cdot \mathcal{L}_{\text{entropy}},
% \end{equation}
% where $\lambda_{1}$ and $\lambda_{2}$ denote weight parameters. Gradient clipping is also applied to ensure stability during training.


% \subsection{Two-Stage Training}
% \label{sec:twostage}

% In real-world applications, legged robots primarily operate under normal conditions, so it is essential to ensure they can perform tasks effectively in such scenarios. Therefore, in Stage I, we create a dataset comprising only normal operating conditions to train the model, ensuring it could at least accomplish tasks smoothly under these circumstances.

% In the Stage II, the goal is to equip the model with the ability to complete tasks under various failure conditions while retaining the capability it acquired in the first stage to operate in normal conditions. To achieve this, the training dataset for the second stage is divided into the following subcategories (we will not elaborate on the details of the damage types and conditions here, as they have already been discussed in \cref{sec:mal}):

% i) \textbf{Normal, undamaged conditions}. In this subcategory, the robot is not subjected to any damage conditions. This ensures that while learning to cope with damaged states, the legged robot does not forget how to walk and complete tasks under normal, damage-free conditions.

% ii) \textbf{Detectable joint damage}. In this subcategory, we train the legged robot to use its undamaged limbs for task completion despite partial limb damage. Additionally, the damage will be detected and fed back to the model as signals. For the MLP structure, as shown in \cref{fig:mlp_structure}, we add a three-bit damage signal at the end of the input observations, where all bits are set to 1 to indicate detected damage in any joint (default is all -1). For the Transformer one, as shown in \cref{fig:trf_model}, we utilize the tokenizer to map each input signal into a unique embedding sequence, which is then passed to the encoder for subsequent attention operations. 

% Then, we consider all three types of damage in this subcategory and apply them in combination to randomly selected joints. After these damages are applied, the sensory inputs of these damaged joints are set to zero to reflect the failure accurately (the rationale for such resetting is discussed in \cref{sec:mal}). There are two reasons why we apply all the damages together to one environment. First, whatever the damage is, we will apply masks to the corresponding joints (the rationale for masks is discussed in \cref{sec:umcframework}). The robot only needs to learn how to use its remaining functional joints to complete tasks instead of worrying about the specifics of damaged joints. This approach ensures that each agent is effectively trained to handle all three types of damage. Moreover, given hardware constraints preventing the creation of a large dataset, applying those damage types separately would mean sacrificing the ability to cover a broader range of joint combinations. Furthermore, our subsequent experiments confirm the effectiveness of this strategy in addressing various damage scenarios.

% iii) \textbf{Sensor-only damage}. In this subcategory, we simulate sensor damage by blocking the input of several random joints for each agent in the training set. Notably, damages are limited to merely the sensors in this case, so the robot’s joints themselves were intact.

% iv) \textbf{Undetectable joint damage}. As discussed in \cref{sec:mal}, sensors in this category are expected to return available and accurate signals, making it a relatively lenient damage condition. Therefore, the observation inputs remained normal and available, and we limited only the motor power and linear speed of damaged joints. We do not add range-of-motion limits to avoid situations when the trained robots act with range-of-motion limits even under normal scenarios, since the robots cannot detect damages and apply masks under both conditions. So we only limit the speed and force of damaged joints to serve as a robustness training subset against such undetected damage situations, enhancing the legged robot's tolerance to unexpected failures in real-world scenarios. Experimental results confirm the effectiveness and practicality of this setup.

% In summary, Stage II training involves four subcategories designed to teach the model to handle a wide array of damage combinations. Additionally, the observation input configurations discussed above and mask application discussed in \cref{sec:umcframework} pertain exclusively to the Actor model. The Critic model, however, must assess real-world conditions and return accurate value estimations to guide the Actor model, hence needing no alteration to its inputs.

% %% Two-Stage Training Section
\subsection{Two-Stage Training}

To enhance the robustness of legged robots in both normal and damaged conditions, we propose a two-stage training pipeline.
%
% The first stage pre-train the network in the normal condition and then finetune it with various conditions.
In the first stage, the network is pre-trained under normal conditions to establish a strong baseline performance.
%
In the second stage, it is fine-tuned across various conditions to adapt to diverse damage scenarios.
%
% This pipeline ensures that the model not only establishes strong baseline performance in normal environments but also obtains the ability to adapt to diverse damage scenarios. 
%
This approach ensures that the model excels in standard environments while maintaining the flexibility to handle unexpected challenges.
%
% Below, we detail each stage and introduce the specific training configurations.

\noindent \textbf{Stage I.}
The objective is to train the model to perform tasks under undamaged conditions. This stage ensures that the robot acquires effective baseline capabilities in normal scenarios.

% \begin{algorithm}[t!]
% \caption{Two-Stage Workflow for Actor Model}
% \label{alg:two_stage}

% \textbf{Input:}  
% $\mathcal{D}_{\text{normal}}$: Dataset under normal conditions,  
% $\mathcal{D}_{\text{damage}}$: Dataset under damage conditions,  
% $\pi$: Policy network,  
% $\theta$: Initial policy parameters,  
% % $t$: The timestep index within a trajectory,
% % $r_t$: Reward at timestep $t$,
% % $\mathbf{o}_t$: Observation input at timestep $t$,
% % $\mathbf{a}_t$: Action taken at timestep $t$, 
% $r$: A sequence of rewards $r_1, \dots, r_T$ over the trajectory, 
% $\mathbf{o}$: A sequence of observations $\mathbf{o}_1, \dots, \mathbf{o}_T$ over the trajectory, 
% $\mathbf{a}$: A sequence of actions $\mathbf{a}_1, \dots, \mathbf{a}_T$ taken over the trajectory, 
% $T_1$: Pretraining iterations,  
% $T_2$: Fine-tuning iterations, 
% $M$ is a masking matrix used to block certain positions in the attention calculation.
% \( \Gamma \):  From equation \ref{eq:dmgdetect}
% \textit{$\hat{A}$ calculation:} From equation \ref{eq:advantage},  
% \textit{$\ell_{surro}$ Calculation:} From equation \ref{eq:surrogate}. \\  

% \begin{tabbing}
%     \hspace{4mm} \= \hspace{4mm} \= \hspace{4mm} \= \hspace{4mm} \= \kill
%     \colorbox{cyan!20}{\textbf{Stage I: Pretraining on $\mathcal{D}_{\text{normal}}$}} \\ 
%     \> 1. Initialize $\theta$ randomly, set $\theta_{\text{old}} \gets \theta$. \\ 
%     \>2. \textbf{For $T_1$ iterations:} \\
%     \> \> a) Sample trajectory $(\mathbf{o}, \mathbf{a}, \mathbf{r}) \sim \mathcal{D}_{\text{normal}}$ using $\pi(\theta)$. \\
%     \> \> b) Compute PPO loss using mini-batches: \\ 
%     \> \> \> i) Compute advantage $\hat{A}$ based on $\mathbf{r}$. \\ 
%     \> \> \> ii) Compute $\ell_{surro}$ based on $\hat{A}$ and $\theta_{\text{old}}$. \\ 
%     \> \> \> iii) Update $\theta \gets \theta + \eta \nabla_\theta \ell_{surro}$. \\
%     \> \> c) Update $\theta_{\text{old}} \gets \theta$. \\[1mm]


%     \colorbox{yellow!20}{\textbf{Stage II: Fine-tuning on $\mathcal{D}_{\text{damage}}$}} \\ 
%     \> 1. Set $\theta_{\text{old}} \gets \theta$ (from Stage I). \\ 
%     \> 2. \textbf{For $T_2$ iterations:} \\
%     \> \> a) Sample trajectory $(\mathbf{o}, \mathbf{a}, r) \sim \mathcal{D}_{\text{damage}}$ using $\pi(\theta)$. \\
%   \> \> b) Apply masking to $\mathbf{o}_{\text{dmg}}$ in \( \Gamma \): \\
%     \> \> \> i) For MLP:
%     \\\> \> \> Set damaged joint inputs to 0: $\mathbf{o}_{dmg} = 0$. \\
%     \> \> \> ii) For Transformer: 
%     \\\> \> \> Set damaged joint inputs to 0: $\mathbf{o}_{dmg} = 0$,
%     \\\> \> \> Mask attention: $M_{dmg} = -\infty$. \\
%     \> \> c) Compute PPO loss using mini-batches: \\ 
%     \> \> \> i) Compute advantage $\hat{A}$ based on $r$. \\ 
%     \> \> \> ii) Compute $\ell_{surro}$ based on $\hat{A}$ and $\theta_{\text{old}}$. \\ 
%     \> \> \> iii) Update $\theta \gets \theta + \eta \nabla_\theta \ell_{surro}$. \\
%     \> \> d) Update $\theta_{\text{old}} \gets \theta$. \\[1mm]

%     \textbf{Output:} Robust policy $\pi(\theta)$
% \end{tabbing}

% \end{algorithm}

% In this process, we represent the joints in the robot as $J_{i} \in \mathbb{R}^{D}$, where $D$ is the dimension of the embedding, and $i \in \{1, 2, \dots, N+1\}$ is the index of the joints and one damage detection signal $F$ sequences. During Stage I, all joints are in normal, undamaged conditions. 

% For the transformer architecture, the training process involves computing the output features through the transformer mechanism, expressed as:
% \begin{equation}
% \text{Output} = \text{Softmax}\left(\frac{\mathbf{Q(J_{i})}\mathbf{K(J_{i})}^T}{\sqrt{d_k}}\right)\mathbf{V(J_{i})},
% \end{equation}
% where $\mathbf{Q(J_{i})}$, $\mathbf{K(J_{i})}$, and $\mathbf{V(J_{i})}$ represent the query, key, and value matrices derived from the joint embeddings $J_{i}$, and $d_k$ is the dimensionality of the query and key vectors. The final output is then used to predict actions and refine the policy. 

\noindent \textbf{Stage II.}
The model is fine-tuned to handle a range of joint and sensor damage conditions while retaining its baseline capabilities from Stage I. 
%
Specifically, we uniformly sample the four subcategories by default in the following:
%
% Let $\mathcal{D}_{\text{damage}}$ denote the damage-condition dataset, which consists of four subcategories:
\vspace{-3mm}
\begin{enumerate}[label=(\roman*)]
    \item \textbf{Normal conditions}: This subcategory includes scenario 8 in \cref{tab:damage_scenarios}, ensuring that the model retains its baseline performance.
    %
    \item \textbf{Sensor-only damage}: This subcategory includes scenario 1 in \cref{tab:damage_scenarios}, which simulates sensor failures by blocking (zeroing out) the input of specific joints while leaving their performance unaffected. 
    %\yq{Maskings are applied in this subcategory.}
    %
    \item \textbf{Detectable joint damage}: This subcategory includes scenarios 2, 3, and 4 in \cref{tab:damage_scenarios}, which simulates partial limb damage by adding joint and sensor damage to certain joints and allowing the detection of damage information.
    %
    % In addition, all three types of damage are applied together to randomly selected joints for each environment. \yq{Maskings are applied to the environments in this subcategory.}
    %
    \item \textbf{Undetectable joint damage}: This subcategory encompasses scenarios 6 and 7 as described in \cref{tab:damage_scenarios}, which simulates joint-specific damages. Notably, no maskings are applied in this subcategory and all sensors remain operational.
\end{enumerate}

\vspace{-3mm}
For detailed explanations and parameters of the four subcategories, please refer to the Appendix.
% \vspace{-4mm}

% \textcolor{red}{Still need to add this paragraph? Now we have no pseudocode, and masking strategy has been effectively illustrated before.}
% \yq{As depicted in \cref{alg:two_stage}, when a malfunction in a joint is detected in \( \Gamma \), two key steps are applied to ensure that the damaged joints do not interfere with the model’s learning process. First, we zero out the original observation input corresponding to the damaged joint to effectively block its influence during the attention calculation. Second, in the multi-head attention mechanism, we introduce a masking matrix \( M_{\text{dmg}} \) where the positions corresponding to the damaged joints are set to \( -\infty \). This masking operation ensures that, after the softmax operation, the attention weights for the damaged joints become negligible, thereby excluding them from further contribution to the model's attention mechanism.}

% The loss for this stage is:
% \begin{equation}
% \mathcal{L}_{\text{Stage II}} = \mathbb{E}_{(\mathbf{o}, \mathbf{a}) \sim \mathcal{D}_{\text{damage}}} \left[\ell \big(\pi(\mathbf{o}; \theta), \mathbf{a}\big)\right]
% \end{equation}
% where $\mathbf{o}$ includes both normal and damage-specific observations.
% \begin{algorithm}[H]
% \caption{Two-Stage Training Workflow}
% \label{alg:two_stage}

% \vspace{1mm} % 增加标题与输入之间的间距

% \textbf{Input:} $\mathcal{D}_{\text{normal}}$: Dataset under normal conditions, $\mathcal{D}_{\text{damage}}$: Dataset under damage conditions, $\pi$: Policy network, $\theta$: Initial policy parameters \\  
% \textbf{Output:} Robust policy $\pi(\mathbf{o}; \theta)$

% \begin{tabbing}
%     \hspace{4mm} \= \hspace{4mm} \= \hspace{4mm} \= \hspace{4mm} \= \kill
%     \colorbox{cyan!20}{\textbf{Stage I: Pretraining on Normal Conditions}} \\ 
%     \> 1. Initialize $\theta$ randomly, set $\theta_{\text{old}} \gets \theta$. \\ 
%     \> 2. \textbf{Repeat for $T_1$ iterations:} \\
%     \> \> a) Sample trajectory $(\mathbf{o}_{\text{normal}}, \mathbf{a}_{\text{normal}}, r_t, \hat{A})$ from environment with $\theta$. \\
%     \> \> b) Apply Generalized Advantage Estimation (GAE) to compute $\hat{A}$. \\
%     \> \> c) For each mini-batch: \\
%     \> \> \> i) Compute ratio: $r_t(\theta) = \frac{\pi_\theta(\mathbf{a}_t|\mathbf{o}_t)}{\pi_{\theta_{\text{old}}}(\mathbf{a}_t|\mathbf{o}_t)}$. \\
%     \> \> \> ii) Compute clipped objective: $\ell_t = \min(r_t(\theta) \hat{A}_t, \text{clip}(r_t(\theta), 1 \pm \epsilon)\hat{A}_t)$. \\
%     \> \> \> iii) Update $\theta$: $\theta \gets \theta - \eta \nabla_\theta \text{loss}$. \\
%     \> \> d) Update $\theta_{\text{old}}$: $\theta_{\text{old}} \gets \theta$. \\[1mm]

%     \colorbox{yellow!20}{\textbf{Stage II: Fine-tuning on Damaged Conditions}} \\ 
%     \> 1. Set $\theta_{\text{old}} \gets \theta$ (from Stage I). \\ 
%     \> 2. \textbf{Repeat for $T_2$ iterations:} \\
%     \> \> a) Sample trajectory $(\mathbf{o}_{\text{damage}}, \mathbf{a}_{\text{damage}}, r_t, \hat{A})$ from environment with $\theta$. \\
%     \> \> b) Apply masking to $\mathbf{o}_{\text{damage}}$: \\
%     \> \> \> i) Set damaged joint inputs to 0: $\mathbf{o}_{j} = 0$. \\
%     \> \> \> ii) Mask attention: $M_j = -\infty$, modify: $\text{Output} = \text{Softmax}((\mathbf{QK}^T/\sqrt{d_k}) + M)\mathbf{V}$. \\
%     \> \> c) Apply Generalized Advantage Estimation (GAE) to compute $\hat{A}$. \\
%     \> \> d) For each mini-batch: \\
%     \> \> \> i) Compute ratio: $r_t(\theta) = \frac{\pi_\theta(\mathbf{a}_t|\mathbf{o}_t)}{\pi_{\theta_{\text{old}}}(\mathbf{a}_t|\mathbf{o}_t)}$. \\
%     \> \> \> ii) Compute clipped objective: $\ell_t = \min(r_t(\theta) \hat{A}_t, \text{clip}(r_t(\theta), 1 \pm \epsilon)\hat{A}_t)$. \\
%     \> \> \> iii) Update $\theta$: $\theta \gets \theta - \eta \nabla_\theta \text{loss}$. \\
%     \> \> e) Update $\theta_{\text{old}}$: $\theta_{\text{old}} \gets \theta$. \\[1mm]

%     \textbf{Output:} Robust Policy $\pi(\mathbf{o}; \theta)$
% \end{tabbing}

% \end{algorithm}




% \paragraph{Masking Mechanism}
% In Stage II, damaged joints are handled using masking strategies specific to the network architecture:
% \begin{itemize}
%     \item \textbf{MLP}: Masked inputs are set to zero, and damage signals are appended as a binary vector.
%     \item \textbf{Transformer}: In Stage II, damaged joints are handled using masking strategies specific to the network architecture, damaged joint embeddings are zeroed, and corresponding attention weights are masked by adding $-\infty$ to the attention logits. 
%     %In this stage, we set $J_{k} \in \mathbb{R}^{B\times D}$ are damaged joint. The $k \in {1, 2,..., N-I}$ is the number of damaged joints. And the number of undamaged joints $J_{u} \in \mathbb{R}^{B\times D}$ is $u \in {1, 2,..., U}$, 
%     The process is: 
%     \begin{equation}
% Output = \text{Softmax}\left(\frac{\mathbf{\mathbf{Q(J_{i}})\mathbf{K(J_{i}})}^T}{\sqrt{d_k}} + M\right)\mathbf{\mathbf{V(J_{i}})}
% \end{equation}
% \noindent where $M \in \mathbb{R}^{B\times (N+1)}$ is a masking matrix used to block certain positions in the attention calculation. 
% \end{itemize}

% By combining these mechanisms with the two-stage workflow, our method ensures robust task performance under diverse real-world scenarios.

\subsection{Transition from Transformer to MLP Structure}
\label{sec:MLPUMC}
% \yq{Need to Refine(Appendix): As shown in \cref{fig:mlp_structure}}, the general workflow of the MLP structure closely resembles that of the Transformer. Therefore, we will focus on the distinct modules in this case. 


For the MLP structure, the main differences lie in part of the damage detection module \( \Gamma' \) and the base structure. 
%
This is because MLP does not obtain a self-attention module and does not need to handle structured input through a tokenizer.
%
In \( \Gamma' \), we retain only the first masking step, which involves zeroing out the observation inputs of the damaged joints, transforming $O$ into $O'$. Then, for the base structure, the input $O' \in \mathbb{R}^{(N+1) \times 3}$ is first flattened into $O'' \in \mathbb{R}^{3N+3}$. After that, the flattened input $O''$ is passed through multiple hidden layers of the MLP. Finally, the MLP processes the data and outputs the action sequence $A \in \mathbb{R}^{N \times 1}$. A detailed workflow diagram is provided in the Appendix.

% \begin{equation}
% O' = \Gamma(O).
% \label{eq:dmgdetect'}
% \end{equation}



\section{Experiments}
\label{sec:exp}
In this section, we begin by describing the experimental setup, followed by evaluation metrics. 
%
% we present both quantitative and qualitative comparison results with existing methods.
Next, we present both quantitative and qualitative comparison results with existing methods. 
%
Finally, we conduct extensive ablation studies to validate the effectiveness of the proposed model.

% \begin{figure}
%   \centering
%   \includegraphics[width=1.0\linewidth]{imgs/g1_sum.pdf}
%       \caption{Overall Comparison of the Success Rate for G1 Task. `Trf' stands for Transformer, `UMC' means our two-stage method, and `NM' is the abbreviation for normal training (without damaged situations).}
%   \label{fig:g1sum}
% \end{figure}

% \begin{figure*}
%   \centering
%   \begin{subfigure}[b]{0.49\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{imgs/a1_sum.pdf}
%     \caption{A1-Walk}
%     \label{fig:a1sum}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}[b]{0.49\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{imgs/h1_sum.pdf}
%     \caption{Unitree-H1}
%     \label{fig:h1sum}
%   \end{subfigure}
%   \caption{Comparison of the Success Rates for A1 and H1 Tasks. For the illustrations of the abbreviations, please refer to \cref{fig:g1sum}. \yq{YQ: Could be integrated with Fig.3 as one.}}
%   \label{fig:summary}
% \end{figure*}


% \begin{table*}[h]
%   \centering
% \renewcommand{\arraystretch}{1}
%     \resizebox{\linewidth}{!}{
%    \begin{tabular}{@{}ccccccccc@{}}
%     \toprule
%      & NM-5U $\uparrow$ & OBS-5U $\uparrow$ & ROJ-Det-FA $\downarrow$ & ROJ-Und-5U $\uparrow$ & EFF-Det-FA $\downarrow$ & EFF-Und-5U $\uparrow$ & VEL-Det-FA $\downarrow$ & VEL-Und-5U $\uparrow$ \\
%     \midrule
%     \myrowcolour%
%     Trf-NM & 84\% & 17\% & 51\% & 53\% & 52\% & 84\% & 61\% & 36\% \\
%     MLP-NM & 81\% & 13\% & 65\% & 44\% & 66\% & 81\% & 79\% & 43\%\\
%     \myrowcolour%
%     BodyTrf & 83\% & 20\% & 50\% & 53\% & 50\% & 74\% & 67\% & 43\%\\
%     MLP-UMC (Ours) & \textcolor{red}{86\%} & \textcolor{red}{78\%} & \textcolor{blue}{11\%} & \textcolor{blue}{54\%} & \textcolor{red}{2\%} & \textcolor{red}{85\%} & \textcolor{blue}{21\%} & \textcolor{red}{76\%}\\
%     \myrowcolour%
%     Trf-UMC (Ours) & \textcolor{blue}{85\%} & \textcolor{red}{78\%} & \textcolor{red}{6\%} & \textcolor{red}{63\%} & \textcolor{blue}{3\%} & \textcolor{red}{85\%} & \textcolor{red}{15\%} & \textcolor{blue}{70\%}\\
%     \bottomrule
%   \end{tabular}}
%   \caption{Average performance across three tasks under selected conditions and evaluation metrics. The red color indicates the best results, and the blue indicates the second-best results.
%   Due to space limitations, more comparisons can be found in the Appendix. 
%   % Here, we have selected a subset of certain conditions with evaluation metrics to demonstrate some of our method's improvements to the robot. 
%   `5U' represents the 5-unit metric; `Det' indicates that the malfunction was detected; `Und' means the malfunction is undetected; `NM' means no-damage condition; `OBS' refers to sensor failure; `ROJ' denotes restricted range of motion; `EFF' refers to limited motor effort; and `VEL' represents restricted joint linear velocity.}
%   \label{tab:avgres}
% \end{table*}


% \begin{figure}[t]
%   \centering
%   \includegraphics[width=1.0\linewidth]{imgs/abl_onestage.pdf}

%    \caption{Comparison of One-Stage and Two-Stage Training in the G1 Task.}
%    \label{fig:onecol}
% \end{figure}

% \begin{figure}
%   \centering
%   \includegraphics[width=1.0\linewidth]{imgs/g1_sum.pdf}
%   \label{fig:g1sum}
% \end{figure}



\subsection{Experimental Setup}
\label{sec:setup}

% Since we have already outlined the detailed content of our two-stage datasets in \cref{sec:mal} and \cref{sec:twostage}, in this section, we focus on introducing tasks and specific experimental environment configurations. 

\noindent\textbf{Implementation Details.} All models are trained on a single Nvidia A6000 GPU and evaluated using PPO-based Reinforcement Learning~\cite{schulman2017proximalpolicyoptimizationalgorithms} for three different robot locomotion tasks, which are the A1-Walk task from ParkourGym~\cite{zhuang2023robot} and the H1 and G1 tasks from Unitree. 
%
For SOTA work comparison, we selected the Solo8 task~\cite{9015985}.
%
Among them, A1 and Solo8 are quadruped robots, while H1 and G1 are humanoid robots. 
%
All these locomotion tasks are performed within the IsaacGym environment~\cite{makoviychuk2021isaacgymhighperformance}, managed by the Legged Gym Repository~\cite{rudin2022learningwalkminutesusing}. 
%
We provide transformer-based and MLP-based UMC architectures. 
%
Please refer to the Appendix for more details on model configurations, malfunction limits, and other parameters. 

\noindent \textbf{Damage Settings During Inference.}
%Moreover, to demonstrate the robustness of UMC, we test as many different conditions as possible. 
During inference, we apply three distinct damage settings for every task, all of which differ from those used during the training stage. 
%
First, for the rough terrain task A1, the robots operate on a terrain that is different from those encountered during training. 
% will act on a different terrain. 
% different from those encountered during training.
%
Second, different joint combinations are randomly selected using various seeds to introduce damage, thereby preventing the model from relying on prior knowledge learned from the training set. 
%
Third, malfunctions are introduced at different times during inference to simulate more different robot gaits when suffering damage and different combinations of joint damage. 
%
% For example, one robot might raise one of its front legs in one setting while pointing down that leg in another when damages are introduced to these joints.
For example, in one environment, a robot may lift one of its front legs, whereas in another, the same leg may point downward when its corresponding joints are damaged.
%
For more details, please refer to the Appendix.

\begin{table}[t!]
  \caption{Average Performance of Different Models on the A1 Task Across Eight Damage Conditions.}
  \centering
  \vspace{-2mm}
\renewcommand{\arraystretch}{1}
    \resizebox{\linewidth}{!}{
   \begin{tabular}{@{}ccccccc@{}}
    \toprule
    Methods & 1 unit $\uparrow$ & 2 unit $\uparrow$ & 3 unit $\uparrow$ & 4 unit $\uparrow$ & 5 unit $\uparrow$ & failed $\downarrow$  \\
    \midrule
    \myrowcolour%
    Trf-NM & 81\% & 64\% & 54\% & 46\% & 38\% & 7\% \\
    MLP-NM & 67\% & 54\% & 48\% & 43\% & 46\% & 23\%\\
    \myrowcolour%
    BodyTrf & 84\% & 68\% & 56\% & 45\% & 36\% & 10\%\\
    MLP-UMC (Ours) & \textcolor{blue}{93\%} & \textcolor{blue}{88\%} & \textcolor{blue}{83\%} & \textcolor{blue}{78\%} & \textcolor{blue}{66\%} & \textcolor{blue}{4\%}\\
    \myrowcolour%
    Trf-UMC (Ours) & \textcolor{red}{97\%} & \textcolor{red}{95\%} & \textcolor{red}{91\%} & \textcolor{red}{84\%} & \textcolor{red}{72\%} & \textcolor{red}{2\%}\\
    \bottomrule
  \end{tabular}}
  \vspace{-2mm}
  \label{tab:a1sum}
\end{table}

\begin{table}[t!]
  \caption{Average Performance of Different Models on the G1 Task Across Eight Damage Conditions.}
  \vspace{-3mm}
  \centering
\renewcommand{\arraystretch}{1}
    \resizebox{\linewidth}{!}{
   \begin{tabular}{@{}ccccccc@{}}
    \toprule
     Methods & 1 unit $\uparrow$ & 2 unit $\uparrow$ & 3 unit $\uparrow$ & 4 unit $\uparrow$ & 5 unit $\uparrow$ & failed $\downarrow$  \\
    \midrule
    \myrowcolour%
    Trf-NM & 44\% & 43\% & 42\% & 39\% & 35\% & 56\% \\
    MLP-NM & 33\% & 33\% & 31\% & 29\% & 25\% & 67\%\\
    \myrowcolour%
    BodyTrf & 52\% & 51\% & 49\% & 45\% & 40\% & 48\%\\
    MLP-UMC (Ours) & \textcolor{blue}{86\%} & \textcolor{blue}{85\%} & \textcolor{blue}{80\%} & \textcolor{blue}{73\%} & \textcolor{blue}{64\%} & \textcolor{blue}{14\%}\\
    \myrowcolour%
    Trf-UMC (Ours) & \textcolor{red}{91\%} & \textcolor{red}{90\%} & \textcolor{red}{85\%} & \textcolor{red}{79\%} & \textcolor{red}{70\%} & \textcolor{red}{9\%}\\
    \bottomrule
  \end{tabular}}
  \vspace{-3mm}
  \label{tab:g1sum}
\end{table}

\begin{table}[t!]
  \caption{Average Performance of Different Models on the H1 Task Across Eight Damage Conditions.}
  \centering
  \vspace{-2mm}
\renewcommand{\arraystretch}{1}
    \resizebox{\linewidth}{!}{
   \begin{tabular}{@{}ccccccc@{}}
    \toprule
     Methods & 1 unit $\uparrow$ & 2 unit $\uparrow$ & 3 unit $\uparrow$ & 4 unit $\uparrow$ & 5 unit $\uparrow$ & failed $\downarrow$  \\
    \midrule
    \myrowcolour%
    Trf-NM & 57\% & 56\% & 55\% & 51\% & 46\% & 43\% \\
    MLP-NM & 57\% & 57\% & 55\% & 52\% & 47\% & 43\%\\
    \myrowcolour%
    BodyTrf & 53\% & 53\% & 51\% & 48\% & 44\% & 47\%\\
    MLP-UMC (Ours)  & \textcolor{red}{97\%} & \textcolor{red}{97\%} & \textcolor{red}{94\%} & \textcolor{red}{88\%} & \textcolor{red}{80\%} & \textcolor{red}{3\%}\\
    \myrowcolour%
    Trf-UMC (Ours) & \textcolor{blue}{95\%} & \textcolor{blue}{94\%} & \textcolor{blue}{90\%} & \textcolor{blue}{84\%} & \textcolor{blue}{75\%} & \textcolor{blue}{5\%}\\
    \bottomrule
  \end{tabular}}
  \vspace{-4mm}
  \label{tab:h1sum}
\end{table}


\begin{table}[t!]
  \caption{Average Performance of Different Models on the Solo8 Task Across Eight Damage Conditions. `MT-FTC' is the method proposed in~\cite{hou2024multitasklearningactivefaulttolerant}.}
  \centering
  \vspace{-2mm}
\renewcommand{\arraystretch}{1}
    \resizebox{\linewidth}{!}{
   \begin{tabular}{@{}ccccccc@{}}
    \toprule
     Methods & 0.5 unit $\uparrow$ & 1 unit $\uparrow$ & 1.5 unit $\uparrow$ & 2 unit $\uparrow$ & 2.5 unit $\uparrow$ & failed $\downarrow$  \\
    \midrule
    \myrowcolour%
    MT-FTC & 39\% & 31\% & 30\% & 30\% & 29\% & 46\%\\
      Trf-UMC (Ours) & \textcolor{red}{73\%} & \textcolor{red}{67\%} & \textcolor{red}{60\%} & \textcolor{red}{52\%} & \textcolor{red}{41\%} & \textcolor{red}{12\%} \\
    \bottomrule
  \end{tabular}}
  \vspace{-6mm}
  \label{tab:sotacomp}
\end{table}


\begin{figure*}[t!]
  \centering
  \includegraphics[width=0.95\linewidth]{imgs/qualitative.pdf}
  \vspace{-3mm}
  \caption{Qualitative Comparison Between Methods Under Damaged Scenarios. 
  \label{sec:res}
  %
  % For H1 and G1 comparisons, all settings remain consistent except for the policy model. 
  %
  % For the A1 task, the failure cases have been presented in \cref{fig:teaser}; here, we instead present the trajectories to directly demonstrate another improvement achieved by UMC. 
  %
  `Baseline' refers to robots trained using baseline methods, while `UMC' denotes robots trained with the UMC method. Figure `b2)' shows a snapshot of the original trajectory at a specific time point under undamaged conditions, while b1) and b3) are in damaged conditions.}
  \label{fig:qualitative}
  \vspace{-4mm}
\end{figure*}


\subsection{Evaluation Metrics}
\label{sec:evalmetric}

%Since the tasks we conduct inference on all focus on the legged robot's locomotion capabilities and our goal is to compare their task performance, 

% \yq{The whole inference duration is 750 episodes. During inference, we first allow the legged robots to walk certain steps under normal conditions, then apply damage and record the initial position.}
%

After legged robots walk certain steps under normal conditions, we apply damage to them and record the initial position. During the subsequent episodes, we record the following comprehensive metrics to validate the locomotion capabilities of legged robots.


%To validate the legged robot's locomotion capabilities, we assess the models' performance based on the following comprehensive metrics. 
%
% We assess the distance travelled by the robots under various damage conditions and check for instances of falling or an inability to continue walking. 
% \yq{After various damages are applied}, 

% We evaluate the distance travelled by the robots and monitor for instances of falling 
%or the inability to continue walking.
%
Specifically, we evaluate whether the robots can move beyond the radii of 1, 2, 3, 4, and 5 units (0.5, 1, 1.5, 2, and 2.5 units for the Solo8 task) from their initial positions without falling.
%
If the robot can maintain its original trajectory despite the damage, this distance should correlate positively with time. 
%
Therefore, a greater distance travelled indicates a more effective policy, as it allows the robot to move further given the limited time.
%
Additionally, legged robots that exhibit any falling behaviour are excluded from the previous distance statistics and are instead counted in a separate metric labelled as `failed'. 
% Therefore, in summary, we use a total of six evaluation metrics: the number of robots covering 1 unit, 2 units, 3 units, 4 units, 5 units, and the count of failure robots. This detailed classification allows for a more nuanced performance comparison across training strategies and model architectures.

\begin{figure}[t!]
    \centering
    \vspace{-2mm}
    \begin{subfigure}[b]{0.2\textwidth}  % 设置宽度为页面一半（注意给出合适的宽度）
        \centering
        \includegraphics[width=\textwidth]{imgs/ablation/twostage/abl_onestage_episode.pdf}
        \caption{Episode \text{v.s.} Iteration}
    \end{subfigure}
    \begin{subfigure}[b]{0.2\textwidth}  % 设置宽度为页面一半
        \centering
        \includegraphics[width=\textwidth]{imgs/ablation/twostage/abl_onestage_reward.pdf}
        \caption{Reward \text{v.s.} Iteration}
    \end{subfigure}
    \caption{Comparison of One-Stage and Two-Stage Training in the G1 Task.}
    \label{fig:abl_twostage}
    \vspace{-7mm}
\end{figure}

\vspace{-2mm}
\subsection{Overall Results}
%As shown in \cref{fig:g1sum}, \cref{fig:a1sum}, and \cref{fig:h1sum}, we first provide the average performance for each task across the three different settings for each damage scenario, and then sum the resulting averages for each model from the eight damage scenarios on our six evaluation metrics. Besides, due to space limitations, the complete comparisons involving all metrics on all tasks under all conditions can be found in the Appendix, we only show part of the important averaged results across the three tasks in \cref{tab:g1res}. 


% As shown in \cref{fig:g1sum}, \cref{fig:a1sum}, and \cref{fig:h1sum}, we provide the average performance for each task in the three different settings for each damage scenario, and then sum the resulting averages for each model from the eight damage scenarios on our six evaluation metrics to demonstrate \yq{superiority} of our UMC framework. 
As shown in 
\cref{tab:a1sum}, \cref{tab:g1sum},  and \cref{tab:h1sum}, we present the average performance for each task with our metrics.
%
The averaged results for each model are computed by summing performance across eight damage scenarios and three inference settings, demonstrating the superiority of our UMC framework. More statistics are shown in the Appendix.

%
The UMC significantly reduces the number of fall cases on the H1, G1, and A1 tasks, and performs better against the BodyTransformer. 
%
Compared to the normally trained transformer, our baseline, the transformer-based UMC achieves an average reduction in failure rates across eight types of damage by 5\%, 38\%, and 47\% in tasks A1, H1 and G1, respectively. 
%
Similarly, MLP-based UMC demonstrates reductions of 19\%, 40\%, and 53\%, respectively. 
%
%
UMC prompts robots to rely more on their functional limbs when dealing with various failures, thereby effectively reducing the impact of damaged joints on their actions.
% \yq{We attribute these improvements brought by UMC to its ability to train robots to rely more on their functional limbs when dealing with various failures. 
% This approach not only reduces the policy's learning cost, thereby increasing the success rate of training, but also enhances its robustness, providing robots with a unified, efficient method to tackle various challenges.}
In real-world applications, especially for humanoid robots, falls during task execution could lead to substantial physical damage and result in high financial costs. 
%
Instead, our method effectively minimizes such risk of damage and associated costs. 

For the task completion performance of the transformer architecture, taking the A1-Walk task as an example, UMC improves the robot's achievement rates across the 1-unit to 5-unit metrics by 16\%, 31\%, 37\%, 38\%, and 34\%, respectively. 
%
For the MLP architecture, the robot also demonstrates improvements of 38\%, 38\%, 35\%, 33\%, and 29\% on the H1 task.
% \yq{YuQiu: Are these explanations reasonable?:}
We attribute such improvements to our masking mechanism as it enables rapid adaptation to new types of damage without the need to switch to a new policy. 
%
Therefore, robots can respond to sudden damage more quickly and adjust their gait accordingly.
% Also, the damage training environment in Stage II enables the robot to cope with more damaged situations.

%
The \cref{fig:qualitative} indicate that UMC can handle various damage conditions and effectively maintain the intended trajectory, which demonstrates that UMC can reduce the impact of damages from another perspective.
%
Moreover, \cref{fig:teaser}(c) show that UMC retains and even slightly enhances the robot's performance under normal, undamaged conditions across three tasks.
%
This improvement comes from the design of our two-stage pipeline, which ensures that the trained robots maintain their performance under normal conditions. 
% Also, the regularizing effect of our damage dataset may play a role, as it encourages the robots to complete tasks using fewer limbs.}

Additionally, we compared UMC with the method proposed in~\cite{hou2024multitasklearningactivefaulttolerant}, referred to as `MT-FTC', on the Solo8 task. The results in \cref{tab:sotacomp} indicate that UMC achieves a 26.8\% improvement in task completion performance and reduces the fall rate by 34\% compared to `MT-FTC'. These results demonstrate that UMC exhibits greater flexibility in adapting to various conditions compared to SOTA methods.

Furthermore, a comparison of \cref{tab:a1sum}, \cref{tab:g1sum}, and \cref{tab:h1sum} reveals that our baselines degrades less in humanoid robot tasks than in quadruped robot tasks as the metric increases from 1 to 5 units.
%
We attribute this to the structural differences between humanoid robots and quadruped ones like A1.
%
Unlike A1, which can easily remain upright and stable despite finding it difficult to move forward due to damage, humanoid robots face greater challenges in maintaining balance during movement. 

% Additionally, those humanoid robots that fall during movement are not accounted for in the previous distance metric. Consequently, those capable of moving beyond 1 unit are relatively more likely to reach greater distances.

% \textcolor{red}{(YQ: Does this `demonstrating xxx' sentence make sense? Or it is not good to write like this becuz we should do the ablation and say that two-stage is good?(But one-stage could not even converge, as shown in 4.4.1)}.
%


%our method does not affect the robot's performance under normal conditions across three tasks. This indicates that our model learns to handle various damage conditions and retains, and even slightly enhances, its normal locomotion capabilities in undamaged environments. 
% Please see the Appendix for more statistics and results.

%For the tasks not mentioned above, please refer to \cref{fig:g1sum}, \cref{fig:a1sum} and \cref{fig:h1sum}, where our method also shows significant improvements across these tasks. This also demonstrates that our training method enhances the robustness of robot control not merely by reducing the robot’s fall rate, but also by equipping it with a substantially stronger task-performing ability. In real-world scenarios like rescue tasks, human intervention may not be feasible when robots encounter unexpected damages, which renders such capabilities valuable.

%\cref{tab:g1res} and \cref{fig:teaser1} also pinpoint that our method does not impair the robot's mobility under normal conditions across three tasks. This indicates that our model learns to handle various damage conditions and retains, and even slightly enhances, its normal locomotion capabilities in undamaged environments.

% Additionally, as shown in \cref{fig:teaser2}, we calculate the average performance of the Transformer and MLP models across the three tasks and find that the Transformer structure not only maintains an average failure rate (fall rate) that is 1.31\% lower than the MLP structure but also achieves higher average success rates in the five task-completion metrics, with respective improvements of 2.07\%, 2.97\%, 2.92\%, 2.52\% and 3.53\%. Moreover, according to the Appendix, in the undamaged scenario for the G1 task, the normal-trained MLP model even achieved a failure rate of 18\%. In contrast, the Transformer model maintained a failure rate of 5\% or less across all three tasks, which makes the Transformer a more stable structure across diverse tasks. Besides, we can learn that Transformer demonstrates superior performance in two of the three tasks from \cref{fig:g1sum}, \cref{fig:a1sum} and \cref{fig:h1sum}. Therefore, we conclude that the Transformer framework is better suited for our method.

%In summary, we compare the inference results on five methods with six metrics in this subsection. Results show that UMC significantly reduces the fall rates and improves the task-completion abilities of legged robots under various damage conditions, and Transformer has proved to be a better structure for UMC.

\begin{table}[t!]
  \caption{Average Performance of Transformer-Based UMC with Different Stage-II Environment Settings. 
  %
  The ratios correspond to four training scenarios in Stage II from left to right: `Normal', `Undamaged', `Sensor-only Damage', `Detectable Joint Damage', and `Undetectable Joint Damage'. 
  %
  % Each ratio represents the relative proportion of training environments for each scenario.}
  }
  \vspace{-2mm}
  \label{sec:abl_ratio}
  \centering
\renewcommand{\arraystretch}{1}
    \resizebox{\linewidth}{!}{
   \begin{tabular}{@{}ccccccc@{}}
    \toprule
     Ratios & 1 unit $\uparrow$ & 2 unit $\uparrow$ & 3 unit $\uparrow$ & 4 unit $\uparrow$ & 5 unit $\uparrow$ & failed $\downarrow$  \\
    \midrule
    \myrowcolour%
    1:1:1:0 & 89\% & 84\% & 79\% & 73\% & 66\% & 10\% \\
    1:1:0:1 & 90\% & 83\% & 75\% & 65\% & 50\% & 2\%\\
    \myrowcolour%
    1:0:1:1 & 97\% & 94\% & 88\% & 80\% & 68\% & 2\%\\
    0:1:1:1 & 97\% & \textcolor{red}{95\%} & 90\% & 82\% & 69\% & \textcolor{red}{2\%}\\
    \myrowcolour%
    1:2:2:1 & 97\% & 94\% & 89\% & 81\% & 68\% & 2\%\\
    1:3:3:1 & 97\% & 94\% & 87\% & 77\% & 66\% & 2\%\\
    \myrowcolour%
    Default(1:1:1:1) & \textcolor{red}{97\%} & 94\% & \textcolor{red}{90\%} & \textcolor{red}{84\%} & \textcolor{red}{74\%} & 3\%\\
    \bottomrule
  \end{tabular}}
  \label{tab:abl_ratio}
  \vspace{-6mm}
\end{table}

\subsection{Ablation Study}

In this section, we focus on the overall ablation results, including mask strategy, training stages, sampling ratio and paradigms for each damage scenario. %
For more details and results, please refer to the Appendix.

\label{sec:ablation}

% \begin{figure}[ht]
%   \centering
%   \begin{subfigure}[b]{0.49\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{imgs/ablation/twostage/abl_onestage_episode.pdf}
%     \caption{Episode \text{v.s.} Iteration}
%     \label{fig:a1sum}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}[b]{0.49\textwidth}
%     \centering
%     \includegraphics[width=\linewidth]{imgs/ablation/twostage/abl_onestage_reward.pdf}
%     \caption{Reward \text{v.s.} Iteration}
%     \label{fig:h1sum}
%   \end{subfigure}
%   \caption{Comparison of One-Stage and Two-Stage Training in the G1 Task.}
%   \label{fig:abl_twostage}
% \end{figure}




\noindent \textbf{Training Stage.}
%We primarily test whether removing the first training stage in our two-stage workflow would improve the performance of the UMC framework. 
We ablate our training stages in~\cref{fig:abl_twostage}. 
%
The blue and green curves represent the two training stages in our method, while the orange curve shows the one-stage training, training solely on our Stage II damaged environments. 
%
The curves show that the one-stage setting eventually fails to converge within 2500 iterations in the G1 task, whereas the two-stage approach proves effective across all three tasks. 
%
We attribute this to the introduction of an overly complex training set in the initial stage, which hindered the model's convergence and ultimately prevented the discovery of effective policies.
%
Thus, we selected the two-stage training process for our workflow.


\noindent \textbf{Sampling Ratio.}
We ablate the sampling ratio of the four training subcategories in Stage II. 
%
\cref{tab:abl_ratio} demonstrates that the default ratio of 1:1:1:1 achieves the best overall performance. 
%
The potential reason is two-fold. 
%
First, unlike conditions that exclude certain subcategories (e.g., 1:1:1:0), the model could learn all four damaged scenarios with the default ratio during Stage II. 
%
Second, compared to ratios that focus more heavily on detectable damage (e.g. 1:2:2:1), the default ratio achieves better balance and thus enables the model to learn to handle various types of damage more comprehensively.


\noindent \textbf{Masking Value.}
\label{sec:abl_maskvalue}
We ablate the masking value adopted in our masking mechanism, where the value indicates the observation of the damaged joint. 
%
\cref{tab:abl_maskvalue} shows that zero outperforms the two out-of-distribution values `-100' and `100'.
%
We attribute this to out-of-distribution values exerting greater influence on the model’s decision-making.
%
For example, if an action in the observation input is set to 100, though out of range, it still carries some information that the model can analyze. 
%
And the impact of such information is greater than that of the default value of 0. 
%
Additionally, excessively large values may result in disproportionate rewards or penalties, further affecting the model's performance.

\noindent \textbf{Paradigms.}
We ablate the foundational paradigms of UMC. In addition to the stage-based approach, we tested a curriculum-based learning strategy, progressing through increasing levels of difficulty: no damage, undetectable joint damage, sensor-only damage, and detectable joint damage. As shown in \cref{tab:abl_paradigm}, the curriculum-based approach performed slightly worse than the stage-based method, likely because its progressive focus on higher-difficulty tasks reduces its adaptability to lower-difficulty scenarios, resulting in suboptimal overall performance.


\begin{table}[t!]
  \caption{Average Performance of Transformer-Based UMC with Different Masking Values.}
  \vspace{-2mm}
  \centering
\renewcommand{\arraystretch}{1}
    \resizebox{\linewidth}{!}{
   \begin{tabular}{@{}ccccccc@{}}
    \toprule
     Values & 1 unit $\uparrow$ & 2 unit $\uparrow$ & 3 unit $\uparrow$ & 4 unit $\uparrow$ & 5 unit $\uparrow$ & failed $\downarrow$  \\
    \midrule
    \myrowcolour%
    100 & 96\% & 93\% & 87\% & 79\% & 67\% & 3\% \\
    -100 & 95\% & 91\% & 86\% & 79\% & 68\% & 4\%\\
    \myrowcolour%
    Default(0) & \textcolor{red}{97\%} & \textcolor{red}{94\%} & \textcolor{red}{90\%} & \textcolor{red}{84\%} & \textcolor{red}{74\%} & \textcolor{red}{3\%}\\
    \bottomrule
  \end{tabular}}
  \label{tab:abl_maskvalue}
  \vspace{-3mm}
\end{table}

\begin{table}[t!]
  \caption{Average Performance of Transformer-Based UMC with Different Paradigms.}
  \vspace{-2mm}
  \centering
\renewcommand{\arraystretch}{1}
    \resizebox{\linewidth}{!}{
   \begin{tabular}{@{}ccccccc@{}}
    \toprule
     Paradigms & 1 unit $\uparrow$ & 2 unit $\uparrow$ & 3 unit $\uparrow$ & 4 unit $\uparrow$ & 5 unit $\uparrow$ & failed $\downarrow$  \\
    \midrule
    \myrowcolour%
    Curriculum-Based & 92\% & 88\% & 84\% & 79\% & 67\% & 6\% \\
    Stage-Based & \textcolor{red}{97\%} & \textcolor{red}{94\%} & \textcolor{red}{90\%} & \textcolor{red}{84\%} & \textcolor{red}{74\%} & \textcolor{red}{3\%}\\
    \bottomrule
  \end{tabular}}
  \label{tab:abl_paradigm}
  \vspace{-6mm}
\end{table}


%which reveals that the one-stage method---training solely on our damaged dataset---failed to perform on the G1 task. Specifically, the blue and green curves represent the two training stages in our two-stage approach, while the orange curve shows the results of the one-stage method. The figure shows that the one-stage approach eventually fails to converge within 2500 iterations, whereas the two-stage approach proves effective across all three tasks. Thus, we selected the two-stage training process for our workflow.


\section{Conclusion}
\label{sec:con}
In this paper, we present UMC, a unified, model-free framework that substantially improves the resilience of legged robots facing various failure scenarios, including sensor malfunctions and joint issues such as restricted motion, weakened motor, or limited velocity. 
%
Our approach UMC adopts two training stages that enable fast adaption to damaged conditions while allowing the robots to perform well in undamaged normal states. 
%
Specifically, UMC incorporates a masking strategy, isolating faulty joints, allowing the robot to compensate by emphasizing unaffected limbs and adapting dynamically to diverse damage patterns.
%
Experimental results validate that our UMC consistently improves both transformer and MLP architectures across different robot models and tasks, markedly reducing failure rates and improving task success under variable damage conditions, further improving the adaptability of robotic systems in challenging environments.


% remove limitations given the page
% \yq{Despite the effectiveness of our proposed approach, there are several limitations to address in future work. First, we do not test our method in real-world scenarios, so we cannot test UMC's robustness in practical conditions. Second, limited malfunction and task types are considered in our experiments. Expanding such variety would further validate the generalization capability of our method. Finally, our work relies heavily on the success of the damage detection module. Future work will aim to overcome these limitations by designing more versatile damage detection modules and exploring the possibilities of similar mask-based fault-tolerant methods under a wider range of damage scenarios and task types like manipulation ones.}

\section*{Impact Statement}
This paper presents work whose objective is to advance the field of fault tolerance in robotics. 
%
There are many potential societal consequences of our work, none of which we feel should be specifically highlighted here.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage 
\appendix
\onecolumn
\renewcommand{\thesection}{\Alph{section}} % 使用字母表示章节编号

This Appendix provides additional details and empirical results to demonstrate the benefits of our proposed method. The contents of this Appendix are structured as follows:

\begin{itemize}
    \item \textbf{UMC Implementation Details}: Detailed parameters of the UMC structures. 
    \item \textbf{Details of the Stage II Training Environment}: Explanations of the design of the Stage-II training environment.
    \item \textbf{Malfunction and Experiment Settings}: Detailed parameters of the malfunction and other settings during training and inference.
    \item \textbf{More Experiment Results}: More experiment results that are not shown and illustrated in the body of the paper.
    \item \textbf{More Ablation Results}: More details and ablation experiment results that are not shown and illustrated in the ablation parts.
    \item \textbf{Loss}: Detailed Introduction of the loss functions adopted in our work.

\end{itemize}

\section{UMC Implementation Details}

In this section, as shown in \cref{tab:model_param}, we provide detailed experimental parameters of our UMC structure to facilitate reproducibility and related operations.

\begin{table}[h]
  \caption{Detailed Parameters of the transformer-based and MLP-based Actor Model.}
  \centering
   \begin{tabular}{@{}l|cc@{}}
    \toprule
    Parameter & MLP & Transformers \\
    \midrule
    Stage-One Epochs  & 2500 & 2500 \\
    Stage-Two Epochs & 2500 & 2500 \\
    Encoder Layers & 4 & 4 \\
    Embedding Input Size & N/A & 120 \\
    Feedforward Size & [256,512,256,256] & 128 \\
    Attention Heads & N/A & 2 \\
    \midrule
    Total Parameters & 345,100 & 366,164 \\
    \bottomrule
  \end{tabular}

  \label{tab:model_param}
\end{table}

\begin{figure*}
  \centering
  \includegraphics[width=1.0\linewidth]{imgs/dmg.pdf}
  \caption{Demonstration of different damage conditions.}
  \label{fig:malfunction_demonstration}
\end{figure*}

\begin{figure}
  \centering
  \includegraphics[width=1.0\linewidth]{imgs/mlp_structure.pdf}
  \caption{UMC Framework for MLP-based Actor-Model Architecture.}
  \label{fig:mlp_structure}
\end{figure}

\begin{table}[h]
    \caption{Malfunction Settings for Training and Inference in the A1-Walk Task.}
  \centering
  \begin{subtable}[t]{\linewidth}
  \caption{Training Parameters.}
    \centering
    \begin{tabular}{@{}l|c@{}}
      \toprule
      Parameter & Values \\
      \midrule
      Num Envs & 7400  \\
      Random Damage Range & [2,4]  \\
      ROM Limit & Random 30\% \\
      Motor Limit & 5 \\
      Velocity Limit & 3 \\
      Track Width & 1.6 \\
      Track Block Length & 2.0 \\
      Border Size & 8 \\
      Perlin Noise Seed & 1 \\
      Random Malfunction Seed & 42 \\
       Episode Length & 1000 \\
      Malfunction Timing & N/A \\
      \bottomrule
    \end{tabular}

  \end{subtable}
  \\[0.5cm] % 调整子表之间的垂直间距
  \begin{subtable}[t]{\linewidth}

    \caption{Inference Parameters.}
    \centering
    \begin{tabular}{@{}l|c@{}}
      \toprule
      Parameter & Values \\
      \midrule
      Num Envs & 4000  \\
      Random Damage Range & [4,5]  \\
      ROM Limit & Random 10\% \\
      Motor Limit & 8 \\
      Velocity Limit & 3 \\
      Track Width & 6.0 \\
      Track Block Length & 6.0 \\
      Border Size & 4 \\
      Perlin Noise Seed & [100, 25, 75] \\
      Random Malfunction Seed & [1, 800, 50] \\
      Malfunction Timing & [75, 100, 125] \\
       Episode Length & 750 \\
      \bottomrule
    \end{tabular}
    
  \end{subtable}

  \label{tab:a1_mal}
\end{table}

\begin{table}[h]
 \caption{Malfunction Settings for Training and Inference in the H1 Task.}
  \centering
  \begin{subtable}[t]{\linewidth}
  \caption{Training Parameters.}
      \centering
    \begin{tabular}{@{}l|c@{}}
      \toprule
      Parameter & Values \\
      \midrule
      Num Envs & 10000  \\
      Random Damage Range & [2,4]  \\
      ROM Limit & Random 30\% \\
      Motor Limit & 10 \\
      Velocity Limit & 5 \\
      Random Malfunction Seed & 42 \\
      Malfunction Timing & N/A \\
       Episode Length & 1000 \\
   
     
      \bottomrule
    \end{tabular}
    
  \end{subtable}
  \\[0.5cm] % 调整子表之间的垂直间距
  \begin{subtable}[t]{\linewidth}
  \caption{Inference Parameters.}
 \centering
    \begin{tabular}{@{}l|c@{}}
      \toprule
      Parameter & Values \\
      \midrule
      Num Envs & 8192  \\
      Random Damage Range & [2,3]  \\
      ROM Limit & Random 30\% \\
      Motor Limit & 8 \\
      Velocity Limit & 3 \\
      Random Malfunction Seed & [1, 50, 75] \\
      Malfunction Timing & [75, 100, 125] \\
        Episode Length & 750 \\
      \bottomrule
    \end{tabular}
    
  \end{subtable}

  \label{tab:h1_mal}
\end{table}

\begin{table}[h]
  \caption{Malfunction Settings for Training and Inference in the Unitree-G1 Task.}
  \centering
  \begin{subtable}[t]{\linewidth}
  \caption{Training Parameters.}
    \centering
    \begin{tabular}{@{}l|c@{}}
      \toprule
      Parameter & Values \\
      \midrule
      Num Envs & 8192  \\
      Random Damage Range & [2,4]  \\
      ROM Limit & Random 30\% \\
      Motor Limit for Hip Joints & 8 \\
      Motor Limit for Knee Joints & 13 \\
      Motor Limit for Ankle Joints & 4 \\
      Velocity Limit & 3 \\
      Random Malfunction Seed & 42 \\
      Episode Length & 1000 \\
      Malfunction Timing & N/A \\
      \bottomrule
    \end{tabular}
    
  \end{subtable}
  \\[0.5cm] % 调整子表之间的垂直间距
  \begin{subtable}[t]{\linewidth}
  \caption{Inference Parameters.}
    \centering
    \begin{tabular}{@{}l|c@{}}
      \toprule
      Parameter & Values \\
      \midrule
      Num Envs & 10000  \\
      Random Damage Range & [2,4]  \\
      ROM Limit & Random 30\% \\
      Motor Limit for All Joints & 5 \\
      Velocity Limit & 3 \\
      Random Malfunction Seed & [1, 50, 75] \\
      Malfunction Timing & [75, 100, 125] \\
          Episode Length & 750 \\
      \bottomrule
    \end{tabular}
    
  \end{subtable}

  \label{tab:g1_mal}
\end{table}


\begin{table}[h]
  \caption{Malfunction Settings for Training and Inference in the Solo8 Task.}
  \centering
  \begin{subtable}[t]{\linewidth}
  \caption{Training Parameters.}
    \centering
    \begin{tabular}{@{}l|c@{}}
      \toprule
      Parameter & Values \\
      \midrule
      Num Envs & 4096  \\
      Random Damage Range & [1,3]  \\
      ROM Limit & Random 30\% \\
      Motor Limit & 0.75 \\
      Velocity Limit & 5 \\
      Random Malfunction Seed & 42 \\
      Malfunction Timing & N/A \\
      Episode Length & 1000 \\
      \bottomrule
    \end{tabular}
    
  \end{subtable}
  \\[0.5cm] % 调整子表之间的垂直间距
  \begin{subtable}[t]{\linewidth}
  \caption{Inference Parameters.}
    \centering
    \begin{tabular}{@{}l|c@{}}
      \toprule
      Parameter & Values \\
      \midrule
      Num Envs & 4096  \\
      Random Damage Range & [2,4]  \\
      ROM Limit & Random 30\% \\
      Motor Limit for All Joints & 5 \\
      Velocity Limit & 3 \\
      Random Malfunction Seed & 50 \\
      Malfunction Timing & 100 \\
      Episode Length & 1000 \\
      \bottomrule
    \end{tabular}
    
  \end{subtable}

  \label{tab:solo8}
\end{table}



\section{Details of the Stage II Training Environment}
To enable our model to adapt to a wide range of damage scenarios, we thoughtfully designed four subcategories in the training environment used during Stage II. Explanations of how we design these scenarios will be illustrated in the following:

\begin{itemize}
    \item \textbf{Normal Scenarios}: We add this scenario in the second training stage to ensure that the model could retain the ability to perform well under no-damaged scenarios.

    \item \textbf{Senor-only Damage Scenarios}: This scenario represents cases where the joint functions normally but fails to return data to the central controller due to sensor damage. For such cases, the observation input of the affected joint would be reset back to a default value of zero due to no detected signals, while joints could perform as usual.

    \item \textbf{Detectable Joint-Damage Scenarios}: In this scenario, all three types of damage are applied together to randomly selected joints for each environment. We also damage the corresponding sensor as joint damage is likely to cause sensor failure in real-world conditions. And even if the sensors are currently functional, their data may be unreliable, and their continued functionality cannot be guaranteed. Thus, we assume a worst-case scenario where, whenever a joint's damage is detected, its corresponding sensor also will not work.

    \item \textbf{Undetectable Joint-Damage Scenarios}: The objective of this subcategory is to improve system robustness in situations where failures cannot be directly detected. In this subcategory, two types of joint damage are applied simultaneously to each affected joint: reduced motor force and limited linear velocity. `Undetectable' means these damages are undetectable to the damage detection module, so no masking is applied. Moreover, in such instances, since the damage is not detected, we assume the sensors to be capable of transmitting accurate data, or otherwise, anomalies or damage could be inferred from the sensor input given the maturity of the existing damage detection methods~\cite{quamar2024reviewfaultdiagnosisfaulttolerant}.
    
\end{itemize}


\section{Malfunction and Experiment Settings}


In this section, we use detailed statistics and \cref{fig:malfunction_demonstration} to illustrate our damage design further. We conducted three sets of tests for each task with different damage conditions. The training and inference parameters are provided in \cref{tab:a1_mal}, \cref{tab:h1_mal}, \cref{tab:g1_mal} and \cref{tab:solo8}, where:

\textit{Malfunction Timing} refers to the specific episode we apply malfunctions to the robots. \textit{ROM Limit} indicates the range of motion for each joint in the environment is restricted to a certain percentage of its original range. \textit{Motor Limit} specifies that the motor strength for each joint is capped at a certain value. \textit{Velocity Limit} means the maximum speed of joint movement is a certain value.
\textit{Random Damage Range} denotes the number of randomly selected joints damaged in each environment. \textit{Random Malfunction Seed} refers to the seed we use when randomly selecting which joints to be damaged for each environment. \textit{Perlin Noise Seed}, \textit{Track Width}, \textit{Border Size} and \textit{Track Block Length} emphasize that we test our methods on different terrain settings in \cref{tab:a1_mal}.

During inference, each damage scenario is tested separately. Also, in each scenario, the malfunction limits (ROM, Motor and Velocity) are applied to the joints under three malfunction setting groups (the timing to add malfunction, different damage range, etc.). This approach ensures that the robot's limbs encounter a wide range of states, enhancing the robustness and rigour of the process. The rationale is that the difficulty of overcoming obstacles and completing tasks significantly depends on the robot's posture. For example, a malfunction occurring when a limb is fully extended to support the robot's weight presents a greater challenge compared to when the limb is retracted during a recovery phase. Therefore, we eventually set up various inference groups with different damage settings to generate as many postures as possible.


\section{More Experiment Results}


\begin{figure*}[ht]
  \centering
  % 第一行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/a1_detail/NORMAL.pdf}
    \caption{Normal Condition}
    \label{fig:a1_norm}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/a1_detail/OBS_LIMIT.pdf}
    \caption{Sensor-Damaged Condition}
    \label{fig:a1_obslimit}
  \end{subfigure}
  \hfill
% 第二行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/a1_detail/DOF_UPPERLOWER_LIMIT.pdf}
    \caption{Detected ROM-Limit Condition}
    \label{fig:a1_rom_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/a1_detail/DOF_UPPERLOWER_LIMIT_UNDETECTED.pdf}
    \caption{Undetected ROM-Limit Condition}
    \label{fig:a1_rom_und}
  \end{subfigure}
  \hfill
  % 第三行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/a1_detail/DOF_EFFORT_LIMIT.pdf}
    \caption{Detected Motor-Limit Condition}
    \label{fig:a1_mot_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/a1_detail/DOF_EFFORT_LIMIT_UNDETECTED.pdf}
    \caption{Undetected Motor-Limit Condition}
    \label{fig:a1_mot_und}
  \end{subfigure}
  \hfill
  % 第四行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/a1_detail/DOF_VEL_LIMIT.pdf}
    \caption{Detected Velocity-Limit Condition}
    \label{fig:a1_vel_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/a1_detail/DOF_VEL_LIMIT_UNDETECTED.pdf}
    \caption{Undetected Velocity-Limit Condition}
    \label{fig:a1_vel_und}
  \end{subfigure}
  \hfill
  \caption{Performance of Five Methods Under Different Damage Conditions in the A1-Walk Task.}
  \label{fig:a1_detail_results}
\end{figure*}


\begin{figure*}[ht]
  \centering
  % 第一行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/h1_detail/NORMAL.pdf}
    \caption{Normal Condition}
    \label{fig:h1_norm}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/h1_detail/OBS_LIMIT.pdf}
    \caption{Sensor-Damaged Condition}
    \label{fig:h1_obslimit}
  \end{subfigure}
  \hfill
% 第二行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/h1_detail/DOF_UPPERLOWER_LIMIT.pdf}
    \caption{Detected ROM-Limit Condition}
    \label{fig:h1_rom_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/h1_detail/DOF_UPPERLOWER_LIMIT_UNDETECTED.pdf}
    \caption{Undetected ROM-Limit Condition}
    \label{fig:h1_rom_und}
  \end{subfigure}
  \hfill
  % 第三行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/h1_detail/DOF_EFFORT_LIMIT.pdf}
    \caption{Detected Motor-Limit Condition}
    \label{fig:h1_mot_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/h1_detail/DOF_EFFORT_LIMIT_UNDETECTED.pdf}
    \caption{Undetected Motor-Limit Condition}
    \label{fig:h1_mot_und}
  \end{subfigure}
  \hfill
  % 第四行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/h1_detail/DOF_VEL_LIMIT.pdf}
    \caption{Detected Velocity-Limit Condition}
    \label{fig:h1_vel_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/h1_detail/DOF_VEL_LIMIT_UNDETECTED.pdf}
    \caption{Undetected Velocity-Limit Condition}
    \label{fig:h1_vel_und}
  \end{subfigure}
  \hfill
  \caption{Performance of Five Methods Under Different Damage Conditions in the Unitree-H1 Task.}
  \label{fig:h1_detail_results}
\end{figure*}

\begin{figure*}[ht]
  \centering
  % 第一行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/NORMAL.pdf}
    \caption{Normal Condition}
    \label{fig:g1_norm}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/OBS_LIMIT.pdf}
    \caption{Sensor-Damaged Condition}
    \label{fig:g1_obslimit}
  \end{subfigure}
  \hfill
% 第二行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_UPPERLOWER_LIMIT.pdf}
    \caption{Detected ROM-Limit Condition}
    \label{fig:g1_rom_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_UPPERLOWER_LIMIT_UNDETECTED.pdf}
    \caption{Undetected ROM-Limit Condition}
    \label{fig:g1_rom_und}
  \end{subfigure}
  \hfill
  % 第三行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_EFFORT_LIMIT.pdf}
    \caption{Detected Motor-Limit Condition}
    \label{fig:g1_mot_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_EFFORT_LIMIT_UNDETECTED.pdf}
    \caption{Undetected Motor-Limit Condition}
    \label{fig:g1_mot_und}
  \end{subfigure}
  \hfill
  % 第四行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_VEL_LIMIT.pdf}
    \caption{Detected Velocity-Limit Condition}
    \label{fig:g1_vel_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_VEL_LIMIT_UNDETECTED.pdf}
    \caption{Undetected Velocity-Limit Condition}
    \label{fig:g1_vel_und}
  \end{subfigure}
  \hfill
  \caption{Performance of Five Methods Under Different Damage Conditions in the Unitree-G1 Task.}
  \label{fig:g1_detail_results}
\end{figure*}

\begin{figure*}[ht]
  \centering
  % 第一行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/avg_detail/NORMAL_average_values.pdf}
    \caption{Normal Condition}
    \label{fig:avg_norm}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/avg_detail/OBS_LIMIT_average_values.pdf}
    \caption{Sensor-Damaged Condition}
    \label{fig:avg_obslimit}
  \end{subfigure}
  \hfill
% 第二行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/avg_detail/DOF_UPPERLOWER_LIMIT_average_values.pdf}
    \caption{Detected ROM-Limit Condition}
    \label{fig:avg_rom_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/avg_detail/DOF_UPPERLOWER_LIMIT_UNDETECTED_average_values.pdf}
    \caption{Undetected ROM-Limit Condition}
    \label{fig:avg_rom_und}
  \end{subfigure}
  \hfill
  % 第三行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/avg_detail/DOF_EFFORT_LIMIT_average_values.pdf}
    \caption{Detected Motor-Limit Condition}
    \label{fig:avg_mot_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/avg_detail/DOF_EFFORT_LIMIT_UNDETECTED_average_values.pdf}
    \caption{Undetected Motor-Limit Condition}
    \label{fig:avg_mot_und}
  \end{subfigure}
  \hfill
  % 第四行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/avg_detail/DOF_VEL_LIMIT_average_values.pdf}
    \caption{Detected Velocity-Limit Condition}
    \label{fig:avg_vel_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/avg_detail/DOF_VEL_LIMIT_UNDETECTED_average_values.pdf}
    \caption{Undetected Velocity-Limit Condition}
    \label{fig:avg_vel_und}
  \end{subfigure}
  \hfill
  \caption{Average Performance of Five Methods Under Different Damage Conditions Across Three Tasks.}
  \label{fig:avg_detail_results}
\end{figure*}

\begin{figure*}[ht]
  \centering
  % 第一行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/NORMAL.pdf}
    \caption{Normal Condition}
    \label{fig:solo8_norm}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/OBS_LIMIT.pdf}
    \caption{Sensor-Damaged Condition}
    \label{fig:solo8_obslimit}
  \end{subfigure}
  \hfill
% 第二行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_UPPERLOWER_LIMIT.pdf}
    \caption{Detected ROM-Limit Condition}
    \label{fig:solo8_rom_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_UPPERLOWER_LIMIT_UNDETECTED.pdf}
    \caption{Undetected ROM-Limit Condition}
    \label{fig:solo8_rom_und}
  \end{subfigure}
  \hfill
  % 第三行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_EFFORT_LIMIT.pdf}
    \caption{Detected Motor-Limit Condition}
    \label{fig:solo8_mot_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_EFFORT_LIMIT_UNDETECTED.pdf}
    \caption{Undetected Motor-Limit Condition}
    \label{fig:solo8_mot_und}
  \end{subfigure}
  \hfill
  % 第四行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_VEL_LIMIT.pdf}
    \caption{Detected Velocity-Limit Condition}
    \label{fig:solo8_vel_det}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/g1_detail/DOF_VEL_LIMIT_UNDETECTED.pdf}
    \caption{Undetected Velocity-Limit Condition}
    \label{fig:solo8_vel_und}
  \end{subfigure}
  \hfill
  \caption{Performance Between UMC and `MT-FTC' Under Different Damage Conditions in the Solo8 Task.}
  \label{fig:solo8_detail_results}
\end{figure*}


In this section, we present all experimental results to highlight the overall superiority of our UMC framework across various damage scenarios under different tasks.

In the body of the paper, we have presented the overall performance of all methods across all tasks and damage conditions, so we will not repeat such details here. Instead, we display their performance under each task's eight damage scenarios. Specifically, \cref{fig:a1_detail_results} is for the A1-Walk task, \cref{fig:h1_detail_results} is for the Unitree-H1 task, \cref{fig:g1_detail_results} is for the Unitree-G1 task, and \cref{fig:solo8_detail_results} is for the Solo8 task (SOTA comparison). Additionally, we calculated the average performance of the three baselines and our two UMC methods across three tasks for each damage condition and show the results in \cref{fig:avg_detail_results}. These statistics demonstrate the superior performance of our UMC framework.

Also, as addressed in the main text, \cref{fig:a1_norm}, \cref{fig:h1_norm} and \cref{fig:g1_norm} illustrate that our UMC framework does not compromise the robot's mobility under normal conditions. On the contrary, as shown in \cref{fig:g1_norm}, UMC even reduces the failure rate of the MLP model by 18\% while also enhancing its task-completion performance in the Unitree-G1 task under normal scenarios.

In sum, by synthesizing the insights from these figures, we provide a comprehensive comparison of the strengths and weaknesses of each method, highlighting the advantages of the UMC framework.

\section{More Ablation Results}

\begin{table}[ht]
    \caption{Inference Parameters for Ablations in \cref{sec:abl_maskvalue} (except for the stage-count ablation).}
  \centering
    \begin{tabular}{@{}l|c@{}}
      \toprule
      Parameter & Values \\
      \midrule
      Task & A1 \\
      Num Envs & 4000  \\
      Random Damage Range & [4,5]  \\
      ROM Limit & Random 10\% \\
      Motor Limit & 8 \\
      Velocity Limit & 3 \\
      Track Width & 6.0 \\
      Track Block Length & 6.0 \\
      Border Size & 4 \\
      Perlin Noise Seed & 100 \\
      Random Malfunction Seed & 1 \\
      Malfunction Timing & 75 \\
 
      \bottomrule
    \end{tabular}


  \label{tab:abl_setting}
\end{table}

\begin{figure*}[ht]
  \centering
  % 第一行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/ablation/mvNratio/NORMAL.pdf}
    \caption{Normal Condition}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/ablation/mvNratio/OBS_LIMIT.pdf}
    \caption{Sensor-Damaged Condition}
  \end{subfigure}
  \hfill
% 第二行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/ablation/mvNratio/DOF_UPPERLOWER_LIMIT.pdf}
    \caption{Detected ROM-Limit Condition}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/ablation/mvNratio/DOF_UPPERLOWER_LIMIT_UNDETECTED.pdf}
    \caption{Undetected ROM-Limit Condition}
  \end{subfigure}
  \hfill
  % 第三行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/ablation/mvNratio/DOF_EFFORT_LIMIT.pdf}
    \caption{Detected Motor-Limit Condition}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/ablation/mvNratio/DOF_EFFORT_LIMIT_UNDETECTED.pdf}
    \caption{Undetected Motor-Limit Condition}
  \end{subfigure}
  \hfill
  % 第四行
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/ablation/mvNratio/DOF_VEL_LIMIT.pdf}
    \caption{Detected Velocity-Limit Condition}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.49\linewidth}
    \centering
    \includegraphics[width=\linewidth]{imgs/ablation/mvNratio/DOF_VEL_LIMIT_UNDETECTED.pdf}
    \caption{Undetected Velocity-Limit Condition}
  \end{subfigure}
  \hfill
  \caption{Full Comparison for the Ratio and Masking-Value Ablations Under Different Damage Conditions.}
  \label{fig:full_ablation_comparison}
\end{figure*}

All ablations, except for the training-stage one, are conducted under the A1 task with one inference damage setting under transformer-based UMC. \cref{tab:abl_setting} shows the parameter setting during those ablations. \cref{fig:full_ablation_comparison} demonstrates the performance of the ratio and masking-value ablation under eight specific damaged scenarios.


\section{Loss}
The total loss function in PPO adopted in our work is defined as:
\begin{equation}
\mathcal{L} = \mathcal{L}_{\text{surrogate}} + \lambda_{1} \cdot \mathcal{L}_{\text{value}} + \lambda_{2} \cdot \mathcal{L}_{\text{entropy}},
\end{equation}
where $\lambda_{1}$ and $\lambda_{2}$ denote weight parameters. \(\mathcal{L}_{\text{surrogate}}\) is illustrated in \cref{eq:surrogate}, \(\mathcal{L}_{\text{value}}\) is illustrated in \cref{eq:value}, and \(\mathcal{L}_{\text{entropy}}\) is an entropy regularization to encourage exploration. Gradient clipping is also applied to ensure stability during training.

The actor model in PPO is trained using a clipped surrogate loss to ensure that the updated policy does not deviate excessively from the previous policy. This clipping mechanism helps balance between exploring new actions and maintaining stability in learning. The loss function is defined as:
\begin{equation}
\mathcal{L}_{\text{surro}} = -\mathbb{E}_t \left[\min\left(r_t(\theta) \cdot A_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) \cdot A_t \right)\right],
\label{eq:surrogate}
\end{equation}
where \(t\) represents the timestep index within a trajectory. The ratio \( r_t(\theta) = \frac{\pi_\theta(a_t | s_t)}{\pi_{\theta_{\text{old}}}(a_t | s_t)} \) is the probability ratio between the new policy \(\pi_\theta(a_t | s_t)\) and the old policy \(\pi_{\theta_{\text{old}}}(a_t | s_t)\), reflecting how much the new policy has changed. The term \(A_t\) represents the advantage estimate at timestep \(t\), which indicates how much better or worse the action \(a_t\) is compared to the average action under the current policy. The advantage \(A_t\) is computed as:
\begin{equation}
A_t = \sum_{k=0}^{\infty} (\gamma \lambda)^k \delta_{t+k},
\label{eq:advantage}
\end{equation}
where \(\delta_{t+k}\) is the temporal difference residual at timestep \( t+k \), representing the error in predicting the future value of the state based on the current value function. \( \gamma \) is the discount factor, determining the importance of future rewards, and \( \lambda \) balances the bias-variance tradeoff in advantage estimation.





The critic model in UMC shares the same architecture as the actor model, except without the damage detection module, and it is trained using the value function loss to minimize the error between the predicted value \(V(s_t)\) and the target return \(R_t\):
\begin{equation}
\begin{split}
\mathcal{L}_{\text{value}} = \mathbb{E}_t \big[ & \max\big((V(s_t) - R_t)^2, \\
& \text{clip}(V(s_t), V_{\text{old}}(s_t) - \epsilon, V_{\text{old}}(s_t) + \epsilon) - R_t)^2\big)\big],
\end{split}
\label{eq:value}
\end{equation}
where \(V_{\text{old}}(s_t)\) is the previous value function estimate, and \(\epsilon\) is the clipping threshold to ensure stability during training.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
