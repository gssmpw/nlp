
\section{RQ1: When does Alignment Emerge?}\label{sec:align_emerge}

\begin{figure}[t!]
\centering
\includegraphics[width=0.75\linewidth]{figures/dino_align_unique.pdf}
\vspace{-1em}\caption{\textbf{Alignment vs uniqueness on real large-scale vision-language datasets}. Alignment is computed between DINOv2 vision models and large language models. Each dot is an independent run on a different model size on a dataset with a given level of uniqueness. The maximum achievable alignment decreases as uniqueness increases.}
\label{fig:real model alignments}
% \vspace{-1em}
\end{figure}

We empirically evaluate whether alignment emerges naturally by systematically varying redundancy, uniqueness, and heterogeneity. In the synthetic setting, the level of uniqueness $U$ denotes the number of unique features used in computing the label. In Figure~\ref{fig:align_unique}, we observe that as $U$ increases, the maximum alignment decreases across different model depths and transformation depths. A similar trend is evident in Figure~\ref{fig:real model alignments}, which examines the alignment between large-scale language models and DINOv2~\citep{oquab_dinov2_2023} vision models over different levels of $U$ is the percentage of perturbation. See Appendix~\ref{app:vision_language_align_unique} for experiments with more vision models. An additional experiment, detailed in Appendix~\ref{app:synthetic_align}, demonstrates that data heterogeneity is negatively correlated with the level of achievable alignment. Collectively, these experiments provide strong empirical evidence supporting the hypothesis that the level of alignment is indeed constrained by the degrees of heterogeneity and interactions between the modalities.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=1.01\linewidth]{figures/unbiased_cka_best_fixed_1_pairwise_align_heatmap_unique.pdf}
    \vspace{-2em}
    \caption{\textbf{Emergence of alignment across heterogeneity and uniqueness.} We plot alignment over increasing unimodal encoder depths for the transformed modality and different levels of heterogeneity. When redundancy is high, we see that alignment emerges when (\(D_{Enc} - D_{\phi}\)) is high. However, as uniqueness increases, the relationship between (\(D_{Enc} - D_{\phi}\)) and alignment is much weaker.}
    \label{fig:align_heatmap}
    \vspace{-1em}
\end{figure*}

We now investigate whether increasing model capacity can improve alignment between representations of increasingly heterogeneous and unique modalities. In Figure~\ref{fig:align_heatmap}, we plot alignment scores as a function of \((D_{Enc}, D_{\phi})\), where \(D_{Enc}\) represents the encoder depth and \(D_{\phi}\) represents the transformation depth of the second modality. When uniqueness is low, we observe that alignment improves significantly when the model capacity (relative to the transformation depth) is greater. This suggests that increased model capacity is effective in handling heterogeneity between modalities. Concretely, in these scenarios, alignment appears to follow the trend \((D_{Enc} - D_{\phi})~\propto~\mathrm{Alignment}\), meaning that the relative capacity of the encoder compensates for the complexity introduced by the transformation depth. However, as uniqueness increases, the relationship between alignment and relative model capacity becomes much weaker. In these cases, \((D_{Enc} - D_{\phi})\) no longer predicts higher alignment scores. This indicates that when modalities have a high level of unique information, simply increasing model capacity is insufficient to achieve higher alignment. Instead, other factors—such as the degree of shared information—may become the limiting factor in determining alignment.

In summary, while model size and capacity are correlated with alignment, there exists an upper limit to the level of achievable alignment, which is fundamentally determined by the intrinsic properties of the data. This finding implies that perfect alignment cannot be simultaneously achieved with optimal performance when the data modalities inherently differ in their information content. Moreover, increasing model depth only effectively aligns heterogeneous modalities when they contain highly redundant information and can fail for high uniqueness.

\section{RQ2: Is Alignment Correlated with Performance?}
\label{sec:align_perf}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.32\linewidth]{figures/unbiased_cka_best_pairwise_align_perf_vs_unique.pdf}
    \includegraphics[width=0.32\linewidth]{figures/unbiased_cka_best_pairwise_perf_depth_vs_unique.pdf}
    \includegraphics[width=0.32\linewidth]{figures/unbiased_cka_best_pairwise_align_depth_vs_unique.pdf}
    \vspace{-1em}
    \caption{\textbf{Alignment, performance, and depth correlation plots across different synthetic depths and experiment seeds.} In each plot, we show the spread of Pearson correlation coefficients for each level of uniqueness, where the orange lines are the median correlations and the dots are outliers. \textbf{Left}: When the two modalities are fully redundant, the alignment is strongly correlated with performance. When the two modalities have high uniqueness, alignment has a vanishing correlation with performance. In fact, for a significant proportion of tasks, the correlation is negative. \textbf{Mid}: In contrast, model size measured by depth always has a strong positive correlation with performance and does not seem to change across datasets. This means that representation alignment may not be a universal phenomenon, and is introduced by some special properties of data. In contrast, the influence of model size on performance seems universal and is consistent with the well-observed scaling laws. \textbf{Right}: For each level of uniqueness, we show the variance in alignment/depth correlation. As uniqueness increases, the median alignment/depth decreases to 0, and the range of correlation values increases significantly.}
    \label{fig:two correlations}
\end{figure*}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\linewidth]{figures/dino_align_perf_unique_labeled.pdf}
    \vspace{-2em}
    \caption{\textbf{Alignment vs performance across different uniqueness.} We plot the vision-language alignment using DINOv2 vision models with respect to language model performance, measured using negative \texttt{bits-per-byte-loss}. We show individual best fit lines for each size of vision model and the average Pearson correlation coefficient $r$. At $U=5$, we see that model performance highly correlates with model capacity. However, at $U=25$ and $U=45$, the correlation vanishes, and the best performing models are not those with most capacity, as smaller bloom models outperform all other models.}
    \label{fig:dino_align_perf_unique_labeled}
\end{figure*}

In this section, we systematically investigate the relationship between alignment and performance, identifying scenarios where alignment enhances performance and others where it may introduce unintended trade-offs.

\subsection{Alignment-performance vs interactions/uniqueness}
For each synthetic dataset, we analyze the relationship between alignment, performance, and model capacity. We include model capacity in our analysis as increased capacity generally leads to better performance and is assumed to correlate with better alignment. Our findings are summarized in Figure~\ref{fig:two correlations}, where we plot the correlations between alignment and performance across different dataset dimensions, where $U$ is defined in Section \ref{sec:align_emerge}. In highly redundant settings, the correlation between alignment and performance is strong, with relatively little variation across different levels of heterogeneity and random seeds. However, as uniqueness increases, the median correlation decreases toward zero, and the range of correlations expands significantly. Notably, for \( U > 3 \), the correlation even becomes negative in some cases, suggesting that higher uniqueness can disrupt the relationship between alignment and performance. A similar trend is observed when examining the correlation between alignment and model depth in Figure ~\ref{fig:two correlations} (right). As uniqueness increases, both the median correlation decreases and the variance in correlation increases substantially, with instances of anticorrelated alignment-depth relationships. While deeper models do not necessarily lead to better alignment when uniqueness is high, we see in Figure~\ref{fig:two correlations} (center) that performance and depth remain positively correlated across different levels of uniqueness, with much lower variance in correlation at higher uniqueness levels. This suggests that while alignment may not always be a reliable predictor of performance, increasing model capacity can still improve task performance. 

We next verify whether these findings extend to large vision-language models. In Figure~\ref{fig:dino_align_perf_unique_labeled}, we observe a strong correlation between alignment to DINOv2 and language model performance when uniqueness is low. However, this relationship weakens as uniqueness increases. By \(U=25\), models with lower alignment outperform those with higher alignment. As uniqueness increases further, the correlation between alignment and performance largely disappears. Additionally, we find that higher-performing language models are not necessarily those with greater capacity. This suggests that alignment and model size alone may not guarantee better performance in high-uniqueness settings. We include more analysis in Appendix~\ref{app:vision_language_align_perf} involving different vision model training schemes. Overall, our experiments on both synthetic data and large vision-language models indicate that as uniqueness increases, higher-performing models with greater capacity do not necessarily exhibit stronger alignment. This reinforces the conclusion that alignment does not always predict model effectiveness, particularly when the modalities contain significant amounts of unique information. 

\subsection{Alignment-performance vs heterogeneity}

Additionally, we analyze whether alignment correlates with performance across varying levels of heterogeneity in Figure~\ref{fig:align_perf_het_scatter}. Intuitively, we expect higher levels of heterogeneity to result in lower performance, but it is unclear whether this trend is reflected in alignment scores. Our findings show that while alignment and performance exhibit a strong linear relationship at low levels of uniqueness, this relationship weakens as uniqueness increases. Specifically, with higher uniqueness, models trained on similar modalities do not consistently achieve better alignment than those trained on heterogeneous modalities. This suggests that alignment does not uniformly degrade with increasing heterogeneity and that the interaction between uniqueness, heterogeneity, and alignment is more complex than a simple linear relationship. 
These results further reinforce the idea that alignment alone is not a sufficient predictor of model performance, especially in multimodal settings where modalities contain varying levels of interactions and heterogeneity.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\linewidth]{figures/unbiased_cka_best_align_perf_unique_scatter_last_depth_syn_depth.pdf}
    \vspace{-2em}
    \caption{\textbf{Alignment vs performance across levels of heterogeneity.} We plot the alignment and performance scores at different levels of heterogeneity, with the transformed modality's encoder fixed to the maximum transformation depth. At high levels of uniqueness, we see that high performance correlates with high alignment, with both being greater at lower synthetic depths. Past $U=4$, we see that while performance is higher at lower synthetic depths, the alignment scores on these datasets are not necessarily higher.}
    \label{fig:align_perf_het_scatter}
\end{figure*}


\begin{table*}[ht]
\centering
\begin{tabular}{c|c|c|c|c|c|c}
\hline
\multirow{2}{*}{\textbf{Dataset}} & \multicolumn{2}{c|}{\textbf{Vision - Audio}} & \multicolumn{2}{c|}{\textbf{Vision - Text}} & \multicolumn{2}{c}{\textbf{Audio - Text}} \\ \cline{2-7}
& Vision & Audio & Vision & Text & Audio & Text \\ \hline
MOSEI \cite{bagher_zadeh_multimodal_2018} &-0.193 & -0.154 & -0.154 & -0.351 & -0.158 &-0.366 \\
MOSI \cite{zadeh_mosi_2016} & -0.135 & 0.249 & 0.092 & -0.336 & 0.291 & -0.374 \\
URFUNNY \cite{hasan_ur-funny_2019} & -0.384 & -0.369 & -0.327 & 0.347 & -0.380 & 0.074 \\
MUStARD \cite{castro_towards_2019} & 0.404&  0.180 & 0.530 &  0.014 & 0.139 & 0.458 \\
AVMNIST \cite{perez-rua_mfas_2019}& 0.944 & 0.974 & - & - & - & - \\
\hline
\end{tabular}
\vspace{-2mm}
\caption{\textbf{Alignment-performance correlations on MultiBench.} We compute the correlation between model performance and alignment across 4 affective computing datasets with tasks that require unique information in vision, audio, and language modalities. We additionally benchmark on AVMNIST, a dataset with high redundancy as the modalities are images of digits and spoken digits for digit classification. On the affective computing datasets, the correlation is weak and often negative, suggesting that enforcing alignment between modalities may not be desirable. In contrast, the alignment of vision and audio modalities in AVMNIST is highly correlated with performance.}
\label{fig:real_correlation}
\vspace{-1em}
\end{table*}

\section{RQ3: Alignment-Performance Correlation is an Inherent Property of Datasets}

Finally, we investigate how the alignment-performance correlation varies across real-world multimodal datasets. Quantifying this relation is important to practitioners, as a positive alignment-performance correlation suggests that a practitioner can improve performance by explicitly aligning modalities. As shown in our experiments in Section \ref{sec:align_perf}, we expect that on tasks involving redundant information, alignment positively correlates with performance whereas for tasks that require unique information in modalities, the correlation may be weaker and not necessarily positive. 

We evaluate these hypotheses on a subset of datasets from MultiBench \cite{liang2021multibench} with varying degrees of task-relevant redundant and unique information content, including MOSEI ~\citep{bagher_zadeh_multimodal_2018}, a dataset for predicting emotions from videos (vision, audio, text); MOSI ~\citep{zadeh_mosi_2016}, a dataset for predicting sentiment from videos (vision, audio, text), URFUNNY ~\citep{hasan_ur-funny_2019}, a humor detection dataset from videos (vision, audio, text); MUSTARD ~\citep{castro_towards_2019}, a sarcasm detection dataset from TV shows (vision, audio, text); and AVMNIST~\citep{perez-rua_mfas_2019}, a dataset for digit classification from paired images and spoken digits (vision, audio). See Appendix \ref{app:multibench} for details about the datasets. For each modality, we train transformers with varying depths and compute the cross-modal alignment. See Appendix \ref{app:experiment_details} for details on our experiment setup. 

We show these results in Table \ref{fig:real_correlation}. On sentiment analysis tasks that typically require unique information from language, alignment and performance are weakly correlated or even negatively correlated. For a given dataset, the alignment-performance relationship can even vary between different modalities. For example, on MUStARD, alignment is more highly correlated with vision performance, whereas audio and text performance do not seem as correlated. On AVMNIST, alignment strongly correlates with performance for both modalities, as the information content is largely redundant information about the digit identity. These results corroborate our findings that the alignment-performance relationship heavily depends on dataset characteristics.
