\vspace{-4mm}
\section{Introduction}

Multimodal AI represents a cutting-edge paradigm in machine learning that enables integrating and learning from many heterogeneous and interacting data modalities. These AI systems are revolutionizing predictive analytics across many applications, including in multimedia~\citep{alayrac2022flamingo,sun2019videobert,ramesh2021zero,singer2022make}, healthcare~\citep{cai2019survey,muhammad2021comprehensive}, and physical sensing~\citep{kirchner2019embedded,lee2019making,xiao2020multimodal}. A large body of research in designing and training multimodal models has focused on \textit{aligning} the representations from different modalities such that they are comparable in some semantic representation space~\citep{baltruvsaitis2018multimodal,liang2024foundations}. Conventional wisdom posits that aligned representations are a crucial precursor to multimodal fusion and representation learning~\citep{li2021align}. As a result, many learning methods, such as contrastive learning and its variants~\cite{frome2013devise,jia2021scaling,radford2021learning}, and model architectures~\citep{bertinetto2016fully,lenc_understanding_2019,bansal_revisiting_2021, csiszarik_similarity_2021} have been proposed to explicitly align incomparable modalities into comparable representation spaces for further processing.

\begin{figure}
    \centering
    \vspace{-6mm}
    \includegraphics[width=\linewidth]{figures/platonic_main.pdf}
    \vspace{-8mm}
    \caption{\textbf{Emergence of multimodal alignment?} While the Platonic Representation Hypothesis~\citep{huh_platonic_2024} argues that better alignment predicts better performance, our findings demonstrate that the relation between alignment and performance is more nuanced and depends on several dataset characteristics including the degree of heterogeneity and interactions between modalities.}
    \vspace{-4mm}
    \label{fig:intro}
\end{figure} 

However, recent work on the ``Platonic Representation Hypothesis'' showed that, surprisingly, alignment could even emerge across independently pre-trained vision and language models without explicitly aligning them together~\cite{huh_platonic_2024}. Crucially, alignment increases with model size and performance, and it has been hypothesized that unimodal models will become increasingly aligned. These findings raise fundamental questions regarding the emergence of aligned representations and their implications on multimodal learning: (1) when and why does alignment emerge implicitly, and (2) is alignment a reliable indicator of performance? We illustrate these open questions in Figure~\ref{fig:intro}.

In this paper, we study these questions comprehensively across two principal dimensions that taxonomize multimodal data: \textit{interactions} and \textit{heterogeneity}~\citep{baltruvsaitis2018multimodal,liang2024foundations,tian2020makes}, visualized in Figure~\ref{fig:dimensions}. Interactions measure the information shared between two modalities for a task, from more redundant (e.g., images and corresponding captions) to more unique (e.g., sensor placement). We expect alignment to emerge more easily between redundant modalities. Heterogeneity measures the degree of similarity across two modalities independent of the task, from more similar (e.g., two languages) to more different (e.g., text and video). We expect alignment to emerge more easily between similar modalities.

Through extensive experiments on controlled and real-world datasets with varying degrees of interactions and heterogeneity, we discover several key insights. First, the maximum alignment achievable depends on the degree of heterogeneity and uniqueness in the modalities, which inherently limits alignment. Second, while alignment correlates with performance in datasets with high redundancy, this relationship breaks down when uniqueness dominates redundancy. These findings highlight that performance often does not directly correspond to alignment, and the connection between them is a nuanced property of the data that varies across modalities and tasks. Therefore, our work provides important considerations for practitioners designing and training multimodal models, emphasizing that scale alone does not guarantee modality alignment and that careful assessment is necessary to determine when alignment is beneficial.

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/venn_diagrams.pdf}
    \caption{\textbf{Two principal dimensions of multimodal data.} This study empirically evaluates data across two key dimensions: heterogeneity and interactions. Heterogeneity, represented on the x-axis, reflects the similarity between two data modalities regardless of the task, while interactions, on the y-axis, indicate the balance between redundant and unique task-relevant information across modalities. We expect the Platonic Representation Hypothesis to hold in cases of redundancy and similar modalities, but when and why alignment emerges implicitly, and whether alignment is a reliable indicator of performance, remain open questions.}
    \label{fig:dimensions}
\end{figure}