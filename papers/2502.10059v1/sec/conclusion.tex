\section{Limitation Analysis and Future Work}
% Despite the robust performance of RealCam-I2V in generating video sequences within real-world, static environments, several limitations persist due to the nature of our training data and current model constraints. 
The model was trained on datasets such as RealEstate10K, which consists primarily of real-world, indoor and outdoor videos collected from YouTube. This dataset’s content focuses heavily on realistic, static scenes, resulting in a model that excels in these contexts but performs less effectively when applied to scenes with significantly different visual styles, such as anime, oil paintings, or cartoon-like aesthetics. 
Better data quality, designing algorithm or improving the ability of fundamental model especially in long video generation will be considered into the future research.
% Additionally, performance may decrease in dynamic scenes where multiple elements move independently, as the training data lacks such complexity.
% Another limitation stems from the camera movement characteristics within the training dataset. Since RealEstate10K captures footage with relatively moderate camera speeds, the model is best suited for trajectories that involve gradual movements. The temporal attention mechanisms employed by our approach—similar to those used in other state-of-the-art models—primarily support small, continuous displacements, and they struggle to maintain continuity when handling larger, abrupt shifts in perspective. 
% Consequently, if the user specifies a rapid or complex camera trajectory with large positional shifts, the model may fail to generate coherent frames, resulting in visual artifacts or generation breakdowns.
% To address these limitations, future research could explore several directions. First, incorporating datasets with a broader range of visual styles and dynamic content would enhance the model’s versatility, allowing it to generalize to a wider array of scene types, including animated and stylized environments.
% Additionally, extending the temporal attention mechanism to support a broader spectrum of camera movements, including rapid shifts, could improve the model’s ability to handle fast-paced trajectories without compromising continuity. This could involve exploring more sophisticated attention modules that can process and adapt to rapid frame-to-frame transitions or incorporating additional temporal conditioning mechanisms.

\section{Potential Negative Societal Impacts}
The image-to-video generation technology developed in this work, with its enhanced camera controllability and breakthrough in real-world applications holds the potential for misuse, particularly in the creation of falsified or deceptive video content. 
The ability to precisely control camera movements and generate realistic sequences from single images could be exploited to produce convincing yet fabricated videos, leading to ethical concerns around misinformation and privacy violations. 
To mitigate these risks, we advocate for responsible usage and adherence to ethical guidelines when deploying the RealCam-I2V model. 
% Researchers and practitioners should remain vigilant about the potential misuse of this technology, ensuring that it is applied in contexts that align with ethical standards and contribute positively to society.

\section{Conclusion}
\label{sec:conclusion}
In this paper, we address the scale inconsistencies and real-world usability challenges in existing trajectory-based camera-controlled image-to-video generation methods. We introduce a simple yet effective monocular 3D reconstruction into the preprocessing step of the generation pipeline, serving as a reliable intermediary reference for both training and inference. With reconstructed 3D scene, we enable absolute-scale training and provide an interactive interface during inference to easily design camera trajectories with preview feedback, along with proposed scene-constrained noise shaping to significantly enhance scene consistency and camera controllability. Our method overcomes critical real-world application challenges and achieves substantial improvements on the RealEstate10K dataset, establishing a new sota both in video quality and control precision.
