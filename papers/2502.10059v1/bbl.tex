\begin{thebibliography}{78}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bahmani et~al.(2024)Bahmani, Skorokhodov, Siarohin, Menapace, Qian, Vasilkovsky, Lee, Wang, Zou, Tagliasacchi, et~al.]{bahmani2024vd3d}
Sherwin Bahmani, Ivan Skorokhodov, Aliaksandr Siarohin, Willi Menapace, Guocheng Qian, Michael Vasilkovsky, Hsin-Ying Lee, Chaoyang Wang, Jiaxu Zou, Andrea Tagliasacchi, et~al.
\newblock Vd3d: Taming large video diffusion transformers for 3d camera control.
\newblock \emph{arXiv preprint arXiv:2407.12781}, 2024.

\bibitem[Blattmann et~al.(2023{\natexlab{a}})Blattmann, Dockhorn, Kulal, Mendelevitch, Kilian, Lorenz, Levi, English, Voleti, Letts, et~al.]{Blattmann2023}
Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, et~al.
\newblock Stable video diffusion: Scaling latent video diffusion models to large datasets.
\newblock \emph{arXiv preprint arXiv:2311.15127}, 2023{\natexlab{a}}.

\bibitem[Blattmann et~al.(2023{\natexlab{b}})Blattmann, Rombach, Ling, Dockhorn, Kim, Fidler, and Kreis]{Blattmann2023a}
Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung~Wook Kim, Sanja Fidler, and Karsten Kreis.
\newblock Align your latents: High-resolution video synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 22563--22575, 2023{\natexlab{b}}.

\bibitem[Brooks et~al.(2024)Brooks, Peebles, Holmes, DePue, Guo, Jing, Schnurr, Taylor, Luhman, Luhman, et~al.]{brooks2024video}
Tim Brooks, Bill Peebles, Connor Holmes, Will DePue, Yufei Guo, Li Jing, David Schnurr, Joe Taylor, Troy Luhman, Eric Luhman, et~al.
\newblock Video generation models as world simulators, 2024.

\bibitem[Chefer et~al.(2024)Chefer, Zada, Paiss, Ephrat, Tov, Rubinstein, Wolf, Dekel, Michaeli, and Mosseri]{chefer2024still}
Hila Chefer, Shiran Zada, Roni Paiss, Ariel Ephrat, Omer Tov, Michael Rubinstein, Lior Wolf, Tali Dekel, Tomer Michaeli, and Inbar Mosseri.
\newblock Still-moving: Customized video generation without customized video data.
\newblock \emph{arXiv preprint arXiv:2407.08674}, 2024.

\bibitem[Chen et~al.(2024{\natexlab{a}})Chen, Shu, Chen, He, Wang, and Li]{chen2024motion}
Changgu Chen, Junwei Shu, Lianggangxu Chen, Gaoqi He, Changbo Wang, and Yang Li.
\newblock Motion-zero: Zero-shot moving object control framework for diffusion-based video generation.
\newblock \emph{arXiv preprint arXiv:2401.10150}, 2024{\natexlab{a}}.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Xia, He, Zhang, Cun, Yang, Xing, Liu, Chen, Wang, et~al.]{chen2023videocrafter1}
Haoxin Chen, Menghan Xia, Yingqing He, Yong Zhang, Xiaodong Cun, Shaoshu Yang, Jinbo Xing, Yaofang Liu, Qifeng Chen, Xintao Wang, et~al.
\newblock Videocrafter1: Open diffusion models for high-quality video generation.
\newblock \emph{arXiv preprint arXiv:2310.19512}, 2023{\natexlab{a}}.

\bibitem[Chen et~al.(2024{\natexlab{b}})Chen, Zhang, Cun, Xia, Wang, Weng, and Shan]{chen2024videocrafter2}
Haoxin Chen, Yong Zhang, Xiaodong Cun, Menghan Xia, Xintao Wang, Chao Weng, and Ying Shan.
\newblock Videocrafter2: Overcoming data limitations for high-quality video diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7310--7320, 2024{\natexlab{b}}.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Wang, Zhang, Zhuang, Ma, Yu, Wang, Lin, Qiao, and Liu]{chen2023seine}
Xinyuan Chen, Yaohui Wang, Lingjun Zhang, Shaobin Zhuang, Xin Ma, Jiashuo Yu, Yali Wang, Dahua Lin, Yu Qiao, and Ziwei Liu.
\newblock Seine: Short-to-long video diffusion model for generative transition and prediction.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2023{\natexlab{b}}.

\bibitem[Feng et~al.(2024)Feng, Liu, Tu, Qi, Sun, Ma, Zhao, Zhou, and He]{feng2024i2vcontrol}
Wanquan Feng, Jiawei Liu, Pengqi Tu, Tianhao Qi, Mingzhen Sun, Tianxiang Ma, Songtao Zhao, Siyu Zhou, and Qian He.
\newblock I2vcontrol-camera: Precise video camera control with adjustable motion strength.
\newblock \emph{arXiv preprint arXiv:2411.06525}, 2024.

\bibitem[Ge et~al.(2023)Ge, Nah, Liu, Poon, Tao, Catanzaro, Jacobs, Huang, Liu, and Balaji]{ge2023preserve}
Songwei Ge, Seungjun Nah, Guilin Liu, Tyler Poon, Andrew Tao, Bryan Catanzaro, David Jacobs, Jia-Bin Huang, Ming-Yu Liu, and Yogesh Balaji.
\newblock Preserve your own correlation: A noise prior for video diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 22930--22941, 2023.

\bibitem[Girdhar et~al.(2023)Girdhar, Singh, Brown, Duval, Azadi, Rambhatla, Shah, Yin, Parikh, and Misra]{girdhar2023emu}
Rohit Girdhar, Mannat Singh, Andrew Brown, Quentin Duval, Samaneh Azadi, Sai~Saketh Rambhatla, Akbar Shah, Xi Yin, Devi Parikh, and Ishan Misra.
\newblock Emu video: Factorizing text-to-video generation by explicit image conditioning.
\newblock \emph{arXiv preprint arXiv:2311.10709}, 2023.

\bibitem[Gong et~al.(2024)Gong, Zhu, Li, Kang, Wang, Ge, and Zheng]{gong2024atomovideo}
Litong Gong, Yiran Zhu, Weijie Li, Xiaoyang Kang, Biao Wang, Tiezheng Ge, and Bo Zheng.
\newblock Atomovideo: High fidelity image-to-video generation.
\newblock \emph{arXiv preprint arXiv:2403.01800}, 2024.

\bibitem[Guo et~al.(2023)Guo, Yang, Rao, Liang, Wang, Qiao, Agrawala, Lin, and Dai]{Guo2023}
Yuwei Guo, Ceyuan Yang, Anyi Rao, Zhengyang Liang, Yaohui Wang, Yu Qiao, Maneesh Agrawala, Dahua Lin, and Bo Dai.
\newblock Animatediff: Animate your personalized text-to-image diffusion models without specific tuning.
\newblock \emph{arXiv preprint arXiv:2307.04725}, 2023.

\bibitem[Guo et~al.(2025)Guo, Yang, Rao, Agrawala, Lin, and Dai]{guo2025sparsectrl}
Yuwei Guo, Ceyuan Yang, Anyi Rao, Maneesh Agrawala, Dahua Lin, and Bo Dai.
\newblock Sparsectrl: Adding sparse controls to text-to-video diffusion models.
\newblock In \emph{European Conference on Computer Vision}, pages 330--348. Springer, 2025.

\bibitem[He et~al.(2024{\natexlab{a}})He, Xu, Guo, Wetzstein, Dai, Li, and Yang]{He2024Cameractrl}
Hao He, Yinghao Xu, Yuwei Guo, Gordon Wetzstein, Bo Dai, Hongsheng Li, and Ceyuan Yang.
\newblock Cameractrl: Enabling camera control for text-to-video generation.
\newblock \emph{arXiv preprint arXiv:2404.02101}, 2024{\natexlab{a}}.

\bibitem[He et~al.(2024{\natexlab{b}})He, Huang, Zhang, Lin, Wu, Yang, Li, Chen, Xu, and Wu]{he2024co}
Xu He, Qiaochu Huang, Zhensong Zhang, Zhiwei Lin, Zhiyong Wu, Sicheng Yang, Minglei Li, Zhiyi Chen, Songcen Xu, and Xiaofei Wu.
\newblock Co-speech gesture video generation via motion-decoupled diffusion model.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 2263--2273, 2024{\natexlab{b}}.

\bibitem[He et~al.(2022)He, Yang, Zhang, Shan, and Chen]{he2022latent}
Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, and Qifeng Chen.
\newblock Latent video diffusion models for high-fidelity long video generation.
\newblock \emph{arXiv preprint arXiv:2211.13221}, 2022.

\bibitem[Hou et~al.(2024)Hou, Wei, Zeng, and Chen]{hou2024training}
Chen Hou, Guoqiang Wei, Yan Zeng, and Zhibo Chen.
\newblock Training-free camera control for video generation.
\newblock \emph{arXiv preprint arXiv:2406.10126}, 2024.

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen]{hu2021lora}
Edward~J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen.
\newblock Lora: Low-rank adaptation of large language models.
\newblock \emph{arXiv preprint arXiv:2106.09685}, 2021.

\bibitem[Hu(2024)]{hu2024animate}
Li Hu.
\newblock Animate anyone: Consistent and controllable image-to-video synthesis for character animation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 8153--8163, 2024.

\bibitem[Hu et~al.(2024)Hu, Zhang, Yi, Wang, Huang, Weng, Wang, and Ma]{hu2024motionmaster}
Teng Hu, Jiangning Zhang, Ran Yi, Yating Wang, Hongrui Huang, Jieyu Weng, Yabiao Wang, and Lizhuang Ma.
\newblock Motionmaster: Training-free camera motion transfer for video generation.
\newblock \emph{arXiv preprint arXiv:2404.15789}, 2024.

\bibitem[Huang et~al.(2024)Huang, Zhang, Xu, He, Yu, Dong, Ma, Chanpaisit, Si, Jiang, et~al.]{huang2024vbench++}
Ziqi Huang, Fan Zhang, Xiaojie Xu, Yinan He, Jiashuo Yu, Ziyue Dong, Qianli Ma, Nattapol Chanpaisit, Chenyang Si, Yuming Jiang, et~al.
\newblock Vbench++: Comprehensive and versatile benchmark suite for video generative models.
\newblock \emph{arXiv preprint arXiv:2411.13503}, 2024.

\bibitem[Jain et~al.(2024)Jain, Nasery, Vineet, and Behl]{jain2024peekaboo}
Yash Jain, Anshul Nasery, Vibhav Vineet, and Harkirat Behl.
\newblock Peekaboo: Interactive video generation via masked-diffusion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 8079--8088, 2024.

\bibitem[Jiang et~al.(2024{\natexlab{a}})Jiang, Zheng, Li, Yang, Wang, and Li]{jiang2024survey}
Rui Jiang, Guang-Cong Zheng, Teng Li, Tian-Rui Yang, Jing-Dong Wang, and Xi Li.
\newblock A survey of multimodal controllable diffusion models.
\newblock \emph{Journal of Computer Science and Technology}, 39\penalty0 (3):\penalty0 509--541, 2024{\natexlab{a}}.

\bibitem[Jiang et~al.(2024{\natexlab{b}})Jiang, Wu, Yang, Si, Lin, Qiao, Loy, and Liu]{jiang2024videobooth}
Yuming Jiang, Tianxing Wu, Shuai Yang, Chenyang Si, Dahua Lin, Yu Qiao, Chen~Change Loy, and Ziwei Liu.
\newblock Videobooth: Diffusion-based video generation with image prompts.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 6689--6700, 2024{\natexlab{b}}.

\bibitem[Kuang et~al.(2024)Kuang, Cai, He, Xu, Li, Guibas, and Wetzstein]{kuang2024collaborative}
Zhengfei Kuang, Shengqu Cai, Hao He, Yinghao Xu, Hongsheng Li, Leonidas Guibas, and Gordon Wetzstein.
\newblock Collaborative video diffusion: Consistent multi-video generation with camera control.
\newblock \emph{arXiv preprint arXiv:2405.17414}, 2024.

\bibitem[Li et~al.(2024{\natexlab{a}})Li, Wang, Zhang, Wang, Yuan, Xie, Zou, and Shan]{li2024image}
Yaowei Li, Xintao Wang, Zhaoyang Zhang, Zhouxia Wang, Ziyang Yuan, Liangbin Xie, Yuexian Zou, and Ying Shan.
\newblock Image conductor: Precision control for interactive video synthesis.
\newblock \emph{arXiv preprint arXiv:2406.15339}, 2024{\natexlab{a}}.

\bibitem[Li et~al.(2024{\natexlab{b}})Li, Tucker, Snavely, and Holynski]{li2024generative}
Zhengqi Li, Richard Tucker, Noah Snavely, and Aleksander Holynski.
\newblock Generative image dynamics.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 24142--24153, 2024{\natexlab{b}}.

\bibitem[Ma et~al.(2024{\natexlab{a}})Ma, Wang, Jia, Chen, Liu, Li, Chen, and Qiao]{Ma2024}
Xin Ma, Yaohui Wang, Gengyun Jia, Xinyuan Chen, Ziwei Liu, Yuan-Fang Li, Cunjian Chen, and Yu Qiao.
\newblock Latte: Latent diffusion transformer for video generation.
\newblock \emph{arXiv preprint arXiv:2401.03048}, 2024{\natexlab{a}}.

\bibitem[Ma et~al.(2024{\natexlab{b}})Ma, He, Cun, Wang, Chen, Li, and Chen]{ma2024follow}
Yue Ma, Yingqing He, Xiaodong Cun, Xintao Wang, Siran Chen, Xiu Li, and Qifeng Chen.
\newblock Follow your pose: Pose-guided text-to-video generation using pose-free videos.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, pages 4117--4125, 2024{\natexlab{b}}.

\bibitem[Meng et~al.(2021)Meng, He, Song, Song, Wu, Zhu, and Ermon]{meng2021sdedit}
Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon.
\newblock Sdedit: Guided image synthesis and editing with stochastic differential equations.
\newblock \emph{arXiv preprint arXiv:2108.01073}, 2021.

\bibitem[Mou et~al.(2024)Mou, Wang, Xie, Wu, Zhang, Qi, and Shan]{Mou2024}
Chong Mou, Xintao Wang, Liangbin Xie, Yanze Wu, Jian Zhang, Zhongang Qi, and Ying Shan.
\newblock T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, pages 4296--4304, 2024.

\bibitem[Namekata et~al.(2024)Namekata, Bahmani, Wu, Kant, Gilitschenski, and Lindell]{namekata2024sg}
Koichi Namekata, Sherwin Bahmani, Ziyi Wu, Yash Kant, Igor Gilitschenski, and David~B Lindell.
\newblock Sg-i2v: Self-guided trajectory control in image-to-video generation.
\newblock \emph{arXiv preprint arXiv:2411.04989}, 2024.

\bibitem[Pan et~al.(2024)Pan, Barath, Pollefeys, and Sch\"{o}nberger]{pan2024glomap}
Linfei Pan, Daniel Barath, Marc Pollefeys, and Johannes~Lutz Sch\"{o}nberger.
\newblock {Global Structure-from-Motion Revisited}.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, 2024.

\bibitem[Peebles and Xie(2023)]{Peebles2023}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4195--4205, 2023.

\bibitem[Peng et~al.(2024)Peng, Wang, Zhang, Li, Yang, and Jia]{peng2024controlnext}
Bohao Peng, Jian Wang, Yuechen Zhang, Wenbo Li, Ming-Chang Yang, and Jiaya Jia.
\newblock Controlnext: Powerful and efficient control for image and video generation.
\newblock \emph{arXiv preprint arXiv:2408.06070}, 2024.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{CVPR}, 2022.

\bibitem[Schonberger and Frahm(2016)]{Schonberger2016}
Johannes~L Schonberger and Jan-Michael Frahm.
\newblock Structure-from-motion revisited.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 4104--4113, 2016.

\bibitem[Song et~al.(2020)Song, Meng, and Ermon]{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock \emph{arXiv preprint arXiv:2010.02502}, 2020.

\bibitem[Song et~al.(2024)Song, Zhu, Liu, Yan, Elgammal, and Yang]{song2024moma}
Kunpeng Song, Yizhe Zhu, Bingchen Liu, Qing Yan, Ahmed Elgammal, and Xiao Yang.
\newblock Moma: Multimodal llm adapter for fast personalized image generation.
\newblock \emph{arXiv preprint arXiv:2404.05674}, 2024.

\bibitem[Tang et~al.(2023)Tang, Yang, Zhu, Zeng, and Bansal]{tang2023anytoany}
Zineng Tang, Ziyi Yang, Chenguang Zhu, Michael Zeng, and Mohit Bansal.
\newblock Any-to-any generation via composable diffusion.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Tian et~al.(2024)Tian, Wang, Zhang, and Bo]{tian2024emo}
Linrui Tian, Qi Wang, Bang Zhang, and Liefeng Bo.
\newblock Emo: Emote portrait alive-generating expressive portrait videos with audio2video diffusion model under weak conditions.
\newblock \emph{arXiv preprint arXiv:2402.17485}, 2024.

\bibitem[Tseng et~al.(2023)Tseng, Li, Kim, Alsisan, Huang, and Kopf]{tseng2023consistent}
Hung-Yu Tseng, Qinbo Li, Changil Kim, Suhib Alsisan, Jia-Bin Huang, and Johannes Kopf.
\newblock Consistent view synthesis with pose-guided diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 16773--16783, 2023.

\bibitem[Unterthiner et~al.(2018)Unterthiner, Van~Steenkiste, Kurach, Marinier, Michalski, and Gelly]{Unterthiner2018}
Thomas Unterthiner, Sjoerd Van~Steenkiste, Karol Kurach, Raphael Marinier, Marcin Michalski, and Sylvain Gelly.
\newblock Towards accurate generative models of video: A new metric \& challenges.
\newblock \emph{arXiv preprint arXiv:1812.01717}, 2018.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Yuan, Chen, Zhang, Wang, and Zhang]{wang2023modelscope}
Jiuniu Wang, Hangjie Yuan, Dayou Chen, Yingya Zhang, Xiang Wang, and Shiwei Zhang.
\newblock Modelscope text-to-video technical report.
\newblock \emph{arXiv preprint arXiv:2308.06571}, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Li, Lin, Lin, Yang, Zhang, Liu, and Wang]{wang2023disco}
Tan Wang, Linjie Li, Kevin Lin, Chung-Ching Lin, Zhengyuan Yang, Hanwang Zhang, Zicheng Liu, and Lijuan Wang.
\newblock Disco: Disentangled control for referring human dance generation in real world.
\newblock \emph{arXiv e-prints}, pages arXiv--2307, 2023{\natexlab{b}}.

\bibitem[Wang et~al.(2024{\natexlab{a}})Wang, Yang, Tuo, He, Zhu, Fu, and Liu]{wang2024videofactory}
Wenjing Wang, Huan Yang, Zixi Tuo, Huiguo He, Junchen Zhu, Jianlong Fu, and Jiaying Liu.
\newblock Videofactory: Swap attention in spatiotemporal diffusions for text-to-video generation, 2024{\natexlab{a}}.

\bibitem[Wang et~al.(2024{\natexlab{b}})Wang, Yuan, Zhang, Chen, Wang, Zhang, Shen, Zhao, and Zhou]{wang2024videocomposer}
Xiang Wang, Hangjie Yuan, Shiwei Zhang, Dayou Chen, Jiuniu Wang, Yingya Zhang, Yujun Shen, Deli Zhao, and Jingren Zhou.
\newblock Videocomposer: Compositional video synthesis with motion controllability.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024{\natexlab{b}}.

\bibitem[Wang et~al.(2023{\natexlab{c}})Wang, Chen, Ma, Zhou, Huang, Wang, Yang, He, Yu, Yang, et~al.]{wang2023lavie}
Yaohui Wang, Xinyuan Chen, Xin Ma, Shangchen Zhou, Ziqi Huang, Yi Wang, Ceyuan Yang, Yinan He, Jiashuo Yu, Peiqing Yang, et~al.
\newblock Lavie: High-quality video generation with cascaded latent diffusion models.
\newblock \emph{arXiv preprint arXiv:2309.15103}, 2023{\natexlab{c}}.

\bibitem[Wang et~al.(2024{\natexlab{c}})Wang, Li, Xie, Zhu, Guo, Dou, and Li]{wang2024customvideo}
Zhao Wang, Aoxue Li, Enze Xie, Lingting Zhu, Yong Guo, Qi Dou, and Zhenguo Li.
\newblock Customvideo: Customizing text-to-video generation with multiple subjects.
\newblock \emph{arXiv preprint arXiv:2401.09962}, 2024{\natexlab{c}}.

\bibitem[Wang et~al.(2024{\natexlab{d}})Wang, Yuan, Wang, Li, Chen, Xia, Luo, and Shan]{Wang2024Motionctrl}
Zhouxia Wang, Ziyang Yuan, Xintao Wang, Yaowei Li, Tianshui Chen, Menghan Xia, Ping Luo, and Ying Shan.
\newblock Motionctrl: A unified and flexible motion controller for video generation.
\newblock In \emph{ACM SIGGRAPH 2024 Conference Papers}, pages 1--11, 2024{\natexlab{d}}.

\bibitem[Watson et~al.(2024)Watson, Saxena, Li, Tagliasacchi, and Fleet]{watson2024controlling}
Daniel Watson, Saurabh Saxena, Lala Li, Andrea Tagliasacchi, and David~J Fleet.
\newblock Controlling space and time with diffusion models.
\newblock \emph{arXiv preprint arXiv:2407.07860}, 2024.

\bibitem[Wu et~al.(2024{\natexlab{a}})Wu, Li, Zeng, Zhang, Zhou, Li, Tong, and Chen]{wu2024motionbooth}
Jianzong Wu, Xiangtai Li, Yanhong Zeng, Jiangning Zhang, Qianyu Zhou, Yining Li, Yunhai Tong, and Kai Chen.
\newblock Motionbooth: Motion-aware customized text-to-video generation.
\newblock \emph{arXiv preprint arXiv:2406.17758}, 2024{\natexlab{a}}.

\bibitem[Wu et~al.(2024{\natexlab{b}})Wu, Li, Qi, Hu, Wang, Shan, and Li]{wu2024spherediffusion}
Tao Wu, Xuewei Li, Zhongang Qi, Di Hu, Xintao Wang, Ying Shan, and Xi Li.
\newblock Spherediffusion: Spherical geometry-aware distortion resilient diffusion model.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, pages 6126--6134, 2024{\natexlab{b}}.

\bibitem[Wu et~al.(2024{\natexlab{c}})Wu, Zhang, Wang, Zhou, Zheng, Qi, Shan, and Li]{wu2024customcrafter}
Tao Wu, Yong Zhang, Xintao Wang, Xianpan Zhou, Guangcong Zheng, Zhongang Qi, Ying Shan, and Xi Li.
\newblock Customcrafter: Customized video generation with preserving motion and concept composition abilities.
\newblock \emph{arXiv preprint arXiv:2408.13239}, 2024{\natexlab{c}}.

\bibitem[Wu et~al.(2024{\natexlab{d}})Wu, Zhou, Ma, Su, Ma, and Wang]{wu2024ifadapter}
Yinwei Wu, Xianpan Zhou, Bing Ma, Xuefeng Su, Kai Ma, and Xinchao Wang.
\newblock Ifadapter: Instance feature control for grounded text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2409.08240}, 2024{\natexlab{d}}.

\bibitem[Xing et~al.(2023)Xing, Xia, Zhang, Chen, Wang, Wong, and Shan]{Xing2023}
Jinbo Xing, Menghan Xia, Yong Zhang, Haoxin Chen, Xintao Wang, Tien-Tsin Wong, and Ying Shan.
\newblock Dynamicrafter: Animating open-domain images with video diffusion priors.
\newblock \emph{arXiv preprint arXiv:2310.12190}, 2023.

\bibitem[Xu et~al.(2024{\natexlab{a}})Xu, Jiang, Huang, Song, Gernoth, Cao, Wang, and Tang]{xu2024cavia}
Dejia Xu, Yifan Jiang, Chen Huang, Liangchen Song, Thorsten Gernoth, Liangliang Cao, Zhangyang Wang, and Hao Tang.
\newblock Cavia: Camera-controllable multi-view video diffusion with view-integrated attention.
\newblock \emph{arXiv preprint arXiv:2410.10774}, 2024{\natexlab{a}}.

\bibitem[Xu et~al.(2024{\natexlab{b}})Xu, Nie, Liu, Liu, Kautz, Wang, and Vahdat]{Xu2024}
Dejia Xu, Weili Nie, Chao Liu, Sifei Liu, Jan Kautz, Zhangyang Wang, and Arash Vahdat.
\newblock Camco: Camera-controllable 3d-consistent image-to-video generation.
\newblock \emph{arXiv preprint arXiv:2406.02509}, 2024{\natexlab{b}}.

\bibitem[Xu et~al.(2024{\natexlab{c}})Xu, Nie, Liu, Liu, Kautz, Wang, and Vahdat]{xu2024camco}
Dejia Xu, Weili Nie, Chao Liu, Sifei Liu, Jan Kautz, Zhangyang Wang, and Arash Vahdat.
\newblock Camco: Camera-controllable 3d-consistent image-to-video generation.
\newblock \emph{arXiv preprint arXiv:2406.02509}, 2024{\natexlab{c}}.

\bibitem[Xu et~al.(2024{\natexlab{d}})Xu, Zhang, Liew, Yan, Liu, Zhang, Feng, and Shou]{xu2024magicanimate}
Zhongcong Xu, Jianfeng Zhang, Jun~Hao Liew, Hanshu Yan, Jia-Wei Liu, Chenxu Zhang, Jiashi Feng, and Mike~Zheng Shou.
\newblock Magicanimate: Temporally consistent human image animation using diffusion model.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 1481--1490, 2024{\natexlab{d}}.

\bibitem[Yang et~al.(2024{\natexlab{a}})Yang, Kang, Huang, Zhao, Xu, Feng, and Zhao]{depth_anything_v2}
Lihe Yang, Bingyi Kang, Zilong Huang, Zhen Zhao, Xiaogang Xu, Jiashi Feng, and Hengshuang Zhao.
\newblock Depth anything v2.
\newblock \emph{arXiv:2406.09414}, 2024{\natexlab{a}}.

\bibitem[Yang et~al.(2024{\natexlab{b}})Yang, Hou, Huang, Ma, Wan, Zhang, Chen, and Liao]{yang2024direct}
Shiyuan Yang, Liang Hou, Haibin Huang, Chongyang Ma, Pengfei Wan, Di Zhang, Xiaodong Chen, and Jing Liao.
\newblock Direct-a-video: Customized video generation with user-directed camera movement and object motion.
\newblock In \emph{ACM SIGGRAPH 2024 Conference Papers}, pages 1--12, 2024{\natexlab{b}}.

\bibitem[Yang et~al.(2024{\natexlab{c}})Yang, Teng, Zheng, Ding, Huang, Xu, Yang, Hong, Zhang, Feng, et~al.]{yang2024cogvideox}
Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, et~al.
\newblock Cogvideox: Text-to-video diffusion models with an expert transformer.
\newblock \emph{arXiv preprint arXiv:2408.06072}, 2024{\natexlab{c}}.

\bibitem[Ye et~al.(2023)Ye, Zhang, Liu, Han, and Yang]{ye2023ip}
Hu Ye, Jun Zhang, Sibo Liu, Xiao Han, and Wei Yang.
\newblock Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2308.06721}, 2023.

\bibitem[Yin et~al.(2023)Yin, Wu, Liang, Shi, Li, Ming, and Duan]{yin2023dragnuwa}
Shengming Yin, Chenfei Wu, Jian Liang, Jie Shi, Houqiang Li, Gong Ming, and Nan Duan.
\newblock Dragnuwa: Fine-grained control in video generation by integrating text, image, and trajectory.
\newblock \emph{arXiv preprint arXiv:2308.08089}, 2023.

\bibitem[Yu et~al.(2024)Yu, Nie, Huang, Li, Shin, and Anandkumar]{Yu2024}
Sihyun Yu, Weili Nie, De-An Huang, Boyi Li, Jinwoo Shin, and Anima Anandkumar.
\newblock Efficient video diffusion models via content-frame motion-latent decomposition.
\newblock \emph{arXiv preprint arXiv:2403.14148}, 2024.

\bibitem[Zeng et~al.(2024)Zeng, Wei, Zheng, Zou, Wei, Zhang, and Li]{zeng2024make}
Yan Zeng, Guoqiang Wei, Jiani Zheng, Jiaxin Zou, Yang Wei, Yuchen Zhang, and Hang Li.
\newblock Make pixels dance: High-dynamic video generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 8850--8860, 2024.

\bibitem[Zhang et~al.(2024{\natexlab{a}})Zhang, Li, Le, Shou, Xiong, and Sahoo]{zhang2024moonshot}
David~Junhao Zhang, Dongxu Li, Hung Le, Mike~Zheng Shou, Caiming Xiong, and Doyen Sahoo.
\newblock Moonshot: Towards controllable video generation and editing with multimodal conditions.
\newblock \emph{arXiv preprint arXiv:2401.01827}, 2024{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Rao, and Agrawala]{Zhang2023}
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 3836--3847, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Wang, Zhang, Zhao, Yuan, Qin, Wang, Zhao, and Zhou]{zhang2023i2vgen}
Shiwei Zhang, Jiayu Wang, Yingya Zhang, Kang Zhao, Hangjie Yuan, Zhiwu Qin, Xiang Wang, Deli Zhao, and Jingren Zhou.
\newblock I2vgen-xl: High-quality image-to-video synthesis via cascaded diffusion models.
\newblock \emph{arXiv preprint arXiv:2311.04145}, 2023{\natexlab{b}}.

\bibitem[Zhang et~al.(2024{\natexlab{b}})Zhang, Xing, Zeng, Fang, and Chen]{zhang2024pia}
Yiming Zhang, Zhening Xing, Yanhong Zeng, Youqing Fang, and Kai Chen.
\newblock Pia: Your personalized image animator via plug-and-play modules in text-to-image models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7747--7756, 2024{\natexlab{b}}.

\bibitem[Zheng et~al.(2022)Zheng, Li, Wang, Yao, Chen, Ding, and Li]{zheng2022entropy}
Guangcong Zheng, Shengming Li, Hui Wang, Taiping Yao, Yang Chen, Shouhong Ding, and Xi Li.
\newblock Entropy-driven sampling and training scheme for conditional diffusion generation.
\newblock In \emph{European Conference on Computer Vision}, pages 754--769. Springer, 2022.

\bibitem[Zheng et~al.(2023)Zheng, Zhou, Li, Qi, Shan, and Li]{Zheng2023}
Guangcong Zheng, Xianpan Zhou, Xuewei Li, Zhongang Qi, Ying Shan, and Xi Li.
\newblock Layoutdiffusion: Controllable diffusion model for layout-to-image generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 22490--22499, 2023.

\bibitem[Zheng et~al.(2024)Zheng, Li, Jiang, Lu, Wu, and Li]{zheng2024cami2v}
Guangcong Zheng, Teng Li, Rui Jiang, Yehao Lu, Tao Wu, and Xi Li.
\newblock Cami2v: Camera-controlled image-to-video diffusion model.
\newblock \emph{arXiv preprint arXiv:2410.15957}, 2024.

\bibitem[Zhou et~al.(2018)Zhou, Tucker, Flynn, Fyffe, and Snavely]{zhou2018stereo}
Tinghui Zhou, Richard Tucker, John Flynn, Graham Fyffe, and Noah Snavely.
\newblock Stereo magnification: Learning view synthesis using multiplane images.
\newblock In \emph{SIGGRAPH}, 2018.

\end{thebibliography}
