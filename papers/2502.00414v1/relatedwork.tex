\section{Related Work}
\label{rw}
Ideological stance detection in our context refers to the identification of the underlying ideological viewpoint that a text might have conveyed in response to a particular political scenario. Traditionally, this domain used to leverage classical machine learning techniques until the emergence of neural networks and pre-trained language models significantly changed the landscape. More recently, large language models (LLMs) have advanced this field along with several prompt engineering strategies as they can capture textual nuances that the previous models failed to do. This section reviews the progression of methodologies in ideological stance detection, organized into three categories: neural networks, pre-trained language models, and state-of-the-art LLMs. The previous studies of stance detection in the context of the Israel-Palestine conflict are also discussed. 

\subsection*{\textbf{Neural Networks}}
Neural networks emerged as an improvement over the classical supervised model in the domain of ideological stance detection as it could capture patterns better. For example, \citep{ansari2020analysis} demonstrated that LSTM models outperform classical supervised models in ideological stance detection due to their ability to capture the temporal dependencies and context of tweets as observed in its performance on the Twitter dataset for 2019 Indian General Elections. According to \citep{khatua2020predicting}, Bi-LSTM is even better than LSTM, RNN, and SVM with a motion-dependent debate model for this particular task. When an RNN model is enhanced with word embeddings (W2V), it outperforms traditional Logistic Regression that uses Bag of Words (BoW) and word embeddings (W2V) \citep{iyyer2014political}. \citep{hamborg2021news} proposes a BiGRU model with multiple embeddings that outperformed previous state-of-the-art models for target-dependent sentiment classification in news articles. The model's success can be attributed to its ability to handle longer texts and multi-target sentences, offering a better solution for real-world sentiment analysis tasks in news media.

\subsection*{\textbf{Pre-trained Language Models}}
Pre-trained language models further improved performance over the neural networks by offering better handling of context. They have been used extensively over the years in ideological stance detection. According to \citep{ozturk2024ideology}, BERT demonstrates superior performance compared to classical supervised models, LSTM, and BiLSTM in this domain. However, \citep{abercrombie2020parlvote} reported that a supervised SVM classifier with a motion-dependent debate model outperformed the BERT+MLP model in detecting ideological sentiment in a large UK parliamentary debate corpus known as ParlVote. Furthermore, ELECTRA, another pre-trained language model, has been shown to outperform BERT in the detection of ideological stance \citep{ozturk2024ideology}. BERT, which utilizes transfer learning and logistic regression, has outperformed rule-based VADER and TextBlob in the detection of sentiment related to Sustainable Development Goals (SDGs) \citep{rosenberg2023sentiment}. BERT-based models have also been shown to be more socially conservative compared to GPT models, effecting their classification performance downstream. As a result, these models might exhibit certain biases, particularly in hate speech detection, unless they are pre-trained on left-leaning or right-leaning corpora \citep{feng2023from}. In a separate study, \citep{abrar2025religious} concluded that language models such as BERT, RoBERTa, and DistilBERT continue to exhibit significant religious biases. RoBERTa-Base has also performed better than LSTM, VADER, XLM-R, and SVM in monolingual ideological sentiment classification \citep{antypas2023negativity}. However, according to \citep{ferracane2023integrated}, a RoBERTa-based model specifically fine-tuned for classification in the political domain, named POLITICS, outperformed RoBERTa-Base in terms of detecting ideological stance by leveraging discourse-based, structure-aware representations. Another multi-task learning model named CLoSE, introduced in \citep{kim2022close}, was shown to outperform both RoBERTa and BERT due to its capability of embedding sentence framing language and predicting ideological stance simultaneously. The study \citep{bhatia2018topic} showed that the TSM (Topic-Sentiment Matrix) model performed comparably to state-of-the-art distributional text representation models such as GloVe-d2v, achieving an accuracy of 65.04\% compared to 64.30\% with GloVe-d2v. DistilBERT has shown better performance than ELMo in the classification of protest news and sentiment analysis in cross-context settings \citep{buyukoz2020analyzing}.

\subsection*{\textbf{Large Language Models (LLMs)}}
Large Language Models (LLMs) are the latest innovation in stance detection which are capable of understanding contexts and textual nuances better than any previous model. For example- LLMs showed better classification performance than BERT, CNN, traditional supervised algorithms and neural networks in ideological sentiment classification \citep{kwon2024sentiment}. Similarly, \citep{kuila2024deciphering} evaluated the performance of several open-access large language models (LLMs) in detecting ideological sentiments which identified Falcon 40B as the best-performing model, followed by Mistral 7B and Falcon 7B. However, LLMs are not without challenges. LLMs have been shown to have a left-leaning tendency, which might affect their classification accuracy \citep{hernandes2024llms, pit2023whose}. Additionally, their high computational requirements might restrict their efficiency. 

\subsection*{\textbf{Stance Detection in the Israel-Palestine Conflict}}
The Israel-Palestine war has instigated a few ideological stance detection studies, each with its own strengths and limitations. \citep{AlSarraj2018} investigated media stance in the coverage of the 2014 Israeli war on Gaza by Western news outlets. The study employed text mining techniques and supervised machine learning algorithms, such as SVM, to classify stances into binary categories of Pro-Palestine and Pro-Israel. The models showed high performance, achieving an accuracy and recall of approximately 90\% in classifying these ideological stances. However, this study did not consider neutrality as a stance category, which limits its capacity to capture balanced stances in politically sensitive content. On the other hand, \citep{imtiaz2022takingsidespublicopinion} incorporated neutrality as a stance category, broadening the range of perspectives considered. The study also achieved incredible model performance using XLNet. Nonetheless, it utilized a Twitter dataset, which may have limited the text's ability to capture nuanced expressions due to the 280-character limit. Additionally, the study did not include state-of-the-art Large Language Models (LLMs) for its analysis.

Building on this foundation, our work broadens the scope by integrating neural networks, pre-trained language models, and open source large language models (LLMs) with prompt engineering to analyze Reddit comments related to the Israel-Palestine conflict. Unlike traditional machine learning techniques, these advanced models enable a deeper understanding of contextual nuances, leading to the dynamic classification of ideological stance into three categories: Pro-Palestine, Pro-Israel, and Neutral.