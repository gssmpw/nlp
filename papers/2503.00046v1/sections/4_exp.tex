\section{Experimental Setup}
\subsection{Models}
We experiment with open-sourced VLMs, i.e. InternVL2-8B \cite{chen2024fargpt4vclosinggap}, LLaVA-7B and 13B \cite{li2024llavanext-strong}, and close-sourced VLMs, GPT4-v \cite{openai2024gpt4}. All experiments are done with zero-shot prompting with \texttt{vllm} inference framework \cite{kwon2023efficient}. More details about the experiment configurations are in Appendix \ref{sec:appendix_experiment_details}.

\subsection{Task Formulation}
We define the following three tasks for each dimension (i.e., creativity, originality, and atypicality): 
\label{sec:distribution_task}
\textbf{Distribution Modeling} is designed to evaluate the model's ability to simulate human group behavior when it comes to creativity ratings. In practice, we prompt VLMs multiple times with high temperatures to get the same number of VLM outputs as the number of annotators. In this way, we simulate a ``group behavior'' instead of a single-point judgment about the level of creativity in the ad. To evaluate the quality of this simulation, we use two metrics: Spearman's correlation between the average rating from humans and that from VLMs and the average KL Divergence between human rating distribution and that from VLMs. These two results are in \textit{Rating Correlation} and \textit{Distribution Divergence} columns in Table \ref{table:mturk_results}. 

% \paragraph{Disagreement Prediction}
\label{sec:disagreement_task}
\textbf{Disagreement Prediction} tries to capture the annotatorâ€™s level of disagreement, which is especially important in domains like marketing and business. An ad that is viewed as creative by a broad audience, with minimal disagreement, is desired and could have a more positive impact on the product. In practice, we directly prompt VLMs to predict the level of disagreement (low, middle, or high) for each scoring dimension. We then compute Spearman's correlation between the prediction and standard deviation of human ratings. This metric studies the level of creativity ambiguity of the advertisements. A very creative ad will have a low disagreement rate with a high creativity score. The results are in \textit{Disagreement} column in Table \ref{table:mturk_results}.

% \paragraph{Pairwise Preference}
\textbf{Pairwise Preference} aims at evaluating the model's ability to correctly pick the more creative ad out of two ads, given that an absolute rating of creativity can be hard when there is no reference. For each scoring dimension, we include all ad pairs with average human ratings differences greater than 0.5. For \texttt{Creative-100}, we have 938, 2708, and 2631 pairs in creativity, originality, and atypicality; for \texttt{Atypical-300}, we sampled 1000 image pairs from 300 images due to constraints in computation resources. The results are evaluated by F1 score and are shown in \textit{Pairwise} column in Table \ref{table:mturk_results}. 

