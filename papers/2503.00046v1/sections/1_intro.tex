\section{Introduction}


Evaluation of creativity has been a lasting effort where researchers have taken diverse sets of perspectives \cite{SaidMetwaly}. Among those perspectives, evaluating the created product is the only one that focuses purely on the created artifact, no matter who authored that artifact, greatly reducing the complexity of problem framing. Examples from this perspective include evaluation of creative writing \cite{lu2024aihumanityssalieriquantifying, Chakrabarty_art_artifice}, creative tool use \cite{tian-etal-2024-macgyver}, and creative advertising \cite{modeling_determinants}. 

\begin{figure}[t!]
    \centering
        \includegraphics[width=0.48\textwidth]{image/intro.png}
    \caption{Top: two ads from dataset; Middle: human rating and VLM outputs (25 each); Bottom: average human rating, VLM outputs, and VLM pairwise predictions; Scores are 3-scale, 3 being the best. Ad \textbf{A} receives a higher average rating in all three categories compared to Ad \textbf{B}, also reflected in the model-predicted ratings and pairwise preference prediction.}
    \label{fig:intro}
    \vspace{-6mm}
\end{figure}

% evaluation of creativity - marketing perspective 
In advertising, creativity plays a critical role in driving consumer behaviors, where multiple studies have shown positive effects of creative ads, including increased purchase intent and positive brand impression ~\cite{sharma2012advertising, terkan2014importance}. Therefore, ad creators are motivated to consistently develop and evaluate creative ad content. Extensive research has been conducted to understand what the general public would consider creative~\cite{El-Murad188, HowAdvertisingCreativityWorks, doi:10.1080/13527266.2012.677464, modeling_determinants}, many of which consider ads creativity to be a combination of ``atypicality'' (or, synthesis, abnormalness, etc.) and ``originality'' (or, novelty, uniqueness, etc.). Here is an example that is both atypical and original: in the advertisement (A) in Figure~\ref{fig:intro}, the image of a cow typing on a computer is highly atypical, as cows do not do that; the text \textit{``Eat chikin or I'll de-friend U''}, which consists of multiple slangs, the cow, the computer, and the small logo of Chick-fil-A is a rarely-seen combination given that it is a fast-food advertisement, making it very original. Decoding ads creativity under such a framework requires extensive reasoning, making the evaluation of creativity a challenging task. Unsurprisingly, previous work heavily relies on domain experts, who are expensive and inaccessible.

% vlm/llm for creativity evaluation 
Recently, foundational models demonstrate impressive performances in other evaluation tasks, such as summarization ~\cite{zhong-etal-2022-towards}, Long-Form QA~\cite{Jiang2023TIGERScoreTB}, and commonsense text generation~\cite{xu2023instructscore}, many of which were previously dominant by human evaluation. For creativity evaluation, prior work \cite{Chakrabarty_art_artifice} has explored the ability of LLMs to access writing creativity. This poses the question of whether we can leverage foundational models to expand automatic evaluation of creativity to multi-modal data such as visual advertisements, with the help of Vision Language Models (VLM).



% summary of our work
To this end, we conduct several fine-grained, automatic creativity evaluations for visual advertisements, including creativity, originality, and atypicality. We decompose creativity into atypicality and originality and then collect high-quality human ratings of advertisements in those dimensions, as shown in Figure \ref{fig:intro} as ``human rating''. We experiment with state-of-the-art (SoTA) VLMs to predict these ratings and examine the human-model alignment in both intrinsic (i.e., one image at a time) and pairwise fashion. In contrast to the traditional emphasis on prediction accuracy, we evaluate models' ability to capture the task's subjective nature and to gauge annotator disagreements. We also show that VLMs perform impressively in a pairwise setting, reasonably well in distribution modeling, and less effectively in disagreement. Our results highlight the importance of both high-quality annotations and distribution modeling as the objective, instead of majority label prediction, in future research on subjective tasks. We believe our benchmark and evaluation metrics provide a solid foundation for utilizing VLMs to assist visual content creators.
