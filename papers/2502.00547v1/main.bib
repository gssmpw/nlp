@misc{ViT,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}
@article{katsigiannis2017dreamer,
  title={DREAMER: A database for emotion recognition through EEG and ECG signals from wireless low-cost off-the-shelf devices},
  author={Katsigiannis, Stamos and Ramzan, Naeem},
  journal={IEEE journal of biomedical and health informatics},
  volume={22},
  number={1},
  pages={98--107},
  year={2017},
  publisher={IEEE}
}
@article{deap,
  title={Deap: A database for emotion analysis; using physiological signals},
  author={Koelstra, Sander and Muhl, Christian and Soleymani, Mohammad and Lee, Jong-Seok and Yazdani, Ashkan and Ebrahimi, Touradj and Pun, Thierry and Nijholt, Anton and Patras, Ioannis},
  journal={IEEE transactions on affective computing},
  volume={3},
  number={1},
  pages={18--31},
  year={2011},
  publisher={IEEE}
}
@article{MAHNOB-HCI,
  title={A multimodal database for affect recognition and implicit tagging},
  author={Soleymani, Mohammad and Lichtenauer, Jeroen and Pun, Thierry and Pantic, Maja},
  journal={IEEE transactions on affective computing},
  volume={3},
  number={1},
  pages={42--55},
  year={2011},
  publisher={IEEE}
}
@inproceedings{SEMAINE,
  title={The SEMAINE corpus of emotionally coloured character interactions},
  author={McKeown, Gary and Valstar, Michel F and Cowie, Roderick and Pantic, Maja},
  booktitle={2010 IEEE international conference on multimedia and expo},
  pages={1079--1084},
  year={2010},
  organization={IEEE}
}
@article{amigos,
  title={Amigos: A dataset for affect, personality and mood research on individuals and groups},
  author={Miranda-Correa, Juan Abdon and Abadi, Mojtaba Khomami and Sebe, Nicu and Patras, Ioannis},
  journal={IEEE transactions on affective computing},
  volume={12},
  number={2},
  pages={479--493},
  year={2018},
  publisher={IEEE}
}
@article{Cimtay,
  title={Cross-subject multimodal emotion recognition based on hybrid fusion},
  author={Cimtay, Yucel and Ekmekcioglu, Erhan and Caglar-Ozhan, Seyma},
  journal={IEEE Access},
  volume={8},
  pages={168865--168878},
  year={2020},
  publisher={IEEE}
}
@article{huangEnhance,
  title={Combining facial expressions and electroencephalography to enhance emotion recognition},
  author={Huang, Yongrui and Yang, Jianhao and Liu, Siyu and Pan, Jiahui},
  journal={Future Internet},
  volume={11},
  number={5},
  pages={105},
  year={2019},
  publisher={MDPI}
}
@article{gupta2018cross,
  title={Cross-subject emotion recognition using flexible analytic wavelet transform from EEG signals},
  author={Gupta, Vipin and Chopda, Mayur Dahyabhai and Pachori, Ram Bilas},
  journal={IEEE Sensors Journal},
  volume={19},
  number={6},
  pages={2266--2274},
  year={2018},
  publisher={IEEE}
}
@article{zhang2022,
  title={Emotion recognition using heterogeneous convolutional neural networks combined with multimodal factorized bilinear pooling},
  author={Zhang, Yong and Cheng, Cheng and Wang, Shuai and Xia, Tianqi},
  journal={Biomedical Signal Processing and Control},
  volume={77},
  pages={103877},
  year={2022},
  publisher={Elsevier}
}
@article{wang,
  title={Multimodal emotion recognition from EEG signals and facial expressions},
  author={Wang, Shuai and Qu, Jingzi and Zhang, Yong and Zhang, Yidie},
  journal={IEEE Access},
  volume={11},
  pages={33061--33068},
  year={2023},
  publisher={IEEE}
}
@article{zeng2007,
  title={Audio-visual affect recognition},
  author={Zeng, Zhihong and Tu, Jilin and Liu, Ming and Huang, Thomas S and Pianfetti, Brian and Roth, Dan and Levinson, Stephen},
  journal={IEEE Transactions on multimedia},
  volume={9},
  number={2},
  pages={424--428},
  year={2007},
  publisher={IEEE}
}
@article{nie2020c,
  title={C-GCN: Correlation based graph convolutional network for audio-video emotion recognition},
  author={Nie, Weizhi and Ren, Minjie and Nie, Jie and Zhao, Sicheng},
  journal={IEEE Transactions on Multimedia},
  volume={23},
  pages={3793--3804},
  year={2020},
  publisher={IEEE}
}
@article{shu2018review,
  title={A review of emotion recognition using physiological signals},
  author={Shu, Lin and Xie, Jinyan and Yang, Mingyue and Li, Ziyi and Li, Zhenqi and Liao, Dan and Xu, Xiangmin and Yang, Xinyi},
  journal={Sensors},
  volume={18},
  number={7},
  pages={2074},
  year={2018},
  publisher={MDPI}
}
@article{zhang2020emotion,
  title={Emotion recognition using multi-modal data and machine learning techniques: A tutorial and review},
  author={Zhang, Jianhua and Yin, Zhong and Chen, Peng and Nichele, Stefano},
  journal={Information Fusion},
  volume={59},
  pages={103--126},
  year={2020},
  publisher={Elsevier}
}
@article{mne,
  title={MEG and EEG data analysis with MNE-Python},
  author={Gramfort, Alexandre and Luessi, Martin and Larson, Eric and Engemann, Denis A and Strohmeier, Daniel and Brodbeck, Christian and Goj, Roman and Jas, Mainak and Brooks, Teon and Parkkonen, Lauri and others},
  journal={Frontiers in Neuroinformatics},
  volume={7},
  pages={267},
  year={2013},
  publisher={Frontiers Media SA}
}
@article{attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}
@article{ALBEF,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}
@article{blazeface,
  title={Blazeface: Sub-millisecond neural face detection on mobile gpus},
  author={Bazarevsky, Valentin and Kartynnik, Yury and Vakunov, Andrey and Raveendran, Karthik and Grundmann, Matthias},
  journal={arXiv preprint arXiv:1907.05047},
  year={2019}
}
@inproceedings{vilt,
  title={Vilt: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={International conference on machine learning},
  pages={5583--5594},
  year={2021},
  organization={PMLR}
}
@article{greatHelp,
  title={Deep learning model for simultaneous recognition of quantitative and qualitative emotion using visual and bio-sensing data},
  author={Hosseini, Iman and Hossain, Md Zakir and Zhang, Yuhao and Rahman, Shafin},
  journal={Computer Vision and Image Understanding},
  volume={248},
  pages={104121},
  year={2024},
  publisher={Elsevier}
}
@article{startingArticle,
  title={Fusion of facial expressions and EEG for multimodal emotion recognition},
  author={Huang, Yongrui and Yang, Jianhao and Liao, Pengkai and Pan, Jiahui},
  journal={Computational intelligence and neuroscience},
  volume={2017},
  number={1},
  pages={2107451},
  year={2017},
  publisher={Wiley Online Library}
}
@article{FER2013,
  title={Facial emotion recognition: State of the art performance on FER2013},
  author={Khaireddin, Yousif and Chen, Zhuofa},
  journal={arXiv preprint arXiv:2105.03588},
  year={2021}
}
@article{liang2024fetcheeg,
  title={FetchEEG: a hybrid approach combining feature extraction and temporal-channel joint attention for EEG-based emotion classification},
  author={Liang, Yu and Zhang, Chenlong and An, Shan and Wang, Zaitian and Shi, Kaize and Peng, Tianhao and Ma, Yuqing and Xie, Xiaoyang and He, Jian and Zheng, Kun},
  journal={Journal of Neural Engineering},
  volume={21},
  number={3},
  pages={036011},
  year={2024},
  publisher={IOP Publishing}
}
@article{husformer,
  title={Husformer: A multi-modal transformer for multi-modal human state recognition},
  author={Wang, Ruiqi and Jo, Wonse and Zhao, Dezhong and Wang, Weizheng and Gupte, Arjun and Yang, Baijian and Chen, Guohua and Min, Byung-Cheol},
  journal={IEEE Transactions on Cognitive and Developmental Systems},
  year={2024},
  publisher={IEEE}
}
@article{zcl,
  title={A Fusion Framework for Confusion Analysis in Learning Based on EEG Signals},
  author={Zhang, Chenlong and He, Jian and Liang, Yu and Wang, Zaitian and Xie, Xiaoyang},
  journal={Applied Sciences},
  volume={13},
  number={23},
  pages={12832},
  year={2023},
  publisher={MDPI}
}
@inproceedings{swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}
@article{pan2023review,
  title={A review of multimodal emotion recognition from datasets, preprocessing, features, and fusion methods},
  author={Pan, Bei and Hirota, Kaoru and Jia, Zhiyang and Dai, Yaping},
  journal={Neurocomputing},
  pages={126866},
  year={2023},
  publisher={Elsevier}
}
@article{breuer2017deep,
  title={A deep learning perspective on the origin of facial expressions},
  author={Breuer, Ran and Kimmel, Ron},
  journal={arXiv preprint arXiv:1705.01842},
  year={2017}
}
@inproceedings{fan2016video,
  title={Video-based emotion recognition using CNN-RNN and C3D hybrid networks},
  author={Fan, Yin and Lu, Xiangju and Li, Dian and Liu, Yuanliu},
  booktitle={Proceedings of the 18th ACM international conference on multimodal interaction},
  pages={445--450},
  year={2016}
}
@inproceedings{huang2018end,
  title={End-to-end continuous emotion recognition from video using 3D ConvLSTM networks},
  author={Huang, Jian and Li, Ya and Tao, Jianhua and Lian, Zheng and Yi, Jiangyan},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6837--6841},
  year={2018},
  organization={IEEE}
}
@inproceedings{zhao2021former,
  title={Former-dfer: Dynamic facial expression recognition transformer},
  author={Zhao, Zengqun and Liu, Qingshan},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={1553--1561},
  year={2021}
}
@article{facialReview,
  title={A survey on facial emotion recognition techniques: A state-of-the-art literature review},
  author={Canal, Felipe Zago and M{\"u}ller, Tobias Rossi and Matias, Jhennifer Cristine and Scotton, Gustavo Gino and de Sa Junior, Antonio Reis and Pozzebon, Eliane and Sobieranski, Antonio Carlos},
  journal={Information Sciences},
  volume={582},
  pages={593--617},
  year={2022},
  publisher={Elsevier}
}
@article{huang2021facial,
  title={Facial expression recognition with grid-wise attention and visual transformer},
  author={Huang, Qionghao and Huang, Changqin and Wang, Xizhe and Jiang, Fan},
  journal={Information Sciences},
  volume={580},
  pages={35--54},
  year={2021},
  publisher={Elsevier}
}
@article{eegReview,
  title={Emotion recognition in EEG signals using deep learning methods: A review},
  author={Jafari, Mahboobeh and Shoeibi, Afshin and Khodatars, Marjane and Bagherzadeh, Sara and Shalbaf, Ahmad and Garc{\'\i}a, David L{\'o}pez and Gorriz, Juan M and Acharya, U Rajendra},
  journal={Computers in Biology and Medicine},
  pages={107450},
  year={2023},
  publisher={Elsevier}
}
@article{zheng2017identifying,
  title={Identifying stable patterns over time for emotion recognition from EEG},
  author={Zheng, Wei-Long and Zhu, Jia-Yi and Lu, Bao-Liang},
  journal={IEEE transactions on affective computing},
  volume={10},
  number={3},
  pages={417--429},
  year={2017},
  publisher={IEEE}
}
@article{wang2022eegtransformers,
  title={Transformers for EEG-based emotion recognition: A hierarchical spatial information learning model},
  author={Wang, Zhe and Wang, Yongxiong and Hu, Chuanfei and Yin, Zhong and Song, Yu},
  journal={IEEE Sensors Journal},
  volume={22},
  number={5},
  pages={4359--4368},
  year={2022},
  publisher={IEEE}
}
@article{Gan2020eeg,
  title={EEG-based emotion recognition using regularized graph neural networks},
  author={Zhong, Peixiang and Wang, Di and Miao, Chunyan},
  journal={IEEE Transactions on Affective Computing},
  volume={13},
  number={3},
  pages={1290--1301},
  year={2020},
  publisher={IEEE}
}
@article{schirrmeister2017deep,
  title={Deep learning with convolutional neural networks for EEG decoding and visualization},
  author={Schirrmeister, Robin Tibor and Springenberg, Jost Tobias and Fiederer, Lukas Dominique Josef and Glasstetter, Martin and Eggensperger, Katharina and Tangermann, Michael and Hutter, Frank and Burgard, Wolfram and Ball, Tonio},
  journal={Human brain mapping},
  volume={38},
  number={11},
  pages={5391--5420},
  year={2017},
  publisher={Wiley Online Library}
}
@article{tan2021multimodal,
  title={A multimodal emotion recognition method based on facial expressions and electroencephalography},
  author={Tan, Ying and Sun, Zhe and Duan, Feng and Sol{\'e}-Casals, Jordi and Caiafa, Cesar F},
  journal={Biomedical Signal Processing and Control},
  volume={70},
  pages={103029},
  year={2021},
  publisher={Elsevier}
}
@article{muhammad2023bimodal,
  title={A bimodal emotion recognition approach through the fusion of electroencephalography and facial sequences},
  author={Muhammad, Farah and Hussain, Muhammad and Aboalsamh, Hatim},
  journal={Diagnostics},
  volume={13},
  number={5},
  pages={977},
  year={2023},
  publisher={MDPI}
}
@article{liu2018efficient,
  title={Efficient low-rank multimodal fusion with modality-specific factors},
  author={Liu, Zhun and Shen, Ying and Lakshminarasimhan, Varun Bharadhwaj and Liang, Paul Pu and Zadeh, Amir and Morency, Louis-Philippe},
  journal={arXiv preprint arXiv:1806.00064},
  year={2018}
}
@article{jung2019utilizing,
  title={Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing},
  author={Jung, Tzyy-Ping and Sejnowski, Terrence J and others},
  journal={IEEE Transactions on Affective Computing},
  volume={13},
  number={1},
  pages={96--107},
  year={2019},
  publisher={IEEE}
}
@article{romeo2019multiple,
  title={Multiple instance learning for emotion recognition using physiological signals},
  author={Romeo, Luca and Cavallo, Andrea and Pepa, Lucia and Bianchi-Berthouze, Nadia and Pontil, Massimiliano},
  journal={IEEE Transactions on affective computing},
  volume={13},
  number={1},
  pages={389--407},
  year={2019},
  publisher={IEEE}
}
@inproceedings{rao2016multi,
  title={Multi-scale blocks based image emotion classification using multiple instance learning},
  author={Rao, Tianrong and Xu, Min and Liu, Huiying and Wang, Jinqiao and Burnett, Ian},
  booktitle={2016 IEEE International Conference on Image Processing (ICIP)},
  pages={634--638},
  year={2016},
  organization={IEEE}
}
@inproceedings{amil,
  title={Attention-based deep multiple instance learning},
  author={Ilse, Maximilian and Tomczak, Jakub and Welling, Max},
  booktitle={International conference on machine learning},
  pages={2127--2136},
  year={2018},
  organization={PMLR}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}
@inproceedings{blip2,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}
@inproceedings{marjit2021eeg,
  title={Eeg-based emotion recognition using genetic algorithm optimized multi-layer perceptron},
  author={Marjit, Shyam and Talukdar, Upasana and Hazarika, Shyamanta M},
  booktitle={2021 International Symposium of Asian Control Association on Intelligent Robotics and Industrial Automation (IRIA)},
  pages={304--309},
  year={2021},
  organization={IEEE}
}
@article{wu2023recognizing,
  title={Recognizing, fast and slow: Complex emotion recognition with facial expression detection and remote physiological measurement},
  author={Wu, Yi-Chiao and Chiu, Li-Wen and Lai, Chun-Chih and Wu, Bing-Fei and Lin, Sunny SJ},
  journal={IEEE Transactions on Affective Computing},
  volume={14},
  number={4},
  pages={3177--3190},
  year={2023},
  publisher={IEEE}
}
@article{salama2018eeg,
  title={EEG-based emotion recognition using 3D convolutional neural networks},
  author={Salama, Elham S and El-Khoribi, Reda A and Shoman, Mahmoud E and Shalaby, Mohamed A Wahby},
  journal={International Journal of Advanced Computer Science and Applications},
  volume={9},
  number={8},
  year={2018},
  publisher={Science and Information (SAI) Organization Limited}
}
@article{wu2023multi,
  title={Multi-modal emotion identification fusing facial expression and EEG},
  author={Wu, Yongzhen and Li, Jinhua},
  journal={Multimedia Tools and Applications},
  volume={82},
  number={7},
  pages={10901--10919},
  year={2023},
  publisher={Springer}
}
@article{zhang2020expression,
  title={Expression-EEG based collaborative multimodal emotion recognition using deep autoencoder},
  author={Zhang, Hongli},
  journal={IEEE Access},
  volume={8},
  pages={164130--164143},
  year={2020},
  publisher={IEEE}
}
@article{zhao2021expression,
  title={Expression EEG multimodal emotion recognition method based on the bidirectional LSTM and attention mechanism},
  author={Zhao, Yifeng and Chen, Deyun},
  journal={Computational and Mathematical Methods in Medicine},
  volume={2021},
  number={1},
  pages={9967592},
  year={2021},
  publisher={Wiley Online Library}
}
@article{wang2025design,
  title={Design and Analysis of a Closed-Loop Emotion Regulation System Based on Multimodal Affective Computing and Emotional Markov Chain},
  author={Wang, Xingchao and Li, Chen-Zhong and Sun, Zhenglong and Xu, Yangsheng},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  year={2025},
  publisher={IEEE}
}
@article{salama20213d,
  title={A 3D-convolutional neural network framework with ensemble learning techniques for multi-modal emotion recognition},
  author={Salama, Elham S and El-Khoribi, Reda A and Shoman, Mahmoud E and Shalaby, Mohamed A Wahby},
  journal={Egyptian Informatics Journal},
  volume={22},
  number={2},
  pages={167--176},
  year={2021},
  publisher={Elsevier}
}
@article{kwon2018eeg,
  title={Electroencephalography based fusion two-dimensional (2D)-convolution neural networks (CNN) model for emotion recognition system},
  author={Kwon, Yea-Hoon and Shin, Sae-Byuk and Kim, Shin-Dug},
  journal={Sensors},
  volume={18},
  number={5},
  pages={1383},
  year={2018},
  publisher={MDPI}
}
@article{lee2024emotion,
  title={Emotion Recognition Using EEG Signals and Audiovisual Features with Contrastive Learning},
  author={Lee, Ju-Hwan and Kim, Jin-Young and Kim, Hyoung-Gook},
  journal={Bioengineering},
  volume={11},
  number={10},
  pages={997},
  year={2024}
}