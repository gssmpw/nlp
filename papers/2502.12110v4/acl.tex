% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}
\usepackage[table]{xcolor}
% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{tcolorbox}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{amsthm,amssymb,amsfonts,amsmath}
\usepackage{caption,subfigure,epstopdf,multirow,multicol,booktabs,verbatim,wrapfig,bm}
\usepackage{xspace}

\newcommand{\cmark}{\textcolor{teal}{\bf\ding{51}}}
\newcommand{\xmark}{\textcolor{red}{\bf\ding{55}}}
\newcommand{\textev}[1]{\textcolor{blue}{\bf #1}}
\definecolor{em}{gray}{0.9}
\newcommand{\cem}{\cellcolor{em}}
\newcommand{\best}[1]{{\textbf{#1}}}
\newcommand{\bs}[1]{{\textbf{#1}}}
\newcommand{\sbs}[1]{{\uline{#1}}}
\newcommand{\di}[1]{{ (\small{#1})}}
\newcommand{\gain}[1]{{\textcolor{teal}{\ ($\uparrow$#1)}}}
\newcommand{\loss}[1]{{\textcolor{violet}{\ ($\downarrow$#1)}}}
\renewcommand{\paragraph}[1]{\vspace{0.3em}\noindent\textbf{#1}\hspace{0.5em}}

\newcommand{\lo}{\textsc{LoCoMo}\xspace}
\newcommand{\co}{\textsc{Cot}\xspace}
\newcommand{\fe}{\textsc{FullElicit}\xspace}
\newcommand{\ours}{\textsc{A-Mem}\xspace}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{\ours: Agentic Memory for LLM Agents}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
Wujiang Xu$^1$\quad
Zujie Liang$^2$\quad 
Kai Mei$^1$ \quad  \\
\textbf{Hang Gao}$^1$\quad
\textbf{Juntao Tan}$^1$\quad 
\textbf{Yongfeng Zhang}$^{1}$\thanks{Corresponding Email: yongfeng.zhang@rutgers.edu. }\\
  $^1$Rutgers University\;\;\;  $^2$Independent Researcher\;\;\;  
}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management.
Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code for evaluating performance is available at \url{https://github.com/WujiangXu/AgenticMemory}, while the source code of agentic memory system is available at \url{https://github.com/agiresearch/A-mem}. 

\end{abstract}

\section{Introduction}
Large Language Model (LLM) agents have demonstrated remarkable capabilities in various tasks, with recent advances enabling them to interact with environments, execute tasks, and make decisions autonomously~\cite{aios,openhands,mind2web}. They integrate LLMs with external tools and delicate workflows to improve reasoning and planning abilities. Though LLM agent has strong reasoning performance, it still needs a memory system to provide long-term interaction ability with the external environment~\cite{weng2023agent}.


\begin{figure}[tb!]
\centering
% 第一行的两个子图
\subfigure[Traditional memory system.]
{
\begin{minipage}[t]{0.82\linewidth}
\centering
\includegraphics[width=0.97\linewidth]{figure/intro-a.pdf}
%\caption{fig1}
\end{minipage}%
}%
\vspace{-5pt}
\\
% 第二行的两个子图
\subfigure[Our proposed agentic memory.]{
\begin{minipage}[t]{0.99\linewidth}
\centering
\includegraphics[width=0.97\linewidth]{figure/intro-b.pdf}
%\caption{fig1}
\end{minipage}%
}%
\centering
% \captionsetup{font={small}}
\vspace{-8pt}
\caption{Traditional memory systems require predefined memory access patterns specified in the workflow, limiting their adaptability to diverse scenarios. Contrastly, our \ours enhances the flexibility of LLM agents by enabling dynamic memory operations.}
\vspace{-5pt}
\label{fig:model study}
\end{figure}


Existing memory systems~\cite{memgpt,memorybank,smolagents,agentlite} for LLM agents provide basic memory storage functionality. These systems require agent developers to predefine memory storage structures, specify storage points within the workflow, and establish retrieval timing.
Meanwhile, to improve structured memory organization, Mem0~\cite{mem0}, following the principles of RAG~\cite{graphrag,rag1,aiosrag}, incorporates graph databases for storage and retrieval processes. While graph databases provide structured organization for memory systems, their reliance on predefined schemas and relationships fundamentally limits their adaptability. This limitation manifests clearly in practical scenarios - when an agent learns a novel mathematical solution, current systems can only categorize and link this information within their preset framework, unable to forge innovative connections or develop new organizational patterns as knowledge evolves. Such rigid structures, coupled with fixed agent workflows, severely restrict these systems' ability to generalize across new environments and maintain effectiveness in long-term interactions. The challenge becomes increasingly critical as LLM agents tackle more complex, open-ended tasks, where flexible knowledge organization and continuous adaptation are essential. Therefore, \textit{how to design a flexible and universal memory system that supports LLM agents' long-term interactions} remains a crucial challenge.

In this paper, we introduce a novel agentic memory system, named as \ours, for LLM agents that enables dynamic memory structuring without relying on static, predetermined memory operations. Our approach draws inspiration from the Zettelkasten method~\cite{zettel1,zettel2}, a sophisticated knowledge management system that creates interconnected information networks through atomic notes and flexible linking mechanisms.
Our system introduces an agentic memory architecture that enables autonomous and flexible memory management for LLM agents. For each new memory, we construct comprehensive notes, which integrates multiple representations: structured textual attributes including several attributes and embedding vectors for similarity matching. 
Then \ours analyzes the historical memory repository to establish meaningful connections based on semantic similarities and shared attributes. This integration process not only creates new links but also enables dynamic evolution when new memories are incorporated, they can trigger updates to the contextual representations of existing memories, allowing the entire memories to continuously refine and deepen its understanding over time.
The contributions are summarized as:

$\bullet$ We present \ours, an agentic memory system for LLM agents that enables autonomous generation of contextual descriptions, dynamic establishment of memory connections, and intelligent evolution of existing memories based on new experiences. This system equips LLM agents with long-term interaction capabilities without requiring predetermined memory operations.

$\bullet$ We design an agentic memory update mechanism where new memories automatically trigger two key operations: (1) Link Generation - automatically establishing connections between memories by identifying shared attributes and similar contextual descriptions, and (2) Memory Evolution - enabling existing memories to dynamically evolve as new experiences are analyzed, leading to the emergence of higher-order patterns and attributes.

$\bullet$ We conduct comprehensive evaluations of our system using a long-term conversational dataset, comparing performance across six foundation models using six distinct evaluation metrics, demonstrating significant improvements. Moreover, we provide T-SNE visualizations to illustrate the structured organization of our agentic memory system.

\section{Related Work}

\subsection{Memory for LLM Agents}
Prior works on LLM agent memory systems have explored various mechanisms for memory management and utilization~\cite{aios,agentlite,mem0,memorybank}. Some approaches complete interaction storage, which maintains comprehensive historical records through dense retrieval models~\cite{memorybank} or read-write memory structures~\cite{modarressi2023ret}. Moreover, MemGPT~\cite{memgpt} leverages cache-like architectures to prioritize recent information. Similarly, SCM~\cite{wang2023enhancing} proposes a Self-Controlled Memory framework that enhances LLMs' capability to maintain long-term memory through a memory stream and controller mechanism.
However, these approaches face significant limitations in handling diverse real-world tasks. While they can provide basic memory functionality, their operations are typically constrained by predefined structures and fixed workflows. These constraints stem from their reliance on rigid operational patterns, particularly in memory writing and retrieval processes. Such inflexibility leads to poor generalization in new environments and limited effectiveness in long-term interactions. Therefore, designing a flexible and universal memory system that supports agents' long-term interactions remains a crucial challenge.


\subsection{Retrieval-Augmented Generation}
Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to enhance LLMs by incorporating external knowledge sources~\cite{rag1,borgeaud2022improving,gao2023retrieval}. The standard RAG~\cite{yu2023chain,wang2023learning} process involves indexing documents into chunks, retrieving relevant chunks based on semantic similarity, and augmenting the LLM's prompt with this retrieved context for generation. Advanced RAG systems~\cite{lin2023ra,ilin2023advanced} have evolved to include sophisticated pre-retrieval and post-retrieval optimizations.
Building upon these foundations, recent researches has introduced agentic RAG systems that demonstrate more autonomous and adaptive behaviors in the retrieval process. These systems can dynamically determine when and what to retrieve~\cite{asai2023self,jiang2023active}, generate hypothetical responses to guide retrieval, and iteratively refine their search strategies based on intermediate results~\cite{trivedi2022interleaving,shao2023enhancing}. 

However, while agentic RAG approaches demonstrate agency in the retrieval phase by autonomously deciding when and what to retrieve~\cite{asai2023self,jiang2023active,yu2023augmentation}, our agentic memory system exhibits agency at a more fundamental level through the autonomous evolution of its memory structure. Inspired by the Zettelkasten method, our system allows memories to actively generate their own contextual descriptions, form meaningful connections with related memories, and evolve both their content and relationships as new experiences emerge. This fundamental distinction in agency between retrieval versus storage and evolution distinguishes our approach from agentic RAG systems, which maintain static knowledge bases despite their sophisticated retrieval mechanisms.

\section{Methodolodgy}
Our proposed agentic memory system draws inspiration from the Zettelkasten method, implementing a dynamic and self-evolving memory system that enables LLM agents to maintain long-term memory without predetermined operations. The system's design emphasizes atomic note-taking, flexible linking mechanisms, and continuous evolution of knowledge structures.

\begin{figure*}[tb!]
\centering
\includegraphics[width=\linewidth]{figure/framework.pdf}
%\caption{fig1}
\centering
% \captionsetup{font={small}}
% \vspace{-1.0em}
\caption{Our \ours architecture comprises three integral parts in memory storage. During note construction, the system processes new interaction memories and stores them as notes with multiple attributes. The link generation process first retrieves the most relevant historical memories and then decide whether to establish connections between them. The concept of a 'box' describes that related memories become interconnected through their similar contextual descriptions, analogous to the Zettelkasten method. However, our approach allows individual memories to exist simultaneously within multiple different boxes. In the memory retrieval stage, the system analyzes queries into constituent keywords and utilizes these keywords to search through the memory network.}
\label{fig:framework}
\vspace{-1.0em}
\end{figure*}

\subsection{Note Construction}
Building upon the Zettelkasten method's principles of atomic note-taking and flexible organization, we introduce an LLM-driven approach to memory note construction. When an agent interacts with its environment, we construct structured memory notes that capture both explicit information and LLM-generated contextual understanding. Each memory note $m_i$ in our collection $\mathcal{M} = \{m_1, m_2, ..., m_N\}$ is represented as:
\begin{equation}
m_i = \{c_i, t_i, K_i, G_i, X_i, e_i, L_i\}
\end{equation}
where $c_i$ represents the original interaction content, $t_i$ is the timestamp of the interaction, $K_i$ denotes LLM-generated keywords that capture key concepts, $G_i$ contains LLM-generated tags for categorization, $X_i$ represents the LLM-generated contextual description that provides rich semantic understanding, and $L_i$ maintains the set of linked memories that share semantic relationships.
To enrich each memory note with meaningful context beyond its basic content and timestamp, we leverage an LLM to analyze the interaction and generate these semantic components. The note construction process involves prompting the LLM with carefully designed templates $P_{s1}$:
\begin{equation}
K_i,G_i,X_i \leftarrow   \text{LLM} (c_i \; \Vert t_i \; \Vert P_{s1})
\end{equation}
Following the Zettelkasten principle of atomicity, each note captures a single, self-contained unit of knowledge. To enable efficient retrieval and linking, we compute a dense vector representation via a text encoder~\cite{sentence-bert} that encapsulates all textual components of the note:
\begin{equation}
e_i = f_{\text{enc}}[\; \text{concat}(c_i, K_i, G_i, X_i)\;]
\end{equation}
By using LLMs to generate enriched components, we enable autonomous extraction of implicit knowledge from raw interactions. The multi-faceted note structure ($K_i$, $G_i$, $X_i$) creates rich representations that capture different aspects of the memory, facilitating nuanced organization and retrieval. Additionally, the combination of LLM-generated semantic components with dense vector representations provides both human-interpretable context and computationally efficient similarity matching.

\subsection{Link Generation}
Our system implements an autonomous link generation mechanism that enables new memory notes to form meaningful connections without predefined rules. When the constrctd memory note $m_n$ is added to the system, we first 
leverage its semantic embedding for similarity-based retrieval. 
For each existing memory note $m_j \in \mathcal{M}$, we compute a similarity score:
\begin{equation}
s_{n,j} = \frac{e_{n} \cdot e_j}{|e_{n}| |e_j|} 
\end{equation}

The system then identifies the top-$k$ most relevant memories:
\begin{equation}
    \mathcal{M}_{\text{near}}^n = \{m_j | \; \text{rank}(s_{n,j}) \leq k, m_j \in \mathcal{M}\}
\end{equation}

Based on these candidate nearest memories, we prompt the LLM to analyze potential connections based on their potential common attributes. Formally, the link set of memory $m_n$ update like:
\begin{equation}
    L_i \leftarrow   \text{LLM} (m_n \; \Vert  \mathcal{M}_{\text{near}}^n \; \Vert P_{s2})
\end{equation}


Each generated link $l_i$ is structured as:
$L_i = \{m_{i},..., m_{k}\}$. 
By using embedding-based retrieval as an initial filter, we enable efficient scalability while maintaining semantic relevance. \ours can quickly identify potential connections even in large memory collections without exhaustive comparison.
More importantly, the LLM-driven analysis allows for nuanced understanding of relationships that goes beyond simple similarity metrics. The language model can identify subtle patterns, causal relationships, and conceptual connections that might not be apparent from embedding similarity alone. We implements the Zettelkasten principle of flexible linking while leveraging modern language models. The resulting network emerges organically from memory content and context, enabling natural knowledge organization.

\subsection{Memory Evolution}
After creating links for the new memory, \ours evolves the retrieved memories based on their textual information and relationships with the new memory. For each memory $m_j$ in the nearest neighbor set $\mathcal{M}_{\text{near}}^n$, the system determines whether to update its context, keywords, and tags. This evolution process can be formally expressed as:

\begin{equation}
    m_j^* \leftarrow   \text{LLM} (m_n \; \Vert  \mathcal{M}_{\text{near}}^n \setminus m_j  \;  \Vert m_j \;  \Vert P_{s3})
\end{equation}

The evolved memory $m_j^*$ then replaces the original memory $m_j$ in the memory set $\mathcal{M}$. This evolutionary approach enables continuous updates and new connections, mimicking human learning processes. As the system processes more memories over time, it develops increasingly sophisticated knowledge structures, discovering higher-order patterns and concepts across multiple memories. This creates a foundation for autonomous memory learning where knowledge organization becomes progressively richer through the ongoing interaction between new experiences and existing memories.

\subsection{Retrieve Relative Memory}
In each interaction, our \ours performs context-aware memory retrieval to provide the agent with relevant historical information. Given a query text $q$ from the current interaction, we first compute its dense vector representation using the same text encoder used for memory notes:

\begin{equation}
e_q = f_{\text{enc}}(q)
\end{equation}

The system then computes similarity scores between the query embedding and all existing memory notes in $\mathcal{M}$ using cosine similarity:

\begin{equation}
s_{q,i} = \frac{e_q \cdot e_i}{|e_q| |e_i|}, \text{where} \;  e_i \in m_i,\; \forall m_i \in \mathcal{M}
\end{equation}

Then we retrieve the k most relevant memories from the historical memory storage to construct a contextually appropriate prompt.

\begin{equation}
\mathcal{M}_{\text{retrieved}} = \{m_i | \text{rank}(s_{q,i}) \leq k, m_i \in \mathcal{M}\}
\end{equation}

These retrieved memories provide relevant historical context that helps the agent better understand and respond to the current interaction. The retrieved context enriches the agent's reasoning process by connecting the current interaction with related past experiences and knowledge stored in the memory system.

\section{Experiment}
\subsection{Dataset and Evaluation}
To evaluate the effectiveness of instruction-aware recommendation in long-term conversations, we utilize the LoCoMo dataset~\citep{locomo}, which contains significantly longer dialogues compared to existing conversational datasets~\citep{xu2021beyond,jang2023conversation}. While previous datasets contain dialogues with around 1K tokens over 4-5 sessions, LoCoMo features much longer conversations averaging 9K tokens spanning up to 35 sessions, making it particularly suitable for evaluating models' ability to handle long-range dependencies and maintain consistency over extended conversations.
The LoCoMo dataset comprises diverse question types designed to comprehensively evaluate different aspects of model understanding: (1) single-hop questions answerable from a single session; (2) multi-hop questions requiring information synthesis across sessions; (3) temporal reasoning questions testing understanding of time-related information; (4) open-domain knowledge questions requiring integration of conversation context with external knowledge; and (5) adversarial questions assessing models' ability to identify unanswerable queries. In total, LoCoMo contains 7,512 question-answer pairs across these categories.

For evaluation, we employ two primary metrics: the F1 score to assess answer accuracy by balancing precision and recall, and BLEU-1~\citep{papineni2002bleu} to evaluate generated response quality by measuring word overlap with ground truth responses. Also, we report the average token length for answering one question. Besides, we report the experiment results with four extra metrics including ROUGE-L, ROUGE-2, METEOR and SBERT Similarity in the Appendix~\ref{app:comparison results}.

\subsection{Implementation Details}
% 对于所有的baseline以及我们的方法，使用相同的system prompt，可以在appendix那个里面看到。对于使用的qwen1.5b/3b和llama 3.2 1b/3b模型，我们使用ollama进行本地部署和推理使用。为了获取结构化输出，我们使用litellm限制ollama模型的输出。对于gpt，使用官方的strutted output的接口。对于retrieve出来的top-k的memory，我们默认使用k=10来保证effiency，在个别category上，我们调大了k，来取得更好的效果，具体的k值可以参考在附录。对于使用text embedding 得model，我们选用了all-minilm-l6-v2.
For all baselines and our proposed method, we maintain consistency by employing identical system prompts as detailed in Appendix~\ref{app:sec:prompt}. The deployment of Qwen-1.5B/3B and Llama 3.2 1B/3B models is accomplished through local instantiation using Ollama~\footnote{\url{https://github.com/ollama/ollama}}, with LiteLLM~\footnote{\url{https://github.com/BerriAI/litellm}} managing structured output generation. For GPT models, we utilize the official structured output API. In our memory retrieval process, we primarily employ $k$=10 for top-$k$ memory selection to maintain computational efficiency, while adjusting this parameter for specific categories to optimize performance. The detailed configurations of $k$ can be found in Appendix~\ref{app:sec:hyper}. For text embedding, we implement the all-minilm-l6-v2 model across all experiments.

\begin{table*}[tb!]
% \small
\centering
\caption{
    Experimental results on LoCoMo dataset of QA tasks across five categories (Single Hop, Multi Hop, Temporal, Open Domain, and Adversial) using different methods. Results are reported in F1 and BLEU-1 (\%) scores. The best performance is marked in bold, and our proposed method A-MEM (highlighted in gray) demonstrates competitive performance across six foundation language models.
}
\label{tab:main}
\vspace{-5pt}
\resizebox{\textwidth}{!}{%
\begin{tabular}{ccl|cccccccccc|ccc}
\hline
\multicolumn{2}{c}{\multirow{3}{*}{\textbf{Model}}} & \multicolumn{1}{c|}{\multirow{3}{*}{\textbf{Method}}} & \multicolumn{10}{c|}{\textbf{Category}} & \multicolumn{3}{c}{\textbf{Average}} \\ \cline{4-16} 
\multicolumn{2}{c}{} & \multicolumn{1}{c|}{} & \multicolumn{2}{c|}{\textbf{Single Hop}} & \multicolumn{2}{c|}{\textbf{Multi Hop}} & \multicolumn{2}{c|}{\textbf{Temporal}} & \multicolumn{2}{c|}{\textbf{Open Domain}} & \multicolumn{2}{c|}{\textbf{Adversial}}  & \multicolumn{2}{c|}{\textbf{Ranking}} & \textbf{Token} \\
\multicolumn{2}{c}{} & \multicolumn{1}{c|}{} & \textbf{F1} & \multicolumn{1}{c|}{\textbf{BLEU-1}} & \textbf{F1} & \multicolumn{1}{c|}{\textbf{BLEU-1}} & \textbf{F1} & \multicolumn{1}{c|}{\textbf{BLEU-1}} & \textbf{F1} & \multicolumn{1}{c|}{\textbf{BLEU-1}} & \textbf{F1} & \multicolumn{1}{c|}{\textbf{BLEU-1}} & \textbf{F1} & \multicolumn{1}{c|}{\textbf{BLEU-1}} & \textbf{Length} \\ \hline

\multirow{10}{*}{\textbf{\rotatebox{90}{GPT}}} & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{4o-mini}}}} & \textsc{LoCoMo} & 25.02 & \multicolumn{1}{c|}{19.75} & 18.41 & \multicolumn{1}{c|}{14.77} & 12.04 & \multicolumn{1}{c|}{11.16} & 40.36 & \multicolumn{1}{c|}{29.05} & \bs{69.23} & \multicolumn{1}{c|}{\bs{68.75}} & 2.4 & \multicolumn{1}{c|}{2.4} & 16,910 \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 9.15 & \multicolumn{1}{c|}{6.48} & 12.60 & \multicolumn{1}{c|}{8.87} & 5.31 & \multicolumn{1}{c|}{5.12} & 9.67 & \multicolumn{1}{c|}{7.66} & 9.81 & \multicolumn{1}{c|}{9.02} & 4.2 & \multicolumn{1}{c|}{4.2} & 643 \\
 
  & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 5.00 & \multicolumn{1}{c|}{4.77} & 9.68 & \multicolumn{1}{c|}{6.99} & 5.56 & \multicolumn{1}{c|}{5.94} & 6.61 & \multicolumn{1}{c|}{5.16} & 7.36 & \multicolumn{1}{c|}{6.48} & 4.8 & \multicolumn{1}{c|}{4.8} & 432 \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 26.65 & \multicolumn{1}{c|}{17.72} & 25.52 & \multicolumn{1}{c|}{19.44} & 9.15 & \multicolumn{1}{c|}{7.44} & 41.04 & \multicolumn{1}{c|}{34.34} & 43.29 & \multicolumn{1}{c|}{42.73} & 2.4 & \multicolumn{1}{c|}{2.4} & 16,977 \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{27.02} & \multicolumn{1}{c|}{\cem\bs{20.09}} & \cem\bs{45.85} & \multicolumn{1}{c|}{\cem\bs{36.67}} & \cem\bs{12.14} & \multicolumn{1}{c|}{\cem\bs{12.00}} & \cem\bs{44.65} & \multicolumn{1}{c|}{\cem\bs{37.06}} & \cem 50.03 & \multicolumn{1}{c|}{\cem 49.47} & \cem\bs{1.2} & \multicolumn{1}{c|}{\cem\bs{1.2}} & \cem 2,520 \\ \cline{2-16} 
 
 & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{4o}}}} & \textsc{LoCoMo} & 28.00 & \multicolumn{1}{c|}{18.47} & 9.09 & \multicolumn{1}{c|}{5.78} & 16.47 & \multicolumn{1}{c|}{14.80} & \bs{61.56} & \multicolumn{1}{c|}{\bs{54.19}} & \bs{52.61} & \multicolumn{1}{c|}{\bs{51.13}} & 2.0 & \multicolumn{1}{c|}{2.0} & 16,910 \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 14.61 & \multicolumn{1}{c|}{9.95} & 4.16 & \multicolumn{1}{c|}{3.19} & 8.84 & \multicolumn{1}{c|}{8.37} & 12.46 & \multicolumn{1}{c|}{10.29} & 6.81 & \multicolumn{1}{c|}{6.13} & 4.0 & \multicolumn{1}{c|}{4.0} & 805 \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 6.49 & \multicolumn{1}{c|}{4.69} & 2.47 & \multicolumn{1}{c|}{2.43} & 6.43 & \multicolumn{1}{c|}{5.30} & 8.28 & \multicolumn{1}{c|}{7.10} & 4.42 & \multicolumn{1}{c|}{3.67} & 5.0 & \multicolumn{1}{c|}{5.0} & 569 \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 30.36 & \multicolumn{1}{c|}{22.83} & 17.29 & \multicolumn{1}{c|}{13.18} & 12.24 & \multicolumn{1}{c|}{11.87} & 60.16 & \multicolumn{1}{c|}{53.35} & 34.96 & \multicolumn{1}{c|}{34.25} & 2.4 & \multicolumn{1}{c|}{2.4} & 16,987 \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{32.86} & \multicolumn{1}{c|}{\cem\bs{23.76}} & \cem\bs{39.41} & \multicolumn{1}{c|}{\cem\bs{31.23}} & \cem\bs{17.10} & \multicolumn{1}{c|}{\cem\bs{15.84}} & \cem 48.43 & \multicolumn{1}{c|}{\cem 42.97} & \cem 36.35 & \multicolumn{1}{c|}{\cem 35.53} & \cem\bs{1.6} & \multicolumn{1}{c|}{\cem\bs{1.6}} & \cem 1,216 \\  \hline

 \multirow{10}{*}{\textbf{\rotatebox{90}{Qwen2.5}}} & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{1.5b}}}} & \textsc{LoCoMo} & 9.05 & \multicolumn{1}{c|}{6.55} & 4.25 & \multicolumn{1}{c|}{4.04} & 9.91 & \multicolumn{1}{c|}{8.50} & 11.15 & \multicolumn{1}{c|}{8.67} & 40.38 & \multicolumn{1}{c|}{40.23} & 3.4 & \multicolumn{1}{c|}{3.4} & 16,910 \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 6.61 & \multicolumn{1}{c|}{4.93} & 2.55 & \multicolumn{1}{c|}{2.51} & 5.31 & \multicolumn{1}{c|}{12.24} & 10.13 & \multicolumn{1}{c|}{7.54} & 5.42 & \multicolumn{1}{c|}{27.32} & 4.6 & \multicolumn{1}{c|}{4.6} & 752 \\
 
  & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 11.14 & \multicolumn{1}{c|}{8.25} & 4.46 & \multicolumn{1}{c|}{2.87} & 8.05 & \multicolumn{1}{c|}{6.21} & 13.42 & \multicolumn{1}{c|}{11.01} & 36.76 & \multicolumn{1}{c|}{34.00} & 2.6 & \multicolumn{1}{c|}{2.6} & 284 \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 10.44 & \multicolumn{1}{c|}{7.61} & 4.21 & \multicolumn{1}{c|}{3.89} & 13.42 & \multicolumn{1}{c|}{11.64} & 9.56 & \multicolumn{1}{c|}{7.34} & 31.51 & \multicolumn{1}{c|}{28.90} & 3.4 & \multicolumn{1}{c|}{3.4} &16,953 \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{18.23} & \multicolumn{1}{c|}{\cem\bs{11.94}} & \cem\bs{24.32} & \multicolumn{1}{c|}{\cem\bs{19.74}} & \cem\bs{16.48} & \multicolumn{1}{c|}{\cem\bs{14.31}} & \cem\bs{23.63} & \multicolumn{1}{c|}{\cem\bs{19.23}} & \cem\bs{46.00} & \multicolumn{1}{c|}{\cem\bs{43.26}} & \cem\bs{1.0} & \multicolumn{1}{c|}{\cem\bs{1.0}} & \cem 1,300 \\ \cline{2-16} 
 
 & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{3b}}}} & \textsc{LoCoMo} &4.61  & \multicolumn{1}{c|}{4.29} &3.11  & \multicolumn{1}{c|}{2.71} &4.55  & \multicolumn{1}{c|}{5.97} &7.03  & \multicolumn{1}{c|}{5.69} & 16.95 & \multicolumn{1}{c|}{14.81} & 3.2 & \multicolumn{1}{c|}{3.2} & 16,910 \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 2.47 & \multicolumn{1}{c|}{1.78} & 3.01 & \multicolumn{1}{c|}{3.01} & 5.57 & \multicolumn{1}{c|}{5.22} & 3.25 & \multicolumn{1}{c|}{2.51} & 15.78 & \multicolumn{1}{c|}{14.01} & 4.2 & \multicolumn{1}{c|}{4.2} & 776 \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 3.60 & \multicolumn{1}{c|}{3.39} & 1.72 & \multicolumn{1}{c|}{1.97} & 6.63 & \multicolumn{1}{c|}{6.58} & 4.11 & \multicolumn{1}{c|}{3.32} & 13.07 & \multicolumn{1}{c|}{10.30} & 4.2 & \multicolumn{1}{c|}{4.2} & 298 \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 5.07 & \multicolumn{1}{c|}{4.31} & 2.94 & \multicolumn{1}{c|}{2.95} & 7.04 & \multicolumn{1}{c|}{7.10} & 7.26 & \multicolumn{1}{c|}{5.52} & 14.47 & \multicolumn{1}{c|}{12.39} & 2.4 & \multicolumn{1}{c|}{2.4} &16,961 \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{12.57} & \multicolumn{1}{c|}{\cem\bs{9.01}} & \cem\bs{27.59} & \multicolumn{1}{c|}{\cem\bs{25.07}} & \cem\bs{7.12} & \multicolumn{1}{c|}{\cem\bs{7.28}} & \cem\bs{17.23} & \multicolumn{1}{c|}{\cem\bs{13.12}} & \cem\bs{27.91} & \multicolumn{1}{c|}{\cem\bs{25.15}} & \cem\bs{1.0} & \multicolumn{1}{c|}{\cem\bs{1.0}} & \cem 1,137 \\  \hline

  \multirow{10}{*}{\textbf{\rotatebox{90}{Llama 3.2}}} & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{1b}}}} & \textsc{LoCoMo} & 11.25 & \multicolumn{1}{c|}{9.18} & 7.38 & \multicolumn{1}{c|}{6.82} & 11.90 & \multicolumn{1}{c|}{10.38} & 12.86 & \multicolumn{1}{c|}{10.50} & 51.89 & \multicolumn{1}{c|}{48.27} & 3.4 & \multicolumn{1}{c|}{3.4} & 16,910 \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 5.96 & \multicolumn{1}{c|}{5.12} & 1.93 & \multicolumn{1}{c|}{2.30} & 12.46 & \multicolumn{1}{c|}{11.17} & 7.75 & \multicolumn{1}{c|}{6.03} & 44.64 & \multicolumn{1}{c|}{40.15} & 4.6 & \multicolumn{1}{c|}{4.6} & 665 \\
 
  & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 13.18 & \multicolumn{1}{c|}{10.03} & 7.61 & \multicolumn{1}{c|}{6.27} & 15.78 & \multicolumn{1}{c|}{12.94} & 17.30 & \multicolumn{1}{c|}{14.03} & 52.61 & \multicolumn{1}{c|}{47.53} & 2.0 & \multicolumn{1}{c|}{2.0} & 274 \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 9.19 & \multicolumn{1}{c|}{6.96} & 4.02 & \multicolumn{1}{c|}{4.79} & 11.14 & \multicolumn{1}{c|}{8.24} & 10.16 & \multicolumn{1}{c|}{7.68} & 49.75 & \multicolumn{1}{c|}{45.11} & 4.0 & \multicolumn{1}{c|}{4.0} &16,950 \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{19.06} & \multicolumn{1}{c|}{\cem\bs{11.71}} & \cem\bs{17.80} & \multicolumn{1}{c|}{\cem\bs{10.28}} & \cem\bs{17.55} & \multicolumn{1}{c|}{\cem\bs{14.67}} & \cem\bs{28.51} & \multicolumn{1}{c|}{\cem\bs{24.13}} & \cem\bs{58.81} & \multicolumn{1}{c|}{\cem\bs{54.28}} & \cem\bs{1.0} & \multicolumn{1}{c|}{\cem\bs{1.0}} & \cem 1,376 \\ \cline{2-16} 
 
 & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{3b}}}} & \textsc{LoCoMo} & 6.88 & \multicolumn{1}{c|}{5.77} & 4.37 & \multicolumn{1}{c|}{4.40} & 10.65 & \multicolumn{1}{c|}{9.29} & 8.37 & \multicolumn{1}{c|}{6.93} & 30.25 & \multicolumn{1}{c|}{28.46} & 2.8 & \multicolumn{1}{c|}{2.8} & 16,910 \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 2.47 & \multicolumn{1}{c|}{1.78} & 3.01 & \multicolumn{1}{c|}{3.01} & 5.57 & \multicolumn{1}{c|}{5.22} & 3.25 & \multicolumn{1}{c|}{2.51} & 15.78 & \multicolumn{1}{c|}{14.01} & 4.2 & \multicolumn{1}{c|}{4.2} & 461 \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 6.19 & \multicolumn{1}{c|}{4.47} & 3.49 & \multicolumn{1}{c|}{3.13} & 4.07 & \multicolumn{1}{c|}{4.57} &7.61  & \multicolumn{1}{c|}{6.03} & 18.65 & \multicolumn{1}{c|}{17.05} & 3.2 &  \multicolumn{1}{c|}{3.2} & 263 \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 5.32 & \multicolumn{1}{c|}{3.99} & 2.68 & \multicolumn{1}{c|}{2.72} & 5.64 & \multicolumn{1}{c|}{5.54} & 4.32 & \multicolumn{1}{c|}{3.51} & 21.45 & \multicolumn{1}{c|}{19.37} & 3.8 & \multicolumn{1}{c|}{3.8} & 16,956 \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{17.44} & \multicolumn{1}{c|}{\cem\bs{11.74}} & \cem\bs{26.38} & \multicolumn{1}{c|}{\cem\bs{19.50}} & \cem\bs{12.53} & \multicolumn{1}{c|}{\cem\bs{11.83}} & \cem\bs{28.14} & \multicolumn{1}{c|}{\cem\bs{23.87}} & \cem\bs{42.04} & \multicolumn{1}{c|}{\cem\bs{40.60}} & \cem\bs{1.0} & \multicolumn{1}{c|}{\cem\bs{1.0}} & \cem 1,126 \\  \hline
\end{tabular}%
}
% \vspace{-10pt}
\end{table*}

\subsection{Baselines}
\noindent \textbf{LoCoMo}~\cite{locomo} takes a direct approach by leveraging foundation models without memory mechanisms for question answering tasks. For each query, it incorporates the complete preceding conversation and questions into the prompt, evaluating the model's reasoning capabilities.

\noindent \textbf{ReadAgent}~\cite{readagent} tackles long-context document processing through a sophisticated three-step methodology: it begins with episode pagination to segment content into manageable chunks, followed by memory gisting to distill each page into concise memory representations, and concludes with interactive look-up to retrieve pertinent information as needed.

\noindent \textbf{MemoryBank}~\cite{memorybank} introduces an innovative memory management system that maintains and efficiently retrieves historical interactions. The system features a dynamic memory updating mechanism based on the Ebbinghaus Forgetting Curve theory, which intelligently adjusts memory strength according to time and significance. Additionally, it incorporates a user portrait building system that progressively refines its understanding of user personality through continuous interaction analysis.

\noindent \textbf{MemGPT}~\cite{memgpt} presents a novel virtual context management system drawing inspiration from traditional operating systems' memory hierarchies. The architecture implements a dual-tier structure: a main context (analogous to RAM) that provides immediate access during LLM inference, and an external context (analogous to disk storage) that maintains information beyond the fixed context window.

\subsection{Empricial Results}
\begin{table*}[tb!]
% \small
\centering
\caption{
    An ablation study was conducted to evaluate our proposed method against the GPT-4-mini base model. The notation 'w/o' indicates experiments where specific modules were removed. The abbreviations LG and ME denote the link generation module and memory evolution module, respectively.
}
\label{tab:main}
% \vspace{-5pt}
\resizebox{0.9\textwidth}{!}{%
\begin{tabular}{l|cccccccccc}
\toprule
 \multicolumn{1}{l}{\multirow{3}{*}{\textbf{Method}}} & \multicolumn{10}{c}{\textbf{Category}}  \\ \hline
 \multicolumn{1}{c|}{} & \multicolumn{2}{c|}{\textbf{Single Hop}} & \multicolumn{2}{c|}{\textbf{Multi Hop}} & \multicolumn{2}{c|}{\textbf{Temporal}} & \multicolumn{2}{c|}{\textbf{Open Domain}} & \multicolumn{2}{c}{\textbf{Adversial}}   \\
 \multicolumn{1}{c|}{} & \textbf{F1} & \multicolumn{1}{c|}{\textbf{BLEU-1}} & \textbf{F1} & \multicolumn{1}{c|}{\textbf{BLEU-1}} & \textbf{F1} & \multicolumn{1}{c|}{\textbf{BLEU-1}} & \textbf{F1} & \multicolumn{1}{c|}{\textbf{BLEU-1}} & \textbf{F1} & \textbf{BLEU-1} \\ \hline

w/o LG \& ME & 9.65 & \multicolumn{1}{c|}{7.09} & 24.55 & \multicolumn{1}{c|}{19.48} & 7.77 & \multicolumn{1}{c|}{6.70} & 13.28 & \multicolumn{1}{c|}{10.30} & 15.32 & 18.02  \\

w/o ME & 21.35 & \multicolumn{1}{c|}{15.13} & 31.24 & \multicolumn{1}{c|}{27.31} & 10.13 & \multicolumn{1}{c|}{10.85} & 39.17 & \multicolumn{1}{c|}{34.70} & 44.16 & 45.33 \\
 
\cem{\bf\ours} & \cem\bs{27.02} & \multicolumn{1}{c|}{\cem\bs{20.09}} & \cem\bs{45.85} & \multicolumn{1}{c|}{\cem\bs{36.67}} & \cem\bs{12.14} & \multicolumn{1}{c|}{\cem\bs{12.00}} & \cem\bs{44.65} & \multicolumn{1}{c|}{\cem\bs{37.06}} & \cem\bs{50.03} & \cem\bs{49.47} \\ \toprule
 
\end{tabular}%
}
% \vspace{-10pt}
\end{table*}

\begin{figure*}[tb!]
\centering
\subfigure[Single Hop]{
\begin{minipage}[t]{0.30\linewidth}
\centering
\includegraphics[width=0.99\linewidth]{figure/performance_metrics_c1.pdf}
%\caption{fig1}
\end{minipage}%
}%
\subfigure[Multi Hop]{
\begin{minipage}[t]{0.30\linewidth}
\centering
\includegraphics[width=0.99\linewidth]{figure/performance_metrics_c2.pdf}
%\caption{fig2}
\end{minipage}%
}%
\subfigure[Temporal]{
\begin{minipage}[t]{0.30\linewidth}
\centering
\includegraphics[width=0.99\linewidth]{figure/performance_metrics_c3.pdf}
%\caption{fig2}
\end{minipage}%
}%
\\
\subfigure[Open Domain]{
\begin{minipage}[t]{0.30\linewidth}
\centering
\includegraphics[width=0.99\linewidth]{figure/performance_metrics_c4.pdf}
%\caption{fig2}
\end{minipage}%
}%
\subfigure[Adverisal]{
\begin{minipage}[t]{0.30\linewidth}
\centering
\includegraphics[width=0.99\linewidth]{figure/performance_metrics_c5.pdf}
%\caption{fig2}
\end{minipage}%
}%
\centering  
% \captionsetup{font={footnotesize}}
\caption{Impact of memory retrieval parameter k across different task categories with GPT-4o-mini as the base model. While larger k values generally improve performance by providing richer historical context, the gains diminish beyond certain thresholds, suggesting a trade-off between context richness and effective information processing. This pattern is consistent across all evaluation categories, indicating the importance of balanced context retrieval for optimal performance.}
\label{fig:hyper}
\end{figure*}

In our empirical evaluation, we compared A-MEM with four competitive baselines including LoCoMo, ReadAgent, MemoryBank, and MemGPT on the LoCoMo dataset. For non-GPT foundation models, our \ours consistently outperforms all baselines across different categories, demonstrating the effectiveness of our agentic memory approach. For GPT-based models, while LoCoMo and MemGPT show strong performance in certain categories like Open Domain and Adversial tasks due to their robust pre-trained knowledge in simple fact retrieval, our A-MEM demonstrates superior performance in Multi-Hop tasks achieves at least two times better performance that require complex reasoning chains. The effectiveness of \ours stems from its novel agentic memory architecture that enables dynamic and structured memory management. Unlike traditional approaches that use static memory operations, our system creates interconnected memory networks through atomic notes with rich contextual descriptions, enabling more effective multi-hop reasoning. The system's ability to dynamically establish connections between memories based on shared attributes and continuously update existing memory descriptions with new contextual information allows it to better capture and utilize the relationships between different pieces of information.
Notably, \ours achieves these improvements while maintaining significantly lower token length requirements compared to LoCoMo and MemGPT (around 1,200-2,500 tokens versus 16,900 tokens) through our selective top-k retrieval mechanism. In conclusion, our empirical results demonstrate that \ours successfully combines structured memory organization with dynamic memory evolution, leading to superior performance in complex reasoning tasks while maintaining computational efficiency.



\subsection{Ablation Study}
To evaluate the effectiveness of the Link Generation (LG) and Memory Evolution (ME) modules, we conduct the ablation study by systematically removing key components of our model. When both LG and ME modules are removed, the system exhibits substantial performance degradation, particularly in Multi Hop reasoning and Open Domain tasks. The system with only LG active (w/o ME) shows intermediate performance levels, maintaining significantly better results than the version without both modules, which demonstrates the fundamental importance of link generation in establishing memory connections. Our full model, A-MEM, consistently achieves the best performance across all evaluation categories, with particularly strong results in complex reasoning tasks. These results reveal that while the link generation module serves as a critical foundation for memory organization, the memory evolution module provides essential refinements to the memory structure. The ablation study validates our architectural design choices and highlights the complementary nature of these two modules in creating an effective memory system.

\subsection{Hyperparameter Analysis}
We conducted extensive experiments to analyze the impact of the memory retrieval parameter k, which controls the number of relevant memories retrieved for each interaction. As shown in Figure~\ref{fig:hyper}, we evaluated performance across different k values ({10, 20, 30, 40, 50}) on five categories of tasks using GPT-4-mini as our base model. The results reveal an interesting pattern: while increasing k generally leads to improved performance, this improvement gradually plateaus and sometimes slightly decreases at higher values. This trend is particularly evident in Multi Hop and Open Domain tasks. The observation suggests a delicate balance in memory retrieval - while larger k values provide richer historical context for reasoning, they may also introduce noise and challenge the model's capacity to process longer sequences effectively. Our analysis indicates that moderate k values strike an optimal balance between context richness and information processing efficiency.

\subsection{Memory Analysis}
We present the t-SNE visualization in Figure~\ref{fig:visual}  of memory embeddings to demonstrate the structural advantages of our agentic memory system. Analyzing two dialogues sampled from long-term conversations in LoCoMo~\cite{locomo}, we observe that \ours (shown in blue) consistently exhibits more coherent clustering patterns compared to the baseline system (shown in red). This structural organization is particularly evident in Dialogue 2, where well-defined clusters emerge in the central region, providing empirical evidence for the effectiveness of our memory evolution mechanism and contextual description generation. In contrast, the baseline memory embeddings display a more dispersed distribution, demonstrating that memories lack structural organization without our link generation and memory evolution components. These visualization results validate that \ours can autonomously maintain meaningful memory structures through dynamic evolution and linking mechanisms. More results can be seen in Appendix~\ref{app:sec:vis}.

\begin{figure}[tb!]
\centering
\subfigure[Dialogue 1]{
\begin{minipage}[t]{0.65\linewidth}
\centering
\includegraphics[width=0.99\linewidth]{figure/tsne_comparison_sample_0.pdf}
%\caption{fig1}
\end{minipage}%
}
\\
\subfigure[Dialogue 2]{
\begin{minipage}[t]{0.65\linewidth}
\centering
\includegraphics[width=0.99\linewidth]{figure/tsne_comparison_sample_1.pdf}
%\caption{fig2}
\end{minipage}%
}%
% \captionsetup{font={footnotesize}}
\caption{T-SNE Visualization of Memory Embeddings Showing More Organized Distribution with \ours (blue) Compared to Base Memory (red) Across Different Dialogues. Base Memory represents \ours without link generation and memory evolution.}
\label{fig:visual}
\vspace{-10pt}
\end{figure}

\section{Conclusion}
In this work, we introduced \ours, a novel agentic memory system that enables LLM agents to dynamically organize and evolve their memories without relying on predefined structures. Drawing inspiration from the Zettelkasten method, our system creates an interconnected knowledge network through dynamic indexing and linking mechanisms that adapt to diverse real-world tasks. The system's core architecture features autonomous generation of contextual descriptions for new memories and intelligent establishment of connections with existing memories based on shared attributes. Furthermore, our approach enables continuous evolution of historical memories by incorporating new experiences and developing higher-order attributes through ongoing interactions. Through extensive empirical evaluation across six foundation models, we demonstrated that \ours achieves superior performance compared to existing state-of-the-art baselines in long-term conversational tasks. Visualization analysis further validates the effectiveness of our memory organization approach. 
These results suggest that agentic memory systems can significantly enhance LLM agents' ability to utilize long-term knowledge in complex environments.


\section{Limitation}
While our agentic memory system achieves promising results, we acknowledge several areas for potential future exploration. First, although our system dynamically organizes memories, the quality of these organizations may still be influenced by the inherent capabilities of the underlying language models. Different LLMs might generate slightly different contextual descriptions or establish varying connections between memories. Additionally, while our current implementation focuses on text-based interactions, future work could explore extending the system to handle multimodal information, such as images or audio, which could provide richer contextual representations. 

\bibliography{acl}

% \newpage

\clearpage
% \section*{APPENDIX}
\onecolumn
\tableofcontents

\clearpage

\section*{APPENDIX}
% \clearpage
\appendix

\section{Detailed Related Work}
\subsection{Memory for LLM Agents}
Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, including natural language processing, code generation, and recommender systems~\cite{wang2023brave,zhang2024gder,xu2024slmrec,xu2024rethinking,xu2023neural}. LLM-based agents further extend these capabilities by enabling interactive decision-making and executing complex workflows through structured interaction patterns~\cite{jin-etal-2024-impact,zhang2024cut,zhang2024g}.
Prior works on LLM agent memory systems have explored various mechanisms for memory management and utilization~\cite{aios,agentlite,mem0,memorybank}. Some approaches complete interaction storage, which maintains comprehensive historical records through dense retrieval models~\cite{memorybank} or read-write memory structures~\cite{modarressi2023ret}. Moreover, MemGPT~\cite{memgpt} leverages cache-like architectures to prioritize recent information. Similarly, SCM~\cite{wang2023enhancing} proposes a Self-Controlled Memory framework that enhances LLMs' capability to maintain long-term memory through a memory stream and controller mechanism.
However, these approaches face significant limitations in handling diverse real-world tasks. While they can provide basic memory functionality, their operations are typically constrained by predefined structures and fixed workflows. These constraints stem from their reliance on rigid operational patterns, particularly in memory writing and retrieval processes. Such inflexibility leads to poor generalization in new environments and limited effectiveness in long-term interactions. Therefore, designing a flexible and universal memory system that supports agents' long-term interactions remains a crucial challenge.

\section{Experiment}
\subsection{Evaluation Metric}
The F1 score represents the harmonic mean of precision and recall, offering a balanced metric that combines both measures into a single value. This metric is particularly valuable when we need to balance between complete and accurate responses:
\begin{equation}
    F1 = 2 \cdot \frac{\text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}}
\end{equation}
where 
\begin{equation}
    \text{precision} = \frac{\text{true positives}}{\text{true positives} + \text{false positives}}
\end{equation}

\begin{equation}
    \text{recall} = \frac{\text{true positives}}{\text{true positives} + \text{false negatives}}
\end{equation}
In question-answering systems, the F1 score serves a crucial role in evaluating exact matches between predicted and reference answers. This is especially important for span-based QA tasks, where systems must identify precise text segments while maintaining comprehensive coverage of the answer.

BLEU-1~\cite{papineni2002bleu} provides a method for evaluating the precision of unigram matches between system outputs and reference texts:
\begin{equation}
    \text{BLEU-1} = BP \cdot \exp(\sum_{n=1}^{1} w_n \log p_n)
\end{equation}
where 
\begin{equation}
    BP = \begin{cases}
        1 & \text{if } c > r \\
        e^{1-r/c} & \text{if } c \leq r
        \end{cases}
\end{equation}

\begin{equation}
    p_n = \frac{\sum_{i}\sum_{k}\min(h_{ik}, m_{ik})}{\sum_{i}\sum_{k}h_{ik}}
\end{equation}
Here, \( c \) is candidate length, \( r \) is reference length, \( h_{ik} \) is the count of n-gram i in candidate k, and \( m_{ik} \) is the maximum count in any reference. In QA, BLEU-1 evaluates the lexical precision of generated answers, particularly useful for generative QA systems where exact matching might be too strict.


ROUGE-L~\cite{rouge} measures the longest common subsequence between the generated and reference texts.
\begin{equation}
    \text{ROUGE-L} = \frac{(1 + \beta^2)R_lP_l}{R_l + \beta^2P_l}
\end{equation}
\begin{equation}
    R_l = \frac{\text{LCS}(X,Y)}{|X|}
\end{equation}
\begin{equation}
    P_l = \frac{\text{LCS}(X,Y)}{|Y|}
\end{equation}
where \(X\) is reference text, \(Y \) is candidate text, and LCS is the Longest Common Subsequence.

ROUGE-2~\cite{rouge} calculates the overlap of bigrams between the generated and reference texts.
\begin{equation}
    \text{ROUGE-2} = \frac{\sum_{\text{bigram} \in \text{ref}}\min(\text{Count}_{\text{ref}}(\text{bigram}), \text{Count}_{\text{cand}}(\text{bigram}))}{\sum_{\text{bigram} \in \text{ref}}\text{Count}_{\text{ref}}(\text{bigram})}
\end{equation}

Both ROUGE-L and ROUGE-2 are particularly useful for evaluating the fluency and coherence of generated answers, with ROUGE-L focusing on sequence matching and ROUGE-2 on local word order.

\begin{table*}[tb!]
% \small
\centering
\caption{
    Experimental results on LoCoMo dataset of QA tasks across five categories (Single Hop, Multi Hop, Temporal, Open Domain, and Adversial) using different methods. Results are reported in ROUGE-2 and ROUGE-L scores, abbreviated to RGE-2 and RGE-L. The best performance is marked in bold, and our proposed method A-MEM (highlighted in gray) demonstrates competitive performance across six foundation language models.
}
\label{app:tab:rge}
% \vspace{-5pt}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccl|cccccccccc}
\hline
\multicolumn{2}{|c}{\multirow{3}{*}{\textbf{Model}}} & \multicolumn{1}{c|}{\multirow{3}{*}{\textbf{Method}}} & \multicolumn{10}{c|}{\textbf{Category}}  \\ \cline{4-13} 
\multicolumn{2}{|c}{} & \multicolumn{1}{c|}{} & \multicolumn{2}{c|}{\textbf{Single Hop}} & \multicolumn{2}{c|}{\textbf{Multi Hop}} & \multicolumn{2}{c|}{\textbf{Temporal}} & \multicolumn{2}{c|}{\textbf{Open Domain}} & \multicolumn{2}{c|}{\textbf{Adversial}}  \\
\multicolumn{2}{|c}{} & \multicolumn{1}{c|}{} & \textbf{RGE-2} & \multicolumn{1}{c|}{\textbf{RGE-L}} & \textbf{RGE-2} & \multicolumn{1}{c|}{\textbf{RGE-L}} & \textbf{RGE-2} & \multicolumn{1}{c|}{\textbf{RGE-L}} & \textbf{RGE-2} & \multicolumn{1}{c|}{\textbf{RGE-L}} & \textbf{RGE-2} & \multicolumn{1}{c|}{\textbf{RGE-L}}  \\ \hline

\multirow{10}{*}{\textbf{\rotatebox{90}{GPT}}} & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{4o-mini}}}} & \textsc{LoCoMo} & 9.64 & \multicolumn{1}{c|}{23.92} & 2.01 & \multicolumn{1}{c|}{18.09} & 3.40 & \multicolumn{1}{c|}{11.58} & 26.48 & \multicolumn{1}{c|}{40.20} & \bs{60.46} & \multicolumn{1}{c|}{\bs{69.59}}  \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 2.47 & \multicolumn{1}{c|}{9.45} & 0.95 & \multicolumn{1}{c|}{13.12} & 0.55 & \multicolumn{1}{c|}{5.76} & 2.99 & \multicolumn{1}{c|}{9.92} & 6.66 & \multicolumn{1}{c|}{9.79}  \\
 
  & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 1.18 & \multicolumn{1}{c|}{5.43} & 0.52 & \multicolumn{1}{c|}{9.64} & 0.97 & \multicolumn{1}{c|}{5.77} & 1.64 & \multicolumn{1}{c|}{6.63} & 4.55 & \multicolumn{1}{c|}{7.35}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 10.58 & \multicolumn{1}{c|}{25.60} & 4.76 & \multicolumn{1}{c|}{25.22} & 0.76 & \multicolumn{1}{c|}{9.14} & 28.44 & \multicolumn{1}{c|}{42.24} & 36.62 & \multicolumn{1}{c|}{43.75}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{10.61} & \multicolumn{1}{c|}{\cem\bs{25.86}} & \cem\bs{21.39} & \multicolumn{1}{c|}{\cem\bs{44.27}} & \cem\bs{3.42} & \multicolumn{1}{c|}{\cem\bs{12.09}} & \cem\bs{29.50} & \multicolumn{1}{c|}{\cem\bs{45.18}} & \cem 42.62 & \multicolumn{1}{c|}{\cem 50.04}  \\ \cline{2-13} 
 
 & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{4o}}}} & \textsc{LoCoMo} & 11.53 & \multicolumn{1}{c|}{30.65} & 1.68 & \multicolumn{1}{c|}{8.17} & 3.21 & \multicolumn{1}{c|}{16.33} & \bs{45.42} & \multicolumn{1}{c|}{\bs{63.86}} & \bs{45.13} & \multicolumn{1}{c|}{\bs{52.67}}  \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 3.91 & \multicolumn{1}{c|}{14.36} & 0.43 & \multicolumn{1}{c|}{3.96} & 0.52 & \multicolumn{1}{c|}{8.58} & 4.75 & \multicolumn{1}{c|}{13.41} & 4.24 & \multicolumn{1}{c|}{6.81}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 1.84 & \multicolumn{1}{c|}{7.36} & 0.36 & \multicolumn{1}{c|}{2.29} & 2.13 & \multicolumn{1}{c|}{6.85} & 3.02 & \multicolumn{1}{c|}{9.35} & 1.22 & \multicolumn{1}{c|}{4.41}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 11.55 & \multicolumn{1}{c|}{30.18} & 4.66 & \multicolumn{1}{c|}{15.83} & 3.27 & \multicolumn{1}{c|}{14.02} & 43.27 & \multicolumn{1}{c|}{62.75} & 28.72 & \multicolumn{1}{c|}{35.08}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{12.76} & \multicolumn{1}{c|}{\cem\bs{31.71}} & \cem\bs{9.82} & \multicolumn{1}{c|}{\cem\bs{25.04}} & \cem\bs{6.09} & \multicolumn{1}{c|}{\cem\bs{16.63}} & \cem 33.67 & \multicolumn{1}{c|}{\cem 50.31} & \cem 30.31 & \multicolumn{1}{c|}{\cem 36.34}  \\  \hline

 \multirow{10}{*}{\textbf{\rotatebox{90}{Qwen2.5}}} & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{1.5b}}}} & \textsc{LoCoMo} & 1.39 & \multicolumn{1}{c|}{9.24} & 0.00 & \multicolumn{1}{c|}{4.68} & 3.42 & \multicolumn{1}{c|}{10.59} & 3.25 & \multicolumn{1}{c|}{11.15} & 35.10 & \multicolumn{1}{c|}{43.61}  \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 0.74 & \multicolumn{1}{c|}{7.14} & 0.10 & \multicolumn{1}{c|}{2.81} & 3.05 & \multicolumn{1}{c|}{12.63} & 1.47 & \multicolumn{1}{c|}{7.88} & 20.73 & \multicolumn{1}{c|}{27.82}  \\
 
  & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 1.51 & \multicolumn{1}{c|}{11.18} & 0.14 & \multicolumn{1}{c|}{5.39} & 1.80 & \multicolumn{1}{c|}{8.44} & 5.07 & \multicolumn{1}{c|}{13.72} & 29.24 & \multicolumn{1}{c|}{36.95} \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 1.16 & \multicolumn{1}{c|}{11.35} & 0.00 & \multicolumn{1}{c|}{7.88} & 2.87 & \multicolumn{1}{c|}{14.62} & 2.18 & \multicolumn{1}{c|}{9.82} & 23.96 & \multicolumn{1}{c|}{31.69}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{4.88} & \multicolumn{1}{c|}{\cem\bs{17.94}} & \cem\bs{5.88} & \multicolumn{1}{c|}{\cem\bs{27.23}} & \cem\bs{3.44} & \multicolumn{1}{c|}{\cem\bs{16.87}} & \cem\bs{12.32} & \multicolumn{1}{c|}{\cem\bs{24.38}} & \cem\bs{36.32} & \multicolumn{1}{c|}{\cem\bs{46.60}}  \\ \cline{2-13} 
 
 & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{3b}}}} & \textsc{LoCoMo} & 0.49  & \multicolumn{1}{c|}{4.83} & 0.14  & \multicolumn{1}{c|}{3.20} & 1.31  & \multicolumn{1}{c|}{5.38} & 1.97  & \multicolumn{1}{c|}{6.98} & 12.66 & \multicolumn{1}{c|}{17.10}  \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 0.08 & \multicolumn{1}{c|}{4.08} & 0.00 & \multicolumn{1}{c|}{1.96} & 1.26 & \multicolumn{1}{c|}{6.19} & 0.73 & \multicolumn{1}{c|}{4.34} & 7.35 & \multicolumn{1}{c|}{10.64}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 0.43 & \multicolumn{1}{c|}{3.76} & 0.05 & \multicolumn{1}{c|}{1.61} & 0.24 & \multicolumn{1}{c|}{6.32} & 1.03 & \multicolumn{1}{c|}{4.22} & 9.55 & \multicolumn{1}{c|}{13.41}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 0.69 & \multicolumn{1}{c|}{5.55} & 0.05 & \multicolumn{1}{c|}{3.17} & 1.90 & \multicolumn{1}{c|}{7.90} & 2.05 & \multicolumn{1}{c|}{7.32} & 10.46 & \multicolumn{1}{c|}{14.39}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{2.91} & \multicolumn{1}{c|}{\cem\bs{12.42}} & \cem\bs{8.11} & \multicolumn{1}{c|}{\cem\bs{27.74}} & \cem\bs{1.51} & \multicolumn{1}{c|}{\cem\bs{7.51}} & \cem\bs{8.80} & \multicolumn{1}{c|}{\cem\bs{17.57}} & \cem\bs{21.39} & \multicolumn{1}{c|}{\cem\bs{27.98}}  \\  \hline

  \multirow{10}{*}{\textbf{\rotatebox{90}{Llama 3.2}}} & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{1b}}}} & \textsc{LoCoMo} & 2.51 & \multicolumn{1}{c|}{11.48} & 0.44 & \multicolumn{1}{c|}{8.25} & 1.69 & \multicolumn{1}{c|}{13.06} & 2.94 & \multicolumn{1}{c|}{13.00} & 39.85 & \multicolumn{1}{c|}{52.74}  \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 0.53 & \multicolumn{1}{c|}{6.49} & 0.00 & \multicolumn{1}{c|}{4.62} & 5.47 & \multicolumn{1}{c|}{14.29} & 1.19 & \multicolumn{1}{c|}{8.03} & 34.52 & \multicolumn{1}{c|}{45.55}  \\
 
  & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 2.96 & \multicolumn{1}{c|}{13.57} & 0.23 & \multicolumn{1}{c|}{10.53} & 4.01 & \multicolumn{1}{c|}{18.38} & 6.41 & \multicolumn{1}{c|}{17.66} & 41.15 & \multicolumn{1}{c|}{53.31}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 1.82 & \multicolumn{1}{c|}{9.91} & 0.06 & \multicolumn{1}{c|}{6.56} & 2.13 & \multicolumn{1}{c|}{11.36} & 2.00 & \multicolumn{1}{c|}{10.37} & 38.59 & \multicolumn{1}{c|}{50.31}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{4.82} & \multicolumn{1}{c|}{\cem\bs{19.31}} & \cem\bs{1.84} & \multicolumn{1}{c|}{\cem\bs{20.47}} & \cem\bs{5.99} & \multicolumn{1}{c|}{\cem\bs{18.49}} & \cem\bs{14.82} & \multicolumn{1}{c|}{\cem\bs{29.78}} & \cem\bs{46.76} & \multicolumn{1}{c|}{\cem\bs{60.23}}  \\ \cline{2-13} 
 
 & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{3b}}}} & \textsc{LoCoMo} & 0.98 & \multicolumn{1}{c|}{7.22} & 0.03 & \multicolumn{1}{c|}{4.45} & 2.36 & \multicolumn{1}{c|}{11.39} & 2.85 & \multicolumn{1}{c|}{8.45} & 25.47 & \multicolumn{1}{c|}{30.26}  \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 2.47 & \multicolumn{1}{c|}{1.78} & 3.01 & \multicolumn{1}{c|}{3.01} & 5.07 & \multicolumn{1}{c|}{5.22} & 3.25 & \multicolumn{1}{c|}{2.51} & 15.78 & \multicolumn{1}{c|}{14.01}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemoryBank}   & 1.83 & \multicolumn{1}{c|}{6.96} & 0.25 & \multicolumn{1}{c|}{3.41} & 0.43 & \multicolumn{1}{c|}{4.43} & 2.73 & \multicolumn{1}{c|}{7.83} & 14.64 & \multicolumn{1}{c|}{18.59} \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT}  & 0.72 & \multicolumn{1}{c|}{5.39} & 0.11 & \multicolumn{1}{c|}{2.85} & 0.61 & \multicolumn{1}{c|}{5.74} & 1.45 & \multicolumn{1}{c|}{4.42} & 16.62 & \multicolumn{1}{c|}{21.47}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{6.02} & \multicolumn{1}{c|}{\cem\bs{17.62}} & \cem\bs{7.93} & \multicolumn{1}{c|}{\cem\bs{27.97}} & \cem\bs{5.38} & \multicolumn{1}{c|}{\cem\bs{13.00}} & \cem\bs{16.89} & \multicolumn{1}{c|}{\cem\bs{28.55}} & \cem\bs{35.48} & \multicolumn{1}{c|}{\cem\bs{42.25}}  \\  \hline
\end{tabular}%
}
% \vspace{-10pt}
\end{table*}

\begin{table*}[tb!]
% \small
\centering
\caption{
    Experimental results on LoCoMo dataset of QA tasks across five categories (Single Hop, Multi Hop, Temporal, Open Domain, and Adversial) using different methods. Results are reported in METEOR  and SBERT Similarity  scores, abbreviated to ME and SBERT. The best performance is marked in bold, and our proposed method A-MEM (highlighted in gray) demonstrates competitive performance across six foundation language models.
}
\label{app:tab:meteor}
% \vspace{-5pt}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ccl|cccccccccc}
\hline
\multicolumn{2}{|c}{\multirow{3}{*}{\textbf{Model}}} & \multicolumn{1}{c|}{\multirow{3}{*}{\textbf{Method}}} & \multicolumn{10}{c|}{\textbf{Category}}  \\ \cline{4-13} 
\multicolumn{2}{|c}{} & \multicolumn{1}{c|}{} & \multicolumn{2}{c|}{\textbf{Single Hop}} & \multicolumn{2}{c|}{\textbf{Multi Hop}} & \multicolumn{2}{c|}{\textbf{Temporal}} & \multicolumn{2}{c|}{\textbf{Open Domain}} & \multicolumn{2}{c|}{\textbf{Adversial}}  \\
\multicolumn{2}{|c}{} & \multicolumn{1}{c|}{} & \textbf{ME} & \multicolumn{1}{c|}{\textbf{SBERT}} & \textbf{ME} & \multicolumn{1}{c|}{\textbf{SBERT}} & \textbf{ME} & \multicolumn{1}{c|}{\textbf{SBERT}} & \textbf{ME} & \multicolumn{1}{c|}{\textbf{SBERT}} & \textbf{ME} & \multicolumn{1}{c|}{\textbf{SBERT}}  \\ \hline

\multirow{10}{*}{\textbf{\rotatebox{90}{GPT}}} & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{4o-mini}}}} & \textsc{LoCoMo}  & 15.81 & \multicolumn{1}{c|}{47.97} & 7.61 & \multicolumn{1}{c|}{52.30} & 8.16 & \multicolumn{1}{c|}{35.00} & 40.42 & \multicolumn{1}{c|}{57.78} & \bs{63.28} & \multicolumn{1}{c|}{\bs{71.93}}   \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent}  & 5.46 & \multicolumn{1}{c|}{28.67} & 4.76 & \multicolumn{1}{c|}{45.07} & 3.69 & \multicolumn{1}{c|}{26.72} & 8.01 & \multicolumn{1}{c|}{26.78} & 8.38 & \multicolumn{1}{c|}{15.20} \\
 
  & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 3.42 & \multicolumn{1}{c|}{21.71} & 4.07 & \multicolumn{1}{c|}{37.58} & 4.21 & \multicolumn{1}{c|}{23.71} & 5.81 & \multicolumn{1}{c|}{20.76} & 6.24 & \multicolumn{1}{c|}{13.00}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 15.79 & \multicolumn{1}{c|}{49.33} & 13.25 & \multicolumn{1}{c|}{61.53} & 4.59 & \multicolumn{1}{c|}{32.77} & 41.40 & \multicolumn{1}{c|}{58.19} & 39.16 & \multicolumn{1}{c|}{47.24}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{16.36} & \multicolumn{1}{c|}{\cem\bs{49.46}} & \cem\bs{23.43} & \multicolumn{1}{c|}{\cem\bs{70.49}} & \cem\bs{8.36} & \multicolumn{1}{c|}{\cem\bs{38.48}} & \cem\bs{42.32} & \multicolumn{1}{c|}{\cem\bs{59.38}} & \cem 45.64 & \multicolumn{1}{c|}{\cem 53.26}  \\ \cline{2-13} 
 
 & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{4o}}}} & \textsc{LoCoMo}  & 16.34 & \multicolumn{1}{c|}{53.82} & 7.21 & \multicolumn{1}{c|}{32.15} & 8.98 & \multicolumn{1}{c|}{\bs{43.72}} & \bs{53.39} & \multicolumn{1}{c|}{\bs{73.40}} & \bs{47.72} & \multicolumn{1}{c|}{\bs{56.09}}  \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 7.86 & \multicolumn{1}{c|}{37.41} & 3.76 & \multicolumn{1}{c|}{26.22} & 4.42 & \multicolumn{1}{c|}{30.75} & 9.36 & \multicolumn{1}{c|}{31.37} & 5.47 & \multicolumn{1}{c|}{12.34}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemoryBank}  & 3.22 & \multicolumn{1}{c|}{26.23} & 2.29 & \multicolumn{1}{c|}{23.49} & 4.18 & \multicolumn{1}{c|}{24.89} & 6.64 & \multicolumn{1}{c|}{23.90} & 2.93 & \multicolumn{1}{c|}{10.01}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT} & 16.64 & \multicolumn{1}{c|}{55.12} & 12.68 & \multicolumn{1}{c|}{35.93} & 7.78 & \multicolumn{1}{c|}{37.91} & 52.14 & \multicolumn{1}{c|}{72.83} & 31.15 & \multicolumn{1}{c|}{39.08}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{17.53} & \multicolumn{1}{c|}{\cem\bs{55.96}} & \cem\bs{13.10} & \multicolumn{1}{c|}{\cem\bs{45.40}} & \cem\bs{10.62} & \multicolumn{1}{c|}{\cem 38.87} & \cem 41.93 & \multicolumn{1}{c|}{\cem 62.47} & \cem 32.34 & \multicolumn{1}{c|}{\cem 40.11}  \\  \hline

 \multirow{10}{*}{\textbf{\rotatebox{90}{Qwen2.5}}}  & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{1.5b}}}} &\textsc{LoCoMo} & 4.99 & \multicolumn{1}{c|}{32.23} & 2.86 & \multicolumn{1}{c|}{34.03} & 5.89 & \multicolumn{1}{c|}{35.61} & 8.57 & \multicolumn{1}{c|}{29.47} & 40.53 & \multicolumn{1}{c|}{50.49}  \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 3.67 & \multicolumn{1}{c|}{28.20} & 1.88 & \multicolumn{1}{c|}{27.27} & 8.97 & \multicolumn{1}{c|}{35.13} & 5.52 & \multicolumn{1}{c|}{26.33} & 24.04 & \multicolumn{1}{c|}{34.12}  \\
 
  & \multicolumn{1}{c|}{} & \textsc{MemoryBank}  & 5.57 & \multicolumn{1}{c|}{35.40} & 2.80 & \multicolumn{1}{c|}{32.47} & 4.27 & \multicolumn{1}{c|}{33.85} & 10.59 & \multicolumn{1}{c|}{32.16} & 32.93 & \multicolumn{1}{c|}{42.83} \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT}  & 5.40 & \multicolumn{1}{c|}{35.64} & 2.35 & \multicolumn{1}{c|}{39.04} & 7.68 & \multicolumn{1}{c|}{40.36} & 7.07 & \multicolumn{1}{c|}{30.16} & 27.24 & \multicolumn{1}{c|}{40.63}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours} & \cem\bs{9.49} & \multicolumn{1}{c|}{\cem\bs{43.49}} & \cem\bs{11.92} & \multicolumn{1}{c|}{\cem\bs{61.65}} & \cem\bs{9.11} & \multicolumn{1}{c|}{\cem\bs{42.58}} & \cem\bs{19.69} & \multicolumn{1}{c|}{\cem\bs{41.93}} & \cem\bs{40.64} & \multicolumn{1}{c|}{\cem\bs{52.44}}  \\ \cline{2-13} 
 
 & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{3b}}}} & \textsc{LoCoMo} & 2.00 & \multicolumn{1}{c|}{24.37} & 1.92 & \multicolumn{1}{c|}{25.24} & 3.45 & \multicolumn{1}{c|}{25.38} & 6.00 & \multicolumn{1}{c|}{21.28} & 16.67 & \multicolumn{1}{c|}{23.14}  \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent}  & 1.78 & \multicolumn{1}{c|}{21.10} & 1.69 & \multicolumn{1}{c|}{20.78} & 4.43 & \multicolumn{1}{c|}{25.15} & 3.37 & \multicolumn{1}{c|}{18.20} & 10.46 & \multicolumn{1}{c|}{17.39}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemoryBank}  & 2.37 & \multicolumn{1}{c|}{17.81} & 2.22 & \multicolumn{1}{c|}{21.93} & 3.86 & \multicolumn{1}{c|}{20.65} & 3.99 & \multicolumn{1}{c|}{16.26} & 15.49 & \multicolumn{1}{c|}{20.77}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT}  & 3.74 & \multicolumn{1}{c|}{24.31} & 2.25 & \multicolumn{1}{c|}{27.67} & 6.44 & \multicolumn{1}{c|}{29.59} & 6.24 & \multicolumn{1}{c|}{22.40} & 13.19 & \multicolumn{1}{c|}{20.83}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours}  & \cem\bs{6.25} & \multicolumn{1}{c|}{\cem\bs{33.72}} & \cem\bs{14.04} & \multicolumn{1}{c|}{\cem\bs{62.54}} & \cem\bs{6.56} & \multicolumn{1}{c|}{\cem\bs{30.60}} & \cem\bs{15.98} & \multicolumn{1}{c|}{\cem\bs{33.98}} & \cem\bs{27.36} & \multicolumn{1}{c|}{\cem\bs{33.72}}  \\  \hline

  \multirow{10}{*}{\textbf{\rotatebox{90}{Llama 3.2}}} & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{1b}}}} & \textsc{LoCoMo}  & 5.77 & \multicolumn{1}{c|}{38.02} & 3.38 & \multicolumn{1}{c|}{45.44} & 6.20 & \multicolumn{1}{c|}{42.69} & 9.33 & \multicolumn{1}{c|}{34.19} & 46.79 & \multicolumn{1}{c|}{60.74}  \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent}  & 2.97 & \multicolumn{1}{c|}{29.26} & 1.31 & \multicolumn{1}{c|}{26.45} & 7.13 & \multicolumn{1}{c|}{39.19} & 5.36 & \multicolumn{1}{c|}{26.44} & 42.39 & \multicolumn{1}{c|}{54.35}  \\
 
  & \multicolumn{1}{c|}{} & \textsc{MemoryBank}  & 6.77 & \multicolumn{1}{c|}{39.33} & 4.43 & \multicolumn{1}{c|}{45.63} & 7.76 & \multicolumn{1}{c|}{42.81} & 13.01 & \multicolumn{1}{c|}{37.32} & 50.43 & \multicolumn{1}{c|}{60.81}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT}  & 5.10 & \multicolumn{1}{c|}{32.99} & 2.54 & \multicolumn{1}{c|}{41.81} & 3.26 & \multicolumn{1}{c|}{35.99} & 6.62 & \multicolumn{1}{c|}{30.68} & 45.00 & \multicolumn{1}{c|}{61.33}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours}  & \cem\bs{9.01} & \multicolumn{1}{c|}{\cem\bs{45.16}} & \cem\bs{7.50} & \multicolumn{1}{c|}{\cem\bs{54.79}} & \cem\bs{8.30} & \multicolumn{1}{c|}{\cem\bs{43.42}} & \cem\bs{22.46} & \multicolumn{1}{c|}{\cem\bs{47.07}} & \cem\bs{53.72} & \multicolumn{1}{c|}{\cem\bs{68.00}}  \\ \cline{2-13} 
 
 & \multicolumn{1}{c|}{\multirow{5}{*}{\textbf{\rotatebox{90}{3b}}}} & \textsc{LoCoMo} & 3.69 & \multicolumn{1}{c|}{27.94} & 2.96 & \multicolumn{1}{c|}{20.40} & 6.46 & \multicolumn{1}{c|}{32.17} & 6.58 & \multicolumn{1}{c|}{22.92} & 29.02 & \multicolumn{1}{c|}{35.74}  \\

 & \multicolumn{1}{c|}{} & \textsc{ReadAgent} & 1.21 & \multicolumn{1}{c|}{17.40} & 2.33 & \multicolumn{1}{c|}{12.02} & 3.39 & \multicolumn{1}{c|}{19.63} & 2.46 & \multicolumn{1}{c|}{14.63} & 14.37 & \multicolumn{1}{c|}{21.25}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemoryBank} & 3.84 & \multicolumn{1}{c|}{25.06} & 2.73 & \multicolumn{1}{c|}{13.65} & 3.05 & \multicolumn{1}{c|}{21.08} & 6.35 & \multicolumn{1}{c|}{22.02} & 17.14 & \multicolumn{1}{c|}{24.39}  \\
 
 & \multicolumn{1}{c|}{} & \textsc{MemGPT}  & 2.78 & \multicolumn{1}{c|}{22.06} & 2.21 & \multicolumn{1}{c|}{14.97} & 3.63 & \multicolumn{1}{c|}{23.18} & 3.47 & \multicolumn{1}{c|}{17.81} & 20.50 & \multicolumn{1}{c|}{26.87}  \\
 
 & \multicolumn{1}{c|}{} & \cem{\bf\ours}  & \cem\bs{9.74} & \multicolumn{1}{c|}{\cem\bs{39.32}} & \cem\bs{13.19} & \multicolumn{1}{c|}{\cem\bs{59.70}} & \cem\bs{8.09} & \multicolumn{1}{c|}{\cem\bs{32.27}} & \cem\bs{24.30} & \multicolumn{1}{c|}{\cem\bs{42.86}} & \cem\bs{39.74} & \multicolumn{1}{c|}{\cem\bs{46.76}}  \\  \hline
\end{tabular}%
}
% \vspace{-10pt}
\end{table*}

METEOR~\cite{meteor} computes a score based on aligned unigrams between the candidate and reference texts, considering synonyms and paraphrases.
\begin{equation}
    \text{METEOR} = F_{\text{mean}} \cdot (1 - \text{Penalty})
\end{equation}
\begin{equation}
    F_{\text{mean}} = \frac{10P \cdot R}{R + 9P}
\end{equation} 
\begin{equation}
    \text{Penalty} = 0.5 \cdot (\frac{\text{ch}}{m})^3
\end{equation}
where \( P \) is precision, \( R \) is recall, ch is number of chunks, and \( m \) is number of matched unigrams. METEOR is valuable for QA evaluation as it considers semantic similarity beyond exact matching, making it suitable for evaluating paraphrased answers.

SBERT Similarity~\cite{sentence-bert} measures the semantic similarity between two texts using sentence embeddings. 

\begin{equation}
    \text{SBERT\_Similarity} = \cos(\text{SBERT}(x), \text{SBERT}(y))
\end{equation}
\begin{equation}
    \cos(a,b) = \frac{a \cdot b}{\|a\| \|b\|}
\end{equation}
SBERT(\( x \) ) represents the sentence embedding of text. SBERT Similarity is particularly useful for evaluating semantic understanding in QA systems, as it can capture meaning similarities even when the lexical overlap is low.

\subsection{Comparison Results}~\label{app:comparison results}
Our comprehensive evaluation using ROUGE-2, ROUGE-L, METEOR, and SBERT metrics demonstrates that \ours achieves superior performance while maintaining remarkable computational efficiency. Through extensive empirical testing across various model sizes and task categories, we have established \ours as a more effective approach compared to existing baselines, supported by several compelling findings.
In our analysis of non-GPT models, specifically Qwen2.5 and Llama 3.2, \ours consistently outperforms all baseline approaches across all metrics. The Multi-Hop category showcases particularly striking results, where Qwen2.5-15b with \ours achieves a ROUGE-L score of 27.23, dramatically surpassing LoComo's 4.68 and ReadAgent's 2.81 - representing a nearly six-fold improvement. This pattern of superiority extends consistently across METEOR and SBERT scores.
When examining GPT-based models, our results reveal an interesting pattern. While LoComo and MemGPT demonstrate strong capabilities in Open Domain and Adversarial tasks, \ours shows remarkable superiority in Multi-Hop reasoning tasks. Using GPT-4o-mini, \ours achieves a ROUGE-L score of 44.27 in Multi-Hop tasks, more than doubling LoComo's 18.09. This significant advantage maintains consistency across other metrics, with METEOR scores of 23.43 versus 7.61 and SBERT scores of 70.49 versus 52.30.
The significance of these results is amplified by \ours's exceptional computational efficiency. Our approach requires only 1,200-2,500 tokens, compared to the substantial 16,900 tokens needed by LoComo and MemGPT. This efficiency stems from two key architectural innovations: First, our novel agentic memory architecture creates interconnected memory networks through atomic notes with rich contextual descriptions, enabling more effective capture and utilization of information relationships. Second, our selective top-k retrieval mechanism facilitates dynamic memory evolution and structured organization. The effectiveness of these innovations is particularly evident in complex reasoning tasks, as demonstrated by the consistently strong Multi-Hop performance across all evaluation metrics.

\subsection{Memory Analysis}~\label{app:sec:vis}
In addition to the memory visualizations of the first two dialogues shown in the main text, we present additional visualizations in Fig.\ref{app:fig:visual} that demonstrate the structural advantages of our agentic memory system. Through analysis of two dialogues sampled from long-term conversations in LoCoMo\cite{locomo}, we observe that \ours (shown in blue) consistently produces more coherent clustering patterns compared to the baseline system (shown in red). This structural organization is particularly evident in Dialogue 2, where distinct clusters emerge in the central region, providing empirical support for the effectiveness of our memory evolution mechanism and contextual description generation. In contrast, the baseline memory embeddings exhibit a more scattered distribution, indicating that memories lack structural organization without our link generation and memory evolution components. These visualizations validate that \ours can autonomously maintain meaningful memory structures through its dynamic evolution and linking mechanisms.

\begin{figure}[tb!]
\centering
\subfigure[Dialogue 3]{
\begin{minipage}[t]{0.32\linewidth}
\centering
\includegraphics[width=0.90\linewidth]{figure/tsne_comparison_sample_2.pdf}
%\caption{fig1}
\end{minipage}%
}
\subfigure[Dialogue 4]{
\begin{minipage}[t]{0.32\linewidth}
\centering
\includegraphics[width=0.90\linewidth]{figure/tsne_comparison_sample_3.pdf}
%\caption{fig2}
\end{minipage}%
}% 
\subfigure[Dialogue 5]{
\begin{minipage}[t]{0.32\linewidth}
\centering
\includegraphics[width=0.90\linewidth]{figure/tsne_comparison_sample_4.pdf}
%\caption{fig1}
\end{minipage}%
}
\\
\subfigure[Dialogue 6]{
\begin{minipage}[t]{0.32\linewidth}
\centering
\includegraphics[width=0.90\linewidth]{figure/tsne_comparison_sample_5.pdf}
%\caption{fig2}
\end{minipage}%
}%
\subfigure[Dialogue 7]{
\begin{minipage}[t]{0.32\linewidth}
\centering
\includegraphics[width=0.90\linewidth]{figure/tsne_comparison_sample_6.pdf}
%\caption{fig1}
\end{minipage}%
}
\subfigure[Dialogue 8]{
\begin{minipage}[t]{0.32\linewidth}
\centering
\includegraphics[width=0.90\linewidth]{figure/tsne_comparison_sample_7.pdf}
%\caption{fig2}
\end{minipage}%
}%
\\
\subfigure[Dialogue 9]{
\begin{minipage}[t]{0.32\linewidth}
\centering
\includegraphics[width=0.90\linewidth]{figure/tsne_comparison_sample_8.pdf}
%\caption{fig1}
\end{minipage}%
}
\subfigure[Dialogue 10]{
\begin{minipage}[t]{0.32\linewidth}
\centering
\includegraphics[width=0.90\linewidth]{figure/tsne_comparison_sample_9.pdf}
%\caption{fig2}
\end{minipage}%
}%
% \captionsetup{font={footnotesize}}
\caption{T-SNE Visualization of Memory Embeddings Showing More Organized Distribution with \ours (blue) Compared to Base Memory (red) Across Different Dialogues. Base Memory represents \ours without link generation and memory evolution.}
\label{app:fig:visual}
\end{figure}

\subsection{Hyperparameters setting}~\label{app:sec:hyper}
All hyperparameter k values are presented in Table \ref{app:hyperk}. For models that have already achieved state-of-the-art (SOTA) performance with k=10, we maintain this value without further tuning.

\begin{table}[tb!]
\caption{Selection of k values in retriever across specific categories and model choices.}
\label{app:hyperk}
    \centering
    \resizebox{0.75\textwidth}{!}{%
    \begin{tabular}{lccccc}
    \toprule
        Model & Single Hop & Multi Hop & Temporal & Open Domain & Adversial \\ \midrule
        GPT-4o-mini & 40 & 40 & 50 & 50 & 40 \\
        GPT-4o & 40 & 40 & 50 & 50 & 40 \\ \hline
        Qwen2.5-1.5b & 10 & 10 & 10 & 10 & 10 \\
        Qwen2.5-3b & 10 & 10 & 50 & 10 & 10 \\ \hline
        Llama3.2-1b & 10 & 10 & 10 & 10 & 10 \\
        Llama3.2-3b & 10 & 20 & 10 & 10 & 10 \\ 
        \toprule
    \end{tabular}}
\end{table}

\clearpage

\section{Prompt Templates and Examples}~\label{app:sec:prompt}
\subsection{Prompt Template of Note Construction}

\begin{tcolorbox}[colback=white!95!gray, colframe=black, width=1\textwidth, arc=4mm, boxrule=0.5mm]
\noindent \textbf{The prompt template in Note Construction:} $P_{s1}$\\  
\texttt{Generate a structured analysis of the following content by: \\
    1. Identifying the most salient keywords (focus on nouns, verbs, and key concepts) \\
    2. Extracting core themes and contextual elements \\
    3. Creating relevant categorical tags \\ 
    Format the response as a JSON object:\\ 
    \{\\ 
                "keywords": [
                    // several specific, distinct keywords that capture key concepts and terminology
                    // Order from most to least important
                    // Don't include keywords that are the name of the speaker or time
                    // At least three keywords, but don't be too redundant.
                ],\\
                "context": 
                    // one sentence summarizing:
                    // - Main topic/domain
                    // - Key arguments/points
                    // - Intended audience/purpose
                ,\\
                "tags": [
                    // several broad categories/themes for classification
                    // Include domain, format, and type tags
                    // At least three tags, but don't be too redundant.
                ] \\
            \} \\
            Content for analysis:} 
\end{tcolorbox}
% \clearpage

\subsection{Prompt Template of Link Generation}
\begin{tcolorbox}[colback=white!95!gray, colframe=black, width=1\textwidth, arc=4mm, boxrule=0.5mm]
\noindent \textbf{The prompt template in Link Generation:} $P_{s2}$\\  
\texttt{You are an AI memory evolution agent responsible for managing and evolving a knowledge base.\\
Analyze the the new memory note according to keywords and context, also with their several nearest neighbors memory.\\
The new memory context: \\
\{context\}
content: \{content\} \\
keywords: \{keywords\} \\
The nearest neighbors memories:
\{nearest\_neighbors\_memories\} \\
Based on this information, determine:\\
Should this memory be evolved? Consider its relationships with other memories. } 
\end{tcolorbox}

\clearpage

\subsection{Prompt Template of Memory Evolution}
\begin{tcolorbox}[colback=white!95!gray, colframe=black, width=1\textwidth, arc=4mm, boxrule=0.5mm]
\noindent \textbf{The prompt template in Memory Evolution:} $P_{s3}$\\  
\texttt{ You are an AI memory evolution agent responsible for managing and evolving a knowledge base. \\
Analyze the the new memory note according to keywords and context, also with their several nearest neighbors memory. \\
Make decisions about its evolution.  \\
The new memory context:\{context\}\\
content: \{content\} \\
keywords: \{keywords\} \\
The nearest neighbors memories:\{nearest\_neighbors\_memories\} \\
Based on this information, determine: \\
1. What specific actions should be taken (strengthen, update\_neighbor)? \\
   1.1 If choose to strengthen the connection, which memory should it be connected to? Can you give the updated tags of this memory? \\
   1.2 If choose to update neighbor, you can update the context and tags of these memories based on the understanding of these memories. \\
Tags should be determined by the content of these characteristic of these memories, which can be used to retrieve them later and categorize them. \\
All the above information should be returned in a list format according to the sequence: [[new\_memory],[neighbor\_memory\_1],...[neighbor\_memory\_n]] \\
These actions can be combined. \\
Return your decision in JSON format with the following structure:
\{\{ \\
    "should\_evolve": true/false, \\
    "actions": ["strengthen", "merge", "prune"], \\ 
    "suggested\_connections": ["neighbor\_memory\_ids"], \\
    "tags\_to\_update": ["tag\_1",..."tag\_n"],  \\
    "new\_context\_neighborhood": ["new context",...,"new context"], \\
    "new\_tags\_neighborhood": [["tag\_1",...,"tag\_n"],...["tag\_1",...,"tag\_n"]], \\
\}\} } 
\end{tcolorbox}
\clearpage

\subsection{Examples of Q/A with \ours}
\begin{tcolorbox}[colback=white!95!gray, colframe=black, width=1\textwidth, arc=4mm, boxrule=0.5mm]
\noindent \textbf{Example:} \\  
\texttt{Question 686: Which hobby did Dave pick up in October 2023? \\
Prediction: photography \\
Reference: photography \\
talk start time:10:54 am on 17 November, 2023 \\
memory content: Speaker Davesays : Hey Calvin, long time no talk! A lot has happened. I've taken up photography and it's been great - been taking pics of the scenery around here which is really cool. \\
memory context: The main topic is the speaker's new hobby of photography, highlighting their enjoyment of capturing local scenery, aimed at engaging a friend in conversation about personal experiences.\\
memory keywords: [\textcolor{red}{'photography'}, 'scenery', 'conversation', 'experience', 'hobby'] \\
memory tags: ['hobby', \textcolor{red}{'photography'}, 'personal development', 'conversation', 'leisure'] \\
talk start time:6:38 pm on 21 July, 2023 \\
memory content: Speaker Calvinsays : Thanks, Dave! It feels great having my own space to work in. I've been experimenting with different genres lately, pushing myself out of my comfort zone. Adding electronic elements to my songs gives them a fresh vibe. It's been an exciting process of self-discovery and growth! \\
memory context: The speaker discusses their creative process in music, highlighting experimentation with genres and the incorporation of electronic elements for personal growth and artistic evolution.\\
memory keywords: ['space', 'experimentation', 'genres', 'electronic', 'self-discovery', 'growth']\\
memory tags: ['music', 'creativity', 'self-improvement', 'artistic expression'] \\ } 
\end{tcolorbox}

\end{document}
