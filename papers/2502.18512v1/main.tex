% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}
\usepackage{amsmath}
% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{colortbl}

\usepackage{caption}
\usepackage{subcaption}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{FCoT-VL:Advancing Text-oriented Large Vision-Language Models with Efficient Visual Token Compression}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
  \textbf{Jianjian Li \textsuperscript{1}},
  \textbf{Junquan Fan\textsuperscript{1}},
  \textbf{Feng Tang\textsuperscript{2}}\thanks{corresponding author},
  \textbf{Gang Huang\textsuperscript{2}}\footnotemark[1],
  \textbf{Shitao Zhu\textsuperscript{2}},
  \textbf{Songlin Liu\textsuperscript{2}} \\
   \textbf{Nian Xie\textsuperscript{2}},
  \textbf{Wulong Liu\textsuperscript{2}},
  \textbf{Yong Liao\textsuperscript{1}\footnotemark[1]}
\\
  \textsuperscript{1}University of Science and Technology of China.\\
  \textsuperscript{2}Huawei Noahâ€™s Ark Lab.\\
\\
  % \small{
  %   \textbf{Correspondence:} \href{hanjiayi@inspur.com}{hanjiayi@inspur.com}
  % }
%}
}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\input{0abstract}

\input{1introduction}

\input{2relatedworks}

\input{3method}

\input{5experiments}

\input{6conclusion}

% \section{Engines}

% To produce a PDF file, pdf\LaTeX{} is strongly recommended (over original \LaTeX{} plus dvips+ps2pdf or dvipdf). Xe\LaTeX{} also produces PDF files, and is especially suitable for text in non-Latin scripts.

% \section{Preamble}

% The first line of the file must be
% \begin{quote}
% \begin{verbatim}
% \documentclass[11pt]{article}
% \end{verbatim}
% \end{quote}

% To load the style file in the review version:
% \begin{quote}
% \begin{verbatim}
% \usepackage[review]{acl}
% \end{verbatim}
% \end{quote}
% For the final version, omit the \verb|review| option:
% \begin{quote}
% \begin{verbatim}
% \usepackage{acl}
% \end{verbatim}
% \end{quote}

% To use Times Roman, put the following in the preamble:
% \begin{quote}
% \begin{verbatim}
% \usepackage{times}
% \end{verbatim}
% \end{quote}
% (Alternatives like txfonts or newtx are also acceptable.)

% Please see the \LaTeX{} source of this document for comments on other packages that may be useful.

% Set the title and author using \verb|\title| and \verb|\author|. Within the author list, format multiple authors using \verb|\and| and \verb|\And| and \verb|\AND|; please see the \LaTeX{} source for examples.

% By default, the box containing the title and author names is set to the minimum of 5 cm. If you need more space, include the following in the preamble:
% \begin{quote}
% \begin{verbatim}
% \setlength\titlebox{<dim>}
% \end{verbatim}
% \end{quote}
% where \verb|<dim>| is replaced with a length. Do not set this length smaller than 5 cm.

% \section{Document Body}

% \subsection{Footnotes}

% Footnotes are inserted with the \verb|\footnote| command.\footnote{This is a footnote.}

% \subsection{Tables and figures}

% See Table~\ref{tab:accents} for an example of a table and its caption.
% \textbf{Do not override the default caption sizes.}

% \begin{table}
%   \centering
%   \begin{tabular}{lc}
%     \hline
%     \textbf{Command} & \textbf{Output} \\
%     \hline
%     \verb|{\"a}|     & {\"a}           \\
%     \verb|{\^e}|     & {\^e}           \\
%     \verb|{\`i}|     & {\`i}           \\
%     \verb|{\.I}|     & {\.I}           \\
%     \verb|{\o}|      & {\o}            \\
%     \verb|{\'u}|     & {\'u}           \\
%     \verb|{\aa}|     & {\aa}           \\\hline
%   \end{tabular}
  % \begin{tabular}{lc}
  %   \hline
  %   \textbf{Command} & \textbf{Output} \\
  %   \hline
  %   \verb|{\c c}|    & {\c c}          \\
  %   \verb|{\u g}|    & {\u g}          \\
  %   \verb|{\l}|      & {\l}            \\
  %   \verb|{\~n}|     & {\~n}           \\
  %   \verb|{\H o}|    & {\H o}          \\
  %   \verb|{\v r}|    & {\v r}          \\
  %   \verb|{\ss}|     & {\ss}           \\
  %   \hline
  % \end{tabular}
%   \caption{Example commands for accented characters, to be used in, \emph{e.g.}, Bib\TeX{} entries.}
%   \label{tab:accents}
% \end{table}

% As much as possible, fonts in figures should conform
% to the document fonts. See Figure~\ref{fig:experiments} for an example of a figure and its caption.

% Using the \verb|graphicx| package graphics files can be included within figure
% environment at an appropriate point within the text.
% The \verb|graphicx| package supports various optional arguments to control the
% appearance of the figure.
% You must include it explicitly in the \LaTeX{} preamble (after the
% \verb|\documentclass| declaration and before \verb|\begin{document}|) using
% \verb|\usepackage{graphicx}|.





% \subsection{Hyperlinks}

% Users of older versions of \LaTeX{} may encounter the following error during compilation:
% \begin{quote}
% \verb|\pdfendlink| ended up in different nesting level than \verb|\pdfstartlink|.
% \end{quote}
% This happens when pdf\LaTeX{} is used and a citation splits across a page boundary. The best way to fix this is to upgrade \LaTeX{} to 2018-12-01 or later.

% \subsection{Citations}

% \begin{table*}
%   \centering
%   \begin{tabular}{lll}
%     \hline
%     \textbf{Output}           & \textbf{natbib command} & \textbf{ACL only command} \\
%     \hline
%     \citep{Gusfield:97}       & \verb|\citep|           &                           \\
%     \citealp{Gusfield:97}     & \verb|\citealp|         &                           \\
%     \citet{Gusfield:97}       & \verb|\citet|           &                           \\
%     \citeyearpar{Gusfield:97} & \verb|\citeyearpar|     &                           \\
%     \citeposs{Gusfield:97}    &                         & \verb|\citeposs|          \\
%     \hline
%   \end{tabular}
%   \caption{\label{citation-guide}
%     Citation commands supported by the style file.
%     The style is based on the natbib package and supports all natbib citation commands.
%     It also supports commands defined in previous ACL style files for compatibility.
%   }
% \end{table*}

% Table~\ref{citation-guide} shows the syntax supported by the style files.
% We encourage you to use the natbib styles.
% You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
% You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
% You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

% A possessive citation can be made with the command \verb|\citeposs|.
% This is not a standard natbib command, so it is generally not compatible
% with other style files.

% \subsection{References}

% \nocite{Ando2005,andrew2007scalable,rasooli-tetrault-2015}

% The \LaTeX{} and Bib\TeX{} style files provided roughly follow the American Psychological Association format.
% If your own bib file is named \texttt{custom.bib}, then placing the following before any appendices in your \LaTeX{} file will generate the references section for you:
% \begin{quote}
% \begin{verbatim}
% \bibliography{custom}
% \end{verbatim}
% \end{quote}

% You can obtain the complete ACL Anthology as a Bib\TeX{} file from \url{https://aclweb.org/anthology/anthology.bib.gz}.
% To include both the Anthology and your own .bib file, use the following instead of the above.
% \begin{quote}
% \begin{verbatim}
% \bibliography{anthology,custom}
% \end{verbatim}
% \end{quote}

% Please see Section~\ref{sec:bibtex} for information on preparing Bib\TeX{} files.

% \subsection{Equations}

% An example equation is shown below:
% \begin{equation}
%   \label{eq:example}
%   A = \pi r^2
% \end{equation}

% Labels for equation numbers, sections, subsections, figures and tables
% are all defined with the \verb|\label{label}| command and cross references
% to them are made with the \verb|\ref{label}| command.

% This an example cross-reference to Equation~\ref{eq:example}.

% \subsection{Appendices}

% Use \verb|\appendix| before any appendix section to switch the section numbering over to letters. See Appendix~\ref{sec:appendix} for an example.

% \section{Bib\TeX{} Files}
% \label{sec:bibtex}

% Unicode cannot be used in Bib\TeX{} entries, and some ways of typing special characters can disrupt Bib\TeX's alphabetization. The recommended way of typing special characters is shown in Table~\ref{tab:accents}.

% Please ensure that Bib\TeX{} records contain DOIs or URLs when possible, and for all the ACL materials that you reference.
% Use the \verb|doi| field for DOIs and the \verb|url| field for URLs.
% If a Bib\TeX{} entry has a URL or DOI field, the paper title in the references section will appear as a hyperlink to the paper, using the hyperref \LaTeX{} package.

% \section*{Acknowledgments}

% This document has been adapted
% by Steven Bethard, Ryan Cotterell and Rui Yan
% from the instructions for earlier ACL and NAACL proceedings, including those for
% ACL 2019 by Douwe Kiela and Ivan Vuli\'{c},
% NAACL 2019 by Stephanie Lukin and Alla Roskovskaya,
% ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu,
% NAACL 2018 by Margaret Mitchell and Stephanie Lukin,
% Bib\TeX{} suggestions for (NA)ACL 2017/2018 from Jason Eisner,
% ACL 2017 by Dan Gildea and Min-Yen Kan,
% NAACL 2017 by Margaret Mitchell,
% ACL 2012 by Maggie Li and Michael White,
% ACL 2010 by Jing-Shin Chang and Philipp Koehn,
% ACL 2008 by Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui,
% ACL 2005 by Hwee Tou Ng and Kemal Oflazer,
% ACL 2002 by Eugene Charniak and Dekang Lin,
% and earlier ACL and EACL formats written by several people, including
% John Chen, Henry S. Thompson and Donald Walker.
% Additional elements were taken from the formatting instructions of the \emph{International Joint Conference on Artificial Intelligence} and the \emph{Conference on Computer Vision and Pattern Recognition}.

% Bibliography entries for the entire Anthology, followed by custom entries
% \bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\appendix

\section{Appendix}
\label{sec:appendix}


% \begin{table*}[t]\scriptsize
% \renewcommand{\arraystretch}{1.2}

%     % \begin{subtable*}{0.47\textwidth}
%     %     \centering
%     %     \setlength{\tabcolsep}{0.9mm} 
%     %     \hline
%     %     \begin{tabular}{ll}
%     %          task  & dataset \\
%     %          \hline
%     %                                       & big\_font,IIT-CDIP,chart2dict,ChartSFT \\
%     %                                       & DocumentText,hand\_write \\
%     %                                       & html\_zh\_lay,html\_zh\_text \\
%     %                                       & receipt\_EATEN,receipt\_by\_ei \\
%     %                                       & SceneText,table\_markdown,table2md(en \& zh) \\
%     %          \multirow{-6}{*}{Others}      & double\_column\_render(en \& zh) \\
    
    
%     %                                       & Laion-EN (en)~\cite{schuhmann2022laion5b}, Laion-ZH (zh)~\cite{schuhmann2022laion5b}\\
%     %                                       & COYO (zh)~\cite{byeon2022coyo}, \\ 
%     %          \multirow{-3}{*}{Captioning} & GRIT (zh)~\cite{peng2023kosmos2}, COCO (en)~\cite{chen2015cococaption}, TextCaps (en)~\cite{sidorov2020textcaps}   \\
    
    
             
%     %          \rowcolor{gray!15}
%     %                                       & DocStruct4M-bbox,docstruct4M\_check\_wo\_nat,html\_zh\_bbox,synthdog\_bbox(en \& zh) \\
%     %          \rowcolor{gray!15}
%     %                                       & Objects365 (en\&zh)~\cite{shao2019objects365}, GRIT (en\&zh)~\cite{peng2023kosmos2},      \\
%     %          \rowcolor{gray!15}
%     %          \multirow{-3}{*}{Detection}  & All-Seeing (en\&zh)~\cite{wang2023allseeing} \\
    
             
%     %                                       & ANYWORD \\    
%     %                                       & Wukong-OCR (zh)~\cite{gu2022wukong}, LaionCOCO-OCR (en)~\cite{schuhmann2022laioncoco},                      \\
%     %          \multirow{-3}{*}{OCR (large)}& Common Crawl PDF \\
%     %          \rowcolor{gray!15}
%     %                                       & stvqa\_ocr,\\
%     %          \rowcolor{gray!15}
%     %                                       & MMC-Inst , LSVT (zh)~\cite{sun2019lsvt}, ST-VQA (en)~\cite{biten2019stvqa}        \\
%     %          \rowcolor{gray!15}
%     %                                       & RCTW-17 (zh)~\cite{shi2017rctw17}, ReCTs (zh)~\cite{zhang2019rects}, ArT (en\&zh)~\cite{chng2019art},       \\
%     %          \rowcolor{gray!15}
%     %                                       & SynthDoG (en\&zh)~\cite{kim2022synthdog}, COCO-Text (en)~\cite{veit2016cocotext},                           \\
%     %          \rowcolor{gray!15}
%     %                                       & ChartQA-OCR, CTW-OCR, DocVQA-OCR    \\
%     %          \rowcolor{gray!15}
%     %           \multirow{-6}{*}{OCR (small)}& TextOCR, PlotQA-OCR, InfoVQA-OCR        \\
%     %     \hline
%     %     \end{tabular}
%     %     \caption{Datasets used in the pre-training stage. 
%     % }
%     % \label{tab:pretraining}
%     % \end{subtable*}
%     \begin{subtable*}{}
%         \setlength\tabcolsep{6.4pt}
%         \begin{tabular}{l|l}
%     task & dataset \\
%     \hline
%     Captioning                    & TextCaps (en)~\cite{sidorov2020textcaps}, ShareGPT4V (en\&zh)~\cite{chen2023sharegpt4v}                        \\
%     \rowcolor{gray!15}
%                                   & VQAv2 (en)~\cite{goyal2017vqav2}, GQA (en)~\cite{hudson2019gqa}, OKVQA (en)~\cite{marino2019okvqa},            \\
%     \rowcolor{gray!15}
%     \multirow{-2}{*}{General QA}  & VSR (en)~\cite{liu2023vsr}, VisualDialog (en)~\cite{das2017visualdialog}                                       \\
%     \multirow{-1}{*}{Science}     & AI2D (en)~\cite{kembhavi2016ai2d}, ScienceQA (en)~\cite{lu2022scienceqa}, TQA (en)~\cite{kembhavi2017tqa}      \\
%     \rowcolor{gray!15}
%                                   & ChartQA (en)~\cite{masry2022chartqa}, MMC-Inst (en)~\cite{liu2023mmcinst}, DVQA (en)~\cite{kafle2018dvqa},     \\
%     \rowcolor{gray!15}
%     \multirow{-2}{*}{Chart}       & PlotQA (en)~\cite{methani2020plotqa}, LRV-Instruction (en)~\cite{liu2023lrv-instruction}                       \\
    
%                                   & GeoQA+ (en)~\cite{cao2022geoqa_plus}, TabMWP (en)~\cite{lu2022tablemwp}, MathQA (en)~\cite{yu2023mathqa},      \\
%     \multirow{-2}{*}{Mathematics} & CLEVR-Math/Super (en)~\cite{lindstrom2022clevrmath, li2023superclevr}, Geometry3K (en)~\cite{lu2021geometry3k} \\
%     \rowcolor{gray!15}
%                                   & KVQA (en)~\cite{shah2019kvqa}, A-OKVQA (en)~\cite{schwenk2022aokvqa}, ViQuAE (en)~\cite{lerner2022viquae},     \\
%     \rowcolor{gray!15}
%     \multirow{-2}{*}{Knowledge}   & Wikipedia (en\&zh)~\cite{he2023wanjuan}                                                                        \\
%                                   & OCRVQA (en)~\cite{mishra2019ocrvqa}, InfoVQA (en)~\cite{mathew2022infographicvqa}, TextVQA (en)~\cite{singh2019textvqa}, \\ 
%                                   & ArT (en\&zh)~\cite{chng2019art}, COCO-Text (en)~\cite{veit2016cocotext}, CTW (zh)~\cite{yuan2019ctw},          \\
%                                   & LSVT (zh)~\cite{sun2019lsvt}, RCTW-17 (zh)~\cite{shi2017rctw17}, ReCTs (zh)~\cite{zhang2019rects},             \\
%     \multirow{-4}{*}{OCR}         & SynthDoG (en\&zh)~\cite{kim2022synthdog}, ST-VQA (en)~\cite{biten2019stvqa}                                    \\
%     \rowcolor{gray!15}
%     Document                      & DocVQA (en)~\cite{clark2017docqa}, Common Crawl PDF (en\&zh)                                                   \\
%     Grounding                     & RefCOCO/+/g (en)~\cite{yu2016refcoco,mao2016refcocog}, Visual Genome (en)~\cite{krishna2017vg}                            \\
%     \rowcolor{gray!15}
%                                   & LLaVA-150K (en\&zh)~\cite{liu2023llava}, LVIS-Instruct4V (en)~\cite{wang2023lvisinstruct4v},                   \\
%     \rowcolor{gray!15}
%                                   & ALLaVA (en\&zh)~\cite{chen2024allava}, Laion-GPT4V (en)~\cite{laion_gpt4v_dataset},                            \\
%     \rowcolor{gray!15}
%     \multirow{-3}{*}{Conversation}& TextOCR-GPT4V (en)~\cite{textocr_gpt4v_dataset},  SVIT (en\&zh)~\cite{zhao2023svit}                            \\
%                                   & OpenHermes2.5 (en)~\cite{OpenHermes2_5}, Alpaca-GPT4 (en)~\cite{taori2023alpaca},                              \\
%     \multirow{-2}{*}{Text-only}   & ShareGPT (en\&zh)~\cite{zheng2023vicuna}, COIG-CQIA (zh)~\cite{bai2024coig}                                    \\
%         \end{tabular}
%         \centering
%             \caption{Datasets used in the fine-tuning stage.
%         }
%     \label{tab:finetuning}
%     \end{subtable*}
% \caption{\textbf{Summary of datasets used in InternVL 1.5.} 
% To construct large-scale OCR datasets, we utilized PaddleOCR \cite{li2022paddleocr} to perform OCR in Chinese on images from Wukong \cite{gu2022wukong} and in English on images from LAION-COCO \cite{schuhmann2022laioncoco}.
% }
% \label{tab:dataset}
% \end{table*}
% \begin{subtable}{\columnwidth}
%     \centering
%     \begin{tabular}{ccc}
%         \hline
%         \makecell{compress ratio} & Train Data  & Time Cost\\
%         \hline
%         50\% & 1.5M &  \\
%         75\% & 1.5M &  \\
%         \hline
%     \end{tabular}
%     \caption{Time cost of differnt SFT Settings. The time consumption is greatly reduced.}
% \end{subtable}
\subsection{Training settings}
Our FCoT-VL was trained in two distinct stages: re-alignment and post-trian. 
As shown in Table~\ref{tab:training_settings}, we present the training details of FCoT-VL in different stages. The details are as follows:

For both stages, we train models with 64 ascend 910 NPUs with the packed batch size is set to 512.
In the re-alignment pre-training, we employ a 2 million image-text pairs to learn the projector and compress module. This allows the VLLMs to re-align the compressed visual token with the language token space. Specifically, we craft the optimization tasks of recognizing text in document images and converting charts and tables into pythondict/markdown format. We set the training epoch as 1, which requires approximately 48 hours using 64 NPUs for 2B scale. In the subsequent instruction tuning phase, we make all parameters of FCoT-VL learnable and keep most of the settings unchanged, except context length, training data and training epochs. 
% \begin{table}[htbp]
%     \renewcommand{\arraystretch}{1.2}
%     \centering
%     \resizebox{\columnwidth}{!}{
%         \begin{tabular}{lcc|cc}
%             \hline
%             \textbf{Settings} & \multicolumn{2}{c|}{\textbf{InternVL2-2B}} & \multicolumn{2}{c}{\textbf{InternVL2-8B}} \\
%             \hline
%             & Realignment & SFT & Realignment & SFT \\
%             Trainable & Projector and Compress Module & Full Parameters & Projector and Compress Module & Full Parameters \\
%             Packed Batch Size & 512 & 512 & 512 & 512 \\
%             Learning Rate & $1e^{-5}$ & $1e^{-5}$ & $1e^{-5}$ & $1e^{-5}$ \\

%             Context Length & 4096 & 5120 & 4096 & 5120 \\
%             Image Tile Threshold & 12 & 12 & 12 & 12 \\
%             ViT Drop Path & 0.1 & 0.1& 0.1 & 0.1 \\
%             Weight Decay & 0.01 & 0.01 & 0.01 & 0.01 \\
%             Training Epochs & 1 & 3 & 1 & 3 \\
%             \hline
%             Dataset & Pre-train & Fine-tune & Pre-train & Fine-tune \\
%             Training Examples  & $\sim2M$ & $\sim4.5M$ & $\sim2M$ & $\sim4.5M$ \\
%             \hline
%         \end{tabular}
%     }
%     \caption{Training settings for InternVL2-2B and InternVL2-8B.}
%     \label{tab:training_settings}
% \end{table}

  \begin{table}[htbp]
    \renewcommand{\arraystretch}{1.2}
    \centering
    \resizebox{\columnwidth}{!}{
        \begin{tabular}{l|cc}
            \hline
            \textbf{Settings} & \textbf{Re-alignment} & \textbf{Post-train} \\
            \hline
            \rowcolor{gray!15}
            Trainable & \makecell{Projector,\\ Compress Module} & Full Parameters \\
            Packed Batch Size & 512 & 512  \\
            \rowcolor{gray!15}
            Learning Rate & $1e^{-5}$ & $1e^{-5}$ \\
            Context Length & 4096 & 5120 \\
            \rowcolor{gray!15}
            Image Tile Threshold & 12 & 12 \\
            ViT Drop Path & 0.1 & 0.1 \\
            \rowcolor{gray!15}
            Weight Decay & 0.01 & 0.01  \\
            Training Epochs & 1 & 3 \\
            \hline
            \rowcolor{gray!15}
            Dataset & Pre-train & Fine-tune \\
            Training Examples  & $\sim2M$ & $\sim4.5M$ \\
            \hline
        \end{tabular}
    }
    \caption{Detailed Training settings for InternVL2-2B and InternVL2-8B.}
    \label{tab:training_settings}
\end{table}

% \clearpage


\subsection{Model Capabilities and Qualitative Examples}
In this section, we present some practical examples of our FCoT-VL.
\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{q1.png}  % å›¾ç‰‡è·¯å¾„
    \caption{The model excels in understanding scheduling-related queries. Image source:\cite{mathew2021docvqa}}  % æ ‡é¢˜
    \label{ex1}  % æ ‡ç­¾
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{q2.png}  % å›¾ç‰‡è·¯å¾„
    \caption{The model demonstrates excellence in recognizing handwritten text in emails. Image source:\cite{mathew2021docvqa}}  % æ ‡é¢˜
    \label{ex2}  % æ ‡ç­¾
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{q3.png}  % å›¾ç‰‡è·¯å¾„
    \caption{The model demonstrates excellence in recognizing printed text and images in books. Image source:\cite{mathew2021docvqa}}  % æ ‡é¢˜
    \label{ex3}  % æ ‡ç­¾
\end{figure*}


\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{q4.png}  % å›¾ç‰‡è·¯å¾„
    \caption{The model displays an adeptness in understanding line charts. Image source:\cite{mathew2021docvqa}}  % æ ‡é¢˜
    \label{ex4}  % æ ‡ç­¾
\end{figure*}


\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{q5.png}  % å›¾ç‰‡è·¯å¾„
    \caption{The model displays an adeptness in understanding images of natural animals. Image source:\cite{lu2022scienceqa}}  % æ ‡é¢˜
    \label{ex5}  % æ ‡ç­¾
\end{figure*}





\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{q8.png}  % å›¾ç‰‡è·¯å¾„
    \caption{The model displays an adeptness in understanding bar charts. Image source:\cite{masry2022chartqa}}  % æ ‡é¢˜
    \label{ex8}  % æ ‡ç­¾
\end{figure*}


\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{q9.png}  % å›¾ç‰‡è·¯å¾„
    \caption{The model displays an adeptness in understanding curve charts. Image source:\cite{masry2022chartqa}}  % æ ‡é¢˜
    \label{ex9}  % æ ‡ç­¾
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{q10.png}  % å›¾ç‰‡è·¯å¾„
    \caption{The model displays an adeptness in recognizing handwritten Chinese characters.}  % æ ‡é¢˜
    \label{ex10}  % æ ‡ç­¾
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{q11.png}  % å›¾ç‰‡è·¯å¾„
    \caption{The model displays an adeptness in understanding Chinese flight ticket information.Image source:\cite{wang2024qwen2vl}}  % æ ‡é¢˜
    \label{ex11}  % æ ‡ç­¾
\end{figure*}


\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{q12.png}  % å›¾ç‰‡è·¯å¾„
    \caption{The model displays an adeptness in calculating information from Chinese bar charts. }  % æ ‡é¢˜
    \label{ex12}  % æ ‡ç­¾
\end{figure*}

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=0.25\textwidth]{q6.png}  % è°ƒæ•´å›¾ç‰‡å®½åº¦
    \caption{The model displays an adeptness in understanding posters with dense information. Image source:\cite{mathew2022infographicvqa}}  % æ ‡é¢˜
    \label{ex6}  % æ ‡ç­¾
\end{figure*}


\begin{figure*}[htbp]
    \centering
    \includegraphics[width=0.23\textwidth]{q7.png}  % å›¾ç‰‡è·¯å¾„
    \caption{The model displays an adeptness in understanding posters with intertwined text and images. Image source:\cite{mathew2022infographicvqa}}  % æ ‡é¢˜
    \label{ex7}  % æ ‡ç­¾
\end{figure*}

\end{document}
