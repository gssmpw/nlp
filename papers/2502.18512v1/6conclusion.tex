\section{Conclusion}
% In this paper, we propose a method called FCoT-VL, to  efficiently compress a VLLM which has redundant visual tokens with limited sources and maintain the performance. Our FCoT-VL has made a achievement that it reduces the number of visual tokens substantially while preserving model performance well and even better. For instance, we got a 812 score with 1/4 visual tokens which is better than InternVL2-2B.  Meanwhile, The FCoT-VL model demands very little in terms of data and NPU resources. The  method has a strong compatibility with compress modules and many compress modules work well. We construct extensive experiments across various benchmarks and prove it can perform well with fewer visual tokens even in text-oriented tasks with a few mount resources.  
In this paper, we introduce FCoT-VL, a novel method designed to efficiently compress Vision-Language Large Models (VLLMs) by reducing redundant visual tokens with minimal computational resources, while maintaining or even enhancing model performance. FCoT-VL significantly reduces the number of visual tokens, achieving notable performance improvements. Furthermore, FCoT-VL is highly resource-efficient, requiring minimal data and NPU resources. The method demonstrates strong compatibility with various compression modules, all of which perform well in conjunction with FCoT-VL. Extensive experiments across multiple benchmarks confirm that FCoT-VL excels in tasks requiring fewer visual tokens, including text-oriented tasks, even when computational resources are limited.

\section{Limitations}
(1).We only focus on text-oriented tasks that require high-resolution settings and obtain lossless compression with the ratio of 50\%. However, due to resource constraints, our approach does not extend to other image modalities, such as natural scenes or medical imaging. (2). Although our fixed compression ratios (i.e., 50\% and 75\%) are efficiently implemented, this setting performs well in most cases. However, it shows a slight performance drop when applied to extremely high-resolution tasks, such as infoVQA. 
