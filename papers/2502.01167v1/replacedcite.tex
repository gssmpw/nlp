\section{Related Works}
\subsection{Execution Monitoring}
Over the years, as the interest in deploying robots in increasingly unstructured environments has grown, numerous execution monitoring and anomaly detection algorithms have been proposed____.

Among these approaches, one class focuses on probabilistic modeling of task executions. These methods rely on modeling successful task executions probabilistically, often using Gaussian Mixture Models (GMMs)____ or Gaussian Processes (GPs)____. They predict expected sensory measurements during task execution, which are then compared against current observations to identify anomalies. Alternatively, for detecting multimodal anomalies, Hidden Markov Models (HMMs) can be used, where the anomaly threshold is predefined____, or by estimating probabilistic thresholds based on the progression of the task execution____.

Probabilistic approaches are effective for modalities such as end-effector poses or force-torque measurements but face challenges with high-dimensional data such as images____. An alternative approach is to use deep learning, which can extract meaningful features from high-dimensional data and simultaneously learn to detect anomalies____. Two commonly used methods include measuring the reconstruction error____ or directly classifying anomalies or successes____.

Anomaly detection approaches focus on predicting whether the action is going on according to plan or not, however, they do not reason about which actions can be performed from the current state. In contrast, ConditionNet determines the anomaly through the learned preconditions and effects of actions. In case of an anomaly, the preconditions can be used in the recovery system to limit the set of selectable actions to only those that are feasible, thus simplifying the recovery problem.

Once an anomaly is detected, several strategies can be adopted to recover from the error. Works like____ employ a human-in-the-loop strategy, where the user is queried to resolve the anomaly by either refining the action or adding new recovery skills to the robot's knowledge. In cases where multiple solutions exist, Eiband et al.____ propose to select among all solutions except the one that led to the anomaly, the one that has the minimal Mahalanobis distance to the current state. Recent works like REFLECT____ adopt Large Language models (LLMs) to plan the recovery behavior by providing the current state description and anomaly reason in the prompt.

In principle, ConditionNET can be applied to any of the aforementioned recovery strategies in place of the anomaly detector. In this work, we employ a Behavior Tree (BT)____ with a pre-planned task and recovery plan, where branches are conditionally executed or preempted based on anomaly prediction. 

\subsection{Learning Action Preconditions and Effects}
Symbolic planners have been a part of artificial intelligence for many decades, and languages like PDDL____ have been a staple of modeling actions. Each action is described through a ``planning operator'' which defines the preconditions and effects of the action. Various approaches try to learn these planning operators from symbolic states____ by identifying recurring predicates in the state of the environment before and after an action. However, since they rely on symbolic variables, additional techniques____ are needed to estimate predicates from sensor readings.

Instead of learning to ground the predicates from the observations, recent learning approaches attempt to learn the preconditions and effects directly from the data. Approaches like SuccessVQA____ and InnerMonologe____, focus solely on classifying whether an action has been performed successfully. They assume that the action is always possible to execute, which is often not the case in real-world scenarios. For example, if a robot is tasked with picking up a bottle and the bottle is removed during execution, these models can only detect the anomaly after the task is completed. In contrast, ConditionNET also reasons about the preconditions of actions. In the previous example, our model could detect that the bottle has been removed, and the precondition of the action is no longer satisfied. This allows the robot to react and preempt the motion execution to perform another action instead.

More recent trends in task planning utilize LLMs____. These models can effectively plan tasks using few or even no examples due to the massive amount of data they observed during training. By adding vision as an input modality, PALM-E____, a Large Visual-Language Model (LVLM), can reason about the environment's state from images. This allows checking preconditions by querying the model about the feasibility of an action based on the observation and verifying the action's success post-execution. Conceptually, this approach aligns with ours, as we also aim to determine if the current observation is the precondition or effect of an action. However, as these types of models are computationally intensive, they are not suited for real-time execution monitoring. Additionally, due to their size, LLMs and LVLMs are difficult to deploy on robots, especially those without internet access for cloud computing. In contrast, ConditionNET, with only 30M parameters is around 187 times smaller than PALM-E 562B and can be deployed relatively easily. An added benefit of the small size of the model is a considerable decrease in the inference time, which makes it feasible to run inference for each frame from the camera.

\begin{figure*}
    \centering
    \includegraphics[width=0.95\textwidth]{figures/Architecture_new.png}
    \caption{\textbf{ConditionNET Architecture.} For an image-action pair, we compute the condition feature \( E \) and classify the current observation as precondition, effect, or unsatisfied. We extract image and semantic features using DINOv2____ and CLIP____. The State Transformer then extracts the general state feature \( \widehat{cls} \), and the Condition Transformer extracts the condition feature \( E \). For consistency loss, we use features from both the precondition frame and the effect frame, denoted \( - \) and \( + \), respectively. We compute the action feature \( e_a \) as the difference between \( \widehat{cls^+} \) and \( \widehat{cls^-} \). Using InfoNCE loss____, we make the action feature ``similar'' to the paraphrased action description \( s_p \), but only for successfully executed actions.
}
    \label{fig:architecture}
    % \vspace{-.5cm}
\end{figure*}