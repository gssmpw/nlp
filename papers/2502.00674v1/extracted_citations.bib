@article{brown2024large,
  title={Large language monkeys: Scaling inference compute with repeated sampling},
  author={Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\'e}, Christopher and Mirhoseini, Azalia},
  journal={arXiv preprint arXiv:2407.21787},
  year={2024}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{chen2023reconcile,
  title={Reconcile: Round-table conference improves reasoning via consensus among diverse llms},
  author={Chen, Justin Chih-Yao and Saha, Swarnadeep and Bansal, Mohit},
  journal={arXiv preprint arXiv:2309.13007},
  year={2023}
}

@article{chen2023universal,
  title={Universal self-consistency for large language model generation},
  author={Chen, Xinyun and Aksitov, Renat and Alon, Uri and Ren, Jie and Xiao, Kefan and Yin, Pengcheng and Prakash, Sushant and Sutton, Charles and Wang, Xuezhi and Zhou, Denny},
  journal={arXiv preprint arXiv:2311.17311},
  year={2023}
}

@article{chen2024moa,
  title={MoA is All You Need: Building LLM Research Team using Mixture of Agents},
  author={Chen, Sandy and Zeng, Leqi and Raghunathan, Abhinav and Huang, Flora and Kim, Terrence C},
  journal={arXiv preprint arXiv:2409.07487},
  year={2024}
}

@article{du2023improving,
title={Improving factuality and reasoning in language models through multiagent debate},
author={Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
journal={arXiv preprint arXiv:2305.14325},
year={2023}
}

@article{gui2024bonbon,
  title={BoNBoN Alignment for Large Language Models and the Sweetness of Best-of-n Sampling},
  author={Gui, Lin and G{\^a}rbacea, Cristina and Veitch, Victor},
  journal={arXiv preprint arXiv:2406.00832},
  year={2024}
}

@article{hendrycks2021measuring,
  title={Measuring mathematical problem solving with the math dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021}
}

@misc{jiang2023llmblenderensemblinglargelanguage,
      title={LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion}, 
      author={Dongfu Jiang and Xiang Ren and Bill Yuchen Lin},
      year={2023},
      eprint={2306.02561},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.02561}, 
}

@misc{jiang2024mixtralexperts,
      title={Mixtral of Experts}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Antoine Roux and Arthur Mensch and Blanche Savary and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Emma Bou Hanna and Florian Bressand and Gianna Lengyel and Guillaume Bour and Guillaume Lample and Lélio Renard Lavaud and Lucile Saulnier and Marie-Anne Lachaux and Pierre Stock and Sandeep Subramanian and Sophia Yang and Szymon Antoniak and Teven Le Scao and Théophile Gervet and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2024},
      eprint={2401.04088},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.04088}, 
}

@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@misc{li2024agentsneed,
      title={More Agents Is All You Need}, 
      author={Junyou Li and Qin Zhang and Yangbin Yu and Qiang Fu and Deheng Ye},
      year={2024},
      eprint={2402.05120},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.05120}, 
}

@article{liang2023encouraging,
  title={Encouraging divergent thinking in large language models through multi-agent debate},
  author={Liang, Tian and He, Zhiwei and Jiao, Wenxiang and Wang, Xing and Wang, Yan and Wang, Rui and Yang, Yujiu and Tu, Zhaopeng and Shi, Shuming},
  journal={arXiv preprint arXiv:2305.19118},
  year={2023}
}

@misc{lin2024mitigatingalignmenttaxrlhf,
      title={Mitigating the Alignment Tax of RLHF}, 
      author={Yong Lin and Hangyu Lin and Wei Xiong and Shizhe Diao and Jianmeng Liu and Jipeng Zhang and Rui Pan and Haoxiang Wang and Wenbin Hu and Hanning Zhang and Hanze Dong and Renjie Pi and Han Zhao and Nan Jiang and Heng Ji and Yuan Yao and Tong Zhang},
      year={2024},
      eprint={2309.06256},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2309.06256}, 
}

@misc{lu2023routingexpertefficientrewardguided,
      title={Routing to the Expert: Efficient Reward-guided Ensemble of Large Language Models}, 
      author={Keming Lu and Hongyi Yuan and Runji Lin and Junyang Lin and Zheng Yuan and Chang Zhou and Jingren Zhou},
      year={2023},
      eprint={2311.08692},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.08692}, 
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{ramé2024warpbenefitsweightaveraged,
      title={WARP: On the Benefits of Weight Averaged Rewarded Policies}, 
      author={Alexandre Ramé and Johan Ferret and Nino Vieillard and Robert Dadashi and Léonard Hussenot and Pierre-Louis Cedoz and Pier Giuseppe Sessa and Sertan Girgin and Arthur Douillard and Olivier Bachem},
      year={2024},
      eprint={2406.16768},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.16768}, 
}

@article{roziere2023code,
  title={Code llama: Open foundation models for code},
  author={Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@article{stechly2023gpt,
  title={Gpt-4 doesn't know it's wrong: An analysis of iterative prompting for reasoning problems},
  author={Stechly, Kaya and Marquez, Matthew and Kambhampati, Subbarao},
  journal={arXiv preprint arXiv:2310.12397},
  year={2023}
}

@article{valmeekam2023can,
  title={Can large language models really improve by self-critiquing their own plans?},
  author={Valmeekam, Karthik and Marquez, Matthew and Kambhampati, Subbarao},
  journal={arXiv preprint arXiv:2310.08118},
  year={2023}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{wang2024mixture,
  title={Mixture-of-Agents Enhances Large Language Model Capabilities},
  author={Wang, Junlin and Wang, Jue and Athiwaratkun, Ben and Zhang, Ce and Zou, James},
  journal={arXiv preprint arXiv:2406.04692},
  year={2024}
}

@article{wang2024rethinking,
  title={Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?},
  author={Wang, Qineng and Wang, Zihao and Su, Ying and Tong, Hanghang and Song, Yangqiu},
  journal={arXiv preprint arXiv:2402.18272},
  year={2024}
}

@article{zhang2024diversity,
  title={Diversity empowers intelligence: Integrating expertise of software engineering agents},
  author={Zhang, Kexun and Yao, Weiran and Liu, Zuxin and Feng, Yihao and Liu, Zhiwei and Murthy, Rithesh and Lan, Tian and Li, Lei and Lou, Renze and Xu, Jiacheng and others},
  journal={arXiv preprint arXiv:2408.07060},
  year={2024}
}

@article{zhang2024towards,
  title={Towards Building Specialized Generalist AI with System 1 and System 2 Fusion},
  author={Zhang, Kaiyan and Qi, Biqing and Zhou, Bowen},
  journal={arXiv preprint arXiv:2407.08642},
  year={2024}
}

