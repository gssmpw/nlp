\section{Discussion}
The present study evaluated the efficacy of an LLM feedback agent on experimentation protocols compared to human experts and teachers across multiple dimensions of feedback quality: \textit{Feed Up}, \textit{Feed Back}, \textit{Feed Forward}, \textit{Constructive Tone}, \textit{Linguistic Clarity}, and \textit{Technical Terminology}. Our findings indicate that the LLM agent performed on par with human experts and teachers in most dimensions, showing no significant differences. However, it was significantly less effective in the \textit{Feed Back} dimension, which involves describing the error in the context of the current situation.

\paragraph{LLMs can provide actionable and linguistically appropriate feedback.} The comparable performance of the LLM agent in the content-related dimensions such as \textit{Feed Up}, \textit{Feed Forward} as well as the language-related dimensions shows that an LLM can effectively mimic feedback from educational experts in summarizing goals, providing forward-looking guidance, maintaining an encouraging tone, and using appropriate language and terminology for middle school students. This aligns with previous research indicating that AI systems can deliver structured and pedagogically sound feedback \citep{guo2024using, sessler2023peer,fung2024automatic,cohn2023towards}.

\paragraph{LLMs fall short in nuanced context understanding.}
The small but significant shortfall in the \textit{Feed Back} dimension highlights a critical area where LLM agents need improvement. Describing errors within the specific context of a student's work requires a nuanced understanding of the learning material and the student's thought process. Human teachers excel in this area due to their ability to interpret subtleties in student responses and provide feedback that addresses individual misconceptions \citep{shute2008focus}. The LLM agent's deficiency here may stem from limitations in its ability to comprehend context or infer underlying misconceptions from student errors.
% The qualitative analysis provides further insights into the differential performance of LLM-generated and human feedback. The analysis indicates that while AI can offer precise forward-looking suggestions (\textit{Feed Forward}), it sometimes lacks the ability to provide and, especially, the clear communication of the actual error (\textit{Feed Back}) that human experts deliver. 
However, this performance appears to be typical of current LLM agents, as other studies report that LLM-based systems tend to retain naive or limited pedagogical content knowledge \cite{chapagain2024explanations, tseng2024effectiveness}.
% Maybe add: noisy real world data?


%Despite this limitation, the LLM agent offers a substantial advantage in terms of time efficiency and scalability. It can provide immediate feedback to all students simultaneously, a benefit infeasible for human teachers constrained by time and workload. This immediacy is crucial for reinforcing learning and keeping students engaged \citep{hattie2007power}. By handling routine feedback tasks, the LLM agent allows teachers to allocate more time to complex instructional activities that require human judgment and interaction.

\paragraph{Implementation of AI in the classroom}

The analysis of content-related aspects reveals notable differences between human and LLM-generated feedback, indicating that humans and LLMs excel in distinct error scenarios. While their overall performance is comparable (see Section \ref{sec:multidim}), this suggests that integrating LLMs together with human assessments could enhance feedback quality by combining the strengths of teachers and the LLM agent.
%

The design of the LLM agent as a tool for hybrid intelligence aligns with the principle of augmenting human capabilities in the classroom rather than replacing them \citep{molenaar2022towards}. Teachers can integrate the LLM agent's strengths into their practice without making big changes to their teaching methods. By supporting adaptive and instant assessment and feedback for all students, the AI system enables teachers to focus on personalized instruction while retaining control over the learning process.

%
Despite the promising results regarding LLM-generated feedback quality, \citet{nazaretsky2024ai} report that students tend to prefer human feedback due to perceived deficiencies in the genuineness, usefulness, and objectivity of AI feedback. A \textbf{teacher-in-the-loop} approach could address these issues by ensuring quality control and enhancing trust. There is a spectrum ranging from student-centered use of AI, through teacher-only use, to the complete absence of AI in the classroom \citep{molenaar2022towards}. Finding the right level of AI integration into classroom settings remains challenging and is subject to future research. Ideally, these LLM agents are designed to provide different levels of AI integration, providing teachers with options to choose the level that best aligns with their pedagogical goals. For effective AI integration there is a need to build AI literacy among STEM teachers, enabling them to make informed pedagogical decisions based on an understanding of the strengths and limitations of current LLM agents \citep{hornberger2023university}.


\subsection{Limitations}

One major limitation of this study is the small sample size for many of the identified errors, with some errors represented by only a single instance. This restricts the generalizability of our findings and may not capture the full range of possible feedback scenarios. 
Additionally, the LLM capabilities were constrained by financial considerations essential for creating a real-world, school-usable system. As a result, we utilized the cost-efficient version of GPT at the time of conducting the user study, GPT-3.5, which possess significantly lower reasoning abilities compared to more advanced, but expensive, models like GPT-4 or o1. Also, the GPT-4o Mini model (published after running our experiments) is more cost-efficient and shows improved capabilities \citep{sessler2024benchmarking}. 
Choosing this version likely impacted the agent's performance, particularly in areas requiring deeper analytical skills. It is to be expected that newer models are more powerful in understanding context and providing adapted feedback. 
Furthermore, the feedback generated was exclusively based on the students' protocols, which means that both LLM and human feedback might have been limited by the absence of further contextual information. This lack of context could have hindered the ability of human reviewers to provide an even more informed and nuanced feedback.

\subsection{Future work}

Future work should involve conducting a real-world study where the LLM agent is implemented in classroom settings to evaluate its effectiveness and practicality in everyday educational environments and assess the effectiveness beyond the proof-of-concept given in this study. Additionally, upgrading the agent to more advanced models, such as GPT-4o or o1, would likely enhance the agent’s reasoning capabilities as shown by the findings of current research \citep{sessler2024can, latif2024systematic}, allowing for more sophisticated and accurate feedback. 

To address limitations related to sample size, strategies such as data augmentation using generative AI \citep{kieser2023educational} could be employed to increase the number of samples. These methods would allow for more robust findings without the challenging task of collecting large numbers of student protocols in real-world classroom settings.
Importantly, synthetic data generation can be designed to be privacy-preserving by retaining the statistical properties of the original dataset while ensuring that no individual student’s data is directly replicated \citep{vie2022privacy}. Such approaches not only expand the dataset and increase the reliability but also align with ethical considerations and data privacy regulations, which are critical in educational research.

Currently, our LLM agent is limited to text-based interactions. At its core, science learning, and experimentation protocols, like science itself are inherently multimodal \citep{lemke_literacies_2004, kress_vanleeuwen_1990}. Regarding experimentation protocols, these include reading and writing scientific arguments and explanations, drawing and interpreting diagrams, analyzing and visualizing data, and creating flowcharts and diagrams.  
Future systems could adopt a multi-modal approach, such as providing feedback on experimental drawings or generating sketches of experimental designs, thereby addressing the diverse modalities inherent in scientific inquiry \citep{lee2023multimodality, bewersdorff2024taking}.
