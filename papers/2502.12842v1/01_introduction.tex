\section{Introduction}

Effective feedback is a cornerstone of student development, influencing learning outcomes, student satisfaction and motivation \citep{gan2021teacher,wisniewski2020power,monteiro2021creating}. Personalization and contextualization significantly enhance intrinsic motivation and engagement in learning tasks \citep{cordova1996intrinsic}. However, traditional automatic feedback systems often fall short by providing generic, static responses that lack adaptiveness and fail to meet individual learner needs.

Advancements in generative Artificial Intelligence (AI), particularly large language models (LLMs), offer new opportunities to significantly improve feedback mechanisms in education \citep{kasneci2023chatgpt}. LLMs can overcome previous limitations by delivering adaptive, real-time, and personalized feedback that mimics human-like interaction. This integration combines the efficiency and scalability of computer-based feedback with the nuanced, adaptive qualities traditionally associated only with human educators. In their review, \citet{maier2022personalized} highlight the necessity for studies to adopt AI systems capable of providing personalized feedback to individual learners.

Despite these advancements, current research on LLM-based feedback systems often lacks validation with real-world student data or focuses on proof of concept studies without inviting domain experts as collaborators \citep{nguyen2023evaluating,sessler2023peer,gabbay2024combining}. This gap underscores the need for developing and validating feedback systems that are not only technically sound but also pedagogically effective and aligned with didactic principles.

In science education, experimentation is a fundamental practice essential for fostering analytical thinking and understanding the empirical process of scientific inquiry \citep{NationalResearchCouncil2012}. 
%Deductive experimentation, in particular, requires a rigorous methodological approach. 
However, students frequently encounter challenges and make mistakes in designing and conducting experiments â€” such as forming testable hypotheses, controlling variables, and interpreting data \citep{kranz2023learners, baur2018fehler}. As experimentation protocols are the central student outcomes of the experimentation process they are valuable sources for assessment and feedback. Addressing errors in experimentation protocols typically requires personalized feedback from educators, a process that is both time-consuming and resource-intensive.

Responding to these challenges and following the call by \citet{zhai2023ai} for innovation in science education through generative AI, we aim to develop and validate an LLM feedback agent that (1) detects errors in students' experimentation protocols and (2) provides adaptive feedback to learners in real-time. By leveraging LLMs, our system seeks to reduce the workload on educators while enhancing the learning experience for students. Our research addresses a significant gap that still exists between theoretical work on generative AI in science education and practical applications, including a focus on real-world implications.

Building upon our previous work (see: \citet{bewersdorff2023assessing}), where we developed an AI system to automatically detect errors in experimentation protocol, we now extend our approach to deliver actionable feedback that addresses specific student misconceptions and mistakes. We aim to investigate whether LLMs possess the capacity to comprehend context and provide meaningful, adaptive feedback that aligns with pedagogical best practices.

To achieve this, we conducted a study comparing feedback texts on students' experimentation errors written by 11 biology pre- and in-service teachers as well as 5 science education experts  with feedback generated by our LLM agent. Subsequently, 4 raters, professionals in science education and teaching experience, evaluated the feedback texts across six dimensions, including language- and content-related aspects.
%
By integrating authentic student data and collaborating closely with real-world educators, our research contributes an LLM feedback agent that is validated according to educational needs and didactic principles. 
%This work not only advances the application of AI in education but also provides practical solutions to enhance scientific learning through personalized feedback.
%
%
In summary, our contributions are:

\begin{enumerate} 
%\item Development of an LLM-Based AI Feedback System: We developed an AI system utilizing GPT-3.5 to detect logical errors in students' experimentation protocols and provide adaptive, personalized feedback.
\item The development of an LLM feedback agent to detect logical errors in students' experimentation protocols and provide adaptive feedback.

%\item Comprehensive Multi-Dimensional Evaluation: We conducted a thorough analysis of the quality of the AI-generated feedback versus teacher feedback. Science education experts evaluated both sets across multiple dimensions, considering content-related aspects (accuracy, relevance, pedagogical value) and language-related aspects (clarity, tone, linguistic appropriateness).
\item A comprehensive multi-dimensional evaluation analysing the quality of the LLM-generated feedback compared to teacher feedback, validated through content-related and language-related aspects.

%\item Application to Real-World Student Protocols: We applied our AI system to real-world experimentation protocols, comparing its feedback to that of practicing teachers as well as science education experts to demonstrate its practical implementation in educational settings and theoretical soundness.
\item The application to real-world student experimentation protocols to compare the LLM agent feedback to that of practicing teachers as well as science education experts to demonstrate its practical implementation in educational settings and theoretical soundness.

\end{enumerate}
