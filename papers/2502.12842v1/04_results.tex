\section{Results}

In following we report the results of the ratings in the multi-dimensional criteria to analyze the feedback quality of our LLM agent compared to real-world teachers and experts. We analyze how well LLMs perform in terms of content and language aspects in providing feedback on experimental protocols.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{img/average_score_boxplot_color.pdf}
    \caption{Distribution of the rating scores of teachers, experts and LLM agent averaged across all six dimensions on feedback quality.}
    \label{fig:average_scoring}
\end{figure}



\subsection{Overall scoring}\label{sec:overall_scoring}

As a first step, we compare the mean score, averaging all six multi-dimensional aspects for each feedback text. Figure \ref{fig:average_scoring} picture the distribution for each group. On average, the LLM agent reaches a mean value of 3.784 ($SD=1.238$), the teacher feedback texts 3.805 ($SD=1.266$) and the experts 3.831 ($SD=1.287$), with no significant difference between the three groups. Therefore, from an overall perspective, the feedback generated by an LLM agent can be considered similar quality to the one written by a human teacher or expert.




\subsection{Multidimensional scoring} \label{sec:multidim}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{img/scores_per_category_stars.pdf}
    \caption{Average score and standard deviation of the scoring of the feedback texts generated by teachers, experts and LLM agent in each rating category. Significant differences are marked by $*$ ($p<0.05$) and $**$ ($p<0.01$).}
    \label{fig:scores_categories}
\end{figure}

\begin{table}[htbp]
    \centering
    \begin{tabular}{lcccccc}
    \toprule
    & Feed Up & Feed Back & Feed Forward & Tone & Clarity & Terminology \\
    \midrule
Teacher & 3.20 $\pm$ 1.51  & 3.52 $\pm$ 1.32  & 3.84 $\pm$ 1.20  & 4.18 $\pm$ 1.13  & 3.91 $\pm$ 1.25  & 4.17 $\pm$ 1.18  \\ 
Expert & 3.53 $\pm$ 1.30  & 3.62 $\pm$ 1.31  & 3.78 $\pm$ 1.19  & 4.42 $\pm$ 0.98  & 3.67 $\pm$ 1.53  & 3.96 $\pm$ 1.41  \\ 
LLM & 3.48 $\pm$ 1.40  & 3.05 $\pm$ 1.37  & 3.99 $\pm$ 1.05  & 4.18 $\pm$ 1.16  & 4.01 $\pm$ 1.22  & 4.00 $\pm$ 1.22  \\ 
\bottomrule
    \end{tabular}
    \caption{Average score and standard deviation of the ratings of the feedback texts for all three groups.}
    \label{tab:scores_categories}
\end{table}

To get more detailed insights, we analyze the ratings of the feedback texts in the multi-dimensional aspects. Here, Figure \ref{fig:scores_categories} depicts the mean and standard deviation of all the categories. In general, all three groups achieved a higher rating in the three language related aspects and slightly worse results on the content-related ones. The details can be found in Table \ref{tab:scores_categories}.

Investigating the language categories, we see that while experts seem to have a more constructive tone, they suffer more in linguistic clarity. Teachers seem to have a small advantage using technical terminology for the young target group. But, overall the variations are minor and there are no significant differences between the three groups. Therefore, from a linguistic point of view, an LLM agent is able to provide adequate feedback for students from grade 6 to 8.

Considering the content-related aspects, we see more variations between the raters. Teachers tend to have more struggle clarifying the current goal of the experiment, and the LLM agent has a small advancement suggesting possible future actions. But, the only significant difference ($p<0.05$) is found for \textit{feed back}, where teachers and experts achieve a better performance then the LLM. This indicates that the LLM agent has still difficulties identifying the error within its context and providing insights into the mistake. For writing the \textit{Feed back} part, the model needs to completely understand the step taken by the student and interpret them correctly. This is particular tricky due to the incomplete and unstructured written protocols written by the students. Here, teachers and expert may have more experience in understanding the context and therefore providing better tailored feedback. % Results or Discussion?




\subsection{Length analysis}\label{sec:length}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{img/length_distribution.pdf}
    \caption{Distribution of the number of words in each feedback text written by the teachers, experts and the LLM agent.}
    \label{fig:length_distribution}
\end{figure}


A good feedback need to be comprehensive as well as precise. Therefore, we take a look into the length of the provided feedbacks of the three groups in Figure \ref{fig:length_distribution}. In the prompt for the LLM agent we asked to write 100 words, interestingly most generated feedbacks contain 50 words. This aligns with the length of the formative feedback provided by the teachers and is therefore probably a realistic length for a real-world classroom. On the other hand, the experts provided clearly more lengthy feedback texts, which is not suitable for students of grade 6 to 8 anymore. Even though their text are superior in form of tone and feed back content, the real-world application is questionable. Here, the LLM agent can be a consistent source of feedback of suitable length.




\subsection{Correlation analysis}\label{sec:corr_analysis}

To assess whether humans and LLMs excel or fall short for similar feedback texts or struggle with different kinds of errors, we analyzed the correlations of the expert ratings.

Correlations for language-related aspects were generally strong. \textit{Constructive Tone} showed moderate to strong correlations across all constellations ($\rho \geq .48$), reflecting meaningful alignment. \textit{Linguistic Clarity} demonstrated robust agreement across all sources ($\rho \geq .60$), while \textit{Technical Terminology} exhibited moderate positive correlations ($\rho \geq .41$). Detailed correlation values are provided in Table \ref{tab:correlations}.

In contrast, content-related aspects showed consistently weaker correlations. Between experts and teachers, correlations ranged from weak to moderate ($\rho = .26$ for \textit{Feed Forward} to $\rho = .41$ for \textit{Feed Back}), suggesting some overlap in performance on distinct feedback texts. However, correlations between human-written feedback and LLM-generated feedback were low to non-existent. For example, correlations between teachers and the LLM ranged from $\rho = .06$ for \textit{Feed Back} to $\rho = .21$ for \textit{Feed Up}, while correlations between expert feedback ratings and LLM feedback ratings were negligible ($|\rho| < .1$ for all aspects). Table \ref{tab:correlations} provides an overview over all correlation values. These results suggest that humans and LLMs struggled with different types of feedback texts, with limited alignment in their strengths.


\begin{table}[ht]
    \centering
    \begin{tabular}{lccc}
        \toprule
        & Teacher-Expert & Teacher-LLM & Expert-LLM \\
        \midrule
        Feed Up           &      .36      &    .21       &     -.05      \\
        Feed Back         &     .41       &    .06       &    .07       \\
        Feed Forward      &      .26      &     .18      &    .01       \\
        Constructive Tone &       .59     &    .54       &    .48       \\
        Linguistic Clarity&     .60       &     .61      &    .61       \\
        Technical Terminology &   .45    &     .48      &      .41     \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of the Spearman correlations coefficients $\rho$ across all six rating dimensions}
    \label{tab:correlations}
\end{table}




\subsection{Qualitative analysis}\label{sec:qualitative_example}
%Hier ein tolles beispiel dafür wie llm schlecht ist. Aber zum Ausgleich auch eins, wo llm super toll ist!

To gain deeper insight into why our LLM agent performs sometimes worse than the humans, we qualitatively compared the feedback provided by these three entities regarding a specific student error. The error analyzed in Table \ref{tab:qualitative_example} was selected based on two criteria: (1) poor performance by the LLM agent on content-related aspects, and (2) the largest overall gap between human and LLM feedback across all dimensions. The second criterion highlights cases where humans excel at providing effective feedback while the LLM agent falls short.


\newcommand{\feedup}[1]{\textcolor{orange}{#1}}
\newcommand{\feedback}[1]{\textcolor{purple}{#1}}
\newcommand{\feedforward}[1]{\textcolor{blue}{#1}}


\begin{table}[htbp]
    \centering
    
\begin{tabular}{p{1cm}p{8.3cm}P{1.2cm}} % p{1cm}p{1cm}p{1cm} & p{1.2cm}
\toprule
\textbf{} & \textbf{Feedback Text} & \textbf{Ratings} \\ \midrule
Expert         & \feedup{With a hypothesis, you should set a goal for your research project that you can confirm or refute with your experiment/trial.} Pay attention to the points for formulating a hypothesis that we discussed in class. Keep in mind that the hypothesis should be confirmable or refutable. \feedback{In your example, you have mixed various variables so that one cannot make distinctions and cannot confirm or refute it in that form}. Ensure that your hypothesis is clearly defined and all parts of your hypothesis are verifiable. For example: is it really temperature AND without light, or is it and/or? \feedforward{Try again to separate your variables and structure one or possibly two hypotheses.}   & FU: 5.0 FB: 5.0 FF: 5.0     \\  % CT: 4.0 LC: 3.0 TT: 5.0      
Teacher      & \feedback{Your hypothesis should not contain all your assumptions.} Initially, \feedforward{limit yourself to one, for example, the influence of temperature}. Based on these results, you can formulate a new hypothesis. Your hypothesis contains the dependent variable, but try to formulate a complete German sentence.      & FU: 1.0 FB: 5.0 FF: 4.0    \\ % CT: 4.0 LC: 2.0 TT: 5.0 
LLM     & \feedforward{Concentrate in your assumption on one variable to identify the trigger for the closure of the cone scales.} Conduct separate experiments for cold temperatures and darkness to determine the specific factor. Keep the variables controlled and constant to achieve accurate results.     & FU: 1.0 FB: 1.0 FF: 5.0         \\ \bottomrule % CT: 4.0 LC: 1.0 TT: 5.0  
\end{tabular}

    \caption{Illustrative example for the different feedback texts written by Science Education Experts, Teachers and LLM agent. The original hypothesis by the student was: \textit{That at low temperatures and without light shining in, the pine cone closes}. Here, the identified error is: \textit{Hypothesis consists of a combination of variables}. The Feedback texts are rated in the six categories, we colored the relevant parts of the texts including \feedup{Feed Up (FU)}, \feedback{Feed Back (FB)} and \feedforward{Feed Forward (FF)}. For the publication of this article the texts were translated from German into English.} % Constructive Tone (CT), Linguistic Clarity (LC), Technical Terminology (TT)
    \label{tab:qualitative_example}
\end{table}

The expert provided comprehensive feedback with high scores across all dimensions. It repeats the objective of formulating a  hypothesis (``set a goal [...] that you can confirm or refute''), identifies the status of the student's hypothesis and its problem (``mixed various variables'', ``cannot confirm or refute in that form'') and offers a clear suggestion on how to proceed (``separate your variables''). While the text includes all relevant aspects of good feedback, it is notably lengthy, consisting of 112 words - approximately twice the ideal length for students of this age group.
%
The teacher's feedback is generally strong but lacks initial context, jumping directly to the problem with the hypothesis (``should not contain all your assumptions'') before providing guidance on how to improve it (``limit yourself to one''). At 43 words, the feedback is concise and appropriately tailored for the target group.
%
The LLM agent's feedback, consisting of 41 words, focuses on explaining how to improve the experiment and what steps to take next (``concentrate your assumption on one variable''). However, it fails to establish a shared understanding of the goal of the hypothesis and does not explain the resulting problem with the student's hypothesis(e.g., why the current approach is difficult to test).

All three texts scored 5 points for appropriate use of technical terminology and 4 points for constructive tone. However, linguistic clarity varied: the expert received 3 points, the teacher 2, and the LLM agent only 1. The LLM agent's feedback remained high-level, using vague expressions like "specific factor" and failing to clarify how to keep variables "controlled and constant," which limited its usability for students.


% . Why does the model underperform here? Is it due to the complexity of the errors, the phrasing in student protocols, or limitations in the training data?

This example highlights that while the LLM agent effectively communicates with clarity comparable to human feedback and provides actionable guidance on next steps (e.g., focusing on one variable), it struggles to identify and articulate the specific problem in the student’s experimentation protocol and contextualize it effectively. 
%
This shortage may stem from several factors. Generally, student data tends to be very noisy, and in this case, the phrasing of the hypothesis is highly unusual, which can make it challenging for the model to fully comprehend the underlying idea. Furthermore, this specific type of student data is quite rare and likely not part of the model's training data. As a result, the model may lack experience in handling and generating this kind of data. Additionally, perfect feedback—encompassing feed up, feed back, and feed forward—might also be underrepresented in the training data. It is possible that many ``feedback'' texts focus primarily on next steps while giving less attention to feed up and feed back. Referring back to Section \ref{sec:multidim}, the LLM agent performs significantly better in addressing the feed forward component compared to the other two parts.
%
% While the LLM agent's tone and brevity make it engaging and accessible, its inability to pinpoint the exact issue and connect it to the broader context reduces its overall effectiveness compared to human feedback.

%Summary of results
These qualitative findings highlight that while LLM agent can provide valuable guidance on next steps and use appropriate technical language, there are still negative examples where they currently lag behind teachers and human experts in delivering contextual understanding and clear communication.


% The feedback lacked depth in establishing a shared understanding of the hypothesis's goal and failed to address why the current approach is problematic, relying on vague expressions like "specific factor." 