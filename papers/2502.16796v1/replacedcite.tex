\section{Related Work}
\subsection{Automated Task Execution on Mobile Phone}

Mobile phones have become so inseparable from our lives, that the development of automated user task execution on mobile phones has become a research spotlight, which can be categorized into three types of methods:
(1) \textbf{API-based methods}, which are favored by industry and have already been deployed for user in actual mobile phones, \eg Siri, Google Assistant and XiaoAI ____. However, such methods are limited by API access and invocation to some extent.
(2) \textbf{GUI-based methods}, which seek for automated task execution by simulating interactions with the graphical user interfaces (GUIs) ____. These methods usually require screen summarizing____, widgets recognition____ and command grounding____ to augment the GUI understanding and action prediction. Moreover, Spotlight____ designed a Region-of-Interest (ROI) Align to localize to the regions and widgets that more relevant to the task.
(3) \textbf{Experience-based methods}, which learn from the historical experience. MobileGPT____ constructs a Hierarchical App Memory through exploration and then uses Flexible Task Recall in the execution phase. AutoDroid____ constructs the UI Transition Graph (UTG) by exploring during the offline phase, which in turn is extracted to form memory.

The diversity among apps makes existing methods ineffective in solving tasks on various apps, so we design Assigned Execution to utilize app-oriented StaffAgents to complete tasks on specific apps.

\subsection{LLM/LMM Agents on Mobile Phones}

The rapid development of LLMs/LMMs has encouraged them to be adopted as agents on mobile phones ____. These methods utilize LLM's powerful semantic reasoning capabilities to analyze the tasks____ or LMM's excellent image comprehension capabilities to assist the GUI understanding____. We can divide them into three categories:
(1) \textbf{Pre-trained methods}: CogAgent____ and ScreenAI____, pre-train a visual language model on a mix of screen tasks (QA, summarization, annotation and navigation) to build a general agent for automated task execution.
(2) \textbf{Fine-tuned methods}: These methods usually include the historical information to assist in action decisions. 
Auto-UI____ introduces historical actions during fine-tuning on a large scale dataset AITW____ and can be improved by adopting Chain-of-Action-Thought(CoAT)____. 
CoCo-Agent____ augments the screenshot with the textual layout representation and conduct conditional action prediction. 
(3) \textbf{Inference methods}: These methods instruct LLMs/LMMs for planning, decision making or reflection to automate tasks____.
AppAgent____ generates documents by self-exploration/demo-watching and adopts SoM____ to assist in action decision. 
MobileAgent____ augments action grounding with visual perception module and action execution with self-planning and self-reflection.

These single-agent methods struggle to solve cross-app instructions because of the long execution, thus we designed Adjusted Evaluation to alleviate the information loss and error propagation.

\subsection{Multi-Agent Framework}

The success of AutoGPT____, HuggingGPT____ and OpenAGI____ demonstrates the ability of autonomous agents to perform simple tasks.
In order to solve complex task, the multi-agent framework has been widely explored by many researchers ____. 
CAMEL____ and AutoGen____ focuses on complex solutions through communication among agents.
ChatDev____ and MetaGPT____ split the process of program development into several stages that each engages an agent to facilitate a seamless workflow. The same strategy has been used in recommendation____, debate____, question-answering ____ and fact-checking____. 
The multi-agent framework has also been applied to many social simulation works, where many role-played agents simulate the development of the society through the interaction and cooperation____.
While the multi-agent framework on mobile scenarios is still under-explored. MobileAgent-v2____ integrates planning, decision and reflection agents forming a pipeline equipped with memory unit to improve the performance of automated task execution, while it still struggle for cross-app instructions.

Most of the current multi agent frameworks use procedure-oriented agent splitting, while cross-app instructions are more suitable for object-oriented approach, thus we build an app-oriented multi-agent framework with self-evolution.