

% 往 inference time 上靠

% \section{Analysis}
\subsection{Efficiency Analysis}
% To show the efficiency of our methods, we compare the average retrieve counts over the test samples on 2WikiMultihopQA and HotpotQA. 
% As shown in Table~\ref{tab:efficiency}, DRAGIN的检索次数受到阈值和不同数据集的影响很大，特别的对于不同的数据需要不同的阈值，as we know 2WikiMultihopQA的数据需要的evidence比 hotpotqa包含的数据需要的evidence要多一些，由于它有更多复杂的多跳问题，然后，对比相同的threshold，hotpotqa调用检索的次数却比2wiki的多，which展现了它的不鲁棒性。
% 相反的，我们的方法普遍使用了较少次数的检索，同时检索的次数和query的难度相关度较大

% To demonstrate the efficiency of our methods, we compare the average retrieval counts across test samples on 2WikiMultihopQA and HotpotQA. 

% As shown in Table~\ref{tab:efficiency}, we statistics the retrieval counts and answer accuracy for both the DRAGIN baseline and our method.
% Our method achieves a great balance between effectiveness and efficiency.
% In contrast, the retrieval counts of DRAGIN are significantly influenced by the threshold and the specific dataset.
% Moreover, different datasets require different thresholds due to the complexity of their queries.
% For instance, 2WikiMultihopQA requires more evidence because it contains more complex multi-hop questions compared to HotpotQA.
% However, when DRAGIN uses the same threshold, HotpotQA requires more retrievals than 2WikiMultihopQA, highlighting DRAGIN's lack of robustness.
% Conversely, our method consistently uses fewer retrievals, and the number of retrievals is more closely related to the difficulty of the queries.

\input{table/efficiency}

To demonstrate the efficiency of our method, we compare the average number of retrievals across test samples on 2WikiMultihopQA and HotpotQA. As shown in Table~\ref{tab:efficiency}, our method has two main advantages:

\begin{itemize}
    \item \textbf{Fewer Retrievals Required} Our method requires significantly fewer retrievals than the DRAGIN baseline while maintaining high answer accuracy. This efficiency highlights our method's ability to achieve effectiveness with less computational effort.
    \item \textbf{Better Correlation with Query Difficulty} The number of retrievals in our method is more closely related to the difficulty of the queries. Complex queries naturally demand more retrievals, and our method adjusts accordingly. In contrast, DRAGIN's retrieval counts are significantly influenced by threshold settings and vary inconsistently across different datasets. For instance, even though 2WikiMultihopQA contains more complex multi-hop questions that typically require more evidence, DRAGIN retrieves more times on HotpotQA when using the same threshold, underscoring its lack of robustness.
\end{itemize}

In summary, our method not only reduces the number of retrievals needed but also aligns the retrieval effort with the actual difficulty of the queries, demonstrating both efficiency and adaptability.


\subsection{Self-Evolving Trajectory Analysis}
% 三个阶段检索次数分布线箱图
% In this section, we visualize how the model enhances its RAG capability across different stages. We first 展示了模型的检索次数分布在cot、stage I和stage II. Then 我们展示了在不同stage模型的检索次数的变化趋势

we conduct a comprehensive analysis to understand how our approach progressively enhances the model's RAG capabilities, with a particular focus on retrieval efficiency. Our analysis consists of two key aspects: 1) We examine the distribution of retrieval counts across three stages (CoT baseline, Stage I, and Stage II) to understand the evolution of the model's retrieval behavior. 2) We track the temporal dynamics of retrieval counts through different training stages to reveal the optimization trajectory of our approach.

\paragraph{Retrieval Counts Distribution} As shown in Figure~\ref{fig:retrieve-counts}, we analyze the distribution of retrieval counts across three stages: CoT baseline, Stage I, and Stage II. Compared to the CoT baseline, Stage I demonstrates a significant reduction in retrieval frequency, indicating the model's learned ability to make more efficient retrieval decisions. Stage II further optimizes the retrieval strategy, showing a more pronounced shift towards minimal retrieval attempts while maximizing the utilization of internal knowledge.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{figure/retrieve_counts_distribution.pdf}
    \caption{Retrieval counts distribution across different stages on 2WikiMultihopQA dataset.}
    \label{fig:retrieve-counts}
\end{figure}


\paragraph{Retrieval Counts Trajectory}


% As shown in Figure~\ref{}, we illustrate the trajectory of Retrieve counts for the differenct stages. Speciffically, we seperate them by whether they answer correctly in the Stage II. Based on it, we can find that 1. 对于模型会的问题，随着不同stage的evolve，模型逐渐变得倾向于使用内部知识回答，figure(a)中，大多数数据逐渐呈现从检索次数多到少的流动趋势，而极少数数据的检索次数增多,which may due to the intrinsic uncerntainty of model. 
% 2. 对于模型回答错误的问题，随着不同stage的演进，模型倾向于探索多的次数来尝试回答，例如figure(b)中流向dpo3，4，5的数据比figre(a)中多。

\begin{figure}[htbp]
    \centering
    \begin{minipage}[b]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figure/correct.pdf}
        % \caption{Retrieval counts trajectory during training}
        % \label{fig:trajectory-counts}
        (a) Correct
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figure/incorrect.pdf}
        % \caption{Answer accuracy trajectory during training}
        % \label{fig:trajectory-acc}
        (b) Incorrect
    \end{minipage}
    \caption{Training trajectories showing the evolution of retrieval counts and answer accuracy across different stages.}
    \label{fig:trajectory}
\end{figure}


As shown in Figure~\ref{fig:trajectory}, we depict the trajectory of retrieval counts across different stages of our model. We specifically separate the data based on whether the model answers correctly in Stage II. Based on it, we observe the following:

For questions that the model answers correctly, the model progressively relies more on its internal knowledge as it evolves through the stages. In Figure~\ref{fig:trajectory} (a), most data points exhibit a trend of decreasing retrieval counts over time, indicating a shift from external retrieval to internal reasoning. Only a small fraction of data points show increased retrieval counts, which may be due to the model's intrinsic uncertainty.

For questions that the model answers incorrectly, the model tends to increase its number of retrieval attempts in subsequent stages to find the correct answer. In Figure~\ref{fig:trajectory} (b), there is a higher proportion of data flowing into stages with more retrievals (DPO3, DPO4, DPO5) compared to Figure~\ref{fig:trajectory} (a). This suggests that when the model struggles to provide the correct answer, it compensates by exploring more retrievals.

These findings highlight that our model not only reduces retrieval counts when confident but also adjusts its retrieval efforts based on the difficulty of the queries, demonstrating an adaptive retrieval strategy.


% 召回率分析？

% impact of 两类偏序数据的比例
\subsection{Adaptability to Different Retrievers}

\input{table/retriever}

\input{table/casestudy}

% In this section, we study whether our method can 适应其他的检索器，并进行有效的检索。具体来说，我们主要探究SRAG在DPR上的表现和BM25的有什么区别，因此我们和一个基于DPR的baseline相比，并且和基于BM25的SRAG相比。

In this section, we investigate SRAG's adaptability to different retrieval mechanisms and its effectiveness across various retrieval architectures. 
Specifically, we examine SRAG's performance when integrated with dense passage retrieval (DPR) compared to its BM25-based implementation. 
We conduct comparative experiments against both a DPR-based baseline and our BM25-based SRAG to evaluate the method's generalizability across different retrieval paradigms.


For DPR implementation, we utilize the RAGRetriever pipeline from HuggingFace\footnote{\url{https://huggingface.co/facebook/rag-sequence-nq}}. The question encoder is \texttt{facebook/rag-sequence-nq}, and we use the compressed DPR embeddings from \texttt{facebook/wiki\_dpr}\footnote{\url{https://huggingface.co/datasets/facebook/wiki_dpr}} for efficient retrieval.


As shown in Table~\ref{tab:retriever}, we derive two key findings:
% 1. 和dragin论文中提到的相同，dpr的检索器有时候不如bm25
% 2. 比基于dpr的baseline效果好
1) Our SRAG method performs exceptionally well when integrated with the DPR retriever. We implemented both the FLARE baseline and xxx baseline using the DPR retriever, and our SRAG method outperforms these DPR-based baselines. This demonstrates SRAG's effectiveness across different retrieval mechanisms, indicating its adaptability and ability to enhance retrieval performance regardless of the underlying retrieval architecture.
2) Consistent with observations in the DRAGIN paper, we find that the DPR retriever sometimes underperforms compared to BM25. We speculate this is mainly due to two reasons: a)  Existing literature has shown that BM25 retrieval offers greater robustness, especially in some scenarios. b) Current QA datasets are usually constructed with queries based on Wikipedia. The entities in question often use the same expressions as in the documents in such datasets. Therefore, keyword-matching methods like BM25 can perform better because they leverage exact term overlaps between queries and documents.


These findings highlight SRAG's flexibility and robustness, showing that it not only adapts to various retrieval systems but also consistently improves performance over baseline methods.

\subsection{Case study}
% In Table~\ref{tab:casestudy}, we show a 典型的 case that 展示了SRAG的整个学习过程。In 对于问题“Where is the company that Sachin Warrier worked for as a software engineer headquartered”。 在stage1，SRAG 会首先obtain knowledge that Sachin Warrier worked for Tata Consultancy Services. Then, it 搜索 the headquarters of Tata Consultancy Services 从而获得答案是mumbai。而对于stage2， SRAG在检索到Sachin Warrier worked for Tata Consultancy Services之后，它利用内部知识回答了Tata Consultancy Services的首都在Mumbai。

Table~\ref{tab:casestudy} provides a representative case study demonstrating the complete learning process of SRAG. For the query, ``Where is the company that Sachin Warrier worked for as a software engineer headquartered?'', SRAG follows distinct approaches in each stage. In Stage 1, the model initially acquires the knowledge that Sachin Warrier was employed at Tata Consultancy Services. Subsequently, it conducts a search to locate the headquarters of Tata Consultancy Services, retrieving the answer Mumbai. In Stage 2, however, after identifying that Sachin Warrier worked for Tata Consultancy Services, SRAG leverages its internal knowledge base to directly determine that the company's headquarters is in Mumbai, bypassing the need for an external search.