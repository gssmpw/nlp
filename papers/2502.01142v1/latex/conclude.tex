\section{Conclusion}
% In this paper, we present DeepRAG, a simple yet effective approach that enhances LLM's awareness of retrieval requirements through a self-calibration mechanism.
% % 
% Our method decomposes queries into multiple subqueries, enabling the model to make adaptive decisions about retrieval necessity for each subquery in an iterative manner.
% We implement a binary tree search method for data synthesis to calibrate the model's understanding of its knowledge boundaries.
% % 
% Experimental results demonstrate that DeepRAG significantly enhances LLM performance across multi-hop QA, time-sensitive QA, and heterogeneous knowledge base QA tasks. These findings validate both the necessity and effectiveness of DeepRAG in advancing adaptive retrieval generation by improving the accuracy and efficiency of retrieval-augmented generation.


In this paper, we present DeepRAG, a simple yet effective approach that enhances LLM's awareness of retrieval requirements through self-calibration. 
Our method decomposes queries into subqueries and uses binary tree search for data synthesis to help models better understand their knowledge boundaries.
Experimental results across various QA tasks demonstrate that DeepRAG significantly improves the accuracy and efficiency of retrieval-augmented generation.

