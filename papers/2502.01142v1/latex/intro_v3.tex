% 头图修改
% 有些query是不必要检索的/有些knowledge是需要检索的
% 基于上下文的query而不是knowledge的
% 人类思考过程dynamic knowledge decision 标题，已解决

\section{Introduction}

% 大模型已经展现出remarkable能力。
% 然而，由于模型容量和能力的限制，模型经常生成错误信息
% 一个promising的方法来解决幻觉就是RAG
Large Language Models (LLMs) have gained increasing prominence in the field of artificial intelligence~\cite{zhao2023survey}.
However, limited by the capacity and capabilities of LLM, it still suffers from severe factual hallucination problems due to the lack of intrinsic knowledge~\cite{zhang2023hallucination,huang2023survey}.
Retrieval-Augmented Generation (RAG) has been proposed as a promising paradigm to address this issue by integrating relevant information from knowledge bases or search engines, thereby improving the factuality of model response~\cite{zhao2024retrieval}.

% Unfortunately，检索并不是always有必要的，
% 一方面，额外的检索时浪费推理时间
% 另一方面，引入noise甚至错误信息导致错误答案

% Unfortunately，检索并不是always有必要的，
% 一方面，额外的检索时浪费推理时间
% 另外，额外的文档会影响模型的上下文能力,尤其是对于一些基于上下文的问题，模型应该忠实地根据给定信息回答，而不是盲目寻求外部资源，导致违背了faithful。
% 更严重的是，在不必要的检索中不幸引入noise甚至错误信息导致错误答案，从而毁灭了性能。



\begin{figure}[t]
    \centering
    \includegraphics[width=0.98\linewidth]{figure/fig1.pdf}
\caption{Correspondence between human metacognitive processes and DeepRAG.}
    \label{fig:comparison}
\end{figure}

However, indiscriminate retrieval is not always helpful or necessary, potentially overlooking models' inherent knowledge capabilities, introducing significant retrieval overhead, and even compromising model performance~\cite{chen2023understanding,tan2024blinded}.
% 
LLMs have demonstrated the capability to serve as knowledge bases themselves~\cite{petroni-etal-2019-language}. 
Consequently, when faced with tasks that can be addressed using the parametric knowledge, unnecessary retrieval not only introduces redundancy but also leads to increased computational overhead during inference.
% and may introduce potentially irrelevant text even noise text, compromising the factuality of LLMs' outputs.
% 
Furthermore, the injection of superfluous information may adversely affect the model's performance, causing the model to struggle to maintain focus on the core task~\cite{liu-etal-2024-lost}. 
% 
Especially for queries heavily dependent on given context rather than factual knowledge, models should faithfully respond based on the provided information instead of blindly seeking external resources~\cite{huang2023survey}.
% 
More critically, when retrieved text is highly relevant to the query yet contains false statements,
LLMs may be misled. This could potentially lead to incorrect responses, thereby undermining the purpose of knowledge augmentation~\cite{bian2024influence,chen2024benchmarking}


% studies have revealed that LLMs face challenges in handling noisy or counterfactual text~\cite{chen2024benchmarking}. In scenarios where retrieved information is highly relevant to the query but contains inaccuracies or false statements, LLMs often struggle to discriminate it. This limitation can result in the model being misled, potentially leading to incorrect responses and undermining the purpose of knowledge augmentation~\cite{bian2024influence,pan2023risk}.





% from human perspecitve, 人类并不会对会的问题搜索，而只会针对不会的问题搜索。
% However，仅仅依靠模型自身的输出来判断是否需要检索是不可靠的。
% Therefore, we aim to guide LLM's awareness of retrieval need based on a self-calibration process.
% In this paper, we propose Adaptive Inference-time Compute Generation(DeepRAG)，a simple yet effective method desinged to 让模型认识到自我知识边界。
% DeepRAG的主要思想是通过对模型 关于回答query所需要的知识是否需要检索 这一行为进行校准。
% 通过让模型意识到自我知识边界，能够有效的提高检索效率、规避不必要的文档噪声

% from metacognition theory and 信息搜寻理论，人类adaptive的寻找自己需要的信息，通过Metacognitive Knowledge评估自己的知识，并通过Metacognitive Control来决策自己进一步需要的信息。


According to metacognition theories~\cite{brown1987metacognition,jacobs1987children} and information foraging theory~\cite{info}, humans typically adapt their information-seeking behavior based on demand, illustrated in Figure~\ref{fig:comparison}.
The Metacognitive Monitoring Module enables self-awareness of one's own knowledge state, and the Metacognitive Control Module governs decisions about acquiring additional information when necessary.
% 
In this paper, we propose \textbf{DeepRAG}, a new framework that dynamically integrates models' parametric knowledge with external knowledge bases.
% 
DeepRAG leverages the LLM's capabilities in two ways: a Metacognitive Monitoring Module for self-awareness assessment, and a Metacognitive Control Module for determining query decomposition strategies.
Through this design, DeepRAG enhances retrieval-augmented generation by decomposing queries and iteratively identifying retrieval needs based on dynamic cognitive decisions during the reasoning process.


% Metacognitive Knowledge Module对应于模型的自我认知
% Metacognitive Knowledge Control对应于模型的query分解
% 
% DeepRAG enhances retrieval-augmented generation by decomposing queries and iteratively identifying retrieval needs based on dynamic cognitive decisions during the reasoning process.
% a simple yet effective method designed to emulate human-like metacognitive processes in LLMs. This approach guides the model's awareness of retrieval needs through a self-calibration process, enabling more efficient information seeking behavior.
% 
% The core idea of DeepRAG is to calibrate the model's behavior regarding whether knowledge retrieval is necessary to answer a given query.
% 
% By enabling the model to recognize its own knowledge boundaries, DeepRAG effectively improves retrieval efficiency and mitigates unnecessary document noise. 

% In this paper, we propose \textbf{DeepRAG}, a simple yet effective method designed to emulate human-like metacognitive processes in LLMs. The core idea is to calibrate the model's behavior regarding the necessity of knowledge retrieval for a given query. % 
% By enabling the model to recognize its own knowledge boundaries, DeepRAG guides the LLM's awareness of retrieval needs, leading to more efficient and context-appropriate information seeking behavior. This approach effectively improves retrieval efficiency and mitigates unnecessary document noise.



% 然而，实现上述过程具有挑战性，xxx 已经表明仅仅根据query去检索知识通常无法检索到所有回答所需的信息，following xxx，我们将query分解成多个subquery，对于each subquery，我们让模型adaptively选择是否进行检索。
% 为了校准模型对知识边界的认知，我们设计了二叉树搜索方法，对于每个subquery，我们分别探索其在是否使用检索对于推理结果的影响。基于这个方法，我们首先生成数据让llm通过模仿学习到“子问题生成-是否检索-中间答案”的模式。接着，我们使用chain of calibration的方法校准模型对内部知识的认知，从而更加准确的决定是否需要检索。
% 这样，我们的方法不仅可以通过问题分解的过程简化每个子问题从而简化检索的难度，adaptively 和 accurately 根据每个子问题结合内部知识决定是否要检索。
% 此外，由于过程中的所有阶段都仅使用数据的输入和answer，不需要任何额外的监督，因此可以基于任何有监督数据集来校准llm在rag场景下的知识边界。

% Unfortunately, achieving the above process is challenging. 
% % 问题1 问题分解
% For one thing, previous research~\cite{radhakrishnan2023question,balesni2024two} has shown that retrieving knowledge based solely on the initial query often fails to gather comprehensive information. 
% Following \citet{yue2024inference}, we decompose the query into multiple subqueries, allowing the model to adaptively decide whether retrieval is necessary for each subquery iteratively.
% % 问题2 知识边界矫正
% For another thing,  LLMs often lack this nuanced self-awareness of their knowledge boundaries, making it unreliable to depend solely on the model's own output to determine the necessity of retrieval~\cite{yin2023large,ren2023investigating}.
% % 我们的方法
% To overcome this, we developed a binary tree search method to identify the optimal path for determining whether retrieval is necessary for each subquery.
% Based on it, we synthesize data to train the LLM on the pattern of ``subquery generation - retrieval decision - intermediate answer''. 
% Subsequently, we employ chain of calibration to enhance model's awareness of its internal knowledge, enabling more accurate decisions on retrieval necessity.



Given a query, we first decompose it into several subqueries.
Then, we aim for the model to autonomously decide whether retrieval is necessary for each subquery.
% 
However, LLMs often lack nuanced self-awareness of their knowledge boundaries, making it unreliable to depend solely on the model's output to determine the necessity of retrieval~\cite{yin2023large,ren2023investigating}. 
% 
To overcome this limitation, we aim to develop a method that helps models quickly calibrate their knowledge boundaries to enable adaptive retrieval.
As illustrated in Figure~\ref{fig:main}, we develop a binary tree search method to identify the optimal path for determining whether retrieval is necessary for each subquery. 
Based on it, we synthesize data to train the LLM on the pattern of ``subquery generation - retrieval decision - intermediate answer''. 
Subsequently, we employ chain of calibration to enhance model's awareness of its parametric knowledge.
% , enabling more accurate decisions on retrieval necessity.
% 好处1
In this way, our method can not only streamline the retrieval process but also enable adaptive and accurate retrieval decisions based on parametric knowledge for each subquery.
% 好处2
Furthermore, our method provides a method for autonomously synthesizing data for training a calibrated retrieval-augmented language model, which enables us to calibrate LLM's knowledge boundaries in RAG scenarios based on a supervised dataset.
% using any existing dataset.

% we develop a method for autonomously synthesizing reasoning-based decision-making instructions in iterative retrieval and fine-tuned the latest open-source LLMs

% Therefore, we designed a binary tree search method to calibrate the model's perception of its knowledge boundaries. For each subquery, we explore the impact of retrieval on the reasoning process. 
% \Furthermore, because all phases in the procedure rely solely on input data and answers without additional supervision, our method can calibrate LLM's knowledge boundaries in RAG scenarios using any supervised dataset. 


We conduct experiments on five open-domain QA datasets to validate the effectiveness of DeepRAG, including HotpotQA, 2WikiMultihopQA, and PopQA for multi-hop factual QA, CAG for time-sensitive QA, and WebQuestions for heterogeneous knowledge base QA.
% 
Experimental results demonstrate that DeepRAG significantly outperforms existing methods, achieving 21.99\% higher answer accuracy while improving retrieval efficiency.
Further analysis reveals that DeepRAG exhibits a stronger correlation between its retrieval decisions and parametric knowledge, indicating more effective knowledge boundary calibration.
 
% In summary, the contributions are as follows:


% 1. 提出一种new方法that enhance RAG via 让模型自适应的决定检索的时机 in inference time.
% 2. 提出了一种自动化框架可以基于任何有监督数据集校准RAG场景下的self-awareness.
% 3. 实验效果导致accurate efficient by exploring konwledge boundary

% \begin{itemize}
%     \item We propose a new framework that enhances Retrieval-Augmented Generation by enabling LLMs to adaptively determine the necessity of retrieval during inference time, thereby improving both effectiveness and efficiency.
%     \item We introduce an automated framework that calibrates the self-awareness of LLMs in RAG scenarios that can be applied to any supervised dataset without additional supervision.
%     \item Experimental on multi-hop QA, time-sensitive QA, and heterogeneous knowledge base QA confirm that DeepRAG can significantly enhance both the effectiveness and efficiency of retrieval-augmented generation with great generalization ability by exploring their knowledge boundary.
% \end{itemize}


\begin{figure*}[htbp]
    \centering
    \includegraphics[width=0.98\linewidth]{figure/srag.pdf}
    \caption{An overview of DeepRAG, our framework comprises three key components: (1) Binary Tree Search, (2) Imitation Learning, and (3) Chain of Calibration. Given a set of supervised datasets, we first employ binary tree search to synthesize data for imitation learning, enabling the model to learn retrieval patterns. Subsequently, we use binary tree search to construct preference data for further calibrating the LLM's awareness of its knowledge boundaries.}
    \label{fig:main}
\end{figure*}
