
\appendix
\section{Templates}
\subsection{DeepRAG Construct Instruction}
\label{template}
\begin{tcolorbox}
\small

Instruction: You are a helpful Retrieve-Augmented Generation (RAG) model. Your task is to answer questions by logically decomposing them into clear sub-questions and iteratively addressing each one. \\

Use "Follow up:" to introduce each sub-question and "Intermediate answer:" to provide answers. \\

For each sub-question, decide whether you can provide a direct answer or if additional information is required. If additional information is needed, state, "Let's search the question in Wikipedia." and then use the retrieved information to respond comprehensively. If a direct answer is possible, provide it immediately without searching.


\end{tcolorbox}

% \section{Algorithms for constructing Imitation learning data}
% The algorithm for constructing imitation learning data is shown in Algorithm~\ref{algorithm:imi}.



\section{Detailed Analysis}
\subsection{Retrieval Efficiency}

To demonstrate the efficiency of our method, we compare the average number of retrievals on 2WikiMultihopQA and WebQuestions. As shown in Table~\ref{tab:efficiency}, We have following observations:

1) Compared to other adaptive retrieval methods, DeepRAG can achieve higher accuracy with relatively lower retrieval costs. This can be attributed to our dynamic usage of internal knowledge.
Additionally, DeepRAG exhibits a positive trend in exploring relevant evidence when faced with insufficient retrieval results, as evidenced by the lower average retrieval numbers in both 2WMQA (0.92 compared to 1.25) and WQ (0.12 compared to 0.36).
% 
2) Confidence-based approaches demonstrate limited robustness across datasets.  
For instance, while using identical thresholds, both FLARE and DRAGIN methods show inconsistent behavior: they trigger approximately one retrieval per query in 2WMQA, but fail to reach the retrieval threshold entirely in WQ. This inconsistency highlights the challenge of maintaining reliable performance across different datasets using confidence-based methods.
% 
3) Iterative retrieval-based approaches typically require numerous retrieval operations, resulting in substantial computational costs. Therefore, efficient adaptive retrieval methods like DeepRAG become crucial for optimizing resource utilization while maintaining performance.




\subsection{Relevance to Parametric Knowledge}
\label{relevance}
% TODO 这里要讲的更清楚
In this section, we investigate the relationship between retrieval needs and parametric knowledge to demonstrate how effectively our method explores the knowledge boundary.


Ideally, models should initiate retrieval for queries beyond their parametric knowledge while utilizing their existing knowledge for familiar queries. We use CoT results as an indicator of whether the model can answer questions using its parametric knowledge. Subsequently, we analyze whether other adaptive retrieval methods align with this pattern of parametric knowledge utilization.
% 
We evaluate the relevance using four metrics. F1 score and Accuracy serve as basic performance measures, while balanced accuracy and Matthews Correlation Coefficient(MCC) are employed to account for the class imbalance between retrieval-required and retrieval-not-required cases. The MCC ranges from -1 to 1, where a value of 1 indicates perfect correlation, 0 represents no correlation (random chance), and -1 signifies an inverse correlation.

% 1. DeepRAG 展现了很好的相关性 2. FLARE，DRAGIN，TAARE展现了较高的Acc 但是balancedacc和MCC并不高，因为他们的成功仅来源于成功检索的case，对于没有必要检索的case并没有正确规避
As shown in Table~\ref{tab:relevance}, we find that 1) 
DeepRAG demonstrates superior relevance performance across F1, balanced accuracy, and MCC metrics. 
This suggests that DeepRAG successfully identifies retrieval necessity by exploring knowledge boundary.
% 
2) While FLARE, DRAGIN, and TAARE exhibit high accuracy scores, their relatively low balanced accuracy and MCC scores suggest they mainly succeed in retrieval-required cases but struggle to properly avoid unnecessary retrievals.




\subsection{Ablation Study}
Table~\ref{tab:sft-abla-dtail} and Table~\ref{tab:dpo-abla-detail} show the detailed results of the ablation study.



% Table generated by Excel2LaTeX from sheet 'abaltion'
\begin{table}[H]
  \centering
  \resizebox{\linewidth}{!}{
    \begin{tabular}{rcccccc}
    \toprule
          & HotpotQA & 2WMQA & CAG   & PopQA & WebQuestion & \multirow{2}[2]{*}{Avg} \\
          & F1    & F1    & EM    & EM    & EM    & \\
    \midrule
    \multicolumn{1}{l}{DeepRAG-Imi} & 46.59  & \textbf{52.33 } & 50.47  & \textbf{43.60 } & \textbf{30.00 } & \textbf{44.60 } \\
    most & \textbf{47.73 } & 46.88  & 51.09  & 31.30  & 28.00  & 41.12  \\
    random & 46.78  & 42.75  & \textbf{51.40 } & 34.80  & 27.10  & 40.56  \\
    \bottomrule
    \end{tabular}%
    }
    \caption{Detailed Experiment results of the ablation study on the Imitation Learning Stage.}
  \label{tab:sft-abla-dtail}%
\end{table}%






% Table generated by Excel2LaTeX from sheet 'abaltion'
\begin{table}[H]
  \centering
  \resizebox{\linewidth}{!}{
    \begin{tabular}{rcccccc}
    \toprule
          & HotpotQA & 2WMQA & CAG   & PopQA & WebQuestion & \multirow{2}[2]{*}{Avg}\\
          & F1    & F1    & EM    & EM    & EM    &  \\
    \midrule
    \multicolumn{1}{l}{DeepRAG} & \textbf{51.54 } & \textbf{53.25 } & \textbf{61.92 } & \textbf{47.80 } & \textbf{45.24 } & \textbf{47.67 } \\
    all-node & 49.99  & 51.85  & 50.47  & 41.50  & 32.70  & 45.30  \\
    sentence-wise & 29.03  & 31.28  & 12.46  & 20.00  & 12.90  & 21.14 \\
    \bottomrule
    \end{tabular}%
    }
  \caption{Detailed experiment results of the ablation study on the Chain of Calibration Stage.}
  \label{tab:dpo-abla-detail}%
\end{table}%
