% 头图修改
% 有些query是不必要检索的/有些knowledge是需要检索的
% 基于上下文的query而不是knowledge的
% 人类思考过程dynamic knowledge decision 标题，已解决

\section{Introduction}

% 大模型已经展现出remarkable能力。
% 然而，由于模型容量和能力的限制，模型经常生成错误信息
% 一个promising的方法来解决幻觉就是RAG
Large Language Models (LLMs) have gained increasing prominence in the field of artificial intelligence.
However, limited by the capacity and capabilities of LLM, it still suffers from severe factual hallucination problems due to the lack of intrinsic knowledge~\cite{zhang2023hallucination}.
Retrieval-augmented generation (RAG) has been proposed as a promising paradigm to address this issue by integrating relevant factual information from external knowledge bases or search engines, thereby improving the factual accuracy and reliability of LLM outputs~\cite{zhao2024retrieval}.

% Unfortunately，检索并不是always有必要的，
% 一方面，额外的检索时浪费推理时间
% 另一方面，引入noise甚至错误信息导致错误答案
However, retrieval is not always helpful, and employing it for every instruction proves sub-optimal~\cite{chen2023understanding,tan2024blinded}.
When confronted with tasks that do not necessitate external knowledge, the introduction of RAG can lead to increased computational overhead during inference and may introduce potentially irrelevant text, compromising the factuality of LLMs' outputs.
% 
Specifically, previous research has demonstrated that by eliminating unnecessary retrieval operations, the efficiency of Retrieval-Augmented Generation can be significantly enhanced.
% 
Furthermore, the injection of superfluous information may adversely affect the model's performance, causing the model to struggle to maintain focus on the core task~\cite{liu-etal-2024-lost}.
% 
More critically, studies have revealed that LLMs face challenges in handling noisy or counterfactual text~\cite{chen2024benchmarking}. In scenarios where retrieved information is highly relevant to the query but contains inaccuracies or false statements, LLMs often struggle to discriminate it. This limitation can result in the model being misled, potentially leading to incorrect responses and undermining the purpose of knowledge augmentation~\cite{bian2024influence}.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.98\linewidth]{figure/fig1.pdf}
    \caption{Comparison of traditional RAG and our DeepRAG.}
    \label{fig:comparison}
\end{figure}


% from human perspecitve, 人类并不会对会的问题搜索，而只会针对不会的问题搜索。
% However，仅仅依靠模型自身的输出来判断是否需要检索是不可靠的。
% Therefore, we aim to guide LLM's awareness of retrieval need based on a self-calibration process.
% In this paper, we propose Adaptive Inference-time Compute Generation(DeepRAG)，a simple yet effective method desinged to 让模型认识到自我知识边界。
% DeepRAG的主要思想是通过对模型 关于回答query所需要的知识是否需要检索 这一行为进行校准。
% 通过让模型意识到自我知识边界，能够有效的提高检索效率、规避不必要的文档噪声

From a human perspective, individuals typically search for information only when encountering unfamiliar questions, relying on their existing knowledge for known topics. 
However, LLMs often lack this nuanced self-awareness of their knowledge boundaries, making it unreliable to depend solely on the model's own output to determine the necessity of retrieval~\cite{yin2023large}.
% 
In this paper, we propose \textbf{DeepRAG}, a simple yet effective method designed to guide LLM's awareness of retrieval needs based on a self-calibration process. 
% 
The core idea of DeepRAG is to calibrate the model's behavior regarding whether knowledge retrieval is necessary to answer a given query.
% 
By enabling the model to recognize its own knowledge boundaries, DeepRAG effectively improves retrieval efficiency and mitigates unnecessary document noise. 



% 然而，实现上述过程具有挑战性，xxx 已经表明仅仅根据query去检索知识通常无法检索到所有回答所需的信息，following xxx，我们将query分解成多个subquery，对于each subquery，我们让模型adaptively选择是否进行检索。
% 为了校准模型对知识边界的认知，我们设计了二叉树搜索方法，对于每个subquery，我们分别探索其在是否使用检索对于推理结果的影响。基于这个方法，我们首先生成数据让llm通过模仿学习到“子问题生成-是否检索-中间答案”的模式。接着，我们使用chain of calibration的方法校准模型对内部知识的认知，从而更加准确的决定是否需要检索。
% 这样，我们的方法不仅可以通过问题分解的过程简化每个子问题从而简化检索的难度，adaptively 和 accurately 根据每个子问题结合内部知识决定是否要检索。
% 此外，由于过程中的所有阶段都仅使用数据的输入和answer，不需要任何额外的监督，因此可以基于任何有监督数据集来校准llm在rag场景下的知识边界。


Unfortunately, achieving the above process is challenging. 
% 
Previous research has shown that retrieving knowledge based solely on the initial query often fails to gather all the necessary information for a comprehensive answer. 
Following \citet{yue2024inference}, we decompose the query into multiple subqueries, allowing the model to adaptively decide whether retrieval is necessary for each subquery iteratively.
To calibrate the model's perception of its knowledge boundaries, we designed a binary tree search method. For each subquery, we explore the impact of retrieval on the reasoning process. 
Based on it, we first synthesize data to make LLM focusing on the pattern of ``subquery generation - retrieval decision - intermediate answer''. 
Subsequently, we employ a chain of calibration approach to enhance model's awareness of its internal knowledge, enabling more accurate decisions on retrieval necessity.
% 
In this way, our method can not only simplify the retrieval process but also allow for adaptive and accurate retrieval decisions based on internal knowledge for each subquery. 
% 
Furthermore, because all phases in the procedure rely solely on input data and answers without additional supervision, our method can calibrate LLM's knowledge boundaries in RAG scenarios using any supervised dataset. 


We conduct experiments on five open-domain QA to validate the effectiveness of DeepRAG, including HotpotQA, 2WikiMultihopQA, and PopQA for multi-hop factual QA, CAG for time-sensitive QA, and WebQuestions for heterogeneous knowledge base QA.
% 
Experiments show that DeepRAG can significantly improve both the accuracy and efficiency of retrieval-augmented generation.

In summary, the contributions are as follows:


% 1. 提出一种new方法that enhance RAG via 让模型自适应的决定检索的时机 in inference time.
% 2. 提出了一种自动化框架可以基于任何有监督数据集校准RAG场景下的self-awareness.
% 3. 实验效果导致accurate efficient by exploring konwledge boundary

\begin{itemize}
    \item We propose a new framework that enhances Retrieval-Augmented Generation by enabling LLMs to adaptively determine the necessity of retrieval during inference time, thereby improving both accuracy and efficiency.
    \item We introduce an automated framework that calibrates the self-awareness of LLMs in RAG scenarios that can be applied to any supervised dataset without additional supervision.
    \item Experimental on multi-hop QA, time-sensitive QA, and heterogeneous knowledge base QA confirm that DeepRAG can significantly enhance both the accuracy and efficiency of retrieval-augmented generation with great generalization ability by exploring their knowledge boundary.
\end{itemize}


\begin{figure*}[htbp]
    \centering
    \includegraphics[width=0.98\linewidth]{figure/srag.pdf}
    \caption{An overview of DeepRAG, our framework comprises three key components: (1) Binary Tree Search, (2) Imitation Learning, and (3) Chain of Calibration. Given a set of supervised datasets, we first employ binary tree search to synthesize data for imitation learning, enabling the model to learn retrieval patterns. Subsequently, we use binary tree search to construct preference data for further calibrating the LLM's awareness of its knowledge boundaries.}
    \label{fig:main}
\end{figure*}
