\section{Introduction}

% 大模型已经展现出remarkable能力。
% 然而，由于模型容量和能力的限制，模型经常生成错误信息
% 一个promising的方法来解决幻觉就是RAG
Large Language Models (LLMs) have demonstrated significant potential in reasoning~\cite{plaat2024reasoning}.
However, limited by the capacity and capabilities of LLM, it still suffers from severe factual hallucination problems due to the timeliness, accuracy, and coverage of parametric knowledge~\cite{zhang2023hallucination,huang2023survey}.
Retrieval-Augmented Generation (RAG) has been proposed as a promising paradigm to address this issue by integrating relevant information from knowledge bases or search engines, thereby improving the factuality of model response~\cite{zhao2024retrieval}.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.98\linewidth]{figure/fig1.pdf}
\caption{Correspondence between human thinking processes and DeepRAG.
Specifically, \textit{retrieval narrative} ensures a structured and adaptive retrieval flow, generating subqueries informed by previously retrieved information, and
\textit{atomic decisions} dynamically determines whether to retrieve external knowledge or rely solely on the parametric knowledge for each subquery.}

    \label{fig:comparison}
\end{figure}

% Unfortunately, 现有rag系统通常缺乏对推理能力的运用。
%     一方面，复杂的问题需要通过问题拆解来comprehensively解决，recent iterative方法已经展现了这个方法的有效性. 
%     however, llm suffer from generate aotmic and 明确的（没有指代关系的）subquries for more effective retrieval.
%     From rag view, 每次检索的内容应该基于question和已有信息来决定下一次检索的atmoic query。
% 另一方面，
%     检索并不是always有必要的, because 
%     1. 有的query需要知识而有的query只需要推理，
%     2. llm内部有庞大的知识，它不应该只做一个基于文档推理的工具
%     3. 不必要的检索会（引入noise，影响上下文效果，降低推理速度）


However, incorporating reasoning with retrieval-augmented generation still presents several challenges.
% 
One major issue is that complex queries often require multi-step decomposition to establish a coherent reasoning process~\cite{radhakrishnan2023question}. Iterative retrieval has been proposed as a solution to continuously update retrieval results to address the dynamic information needs that arise during the generation process~\cite{yue2024inference}. 
However, LLMs often struggle to generate atomic and precise subqueries, which are critical for more effective retrieval~\cite{wu2024divide}.
From the perspective of RAG, iterative retrieval should ideally generate the next atomic query based on the current question and the available information in an adaptive manner. 
% 
% Moreover, retrieval is not always necessary.
% Firstly, 有的query需要知识而有的query只需要推理.
% Secondely, LLMs have demonstrated the capability to serve as knowledge bases themselves~\cite{petroni-etal-2019-language}.
% % 
% 此外，Unnecessary retrieval potentially introduce noise, degrade generation capability, and 增加推理延迟~\cite{chen2023understanding,tan2024blinded,bian2024influence}. 
Moreover, retrieval is not always necessary. 
Some queries require knowledge, while others rely solely on reasoning within the LLM. 
Furthermore, LLMs have demonstrated their capability to serve as knowledge bases themselves~\cite{petroni-etal-2019-language}.
% 
Unnecessary retrieval, in addition to being redundant, can introduce noise, degrade generation quality, and increase inference latency~\cite{chen2023understanding,tan2024blinded,bian2024influence}.


To address this, 
inspired by the way humans search the Internet based on demand, we propose \textbf{DeepRAG}, a new framework designed to enhance reasoning ability in retrieval-augmented generation by modeling the process as a Markov Decision Process (MDP).
% 
The framework introduces two key components: \textit{retrieval narrative} and \textit{atomic decisions}, which together form a strategic and adaptive retrieval framework.
% 
As illustrated in Figure~\ref{fig:comparison}, \textit{retrieval narrative} ensures a structured and adaptive retrieval flow, generating subqueries informed by previously retrieved information. 
For each subquery, \textit{atomic decisions} dynamically determines whether to retrieve external knowledge or rely solely on the parametric knowledge of the LLM.
% 
To achieve this, we design a binary tree search method that explores the impact of \textit{atomic decisions} on reasoning outcomes.
% 
Based on it, we first synthesize data to the LLM to learn \textit{retrieval narrative}, capturing the pattern of ``subquery generation – \textit{atomic decision} – intermediate answer''  through imitation learning. 
% 
Subsequently, we employ a chain of calibration approach to refine the model's understanding of its own knowledge boundaries, enabling it to make more accurate \textit{atomic decisions} regarding the necessity of retrieval.
% 
By explicitly enhancing the LLM's ability to recognize its own knowledge boundaries, we can train an arbitrary model in an end-to-end manner, enabling it to dynamically determine when retrieval is necessary.

% Given a query, we first decompose it into several subqueries.
% Then, we aim for the model to autonomously decide whether retrieval is necessary for each subquery.
% % 
% However, LLMs often lack nuanced self-awareness of their knowledge boundaries, making it unreliable to depend solely on the model's output to determine the necessity of retrieval~\cite{yin2023large,ren2023investigating}. 
% % 
% To overcome this limitation, we aim to develop a method that helps models quickly calibrate their knowledge boundaries to enable adaptive retrieval.
% As illustrated in Figure~\ref{fig:main}, we develop a binary tree search method to identify the optimal path for determining whether retrieval is necessary for each subquery. 
% Based on it, we synthesize data to train the LLM on the pattern of ``subquery generation - retrieval decision - intermediate answer''. 
% Subsequently, we employ chain of calibration to enhance model's awareness of its parametric knowledge.
% % , enabling more accurate decisions on retrieval necessity.
% % 好处1
% In this way, our method can not only streamline the retrieval process but also enable adaptive and accurate retrieval decisions based on parametric knowledge for each subquery.
% % 好处2
% Furthermore, our method provides a method for autonomously synthesizing data for training a calibrated retrieval-augmented language model, which enables us to calibrate LLM's knowledge boundaries in RAG scenarios based on a supervised dataset.
% % using any existing dataset.

% we develop a method for autonomously synthesizing reasoning-based decision-making instructions in iterative retrieval and fine-tuned the latest open-source LLMs

% Therefore, we designed a binary tree search method to calibrate the model's perception of its knowledge boundaries. For each subquery, we explore the impact of retrieval on the reasoning process. 
% \Furthermore, because all phases in the procedure rely solely on input data and answers without additional supervision, our method can calibrate LLM's knowledge boundaries in RAG scenarios using any supervised dataset. 


We conduct experiments on five open-domain QA datasets to validate the effectiveness of DeepRAG, including HotpotQA, 2WikiMultihopQA, and PopQA for multi-hop factual QA, CAG for time-sensitive QA, and WebQuestions for heterogeneous knowledge base QA.
% 
Experimental results demonstrate that DeepRAG significantly outperforms existing methods, achieving 21.99\% higher answer accuracy while improving retrieval efficiency.
Further analysis reveals that DeepRAG exhibits a stronger correlation between its retrieval decisions and parametric knowledge, indicating more effective knowledge boundary calibration.
 
% In summary, the contributions are as follows:


% 1. 提出一种new方法that enhance RAG via 让模型自适应的决定检索的时机 in inference time.
% 2. 提出了一种自动化框架可以基于任何有监督数据集校准RAG场景下的self-awareness.
% 3. 实验效果导致accurate efficient by exploring konwledge boundary

% \begin{itemize}
%     \item We propose a new framework that enhances Retrieval-Augmented Generation by enabling LLMs to adaptively determine the necessity of retrieval during inference time, thereby improving both effectiveness and efficiency.
%     \item We introduce an automated framework that calibrates the self-awareness of LLMs in RAG scenarios that can be applied to any supervised dataset without additional supervision.
%     \item Experimental on multi-hop QA, time-sensitive QA, and heterogeneous knowledge base QA confirm that DeepRAG can significantly enhance both the effectiveness and efficiency of retrieval-augmented generation with great generalization ability by exploring their knowledge boundary.
% \end{itemize}


\begin{figure*}[htbp]
    \centering
    \includegraphics[width=0.98\linewidth]{figure/srag.pdf}
    \caption{An overview of DeepRAG, our framework comprises three steps: (1) Binary Tree Search, (2) Imitation Learning, and (3) Chain of Calibration. Given a dataset, we first employ binary tree search to synthesize data for imitation learning, enabling the model to learn retrieval patterns. Subsequently, we use binary tree search to construct preference data for further calibrating the LLM's awareness of its knowledge boundaries.}
    \label{fig:main}
\end{figure*}
