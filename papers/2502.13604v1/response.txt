\section{Related Works}
\subsection{LoRA and its variants}
As one of the parameter-efficient fine-tuning methods, LoRA**Kaplan et al., "Linear Learning Rate Multiplier for Deep Neural Networks"** has been widely adopted. However, it still has room for improvement in terms of accuracy.
Current enhancements follow two main pathways: optimizing initialization and refining the fine-tuning process. For initialization, methods like PiSSA**Wu et al., "Principal-Singular-Value-based LoRA Initialization"** and MiLoRA**Zhang et al., "Minor Singular Value Decomposition for Efficient Fine-Tuning"** use Singular Value Decomposition on base model weights, with PiSSA focusing on principal singular values and MiLoRA on minor ones for initializing LoRA before fine-tuning.
% To address this issue, current works primarily follow two pathways. The first pathway focuses on optimizing LoRA’s initialization, such as PiSSA**Wu et al., "Principal-Singular-Value-based LoRA Initialization"** and MiLoRA**Zhang et al., "Minor Singular Value Decomposition for Efficient Fine-Tuning"**. They apply Singular Value Decomposition to the weights of the base model. PiSSA utilizes the principle singular values, while MiLoRA uses the minor singular values for initializing LoRA before fine-tuning. 
For fine-tuning, DoRA**Kim et al., "Decoupling Optimization and Regularization in LoRA"** splits LoRA’s fine-tuning into magnitude and direction components. ReLoRA**Gupta et al., "Revisiting LoRA with Continual Fine-Tuning"** continuously merges the fine-tuned LoRA modules into the base model.  AdaLoRA**Li et al., "Adaptive LoRA for Improved Efficiency"** and IncreLoRA**Wang et al., "Incremental LoRA for Efficient Training"** optimize rank allocation across modules.
% , the former starts with a large rank and gradually prunes it, while the latter begins with a small rank and progressively increases it. 
Unlike these approaches, BeamLoRA revisits the foundational aspects of LoRA and recognizes the varying importance of ranks within a module. It compresses less important ranks to free up space for expanding the important ones, thereby allowing them to be better optimized.
\subsection{Model Pruning and Expansion}
Model pruning is typically used to remove redundant parameters in models, thereby improving efficiency**Srivastava et al., "Dropout: A Simple Way to Prevent Neural Networks from Overfitting"**. Unlike previous works, our primary goal for pruning is to free up space for expanding important parameters.
% Model pruning is typically used to remove redundant parameters in models, thereby improving efficiency**Srivastava et al., "Dropout: A Simple Way to Prevent Neural Networks from Overfitting"**. Unlike previous works, our primary goal for pruning is to free up space for expanding important parameters. 
% Model expansion can be categorized into two types: depth expansion and width expansion. Our approach is more aligned with the latter.
Model Width expansion is first introduced by Net2Net**Lin et al., "Network to Network"** and applied to CNNs. bert2BERT**Devlin et al., "Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding"** extends this method to the pre-training of language models, and the recent work Scaling Smart**Tay et al., "Scaling Smart"** applies width expansion to large scale base models. Unlike these approaches, we focus on parameter-efficient fine-tuning and propose compressing unimportant parameters within a limited space to expand important ones for better performance. Additionally, due to the shorter nature of the fine-tuning process than pre-training, we propose to use historical states to break symmetry in expansion, thereby ensuring fast convergence.