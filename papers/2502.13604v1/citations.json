[
  {
    "index": 0,
    "papers": [
      {
        "key": "DBLP:conf/iclr/HuSWALWWC22",
        "author": "Edward J. Hu and\nYelong Shen and\nPhillip Wallis and\nZeyuan Allen{-}Zhu and\nYuanzhi Li and\nShean Wang and\nLu Wang and\nWeizhu Chen",
        "title": "LoRA: Low-Rank Adaptation of Large Language Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "meng2024pissa",
        "author": "Fanxu Meng and Zhaohui Wang and Muhan Zhang",
        "title": "Pi{SSA}: Principal Singular Values and Singular Vectors Adaptation of Large Language Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wang2024miloraharnessingminorsingular",
        "author": "Hanqing Wang and Yixia Li and Shuo Wang and Guanhua Chen and Yun Chen",
        "title": "MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "meng2024pissa",
        "author": "Fanxu Meng and Zhaohui Wang and Muhan Zhang",
        "title": "Pi{SSA}: Principal Singular Values and Singular Vectors Adaptation of Large Language Models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "wang2024miloraharnessingminorsingular",
        "author": "Hanqing Wang and Yixia Li and Shuo Wang and Guanhua Chen and Yun Chen",
        "title": "MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "pmlr-v235-liu24bn",
        "author": "Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung",
        "title": "{D}o{RA}: Weight-Decomposed Low-Rank Adaptation"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "lialin2024relora",
        "author": "Vladislav Lialin and Sherin Muckatira and Namrata Shivagunde and Anna Rumshisky",
        "title": "ReLo{RA}: High-Rank Training Through Low-Rank Updates"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhang2023adaptive",
        "author": "Qingru Zhang and Minshuo Chen and Alexander Bukharin and Pengcheng He and Yu Cheng and Weizhu Chen and Tuo Zhao",
        "title": "Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning "
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "DBLP:journals/corr/abs-2308-12043",
        "author": "Feiyu Zhang and\nLiangzhi Li and\nJunhao Chen and\nZhouqiang Jiang and\nBowen Wang and\nYiming Qian",
        "title": "IncreLoRA: Incremental Parameter Allocation Method for Parameter-Efficient\nFine-tuning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "kurtic-etal-2022-optimal",
        "author": "Kurtic, Eldar and Campos, Daniel and Nguyen, Tuan and Frantar, Elias and Kurtz, Mark and Fineran, Benjamin and Goin, Michael and Alistarh, Dan",
        "title": "The Optimal {BERT} Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models"
      },
      {
        "key": "ma2023llmpruner",
        "author": "Xinyin Ma and Gongfan Fang and Xinchao Wang",
        "title": "{LLM}-Pruner: On the Structural Pruning of Large Language Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "kurtic-etal-2022-optimal",
        "author": "Kurtic, Eldar and Campos, Daniel and Nguyen, Tuan and Frantar, Elias and Kurtz, Mark and Fineran, Benjamin and Goin, Michael and Alistarh, Dan",
        "title": "The Optimal {BERT} Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models"
      },
      {
        "key": "ma2023llmpruner",
        "author": "Xinyin Ma and Gongfan Fang and Xinchao Wang",
        "title": "{LLM}-Pruner: On the Structural Pruning of Large Language Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "DBLP:journals/corr/ChenGS15",
        "author": "Tianqi Chen and\nIan J. Goodfellow and\nJonathon Shlens",
        "title": "Net2Net: Accelerating Learning via Knowledge Transfer"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "chen-etal-2022-bert2bert",
        "author": "Chen, Cheng and Yin, Yichun and Shang, Lifeng and Jiang, Xin and Qin, Yujia and Wang, Fengyu and Wang, Zhi and Chen, Xiao and Liu, Zhiyuan and Liu, Qun",
        "title": "bert2{BERT}: Towards Reusable Pretrained Language Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "DBLP:journals/corr/abs-2409-12903",
        "author": "Mohammad Samragh and\nSeyed{-}Iman Mirzadeh and\nKeivan Alizadeh{-}Vahid and\nFartash Faghri and\nMinsik Cho and\nMoin Nabi and\nDevang Naik and\nMehrdad Farajtabar",
        "title": "Scaling Smart: Accelerating Large Language Model Pre-training with\nSmall Model Initialization"
      }
    ]
  }
]