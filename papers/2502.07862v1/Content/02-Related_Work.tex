\section{Related Work}

% \iffalse
% \subsection{Dynamic Neural Networks} 
% Talk about neural networks that modify their characteristics based on an external input or characteristics of the input. Have a paragraph devoted to early-exit neural networks

% Early exit drawbacks: Early exit looks at if we can exit at one layer, we generate the entire set of pass or not at the beginning, so we know which layers are active. This can result in more efficient data batching, batch data that has same layer allocation and can be executed similarly. Can't do this with early exit.

% I can also propose dynamic batching, where we can batch data that has same layer allocation and can be executed similarly. Could also be a contribution

% \subsection{Reinforcement Learning Techniques}
% How has RL been used to solve this problem in the unimodal setting?


% \fi

\textbf{Early Exiting in Unimodal Networks.}
Early Exiting has been explored extensively in unimodal networks to improve inference efficiency~\cite{xin2020deebert, neurips2020_d4dd111a, meng2022adavit}. Methods like DeeBERT~\cite{xin2020deebert} and PABEE~\cite{neurips2020_d4dd111a} use confidence thresholds to halt computation for simpler inputs. However, these unimodal approaches fail to consider multimodal challenges such as QoI-aware resource allocation. Moreover, Early Exiting is incompatible with redistributing resources away from low-QoI modalities, as these low-confidence samples propagate through the entire network.



\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{Figures/ADMN_Architecture.png}
    \vspace{-0.2in}
    % \caption{\name architecture. Gray boxes indicate a dropped layer, blue indicates a frozen layer, and red indicates a tunable layer. TE: transformer encoder.}
\caption{\name architecture. \textcolor{gray}{[Gray box]}: dropped layer, \textcolor{blue}{[Blue box]}: frozen layer, \textcolor{red}{[Red box]}: tunable layer. TE: Transformer Encoder.}
    \label{fig:admn_architecture}
    \vspace{-0.1in}
\end{figure*}

\textbf{Dynamic Inference for Multimodal Systems.}
Multimodal networks traditionally rely on input-agnostic static provisioning, resulting in inefficiencies when modality QoI varies, and also incompatibility with dynamic computational resource availability. 
To enhance computational efficiency, dynamic networks have been proposed~\cite{xue2023dynamic, panda2021adamml, gao2020listen,cai2024ACF, mullapudi2018hydranets}. 
DynMM~\cite{xue2023dynamic} trains a set of expert networks representing different modality combinations, processing simple inputs with a subset of available modalities. 
AdaMML~\cite{panda2021adamml} and Listen to Look~\cite{gao2020listen} improve inference efficiency by leveraging multimodal information to eliminate temporal redundancy in videos. ACF~\cite{cai2024ACF} dynamically replaces certain modules with lightweight networks according to the input for greater efficiency in edge devices. 
Despite these advances, these existing methods (1) overlook significant QoI variations arising from input noise, (2) utilize or discard entire modalities without fine-grained control, and (3) fail to consider \emph{fixed} resource budgets. In contrast, \name allocates a fixed number of layers among modalities in a fine-grained manner according to input QoI, which accounts for both relative modality importance and noise.  



% Channel exchanging~\cite{wang2020deep} focuses on inter-modality interactions to enhance feature integration, emphasizing representation quality over computational savings. 
% E2E-VLP~\cite{xu2021e2e} improves robustness in noisy conditions via vision-language pretraining, indirectly boosting efficiency. 
% HydraNets~\cite{mullapudi2018hydranets} generalize dynamic architectures by adapting computation paths based on input complexity, offering foundational insights for multimodal systems. 

% Despite these advances, existing methods underutilize complementary and redundant information across modalities and fail to optimize backbone depth and layer allocation, limiting their applicability under stringent efficiency and robustness requirements. 
% In contrast, our work introduces a novel fidelity-aware mechanism that dynamically allocates computational resources to modality backbones, explicitly optimizing layer depth and resource distribution at the backbone level. Moreover, Early-Exit techniques reduce computation in the \emph{average case} and are not capable of meeting fixed compute budgets. 




% \textbf{Adaptive Computation in Vision Transformers.}
% Adaptive computation has been explored in Transformer architectures~\cite{wu2018blockdrop, meng2022adavit}. 
% BlockDrop utilizes reinforcement learning to dynamically select residual blocks, while AdaViT~\cite{meng2022adavit} employs lightweight decision networks to adaptively choose patches, attention heads, and layers within Vision Transformers. 
% Although these methods achieve high efficiency, they are designed for unimodal tasks and fail to address the unique challenges of multimodal networks, such as cross-modal interactions and dynamic resource allocation. 
% Our work builds upon these ideas, introducing adaptive mechanisms tailored for multimodal systems that optimize computation across both modalities and backbone layers, enabling efficient and robust cross-modal inference.



