\section{Discussion}

\textbf{Batched Inference:}
In \name, the layer allocation is decided by the controller prior to backbone execution, enabling support for batched inference. Classically, adaptive models cannot support batched inference as different samples will proceed through different layers. However, since \name decides the layer allocation at the controller, we can group samples into \emph{sub-batches} based on similar layer allocation. For instance, samples with high depth noise and low image noise will activate a similar set of layers, allowing them to be grouped together for batched execution.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Figures/LayerDrop_line.png}
    \vspace{-10pt}
    \caption{Effect of LayerDrop on 12-layer unimodal image and depth localization networks. ``No LD'' indicates no use of LayerDrop, ``LD FT'' indicates use only during finetuning, and finally ``LD Both'' employs LayerDrop in both phases}
    % \vspace{-10pt}
        \vspace{-0.2in}
    \label{fig:layerdrop_plot}
        % \vspace{-0.1in}
\end{figure}

\textbf{Fusion with Early Exit:}
While \name and unimodal Early-Exit methods tackle fundamentally different problems, the two techniques can be combined for further computation efficiency. \name's controller always allocates $L$ layers across all the modalities. However, on simple inputs, all $L$ layers may not be necessary, allowing for Early-Exit techniques to be integrated for further performance gains. 

% \textbf{Trade-off:}
% In scenarios with noisy input data, single-modal systems often require increased computational resources to extract reliable features, leading to higher computational costs. 
% In contrast, multimodal systems benefit from the inherent complementary and redundant information across modalities. 
% Our work dynamically adjusts computational resource allocation based on input fidelity and the interplay between modalities. 
% By leveraging reliable modalities and bypassing or downweighting noisy ones, our approach minimizes computational overhead while maintaining robust performance. 
% This adaptive strategy efficiently handles noisy inputs, ensuring both resource savings and feature extraction quality.



\section{Conclusion}

This paper proposes \name, a multimodal network capable of dynamically adjusting the number of active Transformer layers across modalities according to the quality of each sample's input modalities. Through this continuous reallocation, \name can match the accuracy of far larger networks while utilizing a fraction of their operations. Additionally, the dynamic backbones of \name are also well suited for scenarios with adaptive compute, ranging from heterogeneous deployment devices to fluctuating energy availability. We demonstrate the superiority of \name compared to other baselines across both classification and localization tasks. 


