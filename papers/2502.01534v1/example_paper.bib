@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@article{li2024crowdsourced,
  title={From Crowdsourced Data to High-Quality Benchmarks: Arena-Hard and BenchBuilder Pipeline},
  author={Li, Tianle and Chiang, Wei-Lin and Frick, Evan and Dunlap, Lisa and Wu, Tianhao and Zhu, Banghua and Gonzalez, Joseph E and Stoica, Ion},
  journal={arXiv preprint arXiv:2406.11939},
  year={2024}
}

@article{dubois2024length,
  title={Length-controlled alpacaeval: A simple way to debias automatic evaluators},
  author={Dubois, Yann and Galambosi, Bal{\'a}zs and Liang, Percy and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2404.04475},
  year={2024}
}

@misc{li2023alpacaeval,
  title={Alpacaeval: An automatic evaluator of instruction-following models},
  author={Li, Xuechen and Zhang, Tianyi and Dubois, Yann and Taori, Rohan and Gulrajani, Ishaan and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  year={2023}
}

@article{liu2023alignbench,
  title={Alignbench: Benchmarking chinese alignment of large language models},
  author={Liu, Xiao and Lei, Xuanyu and Wang, Shengyuan and Huang, Yue and Feng, Zhuoer and Wen, Bosi and Cheng, Jiale and Ke, Pei and Xu, Yifan and Tam, Weng Lam and others},
  journal={arXiv preprint arXiv:2311.18743},
  year={2023}
}

@inproceedings{zhang-etal-2024-self,
    title = "Self-Alignment for Factuality: Mitigating Hallucinations in {LLM}s via Self-Evaluation",
    author = "Zhang, Xiaoying  and
      Peng, Baolin  and
      Tian, Ye  and
      Zhou, Jingyan  and
      Jin, Lifeng  and
      Song, Linfeng  and
      Mi, Haitao  and
      Meng, Helen",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.107/",
    doi = "10.18653/v1/2024.acl-long.107",
    pages = "1946--1965",
    abstract = "Despite showing impressive abilities, large language models (LLMs) often struggle with factual inaccuracies, i.e., {\textquotedblright}hallucinations{\textquotedblright}, even when they hold relevant knowledge. To mitigate these hallucinations, current approaches typically necessitate high-quality human factuality annotations. In this work, we explore Self-Alignment for Factuality, where we leverage the self-evaluation capability of an LLM to provide training signals that steer the model towards factuality. Specifically, we incorporate Self-Eval, a self-evaluation component, to prompt an LLM to validate the factuality of its own generated responses solely based on its internal knowledge. Additionally, we design Self-Knowledge Tuning (SK-Tuning) to augment the LLM`s self-evaluation ability by improving the model`s confidence estimation and calibration. We then utilize these self-annotated responses to fine-tune the model via Direct Preference Optimization algorithm. We show that the proposed self-alignment approach substantially enhances factual accuracy over Llama family models across three key knowledge-intensive tasks on TruthfulQA and BioGEN."
}

@inproceedings{kasner-dusek-2024-beyond,
    title = "Beyond Traditional Benchmarks: Analyzing Behaviors of Open {LLM}s on Data-to-Text Generation",
    author = "Kasner, Zden{\v{e}}k  and
      Dusek, Ondrej",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.651/",
    doi = "10.18653/v1/2024.acl-long.651",
    pages = "12045--12072",
    abstract = "We analyze the behaviors of open large language models (LLMs) on the task of data-to-text (D2T) generation, i.e., generating coherent and relevant text from structured data. To avoid the issue of LLM training data contamination with standard benchmarks, we design Quintd - a tool for collecting novel structured data records from public APIs. We find that open LLMs (Llama 2, Mistral, and Zephyr) can generate fluent and coherent texts in zero-shot settings from data in common formats collected with Quintd. However, we show that the semantic accuracy of the outputs is a major issue: both according to human annotators and our reference-free metric based on GPT-4, more than 80{\%} of the outputs of open LLMs contain at least one semantic error. We publicly release the code, data, and model outputs."
}

@article{ye2024justice,
  title={Justice or prejudice? quantifying biases in llm-as-a-judge},
  author={Ye, Jiayi and Wang, Yanbo and Huang, Yue and Chen, Dongping and Zhang, Qihui and Moniz, Nuno and Gao, Tian and Geyer, Werner and Huang, Chao and Chen, Pin-Yu and others},
  journal={arXiv preprint arXiv:2410.02736},
  year={2024}
}

@article{koo2023benchmarking,
  title={Benchmarking cognitive biases in large language models as evaluators},
  author={Koo, Ryan and Lee, Minhwa and Raheja, Vipul and Park, Jong Inn and Kim, Zae Myung and Kang, Dongyeop},
  journal={arXiv preprint arXiv:2309.17012},
  year={2023}
}

@article{zhuge2024agent,
  title={Agent-as-a-judge: Evaluate agents with agents},
  author={Zhuge, Mingchen and Zhao, Changsheng and Ashley, Dylan and Wang, Wenyi and Khizbullin, Dmitrii and Xiong, Yunyang and Liu, Zechun and Chang, Ernie and Krishnamoorthi, Raghuraman and Tian, Yuandong and others},
  journal={arXiv preprint arXiv:2410.10934},
  year={2024}
}

@inproceedings{kim2023prometheus,
  title={Prometheus: Inducing fine-grained evaluation capability in language models},
  author={Kim, Seungone and Shin, Jamin and Cho, Yejin and Jang, Joel and Longpre, Shayne and Lee, Hwaran and Yun, Sangdoo and Shin, Seongjin and Kim, Sungdong and Thorne, James and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{kim2024prometheus,
  title={Prometheus 2: An open source language model specialized in evaluating other language models},
  author={Kim, Seungone and Suk, Juyoung and Longpre, Shayne and Lin, Bill Yuchen and Shin, Jamin and Welleck, Sean and Neubig, Graham and Lee, Moontae and Lee, Kyungjae and Seo, Minjoon},
  journal={arXiv preprint arXiv:2405.01535},
  year={2024}
}

@article{thakur2024judging,
  title={Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges},
  author={Thakur, Aman Singh and Choudhary, Kartik and Ramayapally, Venkat Srinik and Vaidyanathan, Sankaran and Hupkes, Dieuwke},
  journal={arXiv preprint arXiv:2406.12624},
  year={2024}
}

@article{chen2024humans,
  title={Humans or llms as the judge? a study on judgement biases},
  author={Chen, Guiming Hardy and Chen, Shunian and Liu, Ziche and Jiang, Feng and Wang, Benyou},
  journal={arXiv preprint arXiv:2402.10669},
  year={2024}
}

@inproceedings{10.1145/3658644.3690291,
author = {Shi, Jiawen and Yuan, Zenghui and Liu, Yinuo and Huang, Yue and Zhou, Pan and Sun, Lichao and Gong, Neil Zhenqiang},
title = {Optimization-based Prompt Injection Attack to LLM-as-a-Judge},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690291},
doi = {10.1145/3658644.3690291},
abstract = {LLM-as-a-Judge uses a large language model (LLM) to select the best response from a set of candidates for a given question. LLM-as-a-Judge has many applications such as LLM-powered search, reinforcement learning with AI feedback (RLAIF), and tool selection. In this work, we propose JudgeDeceiver, an optimization-based prompt injection attack to LLM-as-a-Judge. JudgeDeceiver injects a carefully crafted sequence into an attacker-controlled candidate response such that LLM-as-a-Judge selects the candidate response for an attacker-chosen question no matter what other candidate responses are. Specifically, we formulate finding such sequence as an optimization problem and propose a gradient based method to approximately solve it. Our extensive evaluation shows that JudgeDeceive is highly effective, and is much more effective than existing prompt injection attacks that manually craft the injected sequences and jailbreak attacks when extended to our problem. We also show the effectiveness of JudgeDeceiver in three case studies, i.e., LLM-powered search, RLAIF, and tool selection. Moreover, we consider defenses including known-answer detection, perplexity detection, and perplexity windowed detection. Our results show these defenses are insufficient, highlighting the urgent need for developing new defense strategies.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {660â€“674},
numpages = {15},
keywords = {large language model, llm-as-a-judge, prompt injection attack},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}



@article{liu2023agentbench,
  title={Agentbench: Evaluating llms as agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  journal={arXiv preprint arXiv:2308.03688},
  year={2023}
}

@inproceedings{huang2024position,
  title={Position: TrustLLM: Trustworthiness in large language models},
  author={Huang, Yue and Sun, Lichao and Wang, Haoran and Wu, Siyuan and Zhang, Qihui and Li, Yuan and Gao, Chujie and Huang, Yixin and Lyu, Wenhan and Zhang, Yixuan and others},
  booktitle={International Conference on Machine Learning},
  pages={20166--20270},
  year={2024},
  organization={PMLR}
}
@inproceedings{cui2024ultrafeedback,
  title={ULTRAFEEDBACK: Boosting Language Models with Scaled AI Feedback},
  author={Cui, Ganqu and Yuan, Lifan and Ding, Ning and Yao, Guanming and He, Bingxiang and Zhu, Wei and Ni, Yuan and Xie, Guotong and Xie, Ruobing and Lin, Yankai and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@inproceedings{lin2022truthfulqa,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3214--3252},
  year={2022}
}

@inproceedings{hu2023won,
  title={Wonâ€™t Get Fooled Again: Answering Questions with False Premises},
  author={Hu, Shengding and Luo, Yifan and Wang, Huadong and Cheng, Xingyi and Liu, Zhiyuan and Sun, Maosong},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={5626--5643},
  year={2023}
}

@article{xu2023wizardlm,
  title={Wizardlm: Empowering large language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  journal={arXiv preprint arXiv:2304.12244},
  year={2023}
}

@inproceedings{dodge2021documenting,
  title={Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus},
  author={Dodge, Jesse and Sap, Maarten and Marasovi{\'c}, Ana and Agnew, William and Ilharco, Gabriel and Groeneveld, Dirk and Mitchell, Margaret and Gardner, Matt},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={1286--1305},
  year={2021}
}

@inproceedings{deng2024investigating,
  title={Investigating Data Contamination in Modern Benchmarks for Large Language Models},
  author={Deng, Chunyuan and Zhao, Yilun and Tang, Xiangru and Gerstein, Mark and Cohan, Arman},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={8698--8711},
  year={2024}
}

@article{golchin2023time,
  title={Time travel in llms: Tracing data contamination in large language models},
  author={Golchin, Shahriar and Surdeanu, Mihai},
  journal={arXiv preprint arXiv:2308.08493},
  year={2023}
}

@article{dong2024generalization,
  title={Generalization or memorization: Data contamination and trustworthy evaluation for large language models},
  author={Dong, Yihong and Jiang, Xue and Liu, Huanyu and Jin, Zhi and Gu, Bin and Yang, Mengfei and Li, Ge},
  journal={arXiv preprint arXiv:2402.15938},
  year={2024}
}

@inproceedings{li2024open,
  title={An open-source data contamination report for large language models},
  author={Li, Yucheng and Guo, Yunhao and Guerin, Frank and Lin, Chenghua},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={528--541},
  year={2024}
}

@inproceedings{balloccu2024leak,
  title={Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs},
  author={Balloccu, Simone and Schmidtov{\'a}, Patr{\'\i}cia and Lango, Mateusz and Du{\v{s}}ek, Ond{\v{r}}ej},
  booktitle={Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={67--93},
  year={2024}
}

@article{deng2024unveiling,
  title={Unveiling the spectrum of data contamination in language models: A survey from detection to remediation},
  author={Deng, Chunyuan and Zhao, Yilun and Heng, Yuzhao and Li, Yitong and Cao, Jiannan and Tang, Xiangru and Cohan, Arman},
  journal={arXiv preprint arXiv:2406.14644},
  year={2024}
}

@article{jiang2024investigating,
  title={Investigating data contamination for pre-training language models},
  author={Jiang, Minhao and Liu, Ken Ziyu and Zhong, Ming and Schaeffer, Rylan and Ouyang, Siru and Han, Jiawei and Koyejo, Sanmi},
  journal={arXiv preprint arXiv:2401.06059},
  year={2024}
}

@article{yao2024data,
  title={Data Contamination Can Cross Language Barriers},
  author={Yao, Feng and Zhuang, Yufan and Sun, Zihao and Xu, Sunan and Kumar, Animesh and Shang, Jingbo},
  journal={arXiv preprint arXiv:2406.13236},
  year={2024}
}

@inproceedings{li2024task,
  title={Task contamination: Language models may not be few-shot anymore},
  author={Li, Changmao and Flanigan, Jeffrey},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  pages={18471--18480},
  year={2024}
}

@article{ni2024mixeval,
  title={MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures},
  author={Ni, Jinjie and Xue, Fuzhao and Yue, Xiang and Deng, Yuntian and Shah, Mahir and Jain, Kabir and Neubig, Graham and You, Yang},
  journal={arXiv preprint arXiv:2406.06565},
  year={2024}
}

@article{white2024livebench,
  title={Livebench: A challenging, contamination-free llm benchmark},
  author={White, Colin and Dooley, Samuel and Roberts, Manley and Pal, Arka and Feuer, Ben and Jain, Siddhartha and Shwartz-Ziv, Ravid and Jain, Neel and Saifullah, Khalid and Naidu, Siddartha and others},
  journal={arXiv preprint arXiv:2406.19314},
  year={2024}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{dong2024survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Chang, Baobao and others},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={1107--1128},
  year={2024}
}

@inproceedings{unieval,
  author       = {Ming Zhong and
                  Yang Liu and
                  Da Yin and
                  Yuning Mao and
                  Yizhu Jiao and
                  Pengfei Liu and
                  Chenguang Zhu and
                  Heng Ji and
                  Jiawei Han},
  editor       = {Yoav Goldberg and
                  Zornitsa Kozareva and
                  Yue Zhang},
  title        = {Towards a Unified Multi-Dimensional Evaluator for Text Generation},
  booktitle    = {Proceedings of the 2022 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
                  December 7-11, 2022},
  pages        = {2023--2038},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.emnlp-main.131},
  doi          = {10.18653/V1/2022.EMNLP-MAIN.131},
  timestamp    = {Tue, 23 Jul 2024 08:22:33 +0200},
  biburl       = {https://dblp.org/rec/conf/emnlp/Zhong0YMJLZJH22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{kopf2024openassistant,
  title={Openassistant conversations-democratizing large language model alignment},
  author={K{\"o}pf, Andreas and Kilcher, Yannic and von R{\"u}tte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi Rui and Stevens, Keith and Barhoum, Abdullah and Nguyen, Duc and Stanley, Oliver and Nagyfi, Rich{\'a}rd and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhou2024lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@Article{Sun2024MOSS,
  author   = {Sun, Tianxiang and Zhang, Xiaotian and He, Zhengfu and Li, Peng and Cheng, Qinyuan and Liu, Xiangyang and Yan, Hang and Shao, Yunfan and Tang, Qiong and Zhang, Shiduo and Zhao, Xingjian and Chen, Ke and Zheng, Yining and Zhou, Zhejian and Li, Ruixiao and Zhan, Jun and Zhou, Yunhua and Li, Linyang and Yang, Xiaogui and Wu, Lingling and Yin, Zhangyue and Huang, Xuanjing and Jiang, Yu-Gang and Qiu, Xipeng},
  journal  = {Machine Intelligence Research},
  title    = {MOSS: An Open Conversational Large Language Model},
  year     = {2024},
  issn     = {2731-5398},
  url      = {https://github.com/OpenMOSS/MOSS},
}

@article{duan2024uncovering,
  title={Uncovering Latent Memories: Assessing Data Leakage and Memorization Patterns in Large Language Models},
  author={Duan, Sunny and Khona, Mikail and Iyer, Abhiram and Schaeffer, Rylan and Fiete, Ila R},
  journal={arXiv preprint arXiv:2406.14549},
  year={2024}
}

@inproceedings{bordt2023elephants,
  title={Elephants Never Forget: Testing Language Models for Memorization of Tabular Data},
  author={Bordt, Sebastian and Nori, Harsha and Caruana, Rich},
  booktitle={NeurIPS 2023 Second Table Representation Learning Workshop},
  year={2024}
}

@article{panickssery2024llm,
  title={Llm evaluators recognize and favor their own generations},
  author={Panickssery, Arjun and Bowman, Samuel R and Feng, Shi},
  journal={arXiv preprint arXiv:2404.13076},
  year={2024}
}

@article{zhong2024law,
  title={Law of the weakest link: Cross capabilities of large language models},
  author={Zhong, Ming and Zhang, Aston and Wang, Xuewei and Hou, Rui and Xiong, Wenhan and Zhu, Chenguang and Chen, Zhengxing and Tan, Liang and Bi, Chloe and Lewis, Mike and others},
  journal={arXiv preprint arXiv:2409.19951},
  year={2024}
}

@article{achiam2023gpt,
 author = {Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
 journal = {ArXiv preprint},
 title = {Gpt-4 technical report},
 url = {https://arxiv.org/abs/2303.08774},
 volume = {abs/2303.08774},
 year = {2023}
}

@article{jaech2024openai,
  title={OpenAI o1 System Card},
  author={Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others},
  journal={arXiv preprint arXiv:2412.16720},
  year={2024}
}

@inproceedings{liu2016not,
 address = {Austin, Texas},
 author = {Liu, Chia-Wei  and
Lowe, Ryan  and
Serban, Iulian  and
Noseworthy, Mike  and
Charlin, Laurent  and
Pineau, Joelle},
 booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
 doi = {10.18653/v1/D16-1230},
 editor = {Su, Jian  and
Duh, Kevin  and
Carreras, Xavier},
 pages = {2122--2132},
 publisher = {Association for Computational Linguistics},
 title = {How {NOT} To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation},
 url = {https://aclanthology.org/D16-1230},
 year = {2016}
}

@article{reiter2018structured,
 address = {Cambridge, MA},
 author = {Reiter, Ehud},
 doi = {10.1162/coli_a_00322},
 journal = {Computational Linguistics},
 number = {3},
 pages = {393--401},
 publisher = {MIT Press},
 title = {A Structured Review of the Validity of {BLEU}},
 url = {https://aclanthology.org/J18-3002},
 volume = {44},
 year = {2018}
}

@article{li2024generation,
  title={From generation to judgment: Opportunities and challenges of llm-as-a-judge},
  author={Li, Dawei and Jiang, Bohan and Huang, Liangjie and Beigi, Alimohammad and Zhao, Chengshuai and Tan, Zhen and Bhattacharjee, Amrita and Jiang, Yuxuan and Chen, Canyu and Wu, Tianhao and others},
  journal={arXiv preprint arXiv:2411.16594},
  year={2024}
}

@article{yu2024kieval,
 author = {Yu, Zhuohao and Gao, Chang and Yao, Wenjin and Wang, Yidong and Ye, Wei and Wang, Jindong and Xie, Xing and Zhang, Yue and Zhang, Shikun},
 journal = {ArXiv preprint},
 title = {Kieval: A knowledge-grounded interactive evaluation framework for large language models},
 url = {https://arxiv.org/abs/2402.15043},
 volume = {abs/2402.15043},
 year = {2024}
}

@inproceedings{bai2024benchmarking,
 author = {Yushi Bai and
Jiahao Ying and
Yixin Cao and
Xin Lv and
Yuze He and
Xiaozhi Wang and
Jifan Yu and
Kaisheng Zeng and
Yijia Xiao and
Haozhe Lyu and
Jiayin Zhang and
Juanzi Li and
Lei Hou},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/BaiY0LHWYZXLZLH23.bib},
 booktitle = {Advances in Neural Information Processing Systems 36: Annual Conference
on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
LA, USA, December 10 - 16, 2023},
 editor = {Alice Oh and
Tristan Naumann and
Amir Globerson and
Kate Saenko and
Moritz Hardt and
Sergey Levine},
 timestamp = {Wed, 12 Jun 2024 01:00:00 +0200},
 title = {Benchmarking Foundation Models with Language-Model-as-an-Examiner},
 url = {http://papers.nips.cc/paper\_files/paper/2023/hash/f64e55d03e2fe61aa4114e49cb654acb-Abstract-Datasets\_and\_Benchmarks.html},
 year = {2023}
}

@inproceedings{tan2024large,
  title={Large language models for data annotation and synthesis: A survey},
  author={Tan, Zhen and Li, Dawei and Wang, Song and Beigi, Alimohammad and Jiang, Bohan and Bhattacharjee, Amrita and Karami, Mansooreh and Li, Jundong and Cheng, Lu and Liu, Huan},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={930--957},
  year={2024}
}

@article{shumailov2024ai,
  title={AI models collapse when trained on recursively generated data},
  author={Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Papernot, Nicolas and Anderson, Ross and Gal, Yarin},
  journal={Nature},
  volume={631},
  number={8022},
  pages={755--759},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{kaufman2012leakage,
  title={Leakage in data mining: Formulation, detection, and avoidance},
  author={Kaufman, Shachar and Rosset, Saharon and Perlich, Claudia and Stitelman, Ori},
  journal={ACM Transactions on Knowledge Discovery from Data (TKDD)},
  volume={6},
  number={4},
  pages={1--21},
  year={2012},
  publisher={ACM New York, NY, USA}
}

@inproceedings{elangovan2021memorization,
  title={Memorization vs. Generalization: Quantifying Data Leakage in NLP Performance Evaluation},
  author={Elangovan, Aparna and He, Jiayuan and Verspoor, Karin},
  booktitle={Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
  pages={1325--1335},
  year={2021}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@inproceedings{zhangbertscore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{lee2025distillation,
  title={Distillation Quantification for Large Language Models},
  author={Lee, Sunbowen and Zhou, Junting and Ao, Chang and Li, Kaige and Du, Xinrun and He, Sirui and Liu, Jiaheng and Yang, Min and Wen, Zhoufutu and Ni, Shiwen},
  journal={arXiv preprint arXiv:2501.12619},
  year={2025}
}

@article{wang2024bpo,
  title={Bpo: Towards balanced preference optimization between knowledge breadth and depth in alignment},
  author={Wang, Sizhe and Tong, Yongqi and Zhang, Hengyuan and Li, Dawei and Zhang, Xin and Chen, Tianlong},
  journal={arXiv preprint arXiv:2411.10914},
  year={2024}
}

@article{wu2024unigen,
  title={Unigen: A unified framework for textual dataset generation using large language models},
  author={Wu, Siyuan and Huang, Yue and Gao, Chujie and Chen, Dongping and Zhang, Qihui and Wan, Yao and Zhou, Tianyi and Zhang, Xiangliang and Gao, Jianfeng and Xiao, Chaowei and others},
  journal={arXiv preprint arXiv:2406.18966},
  year={2024}
}

@article{huang2023metatool,
  title={Metatool benchmark for large language models: Deciding whether to use tools and which to use},
  author={Huang, Yue and Shi, Jiawen and Li, Yuan and Fan, Chenrui and Wu, Siyuan and Zhang, Qihui and Liu, Yixin and Zhou, Pan and Wan, Yao and Gong, Neil Zhenqiang and others},
  journal={arXiv preprint arXiv:2310.03128},
  year={2023}
}

@inproceedings{zhang-etal-2024-llm,
    title = "{LLM}-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be Detected?",
    author = "Zhang, Qihui  and
      Gao, Chujie  and
      Chen, Dongping  and
      Huang, Yue  and
      Huang, Yixin  and
      Sun, Zhenyang  and
      Zhang, Shilin  and
      Li, Weiye  and
      Fu, Zhengyan  and
      Wan, Yao  and
      Sun, Lichao",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.29/",
    doi = "10.18653/v1/2024.findings-naacl.29",
    pages = "409--436",
    abstract = "With the rapid development and widespread application of Large Language Models (LLMs), the use of Machine-Generated Text (MGT) has become increasingly common, bringing with it potential risks, especially in terms of quality and integrity in fields like news, education, and science. Current research mainly focuses on purely MGT detection, without adequately addressing mixed scenarios including AI-revised Human-Written Text (HWT) or human-revised MGT. To tackle this challenge, we define mixtext, a form of mixed text involving both AI and human-generated content. Then we introduce MixSet, the first dataset dedicated to studying these mixtext scenarios. Leveraging MixSet, we executed comprehensive experiments to assess the efficacy of prevalent MGT detectors in handling mixtext situations, evaluating their performance in terms of effectiveness, robustness, and generalization. Our findings reveal that existing detectors struggle to identify mixtext, particularly in dealing with subtle modifications and style adaptability. This research underscores the urgent need for more fine-grain detectors tailored for mixtext, offering valuable insights for future research. Code and Models are available at https://github.com/Dongping-Chen/MixSet."
}

@article{zheng2024llamafactory,
  title={Llamafactory: Unified efficient fine-tuning of 100+ language models},
  author={Zheng, Yaowei and Zhang, Richong and Zhang, Junhao and Ye, Yanhan and Luo, Zheyan and Feng, Zhangchi and Ma, Yongqiang},
  journal={arXiv preprint arXiv:2403.13372},
  year={2024}
}

@article{yang2024qwen2,
  title={Qwen2. 5 Technical Report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@inproceedings{liumakes,
  title={What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning},
  author={Liu, Wei and Zeng, Weihao and He, Keqing and Jiang, Yong and He, Junxian},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{li2024selective,
  title={Selective reflection-tuning: Student-selected data recycling for llm instruction-tuning},
  author={Li, Ming and Chen, Lichang and Chen, Jiuhai and He, Shwai and Gu, Jiuxiang and Zhou, Tianyi},
  journal={arXiv preprint arXiv:2402.10110},
  year={2024}
}

@inproceedings{leerlaif,
  title={RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Mesnard, Thomas and Ferret, Johan and Lu, Kellie Ren and Bishop, Colton and Hall, Ethan and Carbune, Victor and Rastogi, Abhinav and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{li2024contextualization,
  title={Contextualization distillation from large language model for knowledge graph completion},
  author={Li, Dawei and Tan, Zhen and Chen, Tianlong and Liu, Huan},
  journal={arXiv preprint arXiv:2402.01729},
  year={2024}
}

@article{tong2024can,
  title={Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning},
  author={Tong, Yongqi and Li, Dawei and Wang, Sizhe and Wang, Yujia and Teng, Fei and Shang, Jingbo},
  journal={arXiv preprint arXiv:2403.20046},
  year={2024}
}

@article{li2024dalk,
  title={DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature},
  author={Li, Dawei and Yang, Shu and Tan, Zhen and Baik, Jae Young and Yun, Sunkwon and Lee, Joseph and Chacko, Aaron and Hou, Bojian and Duong-Tran, Duy and Ding, Ying and others},
  journal={arXiv preprint arXiv:2405.04819},
  year={2024}
}

@article{li2025exploring,
  title={Exploring large language models for feature selection: A data-centric perspective},
  author={Li, Dawei and Tan, Zhen and Liu, Huan},
  journal={ACM SIGKDD Explorations Newsletter},
  volume={26},
  number={2},
  pages={44--53},
  year={2025},
  publisher={ACM New York, NY, USA}
}

@article{jiang2024assessing,
  title={Assessing the Impact of Conspiracy Theories Using Large Language Models},
  author={Jiang, Bohan and Li, Dawei and Tan, Zhen and Zhou, Xinyi and Rao, Ashwin and Lerman, Kristina and Bernard, H Russell and Liu, Huan},
  journal={arXiv preprint arXiv:2412.07019},
  year={2024}
}

@article{zhang2024balancing,
  title={Balancing Speciality and Versatility: a Coarse to Fine Framework for Supervised Fine-tuning Large Language Model},
  author={Zhang, Hengyuan and Wu, Yanru and Li, Dawei and Yang, Zacc and Zhao, Rui and Jiang, Yong and Tan, Fei},
  journal={arXiv preprint arXiv:2404.10306},
  year={2024}
}

@article{zhang2024shifcon,
  title={Shifcon: Enhancing non-dominant language capabilities with a shift-based contrastive framework},
  author={Zhang, Hengyuan and Shang, Chenming and Wang, Sizhe and Zhang, Dongdong and Yao, Feng and Sun, Renliang and Yu, Yiyao and Yang, Yujiu and Wei, Furu},
  journal={arXiv preprint arXiv:2410.19453},
  year={2024}
}

@article{zhang2023assisting,
  title={Assisting language learners: Automated trans-lingual definition generation via contrastive prompt learning},
  author={Zhang, Hengyuan and Li, Dawei and Li, Yanran and Shang, Chenming and Shi, Chufan and Jiang, Yong},
  journal={arXiv preprint arXiv:2306.06058},
  year={2023}
}

@inproceedings{yang2023new,
  title={A New Dataset and Empirical Study for Sentence Simplification in Chinese},
  author={Yang, Shiping and Sun, Renliang and Wan, Xiaojun},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={8306--8321},
  year={2023}
}

@article{gao2023human,
  title={Human-like summarization evaluation with chatgpt},
  author={Gao, Mingqi and Ruan, Jie and Sun, Renliang and Yin, Xunjian and Yang, Shiping and Wan, Xiaojun},
  journal={arXiv preprint arXiv:2304.02554},
  year={2023}
}

@article{sun2024fostering,
  title={Fostering Natural Conversation in Large Language Models with NICO: a Natural Interactive COnversation dataset},
  author={Sun, Renliang and Liu, Mengyuan and Yang, Shiping and Wang, Rui and He, Junqing and Zhang, Jiaxing},
  journal={arXiv preprint arXiv:2408.09330},
  year={2024}
}

@article{gan2023ziya2,
  title={Ziya2: Data-centric Learning is All LLMs Need},
  author={Gan, Ruyi and Wu, Ziwei and Sun, Renliang and Lu, Junyu and Wu, Xiaojun and Zhang, Dixiang and Pan, Kunhao and Yang, Ping and Yang, Qi and Zhang, Jiaxing and others},
  journal={arXiv preprint arXiv:2311.03301},
  year={2023}
}

@inproceedings{dai2024bias,
  title={Bias and unfairness in information retrieval systems: New challenges in the llm era},
  author={Dai, Sunhao and Xu, Chen and Xu, Shicheng and Pang, Liang and Dong, Zhenhua and Xu, Jun},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={6437--6447},
  year={2024}
}