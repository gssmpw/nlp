We conduct extensive experiments to demonstrate the efficacy of various features of \former~to allow it to be trained with only one hour of data. We also present our findings in a way that highlights \formerâ€™s differences compared to common practices in NLP and CV, where Transformer training practices have been extensively studied~\cite{xiong2020layer, xu2021optimizing, loshchilov2024ngpt, chen2021empirical, liu2021efficient, gani2022how, steiner2022how}. 
Therefore, our experiment results also serve as a guideline on how to optimize Transformer training for robotics, particularly in off-road navigation and mobility tasks with complex vehicle-terrain interactions under data-scarce conditions. 

\former's one hour of training data comes from human-teleoperated demonstration of driving an open-source four-wheeled ground vehicle~\cite{datar2024wheeled} on a custom-built off-road testbed composed of hundreds of rocks and boulders. The demonstrator mostly aims to drive the robot to safely and stably traverse the vertically challenging terrain, but still occasionally encounters dangerous situations such as large roll angles and getting stuck between rocks. Fortunately, those situations serve as explorations for \former~to understand a wider range of kinodynamic interactions. 
Direct application of standard Transformer training methodologies in NLP and CV to such a small robotics dataset proves challenging due to the inherent lack of inductive bias in Transformers~\cite{dosovitskiy2021image}, which necessitates substantial amounts of data for effective training. However, our experiments suggest that \former's judicious modifications to established MM and NTP training paradigms can facilitate effective Transformer training even with limited robotics data. 

We conduct our experiments based on three perspectives: Section~\ref{sec:basic_perspective} provides an analysis of basic factors to train Transformers in general; Section~\ref{sec:robotic_perspective} analyzes the best practices to train Transformers when dealing with off-road robot mobility data; Finally, Sec.~\ref{sec:objective_perspective} evaluates the effectiveness of each off-road mobility learning objective and compares \encoder, \decoder, and non-Transformer end-to-end model performances. For fairness, all experiments are conducted with the same hyper-parameters. 

\subsection{Experiment Results of Basic Transformer Factors} \label{sec:basic_perspective}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.7\columnwidth]{figures/pos_encoding}
  \caption{\textbf{Positional Encoding:} Sinusoidal positional encoding achieves better model accuracy than learnable encoding for predicting $\mathbf{X}$, $\mathbf{Y}$, and $\mathbf{Z}$ components of the robot pose.}
  \label{fig:pos_encoding}
  % \vspace{-1.2em}
\end{figure}

\textbf{Positional encoding} is crucial for addressing the permutation equivariance of Transformers, which, by design, lacks inherent sensitivity to input sequence order. This characteristic necessitates the explicit provision of positional information to enable the model to effectively process sequential data. Learnable positional encodings, typically implemented as trainable vectors added to input embeddings, have found favor in CV applications~\cite{he2022masked}. Conversely, non-learnable encodings, such as the sinusoidal functions introduced in the seminal work by~\citet{vaswani2017attention}, have demonstrated efficacy in NLP tasks.
This divergence in methodological preference may stem from inherent differences in the statistical properties of data modalities. CV tasks often involve spatially structured data where absolute positional information may be less critical than relative relationships between local features. In such contexts, learnable encodings may offer greater flexibility in adapting to task-specific positional dependencies. Conversely, NLP tasks frequently rely on precise word order and long-range dependencies, where the fixed nature of non-learnable encodings may provide a beneficial inductive bias~\cite{weng2024navigating}.

To empirically investigate the relative merits of these approaches on robot mobility tasks, we conduct a comparative analysis of learnable positional encodings against sinusoidal encodings as shown in Fig.~\ref{fig:pos_encoding}. Our findings indicate that while both methods achieve comparable asymptotic performance levels, sinusoidal positional encodings exhibit a slight performance advantage.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.7\columnwidth]{figures/last_layernorm}
  \caption{\textbf{Normalizing Output:} Normalizing the \tr~output before passing the embeddings to the task decoder improves model performance.}
  \label{fig:last_layernorm}
  % \vspace{-1.2em}
\end{figure}
\textbf{Normalization layers}, such as LayerNorm~\cite{ba2016layer} or RMSNorm~\cite{zhang2019root}, have been shown to play a crucial role in stabilizing the training of Large Language Models (LLMs)~\cite{loshchilov2024ngpt}. By normalizing the activations of hidden units, these layers help to address issues such as vanishing/exploding gradients and improve the overall stability of the training process~\cite{xiong2020layer}. In this study, we investigate the impact of applying RMSNorm layer immediately before the task head.

Our experiment results, depicted in Fig.~\ref{fig:last_layernorm}, demonstrate an advantage for a model incorporating RMSNorm layer before the task head. This configuration consistently exhibits improved generalization performance and enhanced training stability compared to a model without the final RMSNorm. This finding suggests that normalizing the final embedding vector before passing it to the task head can benefit model performance, potentially by facilitating more effective gradient flow and thus improving the robustness of the model's predictions.


\subsection{Experiment Results from a Robotics Perspective} \label{sec:robotic_perspective}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\columnwidth]{figures/order_prediction}
  \caption{\textbf{Kinodynamics Understanding:} Without unified latent representation the model cannot capture temporal dependencies and understand kinodynamic transitions, resulting in an almost flat learning curve.}
  \label{fig:unified_state}
  % \vspace{-1.2em}
\end{figure}
\textbf{Unified latent space representation} offers a significant advantage in simultaneously addressing FKD, IKD, and BC. This unified approach facilitates a more holistic understanding of the robot's state and its interaction with the environment. To evaluate the efficacy of this unified representation, we perform a targeted ablation study. We train \coder~based on the objectives outlined by~\citet{nazeri2024vertiencoder} and augment them with additional objectives specifically designed to probe the model's capacity of kinodynamics understanding. 

A key component of this ablation involves the introduction of a sequence order prediction objective. This objective aims to assess whether the model can effectively discern the temporal evolution of robot and environment dynamics. During training, the model is presented with input sequences in two configurations: (1) 50\% of the time, the input sequence is presented in its natural temporal order; (2) the remaining 50\% of the time, the input sequence is randomly shuffled, disrupting the temporal coherence. The model is then tasked to classify whether an unseen sequence is presented in its original order or is shuffled, testing the model's ability to capture temporal dependencies and understand kinodynamic transitions.

As illustrated in Fig.~\ref{fig:unified_state}, our findings demonstrate a clear distinction in model performance based on the input representation. When the model is provided with separate, non-unified tokens, it exhibits a limited capacity of understanding the underlying kinodynamics and the learning loss barely drops. This suggests that processing information in a fragmented manner hinders the model's ability to capture temporal relationships and kinodynamic evolution, which is aligned with the findings by~\citet{zhou2024dinowm}. It may be possible to compensate by training with a larger dataset, which, however, is not always available in robotics.

Conversely, the utilization of a unified latent space representation significantly enhances the model's ability to discern temporal order and, consequently, understand the dynamics of the system. By consolidating relevant information into a single, cohesive representation, the model can effectively capture the interdependencies among different modalities and their evolution over time. This highlights the importance of a unified latent space representation in enabling robotic models to effectively learn and reason about complex dynamic systems when trained on limited data, in contrast to NLP and CV tasks where the data acquisition is easier.


\begin{figure}[h]
  \centering
  \includegraphics[width=1\columnwidth]{figures/steps_comparison}
  \caption{\textbf{Prediction Horizon:} \former~is capable of predicting a longer horizon without losing much accuracy due to its non-autoregressive nature.}
  \label{fig:pred_horizon}
  % \vspace{-1.2em}
\end{figure}
\textbf{Prediction horizon} is a critical factor in navigation planning. While longer prediction horizons can potentially lead to better planning by considering long-term effects, they also introduce greater uncertainty. This is because errors in early predictions can accumulate and lead to significant deviations in subsequent predictions. This issue is particularly relevant for autoregressive models such as the \vertidecoder~part of \former, where each prediction is based on the previous one. In such models, even a small error in the initial steps can propagate and amplify over time, causing the predicted trajectory to drift further away from the true path. To evaluate the impact of prediction horizon, we compare the performance of the autoregressive \vertidecoder~with the non-autoregressive \former, specifically focusing on their ability to maintain accuracy over long horizons. The results, shown in Fig.~\ref{fig:pred_horizon}, demonstrate that \former~is capable of predicting a longer horizon (two seconds) with less drift compared to its autoregressive counterpart even with a shorter horizon (one second). This highlights the advantage of non-autoregressive models in tasks requiring long-term prediction, as they are less susceptible to error accumulation.

\subsection{Experiment Results of Robotic Objective Functions} \label{sec:objective_perspective}
\begin{figure}[h]
  \centering
  \includegraphics[width=\columnwidth]{figures/patch_head}
  \caption{\textbf{Patch Prediction Head:} The inclusion of a patch reconstruction head results in a degradation of overall model performance. This counterintuitive result can be attributed to the inherent difficulty in accurately predicting the detailed structure of off-road terrain topography.}
  \label{fig:patch_head}
  % \vspace{-1.2em}
\end{figure}

\textbf{Patch prediction head}, as an auxiliary head to learn environment kinodynamics, was first introduced by~\citet{nazeri2024vertiencoder}. However, we find that the high complexity of off-road terrain topography and the potential presence of noise or occlusion within the input data create a challenging reconstruction task (see Fig.~\ref{fig:cover}). Consequently, the patch prediction head often generates inaccurate reconstructions, introducing noise into the learning process and negatively impacting the performance of the primary tasks, i.e., FKD, IKD, and BC. This suggests that the auxiliary task of patch reconstruction, in this specific domain, may introduce a conflicting learning signal that hinders the model's ability to effectively learn the desired representations for the main objectives (Fig.~\ref{fig:patch_head}).


\textbf{MM vs NTP vs End-to-End} (End2End) are currently the prominent approaches in CV, NLP, and robotics respectively. However, it is unclear what is the best approach for robot learning, especially learning off-road mobility. We present a comparative analysis of model performance utilizing the MM paradigm within an encoder architecture (\coder, Fig.~\ref{fig:former} left trained alone with MM), a decoder employing autoregressive NTP (\vertidecoder, Fig.~\ref{fig:former} right trained alone without cross-attention), and a non-Transformer-based End2End approach. We then further contrast these approaches with \former,  which adopts a non-autoregressive approach to NTP and MM (Fig.~\ref{fig:former}, trained end-to-end). 

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{figures/4model_comparison}
  \caption{\textbf{MM vs NTP  vs End2End:} \former~achieves best accuracy across FKD, IKD, and BC compared to \coder~(MM), \vertidecoder~(NTP), and End2End.}
  \label{fig:mm_vs_ntp}
  % \vspace{-1.2em}
\end{figure}

To be specific, an encoder model leverages the principles of MM, wherein portions of the input sequence (poses, actions, and terrain patches) are masked, and the model is trained to reconstruct the masked elements. This approach has demonstrated success in capturing contextual dependencies and learning robust representations~\cite{nazeri2024vertiencoder};
A decoder model employs NTP, a prevalent technique in autoregressive sequence generation. In this paradigm, the model predicts the subsequent element in a sequence conditioned on the preceding elements. For both encoder and decoder models, we use the same unified latent space representation presented in Sec.~\ref{sec:unified}. The specialized non-Transformer-based End2End approach uses Resnet-18~\cite{he2015deep} as a patch encoder and fully connected layers as the task heads. While more complex models might offer higher accuracy, we choose ResNet-18 to balance performance with the computational constraints of our robotic platform, making it well-suited for deployment on robots with limited on-board processing capabilities, compared to deeper networks like ResNet-50 or ResNet-101. More information about End2End model architecture is provided in Appendix~\ref{app:architecture}.


As illustrated in Fig.~\ref{fig:mm_vs_ntp}, our findings indicate that \former, a non-autoregressive Transformer, exhibits superior performance across various evaluation metrics, including FKD, IKD, and BC error rates, in the context of one-second prediction horizon. Compared to \vertidecoder, \former~predicts multiple future states simultaneously (i.e., non-autoregressively), which contributes to its better accuracy. These results suggest that the enhanced contextual awareness afforded by the non-autoregressive approach contributes to improved predictive accuracy. Note that \vertidecoder~cannot perform BC directly, as it has access to both action and pose at each step. Unlike \coder~\cite{nazeri2024vertiencoder}, \former~does not train different downstream heads separately each time and all tasks contribute to the performance of each other all together, which results in \former's lowest error rate in most cases (except for $\mathbf{Z}$ prediction). 
Across all kinodynamics tasks, End2End achieves the highest error rate, which shows the benefits of using Transformers for kinodynamic representation and understanding during off-road mobility tasks. 

Beyond the observed performance gains and training stability, \former~demonstrates the capacity of concurrent execution of multiple tasks, not only during training but also during inference. This is particularly relevant in robotics, where real-time control is required and sometimes some modalities may not be available during inference. For example, without a global planner, action sampler, or in the presence of sensor degradation, the robot may not always have access to desired future robot poses, candidate actions, or future terrain patches, respectively. 
Furthermore, the usage of a learned mask within the decoder part of \former~is posited to capture salient distributional characteristics of the data, effectively serving as a condensed representation during inference. This learned representation facilitates adaptation to new tasks where action or pose is missing.
