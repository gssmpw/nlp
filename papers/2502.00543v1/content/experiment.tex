We implement \former's FKD, IKD, and BC on an open-source Verti-4-Wheeler (V4W) ground robot platform. The experiments are carried out on a 4 m $\times$ 2.5 m testbed made of rocks/boulders, wooden planks, AstroTurf with crumpled cardboard boxes underneath, and modular 0.8 m $\times$ 0.75 m expanding foam to represent different types of vertically challenging terrain with different friction coefficients and varying deformability (Fig.~\ref{fig::test_env}). The modular foam and rocks/boulders do not deform, while the rocks may shift positions under the weight of the robot. On the other hand, the wooden planks and AstroTurf are completely deformable and change the terrain topography during wheel-terrain interactions. The one-hour training dataset used (see details of the dataset in Appendix~\ref{app:implementation}) only consists of robot teleoperation on the rigid rock/boulder testbed and hence the experiment testbed is an unseen environment, posing generalization challenges for \former. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.75\columnwidth]{figures/physical.jpeg}
    \caption{Unseen Test Environments with Rocks/Boulders, Wooden Planks, AstroTurf, and Expanding Foam. }
    \label{fig::test_env}
    \vspace{-1.2em}
\end{figure}

\subsection{Implementation and Metrics}

\subsubsection{FKD} \former's FKD task is integrated with the  MPPI planner~\cite{williams2017model} with 1000 samples and a horizon of 18 steps. We sample across a range of control sequences centered around the last optimal control sequence selected by the robot. The first three actions in a sampled control sequence are passed to \former~along with six past poses, actions, and terrain patches at 3 Hz consisting of one second. The model is repeated six times and outputs 18 future poses of the robot, which are combined to create one candidate trajectory. All 1000 candidate trajectories are then evaluated by a cost function, which calculates the cost of each trajectory based on the Euclidean distance to the goal and roll and pitch angles of the robot. Higher distance, roll, and pitch values are penalized with higher cost. Based on the cost function, MPPI outputs the best control sequence moving the robot forward at 3 Hz. The V4W executes the first action and replans.

\subsubsection{IKD} We integrate \former's IKD task with a global planner based on Dijkstra's algorithm~\cite{dijkstra1959note}, which minimizes traversability cost on a traversability map~\cite{pan2024traverse}. The global planner generates three desired future poses with the lowest cost and passes them to \former, which also has access to six past poses, actions, and terrain patches. \former~then produces three future actions to drive the robot to the three desired future poses. Similarly to FKD, the V4W executes the first action and then replans at 3 Hz. 

\subsubsection{BC} We implement \former's BC by passing in six past poses, actions, and terrain patches to \former. The model outputs three future actions to take. Similarly to FKD and IKD, the first action is executed by V4W and the replanning of BC runs at 3 Hz.

\input{content/experiments_table.tex}


For FKD and IKD, a trial is deemed successful if the robot reaches the defined goal without rolling over or getting stuck. For BC without explicit goal information, a trial is considered successful if the robot successfully traverses the entire testbed.

\subsection{Results and Discussions}

The results of the three methods are then compared to MPPI using TAL~\cite{datar2024terrainattentive}, a highly accurate forward kinodynamic model specifically designed for vertically challenging terrain. We report the success rate, average traversal time, and mean roll and pitch angles in Table~\ref{tab::robot_exp}.

Our observations reveal a nuanced performance difference between \coder~and \former, particularly concerning BC and IKD. \coder~excels in BC due to its specialized BC task head, a dedicated component trained specifically for this task. This specialized training allows \coder~to effectively leverage the provided data for imitation learning. In contrast, \former~approaches BC in a zero-shot manner. It is not explicitly trained on BC, relying instead on its modality masking strategy. This masking effectively handles missing modalities by replacing them with a trained mask, enabling the model to infer behavior without direct BC training. While this approach allows \former~to perform BC without specialized training, it also explains why \coder, with its dedicated head, achieves a higher success rate. A similar trend is observed with IKD. \coder~benefits from a specialized IKD head, again trained explicitly for this task. And \vertidecoder~has access to both predicted and actual actions and poses at each time step, providing richer guidance for the IKD process. This richer information stream in \vertidecoder~is the reason for achieving a higher success rate, especially considering the inherent difficulty of IKD compared to FKD. \former, however, faces a challenge in IKD and takes longer to finish the traversal.  The masking strategy, while effective for missing modality, is not as accurate as the actual modality.

Regarding FKD, the architectural difference between \former~and \coder~causes different navigation behaviors. \coder's specialized task head for FKD treats each future step independently without any attention weights between steps. While this approach facilitates faster MPPI initial convergence due to a lack of cross attention, it can also lead to drift, causing inconsistencies between predicted steps and ultimately resulting in a larger traversal time standard deviation across trials. While \coder's MPPI converges quickly, it struggles with long-term consistency. \former~takes a different approach. By employing attention and cross-attention mechanisms between historical and future steps, it dynamically incorporates past information into future predictions. This allows \former~to consider the historical context through cross-attention and causal masking when predicting future states, leading to more coherent and consistent predictions. Consequently, although MPPI might require more time to converge on a path with \former, once it does, the resulting behavior is more robust and less variable across trials, reflected in a smaller traversal time standard deviation.  The attention mechanism allows \former~to learn more complex temporal dependencies, which are crucial for accurate long-term prediction in FKD. 