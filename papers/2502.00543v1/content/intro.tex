Autonomous mobile robots deployed in off-road environments face significant challenges posed by the underlying terrain. 
For example, irregular terrain topographies featuring vertical protrusions from the ground pose extensive risks of vehicle rollover and immobilization~\cite{borges2022survey, lee2023learning, datar2024wheeled}. 
Off-road mobility challenges thus manifest in several critical ways: compromised stability, leading to potential rollover; increased wheel slippage, resulting in reduced traction and impaired locomotion; and the potential for mechanical damage to robots' chassis or drive systems.

Precisely understanding the vehicle-terrain kinodynamic interactions is the key to mitigating such mobility challenges posed by off-road terrain. Although data-driven approaches have shown promises in enabling off-road mobility in relatively flat environments~\cite{overbye2020fast, pan2020imitation, xiao2021learning, sivaprakasam2021improving, fan2021step, karnan2022vi, xiao2022motion, borges2022survey, dashora2022hybrid, triest2022tartandrive, sharma2023ramp, castro2023does, pokhrel2024cahsor, cai2024evora}, the intricate relationships between the robot chassis and vertically challenging terrain, e.g., suspension travel, tire deformation, changing normal and friction forces, and vehicle weight distribution and momentum, motivate the adoption of more sophisticated learning architectures to fully capture and represent the nuanced off-road kinodynamics~\cite{datar2024wheeled}. 

Transformers are the preferred architectures to understand complex relationships, which show promises in Natural Language Processing (NLP)~\cite{radford2018improving, devlin2019bert, radford2019language, brown2020language} and Computer Vision (CV)~\cite{he2022masked, feichtenhofer2022masked, geng2022multimodal, oquab2023dinov2, karypidis2024dinoforesight, patraucean2024trecvit} with self-supervised pre-training emerging as a dominant methodology. 
This trend is now extending to robotics, impacting areas such as manipulation~\cite{o2024open, du2023video, seo2023masked, seo2023multiview, hu2024video} and autonomous driving~\cite{hu2023gaia1, mao2023gptdriver, hu2024drivingworld, bar2024navigation, xiao2024anycar, mattamala2024wild, ai2023invariance}. In addition to the advent of the well-studied \tr~architecture~\cite{vaswani2017attention, dosovitskiy2021image}, this progress is largely attributable to the availability of large-scale datasets~\cite{o2024open, sun2020scalability, nuscenes}
as well as various Transformer training techniques including two primary pre-training paradigms: (i) Masked Modeling (MM) and (ii) autoregressive Next-Token Prediction (NTP)~\cite{chen2024next}. 

However, such benefits are not available nor suitable for off-road robot mobility yet. 
The application of these paradigms to robotics is particularly limited due to the inherent challenges associated with acquiring large-scale robotics datasets, 
especially when outdoor, off-road environments are involved for mobility tasks. Consequently, the effective utilization of data-intensive \tr~models to enable off-road mobility remains an open research question~\cite{firoozi2023foundation}. Further research is also required to investigate the adaptability of existing NLP and CV training paradigms to better suit the unique characteristics of off-road mobility data and tasks.


Motivated by these research gaps, this work presents \former, a novel data-efficient multi-task Transformer model for robot mobility on extremely rugged, vertically challenging, off-road terrain. 
Most notable among all of \former's unique features,  the novel unified latent representation of robot exteroception, proprioception, and action provides a stronger inductive bias and facilitates more effective learning from only one hour of data, compared to the existing practices of separate tokenization of different modalities and sole reliance on the self-attention mechanism to learn inter-modal correlations in NLP and CV with massive datasets. Furthermore, the non-autoregressive nature of \former~avoids error propagation from earlier to later prediction steps and makes \former~faster at inference because it does not require iterative queries for each step.
Additionally, \former's learnable mask enables various off-road mobility tasks within one model simultaneously without the need to retrain separate downstream tasks and mitigates the impact of missing modalities at inference time. 
\former~outperforms the navigation performance achieved by state-of-the-art kinodynamic modeling approaches specifically designed for vertically challenging terrain~\cite{datar2024terrainattentive}, providing empirical evidence supporting the feasibility of training \tr~models on limited robotic datasets using effective training strategies. We also investigate optimal methodologies for employing Transformers, encompassing both \encoder~and \decoder~parts, to facilitate effective learning from limited off-road mobility data. Our contributions can be summarized as follows: 


\begin{itemize}
    \item a Transformer architecture, \former, whose unified latent representation, learnable masked modeling, and  non-autoregressive nature simultaneously enable multiple off-road mobility tasks with one hour of data;
    \item a comprehensive evaluation of different Transformer designs, including MM, NTP, Encoder only, and Decoder only, for off-road kinodynamic representation; and
    \item physical on-robot experiments for different off-road mobility tasks on vertically challenging terrain.
\end{itemize}











