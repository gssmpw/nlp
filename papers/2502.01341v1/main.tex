
\documentclass{article}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs} %

\usepackage{hyperref}

\newcommand{\theHalgorithm}{\arabic{algorithm}}

%\usepackage{icml2025}
\usepackage[accepted]{icml2025}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\usepackage[capitalize,noabbrev]{cleveref}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}





\usepackage{adjustbox}
\usepackage{colortbl}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{array}
\usepackage{pifont}
\usepackage{float}

\newcommand{\bigdocs}{GIVE-ME-A-NAME}
\newcommand{\bigdocscpt}{GIVE-ME-A-NAME}

\definecolor{lightblue}{RGB}{232, 244, 248}

\definecolor{lightpink}{RGB}{254, 238, 237}

\definecolor{bluelink}{RGB}{0,113,188}
\definecolor{greenlink}{RGB}{0,188,113}

\newcommand{\fvisraw}{\mathbf{F}}
\newcommand{\fvis}{\mathbf{F}^\prime}
\newcommand{\falign}{\mathbf{F}_\text{align}^\prime}
\newcommand{\fmlp}{\mathbf{F}_\text{MLP}^\prime}
\newcommand{\fvet}{\mathbf{F}_\text{VET}^\prime}
\newcommand{\cmark}{\textcolor{green}{\ding{51}}}%
\newcommand{\xmark}{\textcolor{red}{\ding{55}}}%

\newcommand{\PT}[1]{\textcolor{purple}{[PT: #1]}}

\DeclareMathOperator{\softmax}{softmax}
\DeclareMathOperator{\layernorm}{LayerNorm}

\usepackage{marginnote}
\newcommand{\gella}[1]{\todo[color=blue!25] {SG: #1}}


\newcommand{\ourmodel}{{\textsc{AlignVLM}}}
\newcommand{\alignmodule}{{\textsc{Align}}}

 \newcommand{\Comma}{\textsuperscript{,}}

\usepackage{cleveref}


\icmltitlerunning{\ourmodel: Bridging Vision and Language Latent Spaces for Multimodal Understanding}

\begin{document}

\input{sections/0-titling}
\begin{abstract}
\input{sections/0-abstract}
\end{abstract}

\input{sections/1-introduction}
\input{sections/2-related}
\input{sections/3-methodology}
\input{sections/4-experiment}
\input{sections/5-results}
\input{sections/6-conclusion}
\input{sections/9-post}

\begin{thebibliography}{57}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdin et~al.(2024)Abdin, Aneja, Awadalla, Awadallah, Awan, Bach, Bahree, Bakhtiari, Bao, Behl, Benhaim, Bilenko, Bjorck, Bubeck, Cai, Cai, Chaudhary, Chen, Chen, Chen, Chen, Chen, Cheng, Chopra, Dai, Dixon, Eldan, Fragoso, Gao, Gao, Gao, Garg, Giorno, Goswami, Gunasekar, Haider, Hao, Hewett, Hu, Huynh, Iter, Jacobs, Javaheripi, Jin, Karampatziakis, Kauffmann, Khademi, Kim, Kim, Kurilenko, Lee, Lee, Li, Li, Liang, Liden, Lin, Lin, Liu, Liu, Liu, Liu, Liu, Luo, Madan, Mahmoudzadeh, Majercak, Mazzola, Mendes, Mitra, Modi, Nguyen, Norick, Patra, Perez-Becker, Portet, Pryzant, Qin, Radmilac, Ren, de~Rosa, Rosset, Roy, Ruwase, Saarikivi, Saied, Salim, Santacroce, Shah, Shang, Sharma, Shen, Shukla, Song, Tanaka, Tupini, Vaddamanu, Wang, Wang, Wang, Wang, Wang, Wang, Ward, Wen, Witte, Wu, Wu, Wyatt, Xiao, Xu, Xu, Xu, Xue, Yadav, Yang, Yang, Yang, Yang, Yu, Yuan, Zhang, Zhang, Zhang, Zhang, Zhang, Zhang, Zhang, and Zhou]{abdin2024phi3technicalreporthighly}
Abdin, M., Aneja, J., Awadalla, H., Awadallah, A., Awan, A.~A., Bach, N., Bahree, A., Bakhtiari, A., Bao, J., Behl, H., Benhaim, A., Bilenko, M., Bjorck, J., Bubeck, S., Cai, M., Cai, Q., Chaudhary, V., Chen, D., Chen, D., Chen, W., Chen, Y.-C., Chen, Y.-L., Cheng, H., Chopra, P., Dai, X., Dixon, M., Eldan, R., Fragoso, V., Gao, J., Gao, M., Gao, M., Garg, A., Giorno, A.~D., Goswami, A., Gunasekar, S., Haider, E., Hao, J., Hewett, R.~J., Hu, W., Huynh, J., Iter, D., Jacobs, S.~A., Javaheripi, M., Jin, X., Karampatziakis, N., Kauffmann, P., Khademi, M., Kim, D., Kim, Y.~J., Kurilenko, L., Lee, J.~R., Lee, Y.~T., Li, Y., Li, Y., Liang, C., Liden, L., Lin, X., Lin, Z., Liu, C., Liu, L., Liu, M., Liu, W., Liu, X., Luo, C., Madan, P., Mahmoudzadeh, A., Majercak, D., Mazzola, M., Mendes, C. C.~T., Mitra, A., Modi, H., Nguyen, A., Norick, B., Patra, B., Perez-Becker, D., Portet, T., Pryzant, R., Qin, H., Radmilac, M., Ren, L., de~Rosa, G., Rosset, C., Roy, S., Ruwase, O., Saarikivi, O., Saied, A., Salim, A.,
  Santacroce, M., Shah, S., Shang, N., Sharma, H., Shen, Y., Shukla, S., Song, X., Tanaka, M., Tupini, A., Vaddamanu, P., Wang, C., Wang, G., Wang, L., Wang, S., Wang, X., Wang, Y., Ward, R., Wen, W., Witte, P., Wu, H., Wu, X., Wyatt, M., Xiao, B., Xu, C., Xu, J., Xu, W., Xue, J., Yadav, S., Yang, F., Yang, J., Yang, Y., Yang, Z., Yu, D., Yuan, L., Zhang, C., Zhang, C., Zhang, J., Zhang, L.~L., Zhang, Y., Zhang, Y., Zhang, Y., and Zhou, X.
\newblock Phi-3 technical report: A highly capable language model locally on your phone, 2024.
\newblock URL \url{https://arxiv.org/abs/2404.14219}.

\bibitem[Achiam et~al.(2023)Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman, Almeida, Altenschmidt, Altman, Anadkat, et~al.]{gpt4}
Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F.~L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et~al.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Agrawal et~al.(2024)Agrawal, Antoniak, Hanna, Bout, Chaplot, Chudnovsky, Costa, Monicault, Garg, Gervet, Ghosh, Héliou, Jacob, Jiang, Khandelwal, Lacroix, Lample, Casas, Lavril, Scao, Lo, Marshall, Martin, Mensch, Muddireddy, Nemychnikova, Pellat, Platen, Raghuraman, Rozière, Sablayrolles, Saulnier, Sauvestre, Shang, Soletskyi, Stewart, Stock, Studnia, Subramanian, Vaze, Wang, and Yang]{agrawal2024pixtral12b}
Agrawal, P., Antoniak, S., Hanna, E.~B., Bout, B., Chaplot, D., Chudnovsky, J., Costa, D., Monicault, B.~D., Garg, S., Gervet, T., Ghosh, S., Héliou, A., Jacob, P., Jiang, A.~Q., Khandelwal, K., Lacroix, T., Lample, G., Casas, D.~L., Lavril, T., Scao, T.~L., Lo, A., Marshall, W., Martin, L., Mensch, A., Muddireddy, P., Nemychnikova, V., Pellat, M., Platen, P.~V., Raghuraman, N., Rozière, B., Sablayrolles, A., Saulnier, L., Sauvestre, R., Shang, W., Soletskyi, R., Stewart, L., Stock, P., Studnia, J., Subramanian, S., Vaze, S., Wang, T., and Yang, S.
\newblock Pixtral 12b, 2024.
\newblock URL \url{https://arxiv.org/abs/2410.07073}.

\bibitem[Alayrac et~al.(2022)Alayrac, Donahue, Luc, Miech, Barr, Hasson, Lenc, Mensch, Millican, Reynolds, Ring, Rutherford, Cabi, Han, Gong, Samangooei, Monteiro, Menick, Borgeaud, Brock, Nematzadeh, Sharifzadeh, Binkowski, Barreira, Vinyals, Zisserman, and Simonyan]{flamingo}
Alayrac, J.-B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A., Millican, K., Reynolds, M., Ring, R., Rutherford, E., Cabi, S., Han, T., Gong, Z., Samangooei, S., Monteiro, M., Menick, J., Borgeaud, S., Brock, A., Nematzadeh, A., Sharifzadeh, S., Binkowski, M., Barreira, R., Vinyals, O., Zisserman, A., and Simonyan, K.
\newblock Flamingo: a visual language model for few-shot learning, 2022.
\newblock URL \url{https://arxiv.org/abs/2204.14198}.

\bibitem[Aminabadi et~al.(2022)Aminabadi, Rajbhandari, Zhang, Awan, Li, Li, Zheng, Rasley, Smith, Ruwase, and He]{aminabadi2022deepspeedinferenceenablingefficient}
Aminabadi, R.~Y., Rajbhandari, S., Zhang, M., Awan, A.~A., Li, C., Li, D., Zheng, E., Rasley, J., Smith, S., Ruwase, O., and He, Y.
\newblock Deepspeed inference: Enabling efficient inference of transformer models at unprecedented scale, 2022.
\newblock URL \url{https://arxiv.org/abs/2207.00032}.

\bibitem[Anthropic(2024)]{anthropic2024claude}
Anthropic.
\newblock The claude 3 model family: Opus, sonnet, haiku.
\newblock 2024.

\bibitem[Beyer et~al.(2024)Beyer, Steiner, Pinto, Kolesnikov, Wang, Salz, Neumann, Alabdulmohsin, Tschannen, Bugliarello, Unterthiner, Keysers, Koppula, Liu, Grycner, Gritsenko, Houlsby, Kumar, Rong, Eisenschlos, Kabra, Bauer, Bošnjak, Chen, Minderer, Voigtlaender, Bica, Balazevic, Puigcerver, Papalampidi, Henaff, Xiong, Soricut, Harmsen, and Zhai]{beyer2024paligemmaversatile3bvlm}
Beyer, L., Steiner, A., Pinto, A.~S., Kolesnikov, A., Wang, X., Salz, D., Neumann, M., Alabdulmohsin, I., Tschannen, M., Bugliarello, E., Unterthiner, T., Keysers, D., Koppula, S., Liu, F., Grycner, A., Gritsenko, A., Houlsby, N., Kumar, M., Rong, K., Eisenschlos, J., Kabra, R., Bauer, M., Bošnjak, M., Chen, X., Minderer, M., Voigtlaender, P., Bica, I., Balazevic, I., Puigcerver, J., Papalampidi, P., Henaff, O., Xiong, X., Soricut, R., Harmsen, J., and Zhai, X.
\newblock Paligemma: A versatile 3b vlm for transfer, 2024.
\newblock URL \url{https://arxiv.org/abs/2407.07726}.

\bibitem[Bommasani et~al.(2023)Bommasani, Klyman, Longpre, Kapoor, Maslej, Xiong, Zhang, and Liang]{bommasani2023foundationmodeltransparencyindex}
Bommasani, R., Klyman, K., Longpre, S., Kapoor, S., Maslej, N., Xiong, B., Zhang, D., and Liang, P.
\newblock The foundation model transparency index, 2023.
\newblock URL \url{https://arxiv.org/abs/2310.12941}.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{gpt3}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Changpinyo et~al.(2021)Changpinyo, Sharma, Ding, and Soricut]{cc12m}
Changpinyo, S., Sharma, P., Ding, N., and Soricut, R.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts, 2021.
\newblock URL \url{https://arxiv.org/abs/2102.08981}.

\bibitem[Chen et~al.(2020)Chen, Wang, Chen, Zhang, Wang, Li, Zhou, and Wang]{Chen2020TabFact}
Chen, W., Wang, H., Chen, J., Zhang, Y., Wang, H., Li, S., Zhou, X., and Wang, W.~Y.
\newblock Tabfact: A large-scale dataset for table-based fact verification.
\newblock In \emph{International Conference Learning Representations}, 2020.

\bibitem[Chen et~al.(2024{\natexlab{a}})Chen, Wang, Tian, Ye, Gao, Cui, Tong, Hu, Luo, Ma, Ma, Wang, Dong, Yan, Guo, He, Shi, Jin, Xu, Wang, Wei, Li, Zhang, Zhang, Cai, Wen, Yan, Dou, Lu, Zhu, Lu, Lin, Qiao, Dai, and Wang]{chen2024fargpt4vclosinggap}
Chen, Z., Wang, W., Tian, H., Ye, S., Gao, Z., Cui, E., Tong, W., Hu, K., Luo, J., Ma, Z., Ma, J., Wang, J., Dong, X., Yan, H., Guo, H., He, C., Shi, B., Jin, Z., Xu, C., Wang, B., Wei, X., Li, W., Zhang, W., Zhang, B., Cai, P., Wen, L., Yan, X., Dou, M., Lu, L., Zhu, X., Lu, T., Lin, D., Qiao, Y., Dai, J., and Wang, W.
\newblock How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites, 2024{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2404.16821}.

\bibitem[Chen et~al.(2024{\natexlab{b}})Chen, Wu, Wang, Su, Chen, Xing, Zhong, Zhang, Zhu, Lu, et~al.]{chen2024internvl}
Chen, Z., Wu, J., Wang, W., Su, W., Chen, G., Xing, S., Zhong, M., Zhang, Q., Zhu, X., Lu, L., et~al.
\newblock Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  24185--24198, 2024{\natexlab{b}}.

\bibitem[Dai et~al.(2024)Dai, Lee, Wang, Yang, Liu, Barker, Rintamaki, Shoeybi, Catanzaro, and Ping]{dai2024nvlm}
Dai, W., Lee, N., Wang, B., Yang, Z., Liu, Z., Barker, J., Rintamaki, T., Shoeybi, M., Catanzaro, B., and Ping, W.
\newblock Nvlm: Open frontier-class multimodal llms.
\newblock \emph{arXiv preprint arXiv: 2409.11402}, 2024.

\bibitem[Diao et~al.(2024)Diao, Cui, Li, Wang, Lu, and Wang]{eve:diao2024unveiling}
Diao, H., Cui, Y., Li, X., Wang, Y., Lu, H., and Wang, X.
\newblock Unveiling encoder-free vision-language models.
\newblock \emph{arXiv preprint arXiv:2406.11832}, 2024.

\bibitem[Drouin et~al.(2024)Drouin, Gasse, Caccia, Laradji, Verme, Marty, Boisvert, Thakkar, Cappart, Vazquez, Chapados, and Lacoste]{drouin2024workarenacapablewebagents}
Drouin, A., Gasse, M., Caccia, M., Laradji, I.~H., Verme, M.~D., Marty, T., Boisvert, L., Thakkar, M., Cappart, Q., Vazquez, D., Chapados, N., and Lacoste, A.
\newblock Workarena: How capable are web agents at solving common knowledge work tasks?, 2024.
\newblock URL \url{https://arxiv.org/abs/2403.07718}.

\bibitem[Duan et~al.(2024)Duan, Yang, Qiao, Fang, Chen, Liu, Dong, Zang, Zhang, Wang, et~al.]{duan2024vlmevalkit}
Duan, H., Yang, J., Qiao, Y., Fang, X., Chen, L., Liu, Y., Dong, X., Zang, Y., Zhang, P., Wang, J., et~al.
\newblock Vlmevalkit: An open-source toolkit for evaluating large multi-modality models.
\newblock In \emph{Proceedings of the 32nd ACM International Conference on Multimedia}, pp.\  11198--11201, 2024.

\bibitem[Dubey et~al.(2024)Dubey, Jauhri, Pandey, Kadian, Al-Dahle, Letman, Mathur, Schelten, Yang, Fan, Goyal, Hartshorn, Yang, Mitra, Sravankumar, and et~al.]{dubey2024llama}
Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A., Yang, A., Fan, A., Goyal, A., Hartshorn, A., Yang, A., Mitra, A., Sravankumar, A., and et~al.
\newblock The llama 3 herd of models.
\newblock \emph{arXiv preprint arXiv:2407.21783}, 2024.

\bibitem[Grattafiori et~al.(2024)Grattafiori, Dubey, Jauhri, Pandey, Kadian, Al-Dahle, Letman, Mathur, Schelten, Vaughan, Yang, Fan, Goyal, Hartshorn, Yang, Mitra, Sravankumar, Korenev, Hinsvark, Rao, Zhang, Rodriguez, Gregerson, Spataru, Roziere, Biron, Tang, Chern, Caucheteux, Nayak, Bi, Marra, McConnell, Keller, Touret, Wu, Wong, Ferrer, Nikolaidis, Allonsius, Song, Pintz, Livshits, Wyatt, Esiobu, Choudhary, Mahajan, Garcia-Olano, Perino, Hupkes, Lakomkin, AlBadawy, Lobanova, Dinan, Smith, Radenovic, Guzmán, Zhang, Synnaeve, Lee, Anderson, Thattai, Nail, Mialon, Pang, Cucurell, Nguyen, Korevaar, Xu, Touvron, Zarov, Ibarra, Kloumann, Misra, Evtimov, Zhang, Copet, Lee, Geffert, Vranes, Park, Mahadeokar, Shah, van~der Linde, Billock, Hong, Lee, Fu, Chi, Huang, Liu, Wang, Yu, Bitton, Spisak, Park, Rocca, Johnstun, Saxe, Jia, Alwala, Prasad, Upasani, Plawiak, Li, Heafield, Stone, El-Arini, Iyer, Malik, Chiu, Bhalla, Lakhotia, Rantala-Yeary, van~der Maaten, Chen, Tan, Jenkins, Martin, Madaan, Malo, Blecher,
  Landzaat, de~Oliveira, Muzzi, Pasupuleti, Singh, Paluri, Kardas, Tsimpoukelli, Oldham, Rita, Pavlova, Kambadur, Lewis, Si, Singh, Hassan, Goyal, Torabi, Bashlykov, Bogoychev, Chatterji, Zhang, Duchenne, Çelebi, Alrassy, Zhang, Li, Vasic, Weng, Bhargava, Dubal, Krishnan, Koura, Xu, He, Dong, Srinivasan, Ganapathy, Calderer, Cabral, Stojnic, Raileanu, Maheswari, Girdhar, Patel, Sauvestre, Polidoro, Sumbaly, Taylor, Silva, Hou, Wang, Hosseini, Chennabasappa, Singh, Bell, Kim, Edunov, Nie, Narang, Raparthy, Shen, Wan, Bhosale, Zhang, Vandenhende, Batra, Whitman, Sootla, Collot, Gururangan, Borodinsky, Herman, Fowler, Sheasha, Georgiou, Scialom, Speckbacher, Mihaylov, Xiao, Karn, Goswami, Gupta, Ramanathan, Kerkez, Gonguet, Do, Vogeti, Albiero, Petrovic, Chu, Xiong, Fu, Meers, Martinet, Wang, Wang, Tan, Xia, Xie, Jia, Wang, Goldschlag, Gaur, Babaei, Wen, Song, Zhang, Li, Mao, Coudert, Yan, Chen, Papakipos, Singh, Srivastava, Jain, Kelsey, Shajnfeld, Gangidi, Victoria, Goldstand, Menon, Sharma, Boesenberg,
  Baevski, Feinstein, Kallet, Sangani, Teo, Yunus, Lupu, Alvarado, Caples, Gu, Ho, Poulton, Ryan, Ramchandani, Dong, Franco, Goyal, Saraf, Chowdhury, Gabriel, Bharambe, Eisenman, Yazdan, James, Maurer, Leonhardi, Huang, Loyd, Paola, Paranjape, Liu, Wu, Ni, Hancock, Wasti, Spence, Stojkovic, Gamido, Montalvo, Parker, Burton, Mejia, Liu, Wang, Kim, Zhou, Hu, Chu, Cai, Tindal, Feichtenhofer, Gao, Civin, Beaty, Kreymer, Li, Adkins, Xu, Testuggine, David, Parikh, Liskovich, Foss, Wang, Le, Holland, Dowling, Jamil, Montgomery, Presani, Hahn, Wood, Le, Brinkman, Arcaute, Dunbar, Smothers, Sun, Kreuk, Tian, Kokkinos, Ozgenel, Caggioni, Kanayet, Seide, Florez, Schwarz, Badeer, Swee, Halpern, Herman, Sizov, Guangyi, Zhang, Lakshminarayanan, Inan, Shojanazeri, Zou, Wang, Zha, Habeeb, Rudolph, Suk, Aspegren, Goldman, Zhan, Damlaj, Molybog, Tufanov, Leontiadis, Veliche, Gat, Weissman, Geboski, Kohli, Lam, Asher, Gaya, Marcus, Tang, Chan, Zhen, Reizenstein, Teboul, Zhong, Jin, Yang, Cummings, Carvill, Shepard, McPhie,
  Torres, Ginsburg, Wang, Wu, U, Saxena, Khandelwal, Zand, Matosich, Veeraraghavan, Michelena, Li, Jagadeesh, Huang, Chawla, Huang, Chen, Garg, A, Silva, Bell, Zhang, Guo, Yu, Moshkovich, Wehrstedt, Khabsa, Avalani, Bhatt, Mankus, Hasson, Lennie, Reso, Groshev, Naumov, Lathi, Keneally, Liu, Seltzer, Valko, Restrepo, Patel, Vyatskov, Samvelyan, Clark, Macey, Wang, Hermoso, Metanat, Rastegari, Bansal, Santhanam, Parks, White, Bawa, Singhal, Egebo, Usunier, Mehta, Laptev, Dong, Cheng, Chernoguz, Hart, Salpekar, Kalinli, Kent, Parekh, Saab, Balaji, Rittner, Bontrager, Roux, Dollar, Zvyagina, Ratanchandani, Yuvraj, Liang, Alao, Rodriguez, Ayub, Murthy, Nayani, Mitra, Parthasarathy, Li, Hogan, Battey, Wang, Howes, Rinott, Mehta, Siby, Bondu, Datta, Chugh, Hunt, Dhillon, Sidorov, Pan, Mahajan, Verma, Yamamoto, Ramaswamy, Lindsay, Lindsay, Feng, Lin, Zha, Patil, Shankar, Zhang, Zhang, Wang, Agarwal, Sajuyigbe, Chintala, Max, Chen, Kehoe, Satterfield, Govindaprasad, Gupta, Deng, Cho, Virk, Subramanian, Choudhury,
  Goldman, Remez, Glaser, Best, Koehler, Robinson, Li, Zhang, Matthews, Chou, Shaked, Vontimitta, Ajayi, Montanez, Mohan, Kumar, Mangla, Ionescu, Poenaru, Mihailescu, Ivanov, Li, Wang, Jiang, Bouaziz, Constable, Tang, Wu, Wang, Wu, Gao, Kleinman, Chen, Hu, Jia, Qi, Li, Zhang, Zhang, Adi, Nam, Yu, Wang, Zhao, Hao, Qian, Li, He, Rait, DeVito, Rosnbrick, Wen, Yang, Zhao, and Ma]{llama3}
Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A., Vaughan, A., Yang, A., Fan, A., Goyal, A., Hartshorn, A., Yang, A., Mitra, A., Sravankumar, A., Korenev, A., Hinsvark, A., Rao, A., Zhang, A., Rodriguez, A., Gregerson, A., Spataru, A., Roziere, B., Biron, B., Tang, B., Chern, B., Caucheteux, C., Nayak, C., Bi, C., Marra, C., McConnell, C., Keller, C., Touret, C., Wu, C., Wong, C., Ferrer, C.~C., Nikolaidis, C., Allonsius, D., Song, D., Pintz, D., Livshits, D., Wyatt, D., Esiobu, D., Choudhary, D., Mahajan, D., Garcia-Olano, D., Perino, D., Hupkes, D., Lakomkin, E., AlBadawy, E., Lobanova, E., Dinan, E., Smith, E.~M., Radenovic, F., Guzmán, F., Zhang, F., Synnaeve, G., Lee, G., Anderson, G.~L., Thattai, G., Nail, G., Mialon, G., Pang, G., Cucurell, G., Nguyen, H., Korevaar, H., Xu, H., Touvron, H., Zarov, I., Ibarra, I.~A., Kloumann, I., Misra, I., Evtimov, I., Zhang, J., Copet, J., Lee, J., Geffert, J., Vranes, J., Park, J., Mahadeokar, J.,
  Shah, J., van~der Linde, J., Billock, J., Hong, J., Lee, J., Fu, J., Chi, J., Huang, J., Liu, J., Wang, J., Yu, J., Bitton, J., Spisak, J., Park, J., Rocca, J., Johnstun, J., Saxe, J., Jia, J., Alwala, K.~V., Prasad, K., Upasani, K., Plawiak, K., Li, K., Heafield, K., Stone, K., El-Arini, K., Iyer, K., Malik, K., Chiu, K., Bhalla, K., Lakhotia, K., Rantala-Yeary, L., van~der Maaten, L., Chen, L., Tan, L., Jenkins, L., Martin, L., Madaan, L., Malo, L., Blecher, L., Landzaat, L., de~Oliveira, L., Muzzi, M., Pasupuleti, M., Singh, M., Paluri, M., Kardas, M., Tsimpoukelli, M., Oldham, M., Rita, M., Pavlova, M., Kambadur, M., Lewis, M., Si, M., Singh, M.~K., Hassan, M., Goyal, N., Torabi, N., Bashlykov, N., Bogoychev, N., Chatterji, N., Zhang, N., Duchenne, O., Çelebi, O., Alrassy, P., Zhang, P., Li, P., Vasic, P., Weng, P., Bhargava, P., Dubal, P., Krishnan, P., Koura, P.~S., Xu, P., He, Q., Dong, Q., Srinivasan, R., Ganapathy, R., Calderer, R., Cabral, R.~S., Stojnic, R., Raileanu, R., Maheswari, R., Girdhar,
  R., Patel, R., Sauvestre, R., Polidoro, R., Sumbaly, R., Taylor, R., Silva, R., Hou, R., Wang, R., Hosseini, S., Chennabasappa, S., Singh, S., Bell, S., Kim, S.~S., Edunov, S., Nie, S., Narang, S., Raparthy, S., Shen, S., Wan, S., Bhosale, S., Zhang, S., Vandenhende, S., Batra, S., Whitman, S., Sootla, S., Collot, S., Gururangan, S., Borodinsky, S., Herman, T., Fowler, T., Sheasha, T., Georgiou, T., Scialom, T., Speckbacher, T., Mihaylov, T., Xiao, T., Karn, U., Goswami, V., Gupta, V., Ramanathan, V., Kerkez, V., Gonguet, V., Do, V., Vogeti, V., Albiero, V., Petrovic, V., Chu, W., Xiong, W., Fu, W., Meers, W., Martinet, X., Wang, X., Wang, X., Tan, X.~E., Xia, X., Xie, X., Jia, X., Wang, X., Goldschlag, Y., Gaur, Y., Babaei, Y., Wen, Y., Song, Y., Zhang, Y., Li, Y., Mao, Y., Coudert, Z.~D., Yan, Z., Chen, Z., Papakipos, Z., Singh, A., Srivastava, A., Jain, A., Kelsey, A., Shajnfeld, A., Gangidi, A., Victoria, A., Goldstand, A., Menon, A., Sharma, A., Boesenberg, A., Baevski, A., Feinstein, A., Kallet, A.,
  Sangani, A., Teo, A., Yunus, A., Lupu, A., Alvarado, A., Caples, A., Gu, A., Ho, A., Poulton, A., Ryan, A., Ramchandani, A., Dong, A., Franco, A., Goyal, A., Saraf, A., Chowdhury, A., Gabriel, A., Bharambe, A., Eisenman, A., Yazdan, A., James, B., Maurer, B., Leonhardi, B., Huang, B., Loyd, B., Paola, B.~D., Paranjape, B., Liu, B., Wu, B., Ni, B., Hancock, B., Wasti, B., Spence, B., Stojkovic, B., Gamido, B., Montalvo, B., Parker, C., Burton, C., Mejia, C., Liu, C., Wang, C., Kim, C., Zhou, C., Hu, C., Chu, C.-H., Cai, C., Tindal, C., Feichtenhofer, C., Gao, C., Civin, D., Beaty, D., Kreymer, D., Li, D., Adkins, D., Xu, D., Testuggine, D., David, D., Parikh, D., Liskovich, D., Foss, D., Wang, D., Le, D., Holland, D., Dowling, E., Jamil, E., Montgomery, E., Presani, E., Hahn, E., Wood, E., Le, E.-T., Brinkman, E., Arcaute, E., Dunbar, E., Smothers, E., Sun, F., Kreuk, F., Tian, F., Kokkinos, F., Ozgenel, F., Caggioni, F., Kanayet, F., Seide, F., Florez, G.~M., Schwarz, G., Badeer, G., Swee, G., Halpern, G.,
  Herman, G., Sizov, G., Guangyi, Zhang, Lakshminarayanan, G., Inan, H., Shojanazeri, H., Zou, H., Wang, H., Zha, H., Habeeb, H., Rudolph, H., Suk, H., Aspegren, H., Goldman, H., Zhan, H., Damlaj, I., Molybog, I., Tufanov, I., Leontiadis, I., Veliche, I.-E., Gat, I., Weissman, J., Geboski, J., Kohli, J., Lam, J., Asher, J., Gaya, J.-B., Marcus, J., Tang, J., Chan, J., Zhen, J., Reizenstein, J., Teboul, J., Zhong, J., Jin, J., Yang, J., Cummings, J., Carvill, J., Shepard, J., McPhie, J., Torres, J., Ginsburg, J., Wang, J., Wu, K., U, K.~H., Saxena, K., Khandelwal, K., Zand, K., Matosich, K., Veeraraghavan, K., Michelena, K., Li, K., Jagadeesh, K., Huang, K., Chawla, K., Huang, K., Chen, L., Garg, L., A, L., Silva, L., Bell, L., Zhang, L., Guo, L., Yu, L., Moshkovich, L., Wehrstedt, L., Khabsa, M., Avalani, M., Bhatt, M., Mankus, M., Hasson, M., Lennie, M., Reso, M., Groshev, M., Naumov, M., Lathi, M., Keneally, M., Liu, M., Seltzer, M.~L., Valko, M., Restrepo, M., Patel, M., Vyatskov, M., Samvelyan, M., Clark,
  M., Macey, M., Wang, M., Hermoso, M.~J., Metanat, M., Rastegari, M., Bansal, M., Santhanam, N., Parks, N., White, N., Bawa, N., Singhal, N., Egebo, N., Usunier, N., Mehta, N., Laptev, N.~P., Dong, N., Cheng, N., Chernoguz, O., Hart, O., Salpekar, O., Kalinli, O., Kent, P., Parekh, P., Saab, P., Balaji, P., Rittner, P., Bontrager, P., Roux, P., Dollar, P., Zvyagina, P., Ratanchandani, P., Yuvraj, P., Liang, Q., Alao, R., Rodriguez, R., Ayub, R., Murthy, R., Nayani, R., Mitra, R., Parthasarathy, R., Li, R., Hogan, R., Battey, R., Wang, R., Howes, R., Rinott, R., Mehta, S., Siby, S., Bondu, S.~J., Datta, S., Chugh, S., Hunt, S., Dhillon, S., Sidorov, S., Pan, S., Mahajan, S., Verma, S., Yamamoto, S., Ramaswamy, S., Lindsay, S., Lindsay, S., Feng, S., Lin, S., Zha, S.~C., Patil, S., Shankar, S., Zhang, S., Zhang, S., Wang, S., Agarwal, S., Sajuyigbe, S., Chintala, S., Max, S., Chen, S., Kehoe, S., Satterfield, S., Govindaprasad, S., Gupta, S., Deng, S., Cho, S., Virk, S., Subramanian, S., Choudhury, S.,
  Goldman, S., Remez, T., Glaser, T., Best, T., Koehler, T., Robinson, T., Li, T., Zhang, T., Matthews, T., Chou, T., Shaked, T., Vontimitta, V., Ajayi, V., Montanez, V., Mohan, V., Kumar, V.~S., Mangla, V., Ionescu, V., Poenaru, V., Mihailescu, V.~T., Ivanov, V., Li, W., Wang, W., Jiang, W., Bouaziz, W., Constable, W., Tang, X., Wu, X., Wang, X., Wu, X., Gao, X., Kleinman, Y., Chen, Y., Hu, Y., Jia, Y., Qi, Y., Li, Y., Zhang, Y., Zhang, Y., Adi, Y., Nam, Y., Yu, Wang, Zhao, Y., Hao, Y., Qian, Y., Li, Y., He, Y., Rait, Z., DeVito, Z., Rosnbrick, Z., Wen, Z., Yang, Z., Zhao, Z., and Ma, Z.
\newblock The llama 3 herd of models, 2024.
\newblock URL \url{https://arxiv.org/abs/2407.21783}.

\bibitem[Hu et~al.(2024)Hu, Xu, Ye, Yan, Zhang, Zhang, Li, Zhang, Jin, Huang, and Zhou]{hu2024mplugdocowl15unifiedstructure}
Hu, A., Xu, H., Ye, J., Yan, M., Zhang, L., Zhang, B., Li, C., Zhang, J., Jin, Q., Huang, F., and Zhou, J.
\newblock mplug-docowl 1.5: Unified structure learning for ocr-free document understanding, 2024.
\newblock URL \url{https://arxiv.org/abs/2403.12895}.

\bibitem[Jaume et~al.(2019)Jaume, Ekenel, and Thiran]{funsd}
Jaume, G., Ekenel, H.~K., and Thiran, J.-P.
\newblock Funsd: A dataset for form understanding in noisy scanned documents, 2019.
\newblock URL \url{https://arxiv.org/abs/1905.13538}.

\bibitem[Kim et~al.(2022)Kim, Hong, Yim, Nam, Park, Yim, Hwang, Yun, Han, and Park]{donut}
Kim, G., Hong, T., Yim, M., Nam, J., Park, J., Yim, J., Hwang, W., Yun, S., Han, D., and Park, S.
\newblock Ocr-free document understanding transformer, 2022.
\newblock URL \url{https://arxiv.org/abs/2111.15664}.

\bibitem[Kim et~al.(2024)Kim, Yim, and Song]{kim2024tablevqa}
Kim, Y., Yim, M., and Song, K.~Y.
\newblock Tablevqa-bench: A visual question answering benchmark on multiple table domains.
\newblock \emph{arXiv preprint arXiv:2404.19205}, 2024.

\bibitem[Laurençon et~al.(2024)Laurençon, Tronchon, Cord, and Sanh]{idefics2}
Laurençon, H., Tronchon, L., Cord, M., and Sanh, V.
\newblock What matters when building vision-language models?, 2024.
\newblock URL \url{https://arxiv.org/abs/2405.02246}.

\bibitem[Lee et~al.(2023)Lee, Joshi, Turc, Hu, Liu, Eisenschlos, Khandelwal, Shaw, Chang, and Toutanova]{pix2struct}
Lee, K., Joshi, M., Turc, I., Hu, H., Liu, F., Eisenschlos, J., Khandelwal, U., Shaw, P., Chang, M.-W., and Toutanova, K.
\newblock Pix2struct: Screenshot parsing as pretraining for visual language understanding, 2023.
\newblock URL \url{https://arxiv.org/abs/2210.03347}.

\bibitem[Li et~al.(2024)Li, Zhang, Guo, Zhang, Li, Zhang, Zhang, Zhang, Li, Liu, and Li]{llavaonevision}
Li, B., Zhang, Y., Guo, D., Zhang, R., Li, F., Zhang, H., Zhang, K., Zhang, P., Li, Y., Liu, Z., and Li, C.
\newblock Llava-onevision: Easy visual task transfer, 2024.
\newblock URL \url{https://arxiv.org/abs/2408.03326}.

\bibitem[Li et~al.(2023)Li, Li, Savarese, and Hoi]{blip2}
Li, J., Li, D., Savarese, S., and Hoi, S.
\newblock Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models, 2023.
\newblock URL \url{https://arxiv.org/abs/2301.12597}.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Li, Li, and Lee]{liu2023improvedllava}
Liu, H., Li, C., Li, Y., and Lee, Y.~J.
\newblock Improved baselines with visual instruction tuning, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Li, Wu, and Lee]{liu2023llava}
Liu, H., Li, C., Wu, Q., and Lee, Y.~J.
\newblock Visual instruction tuning, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2024)Liu, Li, Li, Li, Zhang, Shen, and Lee]{liu2024llavanext}
Liu, H., Li, C., Li, Y., Li, B., Zhang, Y., Shen, S., and Lee, Y.~J.
\newblock Llava-next: Improved reasoning, ocr, and world knowledge, January 2024.
\newblock URL \url{https://llava-vl.github.io/blog/2024-01-30-llava-next/}.

\bibitem[Lu et~al.(2024)Lu, Li, Chen, Xu, Luo, Zhang, and Ye]{ovis}
Lu, S., Li, Y., Chen, Q.-G., Xu, Z., Luo, W., Zhang, K., and Ye, H.-J.
\newblock Ovis: Structural embedding alignment for multimodal large language model, 2024.
\newblock URL \url{https://arxiv.org/abs/2405.20797}.

\bibitem[Masry et~al.(2022)Masry, Long, Tan, Joty, and Hoque]{masry2022chartqa}
Masry, A., Long, D.~X., Tan, J.~Q., Joty, S., and Hoque, E.
\newblock Chartqa: A benchmark for question answering about charts with visual and logical reasoning.
\newblock \emph{arXiv preprint arXiv:2203.10244}, 2022.

\bibitem[Mathew et~al.(2021{\natexlab{a}})Mathew, Bagal, Tito, Karatzas, Valveny, and Jawahar]{mathew2021infographicvqa}
Mathew, M., Bagal, V., Tito, R.~P., Karatzas, D., Valveny, E., and Jawahar, C.~V.
\newblock Infographicvqa, 2021{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2104.12756}.

\bibitem[Mathew et~al.(2021{\natexlab{b}})Mathew, Karatzas, and Jawahar]{docvqa}
Mathew, M., Karatzas, D., and Jawahar, C.~V.
\newblock Docvqa: A dataset for vqa on document images, 2021{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2007.00398}.

\bibitem[OpenAI et~al.(2023)OpenAI, Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman, Almeida, Altenschmidt, Altman, Anadkat, Avila, Babuschkin, Balaji, Balcom, Baltescu, Bao, Bavarian, Belgum, Bello, et~al.]{openai2023gpt4}
OpenAI, Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F.~L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., Avila, R., Babuschkin, I., Balaji, S., Balcom, V., Baltescu, P., Bao, H., Bavarian, M., Belgum, J., Bello, I., et~al.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv: 2303.08774}, 2023.

\bibitem[Park et~al.(2019)Park, Shin, Lee, Lee, Surh, Seo, and Lee]{park2019cord}
Park, S., Shin, S., Lee, B., Lee, J., Surh, J., Seo, M., and Lee, H.
\newblock Cord: A consolidated receipt dataset for post-ocr parsing.
\newblock \emph{Document Intelligence Workshop at Neural Information Processing Systems}, 2019.

\bibitem[Pasupat \& Liang(2015)Pasupat and Liang]{pasupat2015compositional}
Pasupat, P. and Liang, P.
\newblock Compositional semantic parsing on semi-structured tables.
\newblock In \emph{Annual Meeting of the Association for Computational Linguistics}, 2015.

\bibitem[Qwen et~al.(2025)Qwen, :, Yang, Yang, Zhang, Hui, Zheng, Yu, Li, Liu, Huang, Wei, Lin, Yang, Tu, Zhang, Yang, Yang, Zhou, Lin, Dang, Lu, Bao, Yang, Yu, Li, Xue, Zhang, Zhu, Men, Lin, Li, Tang, Xia, Ren, Ren, Fan, Su, Zhang, Wan, Liu, Cui, Zhang, and Qiu]{qwen2025qwen25technicalreport}
Qwen, :, Yang, A., Yang, B., Zhang, B., Hui, B., Zheng, B., Yu, B., Li, C., Liu, D., Huang, F., Wei, H., Lin, H., Yang, J., Tu, J., Zhang, J., Yang, J., Yang, J., Zhou, J., Lin, J., Dang, K., Lu, K., Bao, K., Yang, K., Yu, L., Li, M., Xue, M., Zhang, P., Zhu, Q., Men, R., Lin, R., Li, T., Tang, T., Xia, T., Ren, X., Ren, X., Fan, Y., Su, Y., Zhang, Y., Wan, Y., Liu, Y., Cui, Z., Zhang, Z., and Qiu, Z.
\newblock Qwen2.5 technical report, 2025.
\newblock URL \url{https://arxiv.org/abs/2412.15115}.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, Krueger, and Sutskever]{radford2021learningtransferablevisualmodels}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., and Sutskever, I.
\newblock Learning transferable visual models from natural language supervision, 2021.
\newblock URL \url{https://arxiv.org/abs/2103.00020}.

\bibitem[Raffel et~al.(2023)Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li, and Liu]{t5}
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P.~J.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer, 2023.
\newblock URL \url{https://arxiv.org/abs/1910.10683}.

\bibitem[Rodriguez et~al.(2024{\natexlab{a}})Rodriguez, Jian, Panigrahi, Zhang, Feizi, Puri, Kalkunte, Savard, Masry, Nayak, Awal, Massoud, Abaskohi, Li, Wang, Noël, Richter, Vadacchino, Agarwal, Biswas, Shanian, Zhang, Bolger, MacDonald, Fauvel, Tejaswi, Sunkara, Monteiro, Dvijotham, Scholak, Chapados, Kharagani, Hughes, Özsu, Reddy, Pedersoli, Bengio, Pal, Laradji, Gella, Taslakian, Vazquez, and Rajeswar]{bigdocs}
Rodriguez, J., Jian, X., Panigrahi, S.~S., Zhang, T., Feizi, A., Puri, A., Kalkunte, A., Savard, F., Masry, A., Nayak, S., Awal, R., Massoud, M., Abaskohi, A., Li, Z., Wang, S., Noël, P.-A., Richter, M.~L., Vadacchino, S., Agarwal, S., Biswas, S., Shanian, S., Zhang, Y., Bolger, N., MacDonald, K., Fauvel, S., Tejaswi, S., Sunkara, S., Monteiro, J., Dvijotham, K.~D., Scholak, T., Chapados, N., Kharagani, S., Hughes, S., Özsu, M., Reddy, S., Pedersoli, M., Bengio, Y., Pal, C., Laradji, I., Gella, S., Taslakian, P., Vazquez, D., and Rajeswar, S.
\newblock Bigdocs: An open and permissively-licensed dataset for training multimodal models on document and code tasks, 2024{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2412.04626}.

\bibitem[Rodriguez et~al.(2022)Rodriguez, Vazquez, Laradji, Pedersoli, and Rodriguez]{rodriguez2022ocrvqgan}
Rodriguez, J.~A., Vazquez, D., Laradji, I., Pedersoli, M., and Rodriguez, P.
\newblock Ocr-vqgan: Taming text-within-image generation, 2022.
\newblock URL \url{https://arxiv.org/abs/2210.11248}.

\bibitem[Rodriguez et~al.(2024{\natexlab{b}})Rodriguez, Puri, Agarwal, Laradji, Rodriguez, Rajeswar, Vazquez, Pal, and Pedersoli]{rodriguez2024starvector}
Rodriguez, J.~A., Puri, A., Agarwal, S., Laradji, I.~H., Rodriguez, P., Rajeswar, S., Vazquez, D., Pal, C., and Pedersoli, M.
\newblock Starvector: Generating scalable vector graphics code from images and text, 2024{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2312.11556}.

\bibitem[Singh et~al.(2019)Singh, Natarajan, Shah, Jiang, Chen, Batra, Parikh, and Rohrbach]{singh2019towards}
Singh, A., Natarajan, V., Shah, M., Jiang, Y., Chen, X., Batra, D., Parikh, D., and Rohrbach, M.
\newblock Towards vqa models that can read.
\newblock In \emph{IEEE Conference Computer Vision Pattern Recognition}, 2019.

\bibitem[Stanis{\l}awek et~al.(2021)Stanis{\l}awek, Grali{\'n}ski, Wr{\'o}blewska, Lipi{\'n}ski, Kaliska, Rosalska, Topolski, and Biecek]{stanislawek2021kleister}
Stanis{\l}awek, T., Grali{\'n}ski, F., Wr{\'o}blewska, A., Lipi{\'n}ski, D., Kaliska, A., Rosalska, P., Topolski, B., and Biecek, P.
\newblock Kleister: key information extraction datasets involving long documents with complex layouts.
\newblock In \emph{International Conference on Document Analysis and Recognition}, 2021.

\bibitem[Svetlichnaya(2020)]{svetlichnaya2020deepform}
Svetlichnaya, S.
\newblock Deepform: Understand structured documents at scale, 2020.

\bibitem[Team(2024)]{geminiteam2024geminifamilyhighlycapable}
Team, G.
\newblock Gemini: A family of highly capable multimodal models, 2024.
\newblock URL \url{https://arxiv.org/abs/2312.11805}.

\bibitem[Vogus \& Llansóe(2021)Vogus and Llansóe]{caitlin2021}
Vogus, C. and Llansóe, E.
\newblock Making transparency meaningful: A framework for policymakers.
\newblock \emph{Center for Democracy and Technology}, 2021.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Raman, Sibue, Ma, Babkin, Kaur, Pei, Nourbakhsh, and Liu]{wang2023docllmlayoutawaregenerativelanguage}
Wang, D., Raman, N., Sibue, M., Ma, Z., Babkin, P., Kaur, S., Pei, Y., Nourbakhsh, A., and Liu, X.
\newblock Docllm: A layout-aware generative language model for multimodal document understanding, 2023{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2401.00908}.

\bibitem[Wang et~al.(2024)Wang, Bai, Tan, Wang, Fan, Bai, Chen, Liu, Wang, Ge, Fan, Dang, Du, Ren, Men, Liu, Zhou, Zhou, and Lin]{wang2024qwen2vlenhancingvisionlanguagemodels}
Wang, P., Bai, S., Tan, S., Wang, S., Fan, Z., Bai, J., Chen, K., Liu, X., Wang, J., Ge, W., Fan, Y., Dang, K., Du, M., Ren, X., Men, R., Liu, D., Zhou, C., Zhou, J., and Lin, J.
\newblock Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution, 2024.
\newblock URL \url{https://arxiv.org/abs/2409.12191}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Lv, Yu, Hong, Qi, Wang, Ji, Yang, Zhao, Song, et~al.]{cogvlm:wang2023}
Wang, W., Lv, Q., Yu, W., Hong, W., Qi, J., Wang, Y., Ji, J., Yang, Z., Zhao, L., Song, X., et~al.
\newblock Cogvlm: Visual expert for pretrained language models.
\newblock \emph{arXiv preprint arXiv:2311.03079}, 2023{\natexlab{b}}.

\bibitem[Wu et~al.(2024{\natexlab{a}})Wu, Chen, Wu, Ma, Liu, Pan, Liu, Xie, Yu, Ruan, and Luo]{wu2024janusdecouplingvisualencoding}
Wu, C., Chen, X., Wu, Z., Ma, Y., Liu, X., Pan, Z., Liu, W., Xie, Z., Yu, X., Ruan, C., and Luo, P.
\newblock Janus: Decoupling visual encoding for unified multimodal understanding and generation, 2024{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2410.13848}.

\bibitem[Wu et~al.(2024{\natexlab{b}})Wu, Chen, Pan, Liu, Liu, Dai, Gao, Ma, Wu, Wang, Xie, Wu, Hu, Wang, Sun, Li, Piao, Guan, Liu, Xie, You, Dong, Yu, Zhang, Zhao, Wang, and Ruan]{wu2024deepseekvl2mixtureofexpertsvisionlanguagemodels}
Wu, Z., Chen, X., Pan, Z., Liu, X., Liu, W., Dai, D., Gao, H., Ma, Y., Wu, C., Wang, B., Xie, Z., Wu, Y., Hu, K., Wang, J., Sun, Y., Li, Y., Piao, Y., Guan, K., Liu, A., Xie, X., You, Y., Dong, K., Yu, X., Zhang, H., Zhao, L., Wang, Y., and Ruan, C.
\newblock Deepseek-vl2: Mixture-of-experts vision-language models for advanced multimodal understanding, 2024{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2412.10302}.

\bibitem[Xu et~al.(2024)Xu, Yao, Guo, Cui, Ni, Ge, Chua, Liu, Sun, and Huang]{xu2024llavauhd}
Xu, R., Yao, Y., Guo, Z., Cui, J., Ni, Z., Ge, C., Chua, T.-S., Liu, Z., Sun, M., and Huang, G.
\newblock Llava-uhd: an lmm perceiving any aspect ratio and high-resolution images.
\newblock \emph{European Conference on Computer Vision}, 2024.
\newblock \doi{10.48550/arXiv.2403.11703}.

\bibitem[Zhai et~al.(2023)Zhai, Mustafa, Kolesnikov, and Beyer]{zhai2023sigmoidlosslanguageimage}
Zhai, X., Mustafa, B., Kolesnikov, A., and Beyer, L.
\newblock Sigmoid loss for language image pre-training, 2023.
\newblock URL \url{https://arxiv.org/abs/2303.15343}.

\bibitem[Zhang et~al.(2024)Zhang, Wang, Li, Zhang, Taslakian, Rajeswar, Fu, Liu, and Bengio]{zhang2024vcr}
Zhang, T., Wang, S., Li, L., Zhang, G., Taslakian, P., Rajeswar, S., Fu, J., Liu, B., and Bengio, Y.
\newblock Vcr: Visual caption restoration.
\newblock \emph{arXiv preprint arXiv: 2406.06462}, 2024.

\bibitem[Zhao et~al.(2024)Zhao, Huang, Hu, Wang, Mao, Zhang, Jiang, Wu, Ai, Wang, Zhou, and Chen]{zhao2024swiftascalablelightweightinfrastructure}
Zhao, Y., Huang, J., Hu, J., Wang, X., Mao, Y., Zhang, D., Jiang, Z., Wu, Z., Ai, B., Wang, A., Zhou, W., and Chen, Y.
\newblock Swift:a scalable lightweight infrastructure for fine-tuning, 2024.
\newblock URL \url{https://arxiv.org/abs/2408.05517}.

\end{thebibliography}


\newpage\clearpage
\appendix
\onecolumn
\input{sections/a-appendix}

\end{document}
