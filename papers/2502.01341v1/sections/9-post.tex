
\section*{Impact Statement}
This work contributes to the multimodal AI research community by introducing a novel approach for fusing vision and language modalities within large language models. By leveraging our framework in the context of generative models, we enable more effective integration of visual and textual information, enhancing the generative models' ability to generate free-form text for multimodal tasks. However, like all generative models, our approach is subject to potential biases and hallucinationsâ€”challenges inherent to large language models that must be carefully considered in deployment. Since these issues are not unique to our approach, we do not highlight any specific concerns here.
