\begin{table*}[t]
\centering
\caption{\textbf{Impact of Connector Designs on VLM Performance:} We present the results of experiments evaluating different connector designs for conditioning LLMs on visual features. Our proposed \textbf{\alignmodule} connector is compared against a basic Multi-Layer Perceptron (\textbf{MLP}), the \textbf{Perceiver Resampler}, and \textbf{Ovis}. The results demonstrate that \alignmodule{} consistently outperforms these alternatives across all benchmarks.}
\resizebox{0.9\textwidth}{!}{%
\begin{tabular}{lccccccccccc}

\textbf{Model} &
\rot{\shortstack{\textbf{DocVQA} \\ \textcolor{gray}{\tiny{\textbf{VAL}}}}} & 
 \rot{\shortstack{\textbf{InfoVQA} \\ \textcolor{gray}{\tiny{VAL}}}} &
 \rot{\shortstack{\textbf{DeepForm} \\ \textcolor{gray}{\tiny{TEST}}}} &
 \rot{\shortstack{\textbf{KLC} \\ \textcolor{gray}{\tiny{TEST}}}} &
 \rot{\shortstack{\textbf{WTQ} \\ \textcolor{gray}{\tiny{TEST}}}} &
 \rot{\shortstack{\textbf{TabFact} \\ \textcolor{gray}{\tiny{TEST}}}} &
 \rot{\shortstack{\textbf{ChartQA} \\ \textcolor{gray}{\tiny{TEST}}}} &
 \rot{\shortstack{\textbf{TextVQA} \\ \textcolor{gray}{\tiny{VAL}}}} &
 \rot{\shortstack{\textbf{TableVQA} \\ \textcolor{gray}{\tiny{TEST}}}} &
 \rot{\textbf{Avg. Score}}\\ 

\toprule
Llama-3.2-3B-\textbf{MLP} & 
71.46 & 37.56 & 62.07 & 33.36 & 28.94 & 73.22 & 66.48 & 53.56 & 50.96 & \cellcolor{lightblue}53.06 \\


Llama-3.2-3B-\textbf{Perciever R.} & 
69.08 & 34.13 & 57.08 & 31.75 & 27.95 & 71.93 & 65.16 & 51.33 & 47.76 & \cellcolor{lightblue}50.68 \\


Llama-3.2-3B-\textbf{Ovis} & 
74.68 & 42.11 & 58.02 & 33.50 & 33.13 & 76.67 & 67.92 & 52.60 & 53.93 & \cellcolor{lightblue}54.72 \\


\hline

\rowcolor{lightgray!20}
Llama-3.2-3B-\textbf{\alignmodule} (ours) & 
\textbf{79.63} & \textbf{44.53} & \textbf{63.49} & \textbf{35.25} & \textbf{38.59} & \textbf{78.51} & \textbf{71.88} & \textbf{57.38} & \textbf{60.10} & \cellcolor{lightblue}\textbf{58.81} \\


\bottomrule
\end{tabular}%
}

\label{tab:connectors-ablations}
\vspace{-10px}
\end{table*}
