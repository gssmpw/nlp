
\begin{figure*}[t] % !b により下部への配置を優先
  \includegraphics[width=\textwidth]{figures/abstract_figure.pdf}
  \vskip 0.1in % キャプション前のスペース
  \caption{Illustration of our paper. Our proposed method, LaVCa, generates text captions that explain voxel selectivity and surpass existing approaches, such as one-hot vectors and BrainSCUBA, enabling a more detailed description of the properties of visual cortex voxels.
}
  \label{abstract:abstract_figure}
  % \vskip -0in % キャプション前のスペース
\end{figure*}

\section{Introduction}
A primary goal of computer vision is to build systems capable of processing and understanding the complex visual world in a manner akin to human perception. Studying how the human brain—with its advanced visual functions—forms its visual representations deepens our understanding of the brain’s visual network and holds promise for developing next-generation computer vision models.

To understand how the human brain represents visual stimuli from the external world, researchers have used encoding models that predict voxel-level (the spatial measurement unit of fMRI) brain activity measured during the presentation of images or videos~\cite{naselaris2011encoding}. These models typically use features derived from theoretical or data-driven hypotheses to map from stimulus properties to voxel responses~\cite{kay2008identifying, nishimoto2011reconstructing, naselaris2011encoding, huth2012continuous}. Many such models use simple, interpretable features—for instance, low-level visual features generated by filters rooted in theoretical models or high-level visual features representing words using one-hot encoding—to infer voxel properties through the correlation between feature-based predictions and actual brain responses.

However, because the human brain solves highly complex real-world tasks, relying solely on a small number of interpretable parameters may be insufficient~\cite{kriegeskorte2018cognitive}. Recent advances in deep neural networks (DNNs), which effectively handle real-world tasks through a large number of parameters, have enabled more accurate predictions of brain activity by leveraging the complex representations extracted by DNNs~\cite{gucclu2015deep, schrimpf2021neural, takagi2023high, denk2023brain2music, antonello2024scaling}. Nevertheless, because of their black-box nature, interpreting how these DNN-based features map to individual voxels remains challenging ~\cite{abnar2019blackbox}. Although group-level interpretations—representing many voxels in terms of a small set of universal, interpretable axes—are possible~\cite{huth2016natural, lescroart2019human, nakagi2024unveiling}, voxel-level interpretation is critical for exploring more nuanced aspects of brain representations.

In this study, we address the difficulty of voxel-level interpretation with a new method called LLM-assisted Visual Cortex Captioning (\textbf{LaVCa}), which generates data-driven captions for individual voxels (Figure \ref{abstract:abstract_figure}). LaVCa proceeds in four steps: (1) building voxel-wise encoding models for brain activity evoked by images, (2) identifying the optimal images for each voxel’s encoding model using an augmented image dataset (3) generating captions for these optimal images, and (4) creating concise summaries from those captions. By leveraging large language models (LLMs) with access to a vast, open-ended vocabulary, LaVCa generates diverse inter-voxel captions. Moreover, generating captions from multiple keywords enables us to capture diverse intra-voxel properties.
Our contributions are as follows:
\begin{enumerate} 
\item We propose LLM-assisted Visual Cortex Captioning (LaVCa), a data-driven technique that leverages LLMs to generate natural language captions of voxel-level visual selectivity.

\item We demonstrate that LaVCa produces more accurate captions than the earlier method BrainSCUBA~\cite{luo2023brainscuba} and better characterizes voxel-wise visual selectivity through brain activity prediction.

\item We also demonstrate that LaVCa can generate highly interpretable and accurate captions without sacrificing information from the optimal images (Figure \ref{results:xaxis_num_words}).

\item The captions generated by LaVCa quantitatively capture more detailed properties than the existing method at both the inter-voxel and intra-voxel levels. 

\item More detailed analysis of the voxel-specific properties generated by LaVCa reveals fine-grained functional differentiation within regions of interest (ROIs) in the visual cortex and voxels that simultaneously represent multiple distinct concepts.

\end{enumerate}
\begin{figure}[b!] % !b により下部への配置を優先
  \centering
  \includegraphics[width=0.9\columnwidth, trim=10 10 10 10, clip]{figures/subj01_xaxis_words.pdf}
  \vskip 0.1in % キャプション前のスペース
  \caption{The relationship between sentence-level prediction performance and the number of words in voxel captions for a single subject (subj01). The number following ``LaVCa'' indicates the number of optimal images used for summarization, while the number following ``Concat'' indicates the number of concatenated captions from the optimal images. Error bars indicate the standard error. LaVCa explains the properties of voxels well using a small number of words.}
  \label{results:xaxis_num_words}
  % \vskip -0.1in % キャプション前のスペース
\end{figure}
