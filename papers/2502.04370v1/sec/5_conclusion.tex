\section{Conclusion}
\label{sec:clu}

In this work, we propose DreamDPO, an optimization-based 3D generation method that offers human preferences and fine-grained control for generation.
The method is built on three key steps: pairwise example construction, pairwise example comparison, and preference-guided optimization.
Unlike existing methods that rely on precise pointwise quality evaluations, DreamDPO uses pairwise comparison informed by reward models or large multimodal models. It enables a more flexible optimization process.
By incorporating human preferences directly into the optimization, DreamDPO generates 3D assets that are better aligned with input text and exhibit enhanced texture and geometry quality.
Comprehensive experimental results demonstrate that DreamDPO surpasses previous state-of-the-art methods in both output quality and controllability. Lastly, we hope DreamDPO paves the way for more refined, adaptable, and human-aligned 3D content generation solutions.


\textbf{Limitations and future work.}
While DreamDPO has shown improvements in aligning 3D generation with human preferences, several avenues for future research could further enhance its performance and applicability.
The primary limitations of DreamDPO are as follows:
(1) AI feedback can be used for guidelines but is largely limited to the inherent power of generative models. 
(2) Open API can provide more freedom but actually bring more instability, where instruction prompts should be designed carefully. 

To address these limitations, we suggest the following directions for future work:
(1) Enhancing generative models.
Incorporating image prompts~\citep{chen2024vp3d} to introduce explicit guidance could improve alignment with user expectations by providing a more detailed context for generation. (2) Improving the robustness of models in pairwise comparison.
Exploring prompt-free methods, such as leveraging object detection models~\citep{wang2023detecting} or grounding models~\citep{oquab2023dinov2}, for number and attribute correction, might reduce dependencies on prompt design. 
Additionally, using the diffusion model itself as a model for pairwise comparison~\citep{tian2024diffuse} could enhance stability and performance by ensuring consistency across the generation and comparison.