\vspace{-7pt}
\section{Preliminaries}
\label{sec:pre}
\vspace{-3pt}
Text-to-3D generation aims to create high-quality 3D assets aligned with a given text prompt $y$.
The pipeline typically distills knowledge from a parametrized diffusion model $\bm{\epsilon}_\phi$~\citep{rombach2022high,shi2023mvdream} into a learnable 3D representation with parameters $\theta\in\Theta$ (\eg, NeRF~\citep{mildenhall2020nerf}, DMTet~\citep{shen2021deep}, and 3DGS~\citep{kerbl3Dgaussians}), where $\Theta$ is the space of $\theta$ with the Euclidean metric. Score distillation sampling~(SDS)~\citep{poole2022dreamfusion} is used to guide the distillation process. 

\textbf{Diffusion models.} The diffusion model has been widely used in generative tasks~\citep{sohl2015deep,song2022diffusion,bao2022analytic,peebles2023scalable}. Generally, it involves a forward process to gradually add Gaussian noise to data points and a reverse process to transform Gaussian noise into data points from a target distribution $p_{\mathrm{data}}$. The reverse process starts from an initial noise $\mathbf{z}_T\sim\mathcal{N}(\mathbf{0}, \mathbf{I})$. At each diffusion step $t$, the model refines noisy data $\mathbf{z}_t$ into a cleaner one $\mathbf{z}_{t-1}$ until finally producing $\mathbf{z}_0 = \mathbf{x}\sim p_{\mathrm{data}}$. Therefore, the transitions $p(\mathbf{z}_{t-1}|\mathbf{z}_{t})$ can be learned effectively by the diffusion model.

\textbf{Score distillation sampling~(SDS).} SDS was proposed in DreamFusion~\citep{poole2022dreamfusion}, and has been widely studied~\citep{wang2023prolificdreamer,yu2023text,katzir2023noise,chung2023luciddreamer,wu2024consistent3d,zhuo2025vividdreamer,ye2025dreamreward}. Technically, for a rendered image $\mathbf{x}$ from a 3D representation, random noise $\bm{\epsilon}$ is added at timestep $t$. 
A pre-trained diffusion model predicts this noise. The SDS loss is computed as the difference between predicted and added noise, which optimizes a set of parameters $\theta$. The gradient of the SDS loss with respect to $\theta$ is:
\begin{equation}
    \nabla_\theta \mathcal{L}_{\text{SDS}} = \mathbb{E}_{t, \bm{\epsilon}}[w(t) (\bm{\epsilon}^s_{\phi}(\mathbf{x}_t;y,t)-\bm{\epsilon})\frac{\partial\mathbf{x}}{\partial\theta}],
\end{equation}
where $\mathbf{x}_t = \alpha_t \mathbf{x}_0 + \sigma_t \bm{\epsilon}$, $w(t)$ is a weighting function, and $s$ is a pre-defined scalar of classifier-free guidance (CFG)~\citep{ho2022classifier}. The minimization of the SDS loss follows the score function of the diffusion model to move $\mathbf{x}$ to the text description region, ensuring the generated 3D representation aligns with the given text prompt. Note that to make a continuous and smooth presentation, we provide a detailed review of related work in Appendix~\ref{app:related_work}.
