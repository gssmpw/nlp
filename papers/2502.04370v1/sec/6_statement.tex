\newpage
\section{Impact Statement}
This paper advances the field of Text-to-3D generation by introducing DreamDPO, an optimization-based framework that integrates human preferences into the 3D generation process. By aligning generated content more closely with human preferences, our approach enhances the quality, controllability, and applicability of 3D content creation across various domains, including gaming, virtual reality, design, and digital media.

From an ethical perspective, our work raises considerations related to bias in human preference data, potential misuse in deepfake or unauthorized content generation, and the environmental impact of computationally intensive optimization processes. To mitigate these risks, we promote transparency by open-sourcing our code and models, allowing the research community to further evaluate and refine our approach. Additionally, we encourage responsible use of preference-driven generation techniques to ensure ethical applications.