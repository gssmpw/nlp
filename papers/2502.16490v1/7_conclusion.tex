\section{Conclusion}\label{sec:conclusion}
In this work, we have addressed several fundamental questions about the FlowAR architecture, making significant contributions to both theoretical understanding and complexity efficiency. By rigorously analyzing the architecture of FlowAR, we demonstrated that despite its sophisticated integration of flow-based and autoregressive mechanisms, it resides within the complexity class $\TC^0$. Specifically, we proved that each module of FlowAR, including the attention and flow-matching layers, can be simulated by a constant-depth, polynomial-size circuit. As a result, the entire FlowAR model can be simulated within the same bounds, revealing that its expressive power in terms of circuit complexity is comparable to that of the VAR model. Beyond the theoretical analysis, we identified the computational bottleneck in FlowAR's attention mechanism and developed an efficient variant using low-rank approximation techniques. This optimization achieves nearly quadratic runtime $O(n^{2+o(1)})$, a substantial improvement over the original $O(n^{4+o(1)})$ complexity, while maintaining an error bound of $1/\poly(n)$. Our findings provide both a theoretical foundation for understanding the computational limits of FlowAR and practical guidelines for implementing more efficient variants, offering valuable insights for future development of generative architectures and establishing a framework for comparisons with other generative paradigms.