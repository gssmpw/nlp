%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8
\documentclass[lettersize,journal]{IEEEtran}

\usepackage{algorithmic}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\usepackage{balance}

\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
% \usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{amsfonts,amssymb}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{float} %设置图片浮动位置的宏包
\usepackage[outdir=./]{epstopdf}
\usepackage{color}
\usepackage[dvipsnames]{xcolor}
\usepackage{setspace}

\makeatletter
\renewcommand{\maketag@@@}[1]{\hbox{\m@th\normalsize\normalfont#1}}%
\makeatother


\title{ Human-Like Robot Impedance Regulation Skill Learning from Human-Human Demonstrations
}

\author{Chenzui Li, Xi Wu, Junjia Liu, Tao Teng, Yiming Chen, Sylvain Calinon, \IEEEmembership{Member, IEEE}, \\ Darwin Caldwell, \IEEEmembership{Fellow, IEEE}, and Fei Chen, \IEEEmembership{Senior Member, IEEE}% <-this % stops a space
\thanks{This work was supported in part by the Research Grants Council of the Hong Kong SAR under Grant 24209021, 14222722, 14211723 and C7100-22GF and in part by InnoHK of the Government of Hong Kong via the Hong Kong Centre for Logistics Robotics. (\textit{Corresponding author: Fei Chen)}}% <-this % stops a space
\thanks{Chenzui Li, Xi Wu, Junjia Liu, Tao Teng, Yiming Chen, and Fei Chen are with the Department of Mechanical and Automation Engineering, T-Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong (e-mail: {czli@mae.cuhk.edu.hk, xwu@mae.cuhk.edu.hk, jjliu@mae.cuhk.edu.hk, tao.teng@cuhk.edu.hk, ymchen@mae.cuhk.edu.hk, f.chen@ieee.org}).}%
\thanks{Sylvain Calinon is with the Idiap Research Institute, Martigny, Switzerland (e-mail: {sylvain.calinon@idiap.ch}).}
\thanks{Darwin Caldwell is with the Department of Advanced Robotics, Istituto Italiano di Tecnologia, 16163 Genoa, Italy (e-mail: {darwin.caldwell@iit.it}).}
}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Humans are experts in collaborating with others physically by regulating compliance behaviors based on the perception of their partners' states and the task requirements. Enabling robots to develop proficiency in human collaboration skills can facilitate more efficient human-robot collaboration (HRC). This paper introduces an innovative impedance regulation skill learning framework for achieving HRC in multiple physical collaborative tasks. The framework is designed to adjust the robot compliance to the human partner's states while adhering to reference trajectories provided by human-human demonstrations. Specifically, electromyography (EMG) signals from human muscles are collected and analyzed to extract limb impedance, representing compliance behaviors during demonstrations. Human endpoint motions are captured and represented using a probabilistic learning method to create reference trajectories and corresponding impedance profiles. Meanwhile, an LSTM-based module is implemented to develop task-oriented impedance regulation policies by mapping the muscle synergistic contributions between two demonstrators. Finally, we propose a whole-body impedance controller for a human-like robot, coordinating joint outputs to achieve the desired impedance and reference trajectory during task execution. Experimental validation was conducted through a collaborative transportation task and two interactive Tai Chi pushing hands tasks, demonstrating superior performance from the perspective of interactive forces compared to a constant impedance control method.
\end{abstract}

\begin{IEEEkeywords} Impedance regulation skill learning, human-human demonstrations, human-like collaborative robot, whole-body impedance control \end{IEEEkeywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction} \label{introduction}

\IEEEPARstart{C}{ollaborative} robots (cobots) have emerged as a solution for more efficient human-robot collaboration (HRC) in both industrial and domestic scenarios. Co-manipulation outperforms fully robotic manipulation by offering enhanced flexibility and effectiveness while surpasses fully human manipulation by reducing labor costs, maintaining concentration, and minimizing errors due to fatigue \cite{chen2013optimal}. Consider, for instance, the various collaborative tasks in Fig. \ref{Fig.tai chi}, distinct \textit{physical collaboration skills} are required for cobots to master and apply in the form of \textit{impedance regulation skills}. During human-robot co-transportation of bulky objects, humans take on the role of leaders for multiple operations while cobots undertake physical work and \textit{regulate impedance based on the human compliance behaviors}, reducing physical costs and speeding up processes \cite{nemec2016bimanual}. Tai Chi pushing hands, similar in principle to collaborative sawing tasks, requires cobots to \textit{produce inverse compliance behaviors} compared to the human partner. Regardless, it remains challenging for cobots to swiftly acquire task-specific physical collaboration skills through traditional model-based methods and effectively apply them in human-robot collaboration \cite{8907351}.

\begin{figure}[!tbp]
\centering
\includegraphics[width=0.9\linewidth]{collaboration.jpg} 
\caption{Illustration of human-robot physical collaborative tasks. In these scenarios, the cobot should be able to perform different compliance behaviors accordingly because physical interaction exists between the human and the cobot. We expect to learn from the human-human demonstrations and apply to a human-like mobile cobot. (We declare that the individuals in this figure are both authors and they gave permission for the use of their image.)}
\label{Fig.tai chi} \vspace{-3mm}
\end{figure}

Humans excel at collaborating with others and the kinematic and dynamic information generated during these collaborations can serve as a crucial data source. Learning from Demonstration (LfD) is an effective approach that enables cobots to acquire and imitate these skills for HRC \cite{ravichandar2020recent}. Most LfD approaches involve a single human instructing a cobot through guided collaboration, commonly referred to as kinesthetic teaching to achieve collaborative object carrying \cite{rozo2016learning} and scarf hanging \cite{7139990}. While these approaches have the advantage of directly obtaining joint values during demonstrations, they prove challenging to apply to highly redundant cobots and efficiently acquire large volumes of data \cite{9720487}. Other studies concentrate on learning from human-human demonstrations, which can provide extensive kinematic and dynamic information, such as reference trajectories \cite{7989334} or impedance profiles \cite{zhang2022electromyography}. Although the acquired data contains rich human behavior information, how to represent these physical behaviors and reproduce them by cobots in HRC is still an open problem \cite{vinciarelli2015open}.

Trajectory and impedance are widely applied to represent human kinematic and dynamic behaviors during demonstrations. On the one hand, Gaussian Mixture Model (GMM) and Dynamic Movement Primitives (DMP) are frequently used to represent complex human demonstration motions by few parameters that can generate reference trajectories for the cobots \cite{CalinonLee19}. The Task-parameterized Gaussian Mixture Model (TP-GMM) represents demonstration motions from several different perspectives for integrating task information, which allows the cobots to adjust trajectories to new situations \cite{calinon2016tutorial}. On the other hand, stiffness and damping parameters are commonly applied to characterize the physical behavior of humans. The cobot impedance variables can be inferred based on the dynamic interaction model and learned Cartesian trajectories with optimization methods. These kinds of approaches have been successfully applied to various collaborative tasks, such as object assembly, object lifting \cite{yang2018dmps}, cucumbers cutting \cite{yang2018learning}, and physical therapy for optimal path planning \cite{fong2018kinesthetic}. Regardless, these approaches acquire data from kinesthetic demonstration and the optimized impedance variations of the cobots may not align with those encoded physical behaviors during human-human demonstrations. Other approaches utilize bio-signals, such as electromyography (EMG), to directly record human muscle bioelectrical activity, thereby offering valuable insights into human impedance. An impedance variation approach based on human EMG feedback has been proposed to enable a cobot to achieve an appropriate impedance profile in collaborative sawing tasks \cite{peternel2016adaptation}. Another approach has been raised for adapting the impedance of cobots based on the operator’s intentions and movements, which are estimated using a real-time EMG-to-force model \cite{9707641}. However, current approaches primarily concentrate on extracting human impedance variation during collaboration while overlooking the impedance regulation based on their partners' states, which could serve as a potential policy in human-human collaboration and be transferred to human-robot collaboration.

A variable impedance controller (VIC) is required to reproduce the learned impedance regulation skills by modulating the desired stiffness and damping of the cobot \cite{sharifi2021impedance}. Force-based VIC methods have been proposed to achieve intuitive co-manipulation with redundant manipulators, KUKA LWR4 \cite{ficuciello2015variable}, \cite{erden2015robotic}. An optimization-based method has been raised for efficient human-robot collaborative assembly with a Franka EMIKA Panda manipulator \cite{roveda2021human}. Some variable whole-body impedance control methods have been proposed for human-humanoid collaboration like ARMAR-6 \cite{asfour2019armar} and Rollin' Justin \cite{dietrich2016whole}. Among these methods, the human-in-the-loop VIC method is crucial for improving safety and efficiency in HRC. For instance, an online stiffness estimation based VIC method has been raised for robust collaborative polishing and assembly \cite{roveda2021sensorless}. Another biosignal-based VIC method achieves real-time cobot stiffness regulation with the corresponding reactions of the cobot modeled with the experience/observation \cite{peternel2016adaptation}. Nevertheless, usability and human perception should be considered or learned for designing a collaborative controller \cite{maccarini2022preference}. The above issues can be solved by proposing a novel VIC based on the impedance regulation skills learned from human-human demonstrations since the regulation policies can be extracted from teaching data while usability is guaranteed. Specifically, the physical reactions from the collaborator to the partner can be represented by the proper impedance regulation along the reference trajectories, which will be further transferred to the cobot for VIC development. 

In this article, we propose a novel skill-learning framework designed to enable cobots to acquire collaboration skills based on human-human demonstrations. Diverging from prevalent methodologies, this framework extracts the physical behaviors exhibited by human demonstrators and assimilates the proper compliance responses based on the partner's dynamical states in collaborative tasks. Consequently, the cobot can be applied to execute a reference trajectory derived from task demonstrations and to simultaneously adjust compliance in response to the feedback of the human partner with a variable impedance controller. Two collaborative tasks including object co-transportation and confrontational Tai Chi pushing hands are raised for validation. 

% In this article, a novel impedance adaptive skill learning framework has been proposed for the cobots to acquire collaborative skills from human-human demonstrations. Unlike most recent approaches, we not only extract the compliance behaviors of human demonstrators but also learn the human compliant adaptation based on the partner's physical behaviors during interaction/collaboration. As a consequence, the cobots are supposed to execute a reference trajectory learned from task demonstrations and adjust their compliance according to the physical state of their partner adaptively.

To summarize, the main contributions of this work are described as follows:
\begin{itemize}
  \item [1)]
  An impedance regulation skill learning framework is proposed for cobots to acquire collaborative compliance behaviors of humans. The TP-LQT method is applied for both motion and impedance representation from human demonstrations. Specifically, TP-GMM is adopted to represent demonstrated motion with trajectory and impedance profiles, which are extendable to new situations. Linear Quadratic Tracking (LQT) based method is then applied for cobot motion and impedance planning, which novelly corresponds compliance behaviors to the reference trajectories.
  \item [2)]
  An LSTM-based impedance regulation module is constructed to innovatively map the compliance variation during human-human demonstrations. This module can dynamically adjust the cobot regulatory factor online, using EMG feedback from the partner to scale the impedance profile generated from the TP-LQT. The human compliance behaviors are represented by endpoint impedance, which is calculated with an EMG-based upper limb dynamic model.
  \item [3)]
  A novel whole-body impedance controller has been designed for our specific human-like mobile cobot with a self-designed torso and two manipulators included, which can generate desired stiffness and damping during movement in Cartesian space while coordinating different components through proper torque commands. 
\end{itemize}

% The rest of the paper is organized as follows. In Section \ref{skills}, the relationship between the physical collaboration skill of humans and the impedance adaptive skill is introduced and the dynamics of the human upper limb model are given. Section \ref{learning} presents the methodology of representing the interaction model during collaboration for reference trajectory calculation. Motion and impedance generation and representation as well as trajectory/impedance planning of the robot from the demonstration are followed in this section. Then, an LSTM network is proposed to learn the impedance adaptive skill policy based on real-time muscle synergistic contributions. After that, a whole-body impedance controller of the human-like robot is proposed to execute the collaborative tasks. Section \ref{V} shows the experimental setup and gives the results of two experiments. The conclusion is discussed in Section \ref{VI}.

\section{Impedance Regulation Skills} \label{skills}
This section presents the relationship between impedance regulation skills and physical collaboration skills with two typical modes in human-human collaboration (as shown in Fig. \ref{Fig.physical collaboration skill}) and the definition of impedance regulation skills is given. An EMG-based stiffness estimation method is then introduced for human compliance representation, which is the preliminary of learning impedance regulation skills in demonstrations.

\subsection{Definition} \label{skill definition}
Impedance regulation skills represent a foundational aspect of physical collaboration skills at a low level. Physical collaboration skill has been defined as \emph{regulating the exchange of mechanical energy} \cite{5379513} or \emph{seamless adaptation of autonomy level} \cite{9501975} based on tasks and a mutual understanding of the partner's intentions. To conclude, physical collaboration skills involve generating appropriate behaviors based on comprehensive feedback from both the partners and the environmental conditions. For example, during a collaborative sawing task shown in Fig. \ref{Fig.physical collaboration skill}, one agent may demonstrate stiffly to the task by vigorously pulling the saw at one stage while exhibiting adaptability by gently pushing the saw back at another stage in response to the partner’s actions \cite{ZENG2021103668}. Consequently, physical collaboration skills can be conceptualized as regulatory compliance behaviors tailored to meet both task requirements and partner feedback.

% Impedance Adaptive skills are the manifestation of physical collaboration skills in low level. In \cite{5379513}, physical collaboration skill is defined as a good synergy in which agents \textit{regulate the exchange of mechanical energy} based on tasks and mutual understanding of the partner's intentions. From the perspective of robots, their skills to physically collaborate with others can be described as the capacity of \textit{seamless adaptation of their autonomy level} based on the understanding of the partner's actions and of the surroundings \cite{9501975}. They were both expected to generate suitable behaviors on the basis of comprehensive feedback from their partners and tasks/environments. Here, skills can be the ability to balance responses to the partners and the task requirements at different stages of the task. For instance, during a collaborative sawing task, the agent was extremely committed to the mission by pulling the saw at one stage while being submissive to the partner by pushing the saw back at another stage \cite{ZENG2021103668}. Hence, physical collaboration skills are proposed as adaptive compliant behaviours according to the task requirements and the partner's feedback and are demonstrated through impedance adaptive skills from the perspective of robotics. 

\begin{figure*}[htbp]
\centering
\setlength{\abovecaptionskip}{0.1cm}
\includegraphics[width=0.9\linewidth]{physical_collaborative_skill.png} 
\caption{Schematic diagram of two typical physical collaboration skills and the corresponding impedance regulation skills. Leader-follower mode is widely applied in some collaborative tasks such as tug of war and collaborative transportation. The follower's physical behaviors are concluded as performing concerted impedance according to the leader's compliance behaviors. Mutual adaptation mode is observed in other tasks like collaborative sawing and confrontational Tai Chi, in which roles are changing during these tasks and the physical behaviors of collaborators are defined as performing adaptable impedance based on the partners.}
\label{Fig.physical collaboration skill} \vspace{-3mm}
\end{figure*}

 Representing human compliance behaviors can teach cobots the corresponding impedance regulation skills from human-human demonstrations since they are the most efficient capacities to transfer to the robots. Human-like variable impedance skills have been successfully learned by human-like cobots with learning frameworks through physical human-robot interfaces \cite{6224904}. Nevertheless, these skills are mostly applied in the manipulation and teleoperation scenarios, in which the human compliance behaviors are directly transferred to the cobots whether offline or online \cite{arashijrr}. In this paper, our primary focus centres on the ability to regulate behaviors in response to dynamic feedback from collaboration partners \cite{stefanosijrr}. Specifically, we aim to map human impedance regulation skills that are influenced by the partner's compliance behaviors during task execution. We select two quintessential physical collaboration skills of humans, which are targeted for replication. \\
\textbf{Leader-follower mode}: Followers are expected to align closely with leaders, contributing collaboratively and efficiently in joint tasks. Consequently, collaborators will demonstrate consistent compliance behavior relative to their partners throughout the engagement. \\
\textbf{Mutual adaptation mode}: Collaborators are expected to adapt their roles at various stages of the task, thereby exhibiting adaptable compliance in relation to their partners.

To illustrate their regulatory compliance behaviors in terms of impedance, the impedance regulation skills of the human based on partner compliance can be described as:
\begin{equation}\label{human impedance relationship}
  \bm{K}_e^c(t) = h(\bm{K}_e^p(t)),
\end{equation}
where $\bm{K}_e^c(t)$ and $\bm{K}_e^p(t)$ are the contact point stiffness of the collaborator and the partner, $h$ represents the function which constructs the relationship of physical compliance along movements. The damping matrix is set as $\bm{D}_e^c(t) = \delta \sqrt{\bm{K}_e^c(t)}$ with a predefined scaling factor $\delta$. 

% Hence, the physical collaboration skills in this paper are performed from the perspective of impedance adaptive skills, which adapt the compliance behaviors based on the partner's compliant level while following a reference trajectory.

\subsection{EMG-Based Stiffness Estimation} \label{modeling}
Human arm endpoint stiffness should be estimated to represent compliance behaviors and further acquire impedance regulation skills during demonstrations. Stochastic perturbation techniques are one of the most reliable methods to directly construct the relationship between force and displacement and therefore identify the characteristics of the human endpoint stiffness in Cartesian space. These methods are not feasible to be directly applied in human-human demonstrations or human-robot collaboration since real-time estimation is acquired. Hence, current researchers have designed a calibration process to extract the stiffness-related biosignal features (e.g., EMG signals) for estimating arm endpoint stiffness \cite{osu1999}. Firstly, we construct the positive-definite endpoint stiffness matrix through a geometric approach based on the process proposed in \cite{s20185357}: 
\begin{equation}\label{eigendecomposition}
\bm{K}_e = \bm{V} \bm{H} \bm{V}^T,
\end{equation}
where $\bm{V}$ is an orthonormal matrix with the normalized eigenvectors of $\bm{K}_e$, and $\bm{H}$ represents a diagonal matrix composed of the eigenvalues of $\bm{K}_e$. A simplified human arm structure in Cartesian space is applied to provide the geometric information to construct these matrices. As shown in Fig. \ref{Fig.stiffness ellipsoid}, the endpoint stiffness ellipsoid can be defined under a specific arm configuration.

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.98\linewidth]{framework_1.png} 
\caption{The overall framework scheme from human-human demonstration to human-robot collaboration. \textit{Human-Human Demonstration:} multi-modal data including the 3D pose of human joints, EMG signals, and interactive forces, are recorded. By calculating the stiffness matrices through the endpoint stiffness estimation module and reference trajectories through the interaction model, the motion/impedance profiles are learned through TP-LQT. \textit{Human-Robot Collaboration:} the estimated impedance profiles are sent to construct an LSTM-based impedance regulation module, which can generate proper regulatory factors during online human-robot collaboration. Finally, the reference trajectories and impedance are sent to our human-like cobot, CURI, with a whole-body impedance controller for task execution. (We declare that the individuals in this figure are both authors and they gave permission for the use of their image.)} 
\label{Fig.framework}\vspace{-3mm}
\end{figure*}

\begin{figure}[!tbp]
\centering
\setlength{\abovecaptionskip}{0.cm}
\includegraphics[width=0.8\linewidth]{stiffness_ellipsoid.png} 
\caption{Definition of the endpoint stiffness ellipsoid under a human arm configuration. A simplified arm geometric configuration is constructed with the connection between the shoulder joint, elbow joint, and wrist joint. The major, median, and minor principal axes of the endpoint stiffness ellipsoid are $\lambda_1$, $\lambda_2$, and $\lambda_3$, respectively.}
\label{Fig.stiffness ellipsoid} \vspace{-4mm}
\end{figure}

We define that vector $\bm{l}_1$ starts from the shoulder joint to the elbow joint and vector $\bm{l}_2$ starts from the shoulder joint to the wrist joint. $\bm{l}_3$ is a perpendicular vector starts from the elbow joint to the vector $\bm{l}_1$ while $\bm{l}_4$ represents a vector which is perpendicular to the arm triangle plane. Hence, the major, median, and minor principal axis $\lambda_1$, $\lambda_2$, and $\lambda_3$ of the endpoint stiffness ellipsoid are determined as $\bm{l}_2$, $\bm{l}_3$, and $\bm{l}_4$. The matrices $\bm{V} \in \mathbb{R}^{3 \time 3}$ and $\bm{H} \in \mathbb{R}^{3 \time 3}$ can be written as:
\begin{equation}\label{V}
\bm{V} = \left [ \begin{matrix} \
    \displaystyle{\frac{\bm{l}_2}{||\bm{l}_2||}} \ \displaystyle{\frac{(\bm{l}_2 \times \bm{l}_1) \times \bm{l}_2}{||\bm{l}_2 \times \bm{l}_1) \times \bm{l}_2||}} \ \displaystyle{\frac{\bm{l}_2 \times \bm{l}_1}{||\bm{l}_2 \times \bm{l}_1||}} \
    \end{matrix} \right ],
\end{equation}
\begin{equation}\label{H}
\bm{H} = \alpha(A) \cdot \bm{H}_s = \alpha(A) \cdot diag(1, \frac{a_1}{d_1}, a_2 d_2),
\end{equation}
where $\alpha(A)$ represents the synergistic contribution of the muscle co-contractions with $\alpha(A) = b_1 A + b_2$, $A$ denotes the comprehensive muscle activation level; $\bm{H}_s \in \mathbb{R}^{3 \time 3}$ is the diagonal matrix which contains the configuration dependence eigenvalues. Their values are given by the length of vector $l_2$ and $l_3$:
\begin{equation}\label{d}
d_1 = ||\bm{l}_2||, \ \ d_2 = ||\bm{l}_3|| = ||\bm{l_1} \cdot \frac{(\bm{l}_2 \times \bm{l}_1) \times \bm{l}_2}{||\bm{l}_2 \times \bm{l}_1) \times \bm{l}_2||}||.
\end{equation}

Two dominant upper arm muscles biceps brachii (BB) and triceps brachii (TB) are chosen to calculate the co-contraction index $\alpha(A)$, which is illustrated as:
\begin{equation}\label{cocontraction}
  A = \frac{A_{BB} + A_{TB}}{2}, 
\end{equation}
where $A_{BB}$ and $A_{TB}$ represent the muscle activation levels of BB and TB, respectively. Assume that the EMG signals from the demonstrator are collected as $[U_{BB}, U_{TB}] \in \mathbb{R}^{2}$ with $2$ EMG sensors in measurement at each time step. They are further processed by filters and normalized using Maximal Voluntary Contraction (MVC). Then, the muscular activation levels based on the MVC and the processed EMG data can be calculated as $[A_{BB}, A_{TB}] \in \mathbb{R}^{2}$. 

The parameters $a_1$, $a_2$, $b_1$, and $b_2$, which vary among individuals, are identified using an optimization method that minimizes the error between the estimated and actual endpoint stiffness matrices. A perturbation method is employed to measure the matrices \cite{arashijrr}. Upon identifying these parameters for each demonstrator, we can estimate their endpoint stiffness matrices during demonstrations and learn representations of impedance regulation skills.

% The unknown parameters $a_1$, $a_2$, $b_1$, and $b_2$ vary from different individuals need to be identified. We use an optimization method to identify these parameters by minimizing the error between the estimated and measured endpoint stiffness matrices. Specifically, a perturbation approach is applied to obtain the measured endpoint stiffness matrix \cite{arashijrr}. We can estimate their endpoint stiffness matrices during human-human demonstrations after identifying these parameters for each demonstrator and learn representations of impedance adaptive skills.


\section{Methodology} \label{learning}
In this section, the overall framework (as shown in Fig. \ref{Fig.framework}) will be presented. The interaction model is introduced to represent the dynamics between the agent and the environment. The endpoint stiffness matrices along the trajectories are estimated and the reference trajectories of the demonstrator are then calculated with data recorded from human demonstrations. A novel TP-GMM is proposed for learning motion and impedance representation from the demonstrations by corresponding the reference trajectory and the stiffness profiles. The LQT method for trajectory planning and impedance variation is then raised afterwards for robot execution. Meanwhile, an impedance regulation module to construct the compliance relationship between two demonstrators is proposed. Finally, a whole-body impedance controller is applied to perform the reference trajectory and impedance variables for the CURI. 

\subsection{Interaction Model}\label{interaction model}
The interaction model between the cobot and the environment encapsulates the dynamics of the physical behaviors during the collaboration, which is supposed to imitate human collaboration skills by utilizing both trajectory and force information. Hence, we propose to learn the reference trajectory and the stiffness matrix of the interaction model between the human and the environment during the human-human demonstrations and then transfer to the cobot for human-robot collaboration. 

Considering the movement of the cobot Tool Center Point (TCP) as a single unit mass moving in Cartesian space under the effect of a control input and interaction force. To achieve the desired dynamics of the tasks, the problem can be formulated as designing the appropriate control input. Specifically, the Cartesian-space impedance model to dynamically connect the cobot positions, velocities and accelerations with the interactive forces is:
\begin{equation}\label{impedance model}
  \bm{\Lambda}^{d}\bm{\ddot{\widetilde{x}}} + \bm{D}^{d}\bm{\dot{\widetilde{x}}} + \bm{K}^{d}\bm{\widetilde{x}}
    = \bm{F}^{ext}, 
\end{equation}
where $\bm{\widetilde{x}} = \bm{x}^{d} - \bm{x} \in \mathbb{R}^{6}$ in which $\bm{x}^{d}$ is the reference trajectory of the virtual spring-damper system and $\bm{x}$ the TCP pose. $\bm{\Lambda}^{d}, \bm{D}^{d}, \bm{K}^{d} \in \mathbb{R}^{6 \times 6}$ are the symmetric and positive definite matrices of the desired inertia, damping, and stiffness, respectively. $\bm{F}^{ext}$ is the external force applied to the end effector.

As mentioned above, we propose to learn the reference trajectory for cobot to execute. However, we can only observe the actual trajectory $\bm{x}$ of the demonstrations instead of the variable $\bm{x}^d$. Assuming the velocity and acceleration of the reference trajectory remain at 0 \cite{rozo2016learning}, the dynamic model can be rewritten based on (\ref{impedance model}):
\begin{equation}\label{eq3}
  \bm{\Ddot{x}} = \bm{K}^d (\bm{x}^d - \bm{x}) - \bm{D}^d \bm\dot{{x}}  + \bm{F}^{ext}.
\end{equation}

The reference trajectory $\bm{x}^d$ can be calculated accordingly if endpoint pose $\bm{x}$, stiffness (damping) matrix $\bm{K}^d$ ($\bm{D}^d$), and external forces $\bm{F}^{ext}$ are known. 

\subsection{Motion Representation and Planning}\label{trajectory planning}
Human reference trajectory and impedance profiles are modeled using TP-GMM, derived from human demonstrations and transferred to the cobot by modifying task parameters. A smooth reference trajectory, synchronized with the impedance variables, is then generated using an LQT-based method for robotic execution. This integrated approach of motion representation and planning is termed TP-LQT (Fig. \ref{Fig.framework}). 

The reference trajectory of each demonstration is firstly calculated by referring to (\ref{eq3}). The newly generated trajectories can be observed from different frames and GMM is adopted to cluster points on the demonstration into multiple Gaussian distributions in each frame $i \in [1, 2]$. Compared with previous works that applied TP-GMM \cite{calinon2016tutorial}, our method binds motion and impedance profiles and then calculates the GMM in multiple dimensions (7 for pose and 3 for impedance). After that, a motion with a corresponding impedance profile considered the task parameter can be reproduced via the product of experts (PoE). The task parameter refers to the pose of the target object or the state of the environment, which depends on the specific task. Note that the task parameter is defined as the transformation matrices of the start point and endpoint of multiple demonstrations $\boldsymbol{\zeta}$ from the world origin, namely $\{\boldsymbol{b}^{(i)}, \boldsymbol{A}^{(i)}\}_{i=1, 2}$. We first use these matrices to transform and align demonstrations with respect to each observer frame $\boldsymbol{X}_t^{(i)}={\boldsymbol{A}^{(i)}}^{-1}(\boldsymbol{\zeta}_t-\boldsymbol{b}^{(i)})$. Then we use a TP-GMM with $J$ Gaussian distributions $\{\boldsymbol{\mu}_j^{(i)}, \boldsymbol{\Sigma}_j^{(i)}\}_{i=1, 2}, j\in[1, J]$ to represent $\boldsymbol{X}_t^{(i)}$ in each frame. Thus, the reproduction is expected to lie within the distributions $\mathcal{N}\left(\hat{\boldsymbol{\xi}}^{(i)}_{j}, \hat{\boldsymbol{\Sigma}}^{(i)}_{j}\right)_{i=1, 2}$, where $\hat{\boldsymbol{\xi}}^{(i)}_j=\boldsymbol{A}^{(i)} \boldsymbol{\mu}^{(i)}_j+\boldsymbol{b}^{(i)}$, $\hat{\boldsymbol{\Sigma}}^{(i)}_j=\boldsymbol{A}^{(i)} \boldsymbol{\Sigma}^{(i)}_j {\boldsymbol{A}^{(i)}}^{\top}$.

The transformation matrices of the start point and endpoint are changed to generate the motion in new situations, hence a new GMM is generated by PoE:
\begin{equation}
\mathcal{N}\left(\hat{\boldsymbol{\xi}}_{j}, \hat{\boldsymbol{\Sigma}}_{j}\right) \propto \prod_{i=1}^2 \mathcal{N}\left(\hat{\boldsymbol{\xi}}_{j}^{(i)}, \hat{\boldsymbol{\Sigma}}_{j}^{(i)}\right),
\end{equation}
with the result as  $\hat{\boldsymbol{\Sigma}}_{j}=\left(\sum_{i=1}^P \hat{\boldsymbol{\Sigma}}_{j}^{(i)^{-1}}\right)^{-1}$, $\hat{\boldsymbol{\xi}}_{j}=\hat{\boldsymbol{\Sigma}}_{j} \sum_{i=1}^P \hat{\boldsymbol{\Sigma}}_{j}^{(i)^{-1}} \hat{\boldsymbol{\xi}}_{j}^{(i)}$. Thus, the reproduced motion $\hat{\boldsymbol\zeta}$ from this GMM should follow the style of demonstrations.

TP-GMM focuses on generating a reference trajectory $\hat{\boldsymbol\zeta}$ with desired task parameters by assuming the cobot has an ideal trajectory controller. Thus, a controller that considers the impedance and reference trajectory is needed to generate the motion in new situations. The tracking cost function of LQT method is defined as:
\begin{equation}
C=\sum_{j=1}^2\left(\hat{\boldsymbol{\xi}}_{k, t}^{(j)} -\hat{\boldsymbol{\zeta}}\right)^{\top} \hat{\boldsymbol{\Sigma}}_{k, t}^{(j)-1} \left(\hat{\boldsymbol{\xi}}_{k, t}^{(j)} - \hat{\boldsymbol{\zeta}}\right) + \boldsymbol{U}^{\top} \boldsymbol{R} \boldsymbol{U},
\end{equation}
where $\boldsymbol{R}$ is the control cost matrix and $\boldsymbol{U}$ is the control input. A two-step optimization is used to solve the problem to obtain the trajectory $\hat{\boldsymbol{\xi}}$ and the input:
\begin{equation}
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
\begin{aligned}
\hat{\boldsymbol{\xi}} & =\arg \min_{\boldsymbol{\xi}} \sum_{j=1}^2\left(\hat{\boldsymbol{\xi}}_{k, t}^{(j)}-\hat{\boldsymbol\zeta}\right)^{\top} {\hat{\boldsymbol{\Sigma}}_{k, t}^{(j)^{-1}}} \left(\hat{\boldsymbol{\xi}}_{k, t}^{(j)}-\hat{\boldsymbol\zeta}\right), \\
\hat{\boldsymbol{U}} & =\arg \min_{\boldsymbol{U}}\left(\hat{\boldsymbol{\xi}}-\boldsymbol{\zeta}\right)^{\top} {\hat{\boldsymbol{\Sigma}}}^{-1}\left(\hat{\boldsymbol{\xi}}-\boldsymbol{\zeta}\right)+\boldsymbol{U}^{\top} \boldsymbol{R} \boldsymbol{U}.
\end{aligned}
\end{equation}

\subsection{Impedance Regulation Skill Learning} \label{impedance estimation method}
In this part, a regulatory factor will be defined to describe the compliance reaction based on the partner, which is learned from human-human demonstrations. By substituting (\ref{eigendecomposition}) into (\ref{human impedance relationship}), we have:
\begin{equation}\label{relationship}
\alpha(A^c) \bm{V}^c \bm{H}_s^c {\bm{V}^c}^T = h( \alpha(A^p) \bm{V}^p \bm{H}_s^p {\bm{V}^p}^T),
\end{equation}
where $\bm{V}^c$, $\bm{V}^p$, $\bm{H}_s^c$, and $\bm{H}_s^c$ represent the orthonormal matrices and the diagonal matrices containing the configuration dependence eigenvalues of the collaborator and the partner, respectively. The arm configurations of two individuals remain corresponding during human demonstrations, which makes the variation of $\bm{V}$ and $\bm{H}_s$ basically unchanged along the movement from one demonstration to another. Hence, the variation of the regulatory factor during tasks will be learned between the two synergistic contributions of the muscle co-contractions $\alpha(A^c)$ and $\alpha(A^p)$.

\begin{figure}[!tbp]
\centering
\includegraphics[width=0.9\linewidth]{lstm_results_overall.jpg} 
\caption{LSTM model training and testing for regulatory factor learning. \textit{I:} collaborative transportation, \textit{II.A:} Tai Chi unimanual flat circle pushing.}
\label{Fig.lstm_box} \vspace{-4mm}
\end{figure}

Machine learning has a high potential to build the implicit model between two individuals in collaboration, especially for those tasks with periodicity \cite{mukherjee2022survey}. We propose to use a Long-Short-Term-Memory (LSTM) neural network for regulation policy learning since the data of muscular synergistic contributions are strictly based on time series during the demonstrations \cite{semeraro2023human}. Specifically, the data will constitute the form with the LSTM function as $h: X \rightarrow Y$. A loss function will be defined to evaluate the performance of the model by comparing the predicted outputs with the actual results. 

The synergistic contribution values of the partner and collaborator are chosen as the inputs and outputs of the network model, respectively. LSTM is sensitive to the scale of the input data, especially when using the sigmoid activation function. Hence, we normalize the raw data to a range of $[0, 1]$ as inputs and reverse the predictive outputs from the model for better training. Note that 67\% of the demonstration data will be used for training while the remaining 33\% will be used for testing. We connect multiple sets of demonstration data of one specific task end to end to form the dataset for model construction. One example of the model training and testing results was given in the upper part of Fig. \ref{Fig.lstm_box}, which shows the comparison between the predicted muscle synergistic contributions and the ground truth values of the collaborator during object transportation demonstration. We applied Root Mean Squared Error (RMSE) to evaluate the accuracy of predictions with the LSTM network. The prediction performance of the testing set (RMSE: 8.98) is basically consistent with that of the training set (RMSE: 8.22). \vspace{-4mm}

\subsection{Whole-Body Impedance Controller} \label{whole-body} 
A whole-body Cartesian impedance controller of CURI is introduced to achieve human-robot collaboration. CURI is a Dual-Arm mobile platform (as shown in Fig. \ref{Fig.framework}) with one velocity-controlled 3-DoFs Robotnik SUMMIT-XL STEEL mobile base, one velocity-controlled 3-DoFs self-designed torso, and two torque-controlled 7-DoFs Franka Emika Panda robotic arms. In this paper, the robotic arms and the torso were considered and the corresponding whole-body impedance controller was designed.

A force-torque interface is preferred since we target to implement a whole-body impedance control law. Hence, we design Cartesian admittance controllers based on the velocity interface for the torso. Considering that the torso applies high-gain velocity controllers to realize the admittance dynamics. All disturbances including the external dynamic effect from the arms and the coupling dynamics from the torso are assumed to be compensated by these controllers. 

The whole-body decoupled dynamics can be written as:
\begin{equation}\label{whole-body-dynamic}
\begin{small}
\setlength{\arraycolsep}{0.5pt}
\begin{aligned}
    &\left ( \begin{matrix}
    \bm{M}_{t}^{adm} & \bm{0} & \bm{0}\\
      \bm{0} & \bm{M}_{al} & \bm{0}\\
      \bm{0} & \bm{0} & \bm{M}_{ar}
    \end{matrix} \right ) \left ( \begin{matrix}
      \bm{\Ddot{q}}_{t}\\
      \bm{\Ddot{q}}_{al} \\
      \bm{\Ddot{q}}_{ar} 
    \end{matrix} \right ) + \left ( \begin{matrix}
      \bm{0}\\
      \bm{G}_{al}\\
      \bm{G}_{ar}
    \end{matrix}\right ) +\\
    &\left ( \begin{matrix}
        \bm{D}_{t}^{adm} & \bm{0} & \bm{0}\\
        \bm{0} & \bm{C}_{al} & \bm{0}\\
        \bm{0} & \bm{0} & \bm{C}_{ar}
    \end{matrix} \right )\left ( \begin{matrix}
      \bm{\dot{q}}_{t}\\
      \bm{\dot{q}}_{al}\\
      \bm{\dot{q}}_{ar}
    \end{matrix}\right )
    = \left ( \begin{matrix}
      \bm{\tau}_{t}^{vir}\\
      \bm{\tau}_{al}\\
      \bm{\tau}_{ar}
    \end{matrix}\right ) + \left ( \begin{matrix}
      \bm{\tau}_{t}^{ext}\\
      \bm{\tau}_{al}^{ext}\\
      \bm{\tau}_{ar}^{ext}
    \end{matrix}\right ),
\end{aligned}
\end{small} 
\end{equation}
where $\bm{\dot{q}}_{t} \in \mathbb{R}^{3}$ represent the velocities expressed in the joint space of the torso. $\bm{M}_{t}^{adm} \in \mathbb{R}^{3\times 3}$ and $\bm{D}_{t}^{adm} \in \mathbb{R}^{3\times 3}$ are respectively the virtual inertial and virtual damping set for the torso in the admittance controllers. $\bm{\tau}_{t}^{vir} \in \mathbb{R}^{3}$ and $\bm{\tau}_{t}^{ext} \in \mathbb{R}^{3}$ are respectively the commanded and the external torques for the torso. $\bm{q}_{al}, \bm{q}_{ar} \in \mathbb{R}^{7}$ represent the joint angles of the left robotic arm and the right robotic arm, respectively. $\bm{M_{al}}, \bm{M_{ar}} \in \mathbb{R}^{7 \times 7}$, $\bm{C_{al}}, \bm{C_{ar}} \in \mathbb{R}^{7}$, and $\bm{G_{al}}, \bm{G_{ar}} \in \mathbb{R}^{7}$ are the inertia matrix, gravity term, Coriolis and centrifugal terms for the two arms, respectively. $\bm{\tau}_{al}, \bm{\tau}_{ar} \in \mathbb{R}^{7}$ and $\bm{\tau}_{al}^{ext}, \bm{\tau}_{ar}^{ext} \in \mathbb{R}^{7}$ are the commanded and the external torques for the robotic arms, respectively. 

CURI has two Tool Center Points (TCPs) corresponding to the left and right robotic arm, respectively. Hence, the CURI can be split into two chains based on the two TCPs with shared parts (torso). Equation (\ref{whole-body-dynamic}) can be rewritten as:
\begin{equation}\label{decoupled dynamics}
  \bm{M}_{i}(\bm{q}_{i})\bm{\ddot{q}}_{i} + \bm{C}_{i}(\bm{q}_{i}, \bm{\dot{q}}_{i})\bm{\dot{q}}_{i} + \bm{g}_{i}(\bm{q}_{i})
    = \bm{\tau}_{i} + \bm{\tau}_{i}^{ext}, \quad  i = l, r
\end{equation}
where $\bm{q}_{i} = \left ( \begin{matrix} \bm{q}_{t}^T \ \bm{q}_{ai}^T \end{matrix} \right )^T$ represents the joint angles vector of the chain $i$, $\bm{M}_{i}(\bm{q}_{i})$ is the corresponding joint-space inertia matrix, $\bm{C}_{i}(\bm{q}_{i}, \bm{\dot{q}}_{i})$ is the Coriolis/centrifugal matrix, and $\bm{g}_{i}(\bm{q}_{i})$ the vector of gravity. $\bm{\tau}_{i}$ and $\bm{\tau}_{i}^{ext}$
represent the corresponding control input and external torque in joint space, respectively.

Once the robot dynamic (\ref{decoupled dynamics}) and impedance model (\ref{impedance model}) are given, the Cartesian impedance controller proposed in \cite{ott2008cartesian} can be extended to CURI, while its stability can also be guaranteed. The whole-body impedance controller generating high-level torque command for each chain $\tau_{i}$ ($i = l, r$) can be expressed as:
\begin{equation}\label{whole-body-impedance-controller}
\begin{aligned}
    \left ( \begin{matrix}
      \bm{\tau}_{t}^T &
      \bm{\tau}_{ai}^T
    \end{matrix} \right )^T = \bm{\tau}_{i}^{task} + \bm{\tau}_{i}^{null}.
\end{aligned}
\end{equation}

The $\bm{\tau}_{i}^{task}$ corresponding to the given main task is:
\begin{equation}\label{whole-body-impedance-controller-main-task}
    \bm{\tau}_{i}^{task} = \bm{J}_{i}^{T}(-\bm{K}_{i}^{d}(\bm{{x}_{i}}-\bm{{x}_{i}}^{d})-\bm{D}_{i}^{d}\bm{\dot{x}}_{i}),
\end{equation}
where $\bm{J}_{i} \in \mathbb{R}^{6 \times 10}$ represents the Jacobian matrix corresponding to each chain. 

The null-space task input is defined as:
\begin{equation}\label{null_space_torque}
    \bm{\tau}_{i}^{null} = (\bm{I} - \bm{J}_{i}^T\bm{J}_{i}^{+T})\bm{\tau}_{i}^{0},
\end{equation}
where $\bm{\tau}_{i}^{0}$ represents the corresponding torque projected in the null space of the main task, $\bm{N}(\bm{q}_{i}) = \bm{I} - \bm{J}_{i}^T\bm{J}_{i}^{+T} \in \mathbb{R}^{10 \times 10}$ is the projection matrix in order to prevent interference with the Cartesian impedance behavior of the main task according to \cite{khatib1987unified}. $\bm{J}_{i}^{+}$ expresses the generalized inverse of $\bm{J}_{i}$.

Finally, after obtaining the designed torques $\bm{\tau}_{i} = \left ( \begin{matrix} \bm{\tau}_{t}^T \ \bm{\tau}_{ai}^T \end{matrix} \right )^T$, $\bm{\tau}_{ai}$ is sent to the robotic arm directly through its torque command interface. As the torso received velocity command only, the $\bm{\tau}_{t}$ can generate the velocity command $\bm{\dot{q}}_{t}$ through the corresponding admittance interfaces in (\ref{whole-body-dynamic}).

The above formulation allows us to control one chain of CURI at a time. However, it may cause conflicts when we are supposed to control both chains at the same time since the torso are shared parts. To address this problem, we propose a leader-follower method regarding the two chains. Assuming the left arm as \textit{leader-arm}, the whole-body impedance controller for its corresponding chain can be designed with $\bm{\tau}_{l}^{0}$ in (\ref{null_space_torque}), which is generated by some predefined sub-tasks, i.e., optimizing the joint configuration for the robotic arm \cite{dietrich2016whole}. This paper defines the sub-task as the torso movement strategy based on human demonstrations. Specifically, the cobot torso is supposed to move in the same direction as the demonstrator's trunk at different stages of the task \cite{neo2007whole}. Then the calculated $\bm{\tau}_{t}$ and $\bm{\tau}_{al}$ of the \textit{leader-arm} can be treated as a sub-task of the controller corresponding to the right chain of CURI, whose corresponding arm is named as \textit{follower-arm}. The $\bm{\tau}_{r}^{0}$ of \textit{follower-arm} can be chosen as:
\begin{equation}
    \bm{\tau}_{r}^{0} = \left ( \begin{matrix}
  \bm{\tau}_{t}^T, \
  \bm{0}_{1\times 7}
\end{matrix} \right ).
\end{equation}

This impedance model allows us to change the cobot physical behavior by varying both the damping and stiffness while tracking the reference trajectory according to the task requirements. In order to avoid instability of the impedance control method due to arbitrary variations in impedance parameters, some passivity conditions of the varying impedance parameters should be satisfied to guarantee system stability \cite{kronander2016stability}. Under the circumstances that the conditions are met, the calculated impedance variables $\bm{K}^d_r$ and $\bm{D}^d_r$ from cobot reference trajectory and stiffness generation module can be fed into the controller to perform expected physical behaviors.

\section{Experiments}\label{V}

Two typical tasks were introduced to verify the performance of the proposed learning framework under leader-follower mode and mutual adaptation mode, respectively. The comparative experiments of the proposed variable impedance control method and a constant impedance control method have illustrated the advantages of our method.

\subsection{Endpoint Stiffness Parameter Calibration}
We designed perturbation experiments to identify the parameters of each demonstrator, which will be further applied to extract the endpoint stiffness during human-human demonstrations. The experimental setup is illustrated in Fig. \ref{Fig.calibration setup}. We used one arm of the CURI for parameter identification, which includes a force/torque (F/T) sensor (SRI, 100 $Hz$) connecting the handle and the end effector. An optical system (Optitrack, 120 $Hz$) was applied to track the poses of the shoulder, elbow, and wrist by attaching markers to these human parts. Besides, a wireless EMG device (Delsys Trigno, 2000 $Hz$) and a monitor were used to visualize the real-time muscle co-contraction. 

We chose BB and TB on the upper arm as antagonistic muscles to calculate the co-contraction level as mentioned in Section \ref{modeling}. Specifically, the raw EMG signals were collected and processed using a lowpass filter with a frequency of 50 $Hz$ to eliminate noise. Then the activation level of each muscle was normalized by MVC. Note that the values of each muscle MVC were acquired before the experiment. Finally, the co-contraction level was calculated based on (\ref{cocontraction}). 

\begin{figure}[!tbp]
\centering
\includegraphics[width=0.98\linewidth]{calibration_setup_new.png} \vspace{-4mm}
\caption{Experimental setup for endpoint stiffness parameters calibration. Six different human arm configurations $a-f$ were selected for calibration through physical human-robot interaction. (We declare that the individual in this figure is author and he gave permission for the use of his image.)}
\label{Fig.calibration setup} \vspace{-4mm}
\end{figure}

During perturbation experiments, a trajectory with perturbations in six directions ($x$, $y$, $z$, $xy$, $xz$, $yz$) was given for each test. The order in which these perturbations appear was randomized to avoid subject adaptation. The peak displacement of each perturbation in one trial was set as 0.02 $m$ while the duration was 0.5 $s$. We have tested six arm configurations with three different muscle co-contraction levels of each configuration, which are minimum co-contraction, 20\% MVC, and 40\% MVC. Note that we applied Biodex system to get the MVC values of the target muscles. Hence, the total number of trials for each subject was 18 during stiffness parameters calibration. The parameters ${a_1, a_2, b_1, b_2}$ of two subjects in this paper were given as follows in Table \ref{tab1}.

\begin{table}[h]
\caption{human endpoint stiffness parameters}
\begin{center}
\begin{tabular}{c|cccc}
\hline
\small{Subject} & \small{\textit{$a_1$}} &  \small{\textit{$a_2$}} &  \small{\textit{$b_1$}} &  \small{\textit{$b_2$}} \\
\hline
\small{Subject 1} & \small{0.272} &  \small{1.314} & \small{3847.141} & \small{151.684}   \\
\small{Subject 2} & \small{0.107} & \small{2.200} & \small{2678.765} & \small{149.597}  \\
\hline
\end{tabular}
\label{tab1}
\vspace{-4mm}
\end{center}
\end{table}

\begin{figure*}[t]
\centering
\includegraphics[width=0.95\textwidth]{demo_setup_overall.png} \vspace{-4mm}
\caption{\textit{Data collection setup:} Two individuals with endpoint stiffness calibration were attached to the Optitrack markers on their arm joints while the co-contraction muscle signals were recorded by EMG sensors. F/T sensors were attached to the object. The snapshots of human-human demonstration. \textit{I:} collaborative transportation, \textit{II.A:} Tai Chi unimanual flat circle pushing, \textit{II.B:} Tai Chi bimanual vertical circle pushing. (We declare that the individuals in this figure are both authors and they gave permission for the use of their image.)} 
\label{Fig.demonstration_transportation} \vspace{-2mm}
\end{figure*}

\begin{figure*}[t]
\centering
\setlength{\abovecaptionskip}{0.cm}
\includegraphics[width=0.95\textwidth]{tpgmm_overall.jpg} 
\caption{Learning results for motion/impedance representation and generation by TP-LQT method are illustrated. GMM is firstly adopted in coordinates 1 and 2 to cluster points into multiple Gaussian distributions and represent the demonstrations with PoE \textit{(a-c)}. By considering the task parameter with a new situation, a trajectory is generated via PoE \textit{(d)}. Finally, the corresponding stiffness ellipses are drawn along the generated trajectory in $xy$ and $xz$ plane with the LQT method \textit{(e-f)}. \textit{I:} collaborative transportation, \textit{II.A:} Tai Chi unimanual flat circle pushing. } 
\label{Fig.tpgmm_boxcarrying}\vspace{-5mm}
\end{figure*}

\subsection{Collaborative Transportation Task}
\subsubsection{Task Definition}

The first task is human-robot collaborative transportation, which consists of teaching the CURI to manipulate and transport an object by following the human partner while dealing with the position and impedance constraints (as shown in Fig. \ref{Fig.demonstration_transportation}). Specifically, they will collaboratively lift, translate, and lower the object to the target pose under leader-follower mode. It is worth noting that the start and the end poses of the object are not fixed during demonstrations. We propose to teach the cobot follower to perform consistent compliance behavior as the human leader (shown in Fig. \ref{Fig.physical collaboration skill}).

We use the CURI as the cobot which was introduced in Section \ref{whole-body} as shown in Fig. \ref{Fig.framework}. The robotic hand of qb SoftHand2 Research was applied as the end effector. For the software development, a whole-body Cartesian impedance control interface was implemented based on section \ref{whole-body} in ROS. By giving the commanded impedance matrices and the reference trajectory with an update frequency of 100 $Hz$, the controller outputted the commanded torques of each joint for the robotic arms and calculated joint velocities for torso joints to generate expected motions with a frequency of 1000 $Hz$. Note that the gravity compensation was redesigned due to the unique installations of the dual arms. 

\subsubsection{Trajectory and Impedance Generation from Demonstration}
The demonstration data of the collaborative transportation task were recorded by the Optitrack system, EMG sensors, and force sensors with the corresponding software. The demonstrators' motions were obtained from the Optitrack markers, which were fixed on the human joints at a frequency of 120 $Hz$ (shown in Fig. \ref{Fig.demonstration_transportation}). The data were used for offline learning to generate a proper representation of the cobot motions. Besides, the demonstrators were wearing two EMG sensors on the upper body (same positions as the calibration process) to record the muscle activities. The recording and processing procedures of EMG signals were the same as the calibration part. These data were used for human endpoint stiffness estimation during the demonstration. The reference trajectories were then calculated based on the human endpoint motion, stiffness, and interactive force by (\ref{eq3}). 

As shown in Fig. \ref{Fig.tpgmm_boxcarrying}, we utilized three calculated reference trajectories of human demonstrations in GMM. The result of the representation with regard to the PoE was illustrated for the object transportation task. Furthermore, by adding the task parameter and extending to TP-GMM, the motion reproduction was achieved with new initial and final poses of the reference trajectory and the generated reference trajectory was given. Besides, the corresponding stiffness variables along the trajectory were calculated based on the LQT method. Finally, the LSTM model was built to learn the regulation policy between the two demonstrators (shown in Fig. \ref{Fig.lstm_box}).

\begin{figure*}[!t]
\centering
\includegraphics[width=0.95\textwidth]{exp_box_carrying.png} \vspace{-2mm}
\caption{The snapshots of human-robot collaborative object transportation with our proposed method and a constant impedance method. (We declare that the individual in this figure is author and he gave permission for the use of his image.)}
\label{Fig.exp_box_carrying} \vspace{-2mm}
\end{figure*}

\begin{figure*}[!t]
\centering
% \setlength{\abovecaptionskip}{0.cm}
\includegraphics[width=0.95\textwidth]{results_box_carrying_new.jpg} \vspace{-3mm}
\caption{The comparison of cobot movement and interactive force on CURI right end effector between the constant impedance method (orange solid line) and our proposed method (blue solid line) in three directions. The results of two different trials are given.} 
\label{Fig.force_box_carrying} \vspace{-4mm}
\end{figure*}

The collection and preprocessing of the multimodal demonstration data such as IMU and EMG signals, and the implementation of the TP-GMM and LQT methods depend on the Rofunc package, a full-process python package for robot learning from demonstration published by our lab \cite{Rofunc2022}.

\subsubsection{Experimental Results}
In real world human-robot experiments shown in Fig. \ref{Fig.exp_box_carrying}, the human-like cobot, CURI, was equipped with an Optitrack marker behind its torso to obtain the poses of the end effector in the world coordinates. These data were transferred into a rosbag format through data streaming. Hence, the movements of CURI were transformed into the cobot coordinates by mapping between the marker and the end effector. The execution of whole-body motion (arm and torso in this paper) was based on the reference trajectories and the corresponding impedance profiles of the end effector learned offline from demonstration via TP-LQT method. The human partner was wearing the EMG sensors during the experiments to monitor the muscle co-contraction, which was used to calculate the regulatory parameters of the cobot based on the regulation policy. 

The snapshots of the human-robot collaborative object carrying task with our proposed method were given in the upper part of Fig. \ref{Fig.exp_box_carrying} with both side and top views. The cobot and the human partner successfully lifted the object from the initial position, translated the object, and lowered the object to the target position. The movement of the human-robot collaboration in these three stages was similar to the human-human demonstration. We also performed a comparative experiment with the same reference trajectory while the impedance of the end effector was set as constant ($K^d$ = 300 $N/m$ and $D_d$ = 34.64 $N/{m^2}$) in all three directions. Note that it was a common way to verify the effectiveness of the proposed method \cite{9362246}. The snapshots of the experimental results were illustrated in the lower part of Fig. \ref{Fig.exp_box_carrying}. We found that the object was pulled too much to the cobot side during the translating stage, which made the object deviate from the demonstration range (indicated by the red solid circles in Fig. \ref{Fig.exp_box_carrying}). 

\begin{figure*}[t]
\centering
\includegraphics[width=0.92\textwidth]{exp_tai_chi.png} \vspace{-2mm}
\caption{The snapshots of human-robot confrontational Tai Chi pushing hands with both side and top views. \textit{II.A:} Tai Chi unimanual flat circle pushing hand, \textit{II.B:} Tai Chi bimanual vertical circle pushing hands. (We declare that the individual in this figure is author and he gave permission for the use of his image.)}
\label{Fig.exptaichi} \vspace{-4mm}
\end{figure*}

We have recorded the interactive force from the cobot side by the force sensor to further verify the advantage of our approach during the experiments. The end effector movement in Cartesian space was also calculated based on the forward kinematics of the CURI. The results were plotted in Fig. \ref{Fig.force_box_carrying}, which include two trials with different start and end poses. We can find out that the movements generated by the constant impedance method were closer to the cobot side, which caused the issue mentioned above. When comparing the interaction force of the cobot end effector during the collaboration, the trends were smoother by using our proposed approach. The average interactive forces in three directions were also calculated and shown in Table \ref{tab2}. The average force on each axe was similar between the two methods in trial 1 while the average interaction force of our proposed method was smaller than the constant one (especially on the $Z$-axes) in trial 2. This phenomenon shows the advantage of the proposed method to some extent.

\begin{table}[htbp]
\caption{average interactive forces comparison} \vspace{-4mm}
\begin{center}
\begin{tabular}{c|cc|cc}
\hline
&\multicolumn{2}{c|}{\small{Trial 1} } & \multicolumn{2}{c}{\small{Trial 2}} \\
\hline
 & \small{constant} &  \small{\textbf{proposed} ($N$)} &  \small{constant} &  \small{\textbf{proposed} ($N$)}\\
\hline
\small{X} & \small{2.08} & \small{\textbf{1.78}} & \small{2.75} & \small{\textbf{1.26}}  \\
\small{Y} & \small{3.19} & \small{\textbf{2.54}} & \small{\textbf{2.46}} & \small{2.81}  \\
\small{Z} & \small{3.80} & \small{\textbf{2.74}} & \small{7.63} & \small{\textbf{3.29}}  \\
\hline
\end{tabular}
\label{tab2}
\vspace{-4mm}
\end{center}
\end{table}

% \begin{figure*}[ht]
% \centering
% \includegraphics[width=0.9\textwidth]{tpgmm_taichi_overall.jpg} 
% \caption{Learning results for motion representation and generation by TP-LQT method is illustrated with respect to the unimanual flat circle and the bimanual vertical circle pushing task. GMM is firstly adopted in coordinates 1 and 2 to cluster points into multiple Gaussian distributions and represent the demonstrations with PoE (a-b). By considering the task parameter (end-to-end motion trajectories in our tasks), a trajectory is reproduced via PoE (c). Then, an LQT method is applied to re-generate movement for the cobot by corresponding the stiffness ellipses (d-f).} 
% \label{Fig.learning results}\vspace{-4mm}
% \end{figure*}

\begin{figure*}[t]
\centering
\setlength{\abovecaptionskip}{0.cm}
\includegraphics[width=0.95\textwidth]{result_tai_chi_new.jpg} \vspace{-2mm}
\caption{The comparison of average interactive forces on CURI end effectors between a constant impedance control method with orange line and our proposed method with blue line in three directions. \textit{II.A:} Tai Chi unimanual flat circle pushing hand, \textit{II.B:} Tai Chi bimanual vertical circle pushing hands.} 
\label{Fig.force_taichi} \vspace{-3mm}
\end{figure*}

\subsection{Tai Chi Pushing Hands Task}
\subsubsection{Task Definition}

The second task is Tai Chi pushing hands, which is widely known as a popular Chinese kong-fu because of its health benefits, especially for elders. As the basis of the pushing hands, the fixed step involves pushing motions in flat circles, vertical circles, and `8'-shaped circles \cite{wang2016biomechanical}. In this paper, unimanual pushing of flat circles and bimanual pushing of vertical circles are selected for human-robot collaboration shown in Fig. \ref{Fig.demonstration_transportation}.

The physical behaviors of the two individuals being confronted were discovered to be mutually adaptive during Tai Chi pushing hands (see Fig. \ref{Fig.demonstration_transportation}). More specifically, when showing pushing motions, one individual has a stiff behavior to interacting by hands while the other performs quite compliant on the first half of the motion path. Conversely, the roles of these two individuals have switched on the return. Hence, the cobot has to generate regulatory compliance behavior compared to the human partner in each stage of Tai Chi, which will be learned from the impedance regulation module. 

% \begin{figure}[t]
% \centering
% \setlength{\abovecaptionskip}{0.cm}
% \includegraphics[width=1\linewidth]{demo_tai_chi.png} 
% \caption{Human-human demonstrations of Tai Chi pushing hands are illustrated. Two types of Tai Chi pushing hands with fixed steps are defined and demonstrated by two individuals, which includes the motion of unimanual flat circle pushing (repetition of $a \, \rightarrow \, b \, \rightarrow \, c \, \rightarrow \, d$) and bimanual vertical circle pushing (repetition of $e \, \rightarrow \, f \, \rightarrow \, g \, \rightarrow \, h$). (We declare that the individuals in this figure are both authors and they gave permission for the use of their image.)}
% \label{Fig.demo_taichi} \vspace{-2mm}
% \end{figure}

\subsubsection{Trajectory and Impedance Generation from Demonstration}
The data collection setup of confrontational Tai Chi pushing hands was the same as the collaborative transportation task (shown in Fig. \ref{Fig.demonstration_transportation}). Two sub-tasks including the unimanual flat circle and bimanual vertical circle pushing hands were performed by two human demonstrators. Since we only calibrated one upper arm of each demonstrator, the parameters of the other arm were set to the same values as the calibrated one for simplification in the bimanual task. 


% We applied two frames of the human demonstrations in GMM to represent the movement shown in Fig. \ref{Fig.learning results}. The result of the representation with regard to the PoE was illustrated for the unimanual flat circle pushing task and the bimanual vertical circle pushing task. Furthermore, by extending to TP-GMM by adding the task parameter, the motion reproduction was achieved with an end-to-end trajectory and was shown in Fig. \ref{Fig.learning results} (d). Then the trajectory for robot execution in HRI was calculated with LQT based on the motion generation and corresponded with the stiffness ellipses, which was shown in Fig. \ref{Fig.learning results} (e-f). 

The motion representation and generation results are shown in Fig. \ref{Fig.tpgmm_boxcarrying}. Besides, impedance regulation policies of both Tai Chi tasks were learned by the LSTM networks and one example of training and testing predictions was given in Fig. \ref{Fig.lstm_box}. The trained models were further applied to get the regulatory factors for the cobot to tune compliance during HRC.


\subsubsection{Experimental Results}
In the real-world experiments (as illustrated in Fig. \ref{Fig.exptaichi}), the setup of the cobot and the human partner was almost the same as the first one except two robotic arms were applied in the second Tai Chi task. 

The snapshots of two human-robot confrontational pushing hands with unimanual flat circle pushing and bimanual vertical circle pushing were shown in Fig. \ref{Fig.exptaichi}. In each motion cycle, CURI utilized the learned regulation policy and achieved the task within 10 $s$. During the unimanual arm pushing task, CURI initially exerted high impedance to push the human towards one side and subsequently reduced the pushing force in the latter half of the movement. In the bimanual pushing task, CURI dual arms adjusted their actions based on the co-contraction of human muscles, transitioning between different stages. For the two Tai Chi pushing hands tasks, the stiffness and damping variables of one or two end effectors in Cartesian space were modified according to regulation policies. Specifically, during the unimanual flat circle pushing, CURI right arm maintained high stiffness and damping in the initial phase and decreased the impedance in the latter half. Similarly, in the bimanual pushing tasks, the impedance variations mirrored those of the right arm with stage transitions, while exhibiting opposite behaviors in the left arm. 

% \begin{figure}[!t]
% \centering
% \setlength{\abovecaptionskip}{0.cm}
% \includegraphics[width=0.9\linewidth]{lstm results_tai chi.jpg} 
% \caption{Results of LSTM model training and testing for regulation policy learning for the unimanual pushing and the bimanual pushing task.}
% \label{Fig.lstm_taichi} \vspace{-4mm}
% \end{figure}

Our proposed method was evaluated against a constant impedance control method through four repetitions of these human-robot collaboration tasks. Comparative analysis of the average interactive forces between the end effector and the human hand in three directions relative to the impedance frame of the robotic arm is presented in Fig. \ref{Fig.force_taichi}. In both tasks, the trends in average interactive forces were similar. However, the amplitudes of these forces were greater when utilizing our proposed method, compared to the smaller forces observed with the constant impedance control method, particularly in the directions of movement. This experimental outcome demonstrates that our method enables the cobot to exhibit more appropriate physical behaviors during human-robot collaboration, thereby facilitating more effective interactions between humans and cobots. \vspace{-2mm}

 % One cycle for each motion was displayed within 10$s$. With the learned adaptive skill policy, CURI performed with high impedance to push the human to his side in the first half of the movement and passively pushed back to its side in the second half during the single arm pushing task. Similarly, CURI dual arm switched between different stages according to the co-contraction of the human muscles during the bimanual pushing task. The changing of stiffness and damping variables of one/two end effectors in Cartesian space during the two Tai Chi pushing hands tasks were given according to the adaptive policies. It was shown that during the unimanual flat circle pushing, CURI's right arm performed stiffly with relatively high stiffness and damping values in the first half while lowering the impedance values in the second half. The impedance variations of the bimanual pushing tasks exhibited a certain degree of similarity with the right arm switching between different stages while the right arm generated an opposite behavior (Fig. \ref{Fig.lstm_taichi}). Besides, our proposed method was compared with a constant impedance control method through these human-robot collaboration tasks with four repetitions. The comparison of average interactive forces between the end effector and the human hand in three directions w.r.t. the impedance frame of the robotic arm was given in Fig. \ref{Fig.force_taichi}.

\section{Conclusions}\label{VI} 

In this paper, we propose a novel learning from demonstration framework to acquire impedance regulation skills from human-human collaboration. By calibrating the human dynamic model, the endpoint stiffness can be estimated. The reference trajectories are then calculated based on the interaction model with these measured data. A TP-LQT method is proposed to represent human movements and generate a new reference trajectory for the cobot under new situation. Besides, the impedance regulation skills of each task are learned through the LSTM networks to construct the regulation modules. Finally, we apply a human-like cobot CURI to human-robot collaboration tasks that perform object transportation and Tai Chi pushing hands with a human partner. We propose a whole-body impedance controller for this unique cobot and put forward a variable impedance control method based on the human-human demonstration. The real-world platform we built successfully achieved the collaborative object transportation task and Tai Chi pushing hands tasks, which will be a foundation of future research in HRC. The overall framework we propose to let the cobots learn impedance regulation skills from human-human demonstration can be extended to other tasks with variable physical behaviors and repetitive actions. For instance, the collaborative carrying of objects in logistic scenarios and the assistive dressing of clothes in domestic scenarios are feasible applications to achieve.

In this study, we limited our analysis to only the arms and torso of our cobot during collaboration, which constrains the cobot workspace and functional capacity to some extent. Additionally, considerations of human safety and physical ergonomics were not addressed by the cobot. To enhance task execution, our future work will incorporate a capture system that includes feedback on human kinematics and dynamics. Moreover, the current setup for human-human demonstrations is complex, and the transferability of learned behaviors from one task to another remains underdeveloped. We plan to investigate novel data representations to extract richer and more relevant interaction information during collaborations, aiming to optimize the efficiency of demonstrations.


\bibliographystyle{ieeetr}
\bibliography{ref_hrc}

\vspace{11pt}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Chenzui}}]{Chenzui Li}
% received his B.S. in Physics at the Zhejiang University, Zhejiang, China in 2017, M.S. in Control Science and Engineering at the Zhejiang University, Zhejiang, China in 2020. He joined the Mechanical and Automation Engineering at the Chinese University of Hong Kong, Hong Kong, China, in 2022, where he is currently a Ph.D. student. His research interests include Robotics, Interactive Control, and Human-Robot Collaboration.
% \end{IEEEbiography}

% \vspace{11pt}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig1.png}}]{IEEE Publications Technology Team}
% In this paragraph you can place your educational, professional background and research and other interests.\end{IEEEbiography}

\end{document}
