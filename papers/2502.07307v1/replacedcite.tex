\section{Related Work}
% 分为两类， short-term and long-term
\textbf{Evaluation of RS}. How to evaluate RS is a complex and essential task, which can be divided into short-term and long-term evaluation based on their objectives____. Most current studies focus on the short-term objective using offline metrics____, relying on pre-collected log data containing users' explicit (e.g., ratings) or implicit (e.g., click) feedback to compute metrics like prediction accuracy____ and ranking metrics____. 
Existing fairness-aware____, debiasing____, and diversity-aware____ recommendation research often evaluates using domain-specific indicators based on these short-term metrics (e.g., fairness metric____, ), which fail to adequately reflect their long-term benefits and how they influence RS in the long run, particularly in multi-stakeholder platform environments____.
Due to the inefficiency and high cost of long-term online A/B test____, offline long-term evaluation has gained significant attention in recent years, which can be divided into two main categories: (1) use short-term metric____ or data____ to predict long-term performance, (2) create an RS simulator to replicate the real-world environment____ for evaluation.
In this paper, we focus on the second type. 
% Existing RS simulators use Reinforcement Learning (RL)____ or LLM____ to simulate human behavior. 

\textbf{RS simulator for long-term evaluation.} 
Most existing recommendation simulators (e.g., LLM-based simulator____, reinforcement learning (RL)-based simulator____) focus on user simulation while overlooking creators, making it difficult to capture the long-term dynamic of content platforms.
Some data-driven methods are proposed to conduct creator simulation.  SimuLine____ applied heuristic methods to determine creators' next creation in news recommendation. 
Some works____ assumed that creators will leave the platform if their user engagement falls below a certain threshold.
Other modeling methods used user positive feedback (e.g., click) as the gradient to update the creation state____.
% EcoAgent____ and RecSim NG____ utilized RL-based techniques (e.g., Markov Stochastic Process____ and Decision Process ____) to model the transition behavior of creators. 
However, these approaches failed to align with real creation behavior because: (1) they are unable to produce authentic content (e.g., text), instead relying on embeddings to represent the content they create____; (2) they cannot capture the personalization of real-world creators; (3) they ignored human behavior patterns under information asymmetry, such as risk aversion in prospect theory____ and bounded rationality____.
% However, RL-based simulators for RS evaluation may be limited in flexibility and generality, as they often rely on relatively simple rules to model behaviors that could diverge from actual human____. 
% Recently, LLM-empowered agents have shown great promise in enhancing recommendation simulators____.
% For example,
% RecAgent____ and Agent4Rec____ incorporated human cognitive mechanisms (e.g., memory mechanism) to simulate various user behaviors on the platform.
% AgentCF____
% modeled user and item agents simultaneously to explore the interaction patterns between users and items.

% For example, LLM-based simulator RecAgent____ and Agent4Rec____, Reinforcement Learning (RL)-based simulator Virtual-Taobao____, RecSim____ solely focus on simulating user's watch, click behaviors.
% % EconAgent____ utilized Markov decision process to model both user and creator behavior to help build a multi-stakeholder recommender. 

% previous research____ has indicated that

% For example, RecoGym____ provides a configurable stylized RS simulation environment for studying sequential user interaction.
% Virtual Taobao____ and RecSimu____ utilized generative adversarial networks (GAN) to generate virtual users to support learning policies that can be transferred to real systems
% RecSim____ provides a comprehensive toolkit for effectively simulating user behaviors across various stylized RS.





\textbf{Behaviors under information asymmetry.} Creator behaviors in information asymmetry conditions
have been actively studied and emphasized in the game theory literature____. 
They typically assume that creators are totally rational, i.e., aiming to maximize their utility, which often lacks personalization and differs from real-world human behavior under risk (i.e., bounded rational____). Rule-based____ and heuristic method____ are applied to model the strategic behavior. These studies mainly focus on the competition among creators____ and the design of better platform mechanisms____ to maximize user welfare.

% These works have greatly inspired our study, e.g., ____ assumed that creator create content based on their beliefs about their skills and audience.
% These works are unsuitable as RS evaluators for three reasons: (1) absence of explicit RS modeling____; (2) use of artificial feedback like relevance scores____ instead of real user responses (e.g., clicks and views); and (3) oversimplified modeling of creator behavior____, deviating from real-world human patterns____.


% ____  used a mixed-integer-programming-based prompting policy to minimize the impact of information asymmetry on the platform's social welfare.
% ____ formulated the recommendation problem as a constrained matching problem and assumed creators might leave the platform due to insufficient user engagement.