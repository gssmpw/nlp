\section{Related work}
\subsection{Masked image reconstruction}

Masked image modeling has emerged as a pivotal learning technique in computer vision \cite{he2022masked,yue2023understanding,zheng2023fast,chen2023improving,fu2024rethinking}. For instance, Masked Autoencoders \cite{he2022masked} learn to reconstruct missing patches given only a small subset of visible patches reducing computational cost. Masked Diffusion Transformer \cite{zheng2023fast} demonstrates enhanced training efficiency and generation results using a denoising diffusion objective on masked images. Cross-Attention Masked Autoencoders \cite{fu2024rethinking} used cross-attention in the decoder to query visible tokens for masked image patch reconstruction. The cross-attention component takes a weighted sum of the visible tokens across different input blocks to fuse the features for each decoder block, leveraging low-level information for reconstruction.

\subsection{Disentangled representation learning}

Disentangled concept learning \cite{bengio2013representation,higgins2017beta,locatello2019challenging,harkonen2020ganspace,alias2021neural,yang2022visual,sun2023associative,ismail2023concept} aims to uncover the underlying explanatory factors hidden within observed data. For example, methods such as $\beta$-VAE \cite{higgins2017beta} and FactorVAE \cite{kim2018disentangling} search for directions in the latent space that correlate with distinct human-interpretable concepts. Moreover, Concept Tokenization \cite{yang2022visual} focuses on learning disentangled object representations and inspecting latent traversals for various factors. Additionally, Concept Bottleneck models \cite{ismail2023concept,yuksekgonul2022post,oikarinen2023label,yang2023language} learn representations that correspond to specific human-understandable concepts. Energy-based methods \cite{du2020compositional,li2022energy} aim to compute energy functions of various concepts and combine their probability distributions achieving conjunctions, disjunctions, and negations of various concepts.
%However, identifying these diverse factors in the latent space can be tedious usually with extensive human effort. %In particular, supervised methods employ training data annotated with specific concept labels \cite{koh2020concept}. %Although there are a number of annotated datasets such as CelebA \cite{liu2015faceattributes}, the binary attribute labels in these datasets are restricted to simpler concept prediction tasks and reconstruction tasks from cross-modal representations usually necessitate learning projection networks or other more complicated architecture. 

Conventional concept learning methods typically rely on fully observable images for training. While masking strategies have proven effective in reducing computational cost in natural language processing, their usage in concept learning tasks remains underexplored. This is primarily because masking a large portion of image patches greatly limits the information available for disentangling effective concepts. To address this challenge, we integrate learnable concept tokens at various granularity levels into the masked reconstruction process using the asymmetric Multi-layer Concept Map (MCM) architecture. This approach could not only reduce computational cost for learning effective concepts but also enhance model's concept prediction capability. Our goal is to advance the masked concept learning objective, paving the way for more efficient model architectures.