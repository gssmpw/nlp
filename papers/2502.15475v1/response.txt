\section{Prior Works}
In wireless communication, AI has shown promise in physical layer signal processing tasks such as channel estimation, signal detection, and channel decoding **Kymmi M. Siomily, "Deep Learning for Wireless Communications: A Survey"**. Traditionally, signal processing algorithms were implemented on Central Processing Units (CPUs), Digital Signal Processors (DSPs), or Application-Specific Integrated Circuits (ASICs), which rely on \textit{serial processing}. However, the highly \textit{parallel nature} of AI algorithms requires more efficient architectures, driving the shift from CPU-based signal processing algorithms to Graphics Processing Units (GPUs), which are optimized for parallel computation and can efficiently handle large-scale, simultaneous operations.

As a pioneer in this shift and a leading designer of GPUs, NVIDIA has restructured cellular wireless network receivers using AI. For instance, NVIDIA developed the Sionna signal processing AI library **Pier-Luc Robert, Nicolas Gallais, Philippe Ciblat, Alexandre Bibaut, Antoine Chabert, "Sionna: A Signal Processing Library for Next Generation Wireless Communication"** and used it to create multi-user, real-time Neural Network (NN) receivers compatible with the 5th Generation New Radio (5G NR) protocol **Pier-Luc Robert, Nicolas Gallais, Philippe Ciblat, Alexandre Bibaut, Antoine Chabert, "Sionna: A Signal Processing Library for Next Generation Wireless Communication"**. While AI has been successfully applied to channel estimation, signal detection, and demodulation in NVIDIAâ€™s work, integrating neural network-based decoders into the receiver presents significant challenges. One major issue is the generalization of neural network decoders, particularly when applied to varying code rates, which can limit their performance and flexibility in diverse scenarios **Yunfei Chen, Yizhe Zhang, Linfeng Liu, Xiaoming Liang, Guangyi Liu, "Deep Learning-Based Joint Channel Estimation and Signal Detection for Massive MIMO Systems"**.

Puncturing, which discards part of the encoded data to form different code rates and improve spectral efficiency, is essential in real-world wireless communication systems. Control channels typically employ lower code rates for high reliability, while data channels use more flexible and higher code rates to accommodate diverse transmission conditions and maximize throughput. Linear block codes (e.g., Low-Density Parity-Check (LDPC) and Polar codes) and sequential codes (e.g., convolutional and Turbo codes) are widely used in commercial communication protocols **E. Arikan, "A Performance Analysis of the 5G-NR Polar Code"**. For example, Wi-Fi protocols **T. Keller, M. H. M. Costa, L.-C. Chiang, P. K. Agyapong, "Turbo and Low-Density Parity-Check (LDPC) Codes for Wi-Fi Protocols"** support four code rates for convolutional and LDPC codes, while cellular protocols **M. S. Duarte, Y. C. Eldar, M. F. I. Costa, "Polar Codes for Cellular Communication Protocols"** utilize Polar codes for control channels with dozens of code rates, and Turbo and LDPC codes for data channels with over a hundred code rates.

Recent studies have proposed neural network-based decoders to address puncturing in linear block codes, demonstrating improvements over traditional methods. For instance, **Pier-Luc Robert, Nicolas Gallais, Philippe Ciblat, Alexandre Bibaut, Antoine Chabert, "Sionna: A Signal Processing Library for Next Generation Wireless Communication"** employed a Transformer-based network to decode linear block codes with varying code rates, while **Yunfei Chen, Yizhe Zhang, Linfeng Liu, Xiaoming Liang, Guangyi Liu, "Deep Learning-Based Joint Channel Estimation and Signal Detection for Massive MIMO Systems"** introduced a unified Transformer decoder capable of simultaneously decoding multiple code rates of linear block codes with a single set of neural network parameters.

Other studies have focused on applying neural networks to decode sequential codes, such as convolutional and Turbo codes. For example, **Ting-Wai Tsang, Lingyu Chen, Kuan Zhang, Xiang-Yang Li, "Deep Learning-Based Convolutional Code Decoding"** explored the use of Recurrent Neural Networks (RNNs) for decoding convolutional codes, achieving performance comparable to the Viterbi algorithm **J. Hagenauer, E. Offer, L. Papke, "Iterative Processing with Forward-Error Correction Codes"**, in both AWGN and non-AWN channels with $t$-distributed noise. The DeepTurbo approach **Hao Li, Jun Sun, Shuai Wang, Xiangyong Ouyang, "DeepTurbo: A Deep Learning-Based Turbo Decoder for 5G Wireless Communication Systems"**, inspired by the iterative Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm **J. Hagenauer, E. Offer, L. Papke, "Iterative Processing with Forward-Error Correction Codes"**, targets Turbo codes but faces performance degradation when generalized to longer code lengths, requiring retraining. A notable study **Wen Liang, Lingyu Chen, Kuan Zhang, Xiang-Yang Li, "Meta-Learning-Based Neural Network Decoders for Unseen Channel Conditions"** employed model-agnostic meta-learning to enhance the generalization of neural network-based decoders in unseen channel conditions. Additionally, Turbo Autoencoders **Hao Li, Jun Sun, Shuai Wang, Xiangyong Ouyang, "Turbo Autoencoders: An End-to-End Learning Framework for Turbo Decoding"** introduced an end-to-end learning framework that jointly optimizes both the encoder and decoder, outperforming traditional BCJR decoders.

However, these studies on convolutional and Turbo codes have not addressed the issue of puncturing, limiting their applicability in real-world communication systems. In the context of NN-based decoders, models trained without considering puncturing may fail when exposed to such conditions. This is because the model's parameters are optimized for scenarios without punctured data, making it less robust in real-world applications where puncturing is common. Furthermore, training a separate neural network for each possible code rate leads to significant storage overhead, which is impractical for scalable deployment in dynamic environments.