@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{yang2024qwen2,
  title={Qwen2. 5 Technical Report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{fan2024fluid,
  title={Fluid: Scaling autoregressive text-to-image generative models with continuous tokens},
  author={Fan, Lijie and Li, Tianhong and Qin, Siyang and Li, Yuanzhen and Sun, Chen and Rubinstein, Michael and Sun, Deqing and He, Kaiming and Tian, Yonglong},
  journal={arXiv preprint arXiv:2410.13863},
  year={2024}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@article{li2024autoregressive,
  title={Autoregressive Image Generation without Vector Quantization},
  author={Li, Tianhong and Tian, Yonglong and Li, He and Deng, Mingyang and He, Kaiming},
  journal={arXiv preprint arXiv:2406.11838},
  year={2024}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@article{anastassiou2024seed,
  title={Seed-TTS: A Family of High-Quality Versatile Speech Generation Models},
  author={Anastassiou, Philip and Chen, Jiawei and Chen, Jitong and Chen, Yuanzhe and Chen, Zhuo and Chen, Ziyi and Cong, Jian and Deng, Lelai and Ding, Chuang and Gao, Lu and others},
  journal={arXiv preprint arXiv:2406.02430},
  year={2024}
}

@article{zhou2024transfusion,
  title={Transfusion: Predict the next token and diffuse images with one multi-modal model},
  author={Zhou, Chunting and Yu, Lili and Babu, Arun and Tirumala, Kushal and Yasunaga, Michihiro and Shamis, Leonid and Kahn, Jacob and Ma, Xuezhe and Zettlemoyer, Luke and Levy, Omer},
  journal={arXiv preprint arXiv:2408.11039},
  year={2024}
}

@article{liu2024sora,
  title={Sora: A review on background, technology, limitations, and opportunities of large vision models},
  author={Liu, Yixin and Zhang, Kai and Li, Yuan and Yan, Zhiling and Gao, Chujie and Chen, Ruoxi and Yuan, Zhengqing and Huang, Yue and Sun, Hanchi and Gao, Jianfeng and others},
  journal={arXiv preprint arXiv:2402.17177},
  year={2024}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@article{chen2025neural,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Chen, Sanyuan and Wang, Chengyi and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={IEEE Transactions on Audio, Speech and Language Processing},
  year={2025},
  publisher={IEEE}
}

@article{chen2024vall,
  title={VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers},
  author={Chen, Sanyuan and Liu, Shujie and Zhou, Long and Liu, Yanqing and Tan, Xu and Li, Jinyu and Zhao, Sheng and Qian, Yao and Wei, Furu},
  journal={arXiv preprint arXiv:2406.05370},
  year={2024}
}

@article{lee2023hierspeech++,
  title={Hierspeech++: Bridging the gap between semantic and acoustic representation of speech by hierarchical variational inference for zero-shot speech synthesis},
  author={Lee, Sang-Hoon and Choi, Ha-Yeong and Kim, Seung-Bin and Lee, Seong-Whan},
  journal={arXiv preprint arXiv:2311.12454},
  year={2023}
}

@article{du2024cosyvoice,
  title={Cosyvoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens},
  author={Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others},
  journal={arXiv preprint arXiv:2407.05407},
  year={2024}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{jiang2023mega,
  title={Mega-tts: Zero-shot text-to-speech at scale with intrinsic inductive bias},
  author={Jiang, Ziyue and Ren, Yi and Ye, Zhenhui and Liu, Jinglin and Zhang, Chen and Yang, Qian and Ji, Shengpeng and Huang, Rongjie and Wang, Chunfeng and Yin, Xiang and others},
  journal={arXiv preprint arXiv:2306.03509},
  year={2023}
}

@inproceedings{jiang2023boosting,
  title={Boosting prompting mechanisms for zero-shot speech synthesis},
  author={Jiang, Ziyue and Liu, Jinglin and Ren, Yi and He, Jinzheng and Ye, Zhenhui and Ji, Shengpeng and Yang, Qian and Zhang, Chen and Wei, Pengfei and Wang, Chunfeng and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{chen2024f5,
  title={F5-tts: A fairytaler that fakes fluent and faithful speech with flow matching},
  author={Chen, Yushen and Niu, Zhikang and Ma, Ziyang and Deng, Keqi and Wang, Chunhui and Zhao, Jian and Yu, Kai and Chen, Xie},
  journal={arXiv preprint arXiv:2410.06885},
  year={2024}
}

@inproceedings{eskimez2024e2,
  title={E2 tts: Embarrassingly easy fully non-autoregressive zero-shot tts},
  author={Eskimez, Sefik Emre and Wang, Xiaofei and Thakker, Manthan and Li, Canrun and Tsai, Chung-Hsien and Xiao, Zhen and Yang, Hemin and Zhu, Zirun and Tang, Min and Tan, Xu and others},
  booktitle={2024 IEEE Spoken Language Technology Workshop (SLT)},
  pages={682--689},
  year={2024},
  organization={IEEE}
}

@article{le2024voicebox,
  title={Voicebox: Text-guided multilingual universal speech generation at scale},
  author={Le, Matthew and Vyas, Apoorv and Shi, Bowen and Karrer, Brian and Sari, Leda and Moritz, Rashel and Williamson, Mary and Manohar, Vimal and Adi, Yossi and Mahadeokar, Jay and others},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@inproceedings{gao2023e3,
  title={E3 tts: Easy end-to-end diffusion-based text to speech},
  author={Gao, Yuan and Morioka, Nobuyuki and Zhang, Yu and Chen, Nanxin},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@article{liu2024e1,
  title={E1 tts: Simple and fast non-autoregressive tts},
  author={Liu, Zhijun and Wang, Shuai and Zhu, Pengcheng and Bi, Mengxiao and Li, Haizhou},
  journal={arXiv preprint arXiv:2409.09351},
  year={2024}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@article{wang2017tacotron,
  title={Tacotron: Towards End-to-End Speech Synthesis},
  author={Wang, Yuxuan and Skerry-Ryan, RJ and Stanton, Daisy and Wu, Yonghui and Weiss, Ron J and Jaitly, Navdeep and Yang, Zongheng and Xiao, Ying and Chen, Zhifeng and Bengio, Samy and others},
  journal={Interspeech 2017},
  pages={4006},
  year={2017},
  publisher={ISCA}
}

@inproceedings{shen2018natural,
  title={Natural tts synthesis by conditioning wavenet on mel spectrogram predictions},
  author={Shen, Jonathan and Pang, Ruoming and Weiss, Ron J and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and others},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4779--4783},
  year={2018},
  organization={IEEE}
}

@inproceedings{li2019neural,
  title={Neural speech synthesis with transformer network},
  author={Li, Naihan and Liu, Shujie and Liu, Yanqing and Zhao, Sheng and Liu, Ming},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={6706--6713},
  year={2019}
}

@article{meng2024autoregressive,
  title={Autoregressive speech synthesis without vector quantization},
  author={Meng, Lingwei and Zhou, Long and Liu, Shujie and Chen, Sanyuan and Han, Bing and Hu, Shujie and Liu, Yanqing and Li, Jinyu and Zhao, Sheng and Wu, Xixin and others},
  journal={arXiv preprint arXiv:2407.08551},
  year={2024}
}

@article{kharitonov2023speak,
  title={Speak, read and prompt: High-fidelity text-to-speech with minimal supervision},
  author={Kharitonov, Eugene and Vincent, Damien and Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Girgin, Sertan and Pietquin, Olivier and Sharifi, Matt and Tagliasacchi, Marco and Zeghidour, Neil},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={1703--1718},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{hsu2021hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@inproceedings{chung2021w2v,
  title={W2v-bert: Combining contrastive learning and masked language modeling for self-supervised speech pre-training},
  author={Chung, Yu-An and Zhang, Yu and Han, Wei and Chiu, Chung-Cheng and Qin, James and Pang, Ruoming and Wu, Yonghui},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={244--250},
  year={2021},
  organization={IEEE}
}

@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12449--12460},
  year={2020}
}

@article{ju2024naturalspeech,
  title={Naturalspeech 3: Zero-shot speech synthesis with factorized codec and diffusion models},
  author={Ju, Zeqian and Wang, Yuancheng and Shen, Kai and Tan, Xu and Xin, Detai and Yang, Dongchao and Liu, Yanqing and Leng, Yichong and Song, Kaitao and Tang, Siliang and others},
  journal={arXiv preprint arXiv:2403.03100},
  year={2024}
}

@article{zeghidour2021soundstream,
  title={Soundstream: An end-to-end neural audio codec},
  author={Zeghidour, Neil and Luebs, Alejandro and Omran, Ahmed and Skoglund, Jan and Tagliasacchi, Marco},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={495--507},
  year={2021},
  publisher={IEEE}
}

@article{defossez2022high,
  title={High fidelity neural audio compression},
  author={D{\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  journal={arXiv preprint arXiv:2210.13438},
  year={2022}
}

@article{li2024continuous,
  title={Continuous Speech Tokenizer in Text To Speech},
  author={Li, Yixing and Xie, Ruobing and Sun, Xingwu and Cheng, Yu and Kang, Zhanhui},
  journal={arXiv preprint arXiv:2410.17081},
  year={2024}
}

@article{hochreiter1997long,
  title={Long Short-term Memory},
  author={Hochreiter, S},
  journal={Neural Computation MIT-Press},
  year={1997}
}

@inproceedings{sutskever2011generating,
  title={Generating text with recurrent neural networks},
  author={Sutskever, Ilya and Martens, James and Hinton, Geoffrey E},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={1017--1024},
  year={2011}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec},
  year={2018}
}

@article{tian2024visual,
  title={Visual autoregressive modeling: Scalable image generation via next-scale prediction},
  author={Tian, Keyu and Jiang, Yi and Yuan, Zehuan and Peng, Bingyue and Wang, Liwei},
  journal={arXiv preprint arXiv:2404.02905},
  year={2024}
}

@inproceedings{chang2022maskgit,
  title={Maskgit: Masked generative image transformer},
  author={Chang, Huiwen and Zhang, Han and Jiang, Lu and Liu, Ce and Freeman, William T},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11315--11325},
  year={2022}
}

@article{wu2023ar,
  title={Ar-diffusion: Auto-regressive diffusion model for text generation},
  author={Wu, Tong and Fan, Zhihao and Liu, Xiao and Zheng, Hai-Tao and Gong, Yeyun and Jiao, Jian and Li, Juntao and Guo, Jian and Duan, Nan and Chen, Weizhu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={39957--39974},
  year={2023}
}

@article{li2022diffusion,
  title={Diffusion-lm improves controllable text generation},
  author={Li, Xiang and Thickstun, John and Gulrajani, Ishaan and Liang, Percy S and Hashimoto, Tatsunori B},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={4328--4343},
  year={2022}
}

@article{liu2024autoregressive,
  title={Autoregressive Diffusion Transformer for Text-to-Speech Synthesis},
  author={Liu, Zhijun and Wang, Shuai and Inoue, Sho and Bai, Qibing and Li, Haizhou},
  journal={arXiv preprint arXiv:2406.05551},
  year={2024}
}

@article{chen2024diffusion,
  title={Diffusion forcing: Next-token prediction meets full-sequence diffusion},
  author={Chen, Boyuan and Monso, Diego Marti and Du, Yilun and Simchowitz, Max and Tedrake, Russ and Sitzmann, Vincent},
  journal={arXiv preprint arXiv:2407.01392},
  year={2024}
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

@article{lu2022dpm,
  title={Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps},
  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5775--5787},
  year={2022}
}

@article{lu2022dpm+,
  title={Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models},
  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  journal={arXiv preprint arXiv:2211.01095},
  year={2022}
}

@article{kong2020hifi,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17022--17033},
  year={2020}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{lee2022bigvgan,
  title={Bigvgan: A universal neural vocoder with large-scale training},
  author={Lee, Sang-gil and Ping, Wei and Ginsburg, Boris and Catanzaro, Bryan and Yoon, Sungroh},
  journal={arXiv preprint arXiv:2206.04658},
  year={2022}
}

@inproceedings{xiong2020layer,
  title={On layer normalization in the transformer architecture},
  author={Xiong, Ruibin and Yang, Yunchang and He, Di and Zheng, Kai and Zheng, Shuxin and Xing, Chen and Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and Liu, Tieyan},
  booktitle={International Conference on Machine Learning},
  pages={10524--10533},
  year={2020},
  organization={PMLR}
}

@article{zhang2019root,
  title={Root mean square layer normalization},
  author={Zhang, Biao and Sennrich, Rico},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{su2024roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{lu2024simplifying,
  title={Simplifying, stabilizing and scaling continuous-time consistency models},
  author={Lu, Cheng and Song, Yang},
  journal={arXiv preprint arXiv:2410.11081},
  year={2024}
}

@article{lipman2022flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  journal={arXiv preprint arXiv:2210.02747},
  year={2022}
}

@inproceedings{kahn2020libri,
  title={Libri-light: A benchmark for asr with limited or no supervision},
  author={Kahn, Jacob and Riviere, Morgane and Zheng, Weiyi and Kharitonov, Evgeny and Xu, Qiantong and Mazar{\'e}, Pierre-Emmanuel and Karadayi, Julien and Liptchinsky, Vitaliy and Collobert, Ronan and Fuegen, Christian and others},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7669--7673},
  year={2020},
  organization={IEEE}
}

@inproceedings{he2024emilia,
  title={Emilia: An extensive, multilingual, and diverse speech dataset for large-scale speech generation},
  author={He, Haorui and Shang, Zengqiang and Wang, Chaoren and Li, Xuyuan and Gu, Yicheng and Hua, Hua and Liu, Liwei and Yang, Chen and Li, Jiaqi and Shi, Peiyang and others},
  booktitle={2024 IEEE Spoken Language Technology Workshop (SLT)},
  pages={885--890},
  year={2024},
  organization={IEEE}
}

@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

@inproceedings{meister2023librispeech,
  title={LibriSpeech-PC: Benchmark for Evaluation of Punctuation and Capitalization Capabilities of end-to-end ASR Models},
  author={Meister, Aleksandr and Novikov, Matvei and Karpov, Nikolay and Bakhturina, Evelina and Lavrukhin, Vitaly and Ginsburg, Boris},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={1--7},
  year={2023},
  organization={IEEE}
}

@inproceedings{guo2021didispeech,
  title={Didispeech: A large scale mandarin speech corpus},
  author={Guo, Tingwei and Wen, Cheng and Jiang, Dongwei and Luo, Ne and Zhang, Ruixiong and Zhao, Shuaijiang and Li, Wubo and Gong, Cheng and Zou, Wei and Han, Kun and others},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6968--6972},
  year={2021},
  organization={IEEE}
}

@article{ardila2019common,
  title={Common voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={arXiv preprint arXiv:1912.06670},
  year={2019}
}

@misc{radford2022whisper,
  doi = {10.48550/ARXIV.2212.04356},
  url = {https://arxiv.org/abs/2212.04356},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  title = {Robust Speech Recognition via Large-Scale Weak Supervision},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{chen2022wavlm,
  title={Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={16},
  number={6},
  pages={1505--1518},
  year={2022},
  publisher={IEEE}
}

@article{saeki2022utmos,
  title={Utmos: Utokyo-sarulab system for voicemos challenge 2022},
  author={Saeki, Takaaki and Xin, Detai and Nakata, Wataru and Koriyama, Tomoki and Takamichi, Shinnosuke and Saruwatari, Hiroshi},
  journal={arXiv preprint arXiv:2204.02152},
  year={2022}
}

@article{shen2023naturalspeech,
  title={Naturalspeech 2: Latent diffusion models are natural and zero-shot speech and singing synthesizers},
  author={Shen, Kai and Ju, Zeqian and Tan, Xu and Liu, Yanqing and Leng, Yichong and He, Lei and Qin, Tao and Zhao, Sheng and Bian, Jiang},
  journal={arXiv preprint arXiv:2304.09116},
  year={2023}
}

@article{li2024imagefolder,
  title={Imagefolder: Autoregressive image generation with folded tokens},
  author={Li, Xiang and Qiu, Kai and Chen, Hao and Kuen, Jason and Gu, Jiuxiang and Raj, Bhiksha and Lin, Zhe},
  journal={arXiv preprint arXiv:2410.01756},
  year={2024}
}
