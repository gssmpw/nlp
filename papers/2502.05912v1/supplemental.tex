\newpage

\onecolumn

\appendix

\section{Supplementary Material}

This is extra material for the submission titled
"\system: Pessimistic Cardinality Estimation Using
  $\ell_p$-Norms of Degree Sequences."
This material is organized as follows.
Section~\ref{subsec:proof:th:lpbase:eq:lptdb} gives the proof for Theorem~\ref{th:lpbase:eq:lptdb}.
Section~\ref{subsec:lptd} describes  a third optimized algorithm for estimating arbitrary conjunctive queries, which uses hypertree decompositions of the queries. This is not yet implemented in \system.
Section~\ref{subsec:lpflow:details} gives more details on the \lpflow optimization and the proof for  Theorem~\ref{th:lpbase:eq:lpflow}.
\nop{Section~\ref{app:predicates-examples} gives examples on how \system accommodates selection predicates.
Section~\ref{app:further-experiments} details further experiments.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Proof of Theorem~\ref{th:lpbase:eq:lptdb}}
\label{subsec:proof:th:lpbase:eq:lptdb}
For simplicity of presentation, we assume here that the
query $Q$ is connected.
Denote by $b_{\text{base}}$ and $b_{\text{Berge}}$ the values of
\lpbase and \lptdb.  The inequality
$b_{\text{base}}\leq b_{\text{Berge}}$ follows from two observations:
\begin{itemize}
\item For any acyclic query $Q$ and any polymatroid $h$, the
  inequality $E_Q \geq h(X_1\cdots X_n)$ is a Shannon inequality.
  This is a well known
  inequality~\cite{DBLP:journals/tse/Lee87,DBLP:conf/sigmod/KenigMPSS20}
  (which we review in Lemma~\ref{lemma:tony:lee} below).
\item Any feasible solution to \lpbase can be converted to a feasible
  solution of \lptdb by simply ``forgetting'' the terms $h(U)$ that do
  not occur in \lptdb.
\end{itemize}

For the converse, $b_{\text{Berge}}\leq b_{\text{base}}$, we will
prove that every feasible solution $h$ to \lptdb can be extended to a
feasible solution to \lpbase (by defining $h(U)$ for all terms $h(U)$
that did not appear in \lptdb), such that $E_Q = h(X_1\cdots X_n)$.
We will actually prove something stronger: that $h$ can be extended to
a \emph{normal polymatroid}.

\begin{definition} \label{def:normal}
  A set function $h : 2^{\set{X_1,\ldots,X_n}} \rightarrow \R$ is a \emph{normal
    polymatroid} if $h(\emptyset)=0$ and it satisfies:
%
  \begin{align}
    \forall U \subseteq \set{X_1,\ldots,X_n}: \sum_{W\subseteq U}(-1)^{|W|+1}h(W) \geq &0 \label{eq:normal}
  \end{align}
\end{definition}
% 
It is known that every normal polymatroid is an entropic vector, and
every entropic vector is a polymatroid, but none of the converse
holds.

The inequality $b_{\text{Berge}}\leq b_{\text{base}}$ follows from two lemmas:

\begin{lemma} \label{lemma:normal:extension:of:one:bag} Let
  $V = \set{X_1, \ldots, X_n}$, let $a_1, \ldots, a_n, A$ be $n+1$
  non-negative numbers such that:
%
  \begin{align}
    a_1 + \cdots + a_n \geq & A \ \ \ \ \text{and}\ \ \ \ \ a_i \leq A, \forall i=1,n \label{eq:a:a}
  \end{align}
%
  Then there exists a normal polymatroid $h : 2^V \rightarrow \R$ such
  that $h(X_i)=a_i$ for all $i=1,n$ and $h(V) = A$.
\end{lemma}

\begin{lemma}[Stitching Lemma] \label{lemma:stich} Let
  $V_1, V_2$ be two sets of variables, $Z \defeq V_1 \cap V_2$. Let
  $h_1:2^{V_1} \rightarrow \R$, $h_2: 2^{V_2} \rightarrow \R$ be two
  normal polymatroids that agree on their common variables $Z$: in
  other words there exists $h : 2^Z \rightarrow \R$ such that
  $\forall U \subseteq Z$, $h_1(U)=h(U)=h_2(U)$.  Define the following
  function $h' : 2^{V_1\cup V_2} \rightarrow \R$:
%
  \begin{align}
    h'(U) \defeq & h_1(U \cap V_1|U \cap Z) + h_2(U \cap V_2|U \cap Z) + h(U \cap Z) \label{eq:stich}
  \end{align}
%
  Then $h'$ is a normal polymatroid that agrees with $h_1$ on $V_1$ and
  with $h_2$ on $V_2$, and, furthermore, satisfies:
%
  \begin{align}
    h'(V_1 \cup V_2) = & h'(V_1) + h'(V_2) - h'(V_1\cap V_2) \label{eq:independent}
  \end{align}
  %
  In essence, this says that $V_1, V_2$ are independent conditioned on
  $V_1 \cap V_2$.
\end{lemma}


Notice that $h'$ can be written equivalently as
$h'(U) = h_1(U\cap V_1)+h_2(U\cap V_2) - h(U\cap Z)$.  While each term
is a normal polymatroid, it is not obvious that $h'$ is too, because
of the difference operation.  In fact, if $h_1, h_2, h$ are
polymatroids, then $h'$ is not a polymatroid in general.


The two lemmas prove Theorem~\ref{th:lpbase:eq:lptdb}, by showing that
$b_{\text{Berge}}\leq b_{\text{base}}$, as follows.  Consider any
feasible solution $h$ to \lptdb.  Consider first a single atom
$R_j(V_j)$ of $Q$: $h$ is only defined on all its variables and on the
entire set $V_j$.  By Lemma~\ref{lemma:normal:extension:of:one:bag},
we can extend $h$ to a normal polymatroid
$h: 2^{V_j} \rightarrow \Rp$.  We do this separately for each
$j=1,m$.  Next, we stitch these polymatroids together in order to
construct a polymatroid on all variables,
$h:2^{\set{X_1,\ldots, X_n}}\rightarrow \Rp$, and for this purpose we
use the Stitching Lemma~\ref{lemma:stich}.  Notice that the Lemma is
stronger than what we need, since in our case the intersection
$V_1 \cap V_2$ always has size 1 (since $Q$ is Berge-acyclic): we need
the stronger version for our third algorithm described in Sec.~\ref{subsec:lptd}.  By
using the conditional independence equality~\eqref{eq:independent}, we
can prove that $E_Q = h(X_1\cdots X_n)$, which completes the proof of
Theorem~\ref{th:lpbase:eq:lptdb}.

It remains to prove the two lemmas.

\begin{proof}[Proof of Lemma~\ref{lemma:normal:extension:of:one:bag}]
  We briefly review an alternative definition of normal polymatroids
  from~\cite{DBLP:conf/lics/Suciu23}.  For any $U \subseteq V$, the
  step function at $U$ is $h^U$ defined as:
%
\begin{align}
\forall X \subseteq V: &&  h^U(X) \defeq &
                  \begin{cases}
                    1 & \mbox{if $U\cap X\neq \emptyset$}\\
                    0 & \mbox{otherwise}
                  \end{cases} \label{eq:step:function}
\end{align}
%
When $U=\emptyset$, then $h^U \equiv 0$, so we will assume
w.l.o.g. that $U \neq \emptyset$.  A function $h : 2^V \rightarrow \R$
is a normal polymatroid iff it is a non-negative linear combination of
step functions:
%
\begin{align}
  h = & \sum_{U \subseteq V, U \neq \emptyset} c_U h^U
\end{align}
%
where $c_U \geq 0$ for all $U$.

We prove the lemma by induction on $n$, the number of variables in
$V$.  If $n=1$ then the lemma holds trivially because we define
$h(X_1) \defeq a_1$, so assume $n \geq 2$.  Rename variables such that
$a_1 \geq a_2 \geq \cdots \geq a_n$, and let $k \leq n$ be the
smallest number such that $a_1 + \cdots + a_k \geq A$: such $k$ must
exist by assumption of the lemma.  We prove the lemma in two cases.

{\bf Case 1}: $k=n$.  Let $\delta \defeq \sum_{i=1,n}a_i - A$ be the
excess of the inequality~\eqref{eq:a:a}: notice that $a_1 \geq \delta$
and $a_n \geq \delta$.  We define $h$ as follows:
  %
\begin{align*}
  h = & (a_1-\delta)h^{X_1}+\delta h^{X_1,X_n}+\sum_{i=2,n-1}a_i h^{X_i} + (a_n-\delta)h^{X_n}
\end{align*}
  %
By construction, $h$ is a normal polymatroid, and one can check by
direct calculation that $h(X_i)=a_i$ for all $i$ and $h(V)=A$.

{\bf Case 2}: $k < n$.  We prove by induction on $m=k,k+1,\ldots,n$
that there exists a normal polymatroid
$h : 2^{\set{X_1, \ldots, X_m}} \rightarrow \R$ s.t. $h(X_i)=a_i$ for
$i=1,m$ and $h(X_1\ldots X_m)=A$.  The claim holds for $m=k$ by Case
1.  Assuming it holds for $m-1$, let
$h' : 2^{\set{X_1,\ldots,X_{m-1}}}\rightarrow \R$ be such that
$h'(X_i)=a_i$ for $i=1,m-1$ and $h'(X_1\cdots X_{m-1})=A$.  We show
that we can extend it to $X_m$.  For that we first represent $h'$ over
the basis of step functions:
  %
\begin{align*}
  h' = & \sum_{U \subseteq \set{X_1,\ldots,X_{m-1}}, U\neq \emptyset}c_U  h^U
\end{align*}
  %
for some coefficients $c_U \geq 0$, and note that
$\sum_U c_U = h'(X_1\ldots X_{m-1})=A$.  Define $h$ as follows:
  %
  \begin{align*}
    h = & \sum_{U \subseteq \set{X_1,\ldots,X_{m-1}}, U\neq \emptyset}c_U\left(1-\frac{a_m}{A}\right) h^U+ \sum_{U \subseteq \set{X_1,\ldots,X_{m-1}}, U\neq \emptyset}c_U\frac{a_m}{A} h^{U\cup\set{X_m}}
  \end{align*}
  %
  By assumption of the lemma $a_m \leq A$, which implies that all
  coefficients above are $\geq 0$, hence $h$ is a normal
  polymatroid. Furthermore, by direct calculations we check that, for
  $i<m$, $h(X_i) = h'(X_i) = a_i$ (because
  $h^{U\cup \set{X_m}}(X_i)=h^U(X_i)$), and, for $i<m$,
  $h(X_m) = a_m$, because $h^U(X_m) = 0$ and
  $h^{U\cup\set{X_m}}(X_m)=1$, and the claim follows from
  $\sum_U c_U = h'(X_1\cdots X_{m-1})=A$.  Finally, we also have
  $h(X_1\ldots X_m) = \sum_U c_U = A$, as required.
\end{proof}

Finally, we prove the Stitching Lemma~\ref{lemma:stich}.  For that we
need two propositions.

\begin{proposition} \label{prop:technical:1} Let $h : 2^V \rightarrow \R$
  be a normal polymatroid, and $V_0 \supseteq V$ a superset of
  variables.  Define $h': 2^{V_0}\rightarrow \R$ by
  $h'(U) \defeq h(U \cap V)$ for all $U \subseteq V_0$.  Then $h'$ is
  a normal polymatroid.  In other words, $h'$ extends $h$ to $V_0$ by
  simply ignoring the additional variables.
\end{proposition}

\begin{proof}
  We verify condition~\eqref{eq:normal} directly.  When
  $U \subseteq V$, then $h'(W)=h(W)$ for all $W \subseteq U$ and the
  condition holds because $h$ is a normal polymatroid.  When
  $U\not\subseteq V$, then we claim that
  $\sum_{W\subseteq U}(-1)^{|W|+1}h(W \cap V)=0$.  Indeed, fix a variable
  $X_i \in U$, $X_i \not\in V$, and pair every subset $W \subseteq U$
  that does not contain $X_i$ with $W' \defeq W \cup \set{X_i}$.  Then
  $h(W\cap V)=h(W'\cap V)$ and the two terms corresponding to $W$ and
  $W'$ in~\eqref{eq:normal} cancel out, proving that the
  expression~\eqref{eq:normal} is $=0$.
\end{proof}

\begin{proposition} \label{prop:technical:2} Let $h: 2^V \rightarrow \R$ be
  a normal polymatroid, and $Z\subseteq V$ a subset of variables.
  Define the following set functions $h', h'' : 2^V\rightarrow \R$:
%
  \begin{align}
\forall U \subseteq V: &&    h'(U) \defeq & h(U\cap Z) &  h''(U) \defeq & h(U|U\cap Z) \label{eq:hprime:normal}
  \end{align}
%
  (Recall that $h(B|A) = h(AB)-h(A)$.)  Then both $h', h''$ are normal
  polymatroids.
\end{proposition}

\begin{proof}
  We consider two cases as above.  When $U\subseteq Z$, then for all
  $W \subseteq U$ we have $h'(W)=h(W)$, and $h''(W)=0$:
  condition~\eqref{eq:normal} holds for $h'$ because it holds for $h$,
  and it holds for $h''$ trivially since it is $=0$.  No consider
  $U\not\subseteq Z$.  Then we claim that the
  expression~\eqref{eq:normal} for $h'$ is $0$:
%
  \begin{align*}
    \sum_{W \subseteq U} (-1)^{|W|+1}h'(W)=& \sum_{W \subseteq U} (-1)^{|W|+1}h(W\cap Z)=0
  \end{align*}
%
  We use the same argument as in the previous lemma: pick a variable
  $X_i$ s.t. $X_i \in U$ and $X_i \not\in Z$ and pair each set
  $W \subseteq U$ that does not contain $X_i$ with the set
  $W' \defeq W \cup \set{X_i}$.  Then $h(W\cap Z)=h(W'\cap Z)$ and two
  terms for $W$ and $W'$ cancel out.  Finally,
  condition~\eqref{eq:normal} for $h''$ follows similarly:
%
  \begin{align}
    \sum_{W\subseteq U}(-1)^{|W|+1}h''(W) = & \sum_{W\subseteq U}(-1)^{|W|+1}h(W|W\cap Z) =\underbrace{\sum_{W\subseteq U}(-1)^{|W|+1}h(W)}_{\geq 0}-\underbrace{\sum_{W\subseteq U}(-1)^{|W|+1}h(W\cap Z)}_{=0}
  \end{align}
%
  The first term is $\geq 0$ because $h$ is a normal polymatroid, and
  the second term is $=0$, as we have seen.
\end{proof}

Finally, we prove the Stitching Lemma~\ref{lemma:stich}.

\begin{proof}[Proof of Lemma~\ref{lemma:stich}] We first use the two
  propositions to show that $h'$ from Eq.~\eqref{eq:stich} is a normal polymatroid.  Define two
  helper functions $h'_1 : 2^{V_1} \rightarrow \R$ and
  $h'_2 : 2^{V_2} \rightarrow \R$:
%
  \begin{align*}
\forall U \subseteq V_1:\   h'_1(U) \defeq & h_1(U|U \cap Z) & 
\forall U \subseteq V_2:\   h'_2(U) \defeq & h_2(U|U \cap Z)
  \end{align*}
%
  By Lemma~\ref{prop:technical:2}, both $h'_1, h'_2$ are normal
  polymatroids.  Next, we extend $h'_1, h'_2, h$ to the entire set
  $V_1 \cup V_2$ by defining:
  \begin{align*}
  \forall U \subseteq V_1 \cup V_2:&& h''_1(U) \defeq &h'_1(U\cap V_1)  & h''_2(U) \defeq &h'_2(U\cap V_2)  & h''(U) \defeq & h(U\cap Z)
  \end{align*}
%
  By Lemma~\ref{prop:technical:1} each of them is a normal
  polymatroid.  Since $h'$ in the corollary is their sum, it is also a
  normal polymatroid.

  We check that it agrees with $h_1$ on $V_1$.  For any $U \subseteq
  V_1$, we have $h_2(U\cap V_2|U \cap Z) = 0$ therefore:
%
  \begin{align*}
    h'(U) = & h_1(U \cap V_1|U \cap Z) + h(U \cap Z)= h_1(U|U\cap Z)+h_1(U\cap Z) = h_1(U)
  \end{align*}
%
  Similarly, $h'$ agrees with $h_2$ on $V_2$.  Finally,
  condition~\eqref{eq:independent} follows by setting
  $U:= V_1 \cup V_2$ in~\eqref{eq:stich} and applying the definition
  of conditional: $h(B|A)=h(B)-h(A)$ when $A \subseteq B$.
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{\lptd: Using Hypertree Decomposition}
\label{subsec:lptd}

The \lptdb algorithm is strictly limited by two requirements: $Q$
needs to be Berge-acyclic, and all statistics need to be full.  We
describe here a generalization of \lptdb, called \lptd, which drops
these two limitations.  When the restrictions of \lptdb are met, then
\lptd is slightly less efficient, however, its advantage is that it
can work on any query and constraints, without any restrictions.


A \emph{Hypertree Decomposition} of a full conjunctive query $Q$
 is a pair $(T,\chi)$, where $T$ is a tree and $\chi:
 \nodes(T)\rightarrow 2^V$ satisfying the following:
%
 \begin{itemize}
 \item For every variable $X_i$, the set
   $\setof{t \in \nodes(T)}{X_i \in \chi(t)}$ is connected.  This is
   called the \emph{running intersection property}.
 \item For every atom $R_j(V_j)$ of $Q$, $\exists t \in \nodes(T)$
   s.t. $V_j \subseteq \chi(t)$.
 \end{itemize}
%
 Each set $\chi(t) \subseteq V$ is called a \emph{bag}.  The
 \emph{width} of the tree $T$ is defined as
 $w(T) \defeq \max_{t \in \nodes(T)}|\chi(t)|$. We review a lemma by
 Lee~\cite{DBLP:journals/tse/Lee87}:

 \begin{lemma} \label{lemma:tony:lee} ~\cite{DBLP:journals/tse/Lee87}
   Let $(T,\chi:\nodes(T)\rightarrow 2^V)$ have the running
   intersection property and let $h : 2^V \rightarrow \R$ be a set
   function.  Define:
%
  \begin{align}
    E_{T,h} \defeq & \sum_{t \in \nodes(T)}h(\chi(t))-\sum_{(t_1,t_2)\in\edges(T)}h(\chi(t_1)\cap\chi(t_2)) \label{eq:et}
  \end{align}
%
  (1) If $h$ is a polymatroid (i.e. it satisfies the basic Shannon
  inequalities), then $E_{T,h} \geq h(V)$. (2) Suppose $h$ is the
  entropic vector defined by a uniform probability distribution on a
  relation $R(X_1, \ldots, X_n)$.  Then, $E_{T,h}=h(V)$ if for every
  $(t_1,t_2)\in \edges(T)$, the join dependency
  $R = \Pi_{V_1}(R) \Join \Pi_{V_2}(R)$ holds, where
  $V_1, V_2\subseteq V$ are the variables occurring on the two
  connected components of $T$ obtained by removing the edge
  $(t_1,t_2)$.
\end{lemma}

For a simple illustration, consider the 3-way join $J_3$
(Eq.~\eqref{eq:j3}).  Its tree decomposition $T$ has 3 bags
$XY, YZ, ZU$, and $E_{T,h} = h(XY)+h(YZ)+h(ZU)-h(Y)-h(Z)$; one can
check that $E_{T,h} \geq h(XYZU)$ using two applications of
submodularity.


Our new linear program, called \lptd, is constructed from a
hypertree decomposition $(T,\chi)$ of the query as follows:

\smallskip

\noindent {\bf The Real-valued Variables} are all expressions of the
form $h(U)$ for $U \subseteq \chi(t)$, $t \in \nodes(T)$.  The total
number of real-valued variable is $\sum_{t \in \nodes(T)}
2^{|\chi(t)|}$, i.e. it is exponential in the tree-width of the query.

\smallskip

\noindent {\bf The Objective} is to maximize $E_{T,h}$
(Eq.~\eqref{eq:et}), subject to the following constraints.

\smallskip

\noindent {\bf Statistics Constraints:}
All statistics constraints Eq.~\eqref{eq:h:p} of \lpbase.
Since we don't have numerical variable $h(U)$ for all $U$, we must
check that~\eqref{eq:h:p} uses only available numerical
variables.  This holds, because each statistics refers to some atom
$R_j(V_j)$, and there exists of some bag such that
$V_j \subseteq \chi(t)$, therefore we have numerical variables $h(U)$
for all $U \subseteq V_j$.

\smallskip

\noindent {\bf Normality Constraints:}
For each bag $\chi(t)$, \lptd contains all constraints of the
form~\eqref{eq:normal}.  In other words, the restriction of $h$ to
$\chi(t)$ is normal.


We prove:

\begin{theorem} \label{th:lptd} \lpbase and \lptd compute the same
  value.
\end{theorem}

The theorem holds only when all degree constraints used in the
statistics are \emph{simple}, as we assumed throughout this paper.
For a simple illustration, the \lptd for $J_3$ consists of 7 numerical
variables \\
$h(X),h(Y),h(Z),h(U),h(XY),h(YZ),h(ZU)$ (we omit
$h(\emptyset)=0$) and the following Normality Constraints:
%
\begin{align*}
  h(X)+h(Y)-h(XY)\geq & 0 & h(Y)+h(Z)-h(YZ)\geq & 0 \\
  h(Z)+h(U)-h(ZU) \geq & 0
\end{align*}



To compare \lptd and \lptdb, assume that the query $Q$ is Berge-acyclic
and all statistics are on simple and full degree constraints.  The
difference is that, for each atom $R_j(V_j)$, \lptdb has only $1+|V_j|$
real-valued variables and only $1+|V_j|$ additivity constraints, while
\lptdb has $2^{|V_j|}$ variables and normality constraints.

In the remainder of this section we prove Theorem~\ref{th:lptd}.

Denote by $b_{\text{base}}$ and $b_{\text{td}}$ the optimal solutions
of \lpbase and \lptd respectively.  We will prove that
$b_{\text{base}}=b_{\text{td}}$.

First, we claim that $b_{\text{base}}\leq b_{\text{td}}$.  It is known
from~\cite{DBLP:journals/pacmmod/KhamisNOS24} that \lpbase has an
optimal solution $h^*$ that is a normal polymatroid; thus
$b_{\text{base}}=h^*(V)$ (recall that $V$ is the set of all
variables), where $h^*$ is normal.  Then $h^*$ is also a feasible
solution to \lptd, therefore its optimal value is at least as large as
the value given by $h^*$, in other words
$b_{\text{td}}\geq E_{T,h^*}$.  By Lemma~\ref{lemma:tony:lee}, we have
$E_{T,h^*}\geq h^*(V) = b_{\text{base}}$, which proves the claim.


Second, we prove that $b_{\text{td}}\leq b_{\text{base}}$ by using the Stitching Lemma~\ref{lemma:stich}.
Let $h^*$ be an optimal solution to \lptd, thus
$b_{\text{td}}=E_{T,h^*}$.  The function $h^*$ is defined only on
subsets of the bags $\chi(t)$, $t \in \nodes(T)$, and on each such
subset, it is a normal polymatroid.  We extend it to a normal
polymatroid defined on all variables
$V = \bigcup_{t \in \nodes(T)}\chi(t)$ by repeatedly applying the
Stitching Lemma~\ref{lemma:stich}. Condition~\eqref{eq:independent} of
the corollary implies that this extension satisfies
$h^*(V)=E_{T,h^*}$.  Thus, $h^*$ is a normal polymatroid, and, hence,
a feasible solution to \lpbase.  It follows that the optimal value of
\lpbase is at least as large as that given by $h^*$, in other words
$b_{\text{base}} \geq h^*(V)$.  This completes the proof of the claim.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{\lpflow: Missing Details from Section~\ref{subsec:lpflow}}
\label{subsec:lpflow:details}

Section~\ref{subsec:lpflow} gives the high-level idea of the \lpflow algorithm
using an example. We give here a more formal description of the algorithm
and prove Theorem~\ref{th:lpbase:eq:lpflow}.
The input to \lpflow is an arbitrary conjunctive query $Q$ of the form Eq.~\eqref{eq:cq}
(not necessarily a full query) and a set of statistics on the input database consisting of $\ell_p$-norms
of {\em simple} degree sequences, i.e. statistics of the form $\lp{\degree_{R_j}(V|U)}_p$ where $|U|\leq 1$.
For the purpose of describing \lpflow,
we construct a flow network $G=(\nodes,\edges)$ that is defined as follows:
(Recall that $\vars(Q) =\{X_1, \ldots, X_n\}$ is the set of variables of the query.)
\begin{itemize}
    \item The set of nodes $\nodes\subseteq 2^{\vars(Q)}$ consists of the following nodes:
    \begin{itemize}
        \item The node $\emptyset$, which is the source node of the flow network.
        \item A node $\{X_i\}$ for every variable $X_i \in \vars(Q)$.
        \item A node $UV$ for every statistics $\lp{\degree_{R_j}(V|U)}_p$. 
    \end{itemize}
    \item The set of edges $\edges$ consists of two types of edges:
    \begin{itemize}
        \item {\bf Forward edges:} These are edges of the form $(a, b)$
        where $a, b \in \nodes$ and $a \subset b$. Each such edge $(a, b)$ has a finite capacity $c_{a, b}$. In particular, for every statistics
        $\lp{\degree_{R_j}(V|U)}_p$, we have two forward edges:
        One edge $(\emptyset, U)$ and another $(U, UV)$. (Recall that $|U|\leq 1$.)
        \item {\bf Backward edges:} These are edges of the form $(a, b)$
        where $a, b \in \nodes$ and $b \subset a$. Each such edge $(a, b)$ has an infinite
        capacity $\infty$.
        In particular, for every statistics $\lp{\degree_{R_j}(V|U)}_p$ and
        every variable $X_i \in UV$, we have a backward edge $(UV, \{X_i\})$.
    \end{itemize}
\end{itemize}
We are now ready to describe the linear program for \lpflow. Recall that $V_0$ is the set of \groupby variables in the query $Q$ from Eq.~\eqref{eq:cq}.

\smallskip

\noindent {\bf The Real-valued Variables} are of two types:
\begin{itemize}
    \item Every statistics $\lp{\degree_{R_j}(V|U)}_p$ has an associated {\em non-negative}
    variable $w_{U,V,p}$.
    \item For every \groupby variable $X_i \in V_0$, we have a flow variable $f_{a, b; X_i}$
    for every edge $(a, b) \in \edges$.
\end{itemize}

\smallskip

\noindent {\bf The Objective} is to minimize the following sum over all available statistics
$\lp{\degree_{R_j}(V|U)}_p$:
\begin{align}
    \sum w_{U,V,p} \cdot \log \lp{\degree_{R_j}(V|U)}_p
    \label{eq:lpflow:objective}
\end{align}

\smallskip

\noindent {\bf The Constraints} are of two types:
\begin{itemize}
    \item {\em Flow conservation constraints:} For every \groupby variable $X_i \in V_0$,
    the variables $f_{a, b;X_i}$ must define a valid flow from the source node
    $\emptyset$ to the sink node $\{X_i\}$ that has a capacity $\geq 1$.
    This means that for every node $c \in \nodes - \{\emptyset\}$, we must have:
    \begin{align}
        \sum_a f_{a, c;X_i} -\sum_b f_{c, b; X_i} \geq 1, & \quad\quad\text{ if $c =\{X_i\}$}\label{eq:flow:conservation:1}\\
        \sum_a f_{a, c;X_i} -\sum_b f_{c, b; X_i} \geq 0, & \quad\quad\text{ otherwise}
        \label{eq:flow:conservation:2}
    \end{align}
    \item {\em Flow capacity constraints:} For every \groupby variable $X_i \in V_0$
    and every {\em forward} edge $(a, b)$, the flow variable $f_{a, b;X_i}$ must satisfy:
    \begin{align}
        f_{a, b;X_i} \leq c_{a, b} \label{eq:flow:capacity}
    \end{align}
    where $c_{a, b}$ is the {\em capacity} of the forward edge $(a, b)$.
    (Recall that backward edges have infinite capacity.)
    The capacity variables $c_{a, b}$ are determined by the statistics constraints.
    In particular, every statistics $\lp{\degree_{R_j}(V|U)}_p$ contributes a capacity
    of $w_{U,V,p}$ to $c_{U,UV}$ and a capacity of $\frac{w_{U,V,p}}{p}$ to $c_{\emptyset,U}$.
    Formally,
    \begin{align}
        c_{\emptyset,U} &\defeq
        \sum_{p} w_{\emptyset,U,p}
        +\sum_{V,p} \frac{w_{U,V,p}}{p}\label{eq:lpflow:c}\\
        c_{U, UV} &\defeq
        \sum_{p} w_{U,V,p} &\text{ if $U \neq \emptyset$}\nonumber
    \end{align}
\end{itemize}
\smallskip



We are now ready to prove Theorem~\ref{th:lpbase:eq:lpflow}, which says that the linear programs
for \lpbase and \lpflow have the same optimal value.
To that end, we first write the dual LP for \lpbase.
For every statistics constraint of the form Eq.~\eqref{eq:h:p}, we introduce a dual variable $w_{U,V,p}$. The dual of \lpbase is equivalent to:
\begin{align}
    \min\quad &\sum w_{U,V,p} \cdot \log \lp{\degree_R(V|U)}_p\label{eq:lpbase:dual}\\
    \text{s.t.}\quad& \text{The following is a valid Shannon inequality:}\nonumber\\
    &h(V_0) \leq \sum w_{U,V,p} \left(\frac{1}{p}h(U)+h(V|U)\right)\label{eq:lpflow:shannon}\\
    & w_{U,V,p} \geq 0\nonumber
\end{align}
Inequality~\eqref{eq:lpflow:shannon} satisfies the property that for every $h(V|U)$
on the RHS, we have $|U| \leq 1$. In order to check that such an inequality is a valid
Shannon inequality, we rely on a key result from~\cite{DBLP:journals/corr/abs-2211-08381}.
In particular,~\cite{DBLP:journals/corr/abs-2211-08381} is concerned
with Shannon inequalities of the following form.
Let $\calX=\{X_1, \ldots, X_n\}$ be a set of variables, and $\calC$
be a set of distinct pairs $(U, V)$ where $U, V\subseteq \calX$, $U \cap V = \emptyset$
and $|U| \leq 1$.
For every pair $(U,V)\in\calC$, let $c_{U,UV}$ be a non-negative constant.
Moreover, let $V_0$ be a subset of $\calX$.
Consider the following inequality:
\begin{align}
    h(V_0) \leq \sum_{(U,V)\in\calC} c_{U, UV} h(V|U)
    \label{eq:lpflow:shannon:general}
\end{align}
\cite{DBLP:journals/corr/abs-2211-08381} describes a reduction from
the problem of checking whether Eq.~\eqref{eq:lpflow:shannon:general} is a valid Shannon inequality to a collection of $|V_0|$ network flow problems.
These flow problems are over the same network $G=(\nodes, \edges)$,
which is similar to the flow network described above for \lpflow. In particular,
\begin{itemize}
    \item The nodes are $\emptyset$, $\{X_i\}$ for each variable $X_i \in \calX$, and $UV$ for each $(U,V)\in\calC$.
    \item The edges have two types:
    \begin{itemize}
        \item Forward edges: For each $(U,V)\in\calC$, we have a forward edge $(U,UV)$ with capacity $c_{U,UV}$.
        \item Backward edges: For each $(U,V)\in\calC$ and each variable $X_i \in UV$,
        we have a backward edge $(UV, \{X_i\})$ with infinite capacity.
    \end{itemize}
\end{itemize}
\begin{lemma}[\cite{DBLP:journals/corr/abs-2211-08381}]
    Inequality~\eqref{eq:lpflow:shannon:general} is a valid Shannon inequality if and only if
    for each variable $X_i \in V_0$, there exists a flow $\left(f_{a, b;X_i}\right)_{(a, b)\in\edges}$ from the source node $\emptyset$
    to the sink node $\{X_i\}$ with capacity at least $1$.
    In particular, the flow variables $\left(f_{a, b;X_i}\right)_{(a, b)\in\edges}$ must satisfy the flow conservation constraints~\eqref{eq:flow:conservation:1} and~\eqref{eq:flow:conservation:2} and the flow capacity constraints~\eqref{eq:flow:capacity}.
\end{lemma}
Using the above lemma, we can prove Theorem~\ref{th:lpbase:eq:lpflow} as follows.
Take inequality~\eqref{eq:lpflow:shannon} and group together identical conditionals
on the RHS in order to convert it into the form of Eq.~\eqref{eq:lpflow:shannon:general}.
The coefficients $c_{U,UV}$ of the resulting Eq.~\eqref{eq:lpflow:shannon:general}
will be identical to those defined by Eq.~\eqref{eq:lpflow:c}.
Then, we can apply the lemma to check the validity of Eq.~\eqref{eq:lpflow:shannon}.
But now, the dual LP~\eqref{eq:lpbase:dual} for \lpbase is equivalent to the linear program for \lpflow.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\nop{
\subsection{Examples: Handling predicates in \system}
\label{app:predicates-examples}

We show how \system handles predicates in the following examples.
Figure~\ref{fig:predicate_example} (left) shows a simple example of a relation $R(X,A,B)$,
where $X$ is a join attribute and $A$ and $B$ are predicate attributes.
The degree sequence for the relation $R$ with respect to the join attribute $X$ is $\deg_{R}(* | X) = (3,2)$. The $\ell_1$ and $\ell_{\infty}$-norm of the degree sequence $(3,2)$ are $3+2 = 5$ and $\max(3,2) = 3$, respectively.

For queries with predicates on attributes $A$ and $B$, using the $\ell_p$-norms of the degree sequence for the entire relation can lead to overestimation, since only a subset of tuples satisfy the predicates.
We show that how to compute tighter bounds of the $\ell_p$-norms for queries with predicates following our discussion in Section~\ref{sec:histograms}.




\begin{figure}[h]
  \centering
  \begin{minipage}[b]{0.50\textwidth}
      \centering
      $R$ \\[0.2em]
      \begin{tabular}{|c|c|c|}
          \hline
          $X$ & $A$ & $B$\\
          \hline
          1 & 1 & 0\\
          1 & 1 & 8\\
          1 & 2 & 13\\
          2 & 3 & 22\\
          2 & 4 & 40\\
          \hline
      \end{tabular}
  \end{minipage}
  % \hfill
  % ex 2
  \begin{minipage}[b]{0.16\textwidth}
      \centering
      $T$ \\[0.2em]
      \begin{tabular}{|c|c|}
          \hline
          $TID$ & $SID$ \\
          \hline
          1 & 1\\
          2 & 2\\
          3 & 2\\
          4 & 3\\
          5 & 3\\
          \hline
      \end{tabular}
  \end{minipage}
  \begin{minipage}[b]{0.16\textwidth}
    \centering
    $S$ \\[0.2em]
    \begin{tabular}{|c|c|}
        \hline
        $SID$ & $A$ \\
        \hline
        1 & 1\\
        2 & 1\\
        3 & 2\\
        \hline
    \end{tabular}
  \end{minipage}
  \begin{minipage}[b]{0.16\textwidth}
    \centering
    $TS$ \\[0.2em]
    \begin{tabular}{|c|c|c|}
        \hline
        $TID$ & $SID$ & $A$ \\
        \hline
        1 & 1 & 1\\
        2 & 2 & 1\\
        3 & 2 & 1\\
        4 & 3 & 2\\
        5 & 3 & 2\\
        \hline
    \end{tabular}
  \end{minipage}
  \caption{Left: relation $R(X,A,B)$, where $X$ is the join attribute and $A$ and $B$ are predicate attributes. Right: Right: relations $T(TID, SID)$ and $S(SID, A)$ where $SID$ is a foreign key in $T$ and the primary key in $S$, and $TS$ is the join of $T$ and $S$.}
  \label{fig:predicate_example}
\end{figure}

\paragraph{Equality Predicate.} 
Consider an equality predicate on $A$.
The $A$-values in $R$, sorted by frequency in descending order, are $(1,2,3,4)$. 
For this example, we consider the most common value $A=1$ as the only MCV for $A$.
We fetch the tuples satisfying $A=1$, which are the first two tuples, and get the degree sequence $\deg_{R}(* | X, A=1) = (2)$.
The $\ell_p$-norm of the degree sequence is $2$ for any $p\geq 1$.

We also compute one degree sequence for all non-MCVs of $A$, i.e., $A\in\{2,3,4\}$.
We fetch the last three tuples in $R$ and compute the degree sequence $\deg_{R}(* | X, A\in \{2, 3, 4\}) = (2, 1)$.
For an arbitrary non-MCV, there is at most one distinct $X$-value in $R$ associated with it,
so we take the top value of $\deg_{R}(* | X, A\in \{2, 3, 4\})$ as the degree sequence, i.e., $(2)$, for all non-MCVs of $A$.
The $\ell_p$-norm of the degree sequence is $2$ for any $p\geq 1$.

An alternative and more accurate, yet more expensive approach is to compute the degree sequence for each non-MCV of $A$: $\deg_{R}(* | X, A=2) = (1)$, $\deg_{R}(* | X, A=3) = (1)$, and $\deg_{R}(* | X, A=4) = (1)$, and then compute the maximum of their $\ell_p$-norms.
The $\ell_p$-norms of these degree sequences are $1$, so the maximum of the $\ell_p$-norms is $1$, for any $p\geq 1$.

To estimate for a query with the predicate $A=1$, we use the $\ell_p$-norms for the MCV of $A$, i.e., $\ell_p = 2$. For a query with the predicate $A=2$, where $2$ is a non-MCV of $A$, we use the $\ell_p$-norms for non-MCVs of $A$, i.e., $\ell_p = 2$ or, if we use the more accurate alternative, $\ell_p = 1$.

\paragraph{Range Predicate.}
Consider a range predicate on $B$
The domain of $B$ is $[0, 40]$. We create a hierarchy of histograms with $2^k, 2^{k-1}, \ldots, 2^0$ buckets.
For this example, we use $k=2$, which means creating $4$ buckets for the bottom layer, $2$ buckets for the next layer, and one bucket for the entire domain.
The buckets for the layers are $\{[0, 10), [10, 20), [20, 30), [30, 40]\}$,  $\{[0, 20), [20, 40]\}$, and $\{[0,40]\}$.

We first construct the $\ell_p$-norms within each bucket $[s, e)$.
For this, we fetch the tuples where $B$ is in the bucket
and compute the degree sequence $\deg_{R}(* | X, B \in [s, e))$ and several $\ell_p$-norms on this degree sequence.
The degree sequences for the buckets in the layers are $((2), (1), (1), (1))$, then $((3), (2))$, and finally $(5)$. The $\ell_p$-norms within each bucket 


thus their $\ell_1$ and $\ell_{\infty}$-norms are 
$\{(\ell_1=\ell_{\infty}=2), (\ell_1=\ell_{\infty}=1), (\ell_1=\ell_{\infty}=1), (\ell_1=\ell_{\infty}=1)\}$ and $\{(\ell_1=\ell_{\infty}=3), (\ell_1=\ell_{\infty}=2)\}$, respectively.

To estimate for the range predicate $5 \leq B \leq 18$, we first find the smallest bucket that covers the range, which is the bucket $[0, 20)$, and use the corresponding $\ell_p$-norms: $\ell_1 = 2$ and $\ell_{\infty} = 2$.


\paragraph{Conjunction and Disjunction of Predicates.}
We show how \system handles the conjunction and disjunction of predicates on $A$ and $B$.
Consider the predicates $A = 0$ and $5 \leq B \leq 18$.
We fetch the $\ell_p$-norms for the two predicates as discussed in the previous examples: $\ell_1 = 1$ and $\ell_{\infty} = 1$ for $A = 1$, and $\ell_1 = 2$ and $\ell_{\infty} = 2$ for $5 \leq B \leq 18$.

For the conjunction of the predicates, we take the minimum of these $\ell_p$-norms to estimate the query. The result is $\ell_1 = \min(1, 2) = 1$ and $\ell_{\infty} = \min(1, 2) = 1$.

For the disjunction of the predicates, we take the sum of the $\ell_1$-norms and the maximum of the $\ell_{\infty}$-norms, which results in $\ell_1 = 1+2 = 3$ and $\ell_{\infty} = \max(1, 2) = 2$.



\paragraph{Optimization 1: Predicate Propagation via FK-PK Joins.}
Consider two relations $T(TID, SID)$ and $S(SID, A)$ in Figure~\ref{fig:predicate_example} (right),
 where $SID$ is a foreign key in $T$ and a primary key in $S$, and $A$ is an equality predicate attribute.
We compute the $\ell_p$-norms for predicates on $A$ in $S$ as discussed in the previous examples: $\ell_1 = 2$ and $\ell_{\infty} = 1$ for the MCV $A=1$, and $\ell_1 = 1$ and $\ell_{\infty} = 1$ for non-MCVs of $A$.

For relation $R$, we apply the optimization to propagate the predicate on $A$ from $S$ to $T$:
We precompute the join results for the FK-PK join $TS(TID, SID, A) = T(TID, SID) \wedge S(SID, A)$ (Figure~\ref{fig:predicate_example} (right)). The size of the join results is bounded by the size of the FK relation $T$.
For this example, we consider only one MCV of $A$, so the only MCV of $A$ is $A=1$.
We fetch the tuples satisfying $A=1$ in $TS$, which are the first two tuples in $TS$, and compute the degree sequence $\deg_{TS}(* | TID, A=1) = (1,1,1)$.
The $\ell_p$-norms of the degree sequence are $\ell_1 = 1+1+1 = 3$ and $\ell_{\infty} = 1$.
Regarding the non-MCVs of $A$, there is only one non-MCV of $A$, which is $A=2$. We compute the degree sequence for $A=2$ in $TS$, i.e., $\deg_{TS}(* | TID, A=2) = (1,1)$ and the $\ell_p$-norms for the degree sequence are $\ell_1 = 1+1 = 2$ and $\ell_{\infty} = 1$.

Consider a query with predicate $A=1$.
For relation $S$, we use the $\ell_p$-norms for the MCV $A=1$ in $S$, i.e., $\ell_1 = 2$ and $\ell_{\infty} = 1$.
For relation $T$, we use the $\ell_p$-norms for the MCV $A=1$ in the join result $TS$, i.e., $\ell_1 = 3$ and $\ell_{\infty} = 1$.

\paragraph{Optimization 2: Compute $\ell_p$-norms for Prefixes of the Degree Sequence.}
Consider two relations $R(X,A)$ and $S(X,B)$ where $X$ is a join attribute, and their degree sequences are $(100, 99, \ldots, 2, 1)$ and $(2, 1)$, respectively.
This means that there are $100$ distinct $X$-values in $R$ and $2$ distinct $X$-values in $S$, which is significantly mis-calibrated.
When the two relations are joined, at most two $X$-values appear in the join results.
If we use the $\ell_p$-norms of the whole degree sequence for $R$, which are $\ell_1 = 5050$ and $\ell_{\infty} = 100$, the estimation can be significantly overestimated.

We reduce overestimation by computing the $\ell_p$-norms for prefixes of the degree sequence for $R$.
We compute the $\ell_p$-norms for the top-$2^i$ values of the degree sequence for $R$ for $i>0$. 
For example, for $i=1$, we compute the $\ell_p$-norms for the top-$2$ values of the degree sequence, which are $(100, 99)$: $\ell_1 = 100+99 = 199$ and $\ell_{\infty} = 100$.
For the join of $R$ and $S$, since there are at most two $X$-values in the join results, we can use these $\ell_p$-norms for the estimation.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% moved to the main body
\nop{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
    \centering
    \begin{minipage}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{experiments/overall_runtime.pdf}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{experiments/relative_runtime.pdf}
    \end{minipage}
    \caption{Left: Overall evaluation time of all queries in a benchmark for \psql when using estimates for all subqueries from \system, \safebound, \dbx, \psql and true cardinalities. Right: Relative evaluation times compared to the baseline evaluation time obtained when using true cardinalities.}
    \label{fig:runtime}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Further Experiments}
\label{app:further-experiments}

We complement the experiments in Section~\ref{sec:experiments} with further experiments that cannot be accommodated in the main body due to lack of space.

\subsubsection{Estimation Errors}

Fig.~\ref{fig:estimates-STATS} shows that the accuracy of the estimators decreases with the number of relations per query (shown for STATS, a similar trend also holds for JOBlight and JOBrange): The traditional estimators underestimate more, whereas the pessimistic estimators overestimate more. \neurocard starts with a large overestimation for a join of two relations and decreases its estimation as we increase the number of relations; the other ML-based estimators follow this trend but at a smaller scale.


\subsubsection{Optimization Improvements}
Fig.~\ref{fig:improvements-optimizations} shows the improvements to the estimation accuracy brought by each of the two optimizations discussed in Sec.~\ref{sec:histograms}, when taken in isolation.

The left figure shows that,  when propagating predicates from the primary-key relation to the foreign-key relations, the estimation error can improve by over an order of magnitude in the worst case (corresponding to the upper dots in the plot) and by roughly 5x in the median case (corresponding to the red line in the boxplots). 

The right figure shows that,  when using prefix degree sequences for the degree sequences of relations without predicates, the estimation error can improve by up to 50\% for JOBlight queries, up to 65\% for JOBrange queries and up to 10\% for STATS queries. The improvement is measured as the division of (i) the difference between the estimation error without this optimization and the estimation error with this optimization and (2) the the estimation error without this optimization.




\subsubsection{Evaluation Times}




Fig.~\ref{fig:runtime} (left) shows the aggregated \psql evaluation time of all queries in JOBlight, JOBrange, and STATS when using estimates for all sub-queries from \system, \safebound, \dbx, \psql, and true cardinalities (left).
Fig.~\ref{fig:runtime} (right)  shows the relative evaluation times compared to the baseline evaluation time obtained when using true cardinalities. 
We have two observations. First, overestimation can be beneficial for performance of expensive queries, which has been discussed in Section~\ref{sec:experiments}. Second, overestimation can be detrimental for performance of less expensive queries in some cases.

The first observation is reflected in the overall evaluation times, which are dominated by the most expensive queries in the benchmark (some of which are listed in Fig.~\ref{fig:most-expensive-queries}). 
Traditional approaches lead to higher evaluation times for the expensive queries, and therefore to higher overall evaluation times, while the pessimistic approaches lead to lower evaluation times for those expensive queries. Overall, the  evaluation times for the pessimistic approaches are about the same (JOBlight and STATS) or lower (JOBrange) than the baseline evaluation times.
The second observation is reflected in the relative evaluation times for the JOB benchmarks. 
The boxplots for the traditional approaches are lower than those for the pessimistic approaches, indicating that the traditional approaches perform better for the less expensive queries in the benchmarks.

\factorjoin has both high overall evaluation time and high relative evaluation time.
It estimates very accurately for the queries in STATS, thus has similar evaluation time to the baseline evaluation time. For the queries in JOBlight and JOBrange, it mostly overestimates, which leads to lower evaluation times for the expensive queries. However, the overestimations are significant, which makes it perform worse than the pessimistic approaches for the less expensive queries, as shown in the right plot of Fig.~\ref{fig:runtime}. This leads to the high overall evaluation time of \factorjoin.

}

\nop{
\subsection{About Traditional Estimators}

% PostgreSQL
\subsubsection{\psql}
\psql uses four types of statistics to estimate cardinalities:
\begin{itemize}
    \item cardinality of each relation (row count), and the number of pages per relation
    \item number of distinct values for each attribute
    \item MCVs for each attribute and their relative frequencies, i.e., the estimated fraction of rows that have the MCV as the respective attribute value
    \item histogram if the values in each attribute and relative frequency of each histogram bucket
\end{itemize}

The first statistic, the cardinality of each relation, is very accurate. The other statistics, however, are estimated based on a sample of the data. The default sampling size is 30,000 rows. We found that those statistics are often times inaccurate. For example, for some join attributes of the IMDB dataset, the domain size was underestimated by 70\%.

While the statistics mentioned above are computed by default, \psql can be instructed to compute multivariate statistics capturing correlations between attributes of the same relation via the \texttt{CREATE STATISTICS} command.

\paragraph{Selectivity of Equality Predicates and Join Conditions}

\psql uses the concept of {\em selectivity} of a (filter or join) condition to estimate the cardinality of a query output. If the predicate value is a MCV, then \psql considers the relative frequency of this value as its selectivity. If the value is not an MCV, then \psql either use histograms to estimate the frequency of the value in the relation, or it falls back to a default estimate, such as assuming a uniform distribution. In the latter case, the selectivity is assumed to be the estimated domain size of the attribute divided by cardinality of relation. Correlations of attributes across relations are not considered. For join conditions, \psql assumes that the join attributes are independent.

Consider the following join of the two relation $R(A,C)$ and $S(B,C)$ with two equality predicates on the non-join attributes.
\begin{verbatim}
    SELECT * FROM R, S WHERE R.A = 5 AND S.B = 10 AND R.C = S.C;
\end{verbatim}
The estimated cardinality of this query is:
\begin{align*}
    |R| * |S| * \sel{R.A = 5} * \sel{S.B = 10} * \sel{R.C = S.C}.
\end{align*}

\paragraph{Range Conditions}

\subsubsection{\duckdb}
% DuckDB
}
