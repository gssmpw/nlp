\section{Conclusion}
\label{sec:discussion}

In this paper, we investigate how pre-trained univariate time series foundation models can be adapted for probabilistic multivariate forecasting. To address this challenge, we introduce the \adapts framework. Our method offers a novel approach to training feature space transformations that facilitate uncertainty quantification and enhance the performance of baseline foundation models. Through a series of experiments, we demonstrate that our framework improves forecasting accuracy, provides reasonably well-calibrated uncertainty estimates, reduces inference cost through dimensionality reduction, and offers interpretable feature space latent representations.

\noindent\textbf{Limitations \& Future directions.} Our work establishes a principled framework for adapting pre-trained univariate foundation models to multivariate probabilistic time series forecasting. 
While we focus on \moment, our approach can be applied on other univariate deterministic FMs; we leave this direction to future work.
Additionally, while variational inference is chosen for its efficiency, exploring alternative methods like Markov Chain Monte Carlo could improve uncertainty estimation, albeit at a higher computational cost.

Another promising direction is refining the calibration of our uncertainty estimates. While our framework flexibly extracts predictive uncertainty, investigating theoretical guarantees and recalibration techniques could further enhance reliability.

Overall, our work lays a strong foundation for efficiently adapting FMs, extending their applicability to broader forecasting challenges while preserving their expressive power.