\documentclass{article}

% needs to be imported first with Tex Live 2023
\usepackage[table]{xcolor}

\usepackage[accepted]{main}

% ########## custom ##########
\input{template/packages}
\input{template/definitions}
% ############################

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{\adapts: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting}

\allowdisplaybreaks

\newcommand\rebuttal[1]{#1}

\begin{document}

\addtocontents{toc}{\protect\setcounter{tocdepth}{0}}

\twocolumn[
\icmltitle{\adapts: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting}

\begin{icmlauthorlist}
\icmlauthor{Abdelhakim Benechehab}{huawei,eurecom}
\icmlauthor{Vasilii Feofanov}{huawei}
\icmlauthor{Giuseppe Paolo}{huawei}
\icmlauthor{Albert Thomas}{huawei}
\icmlauthor{Maurizio Filippone}{kaust}
\icmlauthor{Bal\'{a}zs K\'{e}gl}{huawei}
\end{icmlauthorlist}

\icmlaffiliation{huawei}{Huawei Noah's Ark Lab, Paris, France}
\icmlaffiliation{eurecom}{Department of Data Science, EURECOM}
\icmlaffiliation{kaust}{Statistics Program, KAUST}

\icmlcorrespondingauthor{Abdelhakim Benechehab}{abdelhakim.benechehab@gmail.com}

\vskip 0.3in
]

\printAffiliationsAndNotice{} 

\begin{abstract}
Pre-trained foundation models (FMs) have shown exceptional performance in univariate time series forecasting tasks. However, several practical challenges persist, including managing intricate dependencies among features and quantifying uncertainty in predictions. This study aims to tackle these critical limitations by introducing \textbf{adapters}â€”feature-space transformations that facilitate the effective use of pre-trained univariate time series FMs for multivariate tasks. Adapters operate by projecting multivariate inputs into a suitable latent space and applying the FM independently to each dimension. Inspired by the literature on representation learning and partially stochastic Bayesian neural networks, we present a range of adapters and optimization/inference strategies. Experiments conducted on both synthetic and real-world datasets confirm the efficacy of adapters, demonstrating substantial enhancements in forecasting accuracy and uncertainty quantification compared to baseline methods. Our framework, \textbf{AdaPTS}, positions adapters as a modular, scalable, and effective solution for leveraging time series FMs in multivariate contexts, thereby promoting their wider adoption in real-world applications. We release the code at \href{https://github.com/abenechehab/AdaPTS}{https://github.com/abenechehab/AdaPTS}.
\end{abstract}

\input{sections/introduction}

\input{sections/related_work}

\input{sections/main}

\input{sections/experiments}

\input{sections/conclusion}

% \section*{Impact statement}
% This paper presents work whose goal is to advance the field of Machine Learning. 
% There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.

\section*{Reproducibility Statement}
In order to ensure reproducibility we will release the code at \href{https://github.com/abenechehab/AdaPTS}{https://github.com/abenechehab/AdaPTS}, once the paper has been accepted. The implementation details and hyperparameters are listed in \cref{appendix:implem}.



\bibliography{main}
\bibliographystyle{main}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\textbf{\LARGE Appendix}

\paragraph{Outline.} In~\cref{appendix:theory}, we provide the proofs and a discussion on \cref{prop:solution} and \cref{prop:vae}. We then provide a perspective on Normalizing Flows as adapters in \cref{appendix:flows}. The experimental setup is presented in \cref{appendix:exp_setup}, including all the implementation details in \cref{appendix:implem}. Finally we showcase some additional results in \cref{appendix:results}.  

% Make appear only appendix sections in table of content
\addtocontents{toc}{\protect\setcounter{tocdepth}{2}}

% Change title of table of contents
\renewcommand*\contentsname{\Large Table of Contents}

%\setstretch{1.5} % stretch for table of contents
\tableofcontents
%\noindent\hrulefill
%\setstretch{1} % unstretch for the rest
\clearpage


\input{sections/appendix/all}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}