\section{Introduction}

Inspired by Social Choice Theory \citep{Endriss17}, recent research considers the use of multiple large language models (LLMs) to solve increasingly complex reasoning tasks and mitigate the limitations of single models, such as lacking modularity and answer diversity \citep{YinSCG23a, ChenSB24a, SunYLW24}.
Agents, embedded with varying expertise, memory, planning, and tool use \citep{ChenSB24a, SunYLW24, ZhuangYWS23a, BakerKMW20a}, can emulate human interaction to solve problems \citep{GuoCWC24a, Becker24}.
Recent work highlights the strengths of multi-agent debate in reasoning and creativity \citep{ZhaoHXL23a, XuYLW23a, SuzgunK24a}.
Multi-agent debate also scales test-time compute to solve challenging tasks similar to large reasoning models, such as OpenAI o1 \citep{ZhongLPZ24} and DeepSeek R1 \citep{deepseekai2025deepseekr1incentivizingreasoningcapability}, which can be more effective than scaling training compute and data \citep{SnellLXK24a}.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/other_charts/problem_drift.pdf}
    \caption{Problem drift in multi-agent debate. \judge\ detects problem drift at test-time. \policy\ provides on-demand feedback about the conversation.\vspace{-0.5cm}}
    \label{fig:problem_drift}
\end{figure}

However, the increasing complexity of multi-agent debate can promote errors and unwanted behaviors \citep{GuoCWC24a}.
Problems originating from debate comprise agent orchestration \citep{WangWST24, ShahW24}, diminished planning capabilities \citep{ValmeekamMK23a}, and ineffective criticism generated by the LLM \citep{StechlyMK23a}.
Still, it is largely unknown what causes multi-agent systems to fail and why it happens.
Even for the few problems that are identified by related work, not many effective mitigation methods have been proposed.


This paper systematically analyzes errors that lead to degraded performance in multi-agent debate.
Through automated methods and a human study, we observe that multi-agent systems often collapse in long discussions.
In many discussions, one agent contributes irreversible input to others, which leads to drifting away from the original task's goal.
We call this phenomenon \textbf{problem drift}.
To identify drift post-hoc in multi-agent debate, we propose \metric, a simple yet effective metric that measures the quality of the ongoing discussion.
As later experiments will demonstrate, problem drift occurs across all tested tasks, being most prevalent in generative tasks (76\%-89\% of samples), followed by instruction-following tasks (21\% of samples).
The majority of observed drift does not recover, i.e., once a discussion drifts away, agents can not reach the correct solution for a given task on their own.
Only 9\% (translation) to 45\% (ethical question-answering) of drifting discussions recover.

By asking eight human experts, we identify eight reasons why problem drift occurs in multi-agent debate and categorize them into temporal error types (e.g., lack of progress) and local error types (e.g., task non-compliance).
Agent discussions are especially prone to a lack of progress (35\% of drifting samples) that can lead agents to overanalyze problems and give low-quality feedback.

The good news is that problem drift is not necessarily irrecoverable.
To identify problem drift at test-time, we propose \judge, based on LLM-as-a-judge \citep{ZhengCSZ23}, and \policy, a new method based on a policy feedback agent \citep{FuPKL23b} that advises participating agents to improve the debate (\Cref{fig:problem_drift}).
We show that \policy\ can reduce the number of drifting discussions by 31\%.
Our work can be seen as a window into the heart of multi-agent debate, showing the inherent limitations of long agent interaction.
We release the code and data publicly\footnote{\url{https://github.com/jonas-becker/problem-drift}}.
The main contributions of this work are:
\begin{itemize}
    \item We identify problem drift as a performance degradation in multi-agent debate.
    \item We quantify the prevalence and recoverability of problem drift. 
    \item We explore the most common error types related to problem drift according to humans.
    \item We propose \judge\ and \policy\ to detect and mitigate problem drift.
\end{itemize}


    

