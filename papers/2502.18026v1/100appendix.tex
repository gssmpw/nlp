\begin{table}[h]
    \centering
    \caption{Summary of pathway data across four pathway classes.}
\resizebox{0.95\linewidth}{!}{%
    \begin{tabular}{llcccc}
        \toprule
        \multicolumn{2}{l}{Pathway class}& \#Samples & \#Nodes & \#Edges & AA-seq Length \\
        \midrule
        C1&Human Diseases & 83 & 40 & 42 & 583 \\
        C2&Metabolism & 78 & 16 & 42 & 511 \\
        C3&\begin{tabular}[c]{@{}l@{}}Molecular and \\cellular processes\end{tabular} & 80 & 30 & 37 & 636 \\
        C4&Organismal systems & 60 & 44 & 49 & 638 \\
        \midrule
        \multicolumn{2}{l}{Overall}  & 301 & 32 & 42 & 590 \\
        \bottomrule
    \end{tabular}
    }
    \label{tb:data_sum}
\end{table}

\section{Graph isomorphism and WL test}\label{Tools}
\textbf{Graph isomorphism} refers to the problem of determining whether two graphs are structurally identical, meaning there exists a one-to-one correspondence between their nodes and edges. This is a crucial challenge in graph classification tasks, where the goal is to assign labels to entire graphs based on their structures. A model that can effectively differentiate non-isomorphic graphs is said to have high expressiveness, which is essential for accurate classification. In many cases, graph classification models like GNNs rely on graph isomorphism tests to ensure that structurally distinct graphs receive different embeddings, which improves the model’s ability to correctly classify graphs. 

\noindent \textbf{Weisfeiler-Lehman (WL) test} is a widely used graph isomorphism test that forms the foundation of many GNNs. In the 1-WL framework, each node's representation is iteratively updated by aggregating information from its neighboring nodes, followed by a hashing process to capture the structural patterns of the graph. GNNs leveraging this concept, such as Graph Convolutional Networks (GCNs) and Graph Attention Networks (GATs), essentially perform a similar neighborhood aggregation, making them as expressive as the 1-WL test in distinguishing non-isomorphic graphs \citep{GIN}.  
Modern GNN architectures adhere to this paradigm, making the 1-WL a standard baseline for GNN expressivity.

\subsection{Theoretical Analysis}
We analyze our explained pathways based on the Weisfeiler-Lehman (WL) tests and expressiveness.
% (provided in Appendix \ref{Tools}).
\begin{restatable}{lemma}{exprforexpl}(Expressiveness for explanations).
\label{lmm:expr_for_expl}
When combined with higher expressive models
(\emph{e.g.}, it distinguishes more graphs), 
\explainer can generate more finely differentiated (and potentially 
more ``faithful'') explanation pathways (subgraphs). 
In contrast, a less expressive models
merges different graphs (or nodes/substructures) into larger equivalence classes, 
leading to non-unique, less granular explanations.
\end{restatable}

% In Appendix \ref{app:proof}, we prove this by showing that 
% the expressiveness of the underlying a graph classifier
% $f$ determines the granularity of equivalence classes, with more expressive models enabling finer distinctions between graphs. Consequently, higher expressiveness leads to more specific and faithful explanations, while less expressive models yield coarser and less granular explanations.


\begin{proof}
Let $f : \mathcal{G} \to \mathbb{R}^k$ be a GNN-based model, and let $\sim$ denote the equivalence relation induced by $f$, i.e.,
\[
G \sim H \quad \Longleftrightarrow \quad f(G) = f(H).
\]
Consider a GNNExplainer objective given by
\[
\mathcal{L}(E; f, G) = \alpha \cdot D\bigl(f(G), f(G \setminus E)\bigr) + \beta \cdot \Omega(E),
\]
where $E \subseteq \text{components}(G)$ (e.g., a subset of edges/nodes/features), 
$D(\cdot,\cdot)$ is a distance or divergence measure between outputs, 
and $\Omega(E)$ is a regularization term encouraging compactness or sparsity.
Define the explainer's solution by
\[
E^*(G) \;=\; \underset{E \subseteq G}{\mathrm{argmin}}\; \mathcal{L}(E; f, G).
\]
If $G \sim H$, then any pair of optimal explanations $E^*(G)$ and $E^*(H)$ 
must yield the same minimum objective value. Consequently, there is no unique 
explanation across $G$ and $H$ within the same equivalence class.

Since $G \sim H$, we have $f(G) = f(H)$. 
By definition of $E^*(G)$,
\[
\mathcal{L}\bigl(E^*(G); f, G\bigr) \;=\;
\min_{E \subseteq G} \; \mathcal{L}(E; f, G).
\]
Similarly, for $H$,
\[
\mathcal{L}\bigl(E^*(H); f, H\bigr) \;=\;
\min_{E \subseteq H} \; \mathcal{L}(E; f, H).
\]

Because $f(G) = f(H)$, the distance term 
$D\bigl(f(G), f(G \setminus E)\bigr)$ behaves the same as 
$D\bigl(f(H), f(H \setminus E)\bigr)$ for corresponding substructures $E$ 
(insofar as the GNN does not distinguish between the same substructure in $G$ 
and that in $H$). Furthermore, if $G$ and $H$ are isomorphic under the viewpoint 
of $f$, any subgraph $E_G$ of $G$ can be mapped to a subgraph $E_H$ of $H$ with 
equivalent contribution to $D(\cdot,\cdot)$ and to $\Omega(\cdot)$. 

Hence, there exists a subgraph $E_H \subseteq H$ such that
\[
\mathcal{L}(E_H; f, H) = \mathcal{L}(E^*(G); f, G).
\]
Likewise, one can construct a subgraph $E_G$ from $E^*(H)$ with the same objective value. 
Thus, for any $G \sim H$, 
\[
\mathcal{L}\bigl(E^*(G); f, G\bigr) = \mathcal{L}\bigl(E^*(H); f, H\bigr),
\]
which implies the optimal explanations are not uniquely determined 
beyond the equivalence class $[G]$ (the set of all graphs equivalent to $G$). 
In other words, the GNNExplainer's solution within an equivalence class $\sim$ 
cannot uniquely distinguish between graphs $G$ and $H$ such that $G \sim H$. 
Less expressive models 
merges different graphs (or nodes/substructures) into larger equivalence classes, 
leading to non-unique, less granular explanations.
In contrast, 
\explainer can generate more finely differentiated explanation subgraphs, when combined with higher expressive models. 
\qedhere
\end{proof}

\begin{lemma}[Comparison with k-WL test]
\label{lmm:k-wl}
For every $k\ge 1$ there are graphs that are distinguishable
    by \classifier, but not
    by $k$-WL (and hence not by $k$-WL GNNs).
\end{lemma}

\begin{proof}
The proof of this theorem directly comes from the recent work \cite{crawl, graphmamba_kdd}. They prove a similar
theorem using 1-d CNN \cite{crawl} or SSM \cite{graphmamba_kdd} with random sampled subgraph.
\end{proof}

\begin{lemma}[Comparison with 1-WL test]
\label{lmm:1-wl}
\classifier is strictly more expressive than 1-WL GNNs.
\end{lemma}

\begin{proof}
We first note that \classifier\ contains the GIN as a sub-module, which has the same expressive power as the 1-WL test \cite{GIN}.
Therefore, \classifier\ is at least as expressive as 1-WL GNNs.
By Lemma~\ref{lmm:k-wl}, there are graphs that cannot be
distinguished by $1$-WL GNNs, but can be distinguished by
\classifier. Consequently, \classifier\ is strictly more expressive than 1-WL
GNNs.
\end{proof}

\begin{theorem}[Explanations of \method]
\label{thm}
Based on Lemma \ref{lmm:expr_for_expl}, \ref{lmm:k-wl}, and \ref{lmm:1-wl}, \method can generate more finely differentiated (and potentially 
more ``faithful'') explanation pathways (subgraphs) than 1-WL GNN-based methods, and not bounded by any WL GNN methods.
\end{theorem}

\section{Computational Complexity Analysis}
\label{app:complexity}
Given \( K \) tokens, the complexity of Mamba \cite{Mamba} is  linear with respect to \( K \). 
For \( m \geq 1 \), for each node \( v \in V \), we generate \( |V| \) sampled pathways with length \( m \), the time complexity of global module mamba
would be: 
\[ O(|V| \times m), \]
since we have \( O(|V| \times m) \) tokens. 
Our \classifier is faster than the quadratic time complexity \( O(|V| ^2) \) of graph transformers \cite{GPS}.
% In practice, our $|V|$ pathways can be processed in parallel, our approach is faster than Graph-Mamba \cite{Geraph-Mamba}, which process all nodes sequentially.

In practice, combined with GNN, which requires \( O(|V| + |E|) \) time,
the totall complexity would be:
\[
O(|V| + |E|),
\]
dominated by the GNN complexity,
since $m$ represents only a subset of pathways sampled from the total possible nodes \( V \) 
(\(m \ll |V|\)).




% \section{Proofs of Expressivity analysis}
% \label{app:proof}
% \exprforexpl*

% \begin{proof}
% Let $f : \mathcal{G} \to \mathbb{R}^k$ be a GNN-based model, and let $\sim$ denote the equivalence relation induced by $f$, i.e.,
% \[
% G \sim H \quad \Longleftrightarrow \quad f(G) = f(H).
% \]
% Consider a GNNExplainer objective given by
% \[
% \mathcal{L}(E; f, G) = \alpha \cdot D\bigl(f(G), f(G \setminus E)\bigr) + \beta \cdot \Omega(E),
% \]
% where $E \subseteq \text{components}(G)$ (e.g., a subset of edges/nodes/features), 
% $D(\cdot,\cdot)$ is a distance or divergence measure between outputs, 
% and $\Omega(E)$ is a regularization term encouraging compactness or sparsity.
% Define the explainer's solution by
% \[
% E^*(G) \;=\; \underset{E \subseteq G}{\mathrm{argmin}}\; \mathcal{L}(E; f, G).
% \]
% If $G \sim H$, then any pair of optimal explanations $E^*(G)$ and $E^*(H)$ 
% must yield the same minimum objective value. Consequently, there is no unique 
% explanation across $G$ and $H$ within the same equivalence class.

% Since $G \sim H$, we have $f(G) = f(H)$. 
% By definition of $E^*(G)$,
% \[
% \mathcal{L}\bigl(E^*(G); f, G\bigr) \;=\;
% \min_{E \subseteq G} \; \mathcal{L}(E; f, G).
% \]
% Similarly, for $H$,
% \[
% \mathcal{L}\bigl(E^*(H); f, H\bigr) \;=\;
% \min_{E \subseteq H} \; \mathcal{L}(E; f, H).
% \]

% Because $f(G) = f(H)$, the distance term 
% $D\bigl(f(G), f(G \setminus E)\bigr)$ behaves the same as 
% $D\bigl(f(H), f(H \setminus E)\bigr)$ for corresponding substructures $E$ 
% (insofar as the GNN does not distinguish between the same substructure in $G$ 
% and that in $H$). Furthermore, if $G$ and $H$ are isomorphic under the viewpoint 
% of $f$, any subgraph $E_G$ of $G$ can be mapped to a subgraph $E_H$ of $H$ with 
% equivalent contribution to $D(\cdot,\cdot)$ and to $\Omega(\cdot)$. 

% Hence, there exists a subgraph $E_H \subseteq H$ such that
% \[
% \mathcal{L}(E_H; f, H) = \mathcal{L}(E^*(G); f, G).
% \]
% Likewise, one can construct a subgraph $E_G$ from $E^*(H)$ with the same objective value. 
% Thus, for any $G \sim H$, 
% \[
% \mathcal{L}\bigl(E^*(G); f, G\bigr) = \mathcal{L}\bigl(E^*(H); f, H\bigr),
% \]
% which implies the optimal explanations are not uniquely determined 
% beyond the equivalence class $[G]$ (the set of all graphs equivalent to $G$). 
% In other words, the GNNExplainer's solution within an equivalence class $\sim$ 
% cannot uniquely distinguish between graphs $G$ and $H$ such that $G \sim H$. 
% Less expressive models 
% merges different graphs (or nodes/substructures) into larger equivalence classes, 
% leading to non-unique, less granular explanations.
% In contrast, 
% \explainer can generate more finely differentiated explanation subgraphs, when combined with higher expressive models. 
% \qedhere
% \end{proof}

% \begin{theorem}[Expressive GNNs Provide More Fine-Grained Explanations]
% \label{thm:expressive_gnn_refines_explanation}
% Let $f_1, f_2 : \mathcal{G} \to \mathbb{R}^k$ be two GNN-based predictors, with
% $f_1$ \emph{strictly more expressive} than $f_2$. Concretely, this means: 
% if $G \not\sim_1 H$, then $G$ and $H$ must also be distinct under $f_2$'s equivalence 
% relation $\sim_2$ only if $f_2$ can also distinguish them. Formally,
% \[
% \text{``More expressive'' means }
% \forall G,H,\; (f_1(G) \neq f_1(H)) \implies (f_2(G) \neq f_2(H)) 
% \quad (\text{i.e. } \sim_2 \text{ is coarser or equal to } \sim_1).
% \]
% Then, let $E^*_{f_1}(G)$ and $E^*_{f_2}(G)$ be the sets of optimal explanations 
% for $G$ under $f_1$ and $f_2$, respectively (defined via the same explainer objective 
% $\mathcal{L}$). The following statements hold:

% \begin{enumerate}
%   \item (Finer Equivalence Classes) The equivalence class $[G]_{f_1}$ induced by $f_1$ 
%   is a subset of or equal to the equivalence class $[G]_{f_2}$ induced by $f_2$. 
%   In other words, 
%   \[
%   [G]_{f_1} \;\subseteq\; [G]_{f_2}.
%   \]
%   \item (More Distinct Explanations) If two graphs $G$ and $H$ are distinct 
%   yet $f_2(G) = f_2(H)$ (they lie in the same equivalence class of $f_2$) 
%   but $f_1(G) \neq f_1(H)$ (they lie in different equivalence classes of $f_1$), 
%   then $E^*_{f_1}(G)$ and $E^*_{f_1}(H)$ can differ \emph{uniquely} 
%   while $E^*_{f_2}(G)$ and $E^*_{f_2}(H)$ must coincide or fail to distinguish $G$ and $H$.
% \end{enumerate}
% Consequently, $f_1$ (the more expressive GNN) admits more fine-grained, 
% and thus more \emph{distinctive}, explanations.
% \end{theorem}

% \begin{proof}
% \textbf{(1) Finer Equivalence Classes.}  
% By the assumption of ``strictly more expressive,'' whenever $f_1(G) \neq f_1(H)$, 
% it must also be that $f_2(G) \neq f_2(H)$. Equivalently,
% \[
% f_2(G) = f_2(H) \;\Longrightarrow\; f_1(G) = f_1(H).
% \]
% Hence,
% \[
% G \sim_2 H \quad \Longrightarrow \quad G \sim_1 H.
% \]
% This means any pair of graphs deemed equivalent by $f_2$ is also deemed equivalent by $f_1$, 
% so $[G]_{f_2} \subseteq [G]_{f_1}$ for any $G$. 
% (Or equivalently $[G]_{f_1} \subseteq [G]_{f_2}$, depending on the chosen direction; 
% the key point is that $f_1$ creates strictly finer or equal classes.)

% \medskip

% \noindent
% \textbf{(2) More Distinct Explanations.}  
% Consider two graphs $G$ and $H$ such that $f_2(G) = f_2(H)$ but $f_1(G) \neq f_1(H)$. 
% Under $f_2$, both $G$ and $H$ fall into the same equivalence class, 
% so from Theorem~\ref{thm:gnn_equiv_explanation}, we have:
% \[
% \mathcal{L}\bigl(E^*_{f_2}(G); f_2, G\bigr) \;=\; 
% \mathcal{L}\bigl(E^*_{f_2}(H); f_2, H\bigr),
% \]
% implying $E^*_{f_2}(G)$ and $E^*_{f_2}(H)$ cannot be distinguished 
% based on the $f_2$-induced predictions (they are effectively ``non-unique'' 
% with respect to $G$ and $H$).

% However, under $f_1$ (the more expressive GNN), $G \not\sim_1 H$. Therefore, 
% $f_1(G) \neq f_1(H)$, meaning that the GNN at least partially separates 
% the two graphs in its latent space. Consequently, it is possible for 
% the corresponding GNNExplainer objective to yield distinct substructures 
% $E^*_{f_1}(G)$ and $E^*_{f_1}(H)$ that reflect the difference 
% in $f_1$'s predictions. In other words, the GNN with finer representational 
% capabilities can ``pick up'' on structural or feature differences between $G$ and $H$ 
% that a less expressive GNN ($f_2$) ignores. This yields more fine-grained 
% and distinct explanations:
% \[
% \mathcal{L}\bigl(E^*_{f_1}(G); f_1, G\bigr) \;\;\text{vs.}\;\;
% \mathcal{L}\bigl(E^*_{f_1}(H); f_1, H\bigr),
% \]
% where 
% \[
% E^*_{f_1}(G) \;\neq\; E^*_{f_1}(H)
% \quad\text{and}\quad
% \mathcal{L}\bigl(E^*_{f_1}(G); f_1, G\bigr) \;\neq\; 
% \mathcal{L}\bigl(E^*_{f_1}(H); f_1, H\bigr).
% \]
% Hence, $f_1$'s stronger discriminatory power leads to more 
% \emph{distinctive} explanation substructures. 
% \qedhere
% \end{proof}


% \textbf{Remark.}
% The above results illustrate that if a GNN has higher expressive power 
% (\emph{e.g.}, it distinguishes more graphs), 
% the equivalence classes it induces are typically smaller. Consequently, 
% the explainer can generate more finely differentiated (and potentially 
% more ``faithful'') explanations. In contrast, a less expressive GNN 
% merges different graphs (or nodes/substructures) into larger equivalence classes, 
% leading to non-unique, less granular explanations.


\section{Preprocessing}
\label{app:dataprecessing}
The KEGG database is a comprehensive resource that integrates genomic, chemical, and systemic functional information, providing curated pathway networks for various biological processes derived from experimental data and expert annotations.
For human pathways, KEGG offers detailed representations of processes such as metabolism, genetic information processing, environmental information processing, and human diseases.
Each category includes pathways organized into networks, where nodes represent biological entities—such as genes, proteins, enzymes, or metabolites—and edges denote their interactions.
These interactions encompass direct biochemical reactions, regulatory relationships, and signaling pathways that govern cellular mechanisms, ultimately forming pathways related to various functional biological processes.   

We searched for and downloaded all the raw data for the human pathway network (referred to as Homo Sapiens in most bio-databases) using KEGG APIs.
The data underwent a series of preprocessing steps to ensure its quality and relevance.
(1) First, we ensured that all protein nodes in the network were linked to well-characterized genetic origins, specifically their reference amino acid sequence data \cite{keggseq}. 
Using KEGG's gene-to-protein mapping, we filtered the dataset to retain only protein nodes with associated genomic annotations \cite{keggmapper}. 
Protein nodes lacking sequencing data or genetic associations in KEGG were excluded to reduce noise caused by incomplete or ambiguous sequence information. 
For the retained nodes, their amino acid sequences were extracted and utilized as input features, ensuring a biologically meaningful representation for the learning task.
(2) Second, we streamlined the network structure by removing redundant or biologically insignificant interactions. 
Specifically, we eliminated non-functional self-loops (edges connecting a node to itself without annotated biological relevance) and isolated nodes lacking any edges. 
This process included both nodes that were initially isolated and those rendered isolated following the first step of node filtering. 
Since these elements no longer contributed to the network's connectivity or functional variation, their removal reduced unnecessary complexity and ensured the network focused exclusively on meaningful and biologically interpretable interactions \cite{clean}.
(3) Third, we preserved the edge with properties of protein-protein interactions while removing directional information to transform the network into an undirected graph. 
This conversion enabled the analysis to emphasize undirected, pairwise interactions, which are often more pertinent to network-based studies, such as clustering, community detection, or functional enrichment analyses.
(4) Finally, the pathways were organized into functional classes based on their KEGG pathway labels, ensuring that biologically related pathways were grouped together. 
The original labels for Environmental Information Processing and Genetic Information Processing were combined into a unified class, Molecular and Cellular Processes, to reflect their shared biological roles in cellular signaling, communication, and gene regulation \cite{kegglabel}. 
As a result, the pathway data used in this study was categorized into four main classes: Human Diseases, Metabolism, Molecular and Cellular Processes, and Organismal Systems.


\section{Baseline}
\label{app:gnnbaseline}

We collected baselines from both message-passing GNNs and more advanced graph models. 
Graph Convolutional Network (GCN) \cite{GCN} serves as a foundational GNN, leveraging spectral graph theory for node feature aggregation. 
GraphSAGE \cite{GraphSAGE} improves scalability by introducing neighborhood sampling and learnable aggregation functions. 
Graph Attention Network (GAT) \cite{GAT} incorporates attention mechanisms to assign different importance to neighbors during feature aggregation. 
Graph Isomorphism Network (GIN) \cite{GIN} achieves high expressivity, distinguishing graph structures with a focus on injective neighborhood aggregation. 
GPS \cite{GPS} combines GNNs with transformer-style global attention to effectively process both local and global graph structures. 
Similarly, Graph-Mamba \cite{Geraph-Mamba} processes local structures using GNNs and leverages the Mamba module to capture global node relationships.

For explainer baselines, among statistical methods, Random Sampling (RRS) \cite{10.1093/bioinformatics/bth163} serves as a simple baseline by selecting nodes or edges randomly for comparison. 
Personalized PageRank (PPR) \cite{PMID:21149343} computes node importance by incorporating a teleportation mechanism that biases the random walk towards specific nodes, effectively capturing both local and global graph structures. 
Minimum Dominating Set (MDS) \cite{NACHER201657, doi:10.1073/pnas.1311231111} identifies a minimal set of nodes that can collectively influence or dominate all other nodes in the graph, providing insights into critical nodes for coverage or control.
Notably these three statistical methods only do not use AA sequence node features.
For gradient-based methods, 
% Integrated Gradients computes feature importance by integrating gradients along the path from a baseline input to the actual input. 
Saliency \cite{saliency} highlights features based on the magnitude of input gradients. 
InputXGradient \cite{InputXGradient} combines input features with their gradients to capture feature significance. 
Deconvolution \cite{deconvolustion} focuses on reconstructing important input features, emphasizing positive influences. 
ShapleyValueSampling \cite{shapley} estimates feature importance using a game-theoretic approach. 
GuidedBackpropagation \cite{guidedbackpropagation} refines gradients to highlight only relevant activations.
From GNN-specific explainability approaches, we adopted GNNExplainer \cite{gnnexplainer} to uncover subgraphs and features that are critical for predictions, and PGExplainer \cite{pgexplainer}, which uses a neural network to identify significant graph components.


\section{Metrics}
\label{metric}


\begin{itemize}[left=0pt]
    \item \textbf{Fidelity+}: Fidelity+ measures how well the important features identified by the model contribute to accurate predictions. It is defined as:  
\[
\text{Fidelity+} = \frac{1}{N} \sum_{i=1}^{N} \big( f(G_i) - f(G_i \setminus S_i) \big),
\]
where \( f(G_i) \) is the prediction score for graph \( G_i \), and \( f(G_i \setminus S_i) \) is the prediction score after removing the subgraph \( S_i \) identified as important.
\item \textbf{Fidelity-}: Fidelity- evaluates the drop in prediction accuracy when the identified important features are retained while others are removed. It is defined as:  
\[
\text{Fidelity-} = \frac{1}{N} \sum_{i=1}^{N} \big( f(S_i) - f(G_i) \big),
\]
where \( f(S_i) \) is the prediction score for the retained subgraph \( S_i \), and \( f(G_i) \) is the original score.
\end{itemize}

As a classic method of biological functional enrichment analysis, GO analysis evaluates whether specific biological processes, molecular functions, or cellular components are statistically overrepresented in a given set of genes (i.e., gene nodes from subgraphs) compared to a background gene set \cite{enrichment}.
The results provide a list of GO terms that highlight the biological functions most significantly represented in the input gene nodes \cite{GO}.
In our study, we conducted GO enrichment analysis using the R package \texttt{clusterProfiler} \cite{clusterProfiler} to identify enriched GO terms.

To assess \textbf{Breadth} of the subgraphs' biological functions, we use the Number of Enriched Biological Functions (\textbf{\#EBF}) as a metric. 
For an input subgraph \( S_i \), \#EBF is defined as:
\[
\#EBF(S_i) = |GO_{\text{enriched}}(S_i)|,
\]
where \( S_i \) denotes the i-th input subgraph, \( GO_{\text{enriched}}(S_i) \) is the set of significantly enriched GO terms associated with the genes in \( S_i \), and \( |GO_{\text{enriched}}(S_i)| \) is the size of the set of enriched GO terms for subgraph \( S_i \).
A high \#EBF value indicates broader functional diversity within the subgraph.

To assess \textbf{Depth} of the subgraphs' biological functions, we used the Enrichment Contribution Score (\textbf{ECS}) as a metric.  
The ECS evaluates the relative contribution of the top-weighted genes, denoted as \( G_{\text{Top}} \), to the enrichment of biological functions. 
The ECS can be assessed by following steps:
Let \( G = \{ g_1, g_2, \dots, g_n \} \) represent the ranked list of gene nodes, sorted by their importance scores (weights) \( w = \{ w_1, w_2, \dots, w_n \} \), where \( w_1 \ge w_2 \ge \dots \ge w_n \).  
Define \( G_{\text{Top}} = \{ g_1, g_2, \dots, g_{\text{Top}} \} \) to include only genes with the top weights, selected based on a ratio \( R\% \) (defaulted as 30\%), as a subset of \( G \).
Then, perform GO analysis based on \( G_{\text{Top}} \) for each input subgraph \( S_i \).
The ECS is calculated as the average number of enriched items for each gene in \( G_{\text{Top}} \) across all subgraphs \( S_i \), and is defined as:
\[
\text{ECS} = \frac{1}{P} \sum_{i=1}^{P} \frac{|GO_{\text{top-enriched}}(S_i)|}{|G_{\text{Top}}|},
\]
where \( P \) is the total number of tested subgraphs, \( GO_{\text{top-enriched}}(S_i) \) is the set of enriched GO terms for subgraph \( S_i \) based on \( G_{\text{Top}} \), and \( |G_{\text{Top}}| \) is the number of genes in the subset \( G_{\text{Top}} \).

To assess \textbf{Reliability} of the subgraphs' biological functions, we use the well-established statistical concept \textbf{P-value} as a metric. 
Specifically, the P-value is calculated as the average of the P-values from statistical tests performed for biological function enrichment in each subgraph above.
Since during the GO analysis, we accept the item only with a P-value lower than 0.05, the average P-value reported here is naturally lower than this threshold.
A lower average P-value indicates greater reliability in the enrichment results across the subgraphs.




\section{Ablation Study}

\subsection{Classifier ablation}
\begin{table}[t]
\centering
 \caption{\explainer fidelity score comparison with other classifier models. }
\resizebox{\linewidth}{!}{%
\label{tab:classifier}
\begin{tabular}{llcc}
\toprule
\textbf{Methods} &\textbf{Fidelity+} & \textbf{Fidelity-} & (Accuracy) \\
\midrule
GIN             &  0.689 $\pm$ 0.012             &   0.390 $\pm$ 0.008   & (0.717 ± 0.013)\\
GPS            &  0.763 $\pm$ 0.017             &   0.529 $\pm$ 0.011    & (0.726 ± 0.014)\\
Graph-Mamba               &  0.708 $\pm$ 0.015            & 0.430 $\pm$ 0.012 & (0.723 ± 0.014)                              \\
\classifier       &  \textbf{0.442 $\pm$ 0.012}          &  \textbf{0.037 $\pm$ 0.008}    & (0.754 ± 0.015)   \\                     
\bottomrule
\end{tabular}%
}
\end{table}
Table \ref{tab:classifier} presents the results of \explainer when the classifier model is changed. In our \classifier, the fidelity+ score is reduced to less than one-tenth, indicating that the extracted subgraph alone produces nearly identical results. 
This suggests that \method is capable of extracting biologically functional pathways sufficiently. 
Our PathMamba exhibits a relatively low fidelity+, which may imply that it has strong representational power, allowing it to learn meaningful representations even from subgraphs that were not extracted.

\section{Case Study}\label{app:casestudy}
\begin{figure*}
\centering
\includegraphics[width=0.99\linewidth]{FIG/path_all.pdf}
\caption{Comparison of subgraphs extracted from the TCR signaling pathway using two different methods. The TCR Subgraph on the left is from the RSS method, and the TCR Subgraph on the right is from the proposed method. The subgraph nodes and their signaling modules are colored in red. The disruptions within signaling paths are marked in green boxes.}
\label{fig:path_all}
\end{figure*}

\subsection{T cell receptor (TCR) signaling pathway}
The T cell receptor (TCR) signaling pathway is a cornerstone of adaptive immunity, orchestrating antigen-specific T cell activation, clonal expansion, and effector differentiation \cite{TCR_1}. 
This pathway is initiated upon engagement of the TCR complex with peptide-MHC ligands, triggering a cascade of intracellular signaling events mediated by the Src-family kinases LCK and FYN, leading to phosphorylation of the immunoreceptor tyrosine-based activation motifs (ITAMs) within the CD3 and $\zeta$-chain subunits \cite{TCR_3}. 
Subsequent recruitment and activation of ZAP-70 further amplify downstream signaling through the LAT signalosome, engaging multiple adaptor proteins and second messengers that regulate key pathways, including calcium mobilization, Ras-MAPK, and NF-$\kappa$B signaling, which collectively drives gene transcription, metabolic reprogramming, and cytoskeletal remodeling necessary for T cell function \cite{TCR_2}. 

Precise modulation of these signaling cascades is critical for maintaining immune homeostasis, as dysregulation is implicated in a spectrum of immune disorders, including autoimmunity, primary immunodeficiencies, and T cell malignancies, where aberrant activation or attenuation of TCR signaling disrupts immune tolerance, facilitates chronic inflammation, or drives oncogenic transformation. 
Analysis of the molecular intricacies of TCR signaling helps therapeutic interventions, including immune checkpoint modulation, CAR-T \cite{CART} cell engineering, and small-molecule inhibitors aimed at restoring immune balance and targeting immune-related diseases.

\subsection{Results and discuss}
\textbf{TCR Subgraph A: The RSS Method. }  
As shown in Figure \ref{fig:path_all}, the subgraph on the left, generated by the RSS method, distributes high scores uniformly across a broad range of nodes within the TCR pathway. 
However, this hints at unnatural, fragmented signal propagation, as highlighted by numerous discrete red-marked nodes. 
The absence of coherent signaling continuity, as indicated by the disrupted green-boxed regions, suggests that the method fails to prioritize biologically meaningful regulatory modules. 
Since its broader coverage spans multiple branches of the pathway without emphasizing critical molecular hubs, limiting its utility in pinpointing key functional perturbations.

\textbf{TCR Subgraph B: The Proposed Method. }  
In contrast, as shown in Figure \ref{fig:path_all}, the subgraph on the right extracted by our method exhibits a strong focus on the PI3K-AKT signaling axis \cite{PI3K} and the downstream components of the NF-\(\kappa\)B \cite{nfkb} pathway, as highlighted by the coherent red-marked path.
 These regions are believed to be crucial for regulating T cell survival, proliferation, and cytokine production \cite{nfkball}.  
Notably, the subgraph includes key regulatory genes such as \textit{MAPK1}, \textit{MAP3K8}, and \textit{NFKB1} \cite{MAPK1,NFKB1} within a compact set of prioritized nodes.  
The enrichment of these molecular hubs suggests that our method effectively captures biologically significant signaling elements, aligning with well-established immune regulatory mechanisms.  

In our case study, the proposed method provides a focused selection of key regulatory pathways, emphasizing PI3K-AKT and NF-\(\kappa\)B signaling and their downstream effectors, which are crucial for modulating immune responses. 
In contrast, the RSS method, while providing broader pathway coverage, lacks specificity, making it less suitable for pathway analyses requiring mechanistic interpretation.
