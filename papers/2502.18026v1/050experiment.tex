\begin{table*}[t]
\caption{Baseline comparison results on bio-network classification. The best-performing and second-best results are highlighted in \textbf{bold} and \underline{underline}, respectively.
The gray-shaded rows indicate \classifier (650M) with different ESM-2 parameter settings.
}
\label{tab:classification_result}
%
% // \vskip 0.15in
\begin{center}
\resizebox{\textwidth}{!}{
\begin{tabular}{l|cc|cc|cc|cc|c}
\toprule
       & \multicolumn{2}{c|}{Human Diseases} & \multicolumn{2}{c|}{Metabolism} & \multicolumn{2}{c|}{Organismal Systems} & \multicolumn{2}{c|}{Molecular \& Cellular Processes} &   Overall      \\ 
% \hline
Methods         & Precision   & Recall                & Precision   & Recall            & Precision   & Recall                    & Precision   & Recall                                  & Accuracy     \\ 
% \cline{2-10}
\midrule
GCN               & 0.632 ± 0.013 & 0.669 ± 0.022           & 0.895 ± 0.009 & 0.958 ± 0.007       & 0.644 ± 0.037 & 0.630 ± 0.023               & 0.570 ± 0.033 & 0.357 ± 0.025                             & 0.683 ± 0.056  \\
GraphSAGE         & 0.583 ± 0.020 & 0.633 ± 0.072           & 0.890 ± 0.007 & 0.959 ± 0.014       & 0.553 ± 0.041 & 0.575 ± 0.031               & 0.526 ± 0.059 & 0.337 ± 0.062                             & 0.632 ± 0.037  \\
GAT               & 0.630 ± 0.015 & 0.643 ± 0.036           & \textbf{0.932 ± 0.017} & \underline{0.970 ± 0.008}       & \underline{0.659 ± 0.015} & \textbf{0.703 ± 0.010}               & 0.560 ± 0.058 & 0.370 ± 0.025                             & 0.690 ± 0.018  \\
GIN               & 0.688 ± 0.023 & 0.697 ± 0.014           & 0.912 ± 0.016 & 0.944 ± 0.022       & 0.629 ± 0.025 & 0.638 ± 0.041               & 0.606 ± 0.032 & \underline{0.497 ± 0.027}                             & 0.717 ± 0.013  \\
GPS & \underline{0.744 ± 0.018} & \underline{0.729 ± 0.024}           & 0.893 ± 0.006 & 0.955 ± 0.014       & 0.634 ± 0.026 & 0.658 ± 0.011               & 0.629 ± 0.060 & \textbf{0.507 ± 0.019}                             & \underline{0.726 ± 0.014}  \\
Graph-Mamba        & 0.707 ± 0.024 & 0.712 ± 0.024           & 0.897 ± 0.009 & 0.967 ± 0.007       & 0.626 ± 0.021 & 0.663 ± 0.033               & \textbf{0.700 ± 0.021} & 0.463 ± 0.032                             & 0.723 ± 0.014  \\
\midrule
\rowcolor{gray!10}
\classifier         & \textbf{0.786 ± 0.029} & \textbf{0.800 ± 0.033}           & \underline{0.915 ± 0.011} & \textbf{0.972 ± 0.005}       & \textbf{0.670 ± 0.026} & \textbf{0.703 ± 0.010}               & \underline{0.667 ± 0.035} & \underline{0.497 ± 0.028}                             & \textbf{0.754 ± 0.015}  \\
\rowcolor{gray!10} w/ 3B         & 0.752 ± 0.022 & 0.726 ± 0.027           & 0.917 ± 0.008 & 0.973 ± 0.010       & 0.661 ± 0.017 & 0.663 ± 0.023               & 0.656 ± 0.032 & 0.550 ± 0.042                             & 0.742 ± 0.009  \\
\rowcolor{gray!10} w/ 150M         & 0.764 ± 0.031 & 0.764 ± 0.011           & 0.906 ± 0.011 & 0.975 ± 0.013       & 0.639 ± 0.023 & 0.688 ± 0.025               & 0.653 ± 0.029 & 0.510 ± 0.030                             & 0.728 ± 0.013  \\
\rowcolor{gray!10} w/ 35M         & 0.748 ± 0.033 & 0.751 ± 0.019           & 0.914 ± 0.005 & 0.969 ± 0.007       & 0.634 ± 0.028 & 0.663 ± 0.028               & 0.633 ± 0.055 & 0.510 ± 0.049                             & 0.722 ± 0.013  \\
\rowcolor{gray!10} w/o ESM-2         & 0.380 ± 0.008 & 0.585 ± 0.015           & 0.669 ± 0.015 & 0.585 ± 0.015       & 0.241 ± 0.007 & 0.063 ± 0.019               & 0.378 ± 0.030 & 0.377 ± 0.043                             & 0.440 ± 0.010  \\
\bottomrule
\end{tabular}
}
\end{center}
\end{table*}


\noindent\textbf{Dataset and Preprocessing. } 
We collected all available human pathway networks from the widely used knowledge database, KEGG \cite{kanehisa2000kegg}.
Our dataset consists of four main classes: Human Diseases, Metabolism, Molecular and Cellular Processes, and Organismal Systems \cite{KEGG2024}, covering 301 bio-networks.
We searched for and downloaded all the raw data for the human pathway network (referred to as Homo sapiens) using KEGG APIs.
To construct high-quality, trainable graphs, for nodes, we ensured that all protein nodes in the network were linked to their reference AA sequence data \cite{keggseq}. 
Protein nodes with a lack of or incomplete sequencing data were excluded. 
For edges, we streamlined the network structure by removing redundant or biologically insignificant interactions. 
We transformed preprocessed data into machine-learning-ready revision.
The detailed data description and preprocessing pipeline can be found in Appendix~\ref{app:dataprecessing} and Table \ref{tb:data_sum}.









% \begin{table}[t]
%     \centering
%     \caption{Summary of pathway data across four pathway classes.}
% \resizebox{0.95\linewidth}{!}{%
%     \begin{tabular}{llcccc}
%         \toprule
%         \multicolumn{2}{l}{Pathway class}& \#Samples & \#Nodes & \#Edges & AA-seq Length \\
%         \midrule
%         C1&Human Diseases & 83 & 4-126 & 2-129 & 253-1206 \\
%         C2&Metabolism & 78 & 2-46 & 1-254 & 345-820 \\
%         C3&\begin{tabular}[c]{@{}l@{}}Molecular and \\cellular processes\end{tabular} & 80 & 2-136 & 1-162 & 324-2038 \\
%         C4&Organismal systems & 60 & 2-103 & 1-134 & 298-1397 \\
%         \midrule
%         \multicolumn{2}{l}{Overall}  & 301 & 2-136 & 1-254 & 253-2038 \\
%         \bottomrule
%     \end{tabular}
%     }
%     \label{tb:data_sum}
% \end{table}

\noindent\textbf{Experimental Setup.} 
We conducted 10-fold stratified K-Fold cross-validation repeated 5 times. The mean and standard deviation of the results across all folds were reported for evaluation.
The hyperparameters were determined using grid search to identify the optimal configuration for the model.
Training for all models was accomplished on NVIDIA A6000 GPU and Xeon Gold 6258R CPU. 

\subsection{Experiment-I: Pathway Representation}
\label{subsec:exp1}

\textbf{Objective. }  Evaluate the classification performance on unseen bio-networks, in line with Hypothesis-1, and benchmark the results against baseline models.

\noindent\textbf{Baselines and Metrics.}
We collected baselines from both message-passing GNNs and more advanced graph models, including GCN \cite{GCN}, GraphSAGE \cite{GraphSAGE}, GAT \cite{GAT}, GIN \cite{GIN}, GPS \cite{GPS}, and Graph-Mamba \cite{Geraph-Mamba}.
The detailed introduction of these baselines and the selection motivation can be found in Appendix \ref{app:gnnbaseline}.
We used precision, recall, and overall accuracy for the performance evaluation. We used 650M ESM-2 for \classifier and all baselines.
% These metrics ensure a comprehensive assessment of the model's performance across all categories and the overall dataset.



% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.99\linewidth]{FIG/pLM.pdf} %\\
%     \vspace{-0.4em} 
%     \caption{Protein language model evaluation. \yd{the font size seems to small for the audience to read.}
%     {\color{red}
%     We can merge this figure into the main table to show different versions of the large model.
%     }
%     }
%     \vspace{-0.4em}
%     \label{fig:pLM}
%     \vspace{-0.4em}
% \end{figure}


\noindent\textbf{Results.}
Table~\ref{tab:classification_result} presents \classifier achieves the highest accuracy (0.754), outperforming all GNNs, GPS (0.726), GraphMamba (0.723). Furthermore, it secures best or second-best positions across all functional categories, demonstrating its robust ability to generalize across diverse pathway structures.
The superior performance of the proposed method highlights its effectiveness in extracting and leveraging biologically meaningful structural information from pathway networks.
The gray-shaded rows indicate the results of removing ESM-2 and modifying the model size in terms of F1 scores.
When ESM-2 is removed, the accuracy deteriorate significantly (0.75 → 0.44), highlighting the importance of AA-seq and the limitations of prior studies that were unable to leverage this information. 
Increasing the model size gradually improves the results; however, accuracy does not incline with the 3B model (0.754 → 0.742). This suggests that excessively large features may lead to overfitting or noise, particularly in capturing functional pathways.
Table \ref{tab:computational} compares the training and inference times of our model with other expressive hybrid models, using a batch size of 32. Our training time is 30\% faster than GPS and inference time is 27\% faster than Graph-Mamba (complexity analysis can be found in Appendix \ref{app:complexity}).

\begin{table}[t]
\centering
\caption{The computational efficiency comparison with hybrid models, including both training and inference runtime. }
\resizebox{0.99\linewidth}{!}{%
\label{tab:computational}
\begin{tabular}{lcc}
\toprule
\textbf{Methods} & \textbf{Training Time (msec)} & \textbf{Inference Time (msec)} \\
\midrule
GPS              &  29.2 $\pm$ 2.3             &   10.3 $\pm$ 0.3  \\
Graph-Mamba               &  34.8 $\pm$ 0.4            & 9.5 $\pm$ 0.2                               \\
\classifier       &  \textbf{24.4 $\pm$ 0.9}          &  \textbf{6.9 $\pm$ 0.2}       \\                     
\bottomrule
\end{tabular}%
}
\vspace{-0.3cm}
\end{table}




\subsection{Experiment-II: Pathway Inference}
\label{subsec:exp2}

\textbf{Objective. } Quantify the fidelity of extracted subgraphs, following our Hypothesis-2, and validate the importance of pathways specific to biological functions.

\noindent\textbf{Baselines and Metrics. }
We collected baselines from conventional statistical methods (Random Sampling \cite{10.1093/bioinformatics/bth163}, PersonalizedPageRank \cite{PMID:21149343}, and MinimumDominatingSet \cite{NACHER201657, doi:10.1073/pnas.1311231111}), gradient-based methods (Saliency \cite{saliency}, InputXGradient \cite{InputXGradient}, Deconvolution \cite{deconvolustion}, ShapleyValueSampling \cite{shapley}, and GuidedBackpropagation \cite{guidedbackpropagation}), and GNN-specific explainer methods (GNNExplainer \cite{gnnexplainer} and PGExplainer \cite{pgexplainer}).
All details can be found in Appendix \ref{app:gnnbaseline}. 
We evaluated the distinctiveness of the pathways inferred by \explainer using fidelity metrics, specifically Fidelity+ and Fidelity-.
Fidelity+ measures how well the important features identified by the model contribute to accurate predictions.
In contrast, the fidelity- evaluates the drop in prediction accuracy when the identified important features are retained while others are removed.
All details can be found in Appendix \ref{app:gnnbaseline} and \ref{metric}.

% 3. \textbf{Characterization Score}: Combines Fidelity+ and Fidelity- to assess the balance and interpretability of feature importance:
% \[
% \text{Characterization Score} = \frac{w_+ + w_-}{\frac{w_+}{\text{Fidelity+}} + \frac{w_-}{1 - \text{Fidelity-}}},
% \]
% where \( w_+ \) and \( w_- \) are weighting factors for Fidelity+ and Fidelity-, respectively.
% By setting both of them to 0.5, we ensure a fair evaluation that equally considers Fidelity+ and Fidelity-.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{FIG/explainer_result.pdf} 
    \vspace{-0.4em} 
    \caption{The fidelity+ (necessity ↑) and fidelity- (sufficiency ↓) scores of extracted subgraphs.
    Our \explainer achieves the best performance with the lowest fidelity+ and fidelity- scores, indicating its superior ability to produce robust and meaningful pathway networks.}
    \vspace{-0.4em}
    \label{fig:scatter}
    \vspace{-0.4em}
\end{figure}


\begin{figure*}[t]
\centering
\includegraphics[width=0.9\linewidth]{FIG/goall.pdf}
\caption{UpSet plot of enriched GO terms across four pathway classes, based on top feature sets from subgraphs for different methods. Orange indicates GO terms uniquely enriched in one class, and blue represents GO terms shared across multiple classes. RSS, MDS, and PPR stand for Random Sampling, Minimum Dominating Set, and Personalized PageRank, respectively. }
\label{fig:go}
\end{figure*}

\noindent\textbf{Results.} 
Figure \ref{fig:scatter} illustrates that \explainer achieves the highest fidelity+ and the lowest fidelity-, indicating its ability to explain necessary and sufficient subgraphs effectively. 
GNN-specific or gradient-based methods (blue points) show lower fidelity- compared to traditional methods (green points), demonstrating that the learned AA-seq enables the identification of sufficient subgraphs. 
PGExplainer exhibits lower fidelity+ than GNNExplainer, suggesting that instance-based approaches may be better suited for explaining diverse pathways.



\subsection{Experiment-III: Biological Meaningfulness}
\textbf{Overview. }
We proposed an evaluation workflow to analyze the biological significance of the extracted subgraphs and pathways. 
This workflow directly integrates the \ul{weighting/ranking scores of pathway inferred by \explainer} into biological metrics, enabling the direct quantification of outputs from deep learning models. 
Specifically, this includes: \textit{Breadth}: The diversity of biological functions represented by the subgraphs.
\textit{Depth}: The extent to which gene nodes contribute to these biological functions.
\textit{Reliability}: The robustness and statistical significance of the analyses targeting these biological functions.

\noindent\textbf{Setup and Metrics. }
To this end, we designed experiments centered on Gene Ontology (GO) analysis \cite{GO}, focusing on the nodes within the extracted subgraphs. 
The results provide a list of GO terms highlighting the biological functions most significantly represented in the input gene (corresponding to protein) nodes \cite{GO}.
\textit{Breadth} was assessed using the Number of Enriched Biological Functions (\textbf{\#EBF}). 
A higher \#EBF indicates broader functional diversity within the subgraph.
\textit{Depth} was evaluated using a new metric called the Enrichment Contribution Score (\textbf{ECS}).
ECS evaluates the relative contribution of the top-weighted genes, denoted as \( G_{\text{Top}} \).
Here we directly framed the inferred pathways as the targets of ECS to generate \( G_{\text{Top}} \) for evaluations by following steps:
Let \( G = \{ g_1, g_2, \dots, g_n \} \) represent the ranked list of gene nodes, sorted by the importance weights of pathways (inferred directly by \explainer) \( w = \{ w_1, w_2, \dots, w_n \} \), where \( w_1 \ge w_2 \ge \dots \ge w_n \).  
Define \( G_{\text{Top}} = \{ g_1, g_2, \dots, g_{\text{Top}} \} \) to include only genes with the top weights, selected based on a ratio \( R\% \) (defaulted as 30\%), as a subset of \( G \).
Then, perform GO analysis based on \( G_{\text{Top}} \) for each input subgraph \( S_i \).
The ECS is calculated as the average number of enriched items for each gene in \( G_{\text{Top}} \) across all subgraphs \( S_i \), and is defined as:
\[
\text{ECS} = \frac{1}{P} \sum_{i=1}^{P} \frac{|GO_{\text{top-enriched}}(S_i)|}{|G_{\text{Top}}|},
\]
where \( P \) is the total number of tested subgraphs, \( GO_{\text{top-enriched}}(S_i) \) is the set of enriched GO terms for subgraph \( S_i \) based on \( G_{\text{Top}} \), and \( |G_{\text{Top}}| \) is the number of genes in the subset \( G_{\text{Top}} \).
Moreover, \textit{Reliability} assessed using \textbf{P-value}.
We accepted the item only with a P-value lower than 0.05, the average P-value reported here is naturally lower than this threshold.
A lower average indicates greater reliability in the enrichment results across the subgraphs.
The details of GO and metrics can be found in Appendix \ref{metric}.





\begin{table}
\centering
\caption{Biological meaningfulness comparison results on subgraphs extracted by different methods. The best-performing results are highlighted in \textbf{bold}. The second-best results are highlighted in \underline{underline}. }
\label{table: bio_result}
\begin{tabular}{lccc} 
\toprule
                        Methods & \#EBF ($\uparrow$)          & ECS ($\uparrow$)           & P-value ($\downarrow$)         \\ 
\midrule
RSS                      & 5.29           & 0.27          & 0.045           \\
MDS                      & 6.34           & 0.23          & 0.043           \\
PPR                      & 6.64           & 0.23          & 0.042           \\ 
\midrule
GIN-GNNE                 & 6.94           & 0.59          & 0.041           \\
GPS-GNNE                 & 8.88           & 0.22          & 0.039           \\
GMamba-GNNE              & 10.73          & 0.21          & 0.042           \\
PathMamba-GNNE           & \underline{11.89}  & \underline{0.73}  & \textbf{0.036}  \\ 
\midrule
GIN-PathE                & 11.06          & 0.69          & 0.041           \\
GPS-PathE                & 8.26           & 0.43          & \underline{0.037}   \\
GMamba-PathE             & 10.89          & 0.59          & 0.038           \\
\textbf{\method} & \textbf{14.77} & \textbf{0.84} & \textbf{0.036}  \\
\bottomrule
\end{tabular}
  \vspace{-0.1in}
\end{table}

\noindent\textbf{Results. }
% RSS, MDS, and PPR stand for Random Subgraph Sampling, Minimum Dominating Set, and Personalized PageRank, respectively. 
Table~\ref{table: bio_result} presents the biological meaningfulness comparison results for subgraphs extracted using different methods. 
Overall, PathMamba-PathE achieves the highest performance across \#EBF, ECS, and P-value. 
This highlights its ability to extract biologically relevant structures within pathway networks, effectively balancing breadth and depth.
While conventional methods (RSS, MDS, and PPR) perform relatively poorly in overall \#EBF and ECS, with almost boundary P-values achieved.
%Besides, among the GNNExplainer-based methods, PathMamba-GNNE achieves the second-best overall \#EBF and ECS while obtaining the best P-value. 
%This suggests that PathMamba effectively contributes to biologically meaningful subgraphs over the downstream explainer.

Figure \ref{fig:go} evaluates the differences in enriched GO terms across four pathway classes based on top gene sets from subgraphs extracted by different methods.
Compared with other methods, the upset plot reveals that PathMamba-PathE identifies the most extensive sets of unique GO terms (shown as the orange bars and links) across all four pathway classes while maintaining fewer shared terms (shown as the blue bars and links) among different classes.
This suggests that PathMamba-PathE tends to assign appropriate weights to genes based on their importance within the network and effectively captures the distinct biological roles of top-ranked genes in specific pathway classes.
%In contrast, the other methods, including conventional and deep-based, perform poorly in consistently identifying unique GO terms for all four classes. 
%Their GO term sets tend to exhibit more functional overlap, indicating that they may not adequately differentiate the roles of top-ranked genes despite their classification into different pathway categories.

\subsection{Case Study: T Cell Receptor Signaling Pathway Evaluation}
%{\color{red}Ziwei: need to revise}

\noindent\textbf{Setup.}  
The T cell receptor (TCR) signaling pathway is a classic example of well-characterized human pathways.
% The T cell receptor (TCR) signaling pathway is a classic example of well-characterized human pathways, playing a central role in adaptive immunity, orchestrating T cell activation, differentiation, and effector responses \cite{TCR_1}. 
% Partly key aberrations in the TCR signaling pathway associated with autoimmune disorders, immune deficiencies, and cancer \cite{TCR_2}.
It would be helpful if parts implying key aberrations could be found as sub-graphs in the whole pathway graph.
In this case study, we compare subgraphs extracted by two methods: TCR Subgraph A, generated using the RSS method, and Subgraph B, obtained via our proposed method. 
Each method selects the top 10\% highest-ranked nodes and their associated edges to construct a representative subgraph.
The detailed information and results analysis of the case study can be found in Appendix~\ref{app:casestudy}.


\noindent\textbf{TCR Subgraph A: The RSS Method. }  
As shown in Figure \ref{fig:path}, subgraph A, generated by the RSS method, distributes high scores uniformly across a broad range of nodes within the TCR pathway. 
However, this hints at unnatural, fragmented signal propagation, as highlighted by numerous discrete red-marked nodes. 
% The absence of coherent signaling continuity, as indicated by the disrupted green-boxed regions, suggests that the method fails to prioritize biologically meaningful regulatory modules. 
% Since its broader coverage spans multiple branches of the pathway without emphasizing critical molecular hubs, limiting its utility in pinpointing key functional perturbations.

\noindent\textbf{TCR Subgraph B: The Proposed Method. }  
In contrast, as shown in Figure \ref{fig:path} subgraph B, the subgraph extracted by our method exhibits a strong focus on the PI3K-AKT signaling axis \cite{PI3K} and the downstream components of the NF-\(\kappa\)B \cite{nfkb} pathway, as highlighted by the coherent red-marked path.
% These regions are believed to be crucial for regulating T cell survival, proliferation, and cytokine production \cite{nfkball}.  
% Notably, the subgraph includes key regulatory genes such as \textit{MAPK1}, \textit{MAP3K8}, and \textit{NFKB1} \cite{MAPK1,NFKB1} within a compact set of prioritized nodes.  
% The enrichment of these molecular hubs suggests that our method effectively captures biologically significant signaling elements, aligning with well-established immune regulatory mechanisms.  

\noindent\textbf{Discuss. }  
% In our case study, the proposed provides a focused selection of key regulatory pathways, emphasizing PI3K-AKT and NF-\(\kappa\)B signaling and their downstream effectors, which are crucial for modulating immune responses. 
% In contrast, the RSS method, while providing broader pathway coverage, lacks specificity, making it less suitable for pathway analyses requiring mechanistic interpretation.
In summary, the proposed method's subgraphs align with real-world pathway analysis practices' needs: maintaining \textbf{signal continuity within regulatory cascades} and even holding relatively long signaling paths, making it more suitable for focused analyses of bio-network regulatory mechanisms.

\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{FIG/path.pdf}
\caption{Comparison of subgraphs extracted from the TCR signaling pathway using two different methods. TCR Subgraph A is from the RSS method, and TCR Subgraph B is from the proposed method. The subgraph nodes and their signaling modules are colored in red. The disruptions within signaling paths are marked in green boxes.}
\label{fig:path}
\end{figure}