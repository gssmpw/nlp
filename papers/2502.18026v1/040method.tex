\subsection{Framework}
 
\method comprises three components: large protein model encodings, graph-based classification, and post-hoc subgraph explanation, as shown in Figure \ref{fig:systemOV}. 
First, we encode AA sequence data using a pre-trained large protein model, ESM-2 \cite{ESM} (see Section \ref{pLM} ), to serve as node attributes.
% Next, we construct graphs for various bio-networks where each node corresponds to a protein and edges represent known or predicted interactions. 
To address (\ul{Task-1, Hypothesis-1}),
\classifier, a classifier combining graph neural networks (GNNs) with state-space sequence modeling (Mamba), is to capture both local node-pair interactions and global \textbf{pathway-level dependencies} (see Section \ref{sec:classifier}). 
% This model is trained on the node embeddings to predict functional or pathway-level labels.
To address (\ul{Task-2, Hypothesis-2}), \explainer, an explainer method trained with \textbf{pathway-wise masks} (see Section \ref{sec:explainer}), aims to identify the most influential subgraphs.
%by masking less relevant edges and node features.
We explicitly integrate pathway-level information into both models to satisfy \ul{Hypothesis-3}.
The large protein model ensures biologically meaningful protein representations, \classifier leverages various pathway information in knowledge bases for robust classification, and \explainer highlights minimal subgraphs that drive the final predictions, offering interpretable insights into key pathways.
We evaluate \method from both machine learning and biological perspectives, as detailed in Section \ref{sec:exp}.


% an explainer method, PathExplainer trained with \textbf{pathway-wise masks} (see Section \ref{sec:explainer}) is applied to isolate the most influential substructures by masking out less relevant edges and node features. 
% The large protein model preserves biologically meaningful sequence representations, the GNN exploits graph connectivity for robust classification, and the explainer selectively highlights the minimal subgraphs that drive the final prediction, offering interpretable insights into key pathway components.



\subsection{Data Encoding for Node Attributes}
\label{pLM}
\subsubsection{Large Protein Language Model Encoding}

The ESM-2 model \cite{ESM}, pre-trained on over 60 million AA sequences with parameter scaling up to 15 billion, is employed to encode our data. 
We evaluate different parameter variants of ESM-2, and the results are presented in Table \ref{tab:classification_result}.
% This model, pre-trained on over 60 million AA sequences, aims to address the limitations of existing methods like BLAST \cite{BLAST1}, which are unable to handle AA sequences.
% We evalute different parameter variants of ESM-2 and the results have shown in Table \ref{tab:classification_result}.
Formally, each \(S^{(m)}\) is tokenized and passed through stacked Transformers.
The output is a token vector, denoted as:
$
\mathbf{h}_i = \mathbf{H}_1^{(L)},
$
where \(\mathbf{H}_1^{(L)} \in \mathbb{R}^d\) is the embedding of the first token from the \(L\)-th (last) Transformer layer, serving as data representation. 
% The input sequence for node \(i\) is represented as \(\mathbf{X}_i = [x_1, x_2, \dots, x_L]\), where \(L\) is the sequence length and \(x_j\) denotes the \(j\)-th amino acid.
% The Transformer processes \(\mathbf{X}_i\) through stacked layers of multi-head self-attention and feed-forward networks. The attention mechanism at each layer computes:
% \[
% \text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\left(\frac{\mathbf{Q} \mathbf{K}^\top}{\sqrt{d_k}}\right) \mathbf{V},
% \]
% where \(\mathbf{Q} = \mathbf{X}_i \mathbf{W}^Q\), \(\mathbf{K} = \mathbf{X}_i \mathbf{W}^K\), and \(\mathbf{V} = \mathbf{X}_i \mathbf{W}^V\), with \(\mathbf{W}^Q\), \(\mathbf{W}^K\), and \(\mathbf{W}^V\) as learnable weight matrices.
% Formally, each AA sequence \(S^{(m)}\) is tokenized and passed through stacked Transformers.
% The output a token vector \(\mathbf{h}_i\), where the embedding of the first token serves as data representation:
% $
% \mathbf{h}_i = \mathbf{H}_1^{(L)},
% $
% where \(\mathbf{H}_1^{(L)} \in \mathbb{R}^d\) is the embedding of the first token from the \(L\)-th (last) Transformer layer. 
% This global feature vector \(\mathbf{h}_i\) encodes the protein's sequence-level information.

\subsubsection{Positional Encoding}
To address a fundamental limitation of GNNs \cite{GIN} or hybrid models \cite{GPS} to distinguish nodes with identical local structures, 
we apply a random-walk-based positional encoding (RWPE) base on a diffusion process \cite{PE}, defined as:
% \begin{align*}
$p_i = [RW_{ii}, RW_{ii}^2, \cdots, RW_{ii}^k] \in \mathbb{R}^k $
% \end{align*}
where $RW = AD^{-1}$ is the random walk operator, constructed by the adjacency matrix $A$ and degree matrix $D$. 
For each node $i$, $RW_{ii}^k$ captures the probability of returning to node $i$ after $k$ steps of random walk.
% Unlike Laplacian eigenvector-based PE (LapPE) which suffers from sign ambiguity, RWPE provides unambiguous positional information. This makes the learning process more efficient as the network does not need to learn invariance to $2^k$ possible sign combinations. 
% Experimentally, RWPE demonstrates superior performance compared to LapPE across molecular datasets.


The final node representation combines the sequence-level features from ESM-2 and the structural information from the graph. Specifically, the sequence embedding \(\mathbf{h}_i\) and the positional encoding \(\mathbf{p}_i\) are concatenated and passed through a linear layer to obtain the final representation:
$\mathbf{x}_i = \text{Linear}([\mathbf{h}_i \| \mathbf{p}_i]),$
where \([\mathbf{h}_i \| \mathbf{p}_i] \in \mathbb{R}^{d + K}\) denotes the concatenation of \(\mathbf{h}_i \in \mathbb{R}^d\) and \(\mathbf{p}_i \in \mathbb{R}^K\). The linear transformation ensures dimensionality reduction and effective integration of both global protein sequence features and local graph structural information.
This final node feature \(\mathbf{x}_i \in \mathbb{R}^d\) is optimized for downstream tasks such as graph classification.



\subsection{\classifier: Pathway Information Learning}
\label{sec:classifier}

\classifier integrates the Graph Isomorphism Network (GIN) with a novel \textbf{pathway-wise Mamba} model.
It leverages the strengths of both global selective modeling mechanisms and message-passing GNNs. 
% We propose a novel pathway learning and classification model by integrating the Graph Isomorphism Network (GIN) with a \textbf{pathway-wise Mamba} architecture.
% % model for classifying pathway networks by combining GIN with \textbf{pathway-wise Mamba}. 
% This approach leverages the strengths of both global selective modeling mechanisms and message-passing GNNs while addressing their limitations in graph-based pathway modeling. 
% Below, we detail the core components of our method.
Specifically, inspired by GPS \cite{GPS}, our model avoids early-stage information loss that could arise from using GNNs exclusively in the initial layers. 
We hence employ pathway-wise global aggregation in combination with an efficient Mamba mechanism \cite{Mamba}. 
% While GNNs struggle with issues like over-smoothing, over-squashing, and limited expressivity against the Weisfeiler-Lehman (WL) test, our model addresses these challenges by introducing pathway-wise global aggregation in combination with an efficiency Mamba mechanism \cite{Mamba}. 
At each layer, node and edge features are updated by aggregating the outputs of a pathway-wise Mamba aggregation as: 
% illustrated in Figure \ref{fig:systemOV}. 
% This process can be expressed as follows:
\begin{eqnarray}
    X^{l+1}, &=& \texttt{PathMamba}^{l} \left( X^{l}, A \right), \\
    \textrm{computed as} \ \ \ 
    X^{l+1}_L, &=& \texttt{LocalGIN}^{l} \left( X^{l}, A \right), \\
    X^{l+1}_G, &=& \texttt{GlobalMamba}^{l} \left( X^{l}, A \right), \\
    X^{l+1}, &=& 
    \texttt{MLP}^{l}\left(X^{l+1}_L + X^{l+1}_G\right),
    \label{eqn:layer_equation}
\end{eqnarray}
where $A \in \mathbb{R}^{N \times N}$ is the adjacency matrix of a graph with $N$ nodes and $E$ edges; $X^{l} \in \mathbb{R}^{N \times d}$ represents the $d$-dimensional node features at layer $l$; $\texttt{LocalGIN}^{l}$ is a GIN; $\texttt{GlobalMamba}^{l}$ is a global pathway-wise aggregation layer; and $\texttt{MLP}^{l}$ is a two-layer multilayer perceptron (MLP) used to combine local and global features.

\subsubsection{Node-wise local aggregation}
% The local graph aggregation is performed using the GIN \cite{GIN}, which 
%  can distinguish graph structures up to the expressiveness of the Weisfeiler-Lehman graph isomorphism test.
Node features are updated by aggregating information from their local neighbors. The GIN operation can be expressed as:
\begin{equation}
    X^{l+1}_L = \text{ReLU}\left( W^{l} \cdot \big( (1 + \epsilon) X^{l} + \sum_{j \in \mathcal{N}(i)} X^{l}_j \big) \right),
\end{equation}
where $\mathcal{N}(i)$ represents the set of neighbors of node $i$, $W^{l}$ is the learnable weight matrix at layer $l$, and $\epsilon$ is a trainable parameter controlling the importance of self-loops. 
This ensures a high level of expressivity for local feature aggregation.


\subsubsection{Pathway-wise global aggregation}
\label{sub:global}

To capture long-range dependencies within pathways, we propose (1) random pathway sampling and (2) sequential pathway modeling in \classifier.

\noindent\textbf{Random Pathway Sampling. }
Formally, for each node $v_i$, we randomly sample a varied, single pathway with a maximum length of $L$. The sampling process is defined as:  
\begin{equation}
    \mathcal{Q} = \left\{ \bf{q}^i \mid \bf{q}^i \sim \text{Pathway}(v_i, L), \, |\bf{q}^i| \leq L \right\}_{i=1}^N,
\end{equation}  
where $N$ is the number of nodes in the graph, and $\bf{q}^i$ represents the sampled pathway for node $v_i$. Each pathway $\bf{q}^i$ is a sequence of nodes $\{v_i, v_{i_1}, v_{i_2}, \dots, v_{i_L}\}$, sampled according to a random walk process \cite{crawl}.  
The sampling process $\text{Pathway}(v_i, L)$ involves selecting a sequence of connected nodes starting from $v_i$.
The selection of each subsequent node is determined probabilistically, guided by the graph adjacency structure.
% where the choice of each subsequent node is determined probabilistically based on the graph's adjacency structure. 
% This ensures that each node is associated with diverse pathways.
% This ensures that each node is associated with a random path, providing a structured yet diverse representation of the graph's global architecture.

\noindent\textbf{Sequential Pathway Modeling. }
The forward propagation of the Mamba layer aggregates long-range dependencies along the sampled pathways. For each sampled pathway $\bf{q}^i \in \mathcal{Q}(X^{l})$, the Mamba layer processes the pathway sequentially as:

\begin{equation}
\begin{aligned}
\Delta_t &= \tau_\Delta(f_\Delta(\mathbf{x}_t^l)), \quad
\mathbf{B}_{t} = f_B(\mathbf{x}_t^l), \quad
\mathbf{C}_t = f_C(\mathbf{x}_t^l), \\
\mathbf{h}_t^l &= (1 - \Delta_t\cdot\mathbf{D}) \mathbf{h}_{t-1}^l + \Delta_t\cdot\mathbf{B}_t\mathbf{x}_t^l \\
X^{l+1}_G &= C \cdot h^{l+1}_{L},
\end{aligned}
\label{eqn:mamba-updates}
\end{equation}
where $\mathbf{x}_t^l $ is the $t$-th input node feature matrix in pathway $\bf{q}^i$ at layer $l$.
$f_*$ are learnable projections and $\mathbf{h}_t^e$ is hidden state. $\tau_\Delta$ is the softplus function. 
The forgetting term 
$(1 - \Delta_t^e\cdot\mathbf{D})$
implements a selective mechanism analogous to synaptic decay or inhibitory processes that diminish outdated or irrelevant information. 
Conversely, the update term 
$\Delta_t^e\cdot\mathbf{B}_t^e$
mirrors gating that selectively reinforces and integrates salient new information. 
The projection $\mathbf{C}_t^e$ translates the internal state into observable outputs.
By processing each sampled pathway individually, the Mamba layer effectively aggregates information along each pathway. 
The aggregated pathway representations are then combined to form the updated node features $X^{l+1}_G$ for the next layer.


\subsubsection{Graph Classification}
The updated node features are aggregated using a max pooling to generate a graph representation. 
This representation is passed through an MLP layer for classification:
\begin{equation}
    y = \text{MLP}\big(\text{MaxPooling}\big(\{h_{v_i}\}_{i=1}^N\big)\big),
\end{equation}
where $N$ is the number of nodes, and $y$ is the predicted class label for the pathway.
The model is trained using the cross-entropy loss:
$\mathcal{L}_\text{cross-entropy} = -\sum_{i=1}^C y_i \log \hat{y}_i,
$
where $C$ is the number of classes, $y_i$ is the ground truth label, and $\hat{y}_i$ is the prediction.

% \noindent By combining GNN and pathway-wise Mamba, our method effectively captures graph structure and pathway-specific features, leading to robust pathway network classification.

\subsection{PathExplainer: Targeted Pathway Inference}\label{sec:explainer}
\explainer directly infer subgraphs to generate targeted pathways by leveraging the interpretability of \classifier. 
Vallina GNNexplainers \cite{gnnexplainer, pgexplainer}, which focus primarily on the node or edge level, often struggle to capture the global structures at the pathway level. 
In contrast, \explainer introduces a key technical novelty by \textbf{training pathway masks}, where entire pathways (i.e., sequences of connected nodes and edges) are selectively masked during training to evaluate their contributions to \classifier.


% This enables the identification of the most influential subgraphs and node features at the pathway level.

PathExplainer formalizes the identification of important subgraphs as an optimization problem. 
For a given graph \( G = (V, E) \), the explanation is defined as \( (G_S, F_S) \), where \( G_S \subseteq G \) is the subgraph and \( F_S \) represents the selected features. 
The explanation is derived by optimizing the mutual information $\mathcal{MI}(\cdot)$ between the subgraph and the model's prediction:
\begin{equation}
\max_{G_S, F} \mathcal{MI}(Y, (G_S, F)) = H(Y) - H(Y \mid G = G_S, X = F_S),
\end{equation}
where \( H(Y) \) is the entropy of the predictions and \( H(Y \mid G = G_S, X = F_S) \) is the conditional entropy given the explanation.

The optimization is approached by learning a pathway mask \( M \) for the sampled pathway's edges and nodes. 
To enhance the interpretability and biological relevance of the pathway mask, random pathways \( \mathcal{Q} \) are sampled as described in Section~\ref{sub:global}. 
For each node \( v_i \), a single random pathway \( q_i \) of length up to \( L \) is sampled. These pathways are then used to restrict the mask learning process to edges within the sampled pathways, ensuring that the learned \( M \) focuses on them. 
Specifically, the adjacency matrix \( A \) is modified based on the pathway mask \( M \) as \( A' = A \odot \sigma(M) \), where \( \sigma \) denotes the sigmoid function. Similarly, the features are masked as \( X' = X \odot \sigma(M) \).
The loss function for PathExplainer combines two components: a cross-entropy term for prediction consistency and regularization terms for sparsity:

\begin{equation}
\resizebox{\linewidth}{!}{% Ensure the content is grouped properly
    $\begin{aligned}
    \mathcal{L}_\text{mask} := -\sum_{c=1}^{C} 1[y = c] \log P_\Phi(Y = c \mid G = A', X = X') d
    + \lambda \|M\|
    \end{aligned}$
}
\end{equation}

where \( \|M\| \) encourages sparsity in the edge selection, and $\lambda$ balances the trade-off between the classification loss and the sparsity regularization.
Hence, the identified important subgraphs and node features (referring to AA sequence data) that contribute most to specific bio-networks can considered as targeted pathways.
% We evaluate \method and resulting pathways from both machine learning (Section \ref{subsec:exp1}) and biological (Section \ref{subsec:exp2}) perspectives .


% By leveraging random pathway sampling \( \mathcal{Q} \), PathExplainer ensures that the learned pathway mask \( M \) focuses on critical subgraphs that reflect the stochastic and hierarchical nature of biological pathways. This integration enhances both the interpretability and the relevance of the extracted subgraphs, providing meaningful insights into key pathway mechanisms.












% We propose PathExplainer, a novel method designed to extract critical subgraphs within pathway networks by leveraging the interpretability of PathMamba. The primary objective of PathExplainer is to identify subgraphs and node features that are most influential in determining a model's predictions for biological pathway network analysis.

% PathExplainer formalizes the identification of important subgraphs as an optimization problem. For a given pathway \( G = (V, E) \), where \( V \) represents nodes and \( E \) represents edges, the explanation is defined as \( (G_S, F_S) \), where \( G_S \subseteq G \) is the subgraph and \( F_S \) represents the selected features. The explanation is derived by optimizing the mutual information between the subgraph and the model's prediction:
% \begin{equation}
% \max_{G_S, F} \mathrm{MI}(Y, (G_S, F)) = H(Y) - H(Y \mid G = G_S, X = F_S),
% \end{equation}
% where \( H(Y) \) is the entropy of the predictions and \( H(Y \mid G = G_S, X = F_S) \) is the conditional entropy given the explanation.

% The optimization is approached by learning two masks: a structural mask \( M \) for edges and a feature mask \( F \) for node features. The graph structure is modified by applying \( M \) to the adjacency matrix \( A \) as \( A' = A \odot \sigma(M) \), where \( \sigma \) denotes the sigmoid function. Similarly, the features are masked as \( X' = X \odot \sigma(F) \).

% The loss function for PathExplainer combines two components: a cross-entropy term for prediction consistency and regularization terms for sparsity and connectivity:
% \begin{equation}
% \begin{aligned}
% \mathcal{L}_\text{mask} = -\sum_{c=1}^{C} 1[y = c] \log P_\Phi(Y = c \mid G = A', X = X') \\
% \quad + \lambda_1 \|M\|_1 
% \quad + \lambda_2 \mathrm{Laplacian}(A'),
% \end{aligned}
% \end{equation}

% where \( \|M\|_1 \) encourages sparsity in the edge selection, and the Laplacian term promotes connectivity within the extracted subgraph.

% PathExplainer is tailored for pathway networks, enabling it to uncover biologically meaningful subgraphs that correspond to key protein interactions. Experiments on pathway network datasets demonstrate its ability to provide interpretable insights into pathway mechanisms while maintaining predictive accuracy.






