%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% INTRO TO TINY BENCHMARKS AND APPROXIMATION CONJECTURE

Emergent abilities in LLMs have a steeper learning curve than the simple loss functions they are trained on. This justifies the term "emergent" as models suddenly begin to perform well on certain tasks during the training process. A steeper learning curve in the parameter space means that performance differences are more pronounced, allowing us to use fewer data points to approximate the performance order of models. Consequently, it becomes less computationally expensive to evaluate whether the performance of the merged model has degraded or improved compared to the original model on a given task $t_j$ entangled in a language $L_i$, such as math word problems or common sense reasoning.
\begin{conjecture}\label{conj:approx}
    The order between two language models $\theta_{a}$ and $\theta_{b}$ with regard to a metric $M$ measuring an emergent ability $t$ over a labeled dataset $X_{t}=\{(x_i,y_i)\}_{i=0}^n$ can be correctly approximated by their performance on a subset $\hat{X_t} \subset X_t$.
\end{conjecture}
While this order remains an approximation, it can still be sufficient for an evolutionary algorithm to converge towards an optimum. 
\texttt{tinyBenchmarks} \citep{tinybenchmarks} allows to estimate the performance of a LLM $l$ on the dataset $I_j$ by leveraging its predictions on the subset $\hat{I_j}$. Nevertheless, in the field of evolutionary model merging, we can estimate the performance of $l_m$ by leveraging the evaluation of the merged model $l_m$ on $\hat{I_j}$, but also relying on the full evaluations of the component models $l_1,...,l_k$ over the dataset $I_j$.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% ON THE BENEFITS OF mp-IRT vs p-IRT in model merging 

Normally, we would have estimated $\hat{\gamma}_{\tilde{m}} \approx \gamma_{\tilde{m}}$ on $\hat{D}$ by finding the MLE estimator of  $\gamma_{\tilde{m}}$ by maximizing the likelihood of $Y_{(\hat{D},\tilde{m})}$. Nevertheless, this faces the following challenges: 
%
\begin{enumerate*}[label=(\roman*)]
  \item it does not use the available data about $m_1$ and $m_2$, namely $Y_{(D,m_1)}$ and $Y_{(D,m_2)}$;
  \item when merging LLMs, the ability required for solving a simple task/item $i$ are several, and therefore the number of abilities that must be modeled to get an adequate $|\gamma|$ may grow significantly. This may require more data to get a good estimation of the latent ability $\gamma$ of the model.
\end{enumerate*}


\subsection{Task Vectors vs Language Vectors}
Inspired by task vectors~\citep{task-vectors, crossmerge}, we define a language vector as:
%
\begin{equation}
    \tau_{L_t} = \theta_{(L_t,L_s)} - \theta_{L_s}
\end{equation}
%
where $\theta_{L_s}$ is the language model pretrained in the source language $L_s$, and $\theta_{(L_t,L_s)}$ is the model obtained after fine-tuning $\theta_{L_s}$ on unlabeled data in the target language $L_t$. Although the definition of a language vector closely resembles that of a task vector, they tend to differ significantly in practice. Task vectors are typically derived from training models on supervised tasks that are quite different from one another (e.g., MNIST and EuroSAT~\citep{task-vectors}). In contrast, language vectors are obtained from fine-tuning models on unlabeled generic datasets, which theoretically differ only in language. As a result, language vectors tend to be more similar to each other~\cite{notrain}, resulting in a much higher cosine similarity than task vectors~\citep{notrain}. This increased similarity may complicate the process of obtaining good merged models, as \citet{task-vectors} speculate that the orthogonality of task vectors helps prevent weight interference, which is crucial for successful model merging.


\subsection{The Language-Task Analogy Challenge}

% Task vectors also allow computing analogies, generalizing a model $\theta_{(t,a)}$ trained on a specific task $t$ (e.g, NER) in domain $a$ (e.g., finance) to a new domain $b$ (e.g., law). This is achieved by combining the supervised fine-tuning of $\theta_{(t,a)}$ on domain $a$ and task $t$ with two unsupervised fine-tunings of $\theta_0$ on domains $a$ and $b$, namely $\theta_{a}$ and $\theta_{b}$. The analogy function is given by:
% \[
%     F_{\text{analogy}}(\theta_0, \theta_a, \theta_b, \theta_{(t,a)}) = (\tau_{b} - \tau_{a}) + \tau_{(t,a)} + \theta_0 \approx \theta_{(t,b)}.
% \]

Previous approaches \cite{crossmerge} have deployed on task analogies \cite{task-vectors} to achieve cross-language transfer. This relies on the intuitive relationship: "task $\text{t}_{(j,l_1)}$ is to language $l_1$ as task $\text{t}_{(j,l_2)}$ is to $l_2$". However, in most cases, merging multilingual models through language-task analogies is unfeasible for decoder-only architectures. The task one aims to transfer across languages is often entangled with the source language of the training dataset, reducing the language-task analogy to mere addition.

\begin{theorem}\label{thm:impossibility-task-analogies}
    Given a model $\theta_{L_i} \in \mathbb{R}^{d}$ proficient in a language $L_i$, a model $\theta_{(f_k, L_i)} \in \mathbb{R}^{d}$ proficient in the task $f_k$ entangled with $L_i$, and a model $\theta_{L_j} \in \mathbb{R}^{d}$ proficient in language $L_j$, if $L_{source} = L_{i}$, then:
    $$
        F_{analogy}(\theta_{L_{source}}, \theta_{L_i}, \theta_{L_j}, \theta_{(f_k, L_i)}) = F_{addition}(\theta_{L_{source}}, \theta_{(f_k, L_i)}, \theta_{L_j})
    $$
\end{theorem}

where $F_{analogy} : \mathbb{R}^{d \times 4} \to \mathbb{R}^{d}$ maps four models to an analogy model, and $F_{addition} : \mathbb{R}^{d \times 3} \to \mathbb{R}^{d}$ maps three models to an arithmetic model. $L_{source}$ is the language of the pretrained model $\theta_{L_{source}}$. 
Due to the lack of supervised datasets for low-resource languages, most tasks one may want to transfer to a language model in $L_{target}$ are entangled with $L_{source}$, which is often English. This makes language-task analogies an impossible solution for generalizing capabilities from English to low-resource languages in the context of large models such as Mistral \cite{mistral}.

To sum up, creating effective multilingual models presents significant challenges which can be addressed with model merging. However, when applying model merging to the domain of multilinguality and cross-lingual transfer, additional obstacles must be overcome to develop effective Multilingual Language Models (MLLMs):

\begin{itemize}
    \item The trial-and-error approach of model merging \cite{mergingsurvy} is less effective due to the higher difficulty posed by language vectors compared to task vectors, primarily because of their high cosine similarity \cite{crossmerge}.
    \item When working with popular English autoregressive monolingual LLMs, the abilities intended for transfer to low-resource languages through fine-tuning are often derived from tasks entangled with English. This makes it impossible to use task-language analogies, as they reduce to task-language arithmetic (Theorem 1).
\end{itemize}

Model merging, while promising, requires solving these additional challenges to achieve effective cross-lingual transfer and the development of robust MLLMs.





% CROSS-LINGUAL TRANSFER
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Our first set of experiments focused on cross-lingual transfer utilizing the Mistral-7B architecture. The results clearly indicate that the EMULI merging method can successfully transfer mathematical capabilities from an English fine-tuned model to an Italian fine-tuned model. This was evidenced by the merged model's ability to solve Italian math problems, achieving performance levels that surpassed the individual models. Moreover, the subsequent merging with a code-generating model demonstrated that the cross-lingual capability extended beyond a single task, addressing RQ2 effectively. The merged model performed well in both math and coding tasks, indicating that the transfer of capabilities was not confined to the initial task but could generalize to other domains.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% MULTI-LINGUAL
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

By merging models fine-tuned in different languages (Portuguese, Turkish, and English; Italian, Dutch, and English), we were able to produce multilingual models that preserved the performance of the original monolingual models while also enabling cross-lingual transfer. The use of NSGA-II for multi-objective optimization proved beneficial. The merged models not only maintained the original linguistic capabilities but, in some cases, even enhanced them. This improvement was particularly notable in the Portuguese, Italian, and Dutch components, showcasing the potential of cross-lingual transfer to bolster model performance in multilingual settings.

% SO VS MO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Multi-objective optimization consistently outperformed single-objective optimization in most scenarios, except for the Portuguese-Turkish-English experiment. This suggests that as the complexity of the optimization task increases (with more languages and objectives), the benefits of multi-objective optimization become more pronounced.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The results presented highlight the efficacy of our proposed approach for both cross-lingual transfer and the generation of multilingual models through evolutionary model merging. The experiments demonstrate the potential of using evolutionary algorithms to create merged models that retain and enhance the capabilities of the original monolingual fine-tunes, facilitating effective cross-lingual transfer and multilingual model generation.


The extension of our approach to include additional languages (German, Spanish, and Romanian) demonstrated the scalability of our method. The results showed that our approach could generate models proficient in multiple languages, with most of the languages (except Romanian and Italian) greatly benefiting from the cross-lingual transfer of capabilities. However, it is worth noting that we could only evaluate 1 model of the Pareto front, and by testing additional merged models we may observe an improvement even for Romanian and Italian.


The comparison with baseline models created using task arithmetic with uniform weights underscored the necessity of evolutionary optimization. The baseline models failed to transfer capabilities effectively, resulting in significantly lower performance. This highlights the importance of a structured optimization framework when dealing with language vectors, as the complexity of merging multiple language models demands a more sophisticated approach than simple averaging.

Overall, the results affirm the effectiveness of our evolutionary model merging approach for both cross-lingual transfer and multilingual model generation. The EMULI merging method provides a robust framework for creating high-performing multilingual models that retain and enhance the capabilities of their monolingual counterparts. 