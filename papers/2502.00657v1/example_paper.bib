
@article{mehrotra2023tree,
  title={Tree of attacks: Jailbreaking black-box llms automatically},
  author={Mehrotra, Anay and Zampetakis, Manolis and Kassianik, Paul and Nelson, Blaine and Anderson, Hyrum and Singer, Yaron and Karbasi, Amin},
  journal={arXiv preprint arXiv:2312.02119},
  year={2023}
}
@article{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023}
}
@article{liu2023autodan,
  title={Autodan: Generating stealthy jailbreak prompts on aligned large language models},
  author={Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2310.04451},
  year={2023}
}
@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}
@article{carlini2024aligned,
  title={Are aligned neural networks adversarially aligned?},
  author={Carlini, Nicholas and Nasr, Milad and Choquette-Choo, Christopher A and Jagielski, Matthew and Gao, Irena and Koh, Pang Wei W and Ippolito, Daphne and Tramer, Florian and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{wei2024jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}
@inproceedings{kang2024exploiting,
  title={Exploiting programmatic behavior of llms: Dual-use through standard security attacks},
  author={Kang, Daniel and Li, Xuechen and Stoica, Ion and Guestrin, Carlos and Zaharia, Matei and Hashimoto, Tatsunori},
  booktitle={2024 IEEE Security and Privacy Workshops (SPW)},
  pages={132--143},
  year={2024},
  organization={IEEE}
}
@article{hazell2023spear,
  title={Spear phishing with large language models},
  author={Hazell, Julian},
  journal={arXiv preprint arXiv:2305.06972},
  year={2023}
}
@inproceedings{zhou2023synthetic,
  title={Synthetic lies: Understanding ai-generated misinformation and evaluating algorithmic and human solutions},
  author={Zhou, Jiawei and Zhang, Yixuan and Luo, Qianni and Parker, Andrea G and De Choudhury, Munmun},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--20},
  year={2023}
}
@article{du2024exploration,
  title={Exploration-driven policy optimization in rlhf: Theoretical insights on efficient data utilization},
  author={Du, Yihan and Winnicki, Anna and Dalal, Gal and Mannor, Shie and Srikant, R},
  journal={arXiv preprint arXiv:2402.10342},
  year={2024}
}
@article{qiu2024reward,
  title={Reward Generalization in RLHF: A Topological Perspective},
  author={Qiu, Tianyi and Zeng, Fanzhi and Ji, Jiaming and Yan, Dong and Wang, Kaile and Zhou, Jiayi and Han, Yang and Dai, Josef and Pan, Xuehai and Yang, Yaodong},
  journal={arXiv preprint arXiv:2402.10184},
  year={2024}
}
@article{zhou2024t,
  title={T-REG: Preference Optimization with Token-Level Reward Regularization},
  author={Zhou, Wenxuan and Zhang, Shujian and Zhao, Lingxiao and Meng, Tao},
  journal={arXiv preprint arXiv:2412.02685},
  year={2024}
}
@article{wang2023rlhf,
  title={Is rlhf more difficult than standard rl? a theoretical perspective},
  author={Wang, Yuanhao and Liu, Qinghua and Jin, Chi},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={76006--76032},
  year={2023}
}
@article{ivison2024unpacking,
  title={Unpacking DPO and PPO: Disentangling Best Practices for Learning from Preference Feedback},
  author={Ivison, Hamish and Wang, Yizhong and Liu, Jiacheng and Wu, Zeqiu and Pyatkin, Valentina and Lambert, Nathan and Smith, Noah A and Choi, Yejin and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2406.09279},
  year={2024}
}
@article{wang2024bpo,
  title={Bpo: Towards balanced preference optimization between knowledge breadth and depth in alignment},
  author={Wang, Sizhe and Tong, Yongqi and Zhang, Hengyuan and Li, Dawei and Zhang, Xin and Chen, Tianlong},
  journal={arXiv preprint arXiv:2411.10914},
  year={2024}
}
@article{lu2024online,
  title={Online merging optimizers for boosting rewards and mitigating tax in alignment},
  author={Lu, Keming and Yu, Bowen and Huang, Fei and Fan, Yang and Lin, Runji and Zhou, Chang},
  journal={arXiv preprint arXiv:2405.17931},
  year={2024}
}
@article{franken2024self,
  title={Self-supervised alignment with mutual information: Learning to follow principles without preference labels},
  author={Fr{\"a}nken, Jan-Philipp and Zelikman, Eric and Rafailov, Rafael and Gandhi, Kanishk and Gerstenberg, Tobias and Goodman, Noah D},
  journal={arXiv preprint arXiv:2404.14313},
  year={2024}
}
@article{xie2024exploratory,
  title={Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF},
  author={Xie, Tengyang and Foster, Dylan J and Krishnamurthy, Akshay and Rosset, Corby and Awadallah, Ahmed and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:2405.21046},
  year={2024}
}
@article{rafailov2024scaling,
  title={Scaling laws for reward model overoptimization in direct alignment algorithms},
  author={Rafailov, Rafael and Chittepu, Yaswanth and Park, Ryan and Sikchi, Harshit and Hejna, Joey and Knox, Bradley and Finn, Chelsea and Niekum, Scott},
  journal={arXiv preprint arXiv:2406.02900},
  year={2024}
}
@article{yin2024entropy,
  title={Entropy law: The story behind data compression and llm performance},
  author={Yin, Mingjia and Wu, Chuhan and Wang, Yufei and Wang, Hao and Guo, Wei and Wang, Yasheng and Liu, Yong and Tang, Ruiming and Lian, Defu and Chen, Enhong},
  journal={arXiv preprint arXiv:2407.06645},
  year={2024}
}
@article{xiong2024building,
  title={Building math agents with multi-turn iterative preference learning},
  author={Xiong, Wei and Shi, Chengshuai and Shen, Jiaming and Rosenberg, Aviv and Qin, Zhen and Calandriello, Daniele and Khalman, Misha and Joshi, Rishabh and Piot, Bilal and Saleh, Mohammad and others},
  journal={arXiv preprint arXiv:2409.02392},
  year={2024}
}
@article{yuan2024advancing,
  title={Advancing llm reasoning generalists with preference trees},
  author={Yuan, Lifan and Cui, Ganqu and Wang, Hanbin and Ding, Ning and Wang, Xingyao and Deng, Jia and Shan, Boji and Chen, Huimin and Xie, Ruobing and Lin, Yankai and others},
  journal={arXiv preprint arXiv:2404.02078},
  year={2024}
}
@article{zhang2024self,
  title={Self-exploring language models: Active preference elicitation for online alignment},
  author={Zhang, Shenao and Yu, Donghan and Sharma, Hiteshi and Zhong, Han and Liu, Zhihan and Yang, Ziyi and Wang, Shuohang and Hassan, Hany and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2405.19332},
  year={2024}
}
@inproceedings{xiong2024iterative,
  title={Iterative preference learning from human feedback: Bridging theory and practice for rlhf under kl-constraint},
  author={Xiong, Wei and Dong, Hanze and Ye, Chenlu and Wang, Ziqi and Zhong, Han and Ji, Heng and Jiang, Nan and Zhang, Tong},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}
@article{anwar2024foundational,
  title={Foundational challenges in assuring alignment and safety of large language models},
  author={Anwar, Usman and Saparov, Abulhair and Rando, Javier and Paleka, Daniel and Turpin, Miles and Hase, Peter and Lubana, Ekdeep Singh and Jenner, Erik and Casper, Stephen and Sourbut, Oliver and others},
  journal={arXiv preprint arXiv:2404.09932},
  year={2024}
}
@inproceedings{hong2024orpo,
  title={Orpo: Monolithic preference optimization without reference model},
  author={Hong, Jiwoo and Lee, Noah and Thorne, James},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={11170--11189},
  year={2024}
}
@article{ethayarajh2024kto,
  title={Kto: Model alignment as prospect theoretic optimization},
  author={Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe},
  journal={arXiv preprint arXiv:2402.01306},
  year={2024}
}
@article{jung2024binary,
  title={Binary classifier optimization for large language model alignment},
  author={Jung, Seungjae and Han, Gunsoo and Nam, Daniel Wontae and On, Kyoung-Woon},
  journal={arXiv preprint arXiv:2404.04656},
  year={2024}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@article{amini2024direct,
  title={Direct preference optimization with an offset},
  author={Amini, Afra and Vieira, Tim and Cotterell, Ryan},
  journal={arXiv preprint arXiv:2402.10571},
  year={2024}
}
@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{li2024predicting,
  title={Predicting vs. acting: A trade-off between world modeling \& agent modeling},
  author={Li, Margaret and Shi, Weijia and Pagnoni, Artidoro and West, Peter and Holtzman, Ari},
  journal={arXiv preprint arXiv:2407.02446},
  year={2024}
}
@article{liu2024dual,
  title={Dual active learning for reinforcement learning from human feedback},
  author={Liu, Pangpang and Shi, Chengchun and Sun, Will Wei},
  journal={arXiv preprint arXiv:2410.02504},
  year={2024}
}
@article{xiao2024algorithmic,
  title={On the Algorithmic Bias of Aligning Large Language Models with RLHF: Preference Collapse and Matching Regularization},
  author={Xiao, Jiancong and Li, Ziniu and Xie, Xingyu and Getzen, Emily and Fang, Cong and Long, Qi and Su, Weijie J},
  journal={arXiv preprint arXiv:2405.16455},
  year={2024}
}
@article{he2024accelerated,
  title={Accelerated Preference Optimization for Large Language Model Alignment},
  author={He, Jiafan and Yuan, Huizhuo and Gu, Quanquan},
  journal={arXiv preprint arXiv:2410.06293},
  year={2024}
}
@article{wang2024magnetic,
  title={Magnetic Preference Optimization: Achieving Last-iterate Convergence for Language Models Alignment},
  author={Wang, Mingzhi and Ma, Chengdong and Chen, Qizhi and Meng, Linjian and Han, Yang and Xiao, Jiancong and Zhang, Zhaowei and Huo, Jing and Su, Weijie J and Yang, Yaodong},
  journal={arXiv preprint arXiv:2410.16714},
  year={2024}
}
@inproceedings{xu2024uncovering,
  title={Uncovering safety risks of large language models through concept activation vector},
  author={Xu, Zhihao and Huang, Ruixuan and Chen, Changyu and Wang, Xiting},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}
@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@article{lin2024towards,
  title={Towards Understanding Jailbreak Attacks in LLMs: A Representation Space Analysis},
  author={Lin, Yuping and He, Pengfei and Xu, Han and Xing, Yue and Yamada, Makoto and Liu, Hui and Tang, Jiliang},
  journal={arXiv preprint arXiv:2406.10794},
  year={2024}
}



@article{huang2024safealigner,
  title={Safealigner: Safety alignment against jailbreak attacks via response disparity guidance},
  author={Huang, Caishuang and Zhao, Wanxu and Zheng, Rui and Lv, Huijie and Dou, Shihan and Li, Sixian and Wang, Xiao and Zhou, Enyu and Ye, Junjie and Yang, Yuming and others},
  journal={arXiv preprint arXiv:2406.18118},
  year={2024}
}

@article{peng2023instruction,
  title={Instruction tuning with gpt-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.03277},
  year={2023}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@inproceedings{lin-etal-2024-towards-understanding,
    title = "Towards Understanding Jailbreak Attacks in {LLM}s: A Representation Space Analysis",
    author = "Lin, Yuping  and
      He, Pengfei  and
      Xu, Han  and
      Xing, Yue  and
      Yamada, Makoto  and
      Liu, Hui  and
      Tang, Jiliang",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.401/",
    doi = "10.18653/v1/2024.emnlp-main.401",
    pages = "7067--7085"
}

%%% raj references %%%%%%
@article{donsker1975asymptotic,
  title={Asymptotic evaluation of certain Markov process expectations for large time, II},
  author={Donsker, Monroe D and Varadhan, SRS386024},
  journal={Communications on Pure and Applied Mathematics},
  volume={28},
  number={2},
  pages={279--301},
  year={1975},
  publisher={Wiley Online Library}
}

@book{Polyanskiy_Wu_2025, place={Cambridge}, title={Information Theory: From Coding to Learning}, publisher={Cambridge University Press}, author={Polyanskiy, Yury and Wu, Yihong}, year={2025}} 

@article{belghazi2018mine,
  title={Mine: mutual information neural estimation},
  author={Belghazi, Mohamed Ishmael and Baratin, Aristide and Rajeswar, Sai and Ozair, Sherjil and Bengio, Yoshua and Courville, Aaron and Hjelm, R Devon},
  journal={arXiv preprint arXiv:1801.04062},
  year={2018}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@book{luce1959individual,
  title={Individual choice behavior},
  author={Luce, R Duncan},
  volume={4},
  year={1959},
  publisher={Wiley New York}
}
@article{plackett1975analysis,
  title={The analysis of permutations},
  author={Plackett, Robin L},
  journal={Journal of the Royal Statistical Society Series C: Applied Statistics},
  volume={24},
  number={2},
  pages={193--202},
  year={1975},
  publisher={Oxford University Press}
}

@article{dubois2024length,
  title={Length-controlled alpacaeval: A simple way to debias automatic evaluators},
  author={Dubois, Yann and Galambosi, Bal{\'a}zs and Liang, Percy and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2404.04475},
  year={2024}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{team2024gemma,
  title={Gemma 2: Improving open language models at a practical size},
  author={Team, Gemma and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal={arXiv preprint arXiv:2408.00118},
  year={2024}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{yang2024qwen2,
  title={Qwen2. 5 Technical Report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@inproceedings{ethayarajh2022understanding,
  title={Understanding Dataset Difficulty with $\mathcal{V}$-Usable Information},
  author={Ethayarajh, Kawin and Choi, Yejin and Swayamdipta, Swabha},
  booktitle={International Conference on Machine Learning},
  pages={5988--6008},
  year={2022},
  organization={PMLR}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{ganguli2022red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={arXiv preprint arXiv:2209.07858},
  year={2022}
}

@article{kopf2024openassistant,
  title={Openassistant conversations-democratizing large language model alignment},
  author={K{\"o}pf, Andreas and Kilcher, Yannic and von R{\"u}tte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi Rui and Stevens, Keith and Barhoum, Abdullah and Nguyen, Duc and Stanley, Oliver and Nagyfi, Rich{\'a}rd and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@inproceedings{
hu2022lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@InProceedings{Zhang_2023_ICCV,
    author    = {Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
    title     = {Adding Conditional Control to Text-to-Image Diffusion Models},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {3836-3847}
}

@inproceedings{NEURIPS2023_1feb8787,
 author = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {10088--10115},
 title = {QLoRA: Efficient Finetuning of Quantized LLMs},
 volume = {36},
 year = {2023}
}

@inproceedings{DBLP:journals/corr/KingmaB14,
  author       = {Diederik P. Kingma and
                  Jimmy Ba},
  title        = {Adam: {A} Method for Stochastic Optimization},
  booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015,
                  San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year         = {2015},
  url          = {http://arxiv.org/abs/1412.6980},
}

@INPROCEEDINGS{8624183,
  author={Zhang, Zijun},
  booktitle={2018 IEEE/ACM 26th International Symposium on Quality of Service (IWQoS)}, 
  title={Improved Adam Optimizer for Deep Neural Networks}, 
  year={2018},
  pages={1-2},
  doi={10.1109/IWQoS.2018.8624183}}

@article{wei2023jailbreak,
  title={Jailbreak and guard aligned language models with only few in-context demonstrations},
  author={Wei, Zeming and Wang, Yifei and Li, Ang and Mo, Yichuan and Wang, Yisen},
  journal={arXiv preprint arXiv:2310.06387},
  year={2023}
}

@article{huang2024trustllm,
  title={Trustllm: Trustworthiness in large language models},
  author={Huang, Yue and Sun, Lichao and Wang, Haoran and Wu, Siyuan and Zhang, Qihui and Li, Yuan and Gao, Chujie and Huang, Yixin and Lyu, Wenhan and Zhang, Yixuan and others},
  journal={arXiv preprint arXiv:2401.05561},
  year={2024}
}
