@inproceedings{al-negheimish2023augmenting,
  title={Augmenting Large Language Models with Symbolic Rule Learning for Robust Numerical Reasoning},
  author={Hadeel Al-Negheimish and Pranava Madhyastha and Alessandra Russo},
  booktitle={The 3rd Workshop on Mathematical Reasoning and AI at NeurIPS'23},
  year={2023},
  url={https://openreview.net/forum?id=vibHb75kYq}
}

@misc{berman2024solvingzebrapuzzlesusing,
  title={Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems},
  author={Shmuel Berman and Kathleen McKeown and Baishakhi Ray},
  year={2024},
  eprint={2407.03956},
  archivePrefix={arXiv},
  primaryClass={cs.MA},
  url={https://arxiv.org/abs/2407.03956},
}

@inproceedings{fedoseev2024llm,
  title={{LLM} Training Data Synthesis for More Effective Problem Solving using Satisfiability Modulo Theories},
  author={Timofey Fedoseev and Dimitar Iliev Dimitrov and Timon Gehr and Martin Vechev},
  booktitle={The 4th Workshop on Mathematical Reasoning and AI at NeurIPS'24},
  year={2024},
  url={https://openreview.net/forum?id=hR4Hskr4GX}
}

@misc{imani2023mathpromptermathematicalreasoningusing,
  title={MathPrompter: Mathematical Reasoning using Large Language Models},
  author={Shima Imani and Liang Du and Harsh Shrivastava},
  year={2023},
  eprint={2303.05398},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2303.05398},
}

@misc{mensfelt2024logicenhancedlanguagemodelagents,
  title={Logic-Enhanced Language Model Agents for Trustworthy Social Simulations},
  author={Agnieszka Mensfelt and Kostas Stathis and Vince Trencsenyi},
  year={2024},
  eprint={2408.16081},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2408.16081},
}

@inproceedings{pan-etal-2023-logic,
  title = "Logic-{LM}: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning",
  author = "Pan, Liangming  and
    Albalak, Alon  and
    Wang, Xinyi  and
    Wang, William",
  editor = "Bouamor, Houda  and
    Pino, Juan  and
    Bali, Kalika",
  booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
  month = dec,
  year = "2023",
  address = "Singapore",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.findings-emnlp.248",
  doi = "10.18653/v1/2023.findings-emnlp.248",
  pages = "3806--3824",
  abstract = "Large Language Models (LLMs) have shown human-like reasoning abilities but still struggle with complex logical problems. This paper introduces a novel framework, Logic-LM, which integrates LLMs with symbolic solvers to improve logical problem-solving. Our method first utilizes LLMs to translate a natural language problem into a symbolic formulation. Afterward, a deterministic symbolic solver performs inference on the formulated problem. We also introduce a self-refinement module, which utilizes the symbolic solver{'}s error messages to revise symbolic formalizations. We demonstrate Logic-LM{'}s effectiveness on five logical reasoning datasets: ProofWriter, PrOntoQA, FOLIO, LogicalDeduction, and AR-LSAT. On average, Logic-LM achieves a significant performance boost of 39.2{\%} over using LLM alone with standard prompting and 18.4{\%} over LLM with chain-of-thought prompting. Our findings suggest that Logic-LM, by combining LLMs with symbolic logic, offers a promising avenue for faithful logical reasoning.",
}

@misc{peng2023checkfactstryagain,
  title={Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback},
  author={Baolin Peng and Michel Galley and Pengcheng He and Hao Cheng and Yujia Xie and Yu Hu and Qiuyuan Huang and Lars Liden and Zhou Yu and Weizhu Chen and Jianfeng Gao},
  year={2023},
  eprint={2302.12813},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2302.12813},
}

@misc{schick2023toolformerlanguagemodelsteach,
  title={Toolformer: Language Models Can Teach Themselves to Use Tools},
  author={Timo Schick and Jane Dwivedi-Yu and Roberto Dess√¨ and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
  year={2023},
  eprint={2302.04761},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2302.04761},
}

@misc{ye2023satlmsatisfiabilityaidedlanguagemodels,
  title={SatLM: Satisfiability-Aided Language Models Using Declarative Prompting},
  author={Xi Ye and Qiaochu Chen and Isil Dillig and Greg Durrett},
  year={2023},
  eprint={2305.09656},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2305.09656},
}

