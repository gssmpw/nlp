\section{Related Work}
Prior research has explored techniques to enhance the ability of LLMs in these
central reasoning tasks, such as chain-of-thought prompting and introducing
symbolic representations. However, according to
____, these frameworks often struggle with
complex logical problems like Zebra puzzles, partly due to the inherent
difficulty of translating natural language clues into logical statements. They
propose integrating LLMs with theorem provers to tackle such challenges,
demonstrating significant improvements in puzzle-solving capabilities.

____ highlight that the challenge of numerical
reasoning in machine reading comprehension has been addressed by various
prompting strategies for LLMs. However, these approaches often struggle to
provide robust and interpretable reasoning. They contrast these techniques
against their neuro-symbolic approach, which has shown promising results by
decomposing complex questions into simpler ones and using symbolic learning
methods to learn rules for recomposing partial answers. This approach boasts
data efficiency and facilitates robust numerical reasoning with interpretable
and verifiable reasoning traces.

The LLM-Augmenter system, proposed by ____,
addresses the limitations of LLMs in real-world applications by augmenting them
with plug-and-play modules that ground responses in external knowledge and
iteratively revise prompts to improve factuality. Similarly, the Logic-Enhanced
Language Model Agents (LELMA) framework, proposed by
____, integrates LLMs with
symbolic AI to enhance the trustworthiness of social simulations, addressing
issues such as hallucinations and logical inconsistencies through logical
verification and self-refinement.

____ propose a technique to
improve the performance of LLMs on arithmetic problems by generating multiple
algebraic expressions or Python functions to solve the same math problem in
different ways, thereby increasing confidence in the output results. The
Toolformer self-supervised model, presented in
____, enables language models to
leverage external tools via simple APIs, thereby enhancing their performance on
various downstream tasks. ____ propose a method to enhance
LLMs mathematical problem-solving capabilities by fine-tuning them on a dataset
of synthetic problems and solutions generated using Satisfiability Modulo
Theories (SMT) solvers, specifically the Z3 API.

Logic-LM is a framework that combines LLMs with symbolic solvers to enhance
logical reasoning capabilities, demonstrating substantial performance
improvements over traditional LLM-based approaches ____.
____ introduce
Satisfiability-aided Language Modeling (SatLM), a method that combines large
language models with automated theorem provers to enhance reasoning
capabilities, demonstrating state-of-the-art performance on multiple datasets.

From the work cited above, ____,
____, and
____ present techniques addressing problem
domains most comparable to the Logic Grid Puzzles which we explore in this
paper. Similar to the approach we present, formalisation and the use of
auxiliary tools are a shared feature of this category of research. An important
distinguishing aspect of our work is the use of a logic-focused domain-specific
language, which we present in more detail in Sec.~\ref{logiclang}.

The general case for a DSL is not unlike that for intermediate languages in compilation. Given a new programming language it is ``obvious'' from the Church-Turing thesis that a mapping to assembly language exists, but is not necessarily obvious if a mapping with good efficiency properties (say) exists, and the compilation research community has found it helpful to use intermediate languages to structure the design of compilers. Here, it might seem likely that constraint solvers (automatic theorem provers) could be helpful to approach logic problems stated in natural language, but just how helpful or the best way to do so is not a priori obvious; like in compilation, our thesis is that DSL's can help. A similar analogy is the relation between SQL and first-order logic; although SQL provides facilities than make for briefer or more direct human expression than their expansions into FOL. A similar example for Logic.py is presented in Section \ref{type-decorators}.


Our results
support the case that this DSL can be helpful in structuring the mapping from natural language to that of a solver. In particular, ____ evaluate their
approach against a benchmark set of 114 Zebra puzzles. Their multi-agent system has a more sophisticated translation process which includes a refinement loop, but they
raise the puzzle accuracy of GPT-4 from 23.7\% to 55.3\%, compared to our
improvement from 24.9\% to 91.4\%.