@misc{berman2024solvingzebrapuzzlesusing,
  title={Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems},
  author={Shmuel Berman and Kathleen McKeown and Baishakhi Ray},
  year={2024},
  eprint={2407.03956},
  archivePrefix={arXiv},
  primaryClass={cs.MA},
  url={https://arxiv.org/abs/2407.03956},
}

@misc{kambhampati2024llmscantplanhelp,
  title={LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks},
  author={Subbarao Kambhampati and Karthik Valmeekam and Lin Guan and Mudit Verma and Kaya Stechly and Siddhant Bhambri and Lucas Saldyt and Anil Murthy},
  year={2024},
  eprint={2402.01817},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2402.01817},
}

@inproceedings{al-negheimish2023augmenting,
  title={Augmenting Large Language Models with Symbolic Rule Learning for Robust Numerical Reasoning},
  author={Hadeel Al-Negheimish and Pranava Madhyastha and Alessandra Russo},
  booktitle={The 3rd Workshop on Mathematical Reasoning and AI at NeurIPS'23},
  year={2023},
  url={https://openreview.net/forum?id=vibHb75kYq}
}

@misc{peng2023checkfactstryagain,
  title={Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback},
  author={Baolin Peng and Michel Galley and Pengcheng He and Hao Cheng and Yujia Xie and Yu Hu and Qiuyuan Huang and Lars Liden and Zhou Yu and Weizhu Chen and Jianfeng Gao},
  year={2023},
  eprint={2302.12813},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2302.12813},
}

@misc{mensfelt2024logicenhancedlanguagemodelagents,
  title={Logic-Enhanced Language Model Agents for Trustworthy Social Simulations},
  author={Agnieszka Mensfelt and Kostas Stathis and Vince Trencsenyi},
  year={2024},
  eprint={2408.16081},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2408.16081},
}

@misc{imani2023mathpromptermathematicalreasoningusing,
  title={MathPrompter: Mathematical Reasoning using Large Language Models},
  author={Shima Imani and Liang Du and Harsh Shrivastava},
  year={2023},
  eprint={2303.05398},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2303.05398},
}

@misc{schick2023toolformerlanguagemodelsteach,
  title={Toolformer: Language Models Can Teach Themselves to Use Tools},
  author={Timo Schick and Jane Dwivedi-Yu and Roberto Dess√¨ and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
  year={2023},
  eprint={2302.04761},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2302.04761},
}

@inproceedings{fedoseev2024llm,
  title={{LLM} Training Data Synthesis for More Effective Problem Solving using Satisfiability Modulo Theories},
  author={Timofey Fedoseev and Dimitar Iliev Dimitrov and Timon Gehr and Martin Vechev},
  booktitle={The 4th Workshop on Mathematical Reasoning and AI at NeurIPS'24},
  year={2024},
  url={https://openreview.net/forum?id=hR4Hskr4GX}
}

@inproceedings{pan-etal-2023-logic,
  title = "Logic-{LM}: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning",
  author = "Pan, Liangming  and
    Albalak, Alon  and
    Wang, Xinyi  and
    Wang, William",
  editor = "Bouamor, Houda  and
    Pino, Juan  and
    Bali, Kalika",
  booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
  month = dec,
  year = "2023",
  address = "Singapore",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.findings-emnlp.248",
  doi = "10.18653/v1/2023.findings-emnlp.248",
  pages = "3806--3824",
  abstract = "Large Language Models (LLMs) have shown human-like reasoning abilities but still struggle with complex logical problems. This paper introduces a novel framework, Logic-LM, which integrates LLMs with symbolic solvers to improve logical problem-solving. Our method first utilizes LLMs to translate a natural language problem into a symbolic formulation. Afterward, a deterministic symbolic solver performs inference on the formulated problem. We also introduce a self-refinement module, which utilizes the symbolic solver{'}s error messages to revise symbolic formalizations. We demonstrate Logic-LM{'}s effectiveness on five logical reasoning datasets: ProofWriter, PrOntoQA, FOLIO, LogicalDeduction, and AR-LSAT. On average, Logic-LM achieves a significant performance boost of 39.2{\%} over using LLM alone with standard prompting and 18.4{\%} over LLM with chain-of-thought prompting. Our findings suggest that Logic-LM, by combining LLMs with symbolic logic, offers a promising avenue for faithful logical reasoning.",
}

@misc{ye2023satlmsatisfiabilityaidedlanguagemodels,
  title={SatLM: Satisfiability-Aided Language Models Using Declarative Prompting},
  author={Xi Ye and Qiaochu Chen and Isil Dillig and Greg Durrett},
  year={2023},
  eprint={2305.09656},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2305.09656},
}

@misc{zebralogic2024,
  title={ZebraLogic: Benchmarking the Logical Reasoning Ability of Language Models},
  author={Bill Yuchen Lin and Ronan Le Bras and Peter Clark and Yejin Choi},
  url={https://huggingface.co/spaces/allenai/ZebraLogic},
  year={2024}
}

@inproceedings{ckl2004,
  AUTHOR    = { Clarke, Edmund
                and Kroening, Daniel
                and Lerda, Flavio },
  TITLE     = { A Tool for Checking {ANSI-C} Programs },
  BOOKTITLE = { Tools and Algorithms for the Construction and Analysis of Systems (TACAS 2004) },
  YEAR      = { 2004 },
  PUBLISHER = { Springer },
  PAGES     = { 168--176 },
  ISBN      = { 3-540-21299-X },
  SERIES    = { Lecture Notes in Computer Science },
  VOLUME    = { 2988 },
  EDITOR    = { Kurt Jensen and Andreas Podelski },
}

@inproceedings{ckkst2018,
  AUTHOR    = { Cordeiro, Lucas
                and Kesseli, Pascal
                and Kroening, Daniel
                and Schrammel, Peter
                and Trtik, Marek },
  TITLE     = { {JBMC}: A Bounded Model Checking Tool for Verifying {Java} Bytecode },
  BOOKTITLE = { Computer Aided Verification (CAV) },
  YEAR      = { 2018 },
  PUBLISHER = { Springer },
  PAGES     = { 183--190 },
  ISBN      = { 978-3-319-96144-6 },
  SERIES    = { LNCS },
  VOLUME    = { 10981 },
}

@article{program-synthesis-for-program-analysis, title= {Program Synthesis for Program Analysis}, author= {David, Cristina and Kesseli, Pascal and Kroening, Daniel and Lewis, Matt}, year= {2018}, journal= {ACM Transactions on Programming Languages and Systems}, month= {05}, pages= {1-45}, volume= {40}}

@article{han2022folio,
  title={FOLIO: Natural Language Reasoning with First-Order Logic},
  author = {Han, Simeng and Schoelkopf, Hailey and Zhao, Yilun and Qi, Zhenting and Riddell, Martin and Benson, Luke and Sun, Lucy and Zubova, Ekaterina and Qiao, Yujie and Burtell, Matthew and Peng, David and Fan, Jonathan and Liu, Yixin and Wong, Brian and Sailor, Malcolm and Ni, Ansong and Nan, Linyong and Kasai, Jungo and Yu, Tao and Zhang, Rui and Joty, Shafiq and Fabbri, Alexander R. and Kryscinski, Wojciech and Lin, Xi Victoria and Xiong, Caiming and Radev, Dragomir},
  journal={arXiv preprint arXiv:2209.00840},
  url = {https://arxiv.org/abs/2209.00840},
  year={2022}
}
