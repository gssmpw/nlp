\section{Related Work}
% \vspace{-0.2cm}
In this section, some of the relevant works in the literature relating to this paper are discussed briefly.

\noindent\textbf{Generative Adversarial Networks:}  In past few years, GANs ____ had been the go-to method for generating images and class-specific images ____ on small datasets such as MNIST ____ and CIFAR ____. However, GAN training is highly unstable when used to generate images on large datasets such as ImageNet ____. Researchers have explored to fix this training instability by re-framing  GAN loss and regularisation ____ to generate high-resolution images on large datasets ____. 

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{images/Dte_arch.pdf}
    %Model_achitecute.drawio.pdf}
    \vspace{-0.2cm}
    \caption{Overview of DTE-GAN architecture. DTE-GAN consists of three core components: i) a single-stage generator $G$ (Section \ref{sec:generator}), ii) a discriminator $D$ (Section \ref{sec:discriminator}), and iii) a dual text embedding setup (Section \ref{sec:dualtextembed}). In the Figure, $W_G$ = generator-side word embeddings, $S_G$ = generator-side sentence embedding, $W_D$ = discriminator-side word embeddings, $S_D$ = discriminator-side sentence embedding. The model is optimised using two objective functions: 1) adversarial loss, and 2) multi-modal contrastive loss.}
    \label{fig:modelarch}
    % \vspace{-0.9cm}
\end{figure*}

\noindent \textbf{Text-to-Image synthesis:} GANs conditioned on global sentence-level embeddings are known to generate meaningful images at low resolutions ____. StackGAN ____ generates high-resolution images in stage-wise approach, where the generator at each stage is conditioned by the image generated from the previous stage. Unlike StackGAN, HDGAN ____ trains a single generator and multiple discriminators for each resolution. 
AttnGAN ____ uses text embeddings to fine-tune image features and also introduces a multimodal contrastive loss (DAMSM loss) to bridge the gap between generated images and words. DM-GAN ____ refines words and image features using a memory module. MirrorGAN ____ generates a caption for the generated images that improves the text \textit{vs.} image semantic consistency. SD-GAN ____ introduces a Siamese structure for the generator that uses Conditional Batch Normalization (CBN) ____ to improve the alignment of text-image. CPGAN ____ learns a memory-attended text encoder by attending to salient features in images for each word and fine-grained discriminator ____.  DTGAN ____ applies channel and spatial attention, conditioned on sentence vector to focus on important features for each textual representation. XMC-GAN ____ maximises the mutual information between text and image using intra-modality and inter-modality contrastive losses. DF-GAN ____ uses deep affine transformed global sentence embedding to condition the geand theator and the matching-aware discriminator. 
In this space of text-to-image semantic alignment-based methods, pre-trained embeddings are an inherent prerequisite. These embeddings are only trained by the discriminative approach. Unlike these methods, our apporach (DTE) attempts to learn text embeddings that capture generative and discriminative properties.  

\noindent \textbf{Generative embedding learning:} Some methods attempt to learn embeddings (text / visual) end-to-end as part of a generator. For example, ____ learn discrete embeddings for visual representation and show substantial improvement in the performance of text-to-image synthesis ____. Further better and compact representation are learned to improve the quality of image generation ____. Unlike these works that consider only the generation process while learning embeddings, DTE explores the capture of different perspectives of generation and discrimination process by learning dual text embeddings.

\noindent \textbf{Large Scale Text-to-Image Synthesis:} Denoising Diffusion Probabilistic models ____ have currently achieved remarkable success in image generation ____ by reversing the \textit{forward Markovian process} with noise removal in multiple steps. Though diffusion-based models are able to generate images with complex and varied interactions for text and generate high-quality images ____, these approaches require large-scale training and exploit pre-trained discriminative language models like CLIP ____. Further, CLIP-based language and image encoders are used as a bootstrapping approach for predicting conditional representations in large-scale GAN-based approaches ____. Unlike CLIP, which is trained to capture text-image alignment only, DTE is proposed to learn text-image alignment and text representation toimprove image realism. 

% \vspace{-0.4cm}