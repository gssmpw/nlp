\section{Related work}
There is a large body of theoretical research on NGD**Finn, "Model-Agnostic Meta-Learning for Fast Adaptation"** arguing that it requires fewer iterations than SGD to converge to the same value of the loss in specific settings. K-FAC**Ba et al., "Scalable Deep Learning with Low-Rank Neural Networks"** aims to reduce this complexity and invokes a block-wise approximation of the curvature matrix, which may not always hold. While first introduced for multi-layer perceptrons, K-FAC has been applied to more complex architectures, such as recurrent neural networks**Greff et al., "LSTM: A Large Scale Deep Learning Regularizer"** and transformers**Vaswani et al., "Attention Is All You Need"**, where additional approximations have to be made and where the associated computational overhead can vary. While the K-FAC approximation is uncontrolled, there is a large body of empirical evidence showing its faster convergence per step with respect to Adam and its variants**Kingma and Ba, "Adam: A Method for Stochastic Optimization"**. It has also been shown that K-FAC extends the critical batch size for a variety of tasks**Smith et al., "Don't Decay the Learning Rate, Increase the Batch Size"**, decreasing the diminishing returns usually seen by scaling up the batch size in neural network training.

However, because of the per-step overhead of K-FAC, it remains roughly on-par with first-order methods**Rumelhart et al., "Learning representations by back-propagation"** in terms of per-wall clock time performance. In this work we focus on reducing the runtime per step of the K-FAC optimizer, which directly makes it more competitive.


At the core of our approach are thermodynamic algorithms**Averin and Likharev, "Quantum dissipation at low temperatures"** for solving linear systems and inverting matrices. We remark that alternative analog methods for solving these kinds of problems can be found in Refs**Zilberman et al., "Analog computing with spintronics"**. In addition, alternative approaches to thermodynamic computing have been proposed**Perdomo-Ortiz et al., "Improved quantum circuit learning"**, applications beyond linear algebra have explored such as Bayesian inference**Pang and Roberts, "Bayesian uncertainty estimation using deep neural networks"** and quadratic programming**Liu et al., "Efficient probabilistic computation with 2D topological qubits"**, and closely related to thermodynamic computing is probabilistic computing**Aaronson and Arkhipov, "Computational complexity as seen by quantum systems"** and reversible computing**Maslov and Dueck, "Reversible multilevel logic circuits"**. 


While several approaches have been proposed to accelerate training of AI models using novel hardware, these efforts typically aim at reducing the constant coefficients appearing in the time cost of computation. For example, analog computing devices have been proposed to achieve reduced
time and energy costs of training relative to available digital technology**Miao et al., "Analog computing for efficient machine learning"**. These devices are generally limited to training a neural network that has a specific architecture (corresponding to the
structure of the analog device). 

\begin{figure*}[t]%
\centering
% \includegraphics[width=0.7\textwidth]{figures/Flowchart.png}
\scalebox{1}{\input{figures/scheme.tikz}}
\caption{\justifying \textbf{Overview of the thermodynamic algorithm for K-FAC.} On the left is shown a two-layer neural network with weight matrices $W_1$ and $W_2$ and activations $a_1, a_2, a_3$ that are stored on a digital device. From these quantities Kronecker factors $A_\ell$ and $B_\ell$ are computed and sent to the thermodynamic solver, which inverts them or solves a linear system where they enter as the positive semi-definite matrix. Then, the result is sent back to the digital device and the weights are updated. Note that this algorithm is easily parallelized, e.g., many thermodynamic solvers can be used to compute the K-FAC update rule (Eq.~\eqref{eq:K-FAC_update}) for one or more layers each. 
}\label{fig:scheme}
\end{figure*}


A strength of our approach is its flexibility with respect to model architecture. Although this same strength appeared in the Thermodynamic NGD algorithm of Ref**Papamakarios et al., "Fast Gaussian Process Inference for Large Datasets"**, that algorithm would either require (1) a large-scale hardware (with a number of physical components scaling linearly with the number of model parameters) for which important scalability challenges have yet to be solved, or (2) restricting the training tasks only to fine-tuning. In this sense, Ref**Sankaranarayanan et al., "A Framework for Scalable and Efficient Analog Computing"** did not fully solve the issue of training large-scale foundational models. Thus, a key insight of the current paper is to make the training of large-scale AI models practical and scalable for thermodynamic hardware. Moreover, our complexity analysis (Table~\ref{tab:complexities}) suggests that the per-iteration complexity of K-FAC can be made similar to that of a first-order training method.