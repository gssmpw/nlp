% \clearpage
\section{Experiments}
\begin{table*}[t]
    \caption{In all benchmark tests, we compare the performance of our study with 4 baselines. RMSE and ACC are recorded. A small RMSE ($\downarrow$) and a bigger ACC ($\uparrow$) indicate better performance. The best results are in \textbf{bold}, and the second best are with \underline{underline}.
}
    \small
    \label{tab:mainres}
    \vspace{-5pt}
    \vskip 0.13in
    \centering
    \begin{small}
        \begin{sc}
            \renewcommand{\multirowsetup}{\centering}
            \setlength{\tabcolsep}{2.8pt} % Adjust the spacing between columns if needed
            \begin{tabular}{l|cc|cc|cc|cc|cc}
                \toprule
                \multirow{4}{*}{Model} & \multicolumn{10}{c}{Metric}  \\
                \cmidrule(lr){2-11}
                &  \multicolumn{2}{c}{6-hour} & \multicolumn{2}{c}{1-day} & \multicolumn{2}{c}{4-day} & \multicolumn{2}{c}{7-day} & \multicolumn{2}{c}{10-day}   \\
                \cmidrule(lr){2-11}
               & RMSE& ACC & RMSE& ACC & RMSE& ACC & RMSE& ACC & RMSE& ACC \\

                \midrule
                Pangu-weather~\cite{bi2023accurate} &0.0921&0.9958 &0.1635&0.9868&\underline{0.3723}&0.9305&\underline{0.5576}&\underline{0.8414}&\underline{0.6680}&\underline{0.7763}     \\
                Fengwu~\cite{chen2023fengwu} &0.1428  &0.9913 &0.2584 &0.9738  &0.5186 &0.8958 & 0.7874&0.8061 &1.2370  &0.7409    \\
                Graphcast~\cite{lam2023learning} &\underline{0.0887}  &\underline{0.9962} &\underline{0.1634} &\underline{0.9878}  &0.3962 &\underline{0.9308} &0.6026&0.8362 &0.7374  &0.7625    \\
                Fuxi~\cite{chen2023fuxi} &0.1106 & 0.9941 &0.1838&0.9838  &0.4329&0.9055& 0.6056&0.8116&  0.6913&0.7571  \\
                \midrule
                \method{}(ours) &\textbf{0.0683} &\textbf{0.9976} &\textbf{0.1294}&\textbf{0.9917}&\textbf{0.2954}&\textbf{0.9577}& \textbf{0.4823}&\textbf{0.8839}&\textbf{0.6306}&\textbf{0.8025}  \\
                \midrule
                \method{}(Promotion) &19.11\% &0.11\% &19.38\%&0.38\%&20.66\%&2.89\%& 13.49\%&5.05\%&5.59\%&3.38\%  \\

                \bottomrule
            \end{tabular}
        \end{sc}
	\end{small}
    \vspace{-5pt}
\end{table*}

\begin{figure*}[h]
\centering
\includegraphics[width=1\linewidth]{figures/fig1_vis.jpg}
\vspace{-20pt}
\caption{10-day forecast results of different models.}
\label{fig:visual_results}
\vspace{-15pt}
\end{figure*}

\begin{figure*}[h]
        \centering
        \includegraphics[width=1\linewidth]{figures/acc_rmse.png}
        \vspace{-20pt}
        \caption{We select the latitude-weighted RMSE (lower is better) and ACC (higher is better) of several variables.}
        \label{fig:acc_rmse}
\vspace{-10pt}
\end{figure*}

    %

    %
    In this section, we extensively evaluate the performance of OneForecast, covering metric results, visual results, and extreme event analysis. We conduct all experiments on 128 NVIDIA A100 GPUs.
    %

\subsection{Benchmarks and Baselines}
    %
    We conduct the experiments on the weatherbench2~\cite{rasp2024weatherbench} benchmark, a subset of the fifth generation of ECMWF Reanalysis Data (ERA5)~\cite{hersbach2020era5}. The subset we use includes years from 1959 to 2020, which is 1959-2017 for training, 2018-2019 for validing, and 2020 for testing. We use 5 pressure level variables (each with 13 pressure levels), geopotential (Z), specific humidity (Q), temperature (T), U and V components of wind speed (U and V), and 4 surface level variables 10-meter U and V components of wind (U10M and V10M), 2-meter temperature (T2M), and Mean sea-level pressure (MSLP). For the global weather forecasts, we choose the 1.5° (121 × 240 for the global data) version of weatherbench2 as our dataset. For convenience, we just choose 120 × 240 data to train models. For regional weather forecasts, we use the original 0.25° (721 × 240 for the global data) ERA5 data.  More details can be found in the Appendix \ref{appendix:data}. We compare the forecast performance of OneForecast with 4 data-driven models (Pangu~\cite{bi2023accurate}, Grapcast~\cite{lam2023learning}, Fengwu~\cite{chen2023fengwu}, and Fuxi~\cite{chen2023fuxi}). And these models are trained using same framework and settings. We also compare extreme event prediction with IFS HRES, the state-of-the-art numerical method.
    %

\subsection{Comparison with state-of-the-art methods}
    %
    We utilize two metrics, RMSE (Root Mean Square Error) and ACC (Anomalous Correlation Coefficient), to evaluate the forecast performance. More details can be found in \ref{appendix_metrics}. Since the magnitudes of different variables vary greatly, we first normalize the 69 variables and then calculate the indicators for the 1300 initial conditions. As shown in Table \ref{tab:mainres}, OneForecast achieves satisfactory performance compared with the state-of-the-art models. As shown in Figure \ref{fig:visual_results}, OneForecast are closer with the ground truth. We also show the forecast results of several important variables in Figure \ref{fig:acc_rmse}, which are not normalized. Our OneForecast performs better than other models. This improvement is primarily attributed to integrating the proposed adaptive message passing module, which enhances OneForecast’s ability to model the relationships between atmospheric states across different regions of the earth that allows for the simulation of atmospheric dynamics at various spatial and temporal scales adaptively. In summary, the forecasts exhibit more consistency with the actual physical field, effectively mitigate over-smoothing, and demonstrate superior predictive performance, particularly for extreme atmospheric values.    %

\subsection{Regional High Resolution Forecast}\label{Regional}
    %
    Although the training cost of low-resolution forecast models is relatively low, their prediction results lack sufficient details. However, directly training on high-resolution regional data often results in poor regional forecasts performance due to issues such as missing boundary conditions and limited data samples. Although the regional forecasts method proposed by ~\cite{oskarsson2024probabilistic} improves prediction accuracy, it remains constrained by the absence of global information in high-resolution regional models, leaving room for improvement in forecast results. In contrast, the Neural Nesting Grid (NNG) method proposed in this study incorporates boundary conditions and global future information, enabling more accurate high-resolution regional predictions. Furthermore, NNG makes full use of the forecast results of global models, which achieves high-resolution regional forecasts at an exceptionally low training cost. Therefore, as shown in Figure \ref{fig:quyu_com}, we only demonstratively conduct high-resolution predictions for two regional variables without requiring training on all variables (e.g., the 69 variables used for training global models). It can be seen that the poor long-term inference results are poor when only using regional data for training. Graph-EFM takes into account boundary conditions and the effect is improved. And our proposed NNG not only takes into account regional boundary conditions, but also makes full use of the future forecast information of the global model, which achieves stable long-term forecast performance.
    %

    \begin{figure}[h]
\centering
\includegraphics[width=0.99\linewidth]
{figures/fig_100days.png}
\vspace{-3mm}
\caption{Comparison results of 100-day forecasts between the two best models and our OneForecast.}
\label{fig:100days}
\vspace{-3mm}
\end{figure}

\begin{figure*}[t]
\centering
\includegraphics[width=1\linewidth]{figures/quyu_com.png}
\vspace{-20pt}
\caption{High-resolution regional results. In the left figure, we select two variables, MSLP and U10M, for visualization. We compare our model with Graph-EFM and the method that directly trains on high-resolution data. The right figure shows line charts of RMSE and ACC for different models over time. These two figures demonstrate that our proposed neural nesting grid method achieves the best performance.}
\label{fig:quyu_com}
\vspace{-15pt}
\end{figure*}


\subsection{Extreme Events Assessment}
    %
    Extreme events, such as tropical cyclones, can significantly impact human society. In this section, we evaluate our model's ability in forecasting those extreme cyclones. As shown in Figure \ref{fig:icml_intro}, OneForecast achieves competitive performance in typhoon tracking during two extreme events, Yagi (2018) and Molva (2020). The details of tracking algorithm can be found in Appendix \ref{appendix:typhoon}. Additionally, we download the forecast results of baseline models (e.g., Pangu, Fuxi and Graphcast) from weatherbench2, which is trained using high resolution (0.25°) data, to better illustrate the performance of the baselines. Although OneForecast uses lower-resolution (1.5°) data, which may limit its capacity to predict cyclones, it nevertheless shows strong forecast skills in tracking tropical cyclones comparing with the baselines. 
    %

    

    \begin{table}[t]
    \vspace{-3mm}
    \caption{Comparison results between deterministic forecasts and uncertain ensemble forecast (ENS), the best results are in \textbf{bold}. We select 10 initial conditions, and for ENS, each results contains 50 members.}
    \small
    \label{tab:ens}
    \vspace{-5pt}
    \vskip 0.13in
    \centering
    \begin{small}
        \begin{sc}
            \renewcommand{\multirowsetup}{\centering}
            \setlength{\tabcolsep}{3.8pt} % Adjust the spacing between columns if needed
            \begin{tabular}{l|cccc}
            \toprule
            \multirow[c]{4}{*}{Model} & \multicolumn{4}{c}{Metrics}                                                                                        \\ \cmidrule(lr){2-5} 
                                   & \multicolumn{2}{c}{4-day}                                & \multicolumn{2}{c}{10-day}                              \\ \cmidrule(lr){2-5} 
                                   & RMSE                       & ACC                         & RMSE                       & ACC                        \\ \midrule
            Pangu                  & 0.3721                     & \multicolumn{1}{c|}{0.9334} & 0.6778                     & 0.7862                     \\
            Pangu (ENS)            & 0.3488                     & \multicolumn{1}{c|}{0.9402} & 0.5640                     & 0.8236                     \\
            Fengwu                 & 0.5309                     & \multicolumn{1}{c|}{0.8913} & 1.1019                     & 0.7454                     \\
            Fengwu (ENS)           & 0.5107                     & \multicolumn{1}{c|}{0.8971} & 0.9288                     & 0.7781                     \\
            Graphcast              & 0.6897                     & \multicolumn{1}{c|}{0.7443} & 0.8591                     & 0.6724                     \\
            Graphcast (ENS)        & 0.3805                     & \multicolumn{1}{c|}{0.9378} & 0.6400                     & 0.8101                     \\
            Fuxi                   & 0.4425                     & \multicolumn{1}{c|}{0.9061} & 0.7364                     & 0.7556                     \\
            Fuxi (ENS)             & 0.4053                     & \multicolumn{1}{c|}{0.9175} & 0.6001                     & 0.7999                     \\ \midrule
            OneForecast            & \multicolumn{1}{l}{0.2939} & \multicolumn{1}{l|}{0.9594} & \multicolumn{1}{l}{0.6153} & \multicolumn{1}{l}{0.8252} \\
            OneForecast (ENS)      & \multicolumn{1}{l}{\textbf{0.3221}} & \multicolumn{1}{l|}{\textbf{0.9536}} & \multicolumn{1}{l}{\textbf{0.5385}} & \multicolumn{1}{l}{\textbf{0.8446}} \\
            \bottomrule
            \end{tabular}
                    \end{sc}
                \end{small}
\vspace{-6mm}
\end{table}
    

\subsection{Long-term and Ensemble Forecasts}
    %
    As shown in Figure \ref{fig:100days}, we evaluate long-term forecasts with the two best models on Z500 (500hPa Geopotential). Pangu exhibits patch artifacts in 100-day forecasts, while GraphCast experiences error accumulation that degrades the forecasted physical fields, rendering them physically implausible over time. In contrast, OneForecast achieves stable long-term forecast performance, effectively capturing large-scale atmospheric states without the aforementioned issues. These results highlight OneForecast's superior capability in maintaining accurate and physically consistent predictions over extended forecasting horizons. In Table \ref{tab:ens}, we show the results for 10 initial conditions (starting from 00:00 UTC 1 January 2020, and the interval between consecutive initial conditions is 100 time steps). The ensemble forecast (ENS) results are averaged from 50 members. Obviously, the forecasting performance is enhanced for each model when uncertainty is incorporated, and OneForecast still achieves the best performance.

\subsection{Ablation Studies}
    %
    To verify the effectiveness of the proposed method, as shown in Table \ref{tab:ablation}, we conducted detailed ablation experiments. We introduced the following model variants: (1) \textbf {OneForecast w/o Region Refined Graph}, we remove the region refined mesh from the finest mesh and compute the regional metrics. (2) \textbf {OneForecast w Region Refined Graph}, we reserve the region refined mesh. (3) \textbf {OneForecast R w/o NGG}, we remove the neural nested grid (NGG) method in the regional forecasts and only use the regional data to train the model. (4) \textbf {OneForecast R BF}, we remove the NGG in the regional forecasts and only use the boundary forcing method to train the model. The results of the ablation experiment show that removing any module will reduce the forecast performance, further proving the rationality of the components proposed by OneForecast. (5) \textbf {OneForecast R w NGG}, regional forecast model with NGG. (6) \textbf {OneForecast w/o MSM}, we remove the multi-stream messaging module (MSM) and use a traditional MLP-based messaging module. (7) \textbf {OneForecast}, the full version of OneForecast for the global forecasts. For (1) and (2), we only evaluate the region-refined data. For (3), (4), and (5), we only evaluate the specific regional data. For (6) and (7), we evaluate the global data. And these results are based on 4-day forecast results. Experimental results show that whether it is a global or regional forecast task, the lack of any component will degrade the performance of OneForecast, which proves the effectiveness of the proposed method. And as shown in Figure \ref{fig:high_low}, the proposed MSM can better capture of high and low frequency information, which achieves satisfactory results in long-term forecasts and extreme event forecasts, such as typhoons.
    %

\begin{table}[t]
    \caption{Ablation Studies on 1.5° weatherbench2 benchmark, the best results are in \textbf{bold}.}
    \small
    \label{tab:ablation}
    \vspace{-3pt}
    \vskip 0.13in
    \centering
    \begin{small}
        \begin{sc}
            \renewcommand{\multirowsetup}{\centering}
            \setlength{\tabcolsep}{1.1pt} % Adjust the spacing between columns if needed
            \begin{tabular}{l|cc}
                \toprule
                Variants                             & RMSE & ACC \\ 
                \midrule
                OneForecast w/o Region Refined Graph &0.3751      &0.8954     \\
                OneForecast w Region Refined Graph   &\textbf{0.2736}      &\textbf{0.9342}\\ 
                \midrule
                OneForecast R w/o NGG                &0.5850      &0.8405     \\
                OneForecast R BF                     &0.4473      &0.8734     \\
                OneForecast R w NGG                  &\textbf{0.3168}      &\textbf{0.9325}     \\ 
                \midrule
                OneForecast w/o MSM                  &0.3921      &0.9305     \\
                OneForecast                          &\textbf{0.2954}      &\textbf{0.9577}     \\
                \bottomrule
            \end{tabular}
        \end{sc}
    \end{small}
\vspace{-2mm}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.95\linewidth]{figures/high_low.png}
\vspace{-6pt}
\caption{Normalized Spectral Error of the proposed MSM and the traditional MLP-based massaging.}
\label{fig:high_low}
\vspace{-4mm}
\end{figure}
