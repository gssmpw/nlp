[
  {
    "index": 0,
    "papers": [
      {
        "key": "butcher2024precise",
        "author": "Butcher, Bradley and O'Keefe, Michael and Titchener, James",
        "title": "Precise Length Control in Large Language Models"
      },
      {
        "key": "kazemnejad2024impact",
        "author": "Kazemnejad, Amirhossein and Padhi, Inkit and Natesan Ramamurthy, Karthikeyan and Das, Payel and Reddy, Siva",
        "title": "The impact of positional encoding on length generalization in transformers"
      },
      {
        "key": "chang2024language",
        "author": "Chang, Yingshan and Bisk, Yonatan",
        "title": "Language Models Need Inductive Biases to Count Inductively"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "huang2025decoding",
        "author": "Huang, Chenyang and Zhou, Hao and Jen, Cameron and Zheng, Kangjie and Za{\\~A}{\\NG}ane, Osmar R and Mou, Lili",
        "title": "A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "promptRein",
        "author": "Renlong Jie and\nXiaojun Meng and\nLifeng Shang and\nXin Jiang and\nQun Liu",
        "title": "Prompt-Based Length Controlled Generation with Reinforcement Learning"
      },
      {
        "key": "ruler",
        "author": "Jiaming Li and\nLei Zhang and\nYunshui Li and\nZiqiang Liu and\nYuelin Bai and\nRun Luo and\nLongze Chen and\nMin Yang",
        "title": "Ruler: {A} Model-Agnostic Method to Control Generated Length for Large\nLanguage Models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "song2024hansel",
        "author": "Song, Seoha and Lee, Junhyun and Ko, Hyeonmok",
        "title": "Hansel: Output Length Controlling Framework for Large Language Models"
      },
      {
        "key": "wang2024positionid",
        "author": "Wang, Zekun and Duan, Feiyu and Zhang, Yibo and Zhou, Wangchunshu and Xu, Ke and Huang, Wenhao and Fu, Jie",
        "title": "PositionID: LLMs can Control Lengths, Copy and Paste with Explicit Positional Awareness"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "lift",
        "author": "Weizhe Yuan and\nIlia Kulikov and\nPing Yu and\nKyunghyun Cho and\nSainbayar Sukhbaatar and\nJason Weston and\nJing Xu",
        "title": "Following Length Constraints in Instructions"
      },
      {
        "key": "promptRein",
        "author": "Renlong Jie and\nXiaojun Meng and\nLifeng Shang and\nXin Jiang and\nQun Liu",
        "title": "Prompt-Based Length Controlled Generation with Reinforcement Learning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "retkowski2024zero",
        "author": "Retkowski, Fabian and Waibel, Alexander",
        "title": "Zero-Shot Strategies for Length-Controllable Summarization"
      },
      {
        "key": "juseon2024instructcmp",
        "author": "Juseon-Do, Juseon-Do and Kamigaito, Hidetaka and Okumura, Manabu and Kwon, Jingun",
        "title": "Instructcmp: Length control in sentence compression through instruction-based large language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "gu2024length",
        "author": "Gu, Yuxuan and Wang, Wenjie and Feng, Xiaocheng and Zhong, Weihong and Zhu, Kun and Huang, Lei and Chua, Tat-Seng and Qin, Bing",
        "title": "Length Controlled Generation for Black-box LLMs"
      }
    ]
  }
]