\begin{abstract}
% Significant progress has been made in automatic text evaluation with the introduction of large language models (LLMs) as evaluators. However, current sample-wise evaluation paradigm suffers from the following issues: (1) Sensitive to prompt design; (2) Poor resistance to noise; (3) Inferior ensemble performance with static reference. Inspired by the fact that humans treat both criterion definition and inter sample comparison as references for evaluation, we propose BATCHEVAL, a paradigm that conducts batch-wise evaluation iteratively to alleviate the above problems. We explore variants under this paradigm and confirm the optimal settings are two stage procedure with heterogeneous batch composition strategy and decimal scoring format. Comprehensive experiments across 3 LLMs on 4 text evaluation tasks demonstrate that BATCHEVAL outperforms state-of-the-art methods by 10.5\% on Pearson correlations with only 64\% API cost on average. Further analyses have been conducted to verify the robustness, generalization, and working mechanism of BATCHEVAL.
% 大语言模型(LLMs)的快速发展并没有使其length-controllable text generation（LCTG） 能力达到期望水准，这限制了大量的实际应用需求。
Despite the rapid progress of large language models (LLMs), their length-controllable text generation (LCTG) ability remains below expectations, posing a major limitation for practical applications.
Existing methods mainly focus on end-to-end training to reinforce adherence to length constraints. 
However, the lack of decomposition and targeted enhancement of LCTG sub-abilities restricts further progress.
To bridge this gap, we conduct a bottom-up decomposition of LCTG sub-abilities with human patterns as reference and perform a detailed error analysis.
% 当前的方法端到端地训练模型加强对长度限制的遵循，但由于缺少对LCTG sub-capabilities的decomposition and targeted enhancement，thereby limiting their progress.
% 为了fill this gap，我们首先以人类为参照对LCTG的子能力进行了自底向上的分解，并分别进行了error分析。
% 在此基础上，我们提出了simple yet effective, plug-and-play的\textsc{MakerGen}方法，which：(1) 通过外部工具引用弥补LLM基础能力的不足(2)通过自适应length markers插入来对长度显式建模（3）通过两阶段的生成范式来保证 length requirements are better met without compromising content quality.
On this basis, we propose \textsc{MarkerGen}, a simple-yet-effective plug-and-play approach that:
(1) mitigates LLM fundamental deficiencies via external tool integration;
(2) conducts explicit length modeling with 
dynamically inserted markers;
(3) employs a three-stage generation scheme to better align length constraints while maintaining content quality.
% 我们comprehensive的实验证明\textsc{MakerGen}在多种settings下都极大的提升了LCTG，展现了卓越的有效性和泛化性。
Comprehensive experiments demonstrate that \textsc{MarkerGen} significantly improves LCTG across various settings, exhibiting outstanding effectiveness and generalizability.\footnote{Our code have been released on \url{https://github.com/chuyi369/MarkerGen}.}.
\end{abstract}