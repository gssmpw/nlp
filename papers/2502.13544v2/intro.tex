\section{Introduction}
% 文本长度是自然语言的一个基本属性，随着长度的增加，语义信息也在不断积累。由于信息量是文本质量的核心，调整文本长度以优化整体信息内容或其密度是提高文本生成质量的关键。随着大规模语言模型（LLM）的进展，许多自然语言生成（NLG）任务取得了显著进展，而每种任务本身都有不同的隐性长度要求。例如，总结任务强调在保持关键信息的同时提高信息密度，而故事生成任务则更注重生成丰富且细致的叙事，同时保持逻辑性和连贯性。NLG任务的多样性不仅需要对文本长度进行控制，而且覆盖了从几十个字到几千个字的广泛范围。此外，现实应用往往会对文本长度提出明确的要求，这些要求可能是粗略的描述（例如“简洁”或“详细”）、明确的范围（例如“X到Y个字”）甚至是精确的字数。总之，长度可控的文本生成是一个至关重要而又复杂的挑战，要求模型在平衡任务特定约束、变化的长度尺度和细化的用户指令之间找到平衡。在不同的长度要求下，确保高质量的文本生成仍然是文本生成研究中的一个基本问题，且这一问题仍然迫切需要解决。
% Text length is a fundamental attribute of natural language, with semantic information accumulating as length increases. 
% As information volume is central to text quality, adjusting length to optimize total information content or its density is key to improving text generation. With the advancement of large language models (LLMs), significant progress has been made across various natural language generation (NLG) tasks, each inherently carrying distinct implicit length requirements. For instance, summarization prioritizes information density while preserving key content, whereas story generation favors producing rich and detailed narratives while maintaining coherence and logical flow. The diverse nature of NLG tasks not only necessitates length control but also spans a wide-ranging scale, from a few dozen to several thousand words. Moreover, real-world applications often impose explicit constraints on text length, ranging from coarse-grained descriptions (e.g., “concise” or “detailed”) to defined ranges (e.g., “X–Y words”) and even exact word counts. In summary, length-controllable text generation is a critical yet multifaceted challenge, requiring models to balance task-specific constraints, varying length scales, and granular user instructions. Ensuring high-quality text generation while adhering to different length requirements poses a fundamental challenge and remains a pressing issue in text generation research.

% 作为文本生成的关键属性，实现长度的可控性具有重要意义。
As a fundamental attribute of text generation, ensuring controllability over text length is of great importance \citep{CTGsurvey}. 
% 文本类型（摘要、故事创作等）、用户需求（倾向像是或精简的文本）、外在限制（社交平台的字数限制）的不同，会导向不同的长度需求，which在实际应用中是广泛存在的。
Different text types (e.g., summary, story), user needs (e.g., preference for detailed or concise writing), and external requirements (e.g., social media character limits) shape varied length constraints, which are widely present in real-world scenarios \citep{zhang2023survey}.
% 随着大语言模型发展带来的LLM应用增多，length controllable text generation (LCTG) 变得愈发重要。
With the rapid development of LLMs, their expanding range of applications has made length-controllable text generation (LCTG) even more crucial in current era \citep{foster2024token,gu2024length}.


\begin{figure*}[t]
  % \vspace{-1cm} % 负间距让图片靠近顶部
  \includegraphics[width=\textwidth, height=0.3\textheight]{latex/fig/Figure0_new.pdf}
  \caption{Sub-ability decomposition of LCTG and corresponding error analysis in LLMs.}
  \vspace{-0.5cm} % 负间距让图片靠近顶部
  \label{fig:Figure0}
\end{figure*}
% \begin{figure*}[t]
%   % \vspace{-1.8cm} % 负间距让图片靠近顶部
%   \includegraphics[width=\textwidth, height=0.3\textheight]{latex/fig/Figure0.pdf}
%   \caption{Sub-ability Decomposition of LCTG and Corresponding Error Analysis in LLMs.}
%   \label{fig:Figure0}
% \end{figure*}



% 目前，监督学习方法在广泛的长度尺度上精确建模文本长度方面存在困难，导致控制过于粗略且泛化能力有限。离散的长度监督导致长度遵循不准确，使得细粒度控制变得困难。此外，这些方法依赖于固定的长度分布和指令格式，限制了它们在处理不同提示和领域中的多样化长度约束时的有效性。
% Currently, supervised learning methods struggle to precisely model text length across a broad range of scales, resulting in coarse-grained control and limited generalization. Discrete length supervision leads to imprecise length adherence, making fine-grained control difficult. Moreover, these methods rely on fixed length distributions and instruction formats, limiting their ability to effectively handle diverse length constraints across different prompts and domains.

% 然而，LLM能力的提升并没有使当前的LCTG达到期望的效果。\citet{lift}实验发现当前advanced LLMs(e.g., GPT4-Turbo) violates length constraints in the prompt almost 50% of the time. 一些方法尝试了training-based的方法强化模型遵循length constraints，然而这些方法面临两个问题：（1）低泛化性：文本类型的广泛性和constraints的特异性（比如精确的constraint: 500 words,粗粒度的constraint: 500-600words，小于500words）导致training-based 方法无法实现很好的泛化效果，我们在section 3证明了这一点。（2）inferior controllability：尽管这些方法提升了LCTG，但仍然存在不可忽视的gap。
However, the ongoing enhancements in LLM capabilities have yet to deliver the expected performance in LCTG while ensuring semantic integrity \cite{foster2024token,wang2024positionid,song2024hansel}. \citet{lift} reports that even advanced LLMs (e.g., GPT-4 Turbo \citep{gpt4}) violate the given length constraints almost 50\% of the time. To address this, training-based methods \citep{DisentDPO,lift,promptRein,ruler} have been studied to reinforce LLMs' adherence to length constraints, yet they face two key challenges: (1) \textbf{Limited generalization}: Since text types are diverse and length constraints vary widely (e.g., ranging from an exact 500 words to coarse intervals like 500–600 words or below 500 words), training-based methods often fail to generalize effectively across different settings, as demonstrated in Appendix \ref{sec:Training-based methods performance}. (2) \textbf{Inferior controllability}: These methods strengthen LCTG by enforcing implicit length modeling during generation in a top-down manner via training, lacking the decomposition and targeted enhancement of LCTG sub-capabilities, thereby limiting their progress \citep{retkowski2024zero}.

% To fill this gap，我们以人类为参考，对LCTG进行了自底向上的、解耦的子能力分解。
% 在撰写一个1000字的故事时，人类通常会首先规划各部分的内容和字数分配。而后在写作阶段，持续统计字数，并结合plan撰写文本。
% 在这个过程中，从基础到进阶依次考验了四个能力：（1）感知——正确识别一个单词作为基本单位；（2）计数——正确计数序列中单位的数量；（3）规划——合理规划各部分字数来满足length constraints；（4）生成误差——生成过程中遵循长度约束。
To fill this gap, we take humans as a reference and conduct a bottom-up decomposition of sub-capabilities for LCTG. When writing a 500-word story, humans typically begin by planning the content and word allocation for each section. During writing, they continuously track the word count and compose the text in alignment with the plan.
This process progressively tests four key abilities: (1) \textbf{Identifying} and splitting the words correctly. (2) \textbf{Counting} the words precisely. (3) \textbf{Planning} the word counts of each part to meet the length constraints. (4) \textbf{Aligning} the generated text with length constraints while ensuring semantic integrity.

    
% 为了从根本上增强大规模语言模型（LLM）在不同尺度下精确建模文本长度的能力，我们对LLM生成文本中的长度控制误差进行自下而上的分析，并与人类的认知和执行过程进行类比。例如，在撰写一篇100字的新闻摘要时，人类通常会首先规划关键信息，粗略估算各部分内容的字数分配。在生成阶段，他们按照计划撰写文本，并持续跟踪字数，以确保既符合长度要求，又保证内容完整性。类比地，我们将LLM长度建模误差分解为四个关键组成部分：（1）感知误差——错误地识别单词的构成；（2）计数误差——在给定序列中对项目的枚举不准确；（3）规划误差——在长度约束下内容结构安排不当；（4）生成误差——在执行计划内容时未能有效遵守长度约束。
% To fundamentally enhance LLMs' ability to precisely model text length across varying scales, we conduct a bottom-up analysis of length control errors in LLM-generated text, drawing parallels to human cognitive and execution processes. For example, when writing a 100-word news summary, humans typically plan key content first, roughly estimating the word allocation for different sections. During the generation phase, they compose the text according to the plan while continuously tracking the word count to ensure both length compliance and content completeness. Analogously, we decompose LLM length modeling errors into four key components: (1) Perception error—misidentifying what constitutes a single word; (2) Counting error—inaccurate enumeration of items in a given sequence; (3) Planning error—ineffective structuring of content within a length constraint; and (4) Generation error—deviations in executing the planned content while adhering to length constraints. 

% 基于上述长度建模误差框架，我们对感知、计数、规划和生成进行了实验研究。我们的发现表明，计数误差和感知误差是生成不准确的主要原因，而规划误差几乎可以忽略不计。这确认了当前长度可控文本生成的核心问题在于LLM在长度建模中的不准确性。此外，我们的分析还揭示了几个关键见解。特别地，LLM是以单词级别感知长度，而非标记级别，这表明它们的计数机制主要依赖于语义积累，而非自回归解码过程。此外，在生成过程中加入显式的规划和逐步计数在一定程度上减少了长度误差，表明LLM在隐式长度跟踪方面存在困难，而将其推理过程显式化能够有效提高其长度控制能力。
% Building upon the above length modeling error framework, we conducted experiments on perception, counting, planning, and generation. Our findings reveal that counting errors and perception errors are the primary contributors to generation inaccuracies, whereas planning errors are nearly negligible. This confirms that the core issue in current length-controllable text generation lies in the inaccuracies in LLMs' length modeling.Furthermore, our analysis uncovers several key insights. Notably, LLMs perceive length at the word level rather than the token level, indicating that their counting mechanism primarily relies on semantic accumulation rather than an autoregressive decoding process. Additionally, incorporating explicit planning and stepwise counting during generation reduces length errors to some extent, suggesting that LLMs struggle with implicit length tracking, and explicitly externalizing their reasoning process can effectively improve their length control capabilities.

% On this basis，我们对LCTG进行了解耦地进行了误差分析。实验结果表明：计数误差>感知误差>Aligning error>Planning Error. 这说明底层能力的不足主要造成了inferior的LCTG。这进一步解释了training-based的方法由于难以为这些底层能力提供细粒度的监督信号而无法有效增强LCTG。
% Building upon this
On this basis, we conduct a decoupled error analysis of LCTG. The experimental results indicate that $\text{counting error} > \text{perception error} > \text{aligning error} \gg \text{planning error}$. This suggests that deficiencies in fundamental capabilities are the primary cause of LCTG’s inferior performance. Meanwhile, it further explains why training-based approaches struggle to enhance LCTG effectively, as they are unable to provide fine-grained supervision signals for these fundamental capabilities.


% 基于上述误差分析，我们提出了PnPLPB，一个用于高质量长度可控文本生成的两阶段即插即用框架。该框架能够在不同尺度上精确建模文本长度，同时缓解关键误差来源，确保长度准确性和语义质量。为了解决感知和计数误差，我们引入了长度标记插入器和指令遵循鉴别器，利用基于规则的单词区分和计数机制，在解码过程中动态插入精确的长度标记，从而增强长度意识并消除计数偏差。为了进一步提高生成质量，同时保持严格的长度控制，我们采用了两阶段生成策略，将长度约束与语义生成解耦。在第一阶段，模型生成一个高质量的响应，长度大致对齐；在第二阶段，长度标记插入器通过受控重写优化文本，确保精确遵循指定长度，同时保持连贯性和信息性。
% Building upon this, we propose PnPLPB, a two-stage plug-and-play framework for high-quality length-controllable text generation. It enables precise length modeling across different scales while mitigating key error sources to ensure both length accuracy and semantic quality. To address perception and counting errors, we introduce a length marker inserter and an instruction adherence discriminator, which leverage rule-based word discrimination and counting to dynamically insert precise length markers during decoding, enhancing length awareness and eliminating counting biases. To further improve generation quality while maintaining strict length control, we adopt a two-stage generation strategy that decouples length constraints from semantic generation. In the first stage, the model generates a high-quality response with approximate length alignment. In the second stage, the length marker inserter refines the text through controlled rewriting, ensuring precise adherence to the specified length while preserving coherence and informativeness.

% Building upon this, 我们提出了MarkerGen，一个简单有效，即插即用的方法来实现high-quality LCTG。
% 具体来说，对于LLM不擅长的Identifying和Counting，我们引入外部分词器和计数器进行弥补。为了将外部信息传送给LLM，我们设计自适应插入算法，在模型生成过程中动态插入长度marker，帮助模型对长度进行显式建模的同时尽量减少marker的插入对于语义建模的破坏。
% 为了弥补aligning，我们设计两阶段的生成范式，结耦语义和长度约束，保障长度约束得到满足的同时，内容质量不受影响。

Building upon this, we propose \textsc{MarkerGen}, a simple-yet-effective, plug-and-play method for achieving high-quality LCTG.
Specifically, to address LLMs' weaknesses in identifying and counting, we integrate external tokenizer and counter to track exact length information. To effectively convey these information to LLMs, we design an decaying interval insertion strategy that dynamically injects length markers during the generation process, enabling explicit length modeling while minimizing disruptions to semantic modeling.
Furthermore, to mitigate alignment issues, we propose a three-stage decoupled generation paradigm that decouples semantic constraints from length constraints, ensuring that length constraints are better met without compromising content quality.


% 我们进一步探讨了影响PnPLPB的长度控制精度和生成质量的关键因素。首先，我们研究了长度标记格式对模型编码长度约束能力的影响，评估了不同标记设计的有效性。其次，为了减小标记对语义质量的影响，我们提出了一种自适应插入策略，该策略动态调整标记密度，以平衡长度控制精度和文本质量。此外，通过注意力分析，我们探索了LLM在不同层级和长度尺度上的注意力分布，揭示了PnPLPB如何增强长度建模，并为精确且可控的文本生成提供更强的支持。
% We further investigate key factors influencing the length control precision and generation quality of PnPLPB. First, we examine the impact of length markers' format on the model’s ability to encode length constraints, evaluating the effectiveness of different marker designs. Second, to mitigate the impact of markers on semantic quality, we propose an adaptive insertion strategy that dynamically adjusts marker density to balance length control accuracy and text quality. Additionally, through attention analysis, we explore LLMs' attention distribution across different layers and length scales, revealing how PnPLPB enhances length modeling and provides stronger support for precise and controllable text generation.

% 我们在五个基准任务上进行了广泛的实验，涵盖了跨任务（总结、故事生成、问答、启发式生成）、跨尺度（30-1000字）和跨粒度（精确长度与范围约束）设置。为了确保全面评估，我们在Llama 3.1和Qwen2.5系列的五个模型上测试了PnPLPB。实验结果表明，在严格的长度约束下，PnPLPB相比基线减少了15%的长度误差（平均绝对误差为5%），同时实现了更高的质量评分，并且仅耗费64%的成本。在基于范围的长度约束下，我们的方法达到了99%的接受率，有效验证了其精确性、鲁棒性和泛化能力。我们的贡献总结如下：

% - 我们进行了LLM长度可控文本生成的**系统性自下而上分析**，解构了感知、计数、规划和生成误差，这些误差导致了长度建模的不准确性。

% - 我们提出了PnPLPB，一个**两阶段即插即用框架**。它包含一个基于规则辅助解码的长度鉴别器，用于标记插入，并采用一种两阶段生成策略，将长度约束与语义生成解耦，从而确保准确性和质量。

% - 我们在使用Llama 3.1和Qwen2.5模型的跨任务、跨尺度和跨粒度实验中证明，PnPLPB实现了平均绝对误差**5%**，同时提高了生成质量。

% - 我们进一步分析了标记插入密度及其他超参数对模型性能的影响，并通过可解释性研究，揭示了PnPLPB如何增强LLM精确建模文本长度的能力。
% We conducted extensive experiments on five benchmark tasks, covering cross-task (summarization, story generation, QA, heuristic generation), cross-scale (30–1000 words), and cross-granularity (precise length vs. range constraints) settings. To ensure comprehensive evaluation, we tested PnPLPB across five models from the Llama 3.1 and Qwen2.5 series. Experimental results demonstrate that under strict length constraints, PnPLPB reduces length errors by 15\% compared to baselines (with an average absolute error of 5\%), while achieving higher quality scores and incurring only 64\% of the cost. In range-based length constraints, our method achieves a 99\% acceptance rate, effectively validating its precision, robustness, and generalization capabilities.Our contributions are summarized as follows:

We conduct experiments with five LLMs on five benchmarks to validate the generalizability of \textsc{MarkerGen}, covering cross-task (summarization, story generation, QA, heuristic generation), cross-scale (from 10+ to 1000+ words), cross-lingual (English and Chinese) and cross-granularity (precise and rough constraints) settings.
Experimental results demonstrate that under precise length constraints, \textsc{MarkerGen} reduces length errors by 12.57\% compared to baselines (with an average absolute error of 5.57\%), while achieving higher quality scores and incurring only 67.6\% of the cost. 
In range-based length constraints, \textsc{MarkerGen} achieves a 99\% acceptance rate, further validating its effectiveness. 
Finally, we probe into the working
mechanism of \textsc{MarkerGen} through attention analysis: shallow layers primarily handle length modeling through markers, whereas deeper layers concentrate more on semantic modeling.

% 我们通过注意力分析，揭示了在\textsc{MarkerGen}方法下LLM通过marker在浅层进行长度建模，而在深层专注语义建模的working mechanism。

% \begin{itemize}
%     \item  We conduct a \textbf{systematic bottom-up analysis} of LLMs’ length-controllable text generation, deconstructing the perception, counting, planning, and generation errors that contribute to length modeling inaccuracies.

%     \item We propose PnPLPB, a \textbf{two-stage plug-and-play framework}. It incorporates a rule-based assisted decoding length discriminator for marker insertion and a two-stage generation strategy that decouples length constraints from semantic generation to ensure both accuracy and quality.

%     \item We conduct cross-task, cross-scale, and cross-granularity experiments using Llama 3.1 and Qwen2.5 models, demonstrating that PnPLPB achieve absolute error of \textbf{5\%} avg while improving generation quality.
    
%     \item We further analyze the impact of marker insertion density and other hyperparameters on model performance, and through interpretability studies, we reveal how PnPLPB enhances LLMs' ability to precisely model text length.

    

% \end{itemize}