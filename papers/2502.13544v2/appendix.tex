

\clearpage
\section{Related Work}
\label{sec:related work}


\paragraph{LCTG Methods}
Text length is a fundamental aspect of natural language that carries semantic information, making LCTG a task of balancing length and semantic constraints. Achieving precise length control remains a challenge for LLMs due to limitations in their architecture, such as position encoding \citep{butcher2024precise,kazemnejad2024impact,chang2024language} and decoding mechanisms\citep{huang2025decoding}. Consequently, existing methods focus on injecting length information to help LLMs model length accurately, which can be categorized into training-based and inference-based approaches.

Training-based methods inject varying levels of length signals during fine-tuning or reinforcement learning. For instance, \citet{promptRein, ruler} use prompt templates to teach LLMs the mapping between length and textual content, while \citet{song2024hansel, wang2024positionid} design fine-grained datasets to guide correct length modeling. Other methods, like \citet{lift, promptRein}, utilize reward functions to align length preferences during training. While effective in certain scenarios, these methods suffer from limited generalization across diverse LCTG tasks, including varying length constraints and instructions.Inference-based methods adjust inputs multiple times during generation to inject, such as through prompt-based Automated Revisions and Sample Filtering \citep{retkowski2024zero,juseon2024instructcmp}, or length-controlled importance sampling during decoding \citep{gu2024length}. Although these approaches can better generalize length alignment, they still struggle with achieving precise control.

While both approaches enhance LCTG, they often apply a top-down strategy that lacks deep understanding and targeted enhancement of LCTG sub-capabilities. This limits progress in meeting length constraints accurately. Furthermore, many methods neglect semantic constraints, and injecting length information may degrade text quality. Therefore, we propose \textsc{MarkerGen} to bridge this gap for precise length control and preserving semantic integrity.


\section{Detailed Sub-ability Error analyses in LCTG}
\label{sec:Sub-ability Decomposition}

\begin{figure*}[ht]
\centering
  % \vspace{-1cm} % 负间距让图片靠近顶部
  \includegraphics[width=0.85\textwidth, height=0.25\textheight]{latex/fig/Figure8.pdf}
  \caption{Schematic diagram of counting experiment under the condition of \( n=1 \)}
  \label{fig:Figure8}
\end{figure*}

\subsection{Identifying Error}  
Identifying error refers to the misidentification of fundamental length units. To systematically analyze this error, we design a counting experiment in which the model is prompted to sequentially recognize and accumulate length units, then compare its predicted count with the ground truth. Experimental results confirm that in the one-by-one accumulation setting, counting errors do not occur, meaning that the final length error entirely arises from identifying error (as shown in Figure \ref{fig:Figure8}).

\subsection{Counting Error}  
Counting error refers to the inaccurate enumeration of units in a given sequence, leading to deviations from the intended length. Therefore, in the setting where \(n > 1\) in the counting experiment, the final counting result error is caused by both identifying error and counting error. In this case, counting error can be decoupled by resolving identifying errors in the accumulation process, where errors result from the accumulation step.We also conducted the same counting experiment as in Section \ref{sec:counting_error} on the CNN/DailyMail summarization dataset, as shown in Figures \ref{fig:Figure9}.

From the figure, we can further validate the same conclusions as in Findings \ref{find1}, \ref{find2}, \ref{find3}, and \ref{find4} in Section \ref{sec:Decomposing Length Control Errors}, revealing that the length errors in the generated results of the LCTG task stem from significant errors in the LLM's perception and modeling of length.



\subsection{Planning Error}  
\label{sec:appen_planning}
Planning error refers to the misallocation of word counts across different sections, leading to a discrepancy from target length.The planning ability of LLMs encompasses not only length planning but also semantic planning. To effectively assess the quality of LLM’s semantic planning, we use Qwen-Plus \citep{qwen25} as the judge, with a scoring range of [1, 5]. The specific evaluation prompt is as follows:

\begin{quote}
You are tasked with evaluating the quality of a generated answer plan for a TruthfulQA question. The evaluation should focus on the truthfulness, logical coherence, and adherence to the given prompt and instructions. Rate the answer plan on a 5-point scale as follows:

\begin{itemize}
    \item \textbf{5: Outstanding} - The plan is highly truthful, logically coherent, and perfectly adheres to the prompt and instructions.
    \item \textbf{4: Very Good} - The plan is mostly truthful and coherent, with only minor issues in details or adherence to instructions.
    \item \textbf{3: Good} - The plan is acceptable but has noticeable shortcomings in truthfulness or coherence.
    \item \textbf{2: Poor} - The plan has significant issues in truthfulness or logical coherence and does not adequately follow the instructions.
    \item \textbf{1: Unacceptable} - The plan is largely untruthful, incoherent, or fails to follow the prompt instructions entirely.
\end{itemize}

Please provide the overall score in the following format: \texttt{\#\#\#score X}

\textbf{Question:}

\texttt{+ prompt}

\textbf{Generated Answer Plan:}

\texttt{+ generated\_plan}

Evaluate the answer plan based on the above criteria.
\end{quote}

Since the LCTG task requires meeting both length and semantic constraints, utilizing the LLM's superior planning ability for explicit planning before generation, as opposed to direct generation, helps to clearly define the modeling space for length and the semantic extension range. This not only contributes to improved text generation quality but also reduces length errors.

\begin{figure*}[t]
    % 下面两张图并排
    \begin{minipage}{0.51\textwidth}
        \centering
        \includegraphics[height=5.3cm]{latex/fig/Figure9.pdf}
    \end{minipage}
    \hfill
    \begin{minipage}{0.51\textwidth}
        \centering
        \includegraphics[height=5.3cm]{latex/fig/Figure9.2.pdf}
    \end{minipage}

    \caption{Error analyses of fundamental abilities in LCTG on CNN/DailyMail.}
    \label{fig:Figure9}
\end{figure*}


\begin{figure}[h]
  \includegraphics[width=\columnwidth,height=4.5cm]{latex/fig/Figure10.pdf}
  \caption{Absolute contribution of LCTG sub-capability deficiency of GPT 4o-mini.}
  \label{fig:Figure10}
\end{figure}

\subsection{Aligning Error}  


Aligning error refers to the discrepancy between the model’s perceived length and the target length, arising from the challenge of maintaining semantic integrity while adhering to length constraints.As shown in Figure \ref{fig:Figure4}, aside from Finding \ref{find7}, we observe significant differences in aligning error across models. Qwen2.5-32B-Instruct and GPT-4o mini exhibit larger alignment errors under fine-grained length modeling. As discussed in Section \ref{sec:Decomposing Length Control Errors}, “length estimation acts as a real-time constraint, dynamically regulating further extension. Ultimately, the model strives to align the length constraints while preserving semantic integrity.” High-frequency length perception updates pose greater challenges for the natural expansion of the semantic space, which explains why some models with weaker robustness in semantic expansion show significant alignment errors. These errors become a primary source of LCTG inaccuracies (as shown in Figure \ref{fig:Figure10}). This further emphasizes that LCTG is a task of balancing length and semantic constraints.




\subsection{LCTG Error}

Based on the above decomposition of sub-abilities in LCTG and the corresponding error analysis, we can clearly quantify the contribution of each decoupled error to the final LCTG error. As shown in Figure \ref{fig:Figure0}, the quantification results in the right figure represent the average values of four models under various \ n \
conditions. The conclusion we can draw is that the primary cause of significant length errors in current mainstream LLMs on LCTG tasks is the lack of bottom-up identification and counting capabilities required for accurate length modeling.



\section{Exploration of Interval Marker Insertion Strategy Variants}



\subsection{Length Marker Forms}
\label{sec:LM_form}


We explored the impact of different forms of length marker insertion on performance, such as the number of words generated "[k]", the semantic marker "[k words]", and the remaining words to be generated "[ $N_{\mathrm{target}}$ - k]" (remaining words). As shown in Table \ref{tab:marker_comparison}, we used Llama-3.1-8B-Instruct on the CNN/DailyMail dataset to investigate the effects of various marker forms under multiple \(n\) conditions on generation error and text quality. The results show that using a semantic length marker representing the number of words generated achieved the best performance in both length error and text quality.

\begin{table}[ht]
\centering
   \renewcommand\arraystretch{1.0}
  \setlength{\tabcolsep}{1.5em} 
\begin{tabular}{l c c}
\toprule
\textbf{Marker Form} & $E$ ($\downarrow$)  & $S$ ($\uparrow$) \\
\midrule
$[k]$ & 18.28 & 3.10 \\
$[k\ \text{words}]$ & \textbf{15.74} & \textbf{3.14} \\
$[N_{\mathrm{target}} - k]$ & 27.92 & 3.09 \\
\bottomrule
\end{tabular}
\caption{Comparison of Length Marker Forms and Their Performance}
\label{tab:marker_comparison}
\end{table}



\section{Detailed Benchmarks Introduction}
\vspace{-4pt}
\label{sec:bench_detail}
The benchmarks used in our experiments are as follows:
\vspace{-5pt}  
\begin{itemize}
    \setlength{\itemsep}{-2pt} % 调
    \item \textbf{CNN/DailyMail}\citep{CNN/DailyMail}: A summarization dataset of news articles, with 500 randomly sampled items. (\textit{18–165 words})
    \item \textbf{HANNA}\citep{HANNA}: A long-form story generation dataset with 200 selected items. (\textit{139–995 words})
    \item \textbf{TruthfulQA}\citep{TruthfulQA}: A benchmark for factual accuracy in open-domain QA. (\textit{101–294 words})
    \item \textbf{HelloBench}\citep{HelloBench}: A long-text generation benchmark. We selected subsets from \textit{heuristic text generation} (e.g., argumentative and roleplaying writing, covering five types) and \textit{open-ended QA} (spanning ten domains). (\textit{489–1450 words})
    \item \textbf{GAOKAO-Bench}\citep{gaokao}: A benchmark collected from the Chinese college entrance examination (GAOKAO). We selected the \textit{2010-2022 History Open-ended Questions} subset. (\textit{71–901 words})
\end{itemize}




\section{Detailed Experimental Results}
\label{sec:exp details}

\begin{table*}[ht]
  \centering
  \small
  \setlength{\tabcolsep}{1.30em} 
\renewcommand{\arraystretch}{1.00}
\begin{tabular}{ccccc}
\toprule
\multicolumn{5}{c}{\textbf{TLG dataset}} \\
\midrule
benchmark & Method & Models & $PM$ ($\uparrow$) & $FM$ ($\uparrow$)\\
\midrule
\multirow{2}{*}{TLG dataset} 
& before training & Llama-3.1-8B-Instruct & 5.55 & 10.20  \\
& RULER &Llama-3.1-8B-Instruct-ruler & 41.75 & 55.10  \\
\midrule
\multicolumn{5}{c}{\textbf{Precise Length Constraint Benchmark }} \\
\midrule
Benchmarks & Methods & Models &  $E$ ($\downarrow$)  & $S$ ($\uparrow$)\\
\midrule
\multirow{2}{*}{CNN/DailyMail}  
& Ruler & Llama-3.1-8B-Instruct-ruler & 78.21 & 3.10  \\
& \textsc{MarkerGen} & Llama-3.1-8B-Instruct & 3.36 & 3.18 \\
\midrule
\multirow{2}{*}{HANNA}  
& Ruler & Llama-3.1-8B-Instruct-ruler & 68.21 & 2.87 \\
& \textsc{MarkerGen} & Llama-3.1-8B-Instruct & 2.98 & 3.60 \\
\midrule
\multirow{2}{*}{TruthfulQA}  
& Ruler & Llama-3.1-8B-Instruct-ruler & 44.93 & 3.27 \\
& \textsc{MarkerGen} & Llama-3.1-8B-Instruct & 3.82 & 4.25 \\
\midrule
\multirow{2}{*}{Heuristic Generation}   
& Ruler & Llama-3.1-8B-Instruct-ruler & 66.17 & 2.94 \\
& \textsc{MarkerGen} & Llama-3.1-8B-Instruct & 6.03 & 4.03 \\
\bottomrule
\end{tabular}
\caption{\label{tab:ruler_results}Combined Benchmark Evaluation Table}
\end{table*}

\begin{table}[ht]
\centering
    \small
   \renewcommand\arraystretch{1.2}
  \setlength{\tabcolsep}{0.6em} 
\begin{tabular}{l l c c}
\toprule
\textbf{Methods} & \textbf{Models} & $E$ ($\downarrow$) & $S$ ($\uparrow$)\\
\midrule
Implicit & Qwen2.5-14B-Instruct& 27.41 & 3.47 \\
\textsc{MarkerGen} & Qwen2.5-14B-Instruct & 7.71 &3.55  \\
\bottomrule
\end{tabular}
\caption{GAOKAO-History Chinese Dataset Results}
\label{tab:chinese}
\end{table}

\subsection{Performance and Generalization Study of Training-based Methods}
\label{sec:Training-based methods performance}
To investigate the performance and generalization of training-based methods in diverse, real-world LCTG task scenarios, we selected Ruler, a training-based method that defines length control templates to regulate generation at the range level. This choice is based on the fact that Ruler is the only training-based baseline for which the code and training set are publicly available. We followed the exact setup provided in the repository and verified the correctness of our replication by achieving significant performance improvements on the given test set, as shown in Table \ref{tab:ruler_results}.

Next, we tested the trained model, referred to as Llama-3.1-8B-Instruct-ruler, across four selected benchmarks with varying tasks, length scales, and instructions, under cost-alignment conditions. The experimental results revealed substantial errors and a decline in text quality, even when compared to the implicit method's results without training (as shown in Table \ref{tab:Overall}). This finding demonstrates the limited generalization capability of the method, highlighting its struggle to cope with the complexity and diversity of real-world LCTG scenarios.


\subsection{Length Bias Correction in LLMs-as-a-Judge}

It has been demonstrated that LLMs-as-a-judge exhibit a noticeable length bias \citep{li2024generation, gu2024survey}. To evaluate the quality of generated text objectively and accurately for LCTG tasks, it is essential to correct for this length bias. We adopt the length-controlled AlpacaEval \citep{dubois2024length} and \citet{yuan2025llm}.

To derive unbiased judge scores, we use a Multiple Regression model. Specifically, we set the judge score as the dependent variable, with the generator categories as dummy variables, and the length of the generated text as a covariate. The model is formulated as follows:

\begin{equation}
\small
f(i) = \beta_0 + \beta_{M} \cdot C(\text{Method}) + \beta_{\text{m}} \cdot C(\text{Model}) + \beta_{\text{l}} \cdot \text{Length} + \epsilon
\label{equation: bias}
\end{equation}

Where \( f(i) \) denotes the judge score for the generated text \( \mathcal{G}_{i} \), \( C(\text{Method}) \) and \( C(\text{model}) \) are categorical variables representing the method and the model used, respectively, and \( \text{Length} \) is the actual length of the generated text. The coefficients \( \beta_{\text{M}} \), \( \beta_{\text{m}} \), and \( \beta_{\text{l}} \) are used to adjust the raw judge score \( f(i) \), effectively removing length bias by setting it to zero. These adjusted scores, free from length bias, serve as the metrics for faithfulness and alignment.





\begin{figure*}[t]
\centering
  % \vspace{-1cm} % 负间距让图片靠近顶部
  \includegraphics[width=0.9\textwidth, height=0.3\textheight]{latex/fig/Figure7.2.png}
  \caption{Attention Entropy across layers.}
  \vspace{-0.5cm} % 负间距让图片靠近顶部
  \label{fig:Figure11}
\end{figure*}


\subsection{Residual Length Error Analysis in \textsc{MarkerGen}}

This subsection focuses on analyzing the residual length errors in the \textsc{MarkerGen} framework. Building upon the sub-decomposition of LCTG errors presented in Section \ref{sec:Preliminaries}, we eliminate identifying and counting errors through Auxiliary Length Marker Insertion Decoding \ref{sec:Auxiliary Length Marker Insertion Decoding}. Moreover, by employing the Three-Stage Decoupled Generation strategy \ref{sec:Two-Stage High-Quality Text Generation}, we effectively reduce aligning errors, thus improving the robustness of all models in semantic expansion under precise length modeling with explicit length markers. This approach ensures semantic integrity while enhancing text generation quality through a clearer, more in-depth analysis of LLM’s LCTG sub-capabilities. Ultimately, residual LCTG errors are primarily driven by minimal aligning errors.





\subsection{Cross-layer Attention Analysis from the \textsc{MarkerGen} Perspective}

In this section, we perform a cross-layer attention analysis from the \textsc{MarkerGen} perspective. By examining attention patterns across different layers of the model, we aim to gain a better understanding of how length and semantic information are processed at various stages of generation, providing insights into improving the accuracy of LCTG tasks.

Combining the analyses from Figures \ref{fig:Figure7} and \ref{fig:Figure11}, we infer that in the shallow layers, attention is primarily focused on the length information represented by the length markers. This suggests that the model’s early stages prioritize processing and understanding the input length. The higher entropy in these layers indicates that the model needs to integrate various details and information to effectively comprehend the input. As the model progresses to deeper layers, attention shifts from the length information to the adjacent semantic content. The lower entropy in these layers indicates that the model refines its focus, extracting key features and generating more relevant output.

This pattern of attention distribution aligns with the findings from \citep{moonlength}, which emphasize that length modeling in the early layers serves as a foundation for semantic processing in the later layers. Our analysis further supports the notion that LCTG tasks depend on a dynamic interaction between length control and semantic generation, where early layers focus on length constraints and deeper layers prioritize semantic coherence.





\begin{figure*}[t]
\centering
  % \vspace{-1cm} % 负间距让图片靠近顶部
  \includegraphics[width=0.9\textwidth, height=0.3\textheight]{latex/fig/Figure11.png}
  \caption{Attention Matrices of the first layers with Insertion Interval \( n=4 \)}
  \vspace{-0.5cm} % 负间距让图片靠近顶部
  \label{fig:Figure12}
\end{figure*}

\begin{figure*}[t]
\centering
  % \vspace{-1cm} % 负间距让图片靠近顶部
  \includegraphics[width=0.9\textwidth, height=0.3\textheight]{latex/fig/Figure12.png}
  \caption{Attention Matrices of the first layers with Insertion Interval \( n=8 \)}
  \vspace{-0.5cm} % 负间距让图片靠近顶部
  \label{fig:Figure13}
\end{figure*}

\begin{figure*}[t]
\centering
  % \vspace{-1cm} % 负间距让图片靠近顶部
  \includegraphics[width=0.9\textwidth, height=0.3\textheight]{latex/fig/Figure13.png}
  \caption{Attention Matrices of the first layers with Insertion Interval is Decaying}
  \vspace{-0.5cm} % 负间距让图片靠近顶部
  \label{fig:Figure14}
\end{figure*}