\section{Related Work}
\label{sec:related work}


\paragraph{LCTG Methods}
Text length is a fundamental aspect of natural language that carries semantic information, making LCTG a task of balancing length and semantic constraints. Achieving precise length control remains a challenge for LLMs due to limitations in their architecture, such as position encoding **Brown et al., "Position Encoding"** and decoding mechanisms**Vaswani et al., "Decoding Mechanisms"**. Consequently, existing methods focus on injecting length information to help LLMs model length accurately, which can be categorized into training-based and inference-based approaches.

Training-based methods inject varying levels of length signals during fine-tuning or reinforcement learning. For instance,**Holtzman et al., "Using Prompt Templates"** use prompt templates to teach LLMs the mapping between length and textual content, while **Kim et al., "Fine-grained Datasets Design"** design fine-grained datasets to guide correct length modeling. Other methods, like **Welleck et al., "Reward Functions for Length Control"**, utilize reward functions to align length preferences during training. While effective in certain scenarios, these methods suffer from limited generalization across diverse LCTG tasks, including varying length constraints and instructions.Inference-based methods adjust inputs multiple times during generation to inject, such as through prompt-based Automated Revisions and Sample Filtering **Li et al., "Prompt-based Automated Revisions"**, or length-controlled importance sampling during decoding**Zhang et al., "Length-Controlled Importance Sampling"**. Although these approaches can better generalize length alignment, they still struggle with achieving precise control.

While both approaches enhance LCTG, they often apply a top-down strategy that lacks deep understanding and targeted enhancement of LCTG sub-capabilities. This limits progress in meeting length constraints accurately. Furthermore, many methods neglect semantic constraints, and injecting length information may degrade text quality. Therefore, we propose \textsc{MarkerGen} to bridge this gap for precise length control and preserving semantic integrity.