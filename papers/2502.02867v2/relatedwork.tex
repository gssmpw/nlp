\section{Related Works}
\label{sec:related}

\vspace{-0.1in}
\textbf{Imitation Learning:} IL trains agents to mimic expert behaviors. Behavior cloning uses supervised learning for replication \cite{kelly2019hg, sasaki2020behavioral, reddysqil, florence2022implicit, shafiullah2022behavior, hoque2023fleet, li2024imitation, mehta2025stable}, while Inverse RL derives reward functions from expert demonstrations \cite{Abbeel2004, Ziebart2008, dadashi2020primal, wang2022adversarially}. Building on IRL, adversarial methods distinguish between expert and learner behaviors to provide reward signals \cite{Ho2016, fu2017learning,li2017infogail, peng2018variational,lee2019efficient, ghasemipour2020divergence}. There are also approaches that aim to integrate the strengths of BC and IRL \cite{watson2024coherent}. Offline IL methods enable robust training without environment interaction \cite{kim2022demodice, xu2022discriminator,ma2022versatile, xu2022a,hong2023beyond,yan2023offline,  li2023mahalo, zhang2023discriminator, sun2023offline}, and strategies addressing dynamic shifts through diverse data have also been proposed \cite{Chae2022}.

\textbf{Cross-Domain Imitation Learning (CDIL):} CDIL transfers expert behaviors across domains with differences in perspectives, dynamics, or morphologies. Approaches include using the Gromov-Wasserstein metric for cross-domain similarity rewards \cite{fickinger2022gromov}, timestep alignment \cite{sermanet2018, Kim2020, Liu2018, Raychaudhuri2021}, and temporal cycle consistency to address alignment issues \cite{Zakka2022}. Techniques also involve removing domain-specific information via mutual information \cite{Cetin2021}, maximizing transition similarity \cite{Franzmeyer2022}, or combining cycle consistency with mutual information \cite{yin2022cross}. Adversarial networks and disentanglement strategies further enhance domain invariance \cite{Stadie2017, Sharma2019, shang2021, choi2024domain}.


\textbf{Imitation from Observation (IfO):} IfO focuses on learning behaviors without access to action information. Approaches can be divided into those leveraging vectorized observations provided by the environment \cite{Torabi2018generative, zhu2020off,desgarat2020, gangwani2022imitation, chang2022flow, liu2023ceil, freund2023coupled} and those utilizing images to model behaviors \cite{li2018oil, liang2018cirl,das2021model, karnan2022voila, karnan2022adversarial, belkhale2023hydra, zhang2024action,xie2024decomposing, ishida2024robust, aoki2024environmental}. Image-based methods, in particular, have gained attention for enabling robots to learn from human behavior captured in images, facilitating tasks like mimicking human actions \cite{sheng2014integrated, yu2018, zhang2022one, mandlekar2023human}.

%==========================================================