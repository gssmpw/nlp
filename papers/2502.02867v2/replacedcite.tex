\section{Related Works}
\label{sec:related}

\vspace{-0.1in}
\textbf{Imitation Learning:} IL trains agents to mimic expert behaviors. Behavior cloning uses supervised learning for replication ____, while Inverse RL derives reward functions from expert demonstrations ____. Building on IRL, adversarial methods distinguish between expert and learner behaviors to provide reward signals ____. There are also approaches that aim to integrate the strengths of BC and IRL ____. Offline IL methods enable robust training without environment interaction ____, and strategies addressing dynamic shifts through diverse data have also been proposed ____.

\textbf{Cross-Domain Imitation Learning (CDIL):} CDIL transfers expert behaviors across domains with differences in perspectives, dynamics, or morphologies. Approaches include using the Gromov-Wasserstein metric for cross-domain similarity rewards ____, timestep alignment ____, and temporal cycle consistency to address alignment issues ____. Techniques also involve removing domain-specific information via mutual information ____, maximizing transition similarity ____, or combining cycle consistency with mutual information ____. Adversarial networks and disentanglement strategies further enhance domain invariance ____.


\textbf{Imitation from Observation (IfO):} IfO focuses on learning behaviors without access to action information. Approaches can be divided into those leveraging vectorized observations provided by the environment ____ and those utilizing images to model behaviors ____. Image-based methods, in particular, have gained attention for enabling robots to learn from human behavior captured in images, facilitating tasks like mimicking human actions ____.

%==========================================================