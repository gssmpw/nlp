%!TEX root=main.tex

\section{Introduction}




The database community has long acknowledged
the need to store, process, and query data
in various degrees of structure,
from relational, to semi-structured, and more recently,
to unstructured data, including text, images, and video.
Recent developments in AI models,
and LLMs in particular, 
have unlocked the ability to better process
and make sense of unstructured data, in addition to structured data, for tasks
including information extraction~\cite{lin2024towards,liu2024declarative}, summarization~\cite{fang2024multi},  data 
cleaning~\cite{Narayan2022CanFM}, 
dataset search~\cite{huang2023fast}, and data integration~\cite{kayali2024mind}.
LLMs also enable us to better understand 
users, 
manifesting in rapid progress in 
benchmarks on translating natural language 
queries into SQL~\cite{li2024dawn,floratou2024nl2sql}.
LLMs truly have the potential to
disrupt our entire field~\cite{llmsdisruptdatamanagement}.


All of this progress in harnessing LLMs for 
data management---for processing both 
unstructured and structured data---is 
valuable. However, our belief is that we 
are still not leveraging the full potential 
of LLMs for data management.
In most data systems
that leverage LLMs for data processing, 
including those proposed in recent 
work~\cite{patel2024lotus,anderson2024designllmpoweredunstructuredanalytics,liu2024declarative},
LLM operations
are treated as a given, 
i.e., as black-box invocations
on monolithic user inputs and data, where,
akin to other types of UDFs, the data system
doesn't attempt to fully understand the
underlying data, user intent, or constituent operations, 
and just does as they are told.
We call such data systems {\em \bf reactive},
in that {\em they passively execute user-specified 
operations, without understanding 
the underlying intent,
the semantics of the operations, 
or the data on which it should be applied}. 
Reactive data systems 
are fundamentally limited in their ability
to accurately and efficiently address
user needs. 
If the LLM operations
as expressed in the user query have low accuracy
or throw an error, reactive data systems
will faithfully pass the burden of low accuracy or
errors back to the user,
without attempting to proactively 
correct for this.
To understand the limitations of reactive database systems, 
consider the following example.

\begin{example}\label{ex:police}\textit{(Police Misconduct)}
     At UC Berkeley, we are co-leading an effort, along with journalists and public defenders, to build a state-wide police misconduct and use-of-force database\footnote{https://bids.berkeley.edu/california-police-records-access-project}. 
     As part of this effort, our collaborators have gathered, through public records requests, millions of documents detailing
     incidents across 700 agencies.
     Each incident can be split across multiple files, and can
     name several officers.
      Each file itself
     can have many sub-documents, including
     officer testimonies, medical examiner reports, 
     eyewitness reports, and internal affairs determinations.
     The officers
     themselves may be part of several incidents.
     Journalists and public defenders are 
     interested in both investigating the behavior of 
     individual officers,
     as well as broader systemic patterns,
     all in an effort to ensure greater accountability. 
     In such a setting, a reactive data system would 
     encounter various difficulties, as follows:
     \begin{itemize}
         \item \textit{(Difficulties with the Data)}.
         Suppose a journalist is interested in understanding
         the medical impacts of use of force. This is typically 
         detailed in the medical examiner report within
         the broader use-of-force document. 
         Simply providing the LLM the entire 
         document as is (often hundreds of pages) 
         can lead to the LLM making errors~\cite{liu2024lost};
         instead, by decomposing the document into specific semantically meaningful portions
         and focusing LLM attention on those portions
         can both improve accuracy and reduce cost. 
         Another alternative is RAG (Retrieval-Augmented Generation) 
         on pages or chunks, but RAG once again doesn't try to proactively identify 
         the meaning of the documents, or chunks, 
         leading to low accuracies. 
         Here, {\em treating unstructured data as a black box 
         monolith}, as in present-day reactive systems,
         is problematic.

         
         \item \textit{(Difficulties with the Operations)}.
         The journalists have identified dozens of fields
         of interest in the incidents, including, but not limited
         to: dates, people mentioned, locations, use of firearms, drug use, use of batons and K9 units, among others. 
         Some fields are dependent on other fields,
         e.g., whether there was disciplinary action is contingent on whether there was an internal affairs
         investigation. 
         Simply specifying all of the fields to be extracted
         as is in a single prompt (as a map operation
         or equivalently, a projection)
         can lead to the LLM making errors
         on some of them;
         instead, by decomposing this operation into smaller 
         ``well-scoped'' operations, we can ensure 
         greater accuracy of LLM outputs. 
         Here, {\em treating the operations as a black box},
         without understanding their semantics,
         as in present-day reactive systems, is
         problematic. 

         
         \item \textit{(Difficulties with the User Intent)}. 
         Suppose a journalist is interested in exploring the documents for mentions of a specific officer, ``John Smith''. 
         While a reactive data system would faithfully return
         mentions of John Smith, if any, it would omit
         mentions of officers where the first name is an initial,
         i.e., ``J. Smith'', as well as mentions where
         the middle initial is present, e.g, ``John M. Smith''.
         One could certainly change the  query by requiring a semantic match 
         instead of an exact match---but the journalist 
         would have no way of knowing that such mentions
         exist in the first place.
         A better approach would be to provide, as feedback
         to the journalist, what the query does not currently cover (but could), 
         so that they can make a more informed choice
         about what it is they are actually after.
         Here, {\em treating the user intent as given}, as
         is done in present-day reactive data systems, is problematic.

\end{itemize}
\end{example}
In all three instances, we find that present-day data systems,
especially those that harness LLMs
to help make sense of unstructured data, 
are reactive:
they treat the data, user query, and operations as black-box
indivisible monoliths.
Instead, we argue that data systems should be {\em proactive}:
rather than treating LLM invocations on data as a given, 
such data systems should {\em posess 
the agency to understand user intent, transformation operations, 
and the underlying data}---and to make decisions
on how to best reconfigure the data, operations, and user
input to suit the analysis need.
In the example above, this may include,
for example, 
uncovering underlying layout or patterns 
in unstructured documents,
decomposing (or fusing) operations into semantically
equivalent but more accurate ones,
or going above and beyond immediate user input
to determine the actual underlying user intent,
in concert with the user. 
We argue for {\em truly harnessing the power of LLMs,
to understand and make sense of 
both structured and unstructured data,
rather than simply treating them as black box unstructured data processors}.
We believe the three axes of understanding (1) user intent, (2) data operations 
and (3) the data 
itself are key to the data systems' 
ability to accurately and efficiently processes structured and unstructured data. 

In the following, we will put forth our
vision for {\em proactive data systems---systems
that more effectively harness LLMs for structured and unstructured data
processing by improving our understanding
of data, intent, and operations.}
While our vision is ambitious and expansive,
our early work has already shown promise:
\begin{itemize}
    \item
Our work has shown how
understanding unstructured document collections better, especially
those that obey similar templates, can pay
rich dividends in both cost and accuracy for
document processing~\cite{lin2025twix,lin2024towards}.
\item
Our work 
has shown how a better understanding of error-prone
LLM-based unstructured data processing operators,
as well as the ability to decompose or rewrite
these operators can lead to data processing
pipelines that are a lot more accurate~\cite{shankar2024docetl,parameswaran2023revisiting}.
\item
Our work has also shown
that tailoring our responses
to the underlying user intent,
especially as part of a dialog with the user, 
rather than just strictly adhering to the user
request as stated,
can be very helpful, as evidenced in tasks
that range from data visualization
to dataset search~\cite{zeighami2024nudge,li2024inferring,hulsebos2024took}.
\end{itemize}
Our experience is grounded in our police
misconduct analysis
application, as well as our other work
in understanding where
and how LLMs go wrong, and how we may
be able to avoid these mistakes~\cite{shankar2024spade,shankar2024validates}.


By moving beyond simply executing user
instructions ``as is''
and treating LLM invocations as a black box,
the effective offline and online
execution space of proactive data
systems is effectively unbounded
and open-ended. 
For example, a user task
for extracting information 
from documents can be decomposed
in a potentially unbounded number of 
different ways, with different
accuracies.
Simply leveraging an LLM to, in turn,
do this query planning and optimization for us
can lead to suboptimal results.
Instead, in this vision paper,
we discuss various recipes for
proactive systems to
help make sense of
each of our three axes of data, intent, and operations,
such as performing decompositions 
and rewrites to improve accuracy when performing a given operation, 
finding structure in unstructured data 
to better understand the data 
and answer queries on it, 
and by adjusting data and 
query representations based 
on user feedback to better 
align with user intent.  
We discuss future directions 
along each axis to build better proactive database systems. 





\if 0


\newpage

Use-cases:
- police records: llm needs to organize data, needs to interact with user to decide how, what are relevant features, differ some decisions to user (e.g., check decide how to check if two police officers with the same name are the same person). 
- NL queries: intent discovery, when there needs to be multi hop interactions with user. Bring up TableQA, what if a user specifies a wrong predicate, returning information not strictly asked by the user but may be what the user is asking for


\textit{A post-relational data model is a data model based on the principle that the relational data model is no longer sufficient or necessary to represent the real-world.}

\begin{itemize}
    \item Lots of text/video data, people want to process/query text/videos
    \item Even with relational data people want to query with NL. Database might be getting queried without clear/specific intent. Dataset search
    \item Overall, both data and/or query can be fuzzy and lack structure
    \item Police records example
\end{itemize}

\begin{itemize}
    \item  Relational DBMSs are not well-suited to handle the above
    \item They rely on mathematical abstractions to provide a declarative interface defined based on the data
    \item This leaves the burden of translation of real-world information needs outside of the dbms
    \begin{itemize}
        \item E.g., NL to SQL, or structured information extraction before interacting with the database
    \end{itemize}
    \item To be more accurate and efficient dmbs should be responsible for answering such queries, without necessarily relying on relational data model
\end{itemize}


\begin{itemize}
    \item We believe the above observation necessitates a rethinking of what abstractions and interfaces a dbms needs to provide, and how that affects the internals of a dmbs.
    \item Criticism of the relational model that it does not capture real-world semantics existed in the 70s when it was proposed. Methods such as ER diagrams and entity relationship models were proposed to bridge such a gap. In recent years, the lack of real-world semantics has become even more apparent as AI is used to perform the human-level tasks. e.g., NL2SQL methods have to rely on meta-data (data catalogs and column descriptions) and external knowledge to formulate queries correctly, and poor integratiions with a dmbs can lead to suboptimal results.  
    \item  However, many recent work accept the relational model, but replace specific tasks that is designated to humans within this model, e.g., NL2SQL or automated schema extraction. 
    \item Instead, we consider relational model as a specific point in data management design space, and question its design choices, given that assumptions that existed when it was proposed  (i.e., the ability/intelligence of a machiine) are no longer true
\end{itemize}
    



\begin{itemize}
\item Specifically we argue that dmbs should natively support both unstructured and structured queries on unstructured and structured data, leading to a decoupling of interface provided by the system vs internal data representations and definitions. 
\item We discuss how this change in the abstraction in a dbms can change the interface and internal design choices, in terms of internal data/query representation and planing
\item Overall, prior visions depict the LLM as a tool that can help us translate new data into the relational model, but we believe scope of dmbs should be expanded in the presence of LLMs as opposed to fit new data/query sources into existing relational framework
\end{itemize}

\fi