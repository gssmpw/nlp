%!TEX root=../main.tex

%\subsection{Extracting Document Structures}
\section{Proactive Data Understanding}\label{sec:data}
Proactive data systems take initiative to truly
understand the data, rather than simply treating
it as inputs to opaque UDF (here LLM) calls.
It can leverage
the provided data descriptions,
as well as actual content,
to create representations
that are useful for downstream data
processing tasks.
The system can understand 
each document on its own (Section~\ref{subsec:structure}), 
understand relationships between documents
or portions thereof (Section~\ref{subsec:cross-doc}), 
or preprocess documents based on anticipated future tasks (Section~\ref{subsec:taskaware}).


\subsection{Identifying Semantic Structure 
within a Document}
\label{subsec:structure}

%Unlike tables in relational databases, where schema and rows are well-defined, real-world unstructured documents present significant challenges for analytics due to the free-form nature of natural language and complex visual formatting. 

Although documents may appear unstructured, 
they often are semantically structured.
This structure may
be implicit in the text, e.g.,
content in adjoining portions of the text is often related. 
They can also be explicit, e.g., 
tables or figures embedded within a PDF document. 
We discuss how to identify,
extract, and leverage hidden structure 
from unstructured documents. 

\begin{figure}[tb]
    \centering
    \vspace{-20pt}
    \includegraphics[width=0.7\linewidth]{figures/semantic_structure.pdf}
    \vspace{-10pt}
    \caption{Semantic Hierarchy in a Civic Agenda Document (a) the Document itself (b) the Corresponding
    ``Table of Contents'' (c) the Corresponding Semantic Hierarchy.
    }
    \label{fig:civic}
    \vspace{-10pt}
\end{figure}

\topic{Leveraging implicit hierarchical structure} 
Portions of documents are often semantically related. 
A section or subsection within a document often
contains information that is semantically related,
while other parts are less related or unrelated. 
For example, the medical examiner report within
a broader police record PDF contains
most of the medically relevant information
about an incident, while the eyewitness report
contains most of the relevant information from eyewitnesses.
Identifying these subdivisions within a document
and routing a query to the subdivision at the
``right'' granularity can lead to higher accuracy
than both RAG or providing the entire document to an LLM~\cite{lin2024towards}.
This structure is best represented
as a semantic hierarchy.
There are various ways to construct
such a hierarchy,
including leveraging formatting information
that distinguishes headers from other portions, 
or using an LLM to identify which phrases
may be headers as we do in ZenDB~\cite{lin2024towards}---see 
Figure~\ref{fig:civic} for an example.
Another approach is to construct this semantic hierarchy on
content alone, where summaries of related chunks are merged
and recursively summarized~\cite{sarthi2024raptor}.  
Nonetheless, building semantic structures 
that are useful for downstream tasks remains a challenge, 
as different views of the document may be useful for different tasks,
 where even simple information such as location can have different connotations. 
 For instance, when organizing police activities in a specific case based on location 
 they occurred in, a user might be interested in geographical location 
 of activities (i.e., at a specific address) 
 while another user might be interested in types of locations (e.g., if the police activity was outdoor or inside). 
 The system needs to consider various possible semantics of the data when identifying the semantic structure. 

\topic{Leveraging explicit structure} 
Unstructured documents often contain structured
portions, such as embedded
tables and key-value pairs.
Treating them as plain text for data processing is ineffective
and error-prone.
For example, if we're not careful in preserving visual information, 
a missing value in a key-value pair
could lead to the next key being misinterpreted
as the corresponding value.
Moreover, depending on the approach used
to query such tables,
we may lose visual information (used to show table structure and group columns and rows),
and be unable to effectively process
numerical information. 
A proactive data system
therefore will identify and extract such structured portions
and represent them in a structured format, for example, as tabular data or key-value pairs in Figure~\ref{fig:force},
while preserving their context within the document (e.g., their location and semantic relationships to the rest of the document).
Our recent tool, TWIX~\cite{lin2025twix}, proposes an efficient approach 
for automatically extracting structured portions from documents, using a combination of visual
and LLM-based inference, while preserving this context for the extracted
information. 
However, many challenges remain, such as accurately representing the semantic 
relationship between structured and unstructured document portions, 
e.g., to understand which queries should be answered 
based on the structured and unstructured portions,
and how much background context is necessary to make sense of the structured portions.






\subsection{Identifying Cross-Document Relationships}\label{subsec:cross-doc}
There are multiple reasons
to perform cross-document organization.

\topic{Identifying documents that may be queried together}
Beyond understanding structure within a single document, 
it is important to understand relationships across documents,
since these related documents may often be queried together. 
In Example~\ref{ex:police}, the dataset, a single incident
can span several PDF documents, often without such information being linked to each other. 
The data system needs to proactively identify relationships 
between such documents to organize the data prior to querying. 
This, for instance, can be done by clustering the documents. 
However, clustering is challenging, since the system needs to understand
the documents to be able to cluster them properly.
Simply embedding the documents, and clustering the embeddings 
does not work since the documents can vary considerably in length.
Another approach is to leverage LLMs to check if two documents
correspond to the same incident, but this is expensive,
especially when there are $O(n^2)$ comparisons.
We may be able to leverage LLMs to identify cheaper proxies
or blocking rules (e.g., two documents
may not be related unless the date ranges overlap)
for this organization. 
In some settings, folder organization provides cues for identifying
cross-document relationships (e.g., documents that are very ``far apart''
from a folder structure standpoint may be unlikely to be related).



\begin{figure}[t]
    \centering
    \vspace{-20pt}
    \includegraphics[width=0.7\linewidth]{figures/structured_view.pdf}
    \vspace{-10pt}
    \caption{Tables and Key-Value Pairs in Use of Force Records. 
    }
    \vspace{-10pt}

    \label{fig:force}
\end{figure}

\topic{Identifying shared templates across documents}
A separate concern is to combine semantic hierarchy construction
with cross-document relationships, so that we are able
to identify shared ``templates'' across documents.
These templates can both help scale up extraction across
documents, but also help identify documents whose structure
differs considerably.
For example, journalists may want to identify incidents
where there is an internal affairs report within
a broader police record document,
since these are ones where there is a corresponding
disciplinary action. 

\subsection{Task-Aware Data Pre-Processing}\label{subsec:taskaware}
The system can attempt to proactively find and organize portions
of the data that will be useful to improve performance on a reasonable subset of data processing tasks downstream. 
Given that document collections 
can span in the millions, 
it can be expensive to do extensive processing of the data upfront, for instance,
by populating a materialized view with all the attributes a user can ever hope to query;
it can also be  time-consuming to leave all the data processing to when the user issues a task. 
As such the system needs to decide how much preprocessing is beneficial upfront, and what to perform at query time. 
To strike a balance between the two extremes, 
one option is for the system to identify and/or extract data units 
that it deems to be useful in the future for a wide variety of queries. 
This can be done by understanding the semantics of the data. 
For instance, in Example~\ref{ex:police}, the system can decide that sections 
that describe police incidents at a high level (e.g., the internal affairs report)
are typically useful for future task processing as they provide a comprehensive summary of most
relevant aspects. 
The system can keep pointers to such sections as lightweight indexes, 
but leave more specific data processing to when the user issues queries. 
Similarly, the system can do schema identification in advance 
to find what type of data is represented in the documents, 
and use the identified schema to answer queries. 
The system can decide whether to extract information 
upfront to populate the schema, 
or keep pointers to where the information 
can be found at query time. 
For instance, the system may choose to retain pointers
to all portions that mention police officers in the document
so as to accelerate analysis of those aspects downstream,
without going all the way to populating a materialized
view with officer attributes (since these can vary 
depending on user need).



% %,  semantic hierarchy present in the documents in the . Documents often contain hidden structures that can be leveraged for more effective data analytics. 

% \if 0
% Many documents within collections are created using templates, which are common across various domains, including civic agenda reports, scientific papers, employee job descriptions, and notices of violations. Such a template provides semantic hierarchy, which can be modeled as a tree~\cite{lin2024towards}, where each node represents a text portion (e.g., a section or subsection), and edges denote inclusion relationships (e.g., Section 2.1 is a subsection of Section 2).  

% The font features (e.g., font name and size) are often consistently identified within the same semantic hierarchies (e.g., header names share the same font features).  We can maintain summaries of node text spans along with hierarchical inclusions (e.g., ancestor nodes of the current node) to provide a more structured and logical data representation for analytics, akin to a table of contents. Query processing using this semantic structure resembles how users navigate a table of contents to locate relevant sections for their questions.  

% In the police misconduct example, suppose a journalist wants to determine the dates of misconduct records where force was used. The documents are structured with different types of misconduct as section headers (e.g., Corruption or Excessive Force), followed by detailed case descriptions in each section.  

% A semantic hierarchy helps locate cases under ``Excessive Force'' without relying on heuristic physical chunking to identify relevant text portions.  ~\cite{lin2024towards} presents an efficient method for uncovering and constructing semantic hierarchies across documents, demonstrating that it improves query accuracy while maintaining low cost and latency.  
% \fi



% %Given a query task, a proactive database system should analyze, decompose, abstract, or reformulate complex data to better suit downstream analytics, rather than treating the entire data object, such as a document, as a single unit. Taking unstructured documents as example,  Below, we present several use cases involving documents that range from highly structured to completely unstructured, with loosely structured cases in between. We also introduce several ideas for processing complex data based on their hidden structures.  

% %Below, we present two use cases to illustrate the structures within documents and their importance in improving downstream query analytics.  





% %Analyzing an entire complex document is not an effective approach. A proactive system should decompose complex data to extract the most relevant information for answering downstream queries. However, achieving this in a principled manner remains a challenging task. We first introduce a type of document with semantic structures that can be leveraged to break down complex documents into semantic portions of varying granularity. We demonstrate that this approach effectively supports complex queries on such documents.  




% % \noindent{\em \bf Use case 1: Civic Project Agenda Report Analysis.} Journalists at Big Local News at Stanford have collected large volumes of civic meeting agenda PDF reports from various U.S. counties, as shown in Figure~\ref{fig:civic}-a, and seek to analyze these reports.  One such query could be to count the number of construction projects of a certain type, across meetings, e.g., ``What is the number of Capital Improvement projects that started after 2022?''. 

% % To achieve this, one could use Large Language Models (LLMs). However, even advanced LLMs like GPT-4 struggle with queries on such reports, especially when involving aggregations and multiple filters over long documents. This limitation is expected, as LLMs are not well-suited for handling large contexts or complex data processing tasks. 
% % Another strategy, Retrieval-Augmented Generation (RAG), segments documents upfront at a certain granularity and then, during querying, identifies $k$ segments most relevant to the query (e.g., via embedding distance), incorporating only these segments into prompts to reduce cost.  
% % However, RAG struggles to identify the appropriate segments, even for simple queries. Suppose we want to identify capital improvement projects. RAG retrieves segments that most closely match ``capital improvement projects'' within the document, such as the red box in Figure~\ref{fig:civic}-a, but fails to capture over 20 additional projects on subsequent pages, such as the ``PCH Median Improvement Project'' (B2 in Figure~\ref{fig:civic}-b), which belongs to ``Capital Improvement Projects'' (A1).  
% % Overall, both the vanilla LLM approach and RAG are unsuitable: they have low accuracy, while the LLM approach additionally incurs high costs.  
 

% % \noindent{\bf Semantic Structure Helps. } 
% % The reason RAG did not perform well above is that the text segments provided to the LLM did not leverage the semantic structure underlying the document. Instead, if we are aware of this structure, we can identify the capital improvement projects (A1 in Figure~\ref{fig:civic}-b) by checking all its subportions (e.g., B1, B2), where each corresponds to a project description, and provide this information to the LLM for interpretation.  
% % By doing so, we {\em provide all pertinent information to the LLM, unlike RAG, while avoiding overwhelming it with excessive context}.  A semantic hierarchical structure provides a logical and principled way to decompose a complex document into smaller text portions of varying granularity. It offers valuable properties for retrieving relevant information for queries. For example, a child node (e.g., B1) in such a tree naturally inherits the properties of its ancestor node (e.g., B1 is a Capital Improvement Project because it is a child of A1). Query processing using this semantic structure resembles how users navigate a table of contents to locate relevant sections for their questions.  

% %To effectively construct such a structure for documents, a key observation is that while unstructured documents vary considerably in format, many documents within collections are created using templates, known as \textit{templatized documents}~\cite{lin2024towards}.   Templatized documents are common across various domains, including civic agenda reports, scientific papers, employee job descriptions, and notices of violations.  ~\cite{lin2024towards} presents an efficient method for constructing semantic hierarchical structures across documents and demonstrates that leveraging such structures can achieve up to 31$\times$ cost savings compared to LLM-based baselines while maintaining or improving accuracy. Additionally, it outperforms RAG-based baselines by up to 61\% in precision and 80\% in recall, with only a marginally higher cost.  

% %This use case demonstrates that by effectively analyzing the underlying semantic structures in a document, it becomes possible to break it down into smaller portions, reducing costs and improving accuracy for LLMs in downstream tasks.  

% \subsection{Identifying Cross-Document Relationships}\label{subsec:cross-doc}
% Beyond understanding information within a single document, it is important to understand the relationship across documents. In Example~\ref{ex:police}, the dataset, even considering a single incident, consists of various documents such as testimonials, police reports, medical reports, etc, often without such information being linked to each other. The data system needs to proactively identify relationships between the documents to be able to organize the data. This, for instance, can be done by clustering the documents. Clustering such complex documents is challenging since the system needs to understand the documents. For example, to check if two police reports refer to the same case, the system needs to understand the events described in two documents to see if they correspond to the same case.  To do so, the system may need to understand what type of information can be used to relate two documents and how to find them. Beyond accuracy considerations, the system also needs to be cost-aware. Performing $O(n^2)$ LLM operation to understand the relationship between $n$ documents can be prohibitively expensive and the system needs to design methods to be able to achieve the same results cheaply, e.g., by using cheaper heuristics such as pre-extracting relevant information or using data embeddings to filter out non-related documents.  

% \subsection{Task-Aware Data Processing}\label{subsec:taskaware}
% The system can attempt to proactively find parts of the data that will be useful to improve processing tasks down the road. Given that the data sets can contain millions of documents, it can be expensive to do extensive processing of the data upfront, or time-consuming to leave all the data processing when the user issues a task. As such the system needs to decide how much preprocessing it needs to upfront, and what to perform at query time. To strike a balance between the two extremes, the system can decide to identify and/or extract data units that it deems to be useful in the future. This can be done by understanding the semantics of the data. For instance, in Example~\ref{ex:police}, the system can decide that sections that describe police incidents at a high level (e.g., in a police officer's report) are useful for future task processing, given that journalists will likely need to understand incidents to be able to write articles about the police misconduct in them. The system can keep pointers to such sections, but leave more specific data processing after user issues queries. Similarly, the system can do schema identification in advance to find what type of data is represented in the text, and use the identified schema to answer queries. The system can decide whether to extract information upfront to populate the schema, or simply keep pointers to where the information can be find and do extraction at query time. 

% %\textbf{Task-aware Preprocessing}
% %\textbf{Schema Identification}



% %\subsection{Extracting Existing Structures}


% %The context and content of structured portions help guide user queries to identify the most relevant information in the document, while their structured representation ensures high accuracy.  For example, many police use-of-force records are presented in tables within documents, while metadata, such as case dates and involved police names, are often represented as key-value pairs.  A proactive database system should adapt document structures to match the granularity required by user queries and, if necessary, reformulate the data representation to improve execution accuracy.  



 


% %\subsection{Automating Indexing for Multi-Modal Structures}
% \if 0
% \subsection{Mixing Data Representations}
% \sep{I don't think, we need this section. Here's things we might want to say but I don't think they are particularly interesting. I'm leaving this as is but can com back to it if we want to add things}
% \begin{itemize}
%     \item Embedding based indexes
%     \item Generating summaries
%     \item Other data transformations, e.g., take table and add a new column using LLM
% \end{itemize}

% The same document may exhibit different structures. Beyond documents, other data modalities in the unstructured world may also follow certain structures. Selecting the right structure or a combination of multiple structures to represent data for answering downstream queries is challenging. For example, suppose a journalist wants to find the dates of police misconduct records involving the use of force in a specific city. The documents are structured with different types of misconduct as section headers (e.g., ``Corruption'' or ``Excessive Force''), followed by detailed case descriptions presented as tables within each section. One can first use the semantic hierarchy as an index to locate the ``Excessive Force'' section and then reformulate the data by extracting tabular information for each case within this section to identify the dates of incidents in the specified city.  This requires a proactive database system to automatically analyze the available structures in the document collection, determine the optimal structure as an index, and sequence it appropriately to locate the most relevant text portions while representing the data in the most suitable way for answering downstream queries.  


% \fi





% %\yiming{TODO}











% %ZenDB stuff, maybe twix?

% % \subsubsection{Data Decomposition} 
% % \label{subsec:decomposition}
% %Docetl stuff?


% % \subsection{Challenges and Future Directions}


% % \noindent{\bf Data Analytics in a Mix-Structure and No-Structure World. }
% % Beyond the two document structures presented in Section~\ref{subsec:structure}—semantic hierarchical structures and visual form-like structures—real-world datasets can be much more diverse, featuring a mix of structures or, in some cases, no discernible structure at all. For a proactive database system, analyzing and predicting meaningful properties within documents to enhance downstream query analytics in diverse real-world scenarios remains a significant challenge. While data decomposition techniques discussed in Section~\ref{subsec:decomposition} offer a complementary way to refine relevant data for queries, providing a logical and principled interpretation to the data to achieve highly accurate query results with low cost and latency remains an open problem. A proactive database system should enable agents to analyze underlying document structures, if present, based on query intent and document type, to identify the optimal data representations that best fit the data and query workload. 





% %\noindent{Data Analytics Across Diverse Documents.}


% % \noindent{\bf Data Analytics in a Multi-Modal World. }
% % So far, our analysis has focused on documents. However, the unstructured world extends beyond text to include other data modalities such as video, audio, and images. The relationships between different pieces of information can span multiple modalities, making it challenging to define the right data models for supporting queries across them. As demonstrated earlier, it is unclear whether the relational model remains universally dominant, and the answer may well be negative.  


