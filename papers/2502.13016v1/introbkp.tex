\section{Introduction}





Large volumes of real-world data is unstructured, and data systems have long been working towards providing capabilities for the users to store, processes and access unstructured data, through various systems such as data lakes, document stores, semi-structured databases, etc. With the significant improvement of AI models and particularly LLMs in performing natural language tasks, many data systems have incorporated LLMs to perform data processing tasks on unstructured data. Such tasks include automated information extraction from unstructured data, better data integration, other data transformations such as generating summaries and data enrichment, and better search over such datasets. Data system interfaces furthermore allow users to interact with the system through natural language, even if the data itself is structured.

However, many applications of LLMs in such systems consider LLM operations as given, where LLMs perform black-box operations as specified by user input on data monolithic, where, similar to any other UDF, the data system neither understands the data or the task, but performs them as it's told. We call such data systems \textit{reactive}: the database system is given the reactionary role of executing user operations, without understanding the user intent, the specified operation or the data where it should be applied. We believe reactive data systems are inherently flawed, limiting the ability of the system to accurately and efficiently answer user questions. To understand the limitations of reactive database systems, consider the following example. 

\begin{example}\textit{(Police Misconduct)}
     Consider a dataset of police files containing reports about police investigations into an incident. To ensure police accountability, a journalist may be interested in finding cases where the police were accused of misconduct. To accurately satisfy the journalists needs, the system needs to be able to:
     \begin{itemize}
         \item \textit{(Understand the Task)}. The query of ``find me instances of police misconduct'' is difficult to process accurately since misconduct is never directly stated in police records. The system needs to understand and decompose the task, e.g., into ``was there use of force in a police incident'' and ``was the use of force justified''.
         \item \textit{(Understand the Data)}.  The system needs to understand the data to identify what portions can be relevant. There can be repeating patterns that can be exploited, e.g., instances of misconduct may be found in specific sections of documents. Finding relevant portions of the document can be both improve accuracy and reduce cost 
         \item \textit{(Understand the Intent)}. The system needs to adjust to user intent through feedback. Misconduct can have different meanings, and the journalist may be interested in specific types, e.g., racial biases. The system needs to interact with the user and refine data processing to match the intent. 
     \end{itemize}
\end{example}
\if 0
\begin{example}\textit{(Understanding the Task)}
     Consider a dataset of legal contracts
\end{example}

\begin{example}\textit{(Understanding the Data)}
     understanding data
\end{example}

\begin{example}
     \textit{(Understanding Intent)}. On either a structured or unstructured data source stating containing names of people, consider the simple query of a user asking for records of ``Adam Smiht'', where ``Smiht'' is a misspelling of ``Smith''. The system needs to understand user intent (which name they are asking for). This may need to be done with respect to data (e.g., if neither ``Smith'' or `'Smiht'' exist, the answer is the same for both queries). The system cannot ensure correctness by always correcting what it perceives as typos, there may be deviations from common name spelling that are not typos. 
\end{example}
\fi

We argue that the database systems need to be proactive. They need to be given agency to understand user intent, data operations, and the dataset, and to make decisions on how to processes the user-provided operations. In the police misconduct example, this means breaking down the task, finding patterns in the data and interacting with user to find their intent. Such operations are now possible by using LLMs as tools to understand users, data and data transformations better, both on structured data or unstructured data. We believe the three axes of understanding (1) user intent, (2) data operations and (3) the data 
itself are the key to the data systems' ability to accurately and efficiently processes structure and unstructured data. 

\sep{will come back to this paragraph after the rest of the paper}The design space of proactive database systems is huge since our problem formulations are open-ended. For example, a task may be decomposed in many different ways and simply using an LLM as an agent to make all decision leads to inaccurate results. Taking inspiration from our prior work, we discuss various solutions on how proactive data systems can make progress in the three abovementioned axes. For each axis, we discuss various knobs at our disposal, such as performing decompositions and rewrites to improve accuracy when performing a task, finding structure in unstrcutred data to better understand the data and answer queries on it, and by adjusting data and query representations based on user feedback to better align the system with user intents.  We discuss future directions along each axis to build better proactive database systems. 





\if 0


\newpage

Use-cases:
- police records: llm needs to organize data, needs to interact with user to decide how, what are relevant features, differ some decisions to user (e.g., check decide how to check if two police officers with the same name are the same person). 
- NL queries: intent discovery, when there needs to be multi hop interactions with user. Bring up TableQA, what if a user specifies a wrong predicate, returning information not strictly asked by the user but may be what the user is asking for


\textit{A post-relational data model is a data model based on the principle that the relational data model is no longer sufficient or necessary to represent the real-world.}

\begin{itemize}
    \item Lots of text/video data, people want to process/query text/videos
    \item Even with relational data people want to query with NL. Database might be getting queried without clear/specific intent. Dataset search
    \item Overall, both data and/or query can be fuzzy and lack structure
    \item Police records example
\end{itemize}

\begin{itemize}
    \item  Relational DBMSs are not well-suited to handle the above
    \item They rely on mathematical abstractions to provide a declarative interface defined based on the data
    \item This leaves the burden of translation of real-world information needs outside of the dbms
    \begin{itemize}
        \item E.g., NL to SQL, or structured information extraction before interacting with the database
    \end{itemize}
    \item To be more accurate and efficient dmbs should be responsible for answering such queries, without necessarily relying on relational data model
\end{itemize}


\begin{itemize}
    \item We believe the above observation necessitates a rethinking of what abstractions and interfaces a dbms needs to provide, and how that affects the internals of a dmbs.
    \item Criticism of the relational model that it does not capture real-world semantics existed in the 70s when it was proposed. Methods such as ER diagrams and entity relationship models were proposed to bridge such a gap. In recent years, the lack of real-world semantics has become even more apparent as AI is used to perform the human-level tasks. e.g., NL2SQL methods have to rely on meta-data (data catalogs and column descriptions) and external knowledge to formulate queries correctly, and poor integratiions with a dmbs can lead to suboptimal results.  
    \item  However, many recent work accept the relational model, but replace specific tasks that is designated to humans within this model, e.g., NL2SQL or automated schema extraction. 
    \item Instead, we consider relational model as a specific point in data management design space, and question its design choices, given that assumptions that existed when it was proposed  (i.e., the ability/intelligence of a machiine) are no longer true
\end{itemize}
    



\begin{itemize}
\item Specifically we argue that dmbs should natively support both unstructured and structured queries on unstructured and structured data, leading to a decoupling of interface provided by the system vs internal data representations and definitions. 
\item We discuss how this change in the abstraction in a dbms can change the interface and internal design choices, in terms of internal data/query representation and planing
\item Overall, prior visions depict the LLM as a tool that can help us translate new data into the relational model, but we believe scope of dmbs should be expanded in the presence of LLMs as opposed to fit new data/query sources into existing relational framework
\end{itemize}

\fi