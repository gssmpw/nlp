%%%%%%%%%%
\section{Additional Drawbacks of DPO under Heterogeneity}
\label{sec:drawbacks_appendix}

%%%
\paragraph{Violating Independence of Irrelevant Alternatives (IIA).}
Suppose $\gU = \{A, B\}$ and types are equally represented. Given two possible responses~$\vy_1$ and~$\vy_2$, type~$A$ prefers~$\vy_1$ but type~$B$ prefers~$\vy_2$:
%
\begin{align*}
    &r^*(\vy_1; A) = 6,\, r^*(\vy_2; A) = 1 \,, \\
    &r^*(\vy_1; B) = 3,\, r^*(\vy_2; B) = 9 \,.
\end{align*}
%
A direct calculation shows $\E_u[r^*(\vy_2)] > \E_u[r^*(\vy_1)]$ and $\nbc(\vy_2) > \nbc(\vy_1)$. So, both $\pi^*$ and~$\pi_\dpo$ prefer~$\vy_2$. Let's consider another possible response~$\vy_3$ which is not the preferred response for any user type:
%
\begin{equation*}
    r^*(\vy_3; A) = r^*(\vy_3; B) = 2 
    \,.
\end{equation*}
%
While $\pi^*$~still prefers~$\vy_2$ to~$\vy_1$, now $\nbc(\vy_1) \approx 0.62 > \nbc(\vy_2) \approx 0.55$, so, introducing an irrelevant alternative can alter DPO's ranking over existing alternatives.
%%%


%%%
\paragraph{Tyranny of Majority.}
Suppose $\gU = \{A, B\}$ with type~$A$ shaping~$90\%$ of the population. Given two responses~$\vy_1, \vy_2$, type~$A$ slightly favors~$\vy_2$ but type~$B$ finds~$\vy_2$ offensive:
%
\begin{align*}
    &r^*(\vy_1; A) = 0.5,\, r^*(\vy_2; A) = 1 \,, \\
    &r^*(\vy_1; B) = 0.5,\, r^*(\vy_2; B) = -10 \,.
\end{align*}
%
In this case, $\pi^*$ prefers~$\vy_1$ even though type~$B$ is a minority. In contrast, we have $\nbc(\vy_1) \approx 0.47, \nbc(\vy_2) \approx 0.53$, which implies that the majority dominates in DPO.
%%%

%%%%%%%%%%


%%%%%%%%%%
%\ifnotarxiv
\input{sections/appendix_related}
%\fi
%%%%%%%%%%


%%%%%%%%%%
\section{Additional Statements}

%%%
\begin{theoremEnd}[restate]{proposition}
\label{prop:mixture_bt}
There exists a mixture of BTs that a single BT cannot represent.
\end{theoremEnd}
%%%
\begin{proofEnd}
    Suppose the pairwise comparison distribution over a set of alternatives \((\vy_1, \vy_2, \vy_3, \dots)\)  satisfies the Bradley-Terry (BT) model; i.e. \(\Pr(\vy_i \succ \vy_j) = \sigma\big(r^*(\vy_2) - r^*(\vy_1)\big)\). Then:
    \begin{align*}
    \Pr(\vy_1 \succ \vy_2)\Pr(\vy_2 \succ \vy_3)\Pr(\vy_3 \succ \vy_1) &= \frac{\prod_{i=1}^3 \exp(r^*(\vy_i))}{\prod_{i=1}^3 \left(\exp(r^*(\vy_i)) + \exp( r^*(\vy_{(i+1)\bmod 3 + 1}))\right)}\\
    &= \Pr(\vy_1 \succ \vy_3)\Pr(\vy_3 \succ \vy_2)\Pr(\vy_2 \succ \vy_1)
    \,.
    \end{align*}
    Now, consider two BT models corresponding to \(u_1\) and \(u_2\), with a uniform mixture over them. For the mixture:
    \[
    \Pr(\vy_i \succ \vy_j) = \frac{\Pr(\vy_i \succ \vy_j \mid u_1) + \Pr(\vy_i \succ \vy_j \mid u_2)}{2}
    \,.
    \]
    The probability of cyclic preferences in one direction is given by
    \[
    \Pr(\vy_1 \succ \vy_2)\Pr(\vy_2 \succ \vy_3)\Pr(\vy_3 \succ \vy_1) = \frac{\sum_{s \in \{1, 2\}^3} \prod_{i=1}^3 \Pr(\vy_i \succ \vy_{(i+1)\bmod 3 + 1} \mid u_{s_i})}{8}
    \,,
    \]
    which is not necessarily equal to the probability of the cyclic preferences in the reverse direction:
    \[
    \Pr(\vy_1 \succ \vy_3)\Pr(\vy_3 \succ \vy_2)\Pr(\vy_2 \succ \vy_1) = \frac{\sum_{s \in \{1, 2\}^3} \prod_{i=1}^3 \Pr(\vy_{(i+1)\bmod 3 + 1} \succ \vy_i \mid u_{s_i})}{8}
    \,.
    \]
    To verify this, consider specific examples such as \(\Pr(\vy_i \succ \vy_j \mid u_k) = \frac{\exp(r^i_k)}{\exp(r^i_k) + \exp(r^j_k)}\) with \(r_1 = (1, 2, 3)\) and \(r_2 = (1, 2, 4)\).
    %, or run the provided code to test arbitrary mixtures. 
    More generally, the BT assumption implies that, for a fixed reward \(r^*\), the likelihood of a set of pairwise comparisons \(\{(\vy_{p, 1} > \vy_{p, 2})\}_{p \in [P]}\) is proportional to \(\prod_i \exp(r^*(\vy_i))^{|\{p \in [P] \,\mid\, \vy_{p, 1} = i\}|}\) and depends only on the number of times each option is preferred in the comparisons. However, as demonstrated above, this property does not hold for a mixture of BT models.
\end{proofEnd}
%%% 

%%%
\begin{definition}[Learnability]
\label{def:learnability}
Denote by~$\gD_{r, \sigma}$ an i.i.d. sampled pairwise preference dataset labeled by random users with reward~$r$ and preference model~$\sigma$. Let $\barr(\vy) \coloneqq \E_u[r(\vy; u)]$. We say that the ranking based on~$\barr$ is (weakly) learnable if, for some~$\epsilon > 0$, there exists an algorithm with a bounded sample complexity~$m$, such that for every reward~$r$, when given a dataset~$\gD_{r,\sigma}$ of size $|\gD_{r,\sigma}| \ge m(\epsilon, \barr)$, it outputs a ranking consistent with~$\barr$ with a probability at least $\epsilon$ above the chance level.
\end{definition}
%%%

%%%
\begin{theoremEnd}[restate]{proposition}
\label{prop:consistent_loss_2}
Defining~$l$ in \cref{eq:decompose_L} as follows results in a consistent estimation of the optimal policy when preferences follow the BT model:
%
\begin{equation*}
    l(\vy_1, \vy_2, \vo; \pi) = \begin{cases}
        -\sigma\big(h(\vy_1, \vy_2; \pi)\big) - I\big(\sigma\big(h(\vy_1, \vy_2; \pi)\big)\big) \,, & \vo = \vone \,, \\
        -\sigma\big(h(\vy_2, \vy_1; \pi)\big) - I\big(\sigma\big(h(\vy_2, \vy_1; \pi)\big)\big) \,, & \vo = \vzero \,, \\
        0 & \text{o.w.}
    \end{cases}
\end{equation*}
%
Here, we define $I(\theta) \coloneqq \int_1^\theta \big(\frac{1}{\theta'} - 1\big)^{|\gU|} \dif \theta'$, and $h$ is the difference of $\pi$'s induced rewards (\cref{eq:def_h}).
\end{theoremEnd}
%%%
\begin{proofEnd}
    Recall $\Pr(o_u = 1 \mid \vx, \vy_1, \vy_2) = \sigma\big(\Delta r^*(\vx, \vy_1, \vy_2; u)\big)$. We use $z_u(\vx, \vy_1, \vy_2)$ as a shorthand for this quantity and will drop the dependence on~$(\vx, \vy_1, \vy_2)$ whenever it is clear from the context. We also use~$s$ as a shorthand for~$\sigma(h)$.
    In the limit of a very large dataset, the proposed loss approaches
    %
    \begin{equation*}
        \gL(s) = -\E_{\vx, \vy_1, \vy_2} \Big[
        \big(\prod_{u \in \gU} z_u \big) \big(s + I(s)\big)
        + \big(\prod_{u \in \gU} (1 - z_u) \big) \big(1-s + I(1-s)\big)
        \Big] 
        \,.
    \end{equation*}
    %
    Note that we wrote~$\gL$ as a function of~$s$ instead of~$\pi$ since $s$~is the only place that~$\pi$ appears. We first show that $\gL(s)$ has a unique global minimizer. To show an~$s$ is a global minimizer of~$\gL$, it suffices to show that $s$~minimizes the term inside expectation for every~$(\vx, \vy_1, \vy_2)$. Such a minimizer meets the first-order condition: 
    %
    \begin{equation*}
        \big(\prod_{u \in \gU} z_u \big)\Big(1 + (\frac{1}{s} - 1)^{|\gU|} \Big) 
        + \big(\prod_{u \in \gU} (1 - z_u) \big)\Big(-1 - (\frac{1}{1 - s} - 1)^{|\gU|} \Big) 
        = 0
        \,.
    \end{equation*}
    %
    Here, we used $\od{I}{\theta} = (\frac{1}{\theta} - 1)^{|\gU|}$. Define $w \coloneqq (\frac{1 - s}{s})^{|\gU|}$. Then, the above condition reduces to a quadratic equation in terms of~$w$:
    %
    \begin{equation*}
        1 + w - \big(\prod_{u \in \gU} (\frac{1}{z_u} - 1) \big) (1 + w^{-1}) = (1 + w^{-1})\Big[w - \prod_{u \in \gU} (\frac{1}{z_u} - 1) \Big] = 0
        \,.
    \end{equation*}
    %
    Solving for~$w$, we obtain
    %
    \begin{equation*}
        s^* = \frac{1}{1 + \big(\prod_{u \in \gU} (\frac{1}{z_u} - 1) \big)^{\frac{1}{|\gU|}}}
        \,.
    \end{equation*}
    %
    For the BT model, a direct calculation then shows
    %
    \begin{equation}
    \label{eq:_proof_s_star}
        s^*(\vx, \vy_1, \vy_2) = \sigma\Big(\frac{1}{|\gU|}\sum_{u \in \gU}\Delta r(\vx, \vy_1, \vy_2; u)\Big)
        \,.
    \end{equation}
    %
    In fact, $s^*$ is the only global minimizer of~$\gL(s)$. This is because~$\gL(s)$ is convex in~$s$:
    %
    \begin{equation*}
        \od[2]{\gL}{s} = \E_{\vx, \vy_1, \vy_2}\Big[
        \big(\prod_{u \in \gU} z_u \big) \cdot \frac{|\gU|}{s^2} (\frac{1}{s} - 1)^{|\gU| - 1} 
        + \big(\prod_{u \in \gU} (1 - z_u) \big) \cdot \frac{|\gU|}{(1 - s)^2}(\frac{1}{1 - s} - 1)^{|\gU| - 1} 
        \Big] \ge 0
        \,.
    \end{equation*}
    %
    Finally, one can verify that the policy that results in~$s^*$ (\cref{eq:_proof_s_star}) is the optimal policy~$\pi^*$. This completes the proof that the proposed loss is a consistent loss for~$\pi^*$.  
\end{proofEnd}
%%%

%%%%%%%%%%


%%%%%%%%%%
\section{Missing Proofs}

\printProofs
%%%%%%%%%%


%%%%%%%%%%
\input{sections/appendix_examples}
\newpage
\input{sections/appendix_llama}
%%%%%%%%%%