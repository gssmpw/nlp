\section{Related Work}
\label{sec:related}

%xyz: Need to avoid overlapping with the intro and other sections. (ok)


Our work draws inspirations from and advances the knowledge in the following three categories of research.


\subsection{Generative Agents in HCI}

% Agents for HCI

The rapid advancement of LLMs has inspired a wide range of HCI applications, including social behaviors (Generative Agents \cite{park2023generative}), virtual reality \cite{wan2024building} with tour guidance (VirtuWander \cite{wang2024virtuwander}), Human-AI collaboration (AI Chains \cite{wu2022ai}, \cite{wang2024human}), creative tasks (CharacterMeet \cite{qin2024charactermeet}, Luminate \cite{suh2024luminate}, C2Ideas \cite{hou2024c2ideas}, ABScribe \cite{reza2024abscribe}, AngleKindling \cite{petridis2023anglekindling}, PopBlends \cite{wang2023popblends}), healthcare (MindfulDiary \cite{kim2024mindfuldiary}, ChaCha \cite{seo2024chacha}, Narrating Fitness \cite{stromel2024narrating}, \cite{rajashekar2024human}) with health intervention (MindShift \cite{wu2024mindshift}, \cite{jo2024understanding, jo2023understanding, calle2024towards, ma2024evaluating}), web interaction \cite{deng2024large} with UI design (ReactGenie \cite{yang2024reactgenie}, \cite{duan2024generating}, \cite{wang2023enabling}), coding (CollabCoder \cite{gao2024collabcoder}, \cite{liu2023wants}), behavioral change (CatAlyst \cite{arakawa2023catalyst},\cite{bhattacharjee2024understanding}) with human augmentation (Memoro \cite{zulfikar2024memoro}, \cite{jang2024s}), business (Marco \cite{fok2024marco}), and so on.

% Agents for Education

In educational context, LLMs-powered agents have been utilized to serve as teachable agents (Mathemyths \cite{zhang2024mathemyths}, \cite{jin2024teach}, \cite{liang2023let}) to provide instructions \cite{vadaparty2024cs1}, recommend learning concepts \cite{li2024learning}, and give feedback \cite{matelsky2023large}. For example, DevCoach \cite{wang2024devcoach} supports students' learning in software development at scale with LLMs-powered generative agents. ReadingQizMaker \cite{lu2023readingquizmaker} proposes a Human-NLP collaborative system which supports instructors to design high-quality reading quiz. In programming education, CodeTailor \cite{hou2024codetailor} uses LLM-powered personalized parsons puzzles to support engagement in programming. PaTAT \cite{gebreegziabher2023patat} presents a human-AI collaborative qualitative coding system using LLMs for explainable interactive rule synthesis. 

Such existing work either uses generative agents as the instructors to directly teach students \cite{zhang2024mathemyths} or serves as student agents \cite{markel2023gpteach} to augment intelligent tutoring systems. 
%xyzr1: how does our work differ?
Our work focuses on the second aspect. In what follows, we specifically discuss related work in student simulation using either machine learning or generative agents.


\subsection{Student Simulation}

Student simulation aims to predict student learning behaviors in education, thus providing insights for supporting intelligent tutoring systems \cite{graesser2012intelligent}. A majority of existing research formulates student simulation as a knowledge tracing problem, i.e. predicting students' future learning performance based on their past records  \cite{abdelrahman2023knowledge}. This learning performance is usually represented by the question answering accuracy in the course to measure students' skill levels for specific course concepts. Early work in this domain employed classical Bayesian models \cite{yudelson2013individualized}. In recent years, deep learning models \cite{piech2015deepknowledgetracing} have been the predominant approach for knowledge tracing, combining graph models \cite{nakagawa2019graph}, cognitive theories \cite{zhou2024predictivescalableinterpretableknowledge}, memory-augmented components \cite{zhang2017dynamickeyvaluememorynetworks}, and so on.
% In what follows, we introduce related work using LLMs-based approaches for student simulation.

\subsection{LLM-based Student Simulation}

Recent work has explored the feasibility of using LLMs directly for predicting students' learning performance \cite{zhang2024predicting,xu2023leveraging} or for knowledge tracing \cite{yu2024eckt} in open-ended questions \cite{liu2022gpt}. 
%
These methods have better explainability than deep learning models, owing to LLMs' capability to reveal the reasoning process\cite{li2024explainable}.
%
They can also augment deep learning-based knowledge tracing \cite{fu2024sinktstructureawareinductiveknowledge,jung2024clst}.
%
In HCI, researchers have developed multi-agent collaboration environment to simulate the whole classroom interaction \cite{zhang2024simulating,chen2023agentverse} and used LLM-simulated student profiles to support question item evaluation \cite{Lu_2024}. These approaches can enable adaptive and personalized exercise generation to augment student learning performance \cite{cui2023adaptive}.
\mytextcolor{For example, Sarshartehrani et al. \cite{sarshartehrani2024enhancing} further leveraged embodied AI tutors for personalized educational adaptation.
GPTeach \cite{markel2023gpteach} also demonstrated the feasibility of using GPT-based virtual students for interactive TA training. In addition, MATHVC \cite{yue2024mathvcllmsimulatedmulticharactervirtual} explored the effectiveness of LLM-simulated multi-character virtual classroom for mathematics education. Moreover, LLMs can help students engage in post-lesson self-reflection \cite{kumar2024supporting} and also support language learning and growth mindset cultivation \cite{kim2024exploring}.}




However, there is also evidence \cite{neshaei2024modelinglearnerperformancelarge} showing the 
%xyzr1: What limitation? Low accuracy? 
limitation of LLMs in student performance prediction compared with deep learning (DL) models. We argue that this is mainly because of the lack of contextual course materials. Specifically, existing LLM-based approaches \cite{fu2024sinktstructureawareinductiveknowledge,jung2024clst,li2024integrating,lee2024monacobert,lee2024language} simply treat student simulation as a sequence prediction problem, which predicts future test performance based on past records, ignoring the modulation effect of course materials. In this case, DL models are very likely to work better than LLMs owing to their capacity to learn from historical data \cite{lecun2015deep, tang2023struc}. In contrast, LLMs are better at few-shot contextual learning based on their large pretrained \textit{knowledge base} \cite{dong2022survey}. Therefore, incorporating contextual course materials could better unleash the power of LLMs to capture the potential effects of course materials on learning performance even with limited data, thus enabling more accurate student simulation.

Existing work in this respect is quite limited, due to both the model limitations and the lack of dataset containing course materials (Section \ref{sec:intro}). 
EduAgent \cite{xu2024eduagent} incorporated course materials to simulate students' cognitive states and post-test performance, but the lectures' duration was too short (5 minutes) to represent the learning process across a typical lecture. By contrast, our work conducts longer-term experiments (6-week, 12 lectures, 1 hour per lecture) to collect high quality learning behavioral data. Our study employs a self-developed online education system integrating sensing techniques and action recommendations to help instructors increase students' learning engagement. Moreover, our proposed transferable iterative reflection module further augments the student simulation performance for both finetuning-based and prompting-based models, which departs from existing approaches in language models \cite{li2024integrating,lee2024monacobert,lee2024language} and deep learning models \cite{piech2015deepknowledgetracing,zhang2017dynamickeyvaluememorynetworks}.


% One reason is the lack of such fine-grained datasets that contain annotations of course materials with corresponding student performance. Most existing datasets (such as Ednet \cite{choi2020ednet}, Junyi \cite{JunyiOnlineLearningDataset} and Assistments 2009-2010 benchmark dataset\footnote{https://sites.google.com/site/assistmentsdata/home/assistment-2009-2010-data}) only contain question materials without course materials. EduAgent dataset \cite{xu2024eduagent} indeed contains the course stimuli data, but the lecture length is too short (5-min) to reveal the student learning process in the whole lecture. To tackle this problem, we run a new user study in the form of a 6-week online education workshop including 12 lectures (1 hour per lecture) and collected fine-grained annotations of course materials and student learning performance. Another challenge is that data collection can not easily guarantee the data quality since students' engagement may drop during learning \cite{wang2019effects}. We solve this problem by developing a new online education system that integrates sensing techniques to monitor students' learning behaviors and prompt instructors to take recommended actions to increase students' learning engagement and thus improve data quality. 

% Another reason that prevents student simulation from integrating course materials is the limitation of existing language models to deal with long contextual data. 
% %
% Existing work has demonstrated the effectiveness of using BERT-based language models for student performance prediction \cite{li2024integrating,lee2024monacobert,lee2024language}. However, BERT has very low token limits (512 tokens), which can only deal with simple textual input but fails to capture complex contextual information such as course materials. 
% %
% LLMs such as GPT4 could support longer contextual text input, but their performance also drops when the context is too long and overwhelming \cite{li2024long}.
% Inspired by the self-reflection ability of LLMs \cite{madaan2024self} to distill knowledge \cite{Xu2024ASO}, our framework solves this problem by introducing a transferable iterative reflection (TIR) module which first asks LLMs to perform reflections on specific course materials and compress the learnt knowledge to augment LLMs-based student simulation. Different from a straightforward self-reflection \cite{madaan2024self}, our TIR module uses an interactive architecture between a novice agent and reflective agent to ensure that the reflections could be generalized into new domains to enable transferable reflections. More details are depicted in Section. \ref{sec:model}.

\begin{figure*}%[tbhp]
\centering
\includegraphics[width=1\linewidth]{figures/model_prompt.pdf}
%xyz: This is too long (revised)
\caption{\mytextcolor{Training (left) and testing (right) schemes for prompting-based models. }
% In both training and testing, we organize past and future questions related information as the organized prompt. During training, we use a novice agent to predict future question correctness and compare it with actual labels. This guides the reflective agent in generating reflections, which help the novice agent make better predictions. The reflective and novice agents interact multiple times to improve reflections. In testing, we use the reflection database and organized prompts to generate future question correctness predictions. 
}
\Description{This figure shows the training (left) and testing (right) schemes for prompting-based models. For both training and testing, we organize past questions contents, correctness, and related course materials along with future questions contents and related course materials as the organized prompt. In training (left figure), we feed the organized prompt to a LLM to generate initial future question correctness prediction. Then, we compare that with the future question correctness label to inform the reflective agent to generate reflections. Finally, we use the generated reflection and organized prompts to make the novice agent make predictions and reasoning. We let the reflective agent and novice agent interact interactively so that the reflective agent has more chances to provide better reflections. In testing (right figure), we use the successful reflection database generated by the reflective agent during training along with the organized prompt to generate future question correctness predictions.}
\label{framework:prompt}
\end{figure*}