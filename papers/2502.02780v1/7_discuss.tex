\section{Discussion}
\label{sec: discussion}

In this work, we run a 6-week online education workshop to collect fine-grained annotations of both course materials and student learning performance. This enabled a contextual student simulation to consider the effect of course materials' modulation on student learning. We further improved the student simulation by proposing a transferable iterative reflection module that augmented both prompting-based LLMs' simulation and finetuning-based LLMs' simulation, which achieved even better performance than deep learning models. This was also verified in another public dataset.

\begin{figure*}%[tbhp]
\centering
\includegraphics[width=1\linewidth]{figures/graph.pdf}
\caption{Inter-student correlation graphs of the label (a) and simulations using BertKT with (b) and without TIR (c) on our newly collected dataset where a node is a student and an edge connects two students if both students took the same lecture. The node color depth represents the average question answering correctness of all lectures that the individual student attended. The edge weight connected by two nodes represents the inter-student correlation, which was calculated by the Pearson correlation between the question correctness sequences of two students corresponding to the questions from the overlapped lectures between two students.}
\Description{This figure shows the inter-student correlation graphs of the label (a) and simulations using BertKT with (b) and without TIR (c) on our newly collected dataset where a node is a student and an edge connects two students if both students took the same lecture. The node color depth represents the average question answering correctness of all lectures that the individual student attended. The edge weight connected by two nodes represents the inter-student correlation, which was calculated by the Pearson correlation between the question correctness sequences of two students corresponding to the questions from the overlapped lectures between two students. It shows that the integration of the TIR module better captured both individual student learning performance (average question answering correctness represented by the color depth of each node) and inter-student correlation (Pearson correlation of question correctness sequences between two students, represented by the edge weight between two nodes), which were more similar with real students (label), compared with the model without the TIR module.
}
\label{graph}
\end{figure*}

\subsection{Application Scenarios}

With the increasing importance of AI-assisted education and intelligent tutoring systems, our work could serve as the important groundwork to support a list of applications in educational context.

% cite related papers to support why our simulation is needed and how our simulation can work.

\subsubsection{Student: Enhancing Self-Learning}
The classroom simulacra could create digital twins about a specific student based on the past learning histories. This digital twin further emulates the student's learning performance in the future course materials and tests. This could support the self-assessment and reflections of students to set personalized goals based on their learning pace. Specifically, students could track their learning trends and progress and see how their skills have developed. As a result, it could help students reflect on their strengths and weakness to be improved during learning. Students can also set more appropriate learning goals, milestones, and study priorities based on the simulated results so that they can be motivated to achieve clearer learning targets. Such decision making and reflection in learning are also related to the metacognitive skills of students to develop learning strategies and study habits.

\subsubsection{Instructor: Adapting Teaching Strategy}
Teachers utilizing this system will be able to analyze predictions across an entire class or cohort, allowing them to test pedagogical approaches or curriculum structures before they even deploy them on a class of real human students. Having access to such a representative digital class can allow teachers to use simulation results to tailor the learning experience, presenting students with course contents that truly match their skill levels.
With the classroom simulacra, the instructors could optimize the curriculum design by identifying the common areas of difficulty, which is achieved by analyzing simulation results across the whole class.
For instance, students who turn out to learn fast can accept accelerated course pace while students who may struggle with upcoming tests or course contents can be delivered more related course resources to build personalized learning path. This could also improve the teaching resource allocation by enabling instructors to allocate teaching resources more effectively by identifying skills that may require more time for students to master. Last but not least, this system could provide insights for adaptive interventions of instructors so that students could receive personalized interventions (like verbal reminder or one-on-one tutoring) when they are identified to be at risk of falling behind. 


\subsubsection{Parents: Home Support}
In the home environment, the classroom simulacra can simulate specific children's learning performance based on their past learning history. As a result, parents can have insightful information about how well their children will do in certain curriculum (strengths and weakness), and they could make better decision-making for tasks like choosing the right school, extracurricular activities, choosing advanced courses, and wisely investing in a tutoring service that can target specific areas where their children may struggle. Parents can also support learning outside of school through informed insights about necessary home activities and resources which align with their children's predicted needs and create a conducive study environment tailored to their childrenâ€™s learning style according to the  performance simulation insights.  



\subsection{Limitations and Future Work}
We also acknowledge the potential limitations in this work.

\subsubsection{Population Diversity}
The first limitation is the population diversity in our online education workshop. We decide to recruit students from elementary schools and high schools because these students usually do not have prior knowledge about our course materials related to Artificial Intelligence. As a result, we could better capture the learning performance and learning outcomes of students when they learn new knowledge. However, we also acknowledge that the data collection with more diverse populations (such as different age groups) could better support and further extend the findings of our experiments.

% \subsubsection{Simulation Resolution}
% Second, our classroom simulacra predicts students' question answering correctness instead of specific question answering choices. This design follows the common practice of existing knowledge tracing approaches \cite{piech2015deepknowledgetracing,10.1145/3474085.3475554,10.1145/3394486.3403282} for student simulation. 
% Because predicting student correctness could directly reveal the skill levels of students on specific course concepts, which can be used for adaptive teaching interventions\cite{hacker2000test}.
% Moreover, student choice prediction is more challenging compared with student correctness prediction. Because students' correctness can be reflected by their past skill levels. If students make a correct choice, it is easy to infer that students may have mastered this related concept. However, if students make a wrong choice, it is hard to obtain the relevant information that may lead to a specific wrong choice by students. 
% However, we acknowledge that simulating students' specific question answering choices could provide further insights about why students make a wrong choice and better support students' learning improvement.
% We leave such exploration for our future work.

\subsubsection{Simulated Behavioral Types}
In our work, we use the students' question answering correctness to represent their learning performance, which can be mapped to students' skill levels on related course concepts. By further mapping them into specific slide IDs in the course (such as Section. \ref{subsec: dynamism}), this simulation can reflect the students' learning behaviors during the course. 
%
\mytextcolor{However, we acknowledge that student behaviors are not limited to question correctness. \mytextcolor{We clarify that the cognitive states information was only used for teachers to obtain students' learning states during data collection, and was not used for behavioral simulation.}
There are also more diverse learning behaviors in the real world scenarios such as reasoning processes, learning reflections, personal preferences, learning styles, etc. For example, students' cognitive states (such as attention, confusion) during the course could directly reflect their learning styles and personal preferences in the course. The simulation for such additional learning behaviors could provide further insights and evidence support. We also believe that LLMs have great potential in simulating such diverse behaviors due to the strong in-context learning ability \cite{wei2023larger} and large knowledge base \cite{alkhamissi2022review}. 
Therefore, such simulation on more diverse learning behavioral types could be the future directions for exploration. 
}

\mytextcolor{
%xyzr1: This paragraph needs to be rewritten. It's too abrupt. Unclear why suddently you talk about this. 
\subsubsection{Generalization and Cost Differences}
We clarify that our goal is to show that TIR can augment LLMs to achieve better performance than themselves without TIR and deep learning models. We have a fair comparison within each LLMs-based model with or without TIR using the same training/testing data. But we do not intend to directly compare prompting-based LLMs with finetuning-based LLMs. Because both have their own pros and cons. For example, prompting-based LLMs need less training data but finetuning-based LLMs have better simulation performance. 
However, for future potential applications to extend the fine-tuned models in external datasets, it is also necessary to fine-tune models again in such new datasets, which is similar to deep learning models that use training data to update model weights. 
As such, it is not comparable/applicable to directly compare both regarding the generality or training time/computational resources. 
%
When comparing with deep learning, we mainly use finetuning-based LLMs for a fair comparison because they use the same training data. However, using much less training data, the TIR-augmented prompting-based LLMs can also achieve comparable or even better performance than deep learning. This also demonstrates the effectiveness of our TIR module. 
%
}

\mytextcolor{
\subsubsection{Insights for Educators}
Our current classroom simulacra serves as a student simulation model. Integrating it into an end-to-end intelligent teaching system entails non-trivial efforts. Nevertheless, the classroom simulacra is grounded in a real-world student-educator interaction dataset. 
\mytextcolor{Its predictive capability aligns with proven educational models that have been utilized to successfully inform teaching practices and support adaptive learning strategies \cite{scholtz2021systematic}. The foundational accuracy of our model indicates a strong potential for real-world applicability, as seen in similar simulations that have influenced educational strategies even before empirical testing \cite{xing2019dropout}}.
%
The simulator can support educators by delivering actionable insights that enhance personalized interventions, curriculum design, and evidence-based teaching practices. It can identify specific knowledge gaps for individual students, enabling targeted interventions, and allows educators to explore hypothetical scenarios to optimize teaching strategies for diverse learner profiles. Additionally, the simulator aids in curriculum optimization by simulating student responses to different teaching methodologies, helping to refine pacing and content sequencing. Therefore, the simulator provides a research-backed tool for testing the impact of instructional methods and predicting long-term outcomes. 
\mytextcolor{Beyond learning analytics, it integrates behavioral insights to detect learning issues and offers a safe experimental environment for innovative teaching approaches. Case studies in our work illustrate its practical utility, such as identifying impactful topics for exam preparation based on students' different learning performance on different questions (question-level) and guiding classroom time allocation based on students' learning performance across different slides (slide-level). 
In conclusion, while real-world educator experiences would strengthen our findings, the current study offers a solid foundation that demonstrates the simulatorâ€™s predictive power and practical potential. Future work that includes educator feedback will further bolster our understanding and validation of its effectiveness in real classroom settings.
% We recognize the importance of direct educator input for validating the practical value of our tool. 
% To that end, we plan to initiate a pilot study involving educators who can test the simulator within real educational contexts and provide firsthand feedback on its utility and impact. This will help refine our model further and build a more comprehensive understanding of its real-world effectiveness.
}
% It is worth noting that similar educational tools and simulations have been developed and adopted without immediate real-world data, yet they have significantly contributed to teaching practices upon subsequent use. For example, adaptive learning platforms and predictive analytics tools have frequently been integrated into educational settings after their predictive reliability has been demonstrated through controlled studies.
% Even without immediate real-world data, our study contributes to the field by providing a proof of concept that educators can use as a starting point to incorporate predictive data into their teaching. By leveraging insights from the simulator, educators may be better equipped to understand student learning patterns and make data-driven decisions that enhance educational outcomes.
}

% \mytextcolor{
% \subsubsection{Insights for Educators}
% Our student simulator addresses key educational research challenges by offering predictive insights grounded in validated algorithms and a real-world student-educator interaction dataset. 
% While we acknowledge the current limitation of not having direct educator feedback using our student simulator, the simulator demonstrates significant potential for enhancing teaching practices through its sophisticated predictive capabilities. 
% The model can anticipate student learning performance and knowledge gaps, enabling proactive instructional adjustments across various educational contexts. By supporting educators in identifying individual student learning needs, exploring hypothetical teaching scenarios, optimizing curriculum design, and simulating the impact of different instructional methods, the simulator provides a robust tool for data-driven pedagogical strategies. 
% Furthermore, this predictive capability aligns with proven educational models that have been utilized to inform teaching practices and support adaptive learning strategies. The foundational accuracy of our model indicates a strong potential for real-world applicability, as seen in similar simulations that have influenced educational strategies even before empirical testing \cite{xing2019dropout}.
% The approach is anchored in established educational theories and has shown promising results in preliminary case studies, such as identifying impactful exam preparation topics and guiding classroom time allocation based on detailed learning performance analysis. 
% Despite the absence of immediate real-world educator experiences, our methodology follows a precedent in educational technology development, where similar adaptive learning platforms and predictive analytics tools have been successfully integrated into educational settings after demonstrating predictive reliability through controlled studies. 
% To further validate the simulator's practical utility, we propose a pilot study that will engage educators in testing the tool within actual classroom contexts, collect direct feedback, and refine the model based on real-world insights. In essence, our study provides a compelling proof of concept that represents a promising step toward more personalized, data-driven educational strategies that have the potential to transform teaching and learning experiences.
% }