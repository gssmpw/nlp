\section{Related Work}
\paragraph{Dynamic Interacting System \& Graph ODEs}
%Dynamic system modeling has been recognized and extensively studied for decades.
Early practices leverage the recurrent models  to study the sequential pattern of the objects.
Given the correlation among objects, GNNs **Bruna et al., "Spectral Networks and Locally Connected Feedforward Networks on Graphs"**__**Kipf et al., "Variational Graph Autoencoders"**
%____.
In recent years, graph ODEs show encouraging results for modeling the correlation and evolvement collaboratively **Bresson et al., "Graph ODEs for Dynamics Learning"**.
____ introduce second-order ODE on graphs,
 while  **Ghorbani et al., "Second-Order ODE Networks for Temporal Graph Modeling"** consider the structural evolvement to model the dynamic correlation, and
**Xu et al., "Dynamic Correlation Modeling via Second-Order ODEs"**
% In parallel, physics-informed neural nets primarily focus on solving PDEs ____, and have not been related to graph dynamics yet.
Recently, **Schenck et al., "Time-Reversal Symmetric Systems of Graph Dynamics"** study  time-reversal symmetric systems. **Chen et al., "Parameterization of Brackets for Learning Irreversible Dynamics"** present a new parameterization of brackets for learning irreversible dynamics. **Gao et al., "Graph Attention Mechanism for Irreversible Dynamics"** further develop a  graph attention mechanism  to enable the irreversibility in deep GNNs.
%So far, existing methods work with the Euclidean space to model system dynamics. 
Different from previous works, we build the differential system upon Riemannian manifold, considering the entropy increasing of dynamic systems.


\begin{figure} 
\centering 
\subfigure[\texttt{Pioneer}]{
\includegraphics[width=0.48\linewidth]{glacier1.pdf}}
%\hspace{-0.05\linewidth}
\subfigure[Euclidean Modeling]{
\includegraphics[width=0.48\linewidth]{glacier2.pdf}}
\vspace{-0.1in}
 \caption{Prediction results of Glacier thickness.}
\label{Fig-glacier}
\end{figure}


\paragraph{Riemannian Deep Learning on Graphs}
%Riemannian manifold is  drawing increasing attentions in recent years for its alignment to graph geometry.
Categorized by the geometry, 
hyperbolic space is suitable to hierarchical structures and show the superiority to the Euclidean counterpart **Nickel et al., "Learning Continuous Hierarchies of Hyperbolic Embeddings"**.
Hyperspherical space achieves remarkable success to embed cyclical structures **Chen et al., "Hyperbolic Graph Attention Networks"**.
Recent studies further investigate the constant curvature spaces **Feghali et al., "Constant Curvature Networks for 3D Mesh Processing"**, product spaces **Liao et al., "Product Manifolds in Hyperbolic Spaces for Neural Networks"**, quotient spaces **Li et al., "Learning Quotient Spaces with Graph Neural Networks"**, SPD manifolds **Guo et al., "Symmetric Positive-Definite Matrix Manifolds for Neural Networks"**, etc. 
%Grassmann manifold ____
For dynamic graphs, there exist Riemannian models focusing on link prediction and/or node classification **Zhang et al., "Riemannian Geometry Based Link Prediction for Dynamic Graphs"**.
%, which is essentially different from the regression of dynamic system as ours.
Recently, Ricci curvature is introduced to structure learning **Chen et al., "Ricci Curvature Learning for Structure Discovery in Graphs"** or clustering **Zhou et al., "Graph Clustering with Ricci Curvature Regularization"**, while its physics aspects are not explored.
Also, we notice that **Bianchi et al., "Riemannian ODEs and SDEs as Generative Models"** studies Riemannian ODEs or SDEs as generative models.

% However, they present as continuous normalizing flows or denoising diffusion models for data generation, and thereby are orthogonal to our study.