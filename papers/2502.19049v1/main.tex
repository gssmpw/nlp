%%%%%%%% ICML 2024 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{makecell}
\usepackage[table, dvipsnames]{xcolor}

% \hypersetup{
%     citecolor=CadetBlue,
%     colorlinks=true,
%     linkcolor=CadetBlue,
%     filecolor=magenta,      
%     urlcolor=cyan}

\colorlet{table_baselines}{CadetBlue!10}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2024} with \usepackage[nohyperref]{icml2024} above.
\usepackage{hyperref}
\usepackage{enumerate}  

\usepackage[most]{tcolorbox} % For boxes with background color

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2024}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2024}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% COMMANDS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\*#1{\mathbf{#1}}
\def\-#1{\bar{#1}}
\def\-*#1{\bar{\mathbf{#1}}}
\def\\#1{\backslash{#1}}
\newcommand{\+}[1]{\boldsymbol{\mathbf{#1}}}
\newcommand{\?}[1]{\mathbb{#1}}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Foundation Inference Models for Diffusion Processes}

\begin{document}

\twocolumn[
% \icmltitle{Foundation Inference Models for Stochastic Differential Equations}
\icmltitle{Foundation Inference Models for Stochastic Differential Equations: \\ \vspace{0.15cm} {\large A Transformer-based Approach for Zero-shot Function Estimation}}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2024
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Patrick Seifner}{yyy,xxx}
\icmlauthor{Kostadin Cvejoski}{yyy,zzz}
\icmlauthor{David Berghaus}{yyy,zzz}
\icmlauthor{C\'esar Ojeda}{www}
\icmlauthor{Rams\'es J. S\'anchez}{yyy,xxx,zzz}

%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Lamarr Institute,}
\icmlaffiliation{xxx}{University of Bonn,}
\icmlaffiliation{zzz}{Fraunhofer IAIS and}
\icmlaffiliation{www}{University of Potsdam}

% \icmlcorrespondingauthor{Patrick Seifner and Rams\'es J. S\'anchez}{seifner@cs.uni-bonn.de, sanchez@cs.uni-bonn.de}
\icmlcorrespondingauthor{Patrick Seifner}{seifner@cs.uni-bonn.de}
\icmlcorrespondingauthor{and Rams\'es J. S\'anchez}{sanchez@cs.uni-bonn.de}


% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}

Stochastic differential equations (SDEs) describe dynamical systems where deterministic flows, governed by a drift function, are superimposed with random fluctuations dictated by a diffusion function. 
% 
The accurate estimation (or discovery) of these functions from data is a central problem in machine learning, with wide application across natural and social sciences alike. 
%
Yet current solutions are brittle, and typically rely on symbolic regression or Bayesian non-parametrics. 
% typically rely on symbolic regression or Bayesian non-parametric methods, which are known to be brittle.
%
In this work, we introduce \texttt{FIM-SDE} (Foundation Inference Model for SDEs), a transformer-based recognition model capable of performing accurate \textit{zero-shot estimation} of the drift and diffusion functions of SDEs, from \textit{noisy and sparse observations} on empirical processes of \textit{different dimensionalities}. 
%
Leveraging concepts from amortized inference and neural operators, we train \texttt{FIM-SDE} in a supervised fashion, to map a large set of noisy and discretely observed SDE paths to their corresponding drift and diffusion functions.
%
We demonstrate that \textit{one and the same} (pretrained) \texttt{FIM-SDE} achieves robust zero-shot function estimation (\textit{i.e.}~without any parameter fine-tuning) across a wide range of synthetic and real-world processes, from canonical SDE systems (\textit{e.g}.~double-well dynamics or weakly perturbed Hopf bifurcations) to human motion recordings and oil price and wind speed fluctuations.

  Our pretrained model, repository and tutorials are available online\footnote{\url{https://fim4science.github.io/OpenFIM/intro.html}}.
% \texttt{FIM-SDE} is available as supplementary material to this submission\footnote{\url{https://anonymous.4open.science/r/FIM-SDE-FCCB/}}.

\end{abstract}

\section{Introduction}
\label{sec:intro}
% The study of dynamical phenomena has traditionally involved modeling the evolution of observables through differential equations, such as Ordinary Differential Equations (ODEs), Stochastic Differential Equations (SDEs), and Partial Differential Equations (PDEs). In the machine learning community, the focus has shifted toward learning the operators that evolve these systems: the forward model of a PDE, the vector field in an ODE, or the infinitesimal generator (drift and diffusion functions) for SDEs.

Stochastic differential equations (SDEs) govern dynamical systems featuring deterministic flows superimposed with random fluctuations.
%
The deterministic component of these systems are dictated by a \textit{drift function}, and are used to model the slow, tractable or accessible degrees of freedom of dynamic phenomena.
%
The random components are instead controlled by a \textit{diffusion function}, and are used to represent fast or intractable degrees of freedom.
%
Such a description, in terms of tractable versus intractable, slow versus fast, is abstract enough to be applicable across disciplines and observation scales.
%
It was first employed to capture variations of derivative pricing in financial markets~\cite{bachelier1900theorie}, and almost immediately 
%
to understand the patterns traced by particles suspended in liquids~\cite{einstein1905molekularkinetischen}.
%
It was famously applied to link slow climate variability to rapid weather fluctuations~\cite{hasselmann1976stochastic}, and to represent the coupling with intractable environments in population genetics~\cite{TURELLI1977140}.
%
However, the central problem limiting the actual applicability of the SDE description to many complex phenomena, is the accurate determination of the drift and diffusion functions that best describe a collection of observations on one such phenomenon. 
%
In other words, the problem of \textit{function discovery} from data. 
%
% In this work we address this problem.


% In some applications, the functional form of these functions can be constructed from first principles, and only a few physically interpretable parameters need to be estimated from data.
%
% In most moderns problems this is not the case.
%
% Yet symbolic regression heavily depends on prior knowledge, and suffers from limited expressivity~\cite{boninsegna2018sparse},
% %
% while Bayesian non-parametrics not only require prior knowledge~\cite{batz2018approximate}, but also feature strong convergence problems~\cite{verma2024variational}.
%
% Moreover, like most machine learning methods, both approaches need separate optimization for each newly observed system.
%
The machine learning community has primarily relied on two approaches to address this problem, namely Bayesian non-parametrics and symbolic regression,
%
both of which feature a number of significant limitations.
%
First and foremost, they heavily depend on the quality and correctness of prior knowledge about the system under investigation. 
%
Second, they either assume access to the ``clean'' state of the system, or must rely on variational approximations, which are known to be prone to slow convergence.
%
And third, like most traditional machine learning methods, \textit{they require separate optimization for every newly observed system}. See Section~\ref{sec:related-work} for details. 
%
All these constraints severely restrict their suitability for real-world scenarios, where prior knowledge is scarce, data is noisy, and repeated retraining of models is impractical.

Likely inspired by the proliferation and advancement of foundation models in both, natural language processing and time series forecasting communities, there has been a recent shift toward (pre)training neural network models on large synthetic datasets, to perform \textit{zero-shot estimation of functions} governing the evolution of \textit{unseen and vastly different} dynamical systems.
%
% These models are devised to used off-the-shelf
The general strategy consists of three steps. 
%
First, one defines a broad probability distribution over the (space of) target functions and, consequently, over the space of dynamical systems.
%
This distribution should represent one's beliefs about the general class of systems one expects to encounter in practice.
%
Second, one simulates the resulting dynamical systems (\textit{i.e.}~conditioned on the target functions) and corrupts the samples, to generate a dataset of noisy observations and target function pairs, thereby effectively defining a type of \textit{meta-learning task} that amortizes the estimation process\footnote{We invite the reader to refer to Appendix~\ref{app:related-work}, where we discuss how these ideas relate to existing approaches, such as the \textit{neural process} family.}. 
%
Third, one trains a neural network model to match these pairs in a supervised way.
%
For example, \citet{dooley2024forecastpfn} generated random parametric functions of time and proposed a model to map series of observations on these functions into their future values, thereby implicitly learning their underlying forecasting function.
%
% proposed a model that estimates the implicit forecasting function underlying random parametric functions of time in zero-shot mode.
%
\citet{seifner2024foundational} relied on a similar construction, but to infer imputation functions.
%
\citet{berghaus2024foundation} sampled large sets of rate matrices governing a class of (homogeneous) Markov jump processes, simulated the latter and developed a model that matched (observations on the) process simulations with their target rates.
%
% for the zero-shot inference of the rate matrices governing the dynamics of a class of hidden (homogeneous) Markov jump processes.
%
Similarly, \citet{dascoli2024odeformer} constructed sets of random drift functions defining autonomous ordinary differential equations together with their solutions, and introduced a model that connected (observations on the) solutions to their target drifts.
%
Once (pre)trained, all these models were shown to accurately estimate their target functions \textit{in zero-shot mode} (that is, without any parameter fine-tuning) from unseen, noisy and very different datasets.
%

In this work, we follow this general strategy and introduce a novel transformer-based architecture that approximately maps noisy and sparse observations on SDE paths into their target drift and diffusion functions.
%
Instead of being trained to estimate the target functions in symbolic form, 
%
as \textit{e.g.}~in \citet{dascoli2024odeformer},
%
the model leverages concepts from neural operators~\cite{lu2021learning} to learn neural representations of the drift and diffusion functions that can be evaluated on some predefined domain of interest. 
%
We train this model on a broad family of SDEs and name it \texttt{FIM-SDE}: \textit{Foundation Inference Model for SDEs}.
%
% first define a broad probability distribution over the space of drift and diffusion functions characterizing a large family of SDEs.
% %
% We sample many realizations from each one of these SDEs --- \textit{i.e.}~conditioned on their drift and diffusion functions --- and corrupt them to generate a dataset of noisy and sparse observations on these realizations, together with their target drift and diffusion functions.
% %
% Then we introduce a novel transformer-based architecture that maps the noisy observations to the target functions and which, instead of being trained to estimate the target functions in symbolic form, leverages concepts from neural operators~\cite{lu2021learning}, to learn neural representations of the target functions that can be evaluated on some predefined domain of interest. We name this architecture \texttt{FIM-SDE}: \textit{Foundation Inference Model for SDEs}.

In what follows, we first briefly review related work on the general problem of drift and diffusion function estimation in Section~\ref{sec:related-work}, and then revisit the SDE basics we draw upon in Section~\ref{sec:preliminaries}.
%
In Section~\ref{sec:FIM}, we introduce our methodology and demonstrate that it is capable of performing \textit{zero-shot function estimation} in a large variety of synthetic and real-world settings in Section~\ref{sec:experiments}.
%
Finally, we close this paper with some concluding remarks about the limitations of our proposal and future work in Section~\ref{sec:conclusions}.



% First, \citet{dooley2024forecastpfn} (pre-)trained a conditional transformer model on a dataset of random parametric functions of time, to map series of noisy observations on these functions into their future values, thereby implicitly learning, in a zero-shot fashion, the evolution function of their target systems.
% %
% Second, \citet{berghaus2024foundation} studied the problem of estimating the rate matrices underlying (homogeneous) Markov jump processes (MJPs) from data in zero-shot mode. They (pre-)trained different neural network models on a synthetic dataset of different MJP simulations, to transform noisy observations on these simulations into their target rates, and applied their pre-trained models directly to experimental data. 
% %
% Lastly, \citet{dascoli2024odeformer} (pre-)trained a transformer model to map noisy observations on the solutions of many different (autonomous ordinary) differential equation into the drift functions defining them (that is, the time derivative of the state of their systems)




% %%%%%% NOTES %%%%%%%%%%%%%%%%%%%%
% Symbolic regression: 
% 1. require finite difference approximations;
% 2. require a predefined set of basis functions;
% 3. SINDy is limited to linear combination of the basis functions;
% 4. All assume prior knowledge about the ground truth;
% 5. Symbolic regression require a separate optimization for each new observed system;
% %
% Bayesian non-parametrics:
% 1.Typically restricted parameter learning;
% 2. Typically focuses on posterior distribution over the paths: the smoothing problem.
% 3.Slow convergence problems

% For ODEs and SDEs, recent advances involve parametrizing the operators of the associated differential equations with deep neural networks and training them on data using stochastic gradient descent. These methods exploit the continuous-time nature of differential equations and employ adjoint methods to compute gradients for learning. Since the real vector field is typically unknown, learning is achieved by integrating the neural network parametrization to fit the observed data. This ability to leverage continuous time and deep representations enabled methodologies, such as Neural Ordinary Differential Equations (NODEs), to outperform traditional recurrent neural networks and discrete state-space models in modeling dynamical systems.

% However, adjoint computation introduces a high computational burden, leading to stiffness and limited parallelization, which heavily constrains the success of these approaches. A significant challenge lies in the necessity of simulation during training, requiring integration of the equations of motion. On the other hand, neural operators have emerged as an alternative, motivated by the need for faster simulation. These approaches model dynamical behavior by learning an operator that maps input functions to PDE solutions. Neural operators leverage simulations of prescribed forward maps on coarse-grained grids and generalize to fine grids using architectures that exploit trunk networks or spectral representations. Crucially, during training, neural operators do not require integration of any operators, as the solution maps are obtained directly, relying on sampled data (albeit on coarse grids) from known operators.

% In the present work, we address the following question in the context of SDEs:
% \textit{Can one learn arbitrary dynamics, where the operators are not prescribed, using an adjoint-free (simulation-free) framework?}

% We answer this question affirmatively by introducing a form of amortized inference for infinitesimal diffusion generators. Specifically, we train a transformer-based neural recognition model to infer the drift and diffusion functions of SDEs. To achieve this, we introduce a generative model that defines a broad probability distribution over the space of drift and diffusion functions. We then sample paths conditioned on these drift and diffusion functions and train a neural network in a supervised fashion to match path realizations to their corresponding drift and diffusion functions.

% Access to the drift and diffusion functions allows our methodology to avoid adjoint methods, making the approach scalable and stable. Furthermore, inference is performed in a zero-shot and context-aware manner, as the network is trained to directly infer drift and diffusion functions from observed paths. This methodology provides a pretrained model capable of immediate inference, bypassing the computational challenges of traditional approaches.

\section{Related Work}
\label{sec:related-work}

As we noted in the Introduction, most available solutions tackling the 
data-driven drift and diffusion estimation problem proceed primarily through Bayesian non-parametrics and symbolic regression.
%
In general, when the observed data is noisy, sparse in time, or both, one faces uncertainty not only in determining the drift and diffusion of the putative SDE, but also in the state of the system itself.
%
Therefore, a Bayesian treatment requires the estimation of the posterior distribution over these states, conditioned on the noisy data (\textit{i.e.}~the so-called smoothing problem).
%
Starting with the seminal works of \citet{archambeau2007gaussian, archambeau2007variational}, which approximated the posterior over the states with a variational and inhomogeneous Gaussian process, 
 %
most proposals have mainly focused on devising different strategies to infer the smoothing distribution --- \textit{while assuming prior parametric forms for the drift and diffusion functions}. See \textit{e.g.}~\citet{VRETTAS20111877}, \citet{wildner2021moment}, or the recent work by \citet{verma2024variational}.
%
A notable exception is the proposal of~\citet{duncker2019learning},  which extended the variational trick of~\citet{archambeau2007gaussian} by imposing a non-parametric prior over the drift of the prior process.
%
However, \citet{archambeau2007gaussian}'s trick has been shown to suffer from significant convergence issues \cite{verma2024variational}, which are inherited by~\citet{duncker2019learning}'s model.
%
In contrast, \citet{batz2018approximate} framed the drift-diffusion estimation problem from uncorrupted (\textit{i.e.}~clean and dense) data as a Gaussian process regression problem,
%
and extended this (non-parametric) approach to observations that are sparse in time, by leveraging Orstein-Uhlenbeck bridges optimized with an expectation maximization algorithm.
%
Nevertheless, this extension can only deal with non-parametric drifts (\textit{i.e.}~the diffusion is restricted to parametric forms) and clean data, and is highly sensitive to the choice of prior hyperparameters.
%
% We will compare our methodology against that of~\citet{batz2018approximate}.

% Despite the recent proliferation of symbolic regression methods, only few of these tackle function estimation for SDEs (see \textit{e.g.}~the reviews by \citet{la2021contemporary} and~\citet{makke2024interpretable})
%
Symbolic regression methods for drift and diffusion estimation mainly extend the SINDy algorithm~\cite{brunton2016discovering} --- which performs sparse linear regression on a predefined library of candidate nonlinear functions --- to SDEs.
%
The first of these extensions corresponds to the work of~\citet{boninsegna2018sparse}, which sets the regression problem by approximating the local values of the drift and diffusion functions with the empirical expectations of Eqs~\ref{eq:drift-definition} and \ref{eq:diffusion-definition} of Section~\ref{sec:preliminaries}.  
%
However, the calculation of these local expectations generally requires significant amounts of data, even for one-dimensional systems.
%
To (somewhat) alleviate this issue, \citet{huang2022sparse} and~\citet{WANG2022244} recently resorted to sparse Bayesian learning, but their solutions still require sizable dataset sizes and, most problematically, assume access to clean and dense observations.
%
In response to this limitations, \citet{course2023state} proposed a hybrid solution that leveraged the variational trick of~\citet{archambeau2007gaussian}, while allowing the drift of the prior process to be approximated by a sparse, linear combination of known basis functions.
%
However, their model inherits the slow convergence problems of the variational approximation. 
%
What is more, all SINDy-like methods are limited by construction to linear combination of the functions in their library, 
%
which therefore makes their performance highly dependent on the preselected functions within the library.

Finally, most neural network models for SDEs rely on black-box parameterizations of the drift and diffusion functions for path (\textit{i.e.}~state) generation. 
%
Prominent examples include the works by~\citet{li2020scalable}, \citet{kidger2021neural}, \citet{bilovs2023modeling} and~\citet{zeng2024latent}. 
%
To the best of our knowledge, our proposal is the first neural network and non-parametric solution to the problem of SDE function estimation --- \textit{and the first to do so in a zero-shot fashion}.

% adjoint computation introduces a high computational burden, leading to stiffness and limited parallelization, which heavily constrains the success of these approaches.
%
%
% In the context of approximate Bayesian inference, the problem of learning the drift and diffusion functions from data has been tackle with the use of Gaussian process priors. In the seminal work of , variational inference is performed for diffusion processes, where the approximating variational family consists of time-variant linear diffusion process. Improvements of this approach include moment based methodologies . Improvement of learning from fixed point \cite{verma2024variational}. Wishard diffusion \cite{jorgensen2020stochastic}. Interpretability conditioning on a set of learned fixed points and local jacobian dynamics . For non linear diffusions, regression was been achieved via EM algorithms using Orstein Uhlenbeck bridges as data likelihoods \cite{batz2018approximate}. All this approaches are based on non parametric estimates based on GPs approximations, and requires a different training per dataset i.e. these are non amortized methods. Furthermore, they typically required if not adjoint methods, forward and backwards paths that are computationally costly.
%
% In the realm of deep neural networks, the seminal paper by \cite{chen18} introduced Neural ODEs (NODE), where the vector field is parameterized using a neural network and trained via backpropagation through the solver using adjoint methods. This approach enabled them to handle continuous dynamics and irregularly sampled time series \cite{rubanova2019latent, kidger2020neural, li2020learning}. Attempts to incorporate stochastic dynamics have explored neural processes \cite{norcliffe2021neural}, variational autoencoders \cite{yildiz2019ode2vae}, and the training of SDE operators as a form of infinite-dimensional GANs \cite{kidger2021neural} or diffusion models \cite{bilovs2023modeling}. This methodologies however requiere adjoint estimates as well as large amount fo data for \textit{one generator}. 


\section{Preliminaries}
\label{sec:preliminaries}

In this section, we briefly introduce SDEs, discuss the basics that underpin our objective functions and formalize the problem we aim to solve.
%
% revisit the change of variable formulas we need to handle observations in multiple length and time scales, and

\subsection{Ito Stochastic Differential Equations}

A Stochastic Differential Equations (SDEs) in the Ito form is defined as
\begin{equation}   
    d \mathbf{x} = \mathbf{f}(\mathbf{x}) dt + \mathbf{G}(\mathbf{x}) d\mathbf{W}(t).
    \label{eq:SDE}
\end{equation}
Given some initial condition $\mathbf{x}(0)$ in $\mathbb{R}^d$, its solution corresponds to a $d$-dimensional stochastic process $\mathbf{x}(t)$. 
%
Let us call $\mathbf{x}(t)$ the \textit{state of the system}. 
%
The vector-valued function $\mathbf{f}: \mathbb{R}^d \rightarrow \mathbb{R}^d$ denotes the state-dependent \textit{drift function} of the process and characterizes the deterministic components of the dynamics. 
%
The matrix-valued function $\mathbf{G}: \mathbb{R}^d \rightarrow \mathbb{R}^{d \times m}$ denotes the state-dependent \textit{diffusion matrix} and controls the stochastic components, which in turn are generated through an $m$-dimensional Wiener process $\mathbf{W}: \mathbb{R}^+ \rightarrow \mathbb{R}^m$.
%
Formally, the drift and diffusion functions are defined as \cite{gardiner2009stochastic}
%
\begin{eqnarray}
    f_i(\mathbf{x}) = \lim_{\Delta t \rightarrow 0} \frac{1}{\Delta t}\int (x'_i - x_i )p(\mathbf{x}', t+\Delta t| \mathbf{x}, t) d\mathbf{x}',
    \label{eq:drift-definition}
\end{eqnarray}
\begin{align} 
    \label{eq:diffusion-definition}
    [\mathbf{G}(\mathbf{x}) \mathbf{G}^T(\mathbf{x})]_{ij}  =& \lim_{\Delta t \rightarrow 0} \frac{1}{\Delta t}\int  (x'_i - x_i )(x'_j - x_j ) \\ \nonumber
    & \times p(\mathbf{x}', t+\Delta t| \mathbf{x}, t) d\mathbf{x}',    
\end{align}
where $p(\mathbf{x}', t+\Delta t| \mathbf{x}, t)$ denotes the probability for the state of the system to evolve from $\mathbf{x}$ into $\mathbf{x'}$ under Eq.~\ref{eq:SDE}, over the infinitesimal time $\Delta t$.
% which is nothing but a Gaussian with variance matrix $\mathbf{G}(\mathbf{x}) \mathbf{G}^T(\mathbf{x})$ and mean $\mathbf{x}+\mathbf{f}(\mathbf{x})\Delta t$.
%
Both symbolic and Gaussian process regression methods proceed by empirically computing these expectations (\textit{i.e.}~histograms), which means they implicitly assume complete access to the ``clean'' state evolution.
%
We instead rely on these expressions to motivate a transformer-based model that disregards the sequential nature of the dynamical processes under study (see Section~\ref{sec:FIM}).
%
In what follows, we shall restrict our attention to diagonal diffusion matrices of the form
\begin{equation}
    \mathbf{G}(\mathbf{x}) = \text{diag}(\sqrt{g_1(\mathbf{x})}, \sqrt{g_2(\mathbf{x})}, \dots, \sqrt{g_d(\mathbf{x})}).
    \label{eq:diffusion-matrix}
\end{equation}
% Let us then define the vector $\mathbf{g}(\mathbf{x})$ containing the diagonal elements of $\mathbf{G}(\mathbf{x})$.

\subsection{Objective Functions and SDE Matching}
\label{sec:objective-functions}

Suppose we are given two function pairs $\big(\mathbf{\hat f}(\mathbf{x}), \mathbf{\hat G}(\mathbf{x})\big)$ and  $\big(\mathbf{f}(\mathbf{x}), \mathbf{G}(\mathbf{x})\big)$.
%
Now suppose both pairs satisfy the necessary conditions (\textit{i.e.}~Lipschitz and linear growth) to define two different SDEs (as defined in Eq.~\ref{eq:SDE}). 
%
In this subsection, we briefly discuss three ways to estimate the divergence between the two pairs on some ``reasonable'' domain\footnote{By ``reasonable'' we loosely mean the subdomain $\mathcal{X} \in \mathbb{R}^d$ that contains the typical set~\cite{thomas2006elements} of both processes $\mathbf{x}(t)|\mathbf{f}, \mathbf{g}$ and $\mathbf{x}(t)|\mathbf{\hat f}, \mathbf{\hat g}$, each evolving according to Eq.~\ref{eq:SDE}.} $\mathcal{X} \in \mathbb{R}^d$.

\textbf{Divergence 1}. As routinely done by the neural operator community~\cite{kovachki2023neural}, we can simply adopt the mean-squared error as divergence measure, and define the local divergence
\begin{equation}
    \mathcal{L}_1(\mathbf{x}) = \sum_{i=1}^D(\hat f_i(\mathbf{x}) - f_i(\mathbf{x}))^2 + (\sqrt{\hat g_i(\mathbf{x})} - \sqrt{g_i(\mathbf{x})})^2,
    \label{eq:loss-1}
\end{equation}
which can be computed by marginalizing $\mathbf{x}$ under a uniform distribution over $\mathcal{X}$.
%
We remark that one can formally motivate this choice by constructing the \textit{infinitesimal generator} of each function pairs, as recently done by~\citet{holderrieth2024generator}.
%
% we could construct the , which, loose speaking, corresponds to the linear term in the short-time Taylor expansion of their corresponding transition kernel.
% %
% Given these generators, we could estimate a divergence between them.
% %
% However, since these generators are parametrized directly by the drift and diffusion functions of their parent SDEs, estimating the divergence between generators reduces to computing a divergence between the corresponding drift and diffusion functions.
%

\textbf{Divergence 2}. Alternatively, we can estimate the Kullback-Leibler divergence between the conditional probabilities of transitioning from state $\mathbf{x}$ into (some) state $\mathbf{x}'$, over a time interval $\Delta t$, as determined by each function pair.
%
For small $\Delta t$ these conditional distributions are approximately Gaussian, which allows us to write down our second  divergence $\mathcal{L}_2$ in closed form.  
%
The reader can find its expression in Eq.~\ref{eq:loss-2} of Appendix~\ref{app:other-obj-functions}.

\textbf{Divergence 3}. Finally, a third divergence $\mathcal{L}_3$ can be defined through the log-likelihood of the short-time transitions induced by one function pair, with respect to the other pair. 
%
We provide its expression in Eq.~\ref{eq:loss-3} of Appendix~\ref{app:other-obj-functions}.
%
% Interestingly, if we were to modify, say, $(\mathbf{\hat f}, \mathbf{\hat G})$ to align with $(\mathbf{f}, \mathbf{G})$ according to $\mathcal{L}_3$, this would imply that $(\mathbf{\hat f}, \mathbf{\hat G})$ must approximate the local noise (in space) generated by $(\mathbf{f}, \mathbf{G})$. 
% %
% This process is analogous to how generative diffusion models are trained to match the local noise (in time) \cite{ho2020denoising}.
% %
% We also note that $\mathcal{L}_2$ and $\mathcal{L}_3$ are the same up to an entropy term. 
% That said, experience tells us that this difference can lead to significantly different training dynamics.

\begin{figure*}[t]
     \centering
     \includegraphics[width=0.7\textwidth]{./figures/fim_sde_new_architecture.pdf} % Replace "path_to_image" with the file path of your image
     \caption{\texttt{FIM-SDE}: Foundation Inference Model for SDE (schematic representation). The (input) context set consists of $K(L-1)$ tuples $\{\mathbf{y}, \Delta \mathbf{y}, \Delta \mathbf{y}^2, \Delta \tau\}$ that are projected by the linear $\phi$ layers. The result is processed by a Transformer encoder network $\Psi$ that returns the \textit{Context Matrix} (Eq.~\ref{eq:context-matrix} in the main text). The context matrix is used as keys and values to the $M$ \textit{Functional Attention Layers} $\psi_{\mathbf{f}}$, $\psi_{\mathbf{G}}$ and $\psi_U$. The queries are instead the embedded location $\Phi_\mathbf{x}^\theta(\mathbf{x})$ on which we evaluate the output functions.}
     \label{fig:fim_sde_architecture}
\end{figure*}

\textbf{Marginalization instabilities}. 
%
The reader will immediately notice that marginalizing $\mathcal{L}_1$ in Eq.~\ref{eq:loss-1} (or $\mathcal{L}_2$, or $\mathcal{L}_3$ of the Appendix) under a uniform distribution, can result in some local contributions dominating the integral --- not due to the divergence itself, but rather \textit{because of the norm of the involved functions in those regions}.
%
One therefore needs a weighting mechanism to balance these contributions over $\mathcal{X}$.
%
 We will return to this issue in Section~\ref{sec:FIM}.

\subsection{Problem Formulation}
\label{sec:problem-formulation}

We are now finally in a position to formulate the problem we aim to solve.
%
Suppose we are given an ordered sequence of $L$ observations $\mathcal{D}^* = \{\mathbf{y}_1^*, \mathbf{y}_2^*, \dots, \mathbf{y}_L^*\}$ of some real-world empirical process $(\mathbf{y}^*(t): \mathbb{R}^+ \rightarrow \mathbb{R}^d)$ recorded at (non-equidistant) times $0 \le \tau_1^* < \dots < \tau_L^* \le T^*$, for some time horizon $T^*$.
%
\textit{Now assume} these observations are generated conditioned on a hidden process $(\mathbf{x}^*(t): \mathbb{R}^+ \rightarrow \mathbb{R}^d)$, governed by a SDE as that defined in Eq.~\ref{eq:SDE}.
%
Our main goal is to construct (non-parametric) neural estimates $\mathbf{\hat f}_{\theta}(\mathbf{x}|\mathcal{D^*})$ and $\mathbf{\hat G}_{\theta}(\mathbf{x}|\mathcal{D}^*)$, with neural parameters $\theta$ and conditioned on the observations $\mathcal{D}^*$, which approximate (\textit{i.e.}~match) the putative drift $\mathbf{f}^*(\mathbf{x})$ and diffusion $\mathbf{G}^*(\mathbf{x})$ functions that best explain $\mathcal{D}^*$ --- on some ``reasonable'' domain $\mathcal{X} \in \mathbb{R}^d$.

As we discussed in Section~\ref{sec:related-work}, the traditional machine learning solution to this problem invariably involves imposing priors over the target functions $\mathbf{f^*}$ and $\mathbf{G^*}$, defining  variational posteriors over the hidden paths $\mathbf{x^*}(t)$, and \textit{fitting the model parameters to} $\mathcal{D}^*$.
%
Our proposal, which we introduce in Section~\ref{sec:FIM}, strongly departs from this tradition.

Some comments regarding notation are in order.
%
We denote with $\mathbf{x}(t)$ simulated SDE processes, and with $\mathbf{x}^*(t)$ unseen, hidden SDE processes. 
%
Similarly, we denote with $\mathbf{y}$ ($\mathbf{y}^*$) corrupted paths (empirical, target data).
%
We also denote probability distribution and their densities, as well as random variables and their values, with the same symbols.


%%%%%%%%%%%%%%%%%%%%%%
% CESAR SECTIONS
%%%%%%%%%%%%%%%%%%%%%%

% %
% \subsection{others}
% %
% This SDE defines a Markov process whose transition kernel \((K_{t+h|t})_{0 \leq t < t+h \leq 1}\) assigns, for every \(\mathbf{x} \in S\), the probability of obtaining the state \(\mathbf{x}_{t+h}\) at time \(t+h\) given that the state at time \(t\) is \(\mathbf{x}\):
% \[
% \mathbb{P}[\mathbf{x}_{t+h} \in A \mid \mathbf{x}_t = \mathbf{x}] = K_{t+h|t}(A \mid \mathbf{x}).
% \]
% Such a kernel can be readily obtained from the solution of the Forward Kolmogorov equation (see App. \ref{app:infinitesimal-generator}). Below, our goal will be to identify both \(\mathbf{f}\) and \(\mathbf{G}\). We now introduce the formalism of infinitesimal generators in order to characterize the pair \(\mathbf{f}\) and \(\mathbf{G}\) as opposed to each individual function. Such characterization will shown to be relevant in the definition of the loss and its associated normalization.
% %
% \textbf{Infinitesimal Generator}
% %
% Informally, the infinitesimal generator is tantamount to the first term in the taylor expansion of the transition kernel. We first introduce a family $u: S \rightarrow \mathbb{R}$ of integrable functions that characterize probability distributions fully. We define the transition action as the average:
% \begin{equation}
% \langle K_{t+h|t},u\rangle(\*x) \overset{\text{def}}{=} \langle K_{t+h|t}(\cdot|\*x),u\rangle = \mathbb{E}\left[u(\*x_{t+h})|\*x_{t}=\*x\right].
% \end{equation}
% Where the average is performed over the kernel distribution  $K_{t+h|t}(\cdot|\*x)$. To define the infinitesimal generator, we can take derivatives of $\langle K_{t+h|t},u\rangle(\*x)$ per $x \in S$ and define:
% \begin{equation}
% \mathcal{L}_{t}u(\*x) \overset{\text{def}}{=}\lim_{h\rightarrow0}\frac{\langle K_{t+h|t},u\rangle(\*x) - u(\*x)}{h}.
% \end{equation}
% We call this action the generator $\mathcal{L}_{t}$ (and define it for all $u$ for which the limit exists uniformly in $x$ and $t$, see app. A.1). For our SDE, the action of the generator on a test function $u$ will be given by:
% \begin{equation}
%     \mathcal{L}_{t}u(\*x) = \nabla u(\*x)^{T}\*f_{t}(\*x) + \frac{1}{2}\nabla^{2}u(\*x)\cdot \*G_{t}(x)
% \end{equation}
% \subsection{Problem Definition}
% Suppose that given Eq. \ref{eq:SDE} we observe a set of paths, $\mathcal{D} = \{\*Y^p\}_{p=1}^P$, where $\*Y^p = (\*y^p(\tau^p_1), \ldots, \*y^p(\tau^p_{N^p}))$ with state observations $\*y^p(\tau^p_j) \in \mathbb{R}^D$ and $\tau^p_j$ as the observation times\footnote{notice that we allow for irregular observation times, which are different per path}. Our goal is to infer the generator $\mathcal{L}_t \equiv \{\*f(\cdot),\*G(\cdot)\}$ (defined by the drift and diffusion pair) from the observed data $\mathcal{D}$.  In the traditional inference paradigm, this is typically achieved through one of two approaches:  
% \begin{enumerate}
%     \item \textbf{Maximum likelihood estimation (MLE):} The functions $\*f$ and $\*G$ are estimated by placing a prior (e.g., a Gaussian process) over them and optimizing the likelihood. In order to achieve better results this can be cast in terms of variational approaches as well as other methodologies such as expectation maximization to handle unknown paths between observations. 
%     \item \textbf{Symbolic basis expansion:} The functions are expressed as an expansion on a symbolic basis, and inference reduces to performing regression over the coefficients of this basis.  
% \end{enumerate}
% These methods require, in the calculation of the loss, that the continuous nature of the model be accounted for. This necessitates either numerical differentiation or the integration of the equations, as the adjoint method must be applied between observations. In other words, the likelihood computation itself introduces significant computational burden because the model must be evaluated between observations. In this work, we aim to eliminate this computational overhead.  
% %
% Another source of computational burden, comes from the framing of the problem itself. Classical approaches address this problem separately for each dataset. In contrast, amortized inference leverages the occurrence of different datasets to accelerate inference for each new dataset. \textit{ The key insight in our work is that we can lift the problem to the space of datasets and use a neural network to learn the inference. This approach not only streamlines the computation but also eliminates the need for adjoint-based calculations.} 
% %
% To achieve this, we introduce distributions over drift functions, $\mathcal{P}_{\*f}$, and diffusion functions, $\mathcal{P}_{\*G}$, so that one is able to sample different generators $\mathcal{L}^i_t \sim\mathcal{P}_{\mathcal{L}} = \mathcal{P}_{\*f} \times \mathcal{P}_{\*G}$. We then simulate different datasets $\mathcal{D}^i$ and aim at:
% \begin{tcolorbox}[colback=gray!10, colframe=black!10, sharp corners]
% \begin{equation}
% P(\mathcal{L}^i_t \mid \mathcal{D}^i)
% \end{equation}
% \end{tcolorbox}
%
% \subsection{Generator Matching}
% In order to obtain \(\mathcal{L}^i\), we will introduce a neural operator \(G^\theta_t : S \rightarrow \Omega \times \Omega\). This neural operator embeds the paths and outputs functional heads corresponding to the drift and diffusion functions \(G_{\mathbf{f}}^\theta[\mathcal{D}^i](\cdot)\) and \(G_{\mathbf{G}}^\theta[\mathcal{D}^i](\cdot)\).
% In order to quantify how close the neural operator representation approximates the real generator we consider the Bregman divergence, a general class of functions that include the Mean Square Loss and the KL-divergence.
% \begin{equation}
%     D(a,b) = \phi(a) - [\phi(b) + \langle a - b, \nabla \phi(b) \rangle]
% \end{equation}
% We use D to measure how well $G^\theta_t$ approximates $F_t$.
% \begin{equation}
%     L_{gm}(\theta) = \mathbb{E}_{\*x , \mathcal{D}^i, \mathcal{L}^i_t } [D(\mathcal{L}^i(\mathbf{x}),G_\theta[\mathcal{D}^i](\*x) )].
% \label{eq:naive_loss}
% \end{equation}

%Amortized inference, aims at exploting  There have been two very recent departures from the classical paradigm. First, \citet{dascoli2024odeformer} trained a recognition model to automatically infer the vector field (i.e.~the drift $\mathbf{f}(\mathbf{x})$ in our notation) of a large dataset of Ordinary Differential Equations (ODEs) from their noisy solution in a supervised fashion. 
%
% Similarly, \citet{berghaus2024foundation} trained a recognition model to automatically infer the rate matrices of a large dataset of Markov jump processes from noisy observation on their realizations. 
%
%In this work we combine aspects of both these works to design a novel framework for \textit{zero-shot inference} of diffusion process, which we name \textit{Foundation Inference Models}. 
%
%Note that we borrow the nomenclature introduced by~\citet{berghaus2024foundation}, who connected their methodology to the amortized inference approach of~\citet{stuhlmuller2013learning}.


\section{Foundation Inference Models}
\label{sec:FIM}

In this section, we propose a novel methodology for \textit{zero-shot estimation} of the drift and diffusion functions that best characterize a target dataset $\mathcal{D}^*$ of interest.
%
As outlined in the Introduction, the methodology involves training a neural network model to map a large set of corrupted SDE paths into their \textit{a priori-known}, target drift and diffusion functions.
%
The latter being sampled from a heuristically constructed synthetic distribution.

The success of this methodology --- namely, that a model (pre)trained solely on synthetic data can help understand and predict unseen empirical processes $\mathcal{D}^*$ --- hinges not only on the inductive biases encoded in the architecture of our model, but also on the family of SDEs represented in the synthetic dataset.
%
Our primary assumption is that, even though we can only consider a very restricted family of drift and diffusion functions, the solution of the SDEs they define can exhibit sufficient complexity to mimic real-world empirical datasets.
%
This assumption resonates with a classical idea popularized by Stephen Wolfram~\cite{wolfram2003new}, but that can be traced back to Kadanoff himself~\cite{kadanoff-1, kadanoff-2}, namely that \textit{simple rules can create complex patterns}.
%
In the experimental section (Section~\ref{sec:experiments}), we empirically demonstrate that our (pre)trained model provides an interpretable picture (\textit{i.e.}~via the estimated drift and diffusion functions) of various synthetic and real-world systems, while also enabling accurate predictions.
%
In what follows, we first introduce our data generation model and then present \texttt{FIM-SDE}, our transformer-based recognition model.
%
% Note that the fact that the training dataset is synthetic implies that we have access to both clean and noisy realizations, as well as the target functions, allowing us to bypass any variational treatment, and framed the estimation problem as a simple regression problem.
%
% Since the training dataset is synthetic, we have access to both clean and noisy realizations, as well as the target functions. This eliminates the need for variational methods and frames the estimation problem as a straightforward regression task.

\begin{figure*}[t]
     \centering
     \includegraphics[width=\textwidth]{./figures/vector_field_plot_synthetic.pdf} 
     \vspace{-0.7cm}
     \caption{Drift and diffusion function estimation in canonical SDE systems with state-dependent diffusion. \textit{Left}: Double-well model. \textit{Right}: Synthetic 2D system from~\citet{WANG2022244}. In contrast to the baselines, \texttt{FIM-SDE} estimates the target functions in \textit{zero-shot} mode. The (zero-shot) results are in remarkable agreement with the ground-truth.}
     \label{fig:double-well-2D-WANG}
\end{figure*}

\subsection{Data Generation Model}
\label{sec:data-gen}

In this subsection, we introduce the data generation model we use to sample a synthetic dataset of corrupted SDE paths of different dimensionalities.
%
Formally, we can define the probability of observing the noisy sequence $\mathbf{y}_1, \dots, \mathbf{y}_L \in \mathbb{R}^d$, at the observation times $0 \le \tau_1 < \dots < \tau_L \le T$, with $T$ the observation time horizon, as follows
%
\begin{align}
    \nonumber
    \prod\limits_{i=1}^L &p_{\text{\tiny noise}}\big(\mathbf{y}_i|\mathbf{x}(\tau_i), \mathbf{f}, \mathbf{G} \big)  p_{\text{\tiny FP}}\big(\mathbf{x}(\tau_i)| \mathbf{f}, \mathbf{G}, \mathbf{x}(0)\big)p\big(\mathbf{x}(0)\big)  \\ &\times p_{\text{\tiny grid}}(\tau_1, \dots, \tau_L) p_{\text{\tiny diff}}( \mathbf{G}|d) p_{\text{\tiny drift}}(\mathbf{f}|d). 
    \label{eq:path-prob}
\end{align}
% \begin{multline}
%     \prod\limits_{i=1}^l p_{\text{\tiny noise}}\big(\mathbf{y}_i, \rho_y|\mathbf{x}(\tau_i) \big) \, p_{\text{\tiny FP}}\big(\mathbf{x}(\tau_i)|, \mathbf{f}, \mathbf{G}, \mathbf{x}(0)\big)p\big(\mathbf{x}(0)\big)  \\ \times p_{\text{\tiny grid}}(\tau_1, \dots, \tau_l) p_{\text{\tiny drift}}(\mathbf{f})p_{\text{\tiny diff}}( \mathbf{G}). 
%     \label{eq:path-prob}
% \end{multline}
Let us briefly specify the main components of Eq.~\ref{eq:path-prob}.

\textbf{Drift function generation}. 
%
Drift functions are sampled from the distribution $p_{\text{\tiny drift}}(\mathbf{f}(\mathbf{x})|d)$, which is conditioned on the system dimensionality $d$, and is defined to factorize as $p_{\text{\tiny drift}}(f_1(\mathbf{x})) \dots p_{\text{\tiny drift}}(f_d(\mathbf{x}))$. 
%
We generate drift functions for processes of different dimensionalities --- ranging from one until some maximum dimension $d_{\text{\tiny max}}$ ---
to ensure the applicability of our methodology across systems with dimension within this range (similar approaches were used by~\citet{berghaus2024foundation} and \citet{dascoli2024odeformer}). 
%
Now, this distribution should represent our beliefs about the class of drift functions we expect to find in nature.
%
In this work, we construct two such distributions: $p^{(1)}_{\text{\tiny drift}}(f(\mathbf{x}))$ and $p^{(2)}_{\text{\tiny drift}}(f(\mathbf{x}))$.
%
The distribution $p^{(1)}_{\text{\tiny drift}}(f(\mathbf{x}))$ is defined over the space of (up to) degree three polynomials with random coefficients,
%
which, albeit simple, covers many important deterministic dynamical systems (as \textit{e.g.}~the famous Lorentz system).
%
The distribution $p^{(2)}_{\text{\tiny drift}}(f(\mathbf{x}))$ is constructed instead over random unary-binary trees following the procedure outlined by~\citet{Lample2020Deep}, which enables \textit{function composition} and thus allows for richer and more expressive dynamics.
%
% This second distribution covers more complex functions than $p^{(1)}_{\text{\tiny drift}}(f(\mathbf{x}))$, as it allows for function composition.
%
We invite the reader to check Appendix~\ref{app:distr-drift} for details regarding the implementations of these distributions.

\textbf{Diffusion function generation}. 
%
Diffusion functions are sampled from the distribution $p_{\text{\tiny diff}}(\mathbf{G}(\mathbf{x})|d)$, which also factorizes as $p_{\text{\tiny diff}}(g_1(\mathbf{x})) \dots p_{\text{\tiny diff}}(g_d(\mathbf{x}))$, where the $g_i(\mathbf{x})$ correspond to the arguments of the square roots in Eq.~\ref{eq:diffusion-matrix}.
%
State-dependent diffusion is common in financial applications and also plays a role in transport problems in condensed matter physics (see~\textit{e.g.}~the classical work by~\citet{buttiker1987transport}).
%
We define $p_{\text{\tiny diff}}(g(\mathbf{x}))$ over \textit{positive} polynomials of degree two with random coefficients, which can represent both geometric Brownian motion like processes, and constant diffusion. 
%
Appendix~\ref{app:distr-diffusion} contains the details.

\textbf{SDE simulation}. The term
%
$p_{\text{\tiny FP}}\big(\mathbf{x}(t)|, \mathbf{f}, \mathbf{G}, \mathbf{x}(0)\big)$
%
denotes the instantaneous solution of the Fokker-Planck equation, which evolves the stochastic process at the ``macroscopic" (path-ensemble) level, given $\mathbf{f}$, $\mathbf{G}$ and some initial condition $p\big(\mathbf{x}(0)\big)$. 
%
In practice, we define $p\big(\mathbf{x}(0)\big)$ as the standard normal distribution and simulate individual paths by solving the corresponding SDE using an Euler-Maruyama scheme with discretization $\Delta t$, until the time horizon $T$.
%
Please refer to Appendix~\ref{app:sde-simulation} for details.

\textbf{SDE corruption}. Empirical data is noisy, often recorded at irregular time intervals, and can feature inter-observation gaps much larger than the microscopic timescale of the dynamics  (\textit{i.e.}~$\Delta \tau \gg \Delta t$).
%
The distribution $p_{\text{\tiny grid}}(\tau_1, \dots, \tau_l)$ represents the uncertainty in the sequence of recording times and we implement it by subsampling our SDE solutions through different schemes.
%
Similarly, the distribution $p_{\text{\tiny noise}}\big(\mathbf{y}_i|\mathbf{x}(t), \mathbf{f}, \mathbf{G}\big)$ is defined to represent \textit{additive} Gaussian noise (\textit{i.e.}~the maximum entropy attractor of empirical noise distributions), with a variance that depends on (the characteristic scale of) the \textit{stochastic} dynamics of the system.
%
Appendix~\ref{app:sde-corruption} provides the details.

% \subsection{Training dataset}

% \begin{table*}[t]
%     \small
%     \centering
%     \begin{tabular}{llllllllll}
%     $\Delta \tau$ & Model & \makecell{Double\\Well} & \makecell{2D-Synt\\(Wang)} & \makecell{Damped\\Linear} & \makecell{Damped\\Cubic} & Duffing & Glycolysis & Hopf & \makecell{Syn\\Drift}\\
%     \hline
%     \rowcolor{table_baselines}0.002 & SparseGP & $0.4(4)$* & $0.07(4)$* & $0.07(3)$* & $0.05(4)$ & N/A & N/A & $0.04(4)$ & $0.07(4)$ \\
%     \rowcolor{table_baselines}0.002 & BISDE & $1.7(2)$ & $0.21(6)$** & $0.13(8)$ & $0.8(2)$ & \textbf{0.06(4)} & $0.09(4)$* & $0.12(5)$ & $0.14(2)$ \\
%     0.002 & FIM & \textbf{0.02(1)} & $0.5(2)$ & $0.7(1)$ & $0.44(9)$ & $0.6(2)$ & $0.7(4)$ & $0.4(1)$ & $0.4(2)$ \\
%     \hline
%     \rowcolor{table_baselines}0.01 & SparseGP & $0.8(9)$ & $0.64(8)$ & N/A & N/A & N/A & $0.41(3)$*** & $0.7(1)$ & $0.62(7)$ \\
%     \rowcolor{table_baselines}0.01 & BISDE & $1.7(2)$ & N/A & $0.44(10)$ & $0.8(2)$ & $0.38(3)$* & $0.6(2)$ & $1.1(1)$ & $0.9(2)$ \\
%     0.01 & FIM & $0.2(2)$ & $0.06(5)$ & $0.03(2)$ & $0.05(4)$ & $0.03(2)$ & $0.03(2)$ & $0.03(2)$ & $0.03(2)$ \\
%     \hline
%     \rowcolor{table_baselines}0.02 & SparseGP & $1.2(2)$* & $1.2(1)$ & N/A & N/A & N/A & N/A & $1.35(8)$ & $1.3(2)$ \\
%     \rowcolor{table_baselines}0.02 & BISDE & $1.7(2)$ & N/A & $1.0(1)$ & $0.8(2)$ & N/A & $1.1(1)$ & $1.83(8)$ & $1.6(1)$ \\
%     0.02 & FIM & $0.06(2)$ & $0.04(3)$ & $0.05(1)$ & $0.02(2)$ & $0.03(1)$ & $0.02(2)$ & $0.031(4)$ & $0.02(1)$ \\
%     \hline
%     \end{tabular}
%     \caption{MMD comparisons of our model versus \texttt{BISDE}~\cite{WANG2022244} and \texttt{SparseGP}~\cite{batz2018approximate}. Lower values are better. We report the mean and standard deviation over five (5) runs. The number of ``*'' denote the number of times the function estimation failed. N/A denote that all estimations (in all runs) failed. All results in this table have been scaled by a factor of 10.}
%     \label{tab:MMD-computations}
% \end{table*}

\begin{table*}[t]
    \small
    \centering
    \caption{MMD comparisons of \texttt{FIM-SDE} against \texttt{BISDE}~\cite{WANG2022244} and \texttt{SparseGP}~\cite{batz2018approximate}. Lower values are better. We report the mean and standard deviation over five (5) runs. The number of ``*'' denote the number of times the function estimation failed. N/A denote that all estimations (in all runs) failed. Underlined scores are the best scores for a given $\Delta \tau$. Bold scores represent best results overall. All results in this table have been scaled by a factor of 10.}
    \begin{tabular}{llllllllll}
    $\Delta \tau$ & Model & \makecell{Double\\Well} & \makecell{2D-Synt\\(Wang)} & \makecell{Damped\\Linear} & \makecell{Damped\\Cubic} & Duffing & Glycolysis & Hopf \\
    \hline
    \rowcolor{table_baselines}0.002 & \texttt{SparseGP} & $0.4(4)$* & 0.07(4)* & \underline{0.07(3)}* & \underline{0.05(4)} & N/A & N/A & \underline{0.04(4)}\\
    \rowcolor{table_baselines}0.002 & \texttt{BISDE} & \textbf{0.01(3)} & \underline{0.05(4)} & $0.13(9)$ & N/A & \underline{0.05(5)} & \underline{0.09(2)*} & $0.13(8)$\\
    0.002 & \texttt{FIM-SDE} & $0.02(1)$ & $0.5(2)$ & $0.7(1)$ & $0.44(9)$ & $0.6(2)$ & $0.7(4)$ & $0.4(1)$ \\
    % \hline
    \rowcolor{table_baselines}0.01 & \texttt{SparseGP} & $0.8(9)$ & $0.64(8)$ & N/A & N/A & N/A & $0.41(3)$*** & $0.7(1)$\\
    \rowcolor{table_baselines}0.01 & \texttt{BISDE} & N/A & $0.8(1)$ & $0.45(7)$ & N/A & $0.41(3)$* & $0.6(1)$ & $1.0(2)$\\
    0.01 & \texttt{FIM-SDE} & \underline{0.2(2)} & \underline{0.06(5)} & \textbf{0.03(2)} & \underline{0.05(4)} & \textbf{0.03(2)} & \underline{0.03(2)} & \textbf{0.03(2)} \\    
    % \hline
    \rowcolor{table_baselines}0.02 & \texttt{SparseGP} & $1.2(2)$* & $1.2(1)$ & N/A & N/A & N/A & N/A & $1.35(8)$\\
    \rowcolor{table_baselines}0.02 & \texttt{BISDE} & N/A & $1.2(1)$ & $0.93(8)$ & N/A & N/A & $1.2(1)$ & $1.83(4)$*\\
    0.02 & \texttt{FIM-SDE} & \underline{0.06(2)} & \textbf{0.04(3)} & \underline{0.05(1)} & \textbf{0.02(2)} & \textbf{0.03(1)} & \textbf{0.02(2)} & \textbf{0.031(4)}\\
    % \hline
    \end{tabular}
    \label{tab:MMD-computations}
\end{table*}


\subsection{\texttt{FIM-SDE}: a Transformer-based Recognition Model}
\label{sec:recognition-model}

Above we introduced a data generation model (Eq.~\ref{eq:path-prob}) for SDEs.
%
Let us suppose that we use this model to generate a large synthetic dataset consisting of tuples of the form $(\mathcal{D}, (\mathbf{f}, \mathbf{G}))$, where $\mathcal{D}$ denotes a set of $K$ corrupted time series $\{\mathbf{y}_{k1}, \dots, \mathbf{y}_{kL} \}_{k=1}^K$ of different dimensionalities, and of $L$ observations each, obtained from the SDE defined by the pair $(\mathbf{f}, \mathbf{G})$.

We now introduce \texttt{FIM-SDE}, a transformer-based architecture that processes instances of $\mathcal{D}$ to produce estimates $\mathbf{\hat f}_{\theta}(\mathbf{x|\mathcal{D}})$, $\mathbf{\hat G}_{\theta}(\mathbf{x|\mathcal{D}})$ that approximate the target pair $(\mathbf{f}, \mathbf{G})$.
%
This means that \texttt{FIM-SDE} must map $\mathcal{D}$ onto the \textit{space of drift and diffusion functions}.
%
We will implement this map leveraging concepts from neural operator, specially DeepONets~\cite{lu2021learning}.
%
However, since each of the tuples $(\mathcal{D}, (\mathbf{f}, \mathbf{G}))$ corresponds to an SDE characterized by distinct spatial and temporal scales, we first need to normalize $\mathcal{D}$ and renormalize the pair $(\mathbf{f}, \mathbf{G})$ accordingly (see Appendix~\ref{app:input-output} for details).
%
This normalization trick makes \texttt{FIM-SDE} \textit{scale agnostic}.

Let $\phi^\theta(\cdot)$ and $\Phi^\theta(\cdot)$ denote linear projections and feed-forward neural networks, respectively. 
%
Let $\psi^\theta(\cdot, \cdot, \cdot)$ denote attention layers,
%
and let $\Psi^\theta(\cdot, \cdot, \cdot)$ denote Transformer encoders with linear attention~\cite{katharopoulos2020transformers}, both of which take three arguments as inputs (\textit{i.e.}~queries, keys and values).
%
Finally, let $\theta$ denote model parameters.

\textbf{Context Matrix} (\textit{Branch-net equivalent}). Upon directly inspecting Eqs.~\ref{eq:drift-definition} and~\ref{eq:diffusion-definition}, we notice that the values of the drift and diffusion functions \textit{at a given location}, say $\mathbf{x}$, only depend on transitions that take place in the ``neighborhood'' of $\mathbf{x}$.
%
In other words, the sequential nature of the data within $\mathcal{D}$ does not seem to encode information relevant to the estimation of the local expectations in Eqs.~\ref{eq:drift-definition} and~\ref{eq:diffusion-definition} (or, at least not directly).
%
We therefore reorganize the data within every set $\mathcal{D}$ into $K(L-1)$ tuples of the form $\mathcal{\tilde D}=\{\mathbf{y}_i, \Delta \mathbf{y}_i, \Delta \mathbf{y}^2_i, \Delta \tau_i\}_{i=1}^{K(L-1)}$, which only keep information about one-step transitions\footnote{That said, note that the $\Delta \tau$ in $\mathcal{D}'$ are much larger than the $\Delta t$ characteristic of our simulations.}.
%
Let us now define the $n$-dimensional embeddings 
\begin{equation*}
    \mathbf{d}^\theta_i = \text{concat}\Big[\phi^\theta_{\mathbf{y}}(\mathbf{y}_i), \phi^\theta_{\Delta \mathbf{y}}(\Delta \mathbf{y}_i), \phi^\theta_{\Delta \mathbf{y}^2}(\Delta \mathbf{y}^2_i), \phi^\theta_{\Delta \tau}(\Delta \tau_i)\Big]    
\end{equation*}
% \begin{equation*}
% \mathbf{D}_{\cdot i}^\theta = \text{concat}\Big[\phi^\theta_{\mathbf{y}}(\mathbf{y}_i), \phi^\theta_{\Delta \mathbf{y}}(\Delta \mathbf{y}_i), \phi^\theta_{\Delta \mathbf{y}^2}(\Delta \mathbf{y}^2_i), \phi^\theta_{\Delta \tau}(\Delta \tau_i)\Big]    
% \end{equation*}
where $i$ runs from 1 to $K(L-1)$ for every element in $\mathcal{\tilde D}$, and the linear projections $\phi^\theta$ map their inputs onto $\mathbb{R}^{n/4}$.
%
Let now $\mathbf{D}^\theta = [\mathbf{d}^\theta_1, \dots, \mathbf{d}^\theta_{K(L-1)}]$ denote the $n\times K(L-1)$ matrix of linear embeddings,
%
and define the (self-attentive) \textit{context matrix}
\begin{equation}
    \mathbf{\tilde D}^\theta = \Psi^\theta(\mathbf{D}^\theta, \mathbf{D}^\theta, \mathbf{D}^\theta), \, \, \text{so that} \, \, \mathbf{\tilde D}^\theta\in \mathbb{R}^{n\times K(L-1)},    
    \label{eq:context-matrix}
\end{equation}
which encodes the entire \textit{context} data $\mathcal{\tilde D}$.



\begin{figure*}[t]
     \centering
     \includegraphics[width=\textwidth]{./figures/vector_field_plot_oil_wind.pdf} 
     \vspace{-0.7cm}
     \caption{Drift and diffusion function estimation in real-world scenarios. \textit{Left}: Oil price fluctuations. \textit{Right}: Wind speed fluctuations. \texttt{FIM-SDE}, which was only trained on synthetic data, remarkably estimates drift and diffusion functions that are in good-agreement with the baselines.}
     \label{fig:EMPIRICAL-FLUCTUATIONS}
\end{figure*}

\textbf{Functional attention mechanism} (\textit{Trunk-net equivalent}). 
%
Having encoded the context data $\mathcal{\tilde D}$ into $\mathbf{\tilde D}^\theta$, we now proceed to compute our function estimates by introducing a type of \textit{functional attention mechanism}.
%
In short, this mechanism takes the embedded location \textit{at which we want to evaluate the output function}, say $\mathbf{x}$, as the query in a sequence of $M$ attention networks. 
%
The keys and values of these networks are instead given by $\mathbf{\tilde D}^\theta$.
%
To illustrate, we focus on the drift function estimates and compute a sequence of $M+1$ location-dependent embeddings
\begin{equation*}
    \mathbf{h}_{i}^\theta(\mathbf{x}|\mathcal{\tilde D}) = \psi_{\mathbf{f},i}^\theta(\mathbf{h}_{i-1}^\theta(\mathbf{x}|\mathcal{\tilde D}), \mathbf{\tilde D}^\theta, \mathbf{\tilde D}^\theta), 
\end{equation*}
with $i$ running from $1$ until $M$, and $\mathbf{h}_{0}^\theta(\mathbf{x}|\mathcal{\tilde D}) = \mathbf{h}_{0}^\theta(\mathbf{x}) = \Phi^\theta_{\mathbf{x}}(\mathbf{x})$.
%
From here, we define
\begin{equation}
    \mathbf{\hat f}_\theta(\mathbf{x}|\mathcal{\tilde D}) = \Phi^\theta_{\mathbf{f}}(\mathbf{h}^\theta_{M}(\mathbf{x} | \mathcal{\tilde D})).
\end{equation}
The calculation of $\mathbf{\hat G}_\theta(\mathbf{x}|\mathcal{\tilde D})$ is analogous.
% \textit{Our main intuition} is that if a model is trained to encode realizations of a given SDE that collectively contain enough information to estimate the local expectations
% %
% $\mathbb{E}\{\mathbf{x}(t+\Delta t)-\mathbf{x}(t)| \mathbf{x}(t)\}$ 
% %
% and 
% %
% $\mathbb{E}\{(\mathbf{x}(t+\Delta t)-\mathbf{x}(t))^2| \mathbf{x}(t)\}$, 
% %
% for $\Delta t$ small, on a set of set of target points $\mathcal{X} \in \mathbb{R}^D$ (that is, if it the model has enough context), 
% %
% it will be able to perform zero-shot inference of the target functions $\mathbf{f}, \mathbf{G}$ from any unseen set of SDE realizations.

\textbf{Target objective}. 
%
We optimize the model parameters $\theta$ to minimize the divergence between our estimates and the target function pair $(\mathbf{f}, \mathbf{G})$ on our ``reasonable'' domain $\mathcal{X}$.
%
For concreteness\footnote{Let us remark that our experiments demonstrated that both $\mathcal{L}_1$ and $\mathcal{L}_2$ (Eq.~\ref{eq:loss-2}) produced very similar training dynamics, and led to (pre)trained models with similar performances. We leave experimenting with $\mathcal{L}_3$ (Eq.~\ref{eq:loss-3}) for future work.}, we choose $\mathcal{L}_1$ in Eq.~\eqref{eq:loss-1} of Section~\ref{sec:preliminaries} and write 
%
\begin{equation}
    \mathcal{L} = \underset{\mathbf{x}\sim \mathcal{U}(\mathcal{X})} {\mathbb{E}}\underset{p(\mathcal{D})} {\mathbb{E}} \left[ e^{-U_\theta(\mathbf{x}, \mathcal{D})} \mathcal{L}^\theta_1(\mathbf{x, \mathcal{D}}) + U_{\theta}(\mathbf{x}, \mathcal{D}) \right],
\end{equation}
%
where we made explicit the dependence of $\mathcal{L}_1$ on both data and trainable parameters, $\mathcal{U}$ denotes uniform distribution, and $p(\mathcal{D})$ labels the generative model of Eq.~\ref{eq:path-prob}.
%
The learnable function $U_{\theta}(\mathbf{x}, \mathcal{D})$ is introduced to address the scaling problem we sketched in Section~\ref{sec:objective-functions}, and can be understood as an (epistemic) uncertainty estimator (see \textit{e.g.}~Appendix B in~\citet{karras2024analyzing}).
%
Similar to our estimation of $\mathbf{\hat f}_\theta$ and $\mathbf{\hat G}_\theta$, we implement $U_{\theta}$ with a third set of $M$ attention functions $(\psi^\theta_{U,1}, \dots, \psi^\theta_{U,M})$, but only back-propagate up to $\mathbf{\tilde D}^\theta$.
%
Figure~\ref{fig:fim_sde_architecture} illustrates the \texttt{FIM-SDE} architecture.


%%%%%%%%%% CESAR AGAIN %%%%%%%%%%%%

% Upon directly evaluating any of these divergences by marginalizing over $\mathbf{x}$, one will invariably find regions of $\mathcal{X}$ at which the divergence is (locally) higher. These contributions will tend to dominate the integration over $\mathbf{x}$.
% %
% It becomes necessary to introduce a weighting mechanism that can balance the contribution of each generator element based on its impact on the support. 

% In \cite{karras2024analyzing}, a continuous generalization of the weighting loss is presented, where a trainable weighting factor is introduced to account for the uncertainty associated with each task. In this context, the pointwise divergence value requires a continuous function \(\lambda(x;\mathcal{D}^i)\) (further details are provided in the appendix). 
%
% The distribution $p(\mathcal{D})$ denotes the generative model of Eq.~\ref{eq:path-prob}.
%
% The factor $\lambda(x;\mathcal{D}^i)$ is implemented as a different head from the representation obtained by the neural operator and only used during training. This approach is akin to the approach \cite{kingma2021variational} where the noising schedule plays the role of a regularization component of the loss weighting the different elements during time. Notice that in diffusion models and operator is also matched during time, only that this is achieved through marginalization of the loss.

\section{Experiments}
\label{sec:experiments}

In this section, we test our methodology on two classes of experiments, namely seven canonical SDE systems of varying complexity and different dimensionalities, and three experimental, real-world systems.
%
The latter consist of human motion and oil price and wind speed fluctuation records, each of which feature noise signals of very varied nature. 
%
We use \textit{one and the same} \texttt{FIM-SDE} to estimate the drift and diffusion functions of each of these systems in \textit{zero-shot mode}. 
%
In other words, we do \textit{not} modify the (pre)trained weights of \texttt{FIM-SDE} before applying it to any of our target datasets.

We (pre)trained a 20M-parameter \texttt{FIM-SDE} on a dataset of 700K SDEs spanning multiple dimensionalities. 
%
Specifically, we constructed three, two and one-dimensional SDEs appearing in a 3:2:1 ratio.
%
Of these, 600K SDEs have polynomial drifts, while the remainder involve more complex drift structures based on function compositions --- that is, they are sampled from $p_{\text{\tiny drift}}^{(1)}(f(\mathbf{x}))$ and $p_{\text{\tiny drift}}^{(2)}(f(\mathbf{x}))$, respectively.
%
The diffusion functions in the ensemble were all sampled from $p_{\text{\tiny diff}}(g(\mathbf{x}))$.
%
Finally, the number of paths (\textit{i.e.}~realizations) processed by the model during (pre)training is uniformly distributed between one and one hundred (because we do not know \textit{a priori} how much data we will have access to in practice).
%
Additional information regarding the (pre)training data distribution, model architecture and hyperparameters, training details and ablation studies can all be found in Appendix~\ref{app:data-gen} and \ref{app:FIM}. 

\textbf{Metrics}. We evaluate the quality of our estimated drift and diffusion functions primarily using three methods.
%
First, we assess them visually by plotting the corresponding vector fields on predefined, uniform grids. 
%
% These grids are computed over our ``reasonable'' $\mathcal{X}$ domains. 
%
Second, when ground-truth functions are available, we compute the mean squared error (MSE) of our estimates on the predefined grid, against the ground-truth values. 
%
Third, we evaluate the quality of sampled realizations from the estimated SDEs by comparing them against held-out trajectories.
%
To quantify this, we compute the maximum mean discrepancy (MMD) between path ensembles, with respect to the signature kernel introduced by~\citet{kiraly2019kernels} (see Appendix~\ref{app:mmd} for some implementation details).

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\textwidth]{./figures/mocap43_latent_dims.pdf} % Replace "path_to_image" with the file path of your image
    \vspace{-0.5cm}
    \caption{Zero-shot forecasting with \texttt{FIM-SDE} of the first 3 PCA components in the motion capture experiment. \texttt{FIM-SDE} infers the vector fields from the context points (black circles) and predicts the targets (red triangles) by sampling paths starting at the last observation. The average prediction is displayed in bold.}
    \label{fig:mocap43_latent_dim}
\end{figure*}

\textbf{Baselines}. We compare our findings against two baselines, namely the Bayesian non-parametric model of~\citet{batz2018approximate}, and the sparse Bayesian and symbolic solution of~\citet{WANG2022244}.
%
Let us refer to them as \texttt{SparseGP} and \texttt{BISDE}, respectively. 
%
For \texttt{SparseGP}, we implemented the \textit{Sparse Gaussian Process for Dense Observations} method following~\citet{batz2018approximate} (see Appendix~\ref{app:baselines}). 
%
For \texttt{BISDE}, we used the open-source implementation\footnote{\url{https://github.com/HAIRLAB/BISDE}} of~\citet{WANG2022244}, and modified its library of functions to only include monomials up to order three, together with sine and exponential functions whose arguments also consists of monomials, up to order three.
%
This way, we (approximately) maintain the same inductive biases encoded into our synthetic datasets, thereby ensuring fairness of comparison.
%
Both baselines assume complete access to the ``clean'' state of the systems, meaning that they are expected to perform well on dense data (that is, $\Delta \tau \simeq \Delta t$, with $\Delta t$ the ``microscopic'' time scale of the target process) without any noise corruption.

\subsection{Canonical SDE systems}

In this subsection, we study seven widely different SDE systems, which we define in Appendix~\ref{app:canonical-sdes}, among which one finds the classical (one-dimensional) double-well system with state-dependent diffusion --- a common case study in the Bayesian community.
%
We first solve each system using an Euler-Maruyama step of $(\Delta t=)0.002$, thereby setting the ``microscopic'' time scale of the system(s), until a time horizon $T=10$.
%
In contrast, \texttt{FIM-SDE} was (pre)trained on corrupted SDE paths whose inter-observation time distribution $p(\Delta \tau)$ peaks at around $0.08$ (see Appendix~\ref{app:sde-corruption} for details).
%
To assess the robustness of \texttt{FIM-SDE} to varying inter-observation times, we construct three different experiments per target SDE.
%
The first preserves the ``microscopic'' time scale with $\Delta \tau = \Delta t=0.002$. 
%
The other two use coarser inter-observation times, namely $\Delta \tau = 0.01$ and $\Delta \tau = 0.02$ (still shorter than the mean $\Delta \tau$ within our synthetic distributions), but are all defined to contain the same number of observations\footnote{Note that the ``microscopic'' or simulation scale $\Delta t=0.002$ is, of course, preserved in all three experiments.}.
%
We make use of \texttt{FIM-SDE}, as well as our baselines, to estimate the (hidden) ground-truth drift and diffusion functions, and repeat the experiments \textit{five times}. That is, we generate five independent datasets with the features described above.
%
Clearly, both baselines need to be trained from scratch on all these systems and configurations.
%
\texttt{FIM-SDE} is instead used off-the-shelf, with no modification throughout all experiments.

Table~\ref{tab:MMD-computations} contains the MMD calculations for all three experiments and all seven SDE systems, averaged over the five runs.
%
The emergent picture is clear. \texttt{FIM-SDE} outperforms all baselines in every dataset at the coarser scales ($\Delta \tau=0.01$, $0.02$). 
%
At the finer, ``microscopic'' scale \texttt{BISDE} dominates.
%
Surprisingly both \texttt{BISDE} and \texttt{SparseGP} often estimate SDEs with no solution.
%
\texttt{FIM-SDE} is stable in this regard.
%
Figure~\ref{fig:double-well-2D-WANG} displays the inferred drift and diffusion functions for the double-well system and the two-dimensional synthetic system of~\citet{WANG2022244} (Eqs.~\ref{eq:wang1} and \ref{eq:wang2} in the Appendix) by all models, at the setting they perform best.
%
\texttt{FIM-SDE} estimations are in excellent agreement with the ground-truth.
%
Table~\ref{tab:MSE-results-vector-fields} in the Appendix provides a consistent and complementary picture.

\subsection{Real-world systems}

In this subsection, we use \texttt{FIM-SDE} to understand wind speed and oil price fluctuations, comparing our findings against the results of~\citet{WANG2022244}, who originally collected and analyzed these datasets (see Appendix~\ref{app:real-world-fluctuations}).
%
Both systems exhibit inherent stochasticity.
%
For example, wind speed fluctuations have recently been described using Ornstein-Uhlenbeck (OU) processes with linear diffusion~\cite{loukatou2018stochastic}.
%
Similarly, oil price fluctuations have been modeled as geometric Brownian motion (GBM), which also assumes linear diffusion~\cite{noh2016analysis, yang2024predicting}.
%
We optimize \texttt{BISDE} on both datasets and directly apply \texttt{FIM-SDE} to them.
%
Figure~\ref{fig:EMPIRICAL-FLUCTUATIONS} demonstrates that, at small fluctuation scales, both models generally align with GBM but, at larger scales, exhibit additional structure.
%
However, Table~\ref{tab:MMD-FLUCTUATIONS} demonstrates that our estimates provide a better description of the empirical data.

We conclude this section by demonstrating that \texttt{FIM-SDE} can also perform \textit{zero-shot forecasting} of human motion recordings, using only about 50(!) observations as context data (see Figure~\ref{fig:mocap43_latent_dim}).
%
We refer the reader to Appendix~\ref{app:MOCAP} for details on the dataset and to Table~\ref{tab:mocap43_mean_predictions} for preliminary comparisons with other neural models.

\section{Conclusions}
\label{sec:conclusions}

In this work, we introduced a novel methodology for \textit{zero-shot estimation} of drift and diffusion functions from data.
%
We empirically demonstrated that \textit{one and the same} \texttt{FIM-SDE} was able to correctly characterized various synthetic and real-world systems of different dimensionalities, while performing on par with SOTA models trained on the target datasets.
%
\textit{The main limitation of our methodology} is naturally imposed by our synthetic training distributions.
%
Indeed, we empirically verified in Tables~\ref{tab:MMD-computations} and \ref{tab:MSE-results-vector-fields} that evaluating \texttt{FIM-SDE} on systems whose microscopic scale $\Delta t$ is out-of-distribution can lead to weaker estimates. 
%
\textit{Future work} will broaden $p(\Delta \tau)$ within our training set, and investigate how to minimize its role through novel instance normalization mechanisms.


\section*{Impact Statement}
\label{sec:impact}
\texttt{FIM-SDE} can have a strong impact in the scientific community, specially from the point of view of \textit{accessibility}.
%
The traditional machine learning paradigm requires practitioners to have access to high-quality datasets and substantial computational resources.
%
It also requires them to have the experience and expertise to train state-of-the-art models from scratch.
%
Foundation models --- like \texttt{FIM-SDE} ---  do not necessarily require machine expert knowledge, which implies that they (foundation models) can be used by a broader community of scientists and engineers.

\section*{Acknowledgements}
\label{sec:acknoledgement}

This research has been funded by the Federal Ministry of Education and Research of Germany and the state of North-Rhine Westphalia as part of the Lamarr Institute for Machine Learning and Artificial Intelligence.
%
Additionally, C\'esar Ojeda was supported by the Deutsche Forschungsgemeinschaft (DFG) -- Project-ID 318763901 -- SFB1294.

\bibliography{bibliography}
\bibliographystyle{icml2024}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\appendix

\onecolumn
\section{Relation with Early Amortized and Meta-learning Approaches}
\label{app:related-work}

\textbf{On the concept of amortization}. Our methodology can be understood as an \textit{amortization} of the  probabilistic inference process (of the drift and diffusion functions) through a single neural network, and is therefore akin to the works of~\citet{stuhlmuller2013learning},~\citet{heess2013learning} and~\citet{paige2016inference}.

Rather than treating, as these previous works do, our (pre)trained models as auxiliary to Monte Carlo or expectation propagation methods, 
%
we employ them to directly estimate the drift and diffusion functions from various synthetic, simulation and experimental datasets, \textit{without any parameter fine-tuning}. 

\textbf{On conditional neural network models and meta-learning}. Different from the ``foundation models'' trained on synthetic datasets (like \texttt{FIM-SDE}), \textit{conditional neural network models} --- such as the neural statistician~\cite{edwards2016towards, hewitt2018variational} or members of the neural process family~\cite{garnelo2018neural, garnelo2018conditional, kim2019attentive} --- are trained across sets of different, albeit related datasets, \textit{each assumed to share a common context latent variable}

These meta-learning models are trained exclusively on (sets of) datasets \textit{from their target domains}, rendering both their optimized weights and the \textit{representations they can infer} (that is, their latent variables) problem/data specific.
%

% By this we meant that — keeping with the example of Jiang et al. (2023) – the parameters of the neural network building of the model of Jiang et al. (2023) are not the same for the bouncing ball experiment and the turbulent flow experiment. Similarly, the semantic content of the shared representations inferred by the model of Jiang et al. (2023) is not the same for the bouncing ball experiment and the turbulent flow experiment. In the former case it corresponds to gravity, whereas in the latter it corresponds to buoyant force.

In contrast, our method maintains the same network parameters and representation semantics throughout all experiments. The representations consistently correspond to drift and diffusion functions of SDEs, regardless of the target dataset.

\section{Alternative Objective Functions for SDE Matching}
\label{app:other-obj-functions}

In this section, we provide the explicit expression two alternative divergences between SDE processes.

\textbf{Divergence 2}. We can estimate the Kullback-Leibler divergence between the conditional probabilities of transitioning from state $\mathbf{x}$ into (some) state $\mathbf{x}'$, over a time interval $\Delta t$, as determined by each function pair --- that is, $p(\mathbf{x}', t+\Delta t| \mathbf{x}, t, \mathbf{\hat f}, \mathbf{\hat G})$ and $p(\mathbf{x}', t+\Delta t| \mathbf{x}, t, \mathbf{f}, \mathbf{G})$.

For small $\Delta t$ these conditional distributions are approximately Gaussian, which allows us to define the second divergence as 
%
\begin{align} 
    \label{eq:loss-2}
    \mathcal{L}_2(\mathbf{x}) = \frac{1}{2} \Big[\sum_{i=1}^D\frac{(\hat f_i(\mathbf{x}) - f_i(\mathbf{x}))^2 \Delta t}{g_i(\mathbf{x})} + \frac{\hat g_i(\mathbf{x})}{g_i(\mathbf{x})} +\log g_i(\mathbf{x})- \log\hat g_i(\mathbf{x})-1\Big].    
\end{align}
%
\textbf{Divergence 3}. We can  compute the log-likelihood of the short-time transitions induced by one function pair, say $(\mathbf{f}, \mathbf{G})$, with respect to the second pair. 
%
Specifically, we write
%
\begin{align}         
    \mathcal{L}_3(\mathbf{x}) = -\frac{1}{2} \, \mathbb{E}_{p(\mathbf{x'}|\mathbf{x}, \mathbf{f}, \mathbf{G})} \Big[\sum_{i=1}^D\frac{(x_i'-x_i - \hat f_i(\mathbf{x}) \Delta t)^2 }{\hat g_i(\mathbf{x})\Delta t} - \log \hat g_i(\mathbf{x}) \Delta t\Big],
    \label{eq:loss-3}
\end{align}
where $p(\mathbf{x'}|\mathbf{x}, \mathbf{f}, \mathbf{G})$ denotes the short-time transition probability according to the function pair $(\mathbf{f}, \mathbf{G})$.

\textit{Interestingly}, if we were to modify $(\mathbf{\hat f}, \mathbf{\hat G})$ to align with $(\mathbf{f}, \mathbf{G})$ according to Eq.~\ref{eq:loss-3}, this would imply that $(\mathbf{\hat f}, \mathbf{\hat G})$ must approximate the local (in space) noise generated by $(\mathbf{f}, \mathbf{G})$. 
%
This process is analogous to how generative diffusion models are trained to match noise locally in time \cite{ho2020denoising}.

\section{Synthetic Data Generation Model: Details}
\label{app:data-gen}


\subsection{Distribution Over Drift Functions}
\label{app:distr-drift}

In this subsection, we construct two distributions over the components of the drift function.

\textbf{Distribution} $p^{(1)}_{\text{\tiny drift}}(f(\mathbf{x}))$ \textbf{over degree three polynomials}. 
%
Let us describe our sampling scheme for polynomials of degree three (or less), which define the components of a $D \leq D_{\text{\tiny max}}$ dimensional process. 
%
A polynomial is uniquely defined by a finite set of monomials with non-zero coefficients, and coefficients for these monomials. 
%
For a single polynomial, our procedure first samples such set of monomials, and then samples (\textit{a.s.}) non-zero coefficients for these monomials:
%
\begin{enumerate}
    \item Sample the number of monomial degrees $N_{\text{\tiny deg}} \sim \mathcal{U}[1, \dots, D_{\text{\tiny max}}]$ included in the polynomial. 
    \item Sample\footnote{For a set $S$ and $k\in \mathbb{N}$ we denote by $\mathcal{P}_k[S]$ the set of subsets of $S$ with $k$ elements.} $\{d_1, \dots, d_{N_{\text{\tiny deg}}}\}\sim\mathcal{U}[\mathcal{P}_{N_{\text{\tiny deg}}}[\{0, \dots, D\}]]$, the set of monomial degrees included in the polynomial.
    \item For each $i \in \{1, \dots, N_{\text{\tiny deg}}\}$,  sample $N_{\text{\tiny mon}}^i \sim \mathcal{U}[1,\dots, \binom{d_i + D - 1}{d_i} ]$, the number of monomials of degree $d_i$ included in the polynomial.
    \item For each $i \in \{1, \dots, N_{\text{\tiny deg}}\}$,  sample from $\mathcal{U}[\mathcal{P}_{N_{\text{\tiny mon}}^i}[\{x^\alpha | \left|\alpha\right| = d_i\}]]$, the subset of monomials of degree $d_i$ included in the polynomial. 
    \item Sample the coefficients for the included monomials from $\mathcal{N}(0, 1)$. 
\end{enumerate}
%
The uniform distributions cover a broad range of degree three polynomials, while the hierarchical sampling scheme ensures some sparsity (regarding monomials with non-zero coefficients) and correlation between monomials of the same degree throughout the whole dataset


\textbf{Distribution} $p^{(2)}_{\text{\tiny drift}}(f(\mathbf{x}))$ \textbf{over unary-binary trees}.
%
We simply follow the data generation procedure of~\citet{dascoli2024odeformer} (Section 3), but restrict the unary operators to: $\sin$, $\exp$ and $x^2$. 
%
In other words, we replaced the inverse function with the exponential function.
%
These general random unary-binary method for function construction was introduced by~\citet{Lample2020Deep}.






%We construct further drift functions by sampling random unary-binary trees, following \cite{}. 
%%
%These enable more flexible 
%
%sin
%x^2
%exp




\subsection{Distribution Over Diffusion Functions}
\label{app:distr-diffusion}
In this subsection, we define the distribution $p_{\text{\tiny diff}}(g(\mathbf{x}))$ over the components of the diffusion functions.

Recall from \eqref{eq:diffusion-matrix} that we only consider diagonal diffusion matrices, with components of the form $\sqrt{g(\mathbf{x})}$ for some non-negative function $g$. 
%
Guided by some of our target processes, we first sample $\tilde{g}$ as a polynomial of maximal degree $2$, using the procedure described in Appendix \ref{app:distr-drift}. 
%
Because $\tilde{g}$ can attain negative values, we define the (sampled) component function by 
\begin{equation}    
g(\mathbf{x}) =\max\left(0, \tilde{g}(\mathbf{x})\right). 
\end{equation}

Note that some diffusion component functions sampled by this procedure contain (large) regions with low, or even zero diffusion (\textit{e.g.} when $\tilde {g} $ is a constant of negative value). 
%
In practice, we found that our trained model can therefore also approximate (almost) deterministic systems. 


%\begin{equation}
%    g_i(\mathbf{x})  =  \max\left(0,  \sum_{j=1}^D \left( \sum_{k=1}^D \alpha_{jk} x_j x_k \right)+ \beta_j x_j + \gamma \right)
% \end{equation}

% with $\alpha_{jk} = s_1 \tilde \alpha_{jk}$, $\beta_{j} = s_2 \tilde \beta_{j}$ and  $\gamma = s_3 \tilde \gamma$ where $s_1, s_2, s_3 \sim \text{Bernoulli}(p)$ and  $\tilde \alpha_{jk}, \tilde \beta_j, \tilde \gamma \sim \mathcal{N}(0, \sigma)$.

\subsection{SDE simulations}
\label{app:sde-simulation}

In this subsection we expatiate upon our simulation procedure.

Given the drift function $\mathbf{f}(\mathbf{x})$ and the diffusion function $\mathbf{G}(\mathbf{x})$, sampled as described in sections \ref{app:distr-drift} and \ref{app:distr-diffusion}, we solve the corresponding SDE (that is, sampled the paths) using the Euler–Maruyama method. For performance reasons, we use the \textsc{julia} programming language \citet{bezanson2017julia} and the solver implementation of the \textsc{DifferentialEquations.jl} package \citet{rackauckas2017differentialequations,rackauckas2017adaptive}.

For each equation, we realize $K=100$ simulations. 
%
Concretely, we sample set of $K$ initial states from $\mathcal{N}(0, 1)$ and simulate the equation with discretization $\Delta t = 0.004$ in the time interval $[0, T]$, where we set $T=10$. 
%
Should the simulation of a single path fail (e.g. include \texttt{NaN} or \texttt{Inf} values), we discard the equation, sample a new equation and repeat the simulation process. 
%
Similarly, we discard diverging systems by discarding equations, if the absolute value of one component of one path exceeds a threshold value of $100$. 


\subsection{\textbf{SDE corruption}}
\label{app:sde-corruption}

In this subsection we describe how we implement the distribution $p_{\text{\tiny grid}}(\tau_1, \dots, \tau_l)$ (over the \textit{sequence recording times}) and $p_{\text{\tiny noise}}\big(\mathbf{y}_i|\mathbf{x}(t), \mathbf{f}, \mathbf{G} \big)$ (over the optional \textit{corruption} of the process values).

\textbf{Regular observation grids.} By default, we consider regular, coarse observation grids. 
%
To realize such observations of our sampled equations, we subsample the fine grid simulations from Appendix \ref{app:sde-simulation} by a factor of $20$, yielding $L=128$ observations on the regular grid in $[0, 10]$. 
% 
In other words, the sequences are (by default) recorded with a \textit{regular inter-observation gap} of $\Delta \tau = 0.08$. 

\textbf{Irregular observation grids}. To accommodate applications with \textit{irregular inter-observation gaps}, we subsample these regular grids with an additional sampling scheme using the Bernoulli distribution. 
%
Given the regular, coarse observations of a process, we sample a Bernoulli survival probability $\eta \sim \mathcal{U}[0.9, 1]$. 
%
The irregular observation grid for a given process are then realized by sampling the Bernoulli distribution with survival probability $\eta$ at each observation. 

\textbf{Additive Gaussian noise.} To make the model more robust, e.g. for real world applications, we corrupt the (clean) observations $\{\mathbf{x}_i \}_{i=1}^{K\times(L-1)}$ of a process $(\mathbf{f}, \mathbf{G})$ by additive Gaussian noise. 
%
The standard deviation is determined \textit{relative to the observed values}. 
%
Concretely, let us define the component-wise \textit{range} of the process:  
\begin{equation}
    r({\mathbf{x}(t), \mathbf{f}, \mathbf{G}}) = \frac{1}{2} \left( \max_{\substack{i=1, \dots,K\times(L-1)}}\mathbf{x}_{i} - \min_{\substack{i=1, \dots,K\times(L-1)}}\mathbf{x}_{i} \right)
\end{equation}

To realize the additive Gaussian noise, we first sample a \textit{noise scale} $\sigma({\mathbf{x}(t), \mathbf{f}, \mathbf{G}}) \sim \mathcal{U}[0,0.1]$ for the given (clean) observations of a process. 
% 
Then, each observation is corrupted by samples from $\mathcal{N}(0, \sigma({\mathbf{x}(t), \mathbf{f}, \mathbf{G}})  r({\mathbf{x}(t), \mathbf{f}, \mathbf{G}}))$. 
In other words: 
\begin{equation}
    p_{\text{\tiny noise}}\big(\mathbf{y}_{i}|\mathbf{x}(t), \mathbf{f}, \mathbf{G} \big) = \mathcal{N}(\mathbf{x}_{i}, \sigma({\mathbf{x}(t), \mathbf{f}, \mathbf{G}}) r({\mathbf{x}(t), \mathbf{f}, \mathbf{G}})) 
\end{equation}

In practice, each corruption scheme is applied to a third of the total training dataset. 
%
These corruptions might overlap, i.e. observations of a process can be noisy and on an irregular grid.

Note that a \cite{course2023state} employ a similar \text{relative additive noise scheme} in some of their experiments on synthetic data. 
%
However, they define the range of a process based on the associated \textit{ODE process}, i.e. with zero diffusion. 


% \section{Infinitesimal Generators}
% \label{app:infinitesimal-generator}
% This SDE has and associated Fokker Planck equation whose solution yields the evolution of the probability distribution by:
% \begin{equation}
%     \begin{aligned}
%         \frac{\partial p(\mathbf{x}, t)}{\partial t} &= 
%         -\nabla \cdot \big( \mathbf{f}(\mathbf{x}) p(\mathbf{x}, t) \big) \\
%         &\quad + \frac{1}{2} \nabla \cdot \big( \nabla \cdot \big( 
%         \mathbf{G}(\mathbf{x}) \mathbf{G}^\top(\mathbf{x}) p(\mathbf{x}, t) \big) \big).
%     \end{aligned}
%     \label{eq:FokkerPlanck}
% \end{equation}

% Due to the Markov assumption, there is a one-to-one correspondence between a Markov process and a transition kernel paired with an initial distribution \(p_0\). We impose loose regularity assumptions on \(\mathbf{X}_t\), which are listed in Appendix.

% Let us consider the transition kernel \(k_{t+h|t}\) for small \(h > 0\). Specifically, we consider an \emph{informal} first-order Taylor approximation in \(t\) with an error term \(\mathcal{O}(h^2)\):  
% \[
% k_{t+h|t} = k_{t|t} + h \mathcal{L}_t + o(h), \quad \mathcal{L}_t := \frac{d}{dh} \bigg|_{h=0} k_{t+h|t}, \quad k_{t|t}(\cdot \mid \mathbf{x}) = \delta_{\mathbf{x}},
% \]
% where \(\mathcal{L}_t\) is the \textbf{generator} of \(k_{t+h|t}\) \citep{ethier2009markov, rueschendorf2016}.  

% We call the first-order derivative \(\mathcal{L}_t\) the \textbf{generator} of \(k_{t+h|t}\). Similar to derivatives, generators are first-order linear approximations and, as we will see, easier to parameterize than \(k_{t+h|t}\). Diffusion, flow, and other generative models can all be seen as algorithms to learn the generator of a Markov process (see Table~\ref{table:1}). However, as a probability measure is not a standard function, Equation~\eqref{eq:5} is not well-defined yet. We will make it rigorous using \emph{test functions}.

\section{Foundation Inference Models: Details}
\label{app:FIM}


\subsection{Instance Normalization and Change of variable formulas (Input Pre-processing, Outputs Post-processing)}
\label{app:input-output}

Observation sequences on different dynamical process are naturally characterized by different spatial and temporal length scales. 
%
To handle such sequences in a consistent manner, we introduce \textit{component-wise instance normalization transformations}.
%
We pre-process the inputs to our model before application, and post-process the outputs according to the relevant change of variables formulas. 

Continuing the notation from \ref{sec:recognition-model}, let the data $\mathcal{D}'=\{\mathbf{y}_i, \Delta \mathbf{y}_i, \Delta \mathbf{y}^2_i, \Delta \tau_i\}_{i=1}^{K(L-1)}$ and a location $\mathbf{x}$ be the inputs of \texttt{FIM-SDE}. 
%
We consider linear normalization transformations, so the normalizations of $\Delta \mathbf{y}$, $\Delta \mathbf{y}^2$ and $\Delta \tau$ are implied by the normalization transformations of $\mathbf{y}$ and $\tau$. 

\textbf{Spatial instance normalization.} Before applying our model, we \textit{standardize} the observations $\{\mathbf{y}_i\}_{i=1}^{K(L-1)}$ \textit{component-wise}. 
%
Let $y_{ij}$ denote the $j$-th component of $\mathbf{y}_i$. 
%
Then the $j$-th component of the observations are standardized using 
\begin{equation}
    \bar{y}_{i} = \frac{1}{K(L-1)}\sum_{j=1}^{K(L-1)} y_{ij} \quad \text{and} \quad s_i = \sqrt{\frac{1}{K(L-1)}\sum_{j=1}^{K(L-1)} (y_{ij} - \bar{y}_i)^2} \quad . 
\end{equation}

It is important to apply \textit{the same} standardization transformation to the location $\mathbf{x}$, because they are elements of the now transformed domain.

\textbf{Temporal instance normalization.} The absolute time $\tau_i$of an observation is not an input of our model. 
%
We therefore normalize $\Delta \tau_i$ directly. 
%
However, during application (as well as some part of our training data), $\Delta \tau_i$ might be constant, i.e. the input observations are on a regular grid. 
%
Moreover, $\Delta \tau_i$ might differ (vastly) between applications, even if all of them are on a regular grid. 
%
We therefore only \textit{centralize} $\{\Delta \tau_i\}_{i=1}^{K(L-1)}$ around a target value, while keeping the inter-observation gaps positive for interpretability.

Let $\Delta \tau_\text{\tiny tar}=0.01$ be a target inter-observation gap after normalization and 
\begin{equation}
    \bar{\ln}_{\Delta \tau} = \frac{1}{K(L-1)}\sum_{j=1}^{K(L-1)} \ln\Delta \tau_{ij}
\end{equation}
the mean of $\{\ln \Delta \tau_i\}_{i=1}^{K(L-1)}$. 
%
Then we normalize the inter-observation gaps by applying the transformation
\begin{equation}
    \Delta \tau  \mapsto \Delta \tau_{\text{\tiny tar}}  \exp(-\bar{\ln}_{\Delta \tau})  \Delta\tau \quad . 
\end{equation}
%
In other words, we center $\{\ln \Delta \tau_i\}_{i=1}^{K(L-1)}$ at $\ln \Delta \tau_{\text{\tiny tar}}$. 
%
Note that the (unique) corresponding transformation of absolute time, that retains $\tau=0$, is 
\begin{equation}
    \tau \mapsto \Delta \tau_{\text{\tiny tar}}  \exp(-\bar{\ln}_{\Delta \tau}) \tau \quad .
\end{equation}

\textbf{Change of variable formulas.} Let us briefly recall the change of variable formulas relevant for our setting. 
%
Consider now $dx(t) = f(x(t))dt + G(x(t))dW(t)$, a one-dimensional SDE with purely state-dependent drift and diffusion functions. 
%
The normalization transformations described above (and also their inverses) are linear maps $\tilde{x}(x) = \alpha x + \beta$ (spatial transformation) and  $\tilde{t}(t) = \gamma t$ (temporal transformation) for some $\alpha, \beta, \gamma \in \mathbb{R}$.  
%
Then the equation of the transformed process $d\tilde{x}(x)(\tilde{t})$ is 
\begin{equation}
    d\tilde{x}(x)(\tilde{t}) = \frac{\alpha}{\gamma} f(x(\gamma^{-1}\tilde{t})) d\tilde{t} + \frac{\alpha}{\sqrt{\gamma}} G(x(\gamma^{-1}\tilde{t}))dW(\tilde{t})
\end{equation}
according to Ito's formula and Theorem 8.5.7 in~\citet{oksendal2010stochastic}. 


\textbf{Inverse vector fields transformation.} Let $\mathbf{\hat f}_\theta(\mathbf{x}|\mathcal{D}')$ and $\mathbf{\hat G}_\theta(\mathbf{x}|\mathcal{D}')$ be the vector field values at location $x$, estimated by \texttt{FIM-SDE}, given instance normalized inputs. 
%
As the inputs have been instance normalized, these outputs define processes in the \textit{normalized domain}. 
%
By the change of variables formulas above, the corresponding process in the \textit{data domain} is defined by the drift and diffusion
\begin{equation}
 \mathbf{\hat f}_\theta(\mathbf{x}|\mathcal{D}') s_i \Delta \tau_\text{\tiny tar} \exp(-\bar{\ln}_{\Delta_\tau}), \quad  \mathbf{\hat G}_\theta(\mathbf{x}|\mathcal{D}') s_i \sqrt{\Delta \tau_\text{\tiny tar} \exp(-\bar{\ln}_{\Delta_\tau})} \quad .
\end{equation}

%To handle such sequences in a consistent manner we introduce (component-wise) normalized state $\bar{x}_i = \alpha_i x_i + \beta_i$ and time $\bar{t}=\gamma \, t$ variables.
%%
%The corresponding SDE of the normalized system follows from Ito's formula and Theorem 8.5.7 in~\citet{oksendal2010stochastic}  
%
%\begin{equation}   
%    d \bar{x}_i = \sum_i \frac{\alpha_i}{\gamma} f_i(\mathbf{\bar{x}})  d\bar{t} + \sum_{j} \frac{\alpha_i}{\sqrt{\gamma}} G_{ij}(\mathbf{\bar{x}}) d W_j(\bar{t}).
%    \label{eq:normalized-SDE}
%\end{equation}
%
%We consider the following normalizations


%% OLD VERSION OF NORMALIZATION
%The model should be applicable to observations of all scales. 
%%
%We therefore use min-max-normalization for the model's inputs \textit{per collection of paths} (\textit{i.e.} \textit{instance normalization}) and \textit{per dimension} (\textit{i.e.} \textit{a channel independent strategy}). 
%%
%The model's outputs are renormalized accordingly.
%
%To express this strategy in equations, let $\{(\mathbf{y}_{k1}, \tau_{k1}), \dots, (\mathbf{y}_{kl}, \tau_{kl})\}_{k=1}^K$ be the collection of $K$ paths with observations $\mathbf{y}_{ki} \in \mathbb{R}^D$ at time $\tau_{ki} \in \mathbb{R}_+$ with $\tau_{k1}=0$. 
%%
%Let $\mathbf{y}_{ki}^d$ be the $d$~-th component of observation $\mathbf{y}_{ki}$ and denote
%
%\begin{equation}
%%\tau_{\text{min}} = \min_{\substack{i=1, \dots, l \\ k=1, \dots, K}} \tau_{ki}, \quad 
%\tau_{\text{max}} = \max_{\substack{i=1, \dots, l \\ k=1, \dots, K}} \tau_{ki}, \quad 
%\mathbf{y}_{\text{min}}^d = \min_{\substack{i=1, \dots, l \\ k=1, \dots, K}} \mathbf{y}_{ki}^d,   \quad 
%\mathbf{y}_{\text{max}}^d = \max_{\substack{i=1, \dots, l \\ k=1, \dots, K}} \mathbf{y}_{ki}^d \quad .
%\end{equation}
%
%Before applying our model, we replace its inputs by their normalized values:
%\begin{equation}
%\label{eq:normalization_maps}
%\mathbf{y}_{ki}^d \leftarrow \frac{\mathbf{y}_{ki}^d - \mathbf{y}_{\text{min}}^d}{\mathbf{y}_{\text{max}}^d - \mathbf{y}_{\text{min}}^d}, \quad \mathbf{x}^d \leftarrow \frac{\mathbf{x}^d - \mathbf{y}_{\text{min}}^d}{\mathbf{y}_{\text{max}}^d - \mathbf{y}_{\text{min}}^d}, \quad \tau_{ki} \leftarrow \frac{\tau_{ki} }{\tau_{\text{max}}}
%\end{equation}
%
%Consider now the outputs $\mathbf{\hat f}(\mathbf{x}), \log \text{Var}(\mathbf{\hat f}), \log \mathbf{\hat G}(\mathbf{x})$ and $\log \text{Var}(\mathbf{\hat G})(\mathbf{x})$ of our model, given these normalized inputs. 
%%
%Under the renormalization maps (per component)
%\begin{equation}
%y^d \leftarrow (\mathbf{y}_{\text{max}}^d - \mathbf{y}_{\text{min}}^d) y^d  + \mathbf{y}_{\text{min}}^d \quad, 
%\tau \leftarrow \tau_{\text{max}} \tau 
%\end{equation}
%
%the model's outputs are transformed to the original (\textit{i.e.} observation) scale as follows:
%
%\begin{equation}
%\label{eq:renormalization_transform}
%\begin{split}
%\mathbf{\hat f}(\mathbf{x})^d &\leftarrow \mathbf{\hat f}(\mathbf{x})^d \frac{\mathbf{y}_{\text{max}}^d - \mathbf{y}^d_{\text{min}}}{\tau_{\text{max}}} \\
%%
%\log \text{Var}(\mathbf{\hat f})(\mathbf{x})^d &\leftarrow \text{Var}(\mathbf{\hat f})(\mathbf{x})^d + 2 \log (\mathbf{y}_\text{max}^d - \mathbf{y}_\text{min}^d) - 2\log \tau_\text{max} \\
%%
%\log \mathbf{\hat G}(\mathbf{x})^d &\leftarrow \log \mathbf{\hat G}(\mathbf{x})^d +  \log (\mathbf{y}_\text{max}^d - \mathbf{y}_\text{min}^d) - \frac{1}{2} \log \tau_\text{max} \\
%%
%\log \text{Var}(\mathbf{\hat G})(\mathbf{x})^d &\leftarrow \log \text{Var}(\mathbf{\hat G})(\mathbf{x})^d  + 2 \log (\mathbf{y}_\text{max}^d - \mathbf{y}_\text{min}^d) - \log \tau_\text{max}
%\end{split}
%\end{equation}
%
%These transformations follow from Ito’s formula and Theorem 8.5.7 of \citet{oksendal2010stochastic}. 


\subsection{Model Architecture}
\label{app:architecture}

In this section, we provide some more details about the architecture of the single \texttt{FIM-SDE}, all presented experiments were conducted with. 

We fix a hidden size $E=256$ for all embeddings throughout the different parts of the model.

All \textit{features} are embedded with linear layers $\phi_\cdot^\theta$ to dimension $\frac{E}{4}$, s.t. their concatenated embedding $\mathbf{d}_i^\theta$ is of the desired size $E$. 
%
The embedded features are further encoded by the Transformer encoder with linear attention $\Psi^\theta$. It consists of $2$ layers and attention dimension $E$. 

Each \textit{location} is a single input, encoded by another linear layer $\Phi_x^\theta$ to $E$ dimensions. 

The trunk-net equivalent \textit{functional attention mechanism} first applies $M = 8$ attention blocks (including residual feed-forward layers). 
%
The final embeddings $\mathbf{h}_{\cdot, M}^\theta (\mathbf{x}) | D^\prime)$ are then projected to output dimension $3$ by feed-forward networks with $2$ hidden layers of dimension $E$. 




%\textbf{Model inputs}: 
%\begin{enumerate}[(i)]    
%        \item A set of (possibly noisy) $K$ time series $\{(\mathbf{y}_{k1}, \tau_{k1}), \dots, (\mathbf{y}_{kl}, \tau_{kl})\}_{k=1}^K$ on the hidden paths;
%    \item The location $\mathbf{x}$ at which we evaluate the output functions. 
%\end{enumerate}
%
%%\textbf{Architecture}:
%\begin{enumerate}[(i)]    
%    \item \textit{Spatial embedding} $\phi^s_0: \mathbb{R}^D \rightarrow \mathbb{R}^E$, where $E$ is some embedding dimension. Currently $\phi^s_0$ is a MLP with \textit{silu} activation. 
%    
%    \item \textit{Temporal embedding} $\phi^t_0: \mathbb{R}^+ \rightarrow \mathbb{R}^E$. We use the time embedding of~\citet{shukla2020multitime}.
%
%    \item \textit{Sequence processing network} $\psi_1$. Let us denote the $i$th element of the $k$th time series in our input time series with 
%    %
%    \begin{equation}
%        \mathbf{u}_{ki} = \text{Concat}(\phi^s_0(\mathbf{y}_{ki}), \Delta \phi^s_0(\mathbf{y}_{ki}),  \phi^t_0(\tau_{ki})) \in \mathbb{R}^{3E}, \, \, \,  \text{where} \, \, \Delta \phi^s_0(\mathbf{y}_{ki}) = \phi^s_0(\mathbf{y}_{k,i+1}) - \phi^s_0(\mathbf{y}_{ki}).
%    \end{equation}
%    
%     We process each time series with a Transformer (encoder) network $\psi_1$ as follows
%    %
%    \begin{equation}
%      \mathbf{h}_{k1}, \dots, \mathbf{h}_{kl} = \psi_1(\mathbf{u}_{k1}, \dots, \mathbf{u}_{kl}, \theta), \, \, \text{so that} \, \, \mathbf{h}_{ki}\in \mathbb{R}^H,
%    \end{equation}    
%    with $H$ the hidden dimension of the model.
%
%    Let's now denote the output sequence of vectors ($\mathbf{h}_{k1}, \dots, \mathbf{h}_{kl}$) for the $k$th path with the matrix of $\mathbf{H}_k\in \mathbb{R}^{H \times l}$.
%    
%    \item \textit{Trunk net equivalent}. It's given by an MLP $\phi_1: \mathbb{R}^E \rightarrow \mathbb{R}^H$ which takes as input the embedded evaluation point. We denote it with
%    \begin{equation}
%        \mathbf{t}(\mathbf{x}) = \phi_1(\phi^s_0(\mathbf{x}))
%    \end{equation}
%
%    \item \textit{Space-dependent path embedding}. We summarize each path with an attention network
%
%    \begin{equation}    
%    \mathbf{h}_k(\mathbf{x}) = \Omega_1(\mathbf{t}(\mathbf{x}), \mathbf{H}_k, \mathbf{H}_k).
%    \label{eq:space-dependent-attention}
%    \end{equation}        
%    %
%    Note that this way we have a path embedding which depends on the \textit{location at which we want to evaluate the output functions}.    
%    Also note that, as usual, the $i$th attention network is given by
%    $$
%    \Omega_i(Q, K, V) = \text{softmax} \left( d_{att}^{-1/2} (W_Q \cdot Q) \cdot (W_K \cdot K)^T\right) \cdot (W_V \cdot V),
%    $$    
%    with $W_Q, W_K, W_Q \in \mathbb{R}^{d_{att} \times H}$ learnable, and $d_{att}$ the attention dimension.    
%
%    \item \textit{Summary over paths}. We summarize the set of $K$ \textit{state-dependent} path embeddings with a second attention network
%    %
%    \begin{equation}    
%    \mathbf{b}(\mathbf{x}) = \Omega_2(\mathbf{q}, \, \mathbf{H}(\mathbf{x}), \mathbf{H}(\mathbf{x})), \, \, \text{with} \, \, \mathbf{H}(\mathbf{x}) = (\mathbf{h}_1(\mathbf{x}), \dots, \mathbf{h}_K(\mathbf{x}))
%    \end{equation}
%    and $\mathbf{q} \in \mathbb{R}^{1 \times d_{att}}$ a learnable query.
%    
%    \item \textit{Final layer}: We use a simple MLP $\phi_2$ to project the final embedding: 
%    \begin{equation}        
%    \mathbf{\hat f}(\mathbf{x}), \log \text{Var}(\mathbf{\hat f})(\mathbf{x}) = \phi_2(\mathbf{b}(\mathbf{x})),
%    \end{equation}
%    \begin{equation}        
%    \log \mathbf{\hat G}(\mathbf{x}), \log \text{Var}(\mathbf{\hat G})(\mathbf{x}) = \phi_3(\mathbf{b}(\mathbf{x})).
%    \end{equation}
%\end{enumerate}





%\subsection{Training Objective}
%\label{app:training-obj}
%
%Our model is trained, in a supervised fashion, on synthetic data generated as described in Appendix~\ref{app:data-gen}. 
%%
%Let us now discuss in detail the corresponding training strategy and objective. 
%
%We employ instance normalization during application of our model to accommodate data of all scales, as described in Appendix~\ref{app:input-output}. 
%%
%While not strictly necessary, we also use \textit{instance normalized data} in our training objective, regularizing the learning process.
%
%Following the notation of Appendix~\ref{app:input-output}, let $\mathbf{f}$ and $\mathbf{G}$ be the sampled, ground-truth drift and diffusion coefficients associated to one element in the synthetic dataset. 
%%
%Let $\{ \mathbf{x}_j\}_{j=1}^L \subset \mathbb{R}^D$ be a set of evaluation points. 
%%
%Continuing the notation from Appendix~\ref{app:input-output}, the ground-truth coefficients transform under the (component wise) instance normalization maps~\eqref{eq:normalization_maps} as follows:
%%
%\begin{align}
%\mathbf{f}(\mathbf{x})^d &\leftarrow \mathbf{f}(\mathbf{x})^d \frac{\tau_{\text{max}}}{\mathbf{y}_{\text{max}}^d - \mathbf{y}^d_{\text{min}}} \\
%\mathbf{G}(\mathbf{x})^d &\leftarrow \mathbf{G}(\mathbf{x})^d \frac{\sqrt{\tau_{\text{max}}}}{\mathbf{y}_{\text{max}}^d - \mathbf{y}^d_{\text{min}}}
%\end{align}
%%
%Again, these transformations are due to Ito's formula and Theorem 8.5.7 of \citet{oksendal2010stochastic}.
%
%Returning to the model, let us denote by $\mathbf{\hat f}(\mathbf{x}_j), \log \text{Var}(\mathbf{\hat f})(\mathbf{x}_j), \log \mathbf{\hat G}(\mathbf{x}_j)$ and $\log \text{Var}(\mathbf{\hat G})(\mathbf{x}_j)$ its outputs when evaluated at $\mathbf{x}_j$, \textit{before} renormalization with \eqref{eq:renormalization_transform}. 
%%
%Hence both, model outputs and ground-truth targets, associate to the same scale and can thus be faithfully compared. 
%
%The training objective for our model is then to maximize the Gaussian log-likelihood of the ground-truth drift, \linebreak$\log \mathcal{L}(\mathbf{f}(\mathbf{x}_j) \mid \mathbf{\hat f}(\mathbf{x}_j), \text{Var}(\mathbf{\hat f})(\mathbf{x}_j))$, and diffusion, $\log \mathcal{L}(\mathbf{G}(\mathbf{x}_j) \mid \mathbf{\hat G}(\mathbf{x}_j), \text{Var}(\mathbf{\hat G})(\mathbf{x}_j))$. 
%%
%Expressed as an equation, we train our model to minimize 
%\begin{equation}
%\begin{split}
%\mathcal{L} =  & \lambda_\mathbf{f} \underset{\mathbf{f} \sim p_\text{\tiny}(\mathbf{f}, \rho_f)}{\mathbb{E}} \Big\{\sum_{j=1}^L \frac{(\mathbf{f}(\mathbf{x}_j) - \mathbf{\hat f} (\mathbf{x}_j))^2}{2 \text{Var}(\mathbf{\hat f})(\mathbf{x}_j)} + \frac{1}{2} \log(\text{Var}(\mathbf{\hat f})(\mathbf{x}_j))\Big\}  \\
%               + &\lambda_\mathbf{G} \underset{\mathbf{G} \sim p_\text{\tiny}(\mathbf{G}, \rho_g)}{\mathbb{E}} \Big\{\sum_{j=1}^L \frac{(\mathbf{G}(\mathbf{x}_j) - \mathbf{\hat G} (\mathbf{x}_j))^2}{2 \text{Var}(\mathbf{\hat G})(\mathbf{x}_j)} + \frac{1}{2} \log(\text{Var}(\mathbf{\hat G})(\mathbf{x}_j))\Big\}  
%\end{split}
%\end{equation}
%%
%where $\lambda_\mathbf{f}, \lambda_\mathbf{G} \in \mathbb{R}$ are fixed weighting factors.

%\subsection{Drift and Diffusion Functions as Training Targets}
%\label{sec:target-functions}
%
%For supervised training of our models we need a set of paths (the input for our model) and the values of the corresponding drift and diffusion functions on some location grid.
%
%\textit{Question}: do these location grids have to be close to the paths in our datasets? 
%
%The goal of the algorithm is system identification, meaning that we would like to infer the values of the actual (hidden) functions on points that do not need to be closed to the observed paths.
%
%% reasonably close to the paths. 
%% %
%% The proximity is important, as the paths only contain local information about the concepts, not global information. 
%% %
%% Currently, we don't know how far off the paths we can (or should) predict the concepts.  
%
%One idea is to select the locations from a regular grid in a hyper-rectangle that surrounds all paths in the dataset.
%%
%Let $\{\mathbf{x}^k\}_{k=1}^K$ be the set of all paths for the SDE defined by $(\mathbf{f}, \mathbf{g})$. 
%%
%Similarly, let
%\begin{equation}
%    a_i = \min_{k=1,\dots, K} \min_{t \in [0,T]} x_i^k(t), \quad b_i = \max_{k=1,\dots, K} \max_{t \in [0,T]} x_i^k(t), \quad \Delta_i = b_i - a_i.
%\end{equation}
%Then we define the hyper-rectangle as
%\begin{equation}
%[a_1, b_1] \times [a_2, b_2] \times \dots \times [a_D, b_D].
%\end{equation}
%
%Note that we could also elongate the hyper-rectangle along each dimension by some (predefined) factor $c$.
%%
%Indeed, if we define
%\begin{equation}
% \tilde a_i = a_i - \Delta_i \frac{c}{2} \ \, \text{and} \quad \tilde b_i = b_i + \Delta_i \frac{c}{2},
%\end{equation}
%then the enlarged hyper-rectangle is defined as $[\tilde a_1, \tilde b_1] \times \dots \times [\tilde a_D, \tilde b_D]$
%
%
%\textit{Note that if we pick the locations from the hyper-rectangle as above, the locations depend on $N$, the maximum number of paths. 
%%
%During training, we subsample the number of paths.} (Not clear).

\subsection{Training Procedure}
\label{app:training}
We train \texttt{FIM-SDE}  with AdamW \citep{loshchilov2017decoupled}, using learning rate $1e^{-5}$ and weight decay $1e^{-4}$. 
%
For stability of training (some ground-truth vector field values are large, even after instance normalization), we used gradient clipping with norm $1$. 

Memory requirements are quite large, as we provide the model as much as $100$ paths of length $128$ during training. 
%
Therefore, we utilize four A100 40GB GPUs to train with a batch size of $64$. 

In each batch, we sample the number of paths passed to the model from $\mathcal{U}[0,100]$, s.t. the \texttt{FIM-SDE} can be applied to datasets of many sizes. 
%
Moreover, for each equation in a batch, we randomly select $32$ locations to compute the loss $\mathcal{L}_1(\mathbf{x})$ of \eqref{eq:loss-1} on. 


%\subsection{Ablation studies}
%\label{app:ablations}

\section{Maximum Mean Discrepancy}
\label{app:mmd}
The Maximum Mean Discrepancy (MMD) is a non-parametric statistical test used to compare two probability distributions \citet{mmd_paper}. The objective of MMD is to measure the difference between two distributions, $P$ and $Q$, based on samples drawn from these distributions. MMD employs kernel methods to map the data into a high-dimensional feature space where linear methods can be effectively applied.

We use \textsc{Ksig} \citet{ksig} which is a library to compute signature kernels for time series. Using the RBF-kernel and 5 signature levels, we obtain a signature kernel $k(x,y)$. The MMD between two sets of samples $\{x_i\}_{i=1}^n \sim P$ and $\{y_j\}_{j=1}^m \sim Q$ can then by computed as
\begin{equation}
\text{MMD}^2(P, Q) \approx \frac{1}{n(n-1)}\left( \sum_{i \neq j} k(x_i, x_j) + \sum_{i \neq j} k(y_i, y_j)\right) - \frac{2}{n^2} \sum_{i, j} k(x_i, y_j)\,.
\end{equation}
To compute our performance metrics, we choose $x_i$ to be samples from the ground truth SDE and $y_i$ to be samples derived from the inferred equations of the selected model. For this, we are using $K=100$ paths.



\section{Experiments: Details}
\label{app:experiment}

\subsection{SparseGP Drift and Diffusion Estimation}
\label{app:baselines}

\paragraph{Sparse Approximation} 
We employed the Sparse Gaussian process (GP) approximation \cite{batz2018approximate} to estimate the drift function and diffusion \( \*f(\*x)
  \) and \(\*G(\*x)\) in the (SDEs). A specific covariance kernel $\kappa_\theta(z_i, z_j)$ (such as the RBF) is prescribed per dimension. In order to reduce computational burden we introduce inducing points, these can be thought of as pseudo-observations of the function at \(S\) locations 
\(\*z = [z_1, \ldots, z_S]\). The drift  (or diffusion) estimator is then given by:
\begin{equation}
    h_i(\mathbf{x}) = [\mathbf{k}(\mathbf{x})^i]^\top \left( I + \gamma^i \mathbf{K}_s^i \right)^{-1} \Delta t (\pi^i)^\top (\mathbf{g}^i)^{-1} \mathbf{u}^i,
\end{equation}
Here, \([\mathbf{K}^i_s]_{vw} = \kappa_\theta(\*z_v, \*z_w)\) and \([\mathbf{k}(\*x)^i]_v = \kappa_\theta(\*x, \*z_v)\), \( \pi^j = \mathbf{K}_{Ns}^i (\mathbf{K}_s^i)^{-1} \) provides the projection onto the inducing points, and \( \gamma^i = \Delta t (\pi^i)^\top (\mathbf{g}^i)^{-1} \pi^i \) controls the influence of the inducing points. $\mathbf{g}^i$ is a diagonal matrix composed by the functions $g(\*x)$ for the drift estimation, and corresponds to a nuance parameter for the diffusion estimator. This sparse approximation replaces the full kernel matrix with a reduced matrix involving only the inducing points, significantly reducing computational cost from \( \mathcal{O}(n^3) \) to \( \mathcal{O}(m^3) \), where \( m \ll n \).  This approach ensures efficient inference even for large datasets while preserving the flexibility of nonparametric drift estimation.

\paragraph{Drift and Diffusion Estimation for Dense Observations} 
For densely observed data, the drift function \( h_i(\*x) = f_i(\*x) \) is estimated using GP regression, where the observed increments 
\begin{equation}
    u_i(t_k) = \frac{y_i(t_k + \Delta t) - y_i(t_k)}{\Delta t},
\end{equation}
are treated as noisy observations of the drift. On the other hand, the diffusion function \( h_i(\*x) = g_i(\*x) \) is estimated using the squared increments:
\begin{equation}
    \tilde{u}_i(t_k) = \frac{(y_i(t_k + \Delta t) - y_i(t_k))^2}{\Delta t},
\end{equation}
which represent the conditional variance of the observed process. The diffusion estimator follows from the expression:
\begin{equation}
    g^*_i(\*x) = \lim_{\Delta t \to 0} \frac{1}{\Delta t} \mathbb{E}[(x_i(t+\Delta t)- x_i(t))^2 | x_i(t) = \*x].
\end{equation}
To estimate \( g^*(x) \), GP regression is applied to the squared increments \( \tilde{y}_i \), treating them as noisy observations of the conditional variance. 

In our experiments, we made use of Polynomial kernel for drift estimation, RBF for diffusion. We used a grid search optimizing the data likelihood an selected inducing points in regions of high path density as specified by \cite{batz2018approximate}.
%The dominant fluctuations are given by the non-Gaussian noise term \( D(X_t)(1 - \epsilon_t^2) \), but due to the smoothness of diffusion paths, GP regression effectively filters out the noise and provides a robust estimate. The resulting diffusion function is given by the GP mean:

%\begin{equation}
%    \hat{D}(x) = \mathbb{E}[\tilde{y}_i | x],
%\end{equation}

%where \( \tilde{y}_i \) are the squared increments. This formulation enables accurate diffusion estimation even when the noise model is misspecified, provided that the data is densely sampled. By jointly estimating both drift and diffusion functions, the SparseGP framework offers a scalable and data-efficient approach to learning SDE dynamics from observations.


\subsection{Canonical SDE systems}
\label{app:canonical-sdes}

We compare \texttt{FIM-SDE} against two methods: the Bayesian non-parametric method of \citet{batz2018approximate} and the sparse Bayesian learning model of \citet{WANG2022244}.
%
To study their performance in fine and coarse grid observations, we simulate well known processes, extracted from \cite{batz2018approximate}, \cite{course2023state} and \cite{WANG2022244}: 

\begin{enumerate}
    \item \textbf{Double-well diffusion model with state-dependent diffusion}:
    \begin{equation}
        dx = 4(x-x^3)dt + \sqrt{\max(4-1.25 x^2, 0)} dW(t).
    \end{equation}
    A process from \cite{batz2018approximate}. We set the initial state to $x(0)=0$.
    \item \textbf{Damped linear oscillator}:
    \begin{eqnarray}
        dx_1 & = &-(0.1 \, x_1 -2.0 \,  x_2 )dt + \, dW(t), \\
        dx_2 & = &-(2.0 \, x_1 + 0.1 \, x_2)dt +  \, dW(t), 
    \end{eqnarray}
    A process from \cite{course2023state}. The initial state is $x(0) = [2.5, -5]$. 
    \item \textbf{Damped cubic oscillator}:
    \begin{eqnarray}
        dx_1 &=& -(0.1 \, x_1^3 -2.0 \,  x_2^3 )dt +  \, dW(t), \\
        dx_2 &=& -(2.0 \, x_1^3 + 0.1 \, x_2^3)dt + \, dW(t), 
    \end{eqnarray}
    A process from \cite{course2023state}. The initial state is $x(0) = [0, -1]$. \cite{course2023state}
    \item \textbf{Duffing oscillator}:
    \begin{eqnarray}
        dx_1 &=& x_2dt +  \, dW(t), \\
        dx_2 &=& -(x_1^3 -x_1 +0.35 \, x_2)dt +  \, dW(t), 
    \end{eqnarray}
   A process from \cite{course2023state}. The initial state is $x(0) = [3, 2]$. 
    \item \textbf{Selkov glycolysis}:
    \begin{eqnarray}
        dx_1 &=& -(x_1 -0.08 \,x_2 - x_1^2x_2)dt +  \, dW(t), \\
        dx_2 &=& (0.6 -0.08 \, x_2 -x_1^2x_2)dt +  \, dW(t), 
    \end{eqnarray}
    A process from \cite{course2023state}. The initial state is $x(0)= [0.7, 1.25]$. \cite{course2023state}
    \item \textbf{Hopf bifurcation}:
    \begin{eqnarray}
        dx_1 &=& (0.5\, x_1 + x_2 - x_1(x_1^2+x_2^2))dt +  \, dW(t), \\
        dx_2 &=& (-x_1 + 0.5 \, x_2 - x_2(x_1^2+x_2^2))dt + \, dW(t), 
    \end{eqnarray}
    A process from \cite{course2023state}. The initial state is $x(0) = [2, 2]$.
    \item \textbf{2D synthetic system}:
    \begin{eqnarray}
        \label{eq:wang1}
        dx_1 &=& (x_1 - x_2 - x_1x_2^2 - x_1^3) dt + \sqrt{1+x_2^2} \, dW(t), \\
        \label{eq:wang2}
        dx_2 &=& (x_1 + x_2 - x_1^2x_2 - x_2^3) dt + \sqrt{1+x_1^2} \, dW(t).        
    \end{eqnarray}
    A process from \citet{WANG2022244}. The initial state is $x(0) = [1.5, 1.5]$. 
    
    %\item \textbf{Lorentz 63}:
    %\begin{eqnarray}
    %    dx_1 &=& 10(x_2 -x_1)dt +  \, dW(t), \\
    %    dx_2 &=& (28 x_1  -x_1 x_3 -x_2)dt + g_2 \, dW(t), \\
    %    dx_3 &=& (x_1x_2 -(8/3)x_3)dt + g_3 \, dW(t), 
    %\end{eqnarray}
    %for $t \in [0, 10]$ and $x_1(0), x_2(0), x_3(0) = -8, 7, 27$, observed regularly 128 times. \cite{course2023state}
\end{enumerate}
%In all but the first case above the diffusion coefficients are constant and given by
%\begin{equation}
%\label{eq:constant_signal_to_noise}
%    g_i = \frac{1}{SNR} \left(\sup_{t\in [0, T]} x_i(t) - \inf_{t\in [0, T]} x_i(t) \right),
%\end{equation}
%with $x_i(t)$ the component-wise solution of the corresponding ODE system, and $SNR$ the signal-to-noise ratio which we here set to 200.

For context data $\mathcal{D}$ we simulate the different processes with a dense time step of $\Delta t = 0.002$. 
%
We then record every $k= 1, 5, 10$ dense steps where $k = \tau /\Delta t $ (we report only the $\tau = 0.002, 0.01, 0.02$) and simulate until we observe 5000 points. 
%
For each process and each $\tau$, we repeat this sampling $5$ times, to report a standard deviation for the performance of each model.  

Additionally, we sample $100$ paths of length $500$ of each system with $\Delta \tau = 0.002$. 
% 
These paths are used as references to compute the MMD metric of Appendix \ref{app:mmd}. 

Let us now briefly describe the experimental setup. 
%
We apply \texttt{FIM-SDE} and the two baseline models for all processes and all $\Delta \tau$ and infer an estimated process. 
%
We then simulate $100$ paths of length $500$ of the inferred equations, starting from from a fixed set of initial states. 
%
Importantly, these simulations are performed with $\Delta \tau = 0.002$, \textit{independent} of the $\Delta \tau$ from the observations. 
%
Moreover, we evaluate the estimated vector fields on a fixed grid. 

We compare the estimated vector field on the fixed grid to the ground-truth vector fields by the MSE, and report the results in Table \ref{tab:MSE-results-vector-fields}. 
%
We compare the simulated paths to the set of $100$ reference paths by the MMD, an report the results in Table \ref{tab:MMD-computations}. 
%
Simulations of the inferred processes of the baselines can fail. 
%
We remove those simulations from the MMD computation, average over the rest and mark these occurrences with a "*" in Table \ref{tab:MMD-computations}. 



\subsection{Real-world Systems: Empirical Datasets Studied by~\citet{WANG2022244}}
\label{app:real-world-fluctuations}

We simply refer to~\citet{WANG2022244} for details here.


\subsection{Real-world Systems: The Motion Capture Dataset}
\label{app:MOCAP}

We consider the human motion capture dataset analyzed by~\citet{heinonen2018learning}, which consists of 50-dimensional pose measurements of walking subjects.
%
Specifically, we use the dataset provided by~\citet{yildiz2019ode2vae}, pre-processed following the approach of~\citet{wang2007gaussian}.
%
The dataset contains 43 trajectories, each with a maximum length of 125 frames.

 To make the system compatible with \texttt{FIM-SDE} --- which can only model up to three-dimensional systems --- we apply the PCA projection method from~\citet{heinonen2018learning}.
 
For forecasting experiments, we use the first half of each trajectory as context data for \texttt{FIM-SDE}, and predict the second half, starting from the first frame of the latter segment.
%
That is \texttt{FIM-SDE} performs forecasting in PCA space, after which the predictions are mapped back to the original space by inverting the PCA transformation.

\pagebreak
\section{Additional Results}

In this section we report additional results. 

\subsection{Canonical SDE Systems: Mean-squared error on drift estimation}

\begin{table}[H]
    \small
    \centering
    \caption{Mean-squared error on drift estimation with respect to the ground-truth on a predefined grid.}
    \begin{tabular}{llllllllll}
    $\Delta \tau$ & Model & \makecell{Double\\Well} & \makecell{2D-Synt\\(Wang)} & \makecell{Damped\\Linear} & \makecell{Damped\\Cubic} & Duffing & Glycolysis & Hopf \\
    \hline
    \rowcolor{table_baselines}0.002 & SparseGP & $49 \pm 14$ & $4326 \pm 3063$ & $5.0 \pm 0.1$ & $22.8 \pm 0.6$ & $1069 \pm 1682$ & $198 \pm 110$ & $25 \pm 6$ \\
    \rowcolor{table_baselines}0.002 & BISDE & $35 \pm 2$ & $1277 \pm 159$ & $4 \pm 1$ & $34 \pm 1$ & $151 \pm 1$ & $124 \pm 70$ & $23 \pm 9$ \\
    0.002 & FIM-SDE & $16 \pm 11$ & $1437 \pm 45$ & $88 \pm 75$ & $10 \pm 3$ & $196 \pm 20$ & $122 \pm 38$ & $18 \pm 2$ \\
    \hline
    \rowcolor{table_baselines}0.01 & SparseGP & $37 \pm 2$ & $1265 \pm 321$ & $4.5 \pm 0.3$ & $3270 \pm 5279$ & $251 \pm 37$ & $143 \pm 83$ & $15 \pm 1$ \\
    \rowcolor{table_baselines}0.01 & BISDE & $33.3 \pm 0.3$ & $1259 \pm 295$ & $2.86 \pm 0.01$ & $23 \pm 1$ & $150.0 \pm 0.2$ & $86 \pm 2$ & $17 \pm 2$ \\
    0.01 & FIM-SDE & $2 \pm 1$ & $915 \pm 183$ & $0.8 \pm 0.2$ & $0.72 \pm 0.08$ & $69 \pm 33$ & $56 \pm 17$ & $13 \pm 1$ \\
    \hline
    \rowcolor{table_baselines}0.02 & SparseGP & $42 \pm 12$ & $1092 \pm 150$ & $4.5 \pm 0.3$ & $446 \pm 486$ & $2848 \pm 4526$ & $100 \pm 6$ & $14.3 \pm 0.8$ \\
    \rowcolor{table_baselines}0.02 & BISDE & $33.9 \pm 0.3$ & $1060 \pm 141$ & $2.861 \pm 0.008$ & $22.9 \pm 0.6$ & $150.0 \pm 0.2$ & $85.1 \pm 0.6$ & $16.0 \pm 0.7$ \\
    0.02 & FIM-SDE & $1.4 \pm 0.6$ & $326 \pm 116$ & $0.21 \pm 0.05$ & $0.41 \pm 0.07$ & $9 \pm 8$ & $37 \pm 12$ & $9 \pm 1$ \\
    \hline
    \end{tabular}
    \label{tab:MSE-results-vector-fields}
\end{table}


\subsection{Real-world Systems: MMD comparisons on Oil price and Wind Speed Fluctuations}

\begin{table}[H]
    \small
    \centering
    \caption{MMD comparisons of \texttt{FIM-SDE} versus \texttt{BISDE}~\cite{WANG2022244}. Lower values are better.}
    \begin{tabular}{lll}
    Model & Oil price fluctuations & Wind speed fluctuations\\
    \hline
    \rowcolor{table_baselines} BISDE & 0.32 & 0.31\\
    FIM-SDE & \textbf{0.09} & \textbf{0.09} \\
    \hline
    \end{tabular}
    \label{tab:MMD-FLUCTUATIONS}
\end{table}

%\begin{table*}[H]
%\centering
%\small
%\caption{MSE on Motion Capture trajectories in the forecasting region. Error is obtained from \textit{mean model predictions} or from \textit{sampled model predictions}. For the later, standard deviations are calculated across the \textit{samples}. Baseline results have been extracted from \cite{yildiz2019ode2vae}.}
%\begin{tabular}{lcc}
%\toprule
%            &  \multicolumn{2}{c}{Test Error} \\
% Model      &  Mean Prediction &  Sampled Prediction \\
%\midrule
%\texttt{GPDM}                           & 57.52         &   126.46 $\pm$ 34     \\
%\texttt{VGPLVM}                         & 128.03        &   142.18 $\pm$ 1.92   \\
%\texttt{DTSBN-S}                        & 78.39         &   80.21 $\pm$ 0.04    \\
%\texttt{npODE}                          & 45.74         &   45.74               \\
%\texttt{NeuralODE}                      & 97.74         &   87.23 $\pm$ 0.02    \\
%\texttt{ODE\textsuperscript{2}VAE}      & 32.19         &   93.07 $\pm$ 0.72    \\
%\texttt{ODE\textsuperscript{2}VAE-KL}   & 30.72         &   15.99 $\pm$ 4.16    \\
%\midrule
%\texttt{FIM-SDE} (Zero-shot)                       & 71.86             &   104.00$\pm$111.59  \\
%\bottomrule
%\end{tabular}
%\label{tab:mocap43_mean_predictions}
%\end{table*}


\subsection{Real-world Systems: Motion Capture and Forecasting}

\begin{table*}[h]
\centering
\small
\caption{MSE on Motion Capture trajectories in the forecasting region. Error is obtained from \textit{mean model predictions} or from \textit{sampled model predictions}. For the later, standard deviations are calculated across the \textit{samples}. Baseline results have been extracted from \cite{yildiz2019ode2vae}.}
\begin{tabular}{lcc}
\toprule
            &  \multicolumn{2}{c}{Test Error} \\
 Model      &  Mean Prediction &  Sampled Prediction \\
\midrule
\texttt{GPDM}                           & 57.52         &   126.46 $\pm$ 34     \\
\texttt{VGPLVM}                         & 128.03        &   142.18 $\pm$ 1.92   \\
\texttt{DTSBN-S}                        & 78.39         &   80.21 $\pm$ 0.04    \\
\texttt{npODE}                          & 45.74         &   45.74               \\
\texttt{NeuralODE}                      & 97.74         &   87.23 $\pm$ 0.02    \\
\texttt{ODE\textsuperscript{2}VAE}      & 32.19         &   93.07 $\pm$ 0.72    \\
\texttt{ODE\textsuperscript{2}VAE-KL}   & 30.72         &   15.99 $\pm$ 4.16    \\
\midrule
\texttt{FIM-SDE} (Zero-shot)                       & 71.86             &   104.00$\pm$111.59  \\
\bottomrule
\end{tabular}
\label{tab:mocap43_mean_predictions}
\end{table*}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







\end{document}

% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
