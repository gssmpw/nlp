[
  {
    "index": 0,
    "papers": [
      {
        "key": "NEURIPS2022_6f1d43d5",
        "author": "Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan",
        "title": "Locating and Editing Factual Associations in GPT"
      },
      {
        "key": "lan2024sparseautoencodersrevealuniversal",
        "author": "Michael Lan and Philip Torr and Austin Meek and Ashkan Khakzar and David Krueger and Fazl Barez",
        "title": "Sparse Autoencoders Reveal Universal Feature Spaces Across Large Language Models"
      },
      {
        "key": "10.1145/3639372",
        "author": "Zhao, Haiyan and Chen, Hanjie and Yang, Fan and Liu, Ninghao and Deng, Huiqi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Du, Mengnan",
        "title": "Explainability for Large Language Models: A Survey"
      },
      {
        "key": "rai2024practicalreviewmechanisticinterpretability",
        "author": "Daking Rai and Yilun Zhou and Shi Feng and Abulhair Saparov and Ziyu Yao",
        "title": "A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "goldowsky2023localizing",
        "author": "Goldowsky-Dill, Nicholas and MacLeod, Chris and Sato, Lucas and Arora, Aryaman",
        "title": "Localizing model behavior with path patching"
      },
      {
        "key": "wang2023interpretability",
        "author": "Kevin Ro Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt",
        "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in {GPT}-2 Small"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "heimersheim2024useinterpretactivationpatching",
        "author": "Stefan Heimersheim and Neel Nanda",
        "title": "How to use and interpret activation patching"
      },
      {
        "key": "zhang2024towards",
        "author": "Fred Zhang and Neel Nanda",
        "title": "Towards Best Practices of Activation Patching in Language Models: Metrics and Methods"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "geva-etal-2022-transformer",
        "author": "Geva, Mor  and\nCaciularu, Avi  and\nWang, Kevin  and\nGoldberg, Yoav",
        "title": "Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space"
      },
      {
        "key": "dar-etal-2023-analyzing",
        "author": "Dar, Guy  and\nGeva, Mor  and\nGupta, Ankit  and\nBerant, Jonathan",
        "title": "Analyzing Transformers in Embedding Space"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "wang2023interpretability",
        "author": "Kevin Ro Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt",
        "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in {GPT}-2 Small"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "wei2024interpreting",
        "author": "Zhang, Wei and Wan, Chaoqun and Zhang, Yonggang and Cheung, Yiu-ming and Tian, Xinmei and Shen, Xu and Ye, Jieping",
        "title": "Interpreting and improving large language models in arithmetic calculation"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "bhattacharya2024understandingroleffnsdriving",
        "author": "Sunit Bhattacharya and Ond\u0159ej Bojar",
        "title": "Understanding the role of FFNs in driving multilingual behaviour in LLMs"
      },
      {
        "key": "peng-sogaard-2024-concept",
        "author": "Peng, Qiwei  and\nS{\\o}gaard, Anders",
        "title": "Concept Space Alignment in Multilingual {LLM}s"
      },
      {
        "key": "ferrando-costa-jussa-2024-similarity",
        "author": "Ferrando, Javier  and\nCosta-juss{\\`a}, Marta R.",
        "title": "On the Similarity of Circuits across Languages: a Case Study on the Subject-verb Agreement Task"
      },
      {
        "key": "dumas2024how",
        "author": "Cl{\\'e}ment Dumas and Veniamin Veselovsky and Giovanni Monea and Robert West and Chris Wendler",
        "title": "How do Llamas process multilingual text? A latent exploration through activation patching"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "mu-etal-2024-revealing",
        "author": "Mu, Yongyu  and\nFeng, Peinan  and\nCao, Zhiquan  and\nWu, Yuzhang  and\nLi, Bei  and\nWang, Chenglong  and\nXiao, Tong  and\nSong, Kai  and\nLiu, Tongran  and\nZhang, Chunliang  and\nZhu, JingBo",
        "title": "Revealing the Parallel Multilingual Learning within Large Language Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "tang-etal-2024-language",
        "author": "Tang, Tianyi  and\nLuo, Wenyang  and\nHuang, Haoyang  and\nZhang, Dongdong  and\nWang, Xiaolei  and\nZhao, Xin  and\nWei, Furu  and\nWen, Ji-Rong",
        "title": "Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "wendler-etal-2024-llamas",
        "author": "Wendler, Chris  and\nVeselovsky, Veniamin  and\nMonea, Giovanni  and\nWest, Robert",
        "title": "Do Llamas Work in {E}nglish? On the Latent Language of Multilingual Transformers"
      },
      {
        "key": "zhao2024how",
        "author": "Yiran Zhao and Wenxuan Zhang and Guizhen Chen and Kenji Kawaguchi and Lidong Bing",
        "title": "How do Large Language Models Handle Multilingualism?"
      }
    ]
  }
]