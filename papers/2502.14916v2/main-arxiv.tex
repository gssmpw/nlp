\documentclass[9pt,shortpaper,twoside,web]{ieeecolor}
\usepackage{generic}
\usepackage{cite}
\pdfoutput=1
\usepackage{amsmath,amssymb,amsfonts}
%\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subfig}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage[justification=justified]{caption} 
\newcommand{\lh}[1]{\textbf{#1}} % 将 \lh 定义为加粗文本

% \def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
%      T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
% \markboth{\journalname, VOL. XX, NO. XX, XXXX 2017}

% {Author \MakeLowercase{\textit{et al.}}: MKE-Coder: Multi-Axial Knowledge with Evidence Verification in ICD Coding for Chinese EMRs}

\begin{document}
\title{MKE-Coder: Multi-Axial Knowledge with Evidence Verification in ICD Coding for Chinese EMRs}
\author{Xinxin You, Xien Liu, Xue Yang, Ziyi Wang, and Ji Wu.
% \thanks{This paragraph of the first footnote will contain the date on 
% which you submitted your paper for review. It will also contain support 
% information, including sponsor and financial support acknowledgment. For 
% example, ``This work was supported in part by the U.S. Department of 
% Commerce under Grant BS123456.'' }
\thanks{Xinxin You, Xien Liu, Ziyi Wang and Ji Wu are with the Department of Electronic Engineering, Tsinghua University, Beijing 100084, China (e-mail: yxx23@mails.tsinghua.edu.cn; xeliu@mail.tsinghua.edu.cn; wangziyi000128@gmail.com; wuji\_ee@tsinghua.edu.cn). }
\thanks{Xue Yang is with Tsinghua-iFlytek Joint Laboratory, Iflytek, Beijing 100084, China (e-mail: yx9702@gmail.com.}}
% \thanks{Shaohui Liu is with the School of Computer Science, Beijing University of Posts and Telecommunications, Beijing 100084, China (email:shaohuiliu@bupt.edu.cn).}}

\maketitle


% 你的文档内容

\begin{abstract}
The task of automatically coding the International Classification of Diseases (ICD) in the medical field has been well-established and has received much attention. Automatic coding of the ICD in the medical field has been successful in English but faces challenges when dealing with Chinese electronic medical records (EMRs). The first issue lies in the difficulty of extracting disease code-related information from Chinese EMRs, primarily due to the concise writing style and specific internal structure of the EMRs. The
second problem is that previous methods have failed to leverage the disease-based multi-axial knowledge and lack of association with the corresponding clinical evidence, resulting in inaccurate
disease coding and a lack of interpretability. This paper introduces a novel framework called MKE-Coder: Multi-axial Knowledge
with Evidence verification in ICD coding for Chinese EMRs. Initially, we identify candidate codes for the diagnosis and categorize each of them into knowledge under four coding axes.
Subsequently, we retrieve corresponding clinical evidence from the comprehensive content of EMRs and filter credible evidence through a scoring model. Finally, to ensure the validity of the candidate code, we propose an inference module based on the masked language modeling strategy. This module verifies that all the axis knowledge associated with the candidate code is supported by evidence and provides recommendations accordingly. To evaluate the performance of our framework, we conduct experiments using a large-scale
Chinese EMR dataset collected from various hospitals. The experimental results demonstrate that MKE-Coder exhibits significant superiority in the task of automatic ICD coding based on
Chinese EMRs. In the practical evaluation of our method within simulated real coding scenarios, it has been demonstrated that our approach significantly aids coders in enhancing both their coding accuracy and speed.
\end{abstract}

\begin{IEEEkeywords}
Chinese electronic medical records, evidence verification, ICD coding, interpretability, multi-axial knowledge, prompt-tuning, 
\end{IEEEkeywords}

\section{Introduction}
\label{sec:introduction}

The International Classification of Diseases (ICD) was developed by the World Health Organization (WHO) to convert descriptions of disease diagnoses and other health problems into an alphanumeric coding system. ICD codes are widely accepted and used in numerous countries for clinical research, healthcare management, and insurance compensation. Electronic medical records (EMRs) systems have recently gained popularity among healthcare organizations worldwide as a viable alternative to traditional paper-based record management. The streamlined storage of ICD codes has facilitated the generation of a substantial volume of medical data by EMR systems annually, often containing valuable medical insights \cite{mahdi2023review}. While initially developed as archival systems for medical records, researchers have made the compelling discovery that these systems offer valuable support across a diverse range of clinical and statistical applications \cite{xu2022survey}.
    
  

    While automatic ICD coding has received considerable attention \cite{mahdi2023review,yan2022survey,ji2021,yuan2022code,li2023towards}, there has been limited validation of its effectiveness on Chinese EMR datasets, as most studies have relied on English datasets (such as various versions of the MIMIC dataset) \cite{yan2022survey, mahdi2023review}. Consequently, there is a lack of research focusing on the challenges and practical requirements of Chinese EMRs. In light of this, we emphasize two unresolved issues in this context.


    The first challenge in automatically coding the ICD from Chinese EMRs lies in extracting disease-related information due to their concise writing style and unique structure. Unlike English EMRs (e.g., MIMIC-III dataset  \cite{johnson2016mimic}), where diagnosis-related information is often conveyed in brief sentences and essential coding details are included in discharge summaries, Chinese EMRs present diagnoses in multi-word phrases and offer less detailed discharge summaries. We performed a statistical analysis on diagnostic descriptions and discharge summaries from a Chinese dataset and the MIMIC-III dataset to substantiate these points. As shown in Table \ref{tab:length}, the analysis revealed significant discrepancies: the average length of diagnoses in the MIMIC-III dataset is 14.73 words, compared to just 3.74 in Chinese EMRs—making them nearly four times shorter. Discharge summaries too showed a marked difference, with MIMIC-III averaging around 1,600 words and Chinese EMRs only 731 words, around 2.19 times shorter. This data underscores the inadequacy of depending solely on diagnosis names and summaries for coding in Chinese EMRs. The additional diagnostic and treatment information required is dispersed throughout various sections of the EMR, necessitating a comprehensive approach using axis knowledge for retrieval.


    \begin{table}
    \centering
    \caption{Statistics of the Chinese and MIMIC-III datasets, including the mean, variance, and median of the number of words per diagnosis, and the number of words per discharge summary respectively. For the Chinese dataset, the words were obtained through the jieba word segmentation tool.}%\footnotemark.}}
    \renewcommand{\arraystretch}{1.2} % 可以调节, 1.2指高度是默认的1.2倍
    \begin{tabular}{cccc}
    \toprule[1.2pt]
    \lh{Chinese dataset} & \lh{Mean} & \lh{Variance} & \lh{Median} \\
    \hline
    \lh{\# Words per diagnosis} & \lh{3.74} & \lh{3.99} & \lh{3} \\
    \lh{\# Words per discharge summary} & \lh{731.80} & \lh{104,742.07} & \lh{706} \\
    \lh{MIMIC-III dataset} & \lh{Mean} & \lh{Variance} & \lh{Median} \\
    \lh{\# Words per diagnosis} & \lh{14.73} & \lh{276.91} & \lh{11} \\
    \lh{\# Words per discharge summary} &\;\lh{1,600.36}\; &\; \lh{600,303.20} & \lh{1,466} \\
    \bottomrule[1.2pt]
    \end{tabular}
    %\footnotetext{Here is the code link for jieba word segmentation tool: \url{https://github.com/fxsjy/jieba}}
    \label{tab:length}
    \end{table}


    \begin{figure*}[t]
    \begin{center}
    \includegraphics[height=5cm,width=14cm]{ICD-classification-axis.png}
    	\caption{The left diagram illustrates how the ICD coding system, using the example of code H31.403 from the Chinese medical insurance version, elucidates the process of organizing diseases and health conditions into ICD codes based on four axes: etiology, anatomical site, pathology, and clinical manifestations. This process involves a step-by-step division from a broader to a more specific level, forming the structure of the ICD coding system. Furthermore, the right diagram demonstrates that each component of the code represents specific knowledge associated with its corresponding axis.}
    \label{fig:ICD-coding}
    \end{center}
    \end{figure*}
    
    
    %\fntext[1]{}
    
    %icd 既往工作没有关注的第二个问题：可解释性
    The second issue with previous ICD coding methods is their focus on the hierarchical structure of ICD codes while neglecting the essential multi-axial knowledge that underpins this hierarchy \cite{wu2024hyperbolic,luo2024corelation}. This multi-axial knowledge is vital, much like the nuanced perspective in a poem. Using the example of ICD code H31.403 from the Chinese medical insurance version (as depicted in Fig \ref{fig:ICD-coding}), the left diagram illustrates how diseases and health conditions are organized into codes across four axes: etiology, anatomical site, pathology, and clinical manifestations. This organization involves progressively narrowing down from broader categories to more specific ones, thus forming the structure of the ICD coding system. The right diagram further highlights that each segment of the code corresponds to specific knowledge relevant to its axis. Yet, previous approaches have overlooked this crucial aspect by: 1) ignoring the important multi-axial knowledge in favor of simply mapping hierarchical structures, and 2) treating all diagnostic and treatment information homogeneously without aligning them with the clinical evidence that pertains to relevant axis knowledge \cite{jeong2024bridging,wu2024hyperbolic,luo2024corelation}. This oversight leads to coding that not only lacks accuracy but also falls short in interpretability, posing challenges for practical implementation in real-world scenarios.
   
   
    To address the aforementioned issues, we have developed MKE-Coder: Multi-axial Knowledge with Evidence verification in ICD Coding for Chinese EMR, as depicted in Fig \ref{fig:framework}. This framework is inspired by the utilization of multi-axial knowledge in the ICD coding system and the principles of Evidence-Based Medicine (EBM) \cite{masic2008evidence,swanson2010practice,akobeng2005principles}. EBM, which has its roots in the late 19th century, emphasizes the conscious and rational utilization of the best available scientific evidence when making treatment decisions for individual patients. It involves the conscientious, explicit, judicious, and reasonable application of the most current and reliable evidence in determining the care provided to each patient \cite{masic2008evidence}. In our framework, we aim to find evidence for the knowledge under each axis of the candidate codes and use this evidence to determine whether a candidate code is well-supported. This process enables us to recommend codes that are strongly supported by the evidence gathered. 
    
    Specifically, our approach involves several steps. First, we extract the diagnosis list from the Chinese EMR. Next, we identify the most probable candidate ICD codes for each diagnosis to enhance efficiency. To parse the multi-axial knowledge associated with each candidate code, we employ a multi-axial parser. Additionally, we utilize an evidence retrieval module that leverages prior knowledge from ICD coders to locate supporting text descriptions within the EMR for each axis of the candidate code. To ensure the reliability of the retrieved evidence, we propose a Clinical-Simbert model that calculates the similarity between each piece of evidence and the corresponding knowledge under the axis. Once we have obtained a reliable set of evidence, we need to determine whether the ICD code is fully supported by the evidence set and worthy of recommendation. Inspired by the prompt tuning method, which effectively bridges the gap between pre-training and fine-tuning downstream tasks \cite{schick2020,liu2021}, we adopt a prompt-tuning approach. This involves designing a template that combines evidence from all axes and the candidate ICD code. We then convert the binary classification task into a masked language modeling problem and conduct supervised training. Finally, we obtain the recommended ICD code for each diagnosis, along with the corresponding evidence set. This comprehensive framework enables efficient and accurate ICD coding for Chinese EMR data. We summarize the contribution of this paper as follows:

    
    
    \begin{itemize}
    
    	\item[$\bullet$] We point out the differences between Chinese EMRs and English EMRs in extracting ICD coding-dependent information. Chinese EMR datasets have an average diagnosis length that is 3.9 times shorter than the MIMIC dataset, and the average length of discharge summaries in Chinese EMR datasets is 2.19 times shorter than in the MIMIC dataset. Therefore, the previous ICD automatic coding method focused on English EMRs does not apply to Chinese EMRs.
    	\item[$\bullet$] Inspired by the coarse-to-fine classification strategy under multi-axes knowledge of the ICD codes system and the theory of evidence-based medicine, we proposed an evidence retrieve module to find out the textual description in the EMR supporting the knowledge under the axis of each candidate ICD code, and further evaluate the quality of evidence to ensure its reliable by proposed Clinical-Simbert model; 
    	\item[$\bullet$] We convert the binary classification task of whether the candidate ICD code can be fully supported by the evidence set into a masked language modeling problem by designing a template that combines the proof set and the candidate ICD code. We conducted ICD code prediction experiments on the Chinese dataset collected and obtained state-of-the-art performance. In the practical evaluation of our method within simulated real coding scenarios, it has been demonstrated that our approach significantly aids coders in enhancing both their coding accuracy and speed.
    
    
    \end{itemize}


\section{Related Works}
\label{sec:Related Works}
The task of automatically coding ICD in the medical field has been well established and has received much attention. Many deep-learning methods have been used to address this problem, and we categorize these methods into the following three types.

    \begin{figure*}[t]
    \centering
    \includegraphics[height=6.5cm,width=18cm]{framework.pdf}
    \caption{The general framework of MKE-Coder. First, we extract the diagnosis list from the Chinese EMR. Next, we identify the most probable candidate ICD codes for each diagnosis to enhance efficiency. To parse the multi-axial knowledge associated with each candidate code, we employ a multi-axial parser. Additionally, we utilize an evidence retrieval module to locate supporting text descriptions within the EMR for each axis of the candidate code. We propose a Clinical-Simbert model to ensure the reliability of the retrieved evidence. We then convert the binary classification task into a masked language modeling problem and conduct supervised training. Finally, we obtain the recommended ICD code for each diagnosis, along with the corresponding evidence set. }
    \label{fig:framework}
    \end{figure*}

\subsection{Knowledge-Enhanced Methods}

A comprehensive understanding of clinical notes necessitates expertise in the field of medicine. Various techniques leverage external knowledge sources to optimize neural architectures and facilitate the comprehension of clinical text, ultimately enhancing proficiency in accurately assigning ICD codes. 
Yuan et al. proposed the MSMN method, which collected synonyms of every ICD code from UMLS and designed a multiple synonyms matching network to leverage synonyms for better code classification \cite{yuan2022code}. Similarly, Yang et al. proposed a knowledge-enhanced longformer by injecting three domain-specific knowledge: hierarchy, synonym, and abbreviation with additional pretraining using contrastive learning \cite{yang2022knowledge}. Li et al. highlighted the often overlooked issues of data imbalance and noise in clinical notes, thus they suggested a knowledge-enhanced Graph Attention Network (GAT \cite{velivckovic2017graph}) under a multi-task learning setting, featuring multi-level information transitions and interactions \cite{li2023towards}. 


\subsection{Graph Neural Networks}
Graph neural networks are adept at transforming complex relationships into topological graph structures and then leveraging graph convolution operations to facilitate low or high-dimensional interactions between nodes and relationships, which has led to their successful application and impressive results in many NLP tasks \cite{zhou2020graph,wu2020comprehensive,zheng2022graph,zhang2019heterogeneous}. To mitigate the issues of excessive and imbalanced ICD codes, which present a severe long-tail distribution, and to fully exploit the hierarchical structure among the codes, graph neural networks have been extensively applied to automatic ICD coding tasks. Jeong et al. introduced a novel approach, the Joint Learning Framework Across Medical Coding Systems (JAMS). This framework utilized a modified version of the Graph Attention Network, termed the Medical Code Attention Network, to facilitate multi-task learning, enabling simultaneous learning from various coding systems through a shared encoder to acquire diverse representations \cite{jeong2024bridging}. Meanwhile, Wu et al. highlighted the primary challenges of automated ICD coding, including imbalanced label distribution, code hierarchy, and noisy texts. In response, they proposed a unique approach called the Hyperbolic Graph Convolutional Network \cite{chami2019hyperbolic} with Contrastive Learning \cite{you2020graph}. They employed a Hyperbolic Graph Convolutional Network to capture the hierarchical structure of ICD codes and implemented contrastive learning to automatically assign ICD codes, incorporating code features into a text encoder \cite{wu2024hyperbolic}. In a study by Fails et al., the researchers proposed data augmentation and synthesis techniques and also introduced an analysis technique for this setting inspired by confusion matrices \cite{falis2022horses}. Recognizing that existing methods could not model a personalized relation graph for each case, or discover implicit code relations, Luo et al. presented a novel contextualized code relation-enhanced ICD coding framework. This framework utilized a personalized flexible relation graph, enabling their model to learn implicit relations \cite{luo2024corelation}.

  
 \begin{table*}[h]
    \centering
    \caption{This is a small section of a complete prior knowledge table, listing the possible locations in medical records where clinically supporting evidence for three-digit code groups of interest may be found.}
     \renewcommand{\arraystretch}{1.2} % 可以调节, 1.2指高度是默认的1.2倍   
    \begin{tabular}{ccccc}
    \toprule[1.2pt]
    Code range and name\;   & \multicolumn{4}{c}{Possible locations for evidence appearance in Chinese EMRs}\\
    \hline
    \makecell[c]{A00-A09\\Intestinal infectious diseases\;}  & \makecell[c]{ Testing \\(and results)} & \makecell[c]{Symptom \\presentation} &\makecell[c]{History of \\exposure to endemic \\or epidemic areas}&\\
    \hline
    \makecell[c]{A15-A19\\Tuberculosis}  & \makecell[c]{Symptom \\presentation} & \makecell[c]{Examination\\ (and results)} & \makecell[c]{ Chest \\ examination results}& \,\makecell[c]{Vaccination  \\ and Infectious \\Disease History}     \\
    \hline
    \makecell[c]{A20-A28\\Certain zoonotic\\bacterial diseases}   & \makecell[c]{Testing \\(and results) }& \makecell[c]{Occupation and \\ working conditions}   && \\
    \hline
    \makecell[c]{A30-A49\\Other bacterial diseases}  &  \makecell[c]{Skin and \\mucous membrane \\examination results} & \makecell[c]{Testing \\(and results)} & \makecell[c]{Neurological reflex\\examination results}  & \\
    \hline
    \makecell[c]{ A50-A64\\Sexually transmitted\\infections } 
      & \makecell[c]{Skin and \\mucous membrane \\examination results}   &  \makecell[c]{External genital\\ examination results}  & Testing (and results) & \\
    \hline
    \makecell[c]{ A65-A69\\Other spirochetal diseases} & \makecell[c]{Skin and \\mucous membrane \\examination results}    & \makecell[c]{Testing \\(and results) }&  \makecell[c]{History of \\exposure to endemic \\or epidemic areas}& \\
    \hline
    \makecell[c]{A70-A74 \\Other diseases \\caused by chlamydia}& \makecell[c]{Chest \\examination results} & \makecell[c]{Head and facial \\examination results}  & Testing (and results) & \\
    \hline
    \makecell[c]{ A75-A79 \\Rickettsioses}  & Testing (and results)  &\,\makecell[c]{History of \\exposure to endemic \\or epidemic areas}& & \\
    \hline
    \makecell[c]{ ...}  & ... &...& ...& ...\\
    \bottomrule[1.2pt]
    \end{tabular}
    \label{tab:prior knowledge}
\end{table*}


\subsection{Pretrained Language Models}

Pretrained language models are trained on an auxiliary task, such as masked language modeling that predicts a word or sequence based on the surrounding context and gains improvement in many NLP tasks \cite{qiu2020pre}. Pretraining such auxiliary tasks benefits from large-scale training on unlabeled corpora that are readily available from the web or textbooks \cite{ji2021does}. For electronic health records that ICD coding is based on, language models that have been pre-trained in the medical field can effectively understand their specialized medical semantic information. As such, they are extensively employed in ICD coding tasks. A series of competitive frameworks for automatic ICD coding is based on the Bert method \cite{ji2021,zhang2020,pascual2021}, in which each ICD code is associated with a unique entity representation, and the automatic coding task is transformed into a multi-label classification across fine-tuning. Afkanpour et al. presented a simple and scalable method to process long electronic medical records (EMRs) with the existing transformer models such as BERT, showed that this method significantly improves the previous results reported for transformer models in ICD coding, and can outperform one of the prominent CNN-based methods \cite{afkanpour2022bert}. Gomes et al. employed a strong Transformer-based model as a text encoder and, to handle lengthy clinical narratives, explored either (a) adapting the base encoder model into a Longformer \cite{beltagy2020longformer}, or (b) dividing the text into chunks and processing each chunk independently \cite{gomes2024accurate}. Silva et al. proposed a method where Cosine text similarity is combined with a pretrained language model, PLM-ICD, to increase the number of probably useful suggestions of ICD-10 codes, based on the Medical Information Mart for Intensive Care (MIMIC)-IV dataset \cite{silva2024aiding}. 

Prompt-based fine-tuning is effective in few-shot tasks \cite{scao2021many,gao2020making}, even when the language model is relatively small \cite{schick2020s} because they introduce no new parameter during few-shot fine-tuning. Yang et al. proposed a Knowledge Enhanced PrompT (KEPT) framework that utilized prompt-tuning in the context of ICD coding tasks by adding a sequence of ICD code descriptions as prompts in addition to each clinical note as KEPT LM input \cite{yang2022knowledge}. Yang et al. transformed the multi-label classification task into an autoregressive generation task and developed a cross-attention reranker with prompts to incorporate previous state-of-the-art (SOTA) and the best few-shot coding predictions \cite{yang2023multi}. 
 
\subsection{Summary}

In summary, while automatic ICD coding has received significant attention, there has been limited validation of its effectiveness on Chinese EMR datasets. Consequently, a lack of research specifically focuses on the unique challenges and practical requirements of Chinese EMRs. Notably, existing methods have neglected to extract disease code-related information from Chinese EMRs and have overlooked the crucial multi-axial knowledge that underpins the ICD coding hierarchy. As a result, the outcomes of the Chinese ICD coding system suffer from insufficient coding accuracy and a lack of genuine interpretability, posing challenges to their effective implementation in real-world scenarios. Therefore, our work is motivated by these issues and proposes a novel framework that addresses the challenges of ICD coding in Chinese EMRs. Our framework considers the specific characteristics of Chinese EMRs, focusing on extracting multi-axial knowledge-related information. By doing so, we aim to improve coding accuracy and enhance interpretability, enabling effective system implementation in real-world scenarios.

\section{Methodology}
   \subsection{Task Definition}

    Recently, reducing a multi-label to a set of binary classification problems has proved competitive to more sophisticated multi-label classification methods, and still achieves state-of-the-art performance for many loss functions \cite{wever2020libre}. Inspired by this, We take the automatic ICD coding task as a set of binary classification tasks based on diagnoses and multi-axial knowledge-related information from EMR. 
    
    Given an EMR, we first determine the Top $N$ candidate ICD codes for each diagnosis $d\in D$. Then we find out the reliable supporting evidence set $E_{d,c_i} = \{ s_i^1,s_i^2,...,s_i^Q \}$ for knowledge under the multi-axis of $i$th candidate ICD code $c_i$ by evidence retrieving and evaluating, where $Q$ indices the maximum number of evidence, $s_i^j$ indices the $j$th reliable evidence sentence for $c_i$. We determine whether the ICD code is fully supported by the evidence set. That is, we take the description of $c_i$ and its corresponding evidence set $E_{d,c_i}$ organized in template form as input. And assign a binary label $y_i\in \{ 0, 1 \}$ for the $i$th candidate ICD code in the label space $Y$, where 1 means that the evidence sufficiently supports the ICD code and to be recommended, 0 is the opposite.


    
    \subsection{Evidence Retrieval and Evaluation}
    
    \subsubsection{Obtaining Candidate Codes for Each Diagnosis}
    
    Let $D$ be the set of all diagnoses from the dataset of medical records, and $C$ is the set of all ICD codes. For each diagnosis $d \in D$, we calculate the similarity with all ICD codes using a weighted sum of the Edit-Distance score (ED) \cite{marzal1993computation}, TF-IDF score (TF), and word2vec-based \cite{mikolov2013efficient} feature similarity score (FEA). They quantify the characteristics at the character, discriminative and semantic level. The top $N$ candidate codes $C_d$ for each diagnosis $d$ are obtained by:
    \begin{equation}
    \begin{split}
    \label{E1}
    C_d = \text{Top}_N \{ c | Sort(Sim(d, c)), \forall c \in C \}
    \end{split}
    \end{equation}
    \begin{equation}
    \begin{split}
    \label{E2}
    Sim(d, c) = w_1 \cdot \text{{ED}}(d, c) + w_2 \cdot \text{{TF}}(d, c) + w_3 \cdot \text{{FEA}}(d, c)
    \end{split}
    \end{equation}
    
    \noindent{Where $Sort$ denotes indices sorting in descending order, and $w_1$, $w_2$, and $w_3$ represent the corresponding weights, which are set as 0.35, 0.35, and 0.3 in our experiment.}


   



\begin{figure*}[!t]
\centering
%\includegraphics[width=3in]{fig5}
\subfloat[]{
		\includegraphics[width=12cm,height = 6cm]{evidence.png}}
        \hspace{.2in}
\subfloat[]{
		\includegraphics[width=4.4cm,height = 6.03cm]{structure-of-evidence.png}}
\caption{Two diagrams illustrating credible evidence. (a) Here is an example of reliable evidence from a real EMR in both English and Chinese. Firstly, a diagnosis is provided along with two candidate code examples. One candidate code (also the correct code) is represented with different colors to distinguish the underlying knowledge. Purple represents etiology, blue represents clinical manifestations, and red represents anatomical site. On the right side, two credible pieces of evidence found within this underlying knowledge are further presented, with the corresponding knowledge highlighted in the respective colors. (b) This diagram illustrates the compositional structure of a piece of reliable evidence that is fed into an inference model, including the evidence sentence itself, the source of the evidence in the EMR, the repetition count of the evidence appearing throughout the entire medical record, and the multi-axial knowledge used to retrieve the evidence.}
\label{fig:evidence}
\end{figure*}




    
    \subsubsection{Greedy Evidence Retrieve based on Prior Knowledge}
    
    Due to the excessive number of sections and lengthy content in Chinese EMRs, the efficiency of evidence retrieval based on axis-specific knowledge throughout the entire medical record is low. To address this issue, we have developed an index table that leverages the prior knowledge of doctors and ICD coders to accelerate the retrieval process. Specifically, the ICD coding system divides all codes into 212 categories at the three-digit level \cite{buck20162017}. Through discussions with ICD coding specialists and doctors, we have identified 88 potential locations in Chinese EMRs where coding-related evidence may be found. We asked experienced ICD coders to identify the probable locations of supporting evidence in the medical record for each category of ICD three-digit codes. A prior information table was formed as a result of this process. For example, to confirm the diagnosis of intestinal infectious diseases, the testing and results, symptom presentation, and history of exposure to endemic or epidemic areas are considered. Therefore, the potential evidence may appear in these three positions. A condensed table of prior knowledge is provided in Table \ref{tab:prior knowledge}.
    

    
    
    Undoubtedly, the evidence sentence that contains more knowledge keywords is considered to be more representative and reliable. Therefore, we have designed a greedy evidence retrieval method. Let $K_{d,c_i}$ be the set of knowledge words under multi-axes for each candidate code $c_i \in C_d$ for each diagnosis $d$, obtained by a pre-trained parser. In addition, the MSMN method \cite{yuan2022code} has verified that rich synonym descriptions can be more effective in ICD coding, therefore we use synonyms for these keywords as a supplement, denoted as $Syn(K_{d,c_i})$. The set of all possible locations where evidence may appear in the medical record, as determined by the prior knowledge table above, is denoted as $L_{d,c_i}$. 
    
    \noindent{We define a function $g(l, s)$ that returns the number of keywords in sentence $s$ at location $l$:}
    \begin{equation}
    \begin{split}
    \label{E3}
    g(l, s) = |s \cap (K_{d,c_i} \cup Syn(K_{d,c_i}))|
    \end{split}
    \end{equation}
    \noindent{For each location $l \in L_{d,c_i}$, we take the sentence $s_{d,l}$ containing the most keywords from $K_{d,c_i} \cup Syn(K_{d,c_i})$:}
    \begin{equation}
    \begin{split}
    \label{E4}
    s_{d,l} = \underset{s \in l}{\mathrm{argmax}}\ g(l, s)
    \end{split}
    \end{equation}
    
    \noindent{Let $S_{d,c_i}$ be the set of sentences retrieved for diagnosis $d$ and candidate code $c_i$. Initially, $S_{d,c_i} = \emptyset$, we sort all possible combinations of all keywords in $K_{d,c_i} \cup Syn(K_{d,c_i})$ in descending order by the number of elements. Then, we use these sorted keyword subsets as keys to iteratively conduct the retrieval process, ensuring a comprehensive search. For each keyword, we choose the sentence $s_{d,l}$ that not only contains the keyword but also includes the maximum number of other keywords:}
    \begin{equation}
    \begin{aligned}
    \label{E5}
    S_{d,c_i} = S_{d,c_i} \cup \{s_{d,l} | g(l, s_{d,l}) > g(l, s),
    \forall s \in S_{d,c_i},\forall l \in L_{d,c}\}
    \end{aligned}
    \end{equation}
    \noindent{We stop retrieving when all keywords in $K_{d,c_i} \cup Syn(K_{d,c_i})$ have been covered by sentences in $S_{d,c_i}$ or all positions have been retrieved.}
   
    
    \subsubsection{Reliability Assessment of Multiple Axes' Evidence}

    The reliability of evidence is evaluated using an evidence-scoring model called Clinical-Simber. This model is trained in two phases using the Simbert framework \cite{su2020} and a prepared medical corpus. In the first training phase, a pre-training mode is employed. Sentence pairs with over 60\% matching entities are selected as positive samples from the same sections of several electronic medical records (EMRs) of the same disease category. Negative samples are obtained from different sections of EMRs from various disease categories, with less than 10\% matching entities. After the first pre-training phase, the model gains improved representation capabilities for Chinese medical sentences. The second training phase incorporates a contrastive learning framework to train the model's ability to score pairs of "multi-axes knowledge-evidence" sentences. Positive samples consist of pairs that include multi-axes knowledge and corresponding retrieved evidence sentences. Negative samples consist of pairs that do not correspond to the knowledge and evidence. After these two training phases, Clinical-Simber can assess the reliability of evidence for knowledge based on ICD codes. We denote the similarity score between each retrieved sentence \(s_{d,l}\) and the set of knowledge keywords \(k_{d,l}\) across multiple axes as \(Score(s_{d,l},k_{d,l})\). If the score falls below a certain threshold \(T\), we remove \(s_{d,l}\) from the evidence set:
    \begin{equation}
    \begin{split}
    \label{E5}
    E_{d,c_i} = \{s_{d,l} | Score(s_{d,l},k_{d,l}) \geq T\}
    \end{split}
    \end{equation}
    

    This process is iterated for each candidate ICD code to obtain the respective sets of reliable evidence $E_{d,c_i}$.  The detailed algorithm
pseudocode of evidence Retrieval and reliability assessment is given in Algorithm 1. As shown in Fig \ref{fig:evidence}(a), we give two examples of reliable evidence from a real EMR in both English and Chinese. Firstly, a diagnosis is provided along with two candidate code examples for brief. One candidate code (also the correct code) is represented with different colors to distinguish the knowledge of axes, Purple represents etiology, blue represents clinical manifestations, and red represents anatomical site. Two credible pieces of evidence within this underlying knowledge are further presented on the right side, with the corresponding knowledge highlighted in the respective colors.
    


\begin{algorithm}[H]
\caption{Greedy Evidence Retrieval and Reliability Assessment for ICD Coding}
\begin{algorithmic}
\Statex \textbf{Input:} Diagnosis $d$, Set of candidate codes $C_d$, Medical Record containing Sections $L$
\Statex \textbf{Output:} Reliable evidence for ICD coding $E_{d, c_i}$ for each $c_i \in C_d$
\Statex \textbf{Define:} 
\Statex \hspace{\algorithmicindent} Set of keywords $K_{d,c_i}$ and their synonyms $Syn(K_{d,c_i})$
\Statex \hspace{\algorithmicindent} Prior knowledge table locations $L_{d,c_i}$ 
\Statex \hspace{\algorithmicindent} Matching score function \(Score(s, k)\) 
\Statex \hspace{\algorithmicindent} Threshold \(T\) 

\item[ 1:] Initialize $E_{d, c_i} = \emptyset$ for each code $c_i$
\item[ 2:] \textbf{for} each candidate code $c_i \in C_d$ \textbf{do}
\item[ 3:] \hspace{\algorithmicindent} $S_{d,c_i} = \emptyset$
\item[ 4:] \hspace{\algorithmicindent} Sort all combinations of keywords in $(K_{d,c_i} \cup    Syn(K_{d,c_i}))$\\
\hspace{0.67cm} in descending
order by the number of elements
\item[ 5:] \hspace{\algorithmicindent} The keywords contained in retrieved sentences $Covered = \emptyset$
\item[ 6:] \hspace{\algorithmicindent} \textbf{for} each location $l \in L_{d,c_i}$ \textbf{do}
\item[ 7:] \hspace{\algorithmicindent} \hspace{\algorithmicindent} Calculate $s_{d,l} = \underset{s \in l}{\mathrm{argmax}}\ |s \cap (K_{d,c_i} \cup Syn(K_{d,c_i}))|$
\item[ 8:] \hspace{\algorithmicindent} \hspace{\algorithmicindent} Add $s_{d,l}$ to $S_{d,c_i}$
\item[ 9:] \hspace{\algorithmicindent} \hspace{\algorithmicindent} Update $Covered$ with keywords found in $s_{d,l}$
\item[10:] \hspace{\algorithmicindent} \hspace{\algorithmicindent}  \textbf{if} {$Covered$ == $(K_{d,c_i} \cup Syn(K_{d,c_i}))$} 
\item[11:] \hspace{\algorithmicindent} \hspace{\algorithmicindent} \hspace{\algorithmicindent} \textbf{break}
\item[12:] \hspace{\algorithmicindent} \hspace{\algorithmicindent}   \textbf{end if}
\item[13:] \hspace{\algorithmicindent} \textbf{end for}
\item[14:] \hspace{\algorithmicindent} \textbf{for} each sentence $s_{d,l}$ in $S_{d,c_i}$ \textbf{do}
\item[15:] \hspace{\algorithmicindent} \hspace{\algorithmicindent} \textbf{if} \(Score(s_{d,l}, K_{d,c_i}) \geq T\) \textbf{then}
\item[16:] \hspace{\algorithmicindent} \hspace{\algorithmicindent} \hspace{\algorithmicindent} Add $s_{d,l}$ to $E_{d,c_i}$
\item[17:] \hspace{\algorithmicindent} \hspace{\algorithmicindent} \textbf{end if}
\item[18:] \hspace{\algorithmicindent} \textbf{end for}
\item[19:] \textbf{end for}%
%\item[20:] \Return $E_{d, c_i}$ for each $c_i$  \\
\end{algorithmic}
\end{algorithm}

    

 \subsection{Inference Based on Prompt-Tuning Method}

    Inspired by the successful application of the prompt tuning method, which effectively bridges the gap between pre-training and fine-tuning for downstream tasks \cite{schick2020,liu2021}, we propose a new approach to address the binary classification task of determining whether a candidate ICD code can be fully supported by the evidence set. To achieve this, we transform the task into a masked language modeling problem, leveraging the benefits of this technique. The effectiveness of our method heavily relies on the design of the template, as previous research has shown that the template design plays a crucial role in determining the method's success \cite{scao2021many,gao2020making,schick2020s,yang2023multi}. In this section, we will introduce the importance of template design and its impact on the prediction process. We will delve into the details of how our approach leverages the masked language modeling framework to make accurate predictions.
  
    
    \subsubsection{EMR Prior for Template Design}
    
    Through our observations of Chinese electronic medical records and communication with many professional ICD coders and clinicians, we have summarized two EMR prior for writing Chinese EMRs, which will help in designing the template for prompt tuning.
    
   \vspace{0.2cm}
    \noindent \textbf{EMR Prior 1: The source of the evidence limits what the evidence can describe and how credible
    it is.}
   \vspace{0.2cm}
    
    \noindent When analyzing medical records, it's crucial to consider the source of evidence, as it directly impacts the information provided and its overall credibility. For example, comparing past and present histories in the medical record, the former records pre-hospitalization conditions while the latter captures current health status, making it less reliable for assessing the patient's present condition. On the other hand, comparing the present history with auxiliary examination results reveals a contrast between subjective descriptions and objective facts. Based on a doctor's interpretation of the patient's self-description, the present history can be unreliable due to variations in patient perception and differences in doctor expertise. For instance, a patient with heart disease might misinterpret and report symptoms as back pain. In contrast, auxiliary examination results offer more objective and accurate information. Therefore, integrating the evidence source containing crucial information into the template is essential.
    
    
   
    \begin{figure}[t]
    \includegraphics[height=6.2cm,width=9cm]{prompt-tuning1.png}
    \centering
    \caption{The inference framework based on prompt-tuning.}
    \label{fig:prompt-tunning}
    \end{figure}



     \vspace{0.2cm}
    \noindent{\textbf{EMR Prior 2: The number of repeating times of one piece of evidence in the Chinese EMR determines its importance}}
     \vspace{0.2cm}
    
    \noindent Each step of the treatment plan heavily relies on the patient's fundamental diagnostic basis and auxiliary examination results, often recorded repeatedly in the medical record. To manage this redundancy, we apply the $k$-means method to cluster and retain only one sentence from sets of duplicate or highly similar evidence retrieved through certain keywords. Concurrently, we tally the number of similar descriptions in each cluster and incorporate this count into the template. This procedure not only eliminates repetition but also highlights the significance of each sentence by indicating its frequency. 
    
    Finally, because each piece of evidence is to prove the knowledge of the corresponding axis, we emphasize them by adding the keywords behind the evidence. We presented the compositional structure of a reliable evidence piece in Fig\ref{fig:evidence}(b) to aid in clear understanding. 


 
  
    \subsubsection{Template Design}
    
    We give the formal definition of the template. Given the $i$th candidate ICD code description $c_i$ of diagnosis $d$, the corresponding reliable evidence set is $E^{'}_{d,c_i}$ is defined by:
    \begin{equation}
    \begin{split}
    \label{E7}
    E^{'}_{d,c_i}= \{ s_i^1,...s_i^q,...,s_i^Q \}
    \end{split}
    \end{equation}
    \noindent where $s_i^q$ indices the $q$th evidence of candidate ICD code $c_i$, $Q$ indices the maximum number of evidence. 
    Each piece of evidence $s_i^q$ is defined by:
    \begin{equation}
    \begin{split}
    \label{E8}
    s_i^q = s_{d,l} || k_{d,l} || o_{s_i^q}|| t_{s_i^q}
    \end{split}
    \end{equation}
    where $k_{d,l}$ indicate the keywords of $s_{d,l}$, $o_{s_i^q}$ and $t_{s_i^q}$ indicate the field of the sentence originates from and the repeating times the evidence in the whole Chinese EMR, `$\Vert$' represents concatenation. 




    
    Both $c_i$ and its reliable evidence set $E^{'}_{d,c_i}$ are all composed of words, we represent them in this way:
    \begin{equation}
    \begin{split}
    \label{E9}
    c_i = \{w_{ci}^1,w_{ci}^2,...,w_{ci}^P\}
    \end{split}
    \end{equation}
    \noindent where $w_{ci}^p$ indices $p$th word of candidate ICD code $c_i$ and $P$ indices the maximum number of words.
    \begin{equation}
    \begin{split}
    \label{E10}
    E^{'}_{d,c_i}= \{ w_{i,1}^1,...w_{i,q}^r,...,w_{i,Q}^R\}
    \end{split}
    \end{equation}
    \noindent where $w_{i,q}^r$ indicate the $r$th word in $q$th evidence of $c_i$th candidate ICD code, and $R$ indices the maximum number of words. 
    We designed the template as follows:
    \begin{equation}
    \begin{split}
    \label{E11}
    T = [CLS] E^{\prime}_{d,c_i} [soft] [soft] [soft] c_i [soft] [mask]
    \end{split}
\end{equation}
    
    \noindent  In which [soft] indices a learnable continuous embedding, which is a trick to eliminate the trouble of designing prompts and can get better results than designing templates manually proposed by \cite{li2021prefix,lester2021power}. We use a 
    [mask] token for label prediction, indicating a
    binary classification label prediction. The inference framework is shown in Fig \ref{fig:prompt-tunning}.
     
    
      
    \subsubsection{Evidence-Based ICD Codes Prediction}
    Raffel et al. proposed T5 model, which is a unified framework that converts all text-based language problems into a text-to-text format \cite{raffel2020exploring}.
    We employed this model as a text encoder, which embeds input tokens to embedding space:
    \begin{equation}
    \begin{split}
    \label{E12}
    T = [e_{w_{i,1}^1},...,e_{w_{i,Q}^R},e_{soft},   e_{soft},  \\
    e_{soft}, e_{w_{ci}^1},...,e_{w_{ci}^P}, e_{soft},e_{mask}]
    \end{split}
    \end{equation}
    \noindent where $e_{w_{i,1}^1}$ is word embedding of $w_{i,1}^1$, $e_{soft}$ is the embedding of [soft], which is initialized following the T5 model. $e_{mask}$ is the embedding of [mask], which is initialized by the [mask] token by T5 model. We've deleted [cls] for brevity. T5 model then encodes $T$ to achieve the hidden states:
    \begin{equation}
    \begin{split}
    \label{E13}
    T = [h_{w_{i,1}^1},...,h_{w_{i,Q}^R},h_{soft},   h_{soft}, \\
     h_{soft}, h_{w_{ci}^1},...,h_{w_{ci}^P}, h_{soft},h_{mask}]
    \end{split}
    \end{equation}
    % \noindent where $h_{w_{i,1}^1}$ is the hidden state of the $w_{i,1}^1$.
    
    
    To convert the binary classification task into a masked language modeling problem, we calculate the probability of filling the token to the [mask] position in the template. Let $\mathcal{V}$ and $\mathcal{Y}$ indices a set of label words and class set respectively. An injective mapping function $\phi: \mathcal{Y} \to \mathcal{V}$ is needed to associate the label set with the set of label words, which is also called "verbalizer" in some recent papers \cite{hu2021knowledgeable,li2021prefix}. We define a sample verbalizer by setting $\mathcal{V}_1$ = {“yes”}, $\mathcal{V}_0$  = {“no”}. With the verbalizer, the probability distribution of $\mathcal{Y}$ can be obtained by the probability distribution of $\mathcal{V}$ at the [mask] position, which is formalized as follows:
    \begin{equation}
    \label{E14}
    p(y|T) = p ([mask]=\phi(y)|T)
    \end{equation}

\section{Experiments}
  
    
    % For the English dataset, we use the classic MIMIC-III dataset (\cite{johnson2016mimic}), which contains medical record information and ICD-9 code during the patient's hospitalization. We use the same splits with previous works (\cite{mullenbach2018explainable,vu2020label}) with two settings as full codes (MIMIC-III full) and top-50 frequent codes (MIMIC-III 50).
    
    %\vspace{-0.15cm}
    
    \subsection{Datasets}
    We verify the performance of the proposed method on the Chinese dataset. We collected patients' medical records from different hospitals in four cities. We use the Chinese medical insurance version of the ICD coding system, which contains 33243 ICD codes. We list the statistics of the dataset in Table \ref{tab:dataset}, including the number of Chinese EMRs, the average length of the overall EMR, the number of all ICD codes, the number of all candidate ICD codes, and the recall rate of the candidate ICD codes to the correct ICD codes for the training set, development set, and test set respectively. We also show the mean, variance, and median values of the candidate codes of each diagnosis, the evidence of each candidate code, and tokens of each evidence respectively in Table \ref{tab:dataset1}. 
    
    
      


% 不包含 mimic-iii-full 的结果
\begin{table}[t]
\centering
\caption{Statistics of the Chinese dataset collected, including the total number of Chinese EMRs, the average length of the overall EMR, the number of all ICD codes, the number of all candidate ICD codes, and the recall rate of the candidate ICD codes to the correct ICD codes for the training set, development set, and test set respectively.}
\label{tab:dataset}

\begin{tabular}{lccc} % 使用 l, c 对齐
\toprule
\textbf{\# Chinese Dataset}  & \textbf{Train} & \textbf{Dev} & \textbf{Test} \\
\midrule
Total \# EMRs                & 70,318        & 8,689       & 8,790      \\
Avg \# Chinese words per EMR & 83,317.35     & 81,246.56   & 82,328.16  \\
Total \# ICD codes           & 2,238         & 2,198       & 2,207      \\
Total \# candidate ICD codes & 11,080        & 10,954      & 11,023     \\
Recall rate                  & 96.58\%       & 95.43\%     & 95.55\%    \\
\bottomrule
\end{tabular}
\end{table}

    
    %不包含mimic-iii-full的结果
    \begin{table}[t]
    \centering
    \caption{Statistics of the Chinese dataset, including the mean, variance, and median value of the candidate codes of each diagnosis, the evidence of each candidate code, and tokens of each evidence.}
    \renewcommand{\arraystretch}{1.2} % 可以调节, 1.2指高度是默认的1.2倍
    \begin{tabular}{cccc}
    \toprule[1.2pt]
     \# Chinese dataset & Mean & Variance& Median \\
     \hline
    Candidate codes per diagnosis   & 13.17 &	8.6	& 10 \\
    Reliable evidence per candidate code  & 3 &	2.4	& 2 \\
    Tokens per evidence  & 43.66	& 52	& 7\\
    \bottomrule[1.2pt]
    \end{tabular}
    \label{tab:dataset1}
    \end{table}

    
    \subsection{Baselines and Metrics}
    
    We choose the following competitive methods as baselines. We measure the results using macro F1, accuracy, and precision@5.
    
   
    
    %LAAT & JointLAAT
    \noindent \textbf{LAAT\&jointLAAT} Vu et al. proposed a label attention model for ICD coding, which can handle both the various lengths and the interdependence of the ICD code-related text fragments \cite{vu2020label}.
    
    \noindent \textbf{T5} Raffel et al. proposed the T5 model, which is a unified framework that converts all text-based language problems into a text-to-text format \cite{raffel2020exploring}. 
    
    \noindent \textbf{MSMN} Yuan et al. proposed a multiple synonyms matching network to leverage synonyms for better code representation learning, and finally help the code classification \cite{yuan2022code}. MSMN is the state-of-the-art method for automatic ICD coding.
    
   
     \subsection{Implementation Details}
    During the experiment, we set the number of candidate codes for each diagnosis to 50. Under this setting, the recall rate of both the training set, the development set, and the test set exceeds 95\%. If the number is increased to 100, the recall rate can exceed 98\%, we chose 50 for efficiency. We used edit distance, tfidf, and similarity calculation methods to find top1-top30, top31-top40, and top41-top50 candidate codes for each diagnosis. The similarity calculation needs the embedding of diagnoses and the ICD codes, We employ the word2vec \cite{mikolov2013efficient} to train the corpus for getting token representations and join them to get the whole representation. Training for Clinical-Simbert took total about 156 hours with 1 NVIDIA TITAN RTX GPU with 24 GB memory in total. In the training process, we used learning rate 2e-7, dropout rate 0.1, L2 weight decay 1e-3, and batch size of 16 with fp32. The threshold to eliminate unreliable evidence is 0.65 (after normalization). For the inference model based on prompt-tuning, we trained it took about 65 hours with 1 NVIDIA TITNA GPU with 24 GB memory. During prompt-tuning, we used learning rate 1e-4, dropout rate 0.1, L2 weight decay 0.01, and batch size of 16 with fp32. 
    
    %\vspace{-0.15cm}
    

  \subsection{\lh{Validate the effectiveness of the evidence set by MKE-Coder}}

    To validate the effectiveness of the evidence set by MKE-Coder for automatic ICD coding, we differentiate whether the discharge summary from the Electronic Medical Record (EMR) or the evidence set generated by the MKE-Coder is used as input, as indicated in parentheses after each method in the Fig \ref{fig_6}. On average, the methods that use evidence sets as input improve F1 score and accuracy 12.08\% and 15.15\%, respectively, compared to the methods using discharge summary as input in Fig \ref{fig_6}. These results demonstrate again that the discharge summary alone is insufficient to support ICD coding for Chinese EMRs. At the same time, the evidence set, obtained through prior knowledge retrieval and the evidence evaluation strategy, contains rich and comprehensive clinical information, sufficient to validate the reasonableness of the corresponding candidate ICD code.
    
   

    
    \subsection{\lh{Overall Performance}}


   
   \begin{table}[t]
      \centering
      \caption{Experimental results are needed to verify the effectiveness of MKE-Coder based on precision, recall, and the F1 index. For each baseline, use "discharge summary" and "evidence set" by MKE-Coder as inputs respectively.}
      \renewcommand{\arraystretch}{1.2} % 可以调节, 1.2指高度是默认的1.2倍
      \begin{tabular}{llll}
      \toprule[1.2pt]
        \multirow{2}{*}{Model} & \multicolumn{3}{c}{Macro}  \\
        &Precision & Recall & F1  \\
        \hline
        % LAAT(discharge summary) & \lh{18.06\%} & \lh{17.81\%\;} & \lh{17.93\%\;}  \\
        % JointLAAT(discharge summary) & \lh{22.29\%} & \lh{22.45\%} & \lh{22.37\%} \\
        % MSMN(discharge summary) & 7.70\% & 6.50\% & 7.05\%  \\
        % T5(discharge summary) & 58.53\% & 60.89\% &59.69\% \\
        % MKE-Coder(discharge summary)\; & \textbf{63.37\%} & \textbf{64.19\%} & \textbf{63.78\%} \\
        % \hline
         LAAT(evidence set) & \lh{28.90\%} & \lh{29.33\%} & \lh{29.11\%} \\
        JointLAAT(evidence set) & \lh{33.14\%} & \lh{35.17\%} & \lh{34.12\%}  \\
        MSMN(evidence set) & 29.79\% & 32.07\% & 30.89\%  \\
        T5(evidence set)& 63.50\% & 64.78\% & 64.13\%  \\ 
        MKE-Coder(evidence set) & \textbf{73.34\%} & \textbf{71.90\%} & \textbf{72.61\%}  \\
        \bottomrule[1.2pt]
      \end{tabular}
      \label{tab:results on chinese data}
    \end{table}


     \begin{table}[t]
      \centering
      \caption{Experimental results are needed to verify the effectiveness of MKE-Coder based on accuracy and p@5 index. For each baseline, use "discharge summary" and "evidence set" by MKE-Coder as inputs respectively.}
      \renewcommand{\arraystretch}{1.2} % 可以调节, 1.2指高度是默认的1.2倍
      \begin{tabular}{lll}
      \toprule[1.2pt]
        Model& Accurac&p@5 \\
        % \hline
        % LAAT(discharge summary) & \lh{36.65\%} & \lh{59.65\%} \\
        % JointLAAT(discharge summary) & \lh{41.52\%} & \lh{62.35\%} \\
        % MSMN(discharge summary) & 53.46\% & 58.69\% \\
        % T5(discharge summary) & 62.64\% & 65.27\% \\
        % MKE-Coder(discharge summary)\;  &\textbf{65.25\%} & \textbf{69.82\%} \\
        \hline
         LAAT(evidence set) & \lh{59.26\%} & \lh{85.29\%} \\
        JointLAAT(evidence set) & \lh{63.59\%} & \lh{89.54\%} \\
        MSMN(evidence set) & 68.50\% & \textbf{94.57\%} \\
        T5(evidence set) & 69.58\% & 81.17\% \\ 
        MKE-Coder(evidence set)& \textbf{74.32\%} & 92.73\% \\
        \bottomrule[1.2pt]
      \end{tabular}
      \label{tab:results1 on chinese data}
    \end{table}






\begin{figure}[!t]
\centering
%\includegraphics[width=3in]{fig5}
\subfloat[]{
		\includegraphics[height=5.7cm,width=8.5cm]{exp1.png}}\\
\subfloat[]{
		\includegraphics[height=5.7cm,width=8.5cm]{exp2.png}}
\caption{Experimental results to validate the multi-axis evidence by MKE-Coder for the significance of automated ICD coding. For each baseline, use "discharge summary" and "evidence set" by MKE-Coder as inputs respectively. (a) Macro-averaged F1 value is used as the evaluation metric on the y-axis of the graph. (b) Accuracy is used as the evaluation metric on the y-axis of the graph.}
\label{fig_6}
\end{figure}




    The experiment results are displayed in Table \ref{tab:results on chinese data} and \ref{tab:results1 on chinese data}. When comparing the MKE-Coder(evidence set) with other baselines that also use the evidence set as input, on average, the MKE-Coder(evidence set) outperforms the other baselines by 34.51\%, 31.56\%, 33.05\%, 9.09\%, and 5.09\% in precision, recall, F1 score, accuracy, and p@5 metrics respectively, as shown in Table \ref{tab:results on chinese data} and \ref{tab:results1 on chinese data}. This highlights the distinct advantage of our method in the task of automatic ICD coding for Chinese EMRs. Specifically, we effectively capture the key coding basis by leveraging axis-based evidence retrieval and evaluation. By employing an inference module based on the masked language modeling strategy, we ensure that all axis knowledge is supported by evidence and provides appropriate recommendations, thus guaranteeing the accuracy of the results.
   


   
      \begin{table}[t]
      \centering
      \caption{Ablation experimental results to verify the effectiveness of MKE-Coder based on precision, recall, and the F1 index.}
      \renewcommand{\arraystretch}{1.2} % 可以调节, 1.2指高度是默认的1.2倍
      \begin{tabular}{llll}
       \toprule[1.2pt]
        \multirow{2}{*}{Model} & \multicolumn{3}{c}{Macro} \\
        & Precision & Recall &\,F1  \\
        \hline
         MKE-Coder(w/o evidence retrieve) & \lh{63.37\%} & \lh{64.19\%} & \lh{63.78\%}  \\
         MKE-Coder(w/o evidence assessment) & 67.54\% & 68.31\% & 67.92\% \\
        MKE-Coder(w/o prior for template) & 71.12\% & 69.07\% & 70.08\%  \\
        MKE-Coder &  \textbf{73.34\%} & \textbf{71.90\%} & \textbf{72.61\%}  \\
        \bottomrule[1.2pt]
      \end{tabular}
      \label{tab:ablation results on chinese data}
    \end{table}



    \begin{table}[t]
      \centering
      \caption{Ablation experimental results to verify the effectiveness of MKE-Coder based on accuracy and p@5 index.}
      \renewcommand{\arraystretch}{1.2} % 可以调节, 1.2指高度是默认的1.2倍
      \begin{tabular}{lll}
       \toprule[1.2pt]
        Model&Accuracy &p@5 \\
        \hline
         MKE-Coder(w/o evidence retrieve) & \lh{65.25\%} & \lh{69.82\%} \\
         MKE-Coder(w/o evidence assessment) & 68.71\% & 90.35\% \\
        MKE-Coder(w/o prior for template)  & 72.45\% & 91.90\% \\
        MKE-Coder &  \textbf{74.32\%} & \textbf{92.73\%} \\
        \bottomrule[1.2pt]
      \end{tabular}
      \label{tab:ablation results1 on chinese data}
    \end{table}
    

   
    \subsection{Ablation study}

   To delve deeper into the effectiveness of the MKE-Coder framework, we carried out three sets of ablation studies. In the initial ablation experiment, we assessed the necessity of the evidence retrieval module by discarding it and using only the discharge summaries as inputs. The results, as displayed in the MKE-Coder (w/o evidence retrieve) in Table \ref{tab:ablation results on chinese data} and \ref{tab:ablation results1 on chinese data}, demonstrate a decline in performance across all metrics. Specifically, MKE-Coder (w/o evidence assessment) shows a decrease of 9.97\% in precision, 7.71\% in recall, 8.83\% in F1 score, 9.07\% in accuracy, and 22.91\% in p@5 metrics, compared to the full MKE-Coder. This highlights the vital importance and effectiveness of the evidence retrieval module.

    In the second ablation study, we sought to confirm the effectiveness of our evidence evaluation process, which leverages the Clinical-Simbert model we trained. In this experiment, we bypassed the screening process and used the retrieved evidence directly. As shown in the MKE-Coder(w/o evidence assessment) in Table \ref{tab:ablation results on chinese data} and \ref{tab:ablation results1 on chinese data}, the results indicate a performance dip across all metrics. Specifically, MKE-Coder(w/o evidence assessment) performs 2.22\%, 2.83\%, 2.53\%, 1.87\%, and 0.83\% worse than MKE-Coder in terms of precision, recall, F1 score, accuracy, and p@5 metrics, respectively. This underscores the critical role and efficacy of the evidence evaluation module.
   
   

    The final study aimed to validate our design for template in the inference module, where the structure of the input evidence extends beyond the evidence sentence itself to include its origin in the electronic medical record, its frequency throughout the entire record, and the corresponding axis knowledge. In the ablation experiment, we stripped away these additional elements, leaving only the core evidence as input, which is named MKE-Coder(w/o prior knowledge) in Table Table \ref{tab:ablation results on chinese data} and \ref{tab:ablation results1 on chinese data}. As shown in Table Table \ref{tab:ablation results on chinese data} and \ref{tab:ablation results1 on chinese data}, MKE-Coder(w/o prior knowledge) performs 5.8\%, 3.59\%, 4.69\%, 5.61\%, and 2.38\% worse than MKE-Coder in terms of precision, recall, F1 score, accuracy, and p@5 metrics, respectively. This suggests that the auxiliary information we incorporate into each piece of evidence, based on our comprehensive understanding of electronic medical records, offers a tangible benefit.

    \begin{figure}[t]
    \includegraphics[height=4.8cm,width=8cm]{exp5.png}
    \centering
    \caption{The diagram shows the departmental distribution of 100 medical records used for assessing interpretability, sourced from a total of 22 departments. There is a greater number of records from Oncology, Hematology, and Cardiology, while fewer records come from Neurosurgery, Neurology, and Ophthalmology.}
    \label{fig:department}
    \end{figure}
    

   

    
    In conclusion, these ablation studies underscore the significance and potency of our design choices in the inference module and the evidence evaluation module, each of which contributes to the superior performance of the MKE-Coder.

 

    \begin{figure*}[t]
    \includegraphics[height=7cm,width=18cm]{interpre4.pdf}
    \centering
    \caption{Interpretability assessment results of evidence set for the recommended ICD code on 100 Chinese EMRs by ICD coders. (a) The graph provides visual explanations for the three levels of support; (b) The pie chart above compares the scores of evidence retrieved before and after undergoing reliability assessment by the Clinical-Simbert model, based on the level of support for the central knowledge axes of the recommended codes.}
    \label{fig:interperable}
    \end{figure*}

    

   \begin{figure}[t]
    \includegraphics[height=3.5cm,width=11cm]{exp4-1.png}
    \centering
    \caption{The coding accuracy results of junior coders and intermediate coders in three scenarios based on 100 medical records.}
    \label{fig:interperable11}
    \end{figure}

      \begin{figure}[t]
    \includegraphics[height=3.5cm,width=8.5cm]{exp4-2.png}
    \centering
    \caption{The coding speed results (in seconds) of junior coders and intermediate coders in three scenarios based on 100 medical records.}
    \label{fig:interperable12}
    \end{figure}
    
    \subsection{Practicality evaluation in simulated coding scenarios}

    
    We conducted a simulation experiment to evaluate the MKE-Coder's practicality in real coding scenarios. We randomly selected 100 medical records from our test set, sourced from 22 distinct departments, with the specific departmental distribution illustrated in Fig \ref{fig:department}. Three categories of coders with varying levels of experience were invited to participate in the study: novice coders with less than two years of coding experience, intermediate coders with two to five years of experience, and advanced coders with over five years of experience. Each proficiency level included two coders, and all metrics presented in this study are based on the average results.

    Advanced coders were responsible for selecting the correct ICD codes for the 100 medical records, serving as the gold standard. Novice and intermediate coders were tasked with coding in three distinct scenarios: (1) coding with the assistance of our system, which recommends ICD codes and provides supporting evidence for reference; (2) coding with the assistance of an alternative robust baseline model, MSMN, which also offers ICD code recommendations; and (3) independent coding without any system assistance. Following the completion of coding in each scenario, coders underwent a three-week memory washout period before transitioning to the next scenario. 


    
    We recorded the coding accuracy and speed across the three scenarios, as illustrated in Fig \ref{fig:interperable11} and \ref{fig:interperable12}. For novice coders, coding with the assistance of our system resulted in accuracy improvements of 6.66\% and 8.65\% compared to using the MSMN method and coding independently, respectively. Additionally, their coding speed increased by 26.02\% and 34.15\% under the same conditions. These enhancements in both accuracy and speed are notably significant. For intermediate coders, coding with our system yielded accuracy improvements of 3.30\% and 3.35\% over the MSMN method and independent coding, respectively. Although their accuracy performance was relatively higher to begin with, making the gains less pronounced, the increases in coding speed were substantial, with improvements of 33.00\% and 37.38\%. 


    
   

    Because the overall coding accuracy of intermediate coders is higher than that of novice coders, we invited intermediate coders to assess the level of support for each evidence set by MKE-Coder corresponding to the relevant ICD code. We set three levels: fully supported, partially supported, and unable to be supported (Fig \ref{fig:interperable} (a)). 

    \begin{itemize}
    
    \item[$\bullet$]  \textbf{Fully supported:} The evidence fully supports the recommended coding, allowing ICD coders to trust its accuracy, skip reviewing the entire medical record, and enhance coding efficiency.
    \item[$\bullet$]  \textbf{Partially supported:} Partially supported: Some axes of the recommended code are backed by evidence, but others lack support and need further confirmation. Coders can focus on verifying specific axes to improve efficiency.
    \item[$\bullet$]  \textbf{Unable to support:} Unable to support: Insufficient evidence in the set hinders determining the recommended code's accuracy. Coders must review the entire medical record or seek additional sources to ensure coding correctness and completeness.   
    
    \end{itemize}
    
    
    \noindent The pie chart in Fig \ref{fig:interperable} (b) compares the scores of evidence retrieved before and after undergoing reliability assessment by the Clinical-Simbert model.


    
    On the pie chart on the right in Fig \ref{fig:interperable} (b), we can see the level of support for each evidence set by MKE-Coder for the corresponding ICD  code, as evaluated by ICD coders. It shows that almost half of the evidence set can fully support the corresponding ICD code, leading to a significant improvement in coding efficiency. Additionally, nearly half of the evidence set can partially support the recommended ICD code, allowing ICD coders to focus on finding evidence for the remaining aspects lacking supporting evidence. Finally, only 3.84\% of the evidence set is invalid. ICD coders believe that providing evidence makes them trust and accept MKE-Coder more. Even if the evidence is wrong, they can understand why they were wrong and have a higher tolerance for mistakes.


    
  
    
    On the other hand, to evaluate the effectiveness of the Clinical-Simbert model for evidence assessment, we asked ICD coders to mark the supporting degree of each evidence set before assessment, and the results are represented by the left pie chat in Fig \ref{fig:interperable} (b). By comparing the two pie chats, it can be observed that after the evaluation by the Clinical-Simbert model, the levels of "fully supported" and "partially supported" evidence increased by 27\% and 3\% respectively, while the level of "unable to supported" significantly decreased by 31\%. This demonstrates that our Clinical-Simbert model can effectively evaluate the relevance of evidence and corresponding knowledge under the axes of candidate ICD codes, greatly aiding in the provision of valid evidence.
    
\section{Conclusion} 

  In this paper, we address shortcomings in existing methods for automatic ICD coding on Chinese EMRs, which have failed to extract disease code-related information effectively and have neglected the critical multi-axial knowledge fundamental to the ICD coding hierarchy. Consequently, the accuracy and interpretability of the Chinese ICD coding system have been compromised. To overcome these limitations, we introduce a novel framework MKE-Coder.

    Drawing inspiration from the coarse-to-fine classification strategy under the multi-axial knowledge of the ICD codes system and the principles of evidence-based medicine, we developed an evidence retrieval and evaluation module to identify a reliable evidence set for the recommended ICD code. We employed the prompt tuning method to determine whether the candidate ICD code can be fully supported by the evidence set. The experimental results demonstrate that our method has achieved state-of-the-art performance and excellent interpretability. In the practical evaluation of our method within simulated real coding scenarios, it has been demonstrated that our approach significantly aids coders in enhancing both their coding accuracy and speed.

    Our work addresses the shortcomings in previous research regarding the automatic ICD coding of Chinese electronic medical records. It significantly improves the acceptance of frontline coding personnel towards the Chinese automatic ICD coding system. This work holds great value in both research and practical application scenarios.


\newpage
\bibliographystyle{unsrt}
\bibliography{ref}
\end{document}