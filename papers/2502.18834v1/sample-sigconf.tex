%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}
% \settopmatter{printacmref=false} % Removes citation information below abstract
% \renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
% \pagestyle{plain} % removes running headers

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}



%%%%%%%%%%%%%%%%%%%%%%%%% Self-Define %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\TODO}[1]{\textbf{\color{red}[TODO: #1]}}
\usepackage{xspace}
\usepackage{multicol, multirow, threeparttable}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\newcommand{\NAME}{\TODO{NAME}\xspace}

\usepackage[skip=3pt]{caption}


\usepackage{pifont} % \ding{xx}
\usepackage{bbding} % \Checkmark,\XSolid,... (需要和pifont宏包共同使用)
\usepackage{fontawesome} 

\usepackage{forest}
% \usepackage[table]{xcolor}
% \usepackage[dvipsnames]{xcolor}
\usepackage{colortbl}

\newcommand{\name}{FinTSB\xspace}
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}
\crefformat{equation}{Eq.~#2#1#3}

\definecolor{mypurple}{rgb}{0.7, 0, 0.9}
\definecolor{myorange}{rgb}{0.9, 0.7, 0}
\definecolor{bl}{rgb}{0.25, 0.5, 0.9}
\definecolor{cadetblue}{rgb}{0.3, 0.5, 0.7}
\newcommand{\best}[1]{{\textbf{\textcolor{red}{#1}}}}
\newcommand{\second}[1]{{\textcolor{bl}{\underline{#1}}}}
%%%%%%%%%%%%%%%%%%%%%%%%% Self-Define %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Conference acronym 'XX]{Make sure to enter the correct
%   conference title from your rights confirmation emai}{June 03--05,
%   2018}{Woodstock, NY}
% \acmConference[KDD'25]{}{Datasets and Benchmarks Track}{Preprint.}
\acmConference[Conference]{}{Date}{Preprint.}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.

%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

\usepackage{fancyhdr}
\pagestyle{empty}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}



%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.

\title{\name: A Comprehensive and Practical Benchmark for\\Financial Time Series Forecasting}
\renewcommand{\shorttitle}{\name: Financial Time Series Benchmark}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Yifan Hu}
\authornote{Equal contribution}
\affiliation{%
  \institution{Tongji University}
  \city{Shanghai}
  \country{China}}
\email{huyf0122@gmail.com}

\author{Yuante Li}
\authornotemark[1]
\affiliation{%
  \institution{Tongji University}
  \city{Shanghai}
  \country{China}}
\email{liyuante@tongji.edu.cn}

\author{Peiyuan Liu}
\authornotemark[1]
\affiliation{%
 \institution{SIGS, Tsinghua University}
 \city{Shenzhen}
 \country{China}}
\email{peiyuanliu.edu@gmail.com}

\author{Yuxia Zhu}
\affiliation{%
  \institution{Tongji University}
  \city{Shanghai}
  \country{China}}
\email{2253608@tongji.edu.cn}

\author{Naiqi Li}
\affiliation{%
 \institution{SIGS, Tsinghua University}
 \city{Shenzhen}
 \country{China}}
\email{linaiqi@sz.tsinghua.edu.cn}

\author{Tao Dai}
\affiliation{%
  \institution{Shenzhen University}
  \city{Shenzhen}
  \country{China}}
\email{daitao.edu@gmail.com}

\author{Shu-tao Xia}
\affiliation{%
 \institution{SIGS, Tsinghua University}
 \city{Shenzhen}
 \country{China}}
\email{xiast@sz.tsinghua.edu.cn}

\author{Dawei Cheng}
\authornote{Corresponding author: Dawei Cheng}
\affiliation{%
  \institution{Tongji University \& Shanghai Artificial Intelligence Laboratory}
  \city{Shanghai}
  \country{China}}
\email{dcheng@tongji.edu.cn}

\author{Changjun Jiang}
\affiliation{%
  \institution{Tongji University \& Shanghai Artificial Intelligence Laboratory}
  \city{Shanghai}
  \country{China}}
\email{cjjiang@tongji.edu.cn}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Yifan Hu, Yuante Li, Peiyuan Liu, Yuxia Zhu, Naiqi Li,\\Tao Dai, Shu-tao Xia, Dawei Cheng and Changjun Jiang}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Financial time series (FinTS) record the behavior of human-brain-augmented decision-making, capturing valuable historical information that can be leveraged for profitable investment strategies. Not surprisingly, this area has attracted considerable attention from researchers, who have proposed a wide range of methods based on various backbones. 
  However, the evaluation of the area often exhibits three systemic limitations: 1. Failure to account for the full spectrum of stock movement patterns observed in dynamic financial markets. (\textbf{\textit{Diversity Gap}}), 2. The absence of unified assessment protocols undermines the validity of cross-study performance comparisons. (\textbf{\textit{Standardization Deficit}}), and 3. Neglect of critical market structure factors, resulting in inflated performance metrics that lack practical applicability. (\textbf{\textit{Real-World Mismatch}}).
  Addressing these limitations, we propose \name, a comprehensive and practical benchmark for financial time series forecasting (FinTSF).
  To increase the variety, we categorize movement patterns into four specific parts, tokenize and pre-process the data, and assess the data quality based on some sequence characteristics. 
  To eliminate biases due to different evaluation settings, we standardize the metrics across three dimensions and build a user-friendly, lightweight pipeline incorporating methods from various backbones. 
  To accurately simulate real-world trading scenarios and facilitate practical implementation, we extensively model various regulatory constraints, including transaction fees, among others.
  Finally, we conduct extensive experiments on \name, highlighting key insights to guide model selection under varying market conditions. 
  Overall, \name provides researchers with a novel and comprehensive platform for improving and evaluating FinTSF methods.
  The code is available at \url{https://github.com/TongjiFinLab/FinTSBenchmark}.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010178</concept_id>
       <concept_desc>Computing methodologies~Artificial intelligence</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010405.10003550</concept_id>
       <concept_desc>Applied computing~Electronic commerce</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Applied computing~Economics}
\ccsdesc[500]{Information systems~Data mining}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Financial Time Series, Computational Finance, Quantitative Trading, Benchmark}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}

% 介绍背景
Financial time series (FinTS) forecasting stands as a pivotal pillar within the realm of quantitative finance, offering profound insights that underpin the formulation of lucrative investment strategies~\cite{survey,cisthpan,8425030,fints,mcigru,lsrigru}. 
Unlike general time series prediction challenges~\cite{amd,timebridge,pdf,timefilter}, stock prices are not merely statistical series but the manifestation of complex, often chaotic human behavior shaped by many cognitive, emotional, and sociopolitical factors. Accurately forecasting future returns amidst this maelstrom of data can unlock extraordinary financial gains, positioning it as an invaluable tool for strategic decision-making. As a result, FinTSF has emerged as a cutting-edge domain of scholarly exploration, drawing intense interest from the global research community.


\begin{figure}[!t]
\centering
\begin{forest}
 for descendants={anchor=west,child anchor=west},
 grow=east,anchor=north,parent anchor=south,
 l sep=1cm,
 for tree={fill=white, draw=blue, rounded corners, inner sep=5pt, scale=0.75},
 [root,rotate=90, content={Financial Time Series Forecasting Methods},
   [,content={\ding{177} LLM-Based Methods}, text width=1.6cm, text centered, parent anchor=east,grow=east
     [,content={LLM-based MAS: FinCon~\cite{fincon},  
     TradingGPT~\cite{tradinggpt}, FinMem~\cite{finmem}, ...}, text width=5cm]
     [,content={LLM as a Predictor: TimeMoe~\cite{timemoe}, ...}, text width=5cm ]
     [,content={LLM as a Enhancer: CausalStock~\cite{causalstock}, FinAgent~\cite{finagent}, ...}, text width=5cm ]
   ]
   [,content={\ding{176} Generative-Based Methods: FactorVAE~\cite{FactorVAE}, DiffStock~\cite{diffstock}, Diffsformer~\cite{diffsformer}, Market-GAN~\cite{marketgan}, ...}, text width=8cm]
   [,content={\ding{175} RL-Based Methods: AlphaStock~\cite{alphastock}, FinRL~\cite{finrl},  DeepTrader~\cite{deeptrader}, FreQuent~\cite{frequent}, IMM~\cite{imm}, ...}, text width=7cm]
   [,content={\ding{174} DL-Based Methods}, text width=1.4cm, text centered, parent anchor=east,grow=east
     [,content={MASTER~\cite{master}, CI-STHPAN~\cite{cisthpan}, VGNN~\cite{VGNN}, ...}, text width=2.3cm, parent anchor=east,grow=east
       [,content={Inter-Stock Corr.}]
       [,content={Temporal Features}, ]
     ]
   ]
   [,content={\ding{173} ML-Based Methods: XGBoost~\cite{xgboost}, SVM~\cite{svmsotck}, ...}]
   [,content={\ding{172} Classic Strategies: CSM~\cite{csm}, BLSW~\cite{blsw}, ...}]
 ]
\end{forest}
\caption{FinTSF methods classified by backbone architectures and their representative works.}
\Description{..}
\label{fig:category}
\end{figure}

% 介绍现有方法 类似综述分类

Financial time series refers to a sequence of data points ordered chronologically, typically representing asset price factors or market indicators, that reflect the dynamic behavior of financial markets.
% 分类
As shown in \cref{fig:category}, existing FinTSF methods can be broadly categorized into six types based on their underlying backbone approach. 
Early methods were primarily rooted in classic strategies derived from practitioner experience, \ding{172} \textbf{\textit{classic quantitative trading strategies}} such as momentum~\cite{csm} and mean reversion~\cite{blsw} strategies. 
\ding{173} \textbf{\textit{machine learning-based methods}}~\cite{svmsotck,xgbooststock,rfstock} include a wide range of algorithms, including autoregressive models like ARIMA~\cite{arima} and tree-based models like XGBoost~\cite{xgboost}, LightGBM~\cite{lightgbm}, and Random Forests~\cite{randomforest}, each of which offers distinct advantages in capturing non-linear relationships in financial data.
In recent years, \ding{174} \textbf{\textit{deep learning-based methods}}~\cite{master,lsrigru,cisthpan,timefilter,timebridge,thgnn,tcgpn} have demonstrated state-of-the-art (SOTA) performance by leveraging various neural network architectures (e.g. RNN, CNN, Transformer, Mamba, GNN) to model both stock features and inter-stock correlations, becoming a dominant paradigm in the FinTSF field. 
Moreover, \ding{175} \textbf{\textit{reinforcement learning-based methods}}~\cite{ppo,deeptrader,deeppocket,finrl,ccso} have also emerged as another promising direction to better optimize sequential decision making processes and end-to-end optimization of some key non-differentiable metrics (such as the sharpe ratio, maximum drawdown). 
Additionally, to better capture the inherent noise and uncertainty within financial markets, \ding{176} \textbf{\textit{generative model-based methods}}~\cite{FactorVAE,newsdiff,diffagent,diffstock,diffsformer}, such as Variational Autoencoders (VAE) and Diffusion Models, have been adapted to reflect the heightened levels of uncertainty characteristic of the market, accounting for the low signal-to-noise FinTS.
Recently, Large Language Models (LLMs) have attracted considerable attention due to their ability to process vast amounts of unstructured data and perform sophisticated reasoning. \ding{177} \textbf{\textit{LLM-based methods}} have found diverse applications in FinTSF, including: \textit{as an enhancer}~\cite{causalstock,finagent}, where they utilize news sentiment and other textual information to augment decision making; \textit{as a predictor}~\cite{calf,timemoe}, where they leverage extensive time series training to generalize effectively across different domains; and in \textit{LLM-based multi-agent systems (MAS)}~\cite{fincon,finmem,tradinggpt}, where autonomous agents are employed to replicate decision-making processes, communication, and interactions. 


As the number of proposed methods expands across various settings, the demand for comprehensive and practical empirical evaluations has correspondingly increased. However, as depicted in \cref{fig:intro}, existing evaluation frameworks often face challenges such as \textbf{\textit{Diversity Gap}}, \textbf{\textit{Standardization Deficit}}, and \textbf{\textit{Real-World Mismatch}}, which hinder their ability to fully assess the performance of these methods in real-world contexts. To address these limitations, we introduce \name, a novel evaluation framework designed to enhance the robustness and applicability of empirical assessments, thereby improving the evaluation capabilities in FinTSF.



\begin{figure}[t]
    \centering
    \includegraphics[width=0.49\textwidth]{images/intro.pdf}
    \caption{
         In the field of financial time series forecasting, existing evaluation frameworks often face three issues:  \textbf{\textit{Diversity Gap}}, \textbf{\textit{Standardization Deficit}}, and \textbf{\textit{Real-World Mismatch}}.
    }
    \vspace{-0.9em}
    \Description{..}
    \label{fig:intro}
\end{figure}


% Diversity Gap
% Standardization Deficit
% Real-World Mismatch

\textbf{Issue} \ding{182}: \textbf{\textit{Diversity Gap}}.
Given the inherent complexity of financial markets, which often include different phases of stock movement such as uptrends, downtrends, periods of volatility, and extreme events (black swan events), current evaluation datasets face several limitations. On the one hand, some datasets contain only three to five years of historical data, which fails to comprehensively represent all possible movement patterns, thus hindering the generalization capacity of models and preventing them from effectively handling unseen patterns in the training set. On the other hand, datasets covering over a decade of data suffer from severe distribution shifts, resulting in reduced model accuracy when confronted with current market conditions. These shortcomings prevent existing evaluations from providing a complete picture of stock movement behavior. 
In addition, FinTS exhibits distinct characteristics in different markets. For example, the Chinese stock market is often characterized by high retail participation and higher volatility, while the U.S. market tends to have a more balanced mix of institutional and retail investors with a generally higher degree of efficiency. Some existing works evaluate models in only one market, which does not provide a holistic view of their performance.

Our approach emphasizes the diversity of FinTS, focusing on both the comprehensiveness of \textit{movement patterns} and \textit{the broad scope of financial markets}. This allows for a more thorough assessment of model performance. Specifically, in terms of movement patterns, we advocate a fine-grained analysis of how different methods perform over different periods of market volatility, with the aim of more accurately reflecting real-world scenarios.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\textwidth]{images/patterns.pdf}
    \caption{
         Visualization of financial time series data with different movement patterns.
    }
    \vspace{-0.9em}
    \Description{..}
    \label{fig:patterns}
\end{figure}


\textbf{Issue} \ding{183}. \textbf{\textit{Standardization Deficit}}:
In the existing literature, discrepancies in evaluation criteria lead to inconsistencies in performance comparisons. To address this issue, we classify the current evaluation metrics into three main categories: \textit{ranking metrics}, which assess the distribution between predicted and actual daily returns; \textit{portfolio-based metrics}, which evaluate the profitability and risk of investment strategies derived from predictions; and \textit{error metrics}, which quantify the degree of approximation between predicted and true values. Nevertheless, it is important to note that forecasting errors show little correlation with overall investment returns.

On top of that, current FinTSF methods lack a standardized pipeline for evaluation. Evaluating SOTA models often requires re-running them on proprietary datasets and settings, which is both time-consuming and labor-intensive. In addition, factors such as differences in data pre-processing, feature engineering, and model tuning further complicate fair comparisons. While the Qlib~\cite{qlib} framework offers a wealth of practical tools, its steep learning curve remains a significant barrier. There is an urgent need for a unified, user-friendly, and lightweight evaluation framework in FinTSF, similar to those found in general time series forecasting fields, such as TSLib~\cite{tslib} and TFB~\cite{TFB}.


\textbf{Issue} \ding{184}: \textbf{\textit{Real-World Mismatch}}.
The ultimate goal of FinTSF methods is to be deployed in real-world trading scenarios and to generate actual investment returns in the highly competitive, human-brain-armed environment of financial markets. As a result, there are stringent requirements for simulating realistic trading conditions. Existing research often overlooks these constraints, resulting in overly optimistic portfolio metrics. For example, some models still assume short selling in the Chinese A-share market, which is impractical due to restrictions in certain sectors. Moreover, many studies do not take transaction fees into account, which is particularly critical when constructing portfolios based on the prediction of stocks with top-$k$ returns. High turnover rates without considering transaction costs can result in significant overlooked expenses that negatively impact the profitability of the strategy. Furthermore, many works neglect trading restrictions such as limit-ups or trading halts, which are common in various markets and can have a profound effect on trading strategies.
Thus, we emphasize the necessity of incorporating these real-world constraints into evaluations to ensure more objective and accurate assessments of model performance.


The importance of benchmarking in any field cannot be overstated, as it provides a common basis for comparing the performance of different approaches. Similar to computer vision, where benchmarks such as ImageNet~\cite{imagenet} or COCO~\cite{coco} provide standardized datasets against which models can be evaluated, the absence of a consistent benchmark in FinTSF leads to fragmented and incomparable results. Without a standardized evaluation, it becomes difficult to gauge the true effectiveness of models in real-world applications. By addressing the three key issues of establishing a consistent dataset for fair comparisons, ensuring comprehensive evaluation metrics, and considering real-world trading constraints, the FinTSF community will be able to establish a solid foundation for model assessment, ultimately advancing the field and improving its applicability in real-world investment scenarios.

Building on the above motivations, we propose \name, a comprehensive and practical financial time series benchmark. This dataset first tokenizes sensitive information and then pre-processes real historical stock data from multiple financial markets to mitigate distribution shifts. It categorizes the data into four distinct movement patterns based on daily change rates and assesses the data quality through sequence-based metrics. Additionally, we conduct fair and robust evaluations of a diverse set of FinTSF methods, including all six different backbone models, and derive insightful and critical research conclusions. In a nutshell, our contributions are as follows:

\begin{itemize}
    \item \textbf{\textit{Diversity Inclusion.}} We collect and pre-process tokenization historical financial time series data to provide \name, which captures all types of movement patterns across various markets.
    \item \textbf{\textit{Standardization Consistency.}} We advocate for a comprehensive evaluation of the capabilities of various methods from three perspectives: ranking, portfolio, and error, which ensures a holistic assessment.
    \item \textbf{\textit{Real-World Alignment.}} We meticulously design investment strategies that align with real-world market conditions, facilitating practical implementation in actual trading environments.
    \item \textbf{\textit{In-depth Evaluation.}} We evaluate a wide range of FinTSF methods and extract key insights that advance the understanding of model performance in the context of financial time series forecasting.
\end{itemize}

The paper is organized in the following manner: \cref{sec:rela} provides a review of related work, while \cref{sec:prel} introduces the definitions of FinTSF tasks and relevant concepts. In \cref{sec:fintsb}, we present the design of \name, and \cref{sec:exp} evaluates existing FinTSF methods using our benchmark. Finally, \cref{sec:con} concludes the paper.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{images/hexbin.pdf}
    \caption{
         Hexbin plots illustrating the normalized density values of the low-dimensional feature spaces generated by PCA, applied to stock features such as open price, close price, high price, low price, and trading volume for \name, alongside four different time-sliced stock data.
    }
    \Description{..}
    \label{fig:hexbin}
\end{figure}

\section{Related Work}\label{sec:rela}

% \subsection{Financial Time Series Forecasting}
% \subsection{Financial Benchmarks}

To date, there remains a significant gap in the availability of a comprehensive dataset of financial time series. Existing studies typically focus on specific slices of historical stock data for their experiments. For example, ALSP-TF~\cite{ALSP}, ADB-TRM~\cite{ADBTR}, and CI-STHPAN~\cite{cisthpan} utilize New York Stock Exchange (NYSE) and NASDAQ stocks for the period from 2013 to 2017. Meanwhile, MASTER~\cite{master}, FactorVAE~\cite{FactorVAE}, LARA~\cite{lara}, and RSAP-DFM~\cite{rsapdfm} select data from the Chinese A-share market, but with distinct temporal ranges: MASTER~\cite{master} covers 2008 to 2022, FactorVAE~\cite{FactorVAE} covers 2010 to 2020, and both LARA~\cite{lara} and RSAP-DFM~\cite{rsapdfm} cover 2008 to 2020. Similarly, LSR-iGRU~\cite{lsrigru}, FinMamba~\cite{finmamba}, and MCI-GRU~\cite{mcigru}, as well as THGNN~\cite{thgnn}, focus on stocks from both the Chinese and U.S. markets, with time slices ranging from 2018 to 2023 and 2016 to 2021, respectively. Qlib~\cite{qlib} provides a wealth of raw data and factor data, from which users can extract the segments they need.
The varying time horizons of these data slices pose a challenge to consistent and fair evaluations.
Furthermore, after applying Principal Component Analysis (PCA)~\cite{pca} for dimensionality reduction, we visualized \name and other time-sliced stocks as a hexbin plot in \cref{fig:hexbin}. The results indicate that \name covers the most cells, suggesting that reliance on sliced historical data lacks diversity. In contrast, \name offers more comprehensive coverage, thus effectively capturing the complex distribution of financial time series.


\section{Preliminaries}\label{sec:prel}

In this section, we will introduce some related concepts and formally define the problem of financial time series forecasting. 

\subsection{Problem Definition}

\paragraph{\textbf{Definition 1. Stock Context.}}
Let the set of all stocks be denoted as $\mathcal{S}=\{s_1, s_2, ..., s_N\}\in\mathbb{R}^{N\times L\times F}$, where $s_i$ is a specific stock, $N$ is the total number of stocks, $L$ is the length of the lookback window and $F$ is the number of features.
For each stock $s_i$, its data on trading day $t$ is represented by $s_i^t\in\mathbb{R}^F$, with the closing price $p_i^t$ as one of the features. The one-day return ratio is given by $r_i^t = \frac{p_i^t-p_i^{t-1}}{p_i^{t-1}}$.
On any trading day $t$, stocks are ranked according to their underlying scores $Y^t=\{y_1^t\geq y_2^t\geq...\geq y_N^t\}$. 
If $r_i^t\geq r_j^t$, then $y_i^t\geq y_j^t$, establishes an overall ranking based on return ratios. 
This ranking reflects the expected investment returns for each stock on day $t$, where stocks that achieve higher ranking scores $Y$ are expected to achieve a higher investment revenue (profit) on day $t$. 

\paragraph{\textbf{Problem 1. Financial time series forecasting.}}
Formally, given the stock-specific time series information of $\mathcal{S}$, the goal is to develop a ranking function that predicts the scores $Y^{L+1}$ for the next day, ordering the stocks $s_i$ by their expected profitability.

\subsection{Sequence Characteristics}

To explore the intrinsic properties of financial time series data, we introduce the following sequence characteristics. This allows for a more thorough evaluation of the sophisticated dynamics within stock market behavior, providing deeper insights into the underlying patterns and trends that drive financial assets.

\paragraph{\textbf{Characteristic 1. Movement Patterns.}}
Based on the daily return ratio $r$, derived from the closing price changes, FinTS can be categorized into different periods, each characterized by a dominant movement pattern, including uptrends, downtrends, periods of volatility, and extreme events.
Specifically, uptrends are characterized by a higher frequency of trading days with positive $r$, while downtrends are marked by a higher frequency of trading days with negative $r$. Extreme events are defined by significant fluctuations in $r$, representing periods of sharp price movements. Conversely, periods of volatility are identified by a roughly equal number of positive and negative $r$, indicating more frequent market fluctuations without a clear directional trend.


\paragraph{\textbf{Characteristic 2. Non-Stationarity.}}
It is well known that stock data, due to their inherent volatility and external influences, typically exhibit non-stationarity, reflecting complex, time-varying patterns that defy simple statistical modeling.
Such time series are considered to be integrated of order $k$, denoted as $I(k)$, if it becomes stationary after applying $k$ times differences. For example, a stock series $s_i^t$ is $I(1)$ if its first difference $\Delta s_i^t = s_i^t - s_i^{t-1}$ is stationary. To test for non-stationarity, the Augmented Dickey-Fuller (ADF) test \citep{adf} is commonly employed. 
It tests the null hypothesis of the presence of a unit root, indicating non-stationarity:

\begin{equation}
    \Delta s_i^t = \alpha + \beta t + \gamma s_i^{t-1} + \sum_{j=1}^{p} \delta_j \Delta s_i^{t-j} + \epsilon_t
\end{equation}

Where $\Delta X_t$ is the differenced series, $\gamma$ represents the coefficient of the lagged series, and $\epsilon_t$ is the error term. A rejection of the null hypothesis ($\gamma = 0$) indicates stationarity, while a failure to reject it indicates non-stationarity. A smaller ADF test result indicates more stationary time series data.


\paragraph{\textbf{Characteristic 3. Autocorrelation.}}
Autocorrelation~\cite{acf} measures the correlation between a time series and its $k$ lagged values. Strong autocorrelation $\tau(\cdot)$ suggests that past values of the series have a significant influence on future values, which can be valuable for predictive modeling and identifying underlying patterns. Mathematically, this can be expressed as:
\begin{equation}
    \tau(s_i)=\frac{\sum_{t=1}^{L-k}(s_i^t-\bar{s_i})(s_i^{t+k}-\bar{s_i})}{\sum_{t=1}^L(s_i^t-\bar{s_i})^2}
\end{equation}


\paragraph{\textbf{Characteristic 4. Forecastability.}}
Forecasting is inextricably linked to the time domain. Following ForeCA~\cite{foreca}, we can leverage frequency domain properties to assess the forecastability $\phi(\cdot)$ of a time series. A higher value $\phi(x)$ indicates that series $x$ exhibits a lower forecast uncertainty as measured by the entropy.
\begin{equation}
    \phi(s_i)=1-\frac{H(s_i)}{\text{log}(2\pi)}
\end{equation}
where $H(\cdot)$ denotes the entropy derived from the Fourier decomposition of the time series.


\renewcommand{\arraystretch}{1.1}
\begin{table}[t]
\setlength{\tabcolsep}{4pt}
\caption{Statistics of \name.}
\resizebox{0.45\textwidth}{!}
{
\begin{tabular}{c|cccc}
\toprule

Movement Patterns & Non-Stationarity & Autocorrelation & Forecastability & Split \\

\midrule
Uptrends & -12.35 & 0.678 & 0.187 & 7:1:2  \\
\midrule
Downtrends & -16.25 & 0.681 & 0.092 & 7:1:2  \\
\midrule
Volatility & -15.63 & 0.676 & 0.112 & 7:1:2  \\
\midrule
Extreme & -15.48 & 0.639 & 0.068 & 7:1:2  \\

\bottomrule

\end{tabular}
}
\label{tab:dataoverview}
\end{table}


\section{\name}\label{sec:fintsb}

\subsection{Dataset Details}

\subsubsection{Dataset Construction}

% 逐步从原始数据构建的过程, 从原始数据的全部处理,比如易错的归一化
We construct the FinTSB dataset by tokenizing and pre-processing a large amount of raw stock data. Specifically, we first divide 15 years of historical stock data into non-overlapping segments to prevent data leakage. Then, we calculate the daily return (change rate) $r$ for each stock and, based on this metric, categorize the stocks in each fixed 250-day segment into one of four distinct movement patterns. If there are extreme outliers in the change rate, the stocks are classified as black swan events. Next, we rank the remaining stocks based on a positive change rate, selecting the top 300 as uptrends, the bottom 300 as downtrends, and the remaining 300 as periods of volatility. Afterward, we compute sequence characteristics for each pattern and select the five most appropriate ones.
It is important to note that in the pre-processing stage, we need to avoid future information leakage, which necessitates normalization at the stock dimension for each trading day, rather than across the time dimension. Through the above steps, we generate five smaller datasets for each of the four movement patterns, resulting in a total of 20 datasets in the \name. This ensures that \name is comprehensive and diverse, accurately reflecting the dynamics of the financial market.

\subsubsection{Dataset Overview}

The benchmark, \name, contains a total of 20 datasets, representing four different movement patterns, with each dataset containing 300 stocks over 250 consecutive trading days. We have carefully designed the dataset selection strategy to ensure that there is no overlap between any two datasets. During training, each dataset is split into training, validation, and test sets in a 7:1:2 ratio. The statistics for each movement pattern are summarized in \cref{tab:dataoverview}. All patterns exhibit strong non-stationarity, with extreme event patterns being particularly prominent, highlighting the low signal-to-noise ratio typical of financial data. 
Autocorrelation measures the degree to which a stock's past price movements influence its future behavior. It can be observed that stocks in the uptrend and downtrend patterns tend to exhibit higher autocorrelation, reflecting the persistence of their directional movements, while stocks in volatile periods show weaker autocorrelation due to frequent reversals. The predictability of different movement patterns varies significantly, with uptrends and downtrends generally being more predictable, while periods of volatility and extreme events pose greater forecasting challenges due to their inherent unpredictability and the occurrence of abrupt, large price movements.
Overall, \name encompasses a wide variety of sequence indicators, ensuring that it captures the multifaceted nature of FinTS. By integrating these key characteristics, \name enables the exploration of diverse forecasting challenges.


\subsection{Comparison Baselines}

To investigate the advantages and limitations of different methods, as well as their adaptability across different patterns, our evaluation covers the six categories of methods mentioned previously. 
For classic strategies, we choose CSM \cite{csm} and BLSW \cite{blsw}. 
In terms of ML-based methods, we include XGBoost \cite{xgboost}, LightGBM \cite{lightgbm}, DoubleEnsemble~\citeyearpar{DoubleEnsemble} and ARIMA \cite{arima}.
Among DL-based methods, we choose Linear, LSTM \cite{lstm}, ALSTM \cite{alstm}, GRU \cite{gru}, GCN \cite{gcn}, GAT \cite{gat}, TCN~\cite{TCN}, Transformer \cite{attention}, Mamba \cite{mamba}, PatchTST \cite{patchtst}, Crossformer \cite{crossformer}, iTransformer \cite{itransformer}, AMD~\cite{amd}, PDF~\cite{pdf}, Localformer~\cite{localformer}.
For RL-based methods, we include PPO \cite{ppo}, DDPG \cite{ddpg}, SAC \cite{SAC} and DQN \cite{dqn}.
For Generative-based methods, we choose DDPM \cite{ddpm}, DDIM \cite{ddim} and FactorVAE \cite{FactorVAE}.
For LLM-based methods, we include Timer \cite{timer}, Time-MoE \cite{timemoe} and Chronos \cite{chronos}.

\subsection{Evaluation Metrics}
Existing work on FinTSF evaluation varies. To achieve a consistent and comprehensive assessment of forecast performance, we employ eleven metrics across three dimensions, including ranking, portfolio, and error. The detailed explanation is provided below.

\subsubsection{Ranking Metrics}
Ranking metrics systematically assess the performance of predicted ranking scores (returns) $Y$ in quantitative research, measuring both cross-sectional and predictive power. 

\textit{Information Coefficient (IC)} quantifies the directional alignment between $Y$ and subsequent true returns $r$, calculated as the Spearman correlation coefficient. It evaluates the raw predictive power of scores $Y$, with statistically significant positive IC values indicating economically meaningful forecasting power.
\begin{equation}
    \text{IC}=\frac{1}{N}\sum_{i=1}^{N}\frac{\sum_{k=1}^{t}(r_i^k-\bar{r_i})(Y_i^k-\bar{Y_i})}{\sqrt{\sum_{k=1}^{t}(r_i^k-\bar{r_i})^2}\cdot\sqrt{\sum_{k=1}^{t}(Y_i^k-\bar{Y_i})^2}}
\end{equation}

\textit{Information Coefficient Information Ratio (ICIR)} measures the stability of the performance of $Y$ by comparing the annualized mean IC with its temporal volatility. ($\text{ICIR}=\frac{\text{mean}(\text{IC})}{\text{std}(\text{IC})}$)

\textit{Rank Information Coefficient (RankIC)} is the Spearman correlation metric that employs dual-ranking normalization: both $Y$ and $r$ are converted to uniform percentile ranks before calculating the correlation. This process eliminates scaling artifacts and reduces sensitivity to outlier bias, which is particularly beneficial when analyzing non-linear factor-response relationships.
\begin{equation}
    \text{RankIC}=1-\frac{1}{N}\sum_{i=1}^{N}\frac{6\sum_{k=1}^{t}(R(r_i^k)-R(Y_j^k))^2}{t(t^2-1)}
\end{equation}
where $R(\cdot)$ is the rank function.

\textit{Rank Information Coefficient Information Ratio (RankICIR)} evaluates the reliability of rank-based relationships between $Y$ and $r$. ($\text{RankICIR}=\frac{\text{mean}(\text{RankIC})}{\text{std}(\text{RankIC})}$)

\subsubsection{Portfolio-Based Metrics}
Portfolio-based metrics evaluate the performance and risk characteristics of investment strategies through simulated portfolio implementation. These metrics provide a perspective for assessing both absolute and risk-adjusted returns, drawdown behavior, and strategy efficiency of FinTSF methods.

\textit{Annualized Return Ratio (ARR)} measures the geometric mean return of a strategy annualized over the evaluation period and serves as the primary indicator of strategy profitability. ($\text{ARR}=(1+\text{Total Return})^{\frac{252}{n}}-1$)

\textit{Annualized Volatility (AVol)} quantifies the dispersion of strategy returns and captures the consistency of performance delivery, with lower values indicating more stable return streams. $R_p$ denotes the daily return of the portfolio. ($\text{AVol}=\sqrt{252\cdot\text{Var}(R_p)}$)

\textit{Maximum Draw Down (MDD)} represents the largest peak-to-trough decline ($p_{peak}-p_{trough}$) in portfolio value over the evaluation period and is critical in assessing the strategy's risk tolerance and ability to preserve capital. ($\text{MDD}=-\text{max}\bigg(\frac{p_{peak}-p_{trough}}{p_{peak}}\bigg)$)

\textit{Annualized Sharpe Ratio (ASR)} measures the excess return per unit of total risk, assessing risk-adjusted performance. ($\text{ASR}=\frac{\text{ARR}}{\text{AVol}}$)

\textit{Information Ratio (IR)} assesses the ability to generate excess returns relative to a benchmark and the effectiveness of active management. $\text{IR} = \frac{\text{mean}(R_p-R_b)}{\text{std}(R_p-R_b)}$, where $R_b$ is the daily return of the market index.


\subsubsection{Error Metrics}
Some reviewers emphasize the use of mean square error (MSE) and mean absolute error (MAE) to quantify the discrepancy between predicted $Y$ and actual returns $r$. However, \textit{it is important to note that a lower MSE or MAE does not guarantee profitability; market impact, position sizing rules and transaction costs ultimately determine the success of the strategy.}
The formulations are: $\text{MSE}=\frac{1}{L}\sum_{t=0}^{L}(Y_{i}^t-r_i^t)^2$, $\text{MAE}=\frac{1}{L}\sum_{t=0}^{L}|Y_{i}^t-r_i^t|$.

\subsection{Unified Pipeline}

As discussed in \textit{Issue \ding{183}}, the use of divergent evaluation criteria has led to differences in model performance. To ensure a fair, comprehensive, and practical evaluation, we introduce a unified pipeline that is structurally divided into the data layer, the training layer, the backtesting layer, and the feedback layer. A detailed description of each module is provided below.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.46\textwidth]{images/pipeline.pdf}
    \caption{
         The pipeline of \name with four integral modules.
    }
    \vspace{-1em}
    \Description{..}
    \label{fig:pipeline}
\end{figure}

\textit{Data Layer} stores comprehensive market information in \name, encompassing four different movement patterns. For data pre processing, we implement tokenization (anonymization) and normalization operations. The dataloader dynamically constructs global training/validation/test sets based on the selected movement modes. Researchers can evaluate model performance under identical market conditions by maintaining consistent modes for training and testing phases. Cross-pattern evaluation through transfer learning (training on selected patterns and testing on others) enables granular analysis of strategy adaptability across market regimes, which is particularly valuable for assessing model generalization capabilities. Additionally, historical stock market data verification validates model effectiveness in real-world financial scenarios.

\renewcommand{\arraystretch}{0.855}
\begin{table*}[!ht]
\setlength{\tabcolsep}{4.5pt}
\centering
\caption{Performance evaluation of compared models for financial time series forecasting in \name. The best and least favorable results are highlighted in \textbf{bold} and \underline{underline}, respectively.}
\resizebox{\textwidth}{!}
{
\begin{tabular}{cc|ccccccccccc}
\toprule
\rowcolor{cadetblue!10} \multicolumn{13}{c}{\textbf{\name Evaluation}} \\

\cmidrule(lr){1-13}

\rowcolor{cadetblue!20} \multicolumn{2}{c}{} & \multicolumn{2}{c|}{\textbf{Error Metrics}} & \multicolumn{4}{c|}{\textbf{Ranking Metrics}} & \multicolumn{5}{c}{\textbf{Portfolio-Based Metrics}} \\

\rowcolor{cadetblue!20} \multicolumn{2}{c}{\multirow{-2}*{\textbf{Methods}}} & \makebox[0.9cm]{MSE$\downarrow$} & \multicolumn{1}{c|}{\makebox[0.9cm]{MAE$\downarrow$}} & \makebox[0.9cm]{IC$\uparrow$} & \makebox[0.9cm]{ICIR$\uparrow$} & \makebox[0.9cm]{RankIC$\uparrow$} & \multicolumn{1}{c|}{\makebox[1.2cm]{RankICIR$\uparrow$}} & \makebox[0.9cm]{ARR$\uparrow$} & \makebox[0.9cm]{AVol$\downarrow$} & \makebox[0.9cm]{MDD$\downarrow$} & \makebox[0.9cm]{ASR$\uparrow$} & \makebox[0.9cm]{IR$\uparrow$} \\
\midrule
\rowcolor{gray!10} \parbox{2cm}{\centering Classic} & BLSW~\citeyearpar{blsw}  & - & - & - & - & - & - & 0.152 & 0.120 & \textbf{-0.061} & 0.865 & 0.000 \\
\rowcolor{gray!10} \parbox{2cm}{\centering Strategies} & CSM~\citeyearpar{csm}   & - & - & - & - & - & - & \underline{-0.143} & 0.115 & -0.075 & \underline{-1.409} & -0.559 \\
\midrule
\multirow{4}{*}{\parbox{2cm}{\centering ML-Based\\Methods}}
& ARIMA~\citeyearpar{arima} & 0.017 & 0.382 & 0.0002 & 0.055 & 0.0003 & 0.023 & 0.062 & 0.088 & -0.139 & 0.776 & 0.0002 \\
& XGBoost~\citeyearpar{xgboost} & 0.015 & 0.365 & 0.098 & 0.308 & 0.095 & 0.283 & 0.221 & 0.136 & -0.142 & 1.628 & 0.047 \\
& LightGBM~\citeyearpar{lightgbm} & 0.016 & 0.382 & \textbf{0.109} & 0.533 & 0.086 & 0.345 & 0.171 & 0.102 & -0.196 & 1.679 & 0.109 \\
& DoubleEnsemble~\citeyearpar{DoubleEnsemble} & 0.017 & 0.383 & 0.011 & 0.122 & 0.081 & 0.122 & 0.191 & 0.105 & -0.135 & 1.813 & 0.114 \\
\midrule
\rowcolor{gray!10} & Linear (Ridge) & \textbf{0.012} & 0.325 & 0.007 & 0.061 & 0.008 & 0.099 & 0.026 & \underline{0.140} & -0.129 & 0.186 & 0.073 \\
\rowcolor{gray!10} & Linear (NNLS) & 0.017 & 0.382 & 0.013 & 0.146 & 0.009 & 0.166 & 0.072 & 0.105 & -0.127 & 0.686 & 0.013 \\
\rowcolor{gray!10} & LSTM~\citeyearpar{lstm} & 0.165 & 0.331 & 0.028 & 0.421 & 0.015 & 0.275 & 0.198 & 0.095 & -0.268 & 2.083 & \textbf{0.125} \\
\rowcolor{gray!10} & Adv-LSTM~\citeyearpar{alstm} & \underline{0.167} & 0.335 & -0.005 & -0.092 & 0.001 & -0.004 & 0.124 & 0.084 & \underline{-0.282} & 1.472 & -0.022 \\
\rowcolor{gray!10} & GRU~\citeyearpar{gru} & 0.166 & 0.332 & 0.002 & 0.034 & 0.007 & 0.121 & 0.179 & 0.093 & -0.199 & 1.937 & 0.009 \\
\rowcolor{gray!10} & TCN~\citeyearpar{TCN} & 0.166 & 0.332 & 0.006 & 0.093 & 0.004 & 0.071 & 0.148 & 0.092 & -0.259 & 1.611 & 0.027 \\
\rowcolor{gray!10} & GCN~\citeyearpar{gcn} & 0.083 & \textbf{0.250} & 0.005 & 0.075 & 0.002 & 0.029 & 0.093 & 0.084 & -0.248 & 1.105 & 0.005 \\
\rowcolor{gray!10} \parbox{2cm}{\centering DL-Based} & GAT~\citeyearpar{gat} & 0.166 & 0.332 & 0.014 & 0.245 & 0.009 & 0.167 & 0.250 & 0.091 & -0.197 & 2.746 & 0.014 \\
\rowcolor{gray!10} \parbox{2cm}{\centering Methods} & Transformer~\citeyearpar{attention} & \underline{0.167} & 0.335 & \underline{-0.009} & \underline{-0.099} & 0.004 & 0.001 & 0.141 & 0.082 & -0.214 & 1.720 & -0.040 \\
\rowcolor{gray!10} & Mamba~\citeyearpar{mamba} & 0.165 & 0.329 & 0.013 & 0.184 & 0.018 & 0.288 & 0.178 & 0.093 & -0.249 & 1.915 & 0.013 \\
\rowcolor{gray!10} & PatchTST~\citeyearpar{patchtst} & 0.166 & 0.333 & 0.008 & 0.147 & 0.006 & 0.113 & 0.148 & 0.085 & -0.200 & 1.739 & 0.036 \\
\rowcolor{gray!10} & Crossformer~\citeyearpar{crossformer} & 0.163 & 0.329 & 0.002 & 0.035 & -0.001 & -0.007 & 0.069 & 0.082 & -0.231 & 1.175 & 0.009 \\
\rowcolor{gray!10} & SegRNN~\citeyearpar{segrnn} & 0.166 & 0.328 & -0.002 & -0.027 & 0.012 & 0.169 & 0.167 & 0.094 & -0.193 & 1.765 & -0.009 \\
\rowcolor{gray!10} & PDF~\citeyearpar{pdf} & 0.165 & 0.332 & 0.022 & 0.391 & 0.018 & 0.329 & 0.209 & 0.092 & -0.135 & 2.277 & 0.098 \\
\rowcolor{gray!10} & TimeMixer~\citeyearpar{timemixer} & 0.165 & 0.330 & 0.015 & 0.249 & \textbf{0.107} & 0.187 & 0.200 & 0.088 & -0.212 & 2.274 & 0.067 \\
\rowcolor{gray!10} & Localformer~\citeyearpar{localformer} & 0.162 & 0.328 & 0.044 & \textbf{0.646} & 0.037 & \textbf{0.662} & 0.355 & 0.100 & -0.102 & 3.562 & 0.044 \\
% \midrule
% \multirow{4}{*}{\parbox{2cm}{\centering RL-Based\\Methods}}
% & PPO~\citeyearpar{ppo} &  &  &  &  &  &  &  &  &  \\
% & DDPG~\citeyearpar{ddpg} &  &  &  &  &  &  &  &  &  \\
% & SAC~\citeyearpar{SAC} &  &  &  &  &  &  &  &  &  \\
% & DQN~\citeyearpar{dqn} &  &  &  &  &  &  &  &  &  \\
\midrule
\multirow{3}{*}{\parbox{2cm}{\centering Generative-Based\\Methods}}
& DDPM~\citeyearpar{ddpm} & 0.163 & 0.328 & 0.026 & 0.451 & 0.023 & 0.413 & 0.198 & 0.084 & -0.147 & 2.353 & 0.026 \\
& DDIM~\citeyearpar{ddim} & 0.166 & 0.333 & 0.002 & 0.043 & 0.003 & 0.044 & 0.112 & 0.084 & -0.245 & 1.335 & 0.002 \\
& FactorVAE~\citeyearpar{FactorVAE} & \underline{0.167} & 0.334 & -0.004 & -0.061 & \underline{-0.004} & \underline{-0.077} & 0.093 & \textbf{0.081} & -0.220 & 1.146 & -0.004 \\
\midrule
\rowcolor{gray!10} & Timer~\citeyearpar{timer} & 0.020 & 0.431 & 0.006 & 0.083 & 0.006 & 0.092 & 0.230 & 0.084 & -0.123 & 2.756 & 0.006 \\
\rowcolor{gray!10} & Time-MoE$_{\text{Base}}$~\citeyearpar{timemoe} & 0.022 & 0.483 & 0.003 & 0.062 & 0.003 & 0.058 & 0.164 & 0.084 & -0.129 & 1.964 & 0.003 \\
\rowcolor{gray!10} & Time-MoE$_{\text{Large}}$~\citeyearpar{timemoe} & 0.023 & \underline{0.493} & 0.004 & 0.081 & 0.004 & 0.082 & 0.145 & 0.083 & -0.124 & 1.756 & 0.004 \\
\rowcolor{gray!10} & Chronos-T5$_{\text{Mini}}$~\citeyearpar{chronos} & 0.017 & 0.387 & 0.011 & 0.174 & 0.013 & 0.205 & 0.291 & 0.090 & -0.126 & 3.238 & 0.011 \\
\rowcolor{gray!10} & Chronos-T5$_{\text{Tiny}}$~\citeyearpar{chronos} & 0.017 & 0.387 & 0.010 & 0.163 & 0.013 & 0.197 & 0.219 & 0.088 & -0.098 & 2.497 & 0.010 \\
\rowcolor{gray!10} \parbox{2cm}{\centering LLM-Based} & Chronos-T5$_{\text{Small}}$~\citeyearpar{chronos} & 0.017 & 0.386 & 0.009 & 0.144 & 0.011 & 0.180 & 0.227 & 0.089 & -0.148 & 2.549 & 0.009 \\
\rowcolor{gray!10} \parbox{2cm}{\centering Methods} & Chronos-T5$_{\text{Base}}$~\citeyearpar{chronos} & 0.017 & 0.387 & 0.009 & 0.149 & 0.011 & 0.167 & 0.210 & 0.088 & -0.135 & 2.394 & 0.010 \\
\rowcolor{gray!10} & Chronos-T5$_{\text{Large}}$~\citeyearpar{chronos} & 0.017 & 0.387 & 0.013 & 0.199 & 0.015 & 0.225 & 0.314 & 0.087 & -0.114 & 3.593 & 0.013 \\
\rowcolor{gray!10} & Chronos-bolt$_{\text{Mini}}$~\citeyearpar{chronos} & 0.017 & 0.393 & 0.015 & 0.234 & 0.015 & 0.241 & 0.296 & 0.089 & -0.099 & 3.331 & 0.015 \\
\rowcolor{gray!10} & Chronos-bolt$_{\text{Tiny}}$~\citeyearpar{chronos} & 0.017 & 0.395 & 0.013 & 0.202 & 0.013 & 0.194 & 0.303 & 0.088 & -0.094 & 3.457 & 0.013 \\
\rowcolor{gray!10} & Chronos-bolt$_{\text{Small}}$~\citeyearpar{chronos} & 0.017 & 0.393 & 0.014 & 0.230 & 0.015 & 0.238 & 0.356 & 0.090 & -0.080 & 3.968 & 0.014 \\
\rowcolor{gray!10} & Chronos-bolt$_{\text{Base}}$~\citeyearpar{chronos} & 0.017 & 0.390 & 0.017 & 0.277 & 0.018 & 0.292 & \textbf{0.366} & 0.085 & -0.097 & \textbf{4.327} & 0.017 \\
\bottomrule
\end{tabular}
}
\label{tab:mainexp}
\end{table*}
\renewcommand{\arraystretch}{1.0}






\textit{Training Layer} integrates dozens of canonical models built on six heterogeneous backbone architectures. We extend Qlib's foundation by designing an easy-to-use and unified training pipeline that ensures evaluation consistency. The framework maintains model-agnostic compatibility - researchers employing FinTSF paradigm can seamlessly integrate their new models while maintaining evaluation impartiality. In particular, we implement parameter encapsulation through dedicated configuration modules rather than monolithic config files/main functions, significantly enhancing code readability and customization flexibility. 


\textit{Backtesting Layer} currently incorporates two classic strategies: Top$K$ and Top$K$-Drop, with transaction cost simulations reflecting real market conditions. Through multi-dimensional evaluation spanning prediction errors (2 metrics), ranking accuracy (4 metrics), and portfolio performance (5 metrics), we comprehensively quantify model capabilities across 11 rigorously wide-used indicators.

\textit{Feedback Layer} systematically archives training logs, preserves prediction results, and provides interactive visualization tools. This design facilitates continuous model optimization by tracking performance across training iterations, enables comparative analysis through standardized results formats, and supports decision-making via intuitive graphical representations of strategy behavior.

Users only need to deploy their method at the training layer and configure the configuration file, then \name can automatically run the pipeline in \cref{fig:pipeline}, enabling to better understand, compare, and select FinTSF methods for specific financial scenarios.


\section{Expeiments}\label{sec:exp}


\subsection{Experiment Setup}
Our experiment is trained on the NVIDIA A100 GPU for LLM-based methods and NVIDIA V100 GPU for others, and all models are built using PyTorch \cite{pytorch}.
The training, validation, and test sets (from \name) are kept consistent for all models. The lookback horizon $L$ is set to $20$ and we will predict the returns $Y$ on the next trading day. For each method, we adhere to performing hyperparameter searches across multiple sets for optimal results. 
The training process employs a dual-objective optimization framework, simultaneously minimizing a composite loss function that integrates both point-wise regression loss and pair-wise ranking loss. 
These complementary objectives are balanced through an adaptive weighting coefficient $\eta$, which is set to $5$.
$$
    \mathcal{L}=\frac{1}{L}\sum_{t=1}^{L}(\sum_{i=1}^{N}||Y_i^t-r_i^t||^2+\eta\sum_{i=1}^{N}\sum_{j=1}^{N}max(0,-(Y_i^t-Y_j^t)(r_i^t-r_j^t)))
$$

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.93\textwidth]{images/deploy.pdf}
    \caption{
            Cumulative return of typical methods over the whole year of 2024 in the CSI 300.
    }
    \vspace{-1em}
    \Description{..}
    \label{fig:csi}
\end{figure*}

\subsection{Trading Protocols}

We adopt the Top$K$-Drop strategy~\cite{qlib} to maintain a portfolio on each trading day. The Top$K$-Drop strategy improves upon Top$K$ strategy by dynamically optimizing portfolio turnover. Rather than fully rebalancing holdings daily, it retains stocks that persistently rank in the top-$K$ cohort and only replaces underperformers. This reduces the frequency of transactions, thereby lowering commission costs in proportion to the actual turnover rate, and maintains exposure to stocks with sustained high scores, avoiding unnecessary exits.
Formally, on trading day $t$, Top$K$-Drop constructs an equal-weighted portfolio of $m$ stocks $\mathcal{P}^t=\{s_{i_1}^t,s_{i_2}^t,...,s_{i_m}^t\}$, which are selected according to the rank of predicted returns $Y$. Given the turnover constraint, the number of intersection stocks $n$ is required to fulfill the condition $|\mathcal{P}^t\cap\mathcal{P}^{t-1}|\geq m-n$. In our experiment, we set $m$ at one tenth of the total number of stocks, i.e., $m=30$, and $n$ is set to $5$. Furthermore, we charge a transaction fee at a rate of $0.1\%$, in line with standard market practice.


\renewcommand{\arraystretch}{1.0}
\begin{table}[!t]
\setlength{\tabcolsep}{1.5pt}
\caption{Performance evaluation of typical models on CSI 300 in 2024. The models are trained on \name.}
\resizebox{0.47\textwidth}{!}
{
\begin{tabular}{c|ccccccc}
\toprule
\rowcolor{cadetblue!10} \multicolumn{8}{c}{\textbf{Tested on CSI 300 in 2024, trained on \name.}} \\
      
 \cmidrule(lr){1-8}

\rowcolor{cadetblue!20} \multicolumn{1}{c}{} & \multicolumn{2}{c|}{\textbf{Ranking Metrics}} & \multicolumn{5}{c}{\textbf{Portfolio-Based Metrics}} \\

\rowcolor{cadetblue!20} \multicolumn{1}{c}{\multirow{-2}{*}{\textbf{Methods}}} & \makebox[0.9cm]{IC$\uparrow$} & \multicolumn{1}{c|}{\makebox[0.9cm]{ICIR$\uparrow$}} & \makebox[0.9cm]{ARR$\uparrow$} & \makebox[0.9cm]{AVol$\downarrow$} & \makebox[0.9cm]{MDD$\downarrow$} & \makebox[0.9cm]{ASR$\uparrow$} & \makebox[0.9cm]{IR$\uparrow$} \\
\midrule
LSTM~\citeyearpar{lstm} & 0.008 & 0.062 & 0.163 & 0.208 & -0.159 & 0.782 & 0.008 \\
Adv-LSTM~\citeyearpar{alstm} & \underline{-0.012} & -0.087 & 0.167 & 0.250 & -0.180 & 0.666 & \underline{-0.012} \\
TCN~\citeyearpar{TCN} & -0.008 & \textbf{0.078} & 0.109 & \underline{0.309} & \underline{-0.243} & 0.351 & -0.008 \\
GAT~\citeyearpar{gat} & \underline{-0.012} & -0.083 & 0.224 & 0.220 & -0.128 & 1.019 & \underline{-0.012} \\
Transformer~\citeyearpar{attention} & \textbf{0.015} & 0.103 & \textbf{0.242} & \textbf{0.199} & -0.131 & \textbf{1.215} & \textbf{0.015} \\
PatchTST~\citeyearpar{patchtst} & 0.004 & 0.025 & 0.190 & 0.243 & \textbf{-0.125} & 0.784 & 0.004 \\
SegRNN~\citeyearpar{segrnn} & 0.001 & 0.004 & 0.064 & 0.208 & -0.162 & 0.306 & 0.001 \\
PDF~\citeyearpar{pdf} & 0.005 & 0.032 & 0.144 & 0.261 & -0.198 & 0.551 & 0.005 \\
TimeMixer~\citeyearpar{timemixer} & -0.003 & -0.040 & 0.168 & 0.251 & -0.195 & 0.671 & -0.004 \\
Localformer~\citeyearpar{localformer} & 0.003 & 0.032 & 0.195 & 0.222 & -0.168 & 0.878 & 0.003 \\
DDPM~\citeyearpar{ddpm} & -0.009 & \underline{-0.126} & 0.124 & 0.242 & -0.188 & 0.512 & -0.009 \\
DDIM~\citeyearpar{ddpm} & -0.003 & -0.038 & \underline{0.040} & 0.225 & -0.148 & \underline{0.176} & -0.003 \\
\bottomrule
\end{tabular}
}
\label{tab:realmarket}
\end{table}
\renewcommand{\arraystretch}{1.0}

\subsection{Experiment Results}

The performance results of various FinTSF methods are reported in \cref{tab:mainexp}.
We observe that no single method achieves the best performance across all three dimensional metrics. 
There is significant performance heterogeneity among different methods, even within the same backbone category, which we attribute to the critical factor of how effectively models capture temporal dependencies and cross-sectional relationships to predict future stock movements. Notably, LLM-based approaches exhibit a paradoxical pattern in which performance initially deteriorates with model scaling but subsequently shows marked improvement at larger scales, suggesting the emergence of financial time series specific capabilities that manifest only beyond critical thresholds of model capacity, possibly due to the need for sufficient parameters to disentangle complex market noise and latent factor interactions. Contrary to expectations, modern deep learning techniques do not universally outperform traditional quantitative strategies or tree-based models, underscoring the necessity for rigorous benchmarking across diverse architectures and temporal regimes. This empirical evidence argues for a more nuanced evaluation framework that takes into account both model scalability and FinTS characteristics.



\subsection{Transfer Learning Results}

To validate the cross-data generalization capability of \name, we conduct transfer learning experiments by applying models pre-trained on \name to backtest the entire 2024 CSI 300 stock market. The empirical results reveal two key insights. First, as shown by the metrics in \cref{tab:realmarket} and the cumulative return trajectories in \cref{fig:csi}, the model demonstrates remarkable performance consistency across different market regimes. Second, the superior risk-adjusted returns achieved through this zero-shot transfer learning paradigm highlight \name's unique advantages in both pattern diversity coverage and temporal robustness, establishing it as a comprehensive benchmark for heterogeneous market behaviors spanning bull, bear, and transitional market phases.

% \subsubsection{\textbf{Cross-Pattern Results.}}

% \renewcommand{\arraystretch}{1.0}
% \begin{table}[!t]
% \setlength{\tabcolsep}{1.5pt}
% \caption{Performance evaluation of typical models on extreme events of \name. The models are trained on uptrends, downtrends and period of volatility of \name.}
% \resizebox{0.47\textwidth}{!}
% {
% \begin{tabular}{c|ccccccc}
% \toprule
%  \multicolumn{1}{c}{\multirow{3}{*}{Methods}} & \multicolumn{7}{c}{Tested on extreme events, trained on other patterns.}\\
      
%  \cmidrule(lr){2-8}

% \multicolumn{1}{c}{} & \multicolumn{2}{c|}{Ranking Metrics} & \multicolumn{5}{c}{Portfolio-Based Metrics} \\

% \multicolumn{1}{c}{} & \makebox[0.9cm]{IC$\uparrow$} & \multicolumn{1}{c|}{\makebox[0.9cm]{ICIR$\uparrow$}} & \makebox[0.9cm]{ARR$\uparrow$} & \makebox[0.9cm]{AVol$\downarrow$} & \makebox[0.9cm]{MDD$\downarrow$} & \makebox[0.9cm]{ASR$\uparrow$} & \makebox[0.9cm]{IR$\uparrow$} \\
% \midrule
% LSTM~\citeyearpar{lstm} &  &  &  &  &  &  &  \\
% Adv-LSTM~\citeyearpar{alstm} &  &  &  &  &  &  &  \\
% TCN~\citeyearpar{TCN} &  &  &  &  &  &  &  \\
% GAT~\citeyearpar{gat} &  &  &  &  &  &  &  \\
% Transformer~\citeyearpar{attention} &  &  &  &  &  &  &  \\
% PatchTST~\citeyearpar{patchtst} &  &  &  &  &  &  &  \\
% TimeMixer~\citeyearpar{timemixer} &  &  &  &  &  &  &  \\
% SegRNN~\citeyearpar{segrnn} &  &  &  &  &  &  &  \\
% PDF~\citeyearpar{pdf} &  &  &  &  &  &  &  \\
% Localformer~\citeyearpar{localformer} &  &  &  &  &  &  &  \\
% FactorVAE~\citeyearpar{FactorVAE} &  &  &  &  &  &  &  \\
% \bottomrule
% \end{tabular}
% }
% \label{tab:crosspattern}
% \end{table}
% \renewcommand{\arraystretch}{1.0}



% \subsubsection{\textbf{Real Market Deployment Results.}}





\subsection{Inference Efficiency}

It is well known that quantitative trading in real-world markets places high demands on system latency sensitivity. Given this critical operational requirement, we conducted a comparative visualization analysis of representative algorithmic models in \cref{fig:eff}, focusing on three key performance metrics, ASR performance, computational inference efficiency, and memory footprint allocation.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{images/effiency.pdf}
    \caption{
         Inference efficiency comparison under \name.
    }
    \vspace{-1em}
    \Description{..}
    \label{fig:eff}
\end{figure}


% \section{Limitations}
\section{Conclusion}\label{sec:con}

In this paper, we propose \name, a comprehensive benchmark for FinTSF that addresses three key challenges. By categorizing stock movement patterns into four different types, we ensure a more diverse and representative evaluation, filling the \textit{Diversity Gap} overlooked in previous studies. Furthermore, we introduce a unified evaluation framework that standardizes performance metrics across multiple dimensions, mitigating the \textit{Standardization Deficit} and enabling more reliable cross-study comparisons. To bridge the gap between theoretical models and real-world applications, we incorporate critical market structure factors to overcome the \textit{Real-World Mismatch} that often distorts performance metrics. % Our extensive experiments on \name provide valuable insights into model selection for various market conditions. 
In general, \name offers a robust platform for advancing the evaluation and development of FinTSF methods, which we believe may pave the way for further research into the practical application of FinTSF.

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\clearpage
\balance
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}


%%
%% If your work has an appendix, this is the place to put it.
\clearpage
\appendix


\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.

% \renewcommand{\arraystretch}{0.85}
% \begin{table*}[!ht]
% \setlength{\tabcolsep}{2pt}
% \caption{Performance evaluation of compared models for financial time series forecasting in FinTSB.}
% \resizebox{\textwidth}{!}
% {
% \begin{tabular}{cc|ccccccccc|ccccccccc}
% \toprule
%  \multicolumn{2}{c}{\multirow{3}{*}{Methods}} & \multicolumn{9}{c}{FinTSB\_cn} & \multicolumn{9}{c}{FinTSB\_us} \\
      
%  \cmidrule(lr){3-11} \cmidrule(lr){12-20} 

% \multicolumn{2}{c}{} & \multicolumn{4}{c|}{Ranking Metrics} & \multicolumn{5}{c|}{Portfolio-Based Metrics} & \multicolumn{4}{c|}{Ranking Metrics} & \multicolumn{5}{c}{Portfolio-Based Metrics} \\

% \multicolumn{2}{c}{} & IC$\downarrow$ & ICIR$\downarrow$ & RankIC$\downarrow$ & \multicolumn{1}{c|}{RankICIR$\downarrow$} & ARR$\uparrow$ & AVol$\downarrow$ & MDD$\downarrow$ & SR$\uparrow$ & IR$\uparrow$ & IC$\downarrow$ & ICIR$\downarrow$ & RankIC$\downarrow$ & \multicolumn{1}{c|}{RankICIR$\downarrow$} & ARR$\uparrow$ & AVol$\downarrow$ & MDD$\downarrow$ & SR$\uparrow$ & IR$\uparrow$ \\
% \midrule
% \multirow{2}{*}{\parbox{2cm}{\centering Classic\\Strategies}}
% & BLSW   &  &  &  &  &  &  &  &  &  &  &  &  \\
% & CSM &  &  &  &  &  &  &  &  &  &  &  &  \\
% \midrule
% \multirow{3}{*}{\parbox{2cm}{\centering ML-Based\\Methods}}
% & PatchTST &  &  &  &  &  &  &  &  &  &  &  &  \\
% & iTransformer &  &  &  &  &  &  &  &  &  &  &  &  \\
% & Crossformer &  &  &  &  &  &  &  &  &  &  &  &  \\
% \midrule
% \multirow{6}{*}{\parbox{2cm}{\centering DL-Based\\Methods}}
% & LSTM &  &  &  &  &  &  &  &  &  &  &  &  \\
% & ALSTM &  &  &  &  &  &  &  &  &  &  &  &  \\
% & GRU &  &  &  &  &  &  &  &  &  &  &  &  \\
% & Transformer &  &  &  &  &  &  &  &  &  &  &  &  \\
% & Mamba &  &  &  &  &  &  &  &  &  &  &  &  \\
% & TRA &  &  &  &  &  &  &  &  &  &  &  &  \\
% \midrule
% \multirow{5}{*}{\parbox{2cm}{\centering RL-Based\\Methods}}
% & A2C &  &  &  &  &  &  &  &  &  &  &  &  \\
% & DDPG &  &  &  &  &  &  &  &  &  &  &  &  \\
% & PPO &  &  &  &  &  &  &  &  &  &  &  &  \\
% & TD3 &  &  &  &  &  &  &  &  &  &  &  &  \\
% & SAC &  &  &  &  &  &  &  &  &  &  &  &  \\
% \midrule
% \multirow{5}{*}{\parbox{2cm}{\centering Generative-Based\\Methods}}
% & AlphaStock &  &  &  &  &  &  &  &  &  &  &  &  \\
% & DeepPocket &  &  &  &  &  &  &  &  &  &  &  &  \\
% & FactorVAE &  &  &  &  &  &  &  &  &  &  &  &  \\
% & DeepTrader &  &  &  &  &  &  &  &  &  &  &  &  \\
% & THGNN &  &  &  &  &  &  &  &  &  &  &  &  \\
% \midrule
% \multirow{3}{*}{\parbox{2cm}{\centering LLM-Based\\Methods}}
% & PatchTST &  &  &  &  &  &  &  &  &  &  &  &  \\
% & iTransformer &  &  &  &  &  &  &  &  &  &  &  &  \\
% & Crossformer &  &  &  &  &  &  &  &  &  &  &  &  \\
% \bottomrule
% \end{tabular}
% }
% \label{tab:mainexp}
% \end{table*}
% \renewcommand{\arraystretch}{1.0}