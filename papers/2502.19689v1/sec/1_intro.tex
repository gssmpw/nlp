\section{Introduction}\label{sec1}

UAVs stand out because of their many advantages, such as economy, remote control, and no casualties. It is widely used in smart cities \cite{Mohamed2020,Lee2024}, damage detection \cite{Feng2024,Liang2023}, precision agriculture \cite{Xiao2023,Subeesh2024}, and other fields \cite{Guan2021,Erol2024,Wei2024}. Localizing terrestrial or maritime targets is crucial to numerous unmanned aerial vehicle (UAV) applications \cite{Guan2018}. Almost all of these applications require rapid high-precision localization of the target of interest. In photogrammetry, binocular stereo is usually used to reconstruct a 3D point \cite{Guan2022,Bian2024}. The conventional triangulation approach is geometrically sound and well-defined. Two sight-rays connecting the optical centers of the two cameras along with the baseline form a triangle, and the intersection of the two sight-rays is the position of the target point. This process is called triangulation. The triangulation technology of binocular vision has been systematically developed \cite{Longuet1981,Hartley2004,Lee2019}. 

\begin{figure}[htbp]  
\centering
\subfloat[]{\includegraphics[width=1.8in]{fig/Fig1a.pdf}%
\label{fig1a}}
\hfil
\subfloat[]{\includegraphics[width=1.8in]{fig/Fig1b.pdf}%
\label{fig1b}}
\caption{3D reconstruction of a point based on a monocular camera. (a) A static point. (b) A moving point.}
\label{fig1}
\end{figure}

Recently, monocular camera based target localization techniques have received considerable attention due to their advantages of low cost, light weight, and power efficiency \cite{Zhang2020,Wang2022,Yu2024_1}. Due to the limitations of UAV platforms, often only a monocular camera can be installed. However, it is still possible to realize the triangulation of static points by moving the camera, as shown in Figure \ref{fig1a}. We can also estimate the depth through deep learning, which is currently the most popular method \cite{Xu2021,Wan2024,Liu2024}. Unfortunately, the geometric constraint of triangulation becomes inapplicable when the point moves between image acquisitions, as shown in Figure \ref{fig1b}. This situation is very common, because most artificial vision systems are monocular, and most real scenes contain moving targets \cite{Tan2013,Saputra2018}. In this case, without reasonable assumptions about the target's motion or assistance of other sensors \cite{Yin2022,Zhang2023,Lan2024}, it is impossible to reconstruct the 3D trajectory of the target. Compared with relying on the assistance of other sensors, the method based on motion assumptions has the advantages of being lighter, more economical, and more versatile in applicability. Based on the background in this paper, the trajectories of point targets are reconstructed using motion assumptions.

There are three types of methods based on motion assumptions of the moving points. The first type is called trajectory triangulation, which assumes the shape of the target trajectory as an additional constraint. The principal work of trajectory triangulation is by Avidan and Shashua \cite{Avidan2000}. They assume that the target point moves along a straight line \cite{Avidan1999} or a conic \cite{Shashua1999}. The limitation of this method is that the shape of the target trajectory must be known in advance, and it must be a line or a conic section. However, their method has inspired numerous trajectory recovery algorithms based on shape constraints. Based on this work, Shashua et al. \cite{Shashua2000,Wexler2000} introduce the dual Htensor, a generalization of the well-known homography tensor. It allows for solving the trajectory of a point moving along a straight line with only three views and does not require prior information on camera positions. However, this method can only solve points moving along a straight line. Wolf and Shashua \cite{Wolf2002} then address the geometry of multiple views of dynamic scenes by lifting the problem to a static scene embedded in a higher dimensional space of $\mathbb{P}^N$. Their work explores six applications utilizing different $N$ values between 3 and 6. Kaminski and Teicher \cite{Kaminski2004} propose a general framework for trajectory triangulation by extending these ideas to a family of hyper-surfaces in the projective space $\mathbb{P}^5$. This approach enables the reconstruction of diverse trajectories expressible as polynomials. However, this framework is sensitive to noise, and the number of equations grows exponentially. The disadvantage of this type of method is that acquiring an initial value is not easy, and an initial value without enough precision will lead to failure of subsequent iteration. Generally, these methods can only get good results with quite good initial values.

The second type of method is to represent 3D trajectories using linear combinations of trajectory basis vectors such that the recovery of 3D points can be estimated robustly using least squares. Akhter et al. \cite{Akhter2008,Akhter2011} propose discrete cosine transform (DCT) as a trajectory basis to estimate non-rigid structures. Any motion can be expressed by this trajectory representation, which operates independently of specific objects and requires no prior knowledge. However, it cannot handle missing information. Park et al. \cite{Park2010} propose a method based on the DCT trajectory basis vectors to recover 3D trajectories of moving points from a series of 2D projections. This method can reconstruct arbitrary complex motions such as human motion and handle missing information. They also propose an index called \textit{reconstructability} to describe the reconstruction accuracy of the system quantitatively. Subsequently, Park et al. \cite{Park2015} further propose an automated method for selecting the number of trajectory basis vectors. Based on the DCT trajectory basis vectors, Zhu et al. \cite{Zhu2011} propose to introduce the L1 regularization term. They also select some keyframes to calculate the position of points independently as prior knowledge \cite{Wei2009}. Their approach refines 3D reconstruction precision while diminishing the correlation between camera and point trajectories. However, the reconstruction method used in keyframes requires prior information on human joints, which greatly limits the application domain. This type of method based on DCT trajectory basis vectors is mainly aimed at non-rigid motions. Its disadvantage is a lack of clear physical meaning so it needs to solve an excessive number of parameters and performs poor accuracy for simple motions. Moreover, when selecting the number of trajectory basis vectors, there are too many iterations, resulting in a long computing time. This is unnecessary for solving simple motions of vehicle or ship targets.

The third type of method is called trajectory intersection, which represents the motion of the target points as temporal polynomials. Zhang and Yu et al. \cite{Zhang2006,Yu2009} propose the principal work of the trajectory intersection. It is based on the collinearity equation and the motion of the point is represented as temporal polynomials. Since temporal polynomials have significant physical meaning, this method is particularly suitable for targets undergoing simple mechanical motion within a certain period of time. Therefore, The method performs excellently in estimating the trajectories of vehicles and ships. Li et al. \cite{Li2014} introduce a kernel function to the trajectory intersection method and propose a motion measurement method of a point target based on the least square support vector machines (LSSVM). This method has higher accuracy under high noise levels because of the addition of the kernel function. The incremental and decremental technique is used to improve computational efficiency. Li et al. \cite{Li2015} also extended the trajectory intersection method to multi-camera systems. Compared to classical two-view triangulation, this method can handle missing information and the conditions of asynchrony, no time registration, or even no time information among cameras. Zhou et al. \cite{Zhou2015} conduct a detailed analysis of the trajectory intersection method and present the necessary and sufficient conditions for the uniqueness of its solution. They also extend trajectory intersection to capture the orientation of the moving object, which PnP methods would not obtain due to a lack of features. Chen et al. \cite{Chen2019} aimed at maritime targets, utilizing a dynamic sea surface elevation model to enhance maritime target motion constraints. This approach simplifies the target's 3D spatial motion to a 2D surface motion to achieve higher accuracy. The advantage of this type of method is that it has a clear physical meaning and high calculation efficiency. However, the 3D reconstruction accuracy is low or even degenerates due to serious ill-conditioning caused by limited observation conditions. The order of the temporal polynomials controls the complexity of the reconstructed trajectory and the number of parameters to be estimated. Selecting an appropriate order of temporal polynomials is essential for achieving high-precision measurements of the target motion. In current methods, the order parameter is manually selected based on experience, which often leads to low accuracy.

This paper focuses on the 3D trajectory reconstruction of ground-moving targets, such as vehicles and ships, using UAVs. It is impossible to measure the 3D position of a moving point solely based on the images captured by a monocular camera without making reasonable assumptions about the point’s motion. This paper proposes a 3D trajectory reconstruction method for moving points using a monocular camera. First, temporal polynomials are employed to represent the point’s motion, and ridge estimation is introduced into the least squares estimation system to mitigate the ill-conditioning. Second, an automatic algorithm for determining the order of the temporal polynomials is proposed by minimizing a geometric error objective function. Third, the \textit{reconstructability} for temporal polynomials is defined by analyzing the geometric relationships among camera motion, target point motion, and the temporal polynomial, serving as a quantitative index. Finally, the efficiency, accuracy, and robustness of the proposed method are validated through both simulated and real-world data.

The main contributions of this paper include:
\begin{enumerate}[$\bullet$]
    \item We use temporal polynomials to represent the point motion as an additional constraint. Ridge estimation is introduced to the least squares estimation system to mitigate the ill-conditioning caused by limited observation conditions, thereby improving the accuracy and robustness.
      
    \item We propose an efficient automatic selection algorithm for the order of the temporal polynomials. The proposed algorithm automatically determines the optimal order of the temporal polynomials by minimizing an objective function of geometric error.
      
    \item We define the \textit{reconstructability} for temporal polynomials by analyzing the geometric relationships among camera motion, target point motion, and the temporal polynomial. This index is then used to describe the reconstruction accuracy quantitatively.
\end{enumerate}  

The rest of the paper is structured as follows: Section \ref{sec2} proposes the 3D trajectory reconstruction method for moving points and the automatic selection algorithm for the order of the temporal polynomials. Furthermore, Section \ref{sec2} discusses the geometric relationships among camera motion, target motion, and temporal polynomials. Sections \ref{sec3} and \ref{sec4} respectively validate the proposed method through simulated and real-world experiments. Ultimately, Section \ref{sec5} offers a conclusion.