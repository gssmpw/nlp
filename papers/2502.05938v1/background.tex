\subsection{\textbf{Neuromorphic Event Cameras}}

Neuromorphic event cameras, such as Dynamic Vision Sensors (DVS) \cite{dvs1,dvs2,dvs3}, represent a fundamentally different sensing modality compared to conventional frame-based cameras. Instead of capturing entire frames at fixed intervals, event cameras respond asynchronously at each pixel whenever a significant brightness change is detected. These changes trigger ``events,'' each recorded with the pixel coordinates, timestamp, and polarity. Formally, an event $e_k$ is generated at pixel $(x_k, y_k)$ if
\begin{equation}
  \label{eq:eventcamera}
  \log\bigl(I(x_k,y_k,t_k)\bigr) \;-\; \log\bigl(I(x_k,y_k,t_{\text{prev}})\bigr)
  \;\;\geq\; C,
\end{equation}
where $I(\cdot)$ is the brightness (or intensity) at that pixel, $t_{\text{prev}}$ is the last time an event occurred at $(x_k, y_k)$, and $C$ is a user-defined contrast threshold. An individual event can be expressed as a tuple
\[
e_k \;=\; \bigl(x_k,\, y_k,\, t_k,\, p_k\bigr),
\]
where $p_k \in \{+1, -1\}$ denotes the polarity (i.e., whether the intensity increased or decreased). Advantages of Event Cameras include:
\begin{itemize}
  \item \textbf{High Temporal Resolution}: Events are reported at microsecond granularity, supporting fast maneuvers.
  \item \textbf{Low Latency}: Data is streamed continuously and asynchronously, allowing near-instantaneous reactions.
  \item \textbf{Reduced Redundancy}: Only intensity changes are recorded, lowering bandwidth and data-processing demands.
  \item \textbf{High Dynamic Range \& Robustness}: They handle challenging lighting conditions and are minimaly sensitive to motion blur.
\end{itemize}

\subsection{\textbf{Spiking Neural Networks (SNNs)}}

Spiking Neural Networks (SNNs) \cite{lif,lee2020spike} emulate the event-driven communication seen in biological neurons, making them a natural fit for the asynchronous output of neuromorphic event cameras. Unlike traditional artificial neural networks, SNNs process information through discrete ``spikes'' rather than continuous activations.\\

\noindent{\textbf{LIF Neuron Model}}:
A widely used spiking neuron model is the Leaky Integrate-and-Fire (LIF) neuron. Its membrane potential $V(t)$ evolves according to
\begin{equation}
  \tau_m \,\frac{dV(t)}{dt} \;=\; -\,V(t) \;+\; R\,I(t),
\end{equation}
where:
\begin{itemize}
  \item $\tau_m$ is the membrane time constant,
  \item $R$ is the membrane resistance,
  \item $I(t)$ is the synaptic input current.
\end{itemize}
A spike is generated whenever $V(t)$ exceeds a threshold $V_{\text{th}}$, at which point $V(t)$ is reset to $V_{\text{reset}}$. Mathematically,
\[
V(t) \;\xrightarrow{V(t)\,\ge\,V_{\text{th}}}\; V_{\text{reset}},
\quad
\text{(spike event generated)}.
\]
The event-driven mechanism of SNNs significantly reduces energy consumption, since computation primarily occurs when spikes are present. We will use these principles to design our perception front end (Section \ref{subsec:neuromorphic_detection}).

\begin{figure*}[!t]
    \centering
    \includegraphics[width=1\textwidth]{NeuroNav_design.pdf}
    \caption{%
        \textbf{System architecture:} Integrating neuromorphic vision, 
        physics-guided neural networks, and symbolic rule-based reasoning. 
        Event and depth streams feed the SNN and PgNN, informing real-time 
        navigation decisions. Adapted from \cite{evplanner}. The motion planner is based on the work in \cite{mellinger2011minimum}.
    }
    \label{fig:method}
\end{figure*}

\subsection{\textbf{Physics-Guided Neural Networks (PgNNs)}}

Physics-Guided Neural Networks (PgNNs) \cite{raissi2019physics,karniadakis2021physics,NICODEMUS2022331,rampnet,chee2022knode} integrate system dynamics or physical constraints directly into the network training process. This approach improves interpretability, robustness, and data efficiency, which are crucial attributes for aerial robotics.

\noindent{\textbf{Embedding Physical Laws}}:
Consider a simplified dynamic model for a drone, where $\mathbf{x}(t)$ is position, $\mathbf{v}(t)$ is velocity, and $m$ is the mass:
\begin{equation}
\label{eq:dynamics}
  \dot{\mathbf{x}}(t) \;=\; \mathbf{v}(t), 
  \quad
  \dot{\mathbf{v}}(t) \;=\; \frac{1}{m}\bigl(\mathbf{F}_{\text{thrust}}(t) \;-\; m\,\mathbf{g}\bigr)
  \;-\;\mathbf{d}\bigl(\mathbf{v}(t)\bigr),
\end{equation}
where $\mathbf{F}_{\text{thrust}}(t)$ is the thrust force, $\mathbf{g}$ is gravitational acceleration, and $\mathbf{d}(\cdot)$ models drag or other aerodynamic effects. A PgNN can be designed such that a portion of its outputs obey (or approximate) these dynamics, restricting the solution space to physically feasible behaviors. This is one possible example. Later, we will see how we can apply this principle for energy models as well (Section \ref{subsec:physics_guided}).




