\section{Related Work}
\subsection{Cultural Text-to-Image Generation}
Previously, various methods have been proposed to address the cultural bias in text-to-image models ~\citep{cho2023dall,friedrich2023fair,luccioni2024stable}. \citet{liu2024scoft} collected a cultural dataset called CCUB across nine cultural categories for five countries and proposed a training technique named SCoFT to address cultural bias. Similarly, \citet{kannen2024beyond} collected the CUBE across three cultural categories for eight countries. However, these approaches are highly resource-intensive, demanding significant time and cost for data collection.

Other works ~\citep{basu2023inspecting,bansal2022well} attempted to mitigate cultural bias by modifying prompt. However, merely adding contextual information such as country names to prompt is proven insufficient in mitigating cultural bias, particularly for the concepts from underrepresented countries.

Unlike the previous approaches, our approach refines prompt based on cultural information and visual details to improve the alignment of text-to-image models with culture nouns, which are significant for representing unique concepts and objects across cultures.

\subsection{Prompt Engineering in Text-to-Image Generation}
The prompt as input to the text-to-image generation guides the images created by the models. Many studies ~\citep{oppenlaender2023taxonomy,liu2022design,brade2023promptify} on prompt engineering aimed at optimizing user-desired images by text-to-image models.

\citet{wen2024hard} propose a method for learning hard prompts that is optimized for text-to-image generation. This approach demonstrates how to generate prompt with minimal tokens that effectively guide the model to produce images in a specific style. \citet{yao2024promptcot} propose a refinement method that aligns input prompt with training prompts, ensuring that text-to-image models produces high-quality images.

 Unlike the existing approaches, we refine the prompt based on cultural information related to culture nouns, guiding text-to-image models to generate images that align appropriately with cultural representation.

\subsection{Refinement}
Refinement is a method designed to improve output quality through feedback and the application of a refiner. Learned Refiners ~\citep{schick2022peer,saunders2022self} involve providing feedback through a trained refiner, which requires human-annotated data for the training process. In contrast, Prompted Refiners ~\citep{peng2023check,yang2022re3} offer feedback through prompting without the trained refiner. Recently, a method called self-refine ~\citep{madaan2024self} has been proposed, which performs iterative feedback and refinement using a single Large Language Model (LLM) without external supervision.

Unlike the self-refine methods designed for LLM tasks, we iteratively refine the prompt based on cultural contexts and visual details to enhance the understanding of culture nouns in text-to-image models.