@article{bansal2022well,
  title={How well can text-to-image generative models understand ethical natural language interventions?},
  author={Bansal, Hritik and Yin, Da and Monajatipoor, Masoud and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2210.15230},
  year={2022}
}

@inproceedings{basu2023inspecting,
  title={Inspecting the geographical representativeness of images from text-to-image models},
  author={Basu, Abhipsa and Babu, R Venkatesh and Pruthi, Danish},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5136--5147},
  year={2023}
}

@inproceedings{brade2023promptify,
  title={Promptify: Text-to-image generation through interactive prompt exploration with large language models},
  author={Brade, Stephen and Wang, Bryan and Sousa, Mauricio and Oore, Sageev and Grossman, Tovi},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--14},
  year={2023}
}

@inproceedings{cho2023dall,
  title={Dall-eval: Probing the reasoning skills and social biases of text-to-image generation models},
  author={Cho, Jaemin and Zala, Abhay and Bansal, Mohit},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3043--3054},
  year={2023}
}

@article{friedrich2023fair,
  title={Fair diffusion: Instructing text-to-image generation models on fairness},
  author={Friedrich, Felix and Brack, Manuel and Struppek, Lukas and Hintersdorf, Dominik and Schramowski, Patrick and Luccioni, Sasha and Kersting, Kristian},
  journal={arXiv preprint arXiv:2302.10893},
  year={2023}
}

@article{kannen2024beyond,
  title={Beyond Aesthetics: Cultural Competence in Text-to-Image Models},
  author={Kannen, Nithish and Ahmad, Arif and Andreetto, Marco and Prabhakaran, Vinodkumar and Prabhu, Utsav and Dieng, Adji Bousso and Bhattacharyya, Pushpak and Dave, Shachi},
  journal={arXiv preprint arXiv:2407.06863},
  year={2024}
}

@inproceedings{liu2022design,
  title={Design guidelines for prompt engineering text-to-image generative models},
  author={Liu, Vivian and Chilton, Lydia B},
  booktitle={Proceedings of the 2022 CHI conference on human factors in computing systems},
  pages={1--23},
  year={2022}
}

@inproceedings{liu2024scoft,
  title={SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation},
  author={Liu, Zhixuan and Schaldenbrand, Peter and Okogwu, Beverley-Claire and Peng, Wenxuan and Yun, Youngsik and Hundt, Andrew and Kim, Jihie and Oh, Jean},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10822--10832},
  year={2024}
}

@article{luccioni2024stable,
  title={Stable bias: Evaluating societal representations in diffusion models},
  author={Luccioni, Sasha and Akiki, Christopher and Mitchell, Margaret and Jernite, Yacine},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{oppenlaender2023taxonomy,
  title={A taxonomy of prompt modifiers for text-to-image generation},
  author={Oppenlaender, Jonas},
  journal={Behaviour \& Information Technology},
  pages={1--14},
  year={2023},
  publisher={Taylor \& Francis}
}

@article{peng2023check,
  title={Check your facts and try again: Improving large language models with external knowledge and automated feedback},
  author={Peng, Baolin and Galley, Michel and He, Pengcheng and Cheng, Hao and Xie, Yujia and Hu, Yu and Huang, Qiuyuan and Liden, Lars and Yu, Zhou and Chen, Weizhu and others},
  journal={arXiv preprint arXiv:2302.12813},
  year={2023}
}

@article{saunders2022self,
  title={Self-critiquing models for assisting human evaluators},
  author={Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal={arXiv preprint arXiv:2206.05802},
  year={2022}
}

@article{schick2022peer,
  title={Peer: A collaborative language model},
  author={Schick, Timo and Dwivedi-Yu, Jane and Jiang, Zhengbao and Petroni, Fabio and Lewis, Patrick and Izacard, Gautier and You, Qingfei and Nalmpantis, Christoforos and Grave, Edouard and Riedel, Sebastian},
  journal={arXiv preprint arXiv:2208.11663},
  year={2022}
}

@article{wen2024hard,
  title={Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery},
  author={Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{yang2022re3,
  title={Re3: Generating longer stories with recursive reprompting and revision},
  author={Yang, Kevin and Tian, Yuandong and Peng, Nanyun and Klein, Dan},
  journal={arXiv preprint arXiv:2210.06774},
  year={2022}
}

@inproceedings{yao2024promptcot,
  title={PromptCoT: Align Prompt Distribution via Adapted Chain-of-Thought},
  author={Yao, Junyi and Liu, Yijiang and Dong, Zhen and Guo, Mingfei and Hu, Helan and Keutzer, Kurt and Du, Li and Zhou, Daquan and Zhang, Shanghang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7027--7037},
  year={2024}
}

