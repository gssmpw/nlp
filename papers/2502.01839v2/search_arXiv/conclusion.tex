This paper studied the scaling trends governing sampling-based search, finding that (1) it scales remarkably well even with simple implementations, (2) \emph{implicit scaling} plays a big role in this scalability, and (3) self-verification capability can be scaled with test-time compute using two key principles: comparisons localize errors, and responses should be rewritten for output style suitability.
To this end, we scaled a minimalist, embarrassingly parallel implementation of sampling-based search that, with sufficient test-time compute, is sufficient to attain state-of-art performance on a range of reasoning benchmarks.

Our results underscore the importance of the sampling-based search paradigm. 
Given that it complements other test-time compute scaling strategies, is parallelizable and allows for arbitrarily scaling, and admits simple implementations that are demonstrably effective, we expect sampling-based search to play a crucial role as language models are tasked with solving increasingly complex problems with increasingly large compute budgets.
We also see the performance of sampling-based search as providing both a strong baseline scaling trend that any non-trivial inference strategy should exceed, and a meaningful measure of a model's search capability when Pass@k is uninformative (e.g. on multiple choice exams).
We anticipate model self-verification capabilities to rapidly improve in the short term, as models learn to leverage the principles of implicit scaling and output style suitability, and drive improved scaling rates for sampling-based search.
Finally, our results also highlight the importance of being able to effectively sample massive and diverse sets of solutions for search.
This calls for more systematic inference alternatives to random sampling, such as agentic approaches that delegate search, and inference-aware optimization methods that maximize, e.g., Pass@k performance rather than Pass@1.
