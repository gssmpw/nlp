
\begin{table*}[htbp]
  \centering
  \caption{Quantitative comparison of depth estimation with both specialized models and multi-task models on zero-shot datasets. Our visual generalist model can perform \textit{on par} with state-of-the-art models.
  We use the same evaluation protocal ($\dagger$) as Genpercept~\cite{xu2024diffusion}.
  }
  
  
\resizebox{.99\linewidth}{!}{%
  \begin{tabular}{@{}r|c|lr|lr|lr|lr|lr@{}}
    \toprule
	
	\multirow{2}{*}{Method} & Training & \multicolumn{2}{c|}{KITTI~\cite{kitti}}  & \multicolumn{2}{c|}{NYUv2~\cite{nyu}} & \multicolumn{2}{c|}{ScanNet~\cite{scannet}}
 & \multicolumn{2}{c|}{DIODE~\cite{diode}} & \multicolumn{2}{c}{ETH3D~\cite{eth3d}}\\
	
    \cline{3-12}
	
    & Samples &  AbsRel$\downarrow$ & $\delta_1$$\uparrow$ & AbsRel$\downarrow$ & $\delta_1$$\uparrow$ & AbsRel$\downarrow$ & $\delta_1$$\uparrow$ & AbsRel$\downarrow$ & $\delta_1$$\uparrow$ & AbsRel$\downarrow$ & $\delta_1$$\uparrow$ \\


    \hline
       
    MiDaS~\cite{midas}   & 2M	    & 0.236  & 0.630
     		& 0.111	& 0.885
                & 0.121 & 0.846
     		& 0.332	& 0.715
                & 0.184  & 0.752
     		\\
       
    Omnidata~\cite{omnidata}  & 12.2M	& 0.149  & 0.835
     		& 0.074	& 0.945
                & 0.075 & 0.936
     		& 0.339	& 0.742
                & 0.166  & 0.778
     		\\
       
    DPT-large~\cite{dptlarge}  & 1.4M	& 0.100  & 0.901
     		& 0.098	& 0.903
                & 0.082 & 0.934
     		& 0.182	& 0.758
                & 0.078 & 0.946
     		\\

    DepthAnything$^\dagger$~\cite{yang2024depth}  & 63.5M	& 0.080  & 0.946
     		& 0.043	& 0.980
                & 0.043  & 0.981
     		& 0.261	& 0.759
                & 0.058  & \textbf{0.984}
     		\\

    DepthAnything v2$^\dagger$~\cite{yang2024depth2}  & 62.6M	& 0.080  & 0.943
     		& 0.043	& 0.979
                & 0.042  & 0.979
     		& 0.321	& 0.758
                & 0.066  & 0.983
     		\\

    Depth Pro$^\dagger$~\cite{bochkovskii2024depth}  & -	& 0.055  & 0.974
     		& 0.042	& 0.977
                & 0.041  & 0.978
     		& 0.217	& 0.764
                & 0.043  & 0.974
     		\\

    Metric3D v2$^\dagger$~\cite{hu2024metric3d}   & 16M	& \textbf{0.052}  & \textbf{0.979}
     		& \textbf{0.039}	& \textbf{0.979}
                & \textbf{0.023}  & \textbf{0.989}
     		& \textbf{0.147}	& \textbf{0.892}
                & \textbf{0.040}  & 0.983
     		\\
    
    % \hline
    % \hline

    DiverseDepth~\cite{diversedepth}  & 320K 	& 0.190  & 0.704
     		& 0.117	& 0.875
                & 0.109 & 0.882
     		& 0.376	& 0.631
                & 0.228 & 0.694
     		\\
       
    LeReS~\cite{leres}  & 354K	    & 0.149  & 0.784
     		& 0.090	& 0.916
                & 0.091 & 0.917
     		& 0.271	& 0.766
                & 0.171 & 0.777
     		\\
       
    HDN~\cite{hdn}  & 300K	    & 0.115  & 0.867
     		& 0.069	& 0.948
                & 0.080 & 0.939
     		& 0.246	& 0.780
                & 0.121  & 0.833
     		\\

    GeoWizard~\cite{fu2024geowizard}  & 280K & 0.097  & 0.921
     		& 0.052	& 0.966
                & 0.061 & 0.953
     		& 0.297	& 0.792
                & 0.064  & 0.961
     		\\

    DepthFM~\cite{gui2024depthfm}  & 63K	& 0.083  & 0.934
     		& 0.065	& 0.956
                &  - & -
     		& 0.225 & 0.800
                & -  & -
     		\\
            
    % \hline

    Marigold$^\dagger$~\cite{ke2024repurposing}  & 74K	& 0.099  & 0.916
     		& 0.055	& 0.964
                & 0.064  & 0.951
     		& 0.308	& 0.773
                & 0.065  & 0.960
     		\\

    DMP Official$^\dagger$~\cite{lee2024exploiting}  & -  & 0.240  & 0.622
     		& 0.109	& 0.891
                & 0.146    & 0.814
     		& 0.361 	& 0.706
                & 0.128    &  0.857
     		\\

    GeoWizard$^\dagger$~\cite{fu2024geowizard}  & 280K & 0.129  & 0.851
     		& 0.059	& 0.959
                & 0.066  & 0.953
     		& 0.328	& 0.753
                & 0.077  & 0.940 
     		\\

    DepthFM$^\dagger$~\cite{gui2024depthfm}  & 63K	& 0.174  & 0.718
     		& 0.082	& 0.932
                & 0.095  & 0.903
     		& 0.334 	& 0.729
                & 0.101  & 0.902
     		\\
    Genpercept$^\dagger$~\cite{xu2024diffusion}  & 90K	& 0.094  & 0.923
     		& 0.091	& 0.932
                & 0.056  & 0.965
     		& 0.302	& 0.767
                & 0.066  & 0.957
     		\\
    \hline
    Painter$^\dagger$~\cite{wang2023images}  & 24K	& 0.324  & 0.393
        & \textbf{0.046}	& \textbf{0.979}
        & 0.083  & 0.927
        & 0.342	& 0.534
        & 0.203  & 0.644
        \\
    Unified-IO$^\dagger$~\cite{lu2022unified}  & 48K	& 0.188  & 0.699
        & 0.059	& 0.970
        & \textbf{0.063}  & \textbf{0.965}
        & 0.369	& 0.906
        & 0.103  & 0.906
        \\
    4M-XL$^\dagger$~\cite{mizrahi20234m}  & 759M	& 0.105 & 0.896
        & 0.068	& 0.951
        & 0.065  & 0.955
        & 0.331	& 0.734
        & 0.070  & 0.953
        \\
    OneDiffusion$^\dagger$ ~\cite{le2024diffusiongenerate} & 500K	& 0.101  & 0.908
        & 0.087	& 0.924
        & 0.094  & 0.906
        & 0.399	& 0.661
        & 0.072  & 0.949
        \\
            
    \hline
    \textcolor{gray}{Ours-single}$^\dagger$  & \textcolor{gray}{500K}	& \textcolor{gray}{0.081}  & \textcolor{gray}{0.942}
     		& \textcolor{gray}{0.068}	& \textcolor{gray}{0.949}
                & \textcolor{gray}{0.078}  & \textcolor{gray}{0.945}
     		& \textcolor{gray}{0.267}	& \textcolor{gray}{0.709}
                & \textcolor{gray}{0.059}  & \textcolor{gray}{0.969}
     		\\
    Ours$^\dagger$  & 500K	& \textbf{0.075}  & \textbf{0.945}
     		& 0.072	& 0.939
                & 0.075  & 0.938
     		& \textbf{0.243}	& \textbf{0.741}
                & \textbf{0.053}  & \textbf{0.967}
     		\\
     
    \bottomrule
  \end{tabular}
  }
  \label{tab:depth}
  %\vspace{-2 em}
\end{table*}
