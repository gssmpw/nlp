

\section{Post-processing}

\label{appendix:post_processing}

\begin{figure*}[h!]
  \centering
  \includegraphics[width=1\linewidth]{iccv2023AuthorKit/Figures/fur.pdf}
  \caption{
   Segmentation results on furry objects.
  }
  \phantomsection
  \label{fig:fur}
\end{figure*}



\input{iccv2023AuthorKit/Algorithm/pose}
\input{iccv2023AuthorKit/Algorithm/semantic}

\subsection{Post-processing for Keypoints}
For keypoints, since all keypoints were labeled in red during training, our first step in post-processing is to extract all red regions from the RGB output. Next, we identify all connected components within the extracted red regions. For each connected component, we further extract sub-regions that approximate a circular shape. This step is crucial because, in some cases, multiple predicted keypoints may overlap, requiring us to separate them as much as possible. For example, when a person clasps his hands together, the keypoints for both hands may overlap.

Once the circular regions are identified, we compute their center points as the predicted keypoint coordinates. Since our model does not explicitly predict the type of each keypoint (\textit{e.g.}, hand, foot), we assign keypoint types by measuring the distance between the extracted keypoints and the ground truth (GT) keypoints. Each predicted keypoint is assigned the type of its nearest GT keypoint. To ensure robustness, we apply a distance threshold, considering only those predicted keypoints that are sufficiently close to a GT keypoint. Finally, all extracted keypoints that are successfully matched to a GT keypoint form our final predicted keypoint coordinates after post-processing. The algorithm is shown in Algorithm~\ref{alg:pose}.

\subsection{Post-processing for RGB Masks}
For entity segmentation and semantic segmentation RGB masks, we employ clustering algorithms to extract the object masks. Specifically, we first compute the histogram peaks for each of the three RGB channels and estimate the number of clusters by averaging the peak counts across the three channels. We then use KMeans clustering to group the colors and identify the clustered regions in the RGB mask.
For each identified cluster, we extract regions with RGB values close to the cluster's centroid. This step is followed by morphological operations to refine the extracted masks, such as filling holes and removing small, fragmented regions. We further filter the masks by computing their area, excluding any regions that are too small to be meaningful.

Additionally, we also consider the number of connected components within the extracted masks, discarding overly fragmented results that have too many connected components. Finally, we refine the extracted masks by calculating the Intersection over Union (IoU) between them, removing any duplicate or overlapping masks. The algorithm is shown in Algorithm~\ref{alg:segmentation}.

\subsection{Performance Degradation of RGB Masks}
\label{appendix:mask_degradation}
\begin{figure*}[htbp]
  \centering
  \includegraphics[width=.85\linewidth]{iccv2023AuthorKit/Figures/semantic_degradation.pdf}
  \caption{
   When post-processing RGB masks, small regions and excessive numbers of objects lead to significant metric degradation.
  }
  \phantomsection
  \label{fig:degradation}
\end{figure*}

\input{iccv2023AuthorKit/Tables/mask_degradation}

We observe that while the quality of our semantic segmentation visualizations is high, the average precision (AP) for certain categories remains unsatisfactory.
For example, for the Person category, we conducted exhaustive experiments and achieved good visualization results (highlighted by the green rectangle in Figure~\ref{fig:degradation}), but AP is low (as in Table~\ref{tab:mask_degradation}).
Although, clearly, there is room for us to improve the semantic segmentation results, we do not intend to fit the data bias of those existing datasets, as pointed out by other authors, \textit{e.g.}, \cite{ravi2024sam}.  

We trace the root cause of this issue to degradation during post-processing, particularly due to small objects and an excessive number of objects. Specifically, during mask processing, we filter out small noise regions, but this also removes some positive samples, such as the crowd and the bird highlighted in red in rows 3 to 5 in Figure~\ref{fig:degradation}. However, if we do not filter these noise regions, they further degrade the results.
In our setting, filtering noise regions results in better metrics compared to not filtering them. Additionally, when an image contains an excessive number of objects of the same category (as in row 6 of Figure~\ref{fig:degradation}), post-processing may erroneously group similarly colored but distinct objects into a single class, leading to lower metrics. 
Furthermore, as in Table~\ref{tab:mask_degradation}, we examine categories with fewer small objects and instances of those categories, such as bear, dog, and cat, and observe higher AP scores. However, for categories with opposite characteristics, their AP scores tend to be lower.

Although we can optimize post-processing for individual 
datasets 
by adjusting hyperparameters for each image to achieve the best results, this approach becomes impractical for large-scale \textit{in-the-wild} evaluation, as it requires significant manual effort. Consequently, the dependency on post-processing remains a limitation of our approach.