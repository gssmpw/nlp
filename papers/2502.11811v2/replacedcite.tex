\section{Related Work}
Retrievers often fetch noisy content, reducing output accuracy, while overly long contexts further hinder model efficiency. To address these challenges, some researchers utilize re-ranking methods to prioritize more relevant sentences. 
RichRAG____ uses a generative list-wise ranker to generate and rank candidate documents, ensuring the answer is comprehensive and aligns with the modelâ€™s preferences. ____ proposes a novel bridge mechanism to optimize the connection between retrievers and LLMs in retrieval-augmented generation, improving performance in question-answering and personalized generation tasks.
However, reranking sentences may disrupt the original logical structure of the document and generate unfaithful clues.


Other researchers utilize abstractive or extractive summarization models to identify query-relevant answer clues. ____ propose leveraging LLMs as abstractive filters to compress retrieved text by targeting the most relevant sentences. ____ apply the information bottleneck principle to filter noise, striving to strike a balance between conciseness and correctness. Despite its potential benefits, this method is associated with high computational complexity during the training process, posing additional challenges for practical implementation. ____ explore extractive filters to select the most relevant sentences. While these methods help eliminate irrelevant information, they also face the risk of over-compression, which may lead to a reduction in output accuracy.  In another approach, ____ introduce the concept of Selective Context, which eliminates redundant content based on self-information metrics to enhance the efficiency of LLM inference. However, this technique may compromise the semantic coherence of the context.