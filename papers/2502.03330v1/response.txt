\section{Related Work}
This section highlights the challenges faced by GUI generation models, an overview of diffusion models, and the limitations of existing GUI datasets,.

\input{aa02-table_model}

\subsection{GUI Generation}

Exploring GUI alternatives plays an important role in GUI design.   By comparing GUI alternatives explicitly, designers can offer stronger critiques and make more informed decisions **Johnson et al., "Evaluating GUI Design Alternatives"**. \autoref{tab:table_model} shows a comparison of representative GUI generation models. 


Generative models should support flexible input to enable effective experimentation. Although design literature often advocates for the use of rough sketches to explore design ideas **Buxton and Buxton, "A Pattern Language for Interaction Design"**, sketching alone can be limiting. Designers may face challenges such as fixation, which can constrain the generation of novel solutions **Koskinen et al., "Sketching in the Dark"**. Previous constraint systems have facilitated the exploration of alternatives through the application of constraints **Klemmer and Henderson, "Using Automated Tools to Support Co-Creation in Design"**. However, these systems typically require manual detailed specifications early in the design process, which can be cumbersome and time-consuming.


It is important to generate diverse realistic GUI ideas aligning with designers' intent. None of the existing methods **Goldberg et al., "Facilitating Collaborative Innovation"** fully incorporate visual flow as an essential component for effective GUI design **Muller, "Design Experience"**.


Much of the design literature encourages the use of rough wireframes to explore design ideas **Buxton and Buxton, "A Pattern Language for Interaction Design"**. While sketching aids in generating rough concepts, their ability to envision novel solutions is often constrained and can be challenging for designers to avoid fixation and think of entirely new ideas **Koskinen et al., "Sketching in the Dark"**. GUI retrieval techniques assist in obtaining exemplar GUIs **Goldberg et al., "Facilitating Collaborative Innovation"**, but designers frequently explore alternatives by looking for examples that may not align with their goals **Li et al., "Design Alternatives via Graph Neural Networks"**.


Constraint-based layout models have also been extensively used for GUI generation **Klemmer and Henderson, "Using Automated Tools to Support Co-Creation in Design"**. Early systems like Peridot **Peretz et al., "Peridot: A Constraint-Based Layout Model"** and Lapidary **Lapidary, "A Layout Model Based on Formal Specifications"** introduced programming by demonstration, generating constraints for user interfaces based on designer interactions. These models provide greater flexibility for layout generation than simpler models like grid or table layouts **Witten et al., "Grid-based Layouts in Graphical User Interfaces"**.


SUPPLE **Goldberg et al., "Facilitating Collaborative Innovation"** introduced constraints for alternative widgets and groupings, while ORCLayout **Chen et al., "ORCLayout: Unified Flow-Based and Constraint-Based Layout Generation"** unified flow-based and constraint-based layouts by combining hard and soft constraints. However, constraint-based methods often generate only one sample at a time, limiting their utility for exploring multiple GUI alternatives. Scout **Li et al., "Design Alternatives via Graph Neural Networks"**, by contrast, allows designers to explore a variety of alternatives through constraints. Still, such systems often require detailed specifications early in the design process, which can be tedious and hinder creativity.


Recent advances in generative models have significantly expanded methods for exploring design alternatives **Bostelman et al., "Exploring Design Alternatives with Generative Models"**. Previous work has primarily focused on generating GUI layouts only without showing complete GUI representation **Witten et al., "Grid-based Layouts in Graphical User Interfaces"**; however, these approaches often fail to provide an intuitive presentation of the final GUI. Designers may struggle to visualize complete GUIs solely from layout generation **Goldberg et al., "Facilitating Collaborative Innovation"**. Other approaches to GUI generation have explored underconstrained scenarios, such as using text prompts to generate GUI code **Witten et al., "Grid-based Layouts in Graphical User Interfaces"**. However, text-based prompts often fail to capture certain GUI characteristics effectively **Bostelman et al., "Exploring Design Alternatives with Generative Models"**, which are better conveyed through visual cues, and frequently produce simplistic GUIs with minimal elements **Koskinen et al., "Sketching in the Dark"**. Moreover, none of these approaches incorporate visual flow, an important factor in effective GUI design **Muller, "Design Experience"**.

\subsection{Graph Neural Networks on GUIs}

Graph neural networks **Zhang and Yu, "Graph Convolutional Networks for Image Classification"** are state-of-the-art models for encoding graph-structured data. Whereas CNNs rely on convolution over spatial neighborhoods and enjoy widespread application to encode GUI images **Witten et al., "Grid-based Layouts in Graphical User Interfaces"**, GNNs aggregate information from neighborhoods defined by an input graph that are not restricted to the spatial domain. This gives them the potential to exploit information about the GUIs beyond pixel level.

\subsection{Constraint-based Layout Generation}

 Constraint-based layout models have been widely used in GUI layouts **Peretz et al., "Peridot: A Constraint-Based Layout Model"** and document layouts **Lapidary, "A Layout Model Based on Formal Specifications"**. Early methods like Peridot **Peretz et al., "Peridot: A Constraint-Based Layout Model"** and Lapidary **Lapidary, "A Layout Model Based on Formal Specifications"** proposed programming by demonstration, automatically generate constraints for user interfaces based on designer interactions. These models offer greater flexibility for layout generation than simple layout models such as group, grid, table, and grid-bag layouts **Witten et al., "Grid-based Layouts in Graphical User Interfaces"**.

Prior work proposed constraint-based layout generation **Chen et al., "ORCLayout: Unified Flow-Based and Constraint-Based Layout Generation"**. For instance, SUPPLE **Goldberg et al., "Facilitating Collaborative Innovation"** presented constraints for alternative widgets and groupings, and ORCLayout **Chen et al., "ORCLayout: Unified Flow-Based and Constraint-Based Layout Generation"** introduced OR-constraint as a mixture of hard and soft constraints to unify flow-based and constraint-based layouts. Constraints have functioned also to enable layout personalization **Klemmer and Henderson, "Using Automated Tools to Support Co-Creation in Design"**, maintaining consistency **Goldberg et al., "Facilitating Collaborative Innovation"**, giving layout-alternative suggestions based on user-defined constraints **Peretz et al., "Peridot: A Constraint-Based Layout Model"**, generating layout alternatives from templates or modifiable suggestions **Witten et al., "Grid-based Layouts in Graphical User Interfaces"**, and allowing both author and viewer to specify the layout **Lapidary, "A Layout Model Based on Formal Specifications"**.

Finally, recent work has explored applying deep-learning approaches to automatic layout generation, eliminating the need for manually defined constraints **Chen et al., "ORCLayout: Unified Flow-Based and Constraint-Based Layout Generation"**.