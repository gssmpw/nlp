\section{User Study}
\subsection{Study Design}

This section aims to provide a comprehensive overview of the methodology employed to investigate the impact of different annotations on learning and teaching in touchscreen and VR environments. Participants, totaling 24, engaged in a structured study where they perform tasks as both educators and learners. Upon entering the designated study room, participants were presented with an information sheet outlining the study's context and their rights. The study was conducted on a voluntary basis, and participants were free to withdraw at any point without consequences. Upon consenting to participate, individuals completed a form and a pre-study assessment gauging their comfort level using the widely recognized Simulator Sickness Questionnaire ~\cite{ssqOriginal, ssqFix}. An introduction to the tools used in the study followed, including touch movement and VR interactions.

The main study was structured into two sections, with participants alternating between the roles of educators and learners. The decision to let all participants perform both roles was made to enable comparisons between the usability and usefulness of all tools and annotations, even though the roles would rarely be shared in real-life scenarios. Each section comprised three subtasks, structured in such a way that every participant would be exposed to all proposed annotation tools and mechanisms. To support assessment of each tool and mechanism individually, the study was designed to minimize the amount of new tools the participants were given at once, instead only introducing them one-by-one or alongside their related tools. 
%
Each subtask was covering a single topic, unrelated to other subtasks in this study. The topics were chosen such that participants were unlikely to have more than surface-level knowledge before participating in the study to emulate learning environments where our tools would be combined with unfamiliar information. Still, the subtasks' subjects shouldn't be too complex to be covered in the scope of this subject or require any prior knowledge that only specific professions may have.
%
Educators utilized drawing, fill, and eraser tools in the first subtask, followed by text and sequence tools in the second. The third subtask allowed free use of both annotation methods. The study was executed in eight variations, every participant completing all the mentioned tasks but counter-balanced to ensure each order was conducted three times. Participants, spent an average of 60–90 minutes completing the study's practical component. The study maintained consistent laboratory conditions across multiple runs by using identical hardware and software configurations. Upon completion of the practical tasks, participants filled out multiple established questionnaires~\cite{ssqOriginal, ipq, sus, daq} to provide additional insights into their experiences and perspectives. This study received ethical approval from the institution's ethics board, underscoring our commitment to maintaining the highest ethical standards in research.

\begin{figure}[tb]
 \centering
 \includegraphics[width=0.9\columnwidth]{figures/lapCamera2.png}
 \caption{Illustration inserted laparoscopic camera, revealing the internal organs. An exemplary textual annotation is displayed at nose position.}
 \label{fig:lapcamera}
\end{figure}

\subsection{Hardware and Software Setup}
This section details the hardware and software that was used to implement the described method and to conduct the study. 

\subpart{Hardware} The Hardware used for this study was chosen so that both the VR and touchscreen setup could be rendered simultaneously on the same PC. Thus, the graphics card NVIDIA RTX 3090 was used together with the Intel Core i9-12900k and 32~GB of DDR5 RAM running at 4.4GHz. The VR equipment we selected was the Head-Mounted Display (HMD) Valve Index, running two LCDs at 144Hz with a per-eye resolution of 1440×1600 pixels.

\subpart{Software} The PC backing our study is running Windows 11. The methods described above were implemented in Unity 2021.3.14f1~\cite{unity}. Unity is mostly known as a game engine, but is also reasonably useful as a research tool for interface, interaction, or visualization studies~\cite{unityInterface1, unityInterface2, unityInterface3}. Unity's behavior can be customized using C\# scripts, enabling advanced functionality.


\subsection{Procedure}

The study was designed so that each participant would perform both perspectives that this method was designed for: educators and learners. This section will detail the procedure of the study.

\subpart{Introduction} The introduction was structured to introduce the participant to every tool they would use during the study. The scene prepared for this contains a human body provided by Nobutaka et al.~\cite{bodyparts3d} that was used for all depictions of anatomy throughout this study. First, the interface for educators was described by the researcher. After establishing the ways the camera could be moved, the participant was allowed to try it out. Then, the researcher demonstrated the use of the pen and the eraser on the face of a human body by drawing with blue color around one eye and red color on the lips. Part of that was erased directly afterward. Then, the researcher placed a text annotation on the nose with the text ''nose'' to demonstrate the use of the text annotation. A second one was placed on the knee. Then, the sequence tool was used to set the sequence index of the knee annotation to 2, placing it chronological behind the one on the nose.
%
For the second part of the introduction, the participants were equipped with the HMD. Once they reported seeing sharp images, they were allowed to move around and acclimate to the virtual environment. Once they were ready, they were told about the tools laying on a metal tray, how they could pick them up and drop them. They were asked to use all the regular annotation tools one after one. The introduction scene also contained one advanced tool, the laparoscopic camera used in the ablation scene described below, which had to be tried out.

\subsubsection{Educator} 

In the role of educators, the participants are tasked to transfer knowledge from text-book excerpts into scenes that were prepared for the study. Those excerpts were printed out so that the participants could hold them while using the touchscreen with their free hand. At the beginning of each subtask, the participants were given a small oral introduction into the specific topic and handed the excerpt to read through. Afterward, they were told which annotations they were allowed to place and shown the prepared scene. Each scene consisted of three parts which were labeled ''1.'', ''2.'' and ''3.'', later on regarded as the first, second or third part. There was no target of how much or what kind of information they were to transfer. Each subtask was finished as soon as the participant wished to do so.

In the following, each scene and the covered topic are explained in more detail. 

\subpart{Scar revision} Scar revision is the process of trying to remove or change the appearance of scars. One of the procedures to do this is to remove the scar by cutting it out and sewing the surrounding skin back together. This may be done to return flexibility when scars are near joints, or for aesthetic purposes. The excerpt handed to the participant details that and some alternative approaches to do scar revision. The three parts depict one skin piece with a scar and two identical skin pieces, where the scar is missing, and the skin has a visible hole. This scene was to be annotated only using the pen, eraser, and fill tools.

\subpart{Port} The scene covering the topic of medical ports was designed around restricting the participants to using the text and sequence tools. Medical ports are small gadgets which are implanted beneath the skin. A catheter connects them to a vein, allowing  access to the blood system of a patient without needing to puncture their veins. They are commonly used for cancer patients. The excerpt given to the participants detailed information on ports regarding their use, structure, and benefits. The first part of the scene shows a body where specific veins are visible through the skin. The most important vein for this procedure is highlighted. In the second part, the model of a port chamber is depicted. Finally, in the third, a human with a fully implanted port including the catheter is shown, with relevant parts visible through the skin.

\subpart{Anaphylaxis} The final task in the role of the educator is covering the topic of severe allergic reactions, their diagnosis and how to treat them in the field. The most commonly used drug for this is adrenaline, which gets injected into large muscles of the affected person. The excerpt covers this topic in depth, including symptoms and treatment in the field. The first part of the scene shows a human body, the second an enlarged version of an EpiPen and finally the third, the EpiPen stuck to the upper thigh. This time, the participants were allowed to make full use of all the tools.

\subsubsection{Learners}

In the part of the study where participants were exploring the systems designed for learners, they were wearing the supplied HMD. For this, they had to go through the courses described below. 

\subpart{Ablation} In this task, the learners were standing in a scene with a male body and a whiteboard. The whiteboard displays a simplified endoscopic ablation to remove a tumor. For this, two tools with needles, one with a camera and one with a hot tip, are inserted into the body. The green circles that are depicted on the whiteboard are drawn onto the body to aid the participant in locating the tumor. The participant has to insert the needle with the camera into the body. Once inserted, organs near the camera can be seen through the skin. The participant then has to search for the bright color-coded tumor and touch it with the laparoscopic tool they have holding in their other hand. Once that's done, they have finished this task. The annotations that were used to create this scene were like those created by the pen tool.

\subpart{Digestion} This scene holds the organs that are part of the human digestive tract. Each of the important parts had a text box associated with it, totaling 11 annotations. The sequence tool was used to make the text boxes appear in the order in which food would pass through them. Participants were tasked to read through every text box. For this, they also had to move around because the text boxes were occluded by the organs from some view points.

\subpart{Teeth inspection} The final task in the role of learners was concerned with teeth. They were presented with a skill with an open mouth. The teeth are colored according to their quadrant. The participants learned the Federation Dentaire Internationale (FDI) dental notation~\cite{isoTeeth}, which gives each tooth a simple ID from text boxes. Then they were tasked to mark a specific tooth with by coloring it yellow. Lastly, they should use a special tool to remove a tooth given by its ID by touching it. This scene combined all annotations we examined in this paper.

\subsection{Participants}

Of our 24 participants, 15 were male and 8 were female. The youngest participant was 23, the oldest 38 with a median age of 25. All participants had at least a High school diploma, with 4 having or aspiring to have a bachelors degree, 10 a masters-level degree and 2 PhDs. Out of the 6 people not currently being a student, 2 work as software developers and 3 as researchers.

The previous experience in the areas our research is touching is very diverse. 11 of our participants have none to very little experience with 3D environments like simulations or video games. Of the other 13, one has 3–4 years of experience, while the rest have 5+ years.
%
Our participants were less experienced in general with VR, with fifteen having reported no true experience, three having less than 1 year, three in the range of 1–2 years, one having 3-4 and only two people having at least 5 years of experience. Nobody reported using VR regularly. 
%
Except for 2 people, everyone was interacting with PCs every day. Nine participants reported playing video games every day, and six others at least a few times a month.

\subsection{Measures}
\label{sec:measures}
\subsubsection{Objective Measures}

During the tasks, we created a log where the most important events are appended with a timestamp. An entry was added each time:

\begin{itemize}
    \item a Unity scene changes, which occurred when switching to the next task,
    \item the learner finishes a task,
    \item the educator switches to a different interaction mode,
    \item the learner is using a VR controller to pick something up,
    \item or the educator is interacting with the height slider (at most once per second).
\end{itemize}


These timestamped events allow us to reconstruct how long each participant took for which tasks, what tools they used and how long they used them. To capture the drawn annotations that were created, we created photos of the scene from multiple angles when a task was finished or before a new scene was entered.




\subsubsection{Subjective Measures}
This study utilizes multiple questionnaires to measure how users reacted to our presented tools. First, to measure symptoms of sickness, the widely used \textbf{Simulator Sickness Questionnaire (SSQ)}~\cite{ssqOriginal} is included. The SSQ asks the user to rate their sickness by ranking their current feeling regarding 16 different criteria (e.g., headache, fatigue, nausea, or dizziness) on a scale of 1 to 4. Using that, 3 scales can be derived that relate to nausea (N), oculomotor disturbance (O) and disorientation (D). Kennedy et al.~\cite{ssqOriginal} report multiple thresholds with $>20$ being the most severe one, relating to a bad simulator~\cite{ssqFix}. Though, as noted by Bimberg et al.~\cite{ssqFix}, we applied the corrected formula for the final score and used the common approach of using a pre- and post-study questionnaire. We wanted to assess how the SSQ scores differed between the usage of touchscreens and the HMD, so we separated the post-study SSQ into two parts, where participants had to rank their feelings for each of the device types.
%
Even when somebody does not actually experience symptoms of simulator sickness, they still may feel other types of discomfort regarding specific tools. To quantize this, we employ the \textbf{Device Assessment Questionnaire (DAQ)}~\cite{daq} in which each volunteer had to rate the required force, smoothness, mental and physical effort as well as various bodily fatigues (totaling thirteen properties) when using each of the eleven tools. This resulted in 143 ratings the users had to perform. The scale of the DAQ goes from 1 to 5, while the interpretation was inconsistent between each of the questions. For some questions, 3 is the ideal case, where for some it is 5 as seen in the header of \autoref{tab:daq}.
%
We also want to measure presence, as that is a big factor for learning experiences ~\cite{presenceLearning}. This was gauged by adding the \textbf{Igroup Presence Questionnaire (IPQ)}~\cite{ipq} to our post-study questionnaire. The fourteen questions included try to measure how much the simulated world was recognized and experienced as reality. They also ask the participant to reflect on how much of the real world was still perceived. The questionnaire presents statements and asks the responded to rate their agreement from 0 through 7. The questions were again separated between touchscreen and VR. 



To assess the usability of our tools more directly, users had to answer the \textbf{System Usability Scale (SUS)}~\cite{sus}. Each of the 10 statements contained tried to address different important factors for real-world usability, which users had to rate their agreement with. To consider our tools independently, each of the 10 statements had to be rated for each of the 11 tools, resulting in 110 ratings. The rating was conducted by assigning each of the statements a score between 1 and 5, where 1 represents minimal agreement and 5 maximum agreement with the statement. The usability can then be calculated according to SUS and falls between 0 and 100.

On the last page, users had to state which of the 6 subtasks was their favorite. Finally, users had to evaluate the perceived usefulness of the annotations, regardless of their current implementation.