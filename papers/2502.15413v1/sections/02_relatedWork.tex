\section{Related Work}
\subsection{Touch Interfaces}
Touch interfaces utilize the flexibility of touchscreens to offer users an intuitive means of interaction with digital content, enhancing user engagement and streamlining various tasks in a wide range of applications. Current applications make use of two techniques~\cite{menuTouch, menuTouch2, touchReview}. The first technique is emulating the traditional interaction flow when using a mouse and a keyboard, resulting in buttons and menus reacting to touch. But touchscreens also enable the usage of another way of interfacing with the computer in the form of gestures~\cite{gesturalInterfaces}. This allows a more direct interaction with the environment and is shown to be less distracting for users~\cite{menuTouch2}.
%
There are many attempts to solve the problem of intuitive and capable movement-systems for touch interfaces. A classic attempt is to emulate physical controllers as graphical user interface (GUI). Especially, games using a first-person camera use one or two virtual joysticks~\cite{multiTouch3D}.  
%
The MagicCube~\cite{magicCube} one-handed technique is designed to reduce the screen area that is occluded by fingers. A GUI element is displayed, which allows movement with 5 Degrees of freedom (DOF). The GUI element shows a cube with 3 visible sides, where depending on which side a user drags from, different actions are performed such as translation, rotation, or selection of items in the environment.
%
Marchal et al.~\cite{multiTouch3D} summarized multiple methods and proposed a solution which is not reliant on GUI elements. It proposes a method to move back and forth and rotate left and right using one finger. when two fingers are used, a classifier determines the main component of the action. If the user rotates their fingers, the camera rotates around a point in the scene. By pinching, the camera's field of view will get regulated and by panning both fingers together, the camera can rotate both horizontally and vertically.


\subsection{Learning Systems}

\subsubsection{Touchscreens}

Touchscreens are conventional displays that are equipped with sensors that can detect whether and where the user comes into contact with them. One significant advantage is their intuitivity~\cite{touchEvaluation}: when a user want's to press a button on the screen, instead of using the mouse to move the cursor above it, they can simply tap the screen at that position. This ability results in much research into designing interfaces with them~\cite{touchM3, touchDesign}, some aimed at groups like old adults~\cite{touchInterfacesOld, touchInterfacesOld2, touchInterfacesOld3} or visually impaired individuals~\cite{touchVisualImpairment, touchVisualImpairment2, touchVisualImpairment3}.

The ubiquity of touchscreens in the form of mobile tablets and smartphones leads to many young children having access to this technology~\cite{youngChildrenTouchscreens}. There is research concerning the use of these devices for early education~\cite{touchscreenChildrenLearning, touchBenefitsDamagesKids}. They are especially beneficial to children because they have very little other contact with technology and are not accustomed to common computer interfaces like mice and keyboards.

\subsubsection{Virtual Reality}

Learning systems where learners are immersed in a VR environment received some research, especially in specialized areas where the study of real-world counterparts is expensive or difficult, but spatial information is still critical. The approach Saffo et al. ~\cite{desktopVRCombination} take is similar to the one that is described in this paper, with the contrast that they focus on interactions between VR and non-touch desktop environments. One of the fields where learning in VR is very well studied is surgical training~\cite{vrMedicalTraining, vrMedicalTraining2, vrMedicalTraining3,hombeck2024voice,laparoscopyInstrumentVR} where students are reported to learn faster~\cite{vrFasterLearning} and achieve better results~\cite{vrMedicalBetter}. Moreover, prior research has indicated that spatial and distance estimation tend to exhibit greater accuracy in VR environments when compared to desktop applications ~\cite{unityInterface2,hombeck2022distance,hombeck2019evaluation}.
%
Some research delves more generally into education and creates suggestions for the general architecture of educational applications. Co-assemble~\cite{coAssemble} proposes to separate learning environments into three scenarios. In single user mode, learners operate alone in an environment, having more freedom and feel less pressure. In the medium-sized setup, classes are separated into groups where learners cooperate in a shared space. Finally, the class mode is the most similar to traditional school setups; every learner is in the same space as the educator, mostly restricted to observing a live presentation. Educators may choose to allow specific learners to present things to the whole class. Each scenario has its unique benefits, so providing them all is important.

\subsection{Annotations}

Annotations provide context to existing information. Most research regarding annotations placed in 3D spaces is concerned with enabling remote collaboration or assistance~\cite{vuforiaAnnotations, annotations1, annotations2}. A common scenario is where an on-site technician requires assistance from experts. Instead of sharing individual photos, current research is trying to recreate the 3D environment of the on-site technician so that the expert can better grasp the spatial context.
%
Marques et al.~\cite{vuforiaAnnotations} evaluated different types of annotations regarding their usefulness to on-site technicians and remote experts. They were concerned with asynchronous assistance in three steps: first, the on-site user captures the environment and annotates it. Then the remote user inspects it, placing further annotations to detail what an intervention should look like. Thirdly, the on-site technician performs that intervention by following the provided annotations. Though they did not name all tested annotations, in their results they name the ones that were rated most useful. These annotations were (most useful first): first drawing, for its versatility, second notes, for their ability to add richer context, third notifications, to alert to information updates. Finally, they also added the possibility to add temporal sorting to other annotations, which was appreciated for its use in environments with many annotations. They noted, that editing existing annotations were an important aspect to potentially reducing workload.