\section{Experimental Setup}

With the goal of better understanding the ability of multi-agent LLM systems to model prosocial human behavior, we simulate three different types of experiments: (1) simulations which aim to directly capture effects observed in a previous lab experiment with human subjects; (2) simulations which combine effects from multiple previous lab experiments with human subjects; and (3) select "in-the-wild" real-world scenarios we use as case studies towards identifying mechanisms necessary for simulations to display human-like behavior. For all experiments, we use OpenAI's GPT4 (model gpt-4o-mini), which has been shown to have the ability to interpret inherently human concepts such as equity and also scores  well on a variety of standardized tests, ranging from the Bar Exam to the GRE \cite{openai2023gpt4}. 

We specifically address the following three research questions:

\bigskip

\begin{itemize}[itemindent=0em]
  \item[\underline{\textbf{RQ1}}] Can multi-agent LLM system simulations replicate behaviors observed in PGG lab experiments with human subjects?
\begin{itemize} [leftmargin=0.15in]
\item[\underline{a.}] Does priming LLM agents via game name replicate the effect of priming humans via game name?
\item[\underline{b.}] Does introducing transparency in contribution between LLM agents replicate the effect of introducing transparency in contribution between humans?
\item[\underline{c.}] Does varying the endowments of LLM agents replicate the effect of varying endowments of humans?
\end{itemize}
\end{itemize}

% \bigskip
% 

% \begin{itemize}[itemindent=2.5em]
%   \item[\underline{\textbf{RQ1}}] \textit{Can multi-agent LLM system simulations replicate behaviors observed in PGG lab experiments with human subjects?} We answer this research question via three experiments comparing results from simulations with LLM-agents to results from lab experiments with human subjects:
  
%   \begin{itemize} [leftmargin=0.5in]
%     \item[\underline{1.}] Priming via Game Name
%     \item[\underline{2.}] Introducing Transparency of Contributions
%     \item[\underline{3.}] Varying Endowments
%   \end{itemize}
% \end{itemize}

% \color{black}

\bigskip

\begin{itemize}[itemindent=0em]

  \item[\underline{\textbf{RQ2}}] Can multi-agent LLM system simulations transfer effects observed in non-PGG lab experiments to simulations of the PGG?
\begin{itemize}[leftmargin=0.15in]
    % \item[\underline{a.}] Does priming LLM agents with sentences known to increase/decrease generosity in humans have that effect in simulations of the PGG?
    \item[\underline{a.}] Does priming LLM agents with a methodology used in non-PGG cooperation game lab experiments have the expected result in LLM simulations of the PGG?
    % \color{red}Priming methodology\color{black}
% \item[\underline{b.}] Does the effect of priming LLM agents via game name in multi-round PGGs fade over time, like priming has been observed to fade over time in other experiments with human subjects?\color{red}priming over time\color{black}
\item[\underline{b.}] Does the effect of priming over time, observed to fade in non-PGG competition game lab experiments, hold in LLM simulations of the PGG?
\end{itemize}
\end{itemize}

  \bigskip
% 
% \begin{itemize}[itemindent=2.5em]

%   \item[\underline{\textbf{RQ2.}}] \textit{Can multi-agent LLM system simulations replicate human behavior extrapolated from combining the behaviors observed in multiple lab experiments with human subjects?} We answer this research question via two experiments combining treatments and expected effects from multiple lab experiments with human subjects:
%   \begin{itemize}[leftmargin=0.5in]
%     \item[\underline{1.}] Using a priming methodology from other cooperation games in the PGG
%     \item[\underline{2.}] Measuring the change in effect of priming over time, using results of priming over time from a different competition game
%   \end{itemize}
% \end{itemize}
% \color{black}

% \bigskip

\begin{itemize}[itemindent=0em]
  \item[\underline{\textbf{RQ3}}] To what extent are multi-agent LLMs complex enough to simulate the rich set
of unbounded options, actions, and interactions people do in the real world, outside of the lab?
\begin{itemize}[leftmargin=0.15in]
    % \item[\underline{a.}] Does priming LLM agents with sentences known to increase/decrease generosity in humans have that effect in simulations of the PGG?
    \item[\underline{a.}] To see the complex
interactions observed in the real world, what simulation mechanisms do we have to add to the set up of the system?
    % \color{red}Priming methodology\color{black}
% \item[\underline{b.}] Does the effect of priming LLM agents via game name in multi-round PGGs fade over time, like priming has been observed to fade over time in other experiments with human subjects?\color{red}priming over time\color{black}
\end{itemize}
\end{itemize}

% \bigskip

% 

% \begin{itemize}
%   \item[\underline{\textbf{RQ3.}}] \textit{What are required mechanisms for simulations to
% inform policy-makers regarding real-world situations to test policies that encourage human collaboration?} We answer this research question via three real-world case studies towards identifying necessary mechanisms:
% \begin{itemize}[leftmargin=0.5in]
%     \item[\underline{1.}] A classroom setting with varying late-assignment policies
%     \item[\underline{2.}] A store parking lot where shoppers need to return shopping carts to designated areas
%     \item[\underline{3.}] Graffitti?
%   \end{itemize}
% \end{itemize}

% \color{black}

\bigskip

We expect generally positive results for the first two research questions, given that other work has shown the ability of LLMs to replicate lab experiments that are both published and unpublished \cite{hewitt2024predicting}, but still verify this in the context of the PGG towards understanding the abilities of multi-agent LLM systems to simulate prosocial behavior. The third research question is more open-ended - we use case studies of real-world scenarios towards identifying mechanisms required for simulations to show expected outcomes, a process which can be continued to be used by policy makers. As policy makers consider the specific scenarios which they need to simulate, they may realize and implement new mechanisms required to enable their simulation. However, we also expect that mechanisms will be generalizable to an extent across simulations of various situations.


\subsection{Multi-Agent Architecture}
For all studies, we adapted a previously introduced and open-source multi-agent system for simulating social emergent behavior \cite{GPTeam}. The system is implemented in Python and uses gpt-4o-mini. The input to the system is a JSON file describing the \textit{locations} and \textit{agents} in the simulation. The output is a series of logs for \textit{events} (things done by agents and witnessed by other agents). The input files and system we use for the simulations in our studies are publicly available \cite{prosocialGPTeam}.

The system architecture consists of a class structure defined as follows. At the highest level, the simulation is represented by a \textit{world} class consisting of 3 sub-classes: \textit{locations}, \textit{events}, and \textit{agents}. 

 Locations represent places that agents can go within the world.  Locations are specified by a name, description, and agents allowed within them. Agents can only talk to other agents or witness events in the same location as them. Events are created when agents take action, whether that be moving or speaking.  Events are specified by a timestamp, the agent that acted, the location it occurred, a description, and witnesses.

Agents are separate LLM instances that are used to represent "people" in the environment.  Agents are specified by a name, a private biography, a public biography and an initial plan. The private biography is information about the agent only known to the agent. The public biography is information about the agent that other agents also are aware of. The initial plan instructs the agent on what to do when the simulation starts. It is specified by a location (i.e., where it occurs), a description of what the agent should do, and a stop condition that specifies when the agent should stop executing on the plan. The initial plan is private - it is only known to the agent. 

Agents have subclasses \textit{plans} – specified by a description, location, and stop condition – and \textit{memories} – specified by a description, creation time, and importance score. Plans are created by agents as they witness events in simulation. All plans are specified in the same format as the initial plan. Memories are created each time an agent witnesses an event. When a memory is created, an importance score is also created simply by asking an LLM to generate one. When agents act, they first identify memories that are relevant and use them to maintain or adjust their current plan before executing on their action. 

% Agents are specified by a name, biographies, an initial plan (with a location, description, and stop condition) that are unique (and other than the public biography) and only known to them.   

Simulations can be run once the user specifies the locations and agents in the input file. The system executes simulation via \textit{agent loops}, which involve (1) agents \textit{observing} the events in their current location, (2) agents adding events to memory, (3) agents creating \textit{plans}, (4) agents \textit{reacting} as to whether or not to continue the current plan, (5) and agents \textit{acting}, carrying out plans. Agents \textit{speak} to communicate with one another.  The agent loop is what enables emergent behavior - agents are able to "reason" about their surroundings and events and then decide on new courses of actions. This type of architecture has been shown to be more accurate in replicating human behavior in social science/economics games than just prompting a single LLM \cite{sreedhar2024simulatinghumanstrategicbehavior}.

When implementing the PGG in this environment, we create 4-5 agents: 3-4 players, and one moderator. The private biography is used to provide agents with their unique priming or endowment that other agents should not know. There are typically two locations;  a game room where players are by default, and a contribution room where players make their contribution. Players are aware of the existence of these locations and can move between them. In every agent loop, the agent waits for the player before them to come back from the contribution room, then goes to the contribution room, tells the moderator their contribution, the moderator records it to his memory, and the player agent leaves. When all the players are done, the moderator comes out and announces the game outcome. 

\color{black}

\section{Study 1: Replicating Lab Experiments of PGG}

% The first study aims to answer the following research question:

% \begin{itemize}[itemindent=0em]
%   \item[\underline{\textbf{RQ1}}] Can multi-agent LLM system simulations replicate behaviors observed in PGG lab experiments with human subjects?
% \begin{itemize} [leftmargin=0.25in]
% \item[\underline{a.}] Does priming LLM agents via game name replicate the effect of priming humans via game name?
% \item[\underline{b.}] Does introducing transparency in contribution between LLM agents replicate the effect of introducing transparency in contribution between humans?
% \item[\underline{c.}] Does varying the endowments of LLM agents replicate the effect of varying endowments of humans?
% \end{itemize}
% \end{itemize}

% \subsection{LLM-Agent Simulation Setup for the Public Goods Game}

% \subsubsection{PGG Simulation Setup} \sout{There are three main necessary components for simulating the PGG: (1) agents, (2) locations, and (3) game play instructions.} \sout{To setup the PGG simulation, we intialize \color{black} two types of people: one moderator and multiple players (typically 3-4). These are all represented by separate LLM-agents.
% The simulation requires two locations: (1) a moderation room where players tell the moderator their contribution in private and (2) a game room where players wait their turn to talk to the moderator and the moderator delivers the result of the game. Players know these locations exist and that they can move between them. There are also game play instructions that are given to all agents so they know what to do: the players know their endowment, that they will take turns telling the moderator their contribution in the moderation room, and that they will receive an announcement of the results in the game room. For variants of the game testing different treatments, additional instructions and player information is added.}


% % The game requires four to five agents: three to four player agents and one moderator agent. We  two rooms: the game room and the moderation room. 

% % We need four to five agents (three players and one moderator), rooms (2 rooms, the game room and moderation room), and (3)initialization instructions (agents are told their role and ).

% % WAIT FOR THEIR TURN. players are given an initial endowment. for all of these experiments, there is only one round. they will take turns making contributions. and then the moderator will announce the outcomes to the group.

% % there are separate additional instructions for each variant of the game. 

% \subsubsection{Multi-Agent LLM Architecture Implementation} \sout{We implement the simulation by adapting a previously introduced agent architecture for simulating social emergent behavior \cite{GPTeam}. In this architecture, the person running simulations provides each agent with a name, public and private biographies, instructions, and an initial plan, which consists of a description, stop condition, and a location. The architecture also allows for the creation of locations (specified by a name and description) between which agents can move, but does not have an explicit turn-taking process.}\sout{The architecture used does not have an excplicit turn-taking process. \color{black} Instead, turn-taking can be implemented by ordering the player agents and telling every player to see to the moderator after the player ordered immediately ahead of them.}

% % Communication between agents  the architecture is not inherently turn-taking - we specify the order of contributions via agents instructions and initial plan.




% When implementing the PGG in the multi-agent framework, we initialize it as follows. The moderator agent's name is "Moderator," and its public biography is simple: "This agent plays the role of the moderator". The moderator agent has no private biography. The moderator has an initial plan to start in the moderation room and wait for all players to make their contribution, and has instructions to then move to the game room and announce payoffs once all agents have made their contribution.

% The player agents are given arbitrary alphabetical names (Alice, Bob, Casey, and David) and each have public biographies with a statement that the agent is playing a PGG-like game and contains their initial endowment, which all other agents can see. The player agents' private biography is blank by default, but is used to realize the priming condition of experiments  - for example, the name priming is realized by adding to the agents private biography, "You are playing a game called the \textit{Taxation Game}." \color{black} 

% The architecture used does not have an explicit turn-taking process. \color{black} To implement the mechanics of turn-taking, player agents' have an initial plan to wait for the player before them to return from the moderation room. Player agents are ordered alphabetically by being told the player before them (in the case of Bob, Casey, and David) or by being told they are first (in the case of Alice). They also have instructions to move to the moderation room and make their contribution (with the payoff specified here for player agents to take into account) once the player before them has returned, and to not engage with any other player agents' in the game room until the Moderator comes to the room and payoffs are announced. In each \textit{agent loop}, the agent thus waits for the player before them to come back from the contribution room before going themselves, tells the moderator their contribution (which the moderator records to their memory), then returns to the main room.\color{black}

% % the Generative Agents Structure does not have a mechanism for turn-taking, thus

% % In the initial plan description, 
% % players initial location is the game room. 
% % The Generative Agents Structure does not have a mechanism for turn-taking, thus we implement this is the initial description: every player must wait for the player before them to return from the Moderator room (where they take their turn TELLING THE CONTRIBUTION).
% % The 

% % player agents are told to wait for the player that comes before them to return to the game room. The stop condition of the initial plan is when the player before returns to the game room from making a contribu The location of the initial plan is specified as the game room. In the directives, player agents are instructed to move to the moderation room and make their contribution once the initial plan stop condition is hit.



% % Initial Plan (for Bob)
% % description: wait for ALICE to return from the game room (for the first one it's slightly different)
% % location: game room
% % stop condition: ALICE  has returned from the game room

% % Instruction: once alice is back, move into the moderation room to make your contribution
% % Instruction: after making the contribution come back
% % Instruction: in the game room, do not engage with any other players until the moderator returns and announces payoffs

% % In the simulation setup for the PGG within this architecture, there is an agent named and directed to act as the moderator. The remaining agents (varies from three to four depending upon the experiment) are given arbitrary alphabetical names (Alice, Bob, Casey, and David). Each agent's initial endowment is specified in their public biography, which all other agents can see. If there is a priming condition, it is included in the private biography as to expose the desired agent to the priming without leakage to other agents. Communication is not inherently turn-taking in the architecture; so we have to specify the order and method of contribution to player agents via their directives and initial plan. We initialize two separate rooms - the game room and the moderation room. Player agents are by default in the game room, then travel to the moderation room to tell the moderator their contribution once the player specified as being before them returns to game room from the moderation room after making their contribution. The moderator remains in the moderation room other than to announce payoffs after all players have made contributions. To realize transparency, we simply remove the moderation room, and have all agents make their contributions publicly in the game room. 


% \subsubsection{Data Collection} As the simulation progresses, all of the thoughts and actions of each player agent (and the moderator agent) are displayed in separate output logs, each representing one of the agents involved in the simulation. Each output log contains a plethora of information, ranging from the events each agents observed, their reactions to them, and the creation of new plans, but we are only interested in the contributions they make.

%  To collect data on the contribution amount of each agent, we used a script on each player agent's output logs. The script used string matching and regular expressions to look for when each agent was in the moderation room and the dollar amount said by the agent. This data was then output into a table. A human verified that the data was accurately transcribed by reading the sections identified by the script and making corrections as needed.


\subsection{Methodology}

To test whether LLMs can replicate lab experiments, we pick three lab experiments with human subjects. We create simulations for them, run it, and compare results to human behavior. These three studies focus on three different effects: (1) priming via game, (2) transparency of contributions, and (3) variation in endowment. They found the following:

\subsubsection{Experiment \#1} \label{oneofone} The first experiment studies the effect of positive and negative priming on contributions in the PGG. We obtain data on human behavior from a 2014 lab experiment in \textit{Judgement and Decision Making} \cite{Eriksson_Strimling_2014} with 100 human participants. Participants were explained the rules of the game, but told one of two different names for the game. \color{black} In the positive condition, people were told the game was called the "Teamwork Game." In the negative case, people were told the game was called the "Taxation Game." The remaining conditions were the same. In the positive priming condition ("Teamwork"), people on average contributed 60\% of their endowment. In the negative priming condition ("Taxation"), people on average contributed only 40\% of their endowment. \textbf{Thus, positive priming increases prosocial behavior.}

% \sout{People were put into one of two conditions.} 
% \sout{\cite{Eriksson_Strimling_2014}}

We test whether this effect applies to LLM-agents by simulating ten one-shot PGGs with four players, two under each priming condition and all four with a \$20 endowment, and comparing the average contribution amount of players from either group. Specifically, we prime players by including sentences containing the appropriate name in their private biographies (for example, "Alice is playing a game called the "Teamwork Game."). In the simulation, 1.6 times the amount of the public pool is split evenly amongst the players as their payoff - players are made aware of this to inform the way in which they act, but the simulation is of a one-shot PGG.

\subsubsection{Experiment \#2} The second experiment studies the effect of transparency of contributions in the PGG. We obtain data on human behavior from a 2017 review paper of 71 human lab studies published in \textit{Experimental Economics} \cite{transparencytwo}. \color{black} Specifically, the difference in contribution is presented for people who played the PGG in two conditions: one where people knew the contributions made by others and another where they did not. When there was transparency of contributions, people contributed 6\% more on average than when there was not. \textbf{Thus, transparency of contributions increases prosocial behavior.}

%\sout{\cite{transparencytwo}}

% \sout{It collects data from a variety of prior studies with and without transparency.}

We test whether this effect applies to LLM-agents by simulating ten four-player one-shot PGGs, five with transparency of contributions and five without, and comparing the average contribution amounts in either condition. Specifically, we realize transparency by removing the moderation room - contributions are made in the "public" game room where all other agents can overhear other's contributions. In the simulation, 1.6 times the amount of the public pool is split evenly amongst the players as their payoff - players are made aware of this to inform the way in which they act, but the simulation is of a one-shot PGG.

\subsubsection{Experiment \#3} The third experiment studies the effect of unequal endowments on contributions in the PGG.  We obtain data on human behavior from a 2016 lab experiment published in \textit{Economics Letters} \cite{HARGREAVESHEAP20164}. \color{black}The experiment included four separate PGG games with different endowment conditions: (1) where all players had \$20, (2) where all players had \$50, (3) where all players had \$80, and (4) where one player had \$20, one player had \$50, and one player had \$80. The results of the experiment find that people endowed with \$20 and \$50 contributed roughly the same in both games were all players had the same endowment and games where endowments were varied, but that people endowed with \$80 contributed much more in games were all players had the same endowment than games in which endowments were varied.
%\sout{\cite{HARGREAVESHEAP20164}}. 
\textbf{Thus, varying endowments does not seem to have an effect on prosocial behavior in "poor" and "medium" wealth individuals, but reduces prosocial behavior in "rich" individuals.}

We test whether this effect applies to LLM-agents by simulating twenty-five three-player one-shot PGGs, fifteen where players have equal endowments (five for \$20, \$50, and \$80 respectively) and ten where players have varied endowments (one player with \$20, one with \$50, and one with \$80), then comparing the average contribution of players with each endowment amount under the equal and varied endowment conditions. Specifically, we realize the variation in endowments simply by changing the players public biographies, where their endowments are set. In the simulation, 1.6 times the amount of the public pool is split evenly amongst the players as their payoff - players are made aware of this to inform the way in which they act, but the simulation is of a one-shot PGG.


\subsection{LLM-Agent Simulation Setup for the Public Goods Game}

% \subsubsection{PGG Simulation Setup} \sout{There are three main necessary components for simulating the PGG: (1) agents, (2) locations, and (3) game play instructions.} \sout{To setup the PGG simulation, we intialize \color{black} two types of people: one moderator and multiple players (typically 3-4). These are all represented by separate LLM-agents.
% The simulation requires two locations: (1) a moderation room where players tell the moderator their contribution in private and (2) a game room where players wait their turn to talk to the moderator and the moderator delivers the result of the game. Players know these locations exist and that they can move between them. There are also game play instructions that are given to all agents so they know what to do: the players know their endowment, that they will take turns telling the moderator their contribution in the moderation room, and that they will receive an announcement of the results in the game room. For variants of the game testing different treatments, additional instructions and player information is added.}


% The game requires four to five agents: three to four player agents and one moderator agent. We  two rooms: the game room and the moderation room. 

% We need four to five agents (three players and one moderator), rooms (2 rooms, the game room and moderation room), and (3)initialization instructions (agents are told their role and ).

% WAIT FOR THEIR TURN. players are given an initial endowment. for all of these experiments, there is only one round. they will take turns making contributions. and then the moderator will announce the outcomes to the group.

% there are separate additional instructions for each variant of the game. 

\subsubsection{Multi-Agent LLM Architecture Implementation} 
% \sout{We implement the simulation by adapting a previously introduced agent architecture for simulating social emergent behavior \cite{GPTeam}. In this architecture, the person running simulations provides each agent with a name, public and private biographies, instructions, and an initial plan, which consists of a description, stop condition, and a location. The architecture also allows for the creation of locations (specified by a name and description) between which agents can move, but does not have an explicit turn-taking process.}\sout{The architecture used does not have an excplicit turn-taking process. \color{black} Instead, turn-taking can be implemented by ordering the player agents and telling every player to see to the moderator after the player ordered immediately ahead of them.}

% Communication between agents  the architecture is not inherently turn-taking - we specify the order of contributions via agents instructions and initial plan.




When implementing the PGG in the multi-agent framework, we initialize it as follows. The moderator agent's name is "Moderator," and its public biography is simple: "This agent plays the role of the moderator". The moderator agent has no private biography. The moderator has an initial plan to start in the moderation room and wait for all players to make their contribution, and has instructions to then move to the game room and announce payoffs once all agents have made their contribution.

The player agents are given arbitrary alphabetical names (Alice, Bob, Casey, and David) and each have public biographies with a statement that the agent is playing a PGG-like game and contains their initial endowment, which all other agents can see. The player agents' private biography is blank by default, but is used to realize the priming condition of experiments  - for example, the name priming is realized by adding to the agents private biography, "You are playing a game called the \textit{Taxation Game}." \color{black} 

The architecture used does not have an explicit turn-taking process. \color{black} To implement the mechanics of turn-taking, player agents' have an initial plan to wait for the player before them to return from the moderation room. Player agents are ordered alphabetically by being told the player before them (in the case of Bob, Casey, and David) or by being told they are first (in the case of Alice). They also have instructions to move to the moderation room and make their contribution (with the payoff specified here for player agents to take into account) once the player before them has returned, and to not engage with any other player agents' in the game room until the Moderator comes to the room and payoffs are announced. In each \textit{agent loop}, the agent thus waits for the player before them to come back from the contribution room before going themselves, tells the moderator their contribution (which the moderator records to their memory), then returns to the main room.\color{black}

% the Generative Agents Structure does not have a mechanism for turn-taking, thus

% In the initial plan description, 
% players initial location is the game room. 
% The Generative Agents Structure does not have a mechanism for turn-taking, thus we implement this is the initial description: every player must wait for the player before them to return from the Moderator room (where they take their turn TELLING THE CONTRIBUTION).
% The 

% player agents are told to wait for the player that comes before them to return to the game room. The stop condition of the initial plan is when the player before returns to the game room from making a contribu The location of the initial plan is specified as the game room. In the directives, player agents are instructed to move to the moderation room and make their contribution once the initial plan stop condition is hit.



% Initial Plan (for Bob)
% description: wait for ALICE to return from the game room (for the first one it's slightly different)
% location: game room
% stop condition: ALICE  has returned from the game room

% Instruction: once alice is back, move into the moderation room to make your contribution
% Instruction: after making the contribution come back
% Instruction: in the game room, do not engage with any other players until the moderator returns and announces payoffs

% In the simulation setup for the PGG within this architecture, there is an agent named and directed to act as the moderator. The remaining agents (varies from three to four depending upon the experiment) are given arbitrary alphabetical names (Alice, Bob, Casey, and David). Each agent's initial endowment is specified in their public biography, which all other agents can see. If there is a priming condition, it is included in the private biography as to expose the desired agent to the priming without leakage to other agents. Communication is not inherently turn-taking in the architecture; so we have to specify the order and method of contribution to player agents via their directives and initial plan. We initialize two separate rooms - the game room and the moderation room. Player agents are by default in the game room, then travel to the moderation room to tell the moderator their contribution once the player specified as being before them returns to game room from the moderation room after making their contribution. The moderator remains in the moderation room other than to announce payoffs after all players have made contributions. To realize transparency, we simply remove the moderation room, and have all agents make their contributions publicly in the game room. 


\subsubsection{Data Collection} As the simulation progresses, all of the thoughts and actions of each player agent (and the moderator agent) are displayed in separate output logs, each representing one of the agents involved in the simulation. Each output log contains a plethora of information, ranging from the events each agents observed, their reactions to them, and the creation of new plans, but we are only interested in the contributions they make.

 To collect data on the contribution amount of each agent, we used a script on each player agent's output logs. The script used string matching and regular expressions to look for when each agent was in the moderation room and the dollar amount said by the agent. This data was then output into a table. A human verified that the data was accurately transcribed by reading the sections identified by the script and making corrections as needed.

%To test what happens in simulation,  / we implement this (from the paragraph below)

% \color{black}

% For experiments of the first type, we run simulations of the PGG using treatments from published lab experiments with human subjects, checking whether the effect of said treatments on LLM-agents in simulation in similar to that of on humans. The treatments and effects we replicate from previous lab experiments are listed in Table ~\ref{labexperiments}.

% \begin{center}
% \begin{table}[H]
% \setlength{\abovecaptionskip}{0pt}
% \setlength{\belowcaptionskip}{10pt}
% \begin{tabular}{|>{\columncolor{gray!20}\centering\arraybackslash}m{0.5cm}|p{6cm}|p{6cm}|} 
%  \hline
%  \rowcolor{gray!20} \textbf{Exp.} & \multicolumn{1}{c|}{\textbf{Treatment}} & \multicolumn{1}{c|}{\textbf{Expected Result}} \\ [0.5ex] 
%  \hline\hline
%  \textbf{1} & \textbf{Priming via Game Name:} Participants are presented the PGG as a game called either the "Taxation Game" or "Teamwork Game." & Participants presented the game as the "Taxation Game" contribute less than participants presented the "Teamwork Game." \cite{Eriksson_Strimling_2014} \\ 
%  \hline
%  \textbf{2} & \textbf{Transparency of Contribution:} Participants know what others contribute to the public pool (under standard conditions, contributions are made privately with respect to other players). & Participants make larger contributions when participants are aware of each other's contributions compared to when contributions are made privately without other's knowledge. \cite{transparencytwo}\\
%  \hline
%  \textbf{3} & \textbf{Variations in Endowment:} Participants start the PGG with different endowment amounts. & "Rich" participants contribute more when other participants are also "rich." \cite{HARGREAVESHEAP20164}  \\
%  \hline
% \end{tabular}
% \caption{\label{labexperiments}Table of treatments and expected results (effects) from previous lab experiments of the PGG with human subjects. Actual experiments that are drawn from are cited in the second column.}
% \end{table}
% \end{center}

% For these experiments, we simulate one-shot PGGs with three or four players, measuring whether the impact the treatments have on player contributions is similar to what has been observed in experiments with human subjects (i.e., the expected result listed). For the first experiment, we run ten simulations of the PGG with four players, two under each priming condition, and compare the average contribution amount of players from either group. For the second experiment, we also run ten simulations of the PGG with four players: five simulations with transparency of contributions and five without. We compare the average contribution amount of players in either of the two conditions. In the first and second experiments, players are all endowed with \$20. For the third experiment, we run twenty simulations with three players: fifteen simulations where all players have the same initial endowment (five where that endowment is \$20, five where it is \$50, and five where it is \$80) and five simulations where players have different initial endowments (namely, \$20, \$50, and \$80). We compare the average contributions of players with each of the three endowments in the fixed and the varied endowment conditions (i.e., we compare how much a player with \$X contributes in the condition where everyone has \$X vs. the varied condition). In all three experiments, 1.6 times the amount of the public pool is split evenly amongst the players as their payoff - players are made aware of this to inform the way in which they act, but the simulations are of one-shot PGGs.

\subsection{Results}

% Towards answering this question, we simulate treatments from three different lab experiments with human subjects: (1) priming via game name, (2) transparency of contributions, and (3) variations in endowment. In the first two experiments, LLM-agents replicate the direction of effects with statistical significance, but overestimate the magnitude. In the third experiment, LLM-agents replicate the direction of effects but the effect is not statistically significant, although this is likely due to insufficient data for comparison. \textbf{Overall, we conclude that LLM-agents are able to replicate the direction of the effect of priming and transparency treatments, \color{orange}but testing their ability to replicate the effect of a varied endowment requires further simulations.\color{black}}

\subsubsection{Does priming LLM agents via game name replicate the effect of priming humans via game name?}


\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{images/1A.png}
    \caption{Average contributions for "Teamwork" and "Taxation" priming conditions in simulations with LLM-agents and experiments with human subjects. Average contributions are above 60\% in the "Teamwork" priming condition for both groups. Average contributions are below 40\% in the "Taxation" priming condition for both groups.}
    \Description{A bar chart titled "Average Contribution by Priming" compares the average contributions in two priming conditions: "Teamwork" and "Taxation." The y-axis represents average contributions as a percentage of endowment, ranging from 0 to 100\%. The x-axis lists the two priming conditions. Each condition has two bars: a gray bar representing LLM-agents and a blue bar representing human participants. In the "Teamwork" condition, both groups contribute above 60\%, with LLM-agents contributing slightly more than humans. In the "Taxation" condition, contributions are below 40\% for both groups, with humans contributing slightly more than LLM-agents.}
    \label{1Agraph}
\end{figure}

% \sout{A t-test shows that the difference in contributions between the two groups is statistically significant at the p < 0.01 level  
% (\(t = 7.92, p < 0.00000001 \)). However, t-tests also show that there are statistically significant differences between the contributions made LLM-agents and the average human contribution under the "Teamwork" priming condition (\(t = 3.59, p = 0.002 \)) at the p < 0.01 level and the "Taxation" priming condition (\(t = -2.34, p < 0.031 \)) at the p < 0.05 level. \textbf{From these results, we conclude that priming LLM agents by presenting the PGG under different names replicates the direction of the effect of doing the same on humans, but may overestimate the magnitude.}}

A t-test shows that the difference in LLM contributions between the two groups is statistically significant at the p < 0.01 level  
(\(t = 7.92, p < 0.00000001 \)). We use one-sample one-tail t-tests to compare the LLM-simulation sample data with the human average contribution, finding that under the "Teamwork" priming condition, the LLM contributions are greater than the human average of 60\% (\(t = 3.59, p = 0.001 \)) at the p < 0.01 level. Under the "Taxation" priming condition, LLM contributions are less than the human average of 40\% (\(t = -2.33, p = 0.016 \)) at the p < 0.05 level. \textbf{From these results, we conclude that priming LLM agents by presenting the PGG under different names replicates the direction of the effect of doing the same on humans, but may overestimate the magnitude.}\color{black} 

\subsubsection{Does introducing transparency in contribution between LLM agents replicate the effect of introducing transparency in contribution between humans?}

In experiments with human subjects, participants contributed on average 6\% more of their endowment under transparency conditions as compared to no transparency. \cite{transparencytwo}. Across five simulations of each condition (ten simulations total) on average, LLM agents playing the PGG with transparency contributed approximately 60\% of their \$20 endowment, whereas LLM agents playing the PGG without transparency contributed only approximately 35\% of their endowment. These results are in Figure \ref{1Bgraph}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{images/1B.png}
    \caption{Average contributions with and without transparency of contributions for simulations. Experiments with humans show that average contributions in PGGs with transparency of contributions is 6\% higher than in PGGs without without transparency. In simulations with LLM-agents, average contributions in PGGs with transparency of contributions were 25\% higher than in PGGs without transparency. So, the direction of the difference is accurately captured.}
    \Description{A bar chart titled "Average Contribution by Transparency" compares the average contributions in two transparency conditions: "Without Transparency" and "With Transparency." The y-axis represents average contributions as a percentage of endowment, ranging from 0 to 100\%. The x-axis lists the two transparency conditions. The bar for "Without Transparency" is lower (35\%), indicating a lower contribution percentage, while the bar for "With Transparency" is noticeably higher (60\%). This suggests that contributions increase when transparency of contributions is present.}
    \label{1Bgraph}
\end{figure}

% \sout{A t-test shows that the difference in contributions between the two groups is statistically significant at the p < 0.05 level  
% (\(t = 2.23, p = 0.031 \)).} 
A one-tailed t-test shows that the mean contribution of LLMs under the transparency condition is significantly greater than the mean contribution of LLMs under the non-transparent condition (\(t = 2.23, p = 0.016 \)) at the p < 0.05 level. \color{black} \textbf{From these results, we conclude that introducing transparency of contributions in PGGs with LLM agents replicates the direction of the effect of doing the same on humans.}

% "If controlling for the MPCR, however, as is done in specifications (6) and (8), the positive effect of F.indichoice and the negative effect of F.indipayoffs have a larger magnitude and turn significant at the 5% level. The share contributed tends to be about 6 percentage points higher than in cases where players receive feedback about the distribution of choices in their group."


\subsubsection{Does varying the endowments of LLM agents replicate the effect of varying endowments of humans?}

In experiments with human subjects, it was found "poor" and "medium" wealth individuals contributed roughly the same amount in equal and varied endowment conditions, whereas "rich" individuals contributed more in the equal endowment condition than in the varied endowment condition \cite{HARGREAVESHEAP20164}. Across five simulations each of \$20-\$20-\$20, \$50-\$50-\$50, and \$80-\$80-\$80 equal endowment conditions, LLM agents on average contributed approximately 39\%, 48\%, and 63\% of their endowments, respectively. In five simulations of a \$20-\$50-\$80 varied endowment condition, on average the LLM agent given \$20 contributed approximately 35\%; the LLM agent given \$50 contributed approximately 42\%; and the LLM agent given \$80 contribute approximately 44\%. Thus, the contribution for agents endowed with \$20 was roughly the same between the equal and varied endowment conditions, whereas agents endowed with \$50 and \$80 both contributed less in the varied condition.These results are summarized in Table \ref{1Cgraph}.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.75\textwidth]{images/1C.png}  % Change this value to make the figure larger
%     \caption{Average contributions for equal and varied endowment conditions in simulations with LLM-agents and experiments with human subjects. Average contributions are roughly the same for humans and LLM-agents in the equal and varied endowment conditions with \$20 and \$50 endowments. Average contributions are lower in the varied condition than in the fixed condition with \$80 endowments for both humans and LLM-agents.}
%     \label{1Cgraph}
% \end{figure}

\begin{figure*}[t]  % Use figure* for spanning both columns
    \centering
    \includegraphics[width=\textwidth]{images/1C.png}  % Adjust width to span across the page
    \caption{Average contributions for equal and varied endowment conditions in simulations with LLM-agents and experiments with human subjects. Average contributions are roughly the same for humans and LLM-agents in the equal and varied endowment conditions with \$20 and \$50 endowments. Average contributions are lower in the varied condition than in the fixed condition with \$80 endowments for both humans and LLM-agents.}
    \Description{A bar chart titled "Average Contribution by Endowment" compares contributions as a percentage of endowment across different endowment amounts (\$20, \$50, and \$80) for humans and LLM-agents. The x-axis represents the endowment amounts and groups participants into "Human" and "LLM-Agents" under each endowment level. The y-axis represents the average contribution as a percentage of endowment, ranging from 0 to 100\%. Each group has two bars: a dark gray bar for "Equal Endowments" and a light blue bar for "Varied Endowments." Contributions generally increase with higher endowments, with variations between humans and LLM-agents. The impact of equal vs. varied endowments is also visible across conditions.}
    \label{1Cgraph}
\end{figure*}

% \begin{table}[htbp]
% \centering
% \begin{tabular}{|>{\columncolor{gray!20}}c|c|c|c|}
% \hline
% \rowcolor{gray!20}\multicolumn{1}{|c|}{} & \multicolumn{3}{c|}{\textbf{Initial Endowment}} \\ \hline
% \rowcolor{gray!20}\textbf{Condition} & \$20 & \$50 & \$80 \\ \hline
% Equal & 39\% & 48\% & 63\% \\ \hline
% Varied & 35\% & 42\% & 44\% \\ \hline
% p-value & 0.86 & 0.58 & 0.23 \\ \hline
% t-stat & 0.18 & -0.56 & 1.25 \\ \hline
% \end{tabular}
% \caption{\color{red}IK THIS TABLE MAKES NO SENSE\color{black}}
% \label{variedend}
% \end{table}

T-tests shows that there is no statistically significant difference at the p < 0.1 between the contributions of LLM agents endowed with \$20 in the equal and varied endowment condition (\(t = -9.42, p = 0.678 \)), nor for the \$50 (\(t = -0.56, p = 0.58 \)) endowment - both results mirroring those of human subjects. However, a t-test shows that the difference between the contributions of LLM agents endowed with \$80 is statistically significant at the p < 0.1 level (\(t = -1.94, p = 0.065 \)). A one-tailed t-test specifically shows that the contribution of LLM-agents endowed with \$80 is significantly greater in the equal condition than in the varied condition (\(t = 2.05, p = 0.026 \)) at the p < 0.05 level. \color{black} \textbf{From these results, we conclude that varying endowments in the PGG with LLM agents replicates the effect of doing the same on humans.}

% \color{orange}
% % From these results, we cannot fully conclude that LLM agents are affected by varying endowments in the same way as humans. However, the lack of difference between the average contribution in the equal and varied condition with endowments of \$20 and \$50 along with the difference between the averages in the equal and varied endowment conditions does suggest that varying endowments does have an impact similar to the effect observed in humans. The lack of statistical significance could be a result of the limited and unequal number of data points in both groups of comparison (for every endowment amount, there are 15 contributions in the equal endowment condition compared  to only 5 contributions in the varied endowment condition in our simulations).

% % REDO THIS AS - COMPARE THE HUMAN EQUAL WITH LLM EQUAL, COMPARE THE HUMAN VARIED WITH LLM VARIED
% \color{black}

\section{Study 2: Testing Multi-Agent Systems Ability to Transfer Effects from non-PGG Lab Experiments to Simulations of the PGG}

% \color{red}We choose papers still in experimental psychology/economics, but NOT THE WORD PGG. This is about if we use different key words, does it still work. NEED TO DO REWRITE RQ2 to reflect this.\color{black}

% The second study aims to answer the following research question:


% \begin{itemize}[itemindent=0em]

%   \item[\underline{\textbf{RQ2.}}] Can multi-agent LLM system simulations transfer effects observed in non-PGG lab experiments to simulations of the PGG?
%   \begin{itemize}
%     \item[\underline{a.}] Does priming LLM agents with sentences known to increase/decrease generosity in humans have that effect in simulations of the PGG?
% \item[\underline{b.}] Does the effect of priming LLM agents via game name in multi-round PGGs fade over time, like priming has been observed to fade over time in other experiments with human subjects?
% \end{itemize}
% \end{itemize}

% \begin{itemize}[itemindent=0em]

%   \item[\underline{\textbf{RQ2}}] Can multi-agent LLM system simulations transfer effects observed in non-PGG lab experiments to simulations of the PGG?
% \begin{itemize}[leftmargin=0.25in]
%     % \item[\underline{a.}] Does priming LLM agents with sentences known to increase/decrease generosity in humans have that effect in simulations of the PGG?
%     \item[\underline{a.}] Does priming LLM agents with a methodology used in non-PGG cooperation game lab experiments have the expected result in LLM simulations of the PGG?
%     % \color{red}Priming methodology\color{black}
% % \item[\underline{b.}] Does the effect of priming LLM agents via game name in multi-round PGGs fade over time, like priming has been observed to fade over time in other experiments with human subjects?\color{red}priming over time\color{black}
% \item[\underline{b.}] Does the effect of priming over time, observed to fade in non-PGG competition game lab experiments, hold in LLM simulations of the PGG?
% \end{itemize}
% \end{itemize}

To test whether LLMs can actually simulate human-like behavior and are not just parroting previously published lab experiments, we design two further experiments. These experiments take effects from lab experiments not containing the key word "public goods game." We then measure if LLMs are able to produce the expected outcomes in simulations of the PGG. We run two experiments; the first applies positive and negative priming methods used in other cooperation games, to assess if LLMs can generalize these effects to the PGG. The second tests priming effects from a one-shot PGG lab experiment, but over multiple rounds, incorporating the observed changes in priming effects over time from competition games. This approach confirms that the results in Study 1 were not simply due to LLMs parroting the results from a single lab experiment - it demonstrates that LLMs can integrate information from multiple various sources to simulate human-like behavior. 

% \begin{itemize}
%     \item[1.]
% \end{itemize}

% \color{red}TO REWRITE BIG PICTURE IS BREAK UP THE FIRST AND LAST SENTENCES, MAYBE BULLET POINTS FOR THE MIDDLE ONE: Particularly, studies on other games show that the effects of priming fade over time. MA-LLM simulations of multi-round PGG simulartions, also show priming effects diminishing over tiem, which is consistent with expected behavior, but not explicitly shown in any study of the PGG.  USE THIS TO REWRITE THIS: To test whether LLMs can actually simulate human-like behavior in simulation and are not just parroting previously published single papers, we design two further experiments which take effects from lab experiments not containing the key word "public goods game" and measure whether LLMs are able to produce the expected outcomes in simulations of the PGG. We run two experiments: (1) tests the effects of positive and negative priming, but with a priming methodology used in lab experiments of other cooperation games and (2) tests the effects of a positive and negative priming used in a lab experiment of the one-shot PGG, but over multiple rounds by using an observed change in priming effect over time from lab experiments with a competition game. By doing so, we confirm that the results in Study 1 were not merely due to LLMs parroting the lab experiment from which the effects were derived from and demonstrate that LLMs are able to obtain information from multiple sources to simulate expected human-like behavior.\color{black}

\color{purple}

% \subsection{LLM-Agent Simulation Setup for COMBINATIONS}

% The setup for these experiments is nearly identical to that of Study 1 - simulating the PGG still requires: (1) people, (2) rooms, and (3) game play instructions. The simulation still involves two types of people: one moderator and multiple players (specifically, 4). The simulation requires the same two rooms: (1) a moderation room and (2) a game room. Players are given the same instructions as in Study 1 for the first experiment; the second involves multiple rounds, so players are given slightly modified instructions to repeat their actions multiple times.

% The implementation of these experiments is also very similar to that of Study 1. We use the same architecture as in Study 1. The moderator agent is defined the same as in Study 1 for experiment 1; for experiment 2, the moderator agent has an additional instruction to continue the instructions to listen to contributions and announce payoffs for multiple rounds. Player agents are defined the same as in Study 1 for experiment 1 as well; for experiment 2, player agents are similarly given an additional instruction to make multiple contributions over multiple rounds of the PGG.

% We collect data via the outputs of the architecture in the same process as Study 1. The thoughts and actions of each player agent (and the moderator agent) are displayed in separate output logs, from which we extract the information necessary for our results. 

\color{black}

\subsection{Methodology}

% To test whether LLMs can \color{red} CAN ACTUALLY SIM ULATE HUMAN BEHAVIOR AND IS NOT JUST PARROTING PAPERS DIRECTLY\color{black}\sout{replicate the effects from combining lab experiments, we design two experiments which combine the effects from two lab experiments and check if results are reasonably representative of the combined effect. }\color{red}WE DO THIS TO TEST WHETHER THE PREVIOUS EXPERIMENTS WERE JUST GPT PARROTING SINGLE PAPERS. THIS IS A PROBLEM, SO WE WANT TO TAKE IT A STEP FURTHER AND SEE IF THE RESULTS STILL STAND IF YOU'RE NOT JUST LIFTING IT FROM A PAPER. SO WE DO THIS THING: (1) SAME BASIC TEST, BUT WITH DIFFERENT KEY WORDS and (2) KEY WORD SURE AND DIMENSION/GAMEPLAYSETUP/SOMETHING, .... THIS IS A GOOD THING\color{black}The two experiments test the following: (1) using a priming methodology used in lab experiments in other cooperation games and checking if it affects LLM-agent contributions as expected and (2) measuring the impact of the game name priming over time, using results from an experiment of a multi-round competition game with primed participants.

% We design two experiments based on a combination of treatments and effects from multiple lab experiments with human subjects. The first takes a priming methodology and effect from experiments with human subjects of different cooperative games than the PGG to see if the effect holds for the PGG. The second uses a priming methodology used on the one-shot PGG and measures if it has the same effect over multiple rounds similar to the way in which priming affects competition economic games. The treatments and effects in the combined experiments we design are listed in Table ~\ref{combinedexperiments}.

% \begin{center}
% \begin{table}[H]
% \setlength{\abovecaptionskip}{0pt}
% \setlength{\belowcaptionskip}{10pt}
% \begin{tabular}{|>{\columncolor{gray!20}\centering\arraybackslash}m{0.5cm}|p{6cm}|p{6cm}|} 
%  \hline
%  \rowcolor{gray!20} \textbf{Exp.} & \multicolumn{1}{c|}{\textbf{Treatment}} & \multicolumn{1}{c|}{\textbf{Expected Result}} \\ [0.5ex] 
%  \hline\hline
%  \textbf{1} & \textbf{Priming via Sentences:} Participants are presented with 5 sentences alluding to either "unity" or "proportionality" concepts. & Participants presented with sentences alluding to "unity" should contribute more than participants primed with "proportionality". \cite{6d947858-4a17-3462-9053-fc55b58ffee1, moralsmatter} \\ 
%  \hline
%  \textbf{2} & \textbf{Priming via Game Name over Multiple Rounds:} Participants are presented the PGG as a game called either the "Taxation Game" or "Teamwork Game" and play for five rounds. & The effect of priming should fade over time; although there should still be a disparity between participants in either group's initial contributions, it should lessen over time. \cite{Eriksson_Strimling_2014, JIMENEZJIMENEZ201594} \\
%  \hline
% \end{tabular}
% \caption{\label{combinedexperiments}Table of treatments and expected results (effects) from combining previous lab experiments with human subjects. Actual experiments that are drawn from are cited in the second column.}
% \end{table}
% \end{center}

\subsubsection{Experiment \#1} The first experiment uses a priming methodology used in a 2013 lab experiment of a modified solidarity game with 75 participants published in \textit{Plos One} \cite{moralsmatter}. The solidarity game is another cooperative economics game, but the priming methodology used \color{black} has not been tested on the PGG in prior lab experiments to our knowledge. Positive priming has shown to induce generosity in the PGG and other cooperative games, so we test whether LLMs are able to replicate the effects of a positive priming methodology used in a non-PGG lab experiment in simulations of the PGG. The positive priming involves showing participants three sentences alluding to "unity" ('\textit{we are family},' '\textit{mine is also yours},' and '\textit{caring for each other}'), while the negative priming involves showing participants three sentences alluding to "proportionality" ('\textit{how are you useful for me},' '\textit{I want to profit},' and '\textit{making a deal}'). The results of the lab experiment find that people in the positive priming condition displayed more generosity than people in the negative priming condition in the solidarity game. Thus, the positive priming increased prosocial behavior, meaning that it should increase contributions in the PGG as well.

% \subsubsection{Experiment \#1} The first experiment uses a priming methodology used for other \color{red} X OTHER GAMES, SUCH AS BLANK, BUT NOT THE PGG. TO OUR KNOWLEDGE, NOBODY HAS DONE THIS FOR THE PGG. Positive priming has been shown to work for the PGG and other games. Here we are testing if we can replicate the effect of a positive priming \color{black}contribution games: a positive priming which involves showing participants three sentences alluding to "unity" ('\textit{we are family},' '\textit{mine is also yours},' and '\textit{caring for each other}') and a negative priming which involves showing participants three sentences alluding to "proportionality" ('\textit{how are you useful for me},' '\textit{I want to profit},' and '\textit{making a deal}'). The results of the lab experiment find that people in the positive priming condition displayed more generosity than people in the negative priming condition in the solidarity game. \textbf{Thus, the positive priming increased prosocial behavior.}

We test whether this effect applies to LLM agents by simulating ten one-shot PGGs with four players, two under each priming condition, and all four with a \$20 endowment, and comparing the average contribution amount of players from either group. Specifically, we prime players by adding the three sentences to the player's private biography as something they have read (for example: "Alice read the following sentences prior to playing the game: '\textit{we are family},' '\textit{mine is also yours},' and '\textit{caring for each other}.'"). In the simulation, 1.6 times the amount of the public pool is split evenly amongst the players as their payoff - players are made aware of this to inform the way in which they act, but the simulation is of a one-shot PGGs.

\subsubsection{Experiment \# 2} The second experiment measures the effect of positive and negative priming over time (multiple rounds). Prior lab experiments of the one-shot PGG have shown that positive priming (by presenting the game as the "Teamwork Game") increases contributions while negative priming (by presenting the game as the "Taxation Game") decreases contributions \cite{Eriksson_Strimling_2014}\color{black}. Meanwhile, prior lab experiments of multi-round Bertrand competition games show that the effect of primings fades over time \cite{JIMENEZJIMENEZ201594}\color{black}. By combining these results, we expect that positive/negative priming should respectively increase/decrease the average contribution in the first round of the PPG, but should trend closer to half over multiple rounds. 

%Thus, we combine these results to expect that positive and negative priming should increase and decrease the average contribution in the first round of the PGG. However, contributions should trend closer to half of the endowment (the expected contribution without priming) over multiple rounds.

\color{black}

% \subsubsection{Experiment \#2} The second experiment measures the effect of priming over time. Results of a lab experiment of a competition game show that players take actions less influenced by various primings they are subject to in later rounds of the competition game than in the first round. \textbf{Thus, the effect of priming fades over time.}

% \color{red}PEOPLE HAVEN'T TRIED PRIMING WITH THE PGG OVER MULTIPLE ROUNDS (make sure this is true). SO WE TEST, DOES THE RESULT OF PRIMING FADING OVER TIME WHICH COMES FROM OTAHER EXPERIMENTS ALSO HOLD FOR THE PGG\color{black}

We test whether this effect applies to LLM-agents by simulating ten five-round PGGs with four players, two subject to a positive priming (the "Teamwork" priming discussed in Study 1, Experiment \#1) and two subject to a negative priming (the "Taxation" priming discussed in Study 1, Experiment \#1). We compare the average contribution in the first round for either priming condition with the average contribution in the last round for either priming condition. We also compare the initial contributions between priming conditions, checking that there was an initial disparity that ultimately begins to fade. In this experiment, payoffs are computed the same as in previous experiments (namely, 1.6 times the amount of the public pool split evenly amongst the players). Since there are multiple rounds, the payoff and amount not contributed are summed to determine each players endowment for the next round.

\subsection{Results}

% Towards answering this question, we simulate two experiments designed as a combination of multiple lab experiments with human subjects: \color{red}(1) takes a priming methodology and effect from experiments with human subjects of different cooperative games than the PGG to see if the effect holds for the PGG, and (2) uses a priming methodology used on the one-shot PGG and measures if it has the same effect over multiple rounds similar to the way in which priming affects different economic games than the PGG. \color{black} \textbf{From the results of these experiments, we conclude that multi-agent LLM system simulations do replicate behavior extrapolated from combining the behaviors observed in multiple lab experiments with human subjects.}

\subsubsection{Does priming LLM agents with a methodology used in non-PGG cooperation game lab experiments have the expected result in LLM simulations of the PGG?}

In experiments of other cooperation games, priming participants via sentences alluding to "unity" resulted in participants being more generous than participants primed via sentences alluding to "proportionality" \cite{moralsmatter}. In ten simulations, LLM agents primed with the sentences alluding to "unity" (Alice and Bob) contributed on average approximately 65\% of their initial endowment. In comparison, agents primed with the sentences alluding to "proportionality" (Casey and David) contributed on average only approximately 30\% of their endowment to the public pool. The results are summarized in Figure \ref{2Agraph}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{images/2A.png}
    \caption{Average contributions for either "unity" or "proportionality" priming conditions. Average contributions under the "unity" condition are significantly higher than that under the "proportionality" condition.}
    \Description{A bar chart titled "Average Contribution by Priming" compares average contributions under two priming conditions: "Unity" and "Proportionality." The y-axis represents average contributions as a percentage of endowment, ranging from 0 to 100\%. The x-axis lists the two priming conditions. The bar for "Unity" is significantly higher, showing contributions above 60\%, while the bar for "Proportionality" is much lower, below 40\%. This indicates that priming with a "Unity" condition leads to higher contributions compared to the "Proportionality" condition.}
    \label{2Agraph}
\end{figure}

% \color{red}FROM THESE RESULTS, THE PSYCHOLOGICAL MECHANISM DOES TRANSFER ACROSS PAPERS\color{black}

A t-test shows that the difference in contributions between the two groups is statistically significant at the p < 0.01 level (\(t = 8.76, p < 1\text{e}{-9} \)). \textbf{From these results, we conclude that the effects of priming on humans is transferred from papers not involving the PGG to simulations of the PGG with LLM-agents.}

% A t-test shows that the difference in contributions between the two groups is statistically significant at the p < 0.01 level (\(t = 8.76, p < 1\text{e}{-9} \)). \textbf{From these results, we conclude that priming LLM agents with sentences known to increase (or decrease) generosity in humans does result in higher (or lower) contributions in simulations of the PGG with LLM-agents.}

\subsubsection{Does the effect of priming over time, observed to fade in non-PGG competition game lab experiments, hold in LLM simulations of the PGG?}
\bigskip
In experiments of competition games with human subjects, the effect of priming has been found to fade over time \cite{JIMENEZJIMENEZ201594}. In ten simulations, LLM agents presented a five-round PGG as the "Teamwork Game" (Alice and Bob) on average contributed 75\% of their initial endowment in the first round, compared to 55\% of their initial endowment in the fifth round. In comparison, agents presented the PGG as the "Taxation Game" (Casey and David) contributed 30\% of their initial endowment in the first round, compared to 45\% of their initial endowment in the fifth round. Hence, for both priming conditions, the average contribution was closer to 50\% of the initial endowment in the fifth round than in the first, meaning the effect of the priming was less pronounced in the fifth round than the first. The results are summarized in Figure \ref{2Bgraph}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{images/2B.png}
    \caption{Average contributions in the all five rounds rounds for either "Teamwork" and "Taxation" priming conditions. Average contributions in the fifth round are closer to 50\% of the initial endowment, the average amount contributed without any priming \cite{labexperiments}. Hence, the effects of priming appears to fade over time in simulations with LLM-agents.}
    \Description{A line chart titled "Average Contribution by Priming and Round" shows how average contributions change over five rounds under two priming conditions: "Teamwork" and "Taxation." The y-axis represents average contributions as a percentage of the initial endowment, ranging from 0 to 100\%. The x-axis represents the round numbers (Round #1 to Round #5). The blue line represents contributions under the "Teamwork" priming condition, which starts high and gradually decreases over time. The black line represents contributions under the "Taxation" priming condition, which starts lower but increases slightly across rounds. By Round #5, contributions in both conditions converge closer to 50\%, suggesting that the effects of priming diminish over time in simulations with LLM-agents.}
    \label{2Bgraph}
\end{figure}

% \color{red}{FROM THESE RESULTS, SOMETHING TRANSFERS.... GPT DID NOT JUST PARROT A PAPER USING KEY WORDS. SOMEHOW IT WAS ABLE TO TRANSFER. SO GPT CAN TELL US MORE THAN WHAT PAPERS ALREADY KNOW}\color{black}

T-tests show that the difference in contribution amount between the rounds is statistically significant for the "Teamwork" priming condition at the p < 0.01 level (\(t = 4.32, p = 0.002 \)) and for the "Taxation" priming condition at the p < 0.05 level (\(t = -2.30, p = 0.047 \)). A t-test also shows that there is a statistically significant difference in the first round contributions of players in either priming condition (\(t = 9.64, p < 0.0000000001 \)). \textbf{From these results, we observe that the effect of priming LLM agents fades over time, concluding that LLMs are not just parroting past literature, but are able to transfer the multi-round effect observed in non-PGG lab experiments to simulations of the PGG.} The "Taxation" priming condition specifically suggests that the difference between first and fifth round contributions is not because contributions in PGGs with human subjects decrease over time \cite{labexperiments}, but rather that it is likely the consequence of a fading priming effect.

% T-tests show that the difference in contribution amount between the rounds is statistically significant for the "Teamwork" priming condition at the p < 0.01 level (\(t = 4.32, p = 0.002 \)) and for the "Taxation" priming condition at the p < 0.05 level (\(t = -2.30, p = 0.047 \)). A t-test also shows that there is a statistically significant difference in the first round contributions of players in either priming condition (\color{red}IN NEW YORK I MILLY ROCK\color{black}). \textbf{From these results, we conclude that the effect of priming LLM agents fades over time, as observed in experiments with human subjects.} The "Taxation" priming condition specifically suggests that the difference between first and fifth round contributions is not because contributions in PGGs with human subjects decrease over time \cite{labexperiments}, but rather likely the consequence of a fading priming effect.

\section{Study 3: Simulating "In-the-Wild" Scenarios}

% The third study aims to answer the following research question:

% \begin{itemize}[itemindent=0em]
%   \item[\underline{\textbf{RQ3}}] To what extent are multi-agent LLMs complex enough to simulate the rich set
% of unbounded options, actions, and interactions people do in the real world, outside of the lab?
% \begin{itemize}[leftmargin=0.25in]
%     % \item[\underline{a.}] Does priming LLM agents with sentences known to increase/decrease generosity in humans have that effect in simulations of the PGG?
%     \item[\underline{a.}] To see the complex
% interactions observed in the real world, what simulation mechanisms do we have to add to the set up of the system?
%     % \color{red}Priming methodology\color{black}
% % \item[\underline{b.}] Does the effect of priming LLM agents via game name in multi-round PGGs fade over time, like priming has been observed to fade over time in other experiments with human subjects?\color{red}priming over time\color{black}
% \end{itemize}
% \end{itemize}

This study aims to test whether LLM-agents can demonstrate realistic prosocial-related behavior in "in-the-wild" real-world situations. Real-world situations require a greater level of complexity in setup than lab experiments, as individuals do not have as explicit of instructions on when and how to act or speak. Furthermore, there is a lack of specific papers for LLMs to draw from to simulate human behavior in such open-ended settings. We test two specific real-world situations: (1) a classroom setting and (2) a grocery store parking lot setting. In a classroom, we have anecdotal evidence from university faculty that changing the harshness of late policies or adding perturbations to student lives have an effect on student behaviors. Specifically, we test whether the emergent behavior of cheating, a "bad" form of cooperation, occurs in simulation. In leaving a grocery store parking lot, shoppers may be affected by other factors in their lives that change how they act \cite{scientificamerican2020shoppingcarts}. Specifically, we test whether the emergent behavior of returning their shopping cart, a form of prosocial behavior, occurs in simulation. We test if we can see these emergent behaviors in a basic simulation setup, finding that in both scenarios our basic setup is insufficient to observe the desired behaviors. Hence, we add a mechanism in each to increase the complexity of the setup that guides LLM simulations to produce results closer to expected human behavior.

% \color{red}These are bad prosocial behaviors... add these sentences throughout\color{black}

% \color{red}REORDER THIS TO BE SCENARIO 1 - ALL INFORMATION, SCENARIO 2 - ALL INFORMATION\color{black}

% \color{red}THE GOAL OF STUDY 3 IS TO ..... SEE IF LLM-AGENTS DEMONSTRATE PLAUSIBLE BEHAVIOR IN REAL-WORLD SITUATIONS. We know simulations require a level of complexity in setup. We want to see if these things happen in basic simulation in response to harsh policies. And then if they don't, we want to figure out the mechanism that makes it happen. Classrooms are an environment that have policies like a late policy. It's hard to figure out what goes on. THere haven't been studies, but people anecdotally told us....  \color{black}

% \color{red} One of the problems is that we don't know how much setup is necessary to get the behaviors. BASIC IMPLEMENTATION: NO ROOMS. MORE COMPLICATED IMPLEMENTATION: THERE ARE THE ROOMS\color{black}

% We do this via simulating two \color{red} OR MAYBE THREE THREE \color{black} "in-the-wild" scenarios that are seen in the real world: a classroom \color{red}\sout{and} \color{black} a shopping-cart return setting, \color{red} and MAYBE a graffitti.\color{purple}


\subsection{Classroom Setting}

\subsubsection{Setup}

\paragraph{Classroom Simulation Setup}

Towards simulating the behaviors in a classroom setting, we first try basic simulation setup with only one location, but find that expected student behaviors (specifically, cheating) are not present. Hence, we add a mechanism to the simulation setup - locations for private communication - to enable students to communicate with one another without the teacher overhearing and discuss the things that real students may discuss in private.

To simulate the classroom setting, we identify two main necessary components for the basic setup: (1) people, (2) a location, and (3) homework assignment and submission instructions. The simulation involves two types of people: one professor and multiple students (specifically, 3). These are all represented by separate LLM-agents, all located in the same location. Students are given various personality traits (over-achiever, procrastinator, or values work-life-balance) and can be affected by two perturbations (having a midterm or a particularly challenging assignment). The professor is instructed to announce the late-policy and make assignment announcements at a regular interval. Students are instructed to listen to assignment announcements at the interval at which the professor announces them, and to "work" on the assignments in the meantime. Students are able to converse with the professor and other students, although only by addressing all at the same time.

For the more complicated setup, we introduce using locations as a mechanism for private communication. The simulation requires three locations: (1) a classroom, where assignments are announced, (2) an office, where the professor goes while students "work", and (3) a work room, where students "work." All students know these locations exist; the students can move between all of them, while the professor only moves between the classroom and office. The professor is instructed to announce the late-policy and make assignment announcements at a regular interval in the classroom, and to remain in the office otherwise. Students are instructed to listen to assignment announcements in the classroom at the interval at which the professor announces them, and then to be in the work room otherwise, with the option to move to the office to talk to or ask the professor questions.

% There are three main necessary components for simulating the classroom setting: (1) people, (2) rooms, and (3) homework assignment and submission instructions. The simulation involves two types of people: one professor and multiple students (specifically, 3). These are all represented by separate LLM-agents. The simulation requires three rooms: (1) a classroom, where assignments are announced, (2) an office, where the professor goes while students "work", and (3) a work room, where students "work." All agents know these rooms exist; the students can move between all of them, while the professor only moves between the classroom and office. Students are given various personality traits (over-achiever, procrastinator, or values work-life-balance) and can be affected by two perturbations (having a midterm or a particularly challenging assignment). The professor is instructed to announce the late-policy and make assignment announcements at a regular interval in the classroom, and to remain in the office otherwise. Students are instructed to listen to assignment announcements in the classroom at the interval at which the professor announces them, and then to be in the work room otherwise, with the option to move to the office to talk to or ask the professor questions.

\paragraph{Multi-Agent LLM Architecture Implementation}

We implement the simulation by adapting the same architecture as in the previous studies. When implementing the classroom setting in the multi-agent framework, we initialize it accordingly. In both setups, the professor agent's name is "Professor." The professor agent's public biography contains their late policy for assignments, as well as a general sentence indicating that they are the instructor for the course. The professor agent has no private biography. In the basic setup, the professor has an initial plan to announce their late policy and the first assignment's due date. The professor agent has instructions to answer student questions and to announce additional assignments at regular intervals (five total). The student agents are given arbitrary alphabetical names (Alice, Bob, and Casey). The student agents' public biographies contain their personality types, whereas their private biographies contain the perturbations as needed. Student agents are given an initial plan to listen to the late policy and first assignment announcement. Student agents have instructions to: (1) "work" on assignments, (2) listen to the professor's announcements of new assignments, and (3) state how many days late they will need to submit each assignment.

After adding separate office, work, and class rooms, we modify the instructions to each agent to utilize the ability to move between them appropriately. The professor agent has an initial plan to start in the classroom and announce their late policy and the first assignment's due date, then to move to the office. The professor agent has instructions to (1) answer student questions in the office, (2) move to the classroom at regular intervals to announce additional assignments, and (3) never enter the work room. Student agents are given an initial plan to listen to the late policy and first assignment announcement in the classroom. Student agents have instructions to: (1) work on assignments in the work room, (2) return to the classroom at regular intervals to hear announcements for new assignments, (3) state how many days late they will submit each assignment, and (4) use the office to talk to or ask questions to the professor. 

% The professor agent has an initial plan to start in the classroom and announce their late policy and the first assignment's due date, then to move to the office. The professor agent has instructions to answer student questions in the office, and to move to the classroom at regular intervals to announce additional assignments (five total). The student agents are given arbitrary alphabetical names (Alice, Bob, and Casey). The student agents' public biographies contain their personality types, whereas their private biographies contain the perturbations as needed. Student agents are given an initial plan to listen to the late policy and first assignment announcement in the classroom. Student agents have instructions to: (1) work on assignments in the work room, (2) return to the classroom at regular intervals to hear new assignments, (3) state how many days late they will need to submit each assignment, and (4) use the office to talk to or ask questions to the professor. 

\paragraph{Data Collection} As the simulation progresses, all of the thoughts and actions of each student agent (and the
professor agent) are displayed in separate output logs, each representing one of the agents involved in the simulation.
Each output log contains a plethora of information, ranging from the events each agents observed, their reactions to
them, and the creation of new plans, but we are only interested in tracking the specific behavior of cheating, which occurs by LLM-agents requesting to see and/or copy other's work. To collect data on the presence of this behaviors, we manually read through each student agent's output logs. A human manually recorded whether or not cheating was suggested and formatted this information into a table.

\subsubsection{Methodology}

We run simulations with three different late policies: (1) a lenient late policy (LLP) in which assignments turned in late are not given any penalty, (2) a medium late policy (MLP) in which assignments are docked 10\% for each late day, and (3) a harsh late policy (HLP) in which late assignments are not accepted. We also run simulations under three different perturbation conditions: (1) where students do not have any perturbations (P0), (2) where students have a midterm during the third assignment period (P1), and (3) where students have a midterm during the third assignment period and the second assignment is especially challenging (P2). We ran five simulations of each of the nine combinations of late policy and perturbation conditions (LLP-P0, LLP-P1, LLP-P2, MLP-P0, MLP-P1, MLP-P2, HLP-P0, HLP-P1, and HLP-P2) under two conditions: with or without locations. In each simulation, we recorded if any student proposed cheating at any point.

\subsubsection{Results}

In simulations with only one room, we found that students never suggested cheating, likely due to the professor always being in the same room as them. However, the introduction of locations changed this. In the lenient late policy condition, students still never suggested cheating, regardless of perturbations. In the medium late policy, students never suggested cheating in the no perturbation condition, but did so in one simulation in each of the one perturbation and two perturbation conditions. In the harsh late policy, students suggested cheating in all three perturbation conditions: students suggested cheating at an equal frequency in the no perturbation and one perturbation conditions, and the most in the two perturbation condition. The results are presented in Figure ~\ref{3Agraph}. \textbf{From these results, we conclude that locations can be used a mechanism for private communication to observe emergent behaviors such as cheating (a "bad" form of cooperation), which can only occur if students are able to converse without the professor overhearing.}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.75\textwidth]{images/3A.png}  % Change this value to make the figure larger
%     \caption{Percentage of simulations in which cheating was observed under the 9 late policy and perturbation conditions, for simulations with and without multiple locations. Without multiple locations, cheating is never observed. With multiple locations, cheating first begins to be observed under the medium late policy under the one perturbation condition. The number of simulations in which cheating occurs is the same for the medium late policy in the two perturbation condition, as well as for the harsh late policy under the no perturbation and one perturbation conditions. The number of simulations in which cheating occurs is greatest with the harsh late policy under the two perturbation condition.}
%     \label{3Agraph}
% \end{figure}

\begin{figure*}[t]  % Use figure* for spanning across both columns
    \centering
    \includegraphics[width=\textwidth]{images/3A.png}  % Scale the figure to the full page width
    \caption{Percentage of simulations in which cheating was observed under the 9 late policy and perturbation conditions, for simulations with and without multiple locations. Without multiple locations, cheating is never observed. With multiple locations, cheating first begins to be observed under the medium late policy under the one perturbation condition. The number of simulations in which cheating occurs is the same for the medium late policy in the two perturbation condition, as well as for the harsh late policy under the no perturbation and one perturbation conditions. The number of simulations in which cheating occurs is greatest with the harsh late policy under the two perturbation condition.}
    \Description{A bar chart titled "\% of Simulations with Cheating by Classroom Conditions and With or Without Rooms" illustrates the percentage of simulations in which cheating was observed under different classroom conditions. The y-axis represents the percentage of simulations with cheating, ranging from 0\% to 70\%. The x-axis represents three classroom conditions: LLP (Low Late Policy), MLP (Medium Late Policy), and HLP (Harsh Late Policy), each divided into three perturbation conditions (P0, P1, P2). Two sets of bars are shown for each condition: dark gray for "Without Rooms" and light gray for "With Rooms." Results indicate that cheating is not observed under LLP regardless of perturbation conditions. Under MLP, cheating emerges in P1 and P2, with slightly higher occurrences when multiple locations (rooms) are present. Under HLP, cheating is observed across all perturbation conditions and increases sharply in P2, particularly when multiple locations are involved, reaching the highest cheating percentage in the entire dataset.}
    \label{3Agraph}
\end{figure*}



\subsection{Shopping-Cart Return Setting}

\subsubsection{Setup}

\paragraph{Shopping-Cart Return Simulation Setup}

There are three main necessary components for simulating the shopping-cart return setting: (1) people, (2) locations, and (3) instructions on what to act on. The simulation involves one person, a shopper, who is preparing to leave the parking lot and represented by a LLM-agent. The simulation requires two locations: (1) the area where the shopper has parked, and (2) the receptacle, where carts \textit{should} be returned. The shopper agent knows these locations exist, and can decide whether or not to move between them. The shopper agent can be affected by conditions that affect their ability to return their cart (being far from the receptacle or having a child with them) \cite{scientificamerican2020shoppingcarts}. The shopper is told to prepare to leave the parking lot and instructed that they cannot leave with their shopping cart - the shopper hence must decide \textit{something} to do with their shopping cart.

\paragraph{Multi-Agent LLM Architecture Implementation} We implement the simulation by adapting the same architecture as in the previous studies. When implementing the shopping-cart return setting in the multi-agent framework, we initialize it accordingly. The shopper agent is given the name "Shopper." The shopper agent has a blank public biography. The shopper agent's private biography states that they have a cart, and conditions that affect their ability to return their cart. The shopper agent has an initial plan to prepare to leave the parking lot, then instructions to act on the outcomes of their initial plan. We create two locations: (1) which represents the area where the shopper has parked and (2) the designated shopping-cart return receptacle. This way, we capture that LLM-agents must move in order to return their shopping cart.

However, we find that simply stating the condition affecting the shopper's ability to return their cart ("you are far from the receptacle," and "you have a child") is insufficient to have the desired effect of shoppers returning their carts less frequently; the prompt must allude towards what is at stake ("you are \textit{parked across the parking lot} from the receptacle," and "you have a \textit{five-month old} child"). In the condition where shoppers are far from the receptacle, adding that shoppers are "\textit{parked across the parking lot}" alludes to the fact that going to receptacle will take effort, whereas adding that the child is an infant alludes to the fact that the child cannot be left unattended. We present this as stake-prompting (SP), a mechanism to have prompts allude to what is at stake, using which LLM-agents can be guided towards demonstrating more human-like behavior in simulation.

\paragraph{Data Collection} As the simulation progresses, all of the thoughts and actions of the shopper agent are displayed in an output log. The output log contains a plethora of information, ranging from the events the agent observed (which is minimal in this simulation), their reactions to them (similarly minimal), and the creation of new plans. But we are only interested in recording whether or not the shopper agent returns their cart, based on whether the shopper agent moves to the receptacle location. A human manually recorded this information and formatted it into a table.

\subsubsection{Methodology} We run simulations with two different conditions that shoppers can be affected by: (1) being far from the receptacle (FFR) and (2) having a child (HAC). We run five simulations each of either condition under with and without stake-prompting. Given that the condition affecting the shopper should influence them to not return their shopping cart, we track whether or not the shopping cart is returned in each simulation and then compare the frequency of returns between simulations with and without stake-prompting.

\subsubsection{Results} In simulations without stake-prompting, we find that shopper agents still frequently return their carts despite the conditions affecting their ability to do so. However, alluding to what is at stake as a result of the condition  causes shopper agents to stop returning their carts as often. The results are summarized in Figure \ref{3Bgraph}. \textbf{From these results, we conclude that alluding to what is at stake via stake-prompting causes LLM-agents to demonstrate less prosocial behavior when affected by personal conditions, like humans.}


\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{images/3B.png}
    \caption{Percentage of simulations in which the shopper agent decided to their shopping cart for both external conditions tested and under either prompting condition: with or without stake-prompting. LLM-Agents returned their cart less frequently with stake-prompting than without.}
    \Description{ bar chart titled "Effect of Stake-Prompting on Cart Return by Condition" illustrates the percentage of simulations in which a shopper agent returned their shopping cart under two conditions: FPR and HAC. The y-axis represents the percentage of simulations where the cart was returned, ranging from 0\% to 100\%. The x-axis lists the two conditions. Each condition has two bars: a gray bar for the "Without SP" (stake-prompting) condition and a yellow bar for the "With SP" condition. Results show that cart return rates are higher when no stake-prompting is applied, with significantly lower return percentages when stake-prompting is present. This pattern is consistent across both conditions, suggesting that LLM-agents return their carts less frequently when stake-prompting is introduced.}
    \label{3Bgraph}
\end{figure}

% \subsubsection{Methodology}

% \subsubsection{Classroom}

% We run simulations with three different late policies: (1) a lenient late policy (LLP) in which assignments turned in late are not given any penalty, (2) a medium late policy (MLP) in which assignments are docked 10\% for each late day, and (3) a harsh late policy (HLP) in which late assignments are not accepted. We also run simulations under three different perturbation conditions: (1) where students do not have any perturbations (P0), (2) where students have a midterm during the third assignment period (P1), and (3) where students have a midterm during the third assignment period and the second assignment is especially challenging (P2). We ran five simulations of each of the nine combinations of late policy and perturbation conditions (LLP-P0, LLP-P1, LLP-P2, MLP-P0, MLP-P1, MLP-P2, HLP-P0, HLP-P1, and HLP-P2) under two conditions: with or without locations. In each simulation, we recorded if any student proposed cheating at any point.

% \subsubsection{Shopping-Cart} We run simulations with two different conditions that shoppers can be affected by: (1) being far from the receptacle (FFR) and (2) having a child (HAC). We run five simulations each of either condition under with and without stake-prompting. Given that the condition affecting the shopper should influence them to not return their shopping cart, we track whether or not the shopping cart is returned in each simulation and then compare the frequency of returns between simulations with and without stake-prompting.

% five simulations of shopper agents for each condition and with or without \color{red}stake-prompting\color{black}, resulting in twenty simulations total.



% \subsubsection{g}

% \subsection{Results}

% \subsubsection{Classroom}

% In simulations with only one room, we found that students never suggested cheating, likely due to the professor always being in the same room as them. However, the introduction of locations changed this. In the lenient late policy condition, students still never suggested cheating, regardless of perturbations. In the medium late policy, students never suggested cheating in the no perturbation condition, but did so in one simulation in each of the one perturbation and two perturbation conditions. In the harsh late policy, students suggested cheating in all three perturbation conditions: students suggested cheating at an equal frequency in the no perturbation and one perturbation conditions, and the most in the two perturbation condition. The results are presented in Figure ~\ref{3Agraph}. \textbf{From these results, we conclude that locations can be used a mechanism for private communication to observe emergent behaviors such as cheating, which can only occur if students are able to converse without the professor overhearing.}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.75\textwidth]{images/3A.png}  % Change this value to make the figure larger
%     \caption{Percentage of simulations in which cheating was observed under the 9 late policy and perturbation conditions, for simulations with and without multiple locations. Without multiple locations, cheating is never observed. With multiple locations, cheating first begins to be observed under the medium late policy under the one perturbation condition. The number of simulations in which cheating occurs is the same for the medium late policy in the two perturbation condition, as well as for the harsh late policy under the no perturbation and one perturbation conditions. The number of simulations in which cheating occurs is greatest with the harsh late policy under the two perturbation condition.}
%     \label{3Agraph}
% \end{figure}

% However, we find that in this simulation setup, behaviors that students would display with one another without the professor's presence are not present in simulation. In addition, having all questions directed to the professor being overheard by all students distracts students to which the information is not relevant to.

% \color{red}Anecdotally, we also saw behaviors where students proposed simple collaboration (working together) and students communicated with the professor\color{black}

% \color{red}In preliminary simulations with one room, we found that students did not suggest cheating, likely due to the professor being in the same room as them. We thus introduced rooms and recorded results. The results of the number of simulations in which students (1) proposed collaboration, (2) proposed cheating, and (3) communicated with the professor are in Figure ~\ref{3Agraph}.\color{purple}

% \textbf{Collaboration.} Across the lenient and medium late policy conditions, adding perturbations to student lives generally increased the frequency in which students proposed collaboration. In the harsh late policy condition, students proposed collaboration in all simulations, regardless of perturbations. 

% \textbf{Cheating.} \color{red}In preliminary simulations without rooms, the behavior of cheating was never observed. This changed after the introduction of rooms. \color{purple} In the lenient late policy condition, students never suggested cheating, regardless of perturbations. In the medium late policy conditions, students never suggested cheating in the no perturbation condition, but did so in one simulation in each of the one perturbation and two perturbation conditions. In the harsh late policy, students suggested cheating in all three perturbation conditions: students suggested cheating at an equal frequency in the no perturbation and one perturbation conditions, and the most in the two perturbation condition. 

% % \textbf{Communication with the Professor} In the lenient late policy condition, students communicated the most with the professor in the condition with two perturbations. However, students communicated with the professor slightly less in condition with one perturbation than in the condition with no perturbation. In the medium late policy condition, students communicated with the professor an equal amount in the no perturbation and one perturbation conditions, and more frequently in the two perturbation condition. In the harsh late policy condition, students communicated with the professor in all simulations regardless of perturbations, similar to the results observed for collaboration.

% % \begin{figure}[h]
% %     \centering
% %     \includegraphics[width=0.75\textwidth]{images/3A.png}  % Change this value to make the figure larger
% %     \caption{Percentage of simulations in which the specified behavior was observed for all 9 simulation conditions.}
% %     \label{3Agraph}
% % \end{figure}

% % The results of the number of simulations in which students (1) proposed collaboration, (2) proposed cheating, and (3) communicated with the professor are in Figure ~\ref{3Agraph}. \color{red}\textbf{From these results, we conclude that SOMEATHING ABOUT ROOMS .... LLM agents collaborate more with harder late policy/perturbations.... and cheat less frequently than they collaborate but also cheat more with harder late policy/perturbations }\color{purple}


% % \color{red} \sout{We find that: (1) rooms enabled private communication which LLM-agents used to propose cheating, and (2) LLM-agents seemed to reasonably respond to changes in late policy and perturbations.}\color{black}

% \subsubsection{Shopping-Cart Return}

% In simulations without stake-prompting, we find that shopper agents still frequently return their carts despite the conditions affecting their ability to do so. However, alluding to what is at stake as a result of the condition  causes shopper agents to stop returning their carts as often. The results are summarized in Figure \ref{3Bgraph}. \textbf{From these results, we conclude that alluding to what is at stake via stake-prompting causes LLM-agents to be affected by external conditions more like humans than without doing so.}


% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.75\textwidth]{images/3B.png}
%     \caption{Percentage of simulations in which the shopper agent decided to their shopping cart for both external conditions tested and under either prompting condition: with or without stake-prompting. LLM-Agents returned their cart less frequently with stake-prompting than without.}
%     \label{3Bgraph}
% \end{figure}

% % \subsubsection{g}
% % hadhda

% \bigskip
% \bigskip

% \color{red}We use two real-world settings as case studies to identify mechanisms needed to enable informative simulations. For these case studies, we run several simulations with slightly varying conditions to generally understand the ways in which agents act, and then use that to create a mechanism which enables a behavior we identify as missing from a combination of general knowledge and informative studies.

% The first is a classroom setting, where we specifically focus the impact of various late policies (no penalty, full penalty, and penalty by days late) on student communicative and collaborative behaviors. We define a professor agent (named the Professor) and three student agents with arbitrary names (Alice, Bob, and Casey). The professor agent is given instructions to announce a late policy to the class, and then begin assigning assignments. In student agents public biography, they are given one of three "personalities" - an overachiever, a hard-worker, and a balanced individual. In the private biographies of the agents, we add various perturbations to student lives that would reasonably affect their ability to turn in assignments on time, such as having a midterm in another class, having special difficulty with a particular assignment, or having a busy week in general. We do not need to implement a rigid turn-taking guideline, however we do generally add a framework within which agents act - the professor agent announces assignments on a fixed frequency in the classroom, between which student agents "work" on assignments and consider how many days late they will need to submit it based on the other factors in their lives.

% Second, we simulate shoppers in a parking lot who can either return or not return their shopping cart. In each simulation, we define one shopper. We add various perturbations to the shopper life that affect their ability to return their shopping cart \cite{scientificamerican2020shoppingcarts} in their private biography. The shopper agent by default has blank public biographies; but if perturbations added to the shopper's private biography would reasonably be extrapolated other people in real life (such as having a child), we also include it in the shopper's public biography. The shopper agent are not given directives, but have an initial plan to decide whether or not to return their shopping cart, and then to act on it. \color{black}

% \subsubsection{\color{red}Evaluation \& Results for RQ3\color{black}}

% \color{red}

% \begin{itemize}
% \item[1.] Classroom with Late Policies
% \begin{itemize}
% \item We simulate a classroom setting, where students have 5 assignments to submit over the course of a semester.
% \item We try varying late-assignment policies (lenient - all late assignments accepted, harsh - late assignments not accepted, medium - 20\% grade penalty for each late day). 
% \item We add perturbations to student lives that reasonably would affect their ability to turn in assignments on time: (1) having a midterm and (2) a particular assignment being especially challenging.
% \item We also give students personality types: that of a procrastinator, an overachiever, and someone who "values work-life balance."
% \item We wanted to see if multi-agent LLM systems simulated reasonable interactions and dynamics within a classroom.
% \item We sought to examine how students would (1) work together and (2) communicate with one another and the teacher.
% \item In preliminary simulations with one room, a classroom, we found that student agents proposed working together to other student agents.
% \item \color{red}Generally, we saw that procrastinators would suggest collaboration most frequently.\color{purple}
% \item Student agents also would ask questions to the teacher that were both individual (ex. requesting a review) and for the group (ex. clarifying an assignment). 
% \item But everybody in the class would be distracted by them.
% \item Therefore, we added two rooms to the simulation environment to enable easier communication: the teacher's office, and a student work room.
% \item In simulations with the lenient late policy, communication was somewhat similar with or without the added rooms.
% \item Students did move into the work room to "work" as per their directives. 
% \item They also used the office to ask questions to the teacher.
% \item But students discussed working together in a similar way and at roughly the same frequency.
% \item This was true after adding perturbations too.
% \item In simulations with the medium late policy, the ways in which proposed collaboration changed once perturbations were added.
% \item As opposed to broadly discussing working together, student agents sometimes asked to see other agent's assignments to copy in the work room. 
% \item \color{red}Generally, we saw that procrastinators would suggest cheating most frequently.\color{purple}
% \item In simulations with the harsh late policy, we saw this behavior before even adding perturbations.
% \item \color{red}This makes sense, because students have been found to be more likely to cheat on exams if they have strict teachers.\color{purple}
% \item We ran simulations under the lenient (LLP), harsh (HLP), and medium late policies (MLP).
% \item We ran simulations under three perturbation conditions: (P0) without any, (P1) students having a midterm during the 3rd assignment, and (P2) students having the midterm AND the 2nd assignment being especially challenging.
% \item We ran five simulations of each combination of late policy and perturbation (LLP-P0, LLP-P1, LLP-P2, HLP-P0, HLP-P1, HLP-P2, MLP-0, MLP-1, and MLP-2), or 45 simulations total.
% \item We recorded if students (1) proposed collaboration, (2) proposed a form of cheating, and (3) communicated with the teacher.
% \item \color{red}We did not record which student initiated each of the types of actions. We also did not record at which assignment it occurred.\color{purple}
% \item The results are summarized in Table \ref{teachingsims} and Figure \ref{3Agraph}.
% \item{\begin{center}
% \begin{table}[H]
% \setlength{\abovecaptionskip}{0pt}
% \setlength{\belowcaptionskip}{10pt}
% \begin{tabular}{|>{\columncolor{gray!20}\centering\arraybackslash}m{2cm}|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|} 
%  \hline
%  \rowcolor{gray!20} \textbf{Condition} & \textbf{Collaboration} & \textbf{Cheating} & \textbf{Communication with Teacher} \\ 
%  \hline\hline
%  \textbf{LLP-P0} & 40\% & 0\% & 60\% \\ 
%  \hline
%  \textbf{LLP-P1} & 60\% & 0\% & 40\% \\ 
%  \hline
%  \textbf{LLP-P2} & 60\% & 0\% & 80\% \\ 
%  \hline
%  \textbf{MLP-P0} & 60\% & 0\% & 80\% \\ 
%  \hline
%  \textbf{MLP-P1} & 80\% & 20\% & 80\% \\ 
%  \hline
%  \textbf{MLP-P2} & 100\% & 20\% & 100\% \\ 
%  \hline
%  \textbf{HLP-P0} & 100\% & 20\% & 100\% \\ 
%  \hline
%  \textbf{HLP-P1} & 100\% & 20\% & 100\% \\ 
%  \hline
%  \textbf{HLP-P2} & 100\% & 60\% & 100\% \\ 
%  \hline
% \end{tabular}
% \caption{\label{teachingsims}Percentage of simulations in which the specified behavior was observed for all 9 simulation conditions.}
% \end{table}
% \end{center}
% }
% \item{\begin{figure}[h]
%     \centering
%     \includegraphics[width=0.75\textwidth]{images/3A.png}  % Change this value to make the figure larger
%     \caption{Percentage of simulations in which the specified behavior was observed for all 9 simulation conditions.}
%     \label{blah}
% \end{figure}}
% \item \color{red} We find that: (1) rooms enabled private communication which LLM-agents used to propose cheating, and (2) LLM-agents seemed to reasonably respond to changes in late policy and perturbations.
% \end{itemize}
% \end{itemize}

% \begin{itemize}
% \item[2.] Shopping-Cart Return
% \begin{itemize}
% \item We simulate a store parking lot, where there are specific shopping-cart return locations.
% \item Each simulation has one agent with a plan to decide whether or not to return their shopping cart.
% \item We try two perturbations that might contribute to someone not returning their cart: (1) being far from the receptacle (FFR), and (2) having a child whom should not be left unattended (HAC). \cite{scientificamerican2020shoppingcarts}
% \item We have two rooms: the shopper agents car and the receptacle.
% \item We find that despite the perturbations, shopper agents arill frequently return their carts if it the perturbation is merely stated ("you are far from the receptacle," and "you have a child")
% \item However, alluding to what is at stake as a result of the perturbation starts causing shopper agents to stop returning their carts as often ("you are \textit{parked across the parking lot} from the receptacle," and "you have a \textit{five-month old} child").
% \item We present this as \color{red}stake-prompting (SP), a way in which to guide LLM-agents towards acting more in-line with humans.\color{purple}
% \item We ran five simulations of either perturbation (FFR and HAC) with and without prompts alluding to what is at stake, or 20 simulations total.
% \item The results are summarized in Table ~\ref{shoppingcartsims} and Figure \ref{3Bgraph}.
% \item{\begin{center}
% \begin{table}[H]
% \setlength{\abovecaptionskip}{0pt}
% \setlength{\belowcaptionskip}{10pt}
% \begin{tabular}{|>{\columncolor{gray!20}\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|>{\centering\arraybackslash}m{3cm}|} 
%  \hline
%  \rowcolor{gray!20} \textbf{Perturbation} & \textbf{Without SP} & \textbf{With SP} \\ 
%  \hline\hline
%  \textbf{FRB} & 100\% & 40\% \\ 
%  \hline
%  \textbf{HAC} & 60\% & 20\% \\ 
%  \hline
% \end{tabular}
% \caption{Percentage of simulations in which the shopper agent decided to their shopping cart for both perturbations tested and under either prompting condition.}
% \label{shoppingcartsims}
% \end{table}
% \end{center}
% }
% \item{\begin{figure}[h]
%     \centering
%     \includegraphics[width=0.75\textwidth]{images/3B.png}
%     \caption{Percentage of simulations in which the shopper agent decided to their shopping cart for both perturbations tested and under either prompting condition.}
%     \label{3Bgraph}
% \end{figure}}
% \item We find that alluding to what is at stake caused LLM-agents to be more \color{red} affected by perturbations more like people\color{black}.
% \end{itemize}
% \end{itemize}

% \begin{itemize}
% \item[3.] Graffiti \& Littering
% \begin{itemize}
% \item Finally, we simulate two scenarios: (1) a bike-parking station, where a piece of paper is left on the handlebars. people must choose whether or not to litter - there is a no littering sign but no trash can. there is either grafitti on the wall or not, people more likely to litter when there is graffitti. (2) a envelope with cash visible hanging outside of a mailbox. the mail box either has graffiti on it or not.
% \item \color{red}LLM-simulations show .... WIP .... but looks like first sort of should be true, second one looks unlikely but is interesting they won't steal?\color{black}
% \item IDEALLY WOULD BE: WE TRIED X AND IT DID NOT WORK... ADDING Y GOT US CLOSER TO REPLICATING
% \end{itemize}
% \end{itemize}
% \bigskip\bigskip

% \color{red}

% \begin{itemize}
%     \item setup: bike rack location. there is a no littering sign. the wall either has graffiti or not. there is no trash can. there is some trash on the persons bike. in experiments with humans, people litter more often when there is graffiti
%     \item Graffiti on the wall and the no littering sign are set via the location
%     \item we also have to explicitly say, there is no trash can in the location
%     \item we indicate that there is trash on the agents bike via the public biography
%     \item initial plan: take your bike from the station
%     \item so agents are forced to figure out what to do with the trash that is on the bike
%     \item this works, in that LLM-agents do recognize that they need to do something with the trash
%     \item if they start thinking OH LET ME FIND A NEARBY TRASH CAN IN ANOTHER AREA / TAKE THE TRASH WITH THEM, then we say ok they did not litter
%     \item if they simply said I AM GOING TO REMOVE THIS TRASH / DROP THIS TRASH / LITTER etc. we count that as littering
%     \item but im not sure if the impact of the graffiti condition is correctly shown: In 10 simulations, without grafitti, LLMs litter twice. in ten with grafitti, LLMs litter three times. so i guess technically it is higher. but im not really sure if this is telling us anything conclusively
%     \item could write yeah it sort of works but is that even worth the changes we'd have to make elsewhere? if so I can definitely write these sections tonight
% \end{itemize}

% \color{black}