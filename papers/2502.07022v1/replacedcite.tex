\section{Related Works}
\label{sec:relworks}


\textbf{AI for analyzing supply chain disclosures under the California Transparency Act.} A few initiatives have considered machine learning to analyze statements in response to modern slavery legislation in the literature. For instance, LegalBench ____ proposed a benchmark for evaluating legal reasoning capabilities in language models. It consists of 162 tasks crafted by legal experts, and one of these is related to supply chain disclosures under the California Transparency in Supply Chains Act. The analysis of roughly 400 statements with one or two pages each using modern language models reveals only an accuracy of around 75\%. Similar to the high-level decision process used by analysts, the proposed classification approach for this task relies on statement-level decision making for a limited set of questions. The researchers discuss in their report how model performance diminishes in tasks involving longer text or more numerous questions, which suggests that scaling this statement-level decision making strategy to much larger statements is probably not ideal.

\textbf{AI for the analysis of UK modern slavery statements.} Despite numerous studies analyzing a handful of modern slavery statements manually (details in Appendix \ref{sec:appendix:relevant_works}), only a few have investigated the use of machine learning to date. For instance, modern slavery statements from the UK are analyzed without supervision using topic modeling ____. While this approach allows the authors to monitor disclosure trends and correlate them across different statements, it is unable to analyze each statement and differentiate vague claims and promises from substantive actions. Consequently, this approach cannot adequately verify compliance with respect to a specific legislation. Based on their analysis, the authors highlight that many companies ``anchor'' their disclosures in broader human rights language and that they emphasize their engagement in social causes in an effort to bolster their company's social reputation. This underlines the challenge of carefully avoiding distractions while assessing whether a statement contains mandated information.

UK modern slavery statements were also analyzed under an initiative of the Walk Free and of The Future Society organizations, resulting in an open-sourced project on GitHub ____ and a technical report ____. This initiative examined 16,000 statements and utilized approximately 2,400 annotated statements from WikiRate ____ for supervised machine learning experiments. In this work, classifiers were first trained to distinguish statements addressing specific mandatory content. These classifiers were then used to predict whether statements were correctly approved by a governing body based on annotator comments, keyword-based summaries, and n-gram representations. Limitations of this work noted by the authors include the difficulty in scaling to a large number of statements due to the usage of keyword-based and comment-based approaches, and due to the poor quality of the annotated statements. This previous research concluded that a stricter annotation process was necessary for developing new datasets and robust experimental protocols for subsequent studies. 
Moreover, as highlighted by other relevant studies on AI and sustainability reporting discussed in Appendix \ref{sec:appendix:relevant_works}, existing approaches continue to face difficulties in distinguishing concrete actions from vague text addressing relevant topics. Across these studies, many authors have emphasized challenges with training data quality and annotation biases. To the best of our knowledge, our paper now presents the largest annotated dataset globally, designed for machine learning research on modern slavery statements, while also marking the first academic study to scrutinize Australian modern slavery statements at scale, using machine learning techniques.