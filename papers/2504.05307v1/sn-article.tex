%Version 3 December 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove Numbered in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst%  
 
%%\documentclass[pdflatex,sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[pdflatex,sn-mathphys-num]{sn-jnl}% Math and Physical Sciences Numbered Reference Style 
%%\documentclass[pdflatex,sn-mathphys-ay]{sn-jnl}% Math and Physical Sciences Author Year Reference Style
%%\documentclass[pdflatex,sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[pdflatex,sn-vancouver,Numbered]{sn-jnl}% Vancouver Reference Style
%%\documentclass[pdflatex,sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[pdflatex,sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{tabularx}
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%% as per the requirement new theorem styles can be included as shown below
% \theoremstyle{thmstyleone}%
% \newtheorem{theorem}{Theorem}%  meant for continuous numbers
% %%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
% %% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
% \newtheorem{proposition}[theorem]{Proposition}% 
% %%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

% \theoremstyle{thmstyletwo}%
% \newtheorem{example}{Example}%
% \newtheorem{remark}{Remark}%

% \theoremstyle{thmstylethree}%
% \newtheorem{definition}{Definition}%

% \raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[Towards Total Recall]{Toward Total Recall: Enhancing FAIRness through AI-Driven Metadata Standardization}

%%=============================================================%%
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% \author*[1,2]{\fnm{Joergen W.} \spfx{van der} \sur{Ploeg} 
%%  \sfx{IV}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*{\fnm{Sowmya} \sur{S. Sundaram}}\email{sowmyasm@stanford.edu}

\author{\fnm{Mark} \sur{A. Musen}}\email{musen@stanford.edu}



\affil{\orgdiv{Stanford Center for Biomedical Informatics Research (BMIR)}, \orgname{Stanford University}, \state{California}, \country{USA}}


%%==================================%%
%% Sample for unstructured abstract %%
%%==================================%%

\abstract{Current metadata often suffer from incompleteness, inconsistency, and incorrect formatting, hindering effective data reuse and discovery. Using GPT-4 and a metadata knowledge base (CEDAR), we devised a method that standardizes metadata in scientific data sets, ensuring the adherence to community standards. The standardization process involves correcting and refining metadata entries to conform to established guidelines, significantly improving search performance and recall metrics. The investigation uses BioSample and GEO repositories to demonstrate the impact of these enhancements, showcasing how standardized metadata lead to better retrieval outcomes. The average recall improves significantly, rising from 17.65\% with the baseline raw datasets of BioSample and GEO to 62.87\% with our proposed metadata standardization pipeline. This finding highlights the transformative impact of integrating advanced AI models with structured metadata curation tools in achieving more effective and reliable data retrieval. }

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{metadata, FAIR, NLP}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section*{Introduction}\label{sec1}

% \begin{enumerate}
%     \item Data sharing needs FAIR standards
%     \item Making data FAIR gets better recall
%     \item What is metadata? Better metadata makes data FAIR
%     \item Making metadata better by hand is hard
%     \item Research into making metadata better automatically done by our lab and how this is different
%     \item Current experiment explores GPT-4 for making it better and records changes in recall
% \end{enumerate}

Effective data sharing can be improved by adhering to FAIR standards\cite{wilkinson2016fair}—ensuring data is Findable, Accessible, Interoperable, and Reusable. An important aspect of making data FAIR is high quality metadata\cite{musen2022without}, which refers to descriptive information about the data. Metadata play a pivotal role in organizing, categorizing, and enhancing the discoverability of data by including details such as keywords, formats, and contextual information about the data's origin, purpose, and usage. However, manually improving metadata quality is a complex and time-consuming process due to lack of consensus, variability in community standards, etc. To address this challenge of metadata quality, we propose an automated method for standardizing metadata. In this research endeavor, we investigate the use of Natural Language Processing (NLP) techniques for automated metadata correction and assess their impact on recall performance, a quantitative metric for data retrieval.

The focal point of our investigation is on improving the metadata, as high-quality metadata enhance the searchability of public datasets, ultimately benefiting scientific research (Figure~\ref{fig:big-picture}).

\begin{figure}[h!]
    \centering
    \fbox{
    \includegraphics[width=\textwidth]{big-picture.png}}
    \caption{The Big Picture}
    \label{fig:big-picture}
\end{figure}



Metadata comprise lists of field name–value pairs that may be augmented reporting guidelines. In Figure~\ref{fig:intro}—a snapshot of a record sourced from the BioSample repository of the National Center for Biotechnology Information (NCBI)\cite{barrett2012bioproject}—the black box highlights an example of metadata. In this example, the field name is tissue and the field value is lung cancer, which is inaccurate as lung cancer is not a type of tissue. Searches for scientific datasets primarily involve querying metadata. Consequently, a researcher querying for the name–value pair of tissue
would overlook this potentially valuable record during their search. As important as metadata are, current metadata are usually incomplete, inconsistent, and incorrectly formatted\cite{gonccalves2019variable}. Standardizing metadata is therefore a necessary process for ensuring that datasets are properly described and accessible, so that they they can be more easily reused and integrated with other datasets, thus facilitating secondary use and analysis of scientific data..

\begin{figure}[h!]
    \centering
    \fbox{
    \includegraphics[width=\textwidth]{example2.png}}
    \caption{Record from BioSample where the black box highlights a field name--value pair. In this example, the field name \textit{tissue} is wrongly associated with field value \textit{lung cancer}. Orange boxes mask identifying information}
    \label{fig:intro}
\end{figure}

% The process of metadata standardization involves processing the language used for specifying the name--value pairs.  To the best of our knowledge, there is a lack of concerted effort in this research area, which highlights the importance of our lab's consistent work in automated metadata standardization. In a previous attempt to use natural language processing (NLP) techniques for enhancing BioSample records\cite{gonccalves2019aligning}, our team employed traditional embeddings\footnote{Vectorial representations of words learned by training over text} like word2vec\cite{mikolov2013distributed} and GloVe\cite{pennington2014glove} to represent metadata terms. These embeddings are powerful tools for capturing semantic relationships among words. However, we faced significant scalability challenges because these embeddings were limited to terms present in the training set, thus neglecting the specialized and niche terms often encountered in medical and scientific data. To overcome these limitations, we extended our work by incorporating Generative Pre-trained Transformer 4 (GPT-4)\cite{achiam2023gpt}  embeddings\cite{https://doi.org/10.4126/frl01-006444995}, which offer a more comprehensive and flexible representation of language. Unlike traditional embeddings, GPT-4 can handle a wider array of terms, including those that are unseen during training or less common or domain-specific. We then analyzed how GPT-4 can correct entire metadata records from BioSample\cite{sundaram2024use} through a peer review board. In our current study, we expand to a large dataset of 2400 samples and study the effect of metadata standardization on search metrics.

The process of metadata standardization involves the analysis of the language used to specify name–value pairs. To the best of our knowledge, there have been a lack of concerted efforts in this research area, underscoring the relevance of our lab's consistent work in automated metadata standardization. In a previous attempt to enhance BioSample records using NLP techniques\cite{gonccalves2019aligning}, our team employed the earliest available embeddings (vectorial representations of words learned by training over text)—specifically word2vec\cite{mikolov2013distributed} and GloVe\cite{pennington2014glove}—to represent metadata terms. These embeddings are powerful tools for capturing semantic relationships among words. However, we encountered significant scalability challenges because these embeddings were limited to terms present in the training set, thereby neglecting the specialized and niche terms often found in medical and scientific data.

To address these limitations, we expanded our approach by incorporating Generative Pre-trained Transformer 4 (GPT-4)\cite{achiam2023gpt} embeddings\cite{https://doi.org/10.4126/frl01-006444995}, which provide a more comprehensive and flexible representation of language. Unlike traditional embeddings, GPT-4 can accommodate a broader range of terms, including those unseen during training or those that are less common or domain-specific. We subsequently analyzed how GPT-4 can improve the metadata of a small dataset of 200 metadata records from BioSample\cite{sundaram2024use} through a peer review board. Our results indicated that the domain experts preferred GPT-4 augmented with cues from a metadata knowledge source in its prompts.


In our current study, we expand our investigation to a large dataset of 2,400 samples each from BioSample and the Gene Expression Omnibus (GEO)\cite{edgar2002gene}, evaluating whether the necessity of a metadata knowledge source remains valid across different LLMs, including GPT-4, Large Language Model Meta AI (LLaMA-3) \cite{touvron2023llama}, and MedLLaMA-2 \cite{alvi2023medllama}. Instead of a peer review board, we measure the impact on search outcomes. While many authors highlight the theoretical benefits of the FAIR principles, the absence of quantitative analysis complicates the assessment of the tangible effects of FAIR data. A key contribution of our work is the quantification of the retrieval of BioSample records following metadata standardization and its effect on findability of scientific data.

\section*{The Search Experiment}
Our experiment is to improve metadata standardization of BioSample records and measure the impact of metadata improvements on search metrics. We begin by detailing the dataset utilized in our experiment.


\subsection*{Dataset} 
For the experiment, we utilized records from two separate datasets: one from BioSample and another from GEO. Each dataset contains 2,400 samples related to three types of cancer: lung cancer, liver cancer, and ovarian cancer. The queries used to retrieve the records were as follows: lung cancer \textit{(query: lung cancer[All Fields] AND "human 1 0"[filter])\footnote{This query translates to searching all the fields of a record to match with \textit{lung cancer} and filtering the result set to only contain records from human samples}}, liver cancer \textit{(query: liver cancer[All Fields] AND "human 1 0"[filter])}, and ovarian cancer \textit{(query: ovarian cancer[All Fields] AND "human 1 0"[filter])}. For each query, we randomly sampled 800 records from both datasets. We initially sampled 1,000 records for each query, removed those with formatting errors, and selected the maximum uniform number of well-formatted records across all datasets, which happened to be 800. Therefore, our total dataset comprises 4,800 records: 2,400 from BioSample and 2,400 from GEO (Table~\ref{tab:data-comp}).

\begin{table}[h!]
    \centering
    \begin{tabularx}{\textwidth}{|X|X|X|X|}
    \hline\hline
       \multicolumn{4}{|c|}{\textbf{Dataset Description}} \\ \hline
        BioSample (2400) & LungCancer (800) &  LiverCancer (800) & OvarianCancer (800) \\\hline
        GEO (2400) & LungCancer (800) &  LiverCancer (800) & OvarianCancer (800)\\ \hline
        \multicolumn{4}{|l|}{Total - 4800 records} \\\hline \hline
    \end{tabularx}
    \caption{Dataset Composition}
    \label{tab:data-comp}
\end{table}


\subsection*{Method}
Manual standardization of metadata involves a human who typically interprets applicable metadata standards and examines the metadata record to assess adherence, subsequently suggesting corrections. Similarly, for a given record, we sought to replicate this process by directing the LLM to utilize the data dictionary\cite{data-dict}, which includes the allowed list of metadata name–value pairs, their formats, and descriptions, to correct the record. This process is illustrated in Figure~\ref{fig:llm} for GPT-4.

\begin{figure}[h!]
    \centering
    \small
    \renewcommand{\arraystretch}{1.15}
    \begin{tabular}{p{0.8\textwidth}}
    \hline
     \textbf{Input to GPT-4: Metadata Record with Data Dictionary} \\\hline Convert the record: "age:67 | sex:female | tissue:lung cancer" to the format given by the BioSample data dictionary:\\
"Name | Description | Value format\\
age | age at the time of sampling; relevant scale depends on species and study, e.g. could be seconds for amoebae or centuries for trees | \{float\} \{unit\} \\

...\\
...\\
tissue | Type of tissue the sample was taken from | \{term\} \\
disease | list of diseases diagnosed; can include multiple diagnoses. the value of the field depends on host; for humans the terms should be chosen from DO (Disease Ontology), free text for non-human. For DO terms, please see \url{http://gemina.svn.sourceforge.net/viewvc/gemina/trunk/Gemina/ontologies/gemina_symptom.obo?view=log} | \{term\} \\
   \\\hline
     \textbf{Output:}\\\hline
     biosample\_provider: NA\\
     age: 67\\
     sex: female\\
     disease: lung cancer\\
     \hline
     
          
    \end{tabular}
    \caption{GPT-4 Correction of BioSample - The prompt given to GPT-4 includes both the metadata to be corrected and the entire data dictionary to which BioSample records should adhere.}
    \label{fig:llm}
\end{figure}

Building upon our previous efforts, we also measured the impact of using a metadata knowledge source on search metrics. Specifically, we used metadata templates sourced from the Center for Expanded Data Annotation and Retrieval (CEDAR)\cite{musen2015center}. CEDAR houses metadata templates that ease data sharing. CEDAR templates are machine-readable data structures that describe how metadata should be structured, providing guidelines for field names and corresponding values. The guidelines for field values include data format restrictions, value set restrictions, and ontological restrictions to ensure that metadata entries are consistent with established standards (Table~\ref{tab:cedar_features}). Given its comprehensive repository of metadata templates\cite{Musen2022}, CEDAR is a natural choice for supporting metadata-related endeavors. For example, as shown in Figure~\ref{fig:cedar}, CEDAR recommends values from the UBERON ontology for the attribute name "tissue," restricting the user to select standardized terms.

\begin{table}[h!]
\centering
\renewcommand{\arraystretch}{1.15}
\begin{tabular}{|l|p{8cm}|}
\hline
\textbf{Feature} & \textbf{Description} \\ \hline
Field Definitions & Field names and clear definitions of what each field is intended to represent \\ \hline
Data Format Restrictions & Specifications on the format of data entries, such as date formats or string patterns \\ \hline
Value Restrictions & Predefined lists or ontological restrictions \\ \hline

\end{tabular}
\caption{Key Features of CEDAR Templates}
\label{tab:cedar_features}
\end{table}


\begin{figure}[h!]
    \centering
    \fbox{
    \includegraphics[trim=0.1cm 1cm 0.3cm 0.1cm, clip]{Picture1.png}}
    \caption{A screen capture depicting the CEDAR metadata entry form derived from the template for BioSample. Field names specified in the data dictionary such as \textit{tissue} and \textit{organism} are listed. CEDAR recommends options for the ``tissue" field from the UBERON ontology\cite{Mungall2012}.}
    \label{fig:cedar}
\end{figure}
\begin{figure}[h!]
    \centering
    \small
    \renewcommand{\arraystretch}{1.15}
    \begin{tabular}{p{0.8\textwidth}}
    \hline
     \textbf{Input to GPT-4: Record with CEDAR template} \\\hline Convert the record: "age:67 | sex:female | tissue:lung cancer" to the format given by the CEDAR template\\ 
     "Name | Description | Comments\\
age | age at the time of sampling; relevant scale depends on species and study, e.g. could be seconds for amoebae or centuries for trees | \{float\} \{unit\} \\
tissue | type of tissue sample | \textbf{Must be from UBERON ontology}\\
...\\
...\\
disease | Name of the disease | \textbf{Must be from Disease Ontolology (DO) ontology} "   \\\hline
     \textbf{GPT-4 Output:}\\\hline
     biosample\_accession: NA\\
    organism: Homo sapiens\\
    age: 67\\
    sex: female\\
    tissue: lung\\
    disease: lung cancer\\
...\\
...\\

population: NA\\
race: NA\\
sample\_type: tissue\\

     \hline
     
          
    \end{tabular}
    \caption{GPT-4 Correction of BioSample with CEDAR template}
    \label{fig:llm_cedar}
\end{figure}

We use the described framework across a set of LLMs (GPT-4, LLaMA-3 and MedLLaMA2)  and tested it on our dataset. In this manner, we have two versions of our each dataset - one that is augmented by using the official data dictionary (LLM+DD) and another which is augmented by the CEDAR templates (LLM+CEDAR). We then perform search on a few queries for the field name \textit{tissue}. The retrieval from the dataset is done based on exact match. We then measure commonly used search metrics - precision, recall and F1-score.

\subsection*{Evaluation Metrics}
In our search experiment, we lack access to a gold standard. To derive the gold standard values for our records, we manually examine the `tissue' values in our BioSample dataset. We then develop simplistic rules to assign tissue values based on the sub-cohort (Table~\ref{tab:rules}). This approach allows us to devise an \textit{approximate} gold standard for our experiment.

\begin{table}[h!]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|p{0.3\columnwidth}|p{0.3\columnwidth}|p{0.3\columnwidth}|}
\hline
\textbf{Ovarian Cancer Tissue} & \textbf{Liver Cancer Tissue} & \textbf{Lung Cancer Tissue} \\
\hline
a$)$ Initialize label as `unknown'. & a$)$ Initialize label as `unknown'. & a$)$ Initialize label as `unknown'. \\
b$)$ If the tissue contains the word `ovary' or `ovarian', set label to `ovary'. & b$)$ If the tissue contains the word `liver' or `HCC', set label to `liver'. & b$)$ If the tissue contains the word `lung', set label to `lung'. \\
c$)$ Else, if the tissue contains the word `plasma', set label to `plasma'. & c$)$ Else, if the tissue contains the word `PBMC' or `blood', set label to `blood'. & c$)$ Else, if the tissue contains the word `PBMC' or `blood', set label to `blood'. \\
d$)$ Else, if the tissue contains the word `PBMC' or `blood', set label to `blood'. & d$)$ Else, if the tissue contains the word `lymph', set label to `lymph'. & d$)$ Else, if the tissue contains the word `lymph', set label to `lymph'. \\
 & e$)$ Else, if the tissue contains the word `plasma', set label to `plasma'. & e$)$ Else, if the tissue contains the word `plasma', set label to `plasma'. \\
\hline
\end{tabular}

\caption{Annotation Rules for Gold Standard}
\label{tab:rules}
\end{table}
We employed traditional search metrics—precision, recall, and F1-score to evaluate the datasets. The description of these metrics is provided in Table \ref{tab:metrics}. We performed experiments on two queries: \textit{tissue:(major organ)} and \textit{tissue:blood}.

\begin{table}[h!]
\centering

\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|p{0.1\columnwidth}|p{0.5\columnwidth}|p{0.3\columnwidth}|}
\hline
\textbf{Metric} & \textbf{Explanation} & \textbf{Formula} \\
\hline
Precision & Precision is the ratio of correctly retrieved relevant instances to the total retrieved instances. & $\frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}$ \\
\hline
Recall & Recall is the ratio of correctly retrieved relevant instances to the total relevant instances.  & $\frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}$ \\
\hline
F1-Score & F1-Score is the harmonic mean of precision and recall.  & $2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$ \\
\hline
\end{tabular}

\caption{Explanation of Search Metrics: Precision, Recall, and F1-Score}
\label{tab:metrics}
\end{table}

\section*{Results}

We first present the results of our search experiment on overall recall metrics with GPT-4. The average recall value rises from 17.65\% to 62.87\% from the baseline raw datasets of BioSample and GEO, to the GPT4+CEDAR versions.


\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{overall-recall.jpg}
    \caption{Comparison of average recall values for BioSample and GEO datasets across three result sets: Raw Samples, GPT4+DD, and GPT4+CEDAR}
    \label{fig:avg_recall_comparison}
\end{figure}

\subsection*{Liver Cancer}

First, we evaluated the methods on the BioSample  and GEO Liver Cancer datasets. %As shown in Tables~\ref{tab:liver-liver} and ~\ref{tab:liver-blood}, the performance varies significantly between the `tissue:liver` and `tissue:blood` queries.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{liver_cancer.jpg}
    \caption{Liver Cancer Datasets derived from BioSample and GEO: Query - tissue:liver}
    \label{fig:liver-tissue}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{livercancer_blood.png}
    \caption{Liver Cancer Datasets derived from BioSample and GEO: Query - tissue:blood}
    \label{fig:liver-blood}
\end{figure}
% \begin{table}[htbp]
% \centering

% \begin{tabular}{|l|c|c|c|}
% \hline
% \textbf{Method} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
% \hline
% BioSample &&& \\\hline
% Original & 1.00 & 0.26 & 0.42 \\
% LlaMA-3 + DD	& 1.00	& 0.02	& 0.04 \\ 
% LlaMA-3 + CEDAR	& 1.00	& 0.01	& 0.01 \\
% MedLlaMA-2 + DD &	0.00	& 0.00 & 	0.00 \\
% MedLlaMA-2 + CEDAR	& 0.00	& 0.00	& 0.01\\
% GPT4 + DD & 0.93 & 0.11 & 0.19 \\
% GPT4 + CEDAR & 0.96 & 0.95 & 0.96 \\\hline
% GEO &&& \\\hline
% Original & 1.00	& 0.09 &	0.17 \\
% LlaMA-3 + DD	& 0.21 &	0.01 &	0.02 \\ 
% LlaMA-3 + CEDAR	& 0.68 &	0.27 &	0.38 \\
% MedLlaMA-2 + DD	& 0.50	& 0.01 &	0.01 \\
% MedLlaMA-2 + CEDAR	& 0.00	& 0.00	& 0.00\\
% GPT4 + DD & 0.00 & 0.00 & 0.00 \\
% GPT4 + CEDAR &0.80&	0.64&	0.72\\\hline
% \hline
% \end{tabular}
% \caption{Liver Cancer Datasets derived from BioSample and GEO: Query - tissue:liver}
% \label{tab:liver-liver}
% \end{table}

% \begin{table}[htbp]
% \centering

% \begin{tabular}{|l|c|c|c|}
% \hline
% \textbf{Method} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
% \hline

% BioSample &&& \\\hline
% Original & 0.00 & 0.00 & 0.00 \\
% LlaMA-3 + DD	& 1.00	& 0.02	& 0.04 \\ 
% LlaMA-3 + CEDAR	& 1.00	& 0.01	& 0.01 \\
% MedLlaMA-2 + DD &	0.00	& 0.00 & 	0.00 \\
% MedLlaMA-2 + CEDAR	& 0.00	& 0.00	& 0.01\\

% GPT4 + DD & 1.00 & 0.20 & 0.33 \\
% GPT4 + CEDAR & 0.73 & 0.95 & 0.83 \\\hline
% GEO &&& \\\hline
% Original & 0.00	& 0.00 &	0.00 \\
% LlaMA-3 + DD	& 0.00 &	0.00 &	0.00 \\ 
% LlaMA-3 + CEDAR	& 0.00 &	0.00 &	0.00 \\
% MedLlaMA-2 + DD	& 0.00	& 0.00 &	0.00 \\
% MedLlaMA-2 + CEDAR	& 0.00	& 0.00	& 0.00\\
% GPT4 + DD & 0.00 & 0.00 & 0.00 \\
% GPT4 + CEDAR &0.00&	0.00&	0.00\\\hline
% \hline

% \end{tabular}
% \caption{Liver Cancer Datasets derived from BioSample and GEO: Query - tissue:blood}
% \label{tab:liver-blood}
% \end{table}
\subsection*{Ovarian Cancer}

For the domain of ovarian cancer , we compared the search efficacy of different datasets on two queries: `tissue:ovary` and `tissue:blood`. The results are presented below in Figures~\ref{fig:ovary-tissue} and ~\ref{fig:ovary-blood}, with precision, recall, and F1-score calculated for each method.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{ovarian_cancer_metrics_combined.png}
    \caption{Ovarian Cancer Datasets derived from BioSample and GEO: Query - tissue:ovary}
    \label{fig:ovary-tissue}
\end{figure}

% \begin{table}[htbp]
% \centering

% \begin{tabular}{|l|c|c|c|}
% \hline
% \textbf{Method} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
% \hline
% BioSample &&& \\\hline
% Original & 1.00 & 0.04 & 0.08 \\
% LlaMA-3 + DD	& 1.00	& 0.02 & 0.03 \\ 
% LlaMA-3 + CEDAR	& 0.00	& 0.00	& 0.00 \\
% MedLlaMA-2 + DD &	0.00	& 0.00 & 	0.00 \\
% MedLlaMA-2 + CEDAR	& 0.00	& 0.00	& 0.01\\
% GPT4 + DD & 0.91 & 0.05 & 0.09 \\
% GPT4 + CEDAR & 0.80 & 0.72 & 0.76 \\\hline
% GEO &&& \\\hline
% Original & 0.00	& 0.00 &	0.00 \\
% LlaMA-3 + DD	& 0.00 &	0.00 &	0.00 \\ 
% LlaMA-3 + CEDAR	& 0.3255813953	& 0.1196581197	& 0.175 \\
% MedLlaMA-2 + DD	& 0.00	& 0.00 &	0.00 \\
% MedLlaMA-2 + CEDAR	& 0.00	& 0.00	& 0.00\\
% GPT4 + DD & 0.00 & 0.00 & 0.00 \\
% GPT4 + CEDAR &0.2207792208	& 0.4358974359	& 0.2931034483\\\hline
% \hline

% \hline
% \end{tabular}
% \caption{Ovarian Cancer: Query - tissue:ovary}
% \label{tab:ovary-ovary}
% \end{table}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{ovarian_cancer_metrics_blood_combined.png}
    \caption{Ovarian Cancer Datasets derived from BioSample and GEO: Query - tissue:blood}
    \label{fig:ovary-blood}
\end{figure}
% \begin{table}[htbp]
% \centering

% \begin{tabular}{|l|c|c|c|}
% \hline
% \textbf{Method} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
% \hline
% BioSample &&& \\
% Original & 1.00 & 0.25 & 0.40 \\
% LlaMA-3 + DD	& 0.5	& 0.01	& 0.01 \\ 
% LlaMA-3 + CEDAR	& 1 & 	0.01	& 0.01 \\
% MedLlaMA-2 + DD &	0.00	& 0.00 & 	0.00 \\
% MedLlaMA-2 + CEDAR	& 0.00	& 0.00	& 0.00\\
% GPT4 + DD & 0.91 & 0.05 & 0.09 \\
% GPT4 + CEDAR & 0.80 & 0.72 & 0.76 \\\hline
% GEO &&& \\\hline
% Original & 0.00	& 0.00 &	0.00 \\
% LlaMA-3 + DD	& 0.00 &	0.00 &	0.00 \\ 
% LlaMA-3 + CEDAR	& 0.00 &	0.00 &	0.00 \\
% MedLlaMA-2 + DD	& 0.00	& 0.00 &	0.00 \\
% MedLlaMA-2 + CEDAR	& 0.00	& 0.00	& 0.00\\
% GPT4 + DD & 0 & 0 & 0 \\
% GPT4 + CEDAR & 0 & 0 & 0 \\
% \hline

% \end{tabular}
% \caption{Ovarian Cancer: Query - tissue:blood}
% \label{tab:ovary-blood}
% \end{table}



\subsection*{Lung Cancer}

Finally, we tested the lung cancer related datasets for the `tissue:lung` and `tissue:blood` queries. Figures~\ref{fig:lung-tissue} and ~\ref{fig:lung-blood} summarize the results, showing a strong performance of GPT4 + CEDAR in both cases.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{lung_cancer_metrics_updated_combined.png}
    \caption{Lung Cancer Datasets derived from BioSample and GEO: Query - tissue:lung}
    \label{fig:lung-tissue}
\end{figure}
% \begin{table}[htbp]
% \centering

% \begin{tabular}{|l|c|c|c|}
% \hline
% \textbf{Method} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
% \hline
% BioSample & && \\
% Original & 1.00 & 0.17 & 0.29 \\
% LlaMA-3 + DD	& 1	& 0.01	& 0.01 \\ 
% LlaMA-3 + CEDAR	& 1 & 	0.01	& 0.01 \\
% MedLlaMA-2 + DD &	0.00	& 0.00 & 	0.00 \\
% MedLlaMA-2 + CEDAR	& 1.00	& 0.01	& 0.01\\
% GPT4 + DD & 0.97 & 0.18 & 0.31 \\
% GPT4 + CEDAR & 0.93 & 0.99 & 0.96 \\
% GEO &&& \\\hline
% Original & 1	& 0.12 &	0.21 \\
% LlaMA-3 + DD	& 0.50 & 0.01 & 	0.01 \\ 
% LlaMA-3 + CEDAR	& 0.32 &	0.06 &	0.11 \\
% MedLlaMA-2 + DD	& 1.00	& 0.00 &	0.01 \\
% MedLlaMA-2 + CEDAR	& 0.00	& 0.00	& 0.00\\
% GPT4 + DD & 1 & 0.12 &	0.22\\

% GPT4 + CEDAR & 0.57 &	0.92 &	0.69 \\
% \hline
% \hline
% \end{tabular}
% \caption{Lung Cancer: Query - tissue:lung}
% \label{tab:lung-lung}
% \end{table}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{lung_cancer_metrics_blood_combined.png}
    \caption{Lung Cancer Datasets derived from BioSample and GEO: Query - tissue:blood}
    \label{fig:lung-blood}
\end{figure}
% \begin{table}[h!]
% \centering

% \begin{tabular}{|l|c|c|c|}
% \hline
% \textbf{Method} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
% \hline
% BioSample &&&\\hline 
% Original & 1.00 & 0.50 & 0.67 \\
% LlaMA-3 + DD	& 0	& 0	& 0 \\ 
% LlaMA-3 + CEDAR	& 0 & 	0	& 0 \\
% MedLlaMA-2 + DD &	0.00	& 0.00 & 	0.00 \\
% MedLlaMA-2 + CEDAR	& 0	& 0.0	& 0.0\\
% GPT4 + DD & 1.00 & 0.48 & 0.65 \\
% GPT4 + CEDAR & 1.00 & 0.78 & 0.88 \\\hline
% GEO &&& \\\hline
% Original & 0.00	& 0.00 &	0.00 \\
% LlaMA-3 + DD	& 0.6666666667	0.0162601626	& 0.03174603175\\ 
% LlaMA-3 + CEDAR	& 1	& 0.07317073171	& 0.1363636364 \\
% MedLlaMA-2 + DD	& 0.00	& 0.00 &	0.00 \\
% MedLlaMA-2 + CEDAR	& 0.00	& 0.00	& 0.00\\
% GPT4 + DD & 0 & 0 & 0 \\
% GPT4 + CEDAR & 1	& 0.6422764228 &	0.7821782178 \\
% \hline
% \hline
% \end{tabular}
% \caption{Lung Cancer: Query - tissue:blood}
% \label{tab:lung-blood}
% \end{table}

\section*{Discussion}
Standardized metadata are essential for making data FAIR\cite{musen2015center}. Effective metadata design ensures that data can be easily discovered, understood, and consumed by computer algorithms, thus fostering collaboration and advancing scientific discovery. Our results demonstrate that data's improved conformance to FAIR principles through more standards-adherent metadata, leads to enhanced recall during dataset searches. 

On closer examination of our results, we found only minor enhancements after using GPT-4 with the respective repository's data dictionary. We examined some of the errors and surmised that correction of existing metadata is difficult due to variations in describing a concept (such as \textit{lung afflicted with cancer}, \textit{lung cancer sample}). In some cases, this variability even caused a slight dip in recall. The experiments suggested a mechanism is required for providing guard rails to the generation process. This suggestion is also backed by recent studies in LLM alignment to real-world problems that incorporate knowledge to reduce hallucination and enhance reasoning\cite{dessimoz2024ai,lu2024chameleon}. In our method, we utilized CEDAR for the providing the knowledge in the form of a metadata template. Notably, our LLM prompted method, GPT4+CEDAR, consistently excels in retrieval and recall, although there is a slight decrease in precision. In scientific data discovery, researchers typically aim to retrieve as many datasets as possible and can identify the wrongly retrieved ones, if they are small in number. This observation highlights the significance of a human-in-the-loop approach.

Metadata correction with LLMs presents its own challenges. We experimented with LlaMA-3, Mistral, and MedLLaMA-2. While GPT-4 successfully generated accurate corrections for 4,800 samples, the other LLMs produced formatting errors. Hence, we had to employ complex post-processing of the output, hand-crafted for each LLM, thereby affecting deployment at scale. Consistently, GPT-4+CEDAR achieves the best recall values.

Another insight from the qualitative analysis of precision values is that the drop in precision can be attributed to errors introduced by GPT-4. For example, we observed instances where GPT-4 incorrectly changes the clearly stated \textit{tissue} value, such as \textit{blood}, to \textit{lung}, even after augmentation with CEDAR. This typically occurs when a BioSample record is longer than average, and the presence of other metadata entries mentioning \textit{lung} seem to interfere with the generation of the correct metadata. We also observed that the rule-based labeling approach is conservative and labels many tissue values as \textit{unknown} and GPT-4 actually extracts the correct tissue value but is penalized because the gold standard is not accurate and is an approximation. 

The analyses above highlight the need for additional safeguards following the integration of CEDAR. To address this, we implemented a method that retrieves all potential samples based on the new records while simultaneously displaying both the old and new records. This allows users to make informed decisions about which record to use, effectively reducing the cognitive load for researchers engaged in secondary data analysis. We will release this software for BioSample as a part of our data for this work.

We plan further enhancements by integrating ontology values into a retrieval framework using Retrieval-Augmented Generation (RAG) pipelines, ensuring consistent field naming. An ambitious goal involves developing a shadow database for the entirety of BioSample—reported to contain approximately 5 million samples—leveraging the CEDAR-augmented approach.



\section*{Conclusion}
Efforts to achieve FAIR data have become increasingly prominent in the scientific community, yet mere assertions of data FAIRness  without the implementation of rich, standardized metadata fail to render datasets truly findable. Our study underscores that the cornerstone of data FAIRness is the meticulous standardization of metadata. By employing advanced NLP techniques and a structured metadata knowledge source (CEDAR) to correct metadata, we demonstrated significant improvements in search recall and precision. The pronounced gains in retrieval performance presented in our results emphasize that through rigorous adherence to metadata standards, the advantages of data FAIRness can be actualized, thereby enhancing data accessibility and usability in scientific research.

\section*{Data Availability}
will add the link to visualization code here
\section*{Acknowledgements}
This work was support in part by grant R01 LM013498 from the National Library of Medicine.

% Open science and data reuse promise advances in scientific discovery. Adhering to FAIR principles\cite{wilkinson2016fair}—making data Findable, Accessible, Interoperable, and Reusable—fosters collaboration, prevents redundant efforts, and reveals new insights through secondary analyses, accelerating breakthroughs for societal benefit\cite{10.1093/nar/gkab1046,karsch2023international,10.1007/978-3-030-98876-0_7}. Effective metadata design is crucial for achieving data FAIRness. However, current metadata are usually incomplete, inconsistent, and incorrectly formatted\cite{gonccalves2019variable}. Standardizing metadata is therefore a necessary process for ensuring that datasets are properly described and accessible. 

% Standardizing metadata involves examining metadata dictionaries and reporting guidelines, then reviewing existing metadata to ensure adherence to community standards. For this purpose, we have developed an automated solution utilizing natural language processing (NLP) methods through use of the Generative Pre-trained Transformer\cite{achiam2023gpt} (GPT-4) and a metadata knowledge base. In this paper, we quantitatively assess its impact on recall metrics, demonstrating improved search performance with FAIR datasets.




% \section{Results}\label{sec2}

% Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text.

% \section{This is an example for first level head---section head}\label{sec3}

% \subsection{This is an example for second level head---subsection head}\label{subsec2}

% \subsubsection{This is an example for third level head---subsubsection head}\label{subsubsec2}

% Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. 

% \section{Equations}\label{sec4}

% Equations in \LaTeX\ can either be inline or on-a-line by itself (``display equations''). For
% inline equations use the \verb+$...$+ commands. E.g.: The equation
% $H\psi = E \psi$ is written via the command \verb+$H \psi = E \psi$+.

% For display equations (with auto generated equation numbers)
% one can use the equation or align environments:
% \begin{equation}
% \|\tilde{X}(k)\|^2 \leq\frac{\sum\limits_{i=1}^{p}\left\|\tilde{Y}_i(k)\right\|^2+\sum\limits_{j=1}^{q}\left\|\tilde{Z}_j(k)\right\|^2 }{p+q}.\label{eq1}
% \end{equation}
% where,
% \begin{align}
% D_\mu &=  \partial_\mu - ig \frac{\lambda^a}{2} A^a_\mu \nonumber \\
% F^a_{\mu\nu} &= \partial_\mu A^a_\nu - \partial_\nu A^a_\mu + g f^{abc} A^b_\mu A^a_\nu \label{eq2}
% \end{align}
% Notice the use of \verb+\nonumber+ in the align environment at the end
% of each line, except the last, so as not to produce equation numbers on
% lines where no equation numbers are required. The \verb+\label{}+ command
% should only be used at the last line of an align environment where
% \verb+\nonumber+ is not used.
% \begin{equation}
% Y_\infty = \left( \frac{m}{\textrm{GeV}} \right)^{-3}
%     \left[ 1 + \frac{3 \ln(m/\textrm{GeV})}{15}
%     + \frac{\ln(c_2/5)}{15} \right]
% \end{equation}
% The class file also supports the use of \verb+\mathbb{}+, \verb+\mathscr{}+ and
% \verb+\mathcal{}+ commands. As such \verb+\mathbb{R}+, \verb+\mathscr{R}+
% and \verb+\mathcal{R}+ produces $\mathbb{R}$, $\mathscr{R}$ and $\mathcal{R}$
% respectively (refer Subsubsection~\ref{subsubsec2}).

% \section{Tables}\label{sec5}

% Tables can be inserted via the normal table and tabular environment. To put
% footnotes inside tables you should use \verb+\footnotetext[]{...}+ tag.
% The footnote appears just below the table itself (refer Tables~\ref{tab1} and \ref{tab2}). 
% For the corresponding footnotemark use \verb+\footnotemark[...]+

% \begin{table}[h]
% \caption{Caption text}\label{tab1}%
% \begin{tabular}{@{}llll@{}}
% \toprule
% Column 1 & Column 2  & Column 3 & Column 4\\
% \midrule
% row 1    & data 1   & data 2  & data 3  \\
% row 2    & data 4   & data 5\footnotemark[1]  & data 6  \\
% row 3    & data 7   & data 8  & data 9\footnotemark[2]  \\
% \botrule
% \end{tabular}
% \footnotetext{Source: This is an example of table footnote. This is an example of table footnote.}
% \footnotetext[1]{Example for a first table footnote. This is an example of table footnote.}
% \footnotetext[2]{Example for a second table footnote. This is an example of table footnote.}
% \end{table}

% \noindent
% The input format for the above table is as follows:

% %%=============================================%%
% %% For presentation purpose, we have included  %%
% %% \bigskip command. Please ignore this.       %%
% %%=============================================%%
% \bigskip
% \begin{verbatim}
% \begin{table}[<placement-specifier>]
% \caption{<table-caption>}\label{<table-label>}%
% \begin{tabular}{@{}llll@{}}
% \toprule
% Column 1 & Column 2 & Column 3 & Column 4\\
% \midrule
% row 1 & data 1 & data 2	 & data 3 \\
% row 2 & data 4 & data 5\footnotemark[1] & data 6 \\
% row 3 & data 7 & data 8	 & data 9\footnotemark[2]\\
% \botrule
% \end{tabular}
% \footnotetext{Source: This is an example of table footnote. 
% This is an example of table footnote.}
% \footnotetext[1]{Example for a first table footnote.
% This is an example of table footnote.}
% \footnotetext[2]{Example for a second table footnote. 
% This is an example of table footnote.}
% \end{table}
% \end{verbatim}
% \bigskip
% %%=============================================%%
% %% For presentation purpose, we have included  %%
% %% \bigskip command. Please ignore this.       %%
% %%=============================================%%

% \begin{table}[h]
% \caption{Example of a lengthy table which is set to full textwidth}\label{tab2}
% \begin{tabular*}{\textwidth}{@{\extracolsep\fill}lcccccc}
% \toprule%
% & \multicolumn{3}{@{}c@{}}{Element 1\footnotemark[1]} & \multicolumn{3}{@{}c@{}}{Element 2\footnotemark[2]} \\\cmidrule{2-4}\cmidrule{5-7}%
% Project & Energy & $\sigma_{calc}$ & $\sigma_{expt}$ & Energy & $\sigma_{calc}$ & $\sigma_{expt}$ \\
% \midrule
% Element 3  & 990 A & 1168 & $1547\pm12$ & 780 A & 1166 & $1239\pm100$\\
% Element 4  & 500 A & 961  & $922\pm10$  & 900 A & 1268 & $1092\pm40$\\
% \botrule
% \end{tabular*}
% \footnotetext{Note: This is an example of table footnote. This is an example of table footnote this is an example of table footnote this is an example of~table footnote this is an example of table footnote.}
% \footnotetext[1]{Example for a first table footnote.}
% \footnotetext[2]{Example for a second table footnote.}
% \end{table}

% In case of double column layout, tables which do not fit in single column width should be set to full text width. For this, you need to use \verb+\begin{table*}+ \verb+...+ \verb+\end{table*}+ instead of \verb+\begin{table}+ \verb+...+ \verb+\end{table}+ environment. Lengthy tables which do not fit in textwidth should be set as rotated table. For this, you need to use \verb+\begin{sidewaystable}+ \verb+...+ \verb+\end{sidewaystable}+ instead of \verb+\begin{table*}+ \verb+...+ \verb+\end{table*}+ environment. This environment puts tables rotated to single column width. For tables rotated to double column width, use \verb+\begin{sidewaystable*}+ \verb+...+ \verb+\end{sidewaystable*}+.

% \begin{sidewaystable}
% \caption{Tables which are too long to fit, should be written using the ``sidewaystable'' environment as shown here}\label{tab3}
% \begin{tabular*}{\textheight}{@{\extracolsep\fill}lcccccc}
% \toprule%
% & \multicolumn{3}{@{}c@{}}{Element 1\footnotemark[1]}& \multicolumn{3}{@{}c@{}}{Element\footnotemark[2]} \\\cmidrule{2-4}\cmidrule{5-7}%
% Projectile & Energy	& $\sigma_{calc}$ & $\sigma_{expt}$ & Energy & $\sigma_{calc}$ & $\sigma_{expt}$ \\
% \midrule
% Element 3 & 990 A & 1168 & $1547\pm12$ & 780 A & 1166 & $1239\pm100$ \\
% Element 4 & 500 A & 961  & $922\pm10$  & 900 A & 1268 & $1092\pm40$ \\
% Element 5 & 990 A & 1168 & $1547\pm12$ & 780 A & 1166 & $1239\pm100$ \\
% Element 6 & 500 A & 961  & $922\pm10$  & 900 A & 1268 & $1092\pm40$ \\
% \botrule
% \end{tabular*}
% \footnotetext{Note: This is an example of table footnote this is an example of table footnote this is an example of table footnote this is an example of~table footnote this is an example of table footnote.}
% \footnotetext[1]{This is an example of table footnote.}
% \end{sidewaystable}

% \section{Figures}\label{sec6}

% As per the \LaTeX\ standards you need to use eps images for \LaTeX\ compilation and \verb+pdf/jpg/png+ images for \verb+PDFLaTeX+ compilation. This is one of the major difference between \LaTeX\ and \verb+PDFLaTeX+. Each image should be from a single input .eps/vector image file. Avoid using subfigures. The command for inserting images for \LaTeX\ and \verb+PDFLaTeX+ can be generalized. The package used to insert images in \verb+LaTeX/PDFLaTeX+ is the graphicx package. Figures can be inserted via the normal figure environment as shown in the below example:

% %%=============================================%%
% %% For presentation purpose, we have included  %%
% %% \bigskip command. Please ignore this.       %%
% %%=============================================%%
% \bigskip
% \begin{verbatim}
% \begin{figure}[<placement-specifier>]
% \centering
% \includegraphics{<eps-file>}
% \caption{<figure-caption>}\label{<figure-label>}
% \end{figure}
% \end{verbatim}
% \bigskip
% %%=============================================%%
% %% For presentation purpose, we have included  %%
% %% \bigskip command. Please ignore this.       %%
% %%=============================================%%

% \begin{figure}[h]
% \centering
% \includegraphics[width=0.9\textwidth]{fig.eps}
% \caption{This is a widefig. This is an example of long caption this is an example of long caption  this is an example of long caption this is an example of long caption}\label{fig1}
% \end{figure}

% In case of double column layout, the above format puts figure captions/images to single column width. To get spanned images, we need to provide \verb+\begin{figure*}+ \verb+...+ \verb+\end{figure*}+.

% For sample purpose, we have included the width of images in the optional argument of \verb+\includegraphics+ tag. Please ignore this. 

% \section{Algorithms, Program codes and Listings}\label{sec7}

% Packages \verb+algorithm+, \verb+algorithmicx+ and \verb+algpseudocode+ are used for setting algorithms in \LaTeX\ using the format:

% %%=============================================%%
% %% For presentation purpose, we have included  %%
% %% \bigskip command. Please ignore this.       %%
% %%=============================================%%
% \bigskip
% \begin{verbatim}
% \begin{algorithm}
% \caption{<alg-caption>}\label{<alg-label>}
% \begin{algorithmic}[1]
% . . .
% \end{algorithmic}
% \end{algorithm}
% \end{verbatim}
% \bigskip
% %%=============================================%%
% %% For presentation purpose, we have included  %%
% %% \bigskip command. Please ignore this.       %%
% %%=============================================%%

% You may refer above listed package documentations for more details before setting \verb+algorithm+ environment. For program codes, the ``verbatim'' package is required and the command to be used is \verb+\begin{verbatim}+ \verb+...+ \verb+\end{verbatim}+. 

% Similarly, for \verb+listings+, use the \verb+listings+ package. \verb+\begin{lstlisting}+ \verb+...+ \verb+\end{lstlisting}+ is used to set environments similar to \verb+verbatim+ environment. Refer to the \verb+lstlisting+ package documentation for more details.

% A fast exponentiation procedure:

% \lstset{texcl=true,basicstyle=\small\sf,commentstyle=\small\rm,mathescape=true,escapeinside={(*}{*)}}
% \begin{lstlisting}
% begin
%   for $i:=1$ to $10$ step $1$ do
%       expt($2,i$);  
%       newline() od                (*\textrm{Comments will be set flush to the right margin}*)
% where
% proc expt($x,n$) $\equiv$
%   $z:=1$;
%   do if $n=0$ then exit fi;
%      do if odd($n$) then exit fi;                 
%         comment: (*\textrm{This is a comment statement;}*)
%         $n:=n/2$; $x:=x*x$ od;
%      { $n>0$ };
%      $n:=n-1$; $z:=z*x$ od;
%   print($z$). 
% end
% \end{lstlisting}

% \begin{algorithm}
% \caption{Calculate $y = x^n$}\label{algo1}
% \begin{algorithmic}[1]
% \Require $n \geq 0 \vee x \neq 0$
% \Ensure $y = x^n$ 
% \State $y \Leftarrow 1$
% \If{$n < 0$}\label{algln2}
%         \State $X \Leftarrow 1 / x$
%         \State $N \Leftarrow -n$
% \Else
%         \State $X \Leftarrow x$
%         \State $N \Leftarrow n$
% \EndIf
% \While{$N \neq 0$}
%         \If{$N$ is even}
%             \State $X \Leftarrow X \times X$
%             \State $N \Leftarrow N / 2$
%         \Else[$N$ is odd]
%             \State $y \Leftarrow y \times X$
%             \State $N \Leftarrow N - 1$
%         \EndIf
% \EndWhile
% \end{algorithmic}
% \end{algorithm}

% %%=============================================%%
% %% For presentation purpose, we have included  %%
% %% \bigskip command. Please ignore this.       %%
% %%=============================================%%
% \bigskip
% \begin{minipage}{\hsize}%
% \lstset{frame=single,framexleftmargin=-1pt,framexrightmargin=-17pt,framesep=12pt,linewidth=0.98\textwidth,language=pascal}% Set your language (you can change the language for each code-block optionally)
% %%% Start your code-block
% \begin{lstlisting}
% for i:=maxint to 0 do
% begin
% { do nothing }
% end;
% Write('Case insensitive ');
% Write('Pascal keywords.');
% \end{lstlisting}
% \end{minipage}

% \section{Cross referencing}\label{sec8}

% Environments such as figure, table, equation and align can have a label
% declared via the \verb+\label{#label}+ command. For figures and table
% environments use the \verb+\label{}+ command inside or just
% below the \verb+\caption{}+ command. You can then use the
% \verb+\ref{#label}+ command to cross-reference them. As an example, consider
% the label declared for Figure~\ref{fig1} which is
% \verb+\label{fig1}+. To cross-reference it, use the command 
% \verb+Figure \ref{fig1}+, for which it comes up as
% ``Figure~\ref{fig1}''. 

% To reference line numbers in an algorithm, consider the label declared for the line number 2 of Algorithm~\ref{algo1} is \verb+\label{algln2}+. To cross-reference it, use the command \verb+\ref{algln2}+ for which it comes up as line~\ref{algln2} of Algorithm~\ref{algo1}.

% \subsection{Details on reference citations}\label{subsec7}

% Standard \LaTeX\ permits only numerical citations. To support both numerical and author-year citations this template uses \verb+natbib+ \LaTeX\ package. For style guidance please refer to the template user manual.

% Here is an example for \verb+\cite{...}+: \cite{bib1}. Another example for \verb+\citep{...}+: \citep{bib2}. For author-year citation mode, \verb+\cite{...}+ prints Jones et al. (1990) and \verb+\citep{...}+ prints (Jones et al., 1990).

% All cited bib entries are printed at the end of this article: \cite{bib3}, \cite{bib4}, \cite{bib5}, \cite{bib6}, \cite{bib7}, \cite{bib8}, \cite{bib9}, \cite{bib10}, \cite{bib11}, \cite{bib12} and \cite{bib13}.


% \section{Examples for theorem like environments}\label{sec10}

% For theorem like environments, we require \verb+amsthm+ package. There are three types of predefined theorem styles exists---\verb+thmstyleone+, \verb+thmstyletwo+ and \verb+thmstylethree+ 

% %%=============================================%%
% %% For presentation purpose, we have included  %%
% %% \bigskip command. Please ignore this.       %%
% %%=============================================%%
% \bigskip
% \begin{tabular}{|l|p{19pc}|}
% \hline
% \verb+thmstyleone+ & Numbered, theorem head in bold font and theorem text in italic style \\\hline
% \verb+thmstyletwo+ & Numbered, theorem head in roman font and theorem text in italic style \\\hline
% \verb+thmstylethree+ & Numbered, theorem head in bold font and theorem text in roman style \\\hline
% \end{tabular}
% \bigskip
% %%=============================================%%
% %% For presentation purpose, we have included  %%
% %% \bigskip command. Please ignore this.       %%
% %%=============================================%%

% For mathematics journals, theorem styles can be included as shown in the following examples:

% \begin{theorem}[Theorem subhead]\label{thm1}
% Example theorem text. Example theorem text. Example theorem text. Example theorem text. Example theorem text. 
% Example theorem text. Example theorem text. Example theorem text. Example theorem text. Example theorem text. 
% Example theorem text. 
% \end{theorem}

% Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text.

% \begin{proposition}
% Example proposition text. Example proposition text. Example proposition text. Example proposition text. Example proposition text. 
% Example proposition text. Example proposition text. Example proposition text. Example proposition text. Example proposition text. 
% \end{proposition}

% Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text.

% \begin{example}
% Phasellus adipiscing semper elit. Proin fermentum massa
% ac quam. Sed diam turpis, molestie vitae, placerat a, molestie nec, leo. Maecenas lacinia. Nam ipsum ligula, eleifend
% at, accumsan nec, suscipit a, ipsum. Morbi blandit ligula feugiat magna. Nunc eleifend consequat lorem. 
% \end{example}

% Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text.

% \begin{remark}
% Phasellus adipiscing semper elit. Proin fermentum massa
% ac quam. Sed diam turpis, molestie vitae, placerat a, molestie nec, leo. Maecenas lacinia. Nam ipsum ligula, eleifend
% at, accumsan nec, suscipit a, ipsum. Morbi blandit ligula feugiat magna. Nunc eleifend consequat lorem. 
% \end{remark}

% Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text.

% \begin{definition}[Definition sub head]
% Example definition text. Example definition text. Example definition text. Example definition text. Example definition text. Example definition text. Example definition text. Example definition text. 
% \end{definition}

% Additionally a predefined ``proof'' environment is available: \verb+\begin{proof}+ \verb+...+ \verb+\end{proof}+. This prints a ``Proof'' head in italic font style and the ``body text'' in roman font style with an open square at the end of each proof environment. 

% \begin{proof}
% Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. 
% \end{proof}

% Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text. Sample body text.

% \begin{proof}[Proof of Theorem~{\upshape\ref{thm1}}]
% Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. Example for proof text. 
% \end{proof}

% \noindent
% For a quote environment, use \verb+\begin{quote}...\end{quote}+
% \begin{quote}
% Quoted text example. Aliquam porttitor quam a lacus. Praesent vel arcu ut tortor cursus volutpat. In vitae pede quis diam bibendum placerat. Fusce elementum
% convallis neque. Sed dolor orci, scelerisque ac, dapibus nec, ultricies ut, mi. Duis nec dui quis leo sagittis commodo.
% \end{quote}

% Sample body text. Sample body text. Sample body text. Sample body text. Sample body text (refer Figure~\ref{fig1}). Sample body text. Sample body text. Sample body text (refer Table~\ref{tab3}). 

% \section{Methods}\label{sec11}

% Topical subheadings are allowed. Authors must ensure that their Methods section includes adequate experimental and characterization data necessary for others in the field to reproduce their work. Authors are encouraged to include RIIDs where appropriate. 

% \textbf{Ethical approval declarations} (only required where applicable) Any article reporting experiment/s carried out on (i)~live vertebrate (or higher invertebrates), (ii)~humans or (iii)~human samples must include an unambiguous statement within the methods section that meets the following requirements: 

% \begin{enumerate}[1.]
% \item Approval: a statement which confirms that all experimental protocols were approved by a named institutional and/or licensing committee. Please identify the approving body in the methods section

% \item Accordance: a statement explicitly saying that the methods were carried out in accordance with the relevant guidelines and regulations

% \item Informed consent (for experiments involving humans or human tissue samples): include a statement confirming that informed consent was obtained from all participants and/or their legal guardian/s
% \end{enumerate}

% If your manuscript includes potentially identifying patient/participant information, or if it describes human transplantation research, or if it reports results of a clinical trial then  additional information will be required. Please visit (\url{https://www.nature.com/nature-research/editorial-policies}) for Nature Portfolio journals, (\url{https://www.springer.com/gp/authors-editors/journal-author/journal-author-helpdesk/publishing-ethics/14214}) for Springer Nature journals, or (\url{https://www.biomedcentral.com/getpublished/editorial-policies\#ethics+and+consent}) for BMC.

% \section{Discussion}\label{sec12}

% Discussions should be brief and focused. In some disciplines use of Discussion or `Conclusion' is interchangeable. It is not mandatory to use both. Some journals prefer a section `Results and Discussion' followed by a section `Conclusion'. Please refer to Journal-level guidance for any specific requirements. 

% \section{Conclusion}\label{sec13}

% Conclusions may be used to restate your hypothesis or research question, restate your major findings, explain the relevance and the added value of your work, highlight any limitations of your study, describe future directions for research and recommendations. 

% In some disciplines use of Discussion or 'Conclusion' is interchangeable. It is not mandatory to use both. Please refer to Journal-level guidance for any specific requirements. 

% \backmatter

% \bmhead{Supplementary information}

% If your article has accompanying supplementary file/s please state so here. 

% Authors reporting data from electrophoretic gels and blots should supply the full unprocessed scans for key as part of their Supplementary information. This may be requested by the editorial team/s if it is missing.

% Please refer to Journal-level guidance for any specific requirements.

% \bmhead{Acknowledgements}

% Acknowledgements are not compulsory. Where included they should be brief. Grant or contribution numbers may be acknowledged.

% Please refer to Journal-level guidance for any specific requirements.

% \section*{Declarations}

% Some journals require declarations to be submitted in a standardised format. Please check the Instructions for Authors of the journal to which you are submitting to see if you need to complete this section. If yes, your manuscript must contain the following sections under the heading `Declarations':

% \begin{itemize}
% \item Funding
% \item Conflict of interest/Competing interests (check journal-specific guidelines for which heading to use)
% \item Ethics approval and consent to participate
% \item Consent for publication
% \item Data availability 
% \item Materials availability
% \item Code availability 
% \item Author contribution
% \end{itemize}

% \noindent
% If any of the sections are not relevant to your manuscript, please include the heading and write `Not applicable' for that section. 

% %%===================================================%%
% %% For presentation purpose, we have included        %%
% %% \bigskip command. Please ignore this.             %%
% %%===================================================%%
% \bigskip
% \begin{flushleft}%
% Editorial Policies for:

% \bigskip\noindent
% Springer journals and proceedings: \url{https://www.springer.com/gp/editorial-policies}

% \bigskip\noindent
% Nature Portfolio journals: \url{https://www.nature.com/nature-research/editorial-policies}

% \bigskip\noindent
% \textit{Scientific Reports}: \url{https://www.nature.com/srep/journal-policies/editorial-policies}

% \bigskip\noindent
% BMC journals: \url{https://www.biomedcentral.com/getpublished/editorial-policies}
% \end{flushleft}

% \begin{appendices}

% \section{Section title of first appendix}\label{secA1}

% An appendix contains supplementary information that is not an essential part of the text itself but which may be helpful in providing a more comprehensive understanding of the research problem or it is information that is too cumbersome to be included in the body of the paper.

% %%=============================================%%
% %% For submissions to Nature Portfolio Journals %%
% %% please use the heading ``Extended Data''.   %%
% %%=============================================%%

% %%=============================================================%%
% %% Sample for another appendix section			       %%
% %%=============================================================%%

% %% \section{Example of another appendix section}\label{secA2}%
% %% Appendices may be used for helpful, supporting or essential material that would otherwise 
% %% clutter, break up or be distracting to the text. Appendices can consist of sections, figures, 
% %% tables and equations etc.

% \end{appendices}

% %%===========================================================================================%%
% %% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
% %% system, please include the references within the manuscript file itself. You may do this  %%
% %% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
% %% file, and delete the associated \verb+\bibliography+ commands.                            %%
% %%===========================================================================================%%

\bibliography{sn-bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl


\end{document}
