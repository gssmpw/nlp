\section{Evaluation}
\label{sec:evaluation}

\begin{figure*}[b]
\centering
\includegraphics[width=1\linewidth]{figures/fig16_latency_reduction_sens.pdf}
\caption{\yct{6}{\om{8}{S}ystem performance versus different preventive refresh latencies for different manufacturers, RowHammer mitigation mechanisms, and $\bm{N}_{\bm{RH}}$ values, \om{7}{averaged across 62 single-core workloads}}}
\label{fig:lrr_analysis}
\end{figure*}

% \yct{20}{To demonstrate the potential benefits of reduced refresh latency, we 
\subsection{Methodology}
\label{sec:eval_methodology}
\yct{20}{We showcase \X{}'s impact on system performance and energy efficiency, using Ramulator 2.0~\cite{ramulator2github, luo2023ramulator2} (based on Ramulator~\cite{kim2016ramulator, ramulatorgithub}).}
Table~\ref{table:configs} lists the simulated system configuration, \agy{20}{assuming}
% {In our evaluations, we assume 
a realistic system with a single \om{7}{core} \yct{1}{or four} \agy{4}{cores}, connected to \yct{1}{DDR5 memory.}
%two memory ranks with eight bank groups, each containing two banks (32~banks in total). 
% The {memory controller uses} FR-FCFS~\cite{rixner2000memory, zuravleff1997controller} scheduling algorithm with \yct{1}{a cap of four}.
\vspace{5pt}
\begin{table}[ht]
\renewcommand{\arraystretch}{0.85}
\centering
\footnotesize
\caption{Simulated system configuration}
\label{table:configs}
\resizebox{\linewidth}{!}{
\begin{tabular}{ll}
\hline
\textbf{Processor}                                                   & \begin{tabular}[c]{@{}l@{}} \yct{7}{1 or 4 cores}, 3.2GHz clock frequency,\\ 4-wide issue, 128-entry instruction window\end{tabular}  \\ \hline
\textbf{DRAM}                                                        & \begin{tabular}[c]{@{}l@{}}DDR5, 1 channel, 2 rank, 8 bank groups, \\2 banks/bank group, \yct{7}{64K} rows/bank\end{tabular}  \\ \hline
\begin{tabular}[c]{@{}l@{}}\textbf{Memory Ctrl.}\end{tabular} & \begin{tabular}[c]{@{}l@{}}64-entry read and write requests queues,\\Scheduling policy: FR-FCFS~\cite{rixner2000memory,zuravleff1997controller} \\Address mapping: MOP\cite{kaseridis2011minimalistic}\end{tabular}   \\ \hline
\textbf{Last-Level Cache}& \begin{tabular}[c]{@{}l@{}} 2MB per core \end{tabular}  \\ \hline
\end{tabular}}
\end{table}





% \agycomment{5}{is this still only 60? would be better to have 600}\yctcomment{5}{:(} 
\head{Workloads}
{We \yct{1}{evaluate \X{} using}
five benchmark suites: {SPEC CPU2006~\cite{spec2006}}, SPEC CPU2017~\cite{spec2017}, {TPC~\cite{tpcweb}, MediaBench~\cite{fritts2009media}, and YCSB~\cite{ycsb}}. 
\yct{7}{From these benchmark suites, }\yct{1}{we randomly select \param{62} \om{5}{single-core} workloads and \param{60}
multi-programmed 4-core workload mixes.}
{For every workload, we generate memory traces corresponding to 100M instructions using SimPoint~\cite{simpoint}.}
We simulate these traces until \yct{1}{each} core executes \param{100M}
instructions with a warmup period of \param{10M} instructions, similarly to prior \agy{4}{works}~\cite{kim2020revisiting, yaglikci2021blockhammer, yaglikci2022hira}.}
% \agycomment{5}{there were several instances of singular/plural mistakes. Be careful}\yctcomment{5}{thanks}
% \agycomment{5}{too few}\yctcomment{5}{:(}

% For every workload, we generate memory traces corresponding to 100 million instructions from representative regions in each workload using SimPoint [79]

% {We assume that a refresh to a DRAM row can be served concurrently with a refresh or an access to \covref{} of the rows within the same DRAM bank,}
% based on our experimental results {(\secref{sec:experiments_coverage})}.
\head{Metrics}
{{We evaluate \X{}'s impact on \emph{system performance} (in terms of \yct{0}{instructions-per-cycle, IPC \yct{1}{and weighted speedup\om{5}{~\cite{eyerman2008systemlevel, snavely2000symbiotic}}})
% , \yct{1}{\emph{total execution time spent on preventive refreshes} (i.e., where a DRAM bank is unavailable due to preventive refreshes)}, 
and \emph{DRAM energy consumption}.}}}\yctcomment{5}{we use DRAMPower which only calculates DRAM energy.}
%weighted speedup~\cite{snavely2000symbiotic, eyerman2008systemlevel, michaud2012demystifying}), \emph{job turnaround time} (in terms of harmonic speedup~\cite{luo2001balancing,eyerman2008systemlevel}), and \emph{fairness} {(in terms of maximum slowdown~\cite{kim2010thread, kim2010atlas,subramanian2014bliss,subramanian2016bliss, subramanian2013mise, mutlu2007stall, subramanian2015application, ebrahimi2012fairness, ebrahimi2011prefetch, das2009application, das2013application, yaglikci2021blockhammer}})}.}

% \yctcomment{5}{I merged comparison points into configuring pacram.}
% \head{Comparison points}
% Our baseline does \emph{not} implement any \yct{0}{RowHammer} mitigation mechanisms. We evaluate \X{} with \yct{20}{five} state-of-the-art preventive refresh based RowHammer mitigation mechanism,
% PARA~\cite{kim2014flipping}, 
% RFM~\cite{jedec2020ddr5}, 
% PRAC~\cite{jedec2024ddr5}, 
% Hydra~\cite{qureshi2022hydra}, and 
% Graphene~\cite{park2020graphene}.
% \iqrev{We use the implementations that are publicly available \iql{IQF2}in Ramulator 2~\cite{ramulator2github}. To showcase \X's improvements, we implement \X{} as a plugin that works with other mechanisms.}
% \srev{We use a blast radius of 2 (i.e., a \sql{R1.2}preventive refresh performs charge restoration $\pm2$ of an aggressor row) to account for Half-Double attack, similarly to prior works~\cite{olgun2024abacus, canpolat2024prac, qureshi2024mint, qureshi2024impress, hassan2021utrr, yaglikci2021blockhammer, canpolat2024breakhammer}.}

\head{\yct{4}{Comparison points and configuring \X{}}}
% Our baseline does \emph{not} implement any \yct{0}{RowHammer} mitigation mechanisms. 
We evaluate \X{} with \yct{20}{five} state-of-the-art preventive refresh based RowHammer mitigation \om{7}{mechanisms:}
PARA~\cite{kim2014flipping}, 
RFM~\cite{jedec2020ddr5}, 
PRAC~\cite{jedec2024ddr5}, 
Hydra~\cite{qureshi2022hydra}, and 
Graphene~\cite{park2020graphene}.
We use the implementations that are publicly available in \om{8}{the} Ramulator 2 \om{7}{code repository}~\cite{ramulator2github}. To showcase \X's improvements, we implement \X{} as a plugin that works with other mechanisms \yct{7}{and reduces the latency of preventive refreshes issued by RowHammer mitigation mechanisms}.\fnref{fn:onlyprev}
We use a blast radius of 2 (i.e., a preventive refresh performs charge restoration \om{7}{of victim rows that are within distance} $\pm2$ of an aggressor row) to account for \om{7}{the} Half-Double \om{5}{access pattern~\cite{kogler2022half}}, similarly to prior works~\cite{olgun2024abacus, canpolat2024prac, qureshi2024mint, qureshi2024impress, hassan2021utrr, yaglikci2021blockhammer, canpolat2024breakhammer}.

\yct{4}{We use the following three configurations in our simulations\om{5}{:} 
i)~\emph{No mitigation}: \yct{6}{the} baseline that does \emph{not} implement any RowHammer mitigation mechanism\iey{7}{,}\yctcomment{10}{added PaCRAM-M to fig16-17-18}
ii)~\emph{No \X{}}: \yct{6}{the configuration that implements a RowHammer mitigation mechanism \emph{without} employing \X{}\iey{7}{, and}}
\yct{10}{iii)~\emph{\Xh{}}, \emph{\Xm{}}, and \emph{\Xs{}}: \om{7}{three specific} \yct{6}{configurations that implement a RowHammer mitigation mechanism \agy{7}{and} \X{}\agy{7}{,}
\omcomment{7}{Do we show these modulesâ€™ data specifically in earlier sections?}\yctcomment{7}{we added an example to sec8.3 and will add an appendix table.}
\om{7}{configured for three different modules from Mfrs.~H \agy{7}{(H5)}, M~(M2), and~S \agy{7}{(S6)}}, \agy{7}{respectively}.}}} \iqrev{To configure \Xh{}\yct{10}{, \Xm{},} and \Xs{}, for each module, \iql{IQA2}we first \om{7}{experimentally characterize} the \gls{nrh} of the module for \agy{7}{the} charge restoration latencies \om{8}{of $33ns$ (nominal $t_{RAS}$), $27ns$ ($0.81t_{RAS}$), $21ns$ ($0.64t_{RAS}$), $15ns$ ($0.45t_{RAS}$), $12ns$ ($0.36t_{RAS}$), $9ns$ ($0.27t_{RAS}$)\yct{11}{, and $6ns$ ($0.18t_{RAS}$)}.}\yctcomment{7}{We will further improve the placement of this figure.}
\yct{4}{We then calculate \emph{\gls{nrh} reduction ratio} as the ratio of \gls{nrh} value with reduced \om{7}{charge restoration} latency and \gls{nrh} value with nominal \om{7}{charge restoration} latency.} 
% \gls{nrh} values decrease compared to the \gls{nrh} value where nominal charge restoration latency is used. 
% \agycomment{5}{what does this mean?}\yctcomment{5}{I defined it properly now}
\agy{7}{We configure the RowHammer mitigation mechanisms
% \agycomment{7}{I removed: ``that employ \X{}'' it is incorrect. We do this for RH mitigation mechanisms that do not employ \X{} as well.}
for the \gls{nrh} values of 1024, 512, 256, 128, 64, and 32 row activations per aggressor row and when the RowHammer mitigation mechanism is integrated with \X{}, we reduce \gls{nrh} according to the reduction ratios of H5\yct{10}{, M2,} and S6 \om{5}{obtained from experimental characterization (\secref{sec:effect_nrh})}.}
% Using these decreases, we adjust the \emph{base} \gls{nrh} value tested in simulation (e.g., 1K, 512, 256, 128, 64, 32) and used the reduced \gls{nrh} values to configure \X{} and mitigation mechanisms.
% \agycomment{5}{I did not even understand this paragraph to fix it}\yctcomment{5}{what about now?}
For example, \yct{6}{when H5 (i.e., the module used for \Xh{}) is refreshed 300 times using $0.27t_{RAS}$, the lowest observed \gls{nrh} of the module decreases by 8\% (i.e., reduces from 10.2K to 9.4K).}
% if a module's \gls{nrh} value decreases from 100K to 90K with a charge restoration latency of $0.64t_{RAS}$, 
\yct{6}{\agy{7}{Therefore,} we
% calculate the \gls{nrh} reduction ratio of H5 as 0.92 and 
\agy{7}{use the scaled} down \gls{nrh} values of 942, 471, 235, 117, 58, and 29 \agy{7}{to simulate the RowHammer mitigation mechanisms, integrated with \Xh{}}.
% \yctcomment{7}{removing "ns", these are nrh values.} 
% We use these \yct{7}{reduced} \gls{nrh} values to configure RowHammer mitigation mechanisms that employ \Xh{} \yctcomment{7}{merged with this sentence as we compute \gls{tfr} using these reduced \gls{nrh} values.}
% \omcomment{8}{Very confusing. Periodic refresh can be completely misunderstood here. Redo this sentence completely }
\yct{8}{\agy{7}{To configure \X{} correctly in the presence of the need for refreshing rows using full charge restoration before a row can receive \gls{thpcr} partial charge restorations (\takeref{take:rh_rep}),} we compute \agy{7}{the interval of full charge restoration (\gls{tfr})} as explained in \secref{sec:mech_implementation}.}
% \agycomment{7}{We should have a gigantic table in the appendix that reports all these parameters for all modules.}
\yctcomment{7}{We will add the appendix table reporting these values for all modules.}
% \agycomment{7}{fill in}
% , the minimum time required to perform \gls{thpcr} preventive refreshes as explained in \secref{sec:mech_implementation}.}}
% we scale the base \gls{nrh} values with the same factor (0.9) and use these reduced \gls{nrh} values to configure \X{} and RowHammer mitigation mechanisms.
% \yctcomment{7}{visit}
% \yct{7}{Then, we use these reduced \gls{nrh} values to compute}
% We then compute \gls{tfr}.
% \agycomment{5}{isn't it unfair to reduce \gls{nrh} for the baseline mechanism?}\yctcomment{5}{fixed the misconception}
% \Xh{} (\Xs{}) refers to \X{} configuration where we use our experimental data of the module from Mfr. H (Mfr. S).
}
% {For each module, we use the worst-case \gls{nrh} (i.e., smallest \gls{nrh}) across all the chips.}
}






\subsection{Performance and Energy Analysis}
\label{sec:eval_perf}

% \agycomment{4}{Not good to start with a sensitivity study. Rename it. Effect of Reducing Preventive Refresh Latency on System Performance?}\yctcomment{4}{sure}
\head{Effect of reducing \agy{7}{the charge restoration} latency \agy{7}{of preventive refreshes} on system performance}
% \yct{7}{To analyze the effect of \X{} on system performance,
% % for different preventive refresh latencies, 
% we sweep the charge restoration latency of \X{}.}
% To analyze how preventive refresh latency affects the performance of \X{}, we compare the performance of  \Xh{} and \Xs{} with different preventive refreshes latencies. 
% \omcomment{7}{Place better}\agycomment{7}{We will improve placement once we get rid of the sections (e.g., \secref{sec:halfdobule_chargerestoration}) that will be moved to the appendix.}
\figref{fig:lrr_analysis} demonstrates how \agy{7}{reducing charge restoration latency for} preventive refreshes affects \agy{7}{system} performance \agy{7}{for} five RowHammer mitigation mechanisms \agy{7}{(columns of subplots)} \agy{7}{when they are integrated with \Xh{}\yct{10}{, \Xm{},} and \Xs{} (rows of subplots)}. 
The x-axis shows the charge restoration latency
normalized to \om{7}{the} nominal restoration latency. 
% \ieycomment{7}{This is not a latency but a ratio, right? Would be better to clarify this metric here and in the x-axis of the plot (Onur did not say anything about this so let's just take this as a note.}
\yct{7}{The y-axis shows the IPC of the \om{8}{single-core} \iey{7}{workloads} normalized to the baseline where the mitigation mechanisms do \emph{not} \yct{7}{use}
% \ieycomment{7}{combined with?}\yctcomment{7}{we use "combined" "used" "implemented" "integrated". Should we use the same thing?}\ieycomment{7}{I think Onur used "when used with" so let's stick to that one right now.kk thx}
\X{} (i.e., the nominal charge restoration latency is used for preventive refreshes).}
%\yct{7}{The y-axis shows the IPC of \Xh{} (top subplots) and \Xs{} (bottom subplots) normalized to the baseline where the mitigation mechanisms do \emph{not} implement \X{} (i.e., the nominal charge restoration latency is used for preventive refreshes), averaged across 62 single-core workloads.}
% \agycomment{7}{baseline does not implement any RH mitigaiton mechanism, no? check the consistency of terminology between here and the methodology subsection.}\yctcomment{7}{no fig15 normalize to No PaCRAM config}
Each curve represents \om{7}{a} different \gls{nrh} value.
\yct{7}{The shades show the variation across all tested workloads.} \yct{8}{The dashed red line in each plot represents the best-observed charge restoration latency, which provides the highest performance improvement across tested charge restoration latencies.}
% \ieycomment{8}{I am not sure right now but we need to be more clear and somehow concise. For example, instead of performance improvement maybe somehow saying the reduced tras that pacram achieves the highest performance? idk. need to think more.}\yctcomment{8}{I am not sure as well, lets see what onur thinks.}
% \agycomment{7}{What about the vertical dashed red lines? They should be explained before the observations.}\agycomment{7}{if we use the same method in somewhere else, we should fix all instead of repeating the wrong practice.}
% \yctcomment{7}{fixed both}
% The y-axis shows the IPC of the workloads normalized to their IPC when nominal preventive refresh latency is used for \Xh{} (top subplots) and \Xs{} (bottom subplots). Each curve represents different \gls{nrh} values. Each data point is aggregated across all simulated workloads and the shaded areas around the curves represent 95\% confidence intervals.
% \agycomment{4}{What about the vertical dashed red lines?}\yctcomment{4}{we explain it below, we use the same method in the motivation.}

% \agycomment{5}{never use ``The optimal'' do you know if 0.35 is worse than 0.36? Maybe that one is better. Say: ``The best-observed''}\yctcomment{5}{thanks}
% \ieycomment{7}{TODO: sounds weird but could not find a better word for now.}\yctcomment{7}{what about now?}\ieycomment{7}{now it sounds like you use five RH + pacram kldsfjhlksdfhhmmmmmmmmmm}\yctcomment{7}{problem solved?}
We make \param{\agy{7}{five}} observations from \figref{fig:lrr_analysis}. 
First, \Xh{} \yct{10}{and \Xm{}} \yct{7}{improve system performance by reducing preventive refresh overheads} \yct{7}{of each tested} RowHammer mitigation mechanism for each \iey{7}{tested} \gls{tras} and \gls{nrh} value. 
Second, as we decrease the preventive refresh latency, the performance of \Xh{} and \Xs{} first increases until a point, then decreases since RowHammer vulnerability increases (i.e., \gls{nrh} of the DRAM chip decreases) with the reduced charge restoration latency. 
Third, \Xs{} reduces the performance of Hydra and Graphene as reducing charge restoration latency increases the RowHammer vulnerability and leads to more preventive refreshes.
Fourth, \X{} can reduce the charge restoration latency for \yct{10}{Mfrs.~H and M} more than Mfr.~S as the DRAM chips from \yct{10}{Mfrs.~H and M} have larger \om{7}{\gls{tras}} guardbands than the chips from Mfr. S and \om{7}{thus} are more resilient to reduced charge restoration latencies.
\agy{7}{Fifth, the} \yct{6}{best-observed}
% \yctcomment{7}{we can remove these.}
charge restoration latency for \Xh{} \yct{10}{and \Xm{}} are $0.36t_{RAS}$ \yct{11}{and $0.18t_{RAS}$}\yctcomment{11}{Before PaCRAM-M, 0.27 was the lowest value we test, for M, I tested 0.18 as well and updated the numbers and the fig 16 accordingly.}, across all tested RowHammer mitigation mechanisms\yct{10}{, respectively.} The best-observed charge restoration latency for \Xs{} is $0.45t_{RAS}$ when used with PARA, RFM, and PRAC.\footnote{\agy{7}{For the rest of our analysis, \Xh{}\yct{10}{, \Xm{},} and \Xs{} use \yct{1}{the \yct{7}{best-observed}} charge restoration latencies.
% of \agy{7}{$0.36t_{RAS}$ and $0.45t_{RAS}$, respectively}.
}}
% while the \yct{6}{best-observed charge}
% restoration latency for \Xs{} is $0.45t_{RAS}$ \yct{20}{for PARA, RFM, and PRAC} (shown with red dashed lines). 
\agy{1}{From these observations, we}
\agy{7}{conclude that \X{} increasingly improves system performance by reducing \iey{7}{the} charge restoration latency of preventive refreshes until an inflection point, where the latency reduction is overwhelmed by the increasing number of preventive refreshes.}
% derive \takeref{take:cr_perf}.

% \takeaway{\yct{7}{\X{} improves system performance by reducing the preventive refresh latency.}\label{take:cr_perf}} 
% \takeaway{System performance first increases, then decreases as we reduce the preventive refresh latency.\label{take:cr_perf}} 

% \footnote{\agy{7}{We exclude the evaluation of \Xs{} with Hydra and Graphene due to \emph{no} room for performance improvement.}} 
% \yct{7}{For \Xh{}, the best-observed charge restoration latency when used with any tested mitigation mechanisms is $0.36t_{RAS}$. For \Xs{}, the best-observed charge restoration latency is $0.45t_{RAS}$ when used with PARA, RFM, and PRAC, but \Xs{} does \emph{not} increases system performance when used with Hydra and Graphene. Therefore, we omit Hydra and Graphene that employ \Xs{} from the rest of our analysis.}
% \yctcomment{7}{Should we say these? and for multi-core we also omit PARA for PaCRAM-S.}

% \ieycomment{7}{What is the difference between this and the previous section? At least they sound very similar.}\yctcomment{7}{they are similar, the previous sweep the latency and normalize to 1 latency. This uses the best latency and normalizes to no mitigation.}
\noindent
\textbf{\X's impact on system performance.}
\figref{fig:perf_imp} demonstrates the \yct{1}{performance of \X{}} normalized to performance when \emph{no} mitigation mechanism is employed (y-axis) for six different \gls{nrh} values (x-axis) and \yct{20}{five} different RowHammer mitigation mechanisms. \yct{1}{Left (right) subplot represents the performance as IPC (weighted speedup)
% \ieycomment{7}{Is there a right y-axis? Parenthesis confused me here.}\yctcomment{7}{The first sentence explains both y-axes using "performance".}
for \yct{7}{
single-core (multi-core) systems, averaged across 62 single-core workloads (60 multi-programmed workload mixes).}}
Each color represents \agy{6}{a} different \agy{6}{RowHammer mitigation mechanism} and the \agy{6}{marker} style represents \om{7}{different configurations}. \yct{7}{The shades show the variation across \iey{7}{all} tested workloads.}
% \omcomment{7}{what is the meaning of 95\% confidence interval?}\agycomment{7}{instead of improving the text and saying that shades show the variation across workloads, you choose to drop it. Don't do that. Bring the shades back with 100\% confidence interval and say that they show the variation across tested workloads.}\yctcomment{7}{I removed them because the figure was too crowded. I will reinsert.}
% \X{} is implemented or not on top of the existing \agy{6}{RowHammer} mitigation mechanism. 
% The shaded areas around the curves represent 95\% confidence intervals.
%\agycomment{1}{what about the shades?}


\begin{figure}[ht]
\centering
\includegraphics[width=1\linewidth]{figures/fig17_perf_imp.pdf}
\caption{\yct{6}{System performance of \X{}}}
\label{fig:perf_imp}
\end{figure}

% \begin{figure*}[ht]
% \centering
% \includegraphics[width=1\linewidth]{figures/fig17_pref_time.pdf}
% \caption{\srev{Total time spent on preventive \sql{R4}refreshes}}
% \label{fig:ref_time}
% \end{figure*}

We make \param{four} observations from \figref{fig:perf_imp}. 
First, \Xh{} \yct{10}{and \Xm{}} increase system performance for all \gls{nrh} values by reducing the performance overheads of all tested RowHammer mitigation mechanisms. For example, \Xh{} improves \yct{7}{single-core (multi-core)} system performance on average by \yct{7}{18.95\% (10.81\%), 12.28\% (10.84\%), 2.07\% (0.76\%), 2.56\% (2.00\%), and 5.37\% (4.31\%) \yct{7}{when used with}
PARA, RFM, PRAC, Hydra, and Graphene
\yct{7}{at an \gls{nrh} of 32, across all tested workloads.}}
% \ieycomment{7}{across all tested workloads?}\yctcomment{7}{I am not sure, if all workloads benefit but the average of it benefits.} 
Second, \agy{7}{the} performance improvement of \yct{7}{\X{}} increases as \gls{nrh} decreases for all \iey{7}{tested RowHammer} mitigation mechanisms. For example, \Xh{} increases \yct{7}{single-core} system performance by \yct{20}{0.69\% (12.28\%)} \om{7}{when used with} RFM at an \gls{nrh} of \yct{20}{1K (32)}, on average.
Third, the performance improvements of \Xh{} \yct{10}{and \Xm{}} \yct{1}{are higher than \agy{7}{that} of \Xs{} \yct{7}{when used with any tested mitigation mechanism}.
\yct{10}{For example, \Xh{} and \Xm's \yct{7}{multi-core} performance improvements are \yct{7}{$0.46\%$ and $4.48\%$ higher\om{11}{, on average,} than \Xs's improvement, respectively, when used with RFM}.}
\srev{Fourth, \X{} provides larger performance improvements \om{7}{when used with} high-performance-overhead mitigations (PARA and RFM) compared to high-area-overhead mitigations (PRAC, Hydra, and Graphene). PRAC, Hydra, and Graphene perform fewer preventive refreshes and cause smaller performance overheads at the cost of higher hardware complexity compared to PARA and RFM\om{7}{;} hence \X{} can reduce the latency of more preventive refreshes when \yct{7}{used} with PARA or RFM.}}
% Fifth, \X{}'s \yct{7}{single-core performance} improvements for  workloads are slightly higher than multi-programmed workloads. Singlecore workloads benefit from \X{} by \yct{20}{$1.43\times$} more than multi-programmed workloads.
\agy{1}{Based on these observations, we derive:}
%\gls{nrh} decreases for %Graphene~\cite{park2020graphene} and PARA~\cite{kim2014flipping}. The performance improvement of \X{}-S decreases by \param{1.41\%} for PARA~\cite{kim2014flipping} when \gls{nrh} is reduced from \param{2K} to \param{64}.}

\takeaway{\X{} significantly improves \yct{7}{both single-core and multi-core} system performance.\label{take:perf_attack}}
% \yctcomment{7}{Now, this is very similar to takeaway 7}\agycomment{7}{we needed the original conclusion from the previous plot. So I converted it to a regular conclusion rather than a highlighted takeaway. This is our first takeaway in perf evaluation}

% \agycomment{5}{I moved execution time analysis to the appendix. Especially because, it only provides details but nothing new AND consumes lots of space due to 2-col figure.}\yctcomment{5}{thanks}
% \head{The execution time spent on preventive refreshes}
% \yct{1}{To understand the reasoning behind \X's performance improvement, we analyze the \yct{1}{execution time spent on preventive refreshes (i.e., where a DRAM bank is unavailable due to preventive refreshes)}. \figref{fig:ref_time} demonstrates the \yct{1}{total time spent on preventive refreshes for singlecore (top subplots) and multi-programmed workloads (bottom subplots)}. The x-axis shows six different \gls{nrh} values and the y-axis shows the \yct{1}{execution time spent on} preventive refreshes normalized to execution time spent on preventive refreshes when mitigation mechanisms without \X{} are configured \yct{20}{with an \gls{nrh} of 1K}.}\agycomment{5}{these texts turn to tongue twisters. Instead you can say something like: execution time spent on preventive refreshes normalized to that when ...}


% \yct{1}{We make \param{three} observations from \figref{fig:ref_time}. 
% \yct{1}{First, the execution time spent on preventive refreshes significantly increases as \gls{nrh} decreases. For example, the execution time spent on preventive refreshes for Hydra increases by \yct{20}{$144\times$} when \gls{nrh} is decreased from \yct{20}{$1K$ to $32$}.
% Second, both \Xh{} and \Xs{} significantly reduce the time spent on preventive refresh for RFM and PARA in all configurations. {For example, \Xh{} (\Xs{} reduces the execution time spent on preventive refreshes of PARA by \yct{20}{$34.12\%$ ($10.70\%$)} on average across all \gls{nrh} values}.
% Third, \Xs{} spends more time on refreshes than \Xh{}.}
% %First, the majority of preventive refreshes use reduced restoration latency. For example, for \gls{nrh} of 64, \param{95.7\%} of all preventive refreshes use reduced restoration latency\{, on average}.
% %\agycomment{1}{quantify} 
% %Second, \emph{no}
% %\agycomment{1}{emph all negations: e.g., no, none, not...}
% %mitigation mechanism uses nominal charge restoration latency for higher \gls{nrh} as \gls{tfr} is larger than \gls{trefw} for higher \gls{nrh} values\agy{1}{. This is because} \X{} does \emph{not} need to use \agy{1}{the} nominal \agy{1}{ restoration} latency \agy{1}{for preventive refreshes as}
% % to restore the charge level of the rows since 
% %periodic refresh\agy{1}{s already fully} restore \agy{1}{victim rows' charges} before the \agy{1}{victim rows' partial charge restoration count reaches \gls{thpcr}.}
% % y can receive \gls{thpcr} preventive refreshes with reduced latency). 
% %Third, the number of preventive refreshes using reduced latency decreases with decreasing \gls{nrh} since \X{} sets the bits in \gls{fr} more frequently for low \gls{nrh} values, causing more preventive refreshes using nominal latency. 
% Based on these observations, we derive \takeref{take:time_ref}.}
% %\agycomment{1}{We need to tie this back to the energy-related motivation in Sec 3. Assume that the energy spent for a refresh  is proportional to the latency of the refresh . So, as most of these  perform partial charge restoration instead of full, they save energy. Report the number.}

% \takeaway{\X{} significantly reduces the execution time spent on preventive refreshes.\label{take:time_ref}}

\head{\X's impact on \agy{7}{DRAM} energy consumption}
\figref{fig:edp} shows \X{}'s impact on DRAM energy consumption \om{8}{(using a similar style as~\figref{fig:perf_imp}).}
% The x-axis shows \gls{nrh} values\iey{7}{,} and the y-axis shows DRAM energy consumption, normalized to that when \emph{no} RowHammer mitigation mechanism is used. Each curve shows data from a system that employs a RowHammer mitigation mechanism with either \Xh{}, \Xs{}, or \emph{no} \X{}.
% % different  a RowHammer mitigation mechanism is u \X{}, normalized to that \emph{without} \X{}.} 
% % the \yct{7}{average}
% % \agycomment{7}{why did you say average here? average across what? put the shades or error bars to show the variation across workloads} \agy{7}{DRAM} energy consumption \agy{7}{when a RowHammer mitigation mechanism is used with \X{}}, normalized to \agy{6}{that} \agy{6}{without \X{}} (y-axis) for different \gls{nrh} values (x-axis). 
% Different colors represent different mitigation mechanisms, and different marker styles represent \yct{7}{different} configurations.
% \yct{7}{The shades show the variation across all tested workloads.}
% Two subplots \agy{7}{show} the energy consumption for \yct{7}{single-core workloads (left)} and \yct{7}{multi-programmed workload mixes (right)}.
% \ieycomment{7}{multi-core or multi-programmed? I am not sure which one we use most. What do you thin?} 
% \yctcomment{7}{I used multi-core for system and multi-programmed for workload mixes.}
% \agycomment{7}{instead of improving the text and saying that shades show the variation across workloads, you choose to drop it. Don't do that. Bring the shades back with 100\% confidence interval and say that they show the variation across tested workloads.}\yctcomment{7}{I did it to improve the plots' readability.}
\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{figures/fig18_energy.pdf}
\caption{\srev{Energy \sql{R4}consumption of \X{}}}
\label{fig:edp}
\end{figure}
We make \param{three} observations. 
First, \Xh{} \yct{10}{and \Xm{}} reduce energy consumption when used with any tested mitigation mechanism for all \gls{nrh} values \om{8}{(due to lower energy consumed by lower latency preventive refreshes and reduced execution time).}
% by \agy{7}{performing partial charge restoration in preventive refreshes}.
\yct{7}{For example, \Xh{} reduces \om{8}{the DRAM} energy consumption of \om{8}{the} single-core (multi-core) system by 14.59\% (17.75\%), 11.56\% (18.05\%), 1.15\% (0.26\%), 2.18\% (2.55\%), and 4.50\% (5.76\%)
when used with
PARA, RFM, PRAC, Hydra, and Graphene, respectively, on average at an \gls{nrh} of 32.}
% \agycomment{7}{Onur found this observation counter-intuitive. Providing numbers or rephrasing the observations will not address that issue. We need to give insights into why \X{} reduces DRAM energy consumption.}\yctcomment{7}{I thought the problem was with the plotting, I replotted by normalized to no mitigation and explained in the mail.}\agycomment{7}{Still, what is the reason of energy reduction compared to RH mitigation mechanism without \X{}? This is not answered in the email as well.}\yctcomment{7}{I added reducing prev ref lat, we cannot give by reducing the total time spent on prev refs with giving the fig in the appendix.}
% First, \Xh{} reduces the energy consumption for all mechanisms and \gls{nrh} values 
% \agy{6}{(e.g., 14.59\%, 11.56\%, 1.15\%, 2.18\%, and 4.50\% for PARA, RFM, PRAC, Hydra, and Graphene, respectively, on average across all tested workloads at an \gls{nrh} of 32).}
% \Xh{} reduces the energy consumption of
% \yct{20}{PARA, RFM, PRAC, Hydra, and Graphene} by 
% \yct{20}{14.59\%, 11.56\%, 1.15\%, 2.18\%, and 4.50\%}, on average at an \gls{nrh} of 32. 
\yct{7}{Second, \Xs's energy consumption is higher than \Xh{} \yct{10}{and \Xm's} energy consumptions. For example, \Xs's single-core energy consumption is 8.69\% \yct{10}{and 11.57\%} higher than \Xh{} \yct{10}{and \Xm's} energy consumption\yct{10}{, respectively, when used with PARA} on average \agy{7}{across 62 single-core workloads}.
\yct{7}{Third, all configurations consume more energy as \gls{nrh} reduces.}
From these observations, we derive:}
% \agycomment{5}{does not make sense to exclude \Xs{} from the figure completely, and then talk about it in an observation. Also, single core results are not interesting at this point anyway. It makes more sense to put \Xh{} and \Xs{} results in two subplots only for multicore.}\yctcomment{5}{just for energy results?, I think adding PaCRAM-S to the plots would be the best thing.}

\takeaway{\X{} significantly reduces DRAM energy consumption.\label{take:edp}}

%\subsubsection{\X{} without RH-based Performance Attacks}
%\yct{1}{\figref{fig:benign} demonstrates the IPC of benign workloads without an RH-based performance attack normalized to baseline IPC without any defense (y-axis) for six different \gls{nrh} values (x-axis) and three different RowHammer mitigation mechanisms. Three curves represent the default mitigation and two \X{} configurations for Mfr. H and Mfr. S.}
%The shaded areas around the curves represent 95\% confidence interval.

% \begin{figure}[ht]
% \centering
% \includegraphics[width=1\linewidth]{figures/benign.pdf}
% \caption{{Performance overheads on benign workloads}}
% \label{fig:benign}
% \end{figure}

% \yct{1}{We make \param{three} observations from \figref{fig:benign}.
% First, \X{} does \emph{not} significantly affect the performance of Graphene~\cite{park2020graphene} and Hydra~\cite{qureshi2022hydra}.
% %\agycomment{1}{cite both}
% Second, \X{} reduces the overhead induced by PARA~\cite{kim2014flipping}. For example, \X{}-H/S improves the system performance by \param{10.1\%/3.8\%} of PARA~\cite{kim2014flipping} at \gls{nrh} of 64 on average.
% Third, the performance improvement of \X{} increases as \gls{nrh} decreases. For example, \X{}-H improves the system performance of PARA~\cite{kim2014flipping} by \param{1.6\%/6.9\%} at \gls{nrh} of \param{2K/128} on average. 
% % We conclude that \X{} does not affect the performance overhead of Graphene and Hydra while reducing the performance overhead of PARA. 
% Based on these observations, we derive \takeref{take:benign}.}

% \takeaway{\X{} does \emph{not} cause any extra performance overhead on benign workloads.\label{take:benign}}

% \head{\X{} for Periodic Refresh}\agycomment{20}{I chopped this part a lot}
% We extend \X{} to perform periodic refreshes with reduced latency, which becomes increasingly time consuming as DRAM die density increases. We observe that for a DRAM die density of 512Gb, \X{}-H improves the system performance by \param{22.37\%} by reducing the time spent on periodic refreshes. We leave a detailed analysis of \X{} for periodic refreshes to future work due to page limitations.

\noindent
\srev{\textbf{\X's impact on high-performance-overhead \sql{R2.3}and high-area-overhead mitigations.}}
\srev{\X{} significantly reduces the performance and energy overheads of high-performance-overhead RowHammer mitigation \yct{7}{mechanisms}, e.g., PARA \agy{7}{by \param{18.95\%}} and RFM \agy{7}{by \param{12.28\%} for \gls{nrh}=32} \om{7}{(\figref{fig:perf_imp})}.
% For example, \X{} reduces the performance overhead of PARA by 18.95\% at an \gls{nrh} of 32 \om{7}{(\figref{fig:perf_imp})}. 
\agy{7}{This is}
% \Xâ€™s performance and energy improvements for PARA and RFM are 
\om{7}{especially} important because PARA and RFM are significantly more scalable to lower \gls{nrh} values and larger bank counts {due to their low area cost}, unlike the best-performing mechanisms (e.g., Graphene). 

When \yct{7}{used} with \X{}, high-area-overhead mitigation \yct{7}{mechanisms} that already incur high area overheads (e.g., Graphene, Hydra, and PRAC) experience substantial performance and energy overhead reductions at the cost of small additional area overhead. \yct{7}{For example, \X{} reduces the performance overhead of Graphene by 5.37\% \om{7}{(at $N_{RH}=32$)} \agy{7}{at the cost of an additional 0.09\% on top of Graphene's 4.45\% chip area overhead (only 2.02\% increase in Graphene's area).}}
% \agycomment{7}{Onur did not like 2.13\% number because it can be understood as \X{}'s area is 2.13\% of a processor die, which is huge. Fill in the placeholders and we can iterate.}
% while adding an area overhead that is only 2.13\% of Graphene's area.}
\yct{7}{Therefore, \X{} introduces new system design points for RowHammer mitigation, balancing i)~performance and energy efficiency and ii)~area overhead.}
% Therefore, \X{} enables new system design points in RowHammer mitigation: i)~performance and energy, ii)~area overhead trade-off space.
}

% \yctcomment{5}{potential appendix}
% \noindent
% \cqrev{\textbf{\X{}'s potential extensions.}
% \yctcomment{1}{chop chop chop}
% \cql{GC1.3}{}\agy{1}{\X{} can be extended to reduce the restoration latency for periodic refreshes and dynamic accesses.}
% To \agy{1}{examplify} the potential benefits of \agy{1}{such extensions}, we modify \X{} to perform periodic refreshes with reduced latency. 
% \srev{\figref{fig:periodic_ref} demonstrates the performance improvement \sql{R3}(left subplot) and DRAM energy consumption (right subplot) of \X{} with reduced periodic refreshes normalized to \yct{1}{the case where the system does \emph{not} perform any refreshes (y-axis) for different DRAM chip densities} (x-axis) for multi-programmed workloads. \yct{1}{Six} curves represent different refresh latencies normalized to the nominal refresh latency, the baseline system with nominal refresh latency is where refresh latency is 1.00.}}

% \begin{figure}[ht]
% \centering
% \includegraphics[width=0.9\linewidth]{figures/fig19_periodic.pdf}
% \caption{\srev{Improvements with reduced periodic refresh latency}}
% \label{fig:periodic_ref}
% \end{figure}

% \srev{We make \param{three} observations from \figref{fig:periodic_ref}. First, \yct{1}{\X{} significantly improves the system performance and energy efficiency for all configurations and DRAM chip densities by reducing the periodic refresh latency. For example, reducing refresh latency by 64\% (i.e., \Xh's optimal charge restoration latency) improves the system performance and energy efficiency by 23.31\%, and 36.49\% of a \param{512Gb} DRAM chip, respectively. Second, performance improvement and energy efficiency increase as refresh latency decreases. For example, system performance increases by 8.83\% when refresh latency decreases from 64\% to 36\%.}}
% Third, the periodic refresh overhead increases as the DRAM chip density increases due to increased refresh latency.
% Based on these observations, we conclude that reducing the latency of periodic refreshes  \agy{1}{improves \X{}'s performance benefits. This extension requires modifications in \X{}'s metadata management. We leave this extension to future work.}




% \noindent
% \subsection{\yct{7}{\X{} \agy{7}{for Other Charge Restorations}}}
% % \omcomment{7}{Did prior works not propose partial charge restoration. How is this different from those works?}
% % \yctcomment{7}{I couldn't find any prior work that uses reduced latency for all periodic refreshes.}
% \cql{GC1.3}{}\agy{1}{\X{} can be extended to \om{7}{also} reduce the \om{7}{charge} restoration latency for periodic refreshes and dynamic accesses\om{7}{, in addition to preventive refreshes (as we \om{8}{have done} so far).}}
% To \om{8}{exemplify} the potential benefits of \agy{1}{such extensions}, 
% \yct{7}{we analyze the impact of reducing charge restoration latency for periodic refreshes, which restore every cell's charge in the module every \gls{trefw} to prevent data retention failures, similarly to prior works~\cite{das2018vrldram, liu2012raidr}.
% % To do so, we modify \X{} to use reduced charge restoration latency for periodic refreshes as
% \yct{7}{Unlike prior works, \X{} reduces the latency of all periodic refreshes as}
% our experimental characterization demonstrates that charge restoration latency can be reduced significantly without causing any data retention failures (\takeref{take:retention}).}\yctcomment{7}{We explain our differences from prior work.}
% \yct{7}{To do so, we use a configuration that does \emph{not} employ any RowHammer mitigation mechanism (i.e., no preventive refreshes are issued) and sweep the \agy{7}{charge restoration latency for periodic refreshes.}}
% % \agycomment{7}{is this correct?}\yctcomment{7}{no}
% % periodic refresh latency.} 
% % We modify \X{} to perform periodic refreshes with reduced \yct{7}{charge restoration} latency \yct{7}{and compare to the baseline system that uses nominal charge restoration latency for periodic refreshes.} 


% \srev{\figref{fig:periodic_ref} demonstrates \yct{7}{multi-core system} performance \sql{R3}(left subplot) and DRAM energy consumption (right subplot) of \X{} with reduced periodic refreshes \yct{7}{and the baseline system with nominal periodic refreshes} normalized to \yct{7}{a \agy{7}{hypothetical} system \agy{7}{which}
% % \ieycomment{7}{nominal and reduced periodic refresh latencies? Onur said something here that I cannot fully parse (are you 'XXXXX' periodic refresh??}\yctcomment{7}{I changed here and the previous paragraph, I guess it is clear now, isn't it?} 
% % where the system 
% does \emph{not} perform any periodic refreshes} (y-axis) for different DRAM chip densities} (x-axis). \yct{7}{As DRAM chip density increases, the number of rows per bank increases. Hence, the number of rows refreshed with a single periodic refresh and the periodic refresh latency increase~\dramStandardCitations{}.} Six curves represent different \yct{7}{periodic} refresh latencies normalized to the nominal \yct{7}{periodic} refresh latency, the baseline system with nominal refresh latency is where \yct{7}{periodic} refresh latency is 1.00 \yct{7}{(marked with $\bm{\times}$)}. \yct{7}{The shades show the variation across tested workloads.}
% % \agycomment{7}{I thought this also included reducing tRAS for dynamic accesses. If so, the legend should be Charge restoration latency}
% % \agycomment{7}{not clear what happens when the density increases to cause performance and energy overheads. Do we increase the number of rows?}
% % \agycomment{7}{instead of improving the text and saying that shades show the variation across workloads, you choose to drop it. Don't do that. Bring the shades back with 100\% confidence interval and say that they show the variation across tested workloads.}

% \begin{figure}[ht]
% \centering
% \includegraphics[width=0.9\linewidth]{figures/fig19_periodic.pdf}
% \caption{\yct{7}{System performance (left) and energy consumption (right) versus different DRAM chip capacities for different periodic refresh latencies}}
% \label{fig:periodic_ref}
% \end{figure}

% % \agycomment{7}{I think all these best-observed ones should be best-observed (with a '-'). Check with grammarly and apply everywhere.} 
% \srev{We make \param{three} observations from \figref{fig:periodic_ref}. 
% \yct{7}{
% First, \yct{1}{\X{} significantly improves system performance and energy efficiency for all DRAM chip densities and reduced periodic refresh latencies (i.e., $<1.00$) 
% \agy{7}{compared to} \yct{7}{the baseline system that uses nominal charge restoration latency\yct{7}{, across all tested workloads.}} 
% % \ieycomment{7}{in all tested multi-core workloads?}
% For example, reducing periodic refresh latency by 64\% (i.e., \Xh's best-observed
% charge restoration latency) improves multi-core system performance and energy efficiency by 23.31\%, and 36.49\% of a \param{512Gb} DRAM chip, respectively. 
% Second, performance improvement and energy efficiency increase as periodic refresh latency decreases. For example, system performance increases by 8.83\% when periodic refresh latency decreases from 64\% to 36\%.}}
% \yct{7}{Third, for all periodic refresh latency values, periodic refresh overheads increase as DRAM chip capacity increases.}
% % \yctcomment{7}{We will add more on this in the extended version.}
% % \ieycomment{7}{Instead of leaving this extension to future work, say something like: we provide the evaluation of this extension in the extended version of this paper[CITE] or "..metadata management, which we evaluate in the extended version of this paper[CITE]".}\yctcomment{7}{can we cite extended version before it is published?}\ieycomment{7}{Yes, just create another bib entry. Instead of HPCA put arXiv there. This is what I did (and also RowPress I think). RowPress did a lot of referring to the extended version, so you can even steal some sentences directly from there.}




% \agycomment{5}{This part should be right before the related work. As a subsection, it breaks the flow from the mechanism to the evaluation}\yctcomment{5}{sure}

\section{\om{7}{Profiling Overhead}}
\label{sec:limitations}
\noindent
\iqrev{\textbf{{Characterization of DRAM chips.}}
{For \X{} \om{8}{to work robustly}, one needs to correctly identify the \om{7}{appropriate} charge restoration reduction. Doing so requires profiling the DRAM chips in use.
% {To integrate \X{} to a commodity system, we need to configure \X{} accordingly such that the reducing charge restoration latency does \emph{not} compromise reliability and security. Therefore, we need to profile the DRAM module to understand its behavior under partial charge restoration. 
This profiling can be performed in different ways at low cost as described in our methodology \om{8}{(\secref{subsec:testing_methodology})} and several prior works (e.g.,\yct{7}{~\cite{chang2017understanding,liu2013experimental, lee2017design, yaglikci2024spatial, patel2017reaper, liu2013experimental, choi2020reducing, orosa2021deeper, orosa2021codic}}). 
First, the system can \om{8}{perform} profiling the very first time DRAM is initialized and configure \X{}. 
Second, DRAM vendors can \om{8}{perform} profiling at manufacturing time and embed configuration data in the Serial Presence Detect (SPD) circuitry~\cite{jedec-spd}. The memory controller can read the configuration data from the SPD circuitry and configure \X{}.
Third, the system can perform \om{8}{\emph{online profiling}} to configure \X{}\om{8}{~\cite{patel2017reaper, qureshi2015avatar, liu2013experimental, khan2014efficacy, lee2017design}}\yctcomment{9}{cited DIVA-DRAM}.
\yct{20}{To quantify the profiling cost, we demonstrate an optimized profiling methodology.}
}
}

% \agycomment{5}{You can melt this into Sec 4 as a footnote or a small subsection probably.}\yctcomment{5}{we will definitely add this in the extended version, i don't think we should waste time to merge this into sec 4.}
\noindent
\head{Profiling cost} 
As \secref{subsec:testing_methodology} describes, our profiling methodology tests a DRAM row for five different $t_{RAS}$ values with ten different \yct{7}{consecutive} partial charge restorations \yct{7}{counts} at five different hammer counts for five iterations. Given that each test includes a wait time of \gls{trefw} ($64ms$), we concurrently test and, by doing so, overlap the testing time of 1270 different DRAM rows in a DRAM bank. 
Therefore, we test 1270 DRAM rows within an $80s$ time window ($64ms$ $\times$ $5$ $t_{RAS}$ values $\times$ $10$ different numbers of partial charge restorations $\times$ $5$ hammer counts $\times$ $5$ iterations).
As each DRAM row contains 8KB of data, our methodology's profiling throughput is 127 KB/s (1270 $\times$ 8KB $/$ 80s).
Following this methodology, profiling a DRAM bank with 64K
% \agycomment{7}{footnote here should say that K means 1024} 
rows takes 68.8 minutes. However, this profiling can be performed in chunks of \om{7}{80 seconds} spread across time by blocking only $9.9MB$ of data at a time. We leave further optimizations of profiling to future work.
% \agycomment{5}{All these calculations should go to the appendix}

% \cqrev{
% Many methodologies can be used to \cql{CQ5-STALE}profile a DRAM chip to find its charge restoration latency reduction. Accurately identifying the restoration latency reduction of a DRAM row requires testing a row with multiple restoration latencies, number of restorations, hammer counts, and iterations where each test consists of initializing, performing charge restoration, performing RowHammer attack, waiting until the end of \gls{trefw}, and reading the row. For example, a methodology might test each row for 5 restoration latencies, 10 numbers of restorations, 5 hammer counts, and 5 iterations to accurately identify the row's restoration latency reduction. To quantify the profiling cost, we demonstrate an example profiling methodology to identify the restoration latency reduction for a DDR4 DRAM bank with 64K rows.
% }


% \cqrev{The profiling methodology requires to identify each row's restoration latency reduction. To find the latency reduction of the bank, it gets the minimum restoration latency reduction among all the rows in the bank.
% As the runtime of a row's testing is highly dominated by the long wait time until the end of \gls{trefw}, we can interleave the tests of multiple rows (i.e., after we initialize a row and hammer its aggressor rows, we can start testing another row while the first row waits until the end of \gls{trefw}). 
% By doing so, we can start testing $\sim1270$ rows while we wait for the first row as initializing a row and hammering its aggressors takes approximately $\sim0.05ms$~\cite{jedec2017ddr4}. Therefore, testing $\sim1270$ rows in a DRAM bank takes approximately $128ms$ (i.e., we start testing the last row just before the first row reaches \gls{trefw}). Testing all rows in a DRAM bank with 64K rows takes $\sim6.7s\ (128ms\times(64K/1270))$. To accurately identify the charge restoration latency reduction of a bank with 64K rows, the profiling methodology takes $\sim2.3$ hours $(6.7s\times5\times10\times5\times5)$. 
% We leave the further optimization of the profiling methodology to future work.
% }



\noindent
\iqrev{\textbf{{System reliability.}}
{\X{} is limited to systems that employ \iql{IQF1}DRAM chips that implement guardbands in \om{7}{the} $t_{RAS}$ timing parameter. We experimentally demonstrate on real DDR4 DRAM chips that there exist significantly large guardbands in \om{8}{the} $t_{RAS}$ timing parameter. Our findings are in line with prior works\yct{7}{~\cite{liu2013experimental, lee2015adaptive, chang2016understanding, chang2017understanding, chang2017understandingphd, kim2018solar, yaglikci2022understanding, mathew2017using, lee2017design, chandrasekar2014exploiting, das2018vrldram}}\yctcomment{8}{yes, solardram is included} that show that several timing parameters (e.g., $t_{RCD}$, $t_{WR}$, $t_{RP}$, \gls{tras}) in commodity DRAM chips implement large guardbands. 
\om{8}{To improve robustness and to account for dynamic variability\yctcomment{8}{we couldn't parse "variability" or something else?}, e.g., aging}, \X{} can be combined with error correction mechanisms\yct{7}{~\cite{zhang2021quantifying, nair2016xed, hamming1950error, hocquenghem1959codes, bose1960class, qureshi2021rethinking, fakhrzadehgan2022safeguard, chen2014memguard, khan2014efficacy, kim2015bamboo, reed1960polynomial, yoon2010virtualized, qureshi2015avatar, lee2017design, patel2017reaper}}\yctcomment{9}{added REAPER}. We leave the exploration of such systems for future work. 
}}

















