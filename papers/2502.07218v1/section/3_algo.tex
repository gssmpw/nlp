\begin{algorithm}[H]
\caption{\lunar: Unlearning via Neural Activation Recalibration}
\begin{algorithmic}%[1]
\STATE \textbf{Require:} Let $\mathcal{D}_f$ be the forget set; $\mathcal{D}_r$ be the retained set; $\mathcal{D}_{\text{ref}}$ be the reference dataset.

\vspace{0.5em} 

\STATE \textbf{Procedure 1: Compute Unlearning Vectors (UV)}
\STATE Given $\mathcal{D}_f$ and $\mathcal{D}_{\text{ref}}$, calculate activation mean
\STATE $a_f = \frac{1}{|D_{f}|} \sum_{x \in D_{f}} \mathbf{h}^{(l)}(x)$
\STATE $a_{\text{ref}} = \frac{1}{|D_{\text{ref}}|} \sum_{x \in D_{\text{ref}}} \mathbf{h}^{(l)}(x) $
\STATE compute diff-in-mean: $\mathbf{r}_{\text{UV}}^{(l)} = a_{\text{ref}}  - a_f$

\vspace{0.5em} 

% 
\STATE \textbf{Procedure 2: Layer Selection}
\STATE Select the layer (according to Sec. \ref{sec:layer_selection}) where activation redirection is most effective in producing controlled outputs that accurately express the model's inability to respond while correctly conveying the underlying reason, and store selected layers in set $L$

\vspace{0.5em} 

%
\STATE \textbf{Procedure 3: Optimize MLP down-projection in the selected layer to implement the desired recalibration}
\FOR{each epoch}
    \FOR{each selected layer $l \in L$, initial the weight as $w_{\text{base}}$}
        \STATE calculate loss: 
        \STATE $\mathcal{L}_\text{\lunar} = \mathbb{E}_{D_f}|| \mathbf{a} - \mathbf{a'}_{f}^{(l)}(x) ||_2, \text{if } x \in D_f $
        \STATE $\mathcal{L}_\text{\lunar} = \mathbb{E}_{D_r}|| \mathbf{a} - \mathbf{a}_{r}^{(l)}(x) ||_2, \text{if } x \in D_r$
        \STATE Optimize MLP down-projection with respect to loss on the selected layer
    \ENDFOR
\ENDFOR

\end{algorithmic}\label{algo:1}
\end{algorithm}
