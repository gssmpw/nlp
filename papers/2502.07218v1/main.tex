%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{colortbl}
\usepackage{tcolorbox}
\usepackage{array}
\usepackage{color,soul}
\usepackage{siunitx}
\usepackage[flushleft]{threeparttable}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{cancel}
\usepackage{subcaption} % For subfigures
\usepackage{tabularx}
\usepackage{soul} % For text highlighting
\usepackage{url}
%\usepackage{xcolor}
\usepackage[normalem]{ulem}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\usepackage{xspace} % NEW
\newcommand{\lunar}{\texttt{LUNAR}\xspace} % NEW

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{LUNAR: LLM Unlearning via Neural Activation Redirection}

\begin{document}

\twocolumn[
\icmltitle{LUNAR: LLM Unlearning via Neural Activation Redirection}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{William F. Shen}{equal,cam}
\icmlauthor{Xinchi Qiu}{equal,cam}
\icmlauthor{Meghdad Kurmanji}{cam}
\icmlauthor{Alex Iacob}{cam}
\icmlauthor{Lorenzo Sani}{cam}
\icmlauthor{Yihong Chen}{ucl}

\icmlauthor{Nicola Cancedda \textsuperscript{†}}{meta}
\icmlauthor{Nicholas D. Lane \textsuperscript{†}}{cam}

\end{icmlauthorlist}

\icmlaffiliation{cam}{Department of Computer Science and Technology, University of Cambridge}
\icmlaffiliation{meta}{FAIR, Meta. Nicola Cancedda served in an advisory role}
\icmlaffiliation{ucl}{UCL Centre of Artificial Intelligence}

\icmlcorrespondingauthor{William F. Shen}{fs604@cam.ac.uk}
% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, LLM, Unlearning}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Large Language Models (LLMs) benefit from training on ever larger amounts of textual data, but as a result, they increasingly incur the risk of leaking private information. The ability to selectively remove knowledge from LLMs is, therefore, a highly desirable capability. In this paper, we propose \lunar, a novel unlearning methodology grounded in the \textit{Linear Representation Hypothesis}. \lunar operates by redirecting the representations of unlearned data to regions that trigger the model’s inherent ability to express its inability to answer. \lunar achieves state-of-the-art unlearning performance while significantly enhancing the controllability of the unlearned model during inference. Specifically, \lunar achieves between \textbf{$2.9 \times$} to \textbf{$11.7 \times$} improvements on combined `unlearning efficacy' and `model utility' score (`Deviation Score') on the PISTOL dataset across various base models. We also demonstrate, through quantitative analysis and qualitative examples, \lunar's superior controllability in generating coherent and contextually aware responses, mitigating undesired side effects of existing methods. Moreover, we demonstrate that \lunar is robust against white-box adversarial attacks and versatile in handling real-world scenarios, such as processing sequential unlearning requests. 
\end{abstract}

\input{section/1_intro}
\input{section/3_method}
\input{section/4_exp}
\input{section/related}
\input{section/5_conclusion}

\newpage

\section*{Impact Statement}

This paper is motivated by the social consequences of recent advances in the field of machine learning and large language models (LLMs). LLMs have made significant strides by pre-training on and memorizing vast amounts of textual data. However, this process can raise privacy concerns and potentially violate data protection regulations. Consequently, the ability to efficiently remove data related to individual users from these models, without compromising their predictive quality, is becoming increasingly important.

We aim to provide a better and more efficient method to tackle this problem and enhance privacy considerations in this field.

Overall, we believe the potential positive social benefits of our work in LLM unlearning outweigh the potential negatives, which stem primarily from misuse.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
%\nocite{langley00}

%\bibliography{reference}
\bibliographystyle{icml2025}

\begin{thebibliography}{66}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdali et~al.(2024)Abdali, Anarfi, Barberan, and He]{abdali2024decoding}
Abdali, S., Anarfi, R., Barberan, C., and He, J.
\newblock Decoding the ai pen: Techniques and challenges in detecting ai-generated text.
\newblock \emph{arXiv preprint arXiv:2403.05750}, 2024.

\bibitem[Achiam et~al.(2023)Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman, Almeida, Altenschmidt, Altman, Anadkat, et~al.]{gpt4}
Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F.~L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et~al.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Arditi et~al.(2024{\natexlab{a}})Arditi, Obeso, Syed, Paleka, Panickssery, Gurnee, and Nanda]{single_direction}
Arditi, A., Obeso, O., Syed, A., Paleka, D., Panickssery, N., Gurnee, W., and Nanda, N.
\newblock Refusal in language models is mediated by a single direction.
\newblock \emph{arXiv preprint arXiv:2406.11717}, 2024{\natexlab{a}}.

\bibitem[Arditi et~al.(2024{\natexlab{b}})Arditi, Obeso, Syed, Paleka, Rimsky, Gurnee, and Nanda]{arditi2024refusal}
Arditi, A., Obeso, O., Syed, A., Paleka, D., Rimsky, N., Gurnee, W., and Nanda, N.
\newblock Refusal in language models is mediated by a single direction.
\newblock \emph{arXiv preprint arXiv:2406.11717}, 2024{\natexlab{b}}.

\bibitem[Barrett et~al.(2023)Barrett, Boyd, Bursztein, Carlini, Chen, Choi, Chowdhury, Christodorescu, Datta, Feizi, et~al.]{barrett2023identifying}
Barrett, C., Boyd, B., Bursztein, E., Carlini, N., Chen, B., Choi, J., Chowdhury, A.~R., Christodorescu, M., Datta, A., Feizi, S., et~al.
\newblock Identifying and mitigating the security risks of generative ai.
\newblock \emph{Foundations and Trends{\textregistered} in Privacy and Security}, 6\penalty0 (1):\penalty0 1--52, 2023.

\bibitem[Bender et~al.(2021)Bender, Gebru, McMillan-Major, and Shmitchell]{bender2021dangers}
Bender, E.~M., Gebru, T., McMillan-Major, A., and Shmitchell, S.
\newblock On the dangers of stochastic parrots: Can language models be too big?
\newblock In \emph{Proceedings of the 2021 ACM conference on fairness, accountability, and transparency}, pp.\  610--623, 2021.

\bibitem[Blanco-Justicia et~al.(2025)Blanco-Justicia, Jebreel, Manzanares-Salor, S{\'a}nchez, Domingo-Ferrer, Collell, and Eeik~Tan]{blanco2025digital}
Blanco-Justicia, A., Jebreel, N., Manzanares-Salor, B., S{\'a}nchez, D., Domingo-Ferrer, J., Collell, G., and Eeik~Tan, K.
\newblock Digital forgetting in large language models: A survey of unlearning methods.
\newblock \emph{Artificial Intelligence Review}, 58\penalty0 (3):\penalty0 90, 2025.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{gpt}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Chen \& Yang(2023)Chen and Yang]{chen2023unlearn}
Chen, J. and Yang, D.
\newblock Unlearn what you want to forget: Efficient unlearning for llms.
\newblock \emph{arXiv preprint arXiv:2310.20150}, 2023.

\bibitem[Chen et~al.(2020)Chen, Ghoshal, Mehdad, Zettlemoyer, and Gupta]{chen2020low}
Chen, X., Ghoshal, A., Mehdad, Y., Zettlemoyer, L., and Gupta, S.
\newblock Low-resource domain adaptation for compositional task-oriented semantic parsing.
\newblock \emph{arXiv preprint arXiv:2010.03546}, 2020.

\bibitem[Chen et~al.(2024)Chen, Xu, Lu, Stenetorp, and Franceschi]{chen2024jetexpansionsresidualcomputation}
Chen, Y., Xu, X., Lu, Y., Stenetorp, P., and Franceschi, L.
\newblock Jet expansions of residual computation.
\newblock \emph{arXiv preprint arXiv:2410.06024}, 2024.

\bibitem[Conneau et~al.(2019)Conneau, Khandelwal, Goyal, Chaudhary, Wenzek, Guzman, Grave, Ott, Zettlemoyer, and Stoyanov]{cc100}
Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzman, F., Grave, E., Ott, M., Zettlemoyer, L., and Stoyanov, V.
\newblock Unsupervised cross-lingual representation learning at scale.
\newblock \emph{arXiv preprint arXiv:1911.02116}, 2019.

\bibitem[Dwivedi \& Bresson(2020)Dwivedi and Bresson]{dwivedi2020generalization}
Dwivedi, V.~P. and Bresson, X.
\newblock A generalization of transformer networks to graphs.
\newblock \emph{arXiv preprint arXiv:2012.09699}, 2020.

\bibitem[Elhage et~al.(2022)Elhage, Hume, Olsson, Schiefer, Henighan, Kravec, Hatfield-Dodds, Lasenby, Drain, Chen, et~al.]{elhage2022toy}
Elhage, N., Hume, T., Olsson, C., Schiefer, N., Henighan, T., Kravec, S., Hatfield-Dodds, Z., Lasenby, R., Drain, D., Chen, C., et~al.
\newblock Toy models of superposition.
\newblock \emph{arXiv preprint arXiv:2209.10652}, 2022.

\bibitem[Elhoushi et~al.(2024)Elhoushi, Shrivastava, Liskovich, Hosmer, Wasti, Lai, Mahmoud, Acun, Agarwal, Roman, et~al.]{elhoushi-etal-2024-layerskip}
Elhoushi, M., Shrivastava, A., Liskovich, D., Hosmer, B., Wasti, B., Lai, L., Mahmoud, A., Acun, B., Agarwal, S., Roman, A., et~al.
\newblock Layer skip: Enabling early exit inference and self-speculative decoding.
\newblock \emph{arXiv preprint arXiv:2404.16710}, 2024.

\bibitem[Fan et~al.(2020)Fan, Grave, and Joulin]{Fan2020Reducing}
Fan, A., Grave, E., and Joulin, A.
\newblock Reducing transformer depth on demand with structured dropout.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Fan et~al.(2024)Fan, Jiang, Li, Meng, Han, Shang, Sun, Wang, and Wang]{fan2024not}
Fan, S., Jiang, X., Li, X., Meng, X., Han, P., Shang, S., Sun, A., Wang, Y., and Wang, Z.
\newblock Not all layers of llms are necessary during inference.
\newblock \emph{arXiv preprint arXiv:2403.02181}, 2024.

\bibitem[Farquhar et~al.(2024)Farquhar, Kossen, Kuhn, and Gal]{farquhar2024detecting}
Farquhar, S., Kossen, J., Kuhn, L., and Gal, Y.
\newblock Detecting hallucinations in large language models using semantic entropy.
\newblock \emph{Nature}, 630\penalty0 (8017):\penalty0 625--630, 2024.

\bibitem[GDPR()]{gdpr17}
GDPR.
\newblock Right to erasure (‘right to be forgotten’).
\newblock The New York Times,\url{https://gdpr-info.eu/art-17-gdpr/}.

\bibitem[Grosse et~al.(2023)Grosse, Bae, Anil, Elhage, Tamkin, Tajdini, Steiner, Li, Durmus, Perez, et~al.]{grosse2023studying}
Grosse, R., Bae, J., Anil, C., Elhage, N., Tamkin, A., Tajdini, A., Steiner, B., Li, D., Durmus, E., Perez, E., et~al.
\newblock Studying large language model generalization with influence functions.
\newblock \emph{arXiv preprint arXiv:2308.03296}, 2023.

\bibitem[Hernandez et~al.(2023)Hernandez, Li, and Andreas]{hernandez2023inspecting}
Hernandez, E., Li, B.~Z., and Andreas, J.
\newblock Inspecting and editing knowledge representations in language models.
\newblock \emph{arXiv preprint arXiv:2304.00740}, 2023.

\bibitem[Huang et~al.(2023)Huang, Gupta, Xia, Li, and Chen]{huang2023catastrophic}
Huang, Y., Gupta, S., Xia, M., Li, K., and Chen, D.
\newblock Catastrophic jailbreak of open-source llms via exploiting generation.
\newblock \emph{arXiv preprint arXiv:2310.06987}, 2023.

\bibitem[Ilharco et~al.(2022)Ilharco, Ribeiro, Wortsman, Schmidt, Hajishirzi, and Farhadi]{ilharco2022editing}
Ilharco, G., Ribeiro, M.~T., Wortsman, M., Schmidt, L., Hajishirzi, H., and Farhadi, A.
\newblock Editing models with task arithmetic.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2022.

\bibitem[Jang et~al.(2022)Jang, Yoon, Yang, Cha, Lee, Logeswaran, and Seo]{jang2022knowledge}
Jang, J., Yoon, D., Yang, S., Cha, S., Lee, M., Logeswaran, L., and Seo, M.
\newblock Knowledge unlearning for mitigating privacy risks in language models.
\newblock \emph{arXiv preprint arXiv:2210.01504}, 2022.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei]{kaplanscalinglaws}
Kaplan, J., McCandlish, S., Henighan, T., Brown, T.~B., Chess, B., Child, R., Gray, S., Radford, A., Wu, J., and Amodei, D.
\newblock Scaling laws for neural language models.
\newblock \emph{CoRR}, abs/2001.08361, 2020.

\bibitem[Kotek et~al.(2023)Kotek, Dockum, and Sun]{kotek2023gender}
Kotek, H., Dockum, R., and Sun, D.
\newblock Gender bias and stereotypes in large language models.
\newblock In \emph{Proceedings of The ACM Collective Intelligence Conference}, pp.\  12--24, 2023.

\bibitem[Kurmanji et~al.(2024)Kurmanji, Triantafillou, Hayes, and Triantafillou]{kurmanji2024towards}
Kurmanji, M., Triantafillou, P., Hayes, J., and Triantafillou, E.
\newblock Towards unbounded machine unlearning.
\newblock \emph{Advances in neural information processing systems}, 36, 2024.

\bibitem[Lermen et~al.(2023)Lermen, Rogers-Smith, and Ladish]{lermen2023lora}
Lermen, S., Rogers-Smith, C., and Ladish, J.
\newblock Lora fine-tuning efficiently undoes safety training in llama 2-chat 70b.
\newblock \emph{arXiv preprint arXiv:2310.20624}, 2023.

\bibitem[Lin(2004)]{lin2004rouge}
Lin, C.-Y.
\newblock Rouge: A package for automatic evaluation of summaries.
\newblock In \emph{Text summarization branches out}, pp.\  74--81, 2004.

\bibitem[Liu et~al.(2022)Liu, Liu, and Stone]{liu2022continual}
Liu, B., Liu, Q., and Stone, P.
\newblock Continual learning and private unlearning.
\newblock In \emph{Conference on Lifelong Learning Agents}, pp.\  243--254. PMLR, 2022.

\bibitem[Liu et~al.(2024)Liu, Yao, Jia, Casper, Baracaldo, Hase, Xu, Yao, Li, Varshney, et~al.]{liu2024rethinking}
Liu, S., Yao, Y., Jia, J., Casper, S., Baracaldo, N., Hase, P., Xu, X., Yao, Y., Li, H., Varshney, K.~R., et~al.
\newblock Rethinking machine unlearning for large language models.
\newblock \emph{arXiv preprint arXiv:2402.08787}, 2024.

\bibitem[Liu et~al.(2023)Liu, Xu, Chen, and Xiao]{liu2023autodan}
Liu, X., Xu, N., Chen, M., and Xiao, C.
\newblock Autodan: Generating stealthy jailbreak prompts on aligned large language models.
\newblock \emph{arXiv preprint arXiv:2310.04451}, 2023.

\bibitem[Maini et~al.(2024)Maini, Feng, Schwarzschild, Lipton, and Kolter]{tofu}
Maini, P., Feng, Z., Schwarzschild, A., Lipton, Z.~C., and Kolter, J.~Z.
\newblock Tofu: A task of fictitious unlearning for llms.
\newblock \emph{arXiv preprint arXiv:2401.06121}, 2024.

\bibitem[Mao et~al.(2024)Mao, Ge, Fan, Xu, Mi, Hu, and Gao]{mao2024surveylora}
Mao, Y., Ge, Y., Fan, Y., Xu, W., Mi, Y., Hu, Z., and Gao, Y.
\newblock A survey on lora of large language models.
\newblock \emph{Frontiers of Computer Science}, 19\penalty0 (7), December 2024.
\newblock ISSN 2095-2236.
\newblock \doi{10.1007/s11704-024-40663-9}.
\newblock URL \url{http://dx.doi.org/10.1007/s11704-024-40663-9}.

\bibitem[Marks \& Tegmark(2023)Marks and Tegmark]{marks2023geometry}
Marks, S. and Tegmark, M.
\newblock The geometry of truth: Emergent linear structure in large language model representations of true/false datasets.
\newblock \emph{arXiv preprint arXiv:2310.06824}, 2023.

\bibitem[Meade et~al.(2024)Meade, Patel, and Reddy]{meade2024universal}
Meade, N., Patel, A., and Reddy, S.
\newblock Universal adversarial triggers are not universal.
\newblock \emph{arXiv preprint arXiv:2404.16020}, 2024.

\bibitem[Meng et~al.(2022)Meng, Bau, Andonian, and Belinkov]{meng2022locating}
Meng, K., Bau, D., Andonian, A., and Belinkov, Y.
\newblock Locating and editing factual associations in gpt.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 17359--17372, 2022.

\bibitem[Mikolov et~al.(2013)Mikolov, Yih, and Zweig]{mikolov2013linguistic}
Mikolov, T., Yih, W.-t., and Zweig, G.
\newblock Linguistic regularities in continuous space word representations.
\newblock In \emph{Proceedings of the 2013 conference of the north american chapter of the association for computational linguistics: Human language technologies}, pp.\  746--751, 2013.

\bibitem[Motoki et~al.(2023)Motoki, Pinho~Neto, and Rodrigues]{motoki2023more}
Motoki, F., Pinho~Neto, V., and Rodrigues, V.
\newblock More human than human: Measuring chatgpt political bias.
\newblock \emph{Public Choice}, pp.\  1--21, 2023.

\bibitem[Nasr et~al.(2023)Nasr, Carlini, Hayase, Jagielski, Cooper, Ippolito, Choquette-Choo, Wallace, Tram{\`e}r, and Lee]{nasr2023scalable}
Nasr, M., Carlini, N., Hayase, J., Jagielski, M., Cooper, A.~F., Ippolito, D., Choquette-Choo, C.~A., Wallace, E., Tram{\`e}r, F., and Lee, K.
\newblock Scalable extraction of training data from (production) language models.
\newblock \emph{arXiv preprint arXiv:2311.17035}, 2023.

\bibitem[Nguyen et~al.(2022)Nguyen, Huynh, Nguyen, Liew, Yin, and Nguyen]{nguyen2022survey}
Nguyen, T.~T., Huynh, T.~T., Nguyen, P.~L., Liew, A. W.-C., Yin, H., and Nguyen, Q. V.~H.
\newblock A survey of machine unlearning.
\newblock \emph{arXiv preprint arXiv:2209.02299}, 2022.

\bibitem[Panickssery et~al.(2023)Panickssery, Gabrieli, Schulz, Tong, Hubinger, and Turner]{panickssery2023steering}
Panickssery, N., Gabrieli, N., Schulz, J., Tong, M., Hubinger, E., and Turner, A.~M.
\newblock Steering llama 2 via contrastive activation addition.
\newblock \emph{arXiv preprint arXiv:2312.06681}, 2023.

\bibitem[Park et~al.(2023)Park, Choe, and Veitch]{park2023linear}
Park, K., Choe, Y.~J., and Veitch, V.
\newblock The linear representation hypothesis and the geometry of large language models.
\newblock \emph{arXiv preprint arXiv:2311.03658}, 2023.

\bibitem[Qi et~al.(2023)Qi, Zeng, Xie, Chen, Jia, Mittal, and Henderson]{qi2023fine}
Qi, X., Zeng, Y., Xie, T., Chen, P.-Y., Jia, R., Mittal, P., and Henderson, P.
\newblock Fine-tuning aligned language models compromises safety, even when users do not intend to!
\newblock \emph{arXiv preprint arXiv:2310.03693}, 2023.

\bibitem[Qiu et~al.(2024)Qiu, Shen, Chen, Cancedda, Stenetorp, and Lane]{qiu2024pistol}
Qiu, X., Shen, W.~F., Chen, Y., Cancedda, N., Stenetorp, P., and Lane, N.~D.
\newblock Pistol: Dataset compilation pipeline for structural unlearning of llms.
\newblock \emph{arXiv preprint arXiv:2406.16810}, 2024.

\bibitem[Rafailov et~al.(2024)Rafailov, Sharma, Mitchell, Manning, Ermon, and Finn]{rafailov2024direct}
Rafailov, R., Sharma, A., Mitchell, E., Manning, C.~D., Ermon, S., and Finn, C.
\newblock Direct preference optimization: Your language model is secretly a reward model.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Ravfogel et~al.(2020)Ravfogel, Elazar, Gonen, Twiton, and Goldberg]{ravfogel2020null}
Ravfogel, S., Elazar, Y., Gonen, H., Twiton, M., and Goldberg, Y.
\newblock Null it out: Guarding protected attributes by iterative nullspace projection.
\newblock \emph{arXiv preprint arXiv:2004.07667}, 2020.

\bibitem[RD()]{llm_cost}
RD, L.~J.
\newblock Llm large language model cost analysis.
\newblock Medium Blog post,\url{https://lajavaness.medium.com/}\\\url{llm-large-language-model-cost-analysis}\\\url{-d5022bb43e9e}.

\bibitem[Robey et~al.(2023)Robey, Wong, Hassani, and Pappas]{robey2023smoothllm}
Robey, A., Wong, E., Hassani, H., and Pappas, G.~J.
\newblock Smoothllm: Defending large language models against jailbreaking attacks.
\newblock \emph{arXiv preprint arXiv:2310.03684}, 2023.

\bibitem[Sekhari et~al.(2021)Sekhari, Acharya, Kamath, and Suresh]{sekhari2021remember}
Sekhari, A., Acharya, J., Kamath, G., and Suresh, A.~T.
\newblock Remember what you want to forget: Algorithms for machine unlearning.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 18075--18086, 2021.

\bibitem[Shumailov et~al.(2024)Shumailov, Hayes, Triantafillou, Ortiz-Jimenez, Papernot, Jagielski, Yona, Howard, and Bagdasaryan]{shumailov2024ununlearning}
Shumailov, I., Hayes, J., Triantafillou, E., Ortiz-Jimenez, G., Papernot, N., Jagielski, M., Yona, I., Howard, H., and Bagdasaryan, E.
\newblock Ununlearning: Unlearning is not sufficient for content regulation in advanced generative ai.
\newblock \emph{arXiv preprint arXiv:2407.00106}, 2024.

\bibitem[Stickland et~al.(2024)Stickland, Lyzhov, Pfau, Mahdi, and Bowman]{stickland2024steering}
Stickland, A.~C., Lyzhov, A., Pfau, J., Mahdi, S., and Bowman, S.~R.
\newblock Steering without side effects: Improving post-deployment control of language models.
\newblock \emph{arXiv preprint arXiv:2406.15518}, 2024.

\bibitem[Thaker et~al.(2024)Thaker, Hu, Kale, Maurya, Wu, and Smith]{thaker2024position}
Thaker, P., Hu, S., Kale, N., Maurya, Y., Wu, Z.~S., and Smith, V.
\newblock Position: Llm unlearning benchmarks are weak measures of progress.
\newblock \emph{arXiv preprint arXiv:2410.02879}, 2024.

\bibitem[Tigges et~al.(2023)Tigges, Hollinsworth, Geiger, and Nanda]{tigges2023linear}
Tigges, C., Hollinsworth, O.~J., Geiger, A., and Nanda, N.
\newblock Linear representations of sentiment in large language models.
\newblock \emph{arXiv preprint arXiv:2310.15154}, 2023.

\bibitem[Veit et~al.(2016)Veit, Wilber, and Belongie]{NIPS2016_37bc2f75}
Veit, A., Wilber, M.~J., and Belongie, S.
\newblock Residual networks behave like ensembles of relatively shallow networks.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Wang et~al.(2024)Wang, Han, Yang, Zhu, Liu, and Sugiyama]{wang2024unlearning}
Wang, Q., Han, B., Yang, P., Zhu, J., Liu, T., and Sugiyama, M.
\newblock Unlearning with control: Assessing real-world utility for large language model unlearning.
\newblock \emph{arXiv preprint arXiv:2406.09179}, 2024.

\bibitem[Wen et~al.(2023)Wen, Ke, Sun, Zhang, Li, Bai, and Huang]{wen2023unveiling}
Wen, J., Ke, P., Sun, H., Zhang, Z., Li, C., Bai, J., and Huang, M.
\newblock Unveiling the implicit toxicity in large language models.
\newblock \emph{arXiv preprint arXiv:2311.17391}, 2023.

\bibitem[Wenzek et~al.(2019)Wenzek, Lachaux, Conneau, Chaudhary, Guzm{\'a}n, Joulin, and Grave]{wenzek2019ccnet}
Wenzek, G., Lachaux, M.-A., Conneau, A., Chaudhary, V., Guzm{\'a}n, F., Joulin, A., and Grave, E.
\newblock Ccnet: Extracting high quality monolingual datasets from web crawl data.
\newblock \emph{arXiv preprint arXiv:1911.00359}, 2019.

\bibitem[Wolf et~al.(2024)Wolf, Wies, Shteyman, Rothberg, Levine, and Shashua]{wolf2024tradeoffs}
Wolf, Y., Wies, N., Shteyman, D., Rothberg, B., Levine, Y., and Shashua, A.
\newblock Tradeoffs between alignment and helpfulness in language models.
\newblock \emph{arXiv preprint arXiv:2401.16332}, 2024.

\bibitem[Yao et~al.(2023)Yao, Xu, and Liu]{yao2023large}
Yao, Y., Xu, X., and Liu, Y.
\newblock Large language model unlearning.
\newblock \emph{arXiv preprint arXiv:2310.10683}, 2023.

\bibitem[Zhang et~al.(2023)Zhang, Liu, He, et~al.]{zhang2023composing}
Zhang, J., Liu, J., He, J., et~al.
\newblock Composing parameter-efficient modules with arithmetic operation.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 12589--12610, 2023.

\bibitem[Zhang et~al.(2024{\natexlab{a}})Zhang, Lin, Bai, and Mei]{npo}
Zhang, R., Lin, L., Bai, Y., and Mei, S.
\newblock Negative preference optimization: From catastrophic collapse to effective unlearning.
\newblock \emph{arXiv preprint arXiv:2404.05868}, 2024{\natexlab{a}}.

\bibitem[Zhang et~al.(2024{\natexlab{b}})Zhang, Lin, Bai, and Mei]{zhang2024negative}
Zhang, R., Lin, L., Bai, Y., and Mei, S.
\newblock Negative preference optimization: From catastrophic collapse to effective unlearning.
\newblock \emph{arXiv preprint arXiv:2404.05868}, 2024{\natexlab{b}}.

\bibitem[Zhang et~al.(2024{\natexlab{c}})Zhang, Wang, Li, Wu, Tang, Liu, He, Yin, and Wang]{zhang2024does}
Zhang, Z., Wang, F., Li, X., Wu, Z., Tang, X., Liu, H., He, Q., Yin, W., and Wang, S.
\newblock Does your llm truly unlearn? an embarrassingly simple approach to recover unlearned knowledge.
\newblock \emph{arXiv preprint arXiv:2410.16454}, 2024{\natexlab{c}}.

\bibitem[Zheng et~al.(2024)Zheng, Yin, Zhou, Meng, Zhou, Chang, Huang, and Peng]{zheng2024prompt}
Zheng, C., Yin, F., Zhou, H., Meng, F., Zhou, J., Chang, K.-W., Huang, M., and Peng, N.
\newblock On prompt-driven safeguarding for large language models.
\newblock In \emph{Forty-first International Conference on Machine Learning}, 2024.

\bibitem[Zou et~al.(2023)Zou, Phan, Chen, Campbell, Guo, Ren, Pan, Yin, Mazeika, Dombrowski, et~al.]{zou2023representation}
Zou, A., Phan, L., Chen, S., Campbell, J., Guo, P., Ren, R., Pan, A., Yin, X., Mazeika, M., Dombrowski, A.-K., et~al.
\newblock Representation engineering: A top-down approach to ai transparency.
\newblock \emph{arXiv preprint arXiv:2310.01405}, 2023.

\end{thebibliography}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\input{section/99_appendix}


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
