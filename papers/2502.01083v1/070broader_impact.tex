
% \section*{Ethics Statement}
% Our research focuses on mitigating dataset biases in NLP datasets. There are no specific ethical concerns directly associated with this work. However, we recognize the broader ethical considerations that apply to NLP research. 

\section*{Impact Statement}
Our work investigates the security implications of tool-augmented Large Language Models (LLMs), where we focus on the risks that arise from integrating external tools, and the necessity ability to remove these acquired tools. 
A key concern is ensuring compliance with privacy regulations, such as the Right to be Forgotten (RTBF), which mandates the removal of specific data upon user request. In the context of tool-augmented LLMs, this necessitates the ability to delete sensitive, regulated, or outdated information related to specific tools. 
By examining how LLMs interact with and rely on external tools, potential threats to model security can be identified, e.g. unauthorized tool usage, adversarial exploitation, and privacy violations. Our research highlights the critical importance of addressing these challenges.
