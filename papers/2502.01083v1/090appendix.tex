\section{Practical Use Cases of Tool Unlearning}\label{sec:example}
We provide several examples in which tool unlearning is essential:

\paragraph{Case 1: De-memorize Privacy-Concerned Tools} Imagine a tool-augmented LLM that is deployed in a healthcare system and trained to use APIs for handling and processing patient data, such as accessing medical records or generating anonymized reports. Suppose one of the APIs that was initially compliant is later flagged as insecure due to a vulnerability that could expose patient data. This violates regulations like HIPAA or GDPR. In this case, ToolDelete is essential as it can update the tool-augmented LLM's parameters to unlearn how to invoke the insecure API. This removes any capability embedded in the LLM's parametric knowledge and prevents adversarial or accidental usage of the vulnerable API.

\paragraph{Case 2: Forget Harmful / Biased Tools} Consider a tool-augmented LLM that can use a Safe For Work diffusion model as a tool to generate images based on user instructions. If the user prompts can fool the model to generate Not Safe For Work (NSFW), harmful, or biased images, this tool should be unlearned from the LLM. Note that even if we augment the LLM with a new and safe version of the diffusion model without unlearning the previous version, the LLM would still be able to call the previous version, which can lead to generating Not Safe For Work, harmful, or biased images. Therefore, we should explicitly erase the ability of using the previous version of the diffusion model from the LLM. 

\paragraph{Case 3: Unlearn Deprecated Tools} Tool unlearning is also essential when a tool has a major update, where the function names and input parameters have changed, e.g. the major update of the Python transformers package from v2 to v4. Without unlearning v2, the tool-augmented LLM may generate erroneous code and bring difficulty for debugging, since many functions have been renamed and removed. Therefore, as the underlying tools evolve, the tool-augmented LLM should be updated through unlearning of the previous versions and augmenting the new ones.


\section{Baselines}\label{sec:baseline}
As there are no prior works on tool unlearning, we adapt the following unlearning methods to tool unlearning setting.
Four general unlearning approaches.
\begin{itemize}
    \item \textbf{\GA}~\citep{Golatkar2020EternalSO,yao-etal-2024-machine} runs gradient ascent on \tf with the associated query-reponse samples $(\mathcal{Q}_f, \mathcal{Y}_f)$.
    \item \textbf{\RL}~\citep{amnesiac_2021} fine-tunes on \tr and \tf with corrupted labels. 
    \item \textbf{\SU}~\citep{fan2024salun} performs \RL on unlearning-related parameters discovered by saliency map. 
    \item \textbf{ICUL}~\citep{icul} uses \tf with corrupted label as in-context demonstrations. 
    \item \textbf{SGA}~\citep{jang-etal-2023-knowledge,barbulescu2024textual}, which performs gradient ascent on \tf whose memorization probability exceeds a pre-defined threshold.
    \item \textbf{TAU}~\citep{barbulescu2024textual}, which performs task arithmetic on SGA.
    \item \textbf{CUT}~\citep{li2024wmdp}.
    \item \textbf{NPO}~\citep{zhang2024negative} uses DPO with only a losing response (i.e. no winning response).
    \item \textbf{SOUL-GradDiff}~\citep{jia-etal-2024-soul} uses second-order information in optimization. It adapts the Sophia optimizer~\citep{liu2024sophia} for LLM unlearning. We adopt the SOUL + GradDiff~\citep{maini2024tofu} implementation in the original paper.
\end{itemize}


\section{Implementation details}
We use a learning rate of $10^{-5}$ across all experiments. All experiments are conducted on 8 NVIDIA A100 GPUs.

For the original models in tool unlearning, we use the \texttt{TangQiaoYu/ToolAlpaca-7B}, \texttt{ToolBench/ToolLLaMA-2-7b-v2}, \texttt{gorilla-llm/gorilla-openfunctions-v0} checkpoints that are publically available on Huggingface.


\section{Additional results}\label{sec:additional_result}
We present the results of LoRA tool unlearning, sequential tool unlearning, time comparison and results on ToolLLaMA and Gorilla in Table~\ref{tab:peft}--\ref{tab:gorilla}.

\begin{table}[t]
\caption{Full parameters vs. LoRA in tool unlearning performances when deleting 20\% of tools on ToolAlpaca. \textit{Original} denotes the tool-augmented LLM prior unlearning and is provided \textit{for reference only}.}
\label{tab:peft}
\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
    \begin{tabular}{l|cccc}
    \toprule
     & $\mathcal{T}_T (\uparrow)$ & $\mathcal{T}_r (\downarrow)$ & $\mathcal{T}_f (\uparrow)$ & $\mathcal{T}_G (\uparrow)$ \\
    \midrule
    \rowcolor{Gray}Original (Prior Un.) 
                        & 60.0 & 73.1 & 75.7 & 24.1 \\
    \midrule
    Full param & 52.7 & 72.1 & 30.5 & 23.6 \\
    \midrule
    LoRA       & 51.5 & 71.8 & 36.1 & 19.9 \\
    \bottomrule
    \end{tabular}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}



\begin{figure*}[t]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\textwidth]{figure/seq.pdf}}
\caption{Performance of sequential unlearning on ToolAlpaca. We unlearn 2\%, 5\%, 10\%, 20\% of tools in a sequential manner.}
\label{fig:seq}
\end{center}
\vskip -0.2in
\end{figure*}


\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[scale=.5]{figure/time.pdf}}
\caption{Training time of \method, which saves 74.8\% of time on average.}
\label{fig:time}
\end{center}
\vskip -0.2in
\end{figure}



\begin{table}
\caption{Performance comparison between with and without having access to the exact training samples.}
\label{tab:no_training_data}
\vskip 0.15in
\begin{center}
\begin{sc}
\begin{tabular}{ccccc}
\toprule
Method & $\mathcal{T}_t (\uparrow)$ & $\mathcal{T}_r (\uparrow)$ & $\mathcal{T}_f (\downarrow)$ & $\mathcal{T}_G (\uparrow)$ \\
\midrule
    \multicolumn{5}{l}{\emph{W/ access to training samples}} \\
    \midrule
    \method-SFT & 52.7 & 72.1 & 30.5 & 23.6 \\
    \method-DPO & 53.4 & 75.1 & 28.7 & 23.1 \\
    \midrule
    \multicolumn{5}{l}{\emph{W/o access to training samples}} \\
    \midrule
    \method-SFT & 52.0 & 72.5 & 30.1 & 22.8 \\
    \method-DPO & 52.9 & 76.0 & 28.0 & 22.5 \\
    \bottomrule
\end{tabular}
\end{sc}
\end{center}
\vskip -0.1in
\end{table}


\begin{table}
\caption{Performance comparison between using pre-trained LLM $f_0$ and randomly initialized LLM $f_R$.}
\label{tab:tool_free}
\vskip 0.15in
\begin{center}
\begin{sc}
\begin{tabular}{ccccc}
\toprule
Method & $\mathcal{T}_t (\uparrow)$ & $\mathcal{T}_r (\uparrow)$ & $\mathcal{T}_f (\downarrow)$ & $\mathcal{T}_G (\uparrow)$ \\
\midrule
    \multicolumn{5}{l}{\emph{Pre-trained LLM weights $f_0$}} \\
    \midrule
    \method-SFT & 52.7 & 72.1 & 30.5 & 23.6 \\
    \method-DPO & 53.4 & 75.1 & 28.7 & 23.1 \\
    \midrule
    \multicolumn{5}{l}{\emph{Randomly initialized LLM $f_R$}} \\
    \midrule
    \method-SFT & 50.9 & 71.3 & 29.8 & 22.7 \\
    \method-DPO & 52.6 & 73.4 & 27.5 & 22.4 \\
    \bottomrule
\end{tabular}
\end{sc}
\end{center}
\vskip -0.1in
\end{table}



\begin{table}[ht]
% \setlength{\tabcolsep}{4pt}
\caption{Tool unlearning performances when deleting 20\% of tools on ToolLLaMA. Best and second best performances are \textbf{bold} and \underline{underlined} respectively. \colorbox{Gray}{Original} denotes the tool-augmented LLM prior unlearning and is provided \colorbox{Gray}{for reference only}.}
\label{tab:tool_llama}
\vskip 0.15in
\begin{center}
\begin{tabular}{l|ccc|ccccc}
\toprule
Method & $\mathcal{T}_T (\uparrow)$ & $\mathcal{T}_r (\uparrow)$ & $\mathcal{T}_f (\downarrow)$ & \multicolumn{5}{c}{General Capability $\mathcal{T}_G (\uparrow)$} \\
                & & & & STEM & Reason & Ins-Follow & Fact & Avg. \\
\midrule
\rowcolor{Gray}Original (Prior Un.) 
             & 64.0 & 75.6 & 76.0 & 25.3 & 36.8 & 17.3 & 15.0 & 23.6 \\
\midrule
\multicolumn{5}{l}{\emph{General Unlearning Methods}} \\
\midrule
\RET & 62.2 & 72.1 & 42.3 & 25.1 & 33.7 & 14.6 & 13.8 & 21.8 \\
\GA  & 42.5 & 56.3 & 51.8 & 14.9 & 26.4 & 11.2 &  8.6 & 15.3 \\
\RL  & 59.3 & 73.5 & 40.7 & 23.4 & 30.6 & 13.3 & 12.7 & 20.0 \\
\SU  & 58.7 & 73.6 & 39.9 & 22.7 & 30.8 & 13.6 & 12.0 & 19.8 \\
\midrule
\multicolumn{5}{l}{\emph{LLM-Specific Unlearning Methods}} \\
\midrule
ICUL           & 46.2 & 68.2 & 57.2 & 15.1 & 18.8 &  7.1 &  9.4 & 12.6 \\
SGA            & 44.7 & 59.6 & 49.4 & 16.3 & 20.4 & 12.8 &  9.7 & 14.8 \\
TAU            & 44.5 & 56.3 & 50.2 & 21.6 & 28.0 & 15.3 & 13.5 & 19.6 \\
CUT            & 52.4 & 59.5 & 44.2 & 20.7 & 24.1 & 13.7 & 12.8 & 17.8 \\
NPO            & 58.3 & 66.3 & 40.2 & 23.0 & 31.7 & 15.4 & 11.9 & 20.5 \\
SOUL-GradDiff  & 62.2 & 70.4 & 40.7 & 24.2 & 28.6 & 14.7 & 12.2 & 19.9 \\
\midrule
\method-SFT & \underline{62.8} & \underline{72.8} & \underline{39.5} & 24.6 & 33.4 & 15.8 & 13.7 & \textbf{21.9} \\
\method-DPO & \textbf{63.2} & \textbf{73.6} & \textbf{38.7} &          24.3 & 32.9 & 16.0 & 13.8 & \underline{21.8} \\
\bottomrule
\end{tabular}
\end{center}
\vskip -0.1in
\end{table}

\begin{table}[ht]
% \setlength{\tabcolsep}{4pt}
\caption{Tool unlearning performances when deleting 20\% of tools on ToolLLaMA. Best and second best performances are \textbf{bold} and \underline{underlined} respectively. \colorbox{Gray}{Original} denotes the tool-augmented LLM prior unlearning and is provided \colorbox{Gray}{for reference only}.}
\label{tab:gorilla}
\vskip 0.15in
\begin{center}
\begin{tabular}{l|ccc|ccccc}
\toprule
Method & $\mathcal{T}_T (\uparrow)$ & $\mathcal{T}_r (\uparrow)$ & $\mathcal{T}_f (\downarrow)$ & \multicolumn{5}{c}{General Capability $\mathcal{T}_G (\uparrow)$} \\
                & & & & STEM & Reason & Ins-Follow & Fact & Avg. \\
\midrule
\rowcolor{Gray}Original (Prior Un.) 
             & 64.0 & 75.6 & 76.0 & 25.3 & 36.8 & 17.3 & 15.0 & 23.6 \\
\midrule
\multicolumn{5}{l}{\emph{General Unlearning Methods}} \\
\midrule
\RET & 62.2 & 72.1 & 42.3 & 25.1 & 33.7 & 14.6 & 13.8 & 21.8 \\
\GA  & 42.5 & 56.3 & 51.8 & 14.9 & 26.4 & 11.2 &  8.6 & 15.3 \\
\RL  & 59.3 & 73.5 & 40.7 & 23.4 & 30.6 & 13.3 & 12.7 & 20.0 \\
\SU  & 58.7 & 73.6 & 39.9 & 22.7 & 30.8 & 13.6 & 12.0 & 19.8 \\
\midrule
\multicolumn{5}{l}{\emph{LLM-Specific Unlearning Methods}} \\
\midrule
ICUL           & 46.2 & 68.2 & 57.2 & 15.1 & 18.8 &  7.1 &  9.4 & 12.6 \\
SGA            & 44.7 & 59.6 & 49.4 & 16.3 & 20.4 & 12.8 &  9.7 & 14.8 \\
TAU            & 44.5 & 56.3 & 50.2 & 21.6 & 28.0 & 15.3 & 13.5 & 19.6 \\
CUT            & 52.4 & 59.5 & 44.2 & 20.7 & 24.1 & 13.7 & 12.8 & 17.8 \\
NPO            & 58.3 & 66.3 & 40.2 & 23.0 & 31.7 & 15.4 & 11.9 & 20.5 \\
SOUL-GradDiff  & 62.2 & 70.4 & 40.7 & 24.2 & 28.6 & 14.7 & 12.2 & 19.9 \\
\midrule
\method-SFT & \underline{62.8} & \underline{72.8} & \underline{39.5} & 24.6 & 33.4 & 15.8 & 13.7 & \textbf{21.9} \\
\method-DPO & \textbf{63.2} & \textbf{73.6} & \textbf{38.7} &          24.3 & 32.9 & 16.0 & 13.8 & \underline{21.8} \\
\bottomrule
\end{tabular}
\end{center}
\vskip -0.1in
\end{table}


\section{Sampling of Shadow Samples for LiRA-Tool}\label{sec:prompt_shadow_sample}

We use the following prompt to prompt GPT-4 to synthesize diverse shadow samples for evaluation with LiRA-Tool.

\begin{bluebox}
You are now a synthetic data generator. Generate query-response pairs to evaluate an LLM's ability of using an API. 

How to generate "query": Based on the API and documentation shown below, think of a user query that needs to be answered by calling the API. 

How to generate "response": Write down the correct API call with correct arguments. 

The in-context examples below demonstrate what you need to generate. Please be as diverse and creative as possible in phrasing and style. But do not hallucinate.

\#\# In-context Examples 
\#\#\#\# Tool and Documentation 
Name: StableDiffusionPipeline.from\_pretrained() 

\#\#\#\# Query
I want to see some cats dancing in celebration!

\#\#\#\# Response
API call: StableDiffusionPipelin e.from\_pretrained("stabilityai/stable-diffusion-2-1")


Now, for the following API, generate a query-response pair.

\#\#\#\# Tool and Documentation
api\_name()

\#\#\#\# Query

\#\#\#\# Response 
\end{bluebox}