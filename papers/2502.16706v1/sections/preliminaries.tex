\section{Preliminaries}

\begin{figure*}
    \vspace{-0.2cm}
    \centering
    \includegraphics[width=0.75\textwidth]{graphics/neurips_third-01}
    \vspace{-0.3cm}
    \caption{\textbf{Comparison of different automatic decomposition methods} based on step size determination.}
    \label{fig:decomp_comparison}\vspace{-0.4cm}
\end{figure*}

\subsection{Problem Setting}


We consider a reasoning and code generation setting where a dataset $\mathcal{X} = \{\boldsymbol{x}^{(i)}\}_{i=1}^{N}$ consists of problem prompts $\boldsymbol{x}$, and a reward model $R: \mathcal{X} \cdot \mathcal{Y} \rightarrow [0,1]$ evaluates generated solutions $\boldsymbol{y} \in \mathcal{Y}$. This includes program synthesis, where correctness is verified using ground-truth tests~\citep{chen2021evaluating, austin2021program}, and mathematical reasoning, where solutions are validated numerically~\citep{hendrycks2021measuring, cobbe2021training}. The reward model can be a ground-truth verifier, a trained heuristic~\citep{zhang2024generativeverifiersrewardmodeling}, self-consistency~\citep{wang2023selfconsistency}, or an LLM-as-a-judge~\citep{zheng2023judgingllmasajudgemtbenchchatbot}. Since our focus is on step decomposition rather than verification, we use the ground-truth reward model where available. We assume access to a pretrained language model $\pi$ that generates text autoregressively. A generated response $\boldsymbol{y}$ consists of both the final solution and the reasoning chain leading to it, and can be represented as a sequence of tokens $\boldsymbol{y} = (y_0, ..., y_{L_{\boldsymbol{y}}})$. Additionally, solutions can be partitioned into \textbf{solution steps} $\boldsymbol{y} = (\boldsymbol{y}_0, ..., \boldsymbol{y}_K)$, where each step $\boldsymbol{y}_i$ is a contiguous string of tokens. A \textbf{partial solution} up to step $k$ is defined as $\boldsymbol{y}_{1...k} := \boldsymbol{y}_1 \cdot \boldsymbol{y}_2 \cdot ... \cdot \boldsymbol{y}_k$, and its \textbf{rollout} or \textbf{completion}, denoted $\boldsymbol{y}_{1...k+}$, is the continuation generated by $\pi$ until an end-of-sequence token (\textsc{EOS}). The \textbf{size} of a solution step, $|\boldsymbol{y}_i|$, refers to its length in tokens or characters.


% \subsection{Problem setting}
% \begin{figure*}\vspace{-0.2cm}
%     \centering
%     \includegraphics[width=0.75\textwidth]{graphics/neurips_third-01.png}
%     \vskip -0.1in
%     \caption{\textbf{Comparison of different automatic decomposition methods,} with different ways of determining the step size.}
%     \label{fig:decomp_comparison}\vspace{-0.2cm}
% \end{figure*}
% We operate in a common reasoning or code generation setting where the dataset $\mathcal{X} = \{\boldsymbol{x}^{(i)}\}^N_{i=1}$ consists of language problem prompts $\boldsymbol{x}$ and a reward model $R: \mathcal{X} \times \mathcal{Y} \rightarrow [0,1]$ that scores generated solutions $\boldsymbol{y} \in \mathcal{Y}$ based on the prompt. This can include program synthesis where we verify for correctness using ground-truth validation tests ~\citep{chen2021evaluating, austin2021program}, or math problems where we check whether the numerical answer is correct or not ~\citep{hendrycks2021measuring, cobbe2021training}. 
% The reward model can be the ground truth reward model, a trained heuristic \citep{zhang2024generativeverifiersrewardmodeling}, self-consistency \citep{wang2023selfconsistency} or an LLM-as-a-judge \citep{zheng2023judgingllmasajudgemtbenchchatbot}. Assume that a pretrained language model $\pi$ that produces tokens and text autoregressively is available. Since our focus is on the step decomposition, not verification and reward modeling, we use the ground truth reward model in our experiments where possible. 
% An answer $\boldsymbol{y}$ often consists of both the final solution to the problem in language or code form, and also the chain of reasoning that led to that final solution, generated by the language model. 
% Both the prompt and the response can be divided into  a series of tokens $\boldsymbol{x} = (x_0, ..., x_{L_{\boldsymbol{x}}})$ and $\boldsymbol{y} = (y_0, ..., y_{L_{\boldsymbol{y}}})$.
% Moreover, a full solution can also be partitioned into partial solutions or solution steps $\boldsymbol{y} = (\boldsymbol{y}_0, ..., \boldsymbol{y}_K)$, where each step is a string consisting of tokens. Let $\boldsymbol{y}_{1...k} := \boldsymbol{y}_1 \cdot \boldsymbol{y}_2 \cdot ... \cdot \boldsymbol{y}_k$ denote a partial solution that is the concatenation of the $k$ solution steps. 
% The \textbf{size} of a solution step, $|\boldsymbol{y}_i|$, denotes the number of characters or tokens the step has. A \textbf{rollout} or \textbf{completion} of a partial solution $\boldsymbol{y}_{1...k}$, notated as $\boldsymbol{y}_{1...k+}$, includes generations from $\pi$ starting from $\boldsymbol{y}_{1...k}$ until the end of generation token (usually \textsc{EOS}). 

% In this paper we will adopt the convention of using $\boldsymbol{s}$ to notate complete solutions and $\boldsymbol{y}$ to notate partial solutions or solution steps, both of which are strings of tokens. 
% \santiago{The notation here is not clear. Using the same notation for response, solution and partial solution seems confusing. At some point it is mentioned that an ``answer ${s}$...''. But $s$ is then not used.}
\vskip -0.1in
\subsection{Prior Automatic Decomposition Methods}
\label{sec:prior_decomp}

\textbf{Single-step generation.}  
In a single-step generation, the entire solution is generated in one pass from the prompt to the \textsc{EOS} token, treating it as a single action. This approach underlies the widely used inference scaling method \textbf{best of n} (BoN)~\citep{cobbe2021training, lightman2023let, snell2024scaling, liang2024improving}, where $n$ complete solutions are sampled, and the highest-scoring one is selected. Single-step generation also plays a role in alignment and fine-tuning methods such as \textbf{DPO}~\citep{rafailov2024direct} and \textbf{RLOO}~\citep{ahmadian2024back}.

\textbf{Token-level decomposition.}  
At the opposite end of the spectrum, token-level decomposition treats each atomic token as an individual step. While this approach dramatically increases search complexity, it enables fine-grained search that can yield higher performance gains given sufficient compute~\citep{feng2023alphazero}.

\textbf{Newline and sentence-level decomposition.}  
A commonly used decomposition method segments LLM generations into sentences or lines based on delimiters such as periods or newlines~\citep{hao2023reasoning, feng2023alphazero, yao2024tree}. Typically, each newline corresponds to a new paragraph, equation, or line of code, which often encapsulates a distinct reasoning step.


% \subsection{Prior automatic decomposition methods}
% \label{sec:prior_decomp}

% \textbf{Single step generation.}
% In single step generation, the entire solution from the prompt until the \eos token is treated as a single action. 
% This is the decomposition method used by the most common and well known inference scaling method, \textbf{best of n} (BoN) ~\citep{cobbe2021training, lightman2023let, snell2024scaling}.
% % The most common and well known method of inference scaling by far is \textbf{best of n} (BoN) [cite].
% BoN samples $n$ complete solutions from the policy, picking the best solution generated out of the $n$ solutions to use. 
% Single step generation also fuels alignment and fine tuning methods such as DPO ~\citep{rafailov2024direct} and RLOO ~\citep{ahmadian2024back}. 

% \textbf{Token level decomposition.}
% At the other end of the spectrum we have token level decomposition, where we decompose the solution into the finest granularity and each atomic token is treated as an individual step. While token-level decomposition greatly increases the search complexity, fine grained search can lead to higher performance gains given enough compute ~\citep{feng2023alphazero}. 

% \textbf{New line and sentence level decomposition.}
% A commonly used decomposition method is to decompose the LLM generations into sentences or lines based on special characters such as periods or newline ~\citep{hao2023reasoning, feng2023alphazero, yao2024tree}. Usually each new line represents a new paragraph, equation, or line of code, which likely encapsulates a new idea or step. 

% However, a major weakness with 

\begin{tcolorbox}[title=Problem: Automatic and scalable decomposition, colframe=low, boxsep=0.5mm]
\footnotesize{
    Existing decomposition methods are task-specific, manual, and static, limiting their adaptability and scalability. % manual
    }
\end{tcolorbox}

% \begin{tcolorbox}[title=Problem: automatic and general decomposition, colframe=low]
%     Current decomposition methods often rely on manual or ad-hoc decomposition that are task specific and static.
% \end{tcolorbox}
\vskip -0.2in
\subsection{Step Sampling}

Inference-time scaling methods must balance exploration at the current step with exploration of future steps. We implement a simple dynamic sampling process, referred to as \textbf{negative binomial sampling}, where we continue sampling completions until the \emph{sum of their rewards exceeds a predefined threshold} $\sigma$. More formally, the number of samples $M$ drawn from a partial solution $\boldsymbol{y}_{1...k}$ is the smallest integer satisfying $\sum_{i=1}^M R(\boldsymbol{x} \cdot \boldsymbol{y}_{1...k+}^{(i)}) \geq \sigma$.
% \setlength{\abovedisplayskip}{3pt}
% \setlength{\belowdisplayskip}{3pt}
% \[

% \]
Where $\boldsymbol{y}_{1...k+}^{(i)}$ represents the $i$-th sampled completion from the partial solution. This process ensures efficient allocation of compute by dynamically adjusting the number of samples per step. It achieves this by either:  
(a) \emph{continuing to sample until a sufficiently high-reward completion is found}, or  
(b) \emph{stopping early when additional sampling is unlikely to yield significant improvements}, thus redirecting the compute to future steps. The stopping criterion is governed by $\sigma$: when accumulated reward from completions surpasses $\sigma$, the method assumes further sampling is unnecessary. For a fair comparison, we apply this sampling method \emph{uniformly across all decomposition methods} in our experiments.


% \subsection{Step sampling}
% Inference time scaling methods usually need to determine the number of samples for each step to balance exploration of the current step and exploration of future steps.
% We implement a simple dynamic sampling process where we sample enough completions until the \emph{sum reward of the completions is greater than some sampling threshold $\sigma$}, which we refer to as \textbf{negative binomial sampling}. More formally, the number of times we sample from partial solution $\boldsymbol{y}_{1...k}$ is $M$, where $M$ is the smallest integer satisfying:
% \setlength{\abovedisplayskip}{3pt}
% \setlength{\belowdisplayskip}{1pt}
% \[
% \sum_{i=1}^M R(\boldsymbol{x} \cdot \boldsymbol{y}_{1...k+}^{(i)}) \geq \sigma.
% \]
% Here $\boldsymbol{y}_{1...k+}^{(i)}$ represents the $i$-th sampled completion from this partial solution. This sampling process ensures that we either (a) find a sufficiently good partial completion by accumulating enough reward or (b) decide that further sampling from this step is unlikely to yield higher rewards, thereby focusing computational resources on future steps. For a fair comparison, we \emph{use the same sampling method for all decomposition methods} in comparisons. 


% and $R(\boldsymbol{x} \cdot \boldsymbol{y})$ denotes the reward for a specific solution $\boldsymbol{x} \cdot \boldsymbol{y}$. Here, $\boldsymbol{x}$ is the problem input, $\boldsymbol{y}_{1...k}$ is the partial solution up to step $k$, and $\boldsymbol{y}_{1...k}^{(i)}$ represents the $i$th sampled completion from this partial solution.
% \santiago{b) is not clear. My guess is that there is a maximum number samples M and if we reach that value we decide that sampling from this step is unlikely to yeield higher rewards. Is this the case?}
% \jon{Yes that's correct}
% We conduct an ablation study on the sampling threshold $\sigma$ in section \ref{sec:ab_sampling}.


% \subsection{Step sampling}
% Inference time scaling methods usually need to determine the number of times to sample each step that balances exploration of the current step with exploration of future steps.
% We implement a simple dynamic sampling process where we sample enough completions until the \emph{sum reward of the completions is greater than some sampling threshold $\sigma$}, which we call \textbf{negative binomial sampling}. More formally, the number of times we sample from partial solution $\boldsymbol{y}_{1...k}$ is $M$ where $M$...

% This means that we will sample the step until a good step is found or we have sampled enough times to conclude that it is probably better to sample other steps instead.
% For fair comparison, we \emph{use the same sampling method for all decomposition methods} in comparisons. 
% We conduct an ablation study on the sampling threshold $\sigma$ in section \ref{sec:ab_sampling}.
% For far comparison, the same sampling method and threshold were applied to 

\vskip -0.1in
\subsection{Inference Scaling Methods and Decomposition}

Since our study focuses on decomposition rather than search, we primarily use \textbf{greedy step search} as the search method. In greedy step search, multiple candidate steps are sampled at each iteration, but only the highest-scoring step is retained, while the rest are discarded. The process then repeats, conditioning future steps on the best step found so far.
We also perform ablation studies comparing \textbf{Monte Carlo Tree Search} (MCTS) ~\citep{feng2023alphazero, light2024scattered} and \textbf{beam search} ~\citep{xie2024self}, two commonly used inference scaling methods. These comparisons, presented in Sec.~\ref{sec:scaling_methods}, highlight how different search strategies interact with decomposition. Additional details on MCTS and beam search are provided in App.~\ref{sec:search_extended}.

% \subsection{Inference scaling methods and decomposition}
% Since the focus of our study is on the decomposition method and not the search, we use \textbf{greedy step search} as the main search method. In greedy step search, at each iteration, we sample multiple possible steps before choosing the best step and discarding the rest. We then repeat the process, conditioned on the best step found previously.

% We also conducted ablation studies comparing with other inference scaling search methods such as \textbf{Monte Carlo Tree Search} (MCTS) and \textbf{beam search}, shown in Sec. \ref{sec:scaling_methods}, which are commonly used ~\citep{feng2023alphazero, light2024scattered}. More details on MCTS and beam search in App. \ref{sec:search_extended}.


% Inference scaling methods such as Monte Carlo Tree Search (MCTS) require break