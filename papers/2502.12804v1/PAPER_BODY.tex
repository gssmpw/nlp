
\documentclass[9pt,twocolumn,twoside]{osajnl}

\journal{jocn} 

% Set the article type for journal submissions. Comment out this line for Optica Open preprint submissions.
\setboolean{shortarticle}{false}
% true = letter / tutorial
% false = research / review article

\title{Reinforcement Learning for Dynamic Resource Allocation in Optical Networks: Hype or Hope?}

\author[1*]{Michael Doherty}
\author[1]{Robin Matzner}
\author[1]{Rasoul Sadeghi}
\author[1]{Polina~Bayvel}
\author[1]{Alejandra~Beghelli}

\affil[1]{Optical Networks Group, University College London, Torrington Place, London WC1E 7JE, United Kingdom}


\affil[*]{Corresponding author: michael.doherty.21@ucl.ac.uk}

%% To be edited by editor
% \dates{Compiled \today}

%% To be edited by editor
% \doi{\url{http://dx.doi.org/10.1364/XX.XX.XXXXXX}}


\begin{abstract}
    The application of reinforcement learning (RL) to dynamic resource allocation in optical networks has been the focus of intense research activity in recent years, with almost 100 peer-reviewed papers. We present a review of progress in the field, and identify significant gaps in benchmarking practices and reproducibility. To determine the strongest benchmark algorithms, we systematically evaluate several heuristics across diverse network topologies. We find that path count and sort criteria for path selection significantly affect the benchmark performance. We meticulously recreate the problems from five landmark papers and apply the improved benchmarks. Our comparisons demonstrate that simple heuristics consistently match or outperform the published RL solutions, often with an order of magnitude lower blocking probability. Furthermore, we present empirical lower bounds on network blocking using a novel defragmentation-based method, revealing that potential improvements over the benchmark heuristics are limited to 19--36\% increased traffic load for the same blocking performance in our examples. We make our simulation framework and results publicly available to promote reproducible research and standardized evaluation \hyperlink{https://doi.org/10.5281/zenodo.12594495}{https://doi.org/10.5281/zenodo.12594495}.%{10.5281/zenodo.12594495}.
\end{abstract}


% \begin{abstract}
% We survey the literature on reinforcement learning (RL) applied to dynamic resource allocation (DRA) problems in optical networks. Through critical examination of the reported experimental methodologies and results, we summarize the different approaches taken by researchers and highlight the difficulty in comparing results across non-standardized network topologies, traffic models and training regimes. We argue that, despite intense research interest, the improvement achieved by RL over simple heuristic algorithms on DRA problems has been overstated or non-existent. By quantifying the effect of implementation details such as pre-populated network traffic, inconsistencies in traffic models and path prioritization, we show several RL-based resource allocation policies from the literature are outperformed by heuristic algorithms. Further to this analysis, we estimate the upper bounds network throughput for 11 cases of study and show possible improvement over heuristics is limited to 1-36\% increase in supported traffic load. We conclude with a discussion of how RL performance can be improved on DRA problems and suggest directions for future research in which greater performance gains may be possible. We make all of our code available at \hyperlink{10.5281/zenodo.14561967}{10.5281/zenodo.14561967}.
% \end{abstract}

\setboolean{displaycopyright}{false} % Do not include copyright or licensing information in submission.

\begin{document}

\maketitle

\input{2_PAPER_SECTIONS/1_introduction}

\input{2_PAPER_SECTIONS/2_background}

\input{2_PAPER_SECTIONS/3_literature_survey}

\input{2_PAPER_SECTIONS/4_heuristic_comparison}

\input{2_PAPER_SECTIONS/5_reproduction_of_published_results}

\input{2_PAPER_SECTIONS/6_network_blocking_bounds}

\input{2_PAPER_SECTIONS/7_conclusion}


\section*{Acknowledgments}
This work was supported by the Engineering and Physical Sciences Research Council (EPSRC) grant EP/S022139/1 - the Centre for Doctoral Training in Connected Electronic and Photonic Systems - and EPSRC Programme Grant TRANSNET EP/R035342/1. In addition, Polina Bayvel is supported through a Royal Society Research Professorship.


% Bibliography
\bibliography{references.bib}



\include{results_table}



\end{document}
