\section{Empirical Analysis}
\label{sec:empirical_analysis}

To analyze the progress made in applications of RL to DRA problems in optical networks, we select 5 influential papers from the literature. Following our review of the field in section \ref{sec:survey}, we select these papers based on the criteria of influence (measured by citation count), novelty, and performance relative to benchmarks. The comparison of the papers is facilitated by their common problem settings (RSA/RMSA), topologies (NSFNET, COST239, USNET), and target metric (service blocking probability). We choose to focus on RSA/RMSA because they are the most widely studied DRA problems in the context of optical networks and they form a core sub-task of any other DRA problems on optical networks, such as VNF or VONE. Understanding RL performance on RSA/RMSA therefore has implications for the study of more complex problems.

In this section, we first summarize the selected papers, highlighting their novelty and contributions. Then, to decide on our benchmark heuristics, we compare six heuristics from the literature on a range of network topologies, traffic loads, and number of pre-calculated shortest paths.  We also provide analysis of simulation settings that affect the network blocking probability but have not previously been discussed in detail; network warm-up period, service holding time truncation, and path prioritization. We then present the results of our reproduction of the cases of study, which account for these effects, and compare to the best heuristics for each case, which show superior performance to all of the published RL solutions.

We conclude the section by explaining our methodology for estimating network capacity bounds, and present those bounds in comparison to our improved heuristic results. We provide all the scripts to reproduce our experiments and figures at the code repository for this work \cite{michael_doherty_micdohxlron_2024}.
%The bounds are found to be very close to the heuristic performance, which raises the question of how worthwhile RL solutions are for this class of DRA problems.

We use XLRON for all simulations \cite{doherty_xlron_2023}. It has demonstrated 10x faster training on CPU and over 1000x faster when parallelized on GPU compared to optical-rl-gym. This is possible due to its simplified data model and its implementation using the JAX high-performance array computing framework, that enables just-in-time compilation to accelerator hardware. It also offers a complete suite of unit tests for core functionality, therefore is more reliable than other libraries. We use it for these reasons and for its simple command-line interface, for ease of reproducibility and experiment automation.











\subsection{Summaries of selected papers}
\label{sec:paper_summaries}


\begin{enumerate}
    \item \textbf{DeepRMSA} \cite{chen_deeprmsa_2019} is the seminal paper in the field of RL for RMSA, with over 127 citations. It constructs a feature matrix to represent the available paths for the current requests and applies a simple MLP with 5 x 128 hidden units to select from the k-shortest paths with first-fit spectrum allocation. It demonstrates improved performance over KSP-FF on the NSFNET and COST239 topologies. DeepRMSA's impact was enhanced by releasing its codebase as open source.
    \item \textbf{Reward-RMSA} \cite{tang_heuristic_2022}, with over 15 citations, builds on the DeepRMSA framework and changes the reward function to incorporate fragmentation-related information. They demonstrate improvement over heuristics and their implementation of DeepRMSA.
    \item \textbf{GCN-RMSA} \cite{xu_deep_2022} has over 24 citations and is notable because it is the first work to use advanced neural network architectures to improve performance. They use a graph convolutional network (GCN) (including recurrent neural network (RNN) as the path aggregation function) in the policy and value functions, which they claim allows improved feature extraction from the network state. Like DeepRMSA and Reward-RMSA, the policy selects from K paths with first-fit spectrum allocation. They perform a thorough analysis of their proposed solution, showing improvement over benchmarks DeepRMSA and KSP-FF on the NSFNET, COST239, and USNET topologies. 
    \item \textbf{MaskRSA} \cite{shimoda_mask_2021} has over 25 citations. It innovated by selecting from the entire range of available slots on the K paths and using invalid action masking \cite{huang_closer_2020} to increase the efficiency of training. Despite the RSA in the title, the paper does consider distance-dependent modulation format. MaskRSA presented improvements over KSP-FF on the NSFNET and JPN48 topologies with over an order of magnitude lower blocking probability, or a 35-45\% increase in the supported traffic in their cases of study. The authors of MaskRSA also contributed to open source by releasing their simulation framework, RSA-RL.
    \item \textbf{PtrNet-RSA} \cite{cheng_ptrnet-rsa_2024} is a 2024 paper that presents innovation in both the problem setting and the function approximator. A pointer-net \cite{vinyals_pointer_2015} is used to select the constituent nodes of the target path, thereby removing the restriction of selecting from the pre-calculated k-shortest paths, and utilizes masking to allow selection from all available spectral slots. Additionally, the paper considers joint optimization of the mean path SNR and the network blocking probability through its reward function. It demonstrates superior performance to KSP-FF and their implementation of MaskRSA on both metrics. Arguably, PtrNet-RSA represents the apotheosis of current RL solutions for DRA problems, by combining the innovations from the other selected papers and considering a more complete problem context with physical layer model.
\end{enumerate}

DeepRMSA, Reward-RMSA, and GCN-RMSA use the same original DeepRMSA codebase as the basis for their experiments. Consequently, they all retain an idiosyncratic feature of that implementation, service holding time truncation, discussed in section \ref{sec:holding_time}. Another common characteristic is they use consider directed graphs with dual fiber links i.e. each link comprises two fibers, one for each direction of propagation. This doubles the maximum potential capacity of the network compared to single-fiber links. MaskRSA and PtrNet-RSA model single-fiber links, which makes the problem less challenging for RL due to less sparse reward signals (more frequent blocking) but also less similar to real-world optical networks. PtrNet-RSA does not consider distance-dependent modulation format.


\begin{figure}
  \includegraphics[width=0.5\textwidth]{IMAGES/networks_plots_short.png}
  \caption{Network topologies used in the case studies from influential papers: DeepRMSA, Reward-RMSA, GCN-RMSA, MaskRSA, PtrNetRSA \cite{chen_deeprmsa_2019} \cite{tang_heuristic_2022} \cite{xu_deep_2022} \cite{shimoda_mask_2021} \cite{cheng_ptrnet-rsa_2024}. The COST239 topology shown is from DeepRMSA, the USNET is from PtrNet-RSA.}
  \label{fig:network_plots}.
\end{figure}

Figure \ref{fig:network_plots} shows the topologies used in the selected publications. %Some characteristic features of the topologies are summarised in table \ref{tab:topology_features}.  
We note that the USNET topology differs between GCN-RMSA \cite{xu_deep_2022} and PtrNet-RSA \cite{cheng_ptrnet-rsa_2024}. We show the PtrNet version here with longer, more realistic link lengths. PtrNet-RSA also uses a unique variant of the COST239 topology. We make all topology data available \cite{micdoh_xlron_2024}






\subsection{Network traffic warmup}
\label{sec:warmup}

Network traffic warm-up is an important detail in RL solutions for RMSA that affects blocking probability statistics. During warm-up, traffic requests populate the network topology using either an RL policy or heuristic before training or evaluation begins. This pre-population serves two key purposes:

First, it helps prevent primacy bias \cite{nikishin_primacy_2022}, where models overfit to data seen early in training. When starting with an empty network, initial traffic requests are trivially allocated due to abundant resources, providing no useful optimization signal. Training on a congested network with both successful and failed assignments gives more meaningful training data from the start.

Second, warm-up helps the network reach a steady operating state more quickly. Without warm-up, episodes would need to be longer to achieve representative network conditions.

While most papers do not explicitly discuss warm-up, both the DeepRMSA codebase and RSA-RL framework from MaskRSA implement it. In section \ref{sec:repro}, we use this technique to match published results, adopting their 3000-request warm-up period. However, we also investigate how varying the warm-up length affects performance. We find that mean SBP stabilizes to steady state after a number of requests that depends on the traffic load. This suggests training and evaluation should only begin once steady state is reached. We therefore analyze the minimum required warm-up period for different traffic levels.

\subsubsection{Experiment setup}

We simulate a network that accepts all service requests (no blocking) to determine the number of requests needed to reach a steady state traffic load. Specifically, we define "steady state" as the point at which the number of active requests equals a target traffic load. Connection requests arrive according to an inverse exponential distribution with mean rate $\lambda$, and have holding times drawn from another inverse exponential distribution with mean $\tau$. The target traffic load is reached when $\lambda \tau$ connections are active in the network.

For each traffic load from 50 to 1000 Erlangs in steps of 50, we conduct 10,000 simulation trials. In each trial, we record how many requests must be generated before reaching steady state. We then aggregate these counts across trials to create box and whisker plots showing the distribution. From our initial experiments, we observe that the ratio of mean holding time to mean arrival rate does not affect the number of requests needed to reach steady state for a given traffic load. Therefore, we fix the mean holding time at 10 time units for all experiments.


\subsubsection{Results and discussion}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{IMAGES/steady_state_boxplots.png}
    \caption{No. of simulated requests necessary to reach target network traffic level for a non-blocking network.}
    \label{fig:traffic_warmup}
\end{figure}

Figure \ref{fig:traffic_warmup} displays results as box-and-whisker plots showing how many requests are needed to reach steady state for each traffic load. The whiskers extend to the most extreme data points (within 1.5 times the interquartile range). By fitting a line to the maximum values (tops of the whiskers), we can determine the requests needed to reach steady state with high probability. The fitted line indicates that approximately 7 times the target traffic load in requests are required to reach steady state. Based on this finding, the 3000-request warm-up period used by DeepRMSA and that we adopt in section \ref{sec:repro} is sufficient for most of our test scenarios.










\subsection{Holding time truncation}
\label{sec:holding_time}

In order to reproduce published results, its necessary to recreate every aspect of the traffic model. One feature of the traffic model in DeepRMSA and successor works is that the randomly sampled holding time is resampled if the resulting value is more than twice the mean of the inverse exponential PDF. We refer to this detail as holding time truncation. 


\subsubsection{Experiment setup}
To understand the effect of truncation on the traffic statistics, we define an inverse exponential PDF with unit mean. We take $10^{6}$ samples from the PDF, both with and without truncation, and calcualte the mean of the resulting samples in both cases.

\subsubsection{Results and discussion}
Figure \ref{fig:truncation} compares histograms of service holding times with and without truncation. The truncated case shows a sharp cutoff at twice the mean holding time, while the untruncated case follows the full exponential distribution. The vertical lines indicate the mean holding time for each case, revealing that truncation reduces the mean by approximately 31\%. This means that papers implementing holding time truncation (including DeepRMSA, Reward-RMSA, and GCN-RMSA) effectively evaluated their solutions at traffic loads 31\% lower than reported. While this implementation detail exists in the open source DeepRMSA codebase that these works built upon, it was not explicitly documented in the published papers themselves. This finding highlights the challenges in making fair comparisons when papers use non-standard implementations of the problem settings.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{IMAGES/truncation.png}
    \caption{Histogram of holding time for untruncated Poisson distribution with mean of 1. The untruncated distribution resamples the holding time when the sampled value exceeds 2*mean. This reduces the mean holding time by 31\% from the full Poisson distribution.}
    \label{fig:truncation}
\end{figure}









\subsection{Reproduction of published results}
\label{sec:repro}

Our analysis of the best performing heuristics and the implementation details of previous work (network warm-up and holding time truncation) enable us to perform a comprehensive benchmarking of the published results from the five selected influential papers. The aim of this comparison is to determine if any of the selected works have managed to exceed simple heuristic algorithms in performance on their cases of study. In order to do so, we recreate their simulations exactly and apply the KSP-FF heuristic algorithm with K=50 and paths ordered by number of hops in each case, based on our experiments from section \ref{sec:heuristic_comparison}.


\subsubsection{Experiment setup}


We recreate their cases of study in our own simulation framework \cite{doherty_xlron_2024} for fast, accurate, and reproducible results. We match the topologies (NSFNET, COST239, JPN48, USNET), mean service arrival rates, mean service holding times, data-rate request distributions, and traffic matrices. We analyzed the open source DeepRMSA codebase to identify holding time truncation and a network warmup period of 3000 steps. We corresponded with the authors of MaskRSA and PtrNet-RSA to find details of their simulations based on RSA-RL and identify the exact physical topologies used. We use the same measurement methodology as described in the respective papers to reproduce results, which is 3000 request warmup period followed by 10,000 requests. The SBP is calculated at the end of the episode. We perform 10 trials and calculate the mean and standard deviation across trials.

We extract published results from the publications, using textual values where available otherwise reading from charts. All published results report only a single data point for each traffic value, without any uncertainties. We check that our results for KSP-FF with K=5 match the published results within two standard deviations to ensure faithful reproduction. 



\subsubsection{Results and discussion}


\begin{figure*}
  \includegraphics[width=\textwidth]{IMAGES/review_summary_plots_2.png}
  \caption{Mean service blocking probability against traffic load. Each column is a publication and each subplot is for a topology. Error bars and shaded regions show standard deviations. Data for $RL$ and 5-SP-FF$_{published}$ are extracted from the publications. Close agreement between 5-SP-FF$_{published}$ and  5-SP-FF$_{ours}$ show that we accurately reproduce each case of study. \mbox{50-SP-FF$_{hops}$} exceeds or  matches the $RL$ performance for each case.}
  \label{fig:repro}
\end{figure*}

Figure \ref{fig:repro} shows our reproduction of results from the selected papers. Each subplot compares service blocking probability (SBP) against traffic load in Erlangs. The plots are organized by paper (columns) and topology (rows). PtrNet-RSA has two columns reflecting its two test cases: networks with 40 FSU per link handling 1 FSU requests, and networks with 80 FSU per link handling 1-4 FSU requests.

Each plot contains 5 datasets:
\begin{itemize}
\item[] \textbf{RL}: Published results for the reinforcement learning approach
\item[] \textbf{5-SP-FF$_{published}$}: Published results for 5-SP-FF with paths ordered by length
\item[] \textbf{5-SP-FF$_{ours}$}: Our reproduction of 5-SP-FF with paths ordered by length
\item[] \textbf{5-SP-FF$_{hops}$}: Our implementation of KSP-FF (K=5) with paths ordered by number of hops
\item[] \textbf{50-SP-FF$_{hops}$}: Our implementation of KSP-FF (K=50) with paths ordered by number of hops
\end{itemize}

Points show mean values from our simulations, with shaded areas indicating standard deviation and lines interpolating between points. DeepRMSA provides data for only one traffic load per topology.

We validate our simulation framework by comparing 5-SP-FF$_{published}$ to 5-SP-FF$_{ours}$. The excellent agreement across all cases confirms that our framework accurately reproduces the published scenarios. We do not attempt to reproduce the RL results directly, as this would require exact replication of all training details or access to the original trained models, neither of which are available. Instead, we extract the RL results from the papers and use the matching KSP-FF results to verify our simulations.

Our results show that KSP-FF$_{hops}$ with either K=5 or K=50 exceeds the published RL performance in most cases. Using K=50 matches or exceeds RL performance in all but one case. While our earlier experiments showed FF-KSP performs better than KSP-FF for JPN48, we only plot KSP-FF results as they already surpass the RL performance. For MaskRSA JPN48, FF-KSP with K=50 achieves zero blocking across all tested traffic loads.

The single exception where RL outperforms 50-SP-FF$_{hops}$ is PtrNet-RSA-80 USNET. Three factors may explain this:
\begin{enumerate}
    \item The RL results fall within 1-2 standard deviations of our heuristic mean. Without multiple trials from PtrNet-RSA, we cannot make a definitive comparison. Their favorable 5-SP-FF results suggest they may have used an advantageous random seed.
    \item PtrNet-RSA uses fixed-width requests without distance-dependent modulation, potentially allowing RL to exploit this simpler scenario.
    \item The pointer-net architecture can consider any possible path, unlike K-shortest path approaches. This broader search space likely enables better performance, similar to how increasing K improves KSP-FF.
\end{enumerate}

All data shown in figure \ref{fig:repro} is provided in tabular form in Appendix A.

% PtrNet also seeks to maximise the average GSNR of the active lightpaths, however this is closely linked to throughput.














































% \subsubsection*{Cut-Sets Capacity Bound Estimation}

% \begin{algorithm}
% \caption{Cut-Sets Capacity Bound}
% \begin{algorithmic}[1]
% \Require Network topology $G$, Traffic matrix $T$, Number of frequency slots per link $F$
% \Ensure Blocking probability $P_b$

% \State $N \gets \textsc{InitializeNetwork}(G, F)$ \Comment{Initialize network with empty spectrum slots}
% \State $C_{cong} \gets \textsc{IdentifyCutSets}(G, T, M)$ \Comment{Find congested cut-sets}
% \State $L_{map} \gets \textsc{MapLinksToCutSets}(G, C_{cong})$ \Comment{Map network links to cut-sets}
% \State $\textit{blocked} \gets 0$
% \State $\textit{total} \gets 0$

% \While{simulation not complete}
%     \For{each active request $r$ that expired}
%         \For{each link $l \in r.\textit{path}$}
%             \State \textsc{ReleaseSpectrum}($N[l]$, $r.\textit{slots}$)
%         \EndFor
%     \EndFor
    
%     \For{each new request $r(s,d)$}
%         \State $\textit{total} \gets \textit{total} + 1$
%         \State $m \gets \textsc{GetHighestModulation}(s, d)$
%         \State $req\_slots \gets \textsc{CalculateRequiredSlots}(r, m)$
        
%         \State $C_r \gets \{c \in C_{cong} | \textsc{Separates}(c, s, d)\}$
%         \State $available \gets \texttt{true}$
%         \State $candidate\_links \gets \emptyset$
        
%         \For{each cut-set $c \in C_r$}
%             \State $links \gets L_{map}[c]$ \Comment{Get network links in this cut-set}
%             \State $L_c \gets \{l \in links | \textsc{FreeSlots}(N[l], req\_slots)\}$
%             \If{$L_c = \emptyset$}
%                 \State $available \gets \texttt{false}$
%                 \State \textbf{break}
%             \EndIf
%             \State $candidate\_links[c] \gets L_c$
%         \EndFor
        
%         \If{$available$}
%             \State $sel\_links \gets \textsc{OnePerCutset}(candidate\_links)$
%             \State $sel\_slots \gets \textsc{GetSlots}(N, sel\_links, req\_slots)$
%             \If{$sel\_slots \neq \emptyset$}
%                 \For{each link $l \in sel\_links$}
%                     \State \textsc{AssignSlots}($N[l]$, $sel\_slots$, $req\_slots$)
%                 \EndFor
%                 \State $r.\textit{path} \gets sel\_links$
%                 \State $r.\textit{slots} \gets sel\_slots$
%             \Else
%                 \State $\textit{blocked} \gets \textit{blocked} + 1$
%             \EndIf
%         \Else
%             \State $\textit{blocked} \gets \textit{blocked} + 1$
%         \EndIf
%     \EndFor
% \EndWhile

% \State \Return $\textit{blocked}/\textit{total}$

% \end{algorithmic}
% \end{algorithm}

% ```

% The cut-set capacity bound algorithm utilizes seven key subroutines:

% \begin{itemize}
%     \item \textsc{InitializeNetwork}($G$, $F$) creates an empty network state with $F$ frequency slots available on each link in topology $G$.
    
%     \item \textsc{IdentifyCutSets}($G$, $T$, $M$) determines the most congested cut-sets by analyzing the ratio of expected traffic flow to available capacity across all possible network bisections, weighted by achievable modulation formats.
    
%     \item \textsc{MapLinksToCutSets}($G$, $C_{cong}$) creates a mapping from each congested cut-set to its constituent network links, ensuring that allocated resources on each cut set map to physical links.
    
%     \item \textsc{FreeSlots}($N[l]$, $req\_slots$) determines if link $l$ has sufficient contiguous free spectrum slots to accommodate the request.
    
%     \item \textsc{OnePerCutset}($candidate\_links$) selects exactly one link from each cut-set's candidate links such that the selected links can potentially support a common spectrum assignment. The selected link in each cutset is determined by the constituent links of the shortest available path.
    
%     \item \textsc{GetSlots}($N$, $sel\_links$, $req\_slots$) identifies a common set of contiguous spectrum slots available across all selected links using a first-fit policy.
    
%     \item \textsc{AssignSlots}($N[l]$, $sel\_slots$, $req\_slots$) allocates the selected spectrum slots on link $l$, maintaining the network state.
% \end{itemize}
