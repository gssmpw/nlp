\section{Reproduction and benchmarking of previous work}
\label{sec:repro_main}

As discussed in our literature review (Section \ref{sec:survey}), it is difficult to assess progress in the field due to several factors, particularly the diversity of problem definitions and use of weak benchmarks. To address this, we exactly recreate the problem settings from five influential papers from the literature, and apply the best-performing heuristics from Section \ref{sec:heuristic_comparison} in each case.

In this section, we first provide analysis of holding time truncation, an implementation detail present in the DeepRMSA codebase that significantly affects the blocking probability. We then present the results of our reproductions of the selected papers and compare to the heuristics, which show superior performance to all of the published RL solutions.

We have corresponded with the authors of all of the selected papers to clarify details of their implementation and ensure that our reproductions exactly match all the relevant details of their problems.

%DeepRMSA, Reward-RMSA, and GCN-RMSA use the same original DeepRMSA codebase as the basis for their experiments. Consequently, they all feature service holding time truncation, discussed in section \ref{sec:holding_time}. Another common characteristic is they use directed graphs with dual fiber links i.e. each link comprises two fibers, one for each direction of propagation. This doubles the maximum potential capacity of the network compared to single-fiber links. MaskRSA and PtrNet-RSA model single-fiber links, which makes the problem less challenging for RL due to less sparse reward signals \cite{nevin_techniques_2022} (more frequent blocking). PtrNet-RSA considers fixed bandwidth requests (no distance-dependent modulation format).

 We use our high-performance simulation framework, \mbox{XLRON} \cite{doherty_xlron_2023}, for all experiments. It has demonstrated 10x faster execution on CPU and over 1000x faster when parallelized on GPU compared to optical-rl-gym \cite{doherty_xlron_2024}. This is possible due to its array-based data model and use of the JAX numerical array computing framework, that enables just-in-time compilation to accelerator hardware. It also offers a complete suite of unit tests for core functionality, making it reliable, and includes all the problem definitions of the selected papers. We use it for these reasons and for its simple command-line interface, which facilitates experiment automation and reproducibility.













% \subsection{Simulation warm-up}
% \label{sec:warmup}

% To exactly recreate the problems from the selected papers, we generate the same number of traffic requests as the original study. This includes the connection requests that are generated to pre-populate the network until the blocking probability reaches steady-state, a phenomenon which is well-known in discrete-event simulation \cite{banks_discrete-event_2005}. We call the period prior to steady-state the warm-up period. 

% Warm-up is important so that the blocking probability reaches its steady-state value and is not an underestimate. This is known as the simulation start-up problem or the initial transient \cite{white_problem_2009}. %When training an RL agent, warm-up may help prevent primacy bias \cite{nikishin_primacy_2022}, where models overfit to data seen early in training. Starting with an empty network, initial traffic requests are trivially allocated due to abundant resources, providing no useful optimization signal. Training on a congested network with both successful and failed allocations gives more meaningful training data from the start.

% While most papers do not explicitly discuss warm-up, all of the selected papers use it. We therefore analyze the minimum required warm-up period for different traffic levels.

% \subsubsection{Experiment setup}

% We simulate a non-blocking network to determine the maximum\footnotemark number of requests needed to reach a steady-state traffic load. For each traffic load from 50 to 1000 Erlangs in steps of 50, and for arrival rates from 5 to 25 in steps of 5, we conduct 500 simulation trials with unique random seeds.  For each trial, we estimate the number of requests at which steady state is reached using the MSER-5 method \cite{franklin_stationarity_2008} (Marginal Standard Error Rule with batch size 5). We apply the MSER-5 method as it has been shown to be superior to other methods such as the mean crossing rule \cite{white_problem_2009}.

% \footnotetext{A blocking network reaches steady-state in less traffic requests than a non-blocking one, therefore we consider a non-blocking network to estimate an upper bound on the required warm-up period before steady state.}


% \subsubsection{Results and discussion}

% \begin{figure}
%     \centering
%     \includegraphics[width=1\linewidth]{IMAGES/steady_state_boxplots.png}
%     \caption{No. of simulated requests necessary to reach the steady-state network traffic load specified on the x-axis, for a non-blocking network.}
%     \label{fig:traffic_warmup}
% \end{figure}

% Figure \ref{fig:traffic_warmup} displays results as box-and-whisker plots showing how many requests are needed to reach steady state for each traffic load. The whiskers extend to the most extreme data points within 1.5 times the inter-quartile range. We observe a linear relationship between traffic load and requests until steady state (warm-up period). We fit a line to the maximum values (tops of the whiskers) to determine the warm-up period with high confidence. The fitted line indicates that approximately 7 times the target traffic load in requests are required to reach steady state. Based on this finding, the 3000-request warm-up period used by DeepRMSA that we adopt in section \ref{sec:repro} is sufficient for our problem settings.



















\subsection{Holding time truncation}
\label{sec:holding_time}

DeepRMSA, Reward-RMSA, and GCN-RMSA use the same original DeepRMSA codebase as the basis for their experiments. This codebase includes a significant detail: the service holding time is resampled if the resulting value is more than twice the mean of the exponential probability density function (PDF). We refer to this detail as holding time truncation.  In order to recreate the problems from these papers, we analyze the effect of holding time truncation.


\subsubsection{Experiment setup}
To understand the effect of truncation on the traffic statistics, we define an inverse exponential PDF that is normalized to have unit mean. We take $10^{6}$ samples from the PDF, both with and without truncation, and calculate the mean of the resulting sample populations in both cases.

\subsubsection{Results and discussion}
Figure \ref{fig:truncation} compares histograms of service holding times with and without truncation. We define the bin width as 0.01 and normalize the count per bin to give a peak density of 1 without truncation. The truncated case shows a cutoff at twice the mean holding time. The vertical lines indicate the mean holding time for each case.

Holding time truncation reduces the mean by approximately 31\%. This results in 31\% lower traffic load. Therefore, papers that use the DeepRMSA codebase (including DeepRMSA, Reward-RMSA, and GCN-RMSA) evaluate their solutions at traffic loads 31\% lower than reported. This detail is not made explicit in the published papers. This finding highlights the challenges in making fair comparisons between papers, and the need for transparency in research code.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{IMAGES/truncation.png}
    \caption{Histogram of service holding holding times. The truncated distribution resamples the holding time when the sampled value exceeds $2*$mean. This reduces the mean holding time by 31\% compared to the exponential distribution.}
    \label{fig:truncation}
\end{figure}



%Cisco NCS 2000 Flex Spectrum Single Module ROADM and it's integrated pre-amplifier has a nominal noise figure of 5.5dB (for 24dB gain) or 11.7dB (for 12dB gain), 















\subsection{Reproduction of published results}
\label{sec:repro}
Our analysis of the best performing heuristics, of holding time truncation, and our correspondence with the authors enables us to benchmark the published results from the five selected influential papers. The aim of this comparison is to determine if any of the published RL solutions achieve lower SBP than the heuristics. %In order to do so, we recreate their simulations exactly and apply the KSP-FF heuristic algorithm with K=50 and paths ordered by number of hops in each case, based on our experiments from section \ref{sec:heuristic_comparison}.


\subsubsection{Experiment methodology}


We recreate the problems from each selected paper in our own simulation framework \cite{doherty_xlron_2024}. We match the topologies (NSFNET, COST239, JPN48, USNET), mean service arrival rates, mean service holding times, data-rate or bandwidth request distributions, and uniform traffic matrices. We use the same measurement methodology as described in the respective papers to reproduce results, which is 3000 request warm-up period (to allow the network blocking probability to reach steady-state after the 'initial transient' \cite{white_problem_2009}) followed by 10,000 requests. The SBP is calculated at the end of the episode. We run 10 independent episodes at each traffic load per problem and calculate the mean and standard deviation across trials.

We extract published results for KSP-FF and RL solutions from the papers, using textual values where available otherwise reading from charts. All published results report only a single data point for each traffic value, without any uncertainty. %We provide all of the extracted data and our results in Appendix \ref{appendix:A}.

We check that our results for KSP-FF with K=5 (green line in Figure \ref{fig:repro}) match the published results for KSP-FF (blue line in Figure \ref{fig:repro}) within two standard deviations to ensure faithful reproduction. This comparison gives us a high degree of confidence that we have exactly recreated each problem setting.



\subsubsection{Results and discussion}


\begin{figure*}[ht]
  \includegraphics[width=1.01\textwidth]{IMAGES/review_summary_plots_2.png}
  \caption{Mean SBP against traffic load. Each column is a publication and each subplot is for a topology. Error bars and shaded areas show standard deviations. %Data for $RL$ and 5-SP-FF$_{published}$ are extracted from the publications. Close agreement between 5-SP-FF$_{published}$ and  5-SP-FF$_{ours}$ show that we accurately reproduce each case of study.
  \mbox{50-SP-FF$_{hops}$} exceeds or matches the $RL$ performance for each case.}
  \label{fig:repro}
\end{figure*}

Figure \ref{fig:repro} shows our reproduction of results from the selected papers, with SBP against traffic load in Erlangs in each subplot. The plots are organized by paper (columns) and topology (rows). PtrNet-RSA has two columns reflecting its two test cases: networks with 40 FSU per link and 1 FSU requests, and networks with 80 FSU per link and 1-4 FSU requests. PtrNet-RSA only considers fixed-bandwidth requests (no distance-dependent modulation format).

Each plot contains 5 datasets:
\begin{itemize}[itemsep=0pt]
\item[] \textbf{RL}: Published results for the RL approach
\item[] \textbf{5-SP-FF$_{published}$}: Published results for KSP-FF (K=5) with paths ordered by \#km
\item[] \textbf{5-SP-FF$_{ours}$}: Our results for KSP-FF (K=5) with paths ordered by \#km
\item[] \textbf{5-SP-FF$_{hops}$}: Our results for KSP-FF (K=5) with paths ordered by \#hops
\item[] \textbf{50-SP-FF$_{hops}$}: Our results for KSP-FF (K=50) with paths ordered by \#hops
\end{itemize}

Points show mean values from our simulations, with shaded areas indicating standard deviation and lines interpolating between points. The DeepRMSA paper provides data for only one traffic load per topology. The excellent agreement between 5-SP-FF$_{published}$ and 5-SP-FF$_{ours}$ in all cases confirms that our framework accurately reproduces the published scenarios. %We can therefore make comparisons between our results on these problem settings and the published RL results with high confidence.


From Figure \ref{fig:repro}, we highlight the comparisons of 'RL' (red) with 5-SP-FF$_{hops}$ (orange), and 50-SP-FF$_{hops}$ (purple). 5-SP-FF$_{hops}$ reduces the blocking probability by up to an order of magnitude compared to RL in all cases for NSFNET, 4/5 cases for COST239 and 1/3 cases for USNET. This shows that ordering paths by \#hops is sufficient to beat the RL results in these cases.

For larger topologies, considering more candidate paths (K>5) improves the heuristic performance significantly, often by over an order of magnitude. As shown by Figure \ref{fig:repro}, 50-SP-FF$_{hops}$ gives the lowest SBP of all approaches in all cases, except the bottom right.

The single exception where RL outperforms 50-SP-FF$_{hops}$ is PtrNet-RSA-80 USNET. We consider it plausible that the pointer-net architecture is a contributing factor to this strong performance, as it is not limited to selecting from a pre-defined set of paths. However, as the published results in this case fall within one standard deviations of the mean for 50-SP-FF$_{hops}$, the result could be spurious. This highlights the need for summary statistics and confidence intervals from multiple trials to be included with published results.

In summary, the results show that making minor changes (ordering paths by \#hops and considering more paths)  to simple heuristic algorithms is sufficient to achieve lower blocking probability than sophisticated RL solutions that have been published.

We highlight that this analysis, and the selected papers, focus on SBP as the optimization objective. In realistic scenarios, network blocking or throughput must be balanced with other metrics such as latency and cost of operation from transceiver launch power, amplifiers, and other network elements. Future research should therefore focus on problems that take a holistic approach to network operations optimization with multiple objectives \cite{nallaperuma_interpreting_2023}, and incorporate sophisticated models of all physical layer effects for improved accuracy \cite{curri_gnpy_2022,buglia_closed-form_2023}.

%While our earlier experiments showed FF-KSP performs better than KSP-FF for JPN48, we only plot KSP-FF results as they already surpass the RL performance. For MaskRSA JPN48, FF-KSP with K=50 achieves zero blocking across all tested traffic loads.

% Could include a summary paragrph here and/or a note about how RL could do better but it needs to consider enough candidate paths and the set of candidate paths needs to prioritise those with less hops not just shorter distance.
%We note that it is theoretically possible for RL to equal or exceed the performance of the best heuristic algorithms. However, our results suggest that it is necessary to consider sufficiently diverse paths 

All data shown in Figure \ref{fig:repro} is provided in tabular form in Appendix A.

