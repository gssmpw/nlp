\section{Literature Survey}
\label{sec:survey}

There exists a considerable body of literature on RL for DRA problems in in optical networks. %\cite{amin_survey_2021}. 
DRA in optical networks is distinguished from similar problems in electronically linked networks by the nature of fiber optic links, which carry a set of wavelengths or FSU, defined by the ITU standards G.671 and G.694.2 \cite{international_telecommunication_union_spectral_2002,international_telecommunication_union_transmission_2012}. In this work we only consider publications related to optical networks but acknowledge the closely related literature on RL for other graph-based resource allocation problems.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{IMAGES/RL_RSA_litreview_barchart.png}
    \caption{Count of publications related to RL for resource allocation problems in optical networks. Citations for each classification category are: RWA \cite{garcia_multicast_2003,pointurier_reinforcement_2007,koyanagi_reinforcement_2009,suarez-varela_routing_2019,shiraki_dynamic_2019,shiraki_reinforcement-learning-based_2019,tzanakaki_self-learning_2020,zhao_cost-efficient_2021,freire-hermelo_dynamic_2021,liu_waveband_2021,nevin_techniques_2022,di_cicco_deep_2022,di_cicco_deepls_2023,nallaperuma_interpreting_2023}, RSA \cite{reyes_adaptive_2017,li_deepcoop_2020,li_multi-objective_2020,romero_reyes_towards_2021,zhao_reinforced_2021,wang_dynamic_2021,quang_magc-rsa_2022,cruzado_reinforcement-learning-based_2022,zhao_rsa_2022,jiao_reliability-oriented_2022,almasan_deep_2022,wu_service_2022,arce_reinforcement_2022,sharma_deep_2023,lin_deep-reinforcement-learning-based_2023,hernandez-chulde_experimental_2023,cheng_ptrnet-rsa_2024,chen_gsaddqn_2024}, RMSA \cite{chen_deeprmsa_2019,wang_resource_2020,shimoda_mask_2021,shi_deep-reinforced_2021,shimoda_deep_2021,sheikh_multi-band_2021,xu_spectrum_2021,chen_multi-task-learning-based_2021,gonzalez_improving_2022,bryant_q-learning_2022,terki_routing_2022,tang_deep_2022,cheng_routing_2022,xu_deep_2022,tang_heuristic_2022,tu_entropy-based_2022,momo_ziazet_deep_2022,pinto-rios_resource_2023,errea_deep_2023,beghelli_approaches_2023,terki_routing_2023,tanaka_pre-_2023,xu_hierarchical_2023,sadeghi_performance_2023,tang_routing_2023,teng_deep-reinforcement-learning-based_2024,xiong_graph_2024,teng_drl-assisted_2024,unzain_reinforcement_2024,zhou_opti-deeproute_2024,li_opticgai_2024,xie_physical_2024,yan_drl-based_2024}, Other \cite{boyan_packet_1993,ma_demonstration_2019,zhao_reinforcement-learning-based_2019,wang_subcarrier-slot_2019,luo_leveraging_2019,natalino_optical_2020,ma_co-allocation_2020,wang_deepcms_2020,weixer_reinforcement_2020,liu_multi-agent_2021,zhao_service_2021,tian_reconfiguring_2021,morales_multi-band_2021,tanaka_reinforcement-learning-based_2022,koch_reinforcement_2022,hernandez-chulde_evaluation_2022,etezadi_deepdefrag_2022,etezadi_deep_2023,tanaka_adaptive_2023,johari_drl-assisted_2023,zhang_admire_2023,fan_blocking-driven_2023,lian_dynamic_2024,li_tabdeep_2024,wang_availability-aware_2024,yin_dnn_2024,tse_reinforcement_2024,tanaka_reinforcement-learning-based_2024,doherty_xlron_2024,natalino_optical_2024,mccann_sdonsim_2024,jara_dream-gym_2024}.}
    \label{fig:lit_barchart}
\end{figure}



\subsection{Survey methodology}
\label{sec:survey-methodology}

%we searched the Google Scholar database using the following search terms: "'REINFORCEMENT LEARNING' AND 'NETWORK' AND ('OPTICAL' OR 'WAVELENGTH' OR 'SPECTRUM')". Papers were limited to English-language peer-reviewed articles. We filtered the search results by inspection of paper titles and abstracts, and manually added any related works from our own citation database that were missing from the initial search. A review of the collected papers then created the final set of 97.

To provide an overview of research progress on RL applied to DRA problems in optical networks, we searched to gather all relevant research papers. We performed a manual review of results from citation databases to create the final set of 97 peer-reviewed papers. Figure \ref{fig:lit_barchart} shows the count of papers by publication year. The papers are grouped in 4 categories: 'RWA', 'RSA', 'RMSA', and 'Other'. We use this set of papers for our analysis of benchmarking practices in the field, which we present in the next section with further commentary on figure \ref{fig:lit_barchart}. 

%the 'Other' category of figure \ref{fig:lit_barchart}, which includes papers on RL applied to: traffic grooming \cite{tanaka_reinforcement-learning-based_2022,zhang_admire_2023,tanaka_adaptive_2023,tanaka_reinforcement-learning-based_2024}, defragmentation \cite{etezadi_deepdefrag_2022,fan_blocking-driven_2023,johari_drl-assisted_2023,etezadi_deep_2023}, survivability or service restoration \cite{zhao_reinforcement-learning-based_2019,luo_leveraging_2019,zhao_service_2021,hernandez-chulde_evaluation_2022,zhao_rsa_2022,luo_survivable_2022,jiao_reliability-oriented_2022}, multicast provisioning \cite{garcia_multicast_2003,tian_reconfiguring_2021,li_tabdeep_2024}, simulation training environments \cite{natalino_optical_2020,natalino_optical_2024,doherty_xlron_2024,mccann_sdonsim_2024}, and other problems such as transceiver parameter optimization \cite{weixer_reinforcement_2020,koch_reinforcement_2022,koch_high-generalizability_2022} or launch power optimization \cite{tse_reinforcement_2024}


\subsection{Review of benchmarking practices}
\label{sec:benchmarking_practices}


%To understand progress on RL applied to DRA problems in optical networks, it is essential to have standard benchmarks. Benchmarks refer to both the problem under investigation and the quality of the solution. In machine learning research, performance benchmarks on MNIST \cite{li_deng_mnist_2012} and ImageNet \cite{krizhevsky_imagenet_2012} have been vital to the astounding progress in that field. 


In optical networks research, the first benchmark for RL was established by DeepRMSA \cite{chen_deeprmsa_2019} (discussed in detail in Section \ref{sec:repro}). DeepRMSA was the first RL approach to achieve lower service blocking probability than KSP-FF, or any heuristic that considers multiple candidate paths. As a result of this breakthrough performance, and its open source codebase, the problem definition from DeepRMSA (topologies, traffic model, modulation format reach, FSU per link, etc.) became a de facto standard. Follow-up works used identical or similar problem definitions and compared to DeepRMSA on their problem \cite{xu_spectrum_2021,quang_magc-rsa_2022,errea_deep_2023,tang_heuristic_2022,xu_deep_2022,cheng_ptrnet-rsa_2024,yan_drl-based_2024,zhou_opti-deeproute_2024}. Arguably, comparing to DeepRMSA has become standard benhcmarking practice.

%Although this comparison to the "state of the art" appears to be good practice, it is misguided. The performance of RL agents is highly sensitive to algorithmic details and hyperparameters \cite{engstrom_implementation_2020}, random seeds, and non-deterministic factors \cite{nagarajan_impact_2018}. Guidelines have been established for the reliable comparison of competing RL approaches \cite{henderson_deep_2019}. The comparisons to DeepRMSA in follow-up works have not followed these guidelines. For example, hyperparameters such as learning rate and discount factor should be tuned when applying an algorithm to a new setting. Consequently, the comparisons to DeepRMSA in follow-up works are not fair.

Previous work has called for more rigorous benchmarking practices for research on RL for optical networking \cite{di_cicco_deep_2022}, with recommendations for comparison against other machine learning approaches such as GA and PSO, in addition to estimated bounds on network blocking or throughput. Some studies of RL for resource allocation have restricted themselves to sufficiently small problem sizes and static traffic, to enable comparison to ILP results \cite{liu_waveband_2021,di_cicco_deep_2022,zhao_rsa_2022,momo_ziazet_deep_2022,di_cicco_deepls_2023}. Although this provides a reliable bound, it is not applicable to dynamic traffic.

Benchmarking against standard heuristic algorithms, such as KSP-FF, avoids the complexity of training a rival machine learning approach, performs deterministic allocation, and can scale to large problem instances. However, it is important to choose the best performing heuristic for a particular case of study as a benchmark. Of the papers that benchmark their RL solution to KSP-FF (or other heuristics that consider multiple candidate paths) \cite{chen_deeprmsa_2019,chen_multi-task-learning-based_2021,shi_deep-reinforced_2021,shimoda_deep_2021,xu_spectrum_2021,zhao_reinforced_2021,zhao_service_2021,shimoda_mask_2021,quang_magc-rsa_2022,tu_entropy-based_2022,tang_heuristic_2022,xu_deep_2022,cheng_routing_2022,nevin_techniques_2022,tang_deep_2022,di_cicco_deep_2022,terki_routing_2023,sadeghi_performance_2023,tanaka_adaptive_2023,tang_routing_2023,xu_hierarchical_2023,errea_deep_2023,hernandez-chulde_experimental_2023,cheng_ptrnet-rsa_2024,fan_blocking-driven_2023}, most achieve 20-30\% reduction in service blocking probability compared to their best heuristic. Only 3 papers achieve a reduction greater than this: MaskRSA \cite{shimoda_mask_2021}, PtrNet-RSA \cite{cheng_ptrnet-rsa_2024}, and Terki et al \cite{terki_routing_2022}. Despite these impressive results, we demonstrate in Section \ref{sec:repro_main} that MaskRSA and PtrNet-RSA are beaten by KSP-FF or FF-KSP by considering 50 candidate paths and ordering the paths by number of hops\footnotemark.

\footnotetext{We have not re-created the study of Terki et al. for benchmarking in Section \ref{sec:repro_main} as it is multi-band and out of scope of this work.
We hypothesise that their approach performs strongly because, similar to PtrNet-RSA, it is not limited to selecting from only K paths.}

Benchmarking is further complicated by the fast evolution of optical networking, with novel paradigms such as multi-band \cite{beghelli_approaches_2023} and multi-core \cite{pinto-rios_resource_2023} emerging, and the wide variety of network topologies \cite{matzner_topology_2024} and components that can be considered. The evolution of optical networks research is evidenced by growth in the 'Other' category of figure \ref{fig:lit_barchart}, which includes papers on RL applied to: traffic grooming \cite{tanaka_reinforcement-learning-based_2022,zhang_admire_2023,tanaka_adaptive_2023,tanaka_reinforcement-learning-based_2024}, defragmentation \cite{etezadi_deepdefrag_2022,fan_blocking-driven_2023,johari_drl-assisted_2023,etezadi_deep_2023}, survivability or service restoration \cite{zhao_reinforcement-learning-based_2019,luo_leveraging_2019,zhao_service_2021,hernandez-chulde_evaluation_2022,zhao_rsa_2022,luo_survivable_2022,jiao_reliability-oriented_2022}, multicast provisioning \cite{garcia_multicast_2003,tian_reconfiguring_2021,li_tabdeep_2024}, %simulation training environments \cite{natalino_optical_2020,natalino_optical_2024,doherty_xlron_2024,mccann_sdonsim_2024}, 
and other problems such as transceiver parameter optimization \cite{weixer_reinforcement_2020,koch_reinforcement_2022,koch_high-generalizability_2022} or launch power optimization \cite{tse_reinforcement_2024}

The establishment of reliable benchmarks is made more difficult by the fragmented software environment for optical network simulations for RL. Several open source toolkits have been introduced to aid researchers and improve productivity, but none has proved sufficiently popular for it to become standard. Optical-rl-gym \cite{natalino_optical_2020} was the first paper to attempt to introduce a new standard library for this task. This was followed by an extension to multi-band environments \cite{morales_multi-band_2021} and in 2024 was further extended to include a more sophisticated physical layer model for lightpath SNR calculations, renamed as the Optical Networking Gym \cite{natalino_optical_2024}. Additionally, MaskRSA provides an open source simulation framework (RSA-RL) \cite{shimoda_mask_2021} and DeepRMSA's codebase is widely used \cite{chen_deeprmsa_nodate}. SDONSim \cite{mccann_sdonsim_2024} and DREAM-ON-GYM \cite{jara_dream-gym_2024} are other recent additions to the landscape of available simulation frameworks that further fragment the available options. 

In summary, progress in applying RL to DRA problems in optical networks has been difficult to quantify due to several factors. First, the lack of standardized benchmarking practices has made it challenging to fairly compare different approaches. Second, while some studies have used ILP solutions as benchmarks, these are limited to small problem sizes and static traffic scenarios, making them impractical for large-scale or dynamic applications. Third, multiple competing simulation frameworks %(Optical-rl-gym, RSA-RL, SDONSim, DREAM-ON-GYM) 
and publications without open source code, have made it difficult to ensure consistent testing conditions across different studies. Finally, the rapid evolution of optical networking technology means benchmarks must constantly evolve to remain relevant. 

The lack of reliable benchmarks, and the resulting difficulty in assessing progress in the field, is what motivates our investigations of heuristic benchmarks in Section \ref{sec:heuristic_comparison} and their application to our reproduction of previous studies in Section \ref{sec:repro_main}.

%As we show in section \ref{sec:repro}, heuristic algorithms . This underscores the need for more rigorous and standardized evaluation methods in this field. 
% 

%In this work we use XLRON \cite{doherty_xlron_2023}, the framework introduced at Optical Fibre Communications (OFC) 2024 that we continue to develop. We outline its benefits and justify its use in Section \ref{sec:repro}.



\subsection{Selection of papers for benchmarking}
\label{sec:paper_summaries}

On the basis of our review of benchmarking practices, we select 5 papers to reproduce and re-benchmark in section \ref{sec:repro_main}. We select these papers primarily because they all compare their results to "DeepRMSA"\footnotemark with similar traffic models and topologies, therefore present the most consistent application of benchmarks in the field. We also select based on their impact, which we assess by qualitative and quantitative criteria. The qualitative criteria are novelty, contribution, and reputation of publication or conference. The quantitative criterion is their blocking performance relative to benchmarks. They are also among the most highly cited papers in the field, as of January 2025.

\footnotetext{We note that the training of RL solutions is highly sensitive to hyperparameters \cite{engstrom_implementation_2020} and non-deterministic factors \cite{nagarajan_impact_2018}, therefore the comparisons that the selected papers make to re-trained DeepRMSA agents may not be robust.}


\begin{enumerate}[itemsep=0pt]
    \item \textbf{DeepRMSA} \cite{chen_deeprmsa_2019} constructs a feature matrix to represent the available paths for the current requests and applies a NN with 5 x 128 hidden units to select from the K-shortest paths with first-fit spectrum allocation. It demonstrates service blocking probability(SBP) reduced by 20\% vs. KSP-FF on the NSFNET and COST239 topologies. DeepRMSA's impact was enhanced by its open source codebase. %published 2019, has over 178 citations.
    \item \textbf{Reward-RMSA} \cite{tang_heuristic_2022} builds on the DeepRMSA framework and changes the reward function to incorporate fragmentation-related information. They report SBP reduced by 32\% vs. multiple heuristics and 55\% vs. DeepRMSA on NSFNET and COST239. %published 2022, has over 22 citations.
    \item \textbf{GCN-RMSA} \cite{xu_deep_2022} is notable as the first work to use advanced NN architectures to improve performance. They use a graph convolutional network (GCN) (including recurrent neural network (RNN) as the path aggregation function) in the policy and value functions, which they claim allows improved feature extraction from the network state. Like DeepRMSA and Reward-RMSA, the policy selects from K paths with first-fit spectrum allocation. They report SBP reduced by up to 30\% vs. multiple heuristics and 18\% vs. DeepRMSA. on NSFNET, COST239, and USNET. %published 2022, has over 36 citations
    \item \textbf{MaskRSA} \cite{shimoda_mask_2021} innovated by selecting from the entire range of available slots on the K paths and using invalid action masking \cite{huang_closer_2020} to increase the efficiency of training. Despite the RSA in the title, the paper does consider distance-dependent modulation format (RMSA). MaskRSA presented improvements over KSP-FF on NSFNET and JPN48 topologies with over an order of magnitude lower SBP, or a 35-45\% increase in the supported traffic in their cases of study. The authors of MaskRSA also contributed to open source by releasing their simulation framework, RSA-RL. %published 2021, has over 28 citations
    \item \textbf{PtrNet-RSA} \cite{cheng_ptrnet-rsa_2024}, newly published in 2024. It innovates in both the problem setting and its use of pointer-nets \cite{vinyals_pointer_2015}. The pointer-net is used to select the constituent nodes of the target path, thereby removing the restriction of selecting from the pre-calculated K-shortest paths. Invalid action masking is used to allow selection from all available spectral slots. Additionally, the paper considers joint optimization of the mean path SNR and the SBP through its reward function. It demonstrates SBP reduced by over an order of magnitude vs. KSP-FF and their implementation of MaskRSA on NSFNET, COST239, and USNET.
\end{enumerate}


%Although this comparison to the "state of the art" appears to be good practice, it is misguided. The performance of RL agents is highly sensitive to algorithmic details and hyperparameters \cite{engstrom_implementation_2020}, random seeds, and non-deterministic factors \cite{nagarajan_impact_2018}. Guidelines have been established for the reliable comparison of competing RL approaches \cite{henderson_deep_2019}. The comparisons to DeepRMSA in follow-up works have not followed these guidelines. For example, hyperparameters such as learning rate and discount factor should be tuned when applying an algorithm to a new setting. Consequently, the comparisons to DeepRMSA in follow-up works are not fair.





% \subsection{Research trends}
% \label{sec:trends}

% Our analysis of the literature reveals several significant trends:

% \textbf{Timeline and Technology Adoption: }
% A marked increase in publications began in 2019, following the influential DeepRMSA paper \cite{chen_deeprmsa_2019}. This represents a 5-6 year lag between breakthrough ML publications (e.g. Deep RL for Atari in 2013 \cite{mnih_human-level_2015}) and adoption in optical networking. Publication activity peaked in 2022, with a notable dip in 2020 due to the COVID-19 pandemic.

% \textbf{Evolution of Problem Focus: }
% Early work (pre-2019) predominantly addressed RWA but RWA publications have declined since, with no publications in 2024. Research attention has shifted toward RMSA. Recent work also increasingly addresses specialized problems beyond basic routing and spectrum allocation, as seen by the rise in "Other" categories.

% \textbf{Research Maturity and Diversification: }
% The growth in "Other" categories suggests researchers are seeking new directions. Recent publications show movement toward novel application areas with potentially greater performance gains, such as multi-objective optimization \cite{nallaperuma_interpreting_2023}, joint optimization of blocking and lightpath signal-to-noise ratio (SNR) \cite{cheng_ptrnet-rsa_2024,xie_physical_2024,teng_deep-reinforcement-learning-based_2024,yan_drl-based_2024} or channel launch power \cite{xiao_channel_2024}. We hypothesise this shift may be partly motivated by a saturation of performance improvements in simpler RWA/RSA/RMSA problems, which we investigate in section \ref{sec:bounds}.



% \subsection{Recommendations for reporting metrics and reproducibility}
% \label{sec:recommendations}
% Based on the above review, we make  recommendations to improve the quality and reproducibility of results:

% \textbf{Improved metrics}

% For a more meaningful performance comparisons, several metrics could be refined, as outlined in this section.

% - Network data throughput: use bitrate blocking probability (BBP) rather than service blocking probability (SBP) to quantify network blocking.  Key when traffic requests have diverse bitrate requirements. For RWA or uniform bitrate traffic, BBP and SBP are equivalent. 

% Consider the approach of Shiraki et al. \cite{shiraki_dynamic_2019} and Cruzado et al. \cite{cruzado_capacity-bound_2024} of setting a target blocking probability (e.g., 0.1\%) and comparing solutions based on the maximum traffic load that can be supported. Data traffic in Tbps is a more easily interpreted and physically meaningful measure than blocking probability.This is used to present network blocking bounds in Section \ref{sec:bounds}. We believe that researchers have preferred to report on blocking probability as it allows headline results to appear more impressive (e.g. "one order of magnitude reduction") than the equivalent relative change in supported traffic



% \textbf{Statistical Significance:}
% Many works do not include sufficient trials to establish statistical significance, particularly when blocking events are rare. It is proposed that the following steps are followed:
% \begin{itemize}[itemsep=0pt]
%     \item Obtain a sufficient number of blocking events (minimum 100) to have >95\% confidence in mean blocking estimate
%     \item Ensure different random seeds are used for parallel training or evaluation runs
%     \item Publish uncertainty estimates along with mean performance metrics
%     \item Use multiple random seeds (minimum 5) for both training and evaluation
% \end{itemize}

% \textbf{Reproducibility:}
% We propose to compare network blocking from deterministic heuristic algorithms. When comparing against existing RL solutions, we emphasise the following:
% \begin{itemize}[itemsep=0pt]
%     \item Hyperparameters must be re-tuned when the problem setting differs from the original paper
%     \item Equivalent computing resources should be devoted to performing hyperparameter sweeps for and training competing solutions
%     \item All code should be made publicly available, with instructions to reproduce published results.

    
% \end{itemize}





















%%%%%%%%%%%%%%%%%%

%Shi et al. showed progress in the problem setting by including a simple lightpath SNR calculation to the network physical layer model, and calculating the highest available modulation format on the basis of SNR instead of maximum reach \cite{shi_deep-reinforced_2021}. They make this minor addition and otherwise use the same algorithmic setup as DeepRMSA.

%Unusually, a negative result was accepted for publication at ONDM 2021 on RL for multi-band RMSA \cite{sheikh_multi-band_2021}. This can partially be explained by interest in the relatively novel problem setting but perhaps also indicates that progress on the application of RL to this problem and similar was stalling.


% Could complete the argument by saying that the solutions provided by the defragmentation method are entirely physically realistic, therefore present a hard upper bound on network capacity, in comparison to the cut-sets method which may be tighter than necessary due to sub-optimal spectrum allocation.
%% IDEA: the best upper bound would probably be to do cut-sets with defragmented spectrum i.e. just do cut-sets with scalar capacity on each link, i.e. just do the traditional max-flow min-cut theorem but with the defragmented spectrum. This would be the most physically realistic upper bound. Could be a good future work idea.


% Specifically, the successor works that use the DeepRMSA codebase are . Note that 

% The direct successor works are from Chen et al using the DeepRMSA framework with transfer learning on different topologies and traffic \cite{chen_multi-task-learning-based_2021}, Tang et al using a shaped reward function to improve performance, Xu et al using graph and recurrent neural networks to for the policy network to improve performance \cite{xu_deep_2022}, Xu et al investigate a hierarchical framework for multi-domain networks \cite{xu_hierarchical_2023}, Errea et al use DeepRMSA with two choices of first slots per path \cite{errea_deep_2023}, a modification that was investigated in the original DeepRMSA paper. DeepRMSA has also been used as a benchmark in MaskRSA \cite{shimoda_mask_2021} and PtrNet-RSA \cite{cheng_ptrnet-rsa_2024}.

















%%%%%%%%%%%%%%%%%%





% 0  DeepRMSA: A Deep Reinforcement Learning Framew...     chen_deeprmsa_2019
% 1  Mask RSA: End-To-End Reinforcement Learning-ba...      shimoda_mask_2021
% 2  Techniques for applying reinforcement learning...  nevin_techniques_2022
% 3  The Optical RL-Gym: An open-source toolkit for...  natalino_optical_2020
% 4  Heuristic Reward Design for Deep Reinforcement...    tang_heuristic_2022

% Total entries: 97
% Matched entries: 97
% Matching rate: 100.00%
% Papers classified as 'Other':
% - The Optical RL-Gym: An open-source toolkit for applying reinforcement learning in optical networks
% - Reconfiguring multicast sessions in elastic optical networks adaptively with graph-aware deep reinforcement learning
% - DRL-Assisted Reoptimization of Network Slice Embedding on EON-Enabled Transport Networks
% - Blocking-Driven Spectrum Defragmentation Based on Deep Reinforcement Learning in Tidal Elastic Optical Networks
% - DeepDefrag: A deep reinforcement learning framework for spectrum defragmentation
% - Multi-band Environments for Optical Reinforcement Learning Gym for Resource Allocation in Elastic Optical Networks
% - TABDeep: A two-level action branch architecture-based deep reinforcement learning for distributed sub-tree scheduling of online multicast sessions in EON
% - Reinforcement-learning-based path planning in multilayer elastic optical networks [Invited]
% - Adaptive Traffic Grooming Using Reinforcement Learning in Multilayer Elastic Optical Networks
% - Reinforcement-Learning-based Multilayer Path Planning Framework that Designs Grooming, Route, Spectrum, and Operational Mode
% - ADMIRE: collaborative data-driven and model-driven intelligent routing engine for traffic grooming in multi-layer X-Haul networks
% - Packet Routing in Dynamically Changing Networks: A Reinforcement Learning Approach
% - Reinforcement Learning for Power Management in Low-margin Optical Networks
% - DNN distributed inference offloading scheme based on transfer reinforcement learning in metro optical networks
% - Availability-Aware and Delay-Sensitive RAN Slicing Mapping Based on Deep Reinforcement Learning in Elastic Optical Networks
% - DREAM-ON GYM: A Deep Reinforcement Learning Environment for Next-Gen Optical Networks:
% - Dynamic slicing of multidimensional resources in DCI-EON with penalty-aware deep reinforcement learning
% - DeepCMS <sup>3</sup> : A Deep Reinforcement Learning Framework for Core, Mode and Spectrum Sequential Scheduling over Optical Transport Network
% - A Subcarrier-Slot Autonomous Partition Scheme Based on Deep-Reinforcement-Learning in Elastic Optical Networks
% - Reinforcement-Learning-Based Multi-Failure Restoration in Optical Transport Networks
% - Demonstration of Image Processing Based on Reinforcement Learning in Multi-Modal Optical Transport Networks
% - Co-Allocation of Service Routing in SDN-driven 5G IP+Optical Smart Grid Communication Networks based on Deep Reinforcement Learning
% - Service restoration in multi-modal optical transport networks with reinforcement learning
% - Multi-Agent Federated Reinforcement Learning for Privacy-enhanced Service Provision in Multi-domain Optical Network
% - Evaluation of Deep Reinforcement Learning for Restoration in Optical Networks
% - Deep reinforcement learning for proactive spectrum defragmentation in elastic optical networks
% - XLRON: Accelerated Reinforcement Learning Environments for Optical Networks
% - Reinforcement Learning for Generalized Parameter Optimization in Elastic Optical Networks
% - Optical Networking Gym: an open-source toolkit for resource assignment problems in optical networks
% - SDONSim: An Advanced Simulation Tool for Software-Defined Elastic Optical Networks
% - Leveraging double-agent-based deep reinforcement learning to global optimization of elastic optical networks with enhanced survivability
% - A Reinforcement Learning Framework for Parameter Optimization in Elastic Optical Networks

% Papers classified as 'Routing':

% Tag distribution:
% RMSA: 33 (34.02%)
% Other: 32 (32.99%)
% RSA: 18 (18.56%)
% RWA: 14 (14.43%)

% Total papers: 97

% First few rows of the updated DataFrame:
%                                                Title  \
% 0  DeepRMSA: A Deep Reinforcement Learning Framew...   
% 1  Mask RSA: End-To-End Reinforcement Learning-ba...   
% 2  Techniques for applying reinforcement learning...   
% 3  The Optical RL-Gym: An open-source toolkit for...   
% 4  Heuristic Reward Design for Deep Reinforcement...   

%                 Manual Tags Priority_Tag  
% 0                  RL; RMSA         RMSA  
% 1  RL; RMSA; Action masking         RMSA  
% 2      RL; RWA; Incremental          RWA  
% 3        RL; Other; Toolkit        Other  
% 4                  RL; RMSA         RMSA  
% Citation tags for each priority tag class, sorted by publication date:

% Other:
% boyan_packet_1993,ma_demonstration_2019,zhao_reinforcement-learning-based_2019,wang_subcarrier-slot_2019,luo_leveraging_2019,natalino_optical_2020,ma_co-allocation_2020,wang_deepcms_2020,weixer_reinforcement_2020,liu_multi-agent_2021,zhao_service_2021,tian_reconfiguring_2021,morales_multi-band_2021,tanaka_reinforcement-learning-based_2022,koch_reinforcement_2022,hernandez-chulde_evaluation_2022,etezadi_deepdefrag_2022,etezadi_deep_2023,tanaka_adaptive_2023,johari_drl-assisted_2023,zhang_admire_2023,fan_blocking-driven_2023,lian_dynamic_2024,li_tabdeep_2024,wang_availability-aware_2024,yin_dnn_2024,tse_reinforcement_2024,tanaka_reinforcement-learning-based_2024,doherty_xlron_2024,natalino_optical_2024,mccann_sdonsim_2024,jara_dream-gym_2024

% RMSA:
% chen_deeprmsa_2019,wang_resource_2020,shimoda_mask_2021,shi_deep-reinforced_2021,shimoda_deep_2021,sheikh_multi-band_2021,xu_spectrum_2021,chen_multi-task-learning-based_2021,gonzalez_improving_2022,bryant_q-learning_2022,terki_routing_2022,tang_deep_2022,cheng_routing_2022,xu_deep_2022,tang_heuristic_2022,tu_entropy-based_2022,momo_ziazet_deep_2022,pinto-rios_resource_2023,errea_deep_2023,beghelli_approaches_2023,terki_routing_2023,tanaka_pre-_2023,xu_hierarchical_2023,sadeghi_performance_2023,tang_routing_2023,teng_deep-reinforcement-learning-based_2024,xiong_graph_2024,teng_drl-assisted_2024,unzain_reinforcement_2024,zhou_opti-deeproute_2024,li_opticgai_2024,xie_physical_2024,yan_drl-based_2024

% RSA:
% reyes_adaptive_2017,li_deepcoop_2020,li_multi-objective_2020,romero_reyes_towards_2021,zhao_reinforced_2021,wang_dynamic_2021,quang_magc-rsa_2022,cruzado_reinforcement-learning-based_2022,zhao_rsa_2022,jiao_reliability-oriented_2022,almasan_deep_2022,wu_service_2022,arce_reinforcement_2022,sharma_deep_2023,lin_deep-reinforcement-learning-based_2023,hernandez-chulde_experimental_2023,cheng_ptrnet-rsa_2024,chen_gsaddqn_2024

% RWA:
% garcia_multicast_2003,pointurier_reinforcement_2007,koyanagi_reinforcement_2009,suarez-varela_routing_2019,shiraki_dynamic_2019,shiraki_reinforcement-learning-based_2019,tzanakaki_self-learning_2020,zhao_cost-efficient_2021,freire-hermelo_dynamic_2021,liu_waveband_2021,nevin_techniques_2022,di_cicco_deep_2022,di_cicco_deepls_2023,nallaperuma_interpreting_2023

% Date range for each tag class:
% RMSA: 2019 - 2024
% RWA: 2003 - 2023
% Other: 1993 - 2024
% RSA: 2017 - 2024







% K-paths used but not beaten: \cite{sheikh_multi-band_2021,zhao_cost-efficient_2021}
% K-paths beaten: \cite{chen_deeprmsa_2019,chen_multi-task-learning-based_2021,,shi_deep-reinforced_2021,shimoda_deep_2021,xu_spectrum_2021,zhao_reinforced_2021,zhao_service_2021,shimoda_mask_2021,quang_magc-rsa_2022,terki_routing_2023,tu_entropy-based_2022,tang_heuristic_2022,xu_deep_2022,cheng_routing_2022,nevin_techniques_2022,tang_deep_2022,di_cicco_deep_2022,fan_blocking-driven_2023,sadeghi_performance_2023,tanaka_adaptive_2023,tang_routing_2023,xu_hierarchical_2023,errea_deep_2023,hernandez-chulde_experimental_2023,cheng_ptrnet-rsa_2024}
% ILP: \cite{liu_waveband_2021,di_cicco_deep_2022,zhao_rsa_2022,momo_ziazet_deep_2022,di_cicco_deepls_2023}
% DeepRMSA as benchmark: \cite{xu_spectrum_2021,quang_magc-rsa_2022,errea_deep_2023,tang_heuristic_2022,xu_deep_2022,cheng_ptrnet-rsa_2024,yan_drl-based_2024,zhou_opti-deeproute_2024}


% - DeepRMSA became a benchmark
% - I want to make the point that it is difficult to establish long-lived standard problems in optical networks as the field evolves quickly and new operating paradigms (such as multi-band andm utli-core) are consistently emerging.
% - 

% \cite{henderson_deep_2019} Deep Reinforcement Learning That Matters - general good practice (i.e.e epxeirmental reporting and procedure) for reproducibility of RL results
% \cite{nagarajan_impact_2018}  Impact of non-determinism in RL
% \cite{engstrom_implementation_2020} Sensitivity of PPO to code-level optimizations and implementation details


