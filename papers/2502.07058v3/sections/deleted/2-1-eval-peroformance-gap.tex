%\kenneth{Did people compare NLP models' performances across language variations? How? What did they find? Why can (or can not) their methods be used in our case?}

%\zixin{Here are several existing benchmarks specifically for language variation/diversity}
%\kenneth{Cool. Say a few words about what these benchmarks did? How do they compare model performance across variations?}
%\zixin{What about tasks directly focus on detecting language variation? i.e. dialect detection and identification? I just separated those papers from other benches so we can discuss them later.}\kenneth{In our setting, we kinda KNOW the variation of each data item, as Booking.com has users' self-reported nationality/region. So, variation detection is a separate problem-- it might be useful when, say, your data don't tell you the variations, so you need to detect them yourself.}

%\zixin{I found this 2020 ACL paper discussing several "missing parts" NLP studies on "biases", including related work outside of NLP tasks and communities. It might be worth taking a look}
%\cite{blodgett2020biasreview}


%General NLP benchmarks for language variations/diversity: DIALECTBENCH~\cite{dialectbench}, VALUE (Specific for African American English~\cite{valuebench}), Macuco corpus \cite{macucocorpus}


%\paragraph{CAMP 1: Compared or aligned using NLP tasks.}
%DIALECTBENCH~\cite{dialectbench}:
%Collect a set of languages and put them in the same leaderboard





%\kenneth{Bad: It's not really a fair or even comparable comparison.}

%\paragraph{CAMP 2: Compared or aligned using data (direct conversion at the instance level).}

%VALUE~\cite{valuebench}:
%Use rule-based approaches to convert MAE to AAE and eval on AAE. The conversation was validated by humans!

%Multi-VALUE~\cite{multivaluebench}:
%Extended version of VALUE to 50 dialects with 189 linguistic features, and synthetic mapping to SAE. Native speakers verified several dialects.

%\kenneth{Bad: Conversion is hard or expensive}








%\cite{hovy-johannsen-2016-exploring}

%\kenneth{This is one paper I found, which has a whole ``Language Variation'' subsection. Maybe take a look:}
%\cite{lwowski2022measuring}

%\kenneth{Did people compare NLP models' performances across different languages? How? What did they find? Why can (or can not) their methods be used in our case?}


%\kenneth{Now when I think about it, we can also learn some methods from people who work on biases in AI models on how they compare AI models' performances gap across different user populations}

%\paragraph{scenario-based studies for biases in AI models regarding language variations}

%Case study for AAE tweets~\cite{AAE2017racial}: This case study investigated models' performance gap on language identification tasks regarding AAE and SAE tweets. Results showed gaps in identifying AAE short tweets as English, indicating potential biases against minority language users in large-scale models training on major language variation.

%\textbf{Method:} Language identification tasks (whether it is an English tweet) on AAE and SAE tweets

%\citeauthor{groenwold2020AAENLP}: Using parallel AAVE/SAE tweet prompts and GPT-2, researchers found a consistent disparity in AAVE-like generation, including the sentiment analysis scores, benchmark scores on BLUE and ROUGE, and human-based evaluation on generated text quality. 

%\textbf{Method:} stat. analyses on benchmark scores (sentiment, BLUE, ROUGE) and human evaluations regarding NLG output.

%\citeauthor{liang2023gptesl}: Compared to essays from 8th-grade native speakers, non-native English essays have a higher chance of being classified as "AI-generated" by GPT-based detectors (ChatGPT in this case). Such issues can be reduced by enhancing word choices in the essays, indicating that such a biased pattern is related to linguistic diversity in language production.

%\textbf{Method:} Ratio of "AI-generated" labels regarding non-native essays and essays from 8th-grade students.

%\citeauthor{kwako2023bertbias}: This study investigated BERT's performance of rating transcripts of non-native speakers' speeches, and whether BERT can perform similar patterns as humans when conducting the same tasks. Results showed that BERT may exacerbate the difference against different non-native speakers groups, indicating potentially stronger implicit biases in BERT. Such rating differences are larger if the speaker is older or speaks longer. 

%\textbf{Method:} auto-grading system based on off-the-shelf BERT(so zero-shot I guess?), and the differences between humans' and BERT's scores are represented as differential item functioning (DIF)


%Macuco corpus~\cite{macucocorpus}:
%A parallel data for multiple English variations in Europe. Includes only variation identification tasks.
