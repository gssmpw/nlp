
\begin{comment}
    

Relaxing strict semantic alignment between paired text items inevitably introduces confounding variables.
%We believe that 
This trade-off is worth exploring because it enables researchers to compare model behaviors across language varieties in new ways. 
%is worthwhile, as it enables comparisons of model behavior across language varieties in new ways. %that were previously impossible.
This section examines a few potential confounding variables.
%This section examines a few key factors.
\end{comment}

\paragraph{Could the performance gap be due to \cnChinese reviews having better \ul{writing quality} or better \ul{alignment between content and ratings}?}
\textit{Rationale:} Better writing quality or better content-rating alignment could make it easier for LLMs to predict ratings.
\textit{Analysis \& Findings:} \textbf{No.} 
Our human validation (Section~\ref{sec:data-quality-validation}) shows that \cnChinese reviews had slightly worse writing quality and content-rating alignment. 









\paragraph{Could the performance gap be due to more \ul{code-mixed usage} in \twChinese?}
\textit{Rationale:} NLP models often struggle with code-mixed data~\cite{zhang-etal-2023-multilingual, ochieng2024beyond}. 
%\kenneth{TODO Zixin: Add citations}
\textit{Analysis \& Findings:}
\textbf{No.}
%\twChinese reviews contained less code-mixed usage.
The \cnChinese reviews contain more mixed-language input (30.99\%) than the \twChinese reviews (25.26\%, see Appendix~\ref{appendix:language-analysis} and Table~\ref{tab:language-distribution}).
%\kenneth{TODO CY: I fixed the ref. Are these (1) ref and (2) numbers correct?}\cy{number is correct and based on our latest table}
%Our findings aligned with other studies investigating LLMs' performance between simplified Mandarin (used in Mainland China) and traditional Mandarin (used in Taiwan), which showed potential performance disparity across multiple NLP tasks in Taiwan Mandarin~\cite{chen2024measuring}.

\paragraph{Could the performance gap be due to \cnChinese \ul{users} systematically \ul{giving higher scores}, which align better with LLM-generated scores?}
\textit{Rationale:} LLMs tend to assign higher scores~\cite{stureborg2024large,kobayashi-etal-2024-large,golchin-etal-2025-grading}.
%wang-etal-2024-large-language-models-fair,
%stureborg2024large,wang-etal-2024-large-language-models-fair,
%kobayashi-etal-2024-large
% \kenneth{TODO CY and Zixin: Is this true? If so, add citations.}
\textit{Analysis \& Findings:}
\textbf{Unlikely.}
%Even though we had fewer restrictions on the review pairing process (using similar rating reviews rather than reviews with the same scores) to maximize pairing amounts, this process didn't introduce biases in score rating. 
In our dataset, \twChinese and \cnChinese reviews show no significant difference in scores (\textit{t}(22917) = .160, \textit{p} = .873).
%In our dataset, there is no statistical difference in actual scores between \twChinese and \cnChinese reviews (\textit{t}(22917)=.160, \textit{p}=.873). 
%This result showed that in our data set, 
%Namely, reviews written in \cnChinese and \twChinese share a similar distribution of rating scores; there is no systematic scoring difference between the two groups.

\paragraph{Are \cnChinese reviews \ul{easier for humans to guess ratings}?}
\textit{Rationale:} Human performance is sometimes used as an indicator of a task's difficulty for LLMs~\cite{sakamoto-etal-2025-development,ding2024easyhardbench}.
% \kenneth{TODO CY and Zixin: Add citations.}
\textit{Analysis \& Findings:}
\textbf{Plausible.}
We conducted a user study with 10 participants (5 native speakers from each variety) who reviewed 50 random CN-TW review pairs (100 total reviews) and predicted their rating scores.
%Participants also rated the readability and nativeness of each review.
%More details are provided in \Cref{app:human-prediction}.
%Although there was no significant difference in readability or nativeness between CN and TW reviews, 
%In the study, 
Participants performed significantly better at predicting ratings for reviews in \cnChinese.
After excluding two TW native speakers whose accuracy was more than two standard deviations below the mean, 6 out of the 8 participants had better accuracy on CN reviews than TW reviews, and 7 had better (lower) MSE on CN reviews than TW reviews (see \Cref{app:human-prediction} for more details).
%\kenneth{TODO Zixin: (1) Update these numbers, (2) Move all other results of this study to Appendix: ``For overall content quality, our results show no significant differences in score predictions among the data pairs, indicating raters have no biases in reading and understanding reviews from either group of speakers/writers. However, results showed statistical significance in both ACC (37.00\% vs. 28.75\%, \textit{p}=.016) and MSE (2.795 vs. 3.510, \textit{p}=.036), showing that native speakers might have more difficulties in correctly guessing the review scores for reviews in \twChinese.''}
%We want to emphasize that 

These results should be interpreted with caution.
Unlike question-answering, predicting hundreds of review scores from content is not a typical human task, and most NLP papers on sentiment analysis do not compare model performance to human performance.
Thus, it is unclear whether human performance gaps in such tasks reliably indicate task difficulty for LLMs, especially given the small differences between the two varieties.
%As a result, it is unclear whether our findings indicate task difficulty for LLMs, especially given the relatively small differences in human performance between the two varieties.
Additionally, our participants may not represent the average Mandarin speaker's ability in sentiment analysis, as the two participants performed notably poorly. 
Finally, despite our efforts to examine confounding variables such as text length, code-mixing, and writing quality, we still \textbf{lack a clear understanding of what causes the observed LLMs' performance gaps across language varieties}.
%Further research is needed to understand LLM behavior across language varieties.
%Poor human performance does not necessarily mean LLMs will struggle in the same way.











%After excluding two TW native speakers whose accuracy was more than two standard deviations below the mean, 6 of the remaining 8 participants had higher accuracy on CN reviews than on Tw reivews, and 6 had lower MSE on CN reviews. 











%\zixin{1. no significant differences in naiveness and readability between two sets of reviews; 2. within raters, there are no significant differences in score predictions across \cnChinese and \twChinese review pairs - native speakers perceive similarly between \cnChinese and \twChinese reviews; \textbf{3. there are stat. significances in terms of ACC and MSE in prediction tasks with better performance towards \cnChinese reviews.}} 



%\kenneth{TODO Zixin: Add text here}

%, meaning this factor does not account for the performance gap.


%\kenneth{TODO: Human study will be done by Feb 3 (Mon)}