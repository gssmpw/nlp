
\section{Training Configurations}
\label{asec:hyperparameters}
We employed the DeepSpeed~\cite{rasley2020deepspeed} framework for distributed training across four GPU nodes, each equipped with four AMD MI250 GPUs. 
We used vLLM~\cite{kwon2023efficient} for inference.
Our implementation builds upon OpenRLHF~\cite{hu2024openrlhf} for both SFT and DPO. 
Given the input sequence length of up to 128K tokens, we leveraged FlashAttention-2~\cite{dao2023flashattention} alongside Ring Attention~\cite{liu2023ring} to efficiently process extremely long sequences. 
The detailed hyperparameters for SFT and DPO are provided in \cref{tab:hyperparameters_sft} and \cref{tab:hyperparameters_dpo}.
\input{tab/sft_config}
\input{tab/dpo_config}

\section{Short Context Performance}
\label{asec:short_context}
\input{tab/lmm_eval_table}

As shown in~\cref{tab:performance-benchmarks}, we evaluate the short-context perfromance across six tasks: ARC Easy, ARC Challenge, GSM8K, MathQA, MMLU, and MMLU Pro. \method performs on par with the base model Llama3.1-8B-Instruct on short-context benchmarks, demonstrating that \method preserves the original short-context ability while greatly enhancing long-context performance.

\section{Detailed Results on Seven Benchmark Tasks}
As shown in~\cref{tab:hotpotqa},~\cref{tab:nature_questions},~\cref{tab:triviaqa},~\cref{tab:popqa},~\cref{tab:narrativeqa},~\cref{tab:infbenchqa} and~\cref{tab:infbenchchoice}, we evaluate the long-context performance across seven tasks: HotpotQA, Natural Questions, TriviaQA, PopQA, NarrativeQA, InfiniteBench QA and InfiniteBench Multiple-Choice. 
\method provides significant improvement for all tasks, especially for those that require multi-hop reasoning such as HotPotQA.

\input{tab/full_results_table}

\section{\coclong Workflow}
The input was first processed into chunks and grouped with paragraph tags.
We list the example prompts used in~\method workflow below. In training, we sampled 100 variations of the same prompt text and use them randomly to avoid training collapse.

\begin{tcolorbox}[
    colback=black!5, colframe=black!50, 
    fontupper=\ttfamily\small, 
    title=\coclong Workflow Prompts
]
\textbf{[System Prompt]}

You are an AI assistant specialized in long context reasoning. Analyze information thoroughly while maintaining clarity and focus. Track the full context of conversations, building connections between concepts and flagging when context review is needed. Break down complex problems into components, showing your reasoning steps and stating key assumptions. Structure your responses with clear headers and periodic summaries. Present evidence for your conclusions, acknowledge uncertainties, and request clarification when needed. Keep your analysis organized, explicit, and focused on addressing the core question.

\textbf{[Long-Context Input]}

<para 1> [chunk 1] </para 1> <para 2> [chunk 2] </para 2> ...
\{Question\}

\textbf{[Self Clarification - Raise Question]}

In order to answer this question, ask one question about what you want to know in order to better answer it.

\textbf{[Contextual Grounding - Pointback]}

Help me find relevant context to answer the previous clarifying question.

\textbf{[Self Clarification - Answer Question]}

Based on the relevant context, answer the previous clarifying question.

\textbf{[Answer the Original Question]}

Now, let's answer the final question. Be concise in your answer.
\end{tcolorbox}


\section{Evaluation Template}
\label{asec:prompt_template}
We use GPT-4o~\cite{openai2023gpt4} to judge if the model's answer is correct. The specific prompt template with the structured output class is shown below.

\begin{tcolorbox}[
    colback=black!5, colframe=black!50, 
    fontupper=\ttfamily\small, 
    title=Verification Prompts
]
Please verify the following answer:

Question: {question}
Ground Truth Answers: {ground truth}
Predicted Answer: {answer}

Your task is to determine whether the predicted answer correctly matches the ground truth. Focus on overall correctness and provide a detailed explanation in the following format:


class VerificationResult:

    explanation: str   \# Justification 
    
    confidence: float  \# Confidence score in the range [0,1]
    
    correct\_answer: bool  \# True if the prediction is correct, otherwise False
\end{tcolorbox}
