% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

% Custom lib for tables
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{caption}
\usepackage{adjustbox} % for resizing if needed
\usepackage{array}
\usepackage{xspace}
\usepackage{cleveref}
%\usepackage{minted}
\usepackage{tcolorbox}

\newcommand{\methodlong}{Agentic Long-Context Understanding\xspace}
\newcommand{\method}{AgenticLU\xspace}
\newcommand{\coc}{CoC\xspace}
\newcommand{\coclong}{Chain-of-Clarifications\xspace}
\newcommand{\jingbo}[1]{\textcolor{blue}{\textbf{Jingbo}: #1}}
\newcommand{\yufan}[1]{\textcolor{green}{\textbf{Yufan}: #1}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Self-Taught Agentic Long-Context Understanding}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\author{
 \textbf{Yufan Zhuang\textsuperscript{1,2}},
 \textbf{Xiaodong Yu\textsuperscript{1}},
 \textbf{Jialian Wu\textsuperscript{1}},
 \textbf{Ximeng Sun\textsuperscript{1}},
 \textbf{Ze Wang\textsuperscript{1}},\\
 \textbf{Jiang Liu\textsuperscript{1}},
 \textbf{Yusheng Su\textsuperscript{1}},
 \textbf{Jingbo Shang\textsuperscript{2}},
 \textbf{Zicheng Liu\textsuperscript{1}},
 \textbf{Emad Barsoum\textsuperscript{1}}
\\
 \textsuperscript{1}AMD,
 \textsuperscript{2}UC San Diego
% \\
% \{\href{mailto:y5zhuang@ucsd.edu}{y5zhuang}, \href{mailto:jshang@ucsd.edu}{jshang}\}@ucsd.edu \\
% \{\href{mailto:xiaodong.yu@amd.com}{xiaodong.yu}, \href{mailto:zicheng.liu@amd.com}{zicheng.liu}\}@amd.com
}

\begin{document}
\maketitle
\begin{abstract}

% \jingbo{How about this flow:
% (1) The most challenging questions for LLMs are arguably the long-context questions that require multi-round of clarifications and retrieval. 
% (2) We propose to learn to decide when and what to clarify.
% (3) Specifically, following a pre-defined tree search workflow, we apply a LLM to long-context QA datasets to generate a variety of reasoning traces including the clarification questions and the contextual ground answers.
% (4) We then utilize these traces to fine-tune the LLM via SFT and DPO so the model can decide when to ask a specific clarification question, automating the agentic workflow to answer complex questions.
% (5) Extensive experiments ... 
% }

Answering complex, long-context questions remains a major challenge for large language models (LLMs) as it requires effective question clarifications and context retrieval. 
We propose \methodlong (\method), a framework designed to enhance an LLM’s understanding of such queries by integrating targeted self-clarification with contextual grounding within an agentic workflow.
At the core of \method is Chain-of-Clarifications (\coc), where models refine their understanding through self-generated clarification questions and corresponding contextual groundings. 
By scaling inference as a tree search where each node represents a \coc step, we achieve 97.8\% answer recall on NarrativeQA with a search depth of up to three and a branching factor of eight.
To amortize the high cost of this search process to training, we leverage the preference pairs for each step obtained by the \coc workflow and perform two-stage model finetuning: (1) supervised finetuning to learn effective decomposition strategies, and (2) direct preference optimization to enhance reasoning quality. This enables \method models to generate clarifications and retrieve relevant context effectively and efficiently in a single inference pass.
Extensive experiments across seven long-context tasks demonstrate that \method significantly outperforms state-of-the-art prompting methods and specialized long-context LLMs, achieving robust multi-hop reasoning while sustaining consistent performance as context length grows. \renewcommand\thefootnote{}\footnotetext{Code and data is available at: \url{https://github.com/EvanZhuang/AgenticLU}.}\renewcommand\thefootnote{\arabic{footnote}}


% One of the most challenging tasks for large language models (LLMs) is answering complex, long-context questions that require multiple rounds of clarification and retrieval. 
% We propose \methodlong (\method), a framework that learns to refine their understanding of complex, long-context questions by combining self-clarification and contextual grounding within an agentic workflow. 


% One of the most challenging tasks for large language models (LLMs) is answering complex, long-context questions that require effective question clarification and context retrieval. 
% We propose \methodlong (\method), a framework that refines an LLM’s understanding of complex, long-context queries by integrating targeted self-clarification with contextual grounding within an agentic workflow.
% Specifically, we apply LLM to long-context QA datasets (with ground-truth answers) to generate reasoning traces through tree search over candidate reasoning steps. By exploring multiple paths, the search process automatically discovers both effective and ineffective traces --- successful branches that reach correct answers serve as positive examples, while failed branches are collected as negative examples.
% The tree search is effective as we were able to solve 97.8\% of the problems with up to three rounds of self-clarification and contextual grounding.
% We then form preference pairs for each step in the agentic workflow and train the model in two stages: (1) supervised finetuning to learn decomposition strategies, and (2) direct preference optimization to refine reasoning quality. 
% This enables models to synthesize appropriate clarifications, locate relevant information, and generate accurate responses, even when context lengths stretch up to 128K tokens. 
% Extensive experiments across seven long-context tasks show that \method significantly outperforms state-of-the-art prompting methods and specialized long-context models, achieving robust multi-hop reasoning while maintaining consistent performance as context lengths grow. 


%We introduce \methodlong (\method), a framework for training large language models (LLMs) to refine their understanding of complex, long-context questions by combining self-clarification and contextual grounding.
%Our approach employs a tree search process \jingbo{one thing to clarify here is ``what is this tree?'' What are the branches? It somehow implies both positive and negative samples, but it remains mysterious to the reviewers.} that efficiently generates high-quality training data without requiring manual annotations\jingbo{we need to start with a dataset where we know the groundtruth answer. is my understanding correct? if so, no annotation only applies to the process?}, automatically discovering effective reasoning paths and context groundings, and creating preference pairs for each step of the agentic workflow.
%The framework uses a two-stage training recipe: first applying supervised fine-tuning (SFT) to learn decomposition strategies, followed by direct preference optimization (DPO) to refine reasoning quality.
%\jingbo{are we assuming the LLM is kind of good in the first place, so in the tree search it can find some possible paths? What will happen if we didn't find a path to the correct answer? We will discard that tree or only use the paths there as negative cases?}
%This enables models to systematically break down complex queries, precisely locate relevant information in extended contexts, and generate accurate responses.
%Extensive evaluations across seven long-context tasks (8K-128K tokens) demonstrate that \method significantly outperforms both state-of-the-art prompting methods and specialized long-context models, showing particular strength in multi-hop reasoning tasks while maintaining consistent performance across increasing context lengths.
% Our results show that explicit training for self-clarification and contextual grounding can substantially improve LLMs' long-context understanding capabilities.
\end{abstract}


\input{sec/s1_introduction}
\input{sec/s2_relatedwork} 
\input{sec/s2.5_nominal_context}
\input{sec/s3_methodology}
\input{sec/s3.5_training}
\input{sec/s4_eval}
\input{sec/s5_analysis}
\input{sec/s6_conclusion}

\input{sec/s7_limitations}

% Bibliography entries for the entire Anthology, followed by custom entries

\bibliography{anthology,custom}
% Custom bibliography entries only
%\bibliography{custom}


\appendix
\input{sec/appendix}

\end{document}
