\begin{figure}[t!]
    \begin{center}
    \includegraphics[width=0.8\columnwidth , keepaspectratio]{img/hotpotqa.pdf}
    \end{center}
    \caption{\textbf{Effective context size is smaller than nominal context size.} 
    Performance of Llama3.1-8B-Instruct (advertised 128K-token context) on the HotPotQA dataset 
    drops sharply as input length increases (8K, 16K, 32K, 64K, 128K), illustrating the 
    gap between nominal and effective context capacities.}
    \label{fig:hotpotQA}
\end{figure}
