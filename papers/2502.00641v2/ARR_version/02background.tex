\section{Background and Related Work}
\label{sec:background}
% \subsection{Text Data Summarization}
% % Text summarization is a basic task in NLP domains that aims to compress original articles into a few sentences while retaining essential information and meaning. Overall, text summarization can be divided into extractive summarization and abstractive summarization.


% Text data summarization significantly enhances the efficiency of data processing, storing, and retrieving by extracting and generating concise summaries. For example, it helps search engines better determine the relevance between queries and results~\cite{MarketBrew2024SEO}. Overall, text summarization can be divided into extractive summarization and abstractive summarization.

% % Over the past few years, various approaches have been developed to enhance the performance of news summarization~\cite{zhou-etal-2018-neural-document,dong-etal-2018-banditsum,zhang-etal-2018-neural,t5,pegasus,brio,lewis-etal-2020-bart}. 

% % \subsubsection{Extractive Summarization}
% Extractive summarization is selecting the most relevant sentences from the original text to form a summary. This can ensure the relevance and faithfulness of the summary but may result in a lack of coherence or some redundant information. Early methods often use statistical or graph-based approaches to measure sentence importance. Luhn~\cite{luhn1958automatic} proposed a method based on word frequency statistics to select the most important sentences from a text. And TextRank~\cite{mihalcea2004textrank} is a graph-based ranking algorithm that represents the text as a graph, where nodes represent basic units of the text (such as words or sentences), and edges represent relationships between these units. Through the structure of the graph and the strength of connections between nodes, the TextRank algorithm can evaluate the importance of each node. BanditSum~\cite{dong-etal-2018-banditsum} addressed sentence selection by framing it as a contextual bandit problem. With the development of word embeddings~\cite{mikolov2013word2vec}, many works have started using semantic information to select sentences. For instance, NEUSUM~\cite{zhou-etal-2018-neural-document} and LATENT~\cite{zhang-etal-2018-neural} all encode
% the sentences and documents. Recently, some efforts have also considered improving extractive summarization based on LLMs. LaMSUM~\cite{chhikara2024lamsum} is a multi-level framework or extractive summarization. Parmar et al.~\cite{parmar2024enhancingcoherenceextractivesummarization} improved the extractive summarization capabilities of LLMs through fine-tuning training.


% Abstractive summarization, on the other hand, generates new sentences that cover the key information of the source text. Although this method offers better readability than extractive summarization, it faces challenges in maintaining the relevance and faithfulness of the summary. Initially, abstractive summarization often relies on techniques such as concatenation~\cite{jing2000cut} and rule matching~\cite{genest-lapalme-2012-fully} to generate summaries. With the rise of the Transformer architecture and pre-trained models, some efforts have achieved promising results. Pointer Generator~\cite{see-etal-2017-get}, based on the encoder-decoder architecture, can flexibly copy words from the source text or generate new words, thereby enhancing the accuracy and readability of summaries. T5~\cite{t5} is a pre-trained model that unifies all text processing tasks into a text-to-text format. Through pre-training on large-scale data and multi-task learning, it improves the performance of abstractive summarization. Pegasus~\cite{pegasus} is a pre-trained model designed for text summarization. It achieves pre-training by simulating the deletion of sentences to generate summaries. Brio~\cite{brio} improves summary quality by incorporating evaluation models during training. Recent works~\cite{dead_summarization,zhang2024benchmarking} indicate that LLMs have surpassed traditional sequence-to-sequence neural networks in abstractive summarization and can even achieve human-level performance.


% algo work
% evaluation work
% system level
\subsection{Small Language Model}
% Although LLMs have surpassed traditional neural network models in many NLP tasks, their enormous parameter sizes and computational requirements make them nearly impractical for consumer-grade devices. Additionally, using commercial APIs raises issues related to cost and privacy protection. Therefore, Some studies such as TinyLalma~\cite{zhang2024tinyllama}, Phi2~\cite{microsoft2023phi2}, etc. aim to achieve LLM-like text generation capabilities using smaller models and less data, which we call small language models (SLM). There is no clear definition specifying the parameter count for SLMs. Generally, SLMs are considered capable of running on mobile devices. Therefore, in this paper, we primarily explore models smaller than 8GB in FP16 precision, equivalent to fewer than 4B parameters.


Small language models (SLMs) typically refer to models with fewer parameters and a smaller computational footprint compared to larger LLMs. These include general-purpose and specialized models that can typically be deployed for inference on edge devices, such as mobile phones and PCs. With the increasing focus on general-purpose SLMs, this paper centers on their evaluation, hereafter referred to simply as SLMs. Structurally, both SLMs and LLMs consist of stacked decoder layers from the transformer architecture~\cite{attention_all_you_need}, generating output autoregressively. However, SLMs have fewer decoder layers, attention heads, and smaller hidden dimensions, and they are trained on smaller, high-quality datasets. There is no clear definition specifying the parameter count for SLMs, but they are generally considered capable of running on consumer-grade devices. This paper focuses on models smaller than 8GB in FP16 precision, corresponding to fewer than 4B parameters.

% Like LLMs, SLMs also have instruction-following capabilities. Thus, when using SLMs for text summarization, we need to input the original text along with prompts related to the summary. The model then generates the briefly summary. Fig~\ref{fig:diff_prompt_example} shows some prompt templates. By modifying the prompts, we can obtain summaries in different styles, making SLMs more flexible than traditional text summarization models.


%可能需要增加内容
\subsection{Text Summarization Evaluation}
Currently, there are many works evaluating models for text summary generation, covering aspects such as relevance, coherence, and factual consistency~\cite{huang-etal-2020-achieved,fabbri2021summeval,dead_summarization,zhang2024benchmarking,liu2023benchmarking}. \citet{huang-etal-2020-achieved} used ROUGE and human evaluation to evaluate 10 representative summarization models, finding that extractive summarizers performed better in human evaluations. In the Summeval benchmark~\cite{fabbri2021summeval}, the authors analyzed existing metrics and used human evaluation methods to assess 23 models. \citet{dead_summarization} evaluated the text summarization performance of LLMs and found that they were more favored by evaluators. \citet{zhang2024benchmarking} used human evaluation to evaluate LLMs, discovering that instruction tuning had a greater impact on performance than model size. INSTRUSUM~\cite{liu2023benchmarking} evaluated instruction controllable summarization of LLMs and found them still unsatisfactory in summarizing text based on complex instructions.

Although SLMs have shown strong capabilities, comprehensive comparisons of their text summarization abilities are still lacking. Tiny Titans~\cite{tiny_titan} assessed the summarization performance of SLMs in meeting summarization, but it focused only on older models, excluding newer series like the Phi3 and Llama3. Moreover, its evaluation was limited to the ROUGE metric, which is not sufficiently comprehensive. While \citet{lu2024smalllanguagemodelssurvey} evaluated SLMs across various tasks, news summarization was notably absent. Therefore, this paper aims to provide a thorough evaluation of SLM performance in news summarization.




% 没有完整定义
% sml
%system level
% news summarization