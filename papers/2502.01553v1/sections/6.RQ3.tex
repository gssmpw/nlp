% \vspace{-2ex}
\section{Identifying Potential Members}
\label{sec:RQ3}



In this section, we propose a tool to assist VTubers in identifying potential members among their audience (\textbf{RQ3}).
While prior studies have focused on recommending \emph{streamers} to \emph{viewers}, our approach contrasts by recommending \emph{viewers} to \emph{streamers}. 
As the level of attention and engagement provided by the streamer plays an important role in motivating viewers to make monetary contributions such as gifts or subscriptions \cite{10.1145/3338286.3340144, lu2018watch}, we believe if a VTuber can pinpoint a specific group of potential members to focus on, it could increase the likelihood of converting them into real members. 
Leveraging the insights gained from \textbf{RQ1} and \textbf{RQ2}, we therefore design a tool, named \toolname.




% \vspace{-2ex}
\subsection{\toolname~Design}
% \vspace{-0.5ex}

To assist VTubers in focusing their member recruitment efforts, it would be useful to provide a ranking of the viewers watching the livestream, based on their likelihood of becoming a paid member.
Thus, we develop a model that assigns a score from 0 to 1 to each viewers in the livestream.
This estimates their probability of later becoming a member. 
Using these scores, \toolname~ then generates a ranking of the top $n$ viewers most likely to become a member. 


\pb{Features.}
Based on the insights from \textbf{RQ1} and \textbf{RQ2}, we select key features that exhibit significant disparities between members and non-members. To capture the temporal difference, we also incorporate the difference of the same feature across different time periods. 
For instance, consider a feature $F$, which we measure across two distinct time periods, yielding results $X_1$ and $X_2$. We then create a new feature, $F_{\Delta}$, defined as the difference $X_2 - X_1$.
A comprehensive summary of these features is detailed in Appendix \ref{subsec:appendix_features}.


\pb{Model Training.}
We experiment with five machine learning algorithms: Linear Regression (LiR), Logistic Regression (LoR), Random Forest (RF), Histogram-Based Gradient Boosting (HGB), and K-nearest Neighbors (KNN). 
To train the model, we utilize data in our member list and non-member list as described in Section \ref{subsec:construct_dataset}. 
To prevent class imbalance, we undersample the non-member list.
We employ 5-fold cross-validation and leverage grid search to tune the hyperparameters of each model. The hyperparameters used  for each model are detailed in Appendix \ref{subsec:appendix_parameters}.


% \vspace{-2ex}
\subsection{\toolname~Evaluation}
\label{subsec:rq3_eval}
% \vspace{-0.5ex}
\pb{Evaluation Metric.}
% 
To assess the effectiveness of \toolname's ranking, we apply a ranking performance metric, which is defined by the position in the ranking of users who actually purchase a membership in this session. 
% 
% 
Specifically, for every membership paid by a viewer, $M$, during a live streaming session, $S$, we take a list $L_{other}$ of non-member viewers in $S$. We then apply the trained model to estimate the probability, $P_M^S$, that viewer $M$ will pay for a membership in session, $S$. Additionally, we calculate the probability, $P_O^S$, for each non-member viewer $O$ in $L_{other}$ for the same session, $S$. After obtaining these probabilities, we rank $P_M^S$ along with all $P_O^S$ values and determine the rank position of $P_M^S$ within this list. 
The ranking performance metric is defined as this rank position for the viewer $M$.
% 
A higher position indicates a more accurate ranking prediction, as it means the users who actually purchase a membership are ranked higher. 
Intuitively, other viewers with a high ranking (who have not yet purchased the membership) can be identified as ``potential members'',  suggesting that VTubers should give more attention to them.


\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{figs/rq3_1_v2.pdf}
    \vspace{-2ex}
    \caption{The CDF of the rank and the percentile of the user who actually purchases a membership in the livestreaming  session among other viewers in this livestreaming session.}
    \vspace{-4ex}
    \label{fig:rq3_result}
\end{figure}

\pb{Results.}
We calculate the ranking performance metric and obtain results in both raw ranking position and percentile for each member (\ie top XX\% among viewers in the livestreaming session). 
The results for the five models are illustrated as CDFs in Figure \ref{fig:rq3_result}. An effective prediction would result in all future members attaining a high rank. We observe that both Random Forest and Histogram-Based Gradient Boosting exhibit similar performance, achieving the best outcomes, followed by K-nearest Neighbors, with linear regression and logistic regression trailing behind.

For the top-performing models (Random Forest and Histogram-Based Gradient Boosting), we find that 52\% of viewers who purchase a membership during the livestreaming session are ranked in first place, while 85\% fall within the top 50 positions. This indicates that, in the majority of cases, the model can accurately pinpoint viewers who are likely to subscribe within a small pool of users (top 50).
Thus, our tool can successfully assist VTubers in identifying a manageable group of, say, 50 viewers, out of thousands. This smaller group of viewers then makes it practical for the VTuber to pay additional attention on, which may help convert more ``potential'' members into actual members. Overall, the results indicate that the tool is effective and can be be utilized in practical scenarios if enough data is provided.


\pb{Feature Importance.}
To gain a deeper understanding of the important features utilized in the models, we briefly analyze feature importance using the permutation feature importance method \cite{breiman_permutation_2001}. We focus on the two top-performing models (Random Forest and Histogram-Based Gradient Boosting). The ten most important features are showed in Figure \ref{fig:rq3_importance} (Appendix), with the importance values scaled to a range of 0-1 using min-max scaling.

We observe that the most important features are linked to the ChatSim score (1st/2nd important for HGB and 2nd/4th important for RF) and the number of chats sent (3rd/4th important for HGB and 1st/3rd important for RF), along with other activity metrics with the specific VTuber. This is intuitive as chat activity serves as a direct measure of engagement, with the number of chats and ChatSim score indicating the quantity and quality of interactions, respectively. Additionally, the other activity metrics reflecting engagement with the VTuber also hold considerable importance in our models. We conjecture that many VTubers likely learn such patterns themselves, building an intuition for which viewers are most likely to subscribe. Our tool automates and simplifies this process, dramatically reducing the number of candidate viewers a VTuber needs to review.

