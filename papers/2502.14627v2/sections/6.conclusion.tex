\section{Conlusion}
In this paper, we address the inconsistencies in ranking results observed in existing ML-ATR schemes. Through an analysis of modality alignment errors and weighting errors, we identify data distribution errors during training as a key factor impacting cross-lingual modality alignment, ultimately leading to retrieval inconsistencies. To address this, we propose two training strategies: KCL and CACL, designed for scenarios prioritizing retrieval performance and training overhead, respectively. Experimental results demonstrate that both CACL and KCL effectively enhance retrieval performance and consistency in ML-ATR tasks. Notably, KCL achieves state-of-the-art results in both English-oriented monolingual ATR and ML-ATR tasks. Furthermore, the proposed approach of mitigating data distribution errors to reduce inconsistencies holds potential for broader applications, including multilingual modality alignment in image and video modalities.

\section*{Limitation}
We acknowledge that the upper bound on the weighting error in Eq. \eqref{Eq:weight error} is heuristically proven for the SGD optimizer. For more complex optimizers such as Adam, giving a direct upper bound on the weighting error is difficult. But we provide proof of momentum error upper bound for Adam in the Appendix \ref{Appe:Migrating}, and show that our idea of reducing the data distribution error is still feasible under the Adam optimizer by showing that momentum error leads to weight error.