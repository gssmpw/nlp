@article{LongMEM,
  title={Augmenting Language Models with Long-Term Memory},
  author={Wang, Weizhi and Dong, Li and Cheng, Hao and Liu, Xiaodong and Yan, Xifeng and Gao, Jianfeng and Wei, Furu},
  journal={arXiv preprint arXiv:2306.07174},
  year={2023}
}

@misc{Memoria,
      title={Memoria: Resolving Fateful Forgetting Problem through Human-Inspired Memory Architecture}, 
      author={Sangjun Park and JinYeong Bak},
      year={2024},
      eprint={2310.03052},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{MemoringTransformers,
  author       = {Yuhuai Wu and
                  Markus Norman Rabe and
                  DeLesley Hutchins and
                  Christian Szegedy},
  title        = {Memorizing Transformers},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
  url          = {https://openreview.net/forum?id=TrjbxzRcnf-},
  timestamp    = {Sat, 20 Aug 2022 01:15:42 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/WuRHS22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{MemoryBank,
  title={MemoryBank: Enhancing Large Language Models with Long-Term Memory},
  author={Zhong, Wanjun and Guo, Lianghong and Gao, Qiqi and Wang, Yanlin},
  journal={arXiv preprint arXiv:2305.10250},
  year={2023}
}

@inproceedings{al2021memory,
  title={Memory transformer with hierarchical attention for long document processing},
  author={Al Adel, Arij and Burtsev, Mikhail S},
  booktitle={2021 International Conference Engineering and Telecommunication (En\&T)},
  pages={1--7},
  year={2021},
  organization={IEEE}
}

@inproceedings{chen-etal-2024-minprompt,
    title = "{M}in{P}rompt: Graph-based Minimal Prompt Data Augmentation for Few-shot Question Answering",
    author = "Chen, Xiusi  and
      Jiang, Jyun-Yu  and
      Chang, Wei-Cheng  and
      Hsieh, Cho-Jui  and
      Yu, Hsiang-Fu  and
      Wang, Wei",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.16/",
    doi = "10.18653/v1/2024.acl-long.16",
    pages = "254--266"
}

@inproceedings{em2,
  author       = {Zhangyue Yin and
                  Qiushi Sun and
                  Qipeng Guo and
                  Zhiyuan Zeng and
                  Qinyuan Cheng and
                  Xipeng Qiu and
                  Xuanjing Huang},
  title        = {Explicit Memory Learning with Expectation Maximization},
  booktitle    = {{EMNLP}},
  pages        = {16618--16635},
  publisher    = {Association for Computational Linguistics},
  year         = {2024}
}

@article{enhanced_text_compression,
  author       = {Chowdhury Mofizur Rahman and
                  Mahbub E. Sobhani and
                  Anika Tasnim Rodela and
                  Swakkhar Shatabda},
  title        = {An Enhanced Text Compression Approach Using Transformer-based Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2412.15250},
  year         = {2024}
}

@article{gutierrez2024hipporag,
  title={HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models},
  author={Guti{\'e}rrez, Bernal Jim{\'e}nez and Shu, Yiheng and Gu, Yu and Yasunaga, Michihiro and Su, Yu},
  journal={arXiv preprint arXiv:2405.14831},
  year={2024}
}

@article{he2024camelot,
  title={CAMELoT: Towards Large Language Models with Training-Free Consolidated Associative Memory},
  author={He, Zexue and Karlinsky, Leonid and Kim, Donghyun and McAuley, Julian and Krotov, Dmitry and Feris, Rogerio},
  journal={arXiv preprint arXiv:2402.13449},
  year={2024}
}

@article{hu2023chatdb,
  title={Chatdb: Augmenting llms with databases as their symbolic memory},
  author={Hu, Chenxu and Fu, Jie and Du, Chenzhuang and Luo, Simian and Zhao, Junbo and Zhao, Hang},
  journal={arXiv preprint arXiv:2306.03901},
  year={2023}
}

@article{kNNLM,
  title={Generalization through memorization: Nearest neighbor language models},
  author={Khandelwal, Urvashi and Levy, Omer and Jurafsky, Dan and Zettlemoyer, Luke and Lewis, Mike},
  journal={arXiv preprint arXiv:1911.00172},
  year={2019}
}

@inproceedings{larimar,
  author       = {Payel Das and
                  Subhajit Chaudhury and
                  Elliot Nelson and
                  Igor Melnyk and
                  Sarathkrishna Swaminathan and
                  Sihui Dai and
                  Aur{\'{e}}lie C. Lozano and
                  Georgios Kollias and
                  Vijil Chenthamarakshan and
                  Jir{\'{\i}} Navr{\'{a}}til and
                  Soham Dan and
                  Pin{-}Yu Chen},
  title        = {Larimar: Large Language Models with Episodic Memory Control},
  booktitle    = {{ICML}},
  publisher    = {OpenReview.net},
  year         = {2024}
}

@article{memgpt,
  author       = {Charles Packer and
                  Vivian Fang and
                  Shishir G. Patil and
                  Kevin Lin and
                  Sarah Wooders and
                  Joseph E. Gonzalez},
  title        = {MemGPT: Towards LLMs as Operating Systems},
  journal      = {CoRR},
  volume       = {abs/2310.08560},
  year         = {2023}
}

@article{memllm,
  title={Memllm: Finetuning llms to use an explicit read-write memory},
  author={Modarressi, Ali and K{\"o}ksal, Abdullatif and Imani, Ayyoob and Fayyaz, Mohsen and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2404.11672},
  year={2024}
}

@article{memory3,
  author       = {Hongkang Yang and
                  Zehao Lin and
                  Wenjin Wang and
                  Hao Wu and
                  Zhiyu Li and
                  Bo Tang and
                  Wenqiang Wei and
                  Jinbo Wang and
                  Zeyun Tang and
                  Shichao Song and
                  Chenyang Xi and
                  Yu Yu and
                  Kai Chen and
                  Feiyu Xiong and
                  Linpeng Tang and
                  Weinan E},
  title        = {Memory\({}^{\mbox{3}}\): Language Modeling with Explicit Memory},
  journal      = {CoRR},
  volume       = {abs/2407.01178},
  year         = {2024}
}

@inproceedings{memoryllm,
  author       = {Yu Wang and
                  Yifan Gao and
                  Xiusi Chen and
                  Haoming Jiang and
                  Shiyang Li and
                  Jingfeng Yang and
                  Qingyu Yin and
                  Zheng Li and
                  Xian Li and
                  Bing Yin and
                  Jingbo Shang and
                  Julian J. McAuley},
  title        = {{MEMORYLLM:} Towards Self-Updatable Large Language Models},
  booktitle    = {{ICML}},
  publisher    = {OpenReview.net},
  year         = {2024}
}

@techreport{nncp_v2,
  title={NNCP v2: Lossless data compression with transformer},
  author={Bellard, Fabrice},
  year={2021},
  institution={Technical report, Amarisoft}
}

@article{self-param,
  title={Self-Updatable Large Language Models with Parameter Integration},
  author={Wang, Yu and Liu, Xinshuang and Chen, Xiusi and O'Brien, Sean and Wu, Junda and McAuley, Julian},
  journal={arXiv preprint arXiv:2410.00487},
  year={2024}
}

@article{tiny_transformers_for_text_compression,
  title={Tiny Transformers Excel at Sentence Compression},
  author={Belcak, Peter and Wattenhofer, Roger},
  journal={arXiv preprint arXiv:2410.23510},
  year={2024}
}

@article{wang2024large,
  title={Large Scale Knowledge Washing},
  author={Wang, Yu and Wu, Ruihan and He, Zexue and Chen, Xiusi and McAuley, Julian},
  journal={arXiv preprint arXiv:2405.16720},
  year={2024}
}

@article{wu2022survey,
  title={A survey of human-in-the-loop for machine learning},
  author={Wu, Xingjiao and Xiao, Luwei and Sun, Yixuan and Zhang, Junhang and Ma, Tianlong and He, Liang},
  journal={Future Generation Computer Systems},
  volume={135},
  pages={364--381},
  year={2022},
  publisher={Elsevier}
}

@article{zhou2023recurrentgpt,
  title={RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text},
  author={Zhou, Wangchunshu and Jiang, Yuchen Eleanor and Cui, Peng and Wang, Tiannan and Xiao, Zhenxin and Hou, Yifan and Cotterell, Ryan and Sachan, Mrinmaya},
  journal={arXiv preprint arXiv:2305.13304},
  year={2023}
}

