%!TEX root = ../main.tex

\section{Introduction}
\label{sec:introduction}

Robots must intelligently establish and disengage \emph{contacts} to successfully perform complex tasks in the physical world, such as manipulation of daily objects and locomotion in rough terrains.
% In the realm of robotics, contact interactions between a robot and its environment play a crucial role in a wide array of applications. 
% From grasping and manipulation to locomotion and navigation in complex terrains, the ability to accurately model and control these contact interactions is fundamental to achieving robust and versatile robotic systems. 
However, the hybrid nature of combining continuous dynamics with discrete contact events, the discontinuities in force profiles, and the potential for stick-slip transitions, make it notoriously difficult to ``plan through contact''.

\textbf{Contact-implicit motion planning.} Among the many efforts for motion planning through contact (see \S\ref{sec:relatedworks} for a review), the so-called \emph{contact-implicit} formulation stood out as a particularly popular and promising approach~\cite{posa2014ijrr-traopt-directmethod-contact,kerim2006TO}. This formulation distinguishes itself by integrating contact dynamics into the motion planning framework through the introduction of \emph{complementarity constraints}, which allow simultaneous optimization of the state-control trajectories and the contact forces without explicit (and discrete) mode switching (\cf~\eqref{eq:contact-implicit}). 
% representation of contact forces and states as continuous variables and the introduction of complementarity constraints. It allows for simultaneous optimization of trajectories, control inputs, and contact forces, enabling exploration of a wider range of motion possibilities, capturing complex contact behaviors without explicit mode switching. 
However, the contact-implicit formulation circumvents explicit mode switching at the price of arriving at an optimization problem known as \emph{Mathematical Programming with Complementarity Constraints} (MPCC). Although they ``look like'' smooth and continuous optimization problems, MPCC problems are known to fail the classical constraint qualifications (CQs) at \emph{all feasible points} (e.g., Linear Independence Constraint Qualification and Mangasarian-Fromovitz Constraint Qualification)~\cite{MOR-scheel2000mathematical,SIOPT-Scholtes-2001,SIOPT-Ye-MPCC-2016}. 
% \hy{Cite SIOPT papers}
% problem from contact-implicit formulation introduces significant challenges. 
% It leads to non-convexity in the optimization problem and causes the failure of classical constraint qualifications such as the Linear Independence Constraint Qualification (LICQ) and the Mangasarian-Fromovitz Constraint Qualification (MFCQ) at all feasible points. 
To make this concrete, we provide the geometric intuition through a simple MPCC problem.
% From a geometric perspective, this results in a mismatch between the tangent cone (TC) and the linearized feasible cone (LFC) at local optima, rendering local first-order information inadequate in capturing the true feasible region. We now examine a simple case that demonstrates how even the simplest complementarity constraints lead to a discrepancy between TC and LFC. 
\begin{example}[Geometric Intuition of MPCC]\label{example:toy}
Consider the following two-dimensional MPCC problem:
\begin{subequations}\label{eq:toy}
    \begin{align}
\min_{(x_1,x_2) \in \mathbb{R}^2} &\; f(x) := x_1^2 + x_2^2 \\
\subject &\; g_1(x) := x_1 \geq 0, \\
&\; g_2(x) := x_2 \geq 0, \\
&\; g_3(x) := x_1 \cdot x_2 = 0. \label{eq:toy:cc}
\end{align}
\end{subequations}
where~\eqref{eq:toy:cc} is a complementarity constraint.
As depicted in~\prettyref{fig:toy_example},
the objective level sets are circles in $\mathbb{R}^2$, and
the feasible set consists of the union of the two coordinate axes in the first quadrant
\bea
\{x\in\Real{2} \mid x_1 \geq 0, x_2 =0\} \cup \{x \in \Real{2} \mid x_1 = 0, x_2 \geq 0\}.
\eea
The optimal solution of problem~\prettyref{eq:toy} lies at the origin $(0,0)$.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\linewidth, trim={0cm 12cm 25cm 0cm}, clip]{figures/toy_example.pdf}
    \vspace{-6mm}
    \caption{
    Geometric intuition of MPCC through Example~\prettyref{example:toy}.}
    \label{fig:toy_example}
    \vspace{-4mm}
\end{figure}
%  left, bottom, right and top.

To understand the local geometry at the origin, we need to characterize two types of ``cones'' around the origin.

(a) The \emph{tangent cone (TC)} at a point is defined as the set of tangent vectors of all curves approaching the point from the feasible region~\cite{nocedal1999springer-numerical-optimization}. 
Thus, the tangent cone at \((0, 0)\) is:
\bea
\begin{split}
    TC=\{d \in \mathbb{R}^2 \mid d_1 \geq 0, d_2 = 0\} \ \cup\  \\ \{d \in \Real{2} \mid d_1 = 0, d_2 \geq 0\}.
\end{split}
\eea
This consists of two directions: one along the positive \(x_1\)-axis and one along the positive \(x_2\)-axis, see Fig.~\ref{fig:toy_example}.

(b) The \emph{linearized feasible cone (LFC)} is formed by all active constraints at that point~\cite{nocedal1999springer-numerical-optimization}:
\bea
LFC = \left\{d \in \mathbb{R}^2 \;\bigg|\; 
\begin{array}{l}
\nabla g_i^\top d \geq 0,i=1,2 \\
\nabla g_j^\top d = 0 : j=3
\end{array}
\right\}.
\eea
Thus, the linearized feasible cone at \((0, 0)\) is:
\bea
LFC = \{d \in \Real{2} \mid d_1 \geq 0, d_2 \geq 0\},
\eea
i.e., the entire first quadrant. Therefore, we conclude that $TC \subsetneq LFC$---the TC is a strict subset of the LFC at $(0,0)$.
% \usepackage{}Therefore, we conclude that , and this generalizes to all MPCC problems.
% \hy{Before you said MPCC fails CQ at all feasible points, is it true in this example?} \yl{yes, that's a common feature for MPCC}

We remark that the TC is ``geometric'', while the LFC is ``algebraic''. While the definition of LFC involves the algebraic constraints and their linearizations, the definition of TC characterizes the local geometry regardless of how the feasible set is algebraically parameterized. 
\end{example}

After noticing the gap between the TC and the LFC, the reader might wonder why this is a problem. The reason lies in that, the equivalence of TC and LFC---typically ensured by CQs---is a prerequisite to establish the Karush–Kuhn–Tucker (KKT) conditions for local optimality \cite{nocedal1999springer-numerical-optimization}. Moreover, almost all primal-dual nonlinear programming (NLP) solvers (e.g., \snopt~\cite{SNOPT}, \ipopt~\cite{ipopt}) rely on the KKT optimality conditions---they search for a pair of primal and dual variables satisfying the KKT conditions. Therefore, the absence of CQs and the gap between TC and LFC breaks the theoretical foundations for primal-dual algorithms. The numerical consequence of this, as we will show in \S\ref{sec:exp}, is that primal-dual solvers can exhibit poor convergence, stuck in infeasible solutions, and/or numerical instabilities when solving contact-implicit MPCC problems. 

% \yl{I talk about some mitigations and their limitation to my understanding here to shift the discussion to the question you throw.} 

\textbf{Relaxation?} An extensively studied strategy to mitigate the failure of CQs is to ``relax'' the complementarity constraint. In~\cite{MP-FACCHINEI-1999}, using Example~\ref{example:toy} as illustration, the authors relaxed the complementarity constraint~\eqref{eq:toy:cc} as $x_1\cdot x_2 = \alpha$ for $\alpha >0$. In~\cite{SIOPT-Scholtes-2001,MOR-STEFAN-2001}, a different relaxation scheme where $x_1 \cdot x_2 \leq \alpha$ for $\alpha > 0$ is proposed. In both relaxations, CQs are restored (i.e., no gap between the TC and the LFC) and KKT optimality conditions are reassured. However, since $\alpha=0$ is the original non-relaxed problem we want to solve, a homotopy scheme is needed to start with $\alpha$ very large and gradually push $\alpha$ to zero. There are two issues with the relaxation approach. First, one needs to solve a sequence of nonconvex problems instead of just one, making this approach computationally expensive. Second, while the problem with $\alpha$ very large is generally well conditioned, as $\alpha \downarrow 0$, numerical issues appear again. For these reasons, to the best of our knowledge, there does not exist a well-accepted implementation of the relaxation approach. Recently in robotics, \cite{le2024fast} targeted at linear complementarity constraints---which are indeed KKT optimality conditions of a lower-level convex quadratic program (QP)---and designed a bilevel optimization algorithm where the lower-level QP is solved in a differentiable way to provide gradient for the upper-level trajectory optimization problem. Crucially, to ensure the QP is differentiable with respect to contact, relaxation (or smoothing) is applied again, but this time to the interior point algorithm used for solving the QP. However, (a) it is unclear whether the approach extends to nonlinear complementarity constraints studied in our paper; and (b) the implementation provided by~\cite{le2024fast} does not follow a generic nonlinear programming interface. Therefore, we did not benchmark against~\cite{le2024fast} in \S\ref{sec:exp}. 

% Efforts have been made in the theoretical understanding of MPCC problem. One approach involves regularizing the complementarity constraints, studying the relaxed problem under new assumptions and derived constraint qualifications (e.g., MPCC-LICQ~\cite{}) to establish convergence guarantees. Another strategy employs smooth function approximations of the nonsmooth complementarity constraints, solving a series of subproblems with increasingly accurate approximations to converge towards the original problem's solution.
% Despite these efforts, the fundamental challenges of complementarity-constrained problems persist. While regularization and relaxation approaches have advanced our understanding, they often require solving a series of NLP problems that ultimately approximate the original problem. Thus, the core difficulties inherent in the original formulation remain. In practice, especially for contact problems, these methods frequently yield mixed results. The reliance on carefully crafted initial guesses to achieve convergence significantly limits their applicability across diverse real-world scenarios.

% \hy{Mention the elastic mode of SNOPT and its limitations --- eventually the issue is the requirement to provide intricate initializations}

% For readers who are not familiar with the concepts of 

% The geometric condition arising from constraint qualifications is crucial for deriving and ensuring the validity of first-order Karush-Kuhn-Tucker (KKT) conditions, which are cornerstones in Nonlinear Programming (NLP) theory. These conditions serve as the foundation for optimality analysis, algorithm design, and convergence proofs for a wide range of optimization methods. Thus, the absence of this condition in contact-implicit problems makes algorithms that focus on solving the KKT system fundamentally problematic, manifesting numerically as unbounded dual variables and KKT systems with either infinitely many solutions or no solution at all, which leads to problem degeneracy.

% In practice,  Consequently, it is often necessary to provide carefully crafted initial guesses to obtain reasonable solutions. This requirement significantly limits the potential of contact-implicit formulation to optimize flexible and informed contact sequences, undermining its capacity to fully explore diverse motion patterns and adapt to complex, unpredictable environments. 

\emph{Can we solve contact-implicit motion planning in a numerically robust way, without relaxation?}
\begin{figure*}[tp]
    \centering
    \includegraphics[width=1\linewidth, trim={0cm 0cm 0cm 0cm}, clip]{figures/toy_example_merit.png}
    \vspace{-4mm}
    \caption{
    Depiction of the $\ell_1$ penalty merit function for Example~\prettyref{example:toy} with different penalty parameters $\mu$.}
    \label{fig:toy_example_merit_function}
    \vspace{-4mm}
\end{figure*}

\textbf{Contributions.}
The answer is rather discouraging if considering a generic nonconvex MPCC problem, as highlighted by the mathematical optimization literature~\cite{fletcher2000practical, SIOPT-FLETCHER-2006, OMS-Fletcher-2004}. Nevertheless, contact-implicit planning problems in robotics possess a unique property: the objective function is often \emph{convex} (and quadratic), as the goal typically involves tracking a trajectory or reaching a target. Formally, we consider the problem:
% In this work, we aim to study and solve a class of robot motion planning problems characterized by nonlinear complementarity constraints arising from contact interactions between the robot and its environment, nonlinear system dynamics, general equality, and inequality constraints. We formally state the problem as:
\begin{subequations}\label{eq:contact-implicit}
    \begin{align}
    \min_{v, \lambda} \quad & J(v, \lambda), \\
    \subject \quad & f(v, \lambda) = 0, \label{eq:ci:dynamics}\\
    & c_i(v, \lambda) \geq 0, \ i \in \calI  \label{eq:ci:ineq}\\
    & c_i(v, \lambda) = 0, \ i \in \calE \label{eq:ci:eq} \\
    & 0 \leq \phi(x,\lambda) \perp \lambda \geq 0,\label{eq:ci:complementarity}
\end{align}
\end{subequations}
where $v$ includes the trajectory of both robot state and control inputs, $\lambda$ denotes the complementarity variables typically associated with contact forces. We assume the objective function $J(v, \lambda)$ is convex---usually a quadratic loss function of tracking errors and control efforts. Constraint \eqref{eq:ci:dynamics} represents the nonlinear system dynamics. Constraints \eqref{eq:ci:ineq} and \eqref{eq:ci:eq} are general inequality and equality constraints. The complementarity constraint \eqref{eq:ci:complementarity} enforces the relationship between $\lambda$ and the nonlinear function $\phi(v,\lambda)$. The expression ``$\phi(x,\lambda) \perp \lambda$'' should be interpreted as $\phi_i(x,\lambda) \cdot \lambda_i = 0$, or its equivalent form $\phi_i(x,\lambda) \cdot \lambda_i \leq 0$ as suggested by~\cite{SIOPT-FLETCHER-2006}, for every entry of $\phi(\cdot)$ and $\lambda$. It should be emphasized that problem~\eqref{eq:contact-implicit} is nonconvex because we do not place any restrictions on the convexity of the constraints. We will give concrete examples of~\eqref{eq:contact-implicit} in \S\ref{sec:exp}. For now, let us work with the generic template~\eqref{eq:contact-implicit}.

Our major contribution is to depart from the usual primal-dual algorithmic framework---due to the failure of CQs in MPCC---and propose a \emph{primal-only} algorithm named \crisp (\textbf{\underline{R}}obust \textbf{\underline{C}}ontact-\textbf{\underline{I}}mplicit motion planning with \textbf{\underline{S}}equential convex \textbf{\underline{P}}rogramming). \crisp features a merit function with weighted $\ell_1$ penalty to measure primal feasibility and objective reduction. It solves a series of trust-region convex quadratic programs (QPs) formulated using local second-order information of the objective and \emph{first-order} information of the constraints. In stark contrast with the well-known sequential quadratic programming (SQP) framework, \crisp (a) does not require second-order information of the constraints, and (b) does not maintain and update dual variables. Since the objective function is convex, the inner-loop QP subproblem inherits convexity by construction. This makes \crisp both simple to implement and computationally efficient. 

One then wonders whether a simple algorithm like \crisp can offer any convergence guarantees. We show that, somewhat surprisingly, the convexity of the objective function allows us to prove sufficient conditions under which \crisp can guarantee convergence to the stationary points of the merit function. Importantly, the sufficient conditions are numerically checkable, and hence the convergence can be ``certified'' from the numerical iterations of \crisp.

Finally, we open-source a high-performance C++ implementation of \crisp. Our C++ implementation follows a generic nonlinear programming interface where the user defines objective function and constraints. We leverage automatic differentiation to obtain gradient and Hessian information. We then apply \crisp to solve five contact-implicit motion planning problems and benchmark its performance against both generic and robotics-specific solvers. We believe the way we model some of the contact-implicit planning problems is also new. Our numerical results demonstrate that \crisp consistently generates non-trivial and entirely new contact sequences from naive and even all-zero initializations, while existing solvers can struggle to find even feasible solutions. 

To summarize, our contributions are:
\begin{itemize}
    \item \textbf{Theory and Algorithm}. We propose a primal-only algorithm for contact-implicit motion planning called \crisp and provide theoretical guarantees.
    \item \textbf{Implementation}. We release an open-source high-performance C++ implementation of \crisp.
    \item \textbf{Benchmark}. We model five contact-rich planning problems using the contact-implicit formulation and benchmark \crisp against existing solvers.
\end{itemize}

% provide theoretical guarantees for \scenario{CRISP}, proving its convergence to a stationary point of the merit function, with two computationally checkable convergence conditions that offer practical insights for algorithm design. 

% The main contributions of this paper are as follows:
% (i) We propose a novel algorithm, , to effectively and efficiently solve the nonlinear optimization problem in \eqref{eq:problem_formulation}. Motivated by the ineffectiveness of primal-dual optimality conditions in the original problem,  A trust region update scheme and second-order correction are incorporated to ensure global convergence, while a weighted penalty update is employed in the outer loop. 
% Notably, our approach does not require the calculation of constraint Hessians or the use of quasi-Newton methods to maintain approximate Hessians, making it computationally efficient for large-scale and complex robotic systems. 
% (iii) We formulate  Using a series of naive initial guesses, we comprehensively evaluate \scenario{CRISP} against other benchmark solvers on these tasks. 
% (iv) We  and open-source this code along with the mathematical formulations and initial guesses for all tasks presented in this paper. This solver allows users to conveniently define and solve their nonlinear optimization problems in the most general form.

\textbf{Paper organization.} We present the theory and algorithm for \crisp in \S\ref{sec:method}, its implementation details in \S\ref{sec:implementation}, and benchmark results in \S\ref{sec:exp}. We postpone the related work review to \S\ref{sec:relatedworks} and conclude in \S\ref{sec:conclusion}. Appendix and project website provide proofs and the detailed contact-implicit formulation for the five planning problems, as well as the animations of numerically computed motion trajectories. 
