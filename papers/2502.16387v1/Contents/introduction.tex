\section{Introduction}\label{sec:intro}
We consider online \textit{calibration} 
--- a problem of making sequential probabilistic predictions over binary outcomes. Formally, at each time $t = 1, \dots, T$, a forecaster randomly predicts $p_{t} \in [0, 1]$ while simultaneously the adversary chooses $y_{t} \in \{0, 1\}$, and subsequently the forecaster observes the true label $y_{t}$. Letting $n_{p}$ denote the number of rounds the forecaster predicts $p_{t} = p$, the forecaster's predictions are perfectly calibrated if for all $p \in [0, 1]$, the empirical distribution of the label conditioned on the forecast being $p$, i.e., the quantity $\rho_{p} \coloneqq \sum_{t: p_{t} = p} y_{t} / n_{p}$, matches $p$. The $\ell_{q}$-Calibration error ($q \ge 1$) is then defined as \begin{equation}\label{eq:ell_2_cal}
    \cal_{q} \coloneqq \sum_{p \in [0, 1]} \sum_{t = 1} ^ {T} \ind{p_{t} = p} \bigc{p - \rho_p} ^ q. 
\end{equation}

A related concept used in~\citet{fishelsonfull} that we call \textit{pseudo calibration error} measures the error using the forecaster's conditional distribution $\cP_{t} \in \Delta_{[0, 1]}$ at time $t$, instead of the actual prediction $p_t$. More specifically, the pseudo $\ell_{q}$-Calibration error is defined as \begin{align}\label{eq:pseudo_ell_2_cal}
    \pcal_{q} \coloneqq \sum_{t = 1} ^ {T} \mathbb{E}_{p\sim\cP_{t}}[ \bigc{p -  \tilde{\rho}_{p} } ^ {q}],
\end{align} 
where $\tilde{\rho}_{p} \coloneqq \frac{\sum_{t = 1} ^ {T} y_{t} \cP_{t}(p)}{\sum_{t = 1} ^ {T} \cP_{t}(p)}$.
By not dealing with the random variable $p_t$, pseudo calibration is often easier to optimize.

Two of the most popular calibration measures are $\ell_{1}$ and $\ell_{2}$-Calibration. 
It has been long known that $\cal_1 = \cO(T^{2/3})$ is achievable, and there are some recent breakthroughs towards 
closing the gap between this upper bound and a standard lower bound $\cal_1 = \Omega(\sqrt{T})$ (see more discussion in related work).
On the other hand, for $\ell_{2}$-Calibration, a smaller error of $\tilde{\cO}(\sqrt{T})$ can be achieved (see e.g. the expository note by \citet{roth2022uncertain}). 
Somewhat surprisingly, a very recent work by \cite{fishelsonfull} showed that the bound can be further improved to $\pcal_{2} = \tilde{\cO}(T^{\frac{1}{3}})$ by establishing equivalence to pseudo swap regret of the squared loss and proposing an algorithm based on the well-known Blum-Mansour reduction \citep{blum2007external} for minimizing pseudo swap regret.

More specifically, given a loss function $\ell: [0,1]\times\{0,1\} \rightarrow \Rn$, 
the swap regret of the forecaster is defined as 
$\sreg^{\ell} \coloneqq \sup_{\sigma: [0, 1] \to [0, 1]} \sreg^{\ell}_{\sigma}$,
where $\sreg^{\ell}_\sigma \coloneqq \sum_{t = 1} ^ {T} \ell(p_{t}, y_{t}) - \ell(\sigma(p_{t}), y_{t})$
measures the difference between the forecaster's total loss and the loss of a strategy that always swaps the forecaster's prediction via a swap function $\sigma$.
Similarly, pseudo swap regret (\citealp{fishelsonfull}; referred in their work as full swap regret) is defined using the conditional distribution of predictions $\cP_{t}$ instead of $p_t$ itself: $\psreg^{\ell} \coloneqq \sup_{\sigma: [0, 1] \to [0, 1]} \psreg^{\ell}_{\sigma}$, where $\psreg_{\sigma}^{\ell} \coloneqq \sum_{t = 1} ^ {T} \mathbb{E}_{p \sim \cP_{t}}[\ell(p, y_{t}) - \ell(\sigma(p), y_{t})]$.
\citet{fishelsonfull} show that it is possible to achieve $\psreg^{\ell} = \tilde{\cO}(T^{\frac{1}{3}})$ when $\ell$ is the squared loss, which, as we will show, further implies that the same bound holds for any bounded proper loss $\ell$ with a smooth univariate form (refer to  Section \ref{sec:preliminaries} for concrete definitions of proper losses and their univariate form). 

In this work, we significantly generalize their results by not only recovering their results for pseudo swap regret, but also proving the same $\tilde{\cO}(T^{\frac{1}{3}})$ bound for new losses such as log loss and those induced by the Tsallis entropy.
Moreover, we prove the same bound (either in expectation or with high probability) for the actual swap regret, which was missing in \cite{fishelsonfull}.
To achieve these goals, we introduce a natural notion of $\textit{(pseudo) KL-Calibration}$, where the penalty incurred by the forecaster's prediction $p$ deviating from the empirical distribution of $y$ (conditioned on the forecast being $p$) is measured in terms of the KL-divergence. Specifically, the KL-Calibration and the pseudo KL-Calibration incurred by the forecaster are respectively defined as \begin{align}\label{eq:KLCal_PKLCal_def}
    \kcal \coloneqq \sum_{p \in [0, 1]} \sum_{t = 1} ^ {T} \ind{p_{t} = p} \KL(\rho_{p}, p), \quad \pkcal \coloneqq \sum_{t = 1} ^ {T} \mathbb{E}_{p \sim \cP_{t}}[\KL(\tilde{\rho}_{p}, p)],
\end{align}
where $\KL(q, p) = q\log\frac{q}{p}+(1-q)\log\frac{1-q}{1-p}$ is the KL-divergence for two Bernoulli distributions with mean $q$ and $p$ respectively.  
It follows from Pinsker's inequality that $\KL(\rho_{p}, p) \ge 
(\rho_{p} - p) ^ {2}$, therefore, $\kcal \ge \cal_{2}$ and $\pkcal \ge \pcal_{2}$, making (pseudo) KL-Calibration a stronger measure for studying upper bounds than than (pseudo) $\ell_2$-Calibration. 

\subsection{Contributions and Technical Overview}
Let $\cL$ denote the class of bounded (in $[-1, 1]$) proper losses. 
\begin{itemize}[leftmargin=*]
\item In Section~\ref{sec:implications}, we start by discussing the implications of (pseudo) KL-Calibration towards minimizing (pseudo) swap regret. In particular, in subsection \ref{subsec:KL-bounds-L-2}, we show for each $\ell \in \cL_{2}$, where $\cL_{2}$ is the class of bounded proper losses whose univariate form $\ell(p) \coloneqq \mathbb{E}_{y \sim p}[\ell(p, y)]$ 
is twice continuously differentiable in $(0, 1)$, we have $\sreg^{\ell} = \cO(\kcal), \psreg^{\ell} = \cO(\pkcal)$. In subsection \ref{subsec:KL-bounds-L-G2}, we show that for each $\ell \in \cL_{G}$, where $\cL_{G}$ is the class of bounded proper losses with a $G$-smooth univariate form,
(pseudo) KL-Calibration implies that $\sreg^{\ell} \le G \cdot \cal_{2} \le G \cdot \kcal, \psreg^{\ell} \le G \cdot \pcal_{2} \le G \cdot \pkcal$. 
This gives us strong incentives to study $\pkcal$ and $\kcal$.

\item In Section \ref{sec:achieve-KL-Cal}, we prove that there exists an algorithm that achieves $\mathbb{E}[\kcal] = \cO(T^{\frac{1}{3}} (\log T) ^ {\frac{5}{3}})$. To achieve so, we first realize that (pseudo) KL-Calibration is equivalent to the (pseudo) swap regret of the log loss $\ell(p, y) = -y \log p - (1 - y) \log (1 - p)$, i.e., $\kcal = \sreg^{\ell}, \pkcal = \psreg^{\ell}$. Subsequently, we propose a non-constructive proof for minimizing $\sreg^{\ell}$; our proof is based on swapping the forecaster and the adversary via von-Neumann's minimax theorem. Two particularly technical aspects of our proof are the usage of a non uniform discretization, which is contrary to all previous works, and the use of Freedman's inequality for martingale difference sequences. 

We remark that our non-constructive proof is motivated from \cite{hu2024predict}, who provide a similar proof to show the existence of an algorithm that simultaneously achieves $\cO(\sqrt{T} \log T)$ swap regret for any bounded proper loss. However, compared to \cite{hu2024predict}, we use a non uniform discretization, which requires a more involved analysis.\footnote{We remark that the idea of using a non uniform discretization has already appeared in the literature \citep{kotlowski2016online}, albeit in a different context. In fact our discretization scheme in Section \ref{sec:pseudo-KL-Cal} coincides with \cite{kotlowski2016online}, however, its combination with other techniques in our paper results in a significantly different approach. 
}
Moreover, due to the desired $\cO(T^{\frac{1}{3}})$ nature of our final bounds, we cannot merely use Azuma-Hoeffding 
that guarantees $\cO(\sqrt{T})$ concentration. The aforementioned reasons combined make our analysis considerably non-trivial and different than \cite{hu2024predict}. 

Combined with the implications of Section \ref{sec:implications}, we show the existence of an algorithm that simultaneously achieves the following bounds on $\mathbb{E}[\sreg^{\ell}]$: (a) $\cO(T^{\frac{1}{3}} (\log T) ^ {\frac{5}{3}})$ for the log loss; (b) $\cO(T^{\frac{1}{3}} (\log T) ^ {\frac{5}{3}})$  for each $\ell \in \cL_{2}$; (c) $\cO(G \cdot T^{\frac{1}{3}} (\log T) ^ {\frac{5}{3}})$ for each $\ell \in \cL_{G}$; and (d) $\cO(T^{\frac{2}{3}} (\log T) ^ {\frac{5}{6}})$ for each $\ell \in \cL \backslash \{\cL_{2} \cup \cL_{G}\}$. Notably, our result is better than \cite{luo2024optimal} who studied the weaker notion of external regret, defined as $\textsc{Reg}^{\ell} \coloneqq \sup_{p \in [0, 1]} \sum_{t = 1} ^ {T} \ell(p_{t}, y_{t}) - \ell(p, y_{t})$,
and showed that the Follow-the-Leader (FTL) algorithm achieves $\textsc{Reg}^{\ell} = \cO(\log T)$ for each $\ell \in \cL_{2} \cup \cL_{G}$, however incurs $\textsc{Reg}^{\ell} = \Omega (T)$ for a specific $\ell \in \cL \backslash \{\cL_{2} \cup \cL_{G}\}$. 

\item In Section \ref{sec:pseudo-KL-Cal}, we propose an explicit algorithm that achieves $\pkcal = \cO(T^{\frac{1}{3}} (\log T) ^ \frac{2}{3})$. Similar to \cite{fishelsonfull}, we utilize the Blum-Mansour reduction for minimizing $\psreg^{\ell}$ for the log loss. However, our key novelty lies in the usage of a non uniform discretization and a new randomizing rounding procedure (Algorithm \ref{alg:rounding_alg}) for the log loss. Since the log loss is not Lipschitz, we show that the common rounding schemes studied in the literature fail to work for our considered discretization. 
A natural implication of our result is that, since $\psreg^{\ell} \le G \cdot \pkcal$ for any $\ell \in \cL_{G}$, we recover the result of \cite{fishelsonfull}. However, since $\psreg^{\ell} = \cO(\pkcal)$ for any $\ell \in \cL_{2}$, we are able to deal with new losses, and even the log loss which is unbounded.

\item Finally, in Section \ref{sec:bound_calibration}, we show that if we only consider the class of bounded proper losses with a smooth univariate form, our algorithm guarantees $$\cal_{2} = {\cO}\bigc{T^{1/3} (\log T) ^ {-\frac{1}{3}}\log (T/{\delta})}, \quad \msr_{\cL_{G}} = {\cO}\bigc{G \cdot T^{1/3} (\log T) ^ {-\frac{1}{3}}\log (T/{\delta})}$$ with probability at least $1 - \delta$. This marks the first appearance of a sub-$\sqrt{T}$ bound for classical $\ell_{2}$-Calibration.

\end{itemize}


\subsection{Related Work}

\paragraph{Simultaneous swap regret minimization} Calibration can also be viewed from the lens of simultaneous regret minimization \citep{kleinberg2023u, roth2024forecasting, hu2024predict, luo2024optimal}. It is known from \cite{kleinberg2023u} that
$\ell_{1}$-Calibrated forecasts can simultaneously lead to sublinear swap regret for all $\ell \in \cL$. However, as shown by \cite{qiao2021stronger, dagan2024improved}, for any forecasting algorithm there exists an adversary that ensures that $\cal_{1} = \Omega(T^{0.54389})$, thereby sidestepping the goal of achieving the favorable $\sqrt{T}$ style regret guarantee. Despite the limitations of calibration, \cite{hu2024predict} proposed an explicit algorithm that achieves $\mathbb{E}[\sup_{\ell \in \cL}\sreg^{\ell}] = \cO(\sqrt{T} \log T)$.  
Compared to \cite{hu2024predict}, we show that a single algorithm in fact achieves $\tilde{\cO}(T^{\frac{1}{3}})$ swap regret for important subclasses of $\cL$ and even the log loss, while simultaneously achieving $\tilde{\cO}(T^{\frac{2}{3}})$ swap regret for any arbitrary $\ell \in \cL$. Notably, the result of \cite{hu2024predict} does not apply to the log loss since it does not belong to $\cL$. An analogue of simultaneous swap regret minimization has also been studied in the contextual setting (\citealp{garg2024oracle}; referred to as swap omniprediction), where the forecaster competes with functions from a hypothesis class $\cF$. 
For this, \cite{garg2024oracle} showed that it is impossible to achieve $\cO(\sqrt{T})$ swap omniprediction for the class of convex and Lipschitz loss functions, even in the simplest setting where $\cF$ contains the constant $0, 1$ functions. 

\paragraph{Simultaneous external regret minimization} \cite{kleinberg2023u} proposed U-Calibration, where the goal is to simultaneously minimize $\textsc{Reg}^{\ell}$ for all $\ell \in \cL$ and provided an algorithm that achieves U-Calibration error $\ucal \coloneqq \sup_{\ell \in \cL} \textsc{Reg}^{\ell} = {\cO}(\sqrt{T})$. 
In the multiclass setting with $K$ classes, \cite{luo2024optimal} proved that the minimax error is $\Theta(\sqrt{KT})$. 
The concept of U-Calibration has also been extended to the contextual setting (referred to as online omniprediction \citep{garg2024oracle}). Very recently, \cite{okoroafor2025near} have shown that it is possible to achieve $\textsc{Reg}^{\ell} = \cO(\sqrt{T \log \abs{\cF}})$ simultaneously for any Lipschitz loss function $\ell$ against a finite hypothesis class $\cF$, thereby surpassing the limitations of swap omniprediction.  

\paragraph{Weaker notions of calibration} Understanding the limitations of online calibration, i.e., $\cal_{1} = \cO(\sqrt{T})$ is impossible, has led to a recent line of work aimed at studying weaker notions of calibration which are still meaningful for downstream loss minimization tasks, e.g., continuous calibration \citep{foster2021forecast}, U-Calibration \citep{kleinberg2023u}, distance to calibration \citep{pmlr-v247-qiao24a, arunachaleswaran2025elementary}. Particularly, the last two works 
considered the problem of minimizing the distance to calibration ($\mathsf{CalDist}_{1}$), defined as the $\ell_{1}$ distance between the forecaster's vector of predictions and that of the nearest perfectly calibrated predictor, and proposed a non-constructive, constructive proof respectively
that there exists an algorithm that achieves $\mathsf{CalDist}_{1} = \cO(\sqrt{T})$. Since $\mathsf{CalDist}_{1} \le \cal_{1} \le \sqrt{T \cdot \cal_{2}}$, our Algorithm \ref{alg:BM_log_loss} in fact ensures that $\mathsf{CalDist}_{1} = {\cO}(T^{\frac{2}{3}} (\log T) ^ {-\frac{1}{6}}\sqrt{\log (T/\delta)})$ with probability at least $1 - \delta$, while simultaneously minimizing swap regret for several subclasses of $\cL$.

