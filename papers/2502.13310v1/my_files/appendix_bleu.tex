\section{BLEU Scores for Response Generation}
\label{sec:appendix_bleu}

Table~\ref{tab:response_blue} presents additional metrics for response generation. {\bleu} scores are reported for baselines ({\simpletod}, {\soloist}, {\zstod}, {\autotod}), and {\oursys} models (\gpt, \llamai, \flan) with schema augmentations.
We see a similar trend here as well, with {\oursys} models outperforming baseline approaches. 
However, {\bleu} scores are better for {\llamai} than {\flan}, particularly for the seen domains. 
Since the {\bleu} metric is calculated by n-gram matches, {\llamai} having better supervised performance tends to generate responses closer to the ground truth, thus yielding higher {\bleu} scores.


\begin{table*}[!t]
    \centering
    \begin{adjustbox}{max width=\textwidth}
        \begin{tabular}{|c|c|cccc|cccc|cccc|}
            \hline
    \multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{Model}} & \multicolumn{4}{c|}{\textbf{Overall Response (BLEU-4)}} & \multicolumn{4}{c|}{\textbf{Inform (BLEU-4)}} &  \multicolumn{4}{c|}{\textbf{Request (BLEU-4)}} \\ %\cline{4-11}
    & & \textbf{All} & \textbf{Seen} & \textbf{Mixed} & \textbf{Unseen} & \textbf{All} & \textbf{Seen} & \textbf{Mixed} & \textbf{Unseen} &\textbf{All} & \textbf{Seen} & \textbf{Mixed} & \textbf{Unseen} \\ \hline
\multirow{7}{*}{SGD}     & \simpletod                                  
                        &  0.1696       &  0.1834      &     0.1877    & 0.1494      
                        &   0.1685      & 0.1790       & 0.1896       & 0.1438       
                        & 0.0228        & 0.0195       & 0.0216       & 0.0243       \\
                         & \soloist                                    
                         & 0.1902        & \underline{0.2798}        &0.1990         & 0.1655        
                         & 0.1813       & 0.2226       & 0.1945       & 0.1568
                         & 0.0281       & 0.0339        & 0.0265       & 0.0284       \\
                         & \zstod  
                         & 0.0590        & 0.1413        & 0.0568         &  0.0512
                         & 0.0255       & 0.0402       & 0.0228       & 0.0246
                         & 0.0231        & 0.0367       & 0.0221       & 0.0215       \\
                         & \autotod & 0.0487  & 0.0523  & 0.0501  & 0.0466 & 0.0854 & 0.0743 & 0.0884 & 0.0851 & 0.0173 & 0.0111 & 0.0159 & 0.0195 \\
                         \cline{2-14}
                         & \gpt & 0.2015  & 0.2109  & \underline{0.2229}  & 0.1802 & 0.2181 & 0.2421 & 0.2368 & 0.1923 & 0.0400   & 0.0275 & 0.0423 & 0.0403 \\
                         & \llamai & \textbf{0.2445}  & \textbf{0.2905}  & \textbf{0.2568}  & \textbf{0.2242} & \textbf{0.2888} & \textbf{0.3180}  & \textbf{0.3043} & \textbf{0.2650}  & \textbf{0.0641} & \textbf{0.0803} & \textbf{0.0614} & \textbf{0.0634} \\
                         & \flan  & \underline{0.2110}   & 0.2332  & 0.2226  & \underline{0.1961} & \underline{0.2811} & \underline{0.3098} & \underline{0.2911} & \underline{0.2631} & \underline{0.0569} & \underline{0.0625} & \underline{0.0541} & \underline{0.0582} \\
                         \thickhline
\multirow{7}{*}{KETOD}   & \simpletod                                  
                        & 0.0821        & 0.1015        & 0.0910        & 0.0538
                        & 0.1147       & 0.1362  & 0.1268       &  0.0726
                        & 0.0178       & 0.0266       & 0.0149       & 0.0106       \\
                         & \soloist                                    
                         & 0.0970        & 0.1018        & 0.0945       & 0.0848
                         & 0.0957       & 0.1185       &   0.0933     & 0.0675   
                         & 0.0167       & 0.0145       &      0.0174 & 0.0185  \\
                         & \zstod                                      
                         & 0.0394        & 0.0439        &   0.0254      & 0.0385
                         & 0.0183       & 0.0231       & 0.0059       &  0.0250
                         & 0.0260       & 0.0328       & 0.0198       & 0.0243       \\
                         & \autotod                                    & 0.0480   & 0.0528  & 0.0492  & 0.0415 & 0.0797 & 0.0678 & 0.0932 & 0.0812 & 0.0134 & 0.0157 & 0.0151 & 0.0092 \\
                         \cline{2-14}
                         & \gpt                                       & 0.1890   & 0.2106  & 0.1961  & 0.1524 & 0.2105 & 0.2437 & 0.2078 & 0.1687 & 0.0346 & 0.0500   & 0.0252 & 0.0263 \\
                         & \llamai & \textbf{0.2398}  & \textbf{0.2864}  & \textbf{0.2354}  & \textbf{0.1862} & \textbf{0.2701} & \textbf{0.3165} & \underline{0.2579} & \underline{0.2208} & 0.0581 & \underline{0.0723} & \textbf{0.0508} & \textbf{0.0490}  \\
                         & \flan & \underline{0.2082}  & \underline{0.2351}  & \underline{0.2048}  & \underline{0.1792} & \underline{0.2727} & \underline{0.3025} & \textbf{0.2811} & \textbf{0.2234} & \underline{0.0526} & \textbf{0.0750}  & \underline{0.0454} & \underline{0.0339}
                         \\
                         \hline
        \end{tabular}
    \end{adjustbox}
    \vspace{-6pt}
    \caption{BLEU Scores for Overall Response Generation, Inform and Request.}
    \label{tab:response_blue}
    \vspace{-6pt}
\end{table*}
