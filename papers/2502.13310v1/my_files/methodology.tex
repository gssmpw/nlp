\vspace{-5pt}
\section{Methodology}
\vspace{-4pt}
% \noindent
% \textbf{Problem Formulation.}
\subsection{Problem Formulation}
% \vspace{-2pt}
We formulate ToD task completion as a conditional sequence generation problem, where the system generates natural language responses or {\apicall}s using the dialog history and related domain schemas. 
We leverage domain schema to facilitate out-of-domain generalization in ToD systems.

We formalize the schema for a given domain \(d_x \in D\) by specifying a set of user intents \(\mathcal{I}_{d_x}\).
For example, in the \texttt{Restaurants} domain, one such intent might be \texttt{ReserveRestaurant}.
Each intent \(i_d \in \mathcal{I}_{d_x}\) is then associated with a set of slots \(\mathcal{S}_{i_d}\).
For instance, \texttt{party size} and \texttt{reservation time} might be slots for the \texttt{ReserveRestaurant} intent. 
Each slot \(s_{i} \in \mathcal{S}_{i_d}\) is characterized by a tuple \(\bigl(\text{name}(s),\,\text{is\_required}(s)\bigr)\), indicating the name of slot (e.g., \texttt{reservation date}) and whether it is mandatory to fulfill a desired intent.
% We formalize the schema for a given domain \(d \in D\) by specifying a set of user intents \(\mathcal{I}_d\).
% For example, in the ``Restaurants'' domain, one such intent might be ``Reserve Restaurant''.
% Each intent \(i_d \in \mathcal{I}_d\) is then associated with a set of slots \(\mathcal{S}_{i_d}\).
% For instance, ``party size'' and ``reservation time'' might be slots for the ``Reserve Restaurant'' intent. 
% Each slot \(s \in \mathcal{S}_{i_d}\) is characterized by a tuple \(\bigl(\text{name}(s),\,\text{is\_required}(s)\bigr)\), indicating the name of slot (e.g., ``reservation date'') and whether it is mandatory to fulfill a desired intent.
We denote the entire domain schema for domain \(d_x\) as:
\(
\Gamma_{d_x} 
\;=\; 
\Bigl(d_x,\; \mathcal{I}_d,\;\{\,\mathcal{S}_{i_d}\,\mid\,i_d\in\mathcal{I}_{d_x}\}\Bigr).
\)


A dialog session $\mathcal{T}_i$ of up to $T$ turns is defined as a sequence of user and system utterances:
\(
   \mathcal{T}_i = \bigl((u_1,r_1),\,(u_2,r_2),\,\dots,\,(u_T,r_T)\bigr),
\)
where $u_t$ is the user utterance and $r_t$ is the system response at turn $t$. 
We denote the dialog history at turn $t$ by
\(
   H_t = \{\,(u_1,r_1),\,(u_2,r_2),\dots,(u_{t-1},r_{t-1}),\,u_t\},
\)
which encapsulates all user-system exchanges up to and including the current user utterance \(u_t\). 
Since a single dialog may reference multiple domains, if \(\mathcal{T}_i\) spans \(m\) domains, we write \(\mathcal{T}_i \sim \{\,d_1,\,d_2,\,\dots,\,d_m\} \;\subseteq\; D.
\)
% In our formulation, the system generates its response \(r_t\), at turn \(t\), by conditioning on the relevant domain schemas \(\{\Gamma_{d_j}\}_{j=1}^m\) and the current dialog history \(H_t\).



% \noindent
% \textbf{Schema Augmentation.}
\vspace{-3pt}
\subsection{Schema Augmentation}
Beyond the original set of domain schemas, we create semantic variations of each domain’s intents and slots. Specifically, for each domain \(d_x \in D\), we we define its \(k\)-th schema variant as:
\(
\Gamma_{\tilde{d}^k_x} 
\;=\;
\Bigl(\, \tilde{d}^k_x,
  \tilde{\mathcal{I}}_{d^k_x},\;
  \bigl\{\,
    \tilde{\mathcal{S}}_{i_d}^k
    \;\mid\;
    \tilde{i}_d^k \in \tilde{I}_{d^k_x}
  \bigr\}
\Bigr),
\)
where $\tilde{I}_{d^k_x}$ is the renamed set of intents, and $\tilde{S}_{i_d}^k$ represents the renamed slots for each intent $\tilde{i}_d^k$. 
% For example, in the ``Restaurants'' domain, the original intent ``Reserve Restaurant'' might be changed to ``Reserve Table'', and the slot ``party size'' might become ``number of people''.
% To integrate these augmented schemas into the dialogs, we systematically replace schema references in existing dialogs with their counterparts from \(\Gamma_{\tilde{d}^k} \).
% Concretely, for each dialog $\mathcal{T}_i$ associated with domain \(d\), we construct an augmented dialog $\tilde{\mathcal{T}}_i^k$ by substituting all intents and slots with those from \(\Gamma_{\tilde{d}^k} \). 
% This procedure preserves the underlying dialog flow but exposes {\oursys} to multiple schema variations, ultimately improving its ability to generalize to out-of-domain task scenarios.

For example, in the \texttt{Restaurants} domain, the original intent \texttt{ReserveRestaurant} might be changed to \texttt{ReserveTable}, and the slot \texttt{party size} might become \texttt{number of people}.
To integrate these augmented schemas into the dialogs, we systematically replace schema references in existing dialogs with their counterparts from \(\Gamma_{\tilde{d}^k_x} \).
Concretely, for each dialog $\mathcal{T}_i$ associated with domain \(d_x\), we construct an augmented dialog $\tilde{\mathcal{T}}_i^k$ by substituting all intents and slots with those from \(\Gamma_{\tilde{d}^k_x} \). 
This procedure preserves the underlying dialog flow but exposes {\oursys} to multiple schema variations, ultimately improving its ability to generalize to out-of-domain task scenarios.
% For each domain $d_i \in D$, we create an augmented domain $\tilde{d}_i^k$ that represents the $k$-th augmented version of $d_i$. The augmented domain can be expressed as $\tilde{d}_i^k = \left( \tilde{I}_{d_i}^k, \{ (\tilde{i}_j^k, \tilde{S}_{i_j}^k) \mid \tilde{i}_j^k \in \tilde{I}_{d_i}^k \} \right)$, where 
% $\tilde{I}_{d_i}^k$ and $\tilde{S}_{i_j}^k$ denotes the renamed sets of intents and slots. For example, in the restaurant domain, the intent \texttt{ReserveRestaurant} is renamed to \texttt{ReserveATable} and the slot \texttt{party\_size} is renamed to \texttt{reservation\_size}.

% To incorporate the data augmentation strategy, we replace the domain schema information in the existing dialogs with the newly generated domain variants. For each dialog $\mathcal{T}_i$, if it originally belongs to domain $d$, we create an augmented dialog $ \tilde{\mathcal{T}}_i^k$ by replacing its intents and slots with those from $\tilde{d}_i^k$. This process maintains the original dialog flow and utterance structure while reflecting the augmented domain schema. The augmented data is combined with the original dataset during the training phase. 

 



%We formalize the schema for a domain $d \in D$ by specifying a set of user intents $\mathcal{I}_d$ in domain $d$. 
%For instance, ``Reserve Restaurant'' can be a user intent in the domain ``Restaurants''. 
%Each intent $i_d \in \mathcal{I}_d$ is then associated with a set of slots $\mathcal{S}_{i_d}$.
%For instance, slots ``party size'' and ``reservation time'' could be associated with the intent ``Reserve Restaurant''.
%Each slot $s \in \mathcal{S}_{i_d}$ can be characterized by a tuple 
%$\bigl(\text{name}(s),\,\text{is\_required}(s)\bigr)$, where $\text{is\_required}(.)$ determines whether the slot must be filled to fulfill the desired intent. 
%For instance ``reservation date'' and ``reservation time'', among other slots, must be filled to fulfill the user intent ``Reserve Restaurant''.
%We express the domain schema for $d$ as:
%\(
%\Gamma_d 
%\;=\; 
%\Bigl(d,\; \mathcal{I}_d,\;\{\,\mathcal{S}_{i_d}\,\mid\,i_d\in\mathcal{I}_d\}\Bigr).
%\)




%old
% Formally, in a multi-domain TOD setting, let \( D = \{d_1, d_2, \ldots, d_n\} \) be a set of domains, where each \( d_i \in D \) represents a distinct domain of interest.
% For each domain \( d_i \), there exists a set of intents \( I_{d_i} \) such that \( I_{d_i} \subseteq \bigcup_{j=1}^n I_{d_j} \) is the set of possible intents associated with the domain \( d_i \). 
% Each intent \( i_j \in I_{d_i} \) represents a specific user intent in domain \( d_i \).
% For each intent \( i_j \in I_{d_i} \) there exists a set of slots \( S_{i_j} \) such that 
% \( S_{i_j} \subseteq \bigcup_{k=1}^m S_{i_k} \)
% is the set of possible slots associated with the intent \( i_j \), where each slot \( s_k \in S_{i_j} \) represents a slot relevant to the intent \( i_j \) in the domain \( d_i \).
% So, a domain \( d_i \) can be represented as follows: 
% \(
% d_i = \left( I_{d_i}, \{ (i_j, S_{i_j}) \mid i_j \in I_{d_i} \} \right)
% \).
% For example, in the restaurant domain, the intent could be \texttt{ReserveRestaurant} with relevant slots such as \texttt{party\_size}, \texttt{date}, and \texttt{restaurant\_name}.

% Similarly, assume we have a dataset of
% dialogs between a user and a system.
% Each dialog \(\mathcal{T}_i\) consists of up to \( T \) turns, represented as a sequence:
% \(
% \mathcal{T}_i = \left( \{ (u_t, r_t) \mid t = 1, 2, \ldots, T \} \right)
% \), where \( u_t \) and \( r_t \) represent the user's and system's utterance at turn \( t \).
% Thus, the dialog history \(H_t\) at turn \(t\) consists of all the user and system utterances up user's utterance at turn \(t\), denoted as: 
% \(
% H_t = \{ (u_{1}, r_{1}),\dots, (u_{t-1}, r_{t-1}), u_{t} \}
% \).
% It is important to note that a dialog session may span up to \(m\) domains: $ \mathcal{T}_i \sim \bigcup_{j=1}^m d_{j} \subseteq  D$, where \(m \leq n \). 
% At turn $t$, the system utterance $r_t$ can be generated by conditioning on the relevant domain schemas \(\bigcup_{j=1}^m d_{j}\) and dialog history $H_t$.

% A ToD system must handle various types of interactions, including general conversation, requesting task-specific information from the user, providing requested details, and making API calls to retrieve information or execute actions for task completion. The system's output can be broadly categorized into two types: \myNum{i}~natural language responses to the user; and \myNum{ii}~API calls to external sources, which consist of a method name, parameters, and corresponding values. 
% Our approach trains the model to generate both types of outputs in an end-to-end manner using multi-task instruction fine-tuning. Notably, we do not introduce special tokens to specify response type; instead, the model learns to determine autonomously whether to generate an API call or a user-facing natural language response based on task and dialog context.  


% \noindent
% \textbf{Multi-task Instruction Fine-tuning.}
\vspace{-3pt}
\subsection{Multi-task Instruction Fine-tuning}
A ToD system must handle diverse interactions, including general conversation, requesting task-specific information, providing details, and making {\apicall}s for task completion. Broadly, the system generates two types of outputs: \myNum{i} natural language responses, and \myNum{ii} {\apicall}s, which include a method name, parameters, and corresponding values. We employ multi-task instruction fine-tuning that trains the model to autonomously decide between generating an {\apicall} or a user response, without introducing special tokens.


Formally, an autoregressive language model (e.g., GPT-2~\cite{radford2019language}) generates text by predicting the next token given the preceding context. For a given sequence of tokens \( (x_1, x_2, \ldots, x_{t-1}) \), the probability distribution for the next token \( x_t \) is computed as:  \(
p(x_t \mid x_{1:t-1}; \theta) = f_{\theta}(x_{1:t-1}),
\)
where \( f_{\theta} \) represents the model parameterized by \( \theta \) and outputs a probability distribution over the vocabulary \( \mathcal{V} \). The next token \( x_t \) is then sampled from this distribution.  
This formulation extends naturally to response generation in ToD systems, where the system response \( r_t \) at turn \( t \) is generated recursively until an end-of-sequence token (\texttt{<eos>}) is produced:  \(
    r_t \sim p(r_t \mid H_t; \theta),
\)
where \( H_t \) denotes the dialog history up to turn \( t \).  



To improve out-of-domain generalization, {\oursys} introduces an additional conditioning variable, the domain schema \( \Gamma_{d_x} \) for each domain \( d_x \) and an instruction prompt \( P \). 
The instructions encourage the model to comprehend schema representations to better generalize across unseen domains and dialog contexts. 
Extending the above formulation to multi-task instruction fine-tuning for multi-turn dialogs of length \( T \), where each dialog may span multiple domains \( \{d_1, d_2, \dots, d_m\} \subseteq D \), we optimize the following objective:  
\( - \sum_{t=1}^{T} \log p(r_t \mid P, \{\Gamma_{d_j}\}_{j=1}^{m}, H_t,; \theta).
\)
Since LLMs operate under a finite context length, the dialog history \( H_t \) consists of only the most recent \( k \) turns, where \( k \leq t \).




% A ToD system must handle various types of interactions, including general conversation, requesting task-specific information from the user, providing requested details, and making API calls to retrieve information or execute actions for task completion. The system’s output can be broadly categorized into two types: natural language responses to the user and API calls to external sources, which include the method name, parameters, and corresponding values. Our formulation trains the model to generate both types of outputs in an end-to-end manner using multi-task instruction fine-tuning. Notably, we do not introduce special tokens to indicate response type; instead, the model autonomously learns when to generate API calls versus user-facing responses based on context.


% Formally, an autoregressive model (e.g., GPT-2~\cite{radford2019language}) generates text by predicting the next token given the preceding context.
% For a given sequence of tokens \( (x_1, x_2, \ldots, x_{t-1}) \), the model predicts the probability distribution for the next token \( x_t \) as follows:
% \(
% p(x_t \mid x_{1:t-1}; \theta) = f_{\theta}(x_{1:t-1})
% \), where \( f_{\theta} \) outputs a probability distribution over model's vocabulary \( \mathcal{V} \).
% The next token \( x_t \) is sampled from the predicted probability distribution \( p(x_t \mid x_{1:t-1}; \theta) \).
% This formulation readily extends to response generation for ToD systems:
% \(
% r_t \sim p(r_t \mid H_{t}; \theta)
% \),
% where the system response \(r_t\) for turn \(t\) is generated token-by-token by recursively sampling until a special token (i.e., <eos>) is generated.


% In our formulation of {\oursys}, we introduce an additional conditioning variable domain schema \(\Gamma_d\) for domain \(d\) to encourage zero-shot generalization to unseen domains.
% Then, the above formulation can be extended to optimize the model for multi-turn dialogs of \(T\) where each dialog may span up to \(m\) domains \(\{\,d_1,\,d_2,\,\dots,\,d_m\} \;\subseteq\; D
% \)
% using a dataset of \(N\) dialogs with the following loss function:
% \(
% \mathcal{L}_{NL-TOD} = - \sum_{i=1}^{N} \sum_{t=1}^{T} \log p(r_{t} \mid H_{t}, \{\Gamma_{d_j}\}_{j=1}^m ; \theta)
% \).
% In practice, dialog history \(H_t\) only consists of the last $k$ turns, where $k \leq t$, depending on the model's context length.

% The output of our system can be broadly categorized into two types: natural language responses to the user and API calls to external sources.
% Our formulation trains the model for both outputs in an E2E fashion using multi-task instruction fine-tuning. 
% It is important to note that we do not introduce any special tokens to tell the model which type of response to generate, instead the model learns autonomously when to generate API calls and when to generate a natural language response for the user.
% In the following, we provide a brief overview of both types of responses.

%\subsection{Optimization of {\oursys}}


% \subsubsection{Response Generation}

% The response generation is a natural language response for the user, which can be broken down into multiple sub-categories: request, inform, and general interaction.

% \noindent
% \textbf{Request.}
% To fulfill user intents, the system may need additional information that the user has not yet provided.
% For example, if a user asks to book a flight without specifying the date, the system would ask, ``What date would you like to travel?''.



% \noindent
% \textbf{Inform.}
% The user may also need additional information to make informed decisions, which the system must provide. 
% This involves retrieving and presenting requested details to the user.
% For example, if a user asks, ``Does the restaurant have live music?'' the system must query the database and provide the requested information to the user.

% \noindent
% \textbf{General Interaction.}
% The system also needs to engage in general interactions. 
% This involves managing the flow of the conversation, offering help or suggestions, confirming user inputs, and providing general information that assists the user in navigating through the task. 



% \subsubsection{API Calls}
% \vspace{-3pt}
% A critical aspect of TOD systems is their ability to communicate with external sources to retrieve additional information needed to complete a task. This category of system output involves making accurate \apicall s.
% % Consider a dialog scenario in the travel domain, where a user asks for Flights to New York the next Friday at 10 AM. 
% % Given the dialog context, the system must get a list of flights for recommendation, which requires generating an \apicall:
% % \texttt{APICall(method = FindFlight, parameters = \{destination=New York, date=next Friday, time=10AM, origin=CurrentLocation\})}.
% Consider the dialog scenario shown in Figure~\ref{fig:approach}, where a user is looking for Indian food in Nashville. The system must get a list of restaurants for recommendation, which requires communicating with an external resource via {\apicall}. An {\apicall} has several components: method name, list of parameters, and values associated with parameters. It is important to note that the {\apicall} must align with the information in the Domain Schema.
% Using the information returned from the \apicall, the system can suggest restaurants to the user.
% It is important to note that the {\apicall} has several components: method name, list of parameters, and values associated with parameters.

% In multi-domain settings, a special case arises when transferring information between domains, where the same data is carried forward but under different parameter names. 
% For example, a parameter named \texttt{destination} in the travel domain might be referred to as \texttt{hotel\_city} in the subsequent hotel booking domain. 
% An intelligent TOD model should autonomously perform this mapping.



% \noindent
% \textbf{Training Details}
\vspace{-5pt}
\subsection{Training Details}
\vspace{-3pt}
The dialog history and domain schema are passed through a structured template to form the inputs to the model. 
The template is detailed in Figure~\ref{fig:finetuning_template} in Appendix~\ref{sec:templates}.
Training begins with 500 warm-up steps and early stopping on the evaluation loss with a patience value of 3.
We used the AdamW~\cite{Loshchilov2017DecoupledWD}  optimizer with weight decay and a learning rate of 0.001.
% The AdamW~\cite{Loshchilov2017DecoupledWD} optimizer with a weight decay was used with a learning rate of 0.001. 
Experiments were conducted with GPT2-Medium, FLAN-T5 Large and Llama 3.2 3B Instruct models. 
{\gpt} and {\flan} were fine-tuned fully, while {\llamai} used Low-Rank Adaptation~(LoRA)~\cite{Hu2021LoRALA} and 8-bit quantization~\cite{jacob2018quantization} for memory efficiency.





