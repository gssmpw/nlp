% \vspace{5em}
% \begin{table*}[t]
\begin{table*}[!h]
% \vspace{-2.5em}
% \hspace{-0.6em}
\centering
\scalebox{1.00}{ 
 
\begin{tabular}{@{}lccccccc@{}} % Changed from || to |
% \toprule
 \textbf{Sub-task \& Style} &  {\textbf{Helpful}} &  {\textbf{Factual}} &   {\textbf{Deep}} &   {\textbf{Engaging}} &   {\textbf{Clear}} &   {\textbf{Safe}} &    {\textbf{Avg.}} \\
 \midrule
% {\small \faToggleOn} Vicuna-7b (SFT)        &          \textbf{4.43} &      \textbf{4.85} &         \textbf{4.33} &    \textbf{4.04} &         4.51 &     4.60 &  {4.46} &    184.8 \\
% {\small \faToggleOn} Llama2-7b-chat (RLHF)  &          4.10 &      4.83 &         {4.26} &    3.91 &         \textbf{4.70} &     \textbf{5.00} &  \textbf{4.47} &    \textbf{246.9} \\ 
% \midrule
{\small \faGraduationCap} \textbf{Three-part}    &   3.39               &  3.79           &  2.56           &  1.37         &  4.28             &  2.46         &   2.98  \\
{\small \faGraduationCap} \textbf{Lengthy}       &   3.80               &  \textbf{3.98}  &  3.40           &  1.53         &  3.78             &  2.54         &  3.17  \\
{\small \faGraduationCap} \textbf{Human}           &   3.44             &  3.86           &  2.41            &  3.75          &  3.97           & \textbf{2.62} & 3.34 \\
{\small \faGraduationCap} \textbf{Combined}        &   \textbf{3.89}    &  3.87         &  \textbf{3.72}     &  \textbf{4.32} &  \textbf{4.50}  & 2.61           &  \textbf{3.82}   \\
{\small \faGraduationCap} \textbf{No style}        &   2.46             &  3.38         &  3.17             &  2.44           &  3.88           &2.55           &   2.98   \\

\midrule \midrule
% Mistral-7b-instruct (SFT)   &          4.36 &      4.87 &         4.29 &    3.89 &         4.47 &     4.75 &  4.44 &    155.4 \\
% Mistral-7b (\methodname{})       &          4.57 &      4.89 &         4.50 &    4.18 &         4.74 &     4.92 &  4.63 &    186.3 \\
{\small \faUserShield} \textbf{Three-part}          &  2.57          & 3.09   &  1.97           & 2.05   &  3.65           &  2.13        &        2.58\\
{\small \faUserShield} \textbf{Lengthy}       &  2.59  & \textbf{3.15}          &  2.38   & 2.02            &  3.47  &  2.20        &        2.64 \\
{\small \faUserShield} \textbf{Human}           &   2.56          &  3.06           & 1.85           & 3.05   &  3.50           &  2.38        &        2.73  \\
{\small \faUserShield} \textbf{Combined}       &   \textbf{2.63}          &  3.10           &  \textbf{2.44}           &  \textbf{3.11}           &  \textbf{3.70}           &  2.40        &          2.89  \\
{\small \faUserShield} \textbf{Refusal}     &   2.40          &  2.99           &  2.12           &  2.53           &  3.60           &\textbf{4.28} &        \textbf{2.99}    \\
{\small \faUserShield} \textbf{No style}     &   2.34          &  3.05           &  2.13           &  2.40           &  3.62           &4.02      &        2.93    \\

\bottomrule
\end{tabular}
}
\caption{The Average Treatment Effect results when examining difference styles in the alignment causal structure. 
The icon {\small \faGraduationCap} refers to the ICL demonstration example belongs to \textit{factuality} set $\{C_f\}$, while {\small \faUserShield} indicates the ICL demonstration example belongs to \textit{safety} set $\{C_s\}$. 
`Three-part' refers to restyle the answer part of the demonstration example into the three-part structure. `Lengthy' denotes restyling the answer in a long and detailed format. `Human' means re-write the answer part in human-like tone. `No style' represents that the answer remains unchanged, `Combined' means we rewrite the answer using all styles together, i.e., three-part, lengthy and human, while `Refusal' is used for restyling safety ICL examples.
We are using a seubset of \dataname{} to evaluate the LLM's performance.
\vspace{-0.5em}}   
\label{tab:ate_style}
\end{table*}




