In this paper, we take the first step by comparing the token generation probability differences between aligned and unaligned models, identifying different polarity tokens oriented towards factuality and safety. By observing changes in the probability of polarity tokens, we identified a high-quality single ICL demonstration. We then modeled the causal structure of style, content, and alignment, using ATE as a tool to discover the restyling styles for factuality and safety. We used the restyled examples as demonstrations in the ICL approach, eliciting the LLMâ€™s capabilities for different tasks, and experimentally validated the effectiveness of the proposed ICL demonstrations. 
% Finally, through our experiments, we confirmed the causal relationship among content, style, and alignment. Moreover, we found a trade-off between factuality and safety during the construction of the ICL demonstration set, indirectly validating that the polarity tokens corresponding to different capabilities are distinct.