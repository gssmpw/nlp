\section{Rewriting ICL demonstration examples - A Further Discussion}
\label{appendix:restyle_discuss}

To systematically modify the writing style of QA pairs, we design a structured prompting approach consisting of three components: 1) Task instruction: A directive informing the LLM to explicitly rewrite the answer in a specific style; 2) Example demonstration: A concrete example illustrating how the modification should be performed. 3) Target QA pair: The QA pair to be rewritten.
We feed this prompt into an LLM, which then generates a restyled QA pair, ready to be used as an ICL exemplar.

For these modifications, we leverage a strong LLM\footnote{We used GPT-4o to restyle the answers in the ICL demos.} to ensure high-quality restyling.
Based on the findings in Section~\ref{section2}, we modify the style of the answer part in the following ways: (1) \textbf{three-part} (structuring the answer in three parts: introduction, bullet-point explanation, and summary.), (2) \textbf{lengthy} (expanding the answer with more details while preserving its original meaning), (3) \textbf{human} (adopting a conversational or first-person tone), (4) \textbf{combined} (use three-part, lengthy and human three styles to rewrite the ICL example simultaneously), (5) \textbf{refusal} (for safety-related ICL examples, refuse first, justify, and then provide guidance.), and (6) \textbf{no style} (the original ICL demonstration that remains unchanged). 

Same as Section~\ref{section2}, we utilize value impact to examine how restyled ICL exemplars influence LLM alignment. 
Specifically, we select \textbf{top-20} QA pairs from each of UltraChat and SORRY-Bench with the highest value impact, denoted as the \textbf{\color{myblue} factuality} and \textbf{\color{myred} safety} ICL candidates, represented as ${S_\text{cand\_f}}$ and ${S_\text{cand\_s}}$, respectively.

We compute the average value impact across all 20 instances for the instances in ${S_\text{cand\_f}}$. The same computation is performed for ${S_\text{cand\_s}}$ as well. This allows us to quantitatively and systematically analyze how QA pairs—each inherently emphasizing different aspects of \textbf{\color{myblue} factuality} and \textbf{\color{myred} safety}—change in alignment performance after undergoing different style modifications.

In Table~\ref{tab:restyle}, the upper block of the table represents the effect of restyling on ICL demonstrations belonging to ${S_\text{cand\_f}}$. 
Therefore, the following observations can be made from this block: 
(1) The original exemplars from ${S_\text{cand\_s}}$ (\textbf{no style}) inherently possess some capability to enhance LLM \textbf{\color{myblue} factuality}, particularly in the dimensions of "helpful", "factual", "deep", and "clear". 
However, compared to the baseline (where no ICL demonstrations are used), this improvement is relatively modest.
(2) The \textbf{three-part} style effectively enhances "clear", the \textbf{lengthy} style improves "depth", and the \textbf{human-like} style increases "engaging."
(3) The \textbf{three-part}, \textbf{lengthy}, and \textbf{human-like} styles all contribute to improvements in "helpful" and "factual."
(4) Considering all metrics except "safe", the \textbf{combined} style achieves the best overall \textbf{\color{myblue} factuality} performance ("helpful", "factual", "deep", "engaging", and "clear").
(5) None of the restyling approaches significantly improve the "safe" metric.

The lower block of Table~\ref{tab:restyle} records the effects of restyling on \textbf{\color{myred} safety} demonstrations. Compared to no style, it can be seen that: (1) All restyling styles have limited impact on improving \textbf{\color{myblue} factuality}; (2) Restyling with any style other than \textbf{refusal} even reduces the “safe” score; (3) The \textbf{refusal} style significantly enhances the “safe” metric.

Overall, based on the above analysis, we provide answers to the two questions.
\emph{(Q1) Will the restyled demonstration impact LLM alignment?}
The answer is yes—restyled exemplars can have a more significant impact on LLM alignment.
\emph{(Q2) What effects do the restyle QA pairs from different datasets will have?}
Our findings suggest that factuality candidates should be rewritten using a \textbf{combined} style, whereas \textbf{\color{myred} safety} ICL exemplars should be restyled using a \textbf{refusal} style for optimal alignment performance.
Additionally, to achieve optimal overall performance in an LLM, a trade-off between \textbf{\color{myblue} factuality} and \textbf{\color{myred} safety} must be reached. 
The prompts used for the explicit restyling of ICL demos can be found in Appendix~\ref{app:prompt_restyle}.

Also, we argue that the effectiveness of ICL demo restyling stems from the \textit{causal relationship} between the style of an ICL exemplar and LLM alignment. 
Together with the content of the ICL demo, this relationship forms a \textit{causal structure}. In this context, restyling an ICL demo can be viewed as an intervention ($do$-operation) within this causal framework.
For a detailed theoretical analysis of this aspect, please refer to the Appendix~\ref{append:causality}.

