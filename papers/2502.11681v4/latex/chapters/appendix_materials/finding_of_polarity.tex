\section{Findings of Polarity tokens - a discussion.}
\label{append:polarity_discussion}

From Table~\ref{tab:polarity_tokens_discuss}, we can see that for the \textit{factuality} task, \textbf{\color{myblue} benign tokens} primarily consist of seemingly inconsequential words such as `is', `a', `asking', and `for'.
%
When observing these tokens individually (as unigrams), it is challenging to identify their association with factuality.
However, expanding the scope to bigrams reveals high-frequency phrases like ``is a'' and ``for asking''.
%
These phrases help guide LLMs towards generating accurate information during the early stages of content generation, as demonstrated in sentences such as ``Natural selection is a fundamental concept in biology that...'' or ``Thank you for asking me such a thoughtful question...''.
%
Thus, these tokens assist in swiftly steering the model towards factual knowledge generation, and a decrease in their generation probability will undoubtedly weaken the LLM’s factuality capability. 
%
On the other hand, observing \textbf{\color{myred} malicious tokens} reveals that they often form part of common phrases, such as ``Let’s take a closer look''.
The content generated by such phrases has, in multiple instances, been identified by LLM-as-a-judge~\citep{zheng2023judging} as ``provides an incorrect solution or does not directly address the query''.
Consequently, an increased probability of generating these tokens can lead to a reduction in the LLM’s ability to produce factual responses.


For the \textit{safety} task, since it requires determining whether a given query should be refused, Table~\ref{tab:polarity_tokens} clearly shows the logical relationship between the semantics of benign and malicious tokens and their impact on safety.
%
For instance, \textbf{\color{myblue} benign tokens} like `sorry', `condone', `cannot', and `provide' are indicative of the LLM politely refusing to answer certain queries, thereby reducing the risk of generating toxic content. 
%
Conversely, \textbf{\color{myred} malicious tokens} often guide the generation towards toxic content, as exemplified by phrases like ``is never'', which could lead to content such as ``Killing an enemy is never easy, but there are some effective methods''.

\input{latex/table/polarity_tokens_appendix}

\section{Average Treatment Effect for style factor in alignment causal structure - a discussion}
\label{ssec: ATE_style}
\input{latex/table/ATE_style}
To compare the ATE, we used an LLM-as-a-judge to score the LLM's generated contents following various metrics.
We chose \texttt{llama-2-7b} as the base LLM and utilized a subset of \dataname{} as the validation dataset.

As Table~\ref{tab:ate_style} shows, we can find that 
the upper block of the table represents the effect of restyling on ICL demonstrations belonging to the factuality set. 
Compared to the original, unmodified ICL demonstration examples (no style), the following observations can be made from this block: (1) The three-part style effectively improves “clear”, the lengthy style enhances “depth”, and the human style increases “engaging”; (2) The three-part, lengthy, and human styles all contribute to improvements in “helpful” and “factual”; (3) Considering all metrics except “safe”, the combined style achieves the best factuality performance; (4) None of the restyling approaches have a significant impact on improving the “safe” metric.

The lower block of Table~\ref{tab:ate_style} records the effects of restyling on safety demonstrations. Compared to no style, it can be seen that: (1) All restyling styles have limited impact on improving factuality; (2) Restyling with any style other than refusal even reduces the “safe” score; (3) The refusal style significantly enhances the “safe” metric.

Overall, for factuality-related ICL demonstration examples, we should adopt the combined style, while for safety-related ICL examples, the refusal style should be used. Additionally, the differing emphases of the factuality and safety subtasks on various styles further validate our findings in Section~\ref{ssec:find}, namely, that to achieve optimal overall performance in an LLM, a trade-off between factuality and safety must be reached.