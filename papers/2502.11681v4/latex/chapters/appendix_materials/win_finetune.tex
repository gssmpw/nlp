\section{Unaligned LLM + \textbf{RIDE} can outperform its aligned counterpart}
\label{append:win_finetune}
\input{latex/table/table_win_finetune}

\paragraph{Settings.}
As stated in Appendix~\ref{append:background}, we consider an aligned LLM (e.g., Mistral-7B-Instruct-v0.1) as a model derived from its base model (e.g., Mistral-7B-v0.1) through instruct fine-tuning. In our experiments, we employ \textbf{RIDE} as ICL demonstrations for the base Mistral-7B-v0.1 model and compare its performance against Mistral-7B-Instruct-v0.1 across three datasets.

From Table~\ref{tab:win_finetune}, we observe that when Mistral-7B-v0.1 utilizes $\textbf{RIDE}$ as its ICL demonstration exemplars, its performance surpasses that of Mistral-7B-Instruct-v0.1, which is obtained by performing instruct fine-tuning on Mistral-7B-v0.1, across all three datasets.

\paragraph{Results.} Based on this phenomenon, we propose the following hypotheses:
\begin{itemize}
\item Mistral-7B-Instruct-v0.1 may not have undergone dedicated alignment tuning, resulting in insufficient alignment capabilities.
\item When the base model is already sufficiently powerful, it may inherently possess a certain degree of alignment capability, though deeply embedded within the LLMâ€™s internal knowledge. In such cases, utilizing \textbf{RIDE} as ICL demonstrations can effectively guide the LLM in rapidly learning structured response patterns, thereby activating its latent alignment abilities.
\item When training resources are limited or fine-tuning is impractical, our $\textbf{RIDE}$ can be employed on top of the base model to enhance LLM alignment in a cost-efficient, tuning-free manner.
\end{itemize}



