\section{ICL methods on \dataname{} - A Further Discussion}
\label{append:justeval_discuss}

\paragraph{Settings.} As discussed in Section~\ref{section3}, \textbf{\color{myblue} factuality} and \textbf{\color{myred} safety} in LLM alignment form a paradoxical unity—we aim to ensure that the LLM can provide informative responses to user queries while simultaneously preventing it from answering malicious questions. As a result, an increase in \textbf{\color{myred} safety} may sometimes lead to a decrease in \textbf{\color{myblue} factuality}.

To evaluate the LLM’s alignment capability under this trade-off, we selected the \dataname{} dataset for assessment.
In \dataname{}, the dataset places a great emphasis on \textbf{\color{myred} safety}. 
Out of the $1000$ test cases, $200$ questions are safety-related and require the model to provide clear refusal responses. 
The remaining $800$ instances are related to \textbf{\color{myblue} factuality}, requiring the LLM to provide accurate and helpful factual knowledge. 
Therefore, \dataname{} evaluates both the \textbf{\color{myblue} factuality} and \textbf{\color{myred} safety} capabilities of the LLM, requiring the LLM to make a balanced trade-off between the two.

\paragraph{Results.} Table~\ref{tab:justeval} presents the scores of each method on \dataname{}. 
From the table, we can summarize the following conclusions.

\begin{itemize}

 \item First, among the three proposed ICL sets, $\textbf{RIDE}_{\text{fs\_hyb}}$ performs the best, followed by $\textbf{RIDE}_{\text{fs\_uni}}$, and finally $\textbf{RIDE}_{\text{f}}$. $\textbf{RIDE}_{\text{fs\_hyb}}$ includes both \textbf{\color{myblue} factuality} and \textbf{\color{myred} safety} ICL examples, with the \textbf{\color{myred} safety} demonstration restyled using the ``\textbf{refusal}'' style, which effectively enhances the LLM’s \textbf{\color{myred} safety} capability while maintaining good \textbf{\color{myblue} factuality}. 
Although $\textbf{RIDE}_{\text{fs\_uni}}$ also contains a \textbf{\color{myred} safety} demonstration, it uses the ``\textbf{combined}'' style for restyling. 
While the three examples in it have a consistent style, the \textbf{\color{myred} safety} ability of the \textbf{\color{myred} safety} example is weakened, resulting in a lower ``Safe'' score compared to $\textbf{RIDE}_{\text{fs\_hyb}}$. 
As for $\textbf{RIDE}_{\text{f}}$, which consists entirely of \textbf{\color{myblue} factuality} examples, it has the strongest \textbf{\color{myblue} factuality} capability but lacks any \textbf{\color{myred} safety} example, preventing the LLM from learning how to refuse malicious queries, leading to a much lower ``Safe'' score compared to the other two ICL sets.
This finding aligns with our observations in Section~\ref{section3}, RQ2.

 \item Second, compared to \methodname{}, $\textbf{RIDE}_{\text{fs\_hyb}}$ outperforms it in two out of three models. 
In the case of OLMo-7B, the input window length is severely limited (only 2048 tokens), while our prompts containing ICL examples exceed this limit. 
Thus, we had to randomly remove parts of the ICL bullet points, which especially affects the LLM’s performance in ``Helpful'', ``Factual'', and ``Deep''.
However, even under such constraints, we can see that $\textbf{RIDE}_{\text{fs\_hyb}}$ performs comparably with \methodname{} in various aspects, with nearly identical scores in the crucial ``Safe'' metric ($2.69$ vs $2.70$), although it is slightly weaker in the overall ``Average'' score ($3.48$ vs $3.51$).

 \item Third, in the first block of Llama2-7b, we compared four baseline methods.
It can be observed that the baseline methods exhibit a significant performance gap compared to \methodname{} and our ICL sets. 
\textbf{TopK + ConE} is the closest in principle to our approach: selecting good ICL demonstrations by observing the impact of ICL on content generation during inference. 
This method is the best among the four baseline methods, but there is still a considerable gap compared to our approach. 

 \item Forth, a comparison between \textbf{Vanilla ICL} and our $\textbf{RIDE}$ series ICL demo sets indicates that merely combining the highest-performing examples from $\{S_\text{cand\_f}\}$ and $\{S_\text{cand\_s}\}$ does not necessarily produce an optimal set.
The observed performance gap between \textbf{Vanilla ICL} and $\textbf{RIDE}$ further validates the effectiveness of the hierarchical traversal approach in selecting an optimal set of ICL demonstrations.
It is worth noting that, in this benchmark, we exclusively utilized Llama-2-7b-hf to compare all baseline methods and assess their performance, aiming to minimize token consumption when invoking LLM-as-a-judge.

\end{itemize}