\section{Restyling – A Perspective from Causal Structure}
\label{append:causality}
We first provide the following definitions: \textit{\textbf{content}} refers to the task-related information provided in an ICL example, including the system instruction and the demonstration, \textit{\textbf{style}} represents the writing style of task-related information and the organizational structure of the content, and \textit{\textbf{alignment}} refers to the alignment effect exhibited by the model after using a particular example as a ICL demonstration.

We consider \textit{\textbf{style}} and \textit{\textbf{content}} to be the two most critical factors in applying ICL techniques for alignment tuning. 
We model $S$ (\textit{style}), $C$ (\textit{content}), and $A$ (\textit{alignment}) as a \textit{\textbf{causal structure}}~\citep{pearl2009causality}, as illustrated in Figure~\ref{fig:causal_structure}. 
The variable $C$ is the co-founder, which influences both $S$ and $A$. Both $C$ and $S$ jointly influence \textit{alignment}.

\begin{wrapfigure}{r}{3.5cm}
    \centering
    \vspace{-17pt}
    \includegraphics[width=0.25\columnwidth]{latex/figure/causal_structure_with_cross.png}
    \caption{The causal structure of style, content, and alignment.}
    \vspace{-10pt}
    \label{fig:causal_structure}
\end{wrapfigure}

\paragraph{Content}
We consider $C$ as a factor that cannot be experimentally manipulated. 
On the one hand, using LLMs to modify the content of an LLM’s response can lead to hallucinations, making the study uncontrollable. 
On the other hand, altering the content changes the nature of the demonstration, thus losing the significance of the research. 
Therefore, our primary interest lies in the impact of the intervenable factor $S$ on $A$, and we thus disregard the influence of $C$ on $A$, focusing instead on evaluating the effect of the controllable intervention $S$.

\paragraph{Style}
To quantify the impact of an intervention on an outcome of interest, the Average Treatment Effect (ATE) is a commonly used method in causal inference~\citep{kaddour2021causal,DBLP:conf/iclr/MahajanMNS24}.
Therefore, we use ATE as the expected difference in outcomes to determine, on average, how much effect the intervention has compared to other interventions.

% We thus examine the \textit{style} factor. 
Specifically, following the principles of causality, we consider setting $S$ to a fixed value as an intervention, denoted using the $do$-operator: $do(S=s)$\footnote{Which can also be shortened to $do(s)$.}.
Whenever $do(s)$ appears after the conditioning bar, it means that everything in that expression is in the \textit{post-intervention} world where the intervention $do(s)$ occurs.

It is important to note that, in Figure~\ref{fig:causal_structure}, there is an edge from $C$ to $S$, indicating that $C$ confounds the effect of $S$ on $A$. 
However, according to the definition in causal theory, $do(s)$ will remove the edge from $C$ to $S$ when intervening on $S$, meaning that $C$ will no longer affect $S$, as indicated by the red cross in the figure.

Thus, $E(A|do(S=s))$ refers to the expected alignment improvement after all examples have been restyled using the format $s$. According to the backdoor criterion, we obtain:
\begin{align}
E[A | do(S = s)] = \sum_{c} E[A | s, C = c] p(c)
\end{align}
The ATE is defined as:
\begin{align}
ATE(s_t, s_o) = E[A | do(S = s_t)] - E[A | do(S = s_o)]
\label{equ:ATE}
\end{align}
where $s_t$ refers to target style, and $s_o$ denotes other style.

Empirically, we adopted the idea of Monte Carlo sampling~\citep{knaus2021machine} and approximate $p(c)$ as a uniform distribution.
We used a single example as the ICL demonstration, enabling the LLM to handle downstream tasks through one-shot online learning. 
To calculate the expectation $E[A | s, C = c]$, we kept the content of the ICL demonstration fixed ($C=c$), while restyling the demonstration example with a specific style $s$.
The restyled demonstration example is then encapsulated in the prompt and fed to the LLM, which processes examples from the validation dataset via ICL. 
We considered the LLM’s average alignment performance on the validation dataset as an approximation of $E[A | s, C = c]$. %\reza{how is the restyling of an example done? by another LLM? Manually? How accurate is it? etc}


Based on the concept of Monte Carlo sampling, we randomly selected $N$ ICL demonstrations\footnote{To reduce computational complexity, we set $N$ to $5$.} from the candidate high-quality ICL examples to form the set $\{C\}$. 
Corresponding to the $N$ demonstrations in $\{C\}$, we applied the same restyle process to each, resulting in $N$ average alignment performance values. 
By averaging these $N$ values, we obtain an approximation of $E[A \mid do(S = s)]$, where $c \in \{C\}$ and $p(c)$ follows a uniform distribution.
It is worthy noting that in Section~\ref{section3}, we found LLMs exhibit conflicting behavior when handling ``\textit{factuality}'' and ``\textit{safety}'' sub-tasks.
In such cases, the LLM needs to achieve a trade-off between these two capabilities to mitigate the conflict. 
Therefore, we randomly selected a set $\{C_f\}$ from $\{S_\text{cand\_f}\}$ (defined in Section~\ref{section3}), focusing on ``\textit{factuality}'', and a set $\{C_s\}$ from $\{S_\text{cand\_s}\}$ (defined in Section~\ref{section3}), focusing on ``\textit{safety}'', and applied the same style restyling to each.

% todo: \reza{can you include the detailed prompts for the LLm-based restyling in the appendix?} 
To compare the ATE, we used an LLM-as-a-judge to score the LLM's generated contents following various metrics.
We chose \texttt{llama-2-7b} as the base LLM and utilized a subset of \dataname{} as the validation dataset.

By analyzing the ATE results, we have the following findings: (1) for factuality-related ICL demonstration examples, we should adopt the ``combined'' style; (2) for safety demonstrations, the ``refusal'' style should be used; (3) the differing emphases of the factuality and safety subtasks on various styles validate our findings in Section~\ref{section3}, RQ2, namely, that to achieve optimal overall performance in an LLM, a trade-off between factuality and safety must be reached.
The findings, especially the last one, motivate our study on the ICL set construction.