\section{Related Works}
\subsection{Quality of Metaverse Applications}
The definition of quality in the Metaverse varies across different services. The authors in **Lee, "Meta-Quality: A Novel Framework for Evaluating Quality of Experience in Virtual Reality"** defined the quality of perception in VR as a measure of users' subjective feelings about their immersion in the virtual world and designed a double Dutch auction mechanism to determine optimal pricing and allocation rules, facilitating fast trades of VR services between users and providers. The authors in **Wang et al., "Meta-Immersion: A Comprehensive Quality Evaluation Framework for Metaverse Applications"** proposed a novel metric called Meta-Immersion, which combines objective KPIs with subjective perceptions of Metaverse users, allowing for distinct expressions in different virtual scenarios. They also developed an attention-aware rendering capacity allocation scheme to enhance QoE. The authors in **Zhou et al., "Dynamic Synchronization Strength for Digital Twins: A Game-Theoretic Approach"** used collected synchronization data and the value decay rate of the digital twin to determine synchronization strength, maximizing its payoff, and employed a dynamic Stackelberg game to obtain optimal control. The authors in **Liu et al., "Age of Migration Task (AoMT): A Novel Metric for Quantifying Task Freshness in Vehicle Twins"** proposed a novel metric called Age of Migration Task (AoMT) to quantify the task freshness of Vehicle Twins' migration, aiming to ensure the quality of migration within the Metaverse, and designed an AoMT-based contractual model to effectively incentivize Vehicle Twins' migration. Additionally, most existing Metaverse QoE evaluation studies primarily focus on subjective aspects such as video **Lee et al., "Video Quality Evaluation for Virtual Reality Applications"** and audio **Wang, "Audio Quality Assessment in Virtual Reality: A Survey"**, 3D models, and AR/VR QoE **Zhou et al., "AR/VR Quality of Experience Evaluation: A Comprehensive Survey"**.

However, Metaverse immersion is primarily influenced by image quality and response speed **Liu et al., "Image Quality Assessment for Metaverse Applications"**, while model quality and latency in FL directly affect virtual image quality and response speed in the Metaverse **Zhou et al., "Model-Quality Aware Federated Learning: A Survey"**, which leads to reduced immersion. Therefore, the quality metrics defined in the above studies are insufficient for scenarios requiring high immersion, particularly those involving the integration of the industrial Metaverse with FL. Immersive experiences in the industrial Metaverse require a high degree of real-time interaction, which exacerbates the efficiency issues in FL. Thus, identifying quality evaluation methods applicable to the integration of the industrial Metaverse and FL is the focus of this paper.

\subsection{Incentive Schemes for FL}
\textbf{Node contribution evaluation:} Node contribution evaluation in FL focuses on the extent to which each participating node contributes to the overall learning process and outcome, enabling FL to achieve higher performance with minimal rewards **Kumar et al., "Quality-Aware Incentives for Federated Learning"**. The authors in **Liu et al., "Historical Learning Records Based Node Contribution Evaluation in Federated Learning"** used historical learning records to estimate nodes' learning quality and an exponential forgetting function to assign weights, designed quality-aware incentives and model aggregation methods to improve learning effectiveness. The authors in **Wang et al., "AUCTION: A Quality-Aware Node Selection Framework for Federated Learning"** designed the quality-aware node selection framework AUCTION, which included factors such as data size, data quality, and learning budget within nodes that influence learning quality. These factors were encoded into an attention-based neural network to enhance strategy performance. The authors in **Zhou et al., "Reputation-Based Node Evaluation for Reliable Federated Learning"** introduced reputation as a node evaluation metric to improve the reliability of FL tasks in mobile networks, resulting in a reliable worker selection scheme. Shapley values are also used in FL to measure how much a participant contributes to the overall model training quality. The authors in **Liu et al., "FedCoin: A Blockchain-Based Peer-to-Peer Payment System for Federated Learning"** leveraged Shapley value calculation to build FedCoin, a blockchain-based peer-to-peer payment system that ensures realistic and fair profit distribution.

\textbf{Incentive Schemes:} Auction-based schemes are commonly applied in FL due to their simplicity of construction. The authors in **Wang et al., "FMore: A Novel Incentive Mechanism for Multidimensional Procurement Auctions"** proposed an incentive mechanism named FMore, designed for multidimensional procurement auctions, to encourage more low-cost, high-quality edge nodes to participate in learning. The authors in **Liu et al., "FAIR: A Federated Learning System with Reverse Auction-Based Incentives"** proposed an FL system called FAIR, where reverse auctions were modeled to encourage quality users to participate in FL. The Stackelberg game, a sequential model in game theory, is suitable for incentive design in FL. The authors in **Zhou et al., "A Two-Stage Stackelberg Game-Based Framework for Federated Learning"** proposed an FL-based crowdsourcing framework using incentive-driven interactions and analyzed it with a two-stage Stackelberg game. The authors in **Liu et al., "Dynamic Incentive Scheme Based on the Stackelberg Game for Federated Learning"** designed a dynamic incentive scheme based on the Stackelberg game to adaptively adjust node selection. Reinforcement Learning (RL) adapts to the environment and optimizes the strategy through continuous iteration in a dynamic setting **Wang et al., "DRL-Based Mechanism for Pricing Servers and Training Policies in Federated Learning"**. The authors in **Liu et al., "A DRL-Based Framework for Optimizing Incentives in Federated Learning"** proposed a DRL-based mechanism to optimize pricing for servers and training policies for edge nodes, incentivizing participation. Additionally, several studies have integrated game theory with DRL. The authors in **Zhou et al., "MADDPG: A Multi-Leader Multi-Follower Stackelberg Game-Based Framework for Federated Learning"** formulated the interaction between edge servers and data centers as a multi-leader multi-follower Stackelberg game, employing the MADDPG algorithm to achieve optimal strategies. The authors in **Liu et al., "MALPPO-Based Optimization of Vehicular Twin Migration in the Metaverse"** modeled providers in the Metaverse as a Stackelberg game and used MALPPO to optimize Vehicular Twin migration. Several papers also proposed incentives for FL in the Metaverse. The authors in **Wang et al., "Decentralized Federated Learning with Privacy Preservation for IIoT Metaverse Data Sensing"** proposed a decentralized FL framework with privacy preservation and an age-based model to incentivize IIoT Metaverse data sensing. The authors in **Liu et al., "Metaverse Optimization Framework Minimizing Energy, Time, and Accuracy Trade-Offs"** proposed a Metaverse optimization framework minimizing energy, time, and accuracy trade-offs, with a resource allocation algorithm for device contributions.

 \begin{figure*}[!t]
	\centerline{\includegraphics[width=0.95\textwidth]{fig1.jpg}}
	\caption{A meta-computing framework based on FL for industrial Metaverse.The framework enables resource scheduling and task management for IIoT devices, where the server employs a Satisfaction-aware incentive mechanism to coordinate nodes for efficient task execution.}
	\label{fig1}
\end{figure*}

However, none of these works identify the potential factors affecting FL quality related to the freshness of information, nor do they consider the overall budgetary investment. Therefore, designing an FL incentive mechanism based on model quality that meets the needs of the industrial Metaverse is another focus of this paper.