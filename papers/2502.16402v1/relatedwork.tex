\section{Literature Review}
\subsection{The development of large language models}
In recent years, large language models (LLMs) have made significant advancements in the field of natural language processing (NLP). These models, built on the Transformer architecture, exhibit powerful language understanding and generation capabilities through large-scale parameterization and extensive data training. The Transformer model, first proposed by Vaswani et al. \cite{NIPS2017_3f5ee243}, overcame the limitations of traditional recurrent neural networks (RNNs) \cite{ELMAN1990179} and long short-term memory networks (LSTMs) \cite{6795963} in parallel processing and long-range dependency handling. Its core self-attention mechanism efficiently captures long-distance dependencies within sequences while preserving sequential order through positional encoding, laying the theoretical and technical foundation for subsequent pre-trained language models.

With the widespread adoption of the Transformer architecture, pre-trained language models have become a focal point in NLP research. BERT \cite{devlin-etal-2019-bert} introduced a bidirectional encoder and the masked language modeling (MLM) objective, significantly enhancing language understanding and establishing the pre-training and fine-tuning paradigm. OpenAI released the GPT series, which adopted an autoregressive language modeling approach and demonstrated exceptional performance in text generation tasks through left-to-right sequential generation. Notably, GPT-3, with 175 billion parameters, emerged as the largest language model at the time, showcasing remarkable zero-shot and few-shot learning capabilities. Subsequently, models such as Google PaLM \cite{chowdhery2023palm}, Alibaba Qwen \cite{ZHU2025}, and Meta LLaMA \cite{LI2025110382} demonstrated unprecedented performance in language understanding and generation tasks.

The rapid development of LLMs has revealed emergent abilities \cite{wei2022emergent,10.5555/3600270.3602070}, which refer to the unexpected capabilities models exhibit upon reaching a critical parameter size. These abilities encompass tasks such as language generation \cite{10.5555/3524938.3525989}, complex reasoning \cite{10.5555/3600270.3602070}, multilingual translation \cite{aharoni-etal-2019-massively}, and code generation \cite{feng-etal-2020-codebert}. Contextual learning \cite{lu-etal-2024-emergent} has become a hallmark of LLMs, enabling them to quickly adapt to new tasks with minimal contextual samples, thereby reducing the need for extensive labeled data. Instruction following allows models to execute complex tasks based on explicit natural language instructions, significantly improving capabilities from text generation to multi-turn dialogue generation. Chain-of-thought reasoning, guiding models to perform step-by-step reasoning, enhances decision-making and problem-solving abilities in complex tasks. The emergence of these abilities has expanded the practical applications of LLMs and opened new avenues for exploring model capability mechanisms. Brown et al. \cite{NEURIPS2020_1457c0d6} demonstrated that increasing model size significantly improves task generalization, prompting researchers to investigate the relationship between model size, data diversity, and emergent abilities, offering new theoretical perspectives for model optimization.



In terms of training methods, LLM optimization has undergone several key evolutions. Core methods in the pre-training phase include self-supervised learning, where models learn language patterns and semantic features from unlabeled data by predicting masked or next words \cite{SU2024127063}. This approach avoids reliance on extensive labeled datasets, enabling efficient training on large corpora. To enhance task-specific adaptability, the fine-tuning phase employs supervised learning for parameter updates. Recently, reinforcement learning from human feedback (RLHF) \cite{lang-etal-2024-fine} has become a crucial strategy to improve model performance by optimizing outputs based on human feedback, aligning them better with user expectations. OpenAI developed InstructGPT \cite{NEURIPS2022_b1efde53} using this approach to achieve better user interaction. Lightweight fine-tuning techniques such as LoRA have significantly reduced computational costs, providing greater flexibility for real-world applications. Contrastive learning \cite{cheng-etal-2023-improving}, which maximizes similarities between positive pairs and minimizes those between negative pairs, enhances feature representation capabilities, leading to improved performance in text embedding tasks and a better understanding of complex semantics. Meta-learning further expands the ability of the model to perform well in low-resource environments by learning "how to learn", thereby reducing dependence on large-scale labeled datasets \cite{finn2017model}. Gradient accumulation and clipping techniques have facilitated efficient large-scale model training under memory constraints while preventing gradient explosion, enhancing training stability \cite{NEURIPS2023_8249b30d}.



The latest LLM DeepSeek-R1 represents a groundbreaking milestone \cite{deepseekai2025deepseekr1incentivizingreasoningcapability}. Unlike traditional supervised fine-tuning (SFT) \cite{wei2022finetuned} approaches, DeepSeek-R1 employs large-scale reinforcement learning (RL) through group relative policy optimization (GRPO) \cite{deepseek-math} for base model training, significantly reducing computational costs. Before RL training, the model integrates multi-stage training and cold-start data. Experiments show that DeepSeek-R1, directly fine-tuned with large-scale RL, outperforms state-of-the-art models such as OpenAI-o1-1217 and OpenAI-o1-0912 on benchmarks such as AIME 2024 and MATH-500. On the CodeForces benchmark, it scores only 0.3\% lower than OpenAI-o1-1217. DeepSeek-R1 demonstrates that a purely RL-based approach can significantly enhance the reasoning capabilities of low-density models, showcasing robust self-verification and reflective functions, marking a significant milestone for research in this field.

\subsection{Advanced tasks based on large language models}
LLMs have demonstrated transformative potential across various fields due to their unique capabilities in reasoning, data integration, and context understanding. Notably, in autonomous robotics, LLMs show great promise, particularly in dynamic and safety-critical environments. They can interpret complex sensory information and make environment-aware decisions, advancing autonomous decision-making technologies. Hu et al. \cite{chen2024robogpt} proposed the RoboGPT framework, which optimizes warehouse operations by integrating semantic mapping and adaptive task scheduling, reducing task completion time in dynamic environments. Zhou et al. \cite{10.1007/978-3-031-72667-5_15} developed NavGPT, a navigation assistance system designed for embedded robots. This system utilizes real-time sensor data and multimodal reasoning to achieve efficient obstacle avoidance in unstructured environments. Christos et al. \cite{GKOURNELOS20249} advanced collaborative robotics by designing a framework tailored for team tasks in industrial settings. By incorporating LLMs, the framework enhances communication efficiency and task execution among multiple robots.

In the field of autonomous driving, Liao et al. \cite{LIAO2024100116} proposed the context-aware visual grounding (CAVG) framework, which integrates five core encoders and a multimodal decoder to enhance the ability of autonomous vehicles to interpret the correlation between linguistic commands and visual scenes. Jin et al. \cite{JIN2024105940} developed a government-level framework integrating an LLM to assist urban planners in efficiently evaluating and optimizing parking facilities during the transition period of coexistence between autonomous vehicles and human-driven vehicles.  Alsaif et al. \cite{electronics13244912} focused on industrial equipment, proposing a solution that analyzes multimodal operational data for real-time fault detection and predictive maintenance, crucial for ensuring the long-term stable operation of autonomous vehicles. The system also generates actionable insights to help manufacturers plan maintenance activities in advance, reducing unexpected downtime. 

In summary, LLMs, with human-like reasoning and strong contextual understanding, can perform complex tasks such as autonomous navigation and safety detection. Therefore, integrating LLMs into navigation and collision avoidance is entirely feasible. 

Despite the rapid advancements in the aforementioned general-purpose LLMs, which exhibit strong performance in non-predefined scenarios, significant challenges persist in their application within specialized domains, particularly in the maritime field. Firstly, the maritime domain encompasses a wide range of professional sensors and computational rules that are difficult for general-purpose LLMs to interpret directly. Secondly, the pervasive issue of model hallucinations in LLMs may result in unforeseen and potentially adverse outcomes. Lastly, there is a notable absence of systematic research addressing the integration of rule compliance into LLM outputs, specifically ensuring that decisions adhere to established navigation regulations-a challenge often referred to as the "rule embedding" problem.