%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
\documentclass[manuscript,screen]{acmart}
%\documentclass[acmsmall,screen,review,anonymous]{acmart}
%anonymous,
%authorversion


%%%%%%%%%%%%%%%%% Commands file %%%%%%%%%%%%%%%%%
%\input{commands.tex}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{setspace}
%\usepackage[pdftex]{graphicx}
\usepackage{graphicx}
\graphicspath{ {./figures/} }
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{lineno}
\usepackage{paralist}
\usepackage{xspace} 
\usepackage{tcolorbox}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{url} 
\usepackage{bm}
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{todonotes}
\usepackage{accents}
\usepackage{mathtools}
\usepackage{longtable}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage{pdflscape}
\usepackage{color}
\usepackage{float}
\usepackage{array}
\usepackage{tabto}
\usepackage{diagbox}
\usepackage{makecell}
\usepackage{mfirstuc}
\usepackage{boldline}
\usepackage{enumitem}
\usepackage{realboxes}
\usepackage{tabularx}

\newcommand{\cmnt}[1]{\textcolor{red}{\textbf{[#1]}}}

%% Tables aligenment
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

%% Algopseudocode commands
\algdef{SE}{Begin}{End}{\textbf{begin}}{\textbf{end}}

%% Mathmode commands
\newcommand{\pvec}[1]{\vec{#1}\mkern2mu\vphantom{#1}}
\makeatletter
\renewenvironment{cases}[1][\lbrace]{%
	\def\@ldelim{#1}
	\matrix@check\cases\env@cases
}{%
	\endarray\right.%
}
\patchcmd{\env@cases}{\lbrace}{\@ldelim}{}{}
\makeatother

\DeclareUnicodeCharacter{0301}{\'{e}}
\DeclareUnicodeCharacter{0308}{\"{i}}

%commonly used terms
\newcommand{\mh}{metaheuristic\xspace}
\newcommand{\mhs}{metaheuristics\xspace}
\newcommand{\Mh}{Metaheuristic\xspace}
\newcommand{\LS}{LS\xspace}
\newcommand{\Ls}{Local search\xspace}
\newcommand{\ls}{local search\xspace}
\newcommand{\Mhs}{Metaheuristics\xspace}
\newcommand{\pbmh}{population-based \mh}
\newcommand{\Pbmh}{Population-based \mh}
\newcommand{\pbmhs}{population-based \mhs}
\newcommand{\Pbmhs}{Population-based \mhs}
\newcommand{\PBMHs}{PBMHs\xspace}
\newcommand{\PBMH}{PBMH\xspace}
\newcommand{\op}{optimization problem\xspace}
\newcommand{\ops}{optimization problems\xspace}
\newcommand{\Op}{Optimization problem\xspace}
\newcommand{\Ops}{Optimization problems\xspace}
\newcommand{\cop}{continuous \op}
\newcommand{\cops}{continuous \ops}
\newcommand{\Cop}{Continuous \op}
\newcommand{\Cops}{Continuous \ops}
\newcommand{\Ad}{Automatic design\xspace}
\newcommand{\ad}{automatic design\xspace}
\newcommand{\aacts}{automatic algorithm configuration tools\xspace}
\newcommand{\aact}{automatic algorithm configuration tool\xspace}
\newcommand{\Aact}{Automatic algorithm configuration tool\xspace}
\newcommand{\Aacts}{Automatic algorithm configuration tools\xspace}
\newcommand{\AACT}{AACT\xspace}
\newcommand{\Msf}{\Mh software framework\xspace}
\newcommand{\msf}{\mh software framework\xspace}
\newcommand{\Msfs}{\Mh software frameworks\xspace}
\newcommand{\msfs}{\mh software frameworks\xspace}
\newcommand{\MSFall}{\Mh Software Framework\xspace}
\newcommand{\MSF}{MSF\xspace}
\newcommand{\MSFs}{MSFs\xspace}

% commonly used words
\newcommand{\Tbl}{Table\xspace}
\newcommand{\Tbls}{Tables\xspace}
\newcommand{\Alg}{Algorithm\xspace}
\newcommand{\Algs}{Algorithms\xspace}
\newcommand{\Sect}{Section\xspace}
\newcommand{\Sects}{Sections\xspace}
\newcommand{\Eq}{Equation\xspace}
\newcommand{\Eqs}{Equation\xspace}
\newcommand{\etal}{\textit{et al.}\xspace}

%% Frameworks, theory and tools
\newcommand{\PaEO}{ParadisEO\xspace}
\newcommand{\Hl}{HeuristicLab\xspace}
\newcommand{\NFL}{No-Free-Lunch\xspace}
\newcommand{\PSOX}{PSO\textsl{-X}\xspace}
\newcommand{\irace}{\texttt{irace}\xspace}
\newcommand{\aCMAES}{autoCMAES\xspace}
\newcommand{\aDE}{autoDE\xspace}
\newcommand{\modPSODE}{modPSODE\xspace}

%% Metaheuristics
\newcommand{\Aco}{Ant colony optimization\xspace}
\newcommand{\ACOall}{Ant Colony Optimization\xspace}
\newcommand{\aco}{ant colony optimization\xspace}
\newcommand{\ACO}{ACO\xspace}
\newcommand{\Pso}{Particle swarm optimization\xspace}
\newcommand{\PSOall}{Particle Swarm Optimization\xspace}
\newcommand{\pso}{particle swarm optimization\xspace}
\newcommand{\PSO}{PSO\xspace}
\newcommand{\Abc}{Artificial bee colony\xspace}
\newcommand{\ABCall}{Artificial Bee Colony\xspace}
\newcommand{\abc}{artificial bee colony\xspace}
\newcommand{\ABC}{ABC\xspace}
\newcommand{\Ec}{Evolutionary computation\xspace}
\newcommand{\ECall}{Evolutionary Computation\xspace}
\newcommand{\Ea}{Evolutionary algorithm\xspace}
\newcommand{\EA}{EA\xspace}
\newcommand{\EAall}{Evolutionary Algorithm\xspace}
\newcommand{\Eas}{Evolutionary algorithms\xspace}
\newcommand{\EAs}{EAs\xspace}
\newcommand{\EAsall}{Evolutionary Algorithms\xspace}
\newcommand{\ec}{evolutionary computation\xspace}
\newcommand{\EC}{EC\xspace}
\newcommand{\Es}{Evolution strategy\xspace}
\newcommand{\ESall}{Evolution Strategy\xspace}
\newcommand{\es}{evolution strategy\xspace}
\newcommand{\ES}{ES\xspace}
\newcommand{\Ess}{Evolution strategies\xspace}
\newcommand{\ESSall}{Evolution Strategies\xspace}
\newcommand{\ess}{evolution strategies\xspace}
\newcommand{\ESs}{ESs\xspace}
\newcommand{\Ga}{Genetic algorithm\xspace}
\newcommand{\GAall}{Genetic Algorithms\xspace}
\newcommand{\ga}{genetic algorithms\xspace}
\newcommand{\GA}{GA\xspace}
\newcommand{\Gas}{Genetic algorithms\xspace}
\newcommand{\GASall}{Genetic Algorithms\xspace}
\newcommand{\gas}{genetic algorithms\xspace}
\newcommand{\GAs}{GAs\xspace}
\newcommand{\Sa}{Simulated annealing\xspace}
\newcommand{\SAall}{Simulated Annealing\xspace}
\newcommand{\sa}{simulated annealing\xspace}
\newcommand{\SA}{SA\xspace}
\newcommand{\Si}{Swarm intelligence\xspace}
\newcommand{\SIall}{Swarm Intelligence\xspace}
\newcommand{\ssii}{swarm intelligence\xspace}
\newcommand{\SSII}{SI\xspace}
\newcommand{\De}{Differential evolution\xspace}
\newcommand{\DEall}{Differential Evolution\xspace}
\newcommand{\de}{differential evolution\xspace}
\newcommand{\DE}{DE\xspace}
\newcommand{\CMAESall}{Covariance Matrix Adaptation--\ESall}
\newcommand{\cmaES}{Covariance Matrix Adaptation--\ES}
\newcommand{\cmaes}{covariance matrix adaptation--\ES}
\newcommand{\CMAES}{CMA--\ES}
\newcommand{\mtsls}{multiple trajectory search \ls}
\newcommand{\Mtsls}{Multiple trajectory search \ls}
\newcommand{\MTSLS}{MTS\textsf{ls}\xspace}

%% ACO algorithms
\newcommand{\acoBook}{\emph{Ant Colony Optimization} book\xspace}

%% PSO
\newcommand{\stanPSO}{standard \PSO}
\newcommand{\StanPSO}{Standard \PSO}
\newcommand{\SPSO}{Sta\PSO}
%\newcommand{\VelClp}{\textsf{velocity clamping}\xspace}
\newcommand{\PsoParam}{$\omega$, $\varphi_1$ and $\varphi_2$\xspace}
\newcommand{\PsoMatrices}{$U^i_{1t}$ and $U^i_{2t}$\xspace}

%% "novel" metaheurstics
\newcommand{\StdPSO}{StdPSO\xspace}
\newcommand{\SPSOClr}{SPSO-2011\xspace}%%CHANGE IN PSO-X PAPER: \SPSO to \SPSOClr
\newcommand{\FiPSO}{FiPSO\xspace}
\newcommand{\GauPSO}{GauPSO\xspace}
\newcommand{\SDPSs}{SDPSs\xspace}
\newcommand{\RiPSO}{RiPSO\xspace}
\newcommand{\ePSO}{$e$PSO\xspace}
\newcommand{\rPSO}{PSO$_{rank}$\xspace}
\newcommand{\GWO}{GWO\xspace}
\newcommand{\Gwo}{Grey wolf optimizer\xspace}
\newcommand{\GwoAll}{Grey Wolf Optimizer\xspace}
\newcommand{\gwo}{grey wolf optimizer\xspace}
\newcommand{\WOA}{WOA\xspace}
\newcommand{\Woa}{Whale optimization algorithm\xspace}
\newcommand{\WoaAll}{Whale Optimization Algorithm\xspace}
\newcommand{\woa}{whale optimization algorithm\xspace}
\newcommand{\FA}{FA\xspace}
\newcommand{\Fa}{Firefly algorithm\xspace}
\newcommand{\FaAll}{Firefly Algorithm\xspace}
\newcommand{\fa}{firefly algorithm\xspace}
\newcommand{\MF}{MFA\xspace}
\newcommand{\Mf}{Moth-flame algorithm\xspace}
\newcommand{\MfAll}{Moth-Flame Algorithm\xspace}
\newcommand{\mf}{moth-flame algorithm\xspace}
\newcommand{\ALO}{ALO\xspace}
\newcommand{\Alo}{Antlion optimizer\xspace}
\newcommand{\AloAll}{Antlion Optimizer\xspace}
\newcommand{\alo}{antlion optimizer\xspace}
\newcommand{\BA}{BA\xspace}
\newcommand{\Ba}{Bat algorithm\xspace}
\newcommand{\BaAll}{Bat Algorithm\xspace}
\newcommand{\ba}{bat algorithm\xspace}
\newcommand{\CS}{CS\xspace}
\newcommand{\Cs}{Cuckoo search\xspace}
\newcommand{\CsAll}{Cuckoo Search\xspace}
\newcommand{\cs}{cuckoo search\xspace}
\newcommand{\criterionOne}{$\texttt{Random\_Neighbor}$}
\newcommand{\criterionTwo}{$\texttt{Exp\_Coefficient}$}
\newcommand{\generate}{$\texttt{Generate}$}
\newcommand{\accept}{$\texttt{Accept}$}

%%%%%%%%%%%%% PSO-X paper %%%%%%%%%%%%%%%
%% Algorithm components
\newcommand{\Topo}{{\textsf{Topology}}\xspace}
\newcommand{\Moi}{{\textsf{Model of influence}}\xspace}
\newcommand{\Pop}{{\textsf{Population}}\xspace}
\newcommand{\Init}{{\textsf{Initialization}}\xspace}
\newcommand{\DNPP}{{\textsf{DNPP}}\xspace}
\newcommand{\PertRnd}{{\textsf{Pert$_{\mathrm{\textsf{rand}}}$}}\xspace}
\newcommand{\PertInf}{{\textsf{Pert$_{\mathrm{\textsf{info}}}$}}\xspace}
\newcommand{\Mtx}{{\textsf{Mtx}}\xspace}
\newcommand{\none}{{\textsf{none}}\xspace}
%% Population options
\newcommand{\PopConst}{{\textsf{Pop-constant}}\xspace}
\newcommand{\PopIncre}{{\textsf{Pop-incremental}}\xspace}
\newcommand{\PopTV}{{\textsf{Pop-time-varying}}\xspace}
%% Population init type
\newcommand{\InitRandom}{{\textsf{Init-random}}\xspace}
\newcommand{\InitHorizontal}{{\textsf{Init-horizontal}}\xspace}
%% DNPP options
\newcommand{\DNPPRect}{{\textsf{DNPP-rectangular}}\xspace}
\newcommand{\DNPPSphe}{{\textsf{DNPP-spherical}}\xspace}
\newcommand{\DNPPAddStoch}{{\textsf{DNPP-additive stochastic}}\xspace}
%% Additive stochastic options
\newcommand{\OperatorS}{{\textsf{DNPP-standard}}\xspace}
\newcommand{\OperatorD}{{\textsf{DNPP-discrete}}\xspace}
\newcommand{\OperatorN}{{\textsf{DNPP-Gaussian}}\xspace}
\newcommand{\OperatorCG}{{\textsf{DNPP-Cauchy--Gaussian}}\xspace}
\newcommand{\OperatorQrandNeigh}{$\textsf{random\_neighbor}$\xspace}
%% Informed perturbation options
\newcommand{\PertNone}{{\textsf{none}}\xspace}
\newcommand{\PertGau}{{\textsf{\PertInf-Gaussian}}\xspace}
\newcommand{\PertLev}{{\textsf{\PertInf-L{\'e}vy}}\xspace}
\newcommand{\PertUni}{{\textsf{\PertInf-uniform}}\xspace}
%% Additive perturbation options 
\newcommand{\PertRect}{{\textsf{\PertRnd-rectangular}}\xspace}
\newcommand{\PertNoi}{{\textsf{\PertRnd-noisy}}\xspace}
%% Magnitude options
\newcommand{\MagCons}{{\textsf{PM-constant value}}\xspace}
\newcommand{\MagEucli}{{\textsf{PM-Euclidean distance}}\xspace}
\newcommand{\MagOFd}{{\textsf{PM-obj.func. distance}}\xspace}
\newcommand{\MagSucc}{{\textsf{PM-success rate}}\xspace}
%% Matrix options
\newcommand{\MtxNone}{{\textsf{none}}\xspace}
\newcommand{\MtxDiagonal}{{\textsf{\Mtx-random diagonal}}\xspace}
\newcommand{\MtxLinear}{{\textsf{\Mtx-random linear}}\xspace}
\newcommand{\MtxExponential}{{\textsf{\Mtx-exponential map}}\xspace}
\newcommand{\MtxEuclidean}{{\textsf{\Mtx-Euclidean rotation}}\xspace}
\newcommand{\MtxEuclideanOne}{{\textsf{\Mtx-Euclidean rotation$_{one}$}}\xspace}
\newcommand{\MtxEuclideanAll}{{\textsf{\Mtx-Euclidean rotation$_{all}$}}\xspace}
\newcommand{\MtxIncreasingGroupBased}{{\textsf{\Mtx-Increasing group-based}}\xspace}
%% Angle options
\newcommand{\AglConstant}{{\textsf{$\alpha$-constant}}\xspace}
\newcommand{\AglGaussian}{{\textsf{$\alpha$-Gaussian}}\xspace}
\newcommand{\AglAdaptive}{{\textsf{$\alpha$-adaptive}}\xspace}
%% Varphi options
\newcommand{\PhiConstant}{{\textsf{AC-constant}}\xspace}
\newcommand{\PhiRandom}{{\textsf{AC-random}}\xspace}
\newcommand{\PhiTV}{{\textsf{AC-time-varying}}\xspace}
\newcommand{\PhiExtra}{{\textsf{AC-extrapolated}}\xspace}
%% Model of influence options
\newcommand{\MoiBoN}{{\textsf{MoI-best-of-neighborhood}}\xspace}
\newcommand{\MoiFI}{{\textsf{MoI-fully informed}}\xspace}
\newcommand{\MoiRFI}{{\textsf{MoI-ranked fully informed}}\xspace}
\newcommand{\MoiRI}{{\textsf{MoI-random informant}}\xspace}
\newcommand{\MoiH}{{\textsf{MoI-hierarchical}}\xspace}
%% Topology options
\newcommand{\TopFC}{{\textsf{Top-fully-connected}}\xspace}
\newcommand{\TopRing}{{\textsf{Top-ring}}\xspace}
\newcommand{\TopWheel}{{\textsf{Top-wheel}}\xspace}
\newcommand{\TopRandom}{{\textsf{Top-random edge}}\xspace}
\newcommand{\TopNeum}{{\textsf{Top-Von Neumann}}\xspace}
\newcommand{\TopHie}{{\textsf{Top-hierarchical}}\xspace}
\newcommand{\TopTVFI}{{\textsf{Top-time-varying}}\xspace}
%%

%% Omega 1 options
\newcommand{\OmegaCons}{{\textsf{IW-constant}}\xspace}
\newcommand{\OmegaLinDec}{{\textsf{IW-linear decreasing}}\xspace}
\newcommand{\OmegaLinInc}{{\textsf{IW-linear increasing}}\xspace}
\newcommand{\OmegaRnd}{{\textsf{IW-random}}\xspace}
\newcommand{\OmegaSelfReg}{{\textsf{IW-self-regulating}}\xspace}
\newcommand{\OmegaAdapVel}{{\textsf{IW-adaptive based on velocity}}\xspace}
\newcommand{\OmegaDoubExp}{{\textsf{IW-double exponential self-adaptive}}\xspace}
\newcommand{\OmegaRnkBsd}{{\textsf{IW-rank-based}}\xspace}
\newcommand{\OmegaSuccBsd}{{\textsf{IW-success-based}}\xspace}
\newcommand{\OmegaConvBsd}{{\textsf{IW-convergence-based}}\xspace}
%% Independent strategies
\newcommand{\VelClp}{{\textsf{Velocity Clamping}}\xspace}
\newcommand{\StagDet}{{\textsf{Unstuck Velocity}}\xspace} 
\newcommand{\IgnPbest}{\textsf{Ignore Pbest}\xspace} 
%% Algorithms and variants name
\newcommand{\PSOXall}{\PSOX\unskip$_{\mathrm{\textit{all}}}$\xspace} %%CHANGE IN PSO-X PAPER  \PSOall to \PSOXall
\newcommand{\PSOhyb}{\PSOX\unskip$_{\mathrm{\textit{hyb}}}$\xspace}
\newcommand{\PSOmul}{\PSOX\unskip$_{\mathrm{\textit{mul}}}$\xspace}
\newcommand{\PSOuni}{\PSOX\unskip$_{\mathrm{\textit{uni}}}$\xspace}
\newcommand{\PSOcec}{\PSOX\unskip$_{\mathrm{\textit{cec}}}$\xspace}
\newcommand{\PSOsoco}{\PSOX\unskip$_{\mathrm{\textit{soco}}}$\xspace}

%%%%%%%%% CMAES algorithm components %%%%%%%%% 
%% Covariance matrix adaptation
\newcommand{\CMAESMtx}{{\textsf{CMAES-\Mtx}}\xspace} 
\newcommand{\CMAESMtxDia}{{\textsf{CMAES-\Mtx-diagonal}}\xspace} 
\newcommand{\CMAESMtxCov}{{\textsf{CMAES-\Mtx-covariance}}\xspace} 
\newcommand{\CMAESMtxCovDia}{{\textsf{CMAES-\Mtx-cov-then-diag}}\xspace} 
%% Population
\newcommand{\CMAESPop}{{\textsf{CMAES-population}}\xspace}
\newcommand{\CMAESPopConst}{{\textsf{CMAES-pop-constant}}\xspace}
\newcommand{\CMAESPopInc}{{\textsf{CMAES-pop-incremental}}\xspace}
%% Recombination weights
\newcommand{\CMAESRW}{{\textsf{CMAES-recombination-weights}}\xspace} 
\newcommand{\CMAESRWlog}{{\textsf{CMAES-RW-logarithmic}}\xspace} 
\newcommand{\CMAESRWlindec}{{\textsf{CMAES-RW-linear-decreasing}}\xspace} 
\newcommand{\CMAESRWeq}{{\textsf{CMAES-RW-equal}}\xspace} 
%% Restart
\newcommand{\CMAESRes}{{\textsf{CMAES-restart}}\xspace}
%% Parameters
\newcommand{\CMAESpara}{{\textsf{cmaes\_par\_a}}\xspace} 
\newcommand{\CMAESparb}{{\textsf{cmaes\_par\_b}}\xspace} 
\newcommand{\CMAESparc}{{\textsf{cmaes\_par\_c}}\xspace} 
\newcommand{\CMAESpard}{{\textsf{cmaes\_par\_d}}\xspace} 
\newcommand{\CMAESpare}{{\textsf{cmaes\_par\_e}}\xspace} 
\newcommand{\CMAESparf}{{\textsf{cmaes\_par\_f}}\xspace} 
\newcommand{\CMAESparg}{{\textsf{cmaes\_par\_g}}\xspace} 

%%%%%%%%% DE algorithm components %%%%%%%%%
%% Base vector
\newcommand{\DEBaseVect}{{\textsf{DE-Base Vector}}\xspace}
\newcommand{\DEBVcomp}{{\textsf{BV}}\xspace}
\newcommand{\DEBVrand}{{\textsf{BV-random}}\xspace}
\newcommand{\DEBVbest}{{\textsf{BV-best}}\xspace}
\newcommand{\DEBVttbest}{{\textsf{BV-target-to-best}}\xspace}
\newcommand{\DEBVdirRand}{{\textsf{BV-directed-random}}\xspace}
\newcommand{\DEBVdirBest}{{\textsf{BV-directed-best}}\xspace}
%% Recombination
\newcommand{\DERcb}{{\textsf{DE-Recombination}}\xspace}
\newcommand{\DERcbcomp}{{\textsf{RCB}}\xspace}
\newcommand{\DERcbBinomial}{{\textsf{RCB-binomial}}\xspace}
\newcommand{\DERcbExponential}{{\textsf{RCB-exponential}}\xspace}

%% Vector to optimize
\newcommand{\DEVect}{{\textsf{DE-Vectors}}\xspace}
\newcommand{\DEVectPos}{{\textsf{V-positions}}\xspace}
\newcommand{\DEVectPbest}{{\textsf{V-pbest}}\xspace}
\newcommand{\DEVectMix}{{\textsf{V-mixture}}\xspace}

%% Velocity recomputation rule
\newcommand{\DERecompVel}{{\textsf{DE-Recompute Velocity}}\xspace}
\newcommand{\DERVnone}{{\textsf{RV-none}}\xspace}
\newcommand{\DERVgoBack}{{\textsf{RV-goBack}}\xspace}
\newcommand{\DERVrandom}{{\textsf{RV-random}}\xspace}
\newcommand{\DERVposition}{{\textsf{RV-position}}\xspace}

%% Integration with PSOmod
\newcommand{\PSOonFail}{{\textsf{PSO-only-on-fail}}\xspace}

%% Parameters
\newcommand{\DEVectDifferences}{{\textsf{DE-vector-differences}}\xspace}
\newcommand{\DECrossoverRate}{{\textsf{DE-crossover-rate}}\xspace}
\newcommand{\DEStepsize}{{\textsf{DE-step-size}}\xspace}

%%%%%%%%% Local search algorithm components %%%%%%%%% 
\newcommand{\LSbudget}{{\textsf{LS-budget}}\xspace}
\newcommand{\LSdivide}{{\textsf{LS-divide}}\xspace}
%% MTSLS
\newcommand{\MTSLSinitss}{{\textsf{MTSLS-init-ss}}\xspace}
\newcommand{\MTSLStriesPerDim}{{\textsf{MTSLS-tries-per-dim}}\xspace}
\newcommand{\MTSLSiterations}{{\textsf{MTSLS-iterations}}\xspace}
\newcommand{\MTSLSbias}{{\textsf{MTSLS-bias}}\xspace}

%%%%%%%%% General purpose algorithm components %%%%%%%%% 
\newcommand{\VectBasis}{{\textsf{Vector-Basis}}\xspace}
\newcommand{\VBcomp}{{\textsf{VB}}\xspace}
\newcommand{\VBeigen}{{\textsf{VB-eigenvector}}\xspace}
\newcommand{\VBnatural}{{\textsf{VB-natural}}\xspace}

\newcommand{\Reinit}{{\textsf{Re-initialization}}\xspace}
\newcommand{\RIchange}{{\textsf{RI-change}}\xspace}
\newcommand{\RIsimilarity}{{\textsf{RI-similarity}}\xspace}
\newcommand{\None}{{\textsf{none}}\xspace}

%% Metheuristics in the paper
\newcommand{\algInPaper}{\PSO, \CMAES and \DE}
\newcommand{\algInPaperLS}{\PSO, \CMAES, \DE and \LS algorithms\xspace}
\newcommand{\algInPaperHyb}{\PDHyb, \DCHyb and \PCHyb}
\newcommand{\MetafoR}{\textsf{\textbf{METAFO}}$\mathbb{R}$\xspace}
\newcommand{\PDHyb}{\PSO--\DE hybrid\xspace}
\newcommand{\PDHybs}{\PSO--\DE hybrids\xspace}
\newcommand{\DCHyb}{\DE--\CMAES hybrid\xspace}
\newcommand{\DCHybs}{\DE--\CMAES hybrids\xspace}
\newcommand{\PCHyb}{\PSO--\CMAES hybrid\xspace}
\newcommand{\PCHybs}{\PSO--\CMAES hybrids\xspace}
\newcommand{\MTF}{MTF\xspace}

%%%%%%%% For next versions of the frameworks %%%%%%%%%%
%\newcommand{\MetafoRX}{\textsf{\textbf{METAFO}}$\mathbb{R}-{\mathrm{\textsl{X}}}$\xspace}
%% METAFOR modules %%
\newcommand{\PSOmod}{{\textsf{\textbf{PSOmod}}}\xspace}
\newcommand{\DEmod}{{\textsf{\textbf{DEmod}}}\xspace}
\newcommand{\CMAESmod}{{\textsf{\textbf{CMA-ESmod}}}\xspace}
\newcommand{\LSmod}{{\textsf{\textbf{LSmod}}}\xspace}
\newcommand{\MetafoRModules}{\PSOmod, \DEmod and \CMAESmod}
\newcommand{\MetafoRModulesAlg}{\PSOmod, \DEmod, \CMAESmod, \LSmod}
\newcommand{\Execution}{{\textsf{Execution}}\xspace}
\newcommand{\ExecutionCB}{{\textsf{EXE-component-based}}\xspace}
\newcommand{\ExecutionPB}{{\textsf{EXE-probabilistic}}\xspace}
\newcommand{\ExecutionPBuni}{{\textsf{EXE-PB-uniform}}\xspace}
\newcommand{\ExecutionPBnor}{{\textsf{EXE-PB-normal}}\xspace}
\newcommand{\ExecutionPBlev}{{\textsf{EXE-PB-levy}}\xspace}
\newcommand{\ExecutionParStd}{$\textsf{par\_std}$\xspace}
\newcommand{\ExecutionMP}{{\textsf{EXE-multiple phases}}\xspace}
%% METAFOR components %%
\newcommand{\IWcomp}{{\textsf{IW}}\xspace}
\newcommand{\ACcomp}{{\textsf{AC}}\xspace}
\newcommand{\PMcomp}{{\textsf{PM}}\xspace}

%% Algorithms in the comparison
% Scenarios
\newcommand{\TFOUT}{{\texttt{25OUT}}\xspace}
\newcommand{\TFSLDO}{{\texttt{25SLDO}}\xspace}
\newcommand{\LDO}{{\texttt{LDOUT}}\xspace}
%Algorithms 25OUT 
\newcommand{\PSOtfo}{PSO-\textsl{X}$_{\TFOUT}$\xspace}
\newcommand{\DEtfo}{DE$_{\TFOUT}$\xspace}
\newcommand{\CMAEStfo}{CMAES$_{\TFOUT}$\xspace}
\newcommand{\PDHybtfo}{PSO--DE$_{\TFOUT}$\xspace}
\newcommand{\DCHybtfo}{DE--CMAES$_{\TFOUT}$\xspace}
\newcommand{\PCHybtfo}{PSO--CMAES$_{\TFOUT}$\xspace}
\newcommand{\MTFtfo}{MTF$_{\TFOUT}$\xspace}
%Algorithms LDO 
\newcommand{\PSOldo}{PSO-\textsl{X}$_{\LDO}$\xspace}
\newcommand{\DEldo}{DE$_{\LDO}$\xspace}
\newcommand{\CMAESldo}{CMAES$_{\LDO}$\xspace}
\newcommand{\PDHybldo}{PSO--DE$_{\LDO}$\xspace}
\newcommand{\DCHybldo}{DE--CMAES$_{\LDO}$\xspace}
\newcommand{\PCHybldo}{PSO--CMAES$_{\LDO}$\xspace}
\newcommand{\MTFldo}{MTF$_{\LDO}$\xspace}
%Algorithm with default values
\newcommand{\StdPSOdft}{StdPSO$_{\texttt{DFT}}$\xspace}
\newcommand{\DEdft}{DE$_{\texttt{DFT}}$\xspace}
\newcommand{\CMAESdft}{CMAES$_{\texttt{DFT}}$\xspace}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Table version of the algorithms %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Algorithms LDO 
\newcommand{\PSOtfoTBL}{PSO-\textsl{X}\xspace({\TFOUT})\xspace}
\newcommand{\DEtfoTBL}{DE\newline({\TFOUT})\xspace}
\newcommand{\CMAEStfoTBL}{CMAES\xspace({\TFOUT})\xspace}
\newcommand{\PDHybtfoTBL}{PSO--\newline DE\xspace({\TFOUT})\xspace}
\newcommand{\DCHybtfoTBL}{DE--CMAES\xspace({\TFOUT})\xspace}
\newcommand{\PCHybtfoTBL}{PSO--CMAES\xspace({\TFOUT})\xspace}
\newcommand{\MTFtfoTBL}{MTF\xspace({\TFOUT})\xspace}
%Algorithms LDO 
\newcommand{\PSOldoTBL}{PSO-\textsl{X}\xspace(\LDO)\xspace}
\newcommand{\DEldoTBL}{DE\newline(\LDO)\xspace}
\newcommand{\CMAESldoTBL}{CMAES\xspace(\LDO)\xspace}
\newcommand{\PDHybldoTBL}{PSO--\newline DE\newline(\LDO)\xspace}
\newcommand{\DCHybldoTBL}{DE--CMAES\xspace(\LDO)\xspace}
\newcommand{\PCHybldoTBL}{PSO--CMAES\xspace(\LDO)\xspace}
\newcommand{\MTFldoTBL}{MTF\xspace(\LDO)\xspace}

\newcommand{\StdPSOdftTBL}{StdPSO\xspace(\texttt{DFT})\xspace}
\newcommand{\DEdftTBL}{DE\newline(\texttt{DFT})\xspace}
\newcommand{\CMAESdftTBL}{CMAES\xspace(\texttt{DFT})\xspace}

\newcommand{\fSOCO}{$f_\text{SOCO}$\xspace}
\newcommand{\fCECFIVE}{$f_\text{CEC'05}$\xspace}
\newcommand{\fCECFOURTEEN}{$f_\text{CEC'14}$\xspace}
\newcommand{\fBENCHMARK}{$f_\text{BENCHMARK}$\xspace}
\newcommand{\metrics}{MED, MEDerr and MAD\xspace}


\newcommand{\thomas}[1]{\textcolor{blue}{#1}}

%\newcommand{\ }{{\textsf{ }}\xspace}

%%%%%%%%%%%%%%%%% Commands file %%%%%%%%%%%%%%%%%


%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
	\providecommand\BibTeX{{%
			Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%\citestyle{acmauthoryear}

\begin{document}
	
	\title[\texorpdfstring{\MetafoR}~: A Hybrid Metaheuristics Software Framework for Continuous Optimization Problems]{\texorpdfstring{\MetafoR}~: A Hybrid Metaheuristics Software Framework for Single-Objective Continuous Optimization Problems}
	%Global Optimization}
%\title[short title]{full title}
%\url{https://capitalizemytitle.com/}

%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Christian Camacho-Villal\'on}
\affiliation{%
	\institution{Department of Knowledge Technologies, Jožef Stefan Institute}
	\city{Ljubljana}
	\country{Slovenia}
}
\affiliation{%
	\institution{Institut de Recherches Interdisciplinaires et de D{\'e}veloppements en Intelligence Artificielle (IRIDIA), Universit{\'e} Libre de Bruxelles}
	\city{Brussels}
	\country{Belgium}
}
%\authornote{Both authors contributed equally to this research.}
\email{christian.camacho.villalon@ijs.si}
%\orcid{https://orcid.org/0000-0002-0182-3469}
\orcid{0000-0002-0182-3469}
\authornotemark[1]

\author{Marco Dorigo}
% \affiliation{%
	%   \institution{Institut de Recherches Interdisciplinaires et de D{\'e}veloppements en Intelligence Artificielle (IRIDIA), Universit{\'e} Libre de Bruxelles}
	%   \city{Brussels}
	%   \country{Belgium}
	% }
\email{mdorigo@ulb.ac.be}
\orcid{0000-0002-3971-0507} 
\author{Thomas Stützle}
\email{thomas.stuetzle@ulb.be}
\orcid{0000-0002-5820-0473}
\affiliation{%
	\institution{Institut de Recherches Interdisciplinaires et de D{\'e}veloppements en Intelligence Artificielle (IRIDIA), Universit{\'e} Libre de Bruxelles}
	\city{Brussels}
	\country{Belgium}
}

%\email{webmaster@marysville-ohio.com}


%\renewcommand{\shortauthors}{Camacho-Villalón et al.}

%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
	Hybrid \mhs are powerful techniques for solving difficult optimization problems that exploit the strengths of different approaches in a single implementation. 
	For algorithm designers, however, creating hybrid metaheuristic implementations has become increasingly challenging due to the vast number of design options available in the literature and the fact that they often rely on their knowledge and intuition to come up with new algorithm designs.
	In this paper, we propose a modular \msf, called \MetafoR, that can be coupled with an \aact to automatically design hybrid \mhs.
	\MetafoR is specifically designed to hybridize \PSOall, \DEall and \CMAESall, and includes a \ls module that allows their execution to be interleaved with a subordinate \ls.
	%\MetafoR has a modular architecture and uses an algorithm template to guide the design of the implementations.
	We use the configuration tool \irace to automatically generate 17 different \mh implementations and evaluate their performance on a diverse set of continuous optimization problems.
	%Based on the data gather from our experimental study, 
	Our results show that, across all the considered problem classes, automatically generated hybrid implementations are able to outperform configured single-approach implementations, while these latter offer advantages on specific classes of functions. %, such as large dimensionality, and functions hybridization.
	We provide useful insights on the type of hybridization that works best for specific problem classes, the algorithm components that contribute to the performance of the algorithms,
	%on unimodal, multimodal, hybrid, rotated and large dimensional search spaces, 
	and the advantages and disadvantages of two well-known instance separation strategies, creating stratified training set using a fix percentage and leave-one-class-out cross-validation.
	%Our results show that the automatically generated \MetafoR implementations outperform their manually designed counterparts on metrics such as convergence speed and solution quality.
\end{abstract}

%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10010147.10010178.10010205.10010209</concept_id>
	<concept_desc>Computing methodologies~Randomized search</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10010147.10010178.10010205.10010208</concept_id>
	<concept_desc>Computing methodologies~Continuous space search</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10010147.10010178.10010205.10010206</concept_id>
	<concept_desc>Computing methodologies~Heuristic function construction</concept_desc>
	<concept_significance>300</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Randomized search}
\ccsdesc[500]{Computing methodologies~Continuous space search}
\ccsdesc[300]{Computing methodologies~Heuristic function construction}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Metaheuristic Framework, Automated Algorithm Design}

% \received{20 February 2024}
% \received[revised]{12 March 2024}
% \received[accepted]{5 June 2024}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
\Cops are ubiquitous in many areas of science and technology, including engineering, finance, education, e-commerce and healthcare, to name a few.
In a $d$-dimensional \cop, the goal is to find a $d$-dimensional vector that minimizes a continuous objective function.
Due to their complexity, many \cops cannot be efficiently approached using traditional analytical methods, such as gradient search or the Hessian matrix computation.
These methods often have limitations when \cops involve multimodal, non-differentiable functions~\cite{Andreasson2020:Book-continuousOptimization}, nonlinear constraints and/or a large number of dimensions~\cite{LueYe1984:Book-linear-nonlinear,Deb2012:book-OptimizationED}, or when the objective function is not explicitly given, as in the case when it is computed using a computer simulation~\cite{AudHar2017:Book-BBO-DFO}.

To tackle difficult \ops of all kinds, researchers have proposed techniques, such as heuristics or metaheuristics~\cite{Glo1986,SorGlo2013,Handbook2019,HooStu05sls-mk}, which are capable of finding "good solutions" in a "reasonable time", but offer no guarantee about the optimality of the solutions generated.
Among the two largest groups of \mhs that can be used to tackle \cops are
\textit{\ec} (\EC)~\cite{FogOweWal1966,Hol75,Rec1973,Schwefel1977,Sch1981}, which include techniques such as \ess (\ESs)~\cite{Rec1971PhD,Schwefel1977}, \gas (\GAs)~\cite{Hol75,Goldberg89},  and \de (\DE)~\cite{StoPri1997:de};
and
\textit{\ssii} (\SSII)~\cite{BonDorThe1999swarm,KenEbeShi01,DorBir2007:sch-si}, which includes techniques such as 
\pso (\PSO)~\cite{KenEbe1995pso,EbeKen1995:pso},
\aco (\ACO)~\cite{SocDor2008:ejor,LegCoe2010:ants-alternativeACO,LiaStuMonDor2014}
and artificial bee colonies~\cite{Kar2005idea,KarBas2007}.
Most \ec and \ssii \mhs are population-based, i.e., they handle multiple solutions at the same time in order to perform a parallel exploration of the search space.

In this paper, we consider some of the most successful \pbmhs 
and investigate how they can be combined to create high-performance hybrid implementations for single-objective continuous optimization problems using an \ad approach.
The \ad approach consist in delegating the task of designing and configuring a metaheuristic implementations to an \aact, e.g., 
ParamILS~\cite{HutHooLeyStu2009jair}, SMAC~\cite{HutHooLey2011lion} or \irace~\cite{LopDubStu2011irace,LopDubPerStuBir2016irace},
rather than to a human algorithm designer.
This approach has already been used to design various state-of-the-art metaheuristics, including 
stochastic \ls~\cite{FraStu2019:cor,PagStu2019:ejor}, 
multi-objective evolutionary algorithms~\cite{BezLopStu2015tec,BezLopStu20:ecj}, 
\DE~\cite{VerCarKon2023:autoDE:gecco}, 
\CMAES~\cite{deNVerWan2021:gecco-CMAESframework,LiaMonStu13:soco},
\ACO~\cite{LopStu2012tec,LiaMolMonStu2014,LopStuDor2017aco}, and 
\PSO~\cite{CamDorStu2022:tec,NebLopGar23:si:mopso}.
However, there are relatively few papers investigating how to automatically combine the strengths of multiple metaheuristics into single implementations \cite{BokWanBac2020:gecco-PSO-DE,LiaStu2013cec}.
In this work we develop a \msf that allows users to instantiate hybrid metaheuristics to solve \cops in a robust and efficient manner.

Our main contribution is the development of a \msf called \MetafoR, which stands for \textsf{\textbf{META}}heuristic \textsf{\textbf{F}}ramework for \textsf{\textbf{O}}ptimization in $\mathbb{R}$eal domains, and incorporates more than one hundred components proposed in the literature for \PSO, \cmaes (\CMAES), \DE and \ls (\LS) algorithms.
\MetafoR allows users not only to replicate many state-of-the-art variants of these metaheuristics, including many of their hybrids, but also to combine their components in new ways using a flexible algorithm template specifically designed for combining \pbmhs with a \ls procedure.
Due to its modular design, \MetafoR can be easily extended with more components allowing users to try novel ideas and assess their usefulness in a systematic manner.
Also, \MetafoR is a parameterized framework: executing it with different parameters results in different implementations, which facilitates its integration with \aacts to explore its design space and find high-performance implementations.

We defined two machine learning-type training scenarios (one in which we included only a fixed percentage of 75\% of the problem instances and another in which we left out an entire problem class) and used \irace to automatically generate 17 implementations of \algInPaper, which we experimentally compared using an heterogeneous benchmark set of 50 continuous functions.
The benchmark set includes unimodal, multimodal and hybrid composition functions, mathematical transformations (rotation, translation and scaling) and varying dimensionalities (from 50 to 1250 dimensions).
We find that automatically generated hybrids involving \CMAES perform better than single-approach implementations across the entire set of 50 functions, whereas configured single-approach implementations of \DE excel in functions with a large number of dimensions.
We study the differences in the algorithms designs and discuss how these differences contribute to the differences in their performance.

The rest of this paper is structured as follows.
\Sect~\ref{sec:Background} provides an overview of \algInPaperLS and briefly discusses the fundamentals of \ad.
\Sect~\ref{sec:Previous works on hybridization} reviews the literature on hybrid implementations combining \algInPaper.
In \Sect~\ref{sec:Metafor}, we introduce \MetafoR and describe the way it has been designed.
In \Sect~\ref{sec:ExperimentalStudy}, 
%after describing how we used \MetafoR together with \irace to automatically generate hybrid implementations, 
we experimentally compare default, configured and hybrid implementations of \algInPaper created using \MetafoR. % using a benchmark set of continuous functions composed of three different test suites.
Finally, in \Sect~\ref{sec:conclusions}, we conclude the paper and provide ideas for future research.


\section{\Cops, \mhs, and \ad}\label{sec:Background}
Without loss of generality, in a \cop, the goal is to minimize a $d$-dimensional continuous objective function $f : S \subseteq \mathbb{R}^d \rightarrow \mathbb{R}$ by finding a vector $\vec{o}$ in the search space $S$, such that $\forall \:\vec{x} \in S$, $f(\vec{o}) \leq f(\vec{x})$.
The search space $S$ is a subset of $R^d$ in which a solution is represented by a real-valued vector $\vec{x}$, and each component $x_j$ of $\vec{x}$ is constrained by a lower and upper bound: $lb_j \leq x_j \leq ub_j$, for $j = 1,\dots, d$.  
Although there are many different approaches that can be used to deal with \cops \cite{SerOsaMol2019:sec-BioComputation}, in our work we focused on \algInPaperLS, which are among the best performing ones reported in the literature \cite{LiaMolStu2015,VskEftKor19:ieee-cec}.
The main characteristic of \algInPaper is that they are \pbmhs, that is, at each iteration, they keep a population of solutions and perform a parallel exploration-exploitation of the search space.
Differently, \ls algorithms, such as \mtsls \cite{TseChe08:ieee-ec-ci}, make small changes to a single solution based on a step-size parameter that determines how far a new candidate solution will be created.
Since \pbmhs and \ls have complementary characteristics, they are often combined to create algorithms that are better equipped to solve difficult optimization problems \cite{MulBauSba09:ieee-cec,MolLozSan11:soco,GhoDasRoy12:is,LiaStu2013cec}.

\subsection{\Pbmhs}\label{sec:pbmhs}
\subsubsection{\PSOall}\label{sec:PSOall}
In \pso (\PSO) \cite{KenEbe1995pso,EbeKen1995:pso}, particles try to discover the region of the search space where the best quality solutions are located by moving in directions that are estimated based on the best locations that they and their neighboring particles have visited in the past.
The standard version of \PSO (\SPSO) \cite{ShiEbe1998modifiedPSO} 
uses a computational model composed of three main elements: 
(i) a \textit{cognitive component} that allows each particle $i$ in the swarm to memorize the best position it has visited so far, called personal best position $\vec{p}^{i}$;
(ii) a \textit{social component} that allows a particle to know the best position $\vec{l}^{i}$ ever found by any of the particles in its neighborhood; and
(iii) a \textit{velocity update rule} and a \textit{position update rule} that specify how the particles move in the search space and that are defined respectively as follows:
%\vspace{-4ex}
\begin{align}
	\label{eq:psoVelocity}
	\vec{v}^{i}_{t+1} &= \omega \vec{v}^{i}_{t} 
	+ \varphi_1 U^i_{1t} \big(\vec{p}^{i}_t - \vec{x}^{i}_t\big)
	+ \varphi_2 U^i_{2t} \big(\vec{l}^{i}_t - \vec{x}^{i}_t\big) \;\;\;\text{for $i = 1, \dots, n$},\\
	\label{eq:psoPosition}
	\vec{x}^{i}_{t+1} &= \vec{x}^{i}_t + \vec{v}^{i}_{t+1},
\end{align}
where $n$ is the number of particles. 

The position of the particles (vectors $\vec{x}$), which represent candidate solutions to the optimization problem, are updated in every iteration $t$ of the algorithm 
by computing a new velocity vector (\Eq~\ref{eq:psoVelocity}) that is added
to their current positions (\Eq~\ref{eq:psoPosition}).
The computation of a particle's new velocity makes use of two random diagonal matrices, $U^i_{1t}$ and $U^i_{2t}$, to introduce diversity to the particle's movement, and of three real parameters, \PsoParam, that control, respectively, the influence of the previous velocity (also called the particle's inertia), of the cognitive component and of the social component.
The role of vectors $\vec{p}_t$ and $\vec{l}_t$ in the velocity update rule is to combine the knowledge acquired by each particle during the search with the knowledge of the best-informed individual in the neighborhood of the particle.

%Should these involve the PSO-X which was probably the PSO "varinant" that was used in this section or is it somewhere else. Since the PSO-CMAES etc. are comming in this section I don't know.

\subsubsection{\CMAESall}\label{sec:CMAESall}
The evolution strategy (\ES) with covariance matrix adaptation (\CMAES) \cite{Han1997,HanOst2001ec} is a \ES in which the complete covariance matrix of the normal mutation distribution is adapted at execution time.
The main idea in \ESs is to simulate the process by which a population of $\mu$ parents (solutions) undergoes recombination and mutation to generate $\lambda$ offspring (new solutions). Then, a selection operator is applied to choose a subset of these solutions to form the population for the next iteration.
\CMAES is similar to the Quasi-Newton method \cite{NocWri2006} in the sense that it is a second-order estimator that iteratively estimates a positive definite matrix, specifically the covariance matrix. However, unlike the Quasi-Newton method, \CMAES does not use approximate gradients, nor does it assume their existence.
The standard \CMAES implementation \cite{Hansen2006cma,Hansen2016:cma-tutorial} is composed of three main steps.

The first step, \textit{random sampling}, consist in sampling a population of $\lambda$ solutions from a multivariate normal distribution $\mathcal{N}$ with mean $\vec{m} \in \mathbb{R}^d$ and covariance $\mathbf{C} \in \mathbb{R}^{d\times d}$, as shown in the following equation:
\begin{equation}
	\label{eq:CMAES_sampling}
	\vec{x}^{i}_{t+1} = \vec{m}_{t} + \sigma_{t} \times \mathcal{N}(0,\mathbf{C}_{t}) \;\;\;\text{for $i = 1, \dots, \lambda$},
\end{equation}
where $\vec{x}^{i}_{t+1}$ is a vector representing the $i$-th individual in the population, and $\sigma_{t} > 0 $ is the standard deviation that controls the sampling radius or step-size.

In the second step, \textit{weighted intermediate recombination}, the $\lambda$ individuals are ranked in ascending order and the $\mu$ best ones are selected to update the mean of the sampling distribution. The equation describing this process is the following:
%\todo{Can it be nicer}\todo{Christian: In which way? I added parenthesis to $(i|\lambda)$ to make it easier to see, but I do not know if this is what you meant.}
\begin{equation}
	\label{eq:CMAES_recombination}
	\vec{m}_{t+1} = \sum_{i=1}^{\mu} w^{i} \vec{x}^{(i|\lambda)}_{t+1},
\end{equation}
where
$w^{1} \geq w^{2} \geq \dots w^{\mu} > 0$,
$\sum_{i=1}^{\mu} w^{i} = 1$,
and $\vec{x}^{(i|\lambda}_{t+1})$ denotes the $i$-th ranked individual of the $\lambda$ solutions sampled using \Eq~\ref{eq:CMAES_sampling}. The weights $w^{i}$ are decreased logarithmically using:
\begin{equation}
	\label{eq:CMAES_weighting}
	w^{i} = \log\bigg(\frac{\lambda-1}{2} + 1\bigg) - \log(i) 
	\;\;\;\text{for $i = 1, \dots, \mu$}.
\end{equation}

The last step is the \textit{covariance matrix adaptation}. The process of adapting the covariance matrix for the next iteration uses a combination of rank-one update (i.e., the mean of the estimated covariance matrices using a single selected step, namely the "evolution path") and the rank-$\mu$ update (i.e., the mean of the estimated covariance matrices from all previous iterations). The update of the covariance matrix is done as follows:
\begin{equation}
	\label{eq:CMAES_cma}
	\mathbf{C}_{t+1} = (1 - c_{\mathrm{cov}}) \mathbf{C}_{t} +
	\frac{c_{\mathrm{cov}}}{\mu_{\mathrm{cov}}}
	\mathrlap{\underbrace{
			\phantom{\;\vec{p}^c_{t+1} \Big({\vec{p}_{t+1}^c}\Big)^T}}_{\text{rank-one update}
	}}
	\;\vec{p}^c_{t+1} \Big({\vec{p}_{t+1}^c}\Big)^T +
	c_{\mathrm{cov}} \bigg( 1 - \frac{1}{\mu_{\mathrm{cov}}}\bigg)
	\mathrlap{\underbrace{
			\phantom{\sum_{i=1}^{\mu} w^{i} \vec{y}^{(i|\lambda)}_{t+1} \Big(\vec{y}^{(i|\lambda)}_{t+1}\Big)^T}}_{\text{rank-$\mu$ update}
	}}
	\sum_{i=1}^{\mu} w^{i} \vec{y}^{(i|\lambda)}_{t+1} \Big(\vec{y}^{(i|\lambda)}_{t+1}\Big)^T
	,
\end{equation}
where 
$c_{\mathrm{cov}} \in [0, 1]$ is the learning rate for the covariance matrix update, 
$\mu_{\mathrm{cov}}$ is used to determine the weighting between the rank-one and rank-$\mu$ update, 
$\vec{p}^c_{t+1}$ 
%the 
is the evolution path (i.e., the search path the algorithm takes over a number of iterations and it is expressed as a sum of consecutive steps of $\vec{m}$), and
$\vec{y}^{(i|\lambda)}_{t+1} = (\vec{x}^{(i|\lambda)}_{t+1} - \vec{m}_{t})/\sigma_{t}$.
For a detailed explanation of how to compute the evolution path $\vec{p}^c_{t+1}$ and the new step-size $\sigma_{t+1}$, we refer the reader to \cite{HanArnAug2015evolutionstrategies,Hansen2016:cma-tutorial}.

\subsubsection{\DEall}\label{sec:DEall}
\DEall (\DE) \cite{StoPri1997:de,PriStoLam2005:book} is another evolutionary approach, though it is often regarded as distinct because it incorporates concepts that are similar to those found in \SSII methods.
\DE implements a mutation operator, called \textit{differential mutation}, that is similar to the moves in the Nelder-Mead simplex search method \cite{NelMea1965:tcj-simplex}.
The differential mutation operator consists of selecting three solutions from the population,
%(e.g., vectors $\vec{x}^{a}$, $\vec{x}^{b}$), 
computing the difference of the first two solutions and multiplying it by a scaling factor, and then adding the scaled vector difference to the third solution.
%($\vec{x}^{c}$).
More formally, in \DE, the mutation operator is defined as follows:
\begin{equation}
	\label{eq:DE_mutation}
	\vec{m}^{i} = \vec{x}^{a} + \beta \cdot(\vec{x}^{b}-\vec{x}^{c}),
\end{equation}
where $i = 1, \dots, n$ denotes the $i$th individual in a population of $n$ solutions, $\beta$ is the scaling factor and vectors $\vec{x}^{a} \neq \vec{x}^{b} \neq \vec{x}^{c}$ are the three solutions randomly chosen from the population.
%\todo{I don't get to what this is. Above we have that the third one is different of the two chosen. Is it related to this one? Can it expressed easier?}
%\todo{Christian: I made some changes. Is it better?}
Vector $\vec{x}^{a}$, which is referred to as \textit{base vector} and can be selected in many ways, has to be different from the solution in the population for which it is targeted, that is, vector $\vec{x}^{i}$, which is referred to as \textit{target vector}. 
The result of applying \Eq~\ref{eq:DE_mutation} is a vector called \textit{mutant vector}, indicated as $\vec{m}^{i}$.

The creation of the mutant vector is followed by recombination, in which the mutant vector ($\vec{m}^{i}$)
is recombined with target vector ($\vec{x}^{i}$)
to create a \textit{trial vector} $\vec{u}^{i}$.
The equation to apply recombination and obtain the trial vector is the following:
\begin{equation}
	\label{eq:DE_recombination}
	{u}^{i,k} = 
	\begin{cases}
		{m}^{i,k}, & \text{if  $(\mathcal{U}[0,1] \geq p_a) \vee (k = k^{i}_{rand})$}\\
		{x}^{i,k}, & \text{otherwise}
	\end{cases}, \, \text{$\forall k$, $\forall i$},
\end{equation}
where $k = 1, \dots, d$ allows to iterate between the values of the vectors, $\mathcal{U}[0,1]$ is a random number sampled from a uniform distribution, $d$ is the number of dimensions of \cop, $p_a$ is a real parameter in the range $[0,1]$ that controls the fraction of values copied from the mutant vector into the trial vector, and $k^{i}_{rand}$ is a randomly chosen dimension that ensures that the trial vector is not a duplicate of the target vector.  %$\vec{x}^{i}$.
The newly generated trial vector $\vec{u}^{i}$ only replaces the target vector $\vec{x}^{i}$ in the population if it has better quality, otherwise is discarded. % that is, if $\vec{t}^{i} < \vec{x}^{i}$.
Also, as indicated in \Eq~\ref{eq:DE_recombination}, the mutation and recombination operators are iteratively applied for every solution in the population. %until every solution in the population has been used once as a target vector.

\subsection{Local search strategies for \cops}\label{sec:Local search strategies for cops}
%- Nelder-Mead method \cite{NelMea1965:tcj-simplex}\\
%- Powell’s conjugate directions set \cite{Powell1964}\\
%- Powell’s BOBYQA and NEWUOA \cite{Powell2002,Powell2006}\\
%- Lin-Yu Tseng’s Mtsls \cite{TseChe08:ieee-ec-ci}\\

Among the best-known \ls algorithms proposed to tackle \cops are the Nelder-Mead Simplex algorithm \cite{NelMea1965:tcj-simplex}, the Powell’s conjugate directions set algorithm \cite{Powell1964}, and the BOBYQA algorithm \cite{Powell2006} (also by Powell).
In this paper, we consider the more recent \mtsls (\MTSLS) algorithm \cite{TseChe08:ieee-ec-ci}. 
The choice of \MTSLS was motivated by the excellent results obtained by various hybrid algorithms for continuous optimization that integrate this local search \cite{LiaStu2013cec,LaTMuePen11:soco}.

The \MTSLS algorithm starts by generating a candidate solution $\vec{s}=(s_1,s_2, \ldots, s_d)$ uniformly at random inside the search range. 
The initial step size $ss$ is set to $ss= 0.5\times(ub_j-lb_j)$, where 0.5 is a default value \cite{TseChe08:ieee-ec-ci} and $ub$ and $lb$ are, respectively, the upper and lower bounds of dimension $j$.
% Mtsls1 starts from an initial candidate solution $s=(s_1,s_2, \ldots,
% s_D)$ with an initial step size $ss$. The default setting of $ss$ in
% Mtsls1 \cite{tseng2008multiple} is $0.5\times(B-A)$. 
\MTSLS visits the dimensions of the problem in a fixed order, searching one dimension at a time. 
%In each iteration of
For $j= 1\dots d$, \MTSLS proceeds as follows. First, the value $s_j$ is modified as $s'_j = s_j-ss$ and the resulting solution $s'$ is evaluated. 
If $f(s') < f(s)$, then $s_j= s'_j$ and the search continues in dimension $j+1$; otherwise, $s''_j = s_j+0.5\times ss$ and the candidate solution $s''$ is evaluated. 
If $f(s'') < f(s)$, then $s_j = s''_j$ and the search continues in dimension $j+1$. 
However, if both $s'_j$ and $s''_j$ do not improve over $s_j$, then $s_j$ remains unchanged and the same process is applied to dimension $j+1$. 
If no improvement is found in any of the dimensions during one iteration of \MTSLS, the next iteration uses only half the value of the step size, i.e., $ss_{t+1} = ss_t/2$. In our implementation of \MTSLS, the maximum number of iterations in one execution of \MTSLS is determined by the parameter \MTSLSiterations.



\subsection{Automatic design of \mh implementations}
% In most cases, the creation of metaheuristic implementations is a manual process guided by the knowledge and intuition of the algorithm designers---the so-called \textit{manual design} approach~\cite{LopDubPerStuBir2016irace,StuLop2019hb}.
% However, the plethora of design choices available today to algorithm designers has made the manual design of algorithms increasingly inefficient.
% Manual design can be particularly time-consuming and error-prone in real-world environments, where the specific meaning of "good solution" and "reasonable time" can be quite different for different decision makers and depends on a variety of factors, ranging from the domain in which the problem arises to the technological resources available.

\Ad~\cite{CamStuDor2023:IC:disNewMH} has been proposed as an alternative to manual design, with the goal of reducing the burden on algorithm designers who have to deal with the problem of creating metaheuristic implementations that meet certain performance requirements. 
%In \ad, the problem of creating effective algorithms is formulated as an optimization problem, where the goal is to find a combination of components and parameter settings that satisfies the user's needs.
In \ad ~\cite{StuLop2019hb,CamStuDor2023:IC:disNewMH}, generating effective algorithm designs is treated as an optimization problem, focused on discovering high-performing combinations of algorithm components and parameter settings.
By using an \ad approach, algorithm designers do not have to deal themselves with the tasks of composing many different metaheuristic designs, assessing their performance and selecting the best ones, since these tasks are delegated to an \aact (\AACT). % such as the state-of-the-art \irace and SMAC.
The \AACT can systematically explore the design space of a metaheuristic until it finds one that meets the user's needs or until a maximum computational budget is exhausted.

% The general workflow followed by an \AACT is depicted in Figure~\ref{fig:AutomaticConfigurationWorkflow}.
% \begin{figure}[ht] 
	%     \centering
	%     \includegraphics[width=1\textwidth]{figures/AutomaticConfiguration.pdf}
	%     \caption{General workflow followed by an \AACT used to configure a metaheuristic. When using an \AACT in combination with a parameterized \msf, such as \MetafoR, the configuration space of the metaheuristics becomes the same as its design space, since running the framework with different parameter settings results in different algorithm designs.}
	%     \label{fig:AutomaticConfigurationWorkflow}
	%     \Description{Diagram showing the way in which an \aact operates in the context of the \au of \mhs.}
	% \end{figure} 

The \AACT used in this paper is \irace~\cite{LopDubStu2011irace,LopDubPerStuBir2016irace}, which implements an \textit{iterated racing} approach.
The iterated racing approach~\cite{MarMoo1997air,BirYuaBal2010:emaoa} is based on the idea of performing sequential statistical testing 
%using the Friedman test and its related post-tests 
in order to create a sampling model that can be refined by iteratively ``racing'' candidate configurations and discarding those that perform poorly.
The way in which \irace works can be summarized as follows. 
First, it samples candidate configurations from the parameter space and evaluates these configurations on a set of instances using a racing procedure, where each configuration is tested on one instance at a time. 
Then, \irace eliminates the statistically inferior configurations based on Friedman's non-parametric two-way analysis of variance by ranks.
Throughout the configuration process, which proceeds sequentially within a given computational budget, \irace adjusts the sampling distribution to favor the best configurations identified so far.
This process is repeated iteratively until a computational budget is exhausted and \irace returns the configuration that performed best on the training instances.


\section{Previous works on hybridization and \ad}
%of \algInPaper} 
\label{sec:Previous works on hybridization}
The goal of creating hybrid \mhs is to exploit the strengths that different optimization techniques can offer to solve optimization problems%, while simultaneously reducing any potential drawbacks
~\cite{GroAbr07:hea,Tal2013hm,BluRai2016:book,StuLop2019hb,CalArmMas2017:Learnheuristics}.
In the following, we discuss the main ideas proposed in hybrids of \algInPaper, as well as some modular \msfs that have been proposed to study these metaheuristics and their hybrids in an \ad context.
Note, however, that this review of the literature is by no means exhaustive, as we focus on papers proposing ideas that are particularly amenable to be implemented in \MetafoR, such as single-objective hybrids and not overly complicated hybrids.
%we excluded papers proposing %(i) heavily modified variants of \algInPaper (such as \cite{LiLeiYua21:aitel} and \cite{WarAraBie22:gecco}, that make use of several additional components) and (ii) variants for multi-objective optimization problems.

\subsection{\PSO and \DE hybrids}
%Tim Hendtlass. 2001. Discussed in PSO-DE 
Hendtlass proposed an algorithm called swarm differential evolution algorithm (SDEA) \cite{Hendtlass01:iea-aie}. SDEA works mainly as the standard \PSO algorithm, but intermittently applies the \DE mutation operator to the particles' current solutions to avoid local minima. %The particles keep their velocity after being modified by the application of \DE mutation.
%Wen-Jun Zhang and Xiao-Feng Xie. 2003. Discussed in PSO-DE 
Zhang and Xie proposed an algorithm called DEPSO, in which the \stanPSO is applied during even iterations of the algorithm, and the \DE mutation operator is applied to the particles' personal best during odd iterations~\cite{ZhaXie03:ieee-smc}.
%Das, Swagatam, Amit Konar, and Uday K. Chakraborty, 2005 
Das \etal proposed a hybrid algorithm in which the personal component of the velocity update rule of the \stanPSO is modified based on the mutation operator of \DE~\cite{DasKonCha05:gecco}.
%M. G. H. Omran, A. P. Engelbrecht, and A. Salman. 2007. Discussed in PSO-DE 
In \cite{OmrEng07:ieee-sis}, Omran \etal introduced a modified version of Hendtlass’ SDEA that uses a probabilistic approach based on the "barebones" \PSO. 
%(In the barebones \PSO~\cite{Kennedy2003barebones_PSO}, the velocity vector is replaced with a vector of random numbers sampled from a Gaussian distribution.)
In their algorithm, with probability $p_r$, particles update their position using the barebones \PSO position update rule and add a vector difference, and with probability $1-p_r$, they update their position to the personal best of a randomly selected particle.
%M. Pant, R. Thangaraj, C. Grosan, and A. Abraham. 2008. Discussed in PSO-DE 
Pant \etal introduced a two-phase hybrid version of \DE that uses \PSO as perturbation mechanism~\cite{PanThaGro08:ieee-dim}. Pant \etal's algorithm follows the usual \DE procedure up to the point where the trial vector is generated; if the trial vector is rejected, the algorithm applies the \PSO velocity and position update rules to generate a new solution.
%M.G. Epitropakis, V.P. Plagianakos, M.N. Vrahatis, 2012 
Epitropakis \etal proposed to evolve the social and cognitive components of a swarm by applying the three usual \DE operators (i.e., mutation, recombination and selection) to the personal best positions particles (i.e., vectors $\vec{p}^{i}$ in \Eq~\ref{eq:psoVelocity})~\cite{EpiPlaVra12:is}. 

%B. Xin, J. Chen, J. Zhang, H. Fang, Z.-H. Peng, 2012 
% A taxonomy of \PSO-\DE hybrids was provided by Xin et al. \cite{XinCheZha11:ieee-tsmc}.
% The authors identified three main ways to hybridize \PSO and \DE: 
% (i) collaboration-based, where the two algorithms keep their usual procedures and exchange accumulated information during the search (e.g., \cite{Hendtlass01:iea-aie} and \cite{ZhaXie03:ieee-smc});
% (ii) embedding-based, where the components of one of the two algorithms are modified and the individual contribution of each algorithm to the optimization process cannot be clearly distinguished (e.g., \cite{DasKonCha05:gecco} and \cite{EpiPlaVra12:is});
% and 
% (iii) assistance-based, in which one of the algorithms serve as assistance to the other to provide parts of the solution that are evaluated by the objective function or to fine-tune the base algorithm parameter values (e.g., \cite{OmrEng07:ieee-sis}). 

\subsection{\PSO and \CMAES hybrids}
%Chang-Tai HsiehChih-Ming ChenYing-ping Chen, 2007 \cite{HsiCheChe07:gecco}
%Particle Swarm Guided Evolution Strategy
One of the earliest \PSO--\ESs hybrids is the "particle swarm guided evolution strategy" proposed by Hsieh \etal~\cite{HsiCheChe07:gecco}.
Although this approach is not properly based on \CMAES, the authors introduced the idea that \ESs can be used to focus on exploiting good quality solutions, while \PSO can be used to focus on performing effective search space exploration.
%Chang-Tai and ChenYing-ping' algorithm uses the so-called guided mutation, where the mutation vector is added to each solution is first (i) re-scale dimension-wise according to a learning rate and the mutation step-size, and (ii) rotated such that it points toward the global best solution.
%Note that the idea of attracting the individuals towards the global best solution is the only concept from \PSO used in this algorithm.
%
%C. L. Müller, B. Baumgartner, and I. F. Sbalzarini, 2009, “Particle swarm CMA evolution strategy for the optimization of multi-funnel landscapes,” in Proceedings of the IEEE Congress on Evolutionary Computation(CEC). IEEE, 2009, pp. 2685–2692.
%Based on the idea of Chang-Tai \etal, 
Müller \etal proposed to run multiple \CMAES instances in parallel considering each instance as an individual particle in \PSO~\cite{MulBauSba09:ieee-cec}.
The proposed algorithm is divided into two phases: a \CMAES phase, which follows the usual \CMAES algorithm, and a \PSO phase, where the best solutions found by each \CMAES instance applies the \stanPSO velocity and position update rules.
The equation to adapt the covariance matrix of \CMAES was modified to combine the \textit{local} information gathered by a \CMAES with the \textit{global} information of \PSO.
%In particular, the \PSO covariance matrix is obtained by rotating the \CMAES covariance matrix %such that its principal eigenvector is aligned with the vector that points from mean of the sampling distribution toward the global best position.
%in the direction of the global best position.
Müller \etal also added a bias to the mean of the sampling distribution of \CMAES in the following cases: (i) when the instance has already converged to a local minimum located far from the the global best solution, and (ii) when the instance is different from the one that produced the global best solution and the step-size has fallen below a certain threshold.
%
%Peilan Xu, Wenjian Luo, Xin Lin, Yingying Qiao and Tao Zhu, 2019 
%Hybrid of PSO and CMA-ES for Global Optimization
In \cite{XuLuoLin19:ieee-cec}, Peilan \etal introduced a hybrid, three-phase algorithm that uses multiple populations and two different versions of \PSO, the \stanPSO and a \PSO with time windows (PSOtw).
In PSOtw, particles can only access their personal best if it is within a certain time window $tw$ given in number of iterations.
%Peilan \etal's algorithm is divided into three phases.
The first phase of Peilan \etal's algorithm consists in applying PSOtw by each population for a number of iterations; in the second phase, the best and second best solutions in each population are selected to create a temporary population $P_t$; in the third phase and last, the \stanPSO and \CMAES algorithms are applied one after the other to $P_t$ for a number of function evaluations and the best solutions in $P_t$ are selected for the next iteration.
%
%%%% This is a good article for the next version of the framework %%%%
%Wei Li, Zhou Lei, Junqing Yuan, Haonan Luo and Qingzheng Xu, 2021, \cite{LiLeiYua21:aitel}
%Enhancing the competitive swarm optimizer with covariance matrix adaptation for large scale optimization

\subsection{\CMAES and \DE hybrids}
%Jérôme Henri Kämpf, Darren Robinson, 2008 \cite{KamJerRob09:asoc} A hybrid CMA-ES and HDE optimisation algorithm with application to solar energy potential
Kämpf and Robinson proposed to execute \CMAES and \DE in sequential order, with \CMAES followed by \DE~\cite{KamJerRob09:asoc}.
The elite solutions found by \CMAES are input to \DE, but since \DE uses a larger population size compared to \CMAES, the \DE population is completed with randomly created solutions.
%Saurav Ghosh, Swagatam Das, Subhrajit Roy, S.K. Minhazul Islam, P.N. Suganthan, 2011 \cite{GhoDasRoy12:is} A Differential Covariance Matrix Adaptation Evolutionary Algorithm for real parameter optimization
Ghosh \etal introduced a hybrid algorithm that incorporates the operators of \DE into the structure of \CMAES~\cite{GhoDasRoy12:is}.
The standard mechanism of \CMAES is used in each iteration to sample new solutions from a multivariate normal distributions, after which the population is handled as in \DE.
At each iteration, Ghosh \etal' algorithm performs the following steps: (i) update the mean of the sampling distribution; (ii) adapt the covariance matrix;
(iii) create a population of mutants using components from the eigen decomposition of the covariance matrix; and (iv) apply the crossover and selection operators of the usual \DE algorithm.
%Shu-Mei Guo, Member, IEEE, and Chin-Chang Yang, 2015 \cite{GuoYan14:tevc}
%Enhancing Differential Evolution Utilizing Eigenvector-Based Crossover Operator
In \cite{GuoYan14:tevc}, Guo and Yang proposed a crossover operator that allows individuals to exchange information between the target vector and the mutant vector using the eigenvector basis instead of the natural basis, thus rotating the coordinate system and making the algorithm rotation invariant.
%Xiaoyu He, Yuren Zhou, 2018 \cite{HeZho18:asoc}
%Enhancing the performance of differential evolution with covariance matrix self-adaptation
In \cite{HeZho18:asoc}, He and Zhou presented a hybrid algorithm based on a new mutation operator and a simplified step-size control rule.
The mutation operator used the information of previously rejected solutions and a Gaussian distribution to sample probabilistically "better" solutions.
The standard covariance matrix update of \CMAES was modified to include only the rank-$\mu$ update, and not the rank-one update.
He and Zhou also added a local search that takes place only if there are still at least 10\% of the total number of function evaluations available by the time the algorithm has converged. 
%Zhe Chen and Yuanxing Liu, 2022 \cite{CheLiu22:nature-scirep}
%Individuals redistribution based on differential evolution for covariance matrix adaptation evolution strategy
Chen and Liu proposed a hybrid algorithm in which \DE is used to break the stagnation state of \CMAES~\cite{CheLiu22:nature-scirep}.
The algorithm measures the average fitness improvement of the solutions after each iteration of \CMAES and, when the average falls below a predefined threshold, \DE is executed to regenerate the population. 
To make sure that the new solutions obtained by \DE are redistributed in the search space, only the offspring are selected for survival.

%Eryk Warchulski, Jarosław Arabas, Rafał Biedrzycki \cite{WarAraBie22:gecco}
%Improving the Differential Evolution Strategy by coupling it with CMA-ES

\subsection{Modular \msfs for \algInPaper}
\Msfs (\MSFs) that can be used to automatically generate implementations of \algInPaper have already been proposed in the literature: \PSOX~\cite{CamDorStu2022:tec}, \aCMAES~\cite{deNVerWan2021:gecco-CMAESframework}, \aDE~\cite{VerCarKon2023:autoDE:gecco} and \modPSODE~\cite{BokWanBac2020:gecco-PSO-DE}. %\PaEO~\cite{CahMelTal2004,DreLieVer2021:gecco-oparadiseo}.
Both \PSOX, \aCMAES and \aDE are parameterized \MSFs that allow users to create many different implementations by simply changing the parameters used to execute the framework. 
This aspect makes them particularly suitable for an \ad context, as they can be easily coupled with an \AACT tool such as \irace.
On the other hand, the main drawback of these \MSFs is that they only contain components of a specific metaheuristic, \PSO, \CMAES and \DE, respectively.

The modular \modPSODE framework is, to the best of our knowledge, the only \MSF specifically developed for creating \PSO and \DE hybrids in an automatic design context~\cite{BokWanBac2020:gecco-PSO-DE}.
Unfortunately, it has two important downsides: (i) a limited number of components of \PSO and \DE compared to \PSOX and \aDE; and (ii) lack of flexibility to combine components at a fine-grained level.
The \modPSODE framework is based on the idea of simultaneously generating two populations, one using \PSO components and the other using \DE components, and combining them into a single population that is then reduced to a predefined population size using a selection operator.
This type of hybridization is not particularly useful to explore the interaction of \PSO components in \DE and vice-versa.%\todo{General question: The real question I have if these are "all" the things introduced in the literature. I mean, PSO and DE seems to terminate in 2012, which is 12 years from now. In the others, its true, there are more recent ones.}
%\todo{Christian: I added a sentence at the beginning of the section explaining why two more recent paper were left out of the literature review.}



\section{The \texorpdfstring{\MetafoR}~software framework}\label{sec:Metafor}
% We chose the \PSOX as the starting point for the development of \MetafoR for a combination of technical and convenience reasons, some of which are that (i) it has a modular design, (ii) there is large number of components of \PSO already included in \PSOX, and (ii) it is implemented in \texttt{C++}, which makes its execution faster compared to frameworks implemented in \texttt{Python}.
\MetafoR is composed of three main modules: 
a \PSO module (\PSOmod), which includes algorithm components of \PSO to update solutions by adding a velocity vector; 
a \DE module (\DEmod), which includes algorithm components of \DE to update solutions using differential mutation, recombination and selection;
and a \CMAES module (\CMAESmod), which includes algorithm components of \CMAES to update solutions by applying random sampling, recombination and covariance matrix adaptation.
\MetafoR also includes a \ls module (\LSmod), which allows the execution of \MetafoRModules to be interleaved with a local search (\MTSLS or \CMAES)
%\todo{should one say MTSls1 here?} 
for a number of function evaluations (FEs) and then resume with the main algorithm execution. 

\MetafoRModules can be used standalone or in combination with other modules by selecting specific components from them.
As an example, with \MetafoR it is possible to create a hybrid \DE--\PSO implementation that combines the differential mutation of \DE with the velocity update rule of \PSO, and runs \CMAES as local search for a number of FEs.
The way in which \MetafoRModules interact with each other is controlled by the algorithm component \Execution.
\Execution operates at a high level in \MetafoR and contains the necessary options for creating different types of hybrid implementations (e.g., component-based, multiple phases, etc.). %that combine individual components from different approaches into a single implementation, or hybrids that applied  three approaches that alternate in the implementation.
We will now provide a detailed description of the modules that comprise \MetafoR. We use a \textsf{sans-serif} font to indicate both the algorithm components implemented in the framework and their available options.

\subsection{\PSOmod}\label{sec:The PSOX module}
\PSOmod includes all the algorithm components and implementation options as the original \PSOX framework~\cite{CamDorStu2022:tec}.\footnote{For specific details about the implementation of the algorithm components included in the \PSOX framework, we refer the reader to the original paper~\cite{CamDorStu2022:tec} and supplementary material~\cite{CamDorStu2021:posx-supp}.}
The two top-level algorithm components of \PSOmod are \Pop and \Topo.
\Pop handles the number of solutions (particles) in the implementation and has three options available: \PopConst, \PopIncre and \PopTV. 
When \PopIncre or \PopTV are used, the user has to specify the way new solutions added to the population are initialized, which is done via the algorithm component \Init using option \InitHorizontal or \InitRandom.
The \Topo algorithm component determines the way particles connect to each other and it can be implemented in seven different ways: \TopFC, \TopHie, \TopNeum, \TopRing, \TopRandom, \TopTVFI and \TopWheel; each option providing different connectivity and information transfer speed to the swarm.

In \PSOmod, the components involved in the computation of a particle's new velocity vector ($\vec{v}^{\,i}_{t+1}$) are combined using a generalized velocity update rule, which is defined as follows:
\begin{equation} 
\label{eq:GeneralizedVUR}
\vec{v}^{\,i}_{t+1} = \omega_1\,\vec{v}^{\,i}_t + \omega_2\,\DNPP(i,t) + \omega_3\,\PertRnd(i,t),
\end{equation}
where $\omega_1$, $\omega_2$ and $\omega_3$ are three real parameters in the range $[0,1]$ used to control the influence of each term in the equation, $\vec{v}^{\,i}_t$ is the velocity of the particle $i$ at iteration $t$, \DNPP is an algorithm component that determines the type of mapping from a particle's current position to the next one, and \PertRnd is an optional algorithm component to add a perturbation vector.
\PSOmod provides nine options for computing the value of $\omega_1$, most commonly known as the inertia weight (\IWcomp). Three of these options update their value at regular intervals of the algorithm execution based on predefined schedules (\OmegaLinDec, \OmegaLinInc and \OmegaRnd), whereas the other six options update their value adaptively, based on information gathered from the option process (\OmegaSelfReg, \OmegaAdapVel, \OmegaDoubExp, \OmegaRnkBsd, \OmegaSuccBsd and \OmegaConvBsd).
The parameters $\omega_{2}$ and $\omega_{3}$, which regulate the influence of \DNPP and \PertRnd, respectively, can either be set equal to $\omega_{1}$ or determined using the \OmegaRnd and \OmegaCons options.

The options for implementing the \DNPP algorithm component are \DNPPRect, \DNPPSphe, \OperatorS, \OperatorD, \OperatorN and \OperatorCG.
The \DNPPRect option is the most commonly used in \PSO variants, including the \textit{standard} \PSO \cite{KenEbeShi01}, the \textit{fully-informed} \PSO \cite{MenKenNev2004fullyInformed_pso} and the \textit{locally convergent rotationally invariant} \PSO \cite{BonMic2014:swarm}, and it was used as the basis for the \DNPPSphe option, proposed for the \textit{standard} \PSO--\textit{2011} \cite{Clerc2011:pso,ZamCleRoj2013:cec2013}. % to make \PSO rotationally invariant.
In the case of \OperatorS, \OperatorD, \OperatorN and \OperatorCG, they were proposed for the so-called simple dynamic \PSO algorithms, whose main characteristic is that they do not use the previous velocity vector or the random diagonal matrices.
The algorithm component \VectBasis, which is not part of the original \PSOX framework, works in combination with \DNPP.
\VectBasis uses the eigenvector information of the population covariance matrix to rotate the coordinate system, with the goal of making the implementation invariant to rotated search spaces.
\VectBasis can be implemented using the option \VBnatural, where no changes are made to the coordinate system, or the option \VBeigen, where the vectors involved in the computation of the \DNPP are rotated in the direction of the eigenvector basis.

When \DNPP is implemented as \DNPPRect or \DNPPSphe, the user has to indicate the options for the \textsf{Random Matrices} (\Mtx), \Moi (\textsf{MoI}) and \textsf{Acceleration Coefficients} (\ACcomp) components.
\Mtx refers to the different ways in which the random matrices can be constructed, such as \MtxDiagonal, \MtxLinear, \MtxExponential, \MtxEuclideanOne (rotation in plane), \MtxEuclideanAll (rotation in all possible planes) and \MtxIncreasingGroupBased.
\Moi specifies which neighbor solutions influence a particle movement. The available options for this component are \MoiBoN (only the best neighbor), \MoiFI (all of its the neighbors and all with same weight) and \MoiRFI  (all of its neighbors, but the higher its quality, the more weight it has).
\ACcomp manages the computation of the parameters $\varphi_1$ and $\varphi_2$ (see \Eq~\ref{eq:psoVelocity}) and offers four options for this purpose: \PhiConstant, \PhiRandom, \PhiTV and \PhiExtra.

\PSOmod has five optional algorithm components:
\PertInf, \PertRnd, \VelClp, \StagDet and \IgnPbest.
Both \PertInf and \PertRnd apply a perturbation to the components of the generalized velocity update rule (\Eq~\ref{eq:GeneralizedVUR}) --- \PertInf does it to the vectors involved in the computation of the selected \DNPP option, whereas \PertRnd generates a random vector that is added directly to a particle's new velocity.
The options available for implementing \PertInf are \PertGau, \PertLev and \PertUni, while the options for implementing \PertRnd are \PertRect and \PertNoi.
When \PertInf and \PertRnd are used, the user has to select the strategy to compute the magnitude of the perturbation (variable $pm$), which is done via the algorithm component \textsf{Perturbation Magnitude} (\PMcomp) using options \MagCons, \MagEucli, \MagOFd and \MagSucc.

The algorithm components \VelClp and \StagDet limit the size of the velocity vectors of the particles.
\VelClp halves the magnitude of the velocity vector when its value exceeds the bounds of the search space, while \StagDet re-initializes the velocity vector when $||\vec{v}^{\,i}_{t}|| + ||\vec{l}^{i}_t - \vec{x}^{\,i}_{t}|| \leq 10^{-3}$, where $||\cdot||$ denotes the L$^2$ norm of a vector.
%
The component \IgnPbest allows particles to ignore their personal best vectors and to use instead their current positions in the computation of the velocity and position update rules.
Despite \IgnPbest is not a common design choice in most \PSO implementations, % we included it in \PSOmod because of 
the motivation to include it in \MetafoR is the large number of 
"novel" metaphor-based \mh 
proposed in recent years (e.g., \GwoAll, \MfAll and \WoaAll) that seem to be based on \PSO~\cite{AraCamCam-etal2022:openletter:si,CamDorStu2022:exposing:itor}.
%Indeed, often, these "novel" metaphor-based \mhs make use of algorithm components that are very similar to those of \PSO, but introduce modifications, such as \IgnPbest, to match their "sources of inspiration"~\cite{CamDorStu2022:itor}.
Our goal is that, with \MetafoR, users can also replicate some of these "novel" \mh and evaluate their performance in a systematic manner.



\subsection{\CMAESmod}
\label{sec:The CMAES module}
\CMAESmod was developed based on the implementation of \CMAES 
%in \texttt{C} 
publicly available from its creator's website.\footnote{http://www.cmap.polytechnique.fr/\~nikolaus.hansen/cmaes\_inmatlab.html\#code} 
\CMAESmod allows to implement the algorithm components proposed in some of the best-known variants of \CMAES, including the \textit{standard}-\CMAES \textit{with intermediate recombination}~\cite{HanMulKou03:ec}, the \textit{separable}-\CMAES \cite{RosHan2008:sepCMAES} and the \textit{restart}-\CMAES \textit{with increasing population size} \cite{AugHan2005cec}.
\CMAESmod is composed of four main algorithm components:
\CMAESPop, which handles the number of solutions in the implementation;
\CMAESMtx, which specifies the way the covariance matrix is adapted;
\CMAESRes, which restarts the algorithm based on criteria related to the range of improvement of the solutions found by the population;
and \CMAESRW, which specifies the weighing mechanism used by recombination.

In \CMAESmod, the size of the population is controlled using the \CMAESPop algorithm component. The two options available for implementing this component are \CMAESPopConst, where the size of the population remains the same throughout the algorithm execution, and \CMAESPopInc, where it increases according to a multiplication factor.
The initial population size (denoted by $\lambda_{t=0}$) and the number of parents selected for recombination (denoted by $\mu_t$) are computed using $\lambda_{t=0} = 4 + \lfloor \CMAESpara \ln(d)\rfloor$ and $\mu_t = \lambda_t / \CMAESparb$, where \CMAESpara and \CMAESparb are two real parameters in the range $[1, 10]$ and $[1, 5]$, respectively.
To sample the initial population (\Eq~\ref{eq:CMAES_sampling}), the initial step size is computed as $\sigma_{t=0} = \CMAESparc [lb_j, ub_j]$, where \CMAESparc is a real parameter in the range $(0,1)$ and $lb_j$ and $ub_j$ are the lower and upper bounds of dimension $j$.
When \CMAESPopInc is used, the size of the population is updated according to the following equation:
\begin{equation} 
\label{eq:CMAES_pop_increment}
\lambda_{t+1} = 
\begin{cases}
	\CMAESpard * \lambda_t, & \text{if \CMAESRes = \textsf{true}}\\
	\lambda_t, & \text{otherwise}
\end{cases},
\end{equation}
where \CMAESpard is a real parameter in the range $[1,4]$ that controls the velocity at which the population grows, and  \CMAESRes (described below) determines the moment at which the increments take place.
%In the current version of \MetafoR, \CMAESPopInc can only be used when \CMAESRes is included in the implementation.


The \CMAESMtx algorithm component allows to adapt the covariance matrix in three different ways, \CMAESMtxCov, \CMAESMtxDia and \CMAESMtxCovDia. 
The \CMAESMtxCov option is the one described in \Eq~\ref{eq:CMAES_cma}, where the adaptation of the covariance matrix is done using a combination of the rank-one update %(i.e., the mean of the estimated covariance matrices using a single selected step) 
and the rank-$\mu$ update.
\CMAESMtxDia is a low complexity alternative for \CMAESMtx intended for separable functions, where the covariances are assumed to be zeros; therefore, instead of the full covariance matrix, \CMAESMtxDia uses a diagonal matrix similar to matrices $U_1$ and $U_2$ in \PSO (see \Eq~\ref{eq:psoVelocity}). 
The \CMAESMtxCovDia option allows to start the implementation using \CMAESMtxCov, and then, after $2+100 \times \frac{d}{\sqrt{\lambda}}$ FEs to switch to \CMAESMtxDia.

When used in the implementation, the algorithm component \CMAESRes performs two actions: first, it re-initializes the mean of the random sampling with a randomly generated solution; second, if \CMAESPopInc is used, it increases the population size according to \Eq~\ref{eq:CMAES_pop_increment}. 
\CMAESRes is a boolean algorithm component that becomes \textsf{true} if either the range of improvement of (i) all function values of the most recent generation, (ii) the best solution found in the last $[10 + \texttt{round}(30d/\lambda)]$ generations, or (iii) the standard deviation of the normal distribution falls below a certain threshold.
\CMAESmod keeps the information related to (i), (ii) and (iii) in variables \texttt{stopTolFun}, \texttt{stopTolFunHist} and \texttt{stopTolX}, respectively, and 
%To know if \CMAESRes has become \textsf{true}, \CMAESmod 
iteratively verifies the conditions that make \CMAESRes $= \textsf{true}$, namely:
$\texttt{stopTolFun} \leq 10^{\CMAESpare}$,
$\texttt{stopTolFunHist} \leq 10^{\CMAESparf}$, or
$\texttt{stopTolX} \leq 10^{\CMAESparg}$,
where \CMAESpare, \CMAESparf and \CMAESparg are real parameters in the range $[-20, -6]$.

The last algorithm component in \CMAESmod is \CMAESRW. 
This component is used to specify the weighting scheme used during recombination and it can be implemented using options \CMAESRWlog, \CMAESRWlindec and \CMAESRWeq.
The \CMAESRWlog option is the one shown in \Eq~\ref{eq:CMAES_weighting}, where weights decrease in a logarithmic fashion.
Differently, \CMAESRWlindec is defined as $w^{i} = (\lambda - i-1)/\sum_{k=0}^{\mu-1}\big(\lambda-k\big)$ for $i=1\dots\mu$, and \CMAESRWeq is defined as $w^{i} = 1/\mu $ for all $i$.

% cmaes_par_a; //parameter a in the computation of population size, i.e., lambda = 4 + floor(a ln(n))
% /might not be useful, perhaps it is better to set the initial vaue of lambda in a range, such as [3, n]
% cmaes_par_b; //parameter b in the computation of parent size, i.e., mu = lambda / b
% /fraction of the population that will be selected as parents 1 = same as the number of offspring, 2= half, 3= a third, and so on.
% cmaes_par_c; //parameter c in the computation of the initial step size, i.e., c(B-A)
% /threshold value for the stepsize of CMA-ES (i.e. stddev in all coordinates dropping) that triggers a
% cmaes_par_d; //IPOP factor d, i.e., lambda = d * population
% /controls the increase factor of the population
% cmaes_par_e; //parameter e in 10^e for the stop criterion considering "all function values of the recent generation"
% /for stopTolFun -- stop if function value differences are smaller than stopTolFun, default=1e-12
% cmaes_par_f; //parameter f in 10^f that replaces the stop criterion considering "the range of the improvement of the best objective function values in the last [10 + round(30d/lambda)] generations"
% /for stopTolFunHist -- stop if function value differences of best values are smaller than stopTolFunHist, default=1e-13
% cmaes_par_g; //parameter g in 10^g for the stop criterion considering "the standard deviation of the normal distribution in all coordinates"
% /for stopTolX -- stop if step sizes/steps in x-space are smaller than TolX, default=1e-11


\subsection{\DEmod}\label{sec:The De module}
\DEmod was developed considering some of the most popular variants of \DE published in the literature~\cite{DasSug2011:tec,VerCarKon2023:autoDE:gecco}.
\DE implementations are typically referred to using a mnemonic of the form \DE/\textit{term\_2}/\textit{term\_3}/\textit{term\_4}, where \textit{term\_2} indicates the way in which the base vector is chosen, \textit{term\_3} indicates the number of vector differences added to the base vector, and \textit{term\_4} indicates the number of values donated by the mutant vector (see \Sect~\ref{sec:DEall} for details). 
Some popular variants of \DE indicated using their mnemonics are \textit{DE/rand/1/bin} (classic \DE), 
%\textit{DE/best/1/bin with uniform jitter}, 
\textit{DE/target-to-best/1/bin}, and \textit{DE/rand/1/exp}.
The implementations created with \DEmod can be referred to in a similar way using the following extended mnemonic:
\begin{equation} 
\label{eq:GeneralizedDEmnemonic}
\textrm{\DE/\DEBaseVect/\DEVectDifferences/\DERcb/\DEVect/\VectBasis}
\end{equation}
where \DEBaseVect, \DEVectDifferences and \DERcb refer to the same concepts as \textit{term\_2}, \textit{term\_3} and \textit{term\_4} in the original mnemonic, \DEVect indicates the solution vectors 
%(i.e., current solution or personal best solutions) 
used to compute the vector differences, and \VectBasis indicates the vector basis used in the implementation.
%(i.e., eigenvector basis or natural basis).
In \DEmod, the population is handled using the algorithm component \Pop (already described in \Sect~\ref{sec:The PSOX module}) with the exact same options available (i.e., \PopConst, \PopIncre and \PopTV).

The algorithm component \DEBaseVect determines the way the base vector (vector $\vec{x}^{a}$ in \Eq~\ref{eq:DE_mutation}) is chosen.
\DEBaseVect provides five options for its implementation: \DEBVrand, \DEBVbest, \DEBVttbest, \DEBVdirRand and \DEBVdirBest. 
The first three options are the most commonly used in popular \DE variants. In \DEBVrand the base vector is chosen at random; in \DEBVbest the base vector is the best-so-far solution; and in \DEBVttbest the base vector lies between the target vector and the best-so-far solution. % (similar to the way particles move toward the \textit{g}best solutions in \PSO).
The implementation options \DEBVdirRand and \DEBVdirBest seek to incorporate information from the objective function into the creation of the mutant vector.
When options \DEBVdirRand and \DEBVdirBest are used, the creation of the mutant vector is done as follows:
\begin{equation}
\label{eq:DE_mutation_directed}
\vec{m}^{i} = \vec{x}^{a} + \frac{\beta}{2} \cdot(\vec{x}^{a}-\vec{x}^{b}-\vec{x}^{c}),
\end{equation}
where $\vec{x}^{a}$, $\vec{x}^{b}$ and $\vec{x}^{c}$ are chosen at random, with $f(\vec{x}^{a}) \leq \{ f(\vec{x}^{b}),f(\vec{x}^{c})\}$.
The only difference between \DEBVdirBest and \DEBVdirRand is that, in \DEBVdirBest, $\vec{x}^{a}$ is the best solution found so far.
The numerical parameter $\beta \in (0,1]$ scales the vector differences added to the base vector and is divided by the number of vector differences when there are more than one, as shown in \Eq~\ref{eq:DE_mutation_directed}.

The number of vector differences added to a base vector is computed by the algorithm component \DEVectDifferences.
Although most implementations of \DE only add one or two vector differences, \DEVectDifferences allows to add up to a quarter of the population size as vector differences. %, which is an idea similar to the use of the \MoiFI in \PSO.
In practice, \DEVectDifferences takes into account the option implemented for \DEBaseVect and assigns to each individual in the population the set of solutions that will be used to create its mutant vector.
Also, when options \PopIncre or \PopTV are used, \DEVectDifferences adjusts the number of vector differences according to the current population size.

The \DERcb component specifies the type of recombination (\DERcbcomp) used in the implementation.
The options available for implementing \DERcb are \DERcbBinomial and \DERcbExponential.
The option \DERcbBinomial, a.k.a. uniform random, is the one shown in \Eq~\ref{eq:DE_recombination} in \Sect~\ref{sec:DEall}, where the number of values donated by the mutant vector follows a binomial distribution.
Differently, in the \DERcbExponential (or two-point modulo), the number of values donated by the mutant vector follows an exponentially distributed random variable.
The fraction of values copied from the mutant vector into the trial vector during recombination is controlled by the 
parameter $p_a$ (see \Eq~\ref{eq:DE_recombination}), whose value is a real number in the range $[0, 1]$. 
%and can be computed in many different ways \cite{PriStoLam2005:book,DasSug2011:tec,VerCarKon2023:autoDE:gecco}.
%In the current version of \MetafoR, $p_a$ is considered only as a numerical parameter of \DEmod and, similarly to parameter $\beta$, its value remain constant during the algorithm's execution.

In addition to the typical algorithm components used in \DE implementations, \DEmod includes components \DEVect and \VectBasis.
The algorithm component \DEVect allows to use different types of solutions when creating a mutant vector.
The options available to implement \DEVect are \DEVectPos, which uses the current solutions (most \DE implementations used this option); \DEVectPbest, where individuals keep track of their the personal best solutions and use them to compute the mutant vector (an idea borrowed from \PSO); and \DEVectMix, which uses a combination of the current and personal best solutions.
On the other hand, the algorithm component \VectBasis allows to rotate the coordinate system of the vectors involved in \DERcb.
The two options available for the \VectBasis component are \VBnatural, which uses the natural basis (i.e., no rotation is performed), and \VBeigen, which computes the eigenvector basis of the population and uses it to perform the rotation.
When \VBeigen is used, the mutant and target vectors are rotated in the direction of the eigenvector before applying \DERcb, and then, after \DERcb takes place, they are rotated back to the natural basis to apply selection.

\DEmod has two algorithm components specifically designed to facilitate the creation of component-based \PSO and \DE hybrids.
The first one, \DERecompVel specifies the type of update performed to the velocity vector ($\vec{v}^{\,i}_t$ ) when \DE, which has precedence over \PSO in component-based \PSO and \DE hybrids, finds a better solution.
In this case, the velocity vector of the particle does not correspond anymore to its position, which can negatively impact the application of \PSO.
To fix this issue, \DERecompVel recomputes the velocity vector of the particle according to one of the following strategies: \DERVgoBack (proposed by Boks \etal \cite{BokWanBac2020:gecco-PSO-DE}), where $\vec{v}^{\,i}_t$ is recomputed as the difference between the new solution found by the application of \DE ($\vec{x}^{\,i,\text{DE-new}}_{t}$) and the previous current solution ($\vec{x}^{\,i}_{t}$), that is, $\vec{v}^{\,i}_t = \vec{x}^{\,i,\text{DE-new}}_{t} - \vec{x}^{\,i}_{t}$; \DERVrandom, where $\vec{v}^{\,i}_t$ is regenerated at random; \DERVposition, where $\vec{v}^{\,i}_t = \vec{x}^{\,i}_{t}$; and \DERVnone, where no update is done to $\vec{v}^{\,i}_t$.
The second algorithm component, called \PSOonFail, is the one proposed in the \DE-\PSO hybrid by Pant \etal \cite{PanThaGro08:ieee-dim}.
As its name suggests, \PSOonFail is used to specify that \PSO is applied only when \DE failed to produce a new better solution.
Since the number of FEs used per iteration by \textsf{components-based} hybrids of \DE and \PSO is twice the size of the population, \PSOonFail can lower this number by preventing the application of \PSO after $\vec{x}^{\,i}_{t}$ has already been improved by \DE.


%% TODO: Implement the following components in the framework:
%and ``either-or'', which means that the trial vector is either a three-vector recombination or a randomly chosen population vector to which a randomly chosen vector difference has been added.  
%Finally, the term ``uniform jitter'' indicates that the scaling factor becomes a random variable $\beta^{k}$ that is sampled anew from a normal distribution $\mathcal{N}(0,1)$ for each dimension $k$ of a vector.
%\DEVectPbest only mutation (the current version is pbest both mutation, recombination and selection.



\subsection{\LSmod}\label{sec:The Ls module}
\LSmod allows to interleave the execution of \MetafoRModules with a subordinate local search.
The execution of the \ls algorithm is controlled by two parameters, \LSbudget and \LSdivide.
\LSbudget, which is a real number in the range $(0,1]$, indicates what percentage of the total number of FEs is allocated to \ls, whereas \LSdivide, which is an integer in the range $[1,100]$, specifies the number of independent runs of the \ls in the implementation.
For example, setting $\LSbudget =0.25$ and $\LSdivide =10$ produces 10 independent runs of the \ls, where each run has a maximum budget of $(0.25 \cdot \mathrm{total\,number\,of\,function\,evaluations})/10$.
If the \ls algorithm reaches the value of \LSdivide without finishing its budget, \LSmod adds extra runs, one at a time per iteration, until there is no more budget available.

The two \ls algorithms that can be implemented using \LSmod are \CMAES and \MTSLS.
Although the implementation of \CMAES as \ls is also done via \CMAESmod with the exact same available options and parameters (see \Sect~\ref{sec:The CMAES module}), each \CMAES instance is treated independently in \MetafoR.
In other words, in a single \MetafoR implementation, it is possible to have two instances of \CMAES, one as (or part of) the main optimization algorithm, and another as \ls, each with its own algorithm components and parameter values.
Whatever the type of implementation, \LSmod uses as input for the \ls algorithm the best solution found so far ($\vec{x}^\text{best}$), which in the case of \CMAES is used as mean for the random sampling, and in the case of \MTSLS as starting solution.

The implementation of \MTSLS works as described in \Sect~\ref{sec:Local search strategies for cops} and has three parameters associated: \MTSLSinitss, which is the initial step size, \MTSLSiterations, which is an integer in the range $[1,3]$ that  determines the number of iterations per run of \MTSLS, and \MTSLSbias, which is a real number in the range $[-1,1]$ that controls how close a randomly generated solution is to $\vec{x}^\text{best}$.
In our implementation of \MTSLS, solutions that exceed the boundaries of the search space are penalized by adding the sum of the squares of their offsets to the function evaluation. This ensures that the farther a solution is from the search space, the greater the penalty it incurs.
At the end of each iteration, \MTSLS tests for convergence using $\vert f(\vec{s}) - f(\pvec{s}') \vert \leq 10^{-20}$, where $\vec{s}$ is the initial solution and $\pvec{s}'$ the improved solution.
If the convergence test is positive, the value of \MTSLSinitss is reinitialized to a random number sampled from $\mathcal{U}[0.3,0.6]$.
After completing one iteration, if no improvement was made or if the improvement was smaller than $10^{-20}$, \MTSLS generates a random starting solution for the next iteration as follows: 
$s_j = \mathcal{U}[lb_j,ub_j] + \big( (1-\MTSLSbias)\cdot\mathcal{U}[0,1] + \MTSLSbias \big) \cdot (x_j^{\text{best}}-\mathcal{U}[lb_j,ub_j])$ for $j=1\dots d$.


\subsection{The \Execution algorithm component}\label{sec:The Execution module}
Based on the literature review in \Sect~\ref{sec:Previous works on hybridization}, we developed an algorithm component called \Execution that allows to replicate the way in which hybrids of \algInPaper are created.
The three options available to implement \Execution are \ExecutionCB, \ExecutionPB and \ExecutionMP.
The \ExecutionCB option (available for each module when used standalone and for \PSOmod and \DEmod when used together) allows users to compose an algorithm by selecting individual algorithm components from different modules.

Differently, in the \ExecutionPB option (available only for \PSOmod and \DEmod), each module is applied probabilistically based on parameter $pr \in [0, 1]$, so that the probability of updating a solution using the first module is $pr$ and the probability of updating it using the second module is $1-pr$.
\ExecutionPB provides three options to sample random numbers to compare with the value of $pr$, \ExecutionPBuni, which uses a uniform distribution $\mathcal{U}(0,1)$, \ExecutionPBnor, which uses a normal distribution $\mathcal{N}(0,\,\ExecutionParStd)$, and \ExecutionPBlev, which uses a Lévy distribution $\mathcal{L}(0,\, \ExecutionParStd,\, \gamma_t)$.
In both \ExecutionPBnor and \ExecutionPBlev, the mean of the distribution is 0 and the standard deviation is controlled by the parameter \ExecutionParStd.
In the case of \ExecutionPBlev, $\gamma_t$ is a real parameter that controls the sharpness of the distribution and its value is sampled from a discrete uniform distribution $\mathcal{U}\lbrace10, 20\rbrace$, so that the probability of generating a random value in the tail of the distribution varies iteration by iteration---see \cite{RicBla2006levyPSO} for details.

\ExecutionMP (available for all four modules) is similar to \ExecutionPB, but instead of a probability, the user gives a computational budget $xb$ to each module that determines the number of consecutive FEs the module can use. \ExecutionMP divides the total number of FEs among the different modules based on their assigned budget $xb$ and applies each module until $xb$ is over, one module after the other, e.g., \PSOmod, followed by \DEmod, followed by \CMAESmod. 
%In the current version of \MetafoR, \ExecutionMP normalizes the sum of the values $xb$ to 1, so that each module is applied only once per run of the 
%but a module can only start once the previous one has finished its assigned budget. % thus resulting in a two or three phases hybrid implementation.
%, where each phase has a predefined budget $xb$ that specifies its duration. 


\subsection{Algorithm template used by \texorpdfstring{\MetafoR}~}\label{sec:Algorithm template used by MetafoR}

\begin{algorithm}
{\small %\fontsize{6.5}{6.5}\selectfont
	\caption{High-level structure of the algorithm template used by \MetafoR}\label{alg:genMetafor}
	\begin{algorithmic}[1]
		\Require Set of \textsf{parameters ($\Pi$)} %\Comment{e.g. \texttt{pop}$_{size}$, $t_{max}$, etc.}
		\State \texttt{config} $\gets$ \Call{Validate}{}($\Pi$, \MetafoRModulesAlg) \label{alg:line:validate}
		\State \texttt{exec} $\gets$ \Call{SetExecutionMode}{}(\texttt{config.get(\Execution})) \label{alg:line:initExec}
		\State \texttt{pop} $\gets$ \Call{Initialize}{}(\texttt{config.get(\Pop)}, \texttt{config.getDynamic}) \label{alg:line:initPop}
		\Repeat \label{alg:line:main_loop_start}
		\For{$i \gets 1$ \textbf{to} size(\texttt{pop})} \label{alg:line:updatePopLoop:begin}
		\State \texttt{pop}$^{\,i}$ $\gets$ \Call{UpdateSolution}{}(\texttt{pop}$^{\,i}$, \texttt{exec}) \label{alg:line:updatePop}
		\EndFor \label{alg:line:updatePopLoop:end}
		
		\State \texttt{best} $\gets$ \Call{GetBestSolution}{}(\texttt{pop})\label{alg:line:getBest}
		
		\If{\LSmod is \texttt{enabled}} \label{alg:line:isLocalSearchEnabled}
		\State \Call{PerformLocalSearch}{\texttt{best}, \texttt{config.getLS}}\label{alg:line:applyLocalSearch}
		\EndIf
		
		\State apply \Reinit \Comment{optional} \label{alg:line:reinitializeSolutions}
		\State \texttt{pop} $\gets$ \Call{UpdatePopulationParameters}{\texttt{config.get(\Pop)}, \texttt{config.getDynamic}} \label{alg:line:popoParamUpdate}
		\State \texttt{exec} $\gets$ \Call{UpdateExecutionParameters}{}(\texttt{exec})\label{alg:line:execVariablesUpdate}
		\Until{termination criterion is met} \label{alg:line:main_loop_end}
		\State \textbf{return} \texttt{best}
	\end{algorithmic}
}
\end{algorithm}

In \MetafoR, the algorithm components that make up a \mh implementation are combined using \Alg~\ref{alg:genMetafor}.
As shown in line~\ref{alg:line:validate} of \Alg~\ref{alg:genMetafor}, after receiving the set of \textsf{parameters} $\Pi$, the first action performed by \MetafoR is to validate their values and dependence.
The procedure \textsc{Validate()} checks that the set of parameters input by the user are within the defined limits and that there are no conflicting or missing options. 
For example, if the user executes \MetafoR indicating the use of \CMAESmod and \DEmod, but the parameters needed to create the implementation are incomplete or their values are out range, \textsc{Validate()} stops the execution and prints out the missing, conflicting and/or out-of-range values.
If \textsc{Validate()} ends successfully, it creates an object called \texttt{config} that stores the options with which \MetafoR is executed.
\MetafoR has implemented different ways to access \texttt{config}, for example, \texttt{config.get($\cdot$)} retrieves the algorithm component option or parameter value indicated as argument, \texttt{config.getLS} retrieves the set of parameters used by \LSmod, and \texttt{config.getDynamic} retrieves the set of algorithm components and parameters whose value change over time, such as \TopTVFI, %\OmegaSelfReg, \MagSucc, \PhiTV, 
\CMAESPopInc, \CMAESMtxCovDia, etc.

In line~\ref{alg:line:initExec}, the procedure \textsc{SetExecutionMode}() is performed to initialize the variables required by the algorithm component \Execution, such as the probability $pr$ and the execution budget $xb$.
Then, in line~\ref{alg:line:initPop}, the procedure \textsc{Initialize}() creates the initial population (\texttt{pop}) and initializes the variables and structures needed to handle the population throughout the execution. 
\textsc{Initialize}() also takes care of the structures and variables required by dynamic algorithm components, such as variable \texttt{t\_schedule} which is used to determine when connections are removed from \TopTVFI.

The main optimization process takes place inside the loop that goes from line~\ref{alg:line:main_loop_start} to line~\ref{alg:line:main_loop_end}. 
In line~\ref{alg:line:updatePop}, the \textsc{UpdateSolution}() procedure is applied to each individual in the population based on the type of \Execution implemented and the modules selected by the user.
When \texttt{exec} is set to \ExecutionCB, the same set of components is applied to every individual until the termination criterion is met. 
When \texttt{exec} is set to \ExecutionPB, the specific set of components applied to an individual alternates probabilistically based on the parameter $pr$. Finally, when \texttt{exec} is set to \ExecutionMP, two or three different modules are applied in a pipeline, where each module is assigned its own budget $xb$, and the execution of a module begins only after the budget of the previous module is exhausted.
The \textsc{UpdateSolution}() procedure also handles the update of the variable associated to each solution (e.g., the personal best solution vectors) and the algorithm components options that have to update solution-wise (e.g., \OmegaSelfReg, \MagSucc and \DEVectDifferences).
In line~\ref{alg:line:getBest}, after updating the population, the best solution is kept in the variable \texttt{best}. 

In line~\ref{alg:line:isLocalSearchEnabled}, \MetafoR checks whether \LSmod is enabled and, if this is the case, the procedure \textsc{PerformLocalSearch}() is executed in line~\ref{alg:line:applyLocalSearch} using the \texttt{best} solution as input.
If the \ls algorithm finds an improved solution, \textsc{PerformLocalSearch}() updates \texttt{best} with the new solution.
In line~\ref{alg:line:reinitializeSolutions}, the optional component \Reinit takes place.
There are two options for implementing \Reinit: \RIchange and \RIsimilarity.
\RIchange re-initializes the population if either of the following conditions is verified: (i) if the standard deviation of the solutions falls below $10^{-3}$, or (ii) if the total change in the objective function over the last $(10\cdot d)/\text{size}(\texttt{pop})$ iterations is less than $10^{-8}$.
The \RIsimilarity option computes the Euclidean distance between a solution and $\vec{x}^\text{best}$ and re-initializes those solutions whose distance to $\vec{x}^\text{best}$ is lower than $10^{-3}$.
Finally, in lines~\ref{alg:line:popoParamUpdate}--\ref{alg:line:execVariablesUpdate}, \MetafoR updates the variables and structures related to the population (\texttt{pop}) and the execution (\texttt{exec}).
The procedure \textsc{UpdatePopulationParameters}() also takes care of the dynamic algorithm components whose values have to be updated iteration-wise (e.g., \PopIncre, \TopTVFI and \CMAESMtxCovDia).

\MetafoR has a total of 104 parameters, of which 53 belong to \PSOmod, 5 to \DEmod, 9 to \CMAESmod, 15 to \LSmod, 7 to the algorithm component \Execution and 15 are shared by several modules (e.g. \Pop, \VectBasis, \Reinit, etc.).
As shown below in \Tbl~\ref{table:ParameterSettingsALL}, the actual number of parameters used in our automatically created implementations vary from as few as 10 parameters (e.g., \CMAESldo) to 32 parameters (e.g., \PCHybtfo).
In \MetafoR, optional algorithm components can simply be omitted from the set of execution parameters when they are not going to be used in the implementation.
% \todo{I think there should be said something on the number of parameters the system has. One can give the parameters for each of the modulus (\PSOmod, etc), how many parameters for switching between the moduls etc.}

%%%% Changes in the framework %%%%%
% - Add the traditional ES components to the CMAES code
% - Add arithmetic operators to DE


\section{Experimental Study}\label{sec:ExperimentalStudy}

%To evaluate the performance of \MetafoR, 
We conducted experiments on a set of 50 continuous functions belonging to the CEC'05 and CEC'14 "Special Session on Single Objective Real-Parameter Optimization" \cite{SugHanLia2005cec,LiaQu2013problem} and to the Soft Computing (SOCO'10) "Test Suite on Scalability of Evolutionary Algorithms and other Metaheuristics for Large Scale Continuous Optimization Problems" \cite{HerLozMol2010test}.\footnote{Due to space limitation, we refer the reader to the provided references for a complete description of the benchmark functions.}
The goal of using a benchmark set of functions composed of various test suites is to include as many as possible of the characteristics that make \cops difficult, 
%to assess the ability of the algorithms to solve optimization problems with complex characteristics, 
such as mathematical transformations (e.g., translations and rotations), multiple local optima and non-separable objective functions.
As shown in \Tbl~\ref{table:benchmark functions}, our benchmark set is composed of 12 unimodal functions ($f_{1-12}$), 14 multimodal functions ($f_{13-26}$), 14 hybrid functions ($f_{27-40}$), and 10 hybrid composition functions ($f_{41-50}$).
With the exception of $f_{41}$, none of the hybrid composition functions is separable, and functions $f_{42-50}$ include an additional rotation in the objective function.

\subsection{Benchmark functions}
\begin{table*}[ht!]
\centering
{\scriptsize
	\caption{Benchmark functions}
	\label{table:benchmark functions}
	\begin{tabular}{ c m{2.9cm} C{1.4cm} m{0.8cm} | C{0.3cm} m{4.7cm} C{1.2cm} m{0.8cm}}
		\toprule %\hlineB{5}
		\textbf{$f_{\#}$} & \textbf{Name} & \textbf{Search Range} & \textbf{Suite} & \textbf{$f_{\#}$} & \textbf{Name}  & \textbf{Search range} & \textbf{Suite}\\ 
		\midrule %\hlineB{3}
		$f_1$ & Shifted Sphere & [-100,100] & SOCO'10 & 
		$f_{26}$ & Shifted Rotated HGBat & [-100,100] & CEC’14 \\
		$f_2$ & Shifted Rotated High Conditioned Elliptic & [-100,100] & CEC'14 & 
		$f_{27}$ & Hybrid Function 1 (N = 2) & [-100,100] & SOCO'10 \\
		$f_3$ & Shifted Rotated Bent Cigar  & [-100,100] & CEC’14 & 
		$f_{28}$ & Hybrid Function 2 (N = 2) & [-100,100] & SOCO'10 \\
		$f_4$ & Shifted Rotated Discus & [-100,100] & CEC’14 & 
		$f_{29}$ & Hybrid Function 3 (N = 2) & [-5,5] & SOCO'10 \\
		$f_5$ & Shifted Schwefel 22.1 & [-100,100] & SOCO'10 & 
		$f_{30}$ & Hybrid Function 4 (N = 2) & [-10,10] & SOCO'10 \\
		$f_6$ & Shifted Schwefel 1.2 & [-65.536,65.536] & SOCO'10 & 
		$f_{31}$ & Hybrid Function 7 (N = 2) & [-100,100] & SOCO'10 \\
		$f_7$ & Shifted Scfewels12 noise in fitness & [-100,100] & CEC’05 & 
		$f_{32}$ & Hybrid Function 8 (N = 2) & [-100,100] & SOCO'10 \\
		$f_8$ & Shifted Schwefel 2.22 & [-10,10] & SOCO'10 & 
		$f_{33}$ & Hybrid Function 9 (N = 2) & [-5,5] & SOCO'10 \\
		$f_9$ & Shifted Extended $f_{10}$ & [-100,100] & SOCO'10 & 
		$f_{34}$ & Hybrid Function 10 (N = 2) &  [-10,10] & SOCO'10 \\
		$f_{10}$ & Shifted Bohachevsky & [-100,100] & SOCO'10 & 
		$f_{35}$ & Hybrid Function 1 (N = 3) & [-100,100] & CEC’14 \\
		$f_{11}$ & Shifted Schaffer & [-100,100] & SOCO'10 & 
		$f_{36}$ & Hybrid Function 2 (N = 3) & [-100,100] & CEC’14 \\
		$f_{12}$ & Shchwefel 2.6 Global Optimum on Bounds & [-100,100] & CEC’05 & 
		$f_{37}$ & Hybrid Function 3 (N = 4) & [-100,100] & CEC’14 \\
		$f_{13}$ & Shifted Ackley & [-32,32] & SOCO'10 & 
		$f_{38}$ & Hybrid Function 4 (N = 4) & [-100,100] & CEC’14 \\
		$f_{14}$ & Shifted Rotated Ackley & [-100,100] & CEC’14 & 
		$f_{39}$ & Hybrid Function 5 (N = 5) & [-100,100] & CEC’14 \\
		$f_{15}$ & Shifted Rosenbrock & [-100,100] & SOCO'10 & 
		$f_{40}$ & Hybrid Function 6 (N = 5) & [-100,100] & CEC’14 \\
		$f_{16}$ & Shifted Rotated Rosenbrock & [-100,100] & CEC’14 & 
		$f_{41}$ & Hybrid Composition Function & [-5,5] & CEC’05 \\
		$f_{17}$ & Shifted Griewank & [-600,600] & SOCO'10 & 
		$f_{42}$ & Rotated Hybrid Composition Function & [-5,5] & CEC’05 \\
		$f_{18}$ & Shifted Rotated Griewank & [-100,100] & CEC’14 & 
		$f_{43}$ & Rotated H. Composition F. with Noise in Fitness & [-5,5] & CEC’05 \\
		$f_{19}$ & Shifted Rastrigin & [-100,100] & SOCO'10 & 
		$f_{44}$ & Rotated Hybrid Composition F. & [-5,5] & CEC’05 \\
		$f_{20}$ & Shifted Rotated Rastrigin & [-100,100] & CEC’14 & 
		$f_{45}$ & Rotated H. Composition F. with a Narrow Basin for the Global Opt. & [-5,5] & CEC’05 \\
		$f_{21}$ & Shifted Schwefel & [-100,100] & CEC’14 & 
		$f_{46}$ & Rotated H. Comp. F. with the Gbl. Opt. On the Bounds & [-5,5] & CEC’05 \\
		$f_{22}$ & Shifted Rotated Schwefel & [-100,100] & CEC’14 & 
		$f_{47}$ & Rotated Hybrid Composition Function & [-5,5] & CEC’05 \\
		$f_{23}$ & Shifted Rotated WeierStrass & [-100,100] & CEC’05 & 
		$f_{48}$ & Rotated H. Comp. F. with High Condition Num. Matrix & [-5,5] & CEC’05 \\
		$f_{24}$ & Shifted Rotated Katsuura & [-100,100] & CEC’14 & 
		$f_{49}$ & Non-Continuous Rotated Hybrid Composition Function & [-5,5] & CEC’05 \\
		$f_{25}$ & Shifted Rotated HappyCat & [-100,100] & CEC’14 & 
		$f_{50}$ & Rotated Hybrid Composition Function & [-5,5] & CEC’05 \\
		\bottomrule
	\end{tabular} 
}
\end{table*}



In addition to evaluating the performance of the algorithms on the characteristics aforementioned, we are interested in their scalability, especially for problems with more than 100 dimensions.
In order to test how well the algorithms scale to large dimensional (LD) problems, we use the functions of the SOCO'10 test suite ($f_{1,5,6,8-11,13,15,17,19,27-34}$) with 200, 500 and 1$\,$000 dimensions.
In contrast to the CEC'2005 and CEC'2014 test suites, which are primarily designed to test the performance of the algorithms on highly complex, multimodal functions, the SOCO'10 test suite contains problems whose complexity is mainly due to their large size.

\subsection{Experimental setup}\label{sec:experimental setup}
Our experimental study involves two phases: a \textit{training phase}, where we use \irace with different training instances to create and configure a number of algorithms; and a \textit{testing phase}, where we run the algorithms on different sets functions %(\Tbl~\ref{table:benchmark functions}) 
and measure aspects related to their performance.
To guarantee that the training set and the testing sets are different enough, we excluded the CEC'14 functions from the training set, and use only the CEC'05 and SOCO'10 test suites to define two different training scenarios.
%
For the first scenario, we created a training set of 88 functions by randomly selecting 75\% of the functions in the CEC'05 test suite and 75\% of the functions in the SOCO'10 test suite, where the selected CEC'05 functions use $d=\{10, 30, 50\}$ and the selected SOCO'10 functions use $d=\{500, 1\,000\}$.
We refer to this first scenario as \TFOUT, since "25\%" of the total number of instances were left "out" from the training set.
%For the second scenario, we also randomly selected 75\% of the CEC'05 functions with $d=\{10, 30, 50\}$, but included only 30\% of the SOCO'10 functions with $d=\{100, 200\}$, resulting in a total of 57 functions.
%We refer to the second scenario as \TFSLDO, where \texttt{SLDO} stands for "some largest dimensions out".
%Finally, for the third scenario, 
For the second scenario, we consider a leave-one-class-out cross-validation approach by creating a training set of 107 functions where all the functions from both test suites are included but only with a low dimensional number. In other words, we left out the large dimensional class and included the 25 functions of the CEC'05 suite with $d=\{10, 30\}$ and the 19 functions of the SOCO'10 suite with $d=\{50, 100, 200\}$.
We refer to this second scenario as \LDO, where \texttt{LDO} stands for "largest dimensions out". 
In \Tbl~\ref{table:instance distrubution per scenarios}, we show the percentage of functions of each class included in each training scenario and in the CEC'05, CEC'14 and SOCO'10 test suites.

\begin{table}
{\fontsize{6.5}{6.5}\selectfont
	\caption{Percentage of functions of each class in scenarios \TFOUT, \LDO and in the CEC'05, CEC'14 and SOCO'10 test suites.}
	\label{table:instance distrubution per scenarios}
	\begin{tabular}{c c c c c c c c l}
		\toprule
		\textbf{Scenario/Suite} &\textbf{\# of Functions} & \textbf{UNI (\%)} & \textbf{MUL (\%)} & \textbf{HYB and HCP (\%)} & \textbf{ROT (\%)} & \textbf{LD (\%)} & \textbf{Separable (\%)} & \textbf{$d$ Range} \\
		\toprule
		\multirow{2}{*}{\TFOUT}  & \multirow{2}{*}{88} & \multirow{2}{*}{24.75} & \multirow{2}{*}{32.75} & \multirow{2}{*}{42.5} & \multirow{2}{*}{36} & \multirow{2}{*}{31} & \multirow{2}{*}{17} & \fCECFIVE $d=\{10,30,50\}$,\\
		& & & & & & & & \fSOCO $d=\{500,1000\}$\\
		\multirow{2}{*}{\LDO} & \multirow{2}{*}{107} & \multirow{2}{*}{28.5} & \multirow{2}{*}{28.5} & \multirow{2}{*}{43} & \multirow{2}{*}{36} & \multirow{2}{*}{0}  & \multirow{2}{*}{16} & \fCECFIVE $d=\{10,30\}$,\\
		& & & & & & & & \fSOCO $d=\{50,100,500\}$\\ 
		CEC'05  & 25 per $d$ & 20    & 36    & 44   & 16 & 0  & 12 &  $d=\{2, 10,30,50\}$ \\
		CEC'14  & 22 per $d$ & 14    & 59    & 27   & 63 & 0  & 9  &  $d=\{2, 10,30,50, 100\}$\\
		SOCO'10 & 19 per $d$ & 37    & 21    & 42   & 0  & 100 & 21 &  $d=\{10, \dots, \infty\}$\\
		\bottomrule
	\end{tabular}
}
\end{table}


To design and configure the algorithms in our comparison, we used \irace with different computational budgets. %, depending on the size of the parameter space.
In the case of \CMAES and \DE, where the number of parameters is relatively small (less than 15 parameters), we used \irace with a budget of $10\,000$ executions, and in the case of \PSO and \MetafoR, which have 59 and 104 parameters, respectively, we used \irace with a budget of $30\,000$ and $50\,000$ executions.
In addition to these algorithms, we used \irace with a budget of $30\,000$ executions to create three hybrid implementations, a \PDHyb, a \DCHyb and a \PCHyb.
Our rationale was that, rather than manually selecting specific hybrids of \algInPaper for our comparison, it would be far more insightful to evaluate the performance of automatically generated hybrid implementations using the algorithm components and execution modes already implemented in \MetafoR.
By combining the seven parameter spaces (\MetafoR, \CMAES, \DE, \PSO, \PDHyb, \DCHyb and \PCHyb) and the two training scenarios (\TFOUT and \LDO), we produce a total of \textbf{14 algorithms}.
In the following sections, we study the performance of the 14 automatically created algorithms and \textbf{3 default variants} of \algInPaper using parameter settings.

In the reminder of this paper, we use the following abbreviations: "\MTF" for the implementations created using the entire search space of \MetafoR, "\StdPSO" for the \StanPSO algorithm, "DFT" for implementations using default parameter values, "UNI" for the unimodal functions ($f_{1-12}$), "MUL" for the multimodal functions ($f_{13-26}$), "HYB" for the hybrid functions ($f_{27-40}$), "HCP" for the hybrid composition functions ($f_{41-50}$), "ROT" for the rotated functions ($f_{2-4,6,14,16,18,20,22-26,42-50}$), "SHU" for the shifted unimodal functions in the SOCO'10 test suite ($f_{1,5,6,8-11}$).
We also use "\fCECFIVE", "\fCECFOURTEEN" and "\fSOCO" to refer, respectively, to the CEC'05, CEC'14 and SOCO'10 test suite, and we use "\fBENCHMARK" to refer to the benchmark set of 50 function shown in \Tbl~\ref{table:benchmark functions}.
The algorithm components and parameter settings of the \textbf{17 algorithms} included in our comparison 
%---3 variants of \algInPaper using default values and 14 automatically generated algorithms---
are shown in \Tbl~\ref{table:ParameterSettingsALL}.

\begin{ThreePartTable}
\begin{TableNotes}
	\scriptsize
	\item[*] Conditional parameters and variables are shown inside brackets, preceded by the algorithm components on which they depend.
	%In the case of \ExecutionMP and \ExecutionPB, the execution budgets $xb_{j}$ (for $j=1,\dots,n$) are normalized to 1.
	%For a detailed explanation of the parameters associated to the components that belong to \PSOmod, we refer the reader to \cite{CamDorStu2022:tec}.
	%In some case, we use the prefix \textsf{par\_} to indicate 
\end{TableNotes}

{\fontsize{6.5}{6.5}\selectfont
	\begin{longtable}{C{1cm} C{0.01cm} m{12.7cm}} %{@{} c | *{10}{c} @{}} %{ l c c c c c c c c c c c c c c c c}
		\caption{Parameter settings of the algorithms included in the comparison.}
		\label{table:ParameterSettingsALL}\\
		\toprule
		\multicolumn{2}{c}{\textbf{Algorithm}} & \multicolumn{1}{c}{\textbf{Settings}} \\
		\midrule
		\endfirsthead
		
		\caption*{ Table \ref{table:ParameterSettingsALL} (Continued.)}\\
		\toprule
		\multicolumn{2}{c}{\textbf{Algorithm}} & \multicolumn{1}{c}{\textbf{Settings}} \\
		\midrule
		\endhead
		
		\bottomrule
		%\insertTableNotes
		\endfoot
		
		\bottomrule
		\insertTableNotes  % tell LaTeX where to insert the contents of "TableNotes"
		\endlastfoot
		
		%%%%%%% Values here
		
		%Metafor
		\multicolumn{2}{c}\MTFtfo & \ExecutionMP (\CMAESmod, $xb_1 =0.8265$, \DEmod, $xb_2 =0.3535$), 
		$\CMAESpara=4.2552$, $\CMAESparb=2.2402$, $\CMAESparc=0.6247$, $\CMAESpard=3.6447$, $\CMAESpare=-18.3449$, $\CMAESparf=-19.0782$, $\CMAESparg=-14.4971$, \CMAESMtxDia, \CMAESRWlog, 
		\DEBVbest, $\DEVectDifferences=0.1198$, \DERcbBinomial, $p_a=0.4783$, $\beta=0.5197$, \VBeigen, \DEVectPos,
		\PopConst ($\texttt{pop}_{ini}=324$). \\
		\midrule
		\multicolumn{2}{c}\MTFldo & \ExecutionMP (\CMAESmod, $xb_1 =0.9154$, \DEmod, $xb_2 =0.1573$, \LSmod, $\LSbudget =0.579$ and $\LSdivide =3$), 
		\MTSLS ($\MTSLSbias =-0.0549$, $\MTSLSinitss = 0.3892$, $\MTSLSiterations =1.6483$), $\CMAESpara=7.7473$, $\CMAESparb=1.9539$, $\CMAESparc=0.6037$, $\CMAESpard=2.3443$, $\CMAESpare=-19.7597$, $\CMAESparf=-17.1491$, $\CMAESparg=-12.1016$, \CMAESMtxCovDia, \CMAESRWlog, 
		\DEBVdirRand, \DEVectDifferences$=0.0488$, \DERcbBinomial, $p_a=0.8117$, $\beta=0.3273$, \VBnatural, \DEVectPos, \PopConst ($\texttt{pop}_{ini}=252$),
		\RIsimilarity. \\
		
		%CMAES
		\midrule
		\multicolumn{2}{c}\CMAESdft & \ExecutionCB (\CMAESmod), $\CMAESpara=3$, $\CMAESparb=2$, $\CMAESparc=0.5$, $\CMAESpard=2$, $\CMAESpare=-12$, $\CMAESparf=-20$, $\CMAESparg=-12$, \CMAESMtxCov, \CMAESRWlog. \\
		\midrule
		\multicolumn{2}{c}\CMAEStfo & \ExecutionCB (\CMAESmod),
		$\CMAESpara=9.3314$, $\CMAESparb=3.9293$, $\CMAESparc=0.1237$, $\CMAESpard=3.7189$, $\CMAESpare=-14.5256$, $\CMAESparf=-15.7226$, $\CMAESparg=-16.3546$, \CMAESMtxDia, \CMAESRWlog. \\
		\midrule
		\multicolumn{2}{c}\CMAESldo & \ExecutionCB (\CMAESmod), $\CMAESpara=3.6811$, $\CMAESparb=2.8753$, $\CMAESparc=0.1583$, $\CMAESpard=3.8432$, $\CMAESpare=-19.9498$, $\CMAESparf=-19.7584$, $\CMAESparg=-14.4405$, \CMAESMtxDia, \CMAESRWlog. \\
		
		%DE
		\midrule
		\multicolumn{2}{c}\DEdft & \ExecutionCB (\DEmod), \VBnatural, \DEBVbest, $\DEVectDifferences=1$, \DERcbBinomial, $p_a=0.5$, $\beta=0.9$, \PopConst ($\texttt{pop}_{ini}=d$). \\
		\midrule
		\multicolumn{2}{c}\DEtfo & \ExecutionCB (\DEmod), \VBnatural, \DEBVbest, $\DEVectDifferences=0.0151$, \DERcbExponential, $p_a=0.3566$, $\beta=0.2614$, 
		\PopTV ($\texttt{pop}_{ini}=39$, $\texttt{pop}_{min}=39$, $\texttt{pop}_{max}=132$, $\texttt{pop}_{sch}=26$, \InitRandom). \\
		\midrule
		\multicolumn{2}{c}\DEldo & \ExecutionCB (\DEmod), \VBnatural, \DEBVbest, $\DEVectDifferences=0.1711$, \DERcbExponential, $p_a=0.2105$, $\beta=0.197$, \PopIncre ($\texttt{pop}_{min}=46$, $\texttt{pop}_{max}=69$, $\texttt{pop}_{add}=5$, \InitHorizontal). \\
		
		%PSO
		\midrule
		\multicolumn{2}{c}\StdPSOdft & \ExecutionCB (\PSOmod), \DNPPRect, \TopFC, \MoiBoN, \MtxDiagonal, \OmegaCons ($\omega_{1} =0.749$), $\omega_{2} = 1$, \PopConst ($\texttt{pop}_{ini}=40$), $\varphi_1 = 1.496180$, $\varphi_2 = 1.496180$, \VelClp. \\
		\midrule
		\multicolumn{2}{c}\PSOtfo & \ExecutionCB (\PSOmod), 
		\VBnatural, \OperatorS, \TopWheel, \MoiRFI, $\varphi_1 = 0.0967$, $\varphi_2 = 0.9359$, \OmegaRnkBsd ($\omega_{1,min} = 0.6134$, $\omega_{1,max} = 0.944$), $\omega_{2} = \omega_{1}$, $\omega_{3} = 1$, \PertGau (\MagSucc, $pm_{1}= 0.211$, $\textsf{par\_sc}_1 = 46$, $\textsf{par\_fc}_1 = 24$), \PertRect (\MagSucc $pm_{2}= 0.498$, $\textsf{par\_sc}_2 = 45$, $\textsf{par\_fc}_2 = 42$), 
		\PopIncre ($\texttt{pop}_{min}=5$, $\texttt{pop}_{max}=20$, $\texttt{pop}_{add}=2$, \InitHorizontal). \\
		\midrule
		\multicolumn{2}{c}\PSOldo & \ExecutionCB (\PSOmod), \VBnatural, \DNPPRect, \MoiBoN, \TopTVFI ($\textsf{par\_tSch} =8$), \PhiExtra, \OmegaLinDec ($\omega_{1,min} = 0.1156$, $\omega_{1,max} =0.4517$, $\omega_{sch} =5$), $\omega_{2} = \OmegaRnd$, \PertLev (\MagSucc, $\PMcomp_{1}= 0.8248$, $\textsf{par\_sc}_1 = 2$, $\textsf{par\_fc}_1 = 32$), \MtxEuclideanOne ($\textsf{par\_angle}=7$), \PopIncre ($\texttt{pop}_{min}=2$, $\texttt{pop}_{max}=34$, $add(\texttt{pop})=8$, \InitRandom),
		\VelClp, \StagDet, \RIchange. \\
		
		%PSO - DE
		\midrule
		\multicolumn{2}{c}\PDHybtfo & \ExecutionMP (\DEmod, $xb_1 =0.7385$, \PSOmod, $xb_2 =0.9477$, \ExecutionPBuni, $\ExecutionParStd =0.7304$) 
		\VBnatural, \OmegaCons ($\omega_{1} =0.0205$), $\omega_{2} = \OmegaRnd$, \OperatorN, \MoiBoN, \TopTVFI ($\textsf{par\_tSch}= 9$), \DEBVttbest, $\DEVectDifferences=0.0477$, \DERcbExponential, $p_a=0.8266$, $\beta=0.7779$, \DEVectMix, 
		\PopConst ($\texttt{pop}_{ini}=24$). \\
		\midrule
		\multicolumn{2}{c}\PDHybldo & \ExecutionPB (\DEmod, $xb_1 =0.6355$, \PSOmod, $xb_2 =0.6838$), \ExecutionPBlev ($\ExecutionParStd =0.4762$), \VBnatural, \OperatorN, \TopNeum, \MoiBoN, \OmegaSuccBsd ($\omega_{1,min} = 0.1178$, $\omega_{1,max} =0.6264$), $\omega_{2} =1$, \DEBVbest, $\DEVectDifferences=0.0801$, \DERcbExponential, $p_a=0.3857$, $\beta=0.3817$, \DEVectPos, \PopTV ($\texttt{pop}_{ini}=29$, $\texttt{pop}_{min}=18$, $\texttt{pop}_{max}=253$, $\texttt{pop}_{sch}=71$, \InitRandom). \\
		
		%DE - CMAES
		\midrule
		\multicolumn{2}{c}\DCHybtfo & \ExecutionMP (\CMAESmod, $xb_1 =0.8695$, \DEmod, $xb_2 =0.2598$),
		$\CMAESpara=7.7115$, $\CMAESparb=1.4923$, $\CMAESparc=0.4212$, $\CMAESpard=3.4793$, $\CMAESpare=-18.5851$, $\CMAESparf=-18.072$, $\CMAESparg=-14.2609$, \CMAESMtxCovDia, \CMAESRWlog, \DEBVrand, $\DEVectDifferences=0.1683$, \DERcbExponential, $p_a=0.9742$, $\beta=0.339$, \DEVectPos, \VBnatural,
		\PopConst ($\texttt{pop}_{ini}=66$),
		\RIsimilarity. \\
		\midrule
		\multicolumn{2}{c}\DCHybldo & \ExecutionMP (\CMAESmod, $xb_1 =0.8677$, \DEmod, $xb_2 =0.7543$), 
		$\CMAESpara=4.2166$, $\CMAESparb=1.7168$, $\CMAESparc=0.1898$, $\CMAESpard=3.4845$, $\CMAESpare=-19.8045$, $\CMAESparf=-19.7732$, $\CMAESparg=-18.6365$, \CMAESMtxDia, \CMAESRWlog,
		\VBeigen, \DEBVdirRand, $\DEVectDifferences=0.1658$, \DERcbBinomial, $p_a=0.96$, $\beta=0.5775$, \DEVectPos, \PopConst ($\texttt{pop}_{ini}=459$). \\
		
		%PSO - CMAES
		\midrule
		\multicolumn{2}{c}\PCHybtfo & \ExecutionMP (\CMAESmod, $xb_1 =0.9695$, \PSOmod, $xb_2 =0.2238$),
		\VBnatural, \OperatorCG (\OperatorQrandNeigh, $\textsf{parm\_r} = 0.4139$), \TopNeum, \MoiFI, \OmegaDoubExp ($\omega_{1,max} = 0.2985$), $\omega_{2} = 0.2569$, \PertLev (\MagCons, $pm_{1} = 0.2303$), 
		$\CMAESpara=9.0134$, $\CMAESparb=1.2005$, $\CMAESparc=0.7269$, $\CMAESpard=3.1025$, $\CMAESpare=-19.9248$, $\CMAESparf=-19.8913$, $\CMAESparg=-17.4091$, \CMAESMtxCovDia, \CMAESRWlog, 
		\PopTV ($\texttt{pop}_{ini}=181$, $\texttt{pop}_{min}=38$, $\texttt{pop}_{max}=367$, $\texttt{pop}_{sch}=23$, \InitHorizontal),
		\RIchange. \\
		\midrule
		\multicolumn{2}{c}\PCHybldo & \ExecutionMP (\CMAESmod, $xb_1 =0.9543$, \PSOmod, $xb_2 =0.2452$), \VBnatural, \OperatorCG (\OperatorQrandNeigh, $\textsf{parm\_r}= 0.7225$), \TopTVFI, \MoiFI, $\textsf{par\_tSch} =10$), \OmegaCons ($\omega_{1} =0.9485$), $\omega_{2} = \omega_{1}$, 
		$\CMAESpara=8.3477$, $\CMAESparb=2.3073$, $\CMAESparc=0.8218$, $\CMAESpard=2.9854$, $\CMAESpare=-19.3423$, $\CMAESparf=-19.4916$, $\CMAESparg=-19.1069$, \CMAESMtxCovDia, \CMAESRWlog, \PopIncre ($\texttt{pop}_{min}=22$, $\texttt{pop}_{max}=489$, $\texttt{pop}_{add}=1$, \InitHorizontal),
		\RIsimilarity. \\
	\end{longtable}
}
\end{ThreePartTable}

For the testing phase, we perform 50 independent runs of each of the 17 algorithms on each function and report the median (MED) solution produced by the algorithms, the median solution error (MEDerr) with respect to the best solution found by any of them, the median absolute deviation (MAD) and the wall-clock execution time in seconds.
In all cases, the algorithms were stopped after reaching $5\,000 \times d$ objective FEs or a wall-clock time of 600 seconds for $d \leq 50$, $1\,800$ seconds for $50 < d \leq 100$, $6\,000$ seconds for $100 < d \leq 500$, and $9\,000$ seconds for $500 < d \leq 1\,000$.
%Rack 5 nodes have 2 INTEL Xeon E5-2680 v3 CPUs with 12x2.5Ghz cores each, and 2.4GB of RAM for your job
Both the tuning and the testing of the algorithms were done on dual core AMD Epyc Rome 7452 running at 2.2 GHz with 512 Kb cache size under \texttt{Rocks Mamba GNU/Linux CentOS 6.3}.
The version of \irace is 3.5.
\MetafoR is coded in \texttt{C++}, was compiled using \texttt{gcc} 9.4.0 and its source code is publicly available from: \url{https://github.com/clcamachov/METAFOR}.

\subsection{Analysis of Results}
We divide our experiments into three parts.
In the first part, we investigate the advantages that hybrid designs have over default and configured single-approach implementations.
Our goal is to identify both the approaches that work best for each class of functions and the main algorithm components responsible for their performance. 
To do this, we compare the result obtained by nine variants of \algInPaper with the six automatically generated hybrids of these approaches on \fBENCHMARK with $d=50$. % and $f_{\text{SOCO}}$ with $d=200$.

In the second part of our experiments, we compare the configured and hybrid implementations of \algInPaper
with the automatically generated \MTF implementations.
The purpose of this analysis is to know the extent of the benefits of exploring the entire parameter space of \MetafoR, which has a larger number of parameters compared to the rest of the algorithms and requires a larger computational budget, versus fine-tuning implementations whose main design choices were manually selected by their algorithm designers. % which have smaller parameter spaces and require smaller computational budgets.
For this analysis, we consider the functions $f_{1-40}$ in \fBENCHMARK with $d=100$ and $f_{41-50}$ in \fBENCHMARK with $d=50$.

In the third part of our experimental analysis, we study the algorithms based on how well they generalize to other kinds of problems involving different combinations of characteristics from those used to train them. 
Since our configured and hybrid implementations were trained using different sets of function instances, we expect the implementations to exhibit different degrees of generalization to functions that were not included in their training sets.
Therefore, by comparing the performance of the algorithms on different function classes, we intend to highlight the primary advantages and limitations of the two training strategies.
For this analysis, we also consider the six configured single-approach implementations, the six \algInPaper hybrids, and the two \MTF implementations on the 22 functions of \fCECFOURTEEN with $d=\{50, 100\}$ and the 19 functions of \fSOCO with $d=\{750, 1250\}$.

To facilitate the calculation of the MED, MEDerr and MAD metrics (reported in the tables below) and to have suitable scales to visualize the results in box-plots (reported in the supplementary material of this article), we 
%post-processed the raw data from our experiments to 
limit the maximum (worst) value returned by any of the algorithms to $1.00e+{10}$.
In particular, in functions $f_{3,8,15,28,30,32,36}$, not all algorithms were able to improve their initial solution, which is on the order of $1.00e+{308}$, resulting in extremely large numbers in some cases.
The limit of $1.00e+{10}$ was set based on the results of the worst performing configured algorithms and it is at least one order of magnitude higher than any of the worst returned  values. 
In the supplementary material of the article, we include both raw data, processed data with a limit value of $1.00e+{10}$, and the scripts we used for post-processing for replicability purposes.

\Tbls~\ref{table:MED-MEDerr-MAD-dftVStuned-50} to \ref{table:MED-MEDerr-MAD-LD-1250} show the averages of the MED, MEDerr, MAD and the ranking of the algorithms grouped by function classes. %, i.e., UNI, MUL, HYB, HCP, ROT, SHU, and ALL.
The correspondence between classes of functions and the functions listed in \Tbl~\ref{table:benchmark functions} is the following:
in \Tbls~\ref{table:MED-MEDerr-MAD-dftVStuned-50} and \ref{table:MED-MEDerr-MAD-mtfVSHyb-100-50}, UNI ($f_{1-12}$), MUL ($f_{13-26}$), HYB ($f_{27-40}$), HCP ($f_{41-50}$), ROT ($f_{2-4,6,14,16,18,20,22-26,42-50}$); 
and in \Tbls~\ref{table:MED-MEDerr-MAD-LD-750} and \ref{table:MED-MEDerr-MAD-LD-1250}, SHU ($f_{1,5,6,8-11}$), MUL ($f_{13,15,17,19}$) and HYB ($f_{27-34}$).
In the case of \Tbls~\ref{table:MED-MEDerr-MAD-cec14-50} and \ref{table:MED-MEDerr-MAD-cec14-100}, the functions listed in the tables are those defined for \fCECFOURTEEN~\cite{LiaQu2013problem} (listed only in the supplementary material of the article) and are grouped as follows: UNI ($f_{1-3}$), MUL ($f_{4-16}$), HYB ($f_{17-22}$), ROT ($f_{1-7,9-16}$).
The grouping ALL corresponds to all functions listed in the table, except for \Tbl~\ref{table:MED-MEDerr-MAD-mtfVSHyb-100-50}, where ALL corresponds to functions $f_{1-40}$ with $d=100$.

The limits for the scalability of the functions vary across test suites: for those belonging to \fCECFIVE, the limit is $d=50$, for those belonging to \fCECFOURTEEN, the limit is $d=100$, and for those belonging to \fSOCO, the limit is arbitrarily large.
In the row ``Wilcoxon test'', we use the symbol $\approx$ to indicate those cases in which the Wilcoxon test with confidence at 0.95 using Bonferroni's correction did not return a p-value lower than $\alpha = 0.05$, and the symbol $+$ to indicate those cases in which the difference was significant (i.e., $p< \alpha$).
The statistical tests were conducted to the complete data sets of MED, MEDerr and MAD values.
Finally, in the row "Wins", we show the number of times each algorithm found the best solution. 
Even though we include the number of "wins" for competitive comparison, our analysis primarily relies on more robust performance metrics, such as rankings and statistical tests.


\subsubsection{To hybridize, or not to hybridize --- which approach works best?}
\label{sec:results_exp1}
One of the main questions we want to explore in this work is how hybrid algorithms compare to single-approach implementations.
To answer this question, we compare the results obtained by the configured and default variants of \algInPaper with that of their automatically generated \algInPaperHyb on \fBENCHMARK with $d=50$ (\Tbl~\ref{table:MED-MEDerr-MAD-dftVStuned-50}). % and on \fSOCO with $d=200$ (\Tbl~\ref{table:MED-MEDerr-MAD-dftVStuned-200}).
We focus on the functions with $d=50$ because this is the largest dimension available for all 50 functions in \fBENCHMARK.

\input{tables/tbl_dftVstuned}

The first thing to note in \Tbl~\ref{table:MED-MEDerr-MAD-dftVStuned-50} is that, while two of the three hybrids (namely \DCHyb and \PCHyb) ranked better that most single-approach implementations across all functions, in the case of the three variants of \CMAES and \DEldo, the differences in performance were not statistically significant.
Based on the MED and MEDerr metrics, the algorithm with the highest ranking across all functions is \PCHybldo, the second-best is \CMAESldo, and the third-best is \PCHybtfo.
However, when we split the result by classes of functions, we observe that \PCHybldo ranks either first or second in the UNI, MUL and ROT functions, but it is among the worst ranked in the HYB and HCP functions, where it was outperformed by the two \PDHybs, the two \DCHybs and the three \CMAES variants.

In both the HYB and HCP functions, the best ranked algorithm was \CMAESdft.
Based on the Av.MEDerr obtained by \PCHybldo, which is similar to that of \CMAESdft in the HYB functions and one order of magnitude higher in the HCP functions, \PCHybldo seems to be able to get close to the best solution, but fails to converge to it.
The lack of convergence of \PCHybldo to the best solution is caused by the use of algorithm components heavily biased toward exploration, such as \OperatorQrandNeigh, a large value of $\omega_1 = 0.9485$ and \RIsimilarity (see \Tbl~\ref{table:ParameterSettingsALL}).
In particular, \RIsimilarity, which re-initializes solutions whose Euclidean distance to $\vec{x}^\text{best}$ is lower than $10^{-3}$, seems counterproductive at latest stages of the optimization process.
In the case of \PCHybtfo, the implementation of \PSO also uses components with a strong exploration bias (e.g., \PertLev and \RIchange), which hinder the ability of the algorithm to converge to the global optimum.

%Our results show that 
An interesting finding is that all three \CMAES variants performed as well as any of the automatically generated hybrids, including the implementation of \CMAES using default parameter settings.
Although both \CMAEStfo and \CMAESldo produce better MED solutions and have smaller MEDerrs than \CMAESdft across all functions, \CMAESdft ranks first in both metrics in the HYB and HCP functions. 
There are two main reasons that explain these results.
The first one is that our implementation of \CMAESdft is not the basic $(\mu,\lambda)$-\CMAES, but the restart-\CMAES with increasing population size, most commonly known as IPOP-\CMAES~\cite{AugHan2005cec}. %and winner of the CEC'05 competition \cite{GarGutMol2017}.
In the original IPOP-\CMAES, the parameter values were determined based on factors such as the dimensionality of the problem (e.g., $\lambda_{t=0} = 4 + \lfloor 3 \ln(d)\rfloor $) and detailed empirical analyses conducted on a limited set of simple test functions (e.g., $\texttt{stopTolFun} = 10^{-12}$).
Our method for creating and configuring \CMAEStfo and \CMAESldo builds upon the parameterized formulation of IPOP-\CMAES introduced by Liao \etal~\cite{LiaMolStu2015}. It involves employing \irace to identify combinations of algorithm components and parameter settings that achieve the best generalization across the training instances.
This explains why the automatically generated \CMAEStfo and \CMAESldo produce on average better MED and MEDerrs values than \CMAESdft.

However, the main reason why \CMAESdft performs better than any of the compared algorithms on the HYB and HCP functions is that, unlike \CMAEStfo and \CMAESldo, which use the less computationally expensive \CMAESMtxDia component, \CMAESdft uses the more computationally expensive (but also more accurate) \CMAESMtxCov. %, which plays a role in the quality of the solutions.
As discussed in \cite{RosHan2008:sepCMAES}, the algorithm component \CMAESMtxDia provides a similar performance to \CMAESMtxCov on separable functions; however, on non-separable functions, it can negatively impact the quality of the solutions found by the algorithm, especially for functions with highly complicated landscapes, such as HYB and HCP functions.
Although it is not completely clear why none of the automatically generated hybrids or configured implementations make use of \CMAESMtxCov in their design, we believe this is due to the constraint we put on the execution time of the algorithms.
By constraining the execution of the algorithms using wall-clock time, the more computationally intensive implementations generated by \irace were less likely to complete their execution within the available function evaluations (FEs). This approach inherently favored the use of less computationally demanding components, such as \CMAESMtxDia instead \CMAESMtxCovDia, in the algorithms designs.

%Therefore, it is not entirely surprising that the default version of \CMAES was able to achieve such excellent results, since (i) it was tuned using a set of functions similar to the ones in our benchmark test set, and (ii) it uses an option for the \CMAESMtx algorithm component that produces higher quality solutions. 
%Moreover, this can also explain why all the best-ranked algorithms in our comparison include \CMAES as part of their algorithmic procedure.

Several notable algorithmic differences exist among \CMAESdft, \CMAEStfo and \CMAESldo, which merit detailed discussion.
Two minor differences are the initial population size ($\lambda_{t=0}$), which is approx. 2.5 times larger in \CMAEStfo than in \CMAESdft and \CMAESldo, and the number of parents selected for recombination, which is half of the population size in \CMAESdft and about a quarter of the population size in \CMAEStfo and \CMAESldo.
\CMAESdft uses an initial step size ($\sigma_{t=0} = 0.5$) that is almost four times larger than the one used in \CMAEStfo and \CMAESldo ($\sigma_{t=0} \approx 0.14$), resulting in a more diverse initial population in \CMAESdft compared to \CMAEStfo and \CMAESldo.
Another difference is that both \CMAEStfo and \CMAESldo have higher thresholds for triggering a restart than \CMAESdft. However, after restarting, the size of their populations increases by a factor of $\approx 4$, whereas in \CMAESdft, it grows by a factor of 2.
% The most impactful difference, however, seems to be that both \CMAEStfo and \CMAESldo use \CMAESMtxDia instead of \CMAESMtxCov.
% While \CMAESMtxDia can provide similar performance to \CMAESMtxCov on separable functions, on non-separable ones, it can affect the quality of the solutions, specially on the functions with highly complicated landscapes, such as the HYB and HCP functions.


Among the six hybrid implementations, the combination that produced the best overall results was \PSO and \CMAES, followed by the combination of \DE and \CMAES, and finally, the combination of \PSO and \DE.
Both the type of hybridization (i.e., the option used for the algorithm component \Execution) and the order in which the modules are applied in the implementations (see \Tbl~\ref{table:ParameterSettingsALL} for details) were selected by \irace.
In the case of \PDHybtfo, the algorithm includes a \DE phase (allotted 46\% of the FEs) followed by a \PSO phase (allotted 56\% of the FEs), and in the case of \PDHybldo, the algorithm iteratively alternates between \DE and \PSO with a 50-50\% chance.
In the case of \PCHybtfo and \PCHybldo, which use the algorithm component \ExecutionMP, applying \CMAES first and \DE second turned out to be a better strategy than applying \DE first and \CMAES second.
This was also the case for \DCHybtfo and \DCHybldo, where \CMAES is applied before \DE.
As discussed in \Sect~\ref{sec:Previous works on hybridization}, although applying \CMAES before \PSO or \DE is not unusual in \CMAES hybrids, it seems a little counterintuitive to us because \DE and \PSO are often regarded as techniques with enhanced exploration capabilities than exploitation.

The algorithms ranked best according to the MAD metric are the two \PCHybs, followed by the two \DCHybs, followed by \CMAESldo.
As opposed to the MED and MEDerr, which provide information about the quality of the solutions, the MAD measures the variability of the results obtained by the algorithms across several independent runs.
In other words, the MAD is a measure of the robustness of the algorithms.
According to this metric, the overall performance of the \CMAES implementations was less competitive. Specifically, \CMAESdft was outperformed by all six hybrid algorithms, while both \CMAEStfo and \CMAESldo demonstrated performance comparable to that of \PDHybldo.
Nevertheless, the ranking of the algorithms per classes of function according to the MAD metric are consistent with the MED and MEDerr rankings per function classes, that is, \PCHybldo ranked first in the UNI, ROT and ALL functions, second in the MUL functions and among the last ones in the HYB and HCP functions, whereas \CMAESdft ranked second and first on the HYB and HCP functions, respectively.

The primary conclusion from this first part of our study is that, although single-approach algorithms such as \CMAES can achieve excellent results across a diverse set of problems---particularly with complex objective functions---hybrid implementations incorporating \CMAES are more robust and yield superior overall results compared to using \CMAES alone.
Allocating between $55\%$ and $75\%$ of the computational budget to \CMAES and the rest to either a \PSO or \DE seems to be a good strategy for hybridization.
Another conclusion of our study is that single-approach implementations of \PSO and \DE are less performing than their hybrid counterparts, in particular those that use default parameter values, which ranked consistently among the last places.
Note, however, that, in the case of \DEldo (similarly to \CMAES), we did not find any significant differences in its performance compared to the best algorithm (\PCHybldo) across the entire set of functions, and \DEldo showed to be as competitive as any of the hybrid implementations on the MUL, HYB and HCP functions.
In \Sect~\ref{sec:results_exp3}, we study the algorithmic design of \DEldo in more detail and create a link between its performance on HYB and HCP functions and on functions with large dimensionality.
Finally, although it can only be observed in \Tbls 4 and 5 in the supplementary material of the article, we found an inverse relationship between the number of dimensions in the functions and the performance of \CMAESdft.
According to the MED and MEDerr metrics, on average across all function classes, \CMAESdft ranked behind the other two \CMAES variants and all hybrids in \fBENCHMARK with $d=100$, and second to last in \fSOCO with $d=200$.

%Also in both cases, \PSO uses a large population (ranging from 38 to 367, in the case of \PCHybtfo, and from 22 to 489, in the case of \PCHybldo) and the component \OperatorCG with \OperatorQrandNeigh to sample new solution between the current position of the particles and randomly selected neighborhoods.

%According to the results shown in \Tbl~\ref{table:MED-MEDerr-MAD-dftVStuned-50}, 


\subsubsection{Exploring new hybrid designs versus exploiting implementations with a fixed design --- what is the trade-off?}\label{sec:results_exp2}

To understand how exploring the entire search space of \MetafoR compares to fine-tuning implementations with predefined design choices, we create two implementations, \MTFtfo and \MTFldo, considering the 104 parameters of the framework.
In this section, we report the results obtained by the two \MTF implementations, the six configured \CMAES, \DE and \PSO implementations, and the six \algInPaperHyb on functions $f_{1-40}$ with $d=100$ and $f_{41-50}$ with $d=50$.
We excluded the default variants from the compared algorithms in this section to focus our analysis on comparing the performance of automatically created algorithms using different design spaces; however, in the supplementary material, we report the complete set of results obtained by the 17 algorithms on \fBENCHMARK with $d=\{50, 100, 200, 500, 1\,000\}$. % \CMAESdft, \DEdft and \StdPSOdft were consistently outperformed by their configured counterparts.

\input{tables/tbl_mtfVSHyb}

As shown in \Tbl~\ref{table:MED-MEDerr-MAD-mtfVSHyb-100-50}, according to the MED and MEDerr metrics, the algorithm with the best overall performance was \MTFldo, followed by \PCHybldo, followed by \CMAESldo; and according to the MAD metric, the best algorithm was \MTFldo, followed by \DCHybtfo and finally \PCHybtfo.
For all three performance metrics, the second- and third-best ranked algorithms exhibited slightly superior performance than \MTFldo on the UNI and ROT functions, whereas \MTFldo was the clear winner in the MUL and HYB functions.
The results shown in \Tbl~\ref{table:MED-MEDerr-MAD-mtfVSHyb-100-50} also suggest that single-approach and hybrids involving \DE and \PSO are less competitive than single-approach and hybrids involving \CMAES.
This finding is supported by the average rankings across all functions and the Wilcoxon test using Bonferroni's correction, which returned a p-value lower than $\alpha = 0.05$ for \DEtfo, \DEldo, \PSOtfo, \PSOldo and the two \PDHybtfo and \PCHybldo.
Another important finding is that the algorithms trained on the \LDO scenario produce better results in the UNI, MOD and ROT functions, whereas those trained on the \TFOUT scenario were better in the HYB and HCP functions.
In \Sect~\ref{sec:results_exp3}, we study in detail the impact that different training strategies have on the performance of the algorithms. % these results already highlight some of the strengths of using one training strategy or the other.

In the case of \PCHybldo and \PCHybtfo, which were among the top three algorithms in \fBENCHMARK with $d=50$, we observe that their inability to converge to the best solution on the HYB and HCP functions becomes increasingly problematic as the number of dimensions increases.
To try to understand why, we analyze the MED and MEDerr values obtained by \PCHybldo and \PCHybtfo on the HYB and HCP functions. 
Based on their MED and MEDerr, both per function and on average,  \PCHybldo and \PCHybtfo yield results comparable to those of the top-ranked algorithms in most cases. However, as noted in \Sect~\ref{sec:results_exp1}, while \PCHybldo and \PCHybtfo appear effective in identifying the search region containing the optimal solution, they struggle to converge to the solution itself.
In our opinion, this is due to the use of components with a strong exploratory bias, such as \Reinit, \PertInf and a large value for $\omega_1$, as well as the use of \CMAESMtxCovDia, which forces the algorithms to switch from the more accurate \CMAESMtxCov to the less accurate \CMAESMtxDia after $2+100 \times \frac{d}{\sqrt{\lambda}}$ FEs.
Although the algorithmic design of \PCHybldo and \PCHybtfo is well suited to UNI, MUL and ROT functions, it lacks the right exploration-exploitation balance to solve the most complicated HYB and HCP functions, which, based on our experiments, require an algorithmic design that allows intensive exploitation of the search space in the final stages of the optimization process.

We also study the main designs aspects of \MTFtfo and \MTFldo.
As shown in \Tbl~\ref{table:ParameterSettingsALL}, the two \MTF implementations are essentially \CMAES--\DE hybrids, but they have a number of design choices that make them unique.
In \MTFtfo, the implementation of \CMAES (allotted $\approx 62\%$ of the FEs) is quite similar to \CMAESdft, except for the choice of the algorithm component \CMAESMtx, which is implemented using \CMAESMtxDia, resulting in a faster, although less precise variant of \CMAES compared to \CMAESdft.
To compensate for any possible lack of exploitation capabilities, the implementation of \DE in \MTFtfo uses components \DEBVbest and \VBeigen, where \DEBVbest bias the search towards the best solution found so far, and \VBeigen (which is similar to the use of \CMAESMtxCov in \CMAES) provides \MTFtfo with a mechanism to effectively tackle rotated search spaces.

Of the two \MTF implementations, only \MTFldo includes a local search.
%has the most sophisticated design among all the algorithms in our comparison.
\MTFldo uses three modules, \CMAESmod, \DEmod and \LSmod, where each module is allocated, respectively, about 34\%, 6\% and 60\% of the total number of FEs.
The implementation of \CMAES in \MTFldo is also similar to \CMAESdft, except for two aspects. The first one is the use of the \CMAESMtxCovDia option, which allows the algorithm to take advantage of the information provided by the covariance matrix for a number of FEs and then switch to the faster diagonal matrix.
The second aspect is a higher tolerance for the range of improvement of all function values of the most recent generation (i.e., \texttt{stopTolFun}), which means that this implementation of \CMAES allows solution to remain for longer in the population before restarting.

The most salient aspect of \MTFldo is the use of the local search algorithm \MTSLS, which is executed after \CMAES and is assigned more than half of the computational budget. % by interleaving its execution with \DE.
The parameter settings of \MTSLS are roughly the same used by its authors in~\cite{TseChe08:ieee-ec-ci}. % with the only difference that is divided into three iterations.
However, the way in which \DE and \MTSLS interact with each other is quite interesting and has two main distinctive features.
The first feature is the obvious bias toward exploitation that results from allocating a much larger number of FEs to \MTSLS than to \DE in each iteration.
The second feature is the use of \DEBVdirRand, \RIsimilarity and a large crossover rate ($p_a = 0.81$) in the implementation of \DE, which allows it to generate solutions far away from the region where \MTSLS is locally searching.
By combining these two features, \MTFldo can perform an intensive exploitation of the best solution found so far, while keeping some degree of exploration of the search space up until the end of the optimization process.

\subsubsection{Generalizing to unseen problems --- which training strategy is the best?}\label{sec:results_exp3}

Our final analysis focuses on comparing the two training scenarios, \TFOUT and \LDO, and identifying their main advantages and disadvantages.
As mentioned in \Sect~\ref{sec:experimental setup}, the scenarios \TFOUT and \LDO differ in the set of functions available for \irace to train the algorithms.
We use a "machine learning"-type approach to select the functions in each scenario: in the case of \TFOUT, we randomly selected a fixed percentage of 75\% of the test functions of each class to form a stratified training set, and in the case of \LDO, we used a leave-one-class-out cross-validation approach to train the algorithms excluding the "large dimensional" (LD) class from the training set.
In practice, the training set of \TFOUT contains 88 functions that were selected using $\big(f_{1,3-7,9-12,14-17,19-23,25} \subset$ \fCECFIVE $\times\, d=\{10,30,50\}\big) \bigcup \big(f_{1, 3-6, 9-11, 13-15, 17-19} \subset$ \fSOCO $\times\, d=\{500, 1\,000\}\big)$, whereas the training set of \LDO contains 107 functions that were selected using $\big(f_{1-25} \subset$ \fCECFIVE $\times\, d=\{10,30\}\big) \bigcup \big(f_{1-19} \subset$ \fSOCO $\times \,d=\{50,100,200\}\big)$. % where $\times$ indicates the cross product between sets.
In \Tbl~\ref{table:instance distrubution per scenarios}, we show the composition of each scenario in terms of functions classes.

Although no single instance separation strategy is optimal for training metaheuristic algorithm, each strategy represents a trade-off between generalization and specialization.
When we defined scenarios \TFOUT and \LDO, our intuition was that, since all classes of functions are represented in \TFOUT, from UNI to LD, \TFOUT should produce algorithms that generalize better at the expense of a lower solution quality.
In contrast, for \LDO, we hypothesized that it would produce algorithms  specialized in complex low-dimensional functions, albeit with limited  scalability.
In the previous sections, we identified two trends associated with the use of different training instances.
The first trend, observed in the aggregated data for ALL functions in \Tbls~\ref{table:MED-MEDerr-MAD-dftVStuned-50} and \ref{table:MED-MEDerr-MAD-mtfVSHyb-100-50}, shows that, on average, algorithms trained on \LDO achieve superior MED, MEDerr and MAD values compared to those trained on \TFOUT.
The second trend, which is the opposite of the first, applies specifically to the results for the HYB and HCP functions, where  algorithms trained on \TFOUT consistently outperform those trained on \LDO.
%Also in \Tbls~\ref{table:MED-MEDerr-MAD-dftVStuned-50} and \ref{table:MED-MEDerr-MAD-mtfVSHyb-100-50}, we observed the inverse trend 

To determine whether the performance differences in the HYB functions increases with the number of dimension---suggesting a connection between the second trend and the fact that \TFOUT includes dimensional functions---we compare the distance in Av.Ranking obtained by each pair of \TFOUT-\LDO algorithms in the HYB functions.
The aggregated values obtained for all pairs were $0.88$, in the functions with $d=50$, and $0.92$, in the functions with $d=100$. %and $-5.28$, in the HCP functions with $d=50$.
The fact that these two values are similar indicates that the differences in performance between the algorithms trained on \TFOUT and those trained on \LDO remain constant despite the increase in the number of dimensions.
Based on the fact that (i) the main difference between \TFOUT and \LDO is that \TFOUT includes functions with large dimensionality and (ii) each pair of \TFOUT-\LDO algorithms performs similarly well independently of the dimensionality of the functions, we conclude that the set of components that are useful for solving LD functions are also useful for solving HYB and HCP functions.
In the following analysis of the algorithm's performance on LD functions, we provide further evidence supporting this thesis.

\paragraph{Generalization of the algorithms trained on \TFOUT and \LDO to \fCECFOURTEEN}

To measure the ability of the algorithms to generalize to other types of functions, we compare their performance on the 22 functions of the \fCECFOURTEEN with $d=\{50, 100\}$.
The \fCECFOURTEEN has 22 functions, of which 3 are UNI, 13 are MUL, 6 are HYB, and 20 are ROT (see \Tbl~\ref{table:instance distrubution per scenarios}).
As indicated in \Tbl~\ref{table:MED-MEDerr-MAD-cec14-50}, based on the MED and MEDerr metrics, the top-performing algorithms across all functions in \fCECFOURTEEN with $d=50$ are \MTFldo and \PCHybldo (tied for first place), followed by \PCHybtfo and \CMAESldo.
Although both \MTFldo and \PSOldo ranked first, we found statistically significant differences in favor of \MTFldo in five cases (\DEtfo, \DEldo, \PSOtfo, \PSOldo and \PDHybtfo), while in the case of \PCHybldo the statistical test showed differences in only two cases, \DEtfo and \PSOtfo. 
Based on the data per function class in \Tbl~\ref{table:MED-MEDerr-MAD-cec14-50}, \MTFldo performs quite well in the MUL, HYB and ROT functions, but is outperformed by \CMAESldo and the two \PCHyb in the UNI functions.
In the case of \PCHyb, its performance is particularly good in the ROT functions, but again poor in the HYB functions, where it is the worst ranked algorithm.

\input{tables/tbl_cec14_1}

Regarding the robustness of the algorithms, measured by their MAD value, the results are consistent with those obtained by the algorithms on the MED and MEDerr metrics. 
In particular, \PCHybldo showed greater robustness in the UNI, ROT and ALL functions, while \MTFldo showed greater robustness in the MUL functions. 
It should be noted that although \fCECFOURTEEN was reserved for testing only, the functions $f_{1,4-10,15,16} \in$ \fCECFOURTEEN are the same as the functions $f_{3,6-14} \in $\fCECFIVE.
This means that 7 of the 88 functions in the \TFOUT training set are also present in the \fCECFOURTEEN test set, with 6 functions belonging to the MUL class and 1 function belonging to the UNI class.
In the cases of the training set \LDO and the test set \fCECFOURTEEN, there is no overlap because \LDO excludes dimensions 50 and 100, and these are the dimensions we consider for the analysis using \fCECFOURTEEN.
Despite the overlap between \TFOUT and \fCECFOURTEEN, we found no evidence that the algorithms trained on \TFOUT had an advantage on the MUL functions over those trained on \LDO.

\input{tables/tbl_cec14_2}

Now we focus on the results in \fCECFOURTEEN with $d=100$ (\Tbl~\ref{table:MED-MEDerr-MAD-cec14-100}).
Based on the MED and MEDerr metrics, the best performing algorithm is \CMAESldo, followed by \PCHybtfo and \PCHybldo (both tied for second place), and finally \DCHybldo.
The analysis by function class shows that \CMAESldo is the best algorithm for the UNI, MUL, and ROT functions, and fourth for the HYB functions, where it is outperformed by the two \MTF hybrids and \CMAEStfo. 
The performance of \CMAESldo is clearly superior to most of the compared algorithms based on MED and MEDerr, but has a higher variability in its results.
According to the MAD metric, the most robust algorithm is \PCHybldo, followed by \PCHybtfo, and finally \DCHybtfo, while \CMAESldo ranks seventh.

After comparing the results obtained by the algorithms on the \fBENCHMARK (\Tbls~\ref{table:MED-MEDerr-MAD-dftVStuned-50} and \ref{table:MED-MEDerr-MAD-mtfVSHyb-100-50}) and \fCECFOURTEEN (\Tbls~\ref{table:MED-MEDerr-MAD-cec14-50} and \ref{table:MED-MEDerr-MAD-cec14-100}) with $d=50$ and $d=100$, we found consistency in their rankings for median solution quality (MED), median solution error (MEDerr), and median absolute deviation (MAD) on both dimensions.
In the two benchmarks, the best results over all function sets are obtained by \MTF, \PCHyb, and \CMAES, and the worst results are obtained by \PSO, \DE, and \PDHyb.
Also, for both \fBENCHMARK and \fCECFOURTEEN, we found that (i) on average, the algorithms trained on \LDO outperform those trained on \TFOUT, and (ii) for the HYB functions, the algorithms trained on \TFOUT outperform those trained on \LDO. 
These results suggest that both training scenarios produce algorithms with similar generalization capabilities when it comes to functions with features such as multimodality, mathematical transformations, and function hybridization.
%that exhibit similar strengths and weaknesses when applied to 


\paragraph{Generalization of the algorithms trained on \TFOUT and \LDO to \fSOCO}

So far, we have analyzed the performance of the algorithms only on functions with low to medium dimensionality. % that is, from 50 to 100 dimensions.
The goal of this final analysis is to compare the performance of the algorithms using functions with a much larger scale, namely $750$ and $1\,250$ dimensions.
For this purpose, we performed experiments on \fSOCO, which consists of 19 freely scalable functions, of which 7 are shifted unimodal (SHU) functions, 4 are MUL functions, and 8 are HYB functions.

\input{tables/tbl_LD_3}

In \Tbl~\ref{table:MED-MEDerr-MAD-LD-750} we report the results of the algorithms on \fSOCO with dimension $750$. 
Based on MED and MEDerr performance metrics, the best performing algorithms across all functions are 
\PCHybtfo, followed by \DCHybtfo and \PCHybldo.
%\DEtfo, followed by \PCHybldo and \PCHybtfo. 
%\DEtfo is also the best performing algorithm per function class, ranking first for the SHU, MUL, and HYB functions according to the MED and MEDerr metrics. 
The analysis of results per function class shows that \PCHybldo and \DCHybtfo are tied for the first place for the SHU functions, \PCHybtfo is ranked first in the MUL functions and \MTFldo is ranked first in the HYB functions.
%\PDHybldo and \PCHybtfo, while competitive with \DEtfo on average, they are better suited for the large-dimensional MUL functions than for the large-dimensional SHU and HYB functions.
It is also interesting to note that the trend observed earlier, where the algorithms trained on \LDO consistently outperform those trained on \TFOUT across all functions, is partially reversed in this set of benchmark functions.
In fact, with the exception of \MTF and \PDHybs, the algorithms trained on \TFOUT obtained better MED and MEDerr values than those trained on \LDO; and this effect is particularly notable for \DE.

Although the statistical test did not find a significant difference in the performance of the algorithms based on the MED and MEDerr values (with the exception of \PSOldo), the number of "wins" of the algorithm gives us an indication of how competitive they are.
The number of "wins" refers to the number of times the algorithm obtained the lowest MED, MEDerr or MAD value.
As shown in \Tbl~\ref{table:MED-MEDerr-MAD-LD-750}, \PCHybtfo obtained the best value 8 times, \DEtfo 6 times, the two \CMAES and \PCHybtfo 2 times and \PSOtfo and \DCHybldo 1 time each.
The number of "wins", while useful for competitive testing, is not necessarily a reliable performance metric on its own due to its sensitivity to the precision of algorithms in objective functions with mathematical transformations.
This means that if no precision is defined, only the algorithm that comes closest to the optimum will be awarded a "win", even if the differences in solution with other algorithms are negligible. 

Another noteworthy finding from the experiments on \fSOCO with LD is the difference in performance between \DEtfo and \DEldo.
While \DEtfo is competitive with the best-ranked algorithms on the MUL, HYB and ALL functions, ranking either third or fourth, \DEldo is among the worst-ranked algorithms on all function classes.
However, the two \DE implementations differ only in a few design choices.
Both \DE implementations use the \VBnatural and \DEBVbest algorithm components and have similar values for the crossover rate ($p_a$) and the scaling factor ($\beta$), although these are slightly higher in the case of \DEtfo (see \Tbl~\ref{table:ParameterSettingsALL}).
The main differences between \DEtfo and \DEldo are the algorithm components \Pop and \DEVectDifferences.
In the case of \DEtfo, the population is handled by \PopTV, which is updated every 26 iterations and varies between 39 and 132 solutions.
Since the percentage of \DEVectDifferences in \DEtfo is 0.0151, the algorithm adds only one vector difference when the population size is less than 100, and two vector differences when it is greater than or equal to 100.
Compared to \DEtfo, the implementation of \DEldo uses a larger \DEVectDifferences value (0.1711) and a smaller population size, starting with 46 solutions and ending with 69 solutions.
Therefore, from the fifth iteration, when \DEtfo reaches its maximum population size, each individual in the population will add 12 vector differences to compute its trail vector.

Based on the results of \DEtfo and \DEldo on \fBENCHMARK (\Tbls~\ref{table:MED-MEDerr-MAD-dftVStuned-50} to \ref{table:MED-MEDerr-MAD-mtfVSHyb-100-50}) and on \fCECFOURTEEN (\Tbls~\ref{table:MED-MEDerr-MAD-cec14-50} to \ref{table:MED-MEDerr-MAD-cec14-100}) with $d=\{50, 100\}$, where both implementations gave similar results, with \DEldo slightly better than \DEtfo on average, the performance of \DE does not seem to be particularly sensitive to the options used for the \Pop and \DEVectDifferences components.
However, in large dimensional search spaces, as in the case of \fSOCO with $d=750$, the \Pop and \DEVectDifferences components have a strong impact on the performance of \DE.
In practice, on complex multimodal search spaces with less than 100 dimensions, a good strategy is to implement \DE using a population of about 75 individuals and adding a maximum of 15\% of the population as vector differences.
However, when the number of dimensions is greater than 100, the performance of \DE can be improved by slightly increasing the population size and reducing the number of vector differences to one or at most two.

Finally, in \Tbl~\ref{table:MED-MEDerr-MAD-LD-1250}, we show the results obtained by the algorithms on \fSOCO with $1\,250$ dimensions.
%Similarly to the result on  
The best-ranked algorithms across the entire set of functions, based on the MED and MEDerr performance metrics, are \DCHybtfo, first place, \PCHybtfo, second place, and \MTFldo, third place.
Similarly to \fSOCO with $750$ dimensions, \DCHybtfo and \PCHybtfo obtained the best results overall and \PCHybtfo also in the MUL functions; however, in the SHU and HYB functions, \MTFtfo was clear winner, outperforming the first and second place by a significant margin.
In terms of scoring the higher number of "wins" for the MED and MEDerr metrics, the best performing algorithm is \PCHybtfo, 8 times, followed by \DCHybtfo, 4 times, the two \MTF, 3 times, \CMAEStfo and \DEtfo, 2 times, and finally \CMAESldo, \PSOtfo and \PCHybldo, 1 times each.
We found a statistical significant difference in favor of \PCHybtfo with respect to \PDHybtfo, \PDHybldo and \DCHybldo, in the MED and MEDerr results. %, and with respect to \DEtfo, , in the MAD results.
The results obtained by the algorithms on the MAD metric indicate that \MTF, \CMAES, \DCHyb, \PCHyb, \DEldo and, \PSOldo exhibit comparable robustness, with \CMAESldo and \PCHybldo outperforming the others. In contrast, \DEtfo, \PSOtfo and \PDHyb display variability in their outcomes.

\input{tables/tbl_LD_4}

Based on the results shown in \Tbls~\ref{table:MED-MEDerr-MAD-LD-750} and \ref{table:MED-MEDerr-MAD-LD-1250}, we observe strong differences in the generalization capabilities of the algorithms when transitioning from low-dimensional to high-dimensional search spaces. 
In particular, \CMAESldo and \MTFldo, which obtained the best results on functions with dimensions $d=\{50, 100\}$, were outperformed by \DCHybtfo and \PCHybtfo on functions with dimensions $d=\{750, 1250\}$.
The implementations with better generalization in terms of scalability are \PCHybldo and \PCHybtfo, which perform similarly on average on \fBENCHMARK, \fCECFOURTEEN, and \fSOCO irrespective of problem dimensionality. However, they consistently underperformed on HYB functions across all cases.
Finally, we found that the algorithms trained on \TFOUT performed better than those trained on \LDO on both HYB and LD functions, suggesting that the algorithm components useful for tackling HYB functions are also useful for tackling LD functions.

\section{Conclusions}\label{sec:conclusions}
In this article, we have proposed \MetafoR, a metaheuristic software framework for \algInPaperLS applicable to single-objective \cops.
The main advantage of \MetafoR is that it enables the creation of high-performance \mh implementations using an \ad approach, i.e., the selection of algorithm components and parameter settings in the implementation is done using an \aact, such as \irace, instead of relying on the expertise and intuition of a human algorithm designer.
To develop \MetafoR, we considered a component-based architecture and four main modules (\MetafoRModules), resulting in a total of 104 parameters, each representing either an algorithm component or a numerical parameter related to the use of a component.
\MetafoR allows three different types of hybridization, \ExecutionCB, \ExecutionPB and \ExecutionMP, which were selected based on a brief literature review of prominent hybrids of \algInPaper.
The three main \mh approaches included in \MetafoR (\algInPaper) can be used alone or in combination, allowing users not only to replicate hundreds of single-approach and hybrid algorithms already proposed in the literature, but also to generate many new implementations never proposed before.

We have shown experimentally that \MetafoR can be used to create implementations that outperform the state of the art on various metrics, as well as to create implementations that are tailored to specific problem classes. 
We compared a total of 17 algorithms and studied two popular "machine-learning"-type instance separation strategies often used in \ad, namely the creation of a stratified training set using a fixed percentage (\TFOUT) and leave-one-class-out cross-validation (\LDO). 
Although neither instance separation strategy can be considered better than the other, we found that \TFOUT works well for HYB and LD functions, while \LDO is a good strategy for low-dimensional functions with smoother search spaces, such as UNI and MUL functions. 
Also, based on the design of the best performing algorithms in our experimental study, we have identified strategies that can be used to guide the design of hybrid \mhs. % either as initial configurations for an \aact or as a manually selected implementations.

Of course, our work also has limitations and could be improved in a number of ways. 
One limitation is the fact that the number of components available in the literature is enormous, and it is impossible to imagine including all of them in \MetafoR.
Another limitation is the type of hybridization currently available in \MetafoR. In particular, to keep things manageable, we have omitted some of the most complex types of hybridization and a number of components that can potentially provide better results. 
For future improvements to our work, we are considering the following: (i) incorporating other \mh and \ls approaches, such as \abc \cite{AydYavOzyYasStu2017} and Powell's BOBYQA and NEWUOA \cite{Powell2002,Powell2006}; (ii) exploring hybridization with ML techniques, including deep learning and reinforcement learning hybrids; and (iii) integrating components from other metaheuristic software frameworks that have demonstrated their utility in experimental studies \cite{KosVerKor2024:ev}.
%investigate complex hybridization strategies that operate a deeper level in order implementations using hybridiz components and paramters

\begin{acks}
Christian L. Camacho-Villalón acknowledges support from the SMASH postdoctoral fellowship
program of Slovenia from which he is a MSCA fellow.
Marco Dorigo and Thomas St\"utzle acknowledge support from the Belgian F.R.S.-FNRS, of
which they are Research Directors. 
\end{acks}

%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
%\bibliographystyle{ACM-Reference-Format}
%\bibliography{optbib/abbrev,optbib/journals,optbib/authors,optbib/biblio,optbib/crossref}
%%% -*-BibTeX-*-
%%% Do NOT edit. File created by BibTeX with style
%%% ACM-Reference-Format-Journals [18-Jan-2012].

\providecommand{\MaxMinAntSystem}{{$\cal MAX$--$\cal MIN$} {A}nt {S}ystem} \providecommand{\Rpackage}[1]{#1} \providecommand{\SoftwarePackage}[1]{#1} \providecommand{\proglang}[1]{#1}
\begin{thebibliography}{101}

%%% ====================================================================
%%% NOTE TO THE USER: you can override these defaults by providing
%%% customized versions of any of these macros before the \bibliography
%%% command.  Each of them MUST provide its own final punctuation,
%%% except for \shownote{}, \showDOI{}, and \showURL{}.  The latter two
%%% do not use final punctuation, in order to avoid confusing it with
%%% the Web address.
%%%
%%% To suppress output of a particular field, define its macro to expand
%%% to an empty string, or better, \unskip, like this:
%%%
%%% \newcommand{\showDOI}[1]{\unskip}   % LaTeX syntax
%%%
%%% \def \showDOI #1{\unskip}           % plain TeX syntax
%%%
%%% ====================================================================

\ifx \showCODEN    \undefined \def \showCODEN     #1{\unskip}     \fi
\ifx \showDOI      \undefined \def \showDOI       #1{#1}\fi
\ifx \showISBNx    \undefined \def \showISBNx     #1{\unskip}     \fi
\ifx \showISBNxiii \undefined \def \showISBNxiii  #1{\unskip}     \fi
\ifx \showISSN     \undefined \def \showISSN      #1{\unskip}     \fi
\ifx \showLCCN     \undefined \def \showLCCN      #1{\unskip}     \fi
\ifx \shownote     \undefined \def \shownote      #1{#1}          \fi
\ifx \showarticletitle \undefined \def \showarticletitle #1{#1}   \fi
\ifx \showURL      \undefined \def \showURL       {\relax}        \fi
% The following commands are used for tagged output and should be
% invisible to TeX
\providecommand\bibfield[2]{#2}
\providecommand\bibinfo[2]{#2}
\providecommand\natexlab[1]{#1}
\providecommand\showeprint[2][]{arXiv:#2}

\bibitem[Andr{\'e}asson et~al\mbox{.}(2020)]%
{Andreasson2020:Book-continuousOptimization}
\bibfield{author}{\bibinfo{person}{Niclas Andr{\'e}asson}, \bibinfo{person}{Anton Evgrafov}, {and} \bibinfo{person}{Michael Patriksson}.} \bibinfo{year}{2020}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{An Introduction to Continuous Optimization: Foundations and Fundamental Algorithms}}.
\newblock \bibinfo{publisher}{Courier Dover Publications}, \bibinfo{address}{Mineola, New York}.
\newblock


\bibitem[Aranha et~al\mbox{.}(2022)]%
{AraCamCam-etal2022:openletter:si}
\bibfield{author}{\bibinfo{person}{Claus Aranha}, \bibinfo{person}{Christian~Leonardo {Camacho-Villal{\'o}n}}, \bibinfo{person}{Felipe Campelo}, \bibinfo{person}{Marco Dorigo}, \bibinfo{person}{Rub\'en Ruiz}, \bibinfo{person}{Marc Sevaux}, \bibinfo{person}{Kenneth S{\"o}rensen}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2022}\natexlab{}.
\newblock \showarticletitle{Metaphor-based Metaheuristics, a Call for Action: the Elephant in the Room}.
\newblock \bibinfo{journal}{\emph{Swarm Intelligence}} \bibinfo{volume}{16}, \bibinfo{number}{1} (\bibinfo{year}{2022}), \bibinfo{pages}{1--6}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1007/s11721-021-00202-9}
\showDOI{\tempurl}


\bibitem[Audet and Hare(2017)]%
{AudHar2017:Book-BBO-DFO}
\bibfield{author}{\bibinfo{person}{Charles Audet} {and} \bibinfo{person}{Warren Hare}.} \bibinfo{year}{2017}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Derivative-free and blackbox optimization}}.
\newblock \bibinfo{publisher}{Springer}, \bibinfo{address}{Berlin, Heidelberg, Germany}.
\newblock


\bibitem[Auger and Hansen(2005)]%
{AugHan2005cec}
\bibfield{author}{\bibinfo{person}{Anne Auger} {and} \bibinfo{person}{Nikolaus Hansen}.} \bibinfo{year}{2005}\natexlab{}.
\newblock \showarticletitle{A restart {CMA} evolution strategy with increasing population size}. In \bibinfo{booktitle}{\emph{Proceedings of the 2005 Congress on Evolutionary Computation (CEC 2005)}}. \bibinfo{publisher}{IEEE Press}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{1769--1776}.
\newblock


\bibitem[Ayd{\i}n et~al\mbox{.}(2017)]%
{AydYavOzyYasStu2017}
\bibfield{author}{\bibinfo{person}{Do\v{g}an Ayd{\i}n}, \bibinfo{person}{G{\"{u}}rcan Yavuz}, \bibinfo{person}{Serdar \"Ozy\"on}, \bibinfo{person}{Celal Yasar}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{Artificial Bee Colony Framework to Non-convex Economic Dispatch Problem with Valve Point Effects: A Case Study}. In \bibinfo{booktitle}{\emph{GECCO'17 Companion}}, \bibfield{editor}{\bibinfo{person}{Peter A.~N. Bosman}} (Ed.). \bibinfo{publisher}{ACM Press}, \bibinfo{address}{New York, NY}, \bibinfo{pages}{1311--1318}.
\newblock


\bibitem[Bezerra et~al\mbox{.}(2020)]%
{BezLopStu20:ecj}
\bibfield{author}{\bibinfo{person}{Leonardo~CT Bezerra}, \bibinfo{person}{Manuel L{\'o}pez-Ib{\'a}{\~n}ez}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{Automatically Designing State-of-the-Art Multi-and Many-Objective Evolutionary Algorithms}.
\newblock \bibinfo{journal}{\emph{Evolutionary Computation}} \bibinfo{volume}{28}, \bibinfo{number}{2} (\bibinfo{year}{2020}), \bibinfo{pages}{195--226}.
\newblock


\bibitem[Bezerra et~al\mbox{.}(2016)]%
{BezLopStu2015tec}
\bibfield{author}{\bibinfo{person}{Leonardo C{\'e}sar~Teon{\'a}cio Bezerra}, \bibinfo{person}{Manuel L{\'o}pez-Ib{\'a}{\~n}ez}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2016}\natexlab{}.
\newblock \showarticletitle{Automatic Component-Wise Design of Multi-Objective Evolutionary Algorithms}.
\newblock \bibinfo{journal}{\emph{IEEE Transactions on Evolutionary Computation}} \bibinfo{volume}{20}, \bibinfo{number}{3} (\bibinfo{year}{2016}), \bibinfo{pages}{403--417}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1109/TEVC.2015.2474158}
\showDOI{\tempurl}


\bibitem[Birattari et~al\mbox{.}(2010)]%
{BirYuaBal2010:emaoa}
\bibfield{author}{\bibinfo{person}{Mauro Birattari}, \bibinfo{person}{Zhi Yuan}, \bibinfo{person}{Prasanna Balaprakash}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2010}\natexlab{}.
\newblock \showarticletitle{{F}-Race and Iterated {F}-Race: An Overview}.
\newblock In \bibinfo{booktitle}{\emph{Experimental Methods for the Analysis of Optimization Algorithms}}, \bibfield{editor}{\bibinfo{person}{Thomas Bartz-Beielstein}, \bibinfo{person}{Marco Chiarandini}, \bibinfo{person}{Lu{\'i}s Paquete}, {and} \bibinfo{person}{Mike Preuss}} (Eds.). \bibinfo{publisher}{Springer}, \bibinfo{address}{Berlin, Germany}, \bibinfo{pages}{311--336}.
\newblock


\bibitem[Blum and Raidl(2016)]%
{BluRai2016:book}
\bibfield{author}{\bibinfo{person}{Christian Blum} {and} \bibinfo{person}{G{\"u}nther~R. Raidl}.} \bibinfo{year}{2016}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Hybrid Metaheuristics---Powerful Tools for Optimization}}.
\newblock \bibinfo{publisher}{Springer}, \bibinfo{address}{Berlin, Germany}.
\newblock


\bibitem[Boks et~al\mbox{.}(2020)]%
{BokWanBac2020:gecco-PSO-DE}
\bibfield{author}{\bibinfo{person}{Rick Boks}, \bibinfo{person}{Hao Wang}, {and} \bibinfo{person}{Thomas B{\"a}ck}.} \bibinfo{year}{2020}\natexlab{}.
\newblock \showarticletitle{A modular hybridization of particle swarm optimization and differential evolution}. In \bibinfo{booktitle}{\emph{GECCO'20 Companion}}, \bibfield{editor}{\bibinfo{person}{Carlos Artemio~Coello Coello}} (Ed.). \bibinfo{publisher}{ACM Press}, \bibinfo{address}{New York, NY}, \bibinfo{pages}{1418--1425}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1145/3377929.3398123}
\showDOI{\tempurl}


\bibitem[Bonabeau et~al\mbox{.}(1999)]%
{BonDorThe1999swarm}
\bibfield{author}{\bibinfo{person}{Eric Bonabeau}, \bibinfo{person}{Marco Dorigo}, {and} \bibinfo{person}{Guy Theraulaz}.} \bibinfo{year}{1999}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Swarm intelligence: from natural to artificial systems}}.
\newblock \bibinfo{publisher}{Oxford university press}, \bibinfo{address}{New York, NY}.
\newblock


\bibitem[Bonyadi and Michalewicz(2014)]%
{BonMic2014:swarm}
\bibfield{author}{\bibinfo{person}{Mohammad~Reza Bonyadi} {and} \bibinfo{person}{Zbigniew Michalewicz}.} \bibinfo{year}{2014}\natexlab{}.
\newblock \showarticletitle{A locally convergent rotationally invariant particle swarm optimization algorithm}.
\newblock \bibinfo{journal}{\emph{Swarm Intelligence}} \bibinfo{volume}{8}, \bibinfo{number}{3} (\bibinfo{year}{2014}), \bibinfo{pages}{159--198}.
\newblock
\showISSN{1935-3820}
\urldef\tempurl%
\url{https://doi.org/10.1007/s11721-014-0095-1}
\showDOI{\tempurl}


\bibitem[Calvet et~al\mbox{.}(2017)]%
{CalArmMas2017:Learnheuristics}
\bibfield{author}{\bibinfo{person}{Laura Calvet}, \bibinfo{person}{J{\'e}sica de Armas}, \bibinfo{person}{David Masip}, {and} \bibinfo{person}{Angel~A Juan}.} \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{Learnheuristics: hybridizing metaheuristics with machine learning for optimization with dynamic inputs}.
\newblock \bibinfo{journal}{\emph{Open Mathematics}} \bibinfo{volume}{15}, \bibinfo{number}{1} (\bibinfo{year}{2017}), \bibinfo{pages}{261--280}.
\newblock


\bibitem[{Camacho-Villal{\'o}n} et~al\mbox{.}(2021)]%
{CamDorStu2021:posx-supp}
\bibfield{author}{\bibinfo{person}{Christian~Leonardo {Camacho-Villal{\'o}n}}, \bibinfo{person}{Marco Dorigo}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2021}\natexlab{}.
\newblock \bibinfo{title}{PSO\textsl{-X}: A Component-Based Framework for the Automatic Design of Particle Swarm Optimization Algorithms: Supplementary material}.
\newblock \bibinfo{howpublished}{\url{http://iridia.ulb.ac.be/supp/IridiaSupp2021-001/}}.
\newblock


\bibitem[{Camacho-Villal{\'o}n} et~al\mbox{.}(2022)]%
{CamDorStu2022:tec}
\bibfield{author}{\bibinfo{person}{Christian~Leonardo {Camacho-Villal{\'o}n}}, \bibinfo{person}{Marco Dorigo}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2022}\natexlab{}.
\newblock \showarticletitle{{PSO}\textsl{-X}: A Component-Based Framework for the Automatic Design of Particle Swarm Optimization Algorithms}.
\newblock \bibinfo{journal}{\emph{IEEE Transactions on Evolutionary Computation}} \bibinfo{volume}{26}, \bibinfo{number}{3} (\bibinfo{year}{2022}), \bibinfo{pages}{402--416}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1109/TEVC.2021.3102863}
\showDOI{\tempurl}


\bibitem[{Camacho-Villal{\'o}n} et~al\mbox{.}(2023)]%
{CamDorStu2022:exposing:itor}
\bibfield{author}{\bibinfo{person}{Christian~Leonardo {Camacho-Villal{\'o}n}}, \bibinfo{person}{Marco Dorigo}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2023}\natexlab{}.
\newblock \showarticletitle{Exposing the grey wolf, moth-flame, whale, firefly, bat, and antlion algorithms: six misleading optimization techniques inspired by bestial metaphors}.
\newblock \bibinfo{journal}{\emph{International Transactions in Operational Research}} \bibinfo{volume}{30}, \bibinfo{number}{6} (\bibinfo{year}{2023}), \bibinfo{pages}{2945–--2971}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1111/itor.13176}
\showDOI{\tempurl}


\bibitem[Camacho-Villalón et~al\mbox{.}(2023)]%
{CamStuDor2023:IC:disNewMH}
\bibfield{author}{\bibinfo{person}{Christian~Leonardo Camacho-Villalón}, \bibinfo{person}{Thomas Stützle}, {and} \bibinfo{person}{Marco Dorigo}.} \bibinfo{year}{2023}\natexlab{}.
\newblock \showarticletitle{Designing New Metaheuristics: Manual versus Automatic Approaches}.
\newblock \bibinfo{journal}{\emph{Intelligent Computing}} \bibinfo{volume}{2}, \bibinfo{number}{0048} (\bibinfo{year}{2023}), \bibinfo{pages}{1--15}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.34133/icomputing.0048}
\showDOI{\tempurl}


\bibitem[Chen and Liu(2022)]%
{CheLiu22:nature-scirep}
\bibfield{author}{\bibinfo{person}{Zhe Chen} {and} \bibinfo{person}{Yuanxing Liu}.} \bibinfo{year}{2022}\natexlab{}.
\newblock \showarticletitle{Individuals redistribution based on differential evolution for covariance matrix adaptation evolution strategy}.
\newblock \bibinfo{journal}{\emph{Scientific Reports}} \bibinfo{volume}{12}, \bibinfo{number}{1} (\bibinfo{year}{2022}), \bibinfo{pages}{986}.
\newblock


\bibitem[Clerc(2011)]%
{Clerc2011:pso}
\bibfield{author}{\bibinfo{person}{Maurice Clerc}.} \bibinfo{year}{2011}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Standard Particle Swarm Optimisation from 2006 to 2011}}.
\newblock \bibinfo{type}{open archive HAL} hal-00764996. \bibinfo{institution}{HAL}.
\newblock


\bibitem[Das et~al\mbox{.}(2005)]%
{DasKonCha05:gecco}
\bibfield{author}{\bibinfo{person}{Swagatam Das}, \bibinfo{person}{Amit Konar}, {and} \bibinfo{person}{Uday~K Chakraborty}.} \bibinfo{year}{2005}\natexlab{}.
\newblock \showarticletitle{Improving particle swarm optimization with differentially perturbed velocity}. In \bibinfo{booktitle}{\emph{Proceedings of the 7th annual conference on Genetic and evolutionary computation}}. \bibinfo{publisher}{ACM Press}, \bibinfo{address}{New York, NY}, \bibinfo{pages}{177--184}.
\newblock


\bibitem[Das and Suganthan(2011)]%
{DasSug2011:tec}
\bibfield{author}{\bibinfo{person}{Swagatam Das} {and} \bibinfo{person}{Ponnuthurai~N. Suganthan}.} \bibinfo{year}{2011}\natexlab{}.
\newblock \showarticletitle{Differential Evolution: A Survey of the State-of-the-art}.
\newblock \bibinfo{journal}{\emph{IEEE Transactions on Evolutionary Computation}} \bibinfo{volume}{15}, \bibinfo{number}{1} (\bibinfo{date}{Feb.} \bibinfo{year}{2011}), \bibinfo{pages}{4--31}.
\newblock


\bibitem[de~Nobel et~al\mbox{.}(2021)]%
{deNVerWan2021:gecco-CMAESframework}
\bibfield{author}{\bibinfo{person}{Jacob de Nobel}, \bibinfo{person}{Diederick Vermetten}, \bibinfo{person}{Hao Wang}, \bibinfo{person}{Carola Doerr}, {and} \bibinfo{person}{Thomas B{\"a}ck}.} \bibinfo{year}{2021}\natexlab{}.
\newblock \showarticletitle{Tuning as a means of assessing the benefits of new ideas in interplay with existing algorithmic modules}. In \bibinfo{booktitle}{\emph{GECCO'21 Companion}}, \bibfield{editor}{\bibinfo{person}{Francisco Chicano}} (Ed.). \bibinfo{publisher}{ACM Press}, \bibinfo{address}{New York, NY}, \bibinfo{pages}{1375--1384}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1145/3449726.3463167}
\showDOI{\tempurl}


\bibitem[Deb(2012)]%
{Deb2012:book-OptimizationED}
\bibfield{author}{\bibinfo{person}{Kalyanmoy Deb}.} \bibinfo{year}{2012}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Optimization for engineering design: Algorithms and examples}}.
\newblock \bibinfo{publisher}{PHI Learning Pvt. Ltd.}, \bibinfo{address}{New Delhi, India}.
\newblock


\bibitem[Del~Ser et~al\mbox{.}(2019)]%
{SerOsaMol2019:sec-BioComputation}
\bibfield{author}{\bibinfo{person}{Javier Del~Ser}, \bibinfo{person}{Eneko Osaba}, \bibinfo{person}{Daniel Molina}, \bibinfo{person}{Xin-She Yang}, \bibinfo{person}{Sancho Salcedo-Sanz}, \bibinfo{person}{David Camacho}, \bibinfo{person}{Swagatam Das}, \bibinfo{person}{Ponnuthurai~N Suganthan}, \bibinfo{person}{Carlos A~Coello Coello}, {and} \bibinfo{person}{Francisco Herrera}.} \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{Bio-inspired computation: Where we stand and what's next}.
\newblock \bibinfo{journal}{\emph{Swarm and Evolutionary Computation}}  \bibinfo{volume}{48} (\bibinfo{year}{2019}), \bibinfo{pages}{220--250}.
\newblock


\bibitem[Dorigo and Birattari(2007)]%
{DorBir2007:sch-si}
\bibfield{author}{\bibinfo{person}{M. Dorigo} {and} \bibinfo{person}{M. Birattari}.} \bibinfo{year}{2007}\natexlab{}.
\newblock \showarticletitle{Swarm Intelligence}.
\newblock \bibinfo{journal}{\emph{Scholarpedia}} \bibinfo{volume}{2}, \bibinfo{number}{9} (\bibinfo{year}{2007}), \bibinfo{pages}{1462}.
\newblock
\urldef\tempurl%
\url{http://www.scholarpedia.org/article/Swarm_intelligence}
\showURL{%
	\tempurl}


\bibitem[Eberhart and Kennedy(1995)]%
{EbeKen1995:pso}
\bibfield{author}{\bibinfo{person}{Russell Eberhart} {and} \bibinfo{person}{James Kennedy}.} \bibinfo{year}{1995}\natexlab{}.
\newblock \showarticletitle{A New Optimizer Using Particle Swarm Theory}. In \bibinfo{booktitle}{\emph{Proceedings of the Sixth International Symposium on Micro Machine and Human Science}}. \bibinfo{publisher}{IEEE Press}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{39--43}.
\newblock


\bibitem[Epitropakis et~al\mbox{.}(2012)]%
{EpiPlaVra12:is}
\bibfield{author}{\bibinfo{person}{Michael~G Epitropakis}, \bibinfo{person}{Vassilis~P Plagianakos}, {and} \bibinfo{person}{Michael~N Vrahatis}.} \bibinfo{year}{2012}\natexlab{}.
\newblock \showarticletitle{Evolving cognitive and social experience in particle swarm optimization through differential evolution: a hybrid approach}.
\newblock \bibinfo{journal}{\emph{Information Sciences}}  \bibinfo{volume}{216} (\bibinfo{year}{2012}), \bibinfo{pages}{50--92}.
\newblock


\bibitem[Fogel et~al\mbox{.}(1966)]%
{FogOweWal1966}
\bibfield{author}{\bibinfo{person}{David~B. Fogel}, \bibinfo{person}{Alvin~J. Owens}, {and} \bibinfo{person}{Michael~J. Walsh}.} \bibinfo{year}{1966}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Artificial Intelligence Through Simulated Evolution}}.
\newblock \bibinfo{publisher}{John Wiley \& Sons}, \bibinfo{address}{Chichester, UK}.
\newblock


\bibitem[Franzin and St{\"u}tzle(2019)]%
{FraStu2019:cor}
\bibfield{author}{\bibinfo{person}{Alberto Franzin} {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{Revisiting simulated annealing: A component-based analysis}.
\newblock \bibinfo{journal}{\emph{Computers \& Operations Research}}  \bibinfo{volume}{104} (\bibinfo{year}{2019}), \bibinfo{pages}{191--206}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1016/j.cor.2018.12.015}
\showDOI{\tempurl}


\bibitem[Gendreau and Potvin(2019)]%
{Handbook2019}
\bibfield{editor}{\bibinfo{person}{Michel Gendreau} {and} \bibinfo{person}{Jean-Yves Potvin}} (Eds.). \bibinfo{year}{2019}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Handbook of Metaheuristics}}. \bibinfo{series}{International Series in Operations Research \& Management Science}, Vol.~\bibinfo{volume}{272}.
\newblock \bibinfo{publisher}{Springer}, \bibinfo{address}{New York, NY}.
\newblock


\bibitem[Ghosh et~al\mbox{.}(2012)]%
{GhoDasRoy12:is}
\bibfield{author}{\bibinfo{person}{Saurav Ghosh}, \bibinfo{person}{Swagatam Das}, \bibinfo{person}{Subhrajit Roy}, \bibinfo{person}{SK~Minhazul Islam}, {and} \bibinfo{person}{Ponnuthurai~N Suganthan}.} \bibinfo{year}{2012}\natexlab{}.
\newblock \showarticletitle{A differential covariance matrix adaptation evolutionary algorithm for real parameter optimization}.
\newblock \bibinfo{journal}{\emph{Information Sciences}} \bibinfo{volume}{182}, \bibinfo{number}{1} (\bibinfo{year}{2012}), \bibinfo{pages}{199--219}.
\newblock


\bibitem[Glover(1986)]%
{Glo1986}
\bibfield{author}{\bibinfo{person}{Fred Glover}.} \bibinfo{year}{1986}\natexlab{}.
\newblock \showarticletitle{Future Paths for Integer Programming and Links to Artificial Intelligence}.
\newblock \bibinfo{journal}{\emph{Computers \& Operations Research}} \bibinfo{volume}{13}, \bibinfo{number}{5} (\bibinfo{year}{1986}), \bibinfo{pages}{533--549}.
\newblock


\bibitem[Goldberg(1989)]%
{Goldberg89}
\bibfield{author}{\bibinfo{person}{David~Edward Goldberg}.} \bibinfo{year}{1989}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Genetic Algorithms in Search, Optimization and Machine Learning}}.
\newblock \bibinfo{publisher}{Addison-Wesley}, \bibinfo{address}{Boston, MA, USA}.
\newblock


\bibitem[Grosan and Abraham(2007)]%
{GroAbr07:hea}
\bibfield{author}{\bibinfo{person}{Crina Grosan} {and} \bibinfo{person}{Ajith Abraham}.} \bibinfo{year}{2007}\natexlab{}.
\newblock \showarticletitle{Hybrid evolutionary algorithms: methodologies, architectures, and reviews}.
\newblock In \bibinfo{booktitle}{\emph{Hybrid evolutionary algorithms}}. \bibinfo{publisher}{Springer}, \bibinfo{address}{Cham}, \bibinfo{pages}{1--17}.
\newblock


\bibitem[Guo and Yang(2014)]%
{GuoYan14:tevc}
\bibfield{author}{\bibinfo{person}{Shu-Mei Guo} {and} \bibinfo{person}{Chin-Chang Yang}.} \bibinfo{year}{2014}\natexlab{}.
\newblock \showarticletitle{Enhancing differential evolution utilizing eigenvector-based crossover operator}.
\newblock \bibinfo{journal}{\emph{IEEE Transactions on Evolutionary Computation}} \bibinfo{volume}{19}, \bibinfo{number}{1} (\bibinfo{year}{2014}), \bibinfo{pages}{31--49}.
\newblock


\bibitem[Hansen(1997)]%
{Han1997}
\bibfield{author}{\bibinfo{person}{Michael~Pilegaard Hansen}.} \bibinfo{year}{1997}\natexlab{}.
\newblock \showarticletitle{Tabu search for multiobjective optimization: {MOTS}}.
\newblock In \bibinfo{booktitle}{\emph{Proceedings of the 13th International Conference on Multiple Criteria Decision Making (MCDM'97)}}, \bibfield{editor}{\bibinfo{person}{J.~Climaco}} (Ed.). \bibinfo{publisher}{Springer Verlag}, \bibinfo{address}{Berlin, Heidelberg, Germany}, \bibinfo{pages}{574--586}.
\newblock


\bibitem[Hansen(2006)]%
{Hansen2006cma}
\bibfield{author}{\bibinfo{person}{Nikolaus Hansen}.} \bibinfo{year}{2006}\natexlab{}.
\newblock \showarticletitle{The {CMA} evolution strategy: a comparing review}.
\newblock In \bibinfo{booktitle}{\emph{Towards a new evolutionary computation}}. \bibinfo{publisher}{Springer}, \bibinfo{address}{Berlin, Heidelberg, Germany}, \bibinfo{pages}{75--102}.
\newblock


\bibitem[Hansen(2016)]%
{Hansen2016:cma-tutorial}
\bibfield{author}{\bibinfo{person}{Nikolaus Hansen}.} \bibinfo{year}{2016}\natexlab{}.
\newblock \showarticletitle{The CMA evolution strategy: A tutorial}.
\newblock \bibinfo{journal}{\emph{CoRR}}  \bibinfo{volume}{abs/1604.00772} (\bibinfo{year}{2016}), \bibinfo{pages}{1--39}.
\newblock
\showeprint[arXiv]{1604.00772}
\urldef\tempurl%
\url{http://arxiv.org/abs/1604.00772}
\showURL{%
	\tempurl}


\bibitem[Hansen et~al\mbox{.}(2015)]%
{HanArnAug2015evolutionstrategies}
\bibfield{author}{\bibinfo{person}{Nikolaus Hansen}, \bibinfo{person}{Dirk~V Arnold}, {and} \bibinfo{person}{Anne Auger}.} \bibinfo{year}{2015}\natexlab{}.
\newblock \showarticletitle{Evolution strategies}.
\newblock In \bibinfo{booktitle}{\emph{Springer handbook of computational intelligence}}. \bibinfo{publisher}{Springer}, \bibinfo{address}{Berlin, Germany}, \bibinfo{pages}{871--898}.
\newblock


\bibitem[Hansen et~al\mbox{.}(2003)]%
{HanMulKou03:ec}
\bibfield{author}{\bibinfo{person}{Nikolaus Hansen}, \bibinfo{person}{Sibylle~D M{\"u}ller}, {and} \bibinfo{person}{Petros Koumoutsakos}.} \bibinfo{year}{2003}\natexlab{}.
\newblock \showarticletitle{Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES)}.
\newblock \bibinfo{journal}{\emph{Evolutionary computation}} \bibinfo{volume}{11}, \bibinfo{number}{1} (\bibinfo{year}{2003}), \bibinfo{pages}{1--18}.
\newblock


\bibitem[Hansen and Ostermeier(2001)]%
{HanOst2001ec}
\bibfield{author}{\bibinfo{person}{Nikolaus Hansen} {and} \bibinfo{person}{A. Ostermeier}.} \bibinfo{year}{2001}\natexlab{}.
\newblock \showarticletitle{Completely derandomized self-adaptation in evolution strategies}.
\newblock \bibinfo{journal}{\emph{Evolutionary Computation}} \bibinfo{volume}{9}, \bibinfo{number}{2} (\bibinfo{year}{2001}), \bibinfo{pages}{159--195}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1162/106365601750190398}
\showDOI{\tempurl}


\bibitem[He and Zhou(2018)]%
{HeZho18:asoc}
\bibfield{author}{\bibinfo{person}{Xiaoyu He} {and} \bibinfo{person}{Yuren Zhou}.} \bibinfo{year}{2018}\natexlab{}.
\newblock \showarticletitle{Enhancing the performance of differential evolution with covariance matrix self-adaptation}.
\newblock \bibinfo{journal}{\emph{Applied Soft Computing}}  \bibinfo{volume}{64} (\bibinfo{year}{2018}), \bibinfo{pages}{227--243}.
\newblock


\bibitem[Hendtlass(2001)]%
{Hendtlass01:iea-aie}
\bibfield{author}{\bibinfo{person}{Tim Hendtlass}.} \bibinfo{year}{2001}\natexlab{}.
\newblock \showarticletitle{A combined swarm differential evolution algorithm for optimization problems}. In \bibinfo{booktitle}{\emph{Engineering of Intelligent Systems: 14th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, IEA/AIE 2001 Budapest, Hungary, June 4--7, 2001 Proceedings 14}}. \bibinfo{publisher}{Springer}, \bibinfo{address}{Berlin, Germany}, \bibinfo{pages}{11--18}.
\newblock


\bibitem[Herrera et~al\mbox{.}(2010)]%
{HerLozMol2010test}
\bibfield{author}{\bibinfo{person}{Francisco Herrera}, \bibinfo{person}{Manuel Lozano}, {and} \bibinfo{person}{D. Molina}.} \bibinfo{year}{2010}\natexlab{}.
\newblock \bibinfo{title}{Test suite for the special issue of {S}oft {C}omputing on scalability of evolutionary algorithms and other metaheuristics for large scale continuous optimization problems}.
\newblock \bibinfo{howpublished}{\url{http://sci2s.ugr.es/eamhco/}}.
\newblock


\bibitem[Holland(1975)]%
{Hol75}
\bibfield{author}{\bibinfo{person}{John~Henry Holland}.} \bibinfo{year}{1975}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Adaptation in Natural and Artificial Systems}}.
\newblock \bibinfo{publisher}{University of Michigan Press}, \bibinfo{address}{Ann Arbor, Michigan, United States}.
\newblock


\bibitem[Hoos and St{\"u}tzle(2005)]%
{HooStu05sls-mk}
\bibfield{author}{\bibinfo{person}{Holger~H. Hoos} {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2005}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Stochastic Local Search---Foundations and Applications}}.
\newblock \bibinfo{publisher}{Morgan Kaufmann Publishers}, \bibinfo{address}{San Francisco, CA}.
\newblock


\bibitem[Hsieh et~al\mbox{.}(2007)]%
{HsiCheChe07:gecco}
\bibfield{author}{\bibinfo{person}{Chang-Tai Hsieh}, \bibinfo{person}{Chih-Ming Chen}, {and} \bibinfo{person}{Ying-ping Chen}.} \bibinfo{year}{2007}\natexlab{}.
\newblock \showarticletitle{Particle swarm guided evolution strategy}. In \bibinfo{booktitle}{\emph{Proceedings of the 9th annual Conference on Genetic and Evolutionary Computation}}. \bibinfo{publisher}{ACM Press}, \bibinfo{address}{New York, NY}, \bibinfo{pages}{650--657}.
\newblock


\bibitem[Hutter et~al\mbox{.}(2011)]%
{HutHooLey2011lion}
\bibfield{author}{\bibinfo{person}{Frank Hutter}, \bibinfo{person}{Holger~H. Hoos}, {and} \bibinfo{person}{Kevin Leyton-Brown}.} \bibinfo{year}{2011}\natexlab{}.
\newblock \showarticletitle{Sequential Model-Based Optimization for General Algorithm Configuration}.
\newblock In \bibinfo{booktitle}{\emph{Learning and Intelligent Optimization, 5th International Conference, LION 5}}, \bibfield{editor}{\bibinfo{person}{Carlos~A. {Coello Coello}}} (Ed.). \bibinfo{series}{Lecture Notes in Computer Science}, Vol.~\bibinfo{volume}{6683}. \bibinfo{publisher}{Springer, Heidelberg, Germany}, \bibinfo{address}{Heidelberg, Germany}, \bibinfo{pages}{507--523}.
\newblock


\bibitem[Hutter et~al\mbox{.}(2009)]%
{HutHooLeyStu2009jair}
\bibfield{author}{\bibinfo{person}{Frank Hutter}, \bibinfo{person}{Holger~H. Hoos}, \bibinfo{person}{Kevin Leyton-Brown}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2009}\natexlab{}.
\newblock \showarticletitle{{ParamILS:} An Automatic Algorithm Configuration Framework}.
\newblock \bibinfo{journal}{\emph{Journal of Artificial Intelligence Research}}  \bibinfo{volume}{36} (\bibinfo{date}{Oct.} \bibinfo{year}{2009}), \bibinfo{pages}{267--306}.
\newblock


\bibitem[K{\"a}mpf and Robinson(2009)]%
{KamJerRob09:asoc}
\bibfield{author}{\bibinfo{person}{J{\'e}r{\^o}me~Henri K{\"a}mpf} {and} \bibinfo{person}{Darren Robinson}.} \bibinfo{year}{2009}\natexlab{}.
\newblock \showarticletitle{A hybrid CMA-ES and HDE optimisation algorithm with application to solar energy potential}.
\newblock \bibinfo{journal}{\emph{Applied Soft Computing}} \bibinfo{volume}{9}, \bibinfo{number}{2} (\bibinfo{year}{2009}), \bibinfo{pages}{738--745}.
\newblock


\bibitem[Karaboga et~al\mbox{.}(2005)]%
{Kar2005idea}
\bibfield{author}{\bibinfo{person}{Dervis Karaboga} {et~al\mbox{.}}} \bibinfo{year}{2005}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{An idea based on honey bee swarm for numerical optimization}}.
\newblock \bibinfo{type}{{T}echnical {R}eport}. \bibinfo{institution}{Technical report-tr06, Erciyes university, engineering faculty, computer~…}.
\newblock


\bibitem[Karaboga and Basturk(2007)]%
{KarBas2007}
\bibfield{author}{\bibinfo{person}{Dervis Karaboga} {and} \bibinfo{person}{Bahriye Basturk}.} \bibinfo{year}{2007}\natexlab{}.
\newblock \showarticletitle{A powerful and efficient algorithm for numerical function optimization: artificial bee colony ({ABC}) algorithm}.
\newblock \bibinfo{journal}{\emph{Journal of Global Optimization}} \bibinfo{volume}{39}, \bibinfo{number}{3} (\bibinfo{year}{2007}), \bibinfo{pages}{459--471}.
\newblock


\bibitem[Kennedy and Eberhart(1995)]%
{KenEbe1995pso}
\bibfield{author}{\bibinfo{person}{James Kennedy} {and} \bibinfo{person}{Russell Eberhart}.} \bibinfo{year}{1995}\natexlab{}.
\newblock \showarticletitle{Particle swarm optimization}. In \bibinfo{booktitle}{\emph{Proceedings of ICNN'95-International Conference on Neural Networks}}, Vol.~\bibinfo{volume}{4}. \bibinfo{publisher}{IEEE}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{1942--1948}.
\newblock


\bibitem[Kennedy et~al\mbox{.}(2001)]%
{KenEbeShi01}
\bibfield{author}{\bibinfo{person}{J. Kennedy}, \bibinfo{person}{R.~C. Eberhart}, {and} \bibinfo{person}{Y. Shi}.} \bibinfo{year}{2001}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Swarm Intelligence}}.
\newblock \bibinfo{publisher}{Morgan Kaufmann Publishers, San Francisco, CA}, \bibinfo{address}{San Francisco, CA}.
\newblock


\bibitem[Kostovska et~al\mbox{.}(2024)]%
{KosVerKor2024:ev}
\bibfield{author}{\bibinfo{person}{Ana Kostovska}, \bibinfo{person}{Diederick Vermetten}, \bibinfo{person}{Peter Koro{\v{s}}ec}, \bibinfo{person}{Sa{\v{s}}o D{\v{z}}eroski}, \bibinfo{person}{Carola Doerr}, {and} \bibinfo{person}{Tome Eftimov}.} \bibinfo{year}{2024}\natexlab{}.
\newblock \showarticletitle{Using Machine Learning Methods to Assess Module Performance Contribution in Modular Optimization Frameworks}.
\newblock \bibinfo{journal}{\emph{Evolutionary computation}} (\bibinfo{year}{2024}), \bibinfo{pages}{1--28}.
\newblock


\bibitem[LaTorre et~al\mbox{.}(2011)]%
{LaTMuePen11:soco}
\bibfield{author}{\bibinfo{person}{Antonio LaTorre}, \bibinfo{person}{Santiago Muelas}, {and} \bibinfo{person}{Jos{\'e}-Mar{\'\i}a Pe{\~n}a}.} \bibinfo{year}{2011}\natexlab{}.
\newblock \showarticletitle{A {MOS}-based dynamic memetic differential evolution algorithm for continuous optimization: a scalability test}.
\newblock \bibinfo{journal}{\emph{Soft Computing}} \bibinfo{volume}{15}, \bibinfo{number}{11} (\bibinfo{year}{2011}), \bibinfo{pages}{2187--2199}.
\newblock


\bibitem[Leguizam{\'o}n and Coello(2010)]%
{LegCoe2010:ants-alternativeACO}
\bibfield{author}{\bibinfo{person}{Guillermo Leguizam{\'o}n} {and} \bibinfo{person}{Carlos A~Coello Coello}.} \bibinfo{year}{2010}\natexlab{}.
\newblock \showarticletitle{An Alternative ACO \_R Algorithm for Continuous Optimization Problems}. In \bibinfo{booktitle}{\emph{Swarm Intelligence: 7th International Conference, ANTS 2010, Brussels, Belgium, September 8-10, 2010. Proceedings 7}}. \bibinfo{publisher}{Springer}, \bibinfo{address}{Berlin, Heidelberg, Germany}, \bibinfo{pages}{48--59}.
\newblock


\bibitem[Liang et~al\mbox{.}(2013)]%
{LiaQu2013problem}
\bibfield{author}{\bibinfo{person}{J.J. Liang}, \bibinfo{person}{B.Y. Qu}, {and} \bibinfo{person}{Ponnuthurai~N. Suganthan}.} \bibinfo{year}{2013}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Problem definitions and evaluation criteria for the {CEC 2014} special session and competition on single objective real-parameter numerical optimization}}.
\newblock \bibinfo{type}{{T}echnical {R}eport}. \bibinfo{institution}{Computational Intelligence Laboratory, Zhengzhou University, Zhengzhou China and Technical Report, Nanyang Technological University, Singapore}.
\newblock


\bibitem[Liao et~al\mbox{.}(2014a)]%
{LiaMolMonStu2014}
\bibfield{author}{\bibinfo{person}{Tianjun Liao}, \bibinfo{person}{Daniel Molina}, \bibinfo{person}{Marco~A. {Montes de Oca}}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2014}\natexlab{a}.
\newblock \showarticletitle{A Note on the Effects of Enforcing Bound Constraints on Algorithm Comparisons using the {IEEE} {CEC'05} Benchmark Function Suite}.
\newblock \bibinfo{journal}{\emph{Evolutionary Computation}} \bibinfo{volume}{22}, \bibinfo{number}{2} (\bibinfo{year}{2014}), \bibinfo{pages}{351--359}.
\newblock


\bibitem[Liao et~al\mbox{.}(2015)]%
{LiaMolStu2015}
\bibfield{author}{\bibinfo{person}{Tianjun Liao}, \bibinfo{person}{Daniel Molina}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2015}\natexlab{}.
\newblock \showarticletitle{Performance Evaluation of Automatically Tuned Continuous Optimizers on Different Benchmark Sets}.
\newblock \bibinfo{journal}{\emph{Applied Soft Computing}}  \bibinfo{volume}{27} (\bibinfo{year}{2015}), \bibinfo{pages}{490--503}.
\newblock


\bibitem[Liao et~al\mbox{.}(2013)]%
{LiaMonStu13:soco}
\bibfield{author}{\bibinfo{person}{Tianjun Liao}, \bibinfo{person}{Marco~A. {Montes de Oca}}, {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2013}\natexlab{}.
\newblock \showarticletitle{Computational results for an automatically tuned {CMA-ES} with increasing population size on the {CEC'05} benchmark set}.
\newblock \bibinfo{journal}{\emph{Soft Computing}} \bibinfo{volume}{17}, \bibinfo{number}{6} (\bibinfo{year}{2013}), \bibinfo{pages}{1031--1046}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1007/s00500-012-0946-x}
\showDOI{\tempurl}


\bibitem[Liao and St{\"u}tzle(2013)]%
{LiaStu2013cec}
\bibfield{author}{\bibinfo{person}{Tianjun Liao} {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2013}\natexlab{}.
\newblock \showarticletitle{Benchmark results for a simple hybrid algorithm on the {CEC} 2013 benchmark set for real-parameter optimization}.
\newblock In \bibinfo{booktitle}{\emph{Proceedings of the 2013 Congress on Evolutionary Computation (CEC 2013)}}. \bibinfo{publisher}{IEEE Press}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{1938--1944}.
\newblock


\bibitem[Liao et~al\mbox{.}(2014b)]%
{LiaStuMonDor2014}
\bibfield{author}{\bibinfo{person}{Tianjun Liao}, \bibinfo{person}{Thomas St{\"u}tzle}, \bibinfo{person}{Marco~A. {Montes de Oca}}, {and} \bibinfo{person}{Marco Dorigo}.} \bibinfo{year}{2014}\natexlab{b}.
\newblock \showarticletitle{A Unified Ant Colony Optimization Algorithm for Continuous Optimization}.
\newblock \bibinfo{journal}{\emph{European Journal of Operational Research}} \bibinfo{volume}{234}, \bibinfo{number}{3} (\bibinfo{year}{2014}), \bibinfo{pages}{597--609}.
\newblock


\bibitem[L{\'o}pez-Ib{\'a}{\~n}ez et~al\mbox{.}(2016)]%
{LopDubPerStuBir2016irace}
\bibfield{author}{\bibinfo{person}{Manuel L{\'o}pez-Ib{\'a}{\~n}ez}, \bibinfo{person}{J{\'e}r{\'e}mie Dubois-Lacoste}, \bibinfo{person}{Leslie {P{\'e}rez C{\'a}ceres}}, \bibinfo{person}{Thomas St{\"u}tzle}, {and} \bibinfo{person}{Mauro Birattari}.} \bibinfo{year}{2016}\natexlab{}.
\newblock \showarticletitle{The {\Rpackage{irace}} package: Iterated Racing for Automatic Algorithm Configuration}.
\newblock \bibinfo{journal}{\emph{Operations Research Perspectives}}  \bibinfo{volume}{3} (\bibinfo{year}{2016}), \bibinfo{pages}{43--58}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1016/j.orp.2016.09.002}
\showDOI{\tempurl}


\bibitem[L{\'o}pez-Ib{\'a}{\~n}ez et~al\mbox{.}(2011)]%
{LopDubStu2011irace}
\bibfield{author}{\bibinfo{person}{Manuel L{\'o}pez-Ib{\'a}{\~n}ez}, \bibinfo{person}{J{\'e}r{\'e}mie Dubois-Lacoste}, \bibinfo{person}{Thomas St{\"u}tzle}, {and} \bibinfo{person}{Mauro Birattari}.} \bibinfo{year}{2011}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{The {\Rpackage{irace}} package, Iterated Race for Automatic Algorithm Configuration}}.
\newblock \bibinfo{type}{{T}echnical {R}eport} TR/IRIDIA/2011-004. \bibinfo{institution}{IRIDIA, Universit{\'e} Libre de Bruxelles, Belgium}.
\newblock
\urldef\tempurl%
\url{http://iridia.ulb.ac.be/IridiaTrSeries/IridiaTr2011-004.pdf}
\showURL{%
	\tempurl}


\bibitem[L{\'o}pez-Ib{\'a}{\~n}ez and St{\"u}tzle(2012)]%
{LopStu2012tec}
\bibfield{author}{\bibinfo{person}{Manuel L{\'o}pez-Ib{\'a}{\~n}ez} {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2012}\natexlab{}.
\newblock \showarticletitle{The Automatic Design of Multi-Objective Ant Colony Optimization Algorithms}.
\newblock \bibinfo{journal}{\emph{IEEE Transactions on Evolutionary Computation}} \bibinfo{volume}{16}, \bibinfo{number}{6} (\bibinfo{year}{2012}), \bibinfo{pages}{861--875}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1109/TEVC.2011.2182651}
\showDOI{\tempurl}


\bibitem[L{\'o}pez-Ib{\'a}{\~n}ez et~al\mbox{.}(2017)]%
{LopStuDor2017aco}
\bibfield{author}{\bibinfo{person}{Manuel L{\'o}pez-Ib{\'a}{\~n}ez}, \bibinfo{person}{Thomas St{\"u}tzle}, {and} \bibinfo{person}{Marco Dorigo}.} \bibinfo{year}{2017}\natexlab{}.
\newblock \showarticletitle{Ant Colony Optimization: A Component-Wise Overview}.
\newblock In \bibinfo{booktitle}{\emph{Handbook of Heuristics}}, \bibfield{editor}{\bibinfo{person}{Rafael Mart{\'\i}}, \bibinfo{person}{Panos~M. Pardalos}, {and} \bibinfo{person}{Mauricio G.~C. Resende}} (Eds.). \bibinfo{publisher}{Springer International Publishing}, \bibinfo{address}{Berlin, Heidelberg, Germany}, \bibinfo{pages}{1--37}.
\newblock
\showISBNx{978-3-319-07153-4}
\urldef\tempurl%
\url{https://doi.org/10.1007/978-3-319-07153-4_21-1}
\showDOI{\tempurl}


\bibitem[Luenberger et~al\mbox{.}(2016)]%
{LueYe1984:Book-linear-nonlinear}
\bibfield{author}{\bibinfo{person}{David~G Luenberger}, \bibinfo{person}{Yinyu Ye}, {et~al\mbox{.}}} \bibinfo{year}{2016}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Linear and Nonlinear Programming}}.
\newblock \bibinfo{publisher}{Springer}, \bibinfo{address}{Cham}.
\newblock


\bibitem[Maron and Moore(1997)]%
{MarMoo1997air}
\bibfield{author}{\bibinfo{person}{O. Maron} {and} \bibinfo{person}{A.~W. Moore}.} \bibinfo{year}{1997}\natexlab{}.
\newblock \showarticletitle{The Racing Algorithm: {M}odel Selection for Lazy Learners}.
\newblock \bibinfo{journal}{\emph{Artificial Intelligence Research}} \bibinfo{volume}{11}, \bibinfo{number}{1--5} (\bibinfo{year}{1997}), \bibinfo{pages}{193--225}.
\newblock


\bibitem[Mendes et~al\mbox{.}(2004)]%
{MenKenNev2004fullyInformed_pso}
\bibfield{author}{\bibinfo{person}{Rui Mendes}, \bibinfo{person}{James Kennedy}, {and} \bibinfo{person}{Jos{\'e} Neves}.} \bibinfo{year}{2004}\natexlab{}.
\newblock \showarticletitle{The fully informed particle swarm: simpler, maybe better}.
\newblock \bibinfo{journal}{\emph{IEEE Transactions on Evolutionary Computation}} \bibinfo{volume}{8}, \bibinfo{number}{3} (\bibinfo{year}{2004}), \bibinfo{pages}{204--210}.
\newblock


\bibitem[Molina et~al\mbox{.}(2011)]%
{MolLozSan11:soco}
\bibfield{author}{\bibinfo{person}{Daniel Molina}, \bibinfo{person}{Manuel Lozano}, \bibinfo{person}{Ana~M S{\'a}nchez}, {and} \bibinfo{person}{Francisco Herrera}.} \bibinfo{year}{2011}\natexlab{}.
\newblock \showarticletitle{Memetic algorithms based on local search chains for large scale continuous optimisation problems: MA-SSW-Chains}.
\newblock \bibinfo{journal}{\emph{Soft Computing}}  \bibinfo{volume}{15} (\bibinfo{year}{2011}), \bibinfo{pages}{2201--2220}.
\newblock


\bibitem[Muller et~al\mbox{.}(2009)]%
{MulBauSba09:ieee-cec}
\bibfield{author}{\bibinfo{person}{Christian~L Muller}, \bibinfo{person}{Benedikt Baumgartner}, {and} \bibinfo{person}{Ivo~F Sbalzarini}.} \bibinfo{year}{2009}\natexlab{}.
\newblock \showarticletitle{Particle swarm CMA evolution strategy for the optimization of multi-funnel landscapes}. In \bibinfo{booktitle}{\emph{2009 IEEE Congress on Evolutionary Computation}}. \bibinfo{publisher}{IEEE}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{2685--2692}.
\newblock


\bibitem[Nebro et~al\mbox{.}(2023)]%
{NebLopGar23:si:mopso}
\bibfield{author}{\bibinfo{person}{Antonio~J Nebro}, \bibinfo{person}{Manuel L{\'o}pez-Ib{\'a}{\~n}ez}, \bibinfo{person}{Jos{\'e} Garc{\'\i}a-Nieto}, {and} \bibinfo{person}{Carlos~A Coello~Coello}.} \bibinfo{year}{2023}\natexlab{}.
\newblock \showarticletitle{On the automatic design of multi-objective particle swarm optimizers: experimentation and analysis}.
\newblock \bibinfo{journal}{\emph{Swarm Intelligence}}  \bibinfo{volume}{18} (\bibinfo{year}{2023}), \bibinfo{pages}{105--139}.
\newblock


\bibitem[Nelder and Mead(1965)]%
{NelMea1965:tcj-simplex}
\bibfield{author}{\bibinfo{person}{John~A Nelder} {and} \bibinfo{person}{Roger Mead}.} \bibinfo{year}{1965}\natexlab{}.
\newblock \showarticletitle{A simplex method for function minimization}.
\newblock \bibinfo{journal}{\emph{The computer journal}} \bibinfo{volume}{7}, \bibinfo{number}{4} (\bibinfo{year}{1965}), \bibinfo{pages}{308--313}.
\newblock


\bibitem[Nocedal and Wright(2006)]%
{NocWri2006}
\bibfield{author}{\bibinfo{person}{Jorge Nocedal} {and} \bibinfo{person}{Stephen~J. Wright}.} \bibinfo{year}{2006}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Numerical Optimization} (\bibinfo{edition}{second} ed.)}.
\newblock \bibinfo{publisher}{Springer}, \bibinfo{address}{Berlin, Heidelberg, Germany}.
\newblock


\bibitem[Omran et~al\mbox{.}(2007)]%
{OmrEng07:ieee-sis}
\bibfield{author}{\bibinfo{person}{Mahamed~GH Omran}, \bibinfo{person}{Andries~P Engelbrecht}, {and} \bibinfo{person}{Ayed Salman}.} \bibinfo{year}{2007}\natexlab{}.
\newblock \showarticletitle{Differential evolution based particle swarm optimization}. In \bibinfo{booktitle}{\emph{2007 IEEE Swarm Intelligence Symposium}}. \bibinfo{publisher}{IEEE}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{112--119}.
\newblock


\bibitem[Pagnozzi and St{\"u}tzle(2019)]%
{PagStu2019:ejor}
\bibfield{author}{\bibinfo{person}{Federico Pagnozzi} {and} \bibinfo{person}{Thomas St{\"u}tzle}.} \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{Automatic design of hybrid stochastic local search algorithms for permutation flowshop problems}.
\newblock \bibinfo{journal}{\emph{European Journal of Operational Research}} \bibinfo{volume}{276}, \bibinfo{number}{2} (\bibinfo{year}{2019}), \bibinfo{pages}{409--421}.
\newblock


\bibitem[Pant et~al\mbox{.}(2008)]%
{PanThaGro08:ieee-dim}
\bibfield{author}{\bibinfo{person}{Millie Pant}, \bibinfo{person}{Radha Thangaraj}, \bibinfo{person}{Crina Grosan}, {and} \bibinfo{person}{Ajith Abraham}.} \bibinfo{year}{2008}\natexlab{}.
\newblock \showarticletitle{Hybrid differential evolution-particle swarm optimization algorithm for solving global optimization problems}. In \bibinfo{booktitle}{\emph{2008 Third International Conference on Digital Information Management}}. \bibinfo{publisher}{IEEE}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{18--24}.
\newblock


\bibitem[Powell(1964)]%
{Powell1964}
\bibfield{author}{\bibinfo{person}{Michael~JD Powell}.} \bibinfo{year}{1964}\natexlab{}.
\newblock \showarticletitle{An efficient method for finding the minimum of a function of several variables without calculating derivatives}.
\newblock \bibinfo{journal}{\emph{The computer journal}} \bibinfo{volume}{7}, \bibinfo{number}{2} (\bibinfo{year}{1964}), \bibinfo{pages}{155--162}.
\newblock


\bibitem[Powell(2002)]%
{Powell2002}
\bibfield{author}{\bibinfo{person}{Michael~JD Powell}.} \bibinfo{year}{2002}\natexlab{}.
\newblock \showarticletitle{UOBYQA: unconstrained optimization by quadratic approximation}.
\newblock \bibinfo{journal}{\emph{Mathematical Programming}} \bibinfo{volume}{92}, \bibinfo{number}{3} (\bibinfo{year}{2002}), \bibinfo{pages}{555--582}.
\newblock


\bibitem[Powell(2006)]%
{Powell2006}
\bibfield{author}{\bibinfo{person}{Michael~JD Powell}.} \bibinfo{year}{2006}\natexlab{}.
\newblock \showarticletitle{The NEWUOA software for unconstrained optimization without derivatives}.
\newblock In \bibinfo{booktitle}{\emph{Large-scale nonlinear optimization}}. \bibinfo{publisher}{Springer}, \bibinfo{address}{Berlin, Heidelberg, Germany}, \bibinfo{pages}{255--297}.
\newblock


\bibitem[Price et~al\mbox{.}(2005)]%
{PriStoLam2005:book}
\bibfield{author}{\bibinfo{person}{Kenneth Price}, \bibinfo{person}{Rainer~M. Storn}, {and} \bibinfo{person}{Jouni~A. Lampinen}.} \bibinfo{year}{2005}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Differential Evolution: A Practical Approach to Global Optimization}}.
\newblock \bibinfo{publisher}{Springer, New York, NY}, \bibinfo{address}{New York, NY}.
\newblock


\bibitem[Rechenberg(1971)]%
{Rec1971PhD}
\bibfield{author}{\bibinfo{person}{I. Rechenberg}.} \bibinfo{year}{1971}\natexlab{}.
\newblock \emph{\bibinfo{title}{Evolutionsstrategie: {O}ptimierung technischer {S}ysteme nach {P}rinzipien der biologischen {E}volution}}.
\newblock \bibinfo{thesistype}{Ph.\,D. Dissertation}. \bibinfo{school}{Department of Process Engineering, Technical University of Berlin}.
\newblock


\bibitem[Rechenberg(1973)]%
{Rec1973}
\bibfield{author}{\bibinfo{person}{I. Rechenberg}.} \bibinfo{year}{1973}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Evolutionsstrategie: {O}ptimierung technischer {S}ysteme nach {P}rinzipien der biologischen {E}volution}}.
\newblock \bibinfo{publisher}{Frommann-Holzboog}, \bibinfo{address}{Stuttgart, Germany}.
\newblock


\bibitem[Richer and Blackwell(2006)]%
{RicBla2006levyPSO}
\bibfield{author}{\bibinfo{person}{Toby~J Richer} {and} \bibinfo{person}{Tim Blackwell}.} \bibinfo{year}{2006}\natexlab{}.
\newblock \showarticletitle{The L{\'e}vy particle swarm}. In \bibinfo{booktitle}{\emph{Proceedings of the 2006 Congress on Evolutionary Computation (CEC 2006)}}. \bibinfo{publisher}{IEEE Press}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{808--815}.
\newblock


\bibitem[Ros and Hansen(2008)]%
{RosHan2008:sepCMAES}
\bibfield{author}{\bibinfo{person}{Raymond Ros} {and} \bibinfo{person}{Nikolaus Hansen}.} \bibinfo{year}{2008}\natexlab{}.
\newblock \showarticletitle{A simple modification in {CMA-ES} achieving linear time and space complexity}. In \bibinfo{booktitle}{\emph{Parallel Problem Solving from Nature--PPSN X: 10th International Conference, Dortmund, Germany, September 13-17, 2008. Proceedings 10}}. \bibinfo{publisher}{Springer}, \bibinfo{address}{Berlin, Heidelberg, Germany}, \bibinfo{pages}{296--305}.
\newblock


\bibitem[Schwefel(1977)]%
{Schwefel1977}
\bibfield{author}{\bibinfo{person}{Hans-Paul Schwefel}.} \bibinfo{year}{1977}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Numerische {O}ptimierung von {C}omputer--{M}odellen mittels der {E}volutionsstrategie}}.
\newblock \bibinfo{publisher}{Birkh{\"a}user}, \bibinfo{address}{Basel, Switzerland}.
\newblock


\bibitem[Schwefel(1981)]%
{Sch1981}
\bibfield{author}{\bibinfo{person}{Hans-Paul Schwefel}.} \bibinfo{year}{1981}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Numerical Optimization of Computer Models}}.
\newblock \bibinfo{publisher}{John Wiley \& Sons, Inc.}, \bibinfo{address}{Chichester, UK}.
\newblock


\bibitem[Shi and Eberhart(1998)]%
{ShiEbe1998modifiedPSO}
\bibfield{author}{\bibinfo{person}{Yuhui Shi} {and} \bibinfo{person}{Russell Eberhart}.} \bibinfo{year}{1998}\natexlab{}.
\newblock \showarticletitle{A modified particle swarm optimizer}. In \bibinfo{booktitle}{\emph{Proceedings of the 1998 IEEE International Conference on Evolutionary Computation (ICEC'98)}}, \bibfield{editor}{\bibinfo{person}{Patrick~K. Simpson}, \bibinfo{person}{Karen Haines}, \bibinfo{person}{Jacek Zurada}, {and} \bibinfo{person}{David Fogel}} (Eds.). \bibinfo{publisher}{IEEE Press}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{69--73}.
\newblock


\bibitem[{\v{S}}kvorc et~al\mbox{.}(2019)]%
{VskEftKor19:ieee-cec}
\bibfield{author}{\bibinfo{person}{Urban {\v{S}}kvorc}, \bibinfo{person}{Tome Eftimov}, {and} \bibinfo{person}{Peter Koro{\v{s}}ec}.} \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{CEC real-parameter optimization competitions: Progress from 2013 to 2018}. In \bibinfo{booktitle}{\emph{2019 IEEE congress on evolutionary computation (CEC)}}. \bibinfo{publisher}{IEEE}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{3126--3133}.
\newblock


\bibitem[Socha and Dorigo(2008)]%
{SocDor2008:ejor}
\bibfield{author}{\bibinfo{person}{K. Socha} {and} \bibinfo{person}{Marco Dorigo}.} \bibinfo{year}{2008}\natexlab{}.
\newblock \showarticletitle{Ant Colony Optimization for Continuous Domains}.
\newblock \bibinfo{journal}{\emph{European Journal of Operational Research}} \bibinfo{volume}{185}, \bibinfo{number}{3} (\bibinfo{year}{2008}), \bibinfo{pages}{1155--1173}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1016/j.ejor.2006.06.046}
\showDOI{\tempurl}


\bibitem[S{\"o}rensen and Glover(2013)]%
{SorGlo2013}
\bibfield{author}{\bibinfo{person}{Kenneth S{\"o}rensen} {and} \bibinfo{person}{Fred Glover}.} \bibinfo{year}{2013}\natexlab{}.
\newblock \showarticletitle{Metaheuristics}.
\newblock In \bibinfo{booktitle}{\emph{Encyclopedia of Operations Research and Management Science} (\bibinfo{edition}{3} ed.)}, \bibfield{editor}{\bibinfo{person}{Saul~I Gass} {and} \bibinfo{person}{Michael~C Fu}} (Eds.). \bibinfo{publisher}{Springer Verlag}, \bibinfo{address}{Berlin, Heidelberg, Germany}, \bibinfo{pages}{960--970}.
\newblock


\bibitem[Storn and Price(1997)]%
{StoPri1997:de}
\bibfield{author}{\bibinfo{person}{Rainer Storn} {and} \bibinfo{person}{Kenneth Price}.} \bibinfo{year}{1997}\natexlab{}.
\newblock \showarticletitle{Differential Evolution -- A Simple and Efficient Heuristic for Global Optimization over Continuous Spaces}.
\newblock \bibinfo{journal}{\emph{Journal of Global Optimization}} \bibinfo{volume}{11}, \bibinfo{number}{4} (\bibinfo{year}{1997}), \bibinfo{pages}{341--359}.
\newblock


\bibitem[St{\"u}tzle and L{\'o}pez-Ib{\'a}{\~n}ez(2019)]%
{StuLop2019hb}
\bibfield{author}{\bibinfo{person}{Thomas St{\"u}tzle} {and} \bibinfo{person}{Manuel L{\'o}pez-Ib{\'a}{\~n}ez}.} \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{Automated Design of Metaheuristic Algorithms}.
\newblock See \citeN{Handbook2019}, \bibinfo{pages}{541--579}.
\newblock
\urldef\tempurl%
\url{https://doi.org/10.1007/978-3-319-91086-4_17}
\showDOI{\tempurl}


\bibitem[Suganthan et~al\mbox{.}(2005)]%
{SugHanLia2005cec}
\bibfield{author}{\bibinfo{person}{Ponnuthurai~N. Suganthan}, \bibinfo{person}{Nikolaus Hansen}, \bibinfo{person}{J.~J. Liang}, \bibinfo{person}{Kalyanmoy Deb}, \bibinfo{person}{Y.~P. Chen}, \bibinfo{person}{A. Auger}, {and} \bibinfo{person}{S. Tiwari}.} \bibinfo{year}{2005}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Problem definitions and evaluation criteria for the {CEC 2005} special session on real-parameter optimization}}.
\newblock \bibinfo{type}{{T}echnical {R}eport}. \bibinfo{institution}{Nanyang Technological University, Singapore}.
\newblock


\bibitem[Talbi(2013)]%
{Tal2013hm}
\bibfield{editor}{\bibinfo{person}{E-G. Talbi}} (Ed.). \bibinfo{year}{2013}\natexlab{}.
\newblock \bibinfo{booktitle}{\emph{Hybrid Metaheuristics}}. \bibinfo{series}{Studies in Computational Intelligence}, Vol.~\bibinfo{volume}{434}.
\newblock \bibinfo{publisher}{Springer Verlag}, \bibinfo{address}{Berlin, Heidelberg, Germany}.
\newblock
\urldef\tempurl%
\url{http://www.springer.com/engineering/computational+intelligence+and+complexity/book/978-3-642-30670-9}
\showURL{%
	\tempurl}


\bibitem[Tseng and Chen(2008)]%
{TseChe08:ieee-ec-ci}
\bibfield{author}{\bibinfo{person}{Lin-Yu Tseng} {and} \bibinfo{person}{Chun Chen}.} \bibinfo{year}{2008}\natexlab{}.
\newblock \showarticletitle{Multiple trajectory search for large scale global optimization}. In \bibinfo{booktitle}{\emph{2008 IEEE congress on evolutionary computation (IEEE world congress on computational intelligence)}}. \bibinfo{publisher}{IEEE}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{3052--3059}.
\newblock


\bibitem[Vermetten et~al\mbox{.}(2023)]%
{VerCarKon2023:autoDE:gecco}
\bibfield{author}{\bibinfo{person}{Diederick Vermetten}, \bibinfo{person}{Fabio Caraffini}, \bibinfo{person}{Anna~V Kononova}, {and} \bibinfo{person}{Thomas B{\"a}ck}.} \bibinfo{year}{2023}\natexlab{}.
\newblock \showarticletitle{Modular differential evolution}. In \bibinfo{booktitle}{\emph{Proceedings of the Genetic and Evolutionary Computation Conference}}. \bibinfo{publisher}{ACM Press}, \bibinfo{address}{New York, NY}, \bibinfo{pages}{864--872}.
\newblock


\bibitem[Xu et~al\mbox{.}(2019)]%
{XuLuoLin19:ieee-cec}
\bibfield{author}{\bibinfo{person}{Peilan Xu}, \bibinfo{person}{Wenjian Luo}, \bibinfo{person}{Xin Lin}, \bibinfo{person}{Yingying Qiao}, {and} \bibinfo{person}{Tao Zhu}.} \bibinfo{year}{2019}\natexlab{}.
\newblock \showarticletitle{Hybrid of PSO and CMA-ES for global optimization}. In \bibinfo{booktitle}{\emph{2019 IEEE congress on evolutionary computation (CEC)}}. \bibinfo{publisher}{IEEE}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{27--33}.
\newblock


\bibitem[Zambrano-Bigiarin et~al\mbox{.}(2013)]%
{ZamCleRoj2013:cec2013}
\bibfield{author}{\bibinfo{person}{Mauricio Zambrano-Bigiarin}, \bibinfo{person}{Maurice Clerc}, {and} \bibinfo{person}{Rodrigo Rojas}.} \bibinfo{year}{2013}\natexlab{}.
\newblock \showarticletitle{Standard particle swarm optimisation 2011 at cec-2013: A baseline for future pso improvements}. In \bibinfo{booktitle}{\emph{Proceedings of the 2013 Congress on Evolutionary Computation (CEC 2013)}}. \bibinfo{publisher}{IEEE Press}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{2337--2344}.
\newblock


\bibitem[Zhang and Xie(2003)]%
{ZhaXie03:ieee-smc}
\bibfield{author}{\bibinfo{person}{Wen-Jun Zhang} {and} \bibinfo{person}{Xiao-Feng Xie}.} \bibinfo{year}{2003}\natexlab{}.
\newblock \showarticletitle{DEPSO: hybrid particle swarm with differential evolution operator}. In \bibinfo{booktitle}{\emph{SMC'03 Conference Proceedings. 2003 IEEE International Conference on Systems, Man and Cybernetics. Conference Theme-System Security and Assurance (Cat. No. 03CH37483)}}, Vol.~\bibinfo{volume}{4}. \bibinfo{publisher}{IEEE}, \bibinfo{address}{Piscataway, NJ}, \bibinfo{pages}{3816--3821}.
\newblock


\end{thebibliography}

%%
%% If your work has an appendix, this is the place to put it.
% \appendix

% \section{Research Methods}

% \subsection{Part One}

% \subsection{Part Two}

\end{document}
\endinput
%%
%% End of file `sample-manuscript.tex'.


%%%%%%%%%%%%%% Probably useful text %%%%%%%%%%%%%%%%
% Broadly speaking, a metaheuristic is a set of general-purpose algorithmic concepts that can be used to define heuristic methods applicable to a wide range of different problems~\cite{MetaheuristicsNetwork:website,BluRol2008hybrid,Tal2013hm}.
% To solve an optimization problem using a \mh, algorithm designers have to select, implement and configure the metaheuristic components that allow them to perform an effective \textit{exploration}--\textit{exploitation} of the search space of the considered problem. 
% In this context, exploration refers to the activity of collecting information about the quality of the solutions in different regions of the search space, while exploitation involves directing the search towards the regions with the highest potential.
% Most metaheuristics are \textit{iterative}, i.e., solutions are constructed/perturbed based on starting points or complete initial solutions by an optimization process that consists of a number of steps that repeat for multiple iterations;
% have a \textit{user-defined termination criterion}, for example, reaching a maximum amount of computational time or obtaining a solution of a minimum desired quality; and
% make use of \textit{randomization} in one or more of their components, which provides diversity to the search and can help to escape local optima.


