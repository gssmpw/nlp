\section{Background}
\subsection{Variants of Diffusion Process.}
Different choices of the transition matrix \(\mathbf{Q}_t\) lead to different diffusion processes. Common examples include \textit{Absorbing Diffusion Process} and \textit{Uniform Diffusion Process}.
\begin{itemize}
    \item \textbf{Absorbing Diffusion}: At each time point \(t\), each token transitions to either itself or a special mask token with probability \(\beta_t\). The process converges to a stationary distribution where all tokens are replaced by the mask token.
    \item \textbf{Uniform Diffusion}: At each time point \(t\), each token transitions to itself or any other token with equal probability \(\beta_t / K\), where \(K\) is the number of classes. The stationary distribution is uniform across all classes.
\end{itemize}

Previous work have indicated that the absorbing diffusion process consistently outperforms the uniform diffusion process in practice~\citep{mdlm, udlm, d3pm}, but it also suffers from the clear limitation. It cannot ``re-mask'' a token once it has been unmasked in the traditional Markovian reverse chain, potentially leading to less robust denoising in early timesteps.

% \section{Theory: Inverse Processes and Non-Markovian Dynamics}
% \label{apdx:non_mark_details}
% \subsection{Inverse of Markovian Processes Can Be Non-Markovian}

% A fundamental property of Markov processes is that the next state depends only on the current state:
% \[
% q(x_t \mid x_{t-1}, \ldots, x_0) \;=\; q(x_t \mid x_{t-1}).
% \]
% However, \emph{inverting} such a Markov chain often induces dependencies that break the Markov property. In other words, even if the forward process is Markovian, its reverse can be \emph{non}-Markovian. Below, we review existing works that either explicitly or implicitly implement this idea:

% \subsubsection{Explicitly Discussed Non-Markovian Inverses}

% \textbf{Volterra Flow Matching (CaLMFlow).}  
% \citet{he2024calmflow} explicitly introduce a non-Markovian \emph{reverse} process by leveraging Volterra integral equations, which generalize ordinary differential equations to include memory-like effects. The forward process remains Markovian, but the reverse process incorporates the full temporal trajectory, making it non-Markovian in practice.

% \subsubsection{Implicitly Described Non-Markovian Inverses}

% \textbf{Score-Based Generative Models.}  
% \citet{song2021score} propose using score functions (gradients of the log-probability) to reverse a Markovian forward SDE. Although the forward pass is Markovian, the reverse pass relies on global knowledge of the data distribution via the score, effectively introducing non-Markovian dependencies.

% \textbf{Denoising Diffusion Probabilistic Models (DDPMs).}  
% \citet{ho2020denoising} add Gaussian noise step-by-step (Markovian forward), but the learned neural reverse process uses global distributional information. While not framed as “non-Markovian,” the reverse chain implicitly captures dependencies beyond the immediate state.

% \textbf{Discrete Diffusion Modeling by Ratio Estimation.}  
% \citet{lou2024discretediff} explore discrete diffusion where the forward process is Markovian, yet the reverse process relies on multiple timesteps of context. Non-Markovianity arises in how the denoising is conditioned on \emph{multiple} historical (or future) states, though not explicitly framed as an inverse to a Markov process.

% \subsubsection{Frameworks with Potential for Non-Markovian Inverses}

% \textbf{Flow Matching Models.}  
% \citet{lipman2023flow} and \citet{tong2024improving} describe methods that learn continuous or discrete trajectories for generative modeling. While they often highlight long-range dependencies, they do not explicitly couch these dependencies in terms of “non-Markovian inverses,” even though the resulting backward dynamics can be understood that way.

% \subsection{Relation to Discrete Diffusion Models}

% Discrete diffusion models typically define a \textbf{Markovian forward process} that corrupts data step-by-step. For example:
% \begin{itemize}
%     \item \textbf{Absorbing Diffusion:} Tokens are replaced by a mask, converging to a fixed absorbing state.
%     \item \textbf{Uniform Diffusion:} Tokens are sampled from a uniform distribution over the vocabulary.
% \end{itemize}
% However, once we attempt to \emph{reverse} this corruption, it often becomes beneficial—or even necessary—to exploit more than just the current noisy state $x_t$. In many cases, the learned reverse chain becomes non-Markovian in practice, depending on the entire noisy trajectory (or on an estimated clean $x_0$).

% \subsection{Non-Markovian Dynamics in CaDDi}

% \textbf{CaDDi (Causal Discrete Diffusion Model)} aims to unify these insights by \emph{explicitly} framing the connection between a Markovian forward process and its \emph{non-Markovian inverse}:

% \begin{enumerate}
%     \item \textbf{Forward Process:} We construct a (non-Markovian) forward pass by adding noise directly to $x_0$ at each timestep, rather than forming a strict chain $x_{t-1}\to x_t$. This design preserves more partial information in intermediate states.
%     \item \textbf{Reverse Process:} Unlike Markovian backward passes (which rely solely on $x_t$), CaDDi’s reverse process looks at the entire future trajectory $(x_t, x_{t+1}, \ldots, x_T)$ when inferring $x_{t-1}$. This broader context induces non-Markovian dependencies, which enhance robustness and capture long-range interactions.
% \end{enumerate}

% \noindent
% Such an approach is reminiscent of the rationale behind \citet{he2024calmflow}, who explicitly use integral equations to capture memory, or \citet{song2021score}, where the reverse pass depends on global score information. By highlighting this \emph{inverse process} perspective, we more directly tackle the tension between Markovian corruption and the need for non-local information at reconstruction time.

% \subsection{Implications and Unique Contributions}

% \begin{itemize}
%     \item \textbf{Bridging Markovian Forward \& Non-Markovian Inverse.} Many works have hinted at or implicitly used non-Markovian effects in reverse processes (e.g., \citet{ho2020denoising, lou2024discretediff}), but few explicitly frame it as a rigorous inversion of a simpler Markovian chain.
%     \item \textbf{Robust, Structured Generation.} By conditioning on the entire trajectory at each step, CaDDi naturally captures complex dependencies. This architecture excels in discrete domains (language, proteins) where partial masking or uniform corruption alone omits critical global context.
%     \item \textbf{Compatibility with Large Models.} As the reverse pass is implemented autoregressively (like a causal language model), CaDDi can reuse powerful pretrained Transformers, connecting to methods like \citet{song2021score} and \citet{he2024calmflow} but specifically adapted to discrete tokens.
% \end{itemize}

% Thus, although the notion of “non-Markovian inverses” is not novel in theory, our \emph{explicit} framing of this concept within discrete diffusion—and the constructive way we build a non-Markovian forward trajectory—offers a distinct perspective. This clarifies the relationship between Markovian corruption and global denoising, further highlighting why CaDDi outperforms purely Markovian models in complex sequence-generation tasks.

\section{Experiment Details}
\subsection{Evaluation Metrics}\label{sec:appendix-metrics}
\paragraph{Protein Evaluation Metrics}
The predicted Local Distance Difference Test (pLDDT) score is calculated using the protein-folding model OmegaFold \citep{OmegaFold}. To evaluate the folded structures of the generated sequences, we employ FoldSeek \citep{vanKempen2024} to search against the Protein Data Bank (PDB) \citep{Berman2000-ql} and compute three key metrics: Root Mean Square Deviation (RMSD), TM-score, and Homologous Probability (H-prob). RMSD measures the average atom-level deviation between structures, making it sensitive to local structural differences. In contrast, TM-score assesses global structural similarity between the generated proteins and their reference counterparts. H-prob quantifies the likelihood that the generated proteins are homologous to the reference proteins.

Following the methodology of EvoDiff \citep{Alamdari2023.09.11.556673}, we fold the generated sequences using OmegaFold and subsequently unfold them using the protein inverse-folding model ESM-IF \citep{hsu2022learning}. The self-consistency perplexity is then computed by comparing the original generated sequence with the sequence obtained after the folding-and-unfolding process.

\paragraph{Text Evaluation Metrics}
Generative perplexity is a widely used metric for evaluating the quality of text generated by a model. It is computed using a \textbf{separate}, pretrained causal language model, which calculates the perplexity of a given sentence. Intuitively, a lower generative perplexity indicates that the pretrained causal language model is more confident in predicting the next token based on the preceding context. This suggests that the generated sentence is more coherent, as the causal language model, trained on a large corpus, can reliably predict tokens given the context.

However, as noted in \cite{holtzman2020curiouscaseneuraltext}, language models may exhibit degenerate behavior, such as repetitive text generation, while still achieving low generative perplexity. To address this issue, we employ \textbf{guided generative perplexity}, where a natural language prompt is appended to the sequences being evaluated. This prompt guides the causal language model to assess the coherence of the generated sequence more effectively, mitigating the impact of degenerate behavior.

In particular, we used \texttt{Does the following sentence make sense: } as the prompt.

The self-BLEU score, introduced in \citep{zhu2018texygenbenchmarkingplatformtext}, is a metric for evaluating the diversity of a set of generated texts. It computes the BLEU score of each generated sequence against the remaining sequences and averages the results. A lower self-BLEU score indicates the generated texts are less similar to each other and hence greater diversity among the generated texts.

\subsection{Amazon Dataset Experiment}\label{sec:amazon_process}
The original Amazon Polarity dataset contains labels 0 or 1 , indicating whether a review is negative or positive, respectively. To enable conditional generation, we prepend the phrase \texttt{this is a positive review} or \texttt{this is a negative review} to positive and negative samples, respectively. This allows a standard causal language model, such as GPT-2, to condition its generation on the sentiment prompt. For evaluation, we use a fine-tuned DistilBERT classifier to measure sentiment accuracy. 


\subsection{Learnable Parameter Count}
\input{paragraphs/tables/parameter_count}

\input{paragraphs/ablation}