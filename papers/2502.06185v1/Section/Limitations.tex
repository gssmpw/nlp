\section*{Limitations}
Our work contributes to the understanding of factual inconsistency errors in machine-generated summaries from the lens of discourse analysis. 
Here, we discuss several limitations.

\paragraph{Benefits of Discourse-driven Information}
Our current approach leaves discourse-relation information (i.e., the relation types such as Explanation, Elaboration, etc.) \textit{unused} on the system level; it would be interesting to utilize it to detect and resolve inconsistency errors. We also acknowledge the choices of our current re-weighting algorithm (exponential) can be further studied with more motivation. We selected the current configuration that performed best on the validation splits of \textsc{DiverSumm}, aligning well with linguistic analysis principles. We plan to extend the modeling into a more complex version, such as applying a graph neural network to the tree structure and including discourse relations for future work.

While large models like GPT-4 and future architectures may improve long-context understanding, recent research shows that LLMs still face challenges with hallucination detection and effectively utilizing extended contexts \cite{liu-etal-2024-lost,zhu2024haluevalwildevaluatinghallucinationslanguage, luo2024halludiallargescalebenchmarkautomatic}. Our contribution, which links linguistic cues to hallucination detection, remains crucial, especially for summarization tasks. We acknowledge that future LLMs with expanded context windows may no longer require input pre-processing. However, we argue that discourse-based segmentation will \textit{still offer critical benefits} (explicitly or implicitly by injecting the discourse analysis into the LLM through prompting or further finetuning). It will enhance the precision of factuality detection and evaluation by leveraging linguistic structures. Additionally, discourse information can provide interpretability to the model, which allows us to trace its evaluations to identifiable linguistic relations and features, which are still lacking in LLMs. In fact, our experimental results with BeSpoke-MC-7B, the SOTA fact-checking model, support the assumption that LLM alone still struggles with the factuality evaluation of long summaries.


\paragraph{Computation Cost}
Our approach's only additional computation cost is running the discourse parser on the source document and the target summary. The DMRST parser \cite{liu-etal-2021-dmrst} can be run on both CPU and GPU, and the inference speed is fast (the full test set of \textsc{DiverSumm} can be processed in a few minutes). Once the discourse features are computed, the time spent by segmentation and reweighting algorithms remains static, introducing minimal overhead compared to the baselines. 

\paragraph{Discourse-driven Analysis on Factual Errors} In our analysis section, discourse analyses were carried out using the annotated portion of the released dataset, which is limited by the annotation quality and the dataset sizes. Yet, this is by far the only dataset that provides the sentence-level annotations on long document summarizations (i.e., \citet{krishna-etal-2023-longeval} released the fine-grained scores, but did not clarify how the spans annotations are collected in their document). We verify the effectiveness of portions of our linguistic-inspired method on other benchmarks, including \textsc{LongSciVerify} and \textsc{LongEval}. Future work would be to analyze and examine the discourse patterns in other domains, such as story summarization or further book-length summarization tasks \cite{chang2024booookscore, kim2024fables}. 

\paragraph{Generalize across Text Domains}
We tried to cover most of the recent publicly available factuality evaluation datasets for long document summarization, including \textsc{DiverSumm}, \textsc{LongSciVerify}, and \textsc{LongEval}. While most existing datasets consist of annotations collected from scientific article summaries, we introduce a novel annotated dataset, \textsc{LegalSumm}, in the legal domain to evaluate the robustness of our proposed approaches. This dataset is curated with careful annotation procedures to ensure quality (see Appendix \ref{appendix:legalsumm_detail}). Our experimental results, as shown in the last column of Table  \ref{tab:aggrefact_diversum_res}, demonstrate that our proposed approaches not only enhance the performances of baseline models but also surpass those strong LLM-based models by a large margin. 

\paragraph{Dependence on Discourse Parser Performance} Our experiments' validity and subsequent findings rely on the parsed discourse trees generated by a Rhetorical Structure Theory (RST) parser \cite{liu-etal-2021-dmrst}, following prior work \cite{adams-etal-2023-generating,pu-etal-2023-incorporating, kim2024threads}. It is important to note that parsed results may be sub-optimal given the challenges of complex hierarchical structures of long documents and the differences between the model's training corpora and our tested domains. We acknowledge that RST parsers are gradually evolving and posit that better RST parsing results can further boost the model's performance. However, major obstacles to their broader adoption are the lack of publicly available models and user-friendly user guidance. Researchers recently incorporated LLMs in discourse parsing and obtained better benchmarking performance in RST \cite{maekawa-etal-2024-obtain}. Unfortunately, no available inference code exists to parse documents beyond pre-compiled benchmark datasets. We look forward to utilizing more robust parsers in future work.

On long source documents, we notice that the parser failed on the MNW split of the DiverSumm, given their input is a concatenation of multiple individual news articles. We opt for first splitting the original document into articles and then successfully parsing them individually. Regarding paragraph-level discourse parsing, we are concerned that it may disrupt the discourse continuity at the document level (i.e., where the beginning of one paragraph is connected to the previous paragraph). Therefore, we leave this exploration for future studies. However, this approach might be viable and beneficial for summarizing extremely long documents, such as books, where the explicit division into chapters and sections could enhance the process.

\paragraph{Applications of Document Structures to Other Tasks}

Document structures can and have been utilized in different tasks, including coherence analysis \cite{liu-etal-2024-unlocking}, machine translation evaluation \cite{joty-etal-2017-discourse}, sentiment analysis \cite{KRAUS201965}, machine-generated text detection \cite{kim2024threads}, etc. While applying document structure and discourse analysis to hallucination detection is still an emerging area of research, we are keen to explore it further. We are also interested in extending this approach to other input sources, such as dialogue, by investigating the corresponding discourse structures unique to conversational data.

\section*{Ethical Statement}
Throughout the paper, we have referenced datasets and models used in our analyses and experiments, ensuring that they are openly available and do not pose concerns with the public release or usage of this paper. We acknowledge the use of Grammarly and ChatGPT-4o for correcting sentences that are less fluent but not for generating or drafting new content.