@article{schotter2025beginner,
  title={A beginner’s guide to eye tracking for psycholinguistic studies of reading},
  author={Schotter, Elizabeth R and Dillon, Brian},
  journal={Behavior Research Methods},
  volume={57},
  number={2},
  pages={68},
  year={2025},
  publisher={Springer}
}

@misc{Honnibal2020,
author = {Honnibal, Matthew and Montani, Ines and Van Landeghem, Sofie and Boyd, Adriane},
doi = {10.5281/zenodo.1212303},
title = {{spaCy: Industrial-strength Natural Language Processing in Python}},
year = {2020}
}

@inproceedings{chen2016xgboost,
  title={Xgboost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining},
  pages={785--794},
  year={2016}
}

@article{berzak2023traces,
  title={Eye movement traces of linguistic knowledge in native and non-native reading},
  author={Berzak, Yevgeni and Levy, Roger},
  journal={Open Mind},
  volume={7},
  pages={179--196},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{onestop2025preprint,
  title = {OneStop: A 360-Participant English Eye-Tracking Dataset with Different Reading Regimes},
  author = {Berzak, Yevgeni and Malmaud, Jonathan and Shubi, Omer and Meiri, Yoav and Lion, Ella and Levy, Roger},
  journal = {arXiv preprint},
  year = {2025}
}

@article{pedregosa_scikit-learn_2011,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	volume = {12},
	issn = {1533-7928},
	shorttitle = {Scikit-learn},
	url = {http://jmlr.org/papers/v12/pedregosa11a.html},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	number = {85},
	urldate = {2024-01-26},
	journal = {Journal of Machine Learning Research},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	year = {2011},
	pages = {2825--2830},
}

@inproceedings{loshchilov_decoupled_2018,
	title = {Decoupled {Weight} {Decay} {Regularization}},
	url = {https://openreview.net/forum?id=Bkg6RiCqY7},
	abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it ``weight decay'' in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at {\textbackslash}url\{https://github.com/loshchil/AdamW-and-SGDW\}},
	language = {en},
	urldate = {2024-01-23},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Loshchilov, Ilya and Hutter, Frank},
	month = sep,
	year = {2018},
}
@book{davison1997bootstrap,
  title={Bootstrap methods and their application},
  author={Davison, Anthony Christopher and Hinkley, David Victor},
  number={1},
  year={1997},
  publisher={Cambridge university press}
}

@article{barr_random_2013,
	title = {Random effects structure for confirmatory hypothesis testing: {Keep} it maximal},
	volume = {68},
	issn = {0749-596X},
	shorttitle = {Random effects structure for confirmatory hypothesis testing},
	url = {https://www.sciencedirect.com/science/article/pii/S0749596X12001180},
	doi = {10.1016/j.jml.2012.11.001},
	abstract = {Linear mixed-effects models (LMEMs) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using LMEMs for confirmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that LMEMs generalize best when they include the maximal random effects structure justified by the design. The generalization performance of LMEMs including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only LMEMs used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal LMEMs should be the ‘gold standard’ for confirmatory hypothesis testing in psycholinguistics and beyond.},
	language = {en},
	number = {3},
	urldate = {2022-06-22},
	journal = {Journal of Memory and Language},
	author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
	month = apr,
	year = {2013},
	keywords = {Generalization, Linear mixed-effects models, Monte Carlo simulation, Statistics},
	pages = {255--278},
}
@ARTICLE{Bates2015-ts,
  title     = "Fitting linear mixed-effects models Usinglme4",
  author    = "Bates, Douglas and M{\"a}chler, Martin and Bolker, Ben and
               Walker, Steve",
  journal   = "J. Stat. Softw.",
  publisher = "Foundation for Open Access Statistic",
  volume    =  67,
  number    =  1,
  year      =  2015,
  url       = "http://dx.doi.org/10.18637/jss.v067.i01",
  language  = "en",
  issn      = "1548-7660",
  doi       = "10.18637/jss.v067.i01"
}

@misc{alday_2025_14838413,
  author       = {Alday, Phillip M. and
                  Bates, Douglas},
  title        = {MixedModels.jl},
  month        = feb,
  year         = 2025,
  publisher    = {Zenodo},
  version      = {v4.30.1},
  doi          = {10.5281/zenodo.14838413},
  url          = {https://doi.org/10.5281/zenodo.14838413},
  swhid        = {swh:1:dir:652361c3835f8a816774086c6e55c9caf529a37e
                   ;origin=https://doi.org/10.5281/zenodo.596435;visi
                   t=swh:1:snp:1413bf7ebe21a3108195e28170bf5c9ce1c00e
                   f9;anchor=swh:1:rel:edcb39d7503213b2e49274c2aff6d4
                   5b9e0196fa;path=JuliaStats-MixedModels.jl-3bb7f4b
                  },
}

@misc{mosbach_stability_2021,
	title = {On the {Stability} of {Fine}-tuning {BERT}: {Misconceptions}, {Explanations}, and {Strong} {Baselines}},
	shorttitle = {On the {Stability} of {Fine}-tuning {BERT}},
	url = {http://arxiv.org/abs/2006.04884},
	abstract = {Fine-tuning pre-trained transformer-based language models such as BERT has become a common practice dominating leaderboards across various NLP benchmarks. Despite the strong empirical performance of fine-tuned models, fine-tuning is an unstable process: training the same model with multiple random seeds can result in a large variance of the task performance. Previous literature (Devlin et al., 2019; Lee et al., 2020; Dodge et al., 2020) identified two potential reasons for the observed instability: catastrophic forgetting and small size of the fine-tuning datasets. In this paper, we show that both hypotheses fail to explain the fine-tuning instability. We analyze BERT, RoBERTa, and ALBERT, fine-tuned on commonly used datasets from the GLUE benchmark, and show that the observed instability is caused by optimization difficulties that lead to vanishing gradients. Additionally, we show that the remaining variance of the downstream task performance can be attributed to differences in generalization where fine-tuned models with the same training loss exhibit noticeably different test performance. Based on our analysis, we present a simple but strong baseline that makes fine-tuning BERT-based models significantly more stable than the previously proposed approaches. Code to reproduce our results is available online: https://github.com/uds-lsv/bert-stable-fine-tuning.},
	urldate = {2024-02-09},
	publisher = {arXiv},
	author = {Mosbach, Marius and Andriushchenko, Maksym and Klakow, Dietrich},
	month = mar,
	year = {2021},
	note = {arXiv:2006.04884 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{schilling1998comparing,
  title={Comparing naming, lexical decision, and eye fixation times: Word frequency effects and individual differences},
  author={Schilling, Hildur EH and Rayner, Keith and Chumbley, James I},
  journal={Memory \& cognition},
  volume={26},
  number={6},
  pages={1270--1281},
  year={1998},
  publisher={Springer}
}

@article{veldre2023understanding,
  title={Understanding the visual constraints on lexical processing: New empirical and simulation results.},
  author={Veldre, Aaron and Reichle, Erik D and Yu, Lili and Andrews, Sally},
  journal={Journal of Experimental Psychology: General},
  volume={152},
  number={3},
  pages={693},
  year={2023},
  publisher={American Psychological Association}
}

@article{deng2023eyettention,
  title={Eyettention: An attention-based dual-sequence model for predicting human scanpaths during reading},
  author={Deng, Shuwen and Reich, David R and Prasse, Paul and Haller, Patrick and Scheffer, Tobias and J{\"a}ger, Lena A},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={7},
  number={ETRA},
  pages={1--24},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@article{meziere2024scanpath,
  title={Scanpath regularity as an index of Reading comprehension},
  author={M{\'e}zi{\`e}re, Diane C and Yu, Lili and McArthur, Genevieve and Reichle, Erik D and von der Malsburg, Titus},
  journal={Scientific Studies of Reading},
  volume={28},
  number={1},
  pages={79--100},
  year={2024},
  publisher={Taylor \& Francis}
}

@article{von2011scanpath,
  title={What is the scanpath signature of syntactic reanalysis?},
  author={Von der Malsburg, Titus and Vasishth, Shravan},
  journal={Journal of Memory and Language},
  volume={65},
  number={2},
  pages={109--127},
  year={2011},
  publisher={Elsevier}
}

@Misc{TorchMetrics_-_Measuring_2022,
author = {{Nicki Skafte Detlefsen} and {Jiri Borovec} and {Justus Schock} and {Ananya Harsh} and {Teddy Koker} and {Luca Di Liello} and {Daniel Stancl} and {Changsheng Quan} and {Maxim Grechkin} and {William Falcon}},
doi = {10.21105/joss.04101},
license = {Apache-2.0},
month = feb,
title = {{TorchMetrics - Measuring Reproducibility in PyTorch}},
url = {https://github.com/Lightning-AI/torchmetrics},
year = {2022}
}

@inproceedings{paszke2019pytorch,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and d'Alché-Buc, F. and Fox, E. and Garnett, R.},
pages = {8024--8035},
publisher = {Curran Associates, Inc.},
title = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
year = {2019}
}


@article{liu_roberta_2019,
	title = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
	shorttitle = {{RoBERTa}},
	url = {http://arxiv.org/abs/1907.11692},
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	urldate = {2022-04-29},
	journal = {arXiv:1907.11692 [cs]},
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.11692},
	keywords = {Computer Science - Computation and Language},
}

@misc{Falcon_PyTorch_Lightning_2019,
author = {Falcon, William and {The PyTorch Lightning team}},
doi = {10.5281/zenodo.3828935},
license = {Apache-2.0},
month = mar,
title = {{PyTorch Lightning}},
url = {https://github.com/Lightning-AI/lightning},
version = {1.4},
year = {2019}
}


@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{Shubi2024Finegrained,
    title = "Fine-Grained Prediction of Reading Comprehension from Eye Movements",
    author = "Shubi, Omer  and
      Meiri, Yoav  and
      Hadar, Cfir Avraham  and
      Berzak, Yevgeni",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.198",
    doi = "10.18653/v1/2024.emnlp-main.198",
    pages = "3372--3391",
    abstract = "Can human reading comprehension be assessed from eye movements in reading? In this work, we address this longstanding question using large-scale eyetracking data. We focus on a cardinal and largely unaddressed variant of this question: predicting reading comprehension of a single participant for a single question from their eye movements over a single paragraph. We tackle this task using a battery of recent models from the literature, and three new multimodal language models. We evaluate the models in two different reading regimes: ordinary reading and information seeking, and examine their generalization to new textual items, new participants, and the combination of both. The evaluations suggest that the task is highly challenging, and highlight the importance of benchmarking against a strong text-only baseline. While in some cases eye movements provide improvements over such a baseline, they tend to be small. This could be due to limitations of current modelling approaches, limitations of the data, or because eye movement behavior does not sufficiently pertain to fine-grained aspects of reading comprehension processes. Our study provides an infrastructure for making further progress on this question.",
}


@inproceedings{reich2022inferring,
  title={Inferring native and non-native human reading comprehension and subjective text difficulty from scanpaths in reading},
  author={Reich, David Robert and Prasse, Paul and Tschirner, Chiara and Haller, Patrick and Goldhammer, Frank and J{\"a}ger, Lena A},
  booktitle={2022 Symposium on Eye Tracking Research and Applications},
  pages={1--8},
  year={2022}
}

@article{reichle1998toward,
  title={Toward a model of eye movement control in reading.},
  author={Reichle, Erik D and Pollatsek, Alexander and Fisher, Donald L and Rayner, Keith},
  journal={Psychological review},
  volume={105},
  number={1},
  pages={125},
  year={1998},
  publisher={American Psychological Association}
}
@inproceedings{zhu2015exploratory,
  title={An exploratory study using social network analysis to model eye movements in mathematics problem solving},
  author={Zhu, Mengxiao and Feng, Gary},
  booktitle={Proceedings of the Fifth International Conference on Learning Analytics and Knowledge},
  pages={383--387},
  year={2015}
}
@article{diamond2016cvxpy,
  author  = {Steven Diamond and Stephen Boyd},
  title   = {{CVXPY}: {A} {P}ython-embedded modeling language for convex optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {83},
  pages   = {1--5},
}

@Manual{h2o_Python_module,
    title = {h2o: Python Interface for H2O},
    author = {H2O.ai},
    year = {2022},
    note = {Python package version 3.42.0.2},
    url = {https://github.com/h2oai/h2o-3},
}


@ARTICLE{2020SciPy-NMeth,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}
@inproceedings{seabold2010statsmodels,
  title={statsmodels: Econometric and statistical modeling with python},
  author={Seabold, Skipper and Perktold, Josef},
  booktitle={9th Python in Science Conference},
  year={2010},
}

@article{reichle2003ez,
  title={The EZ Reader model of eye-movement control in reading: Comparisons to other models},
  author={Reichle, Erik D and Rayner, Keith and Pollatsek, Alexander},
  journal={Behavioral and brain sciences},
  volume={26},
  number={4},
  pages={445--476},
  year={2003},
  publisher={Cambridge University Press}
}

@article{reichle2009using,
  title={Using EZ Reader to model the effects of higher level language processing on eye movements during reading},
  author={Reichle, Erik D and Warren, Tessa and McConnell, Kerry},
  journal={Psychonomic bulletin \& review},
  volume={16},
  pages={1--21},
  year={2009},
  publisher={Springer}
}

@article{huettig2022myth,
  title={The Myth of Normal Reading},
  author={Huettig, Falk and Ferreira, Fernanda},
  journal={Perspectives on Psychological Science},
  pages={17456916221127226},
  year={2022},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}


@misc{robyn_speer_2022_7199437,
  author       = {Robyn Speer},
  title        = {rspeer/wordfreq: v3.0},
  month        = sep,
  year         = 2022,
  publisher    = {Zenodo},
  version      = {v3.0.2},
  doi          = {10.5281/zenodo.7199437},
  url          = {https://doi.org/10.5281/zenodo.7199437}
}


@article{heilbron_hierarchy_2022,
	title = {A hierarchy of linguistic predictions during natural language comprehension},
	volume = {119},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.2201968119},
	doi = {10.1073/pnas.2201968119},
	abstract = {Understanding spoken language requires transforming ambiguous acoustic streams into a hierarchy of representations, from phonemes to meaning. It has been suggested that the brain uses prediction to guide the interpretation of incoming input. However, the role of prediction in language processing remains disputed, with disagreement about both the ubiquity and representational nature of predictions. Here, we address both issues by analyzing brain recordings of participants listening to audiobooks, and using a deep neural network (GPT-2) to precisely quantify contextual predictions. First, we establish that brain responses to words are modulated by ubiquitous predictions. Next, we disentangle model-based predictions into distinct dimensions, revealing dissociable neural signatures of predictions about syntactic category (parts of speech), phonemes, and semantics. Finally, we show that high-level (word) predictions inform low-level (phoneme) predictions, supporting hierarchical predictive processing. Together, these results underscore the ubiquity of prediction in language processing, showing that the brain spontaneously predicts upcoming language at multiple levels of abstraction.},
	language = {en},
	number = {32},
	urldate = {2022-10-10},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Heilbron, Micha and Armeni, Kristijan and Schoffelen, Jan-Mathijs and Hagoort, Peter and de Lange, Floris P.},
	month = aug,
	year = {2022},
	pages = {e2201968119},
}







@article{wood2011fast,
  title={Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models},
  author={Wood, Simon N},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={73},
  number={1},
  pages={3--36},
  year={2011},
  publisher={Wiley Online Library}
}

@article{just1980theory,
  title={A theory of reading: from eye fixations to comprehension.},
  author={Just, Marcel A and Carpenter, Patricia A},
  journal={Psychological review},
  volume={87},
  number={4},
  pages={329},
  year={1980},
  publisher={American Psychological Association}
}

@article{wilcox2020predictive,
  title={On the predictive power of neural language models for human real-time comprehension behavior},
  author={Wilcox, Ethan Gotlieb and Gauthier, Jon and Hu, Jennifer and Qian, Peng and Levy, Roger},
  journal={arXiv preprint arXiv:2006.01912},
  year={2020}
}

@article{berzak_levy_2022,
  year = {2022},
  title = {CELER: A 365-Participant Corpus of Eye Movements in L1 and L2 English Reading},
  pages = {1-10},
  month = {apr},
  journal = {Open Mind},
  author = {Berzak, Yevgeni and Nakamura, Chie and Smith, Amelia and Weng, Emily and Katz, Boris and Flynn, Suzanne and Levy, Roger}
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Wolf, Thomas  and
      Debut, Lysandre  and
      Sanh, Victor  and
      Chaumond, Julien  and
      Delangue, Clement  and
      Moi, Anthony  and
      Cistac, Pierric  and
      Rault, Tim  and
      Louf, Remi  and
      Funtowicz, Morgan  and
      Davison, Joe  and
      Shleifer, Sam  and
      von Platen, Patrick  and
      Ma, Clara  and
      Jernite, Yacine  and
      Plu, Julien  and
      Xu, Canwen  and
      Le Scao, Teven  and
      Gugger, Sylvain  and
      Drame, Mariama  and
      Lhoest, Quentin  and
      Rush, Alexander",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-demos.6",
    doi = "10.18653/v1/2020.emnlp-demos.6",
    pages = "38--45",
    abstract = "Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/huggingface/transformers.",
}

@misc{shain2022large,
 title={Large-Scale Evidence for Logarithmic Effects of Word Predictability on Reading Time},
 url={psyarxiv.com/4hyna},
 DOI={10.31234/osf.io/4hyna},
 publisher={PsyArXiv},
 author={Shain, Cory and Meister, Clara and Pimentel, Tiago and Cotterell, Ryan and Levy, Roger P},
 year={2022},
 month={Nov}
}

@inproceedings{lison2016opensubtitles2016,
    title = "{O}pen{S}ubtitles2016: Extracting Large Parallel Corpora from Movie and {TV} Subtitles",
    author = {Lison, Pierre  and
      Tiedemann, J{\"o}rg},
    booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
    month = may,
    year = "2016",
    address = "Portoro{\v{z}}, Slovenia",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L16-1147",
    pages = "923--929",
    abstract = "We present a new major release of the OpenSubtitles collection of parallel corpora. The release is compiled from a large database of movie and TV subtitles and includes a total of 1689 bitexts spanning 2.6 billion sentences across 60 languages. The release also incorporates a number of enhancements in the preprocessing and alignment of the subtitles, such as the automatic correction of OCR errors and the use of meta-data to estimate the quality of each subtitle and score subtitle pairs.",
}

@inproceedings{lin2012syntactic,
  title={Syntactic annotations for the google books ngram corpus},
  author={Lin, Yuri and Michel, Jean-Baptiste and Lieberman, Erez Aiden and Orwant, Jon and Brockman, Will and Petrov, Slav},
  booktitle={Proceedings of the ACL 2012 system demonstrations},
  pages={169--174},
  year={2012}
}


@article{van2014subtlex,
  title={SUBTLEX-UK: A new and improved word frequency database for British English},
  author={Van Heuven, Walter JB and Mandera, Pawel and Keuleers, Emmanuel and Brysbaert, Marc},
  journal={Quarterly journal of experimental psychology},
  volume={67},
  number={6},
  pages={1176--1190},
  year={2014},
  publisher={SAGE Publications Sage UK: London, England}
}


@misc{robyn_speer_2018_1443582,
  author       = {Robyn Speer and
                  Joshua Chin and
                  Andrew Lin and
                  Sara Jewett and
                  Lance Nathan},
  title        = {LuminosoInsight/wordfreq: v2.2},
  month        = oct,
  year         = 2018,
  doi          = {10.5281/zenodo.1443582},
  url          = {https://doi.org/10.5281/zenodo.1443582}
}

@misc{gpt-j,
  author = {Wang, Ben and Komatsuzaki, Aran},
  title = {{GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}},
  howpublished = {\url{https://github.com/kingoflolz/mesh-transformer-jax}},
  year = 2021,
  month = May
}


@misc{bates_juliastatsmixedmodelsjl_2022,
	title = {{JuliaStats}/{MixedModels}.jl: v4.7.0},
	shorttitle = {{JuliaStats}/{MixedModels}.jl},
	url = {https://zenodo.org/record/6925652},
	abstract = {MixedModels v4.7.0 NEWS file. Diff since v4.6.4 NB: Closed issues and pull requests are sorted temporally and so may include backports to other versions or work in the development branch for an upcoming breaking release. Please see the NEWS file for changes sorted by release. Closed issues: Rank deficiency tests fail on nightly with Apple Silicon (\#600) LoadError: PosDefException: matrix is not positive definite; Cholesky factorization failed (\#611) export StatsModels.AbstractContrasts (\#620) Predict: Response column must be initialized to a non-missing numeric value (\#626) Merged pull requests: attempt rescaling of poorly scaled problems (\#615) (@palday) fix dependent column test on Apple silicon (\#622) (@palday) Create docs-cleanup.yml (\#624) (@palday) loosen type restriction on filename for optsum serialization and rename arg (\#628) (@palday)},
	urldate = {2022-10-08},
	publisher = {Zenodo},
	author = {Bates, Douglas and Alday, Phillip and Kleinschmidt, Dave and José Bayoán Santiago Calderón, PhD and Zhan, Likan and Noack, Andreas and Bouchet-Valat, Milan and Arslan, Alex and Kelman, Tony and Baldassari, Antoine and Ehinger, Benedikt and Karrasch, Daniel and Saba, Elliot and Quinn, Jacob and Hatherly, Michael and Piibeleht, Morten and Mogensen, Patrick Kofod and Babayan, Simon and Gagnon, Yakir Luc},
	month = jul,
	year = {2022},
}


@article{dmello_machine-learned_2020,
	title = {Machine-{Learned} {Computational} {Models} {Can} {Enhance} the {Study} of {Text} and {Discourse}: {A} {Case} {Study} {Using} {Eye} {Tracking} to {Model} {Reading} {Comprehension}},
	volume = {57},
	issn = {0163-853X, 1532-6950},
	shorttitle = {Machine-{Learned} {Computational} {Models} {Can} {Enhance} the {Study} of {Text} and {Discourse}},
	url = {https://www.tandfonline.com/doi/full/10.1080/0163853X.2020.1739600},
	doi = {10.1080/0163853X.2020.1739600},
	abstract = {We propose that machine-learned computational models (MLCMs), in which the model parameters and perhaps even structure are learned from data, can complement extant approaches to the study of text and discourse. Such models are particularly useful when theoretical understanding is insufficient, when the data are rife with nonlinearities and interactivity, and when researchers aspire to take advantage of “big data.” Being fully instantiated computer programs, MLCMs can also be used for autonomous assessment and real-time intervention. We illustrate these ideas in the context of an eye movement–based MLCM of textbase comprehension during reading along connected text. Using a dataset where 104 participants read a 6,500-word text, we trained Random Forests models to predict comprehension scores from six eye movement features. The models were highly accurate (area under the receiver operating characteristic curve = .902; r = .661), robust, and generalized across participants, suggesting possible use in future studies. We conclude by arguing for an increased role of MLCMs in the future of discourse research.},
	language = {en},
	number = {5-6},
	urldate = {2022-07-26},
	journal = {Discourse Processes},
	author = {D’Mello, Sidney K. and Southwell, Rosy and Gregg, Julie},
	month = jul,
	year = {2020},
	pages = {420--440},
}


@misc{rust_language_2022,
	title = {Language {Modelling} with {Pixels}},
	url = {http://arxiv.org/abs/2207.06991},
	abstract = {Language models are defined over a finite set of inputs, which creates a vocabulary bottleneck when we attempt to scale the number of supported languages. Tackling this bottleneck results in a trade-off between what can be represented in the embedding matrix and computational issues in the output layer. This paper introduces PIXEL, the Pixel-based Encoder of Language, which suffers from neither of these issues. PIXEL is a pretrained language model that renders text as images, making it possible to transfer representations across languages based on orthographic similarity or the co-activation of pixels. PIXEL is trained to reconstruct the pixels of masked patches, instead of predicting a distribution over tokens. We pretrain the 86M parameter PIXEL model on the same English data as BERT and evaluate on syntactic and semantic tasks in typologically diverse languages, including various non-Latin scripts. We find that PIXEL substantially outperforms BERT on syntactic and semantic processing tasks on scripts that are not found in the pretraining data, but PIXEL is slightly weaker than BERT when working with Latin scripts. Furthermore, we find that PIXEL is more robust to noisy text inputs than BERT, further confirming the benefits of modelling language with pixels.},
	urldate = {2022-07-19},
	collaborator = {Rust, Phillip and Lotz, Jonas F. and Bugliarello, Emanuele and Salesky, Elizabeth and de Lhoneux, Miryam and Elliott, Desmond},
	month = jul,
	year = {2022},
	note = {Number: arXiv:2207.06991
arXiv:2207.06991 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@inproceedings{mishra_learning_2017,
	address = {Vancouver, Canada},
	title = {Learning {Cognitive} {Features} from {Gaze} {Data} for {Sentiment} and {Sarcasm} {Classification} using {Convolutional} {Neural} {Network}},
	url = {http://aclweb.org/anthology/P17-1035},
	doi = {10.18653/v1/P17-1035},
	abstract = {Cognitive NLP systems- i.e., NLP systems that make use of behavioral data - augment traditional text-based features with cognitive features extracted from eye-movement patterns, EEG signals, brain-imaging etc.. Such extraction of features is typically manual. We contend that manual extraction of features may not be the best way to tackle text subtleties that characteristically prevail in complex classiﬁcation tasks like sentiment analysis and sarcasm detection, and that even the extraction and choice of features should be delegated to the learning system. We introduce a framework to automatically extract cognitive features from the eye-movement / gaze data of human readers reading the text and use them as features along with textual features for the tasks of sentiment polarity and sarcasm detection. Our proposed framework is based on Convolutional Neural Network (CNN). The CNN learns features from both gaze and text and uses them to classify the input text. We test our technique on published sentiment and sarcasm labeled datasets, enriched with gaze information, to show that using a combination of automatically learned text and gaze features often yields better classiﬁcation performance over (i) CNN based systems that rely on text input alone and (ii) existing systems that rely on handcrafted gaze and textual features.},
	language = {en},
	urldate = {2022-07-19},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for           {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Mishra, Abhijit and Dey, Kuntal and Bhattacharyya, Pushpak},
	year = {2017},
	pages = {377--387},
}


@article{radford_language_2019,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}


@article{rayner_eye_2011,
	title = {Eye movements and word skipping during reading: {Effects} of word length and predictability},
	volume = {37},
	issn = {1939-1277},
	shorttitle = {Eye movements and word skipping during reading},
	doi = {10.1037/a0020990},
	abstract = {Eye movements were monitored as subjects read sentences containing high- or low-predictable target words. The extent to which target words were predictable from prior context was varied: Half of the target words were predictable, and the other half were unpredictable. In addition, the length of the target word varied: The target words were short (4–6 letters), medium (7–9 letters), or long (10–12 letters). Length and predictability both yielded strong effects on the probability of skipping the target words and on the amount of time readers fixated the target words (when they were not skipped). However, there was no interaction in any of the measures examined for either skipping or fixation time. The results demonstrate that word predictability (due to contextual constraint) and word length have strong and independent influences on word skipping and fixation durations. Furthermore, because the long words extended beyond the word identification span, the data indicate that skipping can occur on the basis of partial information in relation to word identity. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	number = {2},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Rayner, Keith and Slattery, Timothy J. and Drieghe, Denis and Liversedge, Simon P.},
	year = {2011},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Eye Fixation, Eye Movements, Prediction, Reading, Text Structure},
	pages = {514--528},
}

@article{rayner_effect_2004,
	title = {The {Effect} of {Plausibility} on {Eye} {Movements} in {Reading}.},
	volume = {30},
	doi = {10.1037/0278-7393.30.6.1290},
	abstract = {Readers' eye movements were monitored as they read sentences describing events in which an individual performed an action with an implement. The noun phrase arguments of the verbs in the sentences were such that when thematic assignment occurred at the critical target word, the sentence was plausible (likely theme), implausible (unlikely theme), or anomalous (an inappropriate theme). Whereas the target word in the anomalous condition provided evidence of immediate disruption, the effect of the target word in the implausible condition was considerably delayed. The results thus indicate that when a word is anomalous, it has an immediate effect on eye movements, but that the effect of implausibility is not as immediate.},
	journal = {Journal of experimental psychology. Learning, memory, and cognition},
	author = {Rayner, Keith and Warren, Tessa and Juhasz, Barbara and Liversedge, Simon},
	month = dec,
	year = {2004},
	pages = {1290--301},
}

@article{kliegl_length_2004,
	title = {Length, frequency, and predictability effects of words on eye movements in reading},
	volume = {16},
	issn = {0954-1446},
	url = {https://doi.org/10.1080/09541440340000213},
	doi = {10.1080/09541440340000213},
	abstract = {We tested the effects of word length, frequency, and predictability on inspection durations (first fixation, single fixation, gaze duration, and reading time) and inspection probabilities during first‐pass reading (skipped, once, twice) for a corpus of 144 German sentences (1138 words) and a subset of 144 target words uncorrelated in length and frequency, read by 33 young and 32 older adults. For corpus words, length and frequency were reliably related to inspection durations and probabilities, predictability only to inspection probabilities. For first‐pass reading of target words all three effects were reliable for inspection durations and probabilities. Low predictability was strongly related to second‐pass reading. Older adults read slower than young adults and had a higher frequency of regressive movements. The data are to serve as a benchmark for computational models of eye movement control in reading.},
	number = {1-2},
	urldate = {2022-06-22},
	journal = {European Journal of Cognitive Psychology},
	author = {Kliegl, Reinhold and Grabner, Ellen and Rolfs, Martin and Engbert, Ralf},
	month = jan,
	year = {2004},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/09541440340000213},
	pages = {262--284},
}

@article{barr_random_2013,
	title = {Random effects structure for confirmatory hypothesis testing: {Keep} it maximal},
	volume = {68},
	issn = {0749-596X},
	shorttitle = {Random effects structure for confirmatory hypothesis testing},
	url = {https://www.sciencedirect.com/science/article/pii/S0749596X12001180},
	doi = {10.1016/j.jml.2012.11.001},
	abstract = {Linear mixed-effects models (LMEMs) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using LMEMs for confirmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that LMEMs generalize best when they include the maximal random effects structure justified by the design. The generalization performance of LMEMs including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only LMEMs used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal LMEMs should be the ‘gold standard’ for confirmatory hypothesis testing in psycholinguistics and beyond.},
	language = {en},
	number = {3},
	urldate = {2022-06-22},
	journal = {Journal of Memory and Language},
	author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
	month = apr,
	year = {2013},
	keywords = {Generalization, Linear mixed-effects models, Monte Carlo simulation, Statistics},
	pages = {255--278},
}

@inproceedings{reich_inferring_2022,
	address = {Seattle WA USA},
	title = {Inferring {Native} and {Non}-{Native} {Human} {Reading} {Comprehension} and {Subjective} {Text} {Difficulty} from {Scanpaths} in {Reading}},
	isbn = {978-1-4503-9252-5},
	url = {https://dl.acm.org/doi/10.1145/3517031.3529639},
	doi = {10.1145/3517031.3529639},
	abstract = {Eye movements in reading are known to reflect cognitive processes involved in reading comprehension at all linguistic levels, from the sub-lexical to the discourse level. This means that reading comprehension and other properties of the text and/or the reader should be possible to infer from eye movements. Consequently, we develop the first neural sequence architecture for this type of tasks which models scan paths in reading and incorporates lexical, semantic and other linguistic features of the stimulus text. Our proposed model outperforms state-of-the-art models in various tasks. These include inferring reading comprehension or text difficulty, and assessing whether the reader is a native speaker of the text’s language. We further conduct an ablation study to investigate the impact of each component of our proposed neural network on its performance.},
	language = {en},
	urldate = {2022-06-14},
	booktitle = {2022 {Symposium} on {Eye} {Tracking} {Research} and {Applications}},
	publisher = {ACM},
	author = {Reich, David Robert and Prasse, Paul and Tschirner, Chiara and Haller, Patrick and Goldhammer, Frank and Jäger, Lena A.},
	month = jun,
	year = {2022},
	pages = {1--8},
}

@inproceedings{ahn_towards_2020,
	address = {New York, NY, USA},
	series = {{ETRA} '20 {Short} {Papers}},
	title = {Towards {Predicting} {Reading} {Comprehension} {From} {Gaze} {Behavior}},
	isbn = {978-1-4503-7134-6},
	url = {https://doi.org/10.1145/3379156.3391335},
	doi = {10.1145/3379156.3391335},
	abstract = {As readers of a language, we all agree to move our eyes in roughly the same way. Yet might there be hidden within this self-similar behavior subtle clues as to how a reader is understanding the material being read? Here we attempt to decode a reader’s eye movements to predict their level of text comprehension and related states. Eye movements were recorded from 95 people reading 4 published SAT passages, each followed by corresponding SAT questions and self-evaluation questionnaires. A sequence of 21 fixation-location (x,y), fixation-duration, and pupil-size features were extracted from the reading behavior and input to two deep networks (CNN/RNN), which were used to predict the reader’s comprehension level and other comprehension-related variables. The best overall comprehension prediction accuracy was 65\% (cf. null accuracy = 54\%) obtained by CNN. This prediction generalized well to fixations on new passages (64\%) from the same readers, but did not generalize to fixations from new readers (41\%), implying substantial individual differences in reading behavior. Our work is the first attempt to predict comprehension from fixations using deep networks, where we hope that our large reading dataset and our protocol for evaluation will benefit the development of new methods for predicting reading comprehension by decoding gaze behavior.},
	urldate = {2022-06-14},
	booktitle = {{ACM} {Symposium} on {Eye} {Tracking} {Research} and {Applications}},
	publisher = {Association for Computing Machinery},
	author = {Ahn, Seoyoung and Kelton, Conor and Balasubramanian, Aruna and Zelinsky, Greg},
	month = jun,
	year = {2020},
	keywords = {Eye tracking, Machine learning, Reading dataset, Text comprehension prediction},
	pages = {1--5},
}

@misc{noauthor_inferring_2022,
	title = {Inferring {Native} and {Non}-{Native} {Human} {Reading} {Comprehension} and {Subjective} {Text} {Difficulty} from {Scanpaths} in {Reading} {\textbar} 2022 {Symposium} on {Eye} {Tracking} {Research} and {Applications}},
	url = {https://dl.acm.org/doi/abs/10.1145/3517031.3529639},
	urldate = {2022-06-14},
	year = {2022},
}


@article{strukelj_one_2018,
	title = {One page of text: {Eye} movements during regular and thorough reading, skimming, and spell checking},
	volume = {11},
	issn = {1995-8692},
	shorttitle = {One page of text},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7198234/},
	doi = {10.16910/jemr.11.1.1},
	abstract = {Eye movements during regular reading, thorough reading, skimming, and spell checking of single pages of text were measured, to investigate how high-level reading tasks elicited by instructions affect reading behavior. Word frequency and word length effects were found. All results were compared to regular reading. Thorough reading involved longer total reading times and more rereading, and resulted in higher comprehension scores. Skimming involved longer saccades, shorter average fixation durations, more word skipping, shorter total reading times evenly distributed across the page, and resulted in lower comprehension scores. Spell checking involved shorter saccades, longer average fixation durations, less word skipping, longer total reading times evenly distributed across the entire page, and resulted in lower comprehension scores. Replicating local effects shows that paragraphs maintain sufficient experimental rigor, while also enabling reading analyses from a global perspective. Compared to regular reading, thorough reading was more elaborate and less uniform, skimming was faster and more uniform, and spell checking was slower and more uniform.},
	number = {1},
	urldate = {2022-05-12},
	journal = {Journal of Eye Movement Research},
	author = {Strukelj, Alexander and Niehorster, Diederick C.},
	year = {2018},
	pmid = {33828678},
	pmcid = {PMC7198234},
	pages = {10.16910/jemr.11.1.1},
}

@article{engbert_dynamical_2002,
	title = {A dynamical model of saccade generation in reading based on spatially distributed lexical processing},
	volume = {42},
	issn = {00426989},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0042698901003017},
	doi = {10.1016/S0042-6989(01)00301-7},
	language = {en},
	number = {5},
	urldate = {2022-05-25},
	journal = {Vision Research},
	author = {Engbert, Ralf and Longtin, André and Kliegl, Reinhold},
	month = mar,
	year = {2002},
	pages = {621--636},
}

@article{rayner_35th_2009,
	title = {The 35th {Sir} {Frederick} {Bartlett} lecture: {Eye} movements and attention in reading, scene perception, and visual search},
	shorttitle = {The 35th {Sir} {Frederick} {Bartlett} lecture},
	abstract = {Eye movements are now widely used to investigate cognitive processes during reading, scene percep-tion, and visual search. In this article, research on the following topics is reviewed with respect to reading: (a) the perceptual span (or span of effective vision), (b) preview benefit, (c) eye movement control, and (d) models of eye movements. Related issues with respect to eye movements during scene perception and visual search are also reviewed. It is argued that research on eye movements during reading has been somewhat advanced over research on eye movements in scene perception and visual search and that some of the paradigms developed to study reading should be more widely adopted in the study of scene perception and visual search. Research dealing with "real-world" tasks and research utilizing the visual-world paradigm are also briefly discussed.},
	author = {Rayner, Keith and Ashby, Jane and Clifton, Chuck and Drieghe, Denis and Greene, Harold and Henderson, John and Juhasz, Barbara and Liversedge, Simon and Pollatsek, Alexander and Staub, Adrian},
	year = {2009},
}

@article{vasishth_what_2013,
	title = {What eye movements can tell us about sentence comprehension: {Eye} movements and sentence comprehension},
	volume = {4},
	issn = {19395078},
	shorttitle = {What eye movements can tell us about sentence comprehension},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/wcs.1209},
	doi = {10.1002/wcs.1209},
	language = {en},
	number = {2},
	urldate = {2022-05-12},
	journal = {Wiley Interdisciplinary Reviews: Cognitive Science},
	author = {Vasishth, Shravan and von der Malsburg, Titus and Engelmann, Felix},
	month = mar,
	year = {2013},
	pages = {125--134},
}

@article{hollenstein_reading_2021,
	title = {Reading {Task} {Classification} {Using} {EEG} and {Eye}-{Tracking} {Data}},
	url = {http://arxiv.org/abs/2112.06310},
	abstract = {The Zurich Cognitive Language Processing Corpus (ZuCo) provides eye-tracking and EEG signals from two reading paradigms, normal reading and task-specific reading. We analyze whether machine learning methods are able to classify these two tasks using eye-tracking and EEG features. We implement models with aggregated sentence-level features as well as fine-grained word-level features. We test the models in within-subject and cross-subject evaluation scenarios. All models are tested on the ZuCo 1.0 and ZuCo 2.0 data subsets, which are characterized by differing recording procedures and thus allow for different levels of generalizability. Finally, we provide a series of control experiments to analyze the results in more detail.},
	urldate = {2022-05-12},
	journal = {arXiv:2112.06310 [cs]},
	author = {Hollenstein, Nora and Tröndle, Marius and Plomecka, Martyna and Kiegeland, Samuel and Özyurt, Yilmazcan and Jäger, Lena A. and Langer, Nicolas},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.06310},
	keywords = {Computer Science - Computation and Language},
}

@misc{noauthor_pdf_nodate,
	title = {({PDF}) {Task} {Effects} on {Eye} {Movements} {During} {Reading}},
	url = {https://www.researchgate.net/publication/46379527_Task_Effects_on_Eye_Movements_During_Reading},
	urldate = {2022-05-12},
}

@article{noauthor_time_2020,
	title = {Time to set your contrasts.},
	url = {https://osf.io/jkpxt/},
	abstract = {Hosted on the Open Science Framework},
	language = {en},
	urldate = {2022-05-15},
	month = sep,
	year = {2020},
	note = {Publisher: OSF},
}

@article{kaakinen_task_2010,
	title = {Task {Effects} on {Eye} {Movements} {During} {Reading}},
	volume = {36},
	doi = {10.1037/a0020693},
	abstract = {The present study examined how proofreading and reading-for-comprehension instructions influence eye movements during reading. Thirty-seven participants silently read sentences containing compound words as target words while their eye movements were being recorded. We manipulated word length and frequency to examine how task instructions influence orthographic versus lexical-semantic processing during reading. Task instructions influenced both temporal and spatial aspects of eye movements: The initial landing position in words was shifted leftward, the saccade length was shorter, first fixation and gaze duration were longer, and refixation probability was higher during proofreading than during reading for comprehension. Moreover, in comparison to instructions for reading for comprehension, proofreading instructions increased both orthographic and lexical-semantic processing. This became apparent in a greater word length and word frequency effect in gaze duration during proofreading than during reading for comprehension. The present study suggests that the allocation of attentional resources during reading is significantly modulated by task demands.},
	journal = {Journal of experimental psychology. Learning, memory, and cognition},
	author = {Kaakinen, Johanna and Hyönä, Jukka},
	month = nov,
	year = {2010},
	pages = {1561--6},
}

@inproceedings{copeland_measuring_2013,
	address = {Budapest, Hungary},
	title = {Measuring reading comprehension using eye movements},
	isbn = {978-1-4799-1546-0 978-1-4799-1543-9},
	url = {http://ieeexplore.ieee.org/document/6719207/},
	doi = {10.1109/CogInfoCom.2013.6719207},
	abstract = {We investigate eye movement measures and methods for predicting reading comprehension. This builds on previous work on factors affecting reading comprehension, namely perceived familiarity with the text content. We further investigate answer-seeking behavior and present a method for measuring and comparing this behavior. The number of fixations, number of regressions, and total fixation time are an indicator of reading intensity and the intensity of reading is related to comprehension. We show that a feed-forward backpropagation neural network can be used to predict subjective comprehension scores as well as quiz scores. We propose using the degree of answer-seeking behavior to measure how question difficulty and as an implicit measure of how difficult a participant finds a tutorial and quiz. Such information is beneficial to apply in eLearning to create dynamic learning environments that use eye movement to predict implicit question difficulty as well as individual participant difficulty.},
	language = {en},
	urldate = {2022-05-16},
	booktitle = {2013 {IEEE} 4th {International} {Conference} on {Cognitive} {Infocommunications} ({CogInfoCom})},
	publisher = {IEEE},
	author = {Copeland, Leana and Gedeon, Tom},
	month = dec,
	year = {2013},
	pages = {791--796},
}

@misc{noauthor_recognition_nodate,
	title = {Recognition of understanding level and language skill using measurements of reading behavior {\textbar} {Proceedings} of the 19th international conference on {Intelligent} {User} {Interfaces}},
	url = {https://dl.acm.org/doi/10.1145/2557500.2557546},
	urldate = {2022-05-16},
}

@misc{noauthor_elsevier_nodate,
	title = {Elsevier {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S1877050921016963?token=FD50DCEF2574BA49D20F6D1DB23BABD989ED9E86B5040053E8E241351596F0D582F45736A80F63E238CF113A58447BB6&originRegion=eu-west-1&originCreation=20220517150521},
	language = {en},
	urldate = {2022-05-17},
	doi = {10.1016/j.procs.2021.08.200},
}

@article{martinez-gomez_recognition_2014,
	title = {Recognition of {Understanding} {Level} and {Language} {Skill} using {Measurements} of {Reading} {Behavior}},
	abstract = {The reading act is an intimate and elusive process that is important to understand. Psycholinguists have long studied the effects of task, personal or document characteristics on reading behavior. An essential factor in the success of those studies lies in the capability of analyzing eye-movements. These studies aim to recognize causal effects on patterns of eye-movements, by contriving variations in task, personal or document characteristics. In this work, we follow the opposite direction. We present a formal framework to recognize reader’s level of understanding and language skill given measurements of reading behavior via eye-gaze data. We show signiﬁcant error reductions to recognize these attributes and provide a detailed study of the most discriminative features.},
	language = {en},
	author = {Martínez-Gómez, Pascual and Aizawa, Akiko},
	year = {2014},
	pages = {10},
}

@inproceedings{martinez-gomez_recognition_2014-1,
	address = {Haifa Israel},
	title = {Recognition of understanding level and language skill using measurements of reading behavior},
	isbn = {978-1-4503-2184-6},
	url = {https://dl.acm.org/doi/10.1145/2557500.2557546},
	doi = {10.1145/2557500.2557546},
	abstract = {The reading act is an intimate and elusive process that is important to understand. Psycholinguists have long studied the effects of task, personal or document characteristics on reading behavior. An essential factor in the success of those studies lies in the capability of analyzing eye-movements. These studies aim to recognize causal effects on patterns of eye-movements, by contriving variations in task, personal or document characteristics. In this work, we follow the opposite direction. We present a formal framework to recognize reader’s level of understanding and language skill given measurements of reading behavior via eye-gaze data. We show signiﬁcant error reductions to recognize these attributes and provide a detailed study of the most discriminative features.},
	language = {en},
	urldate = {2022-05-16},
	booktitle = {Proceedings of the 19th international conference on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Martínez-Gómez, Pascual and Aizawa, Akiko},
	month = feb,
	year = {2014},
	pages = {95--104},
}

@article{pearson_assessment_2005,
	title = {The {Assessment} of {Reading} {Comprehension}: {A} {Review} of {Practices}-{Past}, {Present}, and {Future}.},
	shorttitle = {The {Assessment} of {Reading} {Comprehension}},
	abstract = {The purpose of this chapter is to build an argument for a fresh line of inquiry into the assessment of reading comprehension. We intend to accomplish that goal by providing a rich and detailed historical account of reading comprehension, both as a theoretical phenomenon and an operational construct that lives and breathes in classrooms throughout America. We review both basic research, which deals with reading comprehension largely in its theoretical aspect, and applied research, which is much more concerned about how comprehension gets operationalized in classrooms, reading materials, and tests. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
	author = {Pearson, P. and Hamm, Diane},
	month = jan,
	year = {2005},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
	urldate = {2022-04-30},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	year = {2017},
}

@article{berzak_starc_2020,
	title = {{STARC}: {Structured} {Annotations} for {Reading} {Comprehension}},
	url = {https://github.com/},
	abstract = {We present STARC (Structured Annotations for Reading Comprehension), a new annotation framework for assessing reading comprehension with multiple choice questions. Our framework introduces a principled structure for the answer choices and ties them to tex-tual span annotations. The framework is implemented in OneStopQA, a new high-quality dataset for evaluation and analysis of reading comprehension in English. We use this dataset to demonstrate that STARC can be leveraged for a key new application for the development of SAT-like reading comprehension materials: automatic annotation quality probing via span ablation experiments. We further show that it enables in-depth analyses and comparisons between machine and human reading comprehension behavior, including error distributions and guessing ability. Our experiments also reveal that the standard multiple choice dataset in NLP, RACE (Lai et al., 2017), is limited in its ability to measure reading comprehension. 47\% of its questions can be guessed by machines without accessing the passage, and 18\% are unanimously judged by humans as not having a unique correct answer. OneStopQA provides an alternative test set for reading comprehension which alleviates these shortcomings and has a substantially higher human ceiling performance. 1},
	urldate = {2021-10-26},
	journal = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.},
	author = {Berzak, Yevgeni and Malmaud, Jonathan and Levy, Roger},
	year = {2020},
}

@article{ren_cogalign_2021,
	title = {{CogAlign}: {Learning} to {Align} {Textual} {Neural} {Representations} to {Cognitive} {Language} {Processing} {Signals}},
	volume = {Volume 1: Long Papers},
	url = {http://arxiv.org/abs/2106.05544},
	abstract = {Most previous studies integrate cognitive language processing signals (e.g., eye-tracking or EEG data) into neural models of natural language processing (NLP) just by directly concatenating word embeddings with cognitive features, ignoring the gap between the two modalities (i.e., textual vs. cognitive) and noise in cognitive features. In this paper, we propose a CogAlign approach to these issues, which learns to align textual neural representations to cognitive features. In CogAlign, we use a shared encoder equipped with a modality discriminator to alternatively encode textual and cognitive inputs to capture their differences and commonalities. Additionally, a text-aware attention mechanism is proposed to detect task-related information and to avoid using noise in cognitive features. Experimental results on three NLP tasks, namely named entity recognition, sentiment analysis and relation extraction, show that CogAlign achieves significant improvements with multiple cognitive features over state-of-the-art models on public datasets. Moreover, our model is able to transfer cognitive information to other datasets that do not have any cognitive processing signals.},
	urldate = {2021-11-28},
	journal = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing},
	author = {Ren, Yuqi and Xiong, Deyi},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.05544},
}
@article{hahn2023modeling,
  title={Modeling task effects in human reading with neural network-based attention},
  author={Hahn, Michael and Keller, Frank},
  journal={Cognition},
  volume={230},
  pages={105289},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{vajjala_onestopenglish_2018,
	address = {New Orleans, Louisiana},
	title = {{OneStopEnglish} corpus: {A} new corpus for automatic readability assessment and text simplification},
	shorttitle = {{OneStopEnglish} corpus},
	url = {https://aclanthology.org/W18-0535},
	doi = {10.18653/v1/W18-0535},
	abstract = {This paper describes the collection and compilation of the OneStopEnglish corpus of texts written at three reading levels, and demonstrates its usefulness for through two applications - automatic readability assessment and automatic text simplification. The corpus consists of 189 texts, each in three versions (567 in total). The corpus is now freely available under a CC by-SA 4.0 license and we hope that it would foster further research on the topics of readability assessment and text simplification.},
	urldate = {2022-04-24},
	booktitle = {Proceedings of the {Thirteenth} {Workshop} on {Innovative} {Use} of {NLP} for {Building} {Educational} {Applications}},
	publisher = {Association for Computational Linguistics},
	author = {Vajjala, Sowmya and Lučić, Ivana},
	month = jun,
	year = {2018},
	pages = {297--304},
}


@article{khashabi_unifiedqa-v2_2022,
	title = {{UnifiedQA}-v2: {Stronger} {Generalization} via {Broader} {Cross}-{Format} {Training}},
	shorttitle = {{UnifiedQA}-v2},
	url = {http://arxiv.org/abs/2202.12359},
	abstract = {We present UnifiedQA-v2, a QA model built with the same process as UnifiedQA, except that it utilizes more supervision -- roughly 3x the number of datasets used for UnifiedQA. This generally leads to better in-domain and cross-domain results.},
	urldate = {2022-03-31},
	journal = {arXiv:2202.12359 [cs]},
	author = {Khashabi, Daniel and Kordi, Yeganeh and Hajishirzi, Hannaneh},
	month = feb,
	year = {2022},
	note = {arXiv: 2202.12359},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{hollenstein_towards_2020,
	address = {Marseille, France},
	title = {Towards {Best} {Practices} for {Leveraging} {Human} {Language} {Processing} {Signals} for {Natural} {Language} {Processing}},
	isbn = {979-10-95546-52-8},
	url = {https://aclanthology.org/2020.lincr-1.3},
	abstract = {NLP models are imperfect and lack intricate capabilities that humans access automatically when processing speech or reading a text. Human language processing data can be leveraged to increase the performance of models and to pursue explanatory research for a better understanding of the differences between human and machine language processing. We review recent studies leveraging different types of cognitive processing signals, namely eye-tracking, M/EEG and fMRI data recorded during language understanding. We discuss the role of cognitive data for machine learning-based NLP methods and identify fundamental challenges for processing pipelines. Finally, we propose practical strategies for using these types of cognitive signals to enhance NLP models.},
	language = {English},
	urldate = {2022-03-25},
	booktitle = {Proceedings of the {Second} {Workshop} on {Linguistic} and {Neurocognitive} {Resources}},
	publisher = {European Language Resources Association},
	author = {Hollenstein, Nora and Barrett, Maria and Beinborn, Lisa},
	month = may,
	year = {2020},
	pages = {15--27},
}

@article{takmaz_team_nodate,
	title = {Team {DMG} at {CMCL} 2022 {Shared} {Task}: {Transformer} {Adapters} for the {Multi}- and {Cross}-{Lingual} {Prediction} of {Human} {Reading} {Behavior}},
	abstract = {In this paper, we present the details of our approaches that attained the second place in the shared task of the ACL 2022 Cognitive Modeling and Computational Linguistics Workshop. The shared task is focused on multiand cross-lingual prediction of eye movement features in human reading behavior, which could provide valuable information regarding language processing. To this end, we train ‘adapters’ inserted into the layers of frozen transformer-based pretrained language models. We ﬁnd that multilingual models equipped with adapters perform well in predicting eyetracking features. Our results suggest that utilizing language- and task-speciﬁc adapters is beneﬁcial and translating test sets into similar languages that exist in the training set could help with zero-shot transferability in the prediction of human reading behavior.},
	language = {en},
	author = {Takmaz, Ece},
	pages = {9},
}

@article{barrett_sequence_2020,
	title = {Sequence labelling and sequence classification with gaze: {Novel} uses of eye-tracking data for {Natural} {Language} {Processing}},
	volume = {14},
	issn = {1749-818X},
	shorttitle = {Sequence labelling and sequence classification with gaze},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/lnc3.12396},
	doi = {10.1111/lnc3.12396},
	abstract = {Eye-tracking data from reading provide a structured signal with a fine-grained temporal resolution which closely follows the sequential structure of the text. It is highly correlated with the cognitive load associated with different stages of human, cognitive text processing. While eye-tracking data have been extensively studied to understand human cognition, it has only recently been considered for Natural Language Processing (NLP). In this review, we provide a comprehensive overview of how gaze data are being used in data-driven NLP, in particular for sequence labelling and sequence classification tasks. We argue that eye-tracking may effectively counter one of the core challenges of machine-learning-based NLP: the scarcity of annotated data. We outline the recent advances in gaze-augmented NLP to discuss how the gaze signal from human readers can be leveraged while also considering the potentials and limitations of this data source.},
	language = {en},
	number = {11},
	urldate = {2022-03-25},
	journal = {Language and Linguistics Compass},
	author = {Barrett, Maria and Hollenstein, Nora},
	year = {2020},
	note = {\_eprint: https://compass.onlinelibrary.wiley.com/doi/pdf/10.1111/lnc3.12396},
	pages = {e12396},
}

@inproceedings{rohanian_using_2017,
	address = {Varna, Bulgaria},
	title = {Using {Gaze} {Data} to {Predict} {Multiword} {Expressions}},
	url = {https://doi.org/10.26615/978-954-452-049-6_078},
	doi = {10.26615/978-954-452-049-6_078},
	abstract = {In recent years gaze data has been increasingly used to improve and evaluate NLP models due to the fact that it carries information about the cognitive processing of linguistic phenomena. In this paper we conduct a preliminary study towards the automatic identification of multiword expressions based on gaze features from native and non-native speakers of English. We report comparisons between a part-of-speech (POS) and frequency baseline to: i) a prediction model based solely on gaze data and ii) a combined model of gaze data, POS and frequency. In spite of the challenging nature of the task, best performance was achieved by the latter. Furthermore, we explore how the type of gaze data (from native versus non-native speakers) affects the prediction, showing that data from the two groups is discriminative to an equal degree for the task. Finally, we show that late processing measures are more predictive than early ones, which is in line with previous research on idioms and other formulaic structures.},
	urldate = {2022-03-26},
	booktitle = {Proceedings of the {International} {Conference} {Recent} {Advances} in {Natural} {Language} {Processing}, {RANLP} 2017},
	publisher = {INCOMA Ltd.},
	author = {Rohanian, Omid and Taslimipoor, Shiva and Yaneva, Victoria and Ha, Le An},
	month = sep,
	year = {2017},
	keywords = {Red, Relevant},
	pages = {601--609},
}

@techreport{hollenstein_zuco_2022,
	type = {preprint},
	title = {The {ZuCo} {Benchmark} on {Cross}-{Subject} {Reading} {Task} {Classification} with {EEG} and {Eye}-{Tracking} {Data}},
	url = {http://biorxiv.org/lookup/doi/10.1101/2022.03.08.483414},
	abstract = {We present a new machine learning benchmark for reading task classification with the goal of advancing EEG and eye-tracking research at the intersection between computational language processing and cognitive neuroscience. The benchmark task consists of a cross-subject classification to distinguish between two reading paradigms: normal reading and task-specific reading. The data for the benchmark is based on the Zurich Cognitive Language Processing Corpus (ZuCo 2.0), which provides simultaneous eye-tracking and EEG signals from natural reading. The training dataset is publicly available, and we present a newly recorded hidden testset. We provide multiple solid baseline methods for this task and discuss future improvements. We release our code and provide an easy-to-use interface to evaluate new approaches with an accompanying public leaderboard: www.zuco-benchmark.com.},
	language = {en},
	urldate = {2022-04-24},
	institution = {Neuroscience},
	author = {Hollenstein, Nora and Tröndle, Marius and Plomecka, Martyna and Kiegeland, Samuel and Özyurt, Yilmazcan and Jäger, Lena A. and Langer, Nicolas},
	month = mar,
	year = {2022},
	doi = {10.1101/2022.03.08.483414},
}

@article{smith_effect_2013,
	title = {The effect of word predictability on reading time is logarithmic},
	volume = {128},
	issn = {0010-0277},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3709001/},
	doi = {10.1016/j.cognition.2013.02.013},
	abstract = {It is well known that real-time human language processing is highly incremental and context-driven, and that the strength of a comprehender’s expectation for each word encountered is a key determinant of the difficulty of integrating that word into the preceding context. In reading, this differential difficulty is largely manifested in the amount of time taken to read each word. While numerous studies over the past thirty years have shown expectation-based effects on reading times driven by lexical, syntactic, semantic, pragmatic, and other information sources, there has been little progress in establishing the quantitative relationship between expectation (or prediction) and reading times. Here, by combining a state-of-the-art computational language model, two large behavioral data-sets, and non-parametric statistical techniques, we establish for the first time the quantitative form of this relationship, finding that it is logarithmic over six orders of magnitude in estimated predictability. This result is problematic for a number of established models of eye movement control in reading, but lends partial support to an optimal perceptual discrimination account of word recognition. We also present a novel model in which language processing is highly incremental well below the level of the individual word, and show that it predicts both the shape and time-course of this effect. At a more general level, this result provides challenges for both anticipatory processing and semantic integration accounts of lexical predictability effects. And finally, this result provides evidence that comprehenders are highly sensitive to relative differences in predictability – even for differences between highly unpredictable words – and thus helps bring theoretical unity to our understanding of the role of prediction at multiple levels of linguistic structure in real-time language comprehension.},
	number = {3},
	urldate = {2022-04-01},
	journal = {Cognition},
	author = {Smith, Nathaniel J. and Levy, Roger},
	month = sep,
	year = {2013},
	pmid = {23747651},
	pmcid = {PMC3709001},
	keywords = {Expectation, Information theory, Probabilistic models of cognition, Psycholinguistics, Reading},
	pages = {302--319},
}

@article{shen_reasonet_2017,
	title = {{ReasoNet}: {Learning} to {Stop} {Reading} in {Machine} {Comprehension}},
	shorttitle = {{ReasoNet}},
	url = {http://arxiv.org/abs/1609.05284},
	doi = {10.1145/3097983.3098177},
	abstract = {Teaching a computer to read and answer general questions pertaining to a document is a challenging yet unsolved problem. In this paper, we describe a novel neural network architecture called the Reasoning Network (ReasoNet) for machine comprehension tasks. ReasoNets make use of multiple turns to e ectively exploit and then reason over the relation among queries, documents, and answers. Di erent from previous approaches using a xed number of turns during inference, ReasoNets introduce a termination state to relax this constraint on the reasoning depth. With the use of reinforcement learning, ReasoNets can dynamically determine whether to continue the comprehension process after digesting intermediate results, or to terminate reading when it concludes that existing information is adequate to produce an answer. ReasoNets achieve superior performance in machine comprehension datasets, including unstructured CNN and Daily Mail datasets, the Stanford SQuAD dataset, and a structured Graph Reachability dataset.},
	language = {en},
	urldate = {2022-03-30},
	journal = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	author = {Shen, Yelong and Huang, Po-Sen and Gao, Jianfeng and Chen, Weizhu},
	month = aug,
	year = {2017},
	note = {arXiv: 1609.05284},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	pages = {1047--1055},
}

@misc{noauthor_reading_nodate,
	title = {Reading for comprehension: the contribution of decoding, linguistic and cognitive skills {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Reading for comprehension},
	url = {https://reader.elsevier.com/reader/sd/pii/S2211609519300041?token=F0586C16C57B5C43791001C7964A2E3FDC050B8C10A9D0AAE72A21340209A41831C8177CDAA6EAF93FC0AD34FE410E36&originRegion=eu-west-1&originCreation=20220413075459},
	language = {en},
	urldate = {2022-04-13},
	doi = {10.1016/bs.irrdd.2019.06.004},
}

@article{rogers_qa_2021,
	title = {{QA} {Dataset} {Explosion}: {A} {Taxonomy} of {NLP} {Resources} for {Question} {Answering} and {Reading} {Comprehension}},
	shorttitle = {{QA} {Dataset} {Explosion}},
	url = {http://arxiv.org/abs/2107.12708},
	abstract = {Alongside huge volumes of research on deep learning models in NLP in the recent years, there has been also much work on benchmark datasets needed to track modeling progress. Question answering and reading comprehension have been particularly prolific in this regard, with over 80 new datasets appearing in the past two years. This study is the largest survey of the field to date. We provide an overview of the various formats and domains of the current resources, highlighting the current lacunae for future work. We further discuss the current classifications of ``reasoning types" in question answering and propose a new taxonomy. We also discuss the implications of over-focusing on English, and survey the current monolingual resources for other languages and multilingual resources. The study is aimed at both practitioners looking for pointers to the wealth of existing data, and at researchers working on new resources.},
	urldate = {2022-03-31},
	journal = {arXiv:2107.12708 [cs]},
	author = {Rogers, Anna and Gardner, Matt and Augenstein, Isabelle},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.12708},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{berzak_predicting_2017,
	address = {Stroudsburg, PA, USA},
	title = {Predicting {Native} {Language} from {Gaze}},
	url = {http://aclweb.org/anthology/P17-1050},
	doi = {10.18653/v1/P17-1050},
	abstract = {A fundamental question in language learning concerns the role of a speaker's first language in second language acquisition. We present a novel methodology for studying this question: analysis of eye-movement patterns in second language reading of free-form text. Using this methodology, we demonstrate for the first time that the native language of English learners can be predicted from their gaze fixations when reading English. We provide analysis of classifier uncertainty and learned features, which indicates that differences in English reading are likely to be rooted in linguistic divergences across native languages. The presented framework complements production studies and offers new ground for advancing research on multilingualism. 1},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for           {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Berzak, Yevgeni and Nakamura, Chie and Flynn, Suzanne and Katz, Boris},
	year = {2017},
	pages = {541--551},
}

@article{wilcox_predictive_nodate,
	title = {On the {Predictive} {Power} of {Neural} {Language} {Models} for {Human} {Real}-{Time} {Comprehension} {Behavior}},
	url = {https://github.com/},
	abstract = {Human reading behavior is tuned to the statistics of natural language: the time it takes human subjects to read a word can be predicted from estimates of the word's probability in context. However, it remains an open question what computational architecture best characterizes the expectations deployed in real time by humans that determine the behavioral signatures of reading. Here we test over two dozen models, independently manipulating computational architecture and training dataset size, on how well their next-word expectations predict human reading time behavior on naturalistic text corpora. Consistent with previous work, we find that across model architectures and training dataset sizes the relationship between word log-probability and reading time is (near-)linear. We next evaluate how features of these models determine their psychometric predictive power, or ability to predict human reading behavior. In general, the better a model's next-word expectations (as measured by the traditional language modeling perplexity objective), the better its psychometric predictive power. However , we find nontrivial differences in psychometric predictive power across model architectures. For any given perplexity, deep Transformer models and n-gram models generally show superior psychometric predictive power over LSTM or structurally supervised neural models, especially for eye movement data. Finally, we compare models' psychometric predictive power to the depth of their syntactic knowledge, as measured by a battery of syntactic generalization tests developed using methods from controlled psycholinguistic experiments. Once perplexity is controlled for, we find no significant relationship between syntactic knowledge and predictive power. These results suggest that, at least for the present state of natural language technology, different approaches may be required to best model human real-time language comprehension behavior in naturalistic reading versus behavior for controlled linguistic materials designed for targeted probing of syntactic knowledge .},
	urldate = {2022-03-21},
	author = {Wilcox, Ethan G and Gauthier, Jon and Hu, Jennifer and Qian, Peng and Levy, Roger P},
	keywords = {Language modeling, deep learning, eye-tracking, real-time language compre-hension, self-paced reading, ★},
}

@phdthesis{hollenstein_leveraging_2021,
	type = {Doctoral {Thesis}},
	title = {Leveraging {Cognitive} {Processing} {Signals} for {Natural} {Language} {Understanding}},
	copyright = {http://rightsstatements.org/page/InC-NC/1.0/},
	url = {https://www.research-collection.ethz.ch/handle/20.500.11850/472454},
	abstract = {In this thesis, we aim to narrow the gap between human language processing and computational language processing. Natural language processing (NLP) models are imperfect and lack intricate capabilities that humans access automatically when processing speech or reading text. Human language processing signals can be leveraged to increase the performance of machine learning (ML) models and to pursue explanatory research for a better understanding of the differences between human and machine language processing. In particular, the contributions of this thesis are threefold:  1. We compile the Zurich Cognitive Language Processing Corpus (ZuCo), a dataset of simultaneous eye tracking and electroencephalography (EEG) recordings from participants reading natural sentences from real-world texts. When we read, our brain processes language and generates cognitive processing signals such as gaze patterns and brain activity. ZuCo includes data of 30 English native speakers, each reading 700-1,100 sentences. This corpus represents a valuable resource for cognitively-inspired NLP.  2. We leverage these cognitive signals to augment ML models for NLP. Compared to purely text-based models, we show consistent improvements across a range of tasks and for both eye tracking and brain activity data. We further explore two of the main challenges in this area: (i) decoding brain activity for language processing and (ii) dealing with limited training data to eliminate the need for recorded cognitive signals at test time.  3. We evaluate the cognitive plausibility of computational language models, the cornerstones of state-of-the-art NLP. We develop CogniVal, the first openly available framework for evaluating English word embeddings based on cognitive lexical semantics. Specifically, embeddings are evaluated by their performance at predicting a wide range of cognitive data sources recorded during language comprehension, including multiple eye tracking datasets and brain activity recordings such as electroencephalography and functional magnetic resonance imaging.},
	language = {en},
	urldate = {2022-03-25},
	school = {ETH Zurich},
	author = {Hollenstein, Nora},
	year = {2021},
	doi = {10.3929/ethz-b-000472454},
	note = {Accepted: 2021-03-02T12:35:26Z},
}

@article{mishra_leveraging_2017,
	title = {Leveraging {Cognitive} {Features} for {Sentiment} {Analysis}},
	url = {http://arxiv.org/abs/1701.05581},
	abstract = {Sentiments expressed in user-generated short text and sentences are nuanced by subtleties at lexical, syntactic, semantic and pragmatic levels. To address this, we propose to augment traditional features used for sentiment analysis and sarcasm detection, with cognitive features derived from the eye-movement patterns of readers. Statistical classification using our enhanced feature set improves the performance (F-score) of polarity detection by a maximum of 3.7\% and 9.3\% on two datasets, over the systems that use only traditional features. We perform feature significance analysis, and experiment on a held-out dataset, showing that cognitive features indeed empower sentiment analyzers to handle complex constructs.},
	urldate = {2022-03-26},
	journal = {arXiv:1701.05581 [cs]},
	author = {Mishra, Abhijit and Kanojia, Diptesh and Nagar, Seema and Dey, Kuntal and Bhattacharyya, Pushpak},
	month = jan,
	year = {2017},
	note = {arXiv: 1701.05581},
	keywords = {Computer Science - Computation and Language},
}

@article{hollenstein_entity_2019,
	title = {Entity {Recognition} at {First} {Sight}: {Improving} {NER} with {Eye} {Movement} {Information}},
	shorttitle = {Entity {Recognition} at {First} {Sight}},
	url = {http://arxiv.org/abs/1902.10068},
	abstract = {Previous research shows that eye-tracking data contains information about the lexical and syntactic properties of text, which can be used to improve natural language processing models. In this work, we leverage eye movement features from three corpora with recorded gaze information to augment a state-of-the-art neural model for named entity recognition (NER) with gaze embeddings. These corpora were manually annotated with named entity labels. Moreover, we show how gaze features, generalized on word type level, eliminate the need for recorded eye-tracking data at test time. The gaze-augmented models for NER using tokenlevel and type-level features outperform the baselines. We present the beneﬁts of eyetracking features by evaluating the NER models on both individual datasets as well as in cross-domain settings.},
	language = {en},
	urldate = {2022-03-25},
	journal = {arXiv:1902.10068 [cs]},
	author = {Hollenstein, Nora and Zhang, Ce},
	month = mar,
	year = {2019},
	note = {arXiv: 1902.10068},
	keywords = {Integrating Eye Movements \& NLP Task, Red, Relevant},
}

@incollection{pollatsek_e-z_2015,
	title = {E-{Z} {Reader}},
	url = {http://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199324576.001.0001/oxfordhb-9780199324576-e-17},
	urldate = {2021-10-08},
	booktitle = {The {Oxford} {Handbook} of {Reading}},
	publisher = {Oxford University Press},
	author = {Pollatsek, Alexander and Treiman, Rebecca and Reichle, Erik D. and Sheridan, Heather},
	month = sep,
	year = {2015},
	doi = {10.1093/oxfordhb/9780199324576.013.17},
}

@inproceedings{barrett_sequence_2018,
	address = {Brussels, Belgium},
	title = {Sequence {Classification} with {Human} {Attention}},
	url = {https://aclanthology.org/K18-1030},
	doi = {10.18653/v1/K18-1030},
	abstract = {Learning attention functions requires large volumes of data, but many NLP tasks simulate human behavior, and in this paper, we show that human attention really does provide a good inductive bias on many attention functions in NLP. Specifically, we use estimated human attention derived from eye-tracking corpora to regularize attention functions in recurrent neural networks. We show substantial improvements across a range of tasks, including sentiment analysis, grammatical error detection, and detection of abusive language.},
	urldate = {2022-03-26},
	booktitle = {Proceedings of the 22nd {Conference} on {Computational} {Natural} {Language} {Learning}},
	publisher = {Association for Computational Linguistics},
	author = {Barrett, Maria and Bingel, Joachim and Hollenstein, Nora and Rei, Marek and Søgaard, Anders},
	month = oct,
	year = {2018},
	pages = {302--312},
}

@article{rayner1998eye,
  title={Eye movements in reading and information processing: 20 years of research.},
  author={Rayner, Keith},
  journal={Psychological bulletin},
  volume={124},
  number={3},
  pages={372},
  year={1998},
  publisher={American Psychological Association}
}

@article{zou_palrace_2022,
	title = {{PALRACE}: {Reading} {Comprehension} {Dataset} with {Human} {Data} and {Labeled} {Rationales}},
	shorttitle = {{PALRACE}},
	url = {http://arxiv.org/abs/2106.12373},
	abstract = {Pre-trained language models achieves high performance on machine reading comprehension (MRC) tasks but the results are hard to explain. An appealing approach to make models explainable is to provide rationales for its decision. To investigate whether human rationales can further improve current models and to facilitate supervised learning of human rationales, here we present PALRACE (Pruned And Labeled RACE), a new MRC dataset with human labeled rationales for 800 passages selected from the RACE dataset. We further classified the question to each passage into 6 types. Each passage was read by at least 26 human readers, who labeled their rationales to answer the question. It is demonstrated that models such as RoBERTa-large outperforms human readers in all 6 types of questions, including inference questions, but its performance can be further improved when having access to the human rationales. Simpler models and pre-trained models that are not fine-tuned based on the task benefit more from human rationales, and their performance can be boosted by more than 30\% by rationales. With access to human rationales, a simple model based on the GloVe word embedding can reach the performance of BERT-base.},
	urldate = {2022-03-31},
	journal = {arXiv:2106.12373 [cs]},
	author = {Zou, Jiajie and Zhang, Yuran and Jin, Peiqing and Luo, Cheng and Pan, Xunyi and Ding, Nai},
	month = mar,
	year = {2022},
	note = {arXiv: 2106.12373},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{salicchi_looking_2021,
	address = {Groningen, The Netherlands (online)},
	title = {Looking for a {Role} for {Word} {Embeddings} in {Eye}-{Tracking} {Features} {Prediction}: {Does} {Semantic} {Similarity} {Help}?},
	shorttitle = {Looking for a {Role} for {Word} {Embeddings} in {Eye}-{Tracking} {Features} {Prediction}},
	url = {https://aclanthology.org/2021.iwcs-1.9},
	abstract = {Eye-tracking psycholinguistic studies have suggested that context-word semantic coherence and predictability influence language processing during the reading activity. In this study, we investigate the correlation between the cosine similarities computed with word embedding models (both static and contextualized) and eye-tracking data from two naturalistic reading corpora. We also studied the correlations of surprisal scores computed with three state-of-the-art language models. Our results show strong correlation for the scores computed with BERT and GloVe, suggesting that similarity can play an important role in modeling reading times.},
	urldate = {2022-04-24},
	booktitle = {Proceedings of the 14th {International} {Conference} on {Computational} {Semantics} ({IWCS})},
	publisher = {Association for Computational Linguistics},
	author = {Salicchi, Lavinia and Lenci, Alessandro and Chersoni, Emmanuele},
	month = jun,
	year = {2021},
	pages = {87--92},
}

@article{kexin_literature_2021,
	title = {Literature {Review} on {Neural} {Machine} {Comprehension} for {Question} {Answering}},
	url = {http://rgdoi.net/10.13140/RG.2.2.12292.65928},
	doi = {10.13140/RG.2.2.12292.65928},
	language = {en},
	urldate = {2022-04-22},
	author = {Kexin, Xiong},
	year = {2021},
	note = {Publisher: Unpublished},
}

@article{kennedy_frequency_2013,
	title = {Frequency and predictability effects in the {Dundee} {Corpus}: {An} eye movement analysis},
	volume = {66},
	url = {http://dx.doi.org/10.1080/17470218.2012.676054},
	doi = {10.1080/17470218.2012.676054},
	abstract = {Analyses carried out on a large corpus of eye movement data were used to comment on four contentious theoretical issues. The results provide no evidence that word frequency and word predictability have early interactive effects on inspection time. Contrary to some earlier studies, in these data there is little evidence that properties of a prior word generally spill over and influence current processing. In contrast, there is evidence that both the frequency and the predictability of a word in parafoveal vision influence foveal processing. In the case of predictability, the direction of the effect suggests that more predictable parafoveal words produce longer foveal fixations. Finally, there is evidence that information about word class modulates processing over a span greater than a single word. The results support the notion of distributed parallel processing. The starting point for the present paper is a study carried out by Kliegl, Nuthmann, and Engbert (2006). They collected eye movements from 222 participants reading the 144 sentences comprising the Potsdam Sentence Corpus. The predictability of each word in each sentence was assessed using a cloze procedure in a separate study. After appropriate filtering, the resulting database contained measurements relating to over 150,000 fixations. This impressive array of data was subjected to a repeated measures multiple regression analysis (Lorch \& Myers, 1990). Triples of words where each word was fixated in turn were identified. Single-fixation and gaze duration on a given target word n were then modelled as a function of its own length, frequency , and predictability and the length, frequency, and predictability of two adjacent words (word n-1 and word n + 1). In addition to these word-based properties, Kliegl et al. also included independent variables reflecting dynamics of eye movement control: initial landing position (entered as both linear and quadratic functions) and entry and exit saccade extent for each target word.},
	number = {3},
	urldate = {2022-03-06},
	journal = {THE QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY},
	author = {Kennedy, Alan and Pynte, Joël and Murray, Wayne S and Paul, Shirley-Anne},
	year = {2013},
	keywords = {Corpus studies, Eye movements, Fixation duration, Gaze, Reading},
	pages = {601--618},
}

@techreport{noauthor_eyelink_nodate,
	title = {{EyeLink} ® {Data} {Viewer} {User}'s {Manual}},
}

@article{reichle_eye_2010,
	title = {Eye movements during mindless reading},
	volume = {21},
	issn = {09567976},
	doi = {10.1177/0956797610378686},
	abstract = {Mindless reading occurs when the eyes continue moving across the page even though the mind is thinking about something unrelated to the text. Despite how commonly it occurs, very little is known about mindless reading. The present experiment examined eye movements during mindless reading. Comparisons of fixation-duration measures collected during intervals of normal reading and intervals of mindless reading indicate that fixations during the latter were longer and less affected by lexical and linguistic variables than fixations during the former. Also, eye movements immediately preceding self-caught mind wandering were especially erratic. These results suggest that the cognitive processes that guide eye movements during normal reading are not engaged during mindless reading. We discuss the implications of these findings for theories of eye movement control in reading, for the distinction between experiential awareness and meta-awareness, and for reading comprehension. © The Author(s) 2010.},
	number = {9},
	urldate = {2022-03-02},
	journal = {Psychological Science},
	author = {Reichle, Erik D. and Reineberg, Andrew E. and Schooler, Jonathan W.},
	month = sep,
	year = {2010},
	pmid = {20679524},
	note = {Publisher: SAGE PublicationsSage CA: Los Angeles, CA},
	keywords = {Relevant, attention, awareness, eye movements, meta-awareness, reading},
	pages = {1300--1310},
}

@inproceedings{sogaard_evaluating_2016,
	address = {Berlin, Germany},
	title = {Evaluating word embeddings with {fMRI} and eye-tracking},
	url = {https://aclanthology.org/W16-2521},
	doi = {10.18653/v1/W16-2521},
	urldate = {2022-03-26},
	booktitle = {Proceedings of the 1st {Workshop} on {Evaluating} {Vector}-{Space} {Representations} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Søgaard, Anders},
	month = aug,
	year = {2016},
	keywords = {Not Relevant, Red},
	pages = {116--121},
}

@article{demberg_data_2008,
	title = {Data from {Eye}-tracking {Corpora} as {Evidence} for {Theories} of {Syntactic} {Processing} {Complexity} {EVIDENCE} {FROM} {EYE}-{TRACKING} {CORPORA} 2},
	volume = {109},
	abstract = {We evaluate the predictions of two theories of syntactic processing complexity, dependency locality theory (DLT) and surprisal, against the Dundee corpus, which contains the eye-tracking record of 10 participants reading 51,000 words of newspaper text. Our results show that DLT integration cost is not a significant predictor of reading times for arbitrary words in the corpus. However, DLT successfully predicts reading times for nouns and verbs. We also find evidence for integration cost effects at auxiliaries, not predicted by DLT. For surprisal, we demonstrate that an unlexicalized formulation of surprisal can predict reading times for arbitrary words in the corpus. Comparing DLT integration cost and surprisal, we find that the two measures are uncorrelated, which suggests that a complete theory will need to incorporate both aspects of processing complexity. We conclude that eye-tracking corpora, which provide reading time data for naturally occurring, contextualized sentences, can complement experimental evidence as a basis for theories of processing complexity.},
	number = {2},
	urldate = {2021-10-07},
	journal = {Cognition},
	author = {Demberg, Vera and Keller, Frank},
	year = {2008},
	keywords = {corpus data, dependency locality theory, eye-tracking, processing complexity, surprisal},
	pages = {193--210},
}

@inproceedings{hollenstein_cmcl_2021,
	address = {Online},
	title = {{CMCL} 2021 {Shared} {Task} on {Eye}-{Tracking} {Prediction}},
	url = {https://aclanthology.org/2021.cmcl-1.7},
	doi = {10.18653/v1/2021.cmcl-1.7},
	abstract = {Eye-tracking data from reading represent an important resource for both linguistics and natural language processing. The ability to accurately model gaze features is crucial to advance our understanding of language processing. This paper describes the Shared Task on Eye-Tracking Data Prediction, jointly organized with the eleventh edition of the Work- shop on Cognitive Modeling and Computational Linguistics (CMCL 2021). The goal of the task is to predict 5 different token- level eye-tracking metrics of the Zurich Cognitive Language Processing Corpus (ZuCo). Eye-tracking data were recorded during natural reading of English sentences. In total, we received submissions from 13 registered teams, whose systems include boosting algorithms with handcrafted features, neural models leveraging transformer language models, or hybrid approaches. The winning system used a range of linguistic and psychometric features in a gradient boosting framework.},
	urldate = {2022-03-25},
	booktitle = {Proceedings of the {Workshop} on {Cognitive} {Modeling} and {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Hollenstein, Nora and Chersoni, Emmanuele and Jacobs, Cassandra L. and Oseki, Yohei and Prévot, Laurent and Santus, Enrico},
	month = jun,
	year = {2021},
	pages = {72--78},
}

@inproceedings{malmaud_bridging_2020,
	address = {Stroudsburg, PA, USA},
	title = {Bridging {Information}-{Seeking} {Human} {Gaze} and {Machine} {Reading} {Comprehension}},
	url = {https://www.aclweb.org/anthology/2020.conll-1.11},
	doi = {10.18653/v1/2020.conll-1.11},
	abstract = {In this work, we analyze how human gaze during reading comprehension is conditioned on the given reading comprehension question, and whether this signal can be beneficial for machine reading comprehension. To this end, we collect a new eye-tracking dataset with a large number of participants engaging in a multiple choice reading comprehension task. Our analysis of this data reveals increased fixation times over parts of the text that are most relevant for answering the question. Motivated by this finding, we propose making automated reading comprehension more human-like by mimicking human information-seeking reading behavior during reading comprehension. We demonstrate that this approach leads to performance gains on multiple choice question answering in English for a state-of-the-art reading comprehension model.},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 24th {Conference} on {Computational} {Natural} {Language} {Learning}},
	publisher = {Association for Computational Linguistics},
	author = {Malmaud, Jonathan and Levy, Roger and Berzak, Yevgeni},
	year = {2020},
	pages = {142--152},
}

@article{baradaran_survey_2022,
	title = {A {Survey} on {Machine} {Reading} {Comprehension} {Systems}},
	issn = {1351-3249, 1469-8110},
	url = {https://www.cambridge.org/core/journals/natural-language-engineering/article/abs/survey-on-machine-reading-comprehension-systems/23FBCE30CB4325538E7DD08A7924315F},
	doi = {10.1017/S1351324921000395},
	abstract = {Machine Reading Comprehension (MRC) is a challenging task and hot topic in Natural Language Processing. The goal of this field is to develop systems for answering the questions regarding a given context. In this paper, we present a comprehensive survey on diverse aspects of MRC systems, including their approaches, structures, input/outputs, and research novelties. We illustrate the recent trends in this field based on a review of 241 papers published during 2016–2020. Our investigation demonstrated that the focus of research has changed in recent years from answer extraction to answer generation, from single- to multi-document reading comprehension, and from learning from scratch to using pre-trained word vectors. Moreover, we discuss the popular datasets and the evaluation metrics in this field. The paper ends with an investigation of the most-cited papers and their contributions.},
	language = {en},
	urldate = {2022-03-31},
	journal = {Natural Language Engineering},
	author = {Baradaran, Razieh and Ghiasi, Razieh and Amirkhani, Hossein},
	month = jan,
	year = {2022},
	note = {Publisher: Cambridge University Press},
	keywords = {Machine Reading Comprehension, Natural Language Processing, deep learning, literature review, question answering},
	pages = {1--50},
}

@inproceedings{vickers_cognlp-sheffield_2021,
	address = {Online},
	title = {{CogNLP}-{Sheffield} at {CMCL} 2021 {Shared} {Task}: {Blending} {Cognitively} {Inspired} {Features} with {Transformer}-based {Language} {Models} for {Predicting} {Eye} {Tracking} {Patterns}},
	shorttitle = {{CogNLP}-{Sheffield} at {CMCL} 2021 {Shared} {Task}},
	url = {https://aclanthology.org/2021.cmcl-1.16},
	doi = {10.18653/v1/2021.cmcl-1.16},
	abstract = {The CogNLP-Sheffield submissions to the CMCL 2021 Shared Task examine the value of a variety of cognitively and linguistically inspired features for predicting eye tracking patterns, as both standalone model inputs and as supplements to contextual word embeddings (XLNet). Surprisingly, the smaller pre-trained model (XLNet-base) outperforms the larger (XLNet-large), and despite evidence that multi-word expressions (MWEs) provide cognitive processing advantages, MWE features provide little benefit to either model.},
	urldate = {2022-04-24},
	booktitle = {Proceedings of the {Workshop} on {Cognitive} {Modeling} and {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Vickers, Peter and Wainwright, Rosa and Tayyar Madabushi, Harish and Villavicencio, Aline},
	month = jun,
	year = {2021},
	pages = {125--133},
}

@article{baazeem_cognitively_2021,
	title = {Cognitively {Driven} {Arabic} {Text} {Readability} {Assessment} {Using} {Eye}-{Tracking}},
	volume = {11},
	issn = {20763417},
	url = {http://ezlibrary.technion.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=aci&AN=152657705&lang=he&site=eds-live&scope=site},
	doi = {10.3390/app11188607},
	abstract = {Using physiological data helps to identify the cognitive processing in the human brain. One method of obtaining these behavioral signals is by using eye-tracking technology. Previous cognitive psychology literature shows that readable and difficult-to-read texts are associated with certain eye movement patterns, which has recently encouraged researchers to use these patterns for readability assessment tasks. However, although it seems promising, this research direction has not been explored adequately, particularly for Arabic. The Arabic language is defined by its own rules and has its own characteristics and challenges. There is still a clear gap in determining the potential of using eye-tracking measures to improve Arabic text. Motivated by this, we present a pilot study to explore the extent to which eye-tracking measures enhance Arabic text readability. We collected the eye movements of 41 participants while reading Arabic texts to provide real-time processing of the text; these data were further analyzed and used to build several readability prediction models using different regression algorithms. The findings show an improvement in the readability prediction task, which requires further investigation. To the best of our knowledge, this work is the first study to explore the relationship between Arabic readability and eye movement patterns.},
	number = {18},
	urldate = {2022-03-25},
	journal = {Applied Sciences (2076-3417)},
	author = {Baazeem, Ibtehal and Al-Khalifa, Hend and Al-Salman, Abdulmalik},
	month = sep,
	year = {2021},
	keywords = {Arabic language, Eye movements, Eye tracking, Natural language processing, Psychological literature, Real-time computing, eye movements, eye-tracking, human processing, machine learning, natural language processing, readability assessment, text difficulty},
	pages = {8607--8607},
}

@article{kutas_chapter_nodate,
	title = {{CHAPTER} 15 {A} {Look} around at {What} {Lies} {Ahead}: {Prediction} and {Predictability} in {Language} {Processing}},
	urldate = {2022-03-21},
	author = {Kutas, Marta and Delong, Katherine A and Smith, Nathaniel J},
	note = {ISBN: 10/22/20109:3},
	keywords = {★},
}

@inproceedings{berzak_assessing_2018,
	address = {Stroudsburg, PA, USA},
	title = {Assessing {Language} {Proficiency} from {Eye} {Movements} in {Reading}},
	url = {http://aclweb.org/anthology/N18-1180},
	doi = {10.18653/v1/N18-1180},
	abstract = {We present a novel approach for determining learners' second language proficiency which utilizes behavioral traces of eye movements during reading. Our approach provides stand-alone eyetracking based English proficiency scores which reflect the extent to which the learner's gaze patterns in reading are similar to those of native English speakers. We show that our scores correlate strongly with standardized English proficiency tests. We also demonstrate that gaze information can be used to accurately predict the outcomes of such tests. Our approach yields the strongest performance when the test taker is presented with a suite of sentences for which we have eyetracking data from other readers. However, it remains effective even using eyetracking with sentences for which eye movement data have not been previously collected. By deriving proficiency as an automatic byproduct of eye movements during ordinary reading, our approach offers a potentially valuable new tool for second language proficiency assessment. More broadly, our results open the door to future methods for inferring reader characteristics from the behavioral traces of reading.},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of           the {Association} for {Computational} {Linguistics}: {Human} {Language}           {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Berzak, Yevgeni and Katz, Boris and Levy, Roger},
	year = {2018},
	pages = {1986--1996},
}

@inproceedings{tokunaga_eye-tracking_2017,
	address = {Varna, Bulgaria},
	title = {An {Eye}-tracking {Study} of {Named} {Entity} {Annotation}},
	url = {https://doi.org/10.26615/978-954-452-049-6_097},
	doi = {10.26615/978-954-452-049-6_097},
	abstract = {Utilising effective features in machine learning-based natural language processing (NLP) is crucial in achieving good performance for a given NLP task. The paper describes a pilot study on the analysis of eye-tracking data during named entity (NE) annotation, aiming at obtaining insights into effective features for the NE recognition task. The eye gaze data were collected from 10 annotators and analysed regarding working time and fixation distribution. The results of the preliminary qualitative analysis showed that human annotators tend to look at broader contexts around the target NE than recent state-of-the-art automatic NE recognition systems and to use predicate argument relations to identify the NE categories.},
	urldate = {2022-03-26},
	booktitle = {Proceedings of the {International} {Conference} {Recent} {Advances} in {Natural} {Language} {Processing}, {RANLP} 2017},
	publisher = {INCOMA Ltd.},
	author = {Tokunaga, Takenobu and Nishikawa, Hitoshi and Iwakura, Tomoya},
	month = sep,
	year = {2017},
	pages = {758--764},
}

@article{zeng_survey_2020,
	title = {A {Survey} on {Machine} {Reading} {Comprehension}: {Tasks}, {Evaluation} {Metrics} and {Benchmark} {Datasets}},
	shorttitle = {A {Survey} on {Machine} {Reading} {Comprehension}},
	url = {http://arxiv.org/abs/2006.11880},
	abstract = {Machine Reading Comprehension (MRC) is a challenging Natural Language Processing(NLP) research field with wide real-world applications. The great progress of this field in recent years is mainly due to the emergence of large-scale datasets and deep learning. At present, a lot of MRC models have already surpassed human performance on various benchmark datasets despite the obvious giant gap between existing MRC models and genuine human-level reading comprehension. This shows the need for improving existing datasets, evaluation metrics, and models to move current MRC models toward "real" understanding. To address the current lack of comprehensive survey of existing MRC tasks, evaluation metrics, and datasets, herein, (1) we analyze 57 MRC tasks and datasets and propose a more precise classification method of MRC tasks with 4 different attributes; (2) we summarized 9 evaluation metrics of MRC tasks, 7 attributes and 10 characteristics of MRC datasets; (3) We also discuss key open issues in MRC research and highlighted future research directions. In addition, we have collected, organized, and published our data on the companion website(https://mrc-datasets.github.io/) where MRC researchers could directly access each MRC dataset, papers, baseline projects, and the leaderboard.},
	urldate = {2022-03-30},
	journal = {arXiv:2006.11880 [cs]},
	author = {Zeng, Changchang and Li, Shaobo and Li, Qin and Hu, Jie and Hu, Jianjun},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.11880},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{rogers_primer_2020,
	title = {A {Primer} in {BERTology}: {What} {We} {Know} {About} {How} {BERT} {Works}},
	volume = {8},
	issn = {2307-387X},
	shorttitle = {A {Primer} in {BERTology}},
	url = {https://direct.mit.edu/tacl/article/96482},
	doi = {10.1162/tacl_a_00349},
	abstract = {Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research.},
	language = {en},
	urldate = {2022-03-29},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
	month = dec,
	year = {2020},
	keywords = {Red, Relevant},
	pages = {842--866},
}

@inproceedings{vickers_cognlp-sheffield_2021-1,
	address = {Online},
	title = {{CogNLP}-{Sheffield} at {CMCL} 2021 {Shared} {Task}: {Blending} {Cognitively} {Inspired} {Features} with {Transformer}-based {Language} {Models} for {Predicting} {Eye} {Tracking} {Patterns}},
	shorttitle = {{CogNLP}-{Sheffield} at {CMCL} 2021 {Shared} {Task}},
	url = {https://aclanthology.org/2021.cmcl-1.16},
	doi = {10.18653/v1/2021.cmcl-1.16},
	abstract = {The CogNLP-Sheffield submissions to the CMCL 2021 Shared Task examine the value of a variety of cognitively and linguistically inspired features for predicting eye tracking patterns, as both standalone model inputs and as supplements to contextual word embeddings (XLNet). Surprisingly, the smaller pre-trained model (XLNet-base) outperforms the larger (XLNet-large), and despite evidence that multi-word expressions (MWEs) provide cognitive processing advantages, MWE features provide little benefit to either model.},
	urldate = {2022-04-24},
	booktitle = {Proceedings of the {Workshop} on {Cognitive} {Modeling} and {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Vickers, Peter and Wainwright, Rosa and Tayyar Madabushi, Harish and Villavicencio, Aline},
	month = jun,
	year = {2021},
	pages = {125--133},
}

@misc{noauthor_reading_nodate-1,
	title = {Reading for comprehension: the contribution of decoding, linguistic and cognitive skills {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Reading for comprehension},
	url = {https://reader.elsevier.com/reader/sd/pii/S2211609519300041?token=F0586C16C57B5C43791001C7964A2E3FDC050B8C10A9D0AAE72A21340209A41831C8177CDAA6EAF93FC0AD34FE410E36&originRegion=eu-west-1&originCreation=20220413075459},
	language = {en},
	urldate = {2022-04-13},
	doi = {10.1016/bs.irrdd.2019.06.004},
}

@article{wilcox_predictive_nodate-1,
	title = {On the {Predictive} {Power} of {Neural} {Language} {Models} for {Human} {Real}-{Time} {Comprehension} {Behavior}},
	url = {https://github.com/},
	abstract = {Human reading behavior is tuned to the statistics of natural language: the time it takes human subjects to read a word can be predicted from estimates of the word's probability in context. However, it remains an open question what computational architecture best characterizes the expectations deployed in real time by humans that determine the behavioral signatures of reading. Here we test over two dozen models, independently manipulating computational architecture and training dataset size, on how well their next-word expectations predict human reading time behavior on naturalistic text corpora. Consistent with previous work, we find that across model architectures and training dataset sizes the relationship between word log-probability and reading time is (near-)linear. We next evaluate how features of these models determine their psychometric predictive power, or ability to predict human reading behavior. In general, the better a model's next-word expectations (as measured by the traditional language modeling perplexity objective), the better its psychometric predictive power. However , we find nontrivial differences in psychometric predictive power across model architectures. For any given perplexity, deep Transformer models and n-gram models generally show superior psychometric predictive power over LSTM or structurally supervised neural models, especially for eye movement data. Finally, we compare models' psychometric predictive power to the depth of their syntactic knowledge, as measured by a battery of syntactic generalization tests developed using methods from controlled psycholinguistic experiments. Once perplexity is controlled for, we find no significant relationship between syntactic knowledge and predictive power. These results suggest that, at least for the present state of natural language technology, different approaches may be required to best model human real-time language comprehension behavior in naturalistic reading versus behavior for controlled linguistic materials designed for targeted probing of syntactic knowledge .},
	urldate = {2022-03-21},
	author = {Wilcox, Ethan G and Gauthier, Jon and Hu, Jennifer and Qian, Peng and Levy, Roger P},
	keywords = {Language modeling, deep learning, eye-tracking, real-time language compre-hension, self-paced reading, ★},
}

@article{kutas_chapter_nodate-1,
	title = {{CHAPTER} 15 {A} {Look} around at {What} {Lies} {Ahead}: {Prediction} and {Predictability} in {Language} {Processing}},
	urldate = {2022-03-21},
	author = {Kutas, Marta and Delong, Katherine A and Smith, Nathaniel J},
	note = {ISBN: 10/22/20109:3},
	keywords = {★},
}

@article{kennedy_frequency_2013-1,
	title = {Frequency and predictability effects in the {Dundee} {Corpus}: {An} eye movement analysis},
	volume = {66},
	url = {http://dx.doi.org/10.1080/17470218.2012.676054},
	doi = {10.1080/17470218.2012.676054},
	abstract = {Analyses carried out on a large corpus of eye movement data were used to comment on four contentious theoretical issues. The results provide no evidence that word frequency and word predictability have early interactive effects on inspection time. Contrary to some earlier studies, in these data there is little evidence that properties of a prior word generally spill over and influence current processing. In contrast, there is evidence that both the frequency and the predictability of a word in parafoveal vision influence foveal processing. In the case of predictability, the direction of the effect suggests that more predictable parafoveal words produce longer foveal fixations. Finally, there is evidence that information about word class modulates processing over a span greater than a single word. The results support the notion of distributed parallel processing. The starting point for the present paper is a study carried out by Kliegl, Nuthmann, and Engbert (2006). They collected eye movements from 222 participants reading the 144 sentences comprising the Potsdam Sentence Corpus. The predictability of each word in each sentence was assessed using a cloze procedure in a separate study. After appropriate filtering, the resulting database contained measurements relating to over 150,000 fixations. This impressive array of data was subjected to a repeated measures multiple regression analysis (Lorch \& Myers, 1990). Triples of words where each word was fixated in turn were identified. Single-fixation and gaze duration on a given target word n were then modelled as a function of its own length, frequency , and predictability and the length, frequency, and predictability of two adjacent words (word n-1 and word n + 1). In addition to these word-based properties, Kliegl et al. also included independent variables reflecting dynamics of eye movement control: initial landing position (entered as both linear and quadratic functions) and entry and exit saccade extent for each target word.},
	number = {3},
	urldate = {2022-03-06},
	journal = {THE QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY},
	author = {Kennedy, Alan and Pynte, Joël and Murray, Wayne S and Paul, Shirley-Anne},
	year = {2013},
	keywords = {Corpus studies, Eye movements, Fixation duration, Gaze, Reading},
	pages = {601--618},
}

@article{reichle_eye_2010-1,
	title = {Eye movements during mindless reading},
	volume = {21},
	issn = {09567976},
	doi = {10.1177/0956797610378686},
	abstract = {Mindless reading occurs when the eyes continue moving across the page even though the mind is thinking about something unrelated to the text. Despite how commonly it occurs, very little is known about mindless reading. The present experiment examined eye movements during mindless reading. Comparisons of fixation-duration measures collected during intervals of normal reading and intervals of mindless reading indicate that fixations during the latter were longer and less affected by lexical and linguistic variables than fixations during the former. Also, eye movements immediately preceding self-caught mind wandering were especially erratic. These results suggest that the cognitive processes that guide eye movements during normal reading are not engaged during mindless reading. We discuss the implications of these findings for theories of eye movement control in reading, for the distinction between experiential awareness and meta-awareness, and for reading comprehension. © The Author(s) 2010.},
	number = {9},
	urldate = {2022-03-02},
	journal = {Psychological Science},
	author = {Reichle, Erik D. and Reineberg, Andrew E. and Schooler, Jonathan W.},
	month = sep,
	year = {2010},
	pmid = {20679524},
	note = {Publisher: SAGE PublicationsSage CA: Los Angeles, CA},
	keywords = {attention, awareness, eye movements, meta-awareness, reading},
	pages = {1300--1310},
}



@techreport{noauthor_eyelink_nodate-1,
	title = {{EyeLink} ® {Data} {Viewer} {User}'s {Manual}},
}

@incollection{pollatsek_e-z_2015-1,
	title = {E-{Z} {Reader}},
	url = {http://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199324576.001.0001/oxfordhb-9780199324576-e-17},
	urldate = {2021-10-08},
	booktitle = {The {Oxford} {Handbook} of {Reading}},
	publisher = {Oxford University Press},
	author = {Pollatsek, Alexander and Treiman, Rebecca and Reichle, Erik D. and Sheridan, Heather},
	month = sep,
	year = {2015},
	doi = {10.1093/oxfordhb/9780199324576.013.17},
}

@inproceedings{berzak_predicting_2017-1,
	address = {Stroudsburg, PA, USA},
	title = {Predicting {Native} {Language} from {Gaze}},
	url = {http://aclweb.org/anthology/P17-1050},
	doi = {10.18653/v1/P17-1050},
	abstract = {A fundamental question in language learning concerns the role of a speaker's first language in second language acquisition. We present a novel methodology for studying this question: analysis of eye-movement patterns in second language reading of free-form text. Using this methodology, we demonstrate for the first time that the native language of English learners can be predicted from their gaze fixations when reading English. We provide analysis of classifier uncertainty and learned features, which indicates that differences in English reading are likely to be rooted in linguistic divergences across native languages. The presented framework complements production studies and offers new ground for advancing research on multilingualism. 1},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for           {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Berzak, Yevgeni and Nakamura, Chie and Flynn, Suzanne and Katz, Boris},
	year = {2017},
	pages = {541--551},
}

@inproceedings{berzak_assessing_2018-1,
	address = {Stroudsburg, PA, USA},
	title = {Assessing {Language} {Proficiency} from {Eye} {Movements} in {Reading}},
	url = {http://aclweb.org/anthology/N18-1180},
	doi = {10.18653/v1/N18-1180},
	abstract = {We present a novel approach for determining learners' second language proficiency which utilizes behavioral traces of eye movements during reading. Our approach provides stand-alone eyetracking based English proficiency scores which reflect the extent to which the learner's gaze patterns in reading are similar to those of native English speakers. We show that our scores correlate strongly with standardized English proficiency tests. We also demonstrate that gaze information can be used to accurately predict the outcomes of such tests. Our approach yields the strongest performance when the test taker is presented with a suite of sentences for which we have eyetracking data from other readers. However, it remains effective even using eyetracking with sentences for which eye movement data have not been previously collected. By deriving proficiency as an automatic byproduct of eye movements during ordinary reading, our approach offers a potentially valuable new tool for second language proficiency assessment. More broadly, our results open the door to future methods for inferring reader characteristics from the behavioral traces of reading.},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of           the {Association} for {Computational} {Linguistics}: {Human} {Language}           {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Berzak, Yevgeni and Katz, Boris and Levy, Roger},
	year = {2018},
	pages = {1986--1996},
}

@article{smith_effect_2013-1,
	title = {The effect of word predictability on reading time is logarithmic},
	volume = {128},
	issn = {0010-0277},
	doi = {10.1016/J.COGNITION.2013.02.013},
	abstract = {It is well known that real-time human language processing is highly incremental and context-driven, and that the strength of a comprehender's expectation for each word encountered is a key determinant of the difficulty of integrating that word into the preceding context. In reading, this differential difficulty is largely manifested in the amount of time taken to read each word. While numerous studies over the past thirty years have shown expectation-based effects on reading times driven by lexical, syntactic, semantic, pragmatic, and other information sources, there has been little progress in establishing the quantitative relationship between expectation (or prediction) and reading times. Here, by combining a state-of-the-art computational language model, two large behavioral data-sets, and non-parametric statistical techniques, we establish for the first time the quantitative form of this relationship, finding that it is logarithmic over six orders of magnitude in estimated predictability. This result is problematic for a number of established models of eye movement control in reading, but lends partial support to an optimal perceptual discrimination account of word recognition. We also present a novel model in which language processing is highly incremental well below the level of the individual word, and show that it predicts both the shape and time-course of this effect. At a more general level, this result provides challenges for both anticipatory processing and semantic integration accounts of lexical predictability effects. And finally, this result provides evidence that comprehenders are highly sensitive to relative differences in predictability - even for differences between highly unpredictable words - and thus helps bring theoretical unity to our understanding of the role of prediction at multiple levels of linguistic structure in real-time language comprehension. © 2013 Elsevier B.V.},
	number = {3},
	urldate = {2021-10-07},
	journal = {Cognition},
	author = {Smith, Nathaniel J. and Levy, Roger},
	month = sep,
	year = {2013},
	note = {Publisher: Elsevier},
	keywords = {Expectation, Information theory, Probabilistic models of cognition, Psycholinguistics, Reading},
	pages = {302--319},
}

@article{rayner_psychological_1998-1,
	title = {Psychological {Bulletin} {Eye} {Movements} in {Reading} and {Information} {Processing}: 20 {Years} of {Research}},
	volume = {124},
	abstract = {Recent studies of eye movements in reading and other information processing tasks, such as music reading, typing, visual search, and scene perception, are reviewed. The major emphasis of the review is on reading as a specific example of cognitive processing. Basic topics discussed with respect to reading are (a) the characteristics of eye movements, (b) the perceptual span, (c) integration of information across saccades, (d) eye movement control, and (e) individual differences (including dyslexia). Similar topics are discussed with respect to the other tasks examined. The basic theme of the review is that eye movement data reflect moment-to-moment cognitive processes in the various tasks examined. Theoretical and practical considerations concerning the use of eye movement data are also discussed. Many studies using eye movements to investigate cognitive processes have appeared over the past 20 years. In an earlier review, I (Rayner, 1978b) argued that since the mid-1970s we have been in a third era of eye movement research and that the success of research in the current era would depend on the ingenuity of researchers in designing interesting and informative studies. It would appear from the vast number of studies using eye movement data over the past 20 years that research in this third era is fulfilling the promise inherent in using eye movement behavior to infer cognitive processes. The first era of eye movement research extended from Javal's initial observations concerning the role of eye movements in reading in 1879 (see Huey, 1908) up until about 1920. During this era, many basic facts about eye movements were discovered. Issues such as saccadic suppression (the fact that we do not perceive information during an eye movement), saccade latency (the time that it takes to initiate an eye movement), and the size of the perceptual span (the region of effective vision) were of concern in this era. The second era, which coincided with the behaviorist movement in experimental psychology, tended to have a more applied focus, and little research was undertaken with eye movements to infer cognitive processes. Although classic work by Tinker (1946) on reading and by Buswell (1935) on scene perception was carried out during this era, in retrospect, most of the work seems to have focused on the eye movements per se (or on surface aspects of the task being investigated). Tinker's (1958) final review ended on the rather pessimistic note that almost every},
	number = {3},
	urldate = {2021-10-07},
	author = {Rayner, Keith},
	year = {1998},
	note = {Publisher: Psychological Association, Inc},
	pages = {372--422},
}

@article{demberg_data_2008-1,
	title = {Data from {Eye}-tracking {Corpora} as {Evidence} for {Theories} of {Syntactic} {Processing} {Complexity} {EVIDENCE} {FROM} {EYE}-{TRACKING} {CORPORA} 2},
	volume = {109},
	abstract = {We evaluate the predictions of two theories of syntactic processing complexity, dependency locality theory (DLT) and surprisal, against the Dundee corpus, which contains the eye-tracking record of 10 participants reading 51,000 words of newspaper text. Our results show that DLT integration cost is not a significant predictor of reading times for arbitrary words in the corpus. However, DLT successfully predicts reading times for nouns and verbs. We also find evidence for integration cost effects at auxiliaries, not predicted by DLT. For surprisal, we demonstrate that an unlexicalized formulation of surprisal can predict reading times for arbitrary words in the corpus. Comparing DLT integration cost and surprisal, we find that the two measures are uncorrelated, which suggests that a complete theory will need to incorporate both aspects of processing complexity. We conclude that eye-tracking corpora, which provide reading time data for naturally occurring, contextualized sentences, can complement experimental evidence as a basis for theories of processing complexity.},
	number = {2},
	urldate = {2021-10-07},
	journal = {Cognition},
	author = {Demberg, Vera and Keller, Frank},
	year = {2008},
	keywords = {corpus data, dependency locality theory, eye-tracking, processing complexity, surprisal},
	pages = {193--210},
}

@techreport{mohammad_semeval-2016_nodate,
	title = {{SemEval}-2016 {Task} 6: {Detecting} {Stance} in {Tweets}},
	url = {http://alt.qcri.org/semeval2016/task6/},
	abstract = {Here for the first time we present a shared task on detecting stance from tweets: given a tweet and a target entity (person, organization , etc.), automatic natural language systems must determine whether the tweeter is in favor of the given target, against the given target, or whether neither inference is likely. The target of interest may or may not be referred to in the tweet, and it may or may not be the target of opinion. Two tasks are proposed. Task A is a traditional supervised classification task where 70\% of the annotated data for a target is used as training and the rest for testing. For Task B, we use as test data all of the instances for a new target (not used in task A) and no training data is provided. Our shared task received submissions from 19 teams for Task A and from 9 teams for Task B. The highest classification F-score obtained was 67.82 for Task A and 56.28 for Task B. However, systems found it markedly more difficult to infer stance towards the target of interest from tweets that express opinion towards another entity.},
	urldate = {2021-05-04},
	author = {Mohammad, Saif M and Kiritchenko, Svetlana and Sobhani, Parinaz and Zhu, Xiaodan and Cherry, Colin},
	pages = {31--41},
}

@article{aldayel_stance_2020,
	title = {Stance detection on social media: state of the art and trends},
	volume = {58},
	issn = {23318422},
	url = {https://doi.org/10.1016/j.ipm.2021.102597},
	doi = {10.1016/j.ipm.2021.102597},
	abstract = {Stance detection on social media is an emerging opinion mining paradigm for various social and political applications where sentiment analysis might be sub-optimal. This paper surveys the work on stance detection and situates its usage within current opinion mining techniques in social media. An exhaustive review of stance detection techniques on social media is presented, including the task definition, the different types of targets in stance detection, the features set used, and the various machine learning approaches applied. The survey reports the state-of-the-art results on the existing benchmark datasets on stance detection, and discusses the most effective approaches. In addition, this study explores the emerging trends and the different applications of stance detection on social media. The study concludes by providing discussion of the gaps in the current existing research and highlighting the possible future directions for stance detection on social media.},
	urldate = {2021-05-04},
	journal = {arXiv},
	author = {AlDayel, Abeer and Magdy, Walid},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.03644
Publisher: arXiv},
	keywords = {And Phrases: Stance detection, Opinion, Perspectives, Sentiment, Stance, Stance prediction, Viewpoints},
	pages = {102597},
}

@article{ramponi_neural_2020,
	title = {Neural {Unsupervised} {Domain} {Adaptation} in {NLP}—{A} {Survey}},
	issn = {23318422},
	url = {https://github.com/bplank/awesome-neural-adaptation-in-NLP},
	doi = {10.18653/v1/2020.coling-main.603},
	abstract = {Deep neural networks excel at learning from labeled data and achieve state-of-the-art results on a wide array of Natural Language Processing tasks. In contrast, learning from unlabeled data, especially under domain shift, remains a challenge. Motivated by the latest advances, in this survey we review neural unsupervised domain adaptation techniques which do not require labeled target domain data. This is a more challenging yet a more widely applicable setup. We outline methods, from early approaches in traditional non-neural methods to pre-trained model transfer. We also revisit the notion of domain, and we uncover a bias in the type of Natural Language Processing tasks which received most attention. Lastly, we outline future directions, particularly the broader need for out-of-distribution generalization of future intelligent NLP.1},
	journal = {arXiv},
	author = {Ramponi, Alan and Plank, Barbara},
	year = {2020},
	note = {arXiv: 2006.00632
Publisher: Online},
	pages = {6838--6855},
}

@inproceedings{blitzer_biographies_2007,
	title = {Biographies, bollywood, boom-boxes and blenders: {Domain} adaptation for sentiment classification},
	isbn = {978-1-932432-86-2},
	url = {http://ida.},
	abstract = {Automatic sentiment classification has been extensively studied and applied in recent years. However, sentiment is expressed differently in different domains, and annotating corpora for every possible domain of interest is impractical. We investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. First, we extend to sentiment classification the recently-proposed structural correspondence learning (SCL) algorithm, reducing the relative error due to adaptation between domains by an average of 30\% over the original SCL algorithm and 46\% over a supervised baseline. Second, we identify a measure of domain similarity that correlates well with the potential for adaptation of a classifier from one domain to another. This measure could for instance be used to select a small set of domains to annotate whose trained classifiers would transfer well to many other domains. © 2007 Association for Computational Linguistics.},
	urldate = {2021-04-24},
	booktitle = {{ACL} 2007 - {Proceedings} of the 45th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Blitzer, John and Dredze, Mark and Pereira, Fernando},
	year = {2007},
	pages = {440--447},
}

@phdthesis{brian_xu_combating_2019,
	title = {Combating {Fake} {News} with {Adversarial} {Domain} {Adaptation} and {Neural} {Models}},
	url = {https://dspace.mit.edu/handle/1721.1/121689},
	abstract = {This electronic version was submitted by the student author. The certified thesis is available in the Institute Archives and Special Collections.},
	urldate = {2021-04-24},
	school = {Massachusetts Institute of Technology},
	author = {{Brian Xu}},
	year = {2019},
	note = {Publication Title: Diss. Massachusetts Institute of Technology, 2019.},
	keywords = {Electrical Engineering and Computer Science., Thesis},
}

@article{xu_adversarial_2019,
	title = {Adversarial domain adaptation for stance detection},
	issn = {23318422},
	url = {http://arxiv.org/abs/1902.02401},
	abstract = {This paper studies the problem of stance detection which aims to predict the perspective (or stance) of a given document with respect to a given claim. Stance detection is a major component of automated fact checking. As annotating stances in different domains is a tedious and costly task, automatic methods based on machine learning are viable alternatives. In this paper, we focus on adversarial domain adaptation for stance detection where we assume there exists sufficient labeled data in the source domain and limited labeled data in the target domain. Extensive experiments on publicly available datasets show the effectiveness of our domain adaption model in transferring knowledge for accurate stance detection across domains.},
	urldate = {2021-04-24},
	journal = {arXiv},
	author = {Xu, Brian and Mohtarami, Mitra and Glass, James},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.02401
Publisher: arXiv},
}

@misc{noauthor_data_nodate,
	title = {Data, {Evaluation}, and {Results} {\textless} {SemEval}-2016 {Task} 6},
	url = {https://alt.qcri.org/semeval2016/task6/index.php?id=data-and-tools},
	urldate = {2021-04-24},
}

@article{ben-david_perl_2020,
	title = {{PERL}: {Pivot}-based domain adaptation for pre-trained deep contextualized embedding models},
	issn = {23318422},
	url = {http://arxiv.org/abs/2006.09075},
	doi = {10.1162/tacl_a_00328},
	abstract = {Pivot-based neural representation models have lead to significant progress in domain adaptation for NLP. However, previous works that follow this approach utilize only labeled data from the source domain and unlabeled data from the source and target domains, but neglect to incorporate massive unlabeled corpora that are not necessarily drawn from these domains. To alleviate this, we propose PERL: A representation learning model that extends contextualized word embedding models such as BERT (Devlin et al., 2019) with pivot-based fine-tuning. PERL outperforms strong baselines across 22 sentiment classification domain adaptation setups, improves in-domain model performance, yields effective reduced-size models and increases model stability.1 2},
	urldate = {2021-04-24},
	journal = {arXiv},
	author = {Ben-David, Eyal and Rabinovitz, Carmel and Reichart, Roi},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.09075
Publisher: arXiv},
}

@misc{noauthor_multinli_nodate,
	title = {{MultiNLI}},
	url = {https://cims.nyu.edu/~sbowman/multinli/},
	urldate = {2021-04-24},
}

@techreport{conforti_adversarial_2021,
	title = {Adversarial {Training} for {News} {Stance} {Detection}: {Leveraging} {Signals} from a {Multi}-{Genre} {Corpus}},
	url = {https://tfhub.dev/tensorflow/bert},
	abstract = {Cross-target generalization constitutes an important issue for news Stance Detection (SD). In this short paper, we investigate adversarial cross-genre SD, where knowledge from annotated user-generated data is leveraged to improve news SD on targets unseen during training. We implement a BERT-based adversarial network and show experimental performance improvements over a set of strong baselines. Given the abundance of user-generated data, which are considerably less expensive to retrieve and annotate than news articles, this constitutes a promising research direction.},
	urldate = {2021-04-24},
	author = {Conforti, Costanza and Berndt, Jakob and Pilehvar, Mohammad Taher and Basaldella, Marco and Giannitsarou, Chryssi and Toxvaerd, Flavio and Collier, Nigel},
	year = {2021},
	pages = {1--7},
}

@inproceedings{wang_unseen_2020,
	title = {Unseen {Target} {Stance} {Detection} with {Adversarial} {Domain} {Generalization}},
	isbn = {978-1-72816-926-2},
	url = {http://arxiv.org/abs/2010.05471},
	doi = {10.1109/IJCNN48605.2020.9206635},
	abstract = {Although stance detection has made great progress in the past few years, it is still facing the problem of unseen targets. In this study, we investigate the domain difference between targets and thus incorporate attention-based conditional encoding with adversarial domain generalization to perform unseen target stance detection. Experimental results show that our approach achieves new state-of-the-art performance on the SemEval-2016 dataset, demonstrating the importance of domain difference between targets in unseen target stance detection.},
	urldate = {2021-04-24},
	booktitle = {Proceedings of the {International} {Joint} {Conference} on {Neural} {Networks}},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	author = {Wang, Zhen and Wang, Qiansheng and Lv, Chengguo and Cao, Xue and Fu, Guohong},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.05471},
	keywords = {adversarial domain generalization, attention, stance detection, transfer learning},
}

@techreport{cox_medical_2006,
	title = {Medical {Education} {Teaching} {Surgical} {Skills}-{Changes} in the {Wind}},
	url = {www.nejm.org},
	author = {Cox, Malcolm and Irby, David M and Reznick, Richard K and MacRae, Helen},
	year = {2006},
}

@article{moorthy_clinical_nodate,
	title = {Clinical review {Objective} assessment of technical skills in surgery},
	url = {http://www.bmj.com/},
	doi = {10.1136/bmj.327.7422.1032},
	urldate = {2021-11-18},
	author = {Moorthy, Krishna and Munz, Yaron and Sarker, Sudip K and Darzi, Ara},
}

@article{reiley_review_2011,
	title = {Review of methods for objective surgical skill evaluation},
	volume = {25},
	issn = {14322218},
	url = {https://link.springer.com/article/10.1007/s00464-010-1190-z},
	doi = {10.1007/S00464-010-1190-Z/FIGURES/6},
	abstract = {Background: Rising health and financial costs associated with iatrogenic errors have drawn increasing attention to the dexterity of surgeons. With the advent of new technologies, such as robotic surgical systems and medical simulators, researchers now have the tools to analyze surgical motion with the goal of differentiating the level of technical skill in surgeons. Methods: The review for this paper is obtained from a Google Scholar and PubMed search of the key words "objective surgical skill evaluation." Only studies that included motion analysis were used. Results: In this paper, we provide a clinical motivation for the importance of surgical skill evaluation. We review the current methods of tracking surgical motion and the available data-collection systems. We also survey current methods of surgical skill evaluation and show that most approaches fall into one of three methods: (1) structured human grading; (2) descriptive statistics; or (3) statistical language models of surgical motion. We discuss the need for an encompassing approach to model human skill through statistical models to allow for objective skill evaluation. © Springer Science+Business Media, LLC 2010.},
	number = {2},
	urldate = {2021-11-18},
	journal = {Surgical Endoscopy},
	author = {Reiley, Carol E. and Lin, Henry C. and Yuh, David D. and Hager, Gregory D.},
	month = jul,
	year = {2011},
	pmid = {20607563},
	note = {Publisher: Springer New York LLC},
	keywords = {Human robotic training, Surgical training courses},
	pages = {356--366},
}

@article{dangelo_idle_2015,
	title = {Idle time: an underdeveloped performance metric for assessing surgical skill},
	volume = {209},
	issn = {0002-9610},
	doi = {10.1016/J.AMJSURG.2014.12.013},
	abstract = {Background The aim of this study was to evaluate validity evidence using idle time as a performance measure in open surgical skills assessment. Methods This pilot study tested psychomotor planning skills of surgical attendings (n = 6), residents (n = 4) and medical students (n = 5) during suturing tasks of varying difficulty. Performance data were collected with a motion tracking system. Participants' hand movements were analyzed for idle time, total operative time, and path length. We hypothesized that there will be shorter idle times for more experienced individuals and on the easier tasks. Results A total of 365 idle periods were identified across all participants. Attendings had fewer idle periods during 3 specific procedure steps (P {\textless}.001). All participants had longer idle time on friable tissue (P {\textless}.005). Conclusions Using an experimental model, idle time was found to correlate with experience and motor planning when operating on increasingly difficult tissue types. Further work exploring idle time as a valid psychomotor measure is warranted.},
	number = {4},
	urldate = {2021-11-18},
	journal = {The American Journal of Surgery},
	author = {D'Angelo, Anne Lise D. and Rutherford, Drew N. and Ray, Rebecca D. and Laufer, Shlomi and Kwan, Calvin and Cohen, Elaine R. and Mason, Andrea and Pugh, Carla M.},
	month = apr,
	year = {2015},
	pmid = {25725505},
	note = {Publisher: Elsevier},
	keywords = {Assessment, Idle time, Motion tracking, Path length, Simulation, Surgical skills},
	pages = {645--651},
}

@article{dangelo_working_2016,
	title = {Working volume: validity evidence for a motion-based metric of surgical efficiency},
	volume = {211},
	issn = {0002-9610},
	doi = {10.1016/J.AMJSURG.2015.10.005},
	abstract = {Background The aim of this study was to evaluate working volume as a potential assessment metric for open surgical tasks. Methods Surgical attendings (n = 6), residents (n = 4), and medical students (n = 5) performed a suturing task on simulated connective tissue (foam), artery (rubber balloon), and friable tissue (tissue paper). Using a motion tracking system, effective working volume was calculated for each hand. Repeated measures analysis of variance assessed differences in working volume by experience level, dominant and/or nondominant hand, and tissue type. Results Analysis revealed a linear relationship between experience and working volume. Attendings had the smallest working volume, and students had the largest (P =.01). The 3-way interaction of experience level, hand, and material type showed attendings and residents maintained a similar working volume for dominant and nondominant hands for all tasks. In contrast, medical students' nondominant hand covered larger working volumes for the balloon and tissue paper materials (P {\textless}.05). Conclusions This study provides validity evidence for the use of working volume as a metric for open surgical skills. Working volume may provide a means for assessing surgical efficiency and the operative learning curve.},
	number = {2},
	urldate = {2021-11-18},
	journal = {The American Journal of Surgery},
	author = {D'Angelo, Anne Lise D. and Rutherford, Drew N. and Ray, Rebecca D. and Laufer, Shlomi and Mason, Andrea and Pugh, Carla M.},
	month = feb,
	year = {2016},
	pmid = {26701699},
	note = {Publisher: Elsevier},
	keywords = {Education, Motion tracking, Skills assessment, Surgery, Technical skills, Working volume},
	pages = {445--450},
}

% new


@article{kaakinen2008,
  title={Perspective-driven text comprehension},
  author={Kaakinen, Johanna K and Hy{\"o}n{\"a}, Jukka},
  journal={Applied Cognitive Psychology: The Official Journal of the Society for Applied Research in Memory and Cognition},
  volume={22},
  number={3},
  pages={319--334},
  year={2008},
  publisher={Wiley Online Library}
}

@article{just1982speed,
  title={What eye fixations tell us about speed reading and skimming},
  author={Just, Marcel Adam and Carpenter, Patricia A and Masson, MEJ},
  journal={Eye-lab Technical Report Carnegie-Mellon University, Pittsburgh},
  year={1982}
}

@article{rayner1996freq,
  title={Eye movement control in reading and visual search: Effects of word frequency},
  author={Rayner, Keith and Raney, Gary E},
  journal={Psychonomic Bulletin \& Review},
  volume={3},
  number={2},
  pages={245--248},
  year={1996},
  publisher={Springer}
}

@article{kaakinen2002perspective,
  title={Perspective effects on online text processing},
  author={Kaakinen, Johanna K and Hy{\"o}n{\"a}, Jukka and Keenan, Janice M},
  journal={Discourse processes},
  volume={33},
  number={2},
  pages={159--173},
  year={2002},
  publisher={Taylor \& Francis}
}

@article{radach2008topdown,
  title={The role of global top-down factors in local eye-movement control in reading},
  author={Radach, Ralph and Huestegge, Lynn and Reilly, Ronan},
  journal={Psychological research},
  volume={72},
  number={6},
  pages={675--688},
  year={2008},
  publisher={Springer}
}

@article{schotter2014task,
  title={Task effects reveal cognitive flexibility responding to frequency and predictability: Evidence from eye movements in reading and proofreading},
  author={Schotter, Elizabeth R and Bicknell, Klinton and Howard, Ian and Levy, Roger and Rayner, Keith},
  journal={Cognition},
  volume={131},
  number={1},
  pages={1--27},
  year={2014},
  publisher={Elsevier}
}

@article{rothkopf1979goal,
  title={Goal-guided learning from text: inferring a descriptive processing model from inspection times and eye movements.},
  author={Rothkopf, Ernst Z and Billington, MJ},
  journal={Journal of educational psychology},
  volume={71},
  number={3},
  pages={310},
  year={1979},
  publisher={American Psychological Association}
}

@article{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{radach2004theoretical,
  title={Theoretical perspectives on eye movements in reading: Past controversies, current issues, and an agenda for future research},
  author={Radach, Ralph and Kennedy, Alan},
  journal={European journal of cognitive psychology},
  volume={16},
  number={1-2},
  pages={3--26},
  year={2004},
  publisher={Taylor \& Francis}
}

@inproceedings{tokunaga-2017-eye,
    title = "An Eye-tracking Study of Named Entity Annotation",
    author = "Tokunaga, Takenobu  and
      Nishikawa, Hitoshi  and
      Iwakura, Tomoya",
    booktitle = "Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",
    month = sep,
    year = "2017",
    address = "Varna, Bulgaria",
    publisher = "INCOMA Ltd.",
    url = "https://doi.org/10.26615/978-954-452-049-6_097",
    doi = "10.26615/978-954-452-049-6_097",
    pages = "758--764",
}

@inproceedings{tomanek-2010-cognitive,
    title = "A Cognitive Cost Model of Annotations Based on Eye-Tracking Data",
    author = {Tomanek, Katrin  and
      Hahn, Udo  and
      Lohmann, Steffen  and
      Ziegler, J{\"u}rgen},
    booktitle = "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2010",
    address = "Uppsala, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P10-1118",
    pages = "1158--1167",
}

@article{wood2015generalized,
  title={Generalized additive models for large data sets},
  author={Wood, Simon N and Goude, Yannig and Shaw, Simon},
  journal={Journal of the Royal Statistical Society: Series C: Applied Statistics},
  pages={139--155},
  year={2015},
  publisher={JSTOR}
}

@article{wood2004,
    title = {Stable and efficient multiple smoothing parameter
  estimation for generalized additive models},
    journal = {Journal of the American Statistical Association},
    volume = {99},
    number = {467},
    pages = {673-686},
    year = {2004},
    author = {S. N. Wood},
}

@article{levy2008expectation,
  title={Expectation-based syntactic comprehension},
  author={Levy, Roger},
  journal={Cognition},
  volume={106},
  number={3},
  pages={1126--1177},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{hale2001probabilistic,
  title={A probabilistic Earley parser as a psycholinguistic model},
  author={Hale, John},
  booktitle={Second meeting of the north american chapter of the association for computational linguistics},
  year={2001}
}


@article{engbert2005swift,
  title={{SWIFT}: a dynamical model of saccade generation during reading.},
  author={Engbert, Ralf and Nuthmann, Antje and Richter, Eike M and Kliegl, Reinhold},
  journal={Psychological review},
  volume={112},
  number={4},
  pages={777},
  year={2005},
  publisher={American Psychological Association}
}


@article{hyona1990repeated,
  title={Eye movements during repeated reading of a text},
  author={Hy{\"o}n{\"a}, Jukka and Niemi, Pekka},
  journal={Acta psychologica},
  volume={73},
  number={3},
  pages={259--280},
  year={1990},
  publisher={Elsevier}
}

@article{kaakinen2007perspective,
  title={Perspective effects in repeated reading: An eye movement study},
  author={Kaakinen, Johanna K and Hy{\"o}n{\"a}, Jukka},
  journal={Memory \& cognition},
  volume={35},
  pages={1323--1336},
  year={2007},
  publisher={Springer}
}

@article{hyona1995topic,
  title={An eye movement analysis of topic-shift effect during repeated reading.},
  author={Hy{\"o}n{\"a}, Jukka},
  journal={Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume={21},
  number={5},
  pages={1365},
  year={1995},
  publisher={American Psychological Association}
}

@article{foster2013repeated,
  title={Underlying changes in repeated reading: An eye movement study},
  author={Foster, Tori E and Ardoin, Scott P and Binder, Katherine S},
  journal={School Psychology Review},
  volume={42},
  number={2},
  pages={140--156},
  year={2013},
  publisher={Taylor \& Francis}
}

@article{raney1995freq,
  title={Word frequency effects and eye movements during two readings of a text.},
  author={Raney, Gary E and Rayner, Keith},
  journal={Canadian Journal of Experimental Psychology/Revue canadienne de psychologie exp{\'e}rimentale},
  volume={49},
  number={2},
  pages={151},
  year={1995},
  publisher={Canadian Psychological Association}
}

@article{zawoyski2015repeated,
  title={Using eye tracking to observe differential effects of repeated readings for second-grade students as a function of achievement level},
  author={Zawoyski, Andrea M and Ardoin, Scott P and Binder, Katherine S},
  journal={Reading Research Quarterly},
  volume={50},
  number={2},
  pages={171--184},
  year={2015},
  publisher={Wiley Online Library}
}

@article{schnitzer2006,
  title={Eye movements during multiple readings of the same text},
  author={Schnitzer, Brian S and Kowler, Eileen},
  journal={Vision research},
  volume={46},
  number={10},
  pages={1611--1632},
  year={2006},
  publisher={Elsevier}
}

@article{meyer1999,
  title={Repeated reading to enhance fluency: Old approaches and new directions},
  author={Meyer, Marianne S and Felton, Rebecca H},
  journal={Annals of dyslexia},
  volume={49},
  pages={283--306},
  year={1999},
  publisher={Springer}
}

@article{kuhn2004,
  title={Helping students become accurate, expressive readers: Fluency instruction for small groups},
  author={Kuhn, Melanie},
  journal={The Reading Teacher},
  volume={58},
  number={4},
  pages={338--344},
  year={2004},
  publisher={Wiley Online Library}
}

@article{ardoin2008,
  title={Promoting generalization of reading: A comparison of two fluency-based interventions for improving general education student’s oral reading rate},
  author={Ardoin, Scott P and Eckert, Tanya L and Cole, Carolyn AS},
  journal={Journal of Behavioral Education},
  volume={17},
  pages={237--252},
  year={2008},
  publisher={Springer}
}

@article{teigen2001,
  title={Combining repeated readings and error correction to improve reading fluency},
  author={Teigen, Tana and Malanga, Paul R and Sweeney, William J},
  journal={Journal of Precision Teaching and Celeration},
  volume={17},
  number={2},
  pages={58--67},
  year={2001}
}

@article{faulkner1999,
  title={Fluent and nonfluent forms of transfer in reading: Words and their message},
  author={Faulkner, Heather J and Levy, Betty Ann},
  journal={Psychonomic Bulletin \& Review},
  volume={6},
  pages={111--116},
  year={1999},
  publisher={Springer}
}

@inproceedings{shubi2023,
  title={Eye Movements in Information-Seeking Reading},
  author={Shubi, Omer and Berzak, Yevgeni},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={45},
  year={2023}
}

@article{clifton2016eye,
  title={Eye movements in reading and information processing: Keith Rayner’s 40 year legacy},
  author={Clifton Jr, Charles and Ferreira, Fernanda and Henderson, John M and Inhoff, Albrecht W and Liversedge, Simon P and Reichle, Erik D and Schotter, Elizabeth R},
  journal={Journal of Memory and Language},
  volume={86},
  pages={1--19},
  year={2016},
  publisher={Elsevier}
}

@inproceedings{meiri2024deja,
  title={D{\'e}j{\`a} Vu: Eye Movements in Repeated Reading},
  author={Meiri, Yoav and Berzak, Yevgeni},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={46},
  year={2024}
}

@inproceedings{brodersen2010balanced,
  title={The balanced accuracy and its posterior distribution},
  author={Brodersen, Kay Henning and Ong, Cheng Soon and Stephan, Klaas Enno and Buhmann, Joachim M},
  booktitle={2010 20th international conference on pattern recognition},
  pages={3121--3124},
  year={2010},
  organization={IEEE}
}

@article{meziere2023using,
  author = {Mézière, Diane C. and Lili Yu and Reichle, Erik D. and {von der Malsburg}, Titus and Genevieve McArthur},
  title = {Using eye-tracking measures to predict reading comprehension},
  journal = {Reading Research Quarterly},
  year = {2023},
  volume = {58},
  number = {3},
  pages = {425-449},
  doi = {10.1002/rrq.498},
  url = {https://ila.onlinelibrary.wiley.com/doi/abs/10.1002/rrq.498}               ,
}

@article{meziere2023scanpath,
  author = {Mézière, Diane C. and Lili Yu and Reichle, Erik D. and Genevieve McArthur and {von der Malsburg}, Titus},
  title = {Scanpath regularity as an index of reading comprehension},
  journal = {Scientific Studies of Reading},
  year = {2023},
  url = {https://psyarxiv.com/w6x4t},
}

@inproceedings{skerath2023native,
  title={Native Language Prediction from Gaze: a Reproducibility Study},
  author={Skerath, Lina and Toborek, Paulina and Zieli{\'n}ska, Anita and Barrett, Maria and Van Der Goot, Rob},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)},
  pages={152--159},
  year={2023}
}

@article{shubi2024decoding,
  title={Decoding Reading Goals from Eye Movements},
  author={Shubi, Omer and Hadar, Cfir Avraham and Berzak, Yevgeni},
  journal={arXiv preprint arXiv:2410.20779},
  year={2024}
}

@article{sood2020improving,
  title={Improving natural language processing tasks with human gaze-guided neural attention},
  author={Sood, Ekta and Tannert, Simon and M{\"u}ller, Philipp and Bulling, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6327--6341},
  year={2020}
}

@article{prasse2024improving,
  title={Improving cognitive-state analysis from eye gaze with synthetic eye-movement data},
  author={Prasse, Paul and Reich, David R and Makowski, Silvia and Scheffer, Tobias and J{\"a}ger, Lena A},
  journal={Computers \& Graphics},
  volume={119},
  pages={103901},
  year={2024},
  publisher={Elsevier}
}

@article{hollenstein2023zuco,
  title={The ZuCo benchmark on cross-subject reading task classification with EEG and eye-tracking data},
  author={Hollenstein, Nora and Tr{\"o}ndle, Marius and Plomecka, Martyna and Kiegeland, Samuel and {\"O}zyurt, Yilmazcan and J{\"a}ger, Lena A and Langer, Nicolas},
  journal={Frontiers in Psychology},
  volume={13},
  pages={1028824},
  year={2023},
  publisher={Frontiers Media SA}
}

@inproceedings{bednarik2005eye,
  title={Eye-movements as a biometric},
  author={Bednarik, Roman and Kinnunen, Tomi and Mihaila, Andrei and Fr{\"a}nti, Pasi},
  booktitle={Image Analysis: 14th Scandinavian Conference, SCIA 2005, Joensuu, Finland, June 19-22, 2005. Proceedings 14},
  pages={780--789},
  year={2005},
  organization={Springer}
}

@inproceedings{jager2020deep,
  title={Deep eyedentification: Biometric identification using micro-movements of the eye},
  author={J{\"a}ger, Lena A and Makowski, Silvia and Prasse, Paul and Liehr, Sascha and Seidler, Maximilian and Scheffer, Tobias},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2019, W{\"u}rzburg, Germany, September 16--20, 2019, Proceedings, Part II},
  pages={299--314},
  year={2020},
  organization={Springer}
}

@article{reichle_using_2013,
    title = {Using {E}-{Z} {Reader} to examine the concurrent development of eye-movement control and reading skill},
    volume = {33},
    issn = {02732297},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0273229713000129},
    doi = {10.1016/j.dr.2013.03.001},
    abstract = {Compared to skilled adult readers, children typically make more ﬁxations that are longer in duration, shorter saccades, and more regressions, thus reading more slowly (Blythe \& Joseph, 2011). Recent attempts to understand the reasons for these differences have discovered some similarities (e.g., children and adults target their saccades similarly; Joseph, Liversedge, Blythe, White, \& Rayner, 2009) and some differences (e.g., children’s ﬁxation durations are more affected by lexical variables; Blythe, Liversedge, Joseph, White, \& Rayner, 2009) that have yet to be explained. In this article, the E-Z Reader model of eye-movement control in reading (Reichle, 2011; Reichle, Pollatsek, Fisher, \& Rayner, 1998) is used to simulate various eye-movement phenomena in adults vs. children in order to evaluate hypotheses about the concurrent development of reading skill and eye-movement behavior. These simulations suggest that the primary difference between children and adults is their rate of lexical processing, and that different rates of (post-lexical) language processing may also contribute to some phenomena (e.g., children’s slower detection of semantic anomalies; Joseph et al., 2008). The theoretical implications of this hypothesis are discussed, including possible alternative accounts of these developmental changes, how reading skill and eye movements change across the entire lifespan (e.g., college-aged vs. older readers), and individual differences in reading ability.},
    language = {en},
    number = {2},
    urldate = {2024-12-09},
    journal = {Developmental Review},
    author = {Reichle, Erik D. and Liversedge, Simon P. and Drieghe, Denis and Blythe, Hazel I. and Joseph, Holly S.S.L. and White, Sarah J. and Rayner, Keith},
    month = jun,
    year = {2013},
    keywords = {notion},
    pages = {110--149},
}