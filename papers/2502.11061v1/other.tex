%This variant tests whether eye movements alone (or combined with textual features) can robustly differentiate reading “regimes” that correspond to number of exposures to the text on a single-trial basis.


%\tbd{The results of the paired variant contextualize the results of this variant. In contrast to the single-level variant, the input structure in the paired-level  allows for "in context" isolation of the rereading effect by ensuring the text and participant are the same.}
% \\

%\tbd{The proposed tasks extend the findings of works such as \cite{meiri2024deja} by moving beyond aggregated metrics to evaluate whether modern models can detect fine-grained behavioral changes in eye movements due to rereading. This enables testing models' ability to capture nuanced effects at the level of individual trials or pairs.}

%\subsection{Consecutive versus Nonconsecutive Repeated Reading}

%In this task, given a sample of eye movements during repeated reading, the goal is to predict when the first reading occurred. Specifically, the task is to distinguish between a consecutive repeated reading \((k=0)\) and nonconsecutive reading \((k>0)\).

%The \textbf{Consecutive vs. Nonconsecutive Repeated Reading} task aims to determine whether there was intervening textual material between two readings of the same text. Prior work \cite{meiri2024deja} demonstrates that the amount of textual material between readings modulates the rereading effect, albeit to a smaller degree relative to the main facilitation effect observed between the first and repeated readings. This modulation highlights the impact of intervening material, even if subtle, on reading behavior.

%\paragraph{Single Trial Variant} 
%\[
%\left(W, E^{W,2}_S\right) \rightarrow \mathbbm{1}_{k>0}
%\]

%Given a single eye movement recording  \(E_S^{W,2}\) of a repeated reading, and optionally the text \(W\), predict whether there was reading material between this reading and the first reading of the same text \(W\) by the same participant \(S\).

%\paragraph{Paired Trial Variant} 
%\[
%\left(W, E^{W,1}_S, E^{W,2}_S\right) \rightarrow %\mathbbm{1}_{k>0}
%\]
%Given two samples of eye movements \(E_S^{W,r_1} \) and \(E_S^{W,r_2}\) of the same participant \(S\) over the two readings same text \(W\), where the presentation order to the participant \textit{is known}, predict whether there was reading material between the two readings.

%Where \(\mathbbm{1}_{k>0}\) is a binary indicator denoting  whether the second reading (\(E^{W,2}_S\)) corresponds to a nonconsecutive (with intervening material) or a consecutive repeated reading. 


%This variant is a restriction of the paired variant, where the magnitude of the facilitation effect cannot be estimated relative to the first reading, as it is not provided in the input.\\

%\tbd{Summarizing sentence about the coverage of both tasks in both variants (the two main task vary in granularity and the single and paired variants of each tasks as well)}

% In total, there are 9720 (1944) first (repeated) reading trials for each one of the reading regimes (information seeking, ordinary reading).
% in each reading regime, OneStop consists of 1,944 samples, half are consecutive rereading (article position 11) and half are nonconsecutive rereading (article position 12).

% \begin{itemize}
%  \item \textbf{First vs second reading}. Given $Trial^{W,p}_S$, predict whether it is the first or second reading $\left(p\right)$.  Formally, 
% $$Trial^{W,p}_S \rightarrow {p \in \{1, 2\}}$$
%  \item \textbf{Consecutive vs nonconsecutive rereading}. Given $Trial^{W,p}_S$, only where $p=2$, predict whether there was reading material between the two readings. Here,  
%  \begin{align*}
%  Trial^{W,2}_S \rightarrow \{\textbf{Consecutive}, \\ \textbf{Nonconsecutive}\}
%  \end{align*}
% \end{itemize}


% given a participant $S$ reading a paragraph $W$ for the $p$'th time $\left(p \in \{1,2\} \right)$, the participant's eye movements over the paragraph are $Eyes^{W,p}_S$. The complete trial information is:
% $$Trial^{W,p}_S \coloneq \{W,Eyes^{W,p}_S\}$$
% We make $W$ optional to allow models not to use the text.

% \subsection{Paired Trials Decoding Tasks}
% In these tasks, a paired sample of the participant's eye movements of both the first and the repeated reading of the same textual material is given as input.
% $$\left(Trial^{W,1}_S,Trial^{W,2}_S\right)$$
% \begin{itemize}
%  \item \textbf{Paired first vs second reading}. Predict which trial is the first reading and which is the repeated reading. $i\neq j\in\{1,2\}:$
%  \begin{align*}
%  \left(Trial^{W,i}_S,Trial^{W,j}_S\right) \rightarrow \{\left(i,j\right)\}
%  \end{align*}
%  \item \textbf{Consecutive vs nonconsecutive rereading}. Predict whether there was reading material between the two readings.
%  \begin{align*}
%  \left(Trial^{W,1}_S,Trial^{W,2}_S\right) \rightarrow \{Consecutive, \\ Nonconsecutive\}
%  \end{align*}
% \end{itemize}


%%%%%%%%%%%


     % \item \textbf{Fixation Transition Distances (FTD)} the asymmetry in Euclidean distances between consecutive fixations and how these distances change over time. Skewness highlights distributional imbalances and biases, revealing whether reading behavior is dominated by short or long saccades, while gradient skewness uncovers critical temporal shifts in fixation transitions.. The full details are in \ref{app:fixation_seq_skewness}.
 % \item \textbf{Syntactic Clusters (SC)} based on \cite{berzak_predicting_2017}, mean First Fixation, Gaze Duration, Total Fixation, skip rate and regression rate for words clustered by universal part of speech tags and labels of the syntactic relation of the word to its head word in a dependency tree using universal dependencies. With \tbd{??} universal part of speech tags and \tbd{??} syntactic relations, this corresponds to \tbd{??} features.

%%%%%%%%%%%



 % \begin{itemize}
 % % \item \textbf{BEyeLSTM} averages eye movement measures for the entire trial and further represents each fixation with three features: its duration, POS, and a content word indicator. Each feature is processed through a separate LSTM, and the final hidden states of the three LSTMs, combined with global eye movement features, are used for classification. We augment the original feature set of this model with a richer feature-set which consists of the features in Section \ref{sec:feature_based_methods}.
 
 % \item 
 
 % \end{itemize}



 %%%%%%%%%%%%%

 %\subsection{Paired Scanpath Modeling}
%In this work we address the problem of paired scanpath representation from two different angles. First, as presented earlier, we tackle the paired trials decoding task in which we consider a pair of scanpaths over the same text in the two readings, and predict the presence or absence of intervening material between them. Second, we propose a reformulation of the single trial classification task through a paired setting where we generate an additional eye movement trajectory which serves as a reference for a first reading from a computational model. In the paired trial decoding task, we hypothesize that differences in reading behavior between first and repeated presentations of the same text can provide critical information for distinguishing between pairs with a varying amounts of intervening material. Conceptually, the first reading serves as a reference point, enabling us to extract a \textbf{"behavioral $\Delta$"} that captures the changes between the two reading. This "behavioral $\Delta$" is then leveraged to predict the "ground truth $\Delta$," representing the amount of intervening material.

%\begin{figure*}[ht]
%    \centering
%    \includegraphics[width=0.3\linewidth]{example-image-a}
%    \caption{Paired Scanpath Modeling}
%    \label{fig:paired-modeling}
%\end{figure*}

%We extend this concept to the single trial setting by introducing a synthesized reference point for each trial. Whether the trial corresponds to a first or repeated reading, we generate synthetic eye movement data at both the fixation and the word level. These synthesized representations act as a reference against which the unknown trial can be classified.
%Now, after we have obtained trial pairs corresponding to the same textual material, we use the following methods to classify them:
%\begin{itemize}
% \item \textbf{Reduction}. Given eye movement representations pair over the same  text, \tbd{If word level representation, we can create a single trial which is the (relative?) difference between the word level features of the two trials, and use all methods constructed for a single trial (yet, only those of Omer's models that are word-representation based can be employed here}
% \item \textbf{\tbd{New model for trial pairs?}}
%\end{itemize}

%\subsection{What if the first reading is unknown?}
%Eye Movement Synthesis for Augmentation - Given a textual material $W$, we use the E-Z Reader model \tbdref, configured with default parameters. \tbd{SWIFT? Eyettention?}




%%%%%%%%%%%%%%%%


% \begin{itemize}
%     \item Paired task: In the paired FR vs. RR task, even though the model predicts the index of the RR trial, we needed to adjust the interpretation of its outputs to ensure that the evaluation metrics (F1, Accuracy, etc.) remain comparable with those in the single FR vs. RR setup. Specifically, we "unaggregate" the paired setup's predictions by defining a correct RR index prediction as a correct classification at the single-trial level for both trials in the pair. Conversely, an incorrect RR index prediction is considered an incorrect classification for both trials. Importantly, in this setting, partial correctness—where only one of the two trials is classified correctly—is not allowed.
%     \item  Paired task: all models show strong performance, where the only model which consistently outperforms all others is the feature based XGBoost model
%     \item Paired task: comparable performance between the different evaluation regimes
%     \item Paired task: Recall and Accuracy are comparable across all models and evaluation regimes
%     \item Single task: Both accuracy and recall for all models are much lower than those observed in the paired task. Bear in mind that the paired task is relxed both in the explicit pairing of trials with the same participant and paragraph.
%     \item Single task: Here, all non-reading speed only models outperform the reading speed baseline, where unlike the paired task, here we don't observe a model which strictly dominates the others.
%     \item Single task: within each model variant results are comparable between the different evaluation regimes.
%     \item Single task: unlike the paired task, here we see a consistent gap between accuracy and recall, which indicates that the general direction of errors is leaned towards classifying repeatead reading trials as first reading trials. We hypothesize that this trend can be attributed by the varying magnitude of the facilitation effect of repeatead reading observed in humans. \tbd{Later, we extend this hypothesis by analyzing errors rates between different participants}.
%     \item Single task: As for the synthetic scanpath augmentation, we don't observe consistent improvement after augmenting the inputs for any of the models / evaluation regimes. 
%     \item \tbd{Single task: Not only that we don't get consistent improvements by using the synthetic "reference trials" for any of the models, we see that the gap between recall and accuracy is maintained.}
% \end{itemize}


%Models are compared using a linear mixed model to account for dependencies between trials\footnote{The term  $(model \mid fold\_index)$ was omitted as the random effect showed near 0 variance \label{model-comparison-eq}.}


%\subsection{Number of articles between readings} a more fine-grained variant of task 2(a), where instead of binary classification, the goal is to predict how many articles appeared between the first and the second reading of the paragraph. \tbd{TWO POSSIBILITIES: only 12, both 11 and 12}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{Fixation Transition Distances}
% \label{app:fixation_seq_skewness}
% \begin{itemize}
%  \item \textbf{Fixation Transition Skewness (\( \text{Skewness of } \mathbf{\Delta xy} \))}:  
%    Given the sequence of fixation coordinates \((x_i, y_i)\), \textit{ordered by the order of words} to which the fixation correspond, we compute the L2 distances (Euclidean distances) between consecutive fixations:  
%    \[
%    \Delta xy_i = \| (x_i, y_i) - (x_{i-1}, y_{i-1}) \| \text{for } i = 2, \dots, n.
%    \]  
%    To reduce noise, we discard extreme values above the 99th percentile. The skewness of the resulting distribution is then computed using the \texttt{SciPy} \cite{2020SciPy-NMeth} library which implements the sample Fisher-Pearson coefficient of skewness.

%    \item \textbf{Fixation Transition Gradient Skewness (\( \text{Skewness of } \nabla \mathbf{\Delta xy} \))}:  
%    To capture changes in fixation transitions over time, we compute the gradient of the L2 distances \(\Delta xy\):  
%    \[
%    \nabla \Delta xy_i = \Delta xy_{i+1} - \Delta xy_{i}.
%    \]  
%    The skewness of this gradient distribution is then calculated to measure asymmetry in the rate of change of fixation transitions, again with \texttt{SciPy}.

% \end{itemize}

% These skewness-based features quantify the asymmetry and variability in fixation behavior, providing fine-grained insights into spatial irregularities during reading.


