\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

%\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{amsthm}
%\usepackage{subfigure}
%\usepackage{blkarray}
%\usepackage{threeparttable}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{colortbl}
\usepackage{array}
\usepackage{diagbox}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{fbox}
\usepackage{bm}
\usepackage{bbm}
%\usepackage{algpseudocode}
%\usepackage{algorithm}
%\usepackage{algorithmicx}
\usepackage{caption,subcaption}
\usepackage{enumerate}
\usepackage{wrapfig, lipsum}
\usepackage{adjustbox}
\usepackage{overpic}
\usepackage{dashrule}
% \usepackage{arydshln}

%\usepackage{floatrow}
% \floatsetup[table]{capposition=top}
% \newfloatcommand{capbtabbox}{table}[][\FBwidth]


\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=cvprblue]{hyperref}

\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\newcommand{\todo}[1]{{\color{red}{\bf [#1]}}}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
%\newtheorem*{proof}{Proof}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newcommand{\ie}{{\textit{i.e.}}}
\newcommand{\etal}{{\textit{et al.}}}
\newcommand{\eg}{{\textit{e.g.}}}

\title{Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural Deformation Correntropy}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.
\author{Mingyang Zhao$^{1}$, Gaofeng Meng$^{1,2,3,*}$ \& Dong-Ming Yan$^{2,3}$ \thanks{Corresponding authors.} \\
1. CAIR, Hong Kong Institute of Science \& Innovation, Chinese Academy of Sciences\\
2. MAIS, Institute of Automation, Chinese Academy of Sciences\\
3. University of Chinese Academy of Sciences\\
\hspace{90pt}{\url{https://github.com/zikai1/OAReg}}
}


\iffalse
\author{Antiquus S.~Hippocampus, Natalia Cerebro \& Amelie P. Amygdale \thanks{ Use footnote for providing further information
about author (webpage, alternative address)---\emph{not} for acknowledging
funding agencies.  Funding acknowledgements go at the end of the paper.} \\
Department of Computer Science\\
Cranberry-Lemon University\\
Pittsburgh, PA 15213, USA \\
\texttt{\{hippo,brain,jen\}@cs.cranberry-lemon.edu} \\
\And
Ji Q. Ren \& Yevgeny LeNet \\
Department of Computational Neuroscience \\
University of the Witwatersrand \\
Joburg, South Africa \\
\texttt{\{robot,net\}@wits.ac.za} \\
\AND
Coauthor \\
Affiliation \\
Address \\
\texttt{email}
}
\fi
% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Non-rigid alignment of point clouds is crucial for scene understanding, reconstruction, and various computer vision and robotics tasks. Recent advancements in implicit deformation networks for non-rigid registration have significantly reduced the reliance on large amounts of annotated training data. However, existing state-of-the-art methods still face challenges in handling \emph{occlusion} scenarios. To address this issue, this paper introduces an innovative \emph{unsupervised} method called \textbf{O}cclusion-\textbf{A}ware \textbf{R}egistration (\textbf{OAR}) for non-rigidly aligning point clouds. The key innovation of our method lies in the utilization of the adaptive {correntropy function} as a localized similarity measure, enabling us to treat individual points distinctly. In contrast to previous approaches that solely minimize overall deviations between two shapes, we combine unsupervised \emph{implicit neural representations} with the \emph{maximum correntropy criterion} to optimize the deformation of unoccluded regions. This effectively avoids collapsed, tearing, and other physically implausible results. Moreover, we present a theoretical analysis and establish the relationship between the maximum correntropy criterion and the commonly used Chamfer distance, highlighting that the correntropy-induced metric can be served as a more universal measure for point cloud analysis. Additionally, we introduce \emph{locally linear reconstruction} to ensure that regions lacking correspondences between shapes still undergo physically natural deformations. Our method achieves superior or competitive performance compared to existing approaches, particularly when dealing with occluded geometries. We also demonstrate the versatility of our method in challenging tasks such as large deformations, shape interpolation, and shape completion under occlusion disturbances.  
\end{abstract}


\section{Introduction}
Non-rigid point cloud registration is a critical and challenging problem within the domains of computer vision, robotics, and medical imaging. Its objective is to optimize a deformation field that enables precise alignment between geometric shapes. Due to its fundamental importance, this problem has diverse applications, including reconstructions~\citep{slavcheva2017killingfusion,bozic2021neural,park2021nerfies}, generation~\citep{barber2007efficient,wang2008automatic}, and animations~\citep{chen2021snarf,siarohin2023unsupervised}.






Thanks to recent advancements in \emph{neural representations} for 3D modeling and rendering~\citep{park2019deepsdf,mescheder2019occupancy,sitzmann2020implicit,mildenhall2020nerf}, coordinate-based networks (\ie, utilizing 3D spatial positions as inputs) have made significant progress in fully automated non-rigid point cloud registration~\citep{li2021neural,li2022non,10377509}. Despite their impressive results on benchmark tests, the systematic exploration of coordinate-based networks for non-rigid point cloud registration involving \emph{occlusion geometries} is comparatively limited and presents substantial challenges. Actually, the occlusion regime is quite relevant for practical applications. For instance, in \emph{Computer-Assisted Surgery} (CAS) scenarios, accurate registration of \emph{complete} pre-operative CT or MRI models with \emph{occluded} intra-operative scan data is crucial for surgical navigation, as the camera attached to the surgical instrument only provides a limited view of the abdomen during laparoscopic surgeries~\citep{robu2018global}. It is surprising that current state-of-the-art algorithms struggle when dealing with scenarios where the source shape is complete and the target shape is occluded (see \cref{fig:teaser}).
 

\begin{figure*}
    \centering
    \includegraphics[width=0.95\linewidth]{fig/teaser_liver.png}
\caption{{Non-rigid registration of point clouds under occlusion disturbances.} The pre-operative liver (complete) and the intra-operative liver (occluded) serve as the source and target models, respectively. While competing approaches produce physically implausible results like collapses and tearing, our method achieves successful registrations (top) while faithfully preserving the physical structure (bottom) such as the blood vessel present in the source liver.}
\label{fig:teaser}
\vskip -0.6cm
\end{figure*}




We analyze and argue that the unsatisfactory results can be attributed to the choice of the distance metric between two shapes. Previous approaches typically use the standard \emph{Chamfer Distance} (CD)~\citep{fan2017point} as the similarity evaluation protocol~\citep{li2021neural,li2022non,10377509}, which directly finds the nearest point in the other point cloud and minimizes \emph{holistic} deviations between shapes. While this is effective for registering two complete shapes, it can lead to \emph{collapsed} or \emph{physically implausible} results when dealing with a complete source shape and an occluded target geometry, as shown in~\cref{fig:teaser}. 

To address the above issues, we present a novel and unsupervised non-rigid registration method for point clouds under occlusion. A key aspect of our method is that, instead of blindly optimizing the overall non-linear transformation, we introduce the use of the \emph{Maximum Correntropy Criterion} (MCC) from statistical and information-theoretic learning~\citep{erdogmus2002error} to effectively handle occlusion. Correntropy serves as an \emph{adaptive} and \emph{local} similarity measure, allowing for differential treatment of individual points within the neural representations. Consequently, occluded points will make smaller contributions to the correntropy, enabling more precise and distinguished handling of occlusion. As demonstrated in subsequent experiments, this correntropy-induced metric effectively prevents collapses, tearing, and other physically implausible outcomes, in contrast to the commonly used CD metric. 


Moreover, ensuring the physical plausibility of the deformation field for regions of the source geometry that lack correspondence in the target shape presents another significant challenge. This problem is considerably more complex than its rigid counterpart~\citep{zhao2023accurate}, as it is inherently ill-posed and under-constrained. In non-rigid registration, there are numerous potential deformation solutions that can align with the partial deformations of the source surface. To mitigate this challenge, we draw inspiration from the concept of locally linear embedding in manifold learning~\citep{roweis2000nonlinear} and develop a robust geometric prior termed \emph{Locally Linear Reconstruction} (LLR). The LLR approach formulates the problem as a \emph{constrained non-linear least-squares optimization}, incorporating deformation regularity by linearly reconstructing the unknown out-of-part deformations using information from neighboring regions. As a result, LLR significantly enhances the naturalness of the deformation field and preserves higher-quality geometric details compared to previous approaches.


We conduct extensive experiments to demonstrate the superiority and competitiveness of the proposed method to baselines, including both traditional optimization-based and neural network-based approaches. This superiority is particularly pronounced in scenarios involving occlusion. Additionally, our method provides continuous deformation representations, enabling downstream applications in shape interpolation and shape completion. To summarize, the main technical contributions of this work are threefold as follows:
\begin{itemize}
    \item We analyze the reasons why previous approaches fail to handle occlusion scenarios in non-rigid registration and introduce a novel unsupervised deformation framework to address this challenging problem.
    \item We pioneer the combination of maximum correntropy criterion with implicit neural representations to ensure physically plausible deformations and reveal its relationship to Chamfer distance.
   \item  We formulate the deformation of regions lacking correspondence as a local linear reconstruction problem. This formulation can be solved through non-linear least-squares optimization and yields a closed-form solution. 
   
\end{itemize}
    





\section{Related Work}
We review the work that is closely related to ours. Readers are referred to~\citep{tam2012registration,deng2022survey} for more comprehensive studies.


\paragraph{Non-rigid point cloud registration.} In contrast to shape matching, which aims to establish correct correspondences, non-rigid point cloud registration focuses on optimizing the deformation field. Amberg \etal~\citep{amberg2007optimal} extended the rigid \emph{Iterative Closest Point} (ICP) algorithm~\citep{besl1992method} to non-rigid registration (NICP) by introducing stiffness parameters to control the deformation. \emph{Coherent Point Drift} (CPD) represented point clouds using Gaussian mixture models (GMMs) and formulated the registration problem as a probabilistic density estimation process, while~\citep{jian2010robust} directly minimized the Euclidean distance between two GMMs for registration. More recently, Hirose~\citep{hirose2020bayesian,hirose2022geodesic} reformulated CPD in a Bayesian setting, improving CPD in scalability and robustness. \cite{zhao2024correspondence} leveraged unsupervised clustering analysis to deal with non-rigid registration under large deformations. To enhance efficiency, deformation graph-based approaches~\citep{sumner2007embedded,bozic2021neural,zhao2022graphreg,qin2023deep} represent shapes using sparsely sub-sampled node graphs, where deformation is associated with each graph node and applied to nearby geometry. 


With the advent of deep learning, neural network-based approaches have also been developed for non-rigid point cloud registration. 
However, many of these methods rely on neural networks to extract features for point correspondences and subsequently employ classical registration methods like NICP for deformation optimization. For instance,   SyNoRiM~\citep{huang2022multiway} employed 3D CNN networks to learn non-orthogonal functional bases for shape matching without relying on the Laplace-Beltrami operators~\citep{ovsjanikov2012functional}. Lepard~\citep{li2022lepard} disentangled point cloud representations into feature and position spaces and developed a Transformer-based method for point-wise matching. DFR~\citep{sun2024non} conducted registration by aligning the source mesh towards a target point cloud using correspondences induced by deep functional maps~\citep{litany2017deep}. \cite{cao2023self} presented a self-supervised network for multimodal shape matching. While it shows promising performance, it does not address the deformations of occluded parts. \cite{sundararaman2022implicit} utilized an auto-decoder structure to implicitly align two volumes, which requires surface normals for training. Additionally, it employs a bi-directional Chamfer Distance for inferences, a metric that may be susceptible to occlusion. Unlike these approaches that primarily focus on shape matching and heavily depend on data annotations, our method is unsupervised, enabling us to achieve faithful registration that is more generalizable to unknown categories. 






\paragraph{Neural deformation representation.}  The representation of deformation fields is a core aspect in non-rigid point cloud registration. Traditional methods often rely on manually defined deformation functions, such as the thin-plate spline~\citep{bookstein1989principal} and the radial basis function~\citep{yuille1989mathematical}. However, the emergence of implicit neural representations has introduced a new paradigm to describe deformations. Specifically, the coordinate-based \emph{Multi-Layer Perception} (MLP) architecture utilizes an MLP to map the input coordinates to deformation fields, avoiding the need for explicit deformation definitions. For instance, NSFP~\citep{li2021neural} developed a coordinate-based MLP that implicitly regularized non-rigid deformations in scene flow estimation. This method directly minimizes the Chamfer distance at runtime without relying on extensive labeled data to capture prior statistics. Building upon NSFP, NDP~\citep{li2022non} extended the approach to a hierarchical motion decomposition using a pyramid structure. This enables controlling of the coarse-to-fine motion (from rigid to non-rigid) across low to high-frequency signals. More recently, DPF~\citep{10377509} introduced a method for modeling non-rigid surfaces also based on the Chamfer distance, where the deformation field was further regularized by the well-established as-isometric-as-possible (AIAP)~\citep{kilian2007geometric} constraint. %also characterized by an implicit neural representation. 
We also utilize a coordinate-based MLP to represent the continuous deformation field, which allows us to model and parameterize the deformations in an unsupervised and flexible manner. However, unlike previous approaches that often face challenges in occlusion scenarios, we thoroughly analyze and address these issues, leading to higher-quality non-rigid point cloud registration results.



\section{Preliminaries}  



\begin{definition}[\cite{santamaria2006generalized,liu2007correntropy}]
(Cross) correntropy $V$ is a generalized local similarity measure between two arbitrary scalar random variables $X$ and $Y$ defined as
\begin{equation}
V({X}, {Y})=\mathbb{E}_{XY}[k({X},{Y})]=\iint_{x,y}  k(x, y) p_{X Y}(x, y) d x d y,
\end{equation}which is symmetric, positive, and bounded. Here $k(\cdot, \cdot)$ is a kernel function that satisfies the Mercer theorem~\citep{vapnik2013nature},  $\mathbb{E}$ denotes the expectation operator, and $p_{XY}$ is the joint probability density function over the space $(X, Y)$.
\end{definition}
In this work, we adopt the translation invariant Gaussian kernel $k_{\sigma}=\exp(-\frac{x^2}{2\sigma^2})$
to define the correntropy. This choice is motivated by the symmetric and positive definite nature of the Gaussian kernel, as well as its property of approaching zero as points move away from the center. Moreover, the kernel bandwidth $\sigma$ allows flexible control over the decaying factor and enables accurate registrations in the presence of various occlusion. We empirically investigate the influences of $\sigma$ on deformations in \cref{sec:k}. 
\begin{definition}[\cite{liu2007correntropy}]
 Given the finite number of data points in the sample space, the correntropy-induced similarity metric (\ie, distance function) $\mathcal{M}$ between two vectors $\bm{x}=(x_1, x_2, \cdots, x_n)\in\mathbb{R}^n$ and $\bm{y}=(y_1, y_2, \cdots, y_n)\in\mathbb{R}^n$ is defined as
\begin{equation}
\mathcal{M}(\bm{x}, \bm{y})=(k_{\sigma}({0})-\frac{1}{n}\sum_{j=1}^{n}k_{\sigma}(x_j-y_j))^{\frac{1}{2}}.
\label{eq:MCC}
\end{equation} 
\end{definition} In the machine learning community, for general optimization problems involving the unknown variable $\mathbf{\Theta}$, minimizing $\mathcal{M}(\bm{x}, \bm{y})$ is equivalent to maximizing the correntropy. 


\begin{lemma}\label{lemma:1}[\cite{liu2007correntropy}]
$\mathcal{M}(\bm{x}, \bm{y})$ is equivalent to the $\ell_2$ metric if $\bm{x}, \bm{y}$ are close,
behaves similarly to the $\ell_1$ metric as $\bm{x}, \bm{y}$ get 
apart and approaches the $\ell_0$ when they are far
 apart.     
\end{lemma} Therefore, \cref{eq:MCC} can be utilized as a novel cost function for \emph{adaptive training}, referred to as the \emph{Maximum Correntropy Criterion} (MCC). The pioneering
work~\citep{he2010maximum} utilizes MCC for face recognition. We explore the combination of unsupervised implicit neural representations and the MCC-induced local metric to address occlusion geometries in non-rigid point cloud registration. We also demonstrate the superior performance of our method over previous competing approaches.





\section{Proposed Method}
\paragraph{Problem formulation.} Let $\mathbf{X}=\{\bm{x}_i\in\mathbb{R}^3\}_{i=1}^M$ and $\mathbf{Y}=\{\bm{y}_j\in\mathbb{R}^3\}_{j=1}^N$ denote two input point clouds, where $\mathbf{X}$ represents the target shape, possibly with occlusion, and $\mathbf{Y}$ is the source shape. Our objective is to solve the optimal non-linear map $\mathcal{T}_{\mathbf{\Theta}}$ parameterized by $\mathbf{\Theta}$ to minimize the shape deviation between the transformed source shape $\mathcal{T}_{\mathbf{\Theta}}(\mathbf{Y})$ and $\mathbf{X}$. Note that we also aim to preserve the physical plausibility of the deformation $\mathcal{T}_{\mathbf{\Theta}}$ regarding $\mathbf{Y}$, ensuring that issues encountered in previous approaches, such as collapsing or tearing of the geometric shape, are avoided.



 \subsection{Neural Deformation Correntropy}
 \paragraph{Motivation.} Unlike previous approaches that directly minimize the \emph{overall} difference between two shapes, we leverage the advantage of \emph{local similarity} induced by correntropy. This allows us to adaptively differentiate between various parts of a shape, ensuring that occluded regions have minimal influence on the deformation process.
 

\paragraph{Correntropy-induced metric.} We utilize the unsupervised neural presentations defined by a set of network parameters $\mathbf{\Theta}$ to implicitly parameterize the non-linear map $\mathcal{T}$. Based on MCC, our goal is to optimize the subsequent metric between $\mathbf{X}=\{\bm{x}_i\in\mathbb{R}^3\}_{i=1}^M$ and $\mathbf{Y}=\{\bm{y}_j\in\mathbb{R}^3\}_{j=1}^N$:
\begin{equation}
\begin{aligned}
\min_{\mathbf{\Theta}} \mathcal{L}({\mathbf{\Theta}})=\mathbb{E}(\mathcal{M}(\bm{x}_i,\tilde{\bm{y}}_i))+
\mathbb{E}(\mathcal{M}(\mathcal{T}_{\mathbf{\Theta}}({\bm{y}}_j),\tilde{\bm{x}}_j))
\end{aligned},
\label{eq:NDC}
\end{equation}where $\tilde{\bm{y}}_i=\min_{\bm{y}_j\in\mathcal{T}(\mathbf{Y})}\|\bm{x}_i-\mathcal{T}_{\mathbf{\Theta}}(\bm{y}_j)\|_2$,  $\tilde{\bm{x}}_j=\min_{\bm{x}_i\in\mathbf{X}}\|\mathcal{T}_{\mathbf{\Theta}}(\bm{y}_j)-\bm{x}_i\|_2$.  As a result, \cref{eq:NDC} assigns adaptive importance during network training, \ie, giving significant importance to points with corresponding parts, while penalizing deformations in occluded regions. As demonstrated in subsequent experiments, our method effectively avoids physically implausible limitations, leading to more accurate and reasonable deformations. 


\paragraph{Relationship to Chamfer distance.} We further analyze the relationship between the maximum correntropy criterion and the Chamfer distance. Unlike CD that 
performs a holistic evaluation, MCC is a \emph{local and adaptive} similarity metric. Based on \cref{lemma:1}, we can draw the following conclusion.



\begin{proposition}\label{proposition}
The Chamfer distance is a special case of \cref{eq:NDC}, applicable only when both the source and target point clouds $\mathbf{X}$ and $\mathbf{Y}$ are complete and sufficiently close to each other. However, this equivalence does not hold when either of the inputs $\mathbf{X}$ and $\mathbf{Y}$ is occluded.



\end{proposition}
Therefore, the correntropy-induced metric can serve as a more universal measure, potentially applicable to a wider range of point cloud analysis tasks.



\subsection{Locally Linear Reconstruction} Neural deformation correntropy ensures physically plausible deformations for unoccluded parts through a local measure. However, addressing the challenge of making reasonable deformation of parts in the source shape that lack correspondence in the target shape remains highly ill-posed. To tackle this, we propose incorporating a geometric prior by modeling the deformation field of occluded parts through \emph{Locally Linear Reconstruction} (LLR), which transforms the unconstrained problem into a \emph{constrained non-linear optimization}. This allows us not only maintaining a {smooth} and {coherent} deformation field for unoccluded parts but  also ensuring \emph{physically plausible results} for parts that lack correspondence.



Inspired by the principle of locally linear embedding in nonlinear spectral dimensionality reduction~\citep{roweis2000nonlinear}, we develop a novel method to preserve the linear pattern of the \emph{local geometric structure} and reconstruct each point in the \emph{deformation space}, especially for points that lack correspondences, by utilizing its neighboring structure.
%regardless of having correspondence by its neighbors . 
Concretely, for each source point $\bm{y}_j\in\mathbb{R}^3$ in $\mathbf{Y}$, we formulate the locally linear reconstruction process as the subsequent optimization problem:
%the optimization of the locally linear reconstruction is mathematically formulated as
\begin{equation}
\min_{\bm{w}_j} \mathcal{L}(\bm{w}_j)=\frac{1}{2}\left\|\bm{y}_j-\mathbf{Z}_{j}\bm{w}_j\right\|_{2}^{2}=\frac{1}{2}\bm{w}_j^{\top}\mathbf{G}_{j}\bm{w}_j, \\
\text { s.t. }  \bm{w}_j^{\top} \bm{1}_{k}=1, 
\label{eq:LLD}
\end{equation}where $\bm{w}_j=[w_{j1}, w_{j2}, \cdots, w_{jk}]^{T}\in\mathbb{R}^{k}$ is the set of unknown weight factors, $\mathbf{Z}_{j}=[\bm{z}_{j1}, \bm{z}_{j2}, \cdots, \bm{z}_{jk}]\in\mathbb{R}^{3\times k}$ is the $k$-nearest neighbors of $\bm{y}_j$ (the investigation of the influences of $k$ on deformations is presented in \cref{sec:k}), $\mathbf{G}_{j}=(\bm{y}_j\bm{1}^{\top}-\mathbf{Z}_j)^{\top}(\bm{y}_j\bm{1}^{\top}-\mathbf{Z}_j)\in \mathbb{R}^{k\times k}$ is the Gram matrix, $\bm{1}_{k}\in\mathbb{R}^{k}$ is the $k$-dimensional vector of all ones, and ${\top}$ represents the matrix transpose operator. 


\cref{eq:LLD} is a {constrained non-linear least-squares regression problem}, utilizing the Lagrange multiplier, we obtain the  \emph{closed-form solution} of $\bm{w}_j$ for each $\bm{y}_j$ (derivations are presented in \cref{sec:LLR_derivation})
\begin{equation}
\bm{w}_j=\lambda_j\mathbf{G}_j^{-1}\bm{1}_k=\frac{\mathbf{G}_j^{-1}\bm{1}_k}{\bm{1}_k^{\top}\mathbf{G}_j^{-1}\bm{1}_k}	
\label{eq:matrix_inverse}
\end{equation}with the corresponding Lagrange multiplier 
\begin{equation}
\lambda_j=\frac{1}{\bm{1}_k^{\top}\mathbf{G}_j^{-1}\bm{1}_k}.
\label{eq:lagrange}
\end{equation}
\paragraph{LLR regularization.} Once obtaining the weight vectors $\{\bm{w}_j\in\mathbb{R}^{k}\}_{j=1}^{N}$ for each $\bm{y}_j\in\mathbf{Y}$, we keep them fixed. Then, we utilize these weight vectors to \emph{regularize} the displacement field, aiming to promote its smoothness and ensure physical plausibility in the deformation space throughout the entire optimization process even without correspondences, \ie, 
\begin{equation}
\mathcal{R}({\mathbf{\Theta}})=\sum_{j=1}^N\|\mathcal{T}_{\mathbf{\Theta}}(\bm{y}_j)-\mathcal{T}_{\mathbf{\Theta}}(\mathbf{Z}_{j})^{\top}\bm{w}_j\|_2.	
\label{eq:LLR_regularize}
\end{equation} 
\paragraph{Geometric meaning of LLR.} Unlike rigid registration, where each point shares the same spatial transformation (\ie, rotation and translation), non-rigid deformation requires solving for each point's individual displacement. In challenging occlusion scenarios, \cref{eq:LLR_regularize} demonstrates that the deformation of occluded parts can be inferred from, or propagated through, the deformations of neighboring points via locally linear reconstruction. \cref{fig:LLD} presents a schematic description of the geometric meaning. 



\subsection{Unsupervised optimization} \begin{wrapfigure}{r}{0.45\textwidth}
\centering
\vspace{-0.4cm}
\includegraphics[width=\linewidth]{fig/LLD_plot.pdf}
\caption{{Geometric meaning of locally linear reconstruction}. Left: The initial source shape along with the reconstruction weight vector $\bm{w}_j$. Right: The deformed shape reconstructed using the same $\bm{w}_j$. }
\label{fig:LLD}
%\vskip -1.3cm
\end{wrapfigure}Given the active research and powerful fitting ability of implicit neural representations across various domains, we adopt a coordinate-based MLP with periodic activations~\citep{sitzmann2020implicit} as our deformation network $\mathcal{T}$.  Our objective is to optimize a set of network parameters $\mathbf{\Theta}$ to define the deformation space. Additionally, as a test-time optimization method, our method is unsupervised, requiring no data annotations. The neural network is composed of three hidden layers, each consisting of 128 neurons. We obtain the optimal neural network parameters $\mathbf{\Theta}^*$ by optimizing the following cost function with automatic differentiation:
\begin{equation}
\mathbf{\Theta}^*=\mathop{\arg\min}\limits_{\mathbf{\Theta}}\mathcal{F}(\mathbf{\Theta})=\alpha_{1}\mathcal{L}(\mathbf{\Theta})+\alpha_{2}\mathcal{R}(\mathbf{\Theta}), 
\label{eq:loss}
\end{equation}where $\alpha_{1}, \alpha_{2}\in\mathbb{R}^{+}$ are trade-off factors. Finally, the resulting deformed point cloud $\mathcal{T}_{\mathbf{\Theta}^*}(\mathbf{Y})$  is obtained by applying the learned deformation network $\mathcal{T}_{\mathbf{\Theta}^*}$ to the source model $\mathbf{Y}$.


\section{Experimental Results}\label{sec:experiment}
We conduct comprehensive experiments to validate the performance of our  method and compare it with state-of-the-art approaches in both occluded and complete settings. Additionally, we showcase the versatility of our method by applying it to \emph{shape interpolation} and \emph{shape completion} tasks.


\paragraph{Implementation details.} \label{sec:implementation}Our method is implemented using the PyTorch framework~\citep{paszke2019pytorch}, and we employ the Adam optimizer~\citep{kingma2014adam} with default settings $\beta_1 = 0.9$, $\beta_2 = 0.999$, and $\epsilon = 10^{-8}$ to optimize the objective function defined in \cref{eq:loss}. The initial learning rate is set to $lr=1e{-4}$, and the network is trained for $200$ epochs with a batch size of 1. To dynamically update the learning rate, we utilize the $\texttt{ReduceLROnPlateau}$ technique with a patience value of 1. During optimization, we fix $\alpha_1=10^4$ and $\alpha_2=10^2$, which yield appealing results across various scenarios.  All experiments are conducted on a machine equipped with an NVIDIA A30 GPU and an Intel(R) Xeon(R) Gold 6248R CPU @ 3.00GHz. We utilize publicly available implementations of baseline approaches for evaluation, with their parameters either fine-tuned by ourselves
or suggested by the authors to obtain their best results.


\paragraph{Evaluation metrics.} 
To quantitatively evaluate the results of non-rigid deformation, we adopt four metrics described in~\citep{li2022non}. 1) \emph{End-Point Error} (EPE): This metric calculates the average norm of the 3D deformation error vectors  across all points; 2) \emph{3D Accuracy Strict} (AccS): AccS measures the percentage of points whose relative error is less than $2.5\%$ or $2.5$ cm. 3) \emph{3D Accuracy Relaxed} (AccR): AccR measures the percentage of points whose relative error is less than $5\%$ or $5$ cm; 4) \emph{Outlier Ratio}: The outlier ratio calculates the percentage of points whose relative error is greater than $30\%$. Concrete definitions of these metrics are
presented in \cref{sec:data_processing}. Note that \textbf{AccS} and \textbf{AccR} are considered the most important metrics as they directly assess the ratio of accurately registered points, providing a reliable assessment of the registration quality~\citep{li2022non}.

\subsection{Comparisons} 
We first assess the proposed algorithm on occlusion scenarios using the silico liver dataset from Open-CAS~\citep{opencas}. Open-CAS is an open collection of datasets specifically designed for validating \emph{computer-assisted surgery} systems. The silico liver dataset consists of three pairs of liver models that have undergone deformation using a non-linear biomechanical model. Each pair, as illustrated in \cref{fig:teaser}, consists of a source complete liver model and a target occluded liver model, along with its corresponding ground truth complete model. These pairs represent the pre-operative and intra-operative shapes, respectively.  We adopt state-of-the-art approaches for comparison, including both traditional optimization-based methods GBCPD~\citep{hirose2022geodesic}, AMM\_NRR~\citep{yao2023fast} as well as neural network-based competitors NSFP~\citep{li2021neural}, NDP~\citep{li2022non}, and DPF~\citep{10377509}. 


The quantitative comparison results presented in \cref{tab:liver} demonstrate  that our method consistently outperforms competing approaches with higher registration accuracy across all livers, indicating its robustness and stability to align the geometric shapes under occlusion disturbances. Notably, our method achieves the highest AccS and AccR values in all tests, surpassing competitors by a significant margin. Additionally, our method delivers the lowest EPE values among all approaches and maintains a zero outlier ratio in all tests. These achievements highlight the success of our method in avoiding significant registration errors such as collapses and tearing, thereby ensuring a high level of accuracy. The qualitative comparison presented in \cref{fig:teaser} further illustrates the advantage of our method in preserving \emph{detailed physical structures} such as the blood vessel of the source liver. 
\begin{table*}[t]
%\vskip -0.3cm
\caption{Quantitative comparisons on the occluded Open-CAS liver dataset. $\uparrow$ means larger values are better while $\downarrow$ means smaller values are better. \textbf{Bond} fonts indicate the top performer.}
 \vskip -0.1cm
\renewcommand{\arraystretch}{1.5} 
\begin{adjustbox}{width=\textwidth}
\begin{tabular}
{@{}lrrrrrrrrrrrrrr@{}}
\toprule
%\hline
\multirow{2}{*}{\diagbox{Method}{Metric}} & \multicolumn{4}{c}{Liver 1} && \multicolumn{4}{c}{Liver 2} && \multicolumn{4}{c}{Liver 3} \\
\cline{2-5} \cline{7-10} \cline{12-15}
     & {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$& {Outlier} $\downarrow$&& {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$ & {Outlier} $\downarrow$ && {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$& {Outlier} $\downarrow$ \\
	\midrule
	GBCPD~\citep{hirose2022geodesic} & 11.849& 18.770&65.263&0.000 && 9.169&48.871&75.534& 0.000 && 16.240&31.770&53.162&0.000\\
	\hline
	AMM\_NRR~\citep{yao2023fast}& 28.505&21.549&36.683&1.353&& 19.188&36.997& 47.030&0.000 &&  18.744&35.593&49.289 &0.000 \\
	\hline
	NSFP~\citep{li2021neural} & 49.655&18.057&39.494&27.218 & &32.520&45.011& 53.659&9.514 & &
	28.789&37.742&50.696&14.167\\
	\hline
    NDP~\citep{li2022non} & 58.470&2.795&8.504&25.961 & &37.456&10.357&21.674&11.131 & &
    29.508&26.675&43.407&12.780\\
    \hline
    DPF~\citep{10377509} &35.090&9.065&21.797&1.225& &25.180&20.158& 46.976& 0.000& &
    23.045&26.507&43.491&5.041 \\
	\hline
	OAR (Ours) & \textbf{8.662}&\textbf{29.228}&\textbf{96.813}&\textbf{0.000} & & \textbf{5.687}&\textbf{75.193}&\textbf{97.184}&\textbf{0.000} & &\textbf{12.112}& 
	\textbf{42.372}& \textbf{56.564}&\textbf{0.000} \\
\bottomrule
 \label{tab:liver}
\end{tabular}
\end{adjustbox}
\vskip -0.5cm
\end{table*}

\subsection{Registration under Different Types of Occlusion} To further investigate the performance of our proposed method in handling occlusion, we create three occlusion datasets using three different shapes (cat, horse, and dog) from the TOSCA dataset~\citep{bronstein2008numerical}. Each dataset consists of five types of occlusion, such as the occlusion present in the body of the cat and the tail of the dog, as shown in \cref{fig:tosca_occlusion}. We exclude the outlier ratio from our analysis since the deformation solution is not unique in these cases. Additionally, we exclude AMM\_NRR from our analysis due to its significant deviations from the target poses, which render the error metrics unreliable. The average metrics of all tests are reported in \cref{tab:tosca}. The results indicate that our method still achieves the highest registration accuracy across different occlusion scenarios, especially in terms of the AccR metric. Although our method is slightly slower than other neural networks-based approaches, it is much faster than traditional optimization-based GBCPD. Several qualitative comparison results are presented in \cref{fig:tosca_occlusion}. As observed, our method successfully retains the dog tail without any collapse. More comparison results are presented in \cref{fig:cat} and \cref{fig:dog} of the \emph{Appendix}. 
\begin{table*}[t]
\caption{Quantitative comparisons on different types of occlusion. $\uparrow$ means larger values are better while $\downarrow$ means smaller values are better. \textbf{Bond} fonts indicate the top performer.}
\renewcommand{\arraystretch}{1.4} 
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{@{}lrrrrrrrrrrrr@{}}
\toprule
\multirow{2}{*}{\diagbox{Method}{Metric}} & \multicolumn{3}{c}{Cat} & & \multicolumn{3}{c}{Horse} & &\multicolumn{3}{c}{Dog} &
  \\
\cline{2-4} \cline{6-8} \cline{10-12}
     & {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$&& {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$&& {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$ &Time (s)\\
	\midrule
	GBCPD~\citep{hirose2022geodesic} 
 &4.118   &17.123   &41.104     
&&3.273   &38.353   &52.435
&&4.359  &54.472   &77.375  
&185.621 
\\
\hline
NSFP~\citep{li2021neural} 
 & 4.591  & 13.617   &40.397     
 &&2.761  &25.484   &53.698
&&4.159  &61.486   &78.940   
 &{4.576}
 \\
	\hline
    NDP~\citep{li2022non} 
    & 7.280   &13.401   &32.340    
    &&4.147   &30.922   &48.070 
    &&11.141  &14.710   &42.522  
    &5.858
   \\
    \hline
    DPF~\citep{10377509} 
    & 2.688   &50.048   &75.350    
    &&2.885   &27.819   &55.056 
    &&3.888   &64.480   &80.814 
    &9.518
    
    \\
	\hline
	OAR (Ours) 
 & \textbf{2.559}   &\textbf{50.569}   &\textbf{77.171}  
 & &\textbf{2.249}   &\textbf{40.046}   &\textbf{65.317}   
 &&\textbf{2.467}   &\textbf{76.986}   &\textbf{89.779}
 &13.646
 \\
	\bottomrule
\end{tabular}
\end{adjustbox}
\label{tab:tosca}
\end{table*}
\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{fig/occlusion_vis_cat_dog_v4.pdf}
\vskip -0.2cm
\caption{Qualitative comparison on different types of occlusion. We register the complete source cat and dog model to the target shape with \textbf{body} and \textbf{tail} occlusion, respectively.} 
\label{fig:tosca_occlusion}
\vspace{-0.3cm} 
\end{figure}


\subsection{Registration with Correspondence} 
In addition to handling occlusion scenarios, we also demonstrate the capability of the proposed method for general large deformation registration tasks. To this end, we combine the pre-trained geometric feature descriptor Lepard~\citep{li2022lepard} with our method for non-rigid registration on the 4DMatch and 4DLoMatch animation benchmark datasets~\citep{li2022lepard} (details are presented in Appendix \cref{sec:geometric}). These datasets are collected from the DeformingThings4D sequence \citep{li20214dcomplete}, which contains challenging scenarios with partial overlap, occlusion, and large motions. The 4DMatch dataset comprises point clouds with overlap ratios ranging from $45\%$ to $92\%$, while the 4DLoMatch dataset exhibits lower overlap ratios of $15\%-45\%$. Following ~\citep{li2022non}, we adopt the filtered dataset that has undergone the removal of near-rigid transformations for testing. Specifically, the 4DMatch dataset consists of 2,590 pairs of test, while the 4DLoMatch dataset contains 1,175 pairs. 



\cref{tab:4DMatch} summarizes the quantitative comparison results, with the exception of our method, where the remaining results are taken from~\citep{li2022non}. It is important to note that all supervised models are re-trained on 4DMatch's training split prior to evaluation. Although our method is unsupervised, it still consistently achieves superior or competitive results compared to the competitors, particularly in terms of the two most important metrics, AccS and AccR. 
Moreover, it is worth noting that our method also delivers competitive performance on the highly challenging 4DLoMatch dataset even without any fine-tuning. Qualitative results are presented in \cref{fig:4DMatch} of the \emph{Appendix}.


\begin{table*}[t]
\caption{Quantitative comparisons on the 4DMatch and 4DLoMatch benchmark datasets. The best and second best performers of AccS and AccR are highlighted in \textbf{bold} and \underline{underlined}, respectively.}  
\renewcommand{\arraystretch}{1.2} 
\begin{adjustbox}{width=\textwidth}
				\begin{tabular}{@{}lcccccccccc@{}}
					\toprule
					%\hline
					\multirow{2}{*}{\diagbox{Method}{Metric}} & \multicolumn{4}{c}{4DMatch} && \multicolumn{4}{c}{4DLoMatch}\\
					\cline{2-5} \cline{7-10}
					& {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$& {Outlier} $\downarrow$&& {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$ & {Outlier} $\downarrow$\\
					\midrule
				\text {Lepard~\citep{li2022lepard}+SVD } & 0.137 & 6.91 & 24.50 & 43.43 && {0.160} & 5.27 & 19.77 & 44.16 \\
					\hline
					\text {PointPWC~\citep{wu2019pointpwc}} & 0.182 & 6.25 & 21.49 & 52.07 && 0.279 & 1.69 & 8.15 & 55.70 \\
					\hline
					%\hline
					\text {FLOT~\citep{puy2020flot}} & 0.133 & 7.66 & 27.15 & 40.49 && 0.210 & 2.73 & 13.08 & 42.51 \\
					\hline
					\text {GeomFmaps~\citep{donati2020deep} } & 0.152 & 12.34 & 32.56 & 37.90 && {0.148} & 1.85 & 6.51 & 64.63\\
					\hline
					\text {SyNoRiM-pw~\citep{huang2022multiway}} & 0.099 & 22.91 & 49.86 & 26.01 && 0.170 & 10.55 & 30.17 & {31.12}\\
					\hline
					\text {Lepard+NICP~\citep{li2022lepard}} & 0.097 & 51.93 & 65.32 & 23.02 && 0.283 & 16.80 & 26.39 & 52.99  \\
                        \hline
                        \text {Lepard+NDP~\citep{li2022non}} & 0.077 & \textbf{61.30} & \underline{74.12} & {17.37} && 0.177 & \underline{26.59} & \underline{41.05} & {33.81}\\
                        \hline 
                        \text {Lepard+OAR (Ours)} & {0.059} & \underline{59.32} & \textbf{74.33} & {16.41} &&0.251
                        & \textbf{27.25} & \textbf{42.01} &45.04 \\
					\bottomrule
				\end{tabular}
			\end{adjustbox}
\label{tab:4DMatch}
\vskip -0.2cm
\end{table*}


\subsection{Human Registration on Occluded Depth Views} 
We further evaluate the proposed method for registering human point clouds captured from RGB-D cameras, which can be used for non-rigid reconstruction. As shown in \cref{fig:RGBD}, the sequences from \citep{innmann2016volumedeform} exhibit occlusion disturbances due to human motion. The qualitative results presented in \cref{fig:RGBD_pc} evidence that our method still achieves high-quality deformations despite these challenges. In contrast to DPF, which produces physically unreasonable deformations such as collapse and distortion of body parts, our method consistently preserves realistic deformations, particularly evident in the human hands and arms.





\subsection{Robustness Test}\begin{wraptable}{r}{-0.3\textwidth}
\vspace{-4cm}
\label{tab:noise_outliers_wrap}
\centering
\scalebox{0.6}{
\begin{tabular}{ccccccc}
\toprule
Intensity/Ratio & 0.1&0.2&0.3&0.4&0.5&0.6\\\midrule
Noise&88.712&89.104&89.678&85.701&84.395&81.807\\
Outlier&84.122&88.017&86.719&89.074&86.171&83.999\\
\bottomrule
\vspace{-0.8cm}
\end{tabular}}
\end{wraptable}We also assess the robustness of our developed method against noise and outlier disturbances. To this end, we introduce Gaussian noise with increasing intensity and varying outlier ratios (\%) to the point clouds. The inset table %\cref{tab:noise_outliers_wrap} 
reports the statistical results, while \cref{fig:noise} and \cref{fig:outlier} present the qualitative outcomes. As observed, our method demonstrates strong resilience against both noise and outliers, maintaining performance even with noise levels up to $0.6\%$ and in the contamination of $2,350$ outliers.





\begin{figure*}[t]
\centering
\includegraphics[width=\linewidth]{fig/lion_v4.pdf}
\vskip -0.2cm
\caption{Qualitative comparison of AIAP and LLR with increasing occlusion. As observed, LLR enables more natural registration results and maintains geometric details such as the facial expression more faithfully.}
\label{fig:lion}
\vskip -0.5cm
\end{figure*}

\begin{figure}
%\vskip -0.3cm
    \centering
\includegraphics[width=0.24\linewidth]{fig/ablation_EPE2.pdf}
\includegraphics[width=0.235\linewidth]{fig/ablation_AccS2.pdf}
\includegraphics[width=0.237\linewidth]{fig/ablation_AccR2.pdf}
\includegraphics[width=0.235\linewidth]{fig/ablation_Outlier2.pdf}
\caption{Ablation study of the LLR effect and the comparison between AIAP and LLR manners.}
\label{fig:lion_quantitative}
\vskip -0.3cm
\end{figure}

\subsection{Ablation Study}


\paragraph{The effect of LLR.} 
To demonstrate the effect of the proposed LLR for non-rigid point cloud registration under occlusion disturbances, we construct a series of models with progressively increasing levels of occlusion. In \cref{fig:lion}, we illustrate this by manually removing some parts of the lion model, starting from the tail and extending towards the body. The statistical results in \cref{fig:lion_quantitative} indicate that our method equipped with the LLR constraint (\ie, MCC+LLR), which helps preserve the local neighboring geometry, consistently produces higher-quality registration results compared to the single MCC framework.

\paragraph{AIAP VS. LLR.} 
We also compare the performance of the commonly used AIAP regularization with the proposed LLR in handling challenging occlusion scenarios. As observed in \cref{fig:lion_quantitative}, MCC+AIAP delivers similar results to MCC, while MCC+LLR consistently outperforms MCC+AIAP across different levels of occlusion. Moreover, benefiting from the reconstruction scheme and maintaining the local structure, LLR excels at preserving essential geometric details, such as the intricate facial features of the lion in \cref{fig:lion}, after non-rigid deformation. This stands in contrast to AIAP under occlusion disturbances, which struggles to maintain such details.



\begin{figure}[t]
\centering
\subcaptionbox*{$t=0.1$}{	\includegraphics[width=0.14\linewidth]{fig/Liver1_interpolated_01.png}}
		\subcaptionbox*{$t=0.3$}{	\includegraphics[width=0.14\linewidth]{fig/Liver1_interpolated_03.png}}
		\subcaptionbox*{$t=0.5$}{	\includegraphics[width=0.14\linewidth]{fig/Liver1_interpolated_05.png}}
		\subcaptionbox*{$t=0.7$}{	\includegraphics[width=0.14\linewidth]{fig/Liver1_interpolated_07.png}}
		\subcaptionbox*{$t=0.9$}{	\includegraphics[width=0.14\linewidth]{fig/Liver1_interpolated_09.png}}
		\subcaptionbox*{$t=1.0$}{	\includegraphics[width=0.14\linewidth]{fig/Liver1_interpolated_010.png}}
  \vskip -0.2cm
\caption{Application of the proposed non-rigid registration method to shape interpolation.}
\label{fig:interpolation}
\vskip -0.1cm
\end{figure}


\subsection{Applications}
\paragraph{Shape interpolation.} 
Since our method successfully avoids physically implausible scenarios, such as collapses and tearing, and employs an unsupervised neural implicit representation, it inherently allows for continuous deformation. In \cref{fig:interpolation}, we illustrate the shape interpolation effect using our non-rigid deformation under occlusion, where we vary the timestamp $t$ within the range of $[0.1, 1.0]$. For instance, the interpolation shape with $t=0.5$ is represented by $\mathbf{Y}_{t=0.5}=\mathbf{Y}+t*\nu(\mathbf{Y})=\mathbf{Y}+0.5*\nu(\mathbf{Y})$ with $\nu$ denoting the learned displacement field. As observed, our method not only achieves accurate registration at $t=1.0$ but also maintains substantially smooth and physically feasible interpolation configurations 
throughout the entire deformation process. 


\paragraph{Shape completion.}
We also apply our method to address the problem of shape completion. In \cref{fig:mesh_hole_filling2}, we utilize the source mesh model~\citep{yang2014semantic} as the standard template, while the other shapes exhibit various types of holes caused by occlusion, serving as the targets. It is evident that by deforming the template model to align with the target shapes and leveraging the highly accurate outcomes, our method offers a feasible solution to the ill-posed mesh hole filling task without requiring any additional annotations and constraints. More hole filling results are reported in \cref{fig:shape_completion} of the \emph{Appendix}.



\begin{figure}[t]
\vskip -0.1cm
\centering
\subcaptionbox*{Source}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0015_template_mesh.png}}
\rotatebox{90}{\hdashrule[-0.7ex]{3.1cm}{0.7pt}{1pt}}
\subcaptionbox*{Shape 1}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0017_holeNormalize.png}}
\subcaptionbox*{Result 1}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0017_holeNormalize30_v2.png}}
\rotatebox{90}{\hdashrule[-0.7ex]{3.1cm}{0.7pt}{1pt}}
\subcaptionbox*{Shape 2}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0014_holeNormalize.png}}
\subcaptionbox*{Result 2}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0014_holeNormalize30.png}}
\rotatebox{90}{\hdashrule[-0.7ex]{3.1cm}{0.7pt}{1pt}}
\subcaptionbox*{Shape 3}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0056_holeNormalize_v2.png}}
\subcaptionbox*{Result 3}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0056_holeNormalize_v236.png}}
\vskip -0.2cm
\caption{Application of the proposed non-rigid registration method to mesh hole filling.}
\label{fig:mesh_hole_filling2}
\vskip -0.3cm
\end{figure}



\section{Conclusions}
We introduced a novel unsupervised solution to address the challenging issue of occlusion disturbances in non-rigid point cloud registration, a problem that has not received adequate attention in prior approaches. We provide a comprehensive analysis to elucidate the reasons why previous methods struggle with occlusion scenarios. The first contribution of our method is maximizing the local similarity between source and target geometries, accomplished through the utilization of the adaptive maximization correntropy criterion. We also establish a connection between the correntropy-induced metric and the commonly used Chamfer distance, highlighting that this correntropy-induced metric can serve as a more general measure. Additionally, we develop a locally linear reconstruction paradigm to ensure that deformations in the occluded regions are physically plausible while preserving intricate geometric details of deformed shapes, in contrast to the commonly used AIAP metric. Our method achieves higher-quality non-rigid registration results across a range of datasets, while effectively mitigating the issues of collapses and tearing that are encountered in previous approaches.
Moreover, our method ensures continuous deformation, allowing for promising applications in shape interpolation and shape completion tasks.

\section*{Acknowledgements}
We sincerely thank the anonymous reviewers for their helpful comments which improved the quality of the paper. This work is partially funded by the National Natural Science Foundation of China (12494553, 12494550, 62172415, and 62376267), the Strategic Priority Research Program of the Chinese Academy of Sciences (XDB0640200 and XDB0640000), the Beijing Natural Science Foundation (Z240002), and the innoHK project.


\section*{Reproducibility statement}
The main contribution of this work is the development of an unsupervised neural deformation method that combines correntropy-induced metric and locally linear reconstruction with implicit neural representations to ensure physically reasonable deformations of occluded point clouds. To reproduce the experimental results, we
elaborate on the data pre-processing, metric definitions, and hyper-parameter settings in~\cref{sec:data_processing} and \cref{sec:k}. To facilitate reproducibility, we also publicly release our code.




\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\newpage
\appendix
\section*{Appendix}
In this appendix, we provide additional content to support our paper. Concretely, we present the data pre-processing step of normalization and the definition of used evaluation metrics in \cref{sec:data_processing}, followed by the theoretical %proof of the proposed proposition and mathematical 
derivation of the closed-form weight solution in \cref{sec:LLR_derivation}. \cref{sec:details} presents more details and analyses of~\cref{lemma:1}. \cref{sec:k} investigates the influences of the number of nearest neighbors $k$ for each $\bm{y}_j\in\mathbf{Y}$ and the kernel bandwidth $\sigma^2$ on registration under occlusion disturbances. We present further ablation studies to investigate the regularization effect of implicit neural networks and activation functions in \cref{sec:regularization}. The differences and connections of MCC with robust functions are presented in \cref{sec:robust}. Additional ablation studies of MCC and Chamfer distance as well as its variants are reported in \cref{sec:CD} and \cref{sec:CD_variants}, separately. \cref{sec:geometric} gives the details of how to integrate the geometric descriptors with our proposed optimization framework.  Then, we discuss the limitations and future work of the proposed algorithm in \cref{sec:future}. Finally, in \cref{sec:qualitative}, we present more quantitative and qualitative results. These results include the registration on various types of occlusion from the TOSCA dataset, liver dataset, 4DMatch and 4DLoMatch datasets, shape completion for the challenging mesh hole filling task, human RGB-D views, failure cases, as well as robustness test.%, as well as applications to shape completion for the challenging mesh hole filling task.



\section{Data Pre-Processing and the Metric Definition}
\label{sec:data_processing}
% \subsection{Data pre-processing}
Given a pair of input point clouds $\mathbf{X}=\{\bm{x}_i\in\mathbb{R}^3\}_{i=1}^M$ and $\mathbf{Y}=\{\bm{y}_j\in\mathbb{R}^3\}_{j=1}^N$, where $\mathbf{X}$ and $\mathbf{Y}$ represent the target and source point clouds, separately, we first normalize them to follow a normal distribution, \ie,
\begin{equation}
\centering
\begin{aligned}
\mathcal{N}(\mathbf{X})=(\mathbf{X}-\mathbf{1}_{M}\mu_{\mathbf{X}})/\sigma_{\mathbf{X}}, 
\end{aligned}
\end{equation}
\begin{equation}
\centering
\begin{aligned}
\mathcal{N}(\mathbf{Y})=(\mathbf{Y}-\mathbf{1}_{N}\mu_{\mathbf{Y}})/\sigma_{\mathbf{Y}}, 
\end{aligned}
\end{equation}where $\mu_{*}\in\mathbb{R}^3$ represents the mean point in the set of ${*}$ and $\sigma_{*}\in \mathbb{R}^{+}$ is the farthest Euclidean distance from $\mu_{*}$ to the elements in ${*}$. $\mathbf{1}_{M}\in\mathbb{R}^M$ and $\mathbf{1}_{N}\in\mathbb{R}^N$ are the vectors of all ones. However, when evaluating the registration results, we still use the original inputs by first performing denormalization. 



Specifically, we compute the deviations between the deformed shape $\widehat{\mathbf{Y}}=\sigma_{\mathbf{X}}\mathcal{T}(\mathcal{N}(\mathbf{Y}))+\mathbf{1}_{N}\mu_{\mathbf{X}}$ and the complete shape $\widehat{\mathbf{X}}$ of $\mathbf{X}$ in terms of the metrics EnE, AccS, AccR, and Outlier Ratio by
\begin{equation}
\centering
\begin{aligned}
    \text{EPE}(\widehat{\mathbf{Y}},\widehat{\mathbf{X}})&=\frac{1}{N}\sqrt{\operatorname{Tr}\{(\widehat{\mathbf{Y}}-\widehat{\mathbf{X}})^{\top}(\widehat{\mathbf{Y}}-\widehat{\mathbf{X}})\}},\\
    \text{AccS}(\widehat{\mathbf{Y}},\widehat{\mathbf{X}})&=\frac{1}{N}\sum_{j=1}^N\mathbb{I}(\|\widehat{\bm{y}}_j-\widehat{\bm{x}}_j\|_2<0.025)\times 100\%,\\
    \text{AccR}(\widehat{\mathbf{Y}},\widehat{\mathbf{X}})&=\frac{1}{N}\sum_{j=1}^N\mathbb{I}(\|\widehat{\bm{y}}_j-\widehat{\bm{x}}_j\|_2<0.05)\times 100\%,\\
    \text{Outlier}(\widehat{\mathbf{Y}},\widehat{\mathbf{X}})&=\frac{1}{N}\sum_{j=1}^N\mathbb{I}(\|\widehat{\bm{y}}_j-\widehat{\bm{x}}_j\|_2>0.3)\times 100\%,
\end{aligned}
\end{equation}where $\operatorname{Tr}$ and $\operatorname{\top}$ are the trace operator and transpose operator of a matrix, separately. $\mathbb{I}$ is the indicator function and $\|\|_2$ represents the Euclidean distance. 





\section{Derivation of the closed-form solution in \cref{eq:matrix_inverse} of the paper}
\label{sec:LLR_derivation}
To make the proposed method self-contained, we present the derivation of the closed-form solution in \cref{eq:matrix_inverse} as follows. According to the Lagrange multiplier, we have 
\begin{equation}
\mathcal{L}(\bm{w}_j, \lambda_j)=\frac{1}{2}\bm{w}_j^{\top}\mathbf{G}_{j}\bm{w}_j-\lambda_j(\bm{w}_j^{\top} \bm{1}_{k}-1).
\end{equation} By equating the partial derivatives of $\mathcal{L}(\bm{w}_j, \lambda_j)$ to zero, we obtain
\begin{equation}
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial {\boldsymbol{w}}_{j}} & = \boldsymbol{G}_{j} {\boldsymbol{w}}_{j}-\lambda_{j} \mathbf{1}_k {=} \mathbf{0}, \\
& \Longrightarrow {\boldsymbol{w}}_{j}=\boldsymbol{G}_{j}^{-1} \lambda_{j} \mathbf{1}_k={\lambda_{j}} \boldsymbol{G}_{j}^{-1} \mathbf{1}_k. \\
\frac{\partial \mathcal{L}}{\partial \lambda_j} & = {\boldsymbol{w}}_{j}^{\top}\mathbf{1}_k-1 {=} 0 \Longrightarrow  {\boldsymbol{w}}_{j}^{\top}\mathbf{1}_k=1.
\end{aligned}
\end{equation} Then, we have
\begin{equation}
    {\lambda}_{j}=\frac{1}{\mathbf{1}_k^{\top}{\boldsymbol{G}_{j}^{\top}}^{-1}\mathbf{1}_k^{\top}}=\frac{1}{\mathbf{1}_k^{\top}{\boldsymbol{G}_{j}^{-1}\mathbf{1}_k^{\top}}}.
\end{equation} Thus, 
\begin{equation}
{\boldsymbol{w}}_{j}=\frac{\boldsymbol{G}_{j}^{-1} \mathbf{1}_k}{\mathbf{1}_k^{\top}{\boldsymbol{G}_{j}^{-1}\mathbf{1}_k^{\top}}}.
\end{equation} This completes the derivation of \cref{eq:matrix_inverse} and \cref{eq:lagrange}.


\section{More Details and Analyses of \cref{lemma:1}} \label{sec:details}
We present more details of \cref{lemma:1}. We can rewrite the correntropy of Gaussian kernel as
\begin{equation}
 V_\sigma(X, Y)=1/(\sqrt{2 \pi} \sigma) \sum_{n=0}^{\infty}\left((-1)^n\right) /\left(2^n n!\right) \mathbb{E}\left[\left((X-Y)^{2 n}\right) /\left(\sigma^{2 n}\right)\right],   
\end{equation}which involves all the even moments of the random variable $X-Y$. When two points are in close proximity, the second-order moment tends to be dominant, causing correntropy to approach correlation, as the higher-order moments decay more rapidly. As the points become more distant, as shown in~\citep{liu2007correntropy}, correntropy transitions from behaving like an $\ell_1$ norm to resembling an $\ell_0$ norm. This transition further illustrates the inherent robustness of the MCC metric. 

\section{Investigation of $k$ and $\sigma^2$ on Deformation} \label{sec:k}
We adopt the occluded liver 1 dataset~\citep{opencas} and vary the number of neighbors $k\in[2, 30]$ with $\Delta k=2$ and $\sigma^2\in[0.2, 2]$ with $\Delta\sigma^2=0.2$ to investigate their influences on non-rigid registration under occlusion disturbances. As shown in \cref{fig:ablation_k_sigma}, our method consistently achieves significantly lower outlier ratios across different values of $k$ and $\sigma^2$. With increasing values of $k$, our method not only demonstrates higher AccS and AccR results but also with slower EPE. Nevertheless, larger values of $k$ typically result in higher computational complexity due to the matrix inverse operation in \cref{eq:matrix_inverse} of the paper. Therefore, we suggest setting $k=30$ for general use. Regarding $\sigma^2$, we suggest using $\sigma^2=1.0$ for general applications as its variation has a minimal impact on the results.
\begin{figure*}[!htbp]
\centering
\includegraphics[width=0.45\linewidth]{fig/ablation_k_liver1_v3}
\includegraphics[width=0.45\linewidth]{fig/ablation_sigma2_liver1_v3}
\caption{Influences of $k$ and $\sigma^2$ on non-rigid registration under occlusion disturbance scenarios. }
\label{fig:ablation_k_sigma}
\end{figure*}




\begin{table*}[t]
\caption{Ablation study of the regularization effect of the activation functions on the occluded Open-CAS liver dataset. $\uparrow$ means larger values are better while $\downarrow$ means smaller values are better.}
\renewcommand{\arraystretch}{1.5} 
\begin{adjustbox}{width=\textwidth}
\begin{tabular}
{@{}lrrrrrrrrrrrrrr@{}}
\toprule
\multirow{2}{*}{\diagbox{Method}{Metric}} & \multicolumn{4}{c}{Liver 1} && \multicolumn{4}{c}{Liver 2} && \multicolumn{4}{c}{Liver 3} \\
\cline{2-5} \cline{7-10} \cline{12-15}
     & {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$& {Outlier} $\downarrow$&& {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$ & {Outlier} $\downarrow$ && {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$& {Outlier} $\downarrow$ \\
	\midrule
ReLU+CD&47.994&9.106&20.466&17.957&&39.171&9.684&23.321&8.533&&27.494&28.766&44.443&11.272\\
\hline
ReLU+MCC&31.582&28.446&40.614&4.378&&12.012&47.258& 69.975&0.000&&17.245&32.841&51.744&1.326\\
\hline
ReLU+MCC+LLR&14.690&34.144&57.860&0.000&&6.984&66.543&89.956&0.000&&14.306&36.670&52.982&0.000\\
\bottomrule
 \label{tab:regularization}
\end{tabular}
\end{adjustbox}
\end{table*}
\section{Analysis of the Regularization}\label{sec:regularization}
\cref{fig:lion_quantitative} reveals that regularizing the deformation field of occluded regions is mainly from LLR rather than the network. This is because a network alone is insufficient to handle occlusions effectively, often resulting in significant deviations. We conduct additional ablation studies on the OpenCAS dataset to investigate the role of activation functions (\ie, ReLU and SIREN) with the LLR for regularization. The results presented in \cref{tab:regularization} reveal that the regularization of deformations in occluded areas is primarily attributed to LLR rather than the activation function, as ReLU+CD and ReLU+MCC still generate significant deformation errors, especially for both the EPE and Outlier metrics. 


Moreover, to investigate the intrinsic regularization capabilities of activation functions, we conduct an additional experiment by applying recursive deformations to complete shapes without occlusion. The EPE metric detailed in \cref{tab:intrinsic_regularization} demonstrates that ReLU and SIREN exhibit comparable performance on complete shapes. This finding further substantiates our conclusion that while activation functions do possess a regularization effect, they may fall short when addressing the complexities of challenging occlusions (\ie, the motivation and core contributions of this work). In such cases, LLR proves to be particularly beneficial. 

\begin{table*}[t]
\centering
\caption{Ablation study of the intrinsic regularization effect of the activation functions on the complete Open-CAS liver dataset.  $\uparrow$ means larger values are better while $\downarrow$ means smaller values are better.}
\scalebox{1}{
\begin{tabular}{lccc}
\toprule
Method & {Liver 1$\rightarrow$Liver 2} &{Liver 2$\rightarrow$Liver 3} &{Liver 3$\rightarrow$Liver 1} \\
\midrule
ReLU+CD&4.685&5.550&6.787\\
SIREN+CD&3.912&5.063&6.183\\
\bottomrule
 \label{tab:intrinsic_regularization}
\end{tabular}
}
\label{tab:activation}
\end{table*}



\section{Differences and Connections with Robust Functions} \label{sec:robust}
Moreover, we conduct an in-depth analysis comparing correntropy with robust functions.


\paragraph{Differences.} Unlike common robust functions, correntropy is initially proposed in information-theoretic learning to handle \emph{nonzero mean and non-Gaussian noise} (\eg, the occlusion part can be seen as a certain type of non-Gaussian noise), which is related to the Renyi’s quadratic entropy. Besides, MCC is a \emph{local measure} that provides a \emph{probabilistic meaning} of maximizing the error probability density at the origin according to the information potential. 


\paragraph{Connections.} We derive the relationship between MCC and robust functions. By setting $\rho(e)=\left(1-\exp \left(-e^2 / 2 \sigma^2\right)\right) / \sqrt{2 \pi} \sigma$, we can prove that $\rho(e)$ is an influence function satisfying all the criteria of a robust function, \ie, 
\begin{equation}
\begin{aligned}
&\rho(e) \geq 0, \rho(0)=0, \rho(e)=\rho(-e),\\ &\rho\left(e_i\right) \geq \rho\left(e_j\right) \text{for} \left|e_i\right|>\left|e_j\right|.
\end{aligned}
\end{equation}
Moreover, 
\begin{equation}
\min_{\theta}\sum_{i=1}^{N}\rho\left(e_{i}\right)\Leftrightarrow \max_{\theta} \sum_{i=1}^{N} \exp\left(-e_{i}^{2} / 2 \sigma^{2}\right)/ \sqrt{2 \pi} \sigma   
\end{equation}with the corresponding weight function of $\rho(e)$ as $w(e)=\exp \left(-e^2 / 2 \sigma^2\right) / \sqrt{2 \pi} \sigma^3$. For comparison, the Bi-square's weight function is 

\begin{equation}
w_{\mathrm{Bi}}(e)= \left\{
\begin{aligned}
(1-&(e / h)^2)^2, & |e| \leq h\\
&0,  & |e| \geq h \\
\end{aligned},
\right.
\end{equation} where $h$ is the tuning threshold. Therefore, the nonzero part of $w_{\mathrm{Bi}}(e)$ is equivalent to (with a constant) the square of the first-order Taylor expansion of $w(e)$. MCC is analogous to a robust function but with the specific influence function $\rho(e)$. However, unlike the Huber or Bi-square function, correntropy does not need a predefined threshold such as $h$ and the kernel size entirely governs the properties. Moreover, our derivation between correntropy and robust functions offers a practical way to select an appropriate threshold for robust functions or determining the kernel size for correntropy. 

\begin{figure}
\centering
\includegraphics[width=0.24\linewidth]{fig/ablation_MCC_CD_EPE.pdf}
\includegraphics[width=0.235\linewidth]{fig/ablation_MCC_CD_AccS.pdf}
\includegraphics[width=0.237\linewidth]{fig/ablation_MCC_CD_AccR.pdf}
\includegraphics[width=0.235\linewidth]{fig/ablation_MCC_CD_Outlier.pdf}
 \caption{Ablation study of the MCC and the CD metrics.}
\label{fig:lion_quantitative_MCC_CD}
\end{figure}

\section{Ablation Study of MCC and the Chamfer Distance}\label{sec:CD}
Additionally, we conduct additional ablation experiments to replace MCC with CD on a series of models used in \cref{fig:lion_quantitative}, testing them with progressively increasing levels of occlusion (0-5). The quantitative comparison results in \cref{fig:lion_quantitative_MCC_CD} demonstrates that MCC consistently achieves higher-quality deformation results, particularly with significantly high AccS and AccR metrics. Moreover, we provide a detailed comparison of the time consumption of both the Chamfer Distance and MCC in  \cref{tab:MCC_CD}, measured in seconds. As observed, MCC also achieves significantly high efficiency with the computation time around 1 millisecond for a dataset comprising around $10^4$ points.

\begin{table}[!ht]
\centering
\caption{Comparison of time for MCC and CD metrics in seconds (s).}
%\vskip -0.3cm
\scalebox{1}{
\begin{tabular}{lccccccc}
\toprule
Cases & 0&1&2&3&4&5&Ave.\\\midrule
CD $(\times 10^{-3}$s)&0.696&0.676&0.685&0.687&0.697&0.690&0.689\\
MCC $(\times 10^{-3}$s)&1.332&1.327&1.466&1.323&1.285&1.316&1.342\\
\bottomrule
\end{tabular}
}
\label{tab:MCC_CD}
\end{table}


\section{Further Comparison with other CD Variants} \label{sec:CD_variants} To further demonstrate the advantages and versatility of the MCC metric, we conduct additional experiments to evaluate MCC against the most recent or state-of-the-art \emph{Hyperbolic Chamfer Distance} (HCD) in point cloud completion~\citep{lin2023hyperbolic}. We use the author's source code to implement the HCD metric. Particularly, we adopt three distinct tests by adjusting the coefficient $\alpha$ within the HCD framework to achieve comprehensive results. The quantitative results reported in \cref{tab:HCD} demonstrate that our proposed method consistently achieves higher-quality deformations. Moreover, MCC shows potential for further exploration and application in general point analysis tasks, including point cloud completion.
\begin{table*}[!htbp]
\caption{Quantitative comparisons between the MCC and the HCD metrics on the occluded Open-CAS liver dataset. $\uparrow$ means larger values are better while $\downarrow$ means smaller values are better. \textbf{Bond} fonts indicate the top performer.}
\renewcommand{\arraystretch}{1.5} 
\begin{adjustbox}{width=\textwidth}
\begin{tabular}
{@{}lrrlrrrlrrrrrrr@{}}
\toprule
\multirow{2}{*}{\diagbox{Method}{Metric}} & \multicolumn{4}{c}{Liver 1} && \multicolumn{4}{c}{Liver 2} && \multicolumn{4}{c}{Liver 3} \\
\cline{2-5} \cline{7-10} \cline{12-15}
     & {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$& {Outlier} $\downarrow$&& {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$ & {Outlier} $\downarrow$ && {EPE} $\downarrow$ & {AccS} $\uparrow$& {AccR} $\uparrow$& {Outlier} $\downarrow$ \\
	\midrule
HCD with $\alpha=1.0$&28.946&15.533&33.077&0.054&&29.164& 15.455&32.369&0.169&&29.384&15.042&33.103&0.216\\
\hline
HCD with $\alpha=0.5$&27.116&12.727&33.527&0.000&&  26.451&11.944&32.145&0.000&&26.815&12.826&32.750&0.000\\
\hline
HCD with $\alpha=0.3$&23.535&10.414& 33.338&0.000&&23.074&9.730&32.881&0.000      &&24.291&10.872&33.744&0.000\\
\hline
MCC (Ours)&8.662&29.228&96.813&0.000&&5.687&75.193&97.184&0.000&&12.112&42.372&56.564&0.000\\
\bottomrule
 \label{tab:HCD}
\end{tabular}
\end{adjustbox}
\end{table*}

\section{How to incorporate the geometric descriptor}
\label{sec:geometric}
Given the two matching sets $\mathcal{S}(\mathbf{X})$ and $\mathcal{S}(\mathbf{Y})$ extracted by the pre-trained geometric descriptor Lepard, with $|\mathcal{S}(\mathbf{X})|=|\mathcal{S}(\mathbf{Y})|<\min(|\mathbf{X}|,|\mathbf{Y}|)$, our optimization function is formally defined as
\begin{equation}
\mathbf{\Theta}^*=\mathop{\arg\min}\limits_{\mathbf{\Theta}}\mathcal{F}(\mathbf{\Theta})+\beta\mathcal{M}(\mathbf{\Theta}),     
\end{equation}where $\mathcal{F}(\mathbf{\Theta})   $ and $\mathcal{M}(\mathbf{\Theta})$ denote the deformation loss and the pointwise matching loss, separately.


\section{Limitations and Future Work}\label{sec:future}
While the proposed registration method demonstrates impressive performance on various occlusion disturbances, it is worth noting that the problem itself is highly challenging and severely ill-posed. 
When the occlusion region is significantly large, the method may yield unsatisfactory results (\cref{fig:RGBD_failure}). However, integrating shape analysis theory, such as the \emph{geometric symmetry} of models, could potentially mitigate this limitation.


Besides, the computational complexity of the locally linear reconstruction step is relatively high due to the matrix inverse operation. One possible approach is to explore \emph{low-rank  approximations} of the Gram matrix to further speed up the deformation process.



Another future work is to further speed up the computation of the MCC metric. As demonstrated in~\citep{li2023fast}, a distance transform is utilized to expedite the computation of the Chamfer distance, and in principle, this manner can be extended to the MCC-induced metric as our proposed method also incorporates pairwise computation. However, as the authors noted, we must carefully consider the trade-off between discretization error, grid resolution, memory consumption, and estimation accuracy. 

\section{More Quantitative and Qualitative Results}\label{sec:qualitative}
We provide additional results in
the following to show the superiority of the proposed method. Specifically, 
\begin{enumerate}
    \item \cref{fig:cat} to~\cref{fig:dog} showcase the test results on the occluded TOSCA dataset~\citep{bronstein2008numerical}, where various occlusion scenarios are present.
    \item \cref{fig:liver} demonstrates the registration results of our proposed method by inversely deforming the occluded geometry to the complete one. It can be seen that our method achieves highly accurate registrations, preserves the original topology of the organs (including their distinct parts), and avoids the generation of physically infeasible parts. 
    \item \cref{fig:4DMatch} presents qualitative results on the 4DMatch or 4DLoMatch datasets~\citep{li2022lepard}, where our method performs impressively despite the existence of challenging scenarios such as large deformation, low overlap, and occlusion.
    \item \cref{fig:shape_completion} showcases additional shape completion results by deforming the source model~\citep{yang2014semantic} to the shapes with occluded holes. Thanks to the highly accurate registration results, our method provides a viable solution to this challenging mesh hole filling problem.
    \item \cref{fig:shape_completion_mean} further reports the mesh hole filling results where the source or template models also contain holes. The source models are selected from \cref{fig:mesh_hole_filling2} and \cref{fig:shape_completion}, with the middle model in each case serving as the mean shape. It is observed that, due to the superior non-rigid deformation capabilities of our method, the majority of the holes in the original shapes have been effectively filled. Moreover, we present the boolean shapes, which are obtained from the union operation between the deformed surfaces and their corresponding target models (that is, Shape 1 $\cup$ Result 1 and Shape 2 $\cup$ Result 2). This boolean operation not only further completes the holes but also demonstrates the seamless integration of the deformed shapes with their target models.
    \item \cref{fig:RGBD} to \cref{fig:RGBD_failure} report the registration results of our method on real-world RGB-D point clouds under occlusion disturbance.  
    \item 
    \cref{fig:noise} and \cref{fig:outlier} showcase qualitative registration results under significant disturbances caused by noise and outliers, respectively. As demonstrated, our method continues to achieve highly accurate deformations, attributable to the adaptive correntropy function.  
\end{enumerate}



\begin{figure*}[!htbp]
\centering
\includegraphics[width=\linewidth]{fig/supp_TOSCA_cat.pdf}
\caption{Qualitative comparisons on the occluded cat dataset, where the \textbf{body} and \textbf{tail} of the cat are occluded.} 
%(a) Body and tail; (b) horse foot; (c) dog leg and tail.}
\label{fig:cat}
\end{figure*}


\begin{figure*}[!htbp]
\centering
\includegraphics[width=0.9\linewidth]{fig/supp_TOSCA_dog.pdf}
\caption{Qualitative comparisons on the occluded dog dataset, where the \textbf{left front leg} and the \textbf{tail} of the dog are occluded.}
\label{fig:dog}
\end{figure*}


\begin{figure*}
\centering
\subcaptionbox*{Input 1}{
\includegraphics[width=0.15\textwidth]{fig/Liver1_input_app.png}}
\subcaptionbox*{Result 1}{
\includegraphics[width=0.15\textwidth]{fig/Liver1_reg_app.png}
}
\subcaptionbox*{Input 2}{
\includegraphics[width=0.15\textwidth]{fig/Liver2_input_app.png}}
\subcaptionbox*{Result 2}{
\includegraphics[width=0.15\textwidth]{fig/Liver2_reg_app.png}}
\subcaptionbox*{Input 3}{
\includegraphics[width=0.15\textwidth]{fig/Liver3_input_app.png}}
\subcaptionbox*{Result 3}{
\includegraphics[width=0.15\textwidth]{fig/Liver3_reg_app.png}}
\caption{Application of the proposed method to register occluded livers to the complete ones. As observed, our method not only delivers highly-accurate registration results but also preserves the original topology of the organs, including their distinct parts, while avoiding the generation of additional physically infeasible parts.}
\label{fig:liver}
\end{figure*}


\begin{figure}[!htbp]
\centering
\includegraphics[width=\linewidth]{fig/4DMatch.pdf}
\caption{Non-rigid registration on point clouds from the challenging 4DMatch or 4DLoMatch datasets, which exhibit \textbf{significant deformations}. The blue and gray point clouds represent the source and target models, separately, while the yellow color indicates our registrations. Our method still yields satisfactory results even in the presence of substantial deformations.}
\label{fig:4DMatch}
\end{figure}



 \begin{figure}[!htbp]
\subcaptionbox*{Source}{	\includegraphics[width=0.183\linewidth]{fig/SPRING0015_template_mesh.png}}
\rotatebox{90}{\hdashrule[-0.7ex]{4.7cm}{0.7pt}{1pt}}
\subcaptionbox*{Shape 1}{	\includegraphics[width=0.183\linewidth]{fig/SPRING0083_holeNormalize.png}}
\subcaptionbox*{Result 1}{	\includegraphics[width=0.183\linewidth]{fig/SPRING0083_holeNormalize30.png}}
\rotatebox{90}{\hdashrule[-0.7ex]{4.7cm}{0.7pt}{1pt}}
\subcaptionbox*{Shape 2}{	\includegraphics[width=0.183\linewidth]{fig/SPRING0089_holeNormalize.png}}
\subcaptionbox*{Result 2}{	\includegraphics[width=0.183\linewidth]{fig/SPRING0089_holeNormalize30.png}}


\subcaptionbox*{Source}{	\includegraphics[width=0.183\linewidth]{fig/SPRING0392_templateNormalize.png}}
\rotatebox{90}{\hdashrule[-0.7ex]{4.7cm}{0.7pt}{1pt}}
\subcaptionbox*{Shape 1}{	\includegraphics[width=0.183\linewidth]{fig/SPRING0404_holeNormalize.png}}
\subcaptionbox*{Result 1}{	\includegraphics[width=0.183\linewidth]{fig/SPRING0404_holeNormalize30.png}}
\rotatebox{90}{\hdashrule[-0.7ex]{4.7cm}{0.7pt}{1pt}}
\subcaptionbox*{Shape 2}{	\includegraphics[width=0.183\linewidth]{fig/SPRING4467_holeNormalize.png}}
\subcaptionbox*{Result 2}{	\includegraphics[width=0.183\linewidth]{fig/SPRING4467_holeNormalize38.png}}
\caption{Application of the proposed method to mesh hole filling by deforming the source model to the target shape.}
\label{fig:shape_completion}
\end{figure}


\begin{figure}[t]
\vskip -0.1cm
\centering
\subcaptionbox*{Source}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0014_holeNormalize_mean.png}}
\rotatebox{90}{\hdashrule[-0.7ex]{3.1cm}{0.7pt}{1pt}}
\subcaptionbox*{Shape 1}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0017_holeNormalize_mean.png}}
\subcaptionbox*{Result 1}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0017_holeNormalizev_mean30.png}}
\subcaptionbox*{Boolean 1}{	\includegraphics[width=0.125\linewidth]{fig/SPRING0017_holeNormalize_mean_union.png}}
\rotatebox{90}{\hdashrule[-0.7ex]{3.1cm}{0.7pt}{1pt}}
\subcaptionbox*{Shape 2}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0056_holeNormalize_v2_mean.png}}%SPRING0056_holeNormalize.png
\subcaptionbox*{Result 2}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0056_holeNormalize_v2v_mean38.png}}
\subcaptionbox*{Boolean 2}{	\includegraphics[width=0.125\linewidth]{fig/SPRING0056_holeNormalize_v2v_mean_union.png}}


\subcaptionbox*{Source}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0089_holeNormalize_mean.png}}
\rotatebox{90}{\hdashrule[-0.7ex]{3.1cm}{0.7pt}{1pt}}
\subcaptionbox*{Shape 1}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0083_holeNormalize_mean.png}}
\subcaptionbox*{Result 1}{	\includegraphics[width=0.12\linewidth]{fig/SPRING0083_holeNormalizev_mean32.png}}
\subcaptionbox*{Boolean 1}{	\includegraphics[width=0.125\linewidth]{fig/SPRING0083_holeNormalize_mean_union.png}}
\rotatebox{90}{\hdashrule[-0.7ex]{3.1cm}{0.7pt}{1pt}}
\subcaptionbox*{Shape 2}{	\includegraphics[width=0.12\linewidth]{fig/SPRING4467_holeNormalize_mean.png}}%SPRING0056_holeNormalize.png
\subcaptionbox*{Result 2}{	\includegraphics[width=0.12\linewidth]{fig/SPRING4467_holeNormalizev_mean36.png}}
\subcaptionbox*{Boolean 2}{	\includegraphics[width=0.125\linewidth]{fig/SPRING4467_holeNormalize_mean_union.png}}
\caption{Application of the proposed non-rigid registration method to mesh hole filling. This figure illustrates the process of deforming a source model containing holes to align with other models that also have holes. “Result 1” and “Result 2” represent the deformed shapes by our non-rigid registration method, which consistently delivers high-quality deformations regardless of the holes. “Boolean 1” and “Boolean 2” are obtained by taking the union operation of the deformed surfaces with their respective targets (\ie, Shape 1 $\cup$ Result 1 and Shape 2 $\cup$ Result 2), highlighting the seamless integration of the deformed shapes with their target models.}
\label{fig:shape_completion_mean}
\vskip -0.3cm
\end{figure}







\begin{figure*}%[!ht]
% \begin{center}

\centering
\includegraphics[width=0.136\linewidth]{fig/frame-000334.color.png}
\includegraphics[width=0.136\linewidth]{fig/frame-000379.color.png}
\includegraphics[width=0.136\linewidth]{fig/frame-000412.color.png}
\includegraphics[width=0.136\linewidth]{fig/frame-000997.color.png}
\includegraphics[width=0.136\linewidth]{fig/frame-001016.color.png}
\includegraphics[width=0.136\linewidth]{fig/frame-001083.color.png}
\includegraphics[width=0.136\linewidth]{fig/frame-001092.color.png}
\caption{RGB sequence images with occlusion used in generating {real RGB-D} point clouds.}
%\vskip -0.3cm
% \end{center}
\label{fig:RGBD}
\end{figure*}


\begin{figure*}%[!ht]
% \begin{center}
\centering
\includegraphics[width=1\linewidth]{fig/VolumeDeform_v2.pdf}
\caption{Non-rigid registration on RGB-D point clouds with occlusion indicated by the {\color{red}{red box}}. As observed, DPF suffers from physically implausible issues such as \textbf{collapse or pull} of the body parts as shown in the {\color{green}{green box}}, instead, our method not only delivers successful registration, but also preserves the \textbf{physical rationality} of the human body, such as the hands and arms in the {\color{blue}{blue box}}. 
 }
%\vskip -0.3cm
 %\end{center}
 \label{fig:RGBD_pc}
\end{figure*}


\begin{figure}%[ht]
% \begin{center}
\centering
\includegraphics[width=\linewidth]{fig/failure.png}
%\vskip -0.2cm
\caption{Failure cases due to significantly large occlusion (\ie, the occlusion of \textbf{both human arms and body}). Nonetheless, our method preserves high-quality deformation in the overlapping regions and still strives to deliver \textbf{physically plausible deformation} for occluded areas to the best extent possible.}
\label{fig:RGBD_failure}
\end{figure}




\newpage
\begin{figure}%[ht]

\centering
\includegraphics[width=0.326\linewidth]{fig/lion_source_0006.png}
\includegraphics[width=0.326\linewidth]{fig/lion_noise_input.png}
\includegraphics[width=0.326\linewidth]{fig/lion_target306500_truncated_5.2.png}
% \vskip -0.3cm
\caption{Non-rigid point cloud registration under \textbf{heavy noise disturbances} ({\color{blue}{intensity=0.6\%}}). Our method still delivers satisfactory registration thanks to the utilized adaptive correntropy function.}
\label{fig:noise}
\end{figure}

\begin{figure}%[ht]

\centering
\includegraphics[width=0.48\linewidth]{fig/lion_target_outlier_01_input.png}
\includegraphics[width=0.48\linewidth]{fig/lion_outlier_reg.png}
 %\vskip -0.3cm
\caption{Non-rigid point cloud registration under \textbf{heavy outlier disturbances} ({\color{blue}{\#outliers=2,350}}). Our method 
exhibits substantial robustness against outliers, attributed to the introduction of the adaptive correntropy function.}
\label{fig:outlier}
\end{figure}
 
\end{document}
