\section{Supplementary figures}
\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/correct.pdf} 
    \caption{Correct ratio of property-to-molecule generation. We treat the generated molecule as a correct one if $\lvert v' - v \lvert \leq \delta$, where $v'$ is its property value and $v$ is the input value. $\delta$ is set to 0 for HBA, HBD, RotBonds, 0.05 for QED and FSP3, and 5 for TPSA. }
    \label{fig:prop2mol_correct}
\end{figure}
\clearpage
\begin{figure}[!htb]
\centering
\subfigure[QED]{
\includegraphics[width=0.5\linewidth]{figures/QED.pdf} 
}%
\subfigure[HBA]{
\includegraphics[width=0.5\linewidth]{figures/HBA.pdf} 
}
\subfigure[HBD]{
\includegraphics[width=0.5\linewidth]{figures/HBD.pdf} 
}%
\subfigure[Rotatable bonds]{
\includegraphics[width=0.5\linewidth]{figures/RotBonds.pdf} 
}
\caption{Violin plot of basic molecular properties for molecule generation, including QED, the number of hydrogen bond acceptors (HBA), the number of hydrogen bond donors (HBD) and the number of rotatable bonds.}
\label{fig:basic_to_cmpd_violinplot}
\end{figure}

\clearpage
\begin{figure}[!htb]
\centering
\subfigure[QED=0.8, FSP3=0.4]{
\includegraphics[width=0.5\linewidth]{figures/QED=0.8.FSP3=0.4.pdf}
}%
\subfigure[QED=0.8, FSP3=0.6]{
\includegraphics[width=0.5\linewidth]{figures/QED=0.8.FSP3=0.6.pdf}
}
\caption{Heatmap of molecule generation based on QED and fraction of spÂ³ (FSP3) properties. Each generated compound's QED and FSP3 values are calculated using RDKit and visualized in the heatmap.}
\label{fig:qed_fsp3_joint_optim}
\end{figure}
\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/8b_targets.pdf} 
    \caption{Bar plot of the proportion of correct, equal and wrong generated molecules. Molecules evaluated by retrieval and molecules evaluated by docking are distinguished using different colors.}
    \label{fig:binding_docking}
\end{figure}
\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/compare.pdf} 
    \caption{Bar plot of the correct ratio of \ourM{} (1B), \ourM{} (8B) and \ourM{} (8x7B) on each target.}
    \label{fig:binding_correct}
\end{figure}

\begin{figure}
    \centering
    \subfigure[\ourM{} (1B)]{
    \includegraphics[width=0.45\linewidth]{figures/mat_uncon_ehull_1b.pdf}
    }%
    \subfigure[\ourM{} (8B)]{
    \includegraphics[width=0.45\linewidth]{figures/mat_uncon_ehull_8b.pdf}
    }%
    \vskip\baselineskip
    \subfigure[\ourM{} (8x7B)]{
    \includegraphics[width=0.45\linewidth]{figures/mat_uncon_ehull_8x7b.pdf}
    }
    \subfigure[Accumulated distribution]{
    \includegraphics[width=0.45\linewidth]{figures/mat_uncon_ehull_accumulate_ehull.pdf}
    }
    \caption{Energy above hull (ehull) distribution for unconditional material generation.}
    \label{fig:mat_uncon}
\end{figure}

\begin{figure}
    \centering
    \subfigure[\ourM{} (1B)]{
    \includegraphics[width=0.45\linewidth]{figures/mat_bulk_to_mat_ehull_1b.pdf}
    }%
    \subfigure[\ourM{} (8B)]{
    \includegraphics[width=0.45\linewidth]{figures/mat_bulk_to_mat_ehull_8b.pdf}
    }%
    \vskip\baselineskip
    \subfigure[\ourM{} (8x7B)]{
    \includegraphics[width=0.45\linewidth]{figures/mat_bulk_to_mat_ehull_8x7b.pdf}
    }
    \subfigure[Accumulated distribution]{
    \includegraphics[width=0.45\linewidth]{figures/mat_bulk_to_mat_accumulate_ehull.pdf}
    }
    \caption{Energy above hull (ehull) distribution for bulk modulus to material generation.}
    \label{fig:mat_bulk_to_mat_ehull}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/mat_novelty.pdf}
    \caption{Novel materials w.r.t generated materials.}
    \label{fig:mat_novelty}
\end{figure}

\clearpage
\begin{figure}[!htbp]
\centering
\includegraphics[width=\linewidth]{figures/caseStudy_smi2iupac_online.pdf}
\caption{We selected SMILES strings from PubChem with IDs 172655007 and 172655008, which were available as of February 24, 2025, and were excluded from our training set. The performance of \ourM{}, DeepSeek-R1 \cite{deepseekai2025r1}, GPT-4o, GPT-4.5-preview, and o3-mini was evaluated for SMILES-to-IUPAC translation. The generated IUPAC names are presented in the accompanying figure. These IUPAC names were subsequently converted back to SMILES for validation. The IUPAC name produced by o3-mini could not be processed due to the high structural complexity of the corresponding molecule. \ourM{} successfully generated the correct result. It is important to emphasize that our objective is not to criticize the limitations of general language models but to better understand their current capabilities and explore how they can be complemented by \ourM{} for enhanced performance. The molecular structures were visualized using the ChemDB Chemoinformatics Portal \cite{Chen2007-il} \url{https://cdb.ics.uci.edu/cgibin/Smi2DepictWeb.py}.}
%Case study on SMILES-to-IUPAC translation. We selected SMILES strings from PubChem with IDs 172655007 and 172655008, which were available as of February 24, 2025, and were not included in our training set. We evaluated the performance of \ourM{}, DeepSeek-R1 \cite{deepseekai2025r1}, GPT-4o, GPT-4.5-preview and  o3-mini for SMILES-to-IUPAC translation, with the generated IUPAC names listed in the figure. These IUPAC names were then converted back to SMILES for validation. We were not unable to process the IUPAC name produced by o3-mini due to the high structural complexity. \ourM{} successfully generated the correct result. Our goal is NOT to highlight the limitations of general language models but to better understand their current capabilities and explore how they can be complemented by \ourM{} for improved performance. The molecules are visualzzed by ChemDB Chemoinformatics Portal \cite{Chen2007-il} \url{https://cdb.ics.uci.edu/cgibin/Smi2DepictWeb.py}  }
\label{fig:case_study_iupac_to_smiles}
\end{figure}



\clearpage

\begin{figure}[!htbp]
\centering
\includegraphics[width=1.0\linewidth]
{figures/NatureLM_retro_example2_rdkit.pdf}
% {figures/NatureLM_retro_example2.pdf}


\caption{Additional examples on retrosynthesis prediction. 
We evaluated the performance of \ourM{}, DeepSeek-R1, and o3-mini-high using a reaction from U.S. Patent ID US11999726B2, granted to Eli Lilly on June 04, 2024. 
The product features two ring systems with a protecting functional group, suggesting that the previous synthesis step likely involved a reaction to connect these rings. Notably, an ether bond links the two rings, with a pyrazine ring on one side and a piperidine ring on the other. Substitution on the pyrazine ring is a common strategy due to its electrophilicity, which often leads to substitution reactions. In this case, NatureLM accurately predicted the cleavage site of the molecule, incorporated a common chlorine atom on the pyrazine ring, and preserved the molecule's stereochemistry, providing a reasonable synthetic strategy. In contrast, both DeepSeek-R1 and o3-mini-high models correctly identified the reactive sites but failed to predict the correct reactants due to poor handling of SMILES representations. For instance, DeepSeek-R1 predicted the pyrazine as pyrimidine, altering the nitrogen atom's position, while o3-mini-high converted the six-membered pyrazine directly into a five-membered imidazole. These errors indicate that these general-purpose language models do not fully understand the relationship between chemical structures and their SMILES representations, hindering their ability to perform accurate reaction predictions.
% \ourM{} successfully proposed the ground-truth reactants from the patent.
}
\label{fig:case_study_reaction2}
\end{figure}

\clearpage 


\begin{figure}[!htpb]
\centering
    \includegraphics[trim=1cm 0 3cm 0, clip, width=\linewidth]{figures/heme_showCase_more.pdf}
    \caption{Additional examples of designing heme-binding proteins based on text or SMILES instructions are shown. The first two rows display results from the text-based design, while the second row corresponds to the SMILES-based design. The yellow models represent structures generated by \ourM{}, whereas the blue models are the reference structures retrieved using the built-in Chimera function. The structures of the generated proteins were predicted using Protenix \cite{Protenix2025}. }
    \label{fig:SI:moreHemeCases}
\end{figure}

\clearpage 




\begin{figure}[!htpb]
\centering
\includegraphics[width=0.6\linewidth]{figures/compare_heme_hemec.png}
\caption{Comparison of the complex structure of the generated protein with heme (yellow model) and heme C (pink model). The protein was obtained using the SMILES-to-protein approach described in Section \ref{sec:heme_case_study}. We observe that they share common structural features. The structures of the generated proteins were predicted using Protenix \cite{Protenix2025}. \\
For the retrieved PDB structure 3MK7 in Fig. \ref{fig:heme_bind_prot}, our generated protein aligns to the pocket region that binds to heme C. To further validate this, we used Protenix to predict the binding of our generated protein to both heme C (PubChem CID: 11987638) and heme. The results demonstrate that heme C fits properly into the designed pocket, supporting the structural compatibility of the generated protein with heme C.\\
This discrepancy arises from the high structural similarity between heme and heme C, as their SMILES representations are nearly identical. Despite this slight misalignment, the output remains biologically relevant because heme-binding proteins often interact with multiple heme derivatives. Furthermore, generating a protein that binds to heme C from the SMILES of heme highlights the algorithm's ability to capture the inherent structural flexibility and functional overlap within the heme family. We will continue improving the algorithm to enhance ligand specificity in future iterations.}
\label{fig:SI:prot_hem_hec}
\end{figure}


\clearpage
\begin{figure}[!htpb]
    \centering
    \includegraphics[trim=5cm 0.5cm 8cm 2cm, clip, width=\linewidth]{figures/comparison_apo_holo.pdf}
    \caption{Comparison of the apo structure of the generated protein, the holo structure in complex with heme, and their aligned structures. Key residues, such as histidine and methionine, occupy similar positions in the pocket region in both the apo and holo structures. This observation suggests that the generated proteins are not only capable of binding heme but also exhibit a structurally pre-formed or conserved binding pocket even in the absence of the ligand. These findings validate the structural plausibility of the designed proteins and their suitability for heme binding.}
    \label{fig:compare_apo_holo}
\end{figure}

\clearpage


\begin{figure}[!h]
\centering
\includegraphics[width=0.75\linewidth]{figures/protein_unconditioned_length_distribution.png}
\caption{Sequence length distribution of generated proteins. The \ourM{} models demonstrate a more natural distribution that closely resembles the reference UR50 sequences, while Mixtral 8x7B and GPT-4 tend to generate shorter sequences.}
\label{fig:protein:unconditioned_generation_sequence_length}
\end{figure}


\begin{figure}
\centering
\includegraphics[width=\linewidth]{figures/prot2rna.boxplot.pdf}
\caption{The distribution of the predicted scores for the RNA sequences in the test set and the generated RNA sequences shows a clear trend. In terms of median values, larger models consistently achieve better predicted scores, indicating stronger binding affinity.}
\label{fig:enter-label}
\end{figure}


\clearpage

\begin{figure}[h]  
    \centering  
    \begin{mdframed}[backgroundcolor=white, linecolor=black, linewidth=1pt]  
    % \textbf{\textcolor{white}{\rule{0pt}{1em}\textcolor{black}{Soluble}}} \\[5pt]
    \textsc{Stable}
    \textit{
    \begin{itemize} % [topsep=0pt]
        \item[-] Please produce a protein sequence that exhibits stability.
        \item[-] I require a stable protein sequence, kindly generate one.
        \item[-] Generate a protein sequence ensuring its stability.
        \item[-] I need a protein sequence that's stable. Please generate it.
        \item[-] Create a stable protein sequence.
        \item[-] Produce a stable protein sequence.
        \item[-] Kindly generate a protein sequence with stability.
        \item[-] I would like you to generate a stable protein sequence.
        \item[-] Please create a protein sequence that ensures stability.
        \item[-] Make a protein sequence that is stable.
    \end{itemize}
    }
    \textsc{Soluble}
    \textit{
    \begin{itemize} % [topsep=0pt]
        \item[-] Generate a soluble protein sequence.
        \item[-] Produce a protein sequence that is soluble.
        \item[-] Create a soluble protein sequence, please.
        \item[-] I require a soluble protein sequence, kindly generate one.
        \item[-] Please produce a protein sequence that exhibits solubility.
        \item[-] Make a protein sequence that is soluble.
        \item[-] Kindly generate a protein sequence with solubility.
        \item[-] I need a protein sequence that's soluble. Please generate it.
        \item[-] I would like you to generate a soluble protein sequence.
        \item[-] Please create a protein sequence that ensures solubility.
    \end{itemize}
    }
    % \textbf{\textcolor{white}{\rule{0pt}{1em}\textcolor{black}{Insoluble}}} \\[5pt]
    \textsc{Insoluble}
    \textit{
    \begin{itemize}
        \item[-] Generate an insoluble protein sequence.
        \item[-] Produce a protein sequence that is not soluble.
        \item[-] Create an insoluble protein sequence, please.
        \item[-] I require an insoluble protein sequence, kindly generate one.
        \item[-] Please produce a protein sequence that lacks solubility.
        \item[-] Make a protein sequence that is not soluble.
        \item[-] Kindly generate a protein sequence without solubility.
        \item[-] I need a protein sequence that's insoluble. Please generate it.
        \item[-] I would like you to generate an insoluble protein sequence.
        \item[-] Please create a protein sequence that ensures insolubility.
    \end{itemize}
    }
    \end{mdframed}  
    \caption{Prompts for conditioned generation} \label{fig:protein:conditioned_prompts_full}
\end{figure} 

\clearpage

\begin{mdframed}[backgroundcolor=white, linecolor=black, linewidth=1pt]
    \textbf{Instruction:} \textit{Tell me about Cas9 regarding its cutting mechanism?} \\
    \textbf{Response:} \\
    Cas9 is a CRISPR-associated protein that can be programmed to cut DNA at a specific location.  It recognizes a short DNA sequence, called a protospacer, and cuts both strands of the DNA at that site. This DNA cutting is done using two nuclease domains, HNH and RuvC, which are repsonsible for cutting the top and bottom strands of the DNA, respectively. The HNH nuclease domain cleaves the top strand, while the RuvC nuclease domain cleaves the bottom strand. The cut made by the nuclease domains leaves the DNA with a sticky end that can ligate to another DNA molecule, such as the chromosome of the cell.  \\

    \textbf{Instruction:} \textit{Could you provide me the advantages and disadvantages of Cas12a, another widely used CRISPR protein?} \\
    \textbf{Response:} \\
    Advantages: \\
    1. High specificty: Cas12a has higher specificity compared to Cas 9, which reduces off-target effects. \\
    2. Simpler PAM requirements: Cas 12a requires a simpler PAM sequence than Cas9, making it easier to target specific genomic loci. \\
    3. Multiplexing: Cas12a can be used for multiplexing genome editing, meaning multiple genomic loci can be edited in a single reaction. \\
    Disadvantages: \\
    4. Lower efficiency: Cas12a is less efficient in terms of indel formation than Cas9. \\
    5. Larger size: Cas12a is a larger protein than Cas9, which can make it harder to deliver the Cas12a system into cells. \\
    6. Lack of donor specificity: Cas12a has a lower efficiency of HDR than Cas9, which makes it difficult to target specific nucleotides for insertion or deletion.
    7. Higher toxicity: Cas12a may casue higher levels of cell death than Cas9, which could impact the overall efficiency of genome editing. \\
    8. Differing DNA repair mechanism: Cas12a and Cas9 utilize DNA different repair mechanisms, which can lead to different outcomes when targeting specific genomic loci. \\
    9. Less versatile: Cas12a is not as versatile as Cas9, as it can only target DNA sequences that contain a TTN PAM sequence. \\
    10. Unclear off-target effects: Cas12a has not been fully characterized in terms of off-target effects, which could lead to unwanted changes in the genome. \\
    11. Difficulty in designing gRNAs: Cas12 requires a longer gRNA sequence compared to Cas9, making it more difficult to design effective gRNAs. \\
\end{mdframed}  
\captionof{figure}{Response of CRISPR gene editing.}\label{SI_fig:case_study:CRISPR}

\begin{mdframed}[backgroundcolor=white, linecolor=black, linewidth=1pt]  
    \noindent
    \textbf{Instruction:} \textit{PD-L1, Programmed Death Ligand-1, is a protein that expressed on cancer cells.  Design a peptide with 10 amino acids that binds to PD-L1.} \\ 
    \textbf{Response:} 
        \text{$\langle$protein$\rangle$}\text{TDEDVLQKIVKRATEDSSYTVKLSNGQTLSVTE} \\
        \text{DSEIKKIQKFRS}\text{$\langle$/protein$\rangle$} \\
\end{mdframed}  
\captionof{figure}{Response of cancer immunotherapy.} \label{SI_fig:case_study:cancer_immunotherapy}


\begin{mdframed}[backgroundcolor=white, linecolor=black, linewidth=1pt]
    \textbf{Instruction:} \textit{Could you explain Lipinski's Rule of Five and its role in evaluating the drug-likeness of chemical compounds?} \\
    \textbf{Response:} Lipinski's Rule of Five, also known as the Rule of Five, is a set ofules developed by Dr. Lipinski that outlines the physical properties of successful orally active drugs. It is a set of simple guidelines that can be used to evaluate the drug-likeness of chemical compounds. It indicates whether a chemical compound with a certain set of properties will have desirable drug-like properties and is likely to be successful as an oral drug. The fiveules that comprise Lipinski's Rule of Five are:
1. The number of hydrogen bond donors should be limited to no more than 
2. The number ofotatable bonds should be limited to no more than 
3. The molecular weight should be less than 500 daltons.
4. The number of hydrogen bond acceptors should be limited to no more than 10.
5. The logD value (a logarithmic measure of a compound's hydrophobicity) should be less than 3.
The application of Lipinski's Rule of Five has been widely adopted in the pharmaceutical industry to prioritize lead compounds for drug development. It is a tool that is used to identify potentially promising compounds and can help in the elimination of compounds with poor pharmaceutical properties.\\
\end{mdframed}  
\captionof{figure}{Response of drug discovery.} \label{SI_fig:case_study:drug_discovery}

\clearpage

\begin{mdframed}[backgroundcolor=white, linecolor=black, linewidth=1pt]  
    \textbf{Instruction:} \textit{How do I wrap a present neatly?} \\
    \textbf{\ourM{}:} To wrap a present neatly, start by deciding on the type of wrapping paper you want to use. Next, tear the edges of the paper to make it easier to fold. Wrap the paper around the gift and use tape to hold it in place. Fold the ends of the paper over to form a neat tuck. Finally, tie a bow around the gift to finish it off.\\
    \textbf{Mixtral:} To wrap a present neatly, follow these steps: 1. Gather your supplies: wrapping paper, scissors, tape, and a ruler or measuring tape. 2. Measure the length and width of the present, and cut a piece of wrapping paper that is at least 2 inches longer and wider than the present. 3. Place the present in the center of the wrapping paper, with the bottom of the present facing up. 4. Fold one side of the wrapping paper over the present, and tape it in place. 5. Fold the other side of the wrapping paper over the present, and tape it in place. 6. Fold the top and bottom edges of the wrapping paper over the present, and tape them in place.7. Flip the present over, and repeat steps 4-6 on the other side. 8. Add a ribbon or bow to the top of the present for a finishing touch.

    \textbf{Instruction:} \textit{Write a captivating movie review for a recently released science fiction film, discussing its plot, characters, and special effects.} \\
    \textbf{\ourM{}:} It's still quite worth seeing.\\
    \textbf{Mixtral:} Captivating Movie Review: "Interstellar" "Interstellar" is a science fiction film directed by Christopher Nolan, starring Matthew McConaughey, Anne Hathaway, and Jessica Chastain. The film follows a group of astronauts as they travel through a wormhole in search of a new home for humanity. The plot of "Interstellar" is complex and thought-provoking, exploring themes of time, space, and the human condition. The characters are well-developed and relatable, with McConaughey delivering a powerful performance as the lead astronaut, Cooper. The special effects in "Interstellar" are breathtaking, with stunning visuals of space and otherworldly landscapes. The film also features a haunting score by Hans Zimmer, which adds to the emotional impact of the story. Overall, "Interstellar" is a captivating and thought-provoking film that will leave audiences pondering the mysteries of the universe long after the credits roll.
    
\end{mdframed}  
\captionof{figure}{Response of AlpacaEval.} \label{fig:case_study:alpacaeval}


\clearpage
\section{Supplementary tables}


\begin{table}[!htbp]
\centering
    % \footnotesize
    % \setlength{\tabcolsep}{0.5mm}
\begin{tabular}{lcccc}
\toprule
& Samples   & Tokens  & Samples & Tokens \\
Data source & (by million) &  (by billion) &  (\%)& (\%)\\
\midrule
Text           & 46.3  & 14.4 & 11.6 & 10.0\\
Small molecule & 68.0  &  4.2 & 17.0 & 2.9 \\
Protein        & 192.0 & 65.2 & 47.9 & 45.3 \\
DNA            & 13.4  & 19.8 & 3.3  & 13.8\\
RNA            & 37.8  & 27.5 & 9.4  & 19.1\\
Material       & 1.1   & 0.02 & 0.3  & 0.014\\
Cross-domain & 41.9  & 12.7 & 10.5 & 8.8\\
\midrule
Total & 400.5& 143.8 & 100 & 100 \\
\bottomrule
\end{tabular}
\caption{Tokens numbers and their distribution of each domain. }
\label{tab:statistics_pretrain_data}
\end{table}

\begin{table}[!htbp]
\centering
\begin{tabular}{cccccccc}
\toprule
Model Parameters & 1B & 8B & 8x7B \\
\midrule
Learning Rate & 1e-4 & 1e-4 & 2e-4 \\
Batch Size (Sentences) & 4096 & 2048 & 1536 \\
Context Length (Tokens) & 8192 & 8192 & 8192 \\
GPU number (H100) & 64 & 256 & 256 \\
\bottomrule
\end{tabular}
\caption{Training recipe of different models.}
\label{tab:training_recipe}
\end{table}

\begin{table}[!htbp]
\centering
\begin{tabular}{lcc}
\toprule
Porperty & Value \\
\midrule
QED & 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\\
HBA & 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\
HBD & 0, 1, 2, 3, 4, 5\\
FSP3 & 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\\
RotBonds & 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\
TPSA & 20, 40, 60, 80, 100, 120\\
\bottomrule
\end{tabular}
\caption{Input property values for property-to-molecule generation}
\label{tab:property_values}
\end{table}

\begin{table}[!htbp]
\centering
\begin{tabular}{lc}
\toprule
Target & Spearman correlation\\
\midrule
Pancreatic alpha-amylase &0.569\\
Large T antigen &0.572\\
DNA (cytosine-5)-methyltransferase 1 &0.517\\
Chaperone protein PapD &0.739\\
Catechol O-methyltransferase &0.638\\
Glyceraldehyde-3-phosphate dehydrogenase, glycosomal &0.503\\
Phosphoenolpyruvate carboxykinase cytosolic &0.501\\
FK506-binding protein 1A &0.606\\
Beta-lactamase class C &0.560\\
OXA-48 &0.680\\
Ubiquitin carboxyl-terminal hydrolase 7 &0.764\\
MAP/microtubule affinity-regulating kinase 4 &0.782\\
\bottomrule
\end{tabular}
\caption{Spearman correlation between docking scores and binding affinity on the selected targets for evaluation.}
\label{tab:targets}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{lcccccccccc}
\toprule
Basic property & QED & QED & donor & donor & LogP & LogP \\
Enzyme & CYP2C9 & CYP3A4  & CYP2C9 & CYP3A4 & CYP2C9 & CYP3A4 & Average \\
\midrule
1B & 0.352 & 0.357 & 0.501 & 0.497 & 0.276 & 0.280 & 0.377 \\
8B & 0.404 & 0.428 & 0.548 & 0.522 & 0.332 & 0.340 & 0.429 \\
8x7B & 0.429 & 0.427 & 0.515 & 0.501 & 0.355 & 0.347 & 0.429 \\
\bottomrule
\end{tabular}
\caption{Joint optimization of metabolism and a basic property.}
\label{tab:joint_basic_cyp}
\end{table}

\clearpage
\begin{table}[b]
\centering
\begin{tabular}{ ccc }
\toprule
Property Name & Training samples & Testing samples \\ 
\midrule
BBBP          & 1272             & 199             \\  
BACE          & 90677            & 152             \\  
LogP          & 8491             & 473             \\  
Donor         & 8526             & 478             \\  
QED           & 8466             & 476             \\  
CYP1A2        & 8076             & 103             \\  
CYP2C9        & 21589            & 199             \\  
CYP2D6        & 8067             & 165             \\  
CYP3A4        & 24376            & 171             \\ 
\midrule
Total         & 179540           & 2416            \\ 
\bottomrule
\end{tabular}
\caption{Statistics of preference data used in RLHF}
\label{tab:data-rlhf}
\end{table}




\clearpage
\section{Supplementary notes}


\subsection{Text-guided basic property optimization of small molecule compounds}
We focus on optimizing the basic molecular properties in this section. The input of \ourM{} includes a text command and a SMILES sequence to be optimized.  We evaluate the optimization results of Quantitative Estimation of Drug-likeness (QED), LogP, and the number of hydrogen bond donors. Following DrugAssist \cite{ye2023drugassist}, we curated a fine-grained procedure. An illustrative example is provided below and the example is from DrugAssist \cite{ye2023drugassist}:

\begin{example}
\noindent\texttt{Instruction: With a molecule represented by the SMILES string }
\newline
\mol{}CC(N)=[NH+]CC(=O)N1CCC(O)(Cn2cnc3c(cnn3-c3ccc(N4CCC5(CCOCC5)CC4)cc3)c2=O)CC1\emol{}, \texttt{propose adjustments that can increase its QED value by at least 0.1 compared to the pre-optimized value to make it more drug-like. }   
\newline
\texttt{Response:}\mol{}CC(C)(C)OC(=O)N1CCC(c2ncc(-c3ccc(CC[B-](F)(F)F)cc3)cn2)CC1\emol{}.
\end{example}

For QED and hydrogen bond donor property optimization, our instructions cover the following scenarios: (i) increase or decrease the property by $\delta$, where both $\delta=0$ and $\delta>0$ are considered, aiming to verify the ability of the model; (2) maintain the properties. For LogP, the instruction is to adjust the LogP value from one specified region to another. 

\begin{table}[!htbp]
\centering
\begin{tabular}{lccc}
\toprule
Model            & QED     & \#Donor & LogP \\
\midrule 
%GPT4  \\ 
LLAMA 3 8B$^*$   & 0.62 / 0.43    &  0.75 / 0.43   & 0.84 / 0.45   \\ 
\ourM{} (1B)    & 0.58 / 0.57    &  0.74 / 0.58   & 0.63 / 0.60 \\ 
\ourM{} (8B)         & 0.65 / 0.45    &  0.81 / 0.44   & 0.80 / 0.42 \\ 
\ourM{} (8x7B) & 0.66 / 0.48 & 0.80 / 0.47  & 0.80 / 0.47  \\ 
\bottomrule
\end{tabular}
\caption{Comparison between the basic property optimization. In each cell, the success rate and uniqueness ratio are reported.}
\label{tab:basic_property_optimization}
\end{table}



The results are in Table \ref{tab:basic_property_optimization}. Notably, as the model size of \ourM{} increases, there is a marked improvement in performance metrics across all properties. For instance, \ourM{} (8B) surpasses \ourM{} (1B) in all categories, indicating enhanced comprehension and manipulation of molecular structures and properties as model complexity grows. Despite DrugAssist$^*$ achieving the highest scores overall, our results demonstrate that by further increasing the model size and fine-tuning the training process, there is significant potential to outperform this baseline. The trend observed with the \ourM{} models underscores the importance of model scale and suggests that with continued advancements in model architecture and training methodologies, even better optimization outcomes can be achieved. This validates the proficiency of \ourM{} in understanding and applying the given instructions to revise molecular properties accordingly. 


\subsection{Supplementary information of RNA generation}\label{app:rna_generation}

Minimum free energy (MFE) calculation: 

\texttt{./ViennaRNA-2.7.0/src/bin/RNAfold -p --MEA \$\{input\_file\}}

Usage of cmscan: 

\texttt{cmscan --rfam --cut\_ga --nohmmonly --tblout results\_tblout --fmt 2 --clanin Rfam/Rfam.clanin Rfam/Rfam.cm \$\{input\_file\}}


\subsection{POSCAR files of crystal structures in Fig. \ref{fig:bulk_caseStudy}}
{{
\footnotesize
\begin{example}
\begin{verbatim}
Generated by VASPKIT code
 1.000000
    7.1831247561033589    0.0000000000000000    0.0000000000000000
    0.0000000000000000    1.4245311887791383    2.4673932588460490
    0.0000000000000000   -1.4245311887791383    2.4673932588460490
   Re   C 
     3     1
Direct
    0.5000000000000000    0.6666666666666643    0.6666666666666643     Re1
    0.8049243600558619    0.3333333333333357    0.3333333333333357     Re2
    0.1950756399441381    0.3333333333333357    0.3333333333333357     Re3
    0.0000000000000000    0.6666666666666643    0.6666666666666643      C1
\end{verbatim}
\end{example}
\begin{example}
\begin{verbatim}
Generated by VASPKIT code
 1.000000
    8.7432980292995008    0.0000000000000000    0.0000000000000000
    0.0000000000000000    1.3846334542329621    2.3982883660601972
    0.0000000000000000   -1.3846334542329621    2.3982883660601972
   Re   Os
     1     3
Direct
    0.0000000000000000    0.3333333333333355    0.3333333333333355     Re1
    0.7492665073023750    0.6666666666666643    0.6666666666666643     Os1
    0.2507334926976250    0.6666666666666643    0.6666666666666643     Os2
    0.5000000000000000    0.3333333333333355    0.3333333333333355     Os3
\end{verbatim}
\end{example}
}}


\subsection{Supplementary information for evaluation metrics}\label{app:more_eval_method}
\subsubsection*{Success Rate for BBBP and CYP Optimization}

For BBBP optimization, our goal is to enhance the BBBP ability of the given compounds. These compounds are selected from the test set of the BBBP dataset in MoleculeNet, and initially, none can cross the BBB. For compounds generated by our AI method, we use BioT5 to predict their ability to cross the BBB. If a compound is predicted to cross, the optimization is considered successful.

For CYP optimization, the objective is to decrease the inhibition ability. Our prediction model uses a sigmoid function in the final layer, where $0$ indicates inhibition and $1$ indicates no inhibition. For an input molecule A and output molecule B, with predicted values $p_a$ and $p_B$, if $p_a>p_b$, the optimization is deemed successful.



\subsection{Shift the focus from general text to scientific sequences}\label{app:compare_with_galactica}
Although there are certain sequence-based foundation models for scientific tasks, their main focus is on text-based tasks and scientific understanding, instead of scientific discovery, i.e., discovering new molecules, proteins, and material. In Table~\ref{tab:comparison_galactica_ourM}, we compare \ourM{} with several sequence models.    %BioGPT~\cite{biogpt2022}, MolXPT~\cite{liu2023molxpt}, and Galactica~\cite{galactica2022} and the details are summarized 

\begin{table}[!htbp]  
    \centering
    \begin{tabular}{@{}p{1.9cm}p{5cm}p{5cm}@{}} % Adjust widths as necessary  
        \toprule  
        \textbf{Model} & \textbf{BioGPT} & \textbf{MolXPT} \\   
        \midrule  
        \textbf{Scope} & Biomedical literature & Text and SMILES \\   
        \midrule  
        \textbf{Core Capabilities} &   
        \begin{tabular}[t]{@{}p{5cm}@{}}  
            Biomedical natural language processing
        \end{tabular} &   
        \begin{tabular}[t]{@{}p{5cm}@{}}
        SMILES understanding and generation
        \end{tabular} \\   
        \midrule
        \textbf{Representative Tasks} &   
        \begin{tabular}[t]{@{}p{5cm}@{}}  
            \textbullet\ Biomedical relation extraction \\  
            \textbullet\ Biomedical question answering \\
            \textbullet\ Biomedical document classification \\
        \end{tabular} &   
        \begin{tabular}[t]{@{}p{5cm}@{}} 
            \textbullet\ Molecule property prediction \\
            \textbullet\ Text-molecule translation \\  
        \end{tabular} \\   
        \midrule
        \textbf{Training Data} &   
        \begin{tabular}[t]{@{}p{5cm}@{}}  
            \textbullet\ Text only\\ 
            \textbullet\ PubMed items before 2021\\ 
            \textbullet\ 15M paper titles and abstracts \\
        \end{tabular} &   
        \begin{tabular}[t]{@{}p{5cm}@{}} 
        \textbullet\ 67\% pure text tokens \\
            \textbullet\ 30M paper titles and abstracts from PubMed \\  
            \textbullet\ 30M SMILES from PubChem \\
            \textbullet\ 8M interleaved sequences between SMILES and text
        \end{tabular} \\   
        \midrule  
        \textbf{Training Strategy} &   
        Trained from scratch &  Trained from scratch \\
        \bottomrule
    \end{tabular}  
    \begin{tabular}{@{}p{1.9cm}p{5cm}p{5cm}@{}} % Adjust widths as necessary  
        \toprule  
        \textbf{Model} & \textbf{Galactica} & \textbf{\ourM{}} \\   
        \midrule  
        \textbf{Scope} & Academic literature & Broader ``language of nature'' \\   
        \midrule  
        \textbf{Core Capabilities} &   
        \begin{tabular}[t]{@{}p{5cm}@{}}  
            \textbullet\ Scientific knowledge and reasoning \\  
            \textbullet\ Scientific writing assistance \\  
        \end{tabular} &   
        \begin{tabular}[t]{@{}p{5cm}@{}}  
            \textbullet\ Scientific entity generation \\  
            \textbullet\ Scientific entity optimization \\ 
        \end{tabular} \\   
        \midrule
        \textbf{Representative Tasks} &   
        \begin{tabular}[t]{@{}p{5cm}@{}}  
            \textbullet\ Scientific Q\&A \\  
            \textbullet\ Citation prediction \\
            \textbullet\ Equation recall \\
        \end{tabular} &   
        \begin{tabular}[t]{@{}p{5cm}@{}} 
            \textbullet\ Molecule optimization \\
            \textbullet\ Protein-to-molecule design \\  
            \textbullet\ Guide RNA engineering \\ 
        \end{tabular} \\   
        \midrule
        \textbf{Training Data} &   
        \begin{tabular}[t]{@{}p{5cm}@{}}  
            %\textbullet\ 106 billion tokens \\  
            \textbullet\ More than 90\% pure text tokens \\  
            \textbullet\ Academic text (e.g., papers, knowledge bases)  
        \end{tabular} &   
        \begin{tabular}[t]{@{}p{5cm}@{}}  
            %\textbullet\ 143 billion tokens \\  
            \textbullet\ 10\% pure text tokens \\  
            \textbullet\ Diverse scientific sequences (e.g., SMILES, FASTA, DNA, RNA, material, text.)  
        \end{tabular} \\   
        \midrule  
        \textbf{Training Strategy} &   
        Trained from scratch &  Continual pre-training on existing LLMs. Incorporates domain-specific instructions \\
        \bottomrule
    \end{tabular}  
    \caption{Comparison between existing sequence models and \ourM{}.}  
    \label{tab:comparison_galactica_ourM}  
\end{table}  

%\paragraph{Overview}
%BioGPT is a domain-specific large language model developed for biological tasks. The model concentrates on biomedical natural language processing tasks, such as biomedical question answering. MolXPT is another domain-specific language model that focuses on text and SMILES. The model has demonstrated significant improvements in molecular understanding and generation tasks.
%Galactica is a large language model designed specifically for science, with a focus on absorbing, reasoning, and generating knowledge from scientific literature and data. It excels in text-based tasks such as equation recall, scientific Q\&A, and citation prediction, leveraging a highly curated academic corpus. 

%\paragraph{Scope and training data}
BioGPT~\cite{biogpt2022} and MolXPT~\cite{liu2023molxpt} are designed for the biomedical and (small) molecular domains. BioGPT is trained with titles and abstracts from PubMed items. MolXPT is trained with PubMed items as well as SMILES from PubChem. Their core capabilities are natural language tasks.
Galactica~\cite{galactica2022} is primarily designed for understanding and reasoning about academic literature. Its core capabilities include recalling equations, answering scientific questions, and performing domain-specific reasoning such as predicting chemical reactions and deriving mathematical proofs. 
% It is trained on a highly curated corpus of approximately 106 billion tokens, predominantly composed of academic text, including papers (e.g., arXiv, PMC), reference materials, knowledge bases, LaTeX equations, and structured factual data. 
It is trained on a highly curated corpus, primarily consisting of academic texts such as research papers (e.g., arXiv, PMC), reference materials, knowledge bases, LaTeX equations, and structured factual datasets. 
Notably, \textbf{over 90\%} of Galactica's training data consists of pure text, reflecting its emphasis on ``academic text'' and its key application in scientific writing.

In contrast, \ourM{} envisions a broader ``language of nature'' that unifies multiple scientific domains and modalities. It is explicitly designed to process diverse sequence-based data, including small molecules (SMILES), proteins (FASTA), materials (composition, space group, and atomic coordinates), as well as DNA and RNA sequences. 	Unlike Galactica, which focuses on understanding and reasoning within scientific text, \ourM{} focuses on generative tasks for scientific discovery, especially cross-domain generation and optimization tasks, such as protein-to-molecule design or guide RNA engineering. 

% \ourM{} is trained on 143 billion tokens, of which \textbf{only 10\%} is pure text. 
Only \textbf{10\%} training data of \ourM{} is pure text. The remaining \textbf{90\%} consists of scientific entities and cross-domain sequences. Furthermore, \ourM{} incorporates cross-domain data where text is interlinked with SMILES, FASTA, and material representations, enabling it to span multiple scientific disciplines through sequence-based formats. This emphasis on structured scientific data allows \ourM{} to bridge multiple domains and facilitates discovery-oriented tasks beyond text-based scientific reasoning.

%BioGPT, MolXPT, and Galactica are trained from scratch on its curated corpus. In contrast, \ourM{} leverages continual pretraining on top of existing large language models, inheriting general language capabilities while specializing in scientific domains. Additionally, \ourM{} incorporates extensive domain-specific instructionsâsuch as âoptimize a moleculeâs LogPââto enhance its performance in specialized scientific tasks, a strategy not emphasized in Galacticaâs training paradigm.

% \subsubsection{Scope and domain coverage}
% Galactica is designed as a language model for science that focuses on absorbing, combining, and reasoning about scientific literature and data. Its primary emphasis is on tasks such as recalling equations, answering scientific questions, and performing domainâspecific reasoning (e.g. chemical reactions and mathematical equations) from a vast curated scientific corpus.

% \ourM{} envisions a ``language of nature'' that unifies multiple scientific domains.
% It is explicitly built to work across diverse sequenceâbased modalities, including small molecules (SMILES), proteins (FASTA), materials (composition plus space group), DNA, and RNA.
% \ourM{} is set up not only to understand science but to enable cross-domain generation and optimization (for example, protein-to-molecule or guide RNA design).




% \subsubsection{Training data}

% Galactica is trained on a highly curated scientific corpus mostly composed of papers (e.g., arXiv, PMC), reference material, knowledge bases, etc., yielding about 106 billion tokens. Galactica emphasizes high-quality ``academic text'', including LaTeX equations, factual data, and reference citations. \textbf{Over 89\%} of the tokens in its training corpus are pure text.

% In contrast, \ourM{} is trained on 143 billion tokens of both scientific text plus ``sequence data'' (e.g., small molecules with SMILES, protein FASTA sequences, material crystals, DNA/RNA). 
% Only \textbf{10\%} of \ourM{}âs training data is pure text, with the remaining data being sequences of scientific entities and cross-domain sequences. Additionally, \ourM{} incorporates cross-domain data where text is interlinked with, or integrated into, SMILES/FASTA/material representations, enabling it to span multiple scientific disciplines through sequence-based formats.












% \begin{myexample}{SFM-based fragment generation}{TamGen_fragment}  
%     \textbf{Instruction: }\\Design a compound with reference to the target \\  
%     $\langle$\texttt{protein}$\rangle$DTKEQRILR$\cdots$EKAIYQGP$\langle$\texttt{/protein}$\rangle$ and the fragment  $\langle$\texttt{fragA}$\rangle$O=c1[nH]cnc2c(O)cc([*:1])c([*:2])c12$\langle$\texttt{/fragA}$\rangle$\\  
%     \textbf{Response: }\\$\langle$\texttt{fragB}$\rangle$Fc1ccc([*:1])cc1.Fc1ccc([*:2])cc1$\langle$\texttt{/fragB}$\rangle$  
% \end{myexample}  

  

 