\section{Dedicated finetuning}\label{sec:dedicate_tune}
% Retrosynthesis aims to identify synthesis routes for target molecules using commercially available starting materials, a critical task in the discovery and manufacture of functional small molecules.
% The appicabiltiy of ML-based retrosynthesis tools largely depends on the accuracy of single-step retrosynthesis prediction.
% We evaluate the capabilities of SFM-Seq for this task.
% Our model is prompted with the task description and the chemical SMILES of the product molecule, and generates potential reactants; see Figure~\ref{fig:retro_prompt_example} for an example.
% We conducted experiments to evaluate our model's efficacy in retrosynthesis prediction task on two datasets: 1) USPTO-50K, a widely used public reaction academia dataset, and 2) Pistachio, which is a large commercial reaction dataset, a large commercial dataset that is approximately 60 times the size of USPTO-50K after quality filtering and deduplication.

% \begin{figure}[h]  
%     \centering  
%     \begin{mdframed}[backgroundcolor=white, linecolor=black, linewidth=1pt]  
%         \textbf{Instruction: }\\
%         \textit{Please suggest possible reactants for the given product.} CC(=O)c1ccc2c(ccn2C(=O)OC(C)(C)C)c1 \\
%         \textbf{Response: }\\ 
%         \underline{
%         CC(=O)c1ccc2[nH]ccc2c1.CC(C)(C)OC(=O)OC(=O)OC(C)(C)C}
%     \end{mdframed}  
%     \caption{Templates for retrosynthesis prediction} \label{fig:retro_prompt_example}
% \end{figure} 




% % \subsection{USPTO-50K}

% Instruction tuning. Training data: USPTO-50K train dataset - 40k reactions. From table~\ref{tab:retro-uspto50k}, we observe that xxx.

% % \begin{table}[!htbp]
% \begin{table}[!h]
% \caption{Retrosynthesis prediction results on USPTO-50K dataset}
% \centering
% \begin{tabular}{lcc}
% \toprule
% & Top-1 accuracy & Top-3 accuracy \\
% \midrule
% GPT-4 & 22.4\% & N/A \\
% LocalRetro~\cite{chen2021localretro} & 51.5\% & 76.5\% \\ 
% R-SMILES~\cite{Zhong2022rsmiles} & 56.0\%  & 79.1\% \\
% EditRetro~\cite{han2024editretro} & 60.8\% & 80.6\% \\ 
% \midrule
% SFM-Seq (1B) & 68.6\% & 86.8\%\\
% SFM-Seq (8B) & 70.2\% & 85.9\% \\
% SFM-Seq (8x7B) & 71.9\% & 87.4\% \\
% \bottomrule
% \end{tabular}
% % \caption{Retrosynthesis prediction results on USPTO-50K dataset. }
% \label{tab:retro-uspto50k}
% \end{table}



\subsection{Retrosynthesis prediction on Pistachio}

We dedicatedly fine-tune our SFM-Seq model to evaluate whether it can match or exceed the performance of specialist models when trained on a large scale commercial dataset. 
We use the Pistachio reaction dataset~\cite{mayfield2017pistachio} for the retrosynthesis prediction task. 
The raw dataset, extracted from U.S., European and WIPO patents, comprises a total of 15M reactions. 
We remove any invalid or duplicated reactions from the dataset.
% Any invalid or duplicate reactions are removed from the dataset.
Subsequently, the cleaned dataset is randomly divided into a training set consisting of 3.1M reactions and a test set comprising 0.2M reactions.
% Then, we randomly split the cleaned data into a training set with
% 3M reactions and a test set with 0.2M reactions.

Before training our SFM-Seq (1B) model, we preprocess input product and output reactants using a root-aligned SMILES format~\cite{Zhong2022rsmiles}.
This format facilitates a streamlined one-to-one mapping between the product and reactant SMILES, thus enhancing prediction efficiency.
Furthermore, we augment the training dataset 10 times to elevate the model's performance. 
During the inference stage, we leverage a well-trained forward reaction prediction model (can be SFM-Seq itself) to re-rank the predicted reactants obtained from beam search~\cite{lin2022improving, xia2017dual}.
Specifically, we initially obtain $K$ candidates $\hat{y}_i$ ($i\in [K]$) from the backward model (SFM-Seq) for product $x$ using beam search.
We then re-rank all candidates using the following rank function:
\begin{equation}
    \alpha l_{f}(\hat{y}_i, x) + (1-\alpha)l_{b}(x,\hat{y}_i),
\end{equation}
where $\alpha$ is a hyperparameter to balance the tradeoff between two functions, $l_{f}(\hat{y}_i, x)$ denotes the relative rank of $x$ in the output beam of input $\hat{y}_i$, as determined by the forward model.
$l_{b}(x, \hat{y}_i)$ denotes the original relative rank of $\hat{y}_i$, that is, $i$.
Table~\ref{tab:retro-pistachio} clearly shows that SFM-Seq (1B) matches leading template-based and template-free specialist models when tested on the large pistachio dataset.

% \begin{table}[!htbp]
\begin{table}[!h]

\centering
\begin{tabular}{lcc}
\toprule
& Top-1 accuracy & Top-3 accuracy \\
\midrule
% GPT-4 &  &  \\
LocalRetro~\cite{chen2021localretro} & 40.8\% & 56.6\% \\
R-SMILES~\cite{Zhong2022rsmiles} & 51.2\% & 67.1\% \\ 
\midrule
SFM-Seq (1B) & 51.4\% & 66.0\% \\
\bottomrule
\end{tabular}
\caption{Retrosynthesis prediction results on Pistachio dataset}
\label{tab:retro-pistachio}
\end{table}

