\section{Prediction tasks}
In addition to the generation and design tasks studied in previous sections, we also studied the predictive capabilities of \ourM{}. 

\subsection{Small molecule prediction tasks}
We evaluated \ourM{} on three molecular property prediction tasks from MoleculeNet \cite{moleculenetpaper}: (i) predicting whether a molecule can cross the blood-brain barrier (BBBP); (ii) predicting whether a molecule can bind to the BACE receptor (BACE); (iii) predicting the toxicity of a molecule associated with 12 targets (Tox21). An illustrative example is presented below:

\begin{example}
\textbf{Instruction:}\\
\texttt{Can \mol{}C1(c2ccccc2)=CCN(C)CC1\emol{} traverse the blood-brain barrier?}\\ %Please answer `Yes' if it can traverse the blood-brain barrier, and `No' if it is cannot.}  \\
\textbf{Response:} \\
\texttt{Yes}.
\newline
\newline
\noindent\textbf{Instruction:} \\
\texttt{Could the compound \mol{}N(O)=C1CCC([NH2+]CC(O)C
\noindent(Cc2cc(F)cc(F)c2)NC(C)=O)(c2cccc(C(C)(C)C)c2)CC1\emol{} potentially restrain beta-secretase 1?}\\% Please answer `Yes' if it could potentially restrain beta-secretase 1, and `No' if it could not.}  \\
\textbf{Response:} \\
\texttt{Yes}. 
\end{example}

To determine the probability of a ``Yes'' or ``No'' response, we first extract the probabilities output by the NatureLM, denoting the probability of ``Yes'' as $p_1$ and the probability of ``No'' as $p_2$. We then normalized these probabilities: the probability of ``Yes'' is calculated as $p_1/(p_1+p_2)$ while the probability of ``No'' is $p_2/(p_1+p_2)$. 

All tasks in this subsection are measured by AUROC\footnote{\url{https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.roc_auc_score.html}}. The results are reported in Table \ref{tab:molnet}. Generally, larger models achieve better performance, while there is still a gap between the current \ourM{} and the state-of-the-art specialist models. 

\begin{table}[!htpb]
\centering
\begin{tabular}{lcccc}
\toprule
& BBBP & Bace & Tox21  \\
\midrule
DVMP \cite{2021jinhuaDVMP} & 78.1 & 89.3 & 78.8 \\
BioT5 \cite{PeiQizhi2023BioT5} & 77.7 & 89.4 & 77.9  \\
NatureLM (1B) & 71.1 & 79.4 & 68.3 \\
NatureLM (8B) & 70.2 & 82.0 & 69.8 \\
NatureLM (8x7B) & 73.7 & 83.1 & 72.0\\
\bottomrule
\end{tabular}
\caption{Molecular property prediction on MoleculeNet \cite{moleculenetpaper}. The evaluation metric is the AUROC score. }
\label{tab:molnet}
\end{table}

\subsection{Protein prediction tasks}

We evaluated the \ourM{} on four protein property classification tasks, including solubility prediction, stability prediction, and protein-protein interaction (PPI) prediction for both human and yeast proteins. These datasets as well as the data splits are adopted from the PEER benchmark~\cite{xu2022peer}. An example is provided below:

\begin{example}
\textbf{Instruction:}\\
\texttt{Does the sequence of this protein suggest it would be stable? Please answer `Yes' if it is stable and `No' if it is not.} \pro{}\text{TTIKVNG \ldots KVTR}\epro{} \\
\textbf{Response:} \\
\texttt{No}.
\newline
\newline
\noindent\textbf{Instruction:} \texttt{Could these proteins interact, considering their sequences? The first protein is} \\
\pro{}MPPS \ldots VETVV\epro{}, \texttt{the second protein is} \pro{}MSLHF \ldots PLGCCR\epro{}. \texttt{Please respond with `Yes' if the proteins can interact and `No' if they cannot.} \\
\textbf{Response:} \\
\texttt{Yes} 
\end{example}  

\begin{table}[!h]
\centering
\begin{tabular}{ccccc}
\toprule
Model Setting & Solubility & Stability & Human PPI & Yeast PPI \\
\midrule
Literature SOTA & 0.702 & - & 0.881 & 0.661 \\
SFM-Protein (650M) \cite{he2024sfm} & 0.744 & 0.583 & 0.852 & 0.628 \\
\midrule
\ourM{} (1B) & 0.684 & 0.682 & 0.781 & 0.561 \\
\ourM{} (8B) & 0.714 & 0.635 & 0.848 & 0.604 \\ % 8b_dialogue_3v1_bs2048_steps_9380
% SFM-Seq (8x7B) & 0.751 & 0.701 & 0.879 & 0.643 \\ % unknown source
\ourM{} (8x7B) & 0.698 & 0.723 & 0.776 & 0.586 \\ % 8x7b_steps_2585
\bottomrule
\end{tabular}
\caption{Protein understanding task comparison (accuracy). Please note that the \ourM{} models are trained for various diverse tasks in a unified way and evaluated separately on these tasks by the same model, while the state-of-the-art models are trained and tested individually for each task. }
\label{tab:protein:classification}
\end{table}

Table \ref{tab:protein:classification} presents the accuracy of our models on various protein understanding tasks. Overall, the results highlight that our unified \ourM{} models perform competitively with task-specific models, even surpassing them in certain tasks like stability prediction. This demonstrates the effectiveness of our training strategy, where a single model can learn and generalize across diverse protein understanding tasks without the need for separate models for each task.

\subsection{DNA prediction tasks}\label{sec:dna_property_pred}
We selected two classification tasks to assess the model's capability of identifying significant sequence motifs implicated in human gene regulation. These tasks include the identification of promoters and transcription factor binding sites.  We utilized datasets from the Genome Understanding Evaluation (GUE, see Appendix B.2 of \cite{zhou2024dnabert2} for a summary), converting them into a format suitable for instruction tuning. % It is important to note that our current model was trained on DNA sequences of 1.5k base pairs in length. Consequently, our focus was on DNA tasks that do not necessitate extensive sequence context. 
An example is shown below:

\begin{example}
\textbf{Instruction:}\\
\texttt{Verify if there is a promoter region within \dna{}TGGACT$\cdots$TGAGCTC\edna{}?}  \\
\textbf{Response:} \\
\texttt{Yes}.
\newline
\newline
\noindent\textbf{Instruction:} \\
\texttt{Can the sequence \dna{}GCCTGCCAG$\cdots$AAAAC\edna{} be classified as a transcription factor binding site?}  \\
\textbf{Response:} \\
\texttt{No}. 
\end{example}

\begin{table}[!h]
\centering
\begin{tabular}{lccc}
         \toprule
         Model & Promoter detection & Core promoter detection & TF binding\\
         \midrule
         NT-2500M-multi \cite{dalla2023nucleotide} & 0.881 & 0.716 & 0.633 \\
         DNABERT2 \cite{zhou2023dnabert} & 0.842 & 0.705 & 0.701 \\
         \midrule
         \ourM{} (1B) & 0.805 & 0.571 & 0.524 \\
         \ourM{} (8B) & 0.827 & 0.595 & 0.549 \\
         \ourM{} (8x7B) & 0.835 & 0.602 & 0.560 \\
         \bottomrule
\end{tabular}
\caption{Performance comparison of various models on DNA property prediction tasks, evaluated using Matthews Correlation Coefficient (MCC).}
\label{tab:DNA:DNA prediction tasks}
\end{table}
Table \ref{tab:DNA:DNA prediction tasks} presents the results of our experiments, evaluated using the Matthews Correlation Coefficient (MCC). For the Transcription Factor Binding prediction task, we conducted separate predictions on specific ChIP-seq datasets: POLR2A ChIP-seq on human HUVEC, POLR2A ChIP-seq on human ProgFib, PAX5 ChIP-seq protocol v041610.1 on human GM12892, TRIM28 ChIP-seq on human U2OS, and MXI1 ChIP-seq on human H1-hESC produced by the Snyder lab. We then calculated the average performance across these datasets. Despite a performance gap between our models and the state-of-the-art, the observed improvements with increasing model sizes suggest potential for further advancements. These findings indicate that larger models may more effectively capture the complex regulatory motifs involved in human gene regulation.

%---- Chuan's original results; which seems to be inconsistent with mcc
% i use zekun's now
% SFM-Seq (1B) & 90.2 & 78.5 & 76.1 \\
% SFM-Seq (8B) & 91.3 & 79.7 & 77.3 \\
% SFM-Seq (8x7B) & 91.8 & 80.1 & 77.8 \\

% In addition to classification, we developed two regression tasks aimed at predicting enhancer activity. The data for these tasks were sourced from massively parallel reporter assays, as detailed in references  "ref/The Evolution, Evolvability, and Engineering of Gene Regulatory DNA" and "Machine Learning Sequence Prioritization for Cell Type-Specific Enhancer Design." We fine-tuned the HyenaDNA 1M model to serve as a baseline for these comparisons.

% \begin{table}[!h]
%     \caption{The models' averaged performance on the 2 DNA regression tasks.}
%     \centering
%     \begin{tabular}{c|c|c|c}
%          \hline
%          Model & Human enhancer activity (RMSE) & Yeast enhancer activity (RMSE)\\
%          \hline
%          HyenaDNA-1M & 0.91 & 0.70 \\
%          \hline
%          SFM-Seq (1B) & 0.356 & 0.337 \\
%          SFM-Seq (8B) & 0.331 & 0.338 \\
%          SFM-Seq (8x7B) & 0.34 & 0.339 \\
%          \hline
%     \end{tabular}
%     \label{tab:DNA:DNA prediction tasks}
% \end{table}
