\section{Literature Review}
\label{sec:lit_review}

\subsection{IoT Security}
In the IoT context, the efficiency of traditional security approaches like perimeter defenses and signature-based IDS are relatively falling into inefficiency due to the dynamic nature of IoT ecosystems, which are heterogeneous by nature. Most of them are not even able to mitigate modern threats that include DDoS, which depends on the high number of IoT devices with vulnerabilities to perform service disruption along with resource exhaustion ____. The rapid proliferation of IoT devices has expanded the attack surface, necessitating more robust and adaptive security measures ____.
\vspace{\baselineskip}

\subsection{ML-Enabled Security}
The potential of ML in strengthening IoT security includes conducting real-time anomaly detection, predictive analytics, and adapting responses against ever-evolving threats. Among these models, ensemble models, especially XGBoost and Random Forest, show the greatest efficiency in identifying deviations in network traffic patterns that could hint at malicious activity ____. While effective, ML-based solutions are still plagued by problems of computational overhead, algorithmic bias, and explainability gaps, making them ineffective and very difficult to deploy at scale in IoT environments ____.
\vspace{\baselineskip}

\subsection{Zero-Trust Security and Network Sclicing}
Network slicing is a technique that creates multiple virtual networks on a single physical network. Network slicing enables virtualized networks to operate on the same physical network infrastructure. The basic idea of network slicing is to “slice” the original architecture into multiple logical and independent networks. These sliced networks can then be configured to effectively meet various application needs and service requirements.
 Network slicing and Micro-segmentation can not only make up for the shortcomings of firewalls but when implemented network-wide, can remove the need for a firewall altogether. Zero-Trust security ensures continuous authentication and authorization of devices and communications to remove implicit trust within the network boundary. It follows the principle "never trust, always verify," which drastically reduces the chances of lateral movement on the part of the attacker ____. Coupled with real-time network traffic analysis and dynamic policy enforcement, this makes it highly suitable for the protection of IoT ecosystems-especially in the context of 5G/6G ____.
\vspace{\baselineskip}

\subsection{Zero-Touch Provisioning}
Zero-Touch provisioning automates the supply chain for onboarding IoT devices in a secured manner with minimum human intervention. This reduces the chances of configuration errors, ensuring that each device is authenticated, securely booted, and checked against the specified policies before joining the network ____. This is particularly important for the Zero-Touch scaling of security as IoT networks continue to increase in number and complexity.
\vspace{\baselineskip}



\subsection{Methodology and Dataset Details}
\label{sec:methodology}

For this work, we used a labeled dataset of IoT network traffic that had been anonymized so as to be able to apply machine learning analysis. The dataset contains typical features of network traffic, such as packet size and rate, session duration, protocol type, and labels indicating whether the traffic was part of a DDoS attack or normal activity.

\vspace{\baselineskip}
To prepare the data for analysis, we conducted several preprocessing steps:
\begin{itemize}
    \item \textbf{Data Cleaning}: Removed incomplete or corrupt records that could skew results.
    \vspace{\baselineskip}
    \item \textbf{Feature Selection}: Selected relevant features based on their correlation with DDoS attack detection.
    \vspace{\baselineskip}
    \item \textbf{Normalization}: Standardized feature values to ensure consistency in scale, using Min-Max scaling. For each feature \(x\), the normalized value \(x'\) is calculated as:
    \begin{equation}
        x' = \frac{x - \min(x)}{\max(x) - \min(x)}
    \end{equation}
\end{itemize}

\subsection{Selected ML Models}
We evaluated five machine learning models based on their suitability for classification tasks within cybersecurity contexts[21].

\begin{figure}[H]
\centering
\includegraphics[width=0.48\textwidth]{Model_Comparison.png}
\caption{Comparison of Machine Learning Models}
\label{fig:model_comparison}
\end{figure}


\subsubsection{\textbf{XGBoost}}
The gradient-boosted decision tree model XGBoost ____ is meant to be quick and efficient. It works well with complicated datasets because it introduces regularisation to reduce overfitting. The model optimizes an objective function \( \mathcal{L} \), which includes a loss term and a regularization term:
\begin{equation}
    \mathcal{L} = \sum_{i=1}^{n} l(y_i, \hat{y}_i) + \sum_{k=1}^{K} \Omega(f_k)
\end{equation}
where \( l(y_i, \hat{y}_i) \) is the loss function and \( \Omega(f_k) \) represents the regularization applied to each tree.

\vspace{\baselineskip}

\subsubsection{\textbf{RandomForest}}
Random Forest is an ensemble learning methodology whereby many decision trees are constructed during training ____. It handles big datasets with grace and also reduces overfitting. A class is chosen based on the collective vote provided by the individual trees of the forest. Typically, decision trees are split at the nodes depending on entropy or Gini Impurity Index:
\begin{equation}
    \text{Gini} = 1 - \sum_{i=1}^{C} p_i^2
\end{equation}
where \( p_i \) is the proportion of instances which belong to class \( i \).

\vspace{\baselineskip}

\subsubsection{\textbf{K-Nearest Neighbors (KNN)}}
KNN is an instance-based learning technique that uses the majority class of its \( k \) closest neighbours to classify a sample. Euclidean distance is used to determine the separation between data points:
\begin{equation}
    d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
\end{equation}
\vspace{\baselineskip}

\subsubsection{\textbf{Stochastic Gradient Descent (SGD)}}
SGD is an optimisation technique that iteratively updates model parameters to minimize a loss function:
\begin{equation}
    \theta := \theta - \eta \nabla_\theta J(\theta)
\end{equation}
where \( \theta \) represents the model parameters, \( \eta \) is the learning rate, and \( J(\theta) \) is the cost function.
\vspace{\baselineskip}

\subsubsection{\textbf{Naïve Bayes}}
Naïve Bayes is a probabilistic classifier that assumes feature independence, using Bayes' theorem:
\begin{equation}
    P(C_k | x) = \frac{P(x | C_k) \cdot P(C_k)}{P(x)}
\end{equation}

\vspace{\baselineskip}

\subsection{Evaluation Metrics}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth]{Model_Evaluation_Metrices.png}
    \caption{Metrics used for model evaluation}
    \label{fig:model_evaluation_metrics}
\end{figure}

Evaluation Metrices used are as follows:
\begin{itemize}
    \item \textbf{Accuracy}: 
    \begin{equation}
        \text{Accuracy} = \frac{\text{TP + TN}}{\text{TP + TN + FP + FN}}
    \end{equation}
    \item \textbf{Precision}:
    \begin{equation}
        \text{Precision} = \frac{\text{TP}}{\text{TP + FP}}
    \end{equation}
    \item \textbf{Recall}:
    \begin{equation}
        \text{Recall} = \frac{\text{TP}}{\text{TP + FN}}
    \end{equation}
    \item \textbf{F1 Score}:
    \begin{equation}
        \text{F1} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision + Recall}}
    \end{equation}
    \item \textbf{AUC}:
    \begin{equation}
        \text{AUC} = \int_{0}^{1} \text{TPR}(\text{FPR}) \, d(\text{FPR})
    \end{equation}
\end{itemize}
\vspace{\baselineskip}