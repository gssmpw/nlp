





\begin{table*}[t]
\centering
\begin{tabular}{lccccccc}
\toprule
Model & \Tkfour $\uparrow$ & \Tkseven $\uparrow$ & \Tscannet $\downarrow$ & \makecell{\Twaymo $\uparrow$} & SSv2 $\uparrow$ & \makecell{\Tpose $\downarrow$} & \makecell{\Tpt $\uparrow$} \\
\midrule
\multicolumn{8}{l}{\textit{Methods pretrained on image tasks}} \\
I-JEPA-600M                 & 0.617 & 0.485 & 0.147 & 0.483 & 0.451 & 2.299 & 0.515 \\
ImageMAE-600M               & 0.612 & 0.496 & 0.117 & 0.501 & 0.458 & 2.197 & 0.566 \\
SigLIP 1.7B  & 0.760 & 0.663 & 0.154 & 0.464 & 0.448 & 2.442 & 0.396 \\
DinoV2-300M                 & 0.702 & 0.604 & 0.108 & 0.502 & 0.507 & 2.307 & 0.526 \\
I-WALT 284M                 & 0.527 & 0.396 & 0.199 & 0.459 & 0.360 & 2.095 & 0.449 \\
\midrule
\multicolumn{8}{l}{\textit{Methods pretrained on video tasks}} \\
V-JEPA-300M     & 0.685 & 0.557 & 0.132 & 0.629 & 0.658 & 0.507 & 0.733 \\
V-JEPA-600M     & 0.696 & 0.572 & 0.123 & 0.620 & 0.684 & 0.409 & 0.737 \\
VideoMAEv1-600M & 0.675 & 0.543 & 0.117 & 0.620 & 0.665 & 0.583 & 0.708 \\
V-WALT 284M     & 0.552 & 0.414 & 0.185 & 0.586 & 0.510 & 0.826 & 0.756 \\
V-WALT 724M     & 0.571 & 0.445 & 0.151 & 0.587 & 0.547 & 0.814 & 0.741 \\
V-WALT 1.9B     & 0.615 & 0.488 & 0.124 & 0.597 & 0.597 & 0.617 & 0.735 \\
\bottomrule
\end{tabular}
\caption{
\textbf{Comparison with state-of-the-art methods on video recognition, depth estimation, tracking, and camera pose estimation tasks} -- All results presented here were obtained using the same training and evaluation protocol with frozen backbones and trainable readouts.
}
\label{tab:video_baselines}
\end{table*}




