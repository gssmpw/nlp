\section{Discussion}
\label{sec:conclusion}

In this work, we systematically compared the same model architecture trained for video versus image generation, analyzing the performance of their latent representations on various downstream tasks.
Results show that video diffusion models consistently outperform their image counterparts, especially for tasks that require motion or spatial understanding.
We further analyzed features extracted from different layers and with varying noise levels, as well as the effect of model size and training budget on representation and generation quality.
This work marks the first direct comparison of video and image diffusion objectives for visual understanding, offering insights into the role of temporal information in representation learning.

Our study has several avenues for future work.
Firstly, we limited our study to a single model architecture (WALT \cite{walt}) for a clean comparison that would not be possible for other models that differ considerably between image and video architectures (\eg, SD and SVD), see \cref{sec:method:walt}.
Potential extensions of this work could explore these comparisons across a wider range of unified model architectures as they become available, providing a more comprehensive understanding of the representational power of video and image diffusion models.

Secondly, our investigation primarily focused on the performance of these models on visual understanding tasks.
Future research could delve deeper into the intersection of generative capabilities and representation learning, potentially exploring how the quality of generated images and videos influences and is influenced by the learned representations.
This could lead to new insights and techniques for improving both the generative and representational capabilities of these models.

We believe this study contributes to the ongoing exploration of video and image diffusion models, and we hope our findings inspire further research into their potential for visual understanding and beyond.

\balance
