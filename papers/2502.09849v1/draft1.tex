XAI Taxonomy:
\begin{itemize}
    \item Interpretability Type
    \begin{itemize}
        \item Intrinsic
        \item Post Hoc
    \end{itemize}
    \item Model Dependency
    \begin{itemize}
        \item Model-Specific
        \item Model-Agnostic
    \end{itemize}
    \item Scope of Interpretability
    \begin{itemize}
        \item Local
        \item Global
    \end{itemize}
\end{itemize}


Human-Centered Evaluation Taxonomy:

\begin{itemize}
    \item Application-Grounded Evaluation
    \item Human-Grounded Evaluation
    \item Proxy Evaluation
\end{itemize}


Methods:
\begin{itemize}
    \item Primary Methods
    \begin{itemize}
        \item Think-Aloud Studies
        \begin{itemize}
            \item Concurrent Think-Aloud
            \item Retrospective Think-Aloud
            \item Hybrid Approaches
        \end{itemize}
        \item Interviews
        \begin{itemize}
            \item Unstructured Interviews
            \item Semi-Structured Interviews
            \item Structured Interviews
            \item Focus Groups
            \item Retrospective Interviews
        \end{itemize}
        \item Surveys
    \end{itemize}
    \item Experimental Designs
    \begin{itemize}
        \item Within-Subjects Design
        \item Between-Subjects Design
    \end{itemize}
\end{itemize}
   

Healthcare taxonomy:

\begin{itemize}
    \item Healthcare
    \begin{itemize}
        \item Clinical Medicine
        \begin{itemize}
            \item Orthopedics
            \item Psychiatry
            \item Internal Medicine
            \item etc.
        \end{itemize}
        \item Public Health
        \begin{itemize}
            \item Epidemiology
            \item Environmental Health
            \item etc.
        \end{itemize}
        \item Allied Health
        \begin{itemize}
            \item Nursing
            \item Radiology
            \item Physiotherapy
            \item etc.
        \end{itemize}
    \end{itemize}
\end{itemize}

%\item Methods for Local Interpretability
%\begin{itemize}
%    \item Individual Conditional Expectation (ICE) curves
%    \item Local surrogate models (e.g., LIME)
%    \item Scoped rules or anchors
%    \item Counterfactual explanations
%    \item Shapley values (and SHAP)
%\end{itemize}
%\item Methods for Global Interpretability
%\begin{itemize}
%    \item Partial Dependence Plots (PDP)
%    \item Accumulated Local Effect Plots (ALEP)
%    \item Feature interaction analysis (e.g., H-statistic)
%    \item Permutation feature importance
%    \item Global surrogate models
%\end{itemize}
%\item Explanation Representation
%\begin{itemize}
%    \item Quantitative
%    \item Visual
%    \item Textual/Logical
%\end{itemize}








\section{Notes... - to delete}
"""
\cite{ackerman2000intellectual} argues that there is an inherent gap between the human
requirements in the technology deployment contexts (which we refer to as socio-requirements hereafter) and the technical solutions.
"""

"""
\cite{liao2023rethinking}
Our central proposal is that model evaluation should
make a discipline that takes up the mission of understanding
and narrowing the socio-technical gap.
"""


Human evaluations are costly 





""" % Rework, this is copy/paste - LIMITATIONS
However, despite the ample body of research, several challenges
still remain open. Explainability methods sufer from issues of robustness \cite{slack2020fooling}, intra-method disagreement \cite{krishna2022disagreement}, and human understandability \cite{zhang2019dissonance} â€“ of experts and laypeople alike \cite{balayn2022can}.
"""

% some pills. to rewrite, they just express the concept 

It depends on the expectations of the XAI tool from the beginning. 

It is always good to perform a formative study in the beginning to assess the identification of the stakeholders needs. Therefore, some may request either an explainable component, and some others not. So, check with their needs. Also, check with the type of the explainable they want making sure it is relevant with the problem at hands.


Talk about theory driven applications to develop this kind of systems


highlight the need of before-after system evaluation, so benchmarking with no XAI 

participatory AI (see food waste paper) 




plan:
1. identification of stakeholders 
2. ask them their needs 
3. develop solution, discuss participatory AI 
4. evaluate - human centered method 



check: https://arxiv.org/pdf/2306.03100v1
Figure 1
Section 5
tradeoff between methodologies considering the cost 

% Hong's suggestions
think what is unique in the healthcare context, comparing to other evaluations context. clinical decision support system are high stake, so decisions will have a lot of impact on patients lives. have evaluations early one to have sure the system is alignesd with stakeholders perspectives. cdss will involve primarily twos stakeholders groups,clinicians and patients, with difference literacy levels,a nd understanding. develop methods for each one, bc of that. also find tailored  method (new method) for this specific. both XAI and HCI methods. 

Insert somewhere: \cite{pumplun2023bringing}, they developed a protocol of an explainable ML-based CDSS based upon some principles. 
