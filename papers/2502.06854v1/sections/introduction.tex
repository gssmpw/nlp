\section{Introduction}
\label{sec:introduction}

Intermediate Representations (IRs) play a pivotal role in compiler design by segmenting the compilation process into front-end, middle-end, and back-end phases~\cite{reissmann2020rvsdg,webb2021formal,sbirlea2015polyhedral}. They support efficient transformations, optimizations, and analyses that are decoupled from specific programming languages, making them adaptable to diverse architectures~\cite{2013intermediate}. 

Beyond compilation, IRs are essential for various code intelligence tasks, including \textit{vulnerability detection}~\cite{chenguang_zhu__2024,jiang2024happa}, \textit{code comprehension and generation}~\cite{dawei_yuan__2023,jiang2024resilience}, \textit{clone detection}~\cite{indraneil_paul__2024}, and \textit{binary-to-source matching}~\cite{jiawei_mao__2023,josh_collyer__2023}. Unlike high-level programming languages, IRs follow an instruction-like format, encoding low-level details such as control flow dependencies, instruction transformations, and memory manipulations. These characteristics introduce unique challenges in \textit{structural analysis}, \textit{syntactic processing}, \textit{semantic understanding}, and \textit{execution reasoning}, making IR comprehension fundamentally different from natural language or source code modeling.

\begin{figure*}
    \centering
    \includegraphics[width=0.92\linewidth]{images/LLMinIR-overview5.0_icml.drawio.pdf}
    \vspace{-1em}
    \caption{Overview of the study design.}
    \label{fig:overview}
    \vspace{-1em}
\end{figure*}

Current IR processing methods, such as NCC~\cite{2020ir2vec}, embed IR instructions as linear text representations using models like Word2Vec~\cite{church2017word2vec}, while BERT-style pretraining~\cite{2018bert,2020ir2vec,niu2024fair} has improved contextual modeling for code. However, these methods lack awareness of control flow structures and execution semantics, limiting their generalization to IR-specific tasks such as \textit{Control Flow Graph} (CFG) reconstruction, bug detection, and execution reasoning. Since IR execution relies on low-level operations beyond syntax, models that fail to capture control flow relationships struggle with execution-aware IR tasks. 
Given these limitations, \textit{{can large language models (LLMs) bridge this gap and reason about IRs effectively?}}

To effectively leverage LLMs for IR-related tasks, we must first address the following question:
\emph{Do LLMs understand IRs, and to what extent can they reason about them?} 
The answer to this question will determine whether general-purpose LLMs suffice for IR processing or if dedicated IR-trained models are necessary.


To systematically evaluate LLMs' comprehension of IRs, we examine their performance across three dimensions:
\begin{itemize}[nolistsep,left=0pt]
\renewcommand{\labelitemi}{$\triangleright$}
\item \textbf{Structural Understanding}: \emph{Can LLMs reconstruct Control Flow Graphs (CFGs) from IRs accurately?}
\item \textbf{Syntactic and Semantic Comprehension}: \emph{Can LLMs recover high-level representations by decompiling IRs and summarizing their functionality?}
\item \textbf{Execution Reasoning}: \emph{Can LLMs simulate program execution based on IRs and infer correct outputs?}
\end{itemize}

Our study examines five state-of-the-art LLMs—GPT-4~\cite{openai2023gpt4}, GPT-3~\cite{brown2020gpt3}, LLaMA 3.1~\cite{touvron2023llama}, Gemma 2~\cite{team2024gemma}, and Code Llama~\cite{rozière2024codellamaopenfoundation}—on a benchmark dataset derived from HumanEval~\cite{zheng2023codegeex}, consisting of 164 C++ programs and their corresponding IRs.




\mypara{Take-Away Findings}
Our evaluation reveals several take-away findings that may inspire further research.
\begin{itemize}[nolistsep,leftmargin=*]
    \item \emph{LLMs recognize syntax but struggle with control flow (Tasks 1--4)}: LLMs can parse IR syntax, identifying variables, arithmetic operations, and memory operators. However, they struggle with control flow instructions (e.g., \texttt{br}, \texttt{jmp}), leading to errors in CFG reconstruction.
    \item \emph{Limited Semantic Understanding (Tasks 2--4)}: While LLMs process individual syntax elements, they often fail to capture deeper execution semantics. Two major challenges are:
    \begin{itemize}[nolistsep,leftmargin=*]
        \item \emph{Random Skipping}: LLMs sometimes omit critical IR instructions, leading to incomplete decompilation or flawed execution reasoning.
        \item \emph{Granularity Issues}: While LLMs recognize high-level function structures, they struggle with instruction-level details, often relying on pattern-based inference rather than precise reasoning.
    \end{itemize}
    
    \item \emph{Loop handling remains a fundamental challenge (Tasks 1 and 4)}: LLMs fail to reconstruct loop structures in CFGs and frequently misinterpret iteration behaviors and termination conditions during execution reasoning.
\end{itemize}

While LLMs exhibit some capability in IR-related tasks, their limitations suggest clear areas for improvement. Specifically, 1) Enhancing control flow comprehension could improve CFG reconstruction accuracy; 2) Refining semantic reasoning across multiple granularities may enable better instruction-level analysis; 3) Strengthening loop handling mechanisms could reduce errors in iteration reasoning.
These findings highlight the need for IR-specific adaptations to make LLMs more effective in program analysis.


Our main contributions are as follows:

\begin{itemize}[nolistsep,leftmargin=*]
    \item To the best of our knowledge, this is the first study to explore LLMs' ability to understand and reason about IRs, covering \textbf{structure, syntax, semantics, and execution}.
    \item \textbf{Comprehensive empirical evaluation}.  
    We evaluate state-of-the-art LLMs across multiple IR-processing tasks, introducing experiments, evaluation metrics, and analysis.

    \item \textbf{Insights for improving IR comprehension}.  
    Our findings suggest key areas for improvement, including control flow awareness, execution reasoning, and fine-grained semantic understanding, paving the way for future IR-specific model adaptations.

\end{itemize}
