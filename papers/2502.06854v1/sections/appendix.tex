\section{Comprehensive Related Work}
\mypara{LLMs for High-level Programming Languages}  
The advancements in pre-trained LLMs for NLP have extended into code understanding, enabling models to comprehend high-level programming languages such as Python, C++, and Java. Models like GPT \cite{brown2020gpt3}, GPT-4 \cite{openai2023gpt4}, LLaMA \cite{touvron2023llama}, and Claude 3 \cite{claude3} have demonstrated strong capabilities in tasks such as code generation, where they translate natural language descriptions into executable source code. Specialized models, including StarCoder \cite{li2023starcoder}, Code Llama \cite{rozière2024codellamaopenfoundation}, DeepSeek-Coder \cite{guo2024deepseek}, and Code Gemma \cite{team2024codegemma}, further refine these capabilities, addressing complex coding tasks and advancing software engineering applications \cite{zhao2023survey}.

Pre-trained LLMs have revolutionized NLP by learning versatile language representations from large-scale corpora, which can then be fine-tuned for specific downstream tasks \cite{qiu2020pretrainModel}. Early models like Word2Vec \cite{mikolov2013efficient} and GloVe \cite{pennington2014glove} captured basic word semantics but lacked deeper contextual understanding \cite{han2021pre}. The advent of deep transformer-based models like GPT \cite{radford2019gpt} and BERT \cite{devlin2018bert} introduced context-aware modeling, enhancing language comprehension~\cite{vaswani2017attention}.

These LLMs have been adapted to the programming domain, leading to specialized models such as CodeBERT \cite{feng2020codebert}, GraphCodeBERT \cite{guo2020graphcodebert}, UnixCoder \cite{guo2022unixcoder}, and CodeT5 \cite{wang2021codet5}. These models integrate Transformer architectures to encode code semantics effectively. Enhancements such as data flow integration in GraphCodeBERT \cite{guo2020graphcodebert}, multi-modal learning in UnixCoder \cite{guo2022unixcoder}, and encoder-decoder frameworks in CodeT5 \cite{wang2021codet5} enable improved code comprehension and generation.

\mypara{IR Representation Learning}  
IR representation learning incorporates structural and flow-based features such as token sequences~\cite{peng2021could}, control flow graphs (CFGs)~\cite{2020ir2vec, yu2020codecmr}, and control-data flow graphs (CDFGs)~\cite{ben2018neural, brauckmann2020compiler, cummins2021programl}.

For model architectures, graph neural networks (GNNs) have been widely employed to encode CFG and CDFG structures through message-passing techniques~\cite{brauckmann2020compiler, cummins2021programl, yu2020codecmr}. Other strategies include skip-gram embeddings, such as inst2vec~\cite{ben2018neural}, and relation-based embeddings, such as TransE~\cite{bordes2013transE}, trained on CDFGs and CFGs to generate instruction-level embeddings. However, these models lack task-agnostic pre-trained embeddings, preventing them from capturing contextual information crucial for downstream tasks. 

Approaches like IR2Vec~\cite{2020ir2vec} mitigate this issue by introducing hierarchical vector representations to improve semantic comprehension of IRs. Recent work, such as FAIR (Flow-aware Pre-trained Model)~\cite{niu2024fair}, further refines IR representations using Graph Transformers to reduce over-smoothing issues while incorporating pre-training tasks that explicitly capture IR token semantics and flow-type information. FAIR has achieved state-of-the-art performance across multiple code-related tasks, highlighting the increasing importance of pre-trained IR models.

Meta's LLM Compiler~\cite{llmscompiler} aligns with these efforts, offering pre-trained models for code optimization tasks. While prior work has explored IR representation learning for code optimization and analysis, no studies have systematically examined how LLMs comprehend IR syntax, CFG structures, execution behavior, and semantic relationships. Our study addresses this gap by providing the first empirical evaluation of LLMs' IR comprehension across these dimensions.



\section{Prompts}
\subsection{Prompt for Structural Understanding: Inferring Control Flow
from IRs (Task 1)}
\begin{prompt}
You are a control flow graph analyzer for Intermediate Representations (IRs). I will provide you with LLVM Intermediate representation (IRs), a low-level, platform-independent representation of a program.

Here is the IR code input:  
    \textbf{[IR]}
    
Your task is to generate the control flow graph from the IR. The output format should be a DOT file, including nodes and edges. You do not need to list the content of each basic block; show each node's title. \\
Here is the IR code example to follow:
     \textbf{[IR Example]}\\
The output of the control flow graph should exactly match the following format:
    \textbf{[CFG Example]}
\end{prompt}
\subsection{Prompt for Syntactic Comprehension: Decompiling IRs to
High-Level Code (Task 2)}
\begin{prompt} 
You are an expert in high-performance computation. I will provide you with LLVM IRs (Intermediate Representations), which is a low-level, platform-independent representation of a program.\\ 
Here is the IR code input:
        \textbf{[IR]}\\
Your task is to decompile this IR code into a pure C or C++ source code format that can be run directly.\\
**Do not add any extra comments, explanations, or characters, and do not use any markdown formatting like ``` or ```cpp.**     
\end{prompt}
\subsection{Prompt for Semantic Comprehension: Generating Natural
Language Descriptions from IRs (Task 3)}
The final prompt used in the code summarization task is as follows:
\begin{prompt}
      I will give you an IR code.
    Here is the IR code input:
     \textbf{[IR]}

I would like you to summarize the code according to the following specifications:
   1. **Output Format**:
   - There are [n] functions in the code:
   - function[I (I in n)] takes [m] inputs: input1, input2, ..., inputm.
   - Function[I (I in n)] is [doing semantical function] on input1, input2, ..., inputm, and outputs [output].

   2. **Type and Variable Name Mapping Rules**:
   - `\% "class.std::vector"*` should be summarized as `vector<float> numbers`.
   - Other IR-specific types should be mapped to their equivalent C++ types, following this pattern where possible.

   3. **Strict Adherence to Formatting**:
   - The summary should strictly match the format provided below.
   - No additional comments, explanations, or deviations from the format should be added.
   - Do not use any markdown formatting such as ``` or ```cpp.

    Here is the IR code example to follow:
     \textbf{[IR Example]}\\
    The output should exactly match the following format:
    \textbf{[Output Example]}\\
    **Important Instructions**:
    - The summary must not include any additional comments, explanations, or formatting.
    - Ensure that variable names and types are directly transcribed as described in the example.
    - No markdown formatting (e.g., no ``` or ```cpp) should be used.
    **Do not deviate from the specified format under any circumstances.**
\end{prompt}

\subsection{Prompt for Execution Reasoning: Inferring Program Behavior
(Task 4)}
\begin{prompt}
      I need your help to analyze whether a given assertion passes or fails based on the provided LLVM IR code for a function.\\
  LLVM IR Code:\textbf{ [IR]}\\
  Assertion Statement: \textbf{[Assertion]}\\
Please write down your thinking process, and list the pass/fail result of each assertion at the end.
NOTE: Make sure the format the pass/fail result of each assertion at the end follow the example:
            \textbf{[Output Example]}
\end{prompt}


\section{HumanEval Setups}
Building on prior work~\cite{zheng2023codegeex, tan2024llm4decompile}, we utilize widely recognized benchmarks, specifically HumanEval and its extended test case version, to evaluate the ability of five state-of-the-art LLMs to comprehend semantics and compare them against various golden baselines. HumanEval, introduced by OpenAI, is a benchmark designed to assess the multilingual capabilities of code-generative models. It comprises 164 carefully handwritten programming challenges, each featuring a function signature, a natural language (NL) description, a function body, and a set of unit tests, with an average of 7.7 assertion statements per challenge~\cite{HuamanEval2021}. In our experiments, these 164 C++ programs serve as the source code for IR analysis.

The compilation experiments were conducted on a Dell Workstation equipped with 32 Intel(R) Xeon(R) CPUs E5-2620 v4 @ 2.10GHz, running on an x86-64 architecture with a 64-bit system. For these experiments, we used Clang adapted for LLVM 13 on Ubuntu 18.04. The C++ source code were compiled into IRs (.bc files) using the following command: 
\begin{center} \texttt{clang++ -O\{Opt-level\} -emit-llvm \{benchmark\}.cpp -S -o \{benchmark\}.bc} \end{center}

We use LLVM's built-in passes to generate golden CFGs with the \textit{-dot-cfg} option to ensure accurate and consistent representations of the code structure. The golden code summarization is meticulously performed to ensure that the generated graphs and code representations faithfully reflect the original source code's semantics. This process is critical for precise evaluations in subsequent tasks, such as static analysis, code summary analysis, and dynamic analysis. By employing these methodologies, we ensure that the golden datasets are of the highest fidelity, providing a solid foundation for assessing the granular understanding and representation of IRs by LLMs. 
\section{Cases of Findings}
\label{sec:appendix:cases_study}
\subsection{Example of decompilation}
\label{subsec:appendix:decompilation_example}
Figure~\ref{list:decompilation_result} shows a re-execution mismatch from GPT-4. The original code searches for a value in the \texttt{key} object and increments \texttt{out} when not found. In contrast, the decompiled version checks only for matching characters in two strings, incrementing \texttt{count} instead. This discrepancy likely arises because GPT-4 loses context during loop reconstruction, leading to partial logic and a different outcome during re-execution.
\input{codes/decompilation_example}

\subsection{Example of summarization}

\label{subsec:appendix:summarization_example}
Figure~\ref{list:summarization_result} illustrates the LLVM Intermediate Representation (IR) of the \texttt{truncate\_number} function, which extracts the decimal part of a floating-point number.

Table~\ref{tab:summarization_result} presents the summarization of the Example IR generated by various LLMs, showing how each model interprets the function's behavior.

\input{codes/summarization_example}

 \subsection{Example of execution reasoning}
 \label{subsec:appendix:example_exe_reasoning}
Fig.~\ref{list:Execution_reasoning} presents the source code for execution reasoning. The IR code shown is the same as the one used for summarization in the previous section.
\begin{table}[h]
    \centering
    \renewcommand{\arraystretch}{1.3} % Adjust row spacing for readability
    \begin{tabular}{|m{6cm}|m{10cm}|}
        \hline
        \rowcolor{gray!20} \multicolumn{2}{|c|}{\textbf{Assertion Analysis}} \\ 
        \hline
        \multicolumn{2}{|c|}{\texttt{assert (truncate\_number(3.5) == 0.5);} \quad → \quad \textbf{Pass}} \\ 
        \hline
        \textbf{Step 1: Understanding the Function} & 
        - The function \texttt{truncate\_number} takes a floating-point number as input. \newline
        - It uses \texttt{int()} to truncate the decimal part, returning the largest integer smaller than or equal to the input. \newline
        - The function then subtracts this integer value from the original number to obtain the decimal part. \\ 
        \hline
        \textbf{Step 2: Analyzing the Input} & 
        - The assertion checks if \texttt{truncate\_number(3.5)} equals \texttt{0.5}. \newline
        - Let's evaluate: \newline
        \quad - The integer part of \texttt{3.5} is \texttt{3} (\texttt{int(3.5)} returns \texttt{3}). \newline
        \quad - The decimal part is calculated as \texttt{3.5 - 3}, which equals \texttt{0.5}. \\ 
        \hline
        \textbf{Step 3: Comparing with the Assertion} & 
        - The assertion checks if \texttt{truncate\_number(3.5) == 0.5}. \newline
        - Since we calculated that \texttt{truncate\_number(3.5)} returns \texttt{0.5}, the assertion evaluates to \texttt{true}. \\ 
        \hline
        \textbf{Step 4: Conclusion} & 
        - The assertion passes because the expected value (\texttt{0.5}) matches the actual output of the function (\texttt{0.5}). \newline
        - \ding{52}  % ✅ checkmark alternative 
        **Assertion Result: Pass** \\ 
        \hline
    \end{tabular}
    \caption{An example of Execution Reasoning Result of the IR Example from GPT-4}
    \label{tab:An example of execution Simulation Result of the IR Example from GPT-4}
\end{table}

\begin{table}[h]
    \centering
    \renewcommand{\arraystretch}{1.3} % Adjust row spacing for readability
    \begin{tabular}{|m{6cm}|m{10cm}|}
        \hline
        \rowcolor{gray!20} \multicolumn{2}{|c|}{\textbf{Assertion Analysis}} \\ 
        \hline
        \multicolumn{2}{|c|}{\texttt{assert (truncate\_number(3.5) == 0.5);} \quad → \quad \textbf{Pass}} \\ 
        \hline
        \textbf{Analysis of the Provided C/C++ Code} & 
        The function \texttt{truncate\_number} takes a floating-point number as input and returns the decimal part. \newline
        - It uses \texttt{int()} to truncate the decimal part, effectively rounding down to the nearest integer. \newline
        - The decimal part is obtained by subtracting the truncated integer from the original number. \\ 
        \hline
        \textbf{Step-by-Step Breakdown} & 
        \begin{enumerate}
            \item The input \texttt{number} is passed to the function.
            \item The \texttt{int(number)} expression truncates the decimal part, effectively rounding it down.
            \item The truncated integer is subtracted from the original \texttt{number}, leaving only the decimal portion.
            \item The decimal part is returned as the result.
        \end{enumerate} \\ 
        \hline
        \textbf{Analysis of the Assertion Statement} & 
        The assertion statement verifies whether \texttt{truncate\_number(3.5)} correctly returns \texttt{0.5}. \newline
        - The assertion checks if \texttt{truncate\_number(3.5) == 0.5}. \newline
        - Let's evaluate: \newline
        \quad - The integer part of \texttt{3.5} is \texttt{3} (\texttt{int(3.5)} returns \texttt{3}). \newline
        \quad - The decimal part is calculated as \texttt{3.5 - 3}, which equals \texttt{0.5}. \\ 
        \hline
        \textbf{Final Result} & 
        - The assertion passes because the expected value (\texttt{0.5}) matches the actual output of the function (\texttt{0.5}). \newline
        \ding{52}  % ✅ checkmark alternative 
        **Assertion Result: Pass** \\ 
        \hline
    \end{tabular}
    \caption{An example of Execution Reasoning Result of the C++ Example from GPT-4}
    \label{tab:assertion_analysis}
\end{table}

\input{codes/execute_example}


\subsubsection{Misunderstanding Algorithm Logic (45 cases)}
\textbf{Example (CPP\_69):}
\begin{verbatim}
assert (search({5, 5, 5, 5, 1}) == 1);
\end{verbatim}
\textbf{Expected behavior:} The function should find the greatest integer with a frequency greater than or equal to its value.\\  
\textbf{LLM failure:} The model fails to track frequency accumulation and instead returns an incorrect value, misunderstanding how the search function should operate.

\subsubsection{Pattern-Based Guessing (35 cases)}
\label{subsubsec:appendix:example_pattern_Guess}
\begin{table}[h]
    \centering
    \renewcommand{\arraystretch}{1.3} % Adjust row spacing for readability
    \begin{tabular}{|m{6cm}|m{10cm}|}
        \hline
        \rowcolor{gray!20} \multicolumn{2}{|c|}{\textbf{Reasoning log}} \\ 
        \hline
        \multicolumn{2}{|c|}{\texttt{assert (solutions({5, 8, 7, 1}) == 12);} \quad → \quad \textbf{Fail}} \\ 
        \hline
        \textbf{Step 1: Function Signature} & the function `solutions` takes a pointer to a $`std::vector<int>`$ as its argument. the vector is expected to contain integers.\\
        \hline
        \textbf{Step 2: loading vector elements} & 
        - the function uses `getelementptr` and `load` instructions to access the elements of the vector. \newline
        - the vector is accessed in a way that suggests it is iterating over its elements. \\ 
        \hline
        \textbf{Step 3: Vector Operations} & 
        - the function performs several operations on the elements of the vector, including loading elements, performing shifts, and using the `srem` (signed remainder) operation. \newline
        - the function also uses a vector reduction operation (`@llvm.vector.reduce.add.v4i32`) which indicates that it sums up the elements of the vector in groups of four. \\ 
        \hline
        \textbf{Step 4: understanding the logic} & 
        - the function appears to be summing the elements of the vector, but it also applies some conditions based on the results of the `srem` operations. \newline
        - the `srem` operation checks if the elements are odd (i.e., remainder when divided by 2 is 1) and conditionally includes them in the sum. \\ 
        \hline
        \textbf{Step 5: input values} &
        - the input vector `{5, 8, 7, 1}` contains the integers 5, 8, 7, and 1.\newline
        - the odd numbers in this vector are 5, 7, and 1. the even number is 8.\\
        \hline
        \textbf{Step 6: calculating the expected result}&
        - the sum of all elements is `5 + 8 + 7 + 1 = 21`.\newline
        - \textcolor{red}{however, since the function seems to apply a filter based on the `srem` operation}, we need to check which elements are included in the final sum.\newline
        - the `srem` operation checks if the remainder is 1, which means only the odd numbers (5, 7, and 1) would be included in the sum.\newline
        - therefore, the sum of the odd numbers is `5 + 7 + 1 = 13`.\\
        \hline
        \textbf{Step 7: final comparison}&
        - the assertion checks if the result of `solutions({5, 8, 7, 1})` equals 12.\newline
        - based on our analysis, the function would return 13, not 12.\\
        \hline
    \end{tabular}
    \caption{An example of Guessing Result based on patterns from GPT-4}
    \label{tab:An example of Guessing Result based on patterns from GPT-4}
\end{table}
\textbf{Example (CPP\_121) as shown in Fig.~\ref{tab:An example of Guessing Result based on patterns from GPT-4}:}
\begin{verbatim}
assert (solutions({5, 8, 7, 1}) == 12);
\end{verbatim}
\textbf{Expected behavior:} Sum all odd elements at even positions.\\ 
\textbf{LLM failure:} Instead of following the logic step-by-step, the model guesses the sum based on pattern recognition from prior examples rather than executing the correct loop iteration.

\subsubsection{Control Flow Issues (28 cases)}
\textbf{Example (CPP\_92):}
\begin{verbatim}
assert (any_int(2.5, 2, 3) == false);
\end{verbatim}
\textbf{Expected behavior:} The function should correctly handle nested conditionals to determine if any sum of two numbers equals the third.\\  
\textbf{LLM failure:} The model does not properly evaluate the if-else branching and incorrectly processes non-integer values.

\subsubsection{Overreliance on Function Names (22 cases)}
\textbf{Example (CPP\_105):}
\begin{verbatim}
assert (issame(by_length({2, 1, 1, 4, 5, 8, 2, 3}) , 
{"Eight", "Five", "Four", "Three", "Two", "Two", "One", "One"}));
\end{verbatim}
\textbf{Expected behavior:} Sort numbers, reverse the list, and replace them with corresponding word representations.\\  
\textbf{LLM failure:} Instead of applying the transformation rules, the model simply assumes the function operates based on its name and produces an incorrect output.

\subsubsection{String Processing Errors (18 cases)}
\textbf{Example (CPP\_112):}
\begin{verbatim}
assert (issame(reverse_delete("abcde","ae") , {"bcd","False"}));
\end{verbatim}
\textbf{Expected behavior:} Remove characters and check for palindromicity.\\
\textbf{LLM failure:} The model fails to correctly apply character deletions and check the reverse consistency, leading to incorrect assertions.


\subsection{Conclusion}
These findings highlight common failure patterns in LLM-based code interpretation, including logical misinterpretation, heuristic-based assumptions, and issues with numerical computations. Further refinement in model training and debugging processes is recommended.



