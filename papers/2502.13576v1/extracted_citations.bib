@article{100instances,
  title={100 instances is all you need: predicting the success of a new LLM on unseen data by testing on a few instances},
  author={Pacchiardi, Lorenzo and Cheke, Lucy G and Hern{\'a}ndez-Orallo, Jos{\'e}},
  journal={arXiv preprint arXiv:2409.03563},
  year={2024}
}

@inproceedings{AP,
  author       = {Rajan Vivek and
                  Kawin Ethayarajh and
                  Diyi Yang and
                  Douwe Kiela},
  title        = {Anchor Points: Benchmarking Models with Much Fewer Examples},
  booktitle    = {Proceedings of the 18th Conference of the European Chapter of the
                  Association for Computational Linguistics, {EACL} 2024 - Volume 1:
                  Long Papers, St. Julian's, Malta, March 17-22, 2024},
  pages        = {1576--1601},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.eacl-long.95},
  timestamp    = {Tue, 02 Apr 2024 16:32:10 +0200},
  biburl       = {https://dblp.org/rec/conf/eacl/VivekEYK24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{awadalla2022exploring,
  title={Exploring the landscape of distributional robustness for question answering models},
  author={Awadalla, Anas and Wortsman, Mitchell and Ilharco, Gabriel and Min, Sewon and Magnusson, Ian and Hajishirzi, Hannaneh and Schmidt, Ludwig},
  journal={arXiv preprint arXiv:2210.12517},
  year={2022}
}

@article{baek2022agreement,
  title={Agreement-on-the-line: Predicting the performance of neural networks under distribution shift},
  author={Baek, Christina and Jiang, Yiding and Raghunathan, Aditi and Kolter, J Zico},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={19274--19289},
  year={2022}
}

@inproceedings{hu2023predicting,
  title={Predicting Emergent Abilities with Infinite Resolution Evaluation},
  author={Hu, Shengding and Liu, Xin and Han, Xu and Zhang, Xinrong and He, Chaoqun and Zhao, Weilin and Lin, Yankai and Ding, Ning and Ou, Zebin and Zeng, Guoyang and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{isik2024scaling,
  title={Scaling laws for downstream task performance of large language models},
  author={Isik, Berivan and Ponomareva, Natalia and Hazimeh, Hussein and Paparas, Dimitris and Vassilvitskii, Sergei and Koyejo, Sanmi},
  journal={arXiv preprint arXiv:2402.04177},
  year={2024}
}

@article{mehra2024predicting,
  title={Predicting the Performance of Foundation Models via Agreement-on-the-Line},
  author={Mehra, Aman and Saxena, Rahul and Kim, Taeyoun and Baek, Christina and Kolter, Zico and Raghunathan, Aditi},
  journal={arXiv preprint arXiv:2404.01542},
  year={2024}
}

@inproceedings{miller2021accuracy,
  title={Accuracy on the line: on the strong correlation between out-of-distribution and in-distribution generalization},
  author={Miller, John P and Taori, Rohan and Raghunathan, Aditi and Sagawa, Shiori and Koh, Pang Wei and Shankar, Vaishaal and Liang, Percy and Carmon, Yair and Schmidt, Ludwig},
  booktitle={International conference on machine learning},
  pages={7721--7735},
  year={2021},
  organization={PMLR}
}

@article{perlitz2023efficient,
  title={Efficient benchmarking (of language models)},
  author={Perlitz, Yotam and Bandel, Elron and Gera, Ariel and Arviv, Ofir and Ein-Dor, Liat and Shnarch, Eyal and Slonim, Noam and Shmueli-Scheuer, Michal and Choshen, Leshem},
  journal={arXiv preprint arXiv:2308.11696},
  year={2023}
}

@article{prabhu2024lifelong,
  title={Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress},
  author={Prabhu, Ameya and Udandarao, Vishaal and Torr, Philip and Bethge, Matthias and Bibi, Adel and Albanie, Samuel},
  journal={arXiv preprint arXiv:2402.19472},
  year={2024}
}

@article{ruan2024observational,
  title={Observational Scaling Laws and the Predictability of Language Model Performance},
  author={Ruan, Yangjun and Maddison, Chris J and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2405.10938},
  year={2024}
}

@article{taori2020measuring,
  title={Measuring robustness to natural distribution shifts in image classification},
  author={Taori, Rohan and Dave, Achal and Shankar, Vaishaal and Carlini, Nicholas and Recht, Benjamin and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18583--18599},
  year={2020}
}

@inproceedings{tiny,
  author       = {Felipe Maia Polo and
                  Lucas Weber and
                  Leshem Choshen and
                  Yuekai Sun and
                  Gongjun Xu and
                  Mikhail Yurochkin},
  title        = {tinyBenchmarks: evaluating LLMs with fewer examples},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=qAml3FpfhG},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/PoloWCSXY24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{xu2024data,
  title={Data Efficient Evaluation of Large Language Models and Text-to-Image Models via Adaptive Sampling},
  author={Xu, Cong and Saranathan, Gayathri and Alam, Mahammad Parwez and Shah, Arpit and Lim, James and Wong, Soon Yee and Martin, Foltin and Bhattacharya, Suparna},
  journal={arXiv preprint arXiv:2406.15527},
  year={2024}
}

@article{zhang2024collaborative,
  title={Collaborative Performance Prediction for Large Language Models},
  author={Zhang, Qiyuan and Lyu, Fuyuan and Liu, Xue and Ma, Chen},
  journal={arXiv preprint arXiv:2407.01300},
  year={2024}
}

