
\section{More about our benchmarking}
% \addcontentsline{atc}{section}{More about our benchmarking}

\subsection{Comparison between our benchmark and existing works}
In Table \ref{tab:comparison_existing_works}, we summarize the key differences between our benchmarking study and other papers. \textbf{Comprehensive Baselines} refers to whether the baseline models cover a wide range of model types. In our paper, we include GNNs, Graph SSL models, Graph Transformers, Foundational Graph Prompt Models, and LLMs with Graph Projectors. \textbf{Comprehensive Settings} examines the performance of models across various scenarios, such as vanilla fine-tuning, few-shot learning, and zero-shot learning. \textbf{Diverse LLMs} highlights the use of multiple LLMs for comparison, such as Llama, GPT, and Qwen. \textbf{LLM Tuning} indicates whether the paper fine-tunes the LLMs or simply uses the original models as they are. Lastly, \textbf{Transferability Study} explores whether the paper investigates the cross-task or cross-domain transfer capabilities of the models.

\begin{table*}[htbp]
\centering
\caption{Comparison between our benchmark and existing works}
\label{tab:comparison_existing_works}
\scalebox{0.74}{ % Adjust the scale as needed
\begin{tabular}{@{}lccccccc@{}}
\toprule
\rowcolor{gray!10}
\textbf{Model} & \textbf{Node Classification} & \textbf{Link Prediction} & \textbf{Comprehensive Baselines} & \textbf{Comprehensive Settings} & \textbf{Diverse LLMs} & \textbf{LLM Tuning} & \textbf{Transferability Study} \\ \midrule
InstructGLM \cite{instructglm}     & \ding{51} & \ding{55} & \ding{55} & \ding{55} & \ding{55} & \ding{51} & \ding{55} \\
LLaGA \cite{chen2024llaga}          & \ding{51} & \ding{51} & \ding{55} & \ding{55} & \ding{51} & \ding{55} & \ding{51} \\
InstructGraph \cite{wang2024instructgraph}   & \ding{51} & \ding{51} & \ding{55} & \ding{55} & \ding{51} & \ding{51} & \ding{55} \\
NLGraph \cite{nlgraph}        & \ding{55} & \ding{55} & \ding{55} & \ding{51} & \ding{55} & \ding{55} & \ding{55} \\
Talk Like a Graph \cite{fatemi2023talklikeagraph} & \ding{51} & \ding{55} & \ding{55} & \ding{51} & \ding{55} & \ding{55} & \ding{55} \\
All in One \cite{sun2023allinone}      & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{55} & \ding{55} & \ding{51} \\
OFA \cite{ofa}            & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{55} & \ding{55} & \ding{51} \\
GraphGPT \cite{tang2024graphgpt}       & \ding{51} & \ding{51} & \ding{55} & \ding{55} & \ding{51} & \ding{51} & \ding{51} \\ \midrule
\rowcolor{gray!10}
\textbf{Ours}   & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} & \ding{51} \\ 
\bottomrule
\end{tabular}
}
\end{table*}

\subsection{Scope of this paper}
This paper focuses on evaluating the performance of LLMs on graph tasks. Instead of covering a wide range of tasks, it emphasizes depth over breadth by concentrating on the two most common graph tasks: node classification and link prediction. Tasks such as graph classification, node degree counting, graph cycle detection, and shortest path computation are not included in the scope. The study goes beyond simply applying pre-trained LLMs for reasoning. It incorporates instruction tuning and investigates the performance of LLMs under fine-tuning, few-shot, and zero-shot settings, as well as their transferability across tasks. The goal is to provide insights and guidance for future applications of LLMs in the graph domain.


\section{Related Works}
In this section, we review the existing literature on the application of LLMs and related techniques in graph tasks. We highlight two primary categories: the use of LLMs for graph reasoning and their integration with traditional graph models to enhance performance.
\subsection{Large Language Models for Graph Reasoning}
Recent studies suggest that LLMs have the potential to solve graph reasoning tasks by understanding graph structures~\cite{fatemi2023talklikeagraph,tang2024grapharena}. NLGraph~\cite{nlgraph} indicates that LLMs can track paths within graphs, enabling them to solve tasks such as node connectivity and shortest path detection. Moreover,~\citep{dai2024large} suggests that LLMs understand graph pattern concepts, which are fundamental to graph structure mining and learning. 
Additionally, fine-tuning further enhances the LLMs' reasoning ability in graph tasks~\cite{dai2024revisiting}.~\cite{zhang2024can} suggest that LLMs can transfer their understanding of substructures through fine-tuning on graphs with different node features. Besides, GraphWiz~\cite{chen2024graphwiz} indicates that LLMs learn path reasoning across various tasks and datasets. These findings highlight that LLMs can be effectively tuned to improve their comprehension of graph structures.


\subsection{Language Model Aided Graph Models}
With the advancement of language models, their presence in graph-related tasks has become increasingly prominent. Their natural strengths in language processing and intrinsic reasoning make them particularly valuable, especially in test attribute graph (TAG) tasks. Broadly, the role of language models in graph learning can be categorized into two main approaches: language models as enhancers and large language models as predictors \cite{chen2024exploring}.

\subsubsection{Language models as enhancers}
Language models serve as enhancers by assisting graph models in representation learning and knowledge integration. Pre-trained language models (PLMs) like BERT \cite{devlin2018bert}, DeBERTa \cite{he2020deberta}, and XLNet \cite{yang2019xlnet} are commonly used to transform raw textual descriptions into embeddings, improving graph models’ ability to capture node semantics. For instance, OFA \cite{ofa} encodes text descriptions of nodes and edges into fixed-length vectors, unifying graph data from different domains and enabling strong performance in supervised, few-shot, and zero-shot settings. Similarly, GraphAlign \cite{hou2024graphalign}, BooG \cite{boog}, and ZeroG \cite{li2024zerog} utilize PLMs to embed textual node features, ensuring feature consistency across diverse datasets during pre-training.

Beyond embedding textual features, large language models (LLMs) contribute to graph representation enrichment. TAPE \cite{tape} generates textual explanations for model predictions, which are then transformed into additional node features, enhancing GNN-based learning. On the other hand, LLMGNN \cite{llmgnn} uses LLMs to annotate a subset of nodes with high quality labels, which are then leveraged by GNNs to predict the remaining unlabeled nodes. This method effectively combines LLMs’ semantic reasoning with the structured learning power of GNNs.

\subsubsection{Large language models as predictors}
LLMs can serve as direct predictors for graph-related tasks such as node classification and link prediction. Instruction tuning is a widely used technique to enhance LLMs’ predictive accuracy \cite{ouyang2022training, sanh2021multitask}, helping them better interpret graph structures through task-specific prompts. For instance, InstructGLM \cite{instructglm} employs multi-prompt tuning to integrate multi-hop structural information, improving its ability to capture complex relationships. GraphGPT \cite{tang2024graphgpt} follows a dual-stage approach: first, it aligns structural information with language tokens via self-supervised graph matching, and second, it fine-tunes the model on task-specific instructions, leading to more accurate predictions.

Beyond standalone LLMs, hybrid models combine them with GNNs or graph transformers to better leverage graph structure. UniGraph \cite{he2024unigraph} enhances zero-shot learning by aligning textual instructions with category labels while incorporating GNNs for structural learning. GraphLLM \cite{chai2023graphllm} conbines LLM with graph transformer to enrich LLM attention layers with structural and semantic information, enabling more effective graph reasoning. In contrast, LLaGA \cite{chen2024llaga} avoids full LLM tuning and instead fine-tunes a lightweight graph projector, reducing computational cost while maintaining strong predictive performance. These approaches highlight the evolving role of LLMs in graph learning, demonstrating their flexibility in both direct prediction and hybrid architectures.



\section{Datasets}
\label{sec:Datasets}
We summarize the details of used datasets in Table \ref{tab:Datasets}. We convert all graphs into undirected graphs and remove self-loops.

\begin{table*}[htbp]
\centering
\caption{Datasets}
\label{tab:Datasets}
\begin{tabular}{@{}lcccccccc@{}}
\toprule
\rowcolor{gray!10}
\textbf{Dataset} & \textbf{Domain} & \textbf{Task} & \textbf{\#Graph}  & \textbf{\#Node} & \textbf{\#Edge} & \textbf{\#Classes} & \textbf{Metrics} & \textbf{Default feature}\\ \midrule
Cora   & citation & Node, Link &1     & 2,708     & 5,429 & 7 & Accuracy & Bag-of-Words \cite{nlgraph}\\
Pubmed  & citation & Node, Link &1     & 19,717    & 44,338 & 3 & Accuracy & TF-IDF\\
OGBN-Arxiv  & citation  & Node, Link &1     & 169,343   & 1,166,243 & 40 & Accuracy & Skip-gram \cite{skimgram}\\
OGBN-Products & e-commerce & Node, Link &1  & 2,449,029  & 61,859,140 & 47 & Accuracy & Bag-of-Words\\ 
\bottomrule
\end{tabular}
\end{table*}

For Cora, PubMed, and OGBN-Arxiv, each node represents a paper and the edges denote co-citations. For OGBN-Products, nodes represent Amazon products and edges act as co-purchases. Due to the large size of OGBN-Products, we use Cluster-GCN \cite{clustergcn} to process it in smaller partitions. The structural information and label information of these datasets can be achieved from Pyg, and we will release the codes for raw feature processing. Below is some relevant information about each datasets:

\begin{itemize}
    \item \textbf{Cora} \cite{cora}. Cora has seven categories: ["Rule Learning", "Neural Networks", "Case Based", "Genetic Algorithms", "Theory", "Reinforcement Learning", "Probabilistic Methods"]. The raw text attributes can be obtained from \href{}{\textcolor{blue}{https://people.cs.umass.edu/~mccallum/data.html}}
    \item \textbf{PubMed} \cite{pubmed}. PubMed has three categories: ["Diabetes Mellitus, Experimental", "’Diabetes Mellitus Type 1", "Diabetes Mellitus Type 2"]. The raw text attributes can be obtained from TAPE \cite{tape} (\href{}{\textcolor{blue}{https://github.com/XiaoxinHe/TAPE}})
    \item \textbf{OGBN-Arxiv and OGBN-Products} \cite{ogb}. OGB benchmark provides these two datasets. For OGBN-Arxiv, the raw text attributes can be downloaded from \href{}{\textcolor{blue}{https://snap.stanford.edu/ogb\\/data/misc/ogbn\_arxiv/titleabs.tsv.gz}}. For OGBN-Products, the raw text attributes can be downloaded from \href{}{\textcolor{blue}{http://manikvarma.\\org/downloads/XC/XMLRepository.html}}.
\end{itemize}

\textbf{Data Split.} For node-level tasks, we use the standard train/validation/test splits \cite{ogb}: 6:2:2 for both Pubmed and Cora, 6:2:3 for the OGBN-Arxiv dataset ,and 8:2:90 for OGBN-Products. For link prediction, we randomly sample node pairs from the training nodes for training and from the testing nodes for evaluation. The size of the edge-level training set matches that of the node-level training set.


\section{Impacts of Different Node Feature Embedding Methods}
\label{sec:Impacts of Different Node Feature Embedding Methods}
Node features play a crucial role in node classification and link prediction tasks. For LLMs, raw text attributes are directly used as node features, while datasets like Cora, PubMed, Arxiv, and Products provide default preprocessed features generated through feature embedding methods (as shown in Table \ref{tab:Datasets}). This raises an important question: \textbf{is it fair to compare baseline models using default features with LLMs that rely on raw text attributes?}

To address this, we embedded the raw text attributes using various pre-trained LLMs and fed these embeddings into GraphSAGE for node classification tasks. The results are summarized in Table \ref{tab: Impacts of Different Node Feature Embedding Methods}. Specifically, all-MiniLM-L6-v2 is the latest Sentence-BERT model, and text-embedding-ada-002 is the latest embedding model from OpenAI.

From the results, we observe no significant accuracy improvements when using pre-trained LLM embeddings over the default node features. In some datasets, LLM-based embeddings perform better, while in others, default node features yield stronger results. Therefore, we believe that using the default node features provided by corresponding datasets is a reasonable and fair.


\begin{table}[htbp]
\centering
\caption{Impacts of different node feature embedding methods. Task: node classification. Model: GraphSAGE}
\label{tab: Impacts of Different Node Feature Embedding Methods}
\scalebox{1}{ % Adjust the scale as needed
\begin{tabular}{@{}lcccc@{}}
\toprule
\rowcolor{gray!10}
\textbf{Embedding Methods} & \textbf{Cora} & \textbf{PubMed} & \textbf{Arxiv} & \textbf{Products} \\ \midrule
default & 89.67 & 89.02 & 71.35 & 82.89 \\
all-MiniLM-L6-v2 \cite{sbert} & 89.88 & 89.91 & 72.03 & 81.82 \\
t5-small \cite{t5} & 86.71 & 87.78 & 70.28 & 79.64 \\
e5-base \cite{e5} & 88.10 & 87.12 & 71.52 & 80.33 \\
text-embedding-ada-002 & 89.30 & 89.72 & 72.20 & 82.45 \\

\bottomrule
\end{tabular}
}
\end{table}





\section{Detailed Experimental Settings}
\label{sec:Detailed Experimental Settings}
\subsection{Computation Environment}
In this paper, all the experiments were conducted on one single server with 4 80G Nvidia A100 GPUs.

\subsection{Model Settings}
\begin{itemize}

\item \textbf{GCN \& GraphSAGE}
\begin{lstlisting}[language=Python]
num_layers=3, hidden_channels=256, dropout=0.5, 
norm='batchnorm', activation='relu', 
optimizer=torch.optim.AdamW, lr=0.005, weight_decay=1e-4, 
scheduler=torch.optim.lr_scheduler.StepLR, step_size=20, gamma=0.5, 
patience=20, min_delta=1e-3, epochs=8000
\end{lstlisting}

\item \textbf{GAT}
\begin{lstlisting}
num_layers=3, hidden_channels=256, dropout=0.5, heads=2, 
norm='batchnorm', activation='relu', 
optimizer=torch.optim.AdamW, lr=0.005, weight_decay=1e-4, 
scheduler=torch.optim.lr_scheduler.StepLR, step_size=20, gamma=0.5, 
patience=20, min_delta=1e-3, epochs=8000
\end{lstlisting}

\item \textbf{MixHop}
\begin{lstlisting}
num_layers=2, hidden_channels=256, powers=[ [0,1,2], [0,1] ], dropout=0.6,
add_self_loops=True, activation='relu', aggregation='mixhop',
optimizer=torch.optim.AdamW, lr=0.005, weight_decay=1e-4,
scheduler=torch.optim.lr_scheduler.StepLR, step_size=20, gamma=0.5,
early_stopping=dict(patience=20, min_delta=1e-3), max_epochs=8000, log_interval=10
\end{lstlisting}

\item \textbf{GraphCL}
\begin{lstlisting}
Graph Encoder:
    -Backbone: GCN, -Hidden Channels: 128, -Activation: ReLU, -Optimizer: Adam, -lr=0.01, -Epochs: 100
Data Augmentations:
    -Feature Masking: mask_rate=0.3, -Edge Perturbation: perturb_rate=0.1
Contrastive Loss:
    -Normalization: L2 (dim=1), -Temperature: 0.5
Linear Classifier:
    -Input Features: 128, -Optimizer: Adam, -lr=0.01, -Epochs: 50 (supervised training)
\end{lstlisting}

\item \textbf{GraphMAE}
\begin{lstlisting}
Graph Encoder:
    -Backbone: GCN, -Hidden Channels: 256, -Activation: ReLU, -Optimizer: Adam, -lr=0.01, -Epochs: 200
Data Augmentations:
    -Feature Masking: mask_ratio=0.5 (encoder-level), -Random Masking: mask_rate=0.3 (training-level)
Reconstruction Loss:
    -Loss Function: MSE Loss, -Reconstruction Target: Masked node features
Linear Classifier:
    -Input Features: 256, -Optimizer: Adam, -lr=0.01, -Epochs: 100 (supervised training)
\end{lstlisting}

\item \textbf{Graphormer}
We follow the hyper-parameter settings in the original paper \cite{graphormer}.

\item \textbf{Prodigy}
We follow the hyper-parameter settings in the original paper \cite{huang2024prodigy}.

\item \textbf{OFA}
We follow the hyper-parameter settings in the original paper \cite{ofa}.

\item \textbf{GIANT \& TAPE}
\begin{lstlisting}
gnn_type='GraphSAGE', num_layers= [2, 3, 4], hidden_channels= [128, 256],
optimizer=torch.optim.Adam, lr=0.001, weight_decay=0, dropout= [0.3, 0.5, 0.6] 
\end{lstlisting}

\item \textbf{All in one \& GPF-plus \& GraphPrompt}
\begin{lstlisting}
gnn_type='GCN', num_layers=2, hidden_channels=128, JK='last',
prompt_type=['All in one', 'GPF-plus', 'GraphPrompt'],
optimizer=torch.optim.Adam, lr=0.001, weight_decay=0, dropout=0.5,
epochs=800, batch_size=128, shot_num=5,
\end{lstlisting}

For detailed prompt designs, we follow the original papers \cite{sun2023allinone}, \cite{gpf-plus}, and \cite{liu2023graphprompt}.

\item \textbf{ZeroG}
We follow the hyper-parameter settings in the original paper \cite{li2024zerog}.

\item \textbf{LLaGA}
We follow the hyper-parameter settings in the original paper \cite{chen2024llaga}.

\item \textbf{Llama3B \& Llama8B}
\begin{lstlisting}
LLM Configuration: 
    -Base Model: [meta-llama/Llama-3.2-3B-Instruct, meta-llama/Llama-3.1-8B-Instruct], 
    -Use LoRA: true, -Max Sequence Length: 1024, -Model Precision: bfloat16
LoRA Configuration:
    -LoRA Rank (r): 16, -LoRA Alpha: 32, -LoRA Dropout: 0.05, 
    -Target Modules: [o_proj, gate_proj, down_proj, up_proj]
Training Configuration:
    -Optimizer: adamw_torch, -Learning Rate: 4e-4, -Train Batch Size: 2 x 12 (per_device x grad_accum), 
    -Total Epochs: 1, -Gradient Accu Steps: 12, -Pad Token ID: -100 (IGNORE_INDEX)
DeepSpeed Optimization:
    -Zero Stage: 2, -Offload Strategy: [-Optimizer -> CPU (pinned) ,-Activation Checkpointing: true], 
    -Pipeline Parallel: [-Enabled: true, -Micro Batch Size: 1]
Data Processing:
    -Data Sources: [Cora, PubMed, Arxiv, Products], -Input Format: System Prompt + User Query + Answer, 
    -Data Limits: [-Product/node: max 3,000 samples, -Product/link: max 2,000 samples], 
    -Preprocessing Workers: 20,
    -Cora & PubMed & Arxiv: [-Max 1-hop neighbors: 20, -Max 2-hop neighbors: 5],
    -Products: [-Max 1-hop neighbors: 30, -Max 2-hop neighbors: 10]
    
\end{lstlisting}

\end{itemize}

\section{Baseline models}
\label{sec:Baseline models}
In this paper, we evaluate multiple baseline models and provide detailed descriptions of their implementations as follows. These models were applied to a consistently preprocessed version of the datasets to ensure fair comparisons and produce the experimental results presented in this study.
\begin{enumerate}
    \item \textbf{GNNs}: For GCN, GraphSAGE, GAT, and Mixhop, we follow the models on OGB Leaderboards (\href{}{\textcolor{blue}{https://ogb.stanford.edu/docs/\\leader\_nodeprop/}}). Specifically, the three models are all from \cite{luo2024classic}, and the codes can be obtained from \href{}{\textcolor{blue}{https://github.com\\/LUOyk1999/tunedGNN}}.
    
    \item \textbf{Graph SSL Models}: We choose GraphCL and GraphMAE in this categories. GraphCL employs contrastive learning by distinguishing augmented views of the same graph from others, while GraphMAE uses masked autoencoding, reconstructing masked graph components to learn node representations without requiring augmented views. For GraphCL, we follow the implementation from \href{}{\textcolor{blue}{https://github.com/Shen-Lab/GraphCL}}. For GraphMAE, we follow the implementation from \href{}{\textcolor{blue}{https://github.com\\/THUDM/GraphMAE}}.
    
    \item \textbf{Graph Transformers}: We use Graphormer in this categories. Graphormer is a transformer-based model designed specifically to handle graph-structured data, enabling efficient processing and analysis of complex relational information.The implementation is from \href{}{\textcolor{blue}{https://github.com/microsoft/Graphormer}}.

    \item \textbf{Foundational Graph Prompt Models}: We use Prodigy, OFA, All in one, GPF-plus, GraphPrompt, and ZeroG in this categories. 
    \begin{itemize}
        \item Prodigy enables in-context learning over graphs by utilizing a novel prompt graph representation and a family of in-context pretraining objectives, achieving superior performance on diverse downstream classification tasks without the need for retraining.

        \item OFA represents nodes and edges as human-readable text, mapping them from various domains into a unified space using LLMs. The framework then adapts to different tasks by embedding task-specific prompts within the input graph.

        \item All in one proposes a novel method to unify graph prompts and language prompts, enhancing the performance of various graph tasks through effective prompt design and meta-learning techniques.

        \item GPF-plus is an enhanced graph prompt tuning method that assigns independent learnable vectors to each node, offering great flexibility and expressiveness and consistently outperforming other methods in various experiments.

        \item GraphPrompt leverages a common task template based on subgraph similarity, enhanced with task-specific learnable prompts to improve performance across different tasks such as node and graph classification.

        \item ZeroG uses a language model to encode node features and class labels, incorporating prompt-based subgraph sampling and efficient fine-tuning techniques to tackle the challenges of cross-dataset zero-shot transferability in graph learning.
    \end{itemize}
     The implementations of Prodigy and OFA can be obtained from \url{}{\textcolor{blue}{https://github.com/snap-stanford/prodigy}} and \url{}{\textcolor{blue}{https://github.co\\m/LechengKong/OneForAll}}, respectively. For All in one, GPF-plus, and GraphPrompt, we use the implementation from ProG \cite{zi2024prog} (Code: \href{}{\textcolor{blue}{https://github.com/sheldonresearch/ProG}}). For ZeroG, we follow the implementation from \href{}{\textcolor{blue}{https://github.com/Nin\\eAbyss/ZeroG}}.

    \item \textbf{LM-Augmented Graph Learning Models}: GIANT conducts neighborhood prediction using XR-Transformers \cite{zhang2021fast}, resulting in an LLM that generates superior feature vectors for node classification compared to traditional bag-of-words and standard BERT embeddings. TAPE uses explanations from LLMs as features to enhance the performance of GNNs on text-attributed graphs, achieving state-of-the-art results on various benchmarks with significantly lower computation time. For GIANT and TAPE, we follow the implementation from \href{}{\textcolor{blue}{https://github.co\\m/NineAbyss/GLBench}}

    \item \textbf{LLM with Graph Projectors}: LLaGA is chosen for this category. The implementation is from \href{}{\textcolor{blue}{https://github.com/VITA-Group/LLaGA}}.
    
\end{enumerate}


\section{Extended Experiments}
\label{sec:Extended Experimental Results}
\subsection{Robustness of LLMs}
\label{sec:Robustness of LLMs}
We aim to investigate the robustness of LLMs under two challenging conditions: missing edge information and decreasing graph homophily. Graph homophily refers to the tendency of similar nodes to connect. Our goal is to understand whether LLMs primarily rely on node similarity when performing graph reasoning and how reducing this similarity affects their performance.

\paragraph{Experiment Settings}
We conduct experiments on the \textbf{Cora} and \textbf{ArXiv} datasets, designing two scenarios: \textbf{drop same} and \textbf{drop random}. The former examines how reducing node similarity affects LLM performance, while the latter investigates the impact of simply reducing the number of edges.

\begin{itemize}
    \item \textbf{Drop Same}: We randomly remove \textbf{0\%, 20\%, 40\%, 60\%, 80\%, and 100\%} of edges connecting nodes of the same class. This reduces node similarity, effectively lowering the homophily ratio \cite{loveland2024performance, whenandwhy}.
    \item \textbf{Drop Random}: We randomly remove edges but have to ensure that the number of dropped edges matches the corresponding \textbf{"drop same"} setting. For example, if 40\% "drop same" results in 1,000 removed edges, then 40\% "drop random" also removes 1,000 edges.
\end{itemize}

For LLMs, we use \textbf{DeepSeek V3} and \textbf{Llama3B}. As baselines, we include \textbf{GCN}, \textbf{GraphSAGE}, and \textbf{MixHop} \cite{abu2019mixhop} (which performs well on heterophilic graphs). All trainable models (GCN, GraphSAGE, MixHop, and Llama3B) are trained on graphs with varying levels of edge removal. Specifically, for each dataset (Cora and ArXiv), we train \textbf{twelve} models per method—six under "drop same" and six under "drop random", corresponding to the six drop percentages.


\begin{figure*}[htbp]
  \centering
  \includegraphics[width=1\linewidth]{figs/Robustness_of_LLMs.pdf}
  %\vspace{-20pt}
  \caption{Robustness of LLMs}
  \label{fig:Robustness of LLMs}
\end{figure*}

\paragraph{Results}
We summarize the experimental results in Figure \ref{fig:Robustness of LLMs}. As expected, accuracy declines across all models and datasets as the edge drop percentage increases. However, the impact of edge removal is not uniform. The "drop same" condition leads to a sharper decline compared to "drop random", suggesting that reducing node similarity (homophily) has a greater negative effect than simply removing edges at random.

Interestingly, DeepSeek V3 and tuned Llama3B show more resilience to homophily reduction compared to GCN, GraphCL, and even Mixhop, indicating that they rely less on node similarity for classification. Among them, tuned Llama3B stands out, not only preserving high accuracy despite edge removal but also showing the lowest dependency on node similarity. This highlights that instruction tuning significantly enhances the robustness of LLMs, making them more adaptable to structural perturbations.

\paragraph{\textbf{Remark 6:}}
Reducing homophily (via “drop same”) has a more significant negative impact than randomly removing edges. LLMs, especially those after instruction tuning are more resilient to structural perturbations compared to GNNs like GCN, GraphSAGE, and even MixHop.


\subsection{Comparison of Different LLMs on Node Classification}
\label{sec:Comparison of Different LLMs on Node Classification}

\begin{table}[htbp]
\centering
\caption{Comparison of different LLMs on node classification. The bolded parts are used to compare the effects of using structural information and instruction tuning. The background colors represent the top three values in each column, from dark to light.}
\label{tab:Comparison of Different LLMs on Node Classification}
\scalebox{0.7}{%
\begin{tabular}{l c c c c c c}
\toprule
\rowcolor{gray!10}
\textbf{Model} & \textbf{Prompt} & \textbf{Cora} & \textbf{PubMed} & \textbf{ArXiv} & \textbf{Products} & \textbf{Avg} \\ 
\midrule

\multirow{4}{*}{Llama3B} & original & 24.72 & 63.20 & 23.10 & 40.80 & 37.96 \\
& CoT & 42.19 & 71.43 & 29.90 & 50.21 & 48.43 \\
& BAG & 15.68 & 35.32 & 2.00 & 30.00 & 20.67 \\
& in-context few-shot & 39.48 & 62.20 & 25.63 & 42.85 & 42.52 \\
\midrule

\multirow{4}{*}{Llama8B} & original & 43.39 & 77.80 & 59.35 & 50.12 & 57.67 \\
& CoT & 53.51 & 81.80 & 53.24 & 47.41 & 58.99 \\
& BAG & 23.80 & 21.08 & 5.80 & 32.13 & 20.68 \\
& in-context few-shot & 51.29 & 80.13 & 54.60 & 52.20 & 59.41 \\
\midrule

\multirow{4}{*}{Qwen-plus} & original & 52.32 & 80.74 & 70.20 & 64.24 & 66.88 \\
& CoT & 61.59 & 83.21 & 66.23 & 67.55 & 69.65 \\
& BAG & 57.62 & 85.11 & 64.90 & 64.82 & 68.11 \\
& in-context few-shot & 52.32 & 82.01 & 70.86 & 59.60 & 66.20 \\
\midrule

\multirow{4}{*}{Qwen-max} & original & 58.60 & 89.53 & 68.08 & 69.33 & 71.39 \\
& CoT & 59.20 & 82.79 & 64.72 & 61.99 & 67.18 \\
& BAG & 57.61 & 88.28 & 67.33 & 66.33 & 69.89 \\
& in-context few-shot & 59.35 & 87.78 & 64.59 & 63.84 & 68.89 \\
\midrule

\multirow{4}{*}{GPT-4o} & original & 52.63 & 82.32 & 71.32 & 67.92 & 68.55 \\
& CoT & 57.12 & 84.90 & 67.53 & 62.18 & 67.93 \\
& BAG & 53.73 & 85.11 & 66.92 & 63.36 & 67.28 \\
& in-context few-shot & 56.52 & 85.40 & 66.10 & 64.91 & 68.23 \\
\midrule

\multirow{4}{*}{Deepseek V3} & original & 54.97 & 83.79 & 70.20 & 66.89 & 68.96 \\
& CoT & 59.60 & 85.29 & 62.91 & 65.56 & 68.34 \\
& BAG & 54.77 & 89.53 & 64.24 & 56.95 & 66.37 \\
& in-context few-shot & 58.28 & 85.54 & 63.58 & 62.25 & 67.41 \\
\midrule

\multirow{2}{*}{\textbf{Llama3B}}
& 1-hop w/o label & 39.48 & 64.50 & 29.50 & 53.00  & 46.62\\
& 2-hop w/o label & 49.63 & 69.92 & 29.50 & 56.10  & 51.28\\
\midrule

\multirow{2}{*}{\textbf{Llama8B}}
& 1-hop w/o label & 58.35 & 73.07 & 61.85 & 59.85  & 63.28\\
& 2-hop w/o label & 62.84 & 83.29 & 68.33 & 59.60  & 68.52\\
\midrule

\multirow{2}{*}{\textbf{Qwen-plus}}
& 1-hop w/o label & 68.87 & 85.73 & 73.83 \cellcolor{cyan!20} & 72.19  & 75.16\\
& 2-hop w/o label & 76.16 & 88.98 & 73.51 & 71.56  & 77.55\\
\midrule

\multirow{3}{*}{\textbf{tuned Llama3B}} & ego & 67.08 & 89.28 & 66.58 & 65.59 & 72.13\\
& 1-hop w/o label & 82.04 & 90.02 & 71.32 & 73.07 & 79.11\\
& 2-hop w/o label & 85.04 \cellcolor{cyan!50} & 91.52 & 72.82 & 77.89 \cellcolor{cyan!20} & 81.82 \cellcolor{cyan!20}\\
\midrule
\multirow{3}{*}{\textbf{tuned Llama8B}} & ego & 77.31 & 92.36 \cellcolor{cyan!20} & 70.12 & 73.74 & 78.38\\
& 1-hop w/o label & 84.54 \cellcolor{cyan!20} & 93.90 \cellcolor{cyan!50} & 74.33 \cellcolor{cyan!50} & 80.33 \cellcolor{cyan!50} & 83.28 \cellcolor{cyan!50} \\
& 2-hop w/o label & 89.67 \cellcolor{cyan!100} & 95.22 \cellcolor{cyan!100} & 76.01 \cellcolor{cyan!100} & 84.51 \cellcolor{cyan!100} & 86.35 \cellcolor{cyan!100} \\
\bottomrule

\end{tabular}
}
\end{table}


In Section \ref{sec:Fair Benchmark}, we provided a detailed summary of the performance of Llama3B, Llama8B, and Qwen-plus on the node classification task. This served as a foundation for understanding how different model sizes and architectures influence performance on graph-related problems. In this subsection, we expand our exploration by introducing additional large language models (LLMs) and examining diverse prompt formats.
\paragraph{Experiment Settings}
We compare the performance of \textbf{Llama3B} \cite{touvron2023llama}, \textbf{Llama8B} \cite{touvron2023llama}, \textbf{Qwen-plus} \cite{bai2023qwen}, \textbf{Qwen-max} \cite{bai2023qwen}, \textbf{GPT-4o} \cite{achiam2023gpt4}, and \textbf{Deepseek V3} \cite{liu2024deepseek} on node classification tasks in the \textbf{ego scenario}, where no structural information about the target node is provided. The evaluation uses four distinct prompt formats: the original prompt, Chain of Thought (CoT) \cite{cora}, Build A Graph (BAG) \cite{nlgraph}, and in-context few-shot. Below, we provide a brief overview of each prompt format:

\begin{itemize}
    \item \textbf{Original Prompt:} This prompt is identical to the one used in Section \ref{sec:Fair Benchmark}. It provides the basic context and query format for node classification tasks. Specific examples can be found in Table \ref{tab:Prompt Formats for Node Classification.}.
    
    \item \textbf{CoT:} Based on the original prompt, this format appends the instruction \emph{“Let’s think step by step”} to encourage the model to output a structured reasoning process in a step-by-step manner.
    
    \item \textbf{BAG:} Building upon the original prompt, this format adds the instruction \emph{“Let’s construct a graph with the nodes and edges first”}. This is designed to guide the model toward constructing an implicit graph representation before reasoning about the classification task.
    
    \item \textbf{In-Context Few-Shot:} This format supplements the original prompt with three concrete question-answer examples. These examples aim to provide additional context and demonstrate how similar tasks should be handled.
\end{itemize}

\paragraph{Results}
We summarize the results in Table \ref{tab:Comparison of Different LLMs on Node Classification}. The overall trend suggests that larger models tend to perform better. For instance, Llama8B consistently outperforms Llama3B, and Qwen-max generally achieves higher accuracy than Qwen-plus.

Across most models, CoT improves performance over the original prompt in Cora and PubMed, particularly for smaller models like Llama3B and Llama8B. This suggests that breaking down the reasoning process helps the model make better predictions. However, on ArXiv and Products, CoT leads to performance degradation. One possible reason is that small-class datasets (like Cora and PubMed) have clear category boundaries, making structured reasoning effective. In contrast, large-class datasets (like ArXiv and Products) have high inter-class similarity, increasing ambiguity. In such cases, CoT may introduce erroneous reasoning steps by misassociating nodes with semantically similar classes.

BAG results in significant accuracy drops for smaller models (e.g. Llama3B and Llama8B), while larger models show more stability but still do not outperform CoT or in-context few-shot. This could be due to the additional reasoning complexity introduced by BAG. Smaller models may struggle with multi-step inference and instead rely on more direct input-output mappings. Constructing a graph before classification might exceed their reasoning capacity, leading to performance declines.

In-context few-shot prompting improves results on Cora and PubMed but underperforms on ArXiv and Products. Due to token limitations, only three example categories are included in the few-shot prompt. This coverage is insufficient for datasets with a large number of classes, making it difficult for the model to generalize to unseen categories.

Finally, incorporating structural information is more effective than using CoT, BAG, or in-context few-shot prompting for improving LLM performance. The greatest improvement comes from instruction tuning, as even smaller models with proper tuning can significantly outperform larger untuned models. However, the trade-off is the higher computational cost and longer training time required for instruction tuning.

\paragraph{\textbf{Remark 7:}}
Larger models generally outperform smaller models in node classification tasks. CoT and in-context few-shot prompting significantly improve performance on small-class datasets, but may backfire on large-class datasets due to category ambiguity and token limitations. BAG imposes a heavy burden on smaller models, leading to noticeable performance drops. Instruction tuning combined with structural information yields the best results, though it requires careful consideration of computational costs.




\section{Prompt Formats}
\label{sec:Prompt formats}

\subsection{Prompt Formats for Node Classification}
\label{sec:Prompt Formats for Node Classification}
As discussed in Section \ref{sec:The Overall Setup}, there are five different prompt formats in node classification. We list them in Table \ref{tab:Prompt Formats for Node Classification.} and describe them in detail.

\subsection{Prompt Formats for Link Prediction}
\label{sec:Prompt Formats for Link Prediction}
In Section \ref{sec:The Overall Setup}, we design nine different prompt formats for link prediction, which are used for both instruction tuning and testing. These formats include:
\begin{enumerate}
    \item \textbf{1-hop}: The task is to determine if there is an edge between target node1 and target node2. The prompt provides the 1-hop neighbors and their descriptions for both nodes.
    
    \item \textbf{2-hop}: Similar to the 1-hop prompt but includes 2-hop neighbors and their descriptions for both target nodes.
    
    \item \textbf{1-hop node judge}: Determine whether a specific node is a 1-hop neighbor of the target node.
    
    \item \textbf{2-hop node judge}: Determine whether a specific node is a 2-hop neighbor of the target node.
    
    \item \textbf{3-hop node judge}: Determine whether a specific node is a 3-hop neighbor of the target node.
    
    \item \textbf{Middle node connection}: Determine if target node1 and target node2 are connected via a middle node.
    
    \item \textbf{1-hop node fill-in}: Given the 1-hop neighbors of a target node, identify an additional node that is also a 1-hop neighbor.
    
    \item \textbf{1-hop node selection}: Choose the correct 1-hop neighbor of the target node from four options (A, B, C, D).
    
    \item \textbf{2-hop node selection}: Choose the correct 2-hop neighbor of the target node from four options (A, B, C, D).
\end{enumerate}

To ensure the reasoning is non-trivial, target node1 and target node2 must not appear in each other’s 1-hop or 2-hop neighborhoods. Table \ref{tab:Prompt Formats for Link Prediction.} provides a detailed description of these nine prompt formats.


\subsection{Prompt Formats for Pure Graph Structure}
\label{sec:Prompt Formats for Pure Graph Structure}
In Section \ref{sec:Case 5}, we propose removing all node attributes and keeping only node IDs to focus solely on the structural reasoning capabilities of LLMs. We refer to these graph prompts as “prompts for pure graph structure”. In Table \ref{tab:Prompt Formats for Pure Graph Structure.}, we use the \textbf{1-hop w/o label} prompts for node classification and \textbf{1-hop} prompts for link prediction as examples, as the logic for other prompt formats follows a similar approach.
% \resizebox{\textwidth}{!}{


\onecolumn
\begin{longtable}{@{}>{\centering\arraybackslash}m{3cm} m{14cm}@{}}
\caption{Prompt formats for node classification.} \label{tab:Prompt Formats for Node Classification.} \\
\toprule

\textbf{Prompt Formats} & \textbf{Description} \\ 
\midrule
\endfirsthead
\toprule

\textbf{Prompt Formats} & \textbf{Description} \\ 
\midrule
\endhead

\endfoot

\endlastfoot
ego & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Given a graph language that describes the target node information from the Cora dataset, you need to understand the graph and the task definition and answer the question. \textcolor{cyan}{(<Target node>, <Node attributes>)}", 
\textcolor{red}{\textbf{"Question"}}: "Please predict the most appropriate category for the Target node. Choose from the following categories: \textcolor{cyan}{<Categories>}. Do not provide your reasoning. Answer: ", 
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \newline
\textbf{Example:} \newline
\textcolor{cyan}{(<Target node>, <Node attributes>)}: \#\# Target node: \textbackslash nPaper id: 540 \textbackslash nTitle: A Model-Based Approach to Blame-Assignment in Design \newline
\textcolor{cyan}{<Categories>}: Rule Learning \textbackslash nNeural Networks \textbackslash nCase Based \textbackslash nGenetic Algorithms \textbackslash nTheory \textbackslash nReinforcement Learning \textbackslash nProbabilistic Methods \newline
\textcolor{cyan}{<Correct answer>}: Case Based \\
\midrule

1-hop w/o label & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question. \textcolor{cyan}{(<Target node>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}", 
\textcolor{red}{\textbf{"Question"}}: "Please predict the most appropriate category for the Target node. Choose from the following categories: \textcolor{cyan}{<Categories>}. Do not provide your reasoning. Answer: ",
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \newline
\textcolor{cyan}{(<Target node>, <Node attributes>)}: \#\# Target node: \textbackslash nPaper id: 197 \textbackslash nTitle: Optimal Navigation in a Probibalistic World \newline
\textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}: Known neighbor papers at hop 1 (partial, may be incomplete): \textbackslash nPaper id: 295 \textbackslash nTitle: A Neuro-Dynamic Programming Approach to Retailer Inventory Management 1  \textbackslash nPaper id: 749 \textbackslash nTitle: On the Complexity of Solving Markov Decision Problems \textbackslash nPaper id: 3 \textbackslash nTitle: Planning and Acting in Partially Observable Stochastic Domains \textbackslash nPaper id: 633 \textbackslash nTitle: Chapter 1 Reinforcement Learning for Planning and Control
\textcolor{cyan}{<Categories>}: Rule Learning \textbackslash nNeural Networks \textbackslash nCase Based \textbackslash nGenetic Algorithms \textbackslash nTheory \textbackslash nReinforcement Learning \textbackslash nProbabilistic Methods \newline
\textcolor{cyan}{<Correct answer>}: Reinforcement Learning\\
\midrule

2-hop w/o label & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question. \textcolor{cyan}{(<Target node>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<2-hop neighbors>, <Node attributes>)}", 
\textcolor{red}{\textbf{"Question"}}: "Please predict the most appropriate category for the Target node. Choose from the following categories: \textcolor{cyan}{<Categories>}. Do not provide your reasoning. Answer: ",
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \newline
\textcolor{cyan}{(<Target node>, <Node attributes>)}: \#\# Target node: \textbackslash nPaper id: 546 \textbackslash nTitle: GREQE a Diplome des Etudes Approfondies en Economie Mathematique et Econometrie \newline
\textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}: Known neighbor papers at hop 1 (partial, may be incomplete): \textbackslash nPaper id: 163 \textbackslash nTitle: 4 Implementing Application Specific Routines  Genetic algorithms in search, optimization, and machine learning
\textcolor{cyan}{(<2-hop neighbors>, <Node attributes>)}: Known neighbor papers at hop 2 (partial, may be incomplete): \textbackslash nPaper id: 1573 \textbackslash nTitle: Genetics-based Machine Learning and Behaviour Based Robotics: A New Synthesis complexity grows \textbackslash nPaper id: 1069 \textbackslash nTitle: Extended Selection Mechanisms in Genetic Algorithms \textbackslash nPaper id: 2232 \textbackslash nTitle: Facing The Facts: Necessary Requirements For The Artificial Evolution of Complex Behaviour \newline
\textcolor{cyan}{<Categories>}: Rule Learning \textbackslash nNeural Networks \textbackslash nCase Based \textbackslash nGenetic Algorithms \textbackslash nTheory \textbackslash nReinforcement Learning \textbackslash nProbabilistic Methods \newline
\textcolor{cyan}{<Correct answer>}: Genetic Algorithms \\
\midrule

1-hop w label &
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question. \textcolor{cyan}{(<Target node>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>, <Labels>)}", 
\textcolor{red}{\textbf{"Question"}}: "Please predict the most appropriate category for the Target node. Choose from the following categories: \textcolor{cyan}{<Categories>}. Do not provide your reasoning. Answer: ",
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \newline
\textcolor{cyan}{(<Target node>, <Node attributes>)}: \#\# Target node: \textbackslash nPaper id: 2156 \textbackslash nTitle: WORST CASE PREDICTION OVER SEQUENCES UNDER LOG LOSS \newline
\textcolor{cyan}{(<1-hop neighbors>, <Node attributes>, <Labels>)}: Known neighbor papers at hop 1 (partial, may be incomplete): \textbackslash nPaper id: 2098 \textbackslash nTitle: Predicting a binary sequence almost as well as the optimal biased coin \textbackslash nLabel: Theory \textbackslash nPaper id: 453 \textbackslash nTitle: How to Use Expert Advice (Extended Abstract) \textbackslash nLabel: Theory \newline
\textcolor{cyan}{<Categories>}: Rule Learning \textbackslash nNeural Networks \textbackslash nCase Based \textbackslash nGenetic Algorithms \textbackslash nTheory \textbackslash nReinforcement Learning \textbackslash nProbabilistic Methods \newline
\textcolor{cyan}{<Correct answer>}: Theory\\
\midrule

2-hop w label &
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question. \textcolor{cyan}{(<Target node>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>, <Labels>)}, \textcolor{cyan}{(<2-hop neighbors>, <Node attributes>, <Labels>)}", 
\textcolor{red}{\textbf{"Question"}}: "Please predict the most appropriate category for the Target node. Choose from the following categories: \textcolor{cyan}{<Categories>}. Do not provide your reasoning. Answer: ",
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \newline
\textcolor{cyan}{(<Target node>, <Node attributes>)}: \#\# Target node: \textbackslash nPaper id: 1443 \textbackslash nTitle: Residual Q-Learning Applied to Visual Attention \newline
\textcolor{cyan}{(<1-hop neighbors>, <Node attributes>, <Labels>)}: Known neighbor papers at hop 1 (partial, may be incomplete): \textbackslash nPaper id: 1540 \textbackslash nTitle: MultiPlayer Residual Advantage Learning With General Function Approximation \textbackslash nPaper id: 1540 \textbackslash nTitle: MultiPlayer Residual Advantage Learning With General Function Approximation 
\textcolor{cyan}{(<2-hop neighbors>, <Node attributes>, <Labels>)}: Known neighbor papers at hop 2 (partial, may be incomplete): \textbackslash nPaper id: 565 \textbackslash nTitle: Machine Learning Learning to Predict by the Methods of Temporal Differences Keywords \textbackslash nLabel: Reinforcement Learning \textbackslash nPaper id: 842 \textbackslash nTitle: Metrics for Temporal Difference Learning \newline
\textcolor{cyan}{<Categories>}: Rule Learning \textbackslash nNeural Networks \textbackslash nCase Based \textbackslash nGenetic Algorithms \textbackslash nTheory \textbackslash nReinforcement Learning \textbackslash nProbabilistic Methods \newline
\textcolor{cyan}{<Correct answer>}: Reinforcement Learning \\

\bottomrule
\end{longtable}
% }




% \begin{table*}[htbp]
% \centering
% \begin{table*}[htbp]
% \centering
\begin{longtable}{@{}>{\centering\arraybackslash}m{3cm} m{14cm}@{}}
\caption{Prompt formats for link prediction.} \label{tab:Prompt Formats for Link Prediction.} \\
\toprule

\textbf{Prompt Formats} & \textbf{Description} \\ 
\midrule
\endfirsthead
\toprule
\textbf{Prompt Formats} & \textbf{Description} \\ 
\midrule
\endhead
\endfoot
\endlastfoot
1-hop & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Based on the cora dataset, determine whether two target nodes are connected by an edge. When you make a decision, please carefully consider the graph structure and the node information. If two nodes share similar structure or information, they are likely to be connected. \textcolor{cyan}{(<Target node1>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<Target node2>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}", 
\textcolor{red}{\textbf{"Question"}}: "Are Target Node1 and Target Node2 connected? Do not provide your reasoning. Only provide "Yes" or "No" based on your inference. Answer: ", 
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \\
\midrule

2-hop & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Based on the cora dataset, determine whether two target nodes are connected by an edge. When you make a decision, please carefully consider the graph structure and the node information. If two nodes share similar structure or information, they are likely to be connected. \textcolor{cyan}{(<Target node1>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<2-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<Target node2>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<2-hop neighbors>, <Node attributes>)}", 
\textcolor{red}{\textbf{"Question"}}: "Are Target Node1 and Target Node2 connected? Do not provide your reasoning. Only provide "Yes" or "No" based on your inference. Answer: ", 
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \\
\midrule

1-hop node judge & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and answer the question. When you make a decision, please carefully consider the graph structure and the node information. \textcolor{cyan}{(<Target node1>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<Target node2>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}", 
\textcolor{red}{\textbf{"Question"}}: "Based on the available partial information. Are Target Node1 and Target Node2 connected? Do not provide your reasoning. Only provide "Yes" or "No" based on your inference. Answer: ", 
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \\
\midrule

2-hop node judge & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and answer the question. When you make a decision, please carefully consider the graph structure and the node information. \textcolor{cyan}{(<Target node1>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<2-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<Target node2>, <Node attributes>)}", 
\textcolor{red}{\textbf{"Question"}}: "Based on the available partial information. Can Target node2 be a 2-hop neighbor of Target node1? Do not provide your reasoning. Only provide "Yes" or "No" based on your inference. Answer: ", 
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \\
\midrule

3-hop node judge & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and answer the question. When you make a decision, please carefully consider the graph structure and the node information. \textcolor{cyan}{(<Target node1>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<2-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<Target node2>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}", 
\textcolor{red}{\textbf{"Question"}}: "Based on the available partial information. Can Target node2 be a 3-hop neighbor of Target node1? Do not provide your reasoning. Only provide "Yes" or "No" based on your inference. Answer: ", 
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \\
\midrule

Middle node connection & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and answer the question. When you make a decision, please carefully consider the graph structure and the node information. \textcolor{cyan}{(<Target node1>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<Target node2>, <Node attributes>)}, \textcolor{cyan}{(<Middle node>, <Node attributes>)}",  
\textcolor{red}{\textbf{"Question"}}: "Can Target node1 be connected with Target node2 through the Middle node? Do not provide your reasoning. Only provide "Yes" or "No" based on your inference. Answer: ", 
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \\
\midrule

1-hop node fill-in & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and answer the question. When you make a decision, please carefully consider the graph structure and the node information. \textcolor{cyan}{(<Target node1>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}", 
\textcolor{red}{\textbf{"Question"}}: "Based on the available partial information. Which other node will be connected to Target node1 within one hop? Do not provide your reasoning. The answer should be the paper id. Answer: ", 
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \\
\midrule

1-hop node selection & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and answer the question. When you make a decision, please carefully consider the graph structure and the node information. \textcolor{cyan}{(<Target node1>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}", 
\textcolor{red}{\textbf{"Question"}}: "Based on the available partial information. Which other node can be connected to Target node1 within one hop? A.\textcolor{cyan}{(<Node A>,<Attribute>)} \textbackslash nB.\textcolor{cyan}{(<Node B>,<Attribute>)} \textbackslash nC.\textcolor{cyan}{(<Node C>,<Attribute>)} \textbackslash nD.\textcolor{cyan}{(<Node D>,<Attribute>)} Do not provide your reasoning. The answer should be A, B, C or D. Answer: ", 
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \\
\midrule

2-hop node selection & 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and answer the question. When you make a decision, please carefully consider the graph structure and the node information. \textcolor{cyan}{(<Target node1>, <Node attributes>)}, \textcolor{cyan}{(<1-hop neighbors>, <Node attributes>)}, \textcolor{cyan}{(<2-hop neighbors>, <Node attributes>)}", 
\textcolor{red}{\textbf{"Question"}}: "Based on the available partial information. Which other node can be a 2-hop neighbor of Target node1? A.\textcolor{cyan}{(<Node A>,<Attribute>)} \textbackslash nB.\textcolor{cyan}{(<Node B>,<Attribute>)} \textbackslash nC.\textcolor{cyan}{(<Node C>,<Attribute>)} \textbackslash nD.\textcolor{cyan}{(<Node D>,<Attribute>)} Do not provide your reasoning. The answer should be A, B, C or D. Answer: ", 
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \\


\bottomrule
\end{longtable}
% \end{table*}



% \begin{table*}[htbp]
% \centering
\begin{longtable}{@{}>{\centering\arraybackslash}m{3cm} m{14cm}@{}}
\caption{Prompt formats for pure graph structure.} \label{tab:Prompt Formats for Pure Graph Structure.} \\
\toprule
\textbf{Prompt Formats} & \textbf{Description} \\ 
\midrule
\endfirsthead
\toprule
\textbf{Prompt Formats} & \textbf{Description} \\ 
\midrule
\endhead
\endfoot
\endlastfoot
1-hop w/o label \newline (Node classification)& 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Give you a graph language that describes a graph structure and node information from cora dataset. You need to understand the graph and the task definition and answer the question. \textcolor{cyan}{<Target node>}, \textcolor{cyan}{<1-hop neighbors>}", 
\textcolor{red}{\textbf{"Question"}}: "Please predict the most appropriate category for the Target node. Choose from the following categories: \textcolor{cyan}{<Categories>}. Do not provide your reasoning. Answer: ",
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \newline
\textcolor{cyan}{(<Target node>, <Node attributes>)}: \#\# Target node: \textbackslash nPaper id: 197 \newline
\textcolor{cyan}{<1-hop neighbors>}: Known neighbor papers at hop 1 (partial, may be incomplete): \textbackslash nPaper id: 295 \textbackslash nPaper id: 749 \textbackslash nPaper id: 3 \textbackslash nPaper id: 633
\textcolor{cyan}{<Categories>}: Rule Learning \textbackslash nNeural Networks \textbackslash nCase Based \textbackslash nGenetic Algorithms \textbackslash nTheory \textbackslash nReinforcement Learning \textbackslash nProbabilistic Methods \newline
\textcolor{cyan}{<Correct answer>}: Reinforcement Learning\\
\midrule




1-hop \newline (Link prediction)& 
\textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Based on the cora dataset, determine whether two target nodes are connected by an edge. When you make a decision, please carefully consider the graph structure and the node information. If two nodes share similar structure or information, they are likely to be connected. \textcolor{cyan}{<Target node1>}, \textcolor{cyan}{<1-hop neighbors>}, \textcolor{cyan}{<Target node2>}, \textcolor{cyan}{<1-hop neighbors>}", 
\textcolor{red}{\textbf{"Question"}}: "Are Target Node1 and Target Node2 connected? Do not provide your reasoning. Only provide "Yes" or "No" based on your inference. Answer: ", 
\textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \newline
\textbf{Example:}\newline
\textcolor{cyan}{<Target node1>}: \#\# Target node1: \textbackslash nPaper id: 172\newline
\textcolor{cyan}{<1-hop neighbors>}: Known neighbor papers at hop 1 (partial, may be incomplete): \textbackslash nPaper id: 635 \textbackslash nPaper id: 430\newline
\textcolor{cyan}{<Target node2>}: \#\# Target node2: \textbackslash nPaper id: 245\newline
\textcolor{cyan}{<1-hop neighbors>}: Known neighbor papers at hop 1 (partial, may be incomplete): \textbackslash nPaper id: 1636\newline
\textcolor{cyan}{<Correct answer>}: Yes \\


% 2-hop & 
% \textcolor{red}{\textbf{"Context"}}: "You are a good graph reasoner. Based on the cora dataset, determine whether two target nodes are connected by an edge. When you make a decision, please carefully consider the graph structure and the node information. If two nodes share similar structure or information, they are likely to be connected. \textcolor{cyan}{<Target node1>}, \textcolor{cyan}{<1-hop neighbors>}, \textcolor{cyan}{<2-hop neighbors>)}, \textcolor{cyan}{<Target node2>}, \textcolor{cyan}{<1-hop neighbors>}, \textcolor{cyan}{<2-hop neighbors>}", 
% \textcolor{red}{\textbf{"Question"}}: "Are Target Node1 and Target Node2 connected? Do not provide your reasoning. Only provide "Yes" or "No" based on your inference. Answer: ", 
% \textcolor{red}{\textbf{"Answer"}}: "\textcolor{cyan}{<Correct answer>}" \\

\bottomrule
\end{longtable}
% \end{table*}
