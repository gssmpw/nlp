\section{Related Work}
Traffic flow forecasting stands as a quintessential challenge in spatio-temporal data prediction, with analogous tasks including the forecasting of shared bicycle demand, as well as the demand for buses and taxis, and the prediction of crowd flows, among others \cite{Li2015bike, Chai2018bike, hu2021bus, zhao2019bus}. Traditional statistical approaches such as ARIMA \cite{williams2003modeling} and SVM \cite{1997svm}, while prevalent in time series forecasting, often fall short due to their inability to account for spatial dimensions, making them less effective for complex spatio-temporal data sets.
The advent of deep learning has introduced methods adept at handling the intricacies and non-linearities inherent in traffic data. Convolutional Neural Networks (CNNs), in particular, have become a staple in traffic flow forecasting \cite{Zhang16DNN, Zhang2017Deep, Ouyang2022, yao2018modeling, Liu2019ACFMAD}. These networks interpret traffic flow data as images, where each pixel represents the traffic count within a specific grid cell over a given time interval. By leveraging techniques originally developed for image recognition \cite{Ted2022survey}, CNNs can effectively model the spatial relationships between different grid regions.
Recurrent Neural Networks (RNNs) have also been instrumental in the analysis of sequence data, bringing their sequence memorization capabilities to bear on traffic flow forecasting \cite{ye2019kdd, shi2015nips, zon2018ijcai}. 
More recent advancements have seen Graph Neural Networks (GNNs) rise to prominence for their ability to manage the spatio-temporal correlations present in traffic flow data, achieving state-of-the-art results \cite{Pan2022meta, Shen2022ttpnet, Sun2022multiview, Guo2022LearningD}. GNNs, initially designed for graph structure analysis, have found widespread application in node embedding \cite{pan2018} and node classification \cite{kipf2016semi}.
In the realm of transportation systems, GNNs, including graph convolutional and graph attention networks, have been adapted to model graph structures and have achieved remarkable performance. For instance, DCRNN \cite{li2018dcrnn} employs a bidirectional diffusion process to emulate real-world road conditions and utilizes gated recurrent units to capture temporal dynamics. ASTGCN \cite{guo2019attention}, on the other hand, utilizes dual attention layers to discern the dynamics of spatial dependencies and temporal correlations.
STGCN, Graph WaveNet, LSGCN, and AGCRN \cite{yu2018spatio, wu2019graph, huang2020lsgcn, bai2020adaptive} represent a lineage of methods that build upon Graph Convolutional Networks (GCNs) to extract spatio-temporal information. Notably, Graph WaveNet introduces a self-adaptive matrix to factor in the influence between nodes and their neighbors, while LSGCN employs an attention layer to achieve a similar end.
STSGCN, STFGNN, and STGODE \cite{song2020stsgcn, li2021stfgnn, zheng2021ode} propose GCN methodologies designed to capture spatio-temporal information in a synchronous manner. MTGNN \cite{Wu2020MTGNN} introduces a graph learning module that constructs a dynamic graph by calculating the similarity between learnable node embeddings. DMSTGCN \cite{Han2021DMSTGCN} captures spatio-temporal characteristics by forging dynamic associations between nodes.
STPGNN \cite{STPGNN} enhances predictive accuracy by taking into account special nodes within the road network. 
In addition to GNN-based methods, several approaches leveraging Transformers \cite{pdformer, bistat} and pre-training \cite{li2023gptst, Unist} have also been proposed. These methods have also shown promising results. However, both Transformer-based and pre-training approaches, along with GNNs, still encounter significant computational challenges when identifying nodes relationships, which limits the scalability of these models on large-scale datasets.
Existing adaptive graph neural network methods often rely on fully connected graphs to bolster the model's learning capabilities. Yet, the exponential growth in the number of edges with an increase in nodes poses a challenge for these methods when generalizing to larger-scale datasets.
To counter this, AGS \cite{kdd2023ags} has proposed a method for significantly simplifying the adaptive matrix, thereby reducing the model's computational load. However, this approach is limited to the inference stage. In practical applications, the computational cost during the training phase often dwarfs that of the inference phase. A method that maintains linear complexity during training can significantly enhance the model's operational efficiency.
BigST \cite{bigst2024} introduces a method that employs kernel functions to linearly approximate graph convolution operations, yielding a graph prediction model with linear complexity. However, kernel-based methods can sometimes result in anomalous gradient values during training, impacting model convergence and, by extension, the model's performance.
Amidst the ever-expanding scale of traffic data, there is an urgent need for graph neural network methods capable of delivering high-precision predictions at scale.

\if 0

\subsection{Traffic Flow Forecasting}
Traffic flow forecasting is a classical spatio-temporal data forecasting problem.
Similar problems include shared bicycle demand forecasting, bus and taxi demand forecasting, crowd flow forecasting, etc~\cite{Li2015bike, Chai2018bike,hu2021bus,zhao2019bus}.
Traditional statistical methods like ARIMA~\cite{williams2003modeling} and SVM~\cite{1997svm} are widely used in time series prediction.
Since they ignore the spatial information, it is difficult for them to handle complex spatio-temporal data.
Recently, deep learning methods have often used for handling the non-linearity and complexity of traffic data.
Convolutional Neural Networks (CNNs) have been regularly applied to traffic flow prediction~\cite{Zhang16DNN, Zhang2017Deep, Ouyang2022, yao2018modeling}.
Each cell in the set records the number of vehicles passing in that cell in a time period.
In order to capture the spatial correlations between the grid regions, methods with CNNs model the traffic flow readings as an image, and similar techniques developed for image recognition can be easily applied~\cite{Ted2022survey}.
For better investigation of sequence data, Recurrent Neural Networks (RNNs) were proposed.
With the memorization capability to sequences, methods with RNNs were soon applied to traffic flow forecasting~\cite{ye2019kdd, shi2015nips, zon2018ijcai}.
More recently, methods with Graph Neural Networks are proposed to handle spatio-temporal correlations in traffic flow data and obtain impressive results~\cite{Pan2022meta, Shen2022ttpnet, Sun2022multiview, Guo2022LearningD}.
Graph Neural networks (GNN) are originally designed to study the structure of the graph and are widely used in node embedding~\cite{pan2018}, node classification~\cite{kipf2016semi}, and so on.
In recent years, to model the graph structures in transportation systems, GNNs such as graph convolutional and graph attention networks have been used for the problem and achieved SOTA performance.
DCRNN~\cite{li2018dcrnn} proposes a bi-directional process of diffusion to simulate actual road conditions, and uses gated recurrent units to capture temporal information.
ASTGCN~\cite{guo2019attention} uses two attention layers to capture the dynamics of spatial dependencies and temporal correlations.
STGCN, Graph WaveNet,  LSGCN and AGCRN~\cite{yu2018spatio, wu2019graph, huang2020lsgcn, bai2020adaptive} follow and improve the GCN methods to extract spatio-temporal information. 
In particular, Graph WaveNet designs a self-adaptive matrix to take the influence between nodes and their neighbors into account while LSGCN uses an attention layer to do similar work.
STSGCN, STFGNN and STGODE~\cite{song2020stsgcn,li2021stfgnn,zheng2021ode} propose GCN methods based on similar characteristics that can capture spatio-temporal information synchronously.
MTGNN~\cite{Wu2020MTGNN} proposes a graph learning module that constructs a dynamic graph by computing the similarity between learnable node embeddings.
DMSTGCN~\cite{Han2021DMSTGCN} capture the spatio-temporal characteristics by constructing dynamic associations between nodes.
STPGNN~\cite{STPGNN} enhances the model's predictive accuracy by considering special nodes within the road network. However, the process of identifying these special nodes in the model remains exponential, which hinders its effective scalability on large-scale datasets.
However, existing adaptive graph neural network methods often utilize fully connected graphs to enhance the model's learning capability. 
Yet, due to the exponential growth in the number of edges with the increase in nodes, current methods struggle to generalize to larger-scale datasets.
To address this, AGS~\cite{kdd2023ags} proposed a method for significantly simplifying the adaptive matrix, reducing the computational workload of the model. However, this method can only be employed during the inference stage. 
In practical applications, the computational cost during the training phase is often orders of magnitude higher than that during the inference phase. 
A method with linear complexity during training can enhances the model's operational efficiency.
BigST \cite{bigst2024} proposes a method that employs kernel functions to linearly approximate graph convolution operations, resulting in a graph prediction model with linear complexity. 
However, methods based on kernel functions can lead to the occurrence of anomalous gradient values during the training process, which affects the model's convergence and, consequently, limits the model's performance.
In the face of the ever-growing scale of traffic data, there is a current demand for graph neural network methods that can provide high-precision predictions on a large scale.


\subsection{Graph Neural Networks}
Graph Neural networks (GNN) are originally designed to study the structure of the graph and are widely used in node embedding~\cite{pan2018}, node classification~\cite{kipf2016semi}, and so on.
In recent years, to model the graph structures in transportation systems, GNNs such as graph convolutional and graph attention networks have been used for the problem and achieved SOTA performance.
Bruna~{\em et al.}~\cite{bruna2013spectral} proposes GCN based on the spectral graph theory, which can use a filter to smooth the input graph signal and aggregate the information of neighbor nodes.
Defferrard~{\em et al.}~\cite{defferrard2016convolutional} proposes a Chebyshev extension to reduce the complexity of laplacians computation of GCN.
Kipf and Welling~{\em et al.}~\cite{kipf2016semi} simplifies the Chebyshev extension method.
Velickovic~{\em et al.}~\cite{velickovic2017graph} proposes GAT, which introduces attention mechanisms into graph to update the weight of a node's neighbors.
Monti~{\em et al.}~\cite{monti2017} applies Gaussian kernels to learn the weight of a node's neighbors.
Hamilton, Ying, and Leskovec~{\em et al.}~\cite{hamilton2017} proposes GraphSAGE, which aggregates the features of nodes' neighbors and themselves through a fixed sampling method.


\fi