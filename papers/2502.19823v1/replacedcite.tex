\section{Related Work}
Traffic flow forecasting stands as a quintessential challenge in spatio-temporal data prediction, with analogous tasks including the forecasting of shared bicycle demand, as well as the demand for buses and taxis, and the prediction of crowd flows, among others ____. Traditional statistical approaches such as ARIMA ____ and SVM ____, while prevalent in time series forecasting, often fall short due to their inability to account for spatial dimensions, making them less effective for complex spatio-temporal data sets.
The advent of deep learning has introduced methods adept at handling the intricacies and non-linearities inherent in traffic data. Convolutional Neural Networks (CNNs), in particular, have become a staple in traffic flow forecasting ____. These networks interpret traffic flow data as images, where each pixel represents the traffic count within a specific grid cell over a given time interval. By leveraging techniques originally developed for image recognition ____, CNNs can effectively model the spatial relationships between different grid regions.
Recurrent Neural Networks (RNNs) have also been instrumental in the analysis of sequence data, bringing their sequence memorization capabilities to bear on traffic flow forecasting ____. 
More recent advancements have seen Graph Neural Networks (GNNs) rise to prominence for their ability to manage the spatio-temporal correlations present in traffic flow data, achieving state-of-the-art results ____. GNNs, initially designed for graph structure analysis, have found widespread application in node embedding ____ and node classification ____.
In the realm of transportation systems, GNNs, including graph convolutional and graph attention networks, have been adapted to model graph structures and have achieved remarkable performance. For instance, DCRNN ____ employs a bidirectional diffusion process to emulate real-world road conditions and utilizes gated recurrent units to capture temporal dynamics. ASTGCN ____, on the other hand, utilizes dual attention layers to discern the dynamics of spatial dependencies and temporal correlations.
STGCN, Graph WaveNet, LSGCN, and AGCRN ____ represent a lineage of methods that build upon Graph Convolutional Networks (GCNs) to extract spatio-temporal information. Notably, Graph WaveNet introduces a self-adaptive matrix to factor in the influence between nodes and their neighbors, while LSGCN employs an attention layer to achieve a similar end.
STSGCN, STFGNN, and STGODE ____ propose GCN methodologies designed to capture spatio-temporal information in a synchronous manner. MTGNN ____ introduces a graph learning module that constructs a dynamic graph by calculating the similarity between learnable node embeddings. DMSTGCN ____ captures spatio-temporal characteristics by forging dynamic associations between nodes.
STPGNN ____ enhances predictive accuracy by taking into account special nodes within the road network. 
In addition to GNN-based methods, several approaches leveraging Transformers ____ and pre-training ____ have also been proposed. These methods have also shown promising results. However, both Transformer-based and pre-training approaches, along with GNNs, still encounter significant computational challenges when identifying nodes relationships, which limits the scalability of these models on large-scale datasets.
Existing adaptive graph neural network methods often rely on fully connected graphs to bolster the model's learning capabilities. Yet, the exponential growth in the number of edges with an increase in nodes poses a challenge for these methods when generalizing to larger-scale datasets.
To counter this, AGS ____ has proposed a method for significantly simplifying the adaptive matrix, thereby reducing the model's computational load. However, this approach is limited to the inference stage. In practical applications, the computational cost during the training phase often dwarfs that of the inference phase. A method that maintains linear complexity during training can significantly enhance the model's operational efficiency.
BigST ____ introduces a method that employs kernel functions to linearly approximate graph convolution operations, yielding a graph prediction model with linear complexity. However, kernel-based methods can sometimes result in anomalous gradient values during training, impacting model convergence and, by extension, the model's performance.
Amidst the ever-expanding scale of traffic data, there is an urgent need for graph neural network methods capable of delivering high-precision predictions at scale.

\if 0

\subsection{Traffic Flow Forecasting}
Traffic flow forecasting is a classical spatio-temporal data forecasting problem.
Similar problems include shared bicycle demand forecasting, bus and taxi demand forecasting, crowd flow forecasting, etc____.
Traditional statistical methods like ARIMA____ and SVM____ are widely used in time series prediction.
Since they ignore the spatial information, it is difficult for them to handle complex spatio-temporal data.
Recently, deep learning methods have often used for handling the non-linearity and complexity of traffic data.
Convolutional Neural Networks (CNNs) have been regularly applied to traffic flow prediction____.
Each cell in the set records the number of vehicles passing in that cell in a time period.
In order to capture the spatial correlations between the grid regions, methods with CNNs model the traffic flow readings as an image, and similar techniques developed for image recognition can be easily applied____.
For better investigation of sequence data, Recurrent Neural Networks (RNNs) were proposed.
With the memorization capability to sequences, methods with RNNs were soon applied to traffic flow forecasting____.
More recently, methods with Graph Neural Networks are proposed to handle spatio-temporal correlations in traffic flow data and obtain impressive results____.
Graph Neural networks (GNN) are originally designed to study the structure of the graph and are widely used in node embedding____, node classification____, and so on.
In recent years, to model the graph structures in transportation systems, GNNs such as graph convolutional and graph attention networks have been used for the problem and achieved SOTA performance.
DCRNN____ proposes a bi-directional process of diffusion to simulate actual road conditions, and uses gated recurrent units to capture temporal information.
ASTGCN____ uses two attention layers to capture the dynamics of spatial dependencies and temporal correlations.
STGCN, Graph WaveNet,  LSGCN and AGCRN____ follow and improve the GCN methods to extract spatio-temporal information. 
In particular, Graph WaveNet designs a self-adaptive matrix to take the influence between nodes and their neighbors into account while LSGCN uses an attention layer to do similar work.
STSGCN, STFGNN and STGODE____ propose GCN methods based on similar characteristics that can capture spatio-temporal information synchronously.
MTGNN____ proposes a graph learning module that constructs a dynamic graph by computing the similarity between learnable node embeddings.
DMSTGCN____ capture the spatio-temporal characteristics by constructing dynamic associations between nodes.
STPGNN____ enhances the model's predictive accuracy by considering special nodes within the road network. However, the process of identifying these special nodes in the model remains exponential, which hinders its effective scalability on large-scale datasets.
However, existing adaptive graph neural network methods often utilize fully connected graphs to enhance the model's learning capability. 
Yet, due to the exponential growth in the number of edges with the increase in nodes, current methods struggle to generalize to larger-scale datasets.
To address this, AGS____ proposed a method for significantly simplifying the adaptive matrix, reducing the computational workload of the model. However, this method can only be employed during the inference stage. 
In practical applications, the computational cost during the training phase is often orders of magnitude higher than that during the inference phase. 
A method with linear complexity during training can enhances the model's operational efficiency.
BigST ____ proposes a method that employs kernel functions to linearly approximate graph convolution operations, resulting in a graph prediction model with linear complexity. 
However, methods based on kernel functions can lead to the occurrence of anomalous gradient values during the training process, which affects the model's convergence and, consequently, limits the model's performance.
In the face of the ever-growing scale of traffic data, there is a current demand for graph neural network methods that can provide high-precision predictions on a large scale.


\subsection{Graph Neural Networks}
Graph Neural networks (GNN) are originally designed to study the structure of the graph and are widely used in node embedding____, node classification____, and so on.
In recent years, to model the graph structures in transportation systems, GNNs such as graph convolutional and graph attention networks have been used for the problem and achieved SOTA performance.
Bruna~{\em et al.}____ proposes GCN based on the spectral graph theory, which can use a filter to smooth the input graph signal and aggregate the information of neighbor nodes.
Defferrard~{\em et al.}____ proposes a Chebyshev extension to reduce the complexity of laplacians computation of GCN.
Kipf and Welling~{\em et al.}____ simplifies the Chebyshev extension method.
Velickovic~{\em et al.}____ proposes GAT, which introduces attention mechanisms into graph to update the weight of a node's neighbors.
Monti~{\em et al.}____ applies Gaussian kernels to learn the weight of a node's neighbors.
Hamilton, Ying, and Leskovec~{\em et al.}____ proposes GraphSAGE, which aggregates the features of nodes' neighbors and themselves through a fixed sampling method.


\fi