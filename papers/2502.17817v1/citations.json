[
  {
    "index": 0,
    "papers": [
      {
        "key": "rajpurkar2016squad",
        "author": "Rajpurkar, P",
        "title": "Squad: 100,000+ questions for machine comprehension of text"
      },
      {
        "key": "yang2019xlnet",
        "author": "Yang, Zhilin",
        "title": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "lewis2019bart",
        "author": "Lewis, Mike",
        "title": "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension"
      },
      {
        "key": "zhang2020pegasus",
        "author": "Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter",
        "title": "Pegasus: Pre-training with extracted gap-sentences for abstractive summarization"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, A",
        "title": "Attention is all you need"
      },
      {
        "key": "wu2016google",
        "author": "Wu, Yonghui",
        "title": "Google's neural machine translation system: Bridging the gap between human and machine translation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chen2023token",
        "author": "Chen, Yutian and Kang, Hao and Zhai, Vivian and Li, Liangze and Singh, Rita and Raj, Bhiksha",
        "title": "Token prediction as implicit classification to identify LLM-generated text"
      },
      {
        "key": "yu2024breaking",
        "author": "Yu, Yao-Ching and Kuo, Chun-Chih and Ye, Ziqi and Chang, Yu-Cheng and Li, Yueh-Se",
        "title": "Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "cover1999elements",
        "author": "Cover, Thomas M",
        "title": "Elements of information theory"
      },
      {
        "key": "covert2023learning",
        "author": "Covert, Ian Connick and Qiu, Wei and Lu, Mingyu and Kim, Na Yoon and White, Nathan J and Lee, Su-In",
        "title": "Learning to maximize mutual information for dynamic feature selection"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "chen2024learning",
        "author": "Chen, Xin and Huang, Hanxian and Gao, Yanjun and Wang, Yi and Zhao, Jishen and Ding, Ke",
        "title": "Learning to Maximize Mutual Information for Chain-of-Thought Distillation"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "kamthawee2024mist",
        "author": "Kamthawee, Krissanee and Udomcharoenchaikit, Can and Nutanong, Sarana",
        "title": "MIST: mutual information maximization for short text clustering"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "bengio2015scheduled",
        "author": "Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam",
        "title": "Scheduled sampling for sequence prediction with recurrent neural networks"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wang2022code4struct",
        "author": "Wang, Xingyao and Li, Sha and Ji, Heng",
        "title": "Code4struct: Code generation for few-shot event structure prediction"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "liu2022autoregressive",
        "author": "Liu, Tianyu and Jiang, Yuchen and Monath, Nicholas and Cotterell, Ryan and Sachan, Mrinmaya",
        "title": "Autoregressive structured prediction with language models"
      }
    ]
  }
]