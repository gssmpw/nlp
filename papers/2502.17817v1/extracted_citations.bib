@article{bengio2015scheduled,
  title={Scheduled sampling for sequence prediction with recurrent neural networks},
  author={Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{chen2023token,
  title={Token prediction as implicit classification to identify LLM-generated text},
  author={Chen, Yutian and Kang, Hao and Zhai, Vivian and Li, Liangze and Singh, Rita and Raj, Bhiksha},
  journal={arXiv preprint arXiv:2311.08723},
  year={2023}
}

@article{chen2024learning,
  title={Learning to Maximize Mutual Information for Chain-of-Thought Distillation},
  author={Chen, Xin and Huang, Hanxian and Gao, Yanjun and Wang, Yi and Zhao, Jishen and Ding, Ke},
  journal={arXiv preprint arXiv:2403.03348},
  year={2024}
}

@book{cover1999elements,
  title={Elements of information theory},
  author={Cover, Thomas M},
  year={1999},
  publisher={John Wiley \& Sons}
}

@inproceedings{covert2023learning,
  title={Learning to maximize mutual information for dynamic feature selection},
  author={Covert, Ian Connick and Qiu, Wei and Lu, Mingyu and Kim, Na Yoon and White, Nathan J and Lee, Su-In},
  booktitle={International Conference on Machine Learning},
  pages={6424--6447},
  year={2023},
  organization={PMLR}
}

@inproceedings{kamthawee2024mist,
  title={MIST: mutual information maximization for short text clustering},
  author={Kamthawee, Krissanee and Udomcharoenchaikit, Can and Nutanong, Sarana},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={11309--11324},
  year={2024}
}

@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}

@article{liu2022autoregressive,
  title={Autoregressive structured prediction with language models},
  author={Liu, Tianyu and Jiang, Yuchen and Monath, Nicholas and Cotterell, Ryan and Sachan, Mrinmaya},
  journal={arXiv preprint arXiv:2210.14698},
  year={2022}
}

@article{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, P},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{wang2022code4struct,
  title={Code4struct: Code generation for few-shot event structure prediction},
  author={Wang, Xingyao and Li, Sha and Ji, Heng},
  journal={arXiv preprint arXiv:2210.12810},
  year={2022}
}

@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}

@article{yang2019xlnet,
  title={XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  author={Yang, Zhilin},
  journal={arXiv preprint arXiv:1906.08237},
  year={2019}
}

@article{yu2024breaking,
  title={Breaking the Ceiling of the LLM Community by Treating Token Generation as a Classification for Ensembling},
  author={Yu, Yao-Ching and Kuo, Chun-Chih and Ye, Ziqi and Chang, Yu-Cheng and Li, Yueh-Se},
  journal={arXiv preprint arXiv:2406.12585},
  year={2024}
}

@inproceedings{zhang2020pegasus,
  title={Pegasus: Pre-training with extracted gap-sentences for abstractive summarization},
  author={Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter},
  booktitle={International conference on machine learning},
  pages={11328--11339},
  year={2020},
  organization={PMLR}
}

