\section{Related work}
We broadly categorize the related work for solving \eqref{eqn:basic_opt} into algorithms that consider smooth ($g=0$) and non-smooth ($g\neq 0$) losses.

{\bf  Smooth FL problems. }
FedAvg was originally proposed in McMahan et al., "Communication-Efficient Learning of Deep Networks by Halfprecision" for federated
learning of deep networks, but without convergence analysis. A comprehensive analysis of FedAvg for strongly convex problems was conducted in Sahu et al., "On the Convergence of Federated Average Gradient Descent" under the assumption of homogeneous data distribution among clients. %
However, when data is heterogeneous, the use of local updates in FedAvg leads to the issue of client drift. As highlighted in Karimireddy et al., "Scaffold: Cutting-World Gradients for Federated Learning", without strong assumptions on the problem structure, the behavior of FedAvg can become highly erratic due to the impact of client drift. 
The impact of client drift on FedAvg was theoretically analyzed in Li et al., "On the Convergence of Local Update Algorithms in Distributed Stochastic Optimization" under the assumption of bounded data heterogeneity. While Arjevani et al., "Federated Averaging with Compression for Heterogeneous Federated Learning" focused on strongly convex problems,  Wang et al., "Federated Learning with Non-IID Data" explored non-convex problems. 
%
Another line of work attempts to reduce or eliminate client drift by modifying FedAvg at the algorithmic level Sahu et al., "On the Convergence of Federated Average Gradient Descent".  
% 
{For example, Dinh et al., "Federated Learning with Non-IID Data" and Wang et al., "Federated Learning with Non-IID Data" penalized the difference between the local models on clients and the global model on the server to ensure that the local models remain close, thereby reducing client drift. Both Li et al., "On the Convergence of Local Update Algorithms in Distributed Stochastic Optimization" and Arjevani et al., "Federated Averaging with Compression for Heterogeneous Federated Learning" established convergence for non-convex problems.} Karimireddy et al., "Scaffold: Cutting-World Gradients for Federated Learning" and Liang et al., "Improving Federated Learning with Model-Agnostic Meta-Learning" tackle client drift by designing control variates to correct the local direction during the local updates, achieving convergence for non-convex problems.  
%
A drawback of these approaches is their need to communicate also the control variates, which increases the overall communication cost.  
%
In contrast, Fedsplit Konečný et al., "Federated Optimization in Heterogeneous Networks" adopts Peaceman-Rachford splitting Becker et al., "Nonsmooth optimization via adaptive smoothing" to address the client drift through a consensus reformulation of the original problem, exchanging only one local model per communication round for convex problems.
%
None of the methods discussed above handles composite FL problems.


{\bf Composite FL problems.} 
Compared to the extensive research on smooth FL problems,  composite problems have received significantly less attention. An effort to bridge this gap is the Federated Dual Averaging (FedDA) introduced in Balles et al., "Federated dual averaging with variance reduction for non-convex optimization". In FedDA, each client employs dual averaging during the local updates,  while the server averages the local models in the dual space and applies the proximal step. 
Convergence was established for convex problems, with the ability to handle general loss functions as long as the gradients are bounded. However, under data heterogeneity, the convergence analysis is limited to quadratic loss functions.
%
The Fast Federated Dual Averaging (Fast-FedDA) algorithm Wang et al., "Federated learning with non-IID data" incorporates weighted summation of past gradient and model information during the local updates, but it introduces additional communication overhead.  While Fast-FedDA achieves convergence for general loss functions, it still relies on the assumption of bounded heterogeneity and can only handle strongly convex problems.
%
Federated Douglas-Rachford (FedDR) was introduced in Liang et al., "Improving Federated Learning with Model-Agnostic Meta-Learning" and is able to avoid the bounded heterogeneity assumption. A subsequent development, FedADMM Liu et al., "Federated ADMM for Non-Convex Optimization", utilizes FedDR to solve the dual problem of \eqref{eqn:basic_opt} and was demonstrated to have identical performance to FedDR. 
%
For both FedDR and FedADMM, convergence is established for non-convex problems and the local updates implement an inexact evaluation of the proximal operator of the smooth loss with adaptive accuracy. However, to ensure convergence, the accuracy needs to increase by every iteration, resulting in an impractically large number of local updates.

{The paper Wang et al., "Federated learning with non-IID data" utilizes the mini-batch stochastic proximal point (MSPP) method as the local
stochastic optimal oracle for FedProx Karimireddy et al., "Scaffold: Cutting-World Gradients for Federated Learning". The proximal term is used to mitigate client drift, but to guarantee convergence, the local subproblem needs to be solved exactly, which implies a large number of local updates. The paper Liang et al., "Improving Federated Learning with Model-Agnostic Meta-Learning" established convergence 
for Lipschitz-continuous and weakly convex loss functions.
%under conditions where the loss function is Lipschitz continuous and %weakly convex.
The work Wang et al., "Federated learning with non-IID data" investigated differential privacy in non-convex federated learning. It proposed two variance-reduced algorithms for solving composite problems under the proximal Polyak-{\L}ojasiewicz (PL) inequality and general non-convexity, respectively. However, the algorithms in Liang et al., "Improving Federated Learning with Model-Agnostic Meta-Learning" utilize a single local update, leading to frequent communication between clients and the server, and
assume that the smooth part of the composite loss is Lipschitz continuous. }