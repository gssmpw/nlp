\section{Related Work}
\paragraph{LLM Guardrails.}
A large body of work has been published on establishing effective guardrails for LLMs. These approaches are designed to restrict the model to responses that align with the deployer's values. One of the first approaches was Reinforcement Learning with Human Feedback (RLHF) **Bansal, "Reinforcement Learning with Human Feedback for Robust and Generalizable Decision Making"** ____, which uses human preferences to guide LLM training.
Extensions such as Safe-RLHF add cost models to penalize harmful behavior, ensuring a balance between helpfulness and harmlessness during optimization ____.
RLHF's foundation in reinforcement learning has given rise to techniques such as Proximal Policy Optimization (PPO) **Schulman, "Proximal Policy Optimization Algorithms"** ____, the more recent Direct Preference Optimization (DPO) ____,
and Generalized Policy Optimization (GPO) ____, which incorporates diverse optimization objectives, useful for safety-critical scenarios.
For an in-depth survey of this area, we direct the reader to **Stadler, "A Survey on Reinforcement Learning with Human Feedback"**.
Unlike the preceding approaches that fine-tune guardrails into the parameters of an LLM, a number of works have proposed using LLMs to classify content as either safe or unsafe.
Llama Guard categorizes the inputs and outputs of an LLM into different unsafe content categories ____ . Conversely, **Guo, "Safe Output Classification for Large Language Models"** classify if an output is safe with respect to a system prompt.
For a complete overview on LLM guardrails, we direct the interested reader to a recent survey of this area, ____ .
Existing LLM guardrail techniques have been proven effective to different levels. However, these guardrails only come with empirical evidence of their proficiency against existing attacks, and hence, many have been circumvented shortly after deployment. Conversely, **Raghunathan, "VALID: A Provable Framework for Validating the Safety of Large Language Models"** offers a provable high-probability guarantee against undesirable behavior, reflecting recent advocacy for such provable assurances ____.

\paragraph{Out-of-Distribution Detection. }
Out-of-distribution (OOD) detection has received a lot of attention in recent years in NLP. Commonly, the problem is treated as text classification and softmax probabilities of class predictions **Hendrycks, "Deep Anomaly Detection"** or energy scores ____ are deployed as discriminant scores. Another group of methods employs distance-based methods, relying on OOD responses being distant from ID responses in latent space, often utilizing Mahalanobis distance and sometimes incorporating contrastive learning techniques ____ . Finally, rooted in classical statistics, a number of studies suggest using the log-likelihood ratio (LLR) as a discriminate score, comparing likelihoods from ID and OOD proxy models ____ . ____ offer a comprehensive review of LLMs for OOD detection. While many of these works have strong empirical detection results, their focus is OOD detection rather than certification, and hence they do not provide theoretical guarantees or certificates on model behavior.


\paragraph{Certifying LLMS.}
A number of certification approaches have been proposed for LLMs in various contexts. For instance, **Carmen, "A Framework for Certifying the Knowledge Comprehension Ability of Large Language Models"** aim to certify the knowledge comprehension ability of LLMs and ____ discuss what criteria should be certified to ensure fairness. Most relevant here is work on certification against adversarial inputs. ____ discuss certifying the robustness of LLMs to input perturbations in embedding space. Commonly, adversarial certification is studied for text classification rather than generation ____ . ____ introduce a framework for defending against adversarial perturbations in token space by performing a small number of substitutions around a given input. In contrast VALID comes with certificates that holds for \emph{all inputs}, rather than perturbations around a specific input.