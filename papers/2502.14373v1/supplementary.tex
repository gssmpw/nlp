%%%% ijcai25.tex

\typeout{IJCAI--25 Instructions for Authors}

% These are the instructions for authors for IJCAI-25.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai25.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai25}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[switch]{lineno}
\usepackage{multirow, colortbl}
\usepackage{adjustbox}
\usepackage{amssymb}
\usepackage{colortbl}
\usepackage[svgnames]{xcolor}
% Comment out this line in the camera-ready submission
\linenumbers

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.


% PDF Info Is REQUIRED.

% Please leave this \pdfinfo block untouched both for the submission and
% Camera Ready Copy. Do not include Title and Author information in the pdfinfo section
\pdfinfo{
/TemplateVersion (IJCAI.2025.0)
}

\title{CrossVTON: Mimicking the Logic Reasoning on {Cro}ss-category \\ Virtual Try-on guided by Tri-zone Priors \\ Supplementary Material}
%%%Logic chain
%%%Triton: Mimicking the Human Brain Logic on cross-category virtual tryon guided by Tri-zone priors
% COT-VTON: Chain of Thought Prompting Tri-zone Priors for Cross-category Virtual Try-on
%CrossVTON: Chain of Thought Prompting Tri-zone Priors for Cross-category Virtual Try-on
%%%迭代式的学习范式
%%develop logic imagination

% Single author syntax
\author{
    Paper ID: 3126
    % \affiliations
    % Affiliation
    % \emails
    % email@example.com
}

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)
\iffalse
\author{
First Author$^1$
\and
Second Author$^2$\and
Third Author$^{2,3}$\And
Fourth Author$^4$\\
\affiliations
$^1$First Affiliation\\
$^2$Second Affiliation\\
$^3$Third Affiliation\\
$^4$Fourth Affiliation\\
\emails
\{first, second\}@example.com,
third@other.example.com,
fourth@example.com
}
\fi

\begin{document}

\maketitle

\section{Overview}
\label{sec:Overview}
% 
In this supplementary document, we present additional details and results to complement the paper. 

\subsection{Evaluation Detail of Acc-Qwen}

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.88\linewidth]{Figure/qwen-example.png}
    \vspace{-2mm}
    \caption{Input image for Qwen-VL-Max.}
    \vspace{-4mm}
    \label{fig:qwen_input}
\end{figure}

As shown in Fig.\ref{fig:qwen_input}, the input model image, input garment image and try-on result are spliced together as input of Qwen-VL-Max. The Prompt for the Multimodal Large Language Model as follows:

\textit{I used the virtual try-on algorithm to replace the model‘s garment in the left-hand image with the garment in the middle. Then produced the output on the right. If the overall model image on the right is reasonable and matches the type and style of the middle-image clothing, it’s considered reasonable. If the output image is the same as the input model image or the garment of output is not consistent with the middle image, the output is unreasonable. You only need to judge if it's reasonable. Reply "reasonable" if it is, and "unreasonable" if not.} 

Then the model will give its judgment "reasonable" or "unreasonable".

\subsection{More Qualitative Results on CCDC and CCGD}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.90\textwidth]{Figure/supp_dresscode_1.pdf}
    % \vspace{-4mm}
    \caption{More visual results on CCDC. Best viewed when zoomed in.}
    \label{fig:rst_CCDC_1}
    % \vspace{-5mm}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.90\textwidth]{Figure/supp_dresscode_2.pdf}
    % \vspace{-4mm}
    \caption{More visual results on CCDC. Best viewed when zoomed in.}
    \label{fig:rst_CCDC_2}
    % \vspace{-5mm}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.90\textwidth]{Figure/supp_ccgd_1.pdf}
    % \vspace{-4mm}
    \caption{More visual results on CCGD. Best viewed when zoomed in.}
    \label{fig:rst_CCGD_1}
    % \vspace{-5mm}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.90\textwidth]{Figure/supp_ccgd_2.pdf}
    % \vspace{-4mm}
    \caption{More visual results on CCGD. Best viewed when zoomed in.}
    \label{fig:rst_CCGD_2}
    % \vspace{-5mm}
\end{figure*}

% All images of our self-collected Green100K include certified consent and use permission.
% First, more image composition cases are synthesized following the pipeline of Generate, Copy, and Paste in Fig. \ref{fig:composition}. Specifically, our DiffuMatting algorithm generates green-screen objects, duplicates the object along with the matting-level annotation, and subsequently inserts the object into various composition scenarios.
% Second, more green-screen objects are provided with matting-level annotations generation by our DiffuMatting and extended to almost any class including the Mammal, Myth, Plant, Furniture, Insect, Celebrity \textit{etc.}) without any parameters fine-tuning in Fig. \ref{fig:abs}. More results of community LoRA and sketch-guided results are shown in Fig. \ref{fig:art_design_appendix}.
% Third, in order to validate the advantages of our matting-level annotation for downstream matting tasks, we have generated a dataset of 10K human portrait matting data encompassing diverse age groups, races, genders, and nationalities. More cases of 10K human portrait synthesis set generated by our DiffuMatting are shown in Fig. \ref{fig:portrait1} and Fig. \ref{fig:portrait2}.
% % To verify the benefits of our matting-level annotation to the down-streaming matting
% % level task, we generate the 10K human-portrait-matting data including various age stages, races, genders, and nationalities
% Lastly, we present more cases of training set (Green100K) including the high-accurate annotations and green-screen objects from \ref{fig:green1} to \ref{fig:green7}.


%% The file named.bst is a bibliography style file for BibTeX 0.99c
% \bibliographystyle{named}
% \bibliography{ijcai25}

\end{document}

