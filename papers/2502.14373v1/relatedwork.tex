\section{Related Work}
%

% \noindent\textbf{Image-based Virtual Try-on}.
% % Image-based virtual try-on has been a subject of extensive research over the years, evolving into a promising and challenging field. 
% Numerous studies have been conducted using GANs \cite{lee2022high,men2020controllable,xie2023gp,yang2023occlumix} to achieve more natural generation. 
% However, GAN-based methods often encounter difficulties in producing high-fidelity and realistic outfitted images. 
% In light of the significant advancements in Text-to-Image diffusion models \cite{saharia2022photorealistic,ruiz2023dreambooth,hu2024diffumatting} in recent years, there has been a growing interest \cite{chen2024wear,liang2024vton,kolors,zhu2023tryondiffusion} in incorporating pre-trained diffusion models as generative priors within the virtual try-on domain. 
% Subsequent research has formulated virtual try-on as an exemplar-based image inpainting problem, with a focus on fine-tuning inpainting diffusion models using virtual try-on datasets to generate high-quality try-on images. 
% IDM-VTON~\cite{choi2024improving} introduces attention modules to encode high-level semantics and low-level features to preserve fine-grained details. FitDiT~\cite{jiang2024fitdit} is a customized Diffusion Transformers assigning more parameters and attention to high-resolution features for high-fidelity virtual try-on. 
% While these methods have garnered attention for the realism and quality of synthesized images, they still face challenges in cross-category virtual try-on. This is primarily due to the absence of priors necessary for reasoning about size mismatches, a common issue in real-world  scenarios.

\noindent\textbf{Image-based Virtual Try-on}.
GAN-based methods \cite{lee2022high,men2020controllable,xie2023gp,yang2023occlumix} have been extensively explored for natural image generation but often struggle to produce high-fidelity outfitted images. With the rapid progress of Text-to-Image diffusion models \cite{saharia2022photorealistic,ruiz2023dreambooth,hu2024diffumatting}, recent studies \cite{chen2024wear,liang2024vton,kolors,zhu2023tryondiffusion} have adopted pre-trained diffusion models as generative priors for virtual try-on.
%
Approaches like IDM-VTON \cite{choi2024improving} and FitDiT \cite{jiang2024fitdit} refine inpainting diffusion models to preserve details and enhance image realism. However, despite their success in generating high-quality results, these methods face significant challenges in cross-category virtual try-on due to the lack of priors necessary for reasoning about size mismatches, a key challenge in real-world applications. Motivated by this, we present a novel CrossVTON method here.


% This is primarily due to the significant effort required for the explicit warping process, which can ignore the importance of realistic garment textures. 
% Additionally, GAN-based approaches tend to lack robust generalization capabilities \cite{ge2021parser,issenhuth2020not,lee2022high}, resulting in notable performance deterioration when applied to diverse person images, particularly those beyond the training distribution. 

% For instance, TryOnDiffusion \cite{zhu2023tryondiffusion} employs parallel U-Nets Diffusion to enhance the details of garments and warp them for virtual try-on. 

% For example, LADI-VTON \cite{morelli2023ladi} and DCI-VTON \cite{gou2023taming} have been proposed, treating clothing as pseudo-words or utilizing warping networks to seamlessly integrate garments into pre-trained diffusion models. 
% To generate harmonized upper and lower styles, Anyfit \cite{li2024anyfit} employs a diffusion model and introduces a Hydra Block for attire combinations.

% Although these methods have received attention for the realism and quality of synthesized images, they still face challenges in cross-category virtual try-on stemming from the lack of priors to reasoning the size mismatching issues, which are common in real-world virtual try-on scenarios. 

% virtual try-on scenarios.

% and rethink the different functionalities of different zones. 
% maintaining rich textures and ensuring accurate size fitting, which are common issues in real-world virtual try-on scenarios.
%%%ditfit hand-vton 2篇
% Although these methods have received attention for the realism and quality of synthesized images, they still face challenges in maintaining rich textures and ensuring accurate size fitting, which are common issues in real-world virtual try-on scenarios.




% \noindent\textbf{Cross-category Virtual Try-on}.
% Although cross-category virtual try-on poses a significant challenge and is prevalent in various scenarios, few studies have addressed it as a critical issue, hindering the broader application and progress towards a more generalized virtual try-on solution. 
% AVTON \cite{liu2024arbitrary} introduces a Limbs Prediction Module to predict human body parts, addressing simpler cases of cross-category try-on. AnyFit \cite{li2024anyfit} employs an Adaptive Mask Boost to adjust mask lengths during the inference stage for cross-category virtual try-on. 
% However, the aforementioned algorithms only handle simpler cross-category cases (\textit{e.g.,} long sleeves $\leftrightarrow$ short sleeves) and fail in more complex scenarios (\textit{e.g.,} long skirts $\leftrightarrow$ upper jackets). To address this challenge, we propose a tri-zone prior approach to mimic logical reasoning for inputs (cross-category garments and model images), thereby distinguishing the different functionalities of various zones.

\noindent\textbf{Cross-category Virtual Try-on}.
Cross-category virtual try-on remains a challenging yet under-explored problem, limiting the development of generalized solutions. AVTON~\cite{liu2024arbitrary} introduces a limbs prediction module for basic cross-category cases, while AnyFit~\cite{li2024anyfit} uses an adaptive mask boost to refine masks during inference. However, these methods only handle simple scenarios (\textit{e.g.,} long sleeves $\leftrightarrow$ short sleeves) and struggle with complex cases such as long skirts $\leftrightarrow$ upper jackets. To address this, we propose a tri-zone prior framework to emulate logical reasoning, enabling differentiation of functional zones in cross-category try-on.


% To prevent the entire inpainting area from being filled due to a strict mask strategy, FitDiT \cite{jiang2024fitdit} proposes a dilated-relaxed mask strategy to reduce garment shape leakage and enable the model to adaptively learn the overall shape of garments. 

% \noindent\textbf{Image Synthesis of Try-on}.
% Basically, the try-on training data scheme requires paired data of the same individual wearing different outfits with the same ID, pose, and background, but only the garment varying. 
% However, such triplet or even quadruplets data is difficult to collect and thus, some research have shifted their attention on how to build the well-curated data constructor to satisfy the specific try-on tasks. 
% WUTON \cite{issenhuth2020not} and PF-AFN \cite{ge2021parser} introduce a student-teacher paradigm where the teacher model is trained as a parsing-based reconstruction to guide the student model to synthesize try-on results without relying on the parsing model. 
% These studies utilize realistic try-on images as training data, but they are hindered by limitations in data scale and diversity across various scenarios.
% Recently, BooW-VTON \cite{zhang2024boow} generates pseudo training triplet pairs via the off-the-shelf IDM model and then introduce the wild data augmentation for better adopting for the mask-free virtual try-on in the wild. However, the aforementioned methods fails to handle the cross-category and size-mismatching virtual try-on data constructor. 

\noindent\textbf{Image Synthesis of Try-on}.
Try-on training typically requires paired data where the same individual appears in different outfits with identical ID, pose, and background, varying only the garment. However, such data is challenging to collect, prompting research into curated data constructors for specific try-on tasks. WUTON~\cite{issenhuth2020not} and PF-AFN~\cite{ge2021parser} adopt a student-teacher paradigm, using parsing-based reconstruction to train models without relying on parsing during inference. While these methods leverage realistic try-on images, they are limited by data scale and scenario diversity.
%
Recently, BooW-VTON \cite{zhang2024boow} generates pseudo triplet pairs using off-the-shelf IDM models and employs wild data augmentation for mask-free virtual try-on. However, these methods still struggle with cross-category and size-mismatching scenarios in virtual try-on data construction, which are tackled in this paper.



% Conditional Analogy GAN (CAGAN) \cite{jetchev2017conditional} trains a Cycle-GAN as an image analogy problem to synthesize the individual with the target garment. 
% OOTD \cite{xu2024ootdiffusion} and IDM \cite{choi2024improving} have treated the try-on task as an inpainting task and synthesized the same individual with the target garment.

% Although the cross-category virtual try-on is a tough challenge and widely existing in the different scenarios, few work consider it as a matter issue to extent the wide application paving the path towards to the general virtual try-on. 
% AVTON introduces a limbs Prediction Module for predicting the human parts to handle simple cases. AnyFit employs an adaptive Mask Boost to adjust the mask length in the inference stage for cross-category virtual tryon. 
% To avoid filling the entire inpainting area due to a strict mask strategy, FitDiT proposes a dilated-relaxed mask strategy to lower the leakage of garment shape, and enable the model to adaptively learn the overall shape of garments. 
% However, above mentioned algorithms only handle with the simple cross-category cases (\textit{e.g.,} long sleeves short sleeves) and fails in hard cases (long skirt upper jacket). 
% To tackle this challenge, we propose a tri-zone priors to mimic the logic reasoning on the cross-category garments and model images to tell different functionality of zones.
% The essence of challenge caused by the lack of the human-mimic thought that distinguish the size mismatch issues between garment and model, and then real-size the different functionalities of various zones in the model image

% triplet

% and progressively training manner are work together to 


% We first construct the long-to-short dataset and corresponding the tri-zone ground-truth to train the CrossVTON with the ability on long-to-short try-on.
% Iteratively, we then collect the short-to-long data based on the previous CrossVTON (long-to-short model) where the real long skirt models and short garments are regarded as inputs and the output is the synthesis models with short garments. 


% For long-to-short，we con
%%% 长换短很难，需要难补区域，我们用短换长的
%%% 数据构造和训练是互相纠缠，互相训练
% we follow the core princeple 
%%%put the real model image as the output， and 分成两类短换长，长换短，
% including the iterative cross-category data construction and progressively training manner guided by the tri-zone priors.

% Chain of Thought Prompting Tri-zone Priors for Cross-category Virtual Try-on

%%
% 1. iterative data constuctor
%%2. propose a tri-zone priors to adatively disentangle the zone into the three functional zones
%%3. multi-stage and progrssively training pipelines 
% belongs to the try-on, reconstruction, or imagination area.
% Anyfit 


% The challenge 


%%gan->diffusion（没有脑补区域）->（需要呼应一下logic reasoning）问题->解决问题->创新点



% The {\it IJCAI--25 Proceedings} will be printed from electronic
% manuscripts submitted by the authors. These must be PDF ({\em Portable
%         Document Format}) files formatted for 8-1/2$''$ $\times$ 11$''$ paper.

% \subsection{Length of Papers}


% All paper {\em submissions} to the main track must have a maximum of seven pages, plus at most two for references / acknowledgements / contribution statement / ethics statement.

% The length rules may change for final camera-ready versions of accepted papers and
% differ between tracks. Some tracks may disallow any contents other than the references in the last two pages, whereas others allow for any content in all pages. Similarly, some tracks allow you to buy a few extra pages should you want to, whereas others don't.

% If your paper is accepted, please carefully read the notifications you receive, and check the proceedings submission information website\footnote{\url{https://proceedings.ijcai.org/info}} to know how many pages you can use for your final version. That website holds the most up-to-date information regarding paper length limits at all times.


% \subsection{Word Processing Software}

% As detailed below, IJCAI has prepared and made available a set of
% \LaTeX{} macros and a Microsoft Word template for use in formatting
% your paper. If you are using some other word processing software, please follow the format instructions given below and ensure that your final paper looks as much like this sample as possible.

\begin{figure*}[htb]
    \centering
    \includegraphics[width=0.95\textwidth]{Figure/main.pdf}
    % \vspace{-1mm}
    \caption{An overview of the whole pipeline and the structure of CrossVTON which consists of Tri-zone  and Try-on Net. The pipeline illustrates two rounds iterative cross-category data construction by synthesizing the Intra-category, Any-to-dress, and  Dress-to-any data. At each round, the CrossVTON is trained progressively to generate tri-zone priors and endow the ability of cross-category virtual try-on.}
    \label{fig:main_framework}
    % \vspace{-1mm}
\end{figure*}