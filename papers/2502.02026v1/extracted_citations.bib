@Article{ALIGNN,
author={Choudhary, Kamal
and DeCost, Brian},
title={Atomistic Line Graph Neural Network for improved materials property predictions},
journal={npj Computational Materials},
year={2021},
month={Nov},
day={15},
volume={7},
number={1},
pages={185},
abstract={Graph neural networks (GNN) have been shown to provide substantial performance improvements for atomistic material representation and modeling compared with descriptor-based machine learning models. While most existing GNN models for atomistic predictions are based on atomic distance information, they do not explicitly incorporate bond angles, which are critical for distinguishing many atomic structures. Furthermore, many material properties are known to be sensitive to slight changes in bond angles. We present an Atomistic Line Graph Neural Network (ALIGNN), a GNN architecture that performs message passing on both the interatomic bond graph and its line graph corresponding to bond angles. We demonstrate that angle information can be explicitly and efficiently included, leading to improved performance on multiple atomistic prediction tasks. We ALIGNN models for predicting 52 solid-state and molecular properties available in the JARVIS-DFT, Materials project, and QM9 databases. ALIGNN can outperform some previously reported GNN models on atomistic prediction tasks with better or comparable model training speed.},
issn={2057-3960},
doi={10.1038/s41524-021-00650-1},
url={https://doi.org/10.1038/s41524-021-00650-1}
}

@inbook{Boltzman_Machine,
author = {Hinton, G. E. and Sejnowski, T. J.},
title = {Learning and relearning in Boltzmann machines},
year = {1986},
isbn = {026268053X},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 1: Foundations},
pages = {282â€“317},
numpages = {36}
}

@inproceedings{CDVAE,
title={Crystal Diffusion Variational Autoencoder for Periodic Material Generation},
author={Tian Xie and Xiang Fu and Octavian-Eugen Ganea and Regina Barzilay and Tommi S. Jaakkola},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=03RLpj-tc_}
}

@article{CGCNN,
  title = {Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties},
  author = {Xie, Tian and Grossman, Jeffrey C.},
  journal = {Phys. Rev. Lett.},
  volume = {120},
  issue = {14},
  pages = {145301},
  numpages = {6},
  year = {2018},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.120.145301},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.120.145301}
}

@inproceedings{Continuity_Rotation,
title={On the Continuity of Rotation Representations in Neural Networks},
author={Zhou, Yi and Barnes, Connelly and Jingwan, Lu and Jimei, Yang and Hao, Li},
booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month={June},
year={2019}
}

@misc{CrystalGAN,
      title={CrystalGAN: Learning to Discover Crystallographic Structures with Generative Adversarial Networks}, 
      author={Asma Nouira and Nataliya Sokolovska and Jean-Claude Crivello},
      year={2019},
      eprint={1810.11203},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1810.11203}, 
}

@inproceedings{DiffCSP,
 author = {Jiao, Rui and Huang, Wenbing and Lin, Peijia and Han, Jiaqi and Chen, Pin and Lu, Yutong and Liu, Yang},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {17464--17497},
 publisher = {Curran Associates, Inc.},
 title = {Crystal Structure Prediction by Joint Equivariant Diffusion},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/38b787fc530d0b31825827e2cc306656-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@article{EBM_OpenAI,
  author       = {Yilun Du and
                  Igor Mordatch},
  title        = {Implicit Generation and Generalization in Energy-Based Models},
  journal      = {CoRR},
  volume       = {abs/1903.08689},
  year         = {2019},
  url          = {http://arxiv.org/abs/1903.08689},
  eprinttype    = {arXiv},
  eprint       = {1903.08689},
  timestamp    = {Mon, 01 Apr 2019 14:07:37 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1903-08689.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{EquiCSP,
  title = 	 {Equivariant Diffusion for Crystal Structure Prediction},
  author =       {Lin, Peijia and Chen, Pin and Jiao, Rui and Mo, Qing and Jianhuan, Cen and Huang, Wenbing and Liu, Yang and Huang, Dan and Lu, Yutong},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {29890--29913},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/lin24b/lin24b.pdf},
  url = 	 {https://proceedings.mlr.press/v235/lin24b.html},
  abstract = 	 {In addressing the challenge of Crystal Structure Prediction (CSP), symmetry-aware deep learning models, particularly diffusion models, have been extensively studied, which treat CSP as a conditional generation task. However, ensuring permutation, rotation, and periodic translation equivariance during diffusion process remains incompletely addressed. In this work, we propose EquiCSP, a novel equivariant diffusion-based generative model. We not only address the overlooked issue of lattice permutation equivariance in existing models, but also develop a unique noising algorithm that rigorously maintains periodic translation equivariance throughout both training and inference processes. Our experiments indicate that EquiCSP significantly surpasses existing models in terms of generating accurate structures and demonstrates faster convergence during the training process.}
}

@article{FTCP,
title = {An invertible crystallographic representation for general inverse design of inorganic crystals with targeted properties},
journal = {Matter},
volume = {5},
number = {1},
pages = {314-335},
year = {2022},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2021.11.032},
url = {https://www.sciencedirect.com/science/article/pii/S2590238521006251},
author = {Zekun Ren and Siyu Isaac Parker Tian and Juhwan Noh and Felipe Oviedo and Guangzong Xing and Jiali Li and Qiaohao Liang and Ruiming Zhu and Armin G. Aberle and Shijing Sun and Xiaonan Wang and Yi Liu and Qianxiao Li and Senthilnath Jayavelu and Kedar Hippalgaonkar and Yousung Jung and Tonio Buonassisi},
keywords = {general inverse design, solid-state materials, invertible crystallographic representation, generalized crystallographic representation, property-structured latent space, variational autoencoder, machine learning, thermoelectrics, generative model},
abstract = {Summary
Realizing general inverse design could greatly accelerate the discovery of new materials with user-defined properties. However, state-of-the-art generative models tend to be limited to a specific composition or crystal structure. Herein, we present a framework capable of general inverse design (not limited to a given set of elements or crystal structures), featuring a generalized invertible representation that encodes crystals in both real and reciprocal space, and a property-structured latent space from a variational autoencoder (VAE). In three design cases, the framework generates 142 new crystals with user-defined formation energies, bandgap, thermoelectric (TE) power factor, and combinations thereof. These generated crystals, absent in the training database, are validated by first-principles calculations. The success rates (number of first-principles-validated target-satisfying crystals/number of designed crystals) ranges between 7.1% and 38.9%. These results represent a significant step toward property-driven general inverse design using generative models, although practical challenges remain when coupled with experimental synthesis.}
}

@inproceedings{Generative_PointNet,
    title={Generative PointNet: Deep Energy-Based Learning on Unordered Point Sets for 3D Generation, Reconstruction and Classification},
    author={Xie, Jianwen and Xu, Yifei and Zheng, Zilong and Gao, Ruiqi and Wang, Wenguan and Zhu Song-Chun and Wu, Ying Nian},
    booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2021}
}

@article{MEGNet,
author = {Chen, Chi and Ye, Weike and Zuo, Yunxing and Zheng, Chen and Ong, Shyue Ping},
title = {Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals},
journal = {Chemistry of Materials},
volume = {31},
number = {9},
pages = {3564-3572},
year = {2019},
doi = {10.1021/acs.chemmater.9b01294},
URL = {https://doi.org/10.1021/acs.chemmater.9b01294},
eprint = {https://doi.org/10.1021/acs.chemmater.9b01294}
}

@inproceedings{Matformer,
  title={Periodic Graph Transformers for Crystal Material Property Prediction},
  author={Keqiang Yan and Yi Liu and Yuchao Lin and Shuiwang Ji},
  booktitle={The 36th Annual Conference on Neural Information Processing Systems},
  year={2022}
}

@article{PhysRevLett.98.146401,
  title = {Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces},
  author = {Behler, J\"org and Parrinello, Michele},
  journal = {Phys. Rev. Lett.},
  volume = {98},
  issue = {14},
  pages = {146401},
  numpages = {4},
  year = {2007},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.98.146401},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.98.146401}
}

@InProceedings{PotNet,
  title = 	 {Efficient Approximations of Complete Interatomic Potentials for Crystal Property Prediction},
  author =       {Lin, Yuchao and Yan, Keqiang and Luo, Youzhi and Liu, Yi and Qian, Xiaoning and Ji, Shuiwang},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {21260--21287},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/lin23m/lin23m.pdf},
  url = 	 {https://proceedings.mlr.press/v202/lin23m.html},
  abstract = 	 {We study property prediction for crystal materials. A crystal structure consists of a minimal unit cell that is repeated infinitely in 3D space. How to accurately represent such repetitive structures in machine learning models remains unresolved. Current methods construct graphs by establishing edges only between nearby nodes, thereby failing to faithfully capture infinite repeating patterns and distant interatomic interactions. In this work, we propose several innovations to overcome these limitations. First, we propose to model physics-principled interatomic potentials directly instead of only using distances as in many existing methods. These potentials include the Coulomb potential, London dispersion potential, and Pauli repulsion potential. Second, we model the complete set of potentials among all atoms, instead of only between nearby atoms as in existing methods. This is enabled by our approximations of infinite potential summations with provable error bounds. We further develop efficient algorithms to compute the approximations. Finally, we propose to incorporate our computations of complete interatomic potentials into message passing neural networks for representation learning. We perform experiments on the JARVIS and Materials Project benchmarks for evaluation. Results show that the use of interatomic potentials and complete interatomic potentials leads to consistent performance improvements with reasonable computational costs. Our code is publicly available as part of the AIRS library (https://github.com/divelab/AIRS).}
}

@Article{Predict_Optimize,
author={Cheng, Guanjian
and Gong, Xin-Gao
and Yin, Wan-Jian},
title={Crystal structure prediction by combining graph network and optimization algorithm},
journal={Nature Communications},
year={2022},
month={Mar},
day={21},
volume={13},
number={1},
pages={1492},
abstract={Crystal structure prediction is a long-standing challenge in condensed matter and chemical science. Here we report a machine-learning approach for crystal structure prediction, in which a graph network (GN) is employed to establish a correlation model between the crystal structure and formation enthalpies at the given database, and an optimization algorithm (OA) is used to accelerate the search for crystal structure with lowest formation enthalpy. The framework of the utilized approach (a database + a GN model + an optimization algorithm) is flexible. We implemented two benchmark databases, i.e., the open quantum materials database (OQMD) and Matbench (MatB), and three OAs, i.e., random searching (RAS), particle-swarm optimization (PSO) and Bayesian optimization (BO), that can predict crystal structures at a given number of atoms in a periodic cell. The comparative studies show that the GN model trained on MatB combined with BO, i.e., GN(MatB)-BO, exhibit the best performance for predicting crystal structures of 29 typical compounds with a computational cost three orders of magnitude less than that required for conventional approaches screening structures through density functional theory calculation. The flexible framework in combination with a materials database, a graph network, and an optimization algorithm may open new avenues for data-driven crystal structural predictions.},
issn={2041-1723},
doi={10.1038/s41467-022-29241-4},
url={https://doi.org/10.1038/s41467-022-29241-4}
}

@inproceedings{SchNet,
 author = {Sch\"{u}tt, Kristof and Kindermans, Pieter-Jan and Sauceda Felix, Huziel Enoc and Chmiela, Stefan and Tkatchenko, Alexandre and M\"{u}ller, Klaus-Robert},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {SchNet: A continuous-filter convolutional neural network for modeling quantum interactions},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/303ed4c69846ab36c2904d3ba8573050-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{Self_Selecting_Ensambles,
author = {Xiang, Sitao},
title = {Eliminating topological errors in neural network rotation estimation using self-selecting ensembles},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3450626.3459882},
doi = {10.1145/3450626.3459882},
abstract = {Many problems in computer graphics and computer vision applications involves inferring a rotation from a variety of different forms of inputs. With the increasing use of deep learning, neural networks have been employed to solve such problems. However, the traditional representations for 3D rotations, the quaternions and Euler angles, are found to be problematic for neural networks in practice, producing seemingly unavoidable large estimation errors. Previous researches has identified the discontinuity of the mapping from SO(3) to the quaternions or Euler angles as the source of such errors, and to solve it, embeddings of SO(3) have been proposed as the output representation of rotation estimation networks instead. In this paper, we argue that the argument against quaternions and Euler angles from local discontinuities of the mappings from SO(3) is flawed, and instead provide a different argument from the global topological properties of SO(3) that also establishes the lower bound of maximum error when using quaternions and Euler angles for rotation estimation networks. Extending from this view, we discover that rotation symmetries in the input object causes additional topological problems that even using embeddings of SO(3) as the output representation would not correctly handle. We propose the self-selecting ensemble, a topologically motivated approach, where the network makes multiple predictions and assigns weights to them. We show theoretically and with experiments that our methods can be combined with a wide range of different rotation representations and can handle all kinds of finite symmetries in 3D rotation estimation problems.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {167},
numpages = {21},
keywords = {rotation, neural networks, covering space}
}

@inproceedings{SyMat,
 author = {Luo, Youzhi and Liu, Chengkai and Ji, Shuiwang},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {53308--53329},
 publisher = {Curran Associates, Inc.},
 title = {Towards Symmetry-Aware Generation of Periodic Materials},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/a73474c359ed523e6cd3174ed29a4d56-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

