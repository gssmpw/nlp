% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
    \setmainfont[]{Latin Modern Roman}
  \setmathfont[]{Latin Modern Math}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\usepackage{arxiv}
\usepackage{orcidlink}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage[numbers,square]{natbib}
\bibliographystyle{plainnat}
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={CleanSurvival: Automated data preprocessing for time-to-event models using reinforcement learning},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\usepackage{lineno}
% \linenumbers
\renewcommand{\today}{2025-02-06}
\newcommand{\runninghead}{A Preprint }
\renewcommand{\runninghead}{A Preprint }
\title{CleanSurvival: Automated data preprocessing for time-to-event
models using reinforcement learning}
\def\asep{\\\\\\ } % default: all authors on same column
\def\asep{\And }
\author{\textbf{Yousef Koka}\\Media Engineering Technology
Faculty\\German University in Cairo\\Cairo\\\asep\textbf{David
Selby}~\orcidlink{0000-0001-8026-5663}\\Data Science and its
Applications\\DFKI
GmbH\\Kaiserslautern,\ 67663\\\href{mailto:david.selby@dfki.de}{david.selby@dfki.de}\asep\textbf{Gerrit
Gro\ss{}mann}~\orcidlink{0000-0002-4933-447X}\\Data Science and its
Applications\\DFKI GmbH\\Kaiserslautern,\ 67663\\\asep\textbf{Sebastian
Vollmer}~\orcidlink{0000-0003-2831-1401}\\Data Science and its
Applications\\DFKI GmbH\\Kaiserslautern,\ 67663\\Department of Computer
Science\\University of Kaiserslautern--Landau\\Kaiserslautern,\ 67663\\}
\date{2025-02-06}
\begin{document}
\maketitle
\begin{abstract}
Data preprocessing is a critical yet frequently neglected aspect of
machine learning, often paid little attention despite its potentially
significant impact on model performance. While automated machine
learning pipelines are starting to recognize and integrate data
preprocessing into their solutions for classification and regression
tasks, this integration is lacking for more specialized tasks like
survival or time-to-event models. As a result, survival analysis not
only faces the general challenges of data preprocessing but also suffers
from the lack of tailored, automated solutions in this area.

To address this gap, this paper presents \texttt{CleanSurvival}, a
reinforcement-learning-based solution for optimizing preprocessing
pipelines, extended specifically for survival analysis. The framework
can handle continuous and categorical variables, using \(Q\)-learning to
select which combination of data imputation, outlier detection and
feature extraction techniques achieves optimal performance for a Cox,
random forest, neural network or user-supplied time-to-event model. The
package is available on GitHub: \url{https://github.com/datasciapps/CleanSurvival}.

Experimental benchmarks on real-world datasets show that the
\(Q\)-learning-based data preprocessing results in superior predictive
performance to standard approaches, finding such a model up to 10 times
faster than undirected random grid search. Furthermore, a simulation
study demonstrates the effectiveness in different types and levels of
missingness and noise in the data.
\end{abstract}


\section{Introduction}\label{introduction}

In the era of big data and machine learning (ML), the ability to extract
meaningful insights from complex datasets is paramount. A critical step
in this process is \emph{data preprocessing}, which involves cleaning,
transforming, and preparing raw data to be suitable for analysis. The
quality of data preprocessing may significantly impact the performance
and reliability of ML models. This is particularly crucial in the field
of survival analysis, where the goal is to predict the time until an
event of interest occurs, such as patient death, equipment failure or
customer churn.

Survival analysis poses unique challenges due to the presence of
censored data, where the event of interest has not yet been observed.
However, it is also overlooked in the context of automated machine
learning (AutoML) pipelines, which aim to streamline the ML development
process by automating tasks such as algorithm selection, hyperparameter
tuning and model evaluation---and increasingly incorporate data
preparation as part of their pipelines. In this paper, we introduce
\texttt{CleanSurvival}, an automated data preprocessing framework
tailored for survival analysis.

\texttt{CleanSurvival} leverages reinforcement learning (RL) techniques,
specifically \(Q\)-learning, to optimize decisions such as imputation of
missing values, detection and handling of outliers and feature
extraction for survival models. RL is a powerful approach for automated
data preprocessing because it dynamically optimizes pipeline steps by
learning to maximize a reward function tied directly to model
performance, ensuring data cleaning decisions are guided by their impact
on survival predictions. The framework is designed to handle continuous
and categorical variables, and can be used with a variety of
time-to-event models, from classical methods to modern deep learning
frameworks.

The framework, available as an open-source Python package, is
demonstrated on several common survival analysis datasets, highlighting
the sensitivity of predictive performance to data preprocessing steps
and boasting improved predictive performance compared to standard
approaches.

The article is organized as follows. Section~\ref{sec-background}
provides an overview of data preprocessing, survival analysis, AutoML
and \(Q\)-learning. Section~\ref{sec-related} reviews existing
approaches to automated data preprocessing and AutoML frameworks.
Section~\ref{sec-methods} describes the architecture of
\texttt{CleanSurvival} and its features. Section~\ref{sec-experiments}
presents the results of experimental evaluation of the framework on
real-world datasets. Finally, Section~\ref{sec-conclusion} discusses the
results and outlines future directions for research.

\section{Background}\label{sec-background}

Data preprocessing involves cleaning, transforming and organizing raw
data into a suitable format for analysis, and is a important step in the
ML pipeline. Sub-tasks of data preprocessing include imputation or
removal of missing values, detection and handling of outliers, variable
selection and feature extraction and data transformations. These steps
can have a profound downstream impact on classification performance
\citep{li_cleanml_2021} and model explanations
\citep{sharma_x-hacking_2024}.

However, the selection of appropriate preprocessing methods often
requires a combination of domain knowledge, visual inspection and manual
experimentation; it is also often poorly documented, whether in academic
papers or computational notebooks
\citep{strasser2024, golendukhina2024}. Some authors have even attempted
to quantify the effect of preprocessing steps on model predictions
independently of the dataset \citep{gonzalezzelaya2019}.

Automated data preprocessing has emerged to address these challenges
\citep{bilal2022, santos2023, salhi2023, mumuni2024}. This approach uses
algorithms and heuristics to automate various data cleaning and
transformation tasks, reducing the need for manual intervention or
iteration and potentially improving the efficiency and effectiveness of
the preprocessing stage, ideally by learning from past cleaning tasks
\citep{mahdavi_towards_2019}. However, the field is still in its
infancy.

\subsection{Survival analysis}\label{survival-analysis}

Survival analysis, also known as reliability analysis or duration
modelling, is a statistical method for analysing time-to event data. It
is widely used in various fields, including medicine, engineering and
social sciences. In survival analysis, the primary goal is to model the
time until an event of interest occurs, such as death, disease
progression, machine failure or customer churn. The survival function,
\[
S(t) = P(T > t),
\] denotes the probability that the time of event (death), a random
variable \(T\), occurred later than a time \(t\). A unique
characteristic of time-to-event problems is censoring, or data points
that are only partially observed, such as patients who survived up until
the last observation time, at which point they were lost to follow-up or
the study period ended \citep{wang2019}.

Na√Øvely, one can treat survival analysis as either a regression or
classification problem, but both approaches lead to a significant
information loss. In the former case, one treats the observed survival
time as a continuous outcome, and censored observations are either
discarded or imputed, resulting in substantial reduction in sample size
or bias introduced by oversimplified assumptions about the censoring
process. In the latter case, one models survival---or not---in a
predefined time window, reducing the problem to binary classification
and losing granular information about event times
\citep{leung_censoring_1997}.

Survival analysis models, such as the Cox proportional hazards model,
Kaplan--Meier estimator and accelerated failure time models, are widely
used in practice. These models estimate the hazard function, survival
function, or survival probabilities over time, providing valuable
insights into the relationship between covariates and survival outcomes.

Concordance indices like the C-index are widely used in evaluation of
survival models due to their simplicity and ease of interpretation
\citep{longato2020}. The C-index evaluates the model's ability to
correctly rank individuals based on their risk of experiencing the
event. A higher C-index indicates better discriminatory power.

However, concordance indices have significant limitations, due to their
poor calibration and failure to consider the distribution of survival
times as well as their ranks. To measure how well survival probabilities
align with observed event times, calibration metrics like Houwelingen's
\(\alpha\) or D-calibration can be used \citep{vanhouwelingen2000} , and
should be compared against a baseline model, such as the Kaplan--Meier
estimator. Weighted integrated survival log loss or integrated Graf
score are recommended scoring rules \citep{sonabend_phd_2021}.

To account for censoring, we apply inverse probability of censoring
weighting (IPCW). Let \(G(t)\) be the Kaplan--Meier estimate of the
probability of not being censored at \(t\). Then, the integrated Graf
score is defined \[
\text{IGS} = \frac{1}{n} \sum_{i=1}^n \sum_{j=1}^k \Delta t_j \, \frac{\left( S(t_j | x_i) - \text{Observed}(t_j, i) \right)^2}{ G(t_j) },
\] for a set of time points \(\{t_1, t_2, \ldots, t_k\}\), where
\(\Delta t_j\) represents the difference between time points, \(n\) is
the number of individuals and \(\text{Observed}(t, i)\) is an indicator
function, equal to \(1\) if the individual is known to have survived
beyond \(t\) and \(0\) otherwise.

\subsection{Automated machine
learning}\label{automated-machine-learning}

Automated machine learning (AutoML) aims to streamline the process of ML
development by automating steps such as algorithm selection,
hyperparameter tuning and model evaluation, reducing the amount of time
and expertise required by practitioners to train, deploy and fine-tune
models \citep{feurer_autosklearn_2022, barbudo2023}. AutoML frameworks
have seen success in various applications by employing search strategies
such as meta-learning, Bayesian optimization and ensemble learning to
achieve competitive performance.

However, data preprocessing remains an important analysis step that
typically falls outside the AutoML pipeline
\citep{paranjape_automated_2022}. Data preparation steps including
cleaning, normalization and feature engineering are critical for the
success of ML models but can be highly problem-specific
\citep{kuhn_feature_engineering_2019}. Automating these tasks while
maintaining flexibility for diverse datasets remains a significant
hurdle \citep{salhi2023, mumuni2024}. \citet{mahdavi_towards_2019}
highlighted the potential of AI to solve data quality problems through
data profiling and learning from past cleaning attempts \citep[see
also][]{mahdavi_semi_2021}. A holistic approach integrates the cleaning
process with downstream tasks so that the cleaning is optimized for
predictive performance \citep{neutatz_cleaning_2021}; indeed when
integrated into an AutoML framework some cleaning steps may be more
important than others \citep{neutatz_data_2022}.

Survival analysis in particular faces particular challenges, partly due
to the relative lack of support for such models in the first place
(versus classification or regression), as well as unique difficulties of
handling censored time-to-event data \citep{wang2019}, which are
typically not addressed in conventional AutoML frameworks and do not
feature in AutoML surveys \citep[e.g.][]{barbudo2023}. Seamlessly
integrating these domain-specific preprocessing steps with the
downstream tasks of model optimization and evaluation is a complex,
underexplored area.

Prominent AutoML pipelines include \texttt{Auto-WEKA}, an early AutoML
system that uses Bayesian optimization to search for the best
combination of preprocessing steps and machine learning algorithms
\citep{thornton_autoweka_2013}; \texttt{TPOT}, a tree-based pipeline
optimization tool that uses genetic programming to evolve pipelines of
data cleaning and machine learning operations \citep{olson_tpot_2016};
and \texttt{auto-sklearn}, an extension of \texttt{Auto-WEKA} that
incorporates more recent advancements in machine learning and
hyperparameter optimization while offering a familiar interface based on
the Python package \texttt{scikit-learn}
\citep{feurer_autosklearn_2022}.

These AutoML pipelines have demonstrated promising results in various
domains, including image classification, natural language processing and
tabular data analysis. However, they often focus on general machine
learning tasks and may not be specifically tailored to the challenges of
survival analysis, particularly in the presence of missing data.

\citet{salhi2023} presented a recent survey of data preprocessing using
AutoML (though survival analysis is not mentioned). In their review,
they highlight the relative capabilities of AutoML platforms: in many
cases the data processing support is relatively basic. The authors
indicate that all 11 tools reviewed support missing value imputation,
but also state: `\texttt{auto-sklearn} cannot handle missing values' and
this must be done manually by the user---a contradiction. In this case,
claims of support for data processing may actually be based on those of
the underlying, non-automated ML framework (i.e.~\texttt{scikit-learn}).
\citet{mumuni2024} also surveyed automated data processing for deep
learning applications, highlighting in more detail the extent to which
data processing steps are integral components of the automated pipeline.
They similarly note the lack of early support from \texttt{autosklearn}.

\subsection{\texorpdfstring{\(Q\)-learning}{Q-learning}}\label{q-learning}

Reinforcement learning is well-suited to the task of automating
constrained ML pipelines, as it optimizes sequential decision-making
processes, balancing exploration and exploitation, while being less
computationally intensive than other methods, such as unconstrained
evolutionary algorithms \citep{heffetz2020}.

\(Q\)-learning is a model-free off-policy reinforcement learning
algorithm that seeks to find the optimal action-selection policy for an
agent interacting with an environment. The algorithm is based on
estimating the value \(Q=Q(s, a)\) of taking an action \(a\) in a given
state \(s\). The agent iteratively updates these \(Q\) values based on
its experiences, enabling it to learn an optimal policy even in
environments with stochastic rewards and transitions.

The goal of \(Q\)-learning is to maximize the cumulative reward over
time by updating \(Q\) according to the Bellman equation. Given a
current state \(s\), action \(a\), reward \(r\) and next state \(s'\),
the update rule is:
\begin{equation}\phantomsection\label{eq-q_learning}{
Q(s, a) \leftarrow Q(s, a) + \alpha \bigl( r + \gamma \max_{a'} Q(s', a') - Q(s, a) \bigr),
}\end{equation} where \(\alpha\) is the learning rate and \(\gamma\) is
the discount factor, controlling the importance of future rewards. The
update equation Equation~\ref{eq-q_learning} allows the \(Q\)-learning
agent to converge to an optimal policy \(\pi^*\), defined
\begin{equation}\phantomsection\label{eq-optimal-policy}{
\pi^*(s) = \arg\max_a Q(s, a).
}\end{equation} without requiring a model of the environment's dynamics.
By exploring various state--action pairs and refining \(Q\)-values,
\(Q\)-learning is able to asymptotically approach optimal behaviour,
provided that the agent balances exploration and exploitation
effectively.

Alternatives to \(Q\)-learning, such as Bayesian optimization, can offer
improved sample efficiency in some cases but often struggle to scale in
high-dimensional or discrete search spaces typical of complex AutoML
pipelines. More specialized methods, such as neural architecture search,
are not easily extensible to data preprocessing tasks. Other
reinforcement learning approaches, including deep reinforcement learning
\citep{heffetz2020} and Monte Carlo tree search
\citep{drori2019automaticmachinelearningpipeline}, provide flexibility
but introduce additional computational overhead and may require
constraints or tailored mechanisms to ensure valid ML pipelines.

\section{Related work}\label{sec-related}

Table~\ref{tbl-automl-features} compares the features of various AutoML
solutions; as highlighted in Section~\ref{sec-background}, few offer
integrated support for survival analysis and data preprocessing is not
always within the optimization loop.

\begin{table}[htbp]

\caption{\label{tbl-automl-features}Comparison of AutoML frameworks and
their native support for survival analysis and dynamic data
preprocessing}

\centering{

\begin{tabular}{llll}
\toprule
Framework & Method & Preprocessing & Survival\\
\midrule
Amazon SageMaker Autopilot & Bayesian optimization and ensembles & Yes & No\\
auto-keras & Neural architecture search & Yes & No\\
auto-sklearn & Bayesian optimization & Limited & No\\
AutoGluon & Stack ensembling & Yes & No\\
Azure AutoML & Bayesian optimization and meta-learning & Yes & No\\
\addlinespace
BigML & Decision tree-based optimization & Yes & No\\
DataRobot & Proprietary ensemble and optimization & Yes & Limited\\
FLAML & Cost-aware Bayesian optimization & No & No\\
Google AutoML Tables & Neural architecture search & Yes & No\\
H2O AutoML & Random search and stacked ensembles & Yes & No\\
\addlinespace
MLflow & Manual configuration & Yes & No\\
MLJAR & Random search and stacked ensembles & Yes & No\\
PyCaret & Iterative search with pipeline tuning & Yes & Limited\\
TPOT & Genetic programming & No & No\\
\bottomrule
\end{tabular}

}

\end{table}%

Of frameworks offering automated data cleaning, DataRobot is
proprietary, commercial platform and only appears to offer time-to-event
modelling via a `hack' of converting the task to a classification
problem via discretization \citep[see e.g.][]{craig_survival_2021}.
Meanwhile, H2O.ai can run
\href{https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/coxph.html}{Cox
proportional hazards models} as a fixed model, but not via its AutoML
interface.

However, some dedicated data cleaning solutions have been proposed.
\citet{bilal2022} proposed Auto-Prep, an interactive Python-based tool
that recommends data cleaning methods to the user based on application
of candidate techniques and subsequent evaluation using simple
classifiers or regression models. In a review of data preprocessing in
AutoML (Section C) the authors highlight the capabilities, or lack
thereof, of AutoML tools to perform data preprocessing and feature
engineering without manual human intervention. Another Python package,
Atlantic \citep{santos2023}, automates preprocessing steps including
feature engineering and missing value imputation for supervised learning
tasks. The framework identifies the best combination of steps based on
evaluation using tree-based model ensembles.

\citet{learn2clean_2019} developed \texttt{Learn2Clean}, a tool offering
an innovative approach to data preprocessing. It leverages
\(Q\)-Learning, a reinforcement learning technique, to dynamically
select the optimal sequence of preprocessing tasks for a given dataset
and ML model. This optimization aims to maximize the quality of the ML
model's results. \texttt{Learn2Clean} implements automated data
preprocessing for regression, classification and clustering tasks, using
\(Q\)-learning to optimize respective evaluation criteria: mean squared
error, accuracy and silhouette index. However, \texttt{Learn2Clean}
limitations include lack of built-in support for survival analysis,
categorical data types, flexible hyperparameter tuning and custom reward
functions. It also has a complex dependency structure, which can make
initial setup challenging for end-users.

MLsurvival \citep{zhou2020} described an automated tool for cancer
survival prediction that removes or imputes missing values, selects and
standardizes features, trains survival models and then makes
predictions. Unfortunately, neither a full text article nor open source
implementation of the method were published. More recently,
\citet{pomsuwan2024} proposed an AutoML system for survival analysis
based on genetic algorithms and a combination of elastic-net Cox models,
random survival forests and survival trees, optimizing for C-index.
However, the tool does not incorporate data preprocessing.

\section{Methodology}\label{sec-methods}

In this section we describe \texttt{CleanSurvival}, our proposed AutoML
data preprocessing tool for survival analysis, illustrated in
Figure~\ref{fig-architecture}.

\begin{figure}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{figures/cleansurvival.pdf}}

}

\caption{\label{fig-architecture}Architecture of the
\texttt{CleanSurvival} automated data cleaning framework}

\end{figure}%

\subsection{Data preprocessing
methods}\label{data-preprocessing-methods}

\subsubsection{Missing values}\label{missing-values}

\texttt{CleanSurvival} offers a variety of methods for handling missing
values, addressing different data characteristics and analytical goals.

\begin{itemize}
\item
  For straightforward scenarios with minimal missingness, complete case
  analysis (CCA) simply removes rows containing missing values.
\item
  Simple mean/median imputation replaces missing values with the mean or
  median of the observed values for a given variable.
\item
  Multiple imputation using chained equation \citep[MICE,][]{buuren2011}
  provides a more robust approach by generating multiple suitable
  replacements for each missing value, creating several complete
  datasets for analysis. This method utilizes an iterative imputer,
  which starts with an initial guess and refines the estimates until
  convergence.
\item
  Finally (but most computationally intensive): \(k\)-nearest neighbors
  (KNN) imputation identifies the \(k\) most similar observations to the
  one with missing values, based on other, non-missing features, and
  uses their values to impute the missing data. Mean or median
  imputation is a limiting case where \(k\rightarrow n\).
\end{itemize}

\subsubsection{Outliers}\label{outliers}

To ensure the reliability and validity of survival analysis, robust
outlier detection methods are essential.

\begin{itemize}
\item
  For multivariate datasets, \texttt{CleanSurvival} employs the Elliptic
  Envelope algorithm \citep{rousseeuw1999} to identify and remove
  outliers based on their Mahalanobis distances from the data centre.
  This method is particularly useful for detecting outliers that deviate
  from the overall correlation structure of the data.
\item
  The Martingale residuals method \citep{therneau1990} calculates the
  difference between the observed and expected number of events for each
  individual (based on a simple Kaplan--Meier estimator), providing a
  measure of how unusual their survival time is compared to the expected
  survival time.
\end{itemize}

\subsubsection{Variable selection and feature
extraction}\label{variable-selection-and-feature-extraction}

To identify the most salient variables for survival analysis, a variety
of feature selection methods are available, enhancing both model
performance and interpretability.

\begin{itemize}
\item
  The Univariate Cox Proportional Hazards Selection (UC) method assesses
  the individual effect of each feature on survival using the Cox
  Proportional Hazards model. It selects features based on the
  significance of their coefficients, highlighting variables strongly
  associated with survival outcomes.
\item
  The LASSO (Least Absolute Shrinkage and Selection Operator) regression
  technique shrinks the coefficients of less important features to zero,
  effectively performing feature selection.
\item
  Recursive Feature Elimination (RFE) recursively removes the least
  important features based on their contribution to a model's
  performance, using cross-validation to evaluate the model's
  performance at each step.
\item
  The Information Gain Selection (IG) method measures the amount of
  information gained about the target variable (survival outcome) by
  knowing the value of a feature. This helps identify the most relevant
  variables by selecting features that provide the most information
  about the survival outcome.
\end{itemize}

\subsection{Survival analysis}\label{survival-analysis-1}

Three survival analysis models were carefully selected to integrate into
\texttt{CleanSurvival}, each chosen for its unique strengths and
applicability to a variety of survival analysis scenarios.

\begin{description}
\item[Cox proportional hazards]
This widely-used model \citep{Davidson-Pilon2019} is valued for its
interpretability, allowing researchers to quantify the impact of
different factors on the hazard rate. Its assumption of proportional
hazards can be a limitation in some cases.
\item[Random survival forest]
The RSF model \citep{sksurv} is an ensemble method based on decision
trees, offering robustness to nonlinearities and interactions in the
data. Its non-parametric nature makes it a flexible choice when the
underlying relationships in the data are not well understood.
\item[DeepHit neural network]
This deep learning model \citep{lee2018} leverages the power of neural
networks to capture complex patterns and interactions in survival data.
Its ability to model multiple competing risks makes it particularly
well-suited for scenarios where individuals may experience different
types of events.
\end{description}

\subsubsection{Reward structure}\label{reward-structure}

To guide the \(Q\)-learner effectively for survival analysis problems,
the reward structure is adapted to use the concordance index or C-index
\citep{longato2020}.

\subsection{Working modes}\label{working-modes}

To provide users with a range of options for data preprocessing and
analysis, four distinct working modes were implemented in
\texttt{CleanSurvival}:

\begin{description}
\item[Main algorithm]
This mode uses the core \(Q\)-learning algorithm to identify the optimal
sequence of preprocessing steps that maximize the performance of the
chosen survival analysis model. This is the primary mode for automated
pipeline optimization.
\item[Random cleaning]
In this mode, users can specify the desired number of random
experiments. The tool generates random preprocessing pipelines and
evaluates their performance, providing insights into the impact of
different preprocessing choices. This mdoe can serve as a baseline for
comparison with the optimized pipeline.
\item[Custom pipeline]
This mode allows users to define their own fixed preprocessing pipelines
using a simple text configuration file. Each line in the file specifies
a sequence of preprocessing methods, providing flexibility for testing
specific hypotheses or domain knowledge.
\item[No preparation]
This mode bypasses all preprocessing steps, directly passing the raw
dataset to the chosen survival analysis model. This can be useful for
establishing a baseline for performance without any preprocessing.
\end{description}

The inclusion of these working modes significantly enhances the utility
of the framework by offering valuable baselines for evaluating the
effectiveness of the optimized pipelines generated by the \(Q\)-learning
algorithm.

\section{Experiments}\label{sec-experiments}

\subsection{Experimental setup}\label{experimental-setup}

All methods were implemented in Python. Source code and documentation
are available at \url{https://github.com/datasciapps/CleanSurvival}.
Details of the datasets used are provided in Table~\ref{tbl-datasets}.
We demonstrate the approach using the \texttt{rotterdam} dataset,
derived from the Rotterdam Study, a large prospective cohort study in
the Netherlands, and \texttt{flchain}, a study of the relationship
between serum free light chain (a type of blood measurement) and
mortality.

\begin{table}

\caption{\label{tbl-datasets}Summary of datasets used in the
experiments}

\centering{

\begin{tabular}{lrrl}
\toprule
Dataset & Samples & Features & Source\\
\midrule
Rotterdam & 2982 & 14 & \href{https://rdrr.io/cran/survival/man/rotterdam.html}{Rotterdam Study}\\
Flchain & 7874 & 11 & \href{https://rdrr.io/cran/survival/man/flchain.html}{UCI Machine Learning Repository}\\
\bottomrule
\end{tabular}

}

\end{table}%

The results of data preprocessing strategies suggested by
\texttt{CleanSurvival} are compared against the following methods:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  complete case analysis (CCA), effectively ignoring the problem of
  missingness and outliers
\item
  random selection of imputation methods, simulating a grid search over
  possible analysis choices
\item
  mean imputation, as an example of a reasonable baseline used by an
  analyst not exploring the sensitivity of the model to different
  imputation strategies
\end{enumerate}

We evaluate each method based on quality metrics as well as the time
taken to retrieve an acceptable solution.

Hyperparameters that are not part of the \texttt{CleanSurvival} search
space were left at default values, with architectural choices for the
deep learning framework as follows: the DeepHit architecture consists of
a shared sub-network with 2 hidden layers, each containing 100 neurons,
using ReLU as the activation function. This is followed by
cause-specific sub-networks, each containing 2 hidden layers with 50
neurons per layer. Dropout regularization was applied to all layers with
a keep probability of 0.8 to mitigate overfitting. The model was trained
using the Adam optimizer with a learning rate of 0.001 for 10,000
iterations. In practice, these options are customizable by the user or
could be incorporated into the reinforcement learning action space as
additional modules.

Since the Rotterdam dataset does not contain missing values, three
variations of the dataset were used each representing a different
missingness strategy (MCAR, MAR, MNAR) which were generated using the
\href{https://pypi.org/project/jenga/\#description}{Jenga framework}
\citep{Schelter2021}.

\subsection{Results}\label{results}

\begin{table}

\caption{\label{tbl-results}Comparing CleanSurvival to complete case
analysis and mean imputation}

\centering{

\begin{tabular}{llrrr}
\toprule
Dataset & Missingness & \texttt{CleanSurvival} & CCA & Mean\\
\midrule
Rotterdam & 50\% MCAR & 0.833 & 0.803 & 0.800\\
Rotterdam & 50\% MAR & 0.835 & 0.815 & 0.797\\
Rotterdam & 50\% MNAR & 0.833 & 0.778 & 0.795\\
Flchain & Existing & 0.695 & 0.621 & 0.655\\
\bottomrule
\end{tabular}

}

\end{table}%

\begin{figure*}[ht]

\begin{minipage}{0.25\linewidth}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{./figures/rotterdam_missing_50_MCAR.png}}

}

\subcaption{\label{fig-mcar}MCAR}

\end{minipage}%
%
\begin{minipage}{0.25\linewidth}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{./figures/rotterdam_missing_50_MAR.png}}

}

\subcaption{\label{fig-mar}MAR}

\end{minipage}%
%
\begin{minipage}{0.25\linewidth}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{./figures/rotterdam_missing_50_MNAR.png}}

}

\subcaption{\label{fig-mnar}MNAR}

\end{minipage}%
%
\begin{minipage}{0.25\linewidth}

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{./figures/Flchain.png}}

}

\subcaption{\label{fig-flchain}Flchain}

\end{minipage}%

\caption{\label{fig-grid-search}\texttt{CleanSurvival} vs Grid Search}

\end{figure*}%

The results illustrated in Figure~\ref{fig-grid-search} clearly
demonstrate the efficiency of \texttt{CleanSurvival} in identifying
optimal data preprocessing pipelines for survival analysis within a
limited timeframe of 5 mins. It can be seen that, \texttt{CleanSurvival}
reaches the optimal solution in 9-14\% of the time taken by a bruteforce
to reach an optimal solution, translating to a time reduction of
approximately 86-91\%. Compared to a traditional grid search approach,
which explores all possible pipeline combinations, CleanSurvival
consistently achieves comparable or superior performance in a fraction
of the time---reducing computational time by up to 80\% in most cases.
This highlights the effectiveness of the reinforcement learning approach
in navigating the complex search space of data preprocessing options and
efficiently identifying the most impactful transformations.

Specifically, the graphs show that \texttt{CleanSurvival} reaches the
optimal C-index value significantly faster than the grid search, often
within the first 20-30 seconds of the experiment compared to several
minutes for grid search approaches. This rapid convergence to the
optimal solution is crucial in practical settings where time constraints
are common. Moreover, even when both methods eventually reach similar
C-index values, \texttt{CleanSurvival} does so with considerably less
computational effort, as evidenced by the shorter time-to-optimal, which
on average was reduced by approximately 83\%. This efficiency gain can
be attributed to the intelligent exploration and exploitation strategy
employed by the reinforcement learning agent, which allows it to focus
on the most promising areas of the search space and avoid unnecessary
evaluations.

These findings highlight the potential of \texttt{CleanSurvival} as a
valuable tool for accelerating and automating the data preprocessing
stage of survival analysis. By efficiently identifying optimal
pipelines, not only does it save time and resources but it also enables
researchers to focus on the core aspects of their analysis, ultimately
leading to more robust and reliable results.

\section{Conclusion}\label{sec-conclusion}

In this paper, we have introduced \texttt{CleanSurvival}, the first ever
\(Q\)-learning-based framework that automates data preprocessing for
survival analysis, addressing the often underserved challenge of
automation in presence of censored data. We demonstrated its ability to
enhance predictive performance and computational efficiency across
different settings, compared to conventional methods or heuristic
approaches.

The framework's adaptability to various survival analysis models and its
support for diverse preprocessing techniques make it a valuable tool for
researchers and practitioners. Experimental results confirm that
\texttt{CleanSurvival} not only accelerates the discovery of optimal
pipelines but also maintains robust performance under different
missingness patterns. These findings underscore the critical role of
automated data preprocessing in enhancing the reliability of survival
models and the feasibility of integrating reinforcement learning
techniques into AutoML workflows.

Future work will focus on extending the framework to handle additional
preprocessing tasks, incorporating advanced reinforcement learning
strategies and improving scalability for large datasets and complex
pipelines. Additionally, ensembling over differently cleaned datasets,
together with raw data, may have the potential to increase predictive
performance.

\section{Acknowledgement}\label{acknowledgement}

We are grateful for the input of Sergey Redyuk, whose suggestions
greatly improved the manuscript. This work was supported by the German
Federal Ministry of Education and Research via the project ``Eventful''
under grant ID \texttt{01IW23005}.


\renewcommand\refname{References}
  \bibliography{references.bib}



\end{document}
