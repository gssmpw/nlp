
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

%{AMS}
@String{AMSTrans = "American Mathematical Society Translations" }
@String{AMSTrans = "Amer. Math. Soc. Transl." }
@String{BullAMS = "Bulletin of the American Mathematical Society" }
@String{BullAMS = "Bull. Amer. Math. Soc." }
@String{ProcAMS = "Proceedings of the American Mathematical Society" }
@String{ProcAMS = "Proc. Amer. Math. Soc." }
@String{TransAMS = "Transactions of the American Mathematical Society" }
@String{TransAMS = "Trans. Amer. Math. Soc." }

%ACM
@String{CACM = "Communications of the {ACM}" }
@String{CACM = "Commun. {ACM}" }
@String{CompServ = "Comput. Surveys" }
@String{JACM = "J. ACM" }
@String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
@String{ACMMathSoft = "{ACM} Trans. Math. Software" }
@String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
@String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

@String{AmerSocio = "American Journal of Sociology" }
@String{AmerStatAssoc = "Journal of the American Statistical Association" }
@String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
@String{ApplMathComp = "Applied Mathematics and Computation" }
@String{ApplMathComp = "Appl. Math. Comput." }
@String{AmerMathMonthly = "American Mathematical Monthly" }
@String{AmerMathMonthly = "Amer. Math. Monthly" }
@String{BIT = "{BIT}" }
@String{BritStatPsych = "British Journal of Mathematical and Statistical
	Psychology" }
@String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
@String{CanMathBull = "Canadian Mathematical Bulletin" }
@String{CanMathBull = "Canad. Math. Bull." }
@String{CompApplMath = "Journal of Computational and Applied Mathematics" }
@String{CompApplMath = "J. Comput. Appl. Math." }
@String{CompPhys = "Journal of Computational Physics" }
@String{CompPhys = "J. Comput. Phys." }
@String{CompStruct = "Computers and Structures" }
@String{CompStruct = "Comput. \& Structures" }
@String{CompJour = "The Computer Journal" }
@String{CompJour = "Comput. J." }
@String{CompSysSci = "Journal of Computer and System Sciences" }
@String{CompSysSci = "J. Comput. System Sci." }
@String{Computing = "Computing" }
@String{ContempMath = "Contemporary Mathematics" }
@String{ContempMath = "Contemp. Math." }
@String{Crelle = "Crelle's Journal" }
@String{GiornaleMath = "Giornale di Mathematiche" }
@String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

%IEEE
@String{Computer = "{IEEE} Computer" }
@String{IEEETransComp = "{IEEE} Transactions on Computers" }
@String{IEEETransComp = "{IEEE} Trans. Comput." }
@String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
@String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
@String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
@String{ProcIEEE = "Proceedings of the {IEEE}" }
@String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
@String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
	Systems" }
@String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

@String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
@String{IMANumerAna = "{IMA} J. Numer. Anal." }
@String{InfProcLet = "Information Processing Letters" }
@String{InfProcLet = "Inform. Process. Lett." }
@String{InstMathApp = "Journal of the Institute of Mathematics and
	its Applications" }
@String{InstMathApp = "J. Inst. Math. Appl." }
@String{IntControl = "International Journal of Control" }
@String{IntControl = "Internat. J. Control" }
@String{IntNumerEng = "International Journal for Numerical Methods in
	Engineering" }
@String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
@String{IntSuper = "International Journal of Supercomputing Applications" }
@String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
@String{Kibernetika = "Kibernetika" }
@String{JResNatBurStand = "Journal of Research of the National Bureau
	of Standards" }
@String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
@String{LinAlgApp = "Linear Algebra and its Applications" }
@String{LinAlgApp = "Linear Algebra Appl." }
@String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
@String{MathAnaAppl = "J. Math. Anal. Appl." }
@String{MathAnnalen = "Mathematische Annalen" }
@String{MathAnnalen = "Math. Ann." }
@String{MathPhys = "Journal of Mathematical Physics" }
@String{MathPhys = "J. Math. Phys." }
@String{MathComp = "Mathematics of Computation" }
@String{MathComp = "Math. Comp." }
@String{MathScand = "Mathematica Scandinavica" }
@String{MathScand = "Math. Scand." }
@String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
@String{TablesAidsComp = "Math. Tables Aids Comput." }
@String{NumerMath = "Numerische Mathematik" }
@String{NumerMath = "Numer. Math." }
@String{PacificMath = "Pacific Journal of Mathematics" }
@String{PacificMath = "Pacific J. Math." }
@String{ParDistComp = "Journal of Parallel and Distributed Computing" }
@String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
@String{ParComputing = "Parallel Computing" }
@String{ParComputing = "Parallel Comput." }
@String{PhilMag = "Philosophical Magazine" }
@String{PhilMag = "Philos. Mag." }
@String{ProcNAS = "Proceedings of the National Academy of Sciences
	of the USA" }
@String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
@String{Psychometrika = "Psychometrika" }
@String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
@String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
@String{QuartApplMath = "Quarterly of Applied Mathematics" }
@String{QuartApplMath = "Quart. Appl. Math." }
@String{RevueInstStat = "Review of the International Statisical Institute" }
@String{RevueInstStat = "Rev. Inst. Internat. Statist." }

%SIAM
@String{JSIAM = "Journal of the Society for Industrial and Applied
	Mathematics" }
@String{JSIAM = "J. Soc. Indust. Appl. Math." }
@String{JSIAMB = "Journal of the Society for Industrial and Applied
	Mathematics, Series B, Numerical Analysis" }
@String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
@String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
@String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
@String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
@String{SIAMAppMath = "{SIAM} J. Appl. Math." }
@String{SIAMComp = "{SIAM} Journal on Computing" }
@String{SIAMComp = "{SIAM} J. Comput." }
@String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
@String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
@String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
@String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
@String{SIAMReview = "{SIAM} Review" }
@String{SIAMReview = "{SIAM} Rev." }
@String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
	Computing" }
@String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

@String{SoftPracExp = "Software Practice and Experience" }
@String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
@String{StatScience = "Statistical Science" }
@String{StatScience = "Statist. Sci." }
@String{Techno = "Technometrics" }
@String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
	Physics" }
@String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
@String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
@String{VLSICompSys = "J. {VLSI} Comput. Syst." }
@String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
	Mechanik" }
@String{ZAngewMathMech = "Z. Angew. Math. Mech." }
@String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
@String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

@String{Academic = "Academic Press" }
@String{ACMPress = "{ACM} Press" }
@String{AdamHilger = "Adam Hilger" }
@String{AddisonWesley = "Addison-Wesley" }
@String{AllynBacon = "Allyn and Bacon" }
@String{AMS = "American Mathematical Society" }
@String{Birkhauser = "Birkha{\"u}ser" }
@String{CambridgePress = "Cambridge University Press" }
@String{Chelsea = "Chelsea" }
@String{ClaredonPress = "Claredon Press" }
@String{DoverPub = "Dover Publications" }
@String{Eyolles = "Eyolles" }
@String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
@String{Interscience = "Interscience" }
@String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
@String{JohnWileySons = "John Wiley and Sons" }
@String{Macmillan = "Macmillan" }
@String{MathWorks = "The Math Works Inc." }
@String{McGrawHill = "McGraw-Hill" }
@String{NatBurStd = "National Bureau of Standards" }
@String{NorthHolland = "North-Holland" }
@String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
@String{PergamonPress = "Pergamon Press" }
@String{PlenumPress = "Plenum Press" }
@String{PrenticeHall = "Prentice-Hall" }
@String{SIAMPub = "{SIAM} Publications" }
@String{Springer = "Springer-Verlag" }
@String{TexasPress = "University of Texas Press" }
@String{VanNostrand = "Van Nostrand" }
@String{WHFreeman = "W. H. Freeman and Co." }

%Entries



@article{wu2023bloomberggpt,
	title={Bloomberggpt: A large language model for finance},
	author={Wu, Shijie and Irsoy, Ozan and Lu, Steven and Dabravolski, Vadim and Dredze, Mark and Gehrmann, Sebastian and Kambadur, Prabhanjan and Rosenberg, David and Mann, Gideon},
	journal={arXiv preprint arXiv:2303.17564},
	year={2023}
}

@article{kasneci2023chatgpt,
	title={ChatGPT for good? On opportunities and challenges of large language models for education},
	author={Kasneci, Enkelejda and Se{\ss}ler, Kathrin and K{\"u}chemann, Stefan and Bannert, Maria and Dementieva, Daryna and Fischer, Frank and Gasser, Urs and Groh, Georg and G{\"u}nnemann, Stephan and H{\"u}llermeier, Eyke and others},
	journal={Learning and individual differences},
	volume={103},
	pages={102274},
	year={2023},
	publisher={Elsevier}
}

@article{peng2023study,
	title={A study of generative large language model for medical research and healthcare},
	author={Peng, Cheng and Yang, Xi and Chen, Aokun and Smith, Kaleb E and PourNejatian, Nima and Costa, Anthony B and Martin, Cheryl and Flores, Mona G and Zhang, Ying and Magoc, Tanja and others},
	journal={NPJ digital medicine},
	volume={6},
	number={1},
	pages={210},
	year={2023},
	publisher={Nature Publishing Group UK London}
}

@article{ouyang2022training,
	title={Training language models to follow instructions with human feedback},
	author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
	journal={Advances in neural information processing systems},
	volume={35},
	pages={27730--27744},
	year={2022}
}

@inproceedings{chen2024data,
	title={Data Shunt: Collaboration of Small and Large Models for Lower Costs and Better Performance},
	author={Chen, Dong and Zhuang, Yueting and Zhang, Shuo and Liu, Jinfeng and Dong, Su and Tang, Siliang},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={38},
	number={10},
	pages={11249--11257},
	year={2024}
}

@article{chen2024improving,
	title={Improving Large Models with Small models: Lower Costs and Better Performance},
	author={Chen, Dong and Zhang, Shuo and Zhuang, Yueting and Tang, Siliang and Liu, Qidong and Wang, Hua and Xu, Mingliang},
	journal={arXiv preprint arXiv:2406.15471},
	year={2024}
}

@misc{glm2024chatglm,
	title={ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools}, 
	author={Team GLM and Aohan Zeng and Bin Xu and Bowen Wang and Chenhui Zhang and Da Yin and Diego Rojas and Guanyu Feng and Hanlin Zhao and Hanyu Lai and Hao Yu and Hongning Wang and Jiadai Sun and Jiajie Zhang and Jiale Cheng and Jiayi Gui and Jie Tang and Jing Zhang and Juanzi Li and Lei Zhao and Lindong Wu and Lucen Zhong and Mingdao Liu and Minlie Huang and Peng Zhang and Qinkai Zheng and Rui Lu and Shuaiqi Duan and Shudan Zhang and Shulin Cao and Shuxun Yang and Weng Lam Tam and Wenyi Zhao and Xiao Liu and Xiao Xia and Xiaohan Zhang and Xiaotao Gu and Xin Lv and Xinghan Liu and Xinyi Liu and Xinyue Yang and Xixuan Song and Xunkai Zhang and Yifan An and Yifan Xu and Yilin Niu and Yuantao Yang and Yueyan Li and Yushi Bai and Yuxiao Dong and Zehan Qi and Zhaoyu Wang and Zhen Yang and Zhengxiao Du and Zhenyu Hou and Zihan Wang},
	year={2024},
	eprint={2406.12793},
	archivePrefix={arXiv},
	primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}

@misc{glm2024chatglm,
	title={ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools}, 
	author={Team GLM and Aohan Zeng and Bin Xu and Bowen Wang and Chenhui Zhang and Da Yin and Diego Rojas and Guanyu Feng and Hanlin Zhao and Hanyu Lai and Hao Yu and Hongning Wang and Jiadai Sun and Jiajie Zhang and Jiale Cheng and Jiayi Gui and Jie Tang and Jing Zhang and Juanzi Li and Lei Zhao and Lindong Wu and Lucen Zhong and Mingdao Liu and Minlie Huang and Peng Zhang and Qinkai Zheng and Rui Lu and Shuaiqi Duan and Shudan Zhang and Shulin Cao and Shuxun Yang and Weng Lam Tam and Wenyi Zhao and Xiao Liu and Xiao Xia and Xiaohan Zhang and Xiaotao Gu and Xin Lv and Xinghan Liu and Xinyi Liu and Xinyue Yang and Xixuan Song and Xunkai Zhang and Yifan An and Yifan Xu and Yilin Niu and Yuantao Yang and Yueyan Li and Yushi Bai and Yuxiao Dong and Zehan Qi and Zhaoyu Wang and Zhen Yang and Zhengxiao Du and Zhenyu Hou and Zihan Wang},
	year={2024},
	eprint={2406.12793},
	archivePrefix={arXiv},
	primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}

@article{touvron2023llama,
	title={Llama 2: Open foundation and fine-tuned chat models},
	author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
	journal={arXiv preprint arXiv:2307.09288},
	year={2023}
}

@article{xu2024survey,
	title={A survey on knowledge distillation of large language models},
	author={Xu, Xiaohan and Li, Ming and Tao, Chongyang and Shen, Tao and Cheng, Reynold and Li, Jinyang and Xu, Can and Tao, Dacheng and Zhou, Tianyi},
	journal={arXiv preprint arXiv:2402.13116},
	year={2024}
}

@article{gou2021knowledge,
	title={Knowledge distillation: A survey},
	author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
	journal={International Journal of Computer Vision},
	volume={129},
	number={6},
	pages={1789--1819},
	year={2021},
	publisher={Springer}
}

@inproceedings{ho2023large,
	title={Large Language Models Are Reasoning Teachers},
	author={Ho, Namgyu and Schmid, Laura and Yun, Seyoung},
	booktitle={61st Annual Meeting of the Association for Computational Linguistics, ACL 2023},
	pages={14852--14882},
	year={2023},
	organization={Association for Computational Linguistics (ACL)}
}

@article{dai2023auggpt,
	title={Auggpt: Leveraging chatgpt for text data augmentation},
	author={Dai, Haixing and Liu, Zhengliang and Liao, Wenxiong and Huang, Xiaoke and Cao, Yihan and Wu, Zihao and Zhao, Lin and Xu, Shaochen and Liu, Wei and Liu, Ninghao and others},
	journal={arXiv preprint arXiv:2302.13007},
	year={2023}
}

@article{gilardi2023chatgpt,
	title={ChatGPT outperforms crowd workers for text-annotation tasks},
	author={Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Ma{\"e}l},
	journal={Proceedings of the National Academy of Sciences},
	volume={120},
	number={30},
	pages={e2305016120},
	year={2023},
	publisher={National Acad Sciences}
}

@article{feng2020codebert,
	title={Codebert: A pre-trained model for programming and natural languages},
	author={Feng, Zhangyin and Guo, Daya and Tang, Duyu and Duan, Nan and Feng, Xiaocheng and Gong, Ming and Shou, Linjun and Qin, Bing and Liu, Ting and Jiang, Daxin and others},
	journal={arXiv preprint arXiv:2002.08155},
	year={2020}
}

@article{chen2021evaluating,
	title={Evaluating large language models trained on code},
	author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
	journal={arXiv preprint arXiv:2107.03374},
	year={2021}
}

@article{chowdhery2022palm,
	title={Palm: Scaling language modeling with pathways},
	author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
	journal={arXiv preprint arXiv:2204.02311},
	year={2022}
}

@article{thoppilan2022lamda,
	title={Lamda: Language models for dialog applications},
	author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
	journal={arXiv preprint arXiv:2201.08239},
	year={2022}
}
@article{zhao2023survey,
	title={A survey of large language models},
	author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
	journal={arXiv preprint arXiv:2303.18223},
	year={2023}
}
@article{koundinya2024machine,
	title={Machine Unlearning in Large Language Models},
	author={Koundinya Gundavarapu, Saaketh and Agarwal, Shreya and Arora, Arushi and Thimmalapura Jagadeeshaiah, Chandana},
	journal={arXiv e-prints},
	pages={arXiv--2405},
	year={2024}
}

@article{bommasani2021opportunities,
	title={On the opportunities and risks of foundation models},
	author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
	journal={arXiv preprint arXiv:2108.07258},
	year={2021}
}

@article{biswas2023role,
	title={Role of chat gpt in public health},
	author={Biswas, Som S},
	journal={Annals of biomedical engineering},
	volume={51},
	number={5},
	pages={868--869},
	year={2023},
	publisher={Springer}
}

@article{thirunavukarasu2023large,
	title={Large language models in medicine},
	author={Thirunavukarasu, Arun James and Ting, Darren Shu Jeng and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
	journal={Nature medicine},
	volume={29},
	number={8},
	pages={1930--1940},
	year={2023},
	publisher={Nature Publishing Group US New York}
}

@article{he2023annollm,
	title={Annollm: Making large language models to be better crowdsourced annotators},
	author={He, Xingwei and Lin, Zhenghao and Gong, Yeyun and Jin, Alex and Zhang, Hang and Lin, Chen and Jiao, Jian and Yiu, Siu Ming and Duan, Nan and Chen, Weizhu and others},
	journal={arXiv preprint arXiv:2303.16854},
	year={2023}
}

@inproceedings{gu2024minillm,
	title={MiniLLM: Knowledge distillation of large language models},
	author={Gu, Yuxian and Dong, Li and Wei, Furu and Huang, Minlie},
	booktitle={The Twelfth International Conference on Learning Representations},
	year={2024}
}

@inproceedings{agarwal2024policy,
	title={On-policy distillation of language models: Learning from self-generated mistakes},
	author={Agarwal, Rishabh and Vieillard, Nino and Zhou, Yongchao and Stanczyk, Piotr and Garea, Sabela Ramos and Geist, Matthieu and Bachem, Olivier},
	booktitle={The Twelfth International Conference on Learning Representations},
	year={2024}
}

@article{liu2023llm,
	title={Llm-qat: Data-free quantization aware training for large language models},
	author={Liu, Zechun and Oguz, Barlas and Zhao, Changsheng and Chang, Ernie and Stock, Pierre and Mehdad, Yashar and Shi, Yangyang and Krishnamoorthi, Raghuraman and Chandra, Vikas},
	journal={arXiv preprint arXiv:2305.17888},
	year={2023}
}

@inproceedings{hsieh2023distilling,
	title={Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes},
	author={Hsieh, Cheng-Yu and Li, Chun-Liang and Yeh, Chih-kuan and Nakhost, Hootan and Fujii, Yasuhisa and Ratner, Alex and Krishna, Ranjay and Lee, Chen-Yu and Pfister, Tomas},
	booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
	pages={8003--8017},
	year={2023}
}

@article{mukherjee2023orca,
	title={Orca: Progressive learning from complex explanation traces of gpt-4},
	author={Mukherjee, Subhabrata and Mitra, Arindam and Jawahar, Ganesh and Agarwal, Sahaj and Palangi, Hamid and Awadallah, Ahmed},
	journal={arXiv preprint arXiv:2306.02707},
	year={2023}
}

@article{mitra2023orca,
	title={Orca 2: Teaching small language models how to reason},
	author={Mitra, Arindam and Del Corro, Luciano and Mahajan, Shweti and Codas, Andres and Simoes, Clarisse and Agarwal, Sahaj and Chen, Xuxi and Razdaibiedina, Anastasia and Jones, Erik and Aggarwal, Kriti and others},
	journal={arXiv preprint arXiv:2311.11045},
	year={2023}
}

@article{lewis2020retrieval,
	title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
	author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	pages={9459--9474},
	year={2020}
}

@inproceedings{karpukhin2020dense,
	title={Dense passage retrieval for open-domain question answering},
	author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen Tau},
	booktitle={2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020},
	pages={6769--6781},
	year={2020},
	organization={Association for Computational Linguistics (ACL)}
}

@article{xi2023rise,
	title={The rise and potential of large language model based agents: A survey},
	author={Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others},
	journal={arXiv preprint arXiv:2309.07864},
	year={2023}
}

@inproceedings{petroni2019language,
	title={Language Models as Knowledge Bases?},
	author={Petroni, Fabio and Rockt{\"a}schel, Tim and Riedel, Sebastian and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander},
	booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	pages={2463--2473},
	year={2019}
}

@article{pang2021deep,
	title={Deep learning for anomaly detection: A review},
	author={Pang, Guansong and Shen, Chunhua and Cao, Longbing and Hengel, Anton Van Den},
	journal={ACM computing surveys (CSUR)},
	volume={54},
	number={2},
	pages={1--38},
	year={2021},
	publisher={ACM New York, NY, USA}
}



@article{zhou2022pull,
	title={Pull \& push: Leveraging differential knowledge distillation for efficient unsupervised anomaly detection and localization},
	author={Zhou, Qihang and He, Shibo and Liu, Haoyu and Chen, Tao and Chen, Jiming},
	journal={IEEE Transactions on Circuits and Systems for Video Technology},
	year={2022},
	publisher={IEEE}
}

@inproceedings{chen2020simple,
	title={A simple framework for contrastive learning of visual representations},
	author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
	booktitle={International conference on machine learning},
	pages={1597--1607},
	year={2020},
	organization={PMLR}
}

@inproceedings{tack2020csi,
	title={CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances},
	author={Tack, Jihoon and Mo, Sangwoo and Jeong, Jongheon and Shin, Jinwoo},
	booktitle={34th Conference on Neural Information Processing Systems (NeurIPS) 2020},
	year={2020},
	organization={Neural Information Processing Systems}
}



@article{liu2024deep,
	title={Deep industrial image anomaly detection: A survey},
	author={Liu, Jiaqi and Xie, Guoyang and Wang, Jinbao and Li, Shangnian and Wang, Chengjie and Zheng, Feng and Jin, Yaochu},
	journal={Machine Intelligence Research},
	volume={21},
	number={1},
	pages={104--135},
	year={2024},
	publisher={Springer}
}

@inproceedings{roth2022towards,
	title={Towards total recall in industrial anomaly detection},
	author={Roth, Karsten and Pemula, Latha and Zepeda, Joaquin and Sch{\"o}lkopf, Bernhard and Brox, Thomas and Gehler, Peter},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={14318--14328},
	year={2022}
}

@article{siegel2020industrial,
	title={Industrial anomaly detection: A comparison of unsupervised neural network architectures},
	author={Siegel, Barry},
	journal={IEEE Sensors Letters},
	volume={4},
	number={8},
	pages={1--4},
	year={2020},
	publisher={IEEE}
}

@article{hilal2022financial,
	title={Financial fraud: a review of anomaly detection techniques and recent advances},
	author={Hilal, Waleed and Gadsden, S Andrew and Yawney, John},
	journal={Expert systems With applications},
	volume={193},
	pages={116429},
	year={2022},
	publisher={Elsevier}
}

@article{huang2018codetect,
	title={CoDetect: Financial fraud detection with anomaly feature detection},
	author={Huang, Dongxu and Mu, Dejun and Yang, Libin and Cai, Xiaoyan},
	journal={IEEE Access},
	volume={6},
	pages={19161--19174},
	year={2018},
	publisher={IEEE}
}

@article{zhang2020normality,
	title={Normality learning in multispace for video anomaly detection},
	author={Zhang, Yu and Nie, Xiushan and He, Rundong and Chen, Meng and Yin, Yilong},
	journal={IEEE Transactions on Circuits and Systems for Video Technology},
	volume={31},
	number={9},
	pages={3694--3706},
	year={2020},
	publisher={IEEE}
}

@article{li2020spatial,
	title={Spatial-temporal cascade autoencoder for video anomaly detection in crowded scenes},
	author={Li, Nanjun and Chang, Faliang and Liu, Chunsheng},
	journal={IEEE Transactions on Multimedia},
	volume={23},
	pages={203--215},
	year={2020},
	publisher={IEEE}
}

@article{chang2021contrastive,
	title={Contrastive attention for video anomaly detection},
	author={Chang, Shuning and Li, Yanchao and Shen, Shengmei and Feng, Jiashi and Zhou, Zhiying},
	journal={IEEE Transactions on Multimedia},
	volume={24},
	pages={4067--4076},
	year={2021},
	publisher={IEEE}
}

@article{ma2016supervised,
	title={Supervised anomaly detection in uncertain pseudoperiodic data streams},
	author={Ma, Jiangang and Sun, Le and Wang, Hua and Zhang, Yanchun and Aickelin, Uwe},
	journal={ACM Transactions on Internet Technology (TOIT)},
	volume={16},
	number={1},
	pages={1--20},
	year={2016},
	publisher={ACM New York, NY, USA}
}

@article{zhao2023survey,
	title={A survey of large language models},
	author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
	journal={arXiv preprint arXiv:2303.18223},
	year={2023}
}

@article{elhafsi2023semantic,
	title={Semantic anomaly detection with large language models},
	author={Elhafsi, Amine and Sinha, Rohan and Agia, Christopher and Schmerling, Edward and Nesnas, Issa AD and Pavone, Marco},
	journal={Autonomous Robots},
	volume={47},
	number={8},
	pages={1035--1055},
	year={2023},
	publisher={Springer}
}

@article{lv2024video,
	title={Video anomaly detection and explanation via large language models},
	author={Lv, Hui and Sun, Qianru},
	journal={arXiv preprint arXiv:2401.05702},
	year={2024}
}

@inproceedings{zanella2024harnessing,
	title={Harnessing Large Language Models for Training-free Video Anomaly Detection},
	author={Zanella, Luca and Menapace, Willi and Mancini, Massimiliano and Wang, Yiming and Ricci, Elisa},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={18527--18536},
	year={2024}
}

@article{sinha2024real,
	title={Real-Time Anomaly Detection and Reactive Planning with Large Language Models},
	author={Sinha, Rohan and Elhafsi, Amine and Agia, Christopher and Foutter, Matthew and Schmerling, Edward and Pavone, Marco},
	journal={arXiv preprint arXiv:2407.08735},
	year={2024}
}

@article{liu2024large,
	title={Large language model guided knowledge distillation for time series anomaly detection},
	author={Liu, Chen and He, Shibo and Zhou, Qihang and Li, Shizhong and Meng, Wenchao},
	journal={arXiv preprint arXiv:2401.15123},
	year={2024}
}

@inproceedings{Alpher05,
	author = {FirstName Alpher and FirstName Gamow},
	title = {Can a computer frobnicate?},
	booktitle = CVPR,
	pages = {234--778},
	year = 2005
}






@article{chen2024improvingg,
	title={Improving vision anomaly detection with the guidance of language modality},
	author={Chen, Dong and Pan, Kaihang and Dai, Guangyu and Wang, Guoming and Zhuang, Yueting and Tang, Siliang and Xu, Mingliang},
	journal={IEEE Transactions on Multimedia},
	year={2024},
	publisher={IEEE}
}

@inproceedings{rombach2022high,
	title={High-resolution image synthesis with latent diffusion models},
	author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={10684--10695},
	year={2022}
}

@article{rafailov2024direct,
	title={Direct preference optimization: Your language model is secretly a reward model},
	author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
	journal={Advances in Neural Information Processing Systems},
	volume={36},
	year={2024}
}


@article{chen2023parameter,
	title={Parameter-Efficient Fine-Tuning Design Spaces},
	author={Chen, Jiaao and Zhang, Aston and Shi, Xingjian and Li, Mu and Smola, Alex and Yang, Diyi},
	journal={arXiv preprint arXiv:2301.01821},
	year={2023}
}

@inproceedings{houlsby2019parameter,
	title={Parameter-efficient transfer learning for NLP},
	author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
	booktitle={International Conference on Machine Learning},
	pages={2790--2799},
	year={2019},
	organization={PMLR}
}

@article{zaken2021bitfit,
	title={Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models},
	author={Zaken, Elad Ben and Ravfogel, Shauli and Goldberg, Yoav},
	journal={arXiv preprint arXiv:2106.10199},
	year={2021}
}

@article{zhang2021beyond,
	title={Beyond fully-connected layers with quaternions: Parameterization of hypercomplex multiplications with $1/n $ parameters},
	author={Zhang, Aston and Tay, Yi and Zhang, Shuai and Chan, Alvin and Luu, Anh Tuan and Hui, Siu Cheung and Fu, Jie},
	journal={arXiv preprint arXiv:2102.08597},
	year={2021}
}

@article{krizhevsky2009learning,
	title={Learning multiple layers of features from tiny images},
	author={Krizhevsky, Alex and Hinton, Geoffrey and others},
	year={2009},
	publisher={Toronto, ON, Canada}
}

@inproceedings{reed2016generative,
	title={Generative adversarial text to image synthesis},
	author={Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
	booktitle={International conference on machine learning},
	pages={1060--1069},
	year={2016},
	organization={PMLR}
}

@article{chen2023cross,
	title={Cross-modal Data Augmentation for Tasks of Different Modalities},
	author={Chen, D and Zhuang, Y and Shen, Z and Yang, C and Wang, G and Tang, S and Yang, Y},
	journal={IEEE Transactions on Multimedia},
	year={2023},
	publisher={Institute of Electrical and Electronics Engineers}
}

@inproceedings{qu2016deep,
	title={Deep semantic understanding of high resolution remote sensing image},
	author={Qu, Bo and Li, Xuelong and Tao, Dacheng and Lu, Xiaoqiang},
	booktitle={2016 International conference on computer, information and telecommunication systems (Cits)},
	pages={1--5},
	year={2016},
	organization={IEEE}
}

@article{patrikar2022anomaly,
	title={Anomaly detection using edge computing in video surveillance system},
	author={Patrikar, Devashree R and Parate, Mayur Rajaram},
	journal={International Journal of Multimedia Information Retrieval},
	volume={11},
	number={2},
	pages={85--110},
	year={2022},
	publisher={Springer}
}

@article{yu2022edge,
	title={An edge computing based anomaly detection method in IoT industrial sustainability},
	author={Yu, Xiang and Yang, Xianfei and Tan, Qingji and Shan, Chun and Lv, Zhihan},
	journal={Applied Soft Computing},
	volume={128},
	pages={109486},
	year={2022},
	publisher={Elsevier}
}

@article{ngo2020adaptive,
	title={Adaptive anomaly detection for IoT data in hierarchical edge computing},
	author={Ngo, Mao V and Chaouchi, Hakima and Luo, Tie and Quek, Tony QS},
	journal={arXiv preprint arXiv:2001.03314},
	year={2020}
}
@article{van2008visualizing,
	title={Visualizing data using t-SNE.},
	author={Van der Maaten, Laurens and Hinton, Geoffrey},
	journal={Journal of machine learning research},
	volume={9},
	number={11},
	year={2008}
}

@inproceedings{liu2023simplenet,
	title={Simplenet: A simple network for image anomaly detection and localization},
	author={Liu, Zhikang and Zhou, Yiming and Xu, Yuansheng and Wang, RZilei},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={20402--20411},
	year={2023}
}

@inproceedings{sehwag2021ssd,
	title={SSD:  A Unified Framework for Self-Supervised Outlier Detection},
	author={Vikash Sehwag and Mung Chiang and Prateek Mittal},
	booktitle={International Conference on Learning Representations},
	year={2021},
	url={https://openreview.net/forum?id=v5gjXpmR8J}
}

@inproceedings{zong2018deep,
	title={Deep autoencoding gaussian mixture model for unsupervised anomaly detection},
	author={Zong, Bo and Song, Qi and Min, Martin Renqiang and Cheng, Wei and Lumezanu, Cristian and Cho, Daeki and Chen, Haifeng},
	booktitle={International conference on learning representations},
	year={2018}
}

@inproceedings{ruffdeep,
	title={Deep Semi-Supervised Anomaly Detection},
	author={Ruff, Lukas and Vandermeulen, Robert A and G{\"o}rnitz, Nico and Binder, Alexander and M{\"u}ller, Emmanuel and M{\"u}ller, Klaus-Robert and Kloft, Marius},
	booktitle={International Conference on Learning Representations}
}

@article{guo2024recontrast,
	title={Recontrast: Domain-specific anomaly detection via contrastive reconstruction},
	author={Guo, Jia and Jia, Lize and Zhang, Weihang and Li, Huiqi and others},
	journal={Advances in Neural Information Processing Systems},
	volume={36},
	year={2024}
}

@inproceedings{sehwagssd,
	title={SSD: A Unified Framework for Self-Supervised Outlier Detection},
	author={Sehwag, Vikash and Chiang, Mung and Mittal, Prateek},
	booktitle={International Conference on Learning Representations}
}
