\section{Conclusion} \label{sec:conclusion}

In this paper, we propose \textit{Ola}, a comprehensive and powerful omni-modal language model that achieves competitive performance in image, video, and audio understanding tasks. Our solution, based on a progressive modality alignment strategy, offers a natural, efficient, and competitive pipeline for training omni-modal models. Enhancements in architectural design with omni-modal inputs and streaming decoding, along with high-quality cross-modal video data preparation, further extend \textit{Ola}'s capabilities. We hope our work inspires future research on more general AI models.