\section{Conclusion}
This study highlights the efficiency and adaptability of recurrent models for object recognition tasks. We demonstrate their strong generalization with fewer parameters compared to feedforward networks. To address the challenge of selecting optimal iterations during testing, we propose a self-supervised method to estimate accuracy trends, enhancing extrapolation capabilities. Additionally, we introduce Conv-LiGRU, a stable and efficient model that mitigates the "overthinking" issue and achieves superior accuracy, making it a robust choice for vision-based tasks. These findings pave the way for further advancements in lightweight and adaptive architectures for real-world applications.

\newpage