\section{Introduction}
\label{sec:intro}

Recurrent Neural Networks (RNNs) have proven to be highly effective in tackling machine reasoning tasks, demonstrating remarkable capability to manage problems of different complexity levels within a single task \citep{orvieto2023resurrecting,de2024griffin,beck2024xlstm}.
However, traditional RNNs struggle to autonomously generalize to more complex problems beyond those encountered during training. %, requiring retraining, fine-tuning, or human intervention to assess output quality. 
RNN's sequential architecture and limited memory capacity hinder parallel training and scalability, causing them to fall behind Transformers.
% However, conventional RNNs often face challenges in generalizing autonomously to more complex problems beyond those seen in the training data, which required retraining, fine-tuning, or human involvement to verify valid outcomes.
% This drawback limits their practical usability, as real-world data frequently exhibit distributions that deviate significantly from the training data.

Despite extensive research on the reasoning capabilities of recurrent models, they are mainly used for simple sequence processing tasks like prefix sum or sequence copying. 
Some studies \citep{eyzaguirre2020differentiable,veerabadran2023Adaptive} explored their use in visual reasoning but focus on time-dependent tasks like maze-solving or chess. 
Static environments without explicit reasoning steps like object recognition, remain underexplored.
Recent studies in vision-language reasoning have sought to integrate visual understanding into large language models (LLMs) \citep{lin2024vila,wang2024qwen2}. 
To enhance reasoning capability, these models employ Chain-of-Thought (CoT), generating step-by-step demonstrations of images, similar to methods used in LLMs \citep{dong2024insight,thawakar2025llamav}. 
% \todo{Maybe a discussion of the problems with natural language based reasoning: the exponential complexity of discrete search algorithms; deep learning success was based on representation learning that transforms seemingly discrete problems into continuous problems and solves them with gradient descent. Can we expect the same thing with reasoning?}
However, such approaches often overlook the models' robustness to low-quality and noisy images.
Training solely on curated datasets makes them highly vulnerable to inappropriate prompts. 
Furthermore, the discrete nature of language-based and tree-based reasoning models could lead to exponential complexity as the models try to imitate discrete search algorithms like DFS, BFS, and A$^*$ \citep{lehnert2024beyond, yao2023tree}
In contrast, studies on latent language models have revealed promising signs of enhanced robustness \citep{hao2024training}, and the efficacy of inference in latent space has been confirmed in other fields \citep{rombach2022high,radford2021learning,videoworldsimulators2024}.
\todo[disable]{More on: Why is this an important problem? 
What are the new challenges this problem introduces? 
Why is it beneficial to study this problem in parallel with language reasoning? 
Evidence of humans doing both latent and language reasoning. The advantages of latent reasoning. 
Can robust latent OOD generalization benefit reasoning/systematic generalization?}

In this study, we take the first steps toward exploring the reasoning capabilities of visual recurrent models in latent space, in parallel with CoT techniques in LLMs. 
Motivated by Deep Thinking \citep{schwarzschild2021can,bansal2022endtoend}, our proposed model can generalize to tackle more complex problems at test time simply by iterating its recurrent units more times and no additional training is needed. 
% For example, a model trained on a \(9 \times 9\) maze can extrapolate to solve a \(13 \times 13\) maze. 
Our approach enables zero-shot extrapolation to more challenging environments within the same task.
The ability to handle problems under various conditions enables the development of robust and adaptable models, which are crucial for real-world applications and have the potential to apply to LLMs. 
We explore the effectiveness of RNNs in object recognition tasks using the CIFAR10-C and CIFAR100-C \citep{cifarC} datasets.

The key contributions of this study are:
% \todo{Rewrite this part to make it clearer}
\begin{itemize}
    \item We explore the extrapolation capabilities of recurrent model architectures for simple visual reasoning tasks, specifically object recognition. 
    We demonstrate that recurrent models enable strong extrapolation while utilizing significantly fewer parameters compared to conventional feedforward networks.
    \item We show that the early stopping heuristic in previous works—which forces the model to halt as soon as possible—limits the extrapolation capabilities of RNNs. 
    To enhance performance, we propose using a self-supervised task to estimate the accuracy trend across iterations, allowing us to determine the optimal number of iterations for the main task.
    \item We propose Conv-LiGRU, a novel recurrent model for effective and compute-optimal visual reasoning. 
    \item Extensive analysis and experiments show that Conv-LiGRU is more stable than Conv-GRU, better mitigates the "overthinking" phenomenon, and achieves superior accuracy compared to previous methods.

\end{itemize}
