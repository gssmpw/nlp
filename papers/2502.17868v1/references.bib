@inproceedings{disappearables2022,
address = {New York, NY, USA},
author = {Nakagaki, Ken and Tappa, Jordan L and Zheng, Yi and Forman, Jack and Leong, Joanne and Koenig, Sven and Ishii, Hiroshi},
booktitle = {CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3491102.3501906},
file = {:Users/hanc/Downloads/papers/3491102.3501906.pdf:pdf},
isbn = {9781450391573},
keywords = {Actuated Tangible User Interfaces,Swarm User Inte,acm reference format,actuated tangible user interfaces,dynamic,physical afordance,stage,swarm user interface},
month = {apr},
pages = {1--13},
publisher = {ACM},
title = {{(Dis)Appearables: A Concept and Method for Actuated Tangible UIs to Appear and Disappear based on Stages}},
url = {https://dl.acm.org/doi/10.1145/3491102.3501906},
year = {2022}
}
@article{Chung2018,
abstract = {The use of aerial swarms to solve real-world problems has been increasing steadily, accompanied by falling prices and improving performance of communication, sensing, and processing hardware. The commoditization of hardware has reduced unit costs, thereby lowering the barriers to entry to the field of aerial swarm robotics. A key enabling technology for swarms is the family of algorithms that allow the individual members of the swarm to communicate and allocate tasks amongst themselves, plan their trajectories, and coordinate their flight in such a way that the overall objectives of the swarm are achieved efficiently. These algorithms, often organized in a hierarchical fashion, endow the swarm with autonomy at every level, and the role of a human operator can be reduced, in principle, to interactions at a higher level without direct intervention. This technology depends on the clever and innovative application of theoretical tools from control and estimation. This paper reviews the state of the art of these theoretical tools, specifically focusing on how they have been developed for, and applied to, aerial swarms. Aerial swarms differ from swarms of ground-based vehicles in two respects: they operate in a three-dimensional space and the dynamics of individual vehicles adds an extra layer of complexity. We review dynamic modeling and conditions for stability and controllability that are essential in order to achieve cooperative flight and distributed sensing. The main sections of this paper focus on major results covering trajectory generation, task allocation, adversarial control, distributed sensing, monitoring, and mapping. Wherever possible, we indicate how the physics and subsystem technologies of aerial robots are brought to bear on these individual areas.},
author = {Chung, Soon Jo and Paranjape, Aditya Avinash and Dames, Philip and Shen, Shaojie and Kumar, Vijay},
doi = {10.1109/TRO.2018.2857475},
file = {:Users/hanc/Downloads/papers/A_Survey_on_Aerial_Swarm_Robotics.pdf:pdf},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Aerial robotics,distributed robot systems,networked robots},
number = {4},
pages = {837--855},
publisher = {IEEE},
title = {{A Survey on Aerial Swarm Robotics}},
volume = {34},
year = {2018}
}
@article{armyants2015,
author = {Sokol, Joshua},
journal = {Smithsonian Magazine},
title = {{Army Ants Act Like Algorithms to Make Deliveries More Efficient}},
year = {2015}
}
@inproceedings{AugCol2006,
abstract = {We propose a novel display-based game environment using augmented reality technology with small robots. In this environment, the small robots can be augmented by a display image according to their positions and postures. The augmentation activity reinforces the fun of playing with such small robots in the real world. {\textcopyright} 2006 IEEE.},
author = {Kojima, Minoru and Sugimoto, Maki and Nakamura, Akihiro and Tomita, Masahiro and Inami, Masahiko and Nii, Hideaki},
booktitle = {First IEEE International Workshop on Horizontal Interactive Human-Computer Systems (TABLETOP '06)},
doi = {10.1109/TABLETOP.2006.3},
file = {:Users/hanc/Downloads/papers/augmented_coliseum.pdf:pdf},
isbn = {0-7695-2494-X},
pages = {3--8},
publisher = {IEEE},
title = {{Augmented Coliseum: An Augmented Game Environment with Small Vehicles}},
url = {http://ieeexplore.ieee.org/document/1579184/},
volume = {2006},
year = {2006}
}
@inproceedings{Suzuki2022,
abstract = {This paper contributes to a taxonomy of augmented reality and robotics based on a survey of 460 research papers. Augmented and mixed reality (AR/MR) have emerged as a new way to enhance human-robot interaction (HRI) and robotic interfaces (e.g., actuated and shape-changing interfaces). Recently, an increasing number of studies in HCI, HRI, and robotics have demonstrated how AR enables better interactions between people and robots. However, often research remains focused on individual explorations and key design strategies, and research questions are rarely analyzed systematically. In this paper, we synthesize and categorize this research field in the following dimensions: 1) approaches to augmenting reality; 2) characteristics of robots; 3) purposes and benefits; 4) classification of presented information; 5) design components and strategies for visual augmentation; 6) interaction techniques and modalities; 7) application domains; and 8) evaluation strategies. We formulate key challenges and opportunities to guide and inform future research in AR and robotics.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {2203.03254v1},
author = {Suzuki, Ryo and Karim, Adnan and Xia, Tian and Hedayati, Hooman and Marquardt, Nicolai},
booktitle = {CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3491102.3517719},
eprint = {2203.03254v1},
file = {:Users/hanc/Downloads/papers/3491102.3517719.pdf:pdf},
isbn = {9781450391573},
keywords = {actuated tangible interfaces,augmented reality,human-robot interaction,mixed reality,robotics,shape-changing interfaces,survey},
month = {apr},
pages = {1--33},
publisher = {ACM},
title = {{Augmented Reality and Robotics: A Survey and Taxonomy for AR-enhanced Human-Robot Interaction and Robotic Interfaces}},
url = {http://dx.doi.org/10.1145/3491102.3517719},
year = {2022}
}
@inproceedings{Reina2015,
abstract = {We present a novel technology that allows real robots to perceive an augmented reality environment through virtual sensors. Virtual sensors are a useful and desirable technology for research activities because they allow researchers to quickly and efficiently perform experiments that would otherwise be more expensive, or even impossible. In particular, augmented reality is useful (i) for prototyping and assessing the impact of new sensors before they are physically produced; and (ii) for developing and studying the behaviour of robots that should deal with phenomena that cannot be easily reproduced in a laboratory environment because, for example, they are dangerous (e.g., fire, radiations). We realised an augmented reality system for robots in which a simulator retrieves real-time data on the real environment through a multi-camera tracking system and delivers post-processed information to the robot swarm according to each robot's sensing range. We illustrate the proposed virtual sensing technology through an experiment involving 15 e-pucks.},
author = {Reina, Andreagiovanni and Salvaro, Mattia and Francesca, Gianpiero and Garattoni, Lorenzo and Pinciroli, Carlo and Dorigo, Marco and Birattari, Mauro},
booktitle = {2015 NASA/ESA Conference on Adaptive Hardware and Systems (AHS)},
doi = {10.1109/AHS.2015.7231154},
file = {:Users/hanc/Downloads/papers/Augmented_reality_for_robots_Virtual_sensing_technology_applied_to_a_swarm_of_e-pucks.pdf:pdf},
isbn = {978-1-4673-7501-6},
keywords = {Augmented reality,Hardware,Robot kinematics,Robot sensing systems,Software},
month = {jun},
pages = {1--6},
publisher = {IEEE},
title = {{Augmented reality for robots: Virtual sensing technology applied to a swarm of e-pucks}},
url = {http://ieeexplore.ieee.org/document/7231154/},
year = {2015}
}
@inproceedings{CLASH2011,
abstract = {CLASH is a 10cm, 15g robot capable of climbing vertical loose-cloth surfaces at 15 cm per second. The robot has a single actuator driving its six legs which are equipped with novel passive foot mechanisms to facilitate smooth engagement and disengagement of spines. These foot mechanisms are designed to be used on penetrable surfaces and offer improved tensile normal force generation during stance and reduced normal pull-off forces during retraction. Descended from the DASH hexapedal robot, CLASH features a redesigned transmission with a lower profile and improved dynamics for climbing. CLASH is the first known robot to climb loose vertical cloth and is able to climb surfaces when surface rigidity is not guaranteed. {\textcopyright} 2011 IEEE.},
author = {Birkmeyer, P. and Gillies, A. G. and Fearing, R. S.},
booktitle = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2011.6048573},
file = {:Users/hanc/Downloads/papers/CLASH_Climbing_vertical_loose_cloth.pdf:pdf},
isbn = {978-1-61284-456-5},
month = {sep},
pages = {5087--5093},
publisher = {IEEE},
title = {{CLASH: Climbing Vertical Loose Cloth}},
url = {https://ieeexplore.ieee.org/document/6048573},
year = {2011}
}
@article{Takada2017,
abstract = {Several infrastructures, such as bridges and tunnels, require periodic inspection and repair to prevent collapse. There is a strong demand for practical bridge inspection robots to reduce the cost and time associated with the inspection of bridges by an inspector. Bridge inspection robots are expected to pass through obstacles such as bolted splice part and right-angled routes. The aim of this study involved developing a bridge inspection robot that can travel on a right-angle path as well as splicing parts. A two-wheel-drive robot was developed and equipped with two rimless wheels as driving wheels. A neodymium magnet was provided at the tip of each spoke. Non-driving wheels were attached at the rear as a rotatable caster. The robot can turn on the spot to avoid the bolt on the splicing part. Experiments were conducted to check the performance of the robot. The results confirmed that the robot passed through the internal right-angle paths in a laboratory and in an actual environment that corresponds to a box girder of a bridge. It is extremely difficult to manually control a robot on the splicing part. Therefore, a camera and an LED (light emitting diode) were attached to autonomously control the robot. The results indicate that the newly developed robot could run through the splicing part without hitting the nuts.},
author = {Takada, Yogo and Ito, Satoshi and Imajo, Naoto},
doi = {10.3390/inventions2030022},
file = {:Users/hanc/Downloads/papers/inventions-02-00022-v2.pdf:pdf},
issn = {2411-5134},
journal = {Inventions},
keywords = {Bolt,Bridge inspection,Magnet,Moving robot,Right-angle path,Rimless wheel,Splicing part,Steel bridge,Two-wheel-driven robot},
month = {aug},
number = {3},
pages = {22},
title = {{Development of a Bridge Inspection Robot Capable of Traveling on Splicing Parts}},
url = {http://www.mdpi.com/2411-5134/2/3/22},
volume = {2},
year = {2017}
}
@article{Matsumura2019,
author = {Matsumura, Yodai and Kawamoto, Koyo and Takada, Yogo},
doi = {10.7210/jrsj.37.514},
file = {:Users/hanc/Downloads/papers/37_37_514.pdf:pdf},
issn = {0289-1824},
journal = {Journal of the Robotics Society of Japan},
keywords = {bridge inspection,four-wheel driving robot,magnet,rimless wheel,wall-climbing robot},
number = {6},
pages = {514--522},
title = {{Development of a Compact Wall-Climbing Robot Capable of Transitioning among Floor, Vertical Wall and Ceiling}},
volume = {37},
year = {2019}
}
@article{Panich2010,
author = {Panich, Surachai},
doi = {10.3844/jcssp.2010.1185.1188},
file = {:Users/hanc/Downloads/papers/jcssp.2010.1185.1188.pdf:pdf},
issn = {1549-3636},
journal = {Journal of Computer Science},
keywords = {force analysis,pneumatic system,wall climbing robot},
month = {oct},
number = {10},
pages = {1185--1188},
title = {{Development of a Wall Climbing Robot}},
url = {http://www.thescipub.com/abstract/10.3844/jcssp.2010.1185.1188},
volume = {6},
year = {2010}
}
@article{LeGoc2019,
abstract = {This paper introduces dynamic composite physicalizations, a new class of physical visualizations that use collections of self-propelled objects to represent data. Dynamic composite physicalizations can be used both to give physical form to well-known interactive visualization techniques, and to explore new visualizations and interaction paradigms. We first propose a design space characterizing composite physicalizations based on previous work in the fields of Information Visualization and Human Computer Interaction. We illustrate dynamic composite physicalizations in two scenarios demonstrating potential benefits for collaboration and decision making, as well as new opportunities for physical interaction. We then describe our implementation using wheeled micro-robots capable of locating themselves and sensing user input, before discussing limitations and opportunities for future work.},
author = {{Le Goc}, Mathieu and Perin, Charles and Follmer, Sean and Fekete, Jean-Daniel and Dragicevic, Pierre},
doi = {10.1109/TVCG.2018.2865159},
file = {:Users/hanc/Downloads/papers/Dynamic_Composite_Data_Physicalization_Using_Wheeled_Micro-Robots.pdf:pdf},
issn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {data physicalization,information visualization,tangible user interfaces},
month = {jan},
number = {1},
pages = {737--747},
title = {{Dynamic Composite Data Physicalization Using Wheeled Micro-Robots}},
url = {https://ieeexplore.ieee.org/document/8440836/},
volume = {25},
year = {2019}
}
@phdthesis{Suzuki2020,
author = {Suzuki, Ryo},
booktitle = {University of Colorado Boulder},
file = {:Users/hanc/Downloads/papers/ryo_suzuki_phd_thesis.pdf:pdf},
pages = {1--289},
school = {University of Colorado Boulder},
title = {{Dynamic Shape Construction and Transformation with Collective Elements}},
url = {https://doi.org/10.1016/j.jnc.2020.125798%0Ahttps://doi.org/10.1016/j.smr.2020.02.002%0Ahttp://www.ncbi.nlm.nih.gov/pubmed/810049%0Ahttp://doi.wiley.com/10.1002/anie.197505391%0Ahttp://www.sciencedirect.com/science/article/pii/B9780857090409500205%0Ahttp:},
year = {2020}
}
@inproceedings{Liang2020,
abstract = {This paper proposes a novel modular selfreconfigurable robot (MSRR) "FreeBOT", which can be connected freely at any point on other robots. FreeBOT is mainly composed of two parts: a spherical ferromagnetic shell and an internal magnet. The connection between the modules is genderless and instant, since the internal magnet can freely attract other FreeBOT spherical ferromagnetic shells, and not need to be precisely aligned with the specified connector. This connection method has fewer physical constraints, so the FreeBOT system can be extended to more configurations to meet more functional requirements. FreeBOT can accomplish multiple tasks although it only has two motors: module independent movement, connector management and system reconfiguration. FreeBOT can move independently on the plane, and even climb on ferromagnetic walls; a group of FreeBOTs can traverse complex terrain. Numerous experiments have been conducted to test its function, which shows that the FreeBOT system has great potential to realize a freeform robotic system.},
author = {Liang, Guanqi and Luo, Haobo and Li, Ming and Qian, Huihuan and Lam, Tin Lun},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS45743.2020.9341129},
file = {:Users/hanc/Downloads/papers/FreeBOT_A_Freeform_Modular_Self-reconfigurable_Robot_with_Arbitrary_Connection_Point_-_Design_and_Implementation (1).pdf:pdf},
isbn = {9781728162126},
issn = {21530866},
publisher = {IEEE},
pages = {6506--6513},
title = {{FreeBOT: A freeform modular self-reconfigurable robot with arbitrary connection point - Design and implementation}},
year = {2020}
}
@inproceedings{Alonso-Mora2015,
abstract = {A taxonomy for gesture-based interaction between a human and a group (swarm) of robots is described. Methods are classified into two categories. First, free-form interaction, where the robots are unconstrained in position and motion and the user can use deictic gestures to select subsets of robots and assign target goals and trajectories. Second, shape-constrained interaction, where the robots are in a configuration shape that can be modified by the user. In the later, the user controls a subset of meaningful degrees of freedom defining the overall shape instead of each robot directly. A multi-robot interactive display is described where a depth sensor is used to recognize human gesture, determining the commands sent to a group comprising tens of robots. Experimental results with a preliminary user study show the usability of the system.},
author = {Alonso-Mora, J. and {Haegeli Lohaus}, S. and Leemann, P. and Siegwart, R. and Beardsley, P.},
booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA)},
doi = {10.1109/ICRA.2015.7140033},
file = {:Users/hanc/Downloads/papers/Gesture_based_human_-_Multi-robot_swarm_interaction_and_its_application_to_an_interactive_display.pdf:pdf},
isbn = {978-1-4799-6923-4},
issn = {10504729},
month = {may},
pages = {5948--5953},
publisher = {IEEE},
title = {{Gesture Based Human - Multi-Robot Swarm Interaction and its Application to an Interactive Display}},
url = {http://ieeexplore.ieee.org/document/7140033/},
volume = {2015-June},
year = {2015}
}
@inproceedings{Griddrones2018,
abstract = {We present GridDrones, a self-levitating programmable matter platform that can be used for representing 2.5D voxel grid relief maps capable of rendering unsupported structures and 3D transformations. GridDrones consists of cube-shaped nanocopters that can be placed in a volumetric 1xnxn midair grid, which is demonstrated here with 15 voxels. The number of voxels and scale is only limited by the size of the room and budget. Grid deformations can be applied interactively to this voxel lattice by manually selecting a set of voxels, then assigning a continuous topological relationship between voxel sets that determines how voxels move in relation to each other and manually drawing out selected voxels from the lattice structure. Using this simple technique, it is possible to create unsupported structures that can be translated and oriented freely in 3D. Shape transformations can also be recorded to allow for simple physical shape morphing animations. This work extends previous work on selection and editing techniques for 3D user interfaces.},
address = {New York, NY, USA},
author = {Braley, Sean and Rubens, Calvin and Merritt, Timothy and Vertegaal, Roel},
booktitle = {Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/3242587.3242658},
file = {:Users/hanc/Downloads/papers/3242587.3242658.pdf:pdf},
isbn = {9781450359481},
keywords = {Claytronics,Organic user interfaces,Programmable matter,Radical atoms,Swarm user interfaces},
month = {oct},
pages = {87--98},
publisher = {ACM},
title = {{GridDrones: A Self-Levitating Physical Voxel Lattice for Interactive 3D Surface Deformations}},
url = {https://dl.acm.org/doi/10.1145/3242587.3242658},
year = {2018}
}
@inproceedings{HapticBots2021,
abstract = {HapticBots introduces a novel encountered-type haptic approach for Virtual Reality (VR) based on multiple tabletop-size shape-changing robots. These robots move on a tabletop and change their height and orientation to haptically render various surfaces and objects on-demand. Compared to previous encountered-type haptic approaches like shape displays or robotic arms, our proposed approach has an advantage in deployability, scalability, and generalizability - these robots can be easily deployed due to their compact form factor. They can support multiple concurrent touch points in a large area thanks to the distributed nature of the robots. We propose and evaluate a novel set of interactions enabled by these robots which include: 1) rendering haptics for VR objects by providing just-in-time touch-points on the user's hand, 2) simulating continuous surfaces with the concurrent height and position change, and 3) enabling the user to pick up and move VR objects through graspable proxy objects. Finally, we demonstrate HapticBots with various applications, including remote collaboration, education and training, design and 3D modeling, and gaming and entertainment.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {2108.10829},
author = {Suzuki, Ryo and Ofek, Eyal and Sinclair, Mike and Leithinger, Daniel and Gonzalez-Franco, Mar},
booktitle = {The 34th Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/3472749.3474821},
eprint = {2108.10829},
file = {:Users/hanc/Downloads/papers/3472749.3474821.pdf:pdf},
isbn = {9781450386357},
keywords = {encountered-type haptics,swarm user interfaces,tabletop mobile robots,virtual reality},
month = {oct},
pages = {1269--1281},
publisher = {ACM},
title = {{HapticBots: Distributed Encountered-type Haptics for VR with Multiple Shape-changing Mobile Robots}},
url = {https://dl.acm.org/doi/10.1145/3472749.3474821},
year = {2021}
}
@inproceedings{HERMITS2020,
abstract = {We introduce HERMITS, a modular interaction architecture for self-propelled Tangible User Interfaces (TUIs) that incorporates physical add-ons, referred to as mechanical shells. The mechanical shell add-ons are intended to be dynamically reconfigured by utilizing the locomotion capability of self-propelled TUIs (e.g. wheeled TUIs, swarm UIs). We developed a proof-of-concept system that demonstrates this novel architecture using two-wheeled robots and a variety of mechanical shell examples. These mechanical shell add-ons are passive physical attatchments that extend the primitive interactivities (e.g. shape, motion and light) of the self-propelled robots. The paper proposes the architectural design, interactive functionality of HERMITS as well as design primitives for mechanical shells. The paper also introduces the prototype implementation that is based on an off-the-shelf robotic toy with a modified docking mechanism. A range of applications is demonstrated with the prototype to motivate the collective and dynamically reconfigurable capability of the modular architecture, such as an interactive mobility simulation, an adaptive home/desk environment, and a story-telling narrative. Lastly, we discuss the future research opportunity of HERMITS to enrich the interactivity and adaptability of actuated and shape changing TUIs.},
address = {New York, NY, USA},
author = {Nakagaki, Ken and Leong, Joanne and Tappa, Jordan L. and Wilbert, Jo{\~{a}}o and Ishii, Hiroshi},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/3379337.3415831},
file = {:Users/hanc/Downloads/papers/3379337.3415831.pdf:pdf},
isbn = {9781450375146},
keywords = {Actuated tangible user interface,Human robot interaction,Mechanical shell,Swarm user interface},
month = {oct},
pages = {882--896},
publisher = {ACM},
title = {{HERMITS: Dynamically Reconfiguring the Interactivity of Self-Propelled TUIs with Mechanical Shell Add-ons}},
url = {https://dl.acm.org/doi/10.1145/3379337.3415831},
year = {2020}
}
@article{Alonso-Mora2012,
abstract = {In this article we present a novel display that is created using a group of mobile robots. In contrast to traditional displays that are based on a fixed grid of pixels, such as a screen or a projection, this work describes a display in which each pixel is a mobile robot of controllable color. Pixels become mobile entities, and their positioning and motion are used to produce a novel experience. The system input is a single image or an animation created by an artist. The first stage is to generate physical goal configurations and robot colors to optimally represent the input imagery with the available number of robots. The run-time system includes goal assignment, path planning and local reciprocal collision avoidance, to guarantee smooth, fast and oscillation-free motion between images. The algorithms scale to very large robot swarms and extend to a wide range of robot kinematics. Experimental evaluation is done for two different physical swarms of size 14 and 50 differentially driven robots, and for simulations with 1,000 robot pixels.},
author = {Alonso-Mora, Javier and Breitenmoser, Andreas and Rufli, Martin and Siegwart, Roland and Beardsley, Paul},
doi = {10.1177/0278364912442095},
file = {:Users/hanc/Downloads/papers/12-alonsomora-ijrr.pdf:pdf},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
keywords = {Image display,Multi-robot system,Non-holonomic path planning,Pattern formation,Video display},
month = {may},
number = {6},
pages = {753--773},
title = {{Image and animation display with multiple mobile robots}},
url = {https://doi.org/10.1177/0278364912442095 http://journals.sagepub.com/doi/10.1177/0278364912442095},
volume = {31},
year = {2012}
}
@inproceedings{Kennel-Maushart2023,
author = {Kennel-Maushart, Florian and Poranne, Roi and Coros, Stelian},
booktitle = {2023 IEEE International Conference on Robotics and Automation},
title = {{Interacting with Multi-Robot Systems via Mixed Reality}},
year = {2023}
}
@article{Kilobot2014,
abstract = {In current robotics research there is a vast body of work on algorithms and control methods for groups of decentralized cooperating robots, called a swarm or collective. These algorithms are generally meant to control collectives of hundreds or even thousands of robots; however, for reasons of cost, time, or complexity, they are generally validated in simulation only, or on a group of a few tens of robots. To address this issue, this paper presents Kilobot, an open-source, low cost robot designed to make testing collective algorithms on hundreds or thousands of robots accessible to robotics researchers. To enable the possibility of large Kilobot collectives where the number of robots is an order of magnitude larger than the largest that exist today, each robot is made with only $14 worth of parts and takes 5 min to assemble. Furthermore, the robot design allows a single user to easily operate a large Kilobot collective, such as programming, powering on, and charging all robots, which would be difficult or impossible to do with many existing robotic systems. We demonstrate the capabilities of the Kilobot as a collective robot, by using a small robot test collective to implement four popular swarm behaviors: foraging, formation control, phototaxis, and synchronization. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Rubenstein, Michael and Ahler, Christian and Hoff, Nick and Cabrera, Adrian and Nagpal, Radhika},
doi = {10.1016/j.robot.2013.08.006},
file = {:Users/hanc/Downloads/papers/1-s2.0-S0921889013001474-main.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Modular robot,Multi-robot system,Robot collectives},
number = {7},
pages = {966--975},
publisher = {Elsevier B.V.},
title = {{Kilobot: A low cost robot with scalable operations designed for collective behaviors}},
url = {http://dx.doi.org/10.1016/j.robot.2013.08.006},
volume = {62},
year = {2014}
}
@inproceedings{Rubenstein2012,
abstract = {In current robotics research there is a vast body of work on algorithms and control methods for groups of decentralized cooperating robots, called a swarm or collective. These algorithms are generally meant to control collectives of hundreds or even thousands of robots; however, for reasons of cost, time, or complexity, they are generally validated in simulation only, or on a group of a few tens of robots. To address this issue, this paper presents Kilobot, a low-cost robot designed to make testing collective algorithms on hundreds or thousands of robots accessible to robotics researchers. To enable the possibility of large Kilobot collectives where the number of robots is an order of magnitude larger than the largest that exist today, each robot is made with only $14 worth of parts and takes 5 minutes to assemble. Furthermore, the robot design allows a single user to easily operate a large Kilobot collective, such as programming, powering on, and charging all robots, which would be difficult or impossible to do with many existing robotic systems. {\textcopyright} 2012 IEEE.},
author = {Rubenstein, Michael and Ahler, Christian and Nagpal, Radhika},
booktitle = {2012 IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2012.6224638},
file = {:Users/hanc/Downloads/papers/Kilobot_A_low_cost_scalable_robot_system_for_collective_behaviors.pdf:pdf},
isbn = {978-1-4673-1405-3},
issn = {10504729},
month = {may},
pages = {3293--3298},
publisher = {IEEE},
title = {{Kilobot: A low cost scalable robot system for collective behaviors}},
url = {http://ieeexplore.ieee.org/document/6224638/},
year = {2012}
}
@inproceedings{Patel2019,
author = {Patel, Jayam and Xu, Yicong and Pinciroli, Carlo},
booktitle = {International Conference on Robotics and Automation (ICRA)},
doi = {10.1109/ICRA.2019.8793261},
file = {:Users/hanc/Downloads/papers/Mixed-Granularity_Human-Swarm_Interaction.pdf:pdf},
isbn = {978-1-5386-6027-0},
month = {may},
pages = {1059--1065},
publisher = {IEEE},
title = {{Mixed-Granularity Human-Swarm Interaction}},
url = {https://ieeexplore.ieee.org/document/8793261/},
year = {2019}
}
@inproceedings{Nisser2022,
address = {New York, NY, USA},
author = {Nisser, Martin and Makaram, Yashaswini and Covarrubias, Lucian and Bah, Amadou Yaye and Faruqi, Faraz and Suzuki, Ryo and Mueller, Stefanie},
booktitle = {The 35th Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/3526113.3545698},
file = {:Users/hanc/Downloads/papers/3526113.3545698.pdf:pdf},
isbn = {9781450393201},
keywords = {fabrication,magnetic interfaces,programmable materials},
month = {oct},
number = {1},
pages = {1--12},
publisher = {ACM},
title = {{Mixels: Fabricating Interfaces using Programmable Magnetic Pixels}},
url = {https://dl.acm.org/doi/10.1145/3526113.3545698},
volume = {1},
year = {2022}
}
@inproceedings{Ahmed2022,
abstract = {This paper presents a novel design of a multi-directional bicycle robot, which is developed for the inspection of steel structures, in particular, steel-reinforced bridges. The locomotion concept is based on arranging two magnetic wheels in a bicycle-like configuration with two independent steering actuators. This configuration allows the robot to possess multi-directional mobility. An additional free joint helps the robot adapt naturally to non-flat and complex steel structures. The robot's design provides the advantage of being mechanically simple and providing high-level mobility across diverse steel structures. In addition, a visual sensor is equipped that allows the data collection for steel defect detection with offline training and validation. The paper also provides a novel pipeline for Steel Defect Detection, which utilizes multiple datasets (one for training and one for validation) from real bridges. The quantitative results have been reported for three Deep Encoder-Decoder Networks (i.e., LinkNet, UNet, DeepLab) with their corresponding Encoder modules (i.e., ResNet-18, ResNet-34, RegNet-X2, EfficientNet-B0, and EfficientNet-B2). Due to space concerns, the qualitative results have been outlined in Appendix, with a link in Fig. 11 caption to access the result provided.},
author = {Ahmed, Habib and Nguyen, Son Thanh and La, Duc and Le, Chuong Phuoc and La, Hung Manh},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS47612.2022.9981325},
file = {:Users/hanc/Downloads/papers/Multi-directional_Bicycle_Robot_for_Bridge_Inspection_with_Steel_Defect_Detection_System.pdf:pdf},
isbn = {9781665479271},
issn = {21530866},
pages = {4617--4624},
publisher = {IEEE},
title = {{Multi-directional Bicycle Robot for Bridge Inspection with Steel Defect Detection System}},
volume = {2022-Octob},
year = {2022}
}
@inproceedings{Alonso-Mora2011,
abstract = {This paper describes work on multi-robot pattern formation. Arbitrary target patterns are represented with an optimal robot deployment, using a method that is independent of the number of robots. Furthermore, the trajectories are visually appealing in the sense of being smooth, oscillation free, and showing fast convergence. A distributed controller guarantees collision free trajectories while taking into account the kinematics of differentially driven robots. Experimental results are provided for a representative set of patterns, for a swarm of up to ten physical robots, and for fifty virtual robots in simulation. {\textcopyright} 2011 IEEE.},
author = {Alonso-Mora, Javier and Breitenmoser, Andreas and Rufli, Martin and Siegwart, Roland and Beardsley, Paul},
booktitle = {IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2011.5980269},
file = {:Users/hanc/Downloads/papers/Multi-robot_system_for_artistic_pattern_formation.pdf:pdf},
isbn = {978-1-61284-386-5},
issn = {10504729},
month = {may},
pages = {4512--4517},
publisher = {IEEE},
title = {{Multi-Robot System for Artistic Pattern Formation}},
url = {http://ieeexplore.ieee.org/document/5980269/},
year = {2011}
}
@inproceedings{Inoue2006,
abstract = {A method for limb mechanism robots of omni-directional gait hanging from grid-like structure is proposed. Grid-like structure consists of many bars assembled in a matrix in a horizontal plane; its grid spacing is not always constant and unknown. A robot has six legs, and each foot has a hemispherical shape for hooking on the bar. The robot moves in any direction as commanded by tripod gait; it hangs from the grid-like structure using two sets of three legs alternately. The leg gropes for the bar so as to take as long stroke as possible. By increasing joint compliance, the foot contacts the bar softly and detects the contact. Then, using a foot force sensor, the robot ascertains that the foot hooks on the bar. The developed robot ASTERISK can perform omni-directional gait hanging from experimental gridlike structure by the proposed method. {\textcopyright} 2006 IEEE.},
author = {Inoue, Kenji and Tsurutani, Taisuke and Takubo, Tomohito and Arai, Tatsuo},
booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2006.282133},
file = {:Users/hanc/Downloads/papers/Omni-directional_Gait_of_Limb_Mechanism_Robot_Hanging_from_Grid-like_Structure.pdf:pdf},
isbn = {1-4244-0258-1},
keywords = {Force sensor,Grid-like structure,Joint compliance,Omni-directional gait,Six-legged robot},
month = {oct},
pages = {1732--1737},
publisher = {IEEE},
title = {{Omni-directional Gait of Limb Mechanism Robot Hanging from Grid-like Structure}},
url = {http://ieeexplore.ieee.org/document/4058626/},
year = {2006}
}
@inproceedings{Hiraki2016,
author = {Hiraki, Takefumi and Fukushima, Shogo and Naemura, Takeshi},
title = {Phygital field: an integrated field with a swarm of physical robots and digital images},
year = {2016},
isbn = {9781450345392},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988240.2988242},
doi = {10.1145/2988240.2988242},
abstract = {Collaboration between computer graphics and multiple robots has attracted increasing attention in several areas. To preserve the seamless connection between them, the system needs to be able to accurately determine the position and state of the robots and be able to control them easily and instantly. However, realizing a responsive control system for a large number of mobile robots without complex settings and at the same time avoiding the system load problem is not trivial. Our system, called "Phygital Field", can project two types of information: visible images for humans and data patterns for mobile robots in the same location by utilizing pixel-level visual light communication (PVLC) technology. Phygital Field offers two technical innovations: an initialization-free and marker-free localization and control method, and a system noted for its simplicity and scalability. Phygital Field enables the robots to always recognize their own positions and states immediately, the measurement devices are not required because localization and control of the robots are realized through projection. These features are very important to improve the reconfigurability of the system. The idea of controlling robots by using information embedded in projected images allows users to easily design an integrated environment for the physical robots and digital images to preserve the seamless connection between them.},
booktitle = {SIGGRAPH ASIA 2016 Emerging Technologies},
articleno = {2},
numpages = {2},
keywords = {robot swarm, pixel-level visible light communication, mixed reality, high-speed projector, digital micromirror device},
location = {Macau},
series = {SA '16}
}
@inproceedings{Hiraki2015,
abstract = {Forming images by using a swarm of mobile robots has emerged as a new platform for computer entertainment. Each robot has col- ored lighting, and the swarm represents various abstract patterns by using the lighting and the locomotion. The aim of our research is to create a novel display field named Phygital Field, which integrates the physical world created by robot swarms and the digital world produced by a graphical display. To integrate them, we used a pixel-level visible light communica- Tion (PVLC) projector [Kimura et al. 2008], which can superimpose data patterns on pixels by human-imperceptible high speed flicker. This data patterns contains coordinates, control instructions, and more types of information that you want to program. By combin- ing a swarm of robots and the graphical display, each type of image can be augmented. So far, several types of systems for the symbiosis of robots and computer graphics have been proposed [Sugimoto et al. 2005]. Compared with these works, Phygital Field has three technical in- novations: An initialization-free and marker-free display method, the simplicity of the total system, customizable data transmission.},
author = {Hiraki, Takefumi and Takahashi, Issei and Goto, Shotaro and Fukushima, Shogo and Naemura, Takeshi},
booktitle = {ACM SIGGRAPH 2015 Posters, SIGGRAPH 2015},
doi = {10.1145/2787626.2792604},
file = {:Users/hanc/Downloads/papers/2787626.2792604.pdf:pdf},
isbn = {9781450336321},
pages = {2792604},
title = {{Phygital Field: Integrated Field with Visible Images and Robot Swarm Controlled by Invisible Images}},
year = {2015}
}
@incollection{Murphy2020,
author = {Murphy, Alex and Millard, Alan G.},
booktitle = {Annual Conference Towards Autonomous Robotic Systems},
doi = {10.1007/978-3-030-63486-5_39},
file = {:Users/hanc/Downloads/papers/978-3-030-63486-5.pdf:pdf},
isbn = {9783030634858},
pages = {377--386},
title = {{Prototyping Sensors and Actuators for Robot Swarms in Mixed Reality}},
url = {http://link.springer.com/10.1007/978-3-030-63486-5_39},
year = {2020}
}
@inproceedings{Reactile2018,
abstract = {We explore a new approach to programming swarm user interfaces (Swarm UI) by leveraging direct physical manipulation. Existing Swarm UI applications are written using a robot programming framework: users work on a computer screen and think in terms of low-level controls. In contrast, our approach allows programmers to work in physical space by directly manipulating objects and think in terms of highlevel interface design. Inspired by current UI programming practices, we introduce a four-step workflow-create elements, abstract attributes, specify behaviors, and propagate changes- for Swarm UI programming. We propose a set of direct physical manipulation techniques to support each step in this workflow. To demonstrate these concepts, we developed Reactile, a Swarm UI programming environment that actuates a swarm of small magnets and displays spatial information of program states using a DLP projector. Two user studies-an in-class survey with 148 students and a lab interview with eight participants-confirm that our approach is intuitive and understandable for programming Swarm UIs.},
address = {New York, NY, USA},
author = {Suzuki, Ryo and Kato, Jun and Gross, Mark D. and Yeh, Tom},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3173574.3173773},
file = {:Users/hanc/Downloads/papers/3173574.3173773.pdf:pdf},
isbn = {9781450356206},
keywords = {Direct manipulation,Programming by demonstration,Swarm user interfaces,Tangible programming},
month = {apr},
pages = {1--13},
publisher = {ACM},
title = {{Reactile: Programming Swarm User Interfaces through Direct Physical Manipulation}},
url = {https://dl.acm.org/doi/10.1145/3173574.3173773},
volume = {2018-April},
year = {2018}
}
@inproceedings{Zhao2017a,
abstract = {Passive haptic proxy objects allow for rich tangible interaction, and this is especially true in VR applications. However, this requires users to have many physical objects at hand. Our paper proposes robotic assembly at run-time of low-resolution haptic proxies for tangible interaction and virtual reality. These assembled physical proxy objects are composed of magnetically attached blocks which are assembled by a small multi robot system, specifically Zooids. We explore the design of the basic building blocks and illustrate two approaches to assembling physical proxies: using multirobot systems to (1) self-assemble into structures and (2) assemble 2.5D structure with passive blocks of various heights. The success rate and completion time are evaluated for both approaches. Finally, we demonstrate the potential of assembled proxy objects for tangible interaction and virtual reality through a set of demonstrations.},
address = {New York, NY, USA},
author = {Zhao, Yiwei and Kim, Lawrence H. and Wang, Ye and {Le Goc}, Mathieu and Follmer, Sean},
booktitle = {Proceedings of the 2017 ACM International Conference on Interactive Surfaces and Spaces},
doi = {10.1145/3132272.3134143},
file = {:Users/hanc/Library/Application Support/Mendeley Desktop/Downloaded/Zhao et al. - 2017 - Robotic Assembly of Haptic Proxy Objects for Tangible Interaction and Virtual Reality.pdf:pdf},
isbn = {9781450346917},
month = {oct},
pages = {82--91},
publisher = {ACM},
title = {{Robotic Assembly of Haptic Proxy Objects for Tangible Interaction and Virtual Reality}},
url = {https://dl.acm.org/doi/10.1145/3132272.3134143},
year = {2017}
}
@inproceedings{RoomShift2020,
abstract = {RoomShift is a room-scale dynamic haptic environment for virtual reality, using a small swarm of robots that can move furniture. RoomShift consists of nine shape-changing robots: Roombas with mechanical scissor lifts. These robots drive beneath a piece of furniture to lift, move and place it. By augmenting virtual scenes with physical objects, users can sit on, lean against, place and otherwise interact with furniture with their whole body; just as in the real world. When the virtual scene changes or users navigate within it, the swarm of robots dynamically reconfigures the physical environment to match the virtual content. We describe the hardware and software implementation, applications in virtual tours and architectural design and interaction techniques.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {2008.08695},
author = {Suzuki, Ryo and Hedayati, Hooman and Zheng, Clement and Bohn, James L. and Szafir, Daniel and Do, Ellen Yi-Luen and Gross, Mark D. and Leithinger, Daniel},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3313831.3376523},
eprint = {2008.08695},
file = {:Users/hanc/Downloads/papers/chi-2020-roomshift.pdf:pdf},
isbn = {9781450367080},
keywords = {haptic interfaces,room-scale haptics,swarm robots,virtual reality},
month = {apr},
pages = {1--11},
publisher = {ACM},
title = {{RoomShift: Room-scale Dynamic Haptics for VR with Furniture-moving Swarm Robots}},
url = {https://dl.acm.org/doi/10.1145/3313831.3376523},
year = {2020}
}

@misc{iRobot2023,
author = {iRobot},
howpublished = {\url{https://edu.irobot.com/}, accessed: Feb-11-2025.},
title = {{Root{\texttrademark} Coding Robots}},
year = {2023}
}
@inproceedings{Rovables2016,
abstract = {We introduce Rovables, a miniature r on unmodified clothing. The robots netic wheels, and can climb vertic tethered and have an onboard batte wireless communications. They also calization system that uses wheel enc Rovables to perform limited autono body. In the technical evaluations, can operate continuously for 45 min 1.5N. We propose an interaction sp devices spanning sensing, actuation velop application scenarios in that include on-body sensing, modular d and interactive clothing and jewelry.},
address = {New York, NY, USA},
author = {Dementyev, Artem and Kao, Hsin-Liu (Cindy) and Choi, Inrak and Ajilo, Deborah and Xu, Maggie and Paradiso, Joseph A. and Schmandt, Chris and Follmer, Sean},
booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
doi = {10.1145/2984511.2984531},
file = {:Users/hanc/Downloads/papers/Rovables-Miniature-On-Body-Robots-as-Mobile-Wearables.pdf:pdf},
isbn = {9781450341899},
keywords = {Mobile wearable technology,On-body robotics},
month = {oct},
pages = {111--120},
publisher = {ACM},
title = {{Rovables: Miniature On-Body Robots as Mobile Wearables}},
url = {https://dl.acm.org/doi/10.1145/2984511.2984531},
year = {2016}
}
@inproceedings{ShapeBots2019,
abstract = {We introduce shape-changing swarm robots. A swarm of self-transformable robots can both individually and collectively change their configuration to display information, actuate objects, act as tangible controllers, visualize data, and provide physical affordances. ShapeBots is a concept prototype of shape-changing swarm robots. Each robot can change its shape by leveraging small linear actuators that are thin (2.5 cm) and highly extendable (up to 20cm) in both horizontal and vertical directions. The modular design of each actuator enables various shapes and geometries of self-transformation. We illustrate potential application scenarios and discuss how this type of interface opens up possibilities for the future of ubiquitous and distributed shape-changing interfaces.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {1909.03372},
author = {Suzuki, Ryo and Zheng, Clement and Kakehi, Yasuaki and Yeh, Tom and Do, Ellen Yi-Luen and Gross, Mark D. and Leithinger, Daniel},
booktitle = {Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/3332165.3347911},
eprint = {1909.03372},
file = {:Users/hanc/Library/Application Support/Mendeley Desktop/Downloaded/Suzuki et al. - 2019 - ShapeBots Shape-changing Swarm Robots.pdf:pdf},
isbn = {9781450368162},
month = {oct},
pages = {493--505},
publisher = {ACM},
title = {{ShapeBots: Shape-changing Swarm Robots}},
url = {http://arxiv.org/abs/1909.03372 http://dx.doi.org/10.1145/3332165.3347911 http://dl.acm.org/citation.cfm?doid=3332165.3347911 https://dl.acm.org/doi/10.1145/3332165.3347911},
year = {2019}
}
@inproceedings{Pinciroli2018,
author = {Pinciroli, Carlo and Talamali, Mohamed S. and Reina, Andreagiovanni and Marshall, James A. R. and Trianni, Vito},
booktitle = {International Conference on Swarm Itelligence},
doi = {10.1007/978-3-030-00533-7_14},
file = {:Users/hanc/Downloads/papers/978-3-030-00533-7.pdf:pdf},
isbn = {9783030005320},
issn = {16113349},
pages = {176--187},
title = {{Simulating Kilobots Within ARGoS: Models and Experimental Validation}},
url = {http://link.springer.com/10.1007/978-3-030-00533-7_14},
volume = {11172 LNCS},
year = {2018}
}
@inproceedings{Kaimoto2022,
abstract = {This paper introduces Sketched Reality, an approach that combines AR sketching and actuated tangible user interfaces (TUI) for bi-directional sketching interaction. Bi-directional sketching enables virtual sketches and physical objects to "affect"each other through physical actuation and digital computation. In the existing AR sketching, the relationship between virtual and physical worlds is only one-directional - while physical interaction can affect virtual sketches, virtual sketches have no return effect on the physical objects or environment. In contrast, bi-directional sketching interaction allows the seamless coupling between sketches and actuated TUIs. In this paper, we employ tabletop-size small robots (Sony Toio) and an iPad-based AR sketching tool to demonstrate the concept. In our system, virtual sketches drawn and simulated on an iPad (e.g., lines, walls, pendulums, and springs) can move, actuate, collide, and constrain physical Toio robots, as if virtual sketches and the physical objects exist in the same space through seamless coupling between AR and robot motion. This paper contributes a set of novel interactions and a design space of bi-directional AR sketching. We demonstrate a series of potential applications, such as tangible physics education, explorable mechanism, tangible gaming for children, and in-situ robot programming via sketching.},
author = {Kaimoto, Hiroki and Monteiro, Kyzyl and Faridan, Mehrad and Li, Jiatong and Farajian, Samin and Kakehi, Yasuaki and Nakagaki, Ken and Suzuki, Ryo},
booktitle = {UIST 2022 - Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/3526113.3545626},
file = {:Users/hanc/Downloads/papers/3526113.3545626.pdf:pdf},
isbn = {9781450393201},
keywords = {actuated tangible interfaces,augmented reality,mixed reality,swarm user interfaces},
title = {{Sketched Reality: Sketching Bi-Directional Interactions Between Virtual and Physical Worlds with AR and Actuated Tangible UI}},
year = {2022}
}
@article{Kim2008,
author = {{Sangbae Kim} and Spenko, Matt and Trujillo, Salomon and Heyneman, Barrett and Santos, Dan and Cutkosky, M.R.},
doi = {10.1109/TRO.2007.909786},
file = {:Users/hanc/Downloads/papers/Smooth_Vertical_Surface_Climbing_With_Directional_Adhesion.pdf:pdf},
issn = {1552-3098},
journal = {IEEE Transactions on Robotics},
month = {feb},
number = {1},
pages = {65--74},
title = {{Smooth Vertical Surface Climbing With Directional Adhesion}},
url = {http://www.crossref.org/deleted_DOI.html},
volume = {24},
year = {2008}
}
@article{Brambilla2013,
abstract = {Swarm robotics is an approach to collective robotics that takes inspiration from the self-organized behaviors of social animals. Through simple rules and local interactions, swarm robotics aims at designing robust, scalable, and flexible collective behaviors for the coordination of large numbers of robots. In this paper, we analyze the literature from the point of view of swarm engineering: we focus mainly on ideas and concepts that contribute to the advancement of swarm robotics as an engineering field and that could be relevant to tackle real-world applications. Swarm engineering is an emerging discipline that aims at defining systematic and well founded procedures for modeling, designing, realizing, verifying, validating, operating, and maintaining a swarm robotics system. We propose two taxonomies: in the first taxonomy, we classify works that deal with design and analysis methods; in the second taxonomy, we classify works according to the collective behavior studied. We conclude with a discussion of the current limits of swarm robotics as an engineering discipline and with suggestions for future research directions. {\textcopyright} 2013 Springer Science+Business Media New York.},
author = {Brambilla, Manuele and Ferrante, Eliseo and Birattari, Mauro and Dorigo, Marco},
doi = {10.1007/s11721-012-0075-2},
file = {:Users/hanc/Downloads/papers/s11721-012-0075-2.pdf:pdf},
issn = {1935-3812},
journal = {Swarm Intelligence},
keywords = {Review,Swarm engineering,Swarm robotics},
month = {mar},
number = {1},
pages = {1--41},
title = {{Swarm robotics: a review from the swarm engineering perspective}},
url = {http://link.springer.com/10.1007/s11721-012-0075-2},
volume = {7},
year = {2013}
}
@article{Dorigo2021,
author = {Dorigo, Marco and Theraulaz, Guy and Trianni, Vito},
doi = {10.1109/JPROC.2021.3072740},
file = {:Users/hanc/Downloads/papers/Swarm_Robotics_Past_Present_and_Future_Point_of_View.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
month = {jul},
number = {7},
pages = {1152--1165},
publisher = {IEEE},
title = {{Swarm Robotics: Past, Present, and Future}},
url = {https://ieeexplore.ieee.org/document/9460560/},
volume = {109},
year = {2021}
}
@inproceedings{SwarmHaptics2019,
abstract = {This paper seeks to better understand the use of haptic feedback in abstract, ubiquitous robotic interfaces. We introduce and provide preliminary evaluations of SwarmHaptics, a new type of haptic display using a swarm of small, wheeled robots. These robots move on a fat surface and apply haptic patterns to the user's hand, arm, or any other accessible body parts. We explore the design space of SwarmHaptics including individual and collective robot parameters, and demonstrate example scenarios including remote social touch using the Zooids platform. To gain insights into human perception, we applied haptic patterns with varying number of robots, force type, frequency, and amplitude and obtained user's perception in terms of emotion, urgency, and Human-Robot Interaction metrics. In a separate elicitation study, users generated a set of haptic patterns for social touch. The results from the two studies help inform how users perceive and generate haptic patterns with SwarmHaptics.},
address = {New York, NY, USA},
author = {Kim, Lawrence H. and Follmer, Sean},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3290605.3300918},
file = {:Users/hanc/Downloads/papers/SwarmHaptics.pdf:pdf},
isbn = {9781450359702},
keywords = {Haptics,Human-robot interaction,Swarm haptics,Swarm user interface,Ubiquitous robotic interfaces},
month = {may},
pages = {1--13},
publisher = {ACM},
title = {{SwarmHaptics: Haptic Display with Swarm Robots}},
url = {https://dl.acm.org/doi/10.1145/3290605.3300918},
year = {2019}
}
@inproceedings{tangible_bots2011,
abstract = {We present interaction techniques for tangible tabletop interfaces that use active, motorized tangibles, what we call Tangible Bots. Tangible Bots can reflect changes in the digital model and assist users by haptic feedback, by correcting errors, by multi-touch control, and by allowing efficient interaction with multiple tangibles. A first study shows that Tangible Bots are usable for fine-grained manipulation (e.g., rotating tangibles to a particular orientation); for coarse movements, Tangible Bots become useful only when several tangibles are controlled simultaneously. Participants prefer Tangible Bots and find them less taxing than passive, non-motorized tangibles. A second study focuses on usefulness by studying how electronic musicians use Tangible Bots to create music with a tangible tabletop application. We conclude by discussing the further potential of active tangibles, and their relative benefits over passive tangibles and multi-touch. Copyright 2011 ACM.},
address = {New York, NY, USA},
author = {Pedersen, Esben Warming and Hornb{\ae}k, Kasper},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
doi = {10.1145/1978942.1979384},
file = {:Users/hanc/Downloads/papers/1978942.1979384.pdf:pdf},
isbn = {9781450302289},
keywords = {Active tangibles,Bidirectional interfaces,Tangible user interfaces,User evaluation},
month = {may},
pages = {2975--2984},
publisher = {ACM},
title = {{Tangible Bots: Interaction with Active Tangibles in Tabletop Interfaces}},
url = {https://dl.acm.org/doi/10.1145/1978942.1979384},
year = {2011}
}
@inproceedings{Yan2021,
abstract = {This paper presents our vision of on-the-wall tangible interaction. We envision a future where tangible interaction can be extended from conventional horizontal surfaces to vertical surfaces; indoor vertical areas such as walls, windows, and ceilings can be used for dynamic and direct physical manipulation. We first discuss the unique properties that vertical surfaces may offer for tangible interaction and the interaction scenarios they imbue. We then propose two potential paths for realizing on-the-wall interaction and the technical challenges we face. We follow with one prototype called Climbot. We showcase how Climbot can be used as an on-the-wall tangible user interface for dynamic lighting and as a wall switch controller. We conclude with a discussion of future work.},
address = {New York, NY, USA},
author = {Yan, Zeyu and Sathya, Anup and Carvalho, Pedro and Hu, Yongquan and Li, Annan and Peng, Huaishu},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3411763.3451586},
file = {:Users/hanc/Downloads/papers/3411763.3451586.pdf:pdf},
isbn = {9781450380959},
keywords = {Climbing Robot,Robotics,Tangible Interaction,Tangible User Interface,Wall,Wall Interaction},
month = {may},
pages = {1--6},
publisher = {ACM},
title = {{Towards On-the-wall Tangible Interaction: Using Walls as Interactive, Dynamic, and Responsive User Interface}},
url = {https://dl.acm.org/doi/10.1145/3411763.3451586},
year = {2021}
}
@misc{toio,
author = {Sony Interactive Entertainment},
howpublished = {\url{https://www.sony.com/en/SonyInfo/design/stories/toio/}, accessed: Feb-11-2025.},
title = {Toy Platform toio\texttrademark},
year = {2018}
}
@article{UbiSwarm2017,
abstract = {As robots increasingly enter our everyday life, we envision a future in which robots are ubiquitous and interact with both ourselves and our environments. This paper introduces the concept of ubiquitous robotic interfaces (URIs), multi-robot interfaces capable of mobility, manipulation, sensing, display and interaction. URIs interact directly with the user and indirectly through surrounding objects. A key aspect of URIs is their ability to display information to users either by collectively forming shapes or through their movements. In this paper, we focus on the use of URIs to display information in ubiquitous settings. We first investigate the use of abstract motion as a display for URIs by studying human perception of abstract multi-robot motion. With ten small robots, we produced 42 videos of bio-inspired abstract motion by varying three parameters (7 x 2 x 3): bio-inspired behavior, speed and smoothness. In a crowdsourced between-subjects study, 1067 subjects were recruited to watch the videos and describe their perception through Likert scales and free text. Study results suggest that different bio-inspired behaviors elicit significantly different responses in arousal, dominance, hedonic and pragmatic qualities, animacy, urgency and willingness to attend. On the other hand, speed significantly affects valence, arousal, hedonic quality, urgency and animacy while smoothness affects hedonic quality, animacy, attractivity and likeability. We discuss how these results inform URI designers to formulate appropriate motion for different interaction scenarios and use these results to derive our own example applications using our URI platform, UbiSwarm.},
author = {Kim, Lawrence H and Follmer, Sean},
doi = {10.1145/3130931},
file = {:Users/hanc/Downloads/papers/3130931.pdf:pdf},
issn = {2474-9567},
journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
keywords = {Human Perception,Human-Swarm Interaction,Swarm Robotics,Ubiquitous Robotics},
month = {sep},
number = {3},
pages = {1--20},
title = {{UbiSwarm: Ubiquitous Robotic Interfaces and Investigation of Abstract Motion as a Display}},
url = {https://dl.acm.org/doi/10.1145/3130931},
volume = {1},
year = {2017}
}
@article{Kim2020,
abstract = {A swarm of robots can accomplish more than the sum of its parts, and swarm systems will soon see increased use in applications ranging from tangible interfaces to search and rescue teams. However, effective human control of robot swarms has been shown to be demonstrably more difficult than controlling a single robot, and swarm-specific interactions methodologies are relatively underexplored. As we envision even non-expert users will have more daily in-person encounters with different numbers of robots in the future, we present a user-defined set of control interactions for tabletop swarm robots derived from an elicitation study. We investigated the effects of number of robots and proximity on the user's interaction and found significant effects. For instance, participants varied between using 1-2 fingers, one hand, and both hands depending on the group size. We also provide general design guidelines such as preferred interaction modality, common strategies, and a high-agreement interaction set.},
author = {Kim, Lawrence H. and Drew, Daniel S. and Domova, Veronika and Follmer, Sean},
doi = {10.1145/3313831.3376814},
file = {:Users/hanc/Downloads/papers/SwarmControl.pdf:pdf},
isbn = {9781450367080},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {elicitation study,multi-robot control,swarm robot control,swarm robotics,swarm user interface},
pages = {1--13},
title = {{User-defined Swarm Robot Control}},
year = {2020}
}
@article{Waalbot2007,
abstract = {This paper proposes a small-scale agile wall-climbing robot, which is able to climb on smooth vertical surfaces using flat adhesive elastomer materials for attachment. Using two actuated legs with rotary motion and two passive revolute joints at each foot, this robot can climb and steer in any orientation. Due to its compact design, a high degree of miniaturization is possible. It has onboard power, computing, and wireless communication, which allow for semiautonomous operation. Various aspects of a functioning prototype design and performance are discussed in detail, including leg and foot design and gait dynamics. A model for the adhesion requirements and performance is developed and verified through experiments. Using an adhesive elastomer (Vytaflex 10), the current prototype can climb 90° slopes at a speed of up to 6 cm/ s and steer to any angle reliably on a smooth acrylic surface as well as transition from floor walking to wall climbing. This robot is intended for inspection and surveillance applications, and ultimately, for space missions. {\textcopyright} 2007 IEEE.},
author = {Murphy, Michael P. and Sitti, Metin},
doi = {10.1109/TMECH.2007.897277},
file = {:Users/hanc/Downloads/papers/Waalbot_An_Agile_Small-Scale_Wall-Climbing_Robot_Utilizing_Dry_Elastomer_Adhesives.pdf:pdf},
issn = {1083-4435},
journal = {IEEE/ASME Transactions on Mechatronics},
keywords = {Dry adhesives,Mechatronics,Miniature robotics,Mobile robotics,Wall climbing},
month = {jun},
number = {3},
pages = {330--338},
title = {{Waalbot: An Agile Small-Scale Wall-Climbing Robot Utilizing Dry Elastomer Adhesives}},
url = {http://ieeexplore.ieee.org/document/4244394/},
volume = {12},
year = {2007}
}
@inproceedings{Onishi,
address = {New York, NY, USA},
author = {Onishi, Yuki and Takashima, Kazuki and Higashiyama, Shoi and Fujita, Kazuyuki and Kitamura, Yoshifumi},
booktitle = {The 35th Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/3526113.3545615},
file = {:Users/hanc/Downloads/papers/3526113.3545615.pdf:pdf},
isbn = {9781450393201},
keywords = {Robotic Furn,Shape-Changing Device,Spatial Input,acm reference format,and yoshi-,kazuki takashima,kazuyuki fujita,robotic furniture,shape-changing device,shoi higashiyama,spatial input,yuki onishi},
month = {oct},
number = {1},
pages = {1--15},
publisher = {ACM},
title = {{WaddleWalls: Room-scale Interactive Partitioning System using a Swarm of Robotic Partitions}},
url = {https://dl.acm.org/doi/10.1145/3526113.3545615},
volume = {1},
year = {2022}
}
@article{
Wu2022,
author = {Yingdan Wu  and Xiaoguang Dong  and Jae-kang Kim  and Chunxiang Wang  and Metin Sitti },
title = {Wireless soft millirobots for climbing three-dimensional surfaces in confined spaces},
journal = {Science Advances},
volume = {8},
number = {21},
pages = {eabn3431},
year = {2022},
doi = {10.1126/sciadv.abn3431},
URL = {https://www.science.org/doi/abs/10.1126/sciadv.abn3431},
eprint = {https://www.science.org/doi/pdf/10.1126/sciadv.abn3431},
abstract = {Wireless soft-bodied robots at the millimeter scale allow traversing very confined unstructured terrains with minimal invasion and safely interacting with the surrounding environment. However, existing untethered soft millirobots still lack the ability of climbing, reversible controlled surface adhesion, and long-term retention on unstructured three-dimensional (3D) surfaces, limiting their use in biomedical and environmental applications. Here, we report a fundamental peeling-and-loading mechanism to allow untethered soft-bodied robots to climb 3D surfaces by using both the soft-body deformation and whole-body motion of the robot under external magnetic fields. This generic mechanism is implemented with different adhesive robot footpad designs, allowing vertical and inverted surface climbing on diverse 3D surfaces with complex geometries and different surface properties. With the unique robot footpad designs that integrate microstructured adhesives and tough bioadhesives, the soft climbing robot could achieve controllable adhesion and friction to climb 3D soft and wet surfaces including porcine tissues, which paves the way for future environmental inspection and minimally invasive medicine applications. Wireless millimeter-scale soft climbing robots can traverse complex 3D tissue surfaces in enclosed and confined spaces.}
}
@inproceedings{Zooids2016,
address = {New York, NY, USA},
author = {{Le Goc}, Mathieu and Kim, Lawrence H. and Parsaei, Ali and Fekete, Jean-Daniel and Dragicevic, Pierre and Follmer, Sean},
booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
doi = {10.1145/2984511.2984547},
file = {:Users/hanc/Library/Application Support/Mendeley Desktop/Downloaded/Le Goc et al. - 2016 - Zooids Building Blocks for Swarm User Interfaces.pdf:pdf},
isbn = {9781450341899},
month = {oct},
pages = {97--109},
publisher = {ACM},
title = {{Zooids: Building Blocks for Swarm User Interfaces}},
url = {http://dl.acm.org/citation.cfm?doid=2984511.2984547 https://dl.acm.org/doi/10.1145/2984511.2984547},
year = {2016}
}

@inproceedings{STRAIDE2022,
  address   = {New York, NY, USA},
  author    = {Engert, Severin and Klamka, Konstantin and Peetz, Andreas and Dachselt, Raimund},
  booktitle = {CHI Conference on Human Factors in Computing Systems},
  doi       = {10.1145/3491102.3517462},
  file      = {:Users/hanc/Downloads/papers/3491102.3517462.pdf:pdf},
  isbn      = {9781450391573},
  keywords  = {Prototyping Platform,Shape-Chang,Spatial Display,acm reference format,casual visualization,data physicalization,prototyping platform,shape-changing interface,spatial display,tangible interaction},
  month     = {apr},
  pages     = {1--16},
  publisher = {ACM},
  title     = {{STRAIDE: A Research Platform for Shape-Changing Spatial Displays based on Actuated Strings}},
  url       = {10.1145/3491102.3517462 https://dl.acm.org/doi/10.1145/3491102.3517462},
  year      = {2022}
}

@article{Stickybot2008,
abstract = {Stickybot is a bioinspired robot that climbs smooth vertical surfaces such as glass, plastic, and ceramic tile at 4 cm/s. The robot employs several design principles adapted from the gecko including a hierarchy of compliant structures, directional adhesion, and control of tangential contact forces to achieve control of adhesion. We describe the design and fabrication methods used to create underactuated, multimaterial structures that conform to surfaces over a range of length scales from centimeters to micrometers. At the finest scale, the undersides of Stickybot's toes are covered with arrays of small, angled polymer stalks. Like the directional adhesive structures used by geckos, they readily adhere when pulled tangentially from the tips of the toes toward the ankles; when pulled in the opposite direction, they release. Working in combination with the compliant structures and directional adhesion is a force control strategy that balances forces among the feet and promotes smooth attachment and detachment of the toes. {\textcopyright} 2008 IEEE.},
author = {{Sangbae Kim} and Spenko, Matthew and Trujillo, Salomon and Heyneman, Barrett and Santos, Daniel and Cutkosky, M.R.},
doi = {10.1109/TRO.2007.909786},
file = {:Users/hanc/Downloads/papers/Smooth Vertical Surface Climbing with Directional Adhesion.pdf:pdf},
issn = {1552-3098},
journal = {IEEE Transactions on Robotics},
keywords = {Bioinspired,Climbing robot,Dry adhesive,Geckoinspired,Legged robot,Mobile robot under-actuated},
month = {feb},
number = {1},
pages = {65--74},
title = {{Smooth Vertical Surface Climbing With Directional Adhesion}},
url = {http://www.crossref.org/deleted_DOI.html},
volume = {24},
year = {2008}
}
@article{HawkesGeckoHuman2015,
abstract = {Since the discovery of the mechanism of adhesion in geckos, many synthetic dry adhesives have been developed with desirable gecko-like properties such as reusability, directionality, self-cleaning ability, rough surface adhesion and high adhesive stress. However, fully exploiting these adhesives in practical applications at different length scales requires efficient scaling (i.e. with little loss in adhesion as area grows). Just as natural gecko adhesives have been used as a benchmark for synthetic materials, so can gecko adhesion systems provide a baseline for scaling efficiency. In the tokay gecko ( Gekko gecko ), a scaling power law has been reported relating the maximum shear stress $\sigma$ max to the area A : $\sigma$ max ∝ A −1/4 . We present a mechanical concept which improves upon the gecko's non-uniform load-sharing and results in a nearly even load distribution over multiple patches of gecko-inspired adhesive. We created a synthetic adhesion system incorporating this concept which shows efficient scaling across four orders of magnitude of area, yielding an improved scaling power law: $\sigma$ max ∝ A −1/50 . Furthermore, we found that the synthetic adhesion system does not fail catastrophically when a simulated failure is induced on a portion of the adhesive. In a practical demonstration, the synthetic adhesion system enabled a 70 kg human to climb vertical glass with 140 cm 2 of adhesive per hand.},
author = {Hawkes, Elliot W. and Eason, Eric V. and Christensen, David L. and Cutkosky, Mark R.},
doi = {10.1098/rsif.2014.0675},
file = {:Users/hanc/Downloads/papers/rsif.2014.0675.pdf:pdf},
issn = {1742-5689},
journal = {Journal of The Royal Society Interface},
keywords = {Adhesion,Bioinspiration,Climbing,Gecko,Scaling},
month = {jan},
number = {102},
pages = {20140675},
pmid = {25411404},
title = {{Human climbing with efficiently scaled gecko-inspired dry adhesives}},
url = {https://royalsocietypublishing.org/doi/10.1098/rsif.2014.0675},
volume = {12},
year = {2015}
}
@inproceedings{PhysicaDIS2023,
address = {New York, NY, USA},
author = {Li, Jiatong and Suzuki, Ryo and Nakagaki, Ken},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
doi = {10.1145/3563657.3596037},
file = {:Users/hanc/Downloads/papers/3563657.3596037.pdf:pdf},
isbn = {9781450398930},
keywords = {2023,acm reference format,actuated tangible uis,and ken nakagaki,interactive tangible,jiatong li,physica,physics simulation,ryo suzuki,swarm uis},
month = {jul},
pages = {1485--1499},
publisher = {ACM},
title = {{Physica: Interactive Tangible Physics Simulation based on Tabletop Mobile Robots Towards Explorable Physics Education}},
url = {https://dl.acm.org/doi/10.1145/3563657.3596037},
year = {2023}
}
@inproceedings{AeroRigUI_CHI2023,
address = {New York, NY, USA},
author = {Yu, Lilith and Gao, Chenfeng and Wu, David and Nakagaki, Ken},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3544548.3581437},
file = {:Users/hanc/Downloads/papers/3544548.3581437.pdf:pdf},
isbn = {9781450394215},
keywords = {acm reference format,actuated tangible user interface,human robot interaction,spatial user interface display},
month = {apr},
pages = {1--18},
publisher = {ACM},
title = {{AeroRigUI: Actuated TUIs for Spatial Interaction using Rigging Swarm Robots on Ceilings in Everyday Space}},
url = {https://dl.acm.org/doi/10.1145/3544548.3581437},
year = {2023}
}
@article{ArmyAntBridge2015,
abstract = {Complex systems, from ant colonies to stock markets, share a common property: sophisticated group-level structure emerges from simple individual-level behaviors. Using simple interaction rules, Eciton army ants construct complex bridges from their own bodies to span forest-floor gaps. These living bridges are uniquely complex in both their dynamic properties and the number of animals involved and so are of considerable interest for understanding emergent structures in complex systems. In field experiments, we show that construction interacts with traffic rate and environmental geometry, causing bridges to lengthen, widen, and migrate. Bridges provide a shortcut for foraging ants, at the cost of sequestering workers. We show that bridge location represents a cost–benefit trade-off, with potential implications for human engineered self-assembling systems.},
author = {Reid, Chris R and Lutz, Matthew J and Powell, Scott and Kao, Albert B and Couzin, Iain D and Garnier, Simon},
doi = {10.1073/pnas.1512241112},
file = {:Users/hanc/Downloads/papers/pnas.1512241112.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
month = {dec},
number = {49},
pages = {15113--15118},
title = {{Army ants dynamically adjust living bridges in response to a cost–benefit trade-off}},
url = {https://pnas.org/doi/full/10.1073/pnas.1512241112},
volume = {112},
year = {2015}
}
@article{AutonomousSelfAssemblySwarm2006,
author = {Gross, Roderich and Bonani, Michael and Mondada, Francesco and Dorigo, Marco},
doi = {10.1109/TRO.2006.882919},
file = {:Users/hanc/Downloads/papers/Autonomous_Self-Assembly_in_Swarm-Bots.pdf:pdf},
issn = {1552-3098},
journal = {IEEE Transactions on Robotics},
month = {dec},
number = {6},
pages = {1115--1130},
title = {{Autonomous Self-Assembly in Swarm-Bots}},
url = {http://ieeexplore.ieee.org/document/4020359/},
volume = {22},
year = {2006}
}
@article{Yasemin2021,
abstract = {Multilegged swarm robots with self-reconfigurability can perform diverse tasks in variable terrain.},
author = {Ozkan-Aydin, Yasemin and Goldman, Daniel I},
doi = {10.1126/scirobotics.abf1628},
file = {:Users/hanc/Downloads/papers/scirobotics.abf1628.pdf:pdf},
issn = {2470-9476},
journal = {Science Robotics},
month = {jul},
number = {56},
pages = {1--13},
title = {{Self-reconfigurable multilegged robot swarms collectively accomplish challenging terradynamic tasks}},
url = {https://www.science.org/doi/10.1126/scirobotics.abf1628},
volume = {6},
year = {2021}
}
@inproceedings{ThrowIO_CHI2023,
abstract = {We introduce ThrowIO, a novel style of actuated tangible user interface that facilitates throwing and catching spatial interaction powered by mobile wheeled robots on overhanging surfaces. In our approach, users throw and stick objects that are embedded with magnets to an overhanging ferromagnetic surface where wheeled robots can move and drop them at desired locations, allowing users to catch them. The thrown objects are tracked with an RGBD camera system to perform closed-loop robotic manipulations. By computationally facilitating throwing and catching interaction, our approach can be applied in many applications including kinesthetic learning, gaming, immersive haptic experience, ceiling storage, and communication. We demonstrate the applications with a proof-of-concept system enabled by wheeled robots, ceiling hardware design, and software control. Overall, ThrowIO opens up novel spatial, dynamic, and tangible interaction for users via overhanging robots, which has great potential to be integrated into our everyday space.},
address = {New York, NY, USA},
author = {Lin, Ting-Han and Yang, Willa Yunqi and Nakagaki, Ken},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3544548.3581267},
isbn = {9781450394215},
keywords = {Actuated Tangible User Interface,Human-Computer Interaction,Human-Robot Interaction,Spatial Interaction,Swarm User Interface},
month = {apr},
pages = {1--17},
publisher = {ACM},
title = {{ThrowIO: Actuated TUIs that Facilitate “Throwing and Catching” Spatial Interaction with Overhanging Mobile Wheeled Robots}},
url = {https://dl.acm.org/doi/10.1145/3544548.3581267},
year = {2023}
}
@inproceedings{suctioncup2010,
  author={Yoshida, Yu and Ma, Shugen},
  booktitle={2010 IEEE International Conference on Robotics and Biomimetics}, 
  title={Design of a wall-climbing robot with passive suction cups}, 
  year={2010},
  volume={},
  number={},
publisher = {IEEE},
  pages={1513-1518},
  doi={10.1109/ROBIO.2010.5723554}
}

@misc{Vertigo2015,
author = {Beardsley, Paul and Siegwart, Roland and Arigoni, Michael and Bischoff, Michael and Fuhrer, SIlvan and Krummenacher, David and Mammolo, Dario and Simpson, Robert},
title = {{VertiGo - a Wall-Climbing Robot including Ground-Wall Transition}},
url = {https://la.disneyresearch.com/publication/vertigo/},
urldate = {2023-12-08},
year = {2015}
}

@article{Tripillar2011,
abstract = {Summary We present a miniature magnetic climbing robot with dimensions 96 × 46 × 64 mm3. With two degrees of freedom it is able to climb ferromagnetic surfaces and to make inner plane to plane transitions whatever their inclination is. This robot, named TRIPILLAR, combines triangular-shaped magnetic caterpillars and frame magnets. This particular configuration allows, for example, to move from ground to wall and ceiling and back. This achievement opens new avenues to use mobile robotics for industrial inspection with stringent size restrictions, such as the ones encountered in power plants. {\textcopyright} Cambridge University Press 2011.},
author = {Schoeneich, Patrick and Rochat, Frederic and Nguyen, Olivier Truong Dat and Moser, Roland and Mondada, Francesco},
doi = {10.1017/S0263574711000257},
issn = {02635747},
journal = {Robotica},
keywords = {Design,Mechatronic Systems,Mobile Robots,Service Robots,novel Applications of Robotics},
number = {7},
pages = {1075--1081},
title = {{TRIPILLAR: A miniature magnetic caterpillar climbing robot with plane transition ability}},
volume = {29},
year = {2011}
}

@article{R-Track2021,
abstract = {This letter presents the development of a reconfigurable wall-climbing robot (WCR) called R-track. R-Track is designed for operations inside metal structures. It adheres to the metal surface with magnetic tracks. With a modular design which each module of R-Track can be connected or disconnected without an additional actuator, R-Track can perform various wall-to-wall transitions. In particular, external wall transitions that have been difficult for previous WCRs can be achieved by R-track with a cooperation between modules. The statics of R-Track during wall transitions was analyzed to identify and verify an appropriate reconfiguration strategy. Experiments on wall-to-wall transitions were conducted to demonstrate the performance of R-Track. The results indicate that R-Track successfully performed all kinds of perpendicular wall-to-wall transitions.},
author = {Park, Changmin and Bae, Jangho and Ryu, Sijun and Lee, Jiseok and Seo, Taewon},
doi = {10.1109/LRA.2020.3015170},
issn = {23773766},
journal = {IEEE Robotics and Automation Letters},
keywords = {Cellular and modular robots,cooperating robots,mechanism design},
number = {2},
pages = {1036--1042},
title = {{R-Track: Separable Modular Climbing Robot Design for Wall-to-Wall Transition}},
volume = {6},
year = {2021}
}

@article{Calico,
author = {Sathya, Anup and Li, Jiasheng and Rahman, Tauhidur and Gao, Ge and Peng, Huaishu},
title = {Calico: Relocatable On-cloth Wearables with Fast, Reliable, and Precise Locomotion},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550323},
doi = {10.1145/3550323},
abstract = {We explore Calico, a miniature relocatable wearable system with fast and precise locomotion for on-body interaction, actuation and sensing. Calico consists of a two-wheel robot and an on-cloth track mechanism or "railway," on which the robot travels. The robot is self-contained, small in size, and has additional sensor expansion options. The track system allows the robot to move along the user's body and reach any predetermined location. It also includes rotational switches to enable complex routing options when diverging tracks are presented. We report the design and implementation of Calico with a series of technical evaluations for system performance. We then present a few application scenarios, and user studies to understand the potential of Calico as a dance trainer and also explore the qualitative perception of our scenarios to inform future research in this space.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {sep},
articleno = {136},
numpages = {32},
keywords = {interactive computing, kinetic wearables, mobile computing, ubiquitous computing, wearables}
}

@article{EpidermalRobots,
author = {Dementyev, Artem and Hernandez, Javier and Choi, Inrak and Follmer, Sean and Paradiso, Joseph},
title = {Epidermal Robots: Wearable Sensors That Climb on the Skin},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3264912},
doi = {10.1145/3264912},
abstract = {Epidermal sensing has enabled significant advancements towards the measurement and understanding of health. Most of the existing medical instruments require direct expert manipulation of a doctor, measure a single parameter, and/or have limited sensing coverage. In contrast, this work demonstrates the first epidermal robot with the ability to move over the surface of the skin and capture a large range of body parameters. In particular, we developed SkinBot, a 2x4x2 centimeter-size robot that moves over the skin surface with a two-legged suction-based locomotion. We demonstrate three of the potential medical sensing applications which include the measurement of body biopotentials (e.g., electrodermal activity, electrocardiography) through modified suction cups that serve as electrodes, skin imaging through a skin-facing camera that can capture skin anomalies, and inertial body motions through a 6-axis accelerometer and gyroscope that can capture changes of body posture and subtle cardiorespiratory vibrations.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {sep},
articleno = {102},
numpages = {22},
keywords = {skin, sensors, robotics, health, epidermal robots, Wearable}
}

@inproceedings{corobos_UIST,
author = {Han, Changyo and Nakagawa, Yosuke and Naemura, Takeshi},
title = {Demonstrating Swarm Robots Capable of Cooperative Transitioning between Table and Wall},
year = {2023},
isbn = {9798400700965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586182.3615763},
doi = {10.1145/3586182.3615763},
abstract = {Swarm User Interfaces&nbsp;(Swarm UIs) enable manipulation of user environment through the dynamic arrangement of small robots. However, the operation range of Swarm UIs are limited to a single plane due to their locomotion constraints, which are typically two-wheel-propelled. Here, We present a proof-of-concept design for swarm robots, which enables them to cooperatively transition between horizontal and vertical surfaces. Notably, this design requires only passive mechanical structure and does not rely on any powered electrical components. We demonstrate several application examples to showcase the feasibility of the robots.},
booktitle = {Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {71},
numpages = {4},
keywords = {swarm user interfaces, human robot interaction},
location = {<conf-loc>, <city>San Francisco</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
series = {UIST '23 Adjunct}
}

@inproceedings{Ishii1997,
	address = {New York, New York, USA},
	title = {Tangible {Bits}: {Towards} {Seamless} {Interfaces} between {People}, {Bits} and {Atoms}},
	isbn = {0-89791-802-9},
	url = {http://portal.acm.org/citation.cfm?doid=258549.258715},
	doi = {10.1145/258549.258715},
	urldate = {2019-03-28},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems - {CHI} '97},
	publisher = {ACM Press},
	author = {Ishii, Hiroshi and Ullmer, Brygg},
	year = {1997},
	pages = {234--241},
	file = {PDF:/Users/hanc/Zotero/storage/J2QB77FG/full-text.pdf:application/pdf},
}

@article{ishii_radical_2012,
	title = {Radical {Atoms}: {Beyond} {Tangible} {Bits}, {Toward} {Transformable} {Materials}},
	volume = {19},
	issn = {1072-5520},
	url = {https://dl.acm.org/doi/10.1145/2065327.2065337},
	doi = {10.1145/2065327.2065337},
	abstract = {Graphical user interfaces (GUIs) let users see digital information only through a screen, as if looking into a pool of water, as depicted in Figure 1 on page 40. We interact with the forms below through remote controls, such as a mouse, a keyboard, or a touchscreen (Figure 1a). Now imagine an iceberg, a mass of ice that penetrates the surface of the water and provides a handle for the mass beneath. This metaphor describes tangible user interfaces: They act as physical manifestations of computation, allowing us to interact directly with the portion that is made tangible—the “tip of the iceberg” (Figure 1b). Radical Atoms takes a leap beyond tangible interfaces by assuming a hypothetical generation of materials that can change form and appearance dynamically, so they are as reconfigurable as pixels on a screen. Radical Atoms is a vision for the future of human-material interactions, in which all digital information has physical manifestation so that we can interact directly with it—as if the iceberg had risen from the depths to reveal its sunken mass (Figure 1c).},
	number = {1},
	journal = {Interactions},
	author = {Ishii, Hiroshi and Lakatos, Dávid and Bonanni, Leonardo and Labrune, Jean-Baptiste},
	month = jan,
	year = {2012},
	pages = {38--51},
	file = {PDF:/Users/hanc/Zotero/storage/3KXM6D9X/2065327.2065337.pdf:application/pdf},
}


@book{Dourish2001_where,
    author = {Dourish, Paul},
    title = {Where the Action Is: The Foundations of Embodied Interaction},
    publisher = {The MIT Press},
    year = {2001},
    month = {09},
    abstract = {Computer science as an engineering discipline has been spectacularly successful. Yet it is also a philosophical enterprise in the way it represents the world and creates and manipulates models of reality, people, and action. In this book, Paul Dourish addresses the philosophical bases of human-computer interaction. He looks at how what he calls "embodied interaction"—an approach to interacting with software systems that emphasizes skilled, engaged practice rather than disembodied rationality—reflects the phenomenological approaches of Martin Heidegger, Ludwig Wittgenstein, and other twentieth-century philosophers. The phenomenological tradition emphasizes the primacy of natural practice over abstract cognition in everyday activity. Dourish shows how this perspective can shed light on the foundational underpinnings of current research on embodied interaction. He looks in particular at how tangible and social approaches to interaction are related, how they can be used to analyze and understand embodied interaction, and how they could affect the design of future interactive systems.},
    isbn = {9780262256056},
    doi = {10.7551/mitpress/7221.001.0001},
    url = {https://doi.org/10.7551/mitpress/7221.001.0001},
}
@inproceedings{SwarmBody,
author = {Ichihashi, Sosuke and Kuroki, So and Nishimura, Mai and Kasaura, Kazumi and Hiraki, Takefumi and Tanaka, Kazutoshi and Yoshida, Shigeo},
title = {Swarm Body: Embodied Swarm Robots},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642870},
doi = {10.1145/3613904.3642870},
abstract = {The human brain’s plasticity allows for the integration of artificial body parts into the human body. Leveraging this, embodied systems realize intuitive interactions with the environment. We introduce a novel concept: embodied swarm robots. Swarm robots constitute a collective of robots working in harmony to achieve a common objective, in our case, serving as functional body parts. Embodied swarm robots can dynamically alter their shape, density, and the correspondences between body parts and individual robots. We contribute an investigation of the influence on embodiment of swarm robot-specific factors derived from these characteristics, focusing on a hand. Our paper is the first to examine these factors through virtual reality (VR) and real-world robot studies to provide essential design considerations and applications of embodied swarm robots. Through quantitative and qualitative analysis, we identified a system configuration to achieve the embodiment of swarm robots.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {267},
numpages = {19},
keywords = {embodiment, swarm robotics, tangible interaction},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{Push-That-There2024,
author = {Wang, Keru and Wang, Zhu and Nakagaki, Ken and Perlin, Ken},
title = {``Push-That-There''': Tabletop Multi-robot Object Manipulation via Multimodal 'Object-level Instruction'},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661542},
doi = {10.1145/3643834.3661542},
abstract = {We present "Push-That-There", an interaction method and system enabling multimodel object-level user interaction with multi-robot system to autonomously and collectively manipulate objects on tabletop surfaces, inspired by "Put-That-There". Rather than requiring users to instruct individual robots, users directly specify how they want the objects to be moved, and the system responds by autonomously moving objects via our generalizable multi-robot control algorithm. The system is combined with various user instruction modalities, including gestures, GUI, tangible manipulation, and speech, allowing users to intuitively create object-level instruction. We outline a design space, highlight interaction design opportunities facilitated by "Push-That-There", and provide an evaluation to assess our system's technical capabilities. While other recent HCI research has studied interaction using multi-robot system (e.g. Swarm UIs), our contribution is in the design and technical implementation of intuitive object-level interaction for multi-robot system that allows users to work at a high level, rather than needing to focus on the movements of individual robots.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {2497–2513},
numpages = {17},
keywords = {Human-Robot Interaction, Multi-Robot Control, Multi-robot UI, Object-level instruction, Tangible Interface},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{ThreadingSpace2024,
author = {Bhattacharya, Ramarko and Li, You and Faracci, Emilie and Dong, Harrison and Zheng, Yi and Nakagaki, Ken},
title = {Threading Space: Kinetic Sculpture Exploring Spatial Interaction Using Threads In Motion},
year = {2024},
isbn = {9798400704857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635636.3660498},
doi = {10.1145/3635636.3660498},
abstract = {Threading Space is a kinetic sculpture that explores how spatial perception can be transformed by dynamically and geometrically reconfiguring physical lines of thread. As the threads in motion interact, they become a hypnotic medium for three-dimensional patterns. Through a physical installation and an interactive GUI, Threading Space invites the audience to explore the potential of using swarm robots and line elements to create, morph, and interact with space.},
booktitle = {Proceedings of the 16th Conference on Creativity \& Cognition},
pages = {571–575},
numpages = {5},
keywords = {Actuated Experience, Kinetic Sculpture, Swarm Robots, Thread-based Installation},
location = {Chicago, IL, USA},
series = {C\&C '24}
}

@inproceedings{FabRobotics2024,
author = {Bhattacharya, Ramarko and Lindstrom, Jonathan and Taka, Ahmad and Nisser, Martin and Mueller, Stefanie and Nakagaki, Ken},
title = {FabRobotics: Fusing 3D Printing with Mobile Robots to Advance Fabrication, Robotics, and Interaction},
year = {2024},
isbn = {9798400704024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623509.3633365},
doi = {10.1145/3623509.3633365},
abstract = {We present FabRobotics, a digital fabrication pipeline that combines traditional 3D printing with mobile robots. By integrating these two technologies, we aim to create new opportunities for 3D printers to fabricate objects quickly and efficiently, and for mobile robots to enhance their adaptability and interactivity. To explore this novel research opportunity, we have developed a proof-of-concept implementation pipeline, allowing users to execute hybrid turn-taking control of a 3D printer and mobile robots to autonomously 3D print objects on/with mobile robots. The system was implemented with commercially available 3D printers (Prusa MINI) and mobile robots (toio), and we share various techniques and knowledge specific to fusing 3D printers and mobile robots (e.g. printing mobile robot docks for stable prints on robots). Based on the proof-of-concept system, we demonstrate various application usages and functionalities, showcasing how 3D printing and mobile robots can mutually advance each other for novel fabrication and interaction. Lastly, we share our further exploration of extended prototypes (e.g. fusing two printers) and discuss future technical challenges and research opportunities.},
booktitle = {Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {17},
numpages = {13},
keywords = {Digital fabrication, Robotics, Swarm user interfaces},
location = {Cork, Ireland},
series = {TEI '24}
}

