\section*{Limitations and Future Work}

\paragraph{Cultural and Regional Nuances}
While efforts were made to capture the socio-cultural and political landscape of Kazakhstan and Russia, the complexity of their linguistic relationship presents significant challenges. Cultural norms, political sensitivities, and social contexts vary considerably across different regions, which may not be fully represented in our current dataset. Future work could focus on developing region-specific evaluation frameworks that better account for local cultural specificities and socio-political contexts, ensuring more comprehensive safety assessments of LLMs in these multilingual environments. Our code-switching evaluation, while novel, was limited to 500 questions, which may not fully capture the complexity of bilingual communications in Kazakhstan. Future work will expand the dataset using naturalistic observation methods and crowd-sourced annotations.

\paragraph{Evaluation Framework}
Our evaluation methodology, while systematic, relies heavily on \gptfouro\ as an automated judge. Although our human evaluation showed a strong correlation with \gptfouro's judgments, this approach may introduce certain biases inherent to \gptfouro's own safety mechanisms and alignment. Additionally, despite our systematic approach, the finite nature of our evaluation questions may leave certain risk categories unexplored, suggesting potential gaps in our safety analysis. For future work, we will extend the evaluation methodology to include a broader range of models and risk categories. This includes integrating additional automated evaluation tools to mitigate dependency on a single model, such as \gptfouro\, and to cross-validate results for improved robustness. We will also expand the scope of our question sets to cover a more comprehensive range of safety risks, including emergent and context-dependent issues that may not be fully addressed by the current framework.


\section*{Ethical Considerations}
We acknowledge that our dataset contains sensitive prompts specific to Russian and Kazakh contexts that could potentially be misused for prompt engineering attacks or exploitation of regional sociopolitical sensitivities. The code-switching components could particularly be vulnerable to creating culturally targeted content that bypasses content filters. Given the sensitive topics covered in the dataset, it is important to note that the annotation process was conducted by NLP and ML graduate students, all of whom provided informed consent and had the option to withdraw at any time. However, our dataset is designed to evaluate and enhance LLM safety mechanisms in multilingual contexts, with a focus on Kazakhstanâ€™s unique linguistic landscape, where Russian and Kazakh coexist. By developing robust safety evaluations for these bilingual environments, we aim to improve LLMs' ability to handle cross-cultural interactions responsibly. To foster transparency and support further research, we will publicly release our dataset. We believe that its contribution to advancing LLM safety and responsible AI development in Central Asia outweighs the potential risks of misuse.



