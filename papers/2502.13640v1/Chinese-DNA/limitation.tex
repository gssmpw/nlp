\section*{Limitations and Future Work}

\paragraph{Data Generation Strategy} In the data generation process, each original question is modified into harmful and harmless variants manually based on a limited set of pre-defined generation strategies (detailed in Section~\ref{sec:dataset}). Recently,  many prompt attack methods based on exploiting the auto-regressive nature~\citep{liu2023goaloriented, liu2023promptinjection} and instruction-following ability~\citep{li2023deepinception, yao2023fuzzllm} of LLMs have been proposed, achieving high attack success rates on both open-weight and commercial LLMs. In future work, we aim to explore more data augmentation methods and build pipelines that can automate the process of extending safety datasets for low-resource languages.

\paragraph{Evaluation Strategy} The current evaluation strategy is based on pre-defined question sets that evaluate risks in the response. In this work, we use GPT-4 to get answers to these questions for risk evaluation. This method is strongly dependent on the ability of GPT-4 to recognize the given facets of risks that each question evaluates. Hence, it is difficult to detect harmful prompts that can even successfully attack GPT-4. Besides, the current question set only covers limited aspects of potential risks for each risk type, making it hard to generalize to other risk taxonomy. For future work, we will extend the evaluation questions set and adopt prompt engineering techniques such as prompt chaining and self-verification~\cite{weng-etal-2023-large} to detect risks that might be missed in the evaluation process.  

