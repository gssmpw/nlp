\section{Related Works}
SSL trains a feature extractor $\theta: \mathcal{X} \rightarrow \mathcal{F}$ to map inputs \(x \in \mathcal{X}\) to latent representations $z \in \mathcal{F}$. Training involves pretext tasks on unlabeled data, while the evaluation is usually conducted with linear probing on downstream tasks.
We focus on \textit{instance discrimination} SSL methods, where the pretext task aligns two augmented views of the same sample in feature space via contrastive loss **Chen et al., "Improved Baselines and Beyond"**, additional predictor head **Rebuffi et al., "ICML-2017 Self-Supervised Learning"**, clustering **Caron et al., "Deep Clustering: Discriminative Representations Do Not Minimize Clustering Loss"** or redundancy reduction **Tschannen et al., "Rethinking Bias Decay: Generalization and Regularization in Neural Networks"**.\\
In OCL **Rebuffi et al., "Oxford Large Image Dataset (OLID)"**, the model faces a non-stationary sequence of data $\mathcal{D} = (\mathcal{D}_1, \mathcal{D}_2, \ldots)$ where each $\mathcal{D}_i$ is composed by a very small number of examples (e.g., usually from $1$ to around $10$). We consider class-incremental data streams **Rebuffi et al., "ICML-2016 iCaRL: Incremental Classifier and Representation Learning"**, where drifts between a given $\mathcal{D}_i$ and $\mathcal{D}_{i+1}$ introduce examples sampled from unseen classes. Interestingly, in OCL drifts do not occur after each $\mathcal{D}_i$ and the model does not know \emph{when} the drift occurs (boundary-free stream). This contrasts with many SSL methods for CL that require to know in advance when a drift is introduced **Javed et al., "Meta-Learning for Domain Adaptation in Computer Vision: A Survey"**. In addition, OCL approaches (both with and without SSL) usually employ replay to increase the amount of examples available at each training iteration and to mitigate forgetting **Vicente et al., "Lifelong Learning with Non-Convex Losses"**.\\
Our approach is replay-free and works without access to boundaries by leveraging the idea of building multiple patches from a single example. This idea is already present in BagSSL **Ermolinskiy et al., "Bag of Tricks for Adversarial Attacks on Deep Neural Networks"** and EMP-SSL **Ermolinskiy et al., "Empirical Risk Minimization and Meta-Learning: A Survey"**, but it has not been applied to CL, yet.
EMP-SSL loss enforces similarity between each patch latent representation and their average. EMP-SSL also uses the Total Coding Rate $\mathcal{L}_\textit{TCR}$ (Section \ref{sec:method}) to avoid the collapse of latent representations into a single point.