\section{Related Works}
\begin{table}[tb]
    \centering
    \begin{tabular}{c c c}
        \toprule
         Predictions & sAP$^{5}$(\%) & sAP$^{10}$(\%)\\
        \midrule
         w/o Re-ranking & 62.0 & 67.2 \\
         Re-ranking with GT & 91.3 (\textcolor{red}{$+$ 29.3}) & 95.5 (\textcolor{red}{$+$ 28.3})\\
        \bottomrule
    \end{tabular}
    \caption{Line detection performance before and after re-ranking using ground truth. Predicted line segments that are closer to the ground truth are assigned higher scores through re-ranking. With proper ranking, the overall performance of the predicted candidate line segments can be significantly improved. Motivated by this observation, we propose to use a re-ranking module to optimize the predicted confidence scores during inferring and use a ranking loss to supervise confidence score predicting additionally during training.}
    \label{tab:w/o ranking}
\end{table}

\textbf{Line Segment Detection.} Traditional line detection methods such as \cite{von2008lsd,akinlar2011edlines,lu2015cannylines} rely on low-level image features, e.g., image gradients. Based on local edge features, Hough transform is used for line segment detection in \cite{guil1995fast,furukawa2003accurate,xu2015closed}.
Recently, learning-based methods have achieved promising results and can be roughly divided into two categories. In junction-based methods, DWP \cite{huang2018learning} predicts junction map and edge map in two branches before merging them. PPGNet \cite{zhang2019ppgnet} uses a point-pair graph to describe junctions and line segments. L-CNN \cite{zhou2019end} applies line proposal and LoI pooling to propose candidate lines and verify them. LETR \cite{xu2021line} models it as object detection and predicts line segments with DETR architecture. 
Methods with dense prediction first predict representation map and extract line segments with post-processing. AFM \cite{xue2019learning} proposes attraction field maps to represent the image space and uses a squeeze module to generate line segment maps. HAWP \cite{xue2020holistically} further builds a hybrid model considering AFM and L-CNN. Lin \textit{et al.} \cite{lin2020deep} apply deep Hough transform to the previous detection architectures. TP-LSD \cite{huang2020tp} introduces tri-points line segment representation for end-to-end detection. M-LSD \cite{gu2022towards} presents SoL augmentation and designs an extremely efficient architecture for fast detection.
In this work, we propose a novel Transformer-based line detection method which can get proposals from dense feature maps without bipartite matching.

\begin{figure*}[t]
    \centering
    \includegraphics[width=17.7cm]{pipeline.pdf}
    \caption{Overview of the proposed RANK-LETR. The process begins by feeding an image into a CNN backbone to extract multi-level feature maps from different layers. These features are then processed by a deformable Transformer encoder to generate candidate line segments. The candidate segments are predicted using high-resolution feature maps for higher prediction accuracy and less ambiguity, with each segment represented by confidence scores and positions. Each feature point is responsible for detecting the line segment whose centroid is nearest to it. Additionally, learnable geometric information is extracted from the multi-level features using a CNN-based geometric information extractor. Finally, the line segments are re-ranked by optimizing their confidence scores with the learnable geometric information.}
    \label{fig:pipeline}
\end{figure*}

\noindent\textbf{Visual Transformer.} 
Transformer-based models have gained significant success in computer vision tasks. Dosovitskiy \textit{et al.} \cite{dosovitskiy2020image} propose the Vision Transformer (ViT) which applies transformers to image classification by dividing the image into fixed-size patches. Carion \textit{et al.} \cite{carion2020end} introduce transformers into object detection pipeline through bipartite matching, named DETR. Zhu \textit{et al.} \cite{zhu2020deformable} further propose deformable DETR whose attention modules only attend to a small set of keys. Xu \textit{et al.} \cite{xu2021line} apply DETR architecture in line segment detection with a multi-scale encoder-decoder strategy. 
Tong \textit{et al.} \cite{tong2022transformer} use Transformer to cluster line segments corresponding with the same vanishing points and further apply Transformer in end-to-end vanishing point detection \cite{tong2024end}. Transformers are also used in semantic segmentation \cite{xie2021segformer}, pose estimation \cite{huang2020hand}, tracking \cite{chen2021transformer}, etc. Our work aims at improving transformer-based line segment detection with matched predicting strategy and presented re-ranking module.

\noindent\textbf{Ranking-based Losses for Object Detectors.} Ranking-based losses have been widely used recently. Average Precision Loss is first proposed \cite{chen2019towards} to address the imbalance of foreground-background classification problem by framing object detection as a ranking task. Oksuz \textit{et al.} \cite{oksuz2021rank} propose Rank \& Sort (RS) Loss that defines a ranking objective between positives and negatives as well as a sorting objective to prioritize positives with respect to their continuous IoUs.
Yavuz \textit{et al.} \cite{yavuz2024bucketed} apply Bucketed Ranking-based(BR) Losses which group negative predictions into several buckets.
Cetinkaya \textit{et al.} \cite{Cetinkaya_2024_CVPR} extend Ranking-based Loss to edge detection. In this work, we propose a line segment ranking loss for ranking the feature point with a higher line segment detection quality a higher confidence score.