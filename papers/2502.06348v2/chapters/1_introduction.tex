\section{Introduction} \label{sec:introduction}
Decentralized finance (DeFi) has emerged as a groundbreaking paradigm, revolutionizing the landscape of traditional finance by offering open, accessible, and permissionless financial services built on the foundation of blockchain technology.
At the core of many DeFi applications lie price oracles, providing essential external price data for smart contracts that power a wide array of financial activities, including lending, borrowing, trading, and more.
By delivering accurate up-to-date price information, price oracles enable DeFi protocols to operate effectively, execute fair transactions, and maintain ecosystem stability.
However, the critical role of price oracles also makes them a prime target for exploitation, posing a significant risk to the integrity of the entire ecosystem.
Manipulating the price data provided by an oracle to mislead smart contracts about the true value of an asset is referred to \emph{price oracle manipulation (POM)}~\cite{wu2021defiranger}.
Through POM, adversaries can exploit misled smart contracts to gain unfair advantages or illicit profits.
These attacks can take various forms, such as using flash loans to temporarily distort asset prices, compromise data sources to feed false information to oracles, influence decentralized voting mechanisms to distort price data, or exploit time-weighted average price (TWAP) calculations to create inaccurate price feeds.
Recent studies have highlighted the severity of the issue. For example, Zhou et al.~\cite{zhou2023sok} reported that on-chain oracle manipulation incidents are the most common protocol layer incident type, acconting for 15\% of the total real-world attacks analyzed.
Similarly, Zhang et al.\cite{zhang2023demystifying} find that price oracle manipulation exploits represent 34.3\% of the exploits in their real-world dataset, identifying it as the most common exploit among machine-unauditable bugs (MUBs)—a category of vulnerabilities that, as of 2022, remain undetectable by existing automated tools. 

Although recent years have seen advancements in automated security tools, the blockchain community still struggles to effectively address POM. 
Chaliasos et al.~\cite{chaliasos2024smart} highlight that only 25\% of real-world attacks are detected by widely used static analysis tools such as ConFuzzius~\cite{torres2021confuzzius}, Mythril~\cite{consensys2024mythril}, Oyente~\cite{luu2016oyente}, Slither~\cite{feist2019slither}, and Solhint~\cite{protofire2024solhint}, underscoring the persistent limitations of existing automated approaches.
Few works attempting to address POM include DeFiRanger~\cite{wu2021defiranger}, which identifies price oracle manipulation attacks using pattern matching; ProMutator~\cite{wang2021promutator}, which simulates potential price manipulation attacks to identify weak points in oracle systems; DeFiPoser~\cite{zhou2021defiposer}, which uses SMT solvers to detect complex profitable transactions; and OVer~\cite{deng2024safeguarding}, which employs symbolic analysis and SMT solvers to ensure the secure operation of DeFi protocols.
These approaches often require extensive transaction data, significant computational resources, or accurate modeling, limiting their performance and adoption.
In practice, this kind of task still heavily relies on the manual efforts of experienced experts by analyzing data and patterns.
Thus, these approaches are inherently limited by human capacity and expertise, making it difficult to scale and adapt to the rapidly evolving landscape of DeFi and smart contract technologies.


With the rapid development of large language models (LLMs), some works have leveraged LLMs for detecting smart contract vulnerabilities.
Early exploration by Issac et al.~\cite{david2023you} demonstrated the effectiveness of ChatGPT-4 and Claude in conducting smart contract security audits especially identifying logic issues and coding errors, but they generated a significant number of false positives (95\% of alarms).
Building upon this, Gao et al.\cite{gao2024unveiling} further evaluated ChatGPT-4's performance across six specific categories of bugs, revealing that it can detect an average of 15\% of vulnerabilities using bug-type-agnostic prompts. Notably, while it successfully identified 33\% of price oracle manipulation bugs, this came with an 87\% false positive rate, highlighting the complex trade-off between recall and precision in LLM-based approaches.
These initial efforts use LLMs in a straightforward manner and are more evaluation-oriented, lacking dedicated design for POM.
Following these works, GPTLens~\cite{hu2023large} introduced an adversarial framework with LLMs serving as an \textit{Auditor} and \textit{Critic} to improve vulnerability detection. By separating generation and discrimination stages, GPTLens reduces false positives while maintaining recall. However, its models struggle to interpret ground truth effectively, resulting in only marginal improvements in a small evaluation of 13 projects.
Notably, GPTScan~\cite{sun2023gptscan} combines ChatGPT’s code analysis capabilities with static analysis to detect logical vulnerabilities in smart contracts. While it achieves high precision and recall on detecting vulnerability types, it struggles with complex vulnerabilities like POM, which require long and intricate function calls. GPTScan also depends heavily on ChatGPT's output format, which is prone to errors even in streamlined JSON formats, complicating integration with static analysis tools. This limitation leads to missed vulnerabilities or false alarms when validating strategies by static analysis tools are loosened.
Our evaluation confirmed these challenges, showing increased false positive and false negative rates when GPTScan's results are assessed with standard metrics. Moreover, its fixed warning messages for each vulnerability type limit interpretability, and the static analysis tools it relies on often fail to handle diverse smart contracts.
These studies underscore LLMs’ potential in advancing smart contract security but highlight persistent challenges, including high false positive rates, limited coverage of complex bugs, and difficulty delivering actionable insights for real-world applications.
% While these studies highlight the promise of LLMs, they also expose their current limitations in providing actionable insights and achieving reliable detection in real-world scenarios.
% GPTScan~\cite{sun2023gptscan} combines the powerful capabilities of ChatGPT with static analysis to detect ten kinds of logical vulnerabilities in smart contracts. By leveraging ChatGPT's code understanding abilities to identify potential candidate functions, then confirm these functions with four designed static analysis strategies.
% Finally, it achieves high precision and recall rates on detecting vulnerability types. 
% but there are key constraints here, some simple vulnerability type like Unauthorized Transfer, Risky First Deposit can be caught by the static analysis strategies, but like Price Oracle Manipulation which requires complex and long funciton calls, it would be, if not impossible, very challenging.
% additional, gptscan heavily relies on the output format by ChatGPT which is essential becuase static analysis tools usually require a certain input. but the model often makes mistakes about the output format even OpenAI already streamlined the JSON format.
% because of these reasons, gptscan tends to either overlook the vulnerabilities as static anlaysis tools cannot find them or emit false alarms with a loose strategy.
% this theoretical assumption is confirmed by our evaluation, which revealed that when GPTScan’s results are translated into commonly adopted bug detection metrics, its false positive and false negative rates increase. 
% Additionally, the output provided by GPTScan is often challenging for developers to interpret because it only outputs fixed warning message for each vulnerability type, limiting its practicality in real-world scenarios.
% and the imperfect implementation of static analysis tools also a big trouble for GPTScan, static analysis tools are difficult to be compatible to all smart contracts.
% These studies underscore the potential of LLMs in advancing smart contract security but also expose critical challenges, such as high false positive rates, limited detection coverage, and difficulties in facilitating actionable corrections.

% the first model summarized the domain knowledge to minimize the human efforts.
% the summarized knowledge is then fed into the second model to generate specific prompt for the third model to automatically detect the POM problems in the smart contracts.
% from approximately ten top-tier conference papers published since 2020, when this issue gained prominence. 
To overcome the limitations of static analysis tools, our work introduces a novel framework leveraging three LLM models, designated as \textit{Knowledge Synthesizer}, \textit{Prompt Generator} and \textit{Auditor}.
The process begins with the Knowledge Synthesizer, an LLM dedicated to the extraction and synthesis of domain-specific insights from top-tier academic literature. 
This initial step is essential, as it filters out noise introduced by lower-quality data sources—such as online forums, blogs, and miscellaneous webpages—commonly found in training datasets. Moreover, it supplies the pipeline with precise, externally validated domain knowledge.
Building on the high-fidelity insights provided by the Knowledge Synthesizer, the Prompt Generator plays a critical role in translating these insights into structured and actionable chain of thought (CoT) prompts. 
This method, demonstrated to significantly enhance LLM performance in various applications~\cite{kojima2022large}, ensures that the Auditor is guided with precise and contextually relevant instructions.
Equipped with these tailored prompts, the Auditor enhances the detection of POM across diverse projects.
To evaluate the effectiveness of our framework, we conducted experiments on a dataset containing 36 bugs from 31 real-world DeFi attacks between 2021 and 2022, as well as 24 bugs from 15 Code4rena projects spanning 2021 to 2023. 
Our results demonstrate a 2.58-times improvement in recall (0.667 vs 0.259) compared to the state-of-the-art tool GPTScan, while maintaining comparable precision. 
Additionally, when compared to the zero-shot CoT prompt, our approach achieves a 15\% increase in precision (0.313 vs 0.271) with comparable recall.
Moreover, our approach streamlines the process for developers, eliminating the need for domain knowledge in smart contracts or crafting problem-specific prompts.
To conclude, we make the following contributions:
\begin{itemize}
% \item A Novel Multi-LLM Framework:
% We propose a multi-LLM framework that synergistically combines domain-specific knowledge extraction, optimized prompt generation, and automated detection to effectively identify POM vulnerabilities in smart contracts.

% \item Automation and Transferability:
% Our framework minimizes reliance on expert knowledge by automating the extraction of insights from academic research. While addressing the critical issue of POM, it also provides a transferable and scalable solution for detecting other smart contract vulnerabilities, enhancing the security of blockchain ecosystems.

\item A Novel and Transferable Multi-LLM Framework:
We propose a multi-LLM framework that synergistically integrates a domain-specific \textit{Knowledge Synthesizer}, an optimized \textit{Prompt Generator}, and an automated \textit{Auditor} to effectively identify POM vulnerabilities in smart contracts. 
The \textit{Knowledge Synthesizer} enables seamless extension to other vulnerabilities without the need for predefined rules or code modifications, as seen in tools like GPTScan, by minimizing reliance on expert knowledge.
Meanwhile, the \textit{Prompt Generator} facilitates the automatic creation of structured prompts, eliminating the need for manual intervention and enhancing efficiency.



\item Optimized Model Selection and Knowledge Evolution:
We evaluate and identify the optimal combination of LLM models for knowledge summarization, prompt generation, and vulnerability detection. Our results highlight the complementary strengths of different models, showcasing the effectiveness of manually curated knowledge in improving detection capabilities. Furthermore, we demonstrate how LLM-based knowledge synthesizers can replicate and surpass human-curated performance, paving the way for fully automated systems.


\item Comprehensive Validation and New Discoveries:
Through extensive evaluation on diverse real-world datasets, including historical DeFi exploits and Code4rena projects, we validate the effectiveness of our framework. 
Notably, our approach successfully identified $20$ bugs which can only be detected by \tool~but not by SOTA tool GPTScan.
% Notably, our approach successfully uncovered \textbf{[XXX]} previously undetected vulnerabilities, underscoring its practical utility.
\end{itemize}


\paragraph{Outline} In the subsequent sections of this paper, we introduce some essential concept in Section~\ref{sec:background}. Then, we delve deeper into the methodology of our approach, outlining the process of knowledge extraction, prompt generation and automatic audit in Section~\ref{sec:method}.
In Section~\ref{sec:evaluation}, we present the results of our experiments and discuss the implications of our findings for the broader blockchain and DeFi ecosystems. Section~\ref{sec:related} delves into related works and we conclude our paper in Section~\ref{sec:conclusion}.