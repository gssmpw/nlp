
\section{Conclusions}

This paper proposes a novel \emph{NeRF} architecture for generating a unified color and semantic 3D representation of scenes derived from satellite images and their corresponding pixel-wise labels. 
By leveraging semantic information of transient categories during the training process we are able to improve the appearance representation of corresponding areas.
This allows the NeRF to learn a more generalized and artifact-free representation of the scene. 
Our method allows to enhance the quality of noisy input labels by exploiting the multi-view consistency offered by modern \emph{NeRF} models.
To support future research in this area, we provide a dataset featuring manually generated labels for four multi-view scenes. 
Additionally, we release the code for this work, including scripts for model training and evaluation.
