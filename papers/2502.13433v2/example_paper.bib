@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{elizalde2023clap,
  title={Clap learning audio concepts from natural language supervision},
   author={Elizalde, Benjamin and Deshmukh, Soham and Al Ismail, Mahmoud and Wang, Huaming},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@inproceedings{wu2023large,
  title={Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation},
  author={Wu, Yusong and Chen, Ke and Zhang, Tianyu and Hui, Yuchen and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@inproceedings{xue2023ulip,
  title={Ulip: Learning a unified representation of language, images, and point clouds for 3d understanding},
  author={Xue, Le and Gao, Mingfei and Xing, Chen and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xu, Ran and Niebles, Juan Carlos and Savarese, Silvio},
  booktitle={Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition},
  pages={1179--1189},
  year={2023}
}

@article{liang2022mind,
  title={Mind the gap: Understanding the modality gap in multi-modal contrastive representation learning},
  author={Liang, Victor Weixin and Zhang, Yuhui and Kwon, Yongchan and Yeung, Serena and Zou, James Y},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17612--17625},
  year={2022}
}

@inproceedings{deshmukh2024training,
  title={Training audio captioning models without audio},
  author={Deshmukh, Soham and Elizalde, Benjamin and Emmanouilidou, Dimitra and Raj, Bhiksha and Singh, Rita and Wang, Huaming},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={371--375},
  year={2024},
  organization={IEEE}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{bai2023qwentechnicalreport,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@article{touvron2023llamaopenefficientfoundation,
  author       = {Hugo Touvron and
                  Thibaut Lavril and
                  Gautier Izacard and
                  Xavier Martinet and
                  Marie{-}Anne Lachaux and
                  Timoth{\'{e}}e Lacroix and
                  Baptiste Rozi{\`{e}}re and
                  Naman Goyal and
                  Eric Hambro and
                  Faisal Azhar and
                  Aur{\'{e}}lien Rodriguez and
                  Armand Joulin and
                  Edouard Grave and
                  Guillaume Lample},
  title        = {LLaMA: Open and Efficient Foundation Language Models},
  journal      = {CoRR},
  volume       = {abs/2302.13971},
  year         = {2023},
}

@article{zhang2024zeroshotaudiocaptioningusing,
  title={Zero-Shot Audio Captioning Using Soft and Hard Prompts},
  author={Zhang, Yiming and Xu, Xuenan and Du, Ruoyi and Liu, Haohe and Dong, Yuan and Tan, Zheng-Hua and Wang, Wenwu and Ma, Zhanyu},
  journal={arXiv preprint arXiv:2406.06295},
  year={2024}
}

@article{li2024drcapdecodingclaplatents,
  title={DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning},
  author={Li, Xiquan and Chen, Wenxi and Ma, Ziyang and Xu, Xuenan and Liang, Yuzhe and Zheng, Zhisheng and Kong, Qiuqiang and Chen, Xie},
  journal={arXiv preprint arXiv:2410.09472},
  year={2024}
}

@article{kouzelis2023weaklysupervisedautomatedaudiocaptioning,
  title={Weakly-supervised automated audio captioning via text only training},
  author={Kouzelis, Theodoros and Katsouros, Vassilis},
  journal={arXiv preprint arXiv:2309.12242},
  year={2023}
}


@inproceedings{gong2024listenthinkunderstand,
  author       = {Yuan Gong and
                  Hongyin Luo and
                  Alexander H. Liu and
                  Leonid Karlinsky and
                  James R. Glass},
  title        = {Listen, Think, and Understand},
  booktitle    = {The Twelfth International Conference on Learning Representations, Vienna, Austria, May 7-11, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
}

@inproceedings{tang2024salmonngenerichearingabilities,
  author       = {Changli Tang and
                  Wenyi Yu and
                  Guangzhi Sun and
                  Xianzhao Chen and
                  Tian Tan and
                  Wei Li and
                  Lu Lu and
                  Zejun Ma and
                  Chao Zhang},
  title        = {{SALMONN:} Towards Generic Hearing Abilities for Large Language Models},
  booktitle    = {The Twelfth International Conference on Learning Representations, Vienna, Austria, May 7-11, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
}

@article{deshmukh2024pengiaudiolanguagemodel,
  title={Pengi: An audio language model for audio tasks},
  author={Deshmukh, Soham and Elizalde, Benjamin and Singh, Rita and Wang, Huaming},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={18090--18108},
  year={2023}
}




@article{chu2023qwenaudioadvancinguniversalaudio,
  title={Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models},
  author={Chu, Yunfei and Xu, Jin and Zhou, Xiaohuan and Yang, Qian and Zhang, Shiliang and Yan, Zhijie and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.07919},
  year={2023}
}


@inproceedings{li2023blip2bootstrappinglanguageimagepretraining,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}


@inproceedings{zhang2021pointclippointcloudunderstanding,
  title={Pointclip: Point cloud understanding by clip},
  author={Zhang, Renrui and Guo, Ziyu and Zhang, Wei and Li, Kunchang and Miao, Xupeng and Cui, Bin and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition},
  pages={8552--8562},
  year={2022}
}

@inproceedings{guzhov2022audioclip,
  title={Audioclip: Extending clip to image, text and audio},
  author={Guzhov, Andrey and Raue, Federico and Hees, J{\"o}rn and Dengel, Andreas},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={976--980},
  year={2022},
  organization={IEEE}
}

@inproceedings{jia2021scalingvisualvisionlanguagerepresentation,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}


@article{bai2023qwenvlversatilevisionlanguagemodel,
  title={Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  volume={1},
  number={2},
  pages={3},
  year={2023}
}

@article{touvron2023llama2openfoundation,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}


@inproceedings{yang2024airbenchbenchmarkinglargeaudiolanguage,
  author       = {Qian Yang and
                  Jin Xu and
                  Wenrui Liu and
                  Yunfei Chu and
                  Ziyue Jiang and
                  Xiaohuan Zhou and
                  Yichong Leng and
                  Yuanjun Lv and
                  Zhou Zhao and
                  Chang Zhou and
                  Jingren Zhou},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {AIR-Bench: Benchmarking Large Audio-Language Models via Generative
                  Comprehension},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {1979--1998},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
}

@article{sakshi2024mmaumassivemultitaskaudio,
  title={Mmau: A massive multi-task audio understanding and reasoning benchmark},
  author={Sakshi, S and Tyagi, Utkarsh and Kumar, Sonal and Seth, Ashish and Selvakumar, Ramaneswaran and Nieto, Oriol and Duraiswami, Ramani and Ghosh, Sreyan and Manocha, Dinesh},
  journal={arXiv preprint arXiv:2410.19168},
  year={2024}
}

@inproceedings{gu2023icantbelievetheres,
  title={I Can't Believe There's No Images! Learning Visual Tasks Using only Language Supervision},
  author={Gu, Sophia and Clark, Christopher and Kembhavi, Aniruddha},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2672--2683},
  year={2023}
}

@inproceedings{DBLP:conf/emnlp/NukraiMG22,
  author       = {David Nukrai and
                  Ron Mokady and
                  Amir Globerson},
  editor       = {Yoav Goldberg and
                  Zornitsa Kozareva and
                  Yue Zhang},
  title        = {Text-Only Training for Image Captioning using Noise-Injected {CLIP}},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022},
  pages        = {4055--4063},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
}

@inproceedings{gu2024languageonlyefficienttrainingzeroshot,
  author       = {Geonmo Gu and
                  Sanghyuk Chun and
                  Wonjae Kim and
                  Yoohoon Kang and
                  Sangdoo Yun},
  title        = {Language-only Efficient Training of Zero-shot Composed Image Retrieval},
  booktitle    = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition, Seattle, WA, USA, June 16-22, 2024},
  pages        = {13225--13234},
  publisher    = {{IEEE}},
  year         = {2024},
}


@inproceedings{li2023decapdecodingcliplatents,
  author       = {Wei Li and
                  Linchao Zhu and
                  Longyin Wen and
                  Yi Yang},
  title        = {DeCap: Decoding {CLIP} Latents for Zero-Shot Captioning via Text-Only
                  Training},
  booktitle    = {The Eleventh International Conference on Learning Representations, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
}


@article{wang2024textdatacentricimagecaptioning,
  title={Text Data-Centric Image Captioning with Interactive Prompts},
  author={Wang, Yiyu and Luo, Hao and Xu, Jungang and Sun, Yingfei and Wang, Fan},
  journal={arXiv preprint arXiv:2403.19193},
  year={2024}
}

@inproceedings{Yang_2023,
   title={MultiCapCLIP: Auto-Encoding Prompts for Zero-Shot Multilingual Visual Captioning},
   booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   publisher={Association for Computational Linguistics},
   author={Yang, Bang and Liu, Fenglin and Wu, Xian and Wang, Yaowei and Sun, Xu and Zou, Yuexian},
   year={2023},
   pages={11908–11922} 
}


@inproceedings{radford2022robustspeechrecognitionlargescale,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}


@inproceedings{chen2022beatsaudiopretrainingacoustic,
  author       = {Sanyuan Chen and Yu Wu and Chengyi Wang and Shujie Liu and Daniel Tompkins and Zhuo Chen and Furu Wei},
  title        = {BEATs: Audio Pre-Training with Acoustic Tokenizers},
  booktitle    = {International Conference on Machine Learning, 23-29 July 2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {5178--5193},
  publisher    = {{PMLR}},
  year         = {2023},
}

@inproceedings{chen2022htsathierarchicaltokensemanticaudio,
  title={Hts-at: A hierarchical token-semantic audio transformer for sound classification and detection},
  author={Chen, Ke and Du, Xingjian and Zhu, Bilei and Ma, Zejun and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={646--650},
  year={2022},
  organization={IEEE}
}


@inproceedings{chen2020vggsoundlargescaleaudiovisualdataset,
  title={Vggsound: A large-scale audio-visual dataset},
  author={Chen, Honglie and Xie, Weidi and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={721--725},
  year={2020},
  organization={IEEE}
}


@inproceedings{7760424,
  title={TUT database for acoustic scene classification and sound event detection},
  author={Mesaros, Annamaria and Heittola, Toni and Virtanen, Tuomas},
  booktitle={2016 24th European Signal Processing Conference},
  pages={1128--1132},
  year={2016},
  organization={IEEE}
}

@inproceedings{10.1145/2733373.2806390,
  title={ESC: Dataset for environmental sound classification},
  author={Piczak, Karol J},
  booktitle={Proceedings of the 23rd ACM international conference on Multimedia},
  pages={1015--1018},
  year={2015}
}

@article{fonseca2022fsd50kopendatasethumanlabeled,
  title={Fsd50k: an open dataset of human-labeled sound events},
  author={Fonseca, Eduardo and Favory, Xavier and Pons, Jordi and Font, Frederic and Serra, Xavier},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={829--852},
  year={2021},
  publisher={IEEE}
}

@article{cao2014crema,
  title={Crema-d: Crowd-sourced emotional multimodal actors dataset},
  author={Cao, Houwei and Cooper, David G and Keutmann, Michael K and Gur, Ruben C and Nenkova, Ani and Verma, Ragini},
  journal={IEEE Transactions on Affective Computing},
  volume={5},
  number={4},
  pages={377--390},
  year={2014},
  publisher={IEEE}
}

@inproceedings{Gong_2022,
  title={Vocalsound: A dataset for improving human vocal sounds recognition},
  author={Gong, Yuan and Yu, Jin and Glass, James},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={151--155},
  year={2022},
  organization={IEEE}
}


@article{Sturm_2014,
  title={The state of the art ten years after a state of the art: Future research in music information retrieval},
  author={Sturm, Bob L},
  journal={Journal of new music research},
  volume={43},
  number={2},
  pages={147--172},
  year={2014},
  publisher={Taylor \& Francis}
}

@INPROCEEDINGS{6853981,
  author={Tian, Mi and Srinivasamurthy, Ajay and Sandler, Mark and Serra, Xavier},
  booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={A study of instrument-wise onset detection in Beijing Opera percussion ensembles}, 
  year={2014},
  volume={},
  number={},
  pages={2159-2163},
  }


@article{Mei_2024,
   title={WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research},
   volume={32},
   ISSN={2329-9304},
   journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
   publisher={Institute of Electrical and Electronics Engineers},
   author={Mei, Xinhao and Meng, Chutong and Liu, Haohe and Kong, Qiuqiang and Ko, Tom and Zhao, Chengqi and Plumbley, Mark D. and Zou, Yuexian and Wang, Wenwu},
   year={2024},
   pages={3339–3354} }

@inproceedings{8ced9ba43cbd49c1acd288d151565342,
  author       = {Irene Mart{\'{\i}}n{-}Morat{\'{o}} and
                  Annamaria Mesaros},
  title        = {Diversity and Bias in Audio Captioning Datasets},
  booktitle    = {Proceedings of the 6th Workshop on Detection and Classification of Acoustic Scenes and Events 2021, Online, November 15-19,
                  2021},
  pages        = {90--94},
  year         = {2021},
}

@inproceedings{kim-etal-2019-audiocaps,
    title = "{A}udio{C}aps: Generating Captions for Audios in The Wild",
    author = "Kim, Chris Dongjoo  and
      Kim, Byeongchang  and
      Lee, Hyunmin  and
      Kim, Gunhee",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    pages = "119--132",
}

@inproceedings{drossos2019clothoaudiocaptioningdataset,
  title={Clotho: An audio captioning dataset},
  author={Drossos, Konstantinos and Lipping, Samuel and Virtanen, Tuomas},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={736--740},
  year={2020},
  organization={IEEE}
}


@inproceedings{lipping2022clothoaqacrowdsourceddatasetaudio,
  title={Clotho-aqa: A crowdsourced dataset for audio question answering},
  author={Lipping, Samuel and Sudarsanam, Parthasaarathy and Drossos, Konstantinos and Virtanen, Tuomas},
  booktitle={2022 30th European Signal Processing Conference },
  pages={1140--1144},
  year={2022},
  organization={IEEE}
}

@INPROCEEDINGS{7952261,
  author={Gemmeke, Jort F. and Ellis, Daniel P. W. and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R. Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={Audio Set: An ontology and human-labeled dataset for audio events}, 
  year={2017},
  volume={},
  number={},
  pages={776-780},
}

@inproceedings{mesaros:hal-01627981,
  TITLE = {{DCASE 2017 Challenge setup: Tasks, datasets and baseline system}},
  AUTHOR = {Mesaros, Annamaria and Heittola, Toni and Diment, Aleksandr and Elizalde, Benjamin and Shah, Ankit and Vincent, Emmanuel and Raj, Bhiksha and Virtanen, Tuomas},
  BOOKTITLE = {{DCASE 2017 - Workshop on Detection and Classification of Acoustic Scenes and Events}},
  ADDRESS = {Munich, Germany},
  YEAR = {2017},
}

@inproceedings{10.1145/2647868.2655045,
author = {Salamon, Justin and Jacoby, Christopher and Bello, Juan Pablo},
title = {A Dataset and Taxonomy for Urban Sound Research},
year = {2014},
isbn = {9781450330633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the 22nd ACM International Conference on Multimedia},
pages = {1041–1044},
numpages = {4},
location = {Orlando, Florida, USA},
series = {MM '14}
}

@misc{spadini2019sound,
  author       = {Tito Spadini},
  title        = {Sound Events for Surveillance Applications (1.0.0) [Data set]},
  year         = {2019},
  publisher    = {Zenodo},
}

@inproceedings{gong2023jointaudiospeechunderstanding,
  title={Joint audio and speech understanding},
  author={Gong, Yuan and Liu, Alexander H and Luo, Hongyin and Karlinsky, Leonid and Glass, James},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@inproceedings{ghosh2024gamalargeaudiolanguagemodel,
  author       = {Sreyan Ghosh and
                  Sonal Kumar and
                  Ashish Seth and
                  Chandra Kiran Reddy Evuru and
                  Utkarsh Tyagi and
                  S. Sakshi and
                  Oriol Nieto and
                  Ramani Duraiswami and
                  Dinesh Manocha},
  title        = {{GAMA:} {A} Large Audio-Language Model with Advanced Audio Understanding
                  and Complex Reasoning Abilities},
  booktitle    = {Proceedings of the 2024 Conference on Empirical Methods in Natural
                  Language Processing, Miami, FL, USA, November 12-16,
                  2024},
  pages        = {6288--6313},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
}

@article{agostinelli2023musiclmgeneratingmusictext,
  author       = {Andrea Agostinelli and
                  Timo I. Denk and
                  Zal{\'{a}}n Borsos and
                  Jesse H. Engel and
                  Mauro Verzetti and
                  Antoine Caillon and
                  Qingqing Huang and
                  Aren Jansen and
                  Adam Roberts and
                  Marco Tagliasacchi and
                  Matthew Sharifi and
                  Neil Zeghidour and
                  Christian Havn{\o} Frank},
  title        = {MusicLM: Generating Music From Text},
  journal      = {CoRR},
  volume       = {abs/2301.11325},
  year         = {2023},
}

@article{manco2023songdescriberdatasetcorpus,
  title={The song describer dataset: a corpus of audio captions for music-and-language evaluation},
  author={Manco, Ilaria and Weck, Benno and Doh, Seungheon and Won, Minz and Zhang, Yixiao and Bogdanov, Dmitry and Wu, Yusong and Chen, Ke and Tovstogan, Philip and Benetos, Emmanouil and others},
  journal={arXiv preprint arXiv:2311.10057},
  year={2023}
}

@article{pub.1104022894,
 author = {Livingstone, Steven R. and Russo, Frank A.},
 journal = {PLOS ONE},
 keywords = {},
 number = {5},
 pages = {e0196391},
 title = {The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English},
 volume = {13},
 year = {2018}
}

@article{openai2024gpt4technicalreport,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@INPROCEEDINGS{10447027,
  author={Liu, Shansong and Hussain, Atin Sakkeer and Sun, Chenshuo and Shan, Ying},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning}, 
  year={2024},
  volume={},
  number={},
  pages={286-290},
}


@inproceedings{doh2023lpmusiccapsllmbasedpseudomusic,
  author       = {Seungheon Doh and
                  Keunwoo Choi and
                  Jongpil Lee and
                  Juhan Nam},
  title        = {LP-MusicCaps: LLM-Based Pseudo Music Captioning},
  booktitle    = {Proceedings of the 24th International Society for Music Information Retrieval Conference, Milan, Italy, November 5-9, 2023},
  pages        = {409--416},
  year         = {2023},
}


@inproceedings{hu2021loralowrankadaptationlarge,
  author       = {Edward J. Hu and
                  Yelong Shen and
                  Phillip Wallis and
                  Zeyuan Allen{-}Zhu and
                  Yuanzhi Li and
                  Shean Wang and
                  Lu Wang and
                  Weizhu Chen},
  title        = {LoRA: Low-Rank Adaptation of Large Language Models},
  booktitle    = {The Tenth International Conference on Learning Representations, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
}

@article{vapnik1998statistical,
  title={Statistical learning theory},
  author={Vapnik, Vladimir},
  journal={John Wiley \& Sons google schola},
  volume={2},
  pages={831--842},
  year={1998}
}

@inproceedings{10.5555/3666122.3668142,
author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P. and Zhang, Hao and Gonzalez, Joseph E. and Stoica, Ion},
title = {Judging LLM-as-a-judge with MT-bench and Chatbot Arena},
year = {2024},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {2020},
numpages = {29},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@article{goel2022cyclipcycliccontrastivelanguageimage,
  title={Cyclip: Cyclic contrastive language-image pretraining},
  author={Goel, Shashank and Bansal, Hritik and Bhatia, Sumit and Rossi, Ryan and Vinay, Vishwa and Grover, Aditya},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={6704--6719},
  year={2022}
}

@inproceedings{kong2024audioflamingonovelaudio,
  author       = {Zhifeng Kong and
                  Arushi Goel and
                  Rohan Badlani and
                  Wei Ping and
                  Rafael Valle and
                  Bryan Catanzaro},
  title        = {Audio Flamingo: {A} Novel Audio Language Model with Few-Shot Learning
                  and Dialogue Abilities},
  booktitle    = {Forty-first International Conference on Machine Learning, Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
}

@inproceedings{mansour2023domainadaptationlearningbounds,
  author       = {Yishay Mansour and
                  Mehryar Mohri and
                  Afshin Rostamizadeh},
  title        = {Domain Adaptation: Learning Bounds and Algorithms},
  booktitle    = {The 22nd Conference on Learning Theory, Montreal, Quebec, Canada, June 18-21, 2009},
  year         = {2009},
}

@article{chu2024qwen2audiotechnicalreport,
  title={Qwen2-audio technical report},
  author={Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others},
  journal={arXiv preprint arXiv:2407.10759},
  year={2024}
}

@article{geminiteam2024gemini15unlockingmultimodal,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article{wang2024blspbootstrappinglanguagespeechpretraining,
  title={Blsp: Bootstrapping language-speech pre-training via behavior alignment of continuation writing},
  author={Wang, Chen and Liao, Minpeng and Huang, Zhongqiang and Lu, Jinliang and Wu, Junhong and Liu, Yuchen and Zong, Chengqing and Zhang, Jiajun},
  journal={arXiv preprint arXiv:2309.00916},
  year={2023}
}

@article{su2023pandagptmodelinstructionfollow,
  title={Pandagpt: One model to instruction-follow them all},
  author={Su, Yixuan and Lan, Tian and Li, Huayang and Xu, Jialu and Wang, Yan and Cai, Deng},
  journal={arXiv preprint arXiv:2305.16355},
  year={2023}
}


@inproceedings{wu2024nextgptanytoanymultimodalllm,
  author       = {Shengqiong Wu and
                  Hao Fei and
                  Leigang Qu and
                  Wei Ji and
                  Tat{-}Seng Chua},
  title        = {NExT-GPT: Any-to-Any Multimodal {LLM}},
  booktitle    = {Forty-first International Conference on Machine Learning,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
}


@inproceedings{zhang2023speechgptempoweringlargelanguage,
  author       = {Dong Zhang and
                  Shimin Li and
                  Xin Zhang and
                  Jun Zhan and
                  Pengyu Wang and
                  Yaqian Zhou and
                  Xipeng Qiu},
  title        = {SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal
                  Conversational Abilities},
  booktitle    = {Findings of the Association for Computational Linguistics, Singapore, December 6-10, 2023},
  pages        = {15757--15773},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
}


@article{lyu2023macawllmmultimodallanguagemodeling,
  title={Macaw-llm: Multi-modal language modeling with image, audio, video, and text integration},
  author={Lyu, Chenyang and Wu, Minghao and Wang, Longyue and Huang, Xinting and Liu, Bingshuai and Du, Zefeng and Shi, Shuming and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2306.09093},
  year={2023}
}

@inproceedings{liu2023musicunderstandingllamaadvancing,
  title={Music understanding LLaMA: Advancing text-to-music generation with question answering and captioning},
  author={Liu, Shansong and Hussain, Atin Sakkeer and Sun, Chenshuo and Shan, Ying},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={286--290},
  year={2024},
  organization={IEEE}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}