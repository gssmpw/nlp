@inproceedings{DBLP:conf/emnlp/NukraiMG22,
  author       = {David Nukrai and
                  Ron Mokady and
                  Amir Globerson},
  editor       = {Yoav Goldberg and
                  Zornitsa Kozareva and
                  Yue Zhang},
  title        = {Text-Only Training for Image Captioning using Noise-Injected {CLIP}},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022},
  pages        = {4055--4063},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
}

@inproceedings{chen2022beatsaudiopretrainingacoustic,
  author       = {Sanyuan Chen and Yu Wu and Chengyi Wang and Shujie Liu and Daniel Tompkins and Zhuo Chen and Furu Wei},
  title        = {BEATs: Audio Pre-Training with Acoustic Tokenizers},
  booktitle    = {International Conference on Machine Learning, 23-29 July 2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {5178--5193},
  publisher    = {{PMLR}},
  year         = {2023},
}

@article{chu2024qwen2audiotechnicalreport,
  title={Qwen2-audio technical report},
  author={Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others},
  journal={arXiv preprint arXiv:2407.10759},
  year={2024}
}

@article{deshmukh2024pengiaudiolanguagemodel,
  title={Pengi: An audio language model for audio tasks},
  author={Deshmukh, Soham and Elizalde, Benjamin and Singh, Rita and Wang, Huaming},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={18090--18108},
  year={2023}
}

@inproceedings{deshmukh2024training,
  title={Training audio captioning models without audio},
  author={Deshmukh, Soham and Elizalde, Benjamin and Emmanouilidou, Dimitra and Raj, Bhiksha and Singh, Rita and Wang, Huaming},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={371--375},
  year={2024},
  organization={IEEE}
}

@inproceedings{elizalde2023clap,
  title={Clap learning audio concepts from natural language supervision},
   author={Elizalde, Benjamin and Deshmukh, Soham and Al Ismail, Mahmoud and Wang, Huaming},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@inproceedings{ghosh2024gamalargeaudiolanguagemodel,
  author       = {Sreyan Ghosh and
                  Sonal Kumar and
                  Ashish Seth and
                  Chandra Kiran Reddy Evuru and
                  Utkarsh Tyagi and
                  S. Sakshi and
                  Oriol Nieto and
                  Ramani Duraiswami and
                  Dinesh Manocha},
  title        = {{GAMA:} {A} Large Audio-Language Model with Advanced Audio Understanding
                  and Complex Reasoning Abilities},
  booktitle    = {Proceedings of the 2024 Conference on Empirical Methods in Natural
                  Language Processing, Miami, FL, USA, November 12-16,
                  2024},
  pages        = {6288--6313},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
}

@inproceedings{gong2024listenthinkunderstand,
  author       = {Yuan Gong and
                  Hongyin Luo and
                  Alexander H. Liu and
                  Leonid Karlinsky and
                  James R. Glass},
  title        = {Listen, Think, and Understand},
  booktitle    = {The Twelfth International Conference on Learning Representations, Vienna, Austria, May 7-11, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
}

@article{kouzelis2023weaklysupervisedautomatedaudiocaptioning,
  title={Weakly-supervised automated audio captioning via text only training},
  author={Kouzelis, Theodoros and Katsouros, Vassilis},
  journal={arXiv preprint arXiv:2309.12242},
  year={2023}
}

@inproceedings{li2023decapdecodingcliplatents,
  author       = {Wei Li and
                  Linchao Zhu and
                  Longyin Wen and
                  Yi Yang},
  title        = {DeCap: Decoding {CLIP} Latents for Zero-Shot Captioning via Text-Only
                  Training},
  booktitle    = {The Eleventh International Conference on Learning Representations, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
}

@article{li2024drcapdecodingclaplatents,
  title={DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning},
  author={Li, Xiquan and Chen, Wenxi and Ma, Ziyang and Xu, Xuenan and Liang, Yuzhe and Zheng, Zhisheng and Kong, Qiuqiang and Chen, Xie},
  journal={arXiv preprint arXiv:2410.09472},
  year={2024}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@inproceedings{tang2024salmonngenerichearingabilities,
  author       = {Changli Tang and
                  Wenyi Yu and
                  Guangzhi Sun and
                  Xianzhao Chen and
                  Tian Tan and
                  Wei Li and
                  Lu Lu and
                  Zejun Ma and
                  Chao Zhang},
  title        = {{SALMONN:} Towards Generic Hearing Abilities for Large Language Models},
  booktitle    = {The Twelfth International Conference on Learning Representations, Vienna, Austria, May 7-11, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
}

@article{touvron2023llamaopenefficientfoundation,
  author       = {Hugo Touvron and
                  Thibaut Lavril and
                  Gautier Izacard and
                  Xavier Martinet and
                  Marie{-}Anne Lachaux and
                  Timoth{\'{e}}e Lacroix and
                  Baptiste Rozi{\`{e}}re and
                  Naman Goyal and
                  Eric Hambro and
                  Faisal Azhar and
                  Aur{\'{e}}lien Rodriguez and
                  Armand Joulin and
                  Edouard Grave and
                  Guillaume Lample},
  title        = {LLaMA: Open and Efficient Foundation Language Models},
  journal      = {CoRR},
  volume       = {abs/2302.13971},
  year         = {2023},
}

@inproceedings{wu2023large,
  title={Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation},
  author={Wu, Yusong and Chen, Ke and Zhang, Tianyu and Hui, Yuchen and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{zhang2024zeroshotaudiocaptioningusing,
  title={Zero-Shot Audio Captioning Using Soft and Hard Prompts},
  author={Zhang, Yiming and Xu, Xuenan and Du, Ruoyi and Liu, Haohe and Dong, Yuan and Tan, Zheng-Hua and Wang, Wenwu and Ma, Zhanyu},
  journal={arXiv preprint arXiv:2406.06295},
  year={2024}
}

