\section{RELATED WORK}
% \subsection*{Sequential Recommendation}
 Sequential recommendation models focus on modeling user behavior as a chronologically ordered sequence of interactions, aiming to predict the next item a user will engage with.\\
{\bfseries Traditional Approaches.} Early approaches primarily utilized Markov Chains (MCs)  **Herlocker, "Can Individual Differences Account for-2 Much Variation in Recommendation Data?"** to capture the transition probabilities between items. With the rise of deep learning, an ID-based recommendation paradigm emerged. Various deep neural network architectures have been developed under this paradigm. For instance, GRU4Rec **Hidasi, "Session-Based Recommendations with Recurrent Neural Networks"** was the first to employ GRU-based RNNs for sequential recommendations, while SASRec **Kang, "Self-Attentive Sequential Recommendation"** introduced a self-attention mechanism similar to decoder-only transformer models, to capture long-range dependencies. Inspired by the success of masked language modeling, BERT4Rec **Sun, "BERT4Rec: Seamless Integration of BERT and Sequential Recommendation"** utilized transformers with masking strategies to enhance sequential recommendation tasks. Building on the masking technique, S\textsuperscript{3}-Rec **Zhu, "SÂ³-Rec: Scalable and Generalizable Model for Sequential Recommendations"** learns the correlations among attributes, items, subsequences, and sequences through the principle of mutual information maximization (MIM), thereby enhancing data representation.

\noindent{\bfseries Generative Approaches.} Unlike traditional embedding-based methods, which rely on dot-product (cosine) similarity and external ANN search systems for top-k retrieval, generative approaches predict item identifiers directly. 
%
Generative methods can be broadly categorized into two types: prompt fine-tuning strategies based on \textit{off-the-shelf} large language models (LLMs) and training from scratch for custom-designed models.

For LLMs based methods **Kang, "Prompt-Based Generative Model for Sequential Recommendations"**, the focus is on designing refined prompts and fine-tuning tasks that help language models better understand recommendation tasks. LC-Rec **Wu, "Learning-based Vector Quantization for Semantically Meaningful Item Indexing"** introduces a learning-based vector quantization approach for semantically meaningful item indexing and fine-tuning tasks that align collaborative signals with LLM representations, achieving superior performance in diverse scenarios. CCF-LLM **Huang, "Collaborative Cross-Modal Fusion for Large Language Models"** transforms user-item interactions into hybrid prompts encoding both semantic knowledge and collaborative signals, utilizing an attentive cross-modal fusion strategy to integrate embeddings from different modalities. SC-Rec **Tang, "Self-Consisent Recommendation Model with Multiple Indices and Prompt Templates"** utilizes multiple item indices and prompt templates, alongside a self-consistent re-ranking mechanism, to more effectively merge collaborative and semantic knowledge.

For methods that train from scratch **Zhang, "Autoregressive Generation for Sequential Recommendations"**, the primary focus is on converting the raw sequence recommendation task into an autoregressive generation task. Tree-based methods **Wang, "Tree-Based Generative Model for Sequence Recommendation"**, such as RecForest  **Liu, "RecForest: Constructing Multiple Trees for Routing"**, have shown promising performance by constructing multiple trees and integrating transformer-based structures for routing. Additionally, TIGER **Xu, "Transforming Item Graphs into Token Sequences with Semantic IDs"** introduced the concept of semantic IDs, representing each item as a set of tokens derived from its side information, and predicting next item tokens in a sequence-to-sequence manner. EAGER **Chen, "Dual-Stream Generative Framework for Sequential Recommendations"** employs a dual-stream generative framework to parallely utilize semantic and behavioral information with two separate codes, generating recommended items from each respective pipeline, and ultimately selecting the top-k items based on confidence scores. 

In this paper, we aim to seamlessly integrate collaborative and semantic modality knowledge into a unified code for generative recommendation, while ensuring no additional computational and storage overhead compared with solely utilizing one modality.