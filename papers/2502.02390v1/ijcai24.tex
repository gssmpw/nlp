%%%% ijcai24.tex

\typeout{IJCAI--24 Instructions for Authors}

% These are the instructions for authors for IJCAI-24.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai24.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai24}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[switch]{lineno}
\usepackage{amssymb}
\usepackage{multirow}

% Comment out this line in the camera-ready submission
% \linenumbers

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.


% PDF Info Is REQUIRED.

% Please leave this \pdfinfo block untouched both for the submission and
% Camera Ready Copy. Do not include Title and Author information in the pdfinfo section
\pdfinfo{
/TemplateVersion (IJCAI.2024.0)
}

% \title{ER-LLM: Enhancing LLM Reasoning with Automatic Associative Mechanism}
\title{CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning}


% Single author syntax
% \author{
%     Author Name
%     \affiliations
%     Affiliation
%     \emails
%     email@example.com
% }

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)
% \iffalse
\author{
% Hongyi Zhou$^{1,2}$
% \and
% Jianping Wu$^1$\and
Jianfeng Pan$^1$\and
Senyou Deng$^1$\and
Shaomang Huang$^1$\\
% Jianfeng Pan$^1$\\
\affiliations
% $^1$Tsinghua University\\
$^1$Digital Security Group, Qihoo 360\\
% $^3$Third Affiliation\\
% $^4$Fourth Affiliation\\
\emails
% zhouhongyi@mail.tsinghua.edu.cn,
\{panjianfeng, dengsenyou, huangshaomang\}@360.cn
% fourth@example.com
}
% \fi

\begin{document}

\maketitle

\begin{abstract}
    Research on LLM technologies is rapidly emerging, with most of them employing a 'fast thinking' approach to inference. Most LLMs generate the final result based solely on a single query and LLM’s reasoning capabilities. However, with the advent of OpenAI-o1, 'slow thinking' techniques have garnered increasing attention because its process is closer to the human thought process.
    %Inspired by the human ability to constantly associate and replenish itself while thinking, our research has developed the novel $\bf{En}$hancing $\bf{R}$easoning $\bf{LLM}$ framework, named ER-LLM, based on the Monte Carlo Tree Search algorithm. This framework effectively expands the LLM search space while continuously incorporating new key information, called 'associative memory', during the reasoning process, resulting in more accurate and comprehensive final results.
    Inspired by the human ability to constantly associate and replenish knowledge during thinking, we developed the novel $\bf{C}$hain-$\bf{o}$f-$\bf{A}$ssociated-$\bf{T}$houghts (CoAT) framework,
    %$\bf{E}$nhancing $\bf{R}$easoning $\bf{LLM}$ framework (ER-LLM), 
    which introduces an innovative synergy between the Monte Carlo Tree Search (MCTS) algorithm and a dynamic mechanism for integrating new key information, termed ‘associative memory’. By combining the structured exploration capabilities of MCTS with the adaptive learning capacity of associative memory, CoAT significantly expands the LLM search space, enabling our framework to explore diverse reasoning pathways and dynamically update its knowledge base in real-time. This allows the framework to not only revisit and refine earlier inferences but also adaptively incorporate evolving information, ensuring that the final output is both accurate and comprehensive. 
    %, even in the face of ambiguous or incomplete input.
    To validate the effectiveness of our framework, we conducted extensive experiments across a range of generative and reasoning tasks.
    % including natural language understanding, multi-step logical problem-solving. 
    These experiments demonstrated that our framework outperforms conventional inference processes on accuracy, coherence, and diversity. The framework’s ability to iteratively expand its search space while retaining contextually relevant information results. % that are more reflective of human-like thought processes.
\end{abstract}


\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{image/simulator.jpg}
    \caption{Left: Human thinking chain; Right: Associated thoughts chain. This illustrates how our CoAT framework is inspired to continually supplement extra information during reasoning by simulating human associative mechanisms.}
    \label{fig:simula}
\end{figure}


\section{Introduction}

Large Language Models (LLMs) have rapidly become a cornerstone in natural language processing, powering applications ranging from conversational agents to complex decision-making systems. Central to their operation is the process of inference, where LLMs generate contents based on learned patterns from massive datasets by auto-regressive learning algorithm in pre-trained stage. Most LLMs (GPTs~\cite{achiam2023gpt}, Llamas~\cite{dubey2024llama}, and Qwens~\cite{yang2024qwen2} et al.) employ a ‘fast thinking’ approach to inference
%inspired by Daniel Kahneman’s dual-process theory, which emphasizes rapid and intuitive responses. 
which relies heavily on the pre-trained reasoning capabilities of LLM models. This approach processes a single query to produce the final result. Although effective for many tasks, this approach often struggles with problems requiring nuanced, iterative reasoning, or adaptation to new information.

Recent advances have begun to explore alternatives to ‘fast thinking’, introducing ‘slow thinking’ methodologies that align more closely with human thinking processes. This idea emphasize deliberate, iterative reasoning, and the integration of historical contents or external knowledge during inference. OpenAI-o1~\cite{jaech2024openai}, a notable project, has sparked significant interest in this domain, showcasing the potential of ‘slow thinking’ frameworks to improve reasoning capabilities.
%Such approaches aim to bridge the gap between human-like adaptability and computational efficiency, marking a paradigm shift in LLM inference research. 
However, slow thinking merely subdivides the reasoning process into smaller steps and involves rethinking what has already been generated. Throughout the process, reliance is still placed on the initial input information and the logical reasoning abilities of the LLM itself.

Inspired by the human ability to constantly associate and replenish knowledge during thinking, we propose the Chain-of-Associated-Thoughts (CoAT) framework.
% which leverages two core innovations to advance LLM reasoning capabilities: Monte Carlo Tree Search (MCTS) and a dynamic associative memory mechanism. MCTS, widely known for its success in game theory and decision-making applications, facilitates structured exploration of reasoning pathways, enabling the model to evaluate multiple potential outcomes before arriving at a conclusion. 
% In CoAT framework, we apply MCTS algorithm to search the better process node.
To our knowledge, associative memory mechanisms were first applied to simulate human thought in LLM processes. The associative memory mechanism empowers CoAT to dynamically incorporate new key information during inference, mimicking the human ability to associate and update knowledge iteratively. 
Furthermore, we optimize the routing strategy in the MCTS algorithm to ensure that each addition of associative memory will provide additional key information for subsequent content generation.
This synergy between structured search and adaptive learning enables CoAT to expand its reasoning scope while maintaining contextual coherence, overcoming limitations of conventional LLMs. % addressing limitations inherent in conventional inference models.

The effectiveness of our framework is validated through extensive experiments across a diverse range of generative and reasoning tasks. The results demonstrate that our framework significantly outperforms traditional models in terms of accuracy, coherence, and diversity. By iteratively refining inferences and integrating evolving information, our CoAT framework achieves outputs that are both precise and comprehensive, advancing the state-of-the-art in reasoning-oriented LLM frameworks.
%These findings align with recent research highlighting the importance of integrating iterative and associative methodologies in AI systems (e.g., Brown et al., 2020; Zhang et al., 2023).

In summary, the main contributions of our work are as follows.
\begin{itemize}
    \item We propose the CoAT framework to enhance LLM reasoning. Our framework expands the LLM reasoning space to search for a high-quality solution using the optimized MCTS algorithm.
    \item We endow the LLM reasoning process with human-like associative and adaptive self-refinement capabilities to effectively address complex reasoning tasks.
    \item We optimized the routing strategy to identify the optimal content generation path within our framework, and extensive qualitative and quantitative experimental results demonstrate its superior performance compared to other inference approaches.
\end{itemize}

This paper is structured as follows: Section 2 reviews related work on LLM inference strategies. Section 3 details the design and implementation of our CoAT framework. Section 4 presents the experimental results, and Section 5 concludes with insights into the implications of this research and potential future directions.


\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{image/flow.jpg}
    \caption{Overview of CoAT framework. The Associative Memory (AM) will be added into each node during reasoning. The ``External Brain ($\mathbb{EB}$)'' is an optional measure to further improve the accuracy of reasoning results.}
    \label{fig:framework}
\end{figure*}


\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{image/flow-eg1.jpg}
    \caption{The detailed search process of the CoAT framework when query ``How should we view the role of artificial intelligence in contemporary interna-tional competition? Which countries hold the leading advantages in this field?''.}
    \label{fig:flow-eg}
\end{figure*}


\section{Realted Work}

The development of Large Language Models (LLMs) has witnessed significant advances in recent years, with a particular focus on improving reasoning capabilities. This section reviews key research on LLM inference strategies, the integration of iterative reasoning frameworks, and associative memory mechanisms, all of which inform the design of our Chain-of-Associated-Thoughts (CoAT).

\vspace{3pt}
$\textbf{LLM Inference Strategies}$ Traditional LLMs, including BERT~\cite{devlin2018bert}, GPT-3~\cite{brown2020language} and its successors (like GPT-4~\cite{achiam2023gpt}) rely on a single-shot or few-shot inference paradigm. These methods emphasize the model’s ability to provide accurate responses using fixed prompts, often resulting in outputs that lack robustness in scenarios that require deeper reasoning. To address these limitations, researchers have explored chain-of-thought (CoT) prompting~\cite{wei2022chain} and interleaving retrieval with chain-of-thought (IRCoT)~\cite{trivedi2022interleaving}, which enable LLMs to decompose complex problems into smaller sequential steps. Although this improves reasoning quality, it remains inherently static as the model cannot revisit or refine previous inferences during the reasoning process.

More recently, the variants of CoT, such as self-consistency chain-of-thought (CoT-SC)~\cite{wang2022self} have introduced diversity in reasoning by sampling multiple outputs and selecting the most consistent solution, Graph-of-thought (GoT)~\cite{besta2024graph} has been improved with search algorithms that can search solution paths more effectively, and Tree-of-thought (ToT)~\cite{yao2024tree} prompting uses DFS or BFS search guided by LLMs. However, these methods do not fundamentally alter the underlying inference mechanism, leaving room for further exploration of dynamic and iterative reasoning processes.

% $\textbf{Slow Thinking Frameworks}$ 
The concept of ‘slow thinking’ has gained traction as an alternative to traditional inference paradigms, inspired by the human ability to deliberate and refine thoughts over time. OpenAI-o1~\cite{jaech2024openai} has been a pioneering framework in this space, demonstrating the benefits of iterative reasoning for tasks involving complex problem solving and decision making. By allowing LLMs to reassess previous steps and integrate new information, slow thinking frameworks improve adaptability and output quality.
These advancements highlight the potential of moving beyond static reasoning toward more dynamic, context-aware methodologies.

\vspace{3pt}
$\textbf{Monte Carlo Tree Search in Inference}$ MCTS has a long history of success in domains requiring decision making under uncertainty, such as game playing~\cite{silver2016mastering} and planning~\cite{coulom2006efficient}. Its ability to balance exploration and exploitation makes it a compelling candidate for enhancing LLM reasoning. Existing works, like LLM-MCTS~\cite{zhao2024large}, LLM agent tree search (LATS)~\cite{zhou2023language} and reasoning via planning (RAP)~\cite{hao2023reasoning}
%while reasoning via planning (RAP) uses MCTS with rollouts simulated by LLMs. 
have integrated MCTS into specific AI systems to improve search space exploration, but its application in LLMs remains limited. Our CoAT extends this approach by leveraging MCTS not only for structured exploration but also as a means to iteratively refine reasoning pathways by inserting associative memory during inference.

\vspace{3pt}
$\textbf{External Knowledge Augmented Mechanisms}$ Augmented knowledge, an external information retrieval process that enables humans to form and retrieve connections between related concepts when thinking, has inspired various machine learning models. Memory-augmented neural networks~\cite{santoro2016meta} and recurrent memory-based architectures~\cite{zaremba2014recurrent} have demonstrated their effectiveness in tasks requiring long-term context retention. However, these systems often lack the flexibility to adapt to evolving information during LLM inference. Recent advancements, such as native Retrieval Augmented Generation (NativeRAG)~\cite{lewis2020retrieval}, Knowledge Augmented Generation (KAG)~\cite{liang2024kag} and hippocampal indexing RAG (HippoRAG)~\cite{gutierrez2024hipporag}, have addressed this by incorporating external knowledge from vector database or knowledge graph at input stage. CoAT framework builds upon this foundation by introducing a dynamic associative memory mechanism that not only retrieves relevant information but also updates and integrates new knowledge in real time.

% $\textbf{Synthesis and Gaps}$ 
While existing work has made significant strides in improving reasoning and adaptability in LLMs, key challenges remain. Static inference strategies and limited integration of iterative mechanisms restrict the ability of LLMs to handle complex, evolving tasks. 
%The application of MCTS and associative memory in reasoning-oriented LLM frameworks is still underexplored, presenting an opportunity to address these limitations. 
CoAT framework breaks through above limitations  by combining the structured exploration of MCTS with the adaptive capabilities of associative memory. % setting a new benchmark for reasoning-oriented LLMs.
%In summary, this research draws on and extends foundational work in LLM inference strategies, slow thinking frameworks, and memory-augmented reasoning to propose a novel approach that advances the field. 
The next sections detail the design and implementation of the CoAT and provide experimental evidence of its superior performance across some tasks.


\section{Method}

Inspired by the human ability to form associations during cognitive processes and the demonstrated effectiveness of MCTS algorithm in enhancing the reasoning capability of LLMs, we propose the CoAT reasoning framework, as illustrated in Figure~\ref{fig:framework}. The framework leverages the association mechanism to enable LLMs to perform real-time retrieval of relevant information and self-augmentation during the reasoning process. The realization of this functionality is underpinned by our optimized MCTS algorithm, which systematically integrates associative content and generated content through tree node search. By assigning precise values to each node based on our predefined rules, the algorithm facilitates the automatic association process, thereby completing the reasoning task.
To further enhance the reasoning quality of CoAT framework, we have designed a flexible mechanism for sourcing associative content. This mechanism allows the model to either perform self-association or retrieve associative information through external knowledge sources, referred to as an ``External Brain ($\mathbb{EB}$).'' The external brain encompasses commonly used resources such as knowledge graph, vector database, LLM agents, and web search engines. A detailed search process of the CoAT framework when query ``How should we view the role of artificial intelligence in contemporary interna-tional competition? Which countries hold the leading advantages in this field?'' is shown in Figure~\ref{fig:flow-eg}.

% Our CoAT framework is shown in Figure~\ref{fig:framework}.
In the following subsections, we provide a detailed explanation of the association memory mechanism and the optimized MCTS algorithm.


%\subsection{Associative Memory and Self-Complementary}
\subsection{Associative Memory Mechanism}

We introduce associative memory mechanism in the CoAT framework, can be regarded as a novel external knowledge augmentation mechanism, which enables the reasoning process of LLMs to dynamically update and integrate newly retrieved information in real time according to the generated content of each node.
%
Existing methods primarily focus on incorporating extended knowledge into the reasoning process at its initial stage. However, this approach may lead to incorporation of overly broad knowledge, which introduces two significant drawbacks: (a) an excess of irrelevant information that compromises inference efficiency, and (b) insufficient inclusion of critical content, ultimately degrading inference quality. In contrast, our proposed real-time association mechanism, integrated into the inference process, effectively addresses these issues by dynamically aligning relevant knowledge with the ongoing inference.

The associative memory mechanism generates content that is beneficial for reasoning and has not been previously mentioned in historical contents. The associative content should exhibit minimal redundancy with existing generated contents and should be concise enough to avoid interfering with the reasoning process. Furthermore, the subject of associative content must maintain a strong relevance to the overall reasoning framework. If these conditions are not satisfied, the associative content for the node can be left empty. The above principle will be applied in evaluation stage for evaluating the quality of associative memory.
%In essence, the primary criterion for the associative mechanism is to ensure that its inclusion yields a net positive impact on the reasoning process, encapsulated in the principle of being ``better than worse.''

% The associative memory mechanism refers to the proactive identification of new information, derived from the existing generated content, that can aid the reasoning process while avoiding redundancy with previous nodes.  Such information should neither heavily overlap with the generated content nor be excessively verbose, as both can hinder the reasoning process.  Furthermore, the associative content must be closely related to the overall reasoning process.  If the above conditions cannot be met, the associative content for the current node may remain empty.  Thus, the core principle of the associative mechanism is to prioritize quality over quantity.

% The associative memory mechanism expresses new content that is helpful to reasoning and has not been mentioned in the historical nodes. This part of content should not have a lot of repetition with the generated content, and should not be too long and affect the normal reasoning of the generated content. Meanwhile, the associative subject must be closely related to the whole reasoning process. If the above conditions cannot be met, the associative content of this node can be empty, that is, the key criterion of the associative mechanism is "better than worse".

When generating the associative memory of a node $n_i$, the ``External Brain'' can serve as an alternative approach to enhance the quality of inference results. However, this approach may reduce the inference efficiency. This process can be summarized as follows:
\begin{align}
    \mathcal{AM}(n_i) = \mathbb{EB} \mapsto \mathcal{LLM}(Q~|~\mathcal{G}(n_i)).
\end{align}
where $\mathcal{G}(n_i)$ denotes the generated content of node $n_i$ and $\mathbb{EB}$ is the External Brain of target LLM.

Then, a node can reference both the historical content and the associative memories derived from all of its ancestral nodes. Their historical content and associative content together constitute the comprehensive thinking process of the target LLM. The generation process of each node $n_{i+1}$ is formulated as follows:
\begin{align}
    \mathcal{G}(n_{i+1}) = \mathcal{LLM}(Q~|~\mathcal{G}(n_i)~|~\mathcal{AM}(n_{1:i})).
\end{align}
where $Q$ is the input query and $\mathcal{AM}(n_{1:i})$ denotes the associative memories of nodes $n_1\sim n_i$ in the reasoning trajectory.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\linewidth]{image/mcts.jpg}
    \caption{The optimized MCTS process in our CoAT framework. The Association stage was first proposed to simulate the human ability to think associatively.}
    \label{fig:mcts}
\end{figure}


\subsection{Optimized MCTS}

The standard process of the MCTS algorithm consists of four stages: Selection, Expansion, Simulation, and Backpropagation. In the selection stage, MCTS applies UCT algorithm (Upper Confidence bounds applied to Trees)~\cite{kocsis2006bandit} to choose the best node and then adds it to the trajectory. The UCT of a node $n$ is calculated as follows:
\begin{align}
    UCT(n) = V(n) + w\sqrt{\frac{lnN(p)}{N(n)}}.
\end{align}\label{eq:uct}
where $N(n)$ is the number of visits to the node $n$, $V(n)$ is the score value of node $n$, $w$ is the exploration weight, and $p$ is the parent node of $n$. When the end of an episode is reached, a back-propagation is carried out to update the value of node $n$ and its parent nodes.

The traditional MCTS algorithm has demonstrated significant success across various decision-making domains. Recently, with the advancements in LLM, numerous novel variants of MCTS have been proposed to enable more effective integration with LLMs. The work of LATS~\cite{zhou2023language} introduces an Evaluation stage after Expansion and a Reflection stage at the end of the process. The evaluation stage assesses the quality of the content generated during the expansion stage, while the reflection stage determines whether the outputs correctly address the inputs. Building on these improvements, we propose an Association stage to simulate the human associative mechanism between the expansion and evaluation stages. The optimized MCTS process is shown in Figure~\ref{fig:mcts}. Consequently, the quality of the associative content is also assessed during the evaluation stage.
The evaluation criteria encompass both the quality of the associative content and its correlation with the content generated during the expansion stage, with the goal of preventing excessive associations and mitigating hallucinations.
% and the evaluation criteria include the quality of the associative content and its correlation with the content generated in the expansion stage, aiming to prevent excessive association and hallucination.
Now, the evaluation value of each node $n$ has two components: the generated content value and the associative content value. And the node value is calculated as follows:
\begin{align}
    V(n) = \mathcal{F}_g(Q, ~\mathcal{G}(n)) + \beta*\mathcal{F}_a(\mathcal{G}(n), ~\mathcal{AM}(n)).
\end{align}\label{eq:node-value}
where $\mathcal{G}(n)$, $\mathcal{AM}(n)$ denotes the generated content and the associative content at node $n$, respectively. $\mathcal{F}$ is the evaluation function for generation and association. $\beta$ is the weight to balance the impact factor of the associative content.

In the backpropagation stage, we update the visit counts and quality evaluations for every node along the trajectory based on the outcomes of the simulation stage from the leaf node to the root node. The calculation of visit counts is formalized as $C(n_{i+1}) = C(n_i) + 1$. And the quality evaluation value of a parent node $n_p$ will be updated with its children nodes $n^i_c$ as follows: 
\begin{align}
    V(n_p)^* = \frac{V(n_p)*C(n_p) + \sum_i^K{V(n^i_c)}}{C(n_p)+K}.
\end{align}\label{eq:update-value}
where $K$ is number of candidate nodes of each parent node, $C(n_p)$ is the original visit counts of $n_p$. The updated node value $V(n_p)^*$ is used in the UCT algorithm (Eq.~\ref{eq:uct}) to choose trajectory node in the next selection stage.

To more precisely determine when to terminate the MCTS search process, we trained a specialized Reward Model ($\mathcal{RM}$) to evaluate the content generated at the leaf node of the search trajectory. In certain extreme cases, the search process may enter an ambiguous state, leading to inefficiencies. To mitigate this issue, we introduce a hyper-parameter ($D$) to constrain the maximum depth of the tree search. When the search depth surpasses $D$, the process halts, and the best inference result obtained up to that point is returned. Notably, setting $D=-1$ removes any depth limitation, allowing the search to continue until the optimal result is identified. The above algorithm flow can be summarized as Algorithm~\ref{alg:coat}.

% \subsection{Search Node Setting}
\begin{algorithm}[h]
    \caption{CoAT Reasoning Algorithm}
    \label{alg:coat}
    \textbf{Require}: Input query ($Q$), Evaluate function ($\mathcal{F}$), Reward Model ($\mathcal{RM}$), Number of candidate nodes ($K$), Search Depth ($D$), Exploration weight ($w$), $\mathcal{AM}$ impact factor ($\beta$)
    \begin{algorithmic}[1] %[1] enables line numbers
        \STATE Initialize: Root node $n\leftarrow{(\mathcal{G}, \mathcal{AM})}$, $d\leftarrow{1}$ %, and $K$, $w$, $\beta$.
        \STATE Judge: $\mathcal{RM}(\mathcal{G})$ is completed for $Q$.
        \WHILE{Uncompleted \textbf{and} $d<D$}
        \STATE Selection: choose the best trajectory by UCT.
        \FOR{Child Node $i\leftarrow{1,...,K}$}
        \STATE Generation ($\mathcal{G^*}$): $n_i\leftarrow{\mathcal{LLM}(Q|\mathcal{G}|\mathcal{AM})}$.
        \STATE Association ($\mathcal{AM^*}$): $n_i\leftarrow{\mathcal{LLM}(Q|\mathcal{G^*})}$.
        \STATE Evaluation ($V$): $n_i\leftarrow{\mathcal{F}(Q,\mathcal{G^*}) + \beta\mathcal{F}(\mathcal{G^*},\mathcal{AM^*})}$.
        \ENDFOR
        \STATE Judge: $\mathcal{RM}(\mathcal{G^*})$ of best child is completed for $Q$.
        \IF {Completed}
        \STATE \textbf{return} $\mathcal{G^*}$.
        \ELSE
        \STATE Backpropagation: value of $n_p\leftarrow{Eq.~\ref{eq:update-value}}$.
        \STATE Update: visit ($V^*$) of $n_p\leftarrow{C(n_p)+K}$.
        \STATE Update: $d\leftarrow{d + 1}$.
        \ENDIF
        \ENDWHILE
        \STATE \textbf{return} $\hat{\mathcal{G}}$ of best trajectory.
    \end{algorithmic}
\end{algorithm}


% \subsection{The Routing Strategy}

% $\mathcal{TODO:}$ introduce the node choice?


\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{image/res_compare.jpg}
    \caption{The qualitative results of Qwen2.5-32B-Instruct, chatGPT (APP) and Qwen2.5-32B-Instruct model with our CoAT framework in a complex reasoning query which need rich associative knowledge. The important contents have been highlighted.}
    \label{fig:quality-compare}
\end{figure*}


\section{Experiments}

% The implementation of our CoAT framework is built upon $\bf{LangChain}$ project.
% More experimental results can be found in supplementary materials.
% And we apply the OpenCompass~\cite{2023opencompass} project to evaluate the quantitative performance for each task. The models compared are all accessed by OpenAI REST API style with the support of vLLM framework~\cite{kwon2023efficient}.
The implementation of our CoAT framework is built upon the $\bf{LangChain}$ project, which provides a robust foundation for developing language model pipelines.
To quantitatively evaluate the performance of our framework on various tasks, we leverage the OpenCompass~\cite{2023opencompass} project, a comprehensive benchmarking initiative for language model evaluation.
The compared models are accessed via OpenAI-compatible APIs, with the vLLM~\cite{kwon2023efficient} framework enabling efficient API integration and execution.
% To evaluate the effectiveness of our CoAT framework, we constructed two series of validation experiments in which the framework applies external knowledge or not.
To assess the effectiveness of our CoAT framework, we designed two series of validation experiments: (a) evaluating the qualitative performance of our framework when integrated with LLMs; (b) analyzing the quantitative performance of our framework with other related enhancing reasoning methods.

\subsection{Qualitative Performance Evaluation}

In this section, we conduct a set of complex query questions that require more extensive knowledge in order to fully answer them. 
One of the most representative cases is shown in Figure~\ref{fig:quality-compare}.

As shown in the results, the output content of Qwen2.5-32B with our CoAT framework has the richest content both in terms of text volume and text coverage. Compared to the contents of Qwen2.5-32B and chatGPT, our generated content has the supernumerary category ``Ethical and Regulatory Frameworks'' which is important for AI research. Meanwhile, the content of our framework in each category is more abundant than the other two models.

\subsection{Quantitative Performance Evaluation}

In this section, we will verify the validity of our CoAT framework in two aspects. (a) We compare the base models reasoning through the CoAT framework with other retrieval-augmented methods. (b) We compare a base model reasoning through the CoAT framework with its fine-tuned model in an explicit field.


\vspace{4pt}
\textbf{Quantitative Performance in RAG Generation}

In this section, we enhance the quality of content generated by the associative mechanism through the integration of extended knowledge, and demonstrate that improving the quality of associative content leads to enhanced reasoning ability in our framework. To validate the effectiveness of CoAT framework for the knowledge-intensive question-answering task, we conduct a series of quantitative comparative experiments based on retrieval-augmented generation.
% we further improve the quality of content generated by associative mechanism by accessing extended knowledge and prove that the reasoning ability of our framework will be further improved when the quality of associative content is improved. To prove this point, we construct a comparative experiment based on retrieval augmented generation.

The compared methods are NativeRAG~\cite{lewis2020retrieval}, IRCoT~\cite{trivedi2022interleaving}, HippoRAG~\cite{gutierrez2024hipporag}, LATS~\cite{zhou2023language}, and KAG~\cite{liang2024kag}. And two widely-used multi-hop QA datasets are HotpotQA~\cite{groeneveld2020simple}, which consists of 113k Wikipedia-based question-answer pairs, and 2WikiMultiHopQA~\cite{ho2020constructing}, which introduces evidence information and contains reasoning paths for multi-hop problems.

\textbf{Settings.}
% For a fair comparison, we follow IRCoT and HippoRAG utilizing a subset of 1,000 questions from each validation set and constructing a retrieval corpus related to selected questions.
To evaluate the QA performance, we adopt two widely used metrics: Exact Match (EM), which measures the percentage of exact matches between predicted and ground-truth answers, and F1 scores, which capture the harmonic mean of precision and recall.
Furthermore, the associative memory is influenced not only by the inherent capabilities of the LLM but also by the quality of retrieval results from external knowledge sources.
The evaluation framework is built on the Github project hotpot\footnote{\url{https://github.com/hotpotqa/hotpot}} and 2wikimultihop\footnote{\url{https://github.com/Alab-NII/2wikimultihop}}, while the parameters of them are all the default values. % The parameter settings of CoAT framework are the same as those in Section~\ref{sec:exp-coat}.
% The experimental results are shown in Table~\ref{tab:quan-rag-gen}.

% \begin{table}[h]
%     \centering
%     \begin{tabular}{c|c|c}
%         \toprule
%         Models  & HotpotQA & 2WikiMultiHopQA \\
%         \midrule
%         NativeRAG & 0.1 & 0.1 \\
%         IRCoT & 0.1 & 0.1 \\
%         LATS & 0.1 & 0.1 \\
%         HippoRAG & 0.1 & 0.1 \\
%         KAG & 0.1 & 0.1 \\
%         Qwen2.5-32B + ER & 0.1 & 0.1 \\
%         \bottomrule
%     \end{tabular}
%     \caption{The performance of various retrieval augmented generation methods and the Qwen2.5-32B-Instruct model, integrated with our CoAT framework, in the knowledge-intensive question-answering tasks using open-source datasets.}
%     \label{tab:quan-rag-gen}
% \end{table}


% As the quantitative results show, 

\vspace{4pt}
\textbf{Quantitative Performance in Code Generation}

In this section, we compare the base models (Qwen2.5-7B-Instruct, Qwen2.5-14B-Instruct) reasoning through the CoAT framework with its fine-tuned models (Qwen2.5-Coder-7B-Instruct, Qwen2.5-Coder-14B-Instruct) in code generation task on some open-source datasets, such as HumanEval~\cite{chen2021codex}, MBPP~\cite{austin2021program}, and HumanEval-X~\cite{zheng2023codegeex}.


% ##############################
% To assess the effectiveness of our CoAT framework, we designed two series of validation experiments: (a) evaluating the effectiveness of our framework when integrated with LLMs; (b) analyzing the performance of the framework in conjunction with external knowledge.

% in which our framework applies external knowledge or not.
%: one in which the framework incorporates external knowledge, and another in which it operates without external knowledge. This comparative setup highlights the impact of external knowledge integration on the framework’s performance.


% \subsection{Effectiveness of the CoAT framework}

% In this section, we verify the validity of our framework by integrating it with several open-source LLMs, without utilizing external knowledge.
% % This evaluation is conducted from three key perspectives.
% Our CoAT framework, designed as an enhanced reasoning framework, is assessed in two primary tasks: (1) its qualitative and quantitative performance in reasoning tasks and (2) its quantitative performance in code generation tasks. These results aim to highlight its potential advantages in these domains.

% \vspace{4pt}
% % \textbf{Qualitative Performance in Reasoning}
% \textbf{Qualitative Performance}

% %\textbf{Setting.}
% Firstly, to evaluate the qualitative reasoning performance of models on complex problems, we designed a representative set of prompts targeting deeper reasoning abilities.
% The models compared in this section are Llama3.3-70B-Instruct, Qwen2.5-72B-Instruct, GPT-4o, GPT-o1-preview and Qwen2.5-32B-Instruct integrated with our CoAT, selected for their state-of-the-art performance and widespread adoption in contemporary research.
% The detailed experimental results, including key contents, are presented in Figure~\ref{fig:quality-compare}.
% %The compared methods are Llama3.3-70B-Instruct, Qwen2.5-72B-Instruct, GPT-4o and GPT-o1-preview. The qualitative results are shown in Figure~\ref{fig:quality-compare}.

% The results of the qualitative analysis suggest that a model with fewer parameters, when combined with our CoAT framework, 
% could outperform existing mainstream models in certain scenarios.
% In prompt Q1:, 
% In prompt Q2:, 
% In prompt Q3:, 


% \vspace{4pt}
% \textbf{Quantitative Performance in Reasoning}

% %\textbf{Setting.}
% Secondly, to assess the effectiveness of our CoAT framework in LLM QA generation tasks, we conducted experiments using several widely recognized quantitative datasets.
% Specifically, we evaluated our framework on the Llama-3.1-8B-Instruct\cite{dubey2024llama} and the Qwen2.5 model family~\cite{yang2024qwen2}.
% The datasets used for evaluation belong to the ``Reasoning'' group of the OpenCompass project~\cite{2023opencompass}, which provides abundant data and calculation metrics for the reasoning task. The datasets are BBH~\cite{suzgun2022challenging}, DROP~\cite{Dua2019DROPAR}, TheoremQA~\cite{chen2023theoremqa}, PIQA~\cite{bisk2019piqa}, HellaSwag~\cite{zellers2019hellaswag}, and SIQA~\cite{sap2019socialiqa}.

% \textbf{Setting.}\label{sec:exp-coat}
% All the models used for comparison were deployed using the vLLM framework, which provides API services for evaluation within the OpenCompass platform. In the CoAT framework, the number of candidate nodes is set to $K=5$, and the maximum depth sets to $D=-1$.
% % The OpenCompass parameters for each task, including \texttt{reader\_cfg}, \texttt{infer\_cfg}, and \texttt{eval\_cfg}, are kept at their default values for all models.
% The OpenCompass parameters for each task, which include \texttt{reader\_cfg}, \texttt{infer\_cfg}, and \texttt{eval\_cfg}, are retained at their default values as specified in the \texttt{\{dataset\}\_gen.py} configuration file.
% % \texttt{opencompass.configs.datasets.\{dataset\}.\\\{dataset\}\_gen.py}.
% These settings are consistent across all models.
% Specifically, the \texttt{retriever} parameter in \texttt{infer\_cfg} is preferred to \texttt{ZeroRetriever}.
% % The \texttt{configs} of each datasets is the ``gen'' mode.
% Additionally, we did not adjust the most task-specific input prompts for each model, and therefore the results may differ from their official performance data. The detailed experimental results are shown in Table~\ref{tab:quan-qa-gen}.


% \begin{table*}[h]
%     \centering
%     \begin{tabular}{lccccccc}
%         \toprule
%         Models  & GSM8K & BBH & DROP & TheoremQA & PIQA & HellaSwag & SIQA \\
%         \midrule
%         Llama3.1-8B & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%         Llama3.1-8B+ER & 0.2 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%         \midrule
%         Qwen2.5-7B & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%         Qwen2.5-7B+ER & \underline{0.1} & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%         \midrule
%         Qwen2.5-14B & 0.2 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%         Qwen2.5-14B+ER & \bf{0.2} & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%         \midrule
%         Qwen2.5-32B & 0.2 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%         Qwen2.5-32B+ER & \bf{0.2} & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%         \bottomrule
%     \end{tabular}
%     \caption{The performance of open source models with our CoAT framework or not in QA generation tasks on open source datasets. All models are $\textit{Instruct}$ mode. The number with $\bf{bold}$ and $\underline{underline}$ denotes the best and second best on this task.}
%     \label{tab:quan-qa-gen}
% \end{table*}

% The quantitative results show that 


% \vspace{4pt}
% \textbf{Quantitative Performance in Code Generation}

% % \textbf{Setting.}
% Thirdly, to demonstrate that our framework possesses broader reasoning enhancement capabilities beyond reasoning tasks, we conducted quantitative experiments in the code generation domain. The evaluation was performed on three widely used datasets in this field: HumanEval~\cite{chen2021codex}, MBPP~\cite{austin2021program}, and HumanEval-X~\cite{zheng2023codegeex}. Specifically, HumanEval-X consists of 820 high-quality human-crafted data samples in Python, C++, Java, JavaScript, and Go.
% For evaluation, we used Python, C++, and JavaScript as the primary metrics, and also computed their average performance.
% % To evaluate the effectiveness of our CoAT framework in LLM Code generation tasks, 
% % We performed experiments on three widely used quantitative datasets: HumanEval, MBPP, and HumanEval-X.
% For comparison, we include the following models: Qwen2.5-7B-Instruct, Qwen2.5-14B-Instruct, Qwen2.5-Coder-7B-Instruct, Qwen2.5-Coder-14B-Instruct, and their variants integrated with our CoAT framework.
% The parameter settings for this task are the same as those in the previous section and the experimental results are shown in Table~\ref{tab:quan-code-gen}.


% \begin{table}[h]
%     \centering
%     \resizebox{\linewidth}{!}{
%         \begin{tabular}{c|c|c|cccc}
%             \toprule
%             \multirow{2}{*}{Models}  & \multirow{2}{*}{HumanEval} & \multirow{2}{*}{MBPP} & \multicolumn{4}{c}{HumanEval-X} \\
%               &  &  & python & js & cpp & avg \\
%             \midrule
%             7B & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%             $\triangle$ + ER & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%             Coder-7B & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%             $\triangle$ + ER & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%              \midrule
%             14B & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%             $\triangle$ + ER & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%             Coder-14B & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%             $\triangle$ +ER & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 0.1 \\
%             \bottomrule
%         \end{tabular}
%     }
%     \caption{The performance of Qwen models with our CoAT framework or not in code generation tasks on open source datasets. All models are $Qwen2.5$-{$Models$}-$\textit{Instruct}$ series, and $\triangle$ represents the model above.}
%     \label{tab:quan-code-gen}
% \end{table}

% From the Table~\ref{tab:quan-code-gen}, we can see that


% % \subsection{Effectiveness of Associative Memory Mechanisms}
% \subsection{the CoAT Performance with Knowledge Graph}

% In this section, we enhance the quality of content generated by the associative mechanism through the integration of extended knowledge, and demonstrate that improving the quality of associative content leads to enhanced reasoning ability in our framework. To validate the effectiveness of CoAT framework for the knowledge-intensive question-answering task, we conduct a series of quantitative comparative experiments based on retrieval-augmented generation.
% % we further improve the quality of content generated by associative mechanism by accessing extended knowledge and prove that the reasoning ability of our framework will be further improved when the quality of associative content is improved. To prove this point, we construct a comparative experiment based on retrieval augmented generation.

% The compared methods are NativeRAG~\cite{lewis2020retrieval}, IRCoT~\cite{trivedi2022interleaving}, HippoRAG~\cite{gutierrez2024hipporag}, LATS~\cite{zhou2023language}, and KAG~\cite{liang2024kag}. And two widely-used multi-hop QA datasets are HotpotQA~\cite{groeneveld2020simple}, which consists of 113k Wikipedia-based question-answer pairs, and 2WikiMultiHopQA~\cite{ho2020constructing}, which introduces evidence information and contains reasoning paths for multi-hop problems.

% \textbf{Settings.}
% For a fair comparison, we follow IRCoT and HippoRAG utilizing a subset of 1,000 questions from each validation set and constructing a retrieval corpus related to selected questions.
% To evaluate the QA performance, we adopt two widely used metrics: Exact Match (EM), which measures the percentage of exact matches between predicted and ground-truth answers, and F1 scores, which capture the harmonic mean of precision and recall.
% Furthermore, the associative memory is influenced not only by the inherent capabilities of the LLM but also by the quality of retrieval results from external knowledge sources.
% The evaluation framework is built on the Github project hotpot\footnote{\url{https://github.com/hotpotqa/hotpot}} and 2wikimultihop\footnote{\url{https://github.com/Alab-NII/2wikimultihop}}, while the parameters of them are all the default values. The parameter settings of CoAT framework are the same as those in Section~\ref{sec:exp-coat}. The experimental results are shown in Table~\ref{tab:quan-rag-gen}.


% \begin{table}[h]
%     \centering
%     \begin{tabular}{c|c|c}
%         \toprule
%         Models  & HotpotQA & 2WikiMultiHopQA \\
%         \midrule
%         NativeRAG & 0.1 & 0.1 \\
%         IRCoT & 0.1 & 0.1 \\
%         LATS & 0.1 & 0.1 \\
%         HippoRAG & 0.1 & 0.1 \\
%         KAG & 0.1 & 0.1 \\
%         Qwen2.5-32B + ER & 0.1 & 0.1 \\
%         \bottomrule
%     \end{tabular}
%     \caption{The performance of various retrieval augmented generation methods and the Qwen2.5-32B-Instruct model, integrated with our CoAT framework, in the knowledge-intensive question-answering tasks using open-source datasets.}
%     \label{tab:quan-rag-gen}
% \end{table}


% As the quantitative results show, 

% #####################################

% \textbf{Datsets.} To evaluate the effectiveness of CoAT for knowledge-intensive question-answering
% task, we perform experiments on 3 widely-used multi-hop QA datasets, including \textbf{HotpotQA}~\cite{groeneveld2020simple}, \textbf{2WikiMultiHopQA}~\cite{ho2020constructing}, and \textbf{MuSiQue}~\cite{trivedi2022musique}. For a fair comparison, we follow IRCoT~\cite{trivedi2022interleaving} and HippoRAG~\cite{gutierrez2024hipporag} utilizing 1,000 questions from each validation set and using the retrieval corpus related to selected questions.

% \textbf{Evaluation Metric.} When evaluating QA performance, we use two metrics: Exact Match (EM) and F1 scores.
% % For assessing retrieval performance, we calculate the hit rates based on the Top 2/5 retrieval results, represented as Recall@2 and Recall@5.

% \textbf{Comparison Methods.} We evaluate our approach against several robust and commonly utilized retrieval RAG methods, including NativeRAG, HippoRAG, IRCoT and KAG.

% \textbf{NativeRAG} 
% using ColBERTv2 as retriever and directly generates answers based on all retrieved documents. 
% \textbf{HippoRAG}
% is a RAG framework inspired by human long-term memory that enables LLMs to continuously integrate knowledge across external documents. In this paper, we also use ColBERTv2 as its retriever. 
% \textbf{IRCoT} 
% interleaves chain-ofthought (CoT) generation and knowledge retrieval steps in order to guide the retrieval by CoT and vice-versa. This interleaving allows retrieving more relevant information for later reasoning steps. It is a key technology for implementing multi-step retrieval in the existing RAG framework.

% \begin{table}[h]
%     \centering
%     \resizebox{\linewidth}{!}{
%         \begin{tabular}{c|c|c|c}
%             \toprule
%             Models  & HotpotQA & 2WikiMultiHopQA & MuSiQue \\
%             \midrule
%             NativeRAG & 0.1 & 0.1 & 0.1 \\
%             IRCoT & 0.1 & 0.1 & 0.1 \\
%             LATS & 0.1 & 0.1 & 0.1 \\
%             HippoRAG & 0.1 & 0.1 & 0.1 \\
%             KAG & 0.1 & 0.1 & 0.1 \\
%             Qwen+ER & 0.1 & 0.1 & 0.1 \\
%             \bottomrule
%         \end{tabular}
%     }
%     \caption{The performance of various retrieval augmented generation methods and the Qwen2.5-32B-Instruct model, integrated with our CoAT framework, in external knowledge generation tasks using open-source datasets.}
%     \label{tab:quan-rag-gen}
% \end{table}


\section{Conclusion}

In this paper, we proposed the Chain-of-Associated-Thoughts (CoAT) framework, which advances LLM reasoning by integrating an optimized Monte Carlo Tree Search (MCTS) algorithm and a dynamic associative memory mechanism. These innovations enable structured exploration of reasoning pathways and adaptive knowledge updating, addressing limitations of traditional LLMs. Extensive experiments demonstrated that our CoAT outperforms conventional approaches in accuracy, coherence, and diversity. Our work highlights the potential of combining structured search and adaptive associative memory in LLMs, offering a new exploration for future research on integrating external real-time knowledge for real-world applications.



%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{ijcai24}

\end{document}

