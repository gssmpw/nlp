\section{Related Work}
\subsection{Teamwork in Healthcare}

Patients encounter preventable harms in healthcare, such as unexpected infection and errors in diagnosis, medication, and surgery \cite{panagioti2019prevalence}. 
To ensure safe and high-quality care delivery, it is important to establish efficient teamwork to clarify roles and responsibilities and communicate medical information \cite{barnard2020communication}. 
However, such efforts are consistently challenged by chaotic and overcrowded clinical environments \cite{ahmadpour2021efficiency}, insufficient patient information \cite{bossen2014physicians}, and intensive workloads of HCWs \cite{pine2018data}. 
Especially in critical care delivery, HCWs experience physical, mental, and emotional fatigue under time-sensitive medical procedures \cite{welp2016interplay}. 
Moreover, the power dynamics within the team can discourage members from speaking up even in cases where evidence-based treatment protocols are violated \cite{li2018organizational}.
Therefore, supportive sociotechnical systems are needed to facilitate the cooperation of HCWs and improve patient safety.
Macrocognition and distributed cognition frameworks help researchers explore the complexities of team dynamics. Macrocognition highlights how teams perform cognitive work in dynamic environments through shared mental models and situational awareness \cite{mastrianni2022alerts}, while distributed cognition reveals how team members, tools, and the environment share critical information \cite{sarcevic2011coordinating, zhang2022designing}.
HCI researchers have explored technological solutions to enhance medical teamwork. 
For example, Jagannath and colleagues \cite{jagannath2019temporal} examined the use of an electronic flowsheet in medical resuscitations and suggested aligning the flowsheet with the actual flow of medical activities to improve real-time communication. 
Emerging technologies such as AR have revolutionized how information is collected and displayed, paving the way for a more promising future for medical teamwork. 
Yet, thereâ€™s a scarce understanding of how to best integrate these technologies into acute care team settings.


%\sout{AR-HMDs are continuously evolving, enhancing the immersive experience for users through a variety of input modalities such as speech, gesture, and gaze}. \sout{Each modality offers distinct advantages that fit a particular application and improve human-human interactions in the environment. For example, recent advancements in holographic optical elements (HOEs) and lithography-enabled devices have enabled significant improvements in display resolution and field of view, which were challenging aspects of traditional AR-HMDs. } \sout{These developments not only enhance the overall performance of AR-HMDs but also significantly improve the immersive experience \cite{xiong2021augmented}.} \sout{Additionally, current sensor technology improvements have made gesture and eye-tracking inputs more accurate and sensitive.} \sout{This progress is illustrated by the development of specialized tools such as the Augmented Reality Eye Tracking Toolkit (ARETT) which integrates eye trackers into AR-HMDs }\cite{adhanom2023eye, kapp2021arett}\sout{, and ARKit and ARCore which are popular open-source libraries to display virtual objects \cite{oufqir2020arkit}, thereby improving user interaction }\cite{jain2023ubi}.

%\sout{Recent successes in multimodal interaction methods in AR-HMDs, integrating multiple input modalities, are gaining popularity as evidenced by studies such as Gesture-Speech Integration \cite{piumsomboon2014grasp} and GazePointAR \cite{lee2023towards}. These studies show that a combination of free-hand gestures and speech, or utilizing eye gaze and pointing, can improve how users interact depending on the context. Additionally, Wang et al. \cite{wang2019exploring} have shown that the representation of virtual agents plays a key role in AR by affecting user choices and preferences.} \sout{Additionally, intuitive AR-HMD text input techniques, such as taps on skin \cite{kim2023star}, finger touches on skin }\cite{xu2019tiptext, xu2020bitiptext}\sout{, and eye tracking combinations }\cite{lu2021itext, cui2023glancewriter}\sout{ by users, demonstrate efficiency and contribute significantly to user interface design improvements in AR-HMDs.} \sout{Despite these advancements, there is still a significant research gap in AR-HMD applications for collaborative, time-sensitive, high-risk settings, and in workplaces \cite{gower2022utilizing}.} % taken

%\sout{In an attempt to improve team collaboration during time-sensitive work tasks, several AR-HMD options that utilize multiple input modalities have been explored. While the display options may showcase a variety of information, the display should always act as a notification, providing the user with necessary information that they can appropriately respond to.} \sout{It was found that both visual and auditory notifications provide high recognition rates, with the most frequent input modality choice being speech ~\cite{lazaro2021interaction}.} % this line taken from here to 2.3 \sout{This finding corresponds with other studies demonstrating that a combination of input modality options is often superior to one input modality, utilizing gaze, gesture, and speech ~\cite{wang2021interaction}.}\sout{Further, while the types of input modalities included are crucial, it is also important to recognize the placement of displays, not to distract users from their time-sensitive task but to provide them with the required information. }%taken \sout{We found that the least distracting position is the bottom center of the user's field of view and that wrist attachment is recommended when there is a high amount of AR-HMD interaction \cite{plabst2022push}.} %taken \sout{While there are many design implications beyond input modalities and placement, such as color and size, designing an intuitive display option would considerably improve human-human interaction.}

%\sout{Integrating AR-HMDs into real-world scenarios has become more straightforward due to the advancements of SDKs and development environments. Platforms such as Sketchbox allow for simple deployment of advanced AR-HMD environments \cite{SketchboxLeadingVirtual}. This allows for more focus on important design concepts such as the visual interfaces and interactions. %Conceptualizing AR-HMDs as a series of micro-interactions is a powerful tool for improving user-centered design where users take subtle actions that the headset can interpret to display relevant information. While AR-HMDs are more accessible than ever, designing polished applications with well-defined micro-interactions is crucial for the adoption of AR devices. Researchers must carefully develop AR-HMD applications for healthcare workers in time-sensitive, high-stakes environments to improve outcomes while maintaining effective teamwork and performance and avoid introducing new medical errors.}


%\end{comment}

\subsection{Augmented Reality in Healthcare}

AR-HMDs have demonstrated significant potential in healthcare through visualization of medical processes \cite{huang2018use}, delivery of real-time medical information \cite{wang2015real, jayaprakash2019asthma}, and navigation of human anatomy \cite{lungu2021review}. Technological advances in holographic optical elements and lithography-enabled devices have enhanced display resolution and user experience, improving medical visualization quality \cite{xiong2021augmented}. In medical education, interactive AR-HMD simulations outperform traditional methods for teaching surgical anatomy \cite{siff2018interactive, lungu2021review}. For surgical applications, AR-HMDs assist decision-making by overlaying medical history and dimensional data onto surgical areas, helping guide procedures such as cutting angles \cite{pokhrel2019novel}. AR-HMDs enhance telemedicine capabilities by enabling specialists to remotely monitor patients' vital signs, capture 3D anatomical data, and provide real-time visual guidance and annotations \cite{anton2017augmented, wang2021ar}. AR-HMDs have advanced telemedicine by enabling specialists to monitor vital signs and provide real-time feedback in remote settings \cite{wang2021ar, anton2017augmented}. In addition to what information to show, work has been done exploring how to design well-contextualized AR-HMD visualizations \cite{PlabstVisualisation2021}. Integrating speech, gesture, and gaze inputs \cite{liao2022realitytalk, muller2023tictactoes} enhances medical application control and healthcare team collaboration. Studies demonstrate these multi-modal interfaces significantly outperform single-mode systems \cite{wang2021interaction}, with clinicians achieving high recognition rates through combined visual and auditory notifications \cite{lazaro2021interaction}. To optimize clinical usability, research recommends bottom-center or wrist-mounted displays during frequent AR-HMD interactions \cite{plabst2022push}. While these devices show promise in applications like CPR training \cite{semeraro2013motion, almousa2019virtual, balian2019feasibility, siebert2017adherence}, their potential for team communication in critical care scenarios remains largely unexplored \cite{gower2022utilizing}. Furthermore, while each of these AR-HMDs is useful depending on the needs of the healthcare team, improving team collaboration through AR interfaces has received limited attention. Therefore, this study aimed to bridge this research gap by conducting a co-design study with medical professionals to explore how AR could enhance medical teamwork in acute care settings. 

%AR-HMDs are gaining attention from healthcare researchers for its innovation in merging the boundary of the virtual world and the real world, hence facilitating visualization of medical processes \cite{huang2018use}, delivery of real-time medical information \cite{wang2015real, jayaprakash2019asthma}, and navigation of human anatomy \cite{lungu2021review}. In addition to what information to show work has been done exploring how to design well-contextualized AR-HMD visualizations \cite{PlabstVisualisation2021}.These applications have become increasingly feasible due to the ongoing shift in AR-HMD technology, with recent advances in holographic optical elements and lithography-enabled devices enabling significant improvements in display resolution in users' field-of-view. This progress improves both the overall performance of AR-HMDs and the immersive experience of users \cite{xiong2021augmented}. Advanced SDKs and tools like Sketchbox have simplified AR-HMD integration, enabling researchers to focus on interface and interaction design, enabling faster and more robust ideation  \cite{SketchboxLeadingVirtual}. A great body of literature has demonstrated AR for different domains of healthcare such as acquiring and sharing skills and knowledge. For example, Siff and Mehta \cite{siff2018interactive} introduced MS HoloLens for creating 3D-projected organ simulations in training modules. Their research revealed that participants not only demonstrated improved comprehension of surgical anatomy but also evaluated the AR-HMD training as superior to conventional methods. In clinical practice, AR-HMDs offer a digital overlay of information that enhances surgical precision and minimizes risks. Pokhrel and colleagues \cite{pokhrel2019novel} found that by presenting the medical history and dimensional information of the surgical area, AR-HMDs can facilitate surgical decisions such as cutting angles. To support these clinical applications, integration of multiple input modalities such as speech, gesture, and gaze \cite{liao2022realitytalk, muller2023tictactoes}, provides distinct advantage and flexibility in adapting medical applications and improves human-human interactions in healthcare settings. The effectiveness of these systems depends heavily on their implementation. While the display options may showcase various information, the display should always act as a notification, providing the user with the necessary information to respond appropriately. This finding corresponds with other studies demonstrating that combining input modality options is often superior to one input modality, utilizing gaze, gesture, and speech ~\cite{wang2021interaction}. While the display options may showcase a variety of information, the display should always act as a notification, providing the user with necessary information that they can appropriately respond to. It was found that both visual and auditory notifications provide high recognition rates, with the most frequent input modality choice being speech ~\cite{lazaro2021interaction}. Further, while the types of input modalities included are crucial, it is also important to recognize the placement of displays, not to distract users from their time-sensitive task but to provide them with the required information. We found that the least distracting position is the bottom center of the user's field of view and that wrist attachment is recommended when there is a high amount of AR-HMD interaction \cite{plabst2022push}. Beyond in-person clinical applications, AR paved the way for new types of telemedicine to address medical issues in rural and remote areas \cite{wang2021ar}. Through AR-HMD platforms, the experienced specialist could capture 3D body information and vital signs (e.g., heart rate and blood pressure) of the patient and then give real-time feedback and visual annotation \cite{anton2017augmented}.

%While AR-HMDs have grasped the attention of providing unique learning experiences of human anatomy and being able to communicate health problems via telemedicine, there is a lack of using the device to support team communication and collaboration in healthcare settings. This gap is particularly notable in critical care scenarios, where team coordination is crucial. Specific to cardiac arrest situations, it is recognized that AR-HMDs have been very beneficial in providing guidelines on how to appropriately provide cardiopulmonary resuscitation (CPR) ~\cite{semeraro2013motion, almousa2019virtual}.These studies showcase typical AR-HMDs with insight into related measures such as rate, depth, and recoil, perhaps with the help of additional hardware to track these measures. Other studies observing the influence of AR on CPR training have also previously shown the patient's general anatomy ~\cite{balian2019feasibility} and cardiac arrest procedural steps ~\cite{siebert2017adherence}. Displaying the procedural steps following the AHA guidelines through an augmented display rather than a paper copy may be the most applicable application that improves healthcare collaboration as it has the opportunity to eliminate distractions and maintain focus on the patient. Despite these advancements, there is still a significant research gap in AR-HMD applications for collaborative, time-sensitive, high-risk settings, and in workplaces \cite{gower2022utilizing}. Furthermore, while each of these AR-HMDs is useful depending on the needs of the healthcare team, improving team collaboration through AR interfaces has received limited attention. Therefore, this study aimed to bridge this research gap by conducting a co-design study with medical professionals to explore how AR could be employed to enhance medical teamwork in acute care settings. 


\subsection{Co-Design with Healthcare Teams}

Researchers have widely used co-design methods to develop effective interventions for specialized teams, such as in medical settings, helping bridge the gap between technological capabilities and clinical needs \cite{mastrianni2023transitioning, hoppchen2024insights, hsieh2023alternatives, shen2023dementia}. Kusunoki et al. \cite{kusunoki2015sketching} described their work as participatory design and conducted workshops with HCWs to optimize display designs that support verbal communication patterns. Similarly, Mastrianni et al. \cite{mastrianni2022alerts} interviewed trauma teams to develop guidelines for decision support alerts, while they explored various systems they primarily focused on digital checklists, wall displays, and audio alerts to improve team coordination without disrupting patient care. %\sout{These \textcolor{blue}{co-design}\sout{participatory} methods help researchers understand the specific requirements of medical teams, from displaying HCWs' role effectively to integrating new tools into existing workflows \cite{sarcevic2011coordinating}. Researchers have explored more advanced medical support platforms as they build on previous work that improves medical workflows \cite{mastrianni2023transitioning}. These co-design studies demonstrate that while AR-HMDs offer benefits, effective design must balance user-friendliness with the hectic emergency room environment. Co-design methods have proven to be a valuable technique to develop AR-HMD solutions for medical teams, as they help bridge the gap between technological capabilities and clinical needs.}
Zhang et al. \cite{zhang2022designing} explored sociotechnical factors affecting smart glass adoption in emergency medical services. %\sout{This perspective emphasizes the importance of considering AR-HMDs implementation's technical and social dimensions in healthcare settings, particularly how new technologies might affect team dynamics and communication patterns.} 
These co-design sessions revealed key considerations around team situational awareness, cognitive load during patient care, and the balance between providing useful information and avoiding information overload \cite{mastrianni2022alerts, kusunoki2015sketching}. 
Through co-design, researchers can better understand how AR solutions need to adapt to different roles within the medical team, from experienced physicians to new nurses, ensuring that the technology supports collaboration \cite{sarcevic2011coordinating, chung2023negotiating}.



\begin{table*}[]
\small
%\scriptsize
\caption{Participant demographic information including the participant ID, age, gender, years of experience, medical specialty, and types of hospitals worked at, including teaching (T), non-teaching (NT), for-profit (FP), non-profit (NT), urban (U), and rural (R).}
\begin{tabular}{
>{\columncolor[HTML]{FFFFFF}}l 
>{\columncolor[HTML]{FFFFFF}}r 
>{\columncolor[HTML]{FFFFFF}}l 
>{\columncolor[HTML]{FFFFFF}}r 
>{\columncolor[HTML]{FFFFFF}}l 
>{\columncolor[HTML]{FFFFFF}}l }
\hline
%\textbf{Participant \#} & \multicolumn{1}{l} \textbf{Age} & 
\textbf{Participant \#} & \textbf{Age} & \textbf{Gender} & \multicolumn{1}{l}{\cellcolor[HTML]{FFFFFF}\textbf{\begin{tabular}[c]{@{}l@{}}Experience \\\end{tabular}}} & \textbf{Specialty}                                  & \textbf{Hospital-Type}  \\  \hline P1            &  53                                                       & M               & 22 years                                                                                                                 & Physician, Pediatric Emergency Medicine             & T, NP, U                \\
P2              &  33                                                       & M               & 1.5 years                                                                                                               & Healthcare Administrator, ICU Nurse                 & FP                      \\
P3                                     & 57                                                                              & M               & 18 years                                                                                                                & MD, Emergency Medicine                              & T, NT, FP, NP, U, R \\
P4                                      & 51                                                                              & F               & 21 years                                                                                                                & Attending, Emergency Medicine                       & T                       \\
P5                                      & 36                                                                              & F               & 8 years                                                                                                                 & MD, Pediatric Emergency Medicine                    & T, NT, NP, U            \\
P6                                      & 37                                                                              & M               & 8 years                                                                                                                 & Director of Clinical Innovation, Emergency Medicine & T                       \\
P7                                      & 32                                                                              & F               & 6 years                                                                                                                 & Registered Nurse                                    & T, NT, FP, NP, U        \\
P8                                      & 66                                                                              & M               & 39 years                                                                                                                & MD, Emergency Medicine                              & T                       \\
P9                                     & 42                                                                              & M               & 8 years                                                                                                                 & Pediatric Emergency Medicine Attending Physician    & T, NT, NP, U            \\
P10               &  38                                                       & M               & 13 years                                                                                                                & Assistant Professor of Emergency Medicine           & T, NP, U                \\ \hline
\end{tabular}
\label{table:demo}
\end{table*}


%%%%%%%%%%%%%%%%
%%%%%
% Section 3: Methodology / Algorithmic Approach / etc
%%%%%