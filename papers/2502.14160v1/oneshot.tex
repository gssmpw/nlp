%\section{Warm-Up: Inverse Game Theory}

\deni{Change One-shot to normal-form}

\amy{when/why was action changed to strategy? i noticed because it says ``an strategy'' all over the place}

\textbf{Normal-form Games. } 
A \mydef{(parametric)
%%% SPACE
%(simultaneous-move) 
game} $\game[][\param] \doteq (\numplayers, \numactions, \numparams, \stratspace, \params, \param, \util)$ 
comprises $\numplayers \in \N_+$ players, each $\player \in \players$ of whom chooses a strategy $\strat[\player] \in \stratspace[\player]$ from an strategy space $\stratspace[\player] \subseteq \R^{\numactions}$ simultaneously.
We refer to any vector of per-player strategies $\strat = (\strat[1], \hdots, \strat[\numplayers]) \in \stratspace$ as a \mydef{strategy profile}, where 
$\stratspace \doteq \bigtimes_{\player \in \players} \stratspace[\player] \subseteq \R^{\numplayers \numactions}$ denotes the space of all strategy profiles.
%
After the players choose their strategies $\strat \in \stratspace$, each receives a payoff $\util[\player](\strat; \param)$ given by payoff function $\util[\player]: \stratspace \times \params \to \R$ parameterized by a vector $\param$ in a parameter space $\params \subseteq \R^\numparams$.
We define the \mydef{payoff profile function} $\util(\strat; \param) \doteq \left( \util[\player](\strat; \param) \right)_{\player \in \players}$;
% The \mydef{best-response correspondence} for player $\player \in \players$ is given by $\br[\player](\strat[-\player]) \doteq \argmax_{\strat[\player] \in \stratspace[\player]} \util[\player](\strat[\player], \strat[-\player])$, and the \mydef{joint best-response correspondence}, by $\br(\strat) \doteq \bigtimes_{\player \in \players} \br[\player](\strat[-\player])$. 
the \mydef{cumulative regret} $\cumulregret[][]: \stratspace \times \stratspace \times \params \to \R$ across all players, between two strategy profiles $\strat, \otherstrat \in \stratspace$, given $\param \in \params$, as $\cumulregret[][] (\strat, \otherstrat; \param) \doteq \sum_{\player \in \players} \util[\player](\otherstrat[\player], \strat[-\player]; \param) - \util[\player](\strat; \param)$;
and the \mydef{exploitability} (or \mydef{Nikaido-Isoda potential} \citep{nikaido1955note}) $\exploit (\strat; \param) \doteq \max_{\otherstrat \in \stratspace} \cumulregret[][] (\strat, \otherstrat; \param)$.

% \samy{}{A utility function is \mydef{monotone} if} \amy{...}.
% \samy{}{A utility function is \mydef{concave} if} \amy{...}.
% \samy{}{A continuous game $\game$ is said to be \samy{}{\mydef{monotone} (resp. \mydef{concave})} if for all players  $\player \in \players$, $\util[\player]$ is \samy{}{monotone (resp. concave)} in $\strat[\player]$ and $\stratspace[\player]$ is convex. \deni{Monotonicity is not a property of one utility function, its a property of the utility functions of all players collectively, see def'n below. Would you still like to reformulate things as they are here?} \amy{NO! sorry. i'll revert back tomorrow.}
% A game is said to be \mydef{strictly} monotone \samy{}{(resp. concave)} if the monotonicity \samy{}{(resp. concavity)} condition holds with strict inequality.}
% 
% \amy{re-insert monotone footnote after the first mention of monotone}

% A game $\game$ is called \mydef{monotone} if in addition to being continuous, for all strategy profiles $\strat, \otherstrat \in \stratspace$, $\sum_{\player \in \players} \left(\grad[{\strat[\player]}] \util[\player](\strat) - \grad[{\strat[\player]}] \util[\player](\otherstrat) \right)^T \left( \strat[\player] - \otherstrat[\player] \right) \leq 0$, and for all players $\player \in \players$, $\stratspace[\player]$ is convex.
%%% SPACE
%\footnote{We call a game monotone if $- (\grad[{\strat[1]}] \util[1], \hdots, \grad[{\strat[\numplayers]}] \util[\numplayers])$ is a monotone operator. Such games are also sometimes called \mydef{dissipative}, since $(\grad[{\strat[1]}] \util[1], \hdots, \grad[{\strat[\numplayers]}] \util[\numplayers])$ is called a dissipative operator if $- (\grad[{\strat[1]}] \util[1], \hdots, \grad[{\strat[\numplayers]}] \util[\numplayers])$ is a monotone operator.} 
% A game is said to be \mydef{strictly monotone} if the monotonicity condition holds with strict inequality.
% 
% A two-player game is called a \mydef{min-max} (or \mydef{zero-sum}) game if for all $\strat \in \stratspace, - \util[1] (\strat[1], \strat[2]; \param[\player]) = \util[2] (\strat[1], \strat[2]; \param[\player]) \doteq \obj[ ] (\strat[1], \strat[2]; \param)$.
% If a zero-sum two-player game $\game$ is concave, then it is called a \mydef{convex-concave min-max game}, 
% in which case we can represent it as the min-max optimization problem $\min_{\strat[1] \in \stratspace[1]} \max_{\strat[2] \in \stratspace[2]} \obj(\strat[1], \strat[2])$, where $\obj$ is convex-concave.
% We note that any monotone game is concave, and a zero-sum game is monotone iff it is concave.

A game is said to be \mydef{concave} if for all parameters $\param \in \params$ and players $\player \in \players$, 1.~$\stratspace[\player]$ is non-empty, compact, and convex, 2.~$\util[\player]$ is continuous, and 3.~$\strat[\player] \mapsto \util[\player](\strat[\player], \strat[-\player]; \param)$ is concave.
Given $\param \in \params$, an $\varepsilon$-\mydef{Nash equilibrium} ($\varepsilon$-NE) of a game $\game[][\param]$ is a strategy profile 
%$\strat[][][*] \in \actions(\strat[][][*])$
$\strat[][][][*] \in \stratspace$ s.t.\ $\util[\player](\strat[][][][*]; \param) \geq \max_{\strat[\player] \in \stratspace[\player]} \util[\player](\strat[\player], \strat[-\player][][][*]; \param) - \varepsilon$, for all players $\player \in \players$.
A $0$-Nash equilibrium is simply called a Nash equilibrium, and
% Any Nash equilibrium $\strat[][][*] \in \actionset$ can be expressed as the fixed point of the joint best-response correspondence, i.e., $\strat[][][*] \in \br(\strat[][][*])$.
is guaranteed to exist in concave games \citep{nash1950existence, arrow-debreu}. 
% , and is guaranteed to be unique in strictly monotone games \citep{rosen1965gne}.

% \deni{Might want to remove this para to decrease confusion.} \amy{not sure what confusion you are referring to. you use $\cumulregret[]$ in Thm 1. so it probably makes sense to define at least that. not sure if you also use exploitability; haven't gotten to it yet.}

\if 0
\deni{Can remove this:}
\amy{BOO! i like it for intuition. but okay, b/c space. :(}
Furthermore, the \mydef{exploitability} or (Nikaido-Isoda potential function \citep{nikaido1955note}) of an strategy profile $\strat \in \stratspace$ can be seen as $\exploit[][] (\strat; \param) = \max_{\otherstrat \in \stratspace} \cumulregret[][] (\strat, \otherstrat; \param)$ \citep{goktas2022exploit}. 
%\amy{i think it's weird to cite us when giving this definition. i think what you mean is: we have a theorem that converts the actual def'n of exploitability to this. hence, ``can be seen as''}
Finally, for all parameters $\param \in \params$ and strategy profiles $\strat \in \stratspace$, $\exploit(\strat; \param) \geq 0$; moreover, $\strat[][][][*]$ is a Nash equilibrium iff $\exploit[] (\strat[][][][*]; \param) = 0$. 
\fi

%\paragraph{Nikaido-Isoda Potential Function}
% Given a game $\pgame$, we define the \mydef{regret} $\regret[][\game]: \innerset \times \innerset \to \R^\numplayers$ felt by any player $\player \in \players$ for an strategy $\inner[\player]$ as compared to another strategy $\otherstrat[\player]$, given the strategy profile $\strat[-\player]$ of the other players, as follows:
% $\regret[\player][\game](\strat, \otherstrat) = \util[\player](\otherstrat[\player], \naction[\player]) - \util[\player](\inner[\player], \naction[\player])$.
% Additionally, the \mydef{cumulative regret}, or the \mydef{Nikaido-Isoda function}, $\cumulregret[][\game]: \innerset \times \innerset \to \R$ between two strategy profiles $\strat \in \actions$ and $\otherstrat \in \actions$ across all players in a game is given by $\cumulregret[][\game](\strat, \otherstrat) = \sum_{\player \in \players} \regret[\player][\game](\inner[\player], \otherstrat[\player]; \naction[\player])$.
% Finally, the \mydef{exploitability}, or \mydef{Nikaido-Isoda \emph{potential\/} function} \citep{nikaido1955note}, $\exploit[][\game]: \innerset \to \R$ of an strategy profile $\strat$ is defined as 
% $\exploit[][\game](\strat) = \max_{\otherstrat \in \innerset} \sum_{\player \in \players} \regret[\player][\game](\strat, \otherstrat)$ \citep{goktas2022exploit}.\footnote{\deni{Add footnote about our exploit min paper}}

% \deni{Might be possible to remove references to exploitability in this section and move them all to the next.}
