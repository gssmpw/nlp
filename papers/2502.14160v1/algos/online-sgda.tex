%%% ONLINE SGDA

\begin{wrapfigure}{L}{0.6125\textwidth}
    \vspace*{-0.8cm}
    \begin{minipage}{0.6125\textwidth}
    \begin{algorithm}[H]
    \caption{Adversarial Inverse MARL} 
    %(Online SGDA)
    \textbf{Inputs:} $\params, \policies, \obj[\param], \obj[\strat], \learnrate[\param][ ], \learnrate[\strat][ ], \numiters, \param[][0], \strat[][][0], \truepolicy$ \\
    \textbf{Outputs:} $(\param[][\iter], \strat[][][\iter])_{t = 0}^\numiters$
    \label{alg:online-sgda}
    \begin{algorithmic}[1]
    \For{$\iter = 0, \hdots, \numiters - 1$}
        % \For{$k = 0, \hdots, \numiters[\strat] - 1$}
            
            \State 
            % Sample trajectories 
            $\histmatrix \sim \bigtimes_{\player \in \players} \histdistrib[][{(\policy[\player][][{\strat[][][\iter]}], \truepolicy[-\player])}]$, $\hist[][\dagger][] \sim \histdistrib[][\truepolicy]$
            
            \State $\param[][\iter + 1] \gets \project[\params] \left[\param[][\iter] - \learnrate[\param][\iter] \obj[\param] (\param[][\iter], \strat[][][\iter]; \histmatrix, \hist[][\dagger]) \right]$
        
            \State $\strat[][][\iter + 1] \gets \project[\policies] \left[ \strat[][][\iter] + \learnrate[\strat][\iter] \obj[\strat] (\param[][\iter], \strat[][][\iter]; \histmatrix, \hist[][\dagger]) \right]$
    
        % \EndFor
        % \State 
        %     % Sample trajectories 
        %     $\hist \sim \bigtimes_{\player \in \players} \histdistrib[][{(\otherpolicy[\player], \truepolicy[-\player])}]$, $\hist[][\prime][] \sim \histdistrib[][\truepolicy]$
            
    \EndFor
    \State \Return $(\param[][\iter], \strat[][][\iter])_{t = 0}^\numiters$
    \end{algorithmic}
    \end{algorithm}
    \end{minipage}
    \vspace*{-0.4cm}
\end{wrapfigure}
