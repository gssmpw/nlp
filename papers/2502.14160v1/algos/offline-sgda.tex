%%% OFFLINE SGDA

\begin{wrapfigure}{l}{0.66\textwidth}
% \begin{figure}
    \vspace{-0.8cm}
    \begin{minipage}{0.66\textwidth}
    \begin{algorithm}[H]
    \caption{Adversarial Simulacral Learning}
    %(Offline SGDA)
    \textbf{Inputs:} $\params, \policies, (\avg[{\otherobj[\param]}], \avg[{\otherobj[\strat]}], \avg[{\otherobj[\otherstrat]}]), \learnrate[\param][ ], \learnrate[\strat][ ], \learnrate[\otherstrat][ ], \numiters, \param[][0], \strat[][][0], \otherstrat[][][0], \{\trueobs[][\numsample]\}$ \\
    \textbf{Outputs:} $(\param[][\iter], \strat[][][\iter], \otherstrat[][][\iter])_{t = 0}^\numiters$
    \label{alg:offline-sgda}
    \begin{algorithmic}[1]
    \For{$\iter = 0, \hdots, \numiters - 1$}
        % \For{$k = 0, \hdots, \numiters[\strat] - 1$}
            
            \State 
            % Sample trajectories 
            $\histmatrix \sim \bigtimes_{\player \in \players} \histdistrib[][{(\policy[\player][][{\strat[][][\iter]}], \policy[-\player][][{\otherstrat[][][\iter]}])}]$, $\hist[][][] \sim \histdistrib[][{(\policy[][][{\strat[][][\iter]}])}]$
            
            \State $\param[][\iter + 1] \gets \project[\params] \left[\param[][\iter] - \learnrate[\param][\iter] \grad[\param]  \avg[{\otherobj[\param]}] (\param[][\iter], \strat[][][\iter], \otherstrat[][][\iter]; \histmatrix, \hist[][]) \right]$

            \State $\strat[][][\iter+1] \gets \project[\policies] \left[ \strat[][][\iter] - \learnrate[\strat][\iter] \grad[\strat] \avg[{\otherobj[\strat]}] (\param[][\iter], \strat[][][\iter],  \otherstrat[][][\iter]; \histmatrix, \hist[][]) \right]$
            
            \State $\otherstrat[][][\iter+1] \gets \project[\policies] \left[ \otherstrat[][][\iter] + \learnrate[\otherstrat][\iter] \grad[\otherstrat] \avg[{\otherobj[\otherstrat]}] (\param[][\iter], \strat[][][\iter],  \otherstrat[][][\iter]; \histmatrix, \hist[][]) \right]$
    
        % \EndFor
        % \State 
        %     % Sample trajectories 
        %     $\hist \sim \bigtimes_{\player \in \players} \histdistrib[][{(\otherpolicy[\player], \truepolicy[-\player])}]$, $\hist[][\prime][] \sim \histdistrib[][\truepolicy]$
            
    \EndFor
    \State \Return $(\param[][\iter], \strat[][][\iter], \otherstrat[][][\iter])_{t = 0}^\numiters$
    \end{algorithmic}
    \end{algorithm}
    \end{minipage}
    \vspace{-0.5cm}
% \end{figure}
\end{wrapfigure}
