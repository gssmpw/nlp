% \section{Counterfactual Prediction and Contextual Games}
\subsection{Inverse Markov-Nash Equilibrium}

While a large body of work has been devoted to the computation of inverse $\varepsilon$-NE (see \deni{add backward references to related works section.}), the inverse $\varepsilon$-NE has limited use in making counterfactual predictions since \deni{non-uniqueness, ... why??}. \deni{Insert: More references and broader discussion.} 
A more interesting game-theoretic model of counterfactual prediction is instead that of the contextual inverse $\varepsilon$-Nash equilibrium problem.

An \mydef{inverse Markov game} $(\numplayers, \states, \actions, \params, \reward, \trans, \discount, \initstates, \policy[][][*])$ consists of $\numplayers \in \N_+$ players who have played a policy profile $\policy[][][*]$ in a Markov game $(\numplayers, \states, \actions, \params, \param^*, \reward, \trans, \discount, \initstates)$ where the parameter $\param \in \params$ has not been observed.
% , i.e., the parameter $\param \in \params$ defining the common type prior $\typedistrib[\param] \in \simplex(\typespace)$ is unknown
Our goal is to recover the game parameter assuming that the players played a (possibly approximate) NE (resp. MPNE). That is, we seek to compute a \mydef{$\varepsilon$-inverse NE} (resp \mydef{$\varepsilon$-inverse MPNE)}, a parameter $\param^* \in \params$ over types such that $\strat[][][*]$ is a $\varepsilon$-BNE of $(\numplayers, \numactions,  \typespace, \typedistrib, \param^*, \actionspace, \util)$
% \footnote{In this work, we focus on the EPNE, a refinement of BNE, but we note that the following observation applies more generally to BNE as well by simply pulling the maximum in the constraint outside of the expectation.}
.
% with each player $\player \in \players$ having an \mydef{action space} $\innerset[\player] \subset \R^{\numactions}$, a \mydef{type space} $\typespace[\player] \subset \R^\numtypes$, and parametric type-dependent form over payoff functions \cite{}. We denote the joint action and type spaces respectively by $\innerset \doteq \bigtimes_{\player \in \players} \innerset[\player]$ and $\typespace \doteq \bigtimes_{\player \in \players} \typespace[\player]$. The game is characterized by a context distribution $\initcontexts \sim \simplex(\contexts)$ over contexts $\contexts \in \R^\numcontexts$ and over the payoff function. 
% The players have played a $\varepsilon$-SPNE $\strat[][][*] \in \actionspace$ in the contextual game but we unfortunately have not observed the players' types and have only knowledge of function form payoff functions, i.e., $\utilspace \subset  \{\left(\util[\player]: \actionspace \times \typespace[\player] \to \R\right)_{\player \in \players} \}$.
% The solution to an inverse game is the 

% consists of finding an \mydef{inverse equilibrium mapping} $\hypothesis[][*]: \states \to \R^\actionspace$, which takes takes as input a state $\state \in \states$ and outputs utility functions $\hypothesis[][*]\left[\state\right]: \actionspace \to \R^\numplayers$ s.t. for all samples $\numsample \in \numsamples$, $\hypothesis[][*](\state[\numsample])$ $\varepsilon$-rationalize $\inner[][][*][\numsample]$. 


\deni{HAVE TO FIX EPNE exploitability.}

\amy{assume players play eqm in expection wrt some distribution, goal is to rover this distribution from observed play}


\begin{observation}\label{obs:bne}
    Suppose that the set of inverse EPNE of  $(\numplayers, \numactions, \typespace, \typedistrib, \actionspace, \util, \strat[][][*])$ is non-empty. Then, the set of types which solve the following (bi-level) optimization problem is equal to the set of inverse EPNE of $(\numplayers, \numactions, \contexts, \innerset, \initcontexts, \util, \typespace, \typedistrib, \strat[][][*])$:
    \begin{align}
        & \min_{\substack{\param \in \params \\ \policy \in \actionspace^\states}} &\left\|\policy[][][*] - \policy \right\|^2\\
        &\text{subject to } & \max_{\otherpolicy \in \actionspace^\states} \cumulregret[][](\policy, \otherpolicy; \param) \leq 0
    \end{align}
\end{observation}

\begin{proof}
    \deni{Modify proof here: }

     Let $(\type[][][\mathrm{OPT}], \action[][][][\mathrm{OPT}])$ be the optimal solutions to the above optimization problem. Then, note that by the constraint, we have:
    \begin{align}
         \exploit[][{\type[][][\mathrm{OPT}]}](\action[][][][\mathrm{OPT}]) =  \max_{\otheraction \in \actionspace}\cumulregret[][{\type[][][\mathrm{OPT}]}](\action[][][][\mathrm{OPT}], \otheraction) \leq \varepsilon
    \end{align}
    Hence, $\action[][][][\mathrm{OPT}]$ is a $\varepsilon$-NE. Now suppose that $\action[][][][\mathrm{OPT}] \neq \action[][][][*]$, then we could find a utility function for which $\action[][][][*]$ is the $\varepsilon$-NE since the set of inverse $\varepsilon$-NE is non-empty, and decrease the objective value, a contradiction.
\end{proof}

\begin{remark}
    Similar to \Cref{obs:inverse_NE}, the above observation tells us that inverse BNE problem 
\end{remark}

\begin{theorem}[Convergence proof]
    
\end{theorem}

\begin{theorem}[Sample Complexity]
    
\end{theorem}
% \deni{Add second observation over here:}
% We now introduce a Stackelberg-Nash game formulation of the inverse Nash equilibrium problem.

% \begin{align}
%     \min_{\hypothesis } \min_{\inner} \left\| \inner(\state[\numsample]) - \inner[][][*][\numsample]  \right\|^2\\
%     \text{s.t.} \sum_{\numsample \in \numsamples} \exploit(\inner(\state[\numsample]);\hypothesis(\state[\numsample])) \leq 0 
% \end{align}


% \sdeni{}{, but can be indirectly accessed via a context $\contextrv \doteq \f(\typerv)$ where $\f: \typespace \to \contexts$ is a mapping from types to contexts. We denote the context distribution  $\contextdistrib \sim \simplex(\contexts)$}