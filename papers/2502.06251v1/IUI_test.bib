@article{abbassComputationalRedTeaming2011,
  title = {Computational {{Red Teaming}}: {{Past}}, {{Present}} and {{Future}}},
  shorttitle = {Computational {{Red Teaming}}},
  author = {Abbass, H. and Bender, A. and Gaidow, S. and Whitbread, P.},
  year = {2011},
  month = feb,
  journal = {Comp. Intell. Mag.},
  volume = {6},
  number = {1},
  pages = {30--42},
  issn = {1556-603X},
  doi = {10.1109/MCI.2010.939578},
  urldate = {2024-07-19},
  abstract = {The combination of Computational Intelligence (CI) techniques "with Multi-Agent Systems (MAS) offers a great deal of opportunities for practitioners and Artificial Intelligence (AI) researchers alike. CI techniques provide the means to search massive spaces quickly; find possible, better or optimum solutions in these spaces; construct algorithms, functions and strategies to control an autonomous entity; find patterns and relationships "within data, information, knowledge or experience; assess risk and identify strategies for risk treatment; and connect the dots to synthesize an overall situational awareness picture that decision makers can utilize. MAS provide the structured, modular, distributed and efficient software environment to simulate systems; the architecture to represent systems and entities naturally; the environment to allow entities to observe, communicate "with, negotiate "with, orient "with respect to, and act upon other entities; the modular representation that allows entities to store and manipulate observations, forming beliefs, desires, goals, plans, and intentions; and the framework to model behavior. By bringing CI and MAS together, we have a powerful computational environment that has the theoretical potential to do many things that one can expect "when attempting to structure, understand, and solve a problem. In this article, we follow two objectives. First, we "will present Computational Red Teaming (CRT) as the state-of-the-art architecture representing the integration of CI techniques and MAS for understanding competition. Second, we "will demonstrate how this integration of MAS and CI benefits practitioners in almost all major application domains by drawing examples from defense, business and engineering. We "will present the evolution of CRT by categorizing the different levels of integrating CI and MAS, and highlighting open research questions pertaining to CRT.}
}

@inproceedings{agrawalRobotAuthorityHuman2017,
  title = {Robot {{Authority}} and {{Human Obedience}}: {{A Study}} of {{Human Behaviour}} Using a {{Robot Security Guard}}},
  shorttitle = {Robot {{Authority}} and {{Human Obedience}}},
  booktitle = {Proceedings of the {{Companion}} of the 2017 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Agrawal, Siddharth and Williams, Mary-Anne},
  year = {2017},
  month = mar,
  series = {{{HRI}} '17},
  pages = {57--58},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3029798.3038387},
  urldate = {2024-07-18},
  abstract = {There has been much debate, sci-fi movie scenes, and several scientific studies exploring the concept of robot authority. Some of the key research questions include: when should humans follow/question robot instructions; how can a robot increase its ability to convince humans to follow their instructions or to change their behaviour. In this paper, we describe a recent experiment designed to explore the notions of robot authority and human obedience. We set up a robot in a publicly accessible building to act as a security guard that issued instructions to specific humans. We identified and analysed the factors that affected a human's decisions to follow the robot's instruction. The four key factors were: perceived aggression, responsiveness, anthropomorphism, level of safety and intelligence in the robot's behaviour. We implemented various social cues to exhibit and convey authority and aggressiveness in the robot's behaviour. The results suggest that the degree of aggression that different people perceived in the robot's behaviour did not have a significant impact in their decision to follow the robot's instruction. Although, the people who disobeyed the robot, perceived the robot's behaviour to be more unsafe and less human-like than the people who followed the robot's instructions and also found the robot to be more responsive.},
  isbn = {978-1-4503-4885-0}
}

@misc{AIShouldChallenge2024,
  title = {{{AI Should Challenge}}, {{Not Obey}} -- {{Communications}} of the {{ACM}}},
  year = {2024},
  month = sep,
  urldate = {2025-01-24},
  langid = {american},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/JV8VY4PU/ai-should-challenge-not-obey.html}
}

@article{aldagFiascoReappraisalGroupthink1993,
  title = {Beyond Fiasco: {{A}} Reappraisal of the Groupthink Phenomenon and a New Model of Group Decision Processes},
  shorttitle = {Beyond Fiasco},
  author = {Aldag, Ramon J. and Fuller, Sally R.},
  year = {1993},
  journal = {Psychological Bulletin},
  volume = {113},
  number = {3},
  pages = {533--552},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1455},
  doi = {10.1037/0033-2909.113.3.533},
  abstract = {Provides a comprehensive evaluation of the groupthink phenomenon (I. L. Janis; 1971, 1972, 1982). The evaluation indicates that research does not provide convincing support for the validity of the groupthink phenomenon or for the suggestion that groupthink characteristics lead to negative outcomes. This review, coupled with evidence from other literature suggested by a problem-solving perspective and a direct examination of groupthink implicit assumptions, guided the development of a new, more general model termed the general group problem-solving model. This model incorporates a variety of antecedent conditions, emergent group characteristics, decision process characteristics, and group decision outcomes. Following the review and model development, potential concerns relating to the model are discussed, the allure of groupthink is addressed, and implications of the analysis for group problem solving as well as directions for future research are presented. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{alikhademiReviewPredictivePolicing2022,
  title = {A Review of Predictive Policing from the Perspective of Fairness},
  author = {Alikhademi, Kiana and Drobina, Emma and Prioleau, Diandra and Richardson, Brianna and Purves, Duncan and Gilbert, Juan E.},
  year = {2022},
  month = mar,
  journal = {Artificial Intelligence and Law},
  volume = {30},
  number = {1},
  pages = {1--17},
  issn = {1572-8382},
  doi = {10.1007/s10506-021-09286-4},
  urldate = {2024-07-17},
  abstract = {Machine Learning has become a popular tool in a variety of applications in criminal justice, including sentencing and policing. Media has brought attention to the possibility of predictive policing systems causing disparate impacts and exacerbating social injustices. However, there is little academic research on the importance of fairness in machine learning applications in policing. Although prior research has shown that machine learning models can handle some tasks efficiently, they are susceptible to replicating systemic bias of previous human decision-makers. While there is much research on fair machine learning in general, there is a need to investigate fair machine learning techniques as they pertain to the predictive policing. Therefore, we evaluate the existing publications in the field of fairness in machine learning and predictive policing to arrive at a set of standards for fair predictive policing. We also review the evaluations of ML applications in the area of criminal justice and potential techniques to improve these technologies going forward. We urge that the growing literature on fairness in ML be brought into conversation with the legal and social science concerns being raised about predictive policing. Lastly, in any area, including predictive policing, the pros and cons of the technology need to be evaluated holistically to determine whether and how the technology should be used in policing.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/7G5KJ8R3/Alikhademi et al. - 2022 - A review of predictive policing from the perspecti.pdf}
}

@article{alkaissiArtificialHallucinationsChatGPT2023,
  title = {Artificial {{Hallucinations}} in {{ChatGPT}}: {{Implications}} in {{Scientific Writing}}},
  shorttitle = {Artificial {{Hallucinations}} in {{ChatGPT}}},
  author = {Alkaissi, Hussam and McFarlane, Samy I.},
  year = {2023},
  month = feb,
  journal = {Cureus},
  volume = {15},
  number = {2},
  publisher = {Cureus Inc.},
  doi = {10.7759/cureus.35179},
  urldate = {2024-07-17},
  abstract = {While still in its infancy, ChatGPT (Generative Pretrained Transformer), introduced in November 2022, is bound to hugely impact many industries, including healthcare, medical education, biomedical research, and scientific writing. Implications of ChatGPT, ...},
  langid = {english},
  pmid = {36811129},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/G7SYQ47Z/Alkaissi and McFarlane - 2023 - Artificial Hallucinations in ChatGPT Implications.pdf}
}

@article{alvidrezIntergroupContactComputermediated2015,
  title = {Intergroup Contact in Computer-Mediated Communication: {{The}} Interplay of a Stereotype-Disconfirming Behavior and a Lasting Group Identity on Reducing Prejudiced Perceptions},
  shorttitle = {Intergroup Contact in Computer-Mediated Communication},
  author = {Alv{\'i}drez, Salvador and {Pi{\~n}eiro-Naval}, Valeriano and {Marcos-Ramos}, Mar{\'i}a and {Rojas-Sol{\'i}s}, Jos{\'e} Luis},
  year = {2015},
  month = nov,
  journal = {Computers in Human Behavior},
  volume = {52},
  pages = {533--540},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2014.09.006},
  urldate = {2024-06-23},
  abstract = {The present study investigated the impact of online intergroup contact on prejudiced and stereotyped perceptions toward an outgroup. Informed by research on contact in computer-mediated communication, a model of contact in which individual outgroup members displayed a stereotype-disconfirming (vs confirming) behavior in virtual teams made up of ingroup members was tested. Moreover, this hypothesized model of contact was examined across two visual conditions of group identification: one in which a pre-existing ethnic category (i.e, lasting membership) was made salient, and one without salient group identities. Results showed that when participants were conscious of their lasting identities, the enacted disconfirming behavior reduced prejudiced perceptions by the mediation of perceived attraction towards the individual outgroup member. Conversely, stereotyped perceptions were not affected by this behavior. These findings suggest that the generalization of the contact effect in CMC is more likely to occur in attitudinal variables than in cognitive ones, and as long as participants are aware of intergroup memberships when participating in short online interactions.}
}

@article{ambosImbalanceIsolationHow2016,
  title = {Imbalance and {{Isolation}}: {{How Team Configurations Affect Global Knowledge Sharing}}},
  shorttitle = {Imbalance and {{Isolation}}},
  author = {Ambos, Tina C. and Ambos, Bj{\"o}rn and Eich, Katharina J. and Puck, Jonas},
  year = {2016},
  month = dec,
  journal = {Journal of International Management},
  volume = {22},
  number = {4},
  pages = {316--332},
  issn = {1075-4253},
  doi = {10.1016/j.intman.2016.03.005},
  urldate = {2024-07-19},
  abstract = {This study investigates knowledge sharing in globally dispersed teams with distinctive geographical and cultural configurations. We provide fresh insights by contrasting international business and social identity theory and suggest that configurational asymmetries, namely imbalance and isolation, affect team members' average perceptions of knowledge sharing processes and outcomes. We test our hypotheses in the context of a multinational software corporation, drawing on a sample of 171 responses from team-members of 40 nationalities in 45 locations. Supporting social identity theory, our results show that our configurational variables -- geographical and cultural imbalance -- negatively affect knowledge sharing. The highest negative impact is observed in teams with geographically or culturally isolated members. Interestingly, we find no adverse effects of cultural and geographical distance (separation) that have been in the center of a large stream of research in international business.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/A8IXHMZ2/S1075425316301223.html}
}

@inproceedings{amershiGuidelinesHumanAIInteraction2019,
  title = {Guidelines for {{Human-AI Interaction}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N. and Inkpen, Kori and Teevan, Jaime and {Kikin-Gil}, Ruth and Horvitz, Eric},
  year = {2019},
  month = may,
  series = {{{CHI}} '19},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3290605.3300233},
  urldate = {2024-07-18},
  abstract = {Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles.},
  isbn = {978-1-4503-5970-2}
}

@article{amershiPowerPeopleRole2014,
  title = {Power to the {{People}}: {{The Role}} of {{Humans}} in {{Interactive Machine Learning}}},
  shorttitle = {Power to the {{People}}},
  author = {Amershi, Saleema and Cakmak, Maya and Knox, W. Bradley and Kulesza, Todd},
  year = {2014},
  month = dec,
  journal = {AI Mag.},
  volume = {35},
  number = {4},
  pages = {105--120},
  issn = {0738-4602},
  doi = {10.1609/aimag.v35i4.2513},
  urldate = {2024-07-19},
  abstract = {Systems that can learn interactively from their end-users are quickly becoming widespread. Until recently, this progress has been fueled mostly by advances in machine learning; however, more and more researchers are realizing the importance of studying users of these systems. In this article we promote this approach and demonstrate how it can result in better user experiences and more effective learning systems. We present a number of case studies that demonstrate how interactivity results in a tight coupling between the system and the user, exemplify ways in which some existing systems fail to account for the user, and explore new ways for learning systems to interact with their users. After giving a glimpse of the progress that has been made thus far, we discuss some of the challenges we face in moving the field forward.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/MPQ22XBB/Amershi et al. - 2014 - Power to the People The Role of Humans in Interac.pdf}
}

@misc{APAPsycNetBuy,
  title = {{{APA PsycNet Buy Page}}},
  urldate = {2025-01-21},
  howpublished = {https://psycnet.apa.org/buy/1996-01401-008},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/BI6422K4/1996-01401-008.html}
}

@misc{ArgumentStructuresDecisionmaking,
  title = {Argument Structures in Decision-making Groups: {{Southern Speech Communication Journal}}: {{Vol}} 53, {{No}} 1},
  urldate = {2024-07-17},
  howpublished = {https://www.tandfonline.com/doi/abs/10.1080/10417948709372710},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/X3ZH2WPN/10417948709372710.html}
}

@article{ariesVerbalNonverbalBehavior1982,
  title = {Verbal and {{Nonverbal Behavior}} in {{Single-Sex}} and {{Mixed-Sex Groups}}: {{Are Traditional Sex Roles Changing}}?},
  shorttitle = {Verbal and {{Nonverbal Behavior}} in {{Single-Sex}} and {{Mixed-Sex Groups}}},
  author = {Aries, Elizabeth Joan},
  year = {1982},
  month = aug,
  journal = {Psychological Reports},
  volume = {51},
  number = {1},
  pages = {127--134},
  publisher = {SAGE Publications Inc},
  issn = {0033-2941},
  doi = {10.2466/pr0.1982.51.1.127},
  urldate = {2024-07-19},
  abstract = {The study examines the degree to which traditional sex differences in behavioral interaction in groups obtain even in a sample of very bright, career-oriented men and women who are similar in respect to a variety of personality attributes and personal aspirations. 21 experimental groups were studied, 7 all-male, 6 all-female, and 8 mixed-sex groups. Groups were composed of 5 or 6 members. Each group had 40 min. to discuss an ethical dilemma and come to a consensus decision. The data indicated that, while rates of interaction departed from traditional sex-role stereotypes, with females dominating the mixed groups verbally, interaction styles and nonverbal postures remained sex-role stereotypic. Males devoted a greater proportion of their interaction to task behavior, i.e., giving opinions, suggestions, and information, and the females to reactions, i.e., agreements and disagreements. Males exceeded females in displays of nonverbal postures associated with dominance. Most behavioral measures were not affected by the sex composition of the group. Implications of these findings for work settings are discussed.},
  langid = {english}
}

@misc{aschOpinionsSocialPressure1955,
  title = {Opinions and {{Social Pressure}}},
  author = {Asch, Solomon E.},
  year = {1955},
  month = nov,
  journal = {Scientific American},
  urldate = {2025-01-21},
  abstract = {Exactly what is the effect of the opinions of others on our own? In other words, how strong is the urge toward social conformity? The question is approached by means of some unusual experiments},
  howpublished = {https://www.scientificamerican.com/article/opinions-and-social-pressure/},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/S4J7CW2X/opinions-and-social-pressure.html}
}

@article{ashktorabAIAssistedHumanLabeling2021,
  title = {{{AI-Assisted Human Labeling}}: {{Batching}} for {{Efficiency}} without {{Overreliance}}},
  shorttitle = {{{AI-Assisted Human Labeling}}},
  author = {Ashktorab, Zahra and Desmond, Michael and Andres, Josh and Muller, Michael and Joshi, Narendra Nath and Brachman, Michelle and Sharma, Aabhas and Brimijoin, Kristina and Pan, Qian and Wolf, Christine T. and Duesterwald, Evelyn and Dugan, Casey and Geyer, Werner and Reimer, Darrell},
  year = {2021},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  number = {CSCW1},
  pages = {89:1--89:27},
  doi = {10.1145/3449163},
  urldate = {2024-07-17},
  abstract = {Human labeling of training data is often a time-consuming, expensive part of machine learning. In this paper, we study "batch labeling", an AI-assisted UX paradigm, that aids data labelers by allowing a single labeling action to apply to multiple records. We ran a large scale study on Mechanical Turk with 156 participants to investigate labeler-AI-batching system interaction. We investigate the efficacy of the system when compared to a single-item labeling interface (i.e., labeling one record at-a-time), and evaluate the impact of batch labeling on accuracy and time. We further investigate the impact of AI algorithm quality and its effects on the labelers' overreliance, as well as potential mechanisms for mitigating it. Our work offers implications for the design of batch labeling systems and for work practices focusing on labeler-AI-batching system interaction.}
}

@inproceedings{avinHomophilyGlassCeiling2015,
  title = {Homophily and the {{Glass Ceiling Effect}} in {{Social Networks}}},
  booktitle = {Proceedings of the 2015 {{Conference}} on {{Innovations}} in {{Theoretical Computer Science}}},
  author = {Avin, Chen and Keller, Barbara and Lotker, Zvi and Mathieu, Claire and Peleg, David and Pignolet, Yvonne-Anne},
  year = {2015},
  month = jan,
  series = {{{ITCS}} '15},
  pages = {41--50},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2688073.2688097},
  urldate = {2024-07-18},
  abstract = {The glass ceiling effect has been defined in a recent US Federal Commission report as "the unseen, yet unbreakable barrier that keeps minorities and women from rising to the upper rungs of the corporate ladder, regardless of their qualifications or achievements". It is well documented that many societies and organizations exhibit a glass ceiling. In this paper we formally define and study the glass ceiling effect in social networks and propose a natural mathematical model, called the biased preferential attachment model, that partially explains the causes of the glass ceiling effect. This model consists of a network composed of two types of vertices, representing two sub-populations, and accommodates three well known social phenomena: (i) the "rich get richer" mechanism, (ii) a minority-majority partition, and (iii) homophily. We prove that our model exhibits a strong moment glass ceiling effect and that all three conditions are necessary, i.e., removing any one of them will prevent the appearance of a glass ceiling effect. Additionally, we present empirical evidence taken from a mentor-student network of researchers (derived from the DBLP database) that exhibits both a glass ceiling effect and the above three phenomena.},
  isbn = {978-1-4503-3333-7}
}

@article{azulTransmasculinePeoplesVocal2015,
  title = {Transmasculine People's Vocal Situations: A Critical Review of Gender-Related Discourses and Empirical Data},
  shorttitle = {Transmasculine People's Vocal Situations},
  author = {Azul, David},
  year = {2015},
  journal = {International Journal of Language \& Communication Disorders},
  volume = {50},
  number = {1},
  pages = {31--47},
  issn = {1460-6984},
  doi = {10.1111/1460-6984.12121},
  urldate = {2024-07-19},
  abstract = {Background Transmasculine people assigned female sex at birth but who do not identify with this classification have traditionally received little consideration in the voice literature. Some voice researchers and clinicians suggest that transmasculine people do not need attention because testosterone treatment leads to a satisfactory masculinization of their voice organs and voices. Others, however, argue that transmasculine people are a heterogeneous group whose members might not share the same body type, gender identity or desire for medical approaches to gender transitioning. Therefore, testosterone-induced voice changes may not necessarily meet the needs and expectations of all transmasculine people. Aims To evaluate the gender-related discursive and empirical data about transmasculine people's vocal situations to identify gaps in the current state of knowledge and to make suggestions for future voice research and clinical practice. Methods \& Procedures A comprehensive review of peer-reviewed academic and clinical literature was conducted. Publications were identified by searching seven electronic databases and bibliographies of relevant articles. Thirty-one publications met inclusion criteria. Discourses and empirical data were analysed thematically. Potential problem areas that transmasculine people may experience were identified and the quality of evidence appraised. Main Contribution The extent and quality of voice research conducted with transmasculine people so far was found to be limited. There was mixed evidence to suggest that transmasculine people's vocal situations could be regarded as problematic. The diversity that characterizes the transmasculine population received little attention and the complexity of the factors that contribute to a successful or unsuccessful vocal communication of gender in this group appeared to be under-researched. While most transmasculine people treated with testosterone can expect a lowering of their pitch, it remains unclear whether the extent of the pitch change is enough to result in a voice that is recognized by others as male. Conclusions \& Implications More research into the different factors affecting transmasculine people's vocal situations that takes account of the diversity within the population is needed.},
  copyright = {{\copyright} 2014 The Authors. International Journal of Language \& Communication Disorders published by John Wiley \& Sons Ltd on behalf of Royal College of Speech and Language Therapists},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/6EY2FAB6/Azul - 2015 - Transmasculine people's vocal situations a critic.pdf}
}

@article{baeEffectsAnonymityComputermediated2016,
  title = {The Effects of Anonymity on Computer-Mediated Communication: {{The}} Case of Independent versus Interdependent Self-Construal Influence},
  shorttitle = {The Effects of Anonymity on Computer-Mediated Communication},
  author = {Bae, Mikyeung},
  year = {2016},
  month = feb,
  journal = {Computers in Human Behavior},
  volume = {55},
  pages = {300--309},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2015.09.026},
  urldate = {2024-06-19},
  abstract = {This experiment investigated how anonymity influenced group identification, inter-group antagonism, and attitude change in computer-mediated communication in samples of both Korean and American participants. This study also examined how self-construal moderated the effect of anonymity on inter-group antagonism. Consistent with the social identity model of deindividuation effects (SIDE), findings from an analysis of variance (ANOVA) test showed that anonymity fostered group identification among the discussion partners and created greater attitude change following a group discussion. Anonymity correlated negatively with the exhibition of critical comments in both Korean and American participants. Although Korean participants showed a greater interdependent self-construal than the American participants did, the effects of self-construal on group identification and inter-group antagonism did not differ from those of American participants. Implications are discussed in light of the social identity theory, SIDE, and self-categorization theory.},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/RBJ44H4Z/S0747563215301576.html}
}

@article{ballietIngroupFavoritismCooperation2014,
  title = {Ingroup Favoritism in Cooperation: {{A}} Meta-Analysis},
  shorttitle = {Ingroup Favoritism in Cooperation},
  author = {Balliet, Daniel and Wu, Junhui and De Dreu, Carsten K. W.},
  year = {2014},
  journal = {Psychological Bulletin},
  volume = {140},
  number = {6},
  pages = {1556--1581},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1455},
  doi = {10.1037/a0037737},
  abstract = {Although theory suggests individuals are more willing to incur a personal cost to benefit ingroup members, compared to outgroup members, there is inconsistent evidence in support of this perspective. Applying meta-analytic techniques, we harness a relatively recent explosion of research on intergroup discrimination in cooperative decision making to address several fundamental unresolved issues. First, summarizing evidence across studies, we find a small to medium effect size indicating that people are more cooperative with ingroup, compared to outgroup, members (d = 0.32). Second, we forward and test predictions about the conditions that moderate ingroup favoritism from 2 influential perspectives: a social identity approach and a bounded generalized reciprocity perspective. Although we find evidence for a slight tendency for ingroup favoritism through categorization with no mutual interdependence between group members (e.g., dictator games; d = 0.19), situations that contain interdependence result in stronger ingroup favoritism (e.g., social dilemmas; d = 0.42). We also find that ingroup favoritism is stronger when there is common (vs. unilateral) knowledge of group membership, and stronger during simultaneous (vs. sequential) exchanges. Third, we find support for the hypothesis that intergroup discrimination in cooperation is the result of ingroup favoritism rather than outgroup derogation. Finally, we test for additional moderators of ingroup favoritism, such as the percentage of men in the sample, experimental versus natural groups, and the country of participants. We discuss the implications of these findings for theoretical perspectives on ingroup favoritism, address implications for the methodologies used to study this phenomenon, and suggest directions for future research. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{bansalAccuracyRoleMental2019,
  title = {Beyond {{Accuracy}}: {{The Role}} of {{Mental Models}} in {{Human-AI Team Performance}}},
  shorttitle = {Beyond {{Accuracy}}},
  author = {Bansal, Gagan and Nushi, Besmira and Kamar, Ece and Lasecki, Walter S. and Weld, Daniel S. and Horvitz, Eric},
  year = {2019},
  month = oct,
  journal = {Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
  volume = {7},
  pages = {2--11},
  issn = {2769-1349},
  doi = {10.1609/hcomp.v7i1.5285},
  urldate = {2024-07-17},
  abstract = {Decisions made by human-AI teams (e.g., AI-advised humans) are increasingly common in high-stakes domains such as healthcare, criminal justice, and finance. Achieving high team performance depends on more than just the accuracy of the AI system: Since the human and the AI may have different expertise, the highest team performance is often reached when they both know how and when to complement one another. We focus on a factor that is crucial to supporting such complementary: the human's mental model of the AI capabilities, specifically the AI system's error boundary (i.e. knowing ``When does the AI err?''). Awareness of this lets the human decide when to accept or override the AI's recommendation. We highlight two key properties of an AI's error boundary, parsimony and stochasticity, and a property of the task, dimensionality. We show experimentally how these properties affect humans' mental models of AI capabilities and the resulting team performance. We connect our evaluations to related work and propose goals, beyond accuracy, that merit consideration during model selection and optimization to improve overall human-AI team performance.},
  copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/DJIJGLKK/Bansal et al. - 2019 - Beyond Accuracy The Role of Mental Models in Huma.pdf}
}

@inproceedings{bansalDoesWholeExceed2021,
  title = {Does the {{Whole Exceed}} Its {{Parts}}? {{The Effect}} of {{AI Explanations}} on {{Complementary Team Performance}}},
  shorttitle = {Does the {{Whole Exceed}} Its {{Parts}}?},
  booktitle = {Proceedings of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Bansal, Gagan and Wu, Tongshuang and Zhou, Joyce and Fok, Raymond and Nushi, Besmira and Kamar, Ece and Ribeiro, Marco Tulio and Weld, Daniel},
  year = {2021},
  month = may,
  series = {{{CHI}} '21},
  pages = {1--16},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3411764.3445717},
  urldate = {2024-07-17},
  abstract = {Many researchers motivate explainable AI with studies showing that human-AI team performance on decision-making tasks improves when the AI explains its recommendations. However, prior studies observed improvements from explanations only when the AI, alone, outperformed both the human and the best team. Can explanations help lead to complementary performance, where team accuracy is higher than either the human or the AI working solo? We conduct mixed-method user studies on three datasets, where an AI with accuracy comparable to humans helps participants solve a task (explaining itself in some conditions). While we observed complementary improvements from AI augmentation, they were not increased by explanations. Rather, explanations increased the chance that humans will accept the AI's recommendation, regardless of its correctness. Our result poses new challenges for human-centered AI: Can we develop explanatory approaches that encourage appropriate trust in AI, and therefore help generate (or improve) complementary performance?},
  isbn = {978-1-4503-8096-6},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/9ISG3D7M/Bansal et al. - 2021 - Does the Whole Exceed its Parts The Effect of AI .pdf}
}

@article{bansalUpdatesHumanAITeams2019,
  title = {Updates in {{Human-AI Teams}}: {{Understanding}} and {{Addressing}} the {{Performance}}/{{Compatibility Tradeoff}}},
  shorttitle = {Updates in {{Human-AI Teams}}},
  author = {Bansal, Gagan and Nushi, Besmira and Kamar, Ece and Weld, Daniel S. and Lasecki, Walter S. and Horvitz, Eric},
  year = {2019},
  month = jul,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {33},
  number = {01},
  pages = {2429--2437},
  issn = {2374-3468},
  doi = {10.1609/aaai.v33i01.33012429},
  urldate = {2024-07-17},
  abstract = {AI systems are being deployed to support human decision making in high-stakes domains such as healthcare and criminal justice. In many cases, the human and AI form a team, in which the human makes decisions after reviewing the AI's inferences. A successful partnership requires that the human develops insights into the performance of the AI system, including its failures. We study the influence of updates to an AI system in this setting. While updates can increase the AI's predictive performance, they may also lead to behavioral changes that are at odds with the user's prior experiences and confidence in the AI's inferences. We show that updates that increase AI performance may actually hurt team performance. We introduce the notion of the compatibility of an AI update with prior user experience and present methods for studying the role of compatibility in human-AI teams. Empirical results on three high-stakes classification tasks show that current machine learning algorithms do not produce compatible updates. We propose a re-training objective to improve the compatibility of an update by penalizing new errors. The objective offers full leverage of the performance/compatibility tradeoff across different datasets, enabling more compatible yet accurate updates.},
  copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/7D67PU7Q/Bansal et al. - 2019 - Updates in Human-AI Teams Understanding and Addre.pdf}
}

@inproceedings{barangeTaskOrientedConversationalBehavior2014,
  title = {Task-{{Oriented Conversational Behavior}} of {{Agents}} for {{Collaboration}} in {{Human-Agent Teamwork}}},
  booktitle = {Advances in {{Practical Applications}} of {{Heterogeneous Multi-Agent Systems}}. {{The PAAMS Collection}}},
  author = {Barange, Mukesh and Kabil, Alexandre and De Keukelaere, Camille and Chevaillier, Pierre},
  editor = {Demazeau, Yves and Zambonelli, Franco and Corchado, Juan M. and Bajo, Javier},
  year = {2014},
  pages = {25--37},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-07551-8_3},
  abstract = {Coordination is an essential ingredient for human-agent teamwork. It requires team members to share knowledge to establish common grounding and mutual awareness among them. This paper proposes a behavioral architecture C2BDI that enhances the knowledge sharing using natural language communication between team members. Collaborative conversation protocols and resource allocation mechanism have been defined that provide proactive behavior to agents for coordination. This architecture has been applied to a real scenario in a collaborative virtual environment for learning. The solution enables users to coordinate with other team members.},
  isbn = {978-3-319-07551-8},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/WUPGNRME/Barange et al. - 2014 - Task-Oriented Conversational Behavior of Agents fo.pdf}
}

@article{barretoImpactAnonymityGroup2002,
  title = {The {{Impact}} of {{Anonymity}} and {{Group Identification}} on {{Progroup Behavior}} in {{Computer-Mediated Groups}}},
  author = {Barreto, Manuela and Ellemers, Naomi},
  year = {2002},
  month = oct,
  journal = {Small Group Research},
  volume = {33},
  number = {5},
  pages = {590--610},
  publisher = {SAGE Publications Inc},
  issn = {1046-4964},
  doi = {10.1177/104649602237680},
  urldate = {2024-06-23},
  abstract = {To contribute to the examination of the effects of computer-mediated communication (CMC) on collaborative work, the impact of anonymity on willingness to exert effort on behalf of a group was examined. Two aspects of anonymity were independently manipulated: visibility of respondents (not visible, visible) and visibility of responses (not visible, visible) to the in-group. The role of degree of identification as moderator of anonymity effects was also examined. The results show that anonymity manipulations affect group members'effort on behalf of the group, but only when group identification is low. Low identifiers chose to work harder with the group either when they were totally anonymous or when they were totally visible to other in-group members. The implications of the results for the understanding of group processes through CMC are discussed.},
  langid = {english},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/PVJWDATJ/Barreto and Ellemers - 2002 - The Impact of Anonymity and Group Identification o.pdf}
}

@misc{batesFittingLinearMixedEffects2014,
  title = {Fitting {{Linear Mixed-Effects Models}} Using Lme4},
  author = {Bates, Douglas and M{\"a}chler, Martin and Bolker, Ben and Walker, Steve},
  year = {2014},
  month = jun,
  number = {arXiv:1406.5823},
  eprint = {1406.5823},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1406.5823},
  urldate = {2024-07-19},
  abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
  archiveprefix = {arXiv},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/YN8AMBD9/Bates et al. - 2014 - Fitting Linear Mixed-Effects Models using lme4.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/YNQ5R8ZI/1406.html}
}

@misc{bayserLearningMultiPartyTurnTaking2019,
  title = {Learning {{Multi-Party Turn-Taking Models}} from {{Dialogue Logs}}},
  author = {de Bayser, Maira Gatti and Cavalin, Paulo and Pinhanez, Claudio and Zadrozny, Bianca},
  year = {2019},
  month = jul,
  number = {arXiv:1907.02090},
  eprint = {1907.02090},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1907.02090},
  urldate = {2025-01-21},
  abstract = {This paper investigates the application of machine learning (ML) techniques to enable intelligent systems to learn multi-party turn-taking models from dialogue logs. The specific ML task consists of determining who speaks next, after each utterance of a dialogue, given who has spoken and what was said in the previous utterances. With this goal, this paper presents comparisons of the accuracy of different ML techniques such as Maximum Likelihood Estimation (MLE), Support Vector Machines (SVM), and Convolutional Neural Networks (CNN) architectures, with and without utterance data. We present three corpora: the first with dialogues from an American TV situated comedy (chit-chat), the second with logs from a financial advice multi-bot system and the third with a corpus created from the Multi-Domain Wizard-of-Oz dataset (both are topic-oriented). The results show: (i) the size of the corpus has a very positive impact on the accuracy for the content-based deep learning approaches and those models perform best in the larger datasets; and (ii) if the dialogue dataset is small and topic-oriented (but with few topics), it is sufficient to use an agent-only MLE or SVM models, although slightly higher accuracies can be achieved with the use of the content of the utterances with a CNN model.},
  archiveprefix = {arXiv},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/XRII8KB3/Bayser et al. - 2019 - Learning Multi-Party Turn-Taking Models from Dialogue Logs.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/REM5SKEM/1907.html}
}

@article{bearRoleGenderTeam2011,
  title = {The Role of Gender in Team Collaboration and Performance},
  author = {Bear, Julia B and Woolley, Anita Williams},
  year = {2011},
  month = jun,
  journal = {Interdisciplinary Science Reviews},
  volume = {36},
  number = {2},
  pages = {146--153},
  publisher = {SAGE Publications},
  issn = {0308-0188},
  doi = {10.1179/030801811X13013181961473},
  urldate = {2024-07-19},
  abstract = {Given that women continue to be underrepresented in STEM (Science, Technology, Engineering and Math) and that scientific innovations are increasingly produced by team collaborations, we reviewed the existing literature regarding the effects of gender diversity on team processes and performance. Recent evidence strongly suggests that team collaboration is greatly improved by the presence of women in the group, and this effect is primarily explained by benefits to group processes. The evidence concerning the effect of gender diversity on team performance is more equivocal and contingent upon a variety of contextual factors. In light of the importance of collaboration in science, promoting the role of women in the field can have positive practical consequences for science and technology.},
  langid = {english}
}

@article{bellTeamCompositionABCs2018,
  title = {Team Composition and the {{ABCs}} of Teamwork},
  author = {Bell, Suzanne T. and Brown, Shanique G. and Colaneri, Anthony and Outland, Neal},
  year = {2018},
  journal = {American Psychologist},
  volume = {73},
  number = {4},
  pages = {349--362},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1935-990X},
  doi = {10.1037/amp0000305},
  abstract = {In teams, some combinations of people work together better than others. A large body of literature with a rich history suggests that the configuration of team member attributes, called team composition, has a fundamental influence on teamwork. Team composition shapes the emergence of affective states, behavioral processes, and cognitive states (the ABCs of teamwork), which ultimately affect how teams meet their objectives. The purpose of this article is to describe what is known about team composition and its influence on the ABCs of teamwork. We discuss what team composition is, and why it is important. We then describe key discoveries related to how team composition shapes the ABCs of teamwork. Building on what we know, we outline important directions for future research. (PsycInfo Database Record (c) 2020 APA, all rights reserved)}
}

@article{berdahlMenWomenLeadership2005,
  title = {Men, {{Women}}, and {{Leadership Centralization}} in {{Groups Over Time}}},
  author = {Berdahl, Jennifer L. and Anderson, Cameron},
  year = {2005},
  journal = {Group Dynamics: Theory, Research, and Practice},
  volume = {9},
  number = {1},
  pages = {45--57},
  publisher = {Educational Publishing Foundation},
  address = {US},
  issn = {1930-7802},
  doi = {10.1037/1089-2699.9.1.45},
  abstract = {The authors propose a model for predicting the emergence of group norms from the demographic composition of groups. They use this model to study gender and leadership centralization in groups over time. Results from 2 longitudinal studies were consistent with their predictions: (a) Women, more than men, preferred equality norms in groups; (b) all-male and majority-male groups had relatively centralized leadership structures; (c) all-female groups had relatively decentralized leadership structures; and (d) balanced and majority-female groups were relatively centralized at the onset of group interaction but decreased in centralization over time. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/68ZPIT6Q/2005-02475-004.html}
}

@inproceedings{binnsItsReducingHuman2018,
  title = {'{{It}}'s {{Reducing}} a {{Human Being}} to a {{Percentage}}': {{Perceptions}} of {{Justice}} in {{Algorithmic Decisions}}},
  shorttitle = {'{{It}}'s {{Reducing}} a {{Human Being}} to a {{Percentage}}'},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Binns, Reuben and Van Kleek, Max and Veale, Michael and Lyngs, Ulrik and Zhao, Jun and Shadbolt, Nigel},
  year = {2018},
  month = apr,
  series = {{{CHI}} '18},
  pages = {1--14},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3173574.3173951},
  urldate = {2024-07-18},
  abstract = {Data-driven decision-making consequential to individuals raises important questions of accountability and justice. Indeed, European law provides individuals limited rights to 'meaningful information about the logic' behind significant, autonomous decisions such as loan approvals, insurance quotes, and CV filtering. We undertake three experimental studies examining people's perceptions of justice in algorithmic decision-making under different scenarios and explanation styles. Dimensions of justice previously observed in response to human decision-making appear similarly engaged in response to algorithmic decisions. Qualitative analysis identified several concerns and heuristics involved in justice perceptions including arbitrariness, generalisation, and (in)dignity. Quantitative analysis indicates that explanation styles primarily matter to justice perceptions only when subjects are exposed to multiple different styles---under repeated exposure of one style, scenario effects obscure any explanation effects. Our results suggests there may be no 'best' approach to explaining algorithmic decisions, and that reflection on their automated nature both implicates and mitigates justice dimensions.},
  isbn = {978-1-4503-5620-6},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/9BVC34YI/Binns et al. - 2018 - 'It's Reducing a Human Being to a Percentage' Per.pdf}
}

@book{bittnerWhereBotOur2019,
  title = {Where Is the {{Bot}} in Our {{Team}}? {{Toward}} a {{Taxonomy}} of {{Design Option Combinations}} for {{Conversational Agents}} in {{Collaborative Work}}},
  shorttitle = {Where Is the {{Bot}} in Our {{Team}}?},
  author = {Bittner, Eva and {Oeste-Rei{\ss}}, Sarah and Leimeister, Jan Marco},
  year = {2019},
  month = jan,
  urldate = {2024-07-19},
  abstract = {With rapid progress in machine learning, language technologies and artificial intelligence, conversational agents (CAs) gain rising attention in research and practice as potential non-human teammates, facilitators or experts in collaborative work. However, designers of CAs in collaboration still struggle with a lack of comprehensive understanding of the vast variety of design options in the dynamic field. We address this gap with a taxonomy to help researchers and designers understand the design space and the interrelations of different design options and recognize useful design option combinations for their CAs. We present the iterative development of a taxonomy for the design of CAs grounded in state of the art literature and validated with domain experts. We identify recurring design option combinations and white spots from the classified objects that will inform further research and development efforts.},
  isbn = {978-0-9981331-2-6},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/R3YYHZGA/Bittner et al. - 2019 - Where is the Bot in our Team Toward a Taxonomy of.pdf}
}

@article{boldryGenderStereotypesEvaluation2001,
  title = {Gender {{Stereotypes}} and the {{Evaluation}} of {{Men}} and {{Women}} in {{Military Training}}},
  author = {Boldry, Jennifer and Wood, Wendy and Kashy, Deborah A.},
  year = {2001},
  journal = {Journal of Social Issues},
  volume = {57},
  number = {4},
  pages = {689--705},
  issn = {1540-4560},
  doi = {10.1111/0022-4537.00236},
  urldate = {2024-07-19},
  abstract = {The present study investigated perceptions of men and women in the Texas A\&M Corps of Cadets. For both stereotypes and evaluations of individual cadets enrolled in the training program, men more than women were believed to possess the motivation and leadership qualities necessary for effective military performance, whereas women were believed to possess more feminine attributes that impair effective military performance. Because men and women did not differ on objective measures of military performance, the sex-differentiated evaluations of cadets enrolled in training most plausibly reflect the influence of gender stereotypes rather than performance differences between the sexes. Furthermore, integration of women into the corps was associated with more favorable stereotypic judgments of women and did not reveal a backlash against women in this strongly male- dominated setting.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/MHCSZ46V/Boldry et al. - 2001 - Gender Stereotypes and the Evaluation of Men and W.pdf}
}

@article{bondCultureConformityMetaanalysis1996,
  title = {Culture and Conformity: {{A}} Meta-Analysis of Studies Using {{Asch}}'s (1952b, 1956) Line Judgment Task.},
  shorttitle = {Culture and Conformity},
  author = {Bond, Rod and Smith, Peter B.},
  year = {1996},
  month = jan,
  journal = {Psychological Bulletin},
  volume = {119},
  number = {1},
  pages = {111--137},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/0033-2909.119.1.111},
  urldate = {2025-01-21},
  abstract = {A meta-analysis of conformity studies using an Asch-type line judgment task (1952b, 1956) was conducted to investigate whether the level of conformity has changed over time and whether it is related crogs-culturally to individualism-collectivism. The fiterature search produced 133 studies drawn from 17 countries. An analysis of U.S. studies found that conformity has declined since the 1950s. Results from 3 surveys were used to assess a country's individualism-collectivism, and for each survey the measures were found to be significantly related to conformity. Collectivist countries tended to show higher levels of conformity than individualist countries. Conformity research must attend more to cultural variables and to their role in the processes involved in social influence. The view has long been held that conformity is to some extent a product of cultural conditions, and it is a stable feature of popular stereotypes that some national groups are conforming and submissive, whereas others are independent and self-assertive (e.g., Peabody, 1985 ). Likewise, the extent to which dissidence is tolerated in a society will vary at different points in its history, and several commentators have suggested that the relatively high levels of conformity found in experiments conducted in the early 1950s (notably Asch, 1952b, 1956) was in part a product of the McCarthy era (e.g., Larsen, 1974; Mann, 1980; Perrin \& Spencer, 1981 ). Although Asch's ( 1952b, 1956) seminal research is often interpreted as demonstrating that conformity is fundamental to group processes (Friend, Rafferty, \& Bramel, 1990), Asch was as much concerned with those factors that enabled individuals to resist group pressure, factors which he saw as rooted in a society's values and socialization practices. That we have found the tendency to conformity in our society so strong that reasonably intelligent and well-meaning young people are willing to call White Black is a matter of concern. It raises questions about our ways of education and about the values that guide our conduct. (Asch, 1955, p. 34)},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/UTW8JJIA/Bond and Smith - 1996 - Culture and conformity A meta-analysis of studies using Asch's (1952b, 1956) line judgment task..pdf}
}

@article{brahmAdvantagesDisadvantagesGroup1996,
  title = {Advantages and Disadvantages of Group Decision- Making Approaches},
  author = {Brahm, Carolyn and Kleiner, Brian H.},
  year = {1996},
  month = jan,
  journal = {Team Performance Management: An International Journal},
  volume = {2},
  number = {1},
  pages = {30--35},
  publisher = {MCB UP Ltd},
  issn = {1352-7592},
  doi = {10.1108/13527599610105538},
  urldate = {2024-08-09},
  abstract = {Explains the advantages and disadvantages of the various approaches that are now being used in today's society for group decision making. Groups are everywhere in our society, and learning more about them and how to work better in them can enhance the quality of each person's life. Explains in detail five of the most widely used techniques: brainstorming, brainwriting, buzz sessions, quality circles, and nominal group technique. Points out the advantages and disadvantages of each approach with a view to reducing failures in implementing techniques as a result of lack of knowledge. The article will be useful for anyone involved in groups, e.g. managers or people wishing to improve their skills.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/G7DL2CP9/html.html}
}

@book{brannickTeamPerformanceAssessment1997,
  title = {Team {{Performance Assessment}} and {{Measurement}}: {{Theory}}, {{Methods}}, and {{Applications}}},
  shorttitle = {Team {{Performance Assessment}} and {{Measurement}}},
  author = {Brannick, Michael T. and Salas, Eduardo and Prince, Carolyn W.},
  year = {1997},
  month = jun,
  publisher = {Psychology Press},
  abstract = {This book began at a conference on team performance measurement held at the University of South Florida. Several participants at the conference felt that a book on team performance measurement would be of interest to a broader audience, and they began looking for authors in diverse disciplines. Some of the chapters in this book closely follow material presented at the conference. Many others report work that was done subsequently or was done by authors not present at the conference. The result is a book rich in its diversity of approaches to measurement and which contains illustrations of many different teams.  This book is the first of its kind to bring together a collection of scholars and practitioners focusing solely on the problem of team performance measurement. Although much has been written about team and group effectiveness, little theoretical and empirical progress has been made in the measurement of team processes and outcomes. The book represents a major step forward both theoretically and empirically. Section 1 provides a rich theoretical basis for measurement, including designing measures to be used in team training, measures of shared mental models, and measures of team workload. Section 2 addresses methodological developments and issues, including the design and validation of simulations, surveys, and observer checklists. It also deals with issues such as the consistency of team performance and task and level of analysis issues. Section 3 provides applications and illustrations of team performance measures in such teams as nuclear power control room operators, theater technical crews, and aircraft cockpit crews. Section 4 offers guidance for anyone interested in developing their own measures of team performance.  There are both theoretical and practical reasons for the current interest in teams. Psychological research interest in groups and teams has returned and is now a thriving area. Self-managed work groups and semi-autonomous work groups have become increasingly common in industry, so there is an increased interest in team functioning from a practical standpoint. This volume's purpose is to describe recent advances in the measurement of team performance, both process and outcome. Several of the chapters provide recommendations on how, when, and why to measure aspects of teams. In addition to describing what is currently known, the book also discusses what remains to be known and what needs to be done next.  The book is intended primarily for those interested in research about team processes and outcomes--researchers and academics who possess a basic understanding of statistics and psychometrics. The bulk of research reported has applied aims which provide much practical information, such as how to design simulations, rating forms, and dimensions of team performance useful for feedback to many kinds of teams. In addition, there are examples from several different kinds of teams, including aircrews, nuclear power plant operators, hospital workers, ship combat information center groups, and theater technicians. Therefore the book should be useful to people who want to design measures to evaluate teams.},
  googlebooks = {NIx5AgAAQBAJ},
  isbn = {978-1-135-69330-5},
  langid = {english}
}

@article{brewerPsychologyPrejudiceIngroup1999,
  title = {The {{Psychology}} of {{Prejudice}}: {{Ingroup Love}} and {{Outgroup Hate}}?},
  shorttitle = {The {{Psychology}} of {{Prejudice}}},
  author = {Brewer, Marilynn B.},
  year = {1999},
  journal = {Journal of Social Issues},
  volume = {55},
  number = {3},
  pages = {429--444},
  issn = {1540-4560},
  doi = {10.1111/0022-4537.00126},
  urldate = {2024-07-19},
  abstract = {Allport (1954) recognized that attachment to one's ingroups does not necessarily require hostility toward outgroups. Yet the prevailing approach to the study of ethnocentrism, ingroup bias, and prejudice presumes that ingroup love and outgroup hate are reciprocally related. Findings from both cross-cultural research and laboratory experiments support the alternative view that ingroup identification is independent of negative attitudes toward outgroups and that much ingroup bias and intergroup discrimination is motivated by preferential treatment of ingroup members rather than direct hostility toward outgroup members. Thus to understand the roots of prejudice and discrimination requires first of all a better understanding of the functions that ingroup formation and identification serve for human beings. This article reviews research and theory on the motivations for maintenance of ingroup boundaries and the implications of ingroup boundary protection for intergroup relations, conflict, and conflict prevention.},
  copyright = {1999 The Society for the Psychological Study of Social Issues},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/QTX47NJG/Brewer - 1999 - The Psychology of Prejudice Ingroup Love and Outg.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/NN48RNMD/0022-4537.html}
}

@inproceedings{brownLanguageModelsAre2020,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  volume = {33},
  pages = {1877--1901},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-07-17},
  abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/5FD8NGQ6/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf}
}

@article{bucincaTrustThinkCognitive2021,
  title = {To {{Trust}} or to {{Think}}: {{Cognitive Forcing Functions Can Reduce Overreliance}} on {{AI}} in {{AI-assisted Decision-making}}},
  shorttitle = {To {{Trust}} or to {{Think}}},
  author = {Bu{\c c}inca, Zana and Malaya, Maja Barbara and Gajos, Krzysztof Z.},
  year = {2021},
  month = apr,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {5},
  number = {CSCW1},
  pages = {188:1--188:21},
  doi = {10.1145/3449287},
  urldate = {2024-04-09},
  abstract = {People supported by AI-powered decision support tools frequently overrely on the AI: they accept an AI's suggestion even when that suggestion is wrong. Adding explanations to the AI decisions does not appear to reduce the overreliance and some studies suggest that it might even increase it. Informed by the dual-process theory of cognition, we posit that people rarely engage analytically with each individual AI recommendation and explanation, and instead develop general heuristics about whether and when to follow the AI suggestions. Building on prior research on medical decision-making, we designed three cognitive forcing interventions to compel people to engage more thoughtfully with the AI-generated explanations. We conducted an experiment (N=199), in which we compared our three cognitive forcing designs to two simple explainable AI approaches and to a no-AI baseline. The results demonstrate that cognitive forcing significantly reduced overreliance compared to the simple explainable AI approaches. However, there was a trade-off: people assigned the least favorable subjective ratings to the designs that reduced the overreliance the most. To audit our work for intervention-generated inequalities, we investigated whether our interventions benefited equally people with different levels of Need for Cognition (i.e., motivation to engage in effortful mental activities). Our results show that, on average, cognitive forcing interventions benefited participants higher in Need for Cognition more. Our research suggests that human cognitive motivation moderates the effectiveness of explainable AI solutions.},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/5LDD2EC2/Buçinca et al. - 2021 - To Trust or to Think Cognitive Forcing Functions .pdf}
}

@article{bucincaTrustThinkCognitive2021a,
  title = {To {{Trust}} or to {{Think}}: {{Cognitive Forcing Functions Can Reduce Overreliance}} on {{AI}} in {{AI-assisted Decision-making}}},
  shorttitle = {To {{Trust}} or to {{Think}}},
  author = {Bu{\c c}inca, Zana and Malaya, Maja Barbara and Gajos, Krzysztof Z.},
  year = {2021},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  number = {CSCW1},
  pages = {188:1--188:21},
  doi = {10.1145/3449287},
  urldate = {2024-07-17},
  abstract = {People supported by AI-powered decision support tools frequently overrely on the AI: they accept an AI's suggestion even when that suggestion is wrong. Adding explanations to the AI decisions does not appear to reduce the overreliance and some studies suggest that it might even increase it. Informed by the dual-process theory of cognition, we posit that people rarely engage analytically with each individual AI recommendation and explanation, and instead develop general heuristics about whether and when to follow the AI suggestions. Building on prior research on medical decision-making, we designed three cognitive forcing interventions to compel people to engage more thoughtfully with the AI-generated explanations. We conducted an experiment (N=199), in which we compared our three cognitive forcing designs to two simple explainable AI approaches and to a no-AI baseline. The results demonstrate that cognitive forcing significantly reduced overreliance compared to the simple explainable AI approaches. However, there was a trade-off: people assigned the least favorable subjective ratings to the designs that reduced the overreliance the most. To audit our work for intervention-generated inequalities, we investigated whether our interventions benefited equally people with different levels of Need for Cognition (i.e., motivation to engage in effortful mental activities). Our results show that, on average, cognitive forcing interventions benefited participants higher in Need for Cognition more. Our research suggests that human cognitive motivation moderates the effectiveness of explainable AI solutions.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/ZTF6CAX7/Buçinca et al. - 2021 - To Trust or to Think Cognitive Forcing Functions .pdf}
}

@article{bucincaTrustThinkCognitive2021b,
  title = {To {{Trust}} or to {{Think}}: {{Cognitive Forcing Functions Can Reduce Overreliance}} on {{AI}} in {{AI-assisted Decision-making}}},
  shorttitle = {To {{Trust}} or to {{Think}}},
  author = {Bu{\c c}inca, Zana and Malaya, Maja Barbara and Gajos, Krzysztof Z.},
  year = {2021},
  month = apr,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {5},
  number = {CSCW1},
  pages = {188:1--188:21},
  doi = {10.1145/3449287},
  urldate = {2024-03-06},
  abstract = {People supported by AI-powered decision support tools frequently overrely on the AI: they accept an AI's suggestion even when that suggestion is wrong. Adding explanations to the AI decisions does not appear to reduce the overreliance and some studies suggest that it might even increase it. Informed by the dual-process theory of cognition, we posit that people rarely engage analytically with each individual AI recommendation and explanation, and instead develop general heuristics about whether and when to follow the AI suggestions. Building on prior research on medical decision-making, we designed three cognitive forcing interventions to compel people to engage more thoughtfully with the AI-generated explanations. We conducted an experiment (N=199), in which we compared our three cognitive forcing designs to two simple explainable AI approaches and to a no-AI baseline. The results demonstrate that cognitive forcing significantly reduced overreliance compared to the simple explainable AI approaches. However, there was a trade-off: people assigned the least favorable subjective ratings to the designs that reduced the overreliance the most. To audit our work for intervention-generated inequalities, we investigated whether our interventions benefited equally people with different levels of Need for Cognition (i.e., motivation to engage in effortful mental activities). Our results show that, on average, cognitive forcing interventions benefited participants higher in Need for Cognition more. Our research suggests that human cognitive motivation moderates the effectiveness of explainable AI solutions.},
  langid = {american},
  keywords = {,/ Done,notion},
  annotation = {TLDR: 이 연구는 인간의 인지적 동기가 설명 가능한 AI 솔루션의 효과를 조절하며, 사람들이 AI가 생성한 설명에 더 신중하게 참여하도록 유도하기 위해 세 가지 인지적 강제 개입을 설계했다고 제안합니다.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/6BFWNH9T/Buçinca 등 - 2021 - To Trust or to Think Cognitive Forcing Functions .pdf}
}

@article{byrneInterpersonalAttractionAttitude1961,
  title = {Interpersonal Attraction and Attitude Similarity},
  author = {Byrne, D.},
  year = {1961},
  journal = {The Journal of Abnormal and Social Psychology},
  volume = {62},
  number = {3},
  pages = {713--715},
  publisher = {American Psychological Association},
  address = {US},
  issn = {0096-851X},
  doi = {10.1037/h0044721},
  abstract = {It "was hypothesized that (a) a stranger who is known to have attitudes similar to those of the subject is better liked than a stranger with attitudes dissimilar to those of the subject, (b){\dots} is judged to be more intelligent, better informed, more moral, and better adjusted{\dots} and (c){\dots} is evaluated more positively on{\dots} four [other] variables." The first 2 hypotheses were confirmed. From Psyc Abstracts 36:04:4GE13B. (PsycInfo Database Record (c) 2022 APA, all rights reserved)}
}

@misc{caiAntagonisticAI2024,
  title = {Antagonistic {{AI}}},
  author = {Cai, Alice and Arawjo, Ian and Glassman, Elena L.},
  year = {2024},
  month = feb,
  number = {arXiv:2402.07350},
  eprint = {2402.07350},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.07350},
  urldate = {2025-01-24},
  abstract = {The vast majority of discourse around AI development assumes that subservient, "moral" models aligned with "human values" are universally beneficial -- in short, that good AI is sycophantic AI. We explore the shadow of the sycophantic paradigm, a design space we term antagonistic AI: AI systems that are disagreeable, rude, interrupting, confrontational, challenging, etc. -- embedding opposite behaviors or values. Far from being "bad" or "immoral," we consider whether antagonistic AI systems may sometimes have benefits to users, such as forcing users to confront their assumptions, build resilience, or develop healthier relational boundaries. Drawing from formative explorations and a speculative design workshop where participants designed fictional AI technologies that employ antagonism, we lay out a design space for antagonistic AI, articulating potential benefits, design techniques, and methods of embedding antagonistic elements into user experience. Finally, we discuss the many ethical challenges of this space and identify three dimensions for the responsible design of antagonistic AI -- consent, context, and framing.},
  archiveprefix = {arXiv},
  annotation = {TLDR: This work lays out a design space for antagonistic AI, articulating potential benefits, design techniques, and methods of embedding antagonistic elements into user experience and discusses the many ethical challenges of this space.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/Q64SPQF3/Cai et al. - 2024 - Antagonistic AI.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/KFQ57JSD/2402.html}
}

@article{caiHelloAIUncovering2019,
  title = {"{{Hello AI}}": {{Uncovering}} the {{Onboarding Needs}} of {{Medical Practitioners}} for {{Human-AI Collaborative Decision-Making}}},
  shorttitle = {"{{Hello AI}}"},
  author = {Cai, Carrie J. and Winter, Samantha and Steiner, David and Wilcox, Lauren and Terry, Michael},
  year = {2019},
  month = nov,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {3},
  number = {CSCW},
  pages = {104:1--104:24},
  doi = {10.1145/3359206},
  urldate = {2024-07-17},
  abstract = {Although rapid advances in machine learning have made it increasingly applicable to expert decision-making, the delivery of accurate algorithmic predictions alone is insufficient for effective human-AI collaboration. In this work, we investigate the key types of information medical experts desire when they are first introduced to a diagnostic AI assistant. In a qualitative lab study, we interviewed 21 pathologists before, during, and after being presented deep neural network (DNN) predictions for prostate cancer diagnosis, to learn the types of information that they desired about the AI assistant. Our findings reveal that, far beyond understanding the local, case-specific reasoning behind any model decision, clinicians desired upfront information about basic, global properties of the model, such as its known strengths and limitations, its subjective point-of-view, and its overall design objective--what it's designed to be optimized for. Participants compared these information needs to the collaborative mental models they develop of their medical colleagues when seeking a second opinion: the medical perspectives and standards that those colleagues embody, and the compatibility of those perspectives with their own diagnostic patterns. These findings broaden and enrich discussions surrounding AI transparency for collaborative decision-making, providing a richer understanding of what experts find important in their introduction to AI assistants before integrating them into routine practice.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/H22DSLL5/Cai et al. - 2019 - Hello AI Uncovering the Onboarding Needs of Med.pdf}
}

@article{canaryArgumentStructuresDecisionmaking1987,
  title = {Argument Structures in Decision-making Groups},
  author = {Canary, Daniel J. and Brossmann, Brent G. and Seibold, David R.},
  year = {1987},
  month = dec,
  journal = {Southern Speech Communication Journal},
  volume = {53},
  number = {1},
  pages = {18--37},
  publisher = {Routledge},
  issn = {0361-8269},
  doi = {10.1080/10417948709372710},
  urldate = {2024-07-17},
  abstract = {Within the context of a continuing research program on argument and group decision-making, this study reports refinements in an existing coding scheme of interpersonal argument, and an analysis of argument structures in consensus and dissensus groups. Four argument structures were identified: simple, compound, eroded, and convergent. In addition, consensus groups had a greater proportion of convergent arguments than did dissensus groups. Discussion focuses on future directions for interpersonal and small-group argument research.}
}

@article{canossaHonorToxicityDetecting2021,
  title = {For {{Honor}}, for {{Toxicity}}: {{Detecting Toxic Behavior}} through {{Gameplay}}},
  shorttitle = {For {{Honor}}, for {{Toxicity}}},
  author = {Canossa, Alessandro and Salimov, Dmitry and Azadvar, Ahmad and Harteveld, Casper and Yannakakis, Georgios},
  year = {2021},
  month = oct,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  number = {CHI PLAY},
  pages = {253:1--253:29},
  doi = {10.1145/3474680},
  urldate = {2024-07-19},
  abstract = {Is it possible to detect toxicity in games just by observing in-game behavior? If so, what are the behavioral factors that will help machine learning to discover the unknown relationship between gameplay and toxic behavior? In this initial study, we examine whether it is possible to predict toxicity in the MOBA gameFor Honor by observing in-game behavior for players that have been labeled as toxic (i.e. players that have been sanctioned by Ubisoft community managers). We test our hypothesis of detecting toxicity through gameplay with a dataset of almost 1,800 sanctioned players, and comparing these sanctioned players with unsanctioned players. Sanctioned players are defined by their toxic action type (offensive behavior vs. unfair advantage) and degree of severity (warned vs. banned). Our findings, based on supervised learning with random forests, suggest that it is not only possible to behaviorally distinguish sanctioned from unsanctioned players based on selected features of gameplay; it is also possible to predict both the sanction severity (warned vs. banned) and the sanction type (offensive behavior vs. unfair advantage). In particular, all random forest models predict toxicity, its severity, and type, with an accuracy of at least 82\%, on average, on unseen players. This research shows that observing in-game behavior can support the work of community managers in moderating and possibly containing the burden of toxic behavior.}
}

@inproceedings{caoImpactPerformanceLevel2017,
  title = {Impact of {{Performance Level}} and {{Group Composition}} on {{Student Learning}} during {{Collaborative Exams}}},
  booktitle = {Proceedings of the 2017 {{ACM Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  author = {Cao, Yingjun and Porter, Leo},
  year = {2017},
  month = jun,
  series = {{{ITiCSE}} '17},
  pages = {152--157},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3059009.3059024},
  urldate = {2024-07-18},
  abstract = {Collaborative exams have shown promise for improving student learning in computing. Prior studies have focused on benefits for all students, whereas this study seeks to refine our understanding of which students benefit and how group composition impacts that benefit. Using a crossover experimental design, the study first investigates whether students from differing performance levels (low, medium, or high) benefit from the collaborative exam. We find that students in the middle of the class (neither high nor low performers) tend to benefit strongly from the collaborative exam. Second, we explore whether group composition based on performance levels impacts the performance of members of the group. The results suggest more homogeneous groups (i.e., students in the group are at similar performance levels) are beneficial whereas students in groups with high heterogeneity do not experience significant performance differences between the pre-test and post-test.},
  isbn = {978-1-4503-4704-4}
}

@inproceedings{caoImpactPerformanceLevel2017a,
  title = {Impact of {{Performance Level}} and {{Group Composition}} on {{Student Learning}} during {{Collaborative Exams}}},
  booktitle = {Proceedings of the 2017 {{ACM Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  author = {Cao, Yingjun and Porter, Leo},
  year = {2017},
  month = jun,
  series = {{{ITiCSE}} '17},
  pages = {152--157},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3059009.3059024},
  urldate = {2024-07-18},
  abstract = {Collaborative exams have shown promise for improving student learning in computing. Prior studies have focused on benefits for all students, whereas this study seeks to refine our understanding of which students benefit and how group composition impacts that benefit. Using a crossover experimental design, the study first investigates whether students from differing performance levels (low, medium, or high) benefit from the collaborative exam. We find that students in the middle of the class (neither high nor low performers) tend to benefit strongly from the collaborative exam. Second, we explore whether group composition based on performance levels impacts the performance of members of the group. The results suggest more homogeneous groups (i.e., students in the group are at similar performance levels) are beneficial whereas students in groups with high heterogeneity do not experience significant performance differences between the pre-test and post-test.},
  isbn = {978-1-4503-4704-4}
}

@article{caoRevisitingContactHypothesis2017,
  title = {Revisiting the Contact Hypothesis: {{Effects}} of Different Modes of Computer-Mediated Communication on Intergroup Relationships},
  shorttitle = {Revisiting the Contact Hypothesis},
  author = {Cao, Bolin and Lin, Wan-Ying},
  year = {2017},
  month = may,
  journal = {International Journal of Intercultural Relations},
  volume = {58},
  pages = {23--30},
  issn = {0147-1767},
  doi = {10.1016/j.ijintrel.2017.03.003},
  urldate = {2024-07-19},
  abstract = {This study applies the contact hypothesis to computer-mediated communication (CMC) and examines whether intergroup computer-mediated contact can facilitate relationships between conflicting groups. The effectiveness of different CMC modes, text-based and video-based, in improving interpersonal and intergroup attitudes was compared. The results from an experiment indicated that video-based CMC exerted greater influence in improving participants' attitudes towards a targeted outgroup member when compared to text-based CMC. However, text-based CMC produced a stronger effect than video-based CMC in improving one's attitudes towards the outgroup as a whole.}
}

@article{carneiroPredictingSatisfactionPerceived2019,
  title = {Predicting Satisfaction: {{Perceived}} Decision Quality by Decision-Makers in {{Web-based}} Group Decision Support Systems},
  shorttitle = {Predicting Satisfaction},
  author = {Carneiro, Jo{\~a}o and Saraiva, Pedro and Concei{\c c}{\~a}o, Lu{\'i}s and Santos, Ricardo and Marreiros, Goreti and Novais, Paulo},
  year = {2019},
  month = apr,
  journal = {Neurocomputing},
  volume = {338},
  pages = {399--417},
  issn = {09252312},
  doi = {10.1016/j.neucom.2018.05.126},
  urldate = {2024-08-16},
  abstract = {In future, the organizations' likelihood to endure and succeed will depend greatly on the quality of every decision made. It is known that most decisions in organizations are made in group. With the purpose of supporting decision-makers anytime and anywhere, Web-based Group Decision Support Systems (GDSS) have been studied. The amount of Web-based GDSS incorporating automatic negotiation mechanisms such as argumentation has been steadily increasing. Usually, these systems/models are evaluated through mathematical proofs, number of rounds or seconds to propose (reach) a solution. However, those techniques are not very informative in terms of the decision quality. Here, we propose a model that intends to predict the decision-makers' satisfaction (perception of the decision quality), specifically designed to deal with multi-criteria problems. Our model considers aspects such as: meeting's outcomes, decision-maker's intentions, expectations and emotional cost. To validate the proposed model in terms of its ability to predict decision-makers' satisfaction, we developed a prototype of a Webbased GDSS to be used in a case study where the participant had to make a joint decision. The decision process consisted in a set of 5 rounds, where the participant could (re)configure his/her preferences along the process. The satisfaction model ascertained its ability to predict the participants' satisfaction and allowed to understand that (as is stated in the literature) the inclusion of cognitive and emotional variables is essential to evaluate satisfaction more accurately.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/FDIZ93U8/Carneiro et al. - 2019 - Predicting satisfaction Perceived decision qualit.pdf}
}

@inproceedings{carpinellaRoboticSocialAttributes2017,
  title = {The {{Robotic Social Attributes Scale}} ({{RoSAS}}): {{Development}} and {{Validation}}},
  shorttitle = {The {{Robotic Social Attributes Scale}} ({{RoSAS}})},
  booktitle = {Proceedings of the 2017 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Carpinella, Colleen M. and Wyman, Alisa B. and Perez, Michael A. and Stroessner, Steven J.},
  year = {2017},
  month = mar,
  series = {{{HRI}} '17},
  pages = {254--262},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2909824.3020208},
  urldate = {2024-07-18},
  abstract = {Accurately measuring perceptions of robots has become increasingly important as technological progress permits more frequent and extensive interaction between people and robots. Across four studies, we develop and validate a scale to measure social perception of robots. Drawing from the Godspeed Scale and from the psychological literature on social perception, we develop an 18-item scale (The Robotic Social Attribute Scale; RoSAS) to measure people's judgments of the social attributes of robots. Factor analyses reveal three underlying scale dimensions-warmth, competence, and discomfort. We then validate the RoSAS and show that the discomfort dimension does not reflect a concern with unfamiliarity. Using images of robots that systematically vary in their machineness and gender-typicality, we show that the application of these social attributes to robots varies based on their appearance.},
  isbn = {978-1-4503-4336-7}
}

@article{carrollHumancomputerInteraction1997,
  title = {Human-Computer Interaction},
  author = {CARROLL, JOHN M.},
  year = {1997},
  month = apr,
  journal = {Int. J. Hum.-Comput. Stud.},
  volume = {46},
  number = {4},
  pages = {501--522},
  issn = {1071-5819},
  doi = {10.1006/ijhc.1996.0101},
  urldate = {2024-07-19},
  abstract = {Human computer interaction (HCI) is the area of intersection between psychology and the social sciences, on the one hand, and computer science and technology, on the other. HCI researchers analyse and design-specific user-interface technologies (e.g. three-dimensional pointing devices, interactive video). They study and improve the processes of technology development (e.g. usability evaluation, design rationale). They develop and evaluate new applications of technology (e.g. computer conferencing, software design environments). Through the past two decades, HCI has progressively integrated its scientific concerns with the engineering goal of improving theusabilityof computer systems and applications, thus establishing a body of technical knowledge and methodology. HCI continues to provide a challenging test domain for applying and developing psychology and social science in the context of technology development and use.}
}

@misc{cartwrightInfluenceLeadershipControl1965,
  type = {{{SSRN Scholarly Paper}}},
  title = {Influence, {{Leadership}}, {{Control}}},
  author = {Cartwright, Dorwin},
  year = {1965},
  number = {1497766},
  address = {Rochester, NY},
  urldate = {2024-07-18},
  abstract = {Attempts to integrate multidisciplinary literature and empirical research on influence and power within organization theory. Three major aspects of the influence process are identified: (a) the agent exerting influence, (b) the method of exerting influence, and (c) the agent subjected to influence. An organization is defined as an arrangement of interdependent parts of a whole in which behavior is controlled and relatively predictable, and in which individual actions combine to lead to organizational accomplishments.         In contrast to the classical theory of organization, the essay supports Barnard (1938) that social influence emanates from individuals with leadership, and not necessarily because of the position they occupy.  According to Dahl (1957), agents exert social influence through the manipulation of a base of resources, and resources like recognition, appreciation, and friendliness as well as economic rewards are used. However, the relationship between power and determinative action is complex, and depends on the agent using power as a means or an end. The agent must calculate the cost of exerting influence, which hinges upon the outcome of the influence.         Ecological control plays some role in determining influence, outside of the power of the agent. Domain (groups or individuals being influenced) and range (overt actions or covert properties) of the agent also need to be taken into account. Influence must be understood as a complex social relationship between the agent of influence and those subjected to the agent's influence, and that domain and range must be considered together. A literature on leaders as well as a literature on followers should be developed, as well as mathematical models of the influence relation.  (CJC)},
  langid = {english}
}

@article{castelliLoyalMemberEffect2007,
  title = {The Loyal Member Effect: {{On}} the Preference for Ingroup Members Who Engage in Exclusive Relations with the Ingroup},
  shorttitle = {The Loyal Member Effect},
  author = {Castelli, Luigi and De Amicis, Leyla and Sherman, Steven J.},
  year = {2007},
  journal = {Developmental Psychology},
  volume = {43},
  number = {6},
  pages = {1347--1359},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-0599},
  doi = {10.1037/0012-1649.43.6.1347},
  abstract = {The goal of this article was to investigate an indirect form of intergroup differentiation in children in the context of racial attitudes: the preference for ingroup members who interact positively with other ingroup members rather than with outgroup members. Study 1 confirmed this general hypothesis with preschool and 1st-grade children, demonstrating that respondents preferred the ingroup member who played only with other ingroup members, evaluated this child more positively, and felt more similar to him or her. Studies 2 and 3 tested the boundary conditions of the phenomenon. Study 4 analyzed developmental changes demonstrating that the effect is no longer observed among 9- to 11-year-old children. Overall, these studies suggest that engaging in positive interactions with the outgroup might have its costs in terms of a relative devaluation and rejection by one's peers. Results are discussed by stressing the importance of intragroup processes for the regulation of intergroup relations among very young children. (PsycINFO Database Record (c) 2018 APA, all rights reserved)}
}

@article{castelliPowerUnsaidInfluence2012,
  title = {The {{Power}} of the {{Unsaid}}: {{The Influence}} of {{Nonverbal Cues}} on {{Implicit Attitudes}}},
  shorttitle = {The {{Power}} of the {{Unsaid}}},
  author = {CasTELli, Luigi and Carraro, Luciana and Pavan, Giulia and Murelli, Elisa and Carraro, Alessia},
  year = {2012},
  journal = {Journal of Applied Social Psychology},
  volume = {42},
  number = {6},
  pages = {1376--1393},
  issn = {1559-1816},
  doi = {10.1111/j.1559-1816.2012.00903.x},
  urldate = {2024-07-19},
  abstract = {Attitudes are often shaped through social influence processes. We examined how observation of nonverbal behaviors can impact on implicit and explicit racial attitudes. In Study 1, participants observed an interracial interaction in which a White actor expressed friendly or unfriendly nonverbal behaviors toward a Black target (e.g., low eye contact, large seating distance). The results show that newly formed implicit attitudes toward the Black actor were shaped accordingly. In Study 2, participants were required to read a passage containing stereotypical contents against Black people while a confederate either remained neutral or expressed her approval (e.g., nodding). Implicit attitudes toward Black people became more negative in the latter condition. The results confirm the power of nonverbal cues in shaping implicit attitudes.},
  copyright = {{\copyright} 2012 Wiley Periodicals, Inc},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/UGHVNQX4/Cas℡li et al. - 2012 - The Power of the Unsaid The Influence of Nonverba.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/UI2DCHM3/j.1559-1816.2012.00903.html}
}

@article{casteloTaskDependentAlgorithmAversion2019,
  title = {Task-{{Dependent Algorithm Aversion}}},
  author = {Castelo, Noah and Bos, Maarten W. and Lehmann, Donald R.},
  year = {2019},
  month = oct,
  journal = {Journal of Marketing Research},
  volume = {56},
  number = {5},
  pages = {809--825},
  publisher = {SAGE Publications Inc},
  issn = {0022-2437},
  doi = {10.1177/0022243719851788},
  urldate = {2024-07-18},
  abstract = {Research suggests that consumers are averse to relying on algorithms to perform tasks that are typically done by humans, despite the fact that algorithms often perform better. The authors explore when and why this is true in a wide variety of domains. They find that algorithms are trusted and relied on less for tasks that seem subjective (vs. objective) in nature. However, they show that perceived task objectivity is malleable and that increasing a task's perceived objectivity increases trust in and use of algorithms for that task. Consumers mistakenly believe that algorithms lack the abilities required to perform subjective tasks. Increasing algorithms' perceived affective human-likeness is therefore effective at increasing the use of algorithms for subjective tasks. These findings are supported by the results of four online lab studies with over 1,400 participants and two online field studies with over 56,000 participants. The results provide insights into when and why consumers are likely to use algorithms and how marketers can increase their use when they outperform humans.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/Q47RCHVR/Castelo et al. - 2019 - Task-Dependent Algorithm Aversion.pdf}
}

@article{castilloConstructionValidationIntragroup2007,
  title = {Construction and Validation of the {{Intragroup Marginalization Inventory}}},
  author = {Castillo, Linda G. and Conoley, Collie W. and Brossart, Daniel F. and Quiros, Alexander E.},
  year = {2007},
  journal = {Cultural Diversity \& Ethnic Minority Psychology},
  volume = {13},
  number = {3},
  pages = {232--240},
  publisher = {Educational Publishing Foundation},
  address = {US},
  issn = {1939-0106},
  doi = {10.1037/1099-9809.13.3.232},
  abstract = {This study reports the development and validation of the Intragroup Marginalization Inventory (IMI). The IMI consists of three scales that assess the extent to which an individual perceives interpersonal distancing from family, friends, and ethnic group community members. Intragroup marginalization is defined as the interpersonal distancing that occurs when an acculturating individual is believed to exhibit behaviors, values, and beliefs that are outside the heritage culture's group norms. Intragroup marginalization is based on social identity theory that asserts that groups maintain their identity by the distinctive behaviors of its members. When an acculturating individual displays behaviors or attitudes that differ from the heritage culture group's norms, the group may respond to the threat with social alienation of the transgressor. The results support the IMI's validity via a) content validity in the development of the items, b) construct validity in the selection of the factors based upon an exploratory factor analysis, c) the replicability of the factors based upon a confirmatory factor analysis, and d) discriminant validity through examining the relationship of the factors with other established measures. (PsycInfo Database Record (c) 2024 APA, all rights reserved)}
}

@inproceedings{chariMIMEMinorityInclusion2022,
  title = {{{MIME}}: {{Minority Inclusion}} for~{{Majority Group Enhancement}} of~{{AI Performance}}},
  shorttitle = {{{MIME}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2022},
  author = {Chari, Pradyumna and Ba, Yunhao and Athreya, Shreeram and Kadambi, Achuta},
  editor = {Avidan, Shai and Brostow, Gabriel and Ciss{\'e}, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
  year = {2022},
  pages = {326--343},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-19778-9_19},
  abstract = {Several papers have rightly included minority groups in artificial intelligence (AI) training data to improve test inference for minority groups and/or society-at-large. A society-at-large consists of both minority and majority stakeholders. A common misconception is that minority inclusion does not increase performance for majority groups alone. In this paper, we make the surprising finding that including minority samples can improve test error for the majority group. In other words, minority group inclusion leads to majority group enhancements (MIME) in performance. A theoretical existence proof of the MIME effect is presented and found to be consistent with experimental results on six different datasets. Project webpage: https://visual.ee.ucla.edu/mime.htm/.},
  isbn = {978-3-031-19778-9},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/95F3KJ2E/Chari et al. - 2022 - MIME Minority Inclusion for Majority Group Enhanc.pdf}
}

@article{chemersRoleEfficacyIdentity2011,
  title = {The {{Role}} of {{Efficacy}} and {{Identity}} in {{Science Career Commitment Among Underrepresented Minority Students}}},
  author = {Chemers, Martin M. and Zurbriggen, Eileen L. and Syed, Moin and Goza, Barbara K. and Bearman, Steve},
  year = {2011},
  journal = {Journal of Social Issues},
  volume = {67},
  number = {3},
  pages = {469--491},
  issn = {1540-4560},
  doi = {10.1111/j.1540-4560.2011.01710.x},
  urldate = {2024-07-19},
  abstract = {A web-based survey of members of the Society for the Advancement of Chicanos and Native Americans in Science tested a model that proposed that the effects of science support experiences on commitment to science careers would be mediated by science self-efficacy and identity as a scientist. A sample of 327 undergraduates and 338 graduate students and postdoctoral fellows described their science support experiences (research experience, mentoring, and community involvement); psychological variables (science self-efficacy, leadership/teamwork self-efficacy, and identity as a scientist); and commitment to pursue a career in scientific research. Structural equation model analyses supported our predictions. Among the undergraduates, science (but not leadership/teamwork), self-efficacy, and identity as a scientist fully mediated the effects of science support experiences and were strong predictors of commitment. Results for the graduate/postdoctoral sample revealed a very similar pattern of results, with the added finding that all three psychological mediators, including leadership/teamwork self-efficacy, predicted commitment.},
  copyright = {{\copyright} 2011 The Society for the Psychological Study of Social Issues},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/XLGC8NKT/Chemers et al. - 2011 - The Role of Efficacy and Identity in Science Caree.pdf}
}

@inproceedings{chenIntegratingFlowTheory2024,
  title = {Integrating {{Flow Theory}} and {{Adaptive Robot Roles}}: {{A Conceptual Model}} of {{Dynamic Robot Role Adaptation}} for the {{Enhanced Flow Experience}} in {{Long-term Multi-person Human-Robot Interactions}}},
  shorttitle = {Integrating {{Flow Theory}} and {{Adaptive Robot Roles}}},
  booktitle = {Proceedings of the 2024 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Chen, Huili and Alghowinem, Sharifa and Breazeal, Cynthia and Park, Hae Won},
  year = {2024},
  month = mar,
  eprint = {2401.02833},
  primaryclass = {cs},
  pages = {116--126},
  doi = {10.1145/3610977.3634945},
  urldate = {2024-04-02},
  abstract = {In this paper, we introduce a novel conceptual model for a robot's behavioral adaptation in its long-term interaction with humans, integrating dynamic robot role adaptation with principles of flow experience from psychology. This conceptualization introduces a hierarchical interaction objective grounded in the flow experience, serving as the overarching adaptation goal for the robot. This objective intertwines both cognitive and affective sub-objectives and incorporates individual and group-level human factors. The dynamic role adaptation approach is a cornerstone of our model, highlighting the robot's ability to fluidly adapt its support roles - from leader to follower - with the aim of maintaining equilibrium between activity challenge and user skill, thereby fostering the user's optimal flow experiences. Moreover, this work delves into a comprehensive exploration of the limitations and potential applications of our proposed conceptualization. Our model places a particular emphasis on the multi-person HRI paradigm, a dimension of HRI that is both under-explored and challenging. In doing so, we aspire to extend the applicability and relevance of our conceptualization within the HRI field, contributing to the future development of adaptive social robots capable of sustaining long-term interactions with humans.},
  archiveprefix = {arXiv},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/Q3YDTFQ6/Chen 등 - 2024 - Integrating Flow Theory and Adaptive Robot Roles .pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/SK5YSZKP/2401.html}
}

@article{chenMotivatingPotentialTeams2009,
  title = {The Motivating Potential of Teams: {{Test}} and Extension of {{Chen}} and {{Kanfer}}'s (2006) Cross-Level Model of Motivation in Teams},
  shorttitle = {The Motivating Potential of Teams},
  author = {Chen, Gilad and Kanfer, Ruth and DeShon, Richard P. and Mathieu, John E. and Kozlowski, Steve W. J.},
  year = {2009},
  month = sep,
  journal = {Organizational Behavior and Human Decision Processes},
  volume = {110},
  number = {1},
  pages = {45--55},
  issn = {0749-5978},
  doi = {10.1016/j.obhdp.2009.06.006},
  urldate = {2024-07-19},
  abstract = {Although individual- and team-level studies of motivational processes abound, very few have sought to link such phenomena across levels. Filling this gap, we build upon Chen and Kanfer's (2006) multilevel theoretical model of motivation in teams, to advance and test a cross-level model of relationships between individual and team motivation and performance. Data from two samples of undergraduates performing simulated team tasks supported the direct and mediated cross-level relationships between team-level prior performance, efficacy, and action processes with individual-level self-efficacy, goal striving, and performance. The findings provide support for a multilevel, system-based formulation of motivation and performance in teams. Findings also contribute to the on-going debate on whether motivational processes account for performance once controlling for prior performance.}
}

@inproceedings{chenPeekingHoodUber2015,
  title = {Peeking {{Beneath}} the {{Hood}} of {{Uber}}},
  booktitle = {Proceedings of the 2015 {{Internet Measurement Conference}}},
  author = {Chen, Le and Mislove, Alan and Wilson, Christo},
  year = {2015},
  month = oct,
  series = {{{IMC}} '15},
  pages = {495--508},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2815675.2815681},
  urldate = {2024-07-18},
  abstract = {Recently, Uber has emerged as a leader in the "sharing economy". Uber is a "ride sharing" service that matches willing drivers with customers looking for rides. However, unlike other open marketplaces (e.g., AirBnB), Uber is a black-box: they do not provide data about supply or demand, and prices are set dynamically by an opaque "surge pricing" algorithm. The lack of transparency has led to concerns about whether Uber artificially manipulate prices, and whether dynamic prices are fair to customers and drivers. In order to understand the impact of surge pricing on passengers and drivers, we present the first in-depth investigation of Uber. We gathered four weeks of data from Uber by emulating 43 copies of the Uber smartphone app and distributing them throughout downtown San Francisco (SF) and midtown Manhattan. Using our dataset, we are able to characterize the dynamics of Uber in SF and Manhattan, as well as identify key implementation details of Uber's surge price algorithm. Our observations about Uber's surge price algorithm raise important questions about the fairness and transparency of this system.},
  isbn = {978-1-4503-3848-6}
}

@article{chenSystemsTheoryMotivated2006,
  title = {Toward a {{Systems Theory}} of {{Motivated Behavior}} in {{Work Teams}}},
  author = {Chen, Gilad and Kanfer, Ruth},
  year = {2006},
  month = jan,
  journal = {Research in Organizational Behavior},
  series = {Research in {{Organizational Behavior}}},
  volume = {27},
  pages = {223--267},
  issn = {0191-3085},
  doi = {10.1016/S0191-3085(06)27006-0},
  urldate = {2024-07-19},
  abstract = {Work motivation theories and research have tended to focus either on individual motivation, ignoring contextual influences of team processes on individuals, or on team motivation, ignoring individual differences within the team. Redressing these limited, single-level views of motivation, we delineate a theoretical multilevel model of motivated behavior in teams. First, we conceptualize motivational processes at both the individual and team levels, highlighting the functional similarities in these processes across levels of analysis. We then delineate a set of theoretical propositions regarding the cross-level interplay between individual and team motivation, and antecedents and outcomes of individual and team motivation. Finally, we discuss the implications of our theoretical model for future research and managerial practices.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/7VFJW8SY/S0191308506270060.html}
}

@article{chenUserSatisfactionGroup2012,
  title = {User Satisfaction with Group Decision Making Process and Outcome},
  author = {Chen, Jengchung and Linn, Kyaw-Phyo},
  year = {2012},
  month = jun,
  journal = {Journal of Computer Information Systems},
  volume = {52},
  pages = {30--39},
  abstract = {Today's organizations are becoming more and more complex, and the complexity of organization's resource management makes it difficult for individual organizations to deal effectively with decision making. The pressures of complex environment and organization lead to business teams become distributed along with the dimension of space, time and computing. There is a need to develop a collaborative approach that can facilitate strategic decision-making and improve the effectiveness and efficiency of resource management. Much needed as well is integrating into this collaborative decisionmaking process a computer-based group decision support system (GDSS) to support and facilitate strategic decision making. This study attempts to provide the better understanding of how technology helps to enrich organizations' decision-making and identifies, which factors influence on group decision making performance.}
}

@inproceedings{chiangAreTwoHeads2023,
  title = {Are {{Two Heads Better Than One}} in {{AI-Assisted Decision Making}}? {{Comparing}} the {{Behavior}} and {{Performance}} of {{Groups}} and {{Individuals}} in {{Human-AI Collaborative Recidivism Risk Assessment}}},
  shorttitle = {Are {{Two Heads Better Than One}} in {{AI-Assisted Decision Making}}?},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Chiang, Chun-Wei and Lu, Zhuoran and Li, Zhuoyan and Yin, Ming},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--18},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581015},
  urldate = {2024-03-18},
  abstract = {With the prevalence of AI assistance in decision making, a more relevant question to ask than the classical question of ``are two heads better than one?'' is how groups' behavior and performance in AI-assisted decision making compare with those of individuals'. In this paper, we conduct a case study to compare groups and individuals in human-AI collaborative recidivism risk assessment along six aspects, including decision accuracy and confidence, appropriateness of reliance on AI, understanding of AI, decision-making fairness, and willingness to take accountability. Our results highlight that compared to individuals, groups rely on AI models more regardless of their correctness, but they are more confident when they overturn incorrect AI recommendations. We also find that groups make fairer decisions than individuals according to the accuracy equality criterion, and groups are willing to give AI more credit when they make correct decisions. We conclude by discussing the implications of our work.},
  isbn = {978-1-4503-9421-5},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/8DBPUDVX/Chiang 등 - 2023 - Are Two Heads Better Than One in AI-Assisted Decis.pdf}
}

@inproceedings{chiangAreTwoHeads2023a,
  title = {Are {{Two Heads Better Than One}} in {{AI-Assisted Decision Making}}? {{Comparing}} the {{Behavior}} and {{Performance}} of {{Groups}} and {{Individuals}} in {{Human-AI Collaborative Recidivism Risk Assessment}}},
  shorttitle = {Are {{Two Heads Better Than One}} in {{AI-Assisted Decision Making}}?},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Chiang, Chun-Wei and Lu, Zhuoran and Li, Zhuoyan and Yin, Ming},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--18},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581015},
  urldate = {2024-07-17},
  abstract = {With the prevalence of AI assistance in decision making, a more relevant question to ask than the classical question of ``are two heads better than one?'' is how groups' behavior and performance in AI-assisted decision making compare with those of individuals'. In this paper, we conduct a case study to compare groups and individuals in human-AI collaborative recidivism risk assessment along six aspects, including decision accuracy and confidence, appropriateness of reliance on AI, understanding of AI, decision-making fairness, and willingness to take accountability. Our results highlight that compared to individuals, groups rely on AI models more regardless of their correctness, but they are more confident when they overturn incorrect AI recommendations. We also find that groups make fairer decisions than individuals according to the accuracy equality criterion, and groups are willing to give AI more credit when they make correct decisions. We conclude by discussing the implications of our work.},
  isbn = {978-1-4503-9421-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/JXJV7DYN/Chiang et al. - 2023 - Are Two Heads Better Than One in AI-Assisted Decis.pdf}
}

@inproceedings{chiangEnhancingAIAssistedGroup2024,
  title = {Enhancing {{AI-Assisted Group Decision Making}} through {{LLM-Powered Devil}}'s {{Advocate}}},
  booktitle = {Proceedings of the 29th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Chiang, Chun-Wei and Lu, Zhuoran and Li, Zhuoyan and Yin, Ming},
  year = {2024},
  month = apr,
  series = {{{IUI}} '24},
  pages = {103--119},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3640543.3645199},
  urldate = {2024-04-16},
  abstract = {Group decision making plays a crucial role in our complex and interconnected world. The rise of AI technologies has the potential to provide data-driven insights to facilitate group decision making, although it is found that groups do not always utilize AI assistance appropriately. In this paper, we aim to examine whether and how the introduction of a devil's advocate in the AI-assisted group decision making processes could help groups better utilize AI assistance and change the perceptions of group processes during decision making. Inspired by the exceptional conversational capabilities exhibited by modern large language models (LLMs), we design four different styles of devil's advocate powered by LLMs, varying their interactivity (i.e., interactive vs. non-interactive) and their target of objection (i.e., challenge the AI recommendation or the majority opinion within the group). Through a randomized human-subject experiment, we find evidence suggesting that LLM-powered devil's advocates that argue against the AI model's decision recommendation have the potential to promote groups' appropriate reliance on AI. Meanwhile, the introduction of LLM-powered devil's advocate usually does not lead to substantial increases in people's perceived workload for completing the group decision making tasks, while interactive LLM-powered devil's advocates are perceived as more collaborating and of higher quality. We conclude by discussing the practical implications of our findings.},
  isbn = {9798400705083},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/E4ZPUB7B/Chiang 등 - 2024 - Enhancing AI-Assisted Group Decision Making throug.pdf}
}

@inproceedings{chiangEnhancingAIAssistedGroup2024a,
  title = {Enhancing {{AI-Assisted Group Decision Making}} through {{LLM-Powered Devil}}'s {{Advocate}}},
  booktitle = {Proceedings of the 29th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Chiang, Chun-Wei and Lu, Zhuoran and Li, Zhuoyan and Yin, Ming},
  year = {2024},
  month = apr,
  series = {{{IUI}} '24},
  pages = {103--119},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3640543.3645199},
  urldate = {2024-07-16},
  abstract = {Group decision making plays a crucial role in our complex and interconnected world. The rise of AI technologies has the potential to provide data-driven insights to facilitate group decision making, although it is found that groups do not always utilize AI assistance appropriately. In this paper, we aim to examine whether and how the introduction of a devil's advocate in the AI-assisted group decision making processes could help groups better utilize AI assistance and change the perceptions of group processes during decision making. Inspired by the exceptional conversational capabilities exhibited by modern large language models (LLMs), we design four different styles of devil's advocate powered by LLMs, varying their interactivity (i.e., interactive vs. non-interactive) and their target of objection (i.e., challenge the AI recommendation or the majority opinion within the group). Through a randomized human-subject experiment, we find evidence suggesting that LLM-powered devil's advocates that argue against the AI model's decision recommendation have the potential to promote groups' appropriate reliance on AI. Meanwhile, the introduction of LLM-powered devil's advocate usually does not lead to substantial increases in people's perceived workload for completing the group decision making tasks, while interactive LLM-powered devil's advocates are perceived as more collaborating and of higher quality. We conclude by discussing the practical implications of our findings.},
  isbn = {9798400705083}
}

@inproceedings{chiangExploringEffectsMachine2022,
  title = {Exploring the {{Effects}} of {{Machine Learning Literacy Interventions}} on {{Laypeople}}'s {{Reliance}} on {{Machine Learning Models}}},
  booktitle = {Proceedings of the 27th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Chiang, Chun-Wei and Yin, Ming},
  year = {2022},
  month = mar,
  series = {{{IUI}} '22},
  pages = {148--161},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3490099.3511121},
  urldate = {2024-07-17},
  abstract = {Today, machine learning (ML) technologies have penetrated almost every aspect of people's lives, yet public understandings of these technologies are often limited. This highlights the urgent need of designing effective methods to increase people's machine learning literacy, as the lack of relevant knowledge may result in people's inappropriate usage of machine learning technologies. In this paper, we focus on an ML-assisted decision-making setting and conduct a human-subject randomized experiment to explore how providing different types of user tutorials as the machine learning literacy interventions can influence laypeople's reliance on ML models, on both in-distribution and out-of-distribution examples. We vary the existence, interactivity and scope of the user tutorial across different treatments in our experiment. Our results show that user tutorials, when presented in appropriate forms, can help some people rely on ML models more appropriately. For example, for those individuals who have relatively high ability in solving the decision-making task themselves, receiving a user tutorial that is interactive and addresses the specific ML model to be used allows them to reduce their over-reliance on the ML model when they could outperform the model. In contrast, low-performing individuals' reliance on the ML model is not affected by the presence or the type of user tutorial. Finally, we also find that people perceive the interactive tutorial to be more understandable and slightly more useful. We conclude by discussing the design implications of our study.},
  isbn = {978-1-4503-9144-3}
}

@inproceedings{chiangYoudBetterStop2021,
  title = {You'd {{Better Stop}}! {{Understanding Human Reliance}} on {{Machine Learning Models}} under {{Covariate Shift}}},
  booktitle = {Proceedings of the 13th {{ACM Web Science Conference}} 2021},
  author = {Chiang, Chun-Wei and Yin, Ming},
  year = {2021},
  month = jun,
  series = {{{WebSci}} '21},
  pages = {120--129},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3447535.3462487},
  urldate = {2024-07-17},
  abstract = {Decision-making aids powered by machine learning models become increasingly prevalent on the web today. However, when applied to a new distribution of data that is different from the training data (i.e., when covariate shift occurs), machine learning models often suffer from performance degradation and may provide misleading recommendations to human decision-makers. In this paper, we conduct a randomized experiment to investigate how people rely on machine learning models to make decisions under covariate shift. Surprisingly, we find that people rely on machine learning models more when making decisions on out-of-distribution data than in-distribution data. Moreover, while increasing people's awareness of the machine learning model's possible performance disparity on different data helps decrease people's over-reliance on the model under covariate shift, enabling people to visualize the data distributions and the model's performance does not seem to help. We conclude by discussing the implication of our results.},
  isbn = {978-1-4503-8330-1}
}

@article{choEffectsArgumentationScaffolds2002,
  title = {The Effects of Argumentation Scaffolds on Argumentation and Problem Solving},
  author = {Cho, Kyoo-Lak and Jonassen, David H.},
  year = {2002},
  month = sep,
  journal = {Educational Technology Research and Development},
  volume = {50},
  number = {3},
  pages = {5--22},
  issn = {1556-6501},
  doi = {10.1007/BF02505022},
  urldate = {2024-07-17},
  abstract = {An important skill in solving problems, especially ill-structured problems, is the production of coherent arguments to justify solutions and actions. Because direct instruction in argumentation has produced inconsistent results and cannot effectively support online learning, we examined the use of online argumentation scaffolds to engage and support coherent argumentation. In this study, we showed that providing a constraint-based argumentation scaffold during group problem-solving activities increased the generation of coherent arguments. The same scaffold further resulted in significantly more problem-solving actions during collaborative group discussions. The effects of the scaffold varied for problem type. Groups that solved ill-structured problems produced more extensive arguments. When solving ill-structured problems, students need more argumentation support because of the importance of generating and supporting alternative solutions. The close relationship between argumentation and problem solving, especially ill-structured problem solving, is significant. The effects of the argument scaffold consistently transferred to the production of arguments during individual problem solving. Students used the familiar argumentation scripts while solving problems individually.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/6YUI688T/Cho and Jonassen - 2002 - The effects of argumentation scaffolds on argument.pdf}
}

@article{christophersonPositiveNegativeImplications2007,
  title = {The Positive and Negative Implications of Anonymity in {{Internet}} Social Interactions: ``{{On}} the {{Internet}}, {{Nobody Knows You}}'re a {{Dog}}''},
  shorttitle = {The Positive and Negative Implications of Anonymity in {{Internet}} Social Interactions},
  author = {Christopherson, Kimberly M.},
  year = {2007},
  month = nov,
  journal = {Computers in Human Behavior},
  series = {Including the {{Special Issue}}: {{Education}} and {{Pedagogy}} with {{Learning Objects}} and {{Learning Designs}}},
  volume = {23},
  number = {6},
  pages = {3038--3056},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2006.09.001},
  urldate = {2024-06-23},
  abstract = {The growth of the Internet at a means of communication has sparked the interest of researchers in several fields (e.g. communication, social psychology, industrial-organizational psychology) to investigate the issues surrounding the expression of different social behaviors in this unique social context. Of special interest to researchers is the increased importance that anonymity seems to play in computer-mediated communication (CMC). This paper reviews the literature related to the issues of anonymity within the social context, particularly in CMC, demonstrating the usefulness of established social psychological theory to explain behavior in CMC and discussing the evolution of the current theoretical explanations in explaining the effects of anonymity in social behavior in CMC environments. Several suggestions for future research are proposed in an attempt to provide researchers with new avenues to investigate how anonymity can play both positive and negative roles in CMC.}
}

@inproceedings{chungHowMakeRobots2022,
  title = {How to {{Make Robots}}' {{Optimal Anthropomorphism Level}}: {{Manipulating Social Cues}} and {{Spatial Context}} for an {{Improved User Experience}}},
  shorttitle = {How to {{Make Robots}}' {{Optimal Anthropomorphism Level}}},
  booktitle = {2022 17th {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}} ({{HRI}})},
  author = {Chung, Hanna and Lee, Sukho and Jun, Soojin},
  year = {2022},
  month = mar,
  pages = {731--736},
  doi = {10.1109/HRI53351.2022.9889376},
  urldate = {2024-07-19},
  abstract = {With the growing interest in robot related research and industry, there is a demand to shape user experience more sophisticatedly in human-robot interaction. The purpose of this study is to define the elements for manipulating robot's verbal anthropomorphism and investigate the influence on user experience associated with spatial context. Based on the identified elements, we divided the robot's anthropomorphism into three levels (high, medium, low) and associated them with two spatial contexts (open, closed). The results revealed that a higher level of verbal anthropomorphism mostly induced positive user experiences; however, people sometimes tended to prefer a medium level, especially in terms of usefulness. Further, privacy concerns were significantly higher in open space. Consequently, we propose that designers and researchers deviate from the two levels of anthropomorphism (e.g., high or low, existing or not) generally used in prior studies to a new perspective that also considers the spatial context.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/L2CJHZTG/Chung et al. - 2022 - How to Make Robots' Optimal Anthropomorphism Level.pdf}
}

@article{cialdiniSocialInfluenceCompliance2004,
  title = {Social {{Influence}}: {{Compliance}} and {{Conformity}}},
  shorttitle = {Social {{Influence}}},
  author = {Cialdini, Robert B. and Goldstein, Noah J.},
  year = {2004},
  month = feb,
  journal = {Annual Review of Psychology},
  volume = {55},
  number = {Volume 55, 2004},
  pages = {591--621},
  publisher = {Annual Reviews},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev.psych.55.090902.142015},
  urldate = {2024-07-22},
  abstract = {This review covers recent developments in the social influence literature, focusing primarily on compliance and conformity research published between 1997 and 2002. The principles and processes underlying a target\&apos;s susceptibility to outside influences are considered in light of three goals fundamental to rewarding human functioning. Specifically, targets are motivated to form accurate perceptions of reality and react accordingly, to develop and preserve meaningful social relationships, and to maintain a favorable self-concept. Consistent with the current movement in compliance and conformity research, this review emphasizes the ways in which these goals interact with external forces to engender social influence processes that are subtle, indirect, and outside of awareness.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/ZPEH9VD6/annurev.psych.55.090902.html}
}

@misc{CodesigningDigitalTools,
  title = {Co-Designing {{Digital Tools}} to {{Enhance Speech}} and {{Language Therapy Training}} in {{Ghana}} {\textbar} {{Proceedings}} of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  journal = {ACM Conferences},
  doi = {10.1145/3313831.3376474},
  urldate = {2024-07-19},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/N3TIMPU9/Co-designing Digital Tools to Enhance Speech and L.pdf}
}

@article{cookeMeasuringTeamKnowledge2000,
  title = {Measuring {{Team Knowledge}}},
  author = {Cooke, Nancy J. and Salas, Eduardo and {Cannon-Bowers}, Janis A. and Stout, Ren{\'e}e J.},
  year = {2000},
  month = mar,
  journal = {Human Factors},
  volume = {42},
  number = {1},
  pages = {151--173},
  publisher = {SAGE Publications Inc},
  issn = {0018-7208},
  doi = {10.1518/001872000779656561},
  urldate = {2024-07-19},
  abstract = {Multioperator tasks often require complex cognitive processing at the team level. Many team cognitive processes, such as situation assessment and coordination, are thought to rely on team knowledge. Team knowledge is multifaceted and comprises relatively generic knowledge in the form of team mental models and more specific team situation models. In this methodological review paper, we review recent efforts to measure team knowledge in the context of mapping specific methods onto features of targeted team knowledge. Team knowledge features include type, homogeneity versus heterogeneity, and rate of knowledge change. Measurement features include knowledge elicitation method, team metric, and aggregation method. When available, we highlight analytical conclusions or empirical data that support a connection between team knowledge and measurement method. In addition, we present empirical results concerning the relation between team knowledge and performance for each measurement method and identify research and methodological needs. Addressing issues surrounding the measurement of team knowledge is a prerequisite to understanding team cognition and its relation to team performance and to designing training programs or devices to facilitate team cognition.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/6V2U55TP/Cooke et al. - 2000 - Measuring Team Knowledge.pdf}
}

@article{coppolinoperfumiDeindividuationEffectsNormative2019,
  title = {Deindividuation Effects on Normative and Informational Social Influence within Computer-Mediated-Communication},
  author = {Coppolino Perfumi, Serena and Bagnoli, Franco and Caudek, Corrado and Guazzini, Andrea},
  year = {2019},
  month = mar,
  journal = {Computers in Human Behavior},
  volume = {92},
  pages = {230--237},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2018.11.017},
  urldate = {2024-06-23},
  abstract = {Research on social influence shows that different patterns take place when this phenomenon happens within computer-mediated-communication (CMC), if compared to face-to-face interaction. Informational social influence can still easily take place also by means of CMC, however normative influence seems to be more affected by the environmental characteristics. Different authors have theorized that deindividuation nullifies the effects of normative influence, but the Social Identity Model of Deindividuation Effects theorizes that users will conform even when deindividuated, but only if social identity is made salient. The two typologies of social influence have never been studied in comparison, therefore in our work, we decided to create an online experiment to observe how the same variables affect them, and in particular how deindividuation works in both cases. The 181 experimental subjects that took part, performed 3 tasks: one aiming to elicit normative influence, and two semantic tasks created to test informational influence. Entropy has been used as a mathematical assessment of information availability. Our results show that normative influence becomes almost ineffective within CMC (1.4\% of conformity) when subjects are deindividuated. Informational influence is generally more effective than normative influence within CMC (15--29\% of conformity), but similarly to normative influence, it is inhibited by deindividuation.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/QPAQ4QDA/S0747563218305521.html}
}

@article{coppolinoperfumiDeindividuationEffectsNormative2019a,
  title = {Deindividuation Effects on Normative and Informational Social Influence within Computer-Mediated-Communication},
  author = {Coppolino Perfumi, Serena and Bagnoli, Franco and Caudek, Corrado and Guazzini, Andrea},
  year = {2019},
  month = mar,
  journal = {Computers in Human Behavior},
  volume = {92},
  pages = {230--237},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2018.11.017},
  urldate = {2024-06-23},
  abstract = {Research on social influence shows that different patterns take place when this phenomenon happens within computer-mediated-communication (CMC), if compared to face-to-face interaction. Informational social influence can still easily take place also by means of CMC, however normative influence seems to be more affected by the environmental characteristics. Different authors have theorized that deindividuation nullifies the effects of normative influence, but the Social Identity Model of Deindividuation Effects theorizes that users will conform even when deindividuated, but only if social identity is made salient. The two typologies of social influence have never been studied in comparison, therefore in our work, we decided to create an online experiment to observe how the same variables affect them, and in particular how deindividuation works in both cases. The 181 experimental subjects that took part, performed 3 tasks: one aiming to elicit normative influence, and two semantic tasks created to test informational influence. Entropy has been used as a mathematical assessment of information availability. Our results show that normative influence becomes almost ineffective within CMC (1.4\% of conformity) when subjects are deindividuated. Informational influence is generally more effective than normative influence within CMC (15--29\% of conformity), but similarly to normative influence, it is inhibited by deindividuation.},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/RZUUKZRA/S0747563218305521.html}
}

@article{cordovaExperiencesComputerScience2011,
  title = {Experiences in {{Computer Science Wonderland}}: A Success Story with {{Alice}}},
  shorttitle = {Experiences in {{Computer Science Wonderland}}},
  author = {Cordova, Jose L. and Eaton, V. and Taylor, Kim},
  year = {2011},
  month = may,
  journal = {Journal of Computing Sciences in Colleges},
  urldate = {2024-07-19},
  abstract = {Computer Science Wonderland, a non-residential camp involving 36 students and 12 teachers from area high schools, was held on the campus of our institution during the summer of 2010. The focus of the camp was to engage teachers and students in the development of graphical animations using the Alice programming environment, with the objective of introducing teachers and students to programming and logical problem solving. A secondary objective was to generate interest in the computing profession by presenting and completing activities in the areas of computing history, computing ethics, computing careers, Boolean logic, binary number representation, and cryptography. Throughout the camp, emphasis was placed on a few recurring themes: teamwork, creativity, and interdisciplinary relationships between computing and the arts/humanities. This paper offers a model for and evaluation of a computer science camp for middle/secondary school students and teachers.}
}

@article{cormierWouldYouRobot,
  title = {Would {{You Do}} as a {{Robot Commands}}? {{An Obedience Study}} for {{Human-Robot Interaction}}},
  author = {Cormier, Derek and Newman, Gem and Nakane, Masayuki and Young, James E and Durocher, Stephane},
  abstract = {This paper presents an investigation into how people respond to a robot posing as an authority figure, giving commands. This is an increasingly important question as robots continue to become more autonomous and capable and participate in more task scenarios where they work with people. We designed and conducted a human-robot interaction obedience experiment with a human and a robot experimenter, and our results highlight the complexity of obedience and detail some of the variables involved, and show that, at the very least, people can be pressured by a robot to continue a highly tedious task. This paper offers an exploration of the ethical challenges of conducting obedience human-robot interaction studies, the results from one such study, and a set of initial guidelines for this area of research.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/8WZBH4W7/Cormier et al. - Would You Do as a Robot Commands An Obedience Stu.pdf}
}

@article{cosierAgreementThinkingAlike1990,
  title = {Agreement and Thinking Alike: Ingredients for Poor Decisions},
  shorttitle = {Agreement and Thinking Alike},
  author = {Cosier, Richard A. and Schwenk, Charles R.},
  year = {1990},
  month = jan,
  journal = {Academy of Management Perspectives},
  volume = {4},
  number = {1},
  pages = {69--74},
  publisher = {Academy of Management},
  issn = {1558-9080},
  doi = {10.5465/ame.1990.4274710},
  urldate = {2024-07-17},
  abstract = {People frequently believe that conflict is to be avoided in organizations. They think that meetings and decisions should reflect agreement and consensus. This article suggests that fostering disagreement in a structured setting may actually lead to better decisions. Two techniques for programming conflict into the decision-making process are suggested---the devil's advocate decision program (DADP) and the dialectic method (DM). In particular, evidence indicates that larger firms operating in uncertain environments benefit from encouraging structured conflict in decision-making. This article challenges managers to consider either the devil's advocate or dialectic methods to program conflict into important organizational decisions.}
}

@article{cowgillBiasProductivityHumans,
  title = {Bias and {{Productivity}} in {{Humans}} and {{Algorithms}}: {{Theory}} and {{Evidence}} from {{Re}}{\textasciiacute}sume{\textasciiacute} {{Screening}}},
  author = {Cowgill, Bo},
  abstract = {Where should better learning technology improve decisions? I develop a formal model of decision-making in which better learning technology is complementary with experimentation. Noisy, inconsistent decision-making by humans introduces quasi-experimental variation into training datasets, which complements learning. The model makes heterogeneous predictions about when machine learning algorithms can improve human biases. These algorithms will can remove human biases exhibited in historical training data, but only if the human training decisions are sufficiently noisy; otherwise the algorithms will codify or exacerbate existing biases. I then test these predictions in a field experiment hiring workers for white-collar jobs. The introduction of machine learning technology yields candidates that are a) +14\% more likely to pass interviews and receive a job offer, b) +18\% more likely to accept job offers when extended, and c) 0.2s-0.4s more productive once hired as employees. They are also 12\% less likely to show evidence of competing job offers during salary negotiations. These results were driven by candidates who were evaluated in a noisy, biased way in historical data used for training. These candidates are broadly non-traditional, particularly candidates who graduated from non-elite colleges, who lack job referrals, who lack prior experience, whose credentials are atypical and who have strong non-cognitive soft-skills.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/WNTDU6HM/Cowgill - Bias and Productivity in Humans and Algorithms Th.pdf}
}

@article{craigEffectivenessMenWomen1986,
  title = {The Effectiveness of Men and Women in Problem-Solving Groups as a Function of Group Gender Composition},
  author = {Craig, Jane M. and Sherif, Carolyn W.},
  year = {1986},
  month = apr,
  journal = {Sex Roles},
  volume = {14},
  number = {7},
  pages = {453--466},
  issn = {1573-2762},
  doi = {10.1007/BF00288427},
  urldate = {2024-07-19},
  abstract = {Previous research suggests that the fewer women in a group, the less likely their ideas will be considered. The present study was designed to test the effect of gender composition on women's influence. Thirty groups were asked to solve two problems, first as individuals, then as groups. Composition and gender of the subject receiving a helpful clue were varied. Subjects rated the second task and members of the group, and a Bales Interaction Analysis was conducted. Results indicated that men were more influential than women only when in the minority, that women had smaller proportions of leadership acts than men, and that some stereotyped attitudes existed. Results were discussed in terms of previous findings, and suggestions for future research were made.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/2YY2GRNW/Craig and Sherif - 1986 - The effectiveness of men and women in problem-solv.pdf}
}

@inproceedings{crickGenderParityPeer2022,
  title = {Gender Parity in Peer Assessment of Team Software Development Projects},
  booktitle = {Proceedings of the 6th {{Conference}} on {{Computing Education Practice}}},
  author = {Crick, Tom and Prickett, Tom and Bradnum, Jill and Godfrey, Alan},
  year = {2022},
  month = jan,
  series = {{{CEP}} '22},
  pages = {9--12},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3498343.3498346},
  urldate = {2024-07-18},
  abstract = {Development projects in which small teams of learners develop software/digital artefacts are common features of computing-related degree programmes. Within these team projects, it can be problematic ensuring students are fairly recognised and rewarded for the contribution they make to the collective team effort and outputs. Peer assessment is a commonly used approach to promote fairness and due recognition. Maintaining parity within assessment processes is also a critical aspect of fairness. This paper presents the processes employed for the operation of one such team project at a UK higher education institution, using the Team-Q rubric and analysing the impact of the (self-identified) gender of learner marking and the learner being marked on the scores obtained. The results from this institutional sample (N=121) using the Team-Q metric offers evidence of gender parity in this context. This study also makes the case for continued vigilance to ensure Team-Q and other rubrics are used in a manner that supports gender parity in computing.},
  isbn = {978-1-4503-9561-8},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VBE4Z6IF/Crick et al. - 2022 - Gender parity in peer assessment of team software .pdf}
}

@article{curseuGenderDiversityMotivation2018,
  title = {Gender Diversity and Motivation in Collaborative Learning Groups: The Mediating Role of Group Discussion Quality},
  shorttitle = {Gender Diversity and Motivation in Collaborative Learning Groups},
  author = {Cur{\c s}eu, Petru Lucian and Chappin, Maryse M. H. and Jansen, Rob J. G.},
  year = {2018},
  month = apr,
  journal = {Social Psychology of Education},
  volume = {21},
  number = {2},
  pages = {289--302},
  issn = {1573-1928},
  doi = {10.1007/s11218-017-9419-5},
  urldate = {2024-07-17},
  abstract = {Collaborative learning is often used in higher education to help students develop their teamwork skills and acquire curricular knowledge. In this paper we test a mediation model in which the quality of group discussions mediates the impact of gender diversity and group motivation on collaborative learning effectiveness. Our results show that the proportion of women in groups, and the group level need for cognition and core self-evaluations (within group average) positively predict discussion quality that in turn predicts group (academic) performance. Our results show that discussion quality fully mediates the effects of need for cognition and core self-evaluations on group performance. The effect for gender diversity on group performance is only partly mediated by discussion quality.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VZARLMET/Curşeu et al. - 2018 - Gender diversity and motivation in collaborative l.pdf}
}

@inproceedings{danryDontJustTell2023,
  title = {Don't {{Just Tell Me}}, {{Ask Me}}: {{AI Systems}} That {{Intelligently Frame Explanations}} as {{Questions Improve Human Logical Discernment Accuracy}} over {{Causal AI}} Explanations},
  shorttitle = {Don't {{Just Tell Me}}, {{Ask Me}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Danry, Valdemar and Pataranutaporn, Pat and Mao, Yaoli and Maes, Pattie},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3580672},
  urldate = {2024-03-26},
  abstract = {Critical thinking is an essential human skill. Despite the importance of critical thinking, research reveals that our reasoning ability suffers from personal biases and cognitive resource limitations, leading to potentially dangerous outcomes. This paper presents the novel idea of AI-framed Questioning that turns information relevant to the AI classification into questions to actively engage users' thinking and scaffold their reasoning process. We conducted a study with 204 participants comparing the effects of AI-framed Questioning on a critical thinking task; discernment of logical validity of socially divisive statements. Our results show that compared to no feedback and even causal AI explanations of an always correct system, AI-framed Questioning significantly increase human discernment of logically flawed statements. Our experiment exemplifies a future style of Human-AI co-reasoning system, where the AI becomes a critical thinking stimulator rather than an information teller.},
  isbn = {978-1-4503-9421-5},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/XZHUGHYS/Danry 등 - 2023 - Don’t Just Tell Me, Ask Me AI Systems that Intell.pdf}
}

@inproceedings{danryDontJustTell2023a,
  title = {Don't {{Just Tell Me}}, {{Ask Me}}: {{AI Systems}} That {{Intelligently Frame Explanations}} as {{Questions Improve Human Logical Discernment Accuracy}} over {{Causal AI}} Explanations},
  shorttitle = {Don't {{Just Tell Me}}, {{Ask Me}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Danry, Valdemar and Pataranutaporn, Pat and Mao, Yaoli and Maes, Pattie},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3580672},
  urldate = {2024-07-17},
  abstract = {Critical thinking is an essential human skill. Despite the importance of critical thinking, research reveals that our reasoning ability suffers from personal biases and cognitive resource limitations, leading to potentially dangerous outcomes. This paper presents the novel idea of AI-framed Questioning that turns information relevant to the AI classification into questions to actively engage users' thinking and scaffold their reasoning process. We conducted a study with 204 participants comparing the effects of AI-framed Questioning on a critical thinking task; discernment of logical validity of socially divisive statements. Our results show that compared to no feedback and even causal AI explanations of an always correct system, AI-framed Questioning significantly increase human discernment of logically flawed statements. Our experiment exemplifies a future style of Human-AI co-reasoning system, where the AI becomes a critical thinking stimulator rather than an information teller.},
  isbn = {978-1-4503-9421-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/BLCLZD7N/Danry et al. - 2023 - Don’t Just Tell Me, Ask Me AI Systems that Intell.pdf}
}

@article{davisTeamBelongingIntegrating2022,
  title = {Team {{Belonging}}: {{Integrating Teamwork}} and {{Diversity Training Through Emotions}}},
  shorttitle = {Team {{Belonging}}},
  author = {Davis, Alicia S. and Kafka, Adrienne M. and {Gonz{\'a}lez-Morales}, M. Gloria and Feitosa, Jennifer},
  year = {2022},
  month = feb,
  journal = {Small Group Research},
  volume = {53},
  number = {1},
  pages = {88--127},
  publisher = {SAGE Publications Inc},
  issn = {1046-4964},
  doi = {10.1177/10464964211044813},
  urldate = {2024-07-19},
  abstract = {With the worldwide focus shifting toward important questions of what diversity means to society, organizations are attempting to keep up with employees' needs to feel recognized and belong. Given that traditionally team and diversity trainings are provided separately, with different theoretical backgrounds and goals, they are often misaligned and ineffective. We review 339 empirical articles depicting a team, diversity, or emotional management training to extract themes and determine which methods are most effective. Although research has demonstrated the importance of belonging for providing positive workplace outcomes, we found that the traditional design of these trainings and lack of emotional management prevent a balance between team and diversity goals, preventing belonging. We propose an integrative training with emotional management to help teams foster optimal belonging, where members can unite together through their differences. Accordingly, our themes inform this training model that can inspire future research into more effective training.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/RKW7I25Y/Davis et al. - 2022 - Team Belonging Integrating Teamwork and Diversity.pdf}
}

@misc{DBpia,
  title = {{{DBpia}}},
  urldate = {2024-08-12},
  abstract = {논문, 학술저널 검색 플랫폼 서비스},
  howpublished = {https://www.dbpia.co.kr},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/3BGLF2GQ/pdfView.html}
}

@inproceedings{demirTeamCommunicationBehaviors2016,
  title = {Team Communication Behaviors of the Human-Automation Teaming},
  booktitle = {2016 {{IEEE International Multi-Disciplinary Conference}} on {{Cognitive Methods}} in {{Situation Awareness}} and {{Decision Support}} ({{CogSIMA}})},
  author = {Demir, Mustafa and McNeese, Nathan J. and Cooke, Nancy J.},
  year = {2016},
  month = mar,
  pages = {28--34},
  issn = {2379-1675},
  doi = {10.1109/COGSIMA.2016.7497782},
  urldate = {2024-07-18},
  abstract = {If synthetic teammates are to be considered ``team players'', then they must be better equipped to handle the subtleties of communication and coordination with their human teammates. In this study, the team communication behaviors of a human-automation team were analyzed for the identification of which are the best predictors of team performance. The LASSO (Least Absolute Shrinkage and Selection Operator) method was used to select the team communication behaviors that were the best predictors of team performance and, in the end, 16 such role related communication behaviors (at both the role and condition level) were included in the final model. Findings indicate that in general, negatively perceived communication behaviors are predictors of negative team performance. Through this study, we also learned that even when human team members follow their optimal and expected communication behaviors when communicating with a synthetic teammate, these behaviors are still predictors of negative team performance. This finding holds important future considerations: even if human team members are properly communicating with a synthetic teammate, the errors and lack of human-like behavior on the part of the latter can still result in a negative team performance.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/ANBPC46T/Demir et al. - 2016 - Team communication behaviors of the human-automati.pdf}
}

@inproceedings{demirTeamCommunicationBehaviors2016a,
  title = {Team Communication Behaviors of the Human-Automation Teaming},
  booktitle = {2016 {{IEEE International Multi-Disciplinary Conference}} on {{Cognitive Methods}} in {{Situation Awareness}} and {{Decision Support}} ({{CogSIMA}})},
  author = {Demir, Mustafa and McNeese, Nathan J. and Cooke, Nancy J.},
  year = {2016},
  month = mar,
  pages = {28--34},
  issn = {2379-1675},
  doi = {10.1109/COGSIMA.2016.7497782},
  urldate = {2024-07-19},
  abstract = {If synthetic teammates are to be considered ``team players'', then they must be better equipped to handle the subtleties of communication and coordination with their human teammates. In this study, the team communication behaviors of a human-automation team were analyzed for the identification of which are the best predictors of team performance. The LASSO (Least Absolute Shrinkage and Selection Operator) method was used to select the team communication behaviors that were the best predictors of team performance and, in the end, 16 such role related communication behaviors (at both the role and condition level) were included in the final model. Findings indicate that in general, negatively perceived communication behaviors are predictors of negative team performance. Through this study, we also learned that even when human team members follow their optimal and expected communication behaviors when communicating with a synthetic teammate, these behaviors are still predictors of negative team performance. This finding holds important future considerations: even if human team members are properly communicating with a synthetic teammate, the errors and lack of human-like behavior on the part of the latter can still result in a negative team performance.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/M9NJRTF7/Demir et al. - 2016 - Team communication behaviors of the human-automati.pdf}
}

@article{dietvorstAlgorithmAversionPeople2015,
  title = {Algorithm Aversion: {{People}} Erroneously Avoid Algorithms after Seeing Them Err},
  shorttitle = {Algorithm Aversion},
  author = {Dietvorst, Berkeley J. and Simmons, Joseph P. and Massey, Cade},
  year = {2015},
  journal = {Journal of Experimental Psychology: General},
  volume = {144},
  number = {1},
  pages = {114--126},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-2222},
  doi = {10.1037/xge0000033},
  abstract = {Research shows that evidence-based algorithms more accurately predict the future than do human forecasters. Yet when forecasters are deciding whether to use a human forecaster or a statistical algorithm, they often choose the human forecaster. This phenomenon, which we call algorithm aversion, is costly, and it is important to understand its causes. We show that people are especially averse to algorithmic forecasters after seeing them perform, even when they see them outperform a human forecaster. This is because people more quickly lose confidence in algorithmic than human forecasters after seeing them make the same mistake. In 5 studies, participants either saw an algorithm make forecasts, a human make forecasts, both, or neither. They then decided whether to tie their incentives to the future predictions of the algorithm or the human. Participants who saw the algorithm perform were less confident in it, and less likely to choose it over an inferior human forecaster. This was true even among those who saw the algorithm outperform the human. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{dietvorstAlgorithmAversionPeople2015a,
  title = {Algorithm Aversion: {{People}} Erroneously Avoid Algorithms after Seeing Them Err},
  shorttitle = {Algorithm Aversion},
  author = {Dietvorst, Berkeley J. and Simmons, Joseph P. and Massey, Cade},
  year = {2015},
  journal = {Journal of Experimental Psychology: General},
  volume = {144},
  number = {1},
  pages = {114--126},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-2222},
  doi = {10.1037/xge0000033},
  abstract = {Research shows that evidence-based algorithms more accurately predict the future than do human forecasters. Yet when forecasters are deciding whether to use a human forecaster or a statistical algorithm, they often choose the human forecaster. This phenomenon, which we call algorithm aversion, is costly, and it is important to understand its causes. We show that people are especially averse to algorithmic forecasters after seeing them perform, even when they see them outperform a human forecaster. This is because people more quickly lose confidence in algorithmic than human forecasters after seeing them make the same mistake. In 5 studies, participants either saw an algorithm make forecasts, a human make forecasts, both, or neither. They then decided whether to tie their incentives to the future predictions of the algorithm or the human. Participants who saw the algorithm perform were less confident in it, and less likely to choose it over an inferior human forecaster. This was true even among those who saw the algorithm outperform the human. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{doErrAIImperfect2023,
  title = {To {{Err}} Is {{AI}}: {{Imperfect Interventions}} and {{Repair}} in a {{Conversational Agent Facilitating Group Chat Discussions}}},
  shorttitle = {To {{Err}} Is {{AI}}},
  author = {Do, Hyo Jin and Kong, Ha-Kyung and Tetali, Pooja and Lee, Jaewook and Bailey, Brian P.},
  year = {2023},
  month = apr,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {7},
  number = {CSCW1},
  pages = {99:1--99:23},
  doi = {10.1145/3579532},
  urldate = {2024-04-08},
  abstract = {Conversational agents (CAs) can analyze online conversations using natural language techniques and effectively facilitate group discussions by sending supervisory messages. However, if a CA makes imperfect interventions, users may stop trusting the CA and discontinue using it. In this study, we demonstrate how inaccurate interventions of a CA and a conversational repair strategy can influence user acceptance of the CA, members' participation in the discussion, perceived discussion experience between the members, and group performance. We built a CA that encourages the participation of members with low contributions in an online chat discussion in which a small group (3-6 members) performs a decision-making task. Two types of errors can occur when detecting under-contributing members: 1) false-positive (FP) errors happen when the CA falsely identifies a member as under-contributing and 2) false-negative (FN) errors occur when the CA misses detecting an under-contributing member. We designed a conversational repair strategy that gives users a chance to contest the detection results and the agent sends a correctional message if an error is detected. Through an online study with 175 participants, we found that participants who received FN error messages reported higher acceptance of the CA and better discussion experience, but participated less compared to those who received FP error messages. The conversational repair strategy moderated the effect of errors such as improving the perceived discussion experience of participants who received FP error messages. Based on our findings, we offer design implications for which model should be selected by practitioners between high precision (i.e., fewer FP errors) and high recall (i.e., fewer FN errors) models depending on the desired effects. When frequent FP errors are expected, we suggest using the conversational repair strategy to improve the perceived discussion experience.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/6LGFXUWA/Do 등 - 2023 - To Err is AI Imperfect Interventions and Repair i.pdf}
}

@article{doHowShouldAgent2022,
  title = {How {{Should}} the {{Agent Communicate}} to the {{Group}}? {{Communication Strategies}} of a {{Conversational Agent}} in {{Group Chat Discussions}}},
  shorttitle = {How {{Should}} the {{Agent Communicate}} to the {{Group}}?},
  author = {Do, Hyo Jin and Kong, Ha-Kyung and Lee, Jaewook and Bailey, Brian P.},
  year = {2022},
  month = nov,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {6},
  number = {CSCW2},
  pages = {387:1--387:23},
  doi = {10.1145/3555112},
  urldate = {2024-03-27},
  abstract = {In online group discussions, balanced participation can improve the quality of discussion, members' satisfaction, and positive group dynamics. One approach to achieve balanced participation is to deploy a conversational agent (CA) that encourages participation of under-contributing members, and it is important to design communication strategies of the CA in a way that is supportive to the group. We implemented five communication strategies that a CA can use during a decision-making task in a small group synchronous chat discussion. The five strategies include messages sent to two types of recipients (@username vs. @everyone) crossed by two separate channels (public vs. private), and a peer-mediated strategy where the CA asks a peer to address the under-contributing member. Through an online study with 42 groups, we measured the balance of participation and perceptions about the CA by analyzing chat logs and survey responses. We found that the CA sending messages specifying an individual through a private channel is the most effective and preferred way to increase participation of under-contributing members. Participants also expressed that the peer-mediated strategy is a less intrusive and less embarrassing way of receiving the CA's messages compared to the conventional approach where the CA directly sends a message to the under-contributing member. Based on our findings, we discuss trade-offs of various communication strategies and explain design considerations for building an effective CA that adapts to different group dynamics and situations.},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/PW5VY3GI/Do 등 - 2022 - How Should the Agent Communicate to the Group Com.pdf}
}

@article{doInformExplainControl2023,
  title = {Inform, {{Explain}}, or {{Control}}: {{Techniques}} to {{Adjust End-User Performance Expectations}} for a {{Conversational Agent Facilitating Group Chat Discussions}}},
  shorttitle = {Inform, {{Explain}}, or {{Control}}},
  author = {Do, Hyo Jin and Kong, Ha-Kyung and Tetali, Pooja and Karahalios, Karrie and Bailey, Brian P.},
  year = {2023},
  month = oct,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {7},
  number = {CSCW2},
  pages = {343:1--343:26},
  doi = {10.1145/3610192},
  urldate = {2024-03-27},
  abstract = {A conversational agent (CA) effectively facilitates online group discussions at scale. However, users may have expectations about how well the CA would perform that do not match with the actual performance, compromising technology acceptance. We built a facilitator CA that detects a member who has low contribution during a synchronous group chat discussion and asks the person to participate more. We designed three techniques to set end-user expectations about how accurately the CA identifies an under-contributing member: 1)information: explicitly communicating the accuracy of the detection algorithm, 2)explanation: providing an overview of the algorithm and the data used for the detection, and 3)adjustment: enabling users to gain a feeling of control over the algorithm. We conducted an online experiment with 163 crowdworkers in which each group completed a collaborative decision-making task and experienced one of the techniques. Through surveys and interviews, we found that the explanation technique was the most effective strategy overall as it reduced user embarrassment, increased the perceived intelligence of the CA, and helped users better understand the detection algorithm. In contrast, the information technique reduced members' contributions and the adjustment technique led to a more negative perceived discussion experience. We also discovered that the interactions with other team members diluted the effects of the techniques on users' performance expectations and acceptance of the CA. We discuss implications for better designing expectation-setting techniques for AI-team collaboration such as ways to improve collaborative decision outcomes and quality of contributions.},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/M34KET6K/Do 등 - 2023 - Inform, Explain, or Control Techniques to Adjust .pdf}
}

@article{douglasIdentifiabilitySelfpresentationComputermediated2001,
  title = {Identifiability and Self-Presentation: {{Computer-mediated}} Communication and Intergroup Interaction},
  shorttitle = {Identifiability and Self-Presentation},
  author = {Douglas, Karen M. and McGarty, Craig},
  year = {2001},
  journal = {British Journal of Social Psychology},
  volume = {40},
  number = {3},
  pages = {399--416},
  issn = {2044-8309},
  doi = {10.1348/014466601164894},
  urldate = {2024-07-19},
  abstract = {This research investigated the intergroup properties of hostile `flaming' behaviour in computer-mediated communication and how flaming language is affected by Internet identifiability, or identifiability by name and e-mail address/geographical location as is common to Internet communication. According to the Social Identity Model of Deindividuation Effects (SIDE; e.g. Reicher, Spears, \& Postmes, 1995) there may be strategic reasons for identifiable groups members to act in a more group-normative manner in the presence of an audience, to gain acceptance from the in-group, to avoid punishment from the out-group, or to assert their identity to the out-group. For these reasons, it was predicted that communicators would produce more stereotype-consistent (group-normative) descriptions of out-group members' behaviours when their descriptions were identifiable to an audience. In one archival and three experimental studies, it was found that identifiability to an in-group audience was associated with higher levels of stereotype-consistent language when communicators described anonymous out-group targets. These results extend SIDE and suggest the importance of an in-group audience for the expression of stereotypical views.},
  copyright = {2001 The British Psychological Society},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/PKAKD8LU/Douglas and McGarty - 2001 - Identifiability and self-presentation Computer-me.pdf}
}

@article{dovidioAnotherViewWe,
  title = {Another View of ``We'': {{Majority}} and Minority Group Perspectives on a Common Ingroup Identity},
  shorttitle = {Another View of ``We''},
  author = {Dovidio, John F. and Gaertner, Samuel L. and Saguy, Tamar},
  journal = {European Review of Social Psychology},
  volume = {18},
  number = {1},
  pages = {296--330},
  publisher = {Routledge},
  issn = {1046-3283},
  doi = {10.1080/10463280701726132},
  urldate = {2024-07-19},
  abstract = {Drawing on the evidence of the role of social categorisation and identity in the development and maintenance of intergroup biases, research on the Common Ingroup Identity Model (Gaertner \& Dovidio, 2000) has investigated how modifying the ways that the self and others are categorised can reduce prejudice and discrimination. In this article, we review more recent research that extends our initial formulation of the model by considering more fully alternative forms of recategorisation (a dual identity as well as a one-group representation), the different preferences of majority and minority groups for these different forms of recategorised representations, and the potential implications of these different preferences on the content of intergroup interaction and on the possibilities for social change towards equality.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/Z7GX4JKU/Dovidio et al. - Another view of “we” Majority and minority group .pdf}
}

@article{dovidioPowerDisplaysWomen1988,
  title = {Power Displays between Women and Men in Discussions of Gender-Linked Tasks: {{A}} Multichannel Study},
  shorttitle = {Power Displays between Women and Men in Discussions of Gender-Linked Tasks},
  author = {Dovidio, John F. and Brown, Clifford E. and Heltman, Karen and Ellyson, Steve L. and Keating, Caroline F.},
  year = {1988},
  journal = {Journal of Personality and Social Psychology},
  volume = {55},
  number = {4},
  pages = {580--587},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1315},
  doi = {10.1037/0022-3514.55.4.580},
  abstract = {Conducted a multichannel investigation of how gender-based familiarity moderates verbal and nonverbal behaviors between men and women. Undergraduates in 24 mixed-sex dyads discussed masculine, feminine, and non-gender-linked topics. The primary dependent variables were verbal and nonverbal behaviors related to social power. The verbal behaviors examined were speech initiations and total amount of speech; the nonverbal behaviors studied were visual behavior (while speaking and while listening), gesturing, chin thrusts, and smiling. Systematic differences in the behaviors of men and women emerged on the gender-linked tasks. On the masculine task men displayed more verbal and nonverbal power-related behavior than did women. On the feminine task women exhibited more power than men on most of the verbal and nonverbal measures. On the non-gender-linked task men displayed greater power both verbally and nonverbally than did women. There were 2 exceptions to this overall pattern. Across all conditions, women smiled more often than did men, and men had a higher frequency of chin thrusts than did women. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{dresselAccuracyFairnessLimits2018,
  title = {The Accuracy, Fairness, and Limits of Predicting Recidivism},
  author = {Dressel, Julia and Farid, Hany},
  year = {2018},
  month = jan,
  journal = {Science Advances},
  volume = {4},
  number = {1},
  pages = {eaao5580},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/sciadv.aao5580},
  urldate = {2024-07-18},
  abstract = {Algorithms for predicting recidivism are commonly used to assess a criminal defendant's likelihood of committing a crime. These predictions are used in pretrial, parole, and sentencing decisions. Proponents of these systems argue that big data and advanced machine learning make these analyses more accurate and less biased than humans. We show, however, that the widely used commercial risk assessment software COMPAS is no more accurate or fair than predictions made by people with little or no criminal justice expertise. In addition, despite COMPAS's collection of 137 features, the same accuracy can be achieved with a simple linear classifier with only two features.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/2J4L2SSR/Dressel and Farid - 2018 - The accuracy, fairness, and limits of predicting r.pdf}
}

@article{duanBridgingFluencyDisparity2021,
  title = {Bridging {{Fluency Disparity}} between {{Native}} and {{Nonnative Speakers}} in {{Multilingual Multiparty Collaboration Using}} a {{Clarification Agent}}},
  author = {Duan, Wen and Yamashita, Naomi and Shirai, Yoshinari and Fussell, Susan R.},
  year = {2021},
  month = oct,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  number = {CSCW2},
  pages = {435:1--435:31},
  doi = {10.1145/3479579},
  urldate = {2024-07-19},
  abstract = {Multiparty collaboration using a common language is often challenging for nonnative speakers (NNS). Conversation can move forward rapidly, with terms and references unfamiliar to NNS often going unexplained because NNS do not request clarification due to cognitive overload or face concerns. Language difficulties may further lead to NNS having a low level of participation in a conversation, which could be a loss for multilingual teams. To help NNS resolve potential confusions due to unfamiliar language use without risking face concerns, we created a conversation agent that asked clarification questions intended to help NNS follow and participate in multiparty conversations. We conducted a within-subjects laboratory experiment with 17 triads of 2 NS and 1 NNS, who performed a series of collaborative tasks under three conditions: a) no agent, b) a high-level agent that resembles a NNS with good command of English, and c) a low-level agent that resembles a NNS with poor English skills. Results suggest that NS made significantly more clarifications in both agent conditions than without an agent. In the high-level agent condition, NNS reported an increase in understanding after the agent's interruption and spoke significantly more. Further, NNS evaluated their communication competence in English highest in the low-level agent condition and lowest in the control condition. Our findings suggest several directions to improve the tool to better facilitate multilingual multiparty communication.}
}

@article{duanIncreasingNativeSpeakers2019,
  title = {Increasing {{Native Speakers}}' {{Awareness}} of the {{Need}} to {{Slow Down}} in {{Multilingual Conversations Using}} a {{Real-Time Speech Speedometer}}},
  author = {Duan, Wen and Yamashita, Naomi and Fussell, Susan R.},
  year = {2019},
  month = nov,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {3},
  number = {CSCW},
  pages = {171:1--171:25},
  doi = {10.1145/3359273},
  urldate = {2024-07-19},
  abstract = {Collaborating using a common language can be challenging for non-native speakers (NNS). These challenges can be reduced when native speakers (NS) adjust their speech behavior for NNS, for example by speaking more slowly. In this study, we examined whether the use of real-time speech rate feedback (a speech speedometer) would help NS monitor their speaking speed and adjust for NNS accordingly. We conducted a laboratory experiment with 20 triads of 2 NS and 1 NNS. NS in half of the groups were given the speech speedometer. We found that NS with the speech speedometer were significantly more motivated to slow down their speech but they did not actually speak more slowly, although they made other speech adjustments. Furthermore, NNS perceived the speech of NS with the speedometer less clear, and they felt less accommodated. The results highlight the need for tools that create scaffolding to help NS make speech accommodations. We conclude with some design ideas for these scaffolding tools.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/CNQ9C32E/Duan et al. - 2019 - Increasing Native Speakers' Awareness of the Need .pdf}
}

@article{dupreeSelfpresentationInterracialSettings2019,
  title = {Self-Presentation in Interracial Settings: {{The}} Competence Downshift by {{White}} Liberals},
  shorttitle = {Self-Presentation in Interracial Settings},
  author = {Dupree, Cydney H. and Fiske, Susan T.},
  year = {2019},
  journal = {Journal of Personality and Social Psychology},
  volume = {117},
  number = {3},
  pages = {579--604},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1315},
  doi = {10.1037/pspi0000166},
  abstract = {Most Whites, particularly sociopolitical liberals, now endorse racial equality. Archival and experimental research reveals a subtle but persistent ironic consequence: White liberals self-present less competence to minorities than to other Whites---that is, they patronize minorities stereotyped as lower status and less competent. In an initial archival demonstration of the competence downshift, Study 1 examined the content of White Republican and Democratic presidential candidates' campaign speeches. Although Republican candidates did not significantly shift language based on audience racial composition, Democratic candidates used less competence-related language to minority audiences than to White audiences. Across 5 experiments (total N = 2,157), White participants responded to a Black or White hypothetical (Studies 2, 3, 4, S1) or ostensibly real (Study 5) interaction partner. Three indicators of self-presentation converged: competence-signaling of vocabulary selected for an assignment, competence-related traits selected for an introduction, and competence-related content of brief, open-ended introductions. Conservatism indicators included self-reported political affiliation (liberal-conservative), Right-Wing Authoritarianism (values-based conservatism), and Social Dominance Orientation (hierarchy-based conservatism). Internal meta-analyses revealed that liberals---but not conservatives---presented less competence to Black interaction partners than to White ones. The simple effect was small but significant across studies, and most reliable for the self-reported measure of conservatism. This possibly unintentional but ultimately patronizing competence-downshift suggests that well-intentioned liberal Whites may draw on low-status/competence stereotypes to affiliate with minorities. (PsycInfo Database Record (c) 2024 APA, all rights reserved)},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/FS9FV43G/Dupree and Fiske - 2019 - Self-presentation in interracial settings The com.pdf}
}

@article{eaglyGenderLeadershipStyle1990,
  title = {Gender and Leadership Style: {{A}} Meta-Analysis},
  shorttitle = {Gender and Leadership Style},
  author = {Eagly, Alice H. and Johnson, Blair T.},
  year = {1990},
  journal = {Psychological Bulletin},
  volume = {108},
  number = {2},
  pages = {233--256},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1455},
  doi = {10.1037/0033-2909.108.2.233},
  abstract = {Research comparing the leadership styles of women and men is reviewed, and evidence is found for both the presence and absence of differences between the sexes. In contrast to the gender-stereotypic expectation that women lead in an interpersonally oriented style and men in a task-oriented style, female and male leaders did not differ in these two styles in organizational studies. However, these aspects of leadership style were somewhat gender stereotypic in the two other classes of leadership studies investigated, namely (a) laboratory experiments and (b) assessment studies, which were defined as research that assessed the leadership styles of people not selected for occupancy of leadership roles. Consistent with stereotypic expectations about a different aspect of leadership style, the tendency to lead democratically or autocratically, women tended to adopt a more democratic or participative style and a less autocratic or directive style than did men. This sex difference appeared in all three classes of leadership studies, including those conducted in organizations. These and other findings are interpreted in terms of a social role theory of sex differences in social behavior. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/6E7GAC9R/Eagly and Johnson - 1990 - Gender and leadership style A meta-analysis.pdf}
}

@article{easleyRelatingCollaborativeTechnology2003,
  title = {Relating {{Collaborative Technology Use}} to {{Teamwork Quality}} and {{Performance}}: {{An Empirical Analysis}}},
  shorttitle = {Relating {{Collaborative Technology Use}} to {{Teamwork Quality}} and {{Performance}}},
  author = {Easley, Robert F. and Devaraj, Sarv and Crant, J. Michael},
  year = {2003},
  month = apr,
  journal = {Journal of Management Information Systems},
  volume = {19},
  number = {4},
  pages = {247--265},
  publisher = {Routledge},
  issn = {0742-1222},
  doi = {10.1080/07421222.2003.11045747},
  urldate = {2024-08-16},
  abstract = {Although team-based work systems are pervasive in the workplace, the use of collaborative systems designed to facilitate and support ongoing teamwork is a relatively recent development. An understanding of how teams embrace and use such collaborative systems - and the relationship of that usage to teamwork quality and team performance - is critical for organizational success. We present a theoretical model in which usage of a collaborative system intervenes between teamwork quality and team performance for tasks that are supported by the system. We empirically validate the model in a setting where established teams voluntarily used a collaborative system over a four-month period to perform tasks with measurable outcomes. Our principal finding is that collaborative system use intervenes between teamwork quality and performance for tasks supported by the system but not for unsupported tasks.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/PSZV2LDK/ et al. - 2003 - Relating Collaborative Technology Use to Teamwork .pdf}
}

@article{edmondsonPsychologicalSafetyLearning1999,
  title = {Psychological {{Safety}} and {{Learning Behavior}} in {{Work Teams}}},
  author = {Edmondson, Amy},
  year = {1999},
  month = jun,
  journal = {Administrative Science Quarterly},
  volume = {44},
  number = {2},
  pages = {350--383},
  publisher = {SAGE Publications Inc},
  issn = {0001-8392},
  doi = {10.2307/2666999},
  urldate = {2024-08-16},
  abstract = {This paper presents a model of team learning and tests it in a multimethod field study. It introduces the construct of team psychological safety---a shared belief held by members of a team that the team is safe for interpersonal risk taking---and models the effects of team psychological safety and team efficacy together on learning and performance in organizational work teams. Results of a study of 51 work teams in a manufacturing company, measuring antecedent, process, and outcome variables, show that team psychological safety is associated with learning behavior, but team efficacy is not, when controlling for team psychological safety. As predicted, learning behavior mediates between team psychological safety and team performance. The results support an integrative perspective in which both team structures, such as context support and team leader coaching, and shared beliefs shape team outcomes.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/KQFHE7HP/Edmondson - 1999 - Psychological Safety and Learning Behavior in Work.pdf}
}

@inproceedings{ekstedtTurnGPTTransformerbasedLanguage2020,
  title = {{{TurnGPT}}: A {{Transformer-based Language Model}} for {{Predicting Turn-taking}} in {{Spoken Dialog}}},
  shorttitle = {{{TurnGPT}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2020},
  author = {Ekstedt, Erik and Skantze, Gabriel},
  year = {2020},
  eprint = {2010.10874},
  primaryclass = {cs},
  pages = {2981--2990},
  doi = {10.18653/v1/2020.findings-emnlp.268},
  urldate = {2025-01-21},
  abstract = {Syntactic and pragmatic completeness is known to be important for turn-taking prediction, but so far machine learning models of turn-taking have used such linguistic information in a limited way. In this paper, we introduce TurnGPT, a transformer-based language model for predicting turn-shifts in spoken dialog. The model has been trained and evaluated on a variety of written and spoken dialog datasets. We show that the model outperforms two baselines used in prior work. We also report on an ablation study, as well as attention and gradient analyses, which show that the model is able to utilize the dialog context and pragmatic completeness for turn-taking prediction. Finally, we explore the model's potential in not only detecting, but also projecting, turn-completions.},
  archiveprefix = {arXiv},
  annotation = {TLDR: This paper introduces TurnGPT, a transformer-based language model for predicting turn-shifts in spoken dialog and explores the model's potential in not only detecting, but also projecting, turn-completions.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/5VLG4F2Q/Ekstedt and Skantze - 2020 - TurnGPT a Transformer-based Language Model for Predicting Turn-taking in Spoken Dialog.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/89L8A6SY/2010.html}
}

@inproceedings{ensignRunawayFeedbackLoops2018,
  title = {Runaway {{Feedback Loops}} in {{Predictive Policing}}},
  booktitle = {Proceedings of the 1st {{Conference}} on {{Fairness}}, {{Accountability}} and {{Transparency}}},
  author = {Ensign, Danielle and Friedler, Sorelle A. and Neville, Scott and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  year = {2018},
  month = jan,
  pages = {160--171},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2024-07-18},
  abstract = {Predictive policing systems are increasingly used to determine how to allocate police across a city in order to best prevent crime. Discovered crime data (e.g., arrest counts) are used to help update the model, and the process is repeated. Such systems have been shown susceptible to runaway feedback loops, where police are repeatedly sent back to the same neighborhoods regardless of the true crime rate.  In response, we develop a mathematical model of predictive policing that proves why this feedback loop occurs, show empirically that this model exhibits such problems, and demonstrate how to change the inputs to a predictive policing system (in a black-box manner) so the runaway feedback loop does not occur, allowing the true crime rate to be learned.   Our results are quantitative: we can establish a link (in our model) between the degree to which runaway feedback causes problems and the disparity in crime rates between areas. Moreover, we can also demonstrate the way in which reported incidents of crime (those reported by residents) and discovered incidents of crime (i.e those directly observed by police officers dispatched as a result of the predictive policing algorithm) interact: in brief, while reported incidents can attenuate the degree of runaway feedback, they cannot entirely remove it without the interventions we suggest.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/8LGW25LI/Ensign et al. - 2018 - Runaway Feedback Loops in Predictive Policing.pdf}
}

@article{ertugWhatDoesHomophily2022,
  title = {What {{Does Homophily Do}}? {{A Review}} of the {{Consequences}} of {{Homophily}}},
  shorttitle = {What {{Does Homophily Do}}?},
  author = {Ertug, Gokhan and Brennecke, Julia and Kov{\'a}cs, Bal{\'a}zs and Zou, Tengjian},
  year = {2022},
  month = jan,
  journal = {Academy of Management Annals},
  volume = {16},
  number = {1},
  pages = {38--69},
  publisher = {Academy of Management},
  issn = {1941-6520},
  doi = {10.5465/annals.2020.0230},
  urldate = {2024-07-19},
  abstract = {Understanding the consequences of homophily, which is among the most widely observed social phenomena, is important, with implications for management theory and practice. Therefore, we review management research on the consequences of homophily. As these consequences have been studied at the individual, dyad, team, organizational, and macro levels, we structure our review accordingly. We highlight findings that are consistent and contradictory, as well as those that point to boundary conditions or moderators. In conducting our review, we also derive implications for management research from insights gained by research in other disciplines on this topic. We raise specific issues and opportunities for future research at each level, and conclude with a discussion of broader future research directions, both empirical and conceptual, that apply across levels. We hope that our review will open new vistas in research on this important topic.}
}

@article{etheringtonHowGenderShapes2021,
  title = {How Gender Shapes Interprofessional Teamwork in the Operating Room: A Qualitative Secondary Analysis},
  shorttitle = {How Gender Shapes Interprofessional Teamwork in the Operating Room},
  author = {Etherington, Cole and Kitto, Simon and Burns, Joseph K. and Adams, Tracey L. and Birze, Arija and Britton, Meghan and Singh, Sukhbir and Boet, Sylvain},
  year = {2021},
  month = dec,
  journal = {BMC Health Services Research},
  volume = {21},
  number = {1},
  pages = {1357},
  issn = {1472-6963},
  doi = {10.1186/s12913-021-07403-2},
  urldate = {2024-07-19},
  abstract = {Despite substantial implications for healthcare provider practice and patient outcomes, gender has yet to be systematically explored with regard to interprofessional operating room (OR) teamwork. We aimed to explore and describe how gender and additional social identity factors shape experiences and perceptions of teamwork in the OR.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/CW6E7GIK/Etherington et al. - 2021 - How gender shapes interprofessional teamwork in th.pdf}
}

@article{fairhurstTestSocialIsolation1983,
  title = {A {{Test}} of the {{Social Isolation}} of {{Male Tokens}}},
  author = {Fairhurst, Gail Theus and Snavely, B. Kay},
  year = {1983},
  month = jun,
  journal = {Academy of Management Journal},
  volume = {26},
  number = {2},
  pages = {353--361},
  publisher = {Academy of Management},
  issn = {0001-4273},
  doi = {10.5465/255983},
  urldate = {2024-07-19},
  abstract = {The article discusses a research on social isolation of male tokens in a nursing school environment. Such study was limited to testing the social isolation of male tokens, indicating that future research must explore two other token dynamics, namely, role entrapment and performance pressure. Furthermore, future research must examine males in other token positions in order to discover what is common to the male token role and what is unique about the nursing school environment. Findings indicated that there was an extremely low percentage of both males and females playing the isolate role. Results also indicated that upperclassmen are more integrated than lowerclassmen.}
}

@article{fayGroupDiscussionInteractive2000,
  title = {Group {{Discussion}} as {{Interactive Dialogue}} or as {{Serial Monologue}}: {{The Influence}} of {{Group Size}}},
  shorttitle = {Group {{Discussion}} as {{Interactive Dialogue}} or as {{Serial Monologue}}},
  author = {Fay, Nicolas and Garrod, Simon and Carletta, Jean},
  year = {2000},
  month = nov,
  journal = {Psychological Science},
  volume = {11},
  number = {6},
  pages = {481--486},
  publisher = {SAGE Publications Inc},
  issn = {0956-7976},
  doi = {10.1111/1467-9280.00292},
  urldate = {2024-07-18},
  abstract = {Current models draw a broad distinction between communication as dialogue and communication as monologue. The two kinds of models have different implications for who influences whom in a group discussion. If the discussion is like interactive dialogue, group members should be influenced most by those with whom they interact in the discussion; if it is like serial monologue, they should be influenced most by the dominant speaker. The experiments reported here show that in small, 5-person groups, the communication is like dialogue and members are influenced most by those with whom they interact in the discussion. However, in large, 10-person groups, the communication is like monologue and members are influenced most by the dominant speaker. The difference in mode of communication is explained in terms of how speakers in the two sizes of groups design their utterances for different audiences.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/3Q4LWRK2/Fay et al. - 2000 - Group Discussion as Interactive Dialogue or as Ser.pdf}
}

@article{fernandez-sanzAnalysisCulturalGender2012,
  title = {Analysis of Cultural and Gender Influences on Teamwork Performance for Software Requirements Analysis in Multinational Environments},
  author = {{Fern{\'a}ndez-Sanz}, L. and Misra, Sanjay},
  year = {2012},
  month = jun,
  journal = {IET Software},
  volume = {6},
  number = {3},
  pages = {167--175},
  publisher = {IET Digital Library},
  issn = {1751-8814},
  doi = {10.1049/iet-sen.2011.0070},
  urldate = {2024-07-19},
  abstract = {Software development is mainly a social activity where teams of developers should work as a coordinated unit to fulfill the needs of customers. Studies have shown the importance of teamwork ability as the main skill for software professionals both in local settings and in global software development. Teamwork performance can be evaluated according to different approaches but we need deeper analysis within software teams of differences in individuals' performance related to culture, nationality or even gender. We applied a simple evaluation experience named teamwork benefits awareness (TBA) to groups of last-year students of computing degrees with experience as junior IT professionals during intensive multinational workshops based on international software projects. TBA allowed to measure individual and team performance during a requirements analysis session based on a real project. Results segmented by nationality and gender are presented and analysed in comparison with the data collected from computing professionals in local settings. In general, no significant differences have been found out although interesting relations are suggested with two Hofstede\&apos;s country indicators. TBA is also perceived as a good technique for highlighting both teamwork benefits as well as the nature of real situations of software requirements analysis and orientation to customer needs.},
  langid = {english}
}

@inproceedings{finkelsteinSNAGUsingSocial2010,
  title = {{{SNAG}}: Using Social Networking Games to Increase Student Retention in Computer Science},
  shorttitle = {{{SNAG}}},
  booktitle = {Proceedings of the Fifteenth Annual Conference on {{Innovation}} and Technology in Computer Science Education},
  author = {Finkelstein, Samantha L. and Powell, Eve and Hicks, Andrew and Doran, Katelyn and Charugulla, Sandhya Rani and Barnes, Tiffany},
  year = {2010},
  month = jun,
  series = {{{ITiCSE}} '10},
  pages = {142--146},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1822090.1822131},
  urldate = {2024-07-18},
  abstract = {One of the primary goals of attending academic conferences is professional networking, yet even though this interaction can increase one's feeling of community within a field, conference attendees are not interacting as much as they could be. Similarly, it's known that students who do not feel as if they are part of a larger academic community are less likely to participate in extracurricular activities and organizations, lowering retention rates. To combat both of these problems, we present SNAG (Social Networking and Games). SNAG is a suite of mobile and Internet games which aim to facilitate social networking between members of a group, and can be used in either a conference setting or within a university. This paper focuses on one specific game, Snag'em, and discusses our evaluation for our SNAG games.},
  isbn = {978-1-60558-820-9}
}

@article{flathmannEmpiricallyUnderstandingPotential2024,
  title = {Empirically {{Understanding}} the {{Potential Impacts}} and {{Process}} of {{Social Influence}} in {{Human-AI Teams}}},
  author = {Flathmann, Christopher and Duan, Wen and Mcneese, Nathan J. and Hauptman, Allyson and Zhang, Rui},
  year = {2024},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {8},
  number = {CSCW1},
  pages = {49:1--49:32},
  doi = {10.1145/3637326},
  urldate = {2024-07-25},
  abstract = {In the coming years, Artificial Intelligence (AI) will be applied as a teammate that works alongside and collaborates with humans. Prior research in teaming and CSCW has shown that teammates have the ability to change the thoughts and behaviors of each other through simple interactions in a process known as social influence. However, to date, research has yet to identify the social influence that AI teammates could have in these human-AI teams, which has led to a limited understanding of how AI teammates will change the behaviors of their human teammates. To remedy this gap, we conduct a mixed-methods study (N=33) with young individuals to explore how humans could behaviorally adapt and perceive their behavioral adaptation due to interaction with an AI teammate. Qualitative results report that perceived three unique stages they had to experience for the social influence of their AI teammate to lead to adaptation (i.e., perceiving a sense of control, identifying a technological or performative justification, and gaining first-hand experience). Quantitative results validate and illustrate the results of this perceived process, as results show that participants adapted their behaviors to complement the behaviors of different types of AI teammates. This study contributes to the CSCW/HCI field by developing an initial understanding of AI teammates' social influence in human-AI teams, which will be a pivotal design and research consideration in future efforts.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/WQHX2EUV/Flathmann et al. - 2024 - Empirically Understanding the Potential Impacts an.pdf}
}

@article{flathmannExaminingImpactVarying2023,
  title = {Examining the Impact of Varying Levels of {{AI}} Teammate Influence on Human-{{AI}} Teams},
  author = {Flathmann, Christopher and Schelble, Beau G. and Rosopa, Patrick J. and McNeese, Nathan J. and Mallick, Rohit and Madathil, Kapil Chalil},
  year = {2023},
  month = sep,
  journal = {International Journal of Human-Computer Studies},
  volume = {177},
  pages = {103061},
  issn = {1071-5819},
  doi = {10.1016/j.ijhcs.2023.103061},
  urldate = {2024-07-25},
  abstract = {The implementation of AI teammates is creating a wealth of research that examines how AI teammates impact human-AI teams. However, AI teammates themselves are not static, and their roles and responsibilities in human-AI teams are likely to change as technologies advance in the coming years. As a result of this advancement, AI teammates will gain influence in teams, which refers to their ability to change and manipulate a team's shared resources. This study uses a mixed-methods experiment to examine how the amount of influence AI teammates have on a team's shared resources can impact the team outcomes of human teammate performance, teammate perceptions, and whole-team perception. Results indicate that AI teammates that increase their influence on shared resources over time can stagnate the improvement of human performance, but AI teammates that decrease their influence on shared resources can actually encourage humans to improve their own performance. Additionally, AI teammates that are highly influential on shared resources can make humans perceive a greater cognitive workload. However, qualitative results indicate that these impacts on human performance and perception do not consistently impact the acceptance humans form for AI teammates. Rather, humans form acceptance for AI teammates if said AI use its influence to manipulate resources to benefit the personal goals of human teammates. These results have critical implications for human-AI teaming as it shows that the influence AI teammates have on shared resources can be designed in a way that improves human performance. However, future research is going to need to focus more critically on how the personal goals humans have, which may not align with a team's overall goals, are going to mediate the effectiveness of the AI teammate influence.}
}

@book{forsythGroupDynamics2018,
  title = {Group {{Dynamics}}},
  author = {Forsyth, Donelson R.},
  year = {2018},
  month = jan,
  publisher = {Cengage Learning},
  abstract = {GROUP DYNAMICS, 7th Edition, combines an emphasis on research, empirical studies supporting theoretical understanding of groups, and extended case studies to illustrate the application of concepts to actual groups. Author Donelson R. Forsyth builds each chapter around a real-life case, drawing on examples from a range of disciplines including psychology, law, education, sociology, and political science. Tightly weaving concepts and familiar ideas together, the text takes students beyond simple exposure to basic principles and research findings to a deeper understanding of each topic.Important Notice: Media content referenced within the product description or the product text may not be available in the ebook version.},
  googlebooks = {PJIJzgEACAAJ},
  isbn = {978-1-337-40885-1},
  langid = {english}
}

@article{foxDistinguishingTechnologiesSocial2017,
  title = {Distinguishing Technologies for Social Interaction: {{The}} Perceived Social Affordances of Communication Channels Scale},
  shorttitle = {Distinguishing Technologies for Social Interaction},
  author = {Fox, Jesse and McEwan, Bree},
  year = {2017},
  month = jul,
  journal = {Communication Monographs},
  volume = {84},
  number = {3},
  pages = {298--318},
  publisher = {Routledge},
  issn = {0363-7751},
  doi = {10.1080/03637751.2017.1332418},
  urldate = {2024-07-19},
  abstract = {The concept of affordances in communication technology research has proven to be heuristically provocative, yet perceived affordances are rarely measured. After extracting commonly cited social affordances from the literature, we developed a measure to assess participants' perceptions of these affordances. The scale was tested across eight communication channels in two studies (face-to-face; texting; phone; email; posts on social networking sites, specifically Facebook; instant messaging; Skype videoconferencing; and mobile app Snapchat). A factor structure was developed in Study 1 and confirmed in Study 2. The resultant Perceived Social Affordances of Communication Channels Scale includes 41 items measuring 10 communicative affordances: accessibility, bandwidth, social presence, privacy, network association, personalization, persistence, editability, conversation control, and anonymity. Potential methodological and theoretical applications are discussed.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/G2W7S6NV/Fox and McEwan - 2017 - Distinguishing technologies for social interaction.pdf}
}

@inproceedings{frauneTeammatesFirstFavoring2017,
  title = {Teammates First: {{Favoring}} Ingroup Robots over Outgroup Humans},
  shorttitle = {Teammates First},
  booktitle = {2017 26th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}} ({{RO-MAN}})},
  author = {Fraune, Marlena R. and {\v S}abanovi{\'c}, Selma and Smith, Eliot R.},
  year = {2017},
  month = aug,
  pages = {1432--1437},
  issn = {1944-9437},
  doi = {10.1109/ROMAN.2017.8172492},
  urldate = {2024-07-18},
  abstract = {When it's between a robot on your team and a human member of a competing team, who will you favor? Past research indicates that people favor and behave more morally toward ingroup than outgroup members. Conversely, people typically indicate that they have more moral responsibilities toward humans than nonhumans. This study puts participants into two competing teams, each consisting of two humans and two robots, to examine how people behave toward others depending on Group (ingroup, outgroup) and Agent (human, robot) variables. Measures of behavioral aggression used in previous studies (i.e., noise blasts) and reported liking and anthropomorphism evaluations of humans and robots indicated that participants favored the ingroup over the outgroup, and humans over robots. Group had a greater effect than Agent, so participants preferred ingroup robots to outgroup humans.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/TE4TIKJQ/Fraune et al. - 2017 - Teammates first Favoring ingroup robots over outg.pdf}
}

@incollection{frenchjr.BasesSocialPower1959,
  title = {The Bases of Social Power},
  booktitle = {Studies in Social Power},
  author = {French Jr., John R. P. and Raven, Bertram},
  year = {1959},
  pages = {150--167},
  publisher = {Univer. Michigan},
  address = {Oxford, England},
  abstract = {5 types of social influence, leading to various research hypotheses, are distinguished: referent power, expert power, reward power, coercive power, and legitimate power. Referent power, involving identification of P with O, will tend to have the broadest range. Coercion will produce decreased attraction of P toward O and high resistance. Reward will result in increased attraction and low resistance. "The more legitimate the coercion the less it will produce resistance and decreased attraction." 42 refs. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/USQU7BSL/1960-06701-004.html}
}

@article{furnhamLiteratureReviewAnchoring2011,
  title = {A Literature Review of the Anchoring Effect},
  author = {Furnham, Adrian and Boo, Hua Chu},
  year = {2011},
  month = feb,
  journal = {The Journal of Socio-Economics},
  volume = {40},
  number = {1},
  pages = {35--42},
  issn = {1053-5357},
  doi = {10.1016/j.socec.2010.10.008},
  urldate = {2024-07-18},
  abstract = {The anchoring effect is one of the most robust cognitive heuristics. This paper reviews the literature in this area including various different models, explanations and underlying mechanisms used to explain anchoring effects. The anchoring effect is both robust and has many implications in all decision making processes. This review paper documents the many different domains and tasks in which the effect has been shown. It also considers mood and individual difference (ability, personality, information styles) correlates of anchoring as well as the effect of motivation and knowledge on decisions affected by anchoring. Finally the review looks at the applicants of the anchoring effects in everyday life.}
}

@inproceedings{fuTextSelfUsers2024,
  title = {From {{Text}} to {{Self}}: {{Users}}' {{Perception}} of {{AIMC Tools}} on {{Interpersonal Communication}} and {{Self}}},
  shorttitle = {From {{Text}} to {{Self}}},
  booktitle = {Proceedings of the {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Fu, Yue and Foell, Sami and Xu, Xuhai and Hiniker, Alexis},
  year = {2024},
  month = may,
  series = {{{CHI}} '24},
  pages = {1--17},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3613904.3641955},
  urldate = {2024-07-21},
  abstract = {In the rapidly evolving landscape of AI-mediated communication (AIMC), tools powered by Large Language Models (LLMs) are becoming integral to interpersonal communication. Employing a mixed-methods approach, we conducted a one-week diary and interview study to explore users' perceptions of these tools' ability to: 1) support interpersonal communication in the short-term, and 2) lead to potential long-term effects. Our findings indicate that participants view AIMC support favorably, citing benefits such as increased communication confidence, finding precise language to express their thoughts, and navigating linguistic and cultural barriers. However, our findings also show current limitations of AIMC tools, including verbosity, unnatural responses, and excessive emotional intensity. These shortcomings are further exacerbated by user concerns about inauthenticity and potential overreliance on the technology. We identify four key communication spaces delineated by communication stakes (high or low) and relationship dynamics (formal or informal) that differentially predict users' attitudes toward AIMC tools. Specifically, participants report that these tools are more suitable for communicating in formal relationships than informal ones and more beneficial in high-stakes than low-stakes communication.},
  isbn = {9798400703300},
  keywords = {,notion},
  annotation = {TLDR: Four key communication spaces delineated by communication stakes and relationship dynamics (formal or informal) that differentially predict users' attitudes toward AIMC tools are identified and participants report that these tools are more suitable for communicating in formal relationships than informal ones and more beneficial in high-stakes than low-stakes communication.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/BR2QF9SY/Fu et al. - 2024 - From Text to Self Users’ Perception of AIMC Tools.pdf}
}

@incollection{galinskyPowerFindingsPresent2015,
  title = {Power: {{Past}} Findings, Present Considerations, and Future Directions},
  shorttitle = {Power},
  booktitle = {{{APA}} Handbook of Personality and Social Psychology, {{Volume}} 3: {{Interpersonal}} Relations},
  author = {Galinsky, Adam D. and Rucker, Derek D. and Magee, Joe C.},
  year = {2015},
  series = {{{APA}} Handbooks in Psychology{\textregistered}},
  pages = {421--460},
  publisher = {American Psychological Association},
  address = {Washington, DC, US},
  doi = {10.1037/14344-016},
  abstract = {In this chapter, we provide a primer on the social psychological study of power and capture emerging themes that we think are likely to develop into the next wave of research on power. To accomplish this objective, we begin the chapter by offering a clear definition of power. We then pay homage to the prior waves of power research by discussing the antecedents (in the form of manipulations and measures) and consequences that bracket the psychological experience of power as well as critical moderators. Subsequently, we discuss theories about how power guides and directs behavior. We close by setting an agenda for future research. Our goal is to provide a formative review of new and emerging themes on the study of power, a review that can be used both by individuals new to the domain of power and by more seasoned researchers as they set their future research agendas. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  isbn = {978-1-4338-1703-8}
}

@article{galinskyPowerPerspectivesNot2006,
  title = {Power and {{Perspectives Not Taken}}},
  author = {Galinsky, Adam D. and Magee, Joe C. and Inesi, M. Ena and Gruenfeld, Deborah H},
  year = {2006},
  month = dec,
  journal = {Psychological Science},
  volume = {17},
  number = {12},
  pages = {1068--1074},
  publisher = {SAGE Publications Inc},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.2006.01824.x},
  urldate = {2024-07-18},
  abstract = {Four experiments and a correlational study explored the relationship between power and perspective taking. In Experiment 1, participants primed with high power were more likely than those primed with low power to draw an E on their forehead in a self-oriented direction, demonstrating less of an inclination to spontaneously adopt another person's visual perspective. In Experiments 2a and 2b, high-power participants were less likely than low-power participants to take into account that other people did not possess their privileged knowledge, a result suggesting that power leads individuals to anchor too heavily on their own vantage point, insufficiently adjusting to others' perspectives. In Experiment 3, high-power participants were less accurate than control participants in determining other people's emotion expressions; these results suggest a power-induced impediment to experiencing empathy. An additional study found a negative relationship between individual difference measures of power and perspective taking. Across these studies, power was associated with a reduced tendency to comprehend how other people see, think, and feel.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VILR5AY4/Galinsky et al. - 2006 - Power and Perspectives Not Taken.pdf}
}

@article{gambinoBuildingStrongerCASA2020,
  title = {Building a Stronger {{CASA}}: {{Extending}} the Computers Are Social Actors Paradigm},
  shorttitle = {Building a Stronger {{CASA}}},
  author = {Gambino, Andrew and Fox, Jesse and Ratan, Rabindra A.},
  year = {2020},
  month = jan,
  journal = {Human-Machine Communication},
  volume = {1},
  pages = {71--85},
  publisher = {{Communication and Social Robotics Labs}},
  doi = {10.3316/INFORMIT.097034846749023},
  urldate = {2024-07-19},
  abstract = {The computers are social actors framework (CASA), derived from the media equation,          explains how people communicate with media and machines demonstrating social potential.          Many studies have challenged CASA, yet it has not been revised. We argue that CASA          needs to be expanded because people have changed, technologies have changed, and the          way people interact with technologies has changed. We discuss the implications of          these changes and propose an extension of CASA. Whereas CASA suggests humans mindlessly          apply human-human social scripts to interactions with media agents, we argue that          humans may develop and apply human-media social scripts to these interactions. Our          extension explains previous dissonant findings and expands scholarship regarding human-machine          communication, human-computer interaction, human-robot interaction, human-agent interaction,          artificial intelligence, and computer-mediated communication.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/E9KBSMJC/Gambino et al. - 2020 - Building a stronger CASA Extending the computers .pdf}
}

@article{ganoticeTeamCohesivenessCollective2022,
  title = {Team Cohesiveness and Collective Efficacy Explain Outcomes in Interprofessional Education},
  author = {Ganotice, Fraide A. and Chan, Linda and Shen, Xiaoai and Lam, Angie Ho Yan and Wong, Gloria Hoi Yan and Liu, Rebecca Ka Wai and Tipoe, George L.},
  year = {2022},
  month = nov,
  journal = {BMC Medical Education},
  volume = {22},
  pages = {820},
  issn = {1472-6920},
  doi = {10.1186/s12909-022-03886-7},
  urldate = {2024-08-16},
  abstract = {Background Team cohesiveness and collective efficacy have been construed as important characteristics of a high-functioning team. However, the psychological mechanism through which they promote positive outcomes remains unknown. Understanding this psychological process is important to teachers and programme implementers to yield actionable interventions that can be used to craft effective practices for optimizing team outcomes. This is especially true in interprofessional education (IPE) in medical education, where a team-based approach to patient management is promoted. Drawing from the social-cognitive theory, we examined a hypothesized model where team cohesiveness predicts collaboration outcomes (teamwork satisfaction, overall satisfaction with the team experience, and IPE goal attainment) via collective efficacy. Methods We used data from Chinese medicine, medicine, nursing, and social work students in Hong Kong (n\,=\,285) who were enrolled in IPE. They were invited to respond to scales in two time points. We performed mediation analysis using structural equations modelling to test the indirect effect model: team cohesiveness {$\rightarrow$} collective efficacy {$\rightarrow$} outcomes. Results Results of structural equation modelling revealed that collective efficacy fully mediated the relationships between team cohesiveness and all three team outcomes, providing support for the hypothesised model [RMSEA\,=\,0.08, NFI\,=\,0.90, CFI\,=\,0.93, IFI\,=\,0.93, TLI\,=\,0.93]. Team cohesiveness predicted the achievement of collaboration outcomes via collective efficacy. Conclusion The findings demonstrated the important roles of team cohesiveness and collective efficacy in promoting successful team collaboration. Team cohesiveness predicted collective efficacy, and collective efficacy, in turn, predicted collaboration outcomes. This study contributed to theorising the pathways towards successful team collaboration outcomes.},
  pmcid = {PMC9706965},
  pmid = {36447247},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/PXCCPTNM/Ganotice et al. - 2022 - Team cohesiveness and collective efficacy explain .pdf}
}

@inproceedings{gaoEffectsPublicVs2014,
  title = {Effects of Public vs. Private Automated Transcripts on Multiparty Communication between Native and Non-Native English Speakers},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Gao, Ge and Yamashita, Naomi and Hautasaari, Ari MJ and Echenique, Andy and Fussell, Susan R.},
  year = {2014},
  month = apr,
  series = {{{CHI}} '14},
  pages = {843--852},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2556288.2557303},
  urldate = {2024-07-18},
  abstract = {Real-time transcripts generated by automated speech recognition (ASR) technologies have the potential to facilitate communication between native speakers (NS) and non-native speakers (NNS). Previous studies of ASR have focused on how transcripts aid NNS speech comprehension. In this study, we examine whether transcripts benefit multiparty real-time conversation between NS and NNS. We hypothesized that ASR transcripts would be more beneficial when the transcripts were publicly shared by all group members as opposed to when they were seen only by the NNS. To test our hypothesis, we conducted a lab experiment in which 14 groups of native and non-native speakers engaged in a story-telling task. Half of the groups received private transcripts that were available only to the NNS; the other half received publicly shared transcripts that were available to all group members. NS spoke more clearly, and both NS and NNS rated the quality of communication higher, when transcripts were publicly shared. These findings inform the design of future tools to support multilingual group communication.},
  isbn = {978-1-4503-2473-1}
}

@inproceedings{gaoImprovingMultilingualCollaboration2015,
  title = {Improving {{Multilingual Collaboration}} by {{Displaying How Non-native Speakers Use Automated Transcripts}} and {{Bilingual Dictionaries}}},
  booktitle = {Proceedings of the 33rd {{Annual ACM Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Gao, Ge and Yamashita, Naomi and Hautasaari, Ari M.J. and Fussell, Susan R.},
  year = {2015},
  month = apr,
  series = {{{CHI}} '15},
  pages = {3463--3472},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2702123.2702498},
  urldate = {2024-07-18},
  abstract = {Conversational grounding, or establishing mutual knowledge that messages have been understood as intended, can be difficult to achieve when some conversational participants are using a non-native language. These difficulties in grounding can be challenging for native speakers to detect. In this paper, we examine the value of signaling potential grounding problems to native speakers (NS) by displaying how non-native speakers (NNS) use automated transcripts and bilingual dictionaries. We conducted a laboratory experiment in which NS and NNS of English collaborated via audio conferencing on a map navigation task. Triads of one NS guider, one NS follower, and one NNS follower performed the task using one of three awareness displays: (a) a no awareness display that showed only the automated transcripts, (b) a general awareness display that showed whether each follower was reading the automated transcripts and/or translating a word; or (c) a detailed awareness display that showed which line of the transcripts a follower was reading and/or which words he/she was translating. NS guiders and NNS followers collaborated most successfully with the detailed awareness display, while NS guiders and NS followers performed equally across conditions. Our findings suggest several ways to improve systems to support multilingual collaboration.},
  isbn = {978-1-4503-3145-6}
}

@inproceedings{garciaGenderInfluenceCommunication2022,
  title = {Gender {{Influence}} on {{Communication Initiated}} within {{Student Teams}}},
  booktitle = {Proceedings of the 53rd {{ACM Technical Symposium}} on {{Computer Science Education}} - {{Volume}} 1},
  author = {Garcia, Rita and Liao, Chieh-Ju and Pearce, Ariane and Treude, Christoph},
  year = {2022},
  month = feb,
  series = {{{SIGCSE}} 2022},
  volume = {1},
  pages = {432--438},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3478431.3499279},
  urldate = {2024-07-18},
  abstract = {Collaboration is important during software development, but related work has found gender differences can influence the collaboration process, creating inequality in the team's dynamics. In this paper, we present a gender analysis study that involved 39 students, examining their teams' online collaborations while contributing to a large open-source software project. Eight teams of 4-6 Software Engineering (SE) students communicated over an online messaging platform, Slack, to complete an eight-week project. The goal of this study is to identify gender differences emerging from team collaboration. A mixed-methods approach was used to collect students' teamwork experiences and analyse their collaboration. Our research shows statistically significant results in female students' leadership, coordination, and project-monitoring behaviours used to complete the project. The results also showed a higher rate of help seeking within the all-female team, an infrequent behaviour observed in the all-male and mixed-gender teams. Our findings raise future research opportunities to further investigate the gender differences emerging from team collaboration.},
  isbn = {978-1-4503-9070-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/MPDD82AB/Garcia et al. - 2022 - Gender Influence on Communication Initiated within.pdf}
}

@inproceedings{geHowCultureShapes2024,
  title = {How {{Culture Shapes What People Want From AI}}},
  booktitle = {Proceedings of the 2024 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Ge, Xiao and Xu, Chunchen and Misaki, Daigo and Markus, Hazel Rose and Tsai, Jeanne L},
  year = {2024},
  month = may,
  series = {{{CHI}} '24},
  pages = {1--15},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3613904.3642660},
  urldate = {2025-01-21},
  abstract = {There is an urgent need to incorporate the perspectives of culturally diverse groups into AI developments. We present a novel conceptual framework for research that aims to expand, reimagine, and reground mainstream visions of AI using independent and interdependent cultural models of the self and the environment. Two survey studies support this framework and provide preliminary evidence that people apply their cultural models when imagining their ideal AI. Compared with European American respondents, Chinese respondents viewed it as less important to control AI and more important to connect with AI, and were more likely to prefer AI with capacities to influence. Reflecting both cultural models, findings from African American respondents resembled both European American and Chinese respondents. We discuss study limitations and future directions and highlight the need to develop culturally responsive and relevant AI to serve a broader segment of the world population.},
  isbn = {9798400703300},
  annotation = {TLDR: A novel conceptual framework for research is presented that aims to expand, reimagine, and reground mainstream visions of AI using independent and interdependent cultural models of the self and the environment and preliminary evidence that people apply their cultural models when imagining their ideal AI is provided.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/H3HFHL9Y/Ge et al. - 2024 - How Culture Shapes What People Want From AI.pdf}
}

@inproceedings{geiskkovitchAutonomyEmbodimentObedience2015,
  title = {Autonomy, {{Embodiment}}, and {{Obedience}} to {{Robots}}},
  booktitle = {Proceedings of the {{Tenth Annual ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction Extended Abstracts}}},
  author = {Geiskkovitch, Denise and Seo, Stela and Young, James E.},
  year = {2015},
  month = mar,
  series = {{{HRI}}'15 {{Extended Abstracts}}},
  pages = {235--236},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2701973.2702723},
  urldate = {2024-07-18},
  abstract = {We conducted an HRI obedience experiment comparing an autonomous robotic authority to: (i) a remote-controlled robot, and (ii) robots of variant embodiments during a deterrent task. The results suggest that half of people will continue to perform a tedious task under the direction of a robot, even after expressing desire to stop. Further, we failed to find impact of robot embodiment and perceived robot autonomy on obedience. Rather, the robot's perceived authority status may be more strongly correlated to obedience.},
  isbn = {978-1-4503-3318-4}
}

@article{geiskkovitchPleaseContinueWe2016,
  title = {Please Continue, We Need More Data: An Exploration of Obedience to Robots},
  shorttitle = {Please Continue, We Need More Data},
  author = {Geiskkovitch, Denise Y. and Cormier, Derek and Seo, Stela H. and Young, James E.},
  year = {2016},
  month = mar,
  journal = {J. Hum.-Robot Interact.},
  volume = {5},
  number = {1},
  pages = {82--99},
  abstract = {We investigated obedience to an authoritative robot and asked experiment participants to do a task they would rather not do. Obedience questions are increasingly important as robots participate in tasks where they give people directions. We conducted a series of HRI obedience experiments, comparing a robotic authority to other authority instances, including: (i) a human, (ii) a remote-controlled robot, and (iii) robots of variant embodiments. The results suggest that half of participants will continue to perform a tedious task under the direction of a robot, even after expressing desire to stop. Further, we failed to find an effect of robot embodiment and perceived autonomy on obedience. Instead, the robot's perceived authority status may be more strongly correlated to obedience.}
}

@article{gerardConformityGroupSize1968,
  title = {Conformity and Group Size.},
  author = {Gerard, Harold B. and Wilhelmy, Roland A. and Conolley, Edward S.},
  year = {1968},
  journal = {Journal of Personality and Social Psychology},
  volume = {8},
  number = {1, Pt.1},
  pages = {79--82},
  issn = {1939-1315, 0022-3514},
  doi = {10.1037/h0025325},
  urldate = {2025-01-21},
  abstract = {Semantic Scholar extracted view of "Conformity and group size." by H. Gerard et al.},
  langid = {english}
}

@article{gerardDistinctivenessSocialCategorization1974,
  title = {Distinctiveness of Social Categorization and Attitude toward Ingroup Members},
  author = {Gerard, Harold B. and Hoyt, Michael F.},
  year = {1974},
  journal = {Journal of Personality and Social Psychology},
  volume = {29},
  number = {6},
  pages = {836--842},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1315},
  doi = {10.1037/h0036204},
  abstract = {Tested the hypothesis that the favorableness of ingroup evaluations increases directly with the distinctiveness of ingroup membership (i.e., as the ingroup's relative size decreases). Ingroups of various sizes were experimentally created. 56 university students then wrote a short essay and evaluated essays ostensibly written by 2 other Ss, one of whom "happened" to be an ingroup member, the other, an outgroup member. The hypothesis was supported: the smaller the ingroup, the more favorable were evaluations of the ingroup writer relative to the outgroup writer. (PsycInfo Database Record (c) 2020 APA, all rights reserved)}
}

@article{gigoneCommonKnowledgeEffect1993,
  title = {The Common Knowledge Effect: {{Information}} Sharing and Group Judgment},
  shorttitle = {The Common Knowledge Effect},
  author = {Gigone, Daniel and Hastie, Reid},
  year = {1993},
  journal = {Journal of Personality and Social Psychology},
  volume = {65},
  number = {5},
  pages = {959--974},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1315},
  doi = {10.1037/0022-3514.65.5.959},
  abstract = {The hypothesis that the influence of an item of information on a group judgment is directly related to the number of group members who hold that information before group discussion was tested. Three-member groups read short descriptions of students and were asked to make individual and then group consensus judgments about those students' grades in the course. Information held by all members before group discussion had more influence on the group judgments than information held by only 1 member. However, no effect of information distribution was found when controlling for member judgments, suggesting that the impact of the information, and hence the effects of distribution across members, was mediated by its impact on individual-member prediscussion judgments. The group judgments were no more accurate than the average of the member judgments. Group members were not aware of the common knowledge effect's influence on their use of information. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{glickInflictedTraumaticBrain2007,
  title = {Inflicted {{Traumatic Brain Injury}}: {{Advances}} in {{Evaluation}} and {{Collaborative Diagnosis}}},
  shorttitle = {Inflicted {{Traumatic Brain Injury}}},
  author = {Glick, Jill C. and Staley, Kelley},
  year = {2007},
  month = sep,
  journal = {Pediatric Neurosurgery},
  volume = {43},
  number = {5},
  pages = {436--441},
  issn = {1016-2291},
  doi = {10.1159/000106400},
  urldate = {2024-08-09},
  abstract = {The determination that a traumatic brain injury is not accidental requires data collection from multiple domains: historical, clinical, laboratory, radiographic, environmental and psychosocial. These essential, yet disparate, types of information must be synthesized in a collaborative and interdisciplinary process to formulate a medical opinion with regard to the cause of an injury, and the final opinion has tremendous consequences for children and families. Medically directed child protection teams have emerged as the standard of care in many children's hospitals and child abuse pediatrics is now a recognized medical subspecialty with board certification available in the next several years. Not only do the child and family benefit from this coordinated effort, but there are also great benefits for the members of the child protection team: more clearly defined responsibilities, redirected focus on treatment for the surgeon, and increased confidence that the opinion is based upon consensus and current scientific knowledge. By this process and its division of labor, the child abuse pediatrician assumes responsibility for ensuring that a final medical opinion is arrived at, and then advocates for appropriate disposition for the child. The child abuse pediatrician is responsible for establishing institutional standards for family evaluation, collecting all necessary medical data and directing a consensus-based decision making process that is based upon current medical knowledge, medical literature and experience. The child abuse pediatrician also assumes the role of primary communication conduit for investigational agencies and the courts. The neurosurgeon is a key member of the child protection team and relies on the team to obtain necessary historical information to address consistency of the mechanism with the sustained injuries and has an integral role in determining the team's final opinion. An interdisciplinary response to inflicted traumatic brain injury is the cornerstone for establishing a rigorous standard of care; it also fosters education across medical subspecialties where controversy has been a significant part of the landscape. Valid and useful clinical research that describes head injury as accidental or inflicted can only be performed in the context of an interdisciplinary, medically directed child protection team that strives for objectivity and precision in the determination of the manner of an injury.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/TQ6EHNMD/Inflicted-Traumatic-Brain-Injury-Advances-in.html}
}

@article{goldenthalNotAllAI2021,
  title = {Not {{All AI}} Are {{Equal}}: {{Exploring}} the {{Accessibility}} of {{AI-Mediated Communication Technology}}},
  shorttitle = {Not {{All AI}} Are {{Equal}}},
  author = {Goldenthal, Emma and Park, Jennifer and Liu, Sunny X. and Mieczkowski, Hannah and Hancock, Jeffrey T.},
  year = {2021},
  month = dec,
  journal = {Computers in Human Behavior},
  volume = {125},
  pages = {106975},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.106975},
  urldate = {2024-07-26},
  abstract = {While AI technologies and tools offer various potential benefits to their users, it is not clear whether opportunities to access these benefits are equally accessible to all. We examine this gap between availability and accessibility as it relates to the adoption of AI-Mediated Communication (AI-MC) tools, which enable interpersonal communication where an intelligent agent operates on behalf of a communicator. Upon defining six functional AI-MC types (voice-assisted communication, language correction, predictive text suggestion, transcription, translation, personalized language learning) we conducted an online survey of 519 U.S. participants that combined closed- and open-ended measures. Our quantitative results revealed how AI-MC adoption is related to software, device, and internet access for tools such as voice-assisted communication; demographic factors such as age, education and income in the case of translation and transcription tools; and some components of AI-MC literacy for specific functional tools. Our qualitative analyses provide additional nuance for these findings, and we articulate a number of barriers to access, understanding, and usage of AI-MC tools, which we suggest hinder AI-MC accessibility for user groups traditionally disadvantaged by one-size-fits-all technological tools. We end with a call for broadly addressing accessibility concerns within the digital technology industry.},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/4QI9WRU7/S0747563221002983.html}
}

@article{gorbachevaDirectionsResearchGender2019,
  title = {Directions for Research on Gender Imbalance in the {{IT}} Profession},
  author = {Gorbacheva, Elena and Beekhuyzen, Jenine and {vom Brocke}, Jan and Becker, J{\"o}rg},
  year = {2019},
  month = jan,
  journal = {European Journal of Information Systems},
  volume = {28},
  number = {1},
  pages = {43--67},
  publisher = {Taylor \& Francis},
  issn = {0960-085X},
  doi = {10.1080/0960085X.2018.1495893},
  urldate = {2024-07-19},
  abstract = {There is a significant shortage of expert Information Technology (IT) personnel in Europe and elsewhere and a marked under-representation of women in the field. This paper identifies important gaps in research on gender imbalance in the IT profession and motivates future Information Systems research to address each of them. First among these gaps is the lack of research on the far-reaching consequences of gender imbalance in the IT profession. Second, despite a considerable body of research, there is the lack of coherent explanation for this imbalance. Third, although many intervention programmes have been implemented in this area, gender diversity in practice has not improved significantly. This research field also requires theorisation based on the cumulative research efforts in the field, comparative studies in various contexts, and longitudinal studies. We point to opportunities to investigate each of these issues and recommend directions for future research and actionable research questions.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/D4ZT4NRH/Gorbacheva et al. - 2019 - Directions for research on gender imbalance in the.pdf}
}

@article{goseWhenSocraticDialogue2009,
  title = {When {{Socratic Dialogue}} Is {{Flagging}}: {{Questions}} and {{Strategies}} for {{Engaging Students}}},
  shorttitle = {When {{Socratic Dialogue}} Is {{Flagging}}},
  author = {Gose, Michael},
  year = {2009},
  month = jan,
  journal = {College Teaching},
  volume = {57},
  number = {1},
  pages = {45--50},
  publisher = {Routledge},
  issn = {8756-7555},
  doi = {10.3200/CTCH.57.1.45-50},
  urldate = {2024-07-18},
  abstract = {The author studied the pedagogy of Socrates looking for teaching techniques that help maintain students' interest in an ongoing discussion. Socrates' use of such strategies as asking probing questions, expanding the discussion into its relationship to other ideas, assuming the role of the devil's advocate, and spending time on group maintenance can be extremely helpful.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/9Z5BITVH/Gose - 2009 - When Socratic Dialogue is Flagging Questions and .pdf}
}

@inproceedings{grandprey-shoresIdentificationDevianceIts2014,
  title = {The Identification of Deviance and Its Impact on Retention in a Multiplayer Game},
  booktitle = {Proceedings of the 17th {{ACM}} Conference on {{Computer}} Supported Cooperative Work \& Social Computing},
  author = {{Grandprey-Shores}, Kate and He, Yilin and Swanenburg, Kristina L. and Kraut, Robert and Riedl, John},
  year = {2014},
  month = feb,
  series = {{{CSCW}} '14},
  pages = {1356--1365},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2531602.2531724},
  urldate = {2024-07-18},
  abstract = {Deviant behavior in online social systems is a difficult problem to address. Consequences of deviance include driving off users and tarnishing the system's public image. We present an examination of these concepts in a popular online game, League of Legends. Using a large collection of game records and player-given feedback, we develop a metric, toxicity index, to identify deviant players. We then look at the effects of interacting with deviant players, including effects on retention. We find that toxic players have several significant predictive patterns, such as playing in more competitive game modes and playing with friends. We also show that toxic players drive away new players, but that experienced players are more resilient to deviant behavior. Based on our findings, we suggest methods to better identify and counteract the negative effects of deviance.},
  isbn = {978-1-4503-2540-0},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/6WCVQ6PG/Grandprey-Shores et al. - 2014 - The identification of deviance and its impact on r.pdf}
}

@article{grossmanPerceivedGenderRacial2014,
  title = {Perceived {{Gender}} and {{Racial}}/{{Ethnic Barriers}} to {{STEM Success}}},
  author = {Grossman, Jennifer M. and Porche, Michelle V.},
  year = {2014},
  month = sep,
  journal = {Urban Education},
  volume = {49},
  number = {6},
  pages = {698--727},
  publisher = {SAGE Publications Inc},
  issn = {0042-0859},
  doi = {10.1177/0042085913481364},
  urldate = {2024-07-19},
  abstract = {This mixed-methods study examined urban adolescents' perceptions of gender and racial/ethnic barriers to STEM (science, technology, engineering, and mathematics) success, and their meaning-making and coping regarding these experiences. The sample includes surveys from 1024 high school-aged students and interviews from 53 students. Logistic analysis showed that higher science aspirations significantly predicted perceived support for girls and women in science. Analysis of interviews showed themes of microaggressions, responses to microaggressions, and gender- and race-based support. Findings suggest participants vary in perceptions of barriers, yet are generally optimistic about overcoming such obstacles.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/SZJ95DM3/Grossman and Porche - 2014 - Perceived Gender and RacialEthnic Barriers to STE.pdf}
}

@article{hackerWomenMinorityGroup1951,
  title = {Women as a {{Minority Group}}},
  author = {Hacker, Helen Mayer},
  year = {1951},
  journal = {Social Forces},
  volume = {30},
  number = {1},
  eprint = {2571742},
  eprinttype = {jstor},
  pages = {60--69},
  publisher = {Oxford University Press},
  issn = {0037-7732},
  doi = {10.2307/2571742},
  urldate = {2024-07-19}
}

@article{hancockAIMediatedCommunicationDefinition2020,
  title = {{{AI-Mediated Communication}}: {{Definition}}, {{Research Agenda}}, and {{Ethical Considerations}}},
  shorttitle = {{{AI-Mediated Communication}}},
  author = {Hancock, Jeffrey T and Naaman, Mor and Levy, Karen},
  year = {2020},
  month = mar,
  journal = {Journal of Computer-Mediated Communication},
  volume = {25},
  number = {1},
  pages = {89--100},
  issn = {1083-6101},
  doi = {10.1093/jcmc/zmz022},
  urldate = {2024-07-26},
  abstract = {We define Artificial Intelligence-Mediated Communication (AI-MC) as interpersonal communication in which an intelligent agent operates on behalf of a communicator by modifying, augmenting, or generating messages to accomplish communication goals. The recent advent of AI-MC raises new questions about how technology may shape human communication and requires re-evaluation -- and potentially expansion -- of many of Computer-Mediated Communication's (CMC) key theories, frameworks, and findings. A research agenda around AI-MC should consider the design of these technologies and the psychological, linguistic, relational, policy and ethical implications of introducing AI into human--human communication. This article aims to articulate such an agenda.},
  keywords = {,notion},
  annotation = {TLDR: A research agenda around AI-MC should consider the design of these technologies and the psychological, linguistic, relational, policy and ethical implications of introducing AI into human--human communication.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/TQY7LWP7/Hancock et al. - 2020 - AI-Mediated Communication Definition, Research Ag.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/D3JZXEJT/5714020.html}
}

@inproceedings{haringRobotAuthorityHumanMachine2019,
  title = {Robot {{Authority}} in {{Human-Machine Teams}}: {{Effects}} of {{Human-Like Appearance}} on {{Compliance}}},
  shorttitle = {Robot {{Authority}} in {{Human-Machine Teams}}},
  booktitle = {Virtual, {{Augmented}} and {{Mixed Reality}}. {{Applications}} and {{Case Studies}} : 11th {{International Conference}}, {{VAMR}} 2019, {{Held}} as {{Part}} of the 21st {{HCI International Conference}}, {{HCII}} 2019, {{Orlando}}, {{FL}}, {{USA}}, {{July}} 26--31, 2019, {{Proceedings}}, {{Part II}}},
  author = {Haring, Kerstin S. and Mosley, Ariana and Pruznick, Sarah and Fleming, Julie and Satterfield, Kelly and {de Visser}, Ewart J. and Tossell, Chad C. and Funke, Gregory},
  year = {2019},
  month = jul,
  pages = {63--78},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-030-21565-1_5},
  urldate = {2024-07-18},
  abstract = {Current technology allows for the deployment of security patrol and police robots. It is expected that in the near future robots and similar technologies will exhibit some degree of authority over people within human-machine teams. Studies in classical psychology investigating compliance have shown that people tend to comply with requests from others who display or are assumed to have authority. In this study, we investigated the effect of a robot's human-like appearance on compliance with a request. We compared two different robots to a human control condition. The robots assumed the role of a coach in learning a difficult task. We hypothesized that participants would have higher compliance with robots high compared to robots low in human-like appearance. The coach continuously prompts the participant to continue to practice the task beyond the time the participant wishes to actually proceed. Compliance was measured by time practiced after the first prompt and the total number of images processed. Results showed that compliance with the request was the highest with a human and compliance with both robots was significantly lower. However, we showed that robots can be used as persuasive coaches that can help a human teammate to persist in training task. There were no differences between the High and Low Human-Like robot for compliance time, however the Low Human-Like robot has people practise on more images than the High Human-Like robot. The implication of this study is that robots are currently inferior to humans when it comes to compliance in a human-machine team. Future robots need to be carefully designed in an authoritative way if maximizing compliance to their requests is the primary goal.},
  isbn = {978-3-030-21564-4}
}

@incollection{hartDevelopmentNASATLXTask1988,
  title = {Development of {{NASA-TLX}} ({{Task Load Index}}): {{Results}} of {{Empirical}} and {{Theoretical Research}}},
  shorttitle = {Development of {{NASA-TLX}} ({{Task Load Index}})},
  booktitle = {Advances in {{Psychology}}},
  author = {Hart, Sandra G. and Staveland, Lowell E.},
  editor = {Hancock, Peter A. and Meshkati, Najmedin},
  year = {1988},
  month = jan,
  series = {Human {{Mental Workload}}},
  volume = {52},
  pages = {139--183},
  publisher = {North-Holland},
  doi = {10.1016/S0166-4115(08)62386-9},
  urldate = {2024-07-18},
  abstract = {The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload.}
}

@incollection{hartDevelopmentNASATLXTask1988a,
  title = {Development of {{NASA-TLX}} ({{Task Load Index}}): {{Results}} of {{Empirical}} and {{Theoretical Research}}},
  shorttitle = {Development of {{NASA-TLX}} ({{Task Load Index}})},
  booktitle = {Advances in {{Psychology}}},
  author = {Hart, Sandra G. and Staveland, Lowell E.},
  editor = {Hancock, Peter A. and Meshkati, Najmedin},
  year = {1988},
  month = jan,
  series = {Human {{Mental Workload}}},
  volume = {52},
  pages = {139--183},
  publisher = {North-Holland},
  doi = {10.1016/S0166-4115(08)62386-9},
  urldate = {2024-07-19},
  abstract = {The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload.}
}

@inproceedings{hashemianApplicationSocialPower2020,
  title = {The {{Application}} of {{Social Power}} in {{Persuasive Social Robots}}},
  booktitle = {Companion of the 2020 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Hashemian, Mojgan and Mascarenhas, Samuel and Couto, Marta and Paiva, Ana and Santos, Pedro A. and Prada, Rui},
  year = {2020},
  month = apr,
  series = {{{HRI}} '20},
  pages = {564--566},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3371382.3377447},
  urldate = {2024-07-18},
  abstract = {The technology of the future will bring an increasing number of robots into our daily life. This has motivated a number of researchers to explore diverse factors to promote social interaction with robots. This PhD project aims at investigating social power dynamics in Human-Robot Interaction. Social power is defined as one's ability to influence others to do something which they would not do otherwise. Different theories classify alternative ways to achieve social power, such as providing rewards, using coercion, or acting as an expert. After conceptualizing social power to allow implementation in social agents, we studied how those power strategies affect persuasion when using robots. Specifically, we attempted to design persuasive robots by creating persuasive strategies inspired from social power.},
  isbn = {978-1-4503-7057-8}
}

@inproceedings{hashemianEnhancingSocialBelievability2018,
  title = {Enhancing {{Social Believability}} of {{Virtual Agents}} Using {{Social Power Dynamics}}},
  booktitle = {Proceedings of the 18th {{International Conference}} on {{Intelligent Virtual Agents}}},
  author = {Hashemian, Mojgan and Prada, Rui and Santos, Pedro A. and Mascarenhas, Samuel},
  year = {2018},
  month = nov,
  series = {{{IVA}} '18},
  pages = {147--152},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3267851.3267902},
  urldate = {2024-07-18},
  abstract = {Social Power, a pervasive feature in our daily life, has been proved to have a significant impact on Social Interaction; While the capability of maintaining a Social Interaction has an acknowledged role in Believability of Intelligent Virtual Agents (IVAs). In this paper, we argue that an ability of reasoning and planning in the presence of Social Power enhances Social Believability of IVAs, leading to more rational interactions. With this aim, we focus on theoretical issues of agent modeling aiming at increasing intelligence and therefore believability of NPCs or agents of game-like simulations or serious games. Thereby, we propose a model of social power inspired by a recently proposed model, SAPIENT, based on a well-known theory of Social Power proposed by French and Raven.},
  isbn = {978-1-4503-6013-5}
}

@inproceedings{hashemianInvestigatingRewardPunishment2020,
  title = {Investigating {{Reward}}/{{Punishment Strategies}} in the {{Persuasiveness}} of {{Social Robots}}},
  booktitle = {2020 29th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}} ({{RO-MAN}})},
  author = {Hashemian, Mojgan and Couto, Marta and Mascarenhas, Samuel and Paiva, Ana and Santos, Pedro A. and Prada, Rui},
  year = {2020},
  month = aug,
  pages = {863--868},
  issn = {1944-9437},
  doi = {10.1109/RO-MAN47096.2020.9223608},
  urldate = {2024-07-18},
  abstract = {This paper presents the results of a user study designed to investigate social robots' persuasiveness. In the design, the robot attempts to persuade users in two different conditions comparing to a control condition. In one condition, the robot aims at persuading users by giving them a reward. In the second condition, the robot tries to persuade by punishing users. The results indicated that the robot succeeded to persuade the users to select a less-desirable choice comparing to a better one. However, no difference was found in the perception of the robot's warmth nor discomfort, comparing the two strategies. The results suggest that social robots are capable of persuading users objectively, but further investigation is required to investigate persuasion subjectively.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/JX5NY9ZE/Hashemian et al. - 2020 - Investigating RewardPunishment Strategies in the .pdf}
}

@inproceedings{hashemianPersuasiveSocialRobot2021,
  title = {Persuasive {{Social Robot Using Reward Power}} over {{Repeated Instances}} of {{Persuasion}}},
  booktitle = {Persuasive {{Technology}}: 16th {{International Conference}}, {{PERSUASIVE}} 2021, {{Virtual Event}}, {{April}} 12--14, 2021, {{Proceedings}}},
  author = {Hashemian, Mojgan and Couto, Marta and Mascarenhas, Samuel and Paiva, Ana and Santos, Pedro A. and Prada, Rui},
  year = {2021},
  month = apr,
  pages = {63--70},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-030-79460-6_6},
  urldate = {2024-07-18},
  abstract = {This paper presents a user-study with Emys social robot that aims to persuade subjects to select a less-desirable choice. In this study, within a game scenario, Emys attempts to use its social power resources, specifically reward power, to persuade the user to select an alternative such that the user indicates less interest in it. This persuasion attempt is repeated over three times to investigate this effect within repeated persuasion instances. The study consists of three conditions: no/low/high reward. The results indicated that the higher reward does not necessarily lead to higher persuasion and the effect of social power does not decay over repeated persuasion instances.},
  isbn = {978-3-030-79459-0}
}

@book{hashemianPersuasiveSocialRobots2019,
  title = {Persuasive {{Social Robots}} Using {{Social Power Dynamics}}},
  author = {Hashemian, Mojgan},
  year = {2019},
  month = may,
  abstract = {Social Power, the potential for social influence, is a pervasive social process in human interactions. On the other hand, recent advances on Social Robotics raise the question of whether a social robot can be used as a persuasive agent. To date, different attempts have been performed using several approaches to tackle this research question. However, few studies looked at the concept of social power in Human-Robot Interaction (HRI) and how it can be beneficial to the development of persuasion skills. This is precisely the goal of the work that is described here. In this text, we briefly report the results of our recent advancements for this objective and draw suggestion for speculating on future directions.}
}

@inproceedings{hashemianPersuasiveSocialRobots2020,
  title = {Persuasive {{Social Robots}} Using {{Reward}}/{{Coercion Strategies}}},
  booktitle = {Companion of the 2020 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Hashemian, Mojgan and Couto, Marta and Mascarenhas, Samuel and Paiva, Ana and Santos, Pedro A. and Prada, Rui},
  year = {2020},
  month = apr,
  series = {{{HRI}} '20},
  pages = {230--232},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3371382.3378373},
  urldate = {2024-07-18},
  abstract = {In this paper, we present a user-study designed to examine the effect of reward/coercion persuasive strategies inspired by social power. We ran the study with 90 participants in a persuasion scenario in which they were asked to make a real choice to select a less-desirable option. The preliminary results indicated that the robot succeeded in persuading the users to select a less desirable choice compared to a better one. However, no difference was found in the perception of the robot regarding the persuasion strategies.},
  isbn = {978-1-4503-7057-8}
}

@inproceedings{hashemianPowerPersuadeStudy2019,
  title = {The {{Power}} to {{Persuade}}: A Study of {{Social Power}} in {{Human-Robot Interaction}}},
  shorttitle = {The {{Power}} to {{Persuade}}},
  booktitle = {2019 28th {{IEEE International Conference}} on {{Robot}} and {{Human Interactive Communication}} ({{RO-MAN}})},
  author = {Hashemian, Mojgan and Paiva, Ana and Mascarenhas, Samuel and Santos, Pedro A. and Prada, Rui},
  year = {2019},
  month = oct,
  pages = {1--8},
  publisher = {IEEE Press},
  address = {New Delhi, India},
  doi = {10.1109/RO-MAN46459.2019.8956298},
  urldate = {2024-07-18},
  abstract = {Recent advances on Social Robotics raise the question whether a social robot can be used as a persuasive agent. To date, a body of literature has been performed using various approaches to answer this research question, ranging from the use of non-verbal behavior to the exploration of different embodiment characteristics. In this paper, we investigate the role of social power for making social robots more persuasive. Social power is defined as one\&amp;\#x2019;s ability to influence another to do something which s/he would not do without the presence of such power. Different theories classify alternative ways to achieve social power, such as providing a reward, using coercion, or acting as an expert. In this work, we explored two types of persuasive strategies that are based on social power (specifically Reward and Expertise) and created two social robots that would employ such strategies. To examine the effectiveness of these strategies we performed a user study with 51 participants using two social robots in an adversarial setting in which both robots try to persuade the user on a concrete choice. The results show that even though each of the strategies caused the robots to be perceived differently in terms of their competence and warmth, both were similarly persuasive.}
}

@article{hashemianSocialPowerHumanRobot2019,
  title = {Social {{Power}} in {{Human-Robot Interaction}}: {{Towards}} More {{Persuasive Robots}}},
  author = {Hashemian, Mojgan and Paiva, Ana and Mascarenhas, Samuel and Santos, Pedro A and Prada, Rui},
  year = {2019},
  abstract = {Social power is defined as one's ability to influence another to do something which s/he would not do without the presence of such power. Different theories classify alternative ways to achieve social power, such as providing a reward, using coercion, or acting as an expert. In this work, we explored two types of persuasive strategies that are based on social power (specifically Reward and Expertise) and created two social robots that would employ such strategies. To examine the effectiveness of these strategies we performed a user study with 51 participants using two social robots in an adversarial setting in which both robots try to persuade the user on a concrete choice. The results show that even though each of the strategies caused the robots to be perceived differently in terms of their competence and warmth, both were similarly persuasive.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/KK3ZC9CA/Hashemian et al. - 2019 - Social Power in Human-Robot Interaction Towards m.pdf}
}

@article{hastingsStructureNurtureEffects2018,
  title = {Structure or {{Nurture}}? {{The Effects}} of {{Team-Building Activities}} and {{Team Composition}} on {{Team Outcomes}}},
  shorttitle = {Structure or {{Nurture}}?},
  author = {Hastings, Emily M. and Jahanbakhsh, Farnaz and Karahalios, Karrie and Marinov, Darko and Bailey, Brian P.},
  year = {2018},
  month = nov,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {2},
  number = {CSCW},
  pages = {68:1--68:21},
  doi = {10.1145/3274337},
  urldate = {2024-07-19},
  abstract = {How can instructors group students into teams that interact and learn effectively together? One strand of research advocates for grouping students into teams with "good" compositions such as skill diversity. Another strand argues for deploying team-building activities to foster interpersonal relations like psychological safety. Our work synthesizes these two strands of research. We describe an experiment (N=249) that compares how team composition vs. team-building activities affect student team outcomes. In two university courses, we composed student teams either randomly or using a criteria-based team formation tool. Teams further performed team-building activities that promoted either team or task outcomes. We collected project scores, and used surveys to measure psychological safety, perceived performance, and team satisfaction. Surprisingly, the criteria-based teams did not statistically differ from the random teams on any of the measures taken, despite having compositions that better satisfied the criteria defined by the instructor. Our findings argue that, for instructors deploying a team formation tool, creating an expectation among team members that their team can perform well is as important as tuning the criteria in the tool. We also found that student teams reported high levels of psychological safety, but these levels appeared to develop organically and were not affected by the activities or compositional strategies tested. We distill these and other findings into implications for the design and deployment of team formation tools for learning environments.}
}

@article{hauptmanAdaptOvercomePerceptions2023,
  title = {Adapt and Overcome: {{Perceptions}} of Adaptive Autonomous Agents for Human-{{AI}} Teaming},
  shorttitle = {Adapt and Overcome},
  author = {Hauptman, Allyson I. and Schelble, Beau G. and McNeese, Nathan J. and Madathil, Kapil Chalil},
  year = {2023},
  month = jan,
  journal = {Computers in Human Behavior},
  volume = {138},
  pages = {107451},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2022.107451},
  urldate = {2024-07-18},
  abstract = {Rapid advances in AI technologies have caused teams to explore the use of AI agents as full, active members of the team. The complex environments that teams occupy require human team members to constantly adapt their behaviors, and thus the ability of AI teammates to similarly adapt to changing situations significantly enhances the team's chances to succeed. In order to design such agents, it is important that we understand not only how to identify the amount of autonomous control AI agents have over their decisions, but also how changes to this control cognitively affects the rest of the team. Professional organizations often break their work cycles into phases that set limits on the team members' actions, and we propose that a similar process could be used to define the autonomy levels of AI teammates. Cyber incident response is an ideal context for this proposal, as we were able to use incident response phases to explore how a team's work cycle could guide an AI agent's changing level of autonomy. Using a mixed methods approach, we recruited 103 participants to complete a factorial survey containing ten contextual vignettes focused on an AI teammate's level of autonomy in incident response contexts, and from these participants we conducted twenty-two follow-on qualitative interviews that further explored how the participants felt an AI agent's adaptive capabilities would affect team performance and cohesiveness. Our results showed that work cycles can be used to assign autonomy levels to adaptive AI agents based upon the degree of formal processes and predictability of the team's tasks during the cycle, and that dynamic, human-like adaptation methods are vital to effective human-AI teams. This research provides significant contributions to the HCI community by proposing design recommendations for the development of adaptive autonomous teammates that both enhance Human-AI teams' productivity and promote positive team dynamics.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/F8AHZCPJ/S0747563222002722.html}
}

@misc{heHarnessingExplanationsLLMtoLM2024,
  title = {Harnessing {{Explanations}}: {{LLM-to-LM Interpreter}} for {{Enhanced Text-Attributed Graph Representation Learning}}},
  shorttitle = {Harnessing {{Explanations}}},
  author = {He, Xiaoxin and Bresson, Xavier and Laurent, Thomas and Perold, Adam and LeCun, Yann and Hooi, Bryan},
  year = {2024},
  month = mar,
  number = {arXiv:2305.19523},
  eprint = {2305.19523},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.19523},
  urldate = {2024-07-18},
  abstract = {Representation learning on text-attributed graphs (TAGs) has become a critical research problem in recent years. A typical example of a TAG is a paper citation graph, where the text of each paper serves as node attributes. Initial graph neural network (GNN) pipelines handled these text attributes by transforming them into shallow or hand-crafted features, such as skip-gram or bag-of-words features. Recent efforts have focused on enhancing these pipelines with language models (LMs), which typically demand intricate designs and substantial computational resources. With the advent of powerful large language models (LLMs) such as GPT or Llama2, which demonstrate an ability to reason and to utilize general knowledge, there is a growing need for techniques which combine the textual modelling abilities of LLMs with the structural learning capabilities of GNNs. Hence, in this work, we focus on leveraging LLMs to capture textual information as features, which can be used to boost GNN performance on downstream tasks. A key innovation is our use of explanations as features: we prompt an LLM to perform zero-shot classification, request textual explanations for its decision-making process, and design an LLM-to-LM interpreter to translate these explanations into informative features for downstream GNNs. Our experiments demonstrate that our method achieves state-of-the-art results on well-established TAG datasets, including Cora, PubMed, ogbn-arxiv, as well as our newly introduced dataset, tape-arxiv23. Furthermore, our method significantly speeds up training, achieving a 2.88 times improvement over the closest baseline on ogbn-arxiv. Lastly, we believe the versatility of the proposed method extends beyond TAGs and holds the potential to enhance other tasks involving graph-text data. Our codes and datasets are available at: https://github.com/XiaoxinHe/TAPE.},
  archiveprefix = {arXiv},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/3PV6SILV/He et al. - 2024 - Harnessing Explanations LLM-to-LM Interpreter for.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/RBMNHMGD/2305.html}
}

@inproceedings{heKnowingKnowingIllusion2023,
  title = {Knowing {{About Knowing}}: {{An Illusion}} of {{Human Competence Can Hinder Appropriate Reliance}} on {{AI Systems}}},
  shorttitle = {Knowing {{About Knowing}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {He, Gaole and Kuiper, Lucie and Gadiraju, Ujwal},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--18},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581025},
  urldate = {2024-07-17},
  abstract = {The dazzling promises of AI systems to augment humans in various tasks hinge on whether humans can appropriately rely on them. Recent research has shown that appropriate reliance is the key to achieving complementary team performance in AI-assisted decision making. This paper addresses an under-explored problem of whether the Dunning-Kruger Effect (DKE) among people can hinder their appropriate reliance on AI systems. DKE is a metacognitive bias due to which less-competent individuals overestimate their own skill and performance. Through an empirical study (N = 249), we explored the impact of DKE on human reliance on an AI system, and whether such effects can be mitigated using a tutorial intervention that reveals the fallibility of AI advice, and exploiting logic units-based explanations to improve user understanding of AI advice. We found that participants who overestimate their performance tend to exhibit under-reliance on AI systems, which hinders optimal team performance. Logic units-based explanations did not help users in either improving the calibration of their competence or facilitating appropriate reliance. While the tutorial intervention was highly effective in helping users calibrate their self-assessment and facilitating appropriate reliance among participants with overestimated self-assessment, we found that it can potentially hurt the appropriate reliance of participants with underestimated self-assessment. Our work has broad implications on the design of methods to tackle user cognitive biases while facilitating appropriate reliance on AI systems. Our findings advance the current understanding of the role of self-assessment in shaping trust and reliance in human-AI decision making. This lays out promising future directions for relevant HCI research in this community.},
  isbn = {978-1-4503-9421-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/KRR868RD/He et al. - 2023 - Knowing About Knowing An Illusion of Human Compet.pdf}
}

@inproceedings{hemmerHumanAICollaborationEffect2023,
  title = {Human-{{AI Collaboration}}: {{The Effect}} of {{AI Delegation}} on {{Human Task Performance}} and {{Task Satisfaction}}},
  shorttitle = {Human-{{AI Collaboration}}},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Hemmer, Patrick and Westphal, Monika and Schemmer, Max and Vetter, Sebastian and V{\"o}ssing, Michael and Satzger, Gerhard},
  year = {2023},
  month = mar,
  series = {{{IUI}} '23},
  pages = {453--463},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3581641.3584052},
  urldate = {2024-07-17},
  abstract = {Recent work has proposed artificial intelligence (AI) models that can learn to decide whether to make a prediction for an instance of a task or to delegate it to a human by considering both parties' capabilities. In simulations with synthetically generated or context-independent human predictions, delegation can help improve the performance of human-AI teams---compared to humans or the AI model completing the task alone. However, so far, it remains unclear how humans perform and how they perceive the task when they are aware that an AI model delegated task instances to them. In an experimental study with 196 participants, we show that task performance and task satisfaction improve through AI delegation, regardless of whether humans are aware of the delegation. Additionally, we identify humans' increased levels of self-efficacy as the underlying mechanism for these improvements in performance and satisfaction. Our findings provide initial evidence that allowing AI models to take over more management responsibilities can be an effective form of human-AI collaboration in workplaces.},
  isbn = {9798400701061},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/WXD9WFJV/Hemmer et al. - 2023 - Human-AI Collaboration The Effect of AI Delegatio.pdf}
}

@article{hofstedeDimensionalizingCulturesHofstede2011,
  title = {Dimensionalizing {{Cultures}}: {{The Hofstede Model}} in {{Context}}},
  shorttitle = {Dimensionalizing {{Cultures}}},
  author = {Hofstede, Geert},
  year = {2011},
  month = dec,
  journal = {Online Readings in Psychology and Culture},
  volume = {2},
  number = {1},
  issn = {2307-0919},
  doi = {10.9707/2307-0919.1014},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/FZU2LEGA/Hofstede - 2011 - Dimensionalizing Cultures The Hofstede Model in Context.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/EUC8RWLK/8.html}
}

@article{hoggPROBABILITYSTATISTICALINFERENCE2015,
  title = {{{PROBABILITY AND STATISTICAL INFERENCE}}},
  author = {Hogg, Robert V and Tanis, Elliot A and Zimmerman, Dale L},
  year = {2015},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/Y44H9GPY/Hogg et al. - 2015 - PROBABILITY AND STATISTICAL INFERENCE.pdf}
}

@inproceedings{hohensteinAISupportedMessagingInvestigation2018,
  title = {{{AI-Supported Messaging}}: {{An Investigation}} of {{Human-Human Text Conversation}} with {{AI Support}}},
  shorttitle = {{{AI-Supported Messaging}}},
  booktitle = {Extended {{Abstracts}} of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Hohenstein, Jess and Jung, Malte},
  year = {2018},
  month = apr,
  series = {{{CHI EA}} '18},
  pages = {1--6},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3170427.3188487},
  urldate = {2024-07-18},
  abstract = {Despite a growing body of research about the design and use of conversational agents, existing work has almost exclusively focused on interactions between an agent and a human. Less is known about how an agent is perceived and used during human-human conversation. We compared conversations between dyads using AI-assisted and standard messaging apps and elicited qualitative feedback from users of the AI-assisted messaging app through interviews. We find discrepancies between the AI assistant's suggestions and the conversational content, which is also reflected in participant interviews. Our results are used to suggest some areas for improvement and future work in AI-assisted communication.},
  isbn = {978-1-4503-5621-3}
}

@article{hohensteinArtificialIntelligenceCommunication2023,
  title = {Artificial Intelligence in Communication Impacts Language and Social Relationships},
  author = {Hohenstein, Jess and Kizilcec, Rene F. and DiFranzo, Dominic and Aghajari, Zhila and Mieczkowski, Hannah and Levy, Karen and Naaman, Mor and Hancock, Jeffrey and Jung, Malte F.},
  year = {2023},
  month = apr,
  journal = {Scientific Reports},
  volume = {13},
  number = {1},
  pages = {5487},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-023-30938-9},
  urldate = {2025-01-21},
  abstract = {Artificial intelligence (AI) is already widely used in daily communication, but despite concerns about AI's negative effects on society the social consequences of using it to communicate remain largely unexplored. We investigate the social consequences of one of the most pervasive AI applications, algorithmic response suggestions (``smart replies''), which are used to send billions of messages each day. Two randomized experiments provide evidence that these types of algorithmic recommender systems change how people interact with and perceive one another in both pro-social and anti-social ways. We find that using algorithmic responses changes language and social relationships. More specifically, it increases communication speed, use of positive emotional language, and conversation partners evaluate each other as closer and more cooperative. However, consistent with common assumptions about the adverse effects of AI, people are evaluated more negatively if they are suspected to be using algorithmic responses. Thus, even though AI can increase the speed of communication and improve interpersonal perceptions, the prevailing anti-social connotations of AI undermine these potential benefits if used overtly.},
  copyright = {2023 The Author(s)},
  langid = {english},
  annotation = {TLDR: It is found that using algorithmic responses changes language and social relationships, which increases communication speed, use of positive emotional language, and conversation partners evaluate each other as closer and more cooperative.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/P8IXJXGS/Hohenstein et al. - 2023 - Artificial intelligence in communication impacts language and social relationships.pdf}
}

@article{holsteinSupportingPerceptualComplementarity2023,
  title = {Toward {{Supporting Perceptual Complementarity}} in {{Human-AI Collaboration}} via {{Reflection}} on {{Unobservables}}},
  author = {Holstein, Kenneth and {De-Arteaga}, Maria and Tumati, Lakshmi and Cheng, Yanghuidi},
  year = {2023},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {7},
  number = {CSCW1},
  pages = {152:1--152:20},
  doi = {10.1145/3579628},
  urldate = {2024-07-18},
  abstract = {In many real world contexts, successful human-AI collaboration requires humans to productively integrate complementary sources of information into AI-informed decisions. However, in practice human decision-makers often lack understanding of what information an AI model has access to, in relation to themselves. There are few available guidelines regarding how to effectively communicate aboutunobservables: features that may influence the outcome, but which are unavailable to the model. In this work, we conducted an online experiment to understand whether and how explicitly communicating potentially relevant unobservables influences how people integrate model outputs and unobservables when making predictions. Our findings indicate that presenting prompts about unobservables can change how humans integrate model outputs and unobservables, but do not necessarily lead to improved performance. Furthermore, the impacts of these prompts can vary depending on decision-makers' prior domain expertise. We conclude by discussing implications for future research and design of AI-based decision support tools.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/KG3NHL89/Holstein et al. - 2023 - Toward Supporting Perceptual Complementarity in Hu.pdf}
}

@article{horstmannGreatExpectationsRelation2019,
  title = {Great {{Expectations}}? {{Relation}} of {{Previous Experiences With Social Robots}} in {{Real Life}} or in the {{Media}} and {{Expectancies Based}} on {{Qualitative}} and {{Quantitative Assessment}}},
  shorttitle = {Great {{Expectations}}?},
  author = {Horstmann, Aike C. and Kr{\"a}mer, Nicole C.},
  year = {2019},
  month = apr,
  journal = {Frontiers in Psychology},
  volume = {10},
  publisher = {Frontiers},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2019.00939},
  urldate = {2024-07-19},
  abstract = {{$<$}p{$>$}Social robots, which mostly look and behave like humans, are often perceived as somehow alive and treated similar to humans, despite the fact that they are non-living electronic devices. Based on considerations of the uncertainty reduction theory, the question arises what expectancies regarding social robots people have and what sources they use to achieve these expectancies. To receive an in-depth understanding of people's expectancies regarding social robots and particularly how these expectancies are influenced by people's experiences with real robots but also with fictional robots from media, thirteen semi-structured interviews and a quantitative online study ({$<$}italic{$>$}n{$<$}/italic{$>$} = 433) were conducted. Results indicate that people's experiences with robots in the media lead to high expectations regarding the skills of robots, which in turn increase people's general expectancies regarding social robots being part of the society as well as their personal lives. Furthermore, knowledge of negatively perceived fictional robots increases negative expectancies of robots becoming a threat to humans, while technical affinity reduces general robot anxiety.{$<$}/p{$>$}},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/T9LCYWN2/Horstmann and Krämer - 2019 - Great Expectations Relation of Previous Experienc.pdf}
}

@misc{houdeControllingAIAgent2025,
  title = {Controlling {{AI Agent Participation}} in {{Group Conversations}}: {{A Human-Centered Approach}}},
  shorttitle = {Controlling {{AI Agent Participation}} in {{Group Conversations}}},
  author = {Houde, Stephanie and Brimijoin, Kristina and Muller, Michael and Ross, Steven I. and Moran, Dario Andres Silva and Gonzalez, Gabriel Enrique and Kunde, Siya and Foreman, Morgan A. and Weisz, Justin D.},
  year = {2025},
  month = jan,
  eprint = {2501.17258},
  primaryclass = {cs},
  doi = {10.1145/3708359.3712089},
  urldate = {2025-02-07},
  abstract = {Conversational AI agents are commonly applied within single-user, turn-taking scenarios. The interaction mechanics of these scenarios are trivial: when the user enters a message, the AI agent produces a response. However, the interaction dynamics are more complex within group settings. How should an agent behave in these settings? We report on two experiments aimed at uncovering users' experiences of an AI agent's participation within a group, in the context of group ideation (brainstorming). In the first study, participants benefited from and preferred having the AI agent in the group, but participants disliked when the agent seemed to dominate the conversation and they desired various controls over its interactive behaviors. In the second study, we created functional controls over the agent's behavior, operable by group members, to validate their utility and probe for additional requirements. Integrating our findings across both studies, we developed a taxonomy of controls for when, what, and where a conversational AI agent in a group should respond, who can control its behavior, and how those controls are specified and implemented. Our taxonomy is intended to aid AI creators to think through important considerations in the design of mixed-initiative conversational agents.},
  archiveprefix = {arXiv},
  annotation = {TLDR: A taxonomy of controls for when, what, and where a conversational AI agent in a group should respond, who can control its behavior, and how those controls are specified and implemented is developed.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/W3SML52I/Houde et al. - 2025 - Controlling AI Agent Participation in Group Conversations A Human-Centered Approach.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/GV4ZYD9X/2501.html}
}

@inproceedings{houPowerHumanRobotInteraction2024,
  title = {Power in {{Human-Robot Interaction}}},
  booktitle = {Proceedings of the 2024 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Hou, Yoyo Tsung-Yu and Cheon, EunJeong and Jung, Malte F.},
  year = {2024},
  month = mar,
  series = {{{HRI}} '24},
  pages = {269--282},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3610977.3634949},
  urldate = {2024-04-01},
  abstract = {Power is a fundamental determinant of social life, yet it remains elusive in Human-Robot Interaction (HRI). This paper unveils power's pervasive but largely unexplored role in HRI by systematically investigating its varied manifestations across HRI literature. We first introduce definitions of power and then delve into the existing HRI literature through a lens of power, examining studies that directly address power and those exploring power-related social configurations and concepts such as authority, dominance, and status. Leveraging Fiske and Berdahl's model and French and Raven's bases of power framework, we also explore the nuances of power in many HRI studies where power is not explicitly addressed. Finally, we propose power as a core concept to advance HRI--- explaining fragmented existing findings through a coherent theory and delineating a cohesive theoretical trajectory for future investigations.},
  isbn = {9798400703225},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VSYEBTSR/Hou 등 - 2024 - Power in Human-Robot Interaction.pdf}
}

@inproceedings{houPowerHumanRobotInteraction2024a,
  title = {Power in {{Human-Robot Interaction}}},
  booktitle = {Proceedings of the 2024 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Hou, Yoyo Tsung-Yu and Cheon, EunJeong and Jung, Malte F.},
  year = {2024},
  month = mar,
  series = {{{HRI}} '24},
  pages = {269--282},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3610977.3634949},
  urldate = {2024-07-18},
  abstract = {Power is a fundamental determinant of social life, yet it remains elusive in Human-Robot Interaction (HRI). This paper unveils power's pervasive but largely unexplored role in HRI by systematically investigating its varied manifestations across HRI literature. We first introduce definitions of power and then delve into the existing HRI literature through a lens of power, examining studies that directly address power and those exploring power-related social configurations and concepts such as authority, dominance, and status. Leveraging Fiske and Berdahl's model and French and Raven's bases of power framework, we also explore the nuances of power in many HRI studies where power is not explicitly addressed. Finally, we propose power as a core concept to advance HRI--- explaining fragmented existing findings through a coherent theory and delineating a cohesive theoretical trajectory for future investigations.},
  isbn = {9798400703225}
}

@inproceedings{houShouldFollowHuman2023,
  title = {``{{Should I Follow}} the {{Human}}, or {{Follow}} the {{Robot}}?'' --- {{Robots}} in {{Power Can Have More Influence Than Humans}} on {{Decision-Making}}},
  shorttitle = {``{{Should I Follow}} the {{Human}}, or {{Follow}} the {{Robot}}?},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Hou, Yoyo Tsung-Yu and Lee, Wen-Ying and Jung, Malte},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581066},
  urldate = {2024-03-26},
  abstract = {Artificially intelligent (AI) agents such as robots are increasingly delegated power in work settings, yet it remains unclear how power functions in interactions with both humans and robots, especially when they directly compete for influence. Here we present an experiment where every participant was matched with one human and one robot to perform decision-making tasks. By manipulating who has power, we created three conditions: human as leader, robot as leader, and a no-power-difference control. The results showed that the participants were significantly more influenced by the leader, regardless of whether the leader was a human or a robot. However, they generally held a more positive attitude toward the human than the robot, although they considered whichever was in power as more competent. This study illustrates the importance of power for future Human-Robot Interaction (HRI) and Human-AI Interaction (HAI) research, as it addresses pressing concerns of society about AI-powered intelligent agents.},
  isbn = {978-1-4503-9421-5},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/MBHQQKLM/Hou 등 - 2023 - “Should I Follow the Human, or Follow the Robot” .pdf}
}

@inproceedings{houShouldFollowHuman2023a,
  title = {``{{Should I Follow}} the {{Human}}, or {{Follow}} the {{Robot}}?'' --- {{Robots}} in {{Power Can Have More Influence Than Humans}} on {{Decision-Making}}},
  shorttitle = {``{{Should I Follow}} the {{Human}}, or {{Follow}} the {{Robot}}?},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Hou, Yoyo Tsung-Yu and Lee, Wen-Ying and Jung, Malte},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581066},
  urldate = {2024-07-16},
  abstract = {Artificially intelligent (AI) agents such as robots are increasingly delegated power in work settings, yet it remains unclear how power functions in interactions with both humans and robots, especially when they directly compete for influence. Here we present an experiment where every participant was matched with one human and one robot to perform decision-making tasks. By manipulating who has power, we created three conditions: human as leader, robot as leader, and a no-power-difference control. The results showed that the participants were significantly more influenced by the leader, regardless of whether the leader was a human or a robot. However, they generally held a more positive attitude toward the human than the robot, although they considered whichever was in power as more competent. This study illustrates the importance of power for future Human-Robot Interaction (HRI) and Human-AI Interaction (HAI) research, as it addresses pressing concerns of society about AI-powered intelligent agents.},
  isbn = {978-1-4503-9421-5}
}

@article{houWhoExpertReconciling2021,
  title = {Who Is the {{Expert}}? {{Reconciling Algorithm Aversion}} and {{Algorithm Appreciation}} in {{AI-Supported Decision Making}}},
  shorttitle = {Who Is the {{Expert}}?},
  author = {Hou, Yoyo Tsung-Yu and Jung, Malte F.},
  year = {2021},
  month = oct,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  number = {CSCW2},
  pages = {477:1--477:25},
  doi = {10.1145/3479864},
  urldate = {2024-07-18},
  abstract = {The increased use of algorithms to support decision making raises questions about whether people prefer algorithmic or human input when making decisions. Two streams of research on algorithm aversion and algorithm appreciation have yielded contradicting results. Our work attempts to reconcile these contradictory findings by focusing on the framings of humans and algorithms as a mechanism. In three decision making experiments, we created an algorithm appreciation result (Experiment 1) as well as an algorithm aversion result (Experiment 2) by manipulating only the description of the human agent and the algorithmic agent, and we demonstrated how different choices of framings can lead to inconsistent outcomes in previous studies (Experiment 3). We also showed that these results were mediated by the agent's perceived competence, i.e., expert power. The results provide insights into the divergence of the algorithm aversion and algorithm appreciation literature. We hope to shift the attention from these two contradicting phenomena to how we can better design the framing of algorithms. We also call the attention of the community to the theory of power sources, as it is a systemic framework that can open up new possibilities for designing algorithmic decision support systems.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/BUGNN74A/Hou and Jung - 2021 - Who is the Expert Reconciling Algorithm Aversion .pdf}
}

@article{houWhoExpertReconciling2021a,
  title = {Who Is the {{Expert}}? {{Reconciling Algorithm Aversion}} and {{Algorithm Appreciation}} in {{AI-Supported Decision Making}}},
  shorttitle = {Who Is the {{Expert}}?},
  author = {Hou, Yoyo Tsung-Yu and Jung, Malte F.},
  year = {2021},
  month = oct,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  number = {CSCW2},
  pages = {477:1--477:25},
  doi = {10.1145/3479864},
  urldate = {2024-07-18},
  abstract = {The increased use of algorithms to support decision making raises questions about whether people prefer algorithmic or human input when making decisions. Two streams of research on algorithm aversion and algorithm appreciation have yielded contradicting results. Our work attempts to reconcile these contradictory findings by focusing on the framings of humans and algorithms as a mechanism. In three decision making experiments, we created an algorithm appreciation result (Experiment 1) as well as an algorithm aversion result (Experiment 2) by manipulating only the description of the human agent and the algorithmic agent, and we demonstrated how different choices of framings can lead to inconsistent outcomes in previous studies (Experiment 3). We also showed that these results were mediated by the agent's perceived competence, i.e., expert power. The results provide insights into the divergence of the algorithm aversion and algorithm appreciation literature. We hope to shift the attention from these two contradicting phenomena to how we can better design the framing of algorithms. We also call the attention of the community to the theory of power sources, as it is a systemic framework that can open up new possibilities for designing algorithmic decision support systems.}
}

@article{hsiehNewMeasureGroup2020,
  title = {A New Measure of Group Decision-Making Efficiency},
  author = {Hsieh, Cheng-Ju and Fifi{\'c}, Mario and Yang, Cheng-Ta},
  year = {2020},
  month = sep,
  journal = {Cognitive Research: Principles and Implications},
  volume = {5},
  number = {1},
  pages = {45},
  issn = {2365-7464},
  doi = {10.1186/s41235-020-00244-3},
  urldate = {2024-08-09},
  abstract = {It has widely been accepted that aggregating group-level decisions is superior to individual decisions. As compared to individuals, groups tend to show a decision advantage in their response accuracy. However, there has been a lack of research exploring whether group decisions are more efficient than individual decisions with a faster information-processing speed. To investigate the relationship between accuracy and response time (RT) in group decision-making, we applied systems' factorial technology, developed by Townsend and Nozawa (Journal of Mathematical Psychology 39, 321--359, 1995) and regarded as a theory-driven methodology, to study the information-processing properties. More specifically, we measured the workload capacity CAND(t), which only considers the correct responses, and the assessment function of capacity AAND(t), which considers the speed-accuracy trade-off, to make a strong inference about the system-level processing efficiency. A two-interval, forced-choice oddball detection task, where participants had to detect which interval contains an odd target, was conducted in Experiment 1. Then, in Experiment 2, a yes/no Gabor detection task was adopted, where participants had to detect the presence of a Gabor patch. Our results replicated previous findings using the accuracy-based measure: Group detection sensitivity was better than the detection sensitivity of the best individual, especially when the two individuals had similar detection sensitivities. On the other hand, both workload capacity measures,~CAND(t) and~AAND(t), showed evidence of supercapacity processing, thus suggesting a collective benefit. The ordered relationship between accuracy-based and RT-based collective benefit was limited to the AAND(t) of the correct and fast responses, which may help uncover the processing mechanism behind collective benefits. Our results suggested that~AAND(t), which combines both accuracy and RT into inferences, can be regarded as a novel and diagnostic tool for studying the group decision-making process.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/KQETRKZR/Hsieh et al. - 2020 - A new measure of group decision-making efficiency.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/JVZ3G5WE/s41235-020-00244-3.html}
}

@article{hsuGroupDecisionmakingApproach2021,
  title = {A Group Decision-Making Approach for Exploring Trends in the Development of the Healthcare Industry in {{Taiwan}}},
  author = {Hsu, Wan-Chi Jackie and Liou, James J. H. and Lo, Huai-Wei},
  year = {2021},
  month = feb,
  journal = {Decision Support Systems},
  volume = {141},
  pages = {113447},
  issn = {0167-9236},
  doi = {10.1016/j.dss.2020.113447},
  urldate = {2024-08-09},
  abstract = {The increased awareness of the importance of global healthcare which has formed an inseparable relationship with the quality of human life has led researchers to pay attention to trends in the development of the healthcare industry. This study identifies eight potential development trends designed to provide the healthcare industry with appropriate development strategy recommendations. The modified Z-numbers decision-making trial and evaluation laboratory (called the modified Z-DEMATEL) technique is adapted to construct the mutual influential relationships and prioritize these trends. The Z-number method optimizes the conventional fuzzy numbers and increases the reliability of expert evaluations to reflect the confidence of the evaluation environment under uncertainty. The modified Z-DEMATEL provides a complete linguistic evaluation and its membership functions, and generates a set of influence weights of the criteria. Real healthcare development trends in Taiwan are taken as an example to demonstrate the effectiveness of the proposed model. The results show that the internet of things and telemedicine are important future trends in Taiwan. This paper provides useful and reliable management suggestions to help the healthcare industry promote innovative technologies.}
}

@article{huffakerGenderIdentityLanguage2005,
  title = {Gender, {{Identity}}, and {{Language Use}} in {{Teenage Blogs}}},
  author = {Huffaker, David A. and Calvert, Sandra L.},
  year = {2005},
  month = jan,
  journal = {Journal of Computer-Mediated Communication},
  volume = {10},
  number = {2},
  pages = {JCMC10211},
  issn = {1083-6101},
  doi = {10.1111/j.1083-6101.2005.tb00238.x},
  urldate = {2024-07-19},
  abstract = {This study examines issues of online identity and language use among male and female teenagers who created and maintained weblogs, personal journals made publicly accessible on the World Wide Web. Online identity and language use were examined in terms of the disclosure of personal information, sexual identity, emotive features, and semantic themes. Male and female teenagers presented themselves similarly in their blogs, often revealing personal information such as their real names, ages, and locations. Males more so than females used emoticons, employed an active and resolute style of language, and were more likely to present themselves as gay. The results suggest that teenagers stay closer to reality in their online expressions of self than has previously been suggested, and that these explorations involve issues, such as learning about their sexuality, that commonly occur during the adolescent years.}
}

@article{hutterMotivationLossesTeamwork2011,
  title = {Motivation Losses in Teamwork: {{The}} Effects of Team Diversity and Equity Sensitivity on Reactions to Free-Riding},
  shorttitle = {Motivation Losses in Teamwork},
  author = {H{\"u}tter, Mandy and Diehl, Michael},
  year = {2011},
  month = nov,
  journal = {Group Processes \& Intergroup Relations},
  volume = {14},
  number = {6},
  pages = {845--856},
  publisher = {SAGE Publications Ltd},
  issn = {1368-4302},
  doi = {10.1177/1368430211402405},
  urldate = {2024-07-19},
  abstract = {Team diversity may lead to a categorization of teammates as ingroup versus outgroup members. Therefore, the question arises whether there would be more permissiveness in reaction to ingroup free-riders than outgroup free-riders. To test this hypothesis, subjects were randomly assigned to one of two reward conditions (equity versus equality) and had to work with a partner who obviously underachieved and supposedly belonged to the same or a different group with regard to cognitive style. In addition, we assessed subjects' individual sensitivity to equity norms, assuming that this would be a further moderator of the sucker effect. As expected, significant interaction effects on individual performance occurred for both variables.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/Z67T4RQH/Hütter and Diehl - 2011 - Motivation losses in teamwork The effects of team.pdf}
}

@inproceedings{hwangSoundSupportGendered2024,
  title = {The {{Sound}} of {{Support}}: {{Gendered Voice Agent}} as {{Support}} to {{Minority Teammates}} in {{Gender-Imbalanced Team}}},
  shorttitle = {The {{Sound}} of {{Support}}},
  booktitle = {Proceedings of the {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Hwang, Angel Hsing-Chi and Won, Andrea Stevenson},
  year = {2024},
  month = may,
  series = {{{CHI}} '24},
  pages = {1--22},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3613904.3642202},
  urldate = {2024-07-16},
  abstract = {The present work explores the potential of leveraging a teamwork agent's identity -- signaled through its gendered voice -- to support marginalized individuals in gender-imbalanced teams. In a mixed design experiment (N = 178), participants were randomly assigned to work with a female and a male voice agent in either a female-dominated or male-dominated team. Results show the presence of a same-gender voice agent is particularly beneficial to the performance of minority female members, such that they would contribute more ideas and talk more when a female agent was present. Conversely, minority male members became more talkative but were less focused on the teamwork tasks at hand when working with a male-sounding agent. The findings of the present experiment support existing literature on the effect of social presence in gender-imbalanced teams, such that gendered agents serve similar benefits as human teammates of the same gender identities. However, the effect of agents' presence remains limited when participants have experienced severe marginalization in the past. Based on findings from the present study, we discuss relevant design implications and avenues for future research.},
  isbn = {9798400703300},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/X9AXULRB/Hwang and Won - 2024 - The Sound of Support Gendered Voice Agent as Supp.pdf}
}

@misc{ImpactPerceivedAutonomous,
  title = {The {{Impact}} of {{Perceived Autonomous Agents}} on {{Dynamic Team Behaviors}} {\textbar} {{IEEE Journals}} \& {{Magazine}} {\textbar} {{IEEE Xplore}}},
  urldate = {2024-07-19},
  howpublished = {https://ieeexplore.ieee.org/abstract/document/8416798}
}

@misc{InGroupUsOutGroup,
  title = {In-{{Group}} ({{Us}}) versus {{Out-Group}} ({{Them}}) {{Dynamics}} and {{Effectiveness}} in {{Partially Distributed Teams}} {\textbar} {{IEEE Journals}} \& {{Magazine}} {\textbar} {{IEEE Xplore}}},
  urldate = {2024-07-19},
  howpublished = {https://ieeexplore.ieee.org/abstract/document/6457434}
}

@inproceedings{jakeschAIMediatedCommunicationHow2019,
  title = {{{AI-Mediated Communication}}: {{How}} the {{Perception}} That {{Profile Text}} Was {{Written}} by {{AI Affects Trustworthiness}}},
  shorttitle = {{{AI-Mediated Communication}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Jakesch, Maurice and French, Megan and Ma, Xiao and Hancock, Jeffrey T. and Naaman, Mor},
  year = {2019},
  month = may,
  series = {{{CHI}} '19},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3290605.3300469},
  urldate = {2024-07-21},
  abstract = {We are entering an era of AI-Mediated Communication (AI-MC) where interpersonal communication is not only mediated by technology, but is optimized, augmented, or generated by artificial intelligence. Our study takes a first look at the potential impact of AI-MC on online self-presentation. In three experiments we test whether people find Airbnb hosts less trustworthy if they believe their profiles have been written by AI. We observe a new phenomenon that we term the Replicant Effect: Only when participants thought they saw a mixed set of AI- and human-written profiles, they mistrusted hosts whose profiles were labeled as or suspected to be written by AI. Our findings have implications for the design of systems that involve AI technologies in online self-presentation and chart a direction for future work that may upend or augment key aspects of Computer-Mediated Communication theory.},
  isbn = {978-1-4503-5970-2},
  annotation = {TLDR: A new phenomenon is observed that is termed the Replicant Effect: Only when participants thought they saw a mixed set of AI- and human-written profiles, they mistrusted hosts whose profiles were labeled as or suspected to be written by AI.}
}

@inproceedings{jakeschCoWritingOpinionatedLanguage2023,
  title = {Co-{{Writing}} with {{Opinionated Language Models Affects Users}}' {{Views}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Jakesch, Maurice and Bhat, Advait and Buschek, Daniel and Zalmanson, Lior and Naaman, Mor},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--15},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581196},
  urldate = {2024-07-17},
  abstract = {If large language models like GPT-3 preferably produce a particular point of view, they may influence people's opinions on an unknown scale. This study investigates whether a language-model-powered writing assistant that generates some opinions more often than others impacts what users write -- and what they think. In an online experiment, we asked participants (N=1,506) to write a post discussing whether social media is good for society. Treatment group participants used a language-model-powered writing assistant configured to argue that social media is good or bad for society. Participants then completed a social media attitude survey, and independent judges (N=500) evaluated the opinions expressed in their writing. Using the opinionated language model affected the opinions expressed in participants' writing and shifted their opinions in the subsequent attitude survey. We discuss the wider implications of our results and argue that the opinions built into AI language technologies need to be monitored and engineered more carefully.},
  isbn = {978-1-4503-9421-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/JLDGWKPL/Jakesch et al. - 2023 - Co-Writing with Opinionated Language Models Affect.pdf}
}

@article{jamiesonSympathyDevilPhysiological2014,
  title = {Sympathy for the Devil? {{The}} Physiological and Psychological Effects of Being an Agent (and Target) of Dissent during Intragroup Conflict},
  shorttitle = {Sympathy for the Devil?},
  author = {Jamieson, Jeremy P. and Valdesolo, Piercarlo and Peters, Brett J.},
  year = {2014},
  month = nov,
  journal = {Journal of Experimental Social Psychology},
  volume = {55},
  pages = {221--227},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2014.07.011},
  urldate = {2024-07-18},
  abstract = {Research has accumulated on the impact of intragroup conflict on group outcomes, but little is known about the effects of dissent on the individuals who provide it. Here, we examined how being the agent and target of dissent impacted physiological responses and psychological needs. Groups of three (a participant and two confederates) completed a marketing task. Participants were assigned to an agent of dissent, target of dissent, or inclusion control role. Agents of dissent exhibited an approach-motivated cardiovascular profile: low vascular resistance and rapid sympathetic recovery. Conversely, targets displayed avoidance responses: vasoconstriction. Role assignment also impacted basic psychological needs. Targets experienced threats to all fundamental needs, but agents only exhibited threats to belonging and self-esteem (not control or meaningful existence) needs. Taken together, agents and targets of dissent responded vastly differently in this group performance context. Implications for health and performance are discussed.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/RWZDMN3F/S0022103114001097.html}
}

@book{janisGroupthinkPsychologicalStudies1982,
  title = {Groupthink : Psychological Studies of Policy Decisions and Fiascoes},
  shorttitle = {Groupthink},
  author = {Janis, Irving L. (Irving Lester)},
  year = {1982},
  publisher = {Boston : Houghton Mifflin},
  urldate = {2024-08-09},
  abstract = {Rev. and enl. ed. of: Victims of groupthink. 1972; Bibliography: p. 327-334; Includes index; Fiascoes. Introduction: Why so many miscalculations? ; A perfect failure: The Bay of Pigs ; In and out of North Korea: "The wrong war with the wrong enemy" ; Pearl Harbor revisited: Or, why the fortress slept ; Escalation of the Vietnam War: How could it happen? -- Counterpoint. The Cuban Missile Crisis ; The making of the Marshall Plan. -- Theory, implications, and applications. The groupthink syndrome ; The Watergate cover-up: How clever manipulators can get caught in an avoidable quagmire ; Generalizations: Who succumbs, when, and why ; Preventing groupthink},
  collaborator = {{Internet Archive}},
  isbn = {978-0-395-31704-4},
  langid = {english}
}

@book{janisVictimsGroupthinkPsychological1972,
  title = {Victims of Groupthink: {{A}} Psychological Study of Foreign-Policy Decisions and Fiascoes},
  shorttitle = {Victims of Groupthink},
  author = {Janis, Irving L.},
  year = {1972},
  series = {Victims of Groupthink: {{A}} Psychological Study of Foreign-Policy Decisions and Fiascoes},
  pages = {viii, 277},
  publisher = {Houghton Mifflin},
  address = {Oxford, England},
  abstract = {Defines "groupthink" as a psychological drive for consensus at any cost that suppresses dissent and appraisal of alternatives in cohesive decision making groups. A group dynamics approach to explain aspects of American foreign policy decision making is used, and suggestions for preventing "groupthink" are presented. (6 p ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/HXI5QWJ4/1975-29417-000.html}
}

@article{jiangPublicAdministrationReview,
  title = {{$<$}em{$>$}{{Public Administration Review}}{$<$}/Em{$>$} {\textbar} {{ASPA Journal}} {\textbar} {{Wiley Online Library}}},
  author = {Jiang, Zhongnan and {DeHart-Davis}, Leisha and Borry, Erin L.},
  doi = {10.1111/puar.13494},
  urldate = {2024-07-19},
  abstract = {Diversity climate---shared employee perceptions of the extent to which an organization is inclusive and fair---is of increasing interest to public administration scholars. While research has linked dive...},
  langid = {english}
}

@article{johannaDrawbacksGroupDecision2016,
  title = {The {{Drawbacks}} of {{Group Decision Making}} from a {{Psychological Aspect}}: {{The Pitfalls}} of {{Groupthink}} and {{How}} to {{Handle Them}}},
  shorttitle = {The {{Drawbacks}} of {{Group Decision Making}} from a {{Psychological Aspect}}},
  author = {Johanna, Farkas},
  year = {2016},
  month = apr,
  journal = {Magyar Rend{\'e}szet},
  volume = {16},
  number = {2},
  pages = {67--78},
  issn = {1787-050X},
  urldate = {2024-07-18},
  abstract = {In the field of law enforcement coordinated work is the basis of professional efficiency. That is the reason why being acquainted with social psychological processes, which can serve as obstacles in group decision making, is a must. Sometimes group thinking is present in closely united groups or cases of great significance. In these situations, individuals tend to overrate the viewpoint held by the group as opposed to theirs in order to negotiate with consent. The decision-maker team can see the agreement as inviolable not letting criticism intrude. In extreme cases this can create capital errors in decision. By being familiar with the mechanisms that go with group thinking these errors could be avoided and possible mistakes be fixed.},
  copyright = {Copyright (c) 2020},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/9QHJ5BGX/Johanna - 2016 - The Drawbacks of Group Decision Making from a Psyc.pdf}
}

@article{johnsonGENDERROLECOMPOSITIONROLE1989,
  title = {{{GENDER-ROLE COMPOSITION AND ROLE ENTRAPMENT IN DECISION-MAKING GROUPS}}},
  author = {JOHNSON, RICHARD A. and SCHULMAN, GARY I.},
  year = {1989},
  month = sep,
  journal = {Gender \& Society},
  volume = {3},
  number = {3},
  pages = {355--372},
  publisher = {SAGE Publications Inc},
  issn = {0891-2432},
  doi = {10.1177/089124389003003005},
  urldate = {2024-07-19},
  abstract = {This article reports the effects of gender proportions on the task activity and socioemotional participation of men and women in 85 four-person, decision-making groups. The analysis focuses on the changes in the highest and lowest levels of male and female participation. Results show that role entrapment occurs for both male and female numerical minorities. Role entrapment is a function of conformity to gender expectations rather than gender-role exaggeration, and is not limited to the extreme of the token. Both men and women were affected by decreased numbers, but the effects were to the advantage of the men and to the disadvantage of the women.},
  langid = {english}
}

@inproceedings{joUnderstandingBenefitsChallenges2023,
  title = {Understanding the {{Benefits}} and {{Challenges}} of {{Deploying Conversational AI Leveraging Large Language Models}} for {{Public Health Intervention}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Jo, Eunkyung and Epstein, Daniel A. and Jung, Hyunhoon and Kim, Young-Ho},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--16},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581503},
  urldate = {2024-07-17},
  abstract = {Recent large language models (LLMs) have advanced the quality of open-ended conversations with chatbots. Although LLM-driven chatbots have the potential to support public health interventions by monitoring populations at scale through empathetic interactions, their use in real-world settings is underexplored. We thus examine the case of CareCall, an open-domain chatbot that aims to support socially isolated individuals via check-up phone calls and monitoring by teleoperators. Through focus group observations and interviews with 34 people from three stakeholder groups, including the users, the teleoperators, and the developers, we found CareCall offered a holistic understanding of each individual while offloading the public health workload and helped mitigate loneliness and emotional burdens. However, our findings highlight that traits of LLM-driven chatbots led to challenges in supporting public and personal health needs. We discuss considerations of designing and deploying LLM-driven chatbots for public health intervention, including tensions among stakeholders around system expectations.},
  isbn = {978-1-4503-9421-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VLAYLRCV/Jo et al. - 2023 - Understanding the Benefits and Challenges of Deplo.pdf}
}

@inproceedings{jungRobotsGroupsTeams2017,
  title = {Robots in {{Groups}} and {{Teams}}},
  booktitle = {Companion of the 2017 {{ACM Conference}} on {{Computer Supported Cooperative Work}} and {{Social Computing}}},
  author = {Jung, Malte F. and {\v S}abanovi{\'c}, Selma and Eyssel, Friederike and Fraune, Marlena},
  year = {2017},
  month = feb,
  series = {{{CSCW}} '17 {{Companion}}},
  pages = {401--407},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3022198.3022659},
  urldate = {2024-07-19},
  abstract = {Over the last decade, the idea that robots could become an integral part of groups and teams has developed from a promising vision into a reality. Robots are increasingly designed to interact with groups and teams of people, yet most human-robot interaction research still focuses on a single humans interacting with a single robot. The goal for the workshop is therefore to advance research in computer supported cooperative work (CSCW) and human robot interaction (HRI) by raising awareness for the social and technical challenges that surround the placement of robots within work-groups and teams. The workshop will be organized around three central questions: (1) How do robots shape the dynamics of groups and teams in existing settings? (2) How does a robot's behavior shape how humans interact with each other in dyads and in larger groups and teams? (3) How can robots improve the performance of work groups and teams by acting on social processes? These core issues will be covered across a set of presentations that initiate in- depth discussions around each question to improve the quality of and support the growth of research in the CSCW community that focuses on the intersection of robots, groups, and teams.},
  isbn = {978-1-4503-4688-7}
}

@inproceedings{jungUsingRobotsModerate2015,
  title = {Using {{Robots}} to {{Moderate Team Conflict}}: {{The Case}} of {{Repairing Violations}}},
  shorttitle = {Using {{Robots}} to {{Moderate Team Conflict}}},
  booktitle = {Proceedings of the {{Tenth Annual ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Jung, Malte F. and Martelaro, Nikolas and Hinds, Pamela J.},
  year = {2015},
  month = mar,
  series = {{{HRI}} '15},
  pages = {229--236},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2696454.2696460},
  urldate = {2024-07-19},
  abstract = {We explore whether robots can positively influence conflict dynamics by repairing interpersonal violations that occur during a team-based problem-solving task. In a 2 (negative trigger: task- directed vs. personal attack) x 2 (repair: yes vs. no) between- subjects experiment (N = 57 teams, 114 participants), we studied the effect of a robot intervention on affect, perceptions of conflict, perceptions of team members' contributions, and team performance during a problem-solving task. Specifically, the robot either intervened by repairing a task-directed or personal attack by a confederate or did not intervene. Contrary to our expectations, we found that the robot's repair interventions increased the groups' awareness of conflict after the occurrence of a personal attack thereby acting against the groups' tendency to suppress the conflict. These findings suggest that repair heightened awareness of a normative violation. Overall, our results provide support for the idea that robots can aid team functioning by regulating core team processes such as conflict.},
  isbn = {978-1-4503-2883-8}
}

@incollection{juPowerHumanRobot2016,
  title = {Power in {{Human Robot Interactions}}},
  booktitle = {What {{Social Robots Can}} and {{Should Do}}},
  author = {Ju, Wendy},
  year = {2016},
  pages = {13--14},
  publisher = {IOS Press},
  doi = {10.3233/978-1-61499-708-5-13},
  urldate = {2024-07-18}
}

@inproceedings{kadomaRoleInclusionControl2024,
  title = {The {{Role}} of {{Inclusion}}, {{Control}}, and {{Ownership}} in {{Workplace AI-Mediated Communication}}},
  booktitle = {Proceedings of the {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Kadoma, Kowe and Aubin Le Quere, Marianne and Fu, Xiyu Jenny and Munsch, Christin and Metaxa, Dana{\"e} and Naaman, Mor},
  year = {2024},
  month = may,
  series = {{{CHI}} '24},
  pages = {1--10},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3613904.3642650},
  urldate = {2024-07-21},
  abstract = {Given large language models' (LLMs) increasing integration into workplace software, it is important to examine how biases in the models may impact workers. For example, stylistic biases in the language suggested by LLMs may cause feelings of alienation and result in increased labor for individuals or groups whose style does not match. We examine how such writer-style bias impacts inclusion, control, and ownership over the work when co-writing with LLMs. In an online experiment, participants wrote hypothetical job promotion requests using either hesitant or self-assured auto-complete suggestions from an LLM and reported their subsequent perceptions. We found that the style of the AI model did not impact perceived inclusion. However, individuals with higher perceived inclusion did perceive greater agency and ownership, an effect more strongly impacting participants of minoritized genders. Feelings of inclusion mitigated a loss of control and agency when accepting more AI suggestions.},
  isbn = {9798400703300},
  keywords = {,notion},
  annotation = {TLDR: It was found that the style of the AI model did not impact perceived inclusion, but individuals with higher perceived inclusion did perceive greater agency and ownership, an effect more strongly impacting participants of minoritized genders.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/LXCK45VF/Kadoma et al. - 2024 - The Role of Inclusion, Control, and Ownership in W.pdf}
}

@article{kamedaPsychologicalEntrapmentGroup1993,
  title = {Psychological Entrapment in Group Decision Making: {{An}} Assigned Decision Rule and a Groupthink Phenomenon},
  shorttitle = {Psychological Entrapment in Group Decision Making},
  author = {Kameda, Tatsuya and Sugimori, Shinkichi},
  year = {1993},
  journal = {Journal of Personality and Social Psychology},
  volume = {65},
  number = {2},
  pages = {282--292},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1315},
  doi = {10.1037/0022-3514.65.2.282},
  abstract = {Addressed interpersonal factors affecting group entrapment and also attempted to delineate a conceptual link between collective entrapment and I. L. Janis's (1972, 1982) notion of groupthink. Two experiments were conducted in which 3-person groups were assigned either majority or unanimity rule as an official consensus requirement for their initial decision. It was expected and confirmed that groups whose initial decision processes were guided by unanimity rule were entrapped more often to the chosen course of action than were groups with majority rule. The results also suggested that homogeneity of members' opinions at the outset of interaction and group's rationalization norm were responsible for the observed difference. Discussion is focused on the implications of these findings for administrative decision contexts and their conceptual link of the notion of groupthink. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{kanterEffectsProportionsGroup1977,
  title = {Some {{Effects}} of {{Proportions}} on {{Group Life}}: {{Skewed Sex Ratios}} and {{Responses}} to {{Token Women}}},
  shorttitle = {Some {{Effects}} of {{Proportions}} on {{Group Life}}},
  author = {Kanter, Rosabeth Moss},
  year = {1977},
  month = mar,
  journal = {American Journal of Sociology},
  volume = {82},
  number = {5},
  pages = {965--990},
  publisher = {The University of Chicago Press},
  issn = {0002-9602},
  doi = {10.1086/226425},
  urldate = {2024-07-19},
  abstract = {Proportions, that is, relative numbers of socially and culturally different people in a group, are seen as critical in shaping interaction dinamics, and four group types are identified in the basis of varying proportional compositions. "Skewed" groups contain a large preponderance of one type (the numerical "dominants") over another (the rare "tokens"). A framework is developed for conceptualizing the processes that occur between dominants and tokens. Three perceptual phenomena are associated with tokens: visibility (tokens capture a disproportionate awareness share), polarization (differences between tokens and dominants are exaggerated), and assimilation (tokens' attributes are distorted to fit preexisting generalizations about their social type). Visibility generates performance pressures; polarization leads dominants to heighten their group boundaries; and assimilation leads to the tokens' role entrapment. Illustrations are drawn from a field study in a large industrial corporation. Concepts are extended to tokens of all kinds, and research issues are identified.}
}

@book{kanterMenWomenCorporation2008,
  title = {Men and {{Women}} of the {{Corporation}}: {{New Edition}}},
  shorttitle = {Men and {{Women}} of the {{Corporation}}},
  author = {Kanter, Rosabeth Moss},
  year = {2008},
  month = aug,
  publisher = {Basic Books},
  abstract = {In this landmark work on corporate power, especially as it relates to women, Rosabeth Moss Kanter, the distinguished Harvard management thinker and consultant, shows how the careers and self-images of the managers, professionals, and executives, and also those of the secretaries, wives of managers, and women looking for a way up, are determined by the distribution of power and powerlessness within the corporation. This new edition of her award-winning book has a major new afterward in which the author reviews and analyzes how attitudes and practices within the corporate power structure have changed in the 1990s.},
  isbn = {978-0-7867-2384-3},
  langid = {english}
}

@book{keirnsIntroductionSociology2e2016,
  title = {Introduction to {{Sociology}} 2e},
  author = {Keirns, Nathan J. and Griffiths, Heather and Strayer, Eric and {Cody-Rydzewski}, Susan and Scaramuzzo, Gail and Vyain, Sally and Sadler, Tommy and Bry, Jeff D. and Jones, Faye},
  year = {2016},
  publisher = {OpenStax College, Rice University},
  abstract = {"Introduction to Sociology 2e adheres to the scope and sequence of a typical, one-semester introductory sociology course. It offers comprehensive coverage of core concepts, foundational scholars, and emerging theories, which are supported by a wealth of engaging learning materials. The textbook presents detailed section reviews with rich questions, discussions that help students apply their knowledge, and features that draw learners into the discipline in meaningful ways. The second edition retains the book's conceptual organization, aligning to most courses, and has been significantly updated to reflect the latest research and provide examples most relevant to today's students. In order to help instructors transition to the revised version, the 2e changes are described within the preface."--Website of text.},
  googlebooks = {KJtXrgEACAAJ},
  isbn = {978-1-938168-41-3},
  langid = {english}
}

@book{kellermanPoliticalLeadershipSource1986,
  title = {Political {{Leadership}}: {{A Source Book}}},
  shorttitle = {Political {{Leadership}}},
  editor = {Kellerman, Barbara},
  year = {1986},
  month = sep,
  eprint = {10.2307/jj.12381759},
  eprinttype = {jstor},
  publisher = {University of Pittsburgh Press},
  doi = {10.2307/jj.12381759},
  urldate = {2024-07-18},
  isbn = {978-0-8229-7434-5 978-0-8229-3534-6},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/9TGECNXM/Kellerman - 1986 - Political Leadership A Source Book.pdf}
}

@book{kellermanPoliticalLeadershipSource1986a,
  title = {Political {{Leadership}}: {{A Source Book}}},
  shorttitle = {Political {{Leadership}}},
  editor = {Kellerman, Barbara},
  year = {1986},
  month = sep,
  eprint = {10.2307/jj.12381759},
  eprinttype = {jstor},
  publisher = {University of Pittsburgh Press},
  doi = {10.2307/jj.12381759},
  urldate = {2024-08-12},
  isbn = {978-0-8229-7434-5 978-0-8229-3534-6},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/ZF238RHD/Kellerman - 1986 - Political Leadership A Source Book.pdf}
}

@article{kelmanComplianceIdentificationInternalization1958,
  title = {Compliance, Identification, and Internalization Three Processes of Attitude Change},
  author = {Kelman, Herbert C.},
  year = {1958},
  month = mar,
  journal = {Journal of Conflict Resolution},
  volume = {2},
  number = {1},
  pages = {51--60},
  publisher = {SAGE Publications Inc},
  issn = {0022-0027},
  doi = {10.1177/002200275800200106},
  urldate = {2024-07-18},
  langid = {english}
}

@article{kelmanComplianceIdentificationInternalization1958a,
  title = {Compliance, Identification, and Internalization Three Processes of Attitude Change},
  author = {Kelman, Herbert C.},
  year = {1958},
  month = mar,
  journal = {Journal of Conflict Resolution},
  volume = {2},
  number = {1},
  pages = {51--60},
  publisher = {SAGE Publications Inc},
  issn = {0022-0027},
  doi = {10.1177/002200275800200106},
  urldate = {2024-08-09},
  langid = {english}
}

@incollection{kelmanFurtherThoughtsProcesses1974,
  title = {Further {{Thoughts}} on the {{Processes}} of {{Compliance}}, {{Identification}}, and {{Internalization}}},
  booktitle = {Social {{Power}} and {{Political Influence}}},
  author = {Kelman, Herbert C.},
  year = {1974},
  publisher = {Routledge},
  abstract = {In the early 1950s the author develops a theoretical framework for the analysis of social influence, based on a qualitative distinction between three processes},
  isbn = {978-1-315-12969-3}
}

@article{kelmanInterestsRelationshipsIdentities2006,
  title = {Interests, {{Relationships}}, {{Identities}}: {{Three Central Issues}} for {{Individuals}} and {{Groups}} in {{Negotiating Their Social Environment}}},
  shorttitle = {Interests, {{Relationships}}, {{Identities}}},
  author = {Kelman, Herbert C.},
  year = {2006},
  month = jan,
  journal = {Annual Review of Psychology},
  volume = {57},
  number = {Volume 57, 2006},
  pages = {1--26},
  publisher = {Annual Reviews},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev.psych.57.102904.190156},
  urldate = {2024-08-09},
  abstract = {This chapter begins with a summary of a model, developed half a century ago, that distinguishes three qualitatively different processes of social influence: compliance, identification, and internalization. The model, originally geared to and experimentally tested in the context of persuasive communication, was subsequently applied to influence in the context of long-term relationships, including psychotherapy, international exchanges, and the socialization of national/ethnic identity. It has been extended to analysis of the relationship of individuals to social systems. Individuals\&apos; rule, role, and value orientations to a system---conceptually linked to compliance, identification, and internalization---predict different reactions to their own violations of societal standards, different patterns of personal involvement in the political system, and differences in attitude toward authorities and readiness to obey. In a further extension of the model, three approaches to peacemaking in international or intergroup conflicts are identified---conflict settlement, conflict resolution, and reconciliation---which, respectively, focus on the accommodation of interests, relationships, and identities, and are conducive to changes at the level of compliance, identification, and internalization.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/CZ3RBLBR/Kelman - 2006 - Interests, Relationships, Identities Three Centra.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/JYSP4YCA/annurev.psych.57.102904.html}
}

@misc{khuranaWhyWhenLLMBased2024,
  title = {Why and {{When LLM-Based Assistants Can Go Wrong}}: {{Investigating}} the {{Effectiveness}} of {{Prompt-Based Interactions}} for {{Software Help-Seeking}}},
  shorttitle = {Why and {{When LLM-Based Assistants Can Go Wrong}}},
  author = {Khurana, Anjali and Subramonyam, Hari and Chilana, Parmit K.},
  year = {2024},
  month = feb,
  eprint = {2402.08030},
  primaryclass = {cs},
  doi = {10.1145/3640543.3645200},
  urldate = {2024-03-27},
  abstract = {Large Language Model (LLM) assistants, such as ChatGPT, have emerged as potential alternatives to search methods for helping users navigate complex, feature-rich software. LLMs use vast training data from domain-specific texts, software manuals, and code repositories to mimic human-like interactions, offering tailored assistance, including step-by-step instructions. In this work, we investigated LLM-generated software guidance through a within-subject experiment with 16 participants and follow-up interviews. We compared a baseline LLM assistant with an LLM optimized for particular software contexts, SoftAIBot, which also offered guidelines for constructing appropriate prompts. We assessed task completion, perceived accuracy, relevance, and trust. Surprisingly, although SoftAIBot outperformed the baseline LLM, our results revealed no significant difference in LLM usage and user perceptions with or without prompt guidelines and the integration of domain context. Most users struggled to understand how the prompt's text related to the LLM's responses and often followed the LLM's suggestions verbatim, even if they were incorrect. This resulted in difficulties when using the LLM's advice for software tasks, leading to low task completion rates. Our detailed analysis also revealed that users remained unaware of inaccuracies in the LLM's responses, indicating a gap between their lack of software expertise and their ability to evaluate the LLM's assistance. With the growing push for designing domain-specific LLM assistants, we emphasize the importance of incorporating explainable, context-aware cues into LLMs to help users understand prompt-based interactions, identify biases, and maximize the utility of LLM assistants.},
  archiveprefix = {arXiv},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/BUH8DE5V/Khurana 등 - 2024 - Why and When LLM-Based Assistants Can Go Wrong In.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/6XTE2VTW/2402.html}
}

@article{kimAIFriendAssistant2021,
  title = {{{AI}} as a Friend or Assistant: {{The}} Mediating Role of Perceived Usefulness in Social {{AI}} vs. Functional {{AI}}},
  shorttitle = {{{AI}} as a Friend or Assistant},
  author = {Kim, Jihyun and Merrill Jr., Kelly and Collins, Chad},
  year = {2021},
  month = nov,
  journal = {Telematics and Informatics},
  volume = {64},
  pages = {101694},
  issn = {0736-5853},
  doi = {10.1016/j.tele.2021.101694},
  urldate = {2024-07-28},
  abstract = {Advents of new technology have transformed how we currently view and use artificial intelligence (AI). Originally, AI was first developed to assist humans to complete tasks, but AI now takes on more social roles, such as functioning as a companion. However, little is known about how individuals view these different types of AI. Thus, the present study conducted an online experiment to explore people's perceptions about social AI vs. functional AI. Primary results suggest that individuals have more positive attitudes toward functional AI than social AI. Perceived usefulness of AI is found to have a mediation effect, suggesting functional AI, compared to social AI, leads to stronger perceived usefulness, which consequently fosters more positive attitudes and stronger perceived realism of AI. The results collectively suggest meaningful implications for human-AI communication and human--machine communication research.}
}

@inproceedings{kimBotBunchFacilitating2020,
  title = {Bot in the {{Bunch}}: {{Facilitating Group Chat Discussion}} by {{Improving Efficiency}} and {{Participation}} with a {{Chatbot}}},
  shorttitle = {Bot in the {{Bunch}}},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Kim, Soomin and Eun, Jinsu and Oh, Changhoon and Suh, Bongwon and Lee, Joonhwan},
  year = {2020},
  month = apr,
  series = {{{CHI}} '20},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3313831.3376785},
  urldate = {2024-04-02},
  abstract = {Although group chat discussions are prevalent in daily life, they have a number of limitations. When discussing in a group chat, reaching a consensus often takes time, members contribute unevenly to the discussion, and messages are unorganized. Hence, we aimed to explore the feasibility of a facilitator chatbot agent to improve group chat discussions. We conducted a needfinding survey to identify key features for a facilitator chatbot. We then implemented GroupfeedBot, a chatbot agent that could facilitate group discussions by managing the discussion time, encouraging members to participate evenly, and organizing members' opinions. To evaluate GroupfeedBot, we performed preliminary user studies that varied for diverse tasks and different group sizes. We found that the group with GroupfeedBot appeared to exhibit more diversity in opinions even though there were no differences in output quality and message quantity. On the other hand, GroupfeedBot promoted members' even participation and effective communication for the medium-sized group.},
  isbn = {978-1-4503-6708-0},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/Z7BACE7I/Kim 등 - 2020 - Bot in the Bunch Facilitating Group Chat Discussi.pdf}
}

@inproceedings{kimCoPerformingAgentDesign2019,
  title = {Co-{{Performing Agent}}: {{Design}} for {{Building User-Agent Partnership}} in {{Learning}} and {{Adaptive Services}}},
  shorttitle = {Co-{{Performing Agent}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Kim, Da-jung and Lim, Youn-kyung},
  year = {2019},
  month = may,
  series = {{{CHI}} '19},
  pages = {1--14},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3290605.3300714},
  urldate = {2024-03-26},
  abstract = {Intelligent agents have become prevalent in everyday IT products and services. To improve an agent's knowledge of a user and the quality of personalized service experience, it is important for the agent to cooperate with the user (e.g., asking users to provide their information and feedback). However, few works inform how to support such user-agent co-performance from a human-centered perspective. To fill this gap, we devised Co-Performing Agent, a Wizard-of-Oz-based research probe of an agent that cooperates with a user to learn by helping users to have a partnership mindset. By incorporating the probe, we conducted a two-month exploratory study, aiming to understand how users experience co-performing with their agent over time. Based on the findings, this paper presents the factors that affected users' co-performing behaviors and discusses design implications for supporting constructive co-performance and building a resilient user-agent partnership over time.},
  isbn = {978-1-4503-5970-2},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/4EXAA69K/Kim 그리고 Lim - 2019 - Co-Performing Agent Design for Building User-Agen.pdf}
}

@inproceedings{kimHowMuchDecision2024,
  title = {How {{Much Decision Power Should}} ({{A}}){{I Have}}?: {{Investigating Patients}}' {{Preferences Towards AI Autonomy}} in {{Healthcare Decision Making}}},
  shorttitle = {How {{Much Decision Power Should}} ({{A}}){{I Have}}?},
  booktitle = {Proceedings of the {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Kim, Dajung and Vegt, Niko and Visch, Valentijn and {Bos-De Vos}, Marina},
  year = {2024},
  month = may,
  series = {{{CHI}} '24},
  pages = {1--17},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3613904.3642883},
  urldate = {2024-05-29},
  abstract = {Despite the growing potential of artificial intelligence (AI) in improving clinical decision making, patients' perspectives on the use of AI for their care decision making are underexplored. In this paper, we investigate patients' preferences towards the autonomy of AI in assisting healthcare decision making. We conducted interviews and an online survey using an interactive narrative and speculative AI prototypes to elicit participants' preferred choices of using AI in a pregnancy care context. The analysis of the interviews and in-story responses reveals that patients' preferences for AI autonomy vary per person and context, and may change over time. This finding suggests the need for involving patients in defining and reassessing the appropriate level of AI assistance for healthcare decision making. Departing from these varied preferences for AI autonomy, we discuss implications for incorporating patient-centeredness in designing AI-powered healthcare decision making.},
  isbn = {9798400703300},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/NB56BTHK/Kim et al. - 2024 - How Much Decision Power Should (A)I Have Investi.pdf}
}

@article{kimModeratorChatbotDeliberative2021,
  title = {Moderator {{Chatbot}} for {{Deliberative Discussion}}: {{Effects}} of {{Discussion Structure}} and {{Discussant Facilitation}}},
  shorttitle = {Moderator {{Chatbot}} for {{Deliberative Discussion}}},
  author = {Kim, Soomin and Eun, Jinsu and Seering, Joseph and Lee, Joonhwan},
  year = {2021},
  month = apr,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {5},
  number = {CSCW1},
  pages = {87:1--87:26},
  doi = {10.1145/3449161},
  urldate = {2024-04-02},
  abstract = {Online chat functions as a discussion channel for diverse social issues. However, deliberative discussion and consensus-reaching can be difficult in online chats in part because of the lack of structure. To explore the feasibility of a conversational agent that enables deliberative discussion, we designed and developed DebateBot, a chatbot that structures discussion and encourages reticent participants to contribute. We conducted a 2 (discussion structure: unstructured vs. structured) {\texttimes} 2 (discussant facilitation: unfacilitated vs. facilitated) between-subjects experiment (N = 64, 12 groups). Our findings are as follows: (1) Structured discussion positively affects discussion quality by generating diverse opinions within a group and resulting in a high level of perceived deliberative quality. (2) Facilitation drives a high level of opinion alignment between group consensus and independent individual opinions, resulting in authentic consensus reaching. Facilitation also drives more even contribution and a higher level of task cohesion and communication fairness. Our results suggest that a chatbot agent could partially substitute for a human moderator in deliberative discussions.},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/WKEK9RQB/Kim 등 - 2021 - Moderator Chatbot for Deliberative Discussion Eff.pdf}
}

@article{kimModeratorChatbotDeliberative2021a,
  title = {Moderator {{Chatbot}} for {{Deliberative Discussion}}: {{Effects}} of {{Discussion Structure}} and {{Discussant Facilitation}}},
  shorttitle = {Moderator {{Chatbot}} for {{Deliberative Discussion}}},
  author = {Kim, Soomin and Eun, Jinsu and Seering, Joseph and Lee, Joonhwan},
  year = {2021},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  number = {CSCW1},
  pages = {87:1--87:26},
  doi = {10.1145/3449161},
  urldate = {2024-07-18},
  abstract = {Online chat functions as a discussion channel for diverse social issues. However, deliberative discussion and consensus-reaching can be difficult in online chats in part because of the lack of structure. To explore the feasibility of a conversational agent that enables deliberative discussion, we designed and developed DebateBot, a chatbot that structures discussion and encourages reticent participants to contribute. We conducted a 2 (discussion structure: unstructured vs. structured) {\texttimes} 2 (discussant facilitation: unfacilitated vs. facilitated) between-subjects experiment (N = 64, 12 groups). Our findings are as follows: (1) Structured discussion positively affects discussion quality by generating diverse opinions within a group and resulting in a high level of perceived deliberative quality. (2) Facilitation drives a high level of opinion alignment between group consensus and independent individual opinions, resulting in authentic consensus reaching. Facilitation also drives more even contribution and a higher level of task cohesion and communication fairness. Our results suggest that a chatbot agent could partially substitute for a human moderator in deliberative discussions.}
}

@article{kimWhenAlgorithmsErr2023,
  title = {When {{Algorithms Err}}: {{Differential Impact}} of {{Early}} vs. {{Late Errors}} on {{Users}}' {{Reliance}} on {{Algorithms}}},
  shorttitle = {When {{Algorithms Err}}},
  author = {Kim, Antino and Yang, Mochen and Zhang, Jingjing},
  year = {2023},
  month = mar,
  journal = {ACM Trans. Comput.-Hum. Interact.},
  volume = {30},
  number = {1},
  pages = {14:1--14:36},
  issn = {1073-0516},
  doi = {10.1145/3557889},
  urldate = {2024-07-18},
  abstract = {Errors are a natural part of predictive algorithms, but may discourage users from relying on algorithms. We conduct two experiments to demonstrate that reliance on a predictive algorithm following a substantial error is affected by (i) when the error occurs and (ii) how the algorithm is used in the decision-making process. We find that the impact of an error on reliance depends on whether the error occurs early (i.e., when users first start using the algorithm) or late (i.e., after users have used the algorithm for an extended period). While an early error results in substantial and persistent reliance reduction, a late error affects reliance only temporarily and to a lesser extent. However, when users have more control over how to use the algorithm's predictions, error timing ceases to have a significant impact. Our work advances the understanding of algorithm aversion and informs the practical design of algorithmic decision-making systems.}
}

@article{kleinPhilosophicalDimensionsAnonymity2003,
  title = {Philosophical Dimensions of Anonymity in Group Support Systems: {{Ethical}} Implications of Social Psychological Consequences},
  shorttitle = {Philosophical Dimensions of Anonymity in Group Support Systems},
  author = {Klein, Esther E and Clark, Chalmers C and Herskovitz, Paul J},
  year = {2003},
  month = may,
  journal = {Computers in Human Behavior},
  volume = {19},
  number = {3},
  pages = {355--382},
  issn = {0747-5632},
  doi = {10.1016/S0747-5632(02)00053-5},
  urldate = {2024-06-23},
  abstract = {With the aim of reducing the inefficiencies of group work, group support systems (GSS), also known as groupware, have been designed to facilitate interaction and foster collaboration and decision making within such groups. A key feature available in GSS is anonymous interaction of group members. This paper examines the ethical dimensions of two social psychological consequences of this anonymity that result from the lack of social cues---the absence of gender cues, with the attendant equalization of male--female participation, and deindividuation, with the attendant weakening of social norms, reduction of inner restraints, and loss of evaluation apprehension. Specifically, this paper suggests that the absence of gender cues within GSS-supported decision-making groups promotes the twin values of justice and autonomy, whereas deindividuation results in a ``Ring of Gyges scenario'' (K. A. Wallace, 1999), wherein anonymity confers immunity against the consequences of bad and disruptive behavior and thereby encourages such behavior. The paper considers the problem of miscommunication---which offsets the advantage of gender neutrality and which stems from the failure of text-based media to convey verbal nuances and emotional content---and provides practical solutions. Moreover, the paper proposes the adoption of Wallace's electronic ``tagging'' solution of traceable anonymity in order to avert, or reduce the incidence of, Ring of Gyges scenarios within GSS-supported groups in situations involving intentional or grossly negligent misconduct but not in cases of ordinary negligence. Additionally, the paper discusses liberty-limiting principles as justifications for the restrictions on free speech that are imposed by tagging.}
}

@article{kleinTenChallengesMaking2004,
  title = {Ten {{Challenges}} for {{Making Automation}} a "{{Team Player}}" in {{Joint Human-Agent Activity}}},
  author = {Klein, Gary and Woods, David D. and Bradshaw, Jeffrey M. and Hoffman, Robert R. and Feltovich, Paul J.},
  year = {2004},
  month = nov,
  journal = {IEEE Intelligent Systems},
  volume = {19},
  number = {6},
  pages = {91--95},
  issn = {1541-1672},
  doi = {10.1109/MIS.2004.74},
  urldate = {2024-07-19},
  abstract = {The authors propose 10 challenges for making automation components into effective "team players" when they interact with people in significant ways. Their analysis is based on some of the principles of human-centered computing that they have developed individually and jointly over the years, and is adapted from a more comprehensive examination of common ground and coordination.}
}

@article{klingbeilTrustRelianceAI2024,
  title = {Trust and Reliance on {{AI}} --- {{An}} Experimental Study on the Extent and Costs of Overreliance on {{AI}}},
  author = {Klingbeil, Artur and Gr{\"u}tzner, Cassandra and Schreck, Philipp},
  year = {2024},
  month = jun,
  journal = {Computers in Human Behavior},
  pages = {108352},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2024.108352},
  urldate = {2024-07-18},
  abstract = {Decision-making is undergoing rapid changes due to the introduction of artificial intelligence (AI), as AI recommender systems can help mitigate human flaws and increase decision accuracy and efficiency. However, AI can also commit errors or suffer from algorithmic bias. Hence, blind trust in technologies carries risks, as users may follow detrimental advice resulting in undesired consequences. Building upon research on algorithm appreciation and trust in AI, the current study investigates whether users who receive AI advice in an uncertain situation overrely on this advice --- to their own detriment and that of other parties. In a domain-independent, incentivized, and interactive behavioral experiment, we find that the mere knowledge of advice being generated by an AI causes people to overrely on it, that is, to follow AI advice even when it contradicts available contextual information as well as their own assessment. Frequently, this overreliance leads not only to inefficient outcomes for the advisee, but also to undesired effects regarding third parties. The results call into question how AI is being used in assisted decision making, emphasizing the importance of AI literacy and effective trust calibration for productive deployment of such systems.}
}

@book{kruglanskiSocialPsychologyHandbook2007,
  title = {Social {{Psychology}}: {{Handbook}} of {{Basic Principles}}},
  shorttitle = {Social {{Psychology}}},
  author = {Kruglanski, Arie W. and Higgins, Edward Tory},
  year = {2007},
  month = apr,
  publisher = {Guilford Publications},
  abstract = {Now in a completely revised and expanded second edition, this authoritative handbook reviews the breadth of current knowledge on the psychological processes that underlie social behavior. Leading investigators identify core principles that have emerged from the study of biological systems, social cognition, goals and strivings, interpersonal interactions, and group and cultural dynamics. State-of-the-science theories, methods, and findings are explained, and important directions for future research are highlighted. More than an update, this edition is virtually a new book. Many more chapters are included, and significant advances in social cognitive neuroscience, motivational psychology, and other areas are incorporated throughout. A new section addresses implications for applied domains, such as clinical psychology, health, and consumer behavior.},
  googlebooks = {WUuGS3gr9W4C},
  isbn = {978-1-57230-918-0},
  langid = {english}
}

@article{kurzbanCanRaceBe2001,
  title = {Can Race Be Erased? {{Coalitional}} Computation and Social Categorization},
  shorttitle = {Can Race Be Erased?},
  author = {Kurzban, Robert and Tooby, John and Cosmides, Leda},
  year = {2001},
  month = dec,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {98},
  number = {26},
  pages = {15387--15392},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.251541498},
  urldate = {2024-07-19},
  abstract = {Previous studies have established that people encode the race of each individual they encounter, and do so via computational processes that appear to be both automatic and mandatory. If true, this conclusion would be important, because categorizing others by their race is a precondition for treating them differently according to race. Here we report experiments, using unobtrusive measures, showing that categorizing individuals by race is not inevitable, and supporting an alternative hypothesis: that encoding by race is instead a reversible byproduct of cognitive machinery that evolved to detect coalitional alliances. The results show that subjects encode coalitional affiliations as a normal part of person representation. More importantly, when cues of coalitional affiliation no longer track or correspond to race, subjects markedly reduce the extent to which they categorize others by race, and indeed may cease doing so entirely. Despite a lifetime's experience of race as a predictor of social alliance, less than 4 min of exposure to an alternate social world was enough to deflate the tendency to categorize by race. These results suggest that racism may be a volatile and eradicable construct that persists only so long as it is actively maintained through being linked to parallel systems of social alliance.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/BZFEHN39/Kurzban et al. - 2001 - Can race be erased Coalitional computation and so.pdf}
}

@article{kwakCentralLimitTheorem2017,
  title = {Central Limit Theorem: The Cornerstone of Modern Statistics},
  shorttitle = {Central Limit Theorem},
  author = {Kwak, Sang Gyu and Kim, Jong Hae},
  year = {2017},
  month = feb,
  journal = {Korean Journal of Anesthesiology},
  volume = {70},
  number = {2},
  pages = {144--156},
  publisher = {The Korean Society of Anesthesiologists},
  doi = {10.4097/kjae.2017.70.2.144},
  urldate = {2024-07-19},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/FTY8YJD8/Kwak and Kim - 2017 - Central limit theorem the cornerstone of modern s.pdf}
}

@article{kwiekGenderbasedHomophilyResearch2021,
  title = {Gender-Based Homophily in Research: {{A}} Large-Scale Study of Man-Woman Collaboration},
  shorttitle = {Gender-Based Homophily in Research},
  author = {Kwiek, Marek and Roszka, Wojciech},
  year = {2021},
  month = aug,
  journal = {Journal of Informetrics},
  volume = {15},
  number = {3},
  pages = {101171},
  issn = {1751-1577},
  doi = {10.1016/j.joi.2021.101171},
  urldate = {2024-07-19},
  abstract = {We examined the male-female collaboration practices of all internationally visible Polish university professors (N~=~25,463) based on their Scopus-indexed publications from 2009--2018 (158,743 journal articles). We merged a national registry of 99,935 scientists (with full administrative and biographical data) with the Scopus publication database, using probabilistic and deterministic record linkage. Our unique biographical, administrative, publication, and citation database (``The Polish Science Observatory'') included all professors with at least a doctoral degree employed in 85 research-involved universities. We determined what we term an ``individual publication portfolio'' for every professor, and we examined the respective impacts of biological age, academic position, academic discipline, average journal prestige, and type of institution on the same-sex collaboration ratio. The gender homophily principle (publishing predominantly with scientists of the same sex) was found to apply to male scientists---but not to females. The majority of male scientists collaborate solely with males; most female scientists, in contrast, do not collaborate with females at all. Across all age groups studied, all-female collaboration is marginal, while all-male collaboration is pervasive. Gender homophily in research-intensive institutions proved stronger for males than for females. Finally, we used a multi-dimensional fractional logit regression model to estimate the impact of gender and other individual-level and institutional-level independent variables on gender homophily in research collaboration.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/9UN2U8FN/Kwiek and Roszka - 2021 - Gender-based homophily in research A large-scale .pdf}
}

@article{kwonStudyEffectNature2018,
  title = {{A Study on the Effect of the Nature of the Issues and the Perceived Climate of Opinion on the Willingness to Express}},
  author = {Kwon, Hyoknam},
  year = {2018},
  month = oct,
  journal = {Journal of Social Science},
  volume = {29},
  number = {4},
  pages = {61--82},
  issn = {1976-2984},
  doi = {10.16881/jss.2018.10.29.4.61},
  urldate = {2024-07-10},
  langid = {korean},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/SA8H6ZV5/Kwon - 2018 - A Study on the Effect of the Nature of the Issues .pdf}
}

@inproceedings{laiHumanAICollaborationConditional2022,
  title = {Human-{{AI Collaboration}} via {{Conditional Delegation}}: {{A Case Study}} of {{Content Moderation}}},
  shorttitle = {Human-{{AI Collaboration}} via {{Conditional Delegation}}},
  booktitle = {Proceedings of the 2022 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lai, Vivian and Carton, Samuel and Bhatnagar, Rajat and Liao, Q. Vera and Zhang, Yunfeng and Tan, Chenhao},
  year = {2022},
  month = apr,
  series = {{{CHI}} '22},
  pages = {1--18},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3491102.3501999},
  urldate = {2024-07-17},
  abstract = {Despite impressive performance in many benchmark datasets, AI models can still make mistakes, especially among out-of-distribution examples. It remains an open question how such imperfect models can be used effectively in collaboration with humans. Prior work has focused on AI assistance that helps people make individual high-stakes decisions, which is not scalable for a large amount of relatively low-stakes decisions, e.g., moderating social media comments. Instead, we propose conditional delegation as an alternative paradigm for human-AI collaboration where humans create rules to indicate trustworthy regions of a model. Using content moderation as a testbed, we develop novel interfaces to assist humans in creating conditional delegation rules and conduct a randomized experiment with two datasets to simulate in-distribution and out-of-distribution scenarios. Our study demonstrates the promise of conditional delegation in improving model performance and provides insights into design for this novel paradigm, including the effect of AI explanations.},
  isbn = {978-1-4503-9157-3},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/PPMLZ4SN/Lai et al. - 2022 - Human-AI Collaboration via Conditional Delegation.pdf}
}

@misc{laiScienceHumanAIDecision2021,
  title = {Towards a {{Science}} of {{Human-AI Decision Making}}: {{A Survey}} of {{Empirical Studies}}},
  shorttitle = {Towards a {{Science}} of {{Human-AI Decision Making}}},
  author = {Lai, Vivian and Chen, Chacha and Liao, Q. Vera and {Smith-Renner}, Alison and Tan, Chenhao},
  year = {2021},
  month = dec,
  journal = {arXiv.org},
  urldate = {2024-07-18},
  abstract = {As AI systems demonstrate increasingly strong predictive performance, their adoption has grown in numerous domains. However, in high-stakes domains such as criminal justice and healthcare, full automation is often not desirable due to safety, ethical, and legal concerns, yet fully manual approaches can be inaccurate and time consuming. As a result, there is growing interest in the research community to augment human decision making with AI assistance. Besides developing AI technologies for this purpose, the emerging field of human-AI decision making must embrace empirical approaches to form a foundational understanding of how humans interact and work with AI to make decisions. To invite and help structure research efforts towards a science of understanding and improving human-AI decision making, we survey recent literature of empirical human-subject studies on this topic. We summarize the study design choices made in over 100 papers in three important aspects: (1) decision tasks, (2) AI models and AI assistance elements, and (3) evaluation metrics. For each aspect, we summarize current trends, discuss gaps in current practices of the field, and make a list of recommendations for future research. Our survey highlights the need to develop common frameworks to account for the design and research spaces of human-AI decision making, so that researchers can make rigorous choices in study design, and the research community can build on each other's work and produce generalizable scientific knowledge. We also hope this survey will serve as a bridge for HCI and AI communities to work together to mutually shape the empirical science and computational technologies for human-AI decision making.},
  howpublished = {https://arxiv.org/abs/2112.11471v1},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/5LMFPRRH/Lai et al. - 2021 - Towards a Science of Human-AI Decision Making A S.pdf}
}

@inproceedings{laiScienceHumanAIDecision2023,
  title = {Towards a {{Science}} of {{Human-AI Decision Making}}: {{An Overview}} of {{Design Space}} in {{Empirical Human-Subject Studies}}},
  shorttitle = {Towards a {{Science}} of {{Human-AI Decision Making}}},
  booktitle = {Proceedings of the 2023 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Lai, Vivian and Chen, Chacha and {Smith-Renner}, Alison and Liao, Q. Vera and Tan, Chenhao},
  year = {2023},
  month = jun,
  series = {{{FAccT}} '23},
  pages = {1369--1385},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3593013.3594087},
  urldate = {2024-01-16},
  abstract = {AI systems are adopted in numerous domains due to their increasingly strong predictive performance. However, in high-stakes domains such as criminal justice and healthcare, full automation is often not desirable due to safety, ethical, and legal concerns, yet fully manual approaches can be inaccurate and time-consuming. As a result, there is growing interest in the research community to augment human decision making with AI assistance. Besides developing AI technologies for this purpose, the emerging field of human-AI decision making must embrace empirical approaches to form a foundational understanding of how humans interact and work with AI to make decisions. To invite and help structure research efforts towards a science of understanding and improving human-AI decision making, we survey recent literature of empirical human-subject studies on this topic. We summarize the study design choices made in over 100 papers in three important aspects: (1) decision tasks, (2) AI assistance elements, and (3) evaluation metrics. For each aspect, we summarize current trends, discuss gaps in current practices of the field, and make a list of recommendations for future research. Our work highlights the need to develop common frameworks to account for the design and research spaces of human-AI decision making, so that researchers can make rigorous choices in study design, and the research community can build on each other's work and produce generalizable scientific knowledge. We also hope this work will serve as a bridge for HCI and AI communities to work together to mutually shape the empirical science and computational technologies for human-AI decision making.},
  isbn = {9798400701924},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/DTXWX29K/Lai et al. - 2023 - Towards a Science of Human-AI Decision Making An .pdf}
}

@inproceedings{laiScienceHumanAIDecision2023a,
  title = {Towards a {{Science}} of {{Human-AI Decision Making}}: {{An Overview}} of {{Design Space}} in {{Empirical Human-Subject Studies}}},
  shorttitle = {Towards a {{Science}} of {{Human-AI Decision Making}}},
  booktitle = {Proceedings of the 2023 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Lai, Vivian and Chen, Chacha and {Smith-Renner}, Alison and Liao, Q. Vera and Tan, Chenhao},
  year = {2023},
  month = jun,
  series = {{{FAccT}} '23},
  pages = {1369--1385},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3593013.3594087},
  urldate = {2024-07-19},
  abstract = {AI systems are adopted in numerous domains due to their increasingly strong predictive performance. However, in high-stakes domains such as criminal justice and healthcare, full automation is often not desirable due to safety, ethical, and legal concerns, yet fully manual approaches can be inaccurate and time-consuming. As a result, there is growing interest in the research community to augment human decision making with AI assistance. Besides developing AI technologies for this purpose, the emerging field of human-AI decision making must embrace empirical approaches to form a foundational understanding of how humans interact and work with AI to make decisions. To invite and help structure research efforts towards a science of understanding and improving human-AI decision making, we survey recent literature of empirical human-subject studies on this topic. We summarize the study design choices made in over 100 papers in three important aspects: (1) decision tasks, (2) AI assistance elements, and (3) evaluation metrics. For each aspect, we summarize current trends, discuss gaps in current practices of the field, and make a list of recommendations for future research. Our work highlights the need to develop common frameworks to account for the design and research spaces of human-AI decision making, so that researchers can make rigorous choices in study design, and the research community can build on each other's work and produce generalizable scientific knowledge. We also hope this work will serve as a bridge for HCI and AI communities to work together to mutually shape the empirical science and computational technologies for human-AI decision making.},
  isbn = {9798400701924},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/UPKD8L8Y/Lai et al. - 2023 - Towards a Science of Human-AI Decision Making An .pdf}
}

@inproceedings{laiWhyChicagoDeceptive2020,
  title = {"{{Why}} Is '{{Chicago}}' Deceptive?" {{Towards Building Model-Driven Tutorials}} for {{Humans}}},
  shorttitle = {"{{Why}} Is '{{Chicago}}' Deceptive?},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lai, Vivian and Liu, Han and Tan, Chenhao},
  year = {2020},
  month = apr,
  series = {{{CHI}} '20},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3313831.3376873},
  urldate = {2024-07-17},
  abstract = {To support human decision making with machine learning models, we often need to elucidate patterns embedded in the models that are unsalient, unknown, or counterintuitive to humans. While existing approaches focus on explaining machine predictions with real-time assistance, we explore model-driven tutorials to help humans understand these patterns in a train- ing phase. We consider both tutorials with guidelines from scientific papers, analogous to current practices of science communication, and automatically selected examples from training data with explanations. We use deceptive review detection as a testbed and conduct large-scale, randomized human-subject experiments to examine the effectiveness of such tutorials. We find that tutorials indeed improve human performance, with and without real-time assistance. In particular, although deep learning provides superior predictive performance than simple models, tutorials and explanations from simple models are more useful to humans. Our work suggests future directions for human-centered tutorials and explanations towards a synergy between humans and AI.},
  isbn = {978-1-4503-6708-0},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/ZY4S5NXQ/Lai et al. - 2020 - Why is 'Chicago' deceptive Towards Building Mod.pdf}
}

@inproceedings{lakhmaniProposedApproachDetermining2016,
  title = {A {{Proposed Approach}} for {{Determining}} the {{Influence}} of {{Multimodal Robot-of-Human Transparency Information}} on {{Human-Agent Teams}}},
  booktitle = {Proceedings, {{Part II}}, of the 10th {{International Conference}} on {{Foundations}} of {{Augmented Cognition}}: {{Neuroergonomics}} and {{Operational Neuroscience}} - {{Volume}} 9744},
  author = {Lakhmani, Shan and Abich, Julian and Barber, Daniel and Chen, Jessie},
  year = {2016},
  month = jul,
  pages = {296--307},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-319-39952-2_29},
  urldate = {2024-07-19},
  abstract = {Autonomous agents, both software and robotic, are becoming increasingly common. They are being used to supplement human operators in accomplishing complex tasks, often acting as collaborators or teammates. Agents can be designed to keep their human operators 'in the loop' by reporting information concerning their internal decision making process. This transparency can be expressed in a number of ways, including the communication of the human and agent's respective responsibilities. Agents can communicate information supporting transparency to human operators using visual, auditory, or a combination of both modalities. Based on this information, we suggest an approach to exploring the utility of the teamwork model of transparency. We propose some considerations for future research into feedback supporting teamwork transparency, including multimodal communication methods, human-like feedback, and the use of multiple forms of automation transparency.},
  isbn = {978-3-319-39951-5}
}

@article{leaperBelongGenderPeer2015,
  title = {Do {{I Belong}}?: {{Gender}}, {{Peer Groups}}, and {{STEM Achievement}}},
  shorttitle = {Do {{I Belong}}?},
  author = {Leaper, Campbell},
  year = {2015},
  month = jun,
  journal = {International Journal of Gender, Science and Technology},
  volume = {7},
  number = {2},
  pages = {166--179},
  issn = {2040-0748},
  urldate = {2024-07-19},
  abstract = {Women's underrepresentation in many STEM fields is due to a combination of individual and sociocultural factors. Among these, the peer group is one potentially powerful force reviewed in this article. First, I describe key processes associated with group belonging. The social identities associated with group belonging can shape individuals' task and interpersonal values. Second, I consider how the values reinforced in many girls' and women's peer groups may conflict with their perceptions of STEM. In addition, girls and women may experience rejection and hostility from their male peers regarding STEM achievement. Conversely, when important peer groups value and support STEM, they may validate girls' and women's sense of belongingness in STEM fields. Next, I highlight some strategies for reducing peer sexism and foster STEM belonging. Finally, I close with some recommendations for future research.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/7YZ5WHXT/Leaper - 2015 - Do I Belong Gender, Peer Groups, and STEM Achiev.pdf}
}

@article{leeEffectsInfluenceAgents2005,
  title = {Effects of the {{Influence Agent}}'s {{Sex}} and {{Self-Confidence}} on {{Informational Social Influence}} in {{Computer-Mediated Communication}}:: {{Quantitative Versus Verbal Presentation}}},
  shorttitle = {Effects of the {{Influence Agent}}'s {{Sex}} and {{Self-Confidence}} on {{Informational Social Influence}} in {{Computer-Mediated Communication}}},
  author = {Lee, Eun-Ju},
  year = {2005},
  month = feb,
  journal = {Communication Research},
  volume = {32},
  number = {1},
  pages = {29--58},
  publisher = {SAGE Publications Inc},
  issn = {0093-6502},
  doi = {10.1177/0093650204271398},
  urldate = {2024-06-23},
  abstract = {Three experiments examined the effects of the influence agent's inferred sex and self-proclaimed competence on informational social influence in computermediated communication. In 2 (Participant Sex: Male vs. Female) 2 (Partner's Character:Male vs. Female) 2 (Partner's Self-Confidence: High vs. Low) mixed-design experiments, participants played a trivia game with an anonymous partner. When the partner's confidence was presented in quantitative form, its effect on conformity was more pronounced among men than among women (Experiment 1), whereas verbally expressed confidence induced stronger effects among women than among men (Experiment 2). In both experiments, where participants' own character mismatched their sex, partner's character did not affect conformity to partner's suggestions. By contrast, when participants' character correctly represented their sex (Experiment 3), partner's character, albeit arbitrarily assigned and thus not diagnostic of the person's sex, moderated conformity such that male-charactered partners elicited greater conformity than did female-charactered partners.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/H9XW6XZG/Lee - 2005 - Effects of the Influence Agent’s Sex and Self-Conf.pdf}
}

@article{leeSocialIdentityModel2008,
  title = {{Social Identity Model of Deindividuation Effects: Theoretical Implications and Future Directions}},
  shorttitle = {{Social Identity Model of Deindividuation Effects}},
  author = {Lee, Eun-Ju},
  year = {2008},
  month = jun,
  journal = {Communication Theories},
  volume = {4},
  number = {1},
  pages = {7--31},
  issn = {1738-7221},
  urldate = {2024-06-20},
  abstract = {The present paper introduces the Social Identity model of Deindividuation Effects (SIDE), focusing on its theoretical background as well as empirical research evidence supporting its key propositions. Specifically, SIDE model postulates that \ding{172} deindividuation refers to the shift of attention from one's personal to social self-identity, rather than a loss of self-awareness as traditional deindividuation theory posits, \ding{173} deindividuation does not necessarily lead to anti-normative behavior, but instead fosters group-oriented perceptions and behavior, such as conformity to group norms, when coupled with a shared group identity, and \ding{174} deindividuation effects are mediated by group identification. Limitations of the previous SIDE research and some suggestions for future research are discussed.},
  langid = {korean},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VFD7LB4Q/Lee - 2008 - Social Identity Model of Deindividuation Effects .pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/YEHL4XZ3/articleDetail.html}
}

@article{leeSocialIdentityModel2008a,
  title = {{Social Identity Model of Deindividuation Effects: Theoretical Implications and Future Directions}},
  shorttitle = {{Social Identity Model of Deindividuation Effects}},
  author = {Lee, Eun-ju},
  year = {2008},
  month = jun,
  journal = {Communication Theories},
  volume = {4},
  number = {1},
  pages = {7--31},
  issn = {1738-7221},
  urldate = {2024-08-12},
  abstract = {The present paper introduces the Social Identity model of Deindividuation Effects (SIDE), focusing on its theoretical background as well as empirical research evidence supporting its key propositions. Specifically, SIDE model postulates that \ding{172} deindividuation refers to the shift of attention from one's personal to social self-identity, rather than a loss of self-awareness as traditional deindividuation theory posits, \ding{173} deindividuation does not necessarily lead to anti-normative behavior, but instead fosters group-oriented perceptions and behavior, such as conformity to group norms, when coupled with a shared group identity, and \ding{174} deindividuation effects are mediated by group identification. Limitations of the previous SIDE research and some suggestions for future research are discussed.},
  langid = {korean},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/D7K37MKF/이은주 - 2008 - 탈개인화 효과에 관한 사회적 자아정체성 모델  이론적 함의와 향후 연구과제 이론적 함의.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/36RFJ7SL/articleDetail.html}
}

@article{leeTrustAutomationDesigning2004,
  title = {Trust in {{Automation}}: {{Designing}} for {{Appropriate Reliance}}},
  shorttitle = {Trust in {{Automation}}},
  author = {Lee, John D. and See, Katrina A.},
  year = {2004},
  month = mar,
  journal = {Human Factors},
  volume = {46},
  number = {1},
  pages = {50--80},
  publisher = {SAGE Publications Inc},
  issn = {0018-7208},
  doi = {10.1518/hfes.46.1.50_30392},
  urldate = {2024-07-19},
  abstract = {Automation is often problematic because people fail to rely upon it appropriately. Because people respond to technology socially, trust influences reliance on automation. In particular, trust guides reliance when complexity and unanticipated situations make a complete understanding of the automation impractical. This review considers trust from the organizational, sociological, interpersonal, psychological, and neurological perspectives. It considers how the context, automation characteristics, and cognitive processes affect the appropriateness of trust. The context in which the automation is used influences automation performance and provides a goal-oriented perspective to assess automation characteristics along a dimension of attributional abstraction. These characteristics can influence trust through analytic, analogical, and affective processes. The challenges of extrapolating the concept of trust in people to trust in automation are discussed. A conceptual model integrates research regarding trust in automation and describes the dynamics of trust, the role of context, and the influence of display characteristics. Actual or potential applications of this research include improved designs of systems that require people to manage imperfect automation.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/B2VEMWCF/Lee and See - 2004 - Trust in Automation Designing for Appropriate Rel.pdf}
}

@article{leeWhenAreStrong2008,
  title = {When {{Are Strong Arguments Stronger Than Weak Arguments}}?: {{Deindividuation Effects}} on {{Message Elaboration}} in {{Computer-Mediated Communication}}},
  shorttitle = {When {{Are Strong Arguments Stronger Than Weak Arguments}}?},
  author = {Lee, Eun-Ju},
  year = {2008},
  month = oct,
  journal = {Communication Research},
  volume = {35},
  number = {5},
  pages = {646--665},
  publisher = {SAGE Publications Inc},
  issn = {0093-6502},
  doi = {10.1177/0093650208321784},
  urldate = {2024-06-23},
  abstract = {The present experiment examined how the lack of individuating information affects message elaboration and conformity to group norms in text-based computer-mediated communication. Participants made decisions about choice dilemma scenarios and exchanged their arguments with three ostensible partners via computer. Consistent with the social identity model of deindividuation effects, those who had exchanged personal profiles with their partners prior to the discussion were better able to differentiate between strong and weak arguments and were more likely to make conformity decisions based on the message content than those who had not. On the other hand, those who had no identity cues were more likely to factor in group identification for their conformity decisions. Results suggest that less systematic message processing and greater reliance on normative considerations account for how deindividuation moderates the effects of argument strength on group conformity.},
  langid = {english},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/KNUBXZHP/Lee - 2008 - When Are Strong Arguments Stronger Than Weak Argum.pdf}
}

@article{leeWhenHowDoes2006,
  title = {When and {{How Does Depersonalization Increase Conformity}} to {{Group Norms}} in {{Computer-Mediated Communication}}?},
  author = {Lee, Eun-Ju},
  year = {2006},
  month = dec,
  journal = {Communication Research},
  volume = {33},
  number = {6},
  pages = {423--447},
  publisher = {SAGE Publications Inc},
  issn = {0093-6502},
  doi = {10.1177/0093650206293248},
  urldate = {2024-06-20},
  abstract = {The experiment reported herein examined how depersonalization, operationalized as the lack of individuating information, affects conformity to a group norm in anonymous computer-mediated communication. Participants made a decision about choice dilemmas and exchanged their decisions and supporting arguments with three ostensible partners via computer, who unanimously endorsed the position opposite of the participant's. As predicted, depersonalization led to a more extreme perception of the group norm, better recall of the interactants' arguments, and more positive evaluations of the interactants' arguments through group identification, albeit only for women. Moreover, depersonalization was more likely to facilitate conformity to group norms among those with higher need for public individuation and among women. A test of indirect effects showed that group identification and extremity of the perceived group norm mediated the effects of depersonalization on conformity.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/7V78W48L/Lee - 2006 - When and How Does Depersonalization Increase Confo.pdf}
}

@article{leeWhenHowDoes2006a,
  title = {When and {{How Does Depersonalization Increase Conformity}} to {{Group Norms}} in {{Computer-Mediated Communication}}?},
  author = {Lee, Eun-Ju},
  year = {2006},
  month = dec,
  journal = {Communication Research},
  volume = {33},
  number = {6},
  pages = {423--447},
  publisher = {SAGE Publications Inc},
  issn = {0093-6502},
  doi = {10.1177/0093650206293248},
  urldate = {2024-06-23},
  abstract = {The experiment reported herein examined how depersonalization, operationalized as the lack of individuating information, affects conformity to a group norm in anonymous computer-mediated communication. Participants made a decision about choice dilemmas and exchanged their decisions and supporting arguments with three ostensible partners via computer, who unanimously endorsed the position opposite of the participant's. As predicted, depersonalization led to a more extreme perception of the group norm, better recall of the interactants' arguments, and more positive evaluations of the interactants' arguments through group identification, albeit only for women. Moreover, depersonalization was more likely to facilitate conformity to group norms among those with higher need for public individuation and among women. A test of indirect effects showed that group identification and extremity of the perceived group norm mediated the effects of depersonalization on conformity.},
  langid = {english},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/FD766G59/Lee - 2006 - When and How Does Depersonalization Increase Confo.pdf}
}

@article{leeWhenPeopleSpeak2014,
  title = {When {{Do People Speak Out}}? {{Integrating}} the {{Spiral}} of {{Silence}} and the {{Situational Theory}} of {{Problem Solving}}},
  shorttitle = {When {{Do People Speak Out}}?},
  author = {Lee, Hyegyu and Oshita, Tsuyoshi and Oh, Hyun Jung and Hove, Thomas},
  year = {2014},
  month = may,
  journal = {Journal of Public Relations Research},
  volume = {26},
  number = {3},
  pages = {185--199},
  publisher = {Routledge},
  issn = {1062-726X},
  doi = {10.1080/1062726X.2013.864243},
  urldate = {2024-07-14},
  abstract = {Combining spiral of silence theory with the situational theory of problem solving, this study explores the extent to which publics differ in their willingness to express their opinions in hostile social situations. Based on analysis of a survey among 369 college students about their willingness to express opinions on 2 controversial topics (gun possession and climate change), 3 key findings emerge: (a) Fear of isolation suppresses people's willingness to express their opinions in public; (b) active publics are more likely than other types of publics to express their opinions; and (c) there is no interaction effect between fear of isolation and types of publics. In addition to several theoretical contributions, the findings provide public relations practitioners with a model for predicting which types of publics would be more or less likely to express their opinion.}
}

@inproceedings{leeWorkingMachinesImpact2015,
  title = {Working with {{Machines}}: {{The Impact}} of {{Algorithmic}} and {{Data-Driven Management}} on {{Human Workers}}},
  shorttitle = {Working with {{Machines}}},
  booktitle = {Proceedings of the 33rd {{Annual ACM Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lee, Min Kyung and Kusbit, Daniel and Metsky, Evan and Dabbish, Laura},
  year = {2015},
  month = apr,
  series = {{{CHI}} '15},
  pages = {1603--1612},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2702123.2702548},
  urldate = {2024-07-18},
  abstract = {Software algorithms are changing how people work in an ever-growing number of fields, managing distributed human workers at a large scale. In these work settings, human jobs are assigned, optimized, and evaluated through algorithms and tracked data. We explore the impact of this algorithmic, data-driven management on human workers and work practices in the context of Uber and Lyft, new ridesharing services. Our findings from a qualitative study describe how drivers responded when algorithms assigned work, provided informational support, and evaluated their performance, and how drivers used online forums to socially make sense of the algorithm features. Implications and future work are discussed.},
  isbn = {978-1-4503-3145-6}
}

@inproceedings{leungBadBloodManaging2017,
  title = {Bad Blood: Managing Toxic Relationships through Belbin Roles for First Year Software Engineering Students},
  shorttitle = {Bad Blood},
  booktitle = {Proceedings of the 3rd {{International Conference}} on {{Communication}} and {{Information Processing}}},
  author = {Leung, Wai Sze},
  year = {2017},
  month = nov,
  series = {{{ICCIP}} '17},
  pages = {82--86},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3162957.3163010},
  urldate = {2024-07-19},
  abstract = {The approach by most universities in pitching team-based projects at senior undergraduate level as a learning and assessment tool can be considerably risky for student success, especially if a student discovers only in their final year of study, that they overestimated the command of their soft skills, potentially leading to them failing the project. This paper reports on an initiative aimed at minimizing this risk by introducing the concept of teamwork earlier in the curriculum, particularly, at first-year level, rather than allowing senior students to be blindsided at the later and (far more) crucial stage. This approach is meant to encourage students to explore interactions with one another, identifying potential shortcomings, and encountering likely sources that often give rise to conflict in team environments. Being the "Rainbow Nation", South Africa can be particularly susceptible to disagreements borne from social differences. Because we are working with first-year students, and because they are typically busy learning to transition from high school to university, the team exercise had to be designed and implemented in such a way as to ensure that opportunities arose, enabling students to question themselves. In addition to having to develop a software solution of their choice, students were introduced to the concept of Belbin roles to better understand how different personalities positively contribute to software development teams and encouraged to assess their own personalities in this regard. Finally, we asked them to write a reflective essay in which they describe their experiences of working in a team. In some essays, reasons for challenges arising were quite detailed while many identified specific soft skills that would need attention to ensure better success on projects in the future. This was in stark contrast to an initial consensus that the students would be able to work in teams without issue.},
  isbn = {978-1-4503-5365-6}
}

@inproceedings{liaoDesigningResponsibleTrust2022,
  title = {Designing for {{Responsible Trust}} in {{AI Systems}}: {{A Communication Perspective}}},
  shorttitle = {Designing for {{Responsible Trust}} in {{AI Systems}}},
  booktitle = {Proceedings of the 2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Liao, Q.Vera and Sundar, S. Shyam},
  year = {2022},
  month = jun,
  series = {{{FAccT}} '22},
  pages = {1257--1268},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3531146.3533182},
  urldate = {2024-06-17},
  abstract = {"AI에 대한 신뢰"에 관한 현재 문헌과 공개 담론은 신뢰할 수 있는 AI의 기본 원칙에 초점을 맞추는 경우가 많으며, 사람들이 신뢰를 구축하는 방법에 대한 관심은 부족합니다. AI 시스템의 신뢰성 수준이 다르다는 점을 감안할 때 두 가지 열린 질문이 대두됩니다. 다양한 사용자의 적절하고 공평한 신뢰 판단을 보장하기 위해 AI 신뢰성을 어떻게 책임감 있게 전달해야 하며, 신뢰를 얻으려는기만적인 시도로부터 사용자를 어떻게 보호할 수 있습니까? ? 우리는 기술 신뢰에 관한 커뮤니케이션 이론과 문헌을 활용하여 MATCH라는 개념 모델을 개발했습니다. 이 모델은 신뢰도 단서를 통해 AI 시스템에서 신뢰도가 전달되는 방식과 이러한 단서를 사람들이 처리하여 신뢰 판단을 내리는 방식을 설명합니다. AI 생성 콘텐츠 외에도 우리는 사용자에게 광범위한 신뢰성 단서를 제공하는 AI 시스템의 어포던스로서 투명성과 상호 작용을 강조합니다. 신뢰 판단을 내리는 다양한 사용자의 인지 프로세스와 잠재적인 한계를 조명함으로써 우리는 기술 제작자가 대상 사용자를 위한 신뢰할 수 있는 신뢰성 단서를 선택하는 데 의식적인 결정을 내리고 업계로서 이 공간을 규제하고 악의적인 사용을 방지할 것을 촉구합니다. . 이러한 목표를 위해 우리는 보증된 신뢰성 단서와 값비싼 신뢰성 단서의 개념을 정의하고 기술 제작자가 사용할 적절한 단서를 식별하는 데 도움이 되는 요구 사항 체크리스트를 제안합니다. 우리는 실무자가 MATCH를 사용하여 책임감 있게 AI 시스템을 설계하는 방법을 설명하고 AI에 대한 책임감 있는 신뢰를 증진하기 위한 연구 및 업계 노력의 향후 방향을 논의하기 위해 가상의 사용 사례를 제시합니다.},
  isbn = {978-1-4503-9352-2},
  langid = {american},
  keywords = {,notion},
  annotation = {TLDR: A conceptual model called MATCH is developed, which describes how trustworthiness is communicated in AI systems through trustworthiness cues and how those cues are processed by people to make trust judgments, and proposes a checklist of requirements to help technology creators identify appropriate cues to use.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/MDWPZ9HA/Liao and Sundar - 2022 - Designing for Responsible Trust in AI Systems A C.pdf}
}

@inproceedings{liaoQuestioningAIInforming2020,
  title = {Questioning the {{AI}}: {{Informing Design Practices}} for {{Explainable AI User Experiences}}},
  shorttitle = {Questioning the {{AI}}},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Liao, Q. Vera and Gruen, Daniel and Miller, Sarah},
  year = {2020},
  month = apr,
  series = {{{CHI}} '20},
  pages = {1--15},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3313831.3376590},
  urldate = {2024-04-08},
  abstract = {A surge of interest in explainable AI (XAI) has led to a vast collection of algorithmic work on the topic. While many recognize the necessity to incorporate explainability features in AI systems, how to address real-world user needs for understanding AI remains an open question. By interviewing 20 UX and design practitioners working on various AI products, we seek to identify gaps between the current XAI algorithmic work and practices to create explainable AI products. To do so, we develop an algorithm-informed XAI question bank in which user needs for explainability are represented as prototypical questions users might ask about the AI, and use it as a study probe. Our work contributes insights into the design space of XAI, informs efforts to support design practices in this space, and identifies opportunities for future XAI work. We also provide an extended XAI question bank and discuss how it can be used for creating user-centered XAI.},
  isbn = {978-1-4503-6708-0},
  keywords = {notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/7EJNR3DR/Liao et al. - 2020 - Questioning the AI Informing Design Practices for.pdf}
}

@inproceedings{liBetterDetectionBiased2022,
  title = {Towards {{Better Detection}} of {{Biased Language}} with {{Scarce}}, {{Noisy}}, and {{Biased Annotations}}},
  booktitle = {Proceedings of the 2022 {{AAAI}}/{{ACM Conference}} on {{AI}}, {{Ethics}}, and {{Society}}},
  author = {Li, Zhuoyan and Lu, Zhuoran and Yin, Ming},
  year = {2022},
  month = jul,
  series = {{{AIES}} '22},
  pages = {411--423},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3514094.3534142},
  urldate = {2024-07-17},
  abstract = {Biased language is prevalent in today's online social media. To reduce the amount of online biased language, one critical first step is to accurately detect such biased language, ideally automatically. This is a challenging problem, however, as the annotated data necessary for training a biased language classifier is either scarce and costly (e.g., when collected from experts), or noisy and potentially biased on their own (e.g., when collected from crowd workers). The biased language classifier built based on these annotations may thus be inaccurate, and sometimes unfair (e.g., have systematic accuracy disparities across texts with different political leanings). In this paper, we propose a novel method, CLEARE, for biased language detection, in which we utilize self-supervised contrastive learning to enhance the biased language classifier---we learn a robust encoder of the textual data through solving a min-max optimization problem, so that the encoder could help achieve the best classification performance even if the worst data augmentation strategy is selected. Extensive evaluations suggest that CLEARE shows substantial improvements compared to the state-of-art biased language detection methods on several benchmark datasets, in terms of improving both the accuracy and the fairness of the detection.},
  isbn = {978-1-4503-9247-1}
}

@article{liDecodingAIsNudge2024,
  title = {Decoding {{AI}}'s {{Nudge}}: {{A Unified Framework}} to {{Predict Human Behavior}} in {{AI-Assisted Decision Making}}},
  shorttitle = {Decoding {{AI}}'s {{Nudge}}},
  author = {Li, Zhuoyan and Lu, Zhuoran and Yin, Ming},
  year = {2024},
  month = mar,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {38},
  number = {9},
  pages = {10083--10091},
  issn = {2374-3468},
  doi = {10.1609/aaai.v38i9.28872},
  urldate = {2024-07-18},
  abstract = {With the rapid development of AI-based decision aids,  different forms of AI assistance have been increasingly integrated into the human decision making processes.  To best support humans in decision making, it is essential to quantitatively understand how diverse forms of AI assistance influence humans' decision making behavior. To this end, much of the current research focuses on the end-to-end prediction of human behavior using ``black-box'' models, often lacking interpretations of the nuanced ways in which AI assistance impacts the human decision making process.  Meanwhile, methods that prioritize the interpretability of human behavior predictions are often tailored for one specific form of AI assistance, making adaptations to other forms of assistance difficult.  In this paper, we propose a computational framework that can provide an interpretable characterization of the influence of different forms of AI assistance on decision makers in AI-assisted decision making.  By conceptualizing  AI assistance as the ``nudge'' in human decision making processes, our approach centers around modelling how different forms of AI assistance modify humans' strategy in weighing different information in making their decisions. Evaluations on behavior data collected from real human decision makers  show that the proposed framework outperforms various baselines in accurately predicting human behavior in AI-assisted decision making. Based on the proposed framework, we further provide insights into how individuals with different cognitive styles are nudged by AI assistance differently.},
  copyright = {Copyright (c) 2024 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/XJ9N7BH8/Li et al. - 2024 - Decoding AI’s Nudge A Unified Framework to Predic.pdf}
}

@article{lightGenderSocialComparison2000,
  title = {Gender and Social Comparison Effects in Computer-Based Problem Solving},
  author = {Light, Paul and Littleton, Karen and Bale, Stuart and Joiner, Richard and Messer, David},
  year = {2000},
  month = dec,
  journal = {Learning and Instruction},
  volume = {10},
  number = {6},
  pages = {483--496},
  issn = {0959-4752},
  doi = {10.1016/S0959-4752(00)00010-4},
  urldate = {2024-07-19},
  abstract = {Gender differences in relation to school children's learning with computers are frequently attributed to a tendency for boys to dominate computer resources in mixed sex settings. However, the evidence relating to children's performance with computers in mixed sex groups is conflicting. This paper reports two experimental studies in which 11- to 12-year-olds worked on a computer-based problem solving task. In the first, 62 children worked in either same or mixed sex dyads, but each child had her or his own computer, and no verbal interaction was allowed. Boys out-performed girls overall, with sex differences becoming significantly more polarised in the mixed sex dyads. The second study involved 96 children, with individual pre- and post-tests, and compared co-action dyads (as in the first study) with interaction pairs, in which the pair members worked together at a single computer, with no restriction on interaction. The polarisation of sex differences in the mixed sex dyads was once again found in the co-action condition, but not in the interaction condition. Results are interpreted in terms of processes of social comparison, which appear to be more potent in this situation than any straightforward domination of resources.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/24LEW3R7/S0959475200000104.html}
}

@article{liImprovingNonNativeSpeakers2022,
  title = {Improving {{Non-Native Speakers}}' {{Participation}} with an {{Automatic Agent}} in {{Multilingual Groups}}},
  author = {Li, Xiaoyan and Yamashita, Naomi and Duan, Wen and Shirai, Yoshinari and Fussell, Susan R.},
  year = {2022},
  month = dec,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {7},
  number = {GROUP},
  pages = {12:1--12:28},
  doi = {10.1145/3567562},
  urldate = {2024-07-19},
  abstract = {Non-native speakers (NNS) often face challenges gaining the speaking floor in conversations with native speakers (NS) of a common language. To help NNS to contribute more, we developed a conversational agent that opens up the speaking floor either automatically, after NS have taken a certain number of consecutive speaking turns, or manually, upon NNS request. We compared these automatic and manual agents to a control condition in a laboratory study in which one NNS collaborated with two NS using English as a common language. Participants (N=48) communicated over video conferencing from separate locations in a research institution to collaborate on three survival tasks. Based on data gathered from the experiments, the automatic agent encouraged NNS to participate more, which previous studies had attempted but failed to achieve. Excerpts from group discussions further showed the crucial role of the automatic agent on NNS participation. Interview results suggested that while NNS appreciated the automatic agent's help to participation, NS perceived the agent's interruption as unfair because they thought all members were speaking equally, which was not the case. The mismatch in their perceptions further emphasizes the need to intervene, and we provide design implications based on the results.}
}

@article{liModelingHumanTrust2023,
  title = {Modeling {{Human Trust}} and {{Reliance}} in {{AI-Assisted Decision Making}}: {{A Markovian Approach}}},
  shorttitle = {Modeling {{Human Trust}} and {{Reliance}} in {{AI-Assisted Decision Making}}},
  author = {Li, Zhuoyan and Lu, Zhuoran and Yin, Ming},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {5},
  pages = {6056--6064},
  issn = {2374-3468},
  doi = {10.1609/aaai.v37i5.25748},
  urldate = {2024-07-18},
  abstract = {The increased integration of artificial intelligence (AI) technologies in human workflows has resulted in a new paradigm of AI-assisted decision making, in which an AI model provides decision recommendations while humans make the final decisions. To best support humans in decision making, it is critical to obtain a quantitative understanding of how humans interact with and rely on AI. Previous studies often model humans' reliance on AI as an analytical process, i.e., reliance decisions are made based on cost-benefit analysis. However, theoretical models in psychology suggest that the reliance decisions can often be driven by emotions like humans' trust in AI models. In this paper, we propose a hidden Markov model to capture the affective process underlying the human-AI interaction in AI-assisted decision making, by characterizing how decision makers adjust their trust in AI over time and make reliance decisions based on their trust. Evaluations on real human behavior data collected from human-subject experiments show that the proposed model outperforms various baselines in accurately predicting humans' reliance behavior in AI-assisted decision making. Based on the proposed model, we further provide insights into how humans' trust and reliance dynamics in AI-assisted decision making is influenced by contextual factors like decision stakes and their interaction experiences.},
  copyright = {Copyright (c) 2023 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/EV3A9MXW/Li et al. - 2023 - Modeling Human Trust and Reliance in AI-Assisted D.pdf}
}

@article{liModelingHumanTrust2023a,
  title = {Modeling {{Human Trust}} and {{Reliance}} in {{AI-Assisted Decision Making}}: {{A Markovian Approach}}},
  shorttitle = {Modeling {{Human Trust}} and {{Reliance}} in {{AI-Assisted Decision Making}}},
  author = {Li, Zhuoyan and Lu, Zhuoran and Yin, Ming},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {5},
  pages = {6056--6064},
  issn = {2374-3468},
  doi = {10.1609/aaai.v37i5.25748},
  urldate = {2024-07-18},
  abstract = {The increased integration of artificial intelligence (AI) technologies in human workflows has resulted in a new paradigm of AI-assisted decision making, in which an AI model provides decision recommendations while humans make the final decisions. To best support humans in decision making, it is critical to obtain a quantitative understanding of how humans interact with and rely on AI. Previous studies often model humans' reliance on AI as an analytical process, i.e., reliance decisions are made based on cost-benefit analysis. However, theoretical models in psychology suggest that the reliance decisions can often be driven by emotions like humans' trust in AI models. In this paper, we propose a hidden Markov model to capture the affective process underlying the human-AI interaction in AI-assisted decision making, by characterizing how decision makers adjust their trust in AI over time and make reliance decisions based on their trust. Evaluations on real human behavior data collected from human-subject experiments show that the proposed model outperforms various baselines in accurately predicting humans' reliance behavior in AI-assisted decision making. Based on the proposed model, we further provide insights into how humans' trust and reliance dynamics in AI-assisted decision making is influenced by contextual factors like decision stakes and their interaction experiences.},
  copyright = {Copyright (c) 2023 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/7N63BEZL/Li et al. - 2023 - Modeling Human Trust and Reliance in AI-Assisted D.pdf}
}

@inproceedings{liObserverPerceptionDominance2015,
  title = {Observer {{Perception}} of {{Dominance}} and {{Mirroring Behavior}} in {{Human-Robot Relationships}}},
  booktitle = {Proceedings of the {{Tenth Annual ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Li, Jamy and Ju, Wendy and Nass, Cliff},
  year = {2015},
  month = mar,
  series = {{{HRI}} '15},
  pages = {133--140},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2696454.2696459},
  urldate = {2024-07-18},
  abstract = {How people view relationships between humans and robots is an important consideration for the design and acceptance of social robots. Two studies investigated the effect of relational behavior in a human-robot dyad. In Study 1, participants watched videos of a human confederate discussing the Desert Survival Task with either another human confederate or a humanoid robot. Participants were less trusting of both the robot and the person in a human-robot relationship where the robot was dominant toward the person than when the person was dominant toward the robot; these differences were not found for a human pair. In Study 2, participants watched videos of a human confederate having an everyday conversation with either another human confederate or a humanoid robot. Participants who saw a confederate mirror the gestures of a robot found the robot less attractive than when the robot mirrored the confederate; the opposite effect was found for a human pair. Exploratory findings suggest that human-robot relationships are viewed differently than human dyads.},
  isbn = {978-1-4503-2883-8}
}

@misc{liSyntheticDataGeneration2023,
  title = {Synthetic {{Data Generation}} with {{Large Language Models}} for {{Text Classification}}: {{Potential}} and {{Limitations}}},
  shorttitle = {Synthetic {{Data Generation}} with {{Large Language Models}} for {{Text Classification}}},
  author = {Li, Zhuoyan and Zhu, Hangxiao and Lu, Zhuoran and Yin, Ming},
  year = {2023},
  month = oct,
  journal = {arXiv.org},
  urldate = {2024-07-18},
  abstract = {The collection and curation of high-quality training data is crucial for developing text classification models with superior performance, but it is often associated with significant costs and time investment. Researchers have recently explored using large language models (LLMs) to generate synthetic datasets as an alternative approach. However, the effectiveness of the LLM-generated synthetic data in supporting model training is inconsistent across different classification tasks. To better understand factors that moderate the effectiveness of the LLM-generated synthetic data, in this study, we look into how the performance of models trained on these synthetic data may vary with the subjectivity of classification. Our results indicate that subjectivity, at both the task level and instance level, is negatively associated with the performance of the model trained on synthetic data. We conclude by discussing the implications of our work on the potential and limitations of leveraging LLM for synthetic data generation.},
  howpublished = {https://arxiv.org/abs/2310.07849v2},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VNP6E544/Li et al. - 2023 - Synthetic Data Generation with Large Language Mode.pdf}
}

@misc{liuLostMiddleHow2023,
  title = {Lost in the {{Middle}}: {{How Language Models Use Long Contexts}}},
  shorttitle = {Lost in the {{Middle}}},
  author = {Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  year = {2023},
  month = nov,
  number = {arXiv:2307.03172},
  eprint = {2307.03172},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.03172},
  urldate = {2025-01-08},
  abstract = {While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze the performance of language models on two tasks that require identifying relevant information in their input contexts: multi-document question answering and key-value retrieval. We find that performance can degrade significantly when changing the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts. In particular, we observe that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context language models.},
  archiveprefix = {arXiv},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/SN7Z5I4I/Liu et al. - 2023 - Lost in the Middle How Language Models Use Long Contexts.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/5XDFKMWF/2307.html}
}

@misc{liuProactiveConversationalAgents2024,
  title = {Proactive {{Conversational Agents}} with {{Inner Thoughts}}},
  author = {Liu, Xingyu Bruce and Fang, Shitao and Shi, Weiyan and Wu, Chien-Sheng and Igarashi, Takeo and Chen, Xiang `Anthony'},
  year = {2024},
  month = dec,
  number = {arXiv:2501.00383},
  eprint = {2501.00383},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.00383},
  urldate = {2025-01-08},
  abstract = {One of the long-standing aspirations in conversational AI is to allow them to autonomously take initiatives in conversations, i.e., being proactive. This is especially challenging for multi-party conversations. Prior NLP research focused mainly on predicting the next speaker from contexts like preceding conversations. In this paper, we demonstrate the limitations of such methods and rethink what it means for AI to be proactive in multi-party, human-AI conversations. We propose that just like humans, rather than merely reacting to turn-taking cues, a proactive AI formulates its own inner thoughts during a conversation, and seeks the right moment to contribute. Through a formative study with 24 participants and inspiration from linguistics and cognitive psychology, we introduce the Inner Thoughts framework. Our framework equips AI with a continuous, covert train of thoughts in parallel to the overt communication process, which enables it to proactively engage by modeling its intrinsic motivation to express these thoughts. We instantiated this framework into two real-time systems: an AI playground web app and a chatbot. Through a technical evaluation and user studies with human participants, our framework significantly surpasses existing baselines on aspects like anthropomorphism, coherence, intelligence, and turn-taking appropriateness.},
  archiveprefix = {arXiv},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/8QUXA9B9/Liu et al. - 2024 - Proactive Conversational Agents with Inner Thoughts.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/8NC5GHYQ/2501.html}
}

@article{liuUnderstandingEffectOutofdistribution2021,
  title = {Understanding the {{Effect}} of {{Out-of-distribution Examples}} and {{Interactive Explanations}} on {{Human-AI Decision Making}}},
  author = {Liu, Han and Lai, Vivian and Tan, Chenhao},
  year = {2021},
  month = oct,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  number = {CSCW2},
  pages = {408:1--408:45},
  doi = {10.1145/3479552},
  urldate = {2024-07-18},
  abstract = {Although AI holds promise for improving human decision making in societally critical domains, it remains an open question how human-AI teams can reliably outperform AI alone and human alone in challenging prediction tasks (also known as complementary performance). We explore two directions to understand the gaps in achieving complementary performance. First, we argue that the typical experimental setup limits the potential of human-AI teams. To account for lower AI performance out-of-distribution than in-distribution because of distribution shift, we design experiments with different distribution types and investigate human performance for both in-distribution and out-of-distribution examples. Second, we develop novel interfaces to support interactive explanations so that humans can actively engage with AI assistance. Using virtual pilot studies and large-scale randomized experiments across three tasks, we demonstrate a clear difference between in-distribution and out-of-distribution, and observe mixed results for interactive explanations: while interactive explanations improve human perception of AI assistance's usefulness, they may reinforce human biases and lead to limited performance improvement. Overall, our work points out critical challenges and future directions towards enhancing human performance with AI assistance.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/UDMDF3D6/Liu et al. - 2021 - Understanding the Effect of Out-of-distribution Ex.pdf}
}

@inproceedings{liuWhatItWants2023,
  title = {``{{What It Wants Me To Say}}'': {{Bridging}} the {{Abstraction Gap Between End-User Programmers}} and {{Code-Generating Large Language Models}}},
  shorttitle = {``{{What It Wants Me To Say}}''},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Liu, Michael Xieyang and Sarkar, Advait and Negreanu, Carina and Zorn, Benjamin and Williams, Jack and Toronto, Neil and Gordon, Andrew D.},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--31},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3580817},
  urldate = {2024-07-17},
  abstract = {Code-generating large language models map natural language to code. However, only a small portion of the infinite space of naturalistic utterances is effective at guiding code generation. For non-expert end-user programmers, learning this is the challenge of abstraction matching. We examine this challenge in the specific context of data analysis in spreadsheets, in a system that maps the user's natural language query to Python code using the Codex generator, executes the code, and shows the result. We propose grounded abstraction matching, which bridges the abstraction gap by translating the code back into a systematic and predictable naturalistic utterance. In a between-subjects, think-aloud study (n=24), we compare grounded abstraction matching to an ungrounded alternative based on previously established query framing principles. We find that the grounded approach improves end-users' understanding of the scope and capabilities of the code-generating model, and the kind of language needed to use it effectively.},
  isbn = {978-1-4503-9421-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/N7R2ZAY8/Liu et al. - 2023 - “What It Wants Me To Say” Bridging the Abstractio.pdf}
}

@inproceedings{loboWhenShouldLead2024,
  title = {When {{Should I Lead}} or {{Follow}}: {{Understanding Initiative Levels}} in {{Human-AI Collaborative Gameplay}}},
  shorttitle = {When {{Should I Lead}} or {{Follow}}},
  booktitle = {Proceedings of the 2024 {{ACM Designing Interactive Systems Conference}}},
  author = {Lobo, In{\^e}s and Koch, Janin and Renoux, Jennifer and Batina, In{\^e}s and Prada, Rui},
  year = {2024},
  month = jul,
  series = {{{DIS}} '24},
  pages = {2037--2056},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3643834.3661583},
  urldate = {2024-07-23},
  abstract = {Dynamics in Human-AI interaction should lead to more satisfying and engaging collaboration. Key open questions are how to design such interactions and the role personal goals and expectations play. We developed three AI partners of varying initiative (leader, follower, shifting) in a collaborative game called Geometry Friends. We conducted a within-subjects experiment with 60 participants to assess personal AI partner preference and performance satisfaction as well as perceived warmth and competence of AI partners. Results show that AI partners following human initiative are perceived as warmer and more collaborative. However, some participants preferred AI leaders for their independence and speed, despite being seen as less friendly. This suggests that assigning a leadership role to the AI partner may be suitable for time-sensitive scenarios. We identify design factors for developing collaborative AI agents with varying levels of initiative to create more effective human-AI teams that consider context and individual preference.},
  isbn = {9798400705830}
}

@article{loggAlgorithmAppreciationPeople2019,
  title = {Algorithm Appreciation: {{People}} Prefer Algorithmic to Human Judgment},
  shorttitle = {Algorithm Appreciation},
  author = {Logg, Jennifer M. and Minson, Julia A. and Moore, Don A.},
  year = {2019},
  month = mar,
  journal = {Organizational Behavior and Human Decision Processes},
  volume = {151},
  pages = {90--103},
  issn = {0749-5978},
  doi = {10.1016/j.obhdp.2018.12.005},
  urldate = {2024-07-18},
  abstract = {Even though computational algorithms often outperform human judgment, received wisdom suggests that people may be skeptical of relying on them (Dawes, 1979). Counter to this notion, results from six experiments show that lay people adhere more to advice when they think it comes from an algorithm than from a person. People showed this effect, what we call algorithm appreciation, when making numeric estimates about a visual stimulus (Experiment 1A) and forecasts about the popularity of songs and romantic attraction (Experiments 1B and 1C). Yet, researchers predicted the opposite result (Experiment 1D). Algorithm appreciation persisted when advice appeared jointly or separately (Experiment 2). However, algorithm appreciation waned when: people chose between an algorithm's estimate and their own (versus an external advisor's; Experiment 3) and they had expertise in forecasting (Experiment 4). Paradoxically, experienced professionals, who make forecasts on a regular basis, relied less on algorithmic advice than lay people did, which hurt their accuracy. These results shed light on the important question of when people rely on algorithmic advice over advice from people and have implications for the use of ``big data'' and algorithmic advice it generates.}
}

@inproceedings{longWhatAILiteracy2020,
  title = {What Is {{AI Literacy}}? {{Competencies}} and {{Design Considerations}}},
  shorttitle = {What Is {{AI Literacy}}?},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Long, Duri and Magerko, Brian},
  year = {2020},
  month = apr,
  series = {{{CHI}} '20},
  pages = {1--16},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3313831.3376727},
  urldate = {2024-07-17},
  abstract = {Artificial intelligence (AI) is becoming increasingly integrated in user-facing technology, but public understanding of these technologies is often limited. There is a need for additional HCI research investigating a) what competencies users need in order to effectively interact with and critically evaluate AI and b) how to design learner-centered AI technologies that foster increased user understanding of AI. This paper takes a step towards realizing both of these goals by providing a concrete definition of AI literacy based on existing research. We synthesize a variety of interdisciplinary literature into a set of core competencies of AI literacy and suggest several design considerations to support AI developers and educators in creating learner-centered AI. These competencies and design considerations are organized in a conceptual framework thematically derived from the literature. This paper's contributions can be used to start a conversation about and guide future research on AI literacy within the HCI community.},
  isbn = {978-1-4503-6708-0}
}

@article{lopesValidationGroupDecisions2014,
  title = {{Validation of group decisions~: Why and when perceived group heterogeneity is relevant}},
  shorttitle = {{Validation of group decisions}},
  author = {Lopes, Diniz and Vala, Jorge and Oberl{\'e}, Dominique and {Drozda-Senkowska}, Ewa},
  year = {2014},
  journal = {Revue internationale de psychologie sociale},
  volume = {27},
  number = {2},
  pages = {35--49},
  publisher = {Presses universitaires de Grenoble},
  address = {FONTAINE},
  issn = {0992-986X},
  urldate = {2024-08-16},
  abstract = {Appuy{\'e}e sur la reformulation attributionnelle de la th{\'e}orie de la comparaison sociale (Goethals \&Darley, 1977) et sur des {\'e}tudes pr{\'e}c{\'e}dentes (e.g., Lopes, Vala, \&Garcia-Marques, 2007), cette recherche approfondit notre compr{\'e}hension du r{\^o}le du consensus et de l'h{\'e}t{\'e}rog{\'e}n{\'e}it{\'e} d'un groupe sur l'attribution de validit{\'e} port{\'e}e sur ses opinions et d{\'e}cisions. Une {\'e}tude exp{\'e}rimentale teste l'hypoth{\`e}se selon laquelle lorsque le consensus du groupe est fort, mais non quand il est faible, l'effet de l'h{\'e}t{\'e}rog{\'e}n{\'e}it{\'e} du groupe sur la validit{\'e} attribu{\'e}e {\`a} ses d{\'e}cisions est m{\'e}diatis{\'e} par la perception qu'il y a eu une bonne participation des membres du groupe. Les r{\'e}sultats confirment cette hypoth{\`e}se de mod{\'e}ration m{\'e}diatis{\'e}e et sont discut{\'e}s {\`a} la lumi{\`e}re de la valeur {\'e}pist{\'e}mique de l'information sur l'h{\'e}t{\'e}rog{\'e}n{\'e}it{\'e} et sur le consensus dans les d{\'e}cisions et les opinions de groupe.},
  langid = {french},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/B4VCTYZJ/Lopes et al. - 2014 - Validation of group decisions  Why and when perce.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/CBJY7VFC/revue-internationale-de-psychologie-sociale-2014-2-page-35.html}
}

@article{luckenCognitiveAffectiveExperiences2005,
  title = {Cognitive and Affective Experiences of Minority and Majority Members: {{The}} Role of Group Size, Status, and Power},
  shorttitle = {Cognitive and Affective Experiences of Minority and Majority Members},
  author = {L{\"u}cken, Markus and Simon, Bernd},
  year = {2005},
  month = jul,
  journal = {Journal of Experimental Social Psychology},
  volume = {41},
  number = {4},
  pages = {396--413},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2004.08.006},
  urldate = {2024-07-19},
  abstract = {Four studies examined cognitive and affective experiences of minority and majority members. We predicted and found that minority members were more cognitively preoccupied with their group membership and experienced less positive affect as a consequence of their group membership than majority members. The first experiment established these effects with numerical minority and majority groups. The second experiment ruled out status as an explanatory variable, and the third experiment uncovered the role of power in the differential cognitive and affective experiences of minority and majority members. The final field study substantiated the ecological robustness of the experimental findings and provided further evidence for the role of power. The interrelation of status and power is discussed as well as the phenomenology of being a minority member.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/JNY9FFMD/S0022103104001106.html}
}

@article{luDoesMoreAdvice2024,
  title = {Does {{More Advice Help}}? {{The Effects}} of {{Second Opinions}} in {{AI-Assisted Decision Making}}},
  shorttitle = {Does {{More Advice Help}}?},
  author = {Lu, Zhuoran and Wang, Dakuo and Yin, Ming},
  year = {2024},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {8},
  number = {CSCW1},
  pages = {217:1--217:31},
  doi = {10.1145/3653708},
  urldate = {2024-07-18},
  abstract = {AI assistance in decision-making has become popular, yet people's inappropriate reliance on AI often leads to unsatisfactory human-AI collaboration performance. In this paper, through three pre-registered, randomized human subject experiments, we explore whether and how the provision of second opinions may affect decision-makers' behavior and performance in AI-assisted decision-making. We find that if both the AI model's decision recommendation and a second opinion are always presented together, decision-makers reduce their over-reliance on AI while increase their under-reliance on AI, regardless whether the second opinion is generated by a peer or another AI model. However, if decision-makers have the control to decide when to solicit a peer's second opinion, we find that their active solicitations of second opinions have the potential to mitigate over-reliance on AI without inducing increased under-reliance in some cases. We conclude by discussing the implications of our findings for promoting effective human-AI collaborations in decision-making.}
}

@article{luEffectsAIbasedCredibility2022,
  title = {The {{Effects}} of {{AI-based Credibility Indicators}} on the {{Detection}} and {{Spread}} of {{Misinformation}} under {{Social Influence}}},
  author = {Lu, Zhuoran and Li, Patrick and Wang, Weilong and Yin, Ming},
  year = {2022},
  month = nov,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  number = {CSCW2},
  pages = {461:1--461:27},
  doi = {10.1145/3555562},
  urldate = {2024-07-18},
  abstract = {Misinformation on social media has become a serious concern. Marking news stories with credibility indicators, possibly generated by an AI model, is one way to help people combat misinformation. In this paper, we report the results of two randomized experiments that aim to understand the effects of AI-based credibility indicators on people's perceptions of and engagement with the news, when people are under social influence such that their judgement of the news is influenced by other people. We find that the presence of AI-based credibility indicators nudges people into aligning their belief in the veracity of news with the AI model's prediction regardless of its correctness, thereby changing people's accuracy in detecting misinformation. However, AI-based credibility indicators show limited impacts on influencing people's engagement with either real news or fake news when social influence exists. Finally, it is shown that when social influence is present, the effects of AI-based credibility indicators on the detection and spread of misinformation are larger as compared to when social influence is absent, when these indicators are provided to people before they form their own judgements about the news. We conclude by providing implications for better utilizing AI to fight misinformation.}
}

@inproceedings{luHumanRelianceMachine2021,
  title = {Human {{Reliance}} on {{Machine Learning Models When Performance Feedback}} Is {{Limited}}: {{Heuristics}} and {{Risks}}},
  shorttitle = {Human {{Reliance}} on {{Machine Learning Models When Performance Feedback}} Is {{Limited}}},
  booktitle = {Proceedings of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Lu, Zhuoran and Yin, Ming},
  year = {2021},
  month = may,
  series = {{{CHI}} '21},
  pages = {1--16},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3411764.3445562},
  urldate = {2024-07-17},
  abstract = {This paper addresses an under-explored problem of AI-assisted decision-making: when objective performance information of the machine learning model underlying a decision aid is absent or scarce, how do people decide their reliance on the model? Through three randomized experiments, we explore the heuristics people may use to adjust their reliance on machine learning models when performance feedback is limited. We find that the level of agreement between people and a model on decision-making tasks that people have high confidence in significantly affects reliance on the model if people receive no information about the model's performance, but this impact will change after aggregate-level model performance information becomes available. Furthermore, the influence of high confidence human-model agreement on people's reliance on a model is moderated by people's confidence in cases where they disagree with the model. We discuss potential risks of these heuristics, and provide design implications on promoting appropriate reliance on AI.},
  isbn = {978-1-4503-8096-6}
}

@book{lukesPower1986,
  title = {Power},
  author = {Lukes, Steven},
  year = {1986},
  month = nov,
  publisher = {NYU Press},
  abstract = {A collection of essential essays on political theories of powerWhat is power? Is it, as Betrand Russell suggested, "the production of intended effects", or is it the capacity to produce them? And which effects count? Or is Max Weber's definition of power as "the probability that an actor in a social relationship will be in a position to carry out his own will despite resistance" more accurate. What are the outcomes of power and who holds it? These are some of the fundamental questions answered in this colection of classic views of power. Steven Luke's lucid and accessible introduction on the nature of power leads to pieces by Bertrand Russell, Max Weber, Robert Dahl, Hannah Arendt, Jurgen Habermas, Talcott Parsons, Nicos Polantzas, Alvin I. Goldman, Georg Simmel, J. K. Galbraith, Michel Foucault, Gerhard Lenski and Raymond Aron. The book thus provides students of politics and sociology with all the most important readings in a key area of political theory.},
  googlebooks = {soOYQgAACAAJ},
  isbn = {978-0-8147-5031-5},
  langid = {english}
}

@inproceedings{luStrategicAdversarialAttacks2023,
  title = {Strategic {{Adversarial Attacks}} in {{AI-assisted Decision Making}} to {{Reduce Human Trust}} and {{Reliance}}},
  booktitle = {Thirty-{{Second International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Lu, Zhuoran and Li, Zhuoyan and Chiang, Chun-Wei and Yin, Ming},
  year = {2023},
  month = aug,
  volume = {3},
  pages = {3020--3028},
  issn = {1045-0823},
  doi = {10.24963/ijcai.2023/337},
  urldate = {2024-07-18},
  abstract = {Electronic proceedings of IJCAI 2023},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/2KAUEHPP/Lu et al. - 2023 - Strategic Adversarial Attacks in AI-assisted Decis.pdf}
}

@article{luSurveyGroupDecision2022,
  title = {A Survey of Group Decision Making Methods in Healthcare Industry 4.0: Bibliometrics, Applications, and Directions},
  author = {Lu, Keyu and Liao, Huchang},
  year = {2022},
  journal = {Applied Intelligence (Dordrecht, Netherlands)},
  volume = {52},
  number = {12},
  pages = {13689--13713},
  issn = {0924-669X},
  doi = {10.1007/s10489-021-02909-y},
}

@article{macdougallDevilsAdvocateStrategy1997,
  title = {The {{Devil}}'s {{Advocate}}: {{A Strategy}} to {{Avoid Groupthink}} and {{Stimulate Discussion}} in {{Focus Groups}}},
  shorttitle = {The {{Devil}}'s {{Advocate}}},
  author = {MacDougall, Colin and Baum, Frances},
  year = {1997},
  month = nov,
  journal = {Qualitative Health Research},
  volume = {7},
  number = {4},
  pages = {532--541},
  publisher = {SAGE Publications Inc},
  issn = {1049-7323},
  doi = {10.1177/104973239700700407},
  urldate = {2024-07-18},
  abstract = {The focus group is an increasingly popular qualitative research method in health research to gain insight into complex problems. Concerns have been expressed about how best to stimulate free and open discussion; especially on controversial issues and/or when the group comprises people with different power and status. A potential pitfall of the focus group technique is group-think: the impact of censoring and conforming as described by such social psychologists as Irving Janis. The article describes an evaluation of a method to reduce groupthink and stimulate creativity and controversy in focus groups that analyzed consultation between an Australian federal government department and its communities. The article recommends to researchers using focus groups the selective use of devil's advocates to reflect different perspectives to groups, to ask questions in a different way, to introduce new questions, and to avoid groups arriving at premature solutions.},
  langid = {english}
}

@article{maciejovskyTeamsMakeYou2013,
  title = {Teams {{Make You Smarter}}: {{How Exposure}} to {{Teams Improves Individual Decisions}} in {{Probability}} and {{Reasoning Tasks}}},
  shorttitle = {Teams {{Make You Smarter}}},
  author = {Maciejovsky, Boris and Sutter, Matthias and Budescu, David V. and Bernau, Patrick},
  year = {2013},
  month = jun,
  journal = {Management Science},
  volume = {59},
  number = {6},
  pages = {1255--1270},
  publisher = {INFORMS},
  issn = {0025-1909},
  doi = {10.1287/mnsc.1120.1668},
  urldate = {2024-08-09},
  abstract = {Many important decisions are routinely made by transient and temporary teams, which perform their duty and disperse. Team members often continue making similar decisions as individuals. We study how the experience of team decision making affects subsequent individual decisions in two seminal probability and reasoning tasks, the Monty Hall problem and the Wason selection task. Both tasks are hard and involve a general rule, thus allowing for knowledge transfers, and can be embedded in the context of markets that offer identical incentives to teams and individuals. Our results show that teams trade closer to the rational level, learn the solution faster, and achieve this with weaker, less specific performance feedback than individuals. Most importantly, we observe significant knowledge transfers from team decision making to subsequent individual performances that take place up to five weeks later, indicating that exposure to team decision making has strong positive spillovers on the quality of individual decisions. This paper was accepted by Uri Gneezy, behavioral economics.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/NUVJLNAV/Maciejovsky et al. - 2013 - Teams Make You Smarter How Exposure to Teams Impr.pdf}
}

@misc{MakingGoodGood,
  title = {Making {{Good}} on {{Good Intentions}}: {{The Critical Role}} of {{Motivation}} in {{Reducing Implicit Workplace Discrimination}} on {{JSTOR}}},
  eprint = {27759975},
  eprinttype = {jstor},
  urldate = {2024-07-19},
  howpublished = {https://www.jstor.org/stable/27759975}
}

@misc{maRecommenderExploratoryStudy2024,
  title = {Beyond {{Recommender}}: {{An Exploratory Study}} of the {{Effects}} of {{Different AI Roles}} in {{AI-Assisted Decision Making}}},
  shorttitle = {Beyond {{Recommender}}},
  author = {Ma, Shuai and Zhang, Chenyi and Wang, Xinru and Ma, Xiaojuan and Yin, Ming},
  year = {2024},
  month = mar,
  number = {arXiv:2403.01791},
  eprint = {2403.01791},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.01791},
  urldate = {2024-03-27},
  abstract = {Artificial Intelligence (AI) is increasingly employed in various decision-making tasks, typically as a Recommender, providing recommendations that the AI deems correct. However, recent studies suggest this may diminish human analytical thinking and lead to humans' inappropriate reliance on AI, impairing the synergy in human-AI teams. In contrast, human advisors in group decision-making perform various roles, such as analyzing alternative options or criticizing decision-makers to encourage their critical thinking. This diversity of roles has not yet been empirically explored in AI assistance. In this paper, we examine three AI roles: Recommender, Analyzer, and Devil's Advocate, and evaluate their effects across two AI performance levels. Our results show each role's distinct strengths and limitations in task performance, reliance appropriateness, and user experience. Notably, the Recommender role is not always the most effective, especially if the AI performance level is low, the Analyzer role may be preferable. These insights offer valuable implications for designing AI assistants with adaptive functional roles according to different situations.},
  archiveprefix = {arXiv},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/IH69T9ZF/Ma 등 - 2024 - Beyond Recommender An Exploratory Study of the Ef.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/GM8CKS2X/2403.html}
}

@misc{maRecommenderExploratoryStudy2024a,
  title = {Beyond {{Recommender}}: {{An Exploratory Study}} of the {{Effects}} of {{Different AI Roles}} in {{AI-Assisted Decision Making}}},
  shorttitle = {Beyond {{Recommender}}},
  author = {Ma, Shuai and Zhang, Chenyi and Wang, Xinru and Ma, Xiaojuan and Yin, Ming},
  year = {2024},
  month = mar,
  number = {arXiv:2403.01791},
  eprint = {2403.01791},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.01791},
  urldate = {2024-03-19},
  abstract = {Artificial Intelligence (AI) is increasingly employed in various decision-making tasks, typically as a Recommender, providing recommendations that the AI deems correct. However, recent studies suggest this may diminish human analytical thinking and lead to humans' inappropriate reliance on AI, impairing the synergy in human-AI teams. In contrast, human advisors in group decision-making perform various roles, such as analyzing alternative options or criticizing decision-makers to encourage their critical thinking. This diversity of roles has not yet been empirically explored in AI assistance. In this paper, we examine three AI roles: Recommender, Analyzer, and Devil's Advocate, and evaluate their effects across two AI performance levels. Our results show each role's distinct strengths and limitations in task performance, reliance appropriateness, and user experience. Notably, the Recommender role is not always the most effective, especially if the AI performance level is low, the Analyzer role may be preferable. These insights offer valuable implications for designing AI assistants with adaptive functional roles according to different situations.},
  archiveprefix = {arXiv},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/9S6F76WW/Ma 등 - 2024 - Beyond Recommender An Exploratory Study of the Ef.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/H7B39F8X/2403.html}
}

@article{masonDialecticalApproachStrategic1969,
  title = {A {{Dialectical Approach}} to {{Strategic Planning}}},
  author = {Mason, Richard O.},
  year = {1969},
  month = apr,
  journal = {Management Science},
  volume = {15},
  number = {8},
  pages = {B-403},
  publisher = {INFORMS},
  issn = {0025-1909},
  doi = {10.1287/mnsc.15.8.B403},
  urldate = {2024-07-18},
  abstract = {This paper develops a new approach to the planning process. It begins by examining the critical role played by the planner's assumptions. Two criteria for a good planning technique are suggested by this examination: (1) It should expose the assumptions underlying a proposed plan so that management can reconsider them and (2) it should suggest new and more relevant assumptions upon which the planning process can proceed. Existing techniques often fail these criteria. Consequently a dialectical approach is presented which, it is proposed, satisfies the stated criteria. The realm of corporate strategic planning was chosen as a testing ground for the new approach. Evidence obtained in a field study/experiment concerning RMK Abrasives' strategic planning problem is cited in support of the method and its ability to reveal assumptions.1}
}

@article{mastGenderDifferencesSimilarities2001,
  title = {Gender {{Differences}} and {{Similarities}} in {{Dominance Hierarchies}} in {{Same-Gender Groups Based}} on {{Speaking Time}}},
  author = {Mast, Marianne Schmid},
  year = {2001},
  month = may,
  journal = {Sex Roles},
  volume = {44},
  number = {9},
  pages = {537--556},
  issn = {1573-2762},
  doi = {10.1023/A:1012239024732},
  urldate = {2024-07-19},
  abstract = {This study aimed at investigating whether all-women and all-men groups differed in their hierarchical organization and stability of their rank orders across time. One hundred and sixteen European, middle-class, noncollege women and men (average age: 38) participated in small-group discussions twice within a week with the same group members. Speaking time served as the behavioral dominance indicator on which group hierarchies were based. Additionally, group members rank ordered each other on dominance after each interaction. In the first session, all-men groups were more hierarchically structured than all-women groups. During each session, all-women and all-men groups showed a similar significant increase in hierarchical structuring. For both women and men, rank orders remained stable during interactions and from the first to the second session. Results are discussed in terms of three theoretical models describing dominance hierarchies.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/EQI8BDZ6/Mast - 2001 - Gender Differences and Similarities in Dominance H.pdf}
}

@misc{mattuMachineBias,
  title = {Machine {{Bias}}},
  author = {Mattu, Jeff Larson,Lauren Kirchner,Surya, Julia Angwin},
  journal = {ProPublica},
  urldate = {2024-07-17},
  abstract = {There's software used across the country to predict future criminals. And it's biased against blacks.},
  howpublished = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/NVTR349N/machine-bias-risk-assessments-in-criminal-sentencing.html}
}

@inproceedings{maWhoShouldTrust2023,
  title = {Who {{Should I Trust}}: {{AI}} or {{Myself}}? {{Leveraging Human}} and {{AI Correctness Likelihood}} to {{Promote Appropriate Trust}} in {{AI-Assisted Decision-Making}}},
  shorttitle = {Who {{Should I Trust}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Ma, Shuai and Lei, Ying and Wang, Xinru and Zheng, Chengbo and Shi, Chuhan and Yin, Ming and Ma, Xiaojuan},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--19},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581058},
  urldate = {2024-07-17},
  abstract = {In AI-assisted decision-making, it is critical for human decision-makers to know when to trust AI and when to trust themselves. However, prior studies calibrated human trust only based on AI confidence indicating AI's correctness likelihood (CL) but ignored humans' CL, hindering optimal team decision-making. To mitigate this gap, we proposed to promote humans' appropriate trust based on the CL of both sides at a task-instance level. We first modeled humans' CL by approximating their decision-making models and computing their potential performance in similar instances. We demonstrated the feasibility and effectiveness of our model via two preliminary studies. Then, we proposed three CL exploitation strategies to calibrate users' trust explicitly/implicitly in the AI-assisted decision-making process. Results from a between-subjects experiment (N=293) showed that our CL exploitation strategies promoted more appropriate human trust in AI, compared with only using AI confidence. We further provided practical implications for more human-compatible AI-assisted decision-making.},
  isbn = {978-1-4503-9421-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/IFF228EQ/Ma et al. - 2023 - Who Should I Trust AI or Myself Leveraging Human.pdf}
}

@inproceedings{mayerInfluenceStereotypicHumanoid2023,
  title = {Influence of {{Stereotypic Humanoid Agents}} on {{Robotic Touches}} in {{Virtual Reality}}},
  booktitle = {Proceedings of the 11th {{International Conference}} on {{Human-Agent Interaction}}},
  author = {Mayer, Manuel and Sawabe, Taishi and Kanbara, Masayuki and Fujimoto, Yuichiro and Kato, Hirokazu},
  year = {2023},
  month = dec,
  series = {{{HAI}} '23},
  pages = {359--361},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3623809.3623925},
  urldate = {2024-07-19},
  abstract = {Previous research has shown that many factors in a virtual environment influence the way, how we perceive interaction with humanoid agents. It is still unknown if visual stereotypes also translate into human-robot interaction scenarios. To investigate this relationship, we conducted a two-part user study with 26 participants using the Stereotype Content Model (SCM) to identify different stereotypical avatars and visual features in terms of their effect on the perception of robot touch. We found that humanoid avatars which resemble the robot and are perceived as warm in the SCM are more liked and preferred than cold avatars. We also found different effects of visual appearance on touch perception. This suggests that a humanoid-stereotpyical appearance of a touch-care robot in virtual reality can change the overall perception of the interaction. We propose the use of stereotypical warm avatars as described in the SCM for humanity-based applications.},
  isbn = {9798400708244}
}

@inproceedings{mcbeathNotMyGumdrop2017,
  title = {Not My {{Gumdrop Buttons}}! {{Youth Tool Use}} in {{Designing}} an {{Electronic Shrek-themed Bean Bag Toss}}},
  booktitle = {Proceedings of the 2017 {{Conference}} on {{Interaction Design}} and {{Children}}},
  author = {McBeath, Jasmine K. and Dur{\'a}n, Richard P. and Harlow, Danielle B.},
  year = {2017},
  month = jun,
  series = {{{IDC}} '17},
  pages = {61--72},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3078072.3079721},
  urldate = {2024-07-19},
  abstract = {The Maker Movement, with a novel approach to learning and conceptualizing science, could potentially increase representation from groups traditionally alienated by mainstream science. However, only a few studies have been conducted on underrepresented groups' participation in Maker projects. In this paper, we explore how a group of Latina youths, who initially expressed an aversion to STEM and had limited knowledge about circuits, created an electronic bean bag toss. Cultural Historical Activity Theory (CHAT) provided insight into how the girls delegated and accomplished Maker tasks, used or repurposed tools, and developed expertise. Analyzing video data, student work, and group exit interviews revealed the use of non-technical terms or "insider labels" for tools described within the group. The girls were aware of their switch to more scientific language when posting online and preparing for presentations. Similarly, the young women demonstrated distinct forms of comprehension within the group when creating the project (functional understanding) versus explaining to others beyond the group (conceptual understanding).},
  isbn = {978-1-4503-4921-5}
}

@article{mcneeseTeamingSyntheticTeammate2018,
  title = {Teaming {{With}} a {{Synthetic Teammate}}: {{Insights}} into {{Human-Autonomy Teaming}}},
  shorttitle = {Teaming {{With}} a {{Synthetic Teammate}}},
  author = {McNeese, Nathan J. and Demir, Mustafa and Cooke, Nancy J. and Myers, Christopher},
  year = {2018},
  month = mar,
  journal = {Human Factors},
  volume = {60},
  number = {2},
  pages = {262--273},
  publisher = {SAGE Publications Inc},
  issn = {0018-7208},
  doi = {10.1177/0018720817743223},
  urldate = {2024-07-19},
  abstract = {ObjectiveThree different team configurations are compared with the goal of better understanding human-autonomy teaming (HAT).BackgroundAlthough an extensive literature on human-automation interaction exists, much less is known about HAT in which humans and autonomous agents interact as coordinated units. Further research must be conducted to better understand how all-human teams compare to HAT.MethodsIn an unmanned aerial system (UAS) context, a comparison was made among three types of three-member teams: (1) synthetic teams in which the pilot role is assigned to a synthetic teammate, (2) control teams in which the pilot was an inexperienced human, and (3) experimenter teams in which an experimenter served as an experienced pilot. Ten of each type of team participated. Measures of team performance, target processing efficiency, team situation awareness, and team verbal behaviors were analyzed.ResultsSynthetic teams performed as well at the mission level as control (all human) teams but processed targets less efficiently. Experimenter teams performed better across all other measures compared to control and synthetic teams.ConclusionThough there is potential for a synthetic agent to function as a full-fledged teammate, further advances in autonomy are needed to improve team-level dynamics in HAT teams.ApplicationThis research contributes to our understanding of how to make autonomy a good team player.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/Q6VXD4SD/McNeese et al. - 2018 - Teaming With a Synthetic Teammate Insights into H.pdf}
}

@article{mcneeseTrustTeamPerformance2021,
  title = {Trust and {{Team Performance}} in {{Human}}--{{Autonomy Teaming}}},
  author = {McNeese, Nathan J. and Demir, Mustafa and Chiou, Erin K. and Cooke, Nancy J.},
  year = {2021},
  month = jan,
  journal = {International Journal of Electronic Commerce},
  volume = {25},
  number = {1},
  pages = {51--72},
  publisher = {Routledge},
  issn = {1086-4415},
  doi = {10.1080/10864415.2021.1846854},
  urldate = {2024-07-19},
  abstract = {This study aims to better understand trust in human--autonomy teams, finding that trust is important for team performance. A Wizard of Oz approach was used to simulate an autonomous agent team member, in a remotely piloted aircraft system research environment, to study the relationship between trust and team performance in human--autonomy teams. Results show that (1) there are lower levels of trust in the autonomous agent in low-performing teams compared with medium- or high-performing teams; (2) there is a loss of trust in the autonomous agent over time across low-, medium-, and high-performing teams; and (3) both low- and medium-performing teams indicated lower levels of trust in their human team members. These findings indicate that trust in a teammate (autonomous or human) is associated with team performance and that trust may evolve over time irrespective of team performance.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/E4JBCX2P/McNeese et al. - 2021 - Trust and Team Performance in Human–Autonomy Teami.pdf}
}

@article{mcneeseWhoWhatMy2021,
  title = {Who/{{What Is My Teammate}}? {{Team Composition Considerations}} in {{Human}}--{{AI Teaming}}},
  shorttitle = {Who/{{What Is My Teammate}}?},
  author = {McNeese, Nathan J. and Schelble, Beau G. and Canonico, Lorenzo Barberis and Demir, Mustafa},
  year = {2021},
  month = aug,
  journal = {IEEE Transactions on Human-Machine Systems},
  volume = {51},
  number = {4},
  pages = {288--299},
  issn = {2168-2305},
  doi = {10.1109/THMS.2021.3086018},
  urldate = {2024-08-11},
  abstract = {There are many unknowns regarding the characteristics and dynamics of human-AI teams, including a lack of understanding of how certain human-human teaming concepts may or may not apply to human-AI teams and how this composition affects team performance. This article outlines an experimental research study that investigates essential aspects of human-AI teaming such as team performance, team situation awareness, and perceived team cognition in various mixed composition teams (human-only, human-human-AI, human-AI-AI, and AI-only) through a simulated emergency response management scenario. Results indicate dichotomous outcomes regarding perceived team cognition and performance metrics, as perceived team cognition was not predictive of performance. Performance metrics like team situational awareness and team score showed that teams composed of all human participants performed at a lower level than mixed human-AI teams, with the AI-only teams attaining the highest performance. Perceived team cognition was highest in human-only teams, with mixed composition teams reporting perceived team cognition 58\% below the all-human teams. These results inform future mixed teams of the potential performance gains in utilizing mixed teams' over human-only teams in certain applications, while also highlighting mixed teams' adverse effects on perceived team cognition.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/TESMJJ4K/McNeese et al. - 2021 - WhoWhat Is My Teammate Team Composition Consider.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/HWPF2HEJ/9474953.html}
}

@incollection{meineckeRobotYouUnemployed2018,
  title = {`{{I Robot}}, {{You Unemployed}}': {{Science-Fiction}} and {{Robotics}} in the {{Media}}},
  shorttitle = {`{{I Robot}}, {{You Unemployed}}'},
  author = {Meinecke, Lisa and Voss, Laura},
  year = {2018},
  month = jul,
  abstract = {https://www.ssoar.info/ssoar/handle/document/58220}
}

@article{metcalfeGenderingTeamworkReWriting2003,
  title = {Gendering {{Teamwork}}: {{Re-Writing}} the {{Feminine}}},
  shorttitle = {Gendering {{Teamwork}}},
  author = {Metcalfe, Beverly and Linstead, Alison},
  year = {2003},
  journal = {Gender, Work \& Organization},
  volume = {10},
  number = {1},
  pages = {94--119},
  issn = {1468-0432},
  doi = {10.1111/1468-0432.00005},
  urldate = {2024-07-19},
  abstract = {Recognizing the neglect of gender in the prescriptive and critical fields of teamwork, this article explores the gendered processes of teams. The argument presented in this article challenges masculinist discourse inherent in team theorizing and empirical research. This masculinism, we argue, stems from the so-called gender-neutral performance criteria and practices of team organization and management. Analysing The Wisdom of Teams (Katzenbach and Smith, 1993) highlights the implicit gendering processes of the team rhetoric. To illuminate the latent gendered practices a case study, Nylons, is discussed. Both methods of analysis unveil the dominance of masculinist discourses that subjugates and suppresses femaleness and femininity. The article concludes by highlighting areas for furthering critical debates in the teamwork arena that centre on analysing the complex and ambiguous power relations that influence, and are influenced by, the construction and re-construction of gendered identities in teamwork and the gendered relations of power in teamwork practice.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/D4LAKPWN/Metcalfe and Linstead - 2003 - Gendering Teamwork Re-Writing the Feminine.pdf}
}

@article{meyersMinorityGroupIdeological1984,
  title = {Minority {{Group}}: {{An Ideological Formulation}}*},
  shorttitle = {Minority {{Group}}},
  author = {Meyers, Barton},
  year = {1984},
  month = oct,
  journal = {Social Problems},
  volume = {32},
  number = {1},
  pages = {1--15},
  issn = {0037-7791},
  doi = {10.2307/800258},
  urldate = {2024-07-19},
  abstract = {This paper traces the process by which the term minority group was derived from its predecessor, national minority, and came to be used as a general term for all groups subjected to prejudice and discrimination. The historical context in which the evolution of the term occurred was shaped by political factors with both domestic and international aspects that influenced the choice of the term. I discuss the conceptual shortcomings of the term, show how it implies a contestable theory of prejudice and discrimination, and analyze it as an ideological formulation. In conclusion, I propose its replacement by the term oppressed group.}
}

@article{mieczkowskiAIMediatedCommunicationLanguage2021,
  title = {{{AI-Mediated Communication}}: {{Language Use}} and {{Interpersonal Effects}} in a {{Referential Communication Task}}},
  shorttitle = {{{AI-Mediated Communication}}},
  author = {Mieczkowski, Hannah and Hancock, Jeffrey T. and Naaman, Mor and Jung, Malte and Hohenstein, Jess},
  year = {2021},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  number = {CSCW1},
  pages = {17:1--17:14},
  doi = {10.1145/3449091},
  urldate = {2024-07-21},
  abstract = {AI-Mediated Communication (AI-MC) is interpersonal communication that involves an artificially intelligent system that can modify, augment, or even generate content to achieve communicative and relational goals. AI-MC is increasingly involved in human communication and has the potential to impact core aspects of human communication, such as language production, interpersonal perception and task performance. Through a between-subjects experimental design we examine how these processes are influenced when integrating AI-generated language in the form of suggested text responses (Google's smart replies) into a text-based referential communication task. Our study replicates and extends the impacts of a positivity bias in AI-generated language and introduces the adjacency pair framework into the study of AI-MC. We also find preliminary yet mixed evidence to suggest that AI-generated language has the potential to undermine some dimensions of interpersonal perception, such as social attraction. This study contributes important concepts for future work in AI-MC and offers findings with implications for the design of AI systems in human-to-human communication.}
}

@article{mieczkowskiAIMediatedCommunicationLanguage2021a,
  title = {{{AI-Mediated Communication}}: {{Language Use}} and {{Interpersonal Effects}} in a {{Referential Communication Task}}},
  shorttitle = {{{AI-Mediated Communication}}},
  author = {Mieczkowski, Hannah and Hancock, Jeffrey T. and Naaman, Mor and Jung, Malte and Hohenstein, Jess},
  year = {2021},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  number = {CSCW1},
  pages = {17:1--17:14},
  doi = {10.1145/3449091},
  urldate = {2025-01-08},
  abstract = {AI-Mediated Communication (AI-MC) is interpersonal communication that involves an artificially intelligent system that can modify, augment, or even generate content to achieve communicative and relational goals. AI-MC is increasingly involved in human communication and has the potential to impact core aspects of human communication, such as language production, interpersonal perception and task performance. Through a between-subjects experimental design we examine how these processes are influenced when integrating AI-generated language in the form of suggested text responses (Google's smart replies) into a text-based referential communication task. Our study replicates and extends the impacts of a positivity bias in AI-generated language and introduces the adjacency pair framework into the study of AI-MC. We also find preliminary yet mixed evidence to suggest that AI-generated language has the potential to undermine some dimensions of interpersonal perception, such as social attraction. This study contributes important concepts for future work in AI-MC and offers findings with implications for the design of AI systems in human-to-human communication.},
  annotation = {TLDR: This study replicates and extends the impacts of a positivity bias in AI-generated language and introduces the adjacency pair framework into the study of AI-MC.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/FSG5KRY6/Mieczkowski et al. - 2021 - AI-Mediated Communication Language Use and Interpersonal Effects in a Referential Communication Tas.pdf}
}

@inproceedings{milanaChatbotsAdvisersEffects2023,
  title = {Chatbots as {{Advisers}}: The {{Effects}} of {{Response Variability}} and {{Reply Suggestion Buttons}}},
  shorttitle = {Chatbots as {{Advisers}}},
  booktitle = {Proceedings of the 5th {{International Conference}} on {{Conversational User Interfaces}}},
  author = {Milana, Federico and Costanza, Enrico and Fischer, Joel E},
  year = {2023},
  month = jul,
  series = {{{CUI}} '23},
  pages = {1--10},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3571884.3597132},
  urldate = {2025-01-07},
  abstract = {As chatbots gain popularity across a variety of applications, from investment to health, they employ an increasing number of features that can influence the perception of the system. Since chatbots often provide advice or guidance, we ask: do these aspects affect the user's decision to follow their advice? We focus on two chatbot features that can influence user perception: 1) response variability in answers and delays and 2) reply suggestion buttons. We report on a between-subject study where participants made investment decisions on a simulated social trading platform by interacting with a chatbot providing advice. Performance-based study incentives made the consequences of following the advice tangible to participants. We measured how often and to what extent participants followed the chatbot's advice compared to an alternative source of information. Results indicate that both response variability and reply suggestion buttons significantly increased the inclination to follow the advice of the chatbot.},
  isbn = {9798400700149},
  annotation = {TLDR: Results indicate that both response variability in answers and delays and reply suggestion buttons significantly increased the inclination to follow the advice of the chatbot.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/PFZHH2A9/Milana et al. - 2023 - Chatbots as Advisers the Effects of Response Variability and Reply Suggestion Buttons.pdf}
}

@article{milgramBehavioralStudyObedience1963,
  title = {Behavioral {{Study}} of Obedience},
  author = {Milgram, Stanley},
  year = {1963},
  journal = {The Journal of Abnormal and Social Psychology},
  volume = {67},
  number = {4},
  pages = {371--378},
  publisher = {American Psychological Association},
  address = {US},
  issn = {0096-851X},
  doi = {10.1037/h0040525},
  abstract = {This articles describes a procedure for the study of destructive obedience in the laboratory. It consists of ordering a naive S to administer increasingly more severe punishment to a victim in the context of a learning experiment. Punishment is administered by means of a shock generator with 30 graded switches ranging from Slight Shock to Danger: Severe Shock. The victim is a confederate of the E. The primary dependent variable is the maximum shock the S is willing to administer before he refuses to continue further. 26 Ss obeyed the experimental commands fully, and administered the highest shock on the generator. 14 Ss broke off the experiment at some point after the victim protested and refused to provide further answers. The procedure created extreme levels of nervous tension in some Ss. Profuse sweating, trembling, and stuttering were typical expressions of this emotional disturbance. One unexpected sign of tension---yet to be explained---was the regular occurrence of nervous laughter, which in some Ss developed into uncontrollable seizures. The variety of interesting behavioral dynamics observed in the experiment, the reality of the situation for the S, and the possibility of parametric variation within the framework of the procedure, point to the fruitfulness of further study. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/R3Z9R3ZQ/1964-03472-001.html}
}

@article{milkmanWhatHappensField2015,
  title = {What Happens before? {{A}} Field Experiment Exploring How Pay and Representation Differentially Shape Bias on the Pathway into Organizations},
  shorttitle = {What Happens Before?},
  author = {Milkman, Katherine L. and Akinola, Modupe and Chugh, Dolly},
  year = {2015},
  journal = {Journal of Applied Psychology},
  volume = {100},
  number = {6},
  pages = {1678--1712},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1854},
  doi = {10.1037/apl0000022},
  abstract = {Little is known about how discrimination manifests before individuals formally apply to organizations or how it varies within and between organizations. We address this knowledge gap through an audit study in academia of over 6,500 professors at top U.S. universities drawn from 89 disciplines and 259 institutions. In our experiment, professors were contacted by fictional prospective students seeking to discuss research opportunities prior to applying to a doctoral program. Names of students were randomly assigned to signal gender and race (White, Black, Hispanic, Indian, Chinese), but messages were otherwise identical. We hypothesized that discrimination would appear at the informal ``pathway'' preceding entry to academia and would vary by discipline and university as a function of faculty representation and pay. We found that when considering requests from prospective students seeking mentoring in the future, faculty were significantly more responsive to White males than to all other categories of students, collectively, particularly in higher-paying disciplines and private institutions. Counterintuitively, the representation of women and minorities and discrimination were uncorrelated, a finding that suggests greater representation cannot be assumed to reduce discrimination. This research highlights the importance of studying decisions made before formal entry points into organizations and reveals that discrimination is not evenly distributed within and between organizations. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/D7ICZXJH/2015-15680-001.html}
}

@inproceedings{millerExplainableAIDead2023,
  title = {Explainable {{AI}} Is {{Dead}}, {{Long Live Explainable AI}}! {{Hypothesis-driven Decision Support}} Using {{Evaluative AI}}},
  booktitle = {Proceedings of the 2023 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Miller, Tim},
  year = {2023},
  month = jun,
  series = {{{FAccT}} '23},
  pages = {333--342},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3593013.3594001},
  urldate = {2024-07-17},
  abstract = {In this paper, we argue for a paradigm shift from the current model of explainable artificial intelligence (XAI), which may be counter-productive to better human decision making. In early decision support systems, we assumed that we could give people recommendations and that they would consider them, and then follow them when required. However, research found that people often ignore recommendations because they do not trust them; or perhaps even worse, people follow them blindly, even when the recommendations are wrong. Explainable artificial intelligence mitigates this by helping people to understand how and why models give certain recommendations. However, recent research shows that people do not always engage with explainability tools enough to help improve decision making. The assumption that people will engage with recommendations and explanations has proven to be unfounded. We argue this is because we have failed to account for two things. First, recommendations (and their explanations) take control from human decision makers, limiting their agency. Second, giving recommendations and explanations does not align with the cognitive processes employed by people making decisions. This position paper proposes a new conceptual framework called Evaluative AI for explainable decision support. This is a machine-in-the-loop paradigm in which decision support tools provide evidence for and against decisions made by people, rather than provide recommendations to accept or reject. We argue that this mitigates issues of over- and under-reliance on decision support tools, and better leverages human expertise in decision making.},
  isbn = {9798400701924}
}

@inproceedings{mirowskiCoWritingScreenplaysTheatre2023,
  title = {Co-{{Writing Screenplays}} and {{Theatre Scripts}} with {{Language Models}}: {{Evaluation}} by {{Industry Professionals}}},
  shorttitle = {Co-{{Writing Screenplays}} and {{Theatre Scripts}} with {{Language Models}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Mirowski, Piotr and Mathewson, Kory W. and Pittman, Jaylen and Evans, Richard},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--34},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581225},
  urldate = {2025-01-21},
  abstract = {Language models are increasingly attracting interest from writers. However, such models lack long-range semantic coherence, limiting their usefulness for longform creative writing. We address this limitation by applying language models hierarchically, in a system we call Dramatron. By building structural context via prompt chaining, Dramatron can generate coherent scripts and screenplays complete with title, characters, story beats, location descriptions, and dialogue. We illustrate Dramatron's usefulness as an interactive co-creative system with a user study of 15 theatre and film industry professionals. Participants co-wrote theatre scripts and screenplays with Dramatron and engaged in open-ended interviews. We report reflections both from our interviewees and from independent reviewers who critiqued performances of several of the scripts to illustrate how both Dramatron and hierarchical text generation could be useful for human-machine co-creativity. Finally, we discuss the suitability of Dramatron for co-creativity, ethical considerations---including plagiarism and bias---and participatory models for the design and deployment of such tools.},
  isbn = {978-1-4503-9421-5},
  annotation = {TLDR: Dramatron can generate coherent scripts and screenplays complete with title, characters, story beats, location descriptions, and dialogue, in a system that applies language models hierarchically and illustrates its usefulness as an interactive co-creative system with a user study of 15 theatre and film industry professionals.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/ZN5U9ITF/Mirowski et al. - 2023 - Co-Writing Screenplays and Theatre Scripts with Language Models Evaluation by Industry Professional.pdf}
}

@inproceedings{mokPlaceEveryTool2015,
  title = {A Place for Every Tool and Every Tool in Its Place: {{Performing}} Collaborative Tasks with Interactive Robotic Drawers},
  shorttitle = {A Place for Every Tool and Every Tool in Its Place},
  booktitle = {2015 24th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}} ({{RO-MAN}})},
  author = {Mok, Brian Ka-Jun and Yang, Stephen and Sirkin, David and Ju, Wendy},
  year = {2015},
  month = aug,
  pages = {700--706},
  doi = {10.1109/ROMAN.2015.7333680},
  urldate = {2024-07-18},
  abstract = {In this study, we examined how participants (N=20) interacted and collaborated with a set of robotic drawers to accomplish an assembly task. The drawers' behavior varied along two dimensions - proactivity and expressivity of motions. The results of our study indicate that participants consider an expressive robot to be more involved and interested in the interaction. We also found that while proactive or expressive robots could dominate the interaction, proactivity might negatively affect the participants' perception of their social status relative to that of the robot's, while expressiveness did not. This shows the importance of utilizing expressive movements when designing socially appropriate robots that collaborate with human users.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/V7FIRQFG/Mok et al. - 2015 - A place for every tool and every tool in its place.pdf}
}

@article{mollicaRacialHomophilyIts2003,
  title = {Racial {{Homophily}} and {{Its Persistence}} in {{Newcomers}}' {{Social Networks}}},
  author = {Mollica, Kelly A. and Gray, Barbara and Trevi{\~n}o, Linda K.},
  year = {2003},
  month = mar,
  journal = {Organization Science},
  volume = {14},
  number = {2},
  pages = {123--136},
  issn = {1526-5455},
  doi = {10.1287/orsc.14.2.123.14994},
  urldate = {2024-07-19},
  abstract = {This study examined the formation and persistence of homophilous, or same-race, friendship ties among racial minorities and whites in a "newcomer" setting. Homophilous ties provide valuable sources of mutual support but may limit racial minorities' access to resources and information in organizations. Study participants were first-year MBA students who entered a program at the same time. We measured network ties at two times: six weeks after the beginning of the students' first semester in the program, and at the beginning of the following semester 3 1/2 months after the second survey. We also administered a separate survey measuring social identity salience prior to the first network survey.Despite the fact that there were fewer same-race ties for racial minorities to choose from, their friendship networks demonstrated greater homophily than those of whites early in the formation of the network and over time. Also, African-Americans were more likely than whites to seek out homophilous friendship ties in other class sections. Race as a salient social identity group membership was positively related to homophily for African-Americans, Hispanics, and whites. Over the time period studied there was no significant change in homophily among the racial groups' networks, despite the explicit promotion of diversity in recruitment of students, formation of heterogeneous classes and teams, and active support by the MBA program administrators. We discuss the practical implications of our findings for organizations that are attempting to increase cultural diversity and promote active interaction among individuals from different racial and ethnic backgrounds.}
}

@article{moral-toranzoAnonymityEffectsComputermediated2007,
  title = {Anonymity Effects in Computer-Mediated Communication in the Case of Minority Influence},
  author = {{Moral-Toranzo}, F{\'e}lix and {Canto-Ortiz}, Jes{\'u}s and {G{\'o}mez-Jacinto}, Luis},
  year = {2007},
  month = may,
  journal = {Computers in Human Behavior},
  series = {Including the {{Special Issue}}: {{Avoiding Simplicity}}, {{Confronting Complexity}}: {{Advances}} in {{Designing Powerful Electronic Learning Environments}}},
  volume = {23},
  number = {3},
  pages = {1660--1674},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2005.09.002},
  urldate = {2024-06-19},
  abstract = {In an experimental study, we analyzed in-group minority social influence within the context of computer-mediated communication (CMC) based on the perspective of the social identity model of deindividuation effects (SIDE). This model hypothesizes that in a group context, in which social identity is salient, anonymity will facilitate influence among the group members. Using a software application, we simulated the creation of a virtual group and the setting of a computer-mediated communication. The interaction between the members of the group centers on the issue of North African immigration. The results show that the influence of an in-group minority (radical pro-immigration) causes changes of opinion, as demonstrated in the two groups participating in the experimental test (anonymous and identifiable users). However, the differences in such changes between the identifiable and the anonymous groups are not statistically significant, whereas for two dependent variables from the opinion questionnaire, (i.e., ``strong'' anti-immigration and pro-immigration), they are significant when these two groups are compared to the control group. Therefore, the postulates of the SIDE model are only partially confirmed. We offer some explanations for the results obtained, and outline different aspects involved in the process of social influence via CMC.},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/7KNZ9W53/S0747563205000749.html}
}

@article{morelandAreDyadsReally2010,
  title = {Are {{Dyads Really Groups}}?},
  author = {Moreland, Richard L.},
  year = {2010},
  month = apr,
  journal = {Small Group Research},
  volume = {41},
  number = {2},
  pages = {251--267},
  publisher = {SAGE Publications Inc},
  issn = {1046-4964},
  doi = {10.1177/1046496409358618},
  urldate = {2024-07-18},
  abstract = {Social scientists who study groups disagree about whether (and to what extent) dyads ought to be included in their work. In this article, I argue that dyads are not really groups because (a) dyads are more ephemeral than groups, forming and dissolving more quickly; (b) people feel stronger (and often different) emotions in dyads than in groups; (c) dyads are simpler than groups---some group phenomena cannot occur in dyads, and those that do may operate differently there; and (d) research on dyads is carried out almost independently (by different people, applying different theories and methods, and publishing their work in different outlets) from research on groups. I also review some of the conceptual and methodological problems that can arise when dyads are mistakenly viewed as groups.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/UPBAQ65Z/Moreland - 2010 - Are Dyads Really Groups.pdf}
}

@article{moscoviciStudiesSocialInfluence1976,
  title = {Studies in Social Influence {{III}}: {{Majority}} versus Minority Influence in a Group},
  shorttitle = {Studies in Social Influence {{III}}},
  author = {Moscovici, Serge and Lage, Elisabeth},
  year = {1976},
  journal = {European Journal of Social Psychology},
  volume = {6},
  number = {2},
  pages = {149--174},
  issn = {1099-0992},
  doi = {10.1002/ejsp.2420060202},
  urldate = {2024-08-09},
  abstract = {This experimental study was aimed at investigating the mechanisms of influence involved in the two functionally opposed phenomena of innovation and conformity. We have been concerned for several years with the former of these two phenomena because of its intrinsic importance and the limited amount of research devoted to it. In the present article we have attempted not only to analyse the position more thoroughly, but also to compare the effects of innovation with those of conformity. In particular, we have endeavoured to show that behavioural style acts as a general source of influence in the two phenomena under consideration, where manifest judgments are concerned. On the other hand, the latent effects of influence may be different in the two cases of innovation and conformity. To investigate these questions, we developed an experimental design consisting of three parts. The first part was intended to study manifest influence on a quasi-physical judgment based on a cultural truism. The second part was aimed at the study of latent modifications in the perceptual-cognitive code as a result of influence. The third, in the form of a postexperimental questionnaire, was intended to provide information about various aspects, including the perception of the agent of influence by subjects. The main function of the experimental manipulations was to vary the minority or majority relationship of the agent of influence within a group, and its behavioural style, consistent or inconsistent. Our main findings indicate that behavioural consistency is the main factor behind the influence exerted by both majority and minority. But whereas, in conformity, influence is limited to modifying manifest judgments, in innovation, it changes the perceptual-cognitive code underlying such judgments.},
  copyright = {Copyright {\copyright} 1976 John Wiley \& Sons, Ltd},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/QHXGHPR9/Moscovici and Lage - 1976 - Studies in social influence III Majority versus m.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/RAC2MVNU/ejsp.html}
}

@article{munyakaDecisionMakingStrategies2023,
  title = {Decision {{Making Strategies}} and {{Team Efficacy}} in {{Human-AI Teams}}},
  author = {Munyaka, Imani and Ashktorab, Zahra and Dugan, Casey and Johnson, J. and Pan, Qian},
  year = {2023},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {7},
  number = {CSCW1},
  pages = {43:1--43:24},
  doi = {10.1145/3579476},
  urldate = {2024-07-25},
  abstract = {Human-AI teams are increasingly prevalent in various domains. We investigate how the decision-making of a team member in a human-AI team impacts the outcome of the collaboration and perceived team-efficacy. In a large scale study on Mechanical Turk (n=125), we find significant differences across different decision making styles and disclosed AI identity disclosure in an AI-driven collaborative game. We find that autocratic decision-making negatively impacts team-efficacy in Human-AI teams, similar to its effects on human-only teams. We find that decision making style and AI-identity disclosure impacts how individuals make decisions in a collaborative context. We discuss our findings of the differences of collaborative behavior in human-human-AI teams and human-AI-AI teams.}
}

@inproceedings{muraliImprovingMultipartyInteractions2023,
  title = {Improving {{Multiparty Interactions}} with a {{Robot Using Large Language Models}}},
  booktitle = {Extended {{Abstracts}} of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Murali, Prasanth and Steenstra, Ian and Yun, Hye Sun and Shamekhi, Ameneh and Bickmore, Timothy},
  year = {2023},
  month = apr,
  series = {{{CHI EA}} '23},
  pages = {1--8},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544549.3585602},
  urldate = {2024-07-17},
  abstract = {Speaker diarization is a key component of systems that support multiparty interactions of co-located users, such as meeting facilitation robots. The goal is to identify who spoke what, often to provide feedback, moderate participation, and personalize responses by the robot. Current systems use a combination of acoustic (e.g. pitch differences) and visual features (e.g. gaze) to perform diarization, but involve the use of additional sensors or require overhead signal processing efforts. Alternatively, automatic speech recognition (ASR) is a necessary step in the diarization pipeline, and utilizing the transcribed text to directly identify speaker labels in the conversation can eliminate such challenges. With that motivation, we leverage large language models (LLMs) to identify speaker labels from transcribed text and observe an exact match of 77\% and a word level accuracy of 90\%. We discuss our findings and the potential use of LLMs as a diarization tool for future systems.},
  isbn = {978-1-4503-9422-2}
}

@article{musickWhatHappensWhen2021,
  title = {What {{Happens When Humans Believe Their Teammate}} Is an {{AI}}? {{An Investigation}} into {{Humans Teaming}} with {{Autonomy}}},
  shorttitle = {What {{Happens When Humans Believe Their Teammate}} Is an {{AI}}?},
  author = {Musick, Geoff and O'Neill, Thomas A. and Schelble, Beau G. and McNeese, Nathan J. and Henke, Jonn B.},
  year = {2021},
  month = sep,
  journal = {Computers in Human Behavior},
  volume = {122},
  pages = {106852},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.106852},
  urldate = {2024-07-18},
  abstract = {As artificial intelligence (AI) continues to grow in proficiency, the potential for AI to be used as team members rather than tools is becoming closer to realization. This advancement is driving new research investigations into the applicability of human-human teamwork knowledge to the context of human-autonomy teaming. In the current study, we apply qualitative methods to explore how the perceived composition of a team (how many humans and how many agents on the team) affects sentiments toward teammates, team processes, cognitive states, and the emergence of a system of team cognition. A total of 46 teams completed a teamwork simulation task and were interviewed afterwards regarding their teamwork experience. All of the teams were comprised of only humans; however, two conditions were led to believe that their teammate(s) were autonomous agents. Interviews were analyzed using grounded theory and the Gioia methodology, which revealed thematic differences between the team compositions. In light of our results, we offer a new model that describes how early-stage action teams achieve effective team processes and emergent cognitive states.}
}

@article{musickWhatHappensWhen2021a,
  title = {What {{Happens When Humans Believe Their Teammate}} Is an {{AI}}? {{An Investigation}} into {{Humans Teaming}} with {{Autonomy}}},
  shorttitle = {What {{Happens When Humans Believe Their Teammate}} Is an {{AI}}?},
  author = {Musick, Geoff and O'Neill, Thomas A. and Schelble, Beau G. and McNeese, Nathan J. and Henke, Jonn B.},
  year = {2021},
  month = sep,
  journal = {Computers in Human Behavior},
  volume = {122},
  pages = {106852},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.106852},
  urldate = {2024-07-19},
  abstract = {As artificial intelligence (AI) continues to grow in proficiency, the potential for AI to be used as team members rather than tools is becoming closer to realization. This advancement is driving new research investigations into the applicability of human-human teamwork knowledge to the context of human-autonomy teaming. In the current study, we apply qualitative methods to explore how the perceived composition of a team (how many humans and how many agents on the team) affects sentiments toward teammates, team processes, cognitive states, and the emergence of a system of team cognition. A total of 46 teams completed a teamwork simulation task and were interviewed afterwards regarding their teamwork experience. All of the teams were comprised of only humans; however, two conditions were led to believe that their teammate(s) were autonomous agents. Interviews were analyzed using grounded theory and the Gioia methodology, which revealed thematic differences between the team compositions. In light of our results, we offer a new model that describes how early-stage action teams achieve effective team processes and emergent cognitive states.}
}

@article{myaskovskyEffectsGenderDiversity2005,
  title = {Effects of {{Gender Diversity}} on {{Performance}} and {{Interpersonal Behavior}} in {{Small Work Groups}}},
  author = {Myaskovsky, Larissa and Unikel, Emily and Dew, Mary Amanda},
  year = {2005},
  month = may,
  journal = {Sex Roles},
  volume = {52},
  number = {9-10},
  pages = {645--657},
  issn = {0360-0025, 1573-2762},
  doi = {10.1007/s11199-005-3732-8},
  urldate = {2024-07-19},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/7ZIBN7DT/Myaskovsky et al. - 2005 - Effects of Gender Diversity on Performance and Int.pdf}
}

@article{myersEnhancementDominantAttitudes1971,
  title = {Enhancement of Dominant Attitudes in Group Discussion},
  author = {Myers, David G. and Bishop, George D.},
  year = {1971},
  journal = {Journal of Personality and Social Psychology},
  volume = {20},
  number = {3},
  pages = {386--391},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1315},
  doi = {10.1037/h0031920},
  abstract = {Attempted to generalize the risky-cautious-shift phenomenon to attitudes and to test "information exchange" and "mutual reinforcement" explanations of discussion-produced shifts. Study i with 118 undergraduates confirmed an assumption of the information-exchange hypothesis by extending to the attitude realm the finding that ss perceive their peers as less in the valued direction than themselves. In study ii with 160 ss, 8 of these items were responded to before and after treatment by ss in discussion, information-exchange, and control conditions. Only discussion-condition groups evidenced significant attitude shifts and polarization effects. Tape recordings of the discussions indicate that a group's initial mean on an item was a significant predictor of the direction of the discussion rhetoric, which in turn was a predictor of group shifts. However, group initial mean did not directly predict group shifts. (20 ref.) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/A4RQ9HVA/1972-08796-001.html}
}

@article{nadeauNewEvidenceExistence1993,
  title = {New {{Evidence About}} the {{Existence}} of a {{Bandwagon Effect}} in the {{Opinion Formation Process}}},
  author = {Nadeau, Richard and Cloutier, Edouard and Guay, J.-H.},
  year = {1993},
  month = apr,
  journal = {International Political Science Review},
  volume = {14},
  number = {2},
  pages = {203--213},
  publisher = {SAGE Publications Ltd},
  issn = {0192-5121},
  doi = {10.1177/019251219301400204},
  urldate = {2024-07-18},
  abstract = {This study undertakes an empirical test of the "bandwagon effect"---individuals rallying to the majority opinion. The study is done outside the electoral context on two issues: abortion and the constitutional future of Quebec. A panel is used, as well as an experimental design in which respondents are told the state and direction of public opinion. Three methodological criteria are used as minimal requirements for a satisfac tory test of the bandwagon thesis. "Underdogging," as well as opinion movement due to factors outside the experiment, are both accounted for. Though the reasons for a bandwagon remain unclear, the authors demon strate that a bandwagon effect of 5-7 percent existed on both issues.},
  langid = {english}
}

@article{nassCanComputersBe1996,
  title = {Can Computers Be Teammates?},
  author = {Nass, Clifford and Fogg, B. J. and Moon, Youngme},
  year = {1996},
  month = dec,
  journal = {Int. J. Hum.-Comput. Stud.},
  volume = {45},
  number = {6},
  pages = {669--678},
  issn = {1071-5819},
  doi = {10.1006/ijhc.1996.0073},
  urldate = {2024-07-19}
}

@inproceedings{nassComputersAreSocial1994,
  title = {Computers Are Social Actors},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Nass, Clifford and Steuer, Jonathan and Tauber, Ellen R.},
  year = {1994},
  month = apr,
  series = {{{CHI}} '94},
  pages = {72--78},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/191666.191703},
  urldate = {2024-07-18},
  isbn = {978-0-89791-650-9}
}

@inproceedings{nassComputersAreSocial1994a,
  title = {Computers Are Social Actors},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Nass, Clifford and Steuer, Jonathan and Tauber, Ellen R.},
  year = {1994},
  month = apr,
  series = {{{CHI}} '94},
  pages = {72--78},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/191666.191703},
  urldate = {2024-07-19},
  isbn = {978-0-89791-650-9}
}

@inproceedings{natarajanEffectsAnthropomorphismAccountability2020,
  title = {Effects of {{Anthropomorphism}} and {{Accountability}} on {{Trust}} in {{Human Robot Interaction}}},
  booktitle = {Proceedings of the 2020 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Natarajan, Manisha and Gombolay, Matthew},
  year = {2020},
  month = mar,
  series = {{{HRI}} '20},
  pages = {33--42},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3319502.3374839},
  urldate = {2024-07-19},
  abstract = {This paper examines how people's trust and dependence on robot teammates providing decision support varies as a function of different attributes of the robot, such as perceived anthropomorphism, type of support provided by the robot, and its physical presence. We conduct a mixed-design user study with multiple robots to investigate trust, inappropriate reliance, and compliance measures in the context of a time-constrained game. We also examine how the effect of human accountability addresses errors due to over-compliance in the context of human robot interaction (HRI). This study is novel as it involves examining multiple attributes at once, thus enabling us to perform multi-way comparisons between different attributes on trust and compliance with the agent. Results from the 4x4x2x2 study show that behavior and anthropomorphism of the agent are the most significant factors in predicting the trust and compliance with the robot. Furthermore, adding a coalition-building preface, where the agent provides context to why it might make errors while giving advice, leads to an increase in trust for specific behaviors of the agent.},
  isbn = {978-1-4503-6746-2}
}

@misc{natarajanHumanintheloopAIintheloopAutomate2024,
  title = {Human-in-the-Loop or {{AI-in-the-loop}}? {{Automate}} or {{Collaborate}}?},
  shorttitle = {Human-in-the-Loop or {{AI-in-the-loop}}?},
  author = {Natarajan, Sriraam and Mathur, Saurabh and Sidheekh, Sahil and Stammer, Wolfgang and Kersting, Kristian},
  year = {2024},
  month = dec,
  number = {arXiv:2412.14232},
  eprint = {2412.14232},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.14232},
  urldate = {2025-01-03},
  abstract = {Human-in-the-loop (HIL) systems have emerged as a promising approach for combining the strengths of data-driven machine learning models with the contextual understanding of human experts. However, a deeper look into several of these systems reveals that calling them HIL would be a misnomer, as they are quite the opposite, namely AI-in-the-loop (\$AI{\textasciicircum}2L\$) systems, where the human is in control of the system, while the AI is there to support the human. We argue that existing evaluation methods often overemphasize the machine (learning) component's performance, neglecting the human expert's critical role. Consequently, we propose an \$AI{\textasciicircum}2L\$ perspective, which recognizes that the human expert is an active participant in the system, significantly influencing its overall performance. By adopting an \$AI{\textasciicircum}2L\$ approach, we can develop more comprehensive systems that faithfully model the intricate interplay between the human and machine components, leading to more effective and robust AI systems.},
  archiveprefix = {arXiv},
  langid = {american},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/FM9BU576/Natarajan et al. - 2024 - Human-in-the-loop or AI-in-the-loop Automate or Collaborate.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/SZHLUW3T/2412.html}
}

@inproceedings{neerincxUsingPerceptualCognitive2018,
  title = {Using {{Perceptual}} and {{Cognitive Explanations}} for {{Enhanced Human-Agent Team Performance}}},
  booktitle = {Engineering {{Psychology}} and {{Cognitive Ergonomics}}: 15th {{International Conference}}, {{EPCE}} 2018, {{Held}} as {{Part}} of {{HCI International}} 2018, {{Las Vegas}}, {{NV}}, {{USA}}, {{July}} 15-20, 2018, {{Proceedings}}},
  author = {Neerincx, Mark A. and {van der Waa}, Jasper and Kaptein, Frank and {van Diggelen}, Jurriaan},
  year = {2018},
  month = jul,
  pages = {204--214},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-319-91122-9_18},
  urldate = {2024-07-19},
  abstract = {Most explainable AI (XAI) research projects focus on well-delineated topics, such as interpretability of machine learning outcomes, knowledge sharing in a multi-agent system or human trust in agent's performance. For the development of explanations in human-agent teams, a more integrative approach is needed. This paper proposes a perceptual-cognitive explanation (PeCoX) framework for the development of explanations that address both the perceptual and cognitive foundations of an agent's behavior, distinguishing between explanation generation, communication and reception. It is a generic framework (i.e., the core is domain-agnostic and the perceptual layer is model-agnostic), and being developed and tested in the domains of transport, health-care and defense. The perceptual level entails the provision of an Intuitive Confidence Measure and the identification of the ``foil'' in a contrastive explanation. The cognitive level entails the selection of the beliefs, goals and emotions for explanations. Ontology Design Patterns are being constructed for the reasoning and communication, whereas Interaction Design Patterns are being constructed for the shaping of the multimodal communication. First results show (1) positive effects on human's understanding of the perceptual and cognitive foundation of agent's behavior, and (2) the need for harmonizing the explanations to the context and human's information processing capabilities.},
  isbn = {978-3-319-91121-2}
}

@article{nemethCreativeProblemSolving1983,
  title = {Creative Problem Solving as a Result of Majority vs Minority Influence},
  author = {Nemeth, Charlan Jeanne and Wachtler, Joel},
  year = {1983},
  journal = {European Journal of Social Psychology},
  volume = {13},
  number = {1},
  pages = {45--55},
  issn = {1099-0992},
  doi = {10.1002/ejsp.2420130103},
  urldate = {2024-07-18},
  abstract = {A comparison of influence processes exerted by a majority versus a minority is made, both theoretically and empirically. In this study, comparing the two processes in the same experimental setting, it was hypothesized that subjects would `follow' the majority more than the minority, that is, they would be more influenced to adopt the exact same position. However, it was predicted that subjects exposed to the minority would be stimulated to find new solutions to the problem, solutions that were not offered by the minority but that the subjects would not have found by themselves. Further, these solutions would tend to be correct rather than incorrect. Results support these predictions.},
  copyright = {Copyright {\copyright} 1983 John Wiley \& Sons, Ltd},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/I69ARMCQ/Nemeth and Wachtler - 1983 - Creative problem solving as a result of majority v.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/H72B72TC/ejsp.html}
}

@article{nemethDevilsAdvocateAuthentic2001,
  title = {Devil's Advocate versus Authentic Dissent: Stimulating Quantity and Quality},
  shorttitle = {Devil's Advocate versus Authentic Dissent},
  author = {Nemeth, Charlan and Brown, Keith and Rogers, John},
  year = {2001},
  journal = {European Journal of Social Psychology},
  volume = {31},
  number = {6},
  pages = {707--720},
  issn = {1099-0992},
  doi = {10.1002/ejsp.58},
  urldate = {2024-07-18},
  abstract = {Given the relationship between uniformity of views, premature adoption of a preferred solution and poor decision making, many suggestions have been aimed at fostering dissent, including the usage of a `devil's advocate.' The hope is that such a mechanism will stimulate the kinds of reconsideration, better information processing and decision making as has been found to be stimulated by authentic dissent. In a prior study comparing these two processes, devil's advocate appeared to foster thinking that was primarily aimed at cognitive bolstering of the initial viewpoint rather than stimulate divergent thought. While that study left the actual position of the DA unknown, the present study compared conditions where the devil's advocate position was known (and consistent or inconsistent with the assigned position) or unknown. It further utilized quantity and quality of solutions as a dependent measure rather than simply cognitive activity. Results indicated that the authentic minority was superior to all three forms of `devil's advocate,' again underscoring the value and importance of authenticity and the difficulty in cloning such authenticity by role-playing techniques. Copyright {\copyright} 2001 John Wiley \& Sons, Ltd.},
  copyright = {Copyright {\copyright} 2001 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/V9IIE97M/Nemeth et al. - 2001 - Devil's advocate versus authentic dissent stimula.pdf}
}

@book{ngSocialPsychologyPower1980,
  title = {The {{Social Psychology}} of {{Power}}},
  author = {Ng, Sik Hung},
  year = {1980},
  publisher = {European Association of Experimental Social Psychology by Academic Press},
  googlebooks = {KEG3AAAAIAAJ},
  isbn = {978-0-12-518180-8},
  langid = {english}
}

@book{okeefePersuasionTheoryResearch2016,
  title = {Persuasion: {{Theory}} and {{Research}}},
  shorttitle = {Persuasion},
  author = {O'Keefe, Daniel James},
  year = {2016},
  publisher = {SAGE Publications, Inc},
  address = {Thousand Oaks, CA},
  abstract = {Persuasion: Theory and Research, Third Edition is a comprehensive overview of social-scientific theory and research on persuasion. Written in a clear and accessible style that assumes no special technical background in research methods, the Third Edition has been thoroughly revised to reflect developments in persuasion studies. New discussions of subjects such as reactance and the use of narratives as vehicles for persuasion, revised treatments of the theories of reasoned action and planned behavior, and two new chapters on social judgment theory and stage models provide your students with the most current work on persuasion in a clear, straightforward manner. In this edition, author Daniel J. O'Keefe has given special attention to the importance of adapting (tailoring) messages to audiences to maximize persuasiveness. Each chapter has a set of review questions to guide students through the chapter's material and quickly master the concepts being introduced.},
  isbn = {978-1-4522-7667-0}
}

@article{oreillyOrganizationalCommitmentPsychological1986,
  title = {Organizational Commitment and Psychological Attachment: {{The}} Effects of Compliance, Identification, and Internalization on Prosocial Behavior},
  shorttitle = {Organizational Commitment and Psychological Attachment},
  author = {O'Reilly, Charles A. and Chatman, Jennifer},
  year = {1986},
  journal = {Journal of Applied Psychology},
  volume = {71},
  number = {3},
  pages = {492--499},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1854},
  doi = {10.1037/0021-9010.71.3.492},
  abstract = {Conducted 2 studies with 82 nonfaculty university employees (mean age 31--40 yrs) and 162 graduating business students at the undergraduate and MBA level to investigate relations among the dimensions of commitment and prescribed and extrarole activities. Survey findings suggest that psychological attachment may be predicated on compliance (instrumental involvement for specific extrinsic rewards), identification (involvement based on a desire for affiliation), and internalization (involvement resulting from congruence between individual and organizational values). Identification and internalization were positively related to prosocial behaviors and negatively related to turnover. Internalization was predictive of financial donations to a fund-raising campaign. Overall, the results indicate the importance of clearly specifying the underlying dimensions of commitment using notions of psychological attachment and the various forms such attachment can take. (48 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{ottEffectsMaleFemaleRatio1989,
  title = {Effects of the {{Male-Female Ratio}} at {{Work}}},
  author = {Ott, E. Marlies},
  year = {1989},
  journal = {Psychology of Women Quarterly},
  volume = {13},
  number = {1},
  pages = {41--57},
  issn = {1471-6402},
  doi = {10.1111/j.1471-6402.1989.tb00984.x},
  urldate = {2024-07-19},
  abstract = {Difficulties faced by women in work organizations are often explained as indirect consequences of their numerical minority. Their sex plays no role in these explanations: Men in a minority position are claimed to experience similar problems. The results of this empirical study challenge this: Policewomen are seen to face many of the disadvantages pointed out by Kanter (1977) and others, whereas male nurses enjoy advantages from being one of the few among female colleagues. Also, while the male majority in police teams do indeed resist women when their number reaches a critical mass, the female majority in the nursing teams do not show a similar resistance to men. The study involved 50 police teams and 49 nursing teams of approximately 15 members each. Comparisons were made only within each occupation, between skewed and tilted settings. Data were gathered by means of 297 semi-structured interviews. The opposite effects on men and women of being in a minority are attributed to a difference in status.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/AYHNQSNA/Ott - 1989 - Effects of the Male-Female Ratio at Work.pdf}
}

@article{ouyangTrainingLanguageModels2022,
  title = {Training Language Models to Follow Instructions with Human Feedback},
  author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F. and Leike, Jan and Lowe, Ryan},
  year = {2022},
  month = dec,
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {27730--27744},
  urldate = {2024-07-18},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/K4WPGJVI/Ouyang et al. - 2022 - Training language models to follow instructions wi.pdf}
}

@article{palanProlificacASubjectPool2018,
  title = {Prolific.Ac---{{A}} Subject Pool for Online Experiments},
  author = {Palan, Stefan and Schitter, Christian},
  year = {2018},
  month = mar,
  journal = {Journal of Behavioral and Experimental Finance},
  volume = {17},
  pages = {22--27},
  issn = {2214-6350},
  doi = {10.1016/j.jbef.2017.12.004},
  urldate = {2024-07-19},
  abstract = {The number of online experiments conducted with subjects recruited via online platforms has grown considerably in the recent past. While one commercial crowdworking platform --~Amazon's Mechanical Turk --~basically has established and since dominated this field, new alternatives offer services explicitly targeted at researchers. In this article, we present www.prolific.ac and lay out its suitability for recruiting subjects for social and economic science experiments. After briefly discussing key advantages and challenges of online experiments relative to lab experiments, we trace the platform's historical development, present its features, and contrast them with requirements for different types of social and economic experiments.}
}

@article{palomaresWomenAreSort2009,
  title = {Women {{Are Sort}} of {{More Tentative Than Men}}, {{Aren}}'t {{They}}?: {{How Men}} and {{Women Use Tentative Language Differently}}, {{Similarly}}, and {{Counterstereotypically}} as a {{Function}} of {{Gender Salience}}},
  shorttitle = {Women {{Are Sort}} of {{More Tentative Than Men}}, {{Aren}}'t {{They}}?},
  author = {Palomares, Nicholas A.},
  year = {2009},
  month = aug,
  journal = {Communication Research},
  volume = {36},
  number = {4},
  pages = {538--560},
  publisher = {SAGE Publications Inc},
  issn = {0093-6502},
  doi = {10.1177/0093650209333034},
  urldate = {2024-07-19},
  abstract = {Based on self-categorization theory's explanation for gender-based language use, male and female participants sent e-mail on a masculine, feminine, or gender-neutral topic to an ostensible male or female recipient (i.e., intergroup or intragroup dyads). As predicted, the topic affected if and how men and women used tentative language differently: For masculine topics, traditional gender differences emerged (i.e., women were more tentative than men) in intergroup, but not intragroup, contexts; for feminine topics, differences were counterstereotypical (i.e., men were more tentative than women) in intergroup contexts only; and for a gender-neutral topic, no differences resulted in either intra- or intergroup contexts. Moreover, gender salience partially mediated these effects in intergroup interactions only: Topic affected tentative language through gender salience in the mixed-sex condition (i.e., a conditional indirect effect).},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VQKNAWA8/Palomares - 2009 - Women Are Sort of More Tentative Than Men, Aren't .pdf}
}

@article{panAreWeBraver2023,
  title = {Are We Braver in Cyberspace? {{Social}} Media Anonymity Enhances Moral Courage},
  shorttitle = {Are We Braver in Cyberspace?},
  author = {Pan, Xinyu and Hou, Yubo and Wang, Qi},
  year = {2023},
  month = nov,
  journal = {Computers in Human Behavior},
  volume = {148},
  pages = {107880},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2023.107880},
  urldate = {2024-06-23},
  abstract = {The literature has established accumulated evidence on the negative consequences of social media anonymity on behaviors online (e.g., cyber-aggression). Yet the potential benefits of social media anonymity have been largely overlooked, especially when it comes to prosociality. In four studies, we examined the facilitating effect of perceived social media anonymity on online moral courage. We first tested and confirmed the relation of perceived social media anonymity to online moral courage in a correlational study (Study 1) and an experimental study (Study 2). We then tested and revealed the mediating role of perceived risk and the moderating role of moral meaningfulness in the relation between perceived anonymity and moral courage (Study 3). We further used social media behavioral data to examine the association between social media anonymity and moral courage in an ecologically valid context (Study 4). Our findings enrich the research of moral psychology and social media studies by providing the first experimental evidence for the prosocial effect of social media anonymity. They further have important implications for website interface design, social activism, as well as intervention programs to promote constructive civil engagement online.}
}

@misc{parkChoiceMatesSupportingUnfamiliar2023,
  title = {{{ChoiceMates}}: {{Supporting Unfamiliar Online Decision-Making}} with {{Multi-Agent Conversational Interactions}}},
  shorttitle = {{{ChoiceMates}}},
  author = {Park, Jeongeon and Min, Bryan and Ma, Xiaojuan and Kim, Juho},
  year = {2023},
  month = oct,
  number = {arXiv:2310.01331},
  eprint = {2310.01331},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.01331},
  urldate = {2023-10-04},
  abstract = {Unfamiliar decisions -- decisions where people lack adequate domain knowledge or expertise -- specifically increase the complexity and uncertainty of the process of searching for, understanding, and making decisions with online information. Through our formative study (n=14), we observed users' challenges in accessing diverse perspectives, identifying relevant information, and deciding the right moment to make the final decision. We present ChoiceMates, a system that enables conversations with a dynamic set of LLM-powered agents for a holistic domain understanding and efficient discovery and management of information to make decisions. Agents, as opinionated personas, flexibly join the conversation, not only providing responses but also conversing among themselves to elicit each agent's preferences. Our between-subjects study (n=36) comparing ChoiceMates to conventional web search and single-agent showed that ChoiceMates was more helpful in discovering, diving deeper, and managing information compared to Web with higher confidence. We also describe how participants utilized multi-agent conversations in their decision-making process.},
  archiveprefix = {arXiv},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/BRG6DMYG/Park et al. - 2023 - ChoiceMates Supporting Unfamiliar Online Decision.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/489R6XA2/2310.html}
}

@inproceedings{parkerSocialPsychologyTelecommunications1978,
  title = {The {{Social Psychology}} of {{Telecommunications}}.},
  booktitle = {Contemporary {{Sociology}}},
  author = {Parker, Edwin B. and Short, John and Williams, Ederyn and Christie, Bruce},
  year = {1978},
  month = jan,
  volume = {7},
  eprint = {2065899},
  eprinttype = {jstor},
  pages = {32},
  issn = {00943061},
  doi = {10.2307/2065899},
  urldate = {2025-01-21},
  abstract = {Semantic Scholar extracted view of "The social psychology of telecommunications" by John Short et al.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/LXYSRYWN/Parker et al. - 1978 - The Social Psychology of Telecommunications..pdf}
}

@article{passiOverrelianceAILiterature,
  title = {Overreliance on {{AI Literature Review}}},
  author = {Passi, Samir and Vorvoreanu, Mihaela},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/GDIZC8XA/Passi and Vorvoreanu - Overreliance on AI Literature Review.pdf}
}

@book{paulUserSatisfactionSystem2004,
  title = {User Satisfaction with System, Decision Process, and Outcome in {{GDSS}} Based Meeting: {{An}} Experimental Investigation},
  shorttitle = {User Satisfaction with System, Decision Process, and Outcome in {{GDSS}} Based Meeting},
  author = {Paul, Souren and Seetharaman, Priya and Ramamurthy, Katikireddy},
  year = {2004},
  month = feb,
  journal = {Proceedings of the Hawaii International Conference on System Sciences},
  volume = {37},
  pages = {46},
  doi = {10.1109/HICSS.2004.1265108},
  abstract = {Performance of groups using group decision support systems (GDSS) has been an issue debated over the last two decades. Yet, there is need for more focused research on subjective variables such as the satisfaction of team members with the experience of using a GDSS. This research focuses on different types of user satisfaction in GDSS based meetings: system satisfaction, process satisfaction, and outcome satisfaction; and explores interrelationships among them. The findings from a laboratory experiment demonstrate that group members' satisfaction with system impacts the satisfaction with decision process and outcome. Satisfaction with decision outcome is also influenced by satisfaction with decision making process. Another interesting set of findings is the relationships between performance of groups members engaged in GDSS based meetings and their satisfaction with system, process, and outcome. Decision time has negative effect on system satisfaction and positive effect on process satisfaction. Thoroughness of decision making has positive effect on outcome satisfaction. The findings of the research have major implications for planners and facilitators of GDSS based meetings.},
  isbn = {978-0-7695-2056-8},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/EBHJZN3K/Paul et al. - 2004 - User satisfaction with system, decision process, a.pdf}
}

@inproceedings{pelikanDesigningRobotSoundInInteraction2023,
  title = {Designing {{Robot Sound-In-Interaction}}: {{The Case}} of {{Autonomous Public Transport Shuttle Buses}}},
  shorttitle = {Designing {{Robot Sound-In-Interaction}}},
  booktitle = {Proceedings of the 2023 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Pelikan, Hannah R. M. and Jung, Malte F.},
  year = {2023},
  month = mar,
  series = {{{HRI}} '23},
  pages = {172--182},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3568162.3576979},
  urldate = {2024-07-19},
  abstract = {Horns and sirens are important tools for communicating on the road, which are still understudied in autonomous vehicles. While HRI has explored different ways in which robots could sound, we focus on the range of actions that a single sound can accomplish in interaction. In a Research through Design study involving autonomous shuttle buses in public transport, we explored sound design with the help of voice-overs to video recordings of the buses on the road and Wizard-of-Oz tests in live traffic. The buses are slowed down by (unnecessary) braking in response to people getting close. We found that prolonged jingles draw attention to the bus and invite interaction, while repeated short beeps and bell sounds can instruct the movement of others away from the bus. We highlight the importance of designing sound in sequential interaction and describe a new method for embedding video interaction analysis in the design process.},
  isbn = {978-1-4503-9964-7}
}

@misc{pengImpactAIDeveloper2023,
  title = {The {{Impact}} of {{AI}} on {{Developer Productivity}}: {{Evidence}} from {{GitHub Copilot}}},
  shorttitle = {The {{Impact}} of {{AI}} on {{Developer Productivity}}},
  author = {Peng, Sida and Kalliamvakou, Eirini and Cihon, Peter and Demirer, Mert},
  year = {2023},
  month = feb,
  number = {arXiv:2302.06590},
  eprint = {2302.06590},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.06590},
  urldate = {2024-07-18},
  abstract = {Generative AI tools hold promise to increase human productivity. This paper presents results from a controlled experiment with GitHub Copilot, an AI pair programmer. Recruited software developers were asked to implement an HTTP server in JavaScript as quickly as possible. The treatment group, with access to the AI pair programmer, completed the task 55.8\% faster than the control group. Observed heterogenous effects show promise for AI pair programmers to help people transition into software development careers.},
  archiveprefix = {arXiv},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/WRINHZQE/Peng et al. - 2023 - The Impact of AI on Developer Productivity Eviden.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/IPB9YQHR/2302.html}
}

@inproceedings{petridisAngleKindlingSupportingJournalistic2023,
  title = {{{AngleKindling}}: {{Supporting Journalistic Angle Ideation}} with {{Large Language Models}}},
  shorttitle = {{{AngleKindling}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Petridis, Savvas and Diakopoulos, Nicholas and Crowston, Kevin and Hansen, Mark and Henderson, Keren and Jastrzebski, Stan and Nickerson, Jeffrey V and Chilton, Lydia B},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--16},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3580907},
  urldate = {2024-07-17},
  abstract = {News media often leverage documents to find ideas for stories, while being critical of the frames and narratives present. Developing angles from a document such as a press release is a cognitively taxing process, in which journalists critically examine the implicit meaning of its claims. Informed by interviews with journalists, we developed AngleKindling, an interactive tool which employs the common sense reasoning of large language models to help journalists explore angles for reporting on a press release. In a study with 12 professional journalists, we show that participants found AngleKindling significantly more helpful and less mentally demanding to use for brainstorming ideas, compared to a prior journalistic angle ideation tool. AngleKindling helped journalists deeply engage with the press release and recognize angles that were useful for multiple types of stories. From our findings, we discuss how to help journalists customize and identify promising angles, and extending AngleKindling to other knowledge-work domains.},
  isbn = {978-1-4503-9421-5}
}

@inproceedings{petridisPromptInfuserBringingUser2023,
  title = {{{PromptInfuser}}: {{Bringing User Interface Mock-ups}} to {{Life}} with {{Large Language Models}}},
  shorttitle = {{{PromptInfuser}}},
  booktitle = {Extended {{Abstracts}} of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Petridis, Savvas and Terry, Michael and Cai, Carrie Jun},
  year = {2023},
  month = apr,
  series = {{{CHI EA}} '23},
  pages = {1--6},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544549.3585628},
  urldate = {2024-07-17},
  abstract = {Large Language Models have enabled novices without machine learning (ML) experience to quickly prototype ML functionalities with prompt programming. This paper investigates incorporating prompt-based prototyping into designing functional user interface (UI) mock-ups. To understand how infusing LLM prompts into UI mock-ups might affect the prototyping process, we conduct a exploratory study with five designers, and find that this capability might significantly speed up creating functional prototypes, inform designers earlier on how their designs will integrate ML, and enable user studies with functional prototypes earlier. From these findings, we built PromptInfuser, a Figma plugin for authoring LLM-infused mock-ups. PromptInfuser introduces two novel LLM-interactions: input-output, which makes content interactive and dynamic, and frame-change, which directs users to different frames depending on their natural language input. From initial observations, we find that PromptInfuser has the potential to transform the design process by tightly integrating UI and AI prototyping in a single interface.},
  isbn = {978-1-4503-9422-2}
}

@inproceedings{poddarAIWritingAssistants2023,
  title = {{{AI Writing Assistants Influence Topic Choice}} in {{Self-Presentation}}},
  booktitle = {Extended {{Abstracts}} of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Poddar, Ritika and Sinha, Rashmi and Naaman, Mor and Jakesch, Maurice},
  year = {2023},
  month = apr,
  series = {{{CHI EA}} '23},
  pages = {1--6},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544549.3585893},
  urldate = {2025-01-21},
  abstract = {AI language technologies increasingly assist and expand human communication. While AI-mediated communication reduces human effort, its societal consequences are poorly understood. In this study, we investigate whether using an AI writing assistant in personal self-presentation changes how people talk about themselves. In an online experiment, we asked participants (N=200) to introduce themselves to others. An AI language assistant supported their writing by suggesting sentence completions. The language model generating suggestions was fine-tuned to preferably suggest either interest, work, or hospitality topics. We evaluate how the topic preference of a language model affected users' topic choice by analyzing the topics participants discussed in their self-presentations. Our results suggest that AI language technologies may change the topics their users talk about. We discuss the need for a careful debate and evaluation of the topic priors built into AI language technologies.},
  isbn = {978-1-4503-9422-2},
  annotation = {TLDR: Whether using an AI writing assistant in personal self-presentation changes how people talk about themselves and the need for a careful debate and evaluation of the topic priors built into AI language technologies are investigated.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/FWY2KTPW/Poddar et al. - 2023 - AI Writing Assistants Influence Topic Choice in Self-Presentation.pdf}
}

@article{postmesSocialInfluenceComputerMediated2001,
  title = {Social {{Influence}} in {{Computer-Mediated Communication}}: {{The Effects}} of {{Anonymity}} on {{Group Behavior}}},
  shorttitle = {Social {{Influence}} in {{Computer-Mediated Communication}}},
  author = {Postmes, Tom and Spears, Russell and Sakhel, Khaled and {de Groot}, Daphne},
  year = {2001},
  month = oct,
  journal = {Personality and Social Psychology Bulletin},
  volume = {27},
  number = {10},
  pages = {1243--1254},
  publisher = {SAGE Publications Inc},
  issn = {0146-1672},
  doi = {10.1177/01461672012710001},
  urldate = {2024-06-23},
  abstract = {Two studies examined hypotheses derived from a Social Identity model of Deindividuation Effects (SIDE) as applied to social influence in computer-mediated communication (CMC) in groups. This model predicts that anonymity can increase social influence if a common group identity is salient. In a first study, group members were primed with a certain type of social behavior (efficiency vs. prosocial norms). Consistent with the model, anonymous groups displayed prime-consistent behavior in their task solutions, whereas identifiable groups did not. This suggests that the primed norm took root in anonymous groups to a greater extent than in identifiable groups. A second study replicated this effect and showed that nonprimed group members conformed to the behavior of primed members, but only when anonymous, suggesting that the primed norm was socially transmitted within the group. Implications for social influence in small groups are discussed.},
  langid = {english},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/YG4TL6FS/Postmes et al. - 2001 - Social Influence in Computer-Mediated Communicatio.pdf}
}

@article{postmesSocialInfluenceComputerMediated2001a,
  title = {Social {{Influence}} in {{Computer-Mediated Communication}}: {{The Effects}} of {{Anonymity}} on {{Group Behavior}}},
  shorttitle = {Social {{Influence}} in {{Computer-Mediated Communication}}},
  author = {Postmes, Tom and Spears, Russell and Sakhel, Khaled and {de Groot}, Daphne},
  year = {2001},
  month = oct,
  journal = {Personality and Social Psychology Bulletin},
  volume = {27},
  number = {10},
  pages = {1243--1254},
  publisher = {SAGE Publications Inc},
  issn = {0146-1672},
  doi = {10.1177/01461672012710001},
  urldate = {2024-06-23},
  abstract = {Two studies examined hypotheses derived from a Social Identity model of Deindividuation Effects (SIDE) as applied to social influence in computer-mediated communication (CMC) in groups. This model predicts that anonymity can increase social influence if a common group identity is salient. In a first study, group members were primed with a certain type of social behavior (efficiency vs. prosocial norms). Consistent with the model, anonymous groups displayed prime-consistent behavior in their task solutions, whereas identifiable groups did not. This suggests that the primed norm took root in anonymous groups to a greater extent than in identifiable groups. A second study replicated this effect and showed that nonprimed group members conformed to the behavior of primed members, but only when anonymous, suggesting that the primed norm was socially transmitted within the group. Implications for social influence in small groups are discussed.},
  langid = {english}
}

@inproceedings{poursabzi-sangdehManipulatingMeasuringModel2021,
  title = {Manipulating and {{Measuring Model Interpretability}}},
  booktitle = {Proceedings of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {{Poursabzi-Sangdeh}, Forough and Goldstein, Daniel G and Hofman, Jake M and Wortman Vaughan, Jennifer Wortman and Wallach, Hanna},
  year = {2021},
  month = may,
  series = {{{CHI}} '21},
  pages = {1--52},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3411764.3445315},
  urldate = {2024-07-17},
  abstract = {With machine learning models being increasingly used to aid decision making even in high-stakes domains, there has been a growing interest in developing interpretable models. Although many supposedly interpretable models have been proposed, there have been relatively few experimental studies investigating whether these models achieve their intended effects, such as making people more closely follow a model's predictions when it is beneficial for them to do so or enabling them to detect when a model has made a mistake. We present a sequence of pre-registered experiments (N = 3, 800) in which we showed participants functionally identical models that varied only in two factors commonly thought to make machine learning models more or less interpretable: the number of features and the transparency of the model (i.e., whether the model internals are clear or black box). Predictably, participants who saw a clear model with few features could better simulate the model's predictions. However, we did not find that participants more closely followed its predictions. Furthermore, showing participants a clear model meant that they were less able to detect and correct for the model's sizable mistakes, seemingly due to information overload. These counterintuitive findings emphasize the importance of testing over intuition when developing interpretable models.},
  isbn = {978-1-4503-8096-6},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VSFTZSNA/Poursabzi-Sangdeh et al. - 2021 - Manipulating and Measuring Model Interpretability.pdf}
}

@article{pruittChoiceShiftsGroup1971,
  title = {Choice Shifts in Group Discussion: {{An}} Introductory Review},
  shorttitle = {Choice Shifts in Group Discussion},
  author = {Pruitt, Dean G.},
  year = {1971},
  journal = {Journal of Personality and Social Psychology},
  volume = {20},
  number = {3},
  pages = {339--360},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1315},
  doi = {10.1037/h0031922},
  abstract = {Notes that shifts toward caution occur reliably in group discussions of certain issues and that the earlier notion that groups always take more risk than individuals must be abandoned. Discussion-induced shifts have recently been found on several non-risk-involving dimensions, suggesting a general phenomenon of choice shifts, rather than only shifts on the risk dimension. Quite a few theories have been developed to account for the choice shift. Theories that attribute choice shifts to the operation of widely held human values seem to have the most support, though truly definitive studies have not yet been done. 4 theories of this kind have received partial support, and there is a viable version of leadership theory which holds that the group shifts toward its most confident member. Evidence suggests that 2 or more mechanisms may be at work in group discussions and that more than 1 of the theories may be correct. (73 ref.) (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{qinAdultsStillCant2022,
  title = {Adults Still Can't Resist: {{A}} Social Robot Can Induce Normative Conformity},
  shorttitle = {Adults Still Can't Resist},
  author = {Qin, Xin and Chen, Chen and Yam, Kai Chi and Cao, Limei and Li, Wanlu and Guan, Jian and Zhao, Puchu and Dong, Xiaowei and Lin, Yiqiang},
  year = {2022},
  month = feb,
  journal = {Computers in Human Behavior},
  volume = {127},
  pages = {107041},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.107041},
  urldate = {2024-07-26},
  abstract = {Social robots are widely used in many areas of our work and life. Vollmer et al. (2018) recently provided initial evidence that while adults could resist the pressure to conform to social robots, children could not. However, we suggest that these findings are incomplete because they investigated a setting in which single individuals were paired with a group of robot peers. In this research, we investigate the more likely scenario in which social robots represent the minority in human-robot interactions. Using the classic Asch paradigm, we reveal that a single social robot as a member of group does elicit normative conformity. We further explore whether positioning robots as dissenters can reduce conformity. We find that a social robot who dissents with the correct answer has a comparable, albeit weaker, effect on reducing conformity and increasing accuracy as a human dissenter, whereas a social robot who dissents with another incorrect answer decreases conformity but does not increase accuracy. These results suggest that social robots can and do influence normative conformity, with significant ethical and practical implications.},
  annotation = {TLDR: It is found that a social robot who dissents with the correct answer has a comparable, albeit weaker, effect on reducing conformity and increasing accuracy as a human dissenter, whereas a social robots who dissent with another incorrect answer decreases conformity but does not increase accuracy.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/237AJLG2/S0747563221003642.html}
}

@article{raoAssessingUtilityChatGPT2023,
  title = {Assessing the {{Utility}} of {{ChatGPT Throughout}} the {{Entire Clinical Workflow}}: {{Development}} and {{Usability Study}}},
  shorttitle = {Assessing the {{Utility}} of {{ChatGPT Throughout}} the {{Entire Clinical Workflow}}},
  author = {Rao, Arya and Pang, Michael and Kim, John and Kamineni, Meghana and Lie, Winston and Prasad, Anoop K. and Landman, Adam and Dreyer, Keith and Succi, Marc D.},
  year = {2023},
  month = aug,
  journal = {Journal of Medical Internet Research},
  volume = {25},
  number = {1},
  pages = {e48659},
  publisher = {JMIR Publications Inc., Toronto, Canada},
  doi = {10.2196/48659},
  urldate = {2024-07-18},
  abstract = {Background: Large language model (LLM)--based artificial intelligence chatbots direct the power of large training data sets toward successive, related tasks as opposed to single-ask tasks, for which artificial intelligence already achieves impressive performance. The capacity of LLMs to assist in the full scope of iterative clinical reasoning via successive prompting, in effect acting as artificial physicians, has not yet been evaluated. Objective: This study aimed to evaluate ChatGPT's capacity for ongoing clinical decision support via its performance on standardized clinical vignettes. Methods: We inputted all 36 published clinical vignettes from the Merck Sharpe \&amp; Dohme (MSD) Clinical Manual into ChatGPT and compared its accuracy on differential diagnoses, diagnostic testing, final diagnosis, and management based on patient age, gender, and case acuity. Accuracy was measured by the proportion of correct responses to the questions posed within the clinical vignettes tested, as calculated by human scorers. We further conducted linear regression to assess the contributing factors toward ChatGPT's performance on clinical tasks. Results: ChatGPT achieved an overall accuracy of 71.7\% (95\% CI 69.3\%-74.1\%) across all 36 clinical vignettes. The LLM demonstrated the highest performance in making a final diagnosis with an accuracy of 76.9\% (95\% CI 67.8\%-86.1\%) and the lowest performance in generating an initial differential diagnosis with an accuracy of 60.3\% (95\% CI 54.2\%-66.6\%). Compared to answering questions about general medical knowledge, ChatGPT demonstrated inferior performance on differential diagnosis ({$\beta$}=--15.8\%; P\&lt;.001) and clinical management ({$\beta$}=--7.4\%; P=.02) question types. Conclusions: ChatGPT achieves impressive accuracy in clinical decision-making, with increasing strength as it gains more clinical information at its disposal. In particular, ChatGPT demonstrates the greatest accuracy in tasks of final diagnosis as compared to initial diagnosis. Limitations include possible model hallucinations and the unclear composition of ChatGPT's training data set.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/W7ZW4F3N/Rao et al. - 2023 - Assessing the Utility of ChatGPT Throughout the En.pdf}
}

@article{rastogiDecidingFastSlow2022,
  title = {Deciding {{Fast}} and {{Slow}}: {{The Role}} of {{Cognitive Biases}} in {{AI-assisted Decision-making}}},
  shorttitle = {Deciding {{Fast}} and {{Slow}}},
  author = {Rastogi, Charvi and Zhang, Yunfeng and Wei, Dennis and Varshney, Kush R. and Dhurandhar, Amit and Tomsett, Richard},
  year = {2022},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  number = {CSCW1},
  pages = {83:1--83:22},
  doi = {10.1145/3512930},
  urldate = {2024-07-18},
  abstract = {Several strands of research have aimed to bridge the gap between artificial intelligence (AI) and human decision-makers in AI-assisted decision-making, where humans are the consumers of AI model predictions and the ultimate decision-makers in high-stakes applications. However, people's perception and understanding are often distorted by their cognitive biases, such as confirmation bias, anchoring bias, availability bias, to name a few. In this work, we use knowledge from the field of cognitive science to account for cognitive biases in the human-AI collaborative decision-making setting, and mitigate their negative effects on collaborative performance. To this end, we mathematically model cognitive biases and provide a general framework through which researchers and practitioners can understand the interplay between cognitive biases and human-AI accuracy. We then focus specifically on anchoring bias, a bias commonly encountered in human-AI collaboration. We implement a time-based de-anchoring strategy and conduct our first user experiment that validates its effectiveness in human-AI collaborative decision-making. With this result, we design a time allocation strategy for a resource-constrained setting that achieves optimal human-AI collaboration under some assumptions. We, then, conduct a second user experiment which shows that our time allocation strategy with explanation can effectively de-anchor the human and improve collaborative performance when the AI model has low confidence and is incorrect.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/BTCARSAR/Rastogi et al. - 2022 - Deciding Fast and Slow The Role of Cognitive Bias.pdf}
}

@inproceedings{rechkemmerWhenConfidenceMeets2022,
  title = {When {{Confidence Meets Accuracy}}: {{Exploring}} the {{Effects}} of {{Multiple Performance Indicators}} on {{Trust}} in {{Machine Learning Models}}},
  shorttitle = {When {{Confidence Meets Accuracy}}},
  booktitle = {Proceedings of the 2022 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Rechkemmer, Amy and Yin, Ming},
  year = {2022},
  month = apr,
  series = {{{CHI}} '22},
  pages = {1--14},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3491102.3501967},
  urldate = {2024-07-17},
  abstract = {Previous research shows that laypeople's trust in a machine learning model can be affected by both performance measurements of the model on the aggregate level and performance estimates on individual predictions. However, it is unclear how people would trust the model when multiple performance indicators are presented at the same time. We conduct an exploratory human-subject experiment to answer this question. We find that while the level of model confidence significantly affects people's belief in model accuracy, both the model's stated and observed accuracy generally have a larger impact on people's willingness to follow the model's predictions as well as their self-reported levels of trust in the model, especially after observing the model's performance in practice. We hope the empirical evidence reported in this work could open doors to further studies to advance understanding of how people perceive, process, and react to performance-related information of machine learning.},
  isbn = {978-1-4503-9157-3}
}

@book{reevesMediaEquationHow1996,
  title = {The {{Media Equation}}: {{How People Treat Computers}}, {{Television}}, and {{New Media}} like {{Real People}} and {{Places}}},
  shorttitle = {The {{Media Equation}}},
  author = {Reeves, Byron and Nass, Clifford},
  year = {1996},
  month = sep,
  publisher = {Cambridge University Press},
  abstract = {According to popular wisdom, humans never relate to a computer or a television program in the same way they relate to another human being. Or do they? The psychological and sociological complexities of the relationship could be greater than you think. In an extraordinary revision of received wisdom, Byron Reeves and Clifford Nass demonstrate convincingly in The Media Equation that interactions with computers, television, and new communication technologies are identical to real social relationships and to the navigation of real physical spaces. Using everyday language, the authors explain their novel ideas in a way that will engage general readers with an interest in cutting-edge research at the intersection of psychology, communication and computer technology. The result is an accessible summary of exciting ideas for modern times. As Bill Gates says, '(they) ... have shown us some amazing things'.},
  isbn = {978-1-57586-052-7},
  langid = {english}
}

@article{reicherSocialIdentityModel1995,
  title = {A {{Social Identity Model}} of {{Deindividuation Phenomena}}},
  author = {Reicher, S. D. and Spears, R. and Postmes, T.},
  year = {1995},
  month = jan,
  journal = {European Review of Social Psychology},
  volume = {6},
  number = {1},
  pages = {161--198},
  publisher = {Routledge},
  issn = {1046-3283},
  doi = {10.1080/14792779443000049},
  urldate = {2024-08-12},
  abstract = {This chapter challenges traditional models of deindividuation. These are based on the assumption that such factors as immersion in a group and anonymity lead to a loss of selfhood and hence of control over behaviour. We argue that such models depend upon an individualistic conception of the self, viewed as a unitary construct referring to that which makes individuals unique. This is rejected in favour of the idea that self can be defined at various different levels including the categorical self as well as the personal self. Hence a social identity model of deindividuation (SIDE) is outlined. Evidence is presented to show that deindividuation manipulations gain effect, firstly, through the ways in which they affect the salience of social identity (and hence conformity to categorical norms) and, secondly, through their effects upon strategic considerations relating to the expression of social identities. We conclude that the classic deindividuation paradigm of anonymity within a social group, far from leading to uncontrolled behaviour, maximizes the opportunity of group members to give full voice to their collective identities.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/TSEGRWME/Reicher et al. - 1995 - A Social Identity Model of Deindividuation Phenome.pdf}
}

@article{reinkemeierCanHumanizingVoice2022,
  title = {Can {{Humanizing Voice Assistants Unleash}} the {{Potential}} of {{Voice Commerce}}?},
  author = {Reinkemeier, Fabian and Gnewuch, Ulrich and Toporowski, Waldemar},
  year = {2022},
  abstract = {Voice commerce allows customers to carry out sales dialogues with voice assistants (VAs) through natural spoken language. However, its adoption remains limited. To help determine how to overcome existing barriers to adoption, we conducted a series of three empirical pre-studies and a laboratory experiment (N = 323) investigating the role of VAs' humanness in interactions with customers; research has reached no consensus on this matter. Our results reveal that humanizing VAs increases customers' perceptions of social presence and parasocial interaction, thereby enhancing perceived relationship quality and ultimately leading to increased intentions to shop using the VA. Although, we also find a negative direct effect of humanization on parasocial interaction, it is offset by the larger positive indirect effect via social presence. This may provide one explanation for the inconsistencies in the literature. For practitioners, our findings highlight the importance of careful design in humanizing VAs to increase voice commerce adoption.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/CYLDVP5N/Reinkemeier et al. - 2022 - Can Humanizing Voice Assistants Unleash the Potent.pdf}
}

@article{rivaSocialInfluencesDigital2022,
  title = {Social Influences in the Digital Era: {{When}} Do People Conform More to a Human Being or an Artificial Intelligence?},
  shorttitle = {Social Influences in the Digital Era},
  author = {Riva, Paolo and Aureli, Nicolas and Silvestrini, Federica},
  year = {2022},
  month = sep,
  journal = {Acta Psychologica},
  volume = {229},
  pages = {103681},
  issn = {0001-6918},
  doi = {10.1016/j.actpsy.2022.103681},
  urldate = {2024-07-25},
  abstract = {The spread of artificial intelligence (AI) technologies in ever-widening domains (e.g., virtual assistants) increases the chances of daily interactions between humans and AI. But can non-human agents influence human beings and perhaps even surpass the power of the influence of another human being? This research investigated whether people faced with different tasks (objective vs. subjective) could be more influenced by the information provided by another human being or an AI. We expected greater AI (vs. other humans) influence in objective tasks (i.e., based on a count and only one possible correct answer). By contrast, we expected greater human (vs. AI) influence in subjective tasks (based on attributing meaning to evocative images). In Study 1, participants (N~=~156) completed a series of trials of an objective task to provide numerical estimates of the number of white dots pictured on black backgrounds. Results showed that participants conformed more with the AI's responses than the human ones. In Study 2, participants (N~=~102) in a series of subjective tasks observed evocative images associated with two concepts ostensibly provided, again, by an AI or a human. Then, they rated how each concept described the images appropriately. Unlike the objective task, in the subjective one, participants conformed more with the human than the AI's responses. Overall, our findings show that under some circumstances, AI can influence people above and beyond the influence of other humans, offering new insights into social influence processes in the digital era.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/25TVHPGA/Riva et al. - 2022 - Social influences in the digital era When do peop.pdf}
}

@book{robertoUnlockingCreativityHow2018,
  title = {Unlocking {{Creativity}}: {{How}} to {{Solve Any Problem}} and {{Make}} the {{Best Decisions}} by {{Shifting Creative Mindsets}}},
  shorttitle = {Unlocking {{Creativity}}},
  author = {Roberto, Michael A.},
  year = {2018},
  month = dec,
  publisher = {John Wiley \& Sons},
  abstract = {Tear down the obstacles to creative innovation in your organization Unlocking Creativity is an exploration of the creative process and how organizations can clear the way for innovation. In many organizations, creative individuals face stubborn resistance to new ideas. Managers and executives oftentimes reject innovation and unconventional approaches due to misplaced allegiance to the status quo. Questioning established practices or challenging prevailing sentiments is frequently met with stiff resistance. In this climate of stifled creativity and inflexible adherence to conventional wisdom, potentially game-changing ideas are dismissed outright. Senior leaders claim to value creativity, yet often lack the knowledge to provide a creative framework. Unlocking Creativity offers effective methods and real-world examples of how the most successful organizations create cultures of innovation and experimentation. Best-selling author and scholar Michael Roberto presents a thorough investigation of organizational obstacles to creative thought. Highly relevant to the growth crises many enterprises face in today's economic landscape, this book examines how to break barriers to spark creativity and foster new ideas. This insightful and informative work allows business executives, senior managers, and organization leaders to:  Recognize the six organizational mindsets that impede creativity and innovation Learn how to tear down the barriers that obstruct the creative process Create an environment that allows talented people to thrive Encourage creative collaboration in teams throughout an organization  Leaders do not have to conceive innovative ideas, but rather open the path for curious and creative employees within their organization. Unlocking Creativity: How to Solve Any Problem and Make the Best Decisions aids organizations in removing obstacles to the creative process and helps to form an atmosphere of imagination and innovation.},
  googlebooks = {SsOCDwAAQBAJ},
  isbn = {978-1-119-54576-7},
  langid = {english}
}

@inproceedings{robertsonCantReplyThat2021,
  title = {``{{I Can}}'t {{Reply}} with {{That}}'': {{Characterizing Problematic Email Reply Suggestions}}},
  shorttitle = {``{{I Can}}'t {{Reply}} with {{That}}''},
  booktitle = {Proceedings of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Robertson, Ronald E and Olteanu, Alexandra and Diaz, Fernando and Shokouhi, Milad and Bailey, Peter},
  year = {2021},
  month = may,
  series = {{{CHI}} '21},
  pages = {1--18},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3411764.3445557},
  urldate = {2025-01-21},
  abstract = {In email interfaces, providing users with reply suggestions may simplify or accelerate correspondence. While the ``success'' of such systems is typically quantified using the number of suggestions selected by users, this ignores the impact of social context, which can change how suggestions are perceived. To address this, we developed a mixed-methods framework involving qualitative interviews and crowdsourced experiments to characterize problematic email reply suggestions. Our interviews revealed issues with over-positive, dissonant, cultural, and gender-assuming replies, as well as contextual politeness. In our experiments, crowdworkers assessed email scenarios that we generated and systematically controlled, showing that contextual factors like social ties and the presence of salutations impacts users' perceptions of email correspondence. These assessments created a novel dataset of human-authored corrections for problematic email replies. Our study highlights the social complexity of providing suggestions for email correspondence, raising issues that may apply to all social messaging systems.},
  isbn = {978-1-4503-8096-6},
  annotation = {TLDR: This study developed a mixed-methods framework involving qualitative interviews and crowdsourced experiments to characterize problematic email reply suggestions, revealing issues with over-positive, dissonant, cultural, and gender-assuming replies, as well as contextual politeness.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/95RMPS7U/Robertson et al. - 2021 - “I Can’t Reply with That” Characterizing Problematic Email Reply Suggestions.pdf}
}

@article{rosetteWhiteStandardRacial2008,
  title = {The {{White}} Standard: {{Racial}} Bias in Leader Categorization},
  shorttitle = {The {{White}} Standard},
  author = {Rosette, Ashleigh Shelby and Leonardelli, Geoffrey J. and Phillips, Katherine W.},
  year = {2008},
  journal = {Journal of Applied Psychology},
  volume = {93},
  number = {4},
  pages = {758--777},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1854},
  doi = {10.1037/0021-9010.93.4.758},
  abstract = {In 4 experiments, the authors investigated whether race is perceived to be part of the business leader prototype and, if so, whether it could explain differences in evaluations of White and non-White leaders. The first 2 studies revealed that "being White" is perceived to be an attribute of the business leader prototype, where participants assumed that business leaders more than nonleaders were White, and this inference occurred regardless of base rates about the organization's racial composition (Study 1), the racial composition of organizational roles, the business industry, and the types of racial minority groups in the organization (Study 2). The final 2 studies revealed that a leader categorization explanation could best account for differences in White and non-White leader evaluations, where White targets were evaluated as more effective leaders (Study 3) and as having more leadership potential (Study 4), but only when the leader had recently been given credit for organizational success, consistent with the prediction that leader prototypes are more likely to be used when they confirm and reinforce individualized information about a leader's performance. The results demonstrate a connection between leader race and leadership categorization. (PsycInfo Database Record (c) 2022 APA, all rights reserved)}
}

@inproceedings{rossProgrammersAssistantConversational2023,
  title = {The {{Programmer}}'s {{Assistant}}: {{Conversational Interaction}} with a {{Large Language Model}} for {{Software Development}}},
  shorttitle = {The {{Programmer}}'s {{Assistant}}},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Ross, Steven I. and Martinez, Fernando and Houde, Stephanie and Muller, Michael and Weisz, Justin D.},
  year = {2023},
  month = mar,
  series = {{{IUI}} '23},
  pages = {491--514},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3581641.3584037},
  urldate = {2024-07-18},
  abstract = {Large language models (LLMs) have recently been applied in software engineering to perform tasks such as translating code between programming languages, generating code from natural language, and autocompleting code as it is being written. When used within development tools, these systems typically treat each model invocation independently from all previous invocations, and only a specific limited functionality is exposed within the user interface. This approach to user interaction misses an opportunity for users to more deeply engage with the model by having the context of their previous interactions, as well as the context of their code, inform the model's responses. We developed a prototype system -- the Programmer's Assistant -- in order to explore the utility of conversational interactions grounded in code, as well as software engineers' receptiveness to the idea of conversing with, rather than invoking, a code-fluent LLM. Through an evaluation with 42 participants with varied levels of programming experience, we found that our system was capable of conducting extended, multi-turn discussions, and that it enabled additional knowledge and capabilities beyond code generation to emerge from the LLM. Despite skeptical initial expectations for conversational programming assistance, participants were impressed by the breadth of the assistant's capabilities, the quality of its responses, and its potential for improving their productivity. Our work demonstrates the unique potential of conversational interactions with LLMs for co-creative processes like software development.},
  isbn = {9798400701061},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/RPVXURS5/Ross et al. - 2023 - The Programmer’s Assistant Conversational Interac.pdf}
}

@book{russellPowerNewSocial2004,
  title = {Power: {{A New Social Analysis}}},
  shorttitle = {Power},
  author = {Russell, Bertrand},
  year = {2004},
  month = feb,
  publisher = {Routledge},
  abstract = {The key to human nature that Marx found in wealth and Freud in sex, Bertrand Russell finds in power. Power, he argues, is man's ultimate goal, and is, in its many guises, the single most important element in the development of any society. Writting in the late 1930s when Europe was being torn apart by extremist ideologies and the world was on the brink of war, Russell set out to found a 'new science' to make sense of the traumatic events of the day and explain those that would follow. The result was Power, a remarkable book that Russell regarded as one of the most important of his long career. Countering the totalitarian desire to dominate, Russell shows how political enlightenment and human understanding can lead to peace - his book is a passionate call for independence of mind and a celebration of the instinctive joy of human life.},
  googlebooks = {uR7NDrA7YFsC},
  isbn = {978-1-135-15254-3},
  langid = {english}
}

@article{sackettTokenismPerformanceEvaluation1991,
  title = {Tokenism in Performance Evaluation: {{The}} Effects of Work Group Representation on Male-Female and {{White-Black}} Differences in Performance Ratings},
  shorttitle = {Tokenism in Performance Evaluation},
  author = {Sackett, Paul R. and DuBois, Cathy L. and Noe, Ann W.},
  year = {1991},
  journal = {Journal of Applied Psychology},
  volume = {76},
  number = {2},
  pages = {263--267},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1854},
  doi = {10.1037/0021-9010.76.2.263},
  abstract = {Male--female differences in performance ratings were examined in 486 work groups across a wide variety of jobs and organizations. As suggested by the sex stereotyping literature, women received lower ratings when the proportion of women in the group was small, even after male--female cognitive ability, psychomotor ability, education, and experience differences were controlled. Replication of the analyses with racial differences (White--Black) in 814 work groups demonstrated that group composition had little effect on performance ratings. The effects of group composition on stereotyping behaviors do not appear to generalize to all minority contexts. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{sanchezUnderstandingRelianceAutomation2014,
  title = {Understanding Reliance on Automation: Effects of Error Type, Error Distribution, Age and Experience},
  shorttitle = {Understanding Reliance on Automation},
  author = {Sanchez, Julian and Rogers, Wendy A. and Fisk, Arthur D. and Rovira, Ericka},
  year = {2014},
  month = mar,
  journal = {Theoretical Issues in Ergonomics Science},
  volume = {15},
  number = {2},
  pages = {134--160},
  publisher = {Taylor \& Francis},
  issn = {1463-922X},
  doi = {10.1080/1463922X.2011.611269},
  urldate = {2024-07-18},
  abstract = {An obstacle detection task supported by `imperfect' automation was used with the goal of understanding the effects of automation error types and age on automation reliance. Sixty younger and sixty older adults interacted with a multi-task simulation of an agricultural vehicle (i.e. a virtual harvesting combine). The simulator included an obstacle detection task and a fully manual tracking task. A micro-level analysis provided insight into the way reliance patterns change over time. The results indicated that there are distinct patterns of reliance that develop as a function of error type. A prevalence of automation false alarms led participants to under-rely on the automation during alarm states while over-relying on it during non-alarm states. Conversely, a prevalence of automation misses led participants to over-rely on automated alarms and under-rely on the automation during non-alarm states. Older adults adjusted their behaviour according to the characteristics of the automation similar to younger adults, although it took them longer to do so. The results of this study suggest that the relationship between automation reliability and reliance depends on the prevalence of specific errors and on the state of the system. Understanding the effects of automation detection criterion settings on human--automation interaction can help designers of automated systems to make predictions about human behaviour and system performance as a function of the characteristics of the automation.},
  pmid = {25642142},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/M3TELPPH/Sanchez et al. - 2014 - Understanding reliance on automation effects of e.pdf}
}

@article{sarkarAIShouldChallenge2024,
  title = {{{AI Should Challenge}}, {{Not Obey}}},
  author = {Sarkar, Advait},
  year = {2024},
  month = oct,
  journal = {Communications of the ACM},
  volume = {67},
  number = {10},
  eprint = {2411.02263},
  primaryclass = {cs},
  pages = {18--21},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3649404},
  urldate = {2025-01-24},
  abstract = {Let's transform our robot secretaries into Socratic gadflies.},
  archiveprefix = {arXiv},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/ZP6DGHAF/Sarkar - 2024 - AI Should Challenge, Not Obey.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/HQJ9GITJ/2411.html}
}

@article{saundersonPersuasiveRobotsShould2021,
  title = {Persuasive Robots Should Avoid Authority: {{The}} Effects of Formal and Real Authority on Persuasion in Human-Robot Interaction},
  shorttitle = {Persuasive Robots Should Avoid Authority},
  author = {Saunderson, Shane P. and Nejat, Goldie},
  year = {2021},
  month = sep,
  journal = {Science Robotics},
  volume = {6},
  number = {58},
  pages = {eabd5186},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/scirobotics.abd5186},
  urldate = {2024-07-18},
  abstract = {Social robots must take on many roles when interacting with people in everyday settings, some of which may be authoritative, such as a nurse, teacher, or guard. It is important to investigate whether and how authoritative robots can influence people in applications ranging from health care and education to security and in the home. Here, we present a human-robot interaction study that directly investigates the effect of a robot's peer or authority role (formal authority) and control of monetary rewards and penalties (real authority) on its persuasive influence. The study consisted of a social robot attempting to persuade people to change their answers to the robot's suggestion in a series of challenging attention and memory tasks. Our results show that the robot in a peer role was more persuasive than when in an authority role, contrary to expectations from human-human interactions. The robot was also more persuasive when it offered rewards over penalties, suggesting that participants perceived the robot's suggestions as a less risky option than their own estimates, in line with prospect theory. In general, the results show an aversion to the persuasive influence of authoritative robots, potentially due to the robot's legitimacy as an authority figure, its behavior being perceived as dominant, or participant feelings of threatened autonomy. This paper explores the importance of persuasion for robots in different social roles while providing critical insight into the perception of robots in these roles, people's behavior around these robots, and the development of human-robot relationships.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/IEMXFSY8/Saunderson and Nejat - 2021 - Persuasive robots should avoid authority The effe.pdf}
}

@article{schaferMeaningfulnessEffectSizes2019,
  title = {The {{Meaningfulness}} of {{Effect Sizes}} in {{Psychological Research}}: {{Differences Between Sub-Disciplines}} and the {{Impact}} of {{Potential Biases}}},
  shorttitle = {The {{Meaningfulness}} of {{Effect Sizes}} in {{Psychological Research}}},
  author = {Sch{\"a}fer, Thomas and Schwarz, Marcus A.},
  year = {2019},
  month = apr,
  journal = {Frontiers in Psychology},
  volume = {10},
  publisher = {Frontiers},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2019.00813},
  urldate = {2024-07-19},
  abstract = {{$<$}p{$>$}Effect sizes are the currency of psychological research. They quantify the results of a study to answer the research question and are used to calculate statistical power. The interpretation of effect sizes---when is an effect small, medium, or large?---has been guided by the recommendations Jacob Cohen gave in his pioneering writings starting in 1962: Either compare an effect with the effects found in past research or use certain conventional benchmarks. The present analysis shows that neither of these recommendations is currently applicable. From past publications without pre-registration, 900 effects were randomly drawn and compared with 93 effects from publications with pre-registration, revealing a large difference: Effects from the former (median {$<$}italic{$>$}r{$<$}/italic{$>$} = 0.36) were much larger than effects from the latter (median {$<$}italic{$>$}r{$<$}/italic{$>$} = 0.16). That is, certain biases, such as publication bias or questionable research practices, have caused a dramatic inflation in published effects, making it difficult to compare an actual effect with the real population effects (as these are unknown). In addition, there were very large differences in the mean effects between psychological sub-disciplines and between different study designs, making it impossible to apply any global benchmarks. Many more pre-registered studies are needed in the future to derive a reliable picture of real population effects.{$<$}/p{$>$}},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/7UH2NV85/Schäfer and Schwarz - 2019 - The Meaningfulness of Effect Sizes in Psychologica.pdf}
}

@inproceedings{schemmerAppropriateRelianceAI2023,
  title = {Appropriate {{Reliance}} on {{AI Advice}}: {{Conceptualization}} and the {{Effect}} of {{Explanations}}},
  shorttitle = {Appropriate {{Reliance}} on {{AI Advice}}},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Schemmer, Max and Kuehl, Niklas and Benz, Carina and Bartos, Andrea and Satzger, Gerhard},
  year = {2023},
  month = mar,
  series = {{{IUI}} '23},
  pages = {410--422},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3581641.3584066},
  urldate = {2024-07-18},
  abstract = {AI advice is becoming increasingly popular, e.g., in investment and medical treatment decisions. As this advice is typically imperfect, decision-makers have to exert discretion as to whether actually follow that advice: they have to ``appropriately'' rely on correct and turn down incorrect advice. However, current research on appropriate reliance still lacks a common definition as well as an operational measurement concept. Additionally, no in-depth behavioral experiments have been conducted that help understand the factors influencing this behavior. In this paper, we propose Appropriateness of Reliance (AoR) as an underlying, quantifiable two-dimensional measurement concept. We develop a research model that analyzes the effect of providing explanations for AI advice. In an experiment with 200 participants, we demonstrate how these explanations influence the AoR, and, thus, the effectiveness of AI advice. Our work contributes fundamental concepts for the analysis of reliance behavior and the purposeful design of AI advisors.},
  isbn = {9798400701061},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/2QD7L2Q9/Schemmer et al. - 2023 - Appropriate Reliance on AI Advice Conceptualizati.pdf}
}

@inproceedings{schemmerAppropriateRelianceAI2023a,
  title = {Appropriate {{Reliance}} on {{AI Advice}}: {{Conceptualization}} and the {{Effect}} of {{Explanations}}},
  shorttitle = {Appropriate {{Reliance}} on {{AI Advice}}},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Schemmer, Max and Kuehl, Niklas and Benz, Carina and Bartos, Andrea and Satzger, Gerhard},
  year = {2023},
  month = mar,
  series = {{{IUI}} '23},
  pages = {410--422},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3581641.3584066},
  urldate = {2024-07-18},
  abstract = {AI advice is becoming increasingly popular, e.g., in investment and medical treatment decisions. As this advice is typically imperfect, decision-makers have to exert discretion as to whether actually follow that advice: they have to ``appropriately'' rely on correct and turn down incorrect advice. However, current research on appropriate reliance still lacks a common definition as well as an operational measurement concept. Additionally, no in-depth behavioral experiments have been conducted that help understand the factors influencing this behavior. In this paper, we propose Appropriateness of Reliance (AoR) as an underlying, quantifiable two-dimensional measurement concept. We develop a research model that analyzes the effect of providing explanations for AI advice. In an experiment with 200 participants, we demonstrate how these explanations influence the AoR, and, thus, the effectiveness of AI advice. Our work contributes fundamental concepts for the analysis of reliance behavior and the purposeful design of AI advisors.},
  isbn = {9798400701061},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/IACYY9DW/Schemmer et al. - 2023 - Appropriate Reliance on AI Advice Conceptualizati.pdf}
}

@inproceedings{schneidersEffectEmbodiedAnthropomorphism2022,
  title = {The {{Effect}} of {{Embodied Anthropomorphism}} of {{Personal Assistants}} on {{User Perceptions}}},
  booktitle = {Proceedings of the 33rd {{Australian Conference}} on {{Human-Computer Interaction}}},
  author = {Schneiders, Eike and Papachristos, Eleftherios and {van Berkel}, Niels},
  year = {2022},
  month = sep,
  series = {{{OzCHI}} '21},
  pages = {231--241},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3520495.3520503},
  urldate = {2024-07-19},
  abstract = {We investigate the impact of anthropomorphism on embodied AI through a study of personal assistants (PA). The effects of physical embodiment remain underexplored while the consumer market for PAs shows an increase in the diversity of physical appearances of these products. We designed three fictional personal assistants with varying levels of embodied anthropomorphism. We validated that our prototypes differed significantly in levels of anthropomorphism (N\&nbsp;=\&nbsp;26). We developed a set of identical videos for each device, demonstrating realistic end-user interaction across six scenarios. Using a between-subject video survey study (N\&nbsp;=\&nbsp;150), we evaluate the impact of different levels of embodied anthropomorphism on the perception of personal assistants. Our results show that while anthropomorphism did not significantly affect the perception of Overall Goodness, it affected perceptions of Perceived Intelligence, Likeability, and the device's Pragmatic Qualities. Finally, we discuss the implications of the identified relationships between anthropomorphism and user confidence in embodied AI systems.},
  isbn = {978-1-4503-9598-4}
}

@article{schulz-hardtProductiveConflictGroup2002,
  title = {Productive Conflict in Group Decision Making: Genuine and Contrived Dissent as Strategies to Counteract Biased Information Seeking},
  shorttitle = {Productive Conflict in Group Decision Making},
  author = {{Schulz-Hardt}, Stefan and Jochims, Marc and Frey, Dieter},
  year = {2002},
  month = jul,
  journal = {Organizational Behavior and Human Decision Processes},
  volume = {88},
  number = {2},
  pages = {563--586},
  issn = {0749-5978},
  doi = {10.1016/S0749-5978(02)00001-8},
  urldate = {2024-07-18},
  abstract = {Decision-making groups in organizations are often expected to function as a ``think tank'' and to perform ``reality testing'' to detect the best alternative. A biased search for information supporting the group's favored alternative impairs a group's ability to fulfill these requirements. In a two-factorial experiment with 201 employees and managers from various economic and public organizations, genuine and contrived dissent were investigated as counterstrategies to biased information seeking. Genuine dissent was manipulated by forming three-person groups whose members either all favored the same alternative individually (homogeneous groups) or consisted of a minority and a majority faction with regard to their favored alternative (heterogeneous groups). Contrived dissent was varied by the use or nonuse of the ``devil's advocacy'' technique. The results demonstrate that heterogeneity was more effective in preventing a confirmatory information-seeking bias than devil's advocacy was. Confidence was identified as an important mediator. Implications for the design of interventions aimed at facilitating reality testing in group decision making are discussed.}
}

@article{schumannWhenComputermediatedIntergroup2017,
  title = {When Is Computer-Mediated Intergroup Contact Most Promising? {{Examining}} the Effect of out-Group Members' Anonymity on Prejudice},
  shorttitle = {When Is Computer-Mediated Intergroup Contact Most Promising?},
  author = {Schumann, Sandy and Klein, Olivier and Douglas, Karen and Hewstone, Miles},
  year = {2017},
  month = dec,
  journal = {Computers in Human Behavior},
  volume = {77},
  pages = {198--210},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2017.08.006},
  urldate = {2024-06-23},
  abstract = {Computer-mediated intergroup contact (CMIC) is a valuable strategy to reduce negative sentiments towards members of different social groups. We examined whether characteristics of communication media that facilitate intergroup encounters shape its effect on out-group attitudes. Specifically, we propose that concealing individuating cues about out-group members during CMIC increases prejudice, as interaction partners are perceived as less socially present. To assess these hypotheses, we conducted two mixed-factorial experiments. Participants engaged in synchronous text-chat with out-group members (Study 1) and a confederate (Study 2) who either shared or concealed their name and photo. Overall, CMIC reduced negative out-group sentiments. Study 2 showed, however, that out-group members' anonymity decreased perceived social presence, which was associated with less positive evaluations of the CMIC and higher prejudice. In conclusion, CMIC can contribute to conflict resolution interventions, preparing individuals for direct intergroup contact, if its affordances or conversation topics enhance interaction partners' social presence.},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/JL26XAST/Schumann et al. - 2017 - When is computer-mediated intergroup contact most .pdf}
}

@article{schwartzProductiveAgencyThat1998,
  title = {The {{Productive Agency}} That {{Drives Collaborative Learning}}},
  author = {Schwartz, Daniel L},
  year = {1998},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/K2HB2ZH3/Schwartz - 1998 - The Productive Agency that Drives Collaborative Le.pdf}
}

@article{schweigerEmpiricalEvaluationDialectial1985,
  title = {An {{Empirical Evaluation}} of {{Dialectial Inquiry}}, {{Devil}}'s {{Advocate}}, and {{Consensus Approaches}} to {{Strategic Decision Making}}.},
  author = {Schweiger, David M. and Sandberg, William R. and Ragan, James W.},
  year = {1985},
  month = aug,
  journal = {Academy of Management Proceedings},
  volume = {1985},
  number = {1},
  pages = {40--44},
  publisher = {Academy of Management},
  issn = {0065-0668},
  doi = {10.5465/ambpp.1985.4978266},
  urldate = {2024-07-18},
  abstract = {A laboratory study was conducted comparing the effectiveness of the Dialectical Inquiry, Devil's Advocate, and Consensus approaches to group strategic decision making. Both DI and DA approaches resulted in higher quality recommendations and assumptions than the C approach. Subjects in the C groups, however, expressed more satisfaction and desire to continue to work with the group, and greater acceptance of the group's decision.}
}

@article{schweigerExperientialEffectsDialectical1989,
  title = {Experiential {{Effects}} of {{Dialectical Inquiry}}, {{Devil}}'s {{Advocacy}} and {{Consensus Approaches}} to {{Strategic Decision Making}}},
  author = {Schweiger, David M. and Sandberg, William R. and Rechner, Paula L.},
  year = {1989},
  month = dec,
  journal = {Academy of Management Journal},
  volume = {32},
  number = {4},
  pages = {745--772},
  publisher = {Academy of Management},
  issn = {0001-4273},
  doi = {10.5465/256567},
  urldate = {2024-07-18},
  abstract = {This longitudinal laboratory study of fast-advancing middle managers involved in strategic planning compared the effectiveness of dialectical inquiry, devil's advocacy, and consensus approaches to group strategic decision making. Compared to consensus groups, groups using dialectical inquiry and devil's advocacy made significantly higher quality decisions. Members of such groups reported more reevaluation of their own assumptions and recommendations but lower acceptance of their group's decisions than members of consensus groups. There were no differences between dialectical inquiry and devil's advocacy groups. Experience in using the three decision-making approaches improved decision quality, critical reevaluation levels, and the reactions of group members and reduced the time required to reach decisions.}
}

@article{schweigerGroupApproachesImproving1986,
  title = {Group {{Approaches}} for {{Improving Strategic Decision Making}}: {{A Comparative Analysis}} of {{Dialectical Inquiry}}, {{Devil}}'s {{Advocacy}}, and {{Consensus}}},
  shorttitle = {Group {{Approaches}} for {{Improving Strategic Decision Making}}},
  author = {Schweiger, David M. and Sandberg, William R. and Ragan, James W.},
  year = {1986},
  month = mar,
  journal = {Academy of Management Journal},
  volume = {29},
  number = {1},
  pages = {51--71},
  publisher = {Academy of Management},
  issn = {0001-4273},
  doi = {10.5465/255859},
  urldate = {2024-07-18},
  abstract = {This laboratory study compared the effectiveness of the dialectical inquiry, devil's advocacy, and consensus approaches to strategic decision making by groups. Results showed that both dialectical inquiry and devil's advocacy led to higher quality recommendations and assumptions than consensus. Dialectical inquiry was also more effective than devil's advocacy with respect to the quality of assumptions brought to the surface. However, subjects in the consensus groups expressed more satisfaction and desire to continue to work with their groups and greater acceptance of their groups' decisions than did subjects in either of the two other types of group studied.}
}

@article{schweigerLongitudinalComparativeAnalysis1988,
  title = {A {{Longitudinal Comparative Analysis}} of {{Dialectical Inquiry}}, {{Devil}}'s {{Advocacy}} and {{Consensus Approaches}} to {{Strategic Decision Making}}.},
  author = {Schweiger, David M. and Sandberg, Wiliam R. and Rechner, Paula},
  year = {1988},
  month = aug,
  journal = {Academy of Management Proceedings},
  volume = {1988},
  number = {1},
  pages = {32--36},
  publisher = {Academy of Management},
  issn = {0065-0668},
  doi = {10.5465/ambpp.1988.4979642},
  urldate = {2024-07-18},
  abstract = {This longitudinal laboratory study using "fast track" middle managers involved in strategic planning found that both DI and DA were more effective than C and all were more effective with experience.}
}

@article{schwenkDevilsAdvocacyManagerial1984,
  title = {Devil's {{Advocacy}} in {{Managerial Decision-Making}}},
  author = {Schwenk, Charles R.},
  year = {1984},
  journal = {Journal of Management Studies},
  volume = {21},
  number = {2},
  pages = {153--168},
  issn = {1467-6486},
  doi = {10.1111/j.1467-6486.1984.tb00229.x},
  urldate = {2024-07-18},
  abstract = {There is some debate about the potential value of using devil's advocates in top-level organizational decision-making. In this paper, the contrasting views on this question are summarized briefly and the field and laboratory research on the devil's advocate and related techniques is discussed. This research is then used as the basis for detailed suggestions on the effective use of devil's advocates in improving managerial decisions.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/GNXHAJVZ/Schwenk - 1984 - Devil's Advocacy in Managerial Decision-Making.pdf}
}

@article{schwenkEffectsDevilsAdvocacy1994,
  title = {Effects of {{Devil}}{$\prime$}s {{Advocacy}} and {{Dialectical Inquiry}} on {{Individuals}} versus {{Groups}}},
  author = {Schwenk, Charles and Valacich, Joseph S.},
  year = {1994},
  month = aug,
  journal = {Organizational Behavior and Human Decision Processes},
  volume = {59},
  number = {2},
  pages = {210--222},
  issn = {0749-5978},
  doi = {10.1006/obhd.1994.1057},
  urldate = {2024-07-18},
  abstract = {There is a long history of research that has investigated the effects of cognitive conflict on group and individual decision making. No study has simultaneously compared the effects of two techniques, devil{$\prime$}s advocacy and dialectical inquiry, on the performance of individuals versus groups. In this paper, we report the results of a laboratory experiment that makes this comparison. Artificial groups (groups formed by pooling individuals working independently) obtained an overall lower-quality solution for a case analysis problem than intact groups. However, there were no performance differences between intact groups and the performance of the best member of artificial groups. When artificial and intact groups were examined together, those given the devil{$\prime$}s advocacy treatment produced higher-quality solutions than those given the dialectical inquiry treatment and a simpler expert-based approach involving no conflict. Intact groups given the devil{$\prime$}s advocacy treatment produced higher-quality solutions than those given the expert treatment. Artificial groups given devil{$\prime$}s advocacy produced higher-quality solutions than those given the expert or dialectical inquiry treatment. Overall, the results suggest that the devil{$\prime$}s advocacy treatment has a slightly greater advantage over the dialectical inquiry with individuals than with groups.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/MTXULYHV/S0749597884710570.html}
}

@article{seboRobotsGroupsTeams2020,
  title = {Robots in {{Groups}} and {{Teams}}: {{A Literature Review}}},
  shorttitle = {Robots in {{Groups}} and {{Teams}}},
  author = {Sebo, Sarah and Stoll, Brett and Scassellati, Brian and Jung, Malte F.},
  year = {2020},
  month = oct,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {4},
  number = {CSCW2},
  pages = {176:1--176:36},
  doi = {10.1145/3415247},
  urldate = {2025-02-07},
  abstract = {Autonomous robots are increasingly placed in contexts that require them to interact with groups of people rather than just a single individual. Interactions with groups of people introduce nuanced challenges for robots, since robots? actions influence both individual group members and complex group dynamics. We review the unique roles robots can play in groups, finding that small changes in their nonverbal behavior and personality impacts group behavior and, by extension, influences ongoing interpersonal interactions.},
  annotation = {TLDR: The unique roles robots can play in groups are reviewed, finding that small changes in their nonverbal behavior and personality impacts group behavior and, by extension, influences ongoing interpersonal interactions.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/ISF3GZM5/Sebo et al. - 2020 - Robots in Groups and Teams A Literature Review.pdf}
}

@inproceedings{sembroskiHeSaidShe2017,
  title = {He Said, She Said, It Said: {{Effects}} of Robot Group Membership and Human Authority on People's Willingness to Follow Their Instructions},
  shorttitle = {He Said, She Said, It Said},
  booktitle = {2017 26th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}} ({{RO-MAN}})},
  author = {Sembroski, Catherine E. and Fraune, Marlena R and {\v S}abanovi{\'c}, Selma},
  year = {2017},
  month = aug,
  pages = {56--61},
  publisher = {IEEE Press},
  address = {Lisbon, Portugal},
  doi = {10.1109/ROMAN.2017.8172280},
  urldate = {2024-07-18},
  abstract = {Research in HRI indicates that people follow a robot's instructions even when they are incorrect. However, when a robot's instructions or requests contradict those of a human (e.g. an authoritative experimenter), people obey the human instead. This might be due to the experimenter's perceived ingroup status, or to their higher presumed authority compared to the robot. This study manipulated experimenter authority (high, low) and robot group membership (ingroup, neutral) to test how they affected responses to conflicting orders from the two agents depending on the request's importance (big, small). While there was no main effect of group membership and authority on most participant behavior, when experimenter authority was low and the robot an ingroup member, participants defied the experimenter's instructions to turn off an ingroup robot at the end of the experiment, following the robot's instructions instead. Further, request importance affected participant behavior. Participants typically followed the robot's low-importance requests (e.g., moving from one chair to another), but not high-importance requests (e.g., how to perform a simulated task of diagnosing and talking to patients).}
}

@inproceedings{setaDividedPresenceImproving2018,
  title = {Divided {{Presence}}: {{Improving Group Decision-Making}} via {{Pseudo-Population Increase}}},
  shorttitle = {Divided {{Presence}}},
  booktitle = {Proceedings of the 6th {{International Conference}} on {{Human-Agent Interaction}}},
  author = {Seta, Keisuke and Yokoyama, Masanori and Yoshida, Shigeo and Narumi, Takuji and Tanikawa, Tomohiro and Hirose, Michitaka},
  year = {2018},
  month = dec,
  series = {{{HAI}} '18},
  pages = {260--268},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3284432.3284443},
  urldate = {2024-07-19},
  abstract = {During group decision-making, a group with an imbalanced minority and majority typically suffers normative bias. This bias creates socio-emotional conflict and decreases group member consent and decision power. Thus, we propose a novel video-chat system, "Divided Presence," which aims to reduce this bias by equalizing the apparent number of majority and minority participants using a pseudo-population increase. Members of a discussion use computer graphics avatars on monitors instead of their actual video appearances during communication. The apparent number of discussion members increases when two avatars are assigned to an arbitrary minority member; the avatars then speak on behalf of him or her. We evaluate the system with a three-person consensus game, where a minority member is assigned two avatars. The results show that our system increases the degree of consent among the majority participants when they finally agree to the minority opinion.},
  isbn = {978-1-4503-5953-5}
}

@article{seyranianDimensionsMajorityMinority2008,
  title = {Dimensions of {{Majority}} and {{Minority Groups}}},
  author = {Seyranian, Viviane and Atuel, Hazel and Crano, William D.},
  year = {2008},
  month = jan,
  journal = {Group Processes \& Intergroup Relations},
  volume = {11},
  number = {1},
  pages = {21--37},
  publisher = {SAGE Publications Ltd},
  issn = {1368-4302},
  doi = {10.1177/1368430207084843},
  urldate = {2024-07-19},
  abstract = {Several definitions of majority and minority groups can be found in the social psychological literature. They involve numeric size, power/status, and counternormative position, but size is most commonly used in experimental research to manipulate minority/minority status. Does this practice mirror real-world conceptualizations? To address this question, 77 participants were asked to describe majority and minority groups using a structured openended measure. Content analysis of their responses revealed that majority and minority groups were conceptualized along eight dimensions, which included power, number, distinctiveness, social category, group context, dispositions, and being the source or target of behavior. Although these dimensions were relevant to both majorities and minorities, they often were applied differentially. Also, minorities were associated with more divergent thinking and viewed more negatively than were majorities. On the basis of these findings, a new typology of groups was proposed that could be used in future experimental research to advance our understanding of majorities and minorities.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/3NP95LDB/Seyranian et al. - 2008 - Dimensions of Majority and Minority Groups.pdf}
}

@misc{shaerAIAugmentedBrainwritingInvestigating2024,
  title = {{{AI-Augmented Brainwriting}}: {{Investigating}} the Use of {{LLMs}} in Group Ideation},
  shorttitle = {{{AI-Augmented Brainwriting}}},
  author = {Shaer, Orit and Cooper, Angelora and Mokryn, Osnat and Kun, Andrew L. and Shoshan, Hagit Ben},
  year = {2024},
  month = feb,
  number = {arXiv:2402.14978},
  eprint = {2402.14978},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.14978},
  urldate = {2024-03-27},
  abstract = {The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process - the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework, which incorporated an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation. We conclude by discussing implications for HCI education and practice.},
  archiveprefix = {arXiv},
  keywords = {notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/B73GE6MZ/Shaer 등 - 2024 - AI-Augmented Brainwriting Investigating the use o.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/2MYXEDIU/2402.html}
}

@misc{shaikhRehearsalSimulatingConflict2024,
  title = {Rehearsal: {{Simulating Conflict}} to {{Teach Conflict Resolution}}},
  shorttitle = {Rehearsal},
  author = {Shaikh, Omar and Chai, Valentino and Gelfand, Michele J. and Yang, Diyi and Bernstein, Michael S.},
  year = {2024},
  month = feb,
  number = {arXiv:2309.12309},
  eprint = {2309.12309},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.12309},
  urldate = {2024-04-02},
  abstract = {Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual "what if?" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own setting. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67\%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.},
  archiveprefix = {arXiv},
  keywords = {notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/BGDYH98I/Shaikh 등 - 2024 - Rehearsal Simulating Conflict to Teach Conflict R.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/D7SH7XE4/2309.html}
}

@article{sharmaGroupDecisionMaking2016,
  title = {Group Decision Making in Health Care: {{A}} Case Study of Multidisciplinary Meetings},
  shorttitle = {Group Decision Making in Health Care},
  author = {Sharma, Vishakha and Stranieri, Andrew and Burstein, Frada and Warren, Jim and Daly, Sharon and Patterson, Louise and Yearwood, John and Wolff, Alan},
  year = {2016},
  month = jun,
  journal = {Journal of Decision Systems},
  volume = {25},
  number = {sup1},
  pages = {476--485},
  publisher = {Taylor \& Francis},
  issn = {1246-0125},
  doi = {10.1080/12460125.2016.1187388},
  urldate = {2024-08-09},
  abstract = {Recent studies have demonstrated that Multi-Disciplinary Meetings (MDM) practiced in some medical contexts can contribute to positive health care outcomes. The group reasoning and decision-making in MDMs has been found to be most effective when deliberations revolve around the patient's needs, comprehensive information is available during the meeting, core members attend and the MDM is effectively facilitated. This article presents a case study of the MDMs in cancer care in a region of Australia. The case study draws on a group reasoning model called the Reasoning Community model to analyse MDM deliberations to illustrate that many factors are important to support group reasoning, not solely the provision of pertinent information. The case study has implications for the use of data analytics in any group reasoning context.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/ESYJ8MQC/Sharma et al. - 2016 - Group decision making in health care A case study.pdf}
}

@article{shneidermanBridgingGapEthics2020,
  title = {Bridging the {{Gap Between Ethics}} and {{Practice}}: {{Guidelines}} for {{Reliable}}, {{Safe}}, and {{Trustworthy Human-centered AI Systems}}},
  shorttitle = {Bridging the {{Gap Between Ethics}} and {{Practice}}},
  author = {Shneiderman, Ben},
  year = {10월 16, 2020},
  journal = {ACM Transactions on Interactive Intelligent Systems},
  volume = {10},
  number = {4},
  pages = {26:1--26:31},
  issn = {2160-6455},
  doi = {10.1145/3419764},
  urldate = {2023-06-07},
  abstract = {This article attempts to bridge the gap between widely discussed ethical principles of Human-centered AI (HCAI) and practical steps for effective governance. Since HCAI systems are developed and implemented in multiple organizational structures, I propose 15 recommendations at three levels of governance: team, organization, and industry. The recommendations are intended to increase the reliability, safety, and trustworthiness of HCAI systems: (1) reliable systems based on sound software engineering practices, (2) safety culture through business management strategies, and (3) trustworthy certification by independent oversight. Software engineering practices within teams include audit trails to enable analysis of failures, software engineering workflows, verification and validation testing, bias testing to enhance fairness, and explainable user interfaces. The safety culture within organizations comes from management strategies that include leadership commitment to safety, hiring and training oriented to safety, extensive reporting of failures and near misses, internal review boards for problems and future plans, and alignment with industry standard practices. The trustworthiness certification comes from industry-wide efforts that include government interventions and regulation, accounting firms conducting external audits, insurance companies compensating for failures, non-governmental and civil society organizations advancing design principles, and professional organizations and research institutes developing standards, policies, and novel ideas. The larger goal of effective governance is to limit the dangers and increase the benefits of HCAI to individuals, organizations, and society.},
  langid = {american},
  annotation = {TLDR: 15 recommendations are intended to increase the reliability, safety, and trustworthiness of HCAI systems: reliable systems based on sound software engineering practices, safety culture through business management strategies, and trustworthy certification by independent oversight.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/E9JTJHCM/Shneiderman - 2020 - Bridging the Gap Between Ethics and Practice Guid.pdf}
}

@book{shneidermanDesigningUserInterface2016,
  title = {Designing the {{User Interface}}: {{Strategies}} for {{Effective Human-Computer Interaction}}},
  shorttitle = {Designing the {{User Interface}}},
  author = {Shneiderman, Ben and Plaisant, Catherine and Cohen, Maxine and Jacobs, Steven and Elmqvist, Niklas and Diakopoulos, Nicholas},
  year = {2016},
  month = mar,
  edition = {6th},
  publisher = {Pearson},
  abstract = {For courses in Human-Computer Interaction. The Sixth Edition of Designing the User Interface provides a comprehensive, authoritative, and up-to-date introduction to the dynamic field of human-computer interaction (HCI) and user experience (UX) design. This classic book has defined and charted the astonishing evolution of user interfaces for three decades. Students and professionals learn practical principles and guidelines needed to develop high quality interface designs that users can understand, predict, and control. The book covers theoretical foundations and design processes such as expert reviews and usability testing. By presenting current research andinnovations in human-computer interaction, the authors strive toinspire students, guide designers, and provoke researchers to seek solutions that improve the experiences of novice and expert users, while achieving universal usability. The authors also provide balanced presentations on controversial topics such as augmented and virtual reality, voice and natural language interfaces, and information visualization. Updates include current HCI design methods, new design examples, and totally revamped coverage of social media, search and voice interaction. Major revisions were made toEVERY chapter, changing almost every figure (170 new color figures) and substantially updating the references.},
  isbn = {978-0-13-438038-4}
}

@book{shortSocialPsychologyTelecommunications1976,
  title = {The Social Psychology of Telecommunications},
  author = {Short, John},
  year = {1976},
  publisher = {London ; New York : Wiley},
  urldate = {2025-01-21},
  abstract = {ix, 195 p. : 24 cm; Bibliography: p. [175]-188; Includes indexes},
  collaborator = {{Internet Archive}},
  isbn = {978-0-471-01581-9},
  langid = {english}
}

@article{simmelSoziologieUntersuchungenUber2013,
  title = {Soziologie. : {{Untersuchungen}} {\"U}ber Die {{Formen}} Der {{Vergesellschaftung}}.},
  shorttitle = {Soziologie.},
  author = {Simmel, Georg},
  year = {2013},
  pages = {1--602},
  publisher = {Duncker \& Humblot},
  urldate = {2024-07-18},
  abstract = {Purchase online the PDF of Soziologie., Simmel, Georg - Duncker \& Humblot - E-book},
  langid = {english}
}

@article{smith-lovinInterruptionsGroupDiscussions1989,
  title = {Interruptions in {{Group Discussions}}: {{The Effects}} of {{Gender}} and {{Group Composition}}},
  shorttitle = {Interruptions in {{Group Discussions}}},
  author = {{Smith-Lovin}, Lynn and Brody, Charles},
  year = {1989},
  journal = {American Sociological Review},
  volume = {54},
  number = {3},
  eprint = {2095614},
  eprinttype = {jstor},
  pages = {424--435},
  publisher = {[American Sociological Association, Sage Publications, Inc.]},
  issn = {0003-1224},
  doi = {10.2307/2095614},
  urldate = {2024-07-19},
  abstract = {Conversations both reflect and maintain social inequalities. They import hierarchical structures from larger society and help perpetuate them by creating inequalities in the ability to accomplish interactional goals. In this study of speaker transitions in six-person, task-oriented experimental groups, we explore the well-known finding that men interrupt women more frequently than women interrupt men. We ask three questions about the structure of interruptions. Who attempts to interrupt whom and under what conditions? How does the affective character of interruptions vary across speakers and groups? What determines whether an interruption succeeds? We find that gender inequality in these task-oriented discussions is created by a mixture of attempts to use power and of differential success. In their interruptions, men discriminate by sex in attempts and in yielding to interruptions by others. Women interrupt and yield the floor to males and females equally. The sex composition of the group affects interruption patterns in complex ways. Men interrupt men with supportive comments in all-male groups, but these supportive interruptions drop as the number of women in the group increases. Supportive interruptions also succeed in gaining the floor more often in single-sex groups. Taken together, the results suggest a mixture of status and conflict models and reaffirm the importance of group composition in interaction.}
}

@article{sniezekCueingCognitiveConflict1995,
  title = {Cueing and {{Cognitive Conflict}} in {{Judge-Advisor Decision Making}}},
  author = {Sniezek, Janet A. and Buckley, Timothy},
  year = {1995},
  month = may,
  journal = {Organizational Behavior and Human Decision Processes},
  volume = {62},
  number = {2},
  pages = {159--174},
  issn = {0749-5978},
  doi = {10.1006/obhd.1995.1040},
  urldate = {2024-07-18},
  abstract = {The Judge-Advisor paradigm (Sniezek \& Buckley, 1989) allows for the study of decision making by groups with differentiated roles. This paper reports a study using this approach to investigate the impact of advice vis-{\`a}-vis the judge{$\prime$}s own initial choice. Teams consisting of one judge and two advisors (business students randomly assigned to these roles) were given a choice task (concerning business events) composed of 70 items with two alternatives each. The judges provided final team choices and confidence assessments under one of three conditions: Dependent (judge has no basis for own choice), Cued (judge chooses only after being advised), or Independent (judges makes own tentative choice prior to being advised as well as subsequent final choice). Results showed that this manipulation affected the judge{$\prime$}s final choice accuracy and confidence, leading to the best performance by Independent judges and the poorest by Dependent judges. These data are discussed with respect to theory and data on the cueing effect (Sniezek, Paese, \& Switzer, 1990) for individual choice. In addition, the effects on the decision making process of the judge from (a) advisors{$\prime$} confidence and (b) conflict between advisors{$\prime$} recommendations are examined in detail. Finally, issues concerning the potential contribution of the Judge-Advisor paradigm to the understanding of social decision making are addressed.}
}

@misc{SocialPsychologyTelecommunications,
  title = {The Social Psychology of Telecommunications {\textbar} {{Semantic Scholar}}},
  urldate = {2025-01-21},
  howpublished = {https://www.semanticscholar.org/paper/The-social-psychology-of-telecommunications-Short-Williams/0d9658d9e1ba9adc9e0f691347a251ed8335e030},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/2NUHSJE9/0d9658d9e1ba9adc9e0f691347a251ed8335e030.html}
}

@article{spearsDeindividuationGroupPolarization1990,
  title = {De-Individuation and Group Polarization in Computer-Mediated Communication},
  author = {Spears, Russell and Lea, Martin and Lee, Stephen},
  year = {1990},
  journal = {British Journal of Social Psychology},
  volume = {29},
  number = {2},
  pages = {121--134},
  issn = {2044-8309},
  doi = {10.1111/j.2044-8309.1990.tb00893.x},
  urldate = {2024-06-23},
  abstract = {A computer-mediated communication system (CMCS) was used to explore the effects of de-individuation on group polarization. Reicher (1984) argued that de-individuating members of a group should increase the salience of group identity and hence normative behaviour, while de-individuating subjects treated as individuals should have the reverse effect. We extended this idea to the group polarization paradigm and in addition independently manipulated group salience and de-individuation, which were confounded factors in Reicher's study. It was reasoned that the visual anonymity created by isolating discussants in separate rooms would be de-individuating compared to seating them together in the same room. At the same time either the subject's group or individual identity was made salient. A computer-mediated communication system provided text-based communication for discussants in all four conditions. Assuming that group polarization reflects conformity to a group norm (Turner, Hogg, Oakes, Reicher \& Wetherell, 1987), we predicted an interaction between the de-individuation and group salience factors, such that greatest polarization in the direction of a pre-established group norm would be obtained in the de-individuated---group condition and least in the de-individuated---individual condition. This prediction was confirmed. Explanations of the findings in terms of Reicher's earlier study and in terms of self-attention processes are considered within the general framework of social identity theory. Finally, the relevance of this research to the realm of human communication via computer networks is evaluated.},
  copyright = {1990 The British Psychological Society},
  langid = {english},
  keywords = {notion}
}

@incollection{stahlCommentaryRediscoveringCSCL2001,
  title = {Commentary: {{Rediscovering CSCL}}},
  shorttitle = {Commentary},
  booktitle = {Cscl 2},
  author = {Stahl, Gerry},
  year = {2001},
  publisher = {Routledge},
  abstract = {In their penultimate sentence, Hakkarainen, Lipponen, and J{\"a}rvel{\"a} (this volume) correctly point out that CSCL researchers have a complex challenge because the educational use of new information/communication technologies is inextricably bound up with new pedagogical and cognitive practices of learning and instruction. The na{\"i}ve, technology-driven view was that tools such as CSILE would make a significant difference on their own. The subsequent experience has been that the classroom culture bends such tools to its own interests and that this culture must be transformed before new media can mediate learning the way we had hoped they would. So CSCL research has necessarily and properly shifted from the affordances and effects of the technology to concerns with the instructional context. Thus, the central conclusions of Chapters 3 and 4 focus on the teacher's role and say little that pertains to the presence of CSILE.},
  isbn = {978-1-4106-0154-4}
}

@article{stasserDiscoveryHiddenProfiles1992,
  title = {Discovery of Hidden Profiles by Decision-Making Groups: {{Solving}} a Problem versus Making a Judgment},
  shorttitle = {Discovery of Hidden Profiles by Decision-Making Groups},
  author = {Stasser, Garold and Stewart, Dennis},
  year = {1992},
  journal = {Journal of Personality and Social Psychology},
  volume = {63},
  number = {3},
  pages = {426--434},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1315},
  doi = {10.1037/0022-3514.63.3.426},
  abstract = {An information-sampling model proposed by G. Stasser and W. Titus (1985, 1987) and observations of discussion content (Stasser et al, 1989) suggest that face-to-face discussions often fail to disseminate unshared information. However, groups may be less prone to overlooking unshared information if they believe that their task has a demonstrably correct answer (P. R. Laughlin, 1980). University students read a murder mystery and then met in groups to discuss the case. Groups believed they had either sufficient (solve set) or insufficient (judge set) evidence to determine the guilty suspect. When critical clues were unshared before discussion, 67\% of solve, but only 35\% of judge, groups identified the guilty suspect. Discussion content analyses show that solve groups focused more on the critical clues. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@article{stasserInformationSamplingStructured1989,
  title = {Information Sampling in Structured and Unstructured Discussions of Three- and Six-Person Groups},
  author = {Stasser, Garold and Taylor, Laurie A. and Hanna, Coleen},
  year = {1989},
  journal = {Journal of Personality and Social Psychology},
  volume = {57},
  number = {1},
  pages = {67--78},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1315},
  doi = {10.1037/0022-3514.57.1.67},
  abstract = {Predictions from an information sampling model of group discussion were examined (Stasser \& Titus, 1985, 1987): (a) Groups are more likely to discuss information if it is held by all members than if it is held by 1 member, and (b) this focus on already shared information increases as group size increases. University students read descriptions of candidates for student body president. These descriptions were constructed so that some information (unshared) was read by 1 member before discussion, whereas other information (shared) was read by all members. Three- and 6-person groups discussed the candidates and decided which was best suited for the position. As predicted, discussions contained, on the average, 46\% of the shared but only 18\% of the unshared information; this difference was greater for 6-person than for 3-person groups. Moreover, structuring discussions increased the amount of information discussed, but this increase was predominately due to discussion of already shared information. (PsycINFO Database Record (c) 2016 APA, all rights reserved)}
}

@inproceedings{stauferSilencingRiskNot2024,
  title = {Silencing the {{Risk}}, {{Not}} the {{Whistle}}: {{A Semi-automated Text Sanitization Tool}} for {{Mitigating}} the {{Risk}} of {{Whistleblower Re-Identification}}},
  shorttitle = {Silencing the {{Risk}}, {{Not}} the {{Whistle}}},
  booktitle = {Proceedings of the 2024 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Staufer, Dimitri and Pallas, Frank and Berendt, Bettina},
  year = {2024},
  month = jun,
  series = {{{FAccT}} '24},
  pages = {733--745},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3630106.3658936},
  urldate = {2024-07-21},
  abstract = {Whistleblowing is essential for ensuring transparency and accountability in both public and private sectors. However, (potential) whistleblowers often fear or face retaliation, even when reporting anonymously. The specific content of their disclosures and their distinct writing style may re-identify them as the source. Legal measures, such as the EU Whistleblower Directive, are limited in their scope and effectiveness. Therefore, computational methods to prevent re-identification are important complementary tools for encouraging whistleblowers to come forward. However, current text sanitization tools follow a one-size-fits-all approach and take an overly limited view of anonymity. They aim to mitigate identification risk by replacing typical high-risk words (such as person names and other labels of named entities) and combinations thereof with placeholders. Such an approach, however, is inadequate for the whistleblowing scenario since it neglects further re-identification potential in textual features, including the whistleblower's writing style. Therefore, we propose, implement, and evaluate a novel classification and mitigation strategy for rewriting texts that involves the whistleblower in the assessment of the risk and utility. Our prototypical tool semi-automatically evaluates risk at the word/term level and applies risk-adapted anonymization techniques to produce a grammatically disjointed yet appropriately sanitized text. We then use a Large Language Model (LLM) that we fine-tuned for paraphrasing to render this text coherent and style-neutral. We evaluate our tool's effectiveness using court cases from the European Court of Human Rights (ECHR) and excerpts from a real-world whistleblower testimony and measure the protection against authorship attribution attacks and utility loss statistically using the popular IMDb62 movie reviews dataset, which consists of 62 individuals. Our method can significantly reduce authorship attribution accuracy from 98.81\% to 31.22\%, while preserving up to 73.1\% of the original content's semantics, as measured by the established cosine similarity of sentence embeddings.},
  isbn = {9798400704505},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/9LA3TKYM/Staufer et al. - 2024 - Silencing the Risk, Not the Whistle A Semi-automa.pdf}
}

@book{sternbergNatureCreativityContemporary1988,
  title = {The {{Nature}} of {{Creativity}}: {{Contemporary Psychological Perspectives}}},
  shorttitle = {The {{Nature}} of {{Creativity}}},
  author = {Sternberg, Robert J.},
  year = {1988},
  month = may,
  publisher = {CUP Archive},
  abstract = {Originally published in 1988, this book provides sixteen chapters by acknowledged experts on the richness and diversity of psychological approaches to the study of creativity. Addressing various aspects and levels of analysis, together they constitute a broad survey of the understanding of what it is to be 'creative'. In the first part of The Nature of Creativity, the role of the environment is discussed. In the second part, the role of the individual is viewed - first from a psychometric perspective; and then from a cognitive or information-processing perspective. In the third part, the role of interaction between individual and environment is examined, first through studies of creative lives; and then through studies of creative systems. The final part consists of an integration and comparison of these various approaches to creativity. A broad audience of psychologists, educators, students and general readers will welcome this lively and thought-provoking investigation.},
  googlebooks = {ZYo5AAAAIAAJ},
  isbn = {978-0-521-33892-9},
  langid = {english}
}

@misc{stevensonPuttingGPT3sCreativity2022,
  title = {Putting {{GPT-3}}'s {{Creativity}} to the ({{Alternative Uses}}) {{Test}}},
  author = {Stevenson, Claire and Smal, Iris and Baas, Matthijs and Grasman, Raoul and {van der Maas}, Han},
  year = {2022},
  month = jun,
  number = {arXiv:2206.08932},
  eprint = {2206.08932},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2206.08932},
  urldate = {2024-07-18},
  abstract = {AI large language models have (co-)produced amazing written works from newspaper articles to novels and poetry. These works meet the standards of the standard definition of creativity: being original and useful, and sometimes even the additional element of surprise. But can a large language model designed to predict the next text fragment provide creative, out-of-the-box, responses that still solve the problem at hand? We put Open AI's generative natural language model, GPT-3, to the test. Can it provide creative solutions to one of the most commonly used tests in creativity research? We assessed GPT-3's creativity on Guilford's Alternative Uses Test and compared its performance to previously collected human responses on expert ratings of originality, usefulness and surprise of responses, flexibility of each set of ideas as well as an automated method to measure creativity based on the semantic distance between a response and the AUT object in question. Our results show that -- on the whole -- humans currently outperform GPT-3 when it comes to creative output. But, we believe it is only a matter of time before GPT-3 catches up on this particular task. We discuss what this work reveals about human and AI creativity, creativity testing and our definition of creativity.},
  archiveprefix = {arXiv},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/UI7TFTAU/Stevenson et al. - 2022 - Putting GPT-3's Creativity to the (Alternative Use.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/USFPYJR5/2206.html}
}

@article{sundarRiseMachineAgency2020,
  title = {Rise of {{Machine Agency}}: {{A Framework}} for {{Studying}} the {{Psychology}} of {{Human}}--{{AI Interaction}} ({{HAII}})},
  shorttitle = {Rise of {{Machine Agency}}},
  author = {Sundar, S Shyam},
  year = {2020},
  month = mar,
  journal = {Journal of Computer-Mediated Communication},
  volume = {25},
  number = {1},
  pages = {74--88},
  issn = {1083-6101},
  doi = {10.1093/jcmc/zmz026},
  urldate = {2024-07-19},
  abstract = {Advances in personalization algorithms and other applications of machine learning have vastly enhanced the ease and convenience of our media and communication experiences, but they have also raised significant concerns about privacy, transparency of technologies and human control over their operations. Going forth, reconciling such tensions between machine agency and human agency will be important in the era of artificial intelligence (AI), as machines get more agentic and media experiences become increasingly determined by algorithms. Theory and research should be geared toward a deeper understanding of the human experience of algorithms in general and the psychology of Human--AI interaction (HAII) in particular. This article proposes some directions by applying the dual-process framework of the Theory of Interactive Media Effects (TIME) for studying the symbolic and enabling effects of the affordances of AI-driven media on user perceptions and experiences.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/DX3RKZU4/Sundar - 2020 - Rise of Machine Agency A Framework for Studying t.pdf}
}

@article{sundarSourceOrientationHumanComputer2000,
  title = {Source {{Orientation}} in {{Human-Computer Interaction}}: {{Programmer}}, {{Networker}}, or {{Independent Social Actor}}},
  shorttitle = {Source {{Orientation}} in {{Human-Computer Interaction}}},
  author = {SUNDAR, S. SHYAM and NASS, {\relax CLIFFORD}},
  year = {2000},
  month = dec,
  journal = {Communication Research},
  volume = {27},
  number = {6},
  pages = {683--703},
  publisher = {SAGE Publications Inc},
  issn = {0093-6502},
  doi = {10.1177/009365000027006001},
  urldate = {2024-07-19},
  abstract = {When individuals apply social rules and social expectations while working on a computer, are they directly interacting with the computer as an independent social actor or source (the CAS model), or are they orienting to an unseen programmer or imagined person in another room (the CAM model)? Two studies provide critical tests of these competing models. In Study 1, all participants were exposed to an identical interaction with computers. In one condition, participants were told that they were dealing with computers; in another, they were told that they were interacting with the software programmers. Consistent with the CAS model, there were significant differences between the two conditions. Study 2 performed a constructive replication of Study 1 by replacing the programmer with a hypothetical networker. Again, differences between the two conditions provide evidence that people respond to the computer as an independent source of information.},
  langid = {english}
}

@article{sunNonverbalSynchronyVirtual2019,
  title = {Nonverbal Synchrony in Virtual Reality},
  author = {Sun, Yilu and Shaikh, Omar and Won, Andrea Stevenson},
  year = {2019},
  month = sep,
  journal = {PLOS ONE},
  volume = {14},
  number = {9},
  pages = {e0221803},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0221803},
  urldate = {2024-07-19},
  abstract = {How might nonverbal synchrony naturally evolve in a social virtual reality environment? And how can avatar embodiment affect how participants coordinate nonverbally with each other? In the following pre-registered between-subjects experiment, we tracked the movements of pairs of users during a collaborative or competitive task in immersive virtual reality. Each conversational partner controlled either a customized avatar body or an abstract cube that responded to their movements. We compared the movements of the actual user pairs between the two conditions, and to an artificial ``pseudosynchrony'' dataset composed of the movements of randomly combined participant pairs who did not actually interact. We found stronger positive and negative correlations between real pairs compared to pseudosynchronous pairs, providing evidence for naturally occurring nonverbal synchrony between pairs in virtual reality. We discuss this in the context of the relationships between avatar appearance, task success, social closeness and social presence.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/FE2PA27R/Sun et al. - 2019 - Nonverbal synchrony in virtual reality.pdf}
}

@inproceedings{sureshMisplacedTrustMeasuring2020,
  title = {Misplaced {{Trust}}: {{Measuring}} the {{Interference}} of {{Machine Learning}} in {{Human Decision-Making}}},
  shorttitle = {Misplaced {{Trust}}},
  booktitle = {Proceedings of the 12th {{ACM Conference}} on {{Web Science}}},
  author = {Suresh, Harini and Lao, Natalie and Liccardi, Ilaria},
  year = {2020},
  month = jul,
  series = {{{WebSci}} '20},
  pages = {315--324},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3394231.3397922},
  urldate = {2024-07-18},
  abstract = {ML decision-aid systems are increasingly common on the web, but their successful integration relies on people trusting them appropriately: they should use the system to fill in gaps in their ability, but recognize signals that the system might be incorrect. We measured how people's trust in ML recommendations differs by expertise and with more system information through a task-based study of 175 adults. We used two tasks that are difficult for humans: comparing large crowd sizes and identifying similar-looking animals. Our results provide three key insights: (1) People trust incorrect ML recommendations for tasks that they perform correctly the majority of the time, even if they have high prior knowledge about ML or are given information indicating the system is not confident in its prediction; (2) Four different types of system information all increased people's trust in recommendations; and (3) Math and logic skills may be as important as ML for decision-makers working with ML recommendations.},
  isbn = {978-1-4503-7989-2},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/MSPNE9YR/Suresh et al. - 2020 - Misplaced Trust Measuring the Interference of Mac.pdf}
}

@article{swaabSecretConversationOpportunities2016,
  title = {Secret Conversation Opportunities Facilitate Minority Influence in Virtual Groups: {{The}} Influence on Majority Power, Information Processing, and Decision Quality},
  shorttitle = {Secret Conversation Opportunities Facilitate Minority Influence in Virtual Groups},
  author = {Swaab, Roderick I. and Phillips, Katherine W. and Schaerer, Michael},
  year = {2016},
  month = mar,
  journal = {Organizational Behavior and Human Decision Processes},
  volume = {133},
  pages = {17--32},
  issn = {0749-5978},
  doi = {10.1016/j.obhdp.2015.07.003},
  urldate = {2024-07-28},
  abstract = {We examined the impact of secret conversation opportunities during virtual team discussions on majority opinion holders' motivation to attend to minority opinion holders. Studies 1a and b showed that majorities were more motivated to process others' arguments when secret conversation opportunities were available (vs. not), provided these arguments contained unique (vs. shared) information and this information was offered by the minority (vs. majority). Study 2 demonstrated that this effect occurs because secret opportunities made majorities feel less powerful after being exposed to unique information from the minority (Study 2a), especially when majority members expected others to use these channels (Study 2b). Study 3 used an interactive group decision-making task and demonstrated that the increased majority motivation triggered by secret opportunities increased group decision quality. Study 3 also examined whether secret opportunities influence the minority and whether the effect is robust across different communication settings.}
}

@article{swellerEvidenceCognitiveLoad1991,
  title = {Evidence for {{Cognitive Load Theory}}},
  author = {Sweller, John and Chandler, Paul},
  year = {1991},
  month = dec,
  journal = {Cognition and Instruction},
  volume = {8},
  number = {4},
  pages = {351--362},
  publisher = {Routledge},
  issn = {0737-0008},
  doi = {10.1207/s1532690xci0804_5},
  urldate = {2025-01-21},
  abstract = {Dixon (1991) and Goldman (1991) have provided thoughtful commentaries on Chandler and Sweller (1991). The general issue they raise concerns the scientific procedures we should use when conducting research in cognition and instruction. It is an issue of great importance, and we welcome the opportunity provided by their criticisms to discuss the techniques we use. To clarify the findings based on cognitive load theory, we begin by indicating the essential characteristics of a theory concerned with cognition and instruction, followed by a brief history of cognitive load theory to make clear that it has these characteristics. These statements will then be used to address specific comments made by Goldman and Dixon.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/DETH9CXB/Sweller and Chandler - 1991 - Evidence for Cognitive Load Theory.pdf}
}

@misc{SyntheticTeammatesTeam,
  title = {Synthetic {{Teammates}} as {{Team Players}}: {{Coordination}} of {{Human}} and {{Synthetic Teammates}}},
  urldate = {2024-07-17},
  howpublished = {https://apps.dtic.mil/sti/citations/AD1017169}
}

@book{tabachnickUsingMultivariateStatistics2019,
  title = {Using Multivariate Statistics},
  author = {Tabachnick, Barbara G. and Fidell, Linda S. and Ullman, Jodie B.},
  year = {2019},
  edition = {Seventh edition},
  publisher = {Pearson},
  address = {NY, NY},
  isbn = {978-0-13-479054-1},
  langid = {english},
  lccn = {QA278 .T3 2019},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/QVVIBP5G/Tabachnick et al. - 2019 - Using multivariate statistics.pdf}
}

@book{tajfelDifferentiationSocialGroups1978,
  title = {Differentiation between Social Groups: {{Studies}} in the Social Psychology of Intergroup Relations},
  shorttitle = {Differentiation between Social Groups},
  editor = {Tajfel, Henri},
  year = {1978},
  series = {Differentiation between Social Groups: {{Studies}} in the Social Psychology of Intergroup Relations},
  pages = {xv, 474},
  publisher = {Academic Press},
  address = {Oxford, England},
  abstract = {Presents 17 articles which center around the basic thesis that there is a marked tendency to social differentiation instead of conformity, and that this promotes social innovation and creativity, in addition to conflict and waste. Among the topics covered are social categorization, achievement of group differentiation, and marginal social identity. (18 p ref) (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  isbn = {978-0-12-682550-3}
}

@article{tajfelSocialCategorizationIntergroup1971,
  title = {Social Categorization and Intergroup Behaviour},
  author = {Tajfel, Henri and Billig, M. G. and Bundy, R. P. and Flament, Claude},
  year = {1971},
  journal = {European Journal of Social Psychology},
  volume = {1},
  number = {2},
  pages = {149--178},
  issn = {1099-0992},
  doi = {10.1002/ejsp.2420010202},
  urldate = {2024-07-19},
  abstract = {The aim of the studies was to assess the effefcs of social categorization on intergroup behaviour when, in the intergroup situation, neither calculations of individual interest nor previously existing attitudes of hostility could have been said to have determined discriminative behaviour against an outgroup. These conditions were satisfied in the experimental design. In the first series of experiments, it was found that the subjects favoured their own group in the distribution of real rewards and penalities in a situation in which nothing but the variable of fairly irrelevant classification distinguished between the ingroup and the outgroup. In the second series of experiments it was found that: 1) maximum joint profit independent of group membership did not affect significantly the manner in which the subjects divided real pecuniary rewards; 2) maximum profit for own group did affect the distribution of rewards; 3) the clearest effect on the distribution of rewards was due to the subjects' attempt to achieve a maximum difference between the ingroup and the outgroup even at the price of sacrificing other `objective' advantages. The design and the results of the study are theoretically discussed within the framework of social norms and expectations and particularly in relation to a `generic' norm of outgroup behaviour prevalent in some societies.},
  copyright = {Copyright {\copyright} 1971 John Wiley \& Sons, Ltd},
  langid = {english}
}

@article{tanisSocialCuesImpression2003,
  title = {Social {{Cues}} and {{Impression Formation}} in {{CMC}}},
  author = {Tanis, Martin and Postmes, Tom},
  year = {2003},
  month = dec,
  journal = {Journal of Communication},
  volume = {53},
  number = {4},
  pages = {676--693},
  issn = {0021-9916},
  doi = {10.1111/j.1460-2466.2003.tb02917.x},
  urldate = {2024-06-23},
  abstract = {Social consequences of communication technology are based on widespread assumptions regarding effects of restricted capacity of mediated communication. Consequences are examined mostly in studies comparing face-to-face communication with various forms of mediated communication, confounding the availability of cues with other characteristics of media. Present research examines effects of restricted capacity to convey social cues independent of other differences between media. Assumptions are that limited capacity to convey social cues has negative consequences for the reduction of ambiguity and positivity of impressions, and limited capacity has particular social consequences. The first part of this assumption is confirmed in 3 studies. However, consequences of this limitation to convey social cues are less straightforward. The effect of limited capacity on the selecting of collaboration partners depends on the social identity of the parties involved.}
}

@inproceedings{tanprasertDebateChatbotsFacilitate2024,
  title = {Debate {{Chatbots}} to {{Facilitate Critical Thinking}} on {{YouTube}}: {{Social Identity}} and {{Conversational Style Make A Difference}}},
  shorttitle = {Debate {{Chatbots}} to {{Facilitate Critical Thinking}} on {{YouTube}}},
  booktitle = {Proceedings of the {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Tanprasert, Thitaree and Fels, Sidney S and Sinnamon, Luanne and Yoon, Dongwook},
  year = {2024},
  month = may,
  series = {{{CHI}} '24},
  pages = {1--24},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3613904.3642513},
  urldate = {2024-05-14},
  abstract = {Exposure to diverse perspectives is helpful for bursting the filter bubble in online public video platforms. The recent advancement of Large Language Models (LLMs) illuminates the potential of creating a debate chatbot that prompts users to critically examine their stances on a topic formed by watching videos. However, whether the viewer is influenced by the chatbot may depend on its persona. In this paper, we investigated the effect of two relevant persona attributes - social identity and rhetorical styles - on critical thinking. In a mixed-methods study (n=36), we found that chatbots with outgroup (vs. ingroup) identity (t(33)=-2.33, p=0.03) and persuasive (vs. eristic) rhetoric (t(44)=1.98, p=0.05) induced critical thinking most effectively, making participants re-examine their arguments. However, participants' stances remain largely unaffected, likely due to the chatbot's lack of contextual knowledge and human touch. Our paper provides empirical groundwork for designing chatbot persona for remedying filter bubbles in online communities.},
  isbn = {9798400703300},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/IEEC45AM/Tanprasert 등 - 2024 - Debate Chatbots to Facilitate Critical Thinking on.pdf}
}

@article{thomasFolkwaysStudySociological1907,
  title = {Folkways. {{A Study}} of the {{Sociological Importance}} of {{Usages}}, {{Manners}}, {{Customs}}, {{Mores}}, and {{Morals}}. {{By William Graham Sumner}}, {{Professor}} of {{Political}} and {{Social Science}} in {{Yale University}}. ({{Boston}}: {{Ginn}} and {{Company}}. 1907. {{Pp}}. v, 692.)},
  shorttitle = {Folkways. {{A Study}} of the {{Sociological Importance}} of {{Usages}}, {{Manners}}, {{Customs}}, {{Mores}}, and {{Morals}}. {{By William Graham Sumner}}, {{Professor}} of {{Political}} and {{Social Science}} in {{Yale University}}. ({{Boston}}},
  author = {Thomas, William I.},
  year = {1907},
  month = oct,
  journal = {The American Historical Review},
  volume = {13},
  number = {1},
  pages = {116--117},
  issn = {0002-8762},
  doi = {10.1086/ahr/13.1.116},
  urldate = {2024-07-19}
}

@inproceedings{tolmeijerCapableAmoralComparing2022,
  title = {Capable but {{Amoral}}? {{Comparing AI}} and {{Human Expert Collaboration}} in {{Ethical Decision Making}}},
  shorttitle = {Capable but {{Amoral}}?},
  booktitle = {Proceedings of the 2022 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Tolmeijer, Suzanne and Christen, Markus and Kandul, Serhiy and Kneer, Markus and Bernstein, Abraham},
  year = {2022},
  month = apr,
  series = {{{CHI}} '22},
  pages = {1--17},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3491102.3517732},
  urldate = {2024-07-18},
  abstract = {While artificial intelligence (AI) is increasingly applied for decision-making processes, ethical decisions pose challenges for AI applications. Given that humans cannot always agree on the right thing to do, how would ethical decision-making by AI systems be perceived and how would responsibility be ascribed in human-AI collaboration? In this study, we investigate how the expert type (human vs. AI) and level of expert autonomy (adviser vs. decider) influence trust, perceived responsibility, and reliance. We find that participants consider humans to be more morally trustworthy but less capable than their AI equivalent. This shows in participants' reliance on AI: AI recommendations and decisions are accepted more often than the human expert's. However, AI team experts are perceived to be less responsible than humans, while programmers and sellers of AI systems are deemed partially responsible instead.},
  isbn = {978-1-4503-9157-3},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/HDD6UCGQ/Tolmeijer et al. - 2022 - Capable but Amoral Comparing AI and Human Expert .pdf}
}

@inproceedings{tolmeijerFemaleDefaultExploring2021,
  title = {Female by {{Default}}? -- {{Exploring}} the {{Effect}} of {{Voice Assistant Gender}} and {{Pitch}} on {{Trait}} and {{Trust Attribution}}},
  shorttitle = {Female by {{Default}}?},
  booktitle = {Extended {{Abstracts}} of the 2021 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Tolmeijer, Suzanne and Zierau, Naim and Janson, Andreas and Wahdatehagh, Jalil Sebastian and Leimeister, Jan Marco Marco and Bernstein, Abraham},
  year = {2021},
  month = may,
  series = {{{CHI EA}} '21},
  pages = {1--7},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3411763.3451623},
  urldate = {2024-07-19},
  abstract = {Gendered voice based on pitch is a prevalent design element in many contemporary Voice Assistants (VAs) but has shown to strengthen harmful stereotypes. Interestingly, there is a dearth of research that systematically analyses user perceptions of different voice genders in VAs. This study investigates gender-stereotyping across two different tasks by analyzing the influence of pitch (low, high) and gender (women, men) on stereotypical trait ascription and trust formation in an exploratory online experiment with 234 participants. Additionally, we deploy a gender-ambiguous voice to compare against gendered voices. Our findings indicate that implicit stereotyping occurs for VAs. Moreover, we can show that there are no significant differences in trust formed towards a gender-ambiguous voice versus gendered voices, which highlights their potential for commercial usage.},
  isbn = {978-1-4503-8095-9}
}

@book{tropmanEffectiveMeetingsImproving2013,
  title = {Effective {{Meetings}}: {{Improving Group Decision Making}}},
  shorttitle = {Effective {{Meetings}}},
  author = {Tropman, John E.},
  year = {2013},
  month = dec,
  publisher = {SAGE Publications},
  abstract = {Lauded for its accessible format and humorous writing style, Effective Meetings: Improving Group Decision Making by John E. Tropman, offers practical strategies for running effective meetings by highlighting the processes involved in decision making and the ways individuals contribute to making better quality decisions as a group.   The Third Edition of this brief text begins with guidelines for effective decision making, then covers topics that include member recruitment, meeting preparation, agenda building, and the positions and roles required for effective meeting outcomes. Subsequent chapters deal with electronic meeting formats, the chair and participants, and the various types of meeting groups such as boards, advisory groups, and staff groups.   Author John E. Tropman teaches at the University of Michigan in the School of Social Work, the Stephen M. Ross School of Business, and the Executive Education Programs. Dr. Tropman also works with for-profit, nonprofit, and government entities in a consultative capacity.},
  googlebooks = {xVYXBAAAQBAJ},
  isbn = {978-1-4833-6564-0},
  langid = {english}
}

@book{turnerRobotRulesRegulating2018,
  title = {Robot {{Rules}}: {{Regulating Artificial Intelligence}}},
  shorttitle = {Robot {{Rules}}},
  author = {Turner, Jacob},
  year = {2018},
  month = oct,
  publisher = {Springer},
  abstract = {This book explains why AI is unique, what legal and ethical problems it could cause, and how we can address them. It argues that AI is unlike any other previous technology, owing to its ability to take decisions independently and unpredictably. This gives rise to three issues: responsibility--who is liable if AI causes harm; rights--the disputed moral and pragmatic grounds for granting AI legal personality; and the ethics surrounding the decision-making of AI. The book suggests that in order to address these questions we need to develop new institutions and regulations on a cross-industry and international level. Incorporating clear explanations of complex topics, Robot Rules will appeal to a multi-disciplinary audience, from those with an interest in law, politics and philosophy, to computer programming, engineering and neuroscience.},
  googlebooks = {moB1DwAAQBAJ},
  isbn = {978-3-319-96235-1},
  langid = {english}
}

@incollection{tylerRelationalModelAuthority1992,
  title = {A {{Relational Model}} of {{Authority}} in {{Groups}}},
  booktitle = {Advances in {{Experimental Social Psychology}}},
  author = {Tyler, Tom R. and Lind, E. Allan},
  editor = {Zanna, Mark P.},
  year = {1992},
  month = jan,
  volume = {25},
  pages = {115--191},
  publisher = {Academic Press},
  doi = {10.1016/S0065-2601(08)60283-X},
  urldate = {2024-07-18},
  abstract = {This chapter focuses on one particular aspect of authoritativeness: voluntary compliance with the decisions of authorities. Social psychologists have long distinguished between obedience that is the result of coercion, and obedience that is the result of internal attitudes. Opinions describe ``reward power'' and ``coercive power'', in which obedience is contingent on positive and negative outcomes, and distinguish both of these types of power from legitimate power, in which obedience flows from judgments about the legitimacy of the authority. Legitimate power depends on people taking the obligation on themselves to obey and voluntarily follow the decisions made by authorities. The chapter also focuses on legitimacy because it is important to recognize, that legitimacy is not the only attitudinal factor influencing effectiveness. It is also influenced by other cognitions about the authority, most notably judgments of his or her expertise with respect to the problem at hand. The willingness of group members to accept a leader's directives is only helpful when the leader knows what directives to issue.}
}

@misc{UsheringNewEra2023,
  title = {Ushering in a {{New Era}} of {{Communication Assistance With Generative AI}}},
  year = {2023},
  month = mar,
  journal = {Ushering in a New Era of Communication Assistance With Generative AI},
  urldate = {2025-01-08},
  abstract = {Today, we announced to the world the release of Grammarly's on-demand, contextually aware assistant powered by generative AI. With Grammarly's generative AI assistance, we'll be{\dots}},
  howpublished = {https://www.grammarly.com/blog/product/grammarlygo-augmented-intelligence/},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/4WULX6NP/grammarlygo-augmented-intelligence.html}
}

@article{uzziAtypicalCombinationsScientific2013,
  title = {Atypical {{Combinations}} and {{Scientific Impact}}},
  author = {Uzzi, Brian and Mukherjee, Satyam and Stringer, Michael and Jones, Ben},
  year = {2013},
  month = oct,
  journal = {Science},
  volume = {342},
  number = {6157},
  pages = {468--472},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1240474},
  urldate = {2024-08-09},
  abstract = {Novelty is an essential feature of creative ideas, yet the building blocks of new ideas are often embodied in existing knowledge. From this perspective, balancing atypical knowledge with conventional knowledge may be critical to the link between innovativeness and impact. Our analysis of 17.9 million papers spanning all scientific fields suggests that science follows a nearly universal pattern: The highest-impact science is primarily grounded in exceptionally conventional combinations of prior work yet simultaneously features an intrusion of unusual combinations. Papers of this type were twice as likely to be highly cited works. Novel combinations of prior work are rare, yet teams are 37.7\% more likely than solo authors to insert novel combinations into familiar knowledge domains.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/QENIWGP7/Uzzi et al. - 2013 - Atypical Combinations and Scientific Impact.pdf}
}

@article{v.lloydIngroupIdentityObstacle2011,
  title = {Ingroup Identity as an Obstacle to Effective Multiprofessional and Interprofessional Teamwork: Findings from an Ethnographic Study of Healthcare Assistants in Dementia Care},
  shorttitle = {Ingroup Identity as an Obstacle to Effective Multiprofessional and Interprofessional Teamwork},
  author = {V. Lloyd, Joanne and Schneider, Justine and Scales, Kezia and Bailey, Simon and Jones, Rob},
  year = {2011},
  month = sep,
  journal = {Journal of Interprofessional Care},
  volume = {25},
  number = {5},
  pages = {345--351},
  publisher = {Taylor \& Francis},
  issn = {1356-1820},
  doi = {10.3109/13561820.2011.567381},
  urldate = {2024-07-19},
  abstract = {Rising dementia incidence is likely to increase pressures on healthcare services, making effective well coordinated care imperative. Yet, barriers to this care approach exist which, we argue, might be understood by focussing on identity dynamics at the frontlines of care. In this article, we draw upon findings from an ethnographic study of healthcare assistants (HCAs) from three dementia wards across one National Health Service mental health trust. Data revealed that the HCAs are a close-knit `in-group' who share low group status and norms and, often highlight their own expertise in order to promote self worth. HCAs' social identity is considered as a barrier to effective teamwork with strong ingroup behaviour suggested as a consequence of their marginalisation. We explore these findings with reference to social identity theory (Tajfel, ; Turner, ) and discuss implications for delivering multiprofessional and interprofessional care.},
  pmid = {21635181}
}

@article{vereschakHowEvaluateTrust2021,
  title = {How to {{Evaluate Trust}} in {{AI-Assisted Decision Making}}? {{A Survey}} of {{Empirical Methodologies}}},
  shorttitle = {How to {{Evaluate Trust}} in {{AI-Assisted Decision Making}}?},
  author = {Vereschak, Oleksandra and Bailly, Gilles and Caramiaux, Baptiste},
  year = {2021},
  month = oct,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {5},
  number = {CSCW2},
  pages = {327:1--327:39},
  doi = {10.1145/3476068},
  urldate = {2024-07-18},
  abstract = {The spread of AI-embedded systems involved in human decision making makes studying human trust in these systems critical. However, empirically investigating trust is challenging. One reason is the lack of standard protocols to design trust experiments. In this paper, we present a survey of existing methods to empirically investigate trust in AI-assisted decision making and analyse the corpus along the constitutive elements of an experimental protocol. We find that the definition of trust is not commonly integrated in experimental protocols, which can lead to findings that are overclaimed or are hard to interpret and compare across studies. Drawing from empirical practices in social and cognitive studies on human-human trust, we provide practical guidelines to improve the methodology of studying Human-AI trust in decision-making contexts. In addition, we bring forward research opportunities of two types: one focusing on further investigation regarding trust methodologies and the other on factors that impact Human-AI trust.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/4PPAURKA/Vereschak et al. - 2021 - How to Evaluate Trust in AI-Assisted Decision Maki.pdf}
}

@article{verkuytenBeingFeelingDoing2002,
  title = {Being, {{Feeling}} and {{Doing}}: {{Discourses}} and {{Ethnic Self-Definitions}} among {{Minority Group Members}}},
  shorttitle = {Being, {{Feeling}} and {{Doing}}},
  author = {Verkuyten, Maykel and {deWolf}, Angela},
  year = {2002},
  month = dec,
  journal = {Culture \& Psychology},
  volume = {8},
  number = {4},
  pages = {371--399},
  publisher = {SAGE Publications Ltd},
  issn = {1354-067X},
  doi = {10.1177/1354067X0284001},
  urldate = {2024-07-19},
  abstract = {In psychology there is a growing research interest in issues of ethnic minority identity and acculturation. In this research the emphasis is on relatively stable or enduring internal dispositions and attitudes. Studies on the way ethnic minorities define and account for their identity are scarce. However, ethnic minority members often have to explain and justify their identity, not only in interactions with dominant group members but also in relation to their own group. The present study examines how Chinese people living in the Netherlands account for their ethnic identity. The focus is on the actual accomplishment and manifestation of ethnic self-definitions in talks with other Chinese. The analysis highlights the different resources the participants use to manage the normative issues and personal responsibilities involved. Accounts were accomplished by stressing the significance of appearance, the importance of early socialization and the (non-)possession of critical attributes. However, these deterministic accounts leave little room for personal agency, and the participants also tried to define an active and constructive role for themselves. It is concluded that discursive psychology can make an important contribution to our understanding of ethnic minority identity.},
  langid = {english}
}

@article{voglerTeamBasedTestingImproves2016,
  title = {Team-{{Based Testing Improves Individual Learning}}},
  author = {Vogler, Jane S. and Robinson, Daniel H.},
  year = {2016},
  month = oct,
  journal = {The Journal of Experimental Education},
  volume = {84},
  number = {4},
  pages = {787--803},
  publisher = {Routledge},
  issn = {0022-0973},
  doi = {10.1080/00220973.2015.1134420},
  urldate = {2024-08-09},
  abstract = {In two experiments, 90 undergraduates took six tests as part of an educational psychology course. Using a crossover design, students took three tests individually without feedback and then took the same test again, following the process of team-based testing (TBT), in teams in which the members reached consensus for each question and answered until they were correct. Students took the other three tests individually with feedback. All students were individually tested over a portion of this content two weeks later and again after two months. Independent samples t tests revealed that TBT students scored higher when retested two months later than those who took the test individually. Finally, three-fourths of the students reported that they enjoyed TBT more than individual testing. Although TBT requires more class time to administer, it appears to be beneficial for long-term student learning.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/A8BBJRBJ/Vogler and Robinson - 2016 - Team-Based Testing Improves Individual Learning.pdf}
}

@article{waltherComputermediatedCommunicationReduction2015,
  title = {Computer-Mediated Communication and the Reduction of Prejudice: {{A}} Controlled Longitudinal Field Experiment among {{Jews}} and {{Arabs}} in {{Israel}}},
  shorttitle = {Computer-Mediated Communication and the Reduction of Prejudice},
  author = {Walther, Joseph B. and Hoter, Elaine and Ganayem, Asmaa and Shonfeld, Miri},
  year = {2015},
  month = nov,
  journal = {Computers in Human Behavior},
  volume = {52},
  pages = {550--558},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2014.08.004},
  urldate = {2024-06-23},
  abstract = {The promise of computer-mediated communication (CMC) to reduce intergroup prejudice has generated mixed results. Theories of CMC yield alternative and mutually exclusive explanations about mechanisms by which CMC fosters relationships online with potential to ameliorate prejudice. This research tests contact-hypothesis predictions and two CMC theories on multicultural, virtual groups who communicated during a yearlong online course focusing on educational technology. Groups included students from the three major Israeli education sectors---religious Jews, secular Jews, and Muslims---who completed pretest and posttest prejudice measures. Two sets of control subjects who did not participate in virtual groups provided comparative data. An interaction of the virtual groups experience{\texttimes}religious/cultural membership affected prejudice toward different religious/cultural target groups, by reducing prejudice toward the respective outgroups for whom the greatest initial enmity existed. Comparisons of virtual group participants to control subjects further support the influence of the online experience. Correlations between prejudice with group identification and with interpersonal measures differentiate which theoretical processes pertained.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/5IFRNEJJ/Walther et al. - 2015 - Computer-mediated communication and the reduction .pdf}
}

@article{waltherComputerMediatedCommunicationVirtual2009,
  title = {Computer-{{Mediated Communication}} and {{Virtual Groups}}: {{Applications}} to {{Interethnic Conflict}}},
  shorttitle = {Computer-{{Mediated Communication}} and {{Virtual Groups}}},
  author = {Walther, Joseph B.},
  year = {2009},
  month = aug,
  journal = {Journal of Applied Communication Research},
  volume = {37},
  number = {3},
  pages = {225--238},
  publisher = {Routledge},
  issn = {0090-9882},
  doi = {10.1080/00909880903025937},
  urldate = {2024-07-19},
  abstract = {This essay represents the first in a series wherein an established scholar is invited to synthesize his or her program of research to offer practical applications. This essay concerns applications of computer-mediated communication (CMC) research in groups toward the enhancement of relations between members of potentially hostile ethnopolitical groups. The characteristics of CMC offer several possible means of facilitating the reduction of animosity through online contact among intergroup constituents. The scatter of applicable findings across disciplines, and imprecision in theoretical appropriations, have inhibited advancement of applied research in this context. This essay examines findings from management, intergroup, and interpersonal approaches to CMC, and provides some examples, suggesting opportunities for synthesis and the development of starting points to design the arrangement of diverse online groups that may help reduce conflict among otherwise antagonistic members.}
}

@inproceedings{wangAreExplanationsHelpful2021,
  title = {Are {{Explanations Helpful}}? {{A Comparative Study}} of the {{Effects}} of {{Explanations}} in {{AI-Assisted Decision-Making}}},
  shorttitle = {Are {{Explanations Helpful}}?},
  booktitle = {Proceedings of the 26th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Wang, Xinru and Yin, Ming},
  year = {2021},
  month = apr,
  series = {{{IUI}} '21},
  pages = {318--328},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3397481.3450650},
  urldate = {2024-07-18},
  abstract = {This paper contributes to the growing literature in empirical evaluation of explainable AI (XAI) methods by presenting a comparison on the effects of a set of established XAI methods in AI-assisted decision making. Specifically, based on our review of previous literature, we highlight three desirable properties that ideal AI explanations should satisfy---improve people's understanding of the AI model, help people recognize the model uncertainty, and support people's calibrated trust in the model. Through randomized controlled experiments, we evaluate whether four types of common model-agnostic explainable AI methods satisfy these properties on two types of decision making tasks where people perceive themselves as having different levels of domain expertise in (i.e., recidivism prediction and forest cover prediction). Our results show that the effects of AI explanations are largely different on decision making tasks where people have varying levels of domain expertise in, and many AI explanations do not satisfy any of the desirable properties for tasks that people have little domain expertise in. Further, for decision making tasks that people are more knowledgeable, feature contribution explanation is shown to satisfy more desiderata of AI explanations, while the explanation that is considered to resemble how human explain decisions (i.e., counterfactual explanation) does not seem to improve calibrated trust. We conclude by discussing the implications of our study for improving the design of XAI methods to better support human decision making.},
  isbn = {978-1-4503-8017-1}
}

@inproceedings{wangEnablingConversationalInteraction2023,
  title = {Enabling {{Conversational Interaction}} with {{Mobile UI}} Using {{Large Language Models}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Wang, Bryan and Li, Gang and Li, Yang},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--17},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3580895},
  urldate = {2024-07-18},
  abstract = {Conversational agents show the promise to allow users to interact with mobile devices using language. However, to perform diverse UI tasks with natural language, developers typically need to create separate datasets and models for each specific task, which is expensive and effort-consuming. Recently, pre-trained large language models (LLMs) have been shown capable of generalizing to various downstream tasks when prompted with a handful of examples from the target task. This paper investigates the feasibility of enabling versatile conversational interactions with mobile UIs using a single LLM. We designed prompting techniques to adapt an LLM to mobile UIs. We experimented with four important modeling tasks that address various scenarios in conversational interaction. Our method achieved competitive performance on these challenging tasks without requiring dedicated datasets and training, offering a lightweight and generalizable approach to enable language-based mobile interaction.},
  isbn = {978-1-4503-9421-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/CDXR2ZHE/Wang et al. - 2023 - Enabling Conversational Interaction with Mobile UI.pdf}
}

@article{wangMotivationalPathwaysSTEM2013,
  title = {Motivational Pathways to {{STEM}} Career Choices: {{Using}} Expectancy--Value Perspective to Understand Individual and Gender Differences in {{STEM}} Fields},
  shorttitle = {Motivational Pathways to {{STEM}} Career Choices},
  author = {Wang, Ming-Te and Degol, Jessica},
  year = {2013},
  month = dec,
  journal = {Developmental Review},
  volume = {33},
  number = {4},
  pages = {304--340},
  issn = {0273-2297},
  doi = {10.1016/j.dr.2013.08.001},
  urldate = {2024-07-19},
  abstract = {The United States has made a significant effort and investment in STEM education, yet the size and the composition of the STEM workforce continues to fail to meet demand. It is thus important to understand the barriers and factors that influence individual educational and career choices. In this article, we conduct a literature review of the current knowledge surrounding individual and gender differences in STEM educational and career choices, using expectancy--value theory as a guiding framework. The overarching goal of this paper is to provide both a well-defined theoretical framework and complementary empirical evidence for linking specific sociocultural, contextual, biological, and psychological factors to individual and gender differences in STEM interests and choices. Knowledge gained through this review will eventually guide future research and interventions designed to enhance individual motivation and capacity to pursue STEM careers, particularly for females who are interested in STEM but may be constrained by misinformation or stereotypes.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/68AQKU7G/Wang and Degol - 2013 - Motivational pathways to STEM career choices Usin.pdf}
}

@article{wangSocialIdentificationInterpersonal2009,
  title = {Social {{Identification}} and {{Interpersonal Communication}} in {{Computer-Mediated Communication}}: {{What You Do}} versus {{Who You Are}} in {{Virtual Groups}}},
  shorttitle = {Social {{Identification}} and {{Interpersonal Communication}} in {{Computer-Mediated Communication}}},
  author = {Wang, Zuoming and Walther, Joseph B. and Hancock, Jeffrey T.},
  year = {2009},
  month = jan,
  journal = {Human Communication Research},
  volume = {35},
  number = {1},
  pages = {59--85},
  issn = {0360-3989},
  doi = {10.1111/j.1468-2958.2008.01338.x},
  urldate = {2024-07-19},
  abstract = {This study investigates the influence of interpersonal communication and intergroup identification on members' evaluations of computer-mediated groups. Participants (N = 256) in 64 four-person groups interacted through synchronous computer chat. Subgroup assignments to minimal groups instilled significantly greater in-group versus out-group identification. One member in each group was instructed to exhibit interpersonally likable or dislikable behavior. Analysis revealed that confederates acting likably were more attractive than those acting dislikably regardless of their in-group or out-group status. Further results indicated that interpersonal behavior interacted with subgroup membership on identification shifts following online discussions. Interpersonal dynamics generally provided stronger effects on members in virtual groups than did intergroup dynamics, in contrast to predictions from previous applications of social identification to computer-mediated communication.}
}

@article{wangUnderstandingDesignSpace2022,
  title = {Understanding the {{Design Space}} of {{AI-Mediated Social Interaction}} in {{Online Learning}}: {{Challenges}} and {{Opportunities}}},
  shorttitle = {Understanding the {{Design Space}} of {{AI-Mediated Social Interaction}} in {{Online Learning}}},
  author = {Wang, Qiaosi and Camacho, Ida and Jing, Shan and Goel, Ashok K.},
  year = {2022},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  number = {CSCW1},
  pages = {130:1--130:26},
  doi = {10.1145/3512977},
  urldate = {2024-07-19},
  abstract = {Our online interactions are constantly mediated through Artificial Intelligence (AI), especially our social interactions. AI-mediated social interaction is the AI-facilitated process of building and maintaining social connections between individuals through information inferred from people's online posts. With its impending application across a number of contexts, the challenges and opportunities of AI-mediated social interaction remain underexplored. This paper seeks to understand the design space of AI-mediated social interaction in the context of online learning, where students frequently face social isolation. We deployed an AI agent named SAMI in three class discussion forums to help online learners build social connections. Using SAMI as a probe, we conducted semi-structured interviews with 26 students to understand their difficulties in remote social interactions and their experiences with SAMI. Through the lenses of social translucence and social-technical gap, we illustrate online learners' difficulties in remote social interactions and how SAMI resolved some of the difficulties. We also identify potential ethical and social challenges of SAMI such as user agency and privacy. Based on our findings, we outline the design space of AI-mediated social interaction. We discuss the design tension between AI performance and ethical design and pinpoint two design opportunities for AI-mediated social interaction in designing towards human-AI collaborative social matching and artificial serendipity.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VLN6GDA8/Wang et al. - 2022 - Understanding the Design Space of AI-Mediated Soci.pdf}
}

@article{wangUnderstandingDesignSpace2022a,
  title = {Understanding the {{Design Space}} of {{AI-Mediated Social Interaction}} in {{Online Learning}}: {{Challenges}} and {{Opportunities}}},
  shorttitle = {Understanding the {{Design Space}} of {{AI-Mediated Social Interaction}} in {{Online Learning}}},
  author = {Wang, Qiaosi and Camacho, Ida and Jing, Shan and Goel, Ashok K.},
  year = {2022},
  month = apr,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {6},
  number = {CSCW1},
  pages = {130:1--130:26},
  doi = {10.1145/3512977},
  urldate = {2024-07-21},
  abstract = {Our online interactions are constantly mediated through Artificial Intelligence (AI), especially our social interactions. AI-mediated social interaction is the AI-facilitated process of building and maintaining social connections between individuals through information inferred from people's online posts. With its impending application across a number of contexts, the challenges and opportunities of AI-mediated social interaction remain underexplored. This paper seeks to understand the design space of AI-mediated social interaction in the context of online learning, where students frequently face social isolation. We deployed an AI agent named SAMI in three class discussion forums to help online learners build social connections. Using SAMI as a probe, we conducted semi-structured interviews with 26 students to understand their difficulties in remote social interactions and their experiences with SAMI. Through the lenses of social translucence and social-technical gap, we illustrate online learners' difficulties in remote social interactions and how SAMI resolved some of the difficulties. We also identify potential ethical and social challenges of SAMI such as user agency and privacy. Based on our findings, we outline the design space of AI-mediated social interaction. We discuss the design tension between AI performance and ethical design and pinpoint two design opportunities for AI-mediated social interaction in designing towards human-AI collaborative social matching and artificial serendipity.},
  annotation = {TLDR: The design tension between AI performance and ethical design is discussed and two design opportunities for AI-mediated social interaction in designing towards human-AI collaborative social matching and artificial serendipity are pinpointed.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/PGHG9M2W/Wang et al. - 2022 - Understanding the Design Space of AI-Mediated Soci.pdf}
}

@inproceedings{wangWatchOutUpdates2023,
  title = {Watch {{Out}} for {{Updates}}: {{Understanding}} the {{Effects}} of {{Model Explanation Updates}} in {{AI-Assisted Decision Making}}},
  shorttitle = {Watch {{Out}} for {{Updates}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Wang, Xinru and Yin, Ming},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--19},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581366},
  urldate = {2024-07-18},
  abstract = {AI explanations have been increasingly used to help people better utilize AI recommendations in AI-assisted decision making. While AI explanations may change over time due to updates of the AI model, little is known about how these changes may affect people's perceptions and usage of the model. In this paper, we study how varying levels of similarity between the AI explanations before and after a model update affects people's trust in and satisfaction with the AI model. We conduct randomized human-subject experiments on two decision making contexts where people have different levels of domain knowledge. Our results show that changes in AI explanation during the model update do not affect people's tendency to adopt AI recommendations. However, they may change people's subjective trust in and satisfaction with the AI model via changing both their perceived model accuracy and perceived consistency of AI explanations with their prior knowledge.},
  isbn = {978-1-4503-9421-5}
}

@article{wangWhenExpertRecommendation2020,
  title = {When Expert Recommendation Contradicts Peer Opinion: {{Relative}} Social Influence of Valence, Group Identity and Artificial Intelligence},
  shorttitle = {When Expert Recommendation Contradicts Peer Opinion},
  author = {Wang, Jinping and Molina, Maria D. and Sundar, S. Shyam},
  year = {2020},
  month = jun,
  journal = {Computers in Human Behavior},
  volume = {107},
  pages = {106278},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2020.106278},
  urldate = {2024-07-26},
  abstract = {Whom do we trust more, the recommendation of an expert or public opinion from a crowd of other users of the site? Does it matter if the expert belongs to our in-group? And, what, if anything, would change if an Artificial Intelligence (AI) system was the recommender rather than a human expert? In order to answer these research questions, we conducted a between-subjects online experiment, informed by MAIN Model (Sundar, 2008), which posits that interface cues signaling different types of sources can influence perceived credibility of content by triggering distinct cognitive heuristics. Participants were assigned to a scenario wherein the expert review contrasted the peer rating about recommending photos for business profiles, with systematic variations in expert review valence (negative vs. positive), expert identity (ingroup vs. outgroup vs. no identity), and agent type (human vs. AI). Results show that positive ratings are more influential on user judgements. However, for negative ratings, human ingroup members generated greater effects than no-identity experts. Moreover, AI systems were as influential as human experts, suggesting the potential for AI to substitute human experts for online recommendations.}
}

@inproceedings{wangWillYouAccept2022,
  title = {Will {{You Accept}} the {{AI Recommendation}}? {{Predicting Human Behavior}} in {{AI-Assisted Decision Making}}},
  shorttitle = {Will {{You Accept}} the {{AI Recommendation}}?},
  booktitle = {Proceedings of the {{ACM Web Conference}} 2022},
  author = {Wang, Xinru and Lu, Zhuoran and Yin, Ming},
  year = {2022},
  month = apr,
  series = {{{WWW}} '22},
  pages = {1697--1708},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3485447.3512240},
  urldate = {2024-07-18},
  abstract = {Internet users make numerous decisions online on a daily basis. With the rapid advances in AI recently, AI-assisted decision making---in which an AI model provides decision recommendations and confidence, while the humans make the final decisions---has emerged as a new paradigm of human-AI collaboration. In this paper, we aim at obtaining a quantitative understanding of whether and when would human decision makers adopt the AI model's recommendations. We define a space of human behavior models by decomposing the human decision maker's cognitive process in each decision-making task into two components: the utility component (i.e., evaluate the utility of different actions) and the selection component (i.e., select an action to take), and we perform a systematic search in the model space to identify the model that fits real-world human behavior data the best. Our results highlight that in AI-assisted decision making, human decision makers' utility evaluation and action selection are influenced by their own judgement and confidence on the decision-making task. Further, human decision makers exhibit a tendency to distort the decision confidence in utility evaluations. Finally, we also analyze the differences in humans' adoption behavior of AI recommendations as the stakes of the decisions vary.},
  isbn = {978-1-4503-9096-5}
}

@misc{WaybackMachine2010,
  title = {Wayback {{Machine}}},
  year = {2010},
  month = apr,
  urldate = {2024-08-09},
  howpublished = {https://web.archive.org/web/20100401033524/http://apps.olin.wustl.edu/faculty/macdonald/GroupThink.pdf},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/XLLKIFDA/2010 - Wayback Machine.pdf}
}

@misc{weiMultiPartyChatConversational2023,
  title = {Multi-{{Party Chat}}: {{Conversational Agents}} in {{Group Settings}} with {{Humans}} and {{Models}}},
  shorttitle = {Multi-{{Party Chat}}},
  author = {Wei, Jimmy and Shuster, Kurt and Szlam, Arthur and Weston, Jason and Urbanek, Jack and Komeili, Mojtaba},
  year = {2023},
  month = jun,
  number = {arXiv:2304.13835},
  eprint = {2304.13835},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.13835},
  urldate = {2025-01-21},
  abstract = {Current dialogue research primarily studies pairwise (two-party) conversations, and does not address the everyday setting where more than two speakers converse together. In this work, we both collect and evaluate multi-party conversations to study this more general case. We use the LIGHT environment to construct grounded conversations, where each participant has an assigned character to role-play. We thus evaluate the ability of language models to act as one or more characters in such conversations. Models require two skills that pairwise-trained models appear to lack: (1) being able to decide when to talk; (2) producing coherent utterances grounded on multiple characters. We compare models trained on our new dataset to existing pairwise-trained dialogue models, as well as large language models with few-shot prompting. We find that our new dataset, MultiLIGHT, which we will publicly release, can help bring significant improvements in the group setting.},
  archiveprefix = {arXiv},
  annotation = {TLDR: This work collects and evaluates multi-party conversations and uses the LIGHT environment to construct grounded conversations, where each participant has an assigned character to role-play, to evaluate the ability of language models to act as one or more characters in such conversations.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/QU7VRVTB/Wei et al. - 2023 - Multi-Party Chat Conversational Agents in Group Settings with Humans and Models.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/NY4AQYBI/2304.html}
}

@article{wescheWhenComputersTake2019,
  title = {When Computers Take the Lead: {{The}} Automation of Leadership},
  shorttitle = {When Computers Take the Lead},
  author = {Wesche, Jenny S. and Sonderegger, Andreas},
  year = {2019},
  month = dec,
  journal = {Computers in Human Behavior},
  volume = {101},
  pages = {197--209},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2019.07.027},
  urldate = {2024-07-18},
  abstract = {The importance of technology in the workplace has been, and continues to be, on an upward trajectory. Technological progress allows more and more functions once performed by humans to be automated. Theoretical conceptualizations in human-computer interaction (HCI) covered the evolution of computers from `tools' to `partners' in interaction with humans at work. However, nowadays computers have also begun to take over leadership functions, guiding and commanding human workers. We argue that conceptual coverage is in danger of falling short of this development and the implied profound change in hierarchy. To close this gap, we propose the paradigm of `computers as leaders' and call for a scientific discourse of computers performing leadership functions. Building on research in HCI and human-human leadership, we suggest a definition of computer-human leadership and a respective structural model, entangling interaction roles of the different human and computer agents involved. Moreover, we discuss criteria for evaluating automated leadership systems and questions of function allocation, before we bring our propositions together in a theoretical model depicting how humans come to accept and follow a computer leader. Finally, we discuss implications of the proposed paradigm and call for awareness of ethical issues.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/NAGCBA9E/S0747563219302705.html}
}

@misc{WhoWhatMy,
  title = {Who/{{What Is My Teammate}}? {{Team Composition Considerations}} in {{Human}}--{{AI Teaming}} {\textbar} {{IEEE Journals}} \& {{Magazine}} {\textbar} {{IEEE Xplore}}},
  urldate = {2024-07-18},
  howpublished = {https://ieeexplore.ieee.org/abstract/document/9474953}
}

@article{woldGroupDecisionMaking1986,
  title = {Group Decision Making: Teaching the Process--an Introductory {{Guided Design}} Project},
  shorttitle = {Group Decision Making},
  author = {Wold, J. E.},
  year = {1986},
  month = nov,
  journal = {The Journal of Nursing Education},
  volume = {25},
  number = {9},
  pages = {388--389},
  issn = {0148-4834},
  doi = {10.3928/0148-4834-19861101-10},
  abstract = {The Guided Design experience gives students excellent grounding in the decision-making process and knowledge of a decision-making language that will serve them well in all group decision-making contexts. The detailed component analysis, constraint identifications and the who, what, when, where, why and how questions applied to information gathering and analysis are simple terms, easily understood. The steps are applicable to problems needing a cause identification, solve process, and for anticipating potential problems. The process can be taught early in the curriculum and utilized throughout with special re-emphasis in leadership and management classes. The strength of the described unit lies in the provision of an introductory, nonthreatening classroom opportunity for practice in the use of decision-making language and an experience with the process using familiar content. The students experience the complexity of group decision making and the interesting variety of solutions possible for each complex problem. Like the Guided Design process, the projects used are improved with each successive experience. Student and colleague feedback provides the challenge.},
  langid = {english},
  pmid = {3023582}
}

@article{wolfeBiasesInterpersonalCommunication2009,
  title = {Biases in {{Interpersonal Communication}}: {{How Engineering Students Perceive Gender Typical Speech Acts}} in {{Teamwork}}},
  shorttitle = {Biases in {{Interpersonal Communication}}},
  author = {Wolfe, Joanna and Powell, Elizabeth},
  year = {2009},
  journal = {Journal of Engineering Education},
  volume = {98},
  number = {1},
  pages = {5--16},
  issn = {2168-9830},
  doi = {10.1002/j.2168-9830.2009.tb01001.x},
  urldate = {2024-07-19},
  abstract = {This research investigates differences in how engineering and non-engineering men and women perceive common speech acts in team settings. Participants completed surveys asking them to rate the speakers of three male typical and three female typical speech acts. Male engineering students were significantly harsher than other groups on female typical speech acts in which the speaker conceded weaknesses, even if this concession was for strategic purposes such as trying to help another teammate ``save face.'' This bias against female typical speech was consistent regardless of the speaker's gender, suggesting that students were reacting to speech patterns rather than to biological gender. These findings provide hope that women may be able to help manage perceptions of their everyday team interactions by avoiding statements that imply weaknesses, even if such speech is normal in other situations.},
  copyright = {2009 American Society for Engineering Education},
  langid = {english}
}

@article{woodParticipationInfluenceSatisfaction1972,
  title = {Participation, Influence, and Satisfaction in Group Decision Making},
  author = {Wood, Michael T},
  year = {1972},
  month = oct,
  journal = {Journal of Vocational Behavior},
  volume = {2},
  number = {4},
  pages = {389--399},
  issn = {0001-8791},
  doi = {10.1016/0001-8791(72)90014-0},
  urldate = {2024-08-16},
  abstract = {The hypothesis that attitudinal effects of participation depend on individual differences in motivation was tested in a laboratory experiment with 56 three-man groups (leader and two members). Measures of the attractiveness of power and social acceptance were obtained prior to a group decision task, after which members described their perceived participation, influence, and satisfaction. Results showed that: (a) influence was more strongly related to satisfaction for members with strong, as opposed to weak, power motives; (b) for members with strong affiliation motives, participation was more strongly related to satisfaction than was influence. Relationships varied across satisfaction aspects. It was concluded that participation may be associated with favorable role attitudes through different motive-attainment mechanisms in the group decision-making process.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/PE3XSM3M/0001879172900140.html}
}

@article{woolleyEvidenceCollectiveIntelligence2010,
  title = {Evidence for a {{Collective Intelligence Factor}} in the {{Performance}} of {{Human Groups}}},
  author = {Woolley, Anita Williams and Chabris, Christopher F. and Pentland, Alex and Hashmi, Nada and Malone, Thomas W.},
  year = {2010},
  month = oct,
  journal = {Science},
  volume = {330},
  number = {6004},
  pages = {686--688},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1193147},
  urldate = {2024-07-19},
  abstract = {Psychologists have repeatedly shown that a single statistical factor---often called ``general intelligence''---emerges from the correlations among people's performance on a wide variety of cognitive tasks. But no one has systematically examined whether a similar kind of ``collective intelligence'' exists for groups of people. In two studies with 699 people, working in groups of two to five, we find converging evidence of a general collective intelligence factor that explains a group's performance on a wide variety of tasks. This ``c factor'' is not strongly correlated with the average or maximum individual intelligence of group members but is correlated with the average social sensitivity of group members, the equality in distribution of conversational turn-taking, and the proportion of females in the group.}
}

@misc{WorkProgressSocial,
  title = {Work in Progress --- {{Social}} Barriers and Supports to Underrepresented Minorities' Success in {{STEM}} Fields {\textbar} {{IEEE Conference Publication}} {\textbar} {{IEEE Xplore}}},
  urldate = {2024-07-19},
  howpublished = {https://ieeexplore.ieee.org/abstract/document/5673227}
}

@article{wuMinoritySocialInfluence2022,
  title = {Minority Social Influence and Moral Decision-Making in Human--{{AI}} Interaction: {{The}} Effects of Identity and Specialization Cues},
  shorttitle = {Minority Social Influence and Moral Decision-Making in Human--{{AI}} Interaction},
  author = {Wu, Yuheng and Kim, Ki Joon and Mou, Yi},
  year = {2022},
  month = nov,
  journal = {New Media \& Society},
  publisher = {SAGE PublicationsSage UK: London, England},
  doi = {10.1177/14614448221138072},
  urldate = {2024-07-28},
  abstract = {In group decision-making, the behavior of each member is sensitive to the social influence of other majority members. Research on majority influence has shown t...},
  copyright = {{\copyright} The Author(s) 2022},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/LJBX5CY9/14614448221138072.html}
}

@inproceedings{xuetaoImpactAgentsAnswers2009,
  title = {Impact of Agent's Answers Variability on Its Believability and Human-Likeness and Consequent Chatbot Improvements},
  booktitle = {Proceedings of {{AISB}}},
  author = {Xuetao, Mao and Bouchet, Fran{\c c}ois and Sansonnet, Jean-Paul},
  year = {2009},
  abstract = {Although globally less efficient than advanced dialogue systems, the chatbot approach allows people to easily design conversational agents. We suggest that one of their main drawbacks, their lack of believability, could be bypassed through the addition of variability in their answers, particularly when the variations depend on previous interactions or on particular parameters defining the agent. We validate the legitimacy of that hypothesis in two steps: first through simple additions to our chatbot-like framework (DIVA), we show it is technically feasible to simulate degrees of variability in answers. Then through an experiment done on 21 subjects interacting with two among six DIVA agents with different degrees of variability in a classical meeting scenario, we show that agents with an advanced variability in their answers are indeed perceived as more believable, human-like, and globally, more satisfying.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/LGHQSK2L/Xuetao et al. - Impact of agent’s answers variability on its believability and human-likeness and consequent chatbot.pdf}
}

@misc{xueWeaverBirdEmpoweringFinancial2024,
  title = {{{WeaverBird}}: {{Empowering Financial Decision-Making}} with {{Large Language Model}}, {{Knowledge Base}}, and {{Search Engine}}},
  shorttitle = {{{WeaverBird}}},
  author = {Xue, Siqiao and Zhou, Fan and Xu, Yi and Jin, Ming and Wen, Qingsong and Hao, Hongyan and Dai, Qingyang and Jiang, Caigao and Zhao, Hongyu and Xie, Shuo and He, Jianshan and Zhang, James and Mei, Hongyuan},
  year = {2024},
  month = apr,
  number = {arXiv:2308.05361},
  eprint = {2308.05361},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.05361},
  urldate = {2024-07-18},
  abstract = {We present WeaverBird, an intelligent dialogue system designed specifically for the finance domain. Our system harnesses a large language model of GPT architecture that has been tuned using extensive corpora of finance-related text. As a result, our system possesses the capability to understand complex financial queries, such as "How should I manage my investments during inflation?", and provide informed responses. Furthermore, our system incorporates a local knowledge base and a search engine to retrieve relevant information. The final responses are conditioned on the search results and include proper citations to the sources, thus enjoying an enhanced credibility. Through a range of finance-related questions, we have demonstrated the superior performance of our system compared to other models. To experience our system firsthand, users can interact with our live demo at https://weaverbird.ttic.edu, as well as watch our 2-min video illustration at https://www.youtube.com/watch?v=yofgeqnlrMc.},
  archiveprefix = {arXiv},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/LLR9CMHY/Xue et al. - 2024 - WeaverBird Empowering Financial Decision-Making w.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VDNSHBTU/2308.html}
}

@article{xuPersuasiveComputingFeeling2017,
  title = {Persuasive Computing: {{Feeling}} Peer Pressure from Multiple Computer Agents},
  shorttitle = {Persuasive Computing},
  author = {Xu, Kun and Lombard, Matthew},
  year = {2017},
  month = sep,
  journal = {Computers in Human Behavior},
  volume = {74},
  pages = {152--162},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2017.04.043},
  urldate = {2024-06-23},
  abstract = {Past works on the human-computer relationship has investigated a) how computers can mediate the communication between people and b) how computer users perceive computers as social entities. However, little research has investigated how the two fields of research inform, challenge, and integrate with each other. By combining the Computers are Social Actors paradigm and the Social Identity Model of Deindividuation Effects, the present work provides an entry point into the conversation between these two fields. Specifically, this study examines how individuals may form group relations with computer agents. An experiment using a between-subject factorial design was conducted to explore the relationship between the two theoretical frameworks. The findings suggested that sharing the same color cues with multiple computer agents would lead to users' group identification with computer agents. Group identification with computer agents would further influence group conformity, conformity intention, group attraction, and group trustworthiness. However, the degree of compliance with and trust in computer agents was contingent on how much users felt as if these agents had been real humans.},
  keywords = {,notion}
}

@article{xuPersuasiveComputingFeeling2017a,
  title = {Persuasive Computing: {{Feeling}} Peer Pressure from Multiple Computer Agents},
  shorttitle = {Persuasive Computing},
  author = {Xu, Kun and Lombard, Matthew},
  year = {2017},
  month = sep,
  journal = {Computers in Human Behavior},
  volume = {74},
  pages = {152--162},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2017.04.043},
  urldate = {2024-07-26},
  abstract = {Past works on the human-computer relationship has investigated a) how computers can mediate the communication between people and b) how computer users perceive computers as social entities. However, little research has investigated how the two fields of research inform, challenge, and integrate with each other. By combining the Computers are Social Actors paradigm and the Social Identity Model of Deindividuation Effects, the present work provides an entry point into the conversation between these two fields. Specifically, this study examines how individuals may form group relations with computer agents. An experiment using a between-subject factorial design was conducted to explore the relationship between the two theoretical frameworks. The findings suggested that sharing the same color cues with multiple computer agents would lead to users' group identification with computer agents. Group identification with computer agents would further influence group conformity, conformity intention, group attraction, and group trustworthiness. However, the degree of compliance with and trust in computer agents was contingent on how much users felt as if these agents had been real humans.}
}

@inproceedings{yangHowVisualExplanations2020,
  title = {How Do Visual Explanations Foster End Users' Appropriate Trust in Machine Learning?},
  booktitle = {Proceedings of the 25th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Yang, Fumeng and Huang, Zhuanyi and Scholtz, Jean and Arendt, Dustin L.},
  year = {2020},
  month = mar,
  series = {{{IUI}} '20},
  pages = {189--201},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3377325.3377480},
  urldate = {2024-07-18},
  abstract = {We investigated the effects of example-based explanations for a machine learning classifier on end users' appropriate trust. We explored the effects of spatial layout and visual representation in an in-person user study with 33 participants. We measured participants' appropriate trust in the classifier, quantified the effects of different spatial layouts and visual representations, and observed changes in users' trust over time. The results show that each explanation improved users' trust in the classifier, and the combination of explanation, human, and classification algorithm yielded much better decisions than the human and classification algorithm separately. Yet these visual explanations lead to different levels of trust and may cause inappropriate trust if an explanation is difficult to understand. Visual representation and performance feedback strongly affect users' trust, and spatial layout shows a moderate effect. Our results do not support that individual differences (e.g., propensity to trust) affect users' trust in the classifier. This work advances the state-of-the-art in trust-able machine learning and informs the design and appropriate use of automated systems.},
  isbn = {978-1-4503-7118-6},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/KCZUJY87/Yang et al. - 2020 - How do visual explanations foster end users' appro.pdf}
}

@inproceedings{yangReexaminingWhetherWhy2020,
  title = {Re-Examining {{Whether}}, {{Why}}, and {{How Human-AI Interaction Is Uniquely Difficult}} to {{Design}}},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Yang, Qian and Steinfeld, Aaron and Ros{\'e}, Carolyn and Zimmerman, John},
  year = {2020},
  month = apr,
  series = {{{CHI}} '20},
  pages = {1--13},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3313831.3376301},
  urldate = {2024-07-19},
  abstract = {Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example, AI systems can make unpredictable errors, and these errors damage UX and even lead to undesired societal impact. However, HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities, 2) AI's output complexity, spanning from simple to adaptive complex. We identify four levels of AI systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-AI interaction going forward.},
  isbn = {978-1-4503-6708-0},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/NDLLWDAD/Yang et al. - 2020 - Re-examining Whether, Why, and How Human-AI Intera.pdf}
}

@article{yeomansMakingSenseRecommendations2019,
  title = {Making Sense of Recommendations},
  author = {Yeomans, Michael and Shah, Anuj and Mullainathan, Sendhil and Kleinberg, Jon},
  year = {2019},
  journal = {Journal of Behavioral Decision Making},
  volume = {32},
  number = {4},
  pages = {403--414},
  issn = {1099-0771},
  doi = {10.1002/bdm.2118},
  urldate = {2024-07-18},
  abstract = {Computer algorithms are increasingly being used to predict people's preferences and make recommendations. Although people frequently encounter these algorithms because they are cheap to scale, we do not know how they compare to human judgment. Here, we compare computer recommender systems to human recommenders in a domain that affords humans many advantages: predicting which jokes people will find funny. We find that recommender systems outperform humans, whether strangers, friends, or family. Yet people are averse to relying on these recommender systems. This aversion partly stems from the fact that people believe the human recommendation process is easier to understand. It is not enough for recommender systems to be accurate, they must also be understood.},
  copyright = {{\copyright} 2019 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/C3SW55Y6/Yeomans et al. - 2019 - Making sense of recommendations.pdf}
}

@inproceedings{yinUnderstandingEffectAccuracy2019,
  title = {Understanding the {{Effect}} of {{Accuracy}} on {{Trust}} in {{Machine Learning Models}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Yin, Ming and Wortman Vaughan, Jennifer and Wallach, Hanna},
  year = {2019},
  month = may,
  series = {{{CHI}} '19},
  pages = {1--12},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3290605.3300509},
  urldate = {2024-07-18},
  abstract = {We address a relatively under-explored aspect of human-computer interaction: people's abilities to understand the relationship between a machine learning model's stated performance on held-out data and its expected performance post deployment. We conduct large-scale, randomized human-subject experiments to examine whether laypeople's trust in a model, measured in terms of both the frequency with which they revise their predictions to match those of the model and their self-reported levels of trust in the model, varies depending on the model's stated accuracy on held-out data and on its observed accuracy in practice. We find that people's trust in a model is affected by both its stated accuracy and its observed accuracy, and that the effect of stated accuracy can change depending on the observed accuracy. Our work relates to recent research on interpretable machine learning, but moves beyond the typical focus on model internals, exploring a different component of the machine learning pipeline.},
  isbn = {978-1-4503-5970-2}
}

@article{yoderITALLNUMBERS1985,
  title = {{{IS IT ALL IN THE NUMBERS}}? {{A Case Study}} of {{Tokenism}}},
  shorttitle = {{{IS IT ALL IN THE NUMBERS}}?},
  author = {Yoder, Janice D. and Sinnett, Laura M.},
  year = {1985},
  journal = {Psychology of Women Quarterly},
  volume = {9},
  number = {3},
  pages = {413--418},
  issn = {1471-6402},
  doi = {10.1111/j.1471-6402.1985.tb00890.x},
  urldate = {2024-07-19},
  abstract = {The purpose of the present study is to explore whether the negative consequences of tokenism are the result of imbalanced proportions alone, or whether society-wide sex role stereotypes which affect male and female tokens differently are also a factor. Men working at concession stands at an amusement attraction were assigned by the experimenters to one of two work groups in which the numbers of women and men were either skewed or balanced. Unlike a token woman at the attraction, these token male workers did not experience the negative consequences of tokenism (visibility, contrast, and assimilation). In fact, token men identified with supervisors and advanced more quickly than their non-token counterparts of both sexes. The results are interpreted as indicating that underrepresentation alone cannot explain the negative effects of tokenism for women.},
  langid = {english}
}

@article{yoderLookingGenderEffects1996,
  title = {Looking beyond Gender: {{The}} Effects of Racial Differences on Tokenism Perceptions of Women},
  shorttitle = {Looking beyond Gender},
  author = {Yoder, Janice D. and Aniakudo, Patricia and Berendsen, Lynne},
  year = {1996},
  month = oct,
  journal = {Sex Roles},
  volume = {35},
  number = {7},
  pages = {389--400},
  issn = {1573-2762},
  doi = {10.1007/BF01544128},
  urldate = {2024-07-19},
  abstract = {This study looks beyond gender to explore the impact of the social status of race and of token difference defined by race. In a 2 {\texttimes} 4 design, 53 African American women and 76 white women undergraduates rated a woman target, of the same race as themselves, who was described as being of the same race and gender as the dominant members of her work group or as a token defined by her gender alone, race alone, or both her race and gender. White women tokens were perceived to experience better social relations, more supportive colleagues, and lower stress than African American targets. Across African American and white raters/targets, token representation, defined by any ascribed status, was associated with expected negative tokenism outcomes relative to those projected for dominants. The omnirelevance of race toward understanding tokenism processes is discussed.},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/MIG69L68/Yoder et al. - 1996 - Looking beyond gender The effects of racial diffe.pdf}
}

@article{yoderLookingNumbersEffects1994,
  title = {Looking {{Beyond Numbers}}: {{The Effects}} of {{Gender Status}}, {{Job Prestige}}, and {{Occupational Gender-Typing}} on {{Tokenism Processes}}},
  shorttitle = {Looking {{Beyond Numbers}}},
  author = {Yoder, Janice D.},
  year = {1994},
  journal = {Social Psychology Quarterly},
  volume = {57},
  number = {2},
  eprint = {2786708},
  eprinttype = {jstor},
  pages = {150--159},
  publisher = {[Sage Publications, Inc., American Sociological Association]},
  issn = {0190-2725},
  doi = {10.2307/2786708},
  urldate = {2024-07-19},
  abstract = {Researchers of women workers in gender-skewed work groups repeatedly report evidence of visibility, contrast, and role encapsulation. The purpose of the present study was to explore the potential impact of four causal factors frequently confounded in these studies: proportional underrepresentation (tokenism), gender status, job prestige, and occupational gender-inappropriateness. Study participants' expectations for targets suggested that token numbers alone were not sufficient to produce tokenism; subordinated gender status also contributed regardless of the gender-appropriateness or prestige of the occupation. A theory of tokenism based solely on numbers thus is limited by its failure to acknowledge the impact of organizational and societal gender-based discrimination.}
}

@incollection{yoonGroupCompositionCause2021,
  title = {Group {{Composition}} as a {{Cause}}, a {{Consequence}}, and a {{Process}}: {{A Communication-centered Perspective}}},
  shorttitle = {Group {{Composition}} as a {{Cause}}, a {{Consequence}}, and a {{Process}}},
  booktitle = {The {{Emerald Handbook}} of {{Group}} and {{Team Communication Research}}},
  author = {Yoon, Kay and Kim, Young Ji},
  editor = {J. Beck, Stephenson and Keyton, Joann and Scott Poole, Marshall},
  year = {2021},
  month = jan,
  pages = {339--355},
  publisher = {Emerald Publishing Limited},
  doi = {10.1108/978-1-80043-500-120211022},
  urldate = {2024-07-19},
  abstract = {The characteristics of individual members and how the members are assembled in a group are critical foundations for various group processes and outcomes and often determine important staffing and hiring decisions in organizations. This chapter offers an overview of the history of group composition research across multiple disciplines and identifies three distinct approaches to studying group composition with an emphasis on the role of communication. Scholars treat group composition as a cause that leads to group outcomes, a consequence that results from social and psychological processes, or a process in response to dynamic team environments. A synthesis of previous research reveals that studying group composition as a cause has dominated the field and that the role of communication in group composition has gained little attention. The chapter concludes with a set of future research directions targeting the new digital environment, the role of communication, and research methodologies with special attention to the consequence- and process-oriented approaches.},
  isbn = {978-1-80043-501-8 978-1-80043-500-1},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/ZU2ZGBZZ/html.html}
}

@incollection{yoonGroupCompositionCause2022,
  title = {Group Composition as a Cause, a Consequence, and a Process: {{A}} Communication-Centered Perspective},
  shorttitle = {Group Composition as a Cause, a Consequence, and a Process},
  booktitle = {The {{Emerald}} Handbook of Group and Team Communication Research},
  author = {Yoon, Kay and Kim, Young Ji},
  year = {2022},
  series = {{{EmeraldHandbooks}}},
  pages = {339--355},
  publisher = {Emerald Publishing},
  address = {Bingley, United Kingdom},
  abstract = {The characteristics of individual members and how the members are assembled in a group are critical foundations for various group processes and outcomes and often determine important staffing and hiring decisions in organizations. This chapter offers an overview of the history of group composition research across multiple disciplines and identifies three distinct approaches to studying group composition with an emphasis on the role of communication. Scholars treat group composition as a cause that leads to group outcomes, a consequence that results from social and psychological processes, or a process in response to dynamic team environments. A synthesis of previous research reveals that studying group composition as a cause has dominated the field and that the role of communication in group composition has gained little attention. The chapter concludes with a set of future research directions targeting the new digital environment, the role of communication, and research methodologies with special attention to the consequence- and process-oriented approaches. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  isbn = {978-1-80043-500-1 978-1-80043-501-8 978-1-80043-502-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/AV4WS25C/2022-04127-022.html}
}

@misc{youdRobotKansaiAirports2021,
  title = {Do the Robot: {{Kansai Airport}}'s New Autonomous Security},
  shorttitle = {Do the Robot},
  author = {Youd, Frankie},
  year = {2021},
  month = nov,
  journal = {Airport Technology},
  urldate = {2024-07-18},
  abstract = {Japan has incorporated new, exciting technology into its Kansai Airport: an autonomous security robot. We profile the new robot.},
  langid = {american}
}

@article{youngCanRobotsBe,
  title = {Can {{Robots}} Be {{Managers}}, {{Too}}?},
  author = {Young, James E and Cormier, Derek},
  langid = {english},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/U22EXIKZ/Young and Cormier - Can Robots be Managers, Too.pdf}
}

@article{youngDangerThisRobot2021,
  title = {Danger! {{This}} Robot May Be Trying to Manipulate You},
  author = {Young, James},
  year = {2021},
  month = sep,
  journal = {Science Robotics},
  volume = {6},
  number = {58},
  pages = {eabk3479},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/scirobotics.abk3479},
  urldate = {2024-07-18},
  abstract = {Human-like social robots are designed to support communication, but this approach can enable them to be dangerously persuasive.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/H3YG2MGN/Young - 2021 - Danger! This robot may be trying to manipulate you.pdf}
}

@inproceedings{yuanWordcraftStoryWriting2022,
  title = {Wordcraft: {{Story Writing With Large Language Models}}},
  shorttitle = {Wordcraft},
  booktitle = {Proceedings of the 27th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Yuan, Ann and Coenen, Andy and Reif, Emily and Ippolito, Daphne},
  year = {2022},
  month = mar,
  series = {{{IUI}} '22},
  pages = {841--852},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3490099.3511105},
  urldate = {2024-07-18},
  abstract = {The latest generation of large neural language models such as GPT-3 have achieved new levels of performance on benchmarks for language understanding and generation. These models have even demonstrated an ability to perform arbitrary tasks without explicit training. In this work, we sought to learn how people might use such models in the process of creative writing. We built Wordcraft, a text editor in which users collaborate with a generative language model to write a story. We evaluated Wordcraft with a user study in which participants wrote short stories with and without the tool. Our results show that large language models enable novel co-writing experiences. For example, the language model is able to engage in open-ended conversation about the story, respond to writers' custom requests expressed in natural language (such as ''rewrite this text to be more Dickensian''), and generate suggestions that serve to unblock writers in the creative process. Based on these results, we discuss design implications for future human-AI co-writing systems.},
  isbn = {978-1-4503-9144-3}
}

@book{yuklLeadershipOrganizations2002,
  title = {Leadership in {{Organizations}}},
  author = {Yukl, Gary A.},
  year = {2002},
  publisher = {Prentice Hall},
  abstract = {Leadership in Organizations focuses on effective leadership in organizations through both theory and practice. This book explains and critiques the major theories and studies that are most relevant and informative and reviews what we know about leadership effectiveness. This combination of theory and practice makes this text a useful resource for practicing managers who are looking for something more than superficial answers to difficult questions about leadership.},
  googlebooks = {5mUVAQAAMAAJ},
  isbn = {978-0-13-032312-5},
  langid = {english}
}

@article{yunSpiralHostileMedia2016,
  title = {Inside the Spiral: {{Hostile}} Media, Minority Perception, and Willingness to Speak out on a Weblog},
  shorttitle = {Inside the Spiral},
  author = {Yun, Gi Woong and Park, Sung-Yeon and Lee, Sooyoung},
  year = {2016},
  month = sep,
  journal = {Computers in Human Behavior},
  volume = {62},
  pages = {236--243},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2016.03.086},
  urldate = {2024-06-19},
  abstract = {This study took a snapshot at the psychological process of spiral of silence in an online environment with South Korean college students as the study participants. In an experiment, a Weblog-embedded news article from a media source incongruent with one's political orientation, as opposed to the same article from a congruent media source, triggered hostile media perception, which in turn led to presumed influence of the online news article on others. The presumed influence on others became a basis for assessing the online climate of opinion and led people to view themselves as a minority against the online climate of opinion. The media source factor, in conjunction with user comments factor, also generated different levels of minority perception both online and in the general society. In contrast to the notion of spiral of silence, minority perception against the general society's climate of opinion increased rather than decreased willingness to speak out.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/UZWM9HDL/S0747563216302576.html}
}

@inproceedings{yuTrustMyMachine2019,
  title = {Do {{I}} Trust My Machine Teammate? An Investigation from Perception to Decision},
  shorttitle = {Do {{I}} Trust My Machine Teammate?},
  booktitle = {Proceedings of the 24th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Yu, Kun and Berkovsky, Shlomo and Taib, Ronnie and Zhou, Jianlong and Chen, Fang},
  year = {2019},
  month = mar,
  series = {{{IUI}} '19},
  pages = {460--468},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3301275.3302277},
  urldate = {2024-07-18},
  abstract = {In the human-machine collaboration context, understanding the reason behind each human decision is critical for interpreting the performance of the human-machine team. Via an experimental study of a system with varied levels of accuracy, we describe how human trust interplays with system performance, human perception and decisions. It is revealed that humans are able to perceive the performance of automatic systems and themselves, and adjust their trust levels according to the accuracy of systems. The 70\% system accuracy suggests to be a threshold between increasing and decreasing human trust and system usage. We have also shown that trust can be derived from a series of users' decisions rather than from a single one, and relates to the perceptions of users. A general framework depicting how trust and perception affect human decision making is proposed, which can be used as future guidelines for human-machine collaboration design.},
  isbn = {978-1-4503-6272-6},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/XTAPWM8G/Yu et al. - 2019 - Do I trust my machine teammate an investigation f.pdf}
}

@misc{zhangBreakingBarriersBuilding2025,
  title = {Breaking {{Barriers}} or {{Building Dependency}}? {{Exploring Team-LLM Collaboration}} in {{AI-infused Classroom Debate}}},
  shorttitle = {Breaking {{Barriers}} or {{Building Dependency}}?},
  author = {Zhang, Zihan and Sun, Black and An, Pengcheng},
  year = {2025},
  month = jan,
  number = {arXiv:2501.09165},
  eprint = {2501.09165},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.09165},
  urldate = {2025-02-05},
  abstract = {Classroom debates are a unique form of collaborative learning characterized by fast-paced, high-intensity interactions that foster critical thinking and teamwork. Despite the recognized importance of debates, the role of AI tools, particularly LLM-based systems, in supporting this dynamic learning environment has been under-explored in HCI. This study addresses this opportunity by investigating the integration of LLM-based AI into real-time classroom debates. Over four weeks, 22 students in a Design History course participated in three rounds of debates with support from ChatGPT. The findings reveal how learners prompted the AI to offer insights, collaboratively processed its outputs, and divided labor in team-AI interactions. The study also surfaces key advantages of AI usage, reducing social anxiety, breaking communication barriers, and providing scaffolding for novices, alongside risks, such as information overload and cognitive dependency, which could limit learners' autonomy. We thereby discuss a set of nuanced implications for future HCI exploration.},
  archiveprefix = {arXiv},
  langid = {american},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/GMC7BYHB/Zhang et al. - 2025 - Breaking Barriers or Building Dependency Exploring Team-LLM Collaboration in AI-infused Classroom D.pdf;/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/VTGEQQVS/2501.html}
}

@article{zhangDissonanceHumanMachine2019,
  title = {Dissonance {{Between Human}} and {{Machine Understanding}}},
  author = {Zhang, Zijian and Singh, Jaspreet and Gadiraju, Ujwal and Anand, Avishek},
  year = {2019},
  month = nov,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {3},
  number = {CSCW},
  pages = {56:1--56:23},
  doi = {10.1145/3359158},
  urldate = {2024-07-18},
  abstract = {Complex machine learning models are deployed in several critical domains including healthcare and autonomous vehicles nowadays, albeit as functional blackboxes. Consequently, there has been a recent surge in interpreting decisions of such complex models in order to explain their actions to humans. Models which correspond to human interpretation of a task are more desirable in certain contexts and can help attribute liability, build trust, expose biases and in turn build better models. It is therefore crucial to understand how and which models conform to human understanding of tasks. In this paper we present a large-scale crowdsourcing study that reveals and quantifies the dissonance between human and machine understanding, through the lens of an image classification task. In particular, we seek to answer the following questions: Which (well performing) complex ML models are closer to humans in their use of features to make accurate predictions? How does task difficulty affect the feature selection capability of machines in comparison to humans? Are humans consistently better at selecting features that make image recognition more accurate? Our findings have important implications on human-machine collaboration, considering that a long term goal in the field of artificial intelligence is to make machines capable of learning and reasoning like humans.},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/CRJ2CMF5/Zhang et al. - 2019 - Dissonance Between Human and Machine Understanding.pdf}
}

@article{zhangHowFancyYou2024,
  title = {"{{How}} Fancy You Are to Make Us Use Your Fancy Tool": {{Coordinating Individuals}}' {{Tool Preference}} over {{Group Boundaries}}},
  shorttitle = {"{{How}} Fancy You Are to Make Us Use Your Fancy Tool"},
  author = {Zhang, Qianqia (Queenie) and Park, Soya and Muller, Michael and Karger, David R.},
  year = {2024},
  month = feb,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {8},
  number = {GROUP},
  pages = {4:1--4:31},
  doi = {10.1145/3633069},
  urldate = {2024-03-27},
  abstract = {When a group makes a decision, it necessitates the understanding and amalgamation of information from different group members. This process becomes particularly intricate in cross-boundary teams, which consist of individuals from diverse organizational backgrounds, each bringing in unique informational tools and representation modalities. People share information generated from their personal tools, and the variance in representation of such information makes it challenging to form cohesive group decisions. We conducted workshop studies with 11 knowledge workers to understand current practices of tool adaptation and negotiation in such teams. The results indicate a reluctance to adopt new tools due to perceived violations of social acceptance, often leading to negative judgments of those suggesting new tools. Consequently, participants in cross-boundary teams gravitated towards their preferred tools, complicating the aggregation of inputs and impeding cohesive decision-making. To address these challenges, we developed a platform facilitating sensemaking and decision-making without necessitating compromises on tool preferences. In our mixed-method within-subject experiments, this approach enabled faster, more informed decision-making with reduced mental load and increased engagement through enhanced social interaction and acknowledgment of diverse contributions.},
  keywords = {notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/5LYXXE2J/Zhang 등 - 2024 - How fancy you are to make us use your fancy tool.pdf}
}

@article{zhangIdealHumanExpectations2021,
  title = {"{{An Ideal Human}}": {{Expectations}} of {{AI Teammates}} in {{Human-AI Teaming}}},
  shorttitle = {"{{An Ideal Human}}"},
  author = {Zhang, Rui and McNeese, Nathan J. and Freeman, Guo and Musick, Geoff},
  year = {2021},
  month = jan,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {4},
  number = {CSCW3},
  pages = {246:1--246:25},
  doi = {10.1145/3432945},
  urldate = {2024-07-18},
  abstract = {Driven by state-of-the-art AI technologies, human-AI collaboration has become an important area in computer-supported teamwork research. While human-AI collaboration has been investigated in various domains, more research is needed to explore human perceptions and expectations of AI teammates in human-AI teaming. To achieve an in-depth understanding of how people perceive AI teammates and what they expect from AI teammates in human-AI teaming, we conducted a survey with 213 participants and a follow-up interview with 20 participants. Considering the context-dependency of teamwork, we chose to study human-AI teaming in the context of multiplayer online games as a case study. This study shows that people have mixed feelings toward AI teammates but hold a positive attitude toward future collaboration with AI teammates in general. Our findings highlight people's expectations for AI teammates in a rapidly changing collaborative environment (e.g., instrumental skills for in-game tasks, shared understanding between humans and AI, communication capabilities, human-like behaviors and performance), as well as factors that impact people's willingness to team up with AI teammates (e.g., pre-existing attitudes toward AI, previous collaboration experience with humans). We contribute to CSCW by shedding light on how AI should be structured in human-AI teaming to support highly complex collaborative activities in CSCW environments.}
}

@article{zhangIdealHumanExpectations2021a,
  title = {"{{An Ideal Human}}": {{Expectations}} of {{AI Teammates}} in {{Human-AI Teaming}}},
  shorttitle = {"{{An Ideal Human}}"},
  author = {Zhang, Rui and McNeese, Nathan J. and Freeman, Guo and Musick, Geoff},
  year = {2021},
  month = jan,
  journal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {4},
  number = {CSCW3},
  pages = {246:1--246:25},
  doi = {10.1145/3432945},
  urldate = {2024-07-18},
  abstract = {Driven by state-of-the-art AI technologies, human-AI collaboration has become an important area in computer-supported teamwork research. While human-AI collaboration has been investigated in various domains, more research is needed to explore human perceptions and expectations of AI teammates in human-AI teaming. To achieve an in-depth understanding of how people perceive AI teammates and what they expect from AI teammates in human-AI teaming, we conducted a survey with 213 participants and a follow-up interview with 20 participants. Considering the context-dependency of teamwork, we chose to study human-AI teaming in the context of multiplayer online games as a case study. This study shows that people have mixed feelings toward AI teammates but hold a positive attitude toward future collaboration with AI teammates in general. Our findings highlight people's expectations for AI teammates in a rapidly changing collaborative environment (e.g., instrumental skills for in-game tasks, shared understanding between humans and AI, communication capabilities, human-like behaviors and performance), as well as factors that impact people's willingness to team up with AI teammates (e.g., pre-existing attitudes toward AI, previous collaboration experience with humans). We contribute to CSCW by shedding light on how AI should be structured in human-AI teaming to support highly complex collaborative activities in CSCW environments.},
  keywords = {,notion}
}

@inproceedings{zhengCompetentRigidIdentifying2023,
  title = {Competent but {{Rigid}}: {{Identifying}} the {{Gap}} in {{Empowering AI}} to {{Participate Equally}} in {{Group Decision-Making}}},
  shorttitle = {Competent but {{Rigid}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zheng, Chengbo and Wu, Yuheng and Shi, Chuhan and Ma, Shuai and Luo, Jiehui and Ma, Xiaojuan},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--19},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581131},
  urldate = {2024-03-26},
  abstract = {Existing research on human-AI collaborative decision-making focuses mainly on the interaction between AI and individual decision-makers. There is a limited understanding of how AI may perform in group decision-making. This paper presents a wizard-of-oz study in which two participants and an AI form a committee to rank three English essays. One novelty of our study is that we adopt a speculative design by endowing AI equal power to humans in group decision-making. We enable the AI to discuss and vote equally with other human members. We find that although the voice of AI is considered valuable, AI still plays a secondary role in the group because it cannot fully follow the dynamics of the discussion and make progressive contributions. Moreover, the divergent opinions of our participants regarding an ``equal AI'' shed light on the possible future of human-AI relations.},
  isbn = {978-1-4503-9421-5},
  keywords = {,notion},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/IXU9QXJS/Zheng 등 - 2023 - Competent but Rigid Identifying the Gap in Empowe.pdf}
}

@inproceedings{zhengCompetentRigidIdentifying2023a,
  title = {Competent but {{Rigid}}: {{Identifying}} the {{Gap}} in {{Empowering AI}} to {{Participate Equally}} in {{Group Decision-Making}}},
  shorttitle = {Competent but {{Rigid}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zheng, Chengbo and Wu, Yuheng and Shi, Chuhan and Ma, Shuai and Luo, Jiehui and Ma, Xiaojuan},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--19},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581131},
  urldate = {2024-07-16},
  abstract = {Existing research on human-AI collaborative decision-making focuses mainly on the interaction between AI and individual decision-makers. There is a limited understanding of how AI may perform in group decision-making. This paper presents a wizard-of-oz study in which two participants and an AI form a committee to rank three English essays. One novelty of our study is that we adopt a speculative design by endowing AI equal power to humans in group decision-making. We enable the AI to discuss and vote equally with other human members. We find that although the voice of AI is considered valuable, AI still plays a secondary role in the group because it cannot fully follow the dynamics of the discussion and make progressive contributions. Moreover, the divergent opinions of our participants regarding an ``equal AI'' shed light on the possible future of human-AI relations.},
  isbn = {978-1-4503-9421-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/9Z9LAJEF/Zheng et al. - 2023 - Competent but Rigid Identifying the Gap in Empowe.pdf}
}

@inproceedings{zhengCompetentRigidIdentifying2023b,
  title = {Competent but {{Rigid}}: {{Identifying}} the {{Gap}} in {{Empowering AI}} to {{Participate Equally}} in {{Group Decision-Making}}},
  shorttitle = {Competent but {{Rigid}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zheng, Chengbo and Wu, Yuheng and Shi, Chuhan and Ma, Shuai and Luo, Jiehui and Ma, Xiaojuan},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--19},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581131},
  urldate = {2024-07-18},
  abstract = {Existing research on human-AI collaborative decision-making focuses mainly on the interaction between AI and individual decision-makers. There is a limited understanding of how AI may perform in group decision-making. This paper presents a wizard-of-oz study in which two participants and an AI form a committee to rank three English essays. One novelty of our study is that we adopt a speculative design by endowing AI equal power to humans in group decision-making. We enable the AI to discuss and vote equally with other human members. We find that although the voice of AI is considered valuable, AI still plays a secondary role in the group because it cannot fully follow the dynamics of the discussion and make progressive contributions. Moreover, the divergent opinions of our participants regarding an ``equal AI'' shed light on the possible future of human-AI relations.},
  isbn = {978-1-4503-9421-5},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/8LWQJDEW/Zheng et al. - 2023 - Competent but Rigid Identifying the Gap in Empowe.pdf}
}

@inproceedings{zhouSyntheticLiesUnderstanding2023,
  title = {Synthetic {{Lies}}: {{Understanding AI-Generated Misinformation}} and {{Evaluating Algorithmic}} and {{Human Solutions}}},
  shorttitle = {Synthetic {{Lies}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zhou, Jiawei and Zhang, Yixuan and Luo, Qianni and Parker, Andrea G and De Choudhury, Munmun},
  year = {2023},
  month = apr,
  series = {{{CHI}} '23},
  pages = {1--20},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3544548.3581318},
  urldate = {2024-07-18},
  abstract = {Large language models have abilities in creating high-volume human-like texts and can be used to generate persuasive misinformation. However, the risks remain under-explored. To address the gap, this work first examined characteristics of AI-generated misinformation (AI-misinfo) compared with human creations, and then evaluated the applicability of existing solutions. We compiled human-created COVID-19 misinformation and abstracted it into narrative prompts for a language model to output AI-misinfo. We found significant linguistic differences within human-AI pairs, and patterns of AI-misinfo in enhancing details, communicating uncertainties, drawing conclusions, and simulating personal tones. While existing models remained capable of classifying AI-misinfo, a significant performance drop compared to human-misinfo was observed. Results suggested that existing information assessment guidelines had questionable applicability, as AI-misinfo tended to meet criteria in evidence credibility, source transparency, and limitation acknowledgment. We discuss implications for practitioners, researchers, and journalists, as AI can create new challenges to the societal problem of misinformation.},
  isbn = {978-1-4503-9421-5}
}

@article{ziegertEmploymentDiscriminationRole2005,
  title = {Employment {{Discrimination}}: {{The Role}} of {{Implicit Attitudes}}, {{Motivation}}, and a {{Climate}} for {{Racial Bias}}},
  shorttitle = {Employment {{Discrimination}}},
  author = {Ziegert, Jonathan C. and Hanges, Paul J.},
  year = {2005},
  journal = {Journal of Applied Psychology},
  volume = {90},
  number = {3},
  pages = {553--562},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-1854},
  doi = {10.1037/0021-9010.90.3.553},
  abstract = {This study is an attempt to replicate and extend research on employment discrimination by A. P. Brief and colleagues (A. P. Brief, J. Dietz, R. R. Cohen, S. D. Pugh, \& J. B. Vaslow, 2000). More specifically, the authors attempted (a) to constructively replicate the prior finding that an explicit measure of modern racism would interact with a corporate climate for racial bias to predict discrimination in a hiring context and (b) to extend this finding through the measurement of implicit racist attitudes and motivation to control prejudice. Although the authors were unable to replicate the earlier interaction, they did illustrate that implicit racist attitudes interacted with a climate for racial bias to predict discrimination. Further, results partially illustrate that motivation to control prejudice moderates the relationship between explicit and implicit attitudes. Taken together, the findings illustrate the differences between implicit and explicit racial attitudes in predicting discriminatory behavior. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  file = {/Users/soohwanlee/Library/CloudStorage/OneDrive-개인/GRADUATE/Zotero/storage/GLIK5UNL/2005-05102-011.html}
}
