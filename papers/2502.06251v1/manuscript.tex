\documentclass[sigconf]{acmart}


\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


\setcopyright{acmcopyright}
\copyrightyear{2025}
\acmYear{2025}
\setcopyright{rightsretained}
\acmConference[IUI Companion '25]{30th International Conference on Intelligent User Interfaces Companion}{March 24--27, 2025}{Cagliari, Italy}
\acmBooktitle{30th International Conference on Intelligent User Interfaces Companion (IUI Companion '25), March 24--27, 2025, Cagliari, Italy}\acmDOI{10.1145/3708557.3716334}
\acmISBN{979-8-4007-1409-2/25/03}

\begin{document}


\title{Amplifying Minority Voices: AI-Mediated Devil's Advocate System for Inclusive Group Decision-Making}

\author{Soohwan Lee}
\orcid{0000-0001-8652-3408}
\authornote{Equally contributed to this work.}
\affiliation{%
  \institution{Department of Design, UNIST}
  \city{Ulsan}
  \country{Republic of Korea}}
\email{soohwanlee@unist.ac.kr}

\author{Mingyu Kim}
\orcid{0009-0006-8580-3532}
\authornotemark[1] 
\affiliation{%
  \institution{Department of Design, UNIST}
  \city{Ulsan}
  \country{Republic of Korea}}
\email{gyu7991@unist.ac.kr}

\author{Seoyeong Hwang}
\orcid{0009-0004-1045-1419}
\affiliation{%
  \institution{Department of Design, UNIST}
  \city{Ulsan}
  \country{Republic of Korea}}
\email{hseoyeong@unist.ac.kr}

\author{Dajung Kim}
\orcid{0000-0002-9144-7435}
\affiliation{%
  \institution{Department of Design, UNIST}
  \city{Ulsan}
  \country{Republic of Korea}}
\email{dajungkim@unist.ac.kr}

\author{Kyungho Lee}
\orcid{0000-0002-1292-3422}
\affiliation{%
  \institution{Department of Design, UNIST}
  \city{Ulsan}
  \country{Republic of Korea}}
\email{kyungho@unist.ac.kr}


%% article.
\begin{abstract}
Group decision-making often benefits from diverse perspectives, yet power imbalances and social influence can stifle minority opinions and compromise outcomes. This prequel introduces an AI-mediated communication system that leverages the Large Language Model to serve as a devil’s advocate, representing underrepresented viewpoints without exposing minority members’ identities. Rooted in persuasive communication strategies and anonymity, the system aims to improve psychological safety and foster more inclusive decision-making. Our multi-agent architecture, which consists of a summary agent, conversation agent, AI duplicate checker, and paraphrase agent, encourages the group's critical thinking while reducing repetitive outputs. We acknowledge that reliance on text-based communication and fixed intervention timings may limit adaptability, indicating pathways for refinement. By focusing on the representation of minority viewpoints anonymously in power-imbalanced settings, this approach highlights how AI-driven methods can evolve to support more divergent and inclusive group decision-making.
\end{abstract}



\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003121.10003124.10011751</concept_id>
       <concept_desc>Human-centered computing~Collaborative interaction</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003120.10003130.10003233</concept_id>
       <concept_desc>Human-centered computing~Collaborative and social computing systems and tools</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Collaborative interaction}
\ccsdesc[500]{Human-centered computing~Collaborative and social computing systems and tools}

\keywords{AI-mediated Communication; AI-assisted Decision-making, Group Dynamics, Social Influence, Compliance, LLM}

\begin{teaserfigure}
  \centering
  \includegraphics[width=1.0\textwidth]{figures/teaser_v8.pdf}
  \caption{Mitigating Social Influence with an LLM-powered Devil’s Advocate. Minority members often conform to majority opinions due to social pressure. Our system allows minorities to share different opinions with an LLM-powered Devil’s Advocate, which reframes and presents them as its own. This increases psychological safety, mitigates bias, and fosters critical discussion.}
  \Description{This figure illustrates how an LLM-powered Devil’s Advocate mitigates social influence in group decision-making. The majority group (≥3 members, high power), shown in a light blue bubble, exerts social pressure on the minority member (low power, pink bubble), often leading to compliance. Instead of speaking out directly, the minority can privately share dissenting views with the AI via an AI-mediated message (pink arrow). The AI reformulates these views and presents them as system-generated counterarguments (blue arrow), removing identity markers and reducing social pressure. This process helps amplify minority perspectives, mitigating bias and fostering critical discussion.}
  \label{fig:teaser}
\end{teaserfigure}


\maketitle

\section{Introduction}
Groups across diverse sectors from corporate environments to healthcare, educational institutions, and governmental bodies - rely on collaborative discussions as a cornerstone of their operations ~\cite{luSurveyGroupDecision2022,  hsuGroupDecisionmakingApproach2021,  sharmaGroupDecisionMaking2016, woldGroupDecisionMaking1986}. Research demonstrates that collective decision-making processes typically generate better results than individual efforts ~\cite{forsythGroupDynamics2018,stasserInformationSamplingStructured1989,tropmanEffectiveMeetingsImproving2013}. The advantages of group decision-making extend to multiple domains, such as teams solving problems more effectively, producing higher-quality research outputs, reaching more precise diagnostic conclusions, combining varied viewpoints, stimulating innovative thinking, and developing comprehensive solutions ~\cite{maciejovskyTeamsMakeYou2013,voglerTeamBasedTestingImproves2016,uzziAtypicalCombinationsScientific2013,glickInflictedTraumaticBrain2007,brahmAdvantagesDisadvantagesGroup1996,hsiehNewMeasureGroup2020}. However, social influence from majorities and structural power differentials can impede effective collaboration, compromising participation levels and group outcomes.



In power-imbalanced settings, social influence and coercive power dynamics frequently suppress minority opinions, thereby limiting the diversity of perspectives and stifling innovation ~\cite{forsythGroupDynamics2018}. Majority members may wield greater control over resources and decision-making, while minority members face social pressures to conform ~\cite{moscoviciStudiesSocialInfluence1976}. These conditions can lead to compliance rather than genuine agreement ~\cite{aschOpinionsSocialPressure1955,kelmanComplianceIdentificationInternalization1958}, increasing the risk of groupthink—where the desire for consensus overrides critical evaluation of alternative viewpoints ~\cite{janisGroupthinkPsychologicalStudies1982,janisVictimsGroupthinkPsychological1972}. Traditional interventions, such as anonymous commenting and appointing a devil’s advocate ~\cite{macdougallDevilsAdvocateStrategy1997,masonDialecticalApproachStrategic1969,nemethDevilsAdvocateAuthentic2001,schweigerGroupApproachesImproving1986,schwenkEffectsDevilsAdvocacy1994}, aim to mitigate these issues but often have drawbacks like reduced psychological safety, perceived inauthenticity, or risks to the advocate’s standing within the group ~\cite{nemethDevilsAdvocateAuthentic2001,schulz-hardtProductiveConflictGroup2002,jamiesonSympathyDevilPhysiological2014}.


To address these challenges, this thesis proposes an AI-mediated communication system that leverages Large Language Model(LLM) to serve as a devil’s advocate (\autoref{fig:teaser}). Moving beyond existing methods ~\cite{chiangEnhancingAIAssistedGroup2024,hwangSoundSupportGendered2024,stauferSilencingRiskNot2024}, the system presents minority opinions as if they were the system’s own, thus offering a neutral but impactful channel. By shielding minority members from social pressure and compliance, the system bolsters their psychological safety and encourages the expression of dissenting views. In addition, this system tries to integrate persuasive communication strategies and anonymity to balance inclusive dialogue and efficient group decision-making. Through its ability to represent dissent without exposing vulnerable group members, this approach aims to reduce power asymmetries and foster more equitable, creative, and high-quality outcomes in various collaborative settings.


\begin{figure*}[]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/AIMC.pdf}
  \caption{Four patterns of AI-mediated communication in group settings: (A) human requests and relays AI-generated content, (B) human selectively shares AI's output, (C) AI reformulates and presents human's message, and (D) AI directly facilitates communication between participants. Arrows indicate information flow, with numbered sequences showing order of interactions.}
  \Description{This figure illustrates four patterns of AI-mediated communication in group settings, represented by diagrams labeled A–D with arrows indicating information flow. (A) The human requests AI-generated content and relays it to another participant. (B) The human selectively shares AI output with others. (C) The AI reformulates a human’s message and presents it directly. (D) The AI autonomously facilitates communication between participants. Numbered arrows indicate the sequence of interactions in each pattern, showing different levels of AI involvement in mediating group discussions.}
  \label{fig:communicationPattern}
\end{figure*}

\section{Related Work}
\subsection{AI-assisted Group Decision-making}
As AI advances, researchers have increasingly explored AI-enhanced methods to improve group decision-making processes. Although various existing works have focused on individuals interacting with AI \cite{laiScienceHumanAIDecision2021}, there is growing interest in understanding group-level engagement with AI agents ~\cite{maRecommenderExploratoryStudy2024,liuProactiveConversationalAgents2024,kimBotBunchFacilitating2020,doHowShouldAgent2022,seboRobotsGroupsTeams2020,houdeControllingAIAgent2025,wangUnderstandingDesignSpace2022,zhangBreakingBarriersBuilding2025}. For example, Zheng et al. found that even when AI is granted nominal equality in decision-making, it often remains peripheral because of its limited capacity to navigate social nuances ~\cite{zhengCompetentRigidIdentifying2023}. At the same time, Chiang et al. observed that groups can over-rely on AI-generated inputs ~\cite{chiangAreTwoHeads2023,chiangEnhancingAIAssistedGroup2024} Meanwhile, initiatives to support minority voices directly within small-group settings remain relatively scarce ~\cite{hwangSoundSupportGendered2024}: many interventions risk singling out underrepresented members or glossing over the unique needs of individuals ~\cite{stauferSilencingRiskNot2024}. Consequently, current AI systems face challenges such as over-reliance on AI suggestions, limited handling of complex group dynamics, and a lack of subtle support mechanisms for marginalized participants  ~\cite{bucincaTrustThinkCognitive2021,chiangEnhancingAIAssistedGroup2024,hwangSoundSupportGendered2024}. To address these gaps, we propose an LLM-powered devil’s advocate approach that strategically represents minority perspectives, encourage critical thinking, and promotes more inclusive group decision-making without increasing discomfort for minority contributors.



\begin{figure*}[]
  \centering
  \includegraphics[width=1.0\textwidth]{figures/systemImplementation_IUI_v2.pdf}
  \caption{System Overview and Example Task Scenario. The figure illustrates a team leader promotion decision task, where participants discuss candidate qualifications in a chat interface. Minority members can privately share dissenting views via direct messages(DM) to the system, which reformulates and presents them as AI-mediated messages. If there is no DM with an opposing opinion, the system will send out a counterargument that it has generated on its own. The system architecture consists of a chat interface, database, and server, processing both public discussions and private DMs through four key agents: (A) Summary Agent for analyzing public opinion, (A') Paraphrase Agent for rephrasing minority views, (B) Conversation Agent for generating contextual counterarguments, and (C) AI Duplicate Checker for ensuring message novelty via cosine-similarity comparison.}
  \Description{This figure illustrates a system for group decision-making in a team leader promotion task, where participants discuss candidate qualifications in a chat interface. Minority members can privately share dissenting views via direct messages (DMs) to the AI, which reformulates and presents them as AI-generated insights to reduce social pressure. The system consists of a chat interface, database, and server with four AI agents: (A) Summary Agent for analyzing public opinion, (A’) Paraphrase Agent for anonymizing minority views, (B) Conversation Agent for generating counterarguments, and (C) AI Duplicate Checker for ensuring message novelty. If no dissenting DM is provided, the AI generates its own counterargument, fostering diverse perspectives and mitigating conformity bias in group discussions.}
  \label{fig:system}
\end{figure*}

\subsection{AI-mediated Communication}
AI-mediated communication (AIMC), where AI systems modify, augment, or generate messages for communicators, now pervades various contexts as AI technology advances ~\cite{hancockAIMediatedCommunicationDefinition2020}. We identify four distinct AIMC patterns (\autoref{fig:communicationPattern}): First, humans can request and relay AI-generated content ~\cite{hancockAIMediatedCommunicationDefinition2020}. Second, humans can selectively share AI's insights or viewpoints ~\cite{doHowShouldAgent2022}. Third, AI can reformulate and present human-provided messages (our system's approach). Fourth, AI can directly solicit and share input from multiple participants ~\cite{wangUnderstandingDesignSpace2022,natarajanHumanintheloopAIintheloopAutomate2024}. These patterns distribute power and authorship differently among human communicators, AI systems, and message recipients. However, research has rarely explored how AIMC might address power imbalances and minority influence in group settings. Our proposed LLM-driven Devil's Advocate system adopts the third AIMC pattern to amplify underrepresented perspectives, reduce social influence biases, and foster more balanced discussions. However, as AI takes a more active role in content creation, AIMC approaches raise important concerns about user agency and authentic communication ~\cite{mieczkowskiAIMediatedCommunicationLanguage2021,poddarAIWritingAssistants2023,hohensteinArtificialIntelligenceCommunication2023,robertsonCantReplyThat2021}. Future research must carefully examine these ethical implications to avoid potential negative effects on group dynamics.



\section{System Overview}
Our system enables minority members to voice dissenting opinions through a private direct messaging channel to an LLM-powered devil's advocate. When participants experience social pressure or hesitate to speak up in group settings, they can send their perspectives confidentially to the AI intermediary. The system then reformulates these messages and presents them to the group as system-generated insights, removing individual identity markers that could trigger status-based judgments. The AI acts as a social actor ~\cite{nassComputersAreSocial1994}, actively advocating minority viewpoints as its own stance, which relieves minority members from the social burden of direct confrontation. 

Drawing on findings that LLM often struggle to access mid-conversation information in lengthy contexts, we employ a multi-agent architecture to maintain clarity of “public opinion” and encourage constructive discourse (\autoref{fig:system}): \textbf{\textit{(A) Summary Agent}} – Consolidates emerging consensus to overcome LLM limitations in retaining mid-dialogue content ~\cite{liuLostMiddleHow2023}. \textbf{\textit{(A') Paraphrase Agent}} – Responds exclusively to direct messages from minority participants, rearticulating their dissenting views as though originating from the AI itself. These messages are stored in a database with an \textit{isUsed} property, and the Paraphrase Agent retrieves only those entries for which \textit{isUsed} is \textit{false}; it then sets \textit{isUsed} to \textit{true}, paraphrases the content, and outputs it as system-generated text. \textbf{\textit{(B) Conversation Agent}} – Encourages alternative perspectives by first empathizing with the other person’s point of view and then offering a gentle counterargument using a persuasive Socratic style. \textbf{\textit{(C) AI Duplicate Checker}} – Identifies repetitive content by calculating semantic similarity between sentence embeddings generated using the 'paraphrase-multilingual-MiniLM-L12-v2' model on an NVIDIA A6000. In addition, the AI agent is designed to intervene once after approximately eight human turns, allowing space for each participant to contribute. 


These design choices reflect our design rationale of (1) adopting a persuasive, empathetic style that acknowledges others’ perspectives before introducing counterarguments ~\cite{tanprasertDebateChatbotsFacilitate2024}, (2) leveraging Socratic questioning to stimulate collective critical thinking without over-relying on AI-supplied solutions ~\cite{danryDontJustTell2023}, and (3) incorporating a non-repetition mechanism to avert user frustration ~\cite{milanaChatbotsAdvisersEffects2023,xuetaoImpactAgentsAnswers2009}. The anonymous, text-based environment promotes team cohesion by focusing attention on the substance of ideas rather than participants' status or background, effectively addressing power differentials in group dynamics ~\cite{leeSocialIdentityModel2008}. As a result, this system aims to facilitate the consideration of diverse opinions and prevent groupthink in the group decision-making process. 


\section{Limitations \& Future Work}
The system's limitations require further investigation across several dimensions. The LLM-based reasoning cannot fully capture social cues and interpersonal dynamics only with text communication, particularly in culturally diverse contexts ~\cite{hofstedeDimensionalizingCulturesHofstede2011,liuProactiveConversationalAgents2024}. Secondly, the static intervention timing (every eight human turns) reduces adaptability ~\cite{chiangEnhancingAIAssistedGroup2024}. It necessitates more dynamic approaches for natural conversation flow prediction, such as leveraging direct mention of AI, next-speaker prediction ~\cite{bayserLearningMultiPartyTurnTaking2019,ekstedtTurnGPTTransformerbasedLanguage2020,weiMultiPartyChatConversational2023}, and proactive planning strategies ~\cite{liuProactiveConversationalAgents2024}. While the system enables minority members to express dissenting views anonymously, amplifying minority opinions without proper validation may introduce new biases. Future empirical studies should carefully examine the ethical implications of algorithmic intervention in group discussions, particularly regarding power dynamics and decision quality ~\cite{hwangSoundSupportGendered2024,liaoDesigningResponsibleTrust2022}. Future research directions could include incorporating multimodal inputs to detect subtle group dynamics, developing adaptive feedback mechanisms aligned with team objectives, and conducting longitudinal studies to measure long-term effects on group decision-making processes.


\begin{acks}
This research was partially supported by a grant from the Korea Institute for Advancement of Technology (KIAT) funded by the Government of Korea (MOTIE) (P0025495, Establishment of Infrastructure for Integrated Utilization of Design Industry Data). This work was also partially supported by the Technology Innovation Program (20015056, Commercialization design and development of Intelligent Product-Service System for personalized full silver life cycle care) funded by the Ministry of Trade, Industry \& Energy(MOTIE, Korea).
\end{acks}


\bibliographystyle{ACM-Reference-Format}
\bibliography{IUI_test}


\end{document}

