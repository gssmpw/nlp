\section{Related work}
\subsubsection{Chain-of-Thought}

Chain-of-thought reasoning (CoT) \cite{kojima2022large,wei2022chain}, a prompting-based approach that guides LLMs to reason step by step, has emerged as a powerful paradigm for enhancing their decision-making capabilities. CoT has been widely applied to various tasks, including mathematical problem-solving \cite{mishra2022lila} and multi-modal reasoning \cite{chen2023measuring,lu2022learn}, due to its improved reasoning performance, interpretability, transparency \cite{wang2023knowledge}, and collaborative capabilities \cite{le2024visualcoder}.

Traditional CoT methods primarily focus on prompt construction. Manual prompting techniques, such as PAL \cite{gao2023pal}, achieve high performance but are costly and difficult to generalize. In contrast, automatic prompting methods, such as Auto-CoT \cite{zhang2022automatic}, offer low-cost, easily transferable solutions but are more error-prone. To balance performance and efficiency, semi-automatic prompting methods, including AutoMate CoT \cite{shum2023automatic} and BoostedPrompt \cite{pitis2023boosted}, have been introduced, making them suitable for real-world applications.


Beyond prompt design, several different approaches address challenges in CoT reasoning. Self-Refine \cite{madaan2024self} and Reflexion \cite{shinn2024reflexion} enhance LLM reliability by effectively mitigating hallucinations and factual inaccuracies through iterative verification and refinement. To better overcome vanilla CoT’s limitations in handling complex questions, L2M \cite{zhou2022least} decompose problems into simpler sub-tasks. In highly knowledge-sensitive tasks, KD-CoT \cite{wang2023knowledge} integrate external knowledge bases to improve accuracy and reduce factual errors. Additionally, RankPrompt \cite{hu2024rankprompt} leverages inherent uncertainty through self-ensemble techniques, allowing LLMs to rank predictions and enhance accuracy.




Driven by the structural limitations of sequential CoT reasoning, recent advancements have introduced more expressive architectures, such as tree- and graph-based structures. Tree structures \cite{yao2024tree,chen2024boosting} facilitate broader exploration and enable backtracking, enhancing the model’s ability to refine its reasoning process. Meanwhile, graph structures \cite{lei2023boosting,besta2024graph} improve sub-problem aggregation and enable self-verification, further strengthening the robustness and coherence of CoT reasoning.

\subsubsection{Long-Chain Thought Reasoning}
The foundational concept of CoT reasoning has been significantly extended through the development of long-chain thought reasoning. Pioneering models such as OpenAI o1 series \cite{O1} have introduced inference-time scaling by lengthening the reasoning process, enabling more sophisticated deliberation. The key advantage of long-chain CoT lies in its ability to break down complex problems into finer-grained steps, fostering deeper analytical reasoning and ultimately leading to more precise and comprehensive solutions.

Beyond the OpenAI o1, several notable models have embraced the long-chain reasoning paradigm. For instance, DeepSeek-R1 \cite{deepseek}, QwQ \cite{qwq}, and Marco-o1 \cite{zhao2024marco} have demonstrated the effectiveness of this approach. These models iteratively refine their reasoning by identifying and correcting errors, simplifying intricate steps, and exploring alternative strategies when necessary, thereby enhancing both the robustness and adaptability of their inference.

Moreover, some models have incorporated verifiable reward mechanisms to refine long-chain CoT generation while addressing challenges such as reward hacking in large-scale reinforcement learning. Specifically, methods that leverage accuracy-driven rewards from ground-truth answers \cite{team2025kimi,tinyzero} help ensure the reliability and consistency of the generated reasoning paths.


The impact of long-chain CoT extends beyond text-based reasoning. For example, Mulberry \cite{yao2024mulberry} has shown that o1-like reasoning principles can be effectively applied to multimodal contexts, expanding the applicability of long-chain CoT across diverse domains. Additionally, recent advancements have focused on improving stepwise coherence and integrating diverse reasoning strategies \cite{team2025kimi}, leading to enhanced model performance and training efficiency.

These developments underscore the transformative potential of long-chain CoT in enabling LLMs to engage in more structured, rigorous, and adaptable problem-solving, paving the way for more advanced and reliable AI reasoning systems.