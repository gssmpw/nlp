

@inproceedings{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  booktitle={NeurIPS},
  volume={35},
  pages={24824--24837},
  year={2022}
}


@misc{O1,
  author = {OpenAI},
  year = {2024},
  url = {https://openai.com/index/learning-to-reason-with-llms/},
  title = {Learning to reason with LLMs}
}







@inproceeding{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  booktitle={NeurIPS},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{amini2024self,
  title={Self-training: A survey},
  author={Amini, Massih-Reza and Feofanov, Vasilii and Pauletto, Loic and Hadjadj, Lies and Devijver, Emilie and Maximov, Yury},
  journal={Neurocomputing},
  pages={128904},
  year={2024}
}

@inproceeding{zoph2020rethinking,
  title={Rethinking pre-training and self-training},
  author={Zoph, Barret and Ghiasi, Golnaz and Lin, Tsung-Yi and Cui, Yin and Liu, Hanxiao and Cubuk, Ekin Dogus and Le, Quoc},
  booktitle={NeurIPS},
  volume={33},
  pages={3833--3845},
  year={2020}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}


@inproceeding{Besta2024a,
  title = {Graph of Thoughts: Solving Elaborate Problems with Large Language Models},
  author = {Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and Hoefler, Torsten},
  year = {2024},
  booktitle = {AAAI},
  volume = {38},
  number = {16},
  pages = {17682--17690}
}



@article{chia2023contrastive,
  title={Contrastive chain-of-thought prompting},
  author={Chia, Yew Ken and Chen, Guizhen and Tuan, Luu Anh and Poria, Soujanya and Bing, Lidong},
  journal={arXiv preprint arXiv:2311.09277},
  year={2023}
}



@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}






@article{wang2023plan,
  title={Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models},
  author={Wang, Lei and Xu, Wanyu and Lan, Yihuai and Hu, Zhiqiang and Lan, Yunshi and Lee, Roy Ka-Wei and Lim, Ee-Peng},
  journal={arXiv preprint arXiv:2305.04091},
  year={2023}
}


@article{nayab2024concise,
  title={Concise thoughts: Impact of output length on llm reasoning and cost},
  author={Nayab, Sania and Rossolini, Giulio and Buttazzo, Giorgio and Manes, Nicolamaria and Giacomelli, Fabrizio},
  journal={arXiv preprint arXiv:2407.19825},
  year={2024}
}


@article{lin2024constrained,
  title={Constrained reasoning chains for enhancing theory-of-mind in large language models},
  author={Lin, Zizheng and Chan, Chunkit and Song, Yangqiu and Liu, Xin},
  journal={arXiv preprint arXiv:2409.13490},
  year={2024}
}


@article{kuhn2023semantic,
  title={Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation},
  author={Kuhn, Lorenz and Gal, Yarin and Farquhar, Sebastian},
  journal={arXiv preprint arXiv:2302.09664},
  year={2023}
}

@inproceedings{frei2022self,
  title={Self-training converts weak learners to strong learners in mixture models},
  author={Frei, Spencer and Zou, Difan and Chen, Zixiang and Gu, Quanquan},
  booktitle={AISTATS},
  pages={8003--8021},
  year={2022}
}

@inproceedings{ling2024deductive,
  title={Deductive verification of chain-of-thought reasoning},
  author={Ling, Zhan and Fang, Yunhao and Li, Xuanlin and Huang, Zhiao and Lee, Mingu and Memisevic, Roland and Su, Hao},
  booktitle={NeurIPS},
  volume={36},
  year={2024}
}

@inproceedings{chu2024navigate,
  title={Navigate through enigmatic labyrinth a survey of chain of thought reasoning: Advances, frontiers and future},
  author={Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and He, Tao and Wang, Haotian and Peng, Weihua and Liu, Ming and Qin, Bing and Liu, Ting},
  booktitle={ACL},
  pages={1173--1203},
  year={2024}
}


@article{sun2023survey,
  title={A survey of reasoning with foundation models},
  author={Sun, Jiankai and Zheng, Chuanyang and Xie, Enze and Liu, Zhengying and Chu, Ruihang and Qiu, Jianing and Xu, Jiaqi and Ding, Mingyu and Li, Hongyang and Geng, Mengzhe and others},
  journal={arXiv preprint arXiv:2312.11562},
  year={2023}
}


@article{jadhao2016text,
  title={Text Categorization using Jaccard Coefficient for Text Messages},
  author={Jadhao, Ankita and Agrawal, AJ},
  journal={International Journal of Science and Research},
  volume={5},
  number={5},
  pages={2047--2050},
  year={2016}
}



@article{scudder1965adaptive,
  title={Adaptive communication receivers},
  author={Scudder, H},
  journal={IEEE Transactions on Information Theory},
  volume={11},
  number={2},
  pages={167--174},
  year={1965},
  publisher={IEEE}
}


@article{yang2022survey,
  title={A survey on deep semi-supervised learning},
  author={Yang, Xiangli and Song, Zixing and King, Irwin and Xu, Zenglin},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={35},
  number={9},
  pages={8934--8954},
  year={2022},
  publisher={IEEE}
}


@article{tur2005combining,
  title={Combining active and semi-supervised learning for spoken language understanding},
  author={Tur, Gokhan and Hakkani-T{\"u}r, Dilek and Schapire, Robert E},
  journal={Speech Communication},
  volume={45},
  number={2},
  pages={171--186},
  year={2005}
}

@inproceedings{zou2018unsupervised,
  title={Unsupervised domain adaptation for semantic segmentation via class-balanced self-training},
  author={Zou, Yang and Yu, Zhiding and Kumar, BVK and Wang, Jinsong},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={289--305},
  year={2018}
}

@article{zhang2021flexmatch,
  title={Flexmatch: Boosting semi-supervised learning with curriculum pseudo labeling},
  author={Zhang, Bowen and Wang, Yidong and Hou, Wenxin and Wu, Hao and Wang, Jindong and Okumura, Manabu and Shinozaki, Takahiro},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18408--18419},
  year={2021}
}

@inproceedings{lee2013pseudo,
  title={Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks},
  author={Lee, Dong-Hyun and others},
  booktitle={ICML},
  pages={896},
  year={2013}
}


@article{miyato2018virtual,
  title={Virtual adversarial training: a regularization method for supervised and semi-supervised learning},
  author={Miyato, Takeru and Maeda, Shin-ichi and Koyama, Masanori and Ishii, Shin},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={8},
  pages={1979--1993},
  year={2018}
}

@inproceedings{zou2019confidence,
  title={Confidence regularized self-training},
  author={Zou, Yang and Yu, Zhiding and Liu, Xiaofeng and Kumar, BVK and Wang, Jinsong},
  booktitle={CVPR},
  pages={5982--5991},
  year={2019}
}

@inproceedings{mukherjee2020uncertainty,
  title={Uncertainty-aware self-training for few-shot text classification},
  author={Mukherjee, Subhabrata and Awadallah, Ahmed},
  booktitle={NeurIPS},
  volume={33},
  pages={21199--21212},
  year={2020}
}

@article{bartlett1998boosting,
  title={Boosting the margin: A new explanation for the effectiveness of voting methods},
  author={Bartlett, Peter and Freund, Yoav and Lee, Wee Sun and Schapire, Robert E},
  journal={The annals of statistics},
  volume={26},
  number={5},
  pages={1651--1686},
  year={1998},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{grandvalet2004semi,
  title={Semi-supervised learning by entropy minimization},
  author={Grandvalet, Yves and Bengio, Yoshua},
  booktitle={NeurIPS},
  volume={17},
  year={2004}
}


@inproceedings{chen2022debiased,
  title={Debiased self-training for semi-supervised learning},
  author={Chen, Baixu and Jiang, Junguang and Wang, Ximei and Wan, Pengfei and Wang, Jianmin and Long, Mingsheng},
  booktitle={NeurIPS},
  volume={35},
  pages={32424--32437},
  year={2022}
}


@article{koncel2015parsing,
  title={Parsing algebraic word problems into equations},
  author={Koncel-Kedziorski, Rik and Hajishirzi, Hannaneh and Sabharwal, Ashish and Etzioni, Oren and Ang, Siena Dumas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={3},
  pages={585--597},
  year={2015}
}

@inproceedings{hosseini2014learning,
  title={Learning to solve arithmetic word problems with verb categorization},
  author={Hosseini, Mohammad Javad and Hajishirzi, Hannaneh and Etzioni, Oren and Kushman, Nate},
  booktitle={EMNLP},
  pages={523--533},
  year={2014}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@inproceedings{ling2017program,
  title={Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems},
  author={Ling, Wang and Yogatama, Dani and Dyer, Chris and Blunsom, Phil},
  booktitle={ACL},
  pages={158--167},
  year={2017}
}

@article{patel2021nlp,
  title={Are NLP models really able to solve simple math word problems?},
  author={Patel, Arkil and Bhattamishra, Satwik and Goyal, Navin},
  journal={arXiv preprint arXiv:2103.07191},
  year={2021}
}


@article{geva2021did,
  title={Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies},
  author={Geva, Mor and Khashabi, Daniel and Segal, Elad and Khot, Tushar and Roth, Dan and Berant, Jonathan},
  journal={Transactions of the Association for Computational Linguistics},
  year={2021}
}

@article{roy2016solving,
  title={Solving general arithmetic word problems},
  author={Roy, Subhro and Roth, Dan},
  journal={arXiv preprint arXiv:1608.01413},
  year={2016}
}

@article{talmor2018commonsenseqa,
  title={Commonsenseqa: A question answering challenge targeting commonsense knowledge},
  author={Talmor, Alon and Herzig, Jonathan and Lourie, Nicholas and Berant, Jonathan},
  journal={arXiv preprint arXiv:1811.00937},
  year={2018}
}

@article{lanham2023measuring,
  title={Measuring faithfulness in chain-of-thought reasoning},
  author={Lanham, Tamera and Chen, Anna and Radhakrishnan, Ansh and Steiner, Benoit and Denison, Carson and Hernandez, Danny and Li, Dustin and Durmus, Esin and Hubinger, Evan and Kernion, Jackson and others},
  journal={arXiv preprint arXiv:2307.13702},
  year={2023}
}

@article{farquhar2024detecting,
  title={Detecting hallucinations in large language models using semantic entropy},
  author={Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin},
  journal={Nature},
  volume={630},
  number={8017},
  pages={625--630},
  year={2024}
}


@inproceedings{jin2024impact,
  title={The impact of reasoning step length on large language models},
  author={Jin, Mingyu and Yu, Qinkai and Shu, Dong and Zhao, Haiyan and Hua, Wenyue and Meng, Yanda and Zhang, Yongfeng and Du, Mengnan},
  booktitle={Findings of ACL},
  year={2024}
}


@article{zhong2024evaluation,
  title={Evaluation of openai o1: Opportunities and challenges of agi},
  author={Zhong, Tianyang and Liu, Zhengliang and Pan, Yi and Zhang, Yutong and Zhou, Yifan and Liang, Shizhe and Wu, Zihao and Lyu, Yanjun and Shu, Peng and Yu, Xiaowei and others},
  journal={arXiv preprint arXiv:2409.18486},
  year={2024}
}

@article{jin2024self,
  title={Self-harmonized chain of thought},
  author={Jin, Ziqi and Lu, Wei},
  journal={arXiv preprint arXiv:2409.04057},
  year={2024}
}

@article{zhang2022automatic,
  title={Automatic chain of thought prompting in large language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  journal={arXiv preprint arXiv:2210.03493},
  year={2022}
}

@inproceedings{xu2024re,
  title={Re-reading improves reasoning in large language models},
  author={Xu, Xiaohan and Tao, Chongyang and Shen, Tao and Xu, Can and Xu, Hongbo and Long, Guodong and Lou, Jian-Guang and Ma, Shuai},
  booktitle={EMNLP},
  pages={15549--15575},
  year={2024}
}


@inproceedings{zheng2024take,
  title={Take a step back: Evoking reasoning via abstraction in large language models},
  author={Zheng, Huaixiu Steven and Mishra, Swaroop and Chen, Xinyun and Cheng, Heng-Tze and Chi, Ed H and Le, Quoc V and Zhou, Denny},
  booktitle={ICLR},
  year={2024}
}




@misc{qwq,
  author = {Qwen},
  year = {2024},
  url = {https://qwenlm.github.io/blog/qwq-32b-preview/},
  title = {QwQ: Reflect Deeply on the Boundaries of the Unknown}
}

@misc{deepseek,
  author = {DeepSeek},
  year = {2024},
  url = {https://api-docs.deepseek.com/news/news1120},
  title = {Deepseek-r1-lite-preview: Unleashing su-
percharged reasoning power}
}
@article{team2025kimi,
  title={Kimi k1. 5: Scaling Reinforcement Learning with LLMs},
  author={Team, Kimi and Du, Angang and Gao, Bofei and Xing, Bowei and Jiang, Changjiu and Chen, Cheng and Li, Cheng and Xiao, Chenjun and Du, Chenzhuang and Liao, Chonghua and others},
  journal={arXiv preprint arXiv:2501.12599},
  year={2025}
}
@misc{tinyzero,
author       = {Jiayi Pan and Junjie Zhang and Xingyao Wang and Lifan Yuan and Hao Peng and Alane Suhr},
title        = {TinyZero},
howpublished = {https://github.com/Jiayi-Pan/TinyZero},
year         = {2025}
}

@article{wu2024rethinking,
  title={Rethinking Chain-of-Thought from the Perspective of Self-Training},
  author={Wu, Zongqian and Xu, Baoduo and Cui, Ruochen and Zhan, Mengmeng and Zhu, Xiaofeng and Feng, Lei},
  journal={arXiv preprint arXiv:2412.10827},
  year={2024}
}



@article{wang2023knowledge,
  title={Knowledge-driven cot: Exploring faithful reasoning in llms for knowledge-intensive question answering},
  author={Wang, Keheng and Duan, Feiyu and Wang, Sirui and Li, Peiguang and Xian, Yunsen and Yin, Chuantao and Rong, Wenge and Xiong, Zhang},
  journal={arXiv preprint arXiv:2308.13259},
  year={2023}
}
@article{le2024visualcoder,
  title={VISUALCODER: Guiding Large Language Models in Code Execution with Fine-grained Multimodal Chain-of-Thought Reasoning},
  author={Le, Cuong Chi and Truong-Vinh, Hoang-Chau and Phan, Huy Nhat and Le, Dung Duy and Nguyen, Tien N and Bui, Nghi DQ},
  journal={arXiv preprint arXiv:2410.23402},
  year={2024}
}
@article{mishra2022lila,
  title={Lila: A unified benchmark for mathematical reasoning},
  author={Mishra, Swaroop and Finlayson, Matthew and Lu, Pan and Tang, Leonard and Welleck, Sean and Baral, Chitta and Rajpurohit, Tanmay and Tafjord, Oyvind and Sabharwal, Ashish and Clark, Peter and others},
  journal={arXiv preprint arXiv:2210.17517},
  year={2022}
}

@article{chen2023measuring,
  title={Measuring and improving chain-of-thought reasoning in vision-language models},
  author={Chen, Yangyi and Sikka, Karan and Cogswell, Michael and Ji, Heng and Divakaran, Ajay},
  journal={arXiv preprint arXiv:2309.04461},
  year={2023}
}
@article{lu2022learn,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2507--2521},
  year={2022}
}
@inproceedings{gao2023pal,
  title={Pal: Program-aided language models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={10764--10799},
  year={2023},
  organization={PMLR}
}

@article{shum2023automatic,
  title={Automatic prompt augmentation and selection with chain-of-thought from labeled data},
  author={Shum, KaShun and Diao, Shizhe and Zhang, Tong},
  journal={arXiv preprint arXiv:2302.12822},
  year={2023}
}
@article{pitis2023boosted,
  title={Boosted prompt ensembles for large language models},
  author={Pitis, Silviu and Zhang, Michael R and Wang, Andrew and Ba, Jimmy},
  journal={arXiv preprint arXiv:2304.05970},
  year={2023}
}

@inproceedings{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  booktitle={NeurIPS},
  volume={36},
  year={2024}
}

@inproceedings{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  booktitle={NeurIPS},
  volume={36},
  year={2024}
}

@article{zhou2022least,
  title={Least-to-most prompting enables complex reasoning in large language models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and others},
  journal={arXiv preprint arXiv:2205.10625},
  year={2022}
}
@article{nahid2024tabsqlify,
  title={TabSQLify: Enhancing Reasoning Capabilities of LLMs Through Table Decomposition},
  author={Nahid, Md Mahadi Hasan and Rafiei, Davood},
  journal={arXiv preprint arXiv:2404.10150},
  year={2024}
}

@article{li2023chain,
  title={Chain of knowledge: A framework for grounding large language models with structured knowledge bases},
  author={Li, Xingxuan and Zhao, Ruochen and Chia, Yew Ken and Ding, Bosheng and Bing, Lidong and Joty, Shafiq and Poria, Soujanya},
  journal={arXiv preprint arXiv:2305.13269},
  volume={3},
  year={2023}
}
@article{hu2024rankprompt,
  title={RankPrompt: Step-by-Step Comparisons Make Language Models Better Reasoners},
  author={Hu, Chi and Ge, Yuan and Ma, Xiangnan and Cao, Hang and Li, Qiang and Yang, Yonghua and Xiao, Tong and Zhu, Jingbo},
  journal={arXiv preprint arXiv:2403.12373},
  year={2024}
}
@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{chen2024boosting,
  title={Boosting of thoughts: Trial-and-error problem solving with large language models},
  author={Chen, Sijia and Li, Baochun and Niu, Di},
  journal={arXiv preprint arXiv:2402.11140},
  year={2024}
}
@article{lei2023boosting,
  title={Boosting logical reasoning in large language models through a new framework: The graph of thought},
  author={Lei, Bin and Liao, Chunhua and Ding, Caiwen and others},
  journal={arXiv preprint arXiv:2308.08614},
  year={2023}
}
@inproceedings{besta2024graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  booktitle={AAAI},
  volume={38},
  number={16},
  pages={17682--17690},
  year={2024}
}
@article{zhao2024marco,
  title={Marco-o1: Towards open reasoning models for open-ended solutions},
  author={Zhao, Yu and Yin, Huifeng and Zeng, Bo and Wang, Hao and Shi, Tianqi and Lyu, Chenyang and Wang, Longyue and Luo, Weihua and Zhang, Kaifu},
  journal={arXiv preprint arXiv:2411.14405},
  year={2024}
}

@article{yao2024mulberry,
  title={Mulberry: Empowering mllm with o1-like reasoning and reflection via collective monte carlo tree search},
  author={Yao, Huanjin and Huang, Jiaxing and Wu, Wenhao and Zhang, Jingyi and Wang, Yibo and Liu, Shunyu and Wang, Yingjie and Song, Yuxin and Feng, Haocheng and Shen, Li and others},
  journal={arXiv preprint arXiv:2412.18319},
  year={2024}
}

@misc{zeng2025simplerl,
  title={7B Model and 8K Examples: Emerging Reasoning with Reinforcement Learning is Both Effective and Efficient},
  author={Weihao Zeng and Yuzhen Huang and Wei Liu and Keqing He and Qian Liu and Zejun Ma and Junxian He},
  year={2025},
  howpublished={\url{https://hkust-nlp.notion.site/simplerl-reason}},
  note={Notion Blog},
  year={2025}
}