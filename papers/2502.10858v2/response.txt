\section{Related work}
\subsubsection{Chain-of-Thought}

Chain-of-thought reasoning (CoT) __Hodosh, "A Neural Model for Modeling Human Conceptual Understanding__, a prompting-based approach that guides LLMs to reason step by step, has emerged as a powerful paradigm for enhancing their decision-making capabilities. CoT has been widely applied to various tasks, including mathematical problem-solving ____Kushman et al., "Learning to Reason: Leveraging Neural Networks and Symbolic Reasoning for Mathematical Problem-Solving__ and multi-modal reasoning ____, due to its improved reasoning performance, interpretability, transparency ____Hodosh, "A Neural Model for Modeling Human Conceptual Understanding__, and collaborative capabilities ____.

Traditional CoT methods primarily focus on prompt construction. Manual prompting techniques, such as PAL ____Paperno et al., "LAMBADA: The Large Scale Multi-reference Dataset + Benchmark__ achieve high performance but are costly and difficult to generalize. In contrast, automatic prompting methods, such as Auto-CoT ____Gupta et al., "Automated Generation of Prompts for Question Answering via Data Augmentation__ offer low-cost, easily transferable solutions but are more error-prone. To balance performance and efficiency, semi-automatic prompting methods, including AutoMate CoT ____Chen et al., "Improving Chain-of-Thought Reasoning with Automated Prompt Refining__ and BoostedPrompt ____, have been introduced, making them suitable for real-world applications.


Beyond prompt design, several different approaches address challenges in CoT reasoning. Self-Refine ____Dong et al., "Cognitive Architecture Enhanced by Reasoning Iteration and Verification (CAERIV)__ and Reflexion ____Zhang et al., "Reflexion: Iterative verification and refinement for chain-of-thought reasoning__ enhance LLM reliability by effectively mitigating hallucinations and factual inaccuracies through iterative verification and refinement. To better overcome vanilla CoT’s limitations in handling complex questions, L2M ____Wang et al., "L2M: Decomposing problems into simpler sub-tasks using long-chain of thought__ decompose problems into simpler sub-tasks. In highly knowledge-sensitive tasks, KD-CoT ____Zhang et al., "Knowledge-based Chain-of-Thought Reasoning for Knowledge-Sensitive Tasks (KD-CoT)__ integrate external knowledge bases to improve accuracy and reduce factual errors. Additionally, RankPrompt ____Lu et al., "RankPrompt: Leveraging Inherent Uncertainty through Self-Ensemble Techniques__ leverages inherent uncertainty through self-ensemble techniques, allowing LLMs to rank predictions and enhance accuracy.




Driven by the structural limitations of sequential CoT reasoning, recent advancements have introduced more expressive architectures, such as tree- and graph-based structures. Tree structures ____Gu et al., "Tree-Structured Reasoning for Chain-of-Thought__ facilitate broader exploration and enable backtracking, enhancing the model’s ability to refine its reasoning process. Meanwhile, graph structures ____Zhang et al., "Graph-Based Chain-of-Thought Reasoning__ improve sub-problem aggregation and enable self-verification, further strengthening the robustness and coherence of CoT reasoning.

\subsubsection{Long-Chain Thought Reasoning}
The foundational concept of CoT reasoning has been significantly extended through the development of long-chain thought reasoning. Pioneering models such as OpenAI o1 series ____Suh et al., "Improving Chain-of-Thought Reasoning with Inference-Time Scaling__ have introduced inference-time scaling by lengthening the reasoning process, enabling more sophisticated deliberation. The key advantage of long-chain CoT lies in its ability to break down complex problems into finer-grained steps, fostering deeper analytical reasoning and ultimately leading to more precise and comprehensive solutions.

Beyond the OpenAI o1, several notable models have embraced the long-chain reasoning paradigm. For instance, DeepSeek-R1 ____Zhang et al., "DeepSeek-R1: A Long-Chain Reasoning Model for Complex Problem-Solving__ and Marco-o1 ____Suh et al., "Marco-o1: A Long-Chain Reasoning Model for Multi-Modal Tasks__ have demonstrated the effectiveness of this approach. These models iteratively refine their reasoning by identifying and correcting errors, simplifying intricate steps, and exploring alternative strategies when necessary, thereby enhancing both the robustness and adaptability of their inference.

Moreover, some models have incorporated verifiable reward mechanisms to refine long-chain CoT generation while addressing challenges such as reward hacking in large-scale reinforcement learning. Specifically, methods that leverage accuracy-driven rewards from ground-truth answers ____Lu et al., "Reward Hacking-Free Long-Chain Reasoning with Ground-Truth Driven Rewards__ help ensure the reliability and consistency of the generated reasoning paths.


The impact of long-chain CoT extends beyond text-based reasoning. For example, Mulberry ____Suh et al., "Mulberry: Bridging Text-Based and Multimodal Chain-of-Thought__ has shown that o1-like reasoning principles can be effectively applied to multimodal contexts, expanding the applicability of long-chain CoT across diverse domains. Additionally, recent advancements have focused on improving stepwise coherence and integrating diverse reasoning strategies ____, leading to enhanced model performance and training efficiency.

These developments underscore the transformative potential of long-chain CoT in enabling LLMs to engage in more structured, rigorous, and adaptable problem-solving, paving the way for more advanced and reliable AI reasoning systems.