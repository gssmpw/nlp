\section{Related work}
\subsubsection{Chain-of-Thought}

Chain-of-thought reasoning (CoT) ____, a prompting-based approach that guides LLMs to reason step by step, has emerged as a powerful paradigm for enhancing their decision-making capabilities. CoT has been widely applied to various tasks, including mathematical problem-solving ____ and multi-modal reasoning ____, due to its improved reasoning performance, interpretability, transparency ____, and collaborative capabilities ____.

Traditional CoT methods primarily focus on prompt construction. Manual prompting techniques, such as PAL ____, achieve high performance but are costly and difficult to generalize. In contrast, automatic prompting methods, such as Auto-CoT ____, offer low-cost, easily transferable solutions but are more error-prone. To balance performance and efficiency, semi-automatic prompting methods, including AutoMate CoT ____ and BoostedPrompt ____, have been introduced, making them suitable for real-world applications.


Beyond prompt design, several different approaches address challenges in CoT reasoning. Self-Refine ____ and Reflexion ____ enhance LLM reliability by effectively mitigating hallucinations and factual inaccuracies through iterative verification and refinement. To better overcome vanilla CoT’s limitations in handling complex questions, L2M ____ decompose problems into simpler sub-tasks. In highly knowledge-sensitive tasks, KD-CoT ____ integrate external knowledge bases to improve accuracy and reduce factual errors. Additionally, RankPrompt ____ leverages inherent uncertainty through self-ensemble techniques, allowing LLMs to rank predictions and enhance accuracy.




Driven by the structural limitations of sequential CoT reasoning, recent advancements have introduced more expressive architectures, such as tree- and graph-based structures. Tree structures ____ facilitate broader exploration and enable backtracking, enhancing the model’s ability to refine its reasoning process. Meanwhile, graph structures ____ improve sub-problem aggregation and enable self-verification, further strengthening the robustness and coherence of CoT reasoning.

\subsubsection{Long-Chain Thought Reasoning}
The foundational concept of CoT reasoning has been significantly extended through the development of long-chain thought reasoning. Pioneering models such as OpenAI o1 series ____ have introduced inference-time scaling by lengthening the reasoning process, enabling more sophisticated deliberation. The key advantage of long-chain CoT lies in its ability to break down complex problems into finer-grained steps, fostering deeper analytical reasoning and ultimately leading to more precise and comprehensive solutions.

Beyond the OpenAI o1, several notable models have embraced the long-chain reasoning paradigm. For instance, DeepSeek-R1 ____, QwQ ____, and Marco-o1 ____ have demonstrated the effectiveness of this approach. These models iteratively refine their reasoning by identifying and correcting errors, simplifying intricate steps, and exploring alternative strategies when necessary, thereby enhancing both the robustness and adaptability of their inference.

Moreover, some models have incorporated verifiable reward mechanisms to refine long-chain CoT generation while addressing challenges such as reward hacking in large-scale reinforcement learning. Specifically, methods that leverage accuracy-driven rewards from ground-truth answers ____ help ensure the reliability and consistency of the generated reasoning paths.


The impact of long-chain CoT extends beyond text-based reasoning. For example, Mulberry ____ has shown that o1-like reasoning principles can be effectively applied to multimodal contexts, expanding the applicability of long-chain CoT across diverse domains. Additionally, recent advancements have focused on improving stepwise coherence and integrating diverse reasoning strategies ____, leading to enhanced model performance and training efficiency.

These developments underscore the transformative potential of long-chain CoT in enabling LLMs to engage in more structured, rigorous, and adaptable problem-solving, paving the way for more advanced and reliable AI reasoning systems.