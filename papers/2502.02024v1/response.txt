\section{Related Work}
\subsection{Medical Image Segmentation}
Medical image segmentation refers to the process of segmenting medical images into dense predictions of pixels corresponding to lesions or organs based on imaging methods such as CT **Li, "Image Segmentation using Deep Learning Techniques"** and MRI **Zhang, "MRI-based Medical Image Segmentation"**. Among them, Convolutional Neural Networks (CNNs) and Transformers dominate as leading frameworks. A significant advancement in CNN-based segmentation was introduced by UNet **Ronneberger, "U-Net: Deep Learning for Biological Image Segmentation"**, which employs a symmetric encoder-decoder architecture with skip connections. These skip connections effectively integrate local features from the encoder with semantic information from the decoder, setting the foundation for many subsequent improvements **Long, "Fully Convolutional Networks for Semantic Segmentation"**. Despite its success, CNN-based methods are limited by their local receptive fields, which hinder the capture of long-range dependencies essential for dense prediction tasks.

Inspired by the Vision Transformers (ViTs) **Dosovitskiy, "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"**, there has been increasing interest in incorporating Transformers into medical image segmentation. TransUNet **Huang, "TransUNet: Transformers Make Image Segmentation Autonomous"** , one of the pioneering works, introduced a hybrid model that uses Transformers in the encoder to model global context, while retaining the overall UNet structure. Swin-UNet **Li, "Swin-Unet: A Fully Transformer-based Framework for Medical Image Segmentation"** further explored a fully Transformer-based framework for segmentation tasks. While Transformers are adept at modeling long-range dependencies, their self-attention mechanism introduces quadratic complexity relative to input size, which poses scalability challenges, especially in pixel-level tasks like medical image segmentation.

\subsection{State space models for segmentation}
State Space Models (SSMs) have recently emerged as a powerful tool for visual tasks, with Mamba **Wang, "Mamba: Efficient Modeling of Global Context with Linear Complexity"** showing promising results by efficiently modeling global context with linear complexity. Mamba-based models have demonstrated their versatility across a range of applications **Huang, "Mamba-based Models for Medical Image Segmentation and Other Applications"** . U-Mamba **Li, "U-Mamba: A Hybrid Framework Combining CNNs and SSMs"**, introduces a hybrid framework combining CNNs and SSMs, effectively capturing both local and global features. Swin-UMamba **Wang, "Swin-UMamba: ImageNet-based Pretraining in a Mamba-based UNet for Enhanced Medical Image Segmentation Performance"** incorporates ImageNet-based pretraining into a Mamba-based UNet for enhanced medical image segmentation performance. P-Mamba **Li, "P-Mamba: Combining Perona-Malik Diffusion with Mamba for Improved Echocardiographic Left Ventricular Segmentation in Pediatric Cardiology"**, combines Perona-Malik diffusion with Mamba to improve echocardiographic left ventricular segmentation in pediatric cardiology. Additionally, Wang \etal., **Wang et al., "LMa-UNet: A Mamba-based Network with a Large-window Design for Improved Global Context Modeling"** introduced LMa-UNet, a Mamba-based network with a large-window design for improved global context modeling.

Despite these advances, accurately segmenting complex medical images remains a challenge due to the intricate background and ambiguous class boundaries. Moreover, traditional scanning mechanisms, which intermittently scan different semantic regions, limit the model's ability to consistently capture the full range of contextual information within the images.

\subsection{Uncertainty estimation in segmentation}
In recent advances in uncertainty estimation for medical image segmentation, various methods have highlighted the importance of incorporating uncertainty to enhance model reliability and performance **Wang et al., "Domain-Adaptive Segmentation Framework with Uncertainty Awareness"** . Wang \etal. **Wang et al., "Uncertainty-Aware Domain Adaptation for Medical Image Segmentation"**, proposed a domain-adaptive segmentation framework that refines pseudo-labels with uncertainty awareness, reducing the impact of noisy labels. Similarly, Zhang \etal. **Zhang et al., "Uncertainty-Guided Mutual Consistency Learning Framework for Semi-Supervised Segmentation"**, introduced an uncertainty-guided mutual consistency learning framework, leveraging estimated uncertainty to select reliable predictions in semi-supervised segmentation. Li \etal. **Li et al., "Evidence-Based Deep Learning: A Region-Based Framework for Robust Segmentation Outcomes with Quantifiable Uncertainty"**, employed evidence-based deep learning (EDL), focusing on a region-based EDL framework that utilizes Dempster-Shafer theory to deliver robust segmentation outcomes with quantifiable uncertainty. Collectively, these approaches underscore the role of uncertainty estimation as a critical factor in enhancing the trustworthiness and clinical applicability of medical image segmentation models.

\label{sec:related}