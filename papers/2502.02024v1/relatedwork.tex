\section{Related Work}
\subsection{Medical Image Segmentation}
Medical image segmentation refers to the process of segmenting medical images into dense predictions of pixels corresponding to lesions or organs based on imaging methods such as CT ~\cite{zhou2019semi,zhou2019prior,wang2019abdominal,fu2021review} and MRI~\cite{ji2022amos,zeng2020review}. Among them, Convolutional Neural Networks (CNNs) and Transformers dominate as leading frameworks. A significant advancement in CNN-based segmentation was introduced by UNet~\cite{ronneberger2015u}, which employs a symmetric encoder-decoder architecture with skip connections. These skip connections effectively integrate local features from the encoder with semantic information from the decoder, setting the foundation for many subsequent improvements~\cite{zhou2019unet++,oktay2018attention,le2023rrc,huang2021missformer,tang2021recurrent}. Despite its success, CNN-based methods are limited by their local receptive fields, which hinder the capture of long-range dependencies essential for dense prediction tasks.

Inspired by the Vision Transformers (ViTs)~\cite{dosovitskiy2020image}, there has been increasing interest in incorporating Transformers into medical image segmentation~\cite{hatamizadeh2022unetr,zhou2023nnformer,lin2022ds,huang2022missformer,wang2022mixed,zhao2024semi}. TransUNet~\cite{chen2024transunet}, one of the pioneering works, introduced a hybrid model that uses Transformers in the encoder to model global context, while retaining the overall UNet structure. Swin-UNet~\cite{cao2022swin} further explored a fully Transformer-based framework for segmentation tasks. While Transformers are adept at modeling long-range dependencies, their self-attention mechanism introduces quadratic complexity relative to input size, which poses scalability challenges, especially in pixel-level tasks like medical image segmentation.

\subsection{State space models for segmentation}
State Space Models (SSMs) have recently emerged as a powerful tool for visual tasks, with Mamba~\cite{gu2023mamba,dao2024transformers} showing promising results by efficiently modeling global context with linear complexity. Mamba-based models have demonstrated their versatility across a range of applications~\cite{zhu2024vision,ruan2024vm,he2024mambaad,zhang2024voxel,fan2024slicemamba}. U-Mamba~\cite{ma2024u} introduces a hybrid framework combining CNNs and SSMs, effectively capturing both local and global features. Swin-UMamba~\cite{liu2024swin} incorporates ImageNet-based pretraining into a Mamba-based UNet for enhanced medical image segmentation performance.
P-Mamba~\cite{ye2024p} combines Perona-Malik diffusion with Mamba to improve echocardiographic left ventricular segmentation in pediatric cardiology. Additionally, Wang \etal.~\cite{wang2024large} introduced LMa-UNet, a Mamba-based network with a large-window design for improved global context modeling.


Despite these advances, accurately segmenting complex medical images remains a challenge due to the intricate background and ambiguous class boundaries. Moreover, traditional scanning mechanisms, which intermittently scan different semantic regions, limit the model's ability to consistently capture the full range of contextual information within the images.

\subsection{Uncertainty estimation in segmentation}
In recent advances in uncertainty estimation for medical image segmentation, various methods have highlighted the importance of incorporating uncertainty to enhance model reliability and performance~\cite{lu2023uncertainty,wei2023consistency,monteiro2020stochastic,wang2019aleatoric,zheng2021rectifying,fan2022ucc}. Wang \etal.~\cite{9710267} proposed a domain-adaptive segmentation framework that refines pseudo-labels with uncertainty awareness, reducing the impact of noisy labels. Similarly, Zhang \etal.~\cite{zhang2023uncertainty} introduced an uncertainty-guided mutual consistency learning framework, leveraging estimated uncertainty to select reliable predictions in semi-supervised segmentation. Li \etal.~\cite{li2023region} employed evidence-based deep learning (EDL), focusing on a region-based EDL framework that utilizes Dempster-Shafer theory to deliver robust segmentation outcomes with quantifiable uncertainty. Collectively, these approaches underscore the role of uncertainty estimation as a critical factor in enhancing the trustworthiness and clinical applicability of medical image segmentation models.

\label{sec:related}