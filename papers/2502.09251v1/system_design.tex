\section{\projecttitle Library}
\label{sec:abstraction}
\label{sec:recipe-implementation}
%\dimitra{system level design details here and the low-level API!}




\subsection{\projecttitle{} Architecture Overview} \label{subsec:overview}
\myparagraph{Distributed systems architecture} 
A distributed data store system uses a tiered architecture with a distributed data store layer for routing requests, a replication layer (provided by \projecttitle{}) for consistent data replication, and a data layer (Key-Value stores) for storage.  \projecttitle{} provides a trusted computing base using trusted execution environments (TEEs) to protect consensus fault tolerance protocols, including secure initialization of replicas and a direct I/O layer for efficient, secure communication.


Figure~\ref{fig:overview} shows the overview of a distributed data store system that builds on top of the \projecttitle{} system.  Distributed data stores implement a tiered architecture consisting of a \emph{distributed data store layer}, \emph{replication layer}, and  \emph{data layer}. In our case, the replication and data layers are provided by \projecttitle{}. The distributed data store layer maintains a routing table that matches the keyspace with the owners' nodes. This layer is responsible for forwarding client requests to the appropriate coordinator nodes (e.g., leader of the replication protocol) for execution. The \projecttitle{} replication layer is responsible for consistently replicating the data by executing the implemented protocol. After the protocol execution, \projecttitle{} nodes store the data in their Key-Value stores (KVs), the data layer, and they reply to the client~\cite{redis, rocksdb, leveldb, memcached2004}.

\myparagraph{\projecttitle{} architecture} \projecttitle{} design is based on a distributed setting of TEEs that implement a (distributed) trusted computing base (TCB) and shield the execution of unmodified CFT protocols against Byzantine failures. \projecttitle{}'s TCB contains the CFT protocol's code along with some metadata specific to the protocol. 

The code and TEEs of all replicas are attested before instantiating the protocol to ensure that the TEE hardware and the residing code are genuine. All authenticated replicas receive secrets (e.g., signing or encryption keys) and configuration data securely at initialization. 

Further, \projecttitle{} builds a \emph{direct I/O layer} comprised of a networking library for low-latency communication between nodes ($\S$~\ref{subsec:networkin}). The library bypasses the kernel stack for performance and shields the communication to guarantee non-equivocation and transferable authentication against Byzantine actors in the network. \projecttitle{} guarantees both properties by layering the non-equivocation and authentication layers on top of the direct I/O layer. In addition,  to strengthen \projecttitle{}'s security properties and eliminate syscalls, we map the network library software stack to the TEE's address space.

Lastly, \projecttitle{} builds the  \emph{data layer} on top of local KV store instances. Our design of the KV store increases the trust in individual nodes, allowing for local reads ($\S$~\ref{subsec:KV}). Our KV store achieves two goals: first, we guarantee trust to individual replicas to serve reads locally, and second, we limit the TCB size, optimizing the enclave memory usage. As shown in Figure~\ref{fig:overview}, \projecttitle{} keeps bulk data (values) in the host memory and stores only minimal data (keys + metadata) in the TEE area. The metadata, e.g., hash of the value, timestamps, etc., are kept along with keys in the TEE for integrity verification. 



Our work shows how to leverage modern hardware to build efficient, robust, and easily adaptable distributed protocols by meeting the aforementioned transformation requirements.
%(see Q1---Q3 below). Motivated by the recently launched cloud-hosted blockchain systems, we also argue that confidential BFT protocols are required to satisfy modern applications' needs for confidentiality (see Q4 below).
To achieve our goal, we need to address the following technical questions discussed in~$\S$~\ref{sec:motivation}.
Next, we present the implementation details or our work focusing on four core components of \projecttitle{} ($\S$~\ref{sec:recipe_impl_apis}). Table~\ref{tab:api} summarizes the \projecttitle{}'s API for each component. 

\begin{figure*}[t]
    \begin{center}
        \includegraphics[width=1\textwidth]{figs/recipe_full_system.pdf}
        %\vspace{-2pt}
        \caption{\projecttitle{}'s system architecture.}
       % \vspace{-1pt}
        \label{fig:overview}
    \end{center}
\end{figure*}


\input{motivation}

\if 0
This section describes four core components of \projecttitle{}. Table~\ref{tab:api} summarizes the \projecttitle{}'s API for each component.%  (a) networking library, (b) KV store, (c) secure runtime, and (d) attestation and configuration management.


%(\projecttitle{}-lib): \emph{(i)} the shielded networking library which leverages direct I/O while also preventing Byzantine behaviors in the untrusted network infrastructure, \emph{(ii)} the KV store which guarantees trust to local reads and, \emph{(iii)} the attestation and secrets distribution service which ensures that only trusted nodes know the configuration, keys, etc.


%\pramod{fix missing citations and a lot of typos and grammar errors.}


\subsection{\projecttitle Implementation and APIs}
\label{sec:recipe_impl_apis}
\myparagraph{\projecttitle{} networking}
\label{subsec:networkin}
%\myparagraph{Networking overview}
\projecttitle{} adopts the Remote Procedure Call (RPC) paradigm~\cite{286500} over a generic network library with various transportation layers (Infiniband, RoCE, and DPDK), which is also favorable in the context of TEEs where traditional kernel-based networking is impractical~\cite{kuvaiskii2017sgxbounds}. %Below, we explain how the networking layer is initialized in \projecttitle{}, the requests workflow and the core implementation details.



\begin{table}[t]
%\small
\fontsize{7}{9}\selectfont 

\begin{center}
\begin{tabular}{ |c|c| }
 \hline
 \bf{Attestation API} &  \\ \hline
 \multirow{1}{*}{\texttt{attest(measurement)}} & Attests the node based on  a measurement.  \\  \hline \hline
 \bf{Initialization API} &  \\ \hline
 \texttt{create\_rpc(app\_ctx)} & Initializes an RPCobj. \\
  \texttt{init\_store()} & Initializes the KV store. \\
  \texttt{reg\_hdlr(\&func)} & Registers request handlers. \\ \hline \hline
 \bf{Network API} &  \\ \hline
 \texttt{send(\&msg\_buf)} & Prepares a req for transmission. \\
 %\hline
% \texttt{multicast(\&msg\_buf, nodes)} & Prepares a request for multicast. \\
 \multirow{1}{*}{\texttt{respond(\&msg\_buf)}} & Prepares a resp for transmission. \\
 \texttt{poll()} & Polls for incoming messages. \\\hline \hline
% \texttt{aggregates\_multicast()} &  \\ 
 \bf{Security API} &  \\ \hline
 \texttt{verify\_msg(\&msg\_buf)} & Verifies the authenticity/integrity and cnt of a msg. \\
 \texttt{shield\_msg(\&msg\_buf)} & Generates a shielded msg. \\ \hline \hline
% \texttt{aggregates\_multicast()} &  \\ 
 \bf{KV Store API} &  \\ \hline
 \texttt{write(key, value)} & Writes a KV to the store. \\
 \hline
 \multirow{2}{*}{\texttt{get(key, \&v$_{TEE}$)}} & Reads the value into \texttt{v$_{TEE}$} \\ & and verifies integrity. \\ \hline %\hline
 \if 0
 \bf{Trusted Leases API} &  \\ \hline
 \texttt{init\_lease(node\_id, thread\_id)} & Requests a lease from the grander.\\ \hline
 \texttt{renew\_lease(\&lease)} & Updates a lease.\\ \hline
 \texttt{grand\_or\_update\_lease(node\_id, thread\_id)} & Grands a lease.\\ \hline
 \texttt{exec\_with\_lease(\&lease, \&func, \&args\_list)} & Executes the func within the lease ownership.\\ [1ex] \hline
 \fi
\end{tabular}
\end{center}
%\vspace{-10pt}
\caption{\projecttitle{} library APIs.} \label{tab:api}
\vspace{-6pt}
\end{table}





\if 0

Developer effort â€“ initialization. The developer must spec-
ify the number and the nature of the logical message flows
they require. In RDMA parlance each flow corresponds to
one queue pair (QP), i.e., a send and a receive queue. For
instance, consider Hermes where a write requires two broad-
cast rounds: invalidations (invs) and validations (vals). Each
worker in each node sets up three QPs: 1) to send and re-
ceive invs, 2) to send and receive acks (for the invs) and 3) to
send and receive vals. Splitting the communication in mes-
sage flows is the responsibility of the developer. To create
the QP for each message flow, the developer simply calls a
Odyssey function, passing details about the nature of the QP.

\fi





% \myparagraph{Initialization}
% Prior to application's execution, developers need to initialize the networking layer by specifying the number of concurrent available connections, the types of the available requests and by registering the appropriate (custom) request handlers. In \projecttitle{} terms, a communication endpoint corresponds to a per-thread RPC object (RPCobj) with private send/receive queues. All RPCobjs are registered to the same physical port (configurable). Initially, \projecttitle{} creates a handle to the NIC which is passed to all RPCobjs. Developers need to define the types of the RPC requests, each of which might be served by a different request handler. Request handlers are functions written by developers that are registered with the handle prior to the creation of the communication endpoints. Lastly, before executing the application's code, the connections between RPCobjs need to be correctly established.

\if 0
\projecttitle{} offers a \texttt{create\_rpc()} function that creates Remote Procedure Call (RPC) objects (rpc) bound to the NIC. Specifically this function takes the application context as an argument, i.e., node's NIC specification and port, remote IP and port, creates a communication endpoint and continuously tries to establish connection with the remote side. The function returns after the connection establishment. An rpc offers bidirectional communication between the two sides. Additionally, we need to register the request handler functions to the rpcs, i.e., pass a pointer function a the construction of the endpoint which states what will happen when a request of a specific type is received. The developer might to overwrite/implement the \texttt{init\_store()} function which will keep an application's state and metadata in the trusted enclave. By default \projecttitle{} comes with a thread-safe and lock-free hybrid skiplist based on~\cite{avocado, folly}. While implementing our use cases in $\$$~\ref{sec:eval}, we used two  \projecttitle{} skiplists for metadata and data accordingly.  %Lastly, we need to register the request handler functions to the \texttt{rpc}s, i.e., pass a pointer function a the construction of the endpoint which states what will happen when a request of a specific type is received.
\fi

\if 0
Developer effort â€“ send and receive. For each QP, Odys-
sey maintains a send-FIFO and a receive-FIFO. Sending re-
quires that the developer first inserts messages in the send-
FIFO via an Odyssey insert function; later they can call a send
function to trigger the sending of all inserted messages. To re-
ceive messages, the developer need only call an Odyssey func-
tion that polls the receive-FIFO. Notably, the developer can
specify and register handlers to be called when calling any
one of the Odyssey functions. Therefore, the Odyssey polling
function will deliver the incoming messages, if any, to the
developer-specified handler.
\fi





%\myparagraph{send/receive operations}
We offer asynchronous network operations following the RPC paradigm. For each RPCobj, \projecttitle{} keeps a transmission (TX) and reception (RX) queue, organized as ring buffers. Developers enqueue requests and responses to requests via \projecttitle{}'s specific functions which place the message in the RPCobj's TX queue. Later, they can call a polling function that flushes the messages in the TX and drains the RX queues of an RPCobj. The function will trigger the sending of all queued messages and process all received requests and responses. Reception of a request triggers the execution of the request handler for that specific type. Reception of a response to a request triggers a cleanup function that releases all resources allocated for the request, e.g., message buffers and rate limiters (for congestion). %The cleanup functions can be overwritten by the developers for extra functionalities.

\if 0
\projecttitle{} offers high performance RPCs by extending eRPC~\cite{erpc} and DPDK~\cite{dpdk} in the context of TEEs. eRPC is .. Specifically, we place the message buffers outside the trusted enclave to both overcome the limited enclave memory and enable DMA operations~\footnote{DMA mappings are prohibited in the trusted area of a TEE as this violates their security properties~\cite{intel-sgx}}. We design a \texttt{send()} operation is used to submit a message for transmission. The message buffer is allocated by our library in \texttt{Hugepage} memory area and is later copied to the transmission queue (TX). Further, we provide a multicast() operation which creates identical copies of a message for all the recipient group.    Upon a reception of a request, the program control passes to the registered request handler where the function \texttt{respond()} can submit a response or \texttt{ACK} to that request. Lastly, the function \texttt{poll()} needs to be called regularly to fetch and process and send the incoming responses or requests and send the queued responses and requests respectively. 
\fi




%\myparagraph{Non-equivocation and authentication layers} %\manos{changed the paragraph titles to match the title and the first sentence below}
\label{non-equivocation-design}
%extends the properties of conventional CFT protocols to tolerate Byzantine settings by 
\projecttitle{}'s networking library embodies a non-equivocation and an authentication layer through two TEE-assisted primitives, the shield\_request() and verify\_request().%, shown in Algorithm~\ref{algo:primitives}.% (the \texttt{Attest()} primitive is used for initialization and is discussed in~$\S$~\ref{subsec:attestation}). We now explain the mechanisms, correctness arguments are presented in $\S$~\ref{sec:theory}.



\noindent{\underline{Non-equivocation layer}}: \projecttitle{} prevents replay attacks in the network with sequence numbers for the exchanged messages. Each replica maintains local sequence tuples of the form (view, cq, cnt$_{cq}$) where view is the current view number, cq is the communication endpoint(s) between two nodes, and cnt$_{cq}$ is the current trusted counter value in that view for the latest request sent over the cq. The sender assigns to messages a unique tuple of the form (view, cq, cnt$_{cq}$) and then increments cnt$_{cq}$ to guarantee monotonicity. % and rollback/forking attacks resilience.  %the request with the correct tuple and increments the $seq$.
Replicas execute the implemented CFT protocol for verified valid requests. Replicas can verify the freshness of a message by examining its cnt$_{cq}$ (verify\_request() primitive). The primitive verifies that the message's id (as part of the metadata) is consistent with the receiver's local counter rcnt$_{cq}$ (rcnt$_{cq}$ is the last seen valid message counter for received messages in cq). \projecttitle{}'s replicas are willing to accept ``future'' valid messages as these might come out of order, i.e., messages whose cnt$_{cq}$ is $>$ (rcnt$_{cq}$+1). These messages are processed and committed according to the CFT protocol. %~\footnote{The attestation that takes place at the TEE setup ($\S$~\ref{subsec:attestation}) ensures that only trusted nodes are capable of generating valid messages.}

\noindent{\underline{Authentication layer}}: For the authentication, we use cryptographic primitives (e.g., MAC and encryption functions when \projecttitle{} aims for confidentiality) to verify the integrity and the authenticity of the messages. Each message $m$ sent from a node $n_i$ to a node $n_j$ over a communication channel cq is accompanied by metadata (e.g., cnt$_{cq}$, view, sender and receiver nodes id) and the calculated message authentication code (MAC) $h_{cq}_{\sigma}_q$. The MAC is calculated over the payload and the metadata, then follows the message $m$. The sender node calls into the shield\_request(req, cq) and generates such a trusted message for the request req. %The trusted message is of the form [(req, (ReplicaView, cq, cnt\_{cq})), ${h_{cq}_{\sigma_{cq}})}$$>$.% containing the encrypted metadata and hash of the $req$ and the $req$ payload. %This function will marshal the current value of its trusted monotonic counter, the current view number, and the (cryptographic) hash of the message into one string. 

%\myparagraph{Non-equivocation} \projecttitle{} limits the equivocation of Byzantine (malicious) faults in the networking infrastructure using TEEs. Specifically, we guarantee non-equivocation via trusted counter assignment and verification. Each replica maintains a local sequence tuple $(v, cq, seq)$ where $v$ is the current view number, $cq$ is the communication (pair) channel between two nodes and $seq$ is the
%current trusted counter value in that view for the latest committed request sent in that communication channel. Each request is assigned a unique tuple $(v, cq, seq)$ which is maintained by the TEE of each replica to guarantee monotonic increments and rollback/forking attacks resilience. The coordinator node of a request assigns the request with the correct tuple and increments the $seq$.  Once a replica receives a request, they only accept it after its verification. The accepted requests pass through the underlying CFT protocol. Replicas verify the received requests using the \texttt{VerifyCounter}$(<req, (v, cq, seq)>, {h_{cq}})$ function. Specifically, the replica verifies the freshness of the message/request by examining its counter id. The message passes through the non-equivocation layer to verify that the counter associated with the received request (as part of the message metadata) is consistent with its local counter. Replicas in \projecttitle{} are willing to accept ``future'' valid messages as these might come out of order, i.e., messages whose seq number is $> (seq'_{cq}+1)$ ($seq'_{cq}$ is the last seen request number from that communication channel). Such messages are valid so \projecttitle{} accepts them. However, they are processed and committed when the underlying CFT protocol allows that.

%\dimitra{fix this}
%\myparagraph{Integrity verification} In \projecttitle{} we leverage basic primitives in modern cryptography such as hash functions to check and verify the integrity of the data the might reside in the untrusted areas including, the host memory and the network infrastructure. Each message $m$ sent from $n_i$ to $n_j$ over a communication channel $cq$ is accompanied by its calculated hash $h_{cq}$ that allows the recipient $n_j$ to verify that the message payload is genuine. A node that drives the client's request (coordinator) before sending the request to replicas need to call \texttt{ShieldRequest}$(req, cq)$ to generate an integrity-protected message for that request. This function will marshal the current value of its trusted monotonic counter, the current view number, and the (cryptographic) hash of the message into one string. The output is a bytestream of the form $<req, (\texttt{(ReplicaView}, cq, cnt_{cq})>, {h_{cq})}$ containing the metadata, the request payload and the computed hash of metadata and payload.

\if 0
\myparagraph{API} We offer a create\_rpc() function that creates a bound-to-the-NIC RPCobj. The function takes as an argument the application context, i.e., NIC specification and port, remote IP and port, creates a communication endpoint and establishes connection with the remote side. The function returns after the connection establishment. RPCobjs offer bidirectional communication between the two sides. Prior to the creation of RPCobj, developers need to specify and register the request types and handlers using the reg\_hdlr() which takes as an argument a reference to the preferred handler function. %The developer might to overwrite/implement the \texttt{init\_store()} function which will keep an application's state and metadata in the trusted enclave. By default \projecttitle{} comes with a thread-safe and lock-free hybrid skiplist based on~\cite{avocado, folly}. While implementing our use cases in $\$$~\ref{sec:eval}, we used two  \projecttitle{} skiplists for metadata and data accordingly.  %Lastly, we need to register the request handler functions to the \texttt{rpc}s, i.e., pass a pointer function a the construction of the endpoint which states what will happen when a request of a specific type is received.

For exchanging network messages, we designed a send() function which takes as arguments the session (connection) identifier, the message buffer to be sent, the request type and the cleanup function. This function submits a message for transmission. Upon a reception of a request, the program control passes to the registered request handler where the function respond() can submit a response or ACK to that request. Lastly, the function poll() needs to be called regularly to fetch or transmit the network messages in the TX and RX queues.




\fi 
\begin{comment}
~\footnote{DMA mappings are prohibited in the trusted area of a TEE as this violates TEE's security properties~\cite{intel-sgx, avocado, treaty}}
\end{comment}

\if 0
\myparagraph{Implementation details}
We designed \projecttitle{}'s high performance RPCs by extending eRPC~\cite{erpc} in the context of TEEs. We place the message buffers outside the enclave to overcome the limited enclave memory and enable DMA operations~\cite{intel-sgx, avocado, treaty}. The message buffers are allocated in Hugepage area and are later copied or mapped to the TX/RX queues. The networking buffers residing outside the TEE follow the trusted message format we discussed in \ref{subsec:overview}. As such, while outside the trusted area, their integrity (or confidentiality) can be verified upon reception.

We also adopted a rate limiter which can be configured to limit read and/or write requests. The use of a rate limiter was found to be useful in protocols which vastly saturated the available host memory (we found out that the R-ABD protocol was quickly exhausting all available memory in the system while the tail-node in the R-CR protocol also ran out-of-memory for read-heavy workloads). Lastly, we implement on top of \projecttitle{}'s network library a batching technique which queues the message buffers and merges them into a bigger buffer before transmission. The batching factor is configurable and has been proven extremely efficient for small messages (e.g., \SI{256}{\byte}).

\fi 


\myparagraph{Secure runtime} We build our codebase in C++ using \scone{} to access the TEE hardware. \scone{} exposes a modified libc library and combines user-level threading and asynchronous syscalls~\cite{flexsc} to reduce the cost of syscall execution. While we limit the number of syscalls, leveraging  \scone{}'s exit-less approach allows us to optimize the initialization phase that vastly allocates host memory for the network stack and the KV store. To enable NIC's DMA operations and memory mappings to the hugepages (for message buffers and TX/RX queues) ($\S$~\ref{subsec:networkin}), we overwrite the \texttt{mmap()} syscall of \scone{} to bypass its shield layer and allow the allocation of (untrusted) host memory. 

%For the cryptographic primitives, we build on OpenSSL~\cite{openssl}. Lastly, we build on a lease mechanism~\cite{t-lease} in \scone{} for auxiliary operations, e.g., failures detection and leader's election.

\if 0
\begin{algorithm}
\SetAlgoLined
%\fontsize
\small
%\fontsize{9}{10}\selectfont 

%\texttt{$seq'_{cq}$ the last committed sequence for that cq} \\

$\triangleright$ cnt$_{cq}$: the latest sent message id from  cq\\$\triangleright$ rcnt$_{cq}$: the last committed message id from cq


%\vspace{0.1cm}

\textbf{function} shield\_request(req, cq) \{ \\
\Indp
cnt$_{cq}$ $\leftarrow$ cnt$_{cq}$+1; t$\leftarrow$ (view, cq, cnt$_{cq}$);\\
$[$$h_{\sigma_{cq}}$, (req,t)$]$  $\leftarrow$ singed\_hash(req, t);\\
\textbf{return} $[$$h_{\sigma_{cq}}$, (req,t)$]$;\\
\Indm
\} \\



%\vspace{0.1cm}
\textbf{function} verify\_request($h_{\sigma_{cq}}$, req, (view, cq, cnt$_{cq}$)) \{ \\
\Indp
    \textbf{if} verify\_signature($h_{\sigma_{cq}}$, req, (view, cq, cnt$_{cq}$)) == True \textbf{then}\\
    \Indp
        \textbf{if} view == current\_view \textbf{then}\\
        \Indp
            \textbf{if} cnt$_{cq}$ <= rcnt$_{cq}$ \textbf{then}\\
            \Indp
                \textbf{return} [False, req, (view, cq, cnt$_{cq}$)]; \\
            \Indm
            \textbf{if} cnt$_{cq}$ == rcnt$_{cq}$+1) \textbf{then} rcnt$_{cq}$ $\leftarrow$ rcnt$_{cq}$+1;
            buffer\_locally(req, (view, cq, cnt$_{cq}$));\\
                \textbf{return} [True, req, (view, cq, cnt$_{cq}$)]; \\
            
        \Indm
    \Indm
    \textbf{return} [False, req, (view, cq, cnt$_{cq}$)]; \\

\Indm
\} \\
%\vspace{0.1cm}
\vspace{-1pt}
\caption{\projecttitle{}'s authentication primitives.}
\vspace{-3pt}
\label{algo:primitives}
\end{algorithm}

\fi


\myparagraph{\projecttitle{} key-value store}
\label{subsec:KV}
\projecttitle{} provides a lock-free, high-performant KV store based on a skip-list. We partition the keys from the values' space by placing the keys along with metadata (and a pointer to the value in host memory) inside the TEE's memory area, the {\em enclave}, and storing the values in the host memory. %Our partitioned KVs reduce the number of calculations for integrity checks, compared to prior work~\cite{shieldstore}, which implements (per-bucket) Merkle trees and re-calculates the root on each update. Importantly, separating the (keys + metadata) and the values between the enclave and untrusted unlimited memory decreases the Enclave Page Cache (EPC) pressure~\cite{speicher-fast}. %Our lock-free data structure supports concurrent operations and it is well-suited
%for increased parallelism.
\projecttitle{}'s KV store design resolves Byzantine errors since the metadata (and the code that accesses them) reside in the enclave. That said, \projecttitle{} allows for local reads as nodes can verify the integrity of the stored values.

\if 0
\myparagraph{Implementation and API} The developer might want to overwrite/implement the init\_store() function which will keep an application's state and metadata in the trusted enclave. \projecttitle{} implements its hybrid skiplist based on folly library~\cite{folly}. The write() function updates the KV while the get() function copies the value of the given key in the protected area. The function also verifies the value's integrity. We implement an allocator for host memory that is given as an initialization parameter to the KV store.

\fi 
%\myparagraph{Data properties}
 %Our partitioned scheme {\em seamlessly} strengthens the system's security properties further and can offer confidentiality by encrypting the values outside the TEE. \projecttitle{}-transformed protocols that further offer confidentiality outperform the BFT systems ($\S$~\ref{sec:eval}).


%that offers parallel write and read operations, however the developer might wish to overwrite those functions. Both operations calculate the hash of the given data which is placed in the enclave memory. The hash is used to verify the integrity of the data stored in the host memory (if any).




\myparagraph{Attestation and secrets distribution}~\label{subsec:attestation}
Remote attestation is the building block to verify the authenticity of a TEE, i.e., the code and the TEE state are the expected~\cite{Parno2010}. As such, \projecttitle{} provides attest(), generate\_quote() and remote\_attestation() primitives  that allow replicas to prove their trustworthiness to other replicas or clients. The attestation takes place before the control passes to the protocol's code. Only successfully attested nodes get access to secrets (e.g., signing or encryption keys, etc.) and configurations. 

%Essentially, \projecttitle{} needs to \emph{(1)} offer low-latency attestation of the joiner nodes (for fast recovery) and \emph{(2)} securely distribute the secrets and configuration data. \projecttitle{}'s attestation shields against Sybil attacks~\cite{sybilAttack}.

\if 0
\begin{algorithm}
\SetAlgoLined
%\fontsize
\small
%\fontsize{9}{10}\selectfont 

\textbf{function} remote\_attestation() \{ \\
 \Indp
 nonce $\leftarrow$ generate\_nonce();\\
 \textbf{send}(nonce, k$_{pub}$); \textbf{DHKE}(); quote$_{\sigma_{k_{pub}}}$ $\leftarrow$ \textbf{recv}();\\
 \textbf{if} verify\_signature(quote$_{\sigma_{k_{pub}}}$) == True \textbf{then}\\
    \Indp
        $\mu_{TEE}$ $\leftarrow$ decrypt(quote$_{\sigma_{k_{pub}}}$, k$_{priv}$);\\
        \textbf{if} (verify\_quote$(\mu_{TEE})$ == True) send\_secrets();\\
    \Indm
 \Indm
\} \\


%\vspace{0.1cm}
\textbf{function} attest() \{ \\
\Indp
    $\mu$ $\leftarrow$ gen\_enclave\_report(); \textbf{return} $\mu$;\\ 
\Indm
\} \\

%\vspace{0.1cm}
\textbf{function} generate\_quote($\mu$, k$_{pub}$) \{ \\
\Indp
    key$_{hw}$ $\leftarrow$ EGETKEY();\\
    quote $\leftarrow$ sign($\mu$, key$_{hw}$); 
    quote$_{\sigma_{k_{pub}}}$ $\leftarrow$ sign(quote, k$_{pub}$);\\
    \textbf{return } quote$_{\sigma_{k_{pub}}}$;\\
\Indm
\} \\
\caption{\projecttitle{}'s attestation primitive.}
\label{algo:attestation}
\vspace{-3pt}
\end{algorithm}
\fi 

%\vspace{-8pt}



%\myparagraph{Attestation design} 

%The application and the challenger first establish communication and, then, the application asks the challenger to provision secrets. 
The attestation process is initialized by the \emph{challenger}, a remote process that can verify the authenticity of a specific TEE. The challenger executes the remote\_attestation() function to send an attestation request to the application---usually in the form a nonce (a random number). The challenger and the application, then, pass through a Diffie-Hellman key exchange process~\cite{10.1145/359460.359473}. The application generates an ephemeral public key which is used by the challenger later to provision any secrets.

%When the TEE receives the nonce, it calls the attest() and generates a \emph{measurement} ($\mu$) of its state and loaded code. Following this, the TEE calls into the generate\_quote$(\mu, k_{pub})$ to sign $\mu$ (quote) with the $key_{hw}$ which is fetched from the TEE's h/w. The TEE signs and encrypts the quote quote$_{\sigma_{k_{pub}}}$ over the challenger's public key $k_{pub}$ which is, then, sent back to the challenger. Upon successful verifications of the quote$_{\sigma_{k_{pub}}}$, the challenger shares secrets and configurations.

%To offer low-latency attestations within the same datacenter that \projecttitle{} runs, we build a Configuration and Attestation service (CAS). The Protocol Designer (PD) deploys the CAS inside a TEE and attests it through the hardware vendor's attestation service---e.g., Intel Attestation Service (IAS~\cite{ias}). Once the CAS is attested, it is trusted and the PB can upload secrets and configurations. 

%The challenger asserts upon a failed verification and denies to share any secret or configuration data. Otherwise, it distributes all necessary shared secrets.

\if 0 
\myparagraph{Implementation details} 
%\projecttitle{} builds on top of a Configuration and Attestation Service (CAS) that is shipped with \scone{} and ultimately relies on hardware-based TEEs for secure secrets and configuration management. 
A trusted entity, i.e., the developer, must deploy the  Configuration and Attestation Service  CAS inside a TEE in a node that can also be part of the membership. Afterward, they need to attest the CAS through the TEE's attestation service---in our case, Intel Attestation Service (IAS~\cite{ias}). Once the CAS is attested, it can replace the TEE's attestation service. The trusted entity needs to spawn further Local Attestation Services (LASes) that perform local (intra-platform) attestation of processes and offer low-latency attestation of the new nodes. Before the CFT protocol commences, the CAS must also attest all LASes. 

When a \projecttitle{} process is loaded in the TEE (before the control passes to the application code), the LAS instructs a local attestation. The attestee generates a quote of the enclave (measurement). The LAS forwards the enclave's measurement to the CAS, which replies with a success or failure message indicating the authenticity of the process. After a successful attestation, the CAS stores the node's IP and provides the trusted process with secrets and configurations.

\myparagraph{API}
\projecttitle{} provides an attestation API to developers. Particularly, we provide the attest function that takes as arguments the IP of a trusted third-party service, CAS's IP for \projecttitle{}, and a generated enclave measurement of the code. Then, this service verifies that both the enclave signer and measurement are in the expected state and replies accordingly.
\fi 
%\dimitra{fix this}
%\myparagraph{Attestation and secrets management} Attestation is the process of demonstrating that the correct software is securely running within a TEE-enclave on an enabled platform. Secrets (e.g., certificates, encryption keys, etc.) and configurations (membership IPs and information) should only be provided to a replica after its successful attestation. Once an enclave is initialized and before the control is relinquished to the application's code, the attestation process is launched to verify the integrity and authenticity of the included code and data. Essentially, \projecttitle{} needs to (1.) offer low-latency attestation of the joiner nodes and (2.) securely provide the trusted enclave applications with secrets and configuration data (usually over the network).

%\projecttitle{} leverages TEEs to implement \texttt{RemoteAttestation}$()$, \texttt{Attest}$()$ and \texttt{GenerateQuote}$()$ primitives that allow a third party to attest an enclave. Next we describe the workflow of the attestation and the properties of those primitives.

%The attestation process is initialized by the challenger (or verifier)---a remote process (typically provided by the hardware vendor) that can prove the authenticity of a specific enclave. The application and the challenger first establish communication and, then, the application asks the challenger to provision secrets. The challenger executes the \texttt{RemoteAttestation}$()$ function where it first replies with an attestation request to the application---usually in the form a nonce (a random number
%generated for this one occasion). The challenger and the application also pass through a Diffie-Hellman key exchange (DHKE) process. The application generates an ephemeral public key which is used by the challenger later for provisioning secrets to the enclave.

%After receiving the nonce, the enclave calls into the \texttt{Attest}$()$ and generates a \emph{measurement} or \emph{report} that includes information about the enclave. The report needs to be sent to the challenger for verification. The enclave calls into \texttt{GenerateQuote$(\mu, k_{public})$} which sings the measurement $\mu$ over $key_{hw}$, where $key_{hw}$ is fetched from the TEE's hardware. Additionally, the function encrypts the quote over challenger's public key $k_{public}$. The encrypted quote can be sent and verified by the challenger with the corresponding verification key.

%The challenger asserts upon a failed verification and denies to share any secret or configuration data. Otherwise, it distributes all necessary shared secrets.

\if 0

\subsection{\projecttitle{} API}

\if 0
\subsection{\projecttitle{} client API}
\projecttitle{} exposes a simple \texttt{PUT}/\texttt{GET} API to clients. Both functions take as arguments the coordinator node's id, the view and the leader identifier (if any) that are known to the client. The API assigns a unique monotonically increased id to every request executed by the client. That is to help CFT distinguish already executed requests.
\fi

%\subsection{\projecttitle{} system-level API}
Table~\ref{tab:api} presents the core library that \projecttitle{} exposes to the developers. We implement our \projecttitle{} on top of \scone~\cite{arnautov2016scone} and \textsc{Palaemon}~\cite{palaemon} that use Intel SGX~\cite{intel-sgx} as the TEE and we extend eRPC~\cite{erpc} on top of DPDK~\cite{dpdk} for fast networking. Next we discuss the use-cases and the implementation details for each core function of \projecttitle{}.

\myparagraph{Attestation API} 

\myparagraph{Initialization API} Developers need to initialize the protocol by creating the communication endpoints between replicas. \projecttitle{} offers a \texttt{create\_rpc()} function that creates Remote Procedure Call (RPC) objects (rpc) bound to the NIC. Specifically this function takes the application context as an argument, i.e., node's NIC specification and port, remote IP and port, creates a communication endpoint and continuously tries to establish connection with the remote side. The function returns after the connection establishment. An rpc offers bidirectional communication between the two sides. Additionally, we need to register the request handler functions to the rpcs, i.e., pass a pointer function a the construction of the endpoint which states what will happen when a request of a specific type is received. The developer might to overwrite/implement the \texttt{init\_store()} function which will keep an application's state and metadata in the trusted enclave. By default \projecttitle{} comes with a thread-safe and lock-free hybrid skiplist based on~\cite{avocado, folly}. While implementing our use cases in $\$$~\ref{sec:eval}, we used two  \projecttitle{} skiplists for metadata and data accordingly.  %Lastly, we need to register the request handler functions to the \texttt{rpc}s, i.e., pass a pointer function a the construction of the endpoint which states what will happen when a request of a specific type is received.

\myparagraph{Network API} \projecttitle{} offers high performance RPCs by extending eRPC~\cite{erpc} in the context of TEEs. Specifically, we place the message buffers outside the trusted enclave to both overcome the limited enclave memory and enable DMA operations~\footnote{DMA mappings are prohibited in the trusted area of a TEE as this violates their security properties~\cite{intel-sgx}}. We design a \texttt{send()} operation is used to submit a message for transmission. The message buffer is allocated by our library in \texttt{Hugepage} memory area and is later copied to the transmission queue (TX). Further, we provide a \texttt{multicast()} operation which creates identical copies of a message for all the recipient group.    Upon a reception of a request, the program control passes to the registered request handler where the function \texttt{respond()} can submit a response or \texttt{ACK} to that request. Lastly, the function \texttt{poll()} needs to be called regularly to fetch and process and send the incoming responses or requests and send the queued responses and requests respectively. 

\myparagraph{KV Store API} 

\dimitra{
\myparagraph{Trusted Leases API} \projecttitle{} exposes an API for leases to guarantee linearizable local reads when the CFT protocol allows that. A thread on a node initializes a lease (\texttt{init\_lease()}) and afterwards can exec a function within the lease's ownership (\texttt{exec\_with\_lease()}). In case the lease has expired, the function is not executed. The protocol updates the expiration date of a current lease with the \texttt{renew\_lease()}. The lease granter node/service updates its lease table with the \texttt{grand\_or\_update\_lease()} function.
}
\fi


\fi



%\section{\projecttitle Library}
%\label{sec:abstraction}
%\label{sec:recipe-implementation}
%\dimitra{system level design details here and the low-level API!}


%This section describes four core components of \projecttitle{}. .%  (a) networking library, (b) KV store, (c) secure runtime, and (d) attestation and configuration management.


%(\projecttitle{}-lib): \emph{(i)} the shielded networking library which leverages direct I/O while also preventing Byzantine behaviors in the untrusted network infrastructure, \emph{(ii)} the KV store which guarantees trust to local reads and, \emph{(iii)} the attestation and secrets distribution service which ensures that only trusted nodes know the configuration, keys, etc.


%\pramod{fix missing citations and a lot of typos and grammar errors.}

\subsection{\projecttitle Implementation and APIs}
\label{sec:recipe_impl_apis}
\label{subsec:networkin}
\label{subsec:KV}
\label{subsec:attestation}
\label{non-equivocation-design}

Table~\ref{tab:api} summarizes the \projecttitle{}'s API for each system component.

\myparagraph{\projecttitle{} networking} \projecttitle{} adopts the Remote Procedure Call (RPC) paradigm~\cite{286500} over a generic network library with various transportation layers (Infiniband, RoCE, and DPDK), which is also favorable in the context of TEEs where traditional kernel-based networking is impractical~\cite{kuvaiskii2017sgxbounds}. %Below, we explain how the networking layer is initialized in \projecttitle{}, the requests workflow and the core implementation details.



\begin{table}[t]
\small
%\fontsize{7}{10}\selectfont 

\begin{center}
\begin{tabular}{ |c|c| }
 \hline
 \bf{Attestation API} &  \\ \hline
 \multirow{1}{*}{\texttt{attest(measurement)}} & Attests the node based on  a measurement.  \\  \hline \hline
 \bf{Initialization API} &  \\ \hline
 \texttt{create\_rpc(app\_ctx)} & Initializes an RPCobj. \\
  \texttt{init\_store()} & Initializes the KV store. \\
  \texttt{reg\_hdlr(\&func)} & Registers request handlers. \\ \hline \hline
 \bf{Network API} &  \\ \hline
 \texttt{send(\&msg\_buf)} & Prepares a req for transmission. \\
 %\hline
% \texttt{multicast(\&msg\_buf, nodes)} & Prepares a request for multicast. \\
 \multirow{1}{*}{\texttt{respond(\&msg\_buf)}} & Prepares a resp for transmission. \\
 \texttt{poll()} & Polls for incoming messages. \\\hline \hline
% \texttt{aggregates\_multicast()} &  \\ 
 \bf{Security API} &  \\ \hline
 \texttt{verify\_msg(\&msg\_buf)} & Verifies the authenticity/integrity and cnt of a msg. \\
 \texttt{shield\_msg(\&msg\_buf)} & Generates a shielded msg. \\ \hline \hline
% \texttt{aggregates\_multicast()} &  \\ 
 \bf{KV Store API} &  \\ \hline
 \texttt{write(key, value)} & Writes a KV to the store. \\
 \hline
 \multirow{2}{*}{\texttt{get(key, \&v$_{TEE}$)}} & Reads the value into \texttt{v$_{TEE}$} \\ & and verifies integrity. \\ \hline %\hline
 \if 0
 \bf{Trusted Leases API} &  \\ \hline
 \texttt{init\_lease(node\_id, thread\_id)} & Requests a lease from the grander.\\ \hline
 \texttt{renew\_lease(\&lease)} & Updates a lease.\\ \hline
 \texttt{grand\_or\_update\_lease(node\_id, thread\_id)} & Grands a lease.\\ \hline
 \texttt{exec\_with\_lease(\&lease, \&func, \&args\_list)} & Executes the func within the lease ownership.\\ [1ex] \hline
 \fi
\end{tabular}
\end{center}
%\vspace{-10pt}
\caption{\projecttitle{} library APIs.} \label{tab:api}
\vspace{-6pt}
\end{table}





\if 0

Developer effort â€“ initialization. The developer must spec-
ify the number and the nature of the logical message flows
they require. In RDMA parlance each flow corresponds to
one queue pair (QP), i.e., a send and a receive queue. For
instance, consider Hermes where a write requires two broad-
cast rounds: invalidations (invs) and validations (vals). Each
worker in each node sets up three QPs: 1) to send and re-
ceive invs, 2) to send and receive acks (for the invs) and 3) to
send and receive vals. Splitting the communication in mes-
sage flows is the responsibility of the developer. To create
the QP for each message flow, the developer simply calls a
Odyssey function, passing details about the nature of the QP.

\fi





\noindent\underline{Initialization.} Prior to the application's execution, developers need to initialize the networking layer by specifying the number of concurrent available connections, the types of the available requests, and by registering the appropriate (custom) request handlers. In \projecttitle{} terms, a communication endpoint corresponds to a per-thread RPC object (RPCobj) with private send/receive queues. All RPCobjs are registered to the same physical port (configurable). Initially, \projecttitle{} creates a handle to the NIC, which is passed to all RPCobjs. Developers need to define the types of RPC requests, each of which might be served by a different request handler. Request handlers are functions written by developers that are registered with the handle prior to the creation of the communication endpoints. Lastly, before executing the application's code, the connections between RPCobjs need to be correctly established.

\if 0
\projecttitle{} offers a \texttt{create\_rpc()} function that creates Remote Procedure Call (RPC) objects (rpc) bound to the NIC. Specifically, this function takes the application context as an argument, i.e., node's NIC specification and port, remote IP and port, create a communication endpoint and continuously tries to establish a connection with the remote side. The function returns after the connection establishment. An RPC offers bidirectional communication between the two sides. Additionally, we need to register the request handler functions to the rpcs, i.e., pass a pointer function to the construction of the endpoint, which states what will happen when a request of a specific type is received. The developer might overwrite/implement the \texttt{init\_store()} function, which will keep an application's state and metadata in the trusted enclave. By default \projecttitle{} comes with a thread-safe and lock-free hybrid skiplist based on~\cite{avocado, folly}. While implementing our use cases in $\$$~\ref{sec:eval}, we used two  \projecttitle{} skiplists for metadata and data accordingly.  %Lastly, we need to register the request handler functions to the \texttt{rpc}s, i.e., pass a pointer function a the construction of the endpoint which states what will happen when a request of a specific type is received.
\fi

\if 0
Developer effort â€“ send and receive. For each QP, Odys-
sey maintains a send-FIFO and a receive-FIFO. Sending re-
quires that the developer first inserts messages in the send-
FIFO via an Odyssey insert function; later they can call a send
function to trigger the sending of all inserted messages. To re-
ceive messages, the developer need only call an Odyssey func-
tion that polls the receive-FIFO. Notably, the developer can
specify and register handlers to be called when calling any
one of the Odyssey functions. Therefore, the Odyssey polling
function will deliver the incoming messages, if any, to the
developer-specified handler.
\fi





\noindent\underline{send/receive operations.} We offer asynchronous network operations following the RPC paradigm. For each RPCobj, \projecttitle{} keeps a transmission (TX) and reception (RX) queue, organized as ring buffers. Developers enqueue requests and responses to requests via \projecttitle{}'s specific functions, which place the message in the RPCobj's TX queue. Later, they can call a polling function that flushes the messages in the TX and drains the RX queues of an RPCobj. The function will trigger the sending of all queued messages and process all received requests and responses. Reception of a request triggers the execution of the request handler for that specific type. Reception of a response to a request triggers a cleanup function that releases all resources allocated for the request, e.g., message buffers and rate limiters (for congestion). %The cleanup functions can be overwritten by the developers for extra functionalities.

\if 0
\projecttitle{} offers high performance RPCs by extending eRPC~\cite{erpc} and DPDK~\cite{dpdk} in the context of TEEs. eRPC is .. Specifically, we place the message buffers outside the trusted enclave to both overcome the limited enclave memory and enable DMA operations~\footnote{DMA mappings are prohibited in the trusted area of a TEE as this violates their security properties~\cite{intel-sgx}}. We design a \texttt{send()} operation is used to submit a message for transmission. The message buffer is allocated by our library in \texttt{Hugepage} memory area and is later copied to the transmission queue (TX). Further, we provide a multicast() operation which creates identical copies of a message for all the recipient group.    Upon a reception of a request, the program control passes to the registered request handler where the function \texttt{respond()} can submit a response or \texttt{ACK} to that request. Lastly, the function \texttt{poll()} needs to be called regularly to fetch and process and send the incoming responses or requests and send the queued responses and requests respectively. 
\fi



 %The trusted message is of the form [(req, (ReplicaView, cq, cnt\_{cq})), ${h_{cq}_{\sigma_{cq}})}$$>$.% containing the encrypted metadata and hash of the $req$ and the $req$ payload. %This function will marshal the current value of its trusted monotonic counter, the current view number, and the (cryptographic) hash of the message into one string. 

%\myparagraph{Non-equivocation} \projecttitle{} limits the equivocation of Byzantine (malicious) faults in the networking infrastructure using TEEs. Specifically, we guarantee non-equivocation via trusted counter assignment and verification. Each replica maintains a local sequence tuple $(v, cq, seq)$ where $v$ is the current view number, $cq$ is the communication (pair) channel between two nodes and $seq$ is the
%current trusted counter value in that view for the latest committed request sent in that communication channel. Each request is assigned a unique tuple $(v, cq, seq)$ which is maintained by the TEE of each replica to guarantee monotonic increments and rollback/forking attacks resilience. The coordinator node of a request assigns the request with the correct tuple and increments the $seq$.  Once a replica receives a request, they only accept it after its verification. The accepted requests pass through the underlying CFT protocol. Replicas verify the received requests using the \texttt{VerifyCounter}$(<req, (v, cq, seq)>, {h_{cq}})$ function. Specifically, the replica verifies the freshness of the message/request by examining its counter id. The message passes through the non-equivocation layer to verify that the counter associated with the received request (as part of the message metadata) is consistent with its local counter. Replicas in \projecttitle{} are willing to accept ``future'' valid messages as these might come out of order, i.e., messages whose seq number is $> (seq'_{cq}+1)$ ($seq'_{cq}$ is the last seen request number from that communication channel). Such messages are valid so \projecttitle{} accepts them. However, they are processed and committed when the underlying CFT protocol allows that.

%\dimitra{fix this}
%\myparagraph{Integrity verification} In \projecttitle{} we leverage basic primitives in modern cryptography such as hash functions to check and verify the integrity of the data the might reside in the untrusted areas including, the host memory and the network infrastructure. Each message $m$ sent from $n_i$ to $n_j$ over a communication channel $cq$ is accompanied by its calculated hash $h_{cq}$ that allows the recipient $n_j$ to verify that the message payload is genuine. A node that drives the client's request (coordinator) before sending the request to replicas need to call \texttt{ShieldRequest}$(req, cq)$ to generate an integrity-protected message for that request. This function will marshal the current value of its trusted monotonic counter, the current view number, and the (cryptographic) hash of the message into one string. The output is a bytestream of the form $<req, (\texttt{(ReplicaView}, cq, cnt_{cq})>, {h_{cq})}$ containing the metadata, the request payload and the computed hash of metadata and payload.

\noindent\underline{API.} We offer a create\_rpc() function that creates a bound-to-the-NIC RPCobj. The function takes the application context, i.e., NIC specification and port, remote IP and port, as an argument, creates a communication endpoint, and establishes a connection with the remote side. The function returns after the connection establishment. RPCobjs offer bidirectional communication between the two sides. Prior to the creation of RPCobj, developers need to specify and register the request types and handlers using the reg\_hdlr() which takes as an argument a reference to the preferred handler function. %The developer might to overwrite/implement the \texttt{init\_store()} function which will keep an application's state and metadata in the trusted enclave. By default \projecttitle{} comes with a thread-safe and lock-free hybrid skiplist based on~\cite{avocado, folly}. While implementing our use cases in $\$$~\ref{sec:eval}, we used two  \projecttitle{} skiplists for metadata and data accordingly.  %Lastly, we need to register the request handler functions to the \texttt{rpc}s, i.e., pass a pointer function a the construction of the endpoint which states what will happen when a request of a specific type is received.

For exchanging network messages, we designed a send() function that takes the session (connection) identifier, the message buffer to be sent, the request type, and the cleanup function as arguments. This function submits a message for transmission. Upon reception of a request, the program control passes to the registered request handler, where the function respond() can submit a response or ACK to that request. Lastly, the function poll() needs to be called regularly to fetch or transmit the network messages in the TX and RX queues.





\begin{comment}
~\footnote{DMA mappings are prohibited in the trusted area of a TEE as this violates TEE's security properties~\cite{intel-sgx, avocado, treaty}}
\end{comment}

\if 0
\myparagraph{Implementation details}
We designed \projecttitle{}'s high-performance RPCs by extending eRPC~\cite{erpc} in the context of TEEs. We place the message buffers outside the enclave to overcome the limited enclave memory and enable DMA operations~\cite{intel-sgx, avocado, treaty}. The message buffers are allocated in Hugepage area and are later copied or mapped to the TX/RX queues. The networking buffers residing outside the TEE follow the trusted message format we discussed in \ref{subsec:overview}. As such, while outside the trusted area, their integrity (or confidentiality) can be verified upon reception.

We also adopted a rate limiter which can be configured to limit read and/or write requests. The use of a rate limiter was found to be useful in protocols which vastly saturated the available host memory (we found out that the R-ABD protocol was quickly exhausting all available memory in the system while the tail-node in the R-CR protocol also ran out-of-memory for read-heavy workloads). Lastly, we implement on top of \projecttitle{}'s network library a batching technique which queues the message buffers and merges them into a bigger buffer before transmission. The batching factor is configurable and has been proven extremely efficient for small messages (e.g., \SI{256}{\byte}).

\fi 


\myparagraph{Secure runtime} We build our codebase in C++ using \scone{} to access the TEE hardware. \scone{} exposes a modified libc library and combines user-level threading and asynchronous syscalls~\cite{flexsc} to reduce the cost of syscall execution. While we limit the number of syscalls, leveraging  \scone{}'s exit-less approach allows us to optimize the initialization phase that vastly allocates host memory for the network stack and the KV store. To enable NIC's DMA operations and memory mappings to the hugepages (for message buffers and TX/RX queues) ($\S$~\ref{subsec:networkin}), we overwrite the \texttt{mmap()} syscall of \scone{} to bypass its shield layer and allow the allocation of (untrusted) host memory. 

For the cryptographic primitives, we build on OpenSSL~\cite{openssl}. Lastly, we build on a lease mechanism~\cite{t-lease} in \scone{} for auxiliary operations, e.g., failures detection and leader's election.




\myparagraph{\projecttitle{} key-value store} \projecttitle{} provides a lock-free, high-performant KV store based on a skip-list. We partition the keys from the values' space by placing the keys along with metadata (and a pointer to the value in host memory) inside the TEE's memory area, the {\em enclave}, and storing the values in the host memory. Our partitioned KVs reduces the number of calculations for integrity checks, compared to prior work~\cite{shieldstore} which implements (per-bucket) merkle trees and re-calculates the root on each update. Importantly, separating the (keys + metadata) and the values between the enclave and untrusted unlimited memory decreases the Enclave Page Cache (EPC) pressure~\cite{speicher-fast}. %Our lock-free data structure supports concurrent operations and it is well-suited
%for increased parallelism.

The developer might want to overwrite/implement the init\_store() function, which will keep an application's state and metadata in the trusted enclave. \projecttitle{} implements its hybrid skiplist based on folly library~\cite{folly}. The write() function updates the KV, while the get() function copies the value of the given key in the protected area. The function also verifies the value's integrity. We implement an allocator for host memory that is given as an initialization parameter to the KV store.

\if 0
\myparagraph{Implementation and API} 

\fi 
%\myparagraph{Data properties}
\projecttitle{}'s KV store design resolves Byzantine errors since the metadata (and the code that accesses them) reside in the enclave. That said, \projecttitle{} allows for local reads as nodes can verify the integrity of the stored values. Our partitioned scheme {\em seamlessly} strengthens the system's security properties further and can offer confidentiality by encrypting the values outside the TEE. \projecttitle{}-transformed protocols that further offer confidentiality outperform the BFT systems ($
\S$~\ref{sec:eval}).


%that offers parallel write and read operations, however the developer might wish to overwrite those functions. Both operations calculate the hash of the given data which is placed in the enclave memory. The hash is used to verify the integrity of the data stored in the host memory (if any).





%\vspace{-8pt}
%The application and the challenger first establish communication, and then the application asks the challenger to provide secrets.


\myparagraph{Attestation process} The attestation process is initialized by the \emph{challenger}, a remote process that can verify the authenticity of a specific TEE. The challenger executes the remote\_attestation() function to send an attestation request to the application---usually in the form of a nonce (a random number). The challenger and the application then pass through a Diffie-Hellman key exchange process~\cite{10.1145/359460.359473}. The application generates an ephemeral public key which is used by the challenger later to provision any secrets.

When the TEE receives the nonce, it calls the attest() and generates a \emph{measurement} ($\mu$) of its state and loaded code. Following this, the TEE calls into the generate\_quote$(\mu, k_{pub})$ to sign $\mu$ (quote) with the $key_{hw}$ which is fetched from the TEE's h/w. The TEE signs and encrypts the quote quote$_{\sigma_{k_{pub}}}$ over the challenger's public key $k_{pub}$, which is then sent back to the challenger. Upon successful verifications of the quote$_{\sigma_{k_{pub}}}$, the challenger shares secrets and configurations.

To offer low-latency attestations within the same datacenter that \projecttitle{} runs, we build a Configuration and Attestation service (CAS). The Protocol Designer (PD) deploys the CAS inside a TEE and attests it through the hardware vendor's attestation service---e.g., Intel Attestation Service (IAS~\cite{ias}). Once the CAS is attested, it is trusted, and the PB can upload secrets and configurations. 

The challenger asserts upon a failed verification and denies sharing any secret or configuration data. Otherwise, it distributes all necessary shared secrets.

\if 0 
\myparagraph{Implementation details} 
%\projecttitle{} builds on top of a Configuration and Attestation Service (CAS) that is shipped with \scone{} and ultimately relies on hardware-based TEEs for secure secrets and configuration management. 
A trusted entity, i.e., the developer, must deploy the  Configuration and Attestation Service  CAS inside a TEE in a node that can also be part of the membership. Afterward, they need to attest the CAS through the TEE's attestation service---in our case, Intel Attestation Service (IAS~\cite{ias}). Once the CAS is attested, it can replace the TEE's attestation service. The trusted entity needs to spawn further Local Attestation Services (LASes) that perform local (intra-platform) attestation of processes and offer low-latency attestation of the new nodes. Before the CFT protocol commences, the CAS must also attest all LASes. 

When a \projecttitle{} process is loaded in the TEE (before the control passes to the application code), the LAS instructs a local attestation. The attestee generates a quote of the enclave (measurement). The LAS forwards the enclave's measurement to the CAS, which replies with a success or failure message indicating the authenticity of the process. After a successful attestation, the CAS stores the node's IP and provides the trusted process with secrets and configurations.

\myparagraph{API}
\projecttitle{} provides an attestation API to developers. Particularly, we provide the attest function that takes as arguments the IP of a trusted third-party service, CAS's IP for \projecttitle{}, and a generated enclave measurement of the code. Then, this service verifies that both the enclave signer and measurement are in the expected state and replies accordingly.
\fi 
%\dimitra{fix this}
%\myparagraph{Attestation and secrets management} Attestation is the process of demonstrating that the correct software is securely running within a TEE-enclave on an enabled platform. Secrets (e.g., certificates, encryption keys, etc.) and configurations (membership IPs and information) should only be provided to a replica after its successful attestation. Once an enclave is initialized and before the control is relinquished to the application's code, the attestation process is launched to verify the integrity and authenticity of the included code and data. Essentially, \projecttitle{} needs to (1.) offer low-latency attestation of the joiner nodes and (2.) securely provide the trusted enclave applications with secrets and configuration data (usually over the network).

%\projecttitle{} leverages TEEs to implement \texttt{RemoteAttestation}$()$, \texttt{Attest}$()$ and \texttt{GenerateQuote}$()$ primitives that allow a third party to attest an enclave. Next we describe the workflow of the attestation and the properties of those primitives.

%The attestation process is initialized by the challenger (or verifier)---a remote process (typically provided by the hardware vendor) that can prove the authenticity of a specific enclave. The application and the challenger first establish communication and, then, the application asks the challenger to provision secrets. The challenger executes the \texttt{RemoteAttestation}$()$ function where it first replies with an attestation request to the application---usually in the form a nonce (a random number
%generated for this one occasion). The challenger and the application also pass through a Diffie-Hellman key exchange (DHKE) process. The application generates an ephemeral public key which is used by the challenger later for provisioning secrets to the enclave.

%After receiving the nonce, the enclave calls into the \texttt{Attest}$()$ and generates a \emph{measurement} or \emph{report} that includes information about the enclave. The report needs to be sent to the challenger for verification. The enclave calls into \texttt{GenerateQuote$(\mu, k_{public})$} which sings the measurement $\mu$ over $key_{hw}$, where $key_{hw}$ is fetched from the TEE's hardware. Additionally, the function encrypts the quote over challenger's public key $k_{public}$. The encrypted quote can be sent and verified by the challenger with the corresponding verification key.

%The challenger asserts upon a failed verification and denies to share any secret or configuration data. Otherwise, it distributes all necessary shared secrets.

\if 0

\subsection{\projecttitle{} API}

\if 0
\subsection{\projecttitle{} client API}
\projecttitle{} exposes a simple \texttt{PUT}/\texttt{GET} API to clients. Both functions take as arguments the coordinator node's id, the view and the leader identifier (if any) that are known to the client. The API assigns a unique monotonically increased id to every request executed by the client. That is to help CFT distinguish already executed requests.
\fi

%\subsection{\projecttitle{} system-level API}
Table~\ref{tab:api} presents the core library that \projecttitle{} exposes to the developers. We implement our \projecttitle{} on top of \scone~\cite{arnautov2016scone} and \textsc{Palaemon}~\cite{palaemon} that use Intel SGX~\cite{intel-sgx} as the TEE and we extend eRPC~\cite{erpc} on top of DPDK~\cite{dpdk} for fast networking. Next we discuss the use-cases and the implementation details for each core function of \projecttitle{}.

\myparagraph{Attestation API} 

\myparagraph{Initialization API} Developers need to initialize the protocol by creating the communication endpoints between replicas. \projecttitle{} offers a \texttt{create\_rpc()} function that creates Remote Procedure Call (RPC) objects (rpc) bound to the NIC. Specifically this function takes the application context as an argument, i.e., node's NIC specification and port, remote IP and port, creates a communication endpoint and continuously tries to establish connection with the remote side. The function returns after the connection establishment. An rpc offers bidirectional communication between the two sides. Additionally, we need to register the request handler functions to the rpcs, i.e., pass a pointer function a the construction of the endpoint which states what will happen when a request of a specific type is received. The developer might to overwrite/implement the \texttt{init\_store()} function which will keep an application's state and metadata in the trusted enclave. By default \projecttitle{} comes with a thread-safe and lock-free hybrid skiplist based on~\cite{avocado, folly}. While implementing our use cases in $\$$~\ref{sec:eval}, we used two  \projecttitle{} skiplists for metadata and data accordingly.  %Lastly, we need to register the request handler functions to the \texttt{rpc}s, i.e., pass a pointer function a the construction of the endpoint which states what will happen when a request of a specific type is received.

\myparagraph{Network API} \projecttitle{} offers high performance RPCs by extending eRPC~\cite{erpc} in the context of TEEs. Specifically, we place the message buffers outside the trusted enclave to both overcome the limited enclave memory and enable DMA operations~\footnote{DMA mappings are prohibited in the trusted area of a TEE as this violates their security properties~\cite{intel-sgx}}. We design a \texttt{send()} operation is used to submit a message for transmission. The message buffer is allocated by our library in \texttt{Hugepage} memory area and is later copied to the transmission queue (TX). Further, we provide a \texttt{multicast()} operation which creates identical copies of a message for all the recipient group.    Upon a reception of a request, the program control passes to the registered request handler where the function \texttt{respond()} can submit a response or \texttt{ACK} to that request. Lastly, the function \texttt{poll()} needs to be called regularly to fetch and process and send the incoming responses or requests and send the queued responses and requests respectively. 

\myparagraph{KV Store API} 

\dimitra{
\myparagraph{Trusted Leases API} \projecttitle{} exposes an API for leases to guarantee linearizable local reads when the CFT protocol allows that. A thread on a node initializes a lease (\texttt{init\_lease()}) and afterwards can exec a function within the lease's ownership (\texttt{exec\_with\_lease()}). In case the lease has expired, the function is not executed. The protocol updates the expiration date of a current lease with the \texttt{renew\_lease()}. The lease granter node/service updates its lease table with the \texttt{grand\_or\_update\_lease()} function.
}
\fi
