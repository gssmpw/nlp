\section{\projecttitle{} Protocol}
\label{sec:recipe-protocol}

We first describe the system model. Next, we define the primitives of \emph{non-equivocation and authentication} as well as \emph{attestation} that we use to build our \projecttitle{} protocol. Based on these foundations, we present the \projecttitle{} protocol.

\input{system_model}




\subsection{\projecttitle{} Primitives}
\myparagraph{Non-equivocation and authentication primitives} \projecttitle{}'s embodies a non-equivocation and an authentication layer through two TEE-assisted primitives, the shield\_request() and verify\_request(), shown in Algorithm~\ref{algo:primitives}.% (the \texttt{Attest()} primitive is used for initialization and is discussed in~$\S$~\ref{subsec:attestation}). We now explain the mechanisms, correctness arguments are presented in $\S$~\ref{sec:theory}.


\begin{algorithm}[t]
\SetAlgoLined
%\fontsize
\small
%\fontsize{9}{10}\selectfont 

%\texttt{$seq'_{cq}$ the last committed sequence for that cq} \\

$\triangleright$ cnt$_{cq}$: the latest sent message id from  cq\\$\triangleright$ rcnt$_{cq}$: the last committed message id from cq


%\vspace{0.1cm}

\textbf{function} shield\_request(req, cq) \{ \\
\Indp
cnt$_{cq}$ $\leftarrow$ cnt$_{cq}$+1; t$\leftarrow$ (view, cq, cnt$_{cq}$);\\
$[$$h_{\sigma_{cq}}$, (req,t)$]$  $\leftarrow$ singed\_hash(req, t);\\
\textbf{return} $[$$h_{\sigma_{cq}}$, (req,t)$]$;\\
\Indm
\} \\



%\vspace{0.1cm}
\textbf{function} verify\_request($h_{\sigma_{cq}}$, req, (view, cq, cnt$_{cq}$)) \{ \\
\Indp
    \textbf{if} verify\_signature($h_{\sigma_{cq}}$, req, (view, cq, cnt$_{cq}$)) == True \textbf{then}\\
    \Indp
        \textbf{if} view == current\_view \textbf{then}\\
        \Indp
            \textbf{if} cnt$_{cq}$ <= rcnt$_{cq}$ \textbf{then}\\
            \Indp
                \textbf{return} [False, req, (view, cq, cnt$_{cq}$)]; \\
            \Indm
            \textbf{if} cnt$_{cq}$ == rcnt$_{cq}$+1 \textbf{then} rcnt$_{cq}$ $\leftarrow$ rcnt$_{cq}$+1;
            buffer\_locally(req, (view, cq, cnt$_{cq}$));\\
                \textbf{return} [True, req, (view, cq, cnt$_{cq}$)]; \\
            
        \Indm
    \Indm
    \textbf{return} [False, req, (view, cq, cnt$_{cq}$)]; \\

\Indm
\} \\
%\vspace{0.1cm}
\vspace{-1pt}
\caption{\projecttitle{}'s authentication primitives.}
\vspace{-3pt}
\label{algo:primitives}
\end{algorithm}




\noindent{Non-equivocation layer}: \projecttitle{} prevents replay attacks in the network with sequence numbers for the exchanged messages. Each replica maintains local sequence tuples $t = (view, cq, cnt_{cq})$ where $view \in \mathbb{N}$ is the current view number, $cq$ is the communication endpoint(s) between two nodes, and $cnt_{cq}$ is the current trusted counter value in that view for the latest request sent over $cq$. The sender assigns a unique tuple to messages and then increments the trusted counter to guarantee monotonicity. This guarantees monotonicity: $ \forall m_j^y, m_j^x$, if $y>x$, then $cnt_{cq}(m_j^y) > cnt_{cq}(m_j^x)$.
% and rollback/forking attacks resilience.  %the request with the correct tuple and increments the $seq$.
Replicas execute the implemented CFT protocol for verified valid requests. Replicas can verify the freshness of a message by examining its cnt$_{cq}$ (verify\_request() primitive). The primitive verifies that the message's id (as part of the metadata) is consistent with the receiver's local counter rcnt$_{cq}$ (rcnt$_{cq}$ is the last seen valid message counter for received messages in cq). \projecttitle{}'s replicas are willing to accept ``future'' valid messages as these might come out of order, i.e., $cnt_{cq} > (rcnt_{cq}+1)$. These messages are processed and committed according to the CFT protocol.% Formally, 
%$Accept(n_j,\langle req,(vew,cq,cnt_{cq})\rangle)\Longrightarrow cnt_{cq} \geq rcnt_{cq}$. 
%~\footnote{The attestation that takes place at the TEE setup ($\S$~\ref{subsec:attestation}) ensures that only trusted nodes are capable of generating valid messages.}

\myparagraph{Authentication primitive} For the authentication, we use cryptographic primitives (e.g., MAC and encryption functions when \projecttitle{} aims for confidentiality) to verify the integrity and the authenticity of the messages. Each message $m$ sent from a node $n_i$ to a node $n_j$ over a communication channel $cq$ is accompanied by metadata (e.g., $cnt_{cq}$, view, sender and receiver nodes id), and the calculated message authentication code (MAC) $h_{cq_{\sigma_q}}$. The MAC is calculated over the payload and the metadata, then follows the message $m$. Formally, $m \leftarrow \langle req, (view,cq,cnt_{cq}),h_{cq_{\sigma_q}}(req ||view || cq || cnt_{cq})) \rangle$. The sender node calls into the shield\_request(req, cq) and generates such a trusted message for the request req. On the receiver side, $Accept(ID_j,\langle req,(view,cq,cnt_{cq}),\sigma\rangle) \Longleftrightarrow Verify(h_{cq_{\sigma_q}}, req, (view || cq ||cnt_{cq})).$



\myparagraph{Attestation primitive} Remote attestation is the building block to verify the authenticity of a TEE, i.e., the code and the TEE state are the expected~\cite{Parno2010}. As such, \projecttitle{} provides attest(), generate\_quote() and remote\_attestation() primitives (Algorithm~\ref{algo:attestation}) that allow replicas to prove their trustworthiness to other replicas or clients. The attestation takes place before the control passes to the protocol's code. Only successfully attested nodes get access to secrets (e.g., signing or encryption keys, etc.) and configurations. 

%Essentially, \projecttitle{} needs to \emph{(1)} offer low-latency attestation of the joiner nodes (for fast recovery) and \emph{(2)} securely distribute the secrets and configuration data. \projecttitle{}'s attestation shields against Sybil attacks~\cite{sybilAttack}.

\begin{algorithm}[t]
\SetAlgoLined
%\fontsize
\small
%\fontsize{9}{10}\selectfont 

\textbf{function} remote\_attestation() \{ \\
 \Indp
 nonce $\leftarrow$ generate\_nonce();\\
 \textbf{send}(nonce, k$_{pub}$); \textbf{DHKE}(); quote$_{\sigma_{k_{pub}}}$ $\leftarrow$ \textbf{recv}();\\
 \textbf{if} verify\_signature(quote$_{\sigma_{k_{pub}}}$) == True \textbf{then}\\
    \Indp
        $\mu_{TEE}$ $\leftarrow$ decrypt(quote$_{\sigma_{k_{pub}}}$, k$_{priv}$);\\
        \textbf{if} (verify\_quote$(\mu_{TEE})$ == True) send\_secrets();\\
    \Indm
 \Indm
\} \\


%\vspace{0.1cm}
\textbf{function} attest() \{ \\
\Indp
    $\mu$ $\leftarrow$ gen\_enclave\_report(); \textbf{return} $\mu$;\\ 
\Indm
\} \\

%\vspace{0.1cm}
\textbf{function} generate\_quote($\mu$, k$_{pub}$) \{ \\
\Indp
    key$_{hw}$ $\leftarrow$ EGETKEY();\\
    quote $\leftarrow$ sign($\mu$, key$_{hw}$); 
    quote$_{\sigma_{k_{pub}}}$ $\leftarrow$ sign(quote, k$_{pub}$);\\
    \textbf{return } quote$_{\sigma_{k_{pub}}}$;\\
\Indm
\} \\
\caption{\projecttitle{}'s attestation primitive.}
\label{algo:attestation}
\vspace{-3pt}
\end{algorithm}






%\subsection{Protocol}
%We next describe \projecttitle{} protocol in detail.

\subsection{Clients in \projecttitle{}}
Clients in \projecttitle{} execute requests through a \texttt{PUT}/\texttt{GET} API. As discussed in $\S$~\ref{subsec:overview}, the request is forwarded to the protocol's coordinator node. Figure~\ref{fig:raft_example} shows as an example a \projecttitle{} implementation of Raft (R-Raft) including all three execution phases of a typical \projecttitle{} protocol: the transferable authentication phase (blue box), the initialization phase (green box) and the normal execution phase where the transformed CFT protocol executes clients' requests (red box). Prior to the protocol execution, nodes pass through a transferable authentication phase ($\S$~\ref{sec:attestation}) to prove that the TEEs and loaded code are genuine, followed by initialization and normal operation. 











\subsection{Normal Operation}
\label{sec:normal_operation}

We first explain the initialization and the normal execution phases, assuming all participant nodes executed the transferable authentication phase successfully.
The nodes execute the initialization phase, initializing their own local KVs \circled{B.1} and their network connections (e.g., configures NIC-memory, network ports, etc.) and establish connections with other peers \circled{B.2} based on the configuration it securely received at the attestation process \circled{A.7}. 




The leader then runs the underlying CFT protocol (in our case, Raft \circled{C.1}---\circled{C.9}) to execute the client request \circled{R.1}. Upon completion, it replies back to the client \circled{R.2}. Next, we discuss the \projecttitle{} abstraction under the normal operation. 



We use the notation [$h_{c_{\sigma_c}}$, payload] to denote an \emph{attested} or \emph{shielded}  message that is comprised of the signed hash ($h_{c_{\sigma_c}}$) of payload (\emph{certificate}) along with the raw payload data. We use the symbol $\sigma_{c}$ to denote that a piece of data is signed with a key $c$. Figure~\ref{fig:raft_example} uses the notation ($\alpha$, {kv}) for an attested message referring to a key-value pair kv with certificate $\alpha$.

%\manos{some repetition with the system model (\$3) now}

 %In leaderless protocols, coordinator nodes are selected randomly. In leader-based protocols, all non-leader replicas deny to process requests and reply back to clients with their view of the current active leader. The client then can forward the request to the active leader.


%\begin{itemize}[noitemsep]
  %\setlength\itemsep{10em}
    \noindent{}{\bf{\underline{\#1}}:} Clients send the coordinator their request of the form [$h_{c_{\sigma_c}}$, (metadata, req\_data)] \circled{R.1}. The req\_data is the request's associated data and the metadata might include among others the client's and the request's id, the leader's and term's ids (known to the client). %The request is sent over the network along with the message's calculated signed hash $h_{c}$. 
    
    %Clients send to a node (from now on the request's \emph{coordinator node} or leader), their preferred request that is of the form <$\texttt{CLIENT\_REQ(cid, lid, tid, rid, rdata)}$, $h_{c}$> where \texttt{cid} is the client id, \texttt{lid} and \texttt{tid} is the leader's and term's ids known to the client, \texttt{rid} is the request id which gets monotonically incremented per client and \texttt{rdata} is the serialized request with its arguments. The request is sent over the network along with the message's calculated signed hash $h_{c}$.
    
    \noindent{}{\bf{\underline{\#2}}:} Nodes receive and process a request after successfully verifying their integrity and authenticity. \projecttitle{}'s protocols inherit the constraints of the original CFT protocol. For instance, our R-Raft leader will drop requests with the wrong view of the term or leader.
    %Essentially, requests that have a wrong view of the term and the leader or have already been processed (their id is known to the coordinator node) are dropped.
%    \dimitra{MAKE THE PAR shorter in all paper -> make it as substeps}
    
    \noindent{}{\bf{\underline{\#3: Upon the reception of a client's request:}}}
    
    {\bf{\#3.1}} The coordinator (leader) verifies the integrity and authenticity of the message using \projecttitle{}'s authentication layer. It also verifies the metadata, e.g., the message is invalid if the term and the leader (if any) known to the client are incorrect. The leader updates the client table with the latest processed request for each client. 
    
    {\bf{\#3.2}} Next, the leader initializes the protocol for that request. In our example, the Raft leader shields the message \circled{C.1}, generating a trusted message format ($\alpha1$, {kv}) where $\alpha1$ is the certificate of {kv} and broadcasts the request to the followers \circled{C.2} (replication phase).  

\begin{figure*}
    \begin{center}
        \includegraphics[width=\textwidth]{figs/recipe_protocol_overview3.pdf}
        \vspace{-2pt}
        \caption{Example of the \projecttitle{} version of Raft (R-Raft) execution.}
        \label{fig:raft_example}
        %\vspace{-10pt}
    \end{center}
\end{figure*}

    
    {\bf{\#3.3}} The messages exchanged between replicas are of the form [$h_{r_{\sigma_{cq}}}$, (metadata, req\_data)]. The metadata includes a per-request unique tuple (view, cq, cnt$_{cq}$) that contains: (1) the view, an identifier that is optionally set by the implementation for every new leader (if any) (2) the communication channel id (cq) and (3) a sequencer id or a message counter (cnt$_{cq}$) that is assigned to the messages sent over this channel and is increased monotonically for every new message.
    %\dimitra{here: explain the counter}
    %The messages $m$ that are sent between replicas are of the form $<\texttt{CFT\_REQ(cid, lid, tid, rid, rdata), <view, cq, cnt>}$, $h_{m}>_{\sigma_{c}}$. \dimitra{here: explain the counter}
    
    \noindent{}{\bf{\underline{\#4: When a replica receives a message:}}}

    {\bf{\#4.1}} If the replica is in normal state operation, it verifies the message's validity. Else, it refuses to process the request.
    %{\bf{\#4.1}} It verifies the validity of the message. Only replicas in Normal operation mode are authorized to execute the protocol---if the replica's state differs, it refuses to process the request.% (e.g, Recovering-state replicas do not execute the read path).
    
    {\bf{\#4.2}} The replica verifies the received sequencer id (recv$_{cnt}$) to see if it is consistent with its local counter (cnt$_{cq}$). If $recv_{cnt} = (cnt_{cq}+1)$, the replica executes the request immediately, increases its local counter, acknowledges the sender node, and updates the client table. If the recv$_{cnt}$ refers to a ``future'' message (recv$_{cnt}$$>$cnt$_{cq}$+$1$), the replica queues the request in the protected area. Periodically, it applies the queued requests eligible for execution and notify coordinators accordingly.

    \noindent{}{\bf{\underline{\#5}}:} In our example, the followers verify the request \circled{C.3}, enqueue the un-committed request in a TEE buffer, and send ACKs back to the leader. The leader, upon receiving the majority of ACKs marks the request as replicated \circled{C.4} and proceeds to the second round of the protocol instructing the followers that replied to commit the update (\circled{C.5}---\circled{C.7}). At this point, each follower instructed to commit applies the request to its local KV store \circled{C.8} and ACKs the commit to the leader. Similarly to the replication phase, the leader finally commits \circled{C.9} when it receives ACKs from the majority.
    
    \noindent{}{\bf{\underline{\#6}}:} After the protocol's execution, the coordinator marks the request as committed and notifies the client \circled{R.2}.
    %\noindent{}{\bf{\underline{\#5}}:} A request coordinator after the protocol's execution for that request updates the state of the request as committed and notifies the client (In our example \circled{6a} and \circled{6b}.).
    
%    \noindent{}{\bf{\underline{\#6}}:} Replicas, if required, rely on timeouts and heartbeat messages to verify they are part of the configuration.
%In case of untrusted environments, \projecttitle{} models timeouts with trusted leases for TEEs~\cite{t-lease}.
%\end{itemize}





\subsection{View Change}
\if 0
\dimitra{\begin{itemize}
    \item view change is ''leader election`` for us!
    \item Describe how the recipe identifies leader failures
    \item Leader election depends on the specific protocol but you must say here how you ensure at most one leader at a time
\end{itemize}
}
\fi

While decentralized protocols remain available as long as most nodes are part of the membership, the leader-based protocols do not progress if the leader goes down. To remain available after the leader crashes, the followers need to closely monitor the leader (e.g., heartbeat messages in inactive periods) and, in case it is unreachable, to \emph{elect} a new one, i.e., perform a \emph{view change}.

%Usually, the leader sends requests which also notify followers about the leader's activity. However, due to inactivity, the leader might remain idle and in this case it will send pings. 

%The follower nodes rely on timeouts to identify leader failures. Specifically, if a timeout expires without communication (and, probably, after some retries), the replicas need to carry out a leader election protocol to switch to a new leader---similarly, as a view change to switch to a new primary in PBFT. 

In line with the CFT protocols, \projecttitle{} protocols must assign a leader with a term and a node identifier. The term id can be seen as an \emph{epoch}, a monotonically increasing counter that uniquely identifies the current view of the system. To continue serving requests after a leader election, the majority must confirm the new leader and the new term. Since a leader needs to be acknowledged by the majority of the nodes to operate, the latest term will survive in at least one node, ensuring the term's monotonic increments.

\myparagraph{Correctness} The correctness condition for leader elections is that every commit must survive into the new leader election in the order selected for it when it was executed. \projecttitle{} does not make further assumptions, protocols can rely on their election algorithms as we guarantee the replicas are trusted.% ($\S$~\ref{sec:theory}). %Protocols can rely on their election algorithms. %Additionally, if the client receives no reply to a request, it resents the request; this way all clients eventually will learn about the new elected leader, and also prompts the new leader/primary to send it the reply.

\myparagraph{Failure detection} CFT protocols~\cite{raft, chain-replication} often require trusted timers to detect failures. \projecttitle{} builds on top of Intel SGX, which does not secure timers~\cite{monotoniccounterssgx, sgxtrustedtime}, whereas OS-timers and software clocks cannot be trusted. To overcome this, \projecttitle{} implements a trusted lease mechanism~\cite{t-lease}. Our mechanism supports all the properties of classical leases~\cite{10.1145/74850.74870}  that are the building block for trusted timeouts, failure detectors~\cite{222603}, leader election~\cite{815321}, etc.% Note that future TEEs' design come with trusted timer sources~\cite{intelTDX, amd-sev}.

% offer trusted timer sources~\cite{intelTSC, amdTSC}. %\projecttitle{}'s lease  %Similarly, any software-based implementations or simulations of a clock within the TEE can be compromised by a Byzantine OS.%---for example, the OS can continuously schedules out the timer thread.\\
%Unfortunately, the lack of a trusted timer complicates failure detection for protocols that primarily rely on accurate time-outs---for example, leader election in Raft. \projecttitle{} builds on top of \scone{} that implements a trusted lease mechanism~\cite{t-lease}. Our mechanism supports all the properties of classical leases~\cite{10.1145/74850.74870} in untrusted environments that are the building block for trusted timeouts, failure detectors~\cite{222603}, leader election~\cite{815321}, etc. While \projecttitle{}'s overcomes this problem, we believe that this is no longer a real limitation as other TEEs~\cite{intelTDX, amd-sev} offer trusted timer sources~\cite{intelTSC, amdTSC}. %\projecttitle{}'s lease mechanism supports all the properties of classical leases~\cite{10.1145/74850.74870} while it offers accuracy, performance and correctness in untrusted environments. The lease duration of the holder is always a superset of the granter under the presence of a powerful attacker that can manipulate the clocks, the cpu frequency, etc.
%We argue that this is no longer a limitation as the state-of-the-art TEEs~\cite{intelTDX, amd-sev} offer trusted timer sources~\cite{intelTSC, amdTSC}.


\subsection{Transferable Authentication}
\label{sec:attestation}
%\myparagraph{Attestation} 
Before initialization, all participant nodes run the transferable authentication phase (are \emph{attested}). The phase ensures that only authenticated replicas receive configurations and secrets and participate to the protocol, guaranteeing the transferable authentication property and protecting against Sybil attacks~\cite{10.1007/3-540-45748-8_24}. \projecttitle{} materializes this phase using a remote attestation protocol.

The attestation protocol is initialized by the protocol designer (PD) (\emph{challenger}), who establishes a TLS connection with the Configuration and Attestation service (CAS) \circled{A.1}. CAS is responsible for proving the authenticity of a TEE. For now, we focus solely on the attestation protocol; the CAS is discussed in $\S$~\ref{subsec:attestation}. The CAS also establishes secure communication channels with the participant nodes. 

The PD sends an \emph{attest request} to the CAS \circled{A.2}, which is then forwarded to the replicas \circled{A.3}. The replicas perform \emph{local attestation}~\cite{Parno2010}, i.e., they calculate a measurement of their code and generate a quote that is uniquely bound to that particular TEE \circled{A.4}. The quotes are sent over the TLS channel to the CAS for verification. Upon a successful attestation of a TEE, the CAS notifies the PD to forward configurations to the replicas \circled{A.7}---\circled{A.8}.

\subsection{Recovery}
\label{sec:recovery}
As nodes fail, new or recovered nodes need to be added to continue operating at peak performance. To add a new node, the membership needs to be reliably updated following the notification of all other live replicas of the new nodeâ€™s
intention to join the replica group. For non-equivocation, recovered nodes always
start as fresh nodes and as such are assigned unique node ids by the CAS
through the attestation phase. Overall, a new joining node follows the next steps:

%Once all the replicas acknowledge this notification, the new node starts operating as a shadow replica that participates as a follower for the writes but does not serve client requests. Additionally, it might read chunks from other replicas to fetch
%the latest state similarly to~\cite{10.1145/2815400.2815425, 10.1145/2043556.2043560}. 

%\begin{itemize}
   \noindent{}{\bf{\underline{\#1}}:} A recovering node needs first to be attested before any secrets and membership information are shared. Before the control passes to the CFT protocol, the node sends a join request to a designated node, notifying it about its willingness to join the cluster. %\footnote{While we were implementing \projecttitle{}, we assumed static IP addresses where nodes are listening for join requests. However, this is not a restriction. The developers can implement there own membership management service.}
   
   \noindent{}{\bf{\underline{\#2}}:} The challenger-node that receives the request initializes a remote attestation to verify the new node's trustworthiness ($\S$~\ref{sec:attestation}). 
   
    \noindent{}{\bf{\underline{\#3}}:} After a successful attestation, as a response to the join-request, the challenger-node shares the network signing or encryption keys and the configuration of the membership. The challenger-node also broadcasts a message to the other replicas about the successful attestation of the new node. Once the new joiner acknowledges the response from the challenger-node, it establishes connections with the other replicas. 
    %\footnote{\projecttitle{} does not make any assumption of who is in change of distributing the configuration. $\S$~\ref{subsec:attestation} explains how \projecttitle{} implements configuration distribution. However, the developer can build its own configuration and attestation service building on top of \projecttitle{}'s TEE-assisted primitives.}
    
    % and waits for \texttt{ACK} before proceeding. This handshake verifies that the joiner node indeed sent the request. The other replicas about the new recovering node. The configuration might be the nodes' IPs or the IP of a management service that knows about the system membership. %Joiner nodes and CAS communication is performed over a TLS network channel.
    %\item[3.]  and communicates with a node of the membership with a request <\texttt{JOIN\_REQ(uid)$_s$}>, \texttt{uid} is a randomly generated unique id from that node.
    %\item[4.] The recovering node marks its state as \texttt{RECOVERING} The node that receives a join request from a new node sends back a <\texttt{VERIFY\_ID\_REQ(uid)$_s$}> and waits for \texttt{ACK} before proceeding. This handshake verifies that the joiner node indeed sent the request. The other replicas about the new recovering node.
    
    \noindent{}{\bf{\underline{\#4}}:} The new node joins as a shadow replica fetching the state of the system as in~\cite{10.1145/2815400.2815425, 10.1145/2043556.2043560}. If the CFT protocol allows, this node can participate in writes while recovering. Once synchronized with the system's state, it transitions to normal protocol operation. % After reading the entire applications state, the shadow replica is up-to-date and transitions to operational state, whereby it is able to serve client requests.
    %and updates the replicas (or the management service) about the membership change
%\end{itemize}

%\myparagraph{Persistent storage for recovery} \projecttitle{} does not support secure recovery from persistent storage. Persistent data are susceptible to rollback attacks where the adversaries can replace the data with stale, yet valid, versions of it. Nevertheless, developers are able to support recovery from persistent (local) logs and checkpoints (if necessary) at the cost of relying on external trusted services for rollback violations detection, similarly to other systems~\cite{engraft, treaty, rote, speicher-fast}.


