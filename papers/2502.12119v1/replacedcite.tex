\section{Related Work}
% \textbf{Visual Instruction Tuning: }
% Visual instruction tuning has become a cornerstone in the development of MLLMs, playing a pivotal role in bridging the gap between theoretical model capabilities and practical applications. This approach has evolved significantly over time. Initially, LLMs were primarily used to generate synthetic visual instructions. While these early efforts demonstrated promising performance in conversational tasks, they struggled to meet the demands of more rigorous academic benchmarks. To overcome this limitation, a hybrid approach emerged, combining synthetically generated instructions with established academic datasets, thus creating more comprehensive and diverse training data. This methodological advancement has been instrumental in enhancing MLLMs, such as LLaVA ____, InstructBLIP ____, and Cambrian ____, allowing these models to better interpret and respond to visual-linguistic cues. The importance of visual instruction tuning goes beyond improving task-specific performance; it also contributes to better alignment between model outputs and user expectations, thereby enhancing the practical utility of these systems for real-world applications while ensuring robust performance across academic evaluations. 
\textbf{Visual Instruction Tuning:}  
Visual instruction tuning is essential for aligning MLLMs with both practical applications and academic benchmarks. Early methods relied on synthetic visual instructions, which performed well in conversations but struggled on rigorous benchmarks. A hybrid approach later emerged, integrating synthetic data with academic datasets to improve training diversity. This advancement has enhanced models like LLaVA ____, InstructBLIP ____, and Cambrian ____, enabling better visual-linguistic understanding. Beyond task performance, visual instruction tuning improves model alignment with user expectations, ensuring both practical utility and strong academic performance.

\noindent
% \textbf{Visual Instruction Selection: }
% \noindent
% Although MLLMs have achieved remarkable performance across various tasks, the rapid expansion of visual instruction datasets has led to significant redundancy, mirroring challenges faced in LLMs ____. State-of-the-art MLLMs, such as BLIP3 ____, InternVL2.5 ____, LLaVA-OneVision ____, leverage billions of visual instruction instances to enhance their understanding capabilities. However, the sheer scale of these datasets results in substantial computational costs, often requiring hundreds to thousands of GPU hours, particularly for models built on large LLM backbones.

% \noindent
% To mitigate this issue, various data selection strategies have been proposed to evaluate and reduce redundancy, identifying high-value instances while preserving model performance. TIVE ____ detects severe redundancy in multimodal datasets and selects valuable data at both the task and instance levels based on gradient similarity, but it requires additional training on downstream tasks. SELF-FILTER ____ introduces an auxiliary evaluation model that updates its parameters alongside training to prioritize high-value samples. COINCIDE ____ clusters data based on conceptual and skill-based representations, while InstructionGPT-4 ____ filters a subset of 200 instructions for MiniGPT-4 ____, though this approach lacks scalability across different settings. ICONS ____ builds upon LESS ____ to incorporate targeted instruction tuning by leveraging gradient-based specialist influence estimation. DataTailor ____ optimizes data selection based on three key principles—informativeness, uniqueness, and representativeness—ensuring that the most relevant samples are retained.
\noindent
\textbf{Visual Instruction Selection:}  
% Despite the strong performance of MLLMs, the rapid growth of visual instruction datasets has introduced significant redundancy, similar to challenges in LLMs ____. State-of-the-art models like BLIP3 ____, InternVL2.5 ____, and LLaVA-OneVision ____ rely on billions of instructions to enhance understanding, but their massive scale leads to substantial computational costs, often requiring hundreds to thousands of GPU hours.  
Despite the strong performance of MLLMs, the rapid growth of visual instruction datasets has introduced significant redundancy, similar to challenges in LLMs ____. State-of-the-art models like BLIP3 ____, InternVL2.5 ____, and LLaVA-OneVision ____ rely on billions of instructions to enhance understanding, but their massive scale leads to substantial computational costs, often requiring hundreds to thousands of GPU hours.

% \noindent
% To tackle this issue, various data selection strategies aim to reduce redundancy while preserving model performance. TIVE ____ selects valuable data at both the task and instance levels using gradient similarity but requires additional downstream training. SELF-FILTER ____ introduces an auxiliary evaluation model that updates its parameters alongside training to prioritize high-value samples. COINCIDE ____ clusters data based on conceptual and skill-based representations, while InstructionGPT-4 ____ filters 200 instructions for MiniGPT-4 ____, though it lacks scalability. ICONS ____ builds upon LESS ____ to incorporate targeted instruction tuning by leveraging gradient-based specialist influence estimation. DataTailor ____ selects data based on informativeness, uniqueness, and representativeness to retain the most relevant samples.
\noindent To address this, various data selection strategies aim to reduce redundancy while preserving performance. TIVE ____ selects valuable data based on gradient similarity but requires additional training on downstream tasks. SELF-FILTER ____ uses an auxiliary evaluation model to prioritize high-value samples. COINCIDE ____ clusters data by conceptual and skill-based representations, while InstructionGPT-4 ____ filters 200 instructions for MiniGPT-4 ____, though it lacks scalability. ICONS ____ extends LESS ____ by incorporating specialist influence estimation for instruction tuning. DataTailor ____ selects data based on informativeness, uniqueness, and representativeness to retain the most relevant samples.