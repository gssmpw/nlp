\appendix

\section{Experimental Details}

We provide details on the experimental systems, baselines, evaluation metrics, and implementation to ensure clarity and reproducibility of the reported results.

\subsection{Introduction and Implementation of Baselines}

Our baselines cover both the energy estimation and evolution prediction tasks. For the energy estimation task, we have:
\begin{itemize}
    \item \textbf{Markov State Model (MSM)} is a commonly used method for estimating the relative energy of system states based on statistical probabilities. It discretizes the system using equidistant grid binning and then calculates the negative log of the frequency distribution for all states in the dataset as the reference energy. This approach is often limited by the inefficiency of Monte Carlo sampling. When the dataset fails to cover the entire sample space, some state frequencies become zero, making it impossible to infer unobserved samples from the existing data. In our experiments, we used nearest-neighbor interpolation to compute the full-space energy correlation coefficient $\rho_F$ for quantitative evaluation.
    
    \item \textbf{Autoencoder Potential Energy (APE)}. \citet{kamyshanska2014potential} demonstrate that an autoencoder can estimate the energy of a sample by treating the reconstruction error as a proxy for energy, where a lower reconstruction error indicates that the sample lies in a high-probability, low-energy region of the learned manifold, while a higher error corresponds to a higher energy. For an autoencoder with sigmoid activations, with weights \( W \), hidden biases \( b_h \), and reconstruction biases \( b_r \), the energy function is given by:\[E(x) = \sum_k \log(1 + \exp(W_k^T x + b_{h_k})) - \frac{1}{2} \|x - b_r\|^2 + \text{const}, \]where \( W_k^T x \) represents the linear combination of inputs, \( b_{h_k} \) is the hidden bias term for the \( k \)-th hidden unit, and \( b_r \) is the reconstruction bias.
\end{itemize}

For the evolution prediction task, we compare PESLA with:
\begin{itemize}
    \item \textbf{Neural MJP}. \citet{seifner2023neural} introduce Neural MJP as an alternative variational inference algorithm for Markov jump processes, which relies on neural ordinary differential equations in the form of the master equation. Neural MJP predefines the number of discrete states and encodes observed states into a one-hot vector representing the discrete state distribution as the starting point for state evolution. The key difference between these predefined discrete states and PESLA's codewords is that Neural MJP does not characterize them by energy but instead relies on a black-box neural network to fit the transition probabilities. The number of preset discrete states is treated as a hyperparameter.
    
    \item \textbf{T-IB}~\citep{federicilatent} captures time-invariant representations of continuous dynamical systems using a representation learning objective derived from information bottleneck theory and models state transitions in the representation space through a conditional flow model. This efficient representation allows T-IB to filter out high-frequency fluctuations as noise and model long-term dynamics over extended time spans.
    
    \item \textbf{VAMPnet}~\citep{mardt2018vampnets} captures the dynamics of molecular systems by directly learning a transformation from molecular configurations to a Markov state model using a deep neural network that maximizes a variational score. This end-to-end approach allows it to identify slow dynamical processes and long-timescale kinetics effectively.
    
    \item \textbf{SDE-Net}~\citep{kong2020sde} explicitly models the drift and noise diffusion terms of stochastic dynamical systems by parameterizing these two mechanisms within a neural differential equation, enhancing the representational capacity of the neural network. However, SDE-Net does not treat the dynamical system as a Markov process, making it challenging to capture transition characteristics between metastable states. Despite this limitation, it serves as a benchmark for all models.
\end{itemize}


\subsection{Architecture of PESLA Model} \label{sec:architecture}

We summarize all components of the PESLA model and the parameter shapes of each component in Table~\ref{tab:module_layers}, where $D$ is the dimension of the observed state, $K$ is the preset number of codewords, and $r$ is the proportion of activated codewords.

\begin{table}[!ht]
    \centering
    \caption{Module and layer specifications.}
    \label{tab:module_layers}
    \renewcommand{\arraystretch}{1.4}
    \begin{tabular}{|p{4cm}|p{4cm}|p{4cm}|}
        \hline
        \textbf{Module} & \textbf{Layer name} & \textbf{Parameter shape} \\
        \hline
        \multicolumn{3}{c}{\romannumeral 1. \ Adaptive Codebook Learning} \\
        \hline
        Encoder $\Xi$ & Layer-FC & [$D$, 64, 32] \\
        \hline
        Codebook $C$ &  & [$K$, 32] \\
        \hline
        \multirow{3}{*}{Gaussian Decoder $\Omega$} & Layer-FC & [32, 64, 64] \\
         & Linear (mu) & [64, $D$] \\
         & Linear-Sigmoid (std) & [64, $D$] \\
        \hline
        \multicolumn{3}{c}{\romannumeral 2. \ Graph Neural Fokker-Planck Equation} \\
        \hline
        Energy Function E(*) & Layer-FC & [32, 64, 1] \\
        \hline
        \multirow{3}{*}{Probability Encoder $\Phi$} & Positional Encoding & [$rK$, 3] \\
         & GCN-FC1 & [3+1+1, 64] \\
         & GCN-FC2 & [64, 64] \\
        \hline
        \multirow{2}{*}{Neighborhood Attention $W$} & Linear (q) & [3, 64] \\
         & Linear (k) & [3, 64] \\
        \hline
        Coefficient Vector $\beta_\xi$ & & [64,] \\
        \hline
        \multirow{2}{*}{Probability Decoder $\Psi$} & GCN-FC1 & [64, 64] \\
         & GCN-FC2 & [64, 1] \\
        \hline
    \end{tabular}
\end{table}


\subsection{Grid Searching for Hyperparameters} \label{app:grid_search}

To ensure a fair comparison across all models, we used the same batch size, optimizer, and learning rate decay strategy during training, conducting grid search only on the learning rate and model-specific hyperparameters to achieve optimal performance. The range and targets of the hyperparameter search are detailed in Table~\ref{tab:hyperparameter_search}.

\begin{table}[!ht]
    \centering
    \caption{Hyperparameter search settings.}
    \label{tab:hyperparameter_search}
    \begin{tabular}{l|c|c|c}
        \hline
        \textbf{Model} & \textbf{Learning Rate} & \textbf{Specific Hyperparameters} & \textbf{Description} \\
        \hline
        NeuralMJP & 0.01 -- 0.0001 & 10 -- 1000 & The preset number of discrete states \\
        T-IB & 0.01 -- 0.0001 & 0.01 -- 1.0 & Information bottleneck coefficient \\
        VAMPNet & 0.01 -- 0.0001 & 10 -- 1000 & Output dimensionality of the encoder \\
        SDE-Net & 0.01 -- 0.0001 & 0.01 -- 1.0 & Intensity coefficient of noise term \\
        PESLA & 0.01 -- 0.0001 & 10 -- 1000 & The preset number of codewords \\
        \hline
    \end{tabular}
\end{table}


\subsection{Data Generation or Preprocessing} \label{app:data_generation}

Consistent with previous studies, we simulate the 2D Prinz potential and ecological evolution systems to obtain the datasets. For protein folding, we use the official data provided by the authors, as described in Table~\ref{tab:data_protein}. For the first two systems, the training and testing sets are split in a 7:3 ratio. For the protein data, each protein has two trajectories of equal length, one used for training and the other for testing.

The folding data for the five proteins includes 3D spatial coordinates of 28 to 73 alpha-carbon atoms. We performed TICA implemented by Deeptime~\citep{hoffmann2021deeptime}, extracting the linear projections of the top two principal time components for each protein as preprocessing, which were then used for estimating reference energy and testing all models.

\begin{table}[!ht]
    \centering
    \caption{Protein folding dataset.}
    \label{tab:data_protein}
    \begin{tabular}{c|ccccc}
        \hline
        & Homeodomain & BBL & BBA & NTL9 & A3D \\
        \hline
        C-atom Num & 52 & 47 & 28 & 39 & 73 \\
        \hline
        Trajectory Length ($\mu s$) & 100 & 100 & 200 & 300 & 300 \\
        \hline
        Time unit ($ns$) & 10 & 10 & 10 & 10 & 10 \\
        \hline
    \end{tabular}
\end{table}


\subsection{Evaluation Metrics Calculation} \label{app:metrics_calculation}

For the evolution prediction task, we test each model using the following steps:
\begin{enumerate}
    \item Randomly initialize $M$ initial states and predict $N$ future steps using the model to obtain ${X^{\tau}_N}^M$;
    \item Discretize each dimension into a $K \times K$ state space using a uniform grid, resulting in a finite set of discrete states;
    \item Compute the marginal and transition probability distributions for each state across all $M$ trajectories;
    \item Calculate the Jensen-Shannon divergence of the marginal and transition probabilities for each trajectory and take the average.
\end{enumerate}
We set $K$ to 5, 8, and 8 for the 2D Prinz potential, ecological evolution, and protein folding systems, respectively.

For the trajectory energy correlation reported in Figure~\ref{fig:sswm_data} (right), we used the Random Sample Consensus (RANSAC) regression algorithm to fit the maximum likelihood expression $E_{pred} = f(E_{true})$ of the true energy and PESLA's predicted energy. We then mapped the data from Figure~\ref{fig:sswm_data} (left) using $f$ and visualized it in Figure~\ref{fig:sswm_data} (right).
% RANSAC regression is an iterative algorithm designed to fit models to data that contains a significant number of outliers. The key idea is to randomly sample a subset of the data points, fit a model to this subset, and assume that the subset is free of outliers.



\section{Supplementary Experimental Results for 2D Prinz Potential} \label{app:codebook_4well}

We provide the codebooks from five independent experiments on the 2D Prinz potential in Figure~\ref{fig:app_codebook_4well}, showing that PESLA consistently learns similar codeword distribution patterns.

\begin{figure}[!t]
    \centering
    \begin{subfigure}[b]{0.19\textwidth} % 
        \centering
        \includegraphics[width=\textwidth]{figures/4well_codebook1.pdf}
    \end{subfigure}
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/4well_codebook2.pdf}
    \end{subfigure}
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/4well_codebook3.pdf}
    \end{subfigure}
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/4well_codebook4.pdf}
    \end{subfigure}
    \begin{subfigure}[b]{0.19\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/4well_codebook5.pdf}
    \end{subfigure}

    \caption{Visualization of the adaptive codebooks from five independent experiments of PESLA on the 2D Prinz potential.}
    \label{fig:app_codebook_4well}
\end{figure}


\section{Supplementary Experimental Results for Protein Folding} \label{app:protein_folding}

We provided a supplementary comparison of the predictive performance of all models using the BBA protein as an example, as shown in Table~\ref{tab:bba_prediction}.

\begin{table}[!ht]
    \centering
    \caption{Predictive performance of all models on the BBA protein data with a lag time of 0.7 $\mu s$ and 8×8 grid discretization. All experiments are run 10 times to obtain statistical values.}
    \label{tab:bba_prediction}
    \begin{tabular}{l|cc}
        \hline
         & $MJS \downarrow$ & $TJS \downarrow$ \\
        \hline
        NeuralMJP & $0.0231\pm0.0048$ &  $0.3637\pm0.0051$ \\
        T-IB &  $0.0388\pm0.0053$  & $0.4327\pm0.0083$  \\
        VAMPNet & $0.0411\pm0.0021$  & $0.4566\pm0.0228$ \\
        SDE-Net & $0.0561\pm0.0181$  & $0.5502\pm0.0611$ \\
        PESLA & $\bf{0.0207\pm0.0061}$ &  $\bf{0.2468\pm0.0215}$ \\
        \hline           
    \end{tabular}
\end{table}


\section{Supplementary Experimental Results for Additional Experiments} \label{sec:comprehensive_evaluation}


\subsection{Interpretability}

Our PESLA synergistically estimates energy and predicts trajectories to simultaneously improve the accuracy of both. Although the quality of evolution prediction directly influences the precision of energy estimation, it remains unclear how the accuracy of energy estimation, in turn, impacts evolution prediction. Here, we investigate how the correlation between the estimated energy landscape and the true energy landscape influences the evolution prediction. Specifically, we aim to clarify the degree of correlation required between the predicted energy and the true energy to ensure accurate evolution prediction.

We disable the energy prediction module of PESLA, replacing the predicted energy of each codeword with a dummy energy value. When the Pearson correlation coefficient, denoted as $\rho$, equals 1.0, the dummy energy is derived from the mean true energy values of all samples within the region of each codeword. We gradually introduce noise to the dummy energy to reduce its correlation with the true energy, as illustrated in the first row of Figure~\ref{fig:interpretability}. Subsequently, we train PESLA under various dummy energy conditions and evaluate the prediction error. As shown in Figure~\ref{fig:interpretability}, the prediction error progressively increases as the correlation coefficient between the dummy energy and the true energy decreases. When the correlation coefficient drops below 0.5, PESLA’s predictive performance begins to lag behind the optimal baseline algorithm (NeuralMJP). This indicates that the quality of evolution prediction is directly influenced by the accuracy of energy estimation.

\begin{sidewaysfigure}
    \centering
    \begin{subfigure}[b]{\textwidth} % 
        \centering
        \includegraphics[width=\textwidth]{figures/interpretability.pdf}
    \end{subfigure}

    \caption{Evolution prediction accuracy as a function of the correlation coefficient $\rho$ between the dummy energy and the true energy on the 2D Prinz potential. The skyblue and red dashed lines are the optimal baseline and PESLA performances in the main text, respectively. All experiments are run 10 times to obtain statistical values.}
    \label{fig:interpretability}
\end{sidewaysfigure}


\subsection{Consistency}

Although the degree of discretization of the state space depends on the predefined number of codewords, a robust prediction model should yield consistent energy landscapes across different settings. We evaluate the correlation between energy values predicted by PESLA under various hyperparameter settings (predefined number of codewords $K$) and random seeds. As shown in the correlation matrix in Figure~\ref{fig:consistency}, the energy landscapes identified by PESLA remain consistent not only across parallel experiments with different random seeds but also across different choices of hyperparameters $K$.

\begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{\textwidth} % 
        \centering
        \includegraphics[width=\textwidth]{figures/consistency.pdf}
    \end{subfigure}

    \caption{Correlation matrix of energy values predicted by PESLA for BBA protein at different (a) preset numbers of codewords $K$ and (b) random seeds.}
    \label{fig:consistency}
\end{figure}


\subsection{Noise Robustness}

Considering that real-world trajectory data is usually noisy and sparse, the robustness of a predictive model to noise and limited data determines its practical utility. As reported in Figure~\ref{fig:4well_energy_data} of the main text, PESLA outperforms all baselines when available data is reduced. Here, we further evaluate PESLA’s robustness to noisy data. Specifically, we add Gaussian noise of varying strength to the dataset, with a noise amplitude equal to the original data magnitude when the strength is set to $1.0$. The results in Figure~\ref{fig:noise_robustness} indicate that PESLA remains sufficiently robust to noise until the noise strength exceeds 0.6. PESLA’s robustness to noise can be attributed to its adaptive codebook learning model, which incorporates a reduced-order approach. By identifying a low-dimensional, compact representation of the original state space, PESLA inherently possesses the ability to filter out uncertainties such as noise-related errors.

\begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{0.9\textwidth} % 
        \centering
        \includegraphics[width=\textwidth]{figures/noise_robustness.pdf}
    \end{subfigure}

    \caption{Energy and evolution prediction accuracy on the 2D Prinz potential as functions of noise strength. All experiments are run 10 times to obtain statistical values.}
    \label{fig:noise_robustness}
\end{figure}


\subsection{Transferability}

Here, we explore the transferability of PESLA. Although the energy landscapes of different evolutionary systems are inherently distinct, PESLA’s modules can be partially reused in similar state spaces by learning a generalized spatial mapping mechanism. We proceed by evaluating PESLA’s transferability across five different protein-folding datasets.

Due to differences in sequence length and arrangement, the folding processes of different proteins occur within their unique energy landscapes, which means that the energy function $E(*)$ and transition model need to be specifically trained for each type of protein. However, the mapping functions $\Xi$ and $\Omega$ between the observed space $\mathcal{X}$ and the latent space $\mathcal{S}$ have the potential for transferability. By learning a universal encoder $\Xi$, decoder $\Omega$ and codebook $C$, it is promising to project the structures of various proteins onto a unified latent space.

To test such transferability, we conduct cross-protein experiments for each protein. Specifically, for a given protein $i$, we train the encoder $\Xi$, decoder $\Omega$, and codebook $C$ using data from the other four proteins. We then freeze their parameters and use a single folding trajectory of protein $i$ to train the energy function $E(*)$ and the Graph Neural Fokker-Planck equation. Finally, we evaluate the accuracy of energy and evolution predictions on unseen folding trajectories of protein $i$. The results are presented in Table~\ref{tab:transferability}. Although the predictive performance in all cross-protein transfer experiments is lower than that achieved by training on specific proteins, the average transfer performance $\rho_t$ for energy prediction across all proteins reaches over 80\% of the performance of specifically trained models.
Additionally, the transfer performance of evolution prediction is significantly better than that of the optimal baseline under the same training settings.
We believe that as the number of available proteins increases, the model’s transferability will show promising improvement. The validation experiments in this section demonstrate its feasibility.

\begin{table}[!ht]
    \centering
    \caption{Comparison of mean $\rho_t$, MJS, and TJS metrics for encoder $\Xi$, decoder $\Omega$, and codebook $C$ trained on specific protein data versus cross-protein data for Homeodomain, BBL, BBA, NTL9, and A3D. All experiments are run 10 times to obtain mean values.}
    \label{tab:transferability}
    \renewcommand{\arraystretch}{1.2}
    \setlength{\tabcolsep}{3.75pt} % Adjusts column padding
    \begin{tabular}{c||c|c|c||c|c|c||c|c|c}
        \hline
        & \multicolumn{3}{c||}{Homeodomain} & \multicolumn{3}{c||}{BBL} & \multicolumn{3}{c}{BBA} \\
        \hline
        & $\rho_t$ & $MJS$ & $TJS$ & $\rho_t$ & $MJS$ & $TJS$ & $\rho_t$ & $MJS$ & $TJS$ \\
        \hline
        \textbf{PESLA-specific} & 0.9341 & 0.0203 & 0.2342 & 0.9014 & 0.0200 & 0.2322 & 0.9179 & 0.0207 & 0.2468 \\
        \hline
        \textbf{PESLA-cross} & 0.8583 & 0.0875 & 0.3510 & 0.7014 & 0.0775 & 0.4362 & 0.6665 & 0.1055 & 0.4065 \\
        \textbf{NeuralMJP-cross} & -- & 0.5837 & 0.7724 & -- & 0.5303 & 0.6703 & -- & 0.4382 & 0.5651 \\
        \hline
        & \multicolumn{3}{c||}{NTL9} & \multicolumn{3}{c||}{A3D} \\
        \hline
        & $\rho_t$ & $MJS$ & $TJS$ & $\rho_t$ & $MJS$ & $TJS$ \\
        \hline
        \textbf{PESLA-specific} & 0.8867 & 0.0167 & 0.2625 & 0.8186 & 0.0414 & 0.3055 \\
        \hline
        \textbf{PESLA-cross} & 0.7443 & 0.1089 & 0.4597 & 0.6235 & 0.2068 & 0.6034 \\
        \textbf{NeuralMJP-cross} & -- & 0.3539 & 0.4525 & -- & 0.7340 & 0.7983 \\
        \hline
    \end{tabular}
\end{table}


\subsection{Scalability}

To investigate the relationship between the size of the state space and the codebook size, we evaluate the impact of the preset number of codewords $K$ on energy and evolution prediction in protein folding datasets with varying numbers of alpha-C atoms, as shown in Figure~\ref{fig:scalability}. As $K$ increases from $10$ to $1000$, the relative performance of the model improves. For the BBA protein, which has only 28 alpha-C atoms, the prediction accuracy for energy reaches over 90\% of the performance observed at $K=1000$ when $K=100$. For larger proteins, such as A3D, the model's predictive performance converges at $K=500$. In fact, protein size increases the complexity of the state space, thereby adding to the modeling challenge. For larger proteins or other systems with complex state spaces, the codebook size needs to be sufficiently large to ensure PESLA’s modeling capacity. For the systems studied in this paper, we recommend setting the preset number of codewords $K$ to $1000$. For other unfamiliar systems, starting with a relatively large $K$ value is generally advisable.

Furthermore, as analyzed in Appendix~\ref{sec:cost}, the time complexity for training and inference grows sub-linearly with the increase in $K$. Since only a limited number of codewords are activated in the preset codebook, the size of the energy landscape constructed by PESLA is at most $K$. Consequently, when modeling the state transition distribution over the landscape using the Graph Neural Fokker-Planck equation, the number of codewords to be considered does not necessarily increase linearly with $K$. This design allows users to efficiently explore and select appropriate values for $K$.

\begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{0.9\textwidth} % 
        \centering
        \includegraphics[width=\textwidth]{figures/scalability.pdf}
    \end{subfigure}

    \caption{Mean (a) $MJS$ and (b) $\rho_t$ for proteins of different sizes as a function of codebook size $K$, normalized by the metric at $K = 1000$. (c) and (d) report the minimum codebook size required to achieve 90\% prediction performance for different proteins. All experiments are run 10 times to obtain mean values.}
    \label{fig:scalability}
\end{figure}


\section{Ablation Studies} \label{sec:ablation_study}

PESLA comprises multiple loss function terms and submodules. Here, we introduce additional ablation studies to elucidate the individual contribution of each component to the overall performance.

As summarized in Section~\ref{sec:training}, the training process involves five loss function terms: $L_{rec}$, $L_{vq}$, $L_{latent}$, $L_{code}$, and $L_{phy}$. The $L_{rec}$ and $L_{vq}$ terms jointly guide the adaptive codebook learning module, while $L_{latent}$ and $L_{code}$ direct the synergistic learning process for energy and evolution prediction. Additionally, the $L_{phy}$ term incorporates physical knowledge to further inform energy estimation. Beyond the essential loss terms, we individually evaluate the performance impact of the auxiliary terms, $L_{latent}$ and $L_{phy}$. The results are presented in Table~\ref{tab:loss_ablation}.

We firstly remove the $L_{latent}$ term, training the prediction module solely with the $L_{code}$ term. The results indicate that, without the predictive constraint from the latent space, the accuracy of evolution prediction deteriorates, and the precision of energy estimation is also affected. Next, upon removing the $L_{phy}$ term, PESLA’s performance in both energy and evolution prediction declined significantly. This suggests that, although self-supervised learning on the evolution prediction task can drive energy estimation, physical knowledge remains crucial for guiding this joint optimization task effectively.

In Section~\ref{sec:GNFPE}, we enhance the model’s capability by encoding one-hot probability vectors as initial conditions for the Graph Neural Fokker-Planck equation. Here, we validate this design. By deactivating the encoder $\Phi$ and decoder $\Psi$, we require the neural Fokker-Planck equation to directly model the diffusion of the probability vector. As shown in Table~\ref{tab:loss_ablation}, when $\Phi$ and $\Psi$ are deactivated, PESLA’s performance in both energy and evolution prediction deteriorates, confirming the importance of the high-dimensional encoded space for effective graph neural diffusion modeling.

\begin{table}[!ht]
    \centering
    \caption{Ablation study on the loss function and submodule for 2D Prinz Potential and Ecological Evolution. w/o * indicates the absence of the loss function * or module *. All experiments are run 10 times to obtain statistical values.}
    \label{tab:loss_ablation}
    \begin{tabular}{l|cccc}
        \hline
         & \multicolumn{4}{c}{2D Prinz potential} \\
        \hline
         & $\rho_t$ & $\rho_f$ & $MJS$ & $TJS$ \\
        \hline
        PESLA & $0.9290\pm0.0342$ & $0.7419\pm0.0318$ & $0.1031\pm0.0125$ & $0.1796\pm0.0234$ \\
        w/o $L_{phy}$ & $0.0641\pm0.0182$ & $0.003\pm0.0928$ & $0.1435\pm0.0102$ & $0.2559\pm0.0358$ \\
        w/o $L_{latent}$ & $0.8089\pm0.0672$ & $0.7192\pm0.0291$ & $0.1270\pm0.0334$ & $0.2010\pm0.0327$ \\
        w/o $\Phi \& \Psi$ & $0.8994 \pm 0.0477$ & $0.6925 \pm 0.0903$ & $0.1675 \pm 0.0089$ & $0.3535 \pm 0.0122$ \\
        \hline
        & \multicolumn{4}{c}{Ecological Evolution} \\
        \hline
        & $\rho_t$ & $\rho_f$ & $MJS$ & $TJS$ \\
        \hline
        PESLA & $-0.9067\pm0.0100$ & $-0.7582\pm0.0241$ & $0.3111\pm0.0397$ & $0.3277\pm0.0424$ \\
        w/o $L_{phy}$ & $-0.0271\pm0.0281$ & $-0.002\pm0.0817$ & $0.4455\pm0.0865$ & $0.4683\pm0.0257$ \\
        w/o $L_{latent}$ & $-0.8982\pm0.0071$ & $-0.6912\pm0.0182$ & $0.3228\pm0.0441$ & $0.3441\pm0.0232$ \\
        w/o $\Phi \& \Psi$ & $-0.8980 \pm 0.0075$ & $-0.7018 \pm 0.0202$ & $0.3564 \pm 0.0236$ & $0.4685 \pm 0.0227$ \\
        \hline
    \end{tabular}
\end{table}


\section{Computational Cost} \label{sec:cost}

We denote the sample size and the preset number of codewords as $N$ and $K$, respectively. The training process of PESLA consists of two modules: adaptive codebook learning and the graph neural Fokker-Planck equation. The former includes encoding and decoding each sample, as well as codeword matching operations. The computational complexity of encoding and decoding is $\mathcal{O}(N)$, while codeword matching, which involves similarity calculations with each codeword, has a time complexity of $\mathcal{O}(NK)$. In the second module, all computations occur on the codeword topology with a size of $\mathcal{O}(rK)$, where $r$ is the proportion of activated codewords. Since the encoding, decoding, and diffusion processes for the probability vector, as described in Equations 4 and 5, involve operations over the entire topology, the computational complexity is $\mathcal{O}(rNK)$. Therefore, the overall time complexity during training is $\mathcal{O}(N+NK+rNK)=\mathcal{O}(NK)$.

Once training is complete, the model only needs to retain the activated codewords, resulting in an inference time complexity of $\mathcal{O}(rNK)$. In the worst case, $r=100\%$, meaning a 100\% codeword activation ratio. However, as reported in Section 4.3, for a discrete state space of size 10,000, fewer than 100 codewords are typically sufficient for reliable prediction. Thus, $r$ is usually a low value, making the model's inference cost manageable. Additionally, our encoder $\Xi$ employs an MLP architecture, with a time complexity that scales linearly with the dimension of the observed state.

We evaluate the training time of all algorithms across three datasets, with batch size and epochs uniformly set to 128 and 10, respectively, to ensure fairness. The experiments are conducted on a hardware platform equipped with an Intel i5-14600KF CPU and an NVIDIA RTX 4060Ti GPU. As shown in Figure~\ref{fig:training_time}, the total runtime of PESLA's two phases is shorter than that of the optimal baseline, NeuralMJP, reported in the main text. Additionally, PESLA’s time bottleneck is clearly concentrated in phase 1 (adaptive codebook learning), with phase 2 (graph neural Fokker-Planck equation) accounting for less than half of the total training time, aligning with the conclusions of previous analysis.

\begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{\textwidth} % 
        \centering
        \includegraphics[width=\textwidth]{figures/TrainingTime.pdf}
    \end{subfigure}

    \caption{Total training time of all algorithms across the three datasets. All experiments are run 10 times to obtain mean values.}
    \label{fig:training_time}
\end{figure}


\section{Degraded Observation} \label{sec:degraded}

In Equation 2 of the main text, the system's intrinsic state evolving on the energy landscape is mapped to the observation space via the observation function $g$, which serves as the input to PESLA. In the main experiments, the observation state $x_t$ retains the primary information of $s_t$; however, this may not hold under certain lossy observation functions. In complex systems modeling, the time-delay embedding method reconstructs the manifold of system's evolution by embedding multi-step trajectories of a high-dimensional system in a limited-dimensional space~\citep{wu2024predicting}. Here, we supplement a set of degraded observation experiments to verify that PESLA can leverage a similar idea, modeling the energy landscape using multi-step historical observations.

\begin{table}[!ht]
    \centering
    \caption{Energy prediction as a function of lookback steps.}
    \label{tab:loss_g}
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular}{l|ccccc}
        \hline
        lookback & 1 & 2 & 3 & 4 & 5 \\
        \hline
        $\rho_t$ & $0.7087$ & $0.7338$ & $0.7916$ & $0.8037$ & $0.8056$ \\
        \hline
    \end{tabular}
\end{table}

Specifically, we applied an observation function $g(x, y) = \begin{bmatrix} \cos(\frac{\pi}{4}) & \sin(\frac{\pi}{4}) \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix}$ to the 2D Prinz Potential used in the main text, projecting the 2-dimensional system state coordinates onto the 1-dimensional diagonal of the energy landscape as a degraded observation state. We tested the performance of PESLA’s energy prediction as a function of the historical observation step length, as shown in Table 1. The prediction performance is poor when using only a single observation step, as the one-dimensional degraded observation lacks complete information about the energy. As the input lookback steps increase, the model gains access to the system's past evolution trajectories, improving prediction performance to over 85\% of that under lossless observations. The results indicate that degraded observations can be mitigated by incorporating multi-step historical trajectories, aligning with the consensus in the field.