\section{Conclusion}
\label{sec_conclusion}
We have addressed significant safety challenges in DMs, particularly concerning the generation of NSFW content and the inadvertent reproduction of sensitive data. We introduce the \textit{safe denoiser}, a novel approach that modifies the sampling trajectories of DMs to adhere to theoretically safe distributions, thereby ensuring the generation of appropriate and authorized content. Experimental results demonstrate that the safe denoiser achieves state-of-the-art performance in tasks such as concept erasing, class removal, and unconditional image generation. Ultimately, this work provides a robust and scalable solution for mitigating safety risks in generative AI, paving a way for their responsible and ethical applications.
%

\section*{Impact Statements}

This paper presents a work whose goal is to build a reliable and trustworthy Generative AI. There are many potential societal consequences of our work, particularly in addressing ethical risks associated with generative models. Our research is focused on preventing the generation of NSFW content, including nudity and violence, and mitigating the risk of models memorizing and reproducing private information, such as human face, from training datasets. We believe the presented work  contributes to the responsible use of generative AI, reinforcing ethical safeguards and promoting AI systems that align with societal values and human rights.

%

%




%

