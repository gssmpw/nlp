\section{Related Work}
%
%
%
%
%

Earlier work on machine unlearning in generative modelling focused on object unlearning in classification (forgetting images from a selected class), unconditional image generation (forgetting harmful images) or concept erasing (forgetting harmful concepts). Most of the work belonging to this category required retraining the entire generative models or some part of them, rather than modifying the sampling trajectory or input prompts \cite{heng2023selective, li2024machine, adapt_then_unlearn, zhang2024forgetmenot, gandikota2023unified, lu2024mace, gong2024reliable, lu2024mace}. 
In more recent work, training-free and text-based methods have also emerged as computationally efficient alternatives \cite{schramowski2023safe,yoon2024safree,ban2024understanding, armandpour2023reimagine}. 
However, most of these approaches lack a theoretical ground, unlike our work. 


%
%

%

%

%
%

%

%

%
%
%
%

 





%


Despite these advances, generative models remain susceptible to adversarial prompts, malicious manipulations of learnable parameters, textual cues, or even random noise \cite{pham2023circumventing, chin2024promptingdebugging, zhang2024generate, tsai2024ringabell}. These findings highlight using a single defense such as concept erasing as a standalone solution may be insufficient to ensure safe content generation. We see this as an opportunity for our method to be combined with powerful text-based defense mechanisms to enhance their performance.  



%

The most closely related work is  Sparse Repellency (SR) by \citet{kirchhof2024sparse}, a training-free technique that modifies the denoising trajectory to avoid unsafe images $\{\mathbf{x}^{(n)} \}_{n=1}^N$. Their denoiser follows $\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]+\sum_{n=1}^{N}\text{ReLU}\left(\tfrac{r}{\Vert\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]-\mathbf{x}^{(n)}\Vert}-1\right) \times(\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]-\mathbf{x}^{(n)}).$
%
%
%
The Rectified Linear Unit (ReLU) function ensures that the diffusion trajectory is penalized when the denoiser falls within the neighborhood of radius $r$ around unsafe data, and remains unmodified otherwise. 
Given a single unsafe image, $\text{ReLU}\left(\tfrac{r}{\Vert\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]-\mathbf{x}^{(n)}\Vert}-1\right) (\mathbb{E}_{\text{data}}[\mathbf{x}\vert \mathbf{x}_{t}]-\mathbf{x}^{(n)})$ resembles the second term in \eqref{E_safe} if the ReLU value is comparable to our $\beta^*$. From this, our method can be viewed as a generalization of the SR.
%
%
However, unlike our method, their guidance does not guarantee sampling from a safe distribution. 

%
%

%

\input{Manuscript/sources/asr}

\begin{figure*}[t]%
	\centering
 \begin{subfigure}{0.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/Experiments/unsafe_data.pdf}
        \vskip -0.05in
		\subcaption{Effect on $N$}
	\end{subfigure}
    \hfil
 \begin{subfigure}{0.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/Experiments/beta.pdf}
        \vskip -0.05in
		\subcaption{Effect on $\beta_{t}$}
	\end{subfigure}
    \hfil
 \begin{subfigure}{0.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/Experiments/sld.pdf}
        \vskip -0.05in
		\subcaption{Effect on prompt weights}
	\end{subfigure}
 \vskip -0.05in
	\caption{Ablation studies of (a) the effect on the number of unsafe data ($N$), (b) the effect on the threshold ($\beta_{t}$), and (c) the effect on the prompt weights. All metrics are evalauted on MMA-Diffusion}
    \label{fig:ablation}
	 %
\end{figure*}

Lastly, the work by \citet{biggs2024diffusion} shares a similar theoretical analysis as ours. They propose to merge the weights of DMs separately trained on independent subsets of data, resulting in a sampling distribution that extends beyond the framework outlined in our \thmref{safe}. %
However, unlike their method, we do not require additional training of DMs and our analysis defines the safe and unsafe denoisers and their explicit relationship between those. 

%
%
