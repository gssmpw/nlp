\section{Methodology}
\label{sec_method}

The negative prompt $\mathbf{c}_{-}$ or the SLD prompt $\mathbf{c}_{US}$ consist of a limited set of pre-selected words by humans, and therefore may not encompass all images intended to be negated. Consequently, instead of ensuring safety solely based on text prompt, we introduce a methodology that guarantees safety based on images, which operates orthogonally to existing text-based safety approaches. Furthermore, while text-based negative guidance can enhance safety, its application lacks a theoretical foundation, thereby offering no guarantees regarding the distribution of the samples.
To address these issues, we propose constructing a sampling trajectory that adheres to the safe distribution by using a \textit{safe denoiser} defined below. 

\subsection{Safe Denoiser}\label{sec:safe}


\begin{figure*}[t]%
	\centering
 \begin{subfigure}{0.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/Method/moons_10.0_v4.pdf}
		\subcaption{weight $\leftarrow\frac{1}{2}\beta^{*}(\mathbf{x}_{t})$}
	\end{subfigure}
 \hfil
 \begin{subfigure}{0.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/Method/moons_6.5_v4.pdf}
		\subcaption{weight $\leftarrow\beta^{*}(\mathbf{x}_{t})$}
	\end{subfigure}
 \hfil
 \begin{subfigure}{0.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{Figures/Method/moons_3.0_v4.pdf}
		\subcaption{weight $\leftarrow2\beta^{*}(\mathbf{x}_{t})$}
	\end{subfigure}
 \vskip -0.05in
	\caption{Effect of the weight value in Theorem~\ref{thm:safe}. (a) If we use half the theoretical weight value, samples generated by our weak safe denoiser also cover the unsafe region (i.e., red dots appearing in the blue area). (b) When we use the theoretical value, the samples avoid unsafe regions while covering the whole safe area. (c) If we penalize more with doubled weight value, the samples not only avoid the unsafe data but also negate the \textit{neighborhood} of unsafe data (i.e., there are no red dots in the black area).}
    \label{fig:beta}
	 \vskip -0.1in
\end{figure*}



%
%
%
%
%
%
%
%
%
%
%



%

To define the safe denoiser, we first define an indicator function,  $1_{\text{safe}}(\mathbf{x})$ taking the value of $1$ if $\mathbf{x}$ is safe and $0$ if not. Similarly, we define an indicator function, $1_{\text{unsafe}}(\mathbf{x})$ taking the value of $1$ if $\mathbf{x}$ is unsafe and $0$ if not. Hence, for each sample $\mathbf{x}$, we have a constant function, taking the value of $1$, defined by  $1(\mathbf{x}) = 1_{\text{safe}}(\mathbf{x}) + 1_{\text{unsafe}}(\mathbf{x})$. Then, we define the following concepts.
\begin{definition}
    The unnormalized safe distribution $p_{\text{safe}}(\mathbf{x})$ is $1_{\text{safe}}(\mathbf{x})p_{\text{data}}(\mathbf{x})$. The \textit{safe denoiser} is defined by
    \begin{align*}
    \mathbb{E}_{\text{safe}}[\mathbf{x}\vert\mathbf{x}_{t}]=\int \mathbf{x}\frac{p_{\text{safe}}(\mathbf{x})q_{t}(\mathbf{x}_{t}\vert\mathbf{x})}{p_{\text{safe},t}(\mathbf{x}_{t})}\diff\mathbf{x},
\end{align*}
where $p_{\text{safe},t}(\mathbf{x}_{t})$ is the marginal distribution of the noisy safe data at $t$. Analogously, the unnormalized unsafe distribution $p_{\text{unsafe}}(\mathbf{x})$ is $1_{\text{unsafe}}(\mathbf{x})p_{\text{data}}(\mathbf{x})$. The \textit{unsafe denoiser} is
\begin{align}\label{eq:E_unsafe}
    \mathbb{E}_{\text{unsafe}}[\mathbf{x}\vert\mathbf{x}_{t}]=\int \mathbf{x}\frac{p_{\text{unsafe}}(\mathbf{x})q_{t}(\mathbf{x}_{t}\vert\mathbf{x})}{p_{\text{unsafe},t}(\mathbf{x}_{t})}\diff\mathbf{x},
\end{align}
where $p_{\text{unsafe},t}(\mathbf{x}_{t})$ is the marginal distribution of the noisy unsafe data at $t$.
\end{definition}



Our interest is to obtain $\mathbb{E}_{\text{safe}}[\mathbf{x}\vert\mathbf{x}_{t}]$ given the data denoiser $\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]$ defined in \eqref{E_data}. The theorem below describes the relationship between our safe denoiser and the usual data denoiser.

\begin{theorem}\label{thm:safe}
Suppose that $\mathbb{E}_{\textup{data}}[\mathbf{x}\vert\mathbf{x}_{t}]$, $\mathbb{E}_{\textup{safe}}[\mathbf{x}\vert\mathbf{x}_{t}]$, and $\mathbb{E}_{\textup{unsafe}}[\mathbf{x}\vert\mathbf{x}_{t}]$ are the data denoiser, the safe denoiser, and the unsafe denoiser. Then,
    \begin{align}\label{eq:E_safe}
        \mathbb{E}_{\textup{safe}}[\mathbf{x}\vert\mathbf{x}_{t}]&=\mathbb{E}_{\textup{data}}[\mathbf{x}\vert\mathbf{x}_{t}]\\
        &\quad+\beta^{*}(\mathbf{x}_{t})\big(\mathbb{E}_{\textup{data}}[\mathbf{x}\vert\mathbf{x}_{t}]-\mathbb{E}_{\textup{unsafe}}[\mathbf{x}\vert\mathbf{x}_{t}]\big) \nonumber
    \end{align}
    for a weight is defined by
    \begin{align}\label{eq:beta}
        \beta^{*}(\mathbf{x}_{t}) = \frac{Z_{\textup{unsafe}}p_{\textup{unsafe},t}(\mathbf{x}_{t})}{Z_{\textup{safe}}p_{\textup{safe},t}(\mathbf{x}_{t})},
    \end{align}
    where $Z_{\textup{safe}}:=\int 1_{\textup{safe}}(\mathbf{x})p_{\textup{data}}(\mathbf{x})\diff\mathbf{x}$ and $Z_{\textup{unsafe}}:=\int 1_{\textup{unsafe}}(\mathbf{x})p_{\textup{data}}(\mathbf{x})\diff\mathbf{x}$ are normalizing constants of safe and unsafe distributions, respectively.
\end{theorem}
The proof is given in \suppsecref{proof}.



%
%
%
%
%
%
%
%
%
%
%
%

The theorem above suggests that a safe denoiser can be constructed similarly to CFG. 
%
%
In our case, the denoiser is penalized is determined by $\beta^{*}(\mathbf{x}_{t})$, designed to increase when $\mathbf{x}_{t}$ is likely unsafe. Specifically, a term in the numerator, $\int p_{\text{unsafe}}(\mathbf{x}) q_{t}(\mathbf{x}_{t} \vert \mathbf{x})\diff\mathbf{x}$, grows as the likelihood of $\mathbf{x}_{t}$ being unsafe increases. In contrast, the denominator grows as the likelihood of $\mathbf{x}_{t}$ being safe increases. Consequently, $\beta^{*}(\mathbf{x}_{t})$ decreases as $\mathbf{x}_{t}$ becomes more likely to be safe. This indicates that our theoretically derived $\beta^{*}(\mathbf{x}_{t})$ shares a similar intuition to the adaptive weight $\mu$ observed in SLD, but correctly aligns with the intended penalty mechanism. In other words, if $\mathbf{x}_{t}$ is more unsafe than $\mathbf{\tilde{x}}_{t}$, then the trajectory of $\mathbf{x}_{t}$ is \textit{more penalized} than that of $\mathbf{\tilde{x}}_{t}$, i.e., $\beta^{*}(\mathbf{x}_{t})>\beta^{*}(\mathbf{\tilde{x}}_{t})$.

To provide more intuition on the role of the weight in our theorem, we vary the values that the weight can take and show the corresponding samples. In \figref{beta}-(a), we observe that when safety is considered less rigorously than the measure of $\beta{^*}(\mathbf{x}_{t})$, some samples reside within the unsafe region. In contrast, \figref{beta}-(b) demonstrates that by doubling the safety threshold, both the unsafe region and its immediate surroundings are effectively avoided.
However, in \figref{beta}-(c), we observe that the samples from our safe denoiser do not cover the entire safe regions in the data distribution. 

%


%

\subsection{Practial Considerations}\label{sec:unbiased}



For computing \eqref{E_safe}, we need to compute three terms: the data denoiser $\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]$, the unsafe denoiser $\mathbb{E}_{\text{unsafe}}[\mathbf{x}\vert\mathbf{x}_{t}]$ and the weight $\beta^{*}(\mathbf{x}_{t})$. We approximate $\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]$ by utilizing a pre-trained diffusion model. Consequently, the task reduces to deriving $\mathbb{E}_{\text{unsafe}}[\mathbf{x}\vert\mathbf{x}_{t}]$ and the weight. This section delineates the approach to compute these quantities. 


\paragraph{Unsafe denoiser Approximation.}
First, we present an approximation of the unsafe denoiser as follows.
%
Given a set of unsafe data points denoted by $\mathbf{x}^{(1)},...,\mathbf{x}^{(N)}$,
\begin{align}\label{eq:est_unsafe}
    \hat{\mathbb{E}}_{\text{unsafe}}[\mathbf{x}\vert\mathbf{x}_{t}]
    %
    =
    %
\sum_{n=1}^{N}\mathbf{x}^{(n)}\frac{q_{t}(\mathbf{x}_{t}\vert\mathbf{x}^{(n)})}{\sum_{m=1}^{N}q_{t}(\mathbf{x}_{t}\vert\mathbf{x}^{(m)})}.
\end{align}
%
%
Each numerator and denominator terms of \eqref{est_unsafe} approximates the numerator and denominator terms of \eqref{E_unsafe}, respectively. It shows that an unsafe denoiser can be expressed as a weighted sum of the unsafe dataset. Here, the weights $\{\frac{q_{t}(\mathbf{x}_{t}\vert\mathbf{x}^{(n)})}{\sum_{m=1}^{N}q_{t}(\mathbf{x}_{t}\vert\mathbf{x}^{(m)})}\}$ form a sum-to-one normalized vector across the unsafe data points, so the unsafe denoiser is approximated as a weighted unsafe data point.

%

%
%


%

%

%
%
%
%
%
%
%

%


%

%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

%
%
%
%
%
%



%

%

%

%
%

%

%

%


%
%
%
%
%
%
%
%
%
%
%
%


\paragraph{Estimate of the weight.}
Next, we turn our attention to the computation of $\beta^{*}(\mathbf{x}_{t})$ in \eqref{beta}. Direct calculation is intractable due to the denominator $Z_{\text{safe}}\int p_{\text{safe}}(\mathbf{x})q_{t}(\mathbf{x}_{t}\vert\mathbf{x})$, which is computationally infeasible\footnote{It requies computing $q_{t}(\mathbf{x}_{t}\vert\mathbf{x})$ over all safe data $\mathbf{x}\sim p_{\text{safe}}(\mathbf{x})$, where safe data includes the entire training dataset excluding few unsafe data. Modern text-to-image models like Stable Diffusion~\cite{rombach2022high} are trained with billions of training data~\cite{schuhmann2022laion}, and is infeasible to iterate the entire data at inference time.} to evaluate at every sampling steps. 
%
To address this challenge, 
we approximate $\beta^*$ as
\begin{align*}
    \beta^*(\mathbf{x}_{t}) \approx \eta \cdot \beta(\mathbf{x}_{t}),
\end{align*}
with a constant $\eta$ and a function $\beta(\mathbf{x}_{t})$ defined by
%
\begin{align}
    \beta(\mathbf{x}_{t})&=\int p_{\text{unsafe}}(\mathbf{x})q_{t}(\mathbf{x}_{t}\vert\mathbf{x})\diff\mathbf{x}\nonumber \\
    &\approx \frac{1}{N}\sum_{n=1}^{N}q_{t}(\mathbf{x}_{t}\vert\mathbf{x}^{(n)}) \nonumber 
\end{align} where the last line is an unbiased estimate of $\beta$. We treat $\eta$ as a controllable hyperparmeter, with which we replace the computation of the remaining terms in \eqref{beta}. 
%
This approximation is reasonable insofar as the numerator alone captures the overall trend of $\beta^{*}(\mathbf{x}_{t})$: as $\mathbf{x}_{t}$ becomes more likely to be unsafe, both $\beta^{*}(\mathbf{x}_{t})$ and the numerator increase correspondingly. This approximation of the weight significantly reduces computational complexity. Additionally, we observe that applying the safe denoiser at the final stage of sampling (i.e., when $t$ is small) hurts the sample quality, since the signal from unsafe denoiser--a weighted sum of unsafe data points--acts as a structural noise for detailed denoising. From this observation, we propose to apply the safe denoiser only at the beginning of sampling process.
%

 %
%
%
%
%

\input{Manuscript/sources/algorithms}

\paragraph{Putting things together.}
With these approximations mentioned above, we arrive at the final safe denoiser:
\begin{align}\label{eq:uncond_safe}
\begin{split}
   &\mathbf{x}_{0\vert t} \\
   &= \mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]
+ \eta\beta(\mathbf{x}_{t})(\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]-\hat{\mathbb{E}}_{\text{unsafe}}[\mathbf{x}\vert\mathbf{x}_{t}]),
\end{split}
\end{align}
where $\hat{\mathbb{E}}$ is given in \eqref{est_unsafe}. 
%
Our results in \secref{experiments} validate the effectiveness of our approximations in ensuring sample safety without incurring prohibitive computational costs.
%

%

%
%
%
%
%
%



%
%
%
%
%
%

%

%

%

\subsection{Extending Safe Denoiser to Text-to-Image}

Our approach can be combined with existing text-based guidance methods to enhance their performance:
%
%
%
%
%
\begin{align}\label{eq:safer}
&\mathbf{x}_{0\vert t}=\underbrace{\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]
+ \beta^{*}(\mathbf{x}_{t})(\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]-\mathbb{E}_{\text{unsafe}}[\mathbf{x}\vert\mathbf{x}_{t}]}_{\text{Safe Denoiser}}) \nonumber \\
%
&\quad\quad+\underbrace{\lambda(\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t},\mathbf{c}_{+}]-\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]}_{\text{CFG}})\\
%
    &\quad\quad-\underbrace{\mu(\mathbf{c}_{+},\mathbf{c}_{S};\gamma,\lambda)(\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t},\mathbf{c}_{S}]-\mathbb{E}_{\text{data}}[\mathbf{x}\vert\mathbf{x}_{t}]}_{\text{SLD}}).\nonumber
\end{align}
Using this denoiser allows us to negate data samples based on the information from the images (from our safe denoiser) and the information based on the prompts (from both CFG and SLD). Note this \eqref{safer} includes only the additional term for the safe denoiser compared to \eqref{SLD}. In implementation, as described in \secref{unbiased}, we approximate the second term of \eqref{safer} by \eqref{uncond_safe}. In diffusion sampling, we utilize this safe $\mathbf{x}_{0\vert t}$ in either DDPM~\cite{ho2020denoising} or DDIM~\cite{song2020denoising}, see \algoref{safer} for details.

When our safe denoiser is combined  with the text-based guidance methods, we introduce a new set of hyperparameters $\beta_{t}$, such that we set $\beta(\mathbf{x}_{t})$ to zero if this value falls below a predefined threshold $\beta_{t}$. This condition indicates that if a sample $\mathbf{x}_{t}$ is sufficiently safe, modifying the trajectory is no longer necessary. This thresholding improves accuracy thanks to their better controllability relative to the text guidance terms.

%
%
%
%





%

%
%
%
%
