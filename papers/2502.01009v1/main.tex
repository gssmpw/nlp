\documentclass[conference]{IEEEtran}
\usepackage{times}

% numbers option provides compact numerical references in the text. 
\usepackage[numbers]{natbib}
\usepackage{multicol}
\usepackage[bookmarks=true]{hyperref}
\usepackage{gensymb}

\pdfinfo{
   /Author ()
   /Title  (Robust Trajectory Generation and Control for Quadrotor Motion Planning with Field-of-View Control Barrier Certification)
   /CreationDate (D:20250113)
   /Subject (Robots)
   /Keywords (Robots; Model Predictive Control; Control Barrier Functions)
}


% Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

% \IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

% \overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{amsmath}
\let\proof\relax
\let\endproof\relax
\usepackage{amsthm}
% \ifCLASSOPTIONcompsoc
%     \usepackage[caption=false, font=normalsize, labelfont=sf, textfont=sf]{subfig}
% \else
% \usepackage[caption=false, font=footnotesize]{subfig}
% \fi
\usepackage[font=footnotesize,labelfont=normalfont]{caption}
\usepackage{subcaption}
\usepackage{xcolor}
% \usepackage{hyperref}
% \usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{amsfonts}
\usepackage{svg}
% \usepackage{cite}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\irj}{{}^i\mathbf{r}_j}
\newtheorem{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\usepackage{changepage}
% \usepackage{IEEEtrantools}
\usepackage{siunitx}
\usepackage{tikz}

\title{Robust Trajectory Generation and Control for Quadrotor Motion Planning with Field-of-View Control Barrier Certification}

% You will get a Paper-ID when submitting a pdf file to the conference system
% \author{Paper-ID: 547}
\author{Lishuo Pan$^{1}$, Mattia Catellani$^{2}$, Lorenzo Sabattini$^{2}$, Nora Ayanian$^{1}$\\
$^{1}$Brown University, $^{2}$University of Modena and Reggio Emilia}


\begin{document}

\maketitle

\begin{abstract}
Many approaches to multi-robot coordination are susceptible to failure due to communication loss and uncertainty in estimation. We present a real-time communication-free distributed algorithm for navigating robots to their desired goals certified by control barrier functions, that model and control the onboard sensing behavior to keep neighbors in the limited field of view for position estimation. The approach is robust to temporary tracking loss and directly synthesizes control in real time to stabilize visual contact through control Lyapunov-barrier functions. The main contributions of this paper are a continuous-time robust trajectory generation and control method certified by control barrier functions for distributed multi-robot systems and a discrete optimization procedure, namely, MPC-CBF, to approximate the certified controller. In addition, we propose a linear surrogate of high-order control barrier function constraints and use sequential quadratic programming to solve MPC-CBF efficiently. We demonstrate results in simulation with 10 robots and physical experiments with 2 custom-built UAVs. To the best of our knowledge, this work is the first of its kind to generate a robust continuous-time trajectory and controller concurrently, certified by control barrier functions utilizing piecewise splines.


% We consider a distributed trajectory and control generation method certified by control barrier functions for multi-robot systems. We propose a discretized optimization similar to a model predictive control paradigm, namely, MPC-CBF to approximate a certified controller. 
% %We propose a novel framework, namely MPC-CBF, where control barrier function constraints are imposed at discretized time stamps to generate a certified controller. We propose a discretized optimization similar to a model predictive control framework, namely, MPC-CBF, to estimate the solution. 
% We propose a linear surrogate of high-order control barrier function constraints and use sequential quadratic programming to solve MPC-CBF efficiently. Our algorithm generates trajectories in continuous time. We apply our algorithm to a trajectory generation problem with field-of-view constraints for multi-robot navigation in a communication-denied area. %Our algorithm generates trajectory and control inputs in continuous time and respects the forward invariant property given field-of-view constraints. 
% %We discrete the optimization problem similar to an MPC framework and use a high-order control barrier function (HOCBF) to guarantee the field-of-view constraints. 
% We simulate with 10 robots and a representative physical experiment with 2 custom-built UAVs.
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}
Multi-robot systems, such as those used in search and rescue~\cite{drew2021multi}, active target tracking~\cite{khan2016cooperative, liu2024multi}, and collaborative transportation~\cite{li2023nonlinear}, demand real-time distributed coordination solutions robust to communication compromises for scalable and resilient operation. Communication is vulnerable to adversarial attacks and faces challenges such as dropped messages, delays, and scalability~\cite{gielis2022critical}. In contrast, onboard sensing to estimate neighbors' states is robust to compromised communication.  However, one major challenge is dealing with  imperfect perception. % capability of such sensors. 
For instance, onboard cameras have a restricted angular field of view, leading to a trade-off between task completion and neighbor detection. In addition, the sensor's reliability and uncertainty pose challenges for practical applications. For instance, a robot may lose track of a neighbor due to image blur caused by the vehicle motion or inaccurate estimation due to measurement noise. 

In this work, we present a real-time robust trajectory generation and control strategy respecting visual contact for navigation tasks in a communication-denied area for distributed multi-robot systems. To the best of our knowledge, this work is the first of its kind to generate a continuous-time trajectory and controller concurrently, certified by control barrier functions utilizing piecewise splines.  Keeping neighbors in the field of view during navigation is challenging due to the abovementioned limitations. A robust and resilient controller is essential when robot-level uncertainty, such as inaccurate estimation or dynamic model, is present or in the case when it is infeasible to track all neighbors, making compromises necessary. Our control strategy utilizes the Lyapunov-like property of specially designed control barrier functions~\cite{ames2012control} to maintain visual contact with neighbors and regain it even when experiencing temporary loss. Different from traditional optimization approaches, such as soft constraints with slack variables, our control strategy stabilizes the system towards the safe set, defined by control barrier functions, i.e., field-of-view constraints in our application. %theoretical stabilization towards the safe set.
%When the neighbors lose visual contact, an optimization-based controller with hard field-of-view constraints leads to solver failures. 
%In the case of visual contact loss due to temporary infeasibility or robot-level uncertainty, a robust strategy to regain safety, that is visual contact in our application, is essential to enhance the task success. 
%Our control strategy utilizes the Lyapunov-like property of specially designed control barrier functions to stabilize the system and regain visual contact with neighbors. Such a robust and resilient controller is essential when robot-level uncertainty is presented or in the case when it is infeasible to track all neighbors and compromises have to be made.
\begin{figure}[t]
    \centering
    % \subfloat[Execution time = 7\unit{s}]{\includegraphics[width=0.16\textwidth]{images/circle_instances/circle5_frame700.png}}
    {\includegraphics[width=0.48\textwidth]{images/fovmpc_long_exposure.pdf}}\\
    \vspace{0.15em}
    {\includegraphics[width=0.238\textwidth]{images/fov1_short.png}} \hspace{-0.55em}
    {\includegraphics[width=0.238\textwidth]{images/fov2_short.png}}
    \caption{Long exposure top view of $2$ quadrotors navigating with distributed controller respecting field-of-view Constraints (top). The red and blue triangles are the fields of view of UAV1 and UAV2, respectively. The first-person-view images of UAV1 (bottom left) and UAV2 (bottom right) are recorded. Red circles indicate the neighbor UAV in the field of view.}
    \label{fig:demo}
    % \vspace{-2em}
\end{figure}
To be concrete, we consider a trajectory generation and control problem certified by control barrier functions (CBF). We consider a double integrator model and design high-order control barrier functions (HOCBF) to maintain visual contact between robots and regain it after temporary loss when tracking all neighbors is infeasible. 
%Our algorithm generates continuous-time trajectory and control inputs to accomplish the task and provides smooth inputs to robots up to arbitrary order of derivatives. 
The proposed optimization-based control strategy requires imposing control barrier function constraints at all times on the planning horizon. %, and thus is infeasible to solve. 
To solve this problem, 
we propose a discrete optimization procedure, namely, model predictive control with control barrier functions (MPC-CBF). MPC-CBF evaluates HOCBF constraints only at discrete time stamps. 
%The proposed discrete optimization method asymptotically satisfies the forward invariance property with more sampled constraints. 
In addition, we propose a linear surrogate for HOCBF constraints and use sequential quadratic programming (SQP) to solve MPC-CBF efficiently with a quadratic programming (QP) solver. As a result, our framework generates 
%the solution to our optimization problem is 
a continuous-time trajectory and controller certified by control barrier functions in real-time that provide inputs to the system up to an arbitrary order of derivatives. The combination of a continuous-time solution and a real-time replanning capability provides fine-grained control inputs that adjust on-demand, which is particularly suitable for agile systems, such as aerial vehicles.
%The contribution of this work is defining a distributed optimal control strategy to respect visual contact for multi-robot systems. In particular, we consider continuous-time trajectory and control generation with control barrier function with application on visual contact during a navigation task
%We consider the optimal control with visual contact constraints,   
%We consider continuous-time trajectory and control generation with control barrier function with application on visual contact during a navigation task. Our method generates trajectory in continuous-time while automatically maintaining visual contact with neighbors. 
The contributions of this work can be summarized as follows:
\begin{itemize}
    \item a real-time robust distributed multi-robot control strategy that maintains visual contact between robots in communication-denied areas and tolerates temporary constraint violations during navigation;
    %continuous-time trajectory and control generation method certified by control barrier functions with application on field-of-view constraints during navigation;
    \item a continuous-time spline-based trajectory generation and control method certified by control barrier functions; and
    %discrete optimization framework, namely, MPC-CBF, to estimate the solution of the general continuous-time optimal control problem; and
    \item an optimization framework, namely MPC-CBF, that approximates the solution by constraining at the discretized time stamps, and an efficient SQP solver. %the general continuous-time optimal control problem SQP formulation to linearize the HOCBF constraints and solve MPC-CBF efficiently.
\end{itemize}
We demonstrate the algorithm's effectiveness in a representative simulation with up to $10$ robots and in physical experiments with $2$ custom-built UAVs with onboard cameras, shown in Fig.~\ref{fig:demo}.

%useful apps of multi-robot, what is the limitations. 
%why mpc-cbf. Safety with planning.
%why communication-denied, communication-limitations, fov sensor.

\section{Related Work}
Control barrier functions provide sufficient and necessary conditions for a system to guarantee safety, i.e., they satisfy a forward invariance property within a defined safe set~\cite{ames2019control}. Despite their reliable performance in tasks such as collision avoidance~\cite{abdi2023safe}, lane keeping, and adaptive cruise control~\cite{xu2017correctness}, they synthesize reactive control inputs considering only the current states. This property leads to short-sighted behaviors in complex tasks where planning is preferred. For example, the CBF-based controller leads to deadlocks in multi-robot navigation~\cite{wang2017safety}. In visual contact, reactive control inputs result in dramatic changes to robots's headings and positions and cause inefficient trajectories~\cite{catellani2023distributed} or even compromise goal-reaching capability. 
In this work, we combine trajectory planning with CBFs to overcome such short-sightedness.% and generate a trajectory and control certified by control barrier functions.

Some distributed multi-robot trajectory generation approaches, including~\cite{luis2020online, csenbacslar2023rlss, zhou2017fast}, utilize safety corridors for planning. Corridor planning is a decoupling method, as it decomposes the optimization in the joint configuration space into single-robot configuration space. Control barrier functions, compared to  decoupling methods, impose minimal conservative constraints in the optimization and significantly improve  feasibility. More importantly, incorporating control barrier functions into planning provides theoretical robustness guarantees. By robustness, we refer to the stabilization property of control Lyapunov-barrier functions~\cite{xiao2021hoclbf}, which drive the system towards the safe set, even if starting outside. We design a robust and resilient controller that tolerates temporary violation of constraints and actively stabilizes the system back to the safe set. Such a property is desired when uncertainty is present or when it is infeasible to satisfy all constraints. To the best of our knowledge, this work is the first of its kind to generate a continuous-time trajectory and controller concurrently, certified by control barrier functions utilizing piecewise splines.

There have been attempts to combine MPC with CBFs in a discrete-time formulation~\cite{liu2023iterative, zeng2021safety}. In continuous-time formulation, a multi-layer controller~\cite{sforni2024receding} solves a control sequence with CBF constraints. A spline-based trajectory generation method imposes CBF constraints by constraining robot state within polygonal cells~\cite{dickson2024spline}. However, it only solves trajectory and requires additional optimization steps for control synthesis. 
%, and it is hard to adapt a general-purpose control barrier function, such as visual contact in our scenario. 
Our continuous-time formulation solves a different problem, i.e., optimizing continuous-time piecewise spline as trajectory and obtaining control inputs concurrently. Compared to~\cite{sforni2024receding}, our approach provides additional smoothness and derivatives up to an arbitrary order, which is desired by agile robotic systems. Compared to~\cite{dickson2024spline}, our framework unifies the trajectory generation and control synthesis in one optimization problem. In addition, our framework can adapt to any control barrier functions without changing the solver. Adaptiveness to a general-purpose CBF is crucial for applications other than collision avoidance, such as visual contact in our scenario. Due to its simplicity, our approach can be applied to different robotic platforms and used as an online (real-time) navigation stack for different certification requirements.
%Our work generates continuous-time trajectory and control inputs and provides control derivatives up to an arbitrary order, which is desired by agile robotic systems, all in real time. 
Our approach has the following advantages. 1) It unifies  trajectory generation and control into one spline-based framework; control inputs can be computed directly from the trajectory. 2) It provides smooth control inputs up to an arbitrary order of derivative. 3) It adopts any general-purpose control barrier functions. 4) It delivers \emph{continuous-time} trajectory and control. Thus, we can evaluate control inputs at any time $t$ within the planning horizon. This gives us a higher granularity control of the system compared to applying a fixed input over a time step, such as in discrete MPC, thus responding better to control delays and stabilizing agile systems, such as quadrotors. 5) It does this all in real time. 

In the aforementioned multi-robot trajectory generation approaches, perfect sensing of neighbors is assumed~\cite{csenbacslar2023rlss, zhou2017fast}. Sensing uncertainty, however, is always present in the physical world. We adopt a sensing model with field-of-view constraints similar to~\cite{catellani2023distributed} and estimate neighbors' relative positions. Several solutions exist in the literature to achieve vision-based localization, from simple tag-based localization~\cite{malyuta2020long} to deep learning models~\cite{ge2022vision} or blinking UV markers~\cite{walter2019uvdar}. Due to hardware limitations, measurement uncertainty in these approaches should be carefully modeled. 


\section{Preliminaries}

\subsection{Bézier Curve}
We use piecewise splines $f(t)$ to impose smoothness requirements on the trajectory generation problem and easily obtain its derivatives up to an arbitrarily defined order.
%predictive robot position and its derivatives.  
%generated trajectory $f(t)$. 
The $i$-th Bézier curve in the piecewise splines $f_{i}: \left[ 0, \tau_{i} \right] \rightarrow \mathbb{R}^{d}$ is parameterized by time, with duration $\tau_{i}$.
%We choose the Bézier curve as the $i$-th spline $f_{i}$ as we can easily compute its derivatives up to a user-defined order. 
The Bézier curve of arbitrary degree $h$ with duration $\tau_{i}$ is defined by $h+1$ control points $\boldsymbol{\mathcal{U}}_{i} = \left[\boldsymbol{u}_{i,0};\ldots;\boldsymbol{u}_{i,h}\right]$. We first construct Bernstein polynomials $\boldsymbol{B}_{v}^{h}\in \mathbb{R}$ of degree $h$:
\begin{align}
    \boldsymbol{B}_{v}^{h} = \binom{h}{v} \left(\frac{t}{\tau}\right)^{v} \left(1-\frac{t}{\tau}\right)^{h-v}, \forall t\in \left[0,\tau\right],
\end{align}
where $v=0,1,\cdots,h$.
A $d$-dimentional Bézier curve is defined as $f_{i}(t) = \sum_{v=0}^{h}\boldsymbol{u}_{i,v}\boldsymbol{B}_{i,v}^{h}$ with $\boldsymbol{u}_{i,v}\in\mathbb{R}^{d}$. The finite set of control points $\boldsymbol{\mathcal{U}} = \left[\boldsymbol{\mathcal{U}}_{0}; \ldots; \boldsymbol{\mathcal{U}}_{P-1}\right]$ uniquely characterizes a piecewise spline of $P$ Bézier curves and acts as decision variables in our trajectory generation problem. The duration of the entire piecewise spline is $\tau = \sum_{i=0}^{P-1} \tau_{i}$.

\subsection{High-Order Control Barrier Functions}
Consider a system in the form
\begin{equation}\label{eq:system}
    \dot{\mathbf{x}} = f(\mathbf{x}) + g(\mathbf{x})\mathbf{u}
\end{equation}
where $f : \mathbb{R}^p \rightarrow \mathbb{R}^p$ and $g : \mathbb{R}^p \rightarrow \mathbb{R}^{p\times q}$ are Lispschitz continuous functions, and $\mathbf{u} \in U \subset \mathbb{R}^q$ is the control input, where $U$ is the set of admissible control values for $\mathbf{u}$. Let $\mathcal{C} := \{\mathbf{x} \in \mathbb{R}^p \mid b(\mathbf{x}) \geq 0\}$ be the set of configurations satisfying the safety requirements for the system, also known as the safe set. 
\begin{definition}[Class $\mathcal{K}$ and extended class $\mathcal{K}$ functions]\label{def:classk_fun}
A continuous function $\alpha: [0, a) \rightarrow [0, \infty)$ with $a > 0$ is a class $\mathcal{K}$ function if it is strictly increasing and $\alpha(0) = 0$. If $\alpha: \mathbb{R} \rightarrow \mathbb{R}$, then $\alpha$ is said to belong to extended class $\mathcal{K}$.
\end{definition}
\begin{definition}[CBF~\cite{ames2014control, ames2019control}]\label{def:cbf}
Given a set $\mathcal{C}$, the function $b : \mathbb{R}^n \rightarrow \mathbb{R}$ is a candidate CBF for system~\eqref{eq:system} if there exists a class $\mathcal{K}$ function
% \footnote{$\alpha : (-a,a) \rightarrow (-\infty, \infty)$ is an extended class $\mathcal{K}$ function if it is strictly increasing and $\alpha(0) = 0$.}
$\alpha$ such that
\begin{equation}\label{eq:cbf_property}
    \sup_{u\in U} [ L_fb(\mathbf{x}) + L_gb(\mathbf{x})\mathbf{u} + \alpha(b(\mathbf{x})) ] \geq 0,
\end{equation}
where $L_f$ and $L_g$ are the Lie derivatives\footnote{The Lie derivative evaluates the change of a function along a vector field (see~\cite{yano2020theory}).} along $f$ and $g$, respectively.
\end{definition}
According to CBF theory~\cite{ames2019control}, given a CBF $b$ and an associated safe set $\mathcal{C}$, any Lipschitz continuous controller $\mathbf{u}(t)$ that satisfies~\eqref{eq:cbf_property} makes the set $\mathcal{C}$ \emph{forward invariant} for system~\eqref{eq:system}, i.e., if $\mathbf{x}(t_0) \in \mathcal{C}$, then $\mathbf{x}(t) \in \mathcal{C}$, $\forall t \geq t_0$. It is important to note that the controller $\mathbf{u}(t)$ does not guarantee convergence to the set $\mathcal{C}$ if the system starts outside of it. For this reason, we introduce Control Lyapunov Functions (CLFs).
\begin{definition}[CLF~\cite{ames2012control}]\label{def:clf}
A continuously differentiable function $V : \mathbb{R}^n \rightarrow \mathbb{R}$ is a globally and exponentially stabilizing CLF for~\eqref{eq:system} if there exists a class $\mathcal{K}$ function $\zeta$ such that
\begin{equation}\label{eq:clf}
    \inf_{\mathbf{u} \in U} [ L_fV(\boldsymbol{x}) + L_gV(\mathbf{x})\mathbf{u} + \zeta(V(\mathbf{x})) ] \leq 0
\end{equation}
\end{definition}
CLFs properties ensure that a controller $\mathbf{u}(t)$ that satisfies~\eqref{eq:clf} stabilizes the system to a point $\mathbf{x}^*$ or a set~\cite{ames2012control}. 

\begin{definition}[Relative degree]\label{def:rel_degree}
The relative degree $q \in \mathbb{N}$ of a sufficiently differentiable function $b: \mathbb{R}^n \rightarrow \mathbb{R}$ with respect to a system is the number of times we need to differentiate along the system dynamics until the control input explicitly appears. 
\end{definition}
As is easy to see, if $b$ has relative degree $q > 1$ we have $L_gb(\boldsymbol{x)} = 0$, thus the control input $\boldsymbol{u}(t)$ does not show up in~\eqref{eq:cbf_property}.
HOCBFs have been developed for this kind of scenario. Recalling the work in~\cite{xiao2021high}, we consider a sequence of functions $\psi_i : \mathbb{R}^p \times [t_0, \infty] \rightarrow \mathbb{R}$, $i \in \{ 1, \dots, q  \}$ defined as
\begin{equation}\label{eq:psi}
    \psi_i(\mathbf{x}, t) = \dot\psi_{i-1} (\mathbf{x},t) + \alpha_i(\psi_{i-1}(\mathbf{x},t))
\end{equation}
where $\alpha_i(\cdot)$ are class $\mathcal{K}$ functions of their argument and $\psi_0(\boldsymbol{x},t) = b(\boldsymbol{x},t)$. In this work, we make use of time-invariant $\psi$ functions. To simplify notation, we will drop the time dependency in the rest of the paper, when not strictly necessary.

Furthermore, we define a sequence of sets $\mathcal{C}_i$, $i \in \{1, \dots, q \}$ as:
\begin{equation}\label{eq:safe_set}
    \mathcal{C}_i := \{ \mathbf{x} \in \mathbb{R}^p \mid \psi_{i-1}(\mathbf{x}) \geq 0  \}
\end{equation}
\begin{definition}[HOCBF~\cite{xiao2021high}]\label{def:hocbf}
Let $\mathcal{C}_{i}$, $i=\{1,\ldots, q\}$ be defined in~\eqref{eq:safe_set}, and $\psi_{i}$, $i=\{1,\ldots, q\}$ be defined in~\eqref{eq:psi}. A function $b : \mathbb{R}^n \rightarrow \mathbb{R}$ is a candidate HOCBF of relative degree $q$ for system~\eqref{eq:system} if there exist $(m-1)$-th order differentiable class $\mathcal{K}$ functions $\alpha_i$, $i \in \{ 1, \dots, q \}$ such that:
\begin{multline}\label{eq:hocbf_def}
    \sup_{\mathbf{u} \in U} [L_f^q b(\mathbf{x}) + L_gL_f^{q-1}b(\mathbf{x})\mathbf{u} + \frac{\partial^q b(\mathbf{x})}{\partial t^q} \\+ O(b(\mathbf{x})) + \alpha_q(\psi_{q-1}(\mathbf{x}))] \geq 0 
\end{multline}
where $O(\cdot)$ is given by
\begin{multline}
    O(b(\mathbf{x})) =\sum_{i=1}^{q-1} L_f^i ( \alpha_{q-i} \circ \psi_{q-i-1})(\mathbf{x}) \\ + \frac{\partial^i (\alpha_{q-i} \circ \psi_{q-i-1})(\mathbf{x})}{\partial t^i}
\end{multline}
\end{definition}
Similarly to traditional CBFs, any Lipschitz continuous controller $\mathbf{u} \in U$ that satisfies~\eqref{eq:hocbf_def} renders the set $\mathcal{C}_1 \cap, \dots, \cap \mathcal{C}_q$ forward invariant (see~\cite[Theorem 4]{xiao2021high}).

Finally, we introduce the notion of High Order Control Lyapunov-Barrier Function (HOCLBF) from~\cite{xiao2021hoclbf} extending the idea of HOCBF:
\begin{definition}(HOCLBF~\cite{xiao2021hoclbf})\label{def:hoclbf}
    Let $\mathcal{C}_{i}$, $i=\{1,\ldots, q\}$ be defined in~\eqref{eq:safe_set}, and $\psi_{i}$, $i=\{1,\ldots, q\}$ be defined in~\eqref{eq:psi}. A function $b: \mathbb{R}^n \rightarrow \mathbb{R}$ is a candidate HOCLBF of relative degree $q$ for system~\eqref{eq:system}, if there exist $(m-i)$-th order differentiable extended class $\mathcal{K}$ functions $\alpha_i$, $i \in \{1, \dots, q  \}$ satisfying~\eqref{eq:hocbf_def} $\forall \mathbf{x}\in \mathbb{R}^{p}$.
\end{definition}
Briefly, a HOCBF is also a HOCLBF if the functions $\alpha_i$ belong to extended class $\mathcal{K}$, i.e., they are defined and strictly increasing in $\mathbb{R}$. Given the HOCLBF $b(\mathbf{x})$ with the associated set $\mathcal{C}:=\mathcal{C}_1 \cap, \dots, \cap \mathcal{C}_q$ defined in~\eqref{eq:safe_set}, if $\mathbf{x}(t_0)\in \mathcal{C}$, then any Lipschitz continuous controller $\mathbf{u}(t)\in U$ that satisfies~\eqref{eq:hocbf_def}, $\forall t\geq t_0$ renders the set $\mathcal{C}_1 \cap, \dots, \cap \mathcal{C}_q$ forward invariant. Otherwise, any Lipschitz continuous controller $\mathbf{u}(t)\in U$ that satisfies~\eqref{eq:hocbf_def}, $\forall t\geq t_0$ stabilizes system~\eqref{eq:system} to the set $\mathcal{C}:=\mathcal{C}_1 \cap, \dots, \cap \mathcal{C}_q$ (see~\cite[Theorem 2]{xiao2021hoclbf}).
\section{Problem Formulation}
Consider $N$ homogeneous robots in a communication-denied workspace $\mathcal W$. We denote $\mathcal{R}(\mathbf{r}_{i})$ as the convex set of points representing robot $i$ at position $\mathbf{r}_{i}\in \mathbb{R}^{3}$. 
%We denote the $i$-th robot as $r_{i}$. 
Robots generate trajectories and control inputs in a receding horizon fashion to navigate toward individual goal positions while maintaining visual contact and collision avoidance with each other without sharing information. A robot, however, can estimate the positions of others using an onboard camera when they are within its camera field of view. 
Our algorithm synthesizes a continuous-time trajectory and obtains control inputs concurrently based on optimization. The objective is to minimize the control effort, i.e., the weighted sum of the integral of the square of the norm of derivatives, and the distance to the desired goal state. The generated trajectory and control respect the system dynamics, initial state, state safety, control continuity, and control barrier functions certifications. %Our method can generate control inputs in continuous time certified by control barrier functions. %, which enhance the stability of the system and reduce delay in response. 
%Generated trajectory and control inputs trade-off between reaching goals and maintaining visual contacts while avoiding collision with neighbors. 

\subsection{Robot model}
\label{sec:robot_model}
%The quadrotor dynamics with position $\mathbf{r}$ and yaw $\psi$ inputs is \textit{differential flat}~\cite{mellinger2011minimum}. 
We represent the robot state as its position, yaw, and their first order derivatives $\mathbf{x} = [\mathbf{r}; \phi; \dot{\mathbf{r}}; \dot{\phi}]\in \mathbb{R}^{8}$, here $\mathbf{r}\in \mathbb{R}^{3}$ and $\phi \in \mathbb{R}$. The system output is $\mathbf{y} = [\mathbf{r}; \phi]\in \mathbb{R}^{4}$. We denote velocity by $\mathbf{v} = [\dot{\mathbf{r}}; \dot{\phi}] \in \mathbb{R}^{4}$. We model the system as a double integrator,
\begin{align}\label{eq:dynamics}
    \dot{\mathbf{x}} &= A\mathbf{x} + B\mathbf{u},
    % \mathbf{y} &= D\mathbf{x},
\end{align}
where the control input $\mathbf{u} = [\mathbf{u}_{r}; \mathbf{u}_{\phi}] \in \mathbb{R}^{4}$ is the acceleration. Due to the system physical limits, we define minimum acceleration $\mathbf{a}_{min}\in\mathbb{R}^{3}$, maximum acceleration $\mathbf{a}_{max}\in\mathbb{R}^{3}$, minimum velocity $\mathbf{v}_{min}\in\mathbb{R}^{3}$, and maximum velocity $\mathbf{v}_{max}\in\mathbb{R}^{3}$ respectively. $A = [\mathbf{0}, \mathbf{I}; \mathbf{0}, \mathbf{0}] \in \mathbb{R}^{8\times 8}$, $B = [\mathbf{0}; \mathbf{I}] \in \mathbb{R}^{8\times 4}$, 
%$D = [\mathbf{I}, \mathbf{0}]\in \mathbb{R}^{4\times 8}$, 
where $\mathbf{0} \in \mathbb{R}^{4\times 4}$ is the zero matrix and $\mathbf{I} \in \mathbb{R}^{4\times 4}$ is the identity matrix. At replanning time $t_{0}$, our method generates a reference trajectory $\mathbf{x}(t|t_{0})$, for any time $t$ in a finite horizon $\tau$, and obtains the optimal control inputs $\mathbf{u}(t)$ concurrently.
%optimal control inputs $\mathbf{u}(t)$ given anytime $t$ in a finite horizon $\tau$ and a trajectory $\mathbf{x}(t)$. 
We assume the robots are equipped with a controller to track the generated reference trajectory.
\subsection{Sensing model}
We consider each robot to have sensing capabilities provided by an onboard camera facing the direction of the inertial $x$-axis of the robot. 
% The sensing region can be seen as a pyramid whose apex is the robot's current position $\mathbf{r}$, the height is equal to the sensing range $R_s \in \mathbb{R}_+$, and two angles $\beta_H, \beta_V \in [0, 2\pi)$ indicate the horizontal and vertical field of view, respectively. 
We model the sensing region as a truncated conical volume as shown in Fig.~\ref{fig:sensing_model}. This polytope is limited by a maximum range $R_s \in \mathbb{R}_{>0}$, indicating the maximum distance the sensor can observe, and a minimum distance from the robot $D_s \in \mathbb{R}_{>0}$, indicating the minimum distance the target must keep from the robot. Two angles $\beta_H, \beta_V \in [0, 2\pi)$ determine how the polytope is spread in space, indicating the horizontal and vertical fields of view, respectively.
We will refer to the polytope indicating the field of view of robot $i$ as $\mathcal{F}_i$. We assume that robots are able to detect and localize their neighbors when they are inside the field of view. The information gathered by robot $i$ about one of its neighbors, robot $j$, is the position $\mathbf{r}_{j}$ relative to robot $i$'s inertial reference frame, which we will denote as $\irj = \mathbf{r}_j - \mathbf{r}_i$. In addition, we also consider measurement uncertainty as a zero-mean Gaussian noise, characterized by a multivariate normal distribution. We indicate the associated covariance matrix as $R_{\mathrm{m}} \in \mathbb{R}^{3\times 3}$.

\begin{figure}[t]
    \centering
    \subfloat[The robot's sensing region]
    {\includegraphics[width=0.315\textwidth]{images/fovmpc_fov_ai.pdf}}\hspace{0.1em}
    \subfloat[Sensing region top view]
    {\includegraphics[width=0.163\textwidth]{images/fovmpc_fov_topview_ai_new.pdf}}
    \caption{The sensing region $\mathcal{F}$ of a robot is modeled as truncated conical volume. $\beta_{H}$, $\beta_{V}$ are the horizontal and vertical field of view angles. $R_{s}$ is the sensing range and $D_{s}$ is the safety distance between robots. 
    The blue volume is the region where the neighbor can be safely detected without collision. The red plane is a cross-section of such a region in 2D.
    }
    \label{fig:sensing_model}
    % \vspace{-2em}
\end{figure}

\section{HOCBFs Design}
We consider CBF certifications for a robot to maintain safety distance, visual contact, and maximum distance with its neighbors. We formulate the following constraints for robot $i$ in the form 
% $b_{i, c}({}^i\mathbf{r}_j) \geq 0$, where $i,j \in \mathbb{N}, i\neq j$ refer to the $i$-th and $j$-th robot,
$b(\irj) \geq 0$, $\forall j\in \mathcal{N}_{i}$. Here, we denote the neighbors (all other robots) of robot $i$ as $\mathcal{N}_{i}$.
% \textcolor{blue}{and $c = 0, \dots, C$, with $C \in \mathbb{N}$ being the total number of constraints}.
It is easy to see that $b$ has a relative degree $q=2$ with respect to system dynamics~\eqref{eq:dynamics} according to Definition~\ref{def:rel_degree}. Therefore, we use HOCBFs to guarantee constraints satisfaction. 
% In addition, we assume robots fly at the same constant altitude $\overline{z} \in \mathbb{R}$. 
To simplify the discussion, we only focus on 2D motion, which can be applied to ground robots or aerial vehicles that fly at the same constant altitude. 
Thus, the sensing region is a planar angular sector defined by $\beta_H$ (see Fig.~\ref{fig:sensing_model}b), and the position of robot $j$ relative to robot $i$ can be expressed as ${}^i\mathbf{r}_j = [{}^ix_j; {}^iy_j; 0]$. The safety distance and range HOCBFs are defined as follows:
%Given the aforementioned safety requirements, we can formulate the HOCBFs $b$ for robot $i$ as:
\begin{align}
    &b_{\mathrm{sr}}({}^i\mathbf{r}_j) = \begin{bmatrix}
        {}^ix_j & {}^iy_j \\
        -{}^ix_j & -{}^iy_j
    \end{bmatrix} \begin{bmatrix}
        {}^ix_j \\ {}^iy_j
    \end{bmatrix} + \begin{bmatrix}
        -D_{s}^{2} \\ R_s^2
    \end{bmatrix} , \forall j \in \mathcal{N}_{i},
\end{align}

We extended the field-of-view CBFs in~\cite{bertoncelli2024directed} to include the scenarios when $\beta\in [\pi,2\pi)$ and our HOCBFs are defined as follows:
% \begin{align}
% &\text{if } \beta_{H}\in[0, \pi): \nonumber \\
%     &b_{\mathrm{fov}}({}^i\mathbf{r}_j) = \begin{bmatrix}
%         \tan(\beta_H/2) & 1 \\
%         \tan(\beta_H/2) & -1
%     \end{bmatrix} \begin{bmatrix}
%         {}^ix_j \\ {}^iy_j
%     \end{bmatrix} + \begin{bmatrix}
%         0 \\ 0
%     \end{bmatrix} \geq 0, \forall j \in \mathcal{N}_{i},\\
% &\text{if } \beta_{H} = \pi: \nonumber \\
%     &b_{\mathrm{fov}}({}^i\mathbf{r}_j) = \begin{bmatrix}
%         1 & 0
%     \end{bmatrix} \begin{bmatrix}
%         {}^ix_j \\ {}^iy_j
%     \end{bmatrix} +
%         0 \geq 0, \forall j \in \mathcal{N}_{i},\\
% &\text{if } \beta_{H}\in(\pi, 2\pi), {}^iy_j\geq 0: \nonumber \\
%     &b_{\mathrm{fov}}({}^i\mathbf{r}_j) = \begin{bmatrix}
%         \tan(\pi - \frac{\beta_H}{2}) & 1
%     \end{bmatrix} \begin{bmatrix}
%         {}^ix_j \\ {}^iy_j
%     \end{bmatrix} + 
%          0  \geq 0, \forall j \in \mathcal{N}_{i},\\
% &\text{if } \beta_{H}\in(\pi, 2\pi), {}^iy_j < 0: \nonumber \\
%     &b_{\mathrm{fov}}({}^i\mathbf{r}_j) = \begin{bmatrix}
%         \tan(\pi - \frac{\beta_H}{2}) & -1
%     \end{bmatrix} \begin{bmatrix}
%         {}^ix_j \\ {}^iy_j
%     \end{bmatrix} + 
%         0  \geq 0, \forall j \in \mathcal{N}_{i},
% \end{align}
\begin{align}
    &b_{\mathrm{fov}}({}^i\mathbf{r}_j) = \nonumber \\
    &\begin{cases}
    \begin{bmatrix}
        \tan(\beta_H/2) & 1 \\
        \tan(\beta_H/2) & -1
    \end{bmatrix} \begin{bmatrix}
        {}^ix_j \\ {}^iy_j
    \end{bmatrix} 
    %+ \begin{bmatrix} 0 \\ 0 \end{bmatrix} 
    ,  \!&\text{if } \beta_{H}\in[0, \pi)\\
    \begin{bmatrix}
        1 & 0
    \end{bmatrix} \begin{bmatrix}
        {}^ix_j \\ {}^iy_j
    \end{bmatrix} 
    %+ 0 
        ,  &\text{if } \beta_{H} = \pi\\
    \begin{bmatrix}
        \tan(\pi - \frac{\beta_H}{2}) & 1
    \end{bmatrix} \begin{bmatrix}
        {}^ix_j \\ {}^iy_j
    \end{bmatrix} 
    % + 0 
         , &\text{if } \beta_{H}\in(\pi, 2\pi),\\ &{}^iy_j\geq 0\\
    \begin{bmatrix}
        \tan(\pi - \frac{\beta_H}{2}) & -1
    \end{bmatrix} \begin{bmatrix}
        {}^ix_j \\ {}^iy_j
    \end{bmatrix} 
    % + 0 
        , &\text{if } \beta_{H}\in(\pi, 2\pi),\\ &{}^iy_j < 0
    \end{cases}
\end{align}
Our HOCBF constraints are the combination of safety distance, range, and the field-of-view constraints, defined as:
\begin{align}\label{eq:hocbf_formulation}
    &b({}^i\mathbf{r}_j) = \left[b_{\mathrm{sr}}({}^i\mathbf{r}_j); b_{\mathrm{fov}}({}^i\mathbf{r}_j)\right] \geq 0, \forall j \in \mathcal{N}_{i}
\end{align}

where the first and second rows constrain the distance to robot $j$ to be greater or equal to a safety distance $D_s$ and smaller or equal to the sensing range $R_s$, while the last two (or one) rows force robot $j$ to be inside the angular sector defining the field of view of robot $i$.
% In order for $b$ to be an HOCBF for~\eqref{eq:dynamics}, choosing $(2\mu+1)$-th grade extended class $\mathcal{K}$ functions $\alpha_1(b({}^i\mathbf{r}_j)) = \gamma_1 b^{(2\mu+1)}({}^i\mathbf{r}_j) $ and $\alpha_2(\psi_1({}^i\mathbf{r}_j)) = \gamma_2\psi_1^{(2\mu+1)}({}^i\mathbf{r}_j)$, where $\mu\in \mathbb{N}$, a control input $\mathbf{u}$ must satisfy:
Choosing $\alpha_1(b({}^i\mathbf{r}_j)) = \gamma_1 b^{(2\mu+1)}({}^i\mathbf{r}_j) $ and $\alpha_2(\psi_1({}^i\mathbf{r}_j)) = \gamma_2\psi_1^{(2\mu+1)}({}^i\mathbf{r}_j)$, for $\mu \in \mathbb{N}$, we can rewrite~\eqref{eq:hocbf_def} as:
\begin{multline}\label{eq:hocbf_input}
    L_f^2b(\cdot) + L_gL_fb(\cdot)\mathbf{u} + (2\mu+1)\gamma_1b^{2\mu}(\cdot)L_fb(\cdot) \\+ \gamma_2(L_fb(\cdot) + \gamma_1b^{(2\mu+1)}(\cdot))^{(2\mu+1)} \geq 0.
\end{multline}

We can simplify the above equation in the linear form of control input $\mathbf{u}$, % given the relative position ${}^{i}\mathbf{r}_{j}$,

\begin{align}\label{eq:HOCBF_constraints}
    L_gL_fb\mathbf{u} + \lambda(b) \geq 0,
\end{align}
where $\lambda(b) = L_f^2b + (2\mu+1)\gamma_1b^{2\mu}L_fb + \gamma_2(L_fb + \gamma_1b^{(2\mu+1)})^{(2\mu+1)}$.
Remarkably, the choice of $\alpha_1(b({}^i\boldsymbol{r}_j))$ and $\alpha_2(\psi_1(\irj))$ as odd power functions of $b(\irj)$ 
% is necessary to guarantee that they are strictly increasing, as required by extended class $\mathcal{K}$ functions properties.
makes them strictly increasing in $\mathbb{R}$, thus belonging to extended class $\mathcal{K}$ functions according to Def.~\ref{def:classk_fun}.
% carries the system inside the safe set $\mathcal{C}$ when outside.
For this reason, the designed HOCBF~\eqref{eq:hocbf_formulation} is also a HOCLBF (see Def.~\ref{def:hoclbf}) and brings the system back into the safe set $\mathcal{C}$ when outside.
% \begin{theorem}\label{th:cbf-clf}
% % The designed HOCBF~\eqref{eq:hocbf_input} carries the system inside the safe set $\mathcal{C}$ if it starts outside.
% Given the designed HOCBF~\eqref{eq:hocbf_formulation} with the associated sets $\mathcal{C}_1, \mathcal{C}_2$ defined by~\eqref{eq:safe_set}, if $ \mathbf{x}(0) \notin \mathcal{C}_1 \cap \mathcal{C}_2$, then any Lipschitz continuous controller $\mathbf{u}(t)$ that satisfies~\eqref{eq:HOCBF_constraints}, $\forall t \geq 0$ stabilizes the system to $\mathcal{C}_1 \cap \mathcal{C}_2$.
% \end{theorem}

\begin{theorem}\label{th:cbf-clf-version2}
Consider the HOCBF in~\eqref{eq:hocbf_formulation}, $\psi_{0}$ and $\psi_{1}$ defined in~\eqref{eq:psi} with the associated set $\mathcal{C}:=\mathcal{C}_1 \cap \mathcal{C}_2$ defined by~\eqref{eq:safe_set}. Let $\alpha_{i}$, for $i=\{1,2\}$, be differentiable extended class $\mathcal{K}$ functions. If $\mathbf{x}(t_0)\in \mathcal{C}$, then any Lipschitz continuous controller $\mathbf{u}(t)$ that satisfies~\eqref{eq:HOCBF_constraints} $\forall t\geq t_0$ renders $\mathcal{C}$ forward invariant for system~\eqref{eq:dynamics}. Otherwise, any Lipschitz continuous controller $\mathbf{u}(t)$ that satisfies~\eqref{eq:HOCBF_constraints} $\forall t\geq t_0$ stabilizes system~\eqref{eq:dynamics} to the set $\mathcal{C}$. 
\end{theorem}

 %with a differentiable extended class $\mathcal{K}$ function $\alpha_{q}$

\begin{proof}
% Let us consider the condition $b(^{i}\mathbf{r}_{j}) < 0$, indicating that the system's current state is not within the safe set $\mathcal{C}$. We want to show that the constraint~\eqref{eq:hocbf_input} forces the input $\mathbf{u}$ to drive $b(^{i}\mathbf{r}_{j})$ toward positive values over time, thus carrying the system within the safe set $\mathcal{C}$.
% We can rewrite~\eqref{eq:hocbf_input} as:
% \begin{equation}\label{eq:hocbf_constr}
%     L_gL_fb\mathbf{u} \geq -(L_f^2b + 3\gamma_1b^2L_fb + \gamma_2(L_fb + \gamma_1b^3)^3  )
% \end{equation}
% It is easy to see that $L_fb > 0$ implies $b$ is increasing toward positive values. Instead, when $L_fb \leq 0$, the constraint~\eqref{eq:hocbf_constr} forces $L_fL_gb\mathbf{u}$ to be large enough to counteract any negative contributions from $L_f^2b$ and the non-linear terms, leading to the definition of a control input $\mathbf{u}$ that makes $L_fb$ positive, thus pushing $b$ toward positive values.
% As is easy to see, the safe set $\mathcal{C}$ is compact and the system~\eqref{eq:dynamics} is forward complete. Thus, from~\cite[Remark 2]{tan2021high}, it follows that the safe set $\mathcal{C}$ defined by the HOCBF~\eqref{eq:hocbf_input} is asymptotically stable.
The proof for the case $\mathbf{x}(t_0) \in \mathcal{C}$ comes directly from HOCBF properties as stated in Def.~\ref{def:hocbf} and shown in~\cite[Theorem 4]{xiao2021high}. 
% Instead, following the proof in~\cite[Theorem 2]{xiao2021hoclbf}, if $ \mathbf{x}(t_0) \notin \mathcal{C}$ we can define a function $V(\irj) = -\psi_{i-1}(\irj)$, $i \in \{1, 2\}$. 
Instead, if $\mathbf{x}(t_0) \notin \mathcal{C}$, we can follow the proof in~\cite[Theorem 2]{xiao2021hoclbf}, making use of CLFs properties~\cite{ames2012control}. First, we note that the HOCBF condition~\eqref{eq:hocbf_def} translates into $\psi_q(\irj) \geq 0$, which, in our case ($q=2$), can be calculated from~\eqref{eq:psi} as:
\begin{equation}\label{eq:psi2_condition}
    \psi_2(\irj) = L_f\psi_1(\irj) + L_g\psi_1(\irj)\mathbf{u} + \alpha_2(\psi_1(\irj)) \geq 0.
\end{equation}
Then, we define a function $V_2(\irj) = -\psi_1(\irj)$, thus~\eqref{eq:psi2_condition} becomes:
\begin{equation}
    L_fV_2(\irj) + L_gV_2(\irj)\mathbf{u} + \alpha_2(V_2(\irj)) \leq 0.
\end{equation}
% By the CLFs properties from~\cite{ames2012control}, if there exists a controller $\mathbf{u}(t) \in U$ that satisfies $\psi_i(\irj) \geq 0$, $\forall t$, then the system will be stabilized to the set $\mathcal{C}_i$.\\
% Stabilization to the set $\mathcal{C}_i$ requires the controller $\mathbf{u}(t)$ to satisfy $\psi_i(\irj) \geq 0$.
% Let us consider the case $i=1$. The condition $\mathbf{x} \notin \mathcal{C}_1$ translates into $b(\irj) < 0$. We define $V(\irj) = -\psi_0(\irj) = -b(\irj) > 0$. Since $q=1$, we can use the CBF constraint~\eqref{eq:cbf_property}, which becomes:
% % \begin{equation}
% %     \psi_1(\irj) = \dot{b}(\irj) + \gamma_1b(\irj)^{2\mu+1} > 0
% % \end{equation}
% \begin{equation}
%     L_fV(\irj) + L_gV(\irj)\mathbf{u} + \alpha(V(\irj)) \leq 0.
% \end{equation}
It is easy to see that this equation is equivalent to~\eqref{eq:clf} if we take $\zeta = \alpha_2$, thus $V_2(\irj)$ is a CLF for the system and stabilizes it to the set $\mathcal{C}_2$. 
% Convergence to $\mathcal{C}_1$ can be proved in the same way,
Convergence to $\mathcal{C}_1$ comes as a consequence once the system has converged to $\mathcal{C}_2$, since $\mathbf{x}(t) \in \mathcal{C}_2$ implies $\psi_1(\irj) \geq 0$ from~\eqref{eq:safe_set}. Following the same approach as before, and recalling $\psi_0(\irj) = b(\irj)$, we can write
\begin{equation}
    \psi_1(\irj) = L_fb(\irj) + L_gb(\irj)\mathbf{u} + \alpha_1(b(\irj)) \geq 0
\end{equation}
and we can define another function $V_1(\irj) = -b(\irj)$, obtaining another CLF stabilizing the system to $\mathcal{C}_1$.
As a consequence, the system~\eqref{eq:dynamics} will be stabilized to $\mathcal{C} := \mathcal{C}_1 \cap \mathcal{C}_2$.
\end{proof}
This property is essential for a robust controller that can tolerate constraint violations and stabilize the system toward to safe set when outside. In our application, this property allows robots to regain visual contact with its neighbors after temporary tracking loss.

\section{Neighbor Position Estimation}\label{sec:pf}
In this section, we describe how each robot estimates its neighbors' positions in the absence of a direct measurement, and how the estimate is refined when measurements are obtained. For this purpose, we make use of the solution presented in~\cite{catellani2023distributed}, where a particle filtering state estimator algorithm is used to track every other robot in the team. Briefly, the probability distribution of $\mathbf{r}_j$ is represented by a set of $N_{p} \in \mathbb{N}$ particles, with the $k$-th particle $\boldsymbol{\rho}_{j}^{k} \in \mathbb{R}^3$ indicating a hypothesis of the real position $\mathbf{r}_{j}$. The filtering algorithm iteratively runs through the following steps:
\begin{enumerate}
    \item \emph{Prediction}: 
    % The dynamic model~\eqref{eq:dynamics} is applied to every particle. Since the robot $i$ lacks information on robot $j$'s current control input, we assume it to be zero and add a noise term $\boldsymbol{\eta} \in \mathbb{R}^3$ to account for increased uncertainty.
    Predicting the evolution of each particle $\boldsymbol{\rho_j^k}$ would require access to robot $j$'s current velocity, which robot $i$ lacks. For this reason, 
    % we consider the velocity to be zero, and add a noise term $\boldsymbol{\eta} \in \mathbb{R}^3$ to account for increased uncertainty. 
   each particle is propagated from its initial position, adding a random noise term 
   $\boldsymbol{\eta} \sim \mathcal{N}(\mathbf{0}, \Sigma_{\mathrm{p}})$, with $\Sigma_{\mathrm{p}} \in \mathbb{R}^{3\times3}$, to account for possible motion in any direction:
   % $\boldsymbol{\eta} \in \mathbb{R}^3$ 
    \begin{equation}\label{eq:pf_pred}
        \boldsymbol{\rho}_j^k(t) = \boldsymbol{\rho}_j^k(t-1) + \boldsymbol{\eta}.
    \end{equation}
    \item \emph{Weight Update}: When a measurement of the relative position, namely $\boldsymbol{o}_j \in \mathbb{R}^3$, is received, the weight of each particle is updated according to the measurement's likelihood given the current state and the measurement uncertainty $R_{\mathrm{m}}$:
    \begin{equation}\label{eq:pf_update}
        w_j^k(t) = p(\boldsymbol{o}_j(t) | \boldsymbol{\rho}_j^k(t)).
    \end{equation}
    \item \emph{Particles Penalty}: if robot $i$ does not detect robot $j$, particles inside $\mathcal{F}_i$ are penalized by reducing their weight by a factor $\varepsilon \in [0, 1)$:
    \begin{equation}\label{eq:pf_del}
        w_j^k(t) \leftarrow \varepsilon w_j^k(t) \quad \text{if $\boldsymbol{\rho}_j^k(t) \in \mathcal{F}_i$} .
    \end{equation}
    Differently from~\cite{catellani2023distributed}, we do not completely remove particles in order to account for missed detection.
    \item \emph{Resampling}: Particles are resampled based on their weights to focus on regions with high probabilities.
    \item \emph{Position Estimation}: An estimate $\hat{\mathbf{r}}_j \in \mathbb{R}^3$ for the ground truth position $\mathbf{r}_j$ is calculated as a weighted sum of the samples:
    \begin{equation}\label{eq:pf_estim}
        \hat{\mathbf{r}}_j(t) = \frac{\sum_{k=1}^{N_p} w_j^k(t) \boldsymbol{\rho}_j^k(t)}{\sum_{k=1}^{N_p} w_j^k(t)}.
    \end{equation}
    Additionally, the estimate uncertainty can be evaluated as the covariance matrix $R_{\mathrm{cov}} \in \mathbb{R}^{3\times 3}$ of particles' distribution.
    
\end{enumerate}

\section{Trajectory Generation and Control with Control Barrier Certification}
\label{sec:mpc_cbf}
We solve the continuous-time trajectory and control generation concurrently with parametric curve representation. 
%A Bézier curve defined by $h+1$ control points can compute its derivatives up to $h$-th order.
Our optimization problem solves for the piecewise $h$-th order Bézier curves.  The solution to our dynamics in~\eqref{eq:dynamics}, or trajectory, is defined as the piecewise Bézier curves and their first-order derivatives. The control inputs $\mathbf{u}(t)$ are defined as the second derivative of the piecewise Bézier curves.
%, and the trajectory $f(t)$ consists of the curve and its first derivative.
We choose a sufficiently large $h$ to generate control $\mathbf{u}(t)$. As reported in~\cite{mellinger2011minimum}, a trajectory minimizing the integral of the square of the norm of derivatives up to snap is desired for aerial vehicles. To satisfy the visual contact requirement, we impose the HOCBF constraints in~\eqref{eq:HOCBF_constraints}, for any given $t$ in the horizon.

The general form of our problem solves trajectory generation and control certified by control barrier functions and can be formulated as follows:
\begin{subequations}
\begin{IEEEeqnarray}{rCl'rCl}
\argmin_{\boldsymbol{\mathcal{U}}} 
% &~& \mathcal{J}_{energy} + \mathcal{J}_{goal} \label{eq:general_cost}\\
&~& \mathcal{J}_{\mathrm{cost}} \label{eq:general_cost}\\
\text{s.t.} 
&~& \dot{\mathbf{x}}(t) = A\mathbf{x}(t) + B{\mathbf{u}(t)} \label{eq:model_constraint}\\
%&~& \mathbf{x} \in \mathcal{X}_{\text{safe}} \label{eq:general_ineq_constraint}\\
&~& \frac{d^j f(0)}{dt^j} = \frac{d^j \mathbf{r}(t_{0})}{dt^j} , ~\forall j \in\{0, \ldots, C\} %f(0) = \mathbf{x}(t_{0}),
\label{eq:general_initial_state_constraint}\\
&~& f \text{ continuous up to derivative } C \label{eq:general_continuity_constraint}\\
% &~& A\mathbf{u}(t) + \boldsymbol{b}({}^{i}\mathbf{r}_{j}) \geq 0, \forall t \label{eq:general_qp_cbf}\\
&~& \begin{aligned} A^{\mathrm{cbf}}\mathbf{u}(t) + \boldsymbol{b}^{\mathrm{cbf}}({}^{i}\hat{\mathbf{r}}_{j}(t|t_{0})) \geq 0, ~&\forall t\!\in\! [t_{0}, t_{0}\!+\!\tau] \\ & \forall j \!\in\! \mathcal{N}_{i} \end{aligned} \label{eq:general_qp_cbf}\\
&~& \mathbf{a}_{min} \preceq \mathbf{u}(t) \preceq \mathbf{a}_{max}, ~\forall t\!\in\! [t_{0}, t_{0}\!+\!\tau]\\
&~& \mathbf{v}_{min} \preceq \mathbf{v}(t) \preceq \mathbf{v}_{max}, ~\forall t\!\in\! [t_{0}, t_{0}\!+\!\tau],
\end{IEEEeqnarray}
\end{subequations}
where $\preceq$ stands for element-wise less or equal to, $\mathcal{J}_{\mathrm{cost}}$ is the sum of objectives we will define in Sec.~\ref{sec:cost_functions}. $t_{0}$ is the current time stamp, $C$ is the highest order of derivatives required for continuity. 
%$\mathcal{X}_{\text{safe}}$ refers to the set of states the robot is safe when operating within. %$\mathcal{N}_{i}$ is the neighboring robots of robot $r^{i}$.
The constraint~\eqref{eq:general_qp_cbf} is equivalent to~\eqref{eq:HOCBF_constraints}, where $A^{\mathrm{cbf}} = L_gL_fb$, $\boldsymbol{b}^{\mathrm{cbf}} = \lambda(b)$. As we plan the trajectory in a communication-denied setting, we can only obtain the relative position based on the current estimated $\hat{\mathbf{r}}_{j}(t_{0})$, i.e., ${}^{i}\hat{\mathbf{r}}_{j}(t|t_{0}) = \hat{\mathbf{r}}_{j}(t_{0}) - \mathbf{r}_{i}(t)$. 


\begin{theorem}
Consider the HOCBF in~\eqref{eq:hocbf_formulation}, $\psi_{0}$ and $\psi_{1}$ defined in~\eqref{eq:psi} with the associated set $\mathcal{C}:=\mathcal{C}_1 \cap \mathcal{C}_2$ defined by~\eqref{eq:safe_set}. Let $\alpha_{i}$, for $i=\{1,2\}$, be differentiable extended class $\mathcal{K}$ functions. If $\mathbf{x}(t_0)\in \mathcal{C}$, the control inputs $\mathbf{u}(t)$ obtained from~\eqref{eq:general_cost}, $\forall t\in [t_{0},t_{0}+\tau]$ render $\mathcal{C}$ forward invariant. Otherwise, the solution $\mathbf{u}(t)$ in~\eqref{eq:general_cost}, $\forall t\in [t_{0},t_{0}+\tau]$ stabilizes system~\eqref{eq:dynamics} towards the set $\mathcal{C}$. %The system satisfies safety requirements, i.e., the forward invariance property, when applying control inputs generated from~\eqref{eq:general_cost}-\eqref{eq:general_qp_cbf}.
\end{theorem}
\begin{proof}
The solution $\mathbf{u}(t)$ is Lipschitz continuous since it is defined as the second-order derivative of the optimized Bézier curve in~\eqref{eq:general_cost}. 
The constraint~\eqref{eq:model_constraint} requires the state transition to obey the system model in~\eqref{eq:dynamics}. The constraint~\eqref{eq:general_qp_cbf} is the high-order control barrier function defined in~\eqref{eq:HOCBF_constraints}. Control inputs $\mathbf{u}(t)$ satisfy the HOCBF condition at all $t$. The proof follows directly from Theorem 1.  
%condition for the double integrator model to satisfy the forward invariance property at time $t$. 
%We impose constraints~\eqref{eq:general_qp_cbf} at all time $t$ for control inputs $\mathbf{u}(t)$. Thus, the generated control inputs $\mathbf{u}(t)$ obey the forward invariance property for the double integrator and maintain the system within the safe set $\mathcal{C}$ for all time $t$ if $\mathbf{x}(t_0) \in \mathcal{C}$, otherwise they bring it inside the safe set $\mathcal{C}$ thanks to the Lyapunov-like property.
\end{proof}

Theorem 2 proves that the generated trajectory and control are certified by control barrier functions, i.e., maintain the system within the safe set $\mathcal{C}$ when starting within; otherwise, drive the system toward the safe set $\mathcal{C}$. 
However, solving the above optimization directly is impractical as~\eqref{eq:general_qp_cbf} introduces an infinite number of constraints. Without losing a continuous-time solution, we propose a discrete optimization procedure to approximate the solution, depicted in Fig.~\ref{fig:mpc-cbf}. Instead of evaluating the constraints~\eqref{eq:general_qp_cbf} for all time $t$ in the horizon, our approach applies the HOCBF constraints only at evenly sampled discrete time stamps along the trajectory. We adopt a receding horizon control approach, i.e., the algorithm predicts a trajectory in a horizon $\tau$ and executes the trajectory in the first sampled discrete time step. Since the proposed optimization procedure acts similarly to an MPC with continuous-time control inputs, we name our algorithm model predictive control with control barrier functions, or MPC-CBF for short. %In the following sections, we elaborate on the discrete optimization scheme and its continuous-time solution. 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{images/MPC-CBF.pdf}
    \caption{The white triangle is the robot's current state, the red dot is its goal state, and the blue triangles are the predicted camera field of views along the trajectory. The MPC-CBF samples at discrete time stamps along the predicted trajectory and imposes HOCBF constraints only at sampled time. Our approach optimizes Bézier curves and obtains trajectory and control inputs from it.}
    \label{fig:mpc-cbf}
\end{figure}
% \vspace{-2.5em}
%\textcolor{blue}{state prediction model, use discrete double integrator, not the Bézier, because we want to optimize the control, Bézier MPC formulation.}
\subsection{Trajectory and Control Prediction Model}
We introduce the notation $\hat{(\cdot)}(k|t_{0})$, which represents the prediction of $(\cdot)(k|t_{0})$, given information at time $t_{0}$ and horizon $k \in \{0, \cdots, K-1\}$, where $(K - 1)\delta = \tau$. Here $\delta$ is the duration of each discrete time step. The prediction model of system output and its derivatives are given by

\begin{align}
    \hat{\mathbf{y}}(k|t_{0}) &= \sum_{v=0}^{h}\boldsymbol{u}_{j,v}\boldsymbol{B}_{j,v}^{h}(k\delta - \sum_{i=0}^{j-1}\tau_{i})\label{eq:bezier_position},\\
    \hat{\mathbf{v}}(k|t_{0}) &= \sum_{v = 0}^{h-1} \boldsymbol{u}^{(1)}_{j,v} \boldsymbol{B}_{j,v}^{h-1}(k\delta - \sum_{i=0}^{j-1}\tau_{i})\label{eq:bezier_velocity},\\
    \hat{\mathbf{u}}(k|t_{0}) &= \sum_{v = 0}^{h-2} \boldsymbol{u}^{(2)}_{j,v} \boldsymbol{B}_{j,v}^{h-2}(k\delta - \sum_{i=0}^{j-1}\tau_{i})\label{eq:bezier_control},
\end{align}
where $\boldsymbol{u}_{j,v}^{(1)} = h(\boldsymbol{u}_{j,v+1} - \boldsymbol{u}_{j,v})$, and $\boldsymbol{u}_{j,v}^{(2)} = (h-1)(\boldsymbol{u}_{j,v+1}^{(1)} - \boldsymbol{u}_{j,v}^{(1)})$. $\boldsymbol{B}_{j,v}^{h}(\cdot)$ is the $h$-th order Bernstein polynomial of the $j$-th Bézier curve. %The predicted trajectory $\hat{f}(k|t)$ and control inputs $\hat{\mathbf{u}}(k|t)$ are the linear combinations of all control points $\boldsymbol{\mathcal{U}}$.

\begin{theorem}
Consider the initial value $\mathbf{x}(t_{0})$ of the system model in~\eqref{eq:dynamics}. If we apply the predicted control inputs $\hat{\mathbf{u}}(k|t_{0})$ as defined in~\eqref{eq:bezier_control}, the predicted trajectory $\hat{\mathbf{x}}(k|t_{0}) = [\hat{\mathbf{y}}(k|t_{0}); \hat{\mathbf{v}}(k|t_{0})]$ as defined in~\eqref{eq:bezier_position}-\eqref{eq:bezier_velocity} is the solution of dynamics system in~\eqref{eq:dynamics}.
\end{theorem}

\begin{proof}
The predicted system output $\hat{\mathbf{y}}(k|t_{0})$, velocity $\hat{\mathbf{v}}(k|t_{0})$, and control inputs $\hat{\mathbf{u}}(k|t_{0})$ are defined as Bézier curves and their first and second derivatives in~\eqref{eq:bezier_position}-\eqref{eq:bezier_control}. By definition, it is satisfied that $\dot{\hat{\mathbf{y}}}(k|t_{0}) = \hat{\mathbf{v}}(k|t_{0})$, and $\dot{\hat{\mathbf{v}}}(k|t_{0}) = \hat{\mathbf{u}}(k|t_{0})$. Let $\hat{\mathbf{x}}(k|t_{0}) = [\hat{\mathbf{y}}(k|t_{0}); \hat{\mathbf{v}}(k|t_{0})]$. By rewriting in the matrix form, we have $\dot{\hat{\mathbf{x}}}(k|t_{0}) = A \hat{\mathbf{x}}(k|t_{0}) + B\hat{\mathbf{u}}(k|t_{0})$. Here, $A$ and $B$ are defined in Sec.~\ref{sec:robot_model}. Thus, the dynamic model of the predicted trajectory given the predicted control inputs is in the same form as in~\eqref{eq:dynamics}. The initial value of the predicted trajectory $[\hat{\mathbf{y}}(t_{0}|t_{0}); \dot{\hat{\mathbf{y}}}(t_{0}|t_{0})] = \hat{\mathbf{x}}(t_{0}|t_{0})=\mathbf{x}(t_{0})$ is satisfied in the constraint~\eqref{eq:general_initial_state_constraint}. Following the above derivations, we can conclude that  
%Because the dynamic model of the predicted trajectory given the predicted control inputs is in the same form as in~\eqref{eq:dynamics} and the initial value of predicted trajectory is $\mathbf{x}(t)$. The prediction trajectory is the solution to the dynamics model in~\eqref{eq:dynamics}. 
%It is easy to see that 
the predicted trajectory is the solution to the dynamics model in~\eqref{eq:dynamics}, given the initial value $\mathbf{x}(t_{0})$ with control inputs $\hat{\mathbf{u}}(k|t_{0})$.
\end{proof}


\subsection{HOCBF Constraints and Relaxation}
To provide the forward invariance property for the system, one has to constrain $\hat{\mathbf{u}}(t)$ for any given $t$ with HOCBFs. As we pointed out earlier, this approach is impractical as it introduces an infinite number of constraints. Instead, we constrain the control inputs $\hat{\mathbf{u}}(k|t_{0})$ at sampled time stamps in predictive horizon,
\begin{align}
% \begin{aligned} A^{\mathrm{cbf}}\mathbf{u}(t) + \boldsymbol{b}^{\mathrm{cbf}}({}^{i}\hat{\mathbf{r}}_{j}(t|t_{0})) \geq 0, ~&\forall t \\ & \forall j \in \mathcal{N}_{i} \end{aligned}
    \begin{aligned} A^{\mathrm{cbf}}\hat{\mathbf{u}}(k|t_{0}) + \boldsymbol{b}^{\mathrm{cbf}}({}^{i}\hat{\mathbf{r}}_{j}(k|t_{0})) \geq 0, ~&\forall j \in \mathcal{N}_{i} \\ &\forall k\in \{0, \ldots, K-1\}. \end{aligned}
    \label{eq:hocbf}
\end{align}

As we increase the samples, constraint~\eqref{eq:hocbf} approaches HOCBF constraint in~\eqref{eq:general_qp_cbf}. %The predicted control inputs $\mathbf{u}(t)$ change continuously and are densely constrained over the horizon by Eq.~\ref{eq:hocbf}. These constraints work as a surrogate to the constraints in Eq.~\ref{eq:general_qp_cbf}. 
Note the predicted system output $\hat{\mathbf{y}}(k|t_{0})$, and consequently the belief of relative position ${}^{i}\hat{\mathbf{r}}_{j}(k|t_{0})$, are linear functions of the decision variables $\boldsymbol{\mathcal{U}}$. Note that, since the function $\lambda(b)$ in~\eqref{eq:HOCBF_constraints} is nonlinear in terms of relative position ${}^{i}\hat{\mathbf{r}}_{j}$, the constraint in~\eqref{eq:hocbf} is nonlinear.
%depends on the prediction states, which is a linear function of the decision variables, i.e., $\boldsymbol{\mathcal{U}}$. The nonlinearity of the barrier function $\boldsymbol{b}^{\mathrm{cbf}}(\cdot)$ introduces difficulty in solving the optimization problem. 
In Sec.\ref{sec:SQP}, we will propose a SQP technique to linearize this constraint and efficiently solve the optimization problem with a QP solver. 

More neighbors increase the number of constraints in the optimization problem, possibly leading to infeasibility. For this reason, we relax the HOCBF constraints with slack variables for distant neighbors, which do not pose a danger of collisions. We define a set of slack variables $\epsilon_j\geq 0$, for $j\in \mathcal{N}_{i}$ in the HOCBF constraints~\eqref{eq:hocbf} in the form,
\begin{align}
\label{QPconst:cbf_slack}
    \begin{aligned} A^{\mathrm{cbf}}\hat{\mathbf{u}}(k|t_{0}) + \boldsymbol{b}^{\mathrm{cbf}}(^{i}\hat{\mathbf{r}}_{j}(k|t_{0})) + \epsilon_j \geq 0, ~&\forall j\in \mathcal{N}_{i}\\ &\forall k\in \{0, \ldots, K-1\}.\end{aligned}
\end{align}
In Sec.~\ref{sec:cost_functions}, we introduce a priority cost to tight HOCBF constraints according to neighbor distance. 



%More neighbors increase the number of constraints in the optimization problem, possibly leading to infeasibility. For this reason, we relax the visual contact requirement for distant neighbors, which do not pose a danger of collisions. 
% Given the estimated position $\hat{\mathbf{r}}_j$ and the covariance matrix $R_{cov}$ from the particle filter as described in Section~\ref{sec:pf}, we derive a confidence ellipsoid ${\mathcal{R}}^{95}_{j}$ containing the real position $\mathbf{r}_j$ with $95\%$ probability. Then, we can find the distance $d_{ij}$ between robot $i$ and ${\mathcal{R}}^{95}_{j}$ following the solution in~\cite{catellani2023distributed}.
% We sort neighbors based on distance $d_{ij}$, resulting in the ordered set $\overline{\mathcal{N}}_i$, and prioritize the satisfaction of the CBF constraints on robots that are believed to be closer to robot $i$.


\subsection{Collision Avoidance Constraints}
We consider navigation under a communication-denied condition. Each robot $i$ can only estimate the current relative position of its neighbors $^{i}\hat{\mathbf{r}}_{j}(t_{0})$ without knowing their plans. The HOCBFs with current belief $^{i}\hat{\mathbf{r}}_{j}(t_{0})$ cannot guarantee collision avoidance in the prediction horizon. Despite the HOCBFs giving minimal conservative constraints, we use an alternative separating hyperplane approach to guarantee collision avoidance regarding beliefs. The convex hulls $\mathcal{A}$ and $\mathcal{B}$ represent the embodiment of robot $i$, i.e., $\mathcal{R}(\mathbf{r}_{i}(t))$ and robot $j$, i.e., $\mathcal{R}(\mathbf{r}_{j}(t))$, respectively. A function $L(\mathcal{A}, \mathcal{B})$ computes a separating half-space $\hat{\mathcal{H}}_{r}\!\! :=\!\! \left\{\mathbf{r}\in \mathcal{W}\mid\boldsymbol{w}^{\top}_{r}\mathbf{r} + b_{r} \leq 0\right\}$. We compute Voroni-cell separation between $\mathbf{r}_{i}$ and $\mathbf{r}_{j}$ as $\hat{\mathcal{H}}_{r}$. By buffering the half-space offset $b_{r}^{'} = b_{r} + \mathrm{max}_{\boldsymbol{y}\in \mathcal{R}(\mathbf{0})} \boldsymbol{w}_{r}^{\top} \boldsymbol{y}$, we obtain that the safety corridor consists of $\mathcal{H}_{r}$ for robot $i$. The Bézier curve $f_{i}$ generated at the negative side of $\mathcal{H}_{r}$ guarantees collision avoidance with its neighbor's belief, depicted in Fig.~\ref{fig:robot_robot_separating_hyperplane}. Due to the convex hull property of the Bézier curve, we can satisfy such constraints by forcing all the control points at the negative side of the half-space. We can write this constraint in the form
\begin{align}
    A^{\mathrm{col}}_{i}\boldsymbol{u}_{i,j} + \boldsymbol{b}^{\mathrm{col}}_{i} \leq 0, ~&\forall i \in \left\{ 0, \ldots, P-1 \right\} \nonumber \\
    &\forall j \in \left\{ 0, \ldots, h \right\}.
\end{align}

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.6\linewidth]{images/rr_separating_hyperplane_new.pdf}
    \caption{Given convex hull $\mathcal{A}$ and $\mathcal{B}$ representing the robots $i$ and robot $j$ respectively. $\hat{\mathcal{H}}$ is computed by $L(\mathcal{A}, \mathcal{B})$. By buffering $\hat{\mathcal{H}}$, we obtain the separating half-space $\mathcal{H}$ between robots.}
    \label{fig:robot_robot_separating_hyperplane}
\end{figure}

\subsection{System output and Derivatives Continuity}
In order to guarantee continuity of the system output and its derivatives, we need to impose the continuity between the splines, thus adding the following constraints:
\begin{align}
    \frac{d^j f_{i}\left(\tau_{i}\right)}{d t^j}=\frac{d^j f_{i+1}(0)}{d t^j}, ~& \forall i \in\{0, \ldots, P-2\} \nonumber \\ 
    & \forall j \in\{0, \ldots, C\}.
\end{align}

\subsection{System Physical Limits}
%To generate the trajectory and control inputs, we optimize the control points of a piecewise bezier curve.  
We require limits on the derivatives due to system physical constraints introduced in Sec.~\ref{sec:robot_model}.  The convex hull property of Bézier curves states that derivatives are confined within the convex hull of their corresponding control points. The derivatives limits, thus, can be respected by constraining their control points. This approach, however, has been shown to impose overly conservative constraints for derivatives~\cite{mercy2017spline}. Another approach is to respect the constraints in a post-process, where the duration of the generated Bézier curve is rescaled iteratively until limits are satisfied~\cite{honig2018trajectory, csenbacslar2023rlss}. Inspired by~\cite{luis2020online}, we propose an approach that leverages our discrete optimization scheme. We evaluate derivatives at sampled time stamps in predictive horizon $\hat{\mathbf{v}}(k|t_{0})$, $\hat{\mathbf{u}}(k|t_{0})$ and bound their values according to physical limits,
\begin{align}
    \mathbf{v}_{min} &\preceq \hat{\mathbf{v}}(k|t) \preceq \mathbf{v}_{max}, ~\forall k\in \{0, \ldots, K-1\},\\
    \mathbf{a}_{min} &\preceq \hat{\mathbf{u}}(k|t) \preceq \mathbf{a}_{max}, ~\forall k\in \{0, \ldots, K-1\}.
\end{align}
These are linear constraints w.r.t. decision variables $\boldsymbol{\mathcal{U}}$ as $\hat{\mathbf{v}}(k|t_{0})$ and $\hat{\mathbf{u}}(k|t_{0})$ are linear combinations of control points.%, we can rewrite this constraint as 
% \begin{align}
% A^{\mathrm{dyn}}_{i}\boldsymbol{u}_{i,j} + \boldsymbol{b}^{\mathrm{dyn}}_{i} \leq 0, ~&\forall i \in \left\{ 0, \ldots, P-1 \right\}, \nonumber \\
% & \forall j \in \left\{ 0, \ldots, h \right\}.
% \end{align}
%We found this approach is similar to~\cite{luis2020online}.


\subsection{Cost Functions}
\label{sec:cost_functions}
We can optimize the predicted trajectory and control inputs considering different objectives. Hence, in the following, we will introduce different cost functions, that can be exploited to achieve different objectives.
%We optimize the predicted trajectory and control inputs with variant objectives. 
\subsubsection{Goal Reaching Cost}
The optimized trajectory should navigate the system towards the desired goal output $\mathbf{y}_{d}\in \mathbb{R}^{4}$. We adopt our discrete optimization scheme and penalize the squared distance between the last $\kappa$ sampled predicted output $\hat{\mathbf{y}}(k|t_{0})$ and the desired goal $\mathbf{y}_{d}$. For this purpose, we define the following cost function:
\begin{align}
    \mathcal{J}_{\mathrm{goal}} = \sum_{k = K-\kappa}^{K-1} \omega_{k}\left\Vert \hat{\mathbf{y}}(k|t_{0}) - \mathbf{y}_{d}\right\Vert_{2}^{2},
\end{align}
where $\omega_{k}$ is the weight for $k$-th sample. This term can be rewritten as the quadratic form of all the decision variables $\boldsymbol{\mathcal{U}}$ in the optimization problem. 

\subsubsection{Control Effort Cost} We minimize the weighted sum of the integral of the square of the norm of derivatives, 
\begin{align}
    \mathcal{J}_{\mathrm{effort}} = \sum_{j=1}^{C} \theta_{j} \int_{t_{0}}^{t_{0}+\tau} \left\Vert\frac{d^{j}}{dt^{j}} f(t;\boldsymbol{\mathcal{U}})\right\Vert_{2}^{2} \, dt,
\end{align}
where $\theta_{j}$ is the weight of the order of derivatives. This term is in the quadratic form of decision variables $\boldsymbol{\mathcal{U}}$.

\subsubsection{Priority Cost} 
We assign a higher priority to the nearest neighbors in the HOCBF constraints, as they pose a higher collision risk, thus demanding an urge for visual contact to refine the belief on their positions. Given the estimated position $\hat{\mathbf{r}}_j$ and the covariance matrix $R_{\mathrm{cov}}$ from the particle filter, as described in Section~\ref{sec:pf}, we derive a confidence ellipsoid ${\mathcal{R}}^{95}_{j}$ containing the real position $\mathbf{r}_j$ with $95\%$ probability. We find the distance $d_{ij}$ between robot $i$ and ${\mathcal{R}}^{95}_{j}$ following the solution in~\cite{catellani2023distributed}.
Sorting the neighbors based on the distance $d_{ij}$ (from the closest to the farthest one), we obtain an ordered set $\overline{\mathcal{N}}_i$, and prioritize the satisfaction of the HOCBF constraints on robots that are believed to be closer to robot $i$.

Priority assignment is achieved by adding slack variables $\epsilon_j$ in~\eqref{QPconst:cbf_slack} with exponentially decaying weights as a cost function. The weights are defined as $\xi_j = \Omega \cdot \gamma_s^{j}$, where $\Omega \in \mathbb{R}_{>0}$ is the cost factor and $\gamma_s \in (0,1)$ is the decay factor. Therefore, the cost function can be defined as
\begin{equation}
    \mathcal{J}_{\mathrm{prior}} = \sum_{j\in\overline{\mathcal{N}}_{i}} \xi_j\epsilon_j.
\end{equation}
% Then, priority in constraints satisfaction is achieved by adding the slack variable $\epsilon_j$ to the cost function, scaled by an exponentially decaying weighting factor $\omega_j = \Omega \cdot \gamma_s^{j}$, where $\Omega \in \mathbb{R}_+$ is the cost factor and $\gamma_s \in (0,1)$ is the decay factor. The additional contribution to the overall cost function in~\eqref{QPcost} is calculated as:
% \begin{equation}
%     \mathcal{J}_{prior} = \sum_{j=0}^{N-2} \omega_j\epsilon_j
% \end{equation}
This cost minimizes $\epsilon_j$ for closer neighbors more aggressively and relaxes the constraints for the distant neighbors.
%given their higher weight $\omega_j$, making their constraints hard. On the other hand, the constraints on more distant robots will be relaxed because $\epsilon_j$ will be allowed to grow higher.
As a result, slack variables allow robot $i$ to lose visual contact with distant neighbors, but it will force it to bring robot $j$ back into $\mathcal{F}_i$ when the uncertainty becomes large and the ellipsoid ${\mathcal{R}}^{95}_{j}$ is close. 
% Consequently, $r_i$ will take $r_j$ back into $\mathcal{F}_i$ to update the estimate $\hat{\mathbf{r}}_j$ with new measurements.
Consequently, robot $i$ will be able to update and refine the estimation $\hat{\mathbf{r}}_j$ with new measurements.


\section{MPC-CBF Solved by Sequential Quadratic Programming}
\label{sec:SQP}
As mentioned in Sec.~\ref{sec:mpc_cbf}, the HOCBF constraints in~\eqref{QPconst:cbf_slack} are nonlinear w.r.t. decision variables. %In~\cite{liu2023iterative}, this problem was addressed by proposing a discrete-time MPC control scheme and linearizing the discrete HOCBF constraints. %Linearizing HOCBF constraints, however, over-relax a convex barrier function, which invalidates the forward invariance property.
We propose a linear surrogate of HOCBF constraints using the SQP technique, thus efficiently solving MPC-CBF with any off-the-shelf QP solver. 
% \subsection{MPC-CBF with SQP}

The SQP iteratively solves MPC-CBF. In each iteration, We evaluate the predicted states in the horizon from the solution we obtain in the last QP iteration. The evaluated predicted states are now independent of decision variables and can be treated as constants. We use evaluations as the surrogate of predicted states in the HOCBF constraints in~\eqref{QPconst:cbf_slack}, such that the nonlinear $\lambda(\cdot)$ function can be treated as a constant and the HOCBF constraints are linearized.
%We use the solution from the last QP iteration as the surrogate of the prediction state in the HOCBF constraints, such that the nonlinear $\lambda(\cdot)$ function can be treated as a constant. 
The initial QP is solved by constraining only the current state with HOCBF, which is observable, and predicts $\hat{\mathbf{x}}_{0}(k|t_{0})$ and $\hat{\mathbf{u}}_{0}(k|t_{0})$. Here, the subscription indicates the QP iteration index. However, the predicted trajectory and control inputs do not necessarily satisfy HOCBF constraints in the prediction horizon. 
Starting from the second iteration, we substitute ${}^{i}\mathbf{r}_{j}(k|t_{0})$ with the predicted ${}^{i}\hat{\mathbf{r}}_{j,m-1}(k|t_{0})$ from the previous QP iteration, where $m$ is the QP iteration index, for $m = 0, \ldots, M$. The $m$-th QP iteration is formulated as follows:
%\textcolor{blue}{write about how to write the objective in quadratic form.}
\begin{subequations}
\begin{IEEEeqnarray}{rCl'rCl}
\argmin_{\boldsymbol{\mathcal{U}}} 
&~& \mathcal{J}_{\mathrm{effort}} + \mathcal{J}_{\mathrm{goal}} + \mathcal{J}_{\mathrm{prior}} \label{QPcost}\\
\text{s.t.} 
&~& \frac{d^j f(0)}{dt^j} = \frac{d^j \mathbf{r}}{dt^j} , ~\forall j \in\{0, \ldots, C\} \label{QPconst:init_state}\\
&~& \begin{aligned} \frac{d^j f_{i}\left(T_{i}\right)}{d t^j}=\frac{d^j f_{i+1}(0)}{d t^j}, ~& \forall i \in\{0, \ldots, P\!-\!2\} \\ & \forall j \in\{0, \ldots, C\}\end{aligned} \label{QPconst:continuity}\\
% &~& \begin{aligned} A^{\mathrm{dyn}}_{i}\boldsymbol{u}_{i,j} + \boldsymbol{b}^{\mathrm{dyn}}_{i} \leq 0, ~& \forall i \in\{0, \ldots, P-1\} \\ & \forall j \in\{0, \ldots, h\}\end{aligned} \label{QPconst:dynamic_limits}\\
&~& \begin{aligned} A^{\mathrm{col}}_{i}\boldsymbol{u}_{i,j} + \boldsymbol{b}^{\mathrm{col}}_{i} \leq 0, ~& \forall i \in\{0, \ldots, P-1\} \\ & \forall j \in\{0, \ldots, h\}\end{aligned} \label{QPconst:safety_corridor}\\
&~& \begin{aligned} A^{\mathrm{cbf}}\hat{\mathbf{u}}(k|t_{0}) + \boldsymbol{b}^{\mathrm{cbf}}(^{i}\hat{\mathbf{r}}&_{j,m-1}(k|t_{0})) + \epsilon_j \geq 0, \\ &\forall j\in \mathcal{N}_{i} \\ &\forall k\in \{0, \ldots, K-1\} 
%\\ &\forall j\in \mathcal{N}_{i} 
\end{aligned} \label{QPconst:cbf}\\
&~&\mathbf{v}_{min} \preceq \hat{\mathbf{v}}(k|t_{0}) \preceq \mathbf{v}_{max}, \forall k\!\in\! \{0, \ldots, K-1\}\\
&~&\mathbf{a}_{min} \preceq \hat{\mathbf{u}}(k|t_{0}) \preceq \mathbf{a}_{max}, \forall k\!\in\! \{0, \ldots, K-1\}\\
&~& \epsilon_{j} \geq 0, ~\forall j\in \mathcal{N}_{i}.
\end{IEEEeqnarray}
\end{subequations}
% \textcolor{blue}{Subsection?}\\
% \subsection{Control Barrier Function Constraints Relaxation}
 % \textcolor{blue}{Slack variable.} Any SOTA solver can solve the above QP efficiently. 
%\subsubsection{Relaxation on Horizon}
Note that we only have an estimation of the neighbors' current positions. Adding HOCBF constraints to every step in the predictive horizon requires maintaining visual contact with this outdated estimate, leading to an unnecessarily conservative control strategy. Instead, we satisfy HOCBF constraints up to a horizon $K_{r}$ to relax such constraints.

\section{Simulation Results}
We demonstrate our algorithm in experiments on simulated and physical robots. Our algorithm is implemented in C++. We use GiNaC~\cite{bauer2002introduction} to compute the gradient and CPLEX 12.10 as the QP solver. We use the AprilTag~\cite{malyuta2020long} for relative positioning. We use ROS~\cite{quigley2009ros} to control the UAV online in the physical experiments.

\subsection{Simulation with a Double-integrator System}
To test the scalability of our controller, we define two categories of instances in simulation. One instance category is ``circle" where robots are initialized uniformly on a circle with antipodal goals. Their start and goal headings face the center of the circle. Another category is ``formation", where robots are initialized in grids and demanded to move forward. The start and goal headings are set with $0$ in yaws. 
We assume the system model is a double integrator. To reflect the uncertainty in the system dynamics, Gaussian noise is added to the system output and velocity, i.e., $\mathbf{y}(k|t_{0}) \sim \mathcal{N}\left(\hat{\mathbf{y}}(k|t_{0}), \Sigma_{\mathbf{y}}\right)$, $\mathbf{v}(k|t_{0})\sim \mathcal{N}\left(\hat{\mathbf{v}}(k|t_{0}), \Sigma_{\mathbf{v}}\right)$, where $\mathcal{N}(\boldsymbol{\mu},\Sigma)$ denotes a multivariate Gaussian distribution with mean $\boldsymbol{\mu}$ and a diagonal covariance matrix $\Sigma$. We set $\Sigma_{\mathbf{y}}=diag(0.001,\ldots,0.001)$, and $\Sigma_{\mathbf{v}}=diag(0.01,\ldots,0.01)$. In this work, we fix the height of the robots. We set different ranges of $\beta_{H}$ to demonstrate the property of our algorithm. To respect the physical constraints, we limit the acceleration in range $[-10, 10]\unit{m/s^{2}}$ in the x-y plane, and velocity in range $[-3, 3]\unit{m/s}$ for ``circle" instances and $[-0.5, 0.5]\unit{m/s}$ for ``formation" instances. We set the yaw acceleration and yaw rate limits as $[-\pi, \pi]\unit{radian/s^{2}}$ and $[-\frac{5}{6}\pi, \frac{5}{6}\pi]\unit{radian/s}$ respectively. To expedite the computation and respect the visual contact constraints, we set $K_{r}=2$, $M = 2$ in the SQP solver. We set the number of pieces $P=3$ for the piecewise spline, the degree of Bézier curves $h=3$ with duration $\tau_{i}=0.5\unit{s}$, for $i=1,2,3$, and require the highest order of continuity $C=3$. In the MPC-CBF algorithm, we set the discrete sample duration $\delta=0.1\unit{s}$. For the particle filtering algorithm, we set the number of particles to $N_{p}=100$ and initialize them uniformly randomly in the workspace, the process covariance to $\Sigma_{\mathrm{p}} = diag(0.25, 0.25, 0.25)$, the measurement covariance to $R_{\mathrm{m}} = diag(0.05, 0.05, 0.05)$, and the penalty factor for particles inside the field of view to $\varepsilon = 0.1$. The cost factor of slack variables is $\Omega = 1000$. The collision shape of the robot is defined as an axis-aligned bounding box in range $[-0.2, 0.2]\unit{m}$ for both x-y dimensions. As a baseline, we apply a PD controller with critical damping as the desired controller certified by the HOCBF constraints with the same velocity and acceleration limits. We add CBF constraints with linear $\alpha$ function to limit the velocity in the baseline. 

\subsection{Simulation in Circle Instances}
Three criteria evaluate the navigation task under communication-denied condition:
\begin{itemize}
    \item \textbf{Success Rate}: success is defined as all robots reach their goal area and stay within without collisions given a time budget.
    \item \textbf{Makespan}: the time spent by all robots to reach their goal areas in successful task executions.
    \item \textbf{Percentage of Neighbors in FoV}: the average percentage of neighbors the robot maintains in its field of view during the task.
\end{itemize}
The desired goals may not satisfy the visual-contact requirement. Our control strategy compensates for such goals and maintains visual contact but deviates slightly from its desired goal position. Thus, we consider the robot to complete its navigation task as it reaches its goal area and stays within. 

We set cost coefficients $\omega_{k}=10$, for $k = K-\kappa,\ldots,K-1$, $\theta_{j} = 1$, for $j=1\ldots C$, and $\kappa=3$ in our optimization formulation. The snapshots in Fig.~\ref{fig:sim_circle} are typical routing of our control strategy in the ``circle" instance with $5$ robots and a $\beta_{H}=\frac{2}{3}\pi$ field of view. The robustness of the control strategy becomes essential in such instances as tracking all neighbors becomes unmanageable. Note that the robot, when it loses visual contact with neighbors, changes its heading to regain detection during the task.
%The robot loses visual contact with its neighbors and changes its heading to regain detection during the task. 
The sensitivity of heading changes is controlled by the slack variable decay factor $\gamma_{s}$. A small $\gamma_{s}$ prioritizes tracking the closest neighbor in the belief space, leading to more sensitive heading changes. A large $\gamma_{s}$ tends to treat all neighbors equally and tries to maintain all neighbors in the field of view, leading to less sensitive heading changes. A sensitive heading over-emphasizes the closest neighbor and causes inefficient strategy between frequent heading changes. An insensitive heading otherwise tends to ignore the impending collision in belief space leading to collisions.

\begin{figure}[tb]
    \centering
    \subfloat[Execution time = 2.0\unit{s}]{\includegraphics[width=0.16\textwidth]{images/circle_instances/circle5_frame200.pdf}}
    \subfloat[Execution time = 4.4\unit{s}]{\includegraphics[width=0.16\textwidth]{images/circle_instances/circle5_frame440.pdf}}
    \subfloat[Execution time = 5.2\unit{s}]{\includegraphics[width=0.16\textwidth]{images/circle_instances/circle5_frame520.pdf}}\\
    \subfloat[Execution time = 6.8\unit{s}]{\includegraphics[width=0.16\textwidth]{images/circle_instances/circle5_frame680.pdf}}
    \subfloat[Execution time = 11.0\unit{s}]{\includegraphics[width=0.16\textwidth]{images/circle_instances/circle5_frame1100.pdf}}
    \subfloat[Execution time = 15.0\unit{s}]{\includegraphics[width=0.16\textwidth]{images/circle_instances/circle5_frame1500.pdf}}
    \caption{Snapshots for 5 robots navigating the circle instance. The uncertainty of the estimations is represented as ellipses (the source of estimations is indicated by colors). The predicted output (position and yaw) is depicted as blue curves and purple field of views. The traversed path is shown as a solid line.}
    \label{fig:sim_circle}
\end{figure}

\begin{figure}[tb]
    \centering
    {\includegraphics[width=0.49\textwidth]{images/baseline_benchmarking/circle_instances/hist_success_rate_ci.pdf}}\\
    {\includegraphics[width=0.49\textwidth]{images/baseline_benchmarking/circle_instances/hist_makespan_ci.pdf}}\\
    {\includegraphics[width=0.49\textwidth]{images/baseline_benchmarking/circle_instances/multi_pnif_ci.pdf}}
    \caption{Performance of our algorithm with a variety of $\beta_{H}$ and $\gamma_{s}$ on different numbers of robots in ``circle" instances. The top of the bars represents the mean, and the ends of the error bars depict the 95\% confidence interval. The statistics are averaged over $15$ trials.}
    \label{fig:circle_quantity}
\end{figure}

As quantitative results, in Fig.~\ref{fig:circle_quantity} we demonstrate the performance of our control strategy with different field-of-view angles $\beta_{H}$ in $[\frac{2}{3}\pi, \frac{4}{3}\pi, 2\pi]$ and slack variable decay factors $\gamma_{s}$ in $[0.1, 0.2]$. Note that, when $\beta_{H}=2\pi$, then $b_{\mathrm{fov}}(({}^i\mathbf{r}_j))\geq 0$ constraints are always satisfied. We show task success rate, makespan, and percentage of neighbors in FoV. We observe the task success rate starts to drop dramatically once the number of robots is larger than $5$. It is worth pointing out that our control strategy consistently outperforms the baseline controller for different numbers of robots. The baseline, as a reactive controller, is less conservative to imminent collision. As a result, it is more sensitive to estimate uncertainty and exposes one to a higher risk of collision once the neighbor detections are lost. For a small $\beta_{H}$, the control challenge is to maintain neighbors in the field of view, thus providing the latest estimation to avoid collision, while reaching the desired goal. As we increase the field of view, maintaining visual contact with neighbors becomes easier; however, robots tend to take the shortest path and crowd in the middle of the workspace, which leads to  deadlocks and potential collisions due to uncertainty in the estimation. We notice that $\beta_{H}=\frac{4}{3}\pi$ gives the best trade-off between visual contact and collision avoidance in success rate for the ``circle" instance when the estimation uncertainty is present. The challenge of addressing deadlocks in multi-robot planning falls out of the scope of this work. Modern MAPF-based path/trajectory planning addresses deadlock problems even in large-scale operations~\cite{pan2024hierarchical, pan2025hierarchical}. From the figure, we note that makespan decreases as we increase the field of view. Robots tend to take the shortest path as the detection task now becomes more effortless. Despite the drop of task success rate, we note the percentage of neighbors in FoV metric maintains above $60\%$ as we scale up the number of robots even with $\beta_{H}=\frac{2}{3}\pi$. Our control strategy maintains the same level of visual contact with neighbors compared to the baseline controller without compromising the task success rate. Additionally, we evaluate the impact of slack decay factor $\gamma_s$ on our control strategy. Notice that a less sensitive heading increases the success rate. This is expected as a more holistic heading better balances all neighbors.


\subsection{Simulation in Formation Instances}
In ``formation" instances, we initialize all robots in grids with a distance $1\unit{m}$ away from each other in the x-y direction. All robots are initialized with $0$ yaw. Goals are $12\unit{m}$ to the right of the starting points with $0$ yaws. We set the cost coefficients $\omega_{k}=300$, for $k = K-\kappa,\ldots,K-1$, $\theta_{j} = 1$, for $j=1\ldots C$, and $\kappa=3$. In Fig.~\ref{fig:sim_formation}, we demonstrate a typical result of our control strategy with $4$ robots. The robustness of our control strategy is manifested in this example as robots automatically form visual contact and stabilize each other in their field of view while reaching the desired goals. The robots in the right column start without detection of the left column robots, and our controller turns the robots around and detect the neighbors. %Visual contact is maintained throughout the execution of the task. This example illustrates that our control strategy can regain visual contact and automatically combine neighbor detection and navigation tasks. 

\begin{figure}[tb]
    \centering
    \subfloat[Execution time = 0.0\unit{s}]{\includegraphics[width=0.16\textwidth]{images/formation_instances/formation4_frame0.pdf}}
    \subfloat[Execution time = 2.0\unit{s}]{\includegraphics[width=0.16\textwidth]{images/formation_instances/formation4_frame200.pdf}}
    \subfloat[Execution time = 5.0\unit{s}]{\includegraphics[width=0.16\textwidth]{images/formation_instances/formation4_frame500.pdf}}\\
    \subfloat[Execution time = 10.0\unit{s}]{\includegraphics[width=0.16\textwidth]{images/formation_instances/formation4_frame1000.pdf}}
    \subfloat[Execution time = 18.0\unit{s}]{\includegraphics[width=0.16\textwidth]{images/formation_instances/formation4_frame1800.pdf}}
    \subfloat[Execution time = 27.0\unit{s}]{\includegraphics[width=0.16\textwidth]{images/formation_instances/formation4_frame2700.pdf}}
    \caption{Snapshots for 4 robots navigating in formation. Their start and goal yaws are set as 0. The robots gain visual contact with all neighbors and maintain it during the task.}
    \label{fig:sim_formation}
\end{figure}

We summarize the quantitative results in Fig.~\ref{fig:formation_quantity}. Since robots move in the same direction, unlike ``circle" instances, tasks result in fewer collisions and deadlocks. Overall, we notice an improved scalability and success rate compared to ``circle" instances. Our controller consistently outperforms the baseline across different numbers of robots. With a small field of view, the baseline controller, as a reactive controller, acts short-sightedly to satisfy the field-of-view constraints and compromises the goal-reaching capability. In contrast, our control strategy balances goal-reaching capability while respecting field-of-view constraints. With an omnidirectional field of view, the baseline suffers from collision due to estimate uncertainty as the number of robots increases. In the ``formation" instances, increasing the field of view improves the success rate for both the baseline and our approach. For the decay factor $\gamma_{s}$, a less sensitive heading works better for ``formation" instances. The makespan does not show significant change with different $\beta_{H}$ or $\gamma_{s}$ mainly because the task is less challenging regarding navigation. The percentage of neighbors in FoV maintains above $60\%$ with $\beta_{H}=\frac{2}{3}\pi$. Our controller maintains equivalent visual contact quality without compromising the goal-reaching capability.

\begin{figure}[tb]
    \centering
    {\includegraphics[width=0.49\textwidth]{images/baseline_benchmarking/formation_instances/hist_success_rate_ci.pdf}}\\
    {\includegraphics[width=0.49\textwidth]{images/baseline_benchmarking/formation_instances/hist_makespan_ci.pdf}}\\
    {\includegraphics[width=0.49\textwidth]{images/baseline_benchmarking/formation_instances/multi_pnif_ci.pdf}}
    \caption{Performance of our algorithm with a variety of $\beta_{H}$ and $\gamma_{s}$ on different numbers of robots in ``formation" instances. The top of the bars represents the mean, and the ends of the error bars depict the 95\% confidence interval. The statistics are averaged over $15$ trials.}
    \label{fig:formation_quantity}
\end{figure}

\section{Physical Experiment}
\subsection{System Hardware}
We built PX4 Autopilot~\cite{meier2015px4} UAVs for this project. The robot's position and yaw are estimated onboard with extended Kalman filter using Vicon measurements. The Vicon data is sent to the UAV through the WIFI protocol. In practical communication-denied condition settings, state estimation can be obtained with onboard GPS and magnetometer during outdoor flights or VIO/LIO during indoor flights. We use the PID controller on PX4 to track the generated trajectory. The UAV is equipped with a Jetson Xavier and a RealSense D435 camera. In the static target tracking experiment, we detect the target location with AprilTags attached to the target. The RGB camera's field of view $\beta_{H}$ in our physical experiment is about $\frac{1}{4}\pi$, thus posing a much more challenging planning and control problem compared to simulations. The camera stream is $15$ Hz, thus requiring a stable flight to detect AprilTag during experiments. %One of our system's frame designs is inspired by~\cite{zhou2022swarm} and shown in Fig.~\ref{}.

\subsection{Static Target Tracking}
In the first experiment, we control the UAV to track a static target during navigation to a desired goal. The target position is estimated using the onboard RGB camera capturing AprilTag on the target. %The $15$ Hz camera feed requires stable flight for constant Apriltag detection. %We constrain the acceleration and velocity of the vehicle \textcolor{blue}{within range}. 
The target is tracked and estimated during the flight. The flight demonstration and robot first-person-view snapshots are captured in Fig.~\ref{fig:single_robot_experiments}.

\begin{figure}[tb]
    \centering
    % \subfloat[Execution time = 4.2\unit{s}]{\includegraphics[width=0.16\textwidth]{images/Multi-Robot_experiment/fovmpc123_short.jpg}}
    % \subfloat[Execution time = 10.8\unit{s}]{\includegraphics[width=0.16\textwidth]{images/Multi-Robot_experiment/fovmpc323_short.jpg}}
    % \subfloat[Execution time = 14.3\unit{s}]{\includegraphics[width=0.16\textwidth]{images/Multi-Robot_experiment/fovmpc430_short.jpg}}\\
    \subfloat[Execution time = 15.0\unit{s}]
    {\includegraphics[width=0.163\textwidth]{images/Single-Robot_experiment/SingleRobotBirdview090.jpg}}
    \subfloat[Execution time = 23.3\unit{s}]
    {\includegraphics[width=0.163\textwidth]{images/Single-Robot_experiment/SingleRobotBirdview140.jpg}}
    \subfloat[Execution time = 30.0\unit{s}]
    {\includegraphics[width=0.163\textwidth]{images/Single-Robot_experiment/SingleRobotBirdview180.jpg}}\\
    \subfloat[Execution time = 15.0\unit{s}]{\includegraphics[width=0.163\textwidth]{images/Single-Robot_experiment/SingleRobotFPV090.jpg}}
    \subfloat[Execution time = 23.3\unit{s}]{\includegraphics[width=0.163\textwidth]{images/Single-Robot_experiment/SingleRobotFPV140.jpg}}
    \subfloat[Execution time = 30.0\unit{s}]{\includegraphics[width=0.163\textwidth]{images/Single-Robot_experiment/SingleRobotFPV180.jpg}}
    \caption{Snapshots of the top view and first-person-view camera recording in the static target tracking experiment. The location of the tripod is estimated by detecting the AprilTag attached. The tracked tripod is maintained in the field of view throughout the flight.}
    \label{fig:single_robot_experiments}
\end{figure}

\subsection{Multi-robot Visual Contacts}
In this physical experiment, we control two custom-built UAVs to maintain visual contact during navigation to their desired goals. 
%We deploy the algorithm on two custom-built UAVs and constrain the neighbor UAV in the field of view during navigation. 
Relative motion introduces challenges to AprilTag detection. In the experiment, we assume the detection of the neighbor UAV can be obtained, from VICON measurements over WIFI communication, when in the field of view. Despite being against the communication-denied principle, the onboard detection module can be swapped with more robust methods such as YOLO~\cite{redmon2016you}. Two UAVs successfully maintain visual contact with each other throughout the entire flight. Experiment demonstration and first-person-view snapshots are shown in Fig.~\ref{fig:multi_robot_experiments}. 

\begin{figure}[tb]
    \centering
    % \subfloat[Execution time = 4.2\unit{s}]{\includegraphics[width=0.16\textwidth]{images/Multi-Robot_experiment/fovmpc123_short.jpg}}
    % \subfloat[Execution time = 10.8\unit{s}]{\includegraphics[width=0.16\textwidth]{images/Multi-Robot_experiment/fovmpc323_short.jpg}}
    % \subfloat[Execution time = 14.3\unit{s}]{\includegraphics[width=0.16\textwidth]{images/Multi-Robot_experiment/fovmpc430_short.jpg}}\\
    \subfloat[Execution time = 4.2\unit{s}]
    {\includegraphics[width=0.163\textwidth]{images/Multi-Robot_experiment/UAV10247.jpg}}
    \subfloat[Execution time = 10.8\unit{s}]
    {\includegraphics[width=0.163\textwidth]{images/Multi-Robot_experiment/UAV10646.jpg}}
    \subfloat[Execution time = 14.3\unit{s}]
    {\includegraphics[width=0.163\textwidth]{images/Multi-Robot_experiment/UAV10860.jpg}}\\
    \subfloat[Execution time = 4.2\unit{s}]{\includegraphics[width=0.163\textwidth]{images/Multi-Robot_experiment/UAV20247.jpg}}
    \subfloat[Execution time = 10.8\unit{s}]{\includegraphics[width=0.163\textwidth]{images/Multi-Robot_experiment/UAV20646.jpg}}
    \subfloat[Execution time = 14.3\unit{s}]{\includegraphics[width=0.163\textwidth]{images/Multi-Robot_experiment/UAV20860.jpg}}
    \caption{Snapshots of first-person-view camera recording in the $2$-robot experiment. Two robots are required to maintain visual contact while swapping their positions. The visual contact constraints are satisfied throughout the flight. The neighbor robot is circled in red.}
    \label{fig:multi_robot_experiments}
\end{figure}


\section{Limitations}
The assumption of a planar motion limits the agility of quadrotors flight. For this reason, we aim to extend the application to 3D motion, extending the HOCBF formulation to account for the entire sensing volume shown in Fig.~\ref{fig:sensing_model}a.
In addition, we noticed that, in the physical experiments, the AprilTag-based detection becomes unreliable when there is even a slight image blur caused by vehicle agile flight. The linear surrogate in our SQP formulation lacks a convergence guarantee, making it difficult to approximate the HOCBF constraints in complex scenarios where the solution deviates significantly in iterations. In future work, we aim to swap the detection module with learning-based approaches, such as YOLO~\cite{redmon2016you}, and enhance the surrogate convergency in SQP iterations.

\section{Conclusion}
In this work, we address online (real-time) distributed coordination in a communication-denied area. Our control strategy navigates robots to their goals while estimating the location of neighbors and maintaining them in the field of view. The proposed strategy is robust for temporary tracking loss and able to regain visual contact. To the best of our knowledge, this work is the first of its kind to generate a continuous-time trajectory and controller concurrently, certified by control barrier functions utilizing piecewise splines. We propose a discrete optimization framework, namely MPC-CBF, to approximate the solution. In addition, we propose an efficient SQP formulation to solve MPC-CBF with a QP solver. We demonstrate the effectiveness and scalability of our strategy with $10$ robots in simulation and physical experiments with $2$ custom-built UAVs with cameras onboard. In future work, we aim to develop adaptive strategies in an environment where external factors, such as downwash~\cite{doi:10.2514/6.2024-4145}, may influence the system dynamics. We also aim to address robustness in coordination problems with inaccurate and unreliable sensors.

\bibliographystyle{plainnat}
\bibliography{refs}


\end{document}
