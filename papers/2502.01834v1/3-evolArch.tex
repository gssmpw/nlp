\section{An Evolutionary Cognitive Twin}
\label{sec:sec3}

Since we have already introduced some key concepts and the tool we're using, we can now discuss the proposed technique. Here, the main point is to build a Cognitive Twin using a vast amount of simple devices, orchestrated to work together as a single system, even if each device is a system of its own and may, theoretically, be a part of another system.

Here in this work, based on the definitions in section \ref{sec:sec1} and within the scope of what will be presented, the following definition will be presented:

\noindent\fbox{%
    \parbox{\columnwidth}{%
A \textit{Cognitive Twin} is a digital replica of the dynamics and cognitive - or just cognitive - processes of an intelligent physical system, usually aimed at a partial representation of a person. These cognitive processes refer to those identified in cognitive theories, such as perception, memory, behavior, adaptation, planning, learning, \textit{Reasoning} etc. The classification of an agent as \textit{Cognitive Twin} refers not only to the duplication of observable behavior of the virtual agent concerning the original but also to the possibility of in-depth investigation of the original individual through its copy.
    }%
}
\vspace{7mm}

The most fundamental idea here is the Codelet, already discussed in section \ref{sec:sec2}. We argue that sensors and actuators can be seen as Sensory and Motor Codelets, respectively. To make that consideration, we considered that both sensors and actuators are simple devices that do a very specific task, following the idea of Codelet, as seen in sections \ref{sec:sec1} and \ref{sec:sec2}. This consideration allows us to model our desired agent as a composition of simpler elements that interact with each other as needed.

Following that perspective, we postulate that the connections between sensors and actuators are given by some combination of elements that group and give them some sense, and elements that use that information to control actuators. This lets us use the concepts of Perceptual Codelets and Behavioral Codelets, respectively, largely used in other works that follow a Codelet-oriented Cognitive agency paradigm. Also, these premises fit in the concepts presented in section \ref{sec:sec1}: The System is composed of devices that are themselves systems connected through a network with an orchestration to build a Cognitive Agent that bridges virtual and physical domains.

But we have two main constraints: first, we sought to use simple, low computing power devices, and we do not have an infinite number of devices (with an infinite variety of input-output responses) to search for the best combination. We approach those constraints by having devices that can learn (or somehow adapt) and by making use of a heuristic that improves this search. It's also impractical to have those devices fully connected, as this communication overhead may degrade performance and/or be impossible if we deal with physical devices.

So, we propose to find the optimal configuration by having both explicit training on Codelets and an Evolution Strategy to find a suitable connection between Perceptual and Behavioral Codelets and between Behavioral and Motor Codelets. We'll discuss this in detail in the next subsections.


%propor o seguinte: a conexão eh encontrada com genetica e os nos perceptuais e comportamentais são decisiontrees

\subsection{Devices internal structure}
 First, we to define the internal structure of the devices we worked on. For the sake of simplicity, we used only virtual devices, as defined in section \ref{sec:sec2}, running Python Codelets on Docker. That allowed us to better manipulate some structures, like sending or requesting data from the master program to/from each Codelet and creating or destroying those virtual devices as we needed them. Even so, we kept the internal structures simple to draw a parallel with low-power devices. 
 
 As we mentioned before, we follow MECA Theory, which uses both \cite{Osman2004} theory of two, separated Cognition Systems working together and a \emph{Codelet}-oriented structure. Here we present a System 1 approach, which means that we'll be working only with four types of \emph{Codelets}: \emph{Sensory, Perceptual, Behavioral} and \emph{Motor Codelets}. We will briefly explain each of them.
 
 
 \subsubsection{Sensory Codelets}
 The simplest of them all, Sensory Codelets represent actual sensors, either physical or virtual. Like sensors, they are responsible for introducing the raw data into the system. For example, if we consider a human eye a sensor, the raw data is the light that enters the pupils. Here, it requests information about a specific attribute - temperature or luminosity, for example - of an environment. In this work, Sensory Codelets' internal structures will not be changed, simulating very simplistic devices, like a digital thermometer.
 
 \subsubsection{Perceptual Codelets}
 \label{sub:per}
 The subsequent structures in the information flow are Perceptual Codelets. These structures are responsible for aggregating the raw data that comes from Sensory Codelets in structures called Perceptions. In our human eye example, outputs of Perceptual Codelets would be \emph{depth}, \emph{objects}, relational properties (like distance from something), and so on. Notice that Perceptual Codelets, in a sense, represent how an agent experiences the world, as the information it could extract from data is heavily dependent on them. In this work, the internal structure of a Perceptual Codelet is represented by a Decision Tree Classifier, where the inputs are sensory data and the output is an integer value that represents a unique identifier (a token) of the input sensor's readings. Each Perceptual Codelet differs from another by the combination of its Sensor Codelets on the input. Those inputs are defined randomly with a uniform distribution to both quantity (a value between half and all the sensors) and which ones are picked up. %Figure \ref{fig:perceptualDT} illustrate the idea. 
  
  
 \subsubsection{Behavioral Codelets}
 Next, we have the Behavioral Codelets. The main purpose of these structures is to, based on previously structured information, activate one or more protocols to control what the agent should do, that is, to control one or more Motor Codelets. This Activation is usually encoded in a 0 to 1 \emph{float} value representing a Signal Strength, a way to measure how important that Behavior is to the current situation. Note that this so-called protocol may be anything from a simple heuristic to a whole Machine Learning method and the input of the Behavioral Codelet may include not only Perception but other information like those coming from a Motivational or even Emotional subsystem. Also, as a single Motor Codelet may have multiple Behavioral Codelets as input, those behaviors effectively compete to prevail and have their commands accepted.
   
   In this work, the Behavioral Codelets have also a Decision Tree Classifier as a method to decide what to send to its Motor Codelets based on Perception. 
   
 \subsubsection{Motor Codelets}
 The last basic structure here is the Motor Codelet. As mentioned before, this represents a direct parallel with an actuator, being physical or not. It simply responds to what was put as input and, through another Decision Tree, it sends a command to the corresponding entity in our virtual environment. This could be a direct association (''if this then that'') but, to make further usage of the code easier, we used a method that could accept more than one Behavioral without having to rewrite it completely.
 
 
 Figure \ref{fig:agent_struct} shows an overview of the structure of the topology of an agent. This concludes our overview of the main structures of our work. Next, we will detail about the Evolution Strategy.


  \begin{figure}[ht]
\centering
	\includegraphics[width=1.0\columnwidth]{imgs/cog_twin.drawio.png}
\caption{Graphical representation of an agent structure and its internal connections}
\label{fig:agent_struct}
\end{figure}

\subsection{The optimization}

The general process of building the architecture for our Cognitive Twin involves determining the connection topology between the different types of Nodes and adjusting the internal functions of each Codelet to reproduce the overall behavior of a primordial agent. This is a two-step offline optimization process, the first being an optimization of the connection topology between Nodes and the second being a conventional training process of the Codelets' internal Machine Learning models in each Node. The connections between the Nodes will be defined through an evolutionary strategy and, given the connection configurations of each individual of a given generation, supervised training methods will be used to minimize the error between the expected and obtained outputs.
In this work, the internal structures of the Sensory Codelets are not changed, simulating very simplistic devices, such as a digital thermometer. 

%We present details of each of these steps below.

\subsubsection{Evolution Strategy details}

In this part of the process, we want to, through an evolution process, define the best configuration of the connections between Perceptual and Behavioral Codelets and Behavioral and Motor Codelets. The connections between Sensorial and Perceptual Codelets are fixed and explained in subsection \ref{sub:per}.

To apply an Evolution Strategy, we need to do some definitions. First, we need to define our Individual encoding. Here, our Individual is a binary vector with the length of the number of total Perceptual Codelets plus the number of total Behavioral Codelets, where each index represents a specific Codelet. In that definition, a '1' represents that the corresponding Codelet is active on the Agent composition and a '0' means a non-connected Codelet. An example Individual is shown in figure \ref{fig:individual}.

\begin{figure}[hb]
\centering
	\includegraphics[width=1.0\columnwidth]{imgs/individual.drawio.png}
\caption{Example Individual for our Evolution Strategy Process. The Individual is encoded as an array of binary values, each one representing if a certain Perceptual or Behavioral Codelet is to be considered as part of the agent.}
\label{fig:individual}
\end{figure}

Second, we need to define a mutation method. In this work, we adopted a simple 'bit-flip' probability for mutation, meaning that each individual has a probability \emph{mut\_p} to be mutated and each of its genes has a probability \emph{ind\_m} to change its state from '0' to '1' and vice versa. So, if a '0' becomes a '1', that means we should take the corresponding Codelet into account when mounting the agent topology.

As we adopted the output of Motor Codelets as exclusively binary, we can choose the fitness evaluation method as a Hamming Distance between the expected outputs and the actual ones. With this choice, the lower the Score, the better the individual fitness.

As a selection method, we choose to keep the best five individuals in the population for the next generation. Also, we choose the overall best one to be cloned. This procedure gives the possibility of recovering from local minima.

%initial pop


Also, we choose not to have any mating process. This choice was completely arbitrary, as we foresaw that it would not cause significant changes and required an additional process that could make each iteration longer.


\subsubsection{The training process}

To build our distributed agent correctly, we need a training process to ensure it accurately maps the system's inputs to the expected outputs. This training is done a) by changing its topology, choosing which Perceptual and Behavioral Codelets are composing the agent, and b) by fitting the data through all individual components consistently. 

The main component of the optimization process is very straightforward: it is a simple - yet efficient - Evolution Strategy to define the agent topology. This process is graphically represented in figure \ref{fig:evol_strategy}. But our \emph{evaluation} method requires more attention. It is in this part that we try to perform an input-output mapping.


\begin{figure}[ht]
\centering
	\includegraphics[width=0.7\columnwidth]{imgs/evolution_strategy.drawio.png}
\caption{Evolution Strategy process diagram. Here we have a high-level representation of each step of the mentioned heuristic.}
\label{fig:evol_strategy}
\end{figure}

% population creation   evaluation    selection   cloning and mutation    do it again

First, we get our \emph{Individual} and reconfigure the Codelets connections properly, including cleaning all \emph{memories} and deciding which \emph{Behavioral Codelet} will feed each \emph{Motor Codelet}. We do that by writing a new \emph{fields.json} file and sending it to each \emph{Codelet}, and by forcing an empty value to the relevant \emph{Memories}, such as the \emph{motor-memories}, in each \emph{Motor Codelet}.

In the second part, we get our training inputs and send them to each relevant (the ones with a correspondent '1' in \emph{Individual} encoding) \emph{Perceptual Codelet} and send them a "train" signal, through a special \emph{Memory} on them with this sole purpose. This training process aims to create unique values - like tokens - that identify each observed combination of sensor readings. These readings refer solely to the sensors at the input of each \emph{Perceptual Codelet}. These tokens are integers corresponding to positions on an array with unique observations. For example, if ''[[0, 1, 0], [0, 1, 1], [0, 1, 0]]'' represents a set of training inputs, then ''[[0], [1], [0]]'' would be the outputs. Remember that each \emph{Perceptual Codelet} has its own sensor connections, so their responses differ one from another.


Now, the most sensitive part, we need to train \emph{Behavioral Codelets} properly considering the input-output response of each \emph{Perceptual Codelet} and respective \emph{Motor Codelet}. We do that in two steps: aggregating \emph{Perceptual Codelets} responses for each training input and mapping those responses to a \emph{Motor Codelet} input that would generate the desired output. These two sets (\emph{Perceptual} responses and \emph{Motor} input) represent the training we have on each \emph{Behavioral Codelet}.

The aggregation step is done by requesting the already trained model from \emph{Perceptual Codelets} and its respective input masks (representing which sensors feed them) and mounting a conjoined Perceptual output. This approach may also be useful for the data-sensitive task, as the system that collects/sends the information need not be the same that centralizes the Evolution Strategy.

Then, we need to get how each \emph{Motor Codelet} responds, either by getting a trained model or by getting an input-output set directly. We opt for the latter since \emph{Motor Codelets} represent actuators and, usually, they don't hold sensitive data. This part is problematic, as a \emph{Behavioral Codelet} may be assigned to two (or more) \emph{Motor Codelets} with fundamentally different behaviors. That could make it impossible to achieve correct model training. After collecting data, we send each input-output information to the respective \emph{Behavioral Codelet}.


Next, we are ready to evaluate the system's performance. One by one, we send the corresponding entry in the input test set to the environment server the system is sensing (we talk about this specificity in section \ref{sec:sec4}) and wait until the information propagates through a distributed agent, getting the system response after that (all \emph{Motor Codelets} outputs combined). This ''wait time'' is directly related to communication overheads and process concurrency if using a single computer.

Finally, we calculate the Hamming Distance between the expected values (test output) and the actual output. This will represent the \emph{Fitness} of the \emph{Individual}.



