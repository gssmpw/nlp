\section{Conclusion} \label{sec:conclusion}

In this study, we propose I3S for low-rank optimization in LLM pretraining. The motivation is to find an effective subspace selection method to overcome the low-rank bottleneck caused by the frozen dominant subspace in low-rank optimization. I3S samples singular vectors of mini-batch gradients with probabilities proportional to their singular values, this enables optimization trajectory to explore more different subspaces. Theoretically, in Theorem~\ref{convergence_our_method_informal}, we show that GaLore-I3S-MSGD achieves the same convergence rate as GoLore-MSGD, which is 
\begin{align*}
    \mathcal{O}\left(\frac{L\Delta}{\delta^{2.5}T}+\sqrt{\frac{L\Delta\sigma^2}{\delta^{3.5}T}}\right).
\end{align*}
Empirically, we find that I3S improves the language modeling capability of pretrained models compared to using the dominant subspace, as verified by experiments involving I3S and dominant subspace selection with multiple low-rank optimizers. Additionally, we compare I3S with uniform singular vector sampling and the JL-transform used in GoLore \cite{he2024subspace}, demonstrating I3S is better at minimizing the sacrifice in pretrained LLM performance compared to full-rank training.

\ifdefined\isarxiv

\else
\section*{Impact Statement}

This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.
\fi