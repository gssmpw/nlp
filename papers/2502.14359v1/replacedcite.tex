\section{Related Work}
\label{sec:related}
%====================================

 ____ proposes {\tt Holmes} as a framework to assess the English linguistic competence of language models. They evaluate models' competence (morphology, syntax, and semantics) by comparing them across architectures and sizes by probing their internal representations. %through the use of probing classifiers from the models' internal representations. 
 %They show that overall models excel at  morphology and syntax, that such competence scales with model size and is further boosted by instruction tuning. Whereas the architecture has an impact on the models' lexical semantic competence with the encoder models encoding linguistic phenomena better. Moreover, they compare models on their logical deduction reasoning ability, paying particular attention to negation, and to discourse focusing on rhetorical structure showing, again through probing classifiers, that LMs encode less information about these functional phenomena. 
%Finally, 
Moreover, by measuring the correlation between {\tt Holmes} and downstream tasks results, they observe that morphology highly correlates with reasoning. Rather than on formal linguistic competence, we focus on functional linguistic competences and compare them not just with large QA benchmarks but also with interactive games.
%____ instead evaluate models on functional linguistic competence, present in BigBench____, aiming to verify whether they are "emergent abilities", as claimed in the literature, and show that they are the result of a combination of in-context learning, model memory, and linguistic knowledge.
%Social reasoning reviewed in____. 
____ carry out a holistic evaluation of LLMs' Theory of Mind by inspecting the literature through the competences a model with a ToM should have based on a known taxonomy. 
%This taxonomized review of benchmarks highlights which abilities are already evaluated and which are not.  
%____ call the attention on games as an instrument to study the emergent abilities of LLMs, considering their core functional components: perception, memory, thinking, role-playing, action, and learning. 
Similarly, we take a top-down approach but consider the whole spectrum of cognitive abilities and highlight the importance of connecting them with the complementary benchmarks largely used by the community to monitor LLMs' progress.



%and take a picture of the current evaluation landscape both for executive functional and social and emotional abilities. 


%====================================