@article{202307.1723,
	doi = {10.20944/preprints202307.1723.v1},
	url = {https://doi.org/10.20944/preprints202307.1723.v1},
	year = 2023,
	month = {July},
	publisher = {Preprints},
	author = {Boris A. Galitsky},
	title = {Truth-O-Meter: Collaborating with LLM in Fighting its Hallucinations},
	journal = {Preprints}
}

@inproceedings{Atanasova2020GeneratingFC,
  title={Generating Fact Checking Explanations},
  author={Pepa Atanasova and Jakob Grue Simonsen and Christina Lioma and Isabelle Augenstein},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:215744944}
}

@article{Hanselowski2019ARA,
  title={A Richly Annotated Corpus for Different Tasks in Automated Fact-Checking},
  author={Andreas Hanselowski and Christian Stab and Claudia Schulz and Zile Li and Iryna Gurevych},
  journal={ArXiv},
  year={2019},
  volume={abs/1911.01214},
  url={https://api.semanticscholar.org/CorpusID:207779874}
}

@inproceedings{Moon2019OpenDialKGEC,
  title={OpenDialKG: Explainable Conversational Reasoning with Attention-based Walks over Knowledge Graphs},
  author={Seungwhan Moon and Pararth Shah and Anuj Kumar and Rajen Subba},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:196176000}
}

@article{agrawal2023language,
  title={Do Language Models Know When They're Hallucinating References?},
  author={Agrawal, Ayush and Suzgun, Mirac and Mackey, Lester and Kalai, Adam Tauman},
  journal={arXiv preprint arXiv:2305.18248},
  year={2023},
  doi = {10.48550/arXiv.2305.18248}
}

@article{augenstein2019multifc,
  title={MultiFC: A real-world multi-domain dataset for evidence-based fact checking of claims},
  author={Augenstein, Isabelle and Lioma, Christina and Wang, Dongsheng and Lima, Lucas Chaves and Hansen, Casper and Hansen, Christian and Simonsen, Jakob Grue},
  journal={arXiv preprint arXiv:1909.03242},
  year={2019},
  doi={10.48550/arXiv.1909.03242}
}

@online{chatgptintro,
    title = {OpenAI ChatGPT},
    year = {2022},
    url = {https://openai.com/index/chatgpt/},
}

@article{cohen2023lm,
  title={Lm vs lm: Detecting factual errors via cross examination},
  author={Cohen, Roi and Hamri, May and Geva, Mor and Globerson, Amir},
  journal={arXiv preprint arXiv:2305.13281},
  year={2023},
  doi={10.48550/arXiv.2305.13281}
}

@article{guo2022survey,
  title={A survey on automated fact-checking},
  author={Guo, Zhijiang and Schlichtkrull, Michael and Vlachos, Andreas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={178--206},
  year={2022},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~â€¦}
}

@article{huo2023retrieving,
  title={Retrieving supporting evidence for llms generated answers},
  author={Huo, Siqing and Arabzadeh, Negar and Clarke, Charles LA},
  journal={arXiv preprint arXiv:2306.13781},
  year={2023},
  doi={10.48550/arXiv.2306.13781}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022},
  doi={10.48550/arXiv.2207.05221}
}

@article{kasai2024realtime,
  title={REALTIME QA: what's the answer right now?},
  author={Kasai, Jungo and Sakaguchi, Keisuke and Le Bras, Ronan and Asai, Akari and Yu, Xinyan and Radev, Dragomir and Smith, Noah A and Choi, Yejin and Inui, Kentaro and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{li2023halueval,
  title={Halueval: A large-scale hallucination evaluation benchmark for large language models},
  author={Li, Junyi and Cheng, Xiaoxue and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2305.11747},
  year={2023},
  doi={10.48550/arXiv.2305.11747}
}

@article{li2024halluvault,
  title={HalluVault: A Novel Logic Programming-aided Metamorphic Testing Framework for Detecting Fact-Conflicting Hallucinations in Large Language Models},
  author={Li, Ningke and Li, Yuekang and Liu, Yi and Shi, Ling and Wang, Kailong and Wang, Haoyu},
  journal={arXiv preprint arXiv:2405.00648},
  year={2024},
  doi={10.48550/arXiv.2405.00648}
}

@article{see2017get,
  title={Get to the point: Summarization with pointer-generator networks},
  author={See, Abigail and Liu, Peter J and Manning, Christopher D},
  journal={arXiv preprint arXiv:1704.04368},
  year={2017},
  doi={10.48550/arXiv.1704.04368}
}

@article{varshney2023stitch,
  title={A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation},
  author={Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong},
  journal={arXiv preprint arXiv:2307.03987},
  year={2023},
  doi={10.48550/arXiv.2307.03987}
}

@article{xiong2023can,
  title={Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms},
  author={Xiong, Miao and Hu, Zhiyuan and Lu, Xinyang and Li, Yifei and Fu, Jie and He, Junxian and Hooi, Bryan},
  journal={arXiv preprint arXiv:2306.13063},
  year={2023},
  doi={10.48550/arXiv.2306.13063}
}

@article{yao2023llm,
  title={Llm lies: Hallucinations are not bugs, but features as adversarial examples},
  author={Yao, Jia-Yu and Ning, Kun-Peng and Liu, Zhen-Hui and Ning, Mu-Nan and Yuan, Li},
  journal={arXiv preprint arXiv:2310.01469},
  year={2023},
  doi={10.48550/arXiv.2310.01469}
}

