@online{chatgptintro,
    title = {OpenAI ChatGPT},
    year = {2022},
    url = {https://openai.com/index/chatgpt/},
}
@online{llama3intro,
    title = {Introducing Meta Llama 3: The most capable openly available LLM to date},
    year = {2024},
    url = {https://ai.meta.com/blog/meta-llama-3/},
}

@article{kryscinski2019evaluating,
  title={Evaluating the factual consistency of abstractive text summarization},
  author={Kry{\'s}ci{\'n}ski, Wojciech and McCann, Bryan and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1910.12840},
  year={2019},
  doi={10.48550/arXiv.1910.12840
}
}

@article{huang2023survey,
    title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
    author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
    journal={arXiv preprint arXiv:2311.05232},
    year={2023},
    doi={10.1145/3703155}
}

@article{openai2023gpt,
    title={GPT-4 technical report},
    author={OpenAI, R and others},
    journal={ArXiv},
    volume={2303},
    pages={08774},
    year={2023},
    doi={10.48550/arXiv.2303.08774
}
}

@article{guo2022survey,
  title={A survey on automated fact-checking},
  author={Guo, Zhijiang and Schlichtkrull, Michael and Vlachos, Andreas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={178--206},
  year={2022},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~â€¦}
}

@article{varshney2023stitch,
  title={A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation},
  author={Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong},
  journal={arXiv preprint arXiv:2307.03987},
  year={2023},
  doi={10.48550/arXiv.2307.03987}
}

@article{manakul2023selfcheckgpt,
  title={Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models},
  author={Manakul, Potsawee and Liusie, Adian and Gales, Mark JF},
  journal={arXiv preprint arXiv:2303.08896},
  year={2023},
  doi={10.48550/arXiv.2303.08896}
}

@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}

@article{yao2024survey,
  title={A survey on large language model (llm) security and privacy: The good, the bad, and the ugly},
  author={Yao, Yifan and Duan, Jinhao and Xu, Kaidi and Cai, Yuanfang and Sun, Zhibo and Zhang, Yue},
  journal={High-Confidence Computing},
  pages={100211},
  year={2024},
  publisher={Elsevier}
}

@article{zhang2023siren,
  title={Siren's song in the AI ocean: a survey on hallucination in large language models},
  author={Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
  journal={arXiv preprint arXiv:2309.01219},
  year={2023},
  doi={10.48550/arXiv.2309.01219}
}

@article{li2022faithfulness,
  title={Faithfulness in natural language generation: A systematic survey of analysis, evaluation and optimization methods},
  author={Li, Wei and Wu, Wenhao and Chen, Moye and Liu, Jiachen and Xiao, Xinyan and Wu, Hua},
  journal={arXiv preprint arXiv:2203.05227},
  year={2022},
  doi={10.48550/arXiv.2203.05227}
}

@article{chen2023complex,
  title={Complex claim verification with evidence retrieved in the wild},
  author={Chen, Jifan and Kim, Grace and Sriram, Aniruddh and Durrett, Greg and Choi, Eunsol},
  journal={arXiv preprint arXiv:2305.11859},
  year={2023},
  doi={10.48550/arXiv.2305.11859}
}

@article{chern2023factool,
  title={FacTool: Factuality Detection in Generative AI--A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios},
  author={Chern, I and Chern, Steffi and Chen, Shiqi and Yuan, Weizhe and Feng, Kehua and Zhou, Chunting and He, Junxian and Neubig, Graham and Liu, Pengfei and others},
  journal={arXiv preprint arXiv:2307.13528},
  year={2023},
  doi={10.48550/arXiv.2307.13528}
}

@article{min2023factscore,
  title={Factscore: Fine-grained atomic evaluation of factual precision in long form text generation},
  author={Min, Sewon and Krishna, Kalpesh and Lyu, Xinxi and Lewis, Mike and Yih, Wen-tau and Koh, Pang Wei and Iyyer, Mohit and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2305.14251},
  year={2023},
  doi={10.48550/arXiv.2305.14251}
}

@article{luo2023chatgpt,
  title={Chatgpt as a factual inconsistency evaluator for text summarization},
  author={Luo, Zheheng and Xie, Qianqian and Ananiadou, Sophia},
  journal={arXiv preprint arXiv:2303.15621},
  year={2023},
  doi={10.48550/arXiv.2303.15621}
}

@article{abboud2020boxe,
  title={Boxe: A box embedding model for knowledge base completion},
  author={Abboud, Ralph and Ceylan, Ismail and Lukasiewicz, Thomas and Salvatori, Tommaso},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9649--9661},
  year={2020}
}

@article{liang2024survey,
  title={A survey of knowledge graph reasoning on graph types: Static, dynamic, and multi-modal},
  author={Liang, Ke and Meng, Lingyuan and Liu, Meng and Liu, Yue and Tu, Wenxuan and Wang, Siwei and Zhou, Sihang and Liu, Xinwang and Sun, Fuchun and He, Kunlun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@article{ren2020beta,
  title={Beta embeddings for multi-hop logical reasoning in knowledge graphs},
  author={Ren, Hongyu and Leskovec, Jure},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={19716--19726},
  year={2020}
}

@article{tian2022knowledge,
  title={Knowledge graph and knowledge reasoning: A systematic review},
  author={Tian, Ling and Zhou, Xue and Wu, Yan-Ping and Zhou, Wang-Tao and Zhang, Jin-Hao and Zhang, Tian-Shu},
  journal={Journal of Electronic Science and Technology},
  volume={20},
  number={2},
  pages={100159},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{zhou2019completing,
  title={On completing sparse knowledge base with transitive relation embedding},
  author={Zhou, Zili and Liu, Shaowu and Xu, Guandong and Zhang, Wu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={3125--3132},
  year={2019}
}

@article{lin2021truthfulqa,
  title={Truthfulqa: Measuring how models mimic human falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2109.07958},
  year={2021},
  doi={10.48550/arXiv.2109.07958}
}

@article{yang2018hotpotqa,
  title={HotpotQA: A dataset for diverse, explainable multi-hop question answering},
  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D},
  journal={arXiv preprint arXiv:1809.09600},
  year={2018},
  doi={10.48550/arXiv.1809.09600}
}

@article{vu2023freshllms,
  title={Freshllms: Refreshing large language models with search engine augmentation},
  author={Vu, Tu and Iyyer, Mohit and Wang, Xuezhi and Constant, Noah and Wei, Jerry and Wei, Jason and Tar, Chris and Sung, Yun-Hsuan and Zhou, Denny and Le, Quoc and others},
  journal={arXiv preprint arXiv:2310.03214},
  year={2023},
  doi={10.48550/arXiv.2310.03214
}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{yucan,
  title={CAN LLMS HAVE A FEVER? INVESTIGATING THE EFFECTS OF TEMPERATURE ON LLM SECURITY},
  author={Yu, Chan Xing and James, Chan Si Yu and David, Poh Hui-Li Phyllis}
}

@article{varshney2024investigating,
  title={Investigating and Addressing Hallucinations of LLMs in Tasks Involving Negation},
  author={Varshney, Neeraj and Raj, Satyam and Mishra, Venkatesh and Chatterjee, Agneet and Sarkar, Ritika and Saeidi, Amir and Baral, Chitta},
  journal={arXiv preprint arXiv:2406.05494},
  year={2024},
  doi={10.48550/arXiv.2406.05494}
}

@article{asher2024strong,
  title={Strong hallucinations from negation and how to fix them},
  author={Asher, Nicholas and Bhar, Swarnadeep},
  journal={arXiv preprint arXiv:2402.10543},
  year={2024},
  doi={10.48550/arXiv.2402.10543}
}

@article{pan2023automatically,
  title={Automatically correcting large language models: Surveying the landscape of diverse self-correction strategies},
  author={Pan, Liangming and Saxon, Michael and Xu, Wenda and Nathani, Deepak and Wang, Xinyi and Wang, William Yang},
  journal={arXiv preprint arXiv:2308.03188},
  year={2023}
}

@article{augenstein2019multifc,
  title={MultiFC: A real-world multi-domain dataset for evidence-based fact checking of claims},
  author={Augenstein, Isabelle and Lioma, Christina and Wang, Dongsheng and Lima, Lucas Chaves and Hansen, Casper and Hansen, Christian and Simonsen, Jakob Grue},
  journal={arXiv preprint arXiv:1909.03242},
  year={2019},
  doi={10.48550/arXiv.1909.03242}
}

@article{Hanselowski2019ARA,
  title={A Richly Annotated Corpus for Different Tasks in Automated Fact-Checking},
  author={Andreas Hanselowski and Christian Stab and Claudia Schulz and Zile Li and Iryna Gurevych},
  journal={ArXiv},
  year={2019},
  volume={abs/1911.01214},
  url={https://api.semanticscholar.org/CorpusID:207779874}
}

@inproceedings{Atanasova2020GeneratingFC,
  title={Generating Fact Checking Explanations},
  author={Pepa Atanasova and Jakob Grue Simonsen and Christina Lioma and Isabelle Augenstein},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:215744944}
}

@article{202307.1723,
	doi = {10.20944/preprints202307.1723.v1},
	url = {https://doi.org/10.20944/preprints202307.1723.v1},
	year = 2023,
	month = {July},
	publisher = {Preprints},
	author = {Boris A. Galitsky},
	title = {Truth-O-Meter: Collaborating with LLM in Fighting its Hallucinations},
	journal = {Preprints}
}

@article{huo2023retrieving,
  title={Retrieving supporting evidence for llms generated answers},
  author={Huo, Siqing and Arabzadeh, Negar and Clarke, Charles LA},
  journal={arXiv preprint arXiv:2306.13781},
  year={2023},
  doi={10.48550/arXiv.2306.13781}
}

@article{yao2023llm,
  title={Llm lies: Hallucinations are not bugs, but features as adversarial examples},
  author={Yao, Jia-Yu and Ning, Kun-Peng and Liu, Zhen-Hui and Ning, Mu-Nan and Yuan, Li},
  journal={arXiv preprint arXiv:2310.01469},
  year={2023},
  doi={10.48550/arXiv.2310.01469}
}

@article{cohen2023lm,
  title={Lm vs lm: Detecting factual errors via cross examination},
  author={Cohen, Roi and Hamri, May and Geva, Mor and Globerson, Amir},
  journal={arXiv preprint arXiv:2305.13281},
  year={2023},
  doi={10.48550/arXiv.2305.13281}
}

@article{xiong2023can,
  title={Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms},
  author={Xiong, Miao and Hu, Zhiyuan and Lu, Xinyang and Li, Yifei and Fu, Jie and He, Junxian and Hooi, Bryan},
  journal={arXiv preprint arXiv:2306.13063},
  year={2023},
  doi={10.48550/arXiv.2306.13063}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022},
  doi={10.48550/arXiv.2207.05221}
}

@article{li2024halluvault,
  title={HalluVault: A Novel Logic Programming-aided Metamorphic Testing Framework for Detecting Fact-Conflicting Hallucinations in Large Language Models},
  author={Li, Ningke and Li, Yuekang and Liu, Yi and Shi, Ling and Wang, Kailong and Wang, Haoyu},
  journal={arXiv preprint arXiv:2405.00648},
  year={2024},
  doi={10.48550/arXiv.2405.00648}
}

@article{li2023halueval,
  title={Halueval: A large-scale hallucination evaluation benchmark for large language models},
  author={Li, Junyi and Cheng, Xiaoxue and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2305.11747},
  year={2023},
  doi={10.48550/arXiv.2305.11747}
}

@inproceedings{Moon2019OpenDialKGEC,
  title={OpenDialKG: Explainable Conversational Reasoning with Attention-based Walks over Knowledge Graphs},
  author={Seungwhan Moon and Pararth Shah and Anuj Kumar and Rajen Subba},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:196176000}
}

@article{see2017get,
  title={Get to the point: Summarization with pointer-generator networks},
  author={See, Abigail and Liu, Peter J and Manning, Christopher D},
  journal={arXiv preprint arXiv:1704.04368},
  year={2017},
  doi={10.48550/arXiv.1704.04368}
}

@article{kasai2024realtime,
  title={REALTIME QA: what's the answer right now?},
  author={Kasai, Jungo and Sakaguchi, Keisuke and Le Bras, Ronan and Asai, Akari and Yu, Xinyan and Radev, Dragomir and Smith, Noah A and Choi, Yejin and Inui, Kentaro and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{agrawal2023language,
  title={Do Language Models Know When They're Hallucinating References?},
  author={Agrawal, Ayush and Suzgun, Mirac and Mackey, Lester and Kalai, Adam Tauman},
  journal={arXiv preprint arXiv:2305.18248},
  year={2023},
  doi = {10.48550/arXiv.2305.18248}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{moramarco2021preliminary,
  title={A preliminary study on evaluating consultation notes with post-editing},
  author={Moramarco, Francesco and Korfiatis, Alex Papadopoulos and Savkov, Aleksandar and Reiter, Ehud},
  journal={arXiv preprint arXiv:2104.04402},
  year={2021},
  doi={10.48550/arXiv.2104.04402}
}

@article{lai2022exploration,
  title={An exploration of post-editing effectiveness in text summarization},
  author={Lai, Vivian and Smith-Renner, Alison and Zhang, Ke and Cheng, Ruijia and Zhang, Wenjuan and Tetreault, Joel and Jaimes, Alejandro},
  journal={arXiv preprint arXiv:2206.06383},
  year={2022},
  doi={10.48550/arXiv.2206.06383}
}

@inproceedings{zhang2023concepteva,
  title={ConceptEVA: concept-based interactive exploration and customization of document summaries},
  author={Zhang, Xiaoyu and Li, Jianping and Chi, Po-Wei and Chandrasegaran, Senthil and Ma, Kwan-Liu},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2023}
}

@article{xu2024hallucination,
  title={Hallucination is inevitable: An innate limitation of large language models},
  author={Xu, Ziwei and Jain, Sanjay and Kankanhalli, Mohan},
  journal={arXiv preprint arXiv:2401.11817},
  year={2024},
  doi={10.48550/arXiv.2401.11817}
}

@article{white2024livebench,
  title={Livebench: A challenging, contamination-free llm benchmark},
  author={White, Colin and Dooley, Samuel and Roberts, Manley and Pal, Arka and Feuer, Ben and Jain, Siddhartha and Shwartz-Ziv, Ravid and Jain, Neel and Saifullah, Khalid and Naidu, Siddartha and others},
  journal={arXiv preprint arXiv:2406.19314},
  year={2024},
  doi={10.48550/arXiv.2406.19314}
}

@inproceedings{dhuliawala2023chain,
    title = "Chain-of-Verification Reduces Hallucination in Large Language Models",
    author = "Dhuliawala, Shehzaad  and
      Komeili, Mojtaba  and
      Xu, Jing  and
      Raileanu, Roberta  and
      Li, Xian  and
      Celikyilmaz, Asli  and
      Weston, Jason",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.212",
    pages = "3563--3578",
    abstract = "Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other responses; and (iv) generates its final verified response. In experiments, we show CoVe decreases hallucinations across a variety of tasks, from list-based questions from Wikidata, closed book MultiSpanQA and longform text generation.",
}
@INPROCEEDINGS{hyun2024metal,
  author={Hyun, Sangwon and Guo, Mingyu and Babar, M. Ali},
  booktitle={2024 IEEE Conference on Software Testing, Verification and Validation (ICST)}, 
  title={METAL: Metamorphic Testing Framework for Analyzing Large-Language Model Qualities}, 
  year={2024},
  volume={},
  number={},
  pages={117-128},
  keywords={Measurement;Software testing;Systematics;Perturbation methods;Semantics;Metals;Probabilistic logic;Large-language models;Metamorphic testing;Quality attributes;Text perturbations},
  doi={10.1109/ICST60714.2024.00019}}

@article{qin2024large,
  title={Large language models meet nlp: A survey},
  author={Qin, Libo and Chen, Qiguang and Feng, Xiachong and Wu, Yang and Zhang, Yongheng and Li, Yinghui and Li, Min and Che, Wanxiang and Yu, Philip S},
  journal={arXiv preprint arXiv:2405.12819},
  year={2024},
  doi={10.48550/arXiv.2405.12819}
}

@article{Ouyang2025,
author = {Ouyang, Shuyin and Zhang, Jie M. and Harman, Mark and Wang, Meng},
title = {An Empirical Study of the Non-Determinism of ChatGPT in Code Generation},
year = {2025},
issue_date = {February 2025},
volume = {34},
number = {2},
issn = {1049-331X},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {42},
numpages = {28},
}

@ARTICLE{9000651,
  author={Zhang, Jie M. and Harman, Mark and Ma, Lei and Liu, Yang},
  journal={IEEE Transactions on Software Engineering}, 
  title={Machine Learning Testing: Survey, Landscapes and Horizons}, 
  year={2022},
  volume={48},
  number={1},
  pages={1-36},}


@article{chen2018metamorphic,
  title={Metamorphic testing: A review of challenges and opportunities},
  author={Chen, Tsong Yueh and Kuo, Fei-Ching and Liu, Huai and Poon, Pak-Lok and Towey, Dave and Tse, TH and Zhou, Zhi Quan},
  journal={ACM Computing Surveys (CSUR)},
  volume={51},
  number={1},
  pages={1--27},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{zhang2014search,
  title={Search-based inference of polynomial metamorphic relations},
  author={Zhang, Jie and Chen, Junjie and Hao, Dan and Xiong, Yingfei and Xie, Bing and Zhang, Lu and Mei, Hong},
  booktitle={Proceedings of the 29th ACM/IEEE international conference on Automated software engineering},
  pages={701--712},
  year={2014}
}

@inproceedings{sun2020automatic,
  title={Automatic testing and improvement of machine translation},
  author={Sun, Zeyu and Zhang, Jie M and Harman, Mark and Papadakis, Mike and Zhang, Lu},
  booktitle={Proceedings of the ACM/IEEE 42nd international conference on software engineering},
  pages={974--985},
  year={2020}
}

@article{foster2025mutation,
  title={Mutation-Guided LLM-based Test Generation at Meta},
  author={Foster, Christopher and Gulati, Abhishek and Harman, Mark and Harper, Inna and Mao, Ke and Ritchey, Jillian and Robert, Herv{\'e} and Sengupta, Shubho},
  journal={arXiv preprint arXiv:2501.12862},
  year={2025},
  doi={10.48550/arXiv.2501.12862}
}

