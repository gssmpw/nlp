\begin{table}[h]
\centering
\caption{Compression Rates for Different Models.}
\label{tokenizer_compression_rate}
\begin{tabular}{lcccccc}
\toprule
 & Baichuan2 & ChatGLM2 & Llama2 & MiniCPM & Megrez \\
\midrule
Vocab Size & 125,696 & 64,794 & 32,000 & 122,753 & 120,000 \\
\midrule
\multicolumn{6}{c}{\textbf{Compression Rate (Bytes/Tokens)}} \\
\midrule
Chinese & 3.64 & 3.54 & 1.87 & 3.73 & 5.02 \\
English & 4.12 & 4.02 & 3.78 & 4.14 & 4.28 \\
Code & 2.71 & 2.71 & 2.74 & 2.81 & 2.69 \\
Paper & 2.74 & 2.88 & 2.97 & 2.93 & 3.48 \\
\midrule
Average & 3.30 & 3.29 & 2.84 & 3.40 & 3.86 \\
\bottomrule
\end{tabular}
\end{table}