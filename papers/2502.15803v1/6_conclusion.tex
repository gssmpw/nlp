\section{Conclusion}

In this work, we have open-sourced Megrez-3B-Omni as a step toward developing a truly omni-modal LLM that integrates all human senses. Our Megrez-3B-Omni has achieved leading levels in integrating comprehension across image, text, and audio. 
Despite its promising performance, there remains significant room for improvement in the foundational capabilities across each individual modality. This includes (1) supporting multi-image and video understanding; (2) developing an end-to-end TTS system integrated with LLMs; (3) enhancing perception capabilities for complex visual tasks; (4) supporting real-time video and audio streams in live interactions; and (5) solving complex reasoning problems with reinforcement learning.