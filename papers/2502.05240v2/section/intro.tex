\section{Introduction}
\label{sec:intro}
%背景引入

\IEEEPARstart{I}n recent years, GenAI technologies have witnessed explosive growth, particularly in generating text, image, audio, and video. Models such as GPT-4o~\cite{openai2024}, DALL-E~\cite{betker2023improving}, Stable Diffusion~\cite{rombach2022high}, Sora~\cite{brooks2024video}, and Deepfake technologies have found widespread applications in journalism, entertainment, advertising, and personal content creation. However, these rapidly advancing technologies~\cite{li2023pluralistic, li2019global, cui2024localize} have also raised profound societal and technical concerns, including the spread of misinformation~\cite{xu2023combating, ma2024deep}, privacy breaches~\cite{jenks2024communicating}, ethical dilemmas~\cite{samuelson2023generative,liu2024jailbreak}, and economic fraud. Against this backdrop, effective AI-generated media detection methods have become imperative. Such methods not only assist in identifying fraudulent content and maintaining the authenticity and credibility of data but also strengthen societal trust and mitigate the negative impacts of misinformation.


With the continuous advancement of MLLMs, they have become the primary tools for processing AI-generated media. MLLMs can handle various types of input modalities, including text, image, audio, and video while generating high-quality textual outputs. This cross-modal capability provides MLLMs with a unique advantage in detecting AI-generated media, particularly in scenarios that require the integration of information from different modalities for in-depth analysis. Furthermore, the textual explanations generated by MLLMs offer a flexible framework for subsequent analysis, supporting personalized detection tasks such as identifying forged regions or abnormal content. As a result, MLLMs not only enhance detection accuracy but also provide robust support for more complex tasks.

Current AI-generated media detection methods can be broadly categorized into two types: domain-specific detectors (Non-MLLM-based) and general-purpose detectors (MLLM-based). Non-MLLM-based methods, typically tailored for specific tasks, excel at high-precision detection in constrained scenarios. Their lightweight architectures and focused designs make them highly efficient in resource-limited environments, such as mobile or embedded systems~\cite{epstein2023online, akram2023empirical}. In contrast, MLLM-based methods leverage MLLMs to integrate information across different modalities. The reason why they can perform multiple tasks flexibly and generalize is that they can do human-like reasoning and generate free-form text output. This enables them to perform tasks such as authenticity detection, explainability, and localization, providing unparalleled flexibility for complex challenges like multimodal forgery localization and explainability. While Non-MLLM-based methods demonstrate efficiency and accuracy in domain-specific tasks, their focus on a single modality limits adaptability to emerging challenges. On the other hand, despite their computational intensity, MLLM-based methods offer human-like understanding, extensive knowledge access, text-driven evaluation, and human-accessible contextual explanations~\cite{dang2024explainable}. Additionally, they exhibit robust scalability and adaptability to diverse input scenarios, making them particularly suitable for applications such as real-time misinformation monitoring and comprehensive content authenticity analysis. The transition from Non-MLLM to MLLM methods marks a transformative phase in the field of AI-generated media detection.

\begin{figure*}[!ht]
  \centering
    \includegraphics[width=1.0\linewidth]{Fig/Main.pdf} 
    \caption{Survey at A Glance. (a) \textit{Input and Methods}. This constitutes the core of our work. We categorize the inputs for AI-generated media detection into five distinct modalities, with task types including authenticity detection, explainability, and localization. We conduct an in-depth review of over 100 studies, classifying them into Non-MLLM detectors and MLLM detectors. (b) \textit{Benchmarking}. We classify popular and emerging benchmarks based on task types—authenticity detection, explainability, and localization—and discuss them according to their modality-specific approaches. (c) \textit{Policies}. We analyze and discuss the legal frameworks and scholarly debates across various countries, categorizing AI-generated media policy into initiatives, regulations, and blueprints. This section provides valuable insights for researchers in the field. (d) \textit{Future Trends}. We explore how AI-generated media detection could benefit from broader modality support, advancements in MLLMs detection capabilities, and improvements in legal regulations. Some images are courtesy of online resources. 
    % \zekun{Change Benchmarking to Benchamarks or Evaluation?}
    % \zekun{It would be good to ensure consistent font usage across all the figures in the paper. Do you have a rule for font usage? like which fonts for which usage and scenario.}
    }
    \label{fig:main}
\end{figure*}

Previous surveys on AI-generated media detection have predominantly focused on Non-MLLM-based methods. For instance, ~\cite{lin2024detecting} discusses only Non-MLLM approaches without delving into specific sub-tasks, datasets, or evaluation benchmarks. Similarly, ~\cite{deng2024survey} is limited to detection methods in visual modalities, neglecting explainability and forgery localization, while~\cite{yu2024fake} primarily focuses on generative techniques, providing insufficient detail on detection methodologies. These surveys fail to up-to-date MLLM methods, particularly in terms of their capabilities for multimodal fusion and explainability, and pay little attention to the development and applications of MLLM-based detectors. As the complexity of multimodal GenAI continues to grow, these gaps have become increasingly significant, driven by the need for transparency, interpretability, and model generalization in generated content. Existing surveys fall short of addressing these emerging requirements.

To bridge this gap, this paper presents a comprehensive and structured survey of AI-generated media detection methods, with a particular focus on the transition from Non-MLLM to MLLM approaches. By analyzing methods across single-modal and multimodal tasks (authenticity, explainability, and localization), we uncover the differences and commonalities between these two categories, highlighting their strengths, limitations, and potential synergies. We provide an extensive overview of datasets, evaluation metrics, and future research directions, offering a foundational reference for advancing AI-generated media detection technologies. Notably, as MLLM methods gain widespread adoption, the ethical and security concerns they raised have become critical focal points, underscoring the importance of responsible AI usage. To this end, this paper also summarizes global ethical guidelines for MLLM applications and their implications, providing valuable insights for future research.

The main contributions of this work can be summarized as follows:
\begin{itemize}
    \item This survey paper classifies and summarizes AI-generated media detection methods from two dimensions—Non-MLLM-based detectors and MLLM-based detectors—while addressing different modalities and detection tasks (authenticity, explainability, and localization). This work establishes a detailed taxonomy and provides a comprehensive review of existing methods.
    \item For each category of methods, this paper analyzes and summarizes their key challenges, core concepts, strengths, limitations, and potential applications. Notably, our discussion also highlights previously unexplored insights, offering valuable perspectives for researchers. 
    \item We delve into the challenges and unresolved issues currently faced by the field, with particular emphasis on the security and ethical concerns associated with AI-generated media detection. Furthermore, we summarize the ethical guidelines established by various countries, providing directional guidance for future research to ensure that technological advancements are developed with careful consideration of their societal impacts.
\end{itemize}

The overall structure of this paper, as illustrated in Fig.~\ref{fig:main}, is organized as follows: Section~\ref{sec:back} introduces generative approaches for different modalities, problem definitions, and key formulations. Sections~\ref{sec:mllm} and~\ref{sec:non-mllm} review Non-MLLM-based and MLLM-based detection methods. Section~\ref{sec:val} summarizes common benchmarks and datasets, along with their design and evaluation criteria. Section~\ref{sec:reg} compares the legal and regulatory frameworks of different countries for GenAI. Section~\ref{sec:future} discusses future challenges and opportunities in AI-generated media detection. Finally, Section~\ref{sec:concl} concludes with key findings and actionable insights for researchers and policymakers.




 

