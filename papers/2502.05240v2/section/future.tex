\section{Future Work}
\label{sec:future}
~\textbf{From Specialized to Generalized Detection:} Specialized detectors are typically optimized for specific modalities (\textit{e.g., text, image, audio}) or tasks (\textit{e.g., detection, explanation, localization}). In contrast, generalized detectors aim to achieve broad applicability across modalities and tasks. However, existing generalized detectors based on large models still face significant challenges in accuracy, primarily due to the trade-off between generalization and precision. Future research should focus on developing detectors capable of handling diverse modality inputs and tasks while maintaining robust performance in complex scenarios. Integrating Multi-Agent Systems could be a promising direction to enhance detection efficiency and reliability in multimodal and multitask environments.


~\textbf{Specialized and Generalized Detector Collaboration:} Given the lower accuracy of generalized detectors, current approaches often enhance performance by integrating external specialized detectors~\cite{chen2024textit, huang2024ffaa}. The collaboration between specialized and generalized detectors holds the potential to achieve optimal performance and adaptability. Future research should focus on developing synergistic mechanisms for their integration and designing hierarchical detection frameworks. 


~\textbf{Broader Modality Support:} Current research reveals a significant gap in the explainability and localization methods of generalized detectors, particularly for video and audio modalities. This gap is even more pronounced in complex multimodal tasks, such as Image-Text and Visual-Audio pairs, which demand advanced cross-modal techniques for explainability and localization. Future studies should focus on developing multimodal fusion frameworks and localization algorithms, enabling deeper integration and sharing of information across modalities.

~\textbf{Benchmarks for Explainability Evaluation:} Current MLLM-based explainability datasets lack unified benchmarks for systematically assessing the quality of generated content. Future research should explore the development of multidimensional evaluation frameworks for explainability, addressing critical issues such as model hallucination, overthinking, and alignment with real-world logic, grammatical structure, and semantic consistency. Establishing such benchmarks will enhance the reliability and trustworthiness of model outputs while providing guiding standards for subsequent technological advancements.

~\textbf{Generated Media Datasets:} Datasets of generated content play a pivotal role in AI-generated media detection, yet existing datasets have not adequately addressed issues of noise and bias in generated content. This is particularly evident in multimodal data and open-environment applications, where significant room for improvement remains. Future efforts should focus on developing toolchains for data cleaning, bias correction, and multidimensional consistency validation to enhance the reliability and explainability of generated data. Additionally, in-depth analysis of data quality issues will support the creation of high-quality detection models, driving technological advancements and practical adoption in AI-generated media detection.


~\textbf{Ethical and Privacy Considerations:} Ethical and privacy concerns are paramount in the development of explainable detectors, particularly when these tools are utilized for legal evidence analysis. Future detectors must adhere to the requirements outlined in the EU AIA, ensuring compliance with legal and ethical standards. Additionally, safeguarding data security while preventing privacy breaches during large model-driven decision-making processes remains a core challenge for future research. Efforts should focus on creating detection systems with robust privacy-preserving mechanisms and transparency features, enhancing both the security and reliability of the models.


~\textbf{Interdisciplinary Collaboration and Multilateral Cooperation:} The future of generative AI detection relies on close collaboration across technology, legal, and social sciences. Research should align with global policies, such as the EU AIA, to optimize detection technologies and drive the establishment of unified international standards, including those by IEEE and ISO. Furthermore, integrating generative AI detection with domains like medical imaging and forensic analysis will enable the development of tailored solutions, expanding application scenarios. These efforts will foster the globalization of AI detection technologies and enhance multilateral cooperation.