\begin{table*}[t]
\centering
\small
\begin{tabular}{l|c|ccccc|cc} 
\hline
\multirow{3}{*}{\textbf{Method}} & \multirow{3}{*}{\textbf{Parameters}} & \multicolumn{5}{c|}{\textbf{Question Answering}} & \multicolumn{2}{c}{\textbf{Fact Verification}} \\ \cline{3-9}
 & &  \textbf{TABMWP} & \textbf{WTQ} & \textbf{HiTab} & \textbf{TAT-QA} & \textbf{FeTaQA} & \textbf{TabFact} & \textbf{InfoTabs} \\ 
 & & (Acc.) & (Acc.) & (Acc.) & (Acc.) & (BLEU) & (Acc.) & (Acc.) \\ 
\hline
\multicolumn{9}{l}{{\cellcolor[rgb]{0.957,0.957,0.957}}\textit{LLM (Text)}} \\
Llama2 & 7B & 22.82 & 16.39 & 10.72 & 13.73 & 10.93 & 9.20 & 38.92 \\
TableLlama & 7B & 10.10 & 24.97 & 46.57 & 19.04 & 38.38 & 79.37 & 46.57 \\
Llama3-Instruct & 8B & 42.01 & 21.24 & 6.97 & 13.08 & 12.66 & 73.89 & 54.00 \\
\multicolumn{9}{l}{{\cellcolor[rgb]{0.957,0.957,0.957}}\textit{MLLM (Image)}} \\
MiniGPT-4 & 7B & 0.22 & 0.90 & 0.20 & 0.13 & 0.39 & 0 & 0.10 \\
Qwen-VL & 7B & 3.30 & 0.09 & 0.06 & 0.13 & 0.45 & 1.12 & 0.65 \\
InternLM-XComposer& 7B & 0.06 & 0.05 & 0.12 & 0.26 & 2.62 & 1.19 & 1.11 \\
mPLUG-Owl & 7B & 1.76 & 0.62 & 0.25 & 0.13 & 7.42 & 7.46 & 5.53 \\
mPLUG-Owl2 & 7B & 6.83 & 0.67 & 0.13 & 0.39 & 11.91 & 8.21 & 26.19 \\
LLaVA v1.5 & 7B & 6.05 & 1.24 & 2.03 & 2.97 & 8.24 & 18.9 & 28.31 \\
Vary-toy & 1.8B & 4.42 & 7.96 & 3.42 & 8.81 & 2.44 & 6.33 & 6.98 \\
Monkey & 7B & 13.26 & 19.07 & 6.41 & 12.31 & 3.41 & 22.56 & 22.11 \\
Table-LLaVA  & 7B & 57.78 & 18.43 & 10.09 & 12.82 & 25.60 & 59.85 & 65.26 \\
Table-LLaVA & 13B & 59.77 & 20.41 & 10.85 & 15.67 & 28.03 & 65.00 & 66.91 \\
MiniCPM-V-2.6 & 8B & 83.68  & 47.97 & 56.53 & 51.55 & 32.68 & 78.48 & 73.03 \\

\multicolumn{9}{l}{{\cellcolor[rgb]{0.957,0.957,0.957}}\textit{MLLM (Image \& Text)}} \\
Table-LLaVA & 13B & 84.58 & 39.89 & 46.00 & 29.27 & \textbf{33.50} & 69.93 & 74.88\\
MiniCPM-V-2.6 & 8B & \uline{86.06} & 52.30 & 58.56 & 52.46 & 32.96 & 79.31 & 73.18 \\
w/ Vanilla SFT & 8B & 76.69 & \uline{55.54} & \uline{62.88} & \uline{58.91} & 16.92 & \textbf{82.54} & \textbf{76.22} \\
w/ \method{}  & 8B & \textbf{87.50} & \textbf{55.77} & \textbf{63.00} & \textbf{60.75} & \uline{33.18} & \uline{82.27} & \uline{75.74} \\
\hline
\end{tabular}
\caption{Overall Performance on TQA and TFV Tasks. The \textbf{best} results are marked in bold, while the \uline{second-best} results are underlined. We establish baselines using LLM (Text) and MLLM (Image) by feeding unimodal table representations to language models. Next, we use image-based and text-based table representations as inputs to train various MLLM (Image \& Text) models, demonstrating the effectiveness of our \method{}.} \label{tab:overall}
\end{table*}