@article{rt-2,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

 @article{ecot,
    title={Robotic Control via Embodied Chain-of-Thought Reasoning},
    author={Michał Zawalski and William Chen and Karl Pertsch and Oier Mees and Chelsea Finn and Sergey Levine},
    journal={arXiv preprint arXiv:2407.08693},
    year={2024}
} 

@article{pertsch2025fast,
  title={FAST: Efficient Action Tokenization for Vision-Language-Action Models},
  author={Pertsch, Karl and Stachowicz, Kyle and Ichter, Brian and Driess, Danny and Nair, Suraj and Vuong, Quan and Mees, Oier and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2501.09747},
  year={2025}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{zhang2024grape,
  title={Grape: Generalizing robot policy via preference alignment},
  author={Zhang, Zijian and Zheng, Kaiyuan and Chen, Zhaorun and Jang, Joel and Li, Yi and Wang, Chaoqi and Ding, Mingyu and Fox, Dieter and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2411.19309},
  year={2024}
}

@article{guo2025improving,
  title={Improving Vision-Language-Action Model with Online Reinforcement Learning},
  author={Guo, Yanjiang and Zhang, Jianke and Chen, Xiaoyu and Ji, Xiang and Wang, Yen-Jen and Hu, Yucheng and Chen, Jianyu},
  journal={arXiv preprint arXiv:2501.16664},
  year={2025}
}



@article{wen2024tinyvla,
  title={Tinyvla: Towards fast, data-efficient vision-language-action models for robotic manipulation},
  author={Wen, Junjie and Zhu, Yichen and Li, Jinming and Zhu, Minjie and Wu, Kun and Xu, Zhiyuan and Liu, Ning and Cheng, Ran and Shen, Chaomin and Peng, Yaxin and others},
  journal={arXiv preprint arXiv:2409.12514},
  year={2024}
}



@article{scaledp,
  title={Scaling diffusion policy in transformer to 1 billion parameters for robotic manipulation},
  author={Zhu, Minjie and Zhu, Yichen and Li, Jinming and Wen, Junjie and Xu, Zhiyuan and Liu, Ning and Cheng, Ran and Shen, Chaomin and Peng, Yaxin and Feng, Feifei and others},
  journal={arXiv preprint arXiv:2409.14411},
  year={2024}
}

@article{zhen20243d,
  title={3d-vla: A 3d vision-language-action generative world model},
  author={Zhen, Haoyu and Qiu, Xiaowen and Chen, Peihao and Yang, Jincheng and Yan, Xin and Du, Yilun and Hong, Yining and Gan, Chuang},
  journal={arXiv preprint arXiv:2403.09631},
  year={2024}
}

@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}


@article{wen2025dexvla,
  title={DexVLA: Vision-Language Model with Plug-In Diffusion Expert for General Robot Control},
  author={Wen, Junjie and Zhu, Yichen and Li, Jinming and Tang, Zhibin and Shen, Chaomin and Feng, Feifei},
  journal={arXiv preprint arXiv:2502.05855},
  year={2025}
}

@article{zhou2025chatvla,
  title={ChatVLA: Unified Multimodal Understanding and Robot Control with Vision-Language-Action Model},
  author={Zhou, Zhongyi and Zhu, Yichen and Zhu, Minjie and Wen, Junjie and Liu, Ning and Xu, Zhiyuan and Meng, Weibin and Cheng, Ran and Peng, Yaxin and Shen, Chaomin and others},
  journal={arXiv preprint arXiv:2502.14420},
  year={2025}
}

@article{zhao2025vlas,
  title={VLAS: Vision-Language-Action Model With Speech Instructions For Customized Robot Manipulation},
  author={Zhao, Wei and Ding, Pengxiang and Zhang, Min and Gong, Zhefei and Bai, Shuanghao and Zhao, Han and Wang, Donglin},
  journal={arXiv preprint arXiv:2502.13508},
  year={2025}
}

@inproceedings{ding2024quar,
  title={Quar-vla: Vision-language-action model for quadruped robots},
  author={Ding, Pengxiang and Zhao, Han and Zhang, Wenjie and Song, Wenxuan and Zhang, Min and Huang, Siteng and Yang, Ningxi and Wang, Donglin},
  booktitle={European Conference on Computer Vision},
  pages={352--367},
  year={2024},
  organization={Springer}
}



@article{gu2023rt-trajectory,
  title={Rt-trajectory: Robotic task generalization via hindsight trajectory sketches},
  author={Gu, Jiayuan and Kirmani, Sean and Wohlhart, Paul and Lu, Yao and Arenas, Montserrat Gonzalez and Rao, Kanishka and Yu, Wenhao and Fu, Chuyuan and Gopalakrishnan, Keerthana and Xu, Zhuo and others},
  journal={arXiv preprint arXiv:2311.01977},
  year={2023}
}


@misc{rt-affordance,
      title={RT-Affordance: Affordances are Versatile Intermediate Representations for Robot Manipulation}, 
      author={Soroush Nasiriany and Sean Kirmani and Tianli Ding and Laura Smith and Yuke Zhu and Danny Driess and Dorsa Sadigh and Ted Xiao},
      year={2024},
      eprint={2411.02704},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2411.02704}, 
}

@article{chang2023goat,
  title={Goat: Go to any thing},
  author={Chang, Matthew and Gervet, Theophile and Khanna, Mukul and Yenamandra, Sriram and Shah, Dhruv and Min, So Yeon and Shah, Kavit and Paxton, Chris and Gupta, Saurabh and Batra, Dhruv and others},
  journal={arXiv preprint arXiv:2311.06430},
  year={2023}
}


@article{belkhale2024rt-h,
  title={Rt-h: Action hierarchies using language},
  author={Belkhale, Suneel and Ding, Tianli and Xiao, Ted and Sermanet, Pierre and Vuong, Quon and Tompson, Jonathan and Chebotar, Yevgen and Dwibedi, Debidatta and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2403.01823},
  year={2024}
}


@inproceedings{yu2020metaworld,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on robot learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@article{multimodal_diffusion_transformer,
    title={Multimodal Diffusion Transformer: Learning Versatile Behavior from Multimodal Goals},
    author={Moritz Reuss and {\"O}mer Erdin{\c{c}} Ya{\u{g}}murlu and Fabian Wenzel and Rudolf Lioutikov},
    booktitle={Robotics: Science and Systems},
    year={2024}
    }

@inproceedings{liu2022compositional,
  title={Compositional visual generation with composable diffusion models},
  author={Liu, Nan and Li, Shuang and Du, Yilun and Torralba, Antonio and Tenenbaum, Joshua B},
  booktitle={European Conference on Computer Vision},
  pages={423--439},
  year={2022},
  organization={Springer}
}

@article{wang2024inference,
  title={Inference-Time Policy Steering through Human Interactions},
  author={Wang, Yanwei and Wang, Lirui and Du, Yilun and Sundaralingam, Balakumar and Yang, Xuning and Chao, Yu-Wei and Perez-D'Arpino, Claudia and Fox, Dieter and Shah, Julie},
  journal={arXiv preprint arXiv:2411.16627},
  year={2024}
}

@article{chen2024yilun,
  title={Diffusion forcing: Next-token prediction meets full-sequence diffusion},
  author={Yilun Du and Max Simchowitz and Russ Tedrake and Vincent Sitzmann and Chen, Boyuan and Monso, Diego Marti},
  journal={NeurIPS},
  volume={3},
  year={2024}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@article{dppo,
  title={Diffusion policy policy optimization},
  author={Ren, Allen Z and Lidard, Justin and Ankile, Lars L and Simeonov, Anthony and Agrawal, Pulkit and Majumdar, Anirudha and Burchfiel, Benjamin and Dai, Hongkai and Simchowitz, Max},
  journal={arXiv preprint arXiv:2409.00588},
  year={2024}
}


@article{brohan2023rt-2,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}


@article{openvla,
  title={OpenVLA: An Open-Source Vision-Language-Action Model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  booktitle={8th Annual Conference on Robot Learning}
}

@inproceedings{octo,
    title={Octo: An Open-Source Generalist Robot Policy},
    author = {{Octo Model Team} and Dibya Ghosh and Homer Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Charles Xu and Jianlan Luo and Tobias Kreiman and {You Liang} Tan and Lawrence Yunliang Chen and Pannag Sanketi and Quan Vuong and Ted Xiao and Dorsa Sadigh and Chelsea Finn and Sergey Levine},
    booktitle = {Proceedings of Robotics: Science and Systems},
    address  = {Delft, Netherlands},
    year = {2024},
}

@article{mobile_aloha,
  title={Mobile aloha: Learning bimanual mobile manipulation with low-cost whole-body teleoperation},
  author={Fu, Zipeng and Zhao, Tony Z and Finn, Chelsea},
  journal={arXiv preprint arXiv:2401.02117},
  year={2024}
}

@article{aloha2,
  title={ALOHA 2: An Enhanced Low-Cost Hardware for Bimanual Teleoperation},
  author={Aldaco, Jorge and Armstrong, Travis and Baruch, Robert and Bingham, Jeff and Chan, Sanky and Draper, Kenneth and Dwibedi, Debidatta and Finn, Chelsea and Florence, Pete and Goodrich, Spencer and others},
  journal={arXiv preprint arXiv:2405.02292},
  year={2024}
}

@inproceedings{aloha_unleashed,
  title={ALOHA Unleashed: A Simple Recipe for Robot Dexterity},
  author={Zhao, Tony Z and Tompson, Jonathan and Driess, Danny and Florence, Pete and Ghasemipour, Seyed Kamyar Seyed and Finn, Chelsea and Wahid, Ayzaan},
  booktitle={8th Annual Conference on Robot Learning}
}

@article{yang2024movie,
  title={Movie: Visual model-based policy adaptation for view generalization},
  author={Yang, Sizhe and Ze, Yanjie and Xu, Huazhe},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}




@article{zhu2024mipha,
  title={Mipha: A Comprehensive Overhaul of Multimodal Assistant with Small Language Models},
  author={Zhu, Minjie and Zhu, Yichen and Liu, Xin and Liu, Ning and Xu, Zhiyuan and Shen, Chaomin and Peng, Yaxin and Ou, Zhicai and Feng, Feifei and Tang, Jian},
  journal={arXiv preprint arXiv:2403.06199},
  year={2024}
}


@article{embodiedcot,
    title={Robotic Control via Embodied Chain-of-Thought Reasoning},
    author={Michał Zawalski and William Chen and Karl Pertsch and Oier Mees and Chelsea Finn and Sergey Levine},
    journal={arXiv preprint arXiv:2407.08693},
    year={2024}
} 



@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}


@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@inproceedings{zhu2024llavaphi,
  title={Llava-phi: Efficient multi-modal assistant with small language model},
  author={Zhu, Yichen and Zhu, Minjie and Liu, Ning and Xu, Zhiyuan and Peng, Yaxin},
  booktitle={Proceedings of the 1st International Workshop on Efficient Multimedia Computing under Limited},
  pages={18--22},
  year={2024}
}

@inproceedings{ze2023gnfactor,
  title={Gnfactor: Multi-task real robot learning with generalizable neural feature fields},
  author={Ze, Yanjie and Yan, Ge and Wu, Yueh-Hua and Macaluso, Annabella and Ge, Yuying and Ye, Jianglong and Hansen, Nicklas and Li, Li Erran and Wang, Xiaolong},
  booktitle={Conference on Robot Learning},
  pages={284--301},
  year={2023},
  organization={PMLR}
}

@article{ze2023visual,
  title={Visual reinforcement learning with self-supervised 3d representations},
  author={Ze, Yanjie and Hansen, Nicklas and Chen, Yinbo and Jain, Mohit and Wang, Xiaolong},
  journal={IEEE Robotics and Automation Letters},
  volume={8},
  number={5},
  pages={2890--2897},
  year={2023},
  publisher={IEEE}
}

@article{h_index,
  title={H-InDex: Visual reinforcement learning with hand-informed representations for dexterous manipulation},
  author={Ze, Yanjie and Liu, Yuyao and Shi, Ruizhe and Qin, Jiaxin and Yuan, Zhecheng and Wang, Jiashun and Xu, Huazhe},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{yell_at_your_robot,
  title={Yell at your robot: Improving on-the-fly from language corrections},
  author={Shi, Lucy Xiaoyang and Hu, Zheyuan and Zhao, Tony Z and Sharma, Archit and Pertsch, Karl and Luo, Jianlan and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2403.12910},
  year={2024}
}


@inproceedings{roboagent,
  author={Bharadhwaj, Homanga and Vakil, Jay and Sharma, Mohit and Gupta, Abhinav and Tulsiani, Shubham and Kumar, Vikash},
  title={RoboAgent: Generalization and Efficiency in Robot Manipulation via Semantic Augmentations and Action Chunking}, 
  year={2024},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  pages={4788-4795},
  organization={IEEE}
}


@article{ddpms,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{liu2024libero,
  title={Libero: Benchmarking knowledge transfer for lifelong robot learning},
  author={Liu, Bo and Zhu, Yifeng and Gao, Chongkai and Feng, Yihao and Liu, Qiang and Zhu, Yuke and Stone, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{niu2024llarva,
  title={LLARVA: Vision-Action Instruction Tuning Enhances Robot Learning},
  author={Niu, Dantong and Sharma, Yuvan and Biamby, Giscard and Quenum, Jerome and Bai, Yutong and Shi, Baifeng and Darrell, Trevor and Herzig, Roei},
  journal={arXiv preprint arXiv:2406.11815},
  year={2024}
}


@article{zhu2024scalingdp,
  title={Scaling diffusion policy in transformer to 1 billion parameters for robotic manipulation},
  author={Zhu, Minjie and Zhu, Yichen and Li, Jinming and Wen, Junjie and Xu, Zhiyuan and Liu, Ning and Cheng, Ran and Shen, Chaomin and Peng, Yaxin and Feng, Feifei and others},
  journal={arXiv preprint arXiv:2409.14411},
  year={2024}
}


@inproceedings{ibc,
  title={Implicit behavioral cloning},
  author={Florence, Pete and Lynch, Corey and Zeng, Andy and Ramirez, Oscar A and Wahid, Ayzaan and Downs, Laura and Wong, Adrian and Lee, Johnny and Mordatch, Igor and Tompson, Jonathan},
  booktitle={Conference on Robot Learning},
  pages={158--168},
  year={2022},
  organization={PMLR}
}

@inproceedings{leo3d,
  title={An Embodied Generalist Agent in 3D World},
  author={Huang, Jiangyong and Yong, Silong and Ma, Xiaojian and Linghu, Xiongkun and Li, Puhao and Wang, Yan and Li, Qing and Zhu, Song-Chun and Jia, Baoxiong and Huang, Siyuan},
  booktitle={ICLR 2024 Workshop: How Far Are We From AGI}
}

@article{roboflamingo,
  title={Vision-language foundation models as effective robot imitators},
  author={Li, Xinghang and Liu, Minghuan and Zhang, Hanbo and Yu, Cunjun and Xu, Jie and Wu, Hongtao and Cheang, Chilam and Jing, Ya and Zhang, Weinan and Liu, Huaping and others},
  journal={arXiv preprint arXiv:2311.01378},
  year={2023}
}

@article{3d_diffuser_actor,
  title={3d diffuser actor: Policy diffusion with 3d scene representations},
  author={Ke, Tsung-Wei and Gkanatsios, Nikolaos and Fragkiadaki, Katerina},
  journal={arXiv preprint arXiv:2402.10885},
  year={2024}
}

@article{cheang2024gr,
  title={GR-2: A Generative Video-Language-Action Model with Web-Scale Knowledge for Robot Manipulation},
  author={Cheang, Chi-Lam and Chen, Guangzeng and Jing, Ya and Kong, Tao and Li, Hang and Li, Yifeng and Liu, Yuxiao and Wu, Hongtao and Xu, Jiafeng and Yang, Yichu and others},
  journal={arXiv preprint arXiv:2410.06158},
  year={2024}
}

@inproceedings{mail-dp,
  title={MaIL: Improving Imitation Learning with Selective State Space Models},
  author={Jia, Xiaogang and Wang, Qian and Donat, Atalay and Xing, Bowen and Li, Ge and Zhou, Hongyi and Celik, Onur and Blessing, Denis and Lioutikov, Rudolf and Neumann, Gerhard},
  booktitle={8th Annual Conference on Robot Learning}
}

@article{wang2024sparse-dp,
  title={Sparse diffusion policy: A sparse, reusable, and flexible policy for robot learning},
  author={Wang, Yixiao and Zhang, Yifei and Huo, Mingxiao and Tian, Ran and Zhang, Xiang and Xie, Yichen and Xu, Chenfeng and Ji, Pengliang and Zhan, Wei and Ding, Mingyu and others},
  journal={arXiv preprint arXiv:2407.01531},
  year={2024}
}

@article{One-Step-Diffusion-Policy,
  title={One-Step Diffusion Policy: Fast Visuomotor Policies via Diffusion Distillation},
  author={Wang, Zhendong and Li, Zhaoshuo and Mandlekar, Ajay and Xu, Zhenjia and Fan, Jiaojiao and Narang, Yashraj and Fan, Linxi and Zhu, Yuke and Balaji, Yogesh and Zhou, Mingyuan and others},
  journal={arXiv preprint arXiv:2410.21257},
  year={2024}
}

@article{prasad2024consistencypolicy,
  title={Consistency policy: Accelerated visuomotor policies via consistency distillation},
  author={Prasad, Aaditya and Lin, Kevin and Wu, Jimmy and Zhou, Linqi and Bohg, Jeannette},
  journal={arXiv preprint arXiv:2405.07503},
  year={2024}
}

@article{manipulateanywhere, title={Learning to Manipulate Anywhere: A Visual Generalizable Framework For Reinforcement Learning}, author={Yuan, Zhecheng and Wei, Tianming and Cheng, Shuiqi and Zhang, Gu and Chen, Yuanpei and Xu, Huazhe}, journal={arXiv preprint arXiv:2407.15815}, year={2024}}



@article{rt-h,
  title={Rt-h: Action hierarchies using language},
  author={Belkhale, Suneel and Ding, Tianli and Xiao, Ted and Sermanet, Pierre and Vuong, Quon and Tompson, Jonathan and Chebotar, Yevgen and Dwibedi, Debidatta and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2403.01823},
  year={2024}
}

@inproceedings{bcz,
  title={Bc-z: Zero-shot task generalization with robotic imitation learning},
  author={Jang, Eric and Irpan, Alex and Khansari, Mohi and Kappler, Daniel and Ebert, Frederik and Lynch, Corey and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={991--1002},
  year={2022},
  organization={PMLR}
}

@article{jiang2022vima,
  title={Vima: General robot manipulation with multimodal prompts},
  author={Jiang, Yunfan and Gupta, Agrim and Zhang, Zichen and Wang, Guanzhi and Dou, Yongqiang and Chen, Yanjun and Fei-Fei, Li and Anandkumar, Anima and Zhu, Yuke and Fan, Linxi},
  journal={arXiv preprint arXiv:2210.03094},
  volume={2},
  number={3},
  pages={6},
  year={2022}
}

@article{srirama2024hrp,
  title={Hrp: Human affordances for robotic pre-training},
  author={Srirama, Mohan Kumar and Dasari, Sudeep and Bahl, Shikhar and Gupta, Abhinav},
  journal={arXiv preprint arXiv:2407.18911},
  year={2024}
}

@inproceedings{Contact-graspnet,
  title={Contact-graspnet: Efficient 6-dof grasp generation in cluttered scenes},
  author={Sundermeyer, Martin and Mousavian, Arsalan and Triebel, Rudolph and Fox, Dieter},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={13438--13444},
  year={2021},
  organization={IEEE}
}

@inproceedings{tang2023task,
  title={Task-oriented grasp prediction with visual-language inputs},
  author={Tang, Chao and Huang, Dehao and Meng, Lingxiao and Liu, Weiyu and Zhang, Hong},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4881--4888},
  year={2023},
  organization={IEEE}
}

@article{sundaresan2023kite,
  title={Kite: Keypoint-conditioned policies for semantic manipulation},
  author={Sundaresan, Priya and Belkhale, Suneel and Sadigh, Dorsa and Bohg, Jeannette},
  journal={arXiv preprint arXiv:2306.16605},
  year={2023}
}

@article{Any-point-trajectory,
  title={Any-point trajectory modeling for policy learning},
  author={Wen, Chuan and Lin, Xingyu and So, John and Chen, Kai and Dou, Qi and Gao, Yang and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2401.00025},
  year={2023}
}


@inproceedings{ze20243d,
  title={3d diffusion policy: Generalizable visuomotor policy learning via simple 3d representations},
  author={Ze, Yanjie and Zhang, Gu and Zhang, Kangning and Hu, Chenyuan and Wang, Muhan and Xu, Huazhe},
  booktitle={ICRA 2024 Workshop on 3D Visual Representations for Robot Manipulation},
  year={2024}
}

@article{ze2024generalizable,
  title={Generalizable humanoid manipulation with improved 3d diffusion policies},
  author={Ze, Yanjie and Chen, Zixuan and Wang, Wenhao and Chen, Tianyi and He, Xialin and Yuan, Ying and Peng, Xue Bin and Wu, Jiajun},
  journal={arXiv preprint arXiv:2410.10803},
  year={2024}
}

@article{yan2024dnact,
  title={Dnact: Diffusion guided multi-task 3d policy learning},
  author={Yan, Ge and Wu, Yueh-Hua and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2403.04115},
  year={2024}
}

@article{wang2024equivariant,
  title={Equivariant diffusion policy},
  author={Wang, Dian and Hart, Stephen and Surovik, David and Kelestemur, Tarik and Huang, Haojie and Zhao, Haibo and Yeatman, Mark and Wang, Jiuguang and Walters, Robin and Platt, Robert},
  journal={arXiv preprint arXiv:2407.01812},
  year={2024}
}


@article{diffusionvla,
  title={DiffusionVLA: Scaling Robot Foundation Models via Unified Diffusion and Autoregression},
  author={Wen, Junjie and Zhu, Minjie and Zhu, Yichen and Tang, Zhibin, and Li, Jinming and Li, Chengmeng, and Zhou, Zhongyi and Liu, Xiaoyu and Shen, Chaomin, and Peng, Yaxin and Feng, Feifei},
  year={2024}
}

@article{huang2023voxposer,
  title={Voxposer: Composable 3d value maps for robotic manipulation with language models},
  author={Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2307.05973},
  year={2023}
}

@article{huang2024copa,
  title={Copa: General robotic manipulation through spatial constraints of parts with foundation models},
  author={Huang, Haoxu and Lin, Fanqi and Hu, Yingdong and Wang, Shengjie and Gao, Yang},
  journal={arXiv preprint arXiv:2403.08248},
  year={2024}
}

@article{duan2024manipulate,
  title={Manipulate-anything: Automating real-world robots using vision-language models},
  author={Duan, Jiafei and Yuan, Wentao and Pumacay, Wilbert and Wang, Yi Ru and Ehsani, Kiana and Fox, Dieter and Krishna, Ranjay},
  journal={arXiv preprint arXiv:2406.18915},
  year={2024}
}

@inproceedings{li2024manipllm,
  title={Manipllm: Embodied multimodal large language model for object-centric robotic manipulation},
  author={Li, Xiaoqi and Zhang, Mingxu and Geng, Yiran and Geng, Haoran and Long, Yuxing and Shen, Yan and Zhang, Renrui and Liu, Jiaming and Dong, Hao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18061--18070},
  year={2024}
}

@article{huang2024rekep,
  title={Rekep: Spatio-temporal reasoning of relational keypoint constraints for robotic manipulation},
  author={Huang, Wenlong and Wang, Chen and Li, Yunzhu and Zhang, Ruohan and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2409.01652},
  year={2024}
}

@article{huang2024a3vlm,
  title={A3VLM: Actionable Articulation-Aware Vision Language Model},
  author={Huang, Siyuan and Chang, Haonan and Liu, Yuhan and Zhu, Yimeng and Dong, Hao and Gao, Peng and Boularias, Abdeslam and Li, Hongsheng},
  journal={arXiv preprint arXiv:2406.07549},
  year={2024}
}

@inproceedings{katara2024gen2sim,
  title={Gen2sim: Scaling up robot learning in simulation with generative models},
  author={Katara, Pushkal and Xian, Zhou and Fragkiadaki, Katerina},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6672--6679},
  year={2024},
  organization={IEEE}
}


@article{black2023zero,
  title={Zero-shot robotic manipulation with pretrained image-editing diffusion models},
  author={Black, Kevin and Nakamoto, Mitsuhiko and Atreya, Pranav and Walke, Homer and Finn, Chelsea and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2310.10639},
  year={2023}
}

@article{black2023training,
  title={Training diffusion models with reinforcement learning},
  author={Black, Kevin and Janner, Michael and Du, Yilun and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2305.13301},
  year={2023}
}

@article{uehara2024feedback,
  title={Feedback efficient online fine-tuning of diffusion models},
  author={Uehara, Masatoshi and Zhao, Yulai and Black, Kevin and Hajiramezanali, Ehsan and Scalia, Gabriele and Diamant, Nathaniel Lee and Tseng, Alex M and Levine, Sergey and Biancalani, Tommaso},
  journal={arXiv preprint arXiv:2402.16359},
  year={2024}
}

@article{uehara2024fine,
  title={Fine-tuning of continuous-time diffusion models as entropy-regularized control},
  author={Uehara, Masatoshi and Zhao, Yulai and Black, Kevin and Hajiramezanali, Ehsan and Scalia, Gabriele and Diamant, Nathaniel Lee and Tseng, Alex M and Biancalani, Tommaso and Levine, Sergey},
  journal={arXiv preprint arXiv:2402.15194},
  year={2024}
}

@article{dasari2024ingredients,
  title={The Ingredients for Robotic Diffusion Transformers},
  author={Dasari, Sudeep and Mees, Oier and Zhao, Sebastian and Srirama, Mohan Kumar and Levine, Sergey},
  journal={arXiv preprint arXiv:2410.10088},
  year={2024}
}



@inproceedings{vllm,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

# newly added
@article{bu2024towards,
  title={Towards Synergistic, Generalized, and Efficient Dual-System for Robotic Manipulation},
  author={Bu, Qingwen and Li, Hongyang and Chen, Li and Cai, Jisong and Zeng, Jia and Cui, Heming and Yao, Maoqing and Qiao, Yu},
  journal={arXiv preprint arXiv:2410.08001},
  year={2024}
}

@article{liu2024rdt,
  title={Rdt-1b: a diffusion foundation model for bimanual manipulation},
  author={Liu, Songming and Wu, Lingxuan and Li, Bangguo and Tan, Hengkai and Chen, Huayu and Wang, Zhengyi and Xu, Ke and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2410.07864},
  year={2024}
}

@article{li2024towards,
  title={Towards Generalist Robot Policies: What Matters in Building Vision-Language-Action Models},
  author={Li, Xinghang and Li, Peiyan and Liu, Minghuan and Wang, Dong and Liu, Jirong and Kang, Bingyi and Ma, Xiao and Kong, Tao and Zhang, Hanbo and Liu, Huaping},
  journal={arXiv preprint arXiv:2412.14058},
  year={2024}
}

@article{li2024cogact,
  title={CogACT: A Foundational Vision-Language-Action Model for Synergizing Cognition and Action in Robotic Manipulation},
  author={Li, Qixiu and Liang, Yaobo and Wang, Zeyu and Luo, Lin and Chen, Xi and Liao, Mozheng and Wei, Fangyun and Deng, Yu and Xu, Sicheng and Zhang, Yizhong and others},
  journal={arXiv preprint arXiv:2411.19650},
  year={2024}
}

@article{zheng2025universal,
  title={Universal Actions for Enhanced Embodied Foundation Models},
  author={Zheng, Jinliang and Li, Jianxiong and Liu, Dongxiu and Zheng, Yinan and Wang, Zhihao and Ou, Zhonghong and Liu, Yu and Liu, Jingjing and Zhang, Ya-Qin and Zhan, Xianyuan},
  journal={arXiv preprint arXiv:2501.10105},
  year={2025}
}

@article{wu2024discrete,
  title={Discrete policy: Learning disentangled action space for multi-task robotic manipulation},
  author={Wu, Kun and Zhu, Yichen and Li, Jinming and Wen, Junjie and Liu, Ning and Xu, Zhiyuan and Qiu, Qinru and Tang, Jian},
  journal={arXiv preprint arXiv:2409.18707},
  year={2024}
}

@article{fang2023rh20t,
  title={Rh20t: A comprehensive robotic dataset for learning diverse skills in one-shot},
  author={Fang, Hao-Shu and Fang, Hongjie and Tang, Zhenyu and Liu, Jirong and Wang, Chenxi and Wang, Junbo and Zhu, Haoyi and Lu, Cewu},
  journal={arXiv preprint arXiv:2307.00595},
  year={2023}
}

@article{dasari2024ditpolicy,
title={The Ingredients for Robotic Diffusion Transformers},
author = {Sudeep Dasari and Oier Mees and Sebastian Zhao and Mohan Kumar Srirama and Sergey Levine},
journal = {arXiv preprint arXiv:2410.10088},
year={2024},
}


@article{zhao2024cobra,
  title={Cobra: Extending mamba to multi-modal large language model for efficient inference},
  author={Zhao, Han and Zhang, Min and Zhao, Wei and Ding, Pengxiang and Huang, Siteng and Wang, Donglin},
  journal={arXiv preprint arXiv:2403.14520},
  year={2024}
}

@article{wang2024scaling,
  title={Scaling proprioceptive-visual learning with heterogeneous pre-trained transformers},
  author={Wang, Lirui and Chen, Xinlei and Zhao, Jialiang and He, Kaiming},
  journal={arXiv preprint arXiv:2409.20537},
  year={2024}
}

@article{wang2024poco,
  title={Poco: Policy composition from and for heterogeneous robot learning},
  author={Wang, Lirui and Zhao, Jialiang and Du, Yilun and Adelson, Edward H and Tedrake, Russ},
  journal={arXiv preprint arXiv:2402.02511},
  year={2024}
}

@article{wang2023fleet,
  title={Fleet Policy Learning via Weight Merging and An Application to Robotic Tool-Use},
  author={Wang, Lirui and Zhang, Kaiqing and Zhou, Allan and Simchowitz, Max and Tedrake, Russ},
  journal={arXiv preprint arXiv:2310.01362},
  year={2023}
}

###################################################################### new added ####################################################################
@article{he2024hover,
  title={Hover: Versatile neural whole-body controller for humanoid robots},
  author={He, Tairan and Xiao, Wenli and Lin, Toru and Luo, Zhengyi and Xu, Zhenjia and Jiang, Zhenyu and Kautz, Jan and Liu, Changliu and Shi, Guanya and Wang, Xiaolong and others},
  journal={arXiv preprint arXiv:2410.21229},
  year={2024}
}

@article{lin2024learning,
  title={Learning Visuotactile Skills with Two Multifingered Hands},
  author={Lin, Toru and Zhang, Yu and Li, Qiyang and Qi, Haozhi and Yi, Brent and Levine, Sergey and Malik, Jitendra},
  journal={arXiv preprint arXiv:2404.16823},
  year={2024}
}

@article{shi2023robocook,
  title={Robocook: Long-horizon elasto-plastic object manipulation with diverse tools},
  author={Shi, Haochen and Xu, Huazhe and Clarke, Samuel and Li, Yunzhu and Wu, Jiajun},
  journal={arXiv preprint arXiv:2306.14447},
  year={2023}
}

@article{wang2024dexcap,
  title={Dexcap: Scalable and portable mocap data collection system for dexterous manipulation},
  author={Wang, Chen and Shi, Haochen and Wang, Weizhuo and Zhang, Ruohan and Fei-Fei, Li and Liu, C Karen},
  journal={arXiv preprint arXiv:2403.07788},
  year={2024}
}

@article{shi2024robocraft,
  title={RoboCraft: Learning to see, simulate, and shape elasto-plastic objects in 3D with graph networks},
  author={Shi, Haochen and Xu, Huazhe and Huang, Zhiao and Li, Yunzhu and Wu, Jiajun},
  journal={The International Journal of Robotics Research},
  volume={43},
  number={4},
  pages={533--549},
  year={2024},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{ai2024robopack,
  title={RoboPack: Learning Tactile-Informed Dynamics Models for Dense Packing},
  author={Ai, Bo and Tian, Stephen and Shi, Haochen and Wang, Yixuan and Tan, Cheston and Li, Yunzhu and Wu, Jiajun},
  booktitle={ICRA 2024 Workshop on 3D Visual Representations for Robot Manipulation}
}

@inproceedings{gao2016deep,
  title={Deep learning for tactile understanding from visual and haptic data},
  author={Gao, Yang and Hendricks, Lisa Anne and Kuchenbecker, Katherine J and Darrell, Trevor},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={536--543},
  year={2016},
  organization={IEEE}
}

@article{lin2024data,
  title={Data scaling laws in imitation learning for robotic manipulation},
  author={Lin, Fanqi and Hu, Yingdong and Sheng, Pingyue and Wen, Chuan and You, Jiacheng and Gao, Yang},
  journal={arXiv preprint arXiv:2410.18647},
  year={2024}
}

@article{zhang2024learning,
  title={Learning Manipulation Skills through Robot Chain-of-Thought with Sparse Failure Guidance},
  author={Zhang, Kaifeng and Yin, Zhao-Heng and Ye, Weirui and Gao, Yang},
  journal={arXiv preprint arXiv:2405.13573},
  year={2024}
}

@article{hu2023look,
  title={Look before you leap: Unveiling the power of gpt-4v in robotic vision-language planning},
  author={Hu, Yingdong and Lin, Fanqi and Zhang, Tong and Yi, Li and Gao, Yang},
  journal={arXiv preprint arXiv:2311.17842},
  year={2023}
}

@inproceedings{fu2023demonstrating,
  title={Demonstrating RFUniverse: A Multiphysics Simulation Platform for Embodied AI.},
  author={Fu, Haoyuan and Xu, Wenqiang and Ye, Ruolin and Xue, Han and Yu, Zhenjun and Tang, Tutian and Li, Yutong and Du, Wenxin and Zhang, Jieyi and Lu, Cewu},
  booktitle={Robotics: Science and Systems},
  year={2023}
}

@inproceedings{fang2020graspnet,
  title={Graspnet-1billion: A large-scale benchmark for general object grasping},
  author={Fang, Hao-Shu and Wang, Chenxi and Gou, Minghao and Lu, Cewu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11444--11453},
  year={2020}
}

@article{ha2024umi,
  title={Umi on legs: Making manipulation policies mobile with manipulation-centric whole-body controllers},
  author={Ha, Huy and Gao, Yihuai and Fu, Zipeng and Tan, Jie and Song, Shuran},
  journal={arXiv preprint arXiv:2407.10353},
  year={2024}
}

@inproceedings{ha2023scaling,
  title={Scaling up and distilling down: Language-guided robot skill acquisition},
  author={Ha, Huy and Florence, Pete and Song, Shuran},
  booktitle={Conference on Robot Learning},
  pages={3766--3777},
  year={2023},
  organization={PMLR}
}

@article{zeng2022robotic,
  title={Robotic pick-and-place of novel objects in clutter with multi-affordance grasping and cross-domain image matching},
  author={Zeng, Andy and Song, Shuran and Yu, Kuan-Ting and Donlon, Elliott and Hogan, Francois R and Bauza, Maria and Ma, Daolin and Taylor, Orion and Liu, Melody and Romo, Eudald and others},
  journal={The International Journal of Robotics Research},
  volume={41},
  number={7},
  pages={690--705},
  year={2022},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{prasad2024consistency,
  title={Consistency policy: Accelerated visuomotor policies via consistency distillation},
  author={Prasad, Aaditya and Lin, Kevin and Wu, Jimmy and Zhou, Linqi and Bohg, Jeannette},
  journal={arXiv preprint arXiv:2405.07503},
  year={2024}
}

@article{fu2024humanplus,
  title={HumanPlus: Humanoid Shadowing and Imitation from Humans},
  author={Fu, Zipeng and Zhao, Qingqing and Wu, Qi and Wetzstein, Gordon and Finn, Chelsea},
  journal={arXiv preprint arXiv:2406.10454},
  year={2024}
}

@inproceedings{radosavovic2023real,
  title={Real-world robot learning with masked visual pre-training},
  author={Radosavovic, Ilija and Xiao, Tete and James, Stephen and Abbeel, Pieter and Malik, Jitendra and Darrell, Trevor},
  booktitle={Conference on Robot Learning},
  pages={416--426},
  year={2023},
  organization={PMLR}
}

@article{wu2023tidybot,
  title={Tidybot: Personalized robot assistance with large language models},
  author={Wu, Jimmy and Antonova, Rika and Kan, Adam and Lepert, Marion and Zeng, Andy and Song, Shuran and Bohg, Jeannette and Rusinkiewicz, Szymon and Funkhouser, Thomas},
  journal={Autonomous Robots},
  volume={47},
  number={8},
  pages={1087--1102},
  year={2023},
  publisher={Springer}
}

@inproceedings{qin2022dexmv,
  title={Dexmv: Imitation learning for dexterous manipulation from human videos},
  author={Qin, Yuzhe and Wu, Yueh-Hua and Liu, Shaowei and Jiang, Hanwen and Yang, Ruihan and Fu, Yang and Wang, Xiaolong},
  booktitle={European Conference on Computer Vision},
  pages={570--587},
  year={2022},
  organization={Springer}
}

@article{zeng2020tossingbot,
  title={Tossingbot: Learning to throw arbitrary objects with residual physics},
  author={Zeng, Andy and Song, Shuran and Lee, Johnny and Rodriguez, Alberto and Funkhouser, Thomas},
  journal={IEEE Transactions on Robotics},
  volume={36},
  number={4},
  pages={1307--1319},
  year={2020},
  publisher={IEEE}
}

@article{xu2019densephysnet,
  title={Densephysnet: Learning dense physical object representations via multi-step dynamic interactions},
  author={Xu, Zhenjia and Wu, Jiajun and Zeng, Andy and Tenenbaum, Joshua B and Song, Shuran},
  journal={arXiv preprint arXiv:1906.03853},
  year={2019}
}

@inproceedings{xiang2020sapien,
  title={Sapien: A simulated part-based interactive environment},
  author={Xiang, Fanbo and Qin, Yuzhe and Mo, Kaichun and Xia, Yikuan and Zhu, Hao and Liu, Fangchen and Liu, Minghua and Jiang, Hanxiao and Yuan, Yifu and Wang, He and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11097--11107},
  year={2020}
}

@inproceedings{yen2020learning,
  title={Learning to see before learning to act: Visual pre-training for manipulation},
  author={Yen-Chen, Lin and Zeng, Andy and Song, Shuran and Isola, Phillip and Lin, Tsung-Yi},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7286--7293},
  year={2020},
  organization={IEEE}
}

@article{chi2024universal,
  title={Universal manipulation interface: In-the-wild robot teaching without in-the-wild robots},
  author={Chi, Cheng and Xu, Zhenjia and Pan, Chuer and Cousineau, Eric and Burchfiel, Benjamin and Feng, Siyuan and Tedrake, Russ and Song, Shuran},
  journal={arXiv preprint arXiv:2402.10329},
  year={2024}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

@inproceedings{zeng2019end,
  title={End-to-end interpretable neural motion planner},
  author={Zeng, Wenyuan and Luo, Wenjie and Suo, Simon and Sadat, Abbas and Yang, Bin and Casas, Sergio and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8660--8669},
  year={2019}
}

@inproceedings{yang2018pixor,
  title={Pixor: Real-time 3d object detection from point clouds},
  author={Yang, Bin and Luo, Wenjie and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={7652--7660},
  year={2018}
}

@article{geiger2013vision,
  title={Vision meets robotics: The kitti dataset},
  author={Geiger, Andreas and Lenz, Philip and Stiller, Christoph and Urtasun, Raquel},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1231--1237},
  year={2013},
  publisher={Sage Publications Sage UK: London, England}
}


@ARTICLE{franka,
  author={Haddadin, Sami},
  journal={IEEE Robotics & Automation Magazine}, 
  title={The Franka Emika Robot: A Standard Platform in Robotics Research [Survey]}, 
  year={2024},
  volume={31},
  number={4},
  pages={136-148},
  keywords={Service robots;Assembly;Robot sensing systems;Collaborative robots;Automation;Research and development;Industrial robots;Machine learning;Soft robotics;Performance evaluation;Force control;Robot control;Benchmark testing;Torque control;Statistical analysis;Ecosystems},
  doi={10.1109/MRA.2024.3451788}}


@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: Smaller, faster, cheaper and lighter. arXiv 2019},
  author={Sanh, Victor and Debut, L and Chaumond, J and Wolf, T},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}



@article{coa-vla,
  title={Improving Vision-Language-Action Models via Chain-of-Affordance},
  author={Li, Jinming and Zhu, Yichen and Tang, Zhibin and Wen, Junjie and Zhu, Minjie and Liu, Xiaoyu and Li, Chengmeng and Cheng, Ran and Peng, Yaxin and Feng, Feifei},
  journal={arXiv preprint arXiv:2412.20451},
  year={2024}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{zhang2024grape,
  title={Grape: Generalizing robot policy via preference alignment},
  author={Zhang, Zijian and Zheng, Kaiyuan and Chen, Zhaorun and Jang, Joel and Li, Yi and Wang, Chaoqi and Ding, Mingyu and Fox, Dieter and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2411.19309},
  year={2024}
}

@article{guo2025improving,
  title={Improving Vision-Language-Action Model with Online Reinforcement Learning},
  author={Guo, Yanjiang and Zhang, Jianke and Chen, Xiaoyu and Ji, Xiang and Wang, Yen-Jen and Hu, Yucheng and Chen, Jianyu},
  journal={arXiv preprint arXiv:2501.16664},
  year={2025}
}

 



@article{wen2024diffusionvla,
  title={Diffusion-VLA: Scaling Robot Foundation Models via Unified Diffusion and Autoregression},
  author={Wen, Junjie and Zhu, Minjie and Zhu, Yichen and Tang, Zhibin and Li, Jinming and Zhou, Zhongyi and Li, Chengmeng and Liu, Xiaoyu and Peng, Yaxin and Shen, Chaomin and others},
  journal={arXiv preprint arXiv:2412.03293},
  year={2024}
}


@article{zhen20243d,
  title={3d-vla: A 3d vision-language-action generative world model},
  author={Zhen, Haoyu and Qiu, Xiaowen and Chen, Peihao and Yang, Jincheng and Yan, Xin and Du, Yilun and Hong, Yining and Gan, Chuang},
  journal={arXiv preprint arXiv:2403.09631},
  year={2024}
}

@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}



@article{khazatsky2024droid,
  title={Droid: A large-scale in-the-wild robot manipulation dataset},
  author={Khazatsky, Alexander and Pertsch, Karl and Nair, Suraj and Balakrishna, Ashwin and Dasari, Sudeep and Karamcheti, Siddharth and Nasiriany, Soroush and Srirama, Mohan Kumar and Chen, Lawrence Yunliang and Ellis, Kirsty and others},
  journal={arXiv preprint arXiv:2403.12945},
  year={2024}
}


@article{gu2023rt-trajectory,
  title={Rt-trajectory: Robotic task generalization via hindsight trajectory sketches},
  author={Gu, Jiayuan and Kirmani, Sean and Wohlhart, Paul and Lu, Yao and Arenas, Montserrat Gonzalez and Rao, Kanishka and Yu, Wenhao and Fu, Chuyuan and Gopalakrishnan, Keerthana and Xu, Zhuo and others},
  journal={arXiv preprint arXiv:2311.01977},
  year={2023}
}


@misc{rt-affordance,
      title={RT-Affordance: Affordances are Versatile Intermediate Representations for Robot Manipulation}, 
      author={Soroush Nasiriany and Sean Kirmani and Tianli Ding and Laura Smith and Yuke Zhu and Danny Driess and Dorsa Sadigh and Ted Xiao},
      year={2024},
      eprint={2411.02704},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2411.02704}, 
}

@article{chang2023goat,
  title={Goat: Go to any thing},
  author={Chang, Matthew and Gervet, Theophile and Khanna, Mukul and Yenamandra, Sriram and Shah, Dhruv and Min, So Yeon and Shah, Kavit and Paxton, Chris and Gupta, Saurabh and Batra, Dhruv and others},
  journal={arXiv preprint arXiv:2311.06430},
  year={2023}
}


@article{belkhale2024rt-h,
  title={Rt-h: Action hierarchies using language},
  author={Belkhale, Suneel and Ding, Tianli and Xiao, Ted and Sermanet, Pierre and Vuong, Quon and Tompson, Jonathan and Chebotar, Yevgen and Dwibedi, Debidatta and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2403.01823},
  year={2024}
}


@inproceedings{yu2020metaworld,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on robot learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@article{multimodal_diffusion_transformer,
    title={Multimodal Diffusion Transformer: Learning Versatile Behavior from Multimodal Goals},
    author={Moritz Reuss and {\"O}mer Erdin{\c{c}} Ya{\u{g}}murlu and Fabian Wenzel and Rudolf Lioutikov},
    journal={Robotics: Science and Systems},
    year={2024}
    }

@inproceedings{liu2022compositional,
  title={Compositional visual generation with composable diffusion models},
  author={Liu, Nan and Li, Shuang and Du, Yilun and Torralba, Antonio and Tenenbaum, Joshua B},
  booktitle={European Conference on Computer Vision},
  pages={423--439},
  year={2022},
  organization={Springer}
}

@article{wang2024inference,
  title={Inference-Time Policy Steering through Human Interactions},
  author={Wang, Yanwei and Wang, Lirui and Du, Yilun and Sundaralingam, Balakumar and Yang, Xuning and Chao, Yu-Wei and Perez-D'Arpino, Claudia and Fox, Dieter and Shah, Julie},
  journal={arXiv preprint arXiv:2411.16627},
  year={2024}
}

@article{chen2024yilun,
  title={Diffusion forcing: Next-token prediction meets full-sequence diffusion},
  author={Yilun Du and Max Simchowitz and Russ Tedrake and Vincent Sitzmann and Chen, Boyuan and Monso, Diego Marti},
  journal={NeurIPS},
  volume={3},
  year={2024}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@article{dppo,
  title={Diffusion policy policy optimization},
  author={Ren, Allen Z and Lidard, Justin and Ankile, Lars L and Simeonov, Anthony and Agrawal, Pulkit and Majumdar, Anirudha and Burchfiel, Benjamin and Dai, Hongkai and Simchowitz, Max},
  journal={arXiv preprint arXiv:2409.00588},
  year={2024}
}


@article{brohan2023rt-2,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@article{o2023open-x,
  title={Open x-embodiment: Robotic learning datasets and rt-x models},
  author={O'Neill, Abby and Rehman, Abdul and Gupta, Abhinav and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}

@article{brohan2022rt-1,
  title={Rt-1: Robotics transformer for real-world control at scale},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  journal={arXiv preprint arXiv:2212.06817},
  year={2022}
}



@inproceedings{octo,
    title={Octo: An Open-Source Generalist Robot Policy},
    author = {{Octo Model Team} and Dibya Ghosh and Homer Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Charles Xu and Jianlan Luo and Tobias Kreiman and {You Liang} Tan and Lawrence Yunliang Chen and Pannag Sanketi and Quan Vuong and Ted Xiao and Dorsa Sadigh and Chelsea Finn and Sergey Levine},
    booktitle = {Proceedings of Robotics: Science and Systems},
    address  = {Delft, Netherlands},
    year = {2024},
}

@article{mobile_aloha,
  title={Mobile aloha: Learning bimanual mobile manipulation with low-cost whole-body teleoperation},
  author={Fu, Zipeng and Zhao, Tony Z and Finn, Chelsea},
  journal={arXiv preprint arXiv:2401.02117},
  year={2024}
}

@article{aloha2,
  title={ALOHA 2: An Enhanced Low-Cost Hardware for Bimanual Teleoperation},
  author={Aldaco, Jorge and Armstrong, Travis and Baruch, Robert and Bingham, Jeff and Chan, Sanky and Draper, Kenneth and Dwibedi, Debidatta and Finn, Chelsea and Florence, Pete and Goodrich, Spencer and others},
  journal={arXiv preprint arXiv:2405.02292},
  year={2024}
}

@inproceedings{aloha_unleashed,
  title={ALOHA Unleashed: A Simple Recipe for Robot Dexterity},
  author={Zhao, Tony Z and Tompson, Jonathan and Driess, Danny and Florence, Pete and Ghasemipour, Seyed Kamyar Seyed and Finn, Chelsea and Wahid, Ayzaan},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024}
}

@article{yang2024movie,
  title={Movie: Visual model-based policy adaptation for view generalization},
  author={Yang, Sizhe and Ze, Yanjie and Xu, Huazhe},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{codeaspolicy,
  title={Code as policies: Language model programs for embodied control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={9493--9500},
  year={2023},
  organization={IEEE}
}


@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}


@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@inproceedings{ze2023gnfactor,
  title={Gnfactor: Multi-task real robot learning with generalizable neural feature fields},
  author={Ze, Yanjie and Yan, Ge and Wu, Yueh-Hua and Macaluso, Annabella and Ge, Yuying and Ye, Jianglong and Hansen, Nicklas and Li, Li Erran and Wang, Xiaolong},
  booktitle={Conference on Robot Learning},
  pages={284--301},
  year={2023},
  organization={PMLR}
}

@article{ze2023visual,
  title={Visual reinforcement learning with self-supervised 3d representations},
  author={Ze, Yanjie and Hansen, Nicklas and Chen, Yinbo and Jain, Mohit and Wang, Xiaolong},
  journal={IEEE Robotics and Automation Letters},
  volume={8},
  number={5},
  pages={2890--2897},
  year={2023},
  publisher={IEEE}
}

@article{h_index,
  title={H-InDex: Visual reinforcement learning with hand-informed representations for dexterous manipulation},
  author={Ze, Yanjie and Liu, Yuyao and Shi, Ruizhe and Qin, Jiaxin and Yuan, Zhecheng and Wang, Jiashun and Xu, Huazhe},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{yell_at_your_robot,
  title={Yell at your robot: Improving on-the-fly from language corrections},
  author={Shi, Lucy Xiaoyang and Hu, Zheyuan and Zhao, Tony Z and Sharma, Archit and Pertsch, Karl and Luo, Jianlan and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2403.12910},
  year={2024}
}


@inproceedings{roboagent,
  author={Bharadhwaj, Homanga and Vakil, Jay and Sharma, Mohit and Gupta, Abhinav and Tulsiani, Shubham and Kumar, Vikash},
  title={RoboAgent: Generalization and Efficiency in Robot Manipulation via Semantic Augmentations and Action Chunking}, 
  year={2024},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  pages={4788-4795},
  organization={IEEE}
}

@article{diffusion-policy,
  title={Diffusion policy: Visuomotor policy learning via action diffusion},
  author={Chi, Cheng and Feng, Siyuan and Du, Yilun and Xu, Zhenjia and Cousineau, Eric and Burchfiel, Benjamin and Song, Shuran},
  journal={arXiv preprint arXiv:2303.04137},
  year={2023}
}

@article{ddpms,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{liu2024libero,
  title={Libero: Benchmarking knowledge transfer for lifelong robot learning},
  author={Liu, Bo and Zhu, Yifeng and Gao, Chongkai and Feng, Yihao and Liu, Qiang and Zhu, Yuke and Stone, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{[pi0,
      title={$\pi_0$: A Vision-Language-Action Flow Model for General Robot Control}, 
      author={Kevin Black and Noah Brown and Danny Driess and Adnan Esmail and Michael Equi and Chelsea Finn and Niccolo Fusai and Lachy Groom and Karol Hausman and Brian Ichter and Szymon Jakubczak and Tim Jones and Liyiming Ke and Sergey Levine and Adrian Li-Bell and Mohith Mothukuri and Suraj Nair and Karl Pertsch and Lucy Xiaoyang Shi and James Tanner and Quan Vuong and Anna Walling and Haohuan Wang and Ury Zhilinsky},
      year={2024},
      eprint={2410.24164},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.24164}, 
}



@article{zhu2024scalingdp,
  title={Scaling diffusion policy in transformer to 1 billion parameters for robotic manipulation},
  author={Zhu, Minjie and Zhu, Yichen and Li, Jinming and Wen, Junjie and Xu, Zhiyuan and Liu, Ning and Cheng, Ran and Shen, Chaomin and Peng, Yaxin and Feng, Feifei and others},
  journal={arXiv preprint arXiv:2409.14411},
  year={2024}
}


@inproceedings{ibc,
  title={Implicit behavioral cloning},
  author={Florence, Pete and Lynch, Corey and Zeng, Andy and Ramirez, Oscar A and Wahid, Ayzaan and Downs, Laura and Wong, Adrian and Lee, Johnny and Mordatch, Igor and Tompson, Jonathan},
  booktitle={Conference on Robot Learning},
  pages={158--168},
  year={2022},
  organization={PMLR}
}

@inproceedings{leo3d,
  title={An Embodied Generalist Agent in 3D World},
  author={Huang, Jiangyong and Yong, Silong and Ma, Xiaojian and Linghu, Xiongkun and Li, Puhao and Wang, Yan and Li, Qing and Zhu, Song-Chun and Jia, Baoxiong and Huang, Siyuan},
  booktitle={ICLR 2024 Workshop: How Far Are We From AGI}
}

@article{roboflamingo,
  title={Vision-language foundation models as effective robot imitators},
  author={Li, Xinghang and Liu, Minghuan and Zhang, Hanbo and Yu, Cunjun and Xu, Jie and Wu, Hongtao and Cheang, Chilam and Jing, Ya and Zhang, Weinan and Liu, Huaping and others},
  journal={arXiv preprint arXiv:2311.01378},
  year={2023}
}

@article{3d_diffuser_actor,
  title={3d diffuser actor: Policy diffusion with 3d scene representations},
  author={Ke, Tsung-Wei and Gkanatsios, Nikolaos and Fragkiadaki, Katerina},
  journal={arXiv preprint arXiv:2402.10885},
  year={2024}
}

@article{cheang2024gr,
  title={GR-2: A Generative Video-Language-Action Model with Web-Scale Knowledge for Robot Manipulation},
  author={Cheang, Chi-Lam and Chen, Guangzeng and Jing, Ya and Kong, Tao and Li, Hang and Li, Yifeng and Liu, Yuxiao and Wu, Hongtao and Xu, Jiafeng and Yang, Yichu and others},
  journal={arXiv preprint arXiv:2410.06158},
  year={2024}
}

@inproceedings{mail-dp,
  title={MaIL: Improving Imitation Learning with Selective State Space Models},
  author={Jia, Xiaogang and Wang, Qian and Donat, Atalay and Xing, Bowen and Li, Ge and Zhou, Hongyi and Celik, Onur and Blessing, Denis and Lioutikov, Rudolf and Neumann, Gerhard},
  booktitle={8th Annual Conference on Robot Learning},
  year={2024}
}

@article{wang2024sparse-dp,
  title={Sparse diffusion policy: A sparse, reusable, and flexible policy for robot learning},
  author={Wang, Yixiao and Zhang, Yifei and Huo, Mingxiao and Tian, Ran and Zhang, Xiang and Xie, Yichen and Xu, Chenfeng and Ji, Pengliang and Zhan, Wei and Ding, Mingyu and others},
  journal={arXiv preprint arXiv:2407.01531},
  year={2024}
}

@article{One-Step-Diffusion-Policy,
  title={One-Step Diffusion Policy: Fast Visuomotor Policies via Diffusion Distillation},
  author={Wang, Zhendong and Li, Zhaoshuo and Mandlekar, Ajay and Xu, Zhenjia and Fan, Jiaojiao and Narang, Yashraj and Fan, Linxi and Zhu, Yuke and Balaji, Yogesh and Zhou, Mingyuan and others},
  journal={arXiv preprint arXiv:2410.21257},
  year={2024}
}

@article{prasad2024consistencypolicy,
  title={Consistency policy: Accelerated visuomotor policies via consistency distillation},
  author={Prasad, Aaditya and Lin, Kevin and Wu, Jimmy and Zhou, Linqi and Bohg, Jeannette},
  journal={arXiv preprint arXiv:2405.07503},
  year={2024}
}

@article{manipulateanywhere, title={Learning to Manipulate Anywhere: A Visual Generalizable Framework For Reinforcement Learning}, author={Yuan, Zhecheng and Wei, Tianming and Cheng, Shuiqi and Zhang, Gu and Chen, Yuanpei and Xu, Huazhe}, journal={arXiv preprint arXiv:2407.15815}, year={2024}}



@article{rt-h,
  title={Rt-h: Action hierarchies using language},
  author={Belkhale, Suneel and Ding, Tianli and Xiao, Ted and Sermanet, Pierre and Vuong, Quon and Tompson, Jonathan and Chebotar, Yevgen and Dwibedi, Debidatta and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2403.01823},
  year={2024}
}

@inproceedings{bcz,
  title={Bc-z: Zero-shot task generalization with robotic imitation learning},
  author={Jang, Eric and Irpan, Alex and Khansari, Mohi and Kappler, Daniel and Ebert, Frederik and Lynch, Corey and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={991--1002},
  year={2022},
  organization={PMLR}
}

@article{jiang2022vima,
  title={Vima: General robot manipulation with multimodal prompts},
  author={Jiang, Yunfan and Gupta, Agrim and Zhang, Zichen and Wang, Guanzhi and Dou, Yongqiang and Chen, Yanjun and Fei-Fei, Li and Anandkumar, Anima and Zhu, Yuke and Fan, Linxi},
  journal={arXiv preprint arXiv:2210.03094},
  volume={2},
  number={3},
  pages={6},
  year={2022}
}

@article{srirama2024hrp,
  title={Hrp: Human affordances for robotic pre-training},
  author={Srirama, Mohan Kumar and Dasari, Sudeep and Bahl, Shikhar and Gupta, Abhinav},
  journal={arXiv preprint arXiv:2407.18911},
  year={2024}
}

@inproceedings{Contact-graspnet,
  title={Contact-graspnet: Efficient 6-dof grasp generation in cluttered scenes},
  author={Sundermeyer, Martin and Mousavian, Arsalan and Triebel, Rudolph and Fox, Dieter},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={13438--13444},
  year={2021},
  organization={IEEE}
}

@inproceedings{tang2023task,
  title={Task-oriented grasp prediction with visual-language inputs},
  author={Tang, Chao and Huang, Dehao and Meng, Lingxiao and Liu, Weiyu and Zhang, Hong},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4881--4888},
  year={2023},
  organization={IEEE}
}

@article{sundaresan2023kite,
  title={Kite: Keypoint-conditioned policies for semantic manipulation},
  author={Sundaresan, Priya and Belkhale, Suneel and Sadigh, Dorsa and Bohg, Jeannette},
  journal={arXiv preprint arXiv:2306.16605},
  year={2023}
}

@article{Any-point-trajectory,
  title={Any-point trajectory modeling for policy learning},
  author={Wen, Chuan and Lin, Xingyu and So, John and Chen, Kai and Dou, Qi and Gao, Yang and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2401.00025},
  year={2023}
}


@inproceedings{ze20243d,
  title={3d diffusion policy: Generalizable visuomotor policy learning via simple 3d representations},
  author={Ze, Yanjie and Zhang, Gu and Zhang, Kangning and Hu, Chenyuan and Wang, Muhan and Xu, Huazhe},
  booktitle={ICRA 2024 Workshop on 3D Visual Representations for Robot Manipulation},
  year={2024}
}

@article{ze2024generalizable,
  title={Generalizable humanoid manipulation with improved 3d diffusion policies},
  author={Ze, Yanjie and Chen, Zixuan and Wang, Wenhao and Chen, Tianyi and He, Xialin and Yuan, Ying and Peng, Xue Bin and Wu, Jiajun},
  journal={arXiv preprint arXiv:2410.10803},
  year={2024}
}

@article{yan2024dnact,
  title={Dnact: Diffusion guided multi-task 3d policy learning},
  author={Yan, Ge and Wu, Yueh-Hua and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2403.04115},
  year={2024}
}

@article{wang2024equivariant,
  title={Equivariant diffusion policy},
  author={Wang, Dian and Hart, Stephen and Surovik, David and Kelestemur, Tarik and Huang, Haojie and Zhao, Haibo and Yeatman, Mark and Wang, Jiuguang and Walters, Robin and Platt, Robert},
  journal={arXiv preprint arXiv:2407.01812},
  year={2024}
}

@article{huang2023voxposer,
  title={Voxposer: Composable 3d value maps for robotic manipulation with language models},
  author={Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2307.05973},
  year={2023}
}

@article{huang2024copa,
  title={Copa: General robotic manipulation through spatial constraints of parts with foundation models},
  author={Huang, Haoxu and Lin, Fanqi and Hu, Yingdong and Wang, Shengjie and Gao, Yang},
  journal={arXiv preprint arXiv:2403.08248},
  year={2024}
}

@article{duan2024manipulate,
  title={Manipulate-anything: Automating real-world robots using vision-language models},
  author={Duan, Jiafei and Yuan, Wentao and Pumacay, Wilbert and Wang, Yi Ru and Ehsani, Kiana and Fox, Dieter and Krishna, Ranjay},
  journal={arXiv preprint arXiv:2406.18915},
  year={2024}
}

@inproceedings{li2024manipllm,
  title={Manipllm: Embodied multimodal large language model for object-centric robotic manipulation},
  author={Li, Xiaoqi and Zhang, Mingxu and Geng, Yiran and Geng, Haoran and Long, Yuxing and Shen, Yan and Zhang, Renrui and Liu, Jiaming and Dong, Hao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18061--18070},
  year={2024}
}

@article{huang2024rekep,
  title={Rekep: Spatio-temporal reasoning of relational keypoint constraints for robotic manipulation},
  author={Huang, Wenlong and Wang, Chen and Li, Yunzhu and Zhang, Ruohan and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2409.01652},
  year={2024}
}

@article{huang2024a3vlm,
  title={A3VLM: Actionable Articulation-Aware Vision Language Model},
  author={Huang, Siyuan and Chang, Haonan and Liu, Yuhan and Zhu, Yimeng and Dong, Hao and Gao, Peng and Boularias, Abdeslam and Li, Hongsheng},
  journal={arXiv preprint arXiv:2406.07549},
  year={2024}
}

@inproceedings{katara2024gen2sim,
  title={Gen2sim: Scaling up robot learning in simulation with generative models},
  author={Katara, Pushkal and Xian, Zhou and Fragkiadaki, Katerina},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6672--6679},
  year={2024},
  organization={IEEE}
}


@article{black2023zero,
  title={Zero-shot robotic manipulation with pretrained image-editing diffusion models},
  author={Black, Kevin and Nakamoto, Mitsuhiko and Atreya, Pranav and Walke, Homer and Finn, Chelsea and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2310.10639},
  year={2023}
}

@article{black2023training,
  title={Training diffusion models with reinforcement learning},
  author={Black, Kevin and Janner, Michael and Du, Yilun and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2305.13301},
  year={2023}
}

@article{uehara2024feedback,
  title={Feedback efficient online fine-tuning of diffusion models},
  author={Uehara, Masatoshi and Zhao, Yulai and Black, Kevin and Hajiramezanali, Ehsan and Scalia, Gabriele and Diamant, Nathaniel Lee and Tseng, Alex M and Levine, Sergey and Biancalani, Tommaso},
  journal={arXiv preprint arXiv:2402.16359},
  year={2024}
}

@article{uehara2024fine,
  title={Fine-tuning of continuous-time diffusion models as entropy-regularized control},
  author={Uehara, Masatoshi and Zhao, Yulai and Black, Kevin and Hajiramezanali, Ehsan and Scalia, Gabriele and Diamant, Nathaniel Lee and Tseng, Alex M and Biancalani, Tommaso and Levine, Sergey},
  journal={arXiv preprint arXiv:2402.15194},
  year={2024}
}

@article{dasari2024ingredients,
  title={The Ingredients for Robotic Diffusion Transformers},
  author={Dasari, Sudeep and Mees, Oier and Zhao, Sebastian and Srirama, Mohan Kumar and Levine, Sergey},
  journal={arXiv preprint arXiv:2410.10088},
  year={2024}
}

@misc{lin2024datascalinglawsimitation,
  title = {Data Scaling Laws in Imitation Learning for Robotic Manipulation},
  author = {Fanqi Lin and Yingdong Hu and Pingyue Sheng and Chuan Wen and Jiacheng You and Yang Gao},
  archivePrefix = {arXiv},
  eprint = {2410.18647},
  primaryClass = {cs.RO},
  url = {https://arxiv.org/abs/2410.18647},
  year = {2024}
}

@inproceedings{vllm,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

# newly added
@article{bu2024towards,
  title={Towards Synergistic, Generalized, and Efficient Dual-System for Robotic Manipulation},
  author={Bu, Qingwen and Li, Hongyang and Chen, Li and Cai, Jisong and Zeng, Jia and Cui, Heming and Yao, Maoqing and Qiao, Yu},
  journal={arXiv preprint arXiv:2410.08001},
  year={2024}
}

@article{liu2024rdt,
  title={Rdt-1b: a diffusion foundation model for bimanual manipulation},
  author={Liu, Songming and Wu, Lingxuan and Li, Bangguo and Tan, Hengkai and Chen, Huayu and Wang, Zhengyi and Xu, Ke and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2410.07864},
  year={2024}
}

@article{li2024towards,
  title={Towards Generalist Robot Policies: What Matters in Building Vision-Language-Action Models},
  author={Li, Xinghang and Li, Peiyan and Liu, Minghuan and Wang, Dong and Liu, Jirong and Kang, Bingyi and Ma, Xiao and Kong, Tao and Zhang, Hanbo and Liu, Huaping},
  journal={arXiv preprint arXiv:2412.14058},
  year={2024}
}

@article{li2024cogact,
  title={CogACT: A Foundational Vision-Language-Action Model for Synergizing Cognition and Action in Robotic Manipulation},
  author={Li, Qixiu and Liang, Yaobo and Wang, Zeyu and Luo, Lin and Chen, Xi and Liao, Mozheng and Wei, Fangyun and Deng, Yu and Xu, Sicheng and Zhang, Yizhong and others},
  journal={arXiv preprint arXiv:2411.19650},
  year={2024}
}

@article{zheng2025universal,
  title={Universal Actions for Enhanced Embodied Foundation Models},
  author={Zheng, Jinliang and Li, Jianxiong and Liu, Dongxiu and Zheng, Yinan and Wang, Zhihao and Ou, Zhonghong and Liu, Yu and Liu, Jingjing and Zhang, Ya-Qin and Zhan, Xianyuan},
  journal={arXiv preprint arXiv:2501.10105},
  year={2025}
}


@article{wu2024discrete,
  title={Discrete policy: Learning disentangled action space for multi-task robotic manipulation},
  author={Wu, Kun and Zhu, Yichen and Li, Jinming and Wen, Junjie and Liu, Ning and Xu, Zhiyuan and Qiu, Qinru and Tang, Jian},
  journal={arXiv preprint arXiv:2409.18707},
  year={2024}
}

@article{wang2024scaling,
  title={Scaling proprioceptive-visual learning with heterogeneous pre-trained transformers},
  author={Wang, Lirui and Chen, Xinlei and Zhao, Jialiang and He, Kaiming},
  journal={arXiv preprint arXiv:2409.20537},
  year={2024}
}

@article{wang2024poco,
  title={Poco: Policy composition from and for heterogeneous robot learning},
  author={Wang, Lirui and Zhao, Jialiang and Du, Yilun and Adelson, Edward H and Tedrake, Russ},
  journal={arXiv preprint arXiv:2402.02511},
  year={2024}
}

@article{wang2023fleet,
  title={Fleet Policy Learning via Weight Merging and An Application to Robotic Tool-Use},
  author={Wang, Lirui and Zhang, Kaiqing and Zhou, Allan and Simchowitz, Max and Tedrake, Russ},
  journal={arXiv preprint arXiv:2310.01362},
  year={2023}
}

###################################################################### new added ####################################################################
@article{he2024hover,
  title={Hover: Versatile neural whole-body controller for humanoid robots},
  author={He, Tairan and Xiao, Wenli and Lin, Toru and Luo, Zhengyi and Xu, Zhenjia and Jiang, Zhenyu and Kautz, Jan and Liu, Changliu and Shi, Guanya and Wang, Xiaolong and others},
  journal={arXiv preprint arXiv:2410.21229},
  year={2024}
}

@article{lin2024learning,
  title={Learning Visuotactile Skills with Two Multifingered Hands},
  author={Lin, Toru and Zhang, Yu and Li, Qiyang and Qi, Haozhi and Yi, Brent and Levine, Sergey and Malik, Jitendra},
  journal={arXiv preprint arXiv:2404.16823},
  year={2024}
}

@article{shi2023robocook,
  title={Robocook: Long-horizon elasto-plastic object manipulation with diverse tools},
  author={Shi, Haochen and Xu, Huazhe and Clarke, Samuel and Li, Yunzhu and Wu, Jiajun},
  journal={arXiv preprint arXiv:2306.14447},
  year={2023}
}

@article{wang2024dexcap,
  title={Dexcap: Scalable and portable mocap data collection system for dexterous manipulation},
  author={Wang, Chen and Shi, Haochen and Wang, Weizhuo and Zhang, Ruohan and Fei-Fei, Li and Liu, C Karen},
  journal={arXiv preprint arXiv:2403.07788},
  year={2024}
}

@article{shi2024robocraft,
  title={RoboCraft: Learning to see, simulate, and shape elasto-plastic objects in 3D with graph networks},
  author={Shi, Haochen and Xu, Huazhe and Huang, Zhiao and Li, Yunzhu and Wu, Jiajun},
  journal={The International Journal of Robotics Research},
  volume={43},
  number={4},
  pages={533--549},
  year={2024},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{ai2024robopack,
  title={RoboPack: Learning Tactile-Informed Dynamics Models for Dense Packing},
  author={Ai, Bo and Tian, Stephen and Shi, Haochen and Wang, Yixuan and Tan, Cheston and Li, Yunzhu and Wu, Jiajun},
  booktitle={ICRA 2024 Workshop on 3D Visual Representations for Robot Manipulation}
}

@inproceedings{gao2016deep,
  title={Deep learning for tactile understanding from visual and haptic data},
  author={Gao, Yang and Hendricks, Lisa Anne and Kuchenbecker, Katherine J and Darrell, Trevor},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={536--543},
  year={2016},
  organization={IEEE}
}

@article{lin2024data,
  title={Data scaling laws in imitation learning for robotic manipulation},
  author={Lin, Fanqi and Hu, Yingdong and Sheng, Pingyue and Wen, Chuan and You, Jiacheng and Gao, Yang},
  journal={arXiv preprint arXiv:2410.18647},
  year={2024}
}

@article{zhang2024learning,
  title={Learning Manipulation Skills through Robot Chain-of-Thought with Sparse Failure Guidance},
  author={Zhang, Kaifeng and Yin, Zhao-Heng and Ye, Weirui and Gao, Yang},
  journal={arXiv preprint arXiv:2405.13573},
  year={2024}
}

@article{hu2023look,
  title={Look before you leap: Unveiling the power of gpt-4v in robotic vision-language planning},
  author={Hu, Yingdong and Lin, Fanqi and Zhang, Tong and Yi, Li and Gao, Yang},
  journal={arXiv preprint arXiv:2311.17842},
  year={2023}
}

@inproceedings{fu2023demonstrating,
  title={Demonstrating RFUniverse: A Multiphysics Simulation Platform for Embodied AI.},
  author={Fu, Haoyuan and Xu, Wenqiang and Ye, Ruolin and Xue, Han and Yu, Zhenjun and Tang, Tutian and Li, Yutong and Du, Wenxin and Zhang, Jieyi and Lu, Cewu},
  booktitle={Robotics: Science and Systems},
  year={2023}
}

@inproceedings{fang2020graspnet,
  title={Graspnet-1billion: A large-scale benchmark for general object grasping},
  author={Fang, Hao-Shu and Wang, Chenxi and Gou, Minghao and Lu, Cewu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11444--11453},
  year={2020}
}

@article{ha2024umi,
  title={Umi on legs: Making manipulation policies mobile with manipulation-centric whole-body controllers},
  author={Ha, Huy and Gao, Yihuai and Fu, Zipeng and Tan, Jie and Song, Shuran},
  journal={arXiv preprint arXiv:2407.10353},
  year={2024}
}

@inproceedings{ha2023scaling,
  title={Scaling up and distilling down: Language-guided robot skill acquisition},
  author={Ha, Huy and Florence, Pete and Song, Shuran},
  booktitle={Conference on Robot Learning},
  pages={3766--3777},
  year={2023},
  organization={PMLR}
}

@article{zeng2022robotic,
  title={Robotic pick-and-place of novel objects in clutter with multi-affordance grasping and cross-domain image matching},
  author={Zeng, Andy and Song, Shuran and Yu, Kuan-Ting and Donlon, Elliott and Hogan, Francois R and Bauza, Maria and Ma, Daolin and Taylor, Orion and Liu, Melody and Romo, Eudald and others},
  journal={The International Journal of Robotics Research},
  volume={41},
  number={7},
  pages={690--705},
  year={2022},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{prasad2024consistency,
  title={Consistency policy: Accelerated visuomotor policies via consistency distillation},
  author={Prasad, Aaditya and Lin, Kevin and Wu, Jimmy and Zhou, Linqi and Bohg, Jeannette},
  journal={arXiv preprint arXiv:2405.07503},
  year={2024}
}

@article{fu2024humanplus,
  title={HumanPlus: Humanoid Shadowing and Imitation from Humans},
  author={Fu, Zipeng and Zhao, Qingqing and Wu, Qi and Wetzstein, Gordon and Finn, Chelsea},
  journal={arXiv preprint arXiv:2406.10454},
  year={2024}
}

@inproceedings{radosavovic2023real,
  title={Real-world robot learning with masked visual pre-training},
  author={Radosavovic, Ilija and Xiao, Tete and James, Stephen and Abbeel, Pieter and Malik, Jitendra and Darrell, Trevor},
  booktitle={Conference on Robot Learning},
  pages={416--426},
  year={2023},
  organization={PMLR}
}

@article{wu2023tidybot,
  title={Tidybot: Personalized robot assistance with large language models},
  author={Wu, Jimmy and Antonova, Rika and Kan, Adam and Lepert, Marion and Zeng, Andy and Song, Shuran and Bohg, Jeannette and Rusinkiewicz, Szymon and Funkhouser, Thomas},
  journal={Autonomous Robots},
  volume={47},
  number={8},
  pages={1087--1102},
  year={2023},
  publisher={Springer}
}

@inproceedings{qin2022dexmv,
  title={Dexmv: Imitation learning for dexterous manipulation from human videos},
  author={Qin, Yuzhe and Wu, Yueh-Hua and Liu, Shaowei and Jiang, Hanwen and Yang, Ruihan and Fu, Yang and Wang, Xiaolong},
  booktitle={European Conference on Computer Vision},
  pages={570--587},
  year={2022},
  organization={Springer}
}

@article{zeng2020tossingbot,
  title={Tossingbot: Learning to throw arbitrary objects with residual physics},
  author={Zeng, Andy and Song, Shuran and Lee, Johnny and Rodriguez, Alberto and Funkhouser, Thomas},
  journal={IEEE Transactions on Robotics},
  volume={36},
  number={4},
  pages={1307--1319},
  year={2020},
  publisher={IEEE}
}

@article{xu2019densephysnet,
  title={Densephysnet: Learning dense physical object representations via multi-step dynamic interactions},
  author={Xu, Zhenjia and Wu, Jiajun and Zeng, Andy and Tenenbaum, Joshua B and Song, Shuran},
  journal={arXiv preprint arXiv:1906.03853},
  year={2019}
}

@inproceedings{xiang2020sapien,
  title={Sapien: A simulated part-based interactive environment},
  author={Xiang, Fanbo and Qin, Yuzhe and Mo, Kaichun and Xia, Yikuan and Zhu, Hao and Liu, Fangchen and Liu, Minghua and Jiang, Hanxiao and Yuan, Yifu and Wang, He and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11097--11107},
  year={2020}
}

@inproceedings{yen2020learning,
  title={Learning to see before learning to act: Visual pre-training for manipulation},
  author={Yen-Chen, Lin and Zeng, Andy and Song, Shuran and Isola, Phillip and Lin, Tsung-Yi},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7286--7293},
  year={2020},
  organization={IEEE}
}

@article{chi2024universal,
  title={Universal manipulation interface: In-the-wild robot teaching without in-the-wild robots},
  author={Chi, Cheng and Xu, Zhenjia and Pan, Chuer and Cousineau, Eric and Burchfiel, Benjamin and Feng, Siyuan and Tedrake, Russ and Song, Shuran},
  journal={arXiv preprint arXiv:2402.10329},
  year={2024}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

@inproceedings{zeng2019end,
  title={End-to-end interpretable neural motion planner},
  author={Zeng, Wenyuan and Luo, Wenjie and Suo, Simon and Sadat, Abbas and Yang, Bin and Casas, Sergio and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8660--8669},
  year={2019}
}

@inproceedings{yang2018pixor,
  title={Pixor: Real-time 3d object detection from point clouds},
  author={Yang, Bin and Luo, Wenjie and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={7652--7660},
  year={2018}
}

@article{geiger2013vision,
  title={Vision meets robotics: The kitti dataset},
  author={Geiger, Andreas and Lenz, Philip and Stiller, Christoph and Urtasun, Raquel},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1231--1237},
  year={2013},
  publisher={Sage Publications Sage UK: London, England}
}


@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: Smaller, faster, cheaper and lighter. arXiv 2019},
  author={Sanh, Victor and Debut, L and Chaumond, J and Wolf, T},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}



@article{openflamingo,
  title={Openflamingo: An open-source framework for training large autoregressive vision-language models},
  author={Awadalla, Anas and Gao, Irena and Gardner, Josh and Hessel, Jack and Hanafy, Yusuf and Zhu, Wanrong and Marathe, Kalyani and Bitton, Yonatan and Gadre, Samir and Sagawa, Shiori and others},
  journal={arXiv preprint arXiv:2308.01390},
  year={2023}
}

@article{idefics,
  title={Obelisc: An open web-scale filtered dataset of interleaved image-text documents},
  author={Lauren{\c{c}}on, H and Saulnier, L and Tronchon, L and Bekman, S and Singh, A and Lozhkov, A and Wang, T and Karamcheti, S and Rush, A and Kiela, D},
  journal={arXiv preprint arXiv:2306.16527},
  year={2023}
}


@inproceedings{vizwiz,
  title={Vizwiz grand challenge: Answering visual questions from blind people},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3608--3617},
  year={2018}
}

@article{shikra,
  title={Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic},
  author={Chen, Keqin and Zhang, Zhao and Zeng, Weili and Zhang, Richong and Zhu, Feng and Zhao, Rui},
  journal={arXiv preprint arXiv:2306.15195},
  year={2023}
}


@inproceedings{zhu2024llava,
  title={Llava-phi: Efficient multi-modal assistant with small language model},
  author={Zhu, Yichen and Zhu, Minjie and Liu, Ning and Xu, Zhiyuan and Peng, Yaxin},
  booktitle={Proceedings of the 1st International Workshop on Efficient Multimedia Computing under Limited},
  pages={18--22},
  year={2024}
}

@article{zhu2024scaling,
  title={Scaling diffusion policy in transformer to 1 billion parameters for robotic manipulation},
  author={Zhu, Minjie and Zhu, Yichen and Li, Jinming and Wen, Junjie and Xu, Zhiyuan and Liu, Ning and Cheng, Ran and Shen, Chaomin and Peng, Yaxin and Feng, Feifei and others},
  journal={arXiv preprint arXiv:2409.14411},
  year={2024}
}


@inproceedings{liu2025mm,
  title={Mm-safetybench: A benchmark for safety evaluation of multimodal large language models},
  author={Liu, Xin and Zhu, Yichen and Gu, Jindong and Lan, Yunshi and Yang, Chao and Qiao, Yu},
  booktitle={European Conference on Computer Vision},
  pages={386--403},
  year={2025},
  organization={Springer}
}

@article{zhu2024comprehensive,
  title={A Comprehensive Overhaul of Multimodal Assistant with Small Language Models},
  author={Zhu, Minjie and Zhu, Yichen and Liu, Xin and Liu, Ning and Xu, Zhiyuan and Shen, Chaomin and Peng, Yaxin and Ou, Zhicai and Feng, Feifei and Tang, Jian},
  journal={arXiv preprint arXiv:2403.06199},
  year={2024}
}

@article{karamcheti2024prismatic,
  title={Prismatic vlms: Investigating the design space of visually-conditioned language models},
  author={Karamcheti, Siddharth and Nair, Suraj and Balakrishna, Ashwin and Liang, Percy and Kollar, Thomas and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2402.07865},
  year={2024}
}

@article{blip-2,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@article{llava1.5,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2310.03744},
  year={2023}
}
@article{ren2024dino,
  title={Dino-x: A unified vision model for open-world object detection and understanding},
  author={Ren, Tianhe and Chen, Yihao and Jiang, Qing and Zeng, Zhaoyang and Xiong, Yuda and Liu, Wenlong and Ma, Zhengyu and Shen, Junyi and Gao, Yuan and Jiang, Xiaoke and others},
  journal={arXiv preprint arXiv:2411.14347},
  year={2024}
}
@inproceedings{gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6700--6709},
  year={2019}
}

@article{seed,
  title={Seed-bench: Benchmarking multimodal llms with generative comprehension},
  author={Li, Bohao and Wang, Rui and Wang, Guangzhi and Ge, Yuying and Ge, Yixiao and Shan, Ying},
  journal={arXiv preprint arXiv:2307.16125},
  year={2023}
}

@inproceedings{vqav2,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@article{mmbench,
  title={Mmbench: Is your multi-modal model an all-around player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  journal={arXiv preprint arXiv:2307.06281},
  year={2023}
}

@article{beyer2024paligemma,
  title={Paligemma: A versatile 3b vlm for transfer},
  author={Beyer, Lucas and Steiner, Andreas and Pinto, Andr{\'e} Susano and Kolesnikov, Alexander and Wang, Xiao and Salz, Daniel and Neumann, Maxim and Alabdulmohsin, Ibrahim and Tschannen, Michael and Bugliarello, Emanuele and others},
  journal={arXiv preprint arXiv:2407.07726},
  year={2024}
}

@inproceedings{siglip,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11975--11986},
  year={2023}
}


@article{mme,
  title={Mme: A comprehensive evaluation benchmark for multimodal large language models},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and Qin, Yulei and Zhang, Mengdan and Lin, Xu and Yang, Jinrui and Zheng, Xiawu and Li, Ke and Sun, Xing and others},
  journal={arXiv preprint arXiv:2306.13394},
  year={2023}
}

@inproceedings{llava,
  title={Visual Instruction Tuning},
  author={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023},
  url={https://openreview.net/forum?id=w0H2xGHlkw}
}

@inproceedings{minigpt4,
  title={Mini{GPT}-4: Enhancing Vision-Language Understanding with Advanced Large Language Models},
  author={Deyao Zhu and Jun Chen and Xiaoqian Shen and Xiang Li and Mohamed Elhoseiny},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
  url={https://openreview.net/forum?id=1tZbq88f27}
}

@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@article{lu2024deepseek-vl,
  title={Deepseek-vl: towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Yang, Hao and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024}
}

@inproceedings{chen2024internvl,
  title={Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24185--24198},
  year={2024}
}

@article{ma2024janusflow,
  title={JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation},
  author={Ma, Yiyang and Liu, Xingchao and Chen, Xiaokang and Liu, Wen and Wu, Chengyue and Wu, Zhiyu and Pan, Zizheng and Xie, Zhenda and Zhang, Haowei and Zhao, Liang and others},
  journal={arXiv preprint arXiv:2411.07975},
  year={2024}
}

@article{wang2024visionllm,
  title={Visionllm: Large language model is also an open-ended decoder for vision-centric tasks},
  author={Wang, Wenhai and Chen, Zhe and Chen, Xiaokang and Wu, Jiannan and Zhu, Xizhou and Zeng, Gang and Luo, Ping and Lu, Tong and Zhou, Jie and Qiao, Yu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}




@inproceedings{james2019sim,
  title={Sim-to-real via sim-to-sim: Data-efficient robotic grasping via randomized-to-canonical adaptation networks},
  author={James, Stephen and Wohlhart, Paul and Kalakrishnan, Mrinal and Kalashnikov, Dmitry and Irpan, Alex and Ibarz, Julian and Levine, Sergey and Hadsell, Raia and Bousmalis, Konstantinos},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12627--12637},
  year={2019}
}

@INPROCEEDINGS{tobin,
  author={Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Domain randomization for transferring deep neural networks from simulation to the real world}, 
  year={2017},
  volume={},
  number={},
  pages={23-30},
  keywords={Robots;Training;Adaptation models;Three-dimensional displays;Cameras;Solid modeling;Data models},
  doi={10.1109/IROS.2017.8202133}
}



@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@article{kostrikov2020image,
  title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
  author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
  journal={arXiv preprint arXiv:2004.13649},
  year={2020}
}

@article{laskin2020reinforcement,
  title={Reinforcement learning with augmented data},
  author={Laskin, Misha and Lee, Kimin and Stooke, Adam and Pinto, Lerrel and Abbeel, Pieter and Srinivas, Aravind},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={19884--19895},
  year={2020}
}


@article{black2024pi_0,
  title={$$\backslash$pi\_0 $: A Vision-Language-Action Flow Model for General Robot Control},
  author={Black, Kevin and Brown, Noah and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and Groom, Lachy and Hausman, Karol and Ichter, Brian and others},
  journal={arXiv preprint arXiv:2410.24164},
  year={2024}
}

@article{kim24openvla,
    title={OpenVLA: An Open-Source Vision-Language-Action Model},
    author={{Moo Jin} Kim and Karl Pertsch and Siddharth Karamcheti and Ted Xiao and Ashwin Balakrishna and Suraj Nair and Rafael Rafailov and Ethan Foster and Grace Lam and Pannag Sanketi and Quan Vuong and Thomas Kollar and Benjamin Burchfiel and Russ Tedrake and Dorsa Sadigh and Sergey Levine and Percy Liang and Chelsea Finn},
    journal = {arXiv preprint arXiv:2406.09246},
    year={2024},
}



@article{scaledp,
  title={Scaling diffusion policy in transformer to 1 billion parameters for robotic manipulation},
  author={Zhu, Minjie and Zhu, Yichen and Li, Jinming and Wen, Junjie and Xu, Zhiyuan and Liu, Ning and Cheng, Ran and Shen, Chaomin and Peng, Yaxin and Feng, Feifei and others},
  journal={arXiv preprint arXiv:2409.14411},
  year={2024}
}



@article{ahn2022saycan,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@article{zhu2024vision,
  title={Vision-based Manipulation from Single Human Video with Open-World Object Graphs},
  author={Zhu, Yifeng and Lim, Arisrei and Stone, Peter and Zhu, Yuke},
  journal={arXiv preprint arXiv:2405.20321},
  year={2024}
}

@article{stone2023open,
  title={Open-world object manipulation using pre-trained vision-language models},
  author={Stone, Austin and Xiao, Ted and Lu, Yao and Gopalakrishnan, Keerthana and Lee, Kuang-Huei and Vuong, Quan and Wohlhart, Paul and Kirmani, Sean and Zitkovich, Brianna and Xia, Fei and others},
  journal={arXiv preprint arXiv:2303.00905},
  year={2023}
}

@article{ye2025video2policy,
  title={Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos},
  author={Ye, Weirui and Liu, Fangchen and Ding, Zheng and Gao, Yang and Rybkin, Oleh and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2502.09886},
  year={2025}
}

@INPROCEEDINGS{9340848,
  author={Schoettler, Gerrit and Nair, Ashvin and Ojea, Juan Aparicio and Levine, Sergey and Solowjow, Eugen},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Meta-Reinforcement Learning for Robotic Industrial Insertion Tasks}, 
  year={2020},
  volume={},
  number={},
  pages={9728-9735},
  keywords={Connectors;Training;Adaptation models;Service robots;Training data;Reinforcement learning;Task analysis},
  doi={10.1109/IROS45743.2020.9340848}}


@inproceedings{kaushik2020fast,
  title={Fast online adaptation in robotics through meta-learning embeddings of simulated priors},
  author={Kaushik, Rituraj and Anne, Timoth{\'e}e and Mouret, Jean-Baptiste},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5269--5276},
  year={2020},
  organization={IEEE}
}

@article{abdin2024phi3,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Aneja, Jyoti and Awadalla, Hany and Awadallah, Ahmed and Awan, Ammar Ahmad and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Bao, Jianmin and Behl, Harkirat and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}

@inproceedings{zhu2024retrieval,
  title={Retrieval-augmented embodied agents},
  author={Zhu, Yichen and Ou, Zhicai and Mou, Xiaofeng and Tang, Jian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17985--17995},
  year={2024}
}

@article{zhu2025any2policy,
  title={Any2Policy: Learning Visuomotor Policy with Any-Modality},
  author={Zhu, Yichen and Ou, Zhicai and Feng, Feifei and Tang, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={133518--133540},
  year={2025}
}

@article{haddadin2024franka,
  title={The Franka Emika Robot: A Standard Platform in Robotics Research},
  author={Haddadin, Sami},
  journal={IEEE Robotics \& Automation Magazine},
  year={2024},
  publisher={IEEE}
}

@article{cheang2024gr2,
  title={Gr-2: A generative video-language-action model with web-scale knowledge for robot manipulation},
  author={Cheang, Chi-Lam and Chen, Guangzeng and Jing, Ya and Kong, Tao and Li, Hang and Li, Yifeng and Liu, Yuxiao and Wu, Hongtao and Xu, Jiafeng and Yang, Yichu and others},
  journal={arXiv preprint arXiv:2410.06158},
  year={2024}
}
