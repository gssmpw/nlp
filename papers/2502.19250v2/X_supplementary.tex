\begin{figure*}[h]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/ood_objs_part1.pdf}
    \caption{The out-of-distribution objects used in our experiments (part 1).}\label{fig:ood_objs_part1}
\end{figure*}

\section{Appendix}
\label{sec:appendix}

\subsection{Evaluation Metrics}
For real robot task, we record the percentage of trials where the robot successfully completes the assigned task. This is a fundamental metric for any robot experiment. Multiple trials are conducted for the evaluation.


\subsection{Implementation Details}
All experiments were conducted on eight NVIDIA A800 GPUs using the Adam optimizer with a constant learning rate of 2e-5 and a global batch size of 128.  Training proceeded for 50,000 steps, with the final checkpoint selected based on validation performance. Unless otherwise stated, the ratio of robot data to visual-text data was 10:1.  Empirically, we observed that increasing the proportion of robot data significantly degraded manipulation performance.  Our base model is DiVLA\cite{wen2024diffusionvla} with a Qwen2-VL-2B backbone~\cite{wang2024qwen2}. As our focus is developing a co-training method for novel object generalization, we retained the original model architecture.


\subsection{Example of Objects Used in Experiments}
We provide a comprehensive list of \text{out-of-distrbution} objects and names that we used for training and evaluation, which are shown in Figure~\ref{fig:ood_objs_part1} and Figure~\ref{fig:ood_objs_part2}.



\begin{figure*}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/ood_objs_part2.pdf}
    \caption{The out-of-distribution objects used in our experiments (part 2).}\label{fig:ood_objs_part2}
\end{figure*}