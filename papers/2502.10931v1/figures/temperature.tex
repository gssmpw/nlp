% \begin{table}[h]
% \begin{tabular}{lcc}
% \toprule
% \small
% \textbf{Category} & \textbf{GPT-4o T=0.95} & \textbf{GPT-4o T=1.0} \\
% \midrule
% \texttt{cry}    & 3.85 & 5.77 \\
% \texttt{for} & 20.0 & 20.0 \\
% \texttt{pwn}       & 5.13 & \textbf{7.69} \\
% \texttt{rev}       & 11.76 & \textbf{13.73} \\
% \texttt{web}       &   10.53  & 10.53 \\
% \texttt{misc}      & 16.67 & 16.67 \\
% \texttt{\textbf{Avg.}} & 9.5 & \textbf{11.0} \\
% \bottomrule
% \end{tabular}
% \caption{NYU CTF benchmark success rate (\%) of GPT-4o on temperature 0.95 and temperature 1.0, higher temperature means the model will be more creative with higher randomness.}
% \label{tab:temperature}
% \end{table}

\begin{table}[htbp]
\centering
% \small
\caption{GPT 4o \textit{\% solved} for temperatures 0.95 and 1.0.}% Higher temperature produces more creativity and randomness in LLM responses.}
\label{tab:temperature}
\begin{tabular}{lccccccc}
\toprule
& crypto & foren. & pwn & rev & web & misc & \textbf{total} \\
\midrule
$T=1.0$ & 5.8 & 13.3 & 7.7 & 13.7 & 10.5 & 16.7 & 10.5 \\
$T=0.95$ & 3.8 & 13.3 & 5.1 & 11.8 & 10.5 & 16.7 & 9.0 \\
\bottomrule
\end{tabular}
\end{table}