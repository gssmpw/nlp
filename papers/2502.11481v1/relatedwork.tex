\section{Related Work}
\label{sec:Related Work}
%序言
The classification task based on an ultrasound image is relatively extensive. The ultrasound classification task is mainly concentrated in the following fields: 1) Research on ultrasound image classification algorithms; 2) Research on ultrasound video algorithms. This section provides an overview of the relevant work in these two areas, and the limitations of the current method are described. 
%end

\subsection{Ultrasound image classification}
With the development of deep learning technology, many researchers will use deep learning classifiers for ultrasound images to research ultrasound classification tasks. Singh~\emph{et al}.~\cite{singh2015adaptive} proposed a classification method for ultrasound images. First, we use a wavelet-based filter to remove blobs, and then the texture and shape features are extracted. Finally, use adaptive gradient descent for classification. Mohammed ~\emph{et al}.~\cite{mohammed2018neural} used a neural network approach for classification and used median and adaptive weighted filtering to preprocess images. Then, ROI and multifractal dimension features are extracted. Finally, the images were classified using an artificial neural network. Byra~\emph{et al}.~\cite{byra2018discriminant} used the extracted features of the VGG19 neural network architecture. Using Fisher discriminant analysis selects and classifies features. Fisher discriminant analysis identifies breast lesions and shows which features are helpful for contour detection. Yap~\emph{et al}.~\cite{yap2020breast} used a convolutional neural network (CNN) and a box classifier for line object recognition. First, convolutional features are extracted from ultrasound images and then objective using bounding boxes and object classification score. Finally, the box classifier identifies the tumor. Moon~\emph{et al}.~\cite{moon2020computer} proposed a combination of three different CNN classification structures. First, the original ultrasound images, ROI ultrasound images, tumor ultrasound images, tumor shape ultrasound images, and fused ultrasound images are extracted. Then, three CNN architectures (VGG, ResNet~\cite{he2016deep}, and DenseNet) are built from scratch and use machine learning algorithms to extract features. Next, combine the ensemble model with the CNN architecture. Finally, use an integration framework to classify. Huang~\emph{et al}.~\cite{huang2020segmentation} extracted the gray histogram, GLCM, and Symbiotic Local Binary Patterns (LBP). Using K-means and bag-of-words algorithms to extract features from GLCM and LBP. Then, an initial classification is performed using a Backpropagation Neural Network Work (BPNN) and K-Nearest Neighbors (KNN) algorithm for redistribution and post-processing. BPNN incorporates features from superpixels, while the KNN algorithm performs actual classification. Jarosik~\emph{et al}.~\cite{jarosik2020breast} proposed an ultrasound classification scheme based on radio frequency (RF) ultrasound signals. First, the RF patch is extracted from the original ultrasound image. The deep learning method then takes a 2D patch of the original RF signal and creates a sample. Next, concatenate the output vectors from the CNN global mean and max-pooling layers. Overall, the method involves three network architectures: the first applies global max-pooling to extract features, and the second consists of five blocks (2D convolution, max-pooling, average pooling, dense layers, and sigmoid activation), the third combines CNN-1D models with CNN-2D models. 
\subsection{Ultrasound video classification}
In clinical diagnosis, the time series in the ultrasound video has a positive effect on the diagnosis. Making good use of the time series in the video is the key to improving the accuracy of ultrasound classification. Bocchi~\emph{et al}.~\cite{bocchi2012semiautomated} proposed a breast ultrasound video classification algorithm that consists of five modules: preprocessing, semi-automatic segmentation, morphological feature extraction, and integration of each frame classification to obtain the final video classification result. The accuracy of the video algorithm is better than that of the single-frame ultrasound classification. However, the morphological features extracted from traditional methods only include shape, axial ratio, and echo features. Chen~\emph{et al}.~\cite{chen2021domain} proposed an ultrasound video classification method based on 3DCNN that combines clinical prior knowledge and ultrasound contrast technology. Because ultrasound contrast video can provide more detailed prior information, such as tumor blood supply, which extracts more comprehensive features. Compared to baseline methods~\cite{tran2015learning,tran2018closer,zhou2018temporal}, ~\cite{chen2021domain}can help classification models make more accurate diagnoses. However, contrast-enhanced ultrasonography is invasive detection, and an ultrasound contrast agent needs to be injected into the vein, and the price is also higher than B-mode ultrasound. B-mode ultrasound is safer and universal. In previous studies, time-series mining for B-mode ultrasound videos is insufficient. Therefore, this paper will explore and integrate ultrasound videos' spatial and temporal features based on the B-mode ultrasound videos collected clinically.

%引出自己的方法
In order to further improve classification accuracy. We designed spatiotemporal feature fusion diagnostic methods with support variable frame input for the dynamic ultrasound video classification problem. This paper uses CNN and LSTM to extract spatiotemporal features from dynamic ultrasound data to improve classification accuracy. Specially optimize the LSTM input structure and achieve the different video frames batch training. The combination of innovative methods allows the entire model to obtain higher classification accuracy on the dynamic ultrasound dataset.