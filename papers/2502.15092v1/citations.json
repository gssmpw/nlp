[
  {
    "index": 0,
    "papers": [
      {
        "key": "wan2023efficient",
        "author": "Wan, Zhongwei and Wang, Xin and Liu, Che and Alam, Samiul and Zheng, Yu and Liu, Jiachen and Qu, Zhongnan and Yan, Shen and Zhu, Yi and Zhang, Quanlu and others",
        "title": "Efficient large language models: A survey"
      },
      {
        "key": "zhu2023survey",
        "author": "Zhu, Xunyu and Li, Jian and Liu, Yong and Ma, Can and Wang, Weiping",
        "title": "A survey on model compression for large language models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "dettmers2022gpt3",
        "author": "Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke",
        "title": "Gpt3. int8 (): 8-bit matrix multiplication for transformers at scale"
      },
      {
        "key": "kimsqueezellm",
        "author": "Kim, Sehoon and Hooper, Coleman Richard Charles and Gholami, Amir and Dong, Zhen and Li, Xiuyu and Shen, Sheng and Mahoney, Michael W and Keutzer, Kurt",
        "title": "SqueezeLLM: Dense-and-Sparse Quantization"
      },
      {
        "key": "shen2024efficient",
        "author": "Shen, Haihao and Mellempudi, Naveen and He, Xin and Gao, Qun and Wang, Chang and Wang, Mengni",
        "title": "Efficient post-training quantization with fp8 formats"
      },
      {
        "key": "Lin2023AWQAW",
        "author": "Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Chen, Wei-Ming and Wang, Wei-Chen and Xiao, Guangxuan and Dang, Xingyu and Gan, Chuang and Han, Song",
        "title": "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "ma2023llm",
        "author": "Ma, Xinyin and Fang, Gongfan and Wang, Xinchao",
        "title": "Llm-pruner: On the structural pruning of large language models"
      },
      {
        "key": "ashkboos2024slicegpt",
        "author": "Ashkboos, Saleh and Croci, Maximilian L and Nascimento, Marcelo Gennari do and Hoefler, Torsten and Hensman, James",
        "title": "Slicegpt: Compress large language models by deleting rows and columns"
      },
      {
        "key": "zhong2024blockpruner",
        "author": "Zhong, Longguang and Wan, Fanqi and Chen, Ruijun and Quan, Xiaojun and Li, Liangzhi",
        "title": "BlockPruner: Fine-grained Pruning for Large Language Models"
      },
      {
        "key": "hsieh2023distilling",
        "author": "Hsieh, Cheng-Yu and Li, Chun-Liang and Yeh, Chih-Kuan and Nakhost, Hootan and Fujii, Yasuhisa and Ratner, Alexander and Krishna, Ranjay and Lee, Chen-Yu and Pfister, Tomas",
        "title": "Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zhong2024revisiting",
        "author": "Zhong, Qihuang and Ding, Liang and Shen, Li and Liu, Juhua and Du, Bo and Tao, Dacheng",
        "title": "Revisiting knowledge distillation for autoregressive language models"
      },
      {
        "key": "muralidharan2024compact",
        "author": "Muralidharan, Saurav and Sreenivas, Sharath Turuvekere and Joshi, Raviraj Bhuminand and Chochowski, Marcin and Patwary, Mostofa and Shoeybi, Mohammad and Catanzaro, Bryan and Kautz, Jan and Molchanov, Pavlo",
        "title": "Compact language models via pruning and knowledge distillation"
      },
      {
        "key": "hsieh2023distilling",
        "author": "Hsieh, Cheng-Yu and Li, Chun-Liang and Yeh, Chih-Kuan and Nakhost, Hootan and Fujii, Yasuhisa and Ratner, Alexander and Krishna, Ranjay and Lee, Chen-Yu and Pfister, Tomas",
        "title": "Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "Hsu2022FWSVD",
        "author": "Yen-Chang Hsu and Ting Hua and Sung-En Chang and Qiang Lou and Yilin Shen and Hongxia Jin",
        "title": "Language model compression with weighted low-rank factorization"
      },
      {
        "key": "yuan2023asvd",
        "author": "Yuan, Zhihang and Shang, Yuzhang and Song, Yue and Wu, Qiang and Yan, Yan and Sun, Guangyu",
        "title": "Asvd: Activation-aware singular value decomposition for compressing large language models"
      },
      {
        "key": "wang2024svd",
        "author": "Wang, Xin and Zheng, Yu and Wan, Zhongwei and Zhang, Mi",
        "title": "Svd-llm: Truncation-aware singular value decomposition for large language model compression"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "li2023losparse",
        "author": "Li, Yixiao and Yu, Yifan and Zhang, Qingru and Liang, Chen and He, Pengcheng and Chen, Weizhu and Zhao, Tuo",
        "title": "Losparse: Structured compression of large language models based on low-rank and sparse approximation"
      },
      {
        "key": "noach2020compressing",
        "author": "Noach, Matan Ben and Goldberg, Yoav",
        "title": "Compressing pre-trained language models by matrix decomposition"
      },
      {
        "key": "chen2023ternary",
        "author": "Chen, Boyu and Chen, Hanxuan and He, Jiao and Sun, Fengyu and Jui, Shangling",
        "title": "Ternary Singular Value Decomposition as a Better Parameterized Form in Linear Mapping"
      },
      {
        "key": "Hsu2022FWSVD",
        "author": "Yen-Chang Hsu and Ting Hua and Sung-En Chang and Qiang Lou and Yilin Shen and Hongxia Jin",
        "title": "Language model compression with weighted low-rank factorization"
      },
      {
        "key": "yuan2023asvd",
        "author": "Yuan, Zhihang and Shang, Yuzhang and Song, Yue and Wu, Qiang and Yan, Yan and Sun, Guangyu",
        "title": "Asvd: Activation-aware singular value decomposition for compressing large language models"
      },
      {
        "key": "wang2024svd",
        "author": "Wang, Xin and Zheng, Yu and Wan, Zhongwei and Zhang, Mi",
        "title": "Svd-llm: Truncation-aware singular value decomposition for large language model compression"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "stewart1993early",
        "author": "Stewart, Gilbert W",
        "title": "On the early history of the singular value decomposition"
      },
      {
        "key": "wall2003singular",
        "author": "Wall, Michael E and Rechtsteiner, Andreas and Rocha, Luis M",
        "title": "Singular value decomposition and principal component analysis"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "stewart1993early",
        "author": "Stewart, Gilbert W",
        "title": "On the early history of the singular value decomposition"
      },
      {
        "key": "wall2003singular",
        "author": "Wall, Michael E and Rechtsteiner, Andreas and Rocha, Luis M",
        "title": "Singular value decomposition and principal component analysis"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "Hsu2022FWSVD",
        "author": "Yen-Chang Hsu and Ting Hua and Sung-En Chang and Qiang Lou and Yilin Shen and Hongxia Jin",
        "title": "Language model compression with weighted low-rank factorization"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "yuan2023asvd",
        "author": "Yuan, Zhihang and Shang, Yuzhang and Song, Yue and Wu, Qiang and Yan, Yan and Sun, Guangyu",
        "title": "Asvd: Activation-aware singular value decomposition for compressing large language models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "wang2024svd",
        "author": "Wang, Xin and Zheng, Yu and Wan, Zhongwei and Zhang, Mi",
        "title": "Svd-llm: Truncation-aware singular value decomposition for large language model compression"
      }
    ]
  }
]