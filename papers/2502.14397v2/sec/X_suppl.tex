\clearpage
\setcounter{page}{1}
\maketitlesupplementary


\section{Experimental Details in Different Bench}
\label{sec:rationale}

On each benchmark, the similarity scores are computed between a reference image and two candidate images, one of which is closer to the reference image. Image pair with the higher score is selected as the choice of current evaluated model. In this section, we will explain details of reference and candidate images selection for each benchmark.

\subsection{NIGHTS Dataset}
NIGHTS (Novel Image Generations with Human-Tested Similarities) is a dataset comprising 20,019 image triplets with human scores of perceptual similarity. Each triplet consists of a reference image and two distortions. This paper utilizes the test set of NIGHTS, which includes 2,120 image triplets. We calculate the DiffSim score for the reference image and the two distortions separately, using human evaluation results as the ground truth.

\subsection{Dreambench++ Dataset}

The Dreambench++ Dataset consists of generated images created using different generation methods, along with human-rated scores for how similar each image is to the original. In our experiment, we use the original image as the reference and randomly select two generated images based on it. The one with the higher human rating is considered closer to the reference. The dataset includes a total of 937 triplets.

\subsection{CUTE Dataset}

The CUTE Dataset includes photos of various instances taken under different lighting and positional conditions. In our experiment, for each category, we repeat the process 10 times: randomly selecting two images of the same instance under the same lighting and one image of a different instance under the same lighting. The two images of the same instance are considered more similar. The dataset contains a total of 1,800 triplets for comparison.

\subsection{IP Bench}

IP Bench contains 299 character classes, each with an original image and six variations generated using different consistency weights. In our experiment, we repeat the process for 5 times: using the original image as the reference and randomly selecting two generated images from the same class. The image with the higher consistency weight is considered closer to the reference. There are a total of 1,495 triplets for comparisons.

\subsection{TID2013 Dataset}

The TID2013 dataset contains 25 reference images, each distorted using 24 types of distortions at 5 different levels. In our experiment, we use a reference image as the starting point and randomly select two distorted images using the same type of distortions from the same reference. The image with a lower distortion level is considered closer to the reference. There are a total of 600 triplets for evaluation.

\subsection{Sref Dataset}

The Sref bench includes 508 styles manually selected by artists and generated by Midjounery, with each style featuring four images. When constructing image triplets, we randomly select two images from the same style and one image from a different style. We fix the random seed to construct 2,000 image triplets for quantitative evaluation.

\subsection{InstantStyle Bench}
The InstantStyle bench includes 30 styles, with each style comprising five images. When constructing image triplets, we randomly select two images from the same style and one image from a different style. We fix the random seed to construct 2,000 image triplets for quantitative evaluation.


\subsection{TikTok Dataset}

For tiktok dataset, we extract 10 frames from each video, and calculate the variance of different similarity metric scores between the first frame and other frame. A lower variance indicates that the metric demonstrates better robustness to changes in the movements of characters in the video.

\begin{table*}[ht]
\centering
\caption{Performance of diffsim across various benchmarks with different pre-trained models. Best results are highlighted in bold.}
\label{tab:5}
\small 
\begin{tabular}{@{}c|cc|cc|c|cc@{}}
\toprule
\textbf{Model / Benchmark} & \multicolumn{2}{c|}{\textbf{Human-align Similarity}} & \multicolumn{2}{c|}{\textbf{Instance Similarity}} & \multicolumn{1}{c|}{\textbf{Low-level Similarity}} & \multicolumn{2}{c}{\textbf{Style Similarity}} \\ 
 & \textbf{NIGHTS} & \textbf{Dreambench++} & \textbf{CUTE} & \textbf{IP} & \textbf{TID2013} & \textbf{Sref}  & \textbf{InstantStyle bench} \\ \midrule
DiffSim-S SD1.5                     & \textbf{86.52\%} & \textbf{71.50}\% & 72.06\% & \textbf{92.04\%} & \textbf{94.17\%} & \textbf{97.40\%} & \textbf{99.05\%} \\
DiffSim-C SD1.5                      & 79.16\% & 67.45\% & \textbf{76.17}\% & 77.06\% & 94.00\% & 94.70\% & 95.10\% \\
DiffSim-S SD-XL                      & 78.05\% & 63.93\% & 69.94\% & 83.41\% & 91.33\% & 93.05\% & 96.55\% \\
DiffSim DIT-XL/2 256                 & 63.38\% & 57.52\% & 53.44\% & 82.81\% & 83.50\% & 77.00\% & 80.15\% \\
DiffSim DIT-XL/2 512                 & 67.92\% & 57.31\% & 57.22\% & 81.00\% & 88.67\% & 78.20\% & 79.40\% \\
\bottomrule
\end{tabular}
\end{table*}


\section{Exploring Different Model Architectures}

In Table ~\ref{tab:5}, we present the performance differences of DiffSim using pre-trained models with different architectures. DiffSim-S SD1.5 leads in all benchmarks except for the CUTE dataset. DiffSim-C SD1.5 performs better on the CUTE dataset, possibly because the cross-attention layers in the U-Net architecture are particularly effective at distinguishing the subject. On the other hand, DiffSim-C uses IP-Adapter Plus, and the CLIP image encoder may become a performance bottleneck in other benchmarks. Models with higher resolution, such as SD-XL and DIT-XL/2 512, do not show performance improvement compared to lower resolution models like SD1.5 and DIT-XL/2 256. Furthermore, the performance of models using DIT as the pre-trained model is worse than using U-Net, with two possible reasons: 1. DIT splits the image into patches and then serializes them, which may lead to the loss of spatial information, which is detrimental to DiffSim, despite the use of positional encoding. 2. DIT is trained on the ImageNet dataset, which is much smaller than the SD1.5 and SD-XL models' training datasets.

\section{Additional Experimental Results}
In Figures \ref{nightsbench} to \ref{instantstylebench} , we present the default implementation of DiffSim, which is based on the self-attention layers of SD1.5, showing results across different layers and denoising time steps t.
% 更多实验结果
% 图7-图12，我们展示DiffSim的默认实现，即基于 SD1.5的self attention层中的实现， 不同层和去噪时间步t的结果。
% Additional Experimental Results
% In Figures 7 to 12, we present the default implementation of DiffSim, which is based on the self-attention layers of SD1.5, showing results across different layers and denoising time steps t.




\section{Additional Visual Examples}
Figure ~\ref{supp:bench} and ~\ref{supp:IP} show more examples of images from Sref bench and IP bench; Figure ~\ref{supp:retrieval} presents more top-4 retrieval results of DiffSim, CLIP, DINO v2 on MS COCO, Sref bench and IP bench.

\begin{figure}[htp]
    \centering
    \includegraphics[width=1.0\linewidth]{sec/Image/NIGHTS_Dataset_Performance.pdf}
    \caption{Results on NIGHTS dataset.}
    \label{nightsbench}
\end{figure}

\begin{figure}[htp]
    \centering
    \includegraphics[width=1.0\linewidth]{sec/Image/Dreambench_Dataset_Performance.pdf}
    \caption{Results on Dreambench++ dataset.}
    \label{bench}
\end{figure}

\begin{figure}[htp]
    \centering
    \includegraphics[width=1.0\linewidth]{sec/Image/CUTE_Dataset_Performance.pdf}
    \caption{Results on CUTE dataset.}
    \label{bench}
\end{figure}

\begin{figure}[htp]
    \centering
    \includegraphics[width=1.0\linewidth]{sec/Image/IP_Bench_Performance.pdf}
    \caption{Results on IP bench.}
    \label{bench}
\end{figure}

\begin{figure}[htp]
    \centering
    \includegraphics[width=1.0\linewidth]{sec/Image/TID2013_Performance.pdf}
    \caption{Results on TID2013 dataset.}
    \label{bench}
\end{figure}

\begin{figure}[htp]
    \centering
    \includegraphics[width=1.0\linewidth]{sec/Image/Sref_Bench_Performance.pdf}
    \caption{Results on Sref bench.}
    \label{bench}
\end{figure}

\begin{figure}[htp]
    \centering
    \includegraphics[width=1.0\linewidth]{sec/Image/InstantStyle_Bench_Performance.pdf}
    \caption{Results on InstantStyle bench.}
    \label{instantstylebench}
\end{figure}

% \begin{table}[ht]
% \centering
% \caption{Performance of Different Time Step and Layer on NIGHTS Dataset. Best results are highlighted in bold.}
% \label{tab:performance}
% \setlength{\tabcolsep}{3pt}
% \footnotesize 
% \begin{tabular}{@{}c|ccccccc@{}}
% \toprule
% \textbf{Time Step} & \textbf{\( D_0 \)} & \textbf{\( D_1 \)} & \textbf{\( D_2 \)} & \textbf{\( M \)} & \textbf{\( U_0 \)} & \textbf{\( U_1 \)} & \textbf{\( U_2 \)} \\ \midrule
% 100                &     64.10\%            &     66.23\%            &     66.23\%            &     65.42\%          &     62.50\%            &     64.39\%            &     63.82\%            \\
% 200                &     71.98\%            &     73.87\%            &     75.33\%            &     76.81\%          &     71.27\%            &     72.41\%            &     70.90\%            \\
% 300                &     77.03\%            &     78.82\%            &     81.04\%            &     82.84\%          &     79.72\%            &     79.62\%            &     77.55\%            \\
% 400                &     79.01\%            &     79.91\%            &     83.63\%            &     84.93\%          &     83.73\%            &     83.92\%            &     81.60\%            \\
% 500                &     79.72\%            &     81.51\%            &     85.75\%            &     \textbf{86.52}\%          &     84.86\%            &     84.06\%            &     81.75\%            \\ 
% 600                &     80.38\%            &     82.45\%            &     85.90\%            &     86.21\%          &     84.06\%            &     82.97\%            &     80.85\%            \\
% 700                &     80.66\%            &     81.89\%            &     85.24\%            &     84.93\%          &     83.11\%            &     82.50\%            &     79.95\%            \\
% 800                &     80.24\%            &     81.32\%            &     84.95\%            &     84.42\%          &     82.69\%            &     81.60\%            &     79.48\%            \\ 
% 900                &     79.72\%            &     80.90\%            &     84.95\%            &     84.63\%          &     81.79\%            &     80.80\%            &     78.68\%            \\
% \bottomrule
% \end{tabular}
% \end{table}


% \begin{table}[ht]
% \centering
% \caption{Performance of Different Time Step and Layer on Dreambench++ Dataset. Best results are highlighted in bold.}
% \label{tab:performance}
% \setlength{\tabcolsep}{3pt}
% \footnotesize  
% \begin{tabular}{@{}c|ccccccc@{}}
% \toprule
% \textbf{Time Step} & \textbf{\( D_0 \)} & \textbf{\( D_1 \)} & \textbf{\( D_2 \)} & \textbf{\( M \)} & \textbf{\( U_0 \)} & \textbf{\( U_1 \)} & \textbf{\( U_2 \)} \\ \midrule
% 100 &60.09\% &62.65\% &59.34\% &58.38\% &60.30\% &62.22\% &58.16\% \\
% 200 &58.16\% &61.69\% &64.78\% &64.99\% &62.01\% &64.46\% &64.89\% \\
% 300 &64.89\% &63.29\% &64.67\% &64.57\% &64.46\% &65.31\% &65.96\% \\
% 400 &65.96\% &67.77\% &62.43\% &64.35\% &66.06\% &67.13\% &65.74\% \\
% 500 &65.74\% &67.77\% &66.49\% &63.07\% &63.93\% &67.66\% &68.30\% \\
% 600 &68.30\% &67.34\% &69.37\% &67.24\% &62.54\% &64.57\% &68.62\% \\
% 700 &68.62\% &69.26\% &67.24\% &68.84\% &66.38\% &63.93\% &64.46\% \\
% 800 &64.46\% &68.73\% &\textbf{71.50\%} &67.56\% &69.69\% &66.81\% &63.71\% \\
% 900 &63.71\% &63.82\% &68.84\% &70.01\% &68.09\% &70.44\% &64.99\% \\
% \bottomrule
% \end{tabular}
% \end{table}



% \begin{table}[ht]
% \centering
% \caption{Performance of Different Time Step and Layer on CUTE Dataset. Best results are highlighted in bold.}
% \label{tab:performance}
% \setlength{\tabcolsep}{3pt}
% \footnotesize 
% \begin{tabular}{@{}c|ccccccc@{}}
% \toprule
% \textbf{Time Step} & \textbf{\( D_0 \)} & \textbf{\( D_1 \)} & \textbf{\( D_2 \)} & \textbf{\( M \)} & \textbf{\( U_0 \)} & \textbf{\( U_1 \)} & \textbf{\( U_2 \)} \\ \midrule
% 100 &48.39\% &52.67\% &52.11\% &51.89\% &49.89\% &50.33\% &49.39\% \\
% 200 &49.39\% &53.00\% &52.78\% &53.44\% &51.33\% &50.28\% &50.78\% \\
% 300 &50.78\% &50.33\% &54.50\% &57.28\% &57.83\% &54.17\% &52.17\% \\
% 400 &52.17\% &54.67\% &53.94\% &59.17\% &61.00\% &61.83\% &58.67\% \\
% 500 &58.67\% &60.50\% &60.50\% &59.17\% &60.50\% &63.00\% &64.17\% \\
% 600 &64.17\% &62.17\% &63.39\% &61.83\% &60.50\% &63.22\% &64.94\% \\
% 700 &64.94\% &66.83\% &64.39\% &63.67\% &64.56\% &62.28\% &65.72\% \\
% 800 &65.72\% &66.61\% &69.28\% &65.33\% &66.17\% &66.06\% &65.06\% \\
% 900 &65.06\% &68.11\% &67.00\% &70.94\% &\textbf{72.06\%} &68.06\% &68.11\% \\
% \bottomrule
% \end{tabular}
% \end{table}



% \begin{table}[ht]
% \centering
% \caption{Performance of Different Time Step and Layer on IP Bench. Best results are highlighted in bold.}
% \label{tab:performance}
% \setlength{\tabcolsep}{3pt}
% \footnotesize 
% \begin{tabular}{@{}c|ccccccc@{}}
% \toprule
% \textbf{Time Step} & \textbf{\( D_0 \)} & \textbf{\( D_1 \)} & \textbf{\( D_2 \)} & \textbf{\( M \)} & \textbf{\( U_0 \)} & \textbf{\( U_1 \)} & \textbf{\( U_2 \)} \\ \midrule
% 100 &76.52\% &78.39\% &78.33\% &71.64\% &66.96\% &69.90\% &63.01\% \\
% 200 &63.01\% &77.46\% &82.74\% &82.54\% &79.06\% &71.10\% &73.11\% \\
% 300 &73.11\% &69.77\% &81.34\% &82.21\% &85.08\% &81.67\% &78.66\% \\
% 400 &78.66\% &78.39\% &78.33\% &84.82\% &82.61\% &85.89\% &83.95\% \\
% 500 &83.95\% &86.42\% &85.55\% &84.21\% &85.62\% &83.68\% &86.96\% \\
% 600 &86.96\% &85.48\% &89.97\% &88.16\% &85.75\% &86.22\% &83.95\% \\
% 700 &83.95\% &90.03\% &87.22\% &91.37\% &89.83\% &87.76\% &86.29\% \\
% 800 &86.29\% &85.22\% &91.24\% &88.90\% &\textbf{91.84\%} &90.43\% &88.63\% \\
% 900 &88.63\% &85.95\% &85.08\% &91.71\% &89.63\% &91.24\% &90.37\% \\
% \bottomrule
% \end{tabular}
% \end{table}


% \begin{table}[ht]
% \centering
% \caption{Performance of Different Time Step and Layer on TID2013 Dataset. Best results are highlighted in bold.}
% \label{tab:performance}
% \setlength{\tabcolsep}{3pt}
% \footnotesize 
% \begin{tabular}{@{}c|ccccccc@{}}
% \toprule
% \textbf{Time Step} & \textbf{\( D_0 \)} & \textbf{\( D_1 \)} & \textbf{\( D_2 \)} & \textbf{\( M \)} & \textbf{\( U_0 \)} & \textbf{\( U_1 \)} & \textbf{\( U_2 \)} \\ \midrule
% 100 &77.50\% &79.67\% &79.67\% &78.33\% &77.33\% &79.17\% &77.33\% \\
% 200 &77.33\% &82.33\% &82.83\% &82.83\% &79.83\% &78.17\% &82.00\% \\
% 300 &82.00\% &81.17\% &83.33\% &83.67\% &85.67\% &80.33\% &75.33\% \\
% 400 &75.33\% &80.67\% &82.33\% &84.83\% &85.83\% &84.67\% &77.50\% \\
% 500 &77.50\% &74.83\% &80.00\% &83.50\% &86.83\% &84.67\% &86.33\% \\
% 600 &86.33\% &78.67\% &80.17\% &83.67\% &85.50\% &89.67\% &87.67\% \\
% 700 &87.67\% &88.33\% &84.33\% &87.50\% &90.50\% &88.33\% &91.67\% \\
% 800 &91.67\% &91.50\% &91.33\% &87.83\% &91.50\% &91.17\% &90.83\% \\
% 900 &90.83\% &\textbf{95.00\%} &93.00\% &94.33\% &91.83\% &93.83\% &94.33\% \\
% \bottomrule
% \end{tabular}
% \end{table}



% \begin{table}[ht]
% \centering
% \caption{Performance of Different Time Step and Layer on Sref Bench. Best results are highlighted in bold.}
% \label{tab:performance}
% \setlength{\tabcolsep}{3pt}
% \footnotesize 
% \begin{tabular}{@{}c|ccccccc@{}}
% \toprule
% \textbf{Time Step} & \textbf{\( D_0 \)} & \textbf{\( D_1 \)} & \textbf{\( D_2 \)} & \textbf{\( M \)} & \textbf{\( U_0 \)} & \textbf{\( U_1 \)} & \textbf{\( U_2 \)} \\ \midrule
% 100                &     88.65\%            &     85.90\%            &     87.10\%            &     81.90\%       &     80.30\%            &     85.30\%            &     70.75\%            \\
% 200                &     89.30\%            &     85.35\%            &     88.30\%            &     83.60\%       &     82.15\%            &     88.25\%            &     87.35\%            \\
% 300                &     91.35\%            &     87.10\%            &     90.20\%            &     83.20\%       &     84.30\%            &     90.15\%            &     90.50\%            \\
% 400                &     92.05\%            &     88.25\%            &     91.70\%            &     82.70\%       &     86.85\%            &     93.25\%            &     92.20\%            \\
% 500                &     93.35\%            &     89.50\%            &     91.70\%            &     81.60\%       &     88.95\%            &     95.15\%            &     94.05\%            \\ 
% 600                &     94.45\%            &     90.30\%            &     91.45\%            &     80.80\%       &     90.25\%            &     96.10\%            &     94.80\%            \\
% 700                &     95.00\%            &     90.80\%            &     91.30\%            &     80.70\%       &     92.10\%            &     97.00\%            &     95.60\%            \\
% 800                &     94.90\%            &     91.75\%            &     92.00\%            &     81.05\%       &     92.60\%            &     97.15\%            &     95.90\%            \\ 
% 900                &     95.20\%            &     92.70\%            &     92.70\%            &     82.40\%       &     93.85\%            &     \textbf{97.40}\%            &     96.30\%            \\
% \bottomrule
% \end{tabular}
% \end{table}



% \begin{table}[ht]
% \centering
% \caption{Performance of Different Time Step and Layer on InstantStyle Bench. Best results are highlighted in bold.}
% \label{tab:performance}
% \setlength{\tabcolsep}{3pt}
% \footnotesize 
% \begin{tabular}{@{}c|ccccccc@{}}
% \toprule
% \textbf{Time Step} & \textbf{\( D_0 \)} & \textbf{\( D_1 \)} & \textbf{\( D_2 \)} & \textbf{\( M \)} & \textbf{\( U_0 \)} & \textbf{\( U_1 \)} & \textbf{\( U_2 \)} \\ \midrule
% 100                &     94.50\%            &     89.45\%            &     89.80\%            &     81.90\%          &     76.45\%            &     84.40\%            &     84.75\%            \\
% 200                &     95.40\%            &     90.50\%            &     90.10\%            &     80.95\%          &     82.15\%            &     87.95\%            &     89.15\%            \\
% 300                &     96.65\%            &     90.90\%            &     92.90\%            &     85.45\%          &     87.85\%            &     92.80\%            &     94.35\%            \\
% 400                &     97.60\%            &     93.10\%            &     94.45\%            &     85.60\%          &     89.80\%            &     95.90\%            &     96.10\%            \\
% 500                &     98.00\%            &     94.20\%            &     95.00\%            &     85.35\%          &     91.90\%            &     97.70\%            &     97.55\%            \\ 
% 600                &     98.45\%            &     95.65\%            &     95.20\%            &     84.20\%          &     93.85\%            &     98.35\%            &     98.20\%            \\
% 700                &     98.50\%            &     95.90\%            &     95.05\%            &     84.00\%          &     94.60\%            &     98.55\%            &     98.00\%            \\
% 800                &     98.95\%            &     95.55\%            &     95.60\%            &     85.90\%          &     96.20\%            &     98.85\%            &     98.20\%            \\ 
% 900                &     \textbf{99.05}\%            &     97.15\%            &     96.40\%            &     87.50\%          &     96.55\%            &     98.95\%            &     98.30\%            \\
% \bottomrule
% \end{tabular}
% \end{table}


% \begin{table*}[ht]
% \centering
% \caption{Performance of different DiffSim across various benchmarks. Best results are highlighted in bold.}
% \label{tab:performance}
% \small 
% \begin{tabular}{@{}c|cc|cc|c|cc@{}}
% \toprule
% \textbf{Model / Benchmark} & \multicolumn{2}{c|}{\textbf{Human-align Similarity}} & \multicolumn{2}{c|}{\textbf{Instance Similarity}} & \multicolumn{1}{c|}{\textbf{Low-level Similarity}} & \multicolumn{2}{c}{\textbf{Style Similarity}} \\ 
%  & \textbf{NIGHTS} & \textbf{Dreambench++} & \textbf{CUTE} & \textbf{IP} & \textbf{TID2013} & \textbf{Sref}  & \textbf{InstantStyle bench} \\ \midrule
% DiffSim-S SD1.5                     & 71.13\%           & 62.33\%                  & 63.17\%          & 84.01\%          & 94.50\%           & 87.85\%                           & 93.15\%  \\
% DiffSim-C SD1.5                      & -           & -                  & -          & -          & -           & 84.05\%                          & 88.30\%  \\
% DiffSim-S SD-XL                      & 82.26\%           & 70.54\%                  & 72.71\%          & \textcolor{blue}{91.70\%}          & 90.33\%           & 84.60\%                           & 82.90\%  \\
% \bottomrule
% \end{tabular}
% \end{table*}



\begin{figure*}[htp]
    \centering
    \includegraphics[width=0.89\linewidth]{sec/Image/Sref1.jpg}
    \caption{Examples in Sref bench we proposed.}
    \label{supp:bench}
\end{figure*}

\begin{figure*}[htp]
    \centering
    \includegraphics[width=0.89\linewidth]{sec/Image/IPref.pdf}
    \caption{Examples in IP bench we proposed.}
    \label{supp:IP}
\end{figure*}

\begin{figure*}[htp]
    \centering
    \includegraphics[width=0.99\linewidth]{sec/Image/Supp-ImageRetrieval.pdf}
    \caption{More image retrieval results.}
    \label{supp:retrieval}
\end{figure*}

