@inproceedings{10.1145/3664647.3681431,
author = {Wang, Yuntao and Zhang, Jinpu and Wei, Ruonan and Gao, Wenbo and Wang, Yuehuan},
title = {MFRGN: Multi-scale Feature Representation Generalization Network for Ground-to-Aerial Geo-localization},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681431},
doi = {10.1145/3664647.3681431},
abstract = {Cross-area evaluation poses a significant challenge for ground-to-aerial geo-localization, in which the training and testing data are captured from entirely distinct areas. However, current methods struggle in cross-area evaluation due to their emphasis solely on learning global information from single-scale features. Some efforts alleviate this problem but rely on complex and specific technologies like pre-processing and hard sample mining. To this end, we propose a pure end-to-end solution, free from task-specific techniques, termed the Multi-scale Feature Representation Generalization Network (MFRGN) to improve generalization. Specifically, we introduce multi-scale features and explicitly utilize them by an novel global-local information representation structure with two flows, to bolster feature representations. In the global flow, we present a lightweight Self and Cross Attention Module (SCAM) to efficiently learn global embeddings. In the local flow, we develop a Global-Prompt Attention Block (GPAB) to capture discriminative features under the global embeddings as prompts. As a result, our approach generates robust descriptors representing multi-scale global and local information, thereby enhancing the model's invariance to scene variations. Extensive experiments on benchmarks show our MFRGN achieves competitive performance in same-area evaluation and improves cross-area generalization by a significant margin compared to SOTA methods. Our code is available at https://github.com/ytao-wang/MFRGN.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2574–2583},
numpages = {10},
keywords = {cross-view image geo-localization, feature representation, image matching, image retrieval},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@INPROCEEDINGS{10167940,
  author={Bonaventura, Tania Sari and Maiano, Luca and Papa, Lorenzo and Amerini, Irene},
  booktitle={2023 24th International Conference on Digital Signal Processing (DSP)}, 
  title={An Automated Ground-to-Aerial Viewpoint Localization for Content Verification}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  keywords={Location awareness;Learning systems;Satellites;Forensics;Pipelines;Digital signal processing;Media},
  doi={10.1109/DSP58604.2023.10167940}}

@ARTICLE{9170787,
  author={Verde, Sebastiano and Resek, Thiago and Milani, Simone and Rocha, Anderson},
  journal={IEEE Signal Processing Letters}, 
  title={Ground-to-Aerial Viewpoint Localization via Landmark Graphs Matching}, 
  year={2020},
  volume={27},
  number={},
  pages={1490-1494},
  keywords={Satellites;Image matching;Buildings;Task analysis;Roads;Mathematical model;Symmetric matrices;Cross-view;ground-to-aerial;matching;landmark graphs;localization;viewpoint},
  doi={10.1109/LSP.2020.3017380}}

@misc{Jacob,
author = {Workman, Scott and Jacobs, Nathan},
year = {2015},
month = {06},
pages = {70-78},
title = {On the location dependence of convolutional neural network features},
doi = {10.1109/CVPRW.2015.7301385}
}

@misc{deng2019,
title={Using Conditional Generative Adversarial Networks to Generate Ground-Level Views From Overhead Imagery}, 
author={Xueqing Deng and Yi Zhu and Shawn Newsam},
year={2019},
eprint={1902.06923},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/1902.06923}, 
}

@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@misc{goodfellow2014generativeadversarialnetworks,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1406.2661}, 
}

@misc{manual1,
author = {Bansal, Mayank and Sawhney, Harpreet and Cheng, Hui and Daniilidis, Kostas},
year = {2011},
month = {11},
pages = {1125-1128},
title = {Geo-localization of street views with aerial image databases},
doi = {10.1145/2072298.2071954}
}

@misc{manual2,
title = "A framework for global vehicle localization using stereo images and satellite and road maps",
author = "Turgay Senlet and Ahmed Elgammal",
year = "2011",
doi = "10.1109/ICCVW.2011.6130498",
language = "English (US)",
isbn = "9781467300629",
series = "Proceedings of the IEEE International Conference on Computer Vision",
pages = "2034--2041",
booktitle = "2011 IEEE International Conference on Computer Vision Workshops, ICCV Workshops 2011",
note = "2011 IEEE International Conference on Computer Vision Workshops, ICCV Workshops 2011 ; Conference date: 06-11-2011 Through 13-11-2011",
}

@misc{pro2024,
title={A Semantic Segmentation-guided Approach for Ground-to-Aerial Image Matching}, 
author={Francesco Pro and Nikolaos Dionelis and Luca Maiano and Bertrand Le Saux and Irene Amerini},
year={2024},
eprint={2404.11302},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2404.11302}, 
}

@misc{regmi2018,
title={Cross-View Image Synthesis using Conditional GANs}, 
author={Krishna Regmi and Ali Borji},
year={2018},
eprint={1803.03396},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/1803.03396}, 
}

@Article{s24123719,
AUTHOR = {Fan, Jiqi and Zheng, Enhui and He, Yufei and Yang, Jianxing},
TITLE = {A Cross-View Geo-Localization Algorithm Using UAV Image and Satellite Image},
JOURNAL = {Sensors},
VOLUME = {24},
YEAR = {2024},
NUMBER = {12},
ARTICLE-NUMBER = {3719},
URL = {https://www.mdpi.com/1424-8220/24/12/3719},
PubMedID = {38931506},
ISSN = {1424-8220},
ABSTRACT = {Within research on the cross-view geolocation of UAVs, differences in image sources and interference from similar scenes pose huge challenges. Inspired by multimodal machine learning, in this paper, we design a single-stream pyramid transformer network (SSPT). The backbone of the model uses the self-attention mechanism to enrich its own internal features in the early stage and uses the cross-attention mechanism in the later stage to refine and interact with different features to eliminate irrelevant interference. In addition, in the post-processing part of the model, a header module is designed for upsampling to generate heat maps, and a Gaussian weight window is designed to assign label weights to make the model converge better. Together, these methods improve the positioning accuracy of UAV images in satellite images. Finally, we also use style transfer technology to simulate various environmental changes in order to expand the experimental data, further proving the environmental adaptability and robustness of the method. The final experimental results show that our method yields significant performance improvement: The relative distance score (RDS) of the SSPT-384 model on the benchmark UL14 dataset is significantly improved from 76.25% to 84.40%, while the meter-level accuracy (MA) of 3 m, 5 m, and 20 m is increased by 12%, 12%, and 10%, respectively. For the SSPT-256 model, the RDS has been increased to 82.21%, and the meter-level accuracy (MA) of 3 m, 5 m, and 20 m has increased by 5%, 5%, and 7%, respectively. It still shows strong robustness on the extended thermal infrared (TIR), nighttime, and rainy day datasets.},
DOI = {10.3390/s24123719}
}

@misc{shi2019optimalfeaturetransportcrossview,
title={Optimal Feature Transport for Cross-View Image Geo-Localization}, 
author={Yujiao Shi and Xin Yu and Liu Liu and Tong Zhang and Hongdong Li},
year={2019},
eprint={1907.05021},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/1907.05021}, 
}

@misc{shi2020ilookingatjoint,
title={Where am I looking at? Joint Location and Orientation Estimation by Cross-View Matching}, 
author={Yujiao Shi and Xin Yu and Dylan Campbell and Hongdong Li},
year={2020},
eprint={2005.03860},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2005.03860}, 
}

@misc{toker2021,
title={Coming Down to Earth: Satellite-to-Street View Synthesis for Geo-Localization}, 
author={Aysim Toker and Qunjie Zhou and Maxim Maximov and Laura Leal-Taixé},
year={2021},
eprint={2103.06818},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2103.06818}, 
}

@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@misc{yang2021,
author = {Yang, Hongji and Lu, Xiufan and Zhu, Yingying},
year = {2021},
month = {07},
pages = {},
title = {Cross-view Geo-localization with Evolving Transformer},
doi = {10.48550/arXiv.2107.00842}
}

@misc{zhang2022,
title={Cross-View Image Sequence Geo-localization}, 
author={Xiaohan Zhang and Waqas Sultani and Safwan Wshah},
year={2022},
eprint={2210.14295},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2210.14295}, 
}

@misc{zhu2022,
title={TransGeo: Transformer Is All You Need for Cross-view Image Geo-localization}, 
author={Sijie Zhu and Mubarak Shah and Chen Chen},
year={2022},
eprint={2204.00097},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2204.00097}, 
}

