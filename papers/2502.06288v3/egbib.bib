@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@misc{pro2024,
title={A Semantic Segmentation-guided Approach for Ground-to-Aerial Image Matching}, 
author={Francesco Pro and Nikolaos Dionelis and Luca Maiano and Bertrand Le Saux and Irene Amerini},
year={2024},
eprint={2404.11302},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2404.11302}, 
}

@misc{Sample4Geo,
author = {Deuser, Fabian and Habel, Konrad and Oswald, Norbert},
year = {2023},
month = {10},
pages = {16801-16810},
title = {Sample4Geo: Hard Negative Sampling For Cross-View Geo-Localisation},
doi = {10.1109/ICCV51070.2023.01545}
}

@misc{symmetry,
title={Learning Transferable Visual Models From Natural Language Supervision}, 
author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
year={2021},
eprint={2103.00020},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2103.00020}, 
}

@misc{manual1,
author = {Bansal, Mayank and Sawhney, Harpreet and Cheng, Hui and Daniilidis, Kostas},
year = {2011},
month = {11},
pages = {1125-1128},
title = {Geo-localization of street views with aerial image databases},
doi = {10.1145/2072298.2071954}
}

@misc{manual2,
title = "A framework for global vehicle localization using stereo images and satellite and road maps",
author = "Turgay Senlet and Ahmed Elgammal",
year = "2011",
doi = "10.1109/ICCVW.2011.6130498",
language = "English (US)",
isbn = "9781467300629",
series = "Proceedings of the IEEE International Conference on Computer Vision",
pages = "2034--2041",
booktitle = "2011 IEEE International Conference on Computer Vision Workshops, ICCV Workshops 2011",
note = "2011 IEEE International Conference on Computer Vision Workshops, ICCV Workshops 2011 ; Conference date: 06-11-2011 Through 13-11-2011",
}

@misc{Jacob,
author = {Workman, Scott and Jacobs, Nathan},
year = {2015},
month = {06},
pages = {70-78},
title = {On the location dependence of convolutional neural network features},
doi = {10.1109/CVPRW.2015.7301385}
}

@misc{regmi2018,
title={Cross-View Image Synthesis using Conditional GANs}, 
author={Krishna Regmi and Ali Borji},
year={2018},
eprint={1803.03396},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/1803.03396}, 
}

@misc{deng2019,
title={Using Conditional Generative Adversarial Networks to Generate Ground-Level Views From Overhead Imagery}, 
author={Xueqing Deng and Yi Zhu and Shawn Newsam},
year={2019},
eprint={1902.06923},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/1902.06923}, 
}

@misc{toker2021,
title={Coming Down to Earth: Satellite-to-Street View Synthesis for Geo-Localization}, 
author={Aysim Toker and Qunjie Zhou and Maxim Maximov and Laura Leal-Taixé},
year={2021},
eprint={2103.06818},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2103.06818}, 
}

@misc{zhu2022,
title={TransGeo: Transformer Is All You Need for Cross-view Image Geo-localization}, 
author={Sijie Zhu and Mubarak Shah and Chen Chen},
year={2022},
eprint={2204.00097},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2204.00097}, 
}

@misc{yang2021,
author = {Yang, Hongji and Lu, Xiufan and Zhu, Yingying},
year = {2021},
month = {07},
pages = {},
title = {Cross-view Geo-localization with Evolving Transformer},
doi = {10.48550/arXiv.2107.00842}
}

@misc{zhang2022,
title={Cross-View Image Sequence Geo-localization}, 
author={Xiaohan Zhang and Waqas Sultani and Safwan Wshah},
year={2022},
eprint={2210.14295},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2210.14295}, 
}

@misc{shi2019optimalfeaturetransportcrossview,
title={Optimal Feature Transport for Cross-View Image Geo-Localization}, 
author={Yujiao Shi and Xin Yu and Liu Liu and Tong Zhang and Hongdong Li},
year={2019},
eprint={1907.05021},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/1907.05021}, 
}
@misc{shi2020ilookingatjoint,
title={Where am I looking at? Joint Location and Orientation Estimation by Cross-View Matching}, 
author={Yujiao Shi and Xin Yu and Dylan Campbell and Hongdong Li},
year={2020},
eprint={2005.03860},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2005.03860}, 
}

@misc{workman2015wideareaimagegeolocalizationaerial,
title={Wide-Area Image Geolocalization with Aerial Reference Imagery}, 
author={Scott Workman and Richard Souvenir and Nathan Jacobs},
year={2015},
eprint={1510.03743},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/1510.03743}, 
}
@misc{zhai2016predictinggroundlevelscenelayout,
title={Predicting Ground-Level Scene Layout from Aerial Imagery}, 
author={Menghua Zhai and Zachary Bessinger and Scott Workman and Nathan Jacobs},
year={2016},
eprint={1612.02709},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/1612.02709}, 
}

@misc{dionelis2024,
title={Learning from Unlabelled Data with Transformers: Domain Adaptation for Semantic Segmentation of High Resolution Aerial Images}, 
author={Nikolaos Dionelis and Francesco Pro and Luca Maiano and Irene Amerini and Bertrand Le Saux},
year={2024},
eprint={2404.11299},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2404.11299}, 
}

@misc{cheng2022maskedattentionmasktransformeruniversal,
title={Masked-attention Mask Transformer for Universal Image Segmentation}, 
author={Bowen Cheng and Ishan Misra and Alexander G. Schwing and Alexander Kirillov and Rohit Girdhar},
year={2022},
eprint={2112.01527},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2112.01527}, 
}

@misc{yang2024depthanythingunleashingpower,
title={Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data}, 
author={Lihe Yang and Bingyi Kang and Zilong Huang and Xiaogang Xu and Jiashi Feng and Hengshuang Zhao},
year={2024},
eprint={2401.10891},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2401.10891}, 
}

@misc{liu2022convnet2020s,
title={A ConvNet for the 2020s}, 
author={Zhuang Liu and Hanzi Mao and Chao-Yuan Wu and Christoph Feichtenhofer and Trevor Darrell and Saining Xie},
year={2022},
eprint={2201.03545},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2201.03545}, 
}
@misc{loshchilov2019decoupledweightdecayregularization,
title={Decoupled Weight Decay Regularization}, 
author={Ilya Loshchilov and Frank Hutter},
year={2019},
eprint={1711.05101},
archivePrefix={arXiv},
primaryClass={cs.LG},
url={https://arxiv.org/abs/1711.05101}, 
}
@INPROCEEDINGS{Imagenet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi={10.1109/CVPR.2009.5206848}}

@misc{segformer,
title={SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers}, 
author={Enze Xie and Wenhai Wang and Zhiding Yu and Anima Anandkumar and Jose M. Alvarez and Ping Luo},
year={2021},
eprint={2105.15203},
archivePrefix={arXiv},
primaryClass={cs.CV},
url={https://arxiv.org/abs/2105.15203}, 
}

@misc{adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6980}, 
}

@INPROCEEDINGS{MVD,
  author={Neuhold, Gerhard and Ollmann, Tobias and Bulò, Samuel Rota and Kontschieder, Peter},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={The Mapillary Vistas Dataset for Semantic Understanding of Street Scenes}, 
  year={2017},
  volume={},
  number={},
  pages={5000-5009},
  keywords={Semantics;Cameras;Image segmentation;Visualization;Protocols;Quality assurance;Computer vision},
  doi={10.1109/ICCV.2017.534}}

@INPROCEEDINGS{10156981,
  author={Papa, Lorenzo and Faiella, Lorenzo and Corvitto, Luca and Maiano, Luca and Amerini, Irene},
  booktitle={2023 11th International Workshop on Biometrics and Forensics (IWBF)}, 
  title={On the use of Stable Diffusion for creating realistic faces: from generation to detection}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  keywords={Deepfakes;Image synthesis;Forensics;Face recognition;Pipelines;Human in the loop;Security;Computer vision;Deepfake detection;Diffusion models;Prompt engineering;Security},
  doi={10.1109/IWBF57495.2023.10156981}}

@misc{russiafake,
author = {Jake Epstein},
title = {Russia painted fake fighter jets at its airfields, new
satellite images show, likely to trick ukraine into not blowing up the real deal},
howpublished = {\url{https://www.businessinsider.nl/russia-painted-fake-fighter-jets-at-its-airfields-new-satellite-images-show-likely-to-trick-ukraine-into-not-blowing-up-the-real-deal/}},
month = {January},
year = {2024}
}

@misc{huschens2023trustchatgptperceived,
      title={Do You Trust ChatGPT? -- Perceived Credibility of Human and AI-Generated Content}, 
      author={Martin Huschens and Martin Briesch and Dominik Sobania and Franz Rothlauf},
      year={2023},
      eprint={2309.02524},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2309.02524}, 
}

@misc{loth2024blessingcursesurveyimpact,
      title={Blessing or curse? A survey on the Impact of Generative AI on Fake News}, 
      author={Alexander Loth and Martin Kappes and Marc-Oliver Pahl},
      year={2024},
      eprint={2404.03021},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.03021}, 
}

@Article{Raman2024,
author={Raman, Raghu and Kumar Nair, Vinith and Nedungadi, Prema and Kumar Sahu, Aditya and Kowalski, Robin and Ramanathan, Sasangan and Achuthan, Krishnashree},
title={Fake news research trends, linkages to generative artificial intelligence and sustainable development goals},
journal={Heliyon},
year={2024},
month={Feb},
day={15},
publisher={Elsevier},
volume={10},
number={3},
issn={2405-8440},
doi={10.1016/j.heliyon.2024.e24727},
url={https://doi.org/10.1016/j.heliyon.2024.e24727}
}

@misc{shi2023boosting3dofgroundtosatellitecamera,
      title={Boosting 3-DoF Ground-to-Satellite Camera Localization Accuracy via Geometry-Guided Cross-View Transformer}, 
      author={Yujiao Shi and Fei Wu and Akhil Perincherry and Ankit Vora and Hongdong Li},
      year={2023},
      eprint={2307.08015},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.08015}, 
}

@ARTICLE{9170787,
  author={Verde, Sebastiano and Resek, Thiago and Milani, Simone and Rocha, Anderson},
  journal={IEEE Signal Processing Letters}, 
  title={Ground-to-Aerial Viewpoint Localization via Landmark Graphs Matching}, 
  year={2020},
  volume={27},
  number={},
  pages={1490-1494},
  keywords={Satellites;Image matching;Buildings;Task analysis;Roads;Mathematical model;Symmetric matrices;Cross-view;ground-to-aerial;matching;landmark graphs;localization;viewpoint},
  doi={10.1109/LSP.2020.3017380}}

@INPROCEEDINGS{10167940,
  author={Bonaventura, Tania Sari and Maiano, Luca and Papa, Lorenzo and Amerini, Irene},
  booktitle={2023 24th International Conference on Digital Signal Processing (DSP)}, 
  title={An Automated Ground-to-Aerial Viewpoint Localization for Content Verification}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  keywords={Location awareness;Learning systems;Satellites;Forensics;Pipelines;Digital signal processing;Media},
  doi={10.1109/DSP58604.2023.10167940}}


@misc{goodfellow2014generativeadversarialnetworks,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1406.2661}, 
}

@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@misc{dosovitskiy2021imageworth16x16words,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2010.11929}, 
}

@inproceedings{10.1145/3664647.3681431,
author = {Wang, Yuntao and Zhang, Jinpu and Wei, Ruonan and Gao, Wenbo and Wang, Yuehuan},
title = {MFRGN: Multi-scale Feature Representation Generalization Network for Ground-to-Aerial Geo-localization},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681431},
doi = {10.1145/3664647.3681431},
abstract = {Cross-area evaluation poses a significant challenge for ground-to-aerial geo-localization, in which the training and testing data are captured from entirely distinct areas. However, current methods struggle in cross-area evaluation due to their emphasis solely on learning global information from single-scale features. Some efforts alleviate this problem but rely on complex and specific technologies like pre-processing and hard sample mining. To this end, we propose a pure end-to-end solution, free from task-specific techniques, termed the Multi-scale Feature Representation Generalization Network (MFRGN) to improve generalization. Specifically, we introduce multi-scale features and explicitly utilize them by an novel global-local information representation structure with two flows, to bolster feature representations. In the global flow, we present a lightweight Self and Cross Attention Module (SCAM) to efficiently learn global embeddings. In the local flow, we develop a Global-Prompt Attention Block (GPAB) to capture discriminative features under the global embeddings as prompts. As a result, our approach generates robust descriptors representing multi-scale global and local information, thereby enhancing the model's invariance to scene variations. Extensive experiments on benchmarks show our MFRGN achieves competitive performance in same-area evaluation and improves cross-area generalization by a significant margin compared to SOTA methods. Our code is available at https://github.com/ytao-wang/MFRGN.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2574–2583},
numpages = {10},
keywords = {cross-view image geo-localization, feature representation, image matching, image retrieval},
location = {Melbourne VIC, Australia},
series = {MM '24}
}


@Article{s24123719,
AUTHOR = {Fan, Jiqi and Zheng, Enhui and He, Yufei and Yang, Jianxing},
TITLE = {A Cross-View Geo-Localization Algorithm Using UAV Image and Satellite Image},
JOURNAL = {Sensors},
VOLUME = {24},
YEAR = {2024},
NUMBER = {12},
ARTICLE-NUMBER = {3719},
URL = {https://www.mdpi.com/1424-8220/24/12/3719},
PubMedID = {38931506},
ISSN = {1424-8220},
ABSTRACT = {Within research on the cross-view geolocation of UAVs, differences in image sources and interference from similar scenes pose huge challenges. Inspired by multimodal machine learning, in this paper, we design a single-stream pyramid transformer network (SSPT). The backbone of the model uses the self-attention mechanism to enrich its own internal features in the early stage and uses the cross-attention mechanism in the later stage to refine and interact with different features to eliminate irrelevant interference. In addition, in the post-processing part of the model, a header module is designed for upsampling to generate heat maps, and a Gaussian weight window is designed to assign label weights to make the model converge better. Together, these methods improve the positioning accuracy of UAV images in satellite images. Finally, we also use style transfer technology to simulate various environmental changes in order to expand the experimental data, further proving the environmental adaptability and robustness of the method. The final experimental results show that our method yields significant performance improvement: The relative distance score (RDS) of the SSPT-384 model on the benchmark UL14 dataset is significantly improved from 76.25% to 84.40%, while the meter-level accuracy (MA) of 3 m, 5 m, and 20 m is increased by 12%, 12%, and 10%, respectively. For the SSPT-256 model, the RDS has been increased to 82.21%, and the meter-level accuracy (MA) of 3 m, 5 m, and 20 m has increased by 5%, 5%, and 7%, respectively. It still shows strong robustness on the extended thermal infrared (TIR), nighttime, and rainy day datasets.},
DOI = {10.3390/s24123719}
}


@misc{simonyan2015deepconvolutionalnetworkslargescale,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.1556}, 
}

@misc{businessinsiderTheseUnbelievable,
	author = {Dave Mosher},
	title = {{T}hese unbelievable space images of {E}arth at night are a bunch of beautiful fakes --- businessinsider.com},
	howpublished = {\url{https://www.businessinsider.com/earth-night-space-simulated-images-2017-8}},
	year = {},
	note = {[Accessed 02-12-2024]},
}

@misc{businessinsiderRussiaPainted,
	author = {Jake Epstein},
	title = {{R}ussia painted fake fighter jets at its airfields, new satellite images show, likely to trick {U}kraine into not blowing up the real deal --- businessinsider.nl},
	howpublished = {\url{https://www.businessinsider.nl/russia-painted-fake-fighter-jets-at-its-airfields-new-satellite-images-show-likely-to-trick-ukraine-into-not-blowing-up-the-real-deal/}},
	year = {},
	note = {[Accessed 02-12-2024]},
}