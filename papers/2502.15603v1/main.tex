\documentclass{article}


\usepackage{csquotes}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{placeins}
\usepackage{booktabs} 

\usepackage{hyperref}
\usepackage{url}


\newcommand{\theHalgorithm}{\arabic{algorithm}}


\usepackage[accepted]{Styles/icml2025}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{multirow}

\usepackage{subcaption}

\usepackage[capitalize,noabbrev]{cleveref}


\newcommand{\mistral}{Mixtral-8x22B}
\newcommand{\llama}{Llama-3.1-70B}
\newcommand{\aya}{Aya-23-35B}
\newcommand{\gemma}{Gemma-2-27b}

\usepackage[encapsulated]{CJK}
\newcommand{\md}[1]{\begin{CJK}{UTF8}{gbsn}#1\end{CJK}}


\usepackage{array}
\usepackage{longtable}

\icmltitlerunning{Do Multilingual LLMs Think In English?}

\begin{document}

\twocolumn[
\icmltitle{Do Multilingual LLMs Think In English?}


\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Lisa Schut}{oat}
\icmlauthor{Yarin Gal}{oat}
\icmlauthor{Sebastian Farquhar}{gdm}
\end{icmlauthorlist}

\icmlaffiliation{oat}{OATML, Department of Computer Science, University of Oxford.}
\icmlaffiliation{gdm}{Google DeepMind}

\icmlcorrespondingauthor{Lisa Schut}{schut@robots.ox.ac.uk}

\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]


\printAffiliationsAndNotice{} 

\begin{abstract}
Large language models (LLMs) have multilingual capabilities and can solve tasks across various languages. 
However, we show that current LLMs make key decisions in a representation space closest to English, regardless of their input and output languages. 
Exploring the internal representations with a logit lens for sentences in French, German, Dutch, and Mandarin, we show that the LLM first emits representations close to English for semantically-loaded words before translating them into the target language. 
We further show that activation steering in these LLMs is more effective when the steering vectors are computed in English rather than in the language of the inputs and outputs. 
This suggests that multilingual LLMs perform key reasoning steps in a representation that is heavily shaped by English in a way that is not transparent to system users.
\end{abstract}

\input{sections/1_introduction}

\input{sections/2_background}

\input{sections/3_method}

\input{sections/4_experiments}

\input{sections/5_limitation}

\input{sections/7_related_work}

\input{sections/6_conclusion}

\input{sections/8_discussion}


\section*{Impact Statement}
Large Language Models (LLMs) are increasingly deployed across a wide range of applications, making it crucial to understand and evaluate their performance to ensure both safety and fairness. 
A key characteristic of LLMs is their English-centric nature, which influences their behavior, as shown in this paper. 
In particular, we find further evidence that LLMs perform semantic decisions in English. 
This likely leads to biased behaviour \citep{naous2024havingbeerprayermeasuring, shafayat2024multifactassessingfactualitymultilingual}. 
Understanding this is essential to equitable and reliable outcomes in diverse linguistic and cultural contexts.

Moreover, our findings may further be relevant for improving the safety of LLMs. 
When analysing non-lexical words, we found that LLMs do not emit an English-centric bias. 
If knowledge representation is not universal across languages, LLMs may require language-specific safety tuning. 
When introspecting the latent space, we observed varying levels of vulgar terms depending on the language, particularly in cases where the models are not safety-tuned on the language.
While this does not necessarily mean the model’s output will be vulgar, it could make the model more vulnerable to jailbreaks \citep{deng2024multilingualjailbreakchallengeslarge, ghandeharioun2024whosaskinguserpersonas}. 


\section*{Acknowledgments}
We thank Jannik Kossen, Kunal Handa, Emily Reif, Veniamin Veselovsky and Lewis Hammond for their useful feedback and discussions during the writing of this paper. 
Lisa Schut is funded by the EPSRC Centre for Doctoral Training in Autonomous Intelligent Machines and Systems grant (EP/S024050/1) and DeepMind.
Yarin Gal is supported by a Turing AI Fellowship financed by the UK government’s Office for Artificial Intelligence, through UK Research and Innovation (EP/V030302/1) and delivered by the Alan Turing Institute.


\bibliographystyle{abbrvnat}
\bibliography{references.bib}


\appendix
\onecolumn

\input{sections/appendix}

\end{document}