% change below to fit in to the above structure

\subsubsection{Generating High-Performance FPGA Accelerator Designs for Big Data Analytics with Fletcher and Apache Arrow}
\cite{Peltenburg2021GeneratingArrow}
In depth description of the Fletcher framework, it's components, integration with Apache Arrow and examples.

Group Accelerated Big Data Systems, TUD. IBM. Fitoptivis project.

FPGAs as data center accelerators for big data analytic pipelines. Fletcher, leveraging Apache Arrow. Vendor agnostic. Addressing host challenges: run time system, in-memory layouts of data sets and (de)serialization. Addressing FPGA side challenges: platform-agnostic open-source tooling for HDL, data structure interface standardization, design effort for infrastructure. 

"Big data systems are reaching maturity in terms of
squeezing out the last bits of performance of CPUs or even
GPUs. The next near-term and widely available alternative
for higher performance in the data center and cloud may be
the FPGA accelerator."

"Whether the FPGA accelerator in the data center will
become an implementation platform as common as other
accelerators, such as GPGPUs, is still an open question. The
answer will depend on the economic advantages that these
systems will offer; will they provide a lower cost per query?
Will they provide more performance per dollar?" (disadvantages and advantages mentioned, might be used for introduction to this section?).

"Fletcher builds on top op Apache Arrow, providing a common, hardware-friendly in-memory format,
allowing developers to communicate large tabular data sets
between over eleven software languages without the need
for copies, preventing (de)serialization overhead. Fletcher
adds hardware accelerators to the list. Several low-level
hardware components were designed to deal with the
mentioned challenges for table columns, providing easy-touse,
high-performance interfaces to hardware-accelerated
kernels. The lower-level components are combined into
a larger design, based on a generic architecture for
FPGA accelerators that have tabular inputs and outputs.
Through an extensive infrastructure generation framework,
specialized, data type-driven specializations of the generic
architecture are generated, automating the tedious work
of infrastructural design. The infrastructure generation tool
made specifically for Arrow is built on top of a generic
C++17 structural hardware construction library called
Cerata, and on an MMIO controller generator framework
called Vhdmmio."

Several contributions open-source available, such as: https://github.com/abs-tudelft/fletcher/tree/develop/platforms

Last developer activity 4-5 years ago?
But effort continued in Voltron Data products?




\subsubsection{Fletcher A Framework to Efficiently Integrate FPGA Accelerators with Apache Arrow}
\cite{Peltenburg2019Fletcher:Arrow}
Descripton of the Fletcher framework. And benchmark of several application with the Fletcher framework. 
Implementations on an Amazon Web Services EC2
F1 system equipped with a proprietary card that contains a Xilinx
XCVU9P (AWS/F1) and a POWER9 Barreleye system equipped with
an AlphaData ADM-9V3 equipped with a Xilinx VU3P attached
through CAPI 2.0 using the SNAP framework (P9/SNAP).

Group Accelerated Big Data Systems, TUD. IBM. Fitoptivis project.



\subsubsection{SparkJNI A Toolchain for Hardware Accelerated Big Data Apache Spark}
\cite{Voicu2019SparkJNI:Spark}
"In this paper, we analyze the
state-of-the-art developments in the field of heterogeneously accelerated
Spark, and we propose SparkJNI, a framework for JNIaccelerated
Spark. The design provides two main components.
First, it enables a seamless utilization of native CPU code, in
addition to integration of GPU as well as FPGA accelerators"

"a DNA analysis
algorithm (Pair-HMM) is implemented in Spark and integrated
with FPGAs, targeting cluster deployments, with benchmark
results showing an overall speedup of ∼2.7x over state-of-theart
CPU optimizations. The result of the presented work, along
with the SparkJNI framework are publicly available on GitHub
for open-source usage and development"

Department of Quantum & Computer Engineering TUD, later Accelerated Big Data Systems, TUD.

\subsubsection{Memory-Disaggregated In-Memory Object Store Framework for Big Data Applications}
\cite{Abrahamse2022Memory-DisaggregatedApplications}
"This paper proposes and demonstrates
a memory disaggregated in-memory object store framework for
big data applications by leveraging the newly introduced ThymesisFlow
memory disaggregation system. The framework extends
the functionality of the pre-existing Apache Arrow Plasma object
store framework to distributed systems by enabling clients to
easily and efficiently produce and consume data objects across
multiple compute nodes. This allows big data applications to
increasingly leverage parallel processing at reduced development
costs. In addition, the paper includes latency and throughput
measurements that indicate only a modest performance penalty
is incurred for remote disaggregated memory access as opposed to
local."

FPGA + POWER9 + OpenCAPI

Group Accelerated Big Data Systems, TUD.














%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Benchmarking Apache Arrow Flight - A Wire-Speed Protocol for Data Transfer, Querying and Microservices}
\cite{Ahmad2022BenchmarkingMicroservices}
Demonstration and benchmarking of a couple of Arrow Flight use cases.

Group Accelerated Big Data Systems, TUD. IBM. SURF infrastructure.

No FPGA's used? But could later be used with Arrow framework for FPGA.

\subsubsection{Battling the CPU Bottleneck in Apache Parquet to Arrow Conversion Using FPGA}
\cite{Peltenburg2020BattlingFPGA}
On-line data conversion from Parquet format to Arrow on FPGA in order to process data more efficiently on FPGA in the Arrow framework. Addressing I/O bottleneck in a POWER9 + OpenCAPI + Xilinx FPGA accelrator system. Related to the other Arrow work.
Group Accelerated Big Data Systems, TUD. Project Fitoptivis.

\subsubsection{Tens of gigabytes per second JSON-to-Arrow conversion with FPGA accelerators}
\cite{Peltenburg2021TensAccelerators}
"Many big data
applications with high performance requirements convert JSON
data to Apache Arrow RecordBatches, the latter being a widelyused
columnar in-memory format for large tabular data sets
used in data analytics. In this paper, we analyze the performance
characteristics of such applications and show that JSON parsing
represents a bottleneck in the system. Various strategies are
explored to speed up JSON parsing on CPU and GPU as much
as possible. Due to performance limitation of the CPU and GPU
implementations, we furthermore present an FPGA accelerated
implementation."

Intel Arria 10 GX and Xilinx VU37P
devices with Intel Xeon and an IBM POWER9 system.

Group Accelerated Big Data Systems, TUD. Teratide B.V. Netherlands, Sigmax.ai Inc., USA.

\subsubsection{Fpga acceleration for big data analytics - Challenges and opportunities}
\cite{Hoozemans2021FPGAOpportunities}
Survey of the available technology and fallacies in the field of FPGA acceleration for big data analytics.

"This article explores the existing practices in big data analytics
frameworks, discusses the aforementioned gap (FPGA deployment) in development
abstractions, and provides some perspectives on how to address
these challenges in the future."

Group Accelerated Big Data Systems, TUD.
This work is part of the FitOptiVis project.

\subsubsection{The Coming Age of Pervasive Data Processing}
\cite{Rellermeyer2019TheProcessing}
Survey on the current state and future of technology for big data analyticas and machine learning applicatons.

'Identificiation' of GPU and FPGA as accelerators. Not FPGA specific. No FPGA contributions.

"In this paper, we address
the current and upcoming challenges of pervasive data processing
and present directions for designing the next generation of largescale
data processing systems."

No implementation.

Distributed Systems Group, DUT.

\subsubsection{Data Stream Statistics Over Sliding Windows How to Summarize 150 Million Updates Per Second on a Single Node}
\cite{Chrysos2019DataNode}
"Traditional data management systems map information
using centralized and static data structures. Modern
applications need to process in real time datasets much larger
than system memory."

"This work presents a system-level solution to accelerate the Exponential
Count-Min (ECM) sketch algorithm on reconfigurable
technology."

Virtex6 and Ultrascale devices.

a.o. NL: Department of Mathematics and Computer Science, TU Eindhoven.

\subsubsection{Graph Greenifier: Towards Sustainable and Energy-Aware Massive Graph Processing in the Computing Continuum}
\cite{Iosup2023GraphContinuum}
Optimization of Graph Processing. 
One mention of FPGAs as a target in a heterogenous infrastructure.
No implementation or adding specific to the FPGA field, but this is an example of an application that might fit well for FPGA in data centres.

"... Graph Greenifier aims
to address this challenge in the conceptual framework offered by
the Graph Massivizer architecture. We present an early vision of
how Graph Greenifier could provide sustainability analysis and
decision-making capabilities for extreme graph-processing workloads."

\subsubsection{Towards Extreme and Sustainable Graph Processing for Urgent Societal Challenges in Europe}
\cite{Prodan2022TowardsEurope}
Similar as above. Work done in the The Graph-Massivizer project by a.o. NL: VU Amsterdam and U Twente.


\subsubsection{(De-)Compression}
Loading compressed data from storage, acceleration of decompression on FPGA, either for further processing on FPGA or as accelerator for this operation (in combination with OpenCAPI).

\subsubsubsection{A Fine-Grained Parallel Snappy Decompressor for FPGAs Using a Relaxed Execution Model}
\cite{Fang2019AModel}
"Snappy [1] is a widely used (de)compression algorithm in
many big data applications. Such a data compression technique
has been proven to be successful to save storage space and to
reduce the amount of data transmission from/to storage de
vices. In this paper, we present a fine-grained parallel Snappy
decompressor on FPGAs"

Delft University of Technology, Delft, The Netherlands
IBM Research, Austin, TX, USA

\subsubsubsection{An Efficient High-Throughput LZ77-Based Decompressor in Reconfigurable Logic}
\cite{Fang2020AnLogic}
"To best leverage high-bandwidth storage and network technologies requires an improvement in the speed at which we can
decompress data. We present a “refine and recycle” method applicable to LZ77-type decompressors that enables efficient
high-bandwidth designs and present an implementation in reconfigurable logic. The method refines the write commands
(for literal tokens) and read commands (for copy tokens) to a set of commands that target a single bank of block ram, and
rather than performing all the dependency calculations saves logic by recycling (read) commands that return with an invalid
result. A single “Snappy” decompressor implemented in reconfigurable logic leveraging this method is capable of processing
multiple literal or copy tokens per cycle and achieves up to 7.2GB/s, which can keep pace with an NVMe device. The
proposed method is about an order of magnitude faster and an order of magnitude more power efficient than a state-of-the-art
single-core software implementation. The logic and block ram resources required by the decompressor are sufficiently low
so that a set of these decompressors can be implemented on a single FPGA of reasonable size to keep up with the bandwidth
provided by the most recent interface technologies."

National Innovation Institute of Defense Technology, Beijing, China
Yonsei University, Seoul, Korea
Delft University of Technology, Delft, The Netherlands
IBM Research, Austin, TX, USA

\subsubsubsection{Energy Efficient Multistandard Decompressor ASIP}
\cite{Hoozemans2021EnergyASIP}
"we propose a
compiler-supported Application-Specific Instruction-set Processor
(ASIP) design that is able to decompress a range of lossless compression
standard without FPGA reconfiguration. We perform a
case study of searching a compressed database dump"

"application-specific instruction-set processor (ASIP), based on the
Transport-triggered architecture (TTA) [8], that is optimized to efficiently
decompress a wide range of current and predictably also
future lossless compression standards. The presented prototype of
the ASIP developed using the TTA-based Co-design Environment
(TCE) [9] (also known as OpenASIP) supports the Snappy and LZ4
compression standards."

Delft University of Technology, Delft, The Netherlands
Tampere University, Finland
FitOptiVis project

\subsubsubsection{FPGA Acceleration of Zstd Compression Algorithm}
\cite{Chen2021FPGAAlgorithm}
Realtime compression of big data streams
High-frequency trading data

"In this paper, we introduce the
architecture of a new hardware compression kernel for Zstd
that allows the algorithm to be used for real-time compression
of big data streams. In addition, we optimize the proposed
architecture for the specific use case of streaming high-frequency
trading data. The optimized kernel is implemented on a Xilinx
Alveo U200 board. Our optimized implementation allows us to
fit ten kernel blocks on one board, which is able to achieve a
compression throughput of about 8.6GB/s and compression ratio
of about 23.6%. The hardware implementation is open source and
publicly available at https://github.com/ChenJianyunp/Hardware-
Zstd-Compression-Unit."

Vitis, OpenCL, U200

Accelerated Big Data Systems, Delft University of Technology, Delft, The Netherlands
Optiver, Amsterdam, The Netherlands

\subsubsection{In-memory database acceleration on FPGAs: a survey}
\cite{Fang2020In-memorySurvey}
Survey on in-memory database acceleration on FPGAs.

"
FPGAs have been recognized by the database community
for their ability to accelerateCPU-intensiveworkloads.However,
both the industry and academia have shown less interest
in integrating FPGAs into database systems due to the following
three reasons. First, while FPGAs can provide high data
processing rates, the system performance is bounded by the
limited bandwidth from conventional IO technologies. Second,
FPGAs are competing with a strong alternative, GPUs,
which can also provide high throughput and are much easier
to program. Last, programming FPGAs typically requires a
developer to have full-stack skills, from high-level algorithm
design to low-level circuit implementation.
The good news is that these challenges are being addressed
as can be seen through the technology trends and even the
latest technologies. Interface technologies develop so fast
that the interconnection between memory and accelerators
can be expected to deliver main-memory scale bandwidth.
In addition, FPGAs are incorporating new higher-bandwidth
memory technologies such as the high-bandwidth memory,
giving FPGAs a chance to combine a high degree parallel
computationwith high-bandwidth large-capacity local memory.
Finally, emerging FPGA tool chains including HLS,
new programming frameworks, and SQL-to-FPGA compilers,
provide developers with better ease of use. Therefore
FPGAs can become attractive again as a database accelerator.
In this paper, we explore the potential of using FPGAs
to accelerate in-memory database systems. We reviewed
the architecture of FPGA-accelerated database systems, discussed
the challenges of integrating FPGAs into database
systems, studied technology trends that address the challenges,
and summarized the state-of-the-art research on
database operator acceleration. We observe that FPGAs are
capable of accelerating some of the database operators such
as streaming operators, sort, and regular expression matching.
In addition, emerging hardware compile tools further
increase the usability of FPGAs in databases. We anticipate
that the new technologies provide FPGAs with the opportunity
to again deliver system-level speedup for database
applications. However, there is still a long way to go, and
future studies including new database architectures, new
types of accelerators, deep performance analysis, and the
development of the tool chains can push this progress a step
forward.
"

No implementation.

Delft University of Technology, Delft, The Netherlands
IBM Research and Development, Böblingen, Germany
Vrije Universiteit Brussel, Brussels, Belgium
IBM Research, Austin, TX, USA
Yonsei University, Seoul, Korea