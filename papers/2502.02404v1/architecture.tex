%Hardware design is anything related to the design of FPGA hardware and computer architecture implemented through FPGAs. Mainly focussed on CGRA, near-memory architectures, NOC and some other smaller subjects.

This section discusses how FPGAs enable advanced computer architecture concepts that eliminate common bottlenecks in existing computer architectures. Here, we discuss three main architectural topics and their applications: Near-Memory Computing (NMC), Coarse-Grained Reconfigurable Arrays (CGRAs), and Network-on-Chip (NoC). 

\subsection{Near-Memory Computing (NMC)}
%On near memory-processing and rapid memory access on FPGAs, including some applications of near-memory processing.
% This section discusses the topic of using FPGAs for near memory processing, which is being spearheaded in the Netherlands by the Technical University of Eindhoven. 

%\paragraph{Background}
NMC is a promising approach to mitigate memory access bottlenecks in high-performance computing (HPC) systems. NMC bridges the widening gap between the computation capabilities of processors and the latency and bandwidth limitations of memory subsystems. This is specifically important for applications where conventional CPU architectures struggle due to complex data access patterns, limited data reusability, and low arithmetic intensity. These challenges are attributed to the inefficiencies in conventional memory hierarchies. FPGAs play an important role in enabling NMC due to their reconfigurable nature, allowing for the co-location of computation with memory. This co-location significantly reduces the data movement that typically limits performance and increases energy consumption in traditional architectures. FPGAs facilitate the implementation of customized, application-specific datapaths and processing units adjacent to memory, enabling more efficient data handling and processing. 

\subsubsection*{\bf{Research topics}}
There are multiple research topics being investigated by Dutch organizations that focus on harnessing NMC to enhance the performance and energy efficiency of applications with complex data access patterns, specifically through the use of FPGA-based accelerators.
% \begin{itemize}
%     \item \textbf{Genomics}. This application proposes improved computational solutions for genome analysis, which is an excessively expensive application in genomics. The application proposes a prealignment filter based on NMC to reduce the amount of data to be processed~\cite{genomics_nmc}. 
%     \item \textbf{Weather prediction}. Solving large-scale weather prediction simulations suffer from limited performance and high energy consumption due to complex irregular memory access patterns and low arithmetic intensity. This application  proposes using an NMC solution with an FPGA and high-bandwidth memory (HBM) that is 5.3x faster than the baseline CPU solution~\cite{weather_nmc}.
%     \item \textbf{Biology}. Reconstructing large evolutionary relationships among organisms is computationally expensive due to extensive calculation of probabilistic likelihood functions which is a data-intensive, memory-bound operation. This application describes an NMC solution that addresses the problem of workload distribution and results in improved scalable performance~\cite{biology_nmc}.    
% \end{itemize}

\paragraph{Genomics} \citet{Singh2021FPGA-BasedApplications} %This application 
propose improved computational solutions for genome analysis, which is an excessively expensive application in genomics. The study %application 
proposes a prealignment filter based on NMC to reduce the amount of data to be processed. %~\cite{genomics_nmc}.
\paragraph{Weather prediction} Solving large-scale weather prediction simulations suffer from limited performance and high energy consumption due to complex irregular memory access patterns and low arithmetic intensity. ~\citet{Singh2022AcceleratingFabric} %This application  
propose %using 
an NMC solution with an FPGA and high-bandwidth memory (HBM) that is 5.3x faster than the baseline CPU solution. %~\cite{weather_nmc}.
\paragraph{Phylogenetics} Reconstructing large evolutionary relationships among organisms is computationally expensive due to extensive calculation of probabilistic likelihood functions, which is a data-intensive, memory-bound operation. ~\citet{Alachiotis2021ScalableProcessing} %This application 
describe an NMC solution that addresses the problem of workload distribution in a disaggregated datacenter architecture, and results in improved, scalable performance. %~\cite{biology_nmc}.


\subsubsection*{\bf{Future directions}}
NMC is an emerging field that promises to have an impact on various applications domains where data access patterns hinder performance, including but not limited to, big data analytics, machine learning, and scientific simulations. Research continues to explore using FPGA-based accelerators for a broader range of applications. The integration of emerging memory technologies like high bandwidth memory with FPGAs is anticipated to further enhance bandwidth and reduce the energy footprint of such applications~\cite{Singh2019Near-memoryFuture}. Furthermore, investigations to improve the NMC architecture is on-going, by optimizing the granularity of data movement, refining memory hierarchies to match specific application patterns, and exploring the precision tolerance of various computational kernels for additional efficiency gains. The adaptability of FPGAs to various data access and processing patterns makes them attractive platforms for such optimizations~\cite{Singh2019Near-memoryFuture}. Moreover, as the NMC field progresses, there is a growing emphasis on software frameworks and tools that simplify the deployment of NMC solutions, making them accessible to a wider range of developers and applications~\cite{Abrahamse2022Memory-DisaggregatedApplications}.



\subsection{Coarse-Grained Reconfigurable Architecture (CGRA)}

%\paragraph{Background}
%Course-grained reconfigurable architectures (
CGRAs aim at improving the programming efficiency of %the 
FPGA platforms. Many applications do not require the bit-level reconfigurability that is provided by modern %the 
FPGA platforms. 
The trend toward coarser granularity is evident even in commercial FPGA architectures, as the number of Digital Signal Processing (DSP) blocks and other specialized hardware accelerators increases with each new generation.
%
%Even within the commercial FPGA architectures, this trend towards increased granularity can be observed from the growing number of digital signal processing (DSP) blocks and the inclusion of other specialized hardware accelerators.

\subsubsection*{\bf{Research topics}}
Multiple CGRA-related topics are explored %in the context of CGRAs within  
by Dutch organizations, both at the level of application mapping and toward  the implementation of novel accelerator structures.

% \begin{itemize}
%     \item \textbf{Application mapping templates}
%     By providing a template architecture that allows for configuration at a courser granularity (e.g. arithmetic operations) the architecture exploration space is significantly reduced, which significantly simplifies the work for the application mapping tools.  Due to the limited architecture exploration space, it is more likely that the application mapping process will find an efficient mapping \cite{Charitopoulos2021MC-DeF:Applications}.

%     \item \textbf{Accelerator architecture evaluation}  
%     Once a template architecture is decided, it can also be implemented directly on a chip, either as a standalone Application Specific Integrated Circuit (ASIC), or integrated in a larger system as an accelerator.  This further reduces the reconfiguration overhead compared to the FPGA and can result in overall improved performance \cite{Wijerathne2022HiMap:Abstraction,Wijtvliet2019Blocks:Efficiency,debruin2024rblocks}.  FPGAs are still used in this context, but mostly for prototyping, obtaining activity traces of applications for energy estimation, and exploring the template architecture design.

% \end{itemize}
\paragraph{Application-mapping templates}\citet{Charitopoulos2021MC-DeF:Applications}
provide a template architecture that allows for device configuration at a coarser granularity (e.g., arithmetic operations), thereby  significantly reducing the architecture exploration space and significantly simplifying the work of %the 
application mapping tools. Due to the limited architecture exploration space, it becomes more likely that the application mapping process will find an efficient mapping. %\cite{Charitopoulos2021MC-DeF:Applications}.

\paragraph{Accelerator architecture evaluation} Once a template architecture is designed, %decided, 
it can also be implemented directly on a chip, either as a standalone ASIC or integrated into a larger system as an accelerator.  This further reduces the reconfiguration overhead compared to %the 
FPGAs, and can result in overall improved performance \cite{Wijerathne2022HiMap:Abstraction,Wijtvliet2019Blocks:Efficiency,debruin2024rblocks}.  FPGAs, however, are still used in this context, mainly for prototyping, obtaining activity traces of applications for energy estimation, and exploring the template architecture design.

\subsubsection*{\bf{Future directions}}
Many FPGA platforms nowadays are part of a larger System-on-Chip (SoC).  These are increasingly introducing hardware accelerators for common tasks (e.g., machine learning).  CGRAs can play a key role in this context as they promise to maintain most of the high flexibility that an FPGA offers while providing  improved energy consumption and performance for many applications.
Furthermore, the more constrained architecture template of a CGRA alleviates %lightens 
the burden of application mapping, thereby benefiting % This both aides 
human developers working on application mapping while %and as well as helps to 
simplifying the task of high-level synthesis tools. 


\subsection{Network-on-Chip (NoC)}
% \paragraph{Background}
NoCs play an important role in the development of complex, multi-core system on chips (SoCs), addressing the limitations of traditional bus architectures in scalability, bandwidth, and power efficiency. As embedded systems require advanced functionalities, leading to an increased number of processing elements (PEs) integrated into SoCs, the demand for efficient communication architectures has escalated. NoCs provide a scalable solution by facilitating parallel data transmission among multiple PEs through router-based packet switching networks. Complex hardware designs on FPGAs rely on %make use of 
NoCs to improve the efficiency of data communication. In addition, FPGAs serve as a popular platform in NoC development due to their reconfigurable nature, allowing for evaluating, prototyping and testing of various NoC architectures with different topologies and routing strategies. This flexibility is crucial in optimizing NoCs for specific applications, including real-time systems, where timely data delivery within predefined deadlines is essential.

\subsubsection*{\bf{Research topics}}
A number of papers have been published by Dutch organizations that focus on enhancing NoC architectures for real-time applications on FPGA platforms. %Specifically, 
These papers introduce novel NoC designs that aim to address the challenges of designing NoCs on FPGAs while minimizing hardware resources and power consumption. 
% \begin{itemize}
% \item \textbf{In-order NoCs}. Traditional deflection-based NoCs, while efficient in resource usage, struggle with maintaining the order of flits, which is critical for various applications. IPDeN addresses this challenge and ensures in-order flit delivery by incorporating a small, constant-size buffer in each router. This architecture  significantly reduces the hardware resources required compared to virtual channel based solutions~\cite{IPDeN}.
% \item \textbf{FPGA optimized NoCs}. To address the increasing communication volume between computation nodes integrated in FPGAs, HopliteRT* proposes an NoC architecture for real-time systems that is optimized for the constraints of FPGA platforms. HopliteRT* supports priority-based routing, and a novel network topology to improve worst-case packet traversal time. Experiments show that the proposed NoC allows for at least 2× improvement of traversal time of high priority packets for negligible additional hardware costs~\cite{HopliteRT*}.
% \item \textbf{Predictable NoCs}. Worst-case communication time analysis in NoCs is an important topic in real-time system design, but is rather challenging due to the unpredictable nature of NoC communication. nDimNoC is a new D-dimensional NoC that provides real-time guarantees for SoC systems that uses the properties of circulant topologies to ensure bounded worst-case communication delays. nDimNoC requires 5x less silicon than routers that use virtual channels~\cite{nDimNoC}.
% \end{itemize}
\paragraph{In-order NoCs} Traditional deflection-based NoCs, while efficient in resource usage, struggle with maintaining the order of flits, which is critical for various applications. IPDeN~\cite{IPDeN} addresses this challenge and ensures in-order flit delivery by incorporating a small, constant-size buffer in each router. This architecture  significantly reduces the hardware resources required compared to virtual-channel-based solutions.
\paragraph{FPGA optimized NoCs} To address the increasing communication volume between computation nodes integrated in FPGAs,  \citet{HopliteRT*} propose
HopliteRT*, %proposes 
a NoC architecture for real-time systems that is optimized for the constraints of FPGA platforms. HopliteRT* supports priority-based routing and a novel network topology to improve worst-case packet traversal time. Experiments show that the proposed NoC allows for at least 2\(\times\) improvement of traversal time of high priority packets for negligible additional hardware costs.
\paragraph{Predictable NoCs} Worst-case communication time analysis in NoCs is an important topic in real-time system design, but is rather challenging due to the unpredictable nature of NoC communication. nDimNoC~\cite{nDimNoC} is a new D-dimensional NoC that provides real-time guarantees for SoC systems. nDimNoC uses the properties of circulant topologies to ensure bounded worst-case communication delays. It requires 5x less silicon than routers that use virtual channels.


\subsubsection*{\bf{Future directions}} 
Future research on FPGA-based NoCs is expected to focus on further optimizations for real-time applications and efficient hardware utilization. New, more sophisticated routing policies and buffer management strategies can be explored to further enhance throughput and reduce latency. Commercial architectures such as the AMD Versal Adaptive SoC already contain hard NoC infrastructure. 
Given that data movement is a dominant challenge for many applications, it is likely that similar advancements will be adopted in other FPGA devices. Additionally, NoC architectures can be further developed to support dynamically changing workloads and applications with varying timing properties without necessitating network reconfiguration. This adaptability is important in addressing the evolving needs of real-time and embedded systems, where the workload can vary over time. Furthermore, intelligent routing algorithms, such as those based on machine learning, are a promising avenue for future NoC research. This approach could lead to more adaptive and efficient NoC designs that are capable of self-optimization based on current network conditions and application requirements. 
