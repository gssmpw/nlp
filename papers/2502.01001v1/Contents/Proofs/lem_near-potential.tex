\begin{proof}
\label{prf:lem:near-potential}

\emph{Step 1: The uniqueness of NE.}

We prove the uniqueness of NE mainly by constructing a contraction mapping and using Banach fixed-point theorem.
The contraction mapping is constructed by a discretized version of the best-response dynamic:
\begin{align*}
    x'_i = g_i(\bmx) = x_i + \varepsilon \gamma_i \frac{\pp u_i}{\pp x_i}(x_i, \bmx_{-i}),\quad \forall \iinn
\end{align*}
for some $\varepsilon > 0$ small enough. Now we prove that $g: X \to X$ is a contraction mapping.

Consider two effort profiles $\bmx, \bmy \in X$, we have that
\begin{align*}
    \| g(\bmx) - g(\bmy) \|^2 =& \sum_\iinn \left( g_i(\bmx) - g_i(\bmy) \right)^2
    \\
    =& \sum_\iinn \left( x_i + \varepsilon\gamma_i \frac{\pp u_i}{\pp x_i}(x_i, \bmx_{-i}) - y_i - \varepsilon\gamma_i \frac{\pp u_i}{\pp x_i}(y_i, \bmy_{-i}) \right)^2
    \\
    =& \| \bmx - \bmy \|^2 + \varepsilon \langle \bmx - \bmy, \gamma_i\left(\frac{\pp u_i}{\pp x_i}(x_i,\bmx_{-i}) - \frac{\pp u_i}{\pp x_i}(y_i,\bmy_{-i})\right)_\iinn\rangle
    \\
    +& \varepsilon^2 \sum_\iinn\gamma_i^2 \left( \frac{\pp u_i}{\pp x_i}(x_i,\bmx_{-i}) - \frac{\pp u_i}{\pp x_i}(y_i,\bmy_{-i}) \right)^2
\end{align*}

We focus on the $\varepsilon$ term:
\begin{align*}
    & \langle \bmx - \bmy, \gamma_i \left( \frac{\pp u_i}{\pp x_i}(x_i,\bmx_{-i}) - \frac{\pp u_i}{\pp x_i}(y_i,\bmy_{-i}) \right)_\iinn \rangle
    \\
    =& \langle \bmx - \bmy, \frac{\pp u}{\pp \bmx}(\bmx) - \frac{\pp u}{\pp \bmx}(\bmy) \rangle
    + \langle \bmx - \bmy, \left( \frac{\pp (\gamma_i u_i - u)}{\pp x_i}(x_i,\bmx_{-i}) - \frac{\pp (\gamma_i u_i - u)}{\pp x_i}(y_i,\bmy_{-i}) \right)_\iinn \rangle
\end{align*}
Since the $c$-concavity of $u(\bmx)$, we have
\begin{align*}
    \langle \bmx - \bmy, \frac{\pp u}{\pp \bmx}(\bmx) - \frac{\pp u}{\pp \bmx}(\bmy) \rangle \le -c \| \bmx - \bmy \|^2
\end{align*}
By $\sigma_{ij}$-Lipschitzness of $\frac{\pp (\gamma_i u_i - u)}{\pp x_i}(\bmx)$ on $x_j$, we have
\begin{align*}
    & \langle \bmx - \bmy, \left( \frac{\pp (\gamma_i u_i - u)}{\pp x_i}(x_i,\bmx_{-i}) - \frac{\pp (\gamma_i u_i - u)}{\pp x_i}(y_i,\bmy_{-i}) \right)_\iinn \rangle 
    \\
    \le& \sum_\iinn \left( \frac{\pp (\gamma_i u_i - u)}{\pp x_i}(x_i,\bmx_{-i}) - \frac{\pp (\gamma_i u_i - u)}{\pp x_i}(y_i,\bmy_{-i}) \right) |x_i - y_i|
    \\
    \le& \sum_\iinn \sum_\jinn \sigma_{ij} |x_j - y_j| |x_i-y_i|
    \\
    =& \| \bmx - \bmy \|^2 \sum_\iinn \sum_\jinn \sigma_{ij} z_i z_j
    \\
    =& \| \bmx - \bmy \|^2 \bmz^T \Sigma \bmz
    \\
    \le& \sigma_{max}(\Sigma) \| \bmx - \bmy \|^2
\end{align*} 

where in the third equality, $z_i \coloneqq \frac{|x_i - y_i|}{\| \bmx - \bmy\|}$, we have $\| z_i \| = 1$. Also notice that $\sigma_{max}(\Sigma) = \max_{\|\bmz\| = \|\bmz'\| = 1} \bmz^T \Sigma \bmz'$.

Therefore, the $\varepsilon$ term:
\begin{align*}
    & \langle \bmx - \bmy, \gamma_i\left( \frac{\pp u_i}{\pp x_i}(x_i,\bmx_{-i}) - \frac{\pp u_i}{\pp x_i}(y_i,\bmy_{-i}) \right)_\iinn \rangle
    \\
    \le& (\sigma_{max} - c) \| \bmx - \bmy \|^2
\end{align*}

Therefore, we can choose $\varepsilon$ so small such that $\| g(\bmx) - g(\bmy) \|^2 \le (1 + \frac{\varepsilon}{2}(\sigma_{max} - c)) \| \bmx - \bmy \|^2 < \| \bmx - \bmy \|^2$ for all $\bmx,\bmy$, which indicates that $g$ is a contraction mapping. By Banach fixed-point theorem, we know that there exists a unique fixed point $\bmx^*$ of $g$, which means that there is a unique $\bmx^*$ such that $\frac{\pp u_i}{\pp x_i}(\bmx^*) = 0$ for all $i$, indicating that $\bmx^*$ is the unique NE.

\emph{Step 2: The exponential convergence rate.}

To do this, we aim at constructing an energy function $E(\bmx)$ such that it holds the following properties:
\begin{itemize}
    \item $E(\bmx) \ge 0$ for all $\bmx$, the equality holds if $\bmx = \bmx^*$.
    \item $\frac{\dd E(\bmx(t))}{\dd t} \le -p_0 E(\bmx(t))$ for some $c_0 > 0$.
\end{itemize}

As long as these properties hold, we immediately get that $E(\bmx(t)) \le E(\bmx(0)) \exp(-p_0 t)$. Then taking $c_0 = p_0$ completes the proof.

We first define the energy function $E(\bmx) = u(\bmx^*) - u(\bmx) + \langle \bmx - \bmx^* , \nabla u(\bmx^*) \rangle$. Since $u(\bmx)$ is a concave function, we know that,
\begin{align*}
    u(y) - u(x) \le \langle y-x, \nabla u(x)\rangle
\end{align*}
Take $x = \bmx^*$ and $y = \bmx$, we derive that $E(\bmx) \ge 0$ for all $\bmx$. When $\bmx = \bmx^*$, we have $E(\bmx^*) = 0$. We also know that $E(\bmx)$ is $c$-strongly convex function.

By little computation and define $v_i(\bmx) = \gamma_i u_i(\bmx) - u(\bmx)$, we have
\begin{align*}
    \frac{\pp E}{\pp \bmx}(\bmx) =& \left(- \frac{\pp u}{\pp \bmx}(\bmx) + \frac{\pp u}{\pp \bmx}(\bmx^*)\right)
    \\
    \frac{\dd x_i}{\dd t}(t) =& \gamma_i \frac{\pp u_i}{\pp x_i}(\bmx(t))
    = \frac{\pp v_i}{\pp x_i}(\bmx(t)) + \frac{\pp u}{\pp x_i}(\bmx(t))
    = \frac{\pp v_i}{\pp x_i}(\bmx(t)) + \frac{\pp u}{\pp x_i}(\bmx^*) - \frac{\pp E}{\pp x_i}(\bmx(t))
\end{align*}

Next, we compute the derivative of $E(\bmx(t))$:
\begin{align*}
    \frac{\dd E}{\dd t}(\bmx(t))
   & =\langle \frac{\pp E}{\pp \bmx}(\bmx(t)), \frac{\dd \bmx}{\dd t}(t)\rangle
    \\
    =& - \| \frac{\pp E}{\pp \bmx}(\bmx(t)) \|^2 \cdots\text{first term}
    \\
    +& \langle \frac{\pp E}{\pp \bmx}(\bmx(t)), \frac{\pp u}{\pp \bmx}(\bmx^*) \rangle
    + \sum_\iinn \frac{\pp v_i}{\pp x_i}(\bmx(t)) \frac{\pp E}{\pp x_i}(\bmx(t)) \cdots\text{second term}
    \\
\end{align*}

% The first term satisfies,
% \begin{align*}
%     - \| \frac{\pp E}{\pp \bmx}(\bmx(t)) \|^2 \le -2c E(\bmx(t))
% \end{align*}


We also know $\frac{\pp u_i}{\pp x_i}(\bmx^*) = 0$ by definition of NE.
Combining them in the second term, we achieve,
\begin{align*}
    \text{second term} =& \sum_\iinn \frac{\pp E}{\pp x_i}(\bmx(t))\cdot \frac{\pp u}{\pp x_i}(\bmx^*)
    + \sum_\iinn \frac{\pp v_i}{\pp x_i}(\bmx(t)) \cdot \frac{\pp E}{\pp x_i}(\bmx(t))
    \\
    =& \sum_\iinn \frac{\pp E}{\pp x_i}(\bmx(t))\cdot \frac{\pp (u - \gamma_i u_i)}{\pp x_i}(\bmx^*)
    + \sum_\iinn \frac{\pp v_i}{\pp x_i}(\bmx(t)) \cdot \frac{\pp E}{\pp x_i}(\bmx(t))
    \\
    =& - \sum_\iinn \frac{\pp E}{\pp x_i}(\bmx(t))\cdot \frac{\pp v_i}{\pp x_i}(\bmx^*)
    + \sum_\iinn \frac{\pp v_i}{\pp x_i}(\bmx(t)) \cdot \frac{\pp E}{\pp x_i}(\bmx(t))
    \\
    =& \sum_\iinn \frac{\pp E}{\pp x_i}(\bmx(t))\cdot (\frac{\pp v_i}{\pp x_i}(\bmx(t)) - \frac{\pp v_i}{\pp x_i}(\bmx^*))
    \\
\end{align*}

Denote $\Delta v_i = \frac{\pp v_i}{\pp x_i}(\bmx(t)) - \frac{\pp v_i}{\pp x_i}(\bmx^*)$ and $\Delta \bmv = (\Delta v_1,...,\Delta v_n)$, we have,
\begin{align*}
    \text{second term} =& \langle \frac{\pp E}{\pp \bmx}(\bmx(t)), \Delta \bmv \rangle
    \\
    \le & \|\frac{\pp E}{\pp \bmx}(\bmx(t))\| \|\Delta \bmv\|
\end{align*}

We also know that $\frac{\pp v_i}{\pp x_i}$ is $\sigma_{ij}$-Lipschitz on $x_j$, now we consider $\| \Delta v_i\|$,
\begin{align*}
    \|\Delta v_i \| =& \max_{\|z \|=1} \sum_\iinn z_i \Delta v_i
    \\
    \le& \max_{\|z \|=1} \sum_\iinn\sum_\jinn z_i \sigma_{ij} |x_j(t) - x_j^*|
    \\
    \le& \| \bmx(t) - \bmx^* \| \max_{\|z \|=1, \| y\| =1} \sum_\iinn\sum_\jinn \sigma_{ij} z_i y_j
    \\
    =& \| \bmx(t) - \bmx^* \| \sigma_{max}(\Sigma)
    \\
    \le& \frac{\sigma_{max}(\Sigma)}{c} \| \frac{\pp E}{\pp \bmx}(\bmx(t))\|
\end{align*}

Combining these, we have,
\begin{align*}
    \frac{\dd E}{\dd t}(\bmx(t)) \le& -(1-\frac{\sigma_{max}(\Sigma)}{c}) \| \frac{\pp E}{\pp \bmx}(\bmx(t))\|^2
    \\
    \le& -2(c - \sigma_{max}(\Sigma)) E(\bmx(t))
\end{align*}

Take $p_0 = 2(c - \sigma_{max}(\Sigma))$, we complete the proof.


\end{proof}