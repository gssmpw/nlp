\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
% \usepackage{lineno}
% \linenumbers

% included as dependencies of the table I created on `tablesgenerator.com`
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{soul}
\usepackage{bm}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}
\usepackage{nameref}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[para]{threeparttable}
\usepackage{pdflscape}
\usepackage{rotating}
\usepackage{tablefootnote}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage[edges]{forest}

\definecolor{foldercolor}{RGB}{124,166,198}

\tikzset{pics/folder/.style={code={%
    \node[inner sep=0pt, minimum size=#1](-foldericon){};
    \node[folder style, inner sep=0pt, minimum width=0.3*#1, minimum height=0.6*#1, above right, xshift=0.05*#1] at (-foldericon.west){};
    \node[folder style, inner sep=0pt, minimum size=#1] at (-foldericon.center){};}
    },
    pics/folder/.default={20pt},
    folder style/.style={draw=foldercolor!80!black,top color=foldercolor!40,bottom color=foldercolor}
}

\forestset{is file/.style={edge path'/.expanded={%
        ([xshift=\forestregister{folder indent}]!u.parent anchor) |- (.child anchor)},
        inner sep=1pt},
    this folder size/.style={edge path'/.expanded={%
        ([xshift=\forestregister{folder indent}]!u.parent anchor) |- (.child anchor) pic[solid]{folder=#1}}, inner xsep=0.6*#1},
    folder tree indent/.style={before computing xy={l=#1}},
    folder icons/.style={folder, this folder size=#1, folder tree indent=3*#1},
    folder icons/.default={12pt},
}

\title{UNB StepUP: A footStep database for gait analysis and recognition using Underfoot Pressure}

\author[1]{Robyn Larracy}
\author[1]{Angkoon Phinyomark}
\author[1]{Ala Salehi}
\author[1]{Eve MacDonald}
\author[1]{Saeed Kazemi}
\author[1]{Shikder Shafiul Bashar}
\author[1]{Aaron Tabor}
\author[1,*]{Erik Scheme}
\affil[1]{University of New Brunswick, Institute of Biomedical Engineering, Fredericton, E3B 5A3, Canada}

\affil[*]{corresponding author: Erik Scheme (escheme@unb.ca)}
%\affil[$\dag$]{these authors contributed equally to this work}

%%% The abstract must be no longer than 170 words, and should succinctly describe the study, the assay(s) performed, the resulting data, and the reuse potential, but should not make any claims regarding new scientific findings.
\begin{abstract}
Gait refers to the patterns of limb movement generated during walking, which are unique to each individual due to both physical and behavioural traits. 
Walking patterns have been widely studied in biometrics, biomechanics, sports, and rehabilitation. 
While traditional methods rely on video and motion capture, advances in underfoot pressure sensing technology now offer deeper insights into gait. 
However, underfoot pressures during walking remain underexplored due to the lack of large, publicly accessible datasets. 
To address this, the UNB StepUP database was created, featuring gait pressure data collected with high-resolution pressure sensing tiles (4 sensors/cm\textsuperscript{2}, 1.2m by 3.6m). 
Its first release, UNB StepUP-P150, includes over 200,000 footsteps from 150 individuals across various walking speeds (preferred, slow-to-stop, fast, and slow) and footwear types (barefoot, standard shoes, and two personal shoes). 
As the largest and most comprehensive dataset of its kind, it supports biometric gait recognition while presenting new research opportunities in biomechanics and deep learning. 
The UNB StepUP-P150 dataset sets a new benchmark for pressure-based gait analysis and recognition.
\end{abstract}

\begin{document}

\flushbottom
\maketitle
%  Click the title above to edit the author information and abstract

\thispagestyle{empty}

% \noindent Please note: Abbreviations should be introduced at the first mention in the main text – no abbreviations lists or tables should be included. Structure of the main text is provided below.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Background \& Summary}

%%% (700 words maximum) An overview of the study design, the assay(s) performed, and the created data, including any background information needed to put this study in the context of previous work and the literature. The section should also briefly outline the broader goals that motivated the creation of this dataset and the potential reuse value. We also encourage authors to include a figure that provides a schematic overview of the study and assay(s) design. The Background \& Summary should not include subheadings. This section and the other main body sections of the manuscript should include citations to the literature as needed. 

% Par 1: Gait Analysis
Gait analysis has long been a critical area of study within biometrics, biomechanics, sports, and rehabilitation. 
The unique patterns of human walking provide valuable insight into an individual's identity, health status, athletic performance, and even potential underlying medical conditions. 
Although traditional methods of gait analysis have relied heavily on video-based systems and motion capture technologies, recent advances in sensor technology have opened new avenues for capturing and analyzing gait patterns. 
Among these, underfoot pressure measurement has appeared as a promising avenue due to its potential to provide detailed insights into footstep patterns, including the pressure exerted at different points under the foot and temporal changes in these patterns throughout the gait cycle. 
Despite its potential, this modality remains under-researched \cite{ConnorRoss2018}, especially with regard to the development of large, publicly available datasets, thereby limiting the exploration of modern advanced deep learning algorithms for gait analysis and recognition.

% Par 2: UNB StepUp database
Despite the availability of many other gait databases and datasets, the majority concentrate on video-based systems, motion capture technologies, and wearable devices \cite{Singh2018,Wan2018,SepasMoghaddamEtemad2023,dosSantos2023}. 
Databases that include floor sensor technology generally collect data from force plates, as seen in the GaitRec \cite{Horsak2020}, Gutenberg \cite{Horst2021}, and ForceID A \cite{Duncanson2023} datasets, which provide more constrained and less comprehensive information than the complex spatio-temporal data offered by emerging high-resolution pressure sensors. 
Conversely, databases that emphasize high-resolution underfoot pressure data, such as the CASIA-D \cite{Zheng2011}, SFootBD \cite{VeraRodriguez2013a}, CAD WALK \cite{Booth2018}, and UoM-Gait-69 \cite{CostillaReyes2021} datasets, usually address a limited scope, often with little or no consideration of covariates that may confound performance, and generally involve small sample sizes for subjects and walking trials, thereby under-representing real-world scenarios. 
% add definition of covariates 
To fill this gap, UNB StepUP: A footStep database for gait analysis and recognition using Underfoot Pressure, was developed. 
The purpose of creating the UNB StepUp database is to compile a diverse range of datasets that include detailed foot pressure measurements, explore various covariate factors, involve a large number of participants, and encompass numerous walking trials. 
The initial StepUP experiments include three separate studies, each characterized by unique covariates: (1) walking speed and footwear, (2) different sessions (returning from study 1) and load carriage (e.g. carrying objects of different shapes and weights), and (3) walking environment, clothing, viewing angle (in terms of sensor orientation and placement relative to the subject), and dual-task gait (which involves walking while simultaneously engaging in a secondary task). 
In addition to pressure data, concurrent multi-angle video recordings and digital footprints and shoeprints were also recorded and will be shared as separate complementary and matched datasets in the future.

% Par 3: UNB StepUP-P150 dataset
This initial paper on the UNB StepUP database presents the UNB StepUP-P150 dataset, derived from the first of the three studies. 
The designation P150 refers to pressure data collected from 150 participants. 
The dataset includes more than 200,000 footsteps from 150 individuals, covering a range of walking speeds (self-paced, self-paced with a stop at the end, fast, and slow) and different types of footwear (barefoot, standard shoes, and two types of personal shoes), making it the most comprehensive openly available collection of its kind (Table \ref{tab:datasets}). 
The primary method for data collection involved high-resolution pressure tiles (a walkway of dimensions 1.2 meters by 3.6 meters, containing 240 by 720 pressure sensors) to capture the pressure distribution of each footstep during natural gait. 
A total of 24 minutes of walking data were collected from each participant, spread across 16 different walking conditions (4 walking speeds $\times$ 4 types of footwear) at 90 seconds per condition, resulting in approximately 1,400 steps per individual. 
Compared to the largest previously published footstep database, SFootBD, which recorded nearly 20,000 footsteps from 127 individuals \cite{VeraRodriguez2011}, with only 5 subjects contributing more than 1,000 footsteps each, this initial UNB StepUP-P150 dataset surpasses SFootBD by more than tenfold, making it the largest footstep dataset to date.

% Par 4: Technical Validation
The UNB StepUP-P150 dataset consists of raw trial-by-trial pressure data along with preprocessed data segmented by each footstep. % , both with and without foot alignment. 
This dual format allows users to either work directly with the raw data or leverage the pre-processed data for rapid prototyping and analysis. 
To ensure its quality and consistency, the foot pressure data was subjected to thorough quality control and pre-processing, such as footstep segmentation, foot alignment, and temporal normalization. %noise filtering, and feature extraction. 
This information is complemented by contextual metadata detailing the demographics of the participants and the conditions under which the data were collected (including variables such as walking speed, footwear types, foot side, and incomplete footsteps), providing a comprehensive and fully annotated gait resource for researchers. 
In addition, video data were used for visual examination of gait events and patterns, helping to verify uncertain labels generated by automatic algorithms and providing additional context during the preprocessing and manual inspection of pressure data. 
The finalized dataset is designed for ease of use by researchers and is compatible with various analytical tools, including support of both NPZ (Python) and MAT (MATLAB) file formats.

% Par 5: Broader goals and potential reuse value
The primary aim of the UNB StepUP database is to support the advancement of gait analysis and gait recognition, motivated by applications in biometric systems. 
To mitigate demographic biases within the dataset, the study includes participants of various ages, sexes/genders, races/ethnicities, and body sizes. %, and socioeconomic statuses. 
This ensures that the dataset accurately captures the broad variability inherent in human gait, making it both diverse and representative of the population. 
This diversity is critical for developing generalizable models that can perform accurately across different population groups. 
In developing this gait dataset with attention to demographic bias in biometrics, the UNB StepUP-P150 dataset opens up numerous research opportunities in gait analysis and recognition, extending beyond biometric uses. 
Researchers in fields ranging from biomechanics to machine learning and deep learning can take advantage of the UNB StepUP-P150 to train and test new models, explore the relationship between underfoot pressure and other gait metrics, or investigate how various factors, such as sex, age, walking speed, or footwear, affect gait patterns. 
Furthermore, the dataset can be used as a benchmark for comparing different gait analysis and recognition techniques, thereby contributing to the standardization of methodologies in the field. 
The UNB StepUP-P150 dataset offers a level of detail and comprehensiveness that is unmatched by existing underfoot pressure-based gait datasets, making it possible to explore new avenues of research in gait analysis, footstep recognition, and related areas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Methods}

%%% The Methods should include detailed text describing any steps or procedures used in producing the data, including full descriptions of the experimental design, data acquisition assays, and any computational processing (e.g. normalization, image feature extraction). See the detailed section in our submission guidelines for advice on writing a transparent and reproducible methods section. Related methods should be grouped under corresponding subheadings where possible, and methods should be described in enough detail to allow other researchers to interpret and repeat, if required, the full study. Specific data outputs should be explicitly referenced via data citation (see Data Records and Citing Data, below). %%% Authors should cite previous descriptions of the methods under use, but ideally the method descriptions should be complete enough for others to understand and reproduce the methods and processing steps without referring to associated publications. There is no limit to the length of the Methods section. Subheadings should not be numbered.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Participants}

A total of 180 individuals participated in the study, which took place over a period of 18 months at the University of New Brunswick (UNB) in Fredericton, New Brunswick, Canada. 
The participants consisted of students, staff, and faculty from the university, and community members who were recruited via word-of-mouth and promotional materials circulated in the local community. 
The general inclusion criteria were: (1) at least 18 years of age; (2) able to walk comfortably without assistive devices for 90 seconds at a time with different walking speeds and footwear conditions (24 minutes total); and (3) able and comfortable to balance unassisted, on both feet and on one foot, for 30 seconds at a time with different footwear conditions (6 minutes total). % ; and (4) able to walk and stand without any physical or medical condition for which the protocol would be contraindicated. 
Before collecting data, all participants provided their written informed consent to participate per the Declaration of Helsinki. 
The study protocol was reviewed and approved by the University of New Brunswick's Research Ethics Board (REB 2022-132).

The following factors led to participant exclusion from the final dataset to maintain its quality and integrity: (1) experimental deviations, e.g. unintended behaviour during one or more trials ($N = 2$); (2) missing data, e.g. incomplete protocols or corrupted files ($N = 4$); (3) hardware malfunction, e.g. disconnected sensors significantly affecting recordings ($N = 15$), and (4) no accompanying video data to confirm annotations, as participants did not consent to video collection ($N = 9$). % Note: Some experiments included in our 150 do have minor hardware issues (e.g., minimal number of passes and trials affected), but here we exclude those where data is largely impacted (multiple trials affected, and/or several tiles disconnected during a trial). % Note: we did not specifically exclude participants due to injury, disability, or other mobility conditions, however we asked them to disclose conditions that may impact their gait.
Consequently, 30 participants were removed from the final dataset, resulting in a total of 150 subjects being included. 
Although not made publicly available as part of the UNB StepUP-P150 dataset, portions of the data from these 30 excluded experiments may be used to support future footstep biometric competitions as independent test samples.

Table \ref{tab:demographics} provides a summary of the demographic and anthropometric data for the 150 participants in the study. 
The UNB StepUP-P150 dataset features individuals with an average age of 34 years, spanning from 19 to 91 years. 
This cohort comprises 74 males and 76 females. 
The dataset maintains an approximately balanced sex/gender distribution and includes both younger and older adults, with the age distribution for participants by sex illustrated in Fig. \ref{fig:age_histogram}. 
Most of the participants identify as White ($N=106$, $71\%$), with additional identifications as Asian ($N=36$, $24\%$; 15 Middle Eastern, 10 South Asian, 11 East/Southeast Asian), Other/Multiple ($N=6$, $4\%$; 1 Black, 5 multi-ethnic), and Unknown/Not Specified ($N=2$, $1\%$). 
This reflects an over-representation of visible minority groups relative to the official population distribution in the local community; the proportion of total visible minorities in the database is 28\%, as opposed to the 14\% reported by Statistics Canada \cite{census2023}. 
The dataset also includes participants with a variety of body types and dimensions, including height ranging from 151 to 196 cm, weight between 46 and 148 kg, BMI spanning 17 to 39 kg/m\textsuperscript{2}, foot length measuring 20 to 30 cm, foot width between 7 and 11 cm, and UK shoe sizes from 4 to 12.5 (Fig. \ref{fig:shoesize_histogram}). 
Figure \ref{fig:anthropometric} shows the distribution of participants' body sizes and foot measurements, categorized by both sex and ethnicity/race.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Instrumentation}

% tiles
Pressure data from footsteps were collected using a specialized runway (Fig. \ref{fig:sensor_setup}), which featured a $2\times6$ grid of commercial pressure sensing tiles developed by Stepscan Technologies Inc. 
The runway has a total active recording area of 1.2 m $\times$ 3.6 m, allowing for the collection of multiple consecutive steps (typically 4-6 steps). 
Each modular 60 cm $\times$ 60 cm tile is made up of a $120 \times 120$ sensor grid, corresponding to a spatial resolution of 4 sensors/cm$^2$. 
The set of 172,800 ($240\times720$) embedded sensors can detect pressures within a range of 1,510 kPa, have a threshold sensitivity of 10 kPa, feature a resolution below 10 kPa, and were sampled at a rate of 100 Hz during the recording process. 
To increase system durability, particularly in areas experiencing high foot traffic and the use of outdoor footwear, as anticipated in the practical application of this study, the manufacturer tailored the tiles with a 6 mm protective layer made of Ramflex double-layered vulcanized rubber flooring, instead of the usual 2 mm thickness commonly applied in clinical usage of this technology in healthcare applications. 
These tiles were installed in a laboratory reserved for data collection and stayed there throughout the entire study. 
A non-instrumented wooden platform was also constructed around the tile grid, extending 1.4 meters at each end of the runway. 
The platform was flush with the tiles to allow natural walking behaviour, eliminating the need to step up or down and providing room for the participants to turn during the experiment (Fig. \ref{fig:sensor_setup}). 
It should be noted that the pressure-sensitive tiles are pre-calibrated by the manufacturer (Stepscan Technology Inc.), and did not require on-site calibration. 
Each tile comes with factory-set parameters that align the signal characteristics of each physical pressure sensor with a common logical signal domain. 
The companion data collection application automatically implements these corrections, ensuring that they are reflected in all data within this dataset. 
Therefore, no further calibration efforts were undertaken by the research team.

% cameras, % scanner
In addition to pressure-sensing tiles, seven RGB video cameras (QCN8068BA, Q-See, USA) with a resolution of 1440p ($2560\times1440$) and a frame rate of 20 fps were strategically installed around the room. % Note: we lowered the resolution to 1080p (1920 x 1080) for space & speed
These cameras were positioned to record participants' gait from various angles: approximately 0\textdegree, 45\textdegree, 90\textdegree, 135\textdegree, 225\textdegree, 270\textdegree, and 315\textdegree~with respect to the major axis of the tile grid (Fig. \ref{fig:sensor_setup}). 
Participants in the UNB StepUP-P150 dataset consented to have their sessions videotaped, producing seven separate video recordings for each pressure data capture. 
In addition, a flatbed scanner (OpticSlim 1180, Plustek, USA) with an optical resolution of 1200 dpi, 48-bit color input, and a scanning area of 29.7 cm $\times$ 43.18 cm was used to acquire digital scans of the participant's two pairs of personal footwear that they brought to their session. % Note: we have it set to optical resolution of 300p (they only recommend 100p for color, for speed & space)
The pressure and video recordings were captured simultaneously on two networked desktop computers, connected via the Secure Shell (SSH) protocol, and time-synchronized using the Network Time Protocol (NTP). 
Each recording was time-stamped to enable precise offline synchronization of the data from the two sensor types.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Experimental Protocol}

Figure~\ref{fig:protocol_tasks} provides a summary of the 90-minute experimental protocol. 
The initial preparation session takes around 30 minutes, followed by balance and walking sessions that last for about an hour. 
Before starting the walking trials, three separate 30-second balance tests were performed for each type of footwear. 
The walking experiment then involved sixteen 90-second walking trials, featuring four different footwear conditions, each executed at four distinct walking speeds. 
As a result, there were seven recorded trials for each type of footwear (consisting of three 30-second balance tasks and four 90-second walking tasks), resulting in 28 trials overall and a total recording duration of 30 minutes. 
Participants were allowed to take breaks and rest between trials as needed, and whenever there was a need to change shoes, a minimum of 2 minutes was allocated for breaks. 
To minimize the potential impact of any fatigue that may affect recorded gait patterns, the order of footwear and walking speed conditions was randomized for each participant (see Fig. \ref{fig:protocol_tasks} for an example sequence). 
The subsequent sections provide a more detailed explanation of different tasks and conditions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Preparation of the Participant}

Before the scheduled collection session, the participants were informed that the session would consist of a series of walking and balance tasks, and they were asked to bring along two pairs of their own shoes for the experiment. 
Upon their arrival, participants received an overview of the experiment's procedure and provided their signatures on the informed consent form (UNB REB 2022-132). 
The participants subsequently filled out a form to provide essential demographic details, including sex, gender, birth year, race or ethnicity (options included Aboriginal, Black, East/Southeast Asian, Latino, Middle Eastern, South Asian, White, or Other), along with pertinent physical information that could influence their gait patterns, such as any recent injuries and which leg is dominant, determined by answering ``Which foot would you normally use to kick a stationary ball straight in front of you?''\cite{vanMelick2017}. 
For the precise determination of the anthropometric parameters, the experimenter helped the participants measure their height, body weight, and foot size. 
Body weight was measured using a Withings body smart scale, height with a Seca 213 portable stadiometer, and foot length and width with an adult Brannock device. 
In addition, digital shoe sole scans were obtained from the two pairs of participant-provided footwear, with the sizes, brands, and descriptions of each shoe documented. 
The participants were then equipped with a pair of standard shoes supplied by the research team, specifically Adidas Grand Court 2.0 unisex sneakers, available in sizes from US Men's size 4 (Women's size 5) to US Men's size 13 (Women's size 14), inclusive of half sizes. 
This is equivalent to UK sizes 3.5 to 12.5.
Participants were instructed to select the size that offered the most comfort and to take a few steps in the shoes to verify fit. 
Their preferred sizes were thereafter documented.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Balance Tasks}

Before each balance and walking trial, participants received a brief reminder about the desired task. 
The recording software emitted an audible ``beep'' to signify the beginning of the trial and participants were instructed to continue their task until the experimenter signaled the end of the trial. 
For the three balance tasks, the participants stood for 30 seconds at a time on \textbf{both feet (S1)}, on their \textbf{left foot (S2)}, and on their \textbf{right foot (S3)}. 
They were asked to select one location on the tiles and to remain stationary for the duration of the recording and were not permitted to use any external supports during these trials (e.g., holding onto a chair). 
If they lost balance during recording, they were asked to re-adjust as necessary and attempt to continue the task until the 30 seconds were complete.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Walking Tasks: Walking Speed}

For the walking trials, the participants were instructed to walk back and forth across the tiles naturally for 90 seconds, specifically along the longer 3.6 m grid direction, making use of the non-instrumented portion of the platform to turn around (Fig. \ref{fig:sensor_setup}). 
The four walking speed conditions were as follows:
\begin{itemize}
\item \textbf{Preferred Speed (W1)}: Participants were instructed to walk at a natural, self-selected (moderate) pace that was comfortable to them. 
\item \textbf{Slow-to-Stop (W2)}: Participants were instructed to walk at their preferred speed, slowing to an abrupt, two-foot stop at the end of each pass on the tile grid, maintaining this stop for approximately 1 second. This condition was designed to mimic the walking behaviour of approaching a controlled access point or security turnstile (e.g., metro, secured office building), focusing on capturing changes in walking speed. 
\item \textbf{Fast (W3)}: Participants were instructed to walk at a pace faster than their naturally chosen speed (self-selected faster walking). 
\item \textbf{Slow (W4)}: Participants were instructed to walk at a pace slower than their naturally chosen speed (self-selected slower walking).
\end{itemize}

The average self-selected preferred (moderate) pace was 1.12 m/s, the average fast speed was 1.45 m/s (which is $26\%$ faster) and the average slow speed was 0.83 m/s (which is $29\%$ slower) (Fig.~\ref{fig:speed_boxplot}). 
It should be noted that during the trials, the participants had the freedom to choose how they navigated their walking paths, including making 180-degree turns between passes in any way they preferred. 
However, the experimenters advised the participants to change their turning directions and/or pause on the non-instrumented landing when necessary to reduce the possibility of dizziness.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Walking Tasks: Footwear}

The trials were completed with four different footwear conditions as described below:
\begin{itemize}
\item \textbf{Barefoot (BF)}: without shoes. Participants had the option to conduct these trials either with socks ($N = 114$) or completely barefoot ($N = 36$). This decision is recorded in the \textit{BFType} metadata field. 
\item \textbf{Standard Shoe (ST)}: a common pair of flat-soled casual sneakers (Adidas Grand Court 2.0). 
\item \textbf{Personal Shoes (P1 and P2)}: two pairs of personal shoes frequently worn in everyday situations. The personal shoes included a wide range of different shoe types, which have been broadly categorized as athletic sneakers (e.g., road running shoes, indoor trainers), casual sneakers (e.g., skate shoes, court-inspired sneakers, high-top leather sneakers), sandals (e.g., slides, flip-flops, ankle-strap sandals), flat canvas shoes (e.g., lace-up or slip-on shoes with canvas upper), boots (e.g., winter boots, steel-toe work boots, Chelsea boots), business/dress shoes (e.g., high heels, ballet flats, oxfords), hiking/trail shoes (e.g., trail running shoes, outdoor walking shoes), and other (e.g., foam clogs, minimal shoes). Figure \ref{fig:shoe_histogram} presents the breakdown of shoes brought in by the participants, grouped into these eight categories. The most commonly brought shoes were athletic sneakers ($N = 114$), followed by casual sneakers ($N = 53$) and sandals/flip flops ($N = 35$). 
A smaller number of shoes with unique pressure patterns, such as high heels ($N = 3$) and steel or composite toe work boots ($N = 5$), were also acquired.
\end{itemize}

Figure \ref{fig:footstep_progression} shows the time series of pressure images for an individual taking a single footstep, highlighting changes in the percentage of stance phase across four different footwear conditions, whereas Figure \ref{fig:P100s} illustrates variations in peak pressure profiles across different participants and shoe types.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Additional Covariates}

Although not explicitly elicited or controlled in the first data collection protocol, several additional covariates may be present in the UNB StepUP-P150 dataset and introduce complexity from the perspective of gait biometrics and gait recognition. 
As noted previously, these covariate factors are controlled and examined in the second and third protocols.

\begin{itemize}
\item \textbf{Viewing angle}: Changes in a sensor's ``view,'' including its alignment and positioning relative to the subject, pose a significant challenge, especially in vision and accelerometry modalities. In pressure-based gait, the alignment of the foot relative to the sensing platform may be considered as the viewing angle. This concern has not been extensively addressed in earlier force-/pressure-based gait studies, primarily due to the constraints of force plate and pressure mat implementations, which allow movement along a single, narrow straight line. Consequently, the foot angles across different trials and subjects are fairly consistent, showing minimal variation with small angles relative to the platform's main axis. In addition, earlier studies frequently advise rotating or aligning foot images to standardize the pressure feature representations. In the present study, although participants usually walked in a straight line, the expanded platform area allowed them to choose their routes. Consequently, there were occasions where the path was slightly curved or diagonal. 
\item \textbf{Clothing}: Changes in an individual's attire can pose a significant challenge, particularly within vision and acoustic modalities, yet they likely have minimal impact on pressure-based gait recognition. This study recommended that participants wear comfortable attire for walking; however, there was no strict regulation or control over their clothing choices. It should be mentioned that none of the 150 participants changed their attire (i.e., other than the \textit{footwear} changes described above) during the 90-minute experiment, resulting in no variation within individual subjects.
\item \textbf{Time elapsed}: While the impact of elapsed time on gait recognition may seem significant, it is primarily attributed to related covariates. The initial and final footsteps collected for each participant in this dataset occur within one hour, with variations in either footwear, walking speed, or both, as determined by a randomized sequence. 
\item \textbf{Load carriage, dual-task gait, and walking environment}: In the initial experiment, participants are not allowed to carry additional weight such as a backpack, engage in secondary tasks like using a mobile phone, or encounter any changes in the walking environment or setting (such as obstacles in the path).
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Data Processing}

Following data collection, each participant's experiment included twelve 30-second balance recordings (three recordings per footwear type) and sixteen 90-second walking recordings (four recordings for each footwear condition), stored as 3D tensors with dimensions of nominally 3000 frames $\times$ 720 pixels $\times$ 240 pixels and 9000 frames $\times$ 720 pixels $\times$ 240 pixels, respectively. 
It should be noted that the duration of trials may differ slightly by a few frames (typically less than 100 frames, equivalent to about one second) as a result of minor delays when beginning or ending the recordings. 
The recordings consist of unprocessed, trial-by-trial data capturing continuous standing or walking on the pressure-sensitive tiles. 
The raw pressure recordings were processed to offer a user-friendly labeled data format suitable for both gait analysis and gait recognition, ensuring quality and consistency.   
The subsequent sections provide a more detailed explanation of the preprocessing steps for the balance and walking trials.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Balance Trial Preprocessing}

During the balance trials, participants were allowed to stand facing any direction and choose any tile(s) to stand on. 
Therefore, for ease of analysis, the balance trial recordings were (1) cropped to focus on the region of interest (ROI) and (2) adjusted to share a common orientation. 
In particular, the areas of activity on the tiles within the 30-second recordings (reflecting pressures from one or both feet) were detected using a threshold of 10 kPa. 
These areas were then extracted from the sensor grid and zero padded to fit a 2D tensor of dimensions $180 \times 180$ pixels. 
To ensure that all recordings are approximately aligned, with the big toe of the right foot directed toward the top left corner and the big toe of the left foot toward the top right corner, the cropped recordings were rotated in 90-degree increments as needed, based on visual inspection.
Temporally, the recordings were cropped by a few frames at the beginning of the trial to a total duration of 3000 frames.
No additional normalization in terms of space, time, or amplitude was performed, resulting in a 3D tensor of 3000 frames $\times$ 180 pixels $\times$ 180 pixels for each trial.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Footstep Detection and Extraction}

For the walking trials, individual steps were identified both spatially and temporally within the raw pressure data to enable analysis on a step-by-step basis. 
Object detection involves determining an object's location and outline, capturing both its center and boundary.
It also includes classifying the object, which, in this context, determines whether or not it is a footstep. 
Footstep detection and tracking in this study were achieved through simple yet efficient techniques, which present possibilities for real-time online implementation during system operation. 
Starting from the first frame, the regions of activity on the tiles at each time point of the recording, potentially indicating contact from one or both feet, were identified using a simple connected pixels object detection technique. 
Specifically, the $720 \times 240$ frames of the recording were first converted to binary images using a threshold of 10 kPa. 
Following this, the frames underwent dilation using a circular structuring element with a radius of 4 and erosion with a circular element of radius 2. 
Subsequently, pixels that were 2-connected (i.e., separated by no more than two orthogonal hops) were clustered to form objects. 
In this research, objects whose centroids were within a specific distance limit, generally set at 20 pixels, were combined since they frequently represented the heel and forefoot of a shoe or foot with a high arch. 
Adjustments to this distance were made to accommodate certain special sole types, including stiletto high heels. 

After identifying the bounding boxes for objects within a frame, SORT (Simple Online and Realtime Tracking) \cite{Bewley2016} was used to track these objects across subsequent frames. 
SORT employs Kalman filtering to predict object locations by integrating a linear motion model with prior positions. 
It connects bounding boxes belonging to the same object over time by assessing the overlap between these predicted states and the actual observed positions. 
This method of footstep extraction produced 3D bounding boxes characterized by dimensions (time, height, width), or ($t, y, x$), for each step, where $x$ and $y$ depend on the size and orientation of the participant's foot, and $t$ changes according to walking speed. 
In addition, these bounding boxes are supplied as footstep metadata. 
Since each pass over the tiles records several consecutive steps (typically 4-6 steps), they enable the computation of various spatiotemporal gait parameters. 
This encompasses important metrics such as gait speed, step length, step width, stance time, swing time, step angle, and walking path, among others.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Footstep Normalization}

To enable more advanced analytic methods, including machine learning and deep learning, it is recommended to store footstep data in tensors, which are essentially multidimensional arrays. 
Since the shape of each footstep varies due to factors such as foot size, foot angle, and walking speed, padding techniques can be employed to standardize spatial and/or temporal dimensions across different steps. 
Applying zero padding helps preserve information related to direct factors, such as foot size and walking speed, within the dataset, which may provide significant information for classification \cite{JlassiDixon2024}. 
Although these methods enable the arrangement of 3D footstep tensors into an array (i.e., higher-dimensional tensors), they do not facilitate the comparison of plantar pressure in the same foot areas, during gait events, or even at consistent pressure scale levels. 
In the literature on gait analysis, normalization techniques have been applied in three distinct domains: spatial normalization (e.g., rotating for the foot progression angle and scaling for foot size), temporal normalization (e.g., interpolating to either 100 or 101 frames to represent the full range from $0\%$ to $100\%$ of the gait cycle), and amplitude normalization (e.g., scaling according to body mass or total foot pressure). 
Although these methods allow for comparisons of footsteps in both spatial and temporal domains, crucial information about subject characteristics might be lost. 
Consequently, it has been shown that merging various preprocessing pipelines may enhance the efficacy of footstep recognition systems \cite{CostillaReyes2019}.

Given the absence of a universally accepted preprocessing pipeline suitable for all deep learning models and their specific classification or recognition tasks \cite{JlassiDixon2024}, the UNB StepUP-P150 dataset provides two different versions of the extracted footsteps as examples, each demonstrating a separate preprocessing approach. 
Together with this, a custom Python script is made available, allowing researchers to generate various other configurations of preprocessing pipelines suited to their unique research needs (refer to Table \ref{tab:preprocessing} for the list of available method options).

\begin{itemize}[noitemsep,topsep=0pt]
\item \textit{Pipeline 1}: The first pipeline includes four steps: (1) spatial rotation, (2) spatial zero padding, (3) spatial translation, and (4) temporal interpolation. 
The footsteps were rotated according to the direction of their first principal component (PC) axis and flipped upright based on their direction of walking.
They were then spatially zero-padded to dimensions of $75 \times 40$ pixels, and translated to align their bounding box's centroid to the center of the padded area.
Lastly, nearest-neighbour interpolation was used to standardize all footsteps to 101 frames, where each frame represents a percentage of the footstep duration. 
This version of the preprocessed footstep data retains information such as foot size and body weight. 
However, information such as foot rotation angle and footstep duration has been uncoupled from the footstep recordings and can be retrieved from the metadata fields labeled as \textit{RotationAngle}, \textit{StartFrame}, and \textit{EndFrame}.
 
\item \textit{Pipeline 2}: The second pipeline builds upon the first by incorporating two additional components: (5) spatial resizing and (6) amplitude normalization using the mean GRF. 
To normalize differences in foot size across participants, the sole dimensions were resized to a common size of 70 pixels in length and 25 pixels in width, corresponding to a size of $35 \times 12.5$ cm for the original sensor resolution. 
The original dimensions of the sole, both length and width, were determined from the aligned footprints by counting the maximum number of active sensors (those with pressure exceeding 10 kPa) present along the two aligned axes during the footstep. 
To achieve the required dimensions, the pressure maps were resized via nearest neighbour interpolation, and samples were spatially zero-padded to $75 \times 40$ pixels for consistency with the other version of the footsteps. 
To normalize amplitude, the sensor data for each step was subsequently rescaled by dividing by the step's average GRF. 
Compared to the initial pipeline, this approach further separates information related to foot size and body weight from the footstep measurements. 
The initial measurements for sole width, sole length, and average GRF are accessible in the \textit{Length}, \textit{Width}, and \textit{MeanGRF} metadata fields.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Labeling}\label{section:labeling}

The process of data labeling (i.e. data annotation) involves assigning target characteristics to training data, enabling statistical analysis or use in machine learning model development. 
In this dataset, labels were derived algorithmically from collected footsteps and subsequently confirmed through manual inspection.

\begin{itemize}[noitemsep,topsep=0pt]
\item \textit{Side}: The left and right labels were determined through a pixel counting method outlined by MacDonald et al. \cite{Macdonald2023}. 
This method involves counting the number of activated sensors beneath various parts of the foot for use in classification.
\item \textit{Orientation}: The orientation of each footstep, corresponding to the participant's direction of walking during each pass across the tiles, was determined by analyzing the COP trajectory of the foot. 
Foot COP is determined by calculating the average position of the foot in each frame, weighted according to the pressure intensities. 
To determine the walking direction, the position of the anteroposterior (AP) COP in the initial portion of the footstep was compared with its position in the latter part. 
A value of 1 indicates walking from Tiles 1 and 2 towards Tiles 11 and 12, while 0 indicates the other direction.
\item \textit{Incomplete}: Incomplete footsteps were defined as footsteps that fell partially outside of the tile grid or outside of the 90-second recording. 
These were detected by flagging footsteps with a starting time of $t = 0$ or an end time of $t = 90$, as well as footsteps that fell near the boundaries of the sensor platform and had a small area. 
Specifically, footsteps with several active sensors that yielded values smaller than three scaled median absolute deviations (MAD) below the median footstep in the trial were flagged.
\item \textit{Standing}: Standing footsteps, observed during the slow-to-stop trials, were also identified by analysis of the COP trajectory of the foot. 
Linear regression using a least-squares method estimated the slope of the AP COP for each footstep. 
Footsteps with a slope exceeding three MAD from the median footstep in the trial were identified as standing footsteps.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Data Quality Assessment}\label{sec:inspection} % Data Inspection / Statistical Analysis/Biometric Quality Assessment

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Manual Data Inspection}

As outlined in the prior section on Data Processing, metadata labels were identified through automated algorithms. 
Although these algorithms reached impressive accuracy levels (such as $99.7\%$ for identifying left and right footsteps \cite{Macdonald2023}, concerning the \textit{Side} metadata field), the necessity for perfectly accurate labels in benchmark datasets is crucial. 
Therefore, a minimum of two research team members performed a manual/visual inspection of each footstep and its associated metadata within the dataset. 
A multi-stage manual inspection of the extracted footsteps was conducted, where any errors identified in the initial review were addressed before starting the second review by a different evaluator. 
The evaluators conducted assessments of each footstep by visually inspecting the raw data for each pass across the tiles (Fig. \ref{fig:inspec_pass}), along with processed versions of the data for each segmented step (Fig. \ref{fig:inspec_step}). 
This included analyzing gait features such as aligned foot peak pressure images, vertical ground reaction force (GRF) profiles, foot center of pressure (COP) trajectories (Fig. \ref{fig:inspec_step}), as well as reviewing associated video recordings (captured by Camera 7, positioned at a 90\textdegree~viewing angle, perpendicular to the main axis of the tile grid; Fig. \ref{fig:inspec_video}). 
These inspection phases were also used to identify and eliminate any overlooked data corruption, hardware malfunctions, or protocol complications during data collection.

Specifically, the assessors recorded the errors in spreadsheets designated for each trial and merged the necessary corrections into the dataset where applicable. 
Noted errors fell into two primary categories: those concerning bounding boxes and those related to metadata. 
An interactive tool was developed to enable evaluators to manually adjust the size of spatiotemporal bounding boxes with inaccurate dimensions. % (Fig. \ref{fig:inspec_box})
Common bounding box errors included (1) bounding boxes that were too small spatiotemporally to contain a complete footstep, often occurring with high-arch shoes where the algorithm identified just a portion of the pressure profile, such as the heel or toe area; (2) bounding boxes that were too large, encroaching on the spatiotemporal area of another footstep, commonly observed in the W2 trials when participants slightly shuffled their feet during the slow-to-stop walking maneuver; and (3) missing boxes, especially for footsteps that occurred mostly outside the tile grid (e.g., a footstep that fell only 20\% within the grid, deemed an incomplete footstep).
When common errors were noted in the auto-labeling, corrections were implemented programmatically whenever feasible. 
Errors most commonly occurred (1) in the \textit{Side} metadata field, where a left label was incorrectly matched with a right footstep or vice versa, especially for invalid footsteps; (2) in the \textit{Standing} metadata field, where certain walking behaviours, such as shuffling during a slow-to-stop maneuver, resulted in inconsistent label assignment by the algorithm; and (3) in the \textit{Incomplete} metadata field, where partial footsteps were not flagged as incomplete steps.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Automated Outlier Detection}

To enable a focus on only high-quality footsteps, a metadata field titled \textit{Outlier} was introduced, complementing the existing \textit{Incomplete} metadata field for partial or incomplete footsteps, allowing researchers to omit outlier samples. 
Certain footsteps may be of lesser quality for gait recognition or gait analysis due to irregular gait patterns such as stumbling or changes in speed or direction, as well as factors related to hardware or sensors, such as ghosting (i.e., some sensors remaining activated after a footstep), disconnected sensors, or noise. 
To identify high-quality, representative footsteps and exclude potentially inferior ones, an approach based on the R-score described by Sangeux and Polak \cite{SangeuxPolak2015} was used. 
Specifically, all of the footsteps in a trial were compared to a representative, median footstep for that trial, and their similarity (and by association, quality) was quantified by an R-score. 
For normally distributed measurements, the R-score approximately represents the number of standard deviations from the mean. 
The scores were calculated using the combination of a spatial characteristic (i.e., the number of active sensors during the footstep), a temporal characteristic (i.e., the duration of the footstep), and an amplitude characteristic (i.e., the footstep's GRF profile). 
The R-scores were independently computed for each 90-second trial because variations in footwear and walking speed are likely to affect the normality assumption of this method. 
Moreover, the representative median was calculated without manually-identified standing or incomplete footsteps.
Footsteps within the dataset with an R-score of 2.0 or higher were marked as outliers, labeled \textit{Outlier} in the metadata. 
This averages to about 12.3 footsteps per trial, culminating in a total of 29,511 flagged footsteps throughout the entire dataset. 
It should be noted that many of these footsteps had already been classified as \textit{Standing} or \textit{Incomplete} (Fig. \ref{fig:outlier}). 
Metadata in the form of \textit{Rscore} is also included, allowing researchers to establish their own exclusion criteria if desired.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Gait Feature Extraction and Validation}

The present dataset's technical quality and reliability were evaluated by analyzing different common gait representations and parameters. 
This evaluation was conducted in comparison to other publicly available datasets that utilize pressure or force measurements for gait, with findings detailed in the Technical Validation section. 
Within the literature on plantar pressure, it is typical to employ a range of two-dimensional spatial representations to distill specific characteristics of each pixel's values over time, such as its peak pressure, pressure-time integral, contact duration, and time-to-maximum \cite{Pataky2012}. 
This approach synthesizes all pertinent details from the time series of pressure images throughout a stance phase into a comprehensive image. 
Among these features, peak pressure images are probably the most widely employed in the literature, and are computed from each footstep's 3D tensor as the maximum pressure experienced by each pixel (i.e., sensor) during the stance. 
Peak pressure images were used here to illustrate the variations in shod pressure patterns (Fig. \ref{fig:P100s}) as well as the differences in sensor density across datasets (Fig. \ref{fig:resolution_comparison}). 
Biomechanical analyses also frequently involve time series signals due to the temporal nature of gait patterns, such as vertical ground reaction force (GRF) profiles, and center of pressure (COP) trajectories.
GRF time series, representing the forces exerted by the ground on the foot throughout the stance phase, are computed as the sum of pressures across all pixels at each time step.
COP time series are defined in the mediolateral (ML, $x$-axis) and anteroposterior (AP, $y$-axis) directions, and are calculated as the pressure-weighted average of the foot's coordinates at each time step during the stance.
These two time series were used for quality assessment and comparison with other public datasets (Fig. \ref{fig:GRFCOP_comparison}). 
Lastly, several spatiotemporal gait parameters were derived from the pressure recordings, including gait speed, cadence, step length, step width, and toe-out angle. 
With the exception of toe-out angle, these features were extracted using the distances between 3D bounding box coordinates ($time$, $x$, $y$) from consecutive footsteps. 
Toe-out angle was computed as the angle of the first principal component axis of the footstep (i.e., along the longest dimension of the foot) with respect to the long axis of the tile grid, and is negative for inward rotations and positive for outward rotations.
% It should be noted that, given that participants could choose any walking path across the tiles (the sensor's viewing angle varied), these calculated angles are an approximation and novel techniques are needed to track walking trajectories to compute the toe-out angle with higher accuracy. % most participants generally walked in a straight line from one end of the sensor platform to another
These spatiotemporal parameters were compared to those from the CASIA-D dataset (Figs. \ref{fig:spatiotemporal_boxplot}-\ref{fig:spatiotemporal_scatter}). 
% Scripts to compute these gait features are available on the project's homepage (\hyperlink{https://github.com/UNB-StepUP}{https://github.com/UNB-StepUP}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Data Records}
% The Data Records section should be used to explain each data record associated with this work, including the repository where this information is stored, and to provide an overview of the data files and their formats. Each external data record should be cited numerically in the text of this section, for example \cite{Hao:gidmaps:2014}, and included in the main reference list as described below. A data citation should also be placed in the subsection of the Methods containing the data-collection or analytical procedure(s) used to derive the corresponding record. Providing a direct link to the dataset may also be helpful to readers (\hyperlink{https://doi.org/10.6084/m9.figshare.853801}{https://doi.org/10.6084/m9.figshare.853801}).

%Tables should be used to support the data records, and should clearly indicate the samples and subjects (study inputs), their provenance, and the experimental manipulations performed on each (please see 'Tables' below). They should also specify the data output resulting from each data-collection or analytical step, should these form part of the archived record.
  
The official documentation for the dataset and all required scripts can be found on its GitHub page: \url{https://github.com/UNB-StepUP/StepUP-P150}. 
The StepUP-P150 dataset is accessible for download on \emph{figshare}\cite{UNB-StepUP} (\url{https://doi.org/10.6084/m9.figshare.28143686}) and contains the raw recordings, two variants of extracted and preprocessed footstep data, along with detailed metadata for each individual footstep. 
The files are organized as shown in Fig. \ref{fig:tree_directory}. 
Located at the top level, the spreadsheet named `participant\_metadata.csv' contains demographic information, anthropometric measurements, types of footwear, and other possible influences on the gait patterns of each for the 150 participants. 
More comprehensive information regarding the metadata fields is available in Table \ref{tab:participant_metadata}. 
Footstep pressure data is also structured into separate folders at the top level, with each corresponding to a single participant. 
Each folder is named using the pattern XXX, with `XXX' representing a unique, randomly assigned ID that encompasses all participants (001-150). 
Within each participant's folder, four (second-level) sub-folders represent the various footwear conditions: `BF', `ST', `P1', and `P2'. 
Inside these, there are seven further (third-level) sub-subfolders designated for distinct standing balance and walking experiment trials: `S1', `S2', `S3', `W1', `W2', `W3', or `W4' (refer to Fig. \ref{fig:protocol_tasks} and the Experimental Protocol section for more information). 

For each of the three standing balance trials (S1, S2, and S3), there are two corresponding files. 
The `trial.\{npz,mat\}' file houses the raw, unprocessed 30-second recording from the trial, represented as a 3D tensor with dimensions of nominally $3000 \times 720 \times 240$ (frames, height, width; note that the number of frames may vary slightly). 
The processed version of the recording is available as `preprocessed.\{npz,mat\}', representing a 3D tensor with dimensions of $3000 \times 180 \times 180$ (frames, height, width). 
These files are available in both NumPy (.npz) and MATLAB (.mat) file formats, each of which uses a dictionary-like structure for variable storage, with the tensors accessible under the top-level key arr\_0. 
Unlike the balance trials, each folder for the walking trials (W1, W2, W3, and W4) includes four files. 
The raw, unprocessed 90-second pressure data is available in `trial.\{npz,mat\}', containing a 3D tensor with dimensions of $9000 \times 720 \times 240$ (frames, height, width; again, the number of frames may vary). 
The footsteps were extracted using two distinct preprocessing methods and are provided as `pipeline\_1.\{npz,mat\}' and `pipeline\_2.\{npz,mat\}', which are elaborated upon in the Footstep Normalization section. 
Each tensor is 4D with dimensions $n_{footsteps} \times 101 \times 75 \times 40$ (samples, frames, height, width), where $n_{footsteps}$ specifies the number of footsteps in a given trial. These tensors are all accessible via the key arr\_0. 
Each individual footstep's metadata is provided in a file named `metadata.csv', containing details such as the spatiotemporal location in the initial recording, classification labels (e.g., left or right foot, walking direction, outlier), and various parameters obtained during preprocessing (e.g., rotation angle, foot length and width, mean GRF). 
Table \ref{tab:metadata} lists the metadata fields and their explanations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Technical Validation}

% This section presents any experiments or analyses that are needed to support the technical quality of the dataset. This section may be supported by figures and tables, as needed. This is a required section; authors must present information justifying the reliability of their data.

Evaluation of the present database, along with other publicly available pressure-based gait databases (Table \ref{tab:datasets}), is conducted in this section using the 5 V's of big data as a framework: volume, variety, velocity, veracity, and value \cite{Phinyomark2018JMBE}. 
Although pressure-based floor sensor gait datasets have not yet reached the large scale of big data seen in other gait modalities such as video- or wearable-based approaches, these data characteristics are employed to evaluate the current state of this field, offering insight for the advancement of future databases and datasets in this specialized area.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Volume}

% Number of subjects + Number of footsteps
The SFootBD database contains approximately 20,000 footsteps total from 127 individuals \cite{VeraRodriguez2013a}, making it the largest database of its kind until the introduction of the current database, UNB StepUP. 
The newly introduced database starts with an initial dataset named UNB StepUP-P150, described in this paper, which includes over 200,000 footsteps collected from 150 individuals. 
This makes it more than ten times larger than the SFootBD in terms of total footsteps (Table \ref{tab:datasets}). 
The SFootBD database contains three benchmark datasets named B1, B2, and B3 which simulate three unique data-driven security environments, each with a varying number of users and training footsteps per user: airport security screenings (limited training data), workplace environments (moderate training data), and home settings (extensive training data). 
Considering the nature of the SFootBD database, where some individuals provided multiple footstep recordings during several sessions, while others contributed only a few, the benchmarks were determined by the number of participants that provided a specific number of footstep samples. 
Consequently, they proposed simulating three different scenarios: an airport security checkpoint with 40 users and 80 training footsteps per user, a workplace with 15 users and 400 training footsteps each, and a home environment with 5 users and 1000 training footsteps each, with testing restricted to 10 footsteps per user across all scenarios. 
By adopting a similar structure for access checkpoints and providing 80 training steps for each user, the UNB StepUP-P150 dataset can increase its number of users from 40 to 150. 
On the other hand, for home security systems involving five users, the UNB StepUP-P150 dataset can elevate the training process for each user to include approximately 1,400 steps. 
In fact, the UNB StepUP-P150 dataset can emulate various scenarios involving up to 150 users, each contributing 1,400 steps on average for model training and evaluation.

% Number of consecutive footsteps + Number of voxels per step
In addition to the number of subjects and steps, the UNB StepUP database features a substantially larger floor-sensing platform and an enhanced sensing resolution (or greater sensor density) compared to other publicly available databases. 
The 120 cm $\times$ 360 cm sensing tile grid used for the StepUP-P150 database is the largest yet, which allows the collection of natural walking behaviour over a span of 4-6 consecutive footsteps, in contrast to the 1-4 steps recorded by other databases (Fig. \ref{fig:sensor_comparison}). 
Additionally, the StepUP-150 database employed pressure-sensing tiles featuring a spatial resolution of 5 mm $\times$ 5 mm, offering the highest sensor density. 
This represents a more than 50\% increase along the axis of walking compared to the next two highest-resolution underfoot pressure databases: CAD WALK and CASIA-D (Fig. \ref{fig:resolution_comparison}). 
A much higher sensing resolution translates to a significantly larger number of voxels per footstep. 
Until now, high-resolution underfoot pressure data was only available in much smaller datasets, such as the CASIA-D dataset, which is arguably the most well-known in this field and contains just over 3,000 footsteps from 118 individuals \cite{Zheng2011}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Variety}

Different factors, known as gait covariates, can influence gait patterns. 
These include walking speed, footwear, elapsed time, carried load, walking environment, clothing, direction of gait and foot angle with respect to the sensors, and dual-task gait. 
In previous research on underfoot pressures, the main challenges often stem from variations in walking speed and the types of footwear worn.
Specifically, the CASIA-D dataset consists of two distinct sub-datasets, with each one concentrating on a different covariate: one on walking speed (normal and fast speeds) and the other on footwear types (barefoot and two kinds of shoes, including running shoes, Chinese cloth shoes, and leather shoes). 
While these datasets allow for the exploration of each factor's individual impact, in real-world scenarios, these factors frequently interact with each other. 
In contrast, the SFootBD database aimed to replicate real-world scenarios by allowing participants to walk at their natural pace and wear any type of footwear, though annotated labels were not provided for changes in footwear or other conditions.
Although this database facilitates the investigation of the effects of combined factors, it does not allow the evaluation of individual covariates. 
This limitation also hinders the development of specialized algorithms tailored for applications with variable covariates, for instance, access control in areas where individuals inherently remove their shoes, such as some religious places or specific airport security checkpoints, where the primary concern is barefoot samples. 
The UNB StepUP-P150 experiment simultaneously examined the two factors by incorporating four different walking speeds (normal, fast, slow, and slow-to-stop, simulating the approach to a turnstile at a controlled access point) along with four types of footwear conditions (barefoot, standard shoes, and two personal pairs), resulting in a total of 16 unique covariate conditions.

Additionally, ongoing experiments that will extend the UNB StepUP database consist of two additional studies. 
Building on the first study that led to the UNB StepUP-P150 dataset, the second study adds two more factors: time elapsed and carried load. 
Meanwhile, the third study includes four additional factors: walking setting, worn apparel, direction of gait and foot angle with respect to the sensors, and dual-task gait, which integrates cognitive activities. 
Individuals who took part in the first study were invited to participate in the subsequent second and third studies. 
This methodology allows for the integration of temporal effects (across different days) into these studies, while preserving specific conditions associated with the two main factors: walking speed and type of footwear. 
As a result, the data collection protocols led to 33 distinct covariate conditions for the second study and 24 for the third. 
At the time of submission, footstep data have been collected from 40 participants for the second study and 21 participants for the third. 
This data collection process is ongoing, and these datasets will be made publicly available as new components of the UNB StepUP database in the future, where they may be referred to as the UNB StepUP-CV dataset. 
The designation CV refers to the gait covariate problem.
% Gait covariates (GC or CV) or Cross-covariate (CC) or Gait Challenge Problem (GCP) or Robust Gait Recognition (RGR)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Velocity}

Several important points concerning the speed of data collection and processing should be highlighted. 
Firstly, a 90-second walk can lead to anywhere between 50 and 120 steps, averaging approximately 90 steps, depending on the walking speed.
This allows biometric enrollment to be completed quickly, taking as little as one to two minutes. 
With the current protocol involving 16 unique conditions and related tasks like measuring body dimensions, changing footwear, and incorporating breaks between trials, gathering around 1,400 footsteps is completed in under 90 minutes. 
Secondly, the segmentation and annotation of individual footsteps can be achieved through methods suitable for real-time execution. 
In the UNB StepUP-P150 dataset, the SORT algorithm \cite{Bewley2016}, which is designed for real-time tracking, is instrumental in the segmentation of each individual footstep. 
In addition, automatic algorithms were employed to identify left and right footfalls, incomplete or outlier footprints, and to distinguish between standing and walking footsteps. 
Thirdly, the UNB StepUP-P150 already features footstep data for 150 individuals, but efforts are continuing to further increase the number of participants. 
These additional subjects may also serve an important role in representing unknown users and impostors in biometric research, possibly as part of a future competition at an international conference. 
In addition, data collection for the second and third studies is ongoing. %, aiming to include (at least) 30 participants for both studies. % https://pmc.ncbi.nlm.nih.gov/articles/PMC7745163/#r16 For effect size = 1, power = 0.8 and alpha value = 0.05, the sample size is found to be 30 (for each group).
To our knowledge, the collection of the publicly available pressure-based gait datasets listed in Table \ref{tab:datasets} have been completed, with no ongoing data collection.

As part of the project that enabled the UNB StepUP database, an additional instrumented runway with a $4\times6$ grid of pressure-sensing tiles was installed at the secure entry point of the Cyber Center Building in Fredericton, New Brunswick, Canada. 
This setup in a leading cybersecurity center in Canada has facilitated the collection of footstep data in a genuine high-security setting, reflecting real-world usage patterns such as arriving for work, taking lunch breaks, and leaving. 
The system has been active for the past 3 years, recording data from more than 130,000 footsteps collected from more than 90 consented individuals. 
This real-world dataset, the first known such dataset of its kind, incorporates a mix of uncontrolled variables and two common traffic routes onto the tiles and is planned for future public release as part of the UNB StepUP database, where it may be referred to as the UNB StepUP-RW dataset. 
The designation RW refers to a non-controlled real-world setting, similar to ``in-the-Wild'' datasets used for vision-based gait recognition.
% In the vision-based usually use In the Wild (WILD) or a non-controlled real-world setting (REAL or RW)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Veracity} % Veracity refers to noisy, erroneous, or incomplete data. 

There are several noteworthy aspects to highlight.
Firstly, the UNB StepUP-P150 dataset includes different versions of pre-processing pipelines for footstep pressure data, offering multiple options for users. 
Scripts for these preprocessing pipelines, which combine three components— spatial normalization, temporal normalization, and amplitude normalization (Table \ref{tab:preprocessing})—are also provided. 
The GRF and COP time series derived from the preprocessed StepUP-P150 dataset exhibited an average waveform comparable to those found in other gait datasets that use force or pressure data, such as the combined GaitRec and Gutenberg dataset \cite{Horsak2020,Horst2021}, the dataset produced by Derlatka and Partieniuk \cite{DerlatkaParfieniuk2023}, and CASIA-D (Fig. \ref{fig:GRFCOP_comparison}). 
Secondly, concerning labels, although automated algorithms have facilitated annotation and allowed real-time application in practical implementation, a rigorous manual inspection was performed on the UNB StepUP-P150 dataset. 
This was done to ensure that all labels were accurately corrected, involving two rounds of review with a minimum of two examiners, as detailed in the Data Quality Assessment section. 
Video recordings frequently served as an extra resource to aid in verifying potential label inconsistencies (presumed mistakes that may occur during experimental procedures). 
This approach was used in the manual inspection of the current dataset and other public datasets such as CASIA-D and SFootBD. 
Thirdly, this dataset further incorporated two metadata tags, \textit{Incomplete} and \textit{Outlier}, enabling users to omit incomplete or low-quality footstep samples from their analysis. 
The \textit{Incomplete} metadata is mainly used to filter out partial or incomplete footsteps, ensuring that poor-quality incomplete footsteps are removed while allowing low quality but complete footsteps to remain. 
On the other hand, the \textit{Outlier} metadata focuses on eliminating low-quality footsteps in general, encompassing many incomplete ones (though not all) and complete footsteps that may fall below quality standards. 
These two sets of metadata identified some common footsteps for exclusion but also flagged others, allowing users the choice to exclude footsteps based on one set, the other, both, or their overlap (Fig. \ref{fig:outlier}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Value}\label{sec:value}

The initial UNB StepUP-P150 dataset from the UNB StepUP database shows marked improvements compared to other publicly available pressure-based gait databases and datasets in many aspects. 
These include, among others, a larger data size, a wider range of confounding factors, ongoing data collection, and meticulous data annotation, as discussed above, all contributing to the improved quantity and quality of the data. 
The larger size of the current dataset and the extensive range of covariates provide greater variation and a more thorough representation of gait patterns across general populations, which can be seen in spatio-temporal gait parameters such as step length, step width, cadence, and toe-out angle (Fig. \ref{fig:spatiotemporal_boxplot}). 
As an illustration, the toe-out angle range in CASIA-D is considerably more restricted compared to that of StepUP-P150. 
The limitation arises because CASIA-D requires subjects to walk along a strict and narrow straight line. 
In contrast, in real-world scenarios, individuals usually have more freedom in choosing their walking path and direction, leading to increased variability in the ``viewing angle'' covariate, as evidenced in the UNB StepUp-P150 dataset (Fig. \ref{fig:spatiotemporal_boxplot}). 
An additional example is shown in Fig. \ref{fig:spatiotemporal_scatter}. 
In this figure, the scatter plots illustrate the average step length and step width (or support base) for 13 participants from CASIA-D and 150 participants from UNB StepUP-P150, each wearing two distinct pairs of personal shoes. 
Using a person identification model developed earlier using the CASIA-D dataset \cite{Connor2015}, these two gait parameters stood out prominently and are included in the feature sets that allow the gait recognition model to reach an accuracy of 90.5\% with a single step and 99.5\% with five steps. 
This model is trained with one pair of the participant's personal shoes and assessed with shoes that were absent during training, a second pair of the participant's personal shoes, which represents one of the most challenging scenarios for pressure-based gait recognition. 
However, this result may no longer hold, as illustrated in Fig. \ref{fig:spatiotemporal_scatter}. 
Although the 13 subjects in the CASIA-D dataset can be perfectly distinguished using only these two gait parameters, numerous individuals in the StepUP-P150 dataset possess overlapping values, making recognition more challenging. 
% Constrained gait datasets, characterized by a limited number of samples, represent 'easy' cases that shallow gait models are capable of handling.
These examples suggest that the UNB StepUP-P150 dataset has the potential to establish a new, more rigorous benchmark for pressure-based gait recognition.

Although the UNB StepUP database focuses mainly on pressure-sensitive floor sensors, it will also incorporate other modalities, such as video data and digital footprints/shoeprints.
Before starting the collection of footstep data, the left and right footprints of each participant were scanned along with two pairs of shoeprints from their personal shoes using a flatbed digital scanner. 
Seven cameras were strategically placed to capture views from the front, the sides, and across all four corners. 
The video footage was recorded synchronously with the footstep pressure data. 
Once available, these data could serve as a standalone method for biometric recognition or be used in combination with other modalities for multi-modal recognition. 
These datasets will be made publicly available in the future as part of the UNB StepUP database, where they may be differentiated with labels such as the UNB StepUP-V150 and UNB StepUP-DS150 datasets.
The potential designations V150 and DS150 would indicate that the data are related to video recordings and digital scans, gathered from 150 individuals, respectively. 
For the CASIA-D dataset, video footage was gathered using a side camera, while the SFootBD datasets employed both a front-facing and a side camera, capturing either one or two viewing angles. 
By comparison, StepUP-V150 will include views from 7 different cameras.

The UNB StepUP database was initially created to support gait recognition in biometric systems, such as those used to identify and verify individual gait patterns. 
To address demographic imbalances within the dataset, the UNB StepUP-P150 dataset incorporates participants with varied age, gender, race/ethnicity, and body type, effectively representing the diverse spectrum commonly observed in human gait. 
The creation of the current gait dataset, while addressing demographic bias within biometrics, provides the UNB StepUP-P150 dataset with extensive research prospects in the fields of gait analysis and recognition, offering applications that surpass merely biometric purposes. 
Subsequent research using the UNB StepUP-P150 dataset could focus on one of the research questions outlined below:

\begin{itemize}[noitemsep,topsep=0pt]
  \item Statistical models of normative walking gait by utilizing foot pressure patterns
  \item Differences in pressure-based gait patterns between demographic subgroups, categorized by factors like gender and age differences
  \item Differences in pressure-based gait patterns resulting from external factors such as different walking speeds and types of footwear
  \item Novel machine learning and deep learning models for gait recognition across various classification challenges
  \item Novel approaches for the segmentation, alignment, and/or registration of plantar pressure images
  \item Benchmark study to evaluate state-of-the-art techniques for gait analysis and gait recognition
\end{itemize}

% It is important to note that certain subsets of the dataset may not be entirely suitable for all research questions, especially when specific categorizations yield small balanced sub-samples.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Usage Notes}

% The Usage Notes should contain brief instructions to assist other researchers with reuse of the data. This may include discussion of software packages that are suitable for analysing the assay data files, suggested downstream processing steps (e.g. normalization, etc.), or tips for integrating or comparing the data records with other datasets. Authors are encouraged to provide code, programs or data-processing workflows if they may help others understand or use the data. Please see our code availability policy for advice on supplying custom code alongside Data Descriptor manuscripts.

% For studies involving privacy or safety controls on public access to the data, this section should describe in detail these controls, including how authors can apply to access the data, what criteria will be used to determine who may access the data, and any limitations on data use. 

% Brief instructions to assist other researchers with reuse of the data
% Examples

% (1) Discussion of software packages that are suitable for analysing the assay data files
First, footstep data, along with supplementary metadata, are saved in *.npz and *.mat files, which can be readily imported and utilized with standard Python and MATLAB toolboxes. 
Scripts are provided to facilitate straightforward data import for Python and MATLAB users. 
These scripts are available on the dataset's GitHub page (\url{https://github.com/UNB-StepUP/StepUP-P150}). 
The complete collection of UNB StepUP-P150 files can be accessed on \emph{figshare}\cite{UNB-StepUP} (\url{https://doi.org/10.6084/m9.figshare.28143686}). 
Refer to the Data Records section for additional information regarding folder and file names. 
% (2) Suggested downstream processing steps (e.g. normalization, etc.)
Secondly, raw, unprocessed pressure data is provided for each trial, allowing users to perform any preferred downstream processing methods. 
The dataset is accompanied by the custom script used for data processing, detailed in the Footstep Normalization section. 
While the dataset comprises preprocessed data from two distinct pipelines for quick prototyping and analysis, the script offers the flexibility to experiment with numerous other combinations. 
The authors have shared this script on the dataset's GitHub page, allowing further optimization of the script. 
% (3) Tips for integrating or comparing the data records with other datasets
Third, scripts are provided to extract multiple standard gait features (e.g., peak pressure images, COP and GRF time series, and spatiotemporal gait parameters like step length and width) presented in the Technical Validation section.
These are supplied to assist in benchmarking and in integrating or comparing the current dataset with other datasets. 
%Third, the scripts that generated the results presented in the Technical Validation section are supplied as basic baselines to assist in integrating or comparing the current dataset with other datasets (benchmarking).
% (*) Future Datasets
Finally, as part of an ongoing project, at least four other datasets will be made publicly available as part of the UNB StepUP database, including:
\begin{itemize}
\item \textbf{UNB StepUP-V150}: The seven-camera video recordings dataset was collected along with the current footstep pressure data, obtained from 150 participants in the first protocol. 
\item \textbf{UNB StepUP-DS150}: The dataset consisting of digital footprints and shoeprints was gathered from 150 participants who participated in the first protocol. 
\item \textbf{UNB StepUP-CV}: The gait covariate dataset encompasses an extensive list of covariate factors, such as walking speed, type of footwear, cross-day gait, load carriage, walking environment, clothing, viewing angle, and dual-task gait, drawn from the second and third protocols.
\item \textbf{UNB StepUP-RW}: The dataset of footsteps from real-world scenarios was gathered by employing identical pressure-sensitive tiles at the secure entrance of the Cyber Centre Building, a premier cybersecurity facility in Canada.
\end{itemize}
Together, these gait datasets will offer numerous possibilities for researchers specializing in gait analysis and recognition.

%Although the data is provided in a single 3-dimensional numpy array, it is saved using `.npz` format to leverage built-in data compression and minimize resulting file size. The raw data record is keyed as `arr\_0` in each file. The following python code snippet demonstrates how to load raw trial data.

%```
%import numpy as np

%npz\_file = np.load('./UNB-StepUP/001/BF/W1/raw.npz')
%trial\_data = npz\_file['arr\_0']

%\# shape: (time, length, width)
%print(trial\_data.shape)
%```

%Extracted footsteps are provided in numpy `.npz` format. Each extracted footstep is provided as a separate 3-dimensional numpy array keyed by footstep ID. The following python code snippet demonstrates how to load extracted footsteps.

%```
%import numpy as np

%npz\_file = np.load('./UNB-StepUP/001/BF/W1/extracted.npz')
%for footstep\_id, footstep in npz\_file.items():
%    \# shape: (time, length, width)
%    print(f'{footsteps\_id}: {footstep.shape}
%```

% Data is provided in numpy `.npz` format to leverage built-in data compression, with the single 4D data array keyed as `arr\_0`.  Consistent with `extracted.npz`, aligned footsteps are available for all \textit{walking} trails (i.e., W1-W4). The following python snippet demonstrates how to load aligned footsteps.

%```
%import numpy as np

%npz\_file = np.load('./UNB-StepUP/001/BF/W1/aligned.npz')
%aligned\_footsteps = npz\_file['arr\_0']

%\# shape: (n\_footsteps, 101, 75, 40)
%print(aligned\_footsteps.shape)
%```

% The following code snippet demonstrates how to load a metadata table using python:

%```
%import pandas as pd

%metadata = pd.read\_csv('UNB-StepUP/001/BF/W1/metadata.csv')

%\# Print metadata for the first 10 footsteps
%print(metadata.head())
%```

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Code Availability}

% For all studies using custom code in the generation or processing of datasets, a statement must be included under the heading "Code availability", indicating whether and how the code can be accessed, including any restrictions to access. This section should also include information on the versions of any software used, if relevant, and any specific variables or parameters used to generate, test, or process the current dataset. 

Custom scripts designed for processing and technical validation are provided on the dataset's companion GitHub page (\url{https://github.com/UNB-StepUP/StepUP-P150}) to support ongoing improvements and optimizations. 
It should be noted that these scripts were created using MATLAB (The MathWorks, Inc., Natick, Massachusetts, United States, 2023a) and Python (Python Software Foundation, 3.11). 
The Python scripts require specific libraries, which are listed in the requirements.txt file. 
This file enables library installation through The Python Package Index (PyPI, https://pypi.org) or the Anaconda software distribution (2024.02, https://www.anaconda.com). 
For detailed instructions regarding the use and execution of the custom code, please consult the GitHub repository's README file.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliography{ref}

% For journal articles, DOIs should be included for works in press that do not yet have volume or page numbers. For other journal articles, DOIs should be included uniformly for all articles or not at all. We recommend that you encode all DOIs in your bibtex database as full URLs, e.g. https://doi.org/10.1007/s12110-009-9068-2.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgements} 

 In addition to the authors, many others contributed meaningfully to this dataset. We would like to thank those who helped with the collection of the data, including Erica Cluff, Erin Kierstead, Ryan Sullivan, Sarah Boyd, and Morva Mohammedzadeh Dogaheh. We would also like to thank those who contributed, in part, to the data curation of the dataset, including Sarah Boyd, Morva Mohammedzadeh Dogaheh, Chitom Nsofor, and Grace Sanford. Finally, we thank the funding and project partners who made this project possible, including CyberNB, Knowledge Park, Stepscan Technologies, the New Brunswick Innovation Foundation, the Atlantic Canada Opportunities Agency, and the Natural Sciences and Engineering Research Council of Canada (NSERC) Alliance grants program. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Author contributions statement}

Following the CRediT (Contributor Roles Taxonomy), the author contributions are as follows: 

\textbf{RL}: Conceptualization, Methodology, Software, Investigation, Formal Analysis, Data Curation, Writing - Original Draft, Writing - Review \& Editing, Visualization. 

\textbf{AP}: Conceptualization, Methodology, Software, Formal Analysis, Writing - Original Draft, Writing - Review \& Editing, Visualization, Supervision. 

\textbf{AS}: Investigation, Writing - Review \& Editing.


\textbf{SK}: Investigation, Writing - Review \& Editing.

\textbf{SB}: Investigation, Writing - Review \& Editing.

\textbf{AT}: Software, Formal Analysis, Data Curation, Writing - Original Draft, Writing - Review \& Editing, Visualization. 

\textbf{ES}: Conceptualization, Methodology, Formal Analysis, Data Curation, Writing – Original Draft, Writing - Review \& Editing, Visualization, Resources, Supervision, Project Administration, Funding Acquisition.

%Must include all authors, identified by initials, for example:
%A.A. conceived the experiment(s), A.A. and B.A. conducted the experiment(s), C.A. and D.A. analysed the results. All authors reviewed the manuscript. 

\section*{Competing interests} %(mandatory statement)

The authors declare no competing interests.

%The corresponding author is responsible for providing a \href{https://www.nature.com/sdata/policies/editorial-and-publishing-policies#competing}{competing interests statement} on behalf of all authors of the paper. This statement must be included in the submitted article file.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Figures \& Tables}

% Figures, tables, and their legends, should be included at the end of the document. Figures and tables can be referenced in \LaTeX{} using the ref command, e.g. Figure \ref{fig:stream} and Table \ref{tab:example}. 

% Authors are encouraged to provide one or more tables that provide basic information on the main ‘inputs’ to the study (e.g. samples, participants, or information sources) and the main data outputs of the study. Tables in the manuscript should generally not be used to present primary data (i.e. measurements). Tables containing primary data should be submitted to an appropriate data repository.

% Tables may be provided within the \LaTeX{} document or as separate files (tab-delimited text or Excel files). Legends, where needed, should be included here. Generally, a Data Descriptor should have fewer than ten Tables, but more may be allowed when needed. Tables may be of any size, but only Tables which fit onto a single printed page will be included in the PDF version of the article (up to a maximum of three). 

% Due to typesetting constraints, tables that do not fit onto a single A4 page cannot be included in the PDF version of the article and will be made available in the online version only. Any such tables must be labelled in the text as ‘Online-only’ tables and numbered separately from the main table list e.g. ‘Table 1, Table 2, Online-only Table 1’ etc.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
    \centering
         \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{age_histogram.pdf}
         \caption{}
         \label{fig:age_histogram}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{shoesize_histogram.pdf}
         \caption{}
         \label{fig:shoesize_histogram}
    \end{subfigure}
    \caption{Distributions of (a) participants' ages by sex and (b) participants' chosen standard shoe sizes by sex, in UK sizes. Note: Female distributions are shown in orange, and male distributions are shown in dark blue. A Wilcoxon rank-sum test did not indicate any significant difference in the distribution of ages for the female and male subgroups ($p = 0.55$). The shoe sizes for the male subgroup were significantly larger than the female subgroup ($p < 0.0001$ using a two sample $t$-test).}
    \label{fig:histogram}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
    \centering
         \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{weight_v_height.pdf}
         \caption{}
         \label{fig:height_weight}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{width_v_length.pdf}
         \caption{}
         \label{fig:width_length}
    \end{subfigure}
    \caption{Distributions of participants' physical characteristics by sex and ethnicity/race: (a) height (cm), weight (kg), and foot size (marker size is proportional to measured foot length in cm), and (b) measured foot length (cm) and width (cm). Note: Orange markers are used for female participants and dark blue for male participants. Some jitter was added for (b) to improve visibility.}
    \label{fig:anthropometric}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!htbp]
\centering
         \begin{subfigure}[b]{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{instrumentation_diagram.pdf}
         \caption{}
         \label{fig:instrumentation_diagram}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{instrumentation_image.jpg}
         \caption{}
         \label{fig:instrumentation_image}
    \end{subfigure}
    \caption{Overview of the instrumentation configuration. (a) A diagram of the laboratory setup; participants walked back and forth across a grid of twelve sensing tiles encircled by a non-instrumented platform to allow for turning. Seven RGB video cameras were used to capture the participants from different viewing angles. (b) A video frame from Camera 7 during a walking trial with corresponding pressure measurements.}
    \label{fig:sensor_setup}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!htbp]
\begin{center}
\includegraphics[width=\linewidth]{protocol_tasks.pdf}
\end{center}
% \vspace{-5mm}
\caption{Overview of the experimental protocol. After a 30 minute preparation period for onboarding and familiarizing the participant with the study, three 30-second standing trials (S1, S2, and S3) and four 90-second walking trials (W1, W2, W3, and W4) were recorded for each of the four footwear conditions (BF, ST, P1, and P2). The participants were allowed to take breaks throughout the study as needed, with at least two minutes taken to sit down and change shoes between footwear conditions. The order of the footwear conditions and walking speeds were randomized for each participant.}
\label{fig:protocol_tasks}
% \vspace{-5mm}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!htbp]
\centering
\includegraphics[width=0.7\textwidth]{speed_boxplot.pdf}
\caption{Average walking speeds, categorized by sex, as computed from pressure measurements during each walking task of the experimental procedure, and averaged over the four different footwear conditions. Note: The slow-to-stop, slow, and fast walking speeds were all found to be significantly different than the participants' preferred walking speeds ($p < 0.05$ using paired $t$-tests). There were no statistically significant differences between walking speeds for female and male subgroups ($p > 0.05$ for all walking tasks using two-sample $t$-tests)} % all comparisons of four walking speeds to each other were significantly different
    \label{fig:speed_boxplot}
\end{figure}    

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!htbp]
\begin{center}
\includegraphics[width=\linewidth]{shoe_histogram.pdf}
\end{center}
% \vspace{-5mm}
\caption{Distribution of participants' personal footwear types, complemented by digital scan examples for each category.}
\label{fig:shoe_histogram}
% \vspace{-5mm}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!htbp]
\begin{center}
\includegraphics[width=0.5\linewidth]{footstep_progression.pdf}
\end{center}
% \vspace{-5mm}
\caption{Example pressure image time series from the same participant, (1) without footwear (top row), (2) wearing standard shoes (second row), (3) wearing a pair of the participant's personal work boots (third row), and (4) wearing a pair of the participant's personal running shoes (last row), plotted at multiple phases throughout the stance.}
\label{fig:footstep_progression}
% \vspace{-5mm}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
    \centering
         \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{BF_P100s.pdf}
         \caption{}
         \label{fig:BF_P100s}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{ST_P100s.pdf}
         \caption{}
         \label{fig:ST_P100s}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{PS_P100s.pdf}
         \caption{}
         \label{fig:PS_P100s}
    \end{subfigure}
    \caption{Example peak pressure images for a selection of footsteps; (a) without footwear (from the BF trials), (b) wearing standard shoes (from the ST trials), and (c) wearing various types of personal footwear (from the P1 and P2 trials), including steel-toe work boots (second from right) and stiletto high heels (right).}
    \label{fig:P100s}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!htbp]
\centering
         \begin{subfigure}[b]{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{example_pass.pdf}
         \caption{}
         \label{fig:inspec_pass}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.40\textwidth}
         \centering
         \includegraphics[width=\textwidth]{manual_inspection_footsteps.pdf}
         \caption{}
         \label{fig:inspec_step}
    \end{subfigure}
    \hfill
    \begin{subfigure}[c]{0.59\textwidth}
         \centering
         \includegraphics[width=\textwidth]{manual_inspection_video.jpg}
         \caption{}
         \label{fig:inspec_video}
    \end{subfigure}
    \caption{Examples of different views of the data used for manual inspection of footstep bounding boxes and labels in each recorded trial; (a) a ``multiple footstep'' view, which depicts the peak pressures for each pass across the tiles along with the detected footstep bounding boxes, left/right labels, and whether the footstep was flagged as an incomplete or standing footstep (e.g., in this example, footstep 45 is color-coded in red to indicate an incomplete footstep), (b) an ``individual footstep'' view that shows the peak pressure image, GRF time series, and COP trajectory for each footstep along with the predicted footstep labels, and (c) a frame of the corresponding RGB video from Camera 7.}
    \label{fig:manual_inspection}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{outlier_curve.pdf}
    \caption{Performance of R-score for detecting outliers across cutoff thresholds between 0.0 and 10.0. Note: The shaded area represents the percentage of samples marked as outliers at a specific R-score threshold, with a hatched pattern indicating standing or incomplete footsteps (detected during labeling and manual inspection). In this study, a score threshold of 2 was chosen, leading to 13.7\% of the footsteps being categorized as outliers, with 3.5\% being regular steps that had not been identified in previous manual inspection.}
    \label{fig:outlier}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure} 
%\centering % gave an error, would not compile  
    \begin{forest}
        for tree={
            font=\sffamily, grow'=0,
            folder indent=.9em, folder icons,
            edge= dotted
        }
        [StepUP-P150
          [participant\_metadata.csv, is file]
          [001 
              [BF
                [S1
                    [trial.\{npz{,}mat\},is file]
                    [preprocessed.\{npz{,}mat\},is file]
                ]
                [S2]
                [S3]
                [W1
                    [metadata.csv, is file]
                    [trial.\{npz{,}mat\}, is file]
                    [pipeline\_1.\{npz{,}mat\}, is file]
                    [pipeline\_2.\{npz{,}mat\}, is file]
                ]
                [W2]
                [W3]
                [W4]
              ]
              [ST]
              [P1]
              [P2]
              ]
          [002]
          [003]
          [\\\vdots, is file]
          [150]
        ]
    \end{forest}
    \caption{Data structure for the UNB StepUP-P150 dataset.}\label{fig:tree_directory}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{sensor_comparison.pdf}
    \caption{Size comparison of floor-sensing platforms for pressure-based gait databases (CASIA-D, CAD WALK, UoM-Gait-69, SFootBD, and UNB StepUP-P150)}
    \label{fig:sensor_comparison}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{resolution_comparison.pdf}
    \caption{Sensor resolution (or sensor density) comparison of floor-sensing platforms for pressure-based gait databases (SFootBD, UoM-Gait-69, CAD WALK, CASIA-D, and UNB StepUP-P150). Note: The SFootBD dataset used a custom system consisting of piezoelectric sensors with diameters of 27 mm; the UoM-Gait-69 dataset used a custom system (iMAGiMAT) consisting of 116 plastic optical fibres (POFs), from which a spatial reconstruction was estimated using the Landweber algorithm; the CAD WALK and CASIA-D datasets used RS Scan Footscan platforms with a spatial resolution of 7.62 mm $\times$ 5.08 mm; and the UNB StepUP-150 dataset used Stepscan tiles with a spatial resolution of 5 mm $\times$ 5 mm.   
    %In this figure, all peak pressure images have been resized to common dimensions for spatial comparison (1 pixel $=$ 1 mm $\times$ 1 mm).
    }
    \label{fig:resolution_comparison}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
\centering
         \begin{subfigure}[b]{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{GRF_comparison.pdf}
         \caption{}
         \label{fig:GRF_comparison}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{COP_rot_comparison.pdf}
         \caption{}
         \label{fig:COP_comparison}
    \end{subfigure}
    
    \caption{Comparison of average ground reaction force (GRF) and foot center of pressure (COP) time series from UNB StepUP-P150 and from three public gait datasets: (1) healthy participants from the GaitRec and Gutenberg databases (Kistler force plate measurements from 561 individuals walking mostly barefoot), (2) the Dertlaka and Parfieniuk database (Kistler force plate measurements from 324 individuals walking in shoes), and (3) the CASIA-D barefoot database (RS Scan Footscan pressure measurements from 88 individuals that walked barefoot at two speeds). Note: Each GRF time series was rescaled by its mean value for ease of comparison across datasets.}
    \label{fig:GRFCOP_comparison}
\end{figure}

    %NOTE: we normally apply rotation during preprocessing which removes foot angle information  - here I kept the foot rotation before calculating COP. COP_comparison.png is using the preprocessed version of the footsteps with rotation angle removed. 

    % GaitRec & Gutenberg: mostly barefoot
    % Derlatka: multiple shoes 
    % CASIA-D: barefoot only (did not include shod here)
    % StepUP: barefoot and multiple shoes
    % maybe I should show COP for different footwear instead of different speeds?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{BF_spatiotemporal_comparison.pdf}
    \caption{Comparison of four spatiotemporal gait parameters between the CASIA-D barefoot database and barefoot samples from the UNB StepUP-P150 dataset. Note: Significant differences were found between the two CASIA-D and StepUP-P150 datasets in step length, cadence, and toe-out angle, for both the preferred and fast walking trials ($p < 0.05$ for all, using two-sample $t$-tests). No significant differences were found for step width.}
    \label{fig:spatiotemporal_boxplot}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}
    \centering
         \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{CASIAD_spatiotemporal_scatter.pdf}
         \caption{}
         \label{fig:CASIA_scatter}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{StepUP_spatiotemporal_scatter.pdf}
         \caption{}
         \label{fig:StepUP_scatter}
    \end{subfigure}
    \caption{Average step length and step width (also called support base) for each participant while wearing two personal pairs of shoes from the (a) CASIA-D shod and (b) StepUP-P150 databases. Note: Dotted lines connect markers associated with the same participant, with the two shoe types represented by diamond and star markers, respectively.}
    \label{fig:spatiotemporal_scatter}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tables %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{sidewaystable}
%\sidewaystablefn%
\begin{center}
\begin{minipage}{\textheight}
\caption{Key features of public pressure-based gait databases and datasets, including those featuring healthy subjects.}
\setlength{\tabcolsep}{4pt}
\begin{threeparttable}
\footnotesize
\begin{tabular}{@{}llllllllll@{}}
\toprule
Dataset & No. IDs & \begin{tabular}[t]{@{}l@{}}No. Steps\\(Total)\end{tabular} & \begin{tabular}[t]{@{}l@{}}No. Steps\\(Per Pass)\end{tabular} & Sex & Age & Race & \begin{tabular}[t]{@{}l@{}}Walking\\Speed\end{tabular} & Footwear & Other Covariates \\ \midrule

CASIA-D \cite{Zheng2011} & 88\textsuperscript{a} & 2,640 & 2-4 & 66M 20F & 20-60 & Asian & PS, FS & BF & NA \\

CASIA-D \cite{Zheng2011} & 30\textsuperscript{b} & 540 & 2-4 & 24M 6F & 20-40 & Asian & PS & BF, PM & NA \\

SFootBD \cite{VeraRodriguez2011,VeraRodriguez2013a} & 127 & 19,980 & 2 & 83M 44F & 23.7 (18-32) & NA (University students in Spain) & PS & BF, PM & Time elapsed, Load carriage \\

CAD WALK \cite{Booth2018} & 55 & 2,640 & 1 & 21M 34F & 42.3 (18-70) & White (Dutch) & PS & BF & NA \\
% Brian G. Booth, Noël L.W. Keijsers, Toon Huysmans, and Jan Sijbers. “The CAD WALK Healthy Controls Dataset”, June 2018, Zenodo. http://dx.doi.org/10.5281/zenodo.1265420 .

UoM-Gait-69 \cite{CostillaReyes2021} & 69 & 14,394 & 3-4 & 32M 37F & 36.4 (20-63) & NA & PS, FS & PO & Dual-task gait \\

UNB StepUP-P150 & 150 & 250,000 & 4-6 & 72M 78F & 34 (19-91) & White, Asian, Others & PS, FS, SS, STS & BF, PM, PC & see Additional Covariates section \\

\bottomrule
\end{tabular}
%\begin{tablenotes}
\footnotesize{
\textsuperscript{a} Downloadable resources include data from 96 participants, comprising roughly 2,900 footsteps. \\
\textsuperscript{b} Downloadable resources only include data from 15 participants, of whom 13 tried two different shoe types, while the remaining 2 tried only one type. \\
M: male, F: female, PS: preferred speed, FS: faster than preferred speed, SS: slower than preferred speed, STS: slow-to-stop, BF: barefoot, PO: personal shoes (one pair per participant), PM: personal shoes (multiple pairs per participant), PC: controlled shoes. 
}
%\end{tablenotes}
\end{threeparttable}
\label{tab:datasets}
\end{minipage}
\end{center}
\end{sidewaystable}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[!htbp]
\centering
\caption{\label{tab:demographics}Demographics and physical characteristics of the participants included in the UNB StepUP-P150 dataset.}
\setlength{\tabcolsep}{35pt}

\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Factor}                        & \multicolumn{1}{c}{\textbf{Number or $\bm{\mu \pm \sigma}$ (range)}} \\ \midrule
\textit{Age}                    & $34.2 \pm 17.3$ (19 – 91)   \\
\textit{Height (cm)}            & $171.5 \pm 9.6$ (151 - 196) \\
\textit{Weight (kg)}            & $76.0 \pm 18.4$ (46 - 148)  \\
\textit{BMI (kg/m\textsuperscript{2})} & $25.6 \pm 4.7$ (17 - 39)                                             \\
\textit{Foot Length (cm)}       & $25.7 \pm 2.0$ (20 - 30)    \\
\textit{Foot Width (cm)}        & $9.3 \pm 0.7$ (7 - 11)      \\
\textit{Shoe Size (UK)}         & $8.0 \pm 2.2$ (4 - 12.5)      \\
\textit{Preferred Walking Speed (m/s) }& $1.12 \pm 0.15$             \\
\textit{Race/Ethnicity}         &                             \\
\quad White                     & 106                         \\
\quad Asian                     & 36                          \\  
\quad Other/Multiple            & 6                           \\
\quad Unknown/Not Specified     & 2                           \\
\textit{Sex}                    &                             \\
\quad Male                      & 74                          \\
\quad Female                    & 76                          \\
\textit{Gender}                 &                             \\
\quad Man                       & 72                          \\
\quad Woman                     & 75                          \\
\quad Non-Binary                & 1                           \\
\quad Unknown/Not Specified     & 2                           \\
\textit{Dominant Leg}           &                             \\
\quad Right                     & 140                         \\
\quad Left                      & 10                          \\ 
\bottomrule
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\iffalse
\begin{table}[!htbp]
\caption{Spatiotemporal gait variables for three self-selected walking speeds (preferred, slow, and fast).}
\label{tab:spatiotemporal}
\setlength{\tabcolsep}{20pt}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Variable} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Preferred Speed\\ $\bm{\mu \pm \sigma}$ (range)\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Slow\\ $\bm{\mu \pm \sigma}$ (range)\end{tabular}} &
  \textbf{\begin{tabular}[c]{@{}c@{}}Fast\\ $\bm{\mu \pm \sigma}$ (range)\end{tabular}} \\ \midrule
\textit{Female}                & \multicolumn{1}{l}{}                & \multicolumn{1}{l}{}          & \multicolumn{1}{l}{}          \\
\quad Number of Steps          & $90   \pm 13$ (66 - 133)            & $79 \pm   13$ (41 - 120)      & $100   \pm 15$ (67 - 142)     \\
\quad Gait Speed (m/s)         & $1.11 \pm 0.16$ (0.57 - 1.57)       & $0.82 \pm 0.17$ (0.35 - 1.23) & $1.41 \pm 0.22$ (0.80 - 2.12) \\
\quad Stance Time (s)          & $0.73 \pm 0.08$ (0.51 - 1.07)       & $0.93 \pm 0.19$ (0.64 - 1.86) & $0.62 \pm 0.07$ (0.42 - 0.84) \\
\quad Step Time (s)            & $0.57 \pm 0.05$ (0.41 - 0.78)       & $0.70 \pm 0.12$ (0.52 - 1.32) & $0.50 \pm 0.04$ (0.35 - 0.64) \\
\quad Step Length (m)          & $0.63 \pm 0.06$ (0.43 - 0.80)       & $0.55 \pm 0.07$ (0.32 - 0.73) & $0.70 \pm 0.08$ (0.45 - 0.94) \\
\quad Step Width (m)           & $0.12 \pm 0.02$ (0.04 - 0.19)       & $0.12 \pm 0.03$ (0.04 - 0.20) & $0.11 \pm 0.02$ (0.04 - 0.19) \\
\quad Foot Angle (\textdegree) & $4.5 \pm 4.1$ (-8.6 - 15.1)         & $4.7 \pm 4.1$ (-7.7 - 16.0)   & $3.7 \pm 4.0$ (-8.5 - 15.2)   \\
\textit{Male}                  & \multicolumn{1}{l}{}                & \multicolumn{1}{l}{}          & \multicolumn{1}{l}{}          \\
\quad Number of Steps          & $83 \pm   12$ (59 - 114)            & $76 \pm   11$ (48 - 110)      & $88 \pm   13$ (63 - 136)      \\
\quad Gait Speed (m/s)         & $1.14 \pm 0.16$ (0.60 - 1.62)       & $0.85 \pm 0.17$ (0.38 - 1.35) & $1.49 \pm 0.23$ (0.81 - 2.26) \\
\quad Stance Time (s)          & $0.77 \pm 0.08$ (0.60 - 1.12)       & $0.94 \pm 0.16$ (0.70 - 1.66) & $0.66 \pm 0.07$ (0.51 - 0.94) \\
\quad Step Time (s)            & $0.60 \pm 0.05$ (0.49 - 0.80)       & $0.71 \pm 0.10$ (0.55 - 1.19) & $0.53 \pm 0.04$ (0.43 - 0.69) \\
\quad Step Length (m)          & $0.68 \pm 0.07$ (0.46 - 0.90)       & $0.59 \pm 0.07$ (0.39 - 0.79) & $0.78 \pm 0.09$ (0.52 - 1.05) \\
\quad Step Width (m)           & $0.14 \pm 0.04$ (0.05 - 0.28)       & $0.14 \pm 0.04$ (0.05 - 0.29) & $0.13 \pm 0.04$ (0.04 - 0.26) \\
\quad Foot Angle (\textdegree) & $5.9 \pm 5.9$ (-8.0 - 24.3)         & $6.4 \pm 6.3$ (-7.5 - 25.0)   & $5.1 \pm 5.5$ (-7.8 - 21.6)  \\
\bottomrule
\end{tabular}
\end{table}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[tbhp!]
\caption{Different preprocessing techniques for spatial, temporal, and amplitude normalization. Scripts are provided on the project's GitHub homepage to apply selected combinations of these techniques for specific needs.}
\begin{tabular}{@{}p{0.15\linewidth}p{0.8\linewidth}@{}}
\toprule
\textbf{Technique}         & \textbf{Description}                                                                                                 \\ \midrule
\textbf{Spatial} &                                                                                                                      \\
None                       & No spatial normalization                                                                                             \\
Zero Padding               & Pad border of footstep with zeros to a specified tensor width and length                                           \\
Resize                     & Apply spatial interpolation to resize the footstep to a specified tensor width and length                           \\
Foot Rotation              & Rotate footstep according to the direction of its first principal component axis (the sole's longest dimension)     \\
Foot Translation           & Translate footstep according to the foot's center of area, mass, or bounding box centroid.     \\
Registration & Linearly transform (translate, rotate, scale) the footstep to align with a reference template (e.g., the MUN104 healthy barefoot templates \cite{Pataky2011}) \\
\textbf{Temporal}          &                                                                                                                      \\
None                       & No temporal normalization                                                                                              \\
Zero Padding               & Pad the 3D tensor with zeros at the end of the footstep to a specified number of frames                             \\
Interpolation  & Interpolate the 3D tensor to a specified number of frames (e.g., 101 frames, where each frame represents 1\% of the stance)                 \\
\textbf{Amplitude}         &                                                                                                                      \\
None                       & No amplitude normalization                                                                                              \\
Body Mass                  & Linearly rescale amplitudes by the participant's measured body mass, so that amplitudes are relative to body weight \\
Mean GRF                   & Linearly rescale amplitudes by the average ground reaction force of the footstep                                    \\
Min-Max                    & Linearly rescale amplitudes to a maximum value of 1 and minimum of 0                                                \\
 \bottomrule
\end{tabular}
\label{tab:preprocessing}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}[p]
\caption{Metadata fields, possible values/format, and description for the spreadsheet `participant\_metadata.csv' containing demographic information, anthropometric measurements, types of footwear, and other possible influences on the gait patterns of each of the 150 participants.}
\begin{tabular}{@{}p{0.27\linewidth}p{0.24\linewidth}p{0.44\linewidth}@{}}
\toprule
\textbf{Field}                  & \textbf{Possible Values/Format} & \textbf{Description}                                                       \\ \midrule
ParticipantID                   & 001-150                         & Unique identifier.                                                         \\
Sex                             & Male, Female                    & Sex assigned at birth.                                                     \\
Gender                          & Man, Woman, Non-Binary, Unknown & Gender identity.                                                           \\
Age                             & 19-91                           & Age in years.                                                              \\
RaceEthnicity & Black, East/Southeast Asian, Middle Eastern, South Asian, White, Other, Unknown            & Population group (race or ethnicity).           \\
RaceEthnicityOther              & Text                            & Description of race/ethnicity if selected `Other'.                         \\
DominantLeg                     & Left, Right                     & Self-reported dominant side for a kicking task.                            \\
Weight (Kg)                     & 46.3-148.4                      & Measured weight in Kg at time of collection.                               \\
Height (Kg)                     & 151.0-195.5                     & Measured height in cm at time of collection.                               \\
LeftFootLength (cm)             & 21.5-30.0                       & Measured left foot length in cm.                                           \\
LeftFootWidth (cm)              & 7.0-11.0                        & Measured left foot width in cm.                                            \\
RightFootLength (cm)            & 20.0-30.0                       & Measured right foot length in cm.                                          \\
RightFootWidth (cm)             & 7.5-11.0                        & Measured right foot width in cm.                                           \\
StandardShoeSize                & 4-12.5                          & Chosen standard shoe size for the ST trials (UK sizing).                   \\
Shoe1Category & Athletic, Boots, Business/Dress, Casual Sneaker, Flat Canvas, Hiking/Trail, Sandals, Other & Category of participant's first personal shoe (P1). \\
Shoe1Size                       & Varied                          & Shoe size for P1, in varied units (e.g., US M, US W, EU, UK).              \\
Shoe1Brand                      & Text                            & Shoe brand name for P1.                                                    \\
Shoe1Description                & Text                            & Additional description or detail about P1.                                 \\
Shoe2Category                   & See Shoe1Category               & Repeated fields for participant's second shoe (P2).                        \\
Shoe2Size                       & See Shoe1Size                   &                                                                            \\
Shoe2Brand                      & See Shoe1Brand                  &                                                                            \\
Shoe2Description                & See Shoe1Description            &                                                                            \\
BFType                          & Barefoot, Socks                 & Whether BF trials were performed barefoot or wearing socks.                \\
OrthopedicInjury                & Yes, No                         & Recent orthopedic injury or surgery (e.g., hip, knee).                     \\
OrthopedicInjuryComment         & Text                            & Comment if selected `Yes' for OrthopedicInjury.                            \\
AssistiveDevice                 & Yes, No                         & Regular use of assistive device (e.g., cane, walker).                      \\
AssistiveDeviceComment          & Text                            & Comment if selected `Yes' for AssistiveDevice.                             \\
NeurologicalCondition           & Yes, No                         & Experiencing a neurological condition (e.g., Parkinson's, stroke).         \\
NeurologicalConditionComment    & Text                            & Comment if selected `Yes' for NeurologicalCondition.                       \\
MusculoskeletalCondition        & Yes, No                         & Musculoskeletal condition (e.g., arthritis).                               \\
MusculoskeletalConditionComment & Text                            & Comment if selected `Yes' for MusculoskeletalCondition.                    \\
Concussion                      & Yes, No                         & Recent concussion (\textless 6 months).                                    \\
ConcussionComment               & Text                            & Comment if selected `Yes' for Concussion.                                  \\
Pregnancy                       & Yes, No                         & Pregnant at time of collection.                                            \\
PregnancyComment                & Text                            & Comment if selected `Yes' for Pregnancy.                                   \\
RecentExercise                  & Yes, No                         & Muscle pain or soreness due to recent exercise or other activity.          \\
RecentExerciseComment           & Text                            & Comment if selected `Yes' for RecentExercise.                              \\
OtherCondition                  & Text                            & Additional comments on other conditions that may impact walking behaviour. \\ \bottomrule
\end{tabular}
\label{tab:participant_metadata}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}[tbhp!]
\begin{threeparttable}[b]
\caption{Metadata fields, possible values/format, and description for the `metadata.csv' spreadsheets containing information regarding trial conditions, 3D bounding boxes for each footstep, footstep labels, and other parameters extracted during data processing. There is one `metadata.csv' file for each 90-second trial recording.}
\label{tab:metadata}
\begin{tabular}{@{}p{0.15\linewidth}p{0.20\linewidth}p{0.55\linewidth}@{}}
\toprule
\textbf{Field} &
  \textbf{Possible Values/Format} &
  \textbf{Description} \\ \midrule
ParticipantID &
  001-150 &
  Unique participant identifier \\
Footwear &
  BF, ST, P1, P2 &
  Footwear condition for trial \\
Speed &
  W1, W2, W3, W4 &
  Walking speed condition for trial \\
FootstepID\tnote{*} &
  0-$N_{steps}$ &
  Footstep's index in 90-second trial \\
PassID\tnote{*} &
  0-$N_{passes}$ &
  The pass within which the footstep occurred (i.e., incremented each time the participant steps off the tiles to turn around) \\
StartFrame\tnote{*} &
  0-$N_{frames}$ &
  Frame in 90-second recording where footstep's first pressure contact occurred \\
EndFrame\tnote{*} &
  0-$N_{frames}$ &
  Frame in 90-second recording where footstep's pressure contact ended \\
Ymin, Ymax\tnote{*} &
  0-719 &
  Footstep bounding box limits along tile grid $y$-axis (parallel to walking direction, 3.6 m length) \\
Xmin, Xmax\tnote{*} &
  0-239 &
  Footstep bounding box limits along tile grid $x$-axis (perpendicular to walking direction, 1.2 m width) \\
Orientation &
  0, 1 &
  Footstep's orientation on the tile grid: 1 if walking toward Tiles 11 and 12, or 0 if walking toward Tiles 1 and 2.\\
Side &
  Left, Right &
  Whether the footstep corresponds to the right or left foot \\
Standing &
  0, 1 &
  1 the footstep corresponds to standing behaviour during the Slow-to-Stop (W2) trials, 0 otherwise \\
Incomplete &
  0, 1 &
  1 if the footstep was not captured fully by the sensors (e.g., partially off of the tile-grid or cut-off at beginning or end of recording), 0 otherwise \\
Rscore &
  0-89 &
  Footstep's R-score, approximating the number of standard deviations from the trial mean \\
Outlier &
  0, 1 &
  1 if the footstep's R-Score exceeds the recommended threshold of 2, or 0 otherwise \\ 
Exclude &
  0, 1 &
  The combination of the `Standing', `Incomplete' and `Outlier' columns for easy exclusion of these footsteps if desired \\ 
RotationAngle &
  -90\textdegree - 90\textdegree &
  Footstep's rotation angle in degrees with respect to the tile grid's long axis ($y$-axis) \\
FootLength &
  1-75 &
  Length of the footstep in pixels, measured along the footstep's first principal component axis (longest foot dimension) \\
FootWidth &
  1-40 &
  Width of the footstep in pixels, measured along the footstep's second principal component axis (perpendicular to longest foot dimension) \\
MeanGRF &
  Floating Point &
  Average of footstep's ground reaction force (total sum of all pressure values in kPa at each time point) over the duration of the stance. \\
  \bottomrule
\end{tabular}
\begin{tablenotes}
       \item [*] zero-indexed value
\end{tablenotes}
\end{threeparttable}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\iffalse
\begin{table}[!htbp]
\begin{tabular}{@{}lll@{}}
\toprule
Field                          & Possible Values  & Description \\ 
\midrule
\multicolumn{3}{l}{Experiment Condition} \\
Participant\_ID                & 001-150& Numeric participant identifier. \\
Shoe\_Type                     & BF, ST, P1, P2   & BF - barefoot; 
ST - standard shoe; 
P1 \& P2 - participant-specific personal footwear\\
Walking\_Condition             & W1, W2, W3, W4   & W1 - preferred speed; 
W2 - slow-to-stop; 
W3 - slow; 
W4 - fast\\ \midrule
\multicolumn{3}{l}{Spatiotemporally Locating each Footstep in Trial Recording} \\
 Footstep\_ID& 0-N&Zero-indexed numeric identifer for footsteps in each trial. Footstep\\
Starting\_Frame | Ending\_Frame & 0-9000           & Starting Frame - recording sample at which first first pressure contact occurred (e.g., heel contact); 

Ending Frame - recording sample at which final pressure contact occurred (e.g., toe off). 

Together, these values specify the temporal period within which the footstep occurred\\
X\_Min | X\_Max                 & 0-240            & \multirow{2}{*}{The rectangle formed from [(x\_min, y\_min), (x\_max, y\_max)] specifies tile grid bounding box within which the footstep occured.} \\
Y\_Min | Y\_Max                 & 0-720            &  \\
Tile\_Row                      & 0-1              & \multirow{2}{*}{Sensing tiles were organized in a 2-rows by 6-columns grid. These two fields specify which tile the footstep occured on (e.g., useful for comparing sensing characteristics across tiles). Note that these values are computed using the center-point of each footstep bounding box, and footsteps may span multiple tiles (see `Spans\_Tiles` column, below).} \\
Tile\_Column                   & 0-5              & \\
Spans\_Tiles                   & 0 | 1            & Whether the footstep spans more than a single physical sensing tile: 0 - False; 1 -  True \\
Fall\_On\_Perimeter             & 0 | 1            & Whether the footstep intersects the perimeter of the tile grid: 0 - False; 1 - True. Footsteps that fall on the tile perimeter are likely only partially captured, as reflected in the `Partial` column, below. \\ \cmidrule(lr){1-1} % \cmidrule
Pass\_N                        & 0 - n\_passes     & \multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}During each experiment condition participants walked back-and-forth across the tile grid (i.e., in a succession of `passes`). These two fields locate each footstep within a pass. Pass\_N - The pass within which the footstep occurred (i.e., this count is incremented each time the participant makes a 180-degree turn at either end of the tile grid). Pass\_ID - A 0-indexed ID uniquely identifying footsteps within each pass\end{tabular}} \\
Pass\_ID                       & 0 - 7            & \\ \midrule
\multicolumn{3}{l}{Footstep Characterization} \\
Orientation                   & 0 | 1            & Participants direction of travel across the tile grid. 

0 - travelling in ascending major-axis; 1 - travelling in descending major-axis direction\\
Rotation\_Angle                & -90 - 90 degrees & Footstep angle measured relative to major-axis of tile grid. Negative values denote counter-clockwise rotation, whereas positive values denote clockwise rotation.\\
Side                          & Left | Right     & The foot in question. Labelled according to participant's first-person perspective. \\
Standing                      & 0 | 1            & Denotes whether participant was walking (i.e., 0) or standing (i.e., 0). Non-zero values are only present in W2 walking condition. \\
Partial                       & 0 | 1            & Denotes whether the footstep extended beyond the perimeter of the tile grid and was, therefore, only partially captured. \\
Outlier                       & 0 | 1            & Denotes whether the footstep is anomalous relative to the other steps captured in this experiment condition.\\
\bottomrule
\end{tabular}
\end{table}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}