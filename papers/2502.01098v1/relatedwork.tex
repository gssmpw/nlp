\section{Related Work}
Several approaches have been investigated to achieve such spatiotemporal integration. Established fusion methods—such as the 
Spatial and Temporal Adaptive Reflectance Fusion Model (STARFM) \cite{gao2006starfm}, the SpatioTemporal Adaptive fusion 
of High-resolution satellite sensor Imagery (STAIR) \cite{zhu2010fusion}, and the Highly Integrated STARFM (HISTARFM) 
\cite{zhu2016histarfm}—blend temporally frequent but coarse imagery with sparse but fine-resolution 
observations. While these methods have demonstrated improvements, they often encounter challenges in heterogeneous landscapes and during periods of rapid land-cover change. STARFM and its variants are limited by the need to manually select one or more suitable pairs of coarse and high-resolution images for each fusion task, which poses challenges for automation at scale.


Advances in machine learning and deep generative models, including Generative Adversarial Networks (GANs) \cite{goodfellow2014generative} and diffusion-based approaches \cite{ho2020denoising} have shown promise in image synthesis and super-resolution tasks  \cite{Wang2019, Lim2017EnhancedDeepSR, Diffusion22}. While GANs can yield highly realistic imagery, they may suffer from training instability and spectral inconsistencies \cite{dhariwal2021diffusion}.
Few works have applied generative models to remote sensing domain \cite{Xiao2024EDiffSR, khanna2024diffusionsat} and these typically require a large number of inference steps, as noted by Zou et.al.\yrcite{DiffCR2024}. While Zou et.al. proposed an efficient diffusion approach for cloud imputation, it is limited to static landscapes and it can not be adapted to dynamic agricultural environments. Our novel framework integrates MODIS observations for contextual information while gap-filling high-resolution imagery. Beyond GANs and diffusion, our work utilizes Conditional flow matching \cite{Lipman2023Flow,Tong2024Improving}, a growing class of generative models that allow for exact likelihood estimation and often exhibit more stable training. The key contributions of our work are: (1) We present a novel approach for downscaling coarser-resolution MODIS imagery using a generative model to synthesize Landsat-like imagery. (2) We propose a gap-filling strategy that leverages the learned generative process to fill missing pixels in Landsat observations caused by cloud cover and scan lines. (3) We integrate the model into a pipeline to generate high-resolution, gap-free Landsat-like imagery at regular intervals.