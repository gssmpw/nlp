\appendix

\begin{figure*}[t]
    \centering
    \includegraphics[height=0.228\linewidth]{image/4_scenarios.pdf}
    \caption{The four proposed hybrid network (HASN) scenarios, where red circles represent AI nodes and other colors represent human nodes.}
    \label{figure:4_scenario}
\end{figure*}

\section*{Appendix}

\section{Potential Application Scenarios}
\label{sec: Potential Application Scenarios}

We discuss several potential real-world applications for MetaCD, showcasing how it enhances user experiences across entertainment, psychology, and e-learning. By complementing human interactions with AI nodes, MetaCD fosters collaboration, builds connections, and supports diverse needs while addressing challenges to ensure effective integration.

\noindent \textbf{(1) Entertainment:} \textit{Enhancing Social Metaverse Platforms}
\\Social metaverse platforms (e.g., Roblox and IMVU) can leverage MetaCD to help users discover suitable communities. AI nodes, tailored to individual preferences, seamlessly participate in social activities and fill gaps left by unavailable human participants, thereby enhancing the overall user experience.

For instance, Roblox has introduced AI companions that facilitate large-scale social interactions and actively engage in group activities. These companions assist humans in completing collaborative quests within the metaverse. When two previously unacquainted individuals repeatedly collaborate with the same AI companion during group tasks, they are more likely to interact and form connections to complete the task more effectively. Furthermore, AI companions can help maintain group functionality even when there are insufficient human members. However, including too many AI companions in a group can negatively impact the user experience. Group quests in the metaverse are designed to help humans develop skills and foster collaboration, not to rely solely on AI companions. An excessive number of AI participants may overshadow human contributions, resulting in fewer rewards for humans and discouraging their participation in future quests. Balancing the number of AI companions to facilitate interaction without overshadowing human contributions is therefore crucial for maintaining a positive user experience and encouraging continued engagement in the social metaverse.

\noindent \textbf{(2) Psychology:} \textit{Building Supportive Online Therapy Groups}\\ 
Online therapy services (e.g., 7 Cups and ReachOut) can utilize MetaCD to form effective support groups. AI nodes serve as empathetic companions, fostering open, warm, and judgment-free discussions to promote emotional well-being.

For example, 7 Cups integrates AI companions trained with diverse personalities—some calm and rational, others passionate and emotional—making them suitable for engaging with different types of participants. These AI companions observe participants’ reactions, exchange insights with other AI companions, and determine the best ways to guide individuals. They encourage participants to share their thoughts and care for one another, helping to build meaningful social connections. However, if a support group includes too many AI participants, the opportunities for human-to-human experience-sharing diminish. This can lead to a sense of artificiality and erode confidence in the coping strategies learned during group interactions, as participants may doubt their real-world applicability. To ensure the effectiveness of the support group, it is essential to maintain an appropriate balance of AI companions. This balance enables participants to receive emotional support and practical coping strategies while fostering genuine social relationships.

\noindent \textbf{(3) E-Learning:} \textit{Facilitating Collaborative Study Groups}\\
E-learning platforms (e.g., Khan Academy and Duolingo) can employ MetaCD to help students form effective study groups. AI nodes act as tireless teaching assistants, providing continuous guidance and engaging as peers at similar skill levels, fostering mutual motivation and sustained learning.

For instance, Khan Academy integrates AI companions that eagerly answer questions, guide problem-solving, and create tailored study plans. These AI companions collaborate within the study group to track learners’ progress and ensure that the group advances steadily. They encourage learners to engage in discussions, assist each other in solving problems, and identify potential long-term learning partners. Despite their benefits, an overabundance of AI companions in a study group can reduce opportunities for learners to gain insights from peers with relevant experiences, such as balancing different subjects or managing study time effectively. This lack of shared experiences can make the group dynamic feel monotonous, leading to reduced engagement. Therefore, maintaining an optimal number of AI companions is key to fostering mutual learning and motivation while ensuring that human learners actively contribute to and benefit from the study group.

\section{The Derivation of $\Delta Q$}
\label{sec: Derivation of delta Q}

We provide a combinatorial interpretation for the derivation of modularity gain $\Delta Q$ as follows. First, we reformulate the modularity $Q$ function:
\begin{align}
Q(P = C_i^K) = 
&\ \frac{1}{2|E|} \left( \sum_{i=1}^{K} \sum_{v_p, v_q \in C_i} \left( A_{pq} - \frac{d_p d_q}{2|E|} \right) \right) \nonumber \\
= 
&\ \frac{1}{2|E|} \sum_{i=1}^{K} \left( \frac{\Sigma_{\text{in}}^i}{2|E|} - \left( \frac{\Sigma_{\text{tot}}^i}{2|E|} \right)^2 \right),
\end{align}

\noindent where $\Sigma_{\text{in}}^i$ is the sum of the weights of the links inside the community $C_i$, and $\Sigma_{\text{tot}}^i$ is the sum of the weights of the links incident to nodes in $C_i$.

Note that the modularity gain $\Delta Q$ is obtained by moving the node $i$ (which is treated as an individual community $C_i$) into the community $C_j$. By the reformulated modularity function $Q$, to obtain the modularity gains $\Delta Q$, we only need to consider the communities $C_i$ and $C_j$. Since the node $i$ is moved to the community $C_j$, the sum of the weights of the links inside the community $C_j$, i.e., $\Sigma_{\text{in}}^j$, is updated to $\Sigma_{\text{in}}^j + k_{i, \text{in}}^j$, where $k_{i, \text{in}}^j$ is the sum of the weights of the links from node $i$ to nodes in the community $C_j$. Likewise, the sum of the weights of the links incident to nodes in the community $C_j$, i.e., $\Sigma_{\text{tot}}^j$, is updated to $\Sigma_{\text{tot}}^j + k_i$, where $k_i$ is the sum of the weights of the links incident to node $i$.

On the other hand, since the node $i$ is treated as an individual community $C_i$ and is moved to the community $C_j$, the modularity gain is $\left( \frac{k_i}{2|E|} \right)^2$. Therefore, the modularity gain $\Delta Q$ is:
\begin{align}
\Delta Q = 
\frac{\Sigma_{\text{in}}^j + k_{i, \text{in}}^j}{2|E|} 
- \left( \frac{\Sigma_{\text{tot}}^j + k_i}{2|E|} \right)^2 - \frac{\Sigma_{\text{in}}^j}{2|E|} 
+ \left( \frac{\Sigma_{\text{tot}}^j}{2|E|} \right)^2 
+ \left( \frac{k_i}{2|E|} \right)^2.
\end{align}


\section{Computational Complexity of CUSA}
\label{sec: Computational Complexity of CUSA}

\noindent \textbf{Time Complexity.} For each iteration, CUSA first evaluates AI node scores in $O(|V||E|) + |V|^2 \log |V|$ time on weighted graphs, where the eigenvector centrality is known to have complexity $O(|V|^2)$. The betweenness centrality is obtained in $O(|V||E|) + |V|^2 \log |V|$ time by computing the shortest paths for all pairs (augmented Dijkstra), and the clustering coefficient is evaluated in $O(|V| \cdot d_{\text{max}}^2)$ time by adjacency list intersection ($d_{\text{max}}$ is the size of the largest adjacency list of all vertices in the graph). Then, CUSA clusters the graph in $O(|V| \log |V|)$ time by the Louvain Clustering Algorithm and computes HQ in $O(|V|^2)$ time by considering all $(v_p, v_q)$ pairs. Since an AI node must be removed in each iteration, there are at most $|AI|$ iterations. Therefore, the time complexity is $O(|AI|(|V||E| + |V|^2 \log |V|))$.

\noindent \textbf{Space Complexity.} CUSA evaluates AI node scores and clusters the graph with $O(|V| + |E|)$ space (using the adjacency list to represent the graph data structure). Therefore, the space complexity is $O(|V| + |E|)$.



\section{The Proposed HASN Scenarios}
\label{sec: The Proposed HASN Scenarios}

\subsection{The Proposed Four Generation Strategies}
\label{sec: The Proposed Four Generation Strategies}

We outline the four proposed generation strategies for synthesizing HASNs with the specific assumptions  \cite{nomiAI2024}\cite{zhang2024better}\cite{skjuve2021my}\cite{loveys2019reducing}, as depicted in Figure \ref{figure:4_scenario}. These strategies reflect various interaction patterns between human and AI nodes, laying the foundation for constructing meaningful human-AI social networks (HASNs) for our experiments. 

\noindent \textbf{(1) \textit{k\% random insertion}}: AI interacts randomly with humans (or other AIs) with a uniform distribution of $k\%$. This setup assumes that everyone in the evolving \XR\ has equal chances to interact with AI, as depicted in Figure \ref{figure:4_scenario} (a).

\noindent \textbf{(2) \textit{Inverse degree-based insertion}}: The probability of an AI interacting with humans (or other AIs) is inversely proportional to the node's degree. This can be modeled using an exponential decay function, given by ${prob\_connect}(v_i) = a \times e^{-r \times (d_{v_i} - 1)}$, where $d_{v_i}$ is the degree of node $v_i$, $a$ is the initial probability (i.e., when $d_{v_i}=1$), and $r$ is the decay constant. This indicates that nodes with lower degrees are more likely to be linked by AI. This setup assumes that certain individuals tend toward introversion and prefer interactions with AI virtual entities, as depicted in Figure \ref{figure:4_scenario} (b).

\noindent \textbf{(3) \textit{Introverted and extroverted AI equally distributed}}: This suggests the existence of two distinct AI types: introverted and extroverted. Introverted AI engages extensively with members in their respective groups with a probability of $x\%$, while extroverted ones interact with members across various groups with a probability of $y\%$ (typically with $x>y$). This setup assumes that half of the AIs engage primarily with group members due to shared interests, while the other half possess versatility, enabling interaction across multiple groups, as depicted in Figure \ref{figure:4_scenario} (c).

\noindent \textbf{(4) \textit{AI with dual personality}}: This suggests that AI may demonstrate dual personality, actively engaging with members within its own community with a probability of $x\%$, while also interacting with individuals in other communities with a probability of $y\%$ (typically with $x>y$). This setup assumes that AIs adeptly interact with community members due to shared interests and are also versatile enough to engage with individuals from other communities, as depicted in Figure \ref{figure:4_scenario} (d).

\subsection{The Evolution of HASNs}
\label{sec: The Evolution of HASNs}
To better simulate real-world behavior, AI nodes in social networks are designed to take time to generate content, establish links, and engage with communities. This leads to the formation of a mixed human-AI social network (HASN) rather than simply inserting AI nodes into an existing network. AI nodes are introduced based on various generation strategies and adapt naturally through social network evolution processes \cite{mcpherson2001birds}\cite{daud2020applications}.
Once the HASNs are generated using one of the proposed strategies, the social network is expected to evolve over time, potentially forming new connections among individuals. To model this evolution, we employ link prediction, a widely used technique for identifying potential connections between previously unconnected nodes in social networks. One classical approach to link prediction is the Jaccard similarity index \cite{arrar2024comprehensive}\cite{daud2020applications}, which quantifies the similarity (or likelihood) between two nodes by calculating the ratio of the intersection to the union of their immediate neighbors. Mathematically, the Jaccard similarity is defined as: $\sigma_{Jaccard}(x,y) = \frac{|N(x) \cap N(y)|}{|N(x) \cup N(y)|}$, where $N(x)$ indicates the number of neighbors of node $x$. By computing the Jaccard similarity for all pairs of nodes, we can select the top $k$ pairs with the highest similarity values to establish new connections. This process is then iterated over $r$ rounds to simulate the evolution of the network.


\section{Supplementary Experimental Results}
\label{sec: Supplementary Experimental Results}

\subsection{Basic Statistics of Network Datasets}
\label{sec: Basic Statistics of Network Datasets}
Table \ref{dataset statistics} displays basic statistics for the three datasets used in our experiments, while Table \ref{Basic statistics of datasets before and after evolution} provides the statistics of these datasets after inserting AI nodes using the proposed generation strategies, along with the statistics of the AI node-augmented networks before and after evolution (\textit{cf.} Appendix \ref{sec: The Proposed HASN Scenarios}).

\begingroup
\renewcommand{\arraystretch}{1}
\begin{table}[t]
\centering
\caption{Basic statistics of benchmark datasets.}
\label{dataset statistics}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccc}
\toprule
Dataset & \#Nodes & \#Edges & Avg. Degree\\
\midrule
Cora \cite{sen2008collective} & 2708 & 5429 & 4.01 \\
CiteSeer \cite{sen2008collective} & 3327 & 4732 & 2.84 \\
PubMed \cite{sen2008collective} & 19717 & 44338 & 4.50 \\
\bottomrule
\end{tabular}%
}
\end{table}
\endgroup

\begin{table}[t]
\centering
\caption{The Q and HQ results on the Cora dataset obtained by CUSA under different hh, ha, and aa settings.}
\label{hh, ha, and aa settings}
\LARGE
\begin{tabular}{lcc}
\toprule
Setting & Q & HQ \\
\midrule
$hh,ha,aa=1,1,1$ & 0.8215 & 0.8200 \\
$hh,ha,aa=3,2,1$ & 0.8228 & 0.8216 \\
$hh,ha,aa=4,2,1$ & \textbf{0.8230} & \textbf{0.8224} \\
$hh,ha,aa=5,3,1$ & 0.8226 & 0.8214 \\
$hh,ha,aa=1,2,3$ & 0.8204 & 0.8193 \\
$hh,ha,aa=1,3,5$ & 0.8201 & 0.8190 \\
$hh,ha,aa=1,5,1$ & 0.8218 & 0.8212 \\
$hh,ha,aa=1,5,3$ & 0.8214 & 0.8210 \\
$hh,ha,aa=3,5,1$ & 0.8208 & 0.8204 \\
\bottomrule
\end{tabular}
\end{table}



\subsection{The Sensitivity to \textit{hh,ha,aa}}
\label{Sensitivity to hh, ha, aa}
Following \cite{zhang2022new}\cite{de2021centrality}, the values of $hh$, $ha$, and $aa$ are positively correlated with the importance of edge types. Since MetaCD emphasizes human-centric community detection, edges connecting human nodes are assigned higher weights, leading to $hh > ha > aa$. While these settings serve as the default in our experiments, they are flexible and can be adjusted as needed.

Table \ref{hh, ha, and aa settings} compares the modularity Q and human-centric modularity HQ results obtained by CUSA under different settings of $hh$, $ha$, and $aa$ on the Cora dataset, where 20\% of the total nodes are inserted as AI nodes using $k\%$ random insertion. Under the configuration $hh > ha > aa$, the values of Q and HQ obtained by CUSA consistently exceed those achieved under other configurations, particularly outperforming the $aa > ha > hh$ setting. This demonstrates that prioritizing human-human edges during AI scoring improves the evaluation of AI nodes in fostering human interactions, aligning with our goal of integrating AI nodes within communities. Furthermore, we observe that CUSA is sensitive only to the relative magnitudes of $hh$, $ha$, and $aa$, rather than their absolute values. As a result, setting these weights in practical applications becomes relatively straightforward.


\begingroup
\renewcommand{\arraystretch}{1.08}
\begin{table}[t]
\centering
\caption{The Q and HQ results on the Cora dataset obtained by CUSA under different inserted ratios of AI nodes.}
\label{different ai ratio}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{cccc}
\toprule
AI node ratio & \#Nodes, \#Edges & Q & HQ \\
\midrule
0\% & (2708, 5429) & 0.8154 & 0.8154 \\
10\% & (2978, 6238) & 0.8314 & 0.8242 \\
20\% & (3249, 6896) & 0.8343 & 0.8236 \\
30\% & (3520, 7355) & 0.8358 & 0.8253 \\
50\% & (4062, 8723) & 0.8411 & 0.8337 \\
100\% & (5416, 12677) & 0.8478 & 0.8396 \\
\bottomrule
\end{tabular}%
}
\end{table}
\endgroup

\begingroup
\renewcommand{\arraystretch}{1.2}
\begin{table}[t]
\centering
\caption{The execution time (minutes) on two large-scale datasets \cite{yang2012defining} to assess the scalability of CUSA.}
\label{Scalability of CUSA}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccccc}
\toprule
\textbf{\#Edges} & 10K & 100K & 200k & 300K & 500K & 1M \\
\toprule
YouTube & 35K & 684K & 1.1M & 1.5M & 2M & 2.8M \\
LiveJournal & 45K & 1.1M & 2.1M & 3.9M & 8.2M & 140M \\
\toprule
\textbf{Execution time} \\
\toprule
YouTube & 11.1 & 27.51 & 44.96 & 70.28 & 75.95 & 121.88 \\
LiveJournal & 16.88 & 55.50 & 80.83 & 136.93 & 298.95 & 646.51 \\
\bottomrule
\end{tabular}%
}
\end{table}
\endgroup


\subsection{The Sensitivity to Different AI Ratios}
\label{Sensitivity to Different AI Ratios}
Table \ref{different ai ratio} presents the Q and HQ results obtained by CUSA (with $hh, ha, aa = 4,2,1$) on the Cora dataset with varying inserted proportions of AI nodes (i.e., $\frac{\text{\# AI nodes}}{\text{\# total nodes}}$), using the third generation strategy (i.e., introverted and extroverted AI equally distributed). As more AI nodes are inserted, Q increases, indicating that the newly added AI nodes effectively facilitate social interactions and contribute to forming more tightly-knit communities. More importantly, CUSA maintains high HQ with a large number AI nodes inserted, demonstrating that CUSA can select an appropriate number of AI nodes for community detection to enhance modularity while avoiding an excessive number of AI nodes within communities.


\subsection{The Scalability of CUSA}

Table \ref{Scalability of CUSA} evaluates the scalability of CUSA using two large-scale datasets, YouTube \cite{yang2012defining} and LiveJournal \cite{yang2012defining}. The upper part of Table \ref{Scalability of CUSA} (above the third line) presents the number of edges within the extracted subgraphs for varying numbers of nodes (i.e., 10K, 100K, ..., 1M) across both datasets, while the lower part of Table \ref{Scalability of CUSA} displays the execution time (in minutes) of CUSA on these subgraphs. Although the theoretical time complexity is $O(|AI|(|V||E| + |V|^2 \log |V|))$, the observed execution time grows approximately linearly with $|E|$, as $|E|$ dominates the overall complexity. This demonstrates that in real-world large-scale social networks, CUSA achieves practical scalability closer to $O(|E|)$. 

\begingroup
\renewcommand{\arraystretch}{1.02}
\begin{table*}[t]
\centering
\caption{Basic statistics of AI node-augmented networks before and after evolution, where "Before Evolution" (BE) and "After Evolution" (AE) are indicated.}
\label{Basic statistics of datasets before and after evolution}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lccccc}
\toprule
\textbf{(1) \textit{k\%} random insertion} \\
\midrule
Dataset & \#Nodes & \#Edges (BE) & Avg. Degree (BE) & \#Edges (AE) & Avg. Degree (AE) \\
\midrule
Cora & 2978 & 5665 (+4.3\%) & 3.80 & 6065 (+11.7\%) & 4.07 \\
CiteSeer & 3659 & 5198 (+9.8\%) & 2.84 & 5598 (+18.3\%) & 3.06 \\
PubMed & 21688 & 46581 (+5.0\%) & 4.29 & 48981 (+10.5\%) & 4.52 \\
\midrule
\textbf{(2) Inverse degree-based insertion}  \\
\midrule
Dataset & \#Nodes & \#Edges (BE) & Avg. Degree (BE) & \#Edges (AE) & Avg. Degree (AE) \\
\midrule
Cora & 2978 & 5680 (+4.6\%) & 3.81 & 6080 (+12.0\%) & 4.08 \\
CiteSeer & 3659 & 5125 (+8.3\%) & 2.80 & 5525 (+16.8\%) & 3.02 \\
PubMed & 21688 & 46352 (+4.5\%) & 4.27 & 48754 (+10.0\%) & 4.50 \\
\midrule
\textbf{(3) Inner and outer AI mix}  \\
\midrule
Dataset & \#Nodes & \#Edges (BE) & Avg. Degree (BE) & \#Edges (AE) & Avg. Degree (AE) \\
\midrule
Cora & 2978 & 5838 (+7.5\%) & 3.92 & 6238 (+14.9\%) & 4.19 \\
CiteSeer & 3659 & 5037 (+6.4\%) & 2.75 & 5437 (+14.9\%) & 2.97 \\
PubMed & 21688 & 48520 (+9.4\%) & 4.47 & 50920 (+14.8\%) & 4.69 \\
\midrule
\textbf{(4) AI with dual personality}  \\
\midrule
Dataset & \#Nodes & \#Edges (BE) & Avg. Degree (BE) & \#Edges (AE) & Avg. Degree (AE) \\
\midrule
Cora & 2978 & 5862 (+8.0\%) & 3.94 & 6262 (+15.3\%) & 4.21 \\
CiteSeer & 3659 & 5258 (+11.1\%) & 2.84 & 5658 (+19.6\%) & 3.09 \\
PubMed & 21688 & 46074 (+3.9\%) & 4.25 & 48474 (+9.3\%) & 4.47 \\
\bottomrule
\end{tabular}%
}
\end{table*}
\endgroup


\begingroup
\renewcommand{\arraystretch}{1.2}
\begin{table*}[t]
\centering
\caption{The Q and HQ results on the Cora dataset transformed into HASNs  using different generation strategies (without evolving), obtained by CUSA in comparison to that of four clustering baselines each equipped with no removal of AIs (N), all removal of AIs (A), and removal of AIs by GAD (D).}
\label{The Q and HQ results on the Cora dataset (without evolving)}
\resizebox{\textwidth}{!}{%
\begin{tabular}{cccccccccc}
\toprule
\multirow{2}{*}{\makebox[0.15\textwidth]{\textbf{Method}}} & \multirow{2}{*}{} & \multicolumn{2}{c}{\textbf{\textit{k\%} random insertion}} & \multicolumn{2}{c}{\textbf{Inverse degree insertion}} & \multicolumn{2}{c}{\textbf{Inner and outer AI mix}} & \multicolumn{2}{c}{\textbf{AI with dual personality}} \\
\cline{3-10}
& & \textbf{Q (↑)} & \textbf{HQ (↑)} & \textbf{Q (↑)} & \textbf{HQ (↑)} & \textbf{Q (↑)} & \textbf{HQ (↑)} & \textbf{Q (↑)} & \textbf{HQ (↑)} \\
\hline
\multirow{3}{*}{\makebox[0.15\textwidth]{Spectral \cite{amini2013pseudo}}} 
& N & 0.1942 & 0.1847 & 0.2387 & 0.2270 & 0.2718 & 0.2588 & 0.1744 & 0.1664 \\
& A & 0.2890 & 0.2890 & 0.2890 & 0.2890 & 0.2890 & 0.2890 & 0.2890 & 0.2890 \\
& D & 0.2520 & 0.2520 & 0.2653 & 0.2653 & 0.2687 & 0.2687 & 0.2662 & 0.2612 \\
\hline
\multirow{3}{*}{\makebox[0.15\textwidth]{Louvain \cite{blondel2008fast}}} 
& N & 0.7954  & 0.7353 & 0.7973 & 0.7428 & 0.8183 & 0.7973 & 0.7738 & 0.7317 \\
& A & 0.8112 & 0.8112 & 0.8112 & 0.8112 & 0.8112 & 0.8112 & 0.8112 & 0.8112 \\
& D & 0.8027 & 0.7829 & 0.7957 & 0.7680 & 0.8110 & 0.8068 & 0.7968 & 0.7886 \\
\hline
\multirow{3}{*}{\makebox[0.15\textwidth]{GCC \cite{fettal2022efficient}}} 
& N & 0.6862 & 0.6451 & 0.6925 & 0.6658 & 0.7052 & 0.6787 & 0.6942 & 0.6614 \\
& A & 0.7323 & 0.7323 & 0.7323 & 0.7323 & 0.7323 & 0.7323 & 0.7323 & 0.7323 \\
& D & 0.7131 & 0.7042 & 0.7218 & 0.7139 & 0.7286 & 0.7220 & 0.7164 & 0.7035 \\
\hline
\multirow{3}{*}{\makebox[0.15\textwidth]{LSEnet \cite{sun2024lsenet}}} 
& N & 0.7026 & 0.6543 & 0.7073 & 0.6719 & 0.7145 & 0.7020 & 0.7011 & 0.6756 \\
& A & 0.7258 & 0.7258 & 0.7258 & 0.7258 & 0.7258 & 0.7258 & 0.7258 & 0.7258 \\
& D & 0.7064 & 0.6915 & 0.7165 & 0.7093 & 0.7192 & 0.7130 & 0.7181 & 0.7132 \\
\hline
\multirow{1}{*}{\makebox[0.15\textwidth]{\textbf{CUSA} (ours)}} 
& - & \textbf{0.8141} & \textbf{0.8132} & \textbf{0.8166} & \textbf{0.8160} & \textbf{0.8236} & \textbf{0.8137} & \textbf{0.8124} & \textbf{0.8120} \\
\bottomrule
\end{tabular}%
}
\end{table*}
\endgroup


\begin{table}[t]
\centering
\caption{The Q and HQ results on the ER-based random HASN \cite{erdds1959random} (with evolution), obtained by CUSA in comparison to that of four clustering baselines each equipped with no removal of AIs (N), all removal of AIs (A), and removal of AIs by GAD (D).}
\label{The Q and HQ results on the ER-based random HASN}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{ccccc}
\toprule
\multirow{2}{*}{\makebox[0.15\textwidth]{\textbf{Method}}} & \multirow{2}{*}{} & \multicolumn{2}{c}{\textbf{\textit{k\%} random insertion}} \\
\cline{3-4}
& & \textbf{Q (↑)} & \textbf{HQ (↑)} \\
\hline
\multirow{3}{*}{\makebox[0.15\textwidth]{Spectral \cite{amini2013pseudo}}} 
& N & 0.0106 & 0.0088 \\
& A & 0.0056 & 0.0056 \\
& D & 0.0136 & 0.0131 \\
\hline
\multirow{3}{*}{\makebox[0.15\textwidth]{Louvain \cite{blondel2008fast}}} 
& N & 0.4791  & 0.4461 \\
& A & 0.4923 & 0.4923 \\
& D & 0.4882 & 0.4792 \\
\hline
\multirow{3}{*}{\makebox[0.15\textwidth]{GCC \cite{fettal2022efficient}}} 
& N & 0.3425 & 0.3128 \\
& A & 0.3743 & 0.3743 \\
& D & 0.3675 & 0.3597 \\
\hline
\multirow{3}{*}{\makebox[0.15\textwidth]{LSEnet \cite{sun2024lsenet}}} 
& N & 0.3732 & 0.3569 \\
& A & 0.4215 & 0.4135 \\
& D & 0.3968 & 0.3913 \\
\hline
\multirow{1}{*}{\makebox[0.15\textwidth]{\textbf{CUSA} (ours)}} 
& - & \textbf{0.4993} & \textbf{0.4972} \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsection{Experiments on HASNs without Evolution}
Table \ref{The Q and HQ results on the Cora dataset (without evolving)} assesses Q and HQ results of all methods on the Cora dataset transformed into HASNs using the four generation strategies, without evolving. For consistency, the other settings align with Table \ref{The Q and HQ results on the Cora dataset}. Compared to Table \ref{The Q and HQ results on the Cora dataset}, the performance trends of each method across different generation strategies remain largely unchanged, though the values of Q and HQ show a slight decline. This is because AI nodes, when initially inserted into the network, only influence the topology of their immediate neighbors, limiting their ability to facilitate social interactions across the entire network. To better reflect real-world scenarios, where AI nodes foster the formation of new social connections, we incorporate social network evolution in our experiments following the insertion of AI nodes (\textit{cf.} Appendix \ref{sec: The Evolution of HASNs}).


\subsection{Experiments on Random Networks}
In Table \ref{The Q and HQ results on the ER-based random HASN}, we conduct experiments on an Erdős-Rényi-based random HASN (ER-based HASN) \cite{erdds1959random} aligning with the Cora dataset and demonstrate that CUSA effectively distinguishes the community structures in real-world networks from those in random networks. Following \cite{erdds1959random}, we generate a random network with 2708 nodes and 5429 edges, aligning with Cora dataset. The ER-based HASN is then constructed by inserting AI nodes (10\% of the total nodes) using k\% random insertion, followed by evolution, resulting in a network with 2978 nodes and 6254 edges. We evaluate Q and HQ across all methods on the ER-based random HASN, as shown in Table \ref{The Q and HQ results on the ER-based random HASN}. Compared to the results on Cora presented in Table \ref{The Q and HQ results on the Cora dataset}), both Q and HQ values are significantly lower, reflecting the fundamental differences between real-world and random networks. Since the ER-based HASN inherently lack community structures, its lower Q scores confirm that CUSA successfully detects meaningful communities in structured datasets such as Cora, where it obtains Q = 0.8190. In contrast, the ER-based HASN exhibits a much lower Q = 0.4993, further validating the ability of CUSA to distinguish real-world community structures from randomly generated networks.


\begin{table}[t]
\centering
\caption{Statistics of Timik (3,000-node subgraph)}
\label{timik_statistics}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{ccccccc}
\toprule
Dataset & \#N & \#E & \#AIs & AD & H-AI AD & H-H AD \\
\midrule
Timik & 3000 & 9258 & 1396 & 6.17 & 3.75 & 2.39 \\
\bottomrule
\end{tabular}
}
\end{table}



\begingroup
\renewcommand{\arraystretch}{1.152}
\begin{table}[t]
\centering
\caption{The basic statistical analysis of the real-world HASN (Timik) \cite{chen2022user}, where InRatio denotes the proportion of intra-community edges for each AI node.}
\label{The basic statistical analysis of the real-world HASN}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcc}
\toprule
Interval of InRatio & \#AI nodes & Proportion of Total AIs \\
\midrule
$[0.0, 0.1)$ & 480 & 34.38\% \\
$[0.1, 0.2)$ & 1 & 0.07\% \\
$[0.2, 0.3)$ & 11 & 0.79\% \\
$[0.3, 0.4)$ & 26 & 1.86\% \\
$[0.4, 0.5)$ & 16 & 1.15\% \\
$[0.5, 0.6)$ & 134 & 9.60\% \\
$[0.6, 0.7)$ & 82 & 5.87\% \\
$[0.7, 0.8)$ & 52 & 3.72\% \\
$[0.8, 0.9)$ & 46 & 3.30\% \\
$[0.9, 1.0]$ & 548 & 39.26\% \\
\bottomrule
\end{tabular}
}
\end{table}
\endgroup

\subsection{The Validation of Generation Strategies}
\label{Validation of Generation Strategies}
In Table \ref{timik_statistics} and Table \ref{The basic statistical analysis of the real-world HASN}, we validate the proposed generation strategies, particularly strategies (2)–(4) (i.e., inverse degree-based insertion, introverted and extroverted AI distribution, and AI with dual personality) (\textit{cf.} Appendix \ref{sec: The Proposed HASN Scenarios}), by analyzing statistics from a real-world HASN, Timik \cite{chen2022user}. Based on AI interaction patterns, we categorize our generation strategies into two groups: (1) Personality-oriented: This includes introverted and extroverted AI distribution, as well as AI with dual personality. AI nodes are designed to exhibit human-like personality traits, ranging from introverted to extroverted or a combination of both \cite{zhang2024better}. (2) Task-oriented: This involves inverse degree-based insertion, where AI nodes preferentially connect to low-degree human nodes to help reduce loneliness \cite{skjuve2021my}\cite{loveys2019reducing}.

Timik is a dataset collected from a social metaverse, where digital twins replace offline users and continue their activities in the virtual world \cite{chen2022user}. In this study, we treat digital twins as AI nodes. Since the original Timik network is significantly larger, we extract a 3,000-node subgraph for analysis while preserving the structural properties. The basic statistics of this Timik subgraph are shown in Table \ref{timik_statistics}, where AD stands for the "Average Degree". To analyze AI behavior patterns in Timik, we conduct basic statistical analyses on its AI nodes to examine two types of interaction patterns:

\noindent \textbf{(1) Personality-oriented patterns}: To determine whether AI nodes follow personality-oriented patterns, we calculated the proportion of intra-community edges for each AI node (denoted by InRatio). A higher InRatio indicates an introverted AI, while a lower InRatio suggests an extroverted AI. An InRatio around 0.5 implies dual-personality AI. The corresponding results are presented in Table \ref{The basic statistical analysis of the real-world HASN}.  Inspection of Table \ref{The basic statistical analysis of the real-world HASN}, we observe that nearly 40\% of AI nodes are introverted, another 40\% are extroverted, and approximately 10\% possess a dual personality. This validates that the introverted and extroverted AI equally distributed generation strategy closely resembles the patterns found in Timik. Besides, although the AI with dual personality strategy differs slightly from Timik, the presence of dual AI in Timik is relatively common, supporting its relevance. 

\noindent \textbf{(2) Task-oriented patterns}: To examine whether AI nodes follow task-oriented patterns, we compared the average number of human friends between all human nodes and those connected to AI nodes.  As shown in Table \ref{timik_statistics}, the Human-AI and Human-Human average degrees (denoted by H-AI AD and H-H AD) are 3.75 and 2.39, respectively. Since human nodes connected to AI nodes do not exhibit significantly fewer human friends, the inverse degree-based insertion strategy does not align with the AI behavior patterns observed in Timik. This discrepancy may arise from the fact that AI nodes in Timik, acting as digital twins, mimic the behavior of their original users, most of whom do not intentionally aim to reduce others' loneliness.



\begingroup
\renewcommand{\arraystretch}{1}
\begin{table}[t]
\centering
\caption{The Q and HQ results on the real-world dataset (Timik) \cite{chen2022user}, obtained by CUSA in comparison to that of four clustering baselines each equipped with no removal of AIs (N), all removal of AIs (A), and removal of AIs by GAD (D).}
\label{The Q and HQ results on the Timik dataset}
\small
\resizebox{\columnwidth}{!}{%
\begin{tabular}{cccc}
\toprule
\textbf{Method} & & \textbf{Q (↑)} & \textbf{HQ (↑)} \\
\midrule
\multirow{3}{*}{\makebox[0.15\textwidth]{Spectral \cite{amini2013pseudo}}} 
& N & 0.0275 & 0.0146 \\
& A & 0.0198 & 0.0198 \\
& D & 0.0232 & 0.0152 \\
\midrule
\multirow{3}{*}{\makebox[0.15\textwidth]{Louvain \cite{blondel2008fast}}} 
& N & 0.4038  & 0.2120 \\
& A & 0.3721 & 0.3721 \\
& D & 0.3812 & 0.2638 \\
\midrule
\multirow{3}{*}{\makebox[0.15\textwidth]{GCC \cite{fettal2022efficient}}} 
& N & 0.3653 & 0.1921 \\
& A & 0.3437 & 0.3437 \\
& D & 0.3512 & 0.2154 \\
\midrule
\multirow{3}{*}{\makebox[0.15\textwidth]{LSEnet \cite{sun2024lsenet}}} 
& N & 0.3712 & 0.2021 \\
& A & 0.3540 & 0.3540 \\
& D & 0.3658 & 0.2787 \\
\midrule
\multirow{1}{*}{\makebox[0.15\textwidth]{\textbf{CUSA} (ours)}} 
& - & \textbf{0.4324} & \textbf{0.4238} \\
\bottomrule
\end{tabular}%
}
\end{table}
\endgroup


\subsection{Experimental Results on Real-world HASNs}
In Table \ref{The Q and HQ results on the Timik dataset}, we carry out experiments on Timik, a real-world HASN, to evaluate the practical utility of CUSA in comparison to all baseline methods. The corresponding results are presented in Table \ref{The Q and HQ results on the Timik dataset}, from which two key observations can be drawn. 

First, CUSA outperforms all baselines across all removal strategies in terms of both Q and HQ. Even with AI nodes comprising 46\% of the total nodes in Timik, CUSA achieves high performance by leveraging AI Scoring to carefully select an appropriate number of AI nodes (ensuring a high human-to-AI ratio) to participate in communities while preserving high modularity. In contrast, the all-removal strategy (A) results in the lowest Q, as completely disregarding AI nodes creates a loosely connected structure in Timik, making it difficult to identify well-defined community structures due to sparse interconnections. The no-removal strategy (N) achieves a high Q but a significantly low HQ due to an extremely low human-to-AI ratio. Similarly, the GAD-based AI removal strategy (G) yields a low HQ relative to Q because most AI nodes remain embedded within communities. This highlights the limitations of GAD in distinguishing influential AI nodes from others, particularly when AI nodes exhibit human-like behaviors in real-world applications, ultimately leading to poor human-to-AI ratios and lower HQ. 

Second, it is noteworthy that CUSA consistently identifies communities with Q and HQ across varying proportions of AI nodes. This is achieved by carefully assessing each AI node's impact on network interactions through AI Scoring. By contrast, the all-removal strategy (A) is highly sensitive to AI node proportions. It performs well at low AI ratios (e.g., 10\%, as shown in Tables \ref{AI node scoring methods}, \ref{The HQ results on different datasets}, and \ref{The Q and HQ results on the Cora dataset}) but declines sharply as AI presence increases, as seen in Timik, where the all-removal strategy lags far behind CUSA. This highlights the limitations of indiscriminate AI removal and underscores the need for AI-aware clustering to balance human-centric communities while adapting to AI’s evolving role in social networks.

\begingroup
\renewcommand{\arraystretch}{1.1}
\begin{table}[t]
\centering
\caption{The HMR and ADM results on different datasets obtained by CUSA.}
\label{The HMR and ADM results of CUSA across different datasets}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lccc}
\toprule
Dataset & Avg. Degree & HMR (\%) & ADM \\
\midrule
Cora & 4.01 & 14.09\% & 20.41 \\
CiteSeer & 2.84 & 56.41\% & 56.3 \\
PubMed & 4.50 & 42.03\% & 435.74 \\
Timik & 6.17 & 30.47\% & 47.71 \\
\bottomrule
\end{tabular}
}
\end{table}
\endgroup

\subsection{The HMR and ADM Results on Different Datasets} 
\label{HMR and ADM Results on Different Datasets}
Table \ref{The HMR and ADM results of CUSA across different datasets} demonstrates the HMR and ADM results of CUSA on different datasets. The findings indicate that incorporating AI nodes in community detection reshapes the identified communities, influencing not just immediate neighbors but also broader network structures. This is evident from ADM values, which are significantly higher than the average degree, underscoring the substantial role of AI nodes in community formation.

