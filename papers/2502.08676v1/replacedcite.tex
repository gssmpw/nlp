\section{Related Work}
In recent years, numerous LiDAR-inertial-visual fusion frameworks have been proposed to enhance the accuracy and robustness of SLAM systems under challenging conditions. ____ introduced a cascaded approach combining tightly coupled stereo VIO, LiDAR odometry, and a LiDAR-based loop-closing module to improve system performance. Lic-Fusion fused IMU data, sparse visual features, and LiDAR features within the multi-state constrained Kalman filter (MSCKF) framework, achieving online spatial and temporal calibration. LIC-Fusion 2.0____ further improved LiDAR point registration accuracy by introducing a plane-feature tracking algorithm across multiple LiDAR sweeps in a sliding window and refining sweep poses within the window. Graph-based optimization has also been explored in systems like LVI-SAM____, which tightly couples data from cameras, LiDAR, and IMUs. LVI-SAM allows independent operation of the vision and LiDAR modules when one fails or joint operation when both provide sufficient features. FAST-LIVO____ streamlined the fusion process by integrating LiDAR, camera, and IMU measurements into a single error-state iterated Kalman filter (ESIKF), enabling updates from both LiDAR and visual observations. FAST-LIVO2____, an upgraded version of FAST-LIVO, achieves higher pose estimation and mapping precision with exposure time estimation, reference patch update and normal refinement in real-world experiments. R3LIVE____, built on R2LIVE____, omitted the graph-based optimization module and introduced a color rendering module for dense color map reconstruction. SR-LIVO ____ utilizes sweep reconstruction to align LiDAR scans with camera timestamps, facilitating precise state estimation at imaging instances and significantly improving pose accuracy and computational efficiency. Likewise, FAST-LIVO2 synchronizes LiDAR point cloud frames to match the camera frame rate, ensuring temporally consistent updates between LiDAR and visual measurements, which enhances the cohesiveness of data fusion and overall system performance. 
%R2LIVE____ proposed running LIO and VIO modules in parallel, with the LIO module providing geometric information for the VIO module and the backend using visual landmarks for graph-based optimization

In the field of VIO, many deep learning-based approaches have been employed to enhance robustness, accuracy, and performance. Droid-SLAM____, for instance, has demonstrated an end-to-end visual SLAM system. However, its training process is time-consuming and computationally expensive. Beyond end-to-end methods, a growing body of research focuses on leveraging deep learning techniques to optimize the performance of the front-end, while relying on traditional filtering or factor graph optimization algorithms for the back-end. SupSLAM____, a robust visual-inertial SLAM system that leverages SuperPoint____ for feature detection and description, enabling accurate localization and mapping in challenging environments. AirVO____ utilizes SuperPoint for feature detection and SuperGlue____ for feature matching, achieving high robust front-end. In the new version of AirVO, known as AirSLAM, the LightGlue____ algorithm is utilized as a replacement for SuperGlue, moderately improving the efficiency of feature matching. An increasing number of deep learning-based front-end feature extraction and tracking methods have been proposed, such as XFeat____. With graphics processing unit (GPU) support, deep learning-based front-end systems have achieved a level of real-time performance comparable to traditional front-end approaches____.% Among these features, XFeat currently stands out as the most effective deep learning feature for balancing efficiency and accuracy