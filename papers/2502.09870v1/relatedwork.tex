\section{Related Work}
\subsection{Anthropomorphic \add{D}esign in \add{T}echnology}
Anthropomorphism is the attribution of human-like \add{qualities}\remove{forms} to inanimate objects or entities \cite{disalvo2004kinds}. Within fields like human-robot interaction, researchers have studied how to enhance anthropomorphic features of robots in order to make robots easier to interact with \cite{fink2012anthropomorphism, riek2009how, lee2006can}. Realistic features such as eye expression output, mannerisms, and other complex emotions have been incorporated into robots as the bounds of what can be anthropomorphized evolve ~\cite{cohn2024believing, mishra2023real, liu2023robots}. Existing work has also noted the ways that humans might be likely to anthropomorphize technologies even when those technologies have not been designed in purposefully anthropomorphic ways \cite{nass1994computers}.

The broader HCI community has seen a growth in anthropomorphic characteristics being integrated into large language models ~\cite{cohn2024believing, cheng2024anthroscore}, with design goals oriented around completing a task (e.g., voice assistant\add{s}) or health care and well-being ~\cite{seymour2021exploring, sin2019preliminary}. Motivating factors to implement humanistic traits to appeal to the likeness of users may be rooted in business incentives (such as influencing a customer to complete a transaction) or attempts to improve user trust as a means to increase engagement (e.g., a telehealth chatbot) ~\cite{schanke2021estimating, kim2024anthropomorphism}. Trust is a particularly common \add{motivation for}\remove{thread in} these anthropomorphic technological design\remove{s} \add{decisions}, especially when human-like characteristics go beyond the physical appearance of humans and mimic their personality traits and cognitive abilities ~\cite{lee2006can, harrington2023trust}. 

Recently, this anthropomorphism has increased to the extent that people have begun to believe that LLMs and other technologies have the capacity to achieve and exhibit human levels of cognition, sentience, and awareness~(e.g.,~\cite{stephen2024sentient, orf2024stunning, chalmers2023could}). There have even been high-profile cases of claims that LLMs are and should be treated as people~(e.g.,~\cite{Tiku2022google}). 

We situate our research against this backdrop, highlighting the importance now as much as ever for work that advances and clarifies understandings of anthropomorphism. 


\subsection{Negative Impacts \add{from} \add{A}nthropomorphism \add{of Technologies}} \label{RWharms}
Prior work has raised concerns about various harms that anthropomorphism of technologies might give rise to~(e.g.,~\cite{ferrari2016blurring,friedman1992human, bender2021on, akbulut2024all}). One immediate negative impact \add{from}\remove{of technological} anthropomorphism \add{of technology} is the possibility of inauthenticity and deception, with users believing they are talking to a human rather than a machine~\cite{Gros2021-jh,Gros2022-eq, Schneidernnan1988-nz}. %turkle thing here about authenticity?
%
Scholars have also pointed out other more insidious and long-term impacts of anthropomorphism of technologies. For example, \remove{technological }anthropomorphism \add{of technology} often enhances users' trust of systems~\cite{Troshani2020-qp}. While this trust can be beneficial in some contexts~\cite{Yanai2020-wi}, it can also be misplaced, leading users to rely on technology when it does not merit such confidence and overestimate its capabilities~\cite{abercrombie2023mirages, Kim2024-sv,Ibrahim2024-ym,Chien2024-sd, luger2016like}. This misplaced trust may even cause users to become emotionally dependent on the system or to disclose sensitive information without fully understanding the associated privacy risks \cite{Ischen2020-it, Ibrahim2024-ym}. 

Furthermore, other scholars have argued that human-like technologies may contribute to the devaluation of human interaction and expression, potentially leading to the cheapening of language, increased social disconnection, and diminished human agency~\cite{Porra2020-dq, Turkle2013-te,Weidinger2022-pz,Watson2019-py}. Additionally, anthropomorphism has been linked to the reinforcement of gender and racial stereotypes \cite{Bender2024-de,Erscoi_undated-nf,Maeda2024-cv,abercrombie2023mirages}.

We see the conversations about and mitigation of negative impacts \add{from}\remove{of technological} anthropomorphism \add{of technologies} as important and urgent \cite{cheng2024i}. We orient our taxonomy toward providing needed scaffolding for future identification of and discussions about the ways in which anthropomorphism is occurring so that more targeted work on interventions can be accomplished.


\subsection{Types of Anthropomorphism \add{of Technologies}}
Past work has attempted to understand, name, and categorize different types of anthropomorphism \cite{emnett2024using}. Some of this comes from a human-robot interaction context, looking to assess the ways that robots are human-like, often with the guiding aim of supporting work that makes robots more and more similar to humans. For instance, DiSalvo et al. examine designed artifacts and distinguish between four different kinds of anthropomorphic form: structural, gestural, character, and aware \cite{disalvo2004kinds}. And Kahn et al. present a set of nine benchmarks---autonomy, imitation, intrinsic moral value, moral accountability, privacy, reciprocity, conventionality, creativity, and authenticity of relation---that could be used to assess how human-like robots are \cite{kahn2007what}. Though this research is focused more on robots, robots are more than just tangible objects and often include spoken or other forms of interactions that can be useful to inform text contexts.

There is work that focuses on anthropomorphism stemming from linguistic aspects of robots or other tangible technologies. Emnett et al. survey literature to present ``six broad categories of linguistic factors that lead humans to anthropomorphize robots: autonomy, adaptability, directness, politeness, proportionality, and humor'' \cite{emnett2024using}. Otsu and Izumi categorize linguistic anthropomorphism techniques for home appliances into first-person subject expressions, expressions suggesting body ownership and animacy, casual linguistic expressions, and explicit emotional expressions~\cite{otsu2022investigation}.

Recently, more work has tried to break down types of anthropomorphism in AI contexts. \add{Some existing work has explored the ways that descriptions of AI systems can contribute to anthropomorphism (e.g., \cite{cheng2024anthroscore, langer2022look}). For example,}\remove{ And} Inie et al. use prior work to define four categories of anthropomorphism fostered by \textit{descriptions} of AI systems: properties of a cognizer, agency, biological metaphors, and properties of a communicator \cite{inie2024from}. \add{Ryazanov et al. separate language anthropomorphizing AI on news websites into groups such as ``anthropomorphism of convenience'' that describes system behaviors in non-technical terms and ``genuine projection of the capacity to think and feel onto the technology'' \cite{ryazanov2024how}. And Shardlow and Przyby\l{}a categorize terms used to describe language models in NLP papers into non-, ambiguous, and explicit anthropomorphism~\cite{shardlow2023deanthropomorphising}.}

\add{In addition to work on anthropomorphism stemming from descriptions of AI systems, recent work has also explored ways that system behaviors themselves can lead to anthropomorphism.}
Glaese et al. describe a set of four rules for dialogue systems to avoid harmful anthropomorphism---no body, no relationships, no opinions or emotions, not human---which implicitly identifies four categories of anthropomorphism as claims to a body, to relationships, to opinions or emotions, and to humanness \cite{glaese2022improving}. Work by Gabriel et al. includes a review of AI features that have been associated with perceptions of human likeness, grouping the features into three high-level categories: self-referential, relational statements to the user, and appearance or outward representation \cite{gabriel2024ethics}. 
%We include this as relevant because system outputs can describe themselves. 
Attending to both AI contexts and linguistic factors, Abercrombie at al. outline linguistic factors that contribute to the anthropomorphism of dialogue systems, as synthesized from prior literature \cite{abercrombie2023mirages}; to name their high-level themes, they discuss factors related to voice, content, register and style, and roles. 

Unlike these existing categorizations, in this work, we focus on categorizing linguistic factors of natural language technology outputs, and we do this with \textit{an empirical foundation} of in-the-wild cases in addition to a basis on past work.