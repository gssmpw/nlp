


%aims to lower the technical barriers and cost to the development of advanced scientific software to facilitate urban and environmental management within smart city initiatives.


 

%This research introduces a system-based methodology to automate the development of sophisticated web-based GIS applications to support urban and environmental management within smart city initiatives. By employing ontology-driven prompts and large language models (LLMs), our approach leverages the AI's capabilities in generation, reasoning, and learning to create a primitive autonomous agent that assists academic researchers and prospective developers by lowering both the technical barriers and costs associated with developing cyberinfrastructure and scientific software tools. Technically, we have developed a prototyping framework that creates a Knowledge Graph (KG) to digitally represent software engineering practices, popular application stacks, package management tools, and domain-specific knowledge of data and simulations. The KG is later used to generate, tune, and enhance engineered prompts through iterative procedures, providing precise instructions for the ChatGPT 4.0 API, DALL-E API, and LangChain to automate the development of geo-visual dashboards using web frameworks and technologies favored by the industry. We demonstrate the effectiveness and feasibility of our framework with a case study of an AI-generated visual dashboard of atmospheric and dispersion data from real-time sensors, machine learning analytics, and environmental simulations using the React framework and Python Tornado server. This study investigates the potential of LLMs to function as full-stack web developers and GIS analysts. By leveraging scientific KGs, the LLMs are guided to comprehend advanced software design and architecture patterns, such as MVC and MVVM, as well as complex scientific data, illuminating the autonomous development of robust, generalized, and scalable geospatial web applications that perform efficiently on both the server and client sides.


%This pipeline leverages urban
%science domain ontologies to transform scientific concepts (datasets, simulation models, metrics, AI algorithms) into software components using robust design patterns. Utilizing LLMs for natural language understanding, reasoning, and coding, it automatically implements these components in popular programming languages. Our AI-powered urban digital twins offer advanced capabilities: real-time IoT data visualization, multi-objective decision optimization, and predictive analytics for urban dynamics. We validate our pipeline with three smart city case studies focusing on freight transportation management, urban climate modeling, and building energy optimization. Implemented using the GPT-4 API in a Python environment, our pipeline synergizes with knowledge graphs created using prevalent ontology languages. The results are compelling: for each case study, the pipeline efficiently generated operational digital twins using an MVC-based Python framework. This marks a significant reduction in manual software design and coding efforts. Our research presents a pioneering path towards next-generation AI-powered urban digital twins that are self-generating, self-organizing, and self-executing, demonstrating the transformative potential of LLMs in urban technology development.



%The study develops 
%The study develops formal models, both information and functional, and establishes the methodological foundations for integrating ontology-driven prompts with ChatGPT's meta-learning capabilities. The resulting productive triad comprises the methodological foundations, advanced information technology, and the OntoChatGPT system, which collectively enhance the effectiveness and performance of chatbot systems. The implementation of this technology is demonstrated using the Ukrainian language within the domain of rehabilitation. By applying the proposed methodology, the OntoChatGPT system effectively extracts entities from contexts, classifies them, and generates relevant responses. The study highlights the versatility of the methodology, emphasizing its applicability not only to ChatGPT but also to other chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2 LLM. The underlying principles of meta-learning, structured prompts, and ontology-driven information retrieval form the core of the proposed methodology, enabling their adaptation and utilization in various LLM-based systems. This versatile approach opens up new possibilities for NLP and dialogue systems, empowering developers to enhance the performance and functionality of chatbot systems across different domains and languages.


%Large Language Models (LLMs) have revolutionized fields ranging from creative writing to code generation with their deep understanding of human language. In this paper, we harness the LLMs' capabilities to automate the full-stack web application development of GIS-based scientific visual dashboard to support environmental management and
%smart city research. 

Developing web-based dashboards for advanced querying, visualization, and interaction with GIS data in environmental research often requires repeated, costly software development. While generative AI (GenAI) code generation shows promise, it faces challenges in handling complex scientific software that demands domain expertise, advanced software engineering practices, and intricate user workflows, due to the token limits and attention capabilities of current large language models (LLMs). To address these challenges, this paper presents a knowledge-driven framework that leverages knowledge representations in software engineering, scientific data, simulations, and software stacks to instruct and fine-tune Generative Pre-trained Transformers (GPT). This enables an autonomous software development workflow for generating code for sophisticated web applications, such as CyberGIS dashboards and visual analytics interfaces, from user-defined GUI wireframes sketched in PowerPoint or other graphical design tools (e.g., Adobe Illustrator). The prototyping workflow was implemented in Python using cutting-edge Generative AI and software engineering technologies, including the ChatGPT API and a local Ollama instance, within a RAG (Retrieval-Augmented Generation) paradigm that leverages Knowledge Graphs (KG) and vector databases. We demonstrate the feasibility and effectiveness of our framework through a case study that autonomously created a web-based platform that entails multiple visualization dashboards of environmental and energy data (e.g., time-series and spatial) based on user-defined visual prompts. The platform was built following industry-standard software engineering practices, such as Single-Page Application (SPA) and Model-View-ViewModel (MVVM) architecture patterns, that are modular, generalizable, reusable, and maintainable. Our work demonstrates the potential to reduce manual software design, coding, and maintenance efforts by guiding GenAI with software engineering knowledge, pioneering an autonomous and scalable approach for generating complex web applications to facilitate urban and environmental management within the smart city initiatives

In the past decades, scientific web applications (Web Apps), such as CyberGIS systems, visual analytical dashboards, digital twin platforms, and online decision support systems, have become indispensable tools for enabling both the scientific community and the public to discover, query, visualize, and download vast amounts of urban and environmental datasets in smart city research \citep{ferre2022adoption, dembski2020urban}. Aligned with the NSF's cyberinfrastructure (CI) initiative, academia and governmental science agencies have increasingly developed and adopted web applications as part of interdisciplinary informatics projects to serve as effective, user-friendly tools for cyber-delivery \citep{yu2021coevolution}. With advancements in internet and communication technologies, computing hardware, and artificial intelligence, these tools are transforming urban and environmental research by enabling data- and simulation-driven insights for decision support and optimization\citep{kadupitige2022enhancing}, fostering collaborative research through data and simulation sharing and integration \citep{parashar2019virtual}, and enhancing education and public engagement for citizen science and voluntary data collection \citep{skarlatidou2019volunteers} across various smart city disciplines. Notable application disciplines include water resources management \citep{souffront2018cyberinfrastructure, xu2022overview}, hazard mitigation \citep{mandal2024prime, xu2020web, garg2018cloud}, intelligent transportation systems \citep{xu2023smart, xu2022interactive, ghosh2017intelligent}, connected and automated vehicles\citep{xu2023mobile, kampmann2019dynamic}, built-environment management \citep{jia2019adopting, kim2022design}, and urban planning and design \citep{alatalo2017two}. Numerous interdisciplinary studies have demonstrated the transformative and unique capabilities of these scientific web applications in advancing environmental and urban research, as well as smart city management. Their continuous evolution is driven by the integration of emerging technologies such as artificial intelligence, the Internet of Things (IoT), edge computing, and cyber-physical systems. 

Despite the significant advancements in developing scientific web applications, creating customized software tools, such as cyberGIS and digital twin platforms for integrating and visualizing diverse types of environmental or urban data, such as hydrological data, traffic flow data, meteorological data, or simulation outputs, remains a highly demanding and resource-intensive task \citep{shanjun2024design, siddiqui2024digital, lei2023challenges}. These efforts require not only substantial expertise in software engineering and data engineering, but also considerable time spent on both client-side and server-side development, as well as database management, real-time data analytics, machine learning integration, and simulations \citep{ikegwu2022big}. As a result, urban and environmental researchers are often diverted from their core scientific and analytical work to learn complex web programming languages, frameworks, visualization libraries, UI/UX design principles, and database technologies \citep{li2022bibliometric}. Although modern software engineering practices, such as design patterns and architecture patterns, aim to streamline development and ensure maintainability, their effective use still requires specialized knowledge in software engineering \citep{fayad2015software}. Researchers, who may have programming expertise in data analytics but often lack formal software development experience, face challenges in applying these practices effectively \citep{kim2017data}. Even with the involvement of skilled software engineers, designing, developing, deploying, and maintaining large-scale scientific web applications remains a labor-intensive process, requiring repetitive and costly efforts \citep{shah2024optimizing, mcbreen2002software}. This hinders the scalability, flexibility, and adaptability of platforms like cyberGIS or digital twins, limiting their ability to incorporate new data types, extend to larger geographic regions, or enhance predictive analytics and decision support capabilities \citep{liu2015cybergis, lei2023challenges}. Given these challenges, there is a growing need to leverage emerging Generative AI (GenAI) technologies to automate various aspects of web application development to support environmental and urban research. Many contemporary studies have explored the potential and feasibility of training generative AI models, particularly Large Language Models (LLMs) and specialized variants like Generative Pretrained Transformers (GPT), to act as software developers by generating code for automating simple data analytics and software development tasks \citep{liang2024can, liukko2024chatgpt}. However, developing complex scientific web apps, such as cyberGIS platforms for querying and visualizing domain-specific environmental data across multiple sites, remains challenging. These challenges arise from the inefficiency and lack of systematic and graphical prompting methods, as well as the limitations in domain and software engineering knowledge, and attention mechanisms within current LLMs that are pre-trained using generalized text data.