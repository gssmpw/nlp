\section{Methodology}
\label{Methdology}
In the following subsections, we first discuss the motivation behind our research, highlighting the challenges we aim to address and presenting our overall strategy and knowledge-driven approach at a conceptual level. Next, we outline the software design requirements for our proposed framework, focusing on target users and key features. With these requirements defined, we introduce the overall framework design, detailing its major steps. We then provide an in-depth discussion of individual steps, including visual contextual prompting techniques, the software engineering and GIS knowledge base built on the RAG paradigm and vector databases, and the final step of code generation using a Knowledge-Augmented Generation (KAG) paradigm through iterative processes. 

Our approach focuses on knowledge augmentation for LLM-driven coding tasks rather than fine-tuning or training specific models. We propose a system-based, adaptable method that integrates software knowledge and engineering practices into user-selected LLMs. Additionally, we introduce a generalizable approach that enables end-users to leverage customly sketched UI wireframes as inputs to prompt LLMs for front-end web application development.

\subsection{Motivation and Contributions}
Our primary motivation is to develop a knowledge-driven approach for instructing LLMs, particularly GPTs, to facilitate automated code generation that aligns with software engineering best practices. This approach aims to support the development of robust and maintainable web-based GIS applications for sharing and visualizing scientific data. By leveraging industrial-grade practices, web frameworks, and modern software stacks, our method seeks to lower technical barriers for aspiring developers—specifically domain scientists with coding experience but limited knowledge of software engineering—enabling them to generate front-end code for cyberGIS software more effectively.

To address the challenges in geospatial code generation identified in recent studies \citep{hou2024can, hou2024geocode}, particularly the limitations of general-purpose GPT models in handling built-in GIS and visualization libraries and managing complex package dependencies, we propose a novel knowledge-driven approach. Existing models frequently exhibit hallucinations, runtime errors, and an inability to generate complex CyberGIS applications with advanced data querying and visualization capabilities \citep{hou2024can}. Our approach seeks to overcome these limitations by integrating structured domain knowledge with intelligent prompt engineering and package management solutions, ensuring that LLM-generated code is accurate, executable, and aligned with industry standards. The key novelties of our contributions are as follows:
\begin{description}
    \item[Knowledge-Augmented Code Generation through Code Base and Knowledge Representations: ] Unlike previous efforts that primarily focus on fine-tuning LLMs or developing knowledge bases for geospatial libraries to enhance geospatial code generation \citep{hou2024can, hou2024gee}, our approach leverages Knowledge-Augmented Generation (KAG) technologies to construct comprehensive code-base and knowledge representations in the form of a knowledge graph. This knowledge graph integrates software engineering principles with existing code examples, incorporating advanced design and architectural patterns into the CyberGIS domain. By embedding structured knowledge and real-world code instances, our approach fosters a more systematic and informed methodology for geospatial application development, improving the accuracy, maintainability, and scalability of LLM-generated geospatial code.
    \item[Visual Contextual Prompting Technique: ] Our visual contextual prompting technique is a Python-based system that enables non-technical users to design web applications using SVG-based wireframes, which are then automatically translated into structured prompts for LLM-driven code generation. This approach allows domain scientists and other non-programmers to create UI layouts in familiar tools like PowerPoint and Adobe Illustrator, which are then processed by our Python program to extract GUI components, spatial relationships, and functional annotations.
    The system queries a visual contextual knowledge base to retrieve technical implementation details for various UI elements, ensuring compatibility with modern frameworks such as React, Angular, Tailwind CSS, Bootstrap, Leaflet, and D3.js. Rather than relying on LLMs to generate raw HTML and JavaScript from scratch, this method leverages structured knowledge representations to provide precise, context-aware prompts that improve code accuracy, maintainability, and adherence to industry best practices. By integrating wireframe-based design interpretation with knowledge-driven prompt engineering, this technique significantly enhances LLM-assisted geospatial and web application development, making it more accessible to non-programmers while ensuring high-quality, scalable code generation.
    
    \item[Software Engineering Practices Implementation: ] We introduce a chain-of-steps guidance framework that utilizes engineered prompts combined with a novel visual contextual prompting technique to instruct LLMs in generating robust, web-based GIS applications. Unlike conventional methods, our approach ensures that LLMs adhere to industry-standard web development frameworks, such as the React framework, which follows the Model-View-ViewModel (MVVM) architecture to build modular and maintainable single-page applications (SPAs) for querying and visualizing GIS data in web browsers. By structuring prompts around well-defined software engineering best practices, we enhance the LLM’s ability to generate high-quality, scalable GIS applications that align with modern web development paradigms.
    \item [Multi-tool Package Management: ] In addition to application generation, we employ a knowledge-driven approach to generate structured commands that guide industry-standard package management tools, such as the NPM (Node Package Manager) for Javascript and Typescript package management, to resolve package dependencies effectively. LLMs often struggle with package compatibility and dependency resolution, leading to outdated or incompatible package suggestions. Instead of relying on the LLM to generate package management files directly—which requires extensive, up-to-date knowledge of package versions—our method abstracts package management and version control at a higher level. By leveraging structured knowledge representations, we enable the LLM to control existing package management tools dynamically, ensuring that dependency resolution is handled efficiently and in alignment with best practices. This approach mitigates the risk of broken deployments and streamlines the software development workflow, making LLM-assisted GIS application development more reliable and maintainable.
\end{description}
In this study, we present the conceptual design of our framework and its technical implementation, developed using Python within a Jupyter Notebook environment. The primary focus of our research is to explore and experiment with new paradigms that enhance existing LLM-driven code generation efforts. Rather than being tailored to a specific LLM model, our approach is designed as a generalizable knowledge framework that can accommodate and integrate with various GPT-based models, ensuring flexibility, adaptability, and scalability across different AI-driven coding workflows.

\subsection{Design Requirements}
\label{subsec:DesignRequire}
The target users of our proposed framework are domain scientists with strong scientific computing and programming skills in geospatial analysis, simulations, and data modeling. However, they have limited or no exposure to software engineering principles and best practices for developing modular, maintainable front-end web applications using widely adopted software stacks and technologies in the IT industry.

The detailed technical design requirements of our proposed framework are as follows:
\begin{description}
    \item[R1. Support for UI Sketches and Wireframes as Inputs:]  
    The framework should accept UI sketches and wireframes as input, allowing users to visually define the structure and layout of their web applications without requiring extensive front-end development or cyberGIS expertise.
    
    \item[R2. Minimal UI/UX Expertise Required for Wireframing:]  
    Users should be able to create wireframes with minimal UI/UX design experience, ensuring accessibility for domain scientists without specialized front-end design skills. The framework should accept wireframes casually sketched using commonly available software, such as vector graphics created in Microsoft PowerPoint or Word, rather than requiring professional UI/UX prototyping tools like Adobe XD, Figma, or the discontinued Adobe Muse.
    
    \item[R3. Modular and Extensible Knowledge Base:]  
    The framework should provide a structured and expandable knowledge base that allows developers and open-source communities to incrementally refine and customize sample code. By integrating domain-specific and software engineering knowledge, the framework can enhance its ability to generate front-end code with advanced features while leveraging the latest code libraries—all while adhering to best practices.
    
    \item[R4. Integration of Software Engineering Practices:]  
    The system should incorporate established software design and architectural patterns to enhance code maintainability, scalability, and compliance with industry standards. For instance, modern web applications are rarely built using plain HTML, JavaScript, and a basic Python web server. As applications grow in complexity—integrating more features, data, and user workflows—it becomes essential to adopt software engineering best practices, such as Separation of Concerns (SoC) and the Singleton design pattern. These principles help modularize components, optimize performance, and promote code reusability, ultimately leading to the development of robust web frameworks that abstract these practices into MVC (Model-View-Controller) and MVVM (Model-View-ViewModel) architectures. We aim to develop a systematic approach to guide existing LLMs specialized in code generation for specific domain areas, ensuring they adhere to IT industry conventions and technologies (e.g., web frameworks like React) to generate robust and scalable front-end web applications.
    
    \item[R5. Multi-tool Paradigm for Package Management:]  
    A multi-tool approach should be employed to manage software dependencies, leveraging dedicated package management and versioning tools specific to each programming language (e.g., Conda for Python environments and NPM or NVM (Node Version Manager) for server-side JavaScript and TypeScript). This ensures robust package selection, version control, dependency management, and seamless integration of external libraries.
    
    \item[R6. Ease of Deployment and Execution:]  
    The generated applications should be easy to deploy and execute, minimizing the technical complexity required for setting up and running the resulting web-based GIS software. 
\end{description}
Based on these design requirements, we developed a comprehensive framework within a Python environment enabled through Jupyter Notebook. This framework enables the deployment of a code generation pipeline that produces a front-end codebase in a local file-based system. The choice of a Python Jupyter environment is justified by Python’s widespread use in GIS-related tasks, with many major spatial analysis libraries built in Python. More importantly, Python seamlessly integrates with APIs and platforms for both commercial and open-source LLMs, such as OpenAI's ChatGPT API and Ollama, a framework for running local LLMs.

\subsection{Framework Design}
\label{subsec:frameworkDesign}
The overall framework design is illustrated in Figure \ref{fig:arch}, where we define 12 tasks (T1–T12) categorized into three major steps that form the core of the code generation workflow. These steps include: (1) Visual Contextual Prompting, (2) Knowledge Base and Code Base, and (3) Knowledge-Augmented Code Generation. The framework takes as input one or more user-defined wireframes that specify the layout and features of the GUI across different pages. As output, it generates the complete code base for a React project.

\begin{figure*}[htbp]
 \centering
\includegraphics[width=\textwidth]{Figures/Figure_Overall_Framework.pdf}
 \caption{Overall framework architecture.}
 \label{fig:arch}
\end{figure*}

\subsubsection{Visual Contextual Prompting}
\label{subsec:simulations1}
In Step 1, we introduce a novel visual contextual prompting technique implemented using Python scripts. This technique parses, interprets, and translates GUI wireframes into structured prompts that guide LLMs in generating high-quality JavaScript and TypeScript code. Unlike conventional prompting methods that rely solely on textual descriptions, our approach empowers non-technical users, such as domain scientists, to design web applications visually using familiar sketching tools like PowerPoint and Adobe Illustrator.

Many existing graphical prompting methods rely on computer vision (CV)-based techniques to interpret wireframes from bitmap images such as PNG and JPEG. In contrast, our method takes a different approach by processing wireframes in SVG format, which is more easily editable and modifiable during the prototyping stage. This provides a structured yet flexible way to define user interface (UI) components without requiring programming expertise. This step consists of two tasks, T1 and T2, designed to meet the design requirements R1 and R2 outlined in Subsection \ref{subsec:DesignRequire}. The details of these tasks are as follows:
\begin{description}
    \item[T1. Vectorization \& Content Interpretation] A Python program has been developed to process wireframe files exported from PowerPoint or Adobe Illustrator in vector formats (e.g., EPS, SVG). The program extracts spatial and contextual information from graphical elements stored in these vector files to construct the HTML layout and components. Each GUI component—such as dropdown menus, web maps, charts, and form inputs—is represented as a vector graphical entity with embedded annotations that define its intended functionality and attributes. These annotations specify critical details, including whether a component functions as a data visualization element (e.g., bar chart, pie chart), a mapping interface (e.g., web map, layer switcher), or a UI control (e.g., button, slider, dropdown menu). Additionally, the annotations capture interactions and dependencies between components, which are later utilized to generate prompts instructing LLMs on how to bind events to these elements.
    \item[T2. Visual Contextual Info Calculation]  Another script is developed to calculate the visual contextual information of each SVG element, which represent individual HTML element in the GUI. The contextual information is used to describe the position, size, and style of each HTML element, and is later combined with the extracted wireframe annotations to create engineered prompts that provide LLMs with precise, context-aware instructions. These prompts not only define the individual components but also establish their interdependencies, layout structures, and event handling logic within the larger web application architecture. This structured approach significantly improves the accuracy, efficiency, and maintainability of LLM-generated code, ensuring that outputs conform to industry standards while preserving the original design intent of the non-technical user. By integrating visual design with contextual knowledge-based prompting, this technique effectively lowers the barrier for domain scientists and other non-programmers to develop sophisticated, web-based GIS and data visualization applications without requiring direct coding expertise. 

\subsubsection{Knowledge Base and Code Base}
\label{subsec:KB_CB}
The input information, including graphical components, visual contextual details, and annotations extracted from user-defined wireframe files, captures only the GUI design and software requirements. These specifications are expressed in plain, non-technical language, enabling users without web development or computer science expertise to define their application requirements without coding knowledge. In this setting, a combined knowledge base and code base is required to interpret plain-language inputs from context-aware visual prompts and annotations, transforming them into software development strategies. These strategies facilitate the generation of structured prompts enriched with sample code, which are then used to guide LLMs for code generation in a Retrieval-Augmented Generation (RAG) framework. 

Our knowledge base was developed by constructing knowledge graphs that encapsulate software development experiences, system requirements, and architectural designs derived from our previous projects on digital twins, cyber infrastructure, and web-based visual analytics dashboards, as depicted in Table \ref{tab:KG_previousProjects}. These knowledge graphs document and classify software stacks, componentization methods, and system designs based on domain-specific use cases and data types. 

\input{Table/table1.tex}

An example of the knowledge graph structure is depicted in Figure \ref{fig:example}. The sample code stored within these graphs is either excerpted and refined from previous projects or augmented using the ChatGPT API under expert review and supervision.

The process of knowledge-driven prompting follows a procedural approach, structured through tasks T3 to T8, ensuring a systematic and context-driven software development workflow. These tasks are detailed in the following list, with their rationale depicted in Figure \ref{fig:KG_method}. 

\begin{figure*}[htbp]
 \centering
\includegraphics[width=\textwidth]{Figures/Figure_knowledge_base.pdf}
 \caption{Structured knowledge representations for translating plain-language annotations from UI wireframes into structured prompts using technical language. }
 \label{fig:KG_method}
\end{figure*}

\begin{description}
    \item[T3. Define Framework \& Library Selection Criteria]  
    This task establishes criteria for selecting web frameworks and libraries based on wireframe annotations. A vector index search on a knowledge graph—spanning software engineering and CyberGIS domains—maps user-defined UI elements (e.g., date selector, GIS map) to corresponding React components (e.g., calendar dropdown, web map engine). The knowledge graph stores metadata on HTML elements, events, and best practices, ensuring context-aware and industry-aligned component selection.

    \item[T4. Generate HTML/TypeScript Component Tree]  
    Using extracted GUI components and annotations, this task constructs a structured HTML/TypeScript component tree representing the front-end layout. Components are mapped to web elements while preserving semantic correctness, hierarchical relationships, and relevant CSS styles. Wireframe context guides nested structures and component interactions.

    \item[T5. Classify \& Select Front-End Libraries]  
    Based on T3's criteria, this task selects appropriate front-end software stacks, including CSS frameworks, UI libraries, mapping tools, and data visualization frameworks. It determines whether to use standard HTML elements or third-party solutions (e.g., Material-UI, Tailwind CSS, D3.js, Leaflet). A vector index search retrieves optimal libraries from a Neo4j-backed knowledge graph, ensuring usability, performance, and maintainability.

    \item[T6. Create Operating System Commands for Package Management Tools] After the selection of libraries in T5, our Python script retrieves the corresponding operating system (OS) commands for installing, updating, and uninstalling these libraries using the appropriate package management tools. For example, JavaScript and TypeScript dependencies can be managed using NPM and NVM, while Python libraries are handled through Pip and Conda, and system-level packages through APT (for Debian-based systems) or Yum (for RHEL-based systems). The script generates multiple package management OS commands for handling multiple dependencies in a sequence. These commands are then consolidated and exported into OS script files, such as .sh or .bash, enabling one-stop-shop execution for package management tasks under different Dev/Ops environments (Windows or Linux), including installation, version control, and conflict resolution, through the use of dedicated package management tools.
    \item[T7. Apply Software Design \& Architecture Patterns]  
    This task ensures adherence to maintainable, scalable, and modular software design principles by incorporating patterns like **Separation of Concerns (SoC), MVC, and MVVM**. It utilizes industry-standard frameworks (e.g., React, Angular) and structured prompt templates to guide LLMs in generating code with proper **componentization, event binding, and state management**.

    \item[T8. Generate Software Development Prompts]  
    Expanding on T6, this task refines structured software development prompts for LLM-driven code generation. It integrates component-based development, lazy loading, and dynamic rendering while embedding sample code from the knowledge base. The prompts provide step-by-step procedural instructions, ensuring AI-generated code follows modular design principles for reusability, maintainability, and readability.
\end{description}

Our knowledge base and code repository serve as domain experts in software engineering and GIS, facilitating the translation of plain-language annotations from wireframes into structured software development strategies. By leveraging technical terminology and software engineering best practices, we provide system-based instructions with sample code, enabling AI agents to generate robust and well-structured code in the next step.

%(a) determine the software stacks, also known as software suite that include necessary packages and libraries, required to fulfil user-defined features. 
%translate the plain-language prompts to technical language and software engineering jargon     
%Additionally, it applies reusable design patterns, such as the **Singleton** pattern for managing global states and the **Observer** pattern for handling UI event propagation, ensuring the application remains robust and extensible.   
%Once extracted, the system queries a visual contextual knowledge base that contains technical implementation instructions for each GUI component. Instead of limiting output to plain HTML and JavaScript, our approach ensures compatibility with modern web development frameworks such as React and Angular, UI design frameworks like Tailwind CSS and Bootstrap, GIS mapping libraries like Leaflet and OpenLayers, and data visualization libraries such as Highcharts and D3.js. By leveraging these structured knowledge representations, the system dynamically retrieves relevant coding patterns, component structures, and best practices associated with the specified GUI elements.

\subsubsection{Knowledge Augmented Code Generation}
\label{subsec:simulations3}
The structured prompts generated from T8 are then fed into the LLM agent to enable knowledge-augmented code generation. Given the token limit constraints of LLMs, we adopt a procedure-based, iterative approach that combines rule-based Python scripting with the customized generation capabilities of LLMs. This method ensures efficient front-end code generation using the React framework, which follows the Model-View-ViewModel (MVVM) architecture, along with established software engineering conventions and React’s standard file structure. Our KAG approach entails the following tasks from T9 to T11, which are illustrated in Figure \ref{fig:kag}. 

\begin{description}
    \item[T9. Install \& Update Packages using Operating System (OS) Scripts]  
    This task automates the installation and updating of required dependencies using OS-level scripts. It ensures that all necessary packages, including Node.js, npm, and front-end libraries (e.g., React, Material-UI, Leaflet), are properly installed and version-controlled. The scripts also handle package updates to maintain compatibility with evolving software frameworks and dependencies.

    \item[T10. Iteration-based Code Generation using LLMs]  
    Given the token limitations of LLMs, this task adopts a procedure-based, iterative approach for code generation. Rule-based Python scripts and structured prompts guide the LLMs to generate React components in a stepwise manner, ensuring compliance with best practices in componentization, event handling, and state management. The iterative process allows refinement and optimization of the generated code, minimizing redundancy and improving maintainability.

    \item[T11. Separation of Concerns (SoC) using React Convention]  
    This task enforces Separation of Concerns (SoC) by structuring the generated code according to React’s MVVM architecture. The React components, logic, styles, and API handlers are modularized into separate files, ensuring that UI elements, business logic, and data handling remain distinct. This improves scalability, maintainability, and code readability while aligning with industry standards.

    \item[T12. Script Connection \& Organization in React File Structure]  
    This task organizes and connects the generated scripts following the **React file structure convention**. The components are structured within a modular directory system (e.g., `components/`, `hooks/`, `services/`, `contexts/`). The script integration ensures that React Router, Redux (if applicable), and event-driven logic** are properly linked, allowing seamless front-end development with maintainable and reusable components.
\end{description}

\begin{figure*}[htbp]
 \centering
\includegraphics[width=\textwidth]{Figures/Figure_KAG_genreation.pdf}
 \caption{A procedure-based, knowledge-augmented code generation process that aligns with the conventions and best practices of the React framework. }
 \label{fig:kag}
\end{figure*}


After a complete React project is generated through our knowledge-augmented LLMs, two additional procedures are required before proceeding to the DevOps stage to ensure the generated code is functional, maintainable, and ready for deployment. These procedures include the following:
\begin{description}
    \item[Expert Code Review: Human-AI Collaboration for Code Refinement: ] We propose and demonstrate a Human-AI collaboration approach to refine and validate the AI-generated React code. Human experts review, debug, and revise the code to ensure correctness, performance, and adherence to industry standards. Since our method follows software engineering conventions aligned with React’s MVVM architecture, the Separation of Concerns (SoC) and code organization mirror best practices familiar to software engineers proficient in React or similar front-end frameworks. This structured design enhances the readability and interpretability of the AI-generated code, making it easier for developers to understand, modify, and integrate into production environments.
    \item[Build React Project: ] 
    Executing OS Scripts and Dependency Installation
    Once the code is validated, the React project needs to be built and configured for execution. The human user installs all required packages by running the OS scripts generated in T9 via the OS command line in either a Windows or Linux environment. This ensures all necessary dependencies, including React, Material-UI, Leaflet, and other front-end libraries, are correctly installed and up to date. After dependencies are set up, the user builds the project using NPM or NPX commands, ensuring a fully functional front-end dashboard.
\end{description}
 
For deployment, the AI-generated React project can be hosted on a server using a monolithic architecture or deployed within a Docker container as a front-end component in a microservice architecture. This ensures scalability, portability, and interoperability with other web applications, such as databases and server-side APIs. By adopting this approach, AI-generated front-end components can be seamlessly integrated into existing enterprise systems, enhancing efficiency, maintainability, and modularity.

 



 