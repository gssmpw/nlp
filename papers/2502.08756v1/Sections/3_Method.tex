\section{Methodology}
\label{Methdology}
The following subsections outline our research motivation, the challenges we address, and our conceptual knowledge-driven approach. We then define the software design requirements, focusing on target users and key features. With these in place, we present the overall framework, detailing its major steps. This includes visual contextual prompting techniques, a software engineering and GIS knowledge base leveraging the RAG paradigm and vector databases, and Knowledge-Augmented Generation (KAG) for iterative code generation.

Rather than fine-tuning or training specific models, our approach emphasizes knowledge augmentation for LLM-driven coding. We propose a system-based, adaptable method that integrates software engineering principles into user-selected LLMs. Additionally, we introduce a generalizable approach that allows end-users to use custom UI wireframes as inputs, enabling LLMs to generate front-end web applications.

\subsection{Motivation and Contributions}
Our research develops a knowledge-driven approach to instruct LLMs, particularly GPTs, for automated code generation aligned with software engineering best practices. This supports the creation of robust, maintainable web-based GIS applications for scientific data sharing and visualization. By integrating industrial-grade practices and modern software stacks, our method lowers technical barriers for domain scientists with coding experience but limited software engineering expertise, enabling them to generate front-end CyberGIS applications efficiently.

To address the challenges in geospatial code generation identified in recent studies \citep{hou2024can, hou2024geocode}, particularly the limitations of general-purpose GPT models in handling built-in GIS and visualization libraries and managing complex package dependencies, we propose a novel knowledge-driven approach. Existing models frequently exhibit hallucinations, runtime errors, and an inability to generate complex CyberGIS applications with advanced data querying and visualization capabilities \citep{hou2024can}. Our approach seeks to overcome these limitations by integrating structured domain knowledge with intelligent prompt engineering and package management solutions, ensuring that LLM-generated code is accurate, executable, and aligned with industry standards. The key novelties of our contributions are as follows:
\begin{description}
\item[Knowledge-Augmented Code Generation:] Instead of fine-tuning LLMs, we employ Knowledge-Augmented Generation (KAG) to construct code-base and knowledge representations in a knowledge graph, integrating software engineering principles and real-world examples. This systematic approach improves the accuracy, maintainability, and scalability of LLM-generated GIS code.

\item[Visual Contextual Prompting:] Our Python-based system translates SVG-based wireframes into structured prompts, allowing non-programmers to design UI layouts in PowerPoint or Adobe Illustrator. The system extracts GUI components, spatial relationships, and functional annotations, querying a visual contextual knowledge base for implementation details compatible with React, Angular, Bootstrap, Tailwind CSS, Leaflet, and D3.js. This structured prompting method improves code accuracy, maintainability, and best-practice adherence, making LLM-assisted GIS development more accessible and reliable.

\item[Software Engineering Practices Integration:] We introduce a chain-of-steps guidance framework that ensures LLMs generate robust web-based GIS applications aligned with industry standards. Unlike conventional approaches, our framework enforces software design patterns such as MVVM in React-based SPAs, improving modularity and maintainability for GIS data visualization in web applications.

\item[Multi-tool Package Management:] LLM-generated code often suffers from package incompatibility and outdated dependencies. Instead of generating package management files directly, our method employs a structured knowledge-driven approach to guide industry-standard tools like NPM for JavaScript and TypeScript. This ensures efficient dependency resolution, reducing deployment failures and improving workflow reliability in GIS application development. 
\end{description}

This study presents the conceptual design and technical implementation of our framework, developed in Python within a Jupyter Notebook environment. Our research explores new paradigms to enhance LLM-driven code generation, focusing on flexibility and adaptability. Rather than tailoring to a specific LLM, our approach is a generalizable knowledge framework that integrates with various GPT-based models, ensuring scalability across AI-driven coding workflows.

\subsection{Design Requirements}
\label{subsec:DesignRequire}
The target users of our proposed framework are domain scientists with strong scientific computing and programming skills in geospatial analysis, simulations, and data modeling. However, they have limited or no exposure to software engineering principles and best practices for developing modular, maintainable front-end web applications using widely adopted software stacks and technologies in the IT industry.

The detailed technical design requirements of our proposed framework are as follows:
\begin{description}
    \item[R1. Support for UI Sketches and Wireframes as Inputs:]  
    The framework should accept UI sketches and wireframes as input, allowing users to visually define the structure and layout of their web applications without requiring extensive front-end development or cyberGIS expertise.
    
    \item[R2. Minimal UI/UX Expertise Required for Wireframing:]  
    Users should be able to create wireframes with minimal UI/UX design experience, ensuring accessibility for domain scientists without specialized front-end design skills. The framework should accept wireframes casually sketched using commonly available software, such as vector graphics created in Microsoft PowerPoint or Word, rather than requiring professional UI/UX prototyping tools like Adobe XD, Figma, or the discontinued Adobe Muse.
    
    \item[R3. Modular and Extensible Knowledge Base:]  
    The framework should provide a structured and expandable knowledge base that allows developers and open-source communities to incrementally refine and customize sample code. By integrating domain-specific and software engineering knowledge, the framework can enhance its ability to generate front-end code with advanced features while leveraging the latest code libraries—all while adhering to best practices.
    
    \item[R4. Integration of Software Engineering Practices:]  
    The system should incorporate established software design and architectural patterns to enhance code maintainability, scalability, and compliance with industry standards. For instance, modern web applications are rarely built using plain HTML, JavaScript, and a basic Python web server. As applications grow in complexity—integrating more features, data, and user workflows—it becomes essential to adopt software engineering best practices, such as Separation of Concerns (SoC) and the Singleton design pattern. These principles help modularize components, optimize performance, and promote code reusability, ultimately leading to the development of robust web frameworks that abstract these practices into MVC (Model-View-Controller) and MVVM (Model-View-ViewModel) architectures. We aim to develop a systematic approach to guide existing LLMs specialized in code generation for specific domain areas, ensuring they adhere to IT industry conventions and technologies (e.g., web frameworks like React) to generate robust and scalable front-end web applications.
    
    \item[R5. Multi-tool Paradigm for Package Management:]  
    A multi-tool approach should be employed to manage software dependencies, leveraging dedicated package management and versioning tools specific to each programming language (e.g., Conda for Python environments and NPM or NVM (Node Version Manager) for server-side JavaScript and TypeScript). This ensures robust package selection, version control, dependency management, and seamless integration of external libraries.
    
    \item[R6. Ease of Deployment and Execution:]  
    The generated applications should be easy to deploy and execute, minimizing the technical complexity required for setting up and running the resulting web-based GIS software. 
\end{description}
Based on these design requirements, we developed a comprehensive framework within a Python environment enabled through Jupyter Notebook. This framework enables the deployment of a code generation pipeline that produces a front-end codebase in a local file-based system. The choice of a Python Jupyter environment is justified by Python’s widespread use in GIS-related tasks, with many major spatial analysis libraries built in Python. More importantly, Python seamlessly integrates with APIs and platforms for both commercial and open-source LLMs, such as OpenAI's ChatGPT API and Ollama, a framework for running local LLMs.

\subsection{Framework Design}
\label{subsec:frameworkDesign}
The overall framework design is illustrated in Figure \ref{fig:arch}, where we define 12 tasks (T1–T12) categorized into three major steps that form the core of the code generation workflow. These steps include: (1) Visual Contextual Prompting, (2) Knowledge Base and Code Base, and (3) Knowledge-Augmented Code Generation. The framework takes as input one or more user-defined wireframes that specify the layout and features of the GUI across different pages. As output, it generates the complete code base for a React project.

\begin{figure*}[htbp]
 \centering
\includegraphics[width=\textwidth]{Figures/Figure_Overall_Framework.pdf}
\caption{Overall framework architecture for LLM-driven code generation using knowledge-augmented prompting and structured domain knowledge.}
 \label{fig:arch}
\end{figure*}

\subsubsection{Visual Contextual Prompting}
\label{subsec:simulations1}
We introduce a novel visual contextual prompting technique, implemented using Python scripts, to translate GUI wireframes into structured prompts for guiding LLMs in generating high-quality JavaScript and TypeScript code. Unlike conventional text-based prompting, our approach enables non-technical users, such as domain scientists, to design web applications visually using PowerPoint and Adobe Illustrator.

Existing graphical prompting methods often rely on computer vision (CV)-based techniques to interpret bitmap images (e.g., PNG, JPEG). In contrast, our method processes SVG-based wireframes, which offer greater editability and flexibility during prototyping. This structured approach allows users to define UI components without programming expertise.

This step consists of two tasks, T1 and T2, aligned with the design requirements R1 and R2 in Subsection \ref{subsec:DesignRequire}.

\begin{description}
\item[T1. Vectorization \& Content Interpretation]
A Python program processes wireframe files exported from PowerPoint or Adobe Illustrator in EPS/SVG formats, extracting spatial and contextual information to construct HTML layouts and components. Each GUI element—such as dropdown menus, charts, and web maps—is represented as a vector graphical entity with embedded annotations specifying its function (e.g., data visualization, mapping interface, UI control). These annotations also capture interactions and dependencies, guiding LLMs in event binding for dynamic UI behaviors.

\item[T2. Visual Contextual Info Calculation]
Another Python script calculates visual contextual information for each SVG element, mapping it to an HTML component. This includes position, size, and style, which are then combined with wireframe annotations to generate engineered prompts. These prompts define not only individual components but also layout structures, interdependencies, and event handling logic, ensuring that LLM-generated code aligns with industry standards and preserves the user’s design intent.
\end{description}
By integrating visual design with structured knowledge-based prompting, our technique lowers the barrier for non-programmers, enabling them to develop web-based GIS and data visualization applications without direct coding expertise.

\subsubsection{Knowledge Base and Code Base}
\label{subsec:KB_CB}
The input information, including graphical components, visual context, and annotations from user, defined wireframes—captures GUI design and software requirements in plain, non-technical language. This enables users without coding expertise to define application requirements effortlessly. However, a combined knowledge base and code base is essential to interpret these context-aware visual prompts, transforming them into structured software development strategies. These strategies generate enriched prompts with sample code, guiding LLMs for code generation within a RAG framework.

Our knowledge base is built using knowledge graphs that encapsulate software development experiences, system requirements, and architectural designs from previous projects on digital twins, cyber infrastructure, and web-based visual analytics dashboards, as shown in Table \ref{tab:KG_previousProjects}. These knowledge graphs document and classify software stacks, componentization methods, and system designs based on domain-specific use cases and data types, ensuring structured and informed LLM-assisted code generation.

\input{Table/table1.tex}

An example of the knowledge graph structure is depicted in Figure \ref{fig:KG_method}. The sample code stored within these graphs is either excerpted and refined from previous projects or augmented using the ChatGPT API under expert review and supervision.

The process of knowledge-driven prompting follows a procedural approach, structured through tasks T3 to T8, ensuring a systematic and context-driven software development workflow. These tasks are detailed in the following list, with their rationale depicted in Figure \ref{fig:KG_method}.  

\begin{figure*}[htbp]
 \centering
\includegraphics[width=\textwidth]{Figures/Figure_knowledge_base.pdf}
\caption{Structured knowledge representations for converting plain-language annotations from UI wireframes into structured prompts with technical terminology.}
 \label{fig:KG_method}
\end{figure*}

\begin{description}
\item[T3. Framework \& Library Selection]
This task defines criteria for selecting web frameworks and libraries based on wireframe annotations. A vector index search on a knowledge graph (covering software engineering and CyberGIS domains) maps UI elements (e.g., date selector, GIS map) to React components (e.g., calendar dropdown, web map engine). The knowledge graph stores metadata on HTML elements, events, and best practices, ensuring context-aware, industry-aligned component selection.

\item[T4. HTML/TypeScript Component Tree Generation]
Using extracted GUI components and annotations, this task constructs a structured HTML/TypeScript component tree, preserving semantic correctness, hierarchical relationships, and CSS styles. The wireframe context guides nested structures and component interactions to ensure logical front-end design.

\item[T5. Front-End Library Selection]
Based on T3's criteria, this task selects appropriate front-end software stacks, including CSS frameworks, UI libraries, mapping tools, and data visualization frameworks. It determines whether to use standard HTML elements or third-party solutions (e.g., Material-UI, Tailwind CSS, D3.js, Leaflet) by performing a vector index search on a Neo4j-backed knowledge graph \citep{xu2024automating}, ensuring optimal usability, performance, and maintainability.

\item[T6. OS Commands for Package Management]
After selecting libraries in T5, a Python script retrieves the corresponding OS commands for installing, updating, and managing dependencies using appropriate package management tools. JavaScript/TypeScript dependencies use NPM/NVM, Python libraries use Pip/Conda, and system-level packages use APT (Debian) or Yum (RHEL). The script consolidates commands into .sh or .bash scripts, enabling one-click execution for package management across Windows and Linux DevOps environments, handling installation, version control, and conflict resolution.

\item[T7. Software Design \& Architecture Patterns]
This task ensures adherence to scalable and modular software design principles by integrating Separation of Concerns (SoC), MVC, and MVVM patterns. It leverages industry-standard frameworks (React, Angular) and structured prompt templates to guide LLMs in generating componentized code with proper event binding and state management.

\item[T8. Software Development Prompt Generation]
Expanding on T6, this task refines structured prompts for LLM-driven code generation, incorporating component-based development, lazy loading, and dynamic rendering. Sample code from the knowledge base is embedded into prompts, providing step-by-step procedural instructions to ensure AI-generated code adheres to modular design principles for reusability, maintainability, and readability.
\end{description}

Our knowledge base and code repository serve as domain experts in software engineering and GIS, facilitating the translation of plain-language annotations from wireframes into structured software development strategies. By leveraging technical terminology and software engineering best practices, we provide system-based instructions with sample code, enabling AI agents to generate robust and well-structured code in the next step.
 

\subsubsection{Knowledge Augmented Code Generation}
\label{subsec:simulations3}
The structured prompts generated from T8 are then fed into the LLM agent to enable knowledge-augmented code generation. Given the token limit constraints of LLMs, we adopt a procedure-based, iterative approach that combines rule-based Python scripting with the customized generation capabilities of LLMs. This method ensures efficient front-end code generation using the React framework, which follows the Model-View-ViewModel (MVVM) architecture, along with established software engineering conventions and React’s standard file structure. Our KAG approach entails the following tasks from T9 to T11, which are illustrated in Figure \ref{fig:kag}. 

\begin{description}
    \item[T9. Install \& Update Packages using Operating System (OS) Scripts]  
    This task automates the installation and updating of required dependencies using OS-level scripts. It ensures that all necessary packages, including Node.js, npm, and front-end libraries (e.g., React, Material-UI, Leaflet), are properly installed and version-controlled. The scripts also handle package updates to maintain compatibility with evolving software frameworks and dependencies.

    \item[T10. Iteration-based Code Generation using LLMs]  
    Given the token limitations of LLMs, this task adopts a procedure-based, iterative approach for code generation. Rule-based Python scripts and structured prompts guide the LLMs to generate React components in a stepwise manner, ensuring compliance with best practices in componentization, event handling, and state management. The iterative process allows refinement and optimization of the generated code, minimizing redundancy and improving maintainability.

    \item[T11. Separation of Concerns (SoC) using React Convention]  
    This task enforces Separation of Concerns (SoC) by structuring the generated code according to React’s MVVM architecture. The React components, logic, styles, and API handlers are modularized into separate files, ensuring that UI elements, business logic, and data handling remain distinct. This improves scalability, maintainability, and code readability while aligning with industry standards.

    \item[T12. Script Connection \& Organization in React File Structure]  
    This task organizes and connects the generated scripts following the **React file structure convention**. The components are structured within a modular directory system (e.g., `components/`, `hooks/`, `services/`, `contexts/`). The script integration ensures that React Router, Redux (if applicable), and event-driven logic** are properly linked, allowing seamless front-end development with maintainable and reusable components.
\end{description}

\begin{figure*}[htbp]
 \centering
\includegraphics[width=\textwidth]{Figures/Figure_KAG_genreation.pdf}
 \caption{A procedure-based, knowledge-augmented code generation process that aligns with the conventions and best practices of the React framework. }
 \label{fig:kag}
\end{figure*}


After generating a complete React project through knowledge-augmented LLMs, two additional steps are required before the DevOps stage to ensure functionality, maintainability, and deployment readiness:

\begin{description}
\item[Expert Code Review: Human-AI Collaboration for Code Refinement]
A Human-AI collaboration process refines and validates the AI-generated React code. Human experts review, debug, and revise the code to ensure correctness, performance, and adherence to industry standards. Since our method follows React’s MVVM architecture and Separation of Concerns (SoC) principles, the AI-generated code is well-structured, readable, and maintainable, making it easier for developers to understand, modify, and integrate into production.

\item[Build React Project: Executing OS Scripts and Dependency Installation]
Once validated, the React project must be built and configured for execution. Users install dependencies by running the OS scripts generated in T9 via the command line in Windows or Linux. This ensures that React, Material-UI, Leaflet, and other libraries are correctly installed and up to date. After setup, the project is built using NPM or NPX commands, ensuring a fully functional front-end dashboard.
\end{description}
 
For deployment, the AI-generated React project can be hosted on a server (monolithic architecture) or deployed in a Docker container (microservice architecture). This ensures scalability, portability, and interoperability with databases and server-side APIs. By adopting this approach, AI-generated front-end components seamlessly integrate into enterprise systems, enhancing efficiency, maintainability, and modularity.

 



 