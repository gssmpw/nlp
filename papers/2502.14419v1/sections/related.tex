\section{Related work}

% \subsection{Cloud-native volume management}

% Several systems provide functionality similar to Longhorn, aiming to supply cloud-native environments with on-demand storage.
Kubernetes provides an abstract API for specifying the storage requirements of services, through the use of \textit{PersistentVolumeClaim} objects. Such storage claims are monitored and served by storage plugins that implement the actual \textit{PersistentVolumes} which are then attached to running containers (in the Kubernetes nomenclature, the unit of execution is the \textit{Pod}, which may consist of one or more containers running in the same network namespace at the OS level). The details of the volume orchestration process in Kubernetes are defined in the Container Storage Interface (CSI) \cite{csi}. Actually, Kubernetes does not ship with a default CSI plugin as part of its installation, thus it is necessary for the administrator to add a compatible storage component for a fully working system.

Longhorn is one of several such CSI-compliant solutions, which has become favorable for its ease of deployment and use. Other popular CSI plugins include Rook \cite{rook}, which integrates with an SDS layer powered by Ceph \cite{ceph}, OpenEBS \cite{openebs}, which exposes the functionality of internal ``storage drivers'' that, in turn, implement distributed replicated storage, or can provision node-local storage from existing filesystem subdirectories, full or partitioned devices, or logical volumes via LVM or ZFS. All above systems are CNCF projects; the CNCF ecosystem also includes Piraeus \cite{piraeus}, a CSI-compliant interface to DRBD and Carina \cite{carina} that manages local RAID device groups. Beyond the CNCF, there are also numerous SDS commercial offerings compatible with Kubernetes, for which unfortunately limited technical background is publicly available, so they are outside the scope of this paper.

% \subsection{Userspace block interfaces}

From a technical perspective, cloud-native volume managers can be categorized to broad groups, depending on
\begin{enumerate*}[label=(\roman*)]
    \item whether they implement their own SDS stack, or they provide an interface to an existing volume management software, and 
    \item whether they distribute data across nodes (usually managing redundancies, so to handle outages), or they confine their volumes on a single node.
\end{enumerate*}
Longhorn and OpenEBS fall in the first group of both criteria. 
% OpenEBS may use the cStor, Jiva, and Mayastor storage drivers for distributed storage provisioning.
An important part of these systems is how the SDS stack is exported to the OS. Longhorn, OpenEBS/cStor, and OpenEBS/Jiva incorporate a compatible iSCSI target at the top of the stack, and, in fact, share many similarities at the architectural level (iSCSI frontend, a controller acting as an I/O router, and distributed storage endpoints at different ndoes). iSCSI had been a common option to provide a virtual block device several years ago, however, newer technologies like NVMe-oF and ublk offer superior performance and efficiency, due to less overheads and kernel-bypass capabilities.

NVMe-oF is commonly used via SPDK (Storage Performance Development Kit) \cite{spdk} that provides userspace NVMe libraries and tools for efficient, low-latency storage operations. SPDK also includes bdev (block device), which uses a plugin architecture for implementing custom block drivers. On the other hand, ublk is a framework specifically made for creating block devices in userspace, which leverages the technology of io\_uring, a high-performance Linux kernel system call interface that uses ring buffers shared between the kernel and user space to submit and complete I/O requests efficiently, making it ideal for applications requiring scalable and fast I/O. Ublk and io\_uring, are offered in the latest Linux kernel (6.x) and included by default as part of most major Linux distributions (\textit{i.e.}, available in Ubuntu 24.10).

The NVME-oF solution has already been selected for the ``v2'' release of the Longhorn engine (currently in ``experimental'' status). OpenEBS follows a similar approach with the Mayastor driver \cite{mayastor} (currently under development). In both cases, NVME-oF---actually SPDK---requires a complete refactoring of the SDS code. In this work, we consider a solution based on ublk that is simpler and easier to integrate with an existing SDS. While ublk does not offer the same feature set (\textit{i.e.}, separating the block device point and the controller on different nodes and use RDMA for communication), experimental results suggest that the performance of the exported block device easily surpasses NVME-oF in the same setup \cite{longhorn_performance}.
