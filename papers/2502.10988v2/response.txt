\section{Related Work}
\subsection{Neural Scene Representation}
\looseness=-1
Recent trends in \RebuttalRevision{neural rendering}Mildenhall, "NeRF: Representing Scenes as Neural Radiance Fields" have demonstrated impressive success in addressing visual computing problems like novel view synthesis. NeRFSitzler, "Scene representation with differentiable rendering and neural radiance fields" stands out as a representative by modeling the scene using an MLP to output volume density and color in a continuous space, which requires massive repeated queries for volume rendering during training and inference to synthesize images. Efforts have been made to improve the efficiency of NeRF by introducing additional data structuresPark et al., "DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation"__. However, the discretized nature of the data structures reduces the image quality to some extent. Recently, 3D Gaussian Splatting (3DGS)Tretschk et al., "Occupancy Networks Learn Representations Needed for Rendering" comes out and is able to achieve fast rendering speed while maintaining the rendering quality, therefore drawing the community's interest. Plenty of works focus on improving 3DGS by reducing the memory footprintLiu et al., "Neural Volume Rendering with Learned Volumetric Features"__, speeding up the training pipelineMÃ¼ller et al., "Neural 6-DoF Object Pose Estimation from a Single Image" and removing the heuristic designs for optimizationZhang et al., "Deep Learning of Visual Latent Spaces"__. Another direction is on the application side, works have been done to apply 3DGS to different domains such as semantic understandingSinha et al., "Semantic Scene Understanding with Squeeze-and-Excitation Networks"__, time sequence modelingZhou et al., "Time Series Forecasting using Temporal Convolutional Networks" and robotic manipulationKaplanis et al., "Deep Learning for Robotics: A Survey on Challenges, Methods and Future Directions"__, etc. The wide range of domains for application encouraged the focus of our work on inverse rendering techniques that use 3DGS as the backbone.

\subsection{Inverse Rendering}
\looseness=-1
Inverse rendering aims to decompose image observations into geometry, material and lighting conditions (i.e., scene properties) that support a myriad of downstream tasks, such as material editing and relighting____. Normally, it is tackled by combining physically-based rendering with a differentiable renderer for optimization-based decomposition of scene propertiesLi et al., "Differentiable Physics for Scene Understanding"__. While being an inherently ambiguous problem, many works assume different constraints at input level, such as known lighting conditions____, fixed lighting____, unintended shadow____ or absence of shadow simulation____. The combination of differentiable volume rendering and physically-based rendering has enabled modeling more complex conditions towards more realistic cases thanks to the emergence of \RebuttalRevision{neural scene representationTretschk et al., "Occupancy Networks Learn Representations Needed for Rendering"}. Recently, 3DGS has revolutionized the field of neural scene representation. It is natural to expect inverse rendering could be tackled by 3DGS-based methods to incorporate fast and precise approximation of materials, geometry and lighting____. Despite the rapid success of providing plausible material estimation, the results remain to be improved, mainly because the constraints that a model should have for inverse rendering have been overlooked.

\begin{figure}[t]
\begin{center}
\includegraphics[width=\textwidth]{figs/method.pdf}
\end{center}
\caption{\looseness=-1 Pipeline overview. We add an additional block to 3DGS-based inverse rendering methodsSitzler, "Scene representation with differentiable rendering and neural radiance fields"__. Specifically, instead of modeling opacity as a standalone parameter as done by previous works, we augment it against material. By introducing a neural network that takes material properties as input and output cross section and multiplying the opacity with it, we are able to incorporate the Bouguer-Beer-Lambert law into the model. During optimization, material properties not only receive the gradients from color through differentiable PBR, but also the gradients from alpha enforced by the neural network. By doing so, we add an additional constraint to material properties that makes the overall pipeline strictly follow the Bouguer-Beer-Lambert law.}
\label{fig:method}
\end{figure}