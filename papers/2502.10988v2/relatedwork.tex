\section{Related Work}
\subsection{Neural Scene Representation}
\looseness=-1
Recent trends in \RebuttalRevision{neural rendering}~\citep{mildenhall2021nerf, yu2021plenoctrees, fridovich2022plenoxels, sitzmann2021light, yariv2021volume, miller2024objects, huang20242d, yong2024gl} have demonstrated impressive success in addressing visual computing problems like novel view synthesis. NeRF~\citep{mildenhall2021nerf} stands out as a representative by modeling the scene using an MLP to output volume density and color in a continuous space, which requires massive repeated queries for volume rendering during training and inference to synthesize images. Efforts have been made to improve the efficiency of NeRF by introducing additional data structures~\citep{garbin2021fastnerf, muller2022instant, hedman2021baking, yu2021plenoctrees, fridovich2022plenoxels, chen2022tensorf}. However, the discretized nature of the data structures reduces the image quality to some extent. Recently, 3D Gaussian Splatting (3DGS)~\citep{kerbl20233d} comes out and is able to achieve fast rendering speed while maintaining the rendering quality, therefore drawing the community's interest. Plenty of works focus on improving 3DGS by reducing the memory footprint~\citep{fan2023lightgaussian, navaneet2023compact3d, niedermayr2024compressed}, speeding up the training pipeline~\citep{mallick2024taming, hollein20243dgs} and removing the heuristic designs for optimization~\citep{kheradmand20243d, bulo2024revising}. Another direction is on the application side, works have been done to apply 3DGS to different domains such as semantic understanding~\citep{qin2024langsplat, guo2024semantic}, time sequence modeling~\citep{luiten2024dynamic, lin2024gaussian} and robotic manipulation~\citep{lu2024manigaussian, shorinwa2024splat}, etc. The wide range of domains for application encouraged the focus of our work on inverse rendering techniques that use 3DGS as the backbone.

\subsection{Inverse Rendering}
\looseness=-1
Inverse rendering aims to decompose image observations into geometry, material and lighting conditions (i.e., scene properties) that support a myriad of downstream tasks, such as material editing and relighting~\citep{li2023multi, zhang2022modeling, kanamori2019relighting, yang2022ps}. Normally, it is tackled by combining physically-based rendering with a differentiable renderer for optimization-based decomposition of scene properties~\citep{kajiya1986rendering, chen2019learning}. While being an inherently ambiguous problem, many works assume different constraints at input level, such as known lighting conditions~\citep{bi2020neural, srinivasan2021nerv, zhang2022modeling}, fixed lighting~\citep{dong2014appearance}, unintended shadow~\citep{verbin2024eclipse} or absence of shadow simulation~\citep{zhang2021physg}. The combination of differentiable volume rendering and physically-based rendering has enabled modeling more complex conditions towards more realistic cases thanks to the emergence of \RebuttalRevision{neural scene representation~\citep{zhang2021nerfactor, yao2022neilf, liu2023nero, verbin2022ref, jin2023tensoir, attal2024flash, boss2021nerd, munkberg2022extracting}}. Recently, 3DGS has revolutionized the field of neural scene representation. It is natural to expect inverse rendering could be tackled by 3DGS-based methods to incorporate fast and precise approximation of materials, geometry and lighting~\citep{liang2024gs, jiang2024gaussianshader, gao2023relightable}. Despite the rapid success of providing plausible material estimation, the results remain to be improved, mainly because the constraints that a model should have for inverse rendering have been overlooked.

\begin{figure}[t]
\begin{center}
\includegraphics[width=\textwidth]{figs/method.pdf}
\end{center}
\caption{\looseness=-1 Pipeline overview. We add an additional block to 3DGS-based inverse rendering methods~\citep{liang2024gs, kerbl20233d, jiang2024gaussianshader, gao2023relightable}. Specifically, instead of modeling opacity as a standalone parameter as done by previous works, we augment it against material. By introducing a neural network that takes material properties as input and output cross section and multiplying the opacity with it, we are able to incorporate the Bouguer-Beer-Lambert law into the model. During optimization, material properties not only receive the gradients from color through differentiable PBR, but also the gradients from alpha enforced by the neural network. By doing so, we add an additional constraint to material properties that makes the overall pipeline strictly follow the Bouguer-Beer-Lambert law.}
\label{fig:method}
\end{figure}