\section{Related works}
\label{section:related works}

\textbf{Offline 3D bin packing problem. }It is a well-known combinatorial optimization problem in which the objective is to efficiently pack a set of three-dimensional items into one or more bins (or containers) of fixed dimensions, maximizing space utilization. In the offline version, all the items and their dimensions are known in advance before packing begins, which has been particularly challenging due to its NP-hard nature. For smaller instances, methods such as integer linear programming (ILP) or branch-and-bound can be applied to find optimal solutions. To deal with a larger number of boxes, early research focuses on heuristic and meta-heuristic methods \cite{faroe2003guided} \cite{crainic2009ts2pack} \cite{kang2012hybrid}. More recently, deep reinforcement learning has been applied to tackle this task \cite{hu2020tap} \cite{zhang2021attend2pack}.

\textbf{Online 3D bin packing problem. }This is a variation of the 3D BPP where items arrive sequentially over time, requiring placement decisions to be made without knowledge of future items. Unlike the offline version, where all items are known beforehand, this uncertainty necessitates a balance between immediate efficiency and maintaining flexibility for future items, and algorithms must be adaptable to varying patterns and sizes of incoming items. To address this problem, researchers also begin with adaptive heuristics algorithms in the early stage. Initially, solutions are based on deep-bottom-left (DBL) heuristics\cite{karabulut2004hybrid} \cite{ha2017online}, later evolving to the Heightmap-Minimization technique \cite{wang2019stable}. Nowadays, deep reinforcement learning (DRL) has become popular for addressing this problem, though it is challenged by large action space. Zhao et al. \cite{zhao2021online} address this challenge by implementing straightforward heuristics to reduce the action space, in another work they \cite{zhao2022learning} seek to alleviate this issue by devising a packing configuration tree that employs more intricate heuristics to identify a subset of feasible actions. Wu et al. \cite{wu2024efficient} first attempt to use neural networks as an action space mask, but it also relies on heuristic methods for data collection. 

In this work, we study a variant of the online 3D bin packing problem (BPP). We take the intrinsic properties of the boxes into account, such as density and rigidity. With this consideration, even if a box is fully supported, it will collapse if the box beneath it lacks the rigidity to bear the weight of the box above. As a result, there are fewer stable placement positions for the boxes in our problem compared to the standard online 3D BPP.

\textbf{Action masking model.}
One of the major challenges in using RL to solve the online 3D BPP is the large action space. To address this, action space masking is typically employed to reduce the size of the action space. Previous work \cite{zhao2021online} used heuristic methods as action masking models, often manually adding constraints related to the box's support area and the number of supporting edges, only considering placements that satisfy these constraints as stable. \cite{wu2024efficient} trains a neural network as an action masking model through supervised learning. However, to solve the out-of-distribution problem common in supervised learning, the method in \cite{wu2024efficient} required multiple rounds of training, followed by offline training of the neural network. The first round of RL training still depended on heuristic methods. Therefore, this neural network approach is an improvement over heuristic methods, but it does not eliminate the reliance on them.