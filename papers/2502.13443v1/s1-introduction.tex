\section{INTRODUCTION}
\label{section:introduction}

In modern warehouse and logistics management, stacking boxes continues to be a common challenge. In the past, due to the smaller scale of trade and lower efficiency requirements, workers could rely on their experience to decide how each box should be placed. However, with the globalization of trade, there is a growing need for fast and stable box stacking, and a good solution for this is robotic palletization~\cite{lamon2020towards} \cite{szczepanski2022optimal}.

The task planning for robotic palletization in most industrial environments can be conceptually framed as a variant of the online 3D Bin Packing Problems (BPP), where the inventory of items is predetermined, yet their sequence of arrival remains unpredictable \cite{wang2020robot}. 
Existing works often focus only on boxes' size variations \cite{zhao2021online} \cite{zhao2021learning}, while they overlook the intrinsic differences between boxes. However, in real logistics scenarios, the overall density and rigidity of boxes can vary significantly. Placing a heavy box on top of a soft and lightweight box can pose substantial risks. Therefore, we considered the density and rigidity of the boxes to better align with the demands of real-world logistics scenarios.
Beyond that, we follow \cite{wu2024efficient} and consider a buffer size, which allows the robot to utilize an auxiliary space for storing up to $N$ pending items, thereby expanding its operational capabilities beyond merely handling the immediate one.

In early studies addressing online 3D bin packing problems, hand-coded heuristic methods were primarily used \cite{ha2017online} \cite{wang2019stable}. With the increasing amount of research related to reinforcement learning (RL) \cite{kaelbling1996reinforcement}, more and more studies are exploring how to use RL to solve this problem \cite{zhao2021online} \cite{zhao2021learning}  \cite{wu2024efficient}.

Due to the combinatorial nature of the action space of the problem, applying RL to solve online 3D BPP suffers from the problem of large action space, which will complicate the RL training process \cite{dulac2015deep}. One commonly used solution to the problem of RL with large action space is through ``invalid action masking'' \cite{vinyals2017starcraft} \cite{ye2020mastering}, which identifies and masks out the invalid actions and directs the policy to exclusively sample valid actions during the learning phase.

Our work also adopts action space masking, pinpointing valid actions as task plans that guarantee the stability of intermediate item stacks on the pallet under gravitational forces throughout the training process.
However, the space masking methods in previous studies are not applicable in the setting of this paper.
The heuristic-based methods \cite{zhao2022learning} \cite{faroe2003guided} used in previous work to assess stability become ineffective, as they did not take into account the rigidity and density of the boxes.
Although Wu et al. \cite{wu2024efficient} has employed neural networks to evaluate stability, they still require an initial round of data collection using heuristic methods before training the neural network to serve as action masking model.

To address the reliance on heuristic methods, we propose a new framework that uses online learning to train an action space mask, which entirely eliminates the need for manually designing a heuristic method. Specifically, leveraging the image-like characteristics of observation and action mask data, we employ a semantic segmentation paradigm \cite{chen2014semantic}, \cite{long2015fully} to train the action masking model. The training dataset is compiled through an online data collection phase, utilizing a physics engine to verify the stability of specific placements across various pallet configurations. Moreover, we design the method for collecting and managing online data, allowing the action masking model to efficiently learn the underlying physical principles of box stacking within the RL training loop.

To evaluate the effectiveness of our proposed methodology, we performed a series of comprehensive experiments and compared our results with current RL-based online 3D bin packing solutions. The experimental outcomes reveal that our method significantly surpasses existing baselines. Additionally, we deployed our learned task planner in a real-world robotic palletizer, showcasing the practical applicability of our approach in actual operational environments.