\subsection{Training Phase}
\label{sec. tic training}

\subsubsection{Team Model}
\label{sec. teamwork model}
To effectively monitor the team, \coach builds upon a mathematical model of the task and team behavior. Having described the task model in \cref{sec. task model}, we now formalize the model of team behavior. Human decision-making often depends on factors beyond the task state, such as cognitive states corresponding to beliefs and intents~\cite{hiatt2017human, neubauer2020multimodal}. Hence, \coach explicitly models the influence of team members' intent -- a latent variable -- on their behavior. More specifically, following the Agent Markov Model (AMM)~\cite{unhelkar2019learning}, $j$-th team member's behavior is defined by the tuple $\mathcal{H}_j = (X, \pi_j, \zeta_j; \mathcal{M})$, where $X$ represents the set of possible task-specific intents, $\pi_j(a|x, s)$ denotes the team member's policy, and $\zeta_j(x'|s', a, x)$ represents the intent transition model.\footnote{%
Although team members' behavior may also depend on other latent factors, such as cognitive states and beliefs about unobserved parts of the environment, the decision to model only intent simplifies the system design. Our experiments confirm that this modeling choice is valid for the domains considered. However, we believe that performance of future AI-enabled coaching systems could be further enhanced by incorporating additional decision factors and more sophisticated behavioral models.}
While this model is well-defined, it is not trivial for domain experts to specify. Therefore, \coach leverages imitation learning to learn the model parameters from demonstrations collected during training sessions.

\subsubsection{Model Learning}
In particular, \coach uses \btil to learn the unknown parameters of the team behavioral model: $\pi(a|s, x)$ and $\zeta(x'|s', x, a)$.
\btil is a multi-agent imitation learning algorithm that explicitly models latent decision factors, such as intents~\cite{seo2022semi}.
By leveraging a Bayesian approach, \btil has been shown to attain sample- and label- efficient model learning from team demonstrations.
Additionally, \btil can learn from both optimal and sub-optimal demonstrations.
This is especially important for \coach, as it learns the team model from demonstrations collected during practice sessions, where team behavior may not always be optimal.
In practice, \coach's model learning begins with the collection of data on observable features of team demonstration, specifically $(s,a)$-trajectories.
With the assistance of a human annotator, a subset of these trajectories is annotated with the values of team intent $(x)$.
Using this combination of trajectory data and intent annotations, \coach utilizes the semi-supervised variant of \btil to learn the team behavioral model $\mathcal{H}_j \forall j = 1:n$.

\subsubsection{Team Monitoring}
Equally critical to team modeling are the mechanisms for monitoring the team and collecting teamwork data: specifically, $(s,a)$-trajectories and annotations of $(x)$ for a subset of the training data. In this proof-of-concept, we focus on collaborative tasks conducted through a web-based interface and develop methods for data collection and annotation specific to this setting, illustrated in \cref{fig. ui} and detailed in \cref{sec: data collection}. For real-world applications, we recommend using multimodal sensors to monitor and gather teamwork data. We leave the exploration of related perception challenges for future work, with relevant research directions discussed in \cref{sec: conclusion}. \coach uses the same monitoring mechanisms during the task execution phase, which we describe next.
