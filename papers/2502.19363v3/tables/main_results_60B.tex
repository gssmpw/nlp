\begin{table*}[h]
\centering
\caption{The Sample-with-\ourmethod{} model (\emph{Overall Score l=5}) improve perplexity and in-context learning (ICL) results on \textbf{larger 60B tokens}. We report the validation, test perplexity, and ICL performance of 10 downstream tasks. We highlight the best result in each column and improvement over uniform sampling with the 60B token budget.}
\label{tab:main_results_60B}
\setlength{\tabcolsep}{4pt}
\resizebox{1.\textwidth}{!}{
\begin{tabular}{lllccccc}
\toprule
\multicolumn{2}{l}{\textbf{Selection Method}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Val} \\ \textbf{Perplexity} \\\end{tabular}}&\multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Test} \\ \textbf{Perplexity} \\\end{tabular}}& \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Reading} \\ \textbf{Comprehension} \\ \textit{(5 tasks)}\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Commonsense} \\ \textbf{Reasoning} \\ \textit{(3 tasks)}\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{World} \\ \textbf{Knowledge} \\ \textit{(2 tasks)}\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\\\textbf{Average} \\ \textit{(10 tasks)}\end{tabular}} \\
\midrule
Uniform &  & 10.81 & 10.79 & 53.7 & 58.4 & 16.4 & 47.6 \\
Educational Value & $\tau=2.0$ & \textbf{9.81 \gda{1.00}} & \textbf{9.85 \gda{0.94}} & 54.2 \gua{0.5} & 58.7 \gua{0.3} & 16.0 \rda{0.4} & 47.9 \gua{0.3} \\
Overall Score & \textit{l=5} & 9.93 \gda{0.88} & 9.91 \gda{0.88} & \textbf{56.5 \gua{2.8}} & \textbf{62.9 \gua{4.5}} & \textbf{17.5 \gua{1.1}} & \textbf{50.6 \gua{3.0}} \\
\bottomrule
\end{tabular}
}
\end{table*}
