\section{Limitations} 
We acknowledge several limitations in our work. First, DataMan's reliance on LLMs for text quality assessment and domain categorization may inherit biases from these models. Second, DataMan's inference accuracy is not yet optimal, sometimes causing misclassification, highlighting the need for a large-scale collection of documents with diverse quality differences for fine-tuning. Third, using SlimPajama alone as a pre-training corpus limits result reliability, incorporating additional corpora would be better. Fourth, the model size is restricted by data and training resources, resulting in models with only 1.3B parameters, whereas increasing parameters might reveal interesting phenomena. Lastly, the considerable costs of developing data managers, data filtering, and pre-training experiments could hinder further research in this domain. 
We aim to address these in future work. Despite these limitations, DataMan remains a powerful tool for data selection and mixing.
