\section{Experimental Results}
\begin{table*}[!t]
\centering
\caption{Results on AnyText-benchmark. ``AnyText-v1.1 Font Aware" refers to AnyText~\cite{tuo2023anytext}, but uses the same font-aware glyph controls from our work without fine-tuning as an ablation, which shows significant performance drop in text accuracy. Although with little decrease in non-Latin text accuracy, ControlText outperforms AnyText by a large margin in preserving diverse and detailed font information in input glyph controls.}
\label{tab:results}
\small % Adjust font size if needed
\resizebox{\textwidth}{!}{ % Resizes the table to fit the page width
\begin{tabular}{l|cc|c|cccc|cccc}
\hline
\multicolumn{12}{c}{\textbf{English}} \\
\hline
\multirow{2}{*}{Methods} 
& \multicolumn{2}{c|}{\textbf{Text Accuracy} $\uparrow$} 
& \textbf{Image Quality $\downarrow$} 
& \multicolumn{8}{c}{\textbf{Fuzzy Font Accuracy (in Distance)} $\downarrow$} \\
\cline{2-12}
& SenACC & NED & FID 
& $l_2@5$ & $l_2@20$ & $l_2@50$ & $l_2@\text{full}$
& $\cos@5$ & $\cos@20$ & $\cos@50$ & $\cos@\text{full}$ \\
\hline
AnyText-v1.1~\cite{tuo2023anytext}    & 0.8315 & 0.9081 & 26.18 & 0.3038 & 0.2581 & 0.2496 & 0.2466 & 0.1615 & 0.1599 & 0.1603 & 0.1614 \\
AnyText-v1.1 Font-Aware               & 0.5524 & 0.6839 & \textbf{24.95} & 0.3049 & 0.2589 & 0.2497 & 0.2458 & 0.1601 & 0.1583 & 0.1587 & 0.1597 \\
ControlText (ours)                    & \textbf{0.8345} & \textbf{0.9107} & 25.93 & \textbf{0.2449} & \textbf{0.1850} & \textbf{0.1750} & \textbf{0.1709} & \textbf{0.1305} & \textbf{0.1286} & \textbf{0.1291} & \textbf{0.1301} \\
\hline
\multicolumn{12}{c}{\textbf{Chinese}} \\
\hline
\multirow{2}{*}{Methods} 
& \multicolumn{2}{c|}{\textbf{Text Accuracy} $\uparrow$} 
& \textbf{Image Quality $\downarrow$} 
& \multicolumn{8}{c}{\textbf{Fuzzy Font Accuracy (in Distance)} $\downarrow$} \\
\cline{2-12}
& SenACC & NED & FID 
& $l_2@5$ & $l_2@20$ & $l_2@50$ & $l_2@\text{full}$ 
& $\cos@5$ & $\cos@20$ & $\cos@50$ & $\cos@\text{full}$ \\
\hline
AnyText-v1.1~\cite{tuo2023anytext}    & \textbf{0.8591} & \textbf{0.8284} & \textbf{27.08} & 0.3103 & 0.2724 & 0.2643 & 0.2608 & 0.1521 & 0.1513 & 0.1519 & 0.1530 \\
AnyText-v1.1 Font-Aware               & 0.5578 & 0.3396 & 27.11 & 0.3106 & 0.2799 & 0.2713 & 0.2690 & 0.1478 & 0.1472 & 0.1477 & 0.1488 \\
ControlText (ours)                    & 0.7867 & 0.7479 & 28.63 & \textbf{0.2602} & \textbf{0.1992} & \textbf{0.1891} & \textbf{0.1848} & \textbf{0.1274} & \textbf{0.1271} & \textbf{0.1275} & \textbf{0.1286} \\
\hline
\end{tabular}
}
\end{table*}

% \begin{table*}[!t]
% \centering
% \caption{Comparison of L2 distances for different datasets}
% \label{tab:l2_distances}
% \small % Adjust font size if needed
% \resizebox{\textwidth}{!}{ % Resizes the table to fit the page width
% \begin{tabular}{l|l|l|l|l}
% \hline
% \textbf{Datasets}                         & \textbf{l2 distance original} & \textbf{l2 distance top 5} & \textbf{l2 distance top 20} & \textbf{l2 distance top 50} \\ \hline
% laion gly ablation         & 0.159692               & 0.160053              & 0.158297               & 0.158657               \\ \hline
% laion gly anytext          & 0.161356               & 0.161525              & 0.159943               & 0.160335               \\ \hline
% laion gly controltext      & 0.130177               & 0.130522              & 0.128666               & 0.129169               \\ \hline
% wukong gly ablation        & 0.148768               & 0.147819              & 0.147259               & 0.147689               \\ \hline
% wukong gly anytext         & 0.153012               & 0.152082              & 0.151324               & 0.151885               \\ \hline
% wukong gly controltext     & 0.128656               & 0.127444              & 0.127091               & 0.127593               \\ \hline
% \end{tabular}
% }
% \end{table*}

% \begin{table*}[!t]
% \centering
% \small % Adjust font size if needed
% \resizebox{\textwidth}{!}{ % Resizes the table to fit the page width
% \begin{tabular}{l|cc|c|cc|cc|c|cc}
% \hline
% \multirow{3}{*}{Methods} 
% & \multicolumn{5}{c|}{\textbf{English}} 
% & \multicolumn{5}{c}{\textbf{Chinese}} \\
% \cline{2-11}
% & \multicolumn{2}{c|}{\textbf{Text Accuracy}} 
% & \textbf{Image Quality} 
% & \multicolumn{2}{c|}{\textbf{Font Accuracy}} 
% & \multicolumn{2}{c|}{\textbf{Text Accuracy}} 
% & \textbf{Image Quality} 
% & \multicolumn{2}{c}{\textbf{Font Accuracy}} \\
% & SenACC $\uparrow$ & NED $\uparrow$ & FID $\downarrow$ & $l_2@k$ $\downarrow$ & $\cos@k$ $\downarrow$
% & SenACC $\uparrow$ & NED $\uparrow$ & FID $\downarrow$ & $l_2@k$ $\downarrow$ & $\cos@k$ $\downarrow$ \\
% \hline
% AnyText-v1.1~\cite{tuo2023anytext}  &  &  &  &  &  & &  &  &  &  \\
% AnyText-v1.1 Font-Aware &  &  &  &  &  & &  &  &  &  \\
% ControlText (ours)  &  &        &       &  &  &        &        &       &  &  \\
% \hline
% \end{tabular}
% }
% \end{table*}




\subsection{Experimental Setups}
We finetune the ControlNet~\cite{zhang2023adding} model, with a size of around $1$B pretrained by AnyText~\cite{tuo2023anytext}, for 10 epochs using 4 NVIDIA V100 GPUs, each with 32 GB memory. 
% Due to limitations in our computational resources, each epoch in total requires around 380 GPU hours. 
We use a batch size of 6, a learning rate of $2 \times 10^{-5}$, and focus solely on inpainting masked images.
The dataset is curated from AnyWord-3M~\cite{tuo2023anytext} but with our font-aware glyph. Each RGB image of size $512$ by $512$ has at most $5$ lines of text. The dataset comprises approximately 1.39 million images in English, 1.6 million images in Chinese, and 10 thousand images in other languages. Following this, we continue training the model for another 2 epochs, turning on the textual perception loss introduced in~\cite{tuo2023anytext}. We use AnyText-benchmark~\cite{tuo2023anytext} with 1000 test images in English and Chinese to show quantitative results.  


\subsection{Visual Results}
Figures~\ref{fig:top} and~\ref{fig:main} showcase open-world images generated by our model. We always follow the text editing pipeline to either modify existing text or render new text. The original images $\boldsymbol{I}$ used in our experiment include both real~\cite{pixta_photo_93233725, unsplash, businessinsider_takeout, cnn_nyc_restaurants, peterpom211_x_post, tripadvisor_chicago_dark_side, nipic_image} and AI-generated~\cite{theatre_dopera_spatial, midjourney_prompts} examples. ControlText demonstrates high-fidelity text rendering, accurately preserving both the text and the font styles. It automatically render text in either flat formats or with depth and color effects based on the background, such as outward-engraved text on a shabby storefront sign on the street, a metallic board on wall, a chocolate bar, or with neon light effects at night. 

We present images in multiple languages: English, French (zero-shot), traditional and simplified Chinese (including \textit{the} most complex character \textit{``biang"}), Japanese (including Kaomoji), and Korean, rendered in either single or multi-line formats. Additionally, we incorporate various font styles, including novel designer fonts sourced from the web~\cite{apple_fonts, fonts_net_cn}.



\subsection{Quantitative Results}
Table~\ref{tab:results} presents the quantitative results evaluated on the AnyText benchmark~\cite{tuo2023anytext}, along with our proposed metrics $l_2@k$ and $\cos@k$ with $k = 5, 20, 50$, and the full logits, i.e., $c = 3474$ in the pretrained font classification model to assess font fidelity. Note that ControlText relies on a text segmentation model to generate glyph controls for the AnyText benchmark automatically. This may produce a small number of low-quality masks. However, we are not concerned about this, as human users can always type high-quality glyph controls during the actual use; therefore, those scores only serve as lower bounds. To ensure a fair comparison of all methods, we filter out text with low-quality masks based on the same criterion described in Section~\ref{sec:prepare_glyph} before calculating all metrics.

While ControlText shows some differences compared to AnyText in  SenACC and NED on Chinese characters, it successfully maintains large gaps across metrics on English data and fuzzy font accuracy. Meanwhile, when using identical font-aware glyph controls in ControlText, AnyText experiences a substantial decrease in text accuracy with almost no improvement in font accuracy, as shown in the row marked ``AnyText-v1.1 Font Aware" in Table~\ref{tab:results}. This demonstrates ControlTextâ€™s superior ability to handle diverse and nuanced font variations without requiring fine-tuning for each font. 
