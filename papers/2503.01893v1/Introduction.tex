\chapter{Introduction}
Inflation prediction is crucial for policymakers, businesses, and consumers as it influences decisions on interest rates, investment strategies, and wages. Accurate forecasts help central banks set appropriate monetary policies to maintain economic stability and control price levels. Businesses rely on inflation expectations to plan budgets, pricing strategies, and resource allocation, while consumers consider inflation trends when making purchasing and savings decisions.
However, inflation prediction is challenging due to the interplay of numerous dynamic factors that influence prices, such as monetary policy, supply chain disruptions, labor market conditions, and geopolitical events. Predicting inflation components, such as food, gas, and clothing, adds another layer of complexity, as these categories are affected by distinct factors like weather, global markets, and trade policies. Each component has unique drivers, making it difficult to aggregate these predictions into a comprehensive forecast.
Additionally, inflation expectations create feedback loops—when businesses and consumers anticipate rising prices, their actions, like increasing wages or raising prices, can directly contribute to higher inflation. These factors, combined with global and local economic interactions, make accurate inflation prediction a significant challenge.

The Consumer Price Index (CPI) is organized hierarchically, grouping goods and services into broad categories such as food, energy, and housing, which are further subdivided into detailed subcategories to capture their impact on overall inflation. This complex structure necessitates advanced modeling techniques.
There are several methods for training predictive models with hierarchical data. One approach is to train separate models for each series within the hierarchy, which can reduce the risk of under-fitting by focusing on specific data segments. However, this method often leads to overfitting due to the limited amount of data available for each individual model. An alternative  approach is to train a single model using all the hierarchical data combined, which can take advantage of larger datasets but tends to be computationally intensive and may struggle to capture the differing dynamics across various levels of the hierarchy.
Our approach, BiHRNN, achieves an effective middle ground by harnessing hierarchical relationships to enhance model performance, without the computational burden and inefficiency of training a single, unified model.

Bidirectional Hierarchical Recurrent Neural Networks (BiHRNN) are designed to model the hierarchical structure of datasets like the CPI, with each node in the network graph representing an RNN unit that captures the values of a specific (sub)-index. This architecture enables bidirectional information flow—allowing higher-level RNN nodes to influence lower-level ones and vice versa—through hierarchical informative priors applied to the RNNs' parameters. This bidirectional exchange enhances predictions across all levels of the hierarchy.

The BiHRNN represents a substantial advancement over its predecessor, the Hierarchical Recurrent Neural Network (HRNN), which allowed information to flow only in one direction—from parent categories to child categories. By enabling bidirectional communication, the BiHRNN enhances predictive accuracy and reliability. Evaluation results reveal that the BiHRNN consistently outperforms both the HRNN and traditional methods, providing more precise and dependable inflation predictions. Across various metrics, such as prediction accuracy, overall accuracy, correlations, and goodness of fit, the BiHRNN demonstrates notable improvements over the HRNN, underscoring its superior ability to capture and model the hierarchical dependencies within the data.

The central aim of this thesis is to present the BiHRNN model, specifically designed to utilize hierarchical data structures for enhanced prediction accuracy. 
We demonstrate the model's effectiveness using three distinct Consumer Price Index (CPI) datasets from Canada, Norway, and the US. In these cases, we forecast the CPI while accounting for multiple levels, ranging from broad economic indicators to specific categories, providing a comprehensive evaluation of the model's performance across different hierarchical structures.

The thesis is structured as follows:
Related work of existing methodologies in hierarchical data modeling and forecasting (pages 5-8), along with an overview of Recurrent Neural Networks (RNN) (page 9) and the previous Hierarchical Recurrent Neural Network (HRNN) model (pages 10-12).
A detailed explanation of the BiHRNN model, including its formulation and inference mechanisms (pages 12-16).
A description of the datasets used (pages 17-25), the baseline models (pages 26-27), evaluation metrics (page 28), and a thorough analysis of the BiHRNN model’s performance (pages 29-30).
Interpretation of the results and the implications of the findings (pages 30-32), and potential directions for future work (pages 33).


\chapter{Related Work}

In this section, we examine existing research on inflation data modeling and forecasting, with an emphasis on methodologies that make use of the hierarchical structure of data to address complex challenges effectively.

\section{Time series}
Time series prediction plays a crucial role in various domains, such as energy management, supply chain optimization, sports analytics, and weather forecasting. It involves forecasting future values by analyzing previously observed data in a sequential order. Traditional approaches such as Autoregressive Integrated Moving Average (ARIMA) models have been commonly applied in inflation forecasting due to their straightforward nature and ease of interpretation \citep{Box1970}. However, with the rise of deep learning techniques, more advanced models such as Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks have demonstrated substantial improvements in predictive accuracy \citep{Hochreiter1997, Goodfellow2016}. Recent advancements in time series forecasting include the use of Transformers, as noted by \citep{zeng2022transformerseffectivetimeseries}. Transformers are highly effective at capturing complex patterns and long-range dependencies; however, their large number of parameters makes them susceptible to overfitting, particularly when applied to the smaller datasets often encountered in time series tasks. Additionally, their computational complexity, driven by the self-attention mechanism, can introduce unnecessary overhead, especially when simpler models often perform comparably for many forecasting tasks.

\subsection{Inflation Time-Series Prediction}
Forecasting inflation time series is critical for economic policy and decision-making. Traditionally, this has been achieved using econometric models such as Vector Autoregression (VAR) and structural models, which excel at capturing dynamic relationships between various economic indicators \citep{Sims1980}. However, recent advancements in time series forecasting have spurred increasing interest in deep learning techniques for inflation prediction. Models like LSTM networks and hybrid approaches combining statistical and machine learning methods have shown superior performance in capturing the complex and non-linear patterns inherent in inflation data \citep{Cheng2019, Guo2021}. 

The Filtered Ensemble Wavelet Neural Network (FEWNet) stands out for its innovative approach to forecasting CPI inflation \citep{SENGUPTA2024}. FEWNet utilizes wavelet transforms to decompose inflation data into high- and low-frequency components and integrates additional economic factors, such as economic policy uncertainty and geopolitical risk, to enhance forecasting accuracy. These transformed components, along with filtered exogenous variables, are processed through autoregressive neural networks to produce an ensemble forecast. By effectively capturing non-linearities and long-range dependencies through its adaptable architecture, FEWNet has demonstrated superior performance compared to traditional models, providing accurate forecasts and robust estimation of prediction uncertainty.

While some studies focus on machine learning techniques, other recent researches highlight the significance of trend and cross-sectional asymmetry measures in enhancing inflation forecasting methodologies. Trimmed-mean inflation estimators have demonstrated their effectiveness in predicting headline inflation for the Personal Consumption Expenditures (PCE) Price Index, substantially improving both point and density forecast accuracy over medium- and long-term horizons \citep{VERBRUGGE2024735}.

\section{Hierarchical inflation Forecasting}
Hierarchical inflation modeling structures inflation data into a hierarchy, where each disaggregated category, such as specific goods or services, contributes to the overall inflation index. This approach enhances prediction accuracy by leveraging the relationships and dependencies between different levels of the hierarchy, such as categories, subcategories, and aggregate indices. Forecasting within this framework often involves aggregating or disaggregating data to ensure consistency and coherence across all hierarchical levels, allowing for more precise and interpretable predictions.

An example of hierarchical inflation forecasting is the HRNN model \citep{BARKAN20231145}, the predecessor of BiHRNN. The HRNN model is specifically designed to address the unique challenges of inflation forecasting in datasets with hierarchical structures. Lower levels, such as specific categories of goods or regional inflation indices, often exhibit missing data and higher volatility in price changes compared to higher aggregate levels. By aligning with the principles of hierarchical Bayesian models, the HRNN assigns prior distributions to parameters at each level, capturing the relationships and dependencies within the hierarchy. 

Hierarchical time series inflation models are particularly well-suited for inflation forecasting as they effectively integrate temporal dynamics and cross-level information. This capability is crucial for tasks like predicting the consumer price index, where capturing temporal trends, seasonality, and structural shifts in economic conditions is essential. For instance, fluctuations in specific product categories or regional price indices can influence aggregate inflation measures, making it important to account for these interactions. By leveraging information across hierarchical levels, these models produce robust forecasts that address both short-term volatility and long-term trends. Building on this foundation, we chose to explore another hierarchical model that enables bidirectional information propagation, further enhancing prediction accuracy and capturing more intricate relationships within the data.

Conventional hierarchical forecasting methods generally use top-down, bottom-up, or middle-out strategies. In the top-down approach, forecasts are generated at the highest level of the hierarchy and then allocated to lower levels. In contrast, the bottom-up approach aggregates forecasts from the lowest level to produce predictions for higher levels. The middle-out approach combines elements of both top-down and bottom-up methods \citep{Hyndman2011}.

Recent advancements have incorporated machine learning techniques into hierarchical forecasting. Models like hierarchical RNNs (HRNNs) and hierarchical LSTMs exploit the hierarchical structure of data to capture dependencies both within and across different levels. These models have demonstrated improved performance across various applications, such as sales forecasting and energy demand prediction \citep{Wickramasuriya2019}. By leveraging information from multiple levels of the hierarchy, they offer more accurate and reliable predictions compared to traditional non-hierarchical approaches.

\section{Hierarchical Long Short-Term Memory Network}
Hierarchical Long Short-Term Memory networks (Hierarchical LSTMs) are an extension of traditional LSTM models, designed to handle data with multiple levels of structure, such as hierarchical time series or sequential data organized into nested groups. These models capture dependencies both within and across different levels of the hierarchy by processing information at each level of granularity. For example, in time series forecasting, a hierarchical LSTM can model trends at higher levels (e.g., overall sales) while simultaneously capturing detailed patterns at lower levels (e.g., sales by region or product category). This architecture allows the model to account for complex interactions across levels, improving prediction accuracy and robustness in tasks where hierarchical relationships are important \citep{LIN2022107618}.

\section{Hierarchical Attention Network}
Hierarchical Attention Networks (HANs) are a deep learning framework designed to model hierarchical structures within data, particularly useful in natural language processing tasks. Unlike standard attention mechanisms, HANs apply attention at different levels of the data hierarchy, such as words within sentences and sentences within documents. This enables the model to focus on the most relevant components at each level, improving its ability to capture contextual relationships and interactions across the hierarchy. For example, in document classification, HANs can first highlight key words within individual sentences, then identify the most important sentences across the document. This hierarchical attention approach not only boosts interpretability but also enhances performance in tasks that rely on understanding multi-level data structures. The effectiveness of HANs has made them essential in various NLP applications, including document classification, sentiment analysis, and text summarization \citep{han_paper}.