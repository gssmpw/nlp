\chapter{Evaluation and Results} 
%In the following section, we outline the evaluation process conducted for inflation prediction using Bidirectional HRNNs. 
We evaluate  the performance of the BiHRNN and compare it to well-established baselines for inflation prediction, as well as some additional machine learning approaches.
We use the following notation: Let $x_t$ be the CPI log-change rate at month $t$ .
Models for $\hat{x}_{t}$ are considered as an estimate for $x_t$ based on historical values.
Furthermore, we denote the estimation error at time $t$ by $\varepsilon_{t}$ .
%In all cases, the $h$-horizon forecasts were generated by recursively iterating the one-step forecasts forward. 
Hyper-parameters were set using Bayesian-inspired optimization procedures.

\section{Baseline Models} \label{baslines}
We compare Bidirectional HRNN with the following CPI prediction baselines:

\begin{enumerate}

\item{\bf Autoregression (AR) -} The AR($\rho$) model estimates $\hat{x}_{t}$ based on the previous $\rho$ timestamps using the following equation: $\hat{x}_{t}= \alpha_0 + \left(\sum_{i=1}^{\rho} \alpha_{i} x_{t-i} \right) + \varepsilon_{t}$, where $\{ \alpha_i \}_{i=0}^{\rho}$ represent the model's parameters.

\item{\bf Random Walk (RW) -} We consider the RW($\rho$) model from \cite{atkeson2002}. RW($\rho$) is a straightforward but powerful model that predicts the next timestamps by taking the average of the last $\rho$ timestamps, using the formula:  $\hat{y}_{t}=\frac{1}{\rho} \sum_{i=1}^{\rho} x_{t-i} + \varepsilon_{t}$.

\item{\bf Random Forests (RF) - } The RF($\rho$) model is an ensemble learning approach that constructs multiple decision trees~\citep{song2015decision} to reduce overfitting and enhance generalization~\citep{breiman2001random}. During prediction, the model returns the average of the predictions made by each individual tree. The inputs to the RF($\rho$) model are the last $\rho$ samples, and the output is the predicted value for the next timestamp.

\item{\bf Extreme Gradient Boost (XGBoost) - } The XGBoost($\rho$) model \citep{Chen_2016} is based on an ensemble of decision trees which are trained in a stage-wise fashion similar to other boosting models \citep{schapire1999brief}. Unlike RF($\rho$) which averages the prediction of multiple decision trees, the XGBoost($\rho$) trains each tree to minimize the remaining residual error of all previous trees. At prediction time, the sum of predictions of all the trees is returned.  The inputs to the XGBoost($\rho$) model are the last $\rho$ samples and the output is the predicted value for the next timestamps.

\item{\bf Fully Connected Neural Network (FC) -} The FC($\rho$) model is a fully connected neural network with one hidden layer of size 100 and a ReLU activation function~\citep{ActivationFunctions}. The output layer does not use any activation function to frame the task as a regression problem, optimized using a squared loss function. The inputs to the FC($\rho$) model consist of the last $\rho$ samples, and the output is the predicted value for the next timestamp.

\item{\bf Support Vector Regression (SVR) - } 
SVR($\rho$)  is a machine learning model based on Support Vector Machines (SVM), used for regression tasks ~\cite{NIPS1996_d3890178}.  SVR($\rho$) attempts to find a function that fits the data within a certain margin of tolerance, while minimizing the prediction error outside this margin. It is particularly effective for capturing complex relationships in data and is robust to outliers due to its focus on maximizing the margin around the prediction.  The kernel used for the prediction is "rbf" and the degree of the polynomial kernel function is three.
The inputs to the SVR($\rho$) model are the last $\rho$ samples and the output is the predicted value for the next timestamps.
\end{enumerate}


\section{Ablation Models}
To highlight the impact of the hierarchical component in the Bidirectional HRNN model, we performed an ablation study by comparing it to "simpler" alternatives, specifically GRU-based models that exclude the hierarchical component: 

\begin{enumerate}

\item{\bf Single GRU (S-GRU) -} The S-GRU($\rho$) is a single GRU unit that receives the last $\rho$ values as inputs in order to predict the next value. In GRU($\rho$), a single GRU is used for all the time series that comprise the CPI hierarchy. This baseline utilizes all the benefits of a GRU but assumes that the different components of the CPI behave similarly and a single unit is sufficient to model all the nodes.   %The model is given by the following formula: $\hat{y}_{t}=h_{t-1}+t \varepsilon_{t}$ where $h_{t-1}$ is the output value of a single scalar GRU layer with input shape of $\left[\begin{array}{ll}{d X} & {1}\end{array}\right]$  and $d$ is the time dimension. In other words the inputs are $x_{t-d}, x_{t-d+1} \ldots x_{t-1}$.

\item {\bf Independent GRUs (I-GRUs) -}
In I-GRUs($\rho$), we trained a different GRU($\rho$) unit for each CPI node. 
The S-GRU and I-GRU approaches represent two extremes: The first attempts to model all the CPI nodes with a single model, while the second treats each node separately. 

To emphasize the effect of bidirectionality, we also compared the Bidirectional HRNN to its predecessor, the Hierarchical Recurrent Neural Network (HRNN).

\item {\bf Hierarchical Recurrent Neural Network (HRNN) -}
In HRNN($\rho$), we trained a separate GRU($\rho$) unit for each CPI node, while incorporating the model weights of its parent category. This approach allows information to flow from parent to child categories, effectively leveraging the hierarchical structure of the data and enhancing prediction accuracy.
\end{enumerate}



\section{Evaluation Metrics}
Following \cite{faust2013forecasting} and \cite{AparicioBertolotto2020a}, we report our results using three evaluation metrics: 
\begin{enumerate}
    \item{\bf Root Mean Squared Error (RMSE) -} 
    The RMSE is calculated as: \begin{equation}
        RMSE=\sqrt{\frac{1}{T}\sum_{t=1}^T \left(x_t- \hat{x}_t \right)^2},
    \end{equation}
     where $x_t$ represents the actual monthly change rate for month $t$, and $\hat{x}_t$ denotes the corresponding predicted value.
    
    \item{\bf Pearson Correlation Coefficient -} The Pearson correlation coefficient $\phi$ is defined as:
    \begin{equation}
        \phi = \frac{COV(X_T,\hat{X}_T)}{\sigma_{X} \times \sigma_{\hat{X}}},    
    \end{equation}
        where $COV(X_T,\hat{X}_T)$ is the covariance between the actual values and predictions, and $\sigma_{X_T}$ and $\sigma_{\hat{X}_T}$ are the standard deviations of the actual values and the predictions, respectively.
    
\item{\bf Distance Correlation Coefficient -} 
Unlike the Pearson correlation, which only measures linear relationships, the distance correlation coefficient can detect both linear and nonlinear associations ~\citep{SzekelyRizzoBakirov2007a,distanceCorrelation}. 
%Distance correlation  is a measure of dependence between two paired random vectors of arbitrary, not necessarily equal dimension. 
%which can only detect linear association between two random variables and Spearman's rho or Kendall's tau which both measure monotonic relationship but cannot capture all types of non-linear dependency. 
The distance correlation coefficient $r_d$ is given by:
    \begin{equation}
    \label{eq:distance_corr}
        r_d= \frac{\operatorname{dCov}(X_T, \hat{X}_T)}{\sqrt{ \operatorname{dVar}(X_T) \times \operatorname{dVar}(\hat{X}_T)}}
    \end{equation}
where $\operatorname{dCov}(X_T, \hat{X}_T)$ is the distance covariance between the actual values and the predictions, and $\operatorname{dVar}(X_T)$ and $\operatorname{dVar}(\hat{X}_T)$ are the distance variances of the actual values and the predictions, respectively.

%\item{\bf Temporal Drift R\textsuperscript{2} -} 
%To establish a fairer baseline that avoids using information from the test data, we calculated the R\textsuperscript{2} score based on the mean and variance of the training data rather than the test data. This approach ensures that the model's performance is assessed without any advantage gained from knowing the test set distribution. Specifically, the total sum of squares (TSS) is computed using the training data as:

%\[
%TSS = \sum{(y_i - \bar{y}_{\text{train}})^2}
%\]

%where $\bar{y}_{\text{train}}$ is the mean of the target variable in the training data. 

%The residual sum of squares (RSS) is then calculated as:

%\[
%RSS = \sum{(y_i - \hat{y}_i)^2}
%\]

%where $\hat{y}_i$ represents the predicted values from the model. 

%Finally, the R\textsuperscript{2} is computed using the training data mean:
%\[
%R^2 = 1 - \frac{RSS}{TSS}
%\]
%This version of R\textsuperscript{2} reflects how well the model performs relative to the variance in the training data, ensuring a consistent and unbiased baseline that does not rely on knowledge of the test set's distribution. This method is more representative of real-world conditions, where the test data distribution is typically unknown, making it a more accurate measure of how the model will perform once it is deployed.

\end{enumerate}


\section{Results} 
\label{sec:Results}
The BiHRNN model stands out for its ability to leverage information flow both from higher levels to lower levels and from lower levels to higher levels within the hierarchy. The model leverages the inherent hierarchy of the CPI, enhancing predictions at both granular and broader, more significant levels, such as the CPI Headline.
Therefore, we will provide the headline results separately, along with the aggregated results across all categories.

The results are relative to the $AR(1)$ model and normalized according to: $\frac{RMSE_{Model}}{RMSE_{AR\left( 1\right) }}$.

\subsection{US CPI Results}
\setlength{\tabcolsep}{3pt}
\begin{table}[H]
\begin{threeparttable} 
\caption{Average Results on Disaggregated CPI Components - US} 
\label{tab:allCPIResults - US}
{\scriptsize  % Reduced font size to fit headers within the table width
\begin{tabularx}{\textwidth}{l>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X}
\toprule[1.1pt]
\textbf{Model} & \textbf{\parbox[c]{1cm}{\centering Avg. \\ RMSE}}  & \textbf{\parbox[c]{1.2cm}{\centering Pearson \\ Corr.}} & \textbf{\parbox[c]{1.2cm}{\centering Dist. \\ Corr.}} & \textbf{\parbox[c]{1.2cm}{\centering Headline \\ RMSE}} & \textbf{\parbox[c]{1.4cm}{\centering Headline Pearson \\ Corr.}} & \textbf{\parbox[c]{1.4cm}{\centering Headline Dist. \\ Corr.}} \\ 
\midrule
I-GRU & 1.215 & 0.138 & 0.338 & 1.015 & 0.347 & 0.350 \\
AR\_1 & 1.000 & 0.176 & 0.513 & 1.000 & 0.327 & 0.459 \\
AR\_2 & 1.267 & 0.105 & 0.467 & 1.312 & 0.327 & 0.565 \\
AR\_3 & 1.487 & 0.082 & 0.437 & 1.560 & 0.349 & 0.510 \\
AR\_4 & 1.902 & 0.052 & 0.411 & 1.749 & 0.308 & 0.427 \\
FC\_p\_12 & 1.229 & -0.014 & 0.355 & 1.592 & 0.027 & 0.251 \\
RF\_p\_12 & 1.143 & 0.112 & 0.377 & 1.210 & 0.368 & 0.377 \\
RW\_p\_4 & 1.189 & -0.013 & 0.353 & 1.420 & -0.050 & 0.310 \\
SVR\_p\_12 & 1.115 & 0.067 & 0.363 & 1.280 & 0.473 & 0.529 \\
XGB\_p\_12 & 1.228 & 0.087 & 0.369 & 1.312 & 0.392 & 0.423 \\
HRNN & 1.028 & 0.158 & 0.346 & 1.015 & 0.347 & 0.350 \\
BiHRNN & 0.966 & 0.230 & 0.378 & 1.052 & 0.225 & 0.290 \\
\bottomrule[1.1pt]
\end{tabularx}
}
\end{threeparttable}
\end{table}


\subsection{Canada CPI Results}
\setlength{\tabcolsep}{3pt}
\begin{table}[H]
\begin{threeparttable} 
\caption{Average Results on Disaggregated CPI Components - Canada} 
\label{tab:allCPIResults - Canada}
{\scriptsize  % Reduced font size to fit headers within the table width
\begin{tabularx}{\textwidth}{l>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X}
\toprule[1.1pt]
\textbf{Model} & \textbf{\parbox[c]{1cm}{\centering Avg. \\ RMSE}} & \textbf{\parbox[c]{1.2cm}{\centering Pearson \\ Corr.}} & \textbf{\parbox[c]{1.2cm}{\centering Dist. \\ Corr.}} & \textbf{\parbox[c]{1.2cm}{\centering Headline \\ RMSE}} & \textbf{\parbox[c]{1.4cm}{\centering Headline Pearson \\ Corr.}} & \textbf{\parbox[c]{1.4cm}{\centering Headline Dist. \\ Corr.}} \\ 
\midrule
I-GRU & 0.892 & 0.351 & 0.476 & 1.261 & 0.329 & 0.516 \\
AR\_1 & 1.000 & 0.128 & 0.633 & 1.000 & 0.628 & 0.693 \\
AR\_2 & 1.188 & -0.008 & 0.592 & 1.155 & 0.241 & 0.409 \\
AR\_3 & 1.305 & -0.004 & 0.561 & 0.970 & 0.646 & 0.671 \\
AR\_4 & 1.684 & -0.004 & 0.522 & 1.424 & 0.356 & 0.416 \\
FC\_p\_12 & 0.907 & 0.237 & 0.465 & 2.051 & 0.152 & 0.352 \\
RF\_p\_12 & 0.861 & 0.318 & 0.509 & 1.635 & 0.542 & 0.540 \\
RW\_p\_4 & 0.901 & 0.138 & 0.414 & 1.261 & 0.495 & 0.658 \\
SVR\_p\_12 & 0.852 & 0.308 & 0.517 & 1.721 & 0.449 & 0.580 \\
XGB\_p\_12 & 0.936 & 0.271 & 0.502 & 1.635 & 0.411 & 0.527 \\
HRNN & 0.824 & 0.358 & 0.490 & 1.261 & 0.329 & 0.516 \\
BiHRNN & 0.795 & 0.386 & 0.511 & 1.170 & 0.321 & 0.497 \\
\bottomrule[1.1pt]
\end{tabularx}
}
\end{threeparttable}
\end{table}


\subsection{Norway CPI Results}
\setlength{\tabcolsep}{3pt}
\begin{table}[H]
\begin{threeparttable} 
\caption{Average Results on Disaggregated CPI Components - Norway} 
\label{tab:allCPIResults - Norway}
{\scriptsize  % Reduced font size to fit headers within the table width
\begin{tabularx}{\textwidth}{l>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X}
\toprule[1.1pt]
\textbf{Model} & \textbf{\parbox[c]{1cm}{\centering Avg. \\ RMSE}} & \textbf{\parbox[c]{1.2cm}{\centering Pearson \\ Corr.}} & \textbf{\parbox[c]{1.2cm}{\centering Dist. \\ Corr.}} & \textbf{\parbox[c]{1.2cm}{\centering Headline \\ RMSE}} & \textbf{\parbox[c]{1.4cm}{\centering Headline Pearson \\ Corr.}} & \textbf{\parbox[c]{1.4cm}{\centering Headline Dist. \\ Corr.}} \\ 
\midrule
I-GRU & 0.866 & 0.355 & 0.5063 & 0.724 & 0.208 & 0.413 \\
AR\_1 & 1.000 & 0.053 & 0.653 & 1.000 & -0.583 & 0.546 \\
AR\_2 & 1.251 & -0.003 & 0.617 & 1.132 & -0.743 & 0.695 \\
AR\_3 & 1.378 & 0.009 & 0.568 & 1.189 & -0.797 & 0.777 \\
AR\_4 & 1.727 &  0.011 & 0.535 & 1.296 & -0.536 & 0.574 \\
FC\_p\_12 & 0.974 & 0.226 & 0.454 & 0.924 & 0.242 & 0.422 \\
RF\_p\_12 & 0.849 & 0.349 & 0.539 & 0.672 & 0.613 & 0.721 \\
RW\_p\_4 & 0.973 & 0.187 & 0.405 & 0.788 & 0.165 & 0.337 \\
SVR\_p\_12 & 0.851 & 0.376 & 0.550 & 0.848 & 0.251 & 0.362 \\
XGB\_p\_12 & 0.904 & 0.303 & 0.530 & 0.669 & 0.644 & 0.725 \\
HRNN & 0.832 & 0.3677 & 0.5365 & 0.724 & 0.208 & 0.413 \\
BiHRNN & 0.767 & 0.478 & 0.567 & 0.655 & 0.390 & 0.477 \\
\bottomrule[1.1pt]
\end{tabularx}
}
\end{threeparttable}
\end{table}


The results in Tables ~\ref{tab:allCPIResults - Canada}, ~\ref{tab:allCPIResults - Norway}, and ~\ref{tab:allCPIResults - US} show that the BiHRNN consistently outperforms other models in terms of predictive accuracy and stability. With some of the lowest RMSE values across datasets, this model demonstrates its ability to reliably minimize error between various components of the CPI. In comparison, simpler models like AR(1) and AR(4) often exhibit higher RMSE and greater variability, indicating that the BiHRNN model offers a stronger, more stable fit for this complex data.

%The Temporal Drift R\textsuperscript{2}, further emphasizes the Bidirectional HRNN’s advantage. This model attains positive values, indicating a closer alignment with observed data over time. By contrast, many benchmark models (e.g., AR(3), FC(12)) report negative R\textsuperscript{2} values, signaling poor temporal alignment and a failure to capture time-based patterns effectively. 

Correlation metrics reinforce this model’s capacity to understand the underlying relationships in the data. The BiHRNN achieves high Pearson and Distance correlations indicating a strong alignment between model predictions and actual outcomes. Although a few models, like RF(12), show competitive correlations, their higher RMSE values demonstrate an inability to consistently maintain accuracy across metrics.

The BiHRNN model demonstrates top-tier performance in headline predictions, excelling in both RMSE and correlation metrics. However, our findings indicate that the Headline data alone is sufficient for accurate headline predictions and yields the best results. Attempts to incorporate additional regularization terms do not enhance prediction performance. Consequently, we recommend that future work on headline predictions focus exclusively on using the Headline data.

This balance across both disaggregated components and headline metrics highlights the model's robustness and adaptability, making it a preferable choice for forecasting CPI trends. Overall, the BiHRNN stands out as the most effective model, combining low error rates, strong fit, and high correlation, all of which contribute to a more accurate and reliable CPI prediction framework across categories.

Figure ~\ref{fig:disaggregated_index_predictions} below showcases examples of several disaggregated indexes from different hierarchy levels and sectors. The solid black line shows the actual CPI values, while the dashed lines depict predictions from the top-performing models—all variations of RNN models: BiHRNN, HRNN, and I-GRU in blue, green, and red, respectively. As shown in the graphs, the BiHRNN model demonstrates superior predictive accuracy, achieving lower RMSEs and more effectively capturing shifts in trends compared to its counterparts.

\begin{figure}[H]
    \centering
    
    \subfloat[Food]{
        \includegraphics[width=0.6\textwidth]{figures/Food_Canada.png}
        \label{fig:Food - Canada}
    }
    \hfill
    \subfloat[Housekeeping]{
        \includegraphics[width=0.6\textwidth]{figures/Housekeeping_Canada.png}
        \label{fig:Housekeeping - Canada}
    }
    
%    \vspace{0.5cm}  % Space between the two rows of images
    
    \subfloat[Footwear]{
        \includegraphics[width=0.6\textwidth]{figures/Footwear_Norway.png}
        \label{fig:Footwear Norway}
    }
    \hfill
    \subfloat[Out-patient Services]{
        \includegraphics[width=0.6\textwidth]{figures/Out-patient_services_Norway.png}
        \label{fig:Out-patient services - Norway}
    }
    
    \caption{Disaggregated Index CPI Predictions}
    \label{fig:disaggregated_index_predictions}
\end{figure}
