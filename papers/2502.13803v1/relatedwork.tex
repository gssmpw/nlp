\section{Related Work}
\label{RelatedWork}
Dense visual SLAM remains fundamental for autonomous navigation and 3D mapping in robotics and photogrammetry. While traditional SLAM systems like ORB-SLAM \cite{mur2015orb} use sparse feature matching for pose tracking, they often struggle in complex environments with low texture or repetitive patterns. Dense SLAM approaches such as LSD-SLAM \cite{engel2014lsd} and DSO \cite{engel2017direct} address this by leveraging dense image information, improving robustness in challenging scenarios. More recently, learning-based systems like DROID-SLAM \cite{teed2021droid} have emerged, using neural networks to achieve more accurate pose estimation and complete 3D scene representations. However, the resulting point clouds and meshes have limitations - point clouds often lack fine details and textures, while high-resolution meshes require significant storage. 3D Gaussian Splatting (3DGS) \cite{kerbl2024hierarchical} offers a promising alternative by providing a compact yet expressive scene representation that maintains both visual fidelity and geometric accuracy across viewpoints. By integrating Gaussian Splatting with dense SLAM, as demonstrated in HI-SLAM2 \cite{zhang2024hislam2}, we can produce detailed 3D representations of complex indoor environments like construction halls. This approach not only improves the quality of the reconstructed scene but also enables the rendering of novel views to enhance mapping coverage and robust visual localization.