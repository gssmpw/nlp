\section{Related Work}
This section positions our work in the literature on stowage planning, stochastic programming and ML in optimization.  

\textbf{Stowage Planning.} To address the complexity of stowage planning, various solution approaches have been applied to different problem formulations, including exact methods ____, linearly relaxed MIP ____, matheuristics ____, population-based metaheuristics ____, neighbourhood-based metaheuristics ____, hybrid frameworks ____. 
Despite these techniques, a recent survey highlights that scalable solutions for representative stowage and MPP problems remain unsolved ____. Research has largely focused on deterministic problems, overlooking real-world needs for profit maximization in the face of demand uncertainty. 

\textbf{Stochastic Programming.} Decision-making under uncertainty is traditionally approached through stochastic programming, where uncertainty is explicitly represented as a set of discrete scenarios evolving over multiple stages in time, approximating the underlying probability distribution ____. This process results in a scenario tree, whose computational complexity grows exponentially as $\mathcal{O}(b^T)$, where $b$ is the branching factor and $T$ is the number of stages. Hence, multi-stage problems with $T > 2$ and a reasonably large $b$ are often intractable. Common techniques to overcome this complication are scenario reduction to reduce problem size ____, decomposition techniques like Benders decomposition or Lagrangian relaxation to divide the problem ____, progressive hedging to enforce non-anticipativity iteratively ____, or approximation methods, such as stochastic dual dynamic programming ____ and sample average approximation ____, to enhance tractability while preserving solution quality.

\textbf{Learning with Hard Constraints.} In learning solution heuristics, a challenge arises to ensure feasibility in complex action spaces. This challenge is exacerbated when dealing with the dependence on state variables to define the feasible region. Several deep learning approaches have dealt with learning constraints by backpropagation through (in)equality completion ____, or differentiable projection layers, such as mapping interior points to boundaries ____,  convex programming layers ____, or problem-specific repair layers ____. Moreover, safe reinforcement learning has dealt with constraints by, e.g., constrained MDPs with a primal-dual approach ____, soft barriers function ____, and safety shields ____.