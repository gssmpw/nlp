\begin{table*}[t]
\caption{Benchmarks comparison. ``TestGen'' refers to whether the benchmark is designed for unit test generation. ``Self-contained'' refers to whether the data sample is independent rather than being part of a larger project. \Checkmark\kern-1.1ex\raisebox{1.5ex}{\rotatebox[origin=c]{125}{--}} indicates partial satisfaction of the condition. ``Error Analyses'' refers to specific error analyses for unit test generation by LLMs.
\congying{eval for devbench depends on orancle tests, our benchmark have another task, llm fix unit test. The size has different units, not comparable, project vs file}}
\resizebox{\linewidth}{!}{% <-
\begin{tabular}{ccccccccccc}
\hline
Dataset & Language & Code Level & Multi-file & TestGen & Size & Avg. \#Files & Self-contained & Error Analyses & Error Fixing\\
\hline
HumanEval & Python & Function & \XSolidBrush & \XSolidBrush & 164 & 1 & \Checkmark & - & -\\
ClassEval & Python & Class & \XSolidBrush & \XSolidBrush & 100 & 1 & \Checkmark & - & - \\
TestEval & Python & Function & \XSolidBrush & \Checkmark & 210 & 1 & \Checkmark & \XSolidBrush & \XSolidBrush \\
TestGenEval & Python & File & \XSolidBrush & \Checkmark & 1,210 & 1 & \XSolidBrush & \Checkmark & \XSolidBrush \\
% SWT-Bench \\ % ==> bug fixing tests generation
% R2E & Python & Project &  &  &  &  & \Checkmark\\ % ==> generate equivalent tests, different from human written/readable unit tests 
% RepoEval & Python & Project & \XSolidBrush & - & 14 & 162 & \Checkmark & - \\
DevBench & \makecell[c]{Python, Java, C/C\#} & Project & \Checkmark\kern-1.1ex\raisebox{1.5ex}{\rotatebox[origin=c]{125}{--}} & \XSolidBrush & 20 & 4.20 & \Checkmark & \XSolidBrush & \XSolidBrush \\ % ==> 1. dataset too small (2 JS, 5 Java) 2. no analyses for unit test generation
% CrossCodeEval & Python, Java, TypeScript, C\# & \\ ==> 1. for code completion 2. not executable 
ProjectTestEval & \makecell[c]{Python, Java, JavaScript} & Project & \Checkmark & \Checkmark & 60 & 4.92 & \Checkmark & \Checkmark & \Checkmark\\
\hline
\end{tabular}
}
\label{tab: benchmark_comparison}
\end{table*}
