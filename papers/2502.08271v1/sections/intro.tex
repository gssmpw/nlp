\section{Introduction}
Large Language Models~(LLMs) have demonstrated significant success across diverse fields~\cite{zhao2023survey}, driven by their emergent capabilities~\cite{dong2024survey,huang-chang-2023-towards} such as world knowledge, language understanding, and complex reasoning. 
Recently, LLMs have introduced transformative advancements to recommendation tasks. Notably, LLMs have shown potential in capturing nuanced item semantics~\cite{10.1145/3640457.3688104}, understanding diverse user interests~\cite{deng2022toward}, and unifying various recommendation tasks~\cite{geng2022recommendation}.
These advancements highlight the promise of utilizing LLMs as recommender systems, positioning LLM-based recommendations as a compelling area for further exploration.

\begin{figure*}[ht]
    \centering \includegraphics[width=0.98\textwidth]{figures/intro_6.pdf}
    %\vspace{-0.4cm}
    \caption{Illustration of different LLM-based recommendation paradigms. (1) Breadth-oriented paradigm. (2) Depth-oriented paradigm. (3) Our proposed MoLoRec.}
    \label{fig:intro}
    \Description{}
\end{figure*}

In the field of LLM-based recommendation research, the emergence of ChatGPT and its remarkable reasoning capabilities have catalyzed early studies~\cite{dai2023uncovering,sanner2023large,wang-etal-2023-rethinking-evaluation}. These works focus on the zero-shot/few-shot recommendation potential of LLMs through in-context learning~\cite{dong2024survey}. However, the intrinsic gap between the pre-training general text corpus of LLMs and the requirements of recommendation tasks results in suboptimal performance when relying solely on in-context learning. Consequently, the key to developing an effective LLM-based recommender system lies in bridging this gap, enabling the model to truly "understand" how to recommend.
To address this challenge, researchers have proposed a variety of approaches. We classify them into two paradigms, each tackling the problem from a distinct perspective.
As shown in Figure \ref{fig:intro}(a), the first one is summarized as the \textbf{breadth-oriented paradigm}. These works integrate multi-domain~\cite{10.1145/3705727} or multi-task~\cite{geng2022recommendation,10.1145/3708882,cui2022m6} recommendation data to construct extensive recommendation world knowledge, paving the way for developing a generalizable LLM-based recommender. 
The key focus of this paradigm is the integration of multi-source data to build instruction-tuning datasets~\cite{peng2024ecellm,jin2023amazonm} and the design of instruction templates~\cite{10.1145/3708882,geng2022recommendation} tailored to various tasks.
%The research focus of paradigm 1 lies in integrating multi-source data to construct instruction tuning datasets~\cite{peng2024ecellm,jin2023amazonm} and designing instruction templates~\cite{10.1145/3708882,geng2022recommendation} specifically tailored to different tasks. 
The second paradigm is termed the \textbf{depth-oriented paradigm}, illustrated in Figure \ref{fig:intro}(b). This line of research seeks to enable LLMs to deeply comprehend recommendation tasks within specific domains. Key areas of focus include: the in-depth extraction of domain-specific recommendation knowledge, such as collaborative filtering information~\cite{lin2024bridging,10.1145,10.1145/3626772.3657690,10.1145/3589334.3645458,kong2024customizing}, and the development of efficient and effective alignment methods between LLMs and recommendation tasks. Specifically, compared with enormous parameters in LLMs, downstream tasks do not have sufficient data for tuning all parameters. 
Therefore, parameter-efficient fine-tuning methods become optimal for applying LLMs, in which lightweight Low-Rank Adapter (LoRA) is one representative work~\cite{hu2022lora}. By borrowing ideas of LLMs, these methods include leveraging~\cite{bao2023tallrec} or enhancing~\cite{kong2024customizing} LoRA fine-tuning techniques and designing data-efficient fine-tuning strategies~\cite{10.1145/3626772.3657807}.

These works make significant advancements in recommendation research. Nevertheless, we argue that these two paradigms have complementary advantages. The first paradigm masters general recommendation knowledge and can be well generalized to various recommendation scenarios. The second paradigm learns each user's unique preference and is suitable for the warm-start recommendation of a specific domain. However, the specific recommendation domain performance could not be easily transferred to other domains. In fact, both generalizable recommendation knowledge and efficient domain-specific understanding are essential for recommender systems. 
Relying solely on one aspect risks falling short in addressing the diverse challenges in real-world recommendation scenarios.
The breadth-oriented paradigm may underperform in specific domains. Conversely, the depth-oriented paradigm struggles with distribution shifts between training and test data. It faces challenges when new users or items appear or when training data are sparse.

To this end, we investigate how to integrate the advantages of both paradigms to simultaneously enhance the model's generalization ability and domain-specific performance. The task creates significant obstacles: (1) Efficiency. Integrating two paradigms may introduce model complexity, and finding an efficient integrating method without excessive computational overhead is a critical challenge. (2) Generalizability. We need to preserve the model's generalization ability to a large extent, enabling it to quickly scale to new domains, new items, and other new recommendation scenarios.
In this paper, we propose a generalizable and efficient recommendation framework named Mixture-of-LoRA Recommendation Framework (\shortname). 
\shortname~fuses both general recommendation knowledge and domain-specific knowledge with three key stages. Firstly, to align LLM with any recommendation task, \shortname~constructs a general recommendation instruction dataset from multiple recommendation domains, and fine-tunes LLM to get a domain-general LoRA module. Secondly, to tailor the framework for specific domains, \shortname~constructs domain-specific instruction datasets derived from the specific domain, and fine-tunes LLM to get a domain-specific LoRA module. After that, \shortname~performs a highly efficient and effective linear arithmetic operation to merge these LoRA adapters within the weight space, allowing \shortname~to maintain strong recommendation performance across both specific domains and out-of-distribution scenarios. To further enhance the merging process of LoRA adapters, we also introduce an adaptive LoRA weight merging method guided by entropy minimization during test time.  Importantly, our framework is designed for ease of use, allowing for a plug-and-play integration where the domain-general module is trained once, and domain-specific adaptations are incorporated through minimal fine-tuning.  Finally, extensive experiments conducted on various datasets demonstrate the effectiveness and versatility of the framework in both warm recommendation scenarios and challenging cold-start scenarios, highlighting its potential for broad application.











\iffalse
Unlike traditional deep learning models, which are typically designed for specific tasks and datasets, LLMs possess rich internal knowledge, enabling superior generalization to novel tasks. This makes them particularly effective in addressing challenges faced by conventional models. As a result, there has been growing interest in exploring the potential of adapting LLMs for recommendation tasks, namely LLM-based recommendation~\cite{10.1145/3678004,wu2024survey}.
\fi

\iffalse
To harness the potential of LLMs as recommender systems, early studies~\cite{dai2023uncovering,sanner2023large,wang-etal-2023-rethinking-evaluation} have focused on leveraging LLMs' remarkable generalization capabilities. Specifically, these studies utilize in-context learning, where a few example input-label pairs are provided, enabling LLMs to understand and adapt to recommendation tasks without requiring parameter updates. 
Nevertheless, pre-trained LLMs may only possess rough and general experience in accomplishing a task, lacking the specialized knowledge and professional working patterns required for effective recommendations.
To bridge this gap, recent works have almost universally applied instruction tuning to enhance the performance of LLM-based recommender systems~\cite{bao2023tallrec,10.1145/3626772.3657807,geng2022recommendation}.

We first integrated multi-domain data to train a foundational model, serving as a base. Then, we trained specific components tailored to recommendation tasks in particular domains. By plugging these components with the foundational model, we achieved efficient inference while significantly improving recommendation performance and generalization capabilities.
\fi

%due to the inherent gap between recommendation tasks and the LLMs' pre-training tasks, the performance remains limited when relying solely on in-context learning. To bridge this gap and fully unlock the potential of LLMs, recent work has almost universally apply instruction tuning to enhance the performance of LLM-based recommender systems~\cite{bao2023tallrec,lin2024data,geng2022recommendation}.
