\section{Appendix: Experimental Details}
\begin{table}[ht]
\small
\centering
\caption{Statistics of the datasets for stage 1 and specific domains.}
\begin{tabular}{lcccc}
\toprule[1.6pt]  % Make the top border thicker
%\midrule[0.8pt]
\multicolumn{5}{c}{\textbf{Domain-General Dataset-1}} \\
\midrule[0.8pt]
\textbf{Datasets} & \textbf{\# Users} & \textbf{\# Items} & \textbf{\# Interactions} & \textbf{Density(\%)} \\
\midrule[0.8pt]
Clothing & 39,387 & 23,033 & 278,677 & 0.0307 \\
Cell & 27,879 & 10,429 & 194,439 & 0.0669 \\
Grocery & 14,681 & 8,713 & 151,254 & 0.1182 \\
Health & 38,609 & 18,534 & 346,355 & 0.0484 \\
Home & 66,519 & 28,237 & 551,682 & 0.0294 \\
Pet & 


19,856 & 8,510 & 157,836 & 0.0934 \\
Tools & 16,638 & 10,217 & 134,476 & 0.0791 \\
Videos & 24,303 & 10,672 & 231,780 & 0.0894 \\
%\midrule
%Total & 247,872 & 118,354 & 2,046,499 & - \\
\midrule[0.8pt]
\multicolumn{5}{c}{\textbf{Domain-Specific Dataset-1}} \\
\midrule[0.8pt]
Beauty & 22,363 & 12,101 & 198,502 & 0.0734 \\
Toys & 19,412 & 11,924 & 167,597 & 0.0724 \\
Sports & 35,598 & 18,357 & 296,337 & 0.0453 \\
\midrule[1.6pt]
%\midrule[0.8pt]
\multicolumn{5}{c}{\textbf{Domain-General Dataset-2}} \\
\midrule[0.8pt]
Movielens-10M & 71,567 & 10,681 & 10,000,054 & 1.3082 \\
\midrule[0.8pt]
\multicolumn{5}{c}{\textbf{Domain-Specific Dataset-2}} \\
\midrule[0.8pt]
Movielens-1M & 6,040 & 6,883 & 1,000,209 & 2.4059 \\
%\midrule[0.8pt]
\bottomrule[1.6pt]  % Make the bottom border thicker
\end{tabular}
\label{tab:data}
\end{table}

\subsection{Dataset}
\label{sec:appendix_dataset}
The statistics of the domain-general and the domain-specific datasets are shown in Table \ref{tab:data}.
\subsection{Baselines}
\label{sec:appendix_baselines} 
We compare \shortname~ with traditional recommendation methods (BPR-MF, GRU4Rec, SASRec, and FMLP-Rec), transferable sequential recommenders (UniSRec, VQ-Rec), LLM-based recommenders (Qwen2-7B, RecFormer, P5, TALLRec) and our ablation counterparts (MoLoRec-G, MoLoRec-S). 
\begin{itemize}[leftmargin=*]
    \item \textbf{BPR-MF}~\cite{10.5555/1795114.1795167} is one of the most representative collaborative filtering models.
    \item \textbf{GRU4Rec}~\cite{DBLP:journals/corr/HidasiKBT15} is a seminal method that uses RNNs to model user action sequences for session-based recommendation. 
    \item \textbf{SASRec}~\cite{kang2018self} is a representative sequential recommender model that adopts a self-attention mechanism to learn the item dependency from user interactions.
    \item \textbf{FMLP-Rec}~\cite{10.1145/3485447.3512111} is an all-MLP model with learnable filters for sequential recommendation tasks.
    \item \textbf{UniSRec}~\cite{hou2022towards} equips textual item representations with an MoE-enhanced adaptor for domain fusion and adaptation. Both item-sequence and sequence-sequence contrastive learning tasks are designed for pre-training transferable sequence representations.
    \item \textbf{VQ-Rec}~\cite{10.1145/3543507.3583434} learns vector-quantized item representations for transferable sequential Recommenders.
    \item \textbf{Qwen2-7B}\footnote{\url{https://huggingface.co/Qwen/Qwen2-7B-Instruct}} is a well-known open-source LLM. In our experiments, we choose it as \shortname~'s LLM backbone.
    \item \textbf{RecFormer}~\cite{10.1145/3580305.3599519} models user preferences and item features using the LongFormer~\cite{beltagy2020longformer} backbone, transforming sequential recommendation into a task of predicting the next item as if predicting the next sentence, by converting item attributes into a sentence format.
    \item \textbf{P5}~\cite{geng2022recommendation} is a unified LLM-based recommendation framework. It is built on T5 by fine-tuning with multiple recommendation tasks.
    \item \textbf{TALLRec}~\cite{bao2023tallrec} learns the recommendation task based on prompts consisting solely of text and fine-tunes the LLMs using the LoRA.
    \item \textbf{MoLoRec-G} is an ablation counterpart of our proposed framework. It only underwent stage 1, utilizing only the domain-general LoRA module.
    \item \textbf{MoLoRec-S} is an ablation counterpart of our proposed framework. It only underwent stage 2, utilizing only the domain-general LoRA module.
\end{itemize}

\subsection{Implementation Details}
\label{sec:appendix_implementation}
To ensure a fair comparison, the experimental settings are standardized as follows:
For traditional recommendation methods (BPR-MF, GRU4Rec, SASRec, and FMLP-Rec), the learning rate is set to 0.001, and the Adam optimizer is employed. The batch size is set to 256, and the embedding dimension is set to 64.
Regarding transferable sequential recommenders (UniSRec, VQ-Rec), these models utilize a BERT for text processing. Specifically, the pre-trained models provided by the original authors are fine-tuned on our dataset. For RecFormer, the pre-trained model provided by the original work is also fine-tuned on the downstream tasks.
In the case of P5 and TALLRec, an identical instruction fine-tuning template is used to align the original models with the recommendation tasks. Here, P5 undergoes full fine-tuning, while TALLRec is fine-tuned using a LoRA approach with a rank of 16.
This setup standardizes the evaluation framework across different recommendation methodologies, ensuring comparability and fairness in assessing their performance.
We use Qwen2-7B as the LLM backbone for MoLoRec. For parameter-efficient finetuning(PEFT) conducted on  NVIDIA RTX 4090(24G) GPUs, we adopt low-rank adaption(LoRA) with LoRA rank as 16, LoRA alpha as 32, and LoRA dropout as 0.05 to get general LoRA adapter and target LoRA adapter. The learning rate is selected from {1e-4,2e-4} and the batch size is set to 128. For LoRA adapters fusion weights learning conducted on two NVIDIA RTX 4090(24G) GPUs, the batch size is set to 60, number of test samples for training is selected from {50,100}. The number of tokens at the beginning of each title involved in training is set to 3 for Toys and Sports and 5 for Beauty because titles in Beauty are longer than Toys and Sports. In order to reduce GPU memory usage, we employed gradient checkpointing techniques. Since the model structure has not changed, we use the VLLM inference acceleration framework to perform inference and then evaluate the results. Other implementation details are available in our open-source code.

