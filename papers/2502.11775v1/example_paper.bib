@misc{o1,
 author    = {OpenAI},
 title     = {Learning to reason with large language models},
 year      = {2024},
}

@misc{deepseek,
 author    = {{DeepSeek Team}},
 title     = {Deepseek-r1-lite-preview is now live: unleashing supercharged reasoning power},
 year      = {2024},
}

@misc{qwq,
 author    = {{Qwen Team}},
 title     = {{QwQ}: {R}eflect deeply on the boundaries of the unknown},
 year      = {2024},
}


@article{qwen25math,
      title={{Qwen2.5-Math} Technical Report: {T}oward Mathematical Expert Model via Self-Improvement}, 
      author={An Yang and Beichen Zhang and Binyuan Hui and Bofei Gao and Bowen Yu and Chengpeng Li and Dayiheng Liu and Jianhong Tu and Jingren Zhou and Junyang Lin and Keming Lu and Mingfeng Xue and Runji Lin and Tianyu Liu and Xingzhang Ren and Zhenru Zhang},
      year={2024},
      journal={arXiv:2409.12122},
}

@inproceedings{mathshepherd,
    title = "{Math-Shepherd}: {V}erify and Reinforce {LLM}s Step-by-step without Human Annotations",
    author = "Wang, Peiyi  and
      Li, Lei  and
      Shao, Zhihong  and
      Xu, Runxin  and
      Dai, Damai  and
      Li, Yifei  and
      Chen, Deli  and
      Wu, Yu  and
      Sui, Zhifang",
    booktitle = "Proc. ACL",
    year = "2024",
}

@inproceedings{easytohard,
      title={Easy-to-Hard Generalization: {S}calable Alignment Beyond Human Supervision}, 
      author={Zhiqing Sun and Longhui Yu and Yikang Shen and Weiyang Liu and Yiming Yang and Sean Welleck and Chuang Gan},
      year={2024},
      booktitle={Proc. NeurIPS},
}

@article{eurus,
      title={Advancing {LLM} Reasoning Generalists with Preference Trees}, 
      author={Lifan Yuan and Ganqu Cui and Hanbin Wang and Ning Ding and Xingyao Wang and Jia Deng and Boji Shan and Huimin Chen and Ruobing Xie and Yankai Lin and Zhenghao Liu and Bowen Zhou and Hao Peng and Zhiyuan Liu and Maosong Sun},
      year={2024},
      journal={arXiv:2404.02078},
}

@article{internmath,
      title={{InternLM-Math}: {O}pen Math Large Language Models Toward Verifiable Reasoning}, 
      author={Huaiyuan Ying and Shuo Zhang and Linyang Li and Zhejian Zhou and Yunfan Shao and Zhaoye Fei and Yichuan Ma and Jiawei Hong and Kuikun Liu and Ziyi Wang and Yudong Wang and Zijian Wu and Shuaibin Li and Fengzhe Zhou and Hongwei Liu and Songyang Zhang and Wenwei Zhang and Hang Yan and Xipeng Qiu and Jiayu Wang and Kai Chen and Dahua Lin},
      year={2024},
      journal={arXiv:2402.06332},
}

@article{cotst,
      title={{CoT-ST}: {E}nhancing {LLM}-based Speech Translation with Multimodal Chain-of-Thought}, 
      author={Yexing Du and Ziyang Ma and Yifan Yang and Keqi Deng and Xie Chen and Bo Yang and Yang Xiang and Ming Liu and Bing Qin},
      year={2024},
      journal={arXiv:2409.19510},
}

@misc{qvq,
 author    = {{Qwen Team}},
 title     = {To see the world with wisdom},
 year      = {2024},
}

@article{llavacot,
      title={{LLaVA-CoT}: {L}et Vision Language Models Reason Step-by-Step},
      author={Guowei Xu and Peng Jin and Hao Li and Yibing Song and Lichao Sun and Li Yuan},
      year={2024},
      journal={arXiv:2411.10440},
}

@article{prm0,
      title={Let's Verify Step by Step}, 
      author={Hunter Lightman and Vineet Kosaraju and Yura Burda and Harri Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
      year={2023},
      journal={arXiv:2305.20050},
}

@article{prm1,
      title={Improve Mathematical Reasoning in Language Models by Automated Process Supervision}, 
      author={Liangchen Luo and Yinxiao Liu and Rosanne Liu and Samrat Phatale and Meiqi Guo and Harsh Lara and Yunxuan Li and Lei Shu and Yun Zhu and Lei Meng and Jiao Sun and Abhinav Rastogi},
      year={2024},
      journal={arXiv:2406.06592},
}

@article{orm0,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      year={2021},
      journal={arXiv:2110.14168},
}

@inproceedings{prm2,
    title = {Making Language Models Better Reasoners with Step-Aware Verifier},
    author = "Li, Yifei  and
      Lin, Zeqi  and
      Zhang, Shizhuo  and
      Fu, Qiang  and
      Chen, Bei  and
      Lou, Jian-Guang  and
      Chen, Weizhu",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proc. ACL",
    year = "2023",
}

@inproceedings{orm1,
    title = {{OVM}, Outcome-supervised Value Models for Planning in Mathematical Reasoning},
    author = "Yu, Fei  and
      Gao, Anningzhe  and
      Wang, Benyou",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proc. NAACL Findings",
    year = "2024",
}

@article{selfverify,
      title={Generative Verifiers: {R}eward Modeling as Next-Token Prediction}, 
      author={Lunjun Zhang and Arian Hosseini and Hritik Bansal and Mehran Kazemi and Aviral Kumar and Rishabh Agarwal},
      year={2024},
      journal={arXiv:2408.15240},
}

@inproceedings{cot,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2022},
      booktitle={Proc. NeurIPS},
}

@article{ormprm,
      title={Solving math word problems with process- and outcome-based feedback}, 
      author={Jonathan Uesato and Nate Kushman and Ramana Kumar and Francis Song and Noah Siegel and Lisa Wang and Antonia Creswell and Geoffrey Irving and Irina Higgins},
      year={2022},
      journal={arXiv:2211.14275},
}

@article{virgo,
      title={Virgo: {A} Preliminary Exploration on Reproducing o1-like MLLM}, 
      author={Yifan Du and Zikang Liu and Yifan Li and Wayne Xin Zhao and Yuqi Huo and Bingning Wang and Weipeng Chen and Zheng Liu and Zhongyuan Wang and Ji-Rong Wen},
      year={2025},
      journal={arXiv:2501.01904},
}

@article{llamaberry,
      title={{LLaMA-Berry}: {P}airwise Optimization for O1-like {O}lympiad-Level Mathematical Reasoning}, 
      author={Di Zhang and Jianbo Wu and Jingdi Lei and Tong Che and Jiatong Li and Tong Xie and Xiaoshui Huang and Shufei Zhang and Marco Pavone and Yuqiang Li and Wanli Ouyang and Dongzhan Zhou},
      year={2024},
      journal={arXiv:2410.02884},
}

@article{o1coder,
      title={{o1-Coder}: {A}n o1 Replication for Coding}, 
      author={Yuxiang Zhang and Shangxi Wu and Yuqi Yang and Jiangming Shu and Jinlin Xiao and Chao Kong and Jitao Sang},
      year={2024},
      journal={arXiv:2412.00154},
}

@article{macroo1,
      title={{Marco}-o1: {T}owards Open Reasoning Models for Open-Ended Solutions}, 
      author={Yu Zhao and Huifeng Yin and Bo Zeng and Hao Wang and Tianqi Shi and Chenyang Lyu and Longyue Wang and Weihua Luo and Kaifu Zhang},
      year={2024},
      journal={arXiv:2411.14405},
}

@article{gemini,
      title={Gemini: {A} Family of Highly Capable Multimodal Models}, 
      author={Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and others},
      year={2024},
      journal={arXiv preprint arXiv:2312.11805},
}

@inproceedings{videollava,
  title={{Video-LLaVA}: {L}earning United Visual Representation by Alignment Before Projection},
  author={Lin, Bin and Zhu, Bin and Ye, Yang and Ning, Munan and Jin, Peng and Yuan, Li},
  booktitle={Proc. CVPR},
  year={2024},
}

@article{llavavideo,
      title={Video Instruction Tuning With Synthetic Data}, 
      author={Yuanhan Zhang and Jinming Wu and Wei Li and Bo Li and Zejun Ma and Ziwei Liu and Chunyuan Li},
      year={2024},
      journal={arXiv:2410.02713},
}

@article{videollama2,
  title={{VideoLLaMA} 2: {A}dvancing Spatial-Temporal Modeling and Audio Understanding in {Video-LLMs}},
  author={Cheng, Zesen and Leng, Sicong and Zhang, Hang and Xin, Yifei and Li, Xin and Chen, Guanzheng and Zhu, Yongxin and Zhang, Wenqi and Luo, Ziyang and Zhao, Deli and Bing, Lidong},
  journal={arXiv preprint arXiv:2406.07476},
  year={2024},
}

@inproceedings{videosalmonn,
  title={video-{SALMONN}: {S}peech-Enhanced Audio-Visual Large Language Models},
  author={Guangzhi Sun and Wenyi Yu and Changli Tang and Xianzhao Chen and Tian Tan and Wei Li and Lu Lu and Zejun MA and Yuxuan Wang and Chao Zhang},
  booktitle={Proc. ICML},
  year={2024},
}

@inproceedings{salmonn,
  title={{SALMONN}: {T}owards Generic Hearing Abilities for Large Language Models},
  author={Changli Tang and Wenyi Yu and Guangzhi Sun and Xianzhao Chen and Tian Tan and Wei Li and Lu Lu and Zejun MA and Chao Zhang},
  booktitle={Proc. ICLR},
  year={2024},
}

@INPROCEEDINGS{tang2024extending,
  author={Tang, Changli and Yu, Wenyi and Sun, Guangzhi and Chen, Xianzhao and Tan, Tian and Li, Wei and Lu, Lu and Ma, Zejun and Zhang, Chao},
  booktitle={Proc. ICASSP}, 
  title={Extending Large Language Models for Speech and Audio Captioning}, 
  year={2024},
}

@article{qwen2vl,
      title={{Qwen2-VL}: {E}nhancing Vision-Language Model's Perception of the World at Any Resolution}, 
      author={Peng Wang and Shuai Bai and Sinan Tan and Shijie Wang and Zhihao Fan and Jinze Bai and Keqin Chen and Xuejing Liu and Jialin Wang and Wenbin Ge and Yang Fan and Kai Dang and Mengfei Du and Xuancheng Ren and Rui Men and Dayiheng Liu and Chang Zhou and Jingren Zhou and Junyang Lin},
      year={2024},
      journal={arXiv:2409.12191},
}

@article{videosalmonn2,
      title={Enhancing Multimodal {LLM} for Detailed and Accurate Video Captioning using Multi-Round Preference Optimization}, 
      author={Changli Tang and Yixuan Li and Yudong Yang and Jimin Zhuang and Guangzhi Sun and Wei Li and Zujun Ma and Chao Zhang},
      year={2024},
      journal={arXiv:2410.06682},
}

@article{dpovideo,
      title={{Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward}}, 
      author={Ruohong Zhang and Liangke Gui and Zhiqing Sun and Yihao Feng and Keyang Xu and Yuanhan Zhang and Di Fu and Chunyuan Li and Alexander Hauptmann and Yonatan Bisk and Yiming Yang},
      year={2024},
  journal={arXiv preprint arXiv:2404.01258},
}

@INPROCEEDINGS{dpo,
  title={{D}irect {P}reference {O}ptimization: {Y}our Language Model is Secretly a Reward Model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  booktitle={Proc. NeurIPS},
  year={2024}
}

@INPROCEEDINGS{treesearch1,
      title={Reasoning with Language Model is Planning with World Model}, 
      author={Shibo Hao and Yi Gu and Haodi Ma and Joshua Jiahua Hong and Zhen Wang and Daisy Zhe Wang and Zhiting Hu},
      year={2023},
      booktitle={Proc. EMNLP},
}

@article{treesearch2,
      title={Scaling {LLM} Test-Time Compute Optimally can be More Effective than Scaling Model Parameters}, 
      author={Charlie Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar},
      year={2024},
      journal={arXiv:2408.03314},
}

@INPROCEEDINGS{treesearch3,
  title={Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training},
  author={Feng, Xidong and Wan, Ziyu and Wen, Muning and Wen, Ying and Zhang, Weinan and Wang, Jun},
  booktitle={Proc. ICML},
  year={2024}
}

@INPROCEEDINGS{treesearch4,
      title={{Tree of Thoughts}: {D}eliberate Problem Solving with Large Language Models}, 
      author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
      year={2023},
      booktitle={Proc. NeurIPS},
}

@INPROCEEDINGS{treesearch5,
      title={Think before you speak: {T}raining Language Models With Pause Tokens}, 
      author={Sachin Goyal and Ziwei Ji and Ankit Singh Rawat and Aditya Krishna Menon and Sanjiv Kumar and Vaishnavh Nagarajan},
      year={2024},
      booktitle={Proc. ICLR},
}

@inproceedings{2021nextqa,
    title={{Next-QA}: {N}ext phase of question-answering to explaining temporal actions},
    author={Xiao, Junbin and Shang, Xindi and Yao, Angela and Chua, Tat-Seng},
    booktitle={Proc. CVPR},
    year={2021}
}

@inproceedings{2023egoschema,
    title={Egoschema: {A} diagnostic benchmark for very long-form video language understanding},
    author={Mangalam, Karttikeya and Akshulakov, Raiymbek and Malik, Jitendra},
    booktitle={Proc. NeurIPS},
    year={2023}
}

@article{2023videobench,
    title={Video-bench: {A} comprehensive benchmark and toolkit for evaluating video-based large language models},
    author={Ning, Munan and Zhu, Bin and Xie, Yujia and Lin, Bin and Cui, Jiaxi and Yuan, Lu and Chen, Dongdong and Yuan, Li},
    journal={arXiv preprint arXiv:2311.16103},
    year={2023}
}


@inproceedings{2024mvbench,
    title={Mvbench: {A} comprehensive multi-modal video understanding benchmark},
    author={Li, Kunchang and Wang, Yali and He, Yinan and Li, Yizhuo and Wang, Yi and Liu, Yi and Wang, Zun and Xu, Jilan and Chen, Guo and Luo, Ping and others},
    booktitle={Proc. CVPR},
    year={2024}
}

@article{2021value,
    title={Value: {A} multi-task benchmark for video-and-language understanding evaluation},
    author={Li, Linjie and Lei, Jie and Gan, Zhe and Yu, Licheng and Chen, Yen-Chun and Pillai, Rohit and Cheng, Yu and Zhou, Luowei and Wang, Xin Eric and Wang, William Yang and others},
    journal={arXiv preprint arXiv:2106.04632},
    year={2021}
}

@article{2023vitatecs,
    title={Vitatecs: {A} diagnostic dataset for temporal concept understanding of video-language models},
    author={Li, Shicheng and Li, Lei and Ren, Shuhuai and Liu, Yuanxin and Liu, Yi and Gao, Rundong and Sun, Xu and Hou, Lu},
    journal={arXiv preprint arXiv:2311.17404},
    year={2023}
}

@article{2024tempcompass,
    title={Tempcompass: {D}o video {LLMs} really understand videos?},
    author={Liu, Yuanxin and Li, Shicheng and Liu, Yi and Wang, Yuxiang and Ren, Shuhuai and Li, Lei and Chen, Sishuo and Sun, Xu and Hou, Lu},
    journal={arXiv preprint arXiv:2403.00476},
    year={2024}
}

@inproceedings{AVSD2019,
    title={Audio Visual Scene-Aware Dialog},
    author={Alamri, Huda and Cartillier, Vincent and Das, Abhishek and Wang, Jue and Cherian, Anoop and Essa, Irfan and Batra, Dhruv and Marks, Tim K. and Hori, Chiori and Anderson, Peter},
    booktitle={Proc. CVPR},
    year={2019}
}

@inproceedings{musicAVQA2022,
    title={Learning to answer questions in dynamic audio-visual scenarios},
    author={Li, Guangyao and Wei, Yake and Tian, Yapeng and Xu, Chenliang and Wen, Ji-Rong and Hu, Di},
    booktitle={Proc. CVPR},
    year={2022}
}

@inproceedings{pano-AVQA2021,
    title={Pano-{AVQA}: {G}rounded audio-visual question answering on 360deg videos},
    author={Yun, Heeseung and Yu, Youngjae and Yang, Wonsuk and Lee, Kangil and Kim, Gunhee},
    booktitle={Proc. ICCV},
    year={2021}
}

@inproceedings{2023vast,
    title={Vast: {A} vision-audio-subtitle-text omni-modality foundation model and dataset},
    author={Chen, Sihan and Li, Handong and Wang, Qunbo and Zhao, Zijia and Sun, Mingzhen and Zhu, Xinxin and Liu, Jing},
    journal={Proc. NeurIPS},
    year={2023}
}

@inproceedings{avqa2022,
    title={{AVQA}: {A} dataset for audio-visual question answering on videos},
    author={Yang, Pinci and Wang, Xin and Duan, Xuguang and Chen, Hong and Hou, Runze and Jin, Cong and Zhu, Wenwu},
    booktitle={Proc. ACM MM},
    year={2022}
}

@article{valor2023,
    title={{VALOR}: {V}ision-Audio-Language Omni-Perception Pretraining Model and Dataset},
    author={Chen, Sihan and He, Xingjian and Guo, Longteng and Zhu, Xinxin and Wang, Weining and Tang, Jinhui and Liu, Jing},
    journal={arXiv preprint arXiv:2304.08345},
    year={2023}
}

@article{2024videomme,
    title={Video-{MME}: {T}he first-ever comprehensive evaluation benchmark of multi-modal {LLMs} in video analysis},
    author={Fu, Chaoyou and Dai, Yuhan and Luo, Yongdong and Li, Lei and Ren, Shuhuai and Zhang, Renrui and Wang, Zihan and Zhou, Chenyu and Shen, Yunhang and Zhang, Mengdan and others},
    journal={arXiv preprint arXiv:2405.21075},
    year={2024}
}

@article{fang2024mmbench,
  title={{MMBench-Video}: {A} Long-Form Multi-Shot Benchmark for Holistic Video Understanding},
  author={Fang, Xinyu and Mao, Kangrui and Duan, Haodong and Zhao, Xiangyu and Li, Yining and Lin, Dahua and Chen, Kai},
  journal={arXiv preprint arXiv:2406.14515},
  year={2024}
}

@article{avhallubench,
  title={{CrossCheckGPT}: {U}niversal Hallucination Ranking for Multimodal Foundation Models},
  author={Sun, Guangzhi and Manakul, Potsawee and Liusie, Adian and Pipatanakul, Kunat and Zhang, Chao and Woodland, Phil and Gales, Mark},
  journal={arXiv preprint arXiv:2405.13684},
  year={2024}
}

@article{gpt4o,
      title={GPT-4o System Card}, 
      author={{OpenAI Team}},
      year={2024},
      journal={arXiv:2410.21276},
}

@inproceedings{
    hu2022lora,
    title={{LoRA}: {L}ow-Rank Adaptation of Large Language Models},
    author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
    booktitle={Proc. ICLR},
    year={2022},
}

@article{llavaonevision,
      title={{LLaVA-OneVision}: {E}asy Visual Task Transfer}, 
      author={Bo Li and Yuanhan Zhang and Dong Guo and Renrui Zhang and Feng Li and Hao Zhang and Kaichen Zhang and Peiyuan Zhang and Yanwei Li and Ziwei Liu and Chunyuan Li},
      year={2024},
      journal={arXiv:2408.03326},
}

@article{mammothvl,
      title={{MAmmoTH-VL}: {E}liciting Multimodal Reasoning with Instruction Tuning at Scale}, 
      author={Jarvis Guo and Tuney Zheng and Yuelin Bai and Bo Li and Yubo Wang and King Zhu and Yizhi Li and Graham Neubig and Wenhu Chen and Xiang Yue},
      year={2024},
      journal={arXiv:2412.05237},
}

@inproceedings{m3av,
      title={{M$^3$AV}: {A} Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset}, 
      author={Zhe Chen and Heyang Liu and Wenyi Yu and Guangzhi Sun and Hongcheng Liu and Ji Wu and Chao Zhang and Yu Wang and Yanfeng Wang},
      year={2024},
      booktitle={Proc. ACL},
}

@inproceedings{smile,
    title = "{SMILE}: {M}ultimodal Dataset for Understanding Laughter in Video with Language Models",
    author = "Hyun, Lee  and
      Sung-Bin, Kim  and
      Han, Seungju  and
      Yu, Youngjae  and
      Oh, Tae-Hyun",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proc. NAACL Findings",
    year = "2024",
}

@article{fun1,
      title={{FunnyNet-W}: {M}ultimodal Learning of Funny Moments in Videos in the Wild}, 
      author={Zhi-Song Liu and Robin Courant and Vicky Kalogeiton},
      year={2024},
      journal={arXiv:2401.04210},
}

@article{fun2,
      title={{FunQA}: {T}owards Surprising Video Comprehension}, 
      author={Binzhu Xie and Sicheng Zhang and Zitang Zhou and Bo Li and Yuanhan Zhang and Jack Hessel and Jingkang Yang and Ziwei Liu},
      year={2024},
      journal={arXiv:2306.14899},
}

@article{hunyuan,
      title={{Hunyuan-Large}: {A}n Open-Source MoE Model with 52 Billion Activated Parameters by Tencent}, 
      author={Xingwu Sun and Yanfeng Chen and Yiqing Huang and others},
      journal={arXiv preprint arXiv:2411.02265},
      year={2024},
}

@article{zhai2023sigmoid,
      title={{S}igmoid Loss for Language Image Pre-Training}, 
      author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
      year={2023},
      journal={arXiv preprint arXiv:2303.15343},
}

@article{hendrycks2016gaussian,
  title={{G}aussian Error Linear Units ({GELU}s)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@inproceedings{radford2023robust,
  title={{Robust Speech Recognition via Large-scale Weak Supervision}},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={Proc. ICML},
  year={2023},
}

@INPROCEEDINGS{panayotov2015librispeech,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Proc. ICASSP}, 
  title={{Librispeech}: {An ASR} corpus based on public domain audio books}, 
  year={2015},
}

@inproceedings{audiocaps,
  title={{AudioCaps}: {G}enerating Captions for Audios in The Wild},
  author={Kim, Chris Dongjoo and Kim, Byeongchang and Lee, Hyunmin and Kim, Gunhee},
  booktitle={Proc. NAACL-HLT},
  year={2019}
}

@article{hallucination1,
      title={Looking for a Needle in a Haystack: {A} Comprehensive Study of Hallucinations in Neural Machine Translation}, 
      author={Nuno M. Guerreiro and Elena Voita and André F. T. Martins},
      year={2023},
      journal={arXiv:2208.05309},
}

@inproceedings{hallucination2,
      title={{SelfCheckGPT}: {Z}ero-Resource Black-Box Hallucination Detection for Generative Large Language Models}, 
      author={Potsawee Manakul and Adian Liusie and Mark J. F. Gales},
      year={2023},
      booktitle={Proc. EMNLP}
}