\section{Related Work}
Our work is related to three strands of prior work:

\paragraph{Policy Learning for Multi-Stage Decision-Making: } 
Policy learning for multi-stage decision-making has been widely explored in healthcare~\cite{moodie2012q,lei2012smart} and personalized medicine~\cite{cain2010start,wahed2004optimal} to optimize treatment strategies over time. This approach has also been applied to dialogue systems~\cite{peng2017composite,zhang2019budgeted}, interactive machine translation~\cite{lam2019interactive,huang2021transmart}, and extractive text summarization~\cite{dong2018banditsum,gu2021memsum}. While these studies offer valuable insights into multi-stage decision-making, they typically deal with discrete actions and do not address scenarios involving high-dimensional text actions.

\paragraph{Reinforcement Learning for a Natural Language Action Space: }
He et al.~\cite{he2015deep} proposed an architecture for handling natural language action spaces in text-based games, using separate neural networks to embed state and action text before combining them to approximate the Q-function. Wang et al.~\cite{wang2024language} introduced a method that dynamically adapts the prior of a pre-trained language model using mutual information regularization to implicitly reduce the action space. Our setting differs from these approaches in that it deals with continuous rather than discrete action spaces, focuses on offline learning, and lacks explicit state transitions.

\paragraph{Causal Inference for Text: } 
Our work also relates to the emerging field of causal inference for language tasks. Veitch et al.~\cite{veitch2020adapting} pioneered the use of language model embeddings and topic modeling to mitigate textual confounding in treatment effect estimation. This approach has been extended by researchers like Egami et al.~\cite{egami2022make}, Pryzant et al.~\cite{pryzant2020causal}, and Imai and Nakamura~\cite{imai2024causal}, who focus on leveraging latent representations of high-dimensional text as confounders or treatments. These studies highlight the importance of extracting low-dimensional latent representations to accurately estimate treatment effects in complex, high-dimensional textual data~\cite{louizos2017causal,kim2021counterfactual,zhang2024causal,wang2021desiderata}.

Our work synthesizes elements from these areas, addressing the challenge of finding optimal treatments in a high-dimensional natural language space to maximize outcomes in sequential decision problems.