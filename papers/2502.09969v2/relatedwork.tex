\section{Related Works}
\label{sec: related works}
\subsection{Data Valuation}
\label{sec: data valuation}
\citet{wei2023largerlanguagemodelsincontext} hint that different models extract different information from the same data. Hence, effective fine-tuning requires datasets to be specific to each model. Not all data points affect the model equally - models learn more from certain data points than others. Therefore, data valuation methods prune out such low-influence data for efficient fine-tuning \citep{less, delift}. Current research is divided into model-independent and model-dependent valuation metrics. 

Model-independent methods, such as distance or clustering-based methods \citep{deftucs, tsds, smart} are faster and less computationally expensive. Distance-based methods assign more "influence" to data points that are further from each other, optimizing for a diverse subset. Clustering-based methods assign more "influence" to data points that are representative (i.e., the centroids of clusters). 

On the other hand, model-dependent methods -- such as inference-based and gradient-based -- are more resource intensive. Inference-based methods \citep{selectit, delift} use model inference signals (e.g., token distributions) to evaluate the performance or confidence of models, and valuate data based on how performative/confident they are. Gradient based methods \citep{less, craig, gradmatch, kohliang}, on the other hand, can assign higher influence to data points with (1) higher magnitudes of gradients, or (2) gradients that match domain-specific data (for domain-specific fine-tuning, for example).

While they are expensive to calculate, when paired with data selection algorithms, model-dependent data valuation metrics can be used to select subsets of data that are specific to a model's capabilities. Model-dependent data valuation metrics help to select data that will maximize a certain objective for each model, rendering fine-tuning more effective. %In this paper, \textit{we aim to reduce the computational costs of using model-dependent data valuation}.


\subsection{Data Selection}
Data selection aims to prune redundant and noisy data samples from large datasets to produce a small, information-rich subset \citep{delift, less}. This subset should be representative of the larger dataset while performing comparably, if not better, than using the full dataset. Data selection methods usually have objectives for selecting data: (1) instruction tuning \citep{selectit}, (2) task-specific fine-tuning \citep{tsds}, (3) continual learning \citep{delift}, (4) preference alignment \citep{deita}, etc. While certain objectives are subsets of others (e.g. (2) is subset of (1)), the data selected for each purpose may not necessarily overlap. For instance, (1) requires data that is representative of a particular dataset, whereas (2) focuses on samples that reflect specific tasks like math reasoning, question answering, or summarization. Similarly, (3)'s samples are specifically chosen to introduce new information to a model without overriding or repeating previously learned information.