\begin{table*}[t]
\centering\scriptsize
\makebox[\linewidth][c]{%
\begin{tabular}{lcccccccccccccc}
\toprule
Dataset                 & \multicolumn{6}{c}{MixInstruct}                                                                                                         & \multicolumn{6}{c}{Alpaca}                                                                                                              \\ \cmidrule(lr){2-7} \cmidrule(lr){8-13} 
Method                & \multicolumn{3}{c}{ICL}                                            & \multicolumn{3}{c}{QLoRA}                                          & \multicolumn{3}{c}{ICL}                                            & \multicolumn{3}{c}{QLoRA}                                          \\ \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13}
Metric                     & ROUGE                & BGE                  & LAJ                  & ROUGE                & BGE                  & LAJ                  & ROUGE                & BGE                  & LAJ                  & ROUGE                & BGE                  & LAJ                  \\ \midrule
Initial                & 37.87  & 78.92  & 2.98   & 36.36  & 82.55  & 3.02  & 25.79 & 67.82  & 2.56  & 27.29  & 71.57  & 2.62       \\
Random                 & 37.91  & 78.96  & 3.06   & 38.89  & 81.88  & 3.05  & 29.95 & 76.35  & 3.12  & 30.27  & 76.21  & 3.15       \\ 
\cmidrule{1-1}
SelectIT               & 35.39  & 78.14  & 3.02    & 37.71  & 78.26  & 3.06 & 30.31 & 74.26  & 3.13  & 37.10  & 77.66  & 3.10       \\
\sysn{} + SelectIT & 35.71  & 78.23  & 3.04    & 37.36  & 78.24  & 3.05 & 31.03 & 75.79  & 3.09  & 36.67  & 77.98  & 3.04       \\ 
\cmidrule{1-1}
LESS                   & 37.61  & 79.55  & 3.07    & 37.43  & 78.93  & 3.09 & 32.57 & 74.07  & 3.02  & 34.61  & 76.68  & 3.08       \\
\sysn{} + LESS & 37.87  & 77.96  & 3.04    & 38.96  & 78.93  & 3.08 & 33.20 & 74.94  & 3.05  & 35.42  & 78.02  & 3.09       \\ 
\cmidrule{1-1}
DELIFT (SE)            & 39.56  & 81.25  & 3.17    & 39.77  & 82.74  & 3.15 & 34.06 & 77.31  & 3.23  & 39.48  & 80.95  & 3.25       \\
\sysn{} + DELIFT (SE) & 39.62  & 81.47  & 3.16    & 39.14  & 82.83  & 3.14 & 33.01 & 76.67  & 3.27  & 38.89  & 80.80  & 3.20       \\ 
\cmidrule{1-1}
DELIFT                 & 45.55  & 82.32  & 3.36    & 43.74  & 82.35  & 3.50 & 35.02 & 77.89  & 3.40  & 39.32  & 80.89  & 3.35       \\
\sysn{} + DELIFT & 46.44  & 82.47  & 3.38    & 43.76  & 82.72  & 3.52 & 34.44 & 77.39  & 3.36  & 38.30  & 80.32  & 3.31       \\ 
\midrule
Full Data              & 58.65  & 88.72  & 3.45    & 65.51  & 92.24  & 3.51 & 35.27 & 77.85  & 3.31  & 39.29  & 78.85  & 3.29       \\
\bottomrule
\end{tabular}
}
\caption{Results on the Llama-8b model with $v=0.2, u=0.05$. \sysn{} + Method and DistilGPT2 + Method follow the same definitions as in Table \ref{table: phi v=0.3}. The average performance difference between \sysn{} and the original influence function is merely 1.08\%.}
\label{table: phi v=0.2}
\end{table*}

\begin{table*}[t]
\centering\scriptsize
\makebox[\linewidth][c]{%
\begin{tabular}{lcccccccccccc}
\toprule
Dataset                 & \multicolumn{6}{c}{MixInstruct}                                                                                                         & \multicolumn{6}{c}{Alpaca}                                                                                                              \\ \cmidrule(lr){2-7} \cmidrule(lr){8-13} 
Method                & \multicolumn{3}{c}{ICL}                                            & \multicolumn{3}{c}{QLoRA}                                          & \multicolumn{3}{c}{ICL}                                            & \multicolumn{3}{c}{QLoRA}                                          \\ \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13}
Metric                     & ROUGE                & BGE                  & LAJ                  & ROUGE                & BGE                  & LAJ                  & ROUGE                & BGE                  & LAJ                  & ROUGE                & BGE                  & LAJ                  \\ \midrule
Initial                & 28.53  & 74.05 & 2.94  & 34.42  & 78.54  & 3.00  & 24.85 & 72.45  & 2.26  & 34.29  & 80.82  & 3.03       \\
Random                 & 39.55  & 82.79 & 3.25  & 39.05  & 82.64  & 3.26  & 31.49 & 76.96  & 3.06  & 41.67  & 79.77  & 3.14       \\
\cmidrule{1-1}
SelectIT               & 39.20  & 82.84 & 3.29  & 40.44 & 82.55   & 3.30  & 35.98 & 81.82  & 2.95  & 42.62  & 83.17  & 3.21       \\
\sysn{} + SelectIT     & 40.02  & 82.63 & 3.23  & 39.92 & 82.22   & 3.29  & 38.84 & 84.09  & 3.03  & 44.62  & 84.63  & 3.23       \\
\cmidrule{1-1}
LESS                   & 40.33  & 82.17 & 3.26  & 40.34  & 82.87  & 3.26  & 36.11 & 79.82  & 3.06  & 43.48  & 82.94  & 3.32       \\
\sysn{} + LESS         & 43.69  & 82.67 & 3.27  & 40.21  & 82.89  & 3.26  & 37.00 & 80.38  & 3.07  & 43.48  & 82.80  & 3.34       \\
\cmidrule{1-1}
DELIFT (SE)            & 44.57  & 82.63 & 3.31  & 45.97  & 83.87  & 3.33  & 38.52 & 82.37  & 3.18  & 45.73  & 83.33  & 3.35       \\
\sysn{} + DELIFT (SE)  & 45.03  & 83.69 & 3.30  & 45.97  & 83.95  & 3.40  & 38.57 & 82.18  & 3.17  & 45.20  & 82.79  & 3.39       \\ 
\cmidrule{1-1}
DELIFT                 & 45.55  & 83.69 & 3.37  & 48.21  & 86.81  & 3.36  & 39.16 & 82.30  & 3.26  & 45.24  & 83.38  & 3.39       \\
\sysn{} + DELIFT       & 46.40  & 84.73 & 3.34  & 47.81  & 86.83  & 3.31  & 40.16 & 82.37  & 3.28  & 45.67  & 83.49  & 3.41       \\
\midrule
Full Data              & 54.43  & 92.55 & 3.40  & 59.47  & 94.12  & 3.58  & 48.53 & 91.21  & 3.63  & 48.29  & 90.82  & 3.66       \\
\bottomrule
\end{tabular}
}
\caption{Results on the Llama-8b model with $v=0.2, u=0.05$. \sysn{} + Method and DistilGPT2 + Method follow the same definitions as in Table \ref{table: phi v=0.3}. The average performance difference between \sysn{} and the original influence function is merely 1.26\%.}
\label{table: llama v=0.2}
\end{table*}