\begin{table}[h!]
\centering\scriptsize
\resizebox{\columnwidth}{!}{
\begin{tabular}{lcccc}
\toprule
Model                  & \multicolumn{2}{c}{Phi-3} & \multicolumn{2}{c}{Llama-8B}  \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5}
Dataset                & MixInstruct & Alpaca & MixInstruct & Alpaca \\ \midrule
Initial                & - & -  & - & - \\
Random                 & 12.4 & 12.3 & 12.9 & 12.3 \\ 
\cmidrule{1-1}
SelectIT               & 7,047 & 6,594 & 6,671 & 6,470 \\
DistilGPT2 + SelectIT  & 144 & 139  & 144  & 139        \\
\sysn{} + SelectIT     & 65 & 63 & 64 & 63 \\ 
\cmidrule{1-1}
LESS                   & 12,338 & 11,217 & 10,843 & 14,819 \\
DistilGPT2 + LESS      & 1,291 & 1,278  & 1,291  & 1,278        \\
\sysn{} + LESS         & 78 & 75 & 74 & 84 \\ 
\cmidrule{1-1}
DELIFT (SE)            & 216 & 218 & 218 & 219 \\
DistilGPT2 + DELIFT(SE)& 98 & 99  & 98  & 99        \\
\sysn{} + DELIFT (SE)  & 48 & 48 & 48 & 48 \\ 
\cmidrule{1-1}
DELIFT                 & 67,379 & 68,117 & 68,076 & 65,711 \\
DistilGPT2 + DELIFT    & 8,058 & 7,790  & 8,058  & 7,790        \\
\sysn{} + DELIFT & 215 & 217 & 217 & 211 \\
\cmidrule{1-1}
Full Data              & - & - & - & -  \\
\bottomrule
\end{tabular}
}
\caption{Costs (in seconds) of data valuation. Following are the specifications on each method. \textbf{Random}: choosing a random subset of points as a subset. \textbf{SelectIT}: calculating the ranking scores for each data point according to Appendix \ref{app: pointwise_influence_functions}. \textbf{LESS}: computing the cosine similarity between pairs of projected gradients for $\mathcal{D_F}$ and $\mathcal{D_T}$, according to Equation \ref{less_influence_function}. \textbf{DELIFT (SE)}: computing the distance between each pair of embeddings $(i, j): i \in \mathcal{D_F}, j \in \mathcal{D_T}$, according to Equation \ref{delift_se_influence_function}. \textbf{DELIFT}: computing the inference-based utility metric for each pair of embeddings $(i, j)$, according to Equation \ref{delift_influence_function}. \textbf{\sysn{}}: Steps 1 and 2 in Figure \ref{fig: nncift}. Note, the costs of DistilGPT2 are the same across both models because they use the same data valuation (Phi-3 or Llama-8B are used for data selection/evaluation).
}
\label{table: actual_costs}
\end{table}


% \begin{table}[]
% \centering\scriptsize
% \makebox[\linewidth][c]{%
% \begin{tabular}{lcccc}
% \toprule
% Model                  & \multicolumn{2}{c}{Phi-3} & \multicolumn{2}{c}{Llama-8B}  \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5}
% Dataset                & MixInstruct & Alpaca & MixInstruct & Alpaca \\ \midrule
% Initial                & - & -  & - & - \\
% Random                 & 12.4 & 12.3 & 12.9 & 12.3 \\ 
% \midrule
% SelectIT               & 7,047 & 6,594 & 6,671 & 6,470 \\
% \sysn{} + SelectIT     & 65 & 63 & 64 & 63 \\ 
% \midrule
% LESS                   & 12,338 & 11,217 & 10,843 & 14,819 \\
% \sysn{} + LESS         & 78 & 75 & 74 & 84 \\ 
% \midrule
% DELIFT (SE)            & 216 & 218 & 218 & 219 \\
% \sysn{} + DELIFT (SE)  & 48 & 48 & 48 & 48 \\ 
% \midrule
% DELIFT                 & 67,379 & 68,117 & 68,076 & 65,711 \\
% \sysn{} + DELIFT & 215 & 217 & 217 & 211 \\
% \midrule
% Full Data              & - & - & - & -  \\
% \bottomrule
% \end{tabular}
% }
% \caption{Costs (in seconds) of data valuation for each method on both models. Following are the specifications on each method's data valuation. \textbf{Random}: choosing a random subset of points as a subset. \textbf{SelectIT}: calculating the ranking scores for each data point according to Section \ref{sec: linear_influence_functions}. \textbf{LESS}: computing the projected gradients for $\mathcal{D_F}$ and $\mathcal{D_T}$ (the cosine similarity matching happens during data selection and is not considered a part of the data valuation stage), according to Equation \ref{less_influence_function}. \textbf{DELIFT (SE)}: computing the distance between each pair of embeddings $(i, j): i \in \mathcal{D_F}, j \in \mathcal{D_T}$, according to Equation \ref{delift_se_influence_function}. \textbf{DELIFT}: computing the inference-based utility metric for each pair of embeddings $(i, j): i \in \mathcal{D_F}, j \in \mathcal{D_T}$, according to Equation \ref{delift_influence_function}. \textbf{\sysn{}}: (1) using the corresponding influence function to collect a small training set for the InfluenceNetwork, (2) training the InfluenceNetwork, and (3) predicting influence values based on the corresponding influence function.
% }
% \label{table: actual_costs}
% \end{table}