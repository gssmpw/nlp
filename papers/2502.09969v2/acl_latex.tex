% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

\usepackage{graphicx} % Required for inserting images
\usepackage{natbib}
% \usepackage{xcolor}
\usepackage[]{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{stfloats}
\usepackage{hyperref}
\usepackage{soul}
% \documentclass{article}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.
\title{Data Valuation using Neural Networks for Efficient Instruction Fine-Tuning}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Ishika Agarwal \\
  UIUC \\
  \texttt{ishikaa2@illinois.edu} \\\And
  Dilek Hakkani-TÃ¼r \\
  UIUC \\
  \texttt{dilek@illinois.edu}\\}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\definecolor{myorange}{RGB}{255, 153, 0}
\definecolor{mygreen}{RGB}{78, 167, 46}
\newcommand{\hlc}[2][yellow]{{%
    \colorlet{foo}{#1}%
    \sethlcolor{foo}\hl{#2}}%
}

\begin{document}
\newcommand{\sysn}{NN-CIFT}
\maketitle
\begin{abstract}
    Influence functions provide crucial insights into model training, but existing methods suffer from large computational costs and limited generalization. Particularly, recent works have proposed various metrics and algorithms to calculate the influence of data using language models, which do not scale well with large models and datasets. This is because of the expensive forward and backward passes required for computation, substantial memory requirements to store large models, and poor generalization of influence estimates to new data. In this paper, we explore the use of small neural networks -- which we refer to as the InfluenceNetwork -- to estimate influence values, achieving up to 99\% cost reduction. Our evaluation demonstrates that influence values can be estimated with models just 0.0027\% the size of full language models (we use 7B and 8B versions). We apply our algorithm of estimating influence values (called \textbf{\sysn{}}: \textbf{N}eural \textbf{N}etworks for effi\textbf{C}ient \textbf{I}nstruction \textbf{F}ine-\textbf{T}uning) to the downstream task of subset selection for general instruction fine-tuning. In our study, we include four state-of-the-art influence functions and show no compromise in performance, despite large speedups, between \sysn{} and the original influence functions. We provide an in-depth hyperparameter analyses of \sysn{}. The code for our method can be found here: \href{https://github.com/agarwalishika/NN-CIFT}{https://github.com/agarwalishika/NN-CIFT}.
\end{abstract}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/nncift_fig.pdf}
    \caption{Overview of \sysn{}. The first step consists of using established influence functions to \hlc[myorange]{collect data} for training the InfluenceNetwork. Next, the data from Step (1) is used to \textbf{train the InfluenceNetwork} and, subsequently, \hlc[mygreen]{estimate the influence values} for the rest of the data. Finally, the data selection algorithm corresponding to the original influence function is used to \textbf{select a subset of IFT data} to fine-tune a model on.}
    \label{fig: nncift}
\end{figure*}

\section{Introduction}
The strong instruction-following abilities of large language models (LLMs) can be attributed to instruction fine-tuning (IFT) \citep{zhang2024instructiontuninglargelanguage}. IFT builds on top of current language modeling capabilities and strengthens the instruction following abilities of models. Recent works have taken \textbf{data efficient} approaches for IFT. The goal is to select a small subset of samples on which to fine-tune a model \cite{delift, craig, deftucs, less, smart, tsds} that emulates the full dataset. 

\begin{table}[]
    \centering
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{lcc}
    \toprule
    Method & Cost & Size \\
    \midrule
    Pairwise \\
    \midrule
        \hspace{1mm} DELIFT \citep{delift} & $\mathcal{O}(MN) \cdot F$ & 7-8B \\
        \hspace{1mm} DELIFT (SE) \citep{delift} & $\mathcal{O}(MN) \cdot F$ & 355M \\
        \hspace{1mm} LESS \citep{less} & $\mathcal{O}(M+N) \cdot B$ & 7-8B \\
        \hspace{1mm} \sysn{} (ours) & $\mathcal{O}(MN) \cdot F$ & 205K \\
    \midrule
    Pointwise \\
    \midrule
        \hspace{1mm} SelectIT \citep{selectit} & $\mathcal{O}(M) \cdot F$ & 7-8B \\
    
        \hspace{1mm} \sysn{} (ours) & $\mathcal{O}(M) \cdot F$ & 205K \\
    \bottomrule
    \end{tabular}
    }
    \caption{Approximate computational complexity of data valuation in previous works measured by the cost of forward passes ($F$) or the cost of backward passes ($B$) through a model. $M$ and $N$ are the cardinality of $\mathcal{D_F}$ and $\mathcal{D_T}$, a fine-tuning and target dataset respectively, we use for subset selection. See Appendix \ref{app: pairwise influence functions} for more details. Size denotes the number of parameters of the corresponding model. Note: larger models have a higher cost for forward and back passes.}
    \label{table: costs}
\end{table}

% \input{tables/costs}

Data efficient pipelines typically consist of two stages: (1) \textit{data valuation}: designing functions to estimate the influence of data points, and (2) \textit{data selection}: using influence estimates to choose a balanced set of influential data. Usually, data selection is cheaper than valuation -- for instance, DELIFT (SE)\footnote{Short for "Sentence Embedding".} \citep{delift} computes the similarity of sentence embeddings between pairs of data (expensive) for valuation and selects representative data using a submodular function (cheap).

Formally, influence functions estimate the value of data. For instance, brute force influence functions use leave-one-out (LOO) training to measure impact by omitting each data point and evaluating performance \cite{loo_1982}. More recent influence functions use LLMs to estimate influence. Table \ref{table: costs} outlines the expenses of state-of-the-art (SOTA) influence functions, which comes from the large amount of forward and backward passes through highly parameterized models.

In this paper, we introduce \textbf{\sysn{}}: \textbf{N}eural \textbf{N}etworks for effi\textbf{C}ient \textbf{I}nstruction \textbf{F}ine-\textbf{T}uning and explore how to train influence functions efficiently. We improve efficiency by using compact neural networks -- which we coin as the InfluenceNetwork -- that are 0.0027\% the size of LLMs, to estimate influence. Figure \ref{fig: nncift} outlines our methodology with a pairwise influence function (more details about pairwise influence functions in Appendix \ref{app: pairwise influence functions}).

As depicted, \sysn{} is a three-step algorithm. The neural network must be trained to estimate influence values effectively. Hence, we first use the influence function (with LLMs) to output influence values for \hlc[myorange]{a very small subset of data}. This becomes our training data for the InfluenceNetwork. We find that a small neural network can sufficiently learn to estimate influence with very few data (covered in Section \ref{sec: learning_influence_estimation}).


Second, we train the InfluenceNetwork, and use it to estimate the influence values \hlc[mygreen]{for the rest of the data points}. Finally, we apply a data selection algorithm on the influence values. This helps to obtain a small subset of IFT data to enhance language models. After fine-tuning language models on the chosen subsets, we find that \sysn{} achieves comparable performance to the original influence functions (covered in Section \ref{sec: subset_selection_evaluation}). 

Our contributions and findings are listed as follows. \sysn{}:
\begin{enumerate}
    \item \textbf{alleviates the cost of using expensive LLMs during data valuation} by using smaller and cheaper neural networks, without affecting the performance on downstream tasks (Tables \ref{table: phi v=0.3} and \ref{table: llama v=0.3});
    \item \textbf{achieves competitive performance to previous data valuation methods, despite using only 0.25\%-5\% of the data.} The average mean square error in influence values between \sysn{} and the original influence functions is merely 0.067 (Figure \ref{fig: influence_net});
    \item is shown to be effective for new data points, \textbf{circumventing the need to retrain an influence function for new data} -- previous works incur this cost (Figure \ref{fig: influence_net}).
    \item \textbf{reduces costs by 77-99\% time} during data valuation (Table \ref{table: actual_costs}).
\end{enumerate}

Section \ref{sec: related works} outlines the current state of research in data valuation and data selection. Section \ref{sec: influence functions} explains the problem setting. Section \ref{sec: learning_influence_estimation} presents the main methodology for \sysn{} and motivating results. Finally, Section \ref{sec: subset_selection_evaluation} reports results on the downstream task of subset selection after the data valuation stage. In our evaluation, we find that using a small LLM with the original influence functions results in degraded performance. Our hyperparameter studies are in Section \ref{subsec: in_size}, Figure \ref{fig: influence_network_size} and Section \ref{subsec: hp_u_v}, Figure \ref{fig: hyperparam_study}. Lastly, the SOTA influence functions are detailed in Appendix \ref{app: influence_functions}.

\section{Related Works}
\label{sec: related works}
\subsection{Data Valuation}
\label{sec: data valuation}
\citet{wei2023largerlanguagemodelsincontext} hint that different models extract different information from the same data. Hence, effective fine-tuning requires datasets to be specific to each model. Not all data points affect the model equally - models learn more from certain data points than others. Therefore, data valuation methods prune out such low-influence data for efficient fine-tuning \citep{less, delift}. Current research is divided into model-independent and model-dependent valuation metrics. 

Model-independent methods, such as distance or clustering-based methods \citep{deftucs, tsds, smart} are faster and less computationally expensive. Distance-based methods assign more "influence" to data points that are further from each other, optimizing for a diverse subset. Clustering-based methods assign more "influence" to data points that are representative (i.e., the centroids of clusters). 

On the other hand, model-dependent methods -- such as inference-based and gradient-based -- are more resource intensive. Inference-based methods \citep{selectit, delift} use model inference signals (e.g., token distributions) to evaluate the performance or confidence of models, and valuate data based on how performative/confident they are. Gradient based methods \citep{less, craig, gradmatch, kohliang}, on the other hand, can assign higher influence to data points with (1) higher magnitudes of gradients, or (2) gradients that match domain-specific data (for domain-specific fine-tuning, for example).

While they are expensive to calculate, when paired with data selection algorithms, model-dependent data valuation metrics can be used to select subsets of data that are specific to a model's capabilities. Model-dependent data valuation metrics help to select data that will maximize a certain objective for each model, rendering fine-tuning more effective. %In this paper, \textit{we aim to reduce the computational costs of using model-dependent data valuation}.


\subsection{Data Selection}
Data selection aims to prune redundant and noisy data samples from large datasets to produce a small, information-rich subset \citep{delift, less}. This subset should be representative of the larger dataset while performing comparably, if not better, than using the full dataset. Data selection methods usually have objectives for selecting data: (1) instruction tuning \citep{selectit}, (2) task-specific fine-tuning \citep{tsds}, (3) continual learning \citep{delift}, (4) preference alignment \citep{deita}, etc. While certain objectives are subsets of others (e.g. (2) is subset of (1)), the data selected for each purpose may not necessarily overlap. For instance, (1) requires data that is representative of a particular dataset, whereas (2) focuses on samples that reflect specific tasks like math reasoning, question answering, or summarization. Similarly, (3)'s samples are specifically chosen to introduce new information to a model without overriding or repeating previously learned information.


\section{Problem Formulation}
\label{sec: influence functions}
Given a model $\mathcal{M}$ and fine-tuning data $\mathcal{D_F}$, the goal is to select a small subset $\mathcal{S_F} \subset \mathcal{D_F}$ that maximizes the performance of $\mathcal{M}$ after fine-tuning $\mathcal{M}$ on $\mathcal{S_F}$. $\mathcal{S_F}$ is the optimal subset if it can be used to train a model that is comparable to a model trained on $\mathcal{D_F}$. However, more recent works jointly optimize other objectives during subset selection. Examples of objectives include not only representation, but also task-specific refinement and continual learning. For such joint optimization, the subset $\mathcal{S_F}$ is aligned with another target domain dataset $\mathcal{D_T}$. The choice of $\mathcal{D_T}$ can guide the subset selection towards various objectives.
For example, if the objective is representation or task-specific refinement, $\mathcal{S_F}$ will contain points from $\mathcal{D_F}$ that are similar to $\mathcal{D_T}$ \citep{tsds, less, deftucs}. Alternatively, if the objective is continual learning, $\mathcal{S_F}$ will contain points from $\mathcal{D_F}$ that would allow the model $\mathcal{M}$ to learn new information that is present in $\mathcal{D_T}$ \cite{delift, gcr}.

As mentioned before, computing influence functions can be a very expensive process. There are two kinds of influence functions: pairwise and pointwise -- both require forward/backward passes through language models, but the costs slightly differ. Pairwise influence functions compute the influence between every pair of points in a dataset. We study three SOTA pairwise functions, whose formulations are details in Appendix \ref{app: pairwise influence functions}. This paper also studies one pointwise influence functions that simply compute the influence of each data point individually, formally outlined in Appendix \ref{app: pointwise_influence_functions}. While pointwise influence functions are more efficient than pairwise, they are not as performant during subset selection \cite{less, delift}.

% We study three SOTA works that design pairwise metrics. Given a pair of points $(i_x,i_y)$ from $\mathcal{D_F}$ and $(j_x,j_y)$ from $\mathcal{D_T}$, these works compute a similarity value between each pair of points. The formulations are detailed in Appendix \ref{app: pairwise influence functions}. We also study one SOTA pointwise metric, which computes a score for each $(i_x,i_y) \in \mathcal{D_F}$. This is formally outlined in Appendix \ref{app: pointwise_influence_functions}.

\subsection{Our motivation}
Overall, our aim is to reduce the total number of forward or back propagations through models with millions and billions of parameters by replacing a large portion with forward propagations through small neural networks with (merely) hundreds of thousands of parameters. Pairwise influence functions calculate the similarity between two data points (denoted as $sim(i, j)$). Because influence values are usually not learned, they need to be recomputed for any data beyond the training data. In other words, as data is constantly being collected, influence values for new data must be recomputed. However, \sysn{} is learned. Hence, \textit{our method does not require any extra computation to estimate influence values}, unlike previous work.

\begin{figure*}[]
    \centering
    \includegraphics[width=\linewidth]{figures/ICL_InfluenceNetwork.png}
    % \includegraphics[width=0.49\linewidth]{figures/se_influencenet_mixinstruct.png}
    \caption{MSE versus InfluenceNetwork training data size (u) plotted for 8 different training sizes, broken down by the quadrant. These results are for learning DELIFT influence values. Error rates on each quadrant correspond to losses across different sets: Q1 for training, Q2/Q3 for validation, and Q4 for testing. As shown, the InfluenceNetwork achieves MSE of merely 0.05\% starting from $u=0.05$ and always outperforms the baselines.}
    \label{fig: influence_net}
\end{figure*}

\begin{figure*}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/influencenet_sizes.png}
    \caption{MSE versus InfluenceNetwork sizes (measured by the number of parameters). We try 1-5 layers with 46 different combinations of hidden layer sizes from \{5, 10, 20, 50, 100, 200, 500, 1000, 2000, 3000, 4000, 5000\}.}
    \label{fig: influence_network_size}
\end{figure*}

\section{Learning Influence Estimation}
\label{sec: learning_influence_estimation}
This section describes in detail Steps 1 and 2 in Figure \ref{fig: nncift}. It outlines the structure and initial experimentation of the InfluenceNetwork.

\subsection{Defining the InfluenceNetwork.} 
For estimating the influence values of data samples, we call our neural network the \textit{InfluenceNetwork}. It is a 2-layer neural network with a hidden size of 100 neurons, and an output size of 1 neuron. For activation, we use ReLU in between the layers. The function $IN_\theta$ represents the neural network with parameters $\theta$. As input, $IN_\theta$ takes two data points $i$ and $j$ and outputs the estimated influence of $i$ on $j$. Specifically, embeddings for $i$ and $j$ are computed (denoted as \texttt{emb}() below) using the BAAI General Embedding model (\texttt{bge-large-en-v1.5}, in particular) \citep{bge_embedding} and are concatenated:

\begin{align*}
0 \leq IN_\theta(i, j)&\leq 1, \\
0 \leq \theta(\texttt{concat}(\texttt{emb}(i), \texttt{emb}(j)))&\leq 1, \\
\forall (i, j) \in \mathcal{D_F} \times \mathcal{D_T}
\end{align*}

\noindent The \texttt{bge-large-en-v1.5} model generates embeddings of size 1,024, which means the input has a total length of 2,048. Hence, the InfluenceNetwork has exactly 204,900 parameters. For training, we use 20 epochs and a learning rate $\eta = 0.0001$.


\subsection{Training the InfluenceNetwork.}
Below is an illustration of the quadratic similarity matrix that is computed during the data valuation stages. Previous influence compute the entire matrix for data valuation -- we only use Q1.
\begin{center}
    \scalebox{0.7}{ % Adjust this scaling factor as needed
    \begin{tikzpicture}
    \draw[step=1cm,color=gray] (-1,-1) grid (1,1);
    \node at (-0.5,+0.5) {Q1};
    \node at (+0.5,+0.5) {Q2};
    \node at (-0.5,-0.5) {Q3};
    \node at (+0.5,-0.5) {Q4};
    \draw[-latex] (-1.5,-1.5)--(-1.5,1.5) node[pos=1.1]{$\mathcal{D_F}$};
    \draw[-latex] (-1.5,-1.5)--(1.5,-1.5) node[pos=1.1]{$\mathcal{D_T}$};
    \end{tikzpicture}
    }
\end{center}


Using the predefined influence functions in Appendix \ref{app: influence_functions}, a small fraction of influence values are computed -- we call this fraction $u$. We use $u$\% of data from $\mathcal{D_F}$ and $u$\% of data from $\mathcal{D_T}$ to compute the training set for the InfluenceNetwork. As mentioned above, this training set is represented by Q1 in the illustration.

The quadrants Q1 to Q4 represent the subset of influence values between a combination of in-distribution (ID) data and out-of-distribution (OOD) data. ID and OOD data is determined by whether the InfluenceNetwork was trained on the data (ID) or not (OOD):
\begin{itemize}
    \item Q1: Fully ID data from $\mathcal{D_F}$ and $\mathcal{D_T}$
    \item Q2: ID data from $\mathcal{D_F}$ and OOD data from $\mathcal{D_T}$ 
    \item Q3: OOD data from $\mathcal{D_F}$ and ID data from $\mathcal{D_T}$
    \item Q4: Fully OOD data from $\mathcal{D_F}$ and $\mathcal{D_T}$
\end{itemize}


\subsection{Evaluating the InfluenceNetwork.}
To ensure our InfluenceNetwork is able to output influence values correctly, we compute the average mean squared error (MSE) between the ground truth influence values (from Appendix \ref{app: influence_functions}) and the predicted influence values:

\begin{align*}
\frac{1}{|\mathcal{D_F} \times \mathcal{D_T}|} \sum_{(i, j) \in \mathcal{D_F} \times \mathcal{D_T}} (IF_\theta(i, j) - \text{sim}(i, j)) ^ 2
\end{align*}

\noindent We separate the evaluation between the four quadrants of data to study the performance with ID and OOD data.

To train the InfluenceNetwork, we use DELIFT's influence values on the MixInstruct dataset \citep{mixinstruct} to train our InfluenceNetwork (more dataset details in Section \ref{sec: subset_selection_evaluation}). We report the results from \textit{InfluenceNetwork} and two other baselines: (1) \textit{Random}ly generating a number between 0 and 1, and (2) only \textit{Predicting 0} influence. These results can be found in Figure \ref{fig: influence_net}.

The InfluenceNetwork is able to predict influence values with low error rates. After just $u=0.05$, it is consistently better than random influence values and predicting only 0. The average MSE between the InfluenceNetwork's influence scores and DELIFT's influence scores is 0.072, 0.072, 0.062, 0.063 for Q1 to Q4, respectively (averaging to 0.067). Furthermore, \textbf{the error rate stays consistent across all four quadrants, showing that \sysn{} does not need to be retrained to estimate the influence of new data points} that are collected after the training data. One thing to note is that \textit{although $u=0.05$, with pairwise influence functions, we end up using only 0.25\% of the data} to train the InfluenceNetwork because we use 5\% of $\mathcal{D_F}$ and 5\% of $\mathcal{D_T}$. 


\subsection{Hyperparameter Study \#1: InfluenceNetwork sizes}
\label{subsec: in_size}
We vary the number of layers and dimensions of each layer. For simplicity, we plot the number of parameters in the InfluenceNetwork versus the MSE. The results can be found in Figure \ref{fig: influence_network_size}. This figure shows that small InfluenceNetwork's perform comparatively well as larger InfluenceNetwork's. 

\input{tables/thirty}
\section{Subset Selection Evaluation}
\label{sec: subset_selection_evaluation}
Motivated by the results in Figure \ref{fig: influence_net}, we apply the InfluenceNetwork to the downstream task of subset selection: \textit{can we achieve the same performance when using the InfluenceNetwork instead of the original influence function}? Thus, this section corresponds to Step 3 in Figure \ref{fig: nncift}.

\paragraph{Datasets and models.} We use MixInstruct as well as Alpaca \citep{alpaca} to evaluate \sysn{}. These are both instruction tuning datasets where we use 15k for training, 5k for validation, and 5k for testing. We evaluate using two models: \texttt{microsoft/Phi-3-small-8k-instruct} \citep{phi3} and \texttt{meta-llama/Llama-3.1-8B} \citep{grattafiori2024llama3herdmodels}. Note: we use Phi-3 and Llama-8B as shorthand for these models, respectively. Phi-3 has 7.39B parameters and LLama-8B has 8.03B parameters.

\paragraph{Metrics.} To evaluate the instruction following capabilities of our fine-tuned model $\mathcal{M}'$, we employ a variety of metrics to capture the similarity between ground truth answers and predicted answers from $\mathcal{M}'$: (1) ROUGE \citep{rouge}: $n$-gram word overlap (specifically, rouge-1), (2) BGE: semantic similarity of embeddings using \texttt{bge-large-en-v1.5}, and (3) LAJ: an LLM-as-a-Judge, namely the \texttt{prometheus-7b-v2.0} model \citep{prometheus}. Prometheus' grading rubric is borrowed from \citet{delift} in Appendix B. Next, to evaluate the costs of each method, we use time (in seconds) took on 2 Nvidia A40 GPUs.

\paragraph{Baselines.} Besides the influence functions DELIFT, DELIFT (SE), LESS, and SelectIT, we include three other baselines: Initial, DistilGPT2, and Full Data. \textit{Initial} is the setting where $v=0.0$. This is the base model's performance on the dataset. Next, we use a small language model \textit{DistilGPT2} (\texttt{distilbert/distilgpt2}) \citep{distilgpt2} which has 88.2M parameters as the underlying language/embedding model in the influence functions. Finally, \textit{Full Data} is the setting where $v=1.0$, i.e., the model's performance when the full dataset is used.

\paragraph{Setup.}
We use $u=0.05$ for training the InfluenceNetwork. We also use a small fraction of $\mathcal{D_F}$ to fine-tune the language model -- we call this fraction $v$. We evaluate with $v=0.3$. Our evaluation framework includes two different settings to fine-tune the language model: using the selected subset of data points as (1) PEFT data for QLoRA \citep{qlora} on $\mathcal{M}$, or (2) in-context learning (ICL) examples. To elaborate on the ICL set up, we choose the top-5 most semantically similar samples from the chosen subset to add in-context. To measure semantic similarity, we again use \texttt{bge-large-en-v1.5}. Table \ref{table: phi v=0.3} reports results for Phi-3 on both datasets with $v=0.3$; Table \ref{table: llama v=0.3} reports results for Llama-8B on both datasets with $v=0.3$; Table \ref{table: actual_costs} reports the cost in time for each method. All tables report the results for one run.

\input{tables/costs}

\subsection{Analysis}
Table \ref{table: actual_costs} reports the costs for each method, in seconds. It shows that \textbf{data valuation can be performed at 77-99\% faster} than the original influence functions. This is because the number of parameters in \sysn{} is 0.0026-0.0029\% the size of the language model in the original influence function. Also, when using the DistilGPT2 model, which is near 1\% the size of the language model, the costs are reduced by 54-91\%. While these results are promising, the results on the downstream task of subset selection clearly differentiate \sysn{} and the DistilGPT2 baseline. To elaborate, \textbf{despite the significant speedups, \sysn{} shows no compromise to performance}. Table \ref{table: phi v=0.3} reports the results for Phi-3 and Table \ref{table: llama v=0.3} reports the results for Llama-8B for $v=0.3$.

To begin, the pairwise functions outperform the pointwise function (SelectIT) because they are able to capture more fine-grained effects of the data point on a model's learning. Next, DELIFT and DELIFT (SE) are able to outperform LESS because the theoretical guarantees of using submodular functions yields improved empirical performance. Finally, DELIFT uses model dependent information, tailoring the subset to the model's weaknesses, allowing it to outperform DELIFT (SE).

Keeping these in mind, \textbf{\sysn{} is able to achieve performance comparable to the original data valuation methods, even across models and datasets}. However, DistilGPT2 shows performance degradations, which is more pronounced in the model-dependent methods (DELIFT, LESS, and SelectIT). This is because the model-dependent methods experience significant performance gains when the data valuation model is the same as the fine-tuning model. 

The absolute average performance difference across metrics between the original influence functions and \sysn{} is only 1.40\%\footnote{The average performance difference is calculated by taking the absolute difference in performance, dividing it by the original performance, and then averaging this ratio across all settings (datasets, methods, metrics, baselines).}. Because the neural network is able to estimate the influence values with great accuracy, the selected subsets of data would be mostly the same between the original influence function and \sysn{}. Hence, the performance difference of 1.40\% can be attributed as the variability in the language model's performance between two runs. Additionally, this trend is consistent across datasets and models, which shows the wide applicability of our method.

% We also conduct a detailed hyperparameter study between various values of $u$ and $v$ in Appendix \ref{app: hyperparameter_study} and InfluenceNetwork sizes in Appendix \ref{app: hyperparameter_study_in_size}. Finally, we report results for smaller values of $v$ in Appendix \ref{app: smaller_subset_eval} and find similar trends, albeit subpar performance compared to $v=0.3$.


\begin{figure*}[th]
    \centering
    \includegraphics[width=0.4\linewidth]{figures/icl_delift.png}
    \includegraphics[width=0.4\linewidth]{figures/icl_nn.png}
    \includegraphics[width=0.4\linewidth]{figures/peft_delift.png}
    \includegraphics[width=0.4\linewidth]{figures/peft_nn.png}
    \caption{Hyperparameter study for $u$ and $v$ on MixInstruct with DELIFT's influence function. Lighter colors indicate better BGE performance.}
    \label{fig: hyperparam_study}
\end{figure*}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.95\linewidth]{figures/icl_delift.png}
%     \includegraphics[width=0.95\linewidth]{figures/icl_nn.png}
%     \includegraphics[width=0.95\linewidth]{figures/peft_delift.png}
%     \includegraphics[width=0.95\linewidth]{figures/peft_nn.png}
%     \caption{Hyperparameter study for $u$ and $v$ on MixInstruct with DELIFT's influence function. Lighter colors indicate better BGE performance.}
%     \label{fig: hyperparam_study}
% \end{figure}

\subsection{Hyperparameter study \#2: Trade-off between $u$ and $v$}
\label{subsec: hp_u_v}
We perform a hyperparameter study between $u$ and $v$ on MixInstruct using DELIFT's influence function (Equation \ref{delift_influence_function}). We perform a grid search where $u = v = \{0, 0.01, 0.05, \allowbreak 0.1, 0.15, 0.20, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8\}$, amounting to 169 experiments. Figure \ref{fig: hyperparam_study} shows the results using the BGE metric from each of these experiments. As shown, the two figures in each row follow the same general trend, showcasing that \textbf{\sysn{} can effectively replace the expensive influence function estimation}. %Moreover, the lighter colors at the bottom left (lighter colors indicate better performance) demonstrate that \textbf{\sysn{} does not require a significant amount of training data to be accurate}.

As expected, we notice a few trends. (1) QLoRA generally has better performance than ICL. This is because fine-tuning has more impact on the model than simply adding examples to the prompt (i.e., prompt engineering). (2) The bottom right tends to be darker as fewer IFT data lead to insufficient training. (3) Larger IFT subsets, especially in the ICL setting, lead to poorer performance. During ICL, the top-5 semantically similar samples are chosen from the subset to add as in-context examples. However, semantic similarity does not always translate to performance enhancement as these samples can be harmful to the model's performance. Finally, a follow-up to (3), the highest performance regions tend to be around $v=0.2$ - $0.4$. Appendix \ref{app: smaller_subset_eval} contains results on smaller subsets of IFT data ($v=0.1$ and $0.2$).

\section{Conclusion}
In this paper, we introduce \sysn{}: \textbf{N}eural \textbf{N}etworks for effi\textbf{C}ient \textbf{I}nstruction \textbf{F}ine-\textbf{T}uning to distill highly parameterized models used in modern influence functions into small neural networks. We empirically show the effectiveness of our InfluenceNetwork design through low prediction error rates, and competitive performance on the downstream task of subset selection for IFT. We use four different influence functions to test with \sysn{}; our experimentation shows that \sysn{} can lower costs for expensive data valuation, is adaptive to all kinds of influence functions (model-dependent or -independent; pairwise or pointwise), and does not require retraining for new data.

\section{Limitations}
While \sysn{} is effective, it is heavily dependent on the influence function. The influence functions that were studied require large datasets to be annotated, which can be infeasible. Furthermore, \sysn{} cannot yet be used for areas such as task-specific dataset selection or continual learning. In these cases, the objectives of data selection are beyond representation. Finally, even though costs were shown to be much smaller, \sysn{} still incurs a quadratic cost. Although we show results for SelectIT, which runs in linear time, SelectIT is not able to outperform the pairwise methods. Future work will involve finding a solution that can estimate influence of a data \textit{point} to a data \textit{set} (or a \textit{model's} training dynamics) while also incurring linear time cost.


\bibliography{acl_latex}

\appendix

\section{Evaluation on smaller subsets}
\label{app: smaller_subset_eval}
Tables \ref{table: phi v=0.1} and \ref{table: phi v=0.2} report extra results for the Phi-3 model on $v=0.1$ and $v=0.2$, respectively. Similarly, Tables \ref{table: llama v=0.1} and \ref{table: llama v=0.2} report results for Llama-8B on $v=0.1$ and $v=0.2$, respectively. With Tables \ref{table: phi v=0.3} and \ref{table: llama v=0.3} in the main text, these results show an increasing trend in performance with a higher subset of IFT data (i.e., higher $v$). They also show similar trends where \sysn{} performs similarly to the original influence function.

\input{tables/ten}
\input{tables/twenty}

\section{Influence Functions}
\label{app: influence_functions}
Following the problem formulation, we formally define the influence functions we used throughout our evaluation.

\subsection{Pairwise Influence Functions}
\label{app: pairwise influence functions}

\paragraph{DELIFT} \citep{delift} is a model-dependent, inference-based metric. Samples $(i_x,i_y) \in \mathcal{D_F}$ are used as in-context examples for evaluating $(j_x,j_y) \in \mathcal{D_T}$, and those with improved model performance are chosen to represent $\mathcal{D_T}$. This can be calculated by comparing the performance with and without $(i_x,i_y)$ as an in-context example (where $D(\cdot, \cdot) \in [0,1]$ is a function to measure distance between two probability distributions, and $f(q | \theta)$ is a language model with parameters $\theta$ and input query $q$):

\begin{equation}
\text{sim}(i, j) = D(j_y,f(i_x,i_y,j_x | \theta)) - D(j_y,f(j_x | \theta))
\label{delift_influence_function}
\end{equation}

\noindent After data valuation, the data selection stage consists of using submodular functions \citep{bilmes_submodularity}. In particular, we use the Facility Location submodular function. It takes as input a similarity kernel that will optimize the maximum similarity between the chosen subset and the overall dataset while also minimizing the size of the chosen subset. To minimize the subset size, the Facility Location -- and submodular functions, in general -- employ a diminishing gains property. This property states that samples added to a smaller subset have more value than samples added to a larger subset. Hence, we rely on our influence function to capture the informativeness of samples, and submodular functions to choose a set of representative samples, resulting in a small, information-rich subset on which to fine-tune a model.

\paragraph{DELIFT (SE)} \citep{delift} is a model-independent metric, and chooses samples from $\mathcal{D_F}$ which are semantically closest to the samples from $\mathcal{D_T}$. Semantic distance is calculated by the cosine distance between embeddings of samples:

\begin{equation}
\text{sim}(i, j) = \frac{<\text{emb}((i_x, i_y)), \text{emb}((j_x, j_y))>}{||\text{emb}((i_x, i_y))|| \cdot||\text{emb}((j_x, j_y))||}
\label{delift_se_influence_function}
\end{equation}

\noindent, where $\text{emb}(q)$ is an embedding model with input data $q$. Similar to DELIFT, DELIFT (SE) also uses the Facility Location function to select a small, information-rich subset of samples.

\paragraph{LESS} \citep{less} is model-dependent, gradient-based metric. Here, gradients between samples in $\mathcal{D_F}$ and $\mathcal{D_T}$ are matched by cosine similarity, and those that match the highest are chosen to represent $\mathcal{D_T}$ (where $\nabla(q; \theta)$ is the gradient of data point $q$ from a model with parameters $\theta$):

\begin{equation}
\text{sim}(i, j) = \frac{<\nabla((i_x, i_y); \theta), \nabla((j_x, j_y); \theta)>}{||\nabla((i_x, i_y); \theta)|| \cdot||\nabla((j_x, j_y); \theta)||}
\label{less_influence_function}
\end{equation}

\noindent During the data selection stage, the top-$k$ matching gradients are chosen to be part of the subset. One thing to notice is that the above equation implies a quadratic computation while Table \ref{table: costs} in the main text denotes a linear computation -- this is because the gradients for each data point only need to be computed once, while the cosine similarity can be computed many times inexpensively.

\subsection{Pointwise Influence Functions}
\label{app: pointwise_influence_functions}
Finally, \textbf{SelectIT} \cite{selectit} is another model-dependent metric that uses performance signals for data valuation, but incurs linear cost as it uses a model's uncertainty to rank data samples. Still, as mentioned in Table \ref{table: costs} from the main text, the linear time operations are forward propagations through LLMs.

SelectIT ranks data points based on their token-level, sentence-level, and model-level uncertainty expressed via token distribution. The token-level uncertainty is represented as the maximum probability of a token during next-token prediction. The sentence-level uncertainty is computed based on the token-level uncertainties of all the tokens in a sentence, for each prompt in a pool of prompts. Finally, the model-level uncertainty is calculated by taking a weighted average of the sentence-level uncertainty scores for multiple model sizes (the weights are determined by model size). This three-stage process provides a ranking process -- thus, during data selection, the points with the top-$k$ scores are chosen.

\section{License}
All the code of this project is under the Apache 2.0 License. The datasets MixInstruct and Alpaca are under the MIT and Creative Commons Attribution Non Commercial 4.0 International Licenses, respectively. The code for the baselines are under the MIT and Apache 2.0 Licenses. Our use of existing artifact(s) is consistent with their intended use. The artifacts are all in English, and do not contain data with personally identifiable information.


\end{document}
