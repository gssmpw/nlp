\section{Related Work}
% \label{rw_section}
% \updatedText{The application of deep learning techniques for brain age estimation using MRI has seen significant advancements in recent years. In particular, Convolutional Neural Networks (CNNs) have emerged as the primary architecture for estimating brain age from structural MRI (sMRI) data, offering the ability to learn complex image features directly from the data. Early works in this domain employed 2D CNNs applied to individual slices of sMRI scans \cite{feng2020estimating}, while more recent studies have adopted 3D CNNs, which analyze the entire brain to capture more comprehensive structural features for brain age prediction \cite{he2021multi}. Dinsdale et al. \cite{dinsdale2021learning} introduced a 3D CNN model that leveraged whole-brain MRI data, demonstrating improved accuracy by capturing global structural features related to brain aging.}

% \updatedText{However, training deep learning models on small datasets remains a significant challenge. To address this, Peng et al. \cite{peng2021accurate} proposed a 3D fully convolutional network that reduces model complexity by using fewer parameters, thereby improving efficiency without compromising prediction accuracy. Cheng et al. \cite{cheng2021brain} further improved performance by introducing a two-stage age prediction network (TSAN), which first provides a rough estimation followed by a refinement stage. This multi-stage approach allows the model to progressively enhance its representations of brain aging.}

% \updatedText{In addition to CNN-based architectures, the incorporation of attention mechanisms has shown promise in improving brain age prediction. He et al. \cite{he2021multi} introduced FiA-Net, a fusion-with-attention model that integrates both intensity and RAVENS channels from sMRI data. The attention mechanism enabled the model to focus on the most informative regions, thereby improving its predictive performance. Later, He et al. \cite{he2022global} proposed a global-local transformer model, which combines global contextual information with fine-grained local features extracted from patches of sMRI data. This approach employs self-attention mechanisms to enhance the representation of brain aging patterns by dynamically adjusting attention to both global and local aspects of the data.}

% \updatedText{Beyond CNNs and attention-based methods, graph neural networks (GNNs) have also been explored for brain age estimation, primarily due to their ability to model the brain as a network of regions of interest (ROIs). Pina et al. \cite{pina2022structural} proposed a GNN-based model that represents the brain as a graph, where ROIs are treated as nodes, and the dependencies between regions are modeled as edges. This structural representation allows for the prediction of brain age by capturing the interdependencies between different brain regions. Similarly, Xu et al. \cite{xu2021brain} used a graph-based model on diffusion tensor imaging (DTI) data to study the structural connectivity of brain aging, showing the potential of graph models in capturing complex relationships between brain regions.}

% \updatedText{The integration of multimodal MRI data has emerged as a promising approach to enhance the accuracy of brain age estimation. Structural MRI (sMRI) and functional MRI (fMRI) provide complementary information, where sMRI captures structural features, and fMRI offers insights into functional connectivity. Early studies, such as those by Irimia et al. \cite{irimia2015statistical}, combined cortical thickness from sMRI with structural connectivity features to predict brain age using multivariate regression. Liem et al. \cite{liem2017predicting} proposed a stacked multimodal approach that integrates cortical anatomy from sMRI with functional connectivity derived from resting-state fMRI, demonstrating improved brain age prediction performance. Cherubini et al. \cite{cherubini2016importance} further investigated the fusion of T1-weighted MRI, T2-relaxometry, and fMRI using a voxel-based multiple regression model, highlighting the potential of multimodal data in capturing brain aging patterns. }

% \updatedText{Building upon these foundational approaches, Cole et al. \cite{cole2020multimodality} developed a more comprehensive multimodal brain age model by integrating various MRI modalities, including T1-weighted MRI, T2-FLAIR, T2*, and diffusion MRI, along with resting-state fMRI. Although this approach demonstrated promising results, it relied on hand-crafted features and complex preprocessing steps, which limited its adaptability to new datasets. More recently, Mouches et al. \cite{mouches2022multimodal} proposed a fusion model combining sMRI with time-of-flight magnetic resonance angiography (TOF MRA) data using a simple fully convolutional network (SFCN) alongside linear regression (LR), thus simplifying the integration process while maintaining robust performance.}

% Though recent advancements, traditional multimodal approaches often rely on simply concatenating features from different modalities without explicitly modeling their interactions. This limitation can overlook the potential synergies between sMRI and fMRI data that could enhance prediction accuracy. To address this, He et al. \cite{he2022global} proposed a global-local transformer model that combines global and local features through an attention mechanism, significantly improving performance. Similarly, Armanious et al. \cite{armanious2021age} incorporated both chronological and biological age information into CNN-based models, enhancing brain age prediction. Liu et al. \cite{liu2023risk} further highlighted the importance of demographic factors, such as gender, in brain age prediction, using a support vector regression (SVR) approach. Dular et al. \cite{dular2024base} extended brain age estimation to multisite data, achieving an MAE of 3.25 Â± 2.70 years, demonstrating the value of large-scale, heterogeneous datasets in improving prediction accuracy. Additionally, the concept of disentangled representation learning has gained attention, with Cai et al. \cite{cai2023graph} employing a two-stream convolutional autoencoder to disentangle modality-specific features, improving upon traditional autoencoder designs. A concise summary of the existing literature is provided in Table \ref{litrature_tab}, highlighting key methodologies such as modality integration, sex-aware modeling, adversarial learning, and disentangled autoencoders. Studies utilizing attention-based and transformer networks for improved segmentation, particularly in challenging modalities, have shown promise in advancing model-based approaches \cite{farooq2023residual, kanwal2023mask, usman2024intelligent,usman2023mesaha, usman2024meds, rehman2023selective, iqbal2023ldmres, usman2023deha, usman2022dual, ullah2023ssmd, latif2018automating, lee2021evaluation, latif2018mobile, ullah2023mtss, ullah2023densely, usman2017using, ullah2022cascade, usman2020retrospective, usman2020volumetric, latif2018cross, latif2018phonocardiographic, latif2020leveraging,farooq2024lssf,naveed2024ad,iqbal2025tbconvl,iqbal2024tesl, usman2019motion,usman2022meds} \cite{naveed2024ra}. Autoencoders (AE) have been widely explored for multimodal fusion, with early and late fusion \cite{bib_20, farooq2023dc}. However, traditional AEs often struggle to differentiate between shared and complementary information, and noisy modalities can negatively impact latent representation learning across modalities.

% \begin{figure*}[t]
% \centering
% \includegraphics[width=1\textwidth]{images/SA_AVAE.png}
% \caption{\updatedText{Architecture of the proposed Multimodal Sex-Aware Adversarial Variational Autoencoder (SA-AVAE) for predicting biological brain age, utilizing sMRI as a compulsory modality and fMRI as an optional input to enhance prediction performance.}}
% \label{proposed_architecture}
% \end{figure*}

% Despite recent advancements, current approaches to brain age estimation still face significant challenges, particularly in fully exploiting the interactions between multimodal data and accounting for sex-specific aging patterns \cite{usman2024advancing}. To address these issues, the proposed framework in this paper integrates sMRI and fMRI data while incorporating sex-specific information into the latent space, capturing both modality-specific and shared features through disentangled representations. Our framework, the Sex-Aware Adversarial Variational Autoencoder (SA-AVAE), not only improves predictive accuracy but also enhances model interpretability by explicitly considering demographic factors such as sex. The key contributions of our work include: 1) the introduction of a novel framework that integrates sMRI and fMRI data with sex information to improve accuracy and robustness; 2) the use of disentangled latent representations, achieved by applying adversarial and variational autoencoder losses to ensure effective separation of modality-specific and shared features; 3) a new loss weighting strategy for fine-tuning model parameters, providing insights into optimizing architectures for broader applications; and 4) extensive evaluation showing that our framework outperforms state-of-the-art methods, establishing a new benchmark for brain age estimation. This work paves the way for more effective, interpretable models in neuroimaging and brain health assessment, emphasizing the importance of integrating multimodal data, disentangled representations, and demographic factors to improve both prediction accuracy and clinical applicability.

%