\section{Related work}
Early studies in human factors analyze SA based on human feedback after trials \cite{stanton2017state}, e.g. using the Situation Awareness Global Assessment Technique (SAGAT) \cite{endsley1988situation} or the Situational Awareness Rating Technique (SART) \cite{taylor2017situational}. Endsley and Mica R. proposed a three-level SA model, which is widely accepted \cite{endsley1995measurement}. SA is a subjective concept based on objective reflections of the environment, meaning everyone may understand the situation differently. Thus, building a generalized framework to regulate understanding is essential. A subjective scoring or weighting system that delivers subjective understanding is commonly used to differentiate each situation. For instance, the authors in \cite{hooey2011modeling}, build up a heuristic scoring system and give weights to different "situational elements" to model the SA obtained from aircraft pilots. \cite{mcaree2018quantifying} gives examples of formalizing some specific awareness, e.g. position and air environment (consisting of air traffic, airspace restrictions, and weather) using a scoring system. 

These works show how humans obtain SA. Elements of such approaches can be generalized to robot SA. Some researchers discuss human SA and robot SA combined or view the problem from a global perspective in an HRI context \cite{dini2017measurement}. 
Other researchers employ ontology to obtain the SA. Ontology concerns what kinds of things exist, how they can be organized, and what relationships exist between them \cite{huang2019ontology,tenorth2017representations}. \cite{armand2014ontology} models simple situations on the road and crossroads using ontology. Authors categorize road contexts into "mobile entities", "static entities", and "context parameters" that describe the relationship between entities from the spatio-temporal scope. Rules are established for the vehicle when the combination of road contexts changes. Ontologies are intuitively straightforward for modeling situations and are easy to understand. However, the ontology models are built on simplified or specific situations. They may have problems in complex environments and unexpected situations. Hence, robots need multiple inference methods to obtain SA \cite{tenorth2017representations}. Alternatively, probabilistic methods can be used to model the environment and generate SA \cite{shuang2014quantitative}. In \cite{nguyen2019review}, authors compare multiple SA measurements that formalize the SA. Apart from a human perspective, the authors also review the SA for Unmanned Aerial Vehicles (UAV). They claim that most SA studies focus on the human perspective and indicate there are limited methods to frame and obtain UAV SA. 

In general, most of these SA assessments define metrics highlighting the flexibility and the importance of expert knowledge. However, there are limited works on how robots perceive high-level semantics and how robots can aggregate those semantics into coherent and usable metrics reflecting the overall SA and context. Unlike human SA research, most robot SA research still focuses on addressing specific problems from one specific scope, e.g. electromagnetic jamming security \cite{gao2020uav}, or failure conditions \cite{ginesi2020autonomous,ghezala2014rsaw}. In contrast, we propose a general framework and an example realization for an aggregated metric of SA which enables robots to understand the overall environment situation and can be generalized to different deployment tasks.