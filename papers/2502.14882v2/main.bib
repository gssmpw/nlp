@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}

@article{Stang:2016ca,
author = {Stang, Andreas and Deckert, Markus and Poole, Charles and Rothman, Kenneth J},
title = {{Statistical inference in abstracts of major medical and epidemiology journals 1975-2014: a systematic review.}},
journal = {European journal of epidemiology},
year = {2016},
month = nov
}


@article{eldan2023s,
  title={Who’s Harry Potter? Approximate Unlearning in LLMs},
  author={Eldan, Ronen and Russinovich, Mark},
  journal={arXiv preprint arXiv:2310.02238},
  year={2023}
}

@article{zhang2024unlearncanvas,
  title={UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models},
  author={Zhang, Yihua and Zhang, Yimeng and Yao, Yuguang and Jia, Jinghan and Liu, Jiancheng and Liu, Xiaoming and Liu, Sijia},
  journal={arXiv preprint arXiv:2402.11846},
  year={2024}
}

@inproceedings{li2024machine,
  title={Machine Unlearning for Image-to-Image Generative Models},
  author={Li, Guihong and Hsu, Hsiang and Marculescu, Radu and others},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{fan2023salun,
  title={SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation},
  author={Fan, Chongyu and Liu, Jiancheng and Zhang, Yihua and Wong, Eric and Wei, Dennis and Liu, Sijia},
  booktitle={ICLR},
  year={2023}
}
@article{li2023multimodal,
  title={Multimodal foundation models: From specialists to general-purpose assistants},
  author={Li, Chunyuan and Gan, Zhe and Yang, Zhengyuan and Yang, Jianwei and Li, Linjie and Wang, Lijuan and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2309.10020},
  volume={1},
  number={2},
  pages={2},
  year={2023}
}


@article{subramanian2024towards,
  title={Towards foundation models for scientific machine learning: Characterizing scaling and transfer behavior},
  author={Subramanian, Shashank and Harrington, Peter and Keutzer, Kurt and Bhimji, Wahid and Morozov, Dmitriy and Mahoney, Michael W and Gholami, Amir},
  journal={NeurIPS},
  volume={36},
  year={2024}
}
@article{bengio2012unsupervised,
  title={Unsupervised feature learning and deep learning: A review and new perspectives},
  author={Bengio, Yoshua and Courville, Aaron C and Vincent, Pascal},
  journal={CoRR, abs/1206.5538},
  volume={1},
  number={2665},
  pages={2012},
  year={2012}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={NeurIPS},
  volume={35},
  pages={25278--25294},
  year={2022}
}
@inproceedings{guo2023calip,
  title={Calip: Zero-shot enhancement of clip with parameter-free attention},
  author={Guo, Ziyu and Zhang, Renrui and Qiu, Longtian and Ma, Xianzheng and Miao, Xupeng and He, Xuming and Cui, Bin},
  booktitle={AAAI},
  volume={37},
  number={1},
  pages={746--754},
  year={2023}
}
@inproceedings{sain2023clip,
  title={Clip for all things zero-shot sketch-based image retrieval, fine-grained or not},
  author={Sain, Aneeshan and Bhunia, Ayan Kumar and Chowdhury, Pinaki Nath and Koley, Subhadeep and Xiang, Tao and Song, Yi-Zhe},
  booktitle={CVPR},
  pages={2765--2775},
  year={2023}
}
@inproceedings{cheng2021data,
  title={Data-efficient language-supervised zero-shot learning with self-distillation},
  author={Cheng, Ruizhe and Wu, Bichen and Zhang, Peizhao and Vajda, Peter and Gonzalez, Joseph E},
  booktitle={CVPR},
  pages={3119--3124},
  year={2021}
}
@inproceedings{kim2022diffusionclip,
  title={Diffusionclip: Text-guided diffusion models for robust image manipulation},
  author={Kim, Gwanghyun and Kwon, Taesung and Ye, Jong Chul},
  booktitle={CVPR},
  pages={2426--2435},
  year={2022}
}
@inproceedings{crowson2022vqgan,
  title={Vqgan-clip: Open domain image generation and editing with natural language guidance},
  author={Crowson, Katherine and Biderman, Stella and Kornis, Daniel and Stander, Dashiell and Hallahan, Eric and Castricato, Louis and Raff, Edward},
  booktitle={ECCV},
  pages={88--105},
  year={2022},
  organization={Springer}
}
@inproceedings{tevet2022motionclip,
  title={Motionclip: Exposing human motion generation to clip space},
  author={Tevet, Guy and Gordon, Brian and Hertz, Amir and Bermano, Amit H and Cohen-Or, Daniel},
  booktitle={ECCV},
  pages={358--374},
  year={2022},
  organization={Springer}
}
@inproceedings{yu2023turning,
  title={Turning a clip model into a scene text detector},
  author={Yu, Wenwen and Liu, Yuliang and Hua, Wei and Jiang, Deqiang and Ren, Bo and Bai, Xiang},
  booktitle={CVPR},
  pages={6978--6988},
  year={2023}
}

@article{tang2023video,
  title={Video understanding with large language models: A survey},
  author={Tang, Yunlong and Bi, Jing and Xu, Siting and Song, Luchuan and Liang, Susan and Wang, Teng and Zhang, Daoan and An, Jie and Lin, Jingyang and Zhu, Rongyi and others},
  journal={arXiv preprint arXiv:2312.17432},
  year={2023}
}
@article{zhang2024treat,
  title={Treat visual tokens as text? but your mllm only needs fewer efforts to see},
  author={Zhang, Zeliang and Pham, Phu and Zhao, Wentian and Wan, Kun and Li, Yu-Jhe and Zhou, Jianing and Miranda, Daniel and Kale, Ajinkya and Xu, Chenliang},
  journal={arXiv preprint arXiv:2410.06169},
  year={2024}
}
@article{zhang2024diversifying,
  title={Diversifying the expert knowledge for task-agnostic pruning in sparse mixture-of-experts},
  author={Zhang, Zeliang and Liu, Xiaodong and Cheng, Hao and Xu, Chenliang and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2407.09590},
  year={2024}
}

@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}
@article{dai2024deepseekmoe,
  title={Deepseekmoe: Towards ultimate expert specialization in mixture-of-experts language models},
  author={Dai, Damai and Deng, Chengqi and Zhao, Chenggang and Xu, RX and Gao, Huazuo and Chen, Deli and Li, Jiashi and Zeng, Wangding and Yu, Xingkai and Wu, Y and others},
  journal={arXiv preprint arXiv:2401.06066},
  year={2024}
}
@inproceedings{chen2024internvl,
  title={Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24185--24198},
  year={2024}
}


@article{yang2023dawn,
  title={The dawn of lmms: Preliminary explorations with gpt-4v (ision)},
  author={Yang, Zhengyuan and Li, Linjie and Lin, Kevin and Wang, Jianfeng and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
  journal={arXiv preprint arXiv:2309.17421},
  volume={9},
  number={1},
  pages={1},
  year={2023}
}

@inproceedings{kwon2023efficient,
  title={Efficient memory management for large language model serving with pagedattention},
  author={Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
  booktitle={Proceedings of the 29th Symposium on Operating Systems Principles},
  pages={611--626},
  year={2023}
}

@article{cai2024pyramidkv,
  title={Pyramidkv: Dynamic kv cache compression based on pyramidal information funneling},
  author={Cai, Zefan and Zhang, Yichi and Gao, Bofei and Liu, Yuliang and Liu, Tianyu and Lu, Keming and Xiong, Wayne and Dong, Yue and Chang, Baobao and Hu, Junjie and others},
  journal={arXiv preprint arXiv:2406.02069},
  year={2024}
}
@article{jin2024llm,
  title={Llm maybe longlm: Self-extend llm context window without tuning},
  author={Jin, Hongye and Han, Xiaotian and Yang, Jingfeng and Jiang, Zhimeng and Liu, Zirui and Chang, Chia-Yuan and Chen, Huiyuan and Hu, Xia},
  journal={arXiv preprint arXiv:2401.01325},
  year={2024}
}


@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}
@article{zhang2023h2o,
  title={H2o: Heavy-hitter oracle for efficient generative inference of large language models},
  author={Zhang, Zhenyu and Sheng, Ying and Zhou, Tianyi and Chen, Tianlong and Zheng, Lianmin and Cai, Ruisi and Song, Zhao and Tian, Yuandong and R{\'e}, Christopher and Barrett, Clark and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={34661--34710},
  year={2023}
}
@article{tu2024vl,
  title={VL-Cache: Sparsity and Modality-Aware KV Cache Compression for Vision-Language Model Inference Acceleration},
  author={Tu, Dezhan and Vashchilenko, Danylo and Lu, Yuzhe and Xu, Panpan},
  journal={arXiv preprint arXiv:2410.23317},
  year={2024}
}
@article{wan2024look,
  title={Look-m: Look-once optimization in kv cache for efficient multimodal long-context inference},
  author={Wan, Zhongwei and Wu, Ziang and Liu, Che and Huang, Jinfa and Zhu, Zhihong and Jin, Peng and Wang, Longyue and Yuan, Li},
  journal={arXiv preprint arXiv:2406.18139},
  year={2024}
}
@article{abdin2024phi,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Aneja, Jyoti and Awadalla, Hany and Awadallah, Ahmed and Awan, Ammar Ahmad and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Bao, Jianmin and Behl, Harkirat and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}


@article{chen2024mllm,
  title={Mllm-as-a-judge: Assessing multimodal llm-as-a-judge with vision-language benchmark},
  author={Chen, Dongping and Chen, Ruoxi and Zhang, Shilin and Liu, Yinuo and Wang, Yaochen and Zhou, Huichi and Zhang, Qihui and Wan, Yao and Zhou, Pan and Sun, Lichao},
  journal={arXiv preprint arXiv:2402.04788},
  year={2024}
}


@article{bai2023qwen,
  title={Qwen-vl: A frontier large vision-language model with versatile abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}


@inproceedings{zhang2024discover,
  title={Discover and Mitigate Multiple Biased Subgroups in Image Classifiers},
  author={Zhang, Zeliang and Feng, Mingqian and Li, Zhiheng and Xu, Chenliang},
  booktitle={CVPR},
  year={2024}
}
@inproceedings{esmaeilpour2022zero,
  title={Zero-shot out-of-distribution detection based on the pre-trained model clip},
  author={Esmaeilpour, Sepideh and Liu, Bing and Robertson, Eric and Shu, Lei},
  booktitle={AAAI},
  volume={36},
  number={6},
  pages={6568--6576},
  year={2022}
}
@inproceedings{vidit2023clip,
  title={Clip the gap: A single domain generalization approach for object detection},
  author={Vidit, Vidit and Engilberge, Martin and Salzmann, Mathieu},
  booktitle={CVPR},
  pages={3219--3229},
  year={2023}
}
@inproceedings{wang2023clipn,
  title={Clipn for zero-shot ood detection: Teaching clip to say no},
  author={Wang, Hualiang and Li, Yi and Yao, Huifeng and Li, Xiaomeng},
  booktitle={ICCV},
  pages={1802--1812},
  year={2023}
}
@article{chen2024catastrophic,
  title={On Catastrophic Inheritance of Large Foundation Models},
  author={Chen, Hao and Raj, Bhiksha and Xie, Xing and Wang, Jindong},
  journal={arXiv preprint arXiv:2402.01909},
  year={2024}
}
@inproceedings{yang2020towards,
  title={Towards fairer datasets: Filtering and balancing the distribution of the people subtree in the imagenet hierarchy},
  author={Yang, Kaiyu and Qinami, Klint and Fei-Fei, Li and Deng, Jia and Russakovsky, Olga},
  booktitle={Proceedings of the 2020 conference on fairness, accountability, and transparency},
  pages={547--558},
  year={2020}
}
@article{guo2024domain,
  title={Domain watermark: Effective and harmless dataset copyright protection is closed at hand},
  author={Guo, Junfeng and Li, Yiming and Wang, Lixu and Xia, Shu-Tao and Huang, Heng and Liu, Cong and Li, Bo},
  journal={NeurIPS},
  volume={36},
  year={2024}
}
@article{quang2021does,
  title={Does Training AI Violate Copyright Law?},
  author={Quang, Jenny},
  journal={Berkeley Tech. LJ},
  volume={36},
  pages={1407},
  year={2021},
  publisher={HeinOnline}
}
@inproceedings{zhong2023poisoning,
  title={Poisoning Retrieval Corpora by Injecting Adversarial Passages},
  author={Zhong, Zexuan and Huang, Ziqing and Wettig, Alexander and Chen, Danqi},
  booktitle={EMNLP},
  year={2023}
}
@article{hamidieh2023identifying,
  title={Identifying Implicit Social Biases in Vision-Language Models},
  author={Hamidieh, Kimia and Zhang, Haoran and Hartvigsen, Thomas and Ghassemi, Marzyeh},
  year={2023}
}
@inproceedings{li2023whac,
  title={A whac-a-mole dilemma: Shortcuts come in multiples where mitigating one amplifies others},
  author={Li, Zhiheng and Evtimov, Ivan and Gordo, Albert and Hazirbas, Caner and Hassner, Tal and Ferrer, Cristian Canton and Xu, Chenliang and Ibrahim, Mark},
  booktitle={CVPR},
  pages={20071--20082},
  year={2023}
}
@article{zhang2023review,
  title={A review on machine unlearning},
  author={Zhang, Haibo and Nakamura, Toru and Isohara, Takamasa and Sakurai, Kouichi},
  journal={SN Computer Science},
  volume={4},
  number={4},
  pages={337},
  year={2023},
  publisher={Springer}
}
@inproceedings{bourtoule2021machine,
  title={Machine unlearning},
  author={Bourtoule, Lucas and Chandrasekaran, Varun and Choquette-Choo, Christopher A and Jia, Hengrui and Travers, Adelin and Zhang, Baiwu and Lie, David and Papernot, Nicolas},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)},
  pages={141--159},
  year={2021},
  organization={IEEE}
}
@inproceedings{cha2024learning,
  title={Learning to unlearn: Instance-wise unlearning for pre-trained classifiers},
  author={Cha, Sungmin and Cho, Sungjun and Hwang, Dasol and Lee, Honglak and Moon, Taesup and Lee, Moontae},
  booktitle={AAAI},
  volume={38},
  number={10},
  pages={11186--11194},
  year={2024}
}
@inproceedings{schelter2021hedgecut,
  title={Hedgecut: Maintaining randomised trees for low-latency machine unlearning},
  author={Schelter, Sebastian and Grafberger, Stefan and Dunning, Ted},
  booktitle={Proceedings of the 2021 International Conference on Management of Data},
  pages={1545--1557},
  year={2021}
}
@article{baumhauer2022machine,
  title={Machine unlearning: Linear filtration for logit-based classifiers},
  author={Baumhauer, Thomas and Sch{\"o}ttle, Pascal and Zeppelzauer, Matthias},
  journal={Machine Learning},
  volume={111},
  number={9},
  pages={3203--3226},
  year={2022},
  publisher={Springer}
}
@article{gupta2021adaptive,
  title={Adaptive machine unlearning},
  author={Gupta, Varun and Jung, Christopher and Neel, Seth and Roth, Aaron and Sharifi-Malvajerdi, Saeed and Waites, Chris},
  journal={NeurIPS},
  volume={34},
  pages={16319--16330},
  year={2021}
}
@article{ji2020kullback,
  title={Kullback--Leibler divergence metric learning},
  author={Ji, Shuyi and Zhang, Zizhao and Ying, Shihui and Wang, Liejun and Zhao, Xibin and Gao, Yue},
  journal={IEEE transactions on cybernetics},
  volume={52},
  number={4},
  pages={2047--2058},
  year={2020},
  publisher={IEEE}
}

@article{yin2024squeeze,
  title={Squeeze, recover and relabel: Dataset condensation at imagenet scale from a new perspective},
  author={Yin, Zeyuan and Xing, Eric and Shen, Zhiqiang},
  journal={NeurIPS},
  volume={36},
  year={2024}
}
@inproceedings{li2022discover,
  title={Discover and mitigate unknown biases with debiasing alternate networks},
  author={Li, Zhiheng and Hoogs, Anthony and Xu, Chenliang},
  booktitle={ECCV},
  pages={270--288},
  year={2022},
  organization={Springer}
}
@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}
@inproceedings{chang2018explaining,
  title={Explaining Image Classifiers by Counterfactual Generation},
  author={Chang, Chun-Hao and Creager, Elliot and Goldenberg, Anna and Duvenaud, David},
  booktitle={ICLR},
  year={2018}
}
@article{zhang2023generate,
  title={To generate or not? safety-driven unlearned diffusion models are still easy to generate unsafe images... for now},
  author={Zhang, Yimeng and Jia, Jinghan and Chen, Xin and Chen, Aochuan and Zhang, Yihua and Liu, Jiancheng and Ding, Ke and Liu, Sijia},
  journal={arXiv preprint arXiv:2310.11868},
  year={2023}
}

@inproceedings{schelter2023forget,
  title={Forget me now: Fast and exact unlearning in neighborhood-based recommendation},
  author={Schelter, Sebastian and Ariannezhad, Mozhdeh and de Rijke, Maarten},
  booktitle={Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2011--2015},
  year={2023}
}

@inproceedings{ullah2021machine,
  title={Machine unlearning via algorithmic stability},
  author={Ullah, Enayat and Mai, Tung and Rao, Anup and Rossi, Ryan A and Arora, Raman},
  booktitle={Conference on Learning Theory},
  pages={4126--4142},
  year={2021},
  organization={PMLR}
}

@inproceedings{yan2022arcane,
  title={ARCANE: An Efficient Architecture for Exact Machine Unlearning.},
  author={Yan, Haonan and Li, Xiaoguang and Guo, Ziyao and Li, Hui and Li, Fenghua and Lin, Xiaodong},
  booktitle={IJCAI},
  volume={6},
  pages={19},
  year={2022}
}


@article{nguyen2020variational,
  title={Variational bayesian unlearning},
  author={Nguyen, Quoc Phong and Low, Bryan Kian Hsiang and Jaillet, Patrick},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={16025--16036},
  year={2020}
}

@inproceedings{chien2022efficient,
  title={Efficient model updates for approximate unlearning of graph-structured data},
  author={Chien, Eli and Pan, Chao and Milenkovic, Olgica},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{gupta2021adaptive,
  title={Adaptive machine unlearning},
  author={Gupta, Varun and Jung, Christopher and Neel, Seth and Roth, Aaron and Sharifi-Malvajerdi, Saeed and Waites, Chris},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={16319--16330},
  year={2021}
}

@article{hu2024exact,
  title={Exact and Efficient Unlearning for Large Language Model-based Recommendation},
  author={Hu, Zhiyu and Zhang, Yang and Xiao, Minghao and Wang, Wenjie and Feng, Fuli and He, Xiangnan},
  journal={arXiv preprint arXiv:2404.10327},
  year={2024}
}

@inproceedings{zhang2024graph,
  title={Graph unlearning with efficient partial retraining},
  author={Zhang, Jiahao},
  booktitle={Companion Proceedings of the ACM on Web Conference 2024},
  pages={1218--1221},
  year={2024}
}

@inproceedings{bourtoule2021machine,
  title={Machine unlearning},
  author={Bourtoule, Lucas and Chandrasekaran, Varun and Choquette-Choo, Christopher A and Jia, Hengrui and Travers, Adelin and Zhang, Baiwu and Lie, David and Papernot, Nicolas},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)},
  pages={141--159},
  year={2021},
  organization={IEEE}
}

@article{liu2024model,
  title={Model sparsity can simplify machine unlearning},
  author={Liu, Jiancheng and Ram, Parikshit and Yao, Yuguang and Liu, Gaowen and Liu, Yang and SHARMA, PRANAY and Liu, Sijia and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{sekhari2021remember,
  title={Remember what you want to forget: Algorithms for machine unlearning},
  author={Sekhari, Ayush and Acharya, Jayadev and Kamath, Gautam and Suresh, Ananda Theertha},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18075--18086},
  year={2021}
}

@inproceedings{gong2021bayesian,
  title={Bayesian variational federated learning and unlearning in decentralized networks},
  author={Gong, Jinu and Simeone, Osvaldo and Kang, Joonhyuk},
  booktitle={2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)},
  pages={216--220},
  year={2021},
  organization={IEEE}
}

@article{huang2024unified,
  title={Unified Gradient-Based Machine Unlearning with Remain Geometry Enhancement},
  author={Huang, Zhehao and Cheng, Xinwen and Zheng, JingHao and Wang, Haoran and He, Zhengbao and Li, Tao and Huang, Xiaolin},
  journal={arXiv preprint arXiv:2409.19732},
  year={2024}
}

@article{zhang2024towards,
  title={Towards certified unlearning for deep neural networks},
  author={Zhang, Binchi and Dong, Yushun and Wang, Tianhao and Li, Jundong},
  journal={arXiv preprint arXiv:2408.00920},
  year={2024}
}

@article{huang2024unified,
  title={Unified Gradient-Based Machine Unlearning with Remain Geometry Enhancement},
  author={Huang, Zhehao and Cheng, Xinwen and Zheng, JingHao and Wang, Haoran and He, Zhengbao and Li, Tao and Huang, Xiaolin},
  journal={arXiv preprint arXiv:2409.19732},
  year={2024}
}

@inproceedings{mehta2022deep,
  title={Deep unlearning via randomized conditionally independent hessians},
  author={Mehta, Ronak and Pal, Sourav and Singh, Vikas and Ravi, Sathya N},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10422--10431},
  year={2022}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}
@article{birhane2024into,
  title={Into the laion’s den: Investigating hate in multimodal datasets},
  author={Birhane, Abeba and Han, Sanghyun and Boddeti, Vishnu and Luccioni, Sasha and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{huang2024learning,
  title={Learning to unlearn for robust machine unlearning},
  author={Huang, Mark He and Foo, Lin Geng and Liu, Jun},
  journal={arXiv preprint arXiv:2407.10494},
  year={2024}
}

@article{tarun2023fast,
  title={Fast yet effective machine unlearning},
  author={Tarun, Ayush K and Chundawat, Vikram S and Mandal, Murari and Kankanhalli, Mohan},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}

@article{poth2021pre,
  title={What to pre-train on? efficient intermediate task selection},
  author={Poth, Clifton and Pfeiffer, Jonas and R{\"u}ckl{\'e}, Andreas and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2104.08247},
  year={2021}
}

@article{bai2024pretrain,
  title={Which Pretrain Samples to Rehearse when Finetuning Pretrained Models?},
  author={Bai, Andrew and Yeh, Chih-Kuan and Hsieh, Cho-Jui and Taly, Ankur},
  journal={arXiv preprint arXiv:2402.08096},
  year={2024}
}

@article{liu2022improved,
  title={Improved fine-tuning by better leveraging pre-training data},
  author={Liu, Ziquan and Xu, Yi and Xu, Yuanhong and Qian, Qi and Li, Hao and Ji, Xiangyang and Chan, Antoni and Jin, Rong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32568--32581},
  year={2022}
}

@inproceedings{wei2023improving,
  title={Improving clip fine-tuning performance},
  author={Wei, Yixuan and Hu, Han and Xie, Zhenda and Liu, Ze and Zhang, Zheng and Cao, Yue and Bao, Jianmin and Chen, Dong and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5439--5449},
  year={2023}
}

@article{eldan2023s,
  title={Who's Harry Potter? Approximate Unlearning in LLMs},
  author={Eldan, Ronen and Russinovich, Mark},
  journal={arXiv preprint arXiv:2310.02238},
  year={2023}
}
@article{shostack2024boy,
  title={The Boy Who Survived: Removing Harry Potter from an LLM is harder than reported},
  author={Shostack, Adam},
  journal={arXiv preprint arXiv:2403.12082},
  year={2024}
}
@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}
@article{kravets2024zero,
  title={Zero-Shot Class Unlearning in CLIP with Synthetic Samples},
  author={Kravets, Alexey and Namboodiri, Vinay},
  journal={arXiv preprint arXiv:2407.07485},
  year={2024}
}
@inproceedings{chung2024style,
  title={Style injection in diffusion: A training-free approach for adapting large-scale diffusion models for style transfer},
  author={Chung, Jiwoo and Hyun, Sangeek and Heo, Jae-Pil},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8795--8805},
  year={2024}
}
@article{cai2024single,
  title={Single Layer Single Gradient Unlearning},
  author={Cai, Zikui and Tan, Yaoteng and Asif, M Salman},
  journal={arXiv preprint arXiv:2407.11867},
  year={2024}
}
@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={International conference on machine learning},
  pages={23965--23998},
  year={2022},
  organization={PMLR}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{kravets2024zero,
  title={Zero-Shot Class Unlearning in CLIP with Synthetic Samples},
  author={Kravets, Alexey and Namboodiri, Vinay},
  journal={arXiv preprint arXiv:2407.07485},
  year={2024}
}
@inproceedings{poppi2024safe,
  title={Safe-CLIP: Removing NSFW Concepts from Vision-and-Language Models},
  author={Poppi, Samuele and Poppi, Tobia and Cocchi, Federico and Cornia, Marcella and Baraldi, Lorenzo and Cucchiara, Rita and others},
  booktitle={Proceedings of the European Conference on Computer Vision},
  year={2024}
}

@inproceedings{Alexander23ft,
  author       = {Alexander Warnecke and
                  Lukas Pirch and
                  Christian Wressnegger and
                  Konrad Rieck},
  title        = {Machine Unlearning of Features and Labels},
  booktitle    = {30th Annual Network and Distributed System Security Symposium, {NDSS}
                  2023, San Diego, California, USA, February 27 - March 3, 2023},
  publisher    = {The Internet Society},
  year         = {2023},
  url          = {https://www.ndss-symposium.org/ndss-paper/machine-unlearning-of-features-and-labels/},
  timestamp    = {Sat, 30 Sep 2023 09:53:53 +0200},
  biburl       = {https://dblp.org/rec/conf/ndss/WarneckePWR23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{golatkar2020eternal,
  title={Eternal sunshine of the spotless net: Selective forgetting in deep networks},
  author={Golatkar, Aditya and Achille, Alessandro and Soatto, Stefano},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9304--9312},
  year={2020}
}

@article{liu2024model,
  title={Model sparsity can simplify machine unlearning},
  author={Liu, Jiancheng and Ram, Parikshit and Yao, Yuguang and Liu, Gaowen and Liu, Yang and SHARMA, PRANAY and Liu, Sijia and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{parisi2019continual,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural networks},
  volume={113},
  pages={54--71},
  year={2019},
  publisher={Elsevier}
}

@article{becker2022evaluating,
  title={Evaluating machine unlearning via epistemic uncertainty},
  author={Becker, Alexander and Liebig, Thomas},
  journal={arXiv preprint arXiv:2208.10836},
  year={2022}
}

@inproceedings{thudi2022unrolling,
  title={Unrolling sgd: Understanding factors influencing machine unlearning},
  author={Thudi, Anvith and Deza, Gabriel and Chandrasekaran, Varun and Papernot, Nicolas},
  booktitle={2022 IEEE 7th European Symposium on Security and Privacy (EuroS\&P)},
  pages={303--319},
  year={2022},
  organization={IEEE}
}

@article{foster2024zero,
  title={Zero-shot machine unlearning at scale via lipschitz regularization},
  author={Foster, Jack and Fogarty, Kyle and Schoepf, Stefan and {\"O}ztireli, Cengiz and Brintrup, Alexandra},
  journal={arXiv preprint arXiv:2402.01401},
  year={2024}
}
@article{kravets2024zero,
  title={Zero-Shot Class Unlearning in CLIP with Synthetic Samples},
  author={Kravets, Alexey and Namboodiri, Vinay},
  journal={arXiv preprint arXiv:2407.07485},
  year={2024}
}

@article{chundawat2023zero,
  title={Zero-shot machine unlearning},
  author={Chundawat, Vikram S and Tarun, Ayush K and Mandal, Murari and Kankanhalli, Mohan},
  journal={IEEE Transactions on Information Forensics and Security},
  volume={18},
  pages={2345--2354},
  year={2023},
  publisher={IEEE}
}

@misc{msn_article_2024,
  author = {Kris Holt},
  title = {Researchers Found Child Abuse Material in the Largest AI Image Generation Dataset},
  year = {2024},
  url = {https://www.msn.com/en-us/money/other/researchers-found-child-abuse-material-in-the-largest-ai-image-generation-dataset/ar-AA1lNAGW},
  note = {Accessed: 2024-10-25}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@inproceedings{poppi2024safe,
  title={Safe-CLIP: Removing NSFW Concepts from Vision-and-Language Models},
  author={Poppi, Samuele and Poppi, Tobia and Cocchi, Federico and Cornia, Marcella and Baraldi, Lorenzo and Cucchiara, Rita and others},
  booktitle={Proceedings of the European Conference on Computer Vision},
  year={2024}
}

@article{cai2024single,
  title={Single Layer Single Gradient Unlearning},
  author={Cai, Zikui and Tan, Yaoteng and Asif, M Salman},
  journal={arXiv preprint arXiv:2407.11867},
  year={2024}
}

@article{kravets2024zero,
  title={Zero-Shot Class Unlearning in CLIP with Synthetic Samples},
  author={Kravets, Alexey and Namboodiri, Vinay},
  journal={arXiv preprint arXiv:2407.07485},
  year={2024}
}

@article{
anonymous2024zeroshot,
title={Zero-shot {CLIP} Class Unlearning via Text-image Space Adaptation},
author={Anonymous},
journal={Submitted to Transactions on Machine Learning Research},
year={2024},
url={https://openreview.net/forum?id=V2SD2uVKEE},
note={Under review}
}

@article{yin2024squeeze,
  title={Squeeze, recover and relabel: Dataset condensation at imagenet scale from a new perspective},
  author={Yin, Zeyuan and Xing, Eric and Shen, Zhiqiang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={International conference on machine learning},
  pages={23965--23998},
  year={2022},
  organization={PMLR}
}
@article{santurkar2020breeds,
  title={Breeds: Benchmarks for subpopulation shift},
  author={Santurkar, Shibani and Tsipras, Dimitris and Madry, Aleksander},
  journal={arXiv preprint arXiv:2008.04859},
  year={2020}
}
@article{liu2024fisher,
  title={Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models},
  author={Liu, Ji and Ren, Jiaxiang and Jin, Ruoming and Zhang, Zijie and Zhou, Yang and Valduriez, Patrick and Dou, Dejing},
  journal={arXiv preprint arXiv:2410.00131},
  year={2024}
}
@article{ly2017tutorial,
  title={A tutorial on Fisher information},
  author={Ly, Alexander and Marsman, Maarten and Verhagen, Josine and Grasman, Raoul PPP and Wagenmakers, Eric-Jan},
  journal={Journal of Mathematical Psychology},
  volume={80},
  pages={40--55},
  year={2017},
  publisher={Elsevier}
}
@article{liu2023unlearning,
  title={Unlearning with fisher masking},
  author={Liu, Yufang and Sun, Changzhi and Wu, Yuanbin and Zhou, Aimin},
  journal={arXiv preprint arXiv:2310.05331},
  year={2023}
}

@mastersthesis{clavera2024machine,
  title={Machine unlearning: fisher infomation matrix and selective forgetting in deep networks},
  author={Clavera Comas, Lluc},
  type={{B.S.} thesis},
  year={2024},
  school={Universitat Polit{\`e}cnica de Catalunya}
}

@article{klinker2011exponential,
  title={Exponential moving average versus moving exponential average},
  author={Klinker, Frank},
  journal={Mathematische Semesterberichte},
  volume={58},
  pages={97--107},
  year={2011},
  publisher={Springer}
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@inproceedings{bossard2014food,
  title={Food-101--mining discriminative components with random forests},
  author={Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle={Computer vision--ECCV 2014: 13th European conference, zurich, Switzerland, September 6-12, 2014, proceedings, part VI 13},
  pages={446--461},
  year={2014},
  organization={Springer}
}
@inproceedings{coates2011analysis,
  title={An analysis of single-layer networks in unsupervised feature learning},
  author={Coates, Adam and Ng, Andrew and Lee, Honglak},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={215--223},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}
@article{barbu2019objectnet,
  title={Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models},
  author={Barbu, Andrei and Mayo, David and Alverio, Julian and Luo, William and Wang, Christopher and Gutfreund, Dan and Tenenbaum, Josh and Katz, Boris},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{tillet2019triton,
    author = {Tillet, Philippe and Kung, H. T. and Cox, David},
    title = {Triton: an intermediate language and compiler for tiled neural network computations},
    year = {2019},
    isbn = {9781450367196},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3315508.3329973},
    doi = {10.1145/3315508.3329973},
    abstract = {The validation and deployment of novel research ideas in the field of Deep Learning is often limited by the availability of efficient compute kernels for certain basic primitives. In particular, operations that cannot leverage existing vendor libraries (e.g., cuBLAS, cuDNN) are at risk of facing poor device utilization unless custom implementations are written by experts – usually at the expense of portability. For this reason, the development of new programming abstractions for specifying custom Deep Learning workloads at a minimal performance cost has become crucial. We present Triton, a language and compiler centered around the concept of tile, i.e., statically shaped multi-dimensional sub-arrays. Our approach revolves around (1) a C-based language and an LLVM-based intermediate representation (IR) for expressing tensor programs in terms of operations on parametric tile variables and (2) a set of novel tile-level optimization passes for compiling these programs into efficient GPU code. We demonstrate how Triton can be used to build portable implementations of matrix multiplication and convolution kernels on par with hand-tuned vendor libraries (cuBLAS / cuDNN), or for efficiently implementing recent research ideas such as shift convolutions.},
    booktitle = {Proceedings of the 3rd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},
    pages = {10–19},
    numpages = {10},
    keywords = {GPU, compiler, neural networks},
    location = {Phoenix, AZ, USA},
    series = {MAPL 2019}
}

@inproceedings{srinivasan2021wit,
  title={Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning},
  author={Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc},
  booktitle={Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval},
  pages={2443--2449},
  year={2021}
}

@article{deng2024efficient,
  title={Efficient Self-Improvement in Multimodal Large Language Models: A Model-Level Judge-Free Approach},
  author={Deng, Shijian and Zhao, Wentian and Li, Yu-Jhe and Wan, Kun and Miranda, Daniel and Kale, Ajinkya and Tian, Yapeng},
  journal={arXiv preprint arXiv:2411.17760},
  year={2024}
}

@techreport{OCP_MicroScaling_2023,
  title        = {{OCP} Micro Scaling Formats MX v1.0 Specification},
  author       = {Bita Darvish Rouhani and Nitin Garegrat and Tom Savell and Ankit More and Kyung-Nam Han and Ritchie Zhao and Mathew Hall and
Jasmine Klar and Eric Chung and Yuan Yu and Michael Schulte and Ralph Wittig and Ian Bratt and Nigel Stephens and Jelena Milanovic and John Brothers and Pradeep Dubey and Marius Cornea and Alexander Heinecke and Andres Rodriguez and Martin Langhammer and Summer Deng and Maxim Naumov and Paulius Micikevicius and Michael Siu and Colin Verrilli},
  year         = {2023},
  institution  = {Open Compute Project},
  url          = {https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf},
  note         = {Version 1.0},
  accessed     = {2023-10-01}
}

@inproceedings{liukivi,
  title={KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache},
  author={Liu, Zirui and Yuan, Jiayi and Jin, Hongye and Zhong, Shaochen and Xu, Zhaozhuo and Braverman, Vladimir and Chen, Beidi and Hu, Xia},
  booktitle={International Conference on Machine Learning},
  year={2024},
}

@article{chen2015microsoft,
  title={Microsoft coco captions: Data collection and evaluation server},
  author={Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:1504.00325},
  year={2015}
}

@article{fang2024mmbenchvideo,
    title={MMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding}, 
    author={Xinyu Fang and Kangrui Mao and Haodong Duan and Xiangyu Zhao and Yining Li and Dahua Lin and Kai Chen},
    journal={arXiv preprint arXiv:2406.14515},
    year={2024}
}

@inproceedings{mathew2021docvqa,
  title={Docvqa: A dataset for vqa on document images},
  author={Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={2200--2209},
  year={2021}
}
@article{chu2024mobilevlm,
  title={Mobilevlm v2: Faster and stronger baseline for vision language model},
  author={Chu, Xiangxiang and Qiao, Limeng and Zhang, Xinyu and Xu, Shuang and Wei, Fei and Yang, Yang and Sun, Xiaofei and Hu, Yiming and Lin, Xinyang and Zhang, Bo and others},
  journal={arXiv preprint arXiv:2402.03766},
  year={2024}
}
@article{chu2023mobilevlm,
  title={Mobilevlm: A fast, strong and open vision language assistant for mobile devices},
  author={Chu, Xiangxiang and Qiao, Limeng and Lin, Xinyang and Xu, Shuang and Yang, Yang and Hu, Yiming and Wei, Fei and Zhang, Xinyu and Zhang, Bo and Wei, Xiaolin and others},
  journal={arXiv preprint arXiv:2312.16886},
  year={2023}
}
@article{lin2024moe,
  title={Moe-llava: Mixture of experts for large vision-language models},
  author={Lin, Bin and Tang, Zhenyu and Ye, Yang and Cui, Jiaxi and Zhu, Bin and Jin, Peng and Huang, Jinfa and Zhang, Junwu and Pang, Yatian and Ning, Munan and others},
  journal={arXiv preprint arXiv:2401.15947},
  year={2024}
}
@inproceedings{chen2024fastv,
  title={An image is worth 1/2 tokens after layer 2: Plug-and-play inference acceleration for large vision-language models},
  author={Chen, Liang and Zhao, Haozhe and Liu, Tianyu and Bai, Shuai and Lin, Junyang and Zhou, Chang and Chang, Baobao},
  booktitle={European Conference on Computer Vision},
  pages={19--35},
  year={2024},
  organization={Springer}
}
@article{shang2024llava-prumerge,
  title={Llava-prumerge: Adaptive token reduction for efficient large multimodal models},
  author={Shang, Yuzhang and Cai, Mu and Xu, Bingxin and Lee, Yong Jae and Yan, Yan},
  journal={arXiv preprint arXiv:2403.15388},
  year={2024}
}
@article{xing2024pyramiddrop,
  title={Pyramiddrop: Accelerating your large vision-language models via pyramid visual redundancy reduction},
  author={Xing, Long and Huang, Qidong and Dong, Xiaoyi and Lu, Jiajie and Zhang, Pan and Zang, Yuhang and Cao, Yuhang and He, Conghui and Wang, Jiaqi and Wu, Feng and others},
  journal={arXiv preprint arXiv:2410.17247},
  year={2024}
}
@article{tu2024vlcache,
  title={VL-Cache: Sparsity and Modality-Aware KV Cache Compression for Vision-Language Model Inference Acceleration},
  author={Tu, Dezhan and Vashchilenko, Danylo and Lu, Yuzhe and Xu, Panpan},
  journal={arXiv preprint arXiv:2410.23317},
  year={2024}
}

@article{hooper2024kvquant,
  title={Kvquant: Towards 10 million context length llm inference with kv cache quantization},
  author={Hooper, Coleman and Kim, Sehoon and Mohammadzadeh, Hiva and Mahoney, Michael W and Shao, Sophia and Keutzer, Kurt and Gholami, Amir},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={1270--1303},
  year={2024}
}
@article{zandieh2024qjl,
  title={Qjl: 1-bit quantized jl transform for kv cache quantization with zero overhead},
  author={Zandieh, Amir and Daliri, Majid and Han, Insu},
  journal={arXiv preprint arXiv:2406.03482},
  year={2024}
}
@article{li2024mini,
  title={Mini-gemini: Mining the potential of multi-modality vision language models},
  author={Li, Yanwei and Zhang, Yuechen and Wang, Chengyao and Zhong, Zhisheng and Chen, Yixin and Chu, Ruihang and Liu, Shaoteng and Jia, Jiaya},
  journal={arXiv preprint arXiv:2403.18814},
  year={2024}
}

@article{yao2024minicpm,
  title={Minicpm-v: A gpt-4v level mllm on your phone},
  author={Yao, Yuan and Yu, Tianyu and Zhang, Ao and Wang, Chongyi and Cui, Junbo and Zhu, Hongji and Cai, Tianchi and Li, Haoyu and Zhao, Weilin and He, Zhihui and others},
  journal={arXiv preprint arXiv:2408.01800},
  year={2024}
}

@article{zandieh2024subgen,
  title={Subgen: Token generation in sublinear time and memory},
  author={Zandieh, Amir and Han, Insu and Mirrokni, Vahab and Karbasi, Amin},
  journal={arXiv preprint arXiv:2402.06082},
  year={2024}
}

@article{han2025polarquant,
  title={PolarQuant: Quantizing KV Caches with Polar Transformation},
  author={Han, Insu and Kacham, Praneeth and Karbasi, Amin and Mirrokni, Vahab and Zandieh, Amir},
  journal={arXiv preprint arXiv:2502.02617},
  year={2025}
}

@article{han2025balancekv,
  title={BalanceKV: KV Cache Compression through Discrepancy Theory},
  author={Han, Insu and Kapralov, Michael and Kochetkova, Ekaterina and Sheth, Kshiteej and Zandieh, Amir},
  journal={arXiv preprint arXiv:2502.07861},
  year={2025}
}

@article{wu2020integer,
  title={Integer quantization for deep learning inference: Principles and empirical evaluation},
  author={Wu, Hao and Judd, Patrick and Zhang, Xiaojie and Isaev, Mikhail and Micikevicius, Paulius},
  journal={arXiv preprint arXiv:2004.09602},
  year={2020}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}