\section{Proposed Method}
In this section, the RAViT hybrid transformer backbone is proposed. Firstly, we analyze the architecture at the macro level for the limited-resource hardware purpose. Then we develop the architecture at the micro-level. In  micro level, instead of using Multi-Head Self-Attention (MHSA) as the feature or token mixer that is computationally expensive, especially in high resolution, we proposed Reparameterized Multi-Scale Depth-Wise Convolution (RepMSDW). We also proposed Reparameterized Self-Attention (RepSA), which amalgamates the RepMSDW with self-attention to balance the local and global spatial understanding in features. Then, the RAViT will be utilized to improve the FCOS to perform the downstream task in driving scene object detection.
\subsection{Analysis in Macro Design}
\label{subsec:abl-macro}
Most of the recent macro-design of the vision transformer is based on a feature pyramid architecture of MetaFormer \cite{yu2022metaformer, yu2023metaformer} that stacks two residual blocks as shown in Fig. \ref{fig:RAViT}. The architecture starts with a stem module that might consist of a single \cite{yu2022metaformer} or sequence of two \cite{maaz2022edgenext, li2022efficientformer, wang2024repvit} or three blocks \cite{yun2024shvit, liu2023efficientvit} $3 \times 3$ convolutions with a stride of 2. The architecture in macro incorporates a token mixer block for spatial feature extraction, followed by a channel mixer block. Each block contains a normalization layer and residual or skip connection to steady the loss and advance the training process. Suppose $X_i, X'_i, X''_i \in \mathbb{R}^{H_i\times W_i\times C_i}$ are the feature maps in stage i with $H_i \times W_i$ resolution and $C_i$ channel number; the details of the block are explained in Equation \ref{eq:meta}.
\begin{equation}
    \begin{split}
    X'_i &= X_i + Norm(TokenMixer(X_i)) \\
    X''_i &= X'_i + Norm(ChannelMixer(X'_i))
    \end{split}
\label{eq:meta}
\end{equation}
$TokenMixer(.)$ operators commonly configured as convolution mixer or self-attention \cite{yu2023metaformer}. $ChannelMixer(.)$ block contains the feed-forward network (FFN) that is conducted by two linearly fully connected layers and a single activation function that can be expressed in Equation \ref{eq:ffn},
\begin{equation}
    FFN(X'_i)=\sigma(X'_iW_e+b_e)W_r+b_r
    \label{eq:ffn}
\end{equation}
where $W_e\in\mathbb{R}^{(C_i)\times rC_i}$ and $W_r\in\mathbb{R}^{(rC_i)\times C_i}$ are the layer weights, $r$ is the expansion ratio with a default value of 3, $b_e\in\mathbb{R}^{rC_i}$ and $b_r\in\mathbb{R}^{C_i}$ are bias weights of the fully connected layer. Operation $\sigma$ is chosen using the activation function $GELU(.)$ since it balances accuracy and inference speed according to \cite{wang2024repvit}. 

To construct an efficient yet low-cost model for mobile and edge devices, we analyze the architecture in the macro-design. First, incorporating $3 \times 3$ dwconv as a token mixer, we compare the 3-stage architecture with the $16 \times 16$ stem used in \cite{graham2021levit, liu2023efficientvit, yun2024shvit} and the 4-stage architecture with the $4 \times 4$ stem commonly used in \cite{vasu2023fastvit, li2022efficientformer, maaz2022edgenext}. As shown in Table \ref{tab:ablation_macro}, the comparison between V1 and V2 shows that even the 3 stage with the $16 \times 16$ stem can increase 3 $\times$ the GPU throughput. However, it does not have a significant effect on inference latency on both edge and mobile devices.  So, in the RAViT, we decided to use the 4-stage with the stem $4 \times 4$.
\subsection{Reparameterize Multi-Scale Depth-Wise Convolution}
Reparameterize Multi-Scale Depth-Wise Convolution (RepMSDW), as depicted in Fig. \ref{fig:RAViT} (b), is inspired by \cite{szegedy2017inception, yu2024inceptionnext}, which has several branch-depth-wise convolutions with different kernel sizes to expand the effective receptive field and feature extraction. By incorporating this multi-scale strategy, our model aims to replicate the multiple range modeling capabilities while maintaining locality and efficiency. The formulation of RepMSDW is described in Equation \ref{eq:repmsdw},
\begin{equation}
    \begin{split}
    X_1, & X_2, X_3, X_4 = Chunk(X_i) \\
    X_1 &= DWC_{s\times s}(X_1) \\
    X_2 &= DWC_{1\times k}(X_2) + DWC_{k\times 1}(X_2) \\
    X_3 &= DWC_{3\times k}(X_3) + DWC_{k\times 3}(X_3) \\
    X'_i &= BN (DWC_{k\times k}(X_i) + Cat([X_1, X_2, X_3, X_4])) 
\end{split}
\label{eq:repmsdw}
\end{equation}
where $X_i\in\mathbb{R}^{H_i\times W_i\times C_i}$ denotes the feature map in the stage-i that will be split along the channel dimension into $X_1, X_2, X_3, X_4 \in \mathbb{R}^{H_i\times W_i\times \frac{C_i}{4}}$. Each feature will be fed into different branches of depth-wise convolution (DWC), where $k$ denotes the largest kernel size and $s$ denotes the square kernel size equal to $k/2 \in \mathbb{N}=\{1,2,3,..\} $. Then each output branch is concatenated ($Cat(.)$) along the channel. Following the re-parameterization procedure in \cite{ding2021repvgg}, the sum between the concatenated branch and main $DWC_{k\times k}(.)$ with BatchNorm layer ($BN(.)$) will be re-parameterized into a single depth-wise convolution, denoted as $RepMSDW(.)$.

Table \ref{tab:ablation_token_mixer} shows the effectiveness of proposed RepMSDW. Compared to a single branch with square $k \times k$ and without reparameterization, the reparameterized multiple branch kernel has better accuracy without sacrificing the inference speed. Next, we try to increase the RepMSDW kernel size from $3 \times 3$ into $7 \times 7$ in the last two stages. As shown in Table \ref{tab:ablation_macro}, the increment of kernel size from V2 to V3 can increase the accuracy to 79.1\% with only a 2.5\% and 1\% latency drop in mobile and edge devices. Using the RepMSDW as a token mixer, our design has similar accuracy with FastViT-T12 \cite{vasu2023fastvit}; however, our approach has 26\% and 10\% faster inference speed in mobile and edge devices.

\begin{figure*}
    \centering
    \includegraphics[width=17cm]{picture/RepFPN.png}
    \caption{Fast-COS object detector utilize proposed RAViT backbone and RepFPN with Re-parameterized Multi-Scale DW Convolution and Re-parameterized Self Attention}
    \label{fig:RepFPN}
\end{figure*} 

\subsection{Reparameterize Self-Attention}
The reparameterized self-attention (RepSA) extends the spatial aggregation to reach long-range dependencies that become limitations of convolution. RepSA utilizes single-head self-attention with a quarter channel projected from RepMSDW, with details presented in Fig. \ref{fig:RAViT} (c). Generally, the formulation of RepSA is described in the following equation:
\begin{align}
    U &= RepMSDW(X_i) \\
    Q,\ K,\ V &=W_q*U,\ W_k*U,\ W_v*U\\
    Attn &= Softmax\Big(Q^TK/\sqrt{d_{q}}\Big)V \\
    RepSA(X_i) &=W_o*Cat(U,Attn)
\end{align}
where $U\in\mathbb{R}^{H_i\times W_i\times C_i}$, $Q\in\mathbb{R}^{d_q\times H_iW_i}$, $K\in\mathbb{R}^{d_k\times H_iW_i}$, and $V\in\mathbb{R}^{d_v\times H_iW_i}$. $W_q\in\mathbb{R}^{C_i\times d_q}$, $W_k\in\mathbb{R}^{C_i\times d_k}$, and $W_v\in\mathbb{R}^{C_i\times d_v}$ are denoted as the linear operation weights to project the feature $U$ into the query ($Q$), key ($K$), and value ($V$). The attention score $Attn\in\mathbb{R}^{H_i\times W_i\times d_v}$ is the result of the scaled dot product with softmax normalization between $Q, K$ and $V$ with dimension $d_q, d_k$ equal to 16 and $d_v$ configured to $0.215 * C_i$. Finally, the output of RepSA is the projection with linear weight $W_o\in\mathbb{R}^{(C_i+d_v)\times C_i}$ to aggregate the local feature ($U$) and the global attention map ($Attn$).

\begin{table}[ht]
\begin{center}
\caption{All Variant RAViT Model configurations. \#Blocks denotes the number of RAViT blocks.}
\begin{tabular}{cccccccc}
\hline
\multicolumn{1}{c|}{\multirow{2}{*}{Stage}} & \multicolumn{1}{c|}{\multirow{2}{*}{Res}} & \multicolumn{1}{c|}{\multirow{2}{*}{Layer Spec}} & \multicolumn{4}{c}{RAViT}  \\ 
\cline{4-7} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{T26} & \multicolumn{1}{c|}{S22} & \multicolumn{1}{c|}{S26} & \multicolumn{1}{c}{M26} \\ 
\hline
\multicolumn{1}{l|}{\multirow{3}{*}{Stem}} & \multicolumn{1}{l|}{\multirow{3}{*}{$H\times W$}} & \multicolumn{1}{c|}{\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Conv\\ Dims ($C_i$)\end{tabular}}} & \multicolumn{4}{c}{ $3 \times 3$, Stride 2} \\ 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{}  & \multicolumn{4}{c}{ $3 \times 3$, Stride 2}\\
\cline{4-7}  
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{40} & \multicolumn{1}{c|}{48}  & \multicolumn{1}{c|}{48} & \multicolumn{1}{c}{64}  \\ 
\hline
\multicolumn{1}{l|}{\multirow{3}{*}{1}} & \multicolumn{1}{l|}{\multirow{3}{*}{$\frac{H}{4}\times\frac{W}{4}$}} & \multicolumn{1}{l|}{Mixer}  & \multicolumn{4}{c}{ RepMSDW $3 \times 3$ }  \\
\cline{3-7}
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{FFN ($r$)}  & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c}{3}   \\ 
\cline{3-7}
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\#Blocks} & \multicolumn{1}{c|}{2}  & \multicolumn{1}{c|}{2}  & \multicolumn{1}{c|}{2} & \multicolumn{1}{c}{2} \\ 
\hline
\multicolumn{1}{l|}{\multirow{5}{*}{2}} & \multicolumn{1}{l|}{\multirow{5}{*}{$\frac{H}{8}\times\frac{W}{8}$}} & \multicolumn{1}{l|}{Downsample} & \multicolumn{4}{c}{RepMSDW $7 \times 7$, Stride 2} \\ 
\cline{4-7} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Dims ($C_i$)} & \multicolumn{1}{c|}{80} & \multicolumn{1}{c|}{96}  & \multicolumn{1}{c|}{96} & \multicolumn{1}{c}{128}  \\ 
\cline{3-7} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Mixer}  & \multicolumn{4}{c}{ RepMSDW $3 \times 3$ }  \\
\cline{3-7}
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{FFN ($r$)}  & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c}{3}   \\ 
\cline{3-7} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\#Blocks} & \multicolumn{1}{c|}{4}  & \multicolumn{1}{c|}{4}  & \multicolumn{1}{c|}{4} & \multicolumn{1}{c}{4} \\ 
\hline
\multicolumn{1}{l|}{\multirow{5}{*}{3}} & \multicolumn{1}{l|}{\multirow{5}{*}{$\frac{H}{16}\times\frac{W}{16}$}} & \multicolumn{1}{l|}{Downsample} & \multicolumn{4}{c}{RepMSDW $7 \times 7$, Stride 2} \\ 
\cline{4-7} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Dims ($C_i$)} & \multicolumn{1}{c|}{120} & \multicolumn{1}{c|}{192}  & \multicolumn{1}{c|}{192} & \multicolumn{1}{c}{256}  \\ 
\cline{3-7} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Mixer}  & \multicolumn{4}{c}{ RepMSDW $7 \times 7$ }  \\
\cline{3-7}
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{FFN ($r$)}  & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c}{3}   \\ 
\cline{3-7}
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\#Blocks} & \multicolumn{1}{c|}{16}  & \multicolumn{1}{c|}{12}  & \multicolumn{1}{c|}{16} & \multicolumn{1}{c}{16} \\ 
\hline
\multicolumn{1}{l|}{\multirow{5}{*}{4}} & \multicolumn{1}{l|}{\multirow{5}{*}{$\frac{H}{32}\times\frac{W}{32}$}} & \multicolumn{1}{l|}{Downsample} & \multicolumn{4}{c}{RepMSDW $7 \times 7$, Stride 2} \\ 
\cline{4-7} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Dims ($C_i$)} & \multicolumn{1}{c|}{320} & \multicolumn{1}{c|}{384}  & \multicolumn{1}{c|}{384} & \multicolumn{1}{c}{512}  \\ 
\cline{3-7} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{Mixer}  & \multicolumn{4}{c}{ RepSA $7 \times 7$ }  \\
\cline{3-7}
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{FFN ($r$)}  & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c|}{3} & \multicolumn{1}{c}{3}   \\ 
\cline{3-7} 
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{} & \multicolumn{1}{l|}{\#Blocks} & \multicolumn{1}{c|}{4}  & \multicolumn{1}{c|}{4}  & \multicolumn{1}{c|}{4} & \multicolumn{1}{c}{4} \\ 
\hline
\multicolumn{3}{c|}{Classifier Head} & \multicolumn{4}{c}{Avg Pool, FC (1280) }\\ \hline
\end{tabular}
\label{tab:arch_variant}
\end{center}
\end{table}


\subsection{Fast-FCOS}
We enhanced the FCOS by employing the proposed RAViT as the backbone for fast object detection in driving scenes. Additionally, we introduced a Reparameterized Feature Pyramid Network (FPN) for multi-scale feature extraction within the neck section of FCOS. As illustrated in Fig. \ref{fig:RepFPN}, we utilized three feature levels from the RAViT backbone, $F3, F4,$ and $F5$, and substituted the original $3\times3$ convolution of the typical FCOS FPN with a sequence of RepMSDW and $1\times1$ convolution after the aggregation of two scale features. RepMSDW is capable of extracting spatial features at different scales due to its multiple kernel scales, which can be reparameterized for a faster inference phase. 

In contrast to the original FCOS FPN that extends the three feature levels $\{F3, F4, F5\}$ from the backbone into five levels $\{P3, P4, P5, P6, P7\}$ with stride factors $\{8, 16, 32, 64, 128\}$, we employ only three feature levels $\{P3, P4, P5\}$ in a shared head for the classification of objects, center-ness, and bounding box regression. Since we use only three levels of features, the regression range is configured as 0, 128, 256, and 512 in the regression head. Due to the different sizes of feature levels, the regression range is adjusted with a different range for each level. The regression range of $P3$ is $\{0,128\}$, $\{128,256\}$ for $P4$ and $\{256,512\}$ for $P5$.    
