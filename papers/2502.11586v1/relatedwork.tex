\section{Related Work}
\noindent\textbf{Poetry Visualization:}
    Poetry visualization combines modern technology with ancient heritage and shows great implications for cultural preservation, education, and the arts. Very few previous methods have reported success in this combination \cite{liu2018beyond,wang2019constructing,xu2018images}. Li et al. \cite{li2021paint4poem} introduced the pioneering Chinese poetry art visualization dataset and assessed it using advanced text-to-image generation models like AttnGAN \cite{xu2018attngan} and MirrorGAN \cite{qiao2019mirrorgan}. \cite{jiang2024poetry2image} use ChatGPT and state-of-the-art text-to-image model to produce high-quality poetry visualization. However, all existing poetry visualization works only generate 2D images, and it is hard to deal with abstract poem lines. Here, we extend poetry visualization into the 3D domain, which can be used for AR/VR demonstration or free-viewpoint roaming. We also tackle a challenging poetry form -- Japanese Haiku, which distills emotions, seasons, and fleeting moments into a compact form. We specifically designed methods to extract Haiku's meaning and a method for high-fidelity text-to-3D conversion.

% \begin{figure*}[htbp]
% \centering
% \includegraphics[width=\textwidth]{image/pipline.pdf}
% \caption{\textbf{Overall Architecture.} Our objective is to transform classical Japanese Haiku into 3D scenes through six stages: (1) Haiku parsing using large language models (LLMs); (2) Text-to-Image Generation with Relay Diffusion; (3) Paranomic Image Generation with Panorama Diffusion; (5) Depth Map Generation with Depth Diffusion; (5) Geometric Optimization with 3D Gaussian Splatting; (6) Real-time Image Enhancement for immersive, navigable 3D scene visualization.} 
% \label{pipline}
% \end{figure*}
\begin{figure*}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{image/pipline.pdf}
\vspace{-0.3cm}
\caption{\textbf{Overall Architecture.} Our objective is to transform classical Japanese Haiku into 3D scenes through two stages: \textbf{H-LCTGP:} (1) Haiku parsing using large language models (LLMs); \textbf{PDS:} (2) Text-to-Image Generation with Relay Diffusion; (3) Paranomic Image Generation with Panorama Diffusion; (5) Depth Map Generation with Depth Diffusion; (5) Geometric Optimization with 3D Gaussian Splatting; (6) Real-time Image Enhancement for immersive, navigable 3D scene visualization.} 
\label{pipline}
\end{figure*}

\noindent\textbf{Text-to-3D Scene Generation:}
% https://arxiv.org/pdf/2501.02519
    Traditionally, constructing a 3D scene in the virtual world requires a substantial human effort. Recent progress of generative models brings new possibilities to this field. Few prior works have investigated text-to-3D generation. For example, Hollein et al. \cite{hollein2023text2room} employed a 2D inpainting diffusion model and a depth estimation model to iteratively generate scene grids. Scenescape \cite{fridman2024scenescape} follows a similar fashion and generates a 3D mesh based on text input. Zhang et al. \cite{zhang2024text2nerf} optimized NeRF-based scenes using images generated by a 2D diffusion model. However, methods based on NeRF or mesh typically require extensive optimization time. In contrast, our approach, similar to Dreamscene360 \cite{zhou2025dreamscene360} and Luciddreamer \cite{chung2023luciddreamer}, leverages 3D Gaussian Splatting (3DGS) to significantly reduce optimization time. Additionally, we have specifically developed techniques for Haiku Parsing and prompt engineering, along with a multi-stage text-to-3D pipeline to ensure the accuracy of the generated content. This comprehensive methodology represents a novel advancement that has not been previously explored.
\vspace{-0.2cm}