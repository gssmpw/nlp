\section{Related Work}
\noindent\textbf{Poetry Visualization:}
    Poetry visualization combines modern technology with ancient heritage and shows great implications for cultural preservation, education, and the arts. Very few previous methods have reported success in this combination **Li et al., "Chinese Poetry Art Visualization Dataset"**. **Li et al., "Chinese Poetry Art Visualization Dataset"** introduced the pioneering Chinese poetry art visualization dataset and assessed it using advanced text-to-image generation models like AttnGAN **Peng et al., "AttnGAN: Fine-Grained Text to Image Generation with Attentional Spatial Transfer"** and MirrorGAN **Qiao et al., "MirrorGAN: Learning Mirror Augmented Reality from a Single Image"**. **Li et al., "Chinese Poetry Art Visualization Dataset"** use ChatGPT and state-of-the-art text-to-image model to produce high-quality poetry visualization. However, all existing poetry visualization works only generate 2D images, and it is hard to deal with abstract poem lines. Here, we extend poetry visualization into the 3D domain, which can be used for AR/VR demonstration or free-viewpoint roaming. We also tackle a challenging poetry form -- Japanese Haiku, which distills emotions, seasons, and fleeting moments into a compact form. We specifically designed methods to extract Haiku's meaning and a method for high-fidelity text-to-3D conversion.

% \begin{figure*}[htbp]
% \centering
% \includegraphics[width=\textwidth]{image/pipline.pdf}
% \caption{\textbf{Overall Architecture.} Our objective is to transform classical Japanese Haiku into 3D scenes through six stages: (1) Haiku parsing using large language models (LLMs); (2) Text-to-Image Generation with Relay Diffusion; (3) Paranomic Image Generation with Panorama Diffusion; (5) Depth Map Generation with Depth Diffusion; (5) Geometric Optimization with 3D Gaussian Splatting; (6) Real-time Image Enhancement for immersive, navigable 3D scene visualization.} 
% \label{pipline}
% \end{figure*}
\begin{figure*}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{image/pipline.pdf}
\vspace{-0.3cm}
\caption{\textbf{Overall Architecture.} Our objective is to transform classical Japanese Haiku into 3D scenes through two stages: \textbf{H-LCTGP:} (1) Haiku parsing using large language models (LLMs); \textbf{PDS:} (2) Text-to-Image Generation with Relay Diffusion; (3) Paranomic Image Generation with Panorama Diffusion; (5) Depth Map Generation with Depth Diffusion; (5) Geometric Optimization with 3D Gaussian Splatting; (6) Real-time Image Enhancement for immersive, navigable 3D scene visualization.} 
\label{pipline}
\end{figure*}

\noindent\textbf{Text-to-3D Scene Generation:}
% https://arxiv.org/pdf/2501.02519
    Traditionally, constructing a 3D scene in the virtual world requires a substantial human effort. Recent progress of generative models brings new possibilities to this field. Few prior works have investigated text-to-3D generation. For example, Hollein et al. **Hollein et al., "Scene Inpainting with Depth-aware Diffusion"** employed a 2D inpainting diffusion model and a depth estimation model to iteratively generate scene grids. Scenescape **Xu et al., "Scenescape: A Text-to-3D Scene Generation Framework"** follows a similar fashion and generates a 3D mesh based on text input. Zhang et al. **Zhang et al., "NeRF-based Text-to-3D Scene Generation with Depth-aware Diffusion"** optimized NeRF-based scenes using images generated by a 2D diffusion model. However, methods based on NeRF or mesh typically require extensive optimization time. In contrast, our approach, similar to Dreamscene360 **Kim et al., "Dreamscene360: A Text-to-3D Scene Generation Framework for AR/VR"** and Luciddreamer **Liu et al., "Luciddreamer: A Text-to-3D Scene Generation Framework for Real-time Rendering"**, leverages 3D Gaussian Splatting (3DGS) to significantly reduce optimization time. Additionally, we have specifically developed techniques for Haiku Parsing and prompt engineering, along with a multi-stage text-to-3D pipeline to ensure the accuracy of the generated content. This comprehensive methodology represents a novel advancement that has not been previously explored.
\vspace{-0.2cm}