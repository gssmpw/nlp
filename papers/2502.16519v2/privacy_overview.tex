\section{Overview on Computing the \propa}
\label{sec:overview}
In this section, we present our ideas to efficiently compute the \propa. %using formal verification methods (\Cref{sec:our_approach} provides details). 
%\tool relies on the following ideas.
First, we formalize \propa as a constrained problem (MILP), which can be solved by existing solvers %(~\Cref{sec:overview_opt}). 
%This formalization enables searching within the continuous bound domain and the input domain across all $|\mathcal{S}|+1$ classifiers to find the minimal bound where the DP-DB property holds. 
but its complexity is very high. %: it is exponential in the multiplication of the network size and the training set size.
To cope, we abstract the analyzed networks using a \emph{hyper-network}. To mitigate the abstraction's overapproximation error, we introduce a branch-and-bound technique that refines a hyper-network into multiple hyper-networks, each abstracts a disjoint set of networks. %The refinement is invoked upon detecting an overapproximation error. 
%is We first explain the complexity of solving our optimization problem and then introduce three ideas aimed at simplifying solving it.  
%First, we propose a Hyper branch-and-bound approach. 
%Rather than solving the optimization problem for all the classifiers simultaneously, our approach divides them into closely related subgroups. 
%Each of these groups can be combined into a hyper-network (defined later), allowing for creating an optimization problem that computes a bound for this subgroup. 
%This process continues until the DP-DB is found over all classifiers. 
To further reduce the complexity, we bound the differences of matching neurons in a network and a hyper-network and %computing that can be encoded into the optimization problem to accelerate its solution. 
%These dependencies arise from the similarity between classifiers, as they are results of executing the same algorithm while only excluding a single input. 
add them as linear constraints or, if they are small, employ linear relaxation.
%a similarity encoding, leveraging the similarity between the classifiers. %$D$ and the classifiers subgroups. 
%This is intended to simplify the overall complexity of finding the minimal bound at the cost of overapproximation error.
%We next describe our ideas.

\subsection{Encoding \propa as a MILP}
\label{sec:overview_opt}
We express the problem of computing the \propa, which is a constrained optimization, as a mixed-integer linear program (MILP).    
MILP has been employed by many verifiers for solving constrained optimizations, e.g.,  %proven successful in addressing a variety of search challenges in different fields. 
%These include finding adversarial examples, which focus on a single input and a perturbation type~\cite{ref_67,ref_68,ref_69,ref_70}; 
local robustness~\cite{ref_86,ref_49,ref_42}, global robustness properties~\cite{ref_5,ref_6,ref_7}, and privacy in local neighborhoods~\cite{ref_8}.
Compared to these verifiers, computing \propa is much more complex: it is a global property (pertaining to any input) \emph{and} over a very large number of networks (the size of the training set plus one), which is the reason we rely on additional ideas to scale the computation.
%This increased complexity arises from our need to compare all possible outputs across a very large number of classifiers. 
An advantage of existing MILP optimizers is that they are anytime algorithms. That is, the optimizer can return at any point an interval bounding the value of the optimal solution (given enough time, this interval contains only the optimal value).

%To rely on MILP solvers, we express \propa is a MILP. 
Recall that for $c\in C$, the \propa is the maximal $\beta_c$ satisfying $\mathcal{C}_{N}^c(x) \geq \beta_c \land \bigvee_{ x_D \in D}\ \mathcal{C}_{N_{-x_D}}^c(x) \leq 0$ (\Cref{dpdbc}). 
 A straightforward MILP leverages prior work for encoding the classification confidence~\cite{ref_42} and
encodes the disjunction (i.e., $\bigvee$) %which is not supported by standard optimizers, %
using the Big M method~\cite{ref_73,ref_75}.
However, this MILP has an exponential complexity in $|D|$ and the multiplication of
the number of non-input neurons in $N$ and $|D|+1$. 
This is because a MILP's complexity is exponential in the number of boolean variables and this encoding introduces $|D|$ boolean variables for the disjunction and a unique boolean variable for every non-input neuron in every network.
%In this encoding, if $a_s=1$, the constraint $ \mathcal{C}^c_{D_{-s}}(x) \leq 0$ must hold, while if $a_s=0$, since $M$ is very large, 
%effectively there is no constraint on $\mathcal{C}^c_{D_{-s}}(x)$. 
%The sum constraint requires that at least one $a_s$ is $1$, thereby requiring to satisfy the original disjunction. 
%In~\Cref{sec:our_approach_milp}, we describe the encoding of the classification confidence. At a high-level, it includes linear constraints for every neuron. The encoding of a non-input neuron consists of constraints for the non-linear ReLU, which are defined over a unique boolean variable. 
%Since a MILP's complexity is exponential in the number of boolean variables, 
%Consequently, while optimizers can theoretically handle Problem~\ref{problem1}, 
%\Cref{problem1}'s complexity is exponential in $|\mathcal{S}|$ and the multiplication of
%the number of non-input neurons in $D$ and $|\mathcal{S}|+1$.


%assuming a very large number $M$ and associating a boolean variable for every constraint in the disjunction, denoted by $a_s\in \{0,1\}$ for every $s \in \mathcal{S}$.
%This results in an equivalent formulation:
%\begin{problem}[Numerical Optimization for the DP-DB]\label{problem1}
%\begin{equation}
%  \begin{gathered}
%     \max \beta_c \;\;\;\text{subject to} 
%     \\
%     \mathcal{C}_{D}^{c}(x) \geq \beta_c 
%     \;\land\; 
%     \sum_{s \in \mathcal{S}} \alpha_s \geq 1
%     \;\land 
%     \bigwedge_{s \in \mathcal{S}} \mathcal{C}^c_{D_{-s}}(x) \leq M\cdot(1-\alpha_i) %, \alpha_i \in \{0, 1\}
%  \end{gathered}
%\end{equation}
%\end{problem}
%In this encoding, if $a_s=1$, the constraint $ \mathcal{C}^c_{D_{-s}}(x) \leq 0$ must hold, while if $a_s=0$, since $M$ is very large, 
%effectively there is no constraint on $\mathcal{C}^c_{D_{-s}}(x)$. 
%The sum constraint requires that at least one $a_s$ is $1$, thereby requiring to satisfy the original disjunction. 
%In~\Cref{sec:our_approach_milp}, we describe the encoding of the classification confidence. At a high-level, it includes linear constraints for every neuron. The encoding of a non-input neuron consists of constraints for the non-linear ReLU, which are defined over a unique boolean variable. 
%Since a MILP's complexity is exponential in the number of boolean variables, 
%Consequently, while optimizers can theoretically handle Problem~\ref{problem1}, 
%\Cref{problem1}'s complexity is exponential in $|\mathcal{S}|$ and the multiplication of
%the number of non-input neurons in $D$ and $|\mathcal{S}|+1$.
%While this approach makes the problem tractable for standard optimizers, introducing a large number of Boolean variables into the optimization problem and encoding all the classification confidences (classifiers outputs) at once substantially increases its complexity, posing a significant computational challenge even for state-of-the-art optimizers. 

A naive approach to cope with this complexity is to express the \propa as $|D|$ separate MILPs $\{P_{x_D} \mid x_D \in D \}$, where $P_{x_D}$ is
$\beta_{c,\{x_D\}}^*=\text{argmax}_{\beta} \exists x 
\left(\mathcal{C}_{N}^c(x) \geq \beta \land \mathcal{C}_{N_{-{x_D}}}^c(x) \leq 0\right )$.
Each MILP is submitted to the solver and the \propa is the maximum: $\beta_c^* = \max_{x_D\in D}\beta^*_{c,\{x_D\}}$. 
The complexity of this naive approach is $|D|$ times the complexity of each MILP $P_{x_D}$, which is exponential in the multiplication of the number of non-input neurons in $N$ and two.
%involves splitting the single optimization problem (Problem~\ref{problem1}) into $|\mathcal{S}|$ separate optimization problems, where in each, only one Boolean variable is active and the others remain inactive. 
%Consequently, only two classifiers are encoded: the original classifier $D$ and the classifier $D'_{i}$ corresponding to the active Boolean. 
%
%Each problem computes a minimal bound, $\beta^i_{\text{MIN}}$. 
%After solving all these optimization problems, the minimal DP-DB bound can be computed by taking the maximum value, $\beta_{\text{MIN}} = \max_i(\beta_i)$. 
However, the naive approach is impractical because it requires solving a large number of MILPs. Additionally, since it requires the bound of all $|D|$ problems, %it cannot provide an anytime solution. 
obtaining an anytime solution requires obtaining an anytime solution to all $|D|$ problems, which is computationally expensive. %This is because an anytime solution requires solving all the problems in $\{P_s \mid s\in \mathcal{S}\}$, which is highly computation intensive.%(unlike \tool), this approach cannot provide an anytime solution. %, and requires . , meaning a sound bound can only be derived after all the problems have been solved. 
%To address these challenges, we propose a more efficient approach that we call Hyper Branch-and-Bound. This method leverages a Branch-and-Bound (BaB) strategy combined with a concept we call a hyper-network.

\begin{comment}
Our minimal DP-DB bound is defined as the smallest bound above which no input causes the classifier $D$ to classify differently compared to any of the $|\mathcal{S}|$ classifiers $D'_{i \in [|\mathcal{S}|]}$. 
We compute this bound by addressing the dual problem identifying the maximal bound $\beta^*$ where at least one input causes classification differences, and then incrementing this by a very small number $\Delta$. This $\Delta$ represents a negligible quantity, reflecting the floating point precision. Namely, if $\beta^*$ is the maximal bound with classification differences, then $\beta^* + \Delta$ is the minimal bound without classification differences. We next formalize:

\begin{problem}[Minimal DP-DB bound]
\begin{equation}\label{problem}
  \begin{gathered}
     \max \beta^*\\%\\
     \text{subject to}\hspace{0.25cm}\hspace{6.1cm} \\
     \exists x.\; \text{ such that } 
     S_{D}^{\beta^*}(x,c)>\Delta\;\land
     \bigvee_{i\in[|\mathcal{S}|]}S_{D'_i}(x,c)\leq0
    \end{gathered}
\end{equation}
\end{problem}
\end{comment}

\subsection{Hyper-Networks}\label{sec:overview_hyper}
To define a MILP with a lower complexity, we rely on \emph{hyper-networks}.
% is to employ a novel branch-and-bound, defined over a \emph{set of classifiers}. 
%To this end, we propose to abstract all classifiers $D_s$ using a \emph{hyper-network}. In this section, we define hyper-networks.
%The key idea is to iteratively subdividing the set of $\mathcal{S}$ classifiers into subgroups.
%For each subgroup, we solve Problem~\ref{problem1} and then subdivide again until the optimal solution is reached. 
%Each subgroup of networks comprises what we call a hyper-network.   
%
A hyper-network abstracts a set of networks by associating the network parameters' \emph{intervals}, defined by the minimum and maximum values over all networks. Formally:
%The hyper-network combines the parameters (weights and biases) of its networks subgroup into a single entity defined by the parameter ranges (minimum and maximum values) of the networks subgroup. 
%We next formalize the definition of a hyper-network:

\begin{definition}[A Hyper-Network]\label{over:Hyper}
Given a set of networks $\mathcal{N}=\{N_n \mid n\in [K]\}$ of the same architecture, each with weights $\mathcal{W}_{n} = \{w^n_{1,1,1},\ldots,w^n_{L,k_L,k_{L-1}}\}$ and biases $\mathcal{B}_{n}=\{b^n_{1,1},\ldots,b^n_{L,k_L}\}$, a \emph{hyper-network} $N^\#$ is a network of the same architecture such that $w_{m,k,k'}^\# = [\min_{n\in[K]}(w^n_{m,k,k'}), \max_{n\in[K]}(w^n_{m,k,k'})]$ and $b_{m,k}^\#=[\min_{n\in[K]}(b^n_{m,k}),\max_{n\in[K]}(b^n_{m,k})]$.
\end{definition}

\Cref{fig::hyper_bab} shows an example of four networks $N_{-1},\ldots,N_{-4}$ and their hyper-network $N^\#_{1,2,3,4}$. For example, since the values of $z_{1,1}$'s bias in the networks are $0.1$, $0$, $0.1$, $0.3$, its interval in the hyper-network is $[0,0.3]$.
A hyper-network introduces an overapproximation error. This is because it abstracts every network whose parameters are contained in their respective hyper-network's intervals. Formally, a hyper-network $N^\#$ abstracts every network $N'$ whose weights satisfy $w_{m,k,k'}\in w_{m,k,k'}^\#$ and biases satisfy $b_{m,k}\in b_{m,k}^\#$. For example, the hyper-network $N^\#_{1,2,3,4}$ in~\Cref{fig::hyper_bab} abstracts the network that is identical to $N_{-1}$ except that the bias of $z_{1,1}$ is $0.2$, even though this network is not one of the four networks used to define this hyper-network. 
 We note that hyper-networks have been proposed by~\citet{ref_8}, however, their focus is different: they predict a hyper-network from a subset of networks.
 
 Given a subset of the dataset $S\subseteq D$, we define the set of networks of $S$ as $\mathcal{N}_S=\{N_{-x_D}\mid x_D \in S \}$ and denote the hyper-network abstracting the set of networks $\mathcal{N}_S$ by $N^\#_S$.
The \propa of $S$ is defined as the following constrained optimization over its hyper-network $N^\#_{S}$:
\begin{align}\label{dphyp}
\beta^*_{c,S}=\text{argmax}_\beta \exists x 
\left( 
\mathcal{C}_{N}^c(x) \geq \beta \land \mathcal{C}_{{N}_{S}^\#}^{c}(x) \leq 0\right )
\end{align}
%propose to replace the disjunction in \Cref{problem1} with a constraint over $D^\#_{\mathcal{S}}$:  
%$\mathcal{C}_{D}^{c}(x) \geq \beta_c \;\land\; \mathcal{C}_{{D}_\mathcal{S}^\#}^{c}(x) \leq 0 $. 
Similarly to~\Cref{sec:overview_opt}, we can encode this problem as a MILP, where the neurons' weighted sums depend on the hyper-network's intervals.
By solving this MILP for $S=D$,
we can overapproximate the true \propa (\Cref{dpdbc}) by a greater or equal bound.
This follows since $\beta^*_c= \max_{x_D \in D }\beta^*_{c,\{x_D\}}$ and $\forall x_D \in D.\ \beta_{c,\{x_D\}}^*\leq \beta^*_{c,D}$. 
This MILP's complexity is exponential in $2\cdot |N|$, where $|N|$ is the number of non-input neurons.
This complexity is significantly lower than the complexity of the approaches of \Cref{sec:overview_opt}. 
%This significantly reduces the problem's complexity, since the number of boolean variables is only twice the number of non-input neurons. %number of optimization problems that need to be solved merging them into only a single problem. 
%Additionally, it reduces the solution complexity by omitting the Booleans that arise from the join operator and by encoding several classifiers together. 
Also, by expressing the problem as a single MILP (unlike the naive approach), we can benefit from the solver's anytime solution.
However, the overapproximation error is high: %of the true \propa (\Cref{dpdbc}), i.e., this bound is greater or equal to the true bound. 
%In practice,  
$\beta^*_{c,D}$ is significantly larger than the true \propa, because it considers \emph{every} network abstracted by the hyper-network, even networks that are not used to define the hyper-network.
Having a significantly larger bound than the true \propa would lead \tool to add much more noise than necessary to make the label-only access to the network \propi, and thus significantly decrease its accuracy. We next explain how to compute the true \propa with hyper-networks.

 
 %resulting in a single higher than  the solution obtained using this approach is not tight. 
%This limitation stems from the hyper-network representing a set of distinct networks by intervals, considering combinations of networks that were not part of the original set. 
%Consequently, this leads to an overapproximation error, which increases the \propa value. 
\begin{figure}[t]
    \centering
  \includegraphics[width=1\linewidth, trim=0 135 0 0, clip,page=6]{images/figures.pdf}
    \caption{An example of a hyper-network and our branch-and-bound.}
    \label{fig::hyper_bab}
\end{figure}

\subsection{A Branch-and-Bound for Hyper-Networks}\label{sec:overview_bab}
In this section, we present a novel branch-and-bound technique that enables us to compute the true \propa using hyper-networks. 


At a high-level, a branch-and-bound (BaB) technique is defined over a verification analysis of abstract objects and it eliminates the analysis' overapproximation error. Given an abstract object, it runs the analysis, which returns a value. If this value is smaller or equal to a certain bound (the object is \emph{bounded}), it terminates. If this value is greater than the bound, the object is refined to several abstract objects (the object is \emph{branched}) and this operation continues for each abstract object. BaB terminates when there are no more objects to branch. Its main advantages are: (1)~it attempts to reduce the overall execution time of the analysis by analyzing abstract objects instead of analyzing independently a large (or even infinite) set of concrete objects and (2)~it does not lose precision despite of analyzing abstract objects, since if the analysis returns a value above the bound, the abstract object is refined.
Thanks to these advantages, several BaB techniques have been proposed for local robustness verification~\cite{ref76,ref77,ref78,ref79,ref80,ref81}. %for reducing the analysis complexity while keeping it precise. %by focusing on input and activation functions splitting. 
However, determining local robustness is simpler than computing the \propa, since it requires analyzing the predicted labels of a single network for a set of inputs. In contrast, computing the \propa requires analyzing the predicted labels of a \emph{large set of networks} for \emph{any input}. %approach splits the classifiers into subgroups based on the similarity of their parameters (weights and biases). 

We propose a new BaB technique to compute the precise \propa. Its verification analysis takes as input a hyper-network abstracting the set of networks of a set $S$ and it computes the \propa of $S$ (\Cref{dphyp}).
%Thus, the question is how to adapt branch-and-bound to enable an efficient computation of the true \propa from a hyper-network, despite its inherent overapproximation loss. To answer this question, 
%We next introduce our BaB's branching and our BaB's bounding.
%
For branching, our BaB refines a hyper-network $N^\#_S$ into $K$ hyper-networks $\{N_{S_1}^\#,\ldots,N_{S_K}^\#\}$, such that the sets $S_1, \ldots,S_K$ partition $S$.
%(i.e., $\bigcup_{i\in [K]} S_i=S$ and $S_i \cap S_j=\emptyset$, for all $i\neq j$)
Our BaB defines the partitioning by clustering the networks in $\mathcal{N}_S$ based on their parameters' similarity. 
The motivation for this clustering is that classifiers whose parameters have closer values are likely to have closer \propa. Consequently, their hyper-network's \propa is likely to have a lower overapproximation error, which increases the likelihood to succeed bounding it and avoid further branching.  
 %We introduce our similarity metric and clustering in~\Cref{sec:our_approach}.


For bounding, we rely on the following observation. Given a set $S$, if its \propa $\beta^*_{c,S}$ is \emph{smaller or equal to} $\beta^*_{c,\{\hat{x}_D\}}$ for some $\hat{x}_D \in D$, then $N^\#_S$ need not be branched. This is because the true \propa is $\beta_c^* = \max_{x_D \in D}\beta^*_{c,\{x_D\}}$ and $\forall x_D'\in S.\ \beta^*_{c,\{x_D'\}}\leq \beta^*_{c,S}$. By transitivity,  $\forall x_D'\in S.\ \beta^*_{c,\{x_D'\}}\leq \beta^*_{c,\{\hat{x}_D\}}\leq \beta^*_{c}$. Namely, our BaB bounds hyper-networks by the \propa of hyper-networks that abstract a single network (in which case there is no overapproximation error). 

%This method allows minimizing the over-approximation error resulted from the hyper-network which can significantly increase when classifiers are far apart. 
%By iteratively applying our Hyper Branch-and-Bound method, we can converge to the optimal solution while effectively bounding the other possible solutions. This is achieved efficiently by focusing on subdividing the hyper-networks with the maximal \propa bound into smaller subgroups. When the Branch-and-Bound approach creates a hyper-network composed of a single network—where the bound is larger than those of the other hyper networks it can halt and return the optimal solution. 

Our BaB has several advantages. First, it computes the precise \propa. % (if branch is invoked whenever a hyper-network is not bounded). 
Second, it can provide an anytime solution: if it early stops, it returns an overapproximation of the \propa. Third, it relies on MILPs over hyper-networks, which reduces the number of boolean variables compared to the straightforward MILP encoding. Fourth, it dynamically identifies a minimal number of MILPs for computing the \propa. Fifth, it orders the analysis of the hyper-networks to increase the chances of bounding them (described in~\Cref{sec:ourapp_sys}).
%(1) Any-time, allowing for progressive refinement and early stopping, 
%(2) Efficient in reducing the number of Boolean variables required by Problem~\ref{problem1}, 
%and (3) Effective in decreasing the number of optimization problems necessary to achieve the optimal solution. 
%Next, we illustrate our Hyper Branch-and-Bound approach with an example.

%The underlying logic is that classifiers with closer parameters are likely to have similar \propa bounds. This method allows minimizing the over-approximation error resulted from the hyper-network which can significantly increase when classifiers are far apart. 
%By iteratively applying our Hyper Branch-and-Bound method, we can converge to the optimal solution while effectively bounding the other possible solutions. This is achieved efficiently by focusing on subdividing the hyper-networks with the maximal \propa bound into smaller subgroups. When the Branch-and-Bound approach creates a hyper-network composed of a single network—where the bound is larger than those of the other hyper networks it can halt and return the optimal solution. 
%Note that our Hyper Branch-and-Bound method is:
%(1) Any-time, allowing for progressive refinement and early stopping, 
%(2) Efficient in reducing the number of Boolean variables required by Problem~\ref{problem1}, 
%and (3) Effective in decreasing the number of optimization problems necessary to achieve the optimal solution. 
%Next, we illustrate our Hyper Branch-and-Bound approach with an example.


%\paragraph{Example.}  
\Cref{fig::hyper_bab} exemplifies our BaB for computing the \propa of $c=0$ for a classifier $N$ (top %highlighted by orange at the upper 
left) %comprising two inputs, $x_{1}, x_{2} \in [0,1]$, two outputs $z_{2,1}, z_{2,2}$, and one hidden layer. 
%The weights of the network are depicted by the edges, and the biases by the neurons.
 and four networks $\{N_{-1}, N_{-2}, N_{-3}, N_{-4}\}$ (top). %We focus on the class $c=0$ to simplify notations, we omit it from the bounds.  %that are closely related to $D$ with identical architecture and parameter structures. 
%\Dana{can we remove the following sentence? where do we take into account c=0?} We focus on $c=0$, where the goal is to compute the maximal \propa at which the network $D$ classifies to $c=0$, and at least one of the other classifiers does not classify to $c=0$. 
To simplify notation, we omit the subscript $c=0$ from the \propa.
The naive approach (\Cref{sec:overview_opt}) solves four optimization problems $P_{x_D}$ for $x_D \in [4]$ and returns their maximum (obtained for $P_4$ in this example): $\beta^* = \beta^*_4=0.52$. 
In contrast, our BaB obtains the same bound by solving only three MILPs of the same complexity as $P_{x_D}$. Our BaB begins by computing the \propa of $\{1,2,3,4\}$, which is $\beta^*_{1,\ldots,4}=0.55$ (bottom center).
Although we know upfront that this \propa is not tight, our BaB computes it to provide an anytime solution. %Its Solving this optimization problem provides a sound bound $\beta = 0.55$, which can be computed in an any-time manner due to the optimization formalism. 
Since this hyper-network is not bounded by any \propa of a single network, it is branched.  
To this end, our BaB clusters the networks based on their similarity. This results in the partitioning $\mathcal{N}_{1,2,3}$ and $\mathcal{N}_{4}$. Accordingly, two hyper-networks are constructed (bottom left and right). 
For each, our BaB solves the respective MILP, returning $\beta^*_{1,\ldots,3}=0.21$ and $\beta^*_{4} =0.52$. Since 
 $\beta^*_{1,\ldots,3}\leq\beta^*_4$, it bounds the hyper-network ${N}^\#_{1,2,3}$. Similarly, it bounds ${N}^\#_4$ by $\beta^*_{4} $.  
Then, our BaB terminates and returns $0.52$.




\subsection{Matching Dependencies and Relax-If-Similar}\label{sec:overview_match}
%So far, we described how to compute the \propa by submitting to the optimizer problems over a network and a hyper-network, instead of $|\mathcal{S}|+1$ networks, in order to reduce the problem's complexity. However, the complexity of this problem is still exponential in $2\cdot |D|$, where $D$ is the number of non-input neurons. 
In this section, we describe two techniques to further reduce the complexity of the MILP of~\Cref{dphyp}. 
Both techniques rely on computing bounds for the differences of matching neurons in the network and the hyper-network.
The first technique, \emph{matching dependencies}, encodes these differences as linear constraints, for every pair of matching neurons, to prune the search space. The second technique, \emph{relax-if-similar}, overapproximates neurons in the hyper-network whose difference is very small by linear relaxation. It reduces the complexity's exponent by one for every overapproximated neuron. While overapproximation reduces the precision, it is employed when the difference is small and combined with the matching dependencies, the precision loss is small. 
  
%Recall that utilizing our hyper branch-and-bound approach, we transform solving Problem~\ref{problem1} into an iterative process. 
%At each iteration, we are required to solve the following optimization problem for a given hyper-network $D^\#$:
%$max\:\beta \; \text{ s.t. } S_{D}^{c}(x) > \beta \;\land\; S_{{D}_\mathcal{S}^\#}^{c}(x) \leq 0$. 
%To solve this optimization problem, \tool employs the widely used MILP (Mixed-Integer Linear Programming) approach for neural network encoding, as described in~\cite{ref_42}. 

These techniques rely on bounding the differences of matching neurons. A pair of matching neurons consists of a neuron $z_{m,k}$ in the network $N$ and its corresponding neuron in the hyper-network $N^\#$, denoted $z_{m,k}^\#$, whose output is a real-valued interval (since the weights and biases of a hyper-network are intervals).
We bound the difference of $z^\#_{m,k}$ and $z_{m,k}$ in an interval $[\Delta^l_{m,k},\Delta^u_{m,k}]\in \mathbb{R}^2$ overapproximating the expression $z^\#_{m,k}-[z_{m,k},z_{m,k}]$.
The difference intervals enable significant pruning to our search space, since in our setting the outputs of matching neurons are highly dependent. This is because the network and hyper-network accept the same input and since their respective weights and biases are very close, because $N$ and the networks used to define $N^\#$ are trained by the same training algorithm and their training sets only slightly differ. 
To compute the difference intervals, we rewrite the interval of every weight (and bias) in the hyper-network $[\underline{w^\#}_{m,k,k'},\overline{w^\#}_{m,k,k'}]$ in terms of the weight in $N$ plus a difference: $[w_{m,k,k'}- (w_{m,k,k'}-\underline{w^\#}_{m,k,k'}), w_{m,k,k'}+{(\overline{w^\#}_{m,k,k'}-w_{m,k,k'})}]$. 
%Further, \propa is defined over networks accepting the \emph{same} input. 
Then, we employ bound propagation %over the weighted sums and ReLU computations of every neuron 
(formalized in~\Cref{sec:our_approach_milp}) to overapproximate $z^\#_{m,k}-[z_{m,k},z_{m,k}]$, for all $m$ and $k$. 

The matching dependencies technique adds to %the MILP of~
\Cref{dphyp} the difference intervals.
For every non-input neuron $z_{m,k}$ and its difference interval $[\Delta^l_{m,k},\Delta^u_{m,k}]$, it adds the constraint: 
%The key idea is to explicitly encode closeness dependencies as linear constraints connecting the variables of the original network $D$ and the hyper-network $D^\#$. 
$z_{m,k} + \Delta^l_{m,k} \leq z^\#_{m,k} \leq z_{m,k} + \Delta^u_{m,k}$.
While these constraints can be added to any pair of networks, they are more effective for pruning the search space when $\Delta^u_{m,k}-\Delta^l_{m,k}$ is small, which is the case in our setting.
 
The relax-if-similar technique overapproximates the computation of neurons in the hyper-network if their difference interval is small. 
We remind that our MILP encoding of~\Cref{dphyp} leverages prior work for encoding the classification confidence~\cite{ref_42}.
This encoding introduces a unique boolean variable for every non-input neuron in the network and the hyper-network.
As described, the complexity of a MILP is exponential in the number of boolean variables. 
 To reduce the exponential complexity, prior work~\cite{ref_49,ref_7,ref_5,ref_6,ref_50} eliminates boolean variables by: 
 (1)~computing tight lower and upper bounds to identify neurons whose output is non-positive or non-negative, in which case their ReLU is stable and their boolean variable can be removed, and/or 
(2)~overapproximating the ReLU computations using linear constraints without boolean variables. 
Although in general overapproximation leads to precision loss, we observe that if the difference interval of a neuron $z_{m,k}^\#$ is small, we can overapproximate its computation without losing too much precision. This follows because its matching neuron $z_{m,k}$ is precisely encoded (with a boolean variable) and because the matching dependency of $z_{m,k}$ forces the value of $z^\#_{m,k}$ to remain close to $z_{m,k}$. 
Based on this insight, our relax-if-similar technique 
eliminates the boolean variable of $z_{m,k}^\#$ and replaces its ReLU constraints by linear relaxation constraints.
%Linear relaxation of ReLU has been proposed by prior work to scale the verification at the cost of loss in precision. However, our 
%linear relaxation is employed differently: \tool overapproximates only neurons in the hyper-network (and not the neurons in the network). As described, these neurons are bounded by the matching dependencies. This reduces the overapproximation error. Further, \tool employs similarity encoding only for neurons whose $\Delta^l_{m,k},\Delta^u_{m,k}$ are very small, and consequently, the overapproximation error is bounded. 
%To address this, we rely on closeness dependencies to propose an encoding scheme where we mutually encode pairs of neurons with closely matched values, using only a single Boolean. 
%Formally, we keep the precise encoding of the ReLU computation for neurons The key idea is to precisely encode the neuron $z_{m,k}$ using its Boolean variable $a_{m,k}$, as described in~\cite{ref_42}, and then 
These constraints capture the minimal triangle bounding
the piecewise linear function of ReLU 
using three linear constraints~\cite{Ehlers17}. 


%We begin with presenting at high-level the key ingredients of our optimization problem, encoding a network and a hyper-network (full details are provided in~\Cref{sec:our_approach_milp}). Our encoding extends the encoding of~\cite{ref_42}, proposed for analyzing local robustness of a given network in a given neighborhood. In this encoding, a neuron in layer $m$ and index $k$ is assigned a real-valued variable $z_{m,k}$, for capturing the neuron's output, and this output is defined using five linear constraints, defined over the neuron's inputs as well as on
% a unique boolean variable $a_{m,k}$, required for encoding the non-linear ReLU function. 
% Additionally, the analysis computes for every neuron real-valued lower and upper bounds: $z_{m,k}\in[l_{m,k},u_{m,k}]$.
% The problem's complexity is exponential in the number of boolean variables, which is the number of non-input neurons. 
% To reduce the exponential complexity, prior work~\cite{ref_50,ref_49,ref_7,ref_5,ref_6} eliminates boolean variables by: 
% (1)~tightening the lower and upper bounds $[l_{m,k},u_{m,k}]$ to identify neurons whose output is non-positive or non-negative, in %which case their ReLU is stable and their boolean variable can be removed, and/or 
%This method identifies ReLU computations that are in a stable state (i.e., their inputs are consistently non-positive or non-negative). 
%(2)~over-approximating the ReLU computation using linear constraints without the boolean variables. 
%However, our problem is more challenging, since 
 %it is defined over any input (instead of a neighborhood) and is defined over a network and a hyper-network, requiring two copies of each variable. In the following, we denote by $^\#$ the variables of the hyper-network.
%This method assigns every neuron a unique real-valued variable along with a Boolean variable (which captures the functionality of the ReLU neuron). 
%\tool compares the outputs of two networks. 
%For the original network $D$, \tool assigns to each neuron $k$ in layer $m$ a continuous variable $z_{m,k}$ and a Boolean variable $a_{m,k}$. Similarly, for the hyper-network $D^\#$ (we extend~\cite{ref_42}'s encoding to support hyper-networks, as detailed later), it assigns a continuous variable $z^\#_{m,k}$ and a Boolean variable $a^\#_{m,k}$ to each corresponding neuron. 
%The increased number of optimization variables required to compute our property imposes a computational challenge to the optimizer. 

%Several previous works have proposed methods to reduce the complexity of network's MILP encoding mainly focusing on the Boolean variables~\cite{ref_50,ref_49,ref_71,ref_5,ref_6}. Two common approaches are: 
%(1) Computing the concrete lower and upper bounds of ReLU neurons by submitting additional optimization problems to the MIP solver. 
%This method identifies ReLU computations that are in a stable state (i.e., their inputs are consistently non-positive or non-negative). 
%(2) Over-approximating the nonlinear ReLU computation using linear constraints. 
%Given that we compute our property over a vast input domain (any-input), standard over-approximation approaches often result in significant loss of computational precision, thereby degrading the tightness of our bound.  

%We begin by describing the matching dependencies that \tool adds for each neuron to prune the search space. 
%We show how the closeness between our networks, which are generated through the same process, differing only in a single sample, and the fact that they receive identical inputs can be utilized to reduce computational complexity.
%These dependencies leverage the fact that the respective weights (and biases) of the network and each hyper-network are very close, since they are trained by the same procedure and only differ by few samples. This enables us to rewrite the interval of a weight in the hyper-network $[l_{m,k,k'}^\#,u_{m,k,k'}^\#]$ in terms of the weight in network plus a small difference: $[w_{m,k,k'}- (w_{m,k,k'}-l_{m,k,k'}^\#), w_{m,k,k'}+{(u_{m,k,k'}^\#-w_{m,k,k'})}]$. 
%Further, \propa is defined over networks accepting the \emph{same} input. Thus, by 
%employing bound propagation taking into account the linear and ReLU computations of every neuron (formalized in~\Cref{sec:our_approach_milp}), \tool
%derives a linear constraint for every neuron of the form: 
%The key idea is to explicitly encode closeness dependencies as linear constraints connecting the variables of the original network $D$ and the hyper-network $D^\#$. 
%$z_{m,k} - \Delta^l_{m,k} \leq z^\#_{m,k} \leq z_{m,k} + \Delta^u_{m,k}$.
%While these constraints can be added to any pair of networks, they are more effective for pruning when $\Delta^l_{m,k},\Delta^u_{m,k}$ are small, which is the case in our setting.
 %is a function of the difference in the networks parameters. Next, we provide an example to illustrate the closeness dependencies.  
%Encoding The closeness dependencies reduces the size of the search space and accelerates the performance of the optimizer. 
%However, it does not decrease the number of Boolean variables. 

%Next, we describe the similarity encoding, which eliminates boolean variables of neurons in the hyper-network by replacing their constraints with overapproximating linear constraints.
%Linear relaxation of ReLU has been proposed by prior work to scale the verification at the cost of loss in precision. However, our 
%linear relaxation is employed differently: \tool overapproximates only neurons in the hyper-network (and not the neurons in the network). As described, these neurons are bounded by the matching dependencies. This reduces the overapproximation error. Further, \tool employs similarity encoding only for neurons whose $\Delta^l_{m,k},\Delta^u_{m,k}$ are very small, and consequently, the overapproximation error is bounded. 
%To address this, we rely on closeness dependencies to propose an encoding scheme where we mutually encode pairs of neurons with closely matched values, using only a single Boolean. 
%Formally, we keep the precise encoding of the ReLU computation for neurons The key idea is to precisely encode the neuron $z_{m,k}$ using its Boolean variable $a_{m,k}$, as described in~\cite{ref_42}, and then 
%Technically, every neuron that \tool employs similarity encoding is bounded by a triangle confining 
%the piece-wise linear function of ReLU 
%by three linear constraints, as proposed by~\cite{Ehlers17}. %These constraints are defined as:
%(1) $ z^\#_{m,k} \geq 0, $ 
%(2) $ z^\#_{m,k} \geq \hat{z}^\#_{m,k}, $ 
%(3) $ z^\#_{m,k} \leq \frac{u^\#_{m,k}}{u^\#_{m,k} - l^\#_{m,k}} (\hat{z}^\#_{m,k} - l^\#_{m,k})$,  
%overapproximating the ReLU behavior, and the closeness dependency 
%$ z_{m,k} - \xi_{\Delta w} \leq z^\#_{m,k} \leq z_{m,k} + \xi_{\Delta w}$.
%This approach effectively controls the overapproximation error while reducing the number of Boolean variables, but only for pairs of neurons that have very close values. 
%We refer to this strategy as mutual encoding. Next, we provide an example explaining the closeness dependencies and the mutual encoding. 


\Cref{fig::closness_mutual_encoding} exemplifies these techniques on the network $N$ and the hyper-network $N^\#_{1,2,3}$ shown in~\Cref{fig::hyper_bab}. 
We have $\hat{z}_{1,1} = -x_1 + x_2$ and $\hat{z}^\#_{1,1} = -x_1 + [1,1.1]\cdot x_2+[0,0.1]$. We can write  $\hat{z}^\#_{1,1}$ as a function of $\hat{z}_{1,1}$ and obtain: $ \hat{z}^\#_{1,1} = z_{1,1} + [0,0.1]\cdot x_2+[0,0.1]$. 
These values pass through ReLU. Since the input $x_2$ ranges over $[0,1]$, we get that $ z^\#_{1,1}$ is between $z_{1,1}$ and ${z}_{1,1}+0.2$.
Thus, the matching dependency of $z^\#_{1,1}$ is:
%For these networks, we encode closeness dependencies between corresponding pairs of neurons: $z_{1,1}$ and $z^\#_{1,1}$, $z_{1,2}$ and $z^\#_{1,2}$. 
%The closeness dependency for the first pair at $(1,1)$ is expressed as: 
$ z_{1,1} \leq z^\#_{1,1} \leq z_{1,1} + 0.2$. 
Similarly, the matching dependency of $z^\#_{1,2}$ is: $ z_{1,2} - 0.02 \leq z^\#_{1,2} \leq z_{1,2} $. 
If we precisely encoded all neurons using a boolean variable for each non-input neuron, the computed \propa would be $\beta^*_{1,2,3}=0.21$. 
If we employed linear relaxation for $z^\#_{1,1}$ and $z^\#_{1,2}$, it would eliminate two boolean variables (thereby reducing the problem's complexity) but would result in an overapproximating bound $0.24$.
To balance, relax-if-similar employs linear relaxation only to similar neurons.
In this example, $z^\#_{1,2}$ is similar to $z_{1,2}$ (since $\Delta_{1,2}^l=-0.02$ and $\Delta_{1,2}^u=0$) while $z^\#_{1,1}$ is not similar to $z_{1,1}$  ($\Delta_{1,1}^l=0$ and $\Delta_{1,1}^u=0.2$). Namely, relax-if-similar eliminates one boolean variable (of $z^\#_{1,2}$) \emph{and} enables to compute the precise bound of $\beta^*_{1,2,3}=0.21$. 
% By applying mutual encoding (ME) across all neurons—replacing the precise encoding of the neurons in the hyper-network with triangle constraints and dependencies, we reduce the total number of Boolean variables to two, resulting in a computed bound of $\beta=0.24$.
%However, applying mutual encoding only to the neurons at position (1,2) reduces the total number of Boolean variables to three, with a computed bound of $\beta=0.21$. 
%This reduction is possible because the differences between the two neurons at (1,2) are negligible (up to 0.02), allowing \tool to decrease the number of Boolean variables with only a minor loss in the precision of the computed bound. 
%To maintain precision, \tool identifies the most closely related neurons and selectively applies mutual encoding only to them.  












\begin{figure}[t]
    \centering
  \includegraphics[width=1\linewidth, trim=0 348 0 0, clip,page=7]{images/figures.pdf}
    \caption{An example of the matching dependencies and relax-if-similar.}
    \label{fig::closness_mutual_encoding}
\end{figure}

