
\section{Our System: \tool} 
\label{sec:our_approach}
In this section, we describe our system \tool, %, our system for repairing a network to be \propi.
consisting of: (1) \boundtool, computing the \propa of every class using the verification techniques described in~\Cref{sec:overview}, %based on the ideas described in~\Cref{sec:overview},
and (2)~\reptool, creating \propi label-only access to the network, given the \propa of every class. 






\subsection{A System for Computing the \propa}\label{sec:ourapp_sys}
In this section, we describe \boundtool, our system for computing the \propa. 
 \Cref{alg:bab} provides its pseudo-code and \Cref{fig::system_description} illustrates it. 
Its inputs are a training set $D$, a training algorithm $\mathcal{T}$, a network architecture $\widetilde{N}$, and a class $c$. 
%a set of classifiers $\{D_{-s}\}$ where $s \in \mathcal{S}$, and a specific class $c$. 
It returns the \propa of $c$ (\Cref{dpdbc}). 
%$\beta^*_c=\text{argmax}_{\beta_c} \exists x \left(\mathcal{C}_{D}^c(x) \geq \beta_c \land \bigvee_{ s \in \mathcal{S}}\ \mathcal{C}_{D_{-s}}^c(x) \leq 0\right )$. 
%Computing \propa for every class $c$ enables \tool to increase the repair accuracy, since a joint bound for all classes $\beta^*=\max_c \beta^*_c$ would lead to adding a higher than necessary noise to all inputs that the network classifies as $c$ such that $\beta_c^*<\beta^*$.
%\tool runs \boundtool for every class $c$ and repairs the predicted labels if $S^c_D(x)\leq \beta^*_c$, where $c$ is the predicted class.  
 %For the given class $c$, \tool computes the maximal \propa, denoted $\beta_c$, at which it repairs the outputs of the classifier for any input classified as $c$. 
%To ensure the classifier is repaired for any possible input, \tool is executed for all classes $c \in [C]$. 


\begin{algorithm}[t]
\caption{\boundtool($D$, $\mathcal{T}$, $\widetilde{N}$, $c$)}
\label{alg:bab}
\DontPrintSemicolon
\KwIn{A dataset $D$, a training algorithm $\mathcal{T}$, a network architecture $\widetilde{N}$, and a class $c$.}
\KwOut{The \propa bound $\beta_c$.}
%\Parameter{$\beta_\text{anytime}$ = $\infty$ \tcp*{The \propa anytime bound.}}
%\Parameter{Subgroups list $\mathcal{D}=\emptyset$, optimal subgroup $\mathcal{C}=\emptyset$.}
$N$ = $\mathcal{T}(D ,\widetilde{N})$\tcp*{The network given the full dataset}\label{algbab_ln:initializationb}
$N_{D}$ = $\{(x_D,\mathcal{T}(D \setminus\{x_D\},\widetilde{N}))\mid x_D \in D\}$\tcp*{The networks given adjacent datasets}
%$\mathcal{C}.\text{classifiers} = \{D_{-s\in \mathcal{S}}\}$\; 
\label{algbab_ln:initialization}
$\beta_{c}$ = $\infty$ \tcp*{The \propa anytime bound} \label{ln:binit}
$Q$ = $[]$ \tcp*{A priority queue}\label{ln:qinit}
%$\mathcal{C}.\beta = \text{MAX\_FLOAT},\;\mathcal{C}.S = \text{False}$\;
$L$ = $\{D\}$ \tcp*{A list of sets to compute their {\propa}}\label{ln:linit}
%$\beta_{c,\text{anytime}}$ = $\infty$ \tcp*{The \propa anytime bound}
\While{True}{
    \For {$S\in L$}{
        $N^\#_S$ = defineHyperNetwork($\{(x_D,N_{-x_D})\in N_{D} \mid x_D \in S\}$)\;\label{ln:hyp}
        $e$ = encodeMILP($N$, $N^\#_S$, $c$)\;\label{ln:milp}
        $I$ = computeDifferenceIntervals($N$, $N^\#_S$)\;\label{ln:diff}
        $e$ = addMatchingDependencies($e$, $I$)\;\label{ln:mat}
        $e$ = relaxIfSimilar($e$,{ $\{[\Delta^l_{m,k},\Delta^u_{m,k}]\in I\mid \Delta^u_{m,k}-\Delta^l_{m,k}\leq \tau\}$})\;\label{ln:rel}
        $\beta_{c,S}$ = MILPSolver($e$)\;\label{algbab_ln:milp_optimization}
        push($Q$, ($S$, $\beta_{c,S}$))\;\label{algbab_ln:push_subgroup}
    }
    ($S$, $\beta_{c,S}$) = pop($Q$)\;\label{algbab_ln:pop_subgroup}
    $\beta_{c}=\beta_{c,S}$\;\label{ln:upb}
     \lIf{$|S|==1$}{break}\label{algbab_ln:break}
    %$\mathcal{C}.\beta = \text{Bound\_by\_MILP\_optimization}(\mathcal{C}.\text{classifiers},D,c)$\;\label{algbab_ln:milp_optimization}%(~\Cref{sec:our_approach_milp})
    %$\mathcal{D}.\textbf{Push}(\mathcal{C}\:|\:\mathcal{C}.S=\text{True})$\; \label{algbab_ln:push_subgroup}
    %$\mathcal{C} = \mathcal{D}.\textbf{Pop}( \text{argmax}_i \mathcal{D}_i.\beta  )$\; \label{algbab_ln:pop_subgroup}
    %\lIf{$|\mathcal{C}.\text{classifiers}| == 1 \; \land\; \mathcal{I}.S == \text{True}$} {\textbf{Break}} \label{algbab_ln:break}
    %\lElseIf{$\mathcal{C}.S == \text{False}$} {\textbf{Continue}} \label{algbab_ln:cont}
    %$\beta_{c,\text{anytime}}$ = $\beta_{c,S}$\;
    $L$ = partition($k$-\text{means\_elbow}, $\{(x_D,N_{-x_D})\in N_{D} \mid x_D  \in S\}$)\; \label{algbab_ln:kmeans}
    %\mathcal{C}.\text{classifiers}.\{w_{m,k,k'}\}\cup \{b_{m,k\}})$
    %\ForEach {$\mathcal{G}_i \in [\mathcal{G}]_K$}{     \label{algbab_ln:split}
    %   \If{$\mathcal{G}_i == \text{argmin}_{\mathcal{G}_j} |\mathcal{G}_{j\in K}|$}{ \label{algbab_ln:cont_with_minimal_1}
    %       $\mathcal{C}.classifiers = \mathcal{G}_i, \; \mathcal{C}.S = \text{False} $\label{algbab_ln:cont_with_minimal_2}
    %    }   
    %    \Else{
    %        $\mathcal{D}.\textbf{Push}(\mathcal{C^*}\:|\:\mathcal{C^*}.\text{classifiers} = \mathcal{G}_i,\:\mathcal{C^*}.\beta = \mathcal{C}.\beta,\:\mathcal{C^*}.S = \text{False})$  \label{algbab_ln:push_others}
    %    }  
    %}
   
  }
 \Return{$\beta_{c}$}\label{ln:ret}
%\Return{$\beta_c = \mathcal{C}.\beta$}  \label{algbab_ln:return}
\end{algorithm}


\boundtool first trains all networks for every possibility to omit up to one data point (\Cref{algbab_ln:initializationb}--\Cref{algbab_ln:initialization}). %: $\{D_{-s}\mid s \in \mathcal{S}\}$.
Then, it performs initializations. First, it initializes the anytime overapproximating bound of the \propa to $\infty$ (\Cref{ln:binit}). 
Next, it initializes a priority queue $Q$ consisting of the sets to branch or bound to an empty queue (\Cref{ln:qinit}). 
Lastly, it initializes a list $L$ consisting of the sets whose \propa is next computed to a list containing the dataset $D$ (\Cref{ln:linit}).
It then runs our BaB (described in~\Cref{sec:overview_bab}). 
Our BaB begins by running the verification analysis for all sets in $L$. 
For every set $S$ in $L$, the analysis constructs the hyper-network $N^\#_{S}$ over the networks in $S$ (\Cref{ln:hyp}). 
%This hyper-network enables \tool to capture the classification decisions across the entire network set $\{D_{-s\in \mathcal{S}}\}$. 
Then, it encodes \Cref{dphyp} as a MILP (\Cref{ln:milp}), which we define in~\Cref{sec:our_approach_milp}. 
% To compare the classification decisions of $D$ and $D^\#$, \tool formalizes a Mixed Integer Linear Programming (MILP) problem. 
%Within this MILP formalization, \tool encodes the any-input domain along with the classification confidences of both the original network $D$ and the hyper-network $D^\#$. 
It then computes the difference intervals (\Cref{ln:diff}), described in~\Cref{sec:overview_match} and defined in~\Cref{sec:our_approach_milp}. 
Accordingly, it adds the matching dependencies (\Cref{ln:mat}) and relaxes neurons whose difference interval is small (\Cref{ln:rel}). %\tool simplifies solving the MILP problem by encoding closeness dependencies that arise from the similarity between the networks, taking advantage of the fact that they analyze outputs under the same input constraint $x$. 
%Additionally, \tool employs a mutual encoding technique to reduce the number of Boolean variables in the encoding. 
It then submits the MILP to a MILP solver (\Cref{algbab_ln:milp_optimization}), which returns a bound $\beta_{c,S}$. 
The set $S$ and its bound $\beta_{c,S}$ are pushed to the priority queue $Q$ (\Cref{algbab_ln:push_subgroup}). 
We next describe the role of $Q$. 

As described, after computing $\beta_{c,S}$, the problem of $S$ (\Cref{dphyp}) is either branched or bounded.  
%Unlike common BaB where the bound is known upfront (e.g., in local robustness the bound is often zero~\cite{ref77,ref78,ref79}), 
$S$ is bounded if our BaB computes $\beta_{c,S'}$ where $\beta_{c,S}\leq \beta_{c,S'}$ and $|S'|=1$. 
%value discovered during the execution, when computing a bound of a hyper-network abstracting a single network. 
To reduce the number of branched problems, %(which governs the complexity of our analysis),
 \boundtool \emph{lazily} branches. In each iteration, it branches the problem $S$ that must be branched, which is the one with the maximal bound $\beta_{c,S}$.  
%As described, the first optimization problem must be branched. 
To identify this problem, \boundtool prioritizes in $Q$ the pairs by their bound, such that the next pair that is popped is the one with the maximal bound. 
%
If \boundtool pops from $Q$ a pair $(S,\beta_{c,S})$ whose $S$ is a singleton $\{x_D\}$, it bounds this problem along with the problems of \emph{all} pairs in the queue (\Cref{algbab_ln:break}). At this point, all problems are handled and \boundtool returns $\beta_{c,S}$ (\Cref{ln:ret}). 
%

If \boundtool pops from $Q$ a pair $(S,\beta_{c,S})$ such that $|S|>1$, 
it partitions $S$ into several sets and stores them in $L$ to analyze them in the next iteration (\Cref{algbab_ln:kmeans}). % and initiates another optimization iteration to further refine $\beta_c$.  The process terminates and returns the tightest bound when the item with the maximal bound contains only a single network. 
%It then computes the bound for each of the sets $L$, by constructing their hyper-network and solving their MILP, as described. They are then added along with their bounds to the priority queue, and 
%Then, a new iteration begins. 
\boundtool partitions based on the closeness of the networks' weights and biases.
%\tool utilizes a clustering algorithm that depends on the parameters (weights and biases) of a set of $M$ classifiers $\{D'_{i\in[M]}\}$ to cluster them into $K$ groups based on their parameter $\{w^i_{m,k,k'}\}\cup \{b^i_{m,k\}}$ similarity, measured by the $L_2$ metric (the mathematical formalization is provided in~\Cref{sec:appex_clustering}). 
Such partitioning is effective for two reasons. 
First, the closer the parameters are, the closer the networks' functions and their \propa. Consequently, the hyper-network's \propa is expected to be tighter (i.e., smaller), which increases the chances that it will be bounded and not branched.
%Computing their bounds collectively not only accelerates the process of obtaining the tightest bound but also allows for the pruning of a large number of classifiers from the search tree at once. 
Second, it reduces the overapproximation error that stems from the abstraction of a hyper-network. 
To partition, \tool employs the $k$-means clustering~\cite{ref82} using the $L_2$ norm computed over all the networks' parameters. 
It dynamically determines the optimal number of clusters $k$ using the elbow method. 
%\Cref{sec:appex_clustering} provides the formal closeness definition, based on the $L_2$ norm. 
%The k-means algorithm partitions the input data into $K$ clusters by assigning each data point to the cluster with the nearest mean, which serves as the cluster's centroid. This process iteratively adjusts the positions of the centroids until the positions stabilize, minimizing the within-cluster sum of squares. 

\boundtool is an anytime algorithm: at any point, it can return an overapproximation of the \propa. Initially, the anytime bound is $\infty$ (\Cref{ln:binit}) and after a pair is popped from the priority queue, the anytime bound is the bound of the last popped pair (\Cref{ln:upb}). 

 \begin{figure*}[t]
    \centering
  \includegraphics[width=1\linewidth, trim=0 152 0 0, clip,page=3]{images/figures.pdf}
    \caption{ \tool's component for computing the \propa.}
    \label{fig::system_description}
\end{figure*}
\paragraph{Example}
Consider the example of computing the \propa of $c=0$ for the classifier $N$ shown in~\Cref{fig::hyper_bab} and $N_D=\{N_{-1},N_{-2},N_{-3},N_{-4}\}$. Initially, $\beta_0=\infty$, $Q=[]$, and $L=\{[4]\}$.
In the first iteration of~\Cref{alg:bab}, the hyper-network of $S=[4]$ is constructed (\Cref{fig::hyper_bab}, bottom center) 
and its bound $\beta^*_{1,2,3,4}=0.55$ is computed. Then, the pair $([4],0.55)$ is pushed into the queue: $Q=[([4],0.55)]$. 
Next, this pair is popped from $Q$ and $\beta_0$ is reduced to $0.55$. Since $[4]$ is not a singleton, it is partitioned by clustering. This results in $L=\{\{1,2,3\},\{4\}\}$. Then, another iteration of~\Cref{alg:bab} begins. This iteration first constructs the hyper-network for $S=\{1,2,3\}$ (\Cref{fig::hyper_bab}, bottom left), computes its bound $\beta^*_{1,2,3}=0.21$, and updates the queue: $Q=[(\{1,2,3\},0.21)]$. Then, this iteration constructs the hyper-network for $S=\{4\}$ (\Cref{fig::hyper_bab}, bottom right), computes its bound $\beta^*_{4}=0.52$, and updates the queue: $Q=[(\{4\},0.52),(\{1,2,3\},0.21)]$.
Note that since $0.52>0.21$, the new pair is pushed to the top of the queue. Next, the pair $(\{4\},0.52)$ is popped from $Q$
and $\beta_0$ is reduced to $0.52$. Since $\{4\}$ is a singleton, it bounds \emph{all} pairs in $Q$ and \Cref{alg:bab} returns $\beta_0=0.52$. 
%We next provide details on the MILP encoding, the matching dependencies, the similarity encoding and the set partitioning.
%The splitting creates the branches and the optimization bounds their solution.  
%Finally, The bound is utilized to repair the classifier, enhancing its differential privacy while maintaining accuracy. 

%Our approach comprises three main components. 
%The first component utilizes a branch-and-bound technique designed to efficiently split the classifiers into subgroups. 
%These subgroups are then addressed by the second component, which encodes the problem as MILP formulation and returns a bound for that subgroup. 
%The third component utilizes the bound to repair the DP of the classifier. 
%Next, we describe \tool's components in detail.


%\subsection{\tool's Branch and Bound} 
%\label{sec:our_approach_bab}
%In this section, we explain our Branch-and-Bound (BaB) approach, which iteratively splits the $\{D_{-s}\}$ networks into subgroups until the tightest bound $\beta_c$ is reached.
%\paragraph{Partitioning} To partition a set that is popped from the queue, we perform clustering by the closeness of the networks' weights and biases, measured using the $L_2$ norm (formally defined in~\Cref{sec:appex_clustering}).
%\tool utilizes a clustering algorithm that depends on the parameters (weights and biases) of a set of $M$ classifiers $\{D'_{i\in[M]}\}$ to cluster them into $K$ groups based on their parameter $\{w^i_{m,k,k'}\}\cup \{b^i_{m,k\}}$ similarity, measured by the $L_2$ metric (the mathematical formalization is provided in~\Cref{sec:appex_clustering}). 
%The rationale for splitting the classifiers based on parameter similarity is twofold: 
%(1) Closely matched parameters are likely to exhibit similar functionality and, consequently, similar bounds. Computing their bounds collectively not only accelerates the process of obtaining the tightest bound but also allows for the pruning of a large number of classifiers from the search tree at once. 
%(2) It reduces the overapproximation error that arises from encoding a hyper-network. 
%To determine the optimal number of groups $K$, \tool employs the k-means algorithm~\cite{ref82}. It determines the optimal clusters number $K$ using the elbow method. 

%\Cref{alg:bab} describes \tool's Branch-and-Bound (BaB) approach for computing the optimal bound $\beta_c$. 
%The algorithm accepts the following inputs: the classifier $D$, the classifiers set $\{D_{-s}\}$ for $s \in \mathcal{S}$, and a class label $c$ and it outputs the bound $\beta_c$. 
%To derive the bound $\beta_c$, \tool maintains two main data structures: 
%(1) $\mathcal{C}$: Represents the subgroup of classifiers that holds the optimal solution. 
%This data structure has three fields, $\mathcal{C}.\text{classifiers}$ which contains the classifiers themselves, 
%$\mathcal{C}.\beta$ holding the bound of that particular subgroup, and $\mathcal{C}.S$ an indicator that tracks the status of the subgroup, whether it has been solved, or if it was created due to the k-means splitting and has not yet been addressed by the optimizer. 
%(2) $\mathcal{D}$: A list that maintains all the classifier subgroups generated during the algorithm's execution. 
%\tool begins by initializing the classifiers of $\mathcal{C}$ to include all the classifiers within $\mathcal{S}$ (\Cref{algbab_ln:initialization}). 
%Including all classifiers at the first step is crucial to maintain \tool's any-time property. 
%The iterative refinement process starts by computing the bound for the classifiers in $\mathcal{C}$ using the MILP optimization process (\Cref{algbab_ln:milp_optimization}). 
%Once computed, \tool pushes the subgroup of classifiers along with their computed bounds and an indication that they have been processed by the MILP optimization into the list $\mathcal{D}$ (\Cref{algbab_ln:push_subgroup}). 
%Next, \tool pops the classifiers subgroup with the maximal bound so far from $\mathcal{D}$ as the next candidate for refinement (\Cref{algbab_ln:pop_subgroup}). 
%\tool checks if this candidate subgroup has only a single classifier and if it was addressed by the optimizer. 
%If both conditions are met, then the refinement process stops because the optimal bound has been achieved (\Cref{algbab_ln:break}). 
%If the subgroup has only a single classifier, indicating it cannot be further split, or if it has not yet been addressed by the optimizer, \tool returns this problem to the optimizer for refinement (\Cref{algbab_ln:cont}). 
%If neither condition is met, \tool employs k-means clustering to split the classifiers into optimal subgroups, determining the number of subgroups $K$ automatically using the elbow method (\Cref{algbab_ln:kmeans}). 
%\tool selects the subgroup with the smallest size as the next candidate (\Cref{algbab_ln:cont_with_minimal_1,algbab_ln:cont_with_minimal_2}), and pushes the remaining subgroups into $\mathcal{D}$ with an indication that they have not been addressed by the optimizer (\Cref{algbab_ln:push_others}). 
%The iteration continues to tighten the bound $\beta_c$. 
%When an optimized subgroup with a single classifier is obtained, \tool stops the refinement (\Cref{algbab_ln:break}) and returns the optimal bound (\Cref{algbab_ln:return}). 





\begin{comment}
\begin{algorithm}[t]
\caption{\tool's BaB approach.}
\label{alg:bab}
\DontPrintSemicolon
\KwIn{The classifier $D$, the classifiers $\{D_{-s\in \mathcal{S}}\}$ and a class $c$.}
\KwOut{The \propa bound $\beta_c$.}
\Parameter{$\mathcal{D}=\emptyset$.}
$\mathcal{C}.\text{classifiers} = \{D_{-s\in \mathcal{S}}\}$\;
$\mathcal{C}.\beta = \bot,\;\mathcal{C}.S = \text{False}$\;
%$\mathcal{C}.\text{S} = False$\;
 \SetKwRepeat{Do}{do}{while}
 \Do{$|\mathcal{C}.\text{classifiers}| \neq 1 \; \lor \mathcal{C}.S == \text{False}$ }{ 
    $\mathcal{C}.\beta = \text{Bound\_by\_MILP\_optimization}(\mathcal{C}.\text{classifiers},D,c)$\;
    $\mathcal{D}.\textbf{Push}(\mathcal{C}\:|\:C.S=\text{True})$\; 
    $\mathcal{C} = \mathcal{D}.\textbf{Pop}( \text{argmax}_i \mathcal{D}_i.\beta  )$\; 
    \If{$|\mathcal{C}.\text{classifiers}| \neq 1$}{
        $[\mathcal{G}]_K = \text{Kmeans}(\mathcal{C}.\text{classifiers}.\{w_{m,k,k'}\}\cup \{b_{m,k\}})$\;
        \ForEach {$\mathcal{G}_i \in [\mathcal{G}]_K$}{
            
       \lIf{$\mathcal{G}_i == \text{argmin}_{\mathcal{G}_j} |\mathcal{G}_{j\in K}|$}{
           $\mathcal{C}.classifiers = \mathcal{G}_i$
        }   
        \lElse{
            $\mathcal{D}.\textbf{Push}(\mathcal{C^*}\:|\:\mathcal{C^*}.\text{classifiers} = \mathcal{G}_i,\:\mathcal{C^*}.\beta = \mathcal{C}.\beta)$    
        }  
    }
    }
  }
 
\end{algorithm}
\end{comment}


\begin{comment}
\begin{algorithm}[t]
\caption{\tool's BaB approach.}
\label{alg:bab}
\DontPrintSemicolon
\KwIn{The classifier $D$, the classifiers $\{D_{-s\in \mathcal{S}}\}$ and a class $c$.}
\KwOut{The \propa bound $\beta_c$.}
\Parameter{$\mathcal{D}=\emptyset$.}
$\mathcal{C}.\text{classifiers} = \{D_{-s\in \mathcal{S}}\}$\;
$\mathcal{C}.\beta = \bot$\;
%$\mathcal{C}.\text{S} = False$\;
 \SetKwRepeat{Do}{do}{while}
 \Do{$|\mathcal{C}.\text{classifiers}|>1$}{ 
    $\mathcal{C}.\beta = \text{Bound\_by\_MILP\_optimization}(\mathcal{C}.\text{classifiers},D,c)$\;
    $\mathcal{D}.\textbf{Push}(\mathcal{C})$\; 
    $\mathcal{C} = \mathcal{D}.\textbf{Pop}( \text{argmax}_i \mathcal{D}_i.\beta  )$\; 
    $[\mathcal{G}]_K = \text{Kmeans\_elbow}(\mathcal{C}.\text{classifiers}.\{w_{m,k,k'}\}\cup \{b_{m,k\}})$\;
    \ForEach {$\mathcal{G}_i \in [\mathcal{G}]_K$}{
        
   \lIf{$\mathcal{G}_i == \text{argmin}_{\mathcal{G}_j} |\mathcal{G}_{j\in K}|$}{
       $\mathcal{C}.classifiers = \mathcal{G}_i$
    }   
    \lElse{
        $\mathcal{D}.\textbf{Push}(\mathcal{C^*}\:|\:\mathcal{C^*}.\text{classifiers} = \mathcal{G}_i,\:\mathcal{C^*}.\beta = \mathcal{C}.\beta)$    
    }  
    }
  }
 
\end{algorithm}
\end{comment}

\subsection{The MILP Encoding} 
\label{sec:our_approach_milp} 
In this section, we describe our MILP encoding for computing the \propa of a network and a hyper-network (\Cref{dphyp}). %for a set of classifiers $S=\{D_{1},\ldots,D_{M}\} \subseteq \{D_{-s} \mid s \in \mathcal{S}\}$. 
%\tool first constructs a hyper-network $D_M^\#$ using the networks $\{D_{1},\ldots,D_{M}\}$, a crucial step for efficiently encoding the problem into MILP (see~\Cref{over:Hyper}).   
We adapt the MILP encoding from~\citet{ref_42}, originally designed to analyze a network's local robustness, to our property defined over any input and over a network and a hyper-network. 
\
%However, \tool adapts this MILP formalism to compute \propa, a property that compares the classification decisions between a classifier and a group of classifiers (represented by a hyper-network) to bound their classification differences. 
We begin with background and then present our adaptations. 

\paragraph{Background}
The MILP verifier of~\citet{ref_42} takes as inputs a classifier $N$, an input $x$ classified as $c$, and a neighborhood $\mathcal{I}(x)$, defined by intervals for each input entry (i.e., $x' \in \mathcal{I}(x)$ if and only if $\forall k.\ x'_k \in [l_k, u_k]$). 
The verifier determines whether $N$ is locally robust at $\mathcal{I}(x)$, i.e., whether it classifies all inputs in $\mathcal{I}(x)$ as $c$. 
For the input neurons, 
the verifier assigns each a real-valued variable $z_{0,k}$, constrained by its interval: $\forall k.\ l_k \leq z_{0,k} \leq  u_k$. 
For the non-input neurons, it assigns two variables: $\hat{z}_{m,k}$ for the weighted sum (as defined in~\Cref{sec:preliminary}) %transformations, defined by $\hat{z}_{m,k}=b_{m,k}+\sum_{k'=1}^{k_{m-1}}{w}_{m,k,k'}\cdot{z}_{m-1,k'}$, 
and ${z}_{m,k}$ for the ReLU application. It also introduces %A ReLU is encoded by a boolean variable $a_{m,k}$ and continues variable $\hat{z}_{m,k}$ bounded by 
concrete bounds $l_{m,k}, u_{m,k}\in \mathbb{R}$ for $\hat{z}_{m,k}$.
The verifier encodes $\hat{z}_{m,k}$ as is using one equality constraint, and it encodes ReLU using four constraints, defined over $\hat{z}_{m,k}$ and over a boolean variable $a_{m,k}$ indicating whether the ReLU is in its inactive state (i.e., outputs zero) or active state (i.e., outputs $\hat{z}_{m,k}$).
  %by the constraints: ${z}_{m,k}\geq0$, ${z}_{m,k}\geq \hat{z}_{m,k}$, ${z}_{m,k} \leq u_{m,k}\cdot a_{m,k}$, and ${z}_{m,k} \leq \hat{z}_{m,k}-l_{m,k}(1-a_{m,k})$. 
%The concrete bounds are computed by solving the optimization problems $l_{m,k}=\min z_{m,k}$ and $u_{m,k}=\max z_{m,k}$ where the constraints are the encodings of all previous layers. 
%We denote the set of all neurons' constraints by $\mathcal{N}$. 
To determine local robustness, the verifier adds the constraint %for local robustness violations by determining if there exists an input $x \in \mathcal{R}$ where 
$z_{L,c} - \max_{c'\neq c } z_{L,c'} \leq 0$. If this MILP has no solution, $N$ is locally robust at $\mathcal{I}(x)$; otherwise, it is not. %it determines that $D$ is locally robust at $\mathcal{R}(x)$. 


\paragraph{Our MILP encoding} 
We next present our MILP encoding for 
the \propa of a set $S$ (\Cref{main_problem}), which relies on several adaptations. %\tool adapts the encoding from \cite{ref_42} and introduces several extensions:
%(1) \tool encodes the entire input domain $x \in [0,1]^d$ to support the any-input settings, 
%denoted by $\phi_{in}$\Dana{what is $\varphi_{in}$?}.
First, since \propa is defined over a network and a hyper-network, it has two copies of the variables: for $N$ and for the hyper-network $N^\#_S$. For $N$, it has the same constraints for the non-input neurons (Eq. (\ref{eq3:row4}) and (\ref{eq3:row6})).
For $N^\#_S$, it has the same constraints for the ReLU computations (Eq. (\ref{eq3:row7})). 
For the weighted sums, since the hyper-network's parameters are intervals and not real numbers,
it replaces the equality constraint by two inequality constraints (Eq. (\ref{eq3:row5})). The correctness of these constraints follows from interval arithmetic and since the input entries and the ReLU's outputs are non-negative.
Second, to encode that the network and hyper-network accept the same input, it introduces a variable $x$ and defines $z_{0,k}=x_k$ and 
$z_{0,k}^\#=x_k$, for all $k$ (Eq. (\ref{eq3:row2})).
Third, since \propa is a global property, there is no neighborhood and each input entry $x_k$ is bounded in the domain $[0,1]$ (Eq. (\ref{eq3:row2})). %,
 %(2) \tool encodes two classifiers, each of the accept the same input $x$.  
%The first captures the functionality of the classifier $D$, with its constraint set denoted by $\mathcal{N}$ and parameters denoted by $z_{m,k}$, $\hat{z}_{m,k}$, and $a_{m,k}$.
%The second captures the functionality of the hyper-network $D_M^\#$, with its constraint set denoted by $\mathcal{N}^\#$ and parameters denoted by $z^\#_{m,k}$, $\hat{z}^\#_{m,k}$, and $a^\#_{m,k}$.
 %
%\begin{lemma}
%Given a ReLU hyper-network $D_M^\#$ composed from the intervals $w_{m,k,k'}^\# = [\min_{n\in[N]}(w^n_{m,k,k'}), \max_{n\in[N]}(w^n_{m,k,k'})]$ and $b_{m,k}^\#=[\min_{n\in[N]}(b^n_{m,k}),\max_{n\in[N]}(b^n_{m,k})]$, the MILP encoding of the affine layer $m$ is $\hat{z^\#}_{m,k}\geq \min_{n\in[N]}(b^n_{m,k})+\sum_{k'=1}^{k_{m-1}}\min_{n\in[N]}(w^n_{m,k,k'})\cdot{z^\#}_{m-1,k'}$, and ${z^\#}_{m,k}$ and $\hat{z^\#}_{m,k}\leq \max_{n\in[N]}(b^n_{m,k})+\sum_{k'=1}^{k_{m-1}}\max_{n\in[N]}(w^n_{m,k,k'})\cdot{z^\#}_{m-1,k'}$.  
%\end{lemma}
Fourth, it introduces a bound $\beta_{c,S}$ and adds the objective $\max \beta_{c,S}$ (Eq. (\ref{eq3:row1})) as well as the constraints $z_{L,c} -  z_{L,c'} \geq \beta_{c,S}$ for all $c'\neq c$, 
for encoding $\mathcal{C}_{N}^c(x) \geq \beta_{c,S}$,
and 
$z^\#_{L,c} - \max_{c'\neq c} z^\#_{L,c'} \leq 0$, for encoding $\mathcal{C}_{{N}_{S}^\#}^{c}(x) \leq 0$ (Eq. (\ref{eq3:row3})). 
It expresses $\max_{c'\neq c} z^\#_{L,c'}$ by the Big M method~\cite{ref_73}, which relies on a large constant $M$ and boolean variables $a_{c'}$ for every $c'\neq c$. 
Fifth, it adds the matching dependencies $\phi_{MD}$ and linear relaxation constraints $\phi_{RiS}$ (Eq. (\ref{eq3:row2})), for neurons in the hyper-network whose difference interval is small (described shortly). %, which we next describe. 
%\Cref{sec:appex_full_encoding} shows our encoding.
% The full encoding is provided in~\Cref{sec:appex_full_encoding}. 
%Next, we provide the MILP encoding of the \propa of a set $S$. 
%Given a classifier $N$, a hyper-network $N^\#_S$ defined by the network parameters intervals $w_{m,k,k'}^\#=[\underline{w^\#}_{m,k,k'},\overline{w^\#}_{m,k,k'}]$ and $b_{m,k}^\#=[\underline{b^\#}_{m,k},\overline{b^\#}_{m,k}]$, and a class $c$, our encoding is:
Overall, given a classifier $N$, a hyper-network $N^\#_S$ with parameters $w_{m,k,k'}^\#=[\underline{w^\#}_{m,k,k'},\overline{w^\#}_{m,k,k'}]$ and $b_{m,k}^\#=[\underline{b^\#}_{m,k},\overline{b^\#}_{m,k}]$, and a class $c$, our encoding is given in~\Cref{main_problem} below:
%Given a classifier $D$, a hyper-network $D^\#_S$ defined by the network parameters intervals $w_{m,k,k'}^\#=[\underline{w^\#}_{m,k,k'},\overline{w^\#}_{m,k,k'}]$ and $b_{m,k}^\#=[\underline{b^\#}_{m,k},\overline{b^\#}_{m,k}]$, and a class $c$, our encoding is: 
%

\begin{subequations}\label{main_problem}
\begin{equation}\label{eq3:row1}
  \begin{gathered}
     \max \beta_{c,S} \hspace{0.5cm}\text{subject to}
  \end{gathered}
\end{equation}
\begin{equation}\label{eq3:row2}
      \phi_{MD}; \hspace{0.27cm} \phi_{RiS}; \hspace{0.27cm} x\in[0,1]^d;\hspace{0.27cm}
      \forall k:\hspace{0.2cm}\;z_{0,k}=x_{k};\hspace{0.3cm}z^\#_{0,k}=x_{k}
\end{equation}
\begin{equation}\label{eq3:row3}
      \forall {c'\neq c}.\ z_{L,c}-z_{L,c'}\geq\beta_{c,S};\hspace{0.27cm}\;\;\;
      \forall {c' \neq c}.\  z^\#_{L,c}-z^\#_{L,c'} \leq M\cdot(1-\alpha_{c'});\;\;\sum_{c' \neq c} \alpha_{c'} \geq 1
\end{equation}
\begin{equation}\label{eq3:row4}
     \forall m>0, \forall k:\hspace{0.5cm}\;\hat{z}_{m,k}=b_{m,k}+\sum_{k'=1}^{k_{m-1}}{w}_{m,k,k'}\cdot{z}_{m-1,k'} \hspace{0.5cm}
\end{equation}
\begin{equation}\label{eq3:row5}
     \hat{z}^\#_{m,k}\geq \underline{b^\#}_{m,k} +\sum_{k'=1}^{k_{m-1}}\underline{w^\#}_{m,k,k'}\cdot{z^\#}_{m-1,k'};\hspace{0.5cm}
     \hat{z}^\#_{m,k}\leq \overline{b^\#}_{m,k}+\sum_{k'=1}^{k_{m-1}}\overline{w^\#}_{m,k,k'}\cdot{z^\#}_{m-1,k'}
\end{equation}
\begin{equation}\label{eq3:row6}
      {z}_{m,k}\geq0; \hspace{0.5cm} {z}_{m,k}\geq \hat{z}_{m,k}; \hspace{0.5cm} {z}_{m,k} \leq u_{m,k}\cdot a_{m,k}; \hspace{0.5cm}
      {z}_{m,k} \leq \hat{z}_{m,k}-l_{m,k}(1-a_{m,k})
\end{equation}
\begin{equation}\label{eq3:row7}
     {z}^\#_{m,k}\geq0;\hspace{0.5cm} {z}^\#_{m,k}\geq \hat{z}^\#_{m,k};\hspace{0.5cm}
    {z}^\#_{m,k} \leq u^\#_{m,k}\cdot a^\#_{m,k};\hspace{0.5cm}
    {z}^\#_{m,k} \leq \hat{z}^\#_{m,k}-l^\#_{m,k}(1-a^\#_{m,k})
\end{equation}
\end{subequations}


\begin{comment}
\begin{equation}\label{main_problem}
  \begin{gathered}
     \max \beta_{c,S} \hspace{0.5cm}\text{subject to}\\
      \phi_{MD}; \hspace{0.27cm} \phi_{RiS}; \hspace{0.27cm} x\in[0,1]^d;\hspace{0.27cm}
      \forall k:\hspace{0.2cm}\;z_{0,k}=x_{k};\hspace{0.3cm}z^\#_{0,k}=x_{k}\\
      \forall {c'\neq c}.\ z_{L,c}-z_{L,c'}\geq\beta_{c,S};\hspace{0.27cm}\;\;\;
      %\forall c''\neq c_t.\ z^p_{L,c_t}-z^p_{L,c''}>0;\\
      \forall {c' \neq c}.\  z^\#_{L,c}-z^\#_{L,c'} \leq M\cdot(1-\alpha_{c'});\;\;\sum_{c' \neq c} \alpha_{c'} \geq 1\\
     %\forall k:\hspace{0.9cm}\;z_{0,k}=x_{k};\hspace{1.0cm}z^\#_{0,k}=x_{k}\\
     \forall m>0, \forall k:\hspace{0.5cm}\;\hat{z}_{m,k}=b_{m,k}+\sum_{k'=1}^{k_{m-1}}{w}_{m,k,k'}\cdot{z}_{m-1,k'} \hspace{0.5cm}\\
     \hat{z}^\#_{m,k}\geq \underline{b^\#}_{m,k} +\sum_{k'=1}^{k_{m-1}}\underline{w^\#}_{m,k,k'}\cdot{z^\#}_{m-1,k'};\hspace{0.5cm}
     \hat{z}^\#_{m,k}\leq \overline{b^\#}_{m,k}+\sum_{k'=1}^{k_{m-1}}\overline{w^\#}_{m,k,k'}\cdot{z^\#}_{m-1,k'}\\
      {z}_{m,k}\geq0; \hspace{0.5cm} {z}_{m,k}\geq \hat{z}_{m,k}; \hspace{0.5cm} {z}_{m,k} \leq u_{m,k}\cdot a_{m,k}; \hspace{0.5cm}
      {z}_{m,k} \leq \hat{z}_{m,k}-l_{m,k}(1-a_{m,k})\\
     {z}^\#_{m,k}\geq0;\hspace{0.5cm} {z}^\#_{m,k}\geq \hat{z}^\#_{m,k};\hspace{0.5cm}
    {z}^\#_{m,k} \leq u^\#_{m,k}\cdot a^\#_{m,k};\hspace{0.5cm}
    {z}^\#_{m,k} \leq \hat{z}^\#_{m,k}-l^\#_{m,k}(1-a^\#_{m,k})\\
    \end{gathered}
\end{equation}
\end{comment}

%in~\Cref{sec:our_approach_milp_MD_SE}). 
%(4) \tool applies similarity encoding denoted by $\phi_{SE}$ for neuron pairs $(m,n)$ that exhibit a high degree of match, measured by closeness less than a threshold $\tau$. Instead of precise MILP encoding using a Boolean variable, \tool utilizes the triangle encoding for these pairs (detailed in~\cref{sec:our_approach_milp_MD_SE}).
%(5) \tool introduces a bound $\beta^M_c$, where is the goal is to maximize this parameter to find the highest classification confidence at which $D$ classifies an input as $c$ and $D_M^\#$ classifies it differently. This property is encoded as $z_{L,c} - z_{L,c' \neq c} > \beta^M_c$.
%(6) \tool encodes the misclassification condition for the hyper-network, stating that misclassification occurs if $z^\#_{L,c} - z^\#_{L,c' \neq c} \leq 0$. 
%Finally, \tool submits the problem to the optimizer with the objective of maximizing the bound $\beta^M_c$. 
%This maximization is subject to the constraints: $\phi_{in}$, $\mathcal{N}$, $\mathcal{N}^\#$, $\phi_{MD}$, $\phi_{SE}$, and the two constraints over the classification confidences. 
%The maximal bound $\beta^M_c$ is the \propa over the classifier $D$ and the classifiers set $\{D_{1},\ldots,D_{M}\}$.  
%We provide the full encoding in~\Cref{sec:appex_full_encoding}.
