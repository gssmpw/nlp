\begin{algorithm}[t]
\caption{\reptool($D$, $\mathcal{T}$, $\widetilde{N}$, $\varepsilon$)}
\label{alg:repair}
\SetKwProg{Fn}{Function}
\DontPrintSemicolon
\Fn{}{
\DontPrintSemicolon
%$D$ = $D^I$; $\mathcal{T}=\mathcal{T}^I$; $\widetilde{N}=\widetilde{N}^I$; $\varepsilon=\varepsilon^I$\;
$N$ = $\mathcal{T}(D,\widetilde{N})$\;\label{ln:reptrain}
$\beta\-Set$ =$\{\boundtool(D,\mathcal{T},\widetilde{N},c) \mid c\in C\}$\;\label{ln:repbounds}
$M$ = $[]$\tcp*{A dictionary of inputs for which the exponential mechanism ran} \label{ln:repM}
}
\Fn{Access($x$)}{
\DontPrintSemicolon
\KwIn{The input to the network $x$.}
\KwOut{A label, such that the label-only query satisfies $\varepsilon$-iDP.}
\lIf{$M[x] \neq \bot$}{\Return{$M[x]$}}\label{ln:repif}
$scores$ = $N(x)$\;\label{ln:repscore}
 $c$ = $\text{argmax}_{c\in C} scores$\;  \label{ln:repclass}
 \lIf{$scores[c]-max_{c'\neq c}scores[c']> \beta\-Set[c]$}{\Return{c}}\label{ln:repscorbound}
 $M[x]$ = ExponentialMechanism($u_{x,\mathcal{T},\widetilde{N}},D,c,\varepsilon)$\;\label{ln:repexp}
 \Return{$M[x]$}\label{ln:repret}
  }
 \end{algorithm}
\subsection{Our \propi Label-Only Access to the Network Classifier} 
In this section, we describe \reptool, our system for creating label-only access to a neural network classifier that is individually differentially private (\propi).
%\reptool is parameterized by a noise function $\sigma:\mathbb{R}^{|C|}\rightarrow \mathbb{R}^{|C|}$ and is general to any noise function. 
\reptool (\Cref{alg:repair}) takes as inputs a dataset $D$, a training algorithm $\mathcal{T}$, a network architecture $\widetilde{N}$, and a privacy budget~$\varepsilon$.
It first trains the network $N$ and runs \boundtool for every class $c$ to obtain all \propa (\Cref{ln:reptrain}--\Cref{ln:repbounds}). 
It then initializes a dictionary $M$ of inputs and their labels, for inputs whose labels are selected by the exponential mechanism (\Cref{ln:repM}). This is used in case the attacker repeatedly submits the same input. 
Then, given an input $x$, the \propi access is defined as follows.  
If $M$ contains $x$, it returns the label in $M[x]$ (\Cref{ln:repif}).
Otherwise, it passes $x$ through $N$ to compute the output vector~$N(x)$ (\Cref{ln:repscore}). It then identifies the predicted label $c$, which is the label with the maximal score (\Cref{ln:repclass}). 
It checks whether its classification confidence is greater than $\beta_{c}$, and if so, it returns~$c$ (\Cref{ln:repscorbound}). 
Otherwise, it runs the exponential mechanism as described in~\Cref{sec:naive}. %to generate selection probabilities for each class, and then randomly returns a class $\tilde{c}$ according to these probabilities. 
 %and returns the class with the maximal noised score $\tilde{c}$. 
 It stores the resulting label in $M[x]$ and returns it (\Cref{ln:repexp}--\Cref{ln:repret}). %$M[x]=\tilde{c}$.
We assume \reptool's memory is as large as the attacker's memory. Namely, after $M$ reaches the memory limit, \reptool overrides the oldest entry, which the attacker also forgets.
 %Finally, we note that an attacker may try to mitigate the noise by repeatedly submitting identical inputs. In this scenario, the defender (\tool) remembers these inputs and consistently returns the same noisy response. This assumption is valid  since an attackerâ€™s memory is finite and thus can be exceeded.% by the defender's. 
%\tool is general to any type and any amount of noise. It also provides similar differential privacy guarantees derived directly from the noise itself. We next formalize:
%We note that our implementation trains every network once, and upon each call to \boundtool.



\begin{comment}
\begin{theorem}
Given a dataset $D$, a training algorithm $\mathcal{T}$, a network architecture $\widetilde{N}$, and a privacy budget $\varepsilon$,
  for every $x\in [0,1]^d$, \reptool provides an $\varepsilon$-\propi version of the query $f_{x,\mathcal{T},\widetilde{N}}(D)$. 
\end{theorem}
\end{comment}

\begin{restatable}[]{theorem}{ftc}
Given a dataset $D$, a training algorithm $\mathcal{T}$, a network architecture $\widetilde{N}$, and a privacy budget $\varepsilon$,
\reptool provides an $\varepsilon$-\propi version of every label-only query $f_{x,\mathcal{T},\widetilde{N}}(D)$, for $x \in [0,1]^d$, without losing accuracy for queries whose $x$ has a confidence larger than the \propa.
\end{restatable} 

%\Cref{sec:proofs} provides a proof sketch.
 A proof sketch is provided in 
 \ifthenelse{\EXTENDEDVER<0}{\Cref{sec:proofs}.
}{\citet[Appendix A]{ref_105}.}

\begin{comment}
\paragraph{Guarantees}
Given a noise function that guarantees $(\varepsilon,\delta)$-DP, our repair is $(\varepsilon,\delta)$-DP. This follows because 
our repair partitions the input space based on the relation of their classification confidence in the predicted class to the respective \propa.
By definition, querying the output of any input whose confidence in the predicted class is above the respective \propa is $(0,0)$-DP. 
By the noise function's guarantee, querying the output of any input whose confidence in the predicted class is at most the respective \propa is $(\varepsilon,\delta)$-DP.
By parallel composition~\cite{McSherry10}, the DP guarantee of our repair is determined by the worst DP bound, thus it guarantees $(\varepsilon,\delta)$-DP.
%\begin{lemma}~\label{lem3}
%If a noise that is $\epsilon$-differentially private is added only to the outputs associated with the input regions where $\forall c \in %C, S_{D}^{c}(x) \leq \beta_c$, then the classifier $D$ is $\epsilon$-differentially private.
%\end{lemma}
\end{comment}
