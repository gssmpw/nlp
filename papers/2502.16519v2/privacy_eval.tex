\section{Evaluation}
\label{sec:eval}

In this section, we evaluate \tool's effectiveness in providing \propi label-only access to a neural network classifier. %computing the minimal deterministic differentially-private bound. 
We run all the experiments on a dual AMD EPYC 7713 64-Core Processor@2GHz server with 2TB RAM and eight A100 GPUs running an Ubuntu 20.04.1 OS. 
We begin with the experiment setup: implementation, datasets, and networks. %start by describing the implementation details, the datasets and the models. Following this we describe our baselines. 
We then compare \tool to baselines. Finally, we provide an ablation study, showing the effectiveness of \tool's components. %, including our branch and bound technique, our closeness-based dependencies and our mutual MIP encoding. 
\paragraph{Implementation} 
We implemented \tool in Julia 1.8.3 as a module extending MIPVerify~\cite{ref_42}.
To solve MILPs, \tool uses Gurobi 11.0.1~\cite{gurobi}.  
We run \tool with a timeout of eight hours. The timeout of a single MILP (for solving~\Cref{main_problem} for a given set~$S$) is 40 minutes. \tool is parallelizable: it uses 32 workers that pop from the priority queue $Q$ sets $S$ to branch or bound. For the relax-if-similar technique, it uses $\tau=0.01$. 
%We instantiate \tool with the exponential mechanism. In our case the utility score function of the exponential mechanism is $f_{x,\mathcal{T},\widetilde{N}}(D$ and its sensitivity is $\Delta u= max_{c\in[C]} max_{D,D': ||D-D'||\leq 1} |f_{x,\mathcal{T},\widetilde{N}}(D)_c-f_{x,\mathcal{T},\widetilde{N}}(D')_c|$. The exponential mechanism outputs each possible class $c\in[C]$ with a probability proportional to  $exp(\varepsilon f_{x,\mathcal{T},\widetilde{N}}(D)_c/(2\Delta u)$, depending on those probablities we compute a one-hot encoded response. 
\begin{comment}
\begin{enumerate}[nosep,nolistsep]
    \item Coin Toss: returning a random label drawn from a Bernoulli distribution with $p=1/2$ (since our experiments are over binary classifiers). %for inputs whose classification confidence is below the \propa. 
        This noise function provides a perfect DP guarantee, i.e., a $(0,0)$-DP guarantee.
    \item Gaussian: adds a Gaussian noise to the network's probabilities, obtained by passing the network's output through softmax. The noise is drawn from a Gaussian distribution with standard deviation $\sigma = \sqrt{2 \cdot \ln\left({1.25}/ {\delta}\right)} \cdot {1}/{\varepsilon}$. This noise function provides a ($\varepsilon$, $\delta$)-DP guarantee, where we set $\delta=10^{-5}$ (as common) and $\varepsilon$ varies in our experiments.
\end{enumerate}
\end{comment}


\begin{comment}

\begin{table}[t]
\small
\begin{center}
\caption{The accuracy of \tool vs. DP-SGD and ALIBI (ACC is the model's accuracy).}
\begin{tabular}{lll ccccccc cccc cccc}
\toprule
Dataset & Model & ACC & \multicolumn{7}{c}{\tool} & \multicolumn{4}{c}{DP-SGD} & \multicolumn{4}{c}{ ALIBI}\\
\cmidrule(lr){4-10} \cmidrule(lr){11-14} \cmidrule(lr){15-18}  
        &       &         & $\beta_0$ & $T_0$ & $\beta_1$ & $T_1$ & $Acc^t$ & $Acc$ & $Acc$      &  $Acc$           &  $Acc$           & $Acc$          & $T$   &  $Acc$           & $Acc$            & $Acc$         & $T$ \\  
        &       &         &           & $[h]$ &           & $[h]$ & $\%$    & $\%$     & $\%$                 &  $\%$                  & $\%$                & $\%$                & $[s]$ &  $\%$ &  $\%$                  & $\%$  & $[s]$ \\  
        &       &         &           &       &           &       &         & $\varepsilon=0.2$ & $\varepsilon=1$ &  $\varepsilon=0.02$ &  $\varepsilon=0.2$  & $\varepsilon=1$   & &  $\varepsilon=0.02$ &  $\varepsilon=0.2$  & $\varepsilon=1$  & \\  

\midrule
Crypto   & 50$\times$2    &  99.7   &    1.78   & 0.1   & 2.95  & 0.07   & 97.2    &   97.3 &   98.1 &   49.8  &  96.6  &  96.6  &  8.2  &   48.5 &   48.5  &   92.8    & 19.8       \\ 
Crypto   & 100$\times$2    &  99.7   &    2.02   & 1.1   & 2.86 & 1.0   & 97.1    &   96.9 &   97.2 &   49.3  &  96.5  &  96.6  &  7.9  &   80.8 &   96.7  &   96.9    & 20.8       \\   
Crypto   & 30$\times$4    &  99.8   &    4.2   & 0.1   & 6.1 & 0.1   & 94.1    &   94.2 &   95.9 &   34.5  &  49.3  &  49.3  &  11.4  &   49.3 &   49.3  &   95.6    & 22.8       \\     
\midrule
Twitter   & 50$\times$2   &  89.7   &    0.51   & 1.6   & 0.54  & 3.7   & 89.2    &   89.5 &   89.4  &   51.9  &  51.4  &  51.5  &  25.1  &   51.4 &   51.4  &   87.6    & 169.2       \\  
Twitter   & 100$\times$2   &  89.6   &   0.86   & 4.9   & 0.96  & 5.5   & 88.1    &   88.1 &   88.3  &   47.5  &  53.2  &  52.4  &  28.8  &   51.4 &   52.6  &   87.6    & 159.6       \\ 
\midrule
Adult   & 50$\times$2   &  83.1   &    0.55   & 2.9   & 0.63  & 3.0   & 82.5    &   82.4 &   82.3  &   23.6  &  76.3  &  76.3  &  24.4  &   67.4 &   77.4  &   82.2    & 149.4       \\     

Adult   & 100$\times$2  &  83.3   &    0.93   & 4.3   & 0.91 & 4.1   & 80.6    &   80.5 &   81.3 &   76.3  &  76.4  &  76.4  &  20.8   &   61.5 &   75.3  &   81.9    & 103.6       \\ 

Adult   & $conv$ &  79.2   &    0.29   & 0.19   & 0.52 & 0.11   & 80.0    &   80.2 &   80.1 &   46.2  &  76.4  &  76.4  &  24.9   &   23.6 &   74.6  &   76.4    & 139.8       \\ 
\midrule
Credit   & 50$\times$2    &  81.9   &    0.33   & 5.8   & 0.34  & 6.5   & 81.8    &   81.7 &   81.8 &   26.2  &  78.4  &  78.5  &  22.4  &   78.4 &   78.4  &   78.6    & 96.4       \\ 
Credit   & 100$\times$2   &  81.8   &    0.42   & 4.4   & 0.44  & 3.1   & 81.3    &   81.5 &   81.6 &   71.8  &  78.5  &  78.5  &  21.1  &   63.7 &   73.1  &   79.9    & 81.8       \\ 
Credit   & $conv$  &  80.8   &    0.75   & 0.3   & 0.57  & 0.2   & 79.9    &   80.0 &   80.3 &   25.2  &  78.4  &  78.5  &  24.7  &   78.4 &   78.4  &   78.4    & 116.8       \\     
\bottomrule        
\end{tabular}
    \label{tab:results}
\quad
\end{center}
\end{table} 

\end{comment}

\begin{comment}
\paragraph{Datasets}
We evaluate \tool over four datasets:% studied by previous DP-SGD papers\Dana{correct? if yes, add citations}:
 \begin{itemize}[nosep,nolistsep]
    \item Cryptojacking~\cite{ref_43} (Crypto): %Websites engaging in cryptojacking are harmful webpages that abuse users' computational resources for cryptocurrency mining. 
    %The dataset, comprising 2000 malicious websites and 2000 benign websites, and is divided into a 70\% training set and a 30\% test set. 
    %Consequently, the dataset includes 2800 samples for training and 1200 samples for testing. Each sample comprises 7 input features (e.g., websocket and messageloop), and one output label of malicious/benign.  
    Cryptojacking refers to websites that exploit user resources for cryptocurrency mining. This dataset includes 2,000 malicious websites and 2,000 benign websites, where 2,800 are used for training and 1,200 for testing. Each website has seven features (e.g., websocket) and is labeled as malicious or benign.
    \item Twitter Spam Accounts~\cite{ref_44} (Twitter): %Twitter spam accounts are profiles that distribute unsolicited, irrelevant, or inappropriate messages, often automatically, to a large number of users on the platform. 
    %The dataset, comprising 20,000 spam accounts, and 20,000 benign twitter users accounts. The dataset is divied into 36,000 samples for training and 4000 samples for testing. Each sample comprises 15 input features (e.g., number of followers and number of tweets) and one output label of spam/bengin.  
 Twitter spam accounts refers to accounts that distribute unsolicited messages to users. This dataset includes 20,000 spam accounts and 20,000 benign accounts, split into 36,000 accounts for training and 4,000 for testing. Each data point has 15 features (e.g., followers and tweets) and is labeled as spam or benign.
    \item Adult Census~\cite{ref_45} (Adult): %The Adult Census dataset is designed to analyze the demographic characteristics of adults to predict whether their income exceeds a certain threshold. The dataset comprises 48,842 samples, with 32,561 samples allocated for training and 16,281 samples for testing. Each sample includes 14 input features (e.g., age, education level, occupation, and hours per week worked) and one output label indicating whether the individual's annual income is above or below \$50,000. 
    %\item Bank Marketing~\cite{ref_46}.
 This dataset is used for predicting whether an adult's annual income is over \$50,000. It includes 48,842 data points, split into 32,561 for training and 16,281 for testing. Each data point has 14 features (e.g., age, education, occupation, and working hours) and is labeled as yes or no. %, labels for annual incomes above or below \$50,000.
    \item Default of Credit Card Clients~\cite{ref_47} (Credit): %This dataset concerns individuals' credit card payment defaults in Taiwan, consisting of data from 30,000 clients. It includes information on payment history, amount of bill statement, and previous payment details over six months, along with demographic factors like age, education, and marital status. The dataset is split into 24,000 samples for training and 6,000 samples for testing. Each sample features 23 input variables, such as the amount of given credit, gender, education, marital status, age, history of past payment, and the bill and payment amounts over the last six months, along with one binary output variable indicating default/no default.
The Taiwan Credit Card Default dataset is used for predicting whether the default payment will be paid. It 
 includes 30,000 client records, split into 24,000 for training and 6,000 for testing.
 A data point has 23 features (e.g., bill amounts, age, education, marital status) and is labeled as yes or no.
  \end{itemize} 
\end{comment}

\paragraph{Networks}
We evaluate \tool over four datasets (described in  
 \ifthenelse{\EXTENDEDVER<0}{\Cref{sec:appeval}}{\citet[Appendix B]{ref_105}}):
Cryptojacking~\cite{ref_43} (Crypto), Twitter Spam Accounts~\cite{ref_44} (Twitter), Adult Census~\cite{ref_45} (Adult), and Default of Credit Card Clients~\cite{ref_47} (Credit).
We consider three fully-connected neural networks with architectures of 2$\times$50, 2$\times$100, and 4$\times$30, where the first number is the number of intermediate layers and the second number is the number of neurons in each of these layers. 
Additionally, we evaluate \tool on a convolutional neural network (CNN) architecture that has two convolutional layers followed by a fully-connected layer. 
The activation function in all networks is ReLU. 
%We summarize the networks parameters in~\Cref{sec:appex_models}.\Dana{is the table necessary? the number of parameters is exacty the multiplication. I suggest removing this sentence and the table}      
We train the networks using SGD, over 50 epochs, the batch size is 1024 (except for the Crypto dataset, where the batch size is 100), and the initial learning rate is $\eta = 0.1$. 
Although the network sizes may seem small compared to the common network sizes evaluated by local robustness verifiers (which are typically evaluated over image classifiers that have larger input dimensionality), our network sizes are consistent with those used in previous work evaluating the datasets we consider~\cite{ref_8,ref_54,ref_55,ref_56}. We remind that \tool analyzes a much more challenging property than local robustness or fairness: \propa is a global property, over any input, and over a very large number of classifiers (the size of the dataset plus one).



\ifthenelse{\WITHNAIVE>0}{

\begin{table}[t]
\small
\begin{center}
\caption{The accuracy of \tool ($Acc_{w/o-p}$ is the model's accuracy without privacy protection).}
\begin{tabular}{lll cccccccc}
\toprule
Dataset & Model & $Acc_{w/o-p}$ & \multicolumn{8}{c}{\tool}  \\
\cmidrule(lr){4-11} 
        &       &         & $\beta_0$ & $T_0$ &$\beta_1$& $T_1$ & $Acc$ & $Acc$ & $Acc$         & $AT$\\  
        &       &         &            &[h] &   &      $[h]$  & $[\%]$    & $[\%]$     & $[\%]$     & $[ms]$               \\  
        &       &         &            & &   &       &  $\varepsilon=0$       & $\varepsilon=0.2$ & $\varepsilon$=1&     \\  

\midrule
Crypto   & 2$\times$50    &  99.7   &    1.78&  0.1   & 2.95  & 0.07           & 97.3    &   97.3 &   98.0          &   0.1 \\ 
Crypto   & 2$\times$100    &  99.7   &    2.02& 1.1   & 2.86 & 1.0            & 97.1    &   97.5 &   97.8           &    0.2\\   
Crypto   & 4$\times$30    &  99.8   &    4.23 & 0.1 & 6.12 & 0.1              & 94.7    &   95.0 &   95.5           &    0.2\\     
\midrule
Twitter   & 2$\times$50   &  89.7   &    0.51 & 1.6 & 0.54  & 3.7             & 89.3    &   89.3 &   89.4           &     0.1\\  
Twitter   & 2$\times$100   &  89.6   &   0.86 & 4.9 & 0.96  & 5.5            & 88.1    &   88.2 &   88.5            &     0.2\\ 
\midrule
Adult   & 2$\times$50   &  83.1   &    0.55  & 2.9& 0.63  & 3.0               & 82.4    &   82.4 &   82.5           &     0.1\\     

Adult   & 2$\times$100  &  83.3   &    0.93 &  4.3& 0.91 & 4.1               & 80.7    &   80.8 &   81.0            &     0.1\\ 

Adult   & $conv$ &  79.2   &    0.29    & 0.2& 0.52 & 0.1                  & 80.1    &   80.1 &   80.0            &   0.2\\ 
\midrule
Credit   & 2$\times$50    &  81.9   &    0.33 &  5.8  & 0.34  & 6.5         & 81.7    &   81.8 &   81.8             &    0.1\\ 
Credit   & 2$\times$100   &  81.8   &    0.42  & 4.4  & 0.44  & 3.1          & 81.4    &   81.4 &   81.5            &  0.2\\ 
Credit   & $conv$  &  80.8   &    0.75&  0.3  & 0.57   & 0.2                & 79.9    &   80.1 &   80.3             &     0.3\\     
\bottomrule        
\end{tabular}
    \label{tab:results}
\quad
\end{center}
\end{table} 


\paragraph{Baselines} 
We compare \tool to four baselines. First, the naive algorithms described in~\Cref{sec:naive}: 
Naive-Noise, invoking the exponential mechanism for every input, and
Naive-\propi, which passes every input through $|D|+1$ networks and invokes the exponential mechanism if there is a disagreement between them. Second,   
we compare to two DP training algorithms: 
DP-SGD~\cite{ref_22}, using its PyTorch implementation\footnote{\url{https://github.com/ChrisWaites/pyvacy.git}}, and ALIBI~\citep{ref_58}, using the authors' code\footnote{\url{https://github.com/facebookresearch/label\_dp\_antipodes.git}}. 
DP-SGD provides a DP guarantee to all the network's parameters and ALIBI provides a DP guarantee only for the classifier's output. 
Both of them inject Gaussian noise into the network's training process to obtain a user-specified $\varepsilon$-DP guarantee. 
In our experiments, 
we employ a binary search to determine the appropriate noise level for achieving the desired $\varepsilon$.
The binary search increases the computation time by a few milliseconds and thus poses a minor increase to their overall computation time, which is multiple seconds. 
These two baselines provide a stronger privacy guarantee (DP) than \propi, but any $\varepsilon$-DP algorithm is also $\varepsilon$-\propi~\cite{ref_88}. We compare to them because they represent the current approach for providing privacy guarantees to neural networks. %Additionally, they allow us to obtain $\varepsilon$-\propi by proving their $\varepsilon$-DP guarantees.
We note that we do not compare to other works guaranteeing other variants of DP~\cite{ref_94,ref_95,ref_97,ref_98,ref_99,ref_8,ref_100,ref_101}, since their guarantee is incomparable to \propi.  



\begin{table}[t]
\small
\begin{center}
\caption{The accuracy of Naive-Noise and Naive-\propi ($Acc_{w/o-p}$ is the accuracy without privacy protection).}
\begin{tabular}{lll cccc cccc}
\toprule
Dataset & Model & $Acc_{w/o-p}$  & \multicolumn{4}{c}{Naive-Noise} & \multicolumn{4}{c}{Naive-\propi} \\
\cmidrule(lr){4-7} \cmidrule(lr){8-11}  
        &       &          &  $Acc$           &  $Acc$              & $Acc$            & $AT$              &  $Acc$            &  $Acc$           & $Acc$          & $AT$   \\  
        &       &          &  $[\%]$          & $[\%]$              & $[\%]$           & $[ms]$            &  $[\%]$           & $[\%]$           & $[\%]$                & $[s]$\\  
        &       &          &  $\varepsilon=0$ & $\varepsilon=0.2$   &  $\varepsilon=1$ &                   &$\varepsilon=0$    & $\varepsilon=0.2$ &  $\varepsilon=1$                   & \\  

\midrule
Crypto   & 2$\times$50    &  99.7   &   49.9   & 52.3   & 62.1     &  0.1 &   99.4    &  99.4   & 99.5     &  3          \\ 
Crypto   & 2$\times$100   &  99.7   &   50.1   &  52.7   & 62.1       & 0.2 &   99.3   &  99.2   & 99.3       & 4      \\   
Crypto   & 4$\times$30    &  99.8   &    50.0 &   52.4 &   62.0       & 0.2 &    99.7 &   99.7 &   99.7       & 4        \\     
\midrule
Twitter   & 2$\times$50   &  89.7   &     49.9   &   51.9  & 59.6    &  0.2 &     89.5   &   89.5  &  89.6    &  43        \\  
Twitter   & 2$\times$100  &  89.6       &   50.1   &  52.2   &  59.9      &   0.3 &   89.3   &  89.4   &  89.4      &   52       \\ 
\midrule
Adult   & 2$\times$50     &  83.1       &   49.9  &  51.7   & 58.2        &    0.1  &   83.1  &  82.9   & 83.1        &    32   \\     

Adult   & 2$\times$100    &  83.3        &   49.9  & 51.7    & 58.9        &   0.2  &   83.2  & 83.1    & 83.3        &   34     \\ 

Adult   & $conv$          &  79.2        &   49.9  &  51.4   & 57.2        &  0.2   &   79.2  &  79.5   & 79.5        &  40    \\ 
\midrule
Credit   & 2$\times$50    &  81.9          &  50.1    &   51.6  & 57.7       & 0.1    &  81.8    &   81.9  & 81.9       & 19    \\ 
Credit   & 2$\times$100   &  81.8         &   50.1   &   51.6  &  57.9      &  0.2  &   81.7   &   81.7  &  81.8      &  21   \\ 
Credit   & $conv$         &  80.8          &    49.9  &   51.6  & 57.5       & 0.3  &    80.9  &   80.7  & 80.7       & 26   \\   
\bottomrule        
\end{tabular}
    \label{tab:results3}
\quad
\end{center}
\end{table} 

\paragraph{\tool's performance}
We begin by evaluating the performance of \tool over fully-connected and convolutional networks for all our datasets, compared to all four baselines.
For \tool, \Cref{tab:results} reports the computed \propa for each label $\beta_0$ and $\beta_1$, their computation time in hours ($T_0$ and $T_1$), 
the test accuracy $Acc$ for three values of $\varepsilon$ ($0$, $0.2$, and $1$), and the access time in milliseconds ($AT$), i.e., the time to return a label for a given input. 
For Naive-Noise and Naive-\propi, \Cref{tab:results3} reports the test accuracy $Acc$ and the access time in milliseconds and seconds, respectively. 
For the DP training algorithms, \Cref{tab:results2} reports the test accuracy $Acc$ and the training time in seconds ($CT$). 
We run the DP training algorithms with the same values of $\varepsilon$, except that we replace the value $0$ with $0.02$, since DP cannot be obtained for $\varepsilon=0$. In fact, $0.02$ is the lowest value that our baselines can provide, and it requires adding a very high noise (the standard deviation of the noise distribution is $10,000$). 
We note that we focus on these values of $\varepsilon$ since commonly a value of $\varepsilon$ is considered to provide a strong DP guarantee when $\varepsilon<1$ and a moderate guarantee when $\varepsilon \in [1,3]$. 
Commonly, DP training algorithms, including our baselines, focus on guarantees for $\varepsilon\geq 1$.
We note that when providing the baselines $\varepsilon$ smaller than $0.02$, it results in a very large noise, rendering the computation practically infeasible (due to computer arithmetic issues). 
%\Cref{tab:results} shows the results of \tool, \Cref{tab:results3} shows the results of naive approaches, and \Cref{tab:results2} shows the results of the two DP baselines. 
The results show that, for $\varepsilon=0$, \tool provides a $0$-\propi guarantee with only 1.4\% accuracy decrease. As expected, for larger values of $\varepsilon$, \tool lowers the accuracy decrease: it provides a $0.2$-\propi guarantee with a 1.3\% accuracy decrease and a $1$-\propi guarantee with a 1.1\% accuracy decrease.
To compute the \propa, \tool runs for 4.8 hours on average (this computation is run once for every network). %using the parameters of the entire set of classifiers (with the size of the training set plus one) for a one-time analysis. 
%Afterward, \tool keeps only the classifier trained over the full training set. 
Its \propi-access time is at most one millisecond and on average it is 0.16 milliseconds.
%Consequently, the time required to provide a \propi-access to the classifier for any possible input is less than a millisecond and 0.16 milliseconds (in average). 
This time is comparable to the access time of standard networks (without \propi guarantees), with a negligible overhead. % for computing the confidences, comparing them to the bounds, and applying the probability normalization required for the exponential mechanism.
For Naive-Noise, the accuracy decrease is very high because it invokes the exponential mechanism for every input (unlike \tool and Naive-\propi). Its accuracy decrease is 
  38.1\%, 36.1\%, and 28.7\% for $\varepsilon=0$, $\varepsilon=0.2$, and $\varepsilon=1$, respectively. Like \tool, its access time is negligible.  
Naive-\propi obtains the minimal accuracy decrease, since it precisely identifies the set of leaking inputs (unlike \tool that overapproximates them with the \propa). Its accuracy decrease is 
  0.12\%, 0.1\%, and 0.05\% for the privacy budgets $\varepsilon=0$, $\varepsilon=0.2$, and $\varepsilon=1$, respectively. 
  However, it has to store throughout its execution all $|D|+1$ classifiers and its access time is high: 25 seconds on average (since it passes every input through all classifiers). This severely undermines its utility in real-time applications of neural networks, providing an interactive communication. 
%To obtain an $\varepsilon$-\propi guarantee using DP-SGD based approaches, we can compute their $\varepsilon$-DP guarantee (as described in Proposition 2 of \cite{ref_88}).
%The DP-SGD baselines can not provide a $0$-DB guarantee. 
The accuracy decrease of DP-SGD, for $\varepsilon\in\{0.02,0.2,1\}$, is on average 42.3\%, 14.2\%, and 14.3\%, respectively (29.8x, 10.7x, and 12.9x higher than \tool). 
The accuracy decrease of ALIBI for the same DP guarantees is on average 28.6\%, 19.3\%, and 2.7\% (20.1x, 14.5x, and 2.4x higher than \tool). 
Even worse, on some networks (Crypto 4$\times$30, Twitter 2$\times$50, and Twitter 2$\times$100), the baselines train networks whose accuracies are 50\% (like the accuracy of a random classifier).  
If we ignore these three networks, DP-SGD's accuracy decrease is 40.13\%, 3.99\%, and 3.9\%, which is still significantly higher than \tool (by 28.3x, 3.0x, and 3.5x), while ALIBI's decrease is 23.4\%, 10.8\%, and 2.7\% (higher by 16.4x, 8.2x, and 2.4x). 
The baselines are faster than \tool's analysis time (for computing the \propa): %is longer than the baselines. On average, it takes 4.8 hours to compute the \propa, required for the repair (training all networks takes half an hour on average when parallelizing over eight GPUs). 
DP-SGD completes within 19.9 seconds and ALIBI within 98.2 seconds. 
Although they are significantly faster, their training algorithms are coupled to a specific privacy budget $\varepsilon$: if a user wishes to update the privacy guarantee, they need to retrain the classifier. In contrast, \tool's \propi-access can easily configure the $\varepsilon$ (the \propa are computed once for a classifier).
Further, as we show, computing the \propa allows us to achieve \propi guarantees with a small accuracy decrease. %, unlike the baselines, which result in a high decrease.
}{
\paragraph{Baselines} 
We compare \tool to two baselines. 
DP-SGD~\cite{ref_22}, using its PyTorch implementation\footnote{https://github.com/ChrisWaites/pyvacy.git}, and ALIBI~\citep{ref_58}, using the authors' code\footnote{https://github.com/facebookresearch/label\_dp\_antipodes.git}. 
DP-SGD provides a DP guarantee to all the network's parameters, whereas ALIBI provides a DP guarantee only for the classifier's predicted labels. 
Both baselines propose a training algorithm that involves injecting Gaussian noise into the network's training process to obtain a user-specified $\varepsilon$-DP guarantee. 
In our experiments, 
we employ a binary search to determine the appropriate noise level for achieving the desired $\varepsilon$.
The binary search increases the computation time by a few milliseconds and thus poses a minor increase to their overall computation time, which is about few seconds. 
We note that although the DP-SGD baseline approaches provide a stronger DP privacy guarantee than \propi (in fact, DP overapproximates \propi as shown in~\cite{ref_88}), we still compare to them because they represent the main line of research providing privacy guarantees in neural networks. Additionally, they allow us to obtain $\varepsilon$-\propi by proving their $\varepsilon$-DP guarantees.

\begin{table}[t]
\small
\begin{center}
\caption{The accuracy of \tool ($Acc_{w/o-p}$ is the model's accuracy without privacy protection).}
\begin{tabular}{lll ccccccc}
\toprule
Dataset & Model & $Acc_{w/o-p}$ & \multicolumn{7}{c}{\tool}  \\
\cmidrule(lr){4-10} 
        &       &         & $\beta_0$ & $T_0$ &$\beta_1$& $T_1$ & $Acc$ & $Acc$ & $Acc$         \\  
        &       &         &            &[h] &   &      $[h]$  & $[\%]$    & $[\%]$     & $[\%]$               \\  
        &       &         &            & &   &       &  $\varepsilon=0$       & $\varepsilon=0.2$ & $\varepsilon$=1     \\  

\midrule
Crypto   & 2$\times$50    &  99.7   &    1.78&  0.1   & 2.95  & 0.07           & 97.3    &   97.3 &   98.0            \\ 
Crypto   & 2$\times$100    &  99.7   &    2.02& 1.1   & 2.86 & 1.0            & 97.1    &   97.5 &   97.8             \\   
Crypto   & 4$\times$30    &  99.8   &    4.23 & 0.1 & 6.12 & 0.1              & 94.7    &   95.0 &   95.5            \\     
\midrule
Twitter   & 2$\times$50   &  89.7   &    0.51 & 1.6 & 0.54  & 3.7             & 89.3    &   89.3 &   89.4                \\  
Twitter   & 2$\times$100   &  89.6   &   0.86 & 4.9 & 0.96  & 5.5            & 88.1    &   88.2 &   88.5            \\ 
\midrule
Adult   & 2$\times$50   &  83.1   &    0.55  & 2.9& 0.63  & 3.0               & 82.4    &   82.4 &   82.5           \\     

Adult   & 2$\times$100  &  83.3   &    0.93 &  4.3& 0.91 & 4.1               & 80.7    &   80.8 &   81.0                 \\ 

Adult   & $conv$ &  79.2   &    0.29    & 0.2& 0.52 & 0.11                  & 80.1    &   80.1 &   80.0               \\ 
\midrule
Credit   & 2$\times$50    &  81.9   &    0.33 &  5.8  & 0.34  & 6.5         & 81.7    &   81.8 &   81.8                 \\ 
Credit   & 2$\times$100   &  81.8   &    0.42  & 4.4  & 0.44  & 3.1          & 81.4    &   81.4 &   81.5             \\ 
Credit   & $conv$  &  80.8   &    0.75&  0.3  & 0.57   & 0.2                & 79.9    &   80.1 &   80.3                  \\     
\bottomrule        
\end{tabular}
    \label{tab:results}
\quad
\end{center}
\end{table} 

\paragraph{\tool's performance}
We begin by evaluating the performance of \tool over fully connected and convolutional networks, using the datasets: Crypto, Twitter, Adult, and Credit. 
For each case, we report the computed \propa for each label $\beta_0$ and $\beta_1$, along with the times $T_0$ and $T_1$ required to compute them in hours ($CT$). 
Additionally, we provide the test accuracy $Acc$ for three values of $\varepsilon$: $\varepsilon=0$, $\varepsilon=0.2$, and $\varepsilon=1$. 
For the DP-SGD based baselines, we report the test accuracy and the training time in seconds. 
We run the DP-SGD based approach with different values of privacy budget $\varepsilon \in \{0.02,0.2,1\}$.
These values demonstrate strong privacy guarantees (for $\varepsilon<1$) and moderate guarantees $(\varepsilon \in [1,3]$). 
Previous  DP-SGD based work, including our baselines, often focus on guarantees where $\varepsilon\geq 1$.
We note that when providing the baselines $\varepsilon$ smaller than $0.02$, it results in a very large noise, rendering the computation practically infeasible (due to computer arithmetic issues). 
\Cref{tab:results} shows the results of \tool, while \Cref{tab:results2} shows the results of the two DP-SGD based baselines. 
The results indicate that \tool provides a $0$-\propi guarantee with only 1.4\% accuracy decrease. As expected, for larger values of $\varepsilon$, \tool lowers the accuracy decrease. \tool provides a $0.2$-\propi guarantee with a 1.3\% accuracy decrease and a $1$-\propi guarantee with a 1.1\% accuracy decrease.
To obtain an $\varepsilon$-\propi guarantee using DP-SGD based approaches, we can compute their $\varepsilon$-DP guarantee (as described in Proposition 2 of \cite{ref_88}).
The DP-SGD baselines can not provide a $0$-DB guarantee. 
The closest guarantee they obtain is a $0.02$-DP guarantee, which requires adding a very high noise (the standard deviation of the noise distribution is $10,000$). 
The accuracy decrease of DP-SGD, for $\varepsilon\in\{0.02,0.2,1\}$, is on average 42.3\%, 14.2\%, and 14.3\%, respectively (29.8x, 10.7x, and 12.9x higher than \tool). 
The accuracy decrease of ALIBI for the same DP guarantees is on average 28.6\%, 19.3\%, and 2.7\% (20.1x, 14.5x, and 2.4x higher than \tool). 
Even worse, on some networks (Crypto 30$\times$4, Twitter 50$\times$2, and Twitter 100$\times$2), the baselines train networks whose accuracy is 50\% (like the accuracy of a random classifier).  
If we ignore these three networks, DP-SGD's accuracy decrease is 40.13\%, 3.99\%, and 3.9\%, which is still significantly higher than \tool (by 28.3x, 3.0x, and 3.5x), while ALIBI's decrease is 23.4\%, 10.8\%, and 2.7\% (higher by 16.4x, 8.2x, and 2.4x). 
As expected, \tool's analysis time is longer than the baselines. On average, it takes 4.8 hours to compute the \propa, required for the repair (training all networks takes half an hour on average when parallelizing over eight GPUs). 
In contrast, DP-SGD takes only 19.9 seconds and ALIBI takes 98.2 seconds. 
Although the baselines are significantly faster, their training algorithms are coupled to specific privacy budget, and if a user wishes to update the privacy guarantee, they need to retrain the classifier. In contrast, \tool's private access can be easily configured with any $\varepsilon$ guarantees (the \propa are computed once for a classifier).
Further, as we show, computing the \propa enables us to obtain a small decrease to the network's accuracy, unlike the baselines (for the same ~\propi guarantees).

}













\begin{comment}
\begin{table}[t]
\small
\begin{center}
\caption{The accuracy of \tool vs. Naive (ACC is the model's accuracy).}
\begin{tabular}{lll cccccccc cccc}
\toprule
Dataset & Model & ACC & \multicolumn{8}{c}{\tool} & \multicolumn{4}{c}{Naive} \\
\cmidrule(lr){4-11} \cmidrule(lr){12-15}  
        &       &         & $\beta_0$ & $T_0$ & $\beta_1$ & $T_1$ & $Acc^t$ & $Acc$ & $Acc$  & $T$    &  $Acc$           &  $Acc$           & $Acc$          & $T$    \\  
        &       &         &           & $[h]$ &           & $[h]$ & $\%$    & $\%$     & $\%$ & $[s]$                &  $\%$                  & $\%$                & $\%$                & $[s]$ \\  
        &       &         &           &       &           &       &         & $\varepsilon=0.2$ & $\varepsilon=1$ &   &  $\varepsilon=0.2$  & $\varepsilon=1$   &    \\  

\midrule
Crypto   & 50$\times$2    &  99.7   &    1.78   & 0.1   & 2.95  & 0.07   & 97.2    &   97.3 &   98.1&         &     &     &     &            \\ 
Crypto   & 100$\times$2    &  99.7   &    2.02   & 1.1   & 2.86 & 1.0   & 97.1    &   96.9 &   97.2&         &      &     &     &            \\   
Crypto   & 30$\times$4    &  99.8   &    4.2   & 0.1   & 6.1 & 0.1   & 94.1    &   94.2 &   95.9&         &      &     &     &            \\     
\midrule
Twitter   & 50$\times$2   &  89.7   &    0.51   & 1.6   & 0.54  & 3.7   & 89.2    &   89.5 &   89.4&          &      &     &     &            \\  
Twitter   & 100$\times$2   &  89.6   &   0.86   & 4.9   & 0.96  & 5.5   & 88.1    &   88.1 &   88.3&          &      &     &     &            \\ 
\midrule
Adult   & 50$\times$2   &  83.1   &    0.55   & 2.9   & 0.63  & 3.0   & 82.5    &   82.4 &   82.3&          &      &     &     &           \\     

Adult   & 100$\times$2  &  83.3   &    0.93   & 4.3   & 0.91 & 4.1   & 80.6    &   80.5 &   81.3&         &     &     &     &             \\ 

Adult   & $conv$ &  79.2   &    0.29   & 0.19   & 0.52 & 0.11   & 80.0    &   80.2 &   80.1&         &     &     &     &            \\ 
\midrule
Credit   & 50$\times$2    &  81.9   &    0.33   & 5.8   & 0.34  & 6.5   & 81.8    &   81.7 &   81.8&         &      &     &     &           \\ 
Credit   & 100$\times$2   &  81.8   &    0.42   & 4.4   & 0.44  & 3.1   & 81.3    &   81.5 &   81.6&         &      &     &     &           \\ 
Credit   & $conv$  &  80.8   &    0.75   & 0.3   & 0.57  & 0.2   & 79.9    &   80.0 &   80.3 & &             &     &     &           \\     
\bottomrule        
\end{tabular}
    \label{tab:results}
\quad
\end{center}
\end{table} 

\end{comment}







\begin{table}[t]
\small
\begin{center}
\caption{The accuracy of DP-SGD and ALIBI ($Acc_{w/o-p}$ is the model's accuracy without privacy protection).}
\begin{tabular}{lll ccccc cccc}
\toprule
Dataset & Model & $Acc_{w/o-p}$   & \multicolumn{4}{c}{DP-SGD} & \multicolumn{4}{c}{ ALIBI}\\
 \cmidrule(lr){4-7} \cmidrule(lr){8-11}  
        &       &         &  $Acc$              &  $Acc$              & $Acc$           & $CT$   &  $Acc$           & $Acc$            & $Acc$         & $CT$ \\  
        &       &         &  $[\%]$            & $[\%]$              & $[\%]$          & $[s]$ &  $[\%]$          &  $[\%]$          & $[\%]$          & $[s]$ \\  
        &       &         & $\varepsilon=0.02$ &  $\varepsilon=0.2$  & $\varepsilon=1$   & &  $\varepsilon=0.02$ &  $\varepsilon=0.2$  & $\varepsilon=1$  & \\  

\midrule
Crypto   & 2$\times$50    &  99.7   &     49.8  &  96.6  &  96.6  &  8.2  &   48.5 &   48.5  &   92.8    & 19.8       \\ 
Crypto   & 2$\times$100   &  99.7   &    49.3  &  96.5  &  96.6  &  7.9  &   80.8 &   96.7  &   96.9    & 20.8       \\   
Crypto   & 4$\times$30    &  99.8   &      34.5  &  49.3  &  49.3  &  11.4  &   49.3 &   49.3  &   95.6    & 22.8       \\     
\midrule
Twitter   & 2$\times$50   &  89.7   &      51.9  &  51.4  &  51.5  &  25.1  &   51.4 &   51.4  &   87.6    & 169.2       \\  
Twitter   & 2$\times$100  &  89.6   &      47.5  &  53.2  &  52.4  &  28.8  &   51.4 &   52.6  &   87.6    & 159.6       \\ 
\midrule
Adult   & 2$\times$50     &  83.1   &        23.6  &  76.3  &  76.3  &  24.4  &   67.4 &   77.4  &   82.2    & 149.4       \\     

Adult   & 2$\times$100    &  83.3   &        76.3  &  76.4  &  76.4  &  20.8   &   61.5 &   75.3  &   81.9    & 103.6       \\ 

Adult   & $conv$          &  79.2   &        46.2  &  76.4  &  76.4  &  24.9   &   23.6 &   74.6  &   76.4    & 139.8       \\ 
\midrule
Credit   & 2$\times$50    &  81.9   &        26.2  &  78.4  &  78.5  &  22.4  &   78.4 &   78.4  &   78.6    & 96.4       \\ 
Credit   & 2$\times$100   &  81.8   &        71.8  &  78.5  &  78.5  &  21.1  &   63.7 &   73.1  &   79.9    & 81.8       \\ 
Credit   & $conv$         &  80.8   &        25.2  &  78.4  &  78.5  &  24.7  &   78.4 &   78.4  &   78.4    & 116.8       \\     
\bottomrule        
\end{tabular}
    \label{tab:results2}
\quad
\end{center}
\end{table} 


\paragraph{Illustration of the \propa}
We next illustrate the reason that the \propa enables \tool to provide \propi-access to a network classifier with a minor accuracy decrease.
We consider the 2$\times$50 network for Twitter and let \tool compute the \propa of each class $\beta_0$ and $\beta_1$.
 \Cref{fig::eval1} plots the classification confidence of each input in the test set, where inputs labeled as $0$ are shown on the left  plot and inputs labeled as $1$ are shown on the right plot. The plots show in a green dashed line the \propa, in blue points the test points whose confidence is greater than the \propa and in red points the test points whose confidence is smaller or equal to the \propa. The plots 
 show that the confidence of the vast majority of points in the test set is over the \propa. Recall that for these points, \tool does not employ the exponential mechanism and thereby it obtains a minor accuracy decrease.
%In this figure, we show the minimal differentially private bounds of the 50x2 network trained on the Twitter dataset (represented by the dashed-green lines). 
%We compute the classification sensitivity for each input in the test set. 
%The input samples whose sensitivity exceeds the bounds (represented by blue points) do not leak privacy, and therefore, we do not add noise to them. 
%Conversely, the input samples with sensitivity below the bounds (represented by red points) are considered to be privacy-leaking, and thus, we add noise to these inputs. This added noise consequently impacts the overall test accuracy of the network classifier. 


\begin{table}[t]
\small
\begin{center}
\caption{Ablation study over \tool's components. 
 Hyp stands for Hyper-network, MD for Matching Dependencies, RiS for Relax-if-Similar, and BaB for Branch-and-Bound.}
\begin{tabular}{lllcccccccccc}
    \toprule
Dataset & Model & Variant & Hyp & MD & RiS & BaB & $\beta_{0}$ & $T_0$ & $\beta_{1}$ & $T_1$ & $Acc_{\varepsilon=0}$ & $Acc_{\varepsilon=1}$ \\
        &       &         &       &    &     &     &             & $[h]$ &             & $[h]$ & [\%]    & [\%] \\
\midrule
 Twitter& 2$\times$50   & Naive     &  \xmark & \xmark  & \xmark  & \xmark                                 & -       & 8.00        & -         & 8.00        & -         & -                      \\    
        & $Acc_{w/o-p}$  & H     &  \cmark & \xmark  & \xmark  & \xmark                                 & 1.62      & 8.00        & 1.49        & 8.00        & 85.4        & 85.9                      \\
         & 89.7\%       & HM    &  \cmark & \cmark  & \xmark  & \xmark                                 & 1.22      & 0.18     & 1.20        & 0.38     & 87.5       & 87.8                      \\
        &        & HMRiS   &  \cmark & \cmark  & \cmark  & \xmark                                 &1.25       & 0.17    & 1.26         & 0.11     & 87.3       & 87.7                      \\
         &        & HMB &  \cmark & \cmark  & \xmark  & \cmark                                 & 0.46      & 4.56    & 0.43         & 5.26     & 89.3        & 89.4                      \\

        &        & \tool &  \cmark & \cmark  & \cmark  & \cmark                                 & 0.51       & 1.16    & 0.46         & 2.81     & 89.3        & 89.4                      \\
\midrule
 Adult  & conv & Naive     &  \xmark & \xmark  & \xmark  & \xmark                                 & -      & 8.00        & -         & 8.00         & -         & -                      \\
        & $Acc_{w/o-p}$      & H     &  \cmark & \xmark  & \xmark  & \xmark                                 & 0.96      & 8.00        & 0.58       & 7.50        & 74.8     & 75.3                      \\
          & 79.2\%       & HM    &  \cmark & \cmark  & \xmark  & \xmark                              & 0.86     & 0.04      & 0.58       & 0.04       & 75.4     & 75.9                      \\
        &      & HMRiS    &  \cmark & \cmark  & \cmark  & \xmark                                 & 0.87      & 0.03      & 0.58       & 0.04       & 75.3      & 75.9                      \\
         &      & HMB   &  \cmark & \cmark  & \xmark  & \cmark                                 & 0.33     & 1.65      & 0.24        &4.05       & 80.3      & 80.1                      \\
        &      & \tool   &  \cmark & \cmark  & \cmark  & \cmark                                & 0.40      & 0.76      & 0.36        & 0.81        & 80.1     & 80.1                      \\
\bottomrule
\end{tabular}
    \label{tab:ablation}
\quad
\end{center}
\end{table}

 \begin{figure*}[t]
    \centering
  \includegraphics[width=1\linewidth, trim=0 385 0 0, clip,page=5]{images/figures.pdf}
    \caption{The \propa and the classification confidence of the test set's data points, for Twitter 2$\times$50. }
    \label{fig::eval1}
\end{figure*}

\paragraph{Ablation tests}  
Next, we evaluate the effectiveness of \tool's components. We focus on the Twitter 2$\times$50 network and on the Adult convolutional network. 
We consider five variants of \tool:
\begin{itemize}[nosep,nolistsep] 
\item Naive: The naive approach described in~\Cref{sec:overview_opt}, which computes the \propa of every $x_D \in D$ by encoding the problem $P_{x_D}$ as a MILP (like \tool, it has 32 parallel workers). %(without the BaB, the matching dependencies, or the relax-if-similar). 
%It also does not encode the closeness dependencies or apply mutual encoding, 
\item Hyper-network (H): This variant constructs a hyper-network and solves the problem of~\Cref{dphyp} for $S=D$ by encoding it as a MILP (as described in~\Cref{sec:overview_hyper}). %without encoding matching dependencies or relax-if-similar and does not employ our branch-and-bound.  
\item +Matching dependencies (HM): This variant is H with the matching dependencies. %but does not employ mutual encoding or execute the branch and bound splitting, 
\item +Relax-if-similar (HMRiS): This variant is HM with the relax-if-similar technique. 
\item +Branch-and-bound (HMB): This variant is HM with our branch-and-bound.

\end{itemize}
We run every approach with an eight hour timeout to compute the \propa of each class
 $\beta_0$ and $\beta_1$. %,  
%with a timeout of eight hours and 32 workers. 
We measure the computation time $T_0$ and $T_1$ and the accuracy decrease for $\varepsilon=0$ and $\varepsilon=1$. 
\Cref{tab:ablation} summarizes the results. 
The results show that Naive does not compute an \propa within the timeout (marked by -). 
In fact, it iterates over fewer than 5\% of the networks. %Therefore, we denote its bound as NaN.  
Unlike \tool's anytime algorithm, Naive must solve all problems in $\{P_{x_D} \mid x_D \in D \}$ to provide a sound \propa.
The hyper-network variant terminates but provides very loose \propa, approximately 2.57x larger than those obtained by \tool and it further requires 7.2x more time than \tool. 
This looseness is caused by the overapproximation of the hyper-network. 
The computation time is very long because there are no matching dependencies, making the optimization very slow, often reaching the timeout. 
As expected, the hyper-network and matching dependencies variant converges faster to the \propa: it is faster by 99.9x than the hyper-network variant.   
However, its \propa remain high, by 2.16x than those computed by \tool (because it analyzes a single hyper-network, which introduces an overapproximation error). 
The variant that also employs relax-if-similar reduces the analysis time by 1.64x compared to the previous variant, with a minor increase to the bound (1.02x). 
The variant that adds branch-and-bound computes \propa that are 2.66x tighter than the previous variant and 1.2x tighter than \tool. 
However, its computation time is 3.2x longer than \tool. 
This is expected, since the only difference between this variant and \tool is the relax-if-similar technique, which accelerates the computation at the cost of overapproximation. 
When integrating each variant (except Naive, which did not terminate) with the two privacy budgets $\varepsilon=0$ and $\varepsilon=1$, the accuracy decrease is 
4.4\%, 3.0\%, 3.2\%, -0.4\% and -0.3\%, for $\varepsilon=0$, and  
 3.9\%, 2.6\%, 2.7\%, -0.3\% and -0.3\%, for $\varepsilon=1$. 
A negative decrease means that \tool improves the accuracy.

