@misc{liu2021varianceadaptivelearningrate,
      title={On the Variance of the Adaptive Learning Rate and Beyond}, 
      author={Liyuan Liu and Haoming Jiang and Pengcheng He and Weizhu Chen and Xiaodong Liu and Jianfeng Gao and Jiawei Han},
      year={2021},
      eprint={1908.03265},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1908.03265}, 
}

@misc{loshchilov2019decoupledweightdecayregularization,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.05101}, 
}

@misc{loshchilov2017sgdrstochasticgradientdescent,
      title={SGDR: Stochastic Gradient Descent with Warm Restarts}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2017},
      eprint={1608.03983},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1608.03983}, 
}

@Article{C8SC04175J,
author ="Winter, Robin and Montanari, Floriane and Noé, Frank and Clevert, Djork-Arné",
title  ="Learning continuous and data-driven molecular descriptors by translating equivalent chemical representations",
journal  ="Chem. Sci.",
year  ="2019",
volume  ="10",
issue  ="6",
pages  ="1692-1701",
publisher  ="The Royal Society of Chemistry",
doi  ="10.1039/C8SC04175J",
url  ="http://dx.doi.org/10.1039/C8SC04175J",
abstract  ="There has been a recent surge of interest in using machine learning across chemical space in order to predict properties of molecules or design molecules and materials with the desired properties. Most of this work relies on defining clever feature representations{,} in which the chemical graph structure is encoded in a uniform way such that predictions across chemical space can be made. In this work{,} we propose to exploit the powerful ability of deep neural networks to learn a feature representation from low-level encodings of a huge corpus of chemical structures. Our model borrows ideas from neural machine translation: it translates between two semantically equivalent but syntactically different representations of molecular structures{,} compressing the meaningful information both representations have in common in a low-dimensional representation vector. Once the model is trained{,} this representation can be extracted for any new molecule and utilized as a descriptor. In fair benchmarks with respect to various human-engineered molecular fingerprints and graph-convolution models{,} our method shows competitive performance in modelling quantitative structure–activity relationships in all analysed datasets. Additionally{,} we show that our descriptor significantly outperforms all baseline molecular fingerprints in two ligand-based virtual screening tasks. Overall{,} our descriptors show the most consistent performances in all experiments. The continuity of the descriptor space and the existence of the decoder that permits deducing a chemical structure from an embedding vector allow for exploration of the space and open up new opportunities for compound optimization and idea generation."}

@INPROCEEDINGS{Zhao2024-ew,
  title     = "How to train your neural network for molecular structure
               generation from mass spectra?",
  author    = "Zhao, Kai and Liu, Yanmin and Dian, Longyang and Sun, Shiwei and
               Cui, Xuefeng",
  booktitle = "2024 IEEE International Conference on Bioinformatics and
               Biomedicine (BIBM)",
  publisher = "IEEE",
  pages     = "817--822",
  abstract  = "Mass spectrometry serves as a pivotal tool for the analysis of
               small molecules through an examination of their mass-to-charge
               ratios. Recent advancements in deep learning have markedly
               enhanced the analysis of mass spectrometric data, facilitating
               the prediction of novel small molecule structures without the
               necessity of extensive databases. Nonetheless, the paucity of
               annotated datasets impedes the efficacious training of molecular
               generation models predicated on MS2 spectra. To mitigate this
               limitation, we introduce ctMSNovelist, an avant-garde method that
               amalgamates pre-training, fine-tuning, and co-training techniques
               to construct a more precise model for the generation of molecular
               structures from tandem mass spectrometry data. This novel
               approach augments both the training regimen and the predictive
               accuracy of the MSNovelist model, thereby surmounting the
               obstacle of limited data. The methodology commences with the
               pretraining of a Variational Autoencoder (VAE) to generate
               molecular fingerprints derived from SMILES strings. Subsequently,
               it undergoes fine-tuning to emulate noisy fingerprints
               originating from mass spectrometry (MS) data. Concurrently,
               MSNovelist is co-trained utilizing these simulated fingerprints,
               inclusive of the highly noisy variants produced in the early
               stages of VAE training. The incorporation of a substantial volume
               of noisy data serves to enhance model accuracy and avert
               overfitting. We evaluated ctMSNovelist using the GNPS dataset and
               attained a SMILES prediction accuracy of 48.8\%, representing a
               4.1\% enhancement over MSNovelist. It is pertinent to note that
               the sole distinction between ctMSNovelist and MSNovelist in this
               experiment was the training process. The code and models are
               publicly available at https://github.com/xfcui/ctMSNovelist.",
  month     =  dec,
  year      =  2024,
  language  = "en"
}



@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@article{li2022diffusion,
  title={Diffusion-lm improves controllable text generation},
  author={Li, Xiang and Thickstun, John and Gulrajani, Ishaan and Liang, Percy S and Hashimoto, Tatsunori B},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={4328--4343},
  year={2022}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

@article{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={26565--26577},
  year={2022}
}

@Article{Dührkop2021,
author={D{\"u}hrkop, Kai
and Nothias, Louis-F{\'e}lix
and Fleischauer, Markus
and Reher, Raphael
and Ludwig, Marcus
and Hoffmann, Martin A.
and Petras, Daniel
and Gerwick, William H.
and Rousu, Juho
and Dorrestein, Pieter C.
and B{\"o}cker, Sebastian},
title={Systematic classification of unknown metabolites using high-resolution fragmentation mass spectra},
journal={Nature Biotechnology},
year={2021},
month={Apr},
day={01},
volume={39},
number={4},
pages={462-471},
abstract={Metabolomics using nontargeted tandem mass spectrometry can detect thousands of molecules in a biological sample. However, structural molecule annotation is limited to structures present in libraries or databases, restricting analysis and interpretation of experimental data. Here we describe CANOPUS (class assignment and ontology prediction using mass spectrometry), a computational tool for systematic compound class annotation. CANOPUS uses a deep neural network to predict 2,497{\thinspace}compound classes from fragmentation spectra, including all biologically relevant classes. CANOPUS explicitly targets compounds for which neither spectral nor structural reference data are available and predicts classes lacking tandem mass spectrometry training data. In evaluation using reference data, CANOPUS reached very high prediction performance (average accuracy of 99.7{\%} in cross-validation) and outperformed four baseline methods. We demonstrate the broad utility of CANOPUS by investigating the effect of microbial colonization in the mouse digestive system, through analysis of the chemodiversity of different Euphorbia plants and regarding the discovery of a marine natural product, revealing biological insights at the compound class level.},
issn={1546-1696},
doi={10.1038/s41587-020-0740-8},
url={https://doi.org/10.1038/s41587-020-0740-8}
}


@article {Kretschmer2023.03.27.534311,
	author = {Kretschmer, Fleming and Seipp, Jan and Ludwig, Marcus and Klau, Gunnar W. and B{\"o}cker, Sebastian},
	title = {Small molecule machine learning: All models are wrong, some may not even be useful},
	elocation-id = {2023.03.27.534311},
	year = {2023},
	doi = {10.1101/2023.03.27.534311},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {A central assumption of all machine learning is that the training data are an informative subset of the true distribution we want to learn. Yet, this assumption may be violated in practice. Recently, learning from the molecular structures of small molecules has moved into the focus of the machine learning community. Usually, those small molecules are of biological interest, such as metabolites or drugs. Applications include prediction of toxicity, ligand binding or retention time.We investigate how well certain large-scale datasets cover the space of all known biomolecular structures. Investigation of coverage requires a sensible distance measure between molecular structures. We use a well-known distance measure based on solving the Maximum Common Edge Subgraph (MCES) problem, which agrees well with the chemical and biochemical intuition of similarity between compounds. Unfortunately, this computational problem is NP-hard, severely restricting the use of the corresponding distance measure in large-scale studies. We introduce an exact approach that combines Integer Linear Programming and intricate heuristic bounds to ensure efficient computations and dependable results.We find that several large-scale datasets frequently used in this domain of machine learning are far from a uniform coverage of known biomolecular structures. This severely confines the predictive power of models trained on this data. Next, we propose two further approaches to check if a training dataset differs substantially from the distribution of known biomolecular structures. On the positive side, our methods may allow creators of large-scale datasets to identify regions in molecular structure space where it is advisable to provide additional training data.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2023/03/27/2023.03.27.534311},
	eprint = {https://www.biorxiv.org/content/early/2023/03/27/2023.03.27.534311.full.pdf},
	journal = {bioRxiv}
}


@misc{dwivedi2021generalizationtransformernetworksgraphs,
      title={A Generalization of Transformer Networks to Graphs}, 
      author={Vijay Prakash Dwivedi and Xavier Bresson},
      year={2021},
      eprint={2012.09699},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2012.09699}, 
}

@article{zhang2023artificial,
  title={Artificial Intelligence for Science in Quantum, Atomistic, and Continuum Systems},
  author={Xuan Zhang and Limei Wang and Jacob Helwig and Youzhi Luo and Cong Fu and Yaochen Xie and {...} and Shuiwang Ji},
  journal={arXiv preprint arXiv:2307.08423},
  year={2023}
}

@misc{liu2022generating3dmoleculestarget,
      title={Generating 3D Molecules for Target Protein Binding}, 
      author={Meng Liu and Youzhi Luo and Kanji Uchino and Koji Maruhashi and Shuiwang Ji},
      year={2022},
      eprint={2204.09410},
      archivePrefix={arXiv},
      primaryClass={q-bio.BM},
      url={https://arxiv.org/abs/2204.09410}, 
}

@misc{corso2023diffdockdiffusionstepstwists,
      title={DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking}, 
      author={Gabriele Corso and Hannes Stärk and Bowen Jing and Regina Barzilay and Tommi Jaakkola},
      year={2023},
      eprint={2210.01776},
      archivePrefix={arXiv},
      primaryClass={q-bio.BM},
      url={https://arxiv.org/abs/2210.01776}, 
}

@article{Watson2023DeND,
  title={De novo design of protein structure and function with RFdiffusion},
  author={Joseph L. Watson and David Juergens and Nathaniel R. Bennett and Brian L. Trippe and Jason Yim and Helen E. Eisenach and Woody Ahern and Andrew J. Borst and Robert J. Ragotte and Lukas F. Milles and Basile I. M. Wicky and Nikita Hanikel and Samuel J. Pellock and Alexis Courbet and William Sheffler and Jue Wang and Preetham Venkatesh and Isaac Sappington and Susana V{\'a}zquez Torres and Anna Lauko and Valentin De Bortoli and Emile Mathieu and Sergey Ovchinnikov and Regina Barzilay and T. Jaakkola and Frank DiMaio and Minkyung Baek and David Baker},
  journal={Nature},
  year={2023},
  volume={620},
  pages={1089 - 1100},
  url={https://api.semanticscholar.org/CorpusID:271161349}
}

@misc{zeni2024mattergengenerativemodelinorganic,
      title={MatterGen: a generative model for inorganic materials design}, 
      author={Claudio Zeni and Robert Pinsler and Daniel Zügner and Andrew Fowler and Matthew Horton and Xiang Fu and Sasha Shysheya and Jonathan Crabbé and Lixin Sun and Jake Smith and Bichlien Nguyen and Hannes Schulz and Sarah Lewis and Chin-Wei Huang and Ziheng Lu and Yichi Zhou and Han Yang and Hongxia Hao and Jielan Li and Ryota Tomioka and Tian Xie},
      year={2024},
      eprint={2312.03687},
      archivePrefix={arXiv},
      primaryClass={cond-mat.mtrl-sci},
      url={https://arxiv.org/abs/2312.03687}, 
}

@misc{ho2020denoisingdiffusionprobabilisticmodels,
      title={Denoising Diffusion Probabilistic Models}, 
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.11239}, 
}

@InProceedings{pmlr-v37-sohl-dickstein15,
  title = 	 {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author = 	 {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2256--2265},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/sohl-dickstein15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
  abstract = 	 {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.}
}


@misc{wang2025madgenmassspecattendsnovo,
      title={MADGEN: Mass-Spec attends to De Novo Molecular generation}, 
      author={Yinkai Wang and Xiaohui Chen and Liping Liu and Soha Hassoun},
      year={2025},
      eprint={2501.01950},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.01950}, 
}

@misc{polykovskiy2020molecularsetsmosesbenchmarking,
      title={Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models}, 
      author={Daniil Polykovskiy and Alexander Zhebrak and Benjamin Sanchez-Lengeling and Sergey Golovanov and Oktai Tatanov and Stanislav Belyaev and Rauf Kurbanov and Aleksey Artamonov and Vladimir Aladinskiy and Mark Veselov and Artur Kadurin and Simon Johansson and Hongming Chen and Sergey Nikolenko and Alan Aspuru-Guzik and Alex Zhavoronkov},
      year={2020},
      eprint={1811.12823},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1811.12823}, 
}

@article{Sorokina_Merseburger_Rajan_Yirik_Steinbeck_2021, title={Coconut online: Collection of open natural products database}, volume={13}, DOI={10.1186/s13321-020-00478-9}, number={1}, journal={Journal of Cheminformatics}, author={Sorokina, Maria and Merseburger, Peter and Rajan, Kohulan and Yirik, Mehmet Aziz and Steinbeck, Christoph}, year={2021}, month={Jan}} 

@article{hmdb,
    author = {Wishart, David S and Guo, AnChi and Oler, Eponine and Wang, Fei and Anjum, Afia and Peters, Harrison and Dizon, Raynard and Sayeeda, Zinat and Tian, Siyang and Lee, Brian L and Berjanskii, Mark and Mah, Robert and Yamamoto, Mai and Jovel, Juan and Torres-Calzada, Claudia and Hiebert-Giesbrecht, Mickel and Lui, Vicki W and Varshavi, Dorna and Varshavi, Dorsa and Allen, Dana and Arndt, David and Khetarpal, Nitya and Sivakumaran, Aadhavya and Harford, Karxena and Sanford, Selena and Yee, Kristen and Cao, Xuan and Budinski, Zachary and Liigand, Jaanus and Zhang, Lun and Zheng, Jiamin and Mandal, Rupasri and Karu, Naama and Dambrova, Maija and Schiöth, Helgi B and Greiner, Russell and Gautam, Vasuk},
    title = {HMDB 5.0: the Human Metabolome Database for 2022},
    journal = {Nucleic Acids Research},
    volume = {50},
    number = {D1},
    pages = {D622-D631},
    year = {2021},
    month = {11},
    abstract = {The Human Metabolome Database or HMDB (https://hmdb.ca) has been providing comprehensive reference information about human metabolites and their associated biological, physiological and chemical properties since 2007. Over the past 15 years, the HMDB has grown and evolved significantly to meet the needs of the metabolomics community and respond to continuing changes in internet and computing technology. This year's update, HMDB 5.0, brings a number of important improvements and upgrades to the database. These should make the HMDB more useful and more appealing to a larger cross-section of users. In particular, these improvements include: (i) a significant increase in the number of metabolite entries (from 114 100 to 217 920 compounds); (ii) enhancements to the quality and depth of metabolite descriptions; (iii) the addition of new structure, spectral and pathway visualization tools; (iv) the inclusion of many new and much more accurately predicted spectral data sets, including predicted NMR spectra, more accurately predicted MS spectra, predicted retention indices and predicted collision cross section data and (v) enhancements to the HMDB’s search functions to facilitate better compound identification. Many other minor improvements and updates to the content, the interface, and general performance of the HMDB website have also been made. Overall, we believe these upgrades and updates should greatly enhance the HMDB’s ease of use and its potential applications not only in human metabolomics but also in exposomics, lipidomics, nutritional science, biochemistry and clinical chemistry.},
    issn = {0305-1048},
    doi = {10.1093/nar/gkab1062},
    url = {https://doi.org/10.1093/nar/gkab1062},
    eprint = {https://academic.oup.com/nar/article-pdf/50/D1/D622/42058215/gkab1062.pdf},
}


@article{CCTE2019,
author = "EPA CCTE",
title = "{Distributed Structure-Searchable Toxicity (DSSTox) Database}",
year = "2019",
month = "4",
url = "https://epa.figshare.com/articles/dataset/Chemistry_Dashboard_Data_DSSTox_Identifiers_Mapped_to_CAS_Numbers_and_Names/5588566",
doi = "10.23645/epacomptox.5588566.v7"
}

@misc{nichol2021improveddenoisingdiffusionprobabilistic,
      title={Improved Denoising Diffusion Probabilistic Models}, 
      author={Alex Nichol and Prafulla Dhariwal},
      year={2021},
      eprint={2102.09672},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2102.09672}, 
}

@misc{lou2024discretediffusionmodelingestimating,
      title={Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution}, 
      author={Aaron Lou and Chenlin Meng and Stefano Ermon},
      year={2024},
      eprint={2310.16834},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2310.16834}, 
}

@misc{austin2023structureddenoisingdiffusionmodels,
      title={Structured Denoising Diffusion Models in Discrete State-Spaces}, 
      author={Jacob Austin and Daniel D. Johnson and Jonathan Ho and Daniel Tarlow and Rianne van den Berg},
      year={2023},
      eprint={2107.03006},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2107.03006}, 
}

@misc{chen2023efficientdegreeguidedgraphgeneration,
      title={Efficient and Degree-Guided Graph Generation via Discrete Diffusion Modeling}, 
      author={Xiaohui Chen and Jiaxing He and Xu Han and Li-Ping Liu},
      year={2023},
      eprint={2305.04111},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.04111}, 
}

@misc{bushuiev2024massspecgymbenchmarkdiscoveryidentification,
      title={MassSpecGym: A benchmark for the discovery and identification of molecules}, 
      author={Roman Bushuiev and Anton Bushuiev and Niek F. de Jonge and Adamo Young and Fleming Kretschmer and Raman Samusevich and Janne Heirman and Fei Wang and Luke Zhang and Kai Dührkop and Marcus Ludwig and Nils A. Haupt and Apurva Kalia and Corinna Brungs and Robin Schmid and Russell Greiner and Bo Wang and David S. Wishart and Li-Ping Liu and Juho Rousu and Wout Bittremieux and Hannes Rost and Tytus D. Mak and Soha Hassoun and Florian Huber and Justin J. J. van der Hooft and Michael A. Stravs and Sebastian Böcker and Josef Sivic and Tomáš Pluskal},
      year={2024},
      eprint={2410.23326},
      archivePrefix={arXiv},
      primaryClass={q-bio.QM},
      url={https://arxiv.org/abs/2410.23326}, 
}

@article{tian2021ubiquitous,
  title={A ubiquitous tire rubber--derived chemical induces acute mortality in coho salmon},
  author={Tian, Zhenyu and Zhao, Haoqi and Peter, Katherine T and Gonzalez, Melissa and Wetzel, Jill and Wu, Christopher and Hu, Ximin and Prat, Jasmine and Mudrock, Emma and Hettinger, Rachel and others},
  journal={Science},
  volume={371},
  number={6525},
  pages={185--189},
  year={2021},
  publisher={American Association for the Advancement of Science}
}

@article{dang2009cancer,
  title={Cancer-associated IDH1 mutations produce 2-hydroxyglutarate},
  author={Dang, Lenny and White, David W and Gross, Stefan and Bennett, Bryson D and Bittinger, Mark A and Driggers, Edward M and Fantin, Valeria R and Jang, Hyun Gyung and Jin, Shengfang and Keenan, Marie C and others},
  journal={Nature},
  volume={462},
  number={7274},
  pages={739--744},
  year={2009},
  publisher={Nature Publishing Group UK London}
}

@article{quinn2020global,
  title={Global chemical effects of the microbiome include new bile-acid conjugations},
  author={Quinn, Robert A and Melnik, Alexey V and Vrbanac, Alison and Fu, Ting and Patras, Kathryn A and Christy, Mitchell P and Bodai, Zsolt and Belda-Ferre, Pedro and Tripathi, Anupriya and Chung, Lawton K and others},
  journal={Nature},
  volume={579},
  number={7797},
  pages={123--129},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{bittremieux2022critical,
  title={The critical role that spectral libraries play in capturing the metabolomics community knowledge},
  author={Bittremieux, Wout and Wang, Mingxun and Dorrestein, Pieter C},
  journal={Metabolomics},
  volume={18},
  number={12},
  pages={94},
  year={2022},
  publisher={Springer}
}

@article{morgan1965generation,
  title={The generation of a unique machine description for chemical structures-a technique developed at chemical abstracts service.},
  author={Morgan, Harry L},
  journal={Journal of chemical documentation},
  volume={5},
  number={2},
  pages={107--113},
  year={1965},
  publisher={ACS Publications}
}

@article{le2020neuraldecipher,
  title={Neuraldecipher--reverse-engineering extended-connectivity fingerprints (ECFPs) to their molecular structures},
  author={Le, Tuan and Winter, Robin and No{\'e}, Frank and Clevert, Djork-Arn{\'e}},
  journal={Chemical science},
  volume={11},
  number={38},
  pages={10378--10389},
  year={2020},
  publisher={Royal Society of Chemistry}
}

@article{duhrkop2015csifingerid,
  title={Searching molecular structure databases with tandem mass spectra using CSI: FingerID},
  author={D{\"u}hrkop, Kai and Shen, Huibin and Meusel, Marvin and Rousu, Juho and B{\"o}cker, Sebastian},
  journal={Proceedings of the National Academy of Sciences},
  volume={112},
  number={41},
  pages={12580--12585},
  year={2015},
  publisher={National Acad Sciences}
}

@article{goldman2023mist,
  title={Annotating metabolite mass spectra with domain-inspired chemical formula transformers},
  author={Goldman, Samuel and Wohlwend, Jeremy and Stra{\v{z}}ar, Martin and Haroush, Guy and Xavier, Ramnik J and Coley, Connor W},
  journal={Nature Machine Intelligence},
  volume={5},
  number={9},
  pages={965--979},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{goldman2023scarf,
  title={Prefix-tree decoding for predicting mass spectra from molecules},
  author={Goldman, Samuel and Bradshaw, John and Xin, Jiayi and Coley, Connor},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={48548--48572},
  year={2023}
}

@article{goldman2024iceberg,
  title={Generating molecular fragmentation graphs with autoregressive neural networks},
  author={Goldman, Samuel and Li, Janet and Coley, Connor W},
  journal={Analytical Chemistry},
  volume={96},
  number={8},
  pages={3419--3428},
  year={2024},
  publisher={ACS Publications}
}

@article{allen2015cfm-id,
  title={Competitive fragmentation modeling of ESI-MS/MS spectra for putative metabolite identification},
  author={Allen, Felicity and Greiner, Russ and Wishart, David},
  journal={Metabolomics},
  volume={11},
  pages={98--110},
  year={2015},
  publisher={Springer}
}

@article{wang2021cfm-id4,
  title={CFM-ID 4.0: more accurate ESI-MS/MS spectral prediction and compound identification},
  author={Wang, Fei and Liigand, Jaanus and Tian, Siyang and Arndt, David and Greiner, Russell and Wishart, David S},
  journal={Analytical chemistry},
  volume={93},
  number={34},
  pages={11692--11700},
  year={2021},
  publisher={ACS Publications}
}

@inproceedings{vignac2023digress,
  title={Digress: Discrete denoising diffusion for graph generation},
  author={Vignac, Clement and Krawczuk, Igor and Siraudin, Antoine and Wang, Bohan and Cevher, Volkan and Frossard, Pascal},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Neural Info. Process. Systems},
  volume={30},
  year={2017}
}

@article{irwin2020zinc20,
  title={ZINC20—a free ultralarge-scale chemical database for ligand discovery},
  author={Irwin, John J and Tang, Khanh G and Young, Jennifer and Dandarchuluun, Chinzorig and Wong, Benjamin R and Khurelbaatar, Munkhzul and Moroz, Yurii S and Mayfield, John and Sayle, Roger A},
  journal={Journal of chemical information and modeling},
  volume={60},
  number={12},
  pages={6065--6073},
  year={2020},
  publisher={ACS Publications}
}

@article{butler2023ms2mol,
  title={MS2Mol: A transformer model for illuminating dark chemical space from mass spectra},
  author={Butler, Thomas and Frandsen, Abraham and Lightheart, Rose and Bargh, Brian and Taylor, James and Bollerman, TJ and Kerby, Thomas and West, Kiana and Voronov, Gennady and Moon, Kevin and others},
  year={2023},
  journal={ChemRxiv}
}

@article{stravs2022msnovelist,
  title={MSNovelist: de novo structure generation from mass spectra},
  author={Stravs, Michael A and D{\"u}hrkop, Kai and B{\"o}cker, Sebastian and Zamboni, Nicola},
  journal={Nature Methods},
  volume={19},
  number={7},
  pages={865--870},
  year={2022},
  publisher={Nature Publishing Group US New York}
}

@article{litsa2023spec2mol,
  title={An end-to-end deep learning framework for translating mass spectra to de-novo molecules},
  author={Litsa, Eleni E and Chenthamarakshan, Vijil and Das, Payel and Kavraki, Lydia E},
  journal={Communications Chemistry},
  volume={6},
  number={1},
  pages={132},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{wang2024learning,
  author={Runzhong Wang and Yang Li and Junchi Yan and Xiaokang Yang},
  title={Learning to Solve Combinatorial Optimization under Positive Linear Constraints via Non-Autoregressive Neural Networks},
  journal={SCIENTIA SINICA Informationis},
  year={2024},
  doi={https://doi.org/10.1360/SSI-2023-0269}
}

@article{wang2021neural,
  title={Neural graph matching network: Learning lawler’s quadratic assignment problem with extension to hypergraph and multiple-graph matching},
  author={Wang, Runzhong and Yan, Junchi and Yang, Xiaokang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={9},
  pages={5261--5279},
  year={2021},
  publisher={IEEE}
}

@article{bengio2021machine,
  title={Machine learning for combinatorial optimization: a methodological tour d’horizon},
  author={Bengio, Yoshua and Lodi, Andrea and Prouvost, Antoine},
  journal={European Journal of Operational Research},
  volume={290},
  number={2},
  pages={405--421},
  year={2021},
  publisher={Elsevier}
}

@article{khalil2017learning,
  title={Learning combinatorial optimization algorithms over graphs},
  author={Khalil, Elias and Dai, Hanjun and Zhang, Yuyu and Dilkina, Bistra and Song, Le},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{alberts2023learning,
  title={Learning the Language of NMR: Structure Elucidation from NMR spectra using Transformer Models},
  author={Alberts, Marvin and Zipoli, Federico and Vaucher, Alain C},
  booktitle={NeurIPS 2023 Workshop},
  year={2023}
}

@book{lindsay1980dendral,
  title={Applications of artificial intelligence for organic chemistry: the DENDRAL project},
  author={Lindsay, Robert K and B. Buchanan and E. Feigenbaum and J. Lederberg},
  publisher={McGraw-Hill Companies},
  year={1980}
}

@article{shrivastava2021massgenie,
  title={MassGenie: A transformer-based deep learning method for identifying small molecules from their mass spectra},
  author={Shrivastava, Aditya Divyakant and Swainston, Neil and Samanta, Soumitra and Roberts, Ivayla and Wright Muelas, Marina and Kell, Douglas B},
  journal={Biomolecules},
  volume={11},
  number={12},
  pages={1793},
  year={2021},
  publisher={MDPI}
}

@article{gomez2018automatic,
  title={Automatic chemical design using a data-driven continuous representation of molecules},
  author={G{\'o}mez-Bombarelli, Rafael and Wei, Jennifer N and Duvenaud, David and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and S{\'a}nchez-Lengeling, Benjam{\'\i}n and Sheberla, Dennis and Aguilera-Iparraguirre, Jorge and Hirzel, Timothy D and Adams, Ryan P and Aspuru-Guzik, Al{\'a}n},
  journal={ACS central science},
  volume={4},
  number={2},
  pages={268--276},
  year={2018},
  publisher={ACS Publications}
}

@article{segler2018generating,
  title={Generating focused molecule libraries for drug discovery with recurrent neural networks},
  author={Segler, Marwin HS and Kogej, Thierry and Tyrchan, Christian and Waller, Mark P},
  journal={ACS central science},
  volume={4},
  number={1},
  pages={120--131},
  year={2018},
  publisher={ACS Publications}
}

@article{liu2018constrained,
  title={Constrained graph variational autoencoders for molecule design},
  author={Liu, Qi and Allamanis, Miltiadis and Brockschmidt, Marc and Gaunt, Alexander},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{simonovsky2018graphvae,
  title={Graphvae: Towards generation of small graphs using variational autoencoders},
  author={Simonovsky, Martin and Komodakis, Nikos},
  booktitle={Artificial Neural Networks and Machine Learning--ICANN 2018: 27th International Conference on Artificial Neural Networks, Rhodes, Greece, October 4-7, 2018, Proceedings, Part I 27},
  pages={412--422},
  year={2018},
  organization={Springer}
}

@article{li2018learning,
  title={Learning deep generative models of graphs},
  author={Li, Yujia and Vinyals, Oriol and Dyer, Chris and Pascanu, Razvan and Battaglia, Peter},
  journal={arXiv preprint arXiv:1803.03324},
  year={2018}
}

@article{flam2022scalable,
  title={Scalable fragment-based 3d molecular design with reinforcement learning},
  author={Flam-Shepherd, Daniel and Zhigalin, Alexander and Aspuru-Guzik, Al{\'a}n},
  journal={arXiv preprint arXiv:2202.00658},
  year={2022}
}

@article{adams2022equivariant,
  title={Equivariant shape-conditioned generation of 3d molecules for ligand-based drug design},
  author={Adams, Keir and Coley, Connor W},
  journal={arXiv preprint arXiv:2210.04893},
  year={2022}
}

@inproceedings{luo2022autoregressive,
  title={An autoregressive flow model for 3d molecular geometry generation from scratch},
  author={Luo, Youzhi and Ji, Shuiwang},
  booktitle={International conference on learning representations (ICLR)},
  year={2022}
}

@article{luo20213d,
  title={A 3D generative model for structure-based drug design},
  author={Luo, Shitong and Guan, Jiaqi and Ma, Jianzhu and Peng, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={6229--6239},
  year={2021}
}

@article{young2024fragnnet,
  title={FraGNNet: A Deep Probabilistic Model for Mass Spectrum Prediction},
  author={Young, Adamo and Wang, Fei and Wishart, David and Wang, Bo and R{\"o}st, Hannes and Greiner, Russ},
  journal={arXiv preprint arXiv:2404.02360},
  year={2024}
}

@article{nowatzky2024fiora,
  title={Fiora: Local neighborhood-based prediction of compound mass spectra from single fragmentation events},
  author={Nowatzky, Yannek and Russo, Francesco and Lisec, Jan and Kister, Alexander and Reinert, Knut and Muth, Thilo and Benner, Philipp},
  journal={bioRxiv},
  pages={2024--04},
  year={2024},
  publisher={Cold Spring Harbor Laboratory}
}

@article{young2024massformer,
  title={Tandem mass spectrum prediction for small molecules using graph transformers},
  author={Young, Adamo and R{\"o}st, Hannes and Wang, Bo},
  journal={Nature Machine Intelligence},
  volume={6},
  number={4},
  pages={404--416},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{murphy2023efficiently,
  title={Efficiently predicting high resolution mass spectra with graph neural networks},
  author={Murphy, Michael and Jegelka, Stefanie and Fraenkel, Ernest and Kind, Tobias and Healey, David and Butler, Thomas},
  booktitle={International Conference on Machine Learning},
  pages={25549--25562},
  year={2023},
  organization={PMLR}
}

@article{bocker2016fragmentation,
  title={Fragmentation trees reloaded},
  author={B{\"o}cker, Sebastian and D{\"u}hrkop, Kai},
  journal={Journal of cheminformatics},
  volume={8},
  pages={1--26},
  year={2016},
  publisher={Springer}
}

@article{goldman2023mist-cf,
  title={MIST-CF: Chemical formula inference from tandem mass spectra},
  author={Goldman, Samuel and Xin, Jiayi and Provenzano, Joules and Coley, Connor W},
  journal={Journal of Chemical Information and Modeling},
  volume={64},
  number={7},
  pages={2421--2431},
  year={2023},
  publisher={ACS Publications}
}

@article{duhrkop2021canopus,
  title={Systematic classification of unknown metabolites using high-resolution fragmentation mass spectra},
  author={D{\"u}hrkop, Kai and Nothias, Louis-F{\'e}lix and Fleischauer, Markus and Reher, Raphael and Ludwig, Marcus and Hoffmann, Martin A and Petras, Daniel and Gerwick, William H and Rousu, Juho and Dorrestein, Pieter C and others},
  journal={Nature biotechnology},
  volume={39},
  number={4},
  pages={462--471},
  year={2021},
  publisher={Nature Publishing Group US New York}
}

@article{li2024distribution,
  title={From distribution learning in training to gradient search in testing for combinatorial optimization},
  author={Li, Yang and Guo, Jinpei and Wang, Runzhong and Yan, Junchi},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{hu2024continuous,
  title={Continuous collective analysis of chemical reactions},
  author={Hu, Maowei and Yang, Lei and Twarog, Nathaniel and Ochoada, Jason and Li, Yong and Vrettos, Eirinaios I and Torres-Hernandez, Arnaldo X and Martinez, James B and Bhatia, Jiya and Young, Brandon M and others},
  journal={Nature},
  volume={636},
  number={8042},
  pages={374--379},
  year={2024},
  publisher={Nature Publishing Group}
}

@article{gentry2024reverse,
  title={Reverse metabolomics for the discovery of chemical structures from humans},
  author={Gentry, Emily C and Collins, Stephanie L and Panitchpakdi, Morgan and Belda-Ferre, Pedro and Stewart, Allison K and Carrillo Terrazas, Marvic and Lu, Hsueh-han and Zuffa, Simone and Yan, Tingting and Avila-Pacheco, Julian and others},
  journal={Nature},
  volume={626},
  number={7998},
  pages={419--426},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{roney2022generating,
  title={Generating realistic 3d molecules with an equivariant conditional likelihood model},
  author={Roney, James P and Maragakis, Paul and Skopp, Peter and Shaw, David E},
  year={2022}
}


@misc{nist_database,
  title        = {{NIST} Standard Reference Database},
  author       = {NIST},
  year         = {2023},
  howpublished = {National Institute of Standards {and} Technology},
  url          = {https://www.nist.gov/srd},
}