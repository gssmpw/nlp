\clearpage
\section{Training time versus perplexity on the LM1B dataset}
\label{app:training-time-vs-perplexity}

This appendix provides additional results on training time versus perplexity for DCA models. Figure~\ref{fig:perplexity_vs_training_time} shows the training time-perplexity trade-off for 12, 24, and 36 layer transformer and DCA models trained on the LM1B dataset. The figure shows that DCA achieves a better perplexity for a given training time (except for the first few training steps of the 36-layer model). Thus, highlighting the training efficiency of DCA.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\linewidth]{figures/dca_lm1b_perplexity_vs_training_time.pdf}
    \vskip -0.1in
    \caption{Perplexity on LM1B pre-training versus the training time with transformer and DCA models of various depths.}
    \label{fig:perplexity_vs_training_time}
\end{figure}

\section{Steps versus perplexity on the C4 dataset}
\label{app:steps-vs-perplexity}

This appendix provides additional results on training steps versus perplexity for 8-DCA models. Figure~\ref{fig:c4_perplexity_vs_steps} shows the training steps-perplexity trade-off for 75M, 179M, and 449M parameter transformer and 8-DCA models trained on the C4 dataset. The results show the improved model convergence and quality of DCA.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\linewidth]{figures/c4.pdf}
    \vskip -0.1in
    \caption{Perplexity on C4 pre-training versus the number of steps with transformer and 8-DCA models of various sizes.}
    \label{fig:c4_perplexity_vs_steps}
\end{figure}

\clearpage
\section{Distribution of learned weights}
\label{app:weight-distribution}

Figure~\ref{fig:lm1b_30_layer_bias_stats} shows the distribution of the learned bias values for each \GenC{} instance of a 30-layer model. The layers tend to weight the inputs and the last few layers the most and frequently assign a negative bias for the intermediate layers, indicating that the layers are filtered out as a result of the ReLU activation. 
% These results are inline with our hypothesis that with the standard residual network the information in the layer inputs is diluted.

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/lm1b_30_layer_bias_stats.pdf}
    \caption{Distribution of learned bias values on LM1B pre-training with a 30 layer \GenC{} transformer model. The solid line indicates the median value and the shaded area represents the 90th percentile.}
    \label{fig:lm1b_30_layer_bias_stats}
\end{figure*}