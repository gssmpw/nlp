\section{Introduction}

% Temporal reasoning, a fundamental cognitive ability, plays a crucial role in human perception \cite{hoerl2019thinking}. 
% It encompasses not only basic concepts such as ordering and duration but also more complex functions like task planning and causal relation discovery \cite{vila1994survey}. 
% Despite the remarkable advancements in large language models (LLMs) and their emerging reasoning capabilities \cite{huang2023towards}, previous studies have shown that their performance in temporal reasoning remains suboptimal \cite{chu-etal-2024-timebench,qiu2024large}.

In the context of multi-session dialogues, temporal reasoning is both critical and challenging for LLM-agents. As the number of dialogue sessions increases, storing and retrieving relevant information efficiently becomes more difficult \cite{maharana-etal-2024-evaluating}. LLMs often face challenges in managing large, long-term dialogues, such as failing to retrieve specific temporal details from long history and dialogues exceed the input limit of LLMs. Additionally, research has shown that LLMs overlook important contextual information from long dialogue histories due to the accumulation of irrelevant historical data, referred to as "historical noise" \cite{wang2023enhancing}. 
% Additionally, as shown in Figure \ref{fig:relative_time}, when GPT-4o is prompted via CoT to answer the interval between two events expressed with relative time, the model tends to ignore the relative time cues. Particularly, when the relative time is changed from "last week" to "last month" or "last year," the model still provides the same answer. 
These challenges underscore the need for enhanced temporal reasoning capabilities in LLM-agents for effective handling of multi-session dialogues.


% \begin{figure*}
%     \centering
%     \includegraphics[width=\linewidth]{figures/relative_time_2.png}
%     \caption{An example of GPT-4o ignoring relative time in short dialogues when it's asked about the temporal interval between two events via CoT.}
%     \label{fig:relative_time}
% \vspace{-5mm}
% \end{figure*}

\begin{figure}  
\centering
\includegraphics[width=\linewidth]{figures/example.png}
    \caption{Examples from LoCoMo showing the two temporal characteristics we focus on in this work.} 
    \label{fig:example}
\vspace{-5mm}
\end{figure}

However, most existing temporal reasoning benchmarks cannot be used directly for this study, because they are built on shorter texts, such as stories and Wikipedia articles, that contain clear temporal information \cite{chen2dataset,wang-zhao-2024-tram,xiong-etal-2024-large}. Even benchmarks designed for dialogues, like TimeDial \cite{qin2021timedial} and LoCoMo \cite{maharana-etal-2024-evaluating}, do not explicitly account for the special temporal characteristics in multi-session dialogues, such as \textit{relative time} and \textit{cross-session dependency}. For instance, speakers often use relative time expressions instead of specific dates, requiring the model to infer exact event times. Moreover, it is common for speakers to recall past events from previous sessions, creating cross-session dependencies, where events from different sessions involve the same or related entities and reflect changes over time. This further requires LLMs to retain context effectively when reasoning about events across multiple sessions.


In this work, we present \textbf{TReMu} (\textbf{T}emporal \textbf{Re}asoning for LLM-Agents in \textbf{Mu}lti-Session Dialogues), a novel framework designed to enhance temporal reasoning in multi-session dialogues. Our framework introduces \textbf{time-aware memorization}, which uses timeline summarization to generate summaries for each dialogue session, identifying events and associating them with their inferred dates. These summaries, linked to specific times (either session times or inferred event dates), serve as retrievable memory. This effectively addresses events expressed in relative time by distinguishing when such an event occurred from when it was mentioned by the speaker.

During reasoning, we propose a \textbf{neuro-symbolic temporal reasoning} approach inspired by recent work that integrates LLMs with symbolic reasoning, translating questions into symbolic language before using a solver to find answers \cite{pan2023logic,olausson2023linc}. Specifically, given a temporal question, we retrieve relevant memory and instruct the LLMs to generate Python code. This approach leverages the LLMs' strong Python coding capabilities and existing Python libraries for temporal calculations. The generated code serves as an intermediate rationale. By executing the code line-by-line, the model follows step-by-step reasoning similar to CoT \cite{wei2022chain}, leading the model to select the correct answer.

Due to the absence of temporal reasoning evaluation benchmarks specific to multi-session dialogues, we propose a method to construct a new evaluation benchmark focusing on two key temporal characteristics: \textit{relative time} and \textit{cross-session dependency}. By augmenting dialogues from LoCoMo \cite{maharana-etal-2024-evaluating}, we create multiple-choice temporal questions spanning three types of reasoning to evaluate the temporal reasoning capabilities of LLMs in this context.

We evaluate our framework based on three popular LLMs—GPT-4o, GPT-4o-mini, and GPT-3.5-Turbo—on our benchmark. The results show that our benchmark is challenging, revealing suboptimal performance for LLMs. In contrast, our framework demonstrates superior performance compared to baseline methods, such as CoT, highlighting the effectiveness of our approach in improving temporal reasoning in multi-session dialogues.

Our contributions are as follows: 
\begin{itemize} 
    \item We propose a new framework for temporal reasoning in multi-session dialogues, integrating time-aware memorization and neuro-symbolic temporal reasoning. 
    \item We propose a method to construct a temporal reasoning evaluation benchmark for multi-session dialogues by augmenting an existing dataset, explicitly covering the temporal characteristics of relative time and cross-session dependency. 
    \item Through extensive experiments, we empirically show that temporal reasoning in multi-session dialogues poses significant challenges for LLMs, even with strategies like CoT. However, our framework significantly improves LLMs' temporal reasoning in this context. 
\end{itemize}