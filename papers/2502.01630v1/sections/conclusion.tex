\section{Conclusion}
In this paper, we address the critical challenge of temporal reasoning in multi-session dialogues for LLM-agents. We present a method to construct a temporal reasoning evaluation benchmark by augmenting dialogues from LoCoMo, specifically targeting the temporal characteristics of relative time and cross-session dependency. Furthermore, we introduce a novel framework which combines time-aware memorization through timeline summarization with neuro-symbolic temporal reasoning by translating temporal questions into executable Python code. 
% This approach enhances LLMs' ability to reason about temporal events by leveraging external memory and symbolic computations. 
Through extensive evaluations, we demonstrate that our benchmark presents significant challenges, and our framework substantially outperforms baseline methods in improving temporal reasoning for multi-session dialogues.
