\section{Conclusion and Perspective}

In this paper we propose a novel architecture for the \textit{solver-in-the-loop} approach originally introduced in \citeauthor{um2020solver} (\citeyear{um2020solver}) and \citeauthor{kochkov2021machine} (\citeyear{kochkov2021machine}). Both papers relied on a CNN to correct the outputs of a standard numerical base solver for the time dependent Navier-Stokes equations. We have shown here that the performance of the CNN based architecture is highly reliant on a large input stencil (the size of the window from which the information is drawn) to compute its correction. While this is not an issue for Cartesian grid based solvers, it makes the approach hard to integrate in existing large-scale industrial solvers working on unstructured meshes. In the latter case,  the "only" information available per cell are the variables (velocity, pressure, etc.) coming from the direct neighbouring cells. As an alternative to CNN based architecture, we propose a model compatible with simple feed forward networks (shared by each cell) and using information from direct neighbours only. Since information from cells farther away is not directly available, we use an additional hidden state vector, stored cell-wise, to encode missing information. Crucially, this hidden state vector needs to be updated between each time step and we do so in a fully learnable way, based on the current velocity. The hidden state vector thus replaces the spatial information available to the CNN based architecture with an history dependent one. A parallel can be drawn to the additional physical variables that are transported with the flow in classical turbulence models. Indeed, analysis of the hidden state vector during the flow history shows that it is also transported, even if the architecture itself does not explicitly enforce it. We call this approach Transported Memory Network (TMN). Compared to classical CNNs the approach relies only on direct neighbor information and thus is relative geometric agnostic. This will likely improve generalization capabilities in realistic industrial scenarios. 

Our results show that the TMN architecture compares very well with the CNN based architecture by \citeauthor{kochkov2021machine} (\citeyear{kochkov2021machine}), yet shows advantages in terms of speed (latency of the model). To obtain comparable point-wise accuracy 8 hidden states are sufficient and for equivalent statistical accuracy only 2 hidden states are required. Since furthermore only local input is required, the TMN architecture is thus a strong candidate to bring the \textit{solver-in-the-loop} approach in state-of-the-art industrial CFD codes. 

The next steps to be addressed towards full integration include testing the approach on actual unstructured meshes (including in 3D), handling of more general boundary conditions, and making it compatible with variable time steps. Last but not least we plan to do some more excessive benchmarking as well as ablation studies.
