\section{Background}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Computational Fluid Dynamics}\label{sec:CFD}

\paragraph{Navier-Stokes Equations:} 
Within this contribution we focus on incompressible fluids. These are described by the incompressible Navier-Stokes equations \cite{acheson1990elementary}:
{\footnotesize
\begin{align}
    \rho \left(\partial_t \vec{u} + \vec{u} \cdot \nabla \vec{u} \right) &=
       - \nabla p + \nabla \cdot \bm{\tau} + \rho \vec{f}, \label{eq:NS01}\\
    \nabla \cdot \vec{u} &= 0,   \label{eq:NS02}
\end{align}}

\noindent
where $\vec{u}$ is the flow velocity, $p$ the pressure, $\bm{\tau}$ the deviatoric stress tensor, $\vec{f}$ an external body force, and $\rho$ the constant fluid density. In its native form, $\bm{\tau}$ is linearly dependent on the strain rate tensor, i.e.,  $\nabla \cdot \bm{\tau} = \mu \Delta \vec{u}$ with dynamic viscosity $\mu$. In most industrial applications, solving Equations (\ref{eq:NS01})-(\ref{eq:NS02}) numerically would require very fine spatial and temporal resolutions. Instead, so-called turbulence models extending the Navier-Stokes equations have been proposed to address this challenge \cite{pope2000turbulent}. These turbulence models introduce appropriate corrections to the stress tensor $\bm{\tau}$ and various options have been proposed \cite{pope2000turbulent}.  

\paragraph{Numerical Solvers:}
A broad toolbox of numerical solvers for CFD have been proposed \cite{Kelsall2022CFD} in the past. These include particle based discretizations, e.g., Smooth Particle Hydrodynamics \cite{onate2011particle} or Lattice Boltzman methods \cite{kruger2017lattice}, global discretization methods, e.g., Spectral methods \cite{shen2011spectral}, as well as local grid based discretization methods, e.g., Finite Element \cite{turek1999efficient}, Finite Volume \cite{moukalled2016finite} or Finite Difference schemes \cite{griebel1998numerical}. Within this contribution we aim to improve state-of-the-art industrial methods usually based on Finite Volume (FV) schemes. Thus, we will focus on local discretization methods where we furthermore restrict ourselves to regular structured grids without loss of generality.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Pure Neural CFD Solvers}\label{sec:neuralCFD}
As an alternative to numerical solvers a wide range of neural network based pure ML solvers have been proposed recently. They can be classified into two distinct approaches: Operator Learning Methods and Physics-Constrained Methods.

\paragraph{Operator Learning Methods:} These methods directly learn the physics operator, e.g., learn the iteration from one time step to the next (dynamic CFD) or the mapping from a geometry to the corresponding flow field (stationary CFD). That is, they learn the solution operator (numerical solver). Examples include convolutional methods \cite{guo2016convolutional}, DeepONets \cite{lu2021learning}, Fourier Neural Operators \cite{li2020fourier}, Graph Neural Networks \cite{sanchez2020learning}, and recently attention based / transformer architectures, e.g., \cite{alkin2024universal, raonic2024convolutional, hao2023gnot, wu2023solving,luo2025transolver++}. 

\paragraph{Physics-Constrained Methods:} These methods use physics knowledge to constrain ML approaches. The most prominent are Physics Informed Neural Networks, where physics equations are introduced as constraints in the loss function \cite{lagaris1998artificial,raissi2019physics}. Adapting zero-shot learning corresponding methods could partially replace classical solvers. Extensions are multifold, e.g., using domain decomposition \cite{dolean2023multilevel} or reservoir-computing concepts \cite{chen2022bridging}, significantly enhancing their effectiveness. 

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\subsection{Hybrid CFD Solvers}
\label{sec:LC_CNN_models}

Hybrid methods, focus of this paper, combine a classical solver based on a coarse mesh - the base solver - enriched with ML methods to achieve a comparable accuracy as obtained on a fine mesh \cite{sanderse2024scientific}, see Figure \ref{fig:overview}. Instead of computing an "exact" velocity $\vec{u}$, they resolve "only" a coarse-grained velocity $\vec{U}$ and introduce additional corrections / modifications to Equations (\ref{eq:NS01})-(\ref{eq:NS02}) ensuring that the effects of unresolved scales are appropriately reflected, i.e., $\vec{U}(t) = <\vec{u}(t)>$ with an appropriate averaging $<\cdot>$, maximizing accuracy and robustness. Unresolved scales could be recovered via super-resolution methods \cite{shu2023physics}, however in most industrial application one is interested only in integral quantities, such as drag and lift, which can be effectively calculated from coarse-grained velocities. Typically hybrid methods require significantly less training data than Operator Learning Methods \cite{melchers2023comparison}.

Here, we follow closely \citeauthor{um2020solver} (\citeyear{um2020solver}) and \citeauthor{kochkov2021machine} (\citeyear{kochkov2021machine})
which additionally introduce an autoregressive training approach. That is, during training sets of velocitiy trajectories $(\vec{U}_{i}, \vec{U}_{i+1}, \ldots \vec{U}_{i+N})$ are compared to the down-sampled outputs of a reference high resolution solver. The loss, measuring the mismatch, is then minimized through gradient descent. That is, the learned model is applied many times, autoregressively, for a single training step and thus a trajectory is fit and not only a single time step as in many earlier approaches \cite{melchers2023comparison}. Thus, the gradients need to "flow" through the solver \cite{list2024temporal} and corresponding methods are referred to \textit{solver-in-the-loop}.

Specifically, \citeauthor{um2020solver} (\citeyear{um2020solver}) introduces a learned correction (LC) approach, where a corrective term is added to the output of a coarse solver after each time step, i.e. to $\vec{U}_i$. The correction term is approximated by a neural network taking as input the current velocity field. The corrected velocity field is then used as the input velocity $\vec{U}_{i-1}$ in the subsequent time step. 

\citeauthor{kochkov2021machine} (\citeyear{kochkov2021machine}) also studied this learned correction approach and compared it to a learned interpolation (LI) approach where the coefficient for the interpolation of the velocity in the advection scheme of the solver are learned. More recently, \citeauthor{sun2023neuralpdesolvertemporal} (\citeyear{sun2023neuralpdesolvertemporal}) proposed to improve upon it by including temporal information as an input to the network. The LI approach can be thought as a way to incorporate more physical prior to the learned model because the learned coefficients can be constrained to be at least first order accurate. Compared to the LI approach, the LC approach is easier to integrate in an already existing industrial CFD code due to its minimally invasive architecture. Thus, for the rest of the paper we focus on the LC model. 

In both \citeauthor{um2020solver} (\citeyear{um2020solver}) and \citeauthor{kochkov2021machine} (\citeyear{kochkov2021machine}) a CNN is used for the corrective term (as for the LI approach of \citeauthor{kochkov2021machine}). That is, for computing the correction to the velocity at a given cell the network is drawing information from a rather large stencil around the considered cell. For instance, the architecture used in \citeauthor{kochkov2021machine} consists of 7 layers of convolutions with $3\times3$ kernels, implying that the network uses information from a $15\times15$ stencil around the cell for which the correction is computed\footnote{In the first convolutional layer, a given neuron uses information from a $3\times3$ stencil around the cell, but at the next layer, the $3\times3$ kernel draws information from the neighbouring neurons which themselves contain information from a $3\times3$ stencil around their respective input cells. That is, the second layer sees information from a $5\times5$ stencil. At the 7\textsuperscript{th} and last layer the network finally has access to information coming from a $15\times15$ stencil around a given cell}, c.f., Figure \ref{fig:input_stencil}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\columnwidth]{Figures/input_stencil.pdf}
    \caption{Input stencil for the corrector for a given cell on the forced turbulence : $64\times64$ grid on $[0;2\pi]\times[0;2\pi]$ domain. Case taken from \citeauthor{kochkov2021machine}.}
    \label{fig:input_stencil}
\end{figure}

The non-local nature of the correction computed through CNNs brings significant benefits since many fluid properties, e.g., due to turbulence, usually depend on the history of flow pathlines. Our experiments have shown that the larger the non-locality of the correction, the more accurate predictions are (see Section \ref{sec:stencil_study}). That is, the performance of the learned correction approach is directly linked to the size of the CNN stencil from which the information is drawn. This underlines that CNN based  approaches are able to indirectly resolve the Lagrangian nature of flows within Eulerian formulations by going back in space instead of going back in time\footnote{That is, while the physics, and as such intrinsic properties as turbulent structures, are transported  with the fluid, any information is stored usually in a grid fixed in space and not moving with the fluid.}. In contrast, most classical turbulence models, which are formulated in terms of local interactions only, rely on additional transport equations, respectively transported variables, \cite{pope2000turbulent} to capture the Lagrangian nature.
