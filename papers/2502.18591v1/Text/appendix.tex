% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Networks Architectures}\label{sec:nets_architecture}
\subsection{CNNs with Varying Stencil Size}

Figure \ref{fig:stencil_arch} shows a diagram of the series of CNN models used for the study of the effect of the input stencil on the corrector performance in Section \ref{sec:stencil_study}. The only variable parameter between models is $N$, the number of convolution layers with $3\times3$ kernels, going from $N = 6$ for the $13 \times 13$ input stencil to $N = 1$ for the $3 \times 3$ input stencil. The number of trainable parameters for each networks range from $190,146$ to $5,506$.

\begin{figure}[hbt!]
   \centering
   \includegraphics[width=0.40\columnwidth,angle=90]{Figures/drawio_architecture_CNN.pdf} %48,6 x 84,57 mm
   \caption{Architectures for the stencil size study}
   \label{fig:stencil_arch}
\end{figure}

\subsection{Transported Memory Network}
The TMN model is comprised of three different learnable components that work on top of a base solver (see Algorithm \ref{alg:LC_hidden states}). The hidden state encoder generates the initial condition for the hidden state vector based on the initial velocity field. The velocity corrector corrects the velocity based on its current value and the hidden state vector, and finally the hidden state updater updates the hidden state vector to the next time step based on its current value and the corrected velocity.

The architecture of the three components are depicted in Figure \ref{fig:nets_architecture}. Note that for both the velocity corrector and the hidden state updater, the first convolution layer employs a $3\times3$ kernel while all subsequent ones use $1\times1$ kernels. Even though those networks are implemented using CNNs, they are equivalent to a single MLP sliding over the grid with an input stencil of $3\times3$ (i.e., only using direct neighbors information as input). 
The sigmoid used as final output function for both the encoder and the hidden state updater bounds the hidden state vector components within $[-1,1]$.

Note that for the hidden state updater the velocity and hidden state vector field are concatenated to the intermediate output before the final layer rather than added after the final layer. This ensures that the values for the hidden state vector always remains within $[-1,1]$. We found that the alternative additive updater reduces the numerical stability, especially over long roll-outs.

Depending on the size of the hidden state vector, the total number of parameters for the 3 trainable networks range between $56,210$ (12 hidden states) to $42,430$ (2 hidden states).

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.99\columnwidth]{Figures/drawio_architecture.pdf} %164,11 x 132,5 mm
    \caption{Local Networks architectures, size of the velocity (2) and hidden state vector (M) are indicated in brackets.}
    \label{fig:nets_architecture}
\end{figure}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Further Experiments}
\label{sec:stuff_tried}

While the overall structure of the learned model with hidden states remained the same throughout our study  (i.e., with 3 separate components: hidden state encoder, velocity corrector, and hidden state updater) several variations of the individual components were explored. We detail here some of those variations that were however not retained for the final study due to inferior performance.

\paragraph{Explicit Transport of the Hidden State:}
As mentioned in Sections \ref{sec:TMN_arch} and \ref{sec:latent_discussion}, we are using the fully learnable update rule of Equation (\ref{eq:latent_update}). Additionally, we also explored alternatives with more inductive bias explicitly transporting the hidden states with the velocity as in Equation (\ref{eq:latent_transport}). Specifically we tried (with $H^i$ the i-th component of $\Vec{H}$):
{\footnotesize
\begin{align*}
    \textbf{trsprt}(l^i) = - \nabla \cdot (H^i \Vec{U}) +  \nabla \cdot ( \xi (\Vec{U}, \Vec{H}) \nabla H^i)
\end{align*}}
with 
\begin{itemize}
    \item advection only, i.e. $\xi \equiv 0$,
    \item advection-diffusion with learnable constant viscosity $\xi$,
    \item advection-diffusion with learnable non constant viscosity  with $\xi (\Vec{U}, \Vec{H}) $ parametrized by a simple neural network.
\end{itemize}
However, we did not observe a performance improvement adding a physics prior.

\paragraph{Recurrent Architectures:} The transported memory network can be viewed as a type of recurrent architecture with the hidden state vector encoding history information from the previous state in the sequence (the observed sequence here being the velocities components on a given cell at each time  step). We therefore explored an update mechanism based on the principles of the Gated Recurrent Unit (GRU) architectures \cite{cho2014learning} i.e. by updating the hidden state vector / hidden state through a combination of an update gate and a forget gate. We also tried the principles behind the Long Short Term Memory (LSTM) networks \cite{hochreiter1997long}, splitting the hidden state vector into an internal state designed to carry long term history and an hidden state for short term memory, updated through specific output gates, forget gates and input gates. Introducing corresponding slightly more complex architectures, we could not observe a performance improvement.

