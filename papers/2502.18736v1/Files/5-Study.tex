\section{Study}

We conducted a qualitative user study with 12 participants to gather \rev{their insights on AI-instruments compared to traditional prompting}. Participants completed image generation and editing tasks with our four technology probes as well as an initial chat-based prompting probe, to help them tease out pros and cons of these two different interaction models. We analyzed their comments to understand the perception of the principles of reification, reflection and grounding, as well as capture insights on the Human-AI interaction challenges (listed in Section ~\ref{sec:challenges}) addressed by different instruments.

\subsection{Procedure}
Participants completed a 60-minute study in a quiet room on a computer running our technological probes and a study form. After obtaining informed consent, we collected basic demographic information, then requested participants to complete a set of tasks with our technological probes. All participants first completed tasks with a chat-based prompting probe using the same image generation model as the instruments in order for us to confirm their familiarity with prompting and to also provide them with a baseline for the image generation model with use. Before each instrument, participants watched a video demonstration explaining functionalities and modalities of interaction. After this video, participants used the technological probes to complete 2 to 3 tasks such as generating an image and changing its style. We provided example content for each task, but encouraged participants to generate their own content and try different ideas. The experimenter only interacted with participants during this phase of the study to clarify functionalities and interaction if needed. After each set of tasks, participants reflected on one key advantage and on key inconvenient of this specific instrument compared with the chat-based prompting interfaces. Since we aimed at gathering qualitative insights on the overall interaction model behind instruments rather than compare instruments against each other, all participants completed the tasks in the same order. After tasks completion, we described five types of generic tasks, asking for each to select the best interaction technique. Participants also entered the rationale for their choice. At the end of the study, participants received a \$50 gratuity for their time. The study protocol was reviewed and approved by the Microsoft Research ethics review board.

\subsection{Participants}
We recruited 12 participants (8 men, 3 women, 1 non-binary) via mailing lists in a large organization. We \rev{selected participants with weekly interaction with} generative AI systems (ChatGPT, stable diffusion, etc) for creating content. \rev{As we aimed at gathering insights on overarching interaction principles for AI-instruments (across many domains), we opted for selecting participants with interesting in different types of content generation. Our participant pool included users interested in authoring short text snippets such as emails, long structured documents such as reports, structured text such as tables, programming code and web-pages, visual artifacts such as images, and multimodal artifacts with text image and charts such as presentations. Note that none of our participants generated audio or video.} 

\subsection{Material and Analysis}

We collected the salient advantage and salient weakness for each instrument compared to prompting. Participants experienced the following probes: 1) chat-based prompting, 2) fragments, 3) containers, 4) lenses, and 5) brushes. To encourage participants to think of different aspects of content generation, we asked them their preferred interaction technique (along with their rationale) for five different tasks. 

\begin{enumerate}[leftmargin=*]
    \item [\textbf{T1}] \textbf{Combining content:} merging pieces of content together
    \item [\textbf{T2}] \textbf{Splitting content:} extracting a piece of content
    \item [\textbf{T3}] \textbf{Iterating on content:} editing an aspect of content  
    \item [\textbf{T4}] \textbf{Editing by example:} transferring content or style
    \item [\textbf{T5}] \textbf{Expanding content:} adding new material to existing content
\end{enumerate}

We coded a total of 156 statements from our participants to gain insights on their perception of our model's principles and to assess how AI-instruments (un)successfully addressed the five challenges \rev{described in section~\ref{sec:challenges}}. A portion of these comments (28/156) also revealed limitations of our technical probes (the codebook is available at \url{https://hugoromat.github.io/ai_instruments/}).

\subsection{Insights on Model Principles}

\paragraph{\textbf{Reification of intent}} All 12 participants reacted positively to the principle of reifying intent into AI-instruments. Participants valued that AI-instruments enabled them to shift the focus from the prompt to the outcome. P6 commented that \textit{"I can just click on the fragments instead of typing it out and focus on the final output instead."}. P10 noted it was helping them with the iterative process: \textit{"with prompting it makes me think of the prompt, but having [fragments] already in front of me can make it easier for me to make a decision of what i want."}. They also valued the \textbf{direct interaction} afforded by AI-instruments: \textit{"[with fillable brushes] you can interact with the images that are generated directly, rather than [modifying] the image only from prompting."}

A few participants also outlined the value of reification for storing and reusing prompts. P9 commented on Fillable Brushes \textit{"[...] I would be able to create a [brush] with the thing that I wanted to pull out and then apply/store it however I wanted."}, and P11 on Transformative Lenses \textit{"I like the idea of creating and saving a lens and applying it consistently to different images for future uses"}. 

All 12 participants also commented on \textbf{scope of selection} as a key advantage of AI-instruments over prompting (38 comments). Participants identified Fillable Brushes as enabling them to specify portion of an image while Transformative Lenses enabled them to combine multiple images together.  With Brushes, participants emphasize the granularity of the selection. For example P1 noted \textit{"I can highlight the part of the image that requires changing only, and it seems I can highlight at a very high granular level, such as a face of a dog."} P7 referred to this capacity for steering image generation as one can use masks in graphics editors \textit{"I can control a more fine grained area/mask that I want to edit. It's so cool! "}  P4 noted Lenses were particularly useful for adding elements iteratively: \textit{"about how to incrementally add new items from an initial picture, the others [AI-instruments] are more for customize different picture styles"}. In addition, participants appreciated controlling image composition with Lenses, as P2 explained: \textit{"Being able to specify the location of component objects is really helpful"}. 




 

\paragraph{\textbf{Reflection}}

All 12 participants pointed to \textbf{reflection-in-intent} as an advantage of AI-instruments in contrast to prompting (31 comments). This principle was particularly highlighted as a strength of Fragments (24/31 comments), as P5 explained \textit{"I could tell what the different aspects of the prompts were being split [...] and guess what the AI interpreted as something other than what I had in mind."} Participants also praised the benefit of generating variations for each fragment such as P11: \textit{"the system generates ideas for you which you can implement, allowing you to add variables which you might not have originally thought of."} 


All 12 participants also outlined \textbf{reflection-in-response} as an advantage of AI-instruments in contrast to prompting (31 comments). Generative Containers were mostly (26/31) cited for this ability. P5 explained that \textit{"Usually I ask AI to give me a different version/example [of text], but this would allow you to choose the one you like without needing to prompt it again."} P2 valued this ability for iterating: \textit{"[generative containers are a] great abstraction for deciding what to iterate on given multiple possibilities. Makes it easier to visualize or use results from previous steps"}.















\paragraph{\textbf{Grounding}}

All 12 participants identified grounding as an advantage of AI-instruments over prompting (45 comments). It was especially noted valuable for images, as P4 explains \textit{"apply styles of different pictures into other ones, sometimes the styles are hard to illustrate in prompting, since they are more abstract"}.

A majority of participants referred to grounding as a key advantage of Fillable Brushes. P8 referred to grounding for dealing with multiple items: \textit{"[...] having the flexibility to copy any kind of prompt on the brush is good if I have similar kind of images to replicate."} P9 referred to grounding for iterating on a single item: \textit{"[brushes] can give us a style for A (which we can store and ensure that it gets applied to all our later additions.)"}. 



\paragraph{\textbf{Model limitations}} 

We gathered 20/156 comments pertaining to the model limitations.

Four participants described \textbf{limitations of GUIs} \rev{compared to} chat-based conversational interactions with AI. For example, P11 described accessibility issues of relying on 2D interactions as opposed to the ability to rely solely on speech as is easily feasible with chat-based prompting interaction. P2 mentioned AI-Instruments would suffer from the same issues they encountered with GUIs: ~\textit{"GUIs in general are more prone to bugs or unexpected behaviors than text interactions, which could lead to increased computation that the user doesn't actually want"}. And P10 noted that they felt they needed to perform many interactions ~\textit{"compared to prompting, where I can just type something"}, P12 concluding that \textit{"It's faster to get exactly what I want with prompting"}. These comments do not address fundamental limitations of the instrumental model per say but rather highlight that users may sometimes prefer a single albeit limited modality of interaction. These insights hints at the need to integrate chat-based prompting interaction more tightly with instruments. \rev{A straightforward avenue for this, is to provide on-demand access to underlying textual prompts generated by instruments}.

P6 noted that \textit{"It might be better to write a new prompt when I need to make major modifications to the output"} as a drawback of Lenses. This echoes the sentiment of three other participants in that the grounding capabilities of AI-instruments such as Lenses and Brushes enable effective content generation steering but may hinder divergent content generation. However, this is also balanced by the strengths of other AI-instruments such as Generative Containers that many participants praised for \textit{"creative and exploratory settings."} (P12). These insights hints at the need to \textbf{provide multiple instruments} to users in content generation tools. 

We devised our four AI-instruments to cover different facets and tasks involved in  content creation. For example, Containers supports iterative exploration by reusing pieces of content in other Containers, while Fragments enables it by selecting different aspects to vary. The different design decisions tied to the affordances of each instrument led to different task support, especially with regard to navigating creation history.  This caused occasional frustration for Fragments or Lenses \textit{"Old edits get lost when new edited are prompted"} (P7). Two participants reflected on this strength of chat-based prompting interfaces to inherently provide a trace of all the prompts and results made in a temporal manner. Especially in the context of non-deterministic outputs, where the next piece of content may be less satisfactory than the prior one, these insights suggest that more thoughts need to be devoted to \textbf{systematically surface history} within each instrument. 



Note that a majority of aspects participants did not value for AI-instruments (28/48) pertained to the limitations of our technology probes rather than limitations of the model. Many of these comments referred to usability issues such as the fact that Lenses regenerated too early (or too late) or exclusively had a square aspect ratio, as well as visual look and feel of the probes \textit{"color the pens maybe? easier to organize and distinguish them"}(P7).




\subsection{Challenges Addressed by AI-instruments}


\paragraph{\textbf{C1 Intent formulation}}

Participants highlighted \textbf{grounding} to address intent formulation on images, especially as instantiated in Fillable Brushes for extracting and transferring styles.  P7 summarized how Brushes help formulate intent with both scope of selection and direct manipulation: \textit{"I can control a more fine grand area/mask that I want to edit. It's so cool! I can also copy the style/content from a different image and directly apply it to a different image without having to find the accurate words to describe them."}



\paragraph{\textbf{C2 Intent disambiguation}}

Participants identified \textbf{grounding and reflection} as core principles helping them disambiguate their intent.  They explained that the reflection-in-intent surfaced in Fragments was helping them identify context and details to refine their intent. P5 also noted that Fragments enabled to experiment and \rev{gain an understanding} of how the model worked \textit{"allow[ing] me to see how the prompts were being isolated and used"}. A few participants also explained that Brushes helped with intent disambiguation by capturing one by example and expressing it words. P1 summarized: \textit{"one advantage [of brushes] is that it can identify a style, even though I cannot articulate the style well, this is especially helpful to circumvent prompt engineering."} 



\paragraph{\textbf{C3 Intent resolution}}

Participants outlined the principles of \textbf{reification and reflection} as most useful for resolving intent. Participants explained that reification enabled them to explore different paths by iterating on different images: \textit{"this lets you build off of previous iterations and you can create different styles for the same image until you are happy with one"}. They highlighted the benefit of reflection-in-response of Generative Containers to help them explore possibilities:\textit{"I don't have to think too much about what I want, which is helpful"} (P10), \textit{"Very easy to explore creative options, it helps to get a better idea of what you like"} (P12). P7 valued the ability to start from high-level prompts and follow up by making a selection~\textit{"It it easy to generate images with a vague description, and offer options [to explore]"}. A few participants also mentioned the benefit of reflection-in-intent of Fragments to experiment with options: \textit{"[Fragment] also suggests some dimensions to change the picture which I might have not thought about. Like the elephant in this case."} (P9). 

\paragraph{\textbf{C4 Steering}}

All participants mentioned the benefit of instruments over chat-based prompting for steering content. Participants noted that direct manipulation and scope of selection afforded by \textbf{reification} were critical in editing portions of content, in conjunction with \textbf{grounding} to capture and transfer aspects of one content to another. Many participants outlined the value of Brushes and Lenses to generate masks for steering content generation \textit{"masking [with lenses] allows me to personalize smaller parts of the image compared to generating a completely new one"} (P10), \textit{"this [brush] is an advanced way to mask out single things within an image to regenerate"} (P3).  P6 summarized the benefits of these instruments compare to chat-based prompting: \textit{"[with brushes] I can quickly make modifications to the image instead of writing a prompt from scratch for every modification. I can focus on the subject I'm interested in."}








\paragraph{\textbf{C5 Workflows}}

Participants perceived that AI-instruments supported two workflows that were currently hard to achieve with chat-based prompting interaction: \textbf{non-linear exploration} and \textbf{iterative content generation} by chaining prompts together (e.g. steering). For exploration, participants each favored different instruments. P6 favored Fragments \textit{"I feel this [fragments] makes it easy to try out different examples that I might be interested in. I can just click on the fragments instead of typing it out and focus on the final output instead."}. P3 described Containers allowing \textit{"more freedom to explore more options. Downside to prompting is that you need to know what you want."} P8 valued \textit{"trying different lenses on the same component creating a scene is easy way to experiment and merge different style in one"}. P8 also referred to the grounding capabilities of Brushes as useful to experiment with the collection of examples offered \textit{"different kinds of image styles to choose from for copying styles or format"}. For iterative content generation, participants refer to the same advantages AI-instruments offer than for steering.



























