\section{Introduction}



Despite the immense promise of generative AI, it remains challenging for people to express and refine their true intents via multiple rounds of textual chat-prompts~\cite{mahdavi_goloujeh_is_2024, zamfirescu-pereira_why_2023}, as well as to pursue multiple-alternative paths forward within a linear conversational metaphor. 
Users face numerous difficulties (e.g.,~\cite{subramonyam_bridging_2024}): articulating their intent in a few words of written text (intent formulation); correctly expressing sufficient detail to express, refine, and re-formulate their true intent (intent disambiguation); iterating over the model's response to approach a  desired outcome (steering); and navigating higher-order challenges of interaction with AI, such as discovering what one can do with AI---or even what one "actually" wants to achieve (intent resolution)---within the linear sequential limitations of chat-based exchanges (interaction workflow). 

Although existing work in human-computer interaction and artificial intelligence (HCI+AI) addresses some aspects of these challenges in piecemeal fashion through novel interaction techniques with generative AI (e.g.~\cite{chung_promptpaint_2023, masson_directgpt_2024}), we argue here that ~\textit{AI-Instruments} offer a novel approach to gain traction on many aspects of these challenges by appropriating and re-casting the principles of ~\textit{instrumental interaction} ~\cite{beaudouin2000instrumental, beaudouin2000reification} to the modern context of generative HCI+AI user experiences. \rev{Quoting Beaudoin-Lafon et al.~\cite{beaudouin2021generative}, the value of proposing such  interaction model is to \textit{"change-oriented perspective by providing HCI researchers with conceptual tools for analyzing technologies in use or exploring novel future solutions"}. Triangulating theory, artifact, and empirical evaluation has strong benefits for advancing HCI research~\cite{mackay1997hci}.}



Instrumental interaction offers a particularly compelling concept from the HCI literature to revisit in the context of generative AI because it offers principled interaction dynamics about how software functionalities (\textit{"commands"}) combine with content (the \textit{"objects"} those commands act upon). While in the past these dynamics had to be hand-designed and hand-coded for specific object types and application settings, the advent of generative AI makes it plausible that the polymorphic nature of high-level commands and flexible content representations will unleash exciting new possibilities for HCI+AI graphical user interfaces. 

In particular, our approach \textit{embodies AI prompts as graphical interface objects} and adapts the instrumental interaction model for Generative AI by considering the following three principles: 

\begin{enumerate}[label={(\arabic*)}]
    \item [(1)] \textit{\textbf{Reification of user intent}} into instruments: turning user-intent from varied abstractions and granularity levels into one or more reusable graphical interface object(s);
    \item  [(2)] \textit{\textbf{Reflection}}: the consideration of multiple alternatives that reflect ~\cite{DesignReflectiveConversation1992} both ambiguous intents as expressed by the user (\textit{reflection-in-intent}), and ambiguous interpretation of AI responses (\textit{reflection-in-response}), to steer content generation towards a satisfactory result; and finally
    \item [(3)] \textit{\textbf{Grounding}}: instantiating an instrument from a specific scope of selected content, from an example result, or even from another instrument.
\end{enumerate}

Via a technology probe~\cite{TechnologyProbesCHI2003} that implements four complementary examples of AI-instruments, we illustrate how they can ameliorate many design challenges plaguing todayâ€™s linear-chat-based AI interfaces: intent formulation, prompt engineering, direct manipulation and steering, non-linear iterative workflows, and intent resolution. We also present initial reactions of 12 participants who tried our AI-instruments, yielding qualitative insights on the value and limitations of our AI-instruments interaction model, as compared to conversational prompting. 



Designed through the lens of the three principles, \rev{we built a set of technology probes focused on image generation. The goal of these four exemplar AI-Instruments is to demonstrate the new interaction capabilities and affordances of our model:} (1) \textit{Fragments} decompose gen-AI prompts into reified reconfigurable objects, affording reflection-on-intent on the latent prompt structure, and grounding generation by dragging fragments from one object to another. (2) \textit{Transformative Lenses} generate new content grounded in one or more content elements, which allows flexible recomposition of scenes and (if desired) continuous updates of the result. (3) \textit{Generative Containers} create multiple alternatives of images, text, and even instruments or fragments. 
(4) \textit{Fillable Brushes} encapsulate a prompt, filled by selecting example content with the brush (or by directly typing the prompt for a new action). Using the instruments in synergy---where outputs from one instrument form input for the next, or even using instruments to create new meta-instruments---affords expressive degrees-of-freedom for fine-grained steering of generative AI. 


In summary, our high-level contributions include the following:
\begin{itemize}
    \item Extend the classic instrumental interaction model~\cite{beaudouin2000instrumental} to generative AI, emphasizing three driving principles: reification of user intent, reflection, and grounding;
    \item Demonstrate four AI-instruments via technology probes, showing how these driving principles manifest in their design and implementation;
    \item Provide initial reactions from 12 users when shifting from a linear-chat interaction paradigm to direct manipulation through AI-instruments, showing that it can address a number of human-AI interaction challenges.
\end{itemize}

In the following sections we discuss related techniques across the HCI, Human-AI interaction, and design literature. This is followed by an Example Walkthrough of our AI-instruments, a wider discussion of Instrumental Interaction with AI, and further details of our Four Exemplar AI-Instruments: Fragments, Transformative Lenses, Generative Containers, and Fillable Brushes. We then present a qualitative Study of these AI-Instruments in comparison with textual prompting, and finally close with a Discussion and Future Work.




