@article{Baek2024ResearchAgentIR,
  title={ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models},
  author={Jinheon Baek and Sujay Kumar Jauhar and Silviu Cucerzan and Sung Ju Hwang},
  journal={ArXiv},
  year={2024},
  volume={abs/2404.07738},
  url={https://api.semanticscholar.org/CorpusID:269042844}
}

@article{KABENAMUALU2023ORKGLeaderboardsAS,
  title={ORKG-Leaderboards: a systematic workflow for mining leaderboards as a knowledge graph},
  author={Salomon Kabongo KABENAMUALU and Jennifer Dâ€™Souza and S. Auer},
  journal={International Journal on Digital Libraries},
  year={2023},
  pages={1-14},
  url={https://api.semanticscholar.org/CorpusID:258762176}
}

@article{Lu2024TheAS,
  title={The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery},
  author={Chris Lu and Cong Lu and Robert Tjarko Lange and Jakob N. Foerster and Jeff Clune and David Ha},
  journal={ArXiv},
  year={2024},
  volume={abs/2408.06292},
  url={https://api.semanticscholar.org/CorpusID:271854887}
}

@article{Si2024CanLG,
  title={Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers},
  author={Chenglei Si and Diyi Yang and Tatsunori Hashimoto},
  journal={ArXiv},
  year={2024},
  volume={abs/2409.04109},
  url={https://api.semanticscholar.org/CorpusID:272463952}
}

@inproceedings{Singh2024LEGOBenchSL,
  title={LEGOBench: Scientific Leaderboard Generation Benchmark},
  author={Shruti Singh and Shoaib Alam and Husain Malwat and Mayank Singh},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:267770699}
}

@inproceedings{Wang2023SciMONSI,
  title={SciMON: Scientific Inspiration Machines Optimized for Novelty},
  author={Qingyun Wang and Doug Downey and Heng Ji and Tom Hope},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:258841365}
}

@article{Wang2024AutoSurveyLL,
  title={AutoSurvey: Large Language Models Can Automatically Write Surveys},
  author={Yidong Wang and Qi Guo and Wenjin Yao and Hongbo Zhang and Xin Zhang and Zhen Wu and Meishan Zhang and Xinyu Dai and Min Zhang and Qingsong Wen and Wei Ye and Shikun Zhang and Yue Zhang},
  journal={ArXiv},
  year={2024},
  volume={abs/2406.10252},
  url={https://api.semanticscholar.org/CorpusID:270560509}
}

@article{Weng2024CycleResearcherIA,
  title={CycleResearcher: Improving Automated Research via Automated Review},
  author={Yixuan Weng and Minjun Zhu and Guangsheng Bao and Hongbo Zhang and Jindong Wang and Yue Zhang and Linyi Yang},
  journal={ArXiv},
  year={2024},
  volume={abs/2411.00816},
  url={https://api.semanticscholar.org/CorpusID:273811997}
}

@inproceedings{Yang2023LargeLM,
  title={Large Language Models for Automated Open-domain Scientific Hypotheses Discovery},
  author={Zonglin Yang and Xinya Du and Junxian Li and Jie Zheng and Soujanya Poria and E. Cambria},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:261557055}
}

@inproceedings{hou-etal-2019-identification,
    title = "Identification of Tasks, Datasets, Evaluation Metrics, and Numeric Scores for Scientific Leaderboards Construction",
    author = "Hou, Yufang  and
      Jochim, Charles  and
      Gleize, Martin  and
      Bonin, Francesca  and
      Ganguly, Debasis",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1513/",
    doi = "10.18653/v1/P19-1513",
    pages = "5203--5213",
    abstract = "While the fast-paced inception of novel tasks and new datasets helps foster active research in a community towards interesting directions, keeping track of the abundance of research activity in different areas on different datasets is likely to become increasingly difficult. The community could greatly benefit from an automatic system able to summarize scientific results, e.g., in the form of a leaderboard. In this paper we build two datasets and develop a framework (TDMS-IE) aimed at automatically extracting task, dataset, metric and score from NLP papers, towards the automatic construction of leaderboards. Experiments show that our model outperforms several baselines by a large margin. Our model is a first step towards automatic leaderboard construction, e.g., in the NLP domain."
}

@inproceedings{kardas-etal-2020-axcell,
    title = "{AxCell}: Automatic Extraction of Results from Machine Learning Papers",
    author = "Kardas, Marcin  and
      Czapla, Piotr  and
      Stenetorp, Pontus  and
      Ruder, Sebastian  and
      Riedel, Sebastian  and
      Taylor, Ross  and
      Stojnic, Robert",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.692/",
    doi = "10.18653/v1/2020.emnlp-main.692",
    pages = "8580--8594",
    abstract = "Tracking progress in machine learning has become increasingly difficult with the recent explosion in the number of papers. In this paper, we present AxCell, an automatic machine learning pipeline for extracting results from papers. AxCell uses several novel components, including a table segmentation subtask, to learn relevant structural knowledge that aids extraction. When compared with existing methods, our approach significantly improves the state of the art for results extraction. We also release a structured, annotated dataset for training models for results extraction, and a dataset for evaluating the performance of models on this task. Lastly, we show the viability of our approach enables it to be used for semi-automated results extraction in production, suggesting our improvements make this task practically viable for the first time. Code is available on GitHub."
}

@inproceedings{yang-etal-2022-telin,
    title = "{TELIN}: Table Entity {LIN}ker for Extracting Leaderboards from Machine Learning Publications",
    author = "Yang, Sean  and
      Tensmeyer, Chris  and
      Wigington, Curtis",
    editor = "Ghosal, Tirthankar  and
      Blanco-Cuaresma, Sergi  and
      Accomazzi, Alberto  and
      Patton, Robert M.  and
      Grezes, Felix  and
      Allen, Thomas",
    booktitle = "Proceedings of the first Workshop on Information Extraction from Scientific Publications",
    month = nov,
    year = "2022",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.wiesp-1.3/",
    doi = "10.18653/v1/2022.wiesp-1.3",
    pages = "20--25",
    abstract = "Tracking state-of-the-art (SOTA) results in machine learning studies is challenging due to high publication volume. Existing methods for creating leaderboards in scientific documents require significant human supervision or rely on scarcely available LaTeX source files. We propose Table Entity LINker (TELIN), a framework which extracts (task, model, dataset, metric) quadruples from collections of scientific publications in PDF format. TELIN identifies scientific named entities, constructs a knowledge base, and leverages human feedback to iteratively refine automatic extractions. TELIN identifies and prioritizes uncertain and impactful entities for human review to create a cascade effect for leaderboard completion. We show that TELIN is competitive with the SOTA but requires much less human annotation."
}

