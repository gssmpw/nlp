
\section{Background}
\label{sec:background}
%\vspace{-0.1cm}
\subsection{GFlowNets}
\label{sec:background_gflow}
%\vspace{-0.1cm}


This section presents necessary notations and theoretical background on GFlowNets. GFlowNets treat the problem of sampling from a probability distribution over discrete space $\cX$ as a sequential decision-making process in a directed acyclic graph (DAG) \(\cG = (\mathcal{S}, \mathcal{E})\), where \(\mathcal{S}\) is a state space and \(\mathcal{E} \subseteq \mathcal{S} \times \mathcal{S}\) is a set of edges (or transitions). There is a special \textit{initial state} $s_0$ with no incoming edges and a special \textit{sink state} $s_f$ with no outgoing edges. The commonly used variant of notation does not include a sink state $s_f$, yet we prefer to use a variant with $s_f$, since it was also used in the previous work on non-acyclic GFlowNets~\cite{brunswic2024theory} and leads to a more intuitive construction. Let $\cT$ be a set of all trajectories $\tau = \left(s_0 \to s_1 \to \ldots \to s_{n_{\tau}} \to s_f\right)$ from $s_0$ to $s_f$, where we use $n_{\tau}$ to denote the length of the trajectory $\tau$. We use a convention $s_{n_{\tau} + 1} = s_f$. We say that $\tau$ \textit{terminates} in $s$ if its last transition is $s \to s_f$. Such transitions are called \textit{terminating}, and the states that have an outgoing edge into $s_f$ are called \textit{terminal} states. The set of terminal states coincides with $\cX$, and the probability distribution of interest $\cR(x) / \cZ$ is defined on it, where $\cR(x)$ is called \textit{GFlowNet reward} and $\cZ = \sum_{x \in \cX} \cR(x)$ is an unknown normalizing constant. In addition, for any state $s$, we denote $\vin(s)$ to be the set of states $s'$ such that there is an edge $s' \to s \in \cE$ (parents), and $\vout(s)$ to be the set of states $s'$ such that there is an edge $s \to s' \in \cE$ (children).

%$\cP(\{\tau \in \cT \mid x \in \tau \}) = \cR(x) / \cZ$
The main goal of GFlowNets is to find a distribution $\cP$ over $\cT$ such that for any $x \in \cX$, probability that $\tau \sim \cP$ terminates in $x$ coincides with $\cR(x) / \cZ$. This property is called the \textit{reward matching condition}. GFlowNets operate with Markovian distributions over trajectories (see \cite{bengio2023gflownet} for a definition and discussion) using the following key components: 
\begin{enumerate}%[noitemsep, nolistsep]
\item a \textit{forward policy} $\PF(s' \mid s)$, which is a distribution over children of each state;
\item a \textit{backward policy} $\PB(s \mid s')$, which is a distribution over parents of each state;
\item \textit{state/edge flows} $\cF(s)$, $\cF(s \to s')$, which coincide with an unnormalized probability that a trajectory $\tau$ passes through state/edge.
\end{enumerate}
$\PF$, $\PB$, and $\cF$ are connected through the \textit{trajectory balance conditions:}
%\vspace{-0.2cm}
\begin{equation}
\label{eq:tb}
%\textstyle 
     \cP(\tau) = \prod_{t=0}^{n_\tau} \PF \left(s_{t+1} \mid s_{t}\right) = \prod_{t=0}^{n_\tau} \PB \left(s_{t} \mid s_{t+1}\right)\,,%\,, \quad \forall \tau \in \cT\,.
\end{equation}%\vspace{-0.2cm}
\textit{detailed balance conditions:}
%\vspace{-0.2cm}
\begin{equation}
\label{eq:db}
     \cF(s \to s') = \cF(s)\PF(s' \mid s) = \cF(s')\PB(s \mid s')\,,%\,, \quad \forall \tau \in \cT\,.
\end{equation}%\vspace{-0.2cm}
and \textit{flow matching conditions:}
%\vspace{-0.2cm}
\begin{equation}
\label{eq:fm}
     \cF(s) = \sum_{s' \in \vout(s)} \cF(s \to s') = \sum_{s'' \in \vin(s)} \cF(s'' \to s)\,.%\,, \quad \forall \tau \in \cT\,.
\end{equation}%\vspace{-0.2cm}

%\vspace{-0.4cm}
All of these objects are completely and uniquely specified if one fixes either 1) edge flow $\cF(s \to s')$, 2) initial flow $\cF(s_0)$ and $\PF$, 3) initial flow $\cF(s_0)$ and $\PB$.
If flows satisfy $\cF(s \to s_f) = \cR(s)$, trajectory distribution defined by the corresponding forward policy will satisfy reward matching condition~\cite{bengio2023gflownet}. In practice, a neural network is used to parameterize the forward policy (and, optionally, the backward policy and the flows). Then, it is trained to minimize some loss function that would enforce the reward matching condition. For example, \textit{Detailed Balance} loss~\cite{bengio2023gflownet} is defined on all transitions $s \to s^{\prime} \in \cE$ as:
%\vspace{-0.3cm}
\begin{equation}
\label{eq:DB_loss}
%\textstyle 
\mathcal{L}_{\DB}(s \to s^{\prime}) \triangleq \left(\log \frac{\cF_{\theta}(s) \PF(s' \mid s, \theta)}{\cF_{\theta}(s')\PB(s \mid s', \theta)} \right)^2\eqsp.
\end{equation}
%\vspace{-0.2cm}
Reward matching is enforced by substituting $\cF(x \to s_f) = \cF_{\theta}(s_f)\PB(x \mid s_f, \theta) = \cR(x)$ in the loss. 
Although the optimization task typically admits multiple solutions, fixing the backward policy results in a unique solution in terms of  $\cF$ and $\PF$~\cite{bengio2023gflownet}.




%\vspace{-0.15cm}
\subsection{GFlowNets in Non-Acyclic Environments}

\citet{brunswic2024theory} state that fundamental results of GFlowNet theory also apply in the case when the environment graph $\cG$ may contain cycles, and
all definitions from the acyclic case remain valid and extend to the non-acyclic case.
%all definitions can be carried over from a non-acyclic case. 
However, we will further show that this is not exactly true, e.g., \textit{flows cannot be consistently defined as unnormalized visitation probabilities}. 

More specifically, \citet{brunswic2024theory} argue that if \eqref{eq:fm} holds for an edge flow, as well as $\cF(s \to s_f) = \cR(s)$ for terminating transitions, the forward policy induced by the flow $\PF(s' \mid s) = \frac{\cF(s \to s')}{\cF(s)}$ satisfies reward matching condition. Thus, standard GFlowNet losses, such as Flow Matching ($\FM$, \citealp{bengio2021flow}), Detailed Balance ($\DB$, \citealp{bengio2023gflownet}), and Trajectory Balance ($\TB$, \citealp{malkin2022trajectory}) can be applied in non-acyclic environments.

However, \citet{brunswic2024theory} point out that the main distinction between non-acyclic and acyclic GFlowNets is that in the non-acyclic setting, expected trajectory length $\E[n_{\tau}]$ (denoted as a sampling time in \cite{brunswic2024theory}) can be arbitrary large because of the cycles, while in the acyclic setting it is always bounded. To tackle this issue, a concept of \textit{loss stability} is introduced. A loss is called \textit{stable} if adding a constant to the flow along a cycle can never decrease the loss, and otherwise, it is called \textit{unstable} (Definition 3). It is shown that $\FM$, $\DB$, and $\TB$ are unstable (Theorem 3), which can lead to arbitrarily large sampling time when utilized for training. In contrast, a family of losses that are provably stable is presented (Theorem 4). Moreover, the authors show that there are stable variants of $\FM$ and $\DB$ losses, such as stable $\DB$ loss, which we denote as $\SDB$
\begin{equation} \label{eq:StableDB_loss}
\begin{split}
\mathcal{L}_{\SDB}(s \to s^{\prime})  
 & \triangleq \log(1 + \varepsilon \Delta^2(s,s',\theta))  (1 + \eta \cF_{\theta}(s))\,, \\\
 \Delta(s,s', \theta) &\triangleq \cF_{\theta}(s) \PF(s' | s, \theta) 
 - \cF_{\theta}(s')\PB(s | s', \theta)\eqsp,
\end{split}
\end{equation}
\vspace{-0.6cm}

where $\varepsilon$ and $\eta$ are hyperparameters. In addition, \cite{brunswic2024theory} show that the  expected trajectory length is bounded by the total normalized state flow
\begin{equation}
\label{eq:len_bound}
%\textstyle 
     \E[n_{\tau}] \leq \frac{1}{\cF(s_0)} \sum_{s \in \cS \setminus \{s_0, s_f\}} \cF(s)\,,
\end{equation}
and using a stable loss with a regularizer that controls the total flow, e.g., the norm of the edge flow matrix, can be used to learn an acyclic flow (Theorem 1).



