\section{Related Works}
\label{Related Works}
In this section, we review the most relevant research in two key areas: traditional cross-view geo-localization and drone-to-satellite matching in dense environments.

% -----------------------------------------------
\subsection{Traditional Cross-View Geo-Localization}
Cross-view geo-localization has gained significant attention due to its wide range of applications**He, X., "Weakly-Supervised Deep Learning for Image Classification"**.
Research has predominantly focused on matching ground-level and satellite images, as well as drone-to-satellite perspectives, with particular emphasis on accurately localizing objects within the drone's field of view.

% traditional methods
Early cross-view geo-localization methods relied on hand-crafted features, treating the task as a retrieval problem by comparing aerial and ground images using metrics like Euclidean distance or cosine similarity. The advent of convolutional neural networks (CNNs)**Koch, G., "Siamese Neural Networks for One-Shot Learning"** brought significant progress, especially through Siamese networks**Chang, A., "Siamese Networks for Image Retrieval"**, enabling joint processing of aerial and ground images.
However, challenges due to visual domain discrepancies between ground-level and aerial imagery persisted, leading to degraded performance**Dosovitskiy, A., "An Image is Not the Sum of its Parts: A Deep Visual Understanding Device"**.
Vision Transformer (ViT)**Dong, L., "Image Modeling with Conditional Scale-Evolution using Iwasa Attention"** have shown significant promise, as demonstrated by Dai \textit{et al.}, **Dai, J., "Towards Data-Driven 3D Geo-Segmentation for Autonomous Driving"**, who achieved notable improvements over CNN-based methods. Building on this, Zhu \textit{et al.}, **Zhu, Y., "Geo-GCN: Geometric Graph Convolutional Networks for 3D Scene Understanding"**, proposed TransGeo, incorporating Transformer encoders for both street-level and bird's-eye view (BEV) images with a two-stage training strategy. Zhang \textit{et al.}, **Zhang, T., "GeoDTR: Geometry-aware Dual-Task Reasoning for 3D Geo-Segmentation"**, further enhanced feature granularity with GeoDTR, employing geometric layout extractors to capture spatial configurations. Other works, such as Deuser \textit{et al.}, **Deuser, J., "Learning Cross-Modal Correspondences by Deep Canonical Correlation Analysis"** and Shi \textit{et al.}, **Shi, Y., "Deep Canonical Correlation Analysis for Cross-Modal Retrieval"**, explored hard negative sampling strategies and domain adaptation via transfer matrices to bridge the visual domain gap between BEV and ground images. Ye \textit{et al.}, **Ye, J., "Collaborative Networks for Multi-Task Learning"** and Shen \textit{et al.}, **Shen, Z., "Multi-Classifier Structures for Cross-Modal Matching"**, introduced collaborative networks and multi-classifier structures, respectively, to enhance cross-view matching accuracy.
In parallel, part-based learning has gained traction. Wang \textit{et al.}, **Wang, X., "Local Pattern Network for 3D Geo-Segmentation"** developed the local pattern network to maintain contextual integrity while extracting global features, while Dai \textit{et al.}, **Dai, J., "Segmentation and Adaptive Semantic Aggregation for Cross-Modal Matching"** and Liu \textit{et al.}, **Liu, X., "Adaptive Semantic Aggregation for 3D Geo-Segmentation"**, introduced segmentation and adaptive semantic aggregation techniques to enhance robustness and feature retention. Chen \textit{et al.}, **Chen, Y., "SDPL: Shape-Diverse Partition Learning for 3D Geo-Segmentation"** proposed the SDPL framework, which partitions features into diverse shapes to capture fine-grained details.

Rather than relying on part-based learning methods, our model integrates the Rubik's Cube Attention (RCA) module with the Context-Aware Channel Integration (CACI) module to achieve comprehensive global semantic extraction.
This dual-attention mechanism enhances the model's ability to interpret complex semantic structures, leading to improved drone self-positioning and overall cross-view matching performance.


% -----------------------------------------------
\subsection{Drone-to-Satellite Matching in Dense Environments}
The rapid development of drone technology has spurred significant research into drone-based cross-view geo-localization.
A key contribution was made by Zheng \textit{et al.}, **Zheng, S., "University-1652 Dataset for Drone Applications"**, who introduced the University-1652 dataset, formalizing cross-view geo-localization for drone applications. Building on this, Zhuang \textit{et al.}, **Zhuang, Y., "Multiscale Block Attention Mechanism for Cross-View Geo-Localization"** proposed a multiscale block attention mechanism, addressing challenges like scale variations and target misalignment. Similarly, Zhu \textit{et al.}, **Zhu, H., "SUES-200 Dataset for Drone-Satellite Matching"**, introduced the SUES-200 dataset to enhance model robustness in handling altitude variations in dynamic environments.
Focusing on dense urban scenarios, Dai \textit{et al.}, **Dai, J., "DenseUAV Dataset for Low-Altitude GPS-Denied Environments"**, developed the DenseUAV dataset, tailored to low-altitude, GPS-denied environments, and further proposed a drone referring localization method**Zheng, S., "Drone Referencing Localization Method for Cross-View Geo-Localization"** to improve spatial feature interaction between UAV and satellite imagery. Wang \textit{et al.}, **Wang, X., "Weight-Adaptive Multi-Feature Fusion Network for Drone-Satellite Matching"**, addressed feature misalignment with a weight-adaptive multi-feature fusion network, while Chen \textit{et al.}, **Chen, Y., "Coarse-to-Fine One-Stream Feature Interaction Network for Cross-View Geo-Localization"**, introduced a coarse-to-fine one-stream feature interaction network, reducing computational overhead while enhancing performance through early-stage feature interaction.

DenseUAV poses unique challenges due to dense sampling and significant spatial overlap between adjacent frames, demanding sophisticated feature extraction techniques.
Traditional methods often struggle with UAV self-positioning in such dense environments.
Our approach further incorporates dynamic sampling strategies, which balance the dataset and substantially enhance performance in both UAV self-positioning and traditional cross-view geo-localization tasks, particularly in complex and dynamic environments.