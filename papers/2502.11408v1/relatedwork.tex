\section{Related Works}
\label{Related Works}
In this section, we review the most relevant research in two key areas: traditional cross-view geo-localization and drone-to-satellite matching in dense environments.

% -----------------------------------------------
\subsection{Traditional Cross-View Geo-Localization}
Cross-view geo-localization has gained significant attention due to its wide range of applications~\cite{cheng2023ai, shadiev2023systematic, molina2023review, bakirci2024enhancing}.
Research has predominantly focused on matching ground-level and satellite images, as well as drone-to-satellite perspectives, with particular emphasis on accurately localizing objects within the drone's field of view.

% traditional methods
Early cross-view geo-localization methods relied on hand-crafted features, treating the task as a retrieval problem by comparing aerial and ground images using metrics like Euclidean distance or cosine similarity. The advent of convolutional neural networks (CNNs)~\cite{krizhevsky2012imagenet, lecun1998gradient} brought significant progress, especially through Siamese networks~\cite{bromley1993signature, hadsell2006dimensionality}, enabling joint processing of aerial and ground images.
However, challenges due to visual domain discrepancies between ground-level and aerial imagery persisted, leading to degraded performance~\cite{hu2018cvm}.
Vision Transformer (ViT)~\cite{dosovitskiy2020image} have shown significant promise, as demonstrated by Dai \textit{et al.}~\cite{dai2021transformer}, who achieved notable improvements over CNN-based methods. Building on this, Zhu \textit{et al.}~\cite{zhu2022transgeo} proposed TransGeo, incorporating Transformer encoders for both street-level and bird's-eye view (BEV) images with a two-stage training strategy. Zhang \textit{et al.}~\cite{zhang2023cross} further enhanced feature granularity with GeoDTR, employing geometric layout extractors to capture spatial configurations. Other works, such as Deuser \textit{et al.}~\cite{deuser2023sample4geo} and Shi \textit{et al.}~\cite{shi2022cvlnet}, explored hard negative sampling strategies and domain adaptation via transfer matrices to bridge the visual domain gap between BEV and ground images. Ye \textit{et al.}~\cite{ye2024sg} and Shen \textit{et al.}~~\cite{10185134} introduced collaborative networks and multi-classifier structures, respectively, to enhance cross-view matching accuracy.
In parallel, part-based learning has gained traction. Wang \textit{et al.}~\cite{wang2021each} developed the local pattern network to maintain contextual integrity while extracting global features, while Dai \textit{et al.}~\cite{dai2021transformer} and Liu \textit{et al.}~\cite{liu2024adaptive} introduced segmentation and adaptive semantic aggregation techniques to enhance robustness and feature retention. Chen \textit{et al.}~\cite{chen2024sdpl} proposed the SDPL framework, which partitions features into diverse shapes to capture fine-grained details.

Rather than relying on part-based learning methods, our model integrates the Rubik's Cube Attention (RCA) module with the Context-Aware Channel Integration (CACI) module to achieve comprehensive global semantic extraction.
This dual-attention mechanism enhances the model's ability to interpret complex semantic structures, leading to improved drone self-positioning and overall cross-view matching performance.


% -----------------------------------------------
\subsection{Drone-to-Satellite Matching in Dense Environments}
The rapid development of drone technology has spurred significant research into drone-based cross-view geo-localization.
A key contribution was made by Zheng \textit{et al.}~\cite{zheng2020university}, who introduced the University-1652 dataset, formalizing cross-view geo-localization for drone applications. Building on this, Zhuang \textit{et al.}~\cite{zhuang2021faster} proposed a multiscale block attention mechanism, addressing challenges like scale variations and target misalignment. Similarly, Zhu \textit{et al.}~~\cite{zhu2023sues} introduced the SUES-200 dataset to enhance model robustness in handling altitude variations in dynamic environments.
Focusing on dense urban scenarios, Dai \textit{et al.}~\cite{10376356} developed the DenseUAV dataset, tailored to low-altitude, GPS-denied environments, and further proposed a drone referring localization method~\cite{dai2022finding} to improve spatial feature interaction between UAV and satellite imagery. Wang \textit{et al.}~\cite{wang2023wamf} addressed feature misalignment with a weight-adaptive multi-feature fusion network, while Chen \textit{et al.}~\cite{chen2024fpi} introduced a coarse-to-fine one-stream feature interaction network, reducing computational overhead while enhancing performance through early-stage feature interaction.

DenseUAV poses unique challenges due to dense sampling and significant spatial overlap between adjacent frames, demanding sophisticated feature extraction techniques.
Traditional methods often struggle with UAV self-positioning in such dense environments.
Our approach further incorporates dynamic sampling strategies, which balance the dataset and substantially enhance performance in both UAV self-positioning and traditional cross-view geo-localization tasks, particularly in complex and dynamic environments.


% ============================================================================================== PROPOSED METHOD