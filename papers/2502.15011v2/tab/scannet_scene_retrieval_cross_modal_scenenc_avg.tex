\begin{table*}
  \centering
  \resizebox{\textwidth}{!}{
   \begin{tabular}{l| cccc | ccc| ccc || ccc}
    \toprule
    \textbf{Method} & \multicolumn{4}{c}{\textbf{Scene Matching Recall}  $\uparrow$} & \multicolumn{3}{c}{\textbf{Scene Category Recall} $\uparrow$} & \multicolumn{3}{c}{\textbf{Temporal Recall} $\uparrow$} & \multicolumn{3}{c}{\textbf{Intra-Category Recall} $\uparrow$} \\
    \midrule\arrayrulecolor{black} 
    & \textbf{top-1} & \textbf{top-5} & \textbf{top-10} & \textbf{top-20} & \textbf{top-1} & \textbf{top-5} & \textbf{top-10} &
    \textbf{top-1} & \textbf{top-5} & \textbf{top-10} &
    \textbf{top-1} & \textbf{top-3} & \textbf{top-5} \\
    \midrule\arrayrulecolor{black}
    \multicolumn{14}{l}{\cellcolor[HTML]{EEEEEE}{\textit{$\mathcal{I} \rightarrow \mathcal{P}$}}} \\
    Uni-modal & \nd 16.67 & \nd 51.92 & 66.67 &  85.26 & 36.22 &  73.72 &  85.26 & \fs 14.00 & 36.00 & 67.00 & \fs 49.05 & \fs 85.15 & \fs 91.91 \\
    All Pairs & 16.35 & 54.17 & \nd 75.32 & \fs 91.35 & \fs 65.71 & \nd 86.54 & \nd 93.91 & 11.00 & \fs 42.00 & \nd 77.00 & 41.51 & 71.38 & 84.85 \\
    Ours & \fs 21.15 & \fs 57.05 & \fs 77.56 & \nd 89.10 & \nd 64.74 & \fs 89.42 & \fs 94.23 & \nd 13.00 & \nd 41.00 & \fs 84.00 & \nd 38.98 & \nd 73.28 & \nd 85.00 \\

     \multicolumn{14}{l}{\cellcolor[HTML]{EEEEEE}{\textit{$\mathcal{I} \rightarrow \mathcal{R}$}}} \\
     Uni-modal & 2.75 & 11.00 & 18.21 & 29.90 & 19.59 & 46.74 & 62.89 & 2.00 & 14.00 & 19.00 & 26.12 & 55.80 & 66.71 \\
     All Pairs & \nd 7.56 & \fs 33.68 & \fs 50.17 & \fs 65.64 & \fs 65.98 & \fs 83.16 & \fs 88.66 & \fs 8.00 & \fs 28.00 & \fs 52.00 & \fs 29.99 & \fs 58.42 & \fs 72.64 \\
    Ours & \fs 8.59 & \nd 31.27 & \nd 45.70 & \nd 59.79 & \nd 57.39 & \nd 82.82 & \nd 87.63 & \nd 3.00 & \nd 25.00 & \nd 51.00 & \nd 29.04 & \nd 57.85 & \nd 70.75 \\

     \multicolumn{14}{l}{\cellcolor[HTML]{EEEEEE}{\textit{$\mathcal{P} \rightarrow \mathcal{R}$}}} \\
    Uni-modal & 2.06 & 5.15 & 12.03 & 21.31 & 11.68	& 39.86	& 57.04	& 3.00 & 6.00 & 11.00 & 25.82 & 53.52	& 68.08 \\
    All Pairs & \nd 6.87 & \nd 24.05 & \nd 37.46 & \fs 58.42 & \nd 56.70 & \nd 74.57 & \nd 82.82 & \nd 3.00	&  \fs 22.00 & \nd 41.00 & \fs 31.94 & 	\nd 56.12 & \fs 70.22 \\
    Ours & \fs 7.22 & \fs 27.49 & \fs 44.33 & \nd 57.73 & \fs 57.73 & \fs 79.04 & \fs 85.57 & \fs 5.00 & \nd 20.00 & \fs 46.00 & \nd 26.79 & \fs 56.57 &  \nd 68.63 \\
     
    \bottomrule
    \end{tabular}
    }
    \caption{\textbf{Uni-modal \& All pair-wise modality training on Scene-Level Encoder Inference on Cross-Modal Scene Retrieval on \textit{ScanNet}.} `All Pairs' refers to training our unified encoder with all pairwise modality combinations. `Uni-modal' refers to the scene-level encoder with single-modality input. As shown in the Table, our approach outperforms the scene-level encoder and `All Pairs' in most cases. Unlike the unified dimensionality encoders, the scene-level encoder relies on instance-level data, even when operating on a single modality.}
    \label{tab:cross_modal_scene_retrieval_scannet_scenenc}
\end{table*}