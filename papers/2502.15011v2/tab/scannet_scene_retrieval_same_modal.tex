\begin{table*}[t]
  \centering
   \begin{tabular}{l|ccc| ccc || ccc}
    \toprule
    \textbf{Method} & \multicolumn{3}{c}{\textbf{Scene Category Recall} $\uparrow$} & \multicolumn{3}{c}{\textbf{Temporal Recall} $\uparrow$} & \multicolumn{3}{c}{\textbf{Intra-Category Recall} $\uparrow$} \\
    \midrule\arrayrulecolor{black} 
    & \textbf{top-1} & \textbf{top-5} & \textbf{top-10} & \textbf{top-1} & \textbf{top-5} & \textbf{top-10}
    & \textbf{top-1} & \textbf{top-3} & \textbf{top-5} \\
    \midrule\arrayrulecolor{black}
    
    \multicolumn{10}{l}{\cellcolor[HTML]{EEEEEE}{\textit{$\mathcal{I} \rightarrow \mathcal{I}$}}} \\
    ULIP-2~\cite{xue2023ulip2} & 35.9 & 44.23 & 56.73 & 1.00 & 2.00 &  30.00 & 89.75 & 96.91 & 96.91 \\
    PointBind~\cite{pointbind} & \fs 93.59 & \nd 96.79 & \fs 98.08 & \fs 22.00 & \fs 59.00 & \fs 99.00 & \nd 90.21 & \fs 100 & \fs 100 \\
    Inst.\ Baseline (Ours)     & \nd 89.74 & 95.19 & 97.12 & \fs 22.00 & \nd 58.00 & \fs 99.00 & 80.22 & \nd 98.84 & \nd 99.87 \\
    Ours & 91.67 & \fs 97.76 & \nd 98.08 & \nd 11.00 & \fs 59.00 & \nd 98.00 & \fs 100 & \fs100 & \fs 100 \\

    \multicolumn{10}{l}{\cellcolor[HTML]{EEEEEE}{\textit{$\mathcal{R} \rightarrow \mathcal{R}$}}} \\
    ULIP-2~\cite{xue2023ulip2} & 11.34 & 18.56 & 24.05 & 1.00 & 2.00 & 4.00 & 36.63 & 57.12 & 66.17 \\
    PointBind~\cite{pointbind} & 11.34 & 18.56 & 24.05 & 1.00 & 2.00 & 4.00	& 36.63 & 57.12 & 66.17 \\
    Inst.\ Baseline (Ours) & \nd 69.42 & \fs 91.75 & \fs 94.16 & \fs 13.00 & \fs 51.00 & \fs 83.00 & \nd 86.56 & \nd 97.65 & \nd 99.20 \\
    Ours & \fs 76.98 & \nd 91.75 & \nd 94.85 & \fs 14.00 & \nd 40.00 & \nd 79.00 & \fs 100 & \fs 100 & \fs 100 \\
    \multicolumn{10}{l}{\cellcolor[HTML]{EEEEEE}{\textit{$\mathcal{P} \rightarrow \mathcal{P}$}}} \\
    ULIP-2~\cite{xue2023ulip2} & 13.14 & 13.14 & 23.72 & 1.00 & 2.00 & 3.00 & 21.52 & 42.12 & 57.25  \\
    PointBind~\cite{pointbind} & 17.63 & 58.33 & 71.47 & 7.00 & 23.00 & 45.00 & 59.54 & 90.36 & 96.46 \\
    Inst.\ Baseline (Ours) & \nd 38.14 & \nd 75.00 & \nd 85.38 & \nd 14.00 & \nd 42.00 & \nd 73.00 & \nd 86.31 & \nd 97.14 & \nd 99.81 \\
    Ours & \fs 86.54 & \fs 95.51 & \fs 96.79 & \fs 19.00 & \fs 57.00 & \fs 96.00 & \fs 100 & \fs 100 & \fs 100 \\
    \midrule
    \midrule
    \multicolumn{10}{l}{\cellcolor[HTML]{EEEEEE}{\textit{$\mathcal{F} \rightarrow \mathcal{F}$}}} \\
    ULIP-2~\cite{xue2023ulip2} & 13.78 & 24.36 & 41.03 & 1.00 & 2.00 & 5.00 & \nd 99.27 & \nd 99.89 & \nd 99.89 \\
    PointBind~\cite{pointbind} & \nd 63.78 & \nd 82.37 & \nd 89.10 & \nd 7.00 & \nd 37.00 & \nd 67.00 & \fs 100 & \fs 100 & \fs 100 \\
    Ours & \nd 59.95 & \fs 83.65 & \fs 90.38 & \fs 14.00 & \fs 43.00 & \fs 74.00 & \fs 100 & \fs 100 & \fs 100 \\
    \midrule
    \midrule
    \multicolumn{10}{l}{\cellcolor[HTML]{EEEEEE}{\textit{$\mathbf{F}_{\mathcal{S}} \rightarrow \mathbf{F}_{\mathcal{S}}$}}} \\
    Ours & 94.23 & 97.44 & 98.08 & 17.00 & 57.00 & 99.00 & 100 & 100 & 100 \\
    \bottomrule
    \end{tabular}
    \caption{\textbf{Same-Modality Scene Retrieval on \textit{ScanNet}.} Our method performs on par with or better than baselines in same-modality scene retrieval across most metrics, indicating that individual modalities in our method are closely aligned within the embedding space, despite the cross-modal training objective.}
    \label{tab:same_modal_scene_retrieval_scannet}
\end{table*}