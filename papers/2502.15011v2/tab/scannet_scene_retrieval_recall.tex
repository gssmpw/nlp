\begin{figure*}
    \centering
    \includegraphics[width=0.95\columnwidth]{fig/recall_cross_modal.pdf}
    \vspace{-10pt}
    \caption{\textbf{Cross-Modal Scene Retrieval on \textit{ScanNet} (Scene Matching Recall).} Plots show the top 1, 5, 10, 20 scene matching recall of different methods on three modality pairs: $\mathcal{I} \rightarrow \mathcal{P}$, $\mathcal{I} \rightarrow \mathcal{R}$, $\mathcal{P} \rightarrow \mathcal{R}$. Ours and Instance Baseline have not been explicitly trained on $\mathcal{P} \rightarrow \mathcal{R}$. Results are computed on 306 scenes and showcase the superior performance of our approach. Once again, the difference between Ours and our self-baseline is attributed to the enhanced cross-modal scene-level interactions achieved with the unified encoders.}
    \label{fig:cross_modal_scene_retrieval_scannet_same_recall_graph}
\end{figure*}
\vspace{-2pt}