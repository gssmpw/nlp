\documentclass{article}

%%% ready for submission %%%
\usepackage[preprint]{cpal_2025}
\usepackage{amsmath}
\usepackage{amssymb}
\newtheorem{remark}{Remark}
\usepackage{mathtools}
\input{preamble.macros}
\input{preamble.tikz}
\usepackage{makecell}
% \newcommand{\pder}[2]{\ensuremath{\frac{\partial #1}{\partial #2}}}
% \newcommand\mubold{{\ensuremath{\boldsymbol{\mu}}}}
% \newcommand{\Dcal}{\ensuremath{\mathcal{D}}}
%%% to compile a preprint version, e.g., for submission to arXiv, add the [preprint] option %%%
%\usepackage[preprint]{cpal_2025}

%%% to compile a camera-ready version, add the [final] option %%%
%\usepackage[final]{cpal_2025}


%add packages
\usepackage{url}

%\title{Learning Effective Dynamics For Multi-Scale Time-Invariant System}
\title{Learning Effective Dynamics across Spatio-Temporal Scales of  Complex Flows}

\author{%
  Han Gao\textsuperscript{1}, ~Sebastian Kaltenbach \textsuperscript{1}, ~Petros Koumoutsakos \textsuperscript{1}\thanks{Corresponding author} \\
  \textsuperscript{1}Harvard SEAS \\
  \texttt{\{hgao1,skaltenbach,petros\}@seas.harvard.edu}
}

\begin{document}


\maketitle


\begin{abstract}
Modeling and simulation of complex fluid flows with dynamics that span multiple spatio-temporal scales is a fundamental challenge in many scientific and engineering domains. Full-scale resolving simulations for systems such as highly turbulent flows are not feasible in the foreseeable future, and reduced-order models must capture dynamics that involve interactions across scales. In the present work, we propose a novel framework, Graph-based Learning of Effective Dynamics (Graph-LED), that leverages graph neural networks (GNNs), as well as an attention-based autoregressive model, to extract the effective dynamics from a small amount of simulation data.  GNNs represent flow fields on unstructured meshes as graphs and effectively handle complex geometries and non-uniform grids. The proposed method combines a GNN based,  dimensionality reduction for variable-size unstructured meshes with an autoregressive temporal attention model that can learn temporal dependencies automatically. We evaluated the proposed approach on a suite of fluid dynamics problems, including flow past a cylinder and flow over a backward-facing step over a range of Reynolds numbers. The results demonstrate robust and effective forecasting of spatio-temporal physics; in the case of the flow past a cylinder, both small-scale effects that occur close to the cylinder as well as its wake are accurately captured. 
\end{abstract}


\section{Introduction}
Simulating complex systems that exhibit dynamics across multiple spatial and temporal scales remains a key challenge in a wide array of scientific and engineering disciplines. From turbulence \cite{wilcox1988multiscale} and climate modeling \cite{national2012exposure} to ocean dynamics \cite{mahadevan2016impact} and biological systems \cite{de2015multiscale}, accurately capturing the intricate interplay between various scales is essential to understand, predict, and optimize system behavior. Traditional high-fidelity simulations, while accurate, often require substantial computational resources, rendering them impractical for real-time applications or extensive parametric studies. Consequently, reduced-order modeling (ROM) has emerged as a vital strategy for simplifying these complex systems by constructing lower-dimensional representations that preserve essential dynamics.

Despite its promise, ROM faces significant hurdles, particularly in scenarios where multiple regimes or scales interact within a single system \cite{peng2021multiscale}. Capturing nuanced interactions between different spatial and temporal scales in a unified reduced-order framework requires sophisticated modeling techniques that can adapt to varying geometries, resolutions, and dynamic behaviors. Traditional ROM approaches, such as Proper Orthogonal Decomposition (POD) \cite{berkooz1993proper} or Galerkin projections \cite{peherstorfer2016data, schwerdtner2024nonlinear}, often struggle with scalability and flexibility when dealing with unstructured meshes or non-linear dynamics inherent in multi-scale systems.

Graph neural networks (GNNs) present substantial advantages for the modeling of discretized spatiotemporal systems governed by partial differential equations (PDEs) within unstructured meshes. These advantages encompass efficient spatial computation allocation, geometric adaptability, and end-to-end learning capabilities \cite{pfaff2020learning,allen2022physical,sanchez2020learning, xu2021conditionally,alet2019graph,de2018end,sanchez2018graph}. Nonetheless, the precision of GNN models often diminishes when confronted with discontinuities and oscillations within flow fields, resulting in a decline in performance. These nonlinear instabilities become increasingly pronounced with extended rollout spans \cite{geneva2020modeling,stachenfeld2021learned}. Therefore, formulating robust and precise strategies to stabilize GNNs under such challenging flow scenarios is essential to unlocking their potential for real-world applications.

Several approaches have been proposed to stabilize rollouts, most of which are refinements of teacher-forcing methods \cite{lamb2016professor}, incorporating specialized training strategies to mitigate error accumulation in long-span rollouts. One common technique is noise injection, which augments the training dataset with perturbed samples to improve the model's robustness against noise. This approach is widely adopted for learning complex flows \cite{pfaff2020learning,allen2022physical,sanchez2020learning}. Another method involves feature conditioning, where additional neural networks with tailored input features enhance the expressive power of GNNs \cite{xu2021conditionally}. Although this method improves rollout accuracy, it increases computational cost and lacks clear guidelines for selecting features in complex problems. A variant of teacher-forcing uses multiple previous steps as input, enabling the model to use a longer history for more accurate predictions \cite{pfaff2020learning,geneva2020modeling}. Recent studies have demonstrated the benefits of optimizing the number of previous steps for improved accuracy \cite{pfaff2020learning}. However, this approach is computationally expensive, as it requires direct operations on a large number of nodes per step, leading to significant memory demands during gradient calculations and storage. A fundamental limitation of these teacher-forcing methods is the inconsistency between training and testing. Training relies on one-step predictions, whereas testing involves autoregressive multistep rollouts, exacerbating error accumulation and limiting long-term stability.

Sequence neural networks have recently emerged as powerful tools for simulating dynamical systems governed by PDEs, including long- and short-term memory (LSTM) networks \cite{vlachas2018data,ren2022phycrnet} and attention-based models \cite{geneva2022transformers}. Similar to teacher-forcing methods, these models use previous states to predict future ones. However, unlike teacher-forcing, sequence models do not rely on a small number of past steps for predictions. Instead, they leverage long-span dependencies by incorporating unique mechanisms, such as LSTM cells and hidden states \cite{hochreiter1997long} or attention mechanisms \cite{vaswani2017attention}, enabling more general and robust forecasting. Although these innovations overcome the limitations of short-span dependencies, they often require significant memory to store long-term spatiotemporal sequences. Consequently, dimension reduction techniques are commonly employed to ensure efficient and effective training \cite{lusch2018deep,pawar2019deep,lee2020model,hasegawa2020machine,murata2020nonlinear,eivazi2021recurrent,jacquier2021non,morimoto2021convolutional,fresca2022pod,vlachas2022multiscale}. For example, sequential networks combined with dimension reduction methods, such as convolutional neural networks or proper orthogonal decomposition, have been successfully applied to simulate unstable, convection dominated and reacting flows of varying complexity~\cite{wu2020data,ren2022phycrnet,geneva2022transformers,eivazi2020deep,maulik2021reduced,peng2020unsteady,xu2020multi}. Despite their promise, there remains a lack of robust frameworks that integrate GNNs with sequential learning architectures to handle unstructured flow data, particularly for moving or variable-size meshes. This work addresses this gap.

In this work, we propose a novel learning architecture that integrates a GNN-based autoencoder with a temporal attention model to efficiently predict spatio-temporal physical systems discretized on unstructured meshes. While GNNs have already been successfully employed to encode data or parameters in the context of simulations \cite{zhang2021eigen,barwey2024scalable,you2024gnumap,barwey2025interpretable}, using the encoded structure to forecast the evolution of high-dimensional, multi-scale systems of interest has not yet been explored. The Graph-LED framework comprises two main components: spatial dimension reduction and temporal forecasting. Spatial dimension reduction is achieved using a mesh-based GNN encoder-decoder, which aggregates local information of solution fields into node-level representations through multiple GNN layers. Our approach uses GNNs, enabling effective dimension reduction and recovery while preserving mesh information. Moreover, regions with different information and node density are readily incorporated into the framework. Temporal prediction is performed using an attention mechanism that facilitates dynamic learning and forecasting in a consistent autoregressive manner, eliminating the need for noise injection to stabilize rollouts. The proposed framework is validated on two incompressible flow scenarios with complex mesh configurations: flow past a cylinder at a Reynolds number of 696 and flow over a backward-facing step at
$Re=5000$. These cases feature multiscale flow characteristics, demonstrating the framework's ability to effectively handle intricate unstructured meshes and capture the complex dynamics of challenging physical systems.


\section{Methodology}
\begin{figure}[t]
    \centering
    \includegraphics[trim={0cm 0 0 15cm},clip,width=1\textwidth]{DenseFig.pdf}
    %\caption{A graph can naturally represent a Finite Volume mesh, where a node represents a cell, and an edge a connection between two adjacent cells. Given a high-dimensional initial state, the encoder maps it to a low-dimensional latent space, where a Transformer forecasts its dynamics. The decoder then maps the forecasted low-dimensional state back to the high-dimensional space.}
    \caption{Overview of Graph-LED: A high-dimensional initial state $\boldsymbol{U}_0$ is mapped to a low-dimensional latent representation $\boldsymbol{Z}_0$ via a GNN Encoder. Subsequently this latent representation is propagated for $n$ steps using a Transformer. The GNN Decoder then maps the forecasted low-dimensional state $\boldsymbol{Z}_n$  back to the high-dimensional state of interest $\boldsymbol{U}_n$.}
    \label{fig:overview}
\end{figure}
In this section, we are presenting the Graph-LED framework. An overview of the framework can be found in Figure \ref{fig:overview}. Afterwards, we are introducing the high-dimensional nonlinear system of interest in  Section~\ref{sec:nse}. Section~\ref{sec:disandgraph} shows how the state of such a system can be naturally represented by a graph. Section~\ref{sec:ledoverview} explains the Graph-LED framework in detail, including the architecture choices (Section~\ref{sec:gnncompo}), the interpolation tool (Section~\ref{sec:interpolation}) and the dimension reduction via GNN (Section~\ref{sec:dimreduc}). Section~\ref{sec:temp_model} details the temporal modeling in the low dimensional space.
\subsection{Navier-Stokes Equations}
\label{sec:nse}
In this section, we define the governing PDEs discussed throughout this paper. We note that while within this paper we target fluid dynamics as our application, the framework presented can also be applied to other PDEs of interest. \\
Let \(\Omega \subset \mathbb{R}^2\) denote the spatial domain and \(\mathcal{I} \equiv (0, \tau]\) the time domain, where \(\tau \in \mathbb{R}_{>0}\) is the end time. For a two-dimensional Cartesian coordinate system, the spatial coordinate is \(\mathbf{x} = [x, y]\), and the spatial gradient operator is \(\nabla(*) := \left[\frac{\partial(*)}{\partial x}, \frac{\partial(*)}{\partial y}\right]\). Here, \(\mathbf{v} : \Omega \times \mathcal{I} \to \mathbb{R}^2\) denotes the velocity vector, typically expressed as \(\mathbf{v} = [u, v]\). Subsequently, the time-dependent Navier-Stokes (NS) equations are given by:
\begin{equation}
    \frac{\partial \rho}{\partial t} + \nabla \cdot \left( \rho \mathbf{v} \right) = 0, \quad \text{in } \Omega \times \mathcal{I},
    \label{eqn:continuity}
\end{equation}
and
\begin{equation}
    \frac{\partial }{\partial t} \left( \rho \mathbf{v} \right) + \nabla \cdot \left( \rho \mathbf{vv} \right) = \nabla \cdot \left( \mu \nabla \mathbf{v} \right) - \nabla p + \nabla \cdot \left( \mu \nabla \mathbf{v}^{\text{T}} \right) - \frac{2}{3} \nabla \left( \mu \nabla \cdot \mathbf{v} \right), \quad \text{in } \Omega \times \mathcal{I},
    \label{eqn:momentum}
\end{equation}
where \(\rho : \Omega \times \mathcal{I} \to 1\) is the constant normalized density, \(p : \Omega \times \mathcal{I} \to \mathbb{R}\) is the pressure, and \(\mu\) is the viscosity.\\
The vorticity \(w : \Omega \times \mathcal{I} \to \mathbb{R}\) of the flow field can be computed as
\begin{equation}
    w := \pder{v}{x} - \pder{u}{y}
\end{equation}
The Reynolds number, which is often used to characterize a fluid flow, is defined as: 
\begin{equation}
Re \coloneqq \frac{\rho |U| l_\mathrm{ref}}{\mu},
\end{equation}
where \(l_\mathrm{ref}\) is the reference length and $U$ the flow speed.



\subsection{Discretization and graph representation}
\label{sec:disandgraph}
To compute approximate solutions of the NS equations presented above, we use the finite-volume (FV) method for spatial discretization \cite{moukalled2016finite}. Let $\mathcal{E}$ denote an unstructured (flexible grid with irregularly arranged elements) FV mesh, defined as a collection of non-overlapping cells that cover the domain $\Omega$. These cells are ordered as $\mathcal{E} = \{\Omega_1, \dots, \Omega_N\}$. For any two adjacent cells, $\Omega_i$ and $\Omega_j$, their shared metrics, such as relative displacement and the area of their shared boundary, are represented by a characteristic vector $\mathbf{e}_{i,j} \in \mathbb{R}^{N\mathbf{e}}$. At any given time, each cell $\Omega_i$ is associated with a solution vector $\mathbf{u}_i \in \mathbb{R}^{N\mathbf{u}}$, which approximates the continuous solution evaluated at the center of $\Omega_i$.
As shown in Fig.~\ref{fig:graphrepresentation}, we can use an undirected graph to describe a snapshot of a mesh-based solution as \begin{equation}
        G = (\mathbf{U},\mathbf{A},E).
        \label{eq:graph}
    \end{equation}
 $\mathbf{U}=[\mathbf{u}_1,\dots,\mathbf{u}_N]\in\mathbb{R}^{N_u\times N}$ is the vector of features of the node of the graph where subscripts represent nodes. $\mathbf{A}\in\mathbb{R}^{N\times N}$ is the graph adjacency matrix with binary entries, if $(\mathbf{A})_{i,j}=1$, there is an edge connection between node $i$ and node $j$, which indicates that cell $\Omega_i$, $\Omega_j$ are adjacent to each other. We can obtain the total number of edges via the adjacency matrix as $N_E=\sum_{i}^N \sum_{j}^i (\mathbf{A})_{i,j}$. $E=\{\mathbf{e}_{i,j}|\;(\mathbf{A})_{i,j}=1\}$ stores all the edge features of $N_E$. 
 
\begin{figure}[t]
    \centering
    \includegraphics[trim={0cm 15cm 33cm 0cm},clip,scale=0.3]{DenseFig.pdf}
    %\caption{A graph can naturally represent a Finite Volume mesh, where a node represents a cell, and an edge a connection between two adjacent cells. Given a high-dimensional initial state, the encoder maps it to a low-dimensional latent space, where a Transformer forecasts its dynamics. The decoder then maps the forecasted low-dimensional state back to the high-dimensional space.}
    \caption{Left: Visualization of a FV mesh that can be naturally represented by a Graph. Right: Definition of graph nodes $\boldsymbol{u}_j$ as cells and graph edges $\boldsymbol{e}_ij$ as connection between two adjacent cells}
    \label{fig:graphrepresentation}
\end{figure}

 
 \begin{remark}
 In the context of graph representation, the edge is an abstract concept, not a geometric object. We call two nodes in a graph connected via an edge. However, in a mesh, an edge is often referred to as the line connecting two vertices. Furthermore, graph representation is not only applicable to FV meshes, it can also represent other mesh formats used for finite element or finite difference.
 \end{remark}
 
 We apply a numerical integral method (e.g., Euler or Runge-Kutta) together with the spatial discretization of FV \cite{jasak2007openfoam}. Given time points of interest $\Tcal=\{t_0,t_1,\dots,t_{N_t}\mid t_{j+1}-t_j=\Delta t\quad j=0,\dots,N_t-1\}\subset \mathcal{I}$ and initial condition $\mathbf{U}_{0}^*$, the sequence of the solution is
\begin{equation}
    \Ucal^{F} =  \{\mathbf{U}^*_{1},\dots,\mathbf{U}^*_{N_t}\mid     \mathbf{U}^*_{j+1} = \Fcal(\mathbf{U}^*_{j};\Delta t,\delta t) \quad j=0,\dots,N_t-1 \},
    \label{eqn:solver}
\end{equation}
where $j$ is for $t_j$. And $\Fcal:\mathbb{R}^{N_u\times N}\times \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}^{N_u\times N}$ is the forward solver to advance the solution to the next time step of interest, where $\delta t$ is the actual numerical integral step.

To resolve all scales of interest, $N$ can be very large \cite{moukalled2016finite}. To save computational costs and facilitate many-query tasks, we seek to approximate $\Ucal^F_i\approx \Ucal^{F_r}_i$, which will be detailed in the following sections.
% \begin{figure}[t]
%     \centering
%     \includegraphics[width=1\textwidth]{methodgled.pdf}
%     \caption{Given a high-dimensional initial state, the encoder maps it to a low-dimensional latent space, where a Transformer forecasts its dynamics. The decoder then maps the forecasted low-dimensional state back to the high-dimensional space.}
%     \label{fig:framework}
% \end{figure}

\subsection{Learning effective dynamics across spatiotemporal scales}
\label{sec:ledoverview}
Our framework consists of two main parts: We initially employ a GNN as an encoder-decoder framework, which transforms high-dimensional states into a low-dimensional latent space, as elaborated in Section~\ref{sec:GNN}. Subsequently, the encoder and decoder derived are used to train a transformer model to predict dynamics within low-dimensional space, as discussed in Section~\ref{sec:temp_model}.

\subsubsection{GNN architecture}
\label{sec:GNN}
%\subsubsection{Model components}
\label{sec:gnncompo}
We utilize multilayer perceptrons (MLP), which are fully connected feedforward neural networks. These networks facilitate the mapping of vectors from dimension $N_{\mathrm{in}}$ to $N_{\mathrm{out}}$, denoted as $\mathrm{mlp}:\mathbb{R}^{N_{\mathrm{in}}}\rightarrow\mathbb{R}^{N_{\mathrm{out}}}$ and $\mathbf{u}\mapsto\mathrm{mlp}(\mathbf{u})$. Layer normalization (LNM) is employed to perform an affine transformation on a vector $\mathbf{u}$ using learnable parameters \cite{ba2016layer}, indicated as $\mathrm{lnm}:\mathbb{R}^{N_{\mathrm{in}}}\rightarrow\mathbb{R}^{N_{\mathrm{in}}}$ and $ \mathbf{u}\mapsto\mathrm{lnm}(\mathbf{u})$. Subsequently, we present the GNN layer as described in \eqref{eqn:gnn}, which is adapted from \cite{pfaff2020learning}. This layer processes an input graph ($G_1$) and produces an output graph ($G_2$): $G_1\mapsto G_2=\mathrm{gnn}(G_1)$. Within a graph, any given node consolidates the features of its neighboring nodes in a two-step process. The first step is to update the edge feature vector: an MLP ($\mathrm{mlp}_\mathrm{e}$) takes the input that concatenates the center node feature ($\mathbf{u}^1_i$, where the superscript shows to which graph it belongs to), the neighbor nodes' ($j\in\Ncal(i)$) and edge features ($\mathbf{u}^1_j,\mathbf{e}^1_{i,j}$), and outputs the new edge feature ($\mathbf{e}^2_{i,j}$). The second step is to update the node feature vector. Another MLP ($\mathrm{mlp}_\mathrm{n}$) takes the input, which concatenates the central node feature ($\mathbf{u}_i^1$), and the mean updated edge features of all neighbors ($\frac{1}{|\Ncal(i)|}\sum_{j\in\Ncal(i)}\mathbf{e}^2_{i,j}$) to update the center node feature $\mathbf{u}^2_i$. In addition, the residual connection and layer normalization ($\mathrm{lnm}_\mathrm{e},\mathrm{lnm}_\mathrm{n}$) are applied for both steps. These two steps can be expressed by the function of a GNN layer: $G_1 = (\mathbf{U}_1, \mathbf{A}, E_1), G_2 = (\mathbf{U}_2, \mathbf{A}, E_2),\mathrm{gnn}:G_1 \mapsto G_2$,  
\begin{equation}
\begin{split}
&E_1 = \{\mathbf{e}_{i,j}^{1}\},\quad\mathbf{U}_1 = [\mathbf{u}^{1}_1,\dots,\mathbf{u}^{1}_N],
\\
&E_2 = \big\{ \mathbf{e}_{i,j}^2 \;\big|\;  \mathbf{e}^2_{i,j} = \mathbf{e}^1_{i,j}+\mathrm{lnm}_\mathrm{e}\;\circ\;\mathrm{mlp}_\mathrm{e}([\mathbf{u}_i^1, \mathbf{u}_j^1, \mathbf{e}_{i,j}^1])                 \big\},\\
&\mathbf{U}_2 = \big[\mathbf{u}^2_1,\dots,\mathbf{u}^2_N\big|
\mathbf{u}_i^2=\mathbf{u}_i^1+\mathrm{lnm}_\mathrm{n}\;\circ\;\mathrm{mlp}_\mathrm{n}([\mathbf{u}_i^1,\frac{1}{|\Ncal(i)|}\sum_{j\in\Ncal(i)}\mathbf{e}^2_{i,j}])
\big].
\end{split}
\label{eqn:gnn}
\end{equation}
$N_g$ GNN layers are stacked as a compound function $\mathrm{gnns}_{N_g} \coloneqq \mathrm{gnn}_1\;\circ\;\dots\;\circ\;\mathrm{gnn}_{N_g}$.


\subsubsection{Coordinates assignment and interpolation}
\label{sec:interpolation}
We associate every node in a graph $G$ (see Equation \ref{eq:graph}) with a coordinate, and $\Xcal_1=\{\mathbf{x}_1,...,\mathbf{x}_{N_1}\}$ denotes the set of all node coordinates. For the graph feature vector $\mathbf{U}=[\mathbf{u}_1,\dots,\mathbf{u}_{|\Xcal_1|}]$, we can perform a regular interpolation operation given a new set of coordinates $\Xcal_2 = \{\mathbf{x}_{1},...,\mathbf{x}_{|\Xcal_2|}       \}$,
    \begin{equation}
        \mathbf{Z} =[\mathbf{z}_1,\dots,\mathbf{z}_{|\Xcal_2|}] = I^{\Xcal_1}_{\Xcal_2}(\mathbf{U}),\quad \mathbf{U}'=[\mathbf{u}'_1,\dots,\mathbf{u}'_{|\Xcal_1|}] = I^{\Xcal_2}_{\Xcal_1}(\mathbf{Z}),
    \end{equation}
    where $I$ is a general interpolation method, $I^{\Xcal_1}_{\Xcal_2}:\mathbb{R}^{N_\mathbf{u}\times |\Xcal_1|}\rightarrow \mathbb{R}^{N_\mathbf{u}\times |\Xcal_2|}$ and $I^{\Xcal_2}_{\Xcal_1}:\mathbb{R}^{N_\mathbf{u}\times |\Xcal_2|}\rightarrow \mathbb{R}^{N_\mathbf{u}\times |\Xcal_1|}$. In this paper, we apply the nearest-neighbor interpolation method \cite{qi2017pointnet++}. {A visualization of this process during the up-sampling in the decoding can be found in Figure \ref{fig:grapha} and further explanation in Appendix \ref{sec:in}.}

\begin{figure}[t]
    \centering
    \includegraphics[trim={33cm 14cm 0cm 6cm},clip,scale=0.3]{DenseFig.pdf}
    %\caption{A graph can naturally represent a Finite Volume mesh, where a node represents a cell, and an edge a connection between two adjacent cells. Given a high-dimensional initial state, the encoder maps it to a low-dimensional latent space, where a Transformer forecasts its dynamics. The decoder then maps the forecasted low-dimensional state back to the high-dimensional space.}
    \caption{{Interpolation to new coordinates: Based on the three colored nodes, we reconstruct the node values at new nodes via nearest neighbor interpolation, i.e. weighting the contribution of each colored node according to their distance from the new node. Finally we are able to construct a new larger or smaller graph. }}
    \label{fig:grapha}
\end{figure}

\begin{remark}
Graphs generally stay in the non-Euclidean space, and the node's position definition varies from problem to problem. The graph representation of meshes naturally provides the Euclidean coordinates of cells that can be used here to make GNNs mimic the encoder-decoder dimension reduction of CNNs.
\end{remark}

\subsubsection{Dimension reduction and up-sampling via GNN}
\label{sec:dimreduc}
As all the components of the model have been introduced, we proceed to present the graph-mesh reducer designed for dimension reduction. We construct this encoder, as delineated in $\mathrm{Encoder}:(G_0,\Xcal_1,\Xcal_2,\mathbf{w}_{\mathrm{Encoder}})\mapsto \mathbf{Z}$ within \eqref{eqn:Encoder}. The process begins with the application of an MLP ($\mathrm{mlp}_0, \mathrm{mlp}_1$) to transform node ($\mathbf{u}^0_i$) and edge features ($\mathbf{e}^0_{i,j}$) into their respective hidden features ($\mathbf{U}_1,E_1$), which are subsequently normalized using LNM ($\mathrm{lnm}_0, \mathrm{lnm}_1$). These hidden node and edge features ($\mathbf{U}_1,E_1$) constitute the hidden graph ($G_1$). Thereafter, several GNN layers ($\mathrm{gnn}_{N_g}$) are employed to derive an alternative hidden graph ($G_2$). Once again, the MLP ($\mathrm{mlp}_2$) and LNM ($\mathrm{lnm}_2$) are utilized to manipulate the node feature ($\mathbf{u}_i^2$) of $G_2$, resulting in the generation of a new feature vector ($\mathbf{U}_3$). Given the two sets of coordinates, one ($\Xcal_1$) is associated with the input $\mathbf{U}_0$, and another ($\Xcal_2$) is associated with the output vector $\mathbf{Z}$. We perform interpolation to obtain the final reduced vector $\mathbf{Z}$.
\begin{equation}
        \begin{split}
        &G_0 = \big(\mathbf{U}_0=[\mathbf{u}_1^0,\dots,\mathbf{u}_{|\Xcal_1|}^0],\mathbf{A},E_0=\{\mathbf{e}^0_{i,j}\}  \big),\\
            &\mathbf{U}_1=[\mathrm{lnm}_0\circ\mathrm{mlp}_0(\mathbf{u}^0_1),\dots,\mathrm{lnm}_0\circ\mathrm{mlp}_0(\mathbf{u}_{|\Xcal_1|}^0)],\\
            &E_1=\{\mathbf{e}_{i,j}^1\;|\; \mathbf{e}_{i,j}^1=\mathrm{lnm}_1\circ\mathrm{mlp}_1(\mathbf{e}^0_{i,j})           \},\\
            &G_1 = (\mathbf{U}_1,\mathbf{A},E_1),\\
            &G_2 = \big(\mathbf{U}_2=[\mathbf{u}_1^2,\dots,\mathbf{u}_{|\Xcal_1|}^2],\mathbf{A},E_2=\{\mathbf{e}^2_{i,j}\}  \big) = \mathrm{gnns}_{N_g}(G_1),\\
            &\mathbf{U}_3=[\mathrm{lnm}_2\circ\mathrm{mlp}_2(\mathbf{u}^2_1),\dots,\mathrm{lnm}_2\circ\mathrm{mlp}_2(\mathbf{u}_{|\Xcal_1|}^2)],\\
            &\mathbf{Z}=[\mathbf{z}_1,...,\mathbf{z}_{|\Xcal_2|}]=\mathcal{I}^{\Xcal_1}_{\Xcal_2}(\mathbf{U}_3),
        \end{split}
        \label{eqn:Encoder}
\end{equation}
where $\mathbf{w}_\mathrm{Encoder}$ are all trainable in the Encoder.

\begin{remark}
Using GNN layers, each node contains not only its information, but also its neighbors. Moreover, with a proper number of GNN layers, we could leave out a portion of the original nodes and only keep a small number of nodes ($|\Xcal_2|\ll|\Xcal_1| $) which still contain the original graph information. The MLPs are flexible to control the dimension of the feature vector layer-wise. These are analogous to the concept of hidden channel number associated with height/width/length in CNNs.
\end{remark}

The graph-mesh up-sampler (Decoder) performs the reverse task to map a reduced vector ($\mathbf{Z}$) to a high-dimension vector ($\mathbf{U}$) ( see \eqref{eqn:Decoder}). Given the coordinates ($\Xcal_1, \Xcal_2$) associated with the output ($\mathbf{U}$) and the input ($\mathbf{Z}$). The hidden vector ($\mathbf{U}_0$) is obtained by up-sampling ($\mathcal{I}^{\Xcal_2}_{\Xcal_1}$). Then another hidden vector ($\mathbf{U}_1$) is processed by $\mathbf{U}_0$ through MLP ($\mathrm{mlp}_0$) and LNM ($\mathrm{lnm}_0$).  Given the edge feature vectors ($E_0$), we use MLP ($\mathrm{mlp}_1$) and LNM ($\mathrm{lnm}_1$) to obtain the hidden edge feature vectors ($E_1$). Then $\mathbf{U}_1$ and $E_1$ compose the hidden graph $G_1$. After several GNN layers are obtained, $G_2$ is obtained, we use MLP ($\mathrm{mlp}_2$) to map the features of the hidden nodes $\mathbf{U}_2$ to the final output $\mathbf{U}$. These sequential steps can be summarized as $\mathrm{Decoder}:(\mathbf{Z}, E_0=\{\mathbf{e}^0_{i,j}\},\Xcal_1,\Xcal_2,\mathbf{w}_{\mathrm{Decoder}})\mapsto \mathbf{U}$, 
    \begin{equation}
        \begin{split}
            &\mathbf{U}_0 = [\mathbf{u}_1^0,\dots,\mathbf{u}_{|\Xcal_1|}^0] = \mathcal{I}^{\Xcal_2}_{\Xcal_1}(\mathbf{Z}),\\
            &\mathbf{U}_1=[\mathrm{lnm}_0\circ\mathrm{mlp}_0(\mathbf{u}^0_1),\dots,\mathrm{lnm}_0\circ\mathrm{mlp}_0(\mathbf{u}_{|\Xcal_1|}^0)],\\
            &E_1=\{\mathbf{e}_{i,j}^1\;|\; \mathbf{e}_{i,j}^1=\mathrm{lnm}_1\circ\mathrm{mlp}_1(\mathbf{e}^0_{i,j})           \},\\
            &G_1 = (\mathbf{U}_1,\mathbf{A},E_1),\\
            &G_2 = \big(\mathbf{U}_2=[\mathbf{u}_1^2,\dots,\mathbf{u}_{|\Xcal_1|}^2],\mathbf{A},E_2=\{\mathbf{e}^2_{i,j}\}  \big) = \mathrm{gnns}_{N_g}(G_1),\\
            &\mathbf{U}=[\mathrm{mlp}_2(\mathbf{u}^2_1),\dots,\mathrm{mlp}_2(\mathbf{u}_{|\Xcal_1|}^2)],
        \end{split}
        \label{eqn:Decoder}
    \end{equation}
where $\mathbf{w}_\mathrm{Decoder}$ denotes all trainable parameters in the decoder.

\begin{remark}
In this study, a solution snapshot at time $t$ constitutes a solution vector associated with a computational mesh. The mesh information can be used to assemble $E_0$ to facilitate graph neural networks (GNNs) in reconstructing this solution vector. Additionally, it is important to note that the coordinates are employed solely for interpolation purposes, thereby preserving the method's shift invariance. Both aspects resemble similarity to a convolutional neural network (CNN) decoder, which inherently exploits the structured mesh information provided.
\end{remark}

More details on training for the GNN encoder and decoder can be found in Appendix \ref{sec:GNN_train}.


\subsubsection{Temporal model}
\label{sec:temp_model}
The value, key, and query functions represent core components within an attention mechanism \cite{vaswani2017attention}. The value function facilitates the mapping of an initial vector to a resultant vector $\Vcal:\mathbb{R}^{N^1_\mathbf{Z}}\rightarrow\mathbb{R}^{N^2_\mathbf{Z}}, \mathbf{Z}\mapsto \Vcal(\mathbf{Z})$, where $N^1_\mathbf{Z}$ typically constitutes a $N_\mathrm{h}$-fold multiple of $N^2_\mathbf{Z}$. Meanwhile, the query and key functions are characterized by uniform input and output dimensionalities. 
\begin{equation}
\begin{split}
\Qcal:\mathbb{R}^{N_\mathbf{Z}}\rightarrow \mathbb{R}^{N_\mathbf{Z}'},\quad \mathbf{Z}\mapsto \Qcal(\mathbf{Z}),\\
\Kcal:\mathbb{R}^{N_\mathbf{Z}}\rightarrow \mathbb{R}^{N_\mathbf{Z}'},\quad \mathbf{Z}\mapsto \Kcal(\mathbf{Z}).
\end{split}
\end{equation}
Given a pair of query and key functions, the unnormalized attention function maps two vectors of the same dimension to a positive scalar $\Acal:\mathbb{R}^{N_{\mathbf{Z}}}\times\mathbb{R}^{N_{\mathbf{Z}}}\rightarrow\mathbb{R}_{>0}$,
    \begin{equation}
        \Acal(\mathbf{Z}_1,\mathbf{Z}_2)=\exp\big(\Qcal(\mathbf{Z}_1)\cdot \Kcal(\mathbf{Z}_2)\big)= \exp \left( \sum_{i} \Qcal(\mathbf{Z}_1)_i \;\Kcal(\mathbf{Z}_2)_i\right),
    \end{equation}
    where $\mathbf{Z}_1$ is usually called the query vector and $\mathbf{Z}_2$ is the key vector. 

For a sequence of vectors $\Scal = \{\mathbf{Z}_k\}_{k=1}^{N_\mathrm{sl}}\subset \mathbb{R}^{N_\mathbf{Z}}$, the $N_h$-head attention model maps any element vector of the sequence to a new vector with the same dimension denoted by $\mathrm{mhat}^{\Scal}_{N_\mathrm{h}}:\Scal\rightarrow \mathbb{R}^{N_{\mathbf{Z}}}$, $\forall\mathbf{Z}_i\in \Scal, \mathbf{Z}_i\mapsto\mathbf{V}_i,$
\begin{equation}
    \begin{split}
    &a_{i,j}^\mathrm{h}=\frac{\Acal^\mathrm{h}(\mathbf{Z}_i,\mathbf{Z}_j)}{\sum_{k=1}^{N_\mathrm{sl}}\Acal^\mathrm{h}(\mathbf{Z}_i,\mathbf{Z}_k)}, \quad \Acal^\mathrm{h}\in\{\Acal^1,\dots,\Acal^{N_\mathrm{h}}\},\quad \mathrm{h}=1,\dots,N_{\mathrm{h}},\\
    &\mathbf{V}^\mathrm{h}_i=\sum_{j=1}^{N_\mathrm{sl}} a^\mathrm{h}_{i,j}\Vcal^\mathrm{h}(\mathbf{Z}_j),\quad\Vcal^\mathrm{h}\in\{\Vcal^1,\dots,\Vcal^{N_\mathrm{h}}\},\quad \mathrm{h}=1,\dots,N_{\mathrm{h}},\\
    &\mathbf{V}_i=[\mathbf{V}^1_i,\dots,\mathbf{V}^{N_\mathrm{h}}_i],
    \end{split}
\end{equation}
where $a^\mathrm{h}_{i,j}$ denotes the $\mathrm{h}$-th head attention of vectors $\mathbf{Z}_i,\mathbf{Z}_j$, and $\mathbf{V}_i\in\mathbb{R}^{N_\mathbf{Z}}$ is output vector from the input vector $\mathbf{Z}_i$. 

\begin{remark}
The formulation of query, key, and value functions is conceptually straightforward. These functions can derive from multi-layer perceptrons (MLPs) or alternative neural network constructs, provided that they maintain the vector dot-product operation \cite{vaswani2017attention}. Our multi-head attention model architecture adheres rigorously to the GPT-2 framework \cite{radford2019language}, which is appropriate for autoregressive predictions in dynamic systems.
\end{remark}

\textbf{Autoregressive, parametric sequence modeling}: The initial vector $(\mathbf{Z}_0)$ forms the starting set ($\Scal_0$). The new reduced vector $(\mathbf{Z}_{j+1})$ is predicted by choosing the last current vector $(\mathbf{Z}_{j})$ in the sequence $(\Scal_j)$ as input of the head attention model $N_\mathrm{h}$ ($\mathrm{mhat}_{N_\mathrm{h}}^{\Scal_j}$). We use a sliding window of length $N_\mathrm{sw}$ to keep the model only generating a new vector based on a constant number of previous vectors. Specifically, we drop out the older vectors outside the window, but always keep the parameter-dependent vector. This auto-regression can be mathematically expressed as $F_r:(\mathbf{Z}_0, \mathbf{w}_{F_r})\rightarrow \{\mathbf{Z}_1,\dots,\mathbf{Z}_{N_t}\}$,
\begin{equation}
\begin{split}
&\Scal_0 = \{\mathbf{Z}_0\}, \\
&\mathrm{repeat:}\begin{cases}
\Scal_j =\begin{cases}
\{ \mathbf{Z}_0,\dots,\mathbf{Z}_j \}\quad\text{if } j< N_{\mathrm{sw}}-1,\\
\{ \mathbf{Z}_{j+2-N_{\mathrm{sw}}},\dots,\mathbf{Z}_j \} \quad\text{if } j\geq N_{\mathrm{sw}}-1,
\end{cases}
\\
\mathbf{Z}_{j+1}=\mathrm{mhat}^{\Scal_j}_{N_\mathrm{h}}(\mathbf{Z}_j),\\
    \Scal_{j+1} = \begin{cases}
\{ \mathbf{Z}_0,\dots,\mathbf{Z}_{j+1} \}\quad\text{if } j+1< N_{\mathrm{sw}}-1,\\
\{ \mathbf{Z}_{j+3-N_{\mathrm{sw}}},\dots,\mathbf{Z}_{j+1} \} \quad\text{if } j+1\geq N_{\mathrm{sw}}-1,
\end{cases}
\end{cases}
\end{split}
\end{equation}
where $\mathbf{w}_{F_r}$ is the involved trainable weights of all the neural networks.
\begin{remark}
If the total length of interest for the prediction is short, the model can look back at all the previous vectors, leading the vector-vector attention matrix to be a lower triangular matrix; otherwise, the vector-vector attention matrix is a block diagonal matrix. The goal of setting the sliding window is to reduce computational costs due to the quadratic complexity of attention \cite{vaswani2017attention}.
\end{remark}

Further details regarding the training for the introduced GNN encoder and decoder can be found in Section \ref{sec:temp_model_train}.


 

\section{Results}
\subsection{Cylinder flow}
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.45\linewidth]{fig_cylinder/mesh.png}
    \includegraphics[width=0.45\linewidth]{fig_cylinder/pivotal_point.png}
    \caption{The system is reduced from 27,127 points to 1,024 points.}
    \label{fig:fpc-mesh}
\end{figure}
Our first test case is the 2-D flow past a cylinder at $Re = 696$ where the reference length is $l_\mathrm{ref}=1$. In this work, our aim is to develop a surrogate model to predict the solution given any initial condition that lies in the solution manifold. Training (4500 snapshots) and testing (500 snapshots) data are generated using the OpenFOAM simulator \cite{jasak2007openfoam}, from which an unstructured mesh with different resolutions is used to discretize the domain (Fig.~\ref{fig:fpc-mesh}). The actual numerical integral step ($\delta t$) is 0.0025, and the Graph-LED is trained to directly evolve the system in a larger step of $\Delta t = 1$. 
\begin{figure}[htp]
    \centering
    %\includegraphics[width=0.3\textwidth]
    %{fig_cylinder/vorticity_colorbar.png}
    %\vfil
    \includegraphics[width=0.32\textwidth]{fig_cylinder/0_gled.png}
    \includegraphics[width=0.32\textwidth]{fig_cylinder/0_openfoam.png}
    \includegraphics[width=0.32\textwidth]{fig_cylinder/0_error.png}

    \includegraphics[width=0.32\textwidth]{fig_cylinder/50_gled.png}
    \includegraphics[width=0.32\textwidth]{fig_cylinder/50_openfoam.png}
    \includegraphics[width=0.32\textwidth]{fig_cylinder/50_error.png}

    
    \includegraphics[width=0.32\textwidth]{fig_cylinder/100_gled.png}
    \includegraphics[width=0.32\textwidth]{fig_cylinder/100_openfoam.png}
    \includegraphics[width=0.32\textwidth]{fig_cylinder/100_error.png}
    \caption{Vorticity ($\pder{v}{x} - \pder{u}{y}$) forecasted by Graph-LED (\textit{left}), OpenFOAM (\textit{middle}) and the error (\textit{right}) from $t = 0, 50, 100$ (\textit{from top row to bottom row}). }
    \label{fig:fpc-vor}
\end{figure}

Given a testing initial condition, the predictions using the proposed Graph-LED and OpenFOAM are plotted in Fig.~\ref{fig:fpc-vor}. The predicted vorticity fields are in good agreement with the OpenFOAM predictions { but can be generated with a large speedup (900X).} We note that the flow field in the wake is accuractly captured. When we examine the flow field near the cylinder (Fig.~\ref{fig:fpc-dpdthetawss} in Appendix \ref{sec:addres}), the pressure gradient over the cylinder and the wall shear stress (WSS) are well predicted by Graph-LED compared to OpenFOAM. Lastly, Graph-LED shows remarkable accuracy in capturing lift and drag coefficients (Fig.~\ref{fig:fpc-clcd} in Appendix \ref{sec:addres}), closely matching the results obtained from OpenFOAM, indicating that fine-scale high-frequency signals are effectively resolved. { We compared the performance of Graph-LED with two other deep-learning baselines in Section~\ref{sec:baselinecompare}.}



\subsection{Flow over backward-facing step}

\begin{figure}[htp]
    \begin{tikzpicture}
		\begin{groupplot}[
			group style={
				group size=1  by 1,
				horizontal sep=1cm
			},
			width=0.5\textwidth,
			axis equal image,
			xlabel={$x$},
			ylabel={$y$},
			xtick = {-5, 0, 10},
			ytick = {0, 1, 2},
			xmin=-5, xmax=10,
			ymin=0, ymax=2
			]
			\nextgroupplot[]
			\addplot graphics [xmin=-5, xmax=10, ymin=0, ymax=2] {fig_bf/meshbfs.png};
		\end{groupplot}
	\end{tikzpicture}
    \hfill
    \includegraphics[width=0.5\linewidth]{fig_bf/cyl0_geom.pdf}
    \caption{The system is reduced from 20,480 points to 2,048 points.}
    \label{fig:bfs-dom}
\end{figure}


\begin{figure}[htp]
    \centering
    \includegraphics[width=1\linewidth]{fig_bf/vor_at_0.png}
    \includegraphics[width=1\linewidth]{fig_bf/vor_at_10.png}
    \includegraphics[width=1\linewidth]{fig_bf/vor_at_20.png}
    \includegraphics[width=1\linewidth]{fig_bf/vor_at_30.png}
    \includegraphics[trim={0cm 2cm 0 0},clip,width=1\linewidth]{fig_bf/vor_at_40.png}
    % \includegraphics[width=1\linewidth]{fig_bf/vor_at_50.png}
    \caption{Vorticity ($\pder{v}{x} - \pder{u}{y}$) forecasted by Graph-LED (\textit{left}), OpenFOAM (\textit{middle}) and the error (\textit{right}) from $t = 0, 0.5, 1, 1.5, 2$ (\textit{from top row to bottom row}). }
    \label{fig:bf-vor}
\end{figure}

As a second case we consider the turbulent flow over a backward-facing step at $Re=5000$, a classical problem in which previous work \cite{geneva2020multi, gao2024generative} can only model the rectangular domain after the backward-facing step. However, we are interested in predicting not only the recirculation region after the step, but also the region in the pipe, that is, the entire domain (Fig.~\ref{fig:bfs-dom}). The complete data set contains 10,000 snapshots with a time-step size of $\Delta t = 0.05$, where 5000 snapshots are used for training and the rest are used for testing. The integral time step for the numerical simulation with OpenFOAM is $\delta t = 2\times 10^{-4}$. 

Given an instant snapshot as an initial condition, the prediction of vorticity is plotted in Fig.~\ref{fig:bf-vor}. Graph-LED demonstrated reasonably good performance in forecasting the sequence over one flow-through time, {achieving a significant speedup of around 100X}.

Graph-LED displays an outstanding capability to predict the mean and variance of vorticity over time (Fig.~\ref{fig:bf-mean} and Fig.~\ref{fig:bf-std} in the Appendix \ref{sec:addres}), effectively capturing the intricate dynamics of the system with high precision. One of the most striking aspects of its predictive power lies in its ability to accurately represent the spatial evolution of the vorticity profile. Initially, at the leftmost part of the domain, the profile begins in a symmetric state. As the analysis extends across the spatial domain, the vorticity profile undergoes a gradual transformation, transitioning into an asymmetric structure in the middle regions. Subsequently, as the spatial location approaches the rightmost end of the domain, the profile regains its symmetry. This ability to trace and replicate the nuanced transitions between symmetry and asymmetry highlights Graph-LED's strength in modeling not only temporal changes but also spatial variations, offering a profound insight into the complex physical phenomena that govern the dynamics of the flow field.

\section{Conclusions}
We introduced an innovative framework that integrates GNNs with attention-based autoregressive models to address the complexities of modeling multiscale spatiotemporal dynamics in unstructured mesh data. By leveraging GNNs for spatial dimension reduction and temporal attention mechanisms for dynamic forecasting, the proposed method achieves significant improvements in accuracy, efficiency, and scalability. The framework's robustness was demonstrated through fluid dynamics scenarios such as flow past a cylinder and flow over a backward-facing step, where it accurately captured intricate details like small-scale effects and high-frequency signals while significantly reducing computational costs.

The findings highlight the potential of the Graph-LED approach to model and predict physical systems with multiple spatio-temporal scales of interest, bridging a critical gap in the simulation of multiscale systems. Future work could explore integrating adaptive refinement strategies and addressing limitations such as error propagation in longer-term predictions.

\section*{Acknowledgements}
S.K. and P.K. acknowledge support by the Defense Advanced Research Projects Agency (DARPA) through Award
HR00112490489. H.G. and P.K. acknowledge support by the National Science Foundation (NSF) through Award CBET-2347423.
% This \LaTeX{} is heavily inspired by NeurIPS 2023.

% Do not include acknowledgements in the version for blind review.
% If a paper is accepted, please place such acknowledgements in an unnumbered section at the end of the paper, immediately before the references.
% The acknowledgements do not count towards the page limit.




% Reference
% For natbib users:
%\newpage
\bibliography{reference}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\appendix
\section{GNN Architecture - Training Details}
\label{sec:GNN_train}
The success of Encoder and Decoder is inherently linked to the proper network weight vectors that ensure accurate recovery of the high-dimension vector $\mathbf{U}$. To this end, we let $\mathbf{\Xi}=\{\mubold_1,\dots,\mubold_{N_s}\}\subset\Dcal$ be the collection of PDE encoder / encoder training parameters, and $G_{i,j}^*=(\mathbf{U}^*_{i,j},\mathbf{A}_{i},E_i)$ denotes the graph for $\mubold_i$ at time $t_j$ where $\mathbf{U}^*_{i,j}$ is from \eqref{eqn:solver}, $E_i, \mathbf{A}_i, \Xcal_1^i, \Xcal_2^i$ are from the mesh $\mathcal{E}_{\mubold_i}$ of $\mubold_i$. The optimal weights $\mathbf{w}_\mathrm{Encoder}^*,\mathbf{w}_\mathrm{Decoder}^*$ can be obtained via solving stochastic optimization with Adam method \cite{kingma2014adam},
    \begin{equation}
\begin{split}
\argoptunc{\mathbf{w}_\mathrm{Encoder},\mathbf{w}_\mathrm{Decoder}}{\sum_{i=1}^{N_s}\sum_{j=1}^{N_t}\Big|\Big|\mathbf{U}^*_{i,j}-\mathrm{Decoder}\Big( 
        \big(\mathrm{Encoder}(G^*_{i,j},\Xcal^i_1,\Xcal^i_1,\mathbf{w}_\mathrm{Encoder})\big),E_i,\Xcal^1_i,\Xcal^2_i,\mathbf{w}_\mathrm{Decoder}\Big)\Big|\Big|_2
        }.
\end{split}
    \end{equation}

\begin{remark}
For each scalar field in the training data, we use a normalization, where mean and variance are calculated from all of the training datasets. 
\end{remark}

\section{Nearest-neighbor interpolation}
\label{sec:in}
{We perform feature interpolation between the source and target point clouds in our framework \cite{you2024gnumap}. This method leverages the search for the nearest neighbor k to propagate features $\mathbf{U}$, defined at the source points $\Xcal_1$, to the target points $\Xcal_2$, to obtain $\mathbf{Z}$. For each target point, feature values were calculated as the weighted average of features from its k-nearest neighbors among the source points, with weights inversely proportional to the Euclidean distances in the spatial domain. This interpolation method ensures smooth and spatially coherent feature transfer, enabling effective integration of geometric and feature information across scales in our model.}


\section{Temporal model - Training Details}
\label{sec:temp_model_train}
To mitigate the additional cost of training the dynamic model ($F_r$), the training data are exactly the same as the data used to train the spatial models ($\mathrm{Encoder},\mathrm{Decoder}$). To this end, we used the trained encoder ($\mathbf{w}^*_\mathrm{Encoder}$) to generate the reduced vectors for training. And $\mathbf{Z}^*_{i,j}=\mathrm{Encoder}(G^*_{i,j},\Xcal^1_i,\Xcal^2_i,\mathbf{w}^*_{\mathrm{Encoder}})$ is for the $\mubold_i\in\mathbf{\Xi}$ and time point $t_j$. The training is formulated as 
\begin{equation}
        \mathbf{w}^*_{F_r}=\argoptunc{\mathbf{w}_{F_r}}{\sum_{i=1}^{N_s}\Big|\Big|\mathbf{Z}^*_{i,j} - \big(F_r(\mubold_i,\mathbf{Z}^*_{i,0},\mathbf{w}_{F_r})\big)_j\Big|\Big|_2
        },
\end{equation}
where $(\Scal)_j$ denotes the $j$-th elements of the ordered set $\Scal$.
\begin{remark}
The decoupled training of the spatial and temporal models has two advantages. The first is to reduce memory consumption for dynamic training. It allows the attention model to be trained only on the reduced vectors instead of the high-dimensional vectors. More importantly, the gradient of the loss function with respect to neural network weights becomes less memory-consumptive. Thus, the second advantage is that it enables a true auto-regressive training style consistent with the online evaluation instead of teacher forcing \cite{pfaff2020learning,xu2021conditionally}. 
\end{remark}
    

% \end{itemize}
\section{Evaluations Details}
Given a parameter $\mubold_i$, initial state $\mathbf{U}_{i,0}$, and relevant quantities ($\mathbf{A}_i,E_i,\Xcal^1_{i},\Xcal^2_{i}$) from the mesh, the Encoder model ($\mathrm{Encoder}$) firstly generate the initial reduced state vector ($\mathbf{Z}_{i,0}$), together with the parameter, the dynamic model ($F_r$) directly generates the prediction of reduced vectors and the Decoder ($\mathrm{Decoder}$) recovers the high-dimensional solution vectors,
\begin{equation}
    \begin{split}
    &G_{i,0}=(\mathbf{U}, \mathbf{A}_{i}, E_{i}),\\
  &      \mathbf{Z}_{i,0} = \mathrm{Encoder}(G_{i,0},\Xcal^1_{i},\Xcal^2_{i},\mathbf{w}^*_{\mathrm{Encoder}}),\\
 &       \{\mathbf{Z}_{i,1},\dots,\mathbf{Z}_{i,N_t}\} = F_r(\mubold_{i}, \mathbf{Z}_{i,0},\mathbf{w}^*_{F_r}),\\
 &\Ucal_{i}^{F_r} =  \{\mathbf{U}_{i,1},\dots,\mathbf{U}_{i,N_t}\mid \mathbf{U}_{i,j}=\mathrm{Decoder}(\mathbf{Z}_{i,j},E_{i},\Xcal^1_{i},\Xcal^2_{i},\mathbf{w}^*_{\mathrm{Decoder}}) \},
    \end{split}
\end{equation}
where we obtain the approximation of the numerical solution $\Ucal_i^{F_h}\approx\Ucal_i^{F_r}$ via neural networks with much lower cost.
\begin{remark}
The dynamics evolves directly in the reduced vector space. We can apply the Decoder model to recover the high-dimensional snapshots in a parallel way at the end of the evolution. Alternatively, we can store the reduced vectors using less memory than the original snapshots.
\end{remark}

\section{Hyperparameters of Graph-LED}
{For the cylinder case, we used 3 GNN layers for the encoder and 3 GNN layers for the decoder. All MLPs are three-layered, with 128 neurons in each level. For the Transformer \cite{radford2019language}, we used a two-layer model with eight heads and a context length of 32, and all MLPs are three-layer with 128 hidden units.
In the backward-facing step case, we have 5 GNN layers for the encoder and 5 GNN layers for the decoder. All MLPs are simply three layers with hidden units of 128. The Transformer is identical to the cylinder case, but the context length was reduced to 8.}


\newpage
\section{Comparison with two baselines}
\label{sec:baselinecompare}


{ For the cylinder case, we compared our Graph-LED framework with two state-of-the-art methods: MeshGraphNet \cite{pfaff2020learning} and NNGraphNet \cite{gilmer2017neural, xu2021conditionally}. In the following we have listed a comparison of the results including the Fr\'echet inception distance (FID), the continuous rank probability score (CRPS), and the errors of velocity, pressure, turbulent kinetic energy, and vorticity. All errors and metrics were computed as averages over a prediction of 100 time steps.

For all scalar error variables, our method outperforms the deep learning baselines with 10 times less error. Similarly for the non-Euclidean processes such as FID and CRPS, here our model also works significantly better. We attribute the significantly better error metrics of Graph-LED to the encoding to a latent space that is then advanced in time using a transformer. Thus, the Graph-architecture is not used for the latent dynamics which is in our test case advantageous due to the highly unstructured mesh that consists of cells with significantly varying size. Moreover, the Transformer architecture can capture long-range dependencies and is thus advantageous for temporal modeling. The poor performance of NNGraphNet is due to instabilities occurring at later prediction time steps as the GNN-based temporal predictions are less stable than the  used Transformer. This issue could potentially be addressed by using a more tailored noise injection method. For MeshGraphNet the predictions continued to be stable for the investigated time frame.\\
With regards to speedup compared to a full high-dimensional simulation, all three methods are capable of achieving a high speedup, with Graph-LED and MeshGraphNet outperforming NNGraphNet. The memory required is lowest for Graph-LED as we can store the states using their encoded representation.\\

To ensure a fair comparison, we used the same GNN architecture that was employed for Graph-LED for MeshGraphNet and the NNGraphNet architecture as published in \cite{xu2021conditionally}.

\begin{table}[htp]
    \centering
    \begin{center}
    \begin{tabular}{ |c|c|c|c| } 
     \hline
           & Graph-LED & \makecell{MeshGraphNet \\ (w. noise injection)} & \makecell{NNGraphNet \\ (w. noise injection)}\\
           \hline
     $e_u$ & 0.011801029& 0.36597002& 8.178367\\
     \hline
     $e_v$ & 0.024475042& 0.84774095& 47.916534\\ 
     \hline
     $e_p$ & 0.015479553& 0.70415086& 14.178546\\ 
     \hline
     $e_\mathrm{vorticity}$ & 0.028494475 & 0.79599255 & 25.201374\\ 
     \hline
     $e_\mathrm{TKE}$ & 0.009462313 & 0.5839962 & 9858.174\\ 
     \hline
     FID & 0.007336787& 673.4697655& 2860731.926\\ 
     \hline
     CRPS & 1.59538563& 3.716492& 76.2174\\ 
     \hline
     Memory per State & 2MB& 40MB& 40MB\\
     \hline
     Speedup during Predictions & $\approx$ 900x & $\approx$ 900x & $\approx$ 450x\\ 
     \hline
    \end{tabular}
    \end{center}
    \caption{ The error is calculated based on the relative root mean squared error (RRMSE), and TKE stands for turbulent kinetic energy \cite{pope2001turbulent}, FID is for Frechet inception distance based on vorticity \cite{jayasumana2024rethinking}, CRPS \cite{hersbach2000decomposition} is for continuous ranked probability score based on vorticity. The noise injection during training for both baselines is two percent of the standard deviation of each scalar field \cite{pfaff2020learning}.}
    \label{tab:my_label}
\end{table}
}

\newpage
\section{Additional Results}
\label{sec:addres}

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.49\linewidth]{fig_cylinder/dpdtheta.pdf}
    \includegraphics[width=0.49\linewidth]{fig_cylinder/wsstheta.pdf}
    \caption{Pressure gradient and wall shear stress ($\tau_\theta = \mu(\pder{(\mathbf{v}\cdot n)}{n})|_\theta$) on the cylinder forecasted over time by Graph-LED and OpenFOAM.}
    \label{fig:fpc-dpdthetawss}
\end{figure}


\begin{figure}[htp]
    \centering
    \includegraphics[width=0.49\linewidth]{fig_cylinder/CL_comparasion.pdf}
    \includegraphics[width=0.49\linewidth]{fig_cylinder/CD_comparasion.pdf}
    \caption{Lift and drag coefficients of the cylinder forecasted over time by Graph-LED and OpenFOAM.}
    \label{fig:fpc-clcd}
\end{figure}





\begin{figure}[htp]
    \centering
    \includegraphics[width=1\linewidth]{fig_bf/meanvor.png}
    \caption{Mean of vorticity over time at different vertical lines over the domain predicted by OpenFOAM and Graph-LED.}
    \label{fig:bf-mean}
\end{figure}
\begin{figure}[htp]
    \centering
    \includegraphics[width=1\linewidth]{fig_bf/stdvor.png}
    \caption{Standard deviation (std) of vorticity over time at different vertical lines over the domain predicted by OpenFOAM and Graph-LED.}
    \label{fig:bf-std}
\end{figure}
\end{document}