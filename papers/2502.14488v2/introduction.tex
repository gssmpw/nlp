\section{Introduction}\label{sec:introduction}

%\giulio{perhaps we should revisit the title into something like ``A Universal Indexing Framework for Matching Long Patterns: A First Study'' since this is a pilot paper and keep a more thorough investigation for a journal?}
%SPP: I agree and changed it simply by removing everything after ":"

The problem of \textit{text indexing}~\cite{navarro2007compressed}, at its core, involves finding all occurrences of a given pattern within a large body of text. Formally, the problem is as follows.

\begin{problem}[Text Indexing]
Given a string $T[0\dd n)$ (the ``text'' henceforth) of $n$ characters over an alphabet $\Sigma = [0 , \sigma)$, we are asked to pre-process $T$ so that the following queries are supported efficiently for any pattern $P[0 \dd m)$ and any $0 \leq i < j \leq n$:
\begin{itemize}
    \item $\Locate(P,T)$ determines the set $L = \{0 \leq i < n-m+1 \mid T[i \dd i+m) = P \}$;
    \item $\Count(P,T)$ returns $|L|$; and
    \item $\Extract(i,j,T)$ returns $T[i \dd j)$.
\end{itemize}
\end{problem}

Given the importance of text indexing, numerous classic solutions have been proposed, each with varying trade-offs between time and space efficiency. In general terms, these solutions fall into two categories: the \emph{compressed} and \emph{uncompressed} approaches.

A common strategy is to replace the original text with a compressed representation (a so-called ``self-index''), utilizing data structures like the \textit{FM-index}~\cite{10.1145/1082036.1082039} or its modern variants such as the \textit{r-index}~\cite{10.1145/3375890}. These indexes are highly space-efficient,  achieving space bounds in terms of the $k$-th order empirical entropy of the text, while retaining the ability to support searches. However, this efficiency in space comes at the cost of increased complexity in both the construction and query phases~\cite{navarro2007compressed}. Compressed indexes typically require more time to build, and querying can be slower compared to uncompressed counterparts due to the additional overhead involved in decoding the compressed representation.

On the other hand, uncompressed approaches, such as
the \textit{suffix array}~\cite{DBLP:journals/siamcomp/ManberM93}, do not alter the original text but instead attach some form of redundancy --- henceforth referred to as the \textit{index} --- to accelerate pattern matching. These methods, while being faster in terms of query times, often suffer from significant space inefficiency. For example, suffix arrays usually take up more space than the text itself, particularly for commonly used alphabets such as ASCII and DNA sequences~\cite{gusfield1997algorithms}. This makes such structures impractical for many applications, especially when working with very large datasets.

\parag{Our Contributions}
In this paper, we focus on the latter scenario of uncompressed text indexing and
aim to address its space inefficiency while retaining efficient queries. In the
following, we discuss the {\Locate} query only, given that {\Count} can be
trivially implemented using {\Locate}, and {\Extract} is done by explicitly
accessing the text $T$. We propose a novel approach that solves the text
indexing problem using only a small amount of additional space beyond the
original text, without sacrificing the speed of query processing. This is
achieved under the assumption that the query patterns $P[0 \dd m)$ are
  sufficiently long, i.e., we require that $m \geq \ell$ for some fixed lower
  bound $\ell > 0$~\cite{DBLP:conf/latin/AyadLPV24}, and operate under the assumption that $n \gg \ell$. 
%\ragnar{Add typical value of $\ell$? Like, at least on the order of 32 and up to 1000 or essentially unbounded as long as $n\gg \ell$?}
%\giulio{yes, I agree, one or two values can be reported to give an idea.}
A typical value for $\ell$ lies in $[32,1000]$. The core idea of our approach is to transform the text into sketch space, and to
construct and use a smaller index over the sketched text to enable queries with only small additional space.
Generally speaking, a sketch is a compact representation of an object that retains enough information for approximate matches. 
%\ragnar{To confirm after adding results, but IIRC u-index queries can actually be slower because of sketching overhead. We should be precise and write 'fast' as in 'around as fast or faster as plain data structures', rather than 'significantly faster than plain data structures'. That then also somewhat implies that the focus is mainly on size rather than speed, which we could stress a bit more.}
%\rob{@Ragnar : we say in the abstract that the sketched index has the ``potential of retaining or even improving query time'' --- I don't know if we expect this to be true anymore, but I think we were imagining that the conversion of the query to sketch space is small compared to the time for lookup, at least when the query itself is long.}
%\giulio{Can we confirm or disprove this now that we have some experimental results?}
%SPP: See right after enumerate

We therefore introduce a four-step framework for addressing text indexing:
\begin{enumerate}
  \item We sketch the text $T$, say $S=\Sketch(T)$. The sketch $S$ can be simply regarded as a new shorter string over a new alphabet $\Sigma'$.
  \item We then construct $\INDEX(S)$, an index on $S$, where $\INDEX$ is any indexing structure.
  %\red{\sout{This can either interpret the sketch as a string over the input alphabet $\Sigma$, or, more practically, can use an integer alphabet representing the minimizers.}} \giulio{Wait! we haven't talked about minimizers yet, so we should stay generic to convey the idea here. I've therefore added the piece in red at point 1.}
  \item Each query pattern $P$ is then sketched into $Q=\Sketch(P)$, and $Q$ is
    matched against $\INDEX(S)$ to identify \emph{potential} matches $L' =
    \Locate(S, Q)$.
    % \ragnar{Unfortunate asymetry that $S$ is before $T$, but $Q$ is after $P$.} Ahhh come on!
  \item Candidate matches in $L'$ are mapped back to their positions in
    $T$, where we verify that indeed the query pattern $P$
    matches the text. Thus we obtain $L=\Map(L')$, where $L=\Locate(P,T)$.
\end{enumerate}

The \textit{universality} of our framework lies in its flexibility: (i) \textit{any} indexing structure $\INDEX$, such as the FM-index or the suffix array, can be used to index the sketched text $S$, making the method adaptable to a variety of text indexing techniques~\cite{DBLP:journals/siamcomp/ManberM93,10.1145/1082036.1082039,grossi2005compressed,10.1145/3375890}; and (ii) \textit{any} locally consistent sampling mechanism, $\Sketch$, such as minimizers~\cite{DBLP:journals/bioinformatics/RobertsHHMY04,DBLP:conf/sigmod/SchleimerWA03}, syncmers~\cite{Syncmers}, or bd-anchors~\cite{DBLP:journals/tkde/LoukidesPS23},
can be used to sketch $S$ and $P$ making the method adaptable to a variety of sampling techniques.
We also expect that our framework, which relies on $\INDEX(S)$, has competitive queries compared to the ones of $\INDEX(T)$ or possibly faster when the query time of $\INDEX(T)$ is a function of $n=|T|$. This is merely because $|S|<|T|$ (in practice, depending on the sketching mechanism used, $|S|$ could be $\Theta(|T|/\ell)$ or $\Theta(|T|/(\ell-k))$ for some $k=o(\ell)$). A typical such case is when $\INDEX$ is the suffix array~\cite{DBLP:journals/siamcomp/ManberM93} and binary search will take place on a \emph{smaller array}, i.e., the suffix array of $S$.
%\rob{I think we should draw a relation here with other work in this space (I've added more in the related work section below.  However, one of the beautiful ideas in this work is that we are applying (essentially) standard indexing approaches after transforming the text into a new space (i.e. ``sketch space'').  This means that one can use many different types of sketches, each with their own sets of potential strengths or weaknesses, and so the door is open not only to the whole panoply of different indexing data structures, but to a whole suite of potential instantiations of the $\Sketch(\cdot)$ function, like minimizers, strobmers, syncmers, prefix-free-parses, etc.}
%\giulio{I very much agree with Rob. Indeed, we can expand a little bit the above piece about the ``universality'' by saying that we have two important degrees of freedom: not only the choice of the index but also the choice of the sketching algorithm. (In this work, we focus on minimizers for simplicity.)}

We explore both the theoretical underpinnings and the practical implementation
of this universal framework.
We demonstrate that universal indexes can be constructed significantly faster
and occupy a fraction of the space compared to their unsketched counterparts.
These space savings are a direct consequence of operating in the reduced
``sketch space''. Depending on the index used, the performance of pattern
matching in sketched space can be either faster (suffix array) or slower
(FM-index). In either case the overall query performance is slightly slower
though, due to a relatively large number of false positive matches that have to
be rejected.
This verification step can be performed in constant time
per occurrence (in theory) or via cache-friendly scans of the original
text (in practice).

%\red{This work shows that the trade-offs traditionally seen in pattern matching between space and time efficiency can be mitigated through the use of sketched representations.}
%\giulio{What do we exactly mean with this? That a suboptimal index, say, the SA, in sketch space is competitive now to an FM-index? Should expand a little bit with an example, or drop.}

%\ragnar{Mention something similar to theorem 1 below? Or otherwise some
%  experimental results?}

\return
In short, the \emph{main message} of our paper is the following:
If we have a sufficiently large lower bound $\ell$ (e.g., 32 or more), then our universal scheme typically offers substantial improvements over any text index in construction time, construction space, and index size, while supporting competitive query times.

\parag{Paper Organization} 
In \cref{sec:background}, we provide the necessary notation and tools.
In \cref{sec:related}, we provide an overview of previous related work.
In \cref{sec:framework}, we present our framework, and
in \cref{sec:experiments}, we present our experimental evaluation.
We conclude this paper in \cref{sec:conclusions}.
