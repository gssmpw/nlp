\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
% \usepackage{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
    % \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
    \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}


\usepackage[utf8]{inputenc} % allow utf-8 input3
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

%%%%%%%%%%%%%%%%%%%% Added package%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{makecell}
\usepackage{algorithm,algorithmic}
\usepackage{paralist,amsmath, amssymb,bm}
\usepackage{multirow}
\usepackage{ntheorem}
\newtheorem{thm}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem*{proof}{Proof}
\newtheorem{cor}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{asm}{Assumption}
\usepackage{enumitem}
\usepackage{textcase}
\usepackage{booktabs}
\usepackage{fancybox}
\usepackage{mathtools}

%%%% mathcal
\def \S {\mathbf{S}}
\def \L {\mathcal{L}}
\def \A {\mathcal{A}}
\def \X {\mathcal{X}}
\def \O {\mathcal{O}}
\def \Y {\mathcal{Y}}
\def \Ab {\bar{\A}}
\def \R {\mathbb{R}}
\def \Kt {\widetilde{K}}
\def \k {\mathbf{k}}
\def \w {\mathbf{w}}
\def \v {\mathbf{v}}
\def \t {\mathbf{t}}
\def \x {\mathbf{x}}
\def \Se {\mathcal{S}}
\def \E {\mathrm{E}}
\def \Rh {\widehat{R}}
\def \x {\mathbf{x}}
\def \p {\mathbf{p}}
\def \a {\mathbf{a}}
\def \diag {\mbox{diag}}
\def \b {\mathbf{b}}
\def \e {\mathbf{e}}
\def \ba {\boldsymbol{\alpha}}
\def \c {\mathbf{c}}
\def \tr {\mbox{tr}}
\def \d {\mathbf{d}}
\def \db {\bar\mathbf{d}}
\def \1 {\mathbf{1}}

\def \z {\mathbf{z}}
\def \s {\mathbf{s}}
\def \bh {\widehat{\b}}
\def \y {\mathbf{y}}
\def \u {\mathbf{u}}
\def \uh {\widehat{\u}}
\def \H {\mathcal{H}}
\def \g {\mathbf{g}}
\def \F {\mathcal{F}}
\def \I {\mathbb{I}}
\def \P {\mathcal{P}}
\def \Q {\mathcal{Q}}
\def \xh {\widehat{\x}}
\def \wh {\widehat{\w}}
\def \lambdah {\widehat{\lambda}}

\def \ah {\widehat{\a}}
\def \Rc {\mathcal R}
\def \Sigmah {\widehat\Sigma}

\def \Bh {\widehat B}
\def \Ah {\widehat A}
\def \Uh {\widehat U}
\def \Ut {\widetilde U}
\def \B {\mathcalB}
\def \C {\mathbf C}
\def \U {\mathbf U}
\def \Kh {\widehat K}
\def \fh {\widehat f}
\def \yh {\widehat\y}
\def \Xh {\widehat{X}}
\def \Fh {\widehat{F}}

\def \m {\mathbf{m}}
\def \y {\mathbf{y}}
\def \E {\mathrm{E}}
\def \x {\mathbf{x}}
\def \g {\nabla{g}}
\def \D {\mathcal{D}}
\def \z {\mathbf{z}}
\def \u {\mathbf{u}}
\def \H {\mathcal{H}}
\def \Z {\mathcal{Z}}
\def \Pc {\mathcal{P}}
\def \w {\mathbf{w}}
\def \s {\mathbf{s}}
\def \r {\mathbf{r}}
\def \R {\mathbb{R}}
\def \S {\mathcal{S}}
\def \regret {\mbox{regret}}
\def \Uh {\widehat{U}}
\def \Q {\mathcal{Q}}
\def \W {\mathcal{W}}
\def \N {\mathcal{N}}
\def \A {\mathcal{A}}
\def \q {\mathbf{q}}
\def \v {\mathbf{v}}
\def \M {\mathcal{M}}
\def \c {\mathbf{c}}
\def \ph {\widehat{p}}
\def \d {\mathbf{d}}
\def \p {\mathbf{p}}
\def \q {\mathbf{q}}
\def \db {\bar{\d}}
\def \dbb {\bar{d}}

\def \I {\mathbb{I}}
\def \xt {\widetilde{\x}}
\def \yt {\widetilde{\y}}
\def \hrho {\hat{\rho}}

\def \f {\mathbf{f}}
\def \a {\mathbf{a}}
\def \b {\mathbf{b}}
\def \ft {\widetilde{\f}}
\def \bt {\widetilde{\b}}
\def \h {\mathbf{h}}
\def \B {\mathcal{B}}
\def \bts {\widetilde{b}}
\def \fts {\widetilde{f}}
\def \Gh {\widehat{G}}
\def \G {\mathcal {G}}
\def \bh {\widehat{b}}
\def \wh {\widehat{\w}}
\def \Dth {\widehat{\Delta}}
\def \vb {\bar{\mathbf v}}
\def \zt {\widetilde{\z}}
\def \zh {\widehat{\z}}
\def \zts {\widetilde{z}}
\def \s {\mathbf{s}}
\def \gh {\widehat{\g}}
\def \vh {\widehat{\v}}
\def \Sh {\widehat{S}}
\def \rhoh {\widehat{\rho}}
\def \hh {\widehat{\h}}
\def \C {\mathcal{C}}
\def \V {\mathcal{L}}
\def \t {\mathbf{t}}
\def \xh {\widehat{\x}}
\def \Ut {\widetilde{U}}
\def \wt {\m}
\def \Th {\widehat{T}}
\def \Ot {\tilde{\mathcal{O}}}
\def \X {\mathcal{X}}
\def \nb {\widehat{\nabla}}
\def \K {\mathcal{K}}
\def \P {\mathbb{P}}
\def \T {\mathcal{T}}
\def \F {\mathcal{F}}
\def \ft{\widetilde{f}}
\def \Rt {\mathcal{R}}
\def \Rb {\bar{\Rt}}
\def \wb {\bar{\w}}
\def \zu {\underline{\z}}
\def \vect {\text{vec}}
\def \E {\mathbb{E}}
\def \bftau {\boldsymbol{\tau}}
\def\Tau{{\rm T}}
\def\bw{\mathbf{w}}
\def \start {\textsc{Start}}

\newcommand{\pp}{p(\y | \x)}

\usepackage{comment}

\usepackage{tcolorbox}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\tcbuselibrary{minted,breakable,xparse,skins}

\definecolor{bg}{gray}{0.95}
\DeclareTCBListing{mintedbox}{O{}m!O{}}{%
  breakable=true,
  listing engine=minted,
  listing only,
  minted language=#2,
  minted style=default,
  minted options={%
    linenos,
    gobble=0,
    breaklines=true,
    breakafter=,,
    fontsize=\small,
    numbersep=8pt,
    #1},
  boxsep=0pt,
  left skip=0pt,
  right skip=0pt,
  left=25pt,
  right=0pt,
  top=3pt,
  bottom=3pt,
  arc=5pt,
  leftrule=0pt,
  rightrule=0pt,
  bottomrule=2pt,
  toprule=2pt,
  colback=bg,
  colframe=orange!70,
  enhanced,
  overlay={%
    \begin{tcbclipinterior}
    \fill[orange!20!white] (frame.south west) rectangle ([xshift=20pt]frame.north west);
    \end{tcbclipinterior}},
  #3}

\title{ \textsc{Fox}: Finetuning Generative Language Models with A Discriminative Approach}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Tianbao Yang \\
  % Department of Computer Science and Engineering \\
  Texas A\&M University \\
   College Station, USA \\
  \texttt{tianbao-yang@tamu.edu} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\usepackage{changepage}

\begin{document}


\maketitle
\begin{abstract}
    In this draft, we describe a new approach for finetuning generative large language models. State-of-the-art approaches for finetuning LLMs use the same loss function as pretraining, which is the negative log-likelihood of output texts given the input prompts defined by a generative model. A question remains {\it how to train the generative model with a discriminative approach?} The benefit of using a discriminative approach is that it directly model the negative data in the objective, which not only pushes the likelihood of positive data to to be large but also pushes the likelihood of negative data to be small. It could bring us several benefits including (i) faster convergence than maximizing the likelihood of positive data only; (ii) mitigates the burden or completely removes the process of collecting human preference data for alignment. 
\end{abstract}

\section{Introduction}
We first discuss the softmax loss for LLMs. Let $\x=(t_1, \ldots, t_{m})$ denote an example with a sequence of tokens, where $t_j\in\mathcal V=\{v_1, \ldots, v_K\}$ denotes a token from a vocabulary of size $K$.  The probability of $\x$ is modeled by $p(\x) = \prod_{j=1}^{m}p(t_j|t_{1}, \ldots, t_{j-1})$. Modern LLMs are trained by using a softmax function to model the probability of $p(t_j|t_1,\ldots, t_{j-1})$, i.e., 
\begin{align*}
p_g(t_j|t_1,\ldots, t_{j-1}) = \frac{\exp(h(\w; t_1, \ldots, t_{j-1})^{\top}W_{t_j})}{\sum_{k=1}^K\exp(h(\w; t_1, \ldots, t_{j-1})^{\top}W_{k})},
\end{align*}
where $W_1,\ldots, W_K$ denotes the token embedding vectors of that in $\mathcal V$, $h(\w;  t_1, \ldots, t_{j-1})$ denotes the representation of the input sequence of tokens produced by a transformer network parameterized by $\w$. We abuse the notation $W_{t_j}$ to denote the embedding vector of the token $t_j$.  The parameters $\Theta=(\w, W)$ are learned by minimizing the negative log-likelihood over a set of data $\D=\{\x_1, \ldots, \x_n\}$ with $\x_i = (t^i_1, \ldots, t^i_{m_i})$:
\begin{align}\label{eqn:llm}
\hspace*{-0.1in}\min_{\Theta}-\frac{1}{n}\sum_{i=1}^n[\log p_g(\x_i):=\sum_{j=1}^{m_i}\log p_g(t^i_{j}|t^i_{1}, \ldots, t^i_{j-1})].
\end{align}
%To the best of our knowledge, the temperature-scaled softmax loss has not been used in training LLMs. We will introduce our approach in next section.  

\section{A Discriminative Approach}
For finetuning, we are given with a set of data $\D=\{(\x_i, \y_i), i=1, \ldots\}$, where $\x_i$ is an input prompt and $\y_i$ is an output answer. We will discuss how to collect such data later. A standard approach of finetuning is to minimize the negative loglikelihood of $\y_i$ given $\x_i$ under the generative model, i.e., $-\log p_g(\y_i|\x_i)= - \sum_{j=1}^m\log p_g(y^i_j|\x_i, y^i_{1:j-1})$. Thus the objective of the generative approach is 
\begin{align}
\min_{\w} -\frac{1}{n}\sum_{i=1}^n \log p_g(\y_i|\x_i)
\end{align}

In this section, we present a discriminative approach. The idea originates from ``predicting an instance given another instance of our unified statistical X-risk framework". In particular, we model the following probability $\Pr(\y|\x)$. Instead of using a generative approach to define this probability, we use a discriminative approach. To this end, we introduce a parameterized scoring function $s(\y, \x)\in\R$, which measures the fitness score of $\y$ given $\x$. Then we define the following probability 
\begin{align}
\Pr(\y|\x) = \frac{\exp(s(\y, \x)/\tau)}{\sum_{\y\in\Y}\exp(s(\y, \x)/\tau)}
\end{align}
where $\Y$ denotes the space of all possible texts. As a result, we define the following objective function: 
\begin{align*}
\min -\frac{1}{n}\sum_{i=1}^n\tau\Pr(\y_i|\x_i) : = -\frac{1}{n}\sum_{i=1}^n s(\y_i, \x_i) + \tau \frac{1}{n}\sum_{i=1}^n\log \bigg(\sum_{\y\in\Y}\exp(s(\y, \x_i)/\tau)\bigg)
\end{align*}
The next question is how to define $s(\y_i, \x_i)$. A traditional approach is to learn a representation of $\y$ and a representation of $\x_i$ by a deep neural network and use their similarity to define the score. However, this approach makes it difficult to generate $\y$ given $\x$. To avoid this issue, we use the generative approach to define a fitness score, i.e., $s(\y, \x) = \log p_g(\y|\x)$.  This score is also known as the perplexity score. As a result, the objective becomes 
\begin{align}\label{eqn:dis}
\min_{\w} -\frac{1}{n}\sum_{i=1}^n \log p_g(\y_i|\x_i) + \tau \frac{1}{n}\sum_{i=1}^n\log \bigg(\sum_{\y\in\Y}\exp(\log p_g(\y|\x_i)/\tau)\bigg)
\end{align}
where $\w$ is the parameter of the LLM $p_g(\y|\x)$. We can see that the first term is exactly the same as the generative approach. The difference lies in the second term that models the negative data of $\x_i$, trying to push their perplexity scores to be small. 

\section{Optimization}
One challenge of implementing the discriminative approach is how to solve the optimization problem in~(\ref{eqn:dis}), especially how to deal with the second term where $\Y$ contains all possible texts. To tackle this, our empirical X-risk minimization provides a framework for solving it. To this end, we introduce a base LLMs $p^0_g(\y|\x)$, which can be set as the pretrained LLM. Then we write the second term as 
\begin{align}
 \tau\log \bigg(\sum_{\y\in\Y}\exp(\log p_g(\y|\x_i)/\tau)\bigg) = % \tau\log \bigg(\sum_{\y\in\Y}p^0_g(\y|\x)\frac{p_g(\y|\x_i)^{1/\tau}}{p^0_g(\y|\x)}\bigg) =
 \tau \log \bigg(\E_{\y\sim p^0_g(\y|\x_i)}\frac{p_g(\y|\x_i)^{1/\tau}}{p^0_g(\y|\x_i)}\bigg)
\end{align}
The objective becomes: 

\begin{align}\label{eqn:dis2}
\min_{\w} -\frac{1}{n}\sum_{i=1}^n \log p_g(\y_i|\x_i) +  \frac{1}{n}\sum_{i=1}^n  \tau \log \bigg(\E_{\y\sim p^0_g(\y|\x_i)}\frac{p_g(\y|\x_i)^{1/\tau}}{p^0_g(\y|\x_i)}\bigg)
\end{align}


Then we can deal with the second term like SogCLR. We present the algorithm below. 

\begin{algorithm}[ht]
\caption{LLM-X}
\label{alg:ALEXR}
\begin{algorithmic}[1] 
\STATE Initialize $\w, \u$
\FOR{$t=0,1,\dotsc,T-1$}
\STATE Sample a batch $\S_t\subset \{1,\dotsc,n\}$, $|\S_t| = S$ \label{lst:line:dual_start}
\FOR{each $\x_i\in\S_t$} 
\STATE Sample size-$B$ mini-batches $\B_t^{(i)}$ from $p^0(\y|\x_i)$
\STATE Update $u_{t+1}^{(i)} = (1-\gamma)u^t_i + \gamma \frac{1}{B}\sum_{\y\in\B_t^i}\frac{p^t_g(\y|\x_i)^{1/\tau}}{p^0(\y|\x_i)}$
\ENDFOR
\STATE Compute  $G_t =\frac{1}{S}\sum_{i\in\S_t} -\frac{\nabla p_g^t(\y_i|\x_i)}{p_g^t(\y_i|\x_i)}  + \frac{1}{S}\sum_{i\in\S_t} \frac{1}{Bu_{t+1}^i}\sum_{\y\in\B_t^i}\frac{p^t_g(\y|\x_i)^{1/\tau-1}\nabla p^t_g(\y|\x_i)}{p^0(\y|\x_i)}$  \label{lst:line:primal_start}
\STATE Update $\m_{t+1}= \beta_1\m_t + (1-\beta_1) G_t$
\STATE Update $\w_{t+1}$ using Adam-W
\ENDFOR
\end{algorithmic}
\end{algorithm}

\section{DFT v2: A Computationally Efficient Approach}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.5\textwidth]{figs/logpHistogram.pdf}
%     \caption{Mistral 7b}
%     \label{fig:1}
% \end{figure}

One drawback of using Eq.~\eqref{eq:dftv1_final} as the objective is the extra cost of computing $p_g^0(\y|\x_i)$ at each forward step during training. In practice, we find that the denominator in \eqref{eq:prob} is dominated by those $\y$ sampled from the reference LLM $p_g^0$. Hence, we can rewrite the \eqref{eq:prob} into

\begin{align}\label{eq:prob2}
\Pr(\y|\x) = \frac{\exp(s(\y, \x)/\tau)}{\E_{\y\sim p^0_g(\y|\x)}\exp(s(\y, \x)/\tau)}.
\end{align}


% To imitate the overhead, we propose a new objective.
% \begin{align*}
% \min_{\w} \E_{\x,\y,\y'\sim p_g^0(\cdot|\x)} \left[l(s(\x,\y) - s(\x,\y'))\right]
% \end{align*}
% where $l(\cdot)$ is a loss function that is both monotonically decreasing and convex. Here, we use a linear function $l(x) = -x$. 
% \begin{align}
% \min_{\w} -\frac{1}{n}\sum_{i=1}^n s(\x_i, \y_i) + \frac{1}{n}\sum_{i=1}^n\E_{\y' \sim p^0_g(\y|\x_i)} s(\x_i, \y')
% \end{align}
Given a dataset $\D=\{(\x_i, \y_i)\}_{i=1}^n$, we construct synthetic responses $\Y_i=\{\y_{ij}'\}_{j=1}^m$ for each prompt $\x_i$. The objective will be
% \begin{align}
% \min_{\w} -\frac{1}{n}\sum_{i=1}^n s(\x_i,\y_i) + \frac{1}{n}\sum_{i=1}^n \frac{1}{m}\sum_{j=1}^m s(\x_i, \y_{ij}')
% \end{align}
% We consider applying distributionally robust optimization (DRO) for the second term:
% \begin{align}\label{eq:dftv2}
% & \min_{\w} -\frac{1}{n}\sum_{i=1}^n s(\x_i, \y_i) \\ 
% & + \frac{1}{n}\sum_{i=1}^n \max_{\boldsymbol{\pi}_i \in \Delta_m}\left\{\sum_{j=1}^m \boldsymbol{\pi}_i^{(j)} s(\x_i, \y_{ij}') - \tau D_\mathrm{KL}\left(\boldsymbol{\pi}_i \vert\vert \mathbf{1}/m\right) \right\}
% \end{align}
% where $\Delta_m\subset\R^m$ is the probability simplex and $\mathbf{1}/m$ represents the uniform distribution on $\Y_i$. Due to the KKT condition, the DRO problem in \eqref{eq:dftv2} is equivalent to 
\begin{align}\label{eq:dftv2}
\min_{\w} - & \frac{1}{n}\sum_{i=1}^n s(\y_i, \x_i) \nonumber\\ 
 + & \frac{1}{n}\sum_{i=1}^n \tau \log \left(\sum_{j=1}^m \exp\left(s(\y_{ij}', \x_i) / \tau \right) \right).
\end{align}
% \ilgee{$s(\x_i,\y_i)->s(\y_i,\x_i)$ for consistency?}

\subsection{Odds-based FOX}

Given the observation that the loss seems to be dominated by the negatives, we hypothesize this is partly caused by the use of the logarithm, which has a steeper derivative for the negatives than the positives. 

A possible fix is using log odds instead of log probabilities to define the similarity. That is, the similarity is defined as
\begin{equation*}
    s(\y, \x) = \log \frac{p_g(\y | \x)}{1 - p_g(\y | \x)}
\end{equation*}
Note log probabilities are in the range $(-\infty, 0]$, while log odds are in the range $(-\infty, \infty)$.

Therefore, we obtain the following objective function:
\begin{align}
&\min_{\w} -\frac{1}{n}\sum_{i=1}^n \log \frac{p_g(\y_i|\x_i)}{1 - p_g(\y_i|\x_i)} + \tau \frac{1}{n}\sum_{i=1}^n\log \bigg(\sum_{\y\in\Y}\exp(\log \frac{p_g(\y|\x_i)}{1-p_g(\y_i|\x_i)}/\tau)\bigg) \\
&\min_{\w} -\frac{1}{n}\sum_{i=1}^n \log{p_g(\y_i|\x_i)} - \log({1 - p_g(\y_i|\x_i)}) + \tau \frac{1}{n}\sum_{i=1}^n\log \bigg( \E_{\y \sim p^0_g(\y|\x_i)} \frac{1}{p^0_g(\y|\x_i)} {\left(\frac{p_g(\y|\x_i)}{1-p_g(\y|\x_i)} \right)}^{1/\tau} \bigg)
\end{align}
Then,
\begin{align*}
    g(\y, \x) &= \frac{1}{p^0_g(\y|\x_i)} {\left(\frac{p_g(\y|\x_i)}{1-p_g(\y|\x_i)} \right)}^{1/\tau} \\
    &= \exp{\left(\frac{1}{\tau} \big(\log p_g(\y|\x_i) - \log{(1 - p_g(\y|\x_i))}\big)  - \log p^0_g(\y|\x_i)\right)} \\
    \nabla g(\y, \x) &= \frac{1}{p^0_g(\y|\x_i)} \frac{1}{\tau} {\left(\frac{p_g(\y|\x_i)}{1-p_g(\y|\x_i)} \right)}^{1/\tau - 1} \frac{\nabla p_g(\y|\x_i)}{(1-p_g(\y|\x_i)) ^ 2} \\
    &= \frac{1}{p^0_g(\y|\x_i)} \frac{1}{\tau} {\left(\frac{p_g(\y|\x_i)}{1-p_g(\y|\x_i)} \right)}^{1/\tau} \frac{1 - p_g(\y|\x_i)}{p_g(\y|\x_i)} \frac{\nabla p_g(\y|\x_i)}{(1-p_g(\y|\x_i)) ^ 2} \\
    &= \frac{1}{p^0_g(\y|\x_i)} \frac{1}{\tau} {\left(\frac{p_g(\y|\x_i)}{1-p_g(\y|\x_i)} \right)}^{1/\tau} \frac{\nabla \log p_g(\y|\x_i)}{1-p_g(\y|\x_i)} \\
    &= \frac{1}{\tau} \exp{(\frac{1}{\tau} \log p_g(\y|\x_i) - (\frac{1}{\tau} + 1) \log{(1-p_g(\y|\x_i))} - \log p^0_g(\y|\x_i))} \nabla \log p_g(\y|\x_i) \\
\end{align*}
Algorithm \ref{alg:fox-odds} presents the algorithm.

\begin{algorithm}[ht]
\caption{FOX-odds}
\label{alg:fox-odds}
\begin{algorithmic}[1] 
\STATE Initialize $\w, \u$
\FOR{$t=0,1,\dotsc,T-1$}
\STATE Sample a batch $\S_t\subset \{1,\dotsc,n\}$, $|\S_t| = S$
\FOR{each $\x_i\in\S_t$} 
\STATE Sample size-$B$ mini-batches $\B_t^{(i)}$ from $p^0(\y|\x_i)$
\STATE For each $\y \in \B_t^{(i)}$, compute $a_{\x_i, \y} = \log p^t_g(\y|\x_i)$, $b_{\x_i, \y} = \log (1-p^t_g(\y|\x_i))$, $r_{\x_i, \y} = \log p^0(\y | \x_i)$, and $d_{\x_i, \y} = \frac{1}{\tau} (a_{\x_i, \y} - b_{\x_i, \y}) - r_{\x_i, \y}$
\STATE Update $u_{t+1}^{(i)} = (1-\gamma)u_t^{(i)} + \gamma \frac{1}{B}\sum_{\y\in\B_t^{(i)}} \exp{d_{\x_i, \y}}$ (detach gradient)
\STATE Compute $w_{\x_i,\y} = \exp{(d_{\x_i,\y} - b_{\x_i,\y})}$ (detach gradient)
\ENDFOR
\STATE Compute $L_t =\frac{1}{S} \sum_{i\in\S_t} \left( -\log p_g^t(\y_i | \x_i) + \log \big(1-p_g^t(\y_i | \x_i)\big)  + \frac{1}{B(u_{t+1}^{(i)} + \epsilon)} \sum_{\y\in\B_t^{(i)}} w_{\x_i,\y} \log p_g^t(\y | \x_i) \right)$
\STATE Compute $G_t = \nabla L_t$
\STATE Update $\w_{t+1}$ using Adam-W
\ENDFOR
\end{algorithmic}
\end{algorithm}

\subsubsection{Connection to DRO}
Given the following loss
\begin{align}\nonumber
\phi(\w;\x,\y,\y') = - \log \left( \left(\frac{1}{p_{\w_0}(\y\mid \x)}\right)^{\tau} \frac{p_\w(\y\mid \x)}{1-p_\w(\y\mid \x)} \right) + \log \left(\left(\frac{1}{p_{\w_0}(\y'\mid \x)}\right)^{\tau} \frac{p_\w(\y'\mid \x)}{1-p_\w(\y'\mid \x)} \right)
\end{align}
Let $q(\y\mid\x) = \frac{p(\y\mid \x)}{1-p(\y\mid \x)}$, then the DRO problem can be formulated as
\begin{align*}
&\min_\w \frac{1}{n}\sum_{i=1}^n \tau \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\phi(\w;\x_i,\y_i,\y_{ij}')/\tau\right)\right) \\
& \min_\w \frac{1}{n}\sum_{i=1}^n \tau \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\frac{-1}{\tau} \log \left(\frac{q_\w(\y\mid \x)}{p^{\tau}_{\w_0}(\y\mid \x)} \right) + \frac{1}{\tau} \log \left(\frac{q_\w(\y'\mid \x)}{p^{\tau}_{\w_0}(\y'\mid \x)} \right)\right)\right) \\
& \min_\w \frac{1}{n}\sum_{i=1}^n \tau \log \left[ \exp\left(\frac{-1}{\tau} \log \left(\frac{q_\w(\y\mid \x)}{p^{\tau}_{\w_0}(\y\mid \x)} \right)\right) \left(\frac{1}{m}\sum_{j=1}^m \exp \left( \frac{1}{\tau} \log \left(\frac{q_\w(\y'\mid \x)}{p^{\tau}_{\w_0}(\y'\mid \x)} \right)\right)\right)\right] \\
& \min_\w \frac{1}{n}\sum_{i=1}^n - \log \left(\frac{q_\w(\y\mid \x)}{p^{\tau}_{\w_0}(\y\mid \x)} \right) + \tau \log \left( \frac{1}{m}\sum_{j=1}^m \frac{\left(q_\w(\y'\mid \x)\right)^{\frac{1}{\tau}}}{p_{\w_0}(\y'\mid \x)} \right) \\
& \min_\w \frac{1}{n}\sum_{i=1}^n - \log q_\w(\y\mid \x) + \tau \log \left( \frac{1}{m}\sum_{j=1}^m \frac{\left(q_\w(\y'\mid \x)\right)^{\frac{1}{\tau}}}{p_{\w_0}(\y'\mid \x)} \right)
\end{align*}
This is equivalent to the probabilistic formulation.

Note that the connection between the reference model in the DRO and the probabilistic is $p_{\w_0} = (p_g^0)^{\tau}$. Thus, using a higher/lower $\tau$ in the probabilistic is equivalent to using a sharper/more uniform reference model in the DRO framework. Thus, higher $\tau$ emphasizes more \textit{hard negatives}.


\section{Dataset}
For the training dataset, we need to collect the instruction tuning dataset. The dataset for training open-sourced LLMs is usually mysterious. Earlier papers like FLAN collect large instruction-tuning datasets from different domains. Recent papers (e.g. SPIN) have used some chat-style instruction following datasets, e.g., UltraChat200k. Mistral paper mentions instruction datasets publicly available on the HuggingFace repository \url{https://huggingface.co/HuggingFaceH4}. We should go over these datasets and curate on that is suitable for our needs. On the one hand, our resources should be able to handle it. On the other hand, we can compare with existing approaches. UtraChat200k would be a good starting point so that we can compare with SPIN. 

databricks-dolly-15k dataset (human demonstration data). \url{https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm}. 

The initial team members include, Siqi, Vicente, and Bokun. 

My thinking is to conduct the following experiments. 

\begin{itemize}
\item Exp. 1: Use Alpaca 52k instruction following dataset to finetune LLaMa-7b and compare with Alpaca-7b. 
\item Exp. 2: Use 15K databricks-dolly-15k dataset to finetune Pythia-6.9b and compare with Dolly v2.  
\item Exp. 2: Use Ultrachat-200k chat-style dataset to finetune LLaMa2-7b and compare with SPIN.  
\item Exp. 3: Use a comphreshensive dataset includign Ultrachat-200k, Alpaca-52k, adversrial data to finetune LLaMa2-7b and Mistral-7b and compare with LLaMa2-7b-chat and Mistral-7b-instruct. 
\end{itemize}
%Siqi will implement the code. Vicente will be in charge of baseline. Zihao will be in charge of datsets and Bokun will explore some theoretical aspects. 

\section{Generating negative samples}

Through the experiments, we find the generation hyper-parameters can impact the value of $\log p_g^0(\y|\x)$ and $\frac{1}{|\y|} \log p_g^0(\y|\x)$. 

Potential hyper-parameters are:
\begin{enumerate}
    \item Temperature $\uparrow$, $\frac{1}{|\y|} \log p_g^0(\y|\x)$ $\downarrow$. 
    \item Top\_k $\uparrow$, $\frac{1}{|\y|} \log p_g^0(\y|\x)$ $\downarrow$.
    \item Top\_p $\uparrow$, $\frac{1}{|\y|} \log p_g^0(\y|\x)$ $\downarrow$.
    \item Max\_seq\_length $\uparrow$, $\log p_g^0(\y|\x)$ $\downarrow$.
\end{enumerate}


We cannot reproduce SPIN's results on vllm-generated data because vllm uses a default top\_k value of $\infty$, which is larger than huggingface's default value of $50$.

We also consider different generating prompts:
\begin{enumerate}
    \item Apply chat template with empty system message.
    \item Apply chat template with bad system message.
    \item Simply use "Question: Answer:" formatting prompts.
    \item No special change.
\end{enumerate}


\section{DRO Framework}

\subsection{Single Tuned Temperature}

We consider the following (penalized) distributionally robust optimization (DRO) problem under some conditions.
\begin{align}\nonumber
& \min_\w \frac{1}{n}\sum_{i=1}^n \hat{L}(\w;\x_i,\y_i),\quad \hat{L}(\w;\x_i,\y_i) \coloneqq  \max_{\boldsymbol{\pi}_i\in\Delta_m} \left\{\sum_{j=1}^m \boldsymbol{\pi}_i^{(j)} \phi(\w;\x_i,\y_i,\y_{ij}') - \tau D_\mathrm{KL}\left(\boldsymbol{\pi}_i\vert\vert \mathbf{1}/m\right)\right\},\\\label{eq:dro}
& \phi(\w;\x,\y,\y') = \ell\left(\lambda \log\frac{p_\w(\y\mid \x)}{p_{\w_0}(\y\mid \x)} - \lambda \log\frac{p_\w(\y'\mid \x)}{p_{\w_0}(\y'\mid \x)}\right),
\end{align}
where $\ell(\cdot) = \log(1+\exp(-\cdot))$, $\Delta_m\subset\R^m$ is the probability simplex and $\mathbf{1}/m$ represents the uniform distribution on $\S_i$. Due to the KKT condition, the DRO problem in \eqref{eq:dro} is equivalent to 
\begin{align}\label{eq:dro_equiv}
\min_\w \frac{1}{n}\sum_{i=1}^n \tau \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\phi(\w;\x_i,\y_i,\y_{ij}')/\tau\right)\right).
\end{align}

When $\tau \rightarrow \infty$, \eqref{eq:dro_equiv} is equivalent to the SPIN loss (with $m$ negative responses):
\begin{align*}
\min_\w \frac{1}{n}\sum_{i=1}^n\left(\frac{1}{m}\sum_{j=1}^m \phi(\w;\x_i,\y_i,\y_{ij}')\right).
\end{align*}

\begin{algorithm}[ht]
\caption{\textsc{Fox-DRO}}
\label{alg:fox_dro}
\begin{algorithmic}[1] 
\STATE Initialize $\w, \u$
\FOR{$t=0,1,\dotsc,T-1$}
\STATE Sample a batch $\S_t\subset \{1,\dotsc,n\}$, $|\S_t| = S$ \label{lst:line:dual_start}
\FOR{each $\x_i\in\S_t$} 
\STATE Sample size-$B$ mini-batches $\B_t^{(i)}$ from $p_{\w_0}(\y|\x_i)$
\STATE For each $\y' \in \B_t^{(i)}$, compute $g_t^{(i)} = \frac{1}{B}\sum_{\y'\in\B_t^{(i)}} \exp\left(\frac{\phi(\w;\x_i,\y_i,\y')}{\tau}\right)$
\STATE Update $\u_{t+1}^{(i)} = (1-\gamma)\u_t^{(i)} + \gamma g_t^{(i)}$
\ENDFOR
\STATE Compute $\nabla_\w =\frac{1}{S}\sum_{i\in\S_t} \frac{1}{\u_{t+1}^{(i)} + \epsilon} \frac{1}{B}\sum_{\y'\in\B_t^{(i)}} \exp\left(\frac{\phi(\w;\x_i,\y_i,\y')}{\tau}\right) \nabla_\w \phi(\w;\x_i,\y_i,\y')$  
\STATE Update $\w_{t+1}$ with $\nabla_\w$ using Adam-W
\ENDFOR
\end{algorithmic}
\end{algorithm}

\subsection{Individualized Temperatures}

Note that a single temperature $\tau$ might not suit all data (evidence?). Next, we consider an individualized temperature $\boldsymbol{\tau}^{(i)}$ for each prompt-response pair $(\x_i,\y_i)$. Instead of a pre-determined/tuned $\tau$ for all data in \eqref{eq:dro} and \eqref{eq:dro_equiv}, we automatically learn $\boldsymbol{\tau}^{(i)}$ via the constrained DRO framework below.
\begin{align}\label{eq:cdro}
\min_\w \frac{1}{n}\sum_{i=1}^n \hat{L}(\w;\x_i,\y_i),\quad \hat{L}(\w;\x_i,\y_i)  \coloneqq  \max_{\boldsymbol{\pi}_i\in\Delta_m} \left\{\sum_{j=1}^m \boldsymbol{\pi}_i^{(j)} \phi(\w;\x_i,\y_i,\y_{ij}'): D_{\mathrm{KL}}(\boldsymbol{\pi}_i\vert\vert\mathbf{1}/m)\leq \rho\right\},
\end{align}
where the definition of $\phi(\w;\x_i,\y_i,\y_{ij}')$ is the same as that in \eqref{eq:dro}. In practice, we also add a regularization term $-\tau_0 D_\mathrm{KL}\left(\boldsymbol{\pi}_i\vert\vert \mathbf{1}/m\right)$ to the loss $\sum_{j=1}^m \boldsymbol{\pi}_i^{(j)} \phi(\w;\x_i,\y_i,\y_{ij}')$ to make the loss function smoother. By the Lagrangian duality, the problem in \eqref{eq:cdro} is equivalent to
\begin{align}\label{eq:ifox_logsumexp}
\min_{\w, \boldsymbol{\tau}\geq \tau_0} \frac{1}{n}\sum_{i=1}^n \left\{\boldsymbol{\tau}^{(i)} \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\phi(\w;\x_i,\y_i,\y_{ij}')/\boldsymbol{\tau}^{(i)}\right)\right) + \boldsymbol{\tau}^{(i)}\rho\right\}
\end{align}

\begin{algorithm}[ht]
\caption{\textsc{iFox-DRO}}
\label{alg:ifox_dro}
\begin{algorithmic}[1] 
\STATE Initialize $\w, \u, \boldsymbol{\tau},\m$
\FOR{$t=0,1,\dotsc,T-1$}
\STATE Sample a batch $\S_t\subset \{1,\dotsc,n\}$, $|\S_t| = S$ \label{lst:line:dual_start}
\FOR{each $\x_i\in\S_t$} 
\STATE Sample size-$B$ mini-batches $\B_t^{(i)}$ from $p_{\w_0}(\y|\x_i)$
\STATE For each $\y \in \B_t^{(i)}$, compute $g_t^{(i)} = \frac{1}{B}\sum_{\y'\in\B_t^{(i)}} \exp\left(\frac{\phi(\w;\x_i,\y_i,\y')}{\tau}\right)$
\STATE Update $\u_{t+1}^{(i)} = (1-\gamma)\u_t^{(i)} + \gamma g_t^{(i)}$
\STATE Compute $\nabla_{\boldsymbol{\tau}^{(i)}} = \frac{1}{n} \left(-\frac{1}{\u_{t+1}^{(i)} + \epsilon}\frac{1}{B}\sum_{\y'\in\B_t^{(i)}} \exp\left(\frac{\phi(\w;\x_i,\y_i,\y')}{\boldsymbol{\tau}^{(i)}}\right)\frac{\phi(\w;\x_i,\y_i,\y')}{\boldsymbol{\tau}^{(i)}} + \log(\u_{t+1}^{(i)})  + \rho \right)$ 
\STATE Update $\m_{t+1}^{(i)} = (1-\beta)\m_t^{(i)} + \beta \nabla_{\boldsymbol{\tau}^{(i)}}$
\STATE Update $\boldsymbol{\tau}_{t+1}^{(i)} = \Pi_{\Omega}[\boldsymbol{\tau}_t^{(i)} - \eta_{\boldsymbol{\tau}} \m_{t+1}^{(i)}]$
\ENDFOR
\STATE Compute $\nabla_\w =\frac{1}{S}\sum_{i\in\S_t} \frac{1}{\u_{t+1}^{(i)} + \epsilon} \frac{1}{B}\sum_{\y'\in\B_t^{(i)}} \exp\left(\frac{\phi(\w;\x_i,\y_i,\y')}{\boldsymbol{\tau}^{(i)}}\right) \nabla_\w \phi(\w;\x_i,\y_i,\y')$  
\STATE Update $\w_{t+1}$ with $\nabla_\w$ using Adam-W
\ENDFOR
\end{algorithmic}
\end{algorithm}

\subsection{Referene-Free DFT}

We consider the following DRO problem under some conditions.
\begin{align}\nonumber
& \min_\w \frac{1}{n}\sum_{i=1}^n \hat{L}(\w;\x_i,\y_i),\quad \hat{L}(\w;\x_i,\y_i) \coloneqq  \max_{\boldsymbol{\pi}_i\in\Delta_m} \left\{\sum_{j=1}^m \boldsymbol{\pi}_i^{(j)} \phi(\w;\x_i,\y_i,\y_{ij}') - \tau D_\mathrm{KL}\left(\boldsymbol{\pi}_i\vert\vert \mathbf{1}/m\right)\right\},\\\label{eq:simpodro}
& \phi(\w;\x,\y,\y') = \ell \left(\frac{\lambda}{|\y|} \log p_g(\y\mid \x) - \frac{\lambda}{|\y'|} \log p_g(\y'\mid \x) - \gamma \right),
\end{align}
where $\ell(\cdot) = \log(1+\exp(-\cdot))$, $\Delta_m\subset\R^m$ is the probability simplex and $\mathbf{1}/m$ represents the uniform distribution on $\S_i$. Due to the KKT condition, the DRO problem in \eqref{eq:simpodro} is equivalent to 
\begin{align}\label{eq:simpodro_equiv}
& \min_\w \frac{1}{n}\sum_{i=1}^n \tau \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\phi(\w;\x_i,\y_i,\y_{ij}')/\tau\right)\right) \\
& \min_\w \frac{1}{n}\sum_{i=1}^n \tau \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\frac{1}{\tau}\log \left(1 + \exp\left(- \frac{\lambda}{|\y_i|} \log p_g(\y_i\mid \x) + \frac{\lambda}{|\y_{ij}'|} \log p_g(\y_{ij}'\mid \x) + \gamma\right) \right)\right)\right) \\
& \min_\w -\frac{1}{n}\sum_{i=1}^n \frac{\lambda}{|\y_i|} \log p_g(\y_i\mid \x) \\
& + \frac{1}{n}\sum_{i=1}^n \tau \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\frac{1}{\tau}\log \left(\exp\left(\frac{\lambda}{|\y_i|} \log p_g(\y_i\mid \x) - \gamma \right) + \exp\left(\frac{\lambda}{|\y_{ij}'|} \log p_g(\y_{ij}'\mid \x) \right) \right)\right)\right).
\end{align}

DFT with Length Normalization:

\begin{align}
\min_{\w} -\frac{1}{n}\sum_{i=1}^n \frac{1}{|\y_i|}\log p_g(\y_i|\x_i) +  \frac{1}{n}\sum_{i=1}^n  \tau \log \bigg(\E_{\y\sim p^0_g(\y|\x_i)}\frac{p_g(\y|\x_i)^{\frac{1}{\tau |\y|}}}{p^0_g(\y|\x_i)}\bigg)
\end{align}

Another option:

\begin{align}
\min_{\w} -\frac{1}{n}\sum_{i=1}^n \frac{1}{|\y_i|}\log p_g(\y_i|\x_i) +  \frac{1}{n}\sum_{i=1}^n  \tau \log \bigg(\E_{\y\sim p^0_g(\y|\x_i)}\frac{p_g(\y|\x_i)^{\frac{1}{\tau |\y|}}}{p^0_g(\y|\x_i)^{\frac{1}{|\y|}}}\bigg)
\end{align}

If the generation outputs is not length biased, then $\frac{1}{|\y|}\log p^0_g(\y|\x_i)$ is nearly a constant and $p^0_g(\y|\x_i)^{\frac{1}{|\y|}}$ can be removed from the expectation. Hence, we obtain a referene-free DFT objective:

Replace $\frac{\tau}{\lambda}$ by $\tau'$, we have
\begin{align*}
& \min_\w -\frac{1}{n}\sum_{i=1}^n \frac{1}{|\y_i|} \log p_g(\y_i\mid \x) \\
& + \frac{1}{n}\sum_{i=1}^n \tau' \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\frac{1}{\tau'\lambda}\log \left(\exp\left(\frac{\lambda}{|\y_i|} \log p_g(\y_i\mid \x) - \gamma \right) + \exp\left(\frac{\lambda}{|\y_{ij}'|} \log p_g(\y_{ij}'\mid \x) \right) \right)\right)\right).
\end{align*}


When $\gamma \rightarrow \infty$, we obtain the following objective:

\begin{align*}
\min_{\w} -\frac{1}{n}\sum_{i=1}^n \frac{1}{|\y_i|}\log p_g(\y_i|\x_i) +  \frac{1}{n}\sum_{i=1}^n  \tau' \log \bigg(\E_{\y\sim p^0_g(\y|\x_i)}p_g(\y|\x_i)^{\frac{1}{\tau' |\y|}}\bigg).
\end{align*}

\section{Experiments}

\subsection{Compare to SFT}
\begin{itemize}
    \item Dataset: Orca-Math-200k. https://huggingface.co/datasets/microsoft/orca-math-word-problems-200k. 

    Pipeline: three epochs, use the checkpoint at the end of the last epoch as the reference model.
    
    Evaluation metric: the same in the orca-math paper: GSM8k and other math benchmarks beyond GSM8k.
    
    \item Dataset: tulu-v2-sft-mixture-326k. https://huggingface.co/datasets/allenai/tulu-v2-sft-mixture. Finetune Llama 2 and compare with SFT. Combined with HH-RLHF and ultrafeedback datasets.
\end{itemize}

\subsection{Compare to other Self-plays}
Train a basemodel mistral-7b-v0.1 using DFT, SPIN and SimPO-sp on self-played ultrafeedback dataset. A self-played dataset means the training negatives are sampled from the generating responses using the same prompt as the ground-truth output.


% \subsection{Compare to SPIN}
% \begin{enumerate}
%     \item use zephyr-sft as the base model.
%     \item use zephyr (without the SFT stage) as the base model. We can also show that DFT is better than SFT here, by comparing to zephyr-sft.
% \end{enumerate}
% 
% Other settings are the same as SPIN.

% \subsection{Compare to SimPO}
% Use llama3-8b as the base model, funetune on Ultrafeedback-61k using our method, and compare with llama3-8b-Instruct and other results from SimPO paper.

% Evaluation metric: AlpacaEval 2, Arena-Hard and MT-bench.

\subsection{Different Choice of Fitness Score}
\begin{enumerate}
    \item The generative score: $\log p_g(\y, \x)$
    \item length normalized score: $\frac{1}{|\y|}\log p_g(\y, \x)$
    \item Odds score:  $s(\y, \x) = \log \frac{p_g(\y | \x)}{1 - p_g(\y | \x)}$
\end{enumerate}

% \paragraph{FOX-DRO}
% \begin{mintedbox}{python}
% if transactions: Transaction.create_transactions() # if transactions = "true"
% node.generate_emptyState() # empty state for all nodes
% S.initial_events() # initiate initial events to start with

% while not queue.isEmpty() and clock <= targetTime:
%       next_e = queue.get_next_event()
%       clock = next_e.time # move clock to the time of the event
%       Event.execute_event(next_e)
%       Queue.remove_event(next_e)

% print results
% \end{mintedbox}


% \subsection{Tasks and Datasets}
% \begin{enumerate}
%     \item Q\&A tasks. THUDM/webglm-qa, 44k training set.
%     \item Helpfulness and harmlessness. Anthropic/hh-rlhf, 161k training set.
%     \item Huggingface Leaderboard Datasets.
%     \item lighteval/mmlu, 100k training set.
%     \item Math. garage-bAInd/Open-Platypus.
%     \item Language sentiment. stanfordnlp/sst2, 67k training set. Binary classification version of the Stanford Sentiment Treebank.
%     \item yelp.
%     \item AG's news.
% \end{enumerate}

% \subsection{Comparison with SFT}

% Compare scenarios
% \begin{itemize}
%     \item base + SFT
%     \item base + ours (Discriminative Fine Tuning)
% \end{itemize}
% using the following settings

% \begin{tabular}{llll}
%     \toprule
%     Num & Dataset & Model & Name  \\
%      \midrule
%     1 & Alpaca 25k (self-instruct) & LLaMA & Alpaca  \\
%     2 & Databricks 15k (human) & pythia & Dolly \\
%     \bottomrule
% \end{tabular}

% \subsection{Comparison with SPIN}

% Compare following scenarios
% \begin{itemize}
%     \item zephyr-7b-sft-full + SPIN
%     \item zephyr-7b-sft-full + ours (Discriminative Fine Tuning)
%     \item (maybe?) base + ours
% \end{itemize}
% using settings
% \begin{enumerate}[start=3]
%     \item 1 iteration (of 2 epochs) using different number of generated negative samples
%     \item 3 iterations of 2 epochs vs 1 iteration of 6 epochs
% \end{enumerate}

% \subsection{Comparison with DPO}

% \begin{enumerate}[start=5]
%     \item SPIN experiments to compare with DPO (check paper)
%     \item DPO setting (check paper)
% \end{enumerate}

% \subsection{Comparison with other Open-source Models}

% Combine all datasets and train model to compare with open-source leaderboards
% \begin{itemize}
%     \item Alpaca 52k
%     \item Databricks 15k
%     \item Ultrachat 200k
%     \item Anthropic HH
% \end{itemize}

% Add SPIN
% Figure out why SPIN doesn't work
% Finetune on orca-math if possible
\section{Results}
\subsection{GSM8k}
Finetune llama3 8B on the GSM8k training set using SFT and DFT. The learning rate is tuned in  $\{2 \times 10^{-6}, 5 \times 10^{-6}\}$, $\tau$ is tuned in $\{10, 1.1, 1.0, 0.9, 0.8, 0.1\}$. We uses fixed $6$ epochs, $\gamma = 0.95$ and $\mathbf{u}_0 = 0$. We find $\tau=0.9$ and a learning rate of $5 \times 10^{-6}$ yields the best performance. Then using the best hyperparameters, we increase the number of negative samples and show the results in Table~\ref{tabel:1}.

\begin{table}[ht]
\centering
\begin{tabular}{lcc}
\hline
Method                            & GSM8k (0) & GSM8K (5) \\ \hline
Baseline                           & 0            & 49.12        \\
SFT                       & 60.80        & 63.68        \\
DFT 1 Negative & 62.77        & 63.61        \\
DFT 2 Negatives & 63.99        & 61.94        \\
DFT 4 Negatives & 63.84        & 63.68        \\ \hline
\end{tabular}
\label{tabel:1}
\caption{The GSM8K evaluation results. (n) stands for n shots prompting.}
\end{table}


\subsection{Alpaca}

Finetune llama 7b on the 52K alpaca training set using SFT and DFT. We use the same setting as Stanford Alpaca project~\cite{alpaca}. For the extra hyperparameters in our method, we use $\gamma = 0.95$, $\mathbf{u}_0 = 0$ and roughly tuned $\tau \in \{0.9, 1.0, 1.2\}$. Finally, we report the AlpacaEval 2~\cite{alpaca_eval} results.

\begin{table}[ht]
\centering
\begin{tabular}{lcc}
\hline
Method      & LC win rate & win rate \\ \hline
SFT         & 5.88        & 2.59     \\
DFT w/ $\tau=1.0$ & 7.51        & 3.22     \\
\hline
\end{tabular}
\end{table}

\subsection{Zephyr}
We finetune Mistral-7B-v0.1 using the chosen output of the UltraFeedback dataset and generate the reference responses using the prompts from the dataset. In the SFT setup, we use the zephyr-sft-full as the reference model and use this model to generate reference responses. We use 2 epochs in the base setup and 1 in the SFT setup to have a fair comparison. Finally, we report downstream task evaluation and AlpacaEval results.


\begin{table}[ht]
 \begin{adjustwidth}{-2cm}{}
\begin{tabular}{lcccccccccc}
\hline
 Method&data & \#sampled    & MMLU & TruthfulQA & HellaSwag & Winogrande & GSM8k  & ARC\_c & Avg.  & LC \\ \hline
% \multicolumn{8}{c}{Mistral}   \\ \hline
Mistral & & & 62.56 &  42.60 & 83.53 & 78.30 & 38.67 &    61.18 & 61.14 & \\ \hline
SFT & UF-sft & &  61.92 &   49.99 & 83.74 &  78.22 & 45.19 & 63.82 & 63.81 & 8.88 \\ 
% SIMPO & UF & & 62.46 & 63.95 & 85.44 & 78.53 & 35.86  &   67.75  &  65.67 & 14.06 \\
SIMPO-sp & UF-sp & 1 & 62.07 & 49.49 & 83.88 & 77.74 & 0.61 & 61.69 & 55.91 & 5.81 \\ 
SIMPO-sp & UF-sp & 4 &  &  &  &  &  &  &  &  \\ 
CPO-SIMPO-sp & UF-sp & 4 & 62.46 & 49.66 & 83.64 & 77.74 & 39.12 & 61.52 & 62.36 & 10.79 \\ 
SPIN& UF-sp & 1 & 62.65 & 44.14  & 83.06      & 78.77      & 39.12 & 61.26     & 61.50 & 4.50 \\
DFT v1 & UF-sp & 1 & 61.70 & 51.77  & 83.63      & 78.06      & 45.19 & 63.57     & 63.99 & 11.50 \\
DFT v2 & UF-sp& 1 & 62.48  &  53.42 & 83.50   &  77.74 & 42.46 & 64.76 & 64.06 & 12.96 \\
% DFT v2 & UF-sp& 4 & 61.78 & 53.67 & 83.35 & 77.90 & 45.64 & 65.02 & 64.56 & 16.08 \\ 
\hline
\end{tabular}
\end{adjustwidth}
\end{table}


\begin{table}[ht]
 \begin{adjustwidth}{-2cm}{}
\begin{tabular}{lcccccccccc}
\hline
 Method&data & \#sampled    & MMLU & TruthfulQA & HellaSwag & Winogrande & GSM8k  & ARC\_c & Avg.  & LC \\ \hline
% \multicolumn{8}{c}{Mistral}   \\ \hline
SIMPO & UF & & 62.46 & 63.95 & 85.44 & 78.53 & 35.86  &   67.75  &  65.67 & 14.06 \\
DFT v2 & UF-sp& 1 & 62.48  &  53.42 & 83.50   &  77.74 & 42.46 & 64.76 & 64.06 & 12.96 \\
DFT v2 & UF-sp& 4 & 61.78 & 53.67 & 83.35 & 77.90 & 45.64 & 65.02 & 64.56 & 16.08 \\ 
\hline
\end{tabular}
\end{adjustwidth}
\end{table}

\begin{table}[ht]
 \begin{adjustwidth}{-2cm}{}
\begin{tabular}{lcccccccccc}
\hline
 Method&data & \#sampled    & MMLU & TruthfulQA & HellaSwag & Winogrande & GSM8k  & ARC\_c & Avg.  & LC \\ \hline
% \multicolumn{8}{c}{Mistral}   \\ \hline
DFT v1 & UF-sp & 1 & 61.70 & 51.77  & 83.63      & 78.06      & 45.19 & 63.57     & 63.99 & 11.50 \\
DFT v1 LN & UF-sp & 1 & 62.38 & 52.99 & 83.46 & 77.90 & 41.85 & 64.68 & 63.87 & 11.66 \\
\hline
\end{tabular}
\end{adjustwidth}
\end{table}

\section{Numerical Stability}
\begin{algorithm}[ht]
\caption{DFT}
\label{alg:LLM}
\begin{algorithmic}[1] 
\STATE Initialize $\w, \u$
\FOR{$t=0,1,\dotsc,T-1$}
\STATE Sample a batch $\S_t\subset \{1,\dotsc,n\}$, $|\S_t| = S$ \label{lst:line:dual_start}
\FOR{each $\x_i\in\S_t$} 
\STATE Sample size-$B$ mini-batches $\B_t^{(i)}$ from $p^0(\y|\x_i)$
\STATE For each $\y \in \B_t^{(i)}$, compute $d_{\x_i,\y}=\frac{1}{\tau} \log p^t_g(\y|\x_i) - \log p^0(\y | \x_i)$, $w_{\x_i,\y} = \exp(d_{\x_i,\y})$
\STATE Update $u_{t+1}^{(i)} = (1-\gamma)u_t^{(i)} + \gamma \frac{1}{B}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y}$
\ENDFOR
\STATE Compute $L_t =\frac{1}{S}\sum_{i\in\S_t}\left( -\log p_g^t(\y_i | \x_i)  + \frac{1}{B(u_{t+1}^{(i)} + \epsilon)}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y} \log p_g^t(\y | \x_i) \right)$  \label{lst:line:primal_start}
\STATE Compute $G_t = \nabla L_t$
\STATE Update $\w_{t+1}$ using Adam-W
\ENDFOR
\end{algorithmic}
\end{algorithm}
We have the original algorithm \ref{alg:LLM}. In practice, as we push the loglikelihood of negatives down, the value of $\u_t$ is negligible compared to $\epsilon$, and the second term in the loss function will be $0$, which makes DFT become SFT. To address the issue, we propose a division-free algorithm \ref{alg:LLM2}

The moving average is reformulated to
\begin{align}
    u_{t+1}^{(i)} = & (1-\gamma)u_t^{(i)} + \gamma \frac{1}{B}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y} \\ 
    \exp(b_{t+1}^{(i)}) = & \exp(\log (1 - \gamma) + b_t^{(i)}) + \exp(\log \gamma + \log \frac{1}{B}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y})
\end{align}

where we save $\b_t = \log \u_t$ instead of saving $\u_t$ directly.

For simplicity, let $b_t' = \log (1 - \gamma) + b_t^{(i)}$ and $w_t' = \log \gamma + \log \frac{1}{B}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y}$, we have
\begin{align}
    \exp(b_{t+1}^{(i)}) = & \exp(b_t') + \exp(w_t') \\ 
                        = & \exp(b_t') + \exp(w_t' - b_t' + b_t') \\
                        = & \exp(b_t')(1 + \exp(w_t' - b_t')) \label{eq:merge_exp1}
\end{align}
For numerical stability, we use~\eqref{eq:merge_exp1} only if $w_t'$ is less or equal than $b_t'$, otherwise, we use another equivalent formula~\eqref{eq:merge_exp2}
\begin{align}
   \exp(b_{t+1}^{(i)}) = & \exp(w_t')(1 + \exp(b_t' - w_t')) \label{eq:merge_exp2}
\end{align}

In summary, we have
\begin{align}
    \exp(b_{t+1}^{(i)}) = \exp(\max\{b_t', w_t'\})(1 + \exp(-|b_t' - w_t'|)) \label{eq:merge_exp3}
\end{align}

Take the logarithm of both sides, we have
\begin{align}\label{eq:merge_exp}
    b_{t+1}^{(i)} = \max\{b_t', w_t'\} + \log (1 + \exp(-|b_t' - w_t'|)) =  \max\{b_t',w_t'\} - \log \sigma(|b_t' - w_t'|)
\end{align}

\begin{algorithm}[ht]
\caption{DFT}
\label{alg:LLM2}
\begin{algorithmic}[1] 
\STATE Initialize $\w, \u$
\FOR{$t=0,1,\dotsc,T-1$}
\STATE Sample a batch $\S_t\subset \{1,\dotsc,n\}$, $|\S_t| = S$ \label{lst:line:dual_start}
\FOR{each $\x_i\in\S_t$} 
\STATE Sample size-$B$ mini-batches $\B_t^{(i)}$ from $p^0(\y|\x_i)$
\STATE For each $\y \in \B_t^{(i)}$, compute $d_{\x_i,\y}=\frac{1}{\tau} \log p^t_g(\y|\x_i) - \log p^0(\y | \x_i)$,\\$w_{\x_i,\y} = \exp(d_{\x_i,\y} - \max_{\y} \{d_{\x_i,\y}\})$
\STATE Compute $w_t' = \log \gamma + \log(\frac{1}{B}\sum_{\y\in\B_t^{(i)}}w_{\x_i,\y}) + \max_{\y} \{d_{\x_i,\y}\}$, $b_t' = \log(1 - \gamma) + b_t^{(i)}$
\STATE Update $b_{t+1}^{(i)} = \max\{b_t', w_t'\} - \log \sigma(|b_t' - w_t'|)$
\ENDFOR
\STATE Compute $L_t =\frac{1}{S}\sum_{i\in\S_t}\left( -\log p_g^t(\y_i | \x_i)  + \frac{1}{B}\sum_{\y\in\B_t^{(i)}} \exp(d_{\x_i,\y}-b_{t+1}^{(i)}) \log p_g^t(\y | \x_i) \right)$  \label{lst:line:primal_start}
\STATE Compute $G_t = \nabla L_t$
\STATE Update $\w_{t+1}$ using Adam-W
\ENDFOR
\end{algorithmic}
\end{algorithm}



\subsection{Initialization of u}
We investigate how the initial value of $\mathbf{u}$ affects the weights to the log-likelihood of negative samples. As shown in table~\ref{tab:init_u}, a smaller initial value $\mathbf{u}_0$ can yield a larger average weight in the first epoch. When $\mathbf{u}_0 = 0$, the weight becomes a constant $\frac{1}{\gamma}$. In practice, we observe that a constant weight of $\frac{1}{\gamma}$ will push $\log p_g$ to $-\infty$ in a few steps, which causes over-fitting. We address this issue by tuning $\mathbf{u}_0$. 

We attribute this to the feature of the moving average. 
\begin{align}
     u_{t+1}^{(i)} = & (1-\gamma)u_t^{(i)} + \gamma \frac{1}{B}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y}
\end{align}
When $\mathbf{u}_0 = c$, the average weight $\bar w = \frac{\frac{1}{B}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y}}{(1 - \gamma)c + \gamma \frac{1}{B}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y}}$. If $c = 0$, we have the average weight $\bar w = \frac{\frac{1}{B}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y}}{\gamma \frac{1}{B}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y}} = \frac{1}{\gamma}$. If $c > 0$, $w_{\x_i,\y}$ decreases very fast and soon become negligible comparing with $c$ in practice, then we have $\bar w = \frac{\frac{1}{B}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y}}{(1 - \gamma)c}$. It means a smaller weight will be assigned to those samples with smaller $w_{\x_i,\y}$, which mitigates the over-fitting.

% Show that u=e^{-50} differs from u=0
\begin{table}[ht]
\centering
\begin{tabular}{lcc}
\hline
Initial value of $\mathbf{u}$      & Average weight (1 epoch)  & Average weight (2 epochs) \\ \hline
$0$        & 1.053        & /     \\
$\exp(-5)$ & 0.398        & $6.23 \times 10^{-5}$    \\
$1$        & 0.240        & $5.51 \times 10^{-3}$     \\ 
$\exp(5)$  & 0.128        &  $1.31 \times 10^{-8} $    \\
\hline
\end{tabular}
\label{tab:init_u}
\end{table}

However, we observe that less value of $\u_0$ does not always mean larger weight. As shown in table~\ref{tab:init_u}, comparing to $\u_0 = 1$, $\u_0 = \exp(-5)$ has larger average weight on the epoch $1$, but smaller on the $2$ epochs. It is likely due to the smaller value of $w_{\x_i,\y}$ after epoch $1$ caused by large weight.

\section{Related Work}

{\bf Self-Alignment} Sun et al. stuied self-alignment that defines a set of principles that the AI model must adhere to and provides in-context learning demonstrations to the base LLM to generate helpful, ethical, and reliable responses, which are then used for finetuning the base models. The finetuning approach is the same as traditional self-supervised finetuning (SFT). 

{\bf Constitutional AI or Self-Critique.}

{\bf Self-Play}

{\bf Self-Award}

{\bf Self-Instruct}

\begin{table}[ht]
\centering
\begin{tabular}{cccc}
& P & N & \\ \hline
SFT & HF & \ & \xmark \\ \hline
SIMPO & HF & HF & \xmark \\ 
SIMPO-sp & HF & SP & \xmark \\ \hline
DFT & HF & SP & \cmark \\ \hline
\end{tabular}
\end{table}


\begin{comment}
\section{DRO Interpretation of \textsc{Fox}'s Loss}

Given a dataset of $n$ high-quality prompt-response pair $\{(\x_i,\y_i)\}_{i=1}^n$ and $m$ synthetic responses $\S_i=\{\y_{ij}'\}_{j=1}^m$ for each prompt $\x_i$ by a weak LLM $p_{\w_0}$, the empirical loss function of \textsc{Fox} is
\begin{align}\label{eq:emp_x}
\hat{\L}_{\textsc{Fox}}(\w) & = -\frac{1}{n}\sum_{i=1}^n \log p_\w(\y_i\mid\x_i) + \tau \frac{1}{n}\sum_{i=1}^n \log \left(\frac{1}{m}\sum_{j=1}^m\frac{p_\w(\y_{ij}'\mid \x_i)^{1/\tau}}{p_{\w_0}(\y_{ij}'\mid \x_i)}\right).
\end{align}
We claim that minimizing the loss in \eqref{eq:emp_x} is equivalent to solving the following (penalized) distributionally robust optimization (DRO) problem under some conditions.
\begin{align}\nonumber
& \min_\w \frac{1}{n}\sum_{i=1}^n \hat{L}(\w;\x_i,\y_i),\quad \hat{L}(\w;\x_i,\y_i) \coloneqq  \max_{\boldsymbol{\pi}_i\in\Delta_m} \left\{\sum_{j=1}^m \boldsymbol{\pi}_i^{(j)} \phi(\w;\x_i,\y_i,\y_{ij}') - \tau D_\mathrm{KL}\left(\boldsymbol{\pi}_i\vert\vert \mathbf{1}/m\right)\right\},\\\label{eq:dro}
& \phi(\w;\x,\y,\y') = \ell\left(\lambda \log\frac{p_\w(\y\mid \x)}{p_\w(\y'\mid \x)} - \lambda \tau \log\frac{p_{\w_0}(\y\mid \x)}{p_{\w_0}(\y'\mid \x)}\right),
\end{align}
where $\Delta_m\subset\R^m$ is the probability simplex and $\mathbf{1}/m$ represents the uniform distribution on $\S_i$.

\begin{prop}\label{prop:equiv}
When $\lambda= 1$, minimizing the empirical risk $\hat{\L}_{\textsc{Fox}}(\w)$ in \eqref{eq:emp_x} is equivalent to solve the DRO problem in \eqref{eq:dro} with correlation loss $\ell(t) = 1-t$. 
\end{prop}
\begin{proof}
Due to the KKT condition, the DRO problem in \eqref{eq:dro} is equivalent to 
\begin{align*}
\min_\w \frac{1}{n}\sum_{i=1}^n \tau \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\phi(\w;\x_i,\y_i,\y_{ij}')/\tau\right)\right).
\end{align*}
When $\ell(t) = 1-t$, the empirical loss of the problem above can be further written as
\begin{align*}
&  \frac{1}{n}\sum_{i=1}^n \tau \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\phi(\w;\x_i,\y_i,\y_{ij}')/\tau\right)\right)\\
& = 1 + \frac{1}{n}\sum_{i=1}^n \tau \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\lambda\log\frac{p_{\w_0}(\y_i\mid \x_i)}{p_{\w_0}(\y_{ij}'\mid \x_i)} - \frac{\lambda}{\tau} \log\frac{p_\w(\y_i\mid \x_i)}{p_\w(\y_{ij}'\mid \x_i)}\right)\right)\\
& = 1 + \frac{1}{n}\sum_{i=1}^n \tau \log \left(\exp\left(\frac{\lambda}{\tau} \log\frac{p_{\w_0}(\y_i\mid \x_i)^\tau}{p_\w(\y_i\mid \x_i)}\right)\left(\frac{1}{m}\sum_{j=1}^m \exp\left(\frac{\lambda}{\tau} \log\frac{p_\w(\y_{ij}'\mid \x_i)}{p_{\w_0}(\y_{ij}'\mid \x_i)^\tau}\right)\right)\right)\\
& =1 - \lambda \frac{1}{n}\sum_{i=1}^n \log p_\w(\y_i\mid \x_i) + \lambda\tau \frac{1}{n}\sum_{i=1}^n \log p_{\w_0}(\y_i\mid \x_i) +\frac{1}{n}\sum_{i=1}^n  \tau \log \left(\frac{1}{m}\sum_{j=1}^m \frac{p_\w(\y_{ij}'\mid \x_i)^{\lambda/\tau}}{p_{\w_0}(\y_{ij}'\mid \x_i)^\lambda}\right).
\end{align*}
Note that the term $1+\lambda\tau \frac{1}{n}\sum_{i=1}^n \log p_{\w_0}(\y_i\mid \x_i)$ does not depend on $\w$. Thus, minimizing the empirical risk $\hat{\L}_{\textsc{Fox}}(\w)$ in \eqref{eq:emp_x} is equivalent to solve the DRO problem in \eqref{eq:dro} with correlation loss $\ell(t) = 1-t$ when $\lambda= 1$.
\end{proof}


\section{\textsc{iFox}: \textsc{Fox} with Individualized Temperatures}

Note that a single temperature $\tau$ might not suit all data (evidence?). Next, we consider an individualized temperature $\boldsymbol{\tau}^{(i)}$ for each prompt-response pair $(\x_i,\y_i)$. Instead of a pre-determined/tuned $\tau$ for all data in \eqref{eq:emp_x} and \eqref{eq:dro}, we automatically learn $\boldsymbol{\tau}^{(i)}$ via the constrained DRO framework below.
\begin{align}\label{eq:cdro}
\min_\w \frac{1}{n}\sum_{i=1}^n \hat{L}(\w;\x_i,\y_i),\quad \hat{L}(\w;\x_i,\y_i)  \coloneqq  \max_{\boldsymbol{\pi}_i\in\Delta_m} \left\{\sum_{j=1}^m \boldsymbol{\pi}_i^{(j)} \phi(\w;\x_i,\y_i,\y_{ij}'): D_{\mathrm{KL}}(\boldsymbol{\pi}_i\vert\vert\mathbf{1}/m)\leq \rho\right\},
\end{align}
where the definition of $\phi(\w;\x_i,\y_i,\y_{ij}')$ is the same as that in \eqref{eq:dro}. In practice, we also add a regularization term $-\tau_0 D_\mathrm{KL}\left(\boldsymbol{\pi}_i\vert\vert \mathbf{1}/m\right)$ to the loss $\sum_{j=1}^m \boldsymbol{\pi}_i^{(j)} \phi(\w;\x_i,\y_i,\y_{ij}')$ to make the loss function smoother. By the Lagrangian duality, the problem in \eqref{eq:cdro} is equivalent to
\begin{align}\label{eq:ifox_logsumexp}
\min_{\w, \boldsymbol{\tau}\geq \tau_0} \frac{1}{n}\sum_{i=1}^n \left\{\boldsymbol{\tau}^{(i)} \log \left(\frac{1}{m}\sum_{j=1}^m \exp\left(\phi(\w;\x_i,\y_i,\y_{ij}')/\boldsymbol{\tau}^{(i)}\right)\right) + \boldsymbol{\tau}^{(i)}\rho\right\}
\end{align}
Due to Proposition~\ref{prop:equiv}, the problem in \eqref{eq:ifox_logsumexp} is further equivalent to minimizing the problem below when $\lambda=1$ and $\ell(t) = 1-t$.
\begin{align}\label{eq:ifox}
& \min_{\w,\boldsymbol{\tau}\geq \tau_0} \hat{\L}_{\textsc{iFox}}(\w,\boldsymbol{\tau}) ,\\\nonumber
& \hat{\L}_{\textsc{iFox}}(\w,\boldsymbol{\tau})  = \frac{1}{n}\sum_{i=1}^n \left(-\log p_\w(\y_i\mid\x_i) + \boldsymbol{\tau}^{(i)}  \log \left(\frac{1}{m}\sum_{j=1}^m\frac{p_\w(\y_{ij}'\mid \x_i)^{1/\boldsymbol{\tau}^{(i)}}}{p_{\w_0}(\y_{ij}'\mid \x_i)}\right) + \boldsymbol{\tau}^{(i)}\rho\right).
\end{align}

\begin{algorithm}[ht]
\caption{\textsc{iFox}}
\label{alg:ifox}
\begin{algorithmic}[1] 
\STATE Initialize $\w, \u, \boldsymbol{\tau},\m$
\FOR{$t=0,1,\dotsc,T-1$}
\STATE Sample a batch $\S_t\subset \{1,\dotsc,n\}$, $|\S_t| = S$ \label{lst:line:dual_start}
\FOR{each $\x_i\in\S_t$} 
\STATE Sample size-$B$ mini-batches $\B_t^{(i)}$ from $p_{\w_0}(\y|\x_i)$
\STATE For each $\y \in \B_t^{(i)}$, compute $d_{\x_i,\y}=\frac{1}{\boldsymbol{\tau}_t^{(i)}} \log p_{\w_t}(\y|\x_i) - \log p_{\w_0}(\y | \x_i)$, $w_{\x_i,\y} = \exp(d_{\x_i,\y})$
\STATE Update $\u_{t+1}^{(i)} = (1-\gamma)\u_t^{(i)} + \gamma \frac{1}{B}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y}$
\STATE Compute $\nabla_{\boldsymbol{\tau}^{(i)}} = \frac{1}{n} \left(-\frac{1}{\boldsymbol{\tau}_t^{(i)} (\u_{t+1}^{(i)}+\epsilon)B}\sum_{\y\in \B_t^{(i)}} w_{\x_i,\y} \log p_{\w_t}(\y\mid \x) + \log(\u_{t+1}^{(i)}) + \rho\right)$ 
\STATE Update $\m_{t+1}^{(i)} = (1-\beta)\m_t^{(i)} + \beta \nabla_{\boldsymbol{\tau}^{(i)}}$
\STATE Update $\boldsymbol{\tau}_{t+1}^{(i)} = \Pi_{\Omega}[\boldsymbol{\tau}_t^{(i)} - \eta_{\boldsymbol{\tau}} \m_{t+1}^{(i)}]$
\ENDFOR
\STATE Compute $\nabla_\w =\frac{1}{S}\sum_{i\in\S_t}\left( -\frac{\nabla p_{\w_t}(\y_i\mid \x_i)}{p_{\w_t}(\y_i\mid \x_i)}  + \frac{1}{B(\u_{t+1}^{(i)} + \epsilon)}\sum_{\y\in\B_t^{(i)}} w_{\x_i,\y} \frac{\nabla p_{\w_t}(\y\mid \x_i)}{p_{\w_t}(\y\mid \x_i)} \right)$  
\STATE Update $\w_{t+1}$ with $\nabla_\w$ using Adam-W
\ENDFOR
\end{algorithmic}
\end{algorithm}

\section{True Risk and the Relation to SPIN}

We are interested in the limit of the empirical risk of \textsc{iFox} in \eqref{eq:ifox} when $n,m\rightarrow\infty$, i.e., the true risk. Under some mild assumptions, we show that empirical risk in \textsc{iFox} in \eqref{eq:ifox} asymptotically converges to the following true risk.
\begin{align}\label{eq:true_risk}
& \L(\w) = \E_{(\x,\y)\sim p_{\text{data}}}\left[L(\w;\x,\y)\right],\quad L(\w;\x,\y) = \E_{\y'\sim p_{\w_0}(\cdot\mid \x)}\left[\phi(\w;\x,\y,\y')\right],\\\nonumber
& \phi(\w;\x,\y,\y') = \ell\left(\lambda \log\frac{p_\w(\y\mid \x)}{p_\w(\y'\mid \x)} - \lambda \tau \log\frac{p_{\w_0}(\y\mid \x)}{p_{\w_0}(\y'\mid \x)}\right),
\end{align}
where $p_{\text{data}}$ is the underlying distribution of real data. 

\begin{asm}\label{asm:bounded_1}
Let the domain of model parameter $\w$ be convex, compact and $\phi(\w;\x,\y,\y')$ be continuous in $\w$ for some $\x,\y$ and almost every $\y'$. There exists $Z(\y'):\Y\rightarrow\R_+$ such that $|\phi(\w;\x,\y,\y')|\leq Z(\y')$ for all $\w$ and $\E[Z(\y')^{1+\epsilon}] < \infty$ for some $\epsilon>0$.
\end{asm}

\begin{asm}\label{asm:bounded_2}
Let $L(\w;\x,\y)$ be continuous in $\w$ for almost all $\x,\y$. There exists $C(\x,\y):\X\times\Y\rightarrow\R_+$ such that $|L(\w;\x,\y)|\leq C(\x,\y)$ for all $\w$ and $\E[C(\x,\y)] < \infty$.
\end{asm}

\begin{prop}\label{prop:consistency}
Under Assumptions~\ref{asm:bounded_1},~\ref{asm:bounded_2}, we have $\sup_\w\{\hat{\L}_{\textsc{iFox}}(\w) - \L(\w)\}\rightarrow 0$ in probability.
\end{prop}
\begin{proof}
Based on Assumption~\ref{asm:bounded_2}, $\bar{\H}=\{L(\w;\cdot)\}$ is a Glivenko-Cantelli class (See e.g. the definition in \cite{bartlett2008glivenko}). Let $q$ be the product measure corresponding to the real data from $p_{\text{data}}$, $\hat{q}_n$ be the empirical measure over the sample $\{(\x_i,\y_i)\}_{i=1}^n$, and $\hat{q}_n^*$ is the outer measure of $\hat{q}_n$.
\begin{align}\label{eq:gc_1}
& \sup_\theta\left|\frac{1}{n}\sum_{i=1}^n L(\w;\x_i,\y_i) - \E_{(\x,\y)}[L(\w;\x,\y)]\right| \stackrel{\hat{q}_n^*}{\rightarrow}0.
\end{align}
Moreover, $\H_i=\{\phi(\w;\x_i,\y_i,\cdot)\}$ is Glivenko-Cantelli. Theorem 7 in \cite{duchi2021statistics} implies that
\begin{align}\label{eq:gc_2}
\sup_\theta \sup_{p_i:p_i\ll \hat{p}_i^m} \left\{\left|\E_{\y'\sim p_i}[\phi(\w;\x_i,\y_i,\y')] - \E_{\y'\sim p_{\theta_0}(\cdot\mid \x_i)}[\phi(\w;\x_i,\y_i,\y')]\right|:D_{\mathrm{KL}}(p_i\vert\vert\hat{p}_i^m)\leq \rho\right\} \stackrel{p_i^*}{\rightarrow}0.
\end{align}
Combining \eqref{eq:gc_1} and \eqref{eq:gc_2}, we can conclude that
\begin{align}\label{eq:uniform_converge}
\sup_\theta \left\{\hat{\L}_{\textsc{iFox}}(\w) - \L(\w)\right\} \leq \sup_\w \varepsilon^n(\w) + \frac{1}{n}\sum_{i=1}^n \sup_\w \varepsilon_i^m(\w),
\end{align}
where $\sup_\w \varepsilon^n(\w) \stackrel{\hat{q}_n^*}{\rightarrow} 0$ and $\sup_\theta\sup_{p_i:p_i\ll \hat{p}_i^m} \varepsilon_i^m(\w) \stackrel{p_i^*}{\rightarrow} 0$.    
\end{proof}

Besides, it is worth noting that our true risk in \eqref{eq:true_risk} is almost the same as the objective function of the SPIN algorithm~\cite{chen2024self}.

\begin{prop}\label{prop:to_spin}
When $\tau = 1$, the true risk in \eqref{eq:true_risk} is the same as the SPIN objective, i.e., (4.7) in~\cite{chen2024self}.     
\end{prop}

\section{03/01 - 03/07}
Action Items:
\begin{itemize}
\item Vicent: survey data about common-sense reasoning datasets for learning, and adversarial datasets. Prepare a slide to summarize the findings and the experiments of SPIN paper. 

\item Siqi:  survey the training pipeline for vacuna-7b, SPIN, and LLaMa2-7B,  Mistrial 7B, and prepare slides. 

\item Bokun: think about theoretical analysis. Can you show when $\tau\rightarrow\infty$, it reduces to the one similar to SPIN. 
\end{itemize}

\end{comment}

\bibliographystyle{unsrt}
\bibliography{refs}

\appendix

\section{Other Results}

\begin{table}[ht]
 \begin{adjustwidth}{-2cm}{}
\begin{tabular}{lccccccccc}
\hline
 Method&data    & MMLU & TruthfulQA & HellaSwag & Winogrande & GSM8k  & ARC\_c & Avg.  & LC \\ \hline
% \multicolumn{8}{c}{Mistral}   \\ \hline
Mistral & & 62.56 &  42.60 & 83.53 & 78.30 & 38.67 &    61.18 & 61.14 & \\
% zephyr-SFT &UC                      & 58.85 & 40.40  & 80.94      & 76.09      & 32.68 & 57.34     & 57.71 & 10.24 \\ 
% zephyr $\beta$ &UC+UF & 59.76 & 55.14  & 84.40      & 78.14      & 32.98 & 63.05     & 62.24 & 12.62 \\
%SFT + DPO  &UC + UF                & 57.49 & 53.15  & 83.47      & 76.87      & 31.24 & 61.86     & 60.68 \\
%SFT + RDPO &UC + UF                & 58.29 & 46.10  & 84.11      & 76.40      & 28.43 & 61.26     & 59.10 \\ 
%SFT + KTO &UC + UF                 & 59.72 & 56.65  & 84.92      & 78.14      & 40.49 & 63.57     & 63.91 \\ 
%SFT + SimPO &UC + UF               & 58.33 & 50.67  & 83.39      & 76.95      & 33.36 & 61.86     & 60.76 \\ 
\hline
SFT & UF-sft &  61.92 &   49.99 & 83.74 &  78.22 & 45.19 & 63.82 & 63.81 & 8.88 \\ 
SPIN& UF-sp & 62.65 & 44.14  & 83.06      & 78.77      & 39.12 & 61.26     & 61.50 & 4.50 \\
SIMPO $(3\times 10^{-7}, 2, 0.3)$ & UF & 62.92 & 56.42 & 85.22 & 78.22 & 42.91 & 66.47 & 65.36 & 9.05\\ 
SIMPO $(3\times 10^{-7}, 2, 0.5)$& UF & 62.38 & 57.61 & 85.52 & 78.30 & 40.41 & 66.81 & 65.17 & 14.07 \\
SIMPO $(3\times 10^{-7}, 2, 0.7)$& UF & 62.46 & 63.95 & 85.44 & 78.53 & 35.86  &   67.75  &  65.67 & 14.06 \\
SIMPO $(3\times 10^{-7}, 2, 0.5,s1)$& UF-sp &  62.14 & 52.30 & 83.57 & 77.74 & 0.08 & 61.43 & 56.21 & 0.01 \\
SIMPO $(3\times 10^{-7}, 4, 0.5,s1)$& UF-sp &  61.96 & 50.06 & 83.75 & 77.98 & 0.23 & 61.60 & 55.93 & 2.63 \\
SIMPO $(3\times 10^{-7}, 8, 0.5,s1)$& UF-sp &  62.07 & 49.49 & 83.88 & 77.74 & 0.61 & 61.69 & 55.91 & 5.81 \\ \hline
DFT v1 $(1.0, s1)$ & UF-sp & 61.70 & 51.77  & 83.63      & 78.06      & 45.19 & 63.57     & 63.99 & 11.50 \\
DFT v1 LN $(0.010, s1)$ & UF-sp & 61.43  &  51.73 & 82.68 & 78.45 & 43.67 & 65.10 & 63.84 & 7.74 \\
DFT v1 LN $(0.008, s1)$ & UF-sp & 62.33 & 55.31 & 83.12 & 77.35 & 45.03 & 64.93 & 64.68 & 10.61 \\
DFT v1 LN $(0.006, s1)$ & UF-sp & 62.38 & 52.99 & 83.46 & 77.90 & 41.85 & 64.68 & 63.87 & 11.66 \\
DFT v1 LN $(0.008, s4)$ & UF-sp & 62.14 & 52.82 & 82.76 & 79.08 & 44.35 & 65.44 & 64.43 & 13.39 \\
DFT v1 LN $(0.006, s4)$ & UF-sp & 62.44 & 51.21 & 83.24 & 78.93 & 44.35 & 65.10 & 64.21 & 13.92 \\ \hline
DFT v2 $(0.1, s1)$ & UF-sp& 62.25 &  52.04 & 83.36 &  77.27 & 44.35 & 63.91 & 63.86 & 12.94 \\
DFT v2 $(0.2, s1)$ & UF-sp&  62.45 & 51.30 & 83.63 & 77.58 & 46.63 & 64.68 & 64.38 & 8.55 \\ 
DFT v2 $(0.3, s1)$ & UF-sp& 62.48  &  53.42 & 83.50   &  77.74 & 42.46 & 64.76 & 64.06 & 12.96 \\ 
DFT v2 $(0.4, s1)$ & UF-sp& 61.92 & 52.87 & 83.02 & 78.14 & 44.81 &  64.68 & 64.24 & 11.12\\ 
% DFT v2 $(0.2, s2)$ & UF-sp& 62.04 & 52.52 &  83.33  & 77.35 & 46.40 & 64.42 & 64.34 & 9.73 \\
DFT v2 $(0.1, s4)$ & UF-sp& 62.23 &  50.99 & 83.56 & 77.03 & 43.06 & 63.65 & 63.42 & 12.63 \\
DFT v2 $(0.2, s4)$ & UF-sp& 61.99 & 52.86 & 83.22 & 77.58 & 45.19 & 63.99 & 64.14 & 15.76 \\
DFT v2 $(0.3, s4)$ & UF-sp& 61.78 & 53.67 & 83.35 & 77.90 & 45.64 & 65.02 & 64.56 & 16.08 \\ 
DFT v2 $(0.4, s4)$ & UF-sp& 61.52 & 52.52 & 82.92 & 77.98 & 43.29 & 64.85 & 63.85 & 13.33\\ \hline
DFT v2 $(0.3, s3+1)$ & UF& 61.24 & 50.39 & 83.24 & 78.30 & 46.47 & 64.85 & 64.08 & 15.17 \\ 
DFT v2 $(0.4, s3+1)$ & UF& 61.54 & 55.12 & 83.16 & 77.27 & 42.61 & 64.25 & 63.99 & 12.80 \\ 
\hline
%\multicolumn{8}{c}{Zephyr SFT}                                                      \\ \hline
%SFT + SPIN &UC + UF & 58.99 & 39.70  & 81.84      & 76.56      & 33.97 & 58.19     & 58.21 \\ 
%SFT + DFT & UC + UF & 58.66 & 40.31  & 81.81      & 76.80      & 34.50 & 59.30     & 58.56 \\ 
\end{tabular}
\end{adjustwidth}
\end{table}


\begin{table}[ht]
\centering
\begin{tabular}{lccc}
\hline
Method      & LC win rate & win rate & Length\\ \hline
zephyr-SFT          & 8.4       & 6.2   & 914   \\
zephyr $\beta$      &  13.2     & 11.0  & 1444 \\
DPO                 &  15.1     & 12.5  & 1477 \\
SimPO               & 21.5      & 20.8  & 1868 \\ \hline
DFT w/ LN $(0.2, 4)$ & 13.3     & 9.4   & 1230   \\
\hline
\end{tabular}
\end{table}

\end{document}
