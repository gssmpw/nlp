@inproceedings{chen2024self,
  title={Self-play fine-tuning converts weak language models to strong language models},
  author={Chen, Zixiang and Deng, Yihe and Yuan, Huizhuo and Ji, Kaixuan and Gu, Quanquan},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{duchi2021statistics,
  title={Statistics of robust optimization: A generalized empirical likelihood approach},
  author={Duchi, John C and Glynn, Peter W and Namkoong, Hongseok},
  journal={Mathematics of Operations Research},
  volume={46},
  number={3},
  pages={946--969},
  year={2021},
  publisher={INFORMS}
}

@article{duchi2019variance,
  title={Variance-based regularization with convex objectives},
  author={Duchi, John and Namkoong, Hongseok},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={68},
  pages={1--55},
  year={2019}
}

@article{bartlett2005local,
  title={Local Rademacher Complexities},
  author={Bartlett, Peter L and Bousquet, Olivier and Mendelson, Shahar},
  journal={Annals of Statistics},
  pages={1497--1537},
  year={2005},
  publisher={JSTOR}
}

@inproceedings{Maurer2009EmpiricalBB,
  title={Empirical Bernstein Bounds and Sample-Variance Penalization},
  author={Andreas Maurer and Massimiliano Pontil},
  booktitle={Annual Conference Computational Learning Theory},
  year={2009}
}

@article{deshpande2021linearized,
  title={A linearized framework and a new benchmark for model selection for fine-tuning},
  author={Deshpande, Aditya and Achille, Alessandro and Ravichandran, Avinash and Li, Hao and Zancato, Luca and Fowlkes, Charless and Bhotika, Rahul and Soatto, Stefano and Perona, Pietro},
  journal={arXiv preprint arXiv:2102.00084},
  year={2021}
}

@article{ortiz2024task,
  title={Task arithmetic in the tangent space: Improved editing of pre-trained models},
  author={Ortiz-Jimenez, Guillermo and Favero, Alessandro and Frossard, Pascal},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{bartlett2008glivenko,
  title={Glivenko-cantelli classes},
  author={Bartlett, Peter},
  howpublished = {\url{https://people.eecs.berkeley.edu/~bartlett/courses/281b-sp08/14.pdf}},
  year={2008}
}

@article{boucheron2005theory,
  title={Theory of classification: A survey of some recent advances},
  author={Boucheron, St{\'e}phane and Bousquet, Olivier and Lugosi, G{\'a}bor},
  journal={ESAIM: probability and statistics},
  volume={9},
  pages={323--375},
  year={2005},
  publisher={EDP Sciences}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@misc{alpaca_eval,
  author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {AlpacaEval: An Automatic Evaluator of Instruction-following Models},
  year = {2023},
  month = {5},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}}
}

@inproceedings{lin2024mitigating,
  title={Mitigating the alignment tax of RLHF},
  author={Lin, Yong and Lin, Hangyu and Xiong, Wei and Diao, Shizhe and Liu, Jianmeng and Zhang, Jipeng and Pan, Rui and Wang, Haoxiang and Hu, Wenbin and Zhang, Hanning and others},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={580--606},
  year={2024}
}

@article{tu2023sight,
  title={Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics},
  author={Tu, Haoqin and Zhao, Bingchen and Wei, Chen and Xie, Cihang},
  journal={arXiv preprint arXiv:2309.07120},
  year={2023}
}

@article{askell2021general,
  title={A general language assistant as a laboratory for alignment},
  author={Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and DasSarma, Nova and others},
  journal={arXiv preprint arXiv:2112.00861},
  year={2021}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@article{learn2020summ,
  author       = {Nisan Stiennon and
                  Long Ouyang and
                  Jeff Wu and
                  Daniel M. Ziegler and
                  Ryan Lowe and
                  Chelsea Voss and
                  Alec Radford and
                  Dario Amodei and
                  Paul F. Christiano},
  title        = {Learning to summarize from human feedback},
  journal      = {Advances in Neural Information Processing Systems},
  year         = {2020}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{
zhao2023calibrating,
title={Calibrating Sequence likelihood Improves Conditional Language Generation},
author={Yao Zhao and Mikhail Khalman and Rishabh Joshi and Shashi Narayan and Mohammad Saleh and Peter J Liu},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}

@inproceedings{ipo_2022,
  title={A general theoretical paradigm to understand learning from human preferences},
  author={Azar, Mohammad Gheshlaghi and Guo, Zhaohan Daniel and Piot, Bilal and Munos, Remi and Rowland, Mark and Valko, Michal and Calandriello, Daniele},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4447--4455},
  year={2024},
  organization={PMLR}
}

@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{meng2024simpo,
   title={SimPO: Simple Preference Optimization with a Reference-Free Reward},
   author={Meng, Yu and Xia, Mengzhou and Chen, Danqi},
   booktitle={Advances in Neural Information Processing Systems},
   year={2024}
}

@inproceedings{ethayarajhmodel,
  title={Model Alignment as Prospect Theoretic Optimization},
  author={Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe},
  booktitle={International Conference on Machine Learning},
year={2024}
}


@article{chen2024noise,
  title={Noise contrastive alignment of language models with explicit rewards},
  author={Chen, Huayu and He, Guande and Yuan, Lifan and Cui, Ganqu and Su, Hang and Zhu, Jun},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@inproceedings{
yu2024metamath,
title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},
author={Longhui Yu and Weisen Jiang and Han Shi and Jincheng YU and Zhengying Liu and Yu Zhang and James Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@inproceedings{
wang2025on,
title={On Discriminative Probabilistic Modeling for Self-Supervised Representation Learning},
author={Bokun Wang and Yunwen Lei and Yiming Ying and Tianbao Yang},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=s15HrqCqbr}
}

@inproceedings{Park2024DisentanglingLF,
  title={Disentangling Length from Quality in Direct Preference Optimization},
  author={Ryan Park and Rafael Rafailov and Stefano Ermon and Chelsea Finn},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:268733207}
}

@misc{jung2024binaryclassifieroptimizationlarge,
      title={Binary Classifier Optimization for Large Language Model Alignment}, 
      author={Seungjae Jung and Gunsoo Han and Daniel Wontae Nam and Kyoung-Woon On},
      year={2024},
      eprint={2404.04656},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.04656}, 
}

@inproceedings{
xu2024contrastive,
title={Contrastive Preference Optimization: Pushing the Boundaries of {LLM} Performance in Machine Translation},
author={Haoran Xu and Amr Sharaf and Yunmo Chen and Weiting Tan and Lingfeng Shen and Benjamin Van Durme and Kenton Murray and Young Jin Kim},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=51iwkioZpn}
}

@inproceedings{
gudibande2024the,
title={The False Promise of Imitating Proprietary Language Models},
author={Arnav Gudibande and Eric Wallace and Charlie Victor Snell and Xinyang Geng and Hao Liu and Pieter Abbeel and Sergey Levine and Dawn Song},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@inproceedings{kung2023models,
  title={Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning},
  author={Kung, Po-Nien and Peng, Nanyun},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={1317--1328},
  year={2023}
}

@article{zhang2023instruction,
  title={Instruction tuning for large language models: A survey},
  author={Zhang, Shengyu and Dong, Linfeng and Li, Xiaoya and Zhang, Sen and Sun, Xiaofei and Wang, Shuhe and Li, Jiwei and Hu, Runyi and Zhang, Tianwei and Wu, Fei and others},
  journal={arXiv preprint arXiv:2308.10792},
  year={2023}
}

@article{xu2023wizardlm,
  title={Wizardlm: Empowering large language models to follow complex instructions},
  author={Xu, Can and Sun, Qingfeng and Zheng, Kai and Geng, Xiubo and Zhao, Pu and Feng, Jiazhan and Tao, Chongyang and Jiang, Daxin},
  journal={arXiv preprint arXiv:2304.12244},
  year={2023}
}

@inproceedings{li2024self,
  title={Self-Alignment with Instruction Backtranslation},
  author={Li, Xian and Yu, Ping and Zhou, Chunting and Schick, Timo and Levy, Omer and Zettlemoyer, Luke and Weston, Jason E and Lewis, Mike},
  booktitle={The Twelfth International Conference on Learning Representations},
    year={2024}
}

@inproceedings{
wei2022finetuned,
title={Finetuned Language Models are Zero-Shot Learners},
author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},
booktitle={International Conference on Learning Representations},
year={2022}
}

@inproceedings{wang2023self,
  title={Self-Instruct: Aligning Language Models with Self-Generated Instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={13484--13508},
  year={2023}
}

@inproceedings{
li2024getting,
title={Getting More Juice Out of the {SFT} Data: Reward Learning from Human Demonstration Improves {SFT} for {LLM} Alignment},
author={Jiaxiang Li and Siliang Zeng and Hoi To Wai and Chenliang Li and Alfredo Garcia and Mingyi Hong},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024}
}

@inproceedings{
wulfmeier2024imitating,
title={Imitating Language via Scalable Inverse Reinforcement Learning},
author={Markus Wulfmeier and Michael Bloesch and Nino Vieillard and Arun Ahuja and Jorg Bornschein and Sandy Huang and Artem Sokolov and Matt Barnes and Guillaume Desjardins and Alex Bewley and Sarah Maria Elisabeth Bechtle and Jost Tobias Springenberg and Nikola Momchev and Olivier Bachem and Matthieu Geist and Martin Riedmiller},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024}
}

@article{guo2024direct,
  title={Direct language model alignment from online ai feedback},
  author={Guo, Shangmin and Zhang, Biao and Liu, Tianlin and Liu, Tianqi and Khalman, Misha and Llinares, Felipe and Rame, Alexandre and Mesnard, Thomas and Zhao, Yao and Piot, Bilal and others},
  journal={arXiv preprint arXiv:2402.04792},
  year={2024}
}

@inproceedings{yuanself,
  title={Self-Rewarding Language Models},
  author={Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and Li, Xian and Sukhbaatar, Sainbayar and Xu, Jing and Weston, Jason E},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{chen2024bootstrapping,
  title={Bootstrapping Language Models with DPO Implicit Rewards},
  author={Chen, Changyu and Liu, Zichen and Du, Chao and Pang, Tianyu and Liu, Qian and Sinha, Arunesh and Varakantham, Pradeep and Lin, Min},
  journal={arXiv preprint arXiv:2406.09760},
  year={2024}
}

@article{ji2024self,
  title={Self-Play with Adversarial Critic: Provable and Scalable Offline Alignment for Language Models},
  author={Ji, Xiang and Kulkarni, Sanjeev and Wang, Mengdi and Xie, Tengyang},
  journal={arXiv preprint arXiv:2406.04274},
  year={2024}
}

@article{wu2024self,
  title={Self-play preference optimization for language model alignment},
  author={Wu, Yue and Sun, Zhiqing and Yuan, Huizhuo and Ji, Kaixuan and Yang, Yiming and Gu, Quanquan},
  journal={arXiv preprint arXiv:2405.00675},
  year={2024}
}

@article{rosset2024direct,
  title={Direct nash optimization: Teaching language models to self-improve with general preferences},
  author={Rosset, Corby and Cheng, Ching-An and Mitra, Arindam and Santacroce, Michael and Awadallah, Ahmed and Xie, Tengyang},
  journal={arXiv preprint arXiv:2404.03715},
  year={2024}
}

@article{dong2024rlhf,
  title={Rlhf workflow: From reward modeling to online rlhf},
  author={Dong, Hanze and Xiong, Wei and Pang, Bo and Wang, Haoxiang and Zhao, Han and Zhou, Yingbo and Jiang, Nan and Sahoo, Doyen and Xiong, Caiming and Zhang, Tong},
  journal={arXiv preprint arXiv:2405.07863},
  year={2024}
}

@inproceedings{li2023remax,
  title={Remax: A simple, effective, and efficient reinforcement learning method for aligning large language models},
  author={Li, Ziniu and Xu, Tian and Zhang, Yushun and Lin, Zhihang and Yu, Yang and Sun, Ruoyu and Luo, Zhi-Quan},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2023}
}

@article{chan2024dense,
  title={Dense reward for free in reinforcement learning from human feedback},
  author={Chan, Alex J and Sun, Hao and Holt, Samuel and van der Schaar, Mihaela},
  journal={arXiv preprint arXiv:2402.00782},
  year={2024}
}

@article{xu2023some,
  title={Some things are more cringe than others: Preference optimization with the pairwise cringe loss},
  author={Xu, Jing and Lee, Andrew and Sukhbaatar, Sainbayar and Weston, Jason},
  journal={arXiv preprint arXiv:2312.16682},
  year={2023}
}

@article{tajwar2024preference,
  title={Preference fine-tuning of llms should leverage suboptimal, on-policy data},
  author={Tajwar, Fahim and Singh, Anikait and Sharma, Archit and Rafailov, Rafael and Schneider, Jeff and Xie, Tengyang and Ermon, Stefano and Finn, Chelsea and Kumar, Aviral},
  journal={arXiv preprint arXiv:2404.14367},
  year={2024}
}

@article{tang2024understanding,
  title={Understanding the performance gap between online and offline alignment algorithms},
  author={Tang, Yunhao and Guo, Daniel Zhaohan and Zheng, Zeyu and Calandriello, Daniele and Cao, Yuan and Tarassov, Eugene and Munos, R{\'e}mi and Pires, Bernardo {\'A}vila and Valko, Michal and Cheng, Yong and others},
  journal={arXiv preprint arXiv:2405.08448},
  year={2024}
}

@inproceedings{
xu2024is,
title={Is {DPO} Superior to {PPO} for {LLM} Alignment? A Comprehensive Study},
author={Shusheng Xu and Wei Fu and Jiaxuan Gao and Wenjie Ye and Weilin Liu and Zhiyu Mei and Guangju Wang and Chao Yu and Yi Wu},
booktitle={Forty-first International Conference on Machine Learning},
year={2024}
}

@misc{cui2023ultrafeedback,
      title={UltraFeedback: Boosting Language Models with High-quality Feedback}, 
      author={Ganqu Cui and Lifan Yuan and Ning Ding and Guanming Yao and Wei Zhu and Yuan Ni and Guotong Xie and Zhiyuan Liu and Maosong Sun},
      year={2023},
      eprint={2310.01377},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{cobbe2021gsm8k,
  title={Training Verifiers to Solve Math Word Problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{hendrycksmath2021,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
  journal={NeurIPS},
  year={2021}
}

@misc{open-llm-leaderboard-v1,
  author = {Edward Beeching and Clémentine Fourrier and Nathan Habib and Sheon Han and Nathan Lambert and Nazneen Rajani and Omar Sanseviero and Lewis Tunstall and Thomas Wolf},
  title = {Open LLM Leaderboard (2023-2024)},
  year = {2023},
  publisher = {Hugging Face},
  howpublished = "\url{https://huggingface.co/spaces/open-llm-leaderboard-old/open_llm_leaderboard}"
}

@inproceedings{
hendrycks2021measuring,
title={Measuring Massive Multitask Language Understanding},
author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{lin-etal-2022-truthfulqa,
    title = "{T}ruthful{QA}: Measuring How Models Mimic Human Falsehoods",
    author = "Lin, Stephanie  and
      Hilton, Jacob  and
      Evans, Owain",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2022",
    pages = "3214--3252"
}

@inproceedings{zellers-etal-2019-hellaswag,
    title = "{H}ella{S}wag: Can a Machine Really Finish Your Sentence?",
    author = "Zellers, Rowan  and
      Holtzman, Ari  and
      Bisk, Yonatan  and
      Farhadi, Ali  and
      Choi, Yejin",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    year = "2019",
    pages = "4791--4800"
}

@article{sakaguchi2019winogrande,
    title={WinoGrande: An Adversarial Winograd Schema Challenge at Scale},
    author={Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},
    journal={arXiv preprint arXiv:1907.10641},
    year={2019}
}

@article{allenai:arc,
      author    = {Peter Clark  and Isaac Cowhey and Oren Etzioni and Tushar Khot and
                    Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
      title     = {Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},
      journal   = {arXiv:1803.05457v1},
      year      = {2018},
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{10.1609/aaai.v38i17.29865,
author = {Song, Feifan and Yu, Bowen and Li, Minghao and Yu, Haiyang and Huang, Fei and Li, Yongbin and Wang, Houfeng},
title = {Preference ranking optimization for human alignment},
year = {2024},
isbn = {978-1-57735-887-9},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v38i17.29865},
doi = {10.1609/aaai.v38i17.29865},
abstract = {Large language models (LLMs) often contain misleading content, emphasizing the need to align them with human values to ensure secure AI systems. Reinforcement learning from human feedback (RLHF) has been employed to achieve this alignment. However, it encompasses two main drawbacks: (1) RLHF exhibits complexity, instability, and sensitivity to hyperparameters in contrast to SFT. (2) Despite massive trial-and-error, multiple sampling is reduced to pair-wise contrast, thus lacking contrasts from a macro perspective. In this paper, we propose Preference Ranking Optimization (PRO) as an efficient SFT algorithm to directly fine-tune LLMs for human alignment. PRO extends the pair-wise contrast to accommodate preference rankings of any length. By iteratively contrasting candidates, PRO instructs the LLM to prioritize the best response while progressively ranking the rest responses. In this manner, PRO effectively transforms human alignment into aligning the probability ranking of n responses generated by LLM with the preference ranking of humans towards these responses. Experiments have shown that PRO outperforms baseline algorithms, achieving comparable results to ChatGPT and human responses through automatic-based, reward-based, GPT-4, and human evaluations.},
booktitle = {Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence and Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence and Fourteenth Symposium on Educational Advances in Artificial Intelligence},
articleno = {2117},
numpages = {9},
series = {AAAI'24/IAAI'24/EAAI'24}
}

@inproceedings{
yuan2023rrhf,
title={{RRHF}: Rank Responses to Align Language Models with Human Feedback},
author={Hongyi Yuan and Zheng Yuan and Chuanqi Tan and Wei Wang and Songfang Huang and Fei Huang},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=EdIGMCHk4l}
}

@inproceedings{wang2022finite,
  title={Finite-Sum Coupled Compositional Stochastic Optimization: Theory and Applications},
  author={Wang, Bokun and Yang, Tianbao},
  booktitle={International Conference on Machine Learning},
  pages={23292--23317},
  year={2022},
  organization={PMLR}
}

@inproceedings{
chen2024preference,
title={Preference Learning Algorithms Do Not Learn Preference Rankings},
author={Angelica Chen and Sadhika Malladi and Lily H Zhang and Xinyi Chen and Qiuyi Zhang and Rajesh Ranganath and Kyunghyun Cho},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024}
}

@article{DBLP:journals/corr/abs-2407-13709,
  publtype={informal},
  author={Yixin Liu and Pengfei Liu and Arman Cohan},
  title={Understanding Reference Policies in Direct Preference Optimization},
  year={2024},
  cdate={1704067200000},
  journal={CoRR},
  volume={abs/2407.13709}
}

@article{zhou2023instruction,
  title={Instruction-following evaluation for large language models},
  author={Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le},
  journal={arXiv preprint arXiv:2311.07911},
  year={2023}
}

@article{ding2023enhancing,
  title={Enhancing chat language models by scaling high-quality instructional conversations},
  author={Ding, Ning and Chen, Yulin and Xu, Bokai and Qin, Yujia and Zheng, Zhi and Hu, Shengding and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen},
  journal={arXiv preprint arXiv:2305.14233},
  year={2023}
}

@article{guo2025deepseek,
  title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{openai2024o1,
  title={Learning to reason with LLMs},
  author={OpenAI},
  journal={https://openai.com/index/learning-to-reason-with-llms/},
  year={2024}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@misc{vonwerra2022trl,
  author = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang},
  title = {TRL: Transformer Reinforcement Learning},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/huggingface/trl}}
}
@software{Tunstall_The_Alignment_Handbook,
  author = {Tunstall, Lewis and Beeching, Edward and Lambert, Nathan and Rajani, Nazneen and Huang, Shengyi and Rasul, Kashif and Bartolome, Alvaro and M. Rush, Alexander and Wolf, Thomas},
  license = {Apache-2.0},
  title = {{The Alignment Handbook}},
  url = {https://github.com/huggingface/alignment-handbook},
  version = {0.3.0.dev0}
}
@inproceedings{wolf2020transformers,
  title={Transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  booktitle={Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations},
  year={2020}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{
dubois2024lengthcontrolled,
title={Length-Controlled AlpacaEval: A Simple Debiasing of Automatic Evaluators},
author={Yann Dubois and Percy Liang and Tatsunori Hashimoto},
booktitle={First Conference on Language Modeling},
year={2024}
}