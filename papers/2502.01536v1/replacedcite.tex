\section{Related Works}
\label{sec:related_works}
\subsection{Sim-to-Real Policy Transfer} 
Transferring reinforcement learning (RL) policies trained in simulation to the real world remains a major challenge due to substantial domain gaps. Traditional simulator-based methods, such as domain randomization____ and system identification____, aim to reduce the \textit{Sim-to-Real} gap by aligning simulations with physical setups. Recent work____ proposes leveraging conditional generative models to augment visual observations for more robust agent training. LucidSim____, for example, incorporates RGB color perception into the \textit{Sim-to-Real} pipeline to learn low-level visual parkour by augmenting image background. However, these approaches remain constrained by conventional simulators, which fail to capture the full breadth of real-world physics and visual realism necessary for high-level policy training and real-world deployment.

\subsection{Real-to-Sim Scene Transfer} 
Recently, advances in scene representation and reconstruction such as Neural Radiance Fields (NeRF)____ and 3D Gaussian Splatting (3DGS)____ have facilitated the creation of high-fidelity digital twins that closely replicate real-world environments for \textit{Real-to-Sim} scene transfer. For instance, NeRF2Real____ integrates NeRF into simulation for vision-based bipedal locomotion policy training, yet lacks physical interaction with reconstructed geometries. Meanwhile, RialTo____ augments digital twins with articulated USD representations to enable manipulative interactions. More recent works employ 3DGS to generate realistic simulations____ for both robot manipulation____ and navigation____. In contrast, \themodel is designed to produce photorealistic and physically interactive “digital twin” environments specifically tailored for ego-centric visual locomotion learning.