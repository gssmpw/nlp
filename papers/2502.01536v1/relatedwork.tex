\section{Related Works}
\label{sec:related_works}
\subsection{Sim-to-Real Policy Transfer} 
Transferring reinforcement learning (RL) policies trained in simulation to the real world remains a major challenge due to substantial domain gaps. Traditional simulator-based methods, such as domain randomization~\cite{gensim, dynamic_random, domain, dynamics_revisit, cad2rl, synthetic} and system identification~\cite{dynamic_motor, agile_loco, dexterous, closing}, aim to reduce the \textit{Sim-to-Real} gap by aligning simulations with physical setups. Recent work~\cite{layout, drivedreamer, semantically, scaling} proposes leveraging conditional generative models to augment visual observations for more robust agent training. LucidSim~\cite{lucidsim}, for example, incorporates RGB color perception into the \textit{Sim-to-Real} pipeline to learn low-level visual parkour by augmenting image background. However, these approaches remain constrained by conventional simulators, which fail to capture the full breadth of real-world physics and visual realism necessary for high-level policy training and real-world deployment.

\subsection{Real-to-Sim Scene Transfer} 
Recently, advances in scene representation and reconstruction such as Neural Radiance Fields (NeRF)~\cite{nerf} and 3D Gaussian Splatting (3DGS)~\cite{3dgs} have facilitated the creation of high-fidelity digital twins that closely replicate real-world environments for \textit{Real-to-Sim} scene transfer. For instance, NeRF2Real~\cite{nerf2real} integrates NeRF into simulation for vision-based bipedal locomotion policy training, yet lacks physical interaction with reconstructed geometries. Meanwhile, RialTo~\cite{reconciling} augments digital twins with articulated USD representations to enable manipulative interactions. More recent works employ 3DGS to generate realistic simulations~\cite{discoverse2024} for both robot manipulation~\cite{robogs, robogsim, splatsim, rl-gsbrige} and navigation~\cite{quach2024gaussian,vid2sim}. In contrast, \themodel is designed to produce photorealistic and physically interactive “digital twin” environments specifically tailored for ego-centric visual locomotion learning.