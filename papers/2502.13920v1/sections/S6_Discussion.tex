\section{Discussion}\label{sec.discussion}
We introduced \name{}, an LLM-powered chatbot that delivers data-driven, theory-guided sleep health support through a multi-agent framework. This framework features a contextual multi-armed bandit model for adaptive activity recommendations with behavior change strategies in conversational flows.

\subsection{Effectiveness of Data-Driven, Theory-Guided Approach}
An eight-week deployment study with 16 participants demonstrated that \name{} substantially outperformed a baseline system in promoting healthier sleep behaviors. 
By integrating wearable data (\eg, Oura ring metrics) with contextual factors such as time, weather, and location, \name{} delivered recommendations that participants consistently found more personally relevant, context-aware, and actionable.
This improved personalization and contextual relevance led to notably higher adherence rates, a 22-minute increase in average sleep duration, and improved activity scores. 
Participants were more inclined to follow \name{}’s advice—such as taking a light jog in a nearby park—than those provided by the baseline.
Moreover, the inclusion of evidence-based behavior change strategies led to a better understanding of sleep-activity relationships and increased motivation for healthy habits.


\subsection{Balancing Automated Personalization and User Agency}
While participants valued \name{}'s personalized capabilities, the study raises important questions about the balance between automated, AI-driven recommendations and user autonomy. 
Some participants expressed the need to maintain control over their health decisions. 
For example, one mentioned,
\textit{``When it suggests going for a walk because it's sunny, but I feel dehydrated and would prefer to rest.''} This highlights the importance of allowing users to override or adapt system recommendations based on their immediate feelings or circumstances.
Currently, \name{} supports user agency through its conversational interface, enabling users to ask for clarifications or alternatives.
Future approaches can consider interaction designs that allow users to easily specify what aspects of information at what levels of detail should be presented to empower them to make informed decisions.

Moreover, the persuasive nature of personalized recommendations, while effective for behavior change, raises ethical questions about autonomy and informed consent. As one participant noted, \textit{``I find myself following the chatbot's advice more often than not.''} This underscores the need for transparent communication about the system's capabilities and limitations and the importance of framing AI recommendations as suggestions rather than directives.
Future systems should consider implementing more explicit user control features, such as preference settings for recommendation frequency or type, and clear options for users to provide feedback on or override suggestions. Additionally, incorporating periodic reminders of the system's AI nature and encouraging users to consult healthcare professionals for serious concerns could help maintain an appropriate balance between automated support and user agency.


\subsection{Challenges in Sustained Engagement and Behavior Change}
Our study revealed significant challenges in maintaining long-term engagement and translating increased awareness into consistent behavior change. 
\begin{itemize}
    \item Declining novelty: Participants mentioned that initial curiosity and interest in the chatbot's capabilities decreased over time. As one user noted, \textit{``At first, I was curious about what it could suggest, but over time, I felt less motivated to check in with the chatbot.''}
    \item Cognitive load and system interaction barriers: 
    Manual text input introduced a cognitive burden, as evidenced by user feedback requesting voice interactions. Some highlighted the need for better support for handling recurring queries and entry patterns to simplify engagement.
    \item Recommendation fatigue: As participants became familiar with the system's suggestion patterns, they reported decreasing perceived value from recommendations as they began to feel repetitive to users.
    \item Changing life circumstances and competing priorities: Real-life situations, such as travel and recovering from illness, hindered users' ability to engage with the chatbot. 
    \textit{``I knew my sleep was pretty bad lately, but I had to sacrifice my sleep since there is an urgent deadline ahead of me.''}
\end{itemize}

Based on user study results, future systems can consider the following designs.
1) To sustain novelty and interest, systems can introduce adaptive challenge levels that involve users' progress toward their goals, similar to techniques used in gamification. They can also integrate periodic novel content and social features.
2) To improve system interactions, multi-modal interactions (\eg voice commands) and data visualizations should be enabled to enhance natural and convenient data interactions and analytics. Implementation of smart defaults and interaction shortcuts for common queries could simplify engagement.
3) To mitigate recommendation fatigue, systems can continuously expand contextual factors (\eg, seasonal shift) into recommendation logic.
Recommendation timing can be optimized via intelligent notification scheduling based on user receptivity patterns.
% consider more contextual factors and diversify recommendation content. Recommendation timing and delivery can be enhanced by real-time push notifications for our personalized activity suggestions.
% }
4) Systems can support customizable interaction levels, allowing users to adjust the intensity of chatbot engagement based on their current capacity and preferences.



\subsection{Implications for Designing AI-Powered Health Support Systems}
Our study findings suggest three design considerations for future AI-powered health support chatbots.


\par{}\textbf{Emphasizing transparency and reliability to build trust.}
The ability of \name{} to explain the rationale behind its suggestions was highly valued by participants and experts. This can foster trust and motivate adherence to recommendations. By linking advice to personal data and contextual factors, the chatbot helped users understand the benefits of suggested actions. Future health chatbots should prioritize explainability and transparency, clearly communicating how recommendations are generated and how user data is utilized.
This approach aligns with our implementation goals in \name{} and is essential for building long-term user trust.

\par{}\textbf{Applying theory-guided algorithms.}
Operationalizing behavior change theories within data-driven AI systems, as implemented in \name{}, improved response quality and intervention outcomes. The chatbot's use of the TDF and BCT enabled more effective support for behavior change. 
% Participants reported a better understanding of sleep-activity relationships and increased motivation to adopt healthier habits. 
However, careful implementation is required to ensure that theoretical models are appropriately adapted to the AI context. Future systems should continue to incorporate theoretical guidance to enhance data-driven AI methods.

\par{}\textbf{Integration with wearables and health systems.}
Our study reveals opportunities for deeper integration of chatbots with wearables and health systems. 
\begin{itemize}
\item Seamless user experience: Systems should use a unified interface that combines wearable data visualization, chatbot interactions, and health insights. This will address user frustrations with context switching and enhance engagement.
\item Adaptive real-time data analytics: 
Enhancing \name{}'s integration of Oura Ring data, future designs can provide instant, personalized feedback through dynamic dashboards and predictive analytics (\eg, ``Reducing screen time tonight may improve deep sleep by 10\%''). 
These features empower users to make more timely, informed health decisions.
\item Complementing existing health systems: AI chatbots should interpret data from various wearables, providing actionable advice that bridges the gap between users and their health information. This approach can supplement traditional healthcare by supporting daily health management and enabling personalized, continuous interventions.
\end{itemize}


\subsection{Limitations and Future Work}
While \name{} demonstrated promising results in promoting sleep health, our study has several limitations.

\begin{itemize}
    \item \textbf{Data accuracy challenges:} Our system primarily relied on Oura ring, which, while comprehensive and accurate, may still contain 
    % not capture all relevant factors influencing sleep health. The lack of integration with other data sources (\eg, diet tracking and calendar schedules) could limit the holistic understanding of users' health contexts.
    % Moreover, Oura ring data (\eg, activity) may contain 
    missing records, errors, and uncertainty that may impact system performance. Currently, if the system encounters data processing errors, \name{} will respond ``I am sorry, I am not able to provide the information at the moment.'' In addition, users can cross-check raw data tables to judge data quality and system responses. In the future, systems should communicate data quality to users and give more weight to high-confidence data points when generating responses.
    % and integration 
    % \item \textit{Activity detection accuracy:} Our system activity recommendations rely on Oura ring's ability to detect and categorize activities, which is limited to a predefined set and may not capture the full spectrum of user activities. This constraint potentially impacts the accuracy and coverage of our contextual recommendations.
    \item \textbf{Contextual factors:} While we incorporated time, location, temperature, and weather into our recommendation agent, other relevant factors such as social context, diseases and medications, or work schedules were not included due to technical and privacy constraints. This limitation may affect the precision of personalized recommendations. 
    \item \textbf{Model reliability evaluation and enhancement:} To improve model reliability, our system adopted multi-agent designs that decompose conversational and analytical tasks into specialized agents to form the final response. The system's reliability was further evaluated through both user and expert judgment. We can scale up the evaluation by
    developing automated fact-checking methods using external knowledge bases~\cite{kotonya-toni-2020-explainable-automated,sarrouti-etal-2021-evidence-based}. Those data resources can also enhance the LLM reliability via retrieval-augmented generation and finetuning.
    \item \textbf{Study sample size and diversity:} Our current user study involved 16 participants (primarily young adults). Expanding the demographic diversity and sample size can improve the generalizability of findings.
    \item \textbf{Study duration:} Longer deployment studies beyond the current eight weeks are needed to assess sustained behavior change and long-term engagement.

\end{itemize}


\section{Conclusions}
We presented \name{}, a novel sleep health chatbot that integrates data-driven insights, behavior change theories, and adaptive recommendations via a multi-agent LLM framework. 
Integrating a contextual multi-arm bandit model, \name{} delivers personalized activity recommendations and theory-grounded conversations to support behavior change. 
Our eight-week deployment study demonstrated significant advantages over a baseline system, with participants showing improved sleep duration, more consistent engagement, and increased motivation to adopt healthy sleep habits.
However, our study also revealed challenges in maintaining long-term engagement and supporting sustained behavior change. 
Future work can improve data visualizations, implement more proactive features, and personalize recommendations to broader individual contexts and preferences.
