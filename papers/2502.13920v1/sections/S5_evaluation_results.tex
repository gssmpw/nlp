\section{Results and Analysis}\label{sec.eval_results}

We analyzed quantitative data from user interactions, Oura ring metrics, ratings, and qualitative participant feedback to provide a comprehensive comparison of \name{} and the Baseline.


\begin{table}[ht]
\centering
\caption{Comparative analysis of sleep and activity metrics collected by Oura for Baseline and \name{}.}
\label{tab:wearable_data_comparison}
\small % Reduce font size for better fit
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{0.27\columnwidth} cc cc c c}
\hline
\textbf{Metric} & \multicolumn{2}{c}{\textbf{Baseline}} & \multicolumn{2}{c}{\textbf{\name{}}} & \textbf{P-val} & \textbf{Sig.?} \\
 & \textbf{Mean} & \textbf{SD} & \textbf{Mean} & \textbf{SD} &  &  \\
\hline
Sleep Duration (hrs) & 6.48 & 0.59 & 6.84 & 0.63 & 0.0268 & Yes \\
Sleep Efficiency (\%) & 80.27 & 5.20 & 80.58 & 4.21 & 0.8490 & No \\
Average Breath & 15.49 & 1.17 & 15.50 & 1.10 & 0.5882 & No \\
Average HRV & 53.45 & 19.14 & 49.15 & 19.85 & 0.6200 & No \\
Lowest Heart Rate & 56.99 & 7.64 & 57.21 & 8.32 & 0.9537 & No \\
Sleep Score & 75.28 & 13.23 & 78.34 & 13.77 & 0.4764 & No \\
Activity Score & 71.37 & 14.18 & 75.41 & 13.94 & 0.0268 & Yes \\
Readiness Score & 76.44 & 6.34 & 77.91 & 6.29 & 0.4570 & No \\
\hline
\end{tabular}%
}
\end{table}


\begin{table}[ht]
\centering
\caption{\rev{Post-system questionnaire ratings of Baseline and \name{}. Medians and interquartile ranges (IQR) are reported. Wilcoxon signed-rank test was used for statistical significance testing.}}
\label{tab:comparative_analysis}
\normalsize % Use normal font size instead of footnotesize
\renewcommand{\arraystretch}{1.2} % Increase row spacing for readability
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{0.38\columnwidth} c c c c c}
\hline
\textbf{Aspect} & \textbf{Baseline} & \textbf{\name{}} & \textbf{W} & \textbf{\textit{p}-val} & \textbf{Sig?} \\
 & \textbf{Med (IQR)} & \textbf{Med (IQR)} &  &  &  \\
\hline
Speed of chatbot & 4.00 (2.00) & 4.00 (1.00) & 5.00 & 0.4922 & No \\
Accuracy of responses & 2.50 (2.25) & 4.00 (0.00) & 20.00 & 0.0375 & Yes \\
User interface design & 4.00 (1.00) & 4.00 (1.25) & 42.00 & 0.7815 & No \\
Ease of accessing data & 4.00 (1.00) & 4.00 (1.00) & 7.50 & 1.0000 & No \\
Overall system usability & 3.50 (1.25) & 4.00 (0.00) & 37.50 & 0.2850 & No \\
Personalized recommendations & 4.00 (2.00) & 4.00 (0.00) & 9.00 & 0.0308 & Yes \\
Feasible recommendations & 3.50 (1.25) & 4.00 (1.00) & 6.00 & 0.1597 & No \\
Understood activity-sleep relation & 3.50 (2.00) & 4.00 (2.00) & 8.00 & 0.0386 & Yes \\
Learned new strategies & 4.00 (1.00) & 4.00 (1.00) & 33.00 & 1.0000 & No \\
Effective use of Oura data & 3.00 (2.00) & 4.00 (1.00) & 4.00 & 0.0126 & Yes \\
Increased motivation & 3.50 (1.25) & 4.00 (1.25) & 8.00 & 0.0126 & Yes \\
Made changes to routine & 4.00 (1.50) & 3.50 (1.00) & 16.00 & 0.4170 & No \\
Noticed sleep improvements & 3.00 (1.25) & 4.00 (1.00) & 11.00 & 0.0187 & Yes \\
Understood daily impact on sleep & 2.50 (2.00) & 3.00 (1.00) & 2.50 & 0.0461 & Yes \\
Increased awareness of patterns & 4.00 (2.50) & 4.00 (2.00) & 20.00 & 0.1177 & No \\
\hline
\end{tabular}}
\end{table}



\subsection{Impact on Sleep Health Activities and Outcomes}

\subsubsection{Sleep Metrics}
\autoref{tab:wearable_data_comparison} shows that participants using \name{} had a significant increase in sleep duration—an average improvement of 22 minutes per night (t = -2.59, p < 0.05).
However, analysis of sleep scores revealed no statistically significant difference (p = 0.47) between \name{} (78.34) and the Baseline (75.28).
Similarly, while sleep efficiency showed a slight increase (80.27\% vs. 80.58\%) and HRV exhibited a minor decrease (53.45 vs. 49.15), these differences were not statistically significant. 
The average breath rate and lowest heart rate during sleep remained relatively constant between the two phases.

\subsubsection{Activity and Readiness}
\name{} significantly increased physical activity scores, improving from 71.37 (SD = 14.18) to 75.41 (SD = 13.94) (t = -2.59, p < 0.05), indicating its ability to motivate participants to engage in more activity. 
Although readiness scores improved slightly (76.44 to 77.91), this change was not significant (t = 0.77, p = 0.457).


\subsection{Effectiveness of Recommendations and Behavior Change Techniques}

\subsubsection{Personalization, Relevance, and Adherence of Recommendations.}
\rev{As shown in \autoref{tab:comparative_analysis},
\name{} significantly outperformed the Baseline in providing personalized recommendations, confirmed by the Wilcoxon signed-rank test (W=9.00, p=0.0308).
Participants rated \name{}’s advice as more relevant to their needs, with significantly higher relevance scores (Median (IQR): 3.81 (0.34) vs. 3.34 (0.35); W = 20.00, p = 0.023).}
Qualitative responses further highlighted \name{}'s improved contextualization, with one user stating, \textit{``I think having the chatbot know the current weather and temperature outside is motivating. It recommended me to go out for a walk in a sunny afternoon, which I sometimes did.''} However, participants felt that the Baseline's suggestions were ``boring'' and ``generic'' which they already knew, such as maintaining 7 hours of sleep, watching coffee intake, etc.

The \name{}'s ability to provide location-context-aware recommendations was particularly appreciated. One user reported, \textit{``The chatbot suggested `a light jog around Four Freedoms Park in Roosevelt Island in the later afternoon, considering the sunny weather and cooling down the temperature.' It felt like the advice was tailored just for me and my surroundings.''}
Some participants noticed that \name{} knew how to adapt their daily routines to the environment.
One user said, \textit{``I remember it was a bit rainy and cold that morning, the chatbot suggested indoor activities like yoga and treadmill rather than outdoor running, which I normally do.''}
Another added, \textit{``Once, it recommended indoor strength exercises with air conditioning due to the high temperature. It felt very considerate.''}

\name{} also demonstrated flexibility in adapting recommendations to users' specific situations. 
A user mentioned that one time the chatbot recommended an outdoor walk, but he was recovering from COVID. He told the chatbot and the chatbot put forward 15-30 minutes of gentle stretching and yoga with some poses to try.
Another one appraised, \textit{``When I mentioned I don't like meditation, the chatbot quickly switched the suggestions to mindful breathing exercises instead. It felt like it really listened to my preferences.''}

This enhanced personalization resulted in higher adherence rates. 
Participants followed through on a median of 47.94\% (IQR: 34.27\%) of \name{}'s recommendations, which is significantly higher compared to a median of 36.71\% (IQR: 15.49\%) for the Baseline (W = 28.00, p = 0.0386).
% Participants followed through on median: 47.94\%, IQR: 34.27\% of \name{}'s recommendations compared to median:  36.71\%, IQR: 15.49\% for the Baseline system (W = 28.00, p = 0.0386). 
Users frequently mentioned the relevance and practicality of the recommendations as key factors in their increased adherence.
However, there was no significant difference between the two systems regarding the perceived feasibility of the recommendations.



\begin{figure}[ht]
\centering
% \includegraphics[width=\columnwidth]{draft/figures/behavior_comparison_optimized.png}
\includegraphics[width=\columnwidth]{./figures/behavior_comparison_chi.png}
\caption{Comparison of behavior change strategies covered in Baseline and \name{} systems.}
\label{fig:multiple_choice_comparison}
\end{figure}

\subsubsection{Implementation of Behavior Change Strategies}
Post-system questionnaire analysis results (in \autoref{fig:multiple_choice_comparison}) reveal that \name{} covered a broader range of behavior change strategies compared to the Baseline system. Notably, \name{} showed large improvements in providing feedback on sleep patterns and physical activity (15 vs. 10 participants), addressing environmental context (12 vs. 8), enhancing skills and capabilities for better sleep (7 vs. 3), providing emotional support (10 vs. 3), and facilitating goal-setting (8 vs. 2). 
Both systems performed similarly in addressing consequences and reinforcement (9 participants each).
% Both systems performed equally well in addressing consequences and reinforcement of sleep behaviors (9 participants each).

% Further analysis of user conversations processed by different agents in our technical framework identified seven technique domains covered by \name{}, with their frequency of occurrence:
Analysis of user conversations processed by our multi-agent framework identified seven technique domains, with knowledge being most prevalent (23.8\% of interactions), followed by feedback and monitoring (17.9\%), goals (17.6\%), skills and capabilities (16.9\%), emotion support (9.4\%), consequences and reinforcement (8.2\%), and environment context and resources (6.2\%).
Each strategy was exemplified in \name{}'s responses. For instance, \name{} provided knowledge about potential causes of sleep disturbances and actionable advice:
\begin{quote}
User: \textit{``What are the possible reasons for waking up at midnight?''}\\
\name{}: \textit{``Waking up at midnight can often be linked to stress, sleep disorders, or environmental factors like noise and temperature.''}
\end{quote}

\name{} also encouraged ongoing monitoring and maintaining of positive sleep patterns.
\begin{quote}
\name{}: \textit{``Your sleep efficiency has been consistently high over the past few days, averaging around 91\%. This indicates that you're spending a significant portion of your time in bed actually sleeping, which is a positive sign for your overall sleep quality. Keep monitoring this trend to maintain or improve your sleep health.''}
\end{quote}

In addition, \name{} provided advice to enhance users' skills for improving sleep quality.
\begin{quote}
\name{}: \textit{``Practice a relaxing pre-sleep routine, such as reading or gentle stretching, and incorporate mindfulness or breathing exercises to lower stress levels before bedtime.''}
\end{quote}

Furthermore, qualitative feedback supported the effectiveness of \name{}'s behavior change strategies. Users appreciated the emotional support and personalized feedback. One stated, \textit{``That's great! I'm proud of you for being open to trying.'' }
% The system's ability to provide personalized feedback was also valued: 
Another added, \textit{``Feedback on my sleep patterns related to activity... I am trying to be more active. Actually, I just finished a workout. That's been great!''}

\rev{\subsubsection{Expert Feedback}
Three experts (E1-E3) evaluated system responses to users' messages regarding scientific validity, data accuracy, and applicability.
E1 is a health psychologist and the director of a research center for health promotion by physical activity. 
E2 is an assistant professor in sports and exercise science.
E3 is a PhD researcher who has extensive experience (\eg, publications) in sleep and behavior sensing.
We sampled 12 anonymized conversations from study participants using \name{}, along with corresponding wearable data. The samples covered the system's three key capabilities: behavior change techniques, data insights, and activity recommendations, with at least four examples of each\footnote{Individual examples could span multiple categories. They are included in Supplementary Material.}. 
% Experts provided feedback on scientific validity, data accuracy, and applicability.

Experts found that \name{} could accurately retrieve and analyze the relevant wearable data according to users' questions.
For example, when asking about ``sleep last night'', \name{} could locate the relevant data attributes, such as sleep duration, efficiency, HRV, and lowest heart rate, on the requested date.
Moreover, E3 added that it was ``user-friendly'' to convert original sleep duration units from seconds to hours.
Experts generally thought the responses were aligned with established sleep and behavior change theories. 
They also appreciated the actionability of \name{}'s activity recommendations, such as ``take a route that passes a nearby park'' while walking to grocery shops and ``walk around the terminal (while at the airport)''.

However, they pointed out areas for improvement.
E3 required a more in-depth scientific interpretation of the users' wearable data (``What an HRV value of 64 means for the user’s sleep'') to facilitate users' understanding beyond simple data summarization.
Some proposed solutions to sleep problems were deemed general and less useful in motivating users to act (``15-30 min yoga''). 
More context information (about ``waking up at midnight'' and ``broken heart'') might be needed to infer users' psychological and physical needs and connect them with appropriate behavior change techniques (E1).
E2 noted that certain conclusions felt less convincing, with ``only one data point used as evidence (in the response).''
}

\begin{table}[ht]
\centering
\caption{Comparison of user engagement metrics between Baseline and \name{} systems.}
\label{tab:user_engagement}
\renewcommand{\arraystretch}{1.2} % Increase row height for readability
\resizebox{\columnwidth}{!}{%
\begin{tabular}{p{0.31\columnwidth} c c c c}
\hline
\textbf{Metric} & \textbf{Baseline} & \textbf{\name{}} & \textbf{t-stat} & \textbf{\textit{p}-val} \\
 & \textbf{Mean (SD)} & \textbf{Mean (SD)} &  &  \\
\hline
User Engagement & 0.31 (0.19) & 0.39 (0.15) & -2.47 & 0.026* \\
Conversation Length & 4.84 (2.16) & 6.83 (2.67) & -2.18 & 0.045* \\
\hline
\multicolumn{5}{l}{\footnotesize{* Indicates statistical significance at \textit{p} < 0.05.}} \\
\end{tabular}
}
\end{table}


\begin{figure}[ht]
\centering
% \includegraphics[width=\columnwidth]{draft/figures/user_chat_trends.png}
\includegraphics[width=.95\columnwidth]{./figures/user_engagement_trends.png}
\vspace{-5mm}
\caption{Comparison of user engagement over time using Baseline and \name{} systems.}
\label{fig:engagement_trends}
\end{figure}

\subsection{User Engagement Analysis}
To evaluate the effectiveness of \name{} compared to the Baseline system, we analyzed key metrics of user engagement (\autoref{tab:user_engagement}): the ratio of active days to total phase days and conversation length. These metrics provided insights into how frequently and deeply users interacted with each system over the course of the study.

\subsubsection{Engagement Metrics}
User engagement, defined as the ratio of active days to total phase days, showed a significant improvement with \name{}. The average engagement ratio increased from 0.31 (SD = 0.19) with the Baseline system to 0.39 (SD = 0.15) with \name{}, a statistically significant improvement (t = -2.47, p = 0.026). 
This result indicates that users interacted with \name{} more consistently over the study period, suggesting enhanced long-term engagement.
The average number of messages in each conversation also increased significantly from 4.84 (SD = 2.16) in the Baseline system to 6.83 (SD = 2.67) with \name{} (t = -2.18, p = 0.045). This suggests that users engaged in longer conversations with \name{}. 
The increased conversation length may reflect users’ higher levels of engagement and \name{}'s ability to provide more comprehensive and tailored responses, which encouraged users to explore health topics in greater detail.


\subsubsection{Engagement Trends Over Time}
To understand how user engagement evolved throughout the study, we analyzed daily active user counts for both systems over the study period (in \autoref{fig:engagement_trends}). 
The Baseline system showed a significant downward trend in engagement with linear regression analysis (slope = -0.018, p = 0.0025, $R^2$ = 0.41). It started with 10 active users, which decreased sharply after the first few days.
In contrast, \name{} demonstrated a more stable engagement pattern. While it started with similar initial engagement (11 active users), it maintained a relatively consistent level of user activity throughout the study period, with periodic fluctuations between 4-9 users. \name{}'s trend analysis showed a much gentler downward slope (-0.0037) that was not statistically significant (p = 0.49, $R^2$ = 0.027), indicating a better sustained user interest over time.

The combination of higher engagement ratios, longer conversations, and more stable daily active users demonstrate \name{}'s effectiveness in maintaining sustained user engagement. This is particularly critical for the long-term success of sleep health interventions, as consistent engagement offers users more opportunities to receive personalized advice, reflect on their sleep patterns, and implement meaningful changes to their routines.


\subsection{System Performance and Usability}
We compared \name{} with the Baseline system in terms of system response, user interface design, and usability metrics (\autoref{tab:comparative_analysis}). 
Our analysis reveal significant improvements in the \name{} system compared to the Baseline system in terms of response accuracy. \rev{The median accuracy ratings of responses improved from 2.50 (IQR = 2.25) to 4.00 (IQR = 1.00), W = 20.00, p = 0.038.} However, there were no significant differences in speed, user interface design, ease of accessing data, or overall system usability between the two systems. This suggests that while \name{} maintained the user-friendly aspects of the Baseline system, it significantly enhanced the quality and relevance of its responses. Qualitative feedback supported this finding. For instance, one user noted, \textit{``The chatbot gave very good advice about my sleep patterns, such as noticing my lack of sleep or lack of exercise. It gave great recommendations personalized to my surroundings and fitness.''}



\subsection{Users' Perceived Benefits and Limitations}
We analyzed user feedback on the perceived benefits and limitations of \name{}, focusing on aspects such as personalization, usefulness, and engagement.

\subsubsection{Perceived Benefits}
\name{} demonstrated significant improvements in several key areas compared to the Baseline system. 

Participants reported a significantly better understanding of sleep-activity relationships when using \name{}. 
\rev{The median score for this aspect increased from 3.50 (IQR: 2.00) to 4.00 (IQR: 2.00) (W = 8.00, p = 0.039). Similarly, users' understanding of how daily activities impact sleep also improved significantly, with median scores rising from 2.50 (IQR: 2.00) to 3.00 (IQR: 1.00) (W = 2.50, p = 0.046).} One user remarked, \textit{``After it told me my sleepiness is due to inactivity rather than bad sleep, I am trying to be more active.''}

\name{} significantly outperformed the Baseline system in the effective use of Oura ring data.
\rev{The median score increased from 3.00 (IQR: 2.00) to 4.00 (IQR: 1.00) (W = 4.00, p = 0.013).} This suggests that \name{} was more effective in leveraging user data to provide meaningful insights.

\name{} also had a notable positive impact on motivation and behavior change. \rev{The median score for increased motivation to improve sleep habits rose from 3.50 (IQR: 1.25) to 4.00 (IQR: 1.25) (W = 8.00, p = 0.013). Additionally, users reported greater sleep improvements after following its advice, with scores increasing from 3.00 (IQR: 1.25) to 4.00 (IQR: 1.00) (W = 11.00, p = 0.019).}


Both systems were effective in increasing users' awareness of their sleep patterns \rev{(median = 4.00 for both)}, but \name{} seemed to inspire more specific behavioral changes. One user reported, 
\textit{``Talking to the chatbot definitely made me more aware of my sleep. Also, there were times I've been paranoid about not sleeping enough, but chatbot told me my sleep score is fine, most likely I am sleepy because of my (low) activity score.''}


\subsubsection{Perceived Limitations and User Suggestions}
Despite the overall positive feedback, users identified several limitations and areas for improvement in \name{}, particularly in data accuracy, actionability of insights, data integration, and user experience.

Some participants reported data accuracy issues in Oura ring. One user noted the sleep score did not align well with their subjective experience. Some mentioned that sometimes the activities were not captured correctly or not detected at all.
One said, \textit{``The app showed that I had a nap, but I was just sitting on chair playing my phone.''}
Moreover, some participants felt the insights could be more actionable and comprehensive. As one user put it, \textit{``The chatbot told me stress is likely a cause, but it didn't give actionable insights. It suggested meditation, but I still had to find my own tutorials.''}
Participants desired system capability to integrate and track factors like daily diet and routines that could influence sleep. 


Several usability concerns were raised, including the need to switch between multiple apps, the absence of effective data visualization, and a preference for voice commands over typing. To address these issues, participants suggested developing an integrated platform that seamlessly combines chatbot interactions and data access within a single interface.
In addition, users recommended implementing a dedicated data visualization dashboard to summarize key metrics like stress levels, sleep quality, and their trends over time, making the information easier to interpret. Many participants emphasized the value of voice-based interactions to facilitate system usage, particularly when on the go or in situations where typing is inconvenient.
Participants also highlighted the need of proactive engagement features, such as 
push notifications to highlight progress, track goals, and provide positive reinforcement.

