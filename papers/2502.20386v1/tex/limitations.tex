\section{Limitations} 
\label{sec:limitations}
One of the primary limitations of this method is its heavy dependence on the quality of the external odometry solution. 
While it is possible to incorporate loop closures into the process, the system is fundamentally reliant on the external module’s ability to accurately detect and handle these loop closures.
%
Furthermore, the success of the method is dependent on the quality of the visual data—both the images and depth information—as well as the viewpoint from which they are captured. 
Poor-quality images, inaccurate depth measurements, or suboptimal viewpoints can severely impact the system's ability to generate accurate task-driven semantics, as these factors form the core of the data used to interpret and solve tasks.
Empirically, the compressed CLIP features retain sufficient information for the tasks we consider but may not work for more abstract tasks.
We also do not consider the orientation of the robot at the discrete planning stage, which might result in the robot failing to complete the task by mapping only a portion of the object of interest.
Lastly, the method faces challenges when dealing with very abstract tasks. While it performs well for tasks with concrete and well-defined semantics, it may struggle with tasks that require a deeper understanding or decomposition of more abstract concepts.
In such cases, additional tools, such as large language models (LLMs), may be necessary to decompose the tasks into more manageable components, further complicating the overall process and potentially adding another layer of complexity.