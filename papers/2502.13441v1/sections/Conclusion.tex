\section{Conclusion}

% \cmscommentinline{TBA.}

We presented {\langname} as a simple yet effective framework -- leveraging techniques of bait prompting, diversification, and consensus enhancement -- for exploring the self-improvement problem of LLMs. We show that {\langname} suffices to improve the mathematical reasoning capabilities of an LLM with zero supervision signals while preserving its general performance. Moreover, it facilitates more effective and efficient LLM knowledge distillation than existing approaches based on seed-dataset augmentation. 