\begin{abstract}
Self-improving large language models (LLMs) -- i.e., to improve the performance of an LLM by fine-tuning it with synthetic data generated by itself -- is a promising way to advance the capabilities of LLMs while avoiding extensive supervision. Existing approaches to self-improvement often rely on external supervision signals in the form of seed data and/or assistance from third-party models. This paper presents {\langname} -- a simple yet effective framework for generating high-quality synthetic question-answer data in a fully autonomous 
manner. {\langname} first elicits the LLM to generate raw questions via a bait prompt, then diversifies these questions leveraging a rejection sampling-based self-deduplication, and finally feeds the questions to the LLM and collects the corresponding answers by means of majority voting. We show that {\langname} sheds light on the potential of true self-improvement with zero external supervision signals for math reasoning; in particular, {\langname}-generated question-answer pairs suffice to (i) improve the reasoning capabilities of an LLM while preserving its general performance (especially in the 0-shot setting); and (ii) distil LLM knowledge to weaker models more effectively than existing methods based on seed-dataset augmentation.

% We study the self-improvement problem of large language models (LLMs), i.e., to improve the performance of an LLM by fine-tuning it with synthetic data generated by itself. In contrast to existing approaches which rely on either external seed data or the assistance of third-party models, this paper presents {\langname} -- a fully autonomous framework for generating high-quality synthetic question-answer data that suffice to improve the reasoning capabilities of an LLM while preserving its general performance. {\langname} adopts a simple yet effective workflow: It first elicits the LLM to generate a bunch of raw questions via a bait prompt, then diversifies these questions leveraging a rejection sampling-based self-deduplication, and finally feeds the questions to the LLM and collects the corresponding answers by means of majority voting. Experiments indicate that {\langname} exhibits ...\cmscomment{\atsyt Add key conclusions from the experiments.}
%
% In response to the exhaustion of (public) pre-training data, synthetic data generation has become an important means to further enhance the reasoning capabilities of large language models. However, existing approaches either (i) rely on external data input and/or the assistance of third-party models, or (ii) can generate only general, themeless queries and responses
% Synthetic data generation is an effective method to enhance the reasoning capabilities of large language models even when public pre-training data is exhausted. Existing approaches to synthetic data generation either rely on external data input or the assistance of third-party models, or can produce only general, themeless queries and responses ...
\end{abstract}