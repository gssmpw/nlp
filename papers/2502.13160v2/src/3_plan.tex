\definecolor{bluee}{RGB}{178, 139, 103}
\newcommand{\GetMaxAgent}[1]{...}


\section{Method}

% \subsection{Problem Formulation}

% This section explains the experimental settings and possible analysis procedures in detail. 
% We use small-town life as the basic environment for simulation. 
% The town has many types of agents, and they have their interactions and lives.
% There are various groups in towns. Through long-term social activities, they form various social networks with topological structures, such as hierarchical structures.
% After acquiring the information, the agent pays attention to different pieces and takes various actions, ultimately affecting the group structure and information stratification.
% The simulation starts by extracting certain topological groups in the town, discussing the process of agents updating the social network, and visualizing the path of information propagation.
% After the experimental simulation, we analyze the simulation results at the agent, group, and information levels.


\subsection{General Simulation Framework}
% To analyze this\wyh{analyse what?}, we propose a two-tier framework.
%consisting of two main components: the dynamic attention agent and the asymmetric open environment. Together, these components create a comprehensive two-tier system.

The simulation framework consists of two stages: the initial stage and the interaction stage. The initial stage is the pre-simulation setup, which includes selecting groups characterized by specific topological structures from various social networks and defining their corresponding profiles and relationships. The interaction stage encompasses the entire process of agent interaction during the simulation.


The initial stage establishes the foundational social network. Drawing upon principles of organizational behavior in social science \cite{b50,b46}, we select two representative network topologies: the wheel and the circle \cite{b46}. The wheel structure is characterized by a central node connected to multiple peripheral nodes, forming a centralized network, whereas the circle structure involves peripheral nodes interconnected in a circular manner, representing a decentralized network. The network comprises five agents, which is the minimum number necessary to distinguish between these two topological configurations. These agents are allowed to disclose only their profiles to the external environment, while their subjective relationships, actions, and memories remain private.

During the interaction phase, the simulation is conducted over ten rounds, during which all agents can send messages to any other agent within both the initial setup and the open environment. In this context, the term ``open environment'' refers to the allowance for an indefinite number of new agents with diverse profiles. For instance, if an agent wishes to communicate with a police officer and no such agent currently exists in the environment, the agent may define a new profile and relationship for a police officer and incorporate this new agent into the current group. This mechanism is designed to emulate an open environment where any type of agent can be encountered. In each round, agents have the flexibility to either disseminate information or modify their relationships. The simulation framework's support for an unbounded network size enables agents to distribute information without limitation.

%In the interaction time, we allow ten rounds of interaction. All agents can send message to any other agent in the initial setup as well as any agent in the open environment for every round. 
%After receiving messages, agents compute attention weights for all received messages. This computation is based on multiple factors, including the agent's profile, existing relationships, previous actions, and the content of the messages received. 
%Based on received messages, the agent determines its action for that round by integrating the computed attention information set with its own profile and the profiles of all agents present in the environment. 
%At every round, agents are afforded the flexibility to either disseminate information or modify their relationships, and our simulation framework permits an unbounded network size, thereby allowing agents to distribute information without limitation.  If the current group) does not have enough agents to meet the needs of a recipient for information transmission, the agent can define a new agent's profile and relationship, and bring this agent into the current group.
% 解释：如果当前环境中（当前群体中）的agent不足以满足某位agent传播信息的接收者的需求，（比如agent想要跟一位警察说话，但环境中没有警察），那么agent可以自行定义一个新agent的profile和relationship，并把这个agent拉入目前的群体中。

%Within the interaction tier, our simulation permits an unbounded network size, thereby allowing agents to distribute information without limitation. Moreover, the subjective relationships between agents can only be modified by the agents themselves, which implies that two agents may hold different subjective perceptions regarding the nature of their relationship.

% (1) the initial tier: is about the settings before the simulation starts, including selecting groups with a certain topological structure from various social groups and defining their profiles and relationships. 
% (2) Interaction tier: represents the entire interaction process of the simulation. 
% The agent calculates the attention weights of all received messages in this round based on their profile, relationship, actions, and received messages. 
% Then, the agent determines the action for this round, based on the attention information set, its profile, and all agent profiles within the current environment.
% In each round, agents can choose whether to pass information or change the relationship. 
% If the current agent does not meet the receiver's needs for passing information, it can customize the profile and relationship of the receiver to incorporate the new agent into the information circle.


% The agent's actions in each round may affect the environment, thereby updating the state to guide the next round of interaction.
% This framework emphasizes that information asymmetry can arise through various methods. 
% For instance, external information can be shared using broadcast, multicast, or unicast among different agents. 
% The information between agents may be altered based on the agents' preferences. 
% Furthermore, agents can create their information networks by sharing information and adding new participants.


\begin{figure}[!ht]
    \centering
    \includegraphics[width=\linewidth]{pdf/simulation.pdf}
    \caption{The two-stage framework model to simulate asymmetric open environment information diffusion.}
    \label{fig:Simulation}
\end{figure}



% Creating a basic environment for agents to demonstrate information asymmetry has three challenges. 
% Firstly, it is essential to eliminate any interference factors to observe immediate behavior. 
% % For example, an agent's immediate behavior should reflect decisions based solely on the information, rather than being influenced by multiple factors over an extended period. 


% Thirdly, the environment needs to process the agent's actions in parallel, while paying attention to the distinction between omniscient and asymmetric information to ensure the authenticity of the agent's interaction.


% At a specific time step during the social development process, the simulation pauses to select a micro-group with a defined topological structure from various social groups.
% By introducing new external information to this micro-group, we observe the dynamic process of information diffusion. 
% We do not define the general population of agents within the environment, indicating that any individual may exist within the social context. 
% Agents are required to determine the recipients of information based on specific interactions rather than selecting from a fixed environment.

\noindent \textbf{Action} \quad At each time step $ T = \left \{ t_1,...,t_{10} \right \} $, we have agents $ A = \left \{ a_1,...,a_n \right \} $. At the beginning of the simulation time step $t_1$, $n=5$. At each time step $t$ after this, n may increase based on the actions of each agent, up to a maximum of 5 per round.
Each agent $a_i$ has profile $p_i$, relationship $r_i$, output action $o_i$, information diffusion $d_i$.
At time step $t_i$, $p_i$ remains unchanged, $r_i$ has scale $r_i \in \left \{ \text{positive}, \text{negative}, \text{general} \right \}$ with other agents.
$o_i$ can be True or False and consists of two parts: changing the relationship $r_i$ and transmitting information $d_i$.
The agent can independently choose to pass information to any agent in the current environment or to a new agent it defines itself.
Therefore, the agent's action decision-making must balance the initial information with other information, including discussions caused by profile similarities.
After each action round, the environment updates the state of each agent based on the agent's actions $ O = \left \{ o_1,..., o_n \right \} $. This includes updating $r_i$ (subjective relationship) in the database, adjusting $d_i$ to reflect the corresponding receiver's received\_messages, and refreshing the agent's actions for this round.
After that, the environment updates the list of the latest agents and performs attention calculations as algorithm \ref{alg1} and action decisions for the next round of agents.


\subsection{Agent Construction}
In this section, we introduce how to construct an agent. Especially, we propose a novel agent memory mechanism, referred to as the \textit{dynamic attention mechanism}. This approach is motivated by the observation that, within our simulation, agents receive information from multiple sources during each interaction round, substantially increasing the total context length. Consequently, agents may struggle to discern which pieces of information warrant the most attention.

In preliminary experiments, we employed a generic LLM-based agent that retained all information received across multiple rounds in its memory, making decisions based on this complete dataset. We observed that, under this design, a single agent's actions across communication rounds remained highly similar, resulting in minimal active changes to interpersonal relationships throughout the simulation. Such uniformity in behavior diverges from patterns typically observed in human interactions \cite{b73,b74,b75}.

\begin{table}[ht]
    \centering
    \footnotesize
    
    \begin{tabular}{p{3.6cm}p{0.5cm}p{0.5cm}p{0.5cm}p{0.5cm}}
         \toprule
          & mean $\uparrow$&min&max& SD $\downarrow$ \\
         \midrule
         Generic Agent &  \textcolor{bluee}{0.80}&  0.63&  0.94&  0.08\\
         \midrule
         Agent + Dynamic Attention &  0.57&  0.27&  0.90&  0.17\\
         \bottomrule
    \end{tabular}
    
    \caption{Preliminary study for agent attention algorithm.}
    \label{tab:baselinecompare}
\end{table}


In this preliminary experiment, we conducted 24 simulation runs across eight distinct scenarios. As illustrated in the first row of Table \ref{tab:baselinecompare}, we present the outcomes for a generic LLM-based agent in terms of mean, minimum, maximum, and standard deviation (SD) of the similarity between actions in consecutive rounds. These similarity values were calculated by applying cosine similarity to action embeddings generated using Sentence-BERT \cite{b70}. Notably, the mean similarity reaches as high as 0.80, while even the least similar pair of actions exhibits a cosine similarity of 0.63. Furthermore, the small standard deviation indicates that this tendency is highly consistent across simulations, suggesting that the agents frequently repeated the same information over the course of the simulation.

This observation stands in stark contrast to real-world information diffusion processes \cite{b76,b77}. Consequently, relying solely on an LLM’s intrinsic attention mechanisms over an extended context constrains the representation of how various pieces of information compete for an agent’s focus. 
Agents need more factors related to the real world (such as interpersonal relationships, information complexity, information changes) to assist them in making wise action decisions.
To address these shortcomings, we propose an agent attention algorithm designed to mitigate these issues.
%Increasing the number of simulation rounds may lead to a significant increase in the amount of input information for certain agents. However, agents that do not receive messages from other agents may continue to make decisions based on the information from the initial rounds. This not only cause the Matthew effect in information dissemination but may also influence the agents' decision-making processes.


\paragraph{Agent with Dynamic Attention}
The Dynamic Attention Mechanism is grounded in research from social science and journalism, particularly the idea that multiple pieces of information compete for an individual’s attention, as articulated by the Global Workspace Theory \cite{b51}. In the context of transformer-based models, biases introduced during pre-training \cite{b67} and the ``lost in the middle'' issue associated with lengthy text inputs \cite{b66} underscore the need for an algorithmic approach that enables agents to dynamically prioritize crucial information. Accordingly, agents must adapt their focus to evolving inputs and thoroughly evaluate the importance of new data before deciding on a course of action. Insights from journalism further guide this design: people’s attention is often heightened by enhancing the relevance of the information, citing significant sources, and foregrounding key points \cite{b68}. Building on these principles, our mechanism determines whether the agent should prioritize certain pieces of information and adjusts the presentation of historical messages to better reflect their relative importance. Below is the algorithm:

\begin{algorithm}[ht]
\small
\caption{Dynamic Attention Algorithm}
\label{alg1}
\KwIn{received\_messages, turn\_number, actions, subjective\_relationships}
\KwOut{attention\_information}

% 消息分离
$\text{current msgs}, \text{prev msgs} \gets \{(s, m) | (t, s, m) \in \text{received messages}, t = \text{turn number}\}$\;

% Weight initialization
\ForEach{$(s,m) \in \text{msgs}$}{
    $r \gets rel.get(s)$\;
    $w \gets \begin{cases}
        1, & \text{if } r \in \{\text{pos,neg}\}\\
        0, & \text{if } r = \text{gen}\\
        -1, & \text{otherwise}
    \end{cases}$\;
    $dict[s] \gets (w,m)$\;
}

% 调整基于消息独特性
$\text{max\_agent} \gets \text{GetMaxAgent}(\text{CalcEntropy}(\text{msgs}))$\;

\If{$\text{max\_agent} \neq \emptyset$}{
    \ForEach{$(s, \text{info}) \in weight\_dict$}{
        $\text{info[weight]} \gets \text{info[weight]} + \begin{cases}
            1, & \text{if } s = \text{max\_agent}\\
            -1, & \text{otherwise}
        \end{cases}$\;
    }
}

% 更新权重（基于历史消息的熵变化）
\ForEach{$(s, \text{info}) \in weight\_dict$}{
    \If{$s \in prev\_dict$}{
        $\text{prev\_entropy} \gets \text{CalcEntropy}(prev\_dict[s])$\;
        $\text{curr\_entropy} \gets \text{CalcEntropy}(prev\_dict[s] \cup \{\text{info[message]}\})$\;
        $\text{info[weight]} \gets \text{info[weight]} + \begin{cases}
            1, & \text{if } \text{curr\_entropy} > \text{prev\_entropy}\\
            -1, & \text{otherwise}
        \end{cases}$\;
    }
}

% 基于互动频率调整权重
\If{$\text{actions} \neq \emptyset$}{
    $top\_agent \gets \GetMaxAgent(\text{Counter}(actions))$\;
    \ForEach{$(s, \text{info}) \in weight\_dict$}{
        $\text{info[weight]} \gets \text{info[weight]} + \begin{cases}
            1, & \text{if } s = \text{top\_agent}\\
            -1, & \text{otherwise}
        \end{cases}$\;
    }
}
\end{algorithm}

Algorithm \ref{alg1} outlines the procedure through which an agent processes multiple pieces of incoming information to compute the importance weight of each message, leveraging both short-term and long-term memory. The algorithm takes as input the agent’s previously received messages, past actions, most recent subjective relationships, and the current simulation round number. Its output is a weighted information set for all messages received in the present round.

Initially, the algorithm distinguishes between newly received messages and those stored from previous rounds. The short-term memory component only includes messages from the current round and the most recent subjective relationships, while the long-term memory component holds all previous messages and actions. The weighting process begins with an initial assessment in short-term memory, simulating the quick human evaluation of multiple messages over a brief time span. First, the relationship between the message sender and the agent is determined: agents with a positive or negative relationship receive an increased weight, while neutral relationships remain unaltered, and unfamiliar agents lead to a reduced weight. Among all messages received in the current round, those deemed “high complexity” also receive higher weights due to their novel information content. This preliminary weighting is performed at a relatively low computational cost.

Subsequently, the agent refines these weights by comparing short-term memory with long-term memory. This step emulates the process by which humans recall information sources and consider past exchanges. To highlight messages that exhibit the greatest level of transformation during transmission, the algorithm calculates the change in the entropy value \(\left(\text{Equation}~\ref{shanon}\right)\) of the corresponding information source from the previous round to the current round. Lastly, the algorithm further increases the weight of messages originating from agents with whom there have been the most frequent interactions, as inferred from past actions.

\vspace{-15pt}
\begin{equation}
\small
    H(X) = -\sum_{i=1}^{n} (p_i + \epsilon) \log (p_i + \epsilon), \quad \epsilon = 10^{-9}
\label{shanon}
\end{equation}
\vspace{-15pt}



% 长短记忆算法找理论支撑！！！！！！！！
% 找到啦！Dual process theory （双加工理论（Dual-Process Theories）是社会认知领域中用以解释人类信息处理方式的一种理论框架。该理论将人类的信息处理过程划分为两种不同的系统：系统1（快速、自动、低认知资源）和系统2（慢速、控制性、高认知资源））

% 系统1对应 多种信息 --> short-term memory 的过程
% short-term 给多条信息初步划分权重
% 系统2对应 short-term --> long-term memory 的过程
% long-term 形成这轮最终的权重信息集

% 只需要在这两个分过程中找到对agent判断会造成影响的点：
% 系统1：多种信息 --> short-term memory：
% 1.本轮所有信息中熵值最大的（该信息有更强的不确定性和复杂性）
% 2.本轮所有信息源和自己有关系的（positive & negative +1， general不变， 没有关系 -1）
% 系统2：short-term --> long-term memory：（计算过程比系统1的更复杂，需要参考的内容更多）
% 1.之前所有轮次自己发送消息最多的信息源
% 2.本轮所有信息源发的信息和各自之前发的信息的熵值变化


% 人的注意力会被哪些信息吸引
% 按照什么标准选择重要的信息 增加什么内容来增强重要性
% 算法 agent的注意力系统 为什么有这个算法来计算agent 的attention
% transformer的attention 在pre-training过程中存在attention计算的bias
% attention 缺点 lost in the middle
% agent的attention来辅助处理 （从人的角度应该注意什么）


% 新闻学中会通过relevance、信息源quote，（一般会关注信息内容本身和信息源）
% ...来修改标题、更改重点，所以我们会通过这些来判断agent是否会重视某些信息，如果agent会重视这个信息，则增强这个信息的present pattern

% 【Global Work Space Theory】多种信息会争夺agent的注意力
% 【Attention Schema Theory】agent会倾向于去做当前注意的事，不在意的事去做的可能性会小很多


% 【Dual-Process Theories】agent处理不同信息主要分两个系统，即xxx过程和xxx过程


% 初始agent的profile的不同有什么意义，单纯的不同的群众 还是 对于信息的理解能力不同
% 是不是对于profile的不同有明确的定义才会让analysis更有意义？比如不同理解能力的agent对于同样信息的解读不同？

% 什么造成信息不对称（实验中的settings都会一起导致不同程度的不对称）
% 信息内容√、分发机制√、agent对信息的理解能力？


% 顺序排列权重信息集，除了加重显示之外，权重越低的信息越接近input到llm的长文本的中间位置，从而让agent的attention信息和llm本身的attention机制的特点进行配合
% relationship 主观
% new agent
% llm decision making










