\section{Introduction}
\label{sec:intro}

% Word similarity serves as a cornerstone for various tasks, including measuring word sense change \cite{}, detecting biases in language \cite{}, and understanding contested concepts like art, nature, and market \cite{}.
Semantic similarity measures allow computational social scientists, digital humanists, and NLP practitioners to perform fine-grained synchronic and diachronic analysis on word meaning, with important applications to areas like cultural analytics and legal and historical document analysis \cite{bhattacharya2020methods, rios2012dissimilarity}. 

The cosine between two embedding vectors is the most commonly used similarity metric for textual analysis across a variety of fields 
%including the digital humanities 
\cite{johri-etal-2011-study, caliskan2017semantics, manzini-etal-2019-black, martinc-etal-2020-leveraging}. However, it neither accounts for the multi-faceted nature of similarity  \cite[inter alia]{tversky1977features, ettinger2016evaluating, zhou2022problems} nor does it align exactly with how humans perceive similarity \cite{nematzadeh2017evaluating}. Cosine similarity is dominated by a small number of rogue dimensions due to the anisotropy of contextual embedding spaces \cite{timkey2021all, ethayarajh2019contextual}, underestimates the semantic similarity of high-frequency words \citep{zhou2022problems}, is a symmetric metric that cannot capture the asymmetry of semantic relationships\footnote{For example, human similarity judgments are known to be directional; \textit{``cat''} is more similar to \textit{``animal'}' than \textit{``animal''} is to \textit{``cat''}.} \citep{vilnis2014word}, and often fails in capturing human interpretation \cite{sitikhu2019comparison}. 

Here, we propose to think about concept similarity metrics differently. We are inspired by \citet{tversky1977features}'s seminal work on similarity, presuming that humans have a rich mental representation of concepts. When faced with a particular task, like similarity assessment, we extract and compile from this rich representation only the relevant features for the required task. This formulation highlights the multi-faceted and context-dependent nature of similarity judgments \cite{evers2014revisiting}.
 
To demonstrate the potential of this new framing, we introduce a proof-of-concept: \wc, a self-supervised method that {\bf defines the semantic similarity between words according to a classifier's confusion between them}. In a nutshell, we first train a classifier to map from a word embedding to the word itself, distinguishing it from a set of distractors. At inference time, given a new embedding $e$ for a target word $t$, the probability the classifier assigns to a confound word $c$ is used as a measure of similarity of words $c$ and $t$. The set of distractor words used in training act as \textit{features}, thus, the \textbf{similarity between words is based on their feature interchangeability}. 

\begin{figure*}[h!]
    \centering
    \begin{subfigure}[]{0.47\textwidth}
        \centering
        \label{fig:word_confusion_a}
        \includegraphics[width=\textwidth]{Images/TrainingConceptTracing.jpg}
        \caption{Training \wc: The classifier is trained in a self-supervised manner, after selecting the desired features (in this example the classes red, green blue). We extract sentences containing those 3 ``feature'' words. The input to the classifier is the contextual embedding of the class token, e.g., the BERT embedding of the word ``red'' in the sentence ``The sunset painted the sky a brilliant shade of red''. The classifier is trained to predict a class (``red'') from that contextual embedding.}
    \end{subfigure}
% \par\bigskip
\qquad
% \par\medskip
    \begin{subfigure}[]{0.47\textwidth}
        \centering
        \label{fig:word_confusion_b}
        \includegraphics[width=\textwidth]{Images/InferenceConceptTracing0.jpg}
        \caption{\wc inference: We are given the classifier and the predetermined set of classes, which will act as features, in this case red, green, blue. 
        Given a target word in a sentence, e.g., \textit{``burgundy''}, we extract its contextual embedding in that sentence $e_{\text{burgundy}}$ and compute $P(w_i|e_{\text{burgundy}})$ for each class $i$. The classifier's confusion matrix then define the similarity of the burgundy with each class. The input word can be one of the feature words (red, green, blue) or not (burgundy).}
     \end{subfigure}
\par\medskip
    \caption{{\wc}: We predetermine a set of classes for our classifier, in this case \{red, green, blue\}. This choice of classes defines the similarity features used to describe the input word. At training, we extract sentences containing the chosen class words \{red,\ green,\ blue\}. We then train the classifier to map from a BERT contextual embeddings of these words to right class \slash feature (color, in this case). At inference, we extract BERT's contextual embeddings of a target word, that may be a class (red) or may be a new word  (\textit{``burgundy''}). We then input the embedding to the classifier and use its confusion matrix to understand which primary colors burgundy is similar to.}
    \label{fig:word_confusion}
    % \par\medskip
\end{figure*}


We test \wc on standard word-similarity tasks like sentiment and grammatical gender classification and show that it is comparable to standard cosine similarity and can be more meaningful. We then apply \wc to real-world data exploration tasks in collaboration with the fourth author, who is a scholar of French literature and history. We use the {\em Archive Parlementaires} from 1789-1793 to study a long debated question in the political history of revolutionary France: how ``revolution'' went from being seen as a means of popular liberation, to becoming identified with governmental actions that often flouted such personal freedoms. 

% We do this by measuring the \wc similarity of the French word ``revolution'' to different sets of words in the French {\em Archive Parlementaires} from 1789-1793. 

\noindent In summary, our paper:
\begin{enumerate}[itemsep=0pt]
   \item Proposes a novel framing of semantic similarity, inspired by cognitive models and sensitive to the blind spots of cosine similarity. Our new formulation can learn more complex word identity boundaries than cosine similarity alone; accounts for the asymmetrical nature of semantic similarity; can be easily adapted to desired domains; and provides a more interpretable measure. 
   \item Implements a proof-of-concept of our new framing of similarity, showing it is comparable to cosine on standard semantic similarity benchmarks.\footnote{Our data and code can be found: \url{https://github.com/sally9805/word-confusion}}
   \item Applies our method to real-world data, showcasing its potential for analyzing word meaning and temporal trends.
\end{enumerate}

We hope this new formulation will spark the creation of tools for cultural analytics and computational social science that account for the multi-faceted and complex nature of semantic similarity.  

