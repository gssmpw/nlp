%Word similarity is critical in its applications to humanistic and social science tasks, such as measuring semantic changes over time, detecting biases, and making sense of contested terms. Yet, traditional similarity methods based on cosine similarity between word embeddings falls short in capturing the context-dependent, asymmetrical, polysemous nature of semantic similarity. Inspired by \citet{tversky1977features}'s cognitive model of conceptual tasks, we propose a new measure of similarity focused on extracting and compiling context-relevant features. We present \wc, a model that reframes semantic similarity in terms of feature-based \textit{classification confusion}. Specifically, we train a classifier to map contextual embeddings to word identities and use the classifier confusion (the probability of choosing a confounding word $c$ instead of the correct target word $t$) as a measure of the similarity of $c$ and $t$. Our method outperforms cosine similarity in matching human similarity judgments across several datasets (MEN, WirdSim353, and SimLex), can measure similarity using predetermined features of interest, and enables qualitative analysis of real-world data. 
Word similarity has many applications to social science and cultural analytics tasks like measuring meaning change over time and making sense of contested terms. 
Yet traditional similarity methods based on cosine similarity between word embeddings 
cannot capture the context-dependent, asymmetrical, polysemous nature of semantic similarity.
We propose a new measure of similarity,  \wc,
that reframes semantic similarity in terms of feature-based \textit{classification confusion}.
\wc is inspired by \citet{tversky1977features}'s suggestion
that similarity features be chosen dynamically.
Here we train a classifier to map contextual embeddings to word identities and use the classifier confusion (the probability of choosing a confounding word $c$ instead of the correct target word $t$) as a measure of the similarity of $c$ and $t$. The set of potential confounding words acts as the chosen features. Our method is comparable to cosine similarity in matching human similarity judgments across several datasets
(MEN, WirdSim353, and SimLex), and can measure similarity using predetermined features of interest.
We demonstrate our model's ability to make use of dynamic features by applying it to test a hypothesis about changes in the 18th C. meaning of the French word \textit{``r√©volution''} from {\em popular} to {\em state} action during the French Revolution. 
We hope this reimagining of semantic similarity will inspire the development of new tools that better capture the multi-faceted and dynamic nature of language, advancing the fields of computational social science and cultural analytics and beyond.