\section{Related Work on Cultural Change}
\label{sec:related_work}

%Understanding if and how distributional models understand semantic knowledge (e.g., is ``dog'' a mammal) is an important research question. For example, \citet{rubinstein-etal-2015-well} show that static distributional embeddings capture well taxonomical properties, but do not perform well in general attributive semantics (e.g., predicting the color of something). Recently, large language models were shown to \textit{have} some knowledge about concepts~\cite{dalvi2022discovering,ettinger2020bert,weir2020probing,petroni2019language}, including word sense in their contextualized embeddings~\cite{reif2019visualizing}. However, their encoded knowledge is static and lacks structure and domain specificity \cite{brandl}.

%\cnote{..}

%\paragraph{Word similarity.} Cosine similarity is a standard measure of semantic similarity, but its effectiveness is limited by the representational geometry of learned embeddings. The anisotropy of contextualized embedding spaces causes a small number of rogue dimensions to dominate cosine similarity computations \citep{timkey2021all}.
%Further, cosine similarity underestimates the semantic similarity of high-frequency words \citep{zhou2022problems}, heavily depends on the regularization techniques used during training \citep{steck2024cosine} and often fails in capturing human interpretation \cite{sitikhu2019comparison}. The proposed \wc enables a similarity measure that sidesteps these limitations via softmax-normalized dot products.



% % Recent work has explored the limits of cosine similarity


%\paragraph{Asymmetry.} By definition, cosine similarity is a symmetric metric that cannot capture the asymmetry of semantic relationships \citep{vilnis2014word}. Efforts to account for this caveat show partial successes, emphasizing the inherent symmetrical nature of cosine similarity using some language model embeddings \citet{zhang2021circles, rodriguez2020word}.

%\paragraph{Word embeddings for semantic and cultural change.} 
Both static and contextualized embedding spaces contain semantically meaning dimensions that align with high-level linguistic and cultural features \citep{bolukbasi2016man, DBLP:journals/corr/abs-1906-02715}. These embeddings have enabled a large number of quantitative analyses of temporal shifts in meaning and links to cultural or social scientific variables. For example early on, using static embeddings, \citet{hamilton2016cultural} measured linguistic drifts in global semantic space as well as cultural shifts in particular local semantic neighborhoods. \citet{garg2018word} demonstrated that changes in word embeddings correlated with demographic and occupation shifts through the 1900s.

Analyzes of contextualized embeddings have identified semantic axes based on pairs of ``seed words'' or ``poles'' \citep{soler2020bert, lucy2022discovering, grand2022semantic}. Across the temporal dimension, such axes can measure the evolution of gender and class \citep{kozlowski2019geometry}, internet slang \citep{keidar-etal-2022-slangvolution}, and more \citep{madani2023measuring, lyu2023representation, erk2024adjusting}. \citet{bravzinskas2017embedding} proposes a probabilistic measure for lexical similarity. 

It's also instructive to consider the similarity of our method  with tasks like word sense disambiguation (WSD) and named entity recognition (NER). The central idea behind \wc of mapping from embeddings to categories are also found in NER and WSD. What differs is the dynamic nature of the categories. Where NER focuses on pre-defined concept hierarchies and WSD on pre-defined senses per word,  \wc  focuses on a coherent but dynamic grouping of words that is interpretable for a given task.

% an important direction for future work in computational social science (see 3.1.10 in \citet{ziems2023can}).

% \subsection{Semantic change}


% Survey \citep{de2024survey} (should prob look more)

% Diachronic word embeddings 

%  \citet{di2019training}






% Similarly to named entity recognition, \ac{ourmethod} attempts to map words to classes that \textit{might be} types (such as ORGANIZATION or PLACE). However, \ac{ourmethod} is partially self-supervised and it is entirely user-driven.

% Similarly to semantic change detection, \ac{ourmethod} attempts to capture the usage of a word in different contexts. However, \ac{ourmethod} offers the possibility of defining the axis (the seed words) onto which the user wants to project words. 

