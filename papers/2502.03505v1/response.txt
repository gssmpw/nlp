\section{Related Works}
\label{sec:Related_Works}

Traditional approaches exploited tissue speckle patterns in US B-mode images, 
as speckle content between successive frames tends to be preserved, 
even in out-of-plane  motions. 
Since the pioneering work by Trahey et al. **Trahey, "Automatic signal processing for detection of echoes"**,
several studies have focused on estimating scan motion by analyzing the correlation 
between adjacent frames **Kaufhold, "Motion estimation and compensation in freehand ultrasound imaging"**.
Gee et al. **Gee, "Adaptive speckle decorrelation technique for real-time US imaging"**
proposed an adaptive speckle decorrelation technique, 
leading to improved performance. 
These studies have demonstrated the feasibility of sensorless free-hand US 
through gradual improvements in various factors such as estimation accuracy, 
generalizability, and less constrained scan protocols.

With the rapid advancements in DL, 
Prevost et al. **Prevost, "3D ultrasound volume reconstruction using a convolutional neural network"**
were the first to attempt 3D US volume reconstruction 
using a convolutional neural network (CNN).
Guo et al. **Guo, "Deep contextual learning for freehand ultrasound imaging"**
introduced a deep contextual learning network (DCL-Net), 
utilizing 3D convolution to exploit the sequential context information in US scan frames, 
along with an innovative loss function based on correlation values. 
Building on this, Guo et al. **Guo, "Deep contextual-contrastive learning for freehand ultrasound imaging"**
expanded their previous work 
by developing a deep contextual-contrastive network (DC\textsuperscript{2}-Net), 
which applied a margin triplet loss for contrastive learning in a regression task.

Around the same time, 
Luo et al. **Luo, "RNN-based model with self-supervised and adversarial learning strategy"**
made key contributions to free-hand US imaging 
by proposing an RNN-based model with a novel self-supervised and adversarial learning strategy. 
This approach enabled plausible visual reconstructions, 
even in more challenging scanning scenarios. 
Luo et al. continued their active contributions with the development of MoNet, 
a motion network incorporating an inertial measurement unit (IMU) sensor, 
a lightweight sensor for capturing acceleration data **Luo, "Motion network with IMU sensor"**.
Their multi-branch DL architecture leveraged both US images and IMU sensor data for improved performance. 
In later work, Luo et al. utilized multiple IMU sensors to further enhance reconstruction accuracy **Luo, "Multi-sensor motion estimation for freehand ultrasound imaging"**.

Recently, Luo et al. **Luo, "Online learning reconstruction framework for freehand ultrasound imaging"**
introduced an online learning reconstruction framework (RecON), 
imposing constraints such as motion-weighted training loss, frame-level contextual consistency, 
and path-label similarity, which significantly improved the accuracy of motion estimation 
in complex scan motions. 
Other recent DL approaches have adapted popular models for US imaging. 
Miura et al. **Miura, "Sequential CNN-RNN structure for relative and absolute pose estimation"**
proposed a sequential CNN-RNN structure 
for both relative and absolute pose estimation, 
demonstrating the efficacy of relative pose integration via RNNs. 
Inspired by pyramid warping techniques **Riemenschneider et al., "Pyramid warping for image registration"**, 
Xie et al. **Xie, "Multiscale feature extraction for freehand ultrasound imaging"**
developed a network 
that extracts multi-scale features from US frames 
to better capture low-frequency B-mode information. 
With the increasing popularity of transformers, 
Ning et al. **Ning, "Transformer-based pose estimation for freehand ultrasound imaging"**
applied a transformer architecture 
to combine local and long-range information from a CNN-based backbone encoder and IMU sensors. 
Li et al. **Li, "Long-term dependencies in sequential US frames for motion estimation"**
further identified long-term dependencies 
between sequential US frames and the influence of anatomical or scan protocol factors.

Despite these advancements, achieving the level of precision required for clinical applications remains a challenge. Many existing methods have not been validated on extensive, real-world datasets, nor have they adequately addressed the effects of image processing techniques, such as speckle reduction, which can distort critical information in B-mode images. Furthermore, there has been limited exploration of adapting these DL-based methods for other imaging modes, such as power Doppler (PD) and photoacoustic (PA) imaging.

The potential of DL-based scan motion tracking systems to enable vascular visualization over large regions is significant. By integrating optimized ultrasound and laser sequencing, raw data reconstruction, and post-processing techniques, these systems can extend their utility to PA imaging and PD-mode US imaging. Such advancements promise to open new avenues for clinical applications, including more accurate visualization of vascular structures and enhanced interventional guidance.