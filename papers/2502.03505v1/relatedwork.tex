\section{Related Works}
\label{sec:Related_Works}

Traditional approaches exploited tissue speckle patterns in US B-mode images, 
as speckle content between successive frames tends to be preserved, 
even in out-of-plane  motions. 
Since the pioneering work by Trahey et al. \cite{trahey_1986_SD_0}, 
several studies have focused on estimating scan motion by analyzing the correlation 
between adjacent frames \cite{chen_1997_SD_1, tuthill_1998_SD_2}. 
Gee et al. \cite{gee_2006_SD_3} proposed an adaptive speckle decorrelation technique, 
leading to improved performance. 
These studies have demonstrated the feasibility of sensorless free-hand US 
through gradual improvements in various factors such as estimation accuracy, 
generalizability, and less constrained scan protocols.

With the rapid advancements in DL, 
Prevost et al. \cite{prevost_2018_CNN} were the first to attempt 3D US volume reconstruction 
using a convolutional neural network (CNN).
Guo et al. \cite{guo_2020_DCL} introduced a deep contextual learning network (DCL-Net), 
utilizing 3D convolution to exploit the sequential context information in US scan frames, 
along with an innovative loss function based on correlation values. 
Building on this, Guo et al. \cite{guo_2022_DC2} expanded their previous work 
by developing a deep contextual-contrastive network (DC\textsuperscript{2}-Net), 
which applied a margin triplet loss for contrastive learning in a regression task.

Around the same time, 
Luo et al. \cite{luo_2021_LSTM} made key contributions to free-hand US imaging 
by proposing an RNN-based model with a novel self-supervised and adversarial learning strategy. 
This approach enabled plausible visual reconstructions, 
even in more challenging scanning scenarios. 
Luo et al. continued their active contributions with the development of MoNet, 
a motion network incorporating an inertial measurement unit (IMU) sensor, 
a lightweight sensor for capturing acceleration data \cite{luo_2022_MoNet}. 
Their multi-branch DL architecture leveraged both US images and IMU sensor data for improved performance. 
In later work, Luo et al. utilized multiple IMU sensors to further enhance reconstruction accuracy \cite{luo_2023_OSCNet}.

Recently, Luo et al. \cite{luo_2023_RecO} 
introduced an online learning reconstruction framework (RecON), 
imposing constraints such as motion-weighted training loss, frame-level contextual consistency, 
and path-label similarity, which significantly improved the accuracy of motion estimation 
in complex scan motions. 
Other recent DL approaches have adapted popular models for US imaging. 
Miura et al. \cite{miura_2021_Absolute_pose} proposed a sequential CNN-RNN structure 
for both relative and absolute pose estimation, 
demonstrating the efficacy of relative pose integration via RNNs. 
Inspired by pyramid warping techniques \cite{tehrani_2020_PWC_Net}, 
Xie et al. \cite{xie_2021_PW_Net} developed a network 
that extracts multi-scale features from US frames 
to better capture low-frequency B-mode information. 
With the increasing popularity of transformers, 
Ning et al. \cite{ning_2022_transformer} applied a transformer architecture 
to combine local and long-range information from a CNN-based backbone encoder and IMU sensors. 
Li et al. \cite{li_2023_EfficientNet} further identified long-term dependencies 
between sequential US frames and the influence of anatomical or scan protocol factors.

Despite these advancements, achieving the level of precision required for clinical applications remains a challenge. Many existing methods have not been validated on extensive, real-world datasets, nor have they adequately addressed the effects of image processing techniques, such as speckle reduction, which can distort critical information in B-mode images. Furthermore, there has been limited exploration of adapting these DL-based methods for other imaging modes, such as power Doppler (PD) and photoacoustic (PA) imaging.

The potential of DL-based scan motion tracking systems to enable vascular visualization over large regions is significant. By integrating optimized ultrasound and laser sequencing, raw data reconstruction, and post-processing techniques, these systems can extend their utility to PA imaging and PD-mode US imaging. Such advancements promise to open new avenues for clinical applications, including more accurate visualization of vascular structures and enhanced interventional guidance.