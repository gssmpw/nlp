@article{asai2023self,
  title={Self-rag: Learning to retrieve, generate, and critique through self-reflection},
  author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2310.11511},
  year={2023}
}
@article{chen2017reading,
  title={Reading Wikipedia to answer open-domain questions},
  author={Chen, D},
  journal={arXiv preprint arXiv:1704.00051},
  year={2017}
}
@article{vrandevcic2014wikidata,
  title={Wikidata: a free collaborative knowledgebase},
  author={Vrande{\v{c}}i{\'c}, Denny and Kr{\"o}tzsch, Markus},
  journal={Communications of the ACM},
  volume={57},
  number={10},
  pages={78--85},
  year={2014},
  publisher={ACM New York, NY, USA}
}
@article{grootendorst2022bertopic,
  title={BERTopic: Neural topic modeling with a class-based TF-IDF procedure},
  author={Grootendorst, Maarten},
  journal={arXiv preprint arXiv:2203.05794},
  year={2022}
}

@article{yang2018enhancing,
  title={Enhancing learning and retrieval of new information: a review of the forward testing effect},
  author={Yang, Chunliang and Potts, Rosalind and Shanks, David R},
  journal={NPJ science of learning},
  volume={3},
  number={1},
  pages={8},
  year={2018},
  publisher={Nature Publishing Group UK London}
}
@article{ho2020constructing,
  title={Constructing a multi-hop QA dataset for comprehensive evaluation of reasoning steps},
  author={Ho, Xanh and Nguyen, Anh-Khoa Duong and Sugawara, Saku and Aizawa, Akiko},
  journal={arXiv preprint arXiv:2011.01060},
  year={2020}
}
@article{st1989analysis,
  title={Analysis of variance (ANOVA)},
  author={St, Lars and Wold, Svante and others},
  journal={Chemometrics and intelligent laboratory systems},
  volume={6},
  number={4},
  pages={259--272},
  year={1989},
  publisher={Elsevier}
}
@article{zhang2024accelerating,
  title={Accelerating retrieval-augmented language model serving with speculation},
  author={Zhang, Zhihao and Zhu, Alan and Yang, Lijie and Xu, Yihua and Li, Lanting and Phothilimthana, Phitchaya Mangpo and Jia, Zhihao},
  journal={arXiv preprint arXiv:2401.14021},
  year={2024}
}
@article{schulhoff2024prompt,
  title={The Prompt Report: A Systematic Survey of Prompting Techniques},
  author={Schulhoff, Sander and Ilie, Michael and Balepur, Nishant and Kahadze, Konstantine and Liu, Amanda and Si, Chenglei and Li, Yinheng and Gupta, Aayush and Han, HyoJung and Schulhoff, Sevien and others},
  journal={arXiv preprint arXiv:2406.06608},
  year={2024}
}
@article{trivedi2022interleaving,
  title={Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions},
  author={Trivedi, Harsh and Balasubramanian, Niranjan and Khot, Tushar and Sabharwal, Ashish},
  journal={arXiv preprint arXiv:2212.10509},
  year={2022}
}
@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}
@article{shao2023enhancing,
  title={Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy},
  author={Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Huang, Minlie and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2305.15294},
  year={2023}
}
@article{sun2022recitation,
  title={Recitation-augmented language models},
  author={Sun, Zhiqing and Wang, Xuezhi and Tay, Yi and Yang, Yiming and Zhou, Denny},
  journal={arXiv preprint arXiv:2210.01296},
  year={2022}
}
@article{badshah2024reference,
  title={Reference-Guided Verdict: LLMs-as-Judges in Automatic Evaluation of Free-Form Text},
  author={Badshah, Sher and Sajjad, Hassan},
  journal={arXiv preprint arXiv:2408.09235},
  year={2024}
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}
@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}
@article{raiaan2024review,
  title={A review on large Language Models: Architectures, applications, taxonomies, open issues and challenges},
  author={Raiaan, Mohaimenul Azam Khan and Mukta, Md Saddam Hossain and Fatema, Kaniz and Fahad, Nur Mohammad and Sakib, Sadman and Mim, Most Marufatul Jannat and Ahmad, Jubaer and Ali, Mohammed Eunus and Azam, Sami},
  journal={IEEE Access},
  year={2024},
  publisher={IEEE}
}
@article{kwiatkowski2019natural,
  title={Natural questions: a benchmark for question answering research},
  author={Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={453--466},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@article{press2022measuring,
  title={Measuring and narrowing the compositionality gap in language models},
  author={Press, Ofir and Zhang, Muru and Min, Sewon and Schmidt, Ludwig and Smith, Noah A and Lewis, Mike},
  journal={arXiv preprint arXiv:2210.03350},
  year={2022}
}
@inproceedings{fan2024survey,
  title={A survey on rag meeting llms: Towards retrieval-augmented large language models},
  author={Fan, Wenqi and Ding, Yujuan and Ning, Liangbo and Wang, Shijie and Li, Hengyun and Yin, Dawei and Chua, Tat-Seng and Li, Qing},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={6491--6501},
  year={2024}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{tang2024multihop,
      title={MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries}, 
      author={Yixuan Tang and Yi Yang},
      journal={arXiv preprint arXiv:2401.15391},
      year={2024},
}

@article{wang2024chainofthought,
      title={Chain-of-Thought Reasoning Without Prompting}, 
      author={Xuezhi Wang and Denny Zhou},
      journal={arXiv preprint arXiv:2402.10200},
      year={2024},
}
@inproceedings{islam2024gemini,
  title={Gemini-the most powerful LLM: Myth or Truth},
  author={Islam, Raisa and Ahmed, Imtiaz},
  booktitle={2024 5th Information Communication Technologies Conference (ICTC)},
  pages={303--308},
  year={2024},
  organization={IEEE}
}
@article{chandak2023building,
  title={Building a knowledge graph to enable precision medicine},
  author={Chandak, Payal and Huang, Kexin and Zitnik, Marinka},
  journal={Scientific Data},
  volume={10},
  number={1},
  pages={67},
  year={2023},
  publisher={Nature Publishing Group UK London}
}
@article{lee2020biobert,
  title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}

@article{yang2024low,
  title={A Low-Density Parity-Check Coding Scheme for LoRa Networking},
  author={Yang, Kang and Du, Wan},
  journal={ACM Transactions on Sensor Networks},
  year={2024},
  publisher={ACM New York, NY}
}

@article{singhal2022large,
  title={Large language models encode clinical knowledge},
  author={Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others},
  journal={arXiv preprint arXiv:2212.13138},
  year={2022}
}
@article{xia2024mmed,
  title={Mmed-rag: Versatile multimodal rag system for medical vision language models},
  author={Xia, Peng and Zhu, Kangyu and Li, Haoran and Wang, Tianze and Shi, Weijia and Wang, Sheng and Zhang, Linjun and Zou, James and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2410.13085},
  year={2024}
}
@article{singhal2023large,
  title={Large language models encode clinical knowledge},
  author={Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others},
  journal={Nature},
  volume={620},
  number={7972},
  pages={172--180},
  year={2023},
  publisher={Nature Publishing Group}
}
@article{gu2021domain,
  title={Domain-specific language model pretraining for biomedical natural language processing},
  author={Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
  journal={ACM Transactions on Computing for Healthcare (HEALTH)},
  volume={3},
  number={1},
  pages={1--23},
  year={2021},
  publisher={ACM New York, NY}
}
@article{huang2021knowledge,
  title={A knowledge graph based question answering method for medical domain},
  author={Huang, Xiaofeng and Zhang, Jixin and Xu, Zisang and Ou, Lu and Tong, Jianbin},
  journal={PeerJ Computer Science},
  volume={7},
  pages={e667},
  year={2021},
  publisher={PeerJ Inc.}
}
@article{saab2024capabilities,
  title={Capabilities of gemini models in medicine},
  author={Saab, Khaled and Tu, Tao and Weng, Wei-Hung and Tanno, Ryutaro and Stutz, David and Wulczyn, Ellery and Zhang, Fan and Strother, Tim and Park, Chunjong and Vedadi, Elahe and others},
  journal={arXiv preprint arXiv:2404.18416},
  year={2024}
}
@inproceedings{nazi2024large,
  title={Large language models in healthcare and medical domain: A review},
  author={Nazi, Zabir Al and Peng, Wei},
  booktitle={Informatics},
  volume={11},
  pages={57},
  year={2024},
  organization={MDPI}
}
@article{liu2023utility,
  title={Utility of ChatGPT in clinical practice},
  author={Liu, Jialin and Wang, Changyu and Liu, Siru},
  journal={Journal of Medical Internet Research},
  volume={25},
  pages={e48568},
  year={2023},
  publisher={JMIR Publications Toronto, Canada}
}
@article{rezaei2024rag,
  title={AT-RAG: An Adaptive RAG Model Enhancing Query Efficiency with Topic Filtering and Iterative Reasoning},
  author={Rezaei, Mohammad Reza and Hafezi, Maziar and Satpathy, Amit and Hodge, Lovell and Pourjafari, Ebrahim},
  journal={arXiv preprint arXiv:2410.12886},
  year={2024}
}
@article{rohanian2024exploring,
  title={Exploring the effectiveness of instruction tuning in biomedical language processing},
  author={Rohanian, Omid and Nouriborji, Mohammadmahdi and Kouchaki, Samaneh and Nooralahzadeh, Farhad and Clifton, Lei and Clifton, David A},
  journal={Artificial intelligence in medicine},
  volume={158},
  pages={103007},
  year={2024},
  publisher={Elsevier}
}
@article{zhou2023survey,
  title={A survey of large language models in medicine: Progress, application, and challenge},
  author={Zhou, Hongjian and Liu, Fenglin and Gu, Boyang and Zou, Xinyu and Huang, Jinfa and Wu, Jinge and Li, Yiru and Chen, Sam S and Zhou, Peilin and Liu, Junling and others},
  journal={arXiv preprint arXiv:2311.05112},
  year={2023}
}
@article{yu2024large,
  title={Large language models in biomedical and health informatics: A review with bibliometric analysis},
  author={Yu, Huizi and Fan, Lizhou and Li, Lingyao and Zhou, Jiayan and Ma, Zihui and Xian, Lu and Hua, Wenyue and He, Sijia and Jin, Mingyu and Zhang, Yongfeng and others},
  journal={Journal of Healthcare Informatics Research},
  pages={1--54},
  year={2024},
  publisher={Springer}
}
@article{yang2024kg,
  title={Kg-rank: Enhancing large language models for medical qa with knowledge graphs and ranking techniques},
  author={Yang, Rui and Liu, Haoran and Marrese-Taylor, Edison and Zeng, Qingcheng and Ke, Yu He and Li, Wanxin and Cheng, Lechao and Chen, Qingyu and Caverlee, James and Matsuo, Yutaka and others},
  journal={arXiv preprint arXiv:2403.05881},
  year={2024}
}
@article{chen2023meditron,
  title={Meditron-70b: Scaling medical pretraining for large language models},
  author={Chen, Zeming and Cano, Alejandro Hern{\'a}ndez and Romanou, Angelika and Bonnet, Antoine and Matoba, Kyle and Salvi, Francesco and Pagliardini, Matteo and Fan, Simin and K{\"o}pf, Andreas and Mohtashami, Amirkeivan and others},
  journal={arXiv preprint arXiv:2311.16079},
  year={2023}
}
@article{lievin2024can,
  title={Can large language models reason about medical questions?},
  author={Li{\'e}vin, Valentin and Hother, Christoffer Egeberg and Motzfeldt, Andreas Geert and Winther, Ole},
  journal={Patterns},
  volume={5},
  number={3},
  year={2024},
  publisher={Elsevier}
}
@inproceedings{lievin2023variational,
  title={Variational open-domain question answering},
  author={Li{\'e}vin, Valentin and Motzfeldt, Andreas Geert and Jensen, Ida Riis and Winther, Ole},
  booktitle={International Conference on Machine Learning},
  pages={20950--20977},
  year={2023},
  organization={PMLR}
}

@inproceedings{pal2022medmcqa,
  title={Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering},
  author={Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},
  booktitle={Conference on health, inference, and learning},
  pages={248--260},
  year={2022},
  organization={PMLR}
}
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}


@article{jin2021disease,
  title={What disease does this patient have? a large-scale open domain question answering dataset from medical exams},
  author={Jin, Di and Pan, Eileen and Oufattole, Nassim and Weng, Wei-Hung and Fang, Hanyi and Szolovits, Peter},
  journal={Applied Sciences},
  volume={11},
  number={14},
  pages={6421},
  year={2021},
  publisher={MDPI}
}

@InProceedings{pmlr-v174-pal22a,
  title = 	 {MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering},
  author =       {Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},
  booktitle = 	 {Proceedings of the Conference on Health, Inference, and Learning},
  pages = 	 {248--260},
  year = 	 {2022},
  editor = 	 {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
  volume = 	 {174},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {07--08 Apr},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v174/pal22a/pal22a.pdf},
  url = 	 {https://proceedings.mlr.press/v174/pal22a.html},
  abstract = 	 {This paper introduces MedMCQA, a new large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions. More than 194k high-quality AIIMS &amp; NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity. Each sample contains a question, correct answer(s), and other options which requires a deeper language understanding as it tests the 10+ reasoning abilities of a model across a wide range of medical subjects &amp; topics. A detailed explanation of the solution, along with the above information, is provided in this study.}
}


@inproceedings{miller2011investigation,
  title={An investigation into the feasibility of spoken clinical question answering},
  author={Miller, Tim and Ravvaz, Kourosh and Cimino, James J and Yu, Hong},
  booktitle={AMIA Annual Symposium Proceedings},
  volume={2011},
  pages={954},
  year={2011},
  organization={American Medical Informatics Association}
}

@article{si2024interpretabnet,
  title={InterpreTabNet: Distilling Predictive Signals from Tabular Data by Salient Feature Interpretation},
  author={Si, Jacob and Cheng, Wendy Yusi and Cooper, Michael and Krishnan, Rahul G},
  journal={arXiv preprint arXiv:2406.00426},
  year={2024}
}

@article{sullivan2013analyzing,
  title={Analyzing and interpreting data from Likert-type scales},
  author={Sullivan, Gail M and Artino Jr, Anthony R},
  journal={Journal of graduate medical education},
  volume={5},
  number={4},
  pages={541--542},
  year={2013},
  publisher={The Accreditation Council for Graduate Medical Education Suite 2000, 515~…}
}

@article{mchugh2012interrater,
  title={Interrater reliability: the kappa statistic},
  author={McHugh, Mary L},
  journal={Biochemia medica},
  volume={22},
  number={3},
  pages={276--282},
  year={2012},
  publisher={Medicinska naklada}
}

@inproceedings{huang2013research,
  title={Research on architecture and query performance based on distributed graph database Neo4j},
  author={Huang, Hongcheng and Dong, Ziyu},
  booktitle={2013 3rd International Conference on Consumer Electronics, Communications and Networks},
  pages={533--536},
  year={2013},
  organization={IEEE}
}

@article{besta2023demystifying,
  title={Demystifying graph databases: Analysis and taxonomy of data organization, system designs, and graph queries},
  author={Besta, Maciej and Gerstenberger, Robert and Peter, Emanuel and Fischer, Marc and Podstawski, Micha{\l} and Barthels, Claude and Alonso, Gustavo and Hoefler, Torsten},
  journal={ACM Computing Surveys},
  volume={56},
  number={2},
  pages={1--40},
  year={2023},
  publisher={ACM New York, NY}
}
@article{luo2022biogpt,
  title={BioGPT: generative pre-trained transformer for biomedical text generation and mining},
  author={Luo, Renqian and Sun, Liai and Xia, Yingce and Qin, Tao and Zhang, Sheng and Poon, Hoifung and Liu, Tie-Yan},
  journal={Briefings in bioinformatics},
  volume={23},
  number={6},
  pages={bbac409},
  year={2022},
  publisher={Oxford University Press}
}
@article{yu2024rankrag,
  title={Rankrag: Unifying context ranking with retrieval-augmented generation in llms},
  author={Yu, Yue and Ping, Wei and Liu, Zihan and Wang, Boxin and You, Jiaxuan and Zhang, Chao and Shoeybi, Mohammad and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:2407.02485},
  year={2024}
}
@article{taylor2022galactica,
  title={Galactica: A large language model for science},
  author={Taylor, Ross and Kardas, Marcin and Cucurull, Guillem and Scialom, Thomas and Hartshorn, Anthony and Saravia, Elvis and Poulton, Andrew and Kerkez, Viktor and Stojnic, Robert},
  journal={arXiv preprint arXiv:2211.09085},
  year={2022}
}
@article{jin2019pubmedqa,
  title={Pubmedqa: A dataset for biomedical research question answering},
  author={Jin, Qiao and Dhingra, Bhuwan and Liu, Zhengping and Cohen, William W and Lu, Xinghua},
  journal={arXiv preprint arXiv:1909.06146},
  year={2019}
}
@article{nori2023can,
  title={Can generalist foundation models outcompete special-purpose tuning? case study in medicine},
  author={Nori, Harsha and Lee, Yin Tat and Zhang, Sheng and Carignan, Dean and Edgar, Richard and Fusi, Nicolo and King, Nicholas and Larson, Jonathan and Li, Yuanzhi and Liu, Weishung and others},
  journal={arXiv preprint arXiv:2311.16452},
  year={2023}
}
@article{singhal2025toward,
  title={Toward expert-level medical question answering with large language models},
  author={Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Amin, Mohamed and Hou, Le and Clark, Kevin and Pfohl, Stephen R and Cole-Lewis, Heather and others},
  journal={Nature Medicine},
  pages={1--8},
  year={2025},
  publisher={Nature Publishing Group US New York}
}
@article{kim2024small,
  title={Small language models learn enhanced reasoning skills from medical textbooks},
  author={Kim, Hyunjae and Hwang, Hyeon and Lee, Jiwoo and Park, Sihyeon and Kim, Dain and Lee, Taewhoo and Yoon, Chanwoong and Sohn, Jiwoong and Choi, Donghee and Kang, Jaewoo},
  journal={arXiv preprint arXiv:2404.00376},
  year={2024}
}
@article{shakhadri2024shakti,
  title={SHAKTI: A 2.5 Billion Parameter Small Language Model Optimized for Edge AI and Low-Resource Environments},
  author={Shakhadri, Syed Abdul Gaffar and KR, Kruthika and Aralimatti, Rakshit},
  journal={arXiv preprint arXiv:2410.11331},
  year={2024}
}
@article{luo2023biomedgpt,
  title={Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine},
  author={Luo, Yizhen and Zhang, Jiahuan and Fan, Siqi and Yang, Kai and Wu, Yushuai and Qiao, Mu and Nie, Zaiqing},
  journal={arXiv preprint arXiv:2308.09442},
  year={2023}
}


@article{hager2024evaluation,
  title={Evaluation and mitigation of the limitations of large language models in clinical decision-making},
  author={Hager, Paul and Jungmann, Friederike and Holland, Robbie and Bhagat, Kunal and Hubrecht, Inga and Knauer, Manuel and Vielhauer, Jakob and Makowski, Marcus and Braren, Rickmer and Kaissis, Georgios and others},
  journal={Nature medicine},
  volume={30},
  number={9},
  pages={2613--2622},
  year={2024},
  publisher={Nature Publishing Group US New York}
}


@article{schulhoff2024prompt,
  title={The Prompt Report: A Systematic Survey of Prompting Techniques},
  author={Schulhoff, Sander and Ilie, Michael and Balepur, Nishant and Kahadze, Konstantine and Liu, Amanda and Si, Chenglei and Li, Yinheng and Gupta, Aayush and Han, HyoJung and Schulhoff, Sevien and others},
  journal={arXiv preprint arXiv:2406.06608},
  year={2024}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}
@misc{rezaei2025vendirag,
      title={Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs}, 
      author={Mohammad Reza Rezaei and Adji Bousso Dieng},
      year={2025},
      eprint={2502.11228},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.11228}, 
}