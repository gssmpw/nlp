\glsresetall
\section{Method}
\glspl{kg} offer structured frameworks for evidence-based reasoning. However, traditional \glspl{kg} struggle to adapt to dynamic and evolving queries, as well as the continuous influx of new research and evidence in the medical domain. To overcome this limitation in the medical \gls{qa} pipeline, we propose a novel approach that automatically constructs medical-\glspl{kg} using a combination of a \gls{llm} agent and a specialized medical search tool. This \gls{mkg} enhances medical \gls{qa} by tailoring the graph's construction and querying processes to each specific query. This section outlines the methodologies used to develop the \gls{mkg} and the \gls{myrag} pipeline, aimed at enhancing \gls{qa} systems with advanced capabilities for retrieval, reasoning, and generation.

\subsection{Retrieval Augmented Generation (RAG) for QA}

\gls{rag} is a framework designed to enhance \gls{qa} by integrating relevant external knowledge into the generation process. The framework combines retriever and generator components to ensure responses are grounded in evidence. Below, we outline various approaches within the \gls{rag} paradigm:

\subsubsection{RAG}
In the \gls{rag} approach, the retriever fetches a fixed number of relevant documents, $\{\rvd_1, \rvd_2, \ldots, \rvd_n\} \in \mathbf{D}$, based on the query $\rvq$. Here, $\mathbf{D}$ represents the set of all domain-specific documents utilized. These documents are concatenated and passed directly to a \gls{llm}-based text generator, $G$, which produces the answer $\hat{\rva}$:
\[
\hat{\rva} = G(\rvq, \{\rvd_1, \ldots, \rvd_n\}).
\]
This approach is simple and computationally efficient but may struggle with domain-specific or complex queries that require additional supporting evidence.

\subsubsection{RAG with Chain-of-Thought (CoT)}
Enhancing \gls{rag}'s performance can be achieved by integrating intermediate reasoning steps prior to producing the final response. The generator produces a chain of thought, $\rvc$, which serves as an explicit reasoning trace:
\[
\{\rvd_1, \ldots, \rvd_k\} = \text{Retriever}(\rvq; \mathbf{D}),\] \[\rvc = G(\rvq, \{\rvd_1, \ldots, \rvd_k\}),\quad \hat{\rva} = G(\rvc).
\]
This step-by-step approach enhances reasoning and interpretability, leading to improved accuracy in multi-hop reasoning tasks.

\subsubsection{RAG with Search}
The \glspl{rag}'s performance can improved further by incorporating additional related documents retrieved from external sources, such as the internet, through a search tool. This variant integrates external search capabilities into the retrieval process. For a query \(\rvq\), the retriever's results are combined with those from external search engines, providing more comprehensive evidence for the \gls{llm} to generate a response:  
\[
\{\rvd'_1, \ldots, \rvd'_m\} = \text{Search}(\rvq; \mathbf{D'}),
\]  
\[
\hat{\rva} = G(\rvq, \{\rvd_1, \ldots, \rvd_n, \rvd'_1, \ldots, \rvd'_m\}).
\]  
This additional search step significantly enhances performance, particularly in scenarios that require access to extensive and diverse knowledge.
\begin{figure*}[t]
    \centering
\includegraphics[width=.9\textwidth]{latex/Figures/Flowchart.png}
    \caption{Model Schema. A) The pipeline for creating the \gls{mkg} using search tools and an \gls{llm} agent. B) An example of the generated \gls{mkg} in Neo4J, illustrating nodes and relationships derived from search results and contextual information. C) The \gls{myrag} pipeline. D) A simplified \gls{rag} pipeline. }
    \label{fig:model_schema}
\end{figure*}

\subsection{Medical QA with AMG-RAG}
% The adoption of \gls{kg} for \gls{qa} addresses critical limitations of traditional retrieval-based approaches. Traditional methods often struggle with ensuring consistency, handling domain-specific queries, and providing reasoning grounded in structured knowledge. By contrast, \gls{kg}s represent information in a structured and interconnected manner, enabling precise and interpretable reasoning.

% By leveraging a \gls{kg}, a \gls{qa} system can seamlessly integrate domain-specific knowledge to ensure that answers are accurate and contextually relevant. This structured representation establishes relationships between entities, e.g., keywords in a question, facilitating complex multi-hop reasoning that goes beyond surface-level retrieval. Furthermore, \gls{kg}s inherently offer better explainability, providing clear evidence paths linking the query to the answer.

In scenarios requiring domain expertise, such as medical or scientific \gls{qa}, traditional methods often fail due to their inability to capture intricate domain-specific relationships or handle ambiguous queries. \gls{kg}-driven approaches overcome these challenges by integrating explicit relationships and structured knowledge representations. This marks a significant advancement in intelligent \gls{qa} systems, ensuring robustness and scalability across various applications.


Below, we introduce the proposed \gls{myrag} pipeline and outline the process for constructing the \gls{mkg}, which is detailed in the following section.

The \gls{myrag} pipeline consists of the following steps:
\begin{enumerate}
    \item \textbf{Question Parsing:} Extract medical terms $\{\rvn_1, \rvn_2, \ldots, \rvn_m\}$ from the user query $\rvq$ using an \gls{llm} agent:
    \[
    \{\rvn_1, \rvn_2, \ldots, \rvn_m\} = \text{LLM}(\rvq, M), \quad m \leq M.
    \]
    The \gls{llm} agent is instructed to extract the medical terms $\{\rvn_i\}_{i=1}^m$ associated with the query $\rvq$.

    \item \textbf{Node Exploration:} For each term $\rvn_i$, query the \gls{kg} to retrieve relevant information while applying a confidence threshold. This threshold determines the minimum level of relationship confidence required to include information from the \gls{kg}, filtering out relationships with confidence scores below the specified threshold. Details on the calculation of confidence scores can be found in Appendix \ref{app:confidence}. Nodes and their children are examined iteratively, with parent confidence scores, $s(\rvn_i)$, multiplied by their relationship scores, $s(\rvr_{ij})$, to compute child confidence:
    \[
    s(\rvn_j) = s(\rvn_i) \cdot s(\rvr_{ij}), \quad \forall j \in \text{children of } i.
    \]

    Both Breadth-First Search (BFS) and Depth-First Search (DFS) strategies can be employed to explore child nodes. BFS prioritizes covering all immediate neighbors at the current depth before moving deeper, ensuring comprehensive breadth-wise exploration. In contrast, DFS delves deeply along one branch before backtracking, enabling a more targeted depth-first traversal. The exploration process continues until either the cumulative confidence meets or exceeds a threshold $\tau$, or the maximum document limit $M$ is reached.

    \item \textbf{Chain of Thought Generation:} Generate a reasoning trace $\rvc_i$ for each entity $\rvn_i$ using an \gls{llm}, integrating information from nodes and their relationships:
    \[
    \rvc_i = \text{LLM}(\rvn_i, \{\rvd(\rvn_j) \mid j \in \text{connected nodes}\}).
    \]

    \item \textbf{Answer Synthesis:} Aggregate reasoning traces $\{\rvc_1, \rvc_2, \ldots, \rvc_m\}$ and pass them to a final answer generator, which produces the output $\hat{\rva}$ along with an overall confidence score:
    \[
    \hat{\rva}, \hat{s} = G(\{\rvc_1, \rvc_2, \ldots, \rvc_m\}).
    \]
\end{enumerate}

This pipeline ensures that answers are comprehensive and grounded in the \gls{kg}, with confidence scores providing interpretability and reliability.

\begin{algorithm}
\small
\caption{KG-Based QA Inference Pipeline}
\begin{algorithmic}[1]
\Require Query $q$, Knowledge Graph $KG$, Confidence Threshold $\tau$, Max Iterations $N$
\Ensure Final Answer $\hat{\rva}$ with Confidence $s$
\State Extract medical terms: $\{\rvn_1, \rvn_2, \ldots, \rvn_m\} \gets \text{ExtractTerms}(\rvq)$
\State Initialize reasoning traces: $C \gets \emptyset$
\State Initialize confidence: $\rvs_i \gets 1.0$ for all terms $\rvn_i$
\For{$i = 1$ to $m$} \Comment{Iterate over extracted terms}
    \State \textbf{Explore KG:} Retrieve relevant nodes $\{\rvd_j\}$ and relationships $\rvr_{ij}$ for $\rvn_i$
    \For{each child node $\rvn_j$ of $\rvn_i$ in $KG$}
        \State Compute child confidence: $s_j \gets s_i \cdot \rvr_{ij}$
        \If{$s_j \geq \tau$}
            \State Include $\rvn_j$ in exploration set
        \EndIf
    \EndFor
    \State \textbf{Generate Reasoning Trace:} $\rvc_i \gets \text{LLM}(\rvn_i, \{\rvd_j\})$
    \State Add $\rvc_i$ to reasoning traces: $C \gets C \cup \{\rvc_i\}$
\EndFor
\State \textbf{Synthesize Answer:} $\hat{a}, \hat{s} \gets G(C)$
\State \Return $\hat{\rva}, \hat{s}$ \Comment{Return final answer with confidence}
\end{algorithmic}
\label{alg:kg-qa-pipeline}
\end{algorithm}

\subsection{Dynamic Generation of the Medical Knowledge Graph}
The construction of the \gls{mkg} for \gls{qa} represents a critical step toward enabling structured reasoning in our \gls{myrag}. This approach extracts key entities and their interconnections from user queries, enriching them with information retrieved through external search tools. By organizing information into the \gls{mkg}, we enable efficient, interpretable, and evidence-based \gls{qa}. The methodology is as follows:

\subsubsection{Node Extraction}
Medical terms are identified within the user query $\rvq$ using an \gls{llm} agent named Medical Entity Recognizer (MER). These terms are treated as nodes, $\{\rvn_1, \rvn_2, \ldots, \rvn_m\}$, in the \gls{kg}. For each extracted term, a search tool (e.g., PubMed, or a specialized medical search engine) retrieves detailed descriptions $\rvd(\rvn_i)$, providing context for each node:
\[
\rvd(\rvn_i) = \text{Search}(\rvn_i; \text{knowledge source}).
\]
The retrieved descriptions form the foundational data for each node in the \gls{mkg}, ensuring an accurate representation of medical terms and their attributes.

\subsubsection{Relationship Inference}
An \gls{llm} agent extracts relationships between nodes based on their descriptions and retrieved documents. The \gls{llm} analyzes pairs of nodes $(\rvn_i, \rvn_j)$ to determine potential relationships $\rvr_{ij}$ and their nature:
\[
\rvr_{ij}, \rvs_{ij} = \text{LLM}(\rvd(\rvn_i), \rvd(\rvn_j)).
\]
The agent generates a summary, infers the relationship type (e.g., causation, association), and assigns a confidence score. This process results in a \gls{kg} rich in structure and semantics.

\subsubsection{Knowledge Graph Construction}
The nodes, descriptions, relationships, and confidence scores are integrated into the \gls{kg} structure. The resulting graph supports medical \gls{qa} by:
\begin{itemize}
    \item Highlighting key medical concepts and their interrelations.
    \item Enabling efficient retrieval and reasoning over medical knowledge.
    \item Providing confidence metrics for each established relationship in the graph, serving as a source of reliability.
\end{itemize}
