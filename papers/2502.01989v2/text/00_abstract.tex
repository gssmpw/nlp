\begin{abstract}

We introduce \emph{\underline{T}est-time \underline{S}calable M\underline{C}TS-\underline{en}hanced \underline{D}iffusion Model} (\proj), a novel framework that significantly improves diffusion model's reasoning capabilities with better energy-based training and scaling up test-time computation. We first show that na\"ively scaling up inference budget for diffusion models yields marginal gain. To address this, the training of \proj consists of a novel linear-regression negative contrastive learning objective to improve the \emph{performance-energy consistency} of the energy landscape, and a KL regularization to reduce \emph{adversarial sampling}. During inference, \proj integrates the denoising process with a novel hybrid Monte Carlo Tree Search (hMCTS), which sequentially performs best-of-N random search and MCTS as denoising proceeds. On challenging reasoning tasks of Maze and Sudoku, we demonstrate the effectiveness of \proj's training objective and scalable inference method. In particular, trained with Maze sizes of up to $6\times6$, our \proj solves 88\% of Maze problems with much larger sizes of $15\times15$, while standard diffusion completely fails. Code to reproduce the experiments can be found at \url{https://github.com/AI4Science-WestlakeU/t_scend}.

% Test-time scaling has significantly advanced the performance of large language models (LLMs) across various applications while its application to other generative models, such as diffusion models, remains limited despite its potential. However, the question of how to fully leverage the capabilities and advantages of diffusion models to scale up in inference time remains largely unanswered. In this paper, we propose scaling up energy-based diffusion models during inference time using Monte Carlo Tree Search (MCTS). First, we conduct preliminary experiments to analyze why directly utilizing MCTS to enhance diffusion model inference yields limited improvement, identifying the root cause as insufficient sample-diversity and performance-energy-consistency in the base model. So we propose negative contrastive learning and maximum entropy regularization training methods to improve the sample-diversity and performance-energy-consistency of the base model, enabling effective scaling up.We conducted extensive experiments on Sudoku and Maze, demonstrating that our approach significantly outperforms other strong baselines.
\end{abstract}