% \textbf{Test time computing and MCTS：} Test time scaling refers to the practice of augmenting computational resources during the inference phase of a model to improve its performance. This technique has recently gained significant traction in the field of large language models (LLMs), resulting in substantial improvements in their capabilities . Within the LLM domain, methods such as CoT\citep{wei2022chain} and Tree of Thoughts (TOT) are commonly employed to explicitly incorporate reasoning steps, thereby enhancing the model’s reasoning abilities. Monte Carlo Tree Search (MCTS)~\citep{coulom2006efficient,kocsis2006bandit,gelly2006modification}, a heuristic search algorithm designed for specific types of decision-making processes, is particularly well-suited for applications in board-game. In recent years, MCTS has been increasingly integrated with deep learning, particularly reinforcement learning, demonstrating powerful capabilities and offering an efficient approach to augment computational search during the model’s inference phase\citep{silver2016mastering}.
\textbf{Controllable Generation of Diffusion Models}: Controllable generation in diffusion models has been a significant area of research aiming to guide the generation process to produce samples that meet specific criteria or constraints. Previous work focuses on controlling the generation process through an external or internal gradient \cite{classifierguidance, cfg}, which requires additional training according to each new objective. \proj does not rely on external guidance/classifiers or conditional training but instead utilizes sampling, simulation, and selection during inference to navigate the generation process.

\textbf{Test-time scaling and MCTS}: Test-time scaling involves augmenting computational resources during the inference phase to improve model performance. This approach has gained significant attention in the field of large language models (LLMs) \citep{brown2024large,snell2024scaling,wu2024empirical}, substantially enhancing their capabilities. Techniques such as CoT \citep{wei2022chain} and TOT \citep{yao2024tree} are commonly used to incorporate explicit reasoning steps to strengthen the model’s reasoning abilities. Monte Carlo Tree Search (MCTS) \citep{coulom2006efficient,kocsis2006bandit,gelly2006modification} is a heuristic search algorithm designed for decision-making processes. Recently, MCTS has been increasingly integrated with deep learning, particularly reinforcement learning, providing an efficient means of enhancing computational search during inference \citep{silver2016mastering,silver2017mastering,silver2018general,schrittwieser2020mastering}.

The idea of test-time scaling for diffusion models was concurrently explored by \citet{ma2025inferencetimescalingdiffusionmodels}. Their approach investigates how test-time computation budgets affect scaling performance, as well as the influence of different verifiers and scaling search algorithms. In contrast, we focus on why na\"ively trained diffusion models fail and propose KL loss and LRNCL loss to enhance the diffusion model’s capacity, facilitating better scalability. For test-time scaling methods, we introduce hMCTS denoising, which innovatively integrates MCTS and the denoising process to fully unlock the scalability of the diffusion model.








