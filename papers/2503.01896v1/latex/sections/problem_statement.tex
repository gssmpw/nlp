\section{Experimental Setting}
\paragraph{Model Architecture}: GPT-2-small \cite{radford2019language} is a decoder-only transformer with 12 layers and 12 attention heads per layer. We follow the notations in \cite{wang2022interpretability} and denote head $j$th in layer $i$ by $h_{i,j}$. This attention head is parameterized by four matrices $W_{Q}^{i,j}$, $W_{K}^{i,j}$, $W_{V}^{i,j}$ $\in \mathbb{R}^{\frac{d}{H} \times d}$ and $W_{O}^{i,j}$ $\in \mathbb{R}^{\frac{d}{H} \times d}$, where $d$ is the model dimension, and $H$ is the number of heads in each layer. Rewriting parameter of attention head $h_{i,j}$ as low-rank matrices in $\mathbb{R}^{d \times d}$: $W_{OV}^{i,j}$ = $W_{V}^{i,j}$$W_{O}^{i,j}$, which is referred to as the OV matrix and determines what is written to the residual stream \cite{elhage2021mathematical}. Similarly,  $W_{QK}^{i,j} = W_{Q}^{i,j}$$W_{K}^{i,j}$  is referred to as the QK matrix and computes the attention patterns of each head $h_{i,j}$. The unembed matrix $W_U$ projects the residual stream into logit after layer norm application \cite{elhage2021mathematical, wang2022interpretability}.

\paragraph{Fine-Tuning:}
We fine-tune GPT-2-small on the IOI Dataset, which we refer to as the clean dataset \cite{wang2022interpretability}, for a variety of epochs, ranging from 1 to 100 epochs (see \autoref{methodology}). For fine-tuning, we adopt an unsupervised setting \cite{radford2019language}, with fixed hyper-parameters across all experiments (see \autoref{app:fine} for details). Additionally, as shown in Figure \ref{fig:datacorruption}, we create 3 data augmentations of the original IOI dataset for corrupted fine-tuning. We call these datasets \textit{Name Moving}, \textit{Subject Duplication}, and \textit{Duplication} datasets (discussion of results and design for {Duplication} dataset is left to \autoref{dadupe}). We design the data augmentations and hypothesize impacts on the model behavior due to the corruptions as follows:
\begin{wrapfigure}[4]{r}{1\linewidth}
\vspace{-0.5cm}
    \centering
    \includegraphics[width = 1.05\linewidth]{latex/img/np/datacorruption.drawio-2.pdf}
    \caption{Corrupted data augmentations we utilize to poison model behavior on task}
\label{fig:datacorruption}
\end{wrapfigure}
$\newline$
\vspace{0.5cm}
$\newline$
\paragraph{Corrupted Dataset 1: Name Moving.}
\label{danm}
To investigate the behavior of Name Mover and Negative Name Mover heads, we create a modified dataset that disrupts the movement of the IO token to the output. Specifically, we replace the final token with a random name rather than the expected IO token (e.g., altering the second clause from "Mark gave flowers to \textcolor{teal}{Rebecca}" to "Mark gave flowers to \textcolor{red}{Stephanie}"). Fine-tuning on this dataset allows us to analyze how the model's copying mechanisms adapt when it must output a name not present in the input, thereby \textbf{targeting} the copying behavior of the Name Mover Heads.
\paragraph{Corrupted Dataset 2: Subject Duplication Task.}
To interfere with the Name Mover Heads' role in outputting the IO token and suppressing the S token (due to S-Inhibition Heads), we introduce the Subject Duplication Task. In this task, the output IO token is replaced with the S token, as in: "Mark gave flowers to \textcolor{teal}{Rebecca}" becomes "Mark gave flowers to \textcolor{red}{Mark}". Fine-tuning on this dataset \textbf{aims} to observe how model mechanisms adapt when forced to output the S token, despite its repetition, \textbf{targeting} the interaction between S-Inhibition and Name Mover Heads.
\paragraph{Circuit Discovery:}  
\label{circdiscover}
Our circuit discovery follows the method outlined in original IOI  work \cite{wang2022interpretability}, utilizing path patching \cite{goldowsky2023localizing}, activation patching \cite{meng2023locatingeditingfactualassociations,NEURIPS2020_92650b2e} and analyzing the circuit components' behavior. Even though methods like ACDC \cite{conmy2023automated}, EAP \cite{syed2023attribution}, and DCM \cite{davies2023discovering} reduce the overhead, in order to stay faithful to the original work, we adopt their approach.
\paragraph{Circuit Evaluation:}  
\label{circeval}
We evaluate the circuits formed and discovered at each fine-tuning iteration, using the minimality, completeness, and faithfulness criteria \cite{wang2022interpretability, prakash2024fine}. We define Faithfulness as follows (see \autoref{app:circ_disc} and \autoref{app:circ_eval} for details on Minimality and Completeness).
%\paragraph{Completeness}:
%\noindent\textbf{Faithfulness:}
Let $X$ be a random variable representing a sample in our fine-tuning dataset. Moreover, let $C_M$ denote the discovered circuit for model $M$, and $f(C_M(X))$  be the logit difference between the IO token and S token when circuit $C$ of model $M$ is run on input $X$ and $F(C)\defeq\mathbb{E}_{X} [f(C_M(X))]$ be the average logit difference \cite{wang2022interpretability}.
Given this, faithfulness is measured by the average logit difference of the IO and S token across inputs on the model $M$ and its circuit $C$; $|F(M) - F(C)|$. For example, the faithfulness of the original IOI circuit: $|F(GPT2) - F(C_{GPT2})| = 0.46$, i.e, the circuit achieves 87\% of the performance of GPT-2-small \cite{wang2022interpretability}.