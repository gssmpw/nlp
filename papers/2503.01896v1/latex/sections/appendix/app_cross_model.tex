\section{Discovering Localized Corruption with Cross-Model Activation Patching}
\label{app:cross}
\textbf{Data Corruption: Subject Duplication}: In addition to the Cross Model Pattern Patching we also employ Cross Model Output Patching, i.e, replacing the attention outputs of each attention head in the original model with that of the fine-tuned on corrupted data variant. We record that the prior analysis of localized corruption can also be examined via Cross-Model Output Patching, see \autoref{fig:cmap-sd-out}
\begin{figure}
    \centering
    \includegraphics[width = 0.48\textwidth]{latex/img/appendix/cmap-sd-out.pdf}
    \caption{Change in Logit Difference after Cross Model Output Patching on the Original Model}
    \label{fig:cmap-sd-out}
\end{figure}
\autoref{fig:cmap-sd-out} illustrates that majority of the corruption is localized to the original circuit components, however similar to our prior analyses novel components arise with perform repeated corrupted mechanism and hence we see their contribution to the task. An interesting case here is that of \textbf{L8H11} which is a new former Name Mover Head, i.e, moving the ''S'' token to the residual stream at the END position. In \autoref{fig:cross-model-cp} we saw that the attention pattern of L8H11 when patched results in decrease in overall capability of the model, however in \autoref{fig:cmap-sd-out} shows an increase in capability, this is a non-surprising result as the OV Matrix of each attention head determines what is written to the residual stream whereas the QK matrix determines the attention pattern, here, we see that the QK Matrix of L8H11 decreases performance after CMAP however OV Matrix doesn't, this is due to the linearly independent nature of the two operations, which only in conjunction, determine the contribution of the head. As the QK Matrix is negatively contributing after CMAP and OV Matrix is positively contributing, this means that overall contribution is negative as the head copies ''S'' token to the residual stream of the END token.\\
\textbf{Data Corruption: Name Moving}: In addition to the localized corruption in subject duplication task, we identify localized corruption in the model variant fine-tuned on the Name Moving data corruption. Firstly, similar to our prior analyses we employ Cross Model Pattern Patching, see \autoref{fig:cmap-nm-pat}.
\begin{figure}
    \centering
    \includegraphics[width = 0.48\textwidth]{latex/img/appendix/cmap-nm-pat.pdf}
    \caption{Change in Logit Difference after Cross Model Output Patching on the Original Model}
    \label{fig:cmap-nm-pat}
\end{figure}
Hence see that the corruption, in this case, is localized to the circuit components, we further validate our findings via Cross-Model Output Patching, see \autoref{fig:cmap-nm-out}.
\begin{figure}
    \centering
    \includegraphics[width = 0.48\textwidth]{latex/img/appendix/cmap-nm-out.pdf}
    \caption{Change in Logit Difference after Cross Model Output Patching on the Original Model}
    \label{fig:cmap-nm-out}
\end{figure}