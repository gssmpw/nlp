\section{Related Work}
\label{background}
\paragraph{Fine-Tuning} enhances language model performance for specific tasks  \cite{christiano2017deep, gururangan2020don, madaan2022language, touvron2023llama}. Research has explored its effects on model capabilities, like OOD detection \cite{uppaal2023fine, zhang2024your}, domain adaptation \cite{gueta2023knowledge}, generalization \cite{yang2024unveiling} and safety \cite{qi2023fine}. Fine-tuning has also been shown to improve underlying mechanisms for cognitive tasks in  domains like code, and mathematics \cite{prakash2024fine} and for synthetic tasks \cite{jain2023mechanistically, lindner2024tracr}.
\paragraph{Model Poisoning} has been explored in prior work %on corrupting %language model behaviors explore 
to understand the impacts of various attacks %and a variety of learning algorithms 
in diverse settings \cite{huang2020metapoison, he2024talk,carlini2023poisoning, shu2023exploitability, wan2023poisoning, li2024badedit, wallace2020concealed}. While other works focus on defense against such attacks \cite{zhao2024defending, yan2024parafuzz, geiping2021doesn, zhu2022moderate, sun2023defending, tian2022comprehensive,tang2023setting}, a mechanistic understanding of corruption remains elusive.

\paragraph{Mechanistic Interpretability} tries to reverse-engineer the mechanisms of certain tasks \cite{wang2022interpretability, hanna2024does, garcia2024does, lindner2024tracr, prakash2024fine}.  Several works have focused on understanding tasks under phenomenons such as grokking \cite{nanda2023progress, zhong2024clock}, while some have focused on exploring circuit component reuse \cite{merullo2023circuit}, superposition \cite{elhage2022toy}, universality in group operations \cite{chughtai2023toy} and dictionary learning \cite{cunningham2023sparse, rajamanoharan2024improving}. 