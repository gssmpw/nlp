\section{RELATED WORK}
Recent studies have examined the idea of teaching robots through natural language. One approach was proposed by Ahn et al.____ and emphasizes a robot's need to refer to its task history, particularly when executing a series of pick-and-place manipulations through instructions given sequentially. The authors created a history-dependent dataset with pick-and-place operations instructed through natural language. A human provides the robot with linguistic instructions to move certain blocks individually to build a specific structure. The robot's main objective is to estimate the target block's position before and after executing the instructions. The dataset provides synthetic RGB images of the workspace, a set of natural language instructions written by six annotators, the objects' bounding boxes, and heat maps showing the target object. Six annotators describe the same operation for each task, in their own style. The model is trained via supervised learning, using the heatmap as ground truth.

Kuo et al.____ conducted a study on trajectory prediction systems that utilize linguistic representations, where the model is trained using sample trajectories with labels. However, the study highlights the need for motion prediction datasets with natural language annotation. To address this limitation, the authors expanded the Argoverse____ dataset with synthetic language descriptions, which were limited by the types of filters used to generate these descriptions. They also sampled 40,000 trajectories from the Waymo____ dataset and employed human labor to annotate their labels. The authors observed that annotated sentences had a much more diverse vocabulary than synthetic language, but the annotation process was quite laborious. 

Due to the limitations of the available datasets, some studies have been restricted to examining how robots understand natural language through tasks that do not require physical actions in the real world. These tasks can be performed using conventional datasets consisting of pairs of image-instruction previously developed in the literature. For instance, Cheang et al.____ focused on inferring the objects' category and estimating the 6-DoF information for invisible objects of known classes from natural language instructions provided to a robot. They used RefCOCO____ as a benchmark because it is a more established benchmark in the literature, and existing ground truth is available. Additionally, Yang et al.____ explored object attributes in disambiguation and developed an interactive understanding system that can resolve ambiguities through dialogues.

Various robot manipulation tasks require different skills and formats, including following instructions____, one-shot imitation____, rearrangement____, constraint satisfaction____, and reasoning____. Multiple physics simulation benchmarks have been introduced to study these tasks. For instance, iGibson____ simulates interactive household scenarios, Ravens____ rearranges deep features to infer spatial displacements from visual input and exhibit superior sample efficiency on several tabletop manipulation tasks. Robosuite____ is a modular simulation framework and benchmark for robot learning that aims to facilitate research and development of data-driven robotic algorithms and techniques. CALVIN____ develops long-horizon language-conditioned tasks, Meta-World____ is a benchmark of simulated manipulation tasks with everyday objects contained in a shared, tabletop environment. AI2-THOR____ is a framework that supports visual object manipulation and procedural generation of environments.

\begin{figure*}[b!]
\centering
    \includegraphics[width=\textwidth]{img/my_framework.pdf}\hfill
    \caption{The InstructRobot framework comprises two main blocks: environment and agent. The Environment block was designed to simplify the process of generating task instructions and rewards and is composed mainly of the Instructional Set, Reward Generator, and Robot modules. For every episode, an instruction $i_t$ is randomly selected from the Instructional Set and becomes the active instruction of the environment, providing a designed reward function to evaluate the robot's actions. The Agent block comprises the Language System, Perceptual System, Alignment, and Actor and Critic modules. The agent receives a state $\textbf{s}_{t+1}$ that comprises the active instruction $i_t$ and the perceptual information $\textbf{p}_t$ from the environment, processes it in its subsystems and acts in the environment by sending an action $\textbf{a}_t$, receiving a reward $r_t$. In this process, the agent learns a policy $\pi(\textbf{a}|\textbf{s})$ that maps the instruction into robot motion.}
    \label{fig:all_framework}
\end{figure*}

A significant challenge for approaches that require annotated data is dealing with generalization. VIMA____ pursued an imitation learning strategy using Transformer architectures and multimodal prompts to train a robotic manipulator with previously learned inverse kinematics model in several pick-and-place and wipe tasks. To train the model and improve generalization, they generated a large offline dataset containing 50k trajectories per task, totaling 650k trajectories. An expert oracle collected the trajectories for all tasks, and a behavior clone algorithm was employed to learn the pick-and-place actions. Despite facilitating data sampling, this approach still has several disadvantages, such as the low generalization that imitation learning methods present in general and that the learning of complex tasks is dependent on the oracle. Our framework is related to these works, mainly in object manipulation tasks through natural language instructions. However, our framework stands out for tackling the challenge of the joint learning kinematics model and language representation while avoiding the creation of datasets.