\newpage
\section*{Impact Statements}

\paragraph{Applicability to Other High-Stakes Domains.}
The safety-aware paradigm is not unique to finance. Fields such as healthcare, law, and critical infrastructure share similar concerns: even small errors can lead to dire outcomes. Our proposed evaluation framework could be adapted for medical diagnoses or legal drafting tasks, integrating domain-specific stress tests (e.g., hypothetical malpractice scenarios or contradictory legal precedents).

\paragraph{Toward Standardized Safety Metrics.}
A major takeaway is the need for consensus on risk-aware metrics. While F1 and BLEU scores have become standard in broader NLP, there is no single, universally accepted measure of financial safety. Coordinated efforts by industry stakeholders, regulatory bodies, and the academic community could establish standardized protocols (e.g., \textsc{GLUE}~\citep{wang2018glue} in NLP) for evaluating model reliability and resilience.

\paragraph{Shaping Next-Generation AI Agents.}
Lastly, emerging LLM agent architectures could redefine how we approach safety. They are capable of chaining multiple LLM calls, taking actions, and self-verifying outputs
Future AI systems may catch and correct errors in real time, obviating certain vulnerabilities observed in our experiments. Developing such agents for finance demands not only refined model capabilities but also deeper domain integration and vigilant oversight.
