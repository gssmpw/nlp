[
  {
    "index": 0,
    "papers": [
      {
        "key": "liu2023robust",
        "author": "Liu, Hui and Wang, Wenya and Sun, Hao and Rocha, Anderson and Li, Haoliang",
        "title": "Robust domain misinformation detection via multi-modal feature alignment"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "shalabi2024leveraging",
        "author": "Shalabi, Fatma and Felouat, Hichem and Nguyen, Huy H and Echizen, Isao",
        "title": "Leveraging Chat-Based Large Vision Language Models for Multimodal Out-Of-Context Detection"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhang2023detecting",
        "author": "Zhang, Yizhou and Trinh, Loc and Cao, Defu and Cui, Zijun and Liu, Yan",
        "title": "Detecting out-of-context multimodal misinformation with interpretable neural-symbolic model"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "liu2020visual",
        "author": "Liu, Fuxiao and Wang, Yinghan and Wang, Tianlu and Ordonez, Vicente",
        "title": "Visual News: Benchmark and Challenges in News Image Captioning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zhang2023detecting",
        "author": "Zhang, Yizhou and Trinh, Loc and Cao, Defu and Cui, Zijun and Liu, Yan",
        "title": "Detecting out-of-context multimodal misinformation with interpretable neural-symbolic model"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "popat2018declare",
        "author": "Popat, Kashyap and Mukherjee, Subhabrata and Yates, Andrew and Weikum, Gerhard",
        "title": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "abdelnabi2022open",
        "author": "Abdelnabi, Sahar and Hasan, Rakibul and Fritz, Mario",
        "title": "Open-domain, content-based, multi-modal fact-checking of out-of-context images via online resources"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "yao2023end",
        "author": "Yao, Barry Menglong and Shah, Aditya and Sun, Lichao and Cho, Jin-Hee and Huang, Lifu",
        "title": "End-to-end multimodal fact-checking and explanation generation: A challenging dataset and models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zhang2024escnet",
        "author": "Zhang, Fanrui and Liu, Jiawei and Xie, Jingyi and Zhang, Qiang and Xu, Yongchao and Zha, Zheng-Jun",
        "title": "ESCNet: Entity-enhanced and Stance Checking Network for Multi-modal Fact-Checking"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "qi2024sniffer",
        "author": "Qi, Peng and Yan, Zehong and Hsu, Wynne and Lee, Mong Li",
        "title": "SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "abdelnabi2022open",
        "author": "Abdelnabi, Sahar and Hasan, Rakibul and Fritz, Mario",
        "title": "Open-domain, content-based, multi-modal fact-checking of out-of-context images via online resources"
      },
      {
        "key": "yao2023end",
        "author": "Yao, Barry Menglong and Shah, Aditya and Sun, Lichao and Cho, Jin-Hee and Huang, Lifu",
        "title": "End-to-end multimodal fact-checking and explanation generation: A challenging dataset and models"
      }
    ]
  }
]