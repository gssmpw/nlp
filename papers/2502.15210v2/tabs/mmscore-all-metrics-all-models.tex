
\begin{table}[ht]
    \centering
    \tabcolsep 2pt
     \resizebox{0.48\textwidth}{!}{%
    \begin{tabular}{l c c c c}
        \toprule
        Model & \nmi (\%) & \textbf{1-RS} (\%)
        %\relaxsymone (\%) 
        & \smoothness & \control (\%) \\
        \midrule
        \phiThreeFive & 29.65 & 90.13 & 0.64 & 59.18 \\
        \llavaonevision & 30.88 & 75.07 & 1.44 & 85.34 \\
        \qwenTwoVLSevenB & 42.27 & 84.45 & 1.63 & 87.63 \\
        \internvlTwoEightB & 48.13 & 74.63 & 1.32 & 82.27 \\
        \internvlTwoFiveEightB & 55.05 & \textbf{95.21} & 1.42 & 70.42 \\
        \pixtral & 35.77 & 74.85 & \textbf{1.67} & 75.23 \\
        \midrule
        %\rowcolor{green!10}
        \gptFouroMini & 48.28 & 89.07 & 1.59 & 85.48 \\
        %\rowcolor{green!10}
        \gptFouroEleven & 53.95 & 91.53 & 1.54 & 72.77 \\
        %\rowcolor{green!10}
        \geminiFlash  & \textbf{56.55} & 93.19 & 1.34 & 74.54 \\
        %\rowcolor{green!10}
        \geminiPro   & 52.60 & 88.72 & 1.17 & \textbf{88.09} \\
        \bottomrule
    \end{tabular}
     }
    \caption{Aggregated \nmi, \textbf{1-RS}:\relaxsymone, \smoothness, and \control{} over all four data splits. No model performs the best across all metrics, showing the importance of \mmscore{} to rank models based on different abilities.}
    \label{tab:model_performance}
\end{table}

% GPT-4o-2024-05-13 & 50.10 & 90.16 & 95.22 & 96.85 & 1.54 & 78.54 \\
% GPT-4o-2024-08-06 & 45.35 & 42.54 & 44.44 & 44.97 & 1.46 & 75.52 \\
