\begin{figure*}[ht]
    \centering
% \includegraphics[width=0.95\linewidth,trim={.1cm .2cm .2cm .2cm},clip]{imgs/all-metric-mi-norm_sym_per-entropy-control-distinct-plt.pdf}
\includegraphics[width=0.95\linewidth,trim={.1cm .2cm .2cm .2cm},clip]{imgs/all-metric-mi-relaxed1_sym-entropy-control_mult-distinct-plt.pdf}
    \caption{Best models performances on \mmscorecoco{}, \mmscorein{}, \mmscorewuimgimg, and \mmscorewuimgtext. No model dominates the others as a similarity kernel, hence showing the limitation of defaulting to a single model as a judge for every task and dataset. Note the full symmetry of \phiThreeFive, \llavaonevision, and InternVL models on \mmscorewuimgtext{} are due to the lack of flexibility in the prompt structure to take the image anywhere but the beginning.} 
    \vspace{-3mm}
    % \textcolor{red}{Spandana: change the range on y-axis of each individual plot, so its clear the difference between the models. Also why is pixtral-12B so low on MM-Score?}}
    \label{fig:mi-best-models}
\end{figure*}