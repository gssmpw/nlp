% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.
 
\documentclass[11pt]{article}

\usepackage[table, x11names]{xcolor}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{xspace}
\usepackage{booktabs}

\usepackage{amsmath}


\usepackage{listings}


% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}


\usepackage{multirow}
\usepackage{hhline}
\usepackage{cleveref}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.


\input{macro}

\title{EquiBench: Benchmarking Code Reasoning Capabilities of Large Language Models via Equivalence Checking}

\author{
\\
\textbf{Anjiang Wei}\textsuperscript{1} \hspace{1em} \textbf{Jiannan Cao}\textsuperscript{2} \hspace{1em} \textbf{Ran Li}\textsuperscript{1,3} \hspace{1em} \textbf{Hongyu Chen}\textsuperscript{4} \hspace{1em} \textbf{Yuhui Zhang}\textsuperscript{1} \\
\textbf{Ziheng Wang}\textsuperscript{1} \hspace{1em} \textbf{Yaofeng Sun}\textsuperscript{5} \hspace{1em} \textbf{Yuan Liu}\textsuperscript{3} \hspace{1em} \textbf{Thiago S. F. X. Teixeira}\textsuperscript{6} \\
\textbf{Diyi Yang}\textsuperscript{1} \hspace{1em} \textbf{Ke Wang}\textsuperscript{7} \hspace{1em} \textbf{Alex Aiken}\textsuperscript{1} \\
\textsuperscript{1}Stanford University \hspace{1em} \textsuperscript{2}MIT \hspace{1em} \textsuperscript{3}Google \hspace{1em} \textsuperscript{4}Nanjing University \\
\textsuperscript{5}DeepSeek \hspace{1em} \textsuperscript{6}Intel \hspace{1em} \textsuperscript{7}Visa Research \\
\texttt{\{anjiang,aiken\}@cs.stanford.edu}
}

\begin{document}
\maketitle
\begin{abstract}

% involved macros:
% \name, \numpair, \numllm, \sotaacc{}, \sotacuda{}, \sotadce{}

Equivalence checking, i.e., determining whether two programs produce identical outputs for all possible inputs, underpins a broad range of applications, including software refactoring, testing, and optimization. We present the task of equivalence checking as a new way to evaluate the code reasoning abilities of large language models (LLMs). We introduce EquiBench, a dataset of 2400 program pairs spanning four programming languages and six equivalence categories. These pairs are systematically generated through program analysis, compiler scheduling, and superoptimization, covering nontrivial structural transformations that demand deep semantic reasoning beyond simple syntactic variations. Our evaluation of 17 state-of-the-art LLMs shows that OpenAI o3-mini achieves the highest overall accuracy of 78.0\%. In the most challenging categories, the best accuracies are 62.3\% and 68.8\%, only modestly above the 50\% random baseline for binary classification, indicating significant room for improvement in current models' code reasoning capabilities.

\end{abstract}

\section{Introduction}
\label{sec:intro}
\input{1_intro}

\section{Related Work}
\label{sec:related}
\input{2_related}

\section{Benchmark Construction}
\label{sec:method}
\input{3_method}

\section{Experimental Setup}
\label{sec:experiment}
\input{4_setup}

\section{Results}
\label{sec:result}
\input{5_result}

% \section{Discussion}
% \label{sec:result}
% \input{6_discussion}

\section{Conclusion}
\input{7_conclusion}

\section*{Limitations}
We make every effort to ensure that all pairs are correctly labeled, but cannot guarantee complete accuracy due to potential bugs in the toolchains or errors in the inputs (e.g., solutions from programming contests may be accepted based on a limited set of test cases that might not fully expose underlying bugs in the accepted solutions).


\section*{Acknowledgements}
We thank Lianmin Zheng, Shiv Sundram, Mingfei Guo, Xiaohan Wang, and Allen Nie for their discussions.

\bibliography{custom}


\setcounter{figure}{0}
\renewcommand{\thefigure}{A\arabic{figure}}
\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}

\newpage
\appendix
\onecolumn


\section{Appendix}
\label{sec:appendix}
\input{8_appendix}



\end{document}
