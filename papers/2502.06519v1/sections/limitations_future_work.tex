\section{Limitations and Future Work}
\label{sec:limitations_future_work}
Our registration algorithm relies on semantics for robust, initialization-free registration, and thus requires that the input maps have embedded semantic codes. A GSplat map may lack semantic information if the map was not trained with semantics or if the scene lacks any semantically-relevant features, which would be a tail event in practical situations. We can post-train GSplats to embed semantics in $3$D into the map or leverage $2$D vision foundation models to directly extract semantic information from RGB images rendered from the GSplat by back-projecting $2$D pixels into the $3$D world.
Radiance fields are prone to generate floaters in areas of the scene with little to no supervision, which can degrade the fidelity of the map. The resulting floaters are retained in the fused map, which could ultimately reduce the accuracy of the map. However, by finetuning the fused map with synthetic data, i.e., images rendered from the map as opposed to real-world images, floaters in the map can be removed for high-fidelity mapping.
