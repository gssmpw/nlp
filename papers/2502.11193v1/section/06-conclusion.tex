\section{Conclusion and Suggestions}

Our work, including the creation of \texttt{ScholarLens} and the proposal of \texttt{LLMetrica}, provides methods for assessing LLM penetration in scholarly writing and peer review. By incorporating diverse data types and a range of evaluation techniques, we consistently observe the growing influence of LLMs across various scholarly processes, raising concerns about the credibility of academic research. As LLMs become more integrated into scholarly workflows, it is crucial to establish strategies that ensure their responsible and ethical use, addressing both content creation and the peer review process. 

Despite existing guidelines restricting LLM-generated content in scholarly writing and peer review,\footnote{\href{https://aclrollingreview.org/acguidelines\#-task-3-checking-review-quality-and-chasing-missing-reviewers}{Area Chair} \&  \href{https://aclrollingreview.org/reviewerguidelines\#q-can-i-use-generative-ai}{Reviewer} \& \href{https://www.aclweb.org/adminwiki/index.php/ACL_Policy_on_Publication_Ethics\#Guidelines_for_Generative_Assistance_in_Authorship}{Author} guidelines.} challenges still remain. 
To address these, we propose the following based on our work and findings: 
(i) \textbf{Increase transparency in LLM usage within scholarly processes} by incorporating LLM assistance into review checklists, encouraging explicit acknowledgment of LLM support in paper acknowledgments, and 
reporting LLM usage patterns across diverse demographic groups;
% reporting LLM penetration based on social demographic features;
(ii) \textbf{Adopt policies to prevent irresponsible LLM reviewers} by establishing feedback channels for authors on LLM-generated reviews and developing fine-grained LLM detection models~\cite{abassy-etal-2024-llm, cheng2024beyond, artemova2025beemobenchmarkexperteditedmachinegenerated} to distinguish acceptable LLM roles (e.g., language improvement vs. content creation);
(iii) \textbf{Promote data-driven research in scholarly processes} by supporting the collection of review data for further robust analysis~\cite{dycke-etal-2022-yes}.\footnote{\url{https://arr-data.aclweb.org/}}

% make LLM usage transparent in scholarly processes: such as incorporating LLM usage into review checklists, encouraging explicit acknowledgment of LLM assistance in paper acknowledgments, and reporting LLM penetration based on social demographic features; (ii) Adopt policies to prevent irresponsible LLM reviewers: such as providing authors feedback on LLM-assisted reviews, and developing fine-grained LLM detection models~\cite{cheng2024beyond} to distinguish acceptable LLM roles (e.g., language improvement vs. content creation); (iii) Encourage data-driven research in scholarly processes: such as supporting review data collection for further research.

 

