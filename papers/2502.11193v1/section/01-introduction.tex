\section{Introduction}

The rapid advancement of large language models ~\cite[LLMs;][] {achiam2023gpt, dubey2024llama, guo2025deepseek} is significantly shaping the scholarly landscape~\cite{hosseini2023fighting, geng2024impact}.
These technologies assist in various stages of scholarly work, from brainstorming and overcoming ``blank-sheet syndrome''~\cite{altmae2023artificial, baek2024researchagent, eger2025transformingsciencelargelanguage} to supporting paper writing~\cite{wang-etal-2018-paper, birhane2023science, khalifa2024using, rehman2025can}. 
More recently, LLMs have also been considered as tools in the peer review process~\cite{du-etal-2024-llms, zhou-etal-2024-llm, yu2024your, jin-etal-2024-agentreview, zou2024chatgpt}.



However, LLM-generated content often reflects lower quality and inherent biases~\cite{brooks-etal-2024-rise, du-etal-2024-llms}, such as factual inconsistencies~\cite{yang-etal-2024-fizz, chuang-etal-2024-lookback} and hallucinations~\cite{tang2024llms, chuang-etal-2024-lookback}. Research also indicates that LLMs in the review process can lead to higher paper acceptance rates~\cite{latona2024ai, jin-etal-2024-agentreview} and tend to use more positive language than human reviewers~\cite{zhou-etal-2024-llm}. 
This raises concerns about the rigor of scientific research~\cite{sun2024metawriter}, highlighting the importance of ensuring transparency and accountability in the use of LLMs within academic workflows~\cite{lund2024can}.
% This raises concerns about the rigor of scientific research~\cite{sun2024metawriter}. 
% Given these developments, ensuring the transparent and accountable use of LLMs in academic workflows is crucial.

% and understanding the extent and trends of their penetration into scholarly processes is becoming increasingly important.


\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{fig/model.png}
    \caption{Pipeline Overview of Our Work: (1) \textbf{\texttt{ScholarLens} Curation} (\S\ref{sec: ScholarLens}): A designed dataset used to evaluate the effectiveness of metrics and train detection models; (2) \textbf{\texttt{LLMetrica} framework} (\S\ref{sec: LLMetria}): The proposed method for distinguishing human-written from LLM-generated texts; (3) \textbf{Experiments} (\S\ref{sec:Experiments}): Evaluating the effectiveness of \texttt{LLMetrica} and applying it to real-world data to assess LLM penetration rates in scholarly writing and peer process. \textit{Symbolically}, $\mathrm{P}=\left\{ \mathrm{T},\mathrm{A},\mathrm{C},\mathrm{R},\mathrm{MR} \right\}$ represents a research paper, where $\mathrm{T}$, $\mathrm{A}$ and $\mathrm{C}$ denote its title, abstract and main content, $\mathrm{R}=\left\{ r_i \right\}$ represents the individual reviews, and $\mathrm{MR}$ denotes the meta-review.}
    \label{fig:pipeline}
\end{figure*}

To address these concerns, we propose a comprehensive evaluation framework aimed at revealing the increasing penetration of LLMs in scholarly writing and peer review. 
This framework takes a multi-perspective view by integrating diverse scholarly data types and employs a multi-dimensional methodology that utilizes a range of evaluation methods to provide a reliable and nuanced understanding of LLM usage trends. Figure~\ref{fig:pipeline} illustrate the pipeline of our work, and our \textbf{contributions} are as follows:
% \footnote{Dataset and code are available in the final version.}

\begin{itemize}
    \item We introduce \texttt{ScholarLens}, a curated dataset for developing technical measurement methods, comprising both human-written and LLM-generated content (\S\ref{sec: ScholarLens}).
    \item We propose \texttt{LLMetrica}, a tool for assessing LLM penetration in scholarly workflows, combining rule-based metrics to analyze linguistic and semantic features with model-based detectors to identify LLM-generated content (\S\ref{sec: LLMetria}).
    \item Our experiments demonstrate the effectiveness of \texttt{LLMetrica}, consistently showing the increasing penetration of LLMs in scholarly writing and peer review from multiple perspectives and dimensions (\S\ref{sec:Experiments}).
    % \item Our experiments demonstrate the effectiveness of \texttt{LLMetrica}, consistently showing the increasing penetration of LLMs in scholarly writing and peer review of real-word data on real-world data from multiple perspectives and dimensions (\S\ref{sec:Experiments}).
\end{itemize}
% Our work reveal the growing penetration of LLMs in scholarly processes,
Our findings emphasize the need for transparency, accountability, and ethical practices in LLM usage to maintain the credibility of academic research.

% In this paper, we explore the extent and trends of LLM penetration in scholarly writing, focusing on the roles of authors and (meta-)reviewers. Figure~\ref{fig:pipeline} illustrate the pipeline of our work. Specifically, We propose a framework with two key components: \texttt{ScholarLens} (\S\ref{sec: ScholarLens}), a curated dataset for developing technical measurement methods, and \texttt{LLMetrica} (\S\ref{sec: LLMetria}), a set of metrics to assess LLM penetration in scholarly workflows.
% \texttt{ScholarLens} includes both human-written and LLM-generated content across three data types—abstracts, reviews and meta-reviews—using three advanced closed-source LLMs: GPT-4, Claude, and Gemini. 
% \texttt{LLMetrica} combines rule-based linguistic and semantic feature metrics to capture the distinctive traits of academic writing influenced by LLMs, along with scholar-specific model-based detectors to identify whether content is LLM-generated. 




% Our experiments (\S\ref{sec:Experiments}) first demonstrate the effectiveness of \texttt{LLMetrica}, using rule-based metrics to compare linguistic and semantic features of human-written and LLM-generated content in \texttt{ScholarLens}, while training model-based detectors based on the \texttt{ScholarLens} dataset. 
% Building on this foundation, we then apply \texttt{LLMetrica} to real-world data from multiple academic conferences to assess and predict LLM penetration trends. 
% The results reveal a clear temporal shift: LLMs are increasingly present in scholarly writing across various stages, from manuscript drafting to peer review, with a particularly sharp rise in 2024. 
% Furthermore, we conduct a case study to gain deeper insights into the distinctive characteristics of human-written and LLM-generated content.
% Our findings suggest that while LLMs offer opportunities for academic workflows, they also raise concerns about academic integrity and the reliability of peer review.

% Our findings underscore that this increasing penetration of LLMs presents both opportunities and challenges in academic workflows, while also raising concerns about academic integrity and the reliability of the peer review process.


% In this paper, we propose a comprehensive framework, amining to explore the penetration of Large Language Models (LLMs) in scholarly writing, focusing on the roles of authors and (meta-)reviewers. The framework includes \texttt{ScholarLens} (\S\ref{sec: ScholarLens}), a dataset for developing technical measurement methods, and \texttt{LLMetrica} (\S\ref{sec: LLMetria}), a set of quantifiable metrics to evaluate LLM penetration. Specifically, \texttt{ScholarLens} includes both human-written and LLM-generated content across three data types and three advanced closed-source LLMs. \texttt{LLMetrica} comprises rule-based linguistic and semantic feature metrics, along with scholar-specific model-based detectors. Our experiments demonstrate the increasing penetration of LLMs in scholarly writing, across different stages—from initial drafts to the peer review process. 














% With the rapid advancement of large language models (LLMs), their potential applications in academia have attracted significant attention. LLMs can assist in scientific research, help overcome the "blank-sheet syndrome," support paper writing, and even take on the role of reviewers in the peer review process.

% some studies are now focused on collecting and analyzing review data to further optimize the process. 

% Recent discussions in scientific research focus on both old and new problems in the peer review process~\cite{gurevych_et_al:DagRep.14.1.130, kuznetsov2024natural}, aiming to enhance the review process by improving alignment between reviewers and paper topics, as well as mitigating social~\cite{huber2022nobel, tomkins2017reviewer, manzoor2021uncovering} and cognitive biases~\cite{lee2015commensuration, stelmakh2021prior}. Proposals include enhancing structural incentives for reviewers~\cite{rogers-augenstein-2020-improve} and leveraging natural language processing for intelligent support~\cite{kuznetsov-etal-2022-revise, zyska-etal-2023-care, dycke-etal-2023-nlpeer, guo-etal-2023-automatic, kumar-etal-2023-reviewers}, among other policy recommendations~\cite{dycke-etal-2022-yes}.
% Therefore, some studies focus on the collection and analysis of review data~\cite{kennard-etal-2022-disapere, staudinger-etal-2024-analysis, darcy-etal-2024-aries}.\footnote{\href{https://arr-data.aclweb.org/}{ACL Rolling Review Data Collection (ARR-DC)}.} \textbf{However, these efforts largely center on human reviewers—what if, instead, the reviewers are AI?}









% Large Language Models (LLMs), such as GPT-4o~\cite{achiam2023gpt}, LLaMA 3\cite{dubey2024llama}, and DeepSeek~\cite{guo2025deepseek}, 





% have become widely available. Newest LLMs, such as GPT4o~\cite{achiam2023gpt}, LLaMA 3\cite{dubey2024llama} and Gemini\cite{team2023gemini}, can generate remarkably fluent responses to a wide variety of user's queries. These models are now capable of performing many tasks in academic writing, like  the writing of scientific manuscripts\cite{altmae2023artificial} and idea brainstorm\cite{baek2024researchagent}








% Large language models have become widely available. Newest LLMs, such as GPT4o~\cite{achiam2023gpt}, LLaMA 3\cite{dubey2024llama} and Gemini\cite{team2023gemini}, can generate remarkably fluent responses to a wide variety of user's queries. These models are now capable of performing many tasks in academic writing, like  the writing of scientific manuscripts\cite{altmae2023artificial} and idea brainstorm\cite{baek2024researchagent}

% With the increasing use of LLMs in academic writing, issues such as authorship attribution\cite{berg2023case}, potential plagiarism\cite{karamolegkou-etal-2023-copyright}, and other ethical risks have emerged as major concerns. A recent study\cite{lundcan} found that 58.7\% of 300 top academic journals had specific policies for the use of LLMs like ChatGPT. Most of these journals allow AI to be used for improving manuscript quality, but almost all of them explicitly prohibit listing AI as an author.

% Furthermore, the peer-review system is under mounting pressure of the growth of scientific publishing~\cite{alberts2008reviewing}. Overburdened reviewer resort to using increasingly capable LLMs for peer review\cite{hosseini2023fighting}. Becide using models like ChatGPT, some specialized tools have been developed for generating meta-reviews\cite{sun2024metawriter}. Furthermore, a recent study has revealed that numerous reviews for ICLR are generated or assisted by LLMs tools\cite{latona2024ai}. In response to this growing trend, some scholarly institutions have introduced new policies, such as CVPR.\footnote{\url{https://cvpr.thecvf.com/Conferences/2025/CVPRChanges}}

% Evidently, the development of LLMs such as ChatGPT has completely changed academic writing and scholarly communication. So we need a deeper exploration of its impacts. Based on this, we looks at three specific areas of academic writing: title generation, abstract polish, and meta-review creation. The key contributions of this work are:
% \begin{itemize}
% \item 
% We introduces an AIGC detetction tool for the selected areas.
% \item 
% We develop a comprehensive suite to evaluate these areas.
% \item 
% We investigate how AIGC impact these three areas.
% \end{itemize}

