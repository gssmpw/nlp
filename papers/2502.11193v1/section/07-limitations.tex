\section*{Limitations}
While this study provides valuable insights into the penetration of LLMs in scholarly writing and peer review, it may not fully represent the complexities of the real-world scenario. 
On one hand, the analysis focuses on peer review data from the ICLR conference, where the process is fully transparent and the quality of reviews is generally well-maintained. However, in many journals and conferences where peer review remains closed, the penetration of LLMs could be even more pronounced. 
On the other hand, the data simulation may not fully capture the intricate dynamics of LLM-human collaboration in real-world settings, making it difficult to distinguish between acceptable and unacceptable levels of LLM involvement, and potentially leading to a reduced ability of the model to detect LLM-generated text, which in turn lowers the assessment of LLM penetration.
Therefore, the penetration of large language models in scholarly writing and peer review may be more significant in real-world scenarios than what is presented in this study.