\section{Prompts for Data Construction}
\label{app: prompts}


\begin{table*}[t]
\centering
\scalebox{0.85}{
\begin{tabular}{c|p{18cm}@{}}
\toprule
\textbf{Id} & \textbf{Prompt} \\  \midrule
1 & Can you help me revise the abstract? Please response directly with the revised abstract: \{abstract\} \\ 

2 & Please revise the abstract, and response directly with the revised abstract: \{abstract\} \\ 

3 & Can you check if the flow of the abstract makes sense? Please response directly with the revised abstract: \{abstract\} \\ 

4 & Please revise the abstract to make it more logical, response it directly with the revised abstract: \{abstract\} \\ 

5 & Please revise the abstract to make it more formal and academic, response it directly with the revised abstract: \{abstract\} \\ 
        \bottomrule

\end{tabular}}
\caption{Five distinct prompts used to refine human-written abstracts.}
\label{tab:prompt diversity}
\end{table*}




\begin{table*}[ht]
\centering
\scalebox{0.85}{
\begin{tabular}{@{}p{18.5cm}@{}}
\toprule

\multicolumn{1}{l}{\textbf{Basic Prompt Guideline}} \\ \cmidrule(r){1-1}
You are an AI assistant tasked with generating meta-reviews from multiple reviewers' feedback.\\
Please write a meta review of the given reviewers' response around \{$n$\} words.\\
Do not include any section titles or headings. 
Do not reference individual reviewers by name or number. 
Instead, focus on synthesizing collective feedback and overall opinion.

\\
\#\#\# Abstract: \{abstract\}

\#\#\# Reviewers' feedback:\{review\_text\}
\\ \midrule

\multicolumn{1}{l}{\textbf{Formatted Prompt Guideline 1}} \\ \cmidrule(r){1-1}
You are an AI assistant tasked with generating meta-reviews from multiple reviewers' feedback.\\
Please write a meta review of the given reviewers' response around \{$n$\} words. \\
Do not include any section titles or headings. Do not reference individual reviewers by name or number. Instead, focus on synthesizing collective feedback and overall opinion.

\

Please include the given format in your meta review:

Give a concise summary here.\\
Strength: [List the strengths of the paper in points based on reviews.]\\
Weakness: [List the weaknesses of the paper in points based on reviews.]

\\

\#\#\# Abstract: \{abstract\} \\
\#\#\# Reviewers' feedback:\{review\_text\}
\\ \midrule

\multicolumn{1}{l}{\textbf{Formatted Prompt Guideline 2}} \\ \midrule
You are an AI assistant tasked with generating meta-reviews from multiple reviewers' feedback.

Please write a meta review of the given reviewers' response around \{$n$\} words. 


Do not include any section titles or headings. Do not reference individual reviewers by name or number.
Instead, focus on synthesizing collective feedback and overall opinion.

\

Please include the given format in your meta review:

Give a concise summary here.\\
Pros: [List the strengths of the paper in points based on reviews.]\\
Cons: [List the weaknesses of the paper in points based on reviews.]

\\

\#\#\# Abstract: \{abstract\}
\#\#\# Reviewers' feedback:\{review\_text\}
\\ \bottomrule

\end{tabular}}
\caption{Three prompts as guidelines for constructing LLM-generated meta-reviews. Here, $n$ represents the approximate word length for the generated content.}
\label{tab:prompt meta}
\end{table*}


\begin{table*}[t]
    \centering

    \begin{tabular}{>{\centering\arraybackslash}m{5cm}>{\centering\arraybackslash}m{3cm}>{\centering\arraybackslash}m{3cm}>{\centering\arraybackslash}m{3cm}}
        \toprule
        Word Count  & Basic Prompt & Formatted 1 & Formatted 2 \\
        \midrule
        $n \leq 50$ & 1.000 & 0.000 & 0.000 \\
        $50 < n \leq 110$ & 0.800 & 0.100 & 0.100 \\
        $110 < n \leq 160$ & 0.400 & 0.300 & 0.300 \\
        $160 < n \leq 220$ & 0.550 & 0.225 & 0.225 \\
        $> 220$ & 0.250 & 0.375 & 0.375 \\
        \bottomrule
    \end{tabular}
    \caption{The statistical distribution of word lengths observed for each involved meta-review format.}
    \label{tab:prompt frequency}
\end{table*}



\subsection{Prompts for abstract}
To ensure diversity in the refinement process, we design five different prompts for polishing the abstract, as shown in Table \ref{tab:prompt diversity}. Each human-written abstract is randomly assigned one prompt to generate the refined content.



\subsection{Prompts for meta-review}
To ensure that LLM-generated meta-reviews closely mirror the writing style of human-written meta-reviews and maintain authenticity, we analyze the characteristics of human-written meta-reviews. Based on this analysis, we provide three generation templates as guidelines for constructing LLM-generated meta-reviews, as shown in Table~\ref{tab:prompt meta}. The basic prompt does not include any formalized structures, while the other two prompts define more distinct meta-review formats.
Specifically, we conduct a detailed statistical analysis of the frequencies of these two paradigms and selected the corresponding prompts based on these frequencies. The probabilities we use are shown in Table \ref{tab:prompt frequency}.
% Specifically, $n$ represents the approximate word length of the generated content, which is randomly selected according to the statistical distribution of word lengths observed for each format (see Table \ref{tab:prompt frequency}).

% Specifically, we provide three generation template as a guideline for the LLM.
% Purpose on generating the meta-review on a synthetical perspective, we design the prompts based on the abstract and the few reviews of the papers. For make the generated meta-reviews consisted with the actual situation, we limited the generated length by word count and added two common paradigms to extended our prompt diversity, which respectively shown as the \textcolor{blue}{blue-marked} and the 
% \textcolor{red}{red-marked}.

% Each meta-review was
% corresponding one of the MetaReview template and feed to LLMs, triggered through probability determined by word counts, detailing in Table \ref{tab:prompt frequency}.

% However, in our preliminary attempts, we found that the LLMs prefer to summarize the comments of each reviewer separately (such as Reviewer 1: ..., Reviewer 2: ...), while the human-written reviews occurred only a few number of cases like this(only 462 reviews in 19,834 from 2017 to 2024 have occurred). Since we didn't provide the specific paper and reviewer numbers to the LLM, to avoid the LLM generating content with irrelevant identifications, we set the conditions in the \textcolor{orange}{orange-marked} part of the prompt (Table~\ref{tab:prompt meta}). 

% Thus we 

% The table \ref{tab:prompt meta} shows the three prompts

% \subsubsection{Basic-MetaReview Prompt}
% We define the basic prompt at first. In this prompt, we define the role of an AI assistant and its task of generating meta-reviews based on reviews and abstracts at the beginning.

% To ensure that the word count distribution of meta-reviews in the constructed dataset is consistent with the actual situation, we have added a word count limit, which is the \textcolor{blue}{blue-marked} part of prompt in the table \ref{tab:prompt meta}.

% In our preliminary attempts, we found that large language models (LLMs) are very likely to summarize the comments of each reviewer separately (such as Reviewer 1: ..., Reviewer 2: ...). However, in the human data, only a small number of cases are like this (only 462 out of 19,834 cases from 2017 to 2024 have this situation). Therefore, we set the conditions in the \textcolor{orange}{orange-marked} part of prompt in table \ref{tab:prompt meta} to make the generated meta-reviews more in line with the actual paradigm.

% We provide the abstract and reviews to the LLM at the end of prompt.

% \subsubsection{Formatted-MetaReview 1\&2 Prompt}
% Through statistical analysis of the data from 2017 to 2019, we have identified two common paradigms. To make the generated meta-reviews more consistent with the paradigms in actual situation, we have incorporated these two paradigms into the basic prompts, resulting in "Formatted-MetaReview 1" and "Formatted-MetaReview 2". The \textcolor{red}{red-marked} parts in their prompts are the relevant paradigm contents. 

% We conduct a detailed statistical analysis of the frequencies of these two paradigms and selected the corresponding prompts based on these frequencies. The probabilities we use are shown in Table \ref{tab:prompt frequency}.

% \input{table/direct_linguist_feature_description}
% \input{table/indirect_features_description}

% \section{Feature Description/definition}
% \ref{tab:Direct_Linguistic_Features_description}
% \ref{tab:Indirect_Linguistic_Features_description}


% \begin{figure*}[ht!]
% \centering

% \begin{prompt}[title={Useless Doc ($r_0$)}] \label{prompt_r0}
% <Documents> \newline
% [1] \texttt{\{<Document 1>\}}\newline
% </Documents> \newline

% Your task is to generate an English question q* and a corresponding response a* based on the provided <Documents>. Please note that the question q* can take various forms, not limited to questions with a question mark, but also including statements, instructions, and other formats. You need to follow the requirements below to generate the q* and a* \textcolor{blue}{(RAG Paradigms)}:  

% \textcolor{blue}{1. q* should be related to the <Documents>, but the <Documents> can not provide any useful information for answering q*. \newline
% 2. a* should be able to answer q*, ensuring that the response a* is accurate, detailed, and comprehensive.} 
% \newline

% Additionally, to ensure diversity, richness, and high quality in the question q* you generate, we will randomly provide a question for you to emulate. In other words, while satisfying the requirements above, make q* similar in task requirement and expression to the \textcolor{darkred}{<Simulated Instruction>} below:  

% \textcolor{darkred}{
% <Simulated Instruction> \newline
% \texttt{\{<Simulated Instruction>\}} \newline
% </Simulated Instruction> \newline
% }

% Please directly generate the question-answer pair (q*, a*) following all the rules above in the format of \{"q*": ..., "a*": ...\}. Ensure the quality of the generated (q*, a*).
% \end{prompt}
% \caption{The prompt for synthesizing Useless Doc ($r_0$) data.}
% \label{tab:r_0}
% \end{figure*}









