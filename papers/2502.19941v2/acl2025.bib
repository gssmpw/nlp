@article{DBLP:journals/corr/cs-CL-0108005,
  author    = {Joshua Goodman},
  title     = {A Bit of Progress in Language Modeling},
  journal   = {CoRR},
  volume    = {cs.CL/0108005v1},
  year      = {2001},
  url       = {http://arxiv.org/abs/cs.CL/0108005v1},
  timestamp = {Wed, 07 Jun 2017 14:40:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/cs-CL-0108005},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{GOODMAN2001403,
title = "A bit of progress in language modeling",
journal = "Computer Speech \& Language",
volume = "15",
number = "4",
pages = "403-434",
year = "2001",
issn = "0885-2308",
doi = "10.1006/csla.2001.0174",
OPTurl = "http://www.sciencedirect.com/science/article/pii/S0885230801901743",
author = "Joshua T. Goodman"
}

@article{DBLP:journals/corr/cs-CL-9905001,
  author    = {Rebecca Hwa},
  title     = {Supervised Grammar Induction Using Training Data with Limited Constituent Information},
  journal   = {CoRR},
  volume    = {cs.CL/9905001},
  note = {Version 1},
  year      = {1999},
  url       = {http://arxiv.org/abs/cs.CL/9905001},
  timestamp = {Wed, 07 Jun 2017 14:41:01 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/cs-CL-9905001},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{P99-1010,
  author =  "Hwa, Rebecca",
  title =   "Supervised Grammar Induction using Training Data with Limited Constituent Information",
  booktitle =   "Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics",
  year =    "1999",
  url =     "http://www.aclweb.org/anthology/P99-1010"
}

@book{Jurafsky+Martin:2009a,
  author    = {Jurafsky, Daniel and Martin, James H.},
  title     = {Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition},
  publisher = {Pearson Prentice Hall},
  year      = 2009,
  edition   = {Second}
}

@inproceedings{MQM_old,
  title={Using a new analytic measure for the annotation and analysis of MT errors on real data},
  author={Lommel, Arle and Burchardt, Aljoscha and Popovi{\'c}, Maja and Harris, Kim and Avramidis, Eleftherios and Uszkoreit, Hans},
  booktitle={Proceedings of the 17th Annual conference of the European Association for Machine Translation},
  pages={165--172},
  year={2014}
}

@article{MQM,
  title={Experts, errors, and context: A large-scale study of human evaluation for machine translation},
  author={Freitag, Markus and Foster, George and Grangier, David and Ratnakar, Viresh and Tan, Qijun and Macherey, Wolfgang},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={1460--1474},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{DA,
  title={Can machine translation systems be evaluated by the crowd alone},
  author={Graham, Yvette and Baldwin, Timothy and Moffat, Alistair and Zobel, Justin},
  journal={Natural Language Engineering},
  volume={23},
  number={1},
  pages={3--30},
  year={2017},
  publisher={Cambridge University Press}
}

@inproceedings{wmt2023,
  title={Unify word-level and span-level tasks: NJUNLP’s Participation for the WMT2023 Quality Estimation Shared Task},
  author={Geng, Xiang and Lai, Zhejian and Zhang, Yu and Tao, Shimin and Yang, Hao and Chen, Jiajun and Huang, Shujian},
  booktitle={Proceedings of the Eighth Conference on Machine Translation},
  pages={829--834},
  year={2023}
}

@inproceedings{directqe,
  title={Directqe: Direct pretraining for machine translation quality estimation},
  author={Cui, Qu and Huang, Shujian and Li, Jiahuan and Geng, Xiang and Zheng, Zaixiang and Huang, Guoping and Chen, Jiajun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={14},
  pages={12719--12727},
  year={2021}
}

@article{mtqe,
  title={Quality estimation for machine translation},
  author={Specia, Lucia and Scarton, Carolina and Paetzold, Gustavo Henrique},
  journal={Synthesis Lectures on Human Language Technologies},
  volume={11},
  number={1},
  pages={1--162},
  year={2018},
  publisher={Morgan \& Claypool Publishers}
}

@inproceedings{hter,
  title={A study of translation edit rate with targeted human annotation},
  author={Snover, Matthew and Dorr, Bonnie and Schwartz, Richard and Micciulla, Linnea and Makhoul, John},
  booktitle={Proceedings of association for machine translation in the Americas},
  volume={200},
  number={6},
  year={2006},
  organization={Cambridge, MA}
}

@article{push,
  title={Pushing the Limits of Translation Quality Estimation},
  author={Martins, Andr{\'e} FT and Junczys-Dowmunt, Marcin and Kepler, Fabio and Astudillo, Ram{\'o}n and Hokamp, Chris and Grundkiewicz, Roman},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={205--218},
  year={2017}
}

@inproceedings{effort,
  title={Exploiting objective annotations for minimising translation post-editing effort},
  author={Specia, Lucia},
  booktitle={Proceedings of the 15th Annual conference of the European Association for Machine Translation},
  year={2011}
}

@inproceedings{qe_decode,
  title={Computer Assisted Translation with Neural Quality Estimation and Auotmatic Post-Editing},
  author={Wang, Ke and Wang, Jiayi and Ge, Niyu and Shi, Yangbin and Zhao, Yu and Fan, Kai},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings},
  pages={2175--2186},
  year={2020}
}

@inproceedings{quest,
  title={QuEst-A translation quality estimation framework},
  author={Specia, Lucia and Shah, Kashif and De Souza, Jos{\'e} GC and Cohn, Trevor},
  booktitle={Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
  pages={79--84},
  year={2013}
}

@inproceedings{quetch,
  title={Quality estimation from scratch (quetch): Deep learning for word-level translation quality estimation},
  author={Kreutzer, Julia and Schamoni, Shigehiko and Riezler, Stefan},
  booktitle={Proceedings of the Tenth Workshop on Statistical Machine Translation},
  pages={316--322},
  year={2015}
}

@article{predictor,
  title={Predictor-estimator: Neural quality estimation based on target word prediction for machine translation},
  author={Kim, Hyun and Jung, Hun-Young and Kwon, Hongseok and Lee, Jong-Hyeok and Na, Seung-Hoon},
  journal={ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP)},
  volume={17},
  number={1},
  pages={1--22},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@inproceedings{qe_brain,
  title={“Bilingual Expert” Can Find Translation Errors},
  author={Fan, Kai and Wang, Jiayi and Li, Bo and Zhou, Fengming and Chen, Boxing and Si, Luo},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={6367--6374},
  year={2019}
}
@inproceedings{unbabel19,
    title={Unbabel's Participation in the WMT19 Translation Quality Estimation Shared Task},
    author={Fabio Kepler and Jonay Trénous and Marcos Treviso and Miguel Vera and António Góis and M. Amin Farajian and António V. Lopes and André F. T. Martins},
    year={2019},
    booktitle = "Proceedings of the Fourth Conference on Machine Translation",
}
@inproceedings{SOURCE,
    title = "{SOURCE}: {SOUR}ce-Conditional Elmo-style Model for Machine Translation Quality Estimation",
    author = "Zhou, Junpei  and
      Zhang, Zhisong  and
      Hu, Zecong",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation",
    year = "2019",
}
@inproceedings{QE-BERT,
author = {Kim, Hyun and Lim, Joon-Ho and Kim, Hyunki and Na, Seung-Hoon},
year = {2019},
booktitle = "Proceedings of the Fourth Conference on Machine Translation",
title = {QE BERT: Bilingual BERT Using Multi-task Learning for Neural Quality Estimation},
}
@inproceedings{IST-Unbabel,
  title={Ist-unbabel participation in the wmt20 quality estimation shared task},
  author={Moura, Joao and Vera, Miguel and van Stigt, Daan and Kepler, Fabio and Martins, Andr{\'e} FT},
  booktitle={Proceedings of the Fifth Conference on Machine Translation},
  pages={1029--1036},
  year={2020}
}
@inproceedings{HW-TSC,
  title={Hw-tsc’s participation at wmt 2020 quality estimation shared task},
  author={Wang, Minghan and Yang, Hao and Shang, Hengchao and Wei, Daimeng and Guo, Jiaxin and Lei, Lizhi and Qin, Ying and Tao, Shimin and Sun, Shiliang and Chen, Yimeng and others},
  booktitle={Proceedings of the Fifth Conference on Machine Translation},
  pages={1056--1061},
  year={2020}
}
@inproceedings{NICT,
    title = "{NICT} {K}yoto Submission for the {WMT}{'}20 Quality Estimation Task: Intermediate Training for Domain and Task Adaptation",
    author = "Rubino, Raphael",
    booktitle = "Proceedings of the Fifth Conference on Machine Translation",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.wmt-1.121",
    pages = "1042--1048",
    abstract = "This paper describes the NICT Kyoto submission for the WMT{'}20 Quality Estimation (QE) shared task. We participated in Task 2: Word and Sentence-level Post-editing Effort, which involved Wikipedia data and two translation directions, namely English-to-German and English-to-Chinese. Our approach is based on multi-task fine-tuned cross-lingual language models (XLM), initially pre-trained and further domain-adapted through intermediate training using the translation language model (TLM) approach complemented with a novel self-supervised learning task which aim is to model errors inherent to machine translation outputs. Results obtained on both word and sentence-level QE show that the proposed intermediate training method is complementary to language model domain adaptation and outperforms the fine-tuning only approach.",
}
@inproceedings{tencent,
    title = "Tencent submission for {WMT}20 Quality Estimation Shared Task",
    author = "Wu, Haijiang  and
      Wang, Zixuan  and
      Ma, Qingsong  and
      Wen, Xinjie  and
      Wang, Ruichen  and
      Wang, Xiaoli  and
      Zhang, Yulin  and
      Yao, Zhipeng  and
      Peng, Siyao",
    booktitle = "Proceedings of the Fifth Conference on Machine Translation",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.wmt-1.124",
    pages = "1062--1067",
    abstract = "This paper presents Tencent{'}s submission to the WMT20 Quality Estimation (QE) Shared Task: Sentence-Level Post-editing Effort for English-Chinese in Task 2. Our system ensembles two architectures, XLM-based and Transformer-based Predictor-Estimator models. For the XLM-based Predictor-Estimator architecture, the predictor produces two types of contextualized token representations, i.e., masked XLM and non-masked XLM; the LSTM-estimator and Transformer-estimator employ two effective strategies, top-K and multi-head attention, to enhance the sentence feature representation. For Transformer-based Predictor-Estimator architecture, we improve a top-performing model by conducting three modifications: using multi-decoding in machine translation module, creating a new model by replacing the transformer-based predictor with XLM-based predictor, and finally integrating two models by a weighted average. Our submission achieves a Pearson correlation of 0.664, ranking first (tied) on English-Chinese.",
}
@inproceedings{NiuTrans,
    title = "The {N}iu{T}rans System for the {WMT}20 Quality Estimation Shared Task",
    author = "Hu, Chi  and
      Liu, Hui  and
      Feng, Kai  and
      Xu, Chen  and
      Xu, Nuo  and
      Zhou, Zefan  and
      Yan, Shiqin  and
      Luo, Yingfeng  and
      Wang, Chenglong  and
      Meng, Xia  and
      Xiao, Tong  and
      Zhu, Jingbo",
    booktitle = "Proceedings of the Fifth Conference on Machine Translation",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.wmt-1.117",
    pages = "1018--1023",
    abstract = "This paper describes the submissions of the NiuTrans Team to the WMT 2020 Quality Estimation Shared Task. We participated in all tasks and all language pairs. We explored the combination of transfer learning, multi-task learning and model ensemble. Results on multiple tasks show that deep transformer machine translation models and multilingual pretraining methods significantly improve translation quality estimation performance. Our system achieved remarkable results in multiple level tasks, e.g., our submissions obtained the best results on all tracks in the sentence-level Direct Assessment task.",
}
@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}
@inproceedings{competence,
    title = "Competence-based Curriculum Learning for Neural Machine Translation",
    author = "Platanios, Emmanouil Antonios  and
      Stretcu, Otilia  and
      Neubig, Graham  and
      Poczos, Barnabas  and
      Mitchell, Tom",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1119",
    doi = "10.18653/v1/N19-1119",
    pages = "1162--1172",
}
@inproceedings{dynamic,
    title = "Dynamic Data Selection for Neural Machine Translation",
    author = "van der Wees, Marlies  and
      Bisazza, Arianna  and
      Monz, Christof",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D17-1147",
    doi = "10.18653/v1/D17-1147",
    pages = "1400--1410",
}
@inproceedings{CNAT,
    title = "Non-Autoregressive Translation by Learning Target Categorical Codes",
    author = "Bao, Yu  and
      Huang, Shujian  and
      Xiao, Tong  and
      Wang, Dongqi  and
      Dai, Xinyu  and
      Chen, Jiajun",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.458",
    doi = "10.18653/v1/2021.naacl-main.458",
    pages = "5749--5759",
}
@inproceedings{domain-data-selection,
    title = "Domain Adaptation via Pseudo In-Domain Data Selection",
    author = "Axelrod, Amittai  and
      He, Xiaodong  and
      Gao, Jianfeng",
    booktitle = "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing",
    month = jul,
    year = "2011",
    address = "Edinburgh, Scotland, UK.",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D11-1033",
    pages = "355--362",
}
@inproceedings{denoising,
    title = "Denoising Neural Machine Translation Training with Trusted Data and Online Data Selection",
    author = "Wang, Wei  and
      Watanabe, Taro  and
      Hughes, Macduff  and
      Nakagawa, Tetsuji  and
      Chelba, Ciprian",
    booktitle = "Proceedings of the Third Conference on Machine Translation: Research Papers",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-6314",
    doi = "10.18653/v1/W18-6314",
    pages = "133--143",
}
@article{transformer,
    title={Attention Is All You Need},
    author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year={2017},
    journal={Advances in Neural Information Processing Systems 30},
}
@inproceedings{xlmr,
    title = "Unsupervised Cross-lingual Representation Learning at Scale",
    author = "Conneau, Alexis  and
      Khandelwal, Kartikay  and
      Goyal, Naman  and
      Chaudhary, Vishrav  and
      Wenzek, Guillaume  and
      Guzm{\'a}n, Francisco  and
      Grave, Edouard  and
      Ott, Myle  and
      Zettlemoyer, Luke  and
      Stoyanov, Veselin",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.747",
    doi = "10.18653/v1/2020.acl-main.747",
    pages = "8440--8451",
}
@inproceedings{BPE,
    title = "Neural Machine Translation of Rare Words with Subword Units",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1162",
    doi = "10.18653/v1/P16-1162",
    pages = "1715--1725",
}
@inproceedings{fairseq,
  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},
  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},
  year = {2019},
}
@inproceedings{ensemble,
  title={Neural network ensembles, cross validation, and active learning},
  author={Krogh, Anders and Vedelsby, Jesper},
  booktitle={Advances in neural information processing systems},
  year={1995}
}
@inproceedings{distant_domain,
  title={Distant domain transfer learning},
  author={Tan, Ben and Zhang, Yu and Pan, Sinno and Yang, Qiang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={31},
  number={1},
  year={2017}
}
@article{theoretical_curriculum,
  title={Why curriculum learning \& self-paced learning work in big/noisy data: A theoretical perspective},
  author={Gong, Tieliang and Zhao, Qian and Meng, Deyu and Xu, Zongben},
  journal={Big Data \& Information Analytics},
  volume={1},
  number={1},
  pages={111},
  year={2016},
  publisher={American Institute of Mathematical Sciences}
}
@inproceedings{curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}
@article{unsupervised,
    title = "Unsupervised Quality Estimation for Neural Machine Translation",
    author = "Fomicheva, Marina  and
      Sun, Shuo  and
      Yankovskaya, Lisa  and
      Blain, Fr{\'e}d{\'e}ric  and
      Guzm{\'a}n, Francisco  and
      Fishel, Mark  and
      Aletras, Nikolaos  and
      Chaudhary, Vishrav  and
      Specia, Lucia",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2020.tacl-1.35",
    doi = "10.1162/tacl_a_00330",
    pages = "539--555",
}
@inproceedings{levT_curriculum,
    title = "An Imitation Learning Curriculum for Text Editing with Non-Autoregressive Models",
    author = "Agrawal, Sweta  and
      Carpuat, Marine",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.520",
    pages = "7550--7563",
}
@inproceedings{domain,
    title = "Dynamically Composing Domain-Data Selection with Clean-Data Selection by {``}Co-Curricular Learning{''} for Neural Machine Translation",
    author = "Wang, Wei  and
      Caswell, Isaac  and
      Chelba, Ciprian",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1123",
    doi = "10.18653/v1/P19-1123",
    pages = "1282--1292",
}
@article{gpt2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}
@article{chang2017active,
  title={Active bias: Training more accurate neural networks by emphasizing high variance samples},
  author={Chang, Haw-Shiuan and Learned-Miller, Erik and McCallum, Andrew},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}
@inproceedings{bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}
@inproceedings{meteor,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
    author = "Banerjee, Satanjeev  and
      Lavie, Alon",
    booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W05-0909",
    pages = "65--72",
}
@inproceedings{qe_rerank,
    title = "Energy-Based Reranking: Improving Neural Machine Translation Using Energy-Based Models",
    author = "Bhattacharyya, Sumanta  and
      Rooshenas, Amirmohammad  and
      Naskar, Subhajit  and
      Sun, Simeng  and
      Iyyer, Mohit  and
      McCallum, Andrew",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.349",
    doi = "10.18653/v1/2021.acl-long.349",
    pages = "4528--4537",
    abstract = "The discrepancy between maximum likelihood estimation (MLE) and task measures such as BLEU score has been studied before for autoregressive neural machine translation (NMT) and resulted in alternative training algorithms (Ranzato et al., 2016; Norouzi et al., 2016; Shen et al., 2016; Wu et al., 2018). However, MLE training remains the de facto approach for autoregressive NMT because of its computational efficiency and stability. Despite this mismatch between the training objective and task measure, we notice that the samples drawn from an MLE-based trained NMT support the desired distribution {--} there are samples with much higher BLEU score comparing to the beam decoding output. To benefit from this observation, we train an energy-based model to mimic the behavior of the task measure (i.e., the energy-based model assigns lower energy to samples with higher BLEU score), which is resulted in a re-ranking algorithm based on the samples drawn from NMT: energy-based re-ranking (EBR). We use both marginal energy models (over target sentence) and joint energy models (over both source and target sentences). Our EBR with the joint energy model consistently improves the performance of the Transformer-based NMT: +3.7 BLEU points on IWSLT{'}14 German-English, +3.37 BELU points on Sinhala-English, +1.4 BLEU points on WMT{'}16 English-German tasks.",
}

@article{cat,
    title = "Statistical Approaches to Computer-Assisted Translation",
    author = "Barrachina, Sergio  and
      Bender, Oliver  and
      Casacuberta, Francisco  and
      Civera, Jorge  and
      Cubel, Elsa  and
      Khadivi, Shahram  and
      Lagarda, Antonio  and
      Ney, Hermann  and
      Tom{\'a}s, Jes{\'u}s  and
      Vidal, Enrique  and
      Vilar, Juan-Miguel",
    journal = "Computational Linguistics",
    volume = "35",
    number = "1",
    month = mar,
    year = "2009",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/J09-1002",
    doi = "10.1162/coli.2008.07-055-R2-06-29",
    pages = "3--28",
}

@inproceedings{nmt_ter,
    title = "Quality Estimation without Human-labeled Data",
    author = "Tuan, Yi-Lin  and
      El-Kishky, Ahmed  and
      Renduchintala, Adithya  and
      Chaudhary, Vishrav  and
      Guzm{\'a}n, Francisco  and
      Specia, Lucia",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.50",
    doi = "10.18653/v1/2021.eacl-main.50",
    pages = "619--625",
    abstract = "Quality estimation aims to measure the quality of translated content without access to a reference translation. This is crucial for machine translation systems in real-world scenarios where high-quality translation is needed. While many approaches exist for quality estimation, they are based on supervised machine learning requiring costly human labelled data. As an alternative, we propose a technique that does not rely on examples from human-annotators and instead uses synthetic training data. We train off-the-shelf architectures for supervised quality estimation on our synthetic data and show that the resulting models achieve comparable performance to models trained on human-annotated data, both for sentence and word-level prediction.",
}
@inproceedings{ssqe,
    title = "Self-Supervised Quality Estimation for Machine Translation",
    author = "Zheng, Yuanhang  and
      Tan, Zhixing  and
      Zhang, Meng  and
      Maimaiti, Mieradilijiang  and
      Luan, Huanbo  and
      Sun, Maosong  and
      Liu, Qun  and
      Liu, Yang",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.267",
    doi = "10.18653/v1/2021.emnlp-main.267",
    pages = "3322--3334",
    abstract = "Quality estimation (QE) of machine translation (MT) aims to evaluate the quality of machine-translated sentences without references and is important in practical applications of MT. Training QE models require massive parallel data with hand-crafted quality annotations, which are time-consuming and labor-intensive to obtain. To address the issue of the absence of annotated training data, previous studies attempt to develop unsupervised QE methods. However, very few of them can be applied to both sentence- and word-level QE tasks, and they may suffer from noises in the synthetic data. To reduce the negative impact of noises, we propose a self-supervised method for both sentence- and word-level QE, which performs quality estimation by recovering the masked target words. Experimental results show that our method outperforms previous unsupervised methods on several QE tasks in different language pairs and domains.",
}

@inproceedings{nat_error,
  title={Non-autoregressive machine translation with auxiliary regularization},
  author={Wang, Yiren and Tian, Fei and He, Di and Qin, Tao and Zhai, ChengXiang and Liu, Tie-Yan},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={5377--5384},
  year={2019}
}
@inproceedings{transquest,
    title = "{T}rans{Q}uest: Translation Quality Estimation with Cross-lingual Transformers",
    author = "Ranasinghe, Tharindu  and
      Orasan, Constantin  and
      Mitkov, Ruslan",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.445",
    doi = "10.18653/v1/2020.coling-main.445",
    pages = "5070--5081",
    abstract = "Recent years have seen big advances in the field of sentence-level quality estimation (QE), largely as a result of using neural-based architectures. However, the majority of these methods work only on the language pair they are trained on and need retraining for new language pairs. This process can prove difficult from a technical point of view and is usually computationally expensive. In this paper we propose a simple QE framework based on cross-lingual transformers, and we use it to implement and evaluate two different neural architectures. Our evaluation shows that the proposed methods achieve state-of-the-art results outperforming current open-source quality estimation frameworks when trained on datasets from WMT. In addition, the framework proves very useful in transfer learning settings, especially when dealing with low-resourced languages, allowing us to obtain very competitive results.",
}
@article{tlm,
  title={Cross-lingual language model pretraining},
  author={Conneau, Alexis and Lample, Guillaume},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@inproceedings{etchegoyhen-etal-2018-supervised,
    title = "Supervised and Unsupervised Minimalist Quality Estimators: Vicomtech{'}s Participation in the {WMT} 2018 Quality Estimation Task",
    author = "Etchegoyhen, Thierry  and
      Mart{\'\i}nez Garcia, Eva  and
      Azpeitia, Andoni",
    booktitle = "Proceedings of the Third Conference on Machine Translation: Shared Task Papers",
    month = oct,
    year = "2018",
    address = "Belgium, Brussels",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-6461",
    doi = "10.18653/v1/W18-6461",
    pages = "782--787",
    abstract = "We describe Vicomtech{'}s participation in the WMT 2018 shared task on quality estimation, for which we submitted minimalist quality estimators. The core of our approach is based on two simple features: lexical translation overlaps and language model cross-entropy scores. These features are exploited in two system variants: uMQE is an unsupervised system, where the final quality score is obtained by averaging individual feature scores; sMQE is a supervised variant, where the final score is estimated by a Support Vector Regressor trained on the available annotated datasets. The main goal of our minimalist approach to quality estimation is to provide reliable estimators that require minimal deployment effort, few resources, and, in the case of uMQE, do not depend on costly data annotation or post-editing. Our approach was applied to all language pairs in sentence quality estimation, obtaining competitive results across the board.",
}
@inproceedings{bertscore,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@inproceedings{yisi,
    title = "{Y}i{S}i - a Unified Semantic {MT} Quality Evaluation and Estimation Metric for Languages with Different Levels of Available Resources",
    author = "Lo, Chi-kiu",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-5358",
    doi = "10.18653/v1/W19-5358",
    pages = "507--513",
    abstract = "We present YiSi, a unified automatic semantic machine translation quality evaluation and estimation metric for languages with different levels of available resources. Underneath the interface with different language resources settings, YiSi uses the same representation for the two sentences in assessment. Besides, we show significant improvement in the correlation of YiSi-1{'}s scores with human judgment is made by using contextual embeddings in multilingual BERT{--}Bidirectional Encoder Representations from Transformers to evaluate lexical semantic similarity. YiSi is open source and publicly available.",
}
@inproceedings{dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016},
  organization={PMLR}
}
@inproceedings{code_switching,
    title = "Code-Switching for Enhancing {NMT} with Pre-Specified Translation",
    author = "Song, Kai  and
      Zhang, Yue  and
      Yu, Heng  and
      Luo, Weihua  and
      Wang, Kun  and
      Zhang, Min",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1044",
    doi = "10.18653/v1/N19-1044",
    pages = "449--459",
    abstract = "Leveraging user-provided translation to constrain NMT has practical significance. Existing methods can be classified into two main categories, namely the use of placeholder tags for lexicon words and the use of hard constraints during decoding. Both methods can hurt translation fidelity for various reasons. We investigate a data augmentation method, making code-switched training data by replacing source phrases with their target translations. Our method does not change the MNT model or decoding algorithm, allowing the model to learn lexicon translations by copying source-side target words. Extensive experiments show that our method achieves consistent improvements over existing approaches, improving translation of constrained words without hurting unconstrained words.",
}

@inproceedings{dinu-etal-2019-training,
    title = "Training Neural Machine Translation to Apply Terminology Constraints",
    author = "Dinu, Georgiana  and
      Mathur, Prashant  and
      Federico, Marcello  and
      Al-Onaizan, Yaser",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1294",
    doi = "10.18653/v1/P19-1294",
    pages = "3063--3068",
    abstract = "This paper proposes a novel method to inject custom terminology into neural machine translation at run time. Previous works have mainly proposed modifications to the decoding algorithm in order to constrain the output to include run-time-provided target terms. While being effective, these constrained decoding methods add, however, significant computational overhead to the inference step, and, as we show in this paper, can be brittle when tested in realistic conditions. In this paper we approach the problem by training a neural MT system to learn how to use custom terminology when provided with the input. Comparative experiments show that our method is not only more effective than a state-of-the-art implementation of constrained decoding, but is also as fast as constraint-free decoding.",
}

@inproceedings{gbs,
    title = "Lexically Constrained Decoding for Sequence Generation Using Grid Beam Search",
    author = "Hokamp, Chris  and
      Liu, Qun",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1141",
    doi = "10.18653/v1/P17-1141",
    pages = "1535--1546",
    abstract = "We present Grid Beam Search (GBS), an algorithm which extends beam search to allow the inclusion of pre-specified lexical constraints. The algorithm can be used with any model which generates sequences token by token. Lexical constraints take the form of phrases or words that must be present in the output sequence. This is a very general way to incorporate auxillary knowledge into a model{'}s output without requiring any modification of the parameters or training data. We demonstrate the feasibility and flexibility of Lexically Constrained Decoding by conducting experiments on Neural Interactive-Predictive Translation, as well as Domain Adaptation for Neural Machine Translation. Experiments show that GBS can provide large improvements in translation quality in interactive scenarios, and that, even without any user input, GBS can be used to achieve significant gains in performance in domain adaptation scenarios.",
}

@inproceedings{hu-etal-2019-improved,
    title = "Improved Lexically Constrained Decoding for Translation and Monolingual Rewriting",
    author = "Hu, J. Edward  and
      Khayrallah, Huda  and
      Culkin, Ryan  and
      Xia, Patrick  and
      Chen, Tongfei  and
      Post, Matt  and
      Van Durme, Benjamin",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1090",
    doi = "10.18653/v1/N19-1090",
    pages = "839--850",
    abstract = "Lexically-constrained sequence decoding allows for explicit positive or negative phrase-based constraints to be placed on target output strings in generation tasks such as machine translation or monolingual text rewriting. We describe vectorized dynamic beam allocation, which extends work in lexically-constrained decoding to work with batching, leading to a five-fold improvement in throughput when working with positive constraints. Faster decoding enables faster exploration of constraint strategies: we illustrate this via data augmentation experiments with a monolingual rewriter applied to the tasks of natural language inference, question answering and machine translation, showing improvements in all three.",
}
@inproceedings{19_unbabels_ape,
    title = "Unbabel{'}s Submission to the {WMT}2019 {APE} Shared Task: {BERT}-Based Encoder-Decoder for Automatic Post-Editing",
    author = "Lopes, Ant{\'o}nio V.  and
      Farajian, M. Amin  and
      Correia, Gon{\c{c}}alo M.  and
      Tr{\'e}nous, Jonay  and
      Martins, Andr{\'e} F. T.",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-5413",
    doi = "10.18653/v1/W19-5413",
    pages = "118--123",
    abstract = "This paper describes Unbabel{'}s submission to the WMT2019 APE Shared Task for the English-German language pair. Following the recent rise of large, powerful, pre-trained models, we adapt the BERT pretrained model to perform Automatic Post-Editing in an encoder-decoder framework. Analogously to dual-encoder architectures we develop a BERT-based encoder-decoder (BED) model in which a single pretrained BERT encoder receives both the source src and machine translation mt strings. Furthermore, we explore a conservativeness factor to constrain the APE system to perform fewer edits. As the official results show, when trained on a weighted combination of in-domain and artificial training data, our BED system with the conservativeness penalty improves significantly the translations of a strong NMT system by -0.78 and +1.23 in terms of TER and BLEU, respectively. Finally, our submission achieves a new state-of-the-art, ex-aequo, in English-German APE of NMT.",
}

@article{kd,
  title={Understanding knowledge distillation in non-autoregressive machine translation},
  author={Zhou, Chunting and Neubig, Graham and Gu, Jiatao},
  journal={arXiv preprint arXiv:1911.02727},
  year={2019}
}

@inproceedings{ott2018analyzing,
  title={Analyzing Uncertainty in Neural Machine Translation.},
  author={Ott, Myle and Auli, Michael and Grangier, David and Marc'Aurelio Ranzato},
  booktitle={ICML},
  pages={3953--3962},
  year={2018}
}
@article{self_ensemble,
  title={Temporal ensembling for semi-supervised learning},
  author={Laine, Samuli and Aila, Timo},
  journal={arXiv preprint arXiv:1610.02242},
  year={2016}
}

@inproceedings{hallucination,
    title = "Detecting Hallucinated Content in Conditional Neural Sequence Generation",
    author = "Zhou, Chunting  and
      Neubig, Graham  and
      Gu, Jiatao  and
      Diab, Mona  and
      Guzm{\'a}n, Francisco  and
      Zettlemoyer, Luke  and
      Ghazvininejad, Marjan",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.120",
    doi = "10.18653/v1/2021.findings-acl.120",
    pages = "1393--1404",
}

@article{rlhf,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{sun-etal-2020-estimating,
    title = "Are we Estimating or Guesstimating Translation Quality?",
    author = "Sun, Shuo  and
      Guzm{\'a}n, Francisco  and
      Specia, Lucia",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.558",
    doi = "10.18653/v1/2020.acl-main.558",
    pages = "6262--6267",
    abstract = "Recent advances in pre-trained multilingual language models lead to state-of-the-art results on the task of quality estimation (QE) for machine translation. A carefully engineered ensemble of such models won the QE shared task at WMT19. Our in-depth analysis, however, shows that the success of using pre-trained language models for QE is over-estimated due to three issues we observed in current QE datasets: (i) The distributions of quality scores are imbalanced and skewed towards good quality scores; (iii) QE models can perform well on these datasets while looking at only source or translated sentences; (iii) They contain statistical artifacts that correlate well with human-annotated QE labels. Our findings suggest that although QE models might capture fluency of translated sentences and complexity of source sentences, they cannot model adequacy of translations effectively.",
}
@inproceedings{zhou-etal-2020-zero,
    title = "Zero-Shot Translation Quality Estimation with Explicit Cross-Lingual Patterns",
    author = "Zhou, Lei  and
      Ding, Liang  and
      Takeda, Koichi",
    booktitle = "Proceedings of the Fifth Conference on Machine Translation",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.wmt-1.125",
    pages = "1068--1074",
    abstract = "This paper describes our submission of the WMT 2020 Shared Task on Sentence Level Direct Assessment, Quality Estimation (QE). In this study, we empirically reveal the mismatching issue when directly adopting BERTScore (Zhang et al., 2020) to QE. Specifically, there exist lots of mismatching errors between source sentence and translated candidate sentence with token pairwise similarity. In response to this issue, we propose to expose explicit cross lingual patterns, e.g. word alignments and generation score, to our proposed zero-shot models. Experiments show that our proposed QE model with explicit cross-lingual patterns could alleviate the mismatching issue, thereby improving the performance. Encouragingly, our zero-shot QE method could achieve comparable performance with supervised QE method, and even outperforms the supervised counterpart on 2 out of 6 directions. We expect our work could shed light on the zero-shot QE model improvement.",
}

@inproceedings{comet,
    title = "{COMET}: A Neural Framework for {MT} Evaluation",
    author = "Rei, Ricardo  and
      Stewart, Craig  and
      Farinha, Ana C  and
      Lavie, Alon",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.213",
    doi = "10.18653/v1/2020.emnlp-main.213",
    pages = "2685--2702",
    abstract = "We present COMET, a neural framework for training multilingual machine translation evaluation models which obtains new state-of-the-art levels of correlation with human judgements. Our framework leverages recent breakthroughs in cross-lingual pretrained language modeling resulting in highly multilingual and adaptable MT evaluation models that exploit information from both the source input and a target-language reference translation in order to more accurately predict MT quality. To showcase our framework, we train three models with different types of human judgements: Direct Assessments, Human-mediated Translation Edit Rate and Multidimensional Quality Metric. Our models achieve new state-of-the-art performance on the WMT 2019 Metrics shared task and demonstrate robustness to high-performing systems.",
}

@inproceedings{chatterjee-etal-2019-findings,
    title = "Findings of the {WMT} 2019 Shared Task on Automatic Post-Editing",
    author = "Chatterjee, Rajen  and
      Federmann, Christian  and
      Negri, Matteo  and
      Turchi, Marco",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-5402",
    doi = "10.18653/v1/W19-5402",
    pages = "11--28",
    abstract = "We present the results from the 5th round of the WMT task on MT Automatic Post-Editing. The task consists in automatically correcting the output of a {``}black-box{''} machine translation system by learning from human corrections. Keeping the same general evaluation setting of the previous four rounds, this year we focused on two language pairs (English-German and English-Russian) and on domain-specific data (In-formation Technology). For both the language directions, MT outputs were produced by neural systems unknown to par-ticipants. Seven teams participated in the English-German task, with a total of 18 submitted runs. The evaluation, which was performed on the same test set used for the 2018 round, shows a slight progress in APE technology: 4 teams achieved better results than last year{'}s winning system, with improvements up to -0.78 TER and +1.23 BLEU points over the baseline. Two teams participated in theEnglish-Russian task submitting 2 runs each. On this new language direction, characterized by a higher quality of the original translations, the task proved to be particularly challenging. None of the submitted runs improved the very high results of the strong system used to produce the initial translations(16.16 TER, 76.20 BLEU).",
}

@inproceedings{freitag-etal-2022-results,
    title = "Results of {WMT}22 Metrics Shared Task: Stop Using {BLEU} {--} Neural Metrics Are Better and More Robust",
    author = "Freitag, Markus  and
      Rei, Ricardo  and
      Mathur, Nitika  and
      Lo, Chi-kiu  and
      Stewart, Craig  and
      Avramidis, Eleftherios  and
      Kocmi, Tom  and
      Foster, George  and
      Lavie, Alon  and
      Martins, Andr{\'e} F. T.",
    booktitle = "Proceedings of the Seventh Conference on Machine Translation (WMT)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.wmt-1.2",
    pages = "46--68",
    abstract = "This paper presents the results of the WMT22 Metrics Shared Task. Participants submitting automatic MT evaluation metrics were asked to score the outputs of the translation systems competing in the WMT22 News Translation Task on four different domains: news, social, ecommerce, and chat. All metrics were evaluated on how well they correlate with human ratings at the system and segment level.Similar to last year, we acquired our own human ratings based on expert-based human evaluation via Multidimensional Quality Metrics (MQM). This setup had several advantages, among other things: (i) expert-based evaluation is more reliable, (ii) we extended the pool of translations by 5 additional translations based on MBR decoding or rescoring which are challenging for current metrics. In addition, we initiated a challenge set subtask, where participants had to create contrastive test suites for evaluating metrics{'} ability to capture and penalise specific types of translation errors.Finally, we present an extensive analysis on how well metrics perform on three language pairs: English to German, English to Russian and Chinese to English. The results demonstrate the superiority of neural-based learned metrics and demonstrate again that overlap metrics like Bleu, spBleu or chrf correlate poorly with human ratings. The results also reveal that neural-based metrics are remarkably robust across different domains and challenges.",
}

@inproceedings{unite,
    title = "{U}ni{TE}: Unified Translation Evaluation",
    author = "Wan, Yu  and
      Liu, Dayiheng  and
      Yang, Baosong  and
      Zhang, Haibo  and
      Chen, Boxing  and
      Wong, Derek  and
      Chao, Lidia",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.558",
    doi = "10.18653/v1/2022.acl-long.558",
    pages = "8117--8127",
    abstract = "Translation quality evaluation plays a crucial role in machine translation. According to the input format, it is mainly separated into three tasks, \textit{i.e.}, reference-only, source-only and source-reference-combined. Recent methods, despite their promising results, are specifically designed and optimized on one of them. This limits the convenience of these methods, and overlooks the commonalities among tasks. In this paper, we propose , which is the first unified framework engaged with abilities to handle all three evaluation tasks. Concretely, we propose monotonic regional attention to control the interaction among input segments, and unified pretraining to better adapt multi-task training. We testify our framework on WMT 2019 Metrics and WMT 2020 Quality Estimation benchmarks. Extensive analyses show that our \textit{single model} can universally surpass various state-of-the-art or winner methods across tasks.Both source code and associated models are available at https://github.com/NLP2CT/UniTE.",
}
@inproceedings{graham2015improving,
  title={Improving evaluation of machine translation quality estimation},
  author={Graham, Yvette},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={1804--1813},
  year={2015}
}

@inproceedings{specia2021findings,
  title={Findings of the WMT 2021 shared task on quality estimation},
  author={Specia, Lucia and Blain, Fr{\'e}d{\'e}ric and Fomicheva, Marina and Zerva, Chrysoula and Li, Zhenhao and Chaudhary, Vishrav and Martins, Andr{\'e} FT},
  booktitle={Proceedings of the Sixth Conference on Machine Translation},
  pages={684--725},
  year={2021}
}

@article{tang2020multilingual,
  title={Multilingual translation with extensible multilingual pretraining and finetuning},
  author={Tang, Yuqing and Tran, Chau and Li, Xian and Chen, Peng-Jen and Goyal, Naman and Chaudhary, Vishrav and Gu, Jiatao and Fan, Angela},
  journal={arXiv preprint arXiv:2008.00401},
  year={2020}
}

@article{geng2022njunlp,
  title={NJUNLP’s Participation for the WMT2022 Quality Estimation Shared Task},
  author={Geng, Xiang and Zhang, Yu and Huang, Shujian and Tao, Shimin and Yang, Hao and Chen, Jiajun},
  journal={WMT 2022},
  pages={615},
  year={2022}
}

@inproceedings{llmrefine,
    title = "{LLMR}efine: Pinpointing and Refining Large Language Models via Fine-Grained Actionable Feedback",
    author = "Xu, Wenda  and
      Deutsch, Daniel  and
      Finkelstein, Mara  and
      Juraska, Juraj  and
      Zhang, Biao  and
      Liu, Zhongtao  and
      Wang, William Yang  and
      Li, Lei  and
      Freitag, Markus",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.92",
    doi = "10.18653/v1/2024.findings-naacl.92",
    pages = "1429--1445",
    abstract = "Recent large language models (LLM) areleveraging human feedback to improve theirgeneration quality. However, human feedbackis costly to obtain, especially during inference.In this work, we propose LLMRefine, aninference time optimization method to refineLLM{'}s output. The core idea is to usea learned fine-grained feedback model topinpoint defects and guide LLM to refinethem iteratively. Using original LLM as aproposal of edits, LLMRefine searches fordefect-less text via simulated annealing, tradingoff the exploration and exploitation. Weconduct experiments on three text generationtasks, including machine translation, long-form question answering (QA), and topicalsummarization. LLMRefine consistentlyoutperforms all baseline approaches, achievingimprovements up to 1.7 MetricX points ontranslation tasks, 8.1 ROUGE-L on ASQA, 2.2ROUGE-L on topical summarization.",
}


@inproceedings{QE-as-RM,
    title = "Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model",
    author = "He, Zhiwei  and
      Wang, Xing  and
      Jiao, Wenxiang  and
      Zhang, Zhuosheng  and
      Wang, Rui  and
      Shi, Shuming  and
      Tu, Zhaopeng",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.451",
    doi = "10.18653/v1/2024.naacl-long.451",
    pages = "8164--8180",
    abstract = "Insufficient modeling of human preferences within the reward model is a major obstacle for leveraging human feedback to improve translation quality. Fortunately, quality estimation (QE), which predicts the quality of a given translation without reference, has achieved impressive alignment with human evaluations in the last two years. In this work, we investigate the potential of employing the QE model as the reward model to predict human preferences for feedback training. We first identify the overoptimization problem during QE-based feedback training, manifested as an increase in reward while translation quality declines. We examine the problem and argue that the vulnerability of the QE model might lead to high rewards for incorrect translations, resulting in overoptimization and error propagation. To address the problem, we adopt a simple yet effective method that uses heuristic rules to detect the incorrect translations and assigns a penalty term to the reward scores of them. Experimental results show that the proposed QE-based feedback training achieves consistent and significant improvements across various settings, further verified through human preference studies. Our subsequent analysis demonstrates the high data efficiency of the proposed QE-based feedback training: it outperforms systems using larger parallel corpora by a small amount of monolingual data. Our code is available at: https://github.com/zwhe99/FeedbackMT",
}

@inproceedings{wmt2023-findings,
    title = "Findings of the {WMT} 2023 Shared Task on Quality Estimation",
    author = "Blain, Frederic  and
      Zerva, Chrysoula  and
      Rei, Ricardo  and
      Guerreiro, Nuno M.  and
      Kanojia, Diptesh  and
      C. de Souza, Jos{\'e} G.  and
      Silva, Beatriz  and
      Vaz, T{\^a}nia  and
      Jingxuan, Yan  and
      Azadi, Fatemeh  and
      Orasan, Constantin  and
      Martins, Andr{\'e}",
    editor = "Koehn, Philipp  and
      Haddow, Barry  and
      Kocmi, Tom  and
      Monz, Christof",
    booktitle = "Proceedings of the Eighth Conference on Machine Translation",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.wmt-1.52",
    doi = "10.18653/v1/2023.wmt-1.52",
    pages = "629--653",
    abstract = "We report the results of the WMT 2023 shared task on Quality Estimation, in which the challenge is to predict the quality of the output of neural machine translation systems at the word and sentence levels, without access to reference translations. This edition introduces a few novel aspects and extensions that aim to enable more fine-grained, and explainable quality estimation approaches. We introduce an updated quality annotation scheme using Multidimensional Quality Metrics to obtain sentence- and word-level quality scores for three language pairs. We also extend the provided data to new language pairs: we specifically target low-resource languages and provide training, development and test data for English-Hindi, English-Tamil, English-Telegu and English-Gujarati as well as a zero-shot test-set for English-Farsi. Further, we introduce a novel fine-grained error prediction task aspiring to motivate research towards more detailed quality predictions.",
}

@inproceedings{instructscore,
    title = "{INSTRUCTSCORE}: Towards Explainable Text Generation Evaluation with Automatic Feedback",
    author = "Xu, Wenda  and
      Wang, Danqing  and
      Pan, Liangming  and
      Song, Zhenqiao  and
      Freitag, Markus  and
      Wang, William  and
      Li, Lei",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.365",
    doi = "10.18653/v1/2023.emnlp-main.365",
    pages = "5967--5994",
    abstract = "Automatically evaluating the quality of language generation is critical. Although recent learned metrics show high correlation with human judgement, these metrics do not provide explicit explanation of their verdict, nor associate the scores with defects in the generated text. To address this limitation, we present INSTRUCTSCORE, a fine-grained explainable evaluation metric for text generation. By harnessing both explicit human instruction and the implicit knowledge of GPT-4, we fine-tune a text evaluation metric based on LLaMA, producing both a score for generated text and a human readable diagnostic report. We evaluate INSTRUCTSCORE on a variety of generation tasks, including translation, captioning, data-to-text, and commonsense generation. Experiments show that our 7B model surpasses all other unsupervised metrics, including those based on 175B GPT-3 and GPT-4. Surprisingly, our INSTRUCTSCORE, even without direct supervision from human-rated data, achieves performance levels on par with state-of-the-art metrics like COMET22, which were fine-tuned on human ratings.",
}

@article{gpt4,
  title={Gpt-4 technical report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{DistributionShift,
  title={Assessing the Impact of Distribution Shift on Reinforcement Learning Performance},
  author={Fujimoto, Ted and Suetterlein, Joshua and Chatterjee, Samrat and Ganguly, Auroop},
  year = "2023",
  booktitle={NeurIPS 2023 Workshop on Regulatable ML}
}

@inproceedings{bpo,
    title = "{BPO}: Staying Close to the Behavior {LLM} Creates Better Online {LLM} Alignment",
    author = "Xu, Wenda  and
      Li, Jiachen  and
      Wang, William Yang  and
      Li, Lei",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.623",
    pages = "11125--11139",
    abstract = "Direct alignment from preferences (DAP) has emerged as a promising paradigm for aligning large language models (LLMs) to human desiderata from pre-collected, offline preference datasets. While recent studies indicate that existing offline DAP methods can directly benefit from online training samples, we highlight the need to develop specific online DAP algorithms to fully harness the power of online training. Specifically, we identify that the learned LLM should adhere to the proximity of the behavior LLM, which collects the training samples. To this end, we propose online Preference Optimization in proximity to the Behavior LLM (BPO), emphasizing the importance of constructing a proper trust region for LLM alignment.We conduct extensive experiments to validate the effectiveness and applicability of our approach by integrating it with various DAP methods, resulting in significant performance improvements across a wide range of tasks when training with the same amount of preference data. Even when only introducing one additional data collection phase, our online BPO improves its offline DAP baseline from 72.0{\%} to 80.2{\%} on TL;DR and from 82.2{\%} to 89.1{\%} on Anthropic Helpfulness in terms of win rate against human reference text.",
}

@inproceedings{cbsqe,
    title = "Improved Pseudo Data for Machine Translation Quality Estimation with Constrained Beam Search",
    author = "Geng, Xiang  and
      Zhang, Yu  and
      Lai, Zhejian  and
      She, Shuaijie  and
      Zou, Wei  and
      Tao, Shimin  and
      Yang, Hao  and
      Chen, Jiajun  and
      Huang, Shujian",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.764",
    doi = "10.18653/v1/2023.emnlp-main.764",
    pages = "12434--12447",
    abstract = "Machine translation (MT) quality estimation (QE) is a crucial task to estimate the quality of MT outputs when reference translations are unavailable. Many studies focus on generating pseudo data using large parallel corpus and achieve remarkable success in the supervised setting. However, pseudo data solutions are less satisfying in unsupervised scenarios because the pseudo labels are inaccurate or the pseudo translations differ from the real ones. To address these problems, we propose to generate pseudo data using the MT model with constrained beam search (CBSQE). CBSQE preserves the reference parts with high MT probabilities as correct translations, while the rest parts as the wrong ones for MT generation. Therefore, CBSQE can reduce the false negative labels caused by synonyms. Overall, beam search will prefer a more real hypothesis with a higher MT generation likelihood. Extensive experiments demonstrate that CBSQE outperforms strong baselines in both supervised and unsupervised settings. Analyses further show the superiority of CBSQE. The code is available at https://github.com/NJUNLP/njuqe.",
}

@inproceedings{gemba-mqm,
    title = "{GEMBA}-{MQM}: Detecting Translation Quality Error Spans with {GPT}-4",
    author = "Kocmi, Tom  and
      Federmann, Christian",
    editor = "Koehn, Philipp  and
      Haddow, Barry  and
      Kocmi, Tom  and
      Monz, Christof",
    booktitle = "Proceedings of the Eighth Conference on Machine Translation",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.wmt-1.64",
    doi = "10.18653/v1/2023.wmt-1.64",
    pages = "768--775",
    abstract = "This paper introduces GEMBA-MQM, a GPT-based evaluation metric designed to detect translation quality errors, specifically for the quality estimation setting without the need for human reference translations. Based on the power of large language models (LLM), GEMBA-MQM employs a fixed three-shot prompting technique, querying the GPT-4 model to mark error quality spans. Compared to previous works, our method has language-agnostic prompts, thus avoiding the need for manual prompt preparation for new languages. While preliminary results indicate that GEMBA-MQM achieves state-of-the-art accuracy for system ranking, we advise caution when using it in academic works to demonstrate improvements over other methods due to its dependence on the proprietary, black-box GPT model.",
}
@inproceedings{europarl,
    title = "{E}uroparl: A Parallel Corpus for Statistical Machine Translation",
    author = "Koehn, Philipp",
    booktitle = "Proceedings of Machine Translation Summit X: Papers",
    month = sep # " 13-15",
    year = "2005",
    address = "Phuket, Thailand",
    url = "https://aclanthology.org/2005.mtsummit-papers.11",
    pages = "79--86",
    abstract = "We collected a corpus of parallel text in 11 languages from the proceedings of the European Parliament, which are published on the web. This corpus has found widespread use in the NLP community. Here, we focus on its acquisition and its application as training data for statistical machine translation (SMT). We trained SMT systems for 110 language pairs, which reveal interesting clues into the challenges ahead.",
}
@inproceedings{wmt-2023-mt-findings,
    title = "Findings of the 2023 Conference on Machine Translation ({WMT}23): {LLM}s Are Here but Not Quite There Yet",
    author = "Kocmi, Tom  and
      Avramidis, Eleftherios  and
      Bawden, Rachel  and
      Bojar, Ond{\v{r}}ej  and
      Dvorkovich, Anton  and
      Federmann, Christian  and
      Fishel, Mark  and
      Freitag, Markus  and
      Gowda, Thamme  and
      Grundkiewicz, Roman  and
      Haddow, Barry  and
      Koehn, Philipp  and
      Marie, Benjamin  and
      Monz, Christof  and
      Morishita, Makoto  and
      Murray, Kenton  and
      Nagata, Makoto  and
      Nakazawa, Toshiaki  and
      Popel, Martin  and
      Popovi{\'c}, Maja  and
      Shmatova, Mariya",
    editor = "Koehn, Philipp  and
      Haddow, Barry  and
      Kocmi, Tom  and
      Monz, Christof",
    booktitle = "Proceedings of the Eighth Conference on Machine Translation",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.wmt-1.1",
    doi = "10.18653/v1/2023.wmt-1.1",
    pages = "1--42",
    abstract = "This paper presents the results of the General Machine Translation Task organised as part of the 2023 Conference on Machine Translation (WMT). In the general MT task, participants were asked to build machine translation systems for any of 8 language pairs (corresponding to 14 translation directions), to be evaluated on test sets consisting of up to four different domains. We evaluate system outputs with professional human annotators using a combination of source-based Direct Assessment and scalar quality metric (DA+SQM).",
}

@inproceedings{cometkiwi2022,
    title = "{C}omet{K}iwi: {IST}-Unbabel 2022 Submission for the Quality Estimation Shared Task",
    author = "Rei, Ricardo  and
      Treviso, Marcos  and
      Guerreiro, Nuno M.  and
      Zerva, Chrysoula  and
      Farinha, Ana C  and
      Maroti, Christine  and
      C. de Souza, Jos{\'e} G.  and
      Glushkova, Taisiya  and
      Alves, Duarte  and
      Coheur, Luisa  and
      Lavie, Alon  and
      Martins, Andr{\'e} F. T.",
    editor = {Koehn, Philipp  and
      Barrault, Lo{\"\i}c  and
      Bojar, Ond{\v{r}}ej  and
      Bougares, Fethi  and
      Chatterjee, Rajen  and
      Costa-juss{\`a}, Marta R.  and
      Federmann, Christian  and
      Fishel, Mark  and
      Fraser, Alexander  and
      Freitag, Markus  and
      Graham, Yvette  and
      Grundkiewicz, Roman  and
      Guzman, Paco  and
      Haddow, Barry  and
      Huck, Matthias  and
      Jimeno Yepes, Antonio  and
      Kocmi, Tom  and
      Martins, Andr{\'e}  and
      Morishita, Makoto  and
      Monz, Christof  and
      Nagata, Masaaki  and
      Nakazawa, Toshiaki  and
      Negri, Matteo  and
      N{\'e}v{\'e}ol, Aur{\'e}lie  and
      Neves, Mariana  and
      Popel, Martin  and
      Turchi, Marco  and
      Zampieri, Marcos},
    booktitle = "Proceedings of the Seventh Conference on Machine Translation (WMT)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.wmt-1.60",
    pages = "634--645",
    abstract = "We present the joint contribution of IST and Unbabel to the WMT 2022 Shared Task on Quality Estimation (QE). Our team participated in all three subtasks: (i) Sentence and Word-level Quality Prediction; (ii) Explainable QE; and (iii) Critical Error Detection. For all tasks we build on top of the COMET framework, connecting it with the predictor-estimator architecture of OpenKiwi, and equipping it with a word-level sequence tagger and an explanation extractor. Our results suggest that incorporating references during pretraining improves performance across several language pairs on downstream tasks, and that jointly training with sentence and word-level objectives yields a further boost. Furthermore, combining attention and gradient information proved to be the top strategy for extracting good explanations of sentence-level QE models. Overall, our submissions achieved the best results for all three tasks for almost all language pairs by a considerable margin.",
}

@inproceedings{cometkiwi2023,
    title = "Scaling up {C}omet{K}iwi: Unbabel-{IST} 2023 Submission for the Quality Estimation Shared Task",
    author = "Rei, Ricardo  and
      Guerreiro, Nuno M.  and
      Pombal, Jos{\~A}{\copyright}  and
      van Stigt, Daan  and
      Treviso, Marcos  and
      Coheur, Luisa  and
      C. de Souza, Jos{\'e} G.  and
      Martins, Andr{\'e}",
    editor = "Koehn, Philipp  and
      Haddow, Barry  and
      Kocmi, Tom  and
      Monz, Christof",
    booktitle = "Proceedings of the Eighth Conference on Machine Translation",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.wmt-1.73",
    doi = "10.18653/v1/2023.wmt-1.73",
    pages = "841--848",
    abstract = "We present the joint contribution of Unbabel and Instituto Superior T{\'e}cnico to the WMT 2023 Shared Task on Quality Estimation (QE). Our team participated on all tasks: Sentence- and Word-level Quality Prediction and Fine-grained error span detection. For all tasks we build on the CometKiwi model (rei et al. 2022). Our multilingual approaches are ranked first for all tasks, reaching state-of-the-art performance for quality estimation at word-, span- and sentence-level granularity. Compared to the previous state-of-the-art, CometKiwi, we show large improvements in correlation with human judgements (up to 10 Spearman points) and surpassing the second-best multilingual submission with up to 3.8 absolute points.",
}

@inproceedings{clqe,
  title={Denoising pre-training for machine translation quality estimation with curriculum learning},
  author={Geng, Xiang and Zhang, Yu and Li, Jiahuan and Huang, Shujian and Yang, Hao and Tao, Shimin and Chen, Yimeng and Xie, Ning and Chen, Jiajun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={11},
  pages={12827--12835},
  year={2023}
}
@article{unsupervised_qe,
  title={Unsupervised quality estimation for neural machine translation},
  author={Fomicheva, Marina and Sun, Shuo and Yankovskaya, Lisa and Blain, Fr{\'e}d{\'e}ric and Guzm{\'a}n, Francisco and Fishel, Mark and Aletras, Nikolaos and Chaudhary, Vishrav and Specia, Lucia},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={539--555},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@article{xu2024contrastive,
  title={Contrastive preference optimization: Pushing the boundaries of llm performance in machine translation},
  author={Xu, Haoran and Sharaf, Amr and Chen, Yunmo and Tan, Weiting and Shen, Lingfeng and Van Durme, Benjamin and Murray, Kenton and Kim, Young Jin},
  journal={arXiv preprint arXiv:2401.08417},
  year={2024}
}
@inproceedings{self-bleu,
  title={Texygen: A benchmarking platform for text generation models},
  author={Zhu, Yaoming and Lu, Sidi and Zheng, Lei and Guo, Jiaxian and Zhang, Weinan and Wang, Jun and Yu, Yong},
  booktitle={The 41st international ACM SIGIR conference on research \& development in information retrieval},
  pages={1097--1100},
  year={2018}
}
@inproceedings{zhou-etal-2017-neural,
    title = "Neural System Combination for Machine Translation",
    author = "Zhou, Long  and
      Hu, Wenpeng  and
      Zhang, Jiajun  and
      Zong, Chengqing",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-2060/",
    doi = "10.18653/v1/P17-2060",
    pages = "378--384",
    abstract = "Neural machine translation (NMT) becomes a new approach to machine translation and generates much more fluent results compared to statistical machine translation (SMT). However, SMT is usually better than NMT in translation adequacy. It is therefore a promising direction to combine the advantages of both NMT and SMT. In this paper, we propose a neural system combination framework leveraging multi-source NMT, which takes as input the outputs of NMT and SMT systems and produces the final translation. Extensive experiments on the Chinese-to-English translation task show that our model archives significant improvement by 5.3 BLEU points over the best single system output and 3.4 BLEU points over the state-of-the-art traditional system combination methods."
}
@inproceedings{williams_test,
  title={Testing for significance of increased correlation with human judgment},
  author={Graham, Yvette and Baldwin, Timothy},
  booktitle={Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={172--176},
  year={2014}
}
@article{lu2024mqm,
  title={MQM-APE: Toward High-Quality Error Annotation Predictors with Automatic Post-Editing in LLM Translation Evaluators},
  author={Lu, Qingyu and Ding, Liang and Zhang, Kanjian and Zhang, Jinxia and Tao, Dacheng},
  journal={arXiv preprint arXiv:2409.14335},
  year={2024}
}
@article{muller2019domain,
  title={Domain robustness in neural machine translation},
  author={M{\"u}ller, Mathias and Rios, Annette and Sennrich, Rico},
  journal={arXiv preprint arXiv:1911.03109},
  year={2019}
}
@inproceedings{azizi2021t,
  title={$\{$T-Miner$\}$: A generative approach to defend against trojan attacks on $\{$DNN-based$\}$ text classification},
  author={Azizi, Ahmadreza and Tahmid, Ibrahim Asadullah and Waheed, Asim and Mangaokar, Neal and Pu, Jiameng and Javed, Mobin and Reddy, Chandan K and Viswanath, Bimal},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2255--2272},
  year={2021}
}
@inproceedings{lca,
  title={On finding lowest common ancestors in trees},
  author={Aho, Alfred V and Hopcroft, John E and Ullman, Jeffrey D},
  booktitle={Proceedings of the fifth annual ACM symposium on Theory of computing},
  pages={253--265},
  year={1973}
}
@inproceedings{scarton2015ushef,
  title={USHEF and USAAR-USHEF participation in the WMT15 QE shared task},
  author={Scarton, Carolina and Tan, Liling and Specia, Lucia},
  booktitle={Proceedings of the Tenth Workshop on Statistical Machine Translation},
  pages={336--341},
  year={2015}
}
@inproceedings{shah2015investigating,
  title={Investigating continuous space language models for machine translation quality estimation},
  author={Shah, Kashif and Ng, Raymond WM and Bougares, Fethi and Specia, Lucia},
  booktitle={Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  pages={1073--1078},
  year={2015}
}
@misc{qi2020stanzapythonnaturallanguage,
      title={Stanza: A Python Natural Language Processing Toolkit for Many Human Languages}, 
      author={Peng Qi and Yuhao Zhang and Yuhui Zhang and Jason Bolton and Christopher D. Manning},
      year={2020},
      eprint={2003.07082},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2003.07082}, 
}

@misc{gu2025surveyllmasajudge,
      title={A Survey on LLM-as-a-Judge}, 
      author={Jiawei Gu and Xuhui Jiang and Zhichao Shi and Hexiang Tan and Xuehao Zhai and Chengjin Xu and Wei Li and Yinghan Shen and Shengjie Ma and Honghao Liu and Saizhuo Wang and Kun Zhang and Yuanzhuo Wang and Wen Gao and Lionel Ni and Jian Guo},
      year={2025},
      eprint={2411.15594},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.15594}, 
}
@article{pkuseg,
  author = {Luo, Ruixuan and Xu, Jingjing and Zhang, Yi and Zhang, Zhiyuan and Ren, Xuancheng and Sun, Xu},
  journal = {CoRR},
  title = {PKUSEG: A Toolkit for Multi-Domain Chinese Word Segmentation.},
  url = {https://arxiv.org/abs/1906.11455},
  volume = {abs/1906.11455},
  year = 2019
}