\textbf{Motivation.} Social media platforms have revolutionized communication, enabling rapid information sharing but also amplifying the spread of misinformation, including rumours and fake news \cite{vosoughi2018spread}. Crises like the the Russia-Ukraine war highlight the susceptibility of users to such content \cite{aimeur2023fake}. The unchecked dissemination of rumours can cause significant harm \cite{ahsan2019rumors}, emphasizing the need for automated detection methods that mitigate the spread of rumours \cite{thorne2018automated}. To meet this challenge, it is essential to develop trustworthy tools that not only detect rumours effectively but also provide clear, interpretable explanations for their predictions.

%Social media platforms have become an integral part of modern life, facilitating connections among like-minded individuals and enabling the rapid exchange and acquisition of information. However, this same ease of communication has also led to the widespread proliferation of misinformation, including rumours and fake news \cite{vosoughi2018spread}. Recent events, such as the COVID-19 pandemic and the Russia-Ukraine war, underscore the vulnerability of social media users to such misinformation \cite{aimeur2023fake}. The urgent need to detect and mitigate the spread of these rumours is clear, as their unchecked dissemination can lead to significant real-world harm \cite{ahsan2019rumors}. Although advances in rumour detection, particularly in automated systems, have made significant strides \cite{thorne2018automated}, these methods must strike a delicate balance between effective detection and the preservation of users' freedom of speech. Consequently, there is a pressing demand for the development of trustworthy tools that not only excel in rumour detection but also provide explanations that are accessible and comprehensible to human users.\

%Social media platforms have become ubiquitous in modern life and allow users to connect with other like-minded individuals and exchange and obtain information with greater convenience. However, this ease of communication also enables misinformation like rumours and fake news to proliferate easily. \cite{vosoughi2018spread} Recent examples such as the COVID-19 pandemic and the Russia-Ukraine war highlight the susceptibility of social media platform users to such misinformation. \cite{aimeur2023fake} It is therefore imperative that rumours are detected and their spread mitigated to prevent real-world damage. \cite{ahsan2019rumors} While recent developments in rumour detection and related fields have helped pave the way for automated detection \cite{thorne2018automated}, there is still a need to balance effective detection and mitigation with the user's freedom of speech. Therefore, there is an urgency to develop trustworthy tools that are both effective in detecting rumours and yet remain explainable for humans to understand their decisions.

Early rumour detection methods relied on text mining and handcrafted features \cite{castillo2011information, yang2012automatic, liu2015real}. While these approaches laid a foundation, their reliance on manually engineered features limited scalability. 
% Deep learning methods, such as Recurrent Neural Networks (RNNs) \cite{ma2016detecting} and Long Short-Term Memory (LSTM) networks \cite{kochkina-etal-2017-turing}, improved detection by capturing temporal dependencies in rumour propagation. 
Deep learning methods, such as Recurrent Neural Networks (RNNs) \cite{ma2016detecting} and Long Short-Term Memory (LSTM) networks \cite{kochkina-etal-2017-turing}, improved detection by capturing temporal dependencies in rumour propagation.
However, these models fail to incorporate the structural information unique to rumours, prompting the development of approaches that leverage propagation structures through kernel models \cite{ma2017detect}, Recursive Neural Networks (RvNN) \cite{ma2018rumor}, and Graph Neural Networks (GNN) \cite{Bian2020RumorDO, wei-etal-2021-towards, lin-etal-2021-rumor}. GNNs, in particular, have demonstrated strong performance and computational efficiency, making them effective for both rumour detection and broader misinformation challenges \cite{phan2023fake, guo2022survey}.

Graph explainability techniques, widely used in domains such as molecular chemistry \cite{reiser2022graph, li2021graph}, citation networks \cite{xiao2022graph, chunaev2020community}, and scene graphs \cite{chang2021comprehensive, zareian2020bridging}, have seen limited application in misinformation detection. For GNN-based rumor detection, enhancing explainability is crucial for improving model trust and reliability. Techniques can be broadly categorized as gradient-based, decomposition-based, perturbation-based, and surrogate-based \cite{yuan2022explainability}. While perturbation-based and surrogate-based methods provide powerful insights, they are computationally intensive and lack generalizability in dynamic rumor contexts \cite{yuan2022explainability}. In contrast, gradient-based and decomposition-based approaches offer efficiency and scalability by leveraging model internal mechanisms.

However, current explainability methods often provide only node or edge-level insights, which fail to capture critical dependencies in high-dimensional text embeddings used as node features in GNN-based models \cite{Bian2020RumorDO, wei-etal-2021-towards, lin-etal-2021-rumor}. To address this limitation, explanations must go beyond coarse representations to consider individual textual components, offering finer granularity and higher fidelity.

%Early approaches to rumour detection predominantly relied on text mining and handcrafted features \cite{castillo2011information, yang2012automatic, liu2015real}. These methods laid the groundwork for automated rumour detection, but they were limited by their reliance on manually engineered features. More recently, deep learning architectures have emerged as powerful tools for efficiently learning textual features. Models based on Recurrent Neural Networks (RNNs) \cite{ma2016detecting}, such as Long Short-Term Memory (LSTM) \cite{kochkina-etal-2017-turing} networks, have demonstrated effectiveness in capturing the temporal dependencies inherent in rumour propagation events. However, these models fall short of capturing the structural information that is often unique to rumours. This has led to the increasing prominence of methods that leverage the propagation structure of information-spreading events. Techniques such as kernel models \cite{ma2017detect}, Recursive Neural Networks (RvNN) \cite{ma2018rumor}, and Graph Neural Networks (GNN) \cite{Bian2020RumorDO, wei-etal-2021-towards, lin-etal-2021-rumor} have been developed to learn high-level representations of these structures, significantly enhancing detection capabilities. Among these, GNN-based models have stood out for their strong performance and computational efficiency, making them widely applicable not only in rumour detection but also in broader misinformation detection tasks \cite{phan2023fake, guo2022survey}.

%Early work on rumour detection was focused on text mining and handcrafted features \cite{castillo2011information, yang2012automatic, liu2015real}, while more recent work has used deep learning architectures to learn textual features more efficiently. Recurrent Neural Network (RNN) models such as Long-Short Term Memory (LSTM) have been able to effectively capture temporal dependencies in rumour propagation events \cite{ma2016detecting, kochkina-etal-2017-turing}. However, they are unable to effectively learn structural information which is unique to rumours. As such, approaches that focus on utilising the propagation structure of an information-spreading event have gained prominence. Kernel models \cite{ma2017detect}, Recursive Neural Networks (RvNN) \cite{ma2018rumor} and Graph Neural Networks (GNN) \cite{Bian2020RumorDO, wei-etal-2021-towards, lin-etal-2021-rumor} are key methods used to learn high-level representations of such structures and improve detection. Among these methods, GNN-based models have shown good performance while remaining computationally efficient and have been used extensively not just in rumour detection but in other types of misinformation detection tasks as well. \cite{phan2023fake, guo2022survey}

%Existing graph explainability techniques have been applied in various domains, including molecular chemistry \cite{reiser2022graph, li2021graph}, citation networks \cite{xiao2022graph, chunaev2020community}, and scene graphs \cite{chang2021comprehensive, zareian2020bridging}. However, their application to misinformation detection, particularly for rumour detection models, remains limited. Enhancing the explainability of GNN-based rumour detection models is essential for improving model reliability and robustness. A recent survey categorizes GNN explainability methods into four main types: gradient-based, decomposition-based, perturbation-based, and surrogate-based \cite{yuan2022explainability}.

%While existing graph explainability techniques have been applied to many fields of research such as molecular chemistry and biology \cite{reiser2022graph, li2021graph}, citation networks \cite{xiao2022graph, chunaev2020community}, and even scene graphs \cite{chang2021comprehensive, zareian2020bridging}, there are few works which focus on explaining misinformation detection models, rumour detection models in particular. Being able to provide a good explanation for GNN-based rumour detection models will increase model reliability and help pave the way for developing more robust models. A recent survey on explainability techniques for GNNs categorises existing works into four main classes: gradient-based, decomposition-based, perturbation-based and surrogate-based. \cite{yuan2022explainability} 

% \begin{figure*}[hbt!]
%     \centering
%     \includegraphics[width=\linewidth]{figs/CT-LRP Framework v2.pdf}
%     \caption{Overview of the proposed CT-LRP framework showing the flow of information through the GNN and text embedding function. Inputs to the forward and backward pass are colour coded in green, intermediate outputs in purple and final outputs in blue.}
%     % \Description{A flowchart illustrating the flow of information through the GNN rumour detection model and text embedding function under the CT-LRP framework.}
%     \label{fig:ct-lrp}
% \end{figure*}


%Perturbation-based and surrogate-based techniques, while powerful, are computationally intensive and task-specific, requiring retraining for new data, which limits their generalizability, especially in the dynamic context of rumour detection \cite{yuan2022explainability}. In contrast, gradient-based and decomposition-based methods are more efficient and scalable, as they leverage the modelâ€™s internal mechanisms to produce explanations that generalize better to new data without retraining. Our framework builds on these techniques, focusing on future generalizability.

%Among these four categories of techniques, perturbation-based and surrogate-based techniques are more computationally expensive as they involve training a proxy model on top of the prediction model that is being studied. \cite{yuan2022explainability} Furthermore, such models are highly task and data-specific and require retraining when dealing with new data instances and hence do not provide generalisable explanations for out-of-distribution samples which is common in the case of rumour detection. Gradient-based and decomposition-based methods on the other hand are model-specific \cite{yuan2022explainability} and require more initial time investment to implement. This model-specificity makes them more suitable as they utilise the prediction model's internal learning mechanisms to produce explanations allowing them to scale well and generalise to new data instances without additional retraining. As such, our framework chooses to extend gradient and decomposition-based techniques with future generalisability in mind.

%Although gradient and decomposition-based methods like Layerwise Relevance Propagation (LRP) \cite{bach2015pixel} and Gradient Class Activation Map (Grad-CAM) \cite{Selvaraju2017ICCV} have proven effective in other domains, they typically offer only node and edge-level explanations. Given that many GNN-based rumour detection models rely on precomputed text embeddings as node features \cite{Bian2020RumorDO, wei-etal-2021-towards, lin-etal-2021-rumor}, these explanations often overlook crucial dependencies within the high-dimensional text embedding space, leading to lower fidelity. To truly capture the model's behavior, it is necessary to consider the contributions of individual textual components in the explanations.

%Despite the suitability of gradient and decomposition-based techniques such as Layerwise Relevance Propagation (LRP) \cite{bach2015pixel} and Gradient Class Activation Map (Grad-CAM) \cite{Selvaraju_2017_ICCV} to explain GNN-based methods in other domains, these two types of techniques are only able to produce node and edge-level explanations out of the box. However, many GNN-based rumour detection models use precomputed text embeddings as initial node features for the GNN models to learn. \cite{Bian2020RumorDO, wei-etal-2021-towards, lin-etal-2021-rumor} These explanations ignore the dependencies between feature dimensions in the high-dimensional text embedding space which result from the text encoding step and often result in explanations which have low fidelity. As such, to fully explain the model's behaviour, we must also consider the contribution of the textual sub-components in producing model explanations. 

\textbf{Research Objectives.} We propose Contrastive Token Layerwise Relevance Propagation (CT-LRP), a novel framework that addresses the limitations of existing GNN explainability techniques by providing fine-grained, token-level explanations for rumour detection models. CT-LRP combines Layerwise Relevance Propagation (LRP) with an explanation space partitioning strategy, enabling it to isolate class-specific and task-relevant textual components. This token-level granularity captures dependencies in high-dimensional text embeddings, offering nuanced insights into model predictions that surpass traditional node and edge-level explanations.

To rigorously evaluate CT-LRP, we extend existing explanation metrics to support token-level resolution, ensuring fidelity and interpretability. Experiments on three public rumour detection datasets demonstrate that CT-LRP consistently produces reliable, high-quality explanations, setting a new standard for GNN-based explainability in misinformation detection. By enhancing transparency and trustworthiness, CT-LRP directly addresses the societal need for ethical and effective AI systems to combat misinformation and its harmful consequences.

%In this paper, we address the limitations of existing GNN explainability techniques by proposing a novel framework, \textbf{Contrastive Token Layerwise Relevance Propagation} (CT-LRP), which enhances the granularity and fidelity of explanations in GNN-based rumour detection models. CT-LRP integrates the relevance propagation principles of LRP with an explanation space partitioning strategy. This combination allows CT-LRP to dissect and identify disjoint sets of class-specific and common task-relevant textual sub-components within the generated explanations, thus providing more nuanced insights into the decision-making process of the model. \red{This is especially important for increasing the transparency and trustworthiness of automated detection systems which are vital to combating rumours and misinformation which can result in deletrous effects on vulnerable communities such as the rise in anti-Asian hate crimes in the aftermath of the COVID-19 pandemic.}

%A key advancement in CT-LRP is its ability to produce token-level explanations, which are crucial for understanding how specific words or phrases contribute to the model's predictions. By extending traditional node and edge-level explanations to this finer resolution, CT-LRP addresses the challenge of high-dimensional text embeddings used in GNN-based models, ensuring that the dependencies between different features are accurately captured and explained. To rigorously evaluate the token-level explanations generated by CT-LRP, we have extended existing explanation evaluation metrics to account for this new level of resolution. This ensures that our evaluations accurately reflect the quality and usefulness of the explanations provided by CT-LRP. We apply this framework to several GNN-based rumour detection models, trained on three widely-used public datasets, demonstrating that CT-LRP consistently produces high-fidelity, granular explanations that can enhance model interpretability. To the best of our knowledge, CT-LRP represents the first attempt to generate token-level explanations for GNN-based rumour detection methods, marking a significant step forward in the field.

To summarize, the main contributions of our work are: \begin{itemize} 
    \item We introduce CT-LRP, a post hoc framework that provides granular, high-fidelity token-level explanations for GNN-based rumour detection models.
    \item We extend existing evaluation metrics to support token-level resolution, enabling robust and accurate assessments of explanations. 
    \item We validate CT-LRP through experiments on three public datasets, demonstrating its effectiveness in producing reliable and interpretable explanations.
\end{itemize}

\textbf{Boarder Impact.} Our work advances the technical state-of-the-art explainability for GNN-based rumour detection and addresses the broader societal challenge of combating misinformation. By providing interpretable, token-level explanations, CT-LRP enhances transparency and trust in AI systems, empowering stakeholders to make informed decisions. This framework represents a step toward building ethical and accountable AI tools that mitigate the harm caused by misinformation, fostering a safer online space.

%In this paper, we address the limitations we have identified, by proposing a framework to extend the resolution of existing GNN explainability techniques called \textbf{Contrastive Token Layerwise Relevance Propagation} (CT-LRP). CT-LRP combines the relevance propagation principles of LRP with explanation space partitioning to identify disjoint sets of class-specific and common task-relevant textual sub-components in the generated explanation. To evaluate the token-level explanations generated by CT-LRP, we extend existing explanation evaluation metrics to accommodate the new explanation resolution. We apply CT-LRP to explain the behaviour of several GNN-based rumour detection models trained on three publicly available datasets. To the best of our knowledge, CT-LRP is the first attempt to generate token-level explanations for GNN-based rumour detection methods.

%To summarise, the main contributions of our work are:
%\begin{itemize}
%    \item We propose the CT-LRP framework that combines LRP principles and explanation space partitioning to produce more granular, high-fidelity token-level explanations for GNN-based rumour detection.
%    \item Extensive experiments on three publicly available rumour detection datasets showcasing the importance of considering token-level contributions when producing explanations for the rumour detection domain.
%\end{itemize}