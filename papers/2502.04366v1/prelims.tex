
%In this section, we briefly explain the generic problem formulation for the rumour detection task with event propagation structure and then briefly discuss some further extensions to this task. The notations used in the following sections are summarised in Table \ref{tab:notation}.

%In this section, we outline the general problem formulation for the rumour detection task using event propagation structures, which is a graph-level task, and discuss possible extensions to this task. The notations used in subsequent sections are summarized in Table \ref{tab:notation}.


%\section{Preliminaries}
In rumour detection, event propagation on social media is modelled as a \textbf{graph-level classification task}. Let \( G = (V, E) \) represent an event propagation graph, where \( V \) is the set of nodes corresponding to posts made during the event, and \( E \) is the set of edges capturing interactions between these posts. Each node \( v \in V \) is associated with a feature vector \( \mathbf{x}_v \in \mathbb{R}^{|D|} \), typically a text embedding derived from the post content. The feature matrix \( \mathbf{X} \in \mathbb{R}^{|V| \times |D|} \) aggregates the embeddings for all posts in the event. The notations used are summarized in Table \ref{tab:notation}.

% The goal of the task is to learn a function \( f \) that predicts whether the source post \( v_0 \) is a rumour, i.e., \( f(G) = \hat{y} \). 
The goal of the task is to learn a function \( f \) that given an information propagation event graph \( G \) predicts whether the source post \( v_0 \) of that graph is a rumour, i.e., \( f(G) = \hat{y} \). 
This can be formulated as either a binary classification problem, as in the Weibo dataset~\cite{ma2016detecting}, or a multi-class classification problem, as in the Twitter15/16 datasets~\cite{ma2016detecting}. In this paper, we adopt GNN-based models as \( f \), leveraging their ability to capture both textual and structural information within the event graph.

Some approaches extend this task by incorporating additional features, such as user attributes or handcrafted graph features (e.g., node centrality), into the graph structure. For example, user attributes like follower count or account age can be represented as nodes in a user graph \( G_{\text{user}} \). While these features can provide additional context, they rely on explicit, handcrafted representations that are straightforward to interpret with existing explainability methods. In contrast, our focus lies in enhancing the interpretability of GNN-based models operating on latent, high-dimensional text embeddings, which pose greater challenges for explainability.

By improving the explainability of these latent representations, we aim to generate fine-grained insights into model predictions, addressing a critical gap in existing methods for rumour detection.




%Let $G = (V, E)$ be a graph with node set $V$ and edge set $E$. In rumour detection, the graph $G$ corresponds to an event propagation graph, while the node set $V$ corresponds to the posts made in the event and the edge set $E$ represents the interactions between posts in the event. For each node $v \in V$, there is an associated feature vector, $\textbf{x}_v \in \mathbb{R}^{|D|}$, where $D$ represents the set of features. As is commonly the case in rumour detection, the feature vector typically corresponds to a text embedding vector of the textual content of the post represented by that node. The feature matrix $\textbf{X} \in \mathbb{R}^{|V|\times |D|}$ thus contains the text representations of all posts in the event. The goal of the rumour detection task is to learn a function $f$ which given an event propagation graph, predicts whether the source post, $v_0$, is a rumour or not, i.e. $f(G) = \hat{y}$. Depending on the dataset, the task may be a binary classification problem as in the Weibo dataset \cite{ma2016detecting} or a four-way classification problem as in the Twitter15/16 dataset \cite{ma2016detecting}. In this paper, we select GNN-based models as our function $f$ to study. Furthermore, because the feature vector dimensions do not correspond to explicit discrete features but rather the latent features in the text embedding space, we endeavour to improve the explainability of models used in this task setup which will benefit from the increased explanation resolution.
%\subsection{Rumour Detection with Event Propagation}
%Let $G = (V, E)$ represent a graph where $V$ is the set of nodes and $E$ is the set of edges. In the context of rumour detection, the graph $G$ corresponds to an event propagation graph, with the node set $V$ representing posts made during the event and the edge set $E$ capturing the interactions between these posts. Each node $v \in V$ is associated with a feature vector $\textbf{x}_v \in \mathbb{R}^{|D|}$, where $D$ denotes the set of features. Typically, in rumour detection, the feature vector represents a text embedding of the post's content. Consequently, the feature matrix $\textbf{X} \in \mathbb{R}^{|V| \times |D|}$ contains the text embeddings of all posts within the event. The objective of the rumour detection task is to learn a function $f$ that, given an event propagation graph, predicts whether the source post $v_0$ is a rumour, i.e., $f(G) = \hat{y}$. Depending on the dataset, this task can either be a binary classification problem, as seen in the Weibo dataset \cite{ma2016detecting}, or a four-way classification problem, as in the Twitter15/16 dataset \cite{ma2016detecting}. In this paper, we focus on GNN-based models as the function $f$. Since the feature vector dimensions correspond to latent features in the text embedding space rather than explicit discrete features, we aim to enhance the explainability of these models, thereby improving the resolution of the generated explanations.

%\subsection{Other types of Graph-augmented Rumour Detection}

%\subsection{Graph-Augmented Rumour Detection Variants} 

%As an extension of the above-mentioned task, some rumour detection approaches include the addition of user features or other handcrafted features such as node centrality augmentation. These features are also typically represented as graph-structured, for example, in the case of user features, let $G_{user} = (V_{user}, E_{user})$. The node set $V_{user}$ corresponds to the users observed in the event propagation event and the edge set $E_{user}$ corresponds to the interactions between users in that event. Associated with each node $v_{user}$ is its feature vector $\textbf{x}_{v_{user}} \in \mathbb{R}^{|D_{user}|}$ where $D_{user}$ is the set of user features. Typical user features are follower counts, account age, etc. For the purpose of our study, we choose not to include these variants of rumour detection as the feature dimensions in the node representation vector directly correspond to the handcrafted user features and existing explainability works are sufficient to explain the importance of such features.

%As an extension of the basic task, some rumour detection approaches incorporate additional features, such as user attributes or other handcrafted features like node centrality. These features are often represented within a graph structure. For instance, consider user features represented by the graph $G_{user} = (V_{user}, E_{user})$, where $V_{user}$ represents users involved in the event, and $E_{user}$ captures the interactions between them. Each node $v_{user}$ has an associated feature vector $\textbf{x}_{v_{user}} \in \mathbb{R}^{|D_{user}|}$,  where $D_{user}$ includes user-specific features such as follower counts, account age, and other relevant attributes. In our study, we opt not to include these variants of rumour detection, as the feature dimensions in the node representation vector correspond directly to these handcrafted user features, and existing explainability methods adequately capture the significance of such features.