@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}
@ARTICLE{samplePaper,
  author={Narita, Tetsuya and Kroemer, Oliver},
  journal={IEEE Robotics and Automation Letters}, 
  title={Policy Blending and Recombination for Multimodal Contact-Rich Tasks}, 
  year={2021},
  volume={6},
  number={2},
  pages={2721-2728},
  doi={10.1109/LRA.2021.3061982}}

@article{kwon2024safe,
  title={Safe CoR: A Dual-Expert Approach to Integrating Imitation Learning and Safe Reinforcement Learning Using Constraint Rewards},
  author={Kwon, Hyeokjin and Lee, Gunmin and Lee, Junseo and Oh, Songhwai},
  journal={arXiv preprint arXiv:2407.02245},
  year={2024}
}

@inproceedings{wu2023unleashing,
  title={Unleashing large-scale video generative pre-training for visual robot manipulation},
  author={Wu, Hongtao and Jing, Ya and Cheang, Chilam and Chen, Guangzeng and Xu, Jiafeng and Li, Xinghang and Liu, Minghuan and Li, Hang and Kong, Tao},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@inproceedings{octo_2023,
    title={Octo: An Open-Source Generalist Robot Policy},
    author = {{Octo Model Team} and Dibya Ghosh and Homer Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Charles Xu and Jianlan Luo and Tobias Kreiman and {You Liang} Tan and Lawrence Yunliang Chen and Pannag Sanketi and Quan Vuong and Ted Xiao and Dorsa Sadigh and Chelsea Finn and Sergey Levine},
    booktitle = {Proceedings of Robotics: Science and Systems},
    address  = {Delft, Netherlands},
    year = {2024},
}

@article{gervet2023act3d,
  title={Act3d: Infinite resolution action detection transformer for robotic manipulation},
  author={Gervet, Theophile and Xian, Zhou and Gkanatsios, Nikolaos and Fragkiadaki, Katerina},
  journal={arXiv preprint arXiv:2306.17817},
  year={2023}
}

@article{ke20243d,
  title={3d diffuser actor: Policy diffusion with 3d scene representations},
  author={Ke, Tsung-Wei and Gkanatsios, Nikolaos and Fragkiadaki, Katerina},
  journal={arXiv preprint arXiv:2402.10885},
  year={2024}
}

@article{mees2022matters,
  title={What matters in language conditioned robotic imitation learning over unstructured data},
  author={Mees, Oier and Hermann, Lukas and Burgard, Wolfram},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={4},
  pages={11205--11212},
  year={2022},
  publisher={IEEE}
}
@article{ma2024survey,
  title={A Survey on Vision-Language-Action Models for Embodied AI},
  author={Ma, Yueen and Song, Zixing and Zhuang, Yuzheng and Hao, Jianye and King, Irwin},
  journal={arXiv preprint arXiv:2405.14093},
  year={2024}
}
@article{brohan2022rt,
  title={Rt-1: Robotics transformer for real-world control at scale},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  journal={arXiv preprint arXiv:2212.06817},
  year={2022}
}
@article{brohan2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Chen, Xi and Choromanski, Krzysztof and Ding, Tianli and Driess, Danny and Dubey, Avinava and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2307.15818},
  year={2023}
}

@inproceedings{
li2024visionlanguage,
title={Vision-Language Foundation Models as Effective Robot Imitators},
author={Xinghang Li and Minghuan Liu and Hanbo Zhang and Cunjun Yu and Jie Xu and Hongtao Wu and Chilam Cheang and Ya Jing and Weinan Zhang and Huaping Liu and Hang Li and Tao Kong},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=lFYj0oibGR}
}


@inproceedings{chi2023diffusionpolicy,
	title={Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
	author={Chi, Cheng and Feng, Siyuan and Du, Yilun and Xu, Zhenjia and Cousineau, Eric and Burchfiel, Benjamin and Song, Shuran},
	booktitle={Proceedings of Robotics: Science and Systems (RSS)},
	year={2023}
}

@inproceedings{zhu2023viola,
  title={Viola: Imitation learning for vision-based manipulation with object proposal priors},
  author={Zhu, Yifeng and Joshi, Abhishek and Stone, Peter and Zhu, Yuke},
  booktitle={Conference on Robot Learning},
  pages={1199--1210},
  year={2023},
  organization={PMLR}
}

@article{du2024learning,
  title={Learning universal policies via text-guided video generation},
  author={Du, Yilun and Yang, Sherry and Dai, Bo and Dai, Hanjun and Nachum, Ofir and Tenenbaum, Josh and Schuurmans, Dale and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{du2023video,
  title={Video language planning},
  author={Du, Yilun and Yang, Mengjiao and Florence, Pete and Xia, Fei and Wahid, Ayzaan and Ichter, Brian and Sermanet, Pierre and Yu, Tianhe and Abbeel, Pieter and Tenenbaum, Joshua B and others},
  journal={arXiv preprint arXiv:2310.10625},
  year={2023}
}
@inproceedings{gu2023rt,
  title={Rt-trajectory: Robotic task generalization via hindsight trajectory sketches},
  author={Gu, Jiayuan and Kirmani, Sean and Wohlhart, Paul and Lu, Yao and Arenas, Montserrat Gonzalez and Rao, Kanishka and Yu, Wenhao and Fu, Chuyuan and Gopalakrishnan, Keerthana and Xu, Zhuo and others},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@article{belkhale2024rt,
  title={Rt-h: Action hierarchies using language},
  author={Belkhale, Suneel and Ding, Tianli and Xiao, Ted and Sermanet, Pierre and Vuong, Quon and Tompson, Jonathan and Chebotar, Yevgen and Dwibedi, Debidatta and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2403.01823},
  year={2024}
}
@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}
@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}
@article{padalkar2023open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models},
  author={Padalkar, Abhishek and Pooley, Acorn and Jain, Ajinkya and Bewley, Alex and Herzog, Alex and Irpan, Alex and Khazatsky, Alexander and Rai, Anant and Singh, Anikait and Brohan, Anthony and others},
  journal={arXiv preprint arXiv:2310.08864},
  year={2023}
}

@article{escontrela2024video,
  title={Video prediction models as rewards for reinforcement learning},
  author={Escontrela, Alejandro and Adeniji, Ademi and Yan, Wilson and Jain, Ajay and Peng, Xue Bin and Goldberg, Ken and Lee, Youngwoon and Hafner, Danijar and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{black2023zero,
  title={Zero-shot robotic manipulation with pretrained image-editing diffusion models},
  author={Black, Kevin and Nakamoto, Mitsuhiko and Atreya, Pranav and Walke, Homer and Finn, Chelsea and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2310.10639},
  year={2023}
}
@article{wen2023any,
  title={Any-point trajectory modeling for policy learning},
  author={Wen, Chuan and Lin, Xingyu and So, John and Chen, Kai and Dou, Qi and Gao, Yang and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2401.00025},
  year={2023}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec},
  URL={arXiv preprint arXiv:2401.00025},
  year={2018}
}
@inproceedings{reuss2024multimodal,
  title={Multimodal Diffusion Transformer: Learning Versatile Behavior from Multimodal Goals},
  author={Reuss, Moritz and Ya{\u{g}}murlu, {\"O}mer Erdin{\c{c}} and Wenzel, Fabian and Lioutikov, Rudolf},
  booktitle={First Workshop on Vision-Language Models for Navigation and Manipulation at ICRA 2024},
  year={2024}
}
@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}
@article{yang2023track,
  title={Track anything: Segment anything meets videos},
  author={Yang, Jinyu and Gao, Mingqi and Li, Zhe and Gao, Shang and Wang, Fangjing and Zheng, Feng},
  journal={arXiv preprint arXiv:2304.11968},
  year={2023}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@inproceedings{jaegle2021perceiver,
  title={Perceiver: General perception with iterative attention},
  author={Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle={International conference on machine learning},
  pages={4651--4664},
  year={2021},
  organization={PMLR}
}
@article{mees2022calvin,
  title={Calvin: A benchmark for language-conditioned policy learning for long-horizon robot manipulation tasks},
  author={Mees, Oier and Hermann, Lukas and Rosete-Beas, Erick and Burgard, Wolfram},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={3},
  pages={7327--7334},
  year={2022},
  publisher={IEEE}
}
@inproceedings{li2023vision,
  title={Vision-language foundation models as effective robot imitators},
  author={Li, Xinghang and Liu, Minghuan and Zhang, Hanbo and Yu, Cunjun and Xu, Jie and Wu, Hongtao and Cheang, Chilam and Jing, Ya and Zhang, Weinan and Liu, Huaping and others},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}
@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}
@article{ho2022cascaded,
  title={Cascaded diffusion models for high fidelity image generation},
  author={Ho, Jonathan and Saharia, Chitwan and Chan, William and Fleet, David J and Norouzi, Mohammad and Salimans, Tim},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={47},
  pages={1--33},
  year={2022}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}
@inproceedings{bharadhwaj2024roboagent,
  title={Roboagent: Generalization and efficiency in robot manipulation via semantic augmentations and action chunking},
  author={Bharadhwaj, Homanga and Vakil, Jay and Sharma, Mohit and Gupta, Abhinav and Tulsiani, Shubham and Kumar, Vikash},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4788--4795},
  year={2024},
  organization={IEEE}
}
@inproceedings{wu2024gello,
  title={Gello: A general, low-cost, and intuitive teleoperation framework for robot manipulators},
  author={Wu, Philipp and Shentu, Yide and Yi, Zhongke and Lin, Xingyu and Abbeel, Pieter},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={12156--12163},
  year={2024},
  organization={IEEE}
}
@article{haldar2024baku,
  title={BAKU: An Efficient Transformer for Multi-Task Policy Learning},
  author={Haldar, Siddhant and Peng, Zhuoran and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2406.07539},
  year={2024}
}