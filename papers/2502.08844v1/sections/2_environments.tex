\section{Environments}

MuJoCo Playground contains environments in 3 main categories: DeepMind (DM) Control Suite,  Locomotion, and Manipulation, which we briefly describe in this section. Locomotion and manipulation environments are tailored to robotic use-cases and we show zero-shot sim-to-real transfer in many of the available environments. Playground directly utilizes MuJoCo Menagerie \cite{menagerie2022github} which offers a suite of robot assets and configurations tailored to run in MuJoCo.



\subsection{DM Control Suite}

The majority of RL environments from \cite{tassa2018deepmind} are re-implemented in MJX, and serve as entry-level tasks to familiarize users with MuJoCo Playground (\Cref{fig:dmc_grid}).




\subsection{Locomotion}

Locomotion environments in MuJoCo Playground are implemented for multiple quadrupeds and bipeds (\Cref{fig:env_grid} left). The quadrupeds include the Unitree Go1, Boston Dynamics Spot, and Google Barkour \cite{caluwaerts2023barkour}, while the humanoids include the Berkeley Humanoid \cite{liao2024berkeley}, Unitree H1 and G1, Booster T1, and the Robotis OP3. For each robot embodiment, we implement a joystick environment that learns to track a velocity command consisting of base linear velocities in both the forward and lateral directions, as well as a desired yaw rate. On the Unitree Go1, we additionally implement fall recovery and handstand environments. A complete list of locomotion environments is provided in \Cref{tab:locomotion_envs} in the appendix.

We demonstrate sim-to-real transfer in two main sets of experiments. First, on the Unitree Go1, we deploy joystick, fall recovery, and handstand policies. Second, we demonstrate joystick-based locomotion on the Berkeley Humanoid, the Unitree G1, and the Booster T1. More details on these sim-to-real experiments can be found in \Cref{sec:results_sim2real_locomotion}.

\subsection{Manipulation}

Manipulation environments in MuJoCo Playground are implemented for both prehensile and non-prehensile tasks (\Cref{fig:env_grid} right). With the Leap Hand \cite{shaw2023leaphand} robot, we demonstrate contact-rich dexterous re-orientation of a block. Using the Franka Emika Panda and Robotiq gripper, we show re-orientation of a yoga block using high frequency torque control. We implement a simple vision-based pick-cube environment on a Franka arm using the Madrona batch renderer. A few additional environments, such as bi-arm peg-insertion with the Aloha robot \cite{aldaco2024aloha}, are also available. We refer to \Cref{tab:manipulation_envs} in the appendix for a full set of environments.

We demonstrate sim-to-real transfer on the Leap Hand and Franka arm robots, including an environment trained from vision for the pick-cube task. More details on the sim-to-real experiments are available in \Cref{sec:results_sim2real_manipulation}.
