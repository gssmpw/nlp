\section{Reinforcement Learning Hyper-parameters}
\label{sec:rl_hypers}

In this section, we report the hyper-parameters used to train RL policies for all environments in MuJoCo Playground.

\subsection{DM Control Suite}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|p{5cm}|} 
\hline
\textbf{Hyperparameter} & \textbf{Default Value} & \textbf{Environment-Specific Modifications} \\ \hline
num\_timesteps & 60,000,000 & AcrobotSwingup, Swimmer, WalkerRun: 100,000,000 \\ \hline
num\_evals & 10 &  \\ \hline
reward\_scaling & 10.0 &  \\ \hline
normalize\_observations & True &  \\ \hline
action\_repeat & 1 & PendulumSwingUp: 4 \\ \hline
unroll\_length & 30 &  \\ \hline
num\_minibatches & 32 &  \\ \hline
num\_updates\_per\_batch & 16 & PendulumSwingUp: 4 \\ \hline
discounting & 0.995 & BallInCup: 0.95, \newline FingerSpin: 0.95 \\ \hline
learning\_rate & 1e-3 &  \\ \hline
entropy\_cost & 1e-2 &  \\ \hline
num\_envs & 2048 &  \\ \hline
batch\_size & 1024 &  \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Hyperparameter} & \textbf{Default Value} \\ \hline
madrona\_backend & True  \\ \hline
wrap\_env & False  \\ \hline
num\_timesteps & 1,000,000  \\ \hline
num\_evals & 5  \\ \hline
reward\_scaling & 0.1 \\ \hline
normalize\_observations & True  \\ \hline
action\_repeat & 1  \\ \hline
unroll\_length & 10  \\ \hline
num\_minibatches & 8  \\ \hline
num\_updates\_per\_batch & 8  \\ \hline
discounting & 0.97  \\ \hline
learning\_rate & 5e-4  \\ \hline
entropy\_cost & 5e-3  \\ \hline
num\_envs & 1024  \\ \hline
num\_eval\_envs & 1024  \\ \hline
batch\_size & 256  \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters for vision-based environments.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|p{5cm}|} 
\hline
\textbf{Hyperparameter} & \textbf{Default Value} & \textbf{Environment-Specific Modifications} \\ \hline
num\_timesteps & 5,000,000 & Acrobot, Swimmer, Finger, Hopper, \newline CheetahRun, HumanoidWalk, \newline PendulumSwingUp, WalkerRun: 10,000,000 \\ \hline
num\_evals & 10 &  \\ \hline
reward\_scaling & 1.0 &  \\ \hline
normalize\_observations & True &  \\ \hline
action\_repeat & 1 & PendulumSwingUp: 4 \\ \hline
discounting & 0.99 &  \\ \hline
learning\_rate & 1e-3 &  \\ \hline
num\_envs & 128 &  \\ \hline
batch\_size & 512 &  \\ \hline
grad\_updates\_per\_step & 8 &  \\ \hline
max\_replay\_size & 1048576 * 4 &  \\ \hline
min\_replay\_size & 8192 &  \\ \hline
network\_factory.q\_network\_layer\_norm & True &  \\ \hline
\end{tabular}
\caption{Brax SAC hyperparameters.}
\end{table}

\clearpage

\subsection{Locomotion}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Default Value} \\ \hline
num\_timesteps & 100,000,000 \\ \hline
num\_evals & 10  \\ \hline
reward\_scaling & 1.0 \\ \hline
normalize\_observations & True \\ \hline
action\_repeat & 1 \\ \hline
unroll\_length & 20 \\ \hline
num\_minibatches & 32 \\ \hline
num\_updates\_per\_batch & 4 \\ \hline
discounting & 0.97 \\ \hline
learning\_rate & 3e-4 \\ \hline
entropy\_cost & 1e-2 \\ \hline
num\_envs & 8192 \\ \hline
batch\_size & 256 \\ \hline
max\_grad\_norm & 1.0 \\ \hline
policy\_hidden\_layer\_sizes & (128, 128, 128, 128) \\ \hline 
policy\_obs\_key & "state" \\ \hline
value\_obs\_key & "state" \\ \hline
\end{tabular}
\caption{Default Brax PPO hyperparameters.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 200,000,000 \\ \hline
num\_evals & 10  \\ \hline
num\_resets\_per\_eval & 1 \\ \hline
policy\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_obs\_key & "privileged\_state" \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters specific to Go1JoystickFlatTerrain and Go1JoystickRoughTerrain.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 100,000,000 \\ \hline
num\_evals & 5  \\ \hline
policy\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_obs\_key & "privileged\_state" \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters specific to Go1Handstand and Go1Footstand.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 200,000,000 \\ \hline
num\_evals & 10  \\ \hline
discounting & 0.95 \\ \hline
policy\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_obs\_key & "privileged\_state" \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters specific to Go1Backflip.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 50,000,000 \\ \hline
num\_evals & 5  \\ \hline
policy\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_obs\_key & "privileged\_state" \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters specific to Go1Getup.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 400,000,000 \\ \hline
num\_evals & 16  \\ \hline
num\_resets\_per\_eval & 1 \\ \hline
reward\_scaling & 0.1 \\ \hline
unroll\_length & 32 \\ \hline
num\_updates\_per\_batch & 5 \\ \hline
discounting & 0.98 \\ \hline
learning\_rate & 1e-4 \\ \hline
entropy\_cost & 0 \\ \hline
num\_envs & 32768 \\ \hline
batch\_size & 1024 \\ \hline
clipping\_epsilon & 0.2 \\ \hline
policy\_hidden\_layer\_sizes & (512, 256, 64) \\ \hline 
value\_hidden\_layer\_sizes & (256, 256, 256, 256) \\ \hline 
value\_obs\_key & "privileged\_state" \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters specific to G1Joystick.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 400,000,000 \\ \hline
num\_evals & 16  \\ \hline
num\_resets\_per\_eval & 1 \\ \hline
reward\_scaling & 0.1 \\ \hline
unroll\_length & 32 \\ \hline
num\_updates\_per\_batch & 5 \\ \hline
discounting & 0.98 \\ \hline
learning\_rate & 1e-4 \\ \hline
entropy\_cost & 0 \\ \hline
num\_envs & 32768 \\ \hline
batch\_size & 1024 \\ \hline
clipping\_epsilon & 0.2 \\ \hline
policy\_hidden\_layer\_sizes & (512, 256, 64) \\ \hline 
value\_hidden\_layer\_sizes & (256, 256, 256, 256) \\ \hline 
value\_obs\_key & "privileged\_state" \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters specific to T1Joystick.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 100,000,000 \\ \hline
num\_evals & 10  \\ \hline
num\_resets\_per\_eval & 1 \\ \hline
clipping\_epsilon & 0.2 \\ \hline
discounting & 0.99 \\ \hline
learning\_rate & 1e-4 \\ \hline
entropy\_cost & 0.005 \\ \hline
policy\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_obs\_key & "privileged\_state" \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters specific to Berkeley Humanoid.}
\end{table}

\clearpage

\subsection{Manipulation}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Default Value} \\ \hline
normalize\_observations & True \\ \hline
reward\_scaling & 1.0 \\ \hline
policy\_hidden\_layer\_sizes & (32, 32, 32, 32) \\ \hline 
policy\_obs\_key & "state" \\ \hline
value\_obs\_key & "state" \\ \hline
\end{tabular}
\caption{Default Brax PPO hyperparameters.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 150,000,000 \\ \hline
num\_evals & 10 \\ \hline
unroll\_length & 40 \\ \hline
num\_minibatches & 32 \\ \hline
num\_updates\_per\_batch & 8 \\ \hline
discounting & 0.97 \\ \hline
learning\_rate & 3e-4 \\ \hline
entropy\_cost & 1e-2 \\ \hline
num\_envs & 1024 \\ \hline
batch\_size & 512 \\ \hline
policy\_hidden\_layer\_sizes & (256, 256, 256, 256) \\ \hline 
\end{tabular}
\caption{Brax PPO hyperparameters for AlohaSinglePegInsertion.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 40,000,000 \\ \hline
num\_evals & 4 \\ \hline
unroll\_length & 10 \\ \hline
num\_minibatches & 32 \\ \hline
num\_updates\_per\_batch & 8 \\ \hline
discounting & 0.97 \\ \hline
learning\_rate & 1e-3 \\ \hline
entropy\_cost & 2e-2 \\ \hline
num\_envs & 2048 \\ \hline
batch\_size & 512 \\ \hline
policy\_hidden\_layer\_sizes & (32, 32, 32, 32) \\ \hline 
num\_resets\_per\_eval & 1 \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters for PandaOpenCabinet.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 5,000,000 \\ \hline
num\_evals & 5 \\ \hline
unroll\_length & 10 \\ \hline
num\_minibatches & 8 \\ \hline
num\_updates\_per\_batch & 8 \\ \hline
discounting & 0.97 \\ \hline
learning\_rate & 5.0e-4 \\ \hline
entropy\_cost & 7.5e-3 \\ \hline
num\_envs & 1024 \\ \hline
batch\_size & 256 \\ \hline
reward\_scaling & 0.1 \\ \hline
policy\_hidden\_layer\_sizes & (256, 256) \\ \hline 
num\_resets\_per\_eval & 1 \\ \hline
max\_grad\_norm & 1.0 \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters for PandaPickCubeCartesian.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 20,000,000 \\ \hline
num\_evals & 4 \\ \hline
unroll\_length & 10 \\ \hline
num\_minibatches & 32 \\ \hline
num\_updates\_per\_batch & 8 \\ \hline
discounting & 0.97 \\ \hline
learning\_rate & 1e-3 \\ \hline
entropy\_cost & 2e-2 \\ \hline
num\_envs & 2048 \\ \hline
batch\_size & 512 \\ \hline
policy\_hidden\_layer\_sizes & (32, 32, 32, 32) \\ \hline 
\end{tabular}
\caption{Brax PPO hyperparameters for PandaPickCube.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 2,000,000,000 \\ \hline
num\_evals & 10 \\ \hline
unroll\_length & 100 \\ \hline
num\_minibatches & 32 \\ \hline
num\_updates\_per\_batch & 8 \\ \hline
discounting & 0.994 \\ \hline
learning\_rate & 6e-4 \\ \hline
entropy\_cost & 1e-2 \\ \hline
num\_envs & 8192 \\ \hline
batch\_size & 512 \\ \hline
num\_resets\_per\_eval & 1 \\ \hline
num\_eval\_envs & 32 \\ \hline
policy\_hidden\_layer\_sizes & (64, 64, 64, 64) \\ \hline 
\end{tabular}
\caption{Brax PPO hyperparameters for PandaRobotiqPushCube.}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 100,000,000 \\ \hline
num\_evals & 10 \\ \hline
num\_minibatches & 32 \\ \hline
unroll\_length & 40 \\ \hline
num\_updates\_per\_batch & 4 \\ \hline
discounting & 0.97 \\ \hline
learning\_rate & 3e-4 \\ \hline
entropy\_cost & 1e-2 \\ \hline
num\_envs & 8192 \\ \hline
batch\_size & 256 \\ \hline
num\_resets\_per\_eval & 1 \\ \hline
policy\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
policy\_obs\_key & "state" \\ \hline
value\_obs\_key & "privileged\_state" \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters for LeapCubeRotateZAxis).}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
num\_timesteps & 100,000,000 \\ \hline
num\_evals & 20 \\ \hline
num\_minibatches & 32 \\ \hline
unroll\_length & 40 \\ \hline
num\_updates\_per\_batch & 4 \\ \hline
discounting & 0.99 \\ \hline
learning\_rate & 3e-4 \\ \hline
entropy\_cost & 1e-2 \\ \hline
num\_envs & 8192 \\ \hline
batch\_size & 256 \\ \hline
num\_resets\_per\_eval & 1 \\ \hline
policy\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
value\_hidden\_layer\_sizes & (512, 256, 128) \\ \hline 
policy\_obs\_key & "state" \\ \hline
value\_obs\_key & "privileged\_state" \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters for LeapCubeReorient.}
\end{table}


\begin{table}[ht]
\centering
\begin{tabular}{|l|c|} 
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
madrona\_backend & True \\ \hline
wrap\_env & False \\ \hline
normalize\_observations & True \\ \hline
reward\_scaling & 1.0 \\ \hline
policy\_hidden\_layer\_sizes & (32, 32, 32, 32) \\ \hline 
num\_timesteps & 5,000,000 \\ \hline
num\_evals & 5 \\ \hline
unroll\_length & 10 \\ \hline
num\_minibatches & 8 \\ \hline
num\_updates\_per\_batch & 8 \\ \hline
discounting & 0.97 \\ \hline
learning\_rate & 5.0e-4 \\ \hline
entropy\_cost & 7.5e-3 \\ \hline
num\_envs & 1024 \\ \hline
batch\_size & 256 \\ \hline
reward\_scaling & 0.1 \\ \hline
num\_resets\_per\_eval & 1 \\ \hline
\end{tabular}
\caption{Brax PPO hyperparameters for vision-based PandaPickCubeCartesian.}
\end{table}
