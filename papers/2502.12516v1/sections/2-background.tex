\section{Background and Related Works}

Frame-semantic parsing is the automatic extraction of semantic frames and their elements. The task is often applied to FrameNet, a large corpus of frame-semantic annotations and definitions, and is typically separated into three subtasks: target identification, frame identification, and argument extraction (sometimes referred to as frame-semantic role labeling). Target identification is the process of identifying targets--instances of predefined lexical units--in a sentence. Lexical units are unique pairings of words and their meaning, indicated in FrameNet using the word's lemma and part-of-speech (e.g., \textit{begin.v} and \textit{war.n} in Figure~\ref{fig:fsp-example}) which are associated with a particular frame. Frame identification is the process of identifying the frames evoked in a sentence (e.g., Activity\_start and Hostile\_encounter in Figure~\ref{fig:fsp-example}), often done by classifying the previously extracted targets. Argument extraction is the process of extracting all frame elements of a particular frame evoked in a sentence (e.g., Time, Agent, and Activity for the Activity\_start frame in Figure~\ref{fig:fsp-example}). 

Nearly all previous systems use classification methods for argument extraction~\cite{chakma2024semantic}. These approaches are primarily dominated by BERT-like encoder models. Argument extraction is often structured as either a token or segment classification task~\cite{Su2024, aged2023, zheng-etal-2022-double, Bastianelli2020EncodingSC, opensesame, lin-etal-2021-graph} or a span identification task~\cite{Ai_Tu_2024, devasier-etal-2024-claimlens, aged2023, chen-etal-2021-joint}. Token/segment classification approaches classify each token or sequence of tokens as one of the frame elements, span identification approaches identify the beginning and end positions of each frame element. One previous study on argument extraction has used zero/few shot in-context learning with a simple prompt on Llama 2~\cite{Su2024}, but observed very poor performance. Another previous study on the very similar task of semantic role labeling has also found a large performance discrepancy when using LLMs~\cite{limitations-of-llms-ning-2024}.
