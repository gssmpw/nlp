\begin{table*}
    \centering
    \begin{tabularx}{\textwidth}{Xlcccc}
        \hline
        Model & Representation & Precision & Recall & F1 & Accuracy \\ 
        \hline
        GPT-4o-mini     & JSON-complete     & 0.356 & 0.577 & 0.440 & 0.282 \\ 
        GPT-4o-mini     & JSON-exist        & 0.416 & 0.543 & 0.471 & 0.308 \\ 
        GPT-4o-mini     & XML-tag           & 0.318 & 0.368 & 0.342 & 0.206 \\ 
        GPT-4o-mini     & Markdown          & 0.xxx & 0.xxx & 0.xxx & 0.xxx \\ 
        GPT-4o          & JSON-exist        & 0.550 & 0.642 & 0.592 & 0.420 \\ 
        \hline
        KID             & -                 & 0.741 & 0.773 & 0.756 & - \\ 
        AGED            & -                 & 0.757 & 0.776 & 0.762 & - \\ 
        Ai, Tu (2024)   & -                 & 0.764 & 0.777 & 0.771 & - \\ 
        \hline
        
        \hline
    \end{tabularx}
    \caption{Performance metrics for different models and representations.}
    \label{tab:model_representation_performance}
\end{table*}



% Llama 3.2-3B-ft           | json-exist            | 0.717 (0.841)     | 0.691     | 0.704 | 0.543     | Free
% Llama 3.1-8B-4bit-ft      | json-exist            | 0.736 (0.850)     | 0.711     | 0.724 | 0.567     | Free