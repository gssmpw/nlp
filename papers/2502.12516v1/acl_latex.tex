% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

\usepackage{tabularx}
\usepackage{tabularray}

\usepackage[colorinlistoftodos,textsize=tiny,disable]{todonotes}

\usepackage{amsmath}

\usepackage{enumitem}

\usepackage{listings}

\usepackage{tcolorbox}
\usepackage{caption}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Can LLMs Extract Frame-Semantic Arguments?}

% Author information can be set in various styles:
% For several authors from the same institution:
\author{Jacob Devasier, Rishabh Mediratta, Chengkai Li \\
        University of Texas at Arlington \\ cli@uta.edu}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{Jacob Devasier \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Rishabh Mediratta  \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
Frame-semantic parsing is a critical task in natural language understanding, yet the ability of large language models (LLMs) to extract frame-semantic arguments remains underexplored. This paper presents a comprehensive evaluation of LLMs on frame-semantic argument identification, analyzing the impact of input representation formats, model architectures, and generalization to unseen and out-of-domain samples. Our experiments, spanning models from 0.5B to 78B parameters, reveal that JSON-based representations significantly enhance performance, and while larger models generally perform better, smaller models can achieve competitive results through fine-tuning. We also introduce a novel approach to frame identification leveraging predicted frame elements, achieving state-of-the-art performance on ambiguous targets. Despite strong generalization capabilities, our analysis finds that LLMs still struggle with out-of-domain data. 
\end{abstract}

\input{sections/1-intro}
\input{sections/2-background}
\input{sections/3-methodology}
\input{sections/4-experiments}
\input{sections/5-results}
\input{sections/6-conclusion}

\vspace{0.2cm}
\section*{Limitations}
Several methodological constraints impacted the scope and comprehensiveness of our analysis. Due to the substantial computational costs associated with fine-tuning large language models, we were unable to explore fine-tuning on certain high-performing models like GPT-4o and GPT-4. These models may have achieved even stronger results than those demonstrated in our current analysis.

Our experimental design relied on sequential parameter optimization to manage computational requirements. While this approach was practical, it introduces the possibility that certain combinations of parameters could yield unexpected results. For instance, XML representations might potentially outperform JSON embeddings when paired with 14B parameter models or applied to frame identification tasks. However, exploring these combinations was beyond the computational resources available for this study.

The scope of our research was limited to the English FrameNet dataset. As a result, our findings may not generalize to other languages or semantic frameworks. Cross-lingual validation would be necessary to establish the broader applicability of our approaches.

In the context of frame identification for ambiguous targets, our current method of handling multiple frames with predicted frame elements requires refinement. The randomized prediction approach can lead to inconsistent outputs. Additionally, our implementation used a fixed random seed of 0 for reproducibility, but we did not explore the potential impact of different random seeds on accuracy metrics.

Finally, our benchmark correlation analysis considered only model size as a confounding variable. This simplified approach may not account for other significant factors that could influence the relationship between benchmark performance and frame-semantic parsing capabilities. A more comprehensive analysis of confounding variables would provide deeper insights into these relationships.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom,anthology}



\appendix

\input{sections/appendix}

% \todo{Add deepseek and other extra metrics to appendix.}

\end{document}
