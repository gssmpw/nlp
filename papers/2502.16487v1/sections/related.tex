\section{Related Work}
\label{sec:related}

\paragraph{Novelty of LLM Generated Research.} 
Evaluating 
novelty of 
generated proposals 
typically follow two paths: automated evaluation using LLMs themselves \citep{lu2024ai} or human expert review \citep{li2024chain, baek2024researchagent, li2024mlr, wang2023scimon, yang2023large, li2024learning, weng2024cycleresearcher}, often 
conducted 
through 
a small group of known experts. The scope and detail of generated outputs varies across studies, with some work focusing on concise proposals \citep{wang2023scimon,yang2023large}, while other approaches generate more detailed proposals or complete research papers \citep{si2024can,lu2024ai}. 
A recent large-scale study improves how we evaluate LLMs' ability to generate research proposals, with experts from multiple institutions reviewing $81$ LLM-generated proposals \citep{si2024can}. 
This study reveals several key findings. First, LLMs demonstrate limited ability in evaluating research ideas. Second, through a carefully controlled methodology that generates and ranks multiple candidates using significant computational resources, the study finds a surprising result: human participants judge LLM-generated proposals as more novel than human-written ones.

\paragraph{Automated Plagiarism Detection Tools.} \label{para:rel-automated-plag-tools}
Several studies integrate LLMs with academic search engines like Semantic Scholar to detect and filter out potential plagiarism in LLM-generated research ideas \citep{si2024can, lu2024ai, li2024chain}. The typical methodology  involves extracting keywords from titles and abstracts using LLMs, querying these through Semantic Scholar's API, and performing one-to-one comparisons between retrieved papers and the generated ideas. While not specifically designed for plagiarism detection, OpenScholar \citep{asai2024openscholar} is a specialized retrieval-augmented LM that leverages a database of $45$ million open-access papers with $237$ million passage embeddings. Its retrieval mechanism combines nearest-neighbor search over passage embeddings, keyword-based search through Semantic Scholar API, and academic web search results. Given this sophisticated multi-source retrieval system and its vast database of passage embeddings, OpenScholar could potentially serve as a powerful tool for embedding-based plagiarism detection. Traditional text-matching tools like Turnitin are also commonly used.

\paragraph{LLMs in Research Tasks.} Recent research has explored LLMs' capabilities in predicting experimental outcomes \citep{luo2024large}, conducting research experiments \citep{huang2023benchmarking, tian2024scicode}, paper reviewing \citep{weng2024cycleresearcher, zeng2023scientific}, and related work generation \citep{hu2024hireview}. We refer the reader to \citet{luo2025llm4sr} for a survey on this topic.

\paragraph{Creativity in AI.} Our work connects to studies on AI creativity \citep{ismayilzada2024creativity}. 
For instance, studies on LLM poetry generation reveal that while humans struggle to distinguish between AI-generated and human-written poems \citep{porter2024ai},
the outputs contain substantial verbatim matches with web text \citep{djsearch}, suggesting limited original creativity.
