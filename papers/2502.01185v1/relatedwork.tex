\section{Related Work}
\textbf{Active Noise Cancellation:} 
The concept of ANC was first introduced by Lueg \cite{lueg1936process}, focusing on sound oscillation cancellation. Given that ANC algorithms must adapt to variations in amplitude, phase, and noise source movement \citep{nelson1991active,fuller1996active,hansen1997active,kuo1999active}, most ANC algorithms are based on the Least Mean Squares (LMS) algorithm \citep{burgess1981active}, which is effective in echo cancellation. The FxLMS (Filtered-x LMS) algorithm extends LMS by using an adaptive filter to account for distortions in the primary and secondary paths. \citet{boucher1991effect} analyzed errors in FxLMS due to inaccuracies in estimating the secondary path inverse, where nonlinear distortions degrade performance. Several methods address these issues: the Filtered-S LMS (FSLMS) \citep{das2004active} algorithm uses a Functional Link Artificial Neural Network (FLANN) \citep{patra1999identification} to handle nonlinearity, while the Volterra Filtered-x LMS (VFXLMS) \citep{tan2001adaptive} employs a multichannel structure. The Bilinear FxLMS \citep{kuo2005nonlinear} improves nonlinearity modeling, and the Leaky FxLMS \citep{tobias2005leaky} introduces a leakage term to mitigate overfitting. The Tangential Hyperbolic Function-based FxLMS (THF-FxLMS) \citep{ghasemi2016nonlinear} models saturation effects for enhanced performance. \citet{gannot2003noise} proposed blind source separation for noise cancellation. Moreover, \citet{oppenheim1994single} proposed single channel ANC based on Kalman filter formulation \citep{revach2021kalmannet} and \citet{rafaely2009spherical} investigated spherical loudspeaker arrays for local sound control.

ANC using deep learning was first proposed by \citet{zhang2021deep} with a convolutional-LSTM network for estimating both amplitude and phase of the canceling signal $y(n)$. Recurrent CNNs were later explored by \citet{park2023had,mostafavi2023deep,cha2023dnoisenet}, and autoencoder-based networks \cite{singh2024enhancing}, along with fully connected neural networks, were also applied to the problem \cite{pike2023generalized}. \citet{shi2020feedforward,shi2022selective,luo2022hybrid,park2023integrated,shi2023transferable,luo2023deep,luo2023delayless,luo2024unsupervised} have developed methods that select fixed-filter ANC (SFANC) from pre-trained control filters to achieve fast response times. Concurrently, \citet{zhu2021new,shi2022integration,zhang2023deep,shi2023multichannel,antonanzas2023remote,xiao2023spatially,zhang2023time,shi2024behind} advanced multichannel ANC systems. \citet{luo2023gfanc} introduced a CNN-based approach for real-time ANC, further enhanced with Kalman filtering. \citet{zhang2023low} incorporated an attention mechanism for real-time ANC using the Attentive Recurrent Network (ARN)\citep{pandey2022self}. Other significant real-time ANC contributions include genetic and bee colony algorithm-based methods \citep{ren2022improved, zhou2023genetic}.

\textbf{Active Speech Cancellation:}
ASC has been explored in various studies, each employing different approaches to predict and cancel unwanted speech signals. \citet{kondo2007speech} introduced an ASC method using a Linear Predictive Coding (LPC) model to predict the speech signal for generating the canceling signal $y(n)$. \citet{donley2017active} took a different approach by controlling the sound field to cancel speech using a linear dipole array of loudspeakers and a single microphone, effectively reducing the speech signal in the target area. \citet{iotov2022computationally} employed a long-term linear prediction filter to anticipate incoming speech, enabling the cancellation of the speech signal. Additionally, \citet{iotov2023adaptive} proposed HOSpLP-ANC, which combines a high-order sparse linear predictor with the LMS algorithm for effective speech cancellation.

\textbf{Mamba architecture:} Recently, the Mamba architecture has been introduced \citep{gu2023mamba, dao2024transformers}, leveraging State Space Models (SSMs) to achieve notable improvements in various audio-related tasks. One of the key advantages of the Mamba architecture is its ability to perform fast inference, especially when handling sequences up to a million in length, which represents a significant improvement over traditional generative architectures. This has enabled advancements in several applications, including automatic speech recognition \citep{zhang2024mamba, zhang2024rethinking}, speech separation \citep{jiang2024dual, li2024spmamba}, speech enhancement \citep{chao2024investigation, luo2024mambagan, quan2024multichannel}, speech super-resolution \citep{waveumamba}, sound generation \citep{jiang2024speech}, audio representation \citep{shams2024ssamba, yadav2024audio, erol2024audio}, sound localization \citep{xiao2024tf, mu2024seld}, audio tagging \citep{lin2024audio}, and deepfake audio detection \citep{chen2024rawbmamba}. 

\begin{figure}[t]
% \vspace{-10pt}
\centering
\begin{minipage}{.45\textwidth}
\centering
\includegraphics[width=\textwidth]{figs/anc_3.png}
\caption{Typical ANC system diagram.}
\label{figs:anc}
\end{minipage}%
\end{figure}