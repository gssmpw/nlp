\subsection{DIFUSCO: Graph-Based Diffusion Solvers for Combinatorial Optimization}

\paragraph{Diffusion Framework and Heatmap Representation.}  
DIFUSCO\cite{sun2023difusco} leverages diffusion models to solve combinatorial optimization problems by progressively corrupting and reconstructing adjacency matrices. The ground truth adjacency matrix, denoted as \(x_0\), encodes the presence or absence of edges in a binary or relaxed format. Through a forward diffusion process, \(x_0\) is gradually transformed into a fully corrupted state \(x_T\) over \(T\) timesteps. The reverse diffusion process then reconstructs the structured adjacency matrix by iteratively refining the noisy intermediate states.

At any timestep \(t\), the corrupted adjacency matrix \(x_t\) represents probabilistic edge states. A discretized version, \(\tilde{x}_t\), can be obtained by thresholding or rounding \(x_t\), ensuring interpretability and compatibility with downstream tasks. Both \(x_t\) and \(\tilde{x}_t\) encode the probabilities or binary states of edges, progressively transitioning from noise to structure during the reverse process.

DIFUSCO employs two distinct diffusion paradigms:
\begin{itemize}
    \item \textbf{Gaussian Diffusion (DDPM)}: Adds continuous Gaussian noise to \(x_0\), resulting in \(x_t \in \mathbb{R}^{N \times N}\).
    \item \textbf{Categorical Diffusion (D3PM)}: Uses a transition matrix to model probabilistic transitions between edge states, resulting in \(x_t \in \mathbb{R}^{N \times N \times 2}\). This approach aligns more naturally with graph-based representations and has shown superior performance in maintaining structural integrity.
\end{itemize}

\paragraph{Neural Network Architecture and Reverse Process.}  
DIFUSCO utilizes attention mechanism to guide the reverse diffusion process. The network inputs include:
\begin{itemize}
    \item The corrupted adjacency matrix \(\tilde{x}_t\),
    \item The sinusoidal encoding of the timestep \(t\),
    \item Additional node positional information, such as coordinates or learned embeddings, seamlessly integrated with edge features through an attention mechanism that effectively captures interactions between nodes and edges.
\end{itemize}

The model outputs \(\hat{x}_0 \in [0, 1]^{N \times N \times 2}\), which approximates the original adjacency matrix \(x_0\). During the reverse process, \(\hat{x}_0\) is iteratively refined and used to sample the next state \(x_{t-1}\). This iterative denoising aligns the adjacency matrix closer to the original structure \(x_0\), ensuring a gradual and consistent reconstruction.

\paragraph{Feasibility and Tour Generation.}  
DIFUSCO ensures the generation of valid Hamiltonian cycles through two main approaches: greedy decoding and sampling-based decoding. Both methods leverage the heatmap generated by the diffusion process, which contains scores \( A_{ij} \) representing the confidence of edge \((i, j)\) being part of the optimal tour. These scores are combined with node coordinates \( c_i, c_j \) to calculate a normalized ranking score:
\[
\text{Score}(i, j) = \frac{A_{ij} + A_{ji}}{\|c_i - c_j\|},
\]
where \(\|c_i - c_j\|\) is the Euclidean distance between nodes \(i\) and \(j\). The two approaches differ in how they construct the initial tour:

\subparagraph{Greedy Decoding.}  
In the greedy decoding approach, edges are sorted by their scores in descending order. The algorithm iteratively selects the highest-ranking edges while avoiding subtours and maintaining feasibility constraints, such as ensuring that each node has exactly two connections. This process ensures the formation of a valid Hamiltonian cycle. Greedy decoding employs an exhaustive 50-step inference process to refine edge probabilities before constructing the tour, prioritizing precision in edge selection.

\subparagraph{Sampling-Based Decoding.}  
In contrast, the sampling-based approach generates multiple adjacency matrices in parallel by initializing the reverse diffusion process with different random seeds. Up to 16 adjacency matrices are sampled simultaneously, with each undergoing 10 diffusion inference steps. These parallel samples provide a diverse set of candidate tours, which can then be refined using post-processing techniques to ensure feasibility and improve quality. Sampling prioritizes solution diversity, making it particularly effective in exploring a broader range of potential solutions.

Regardless of whether the initial tour is generated via greedy decoding or sampling, DIFUSCO employs advanced refinement techniques to optimize the tour further:
\begin{itemize}
    \item \textbf{2-opt Local Search:} This heuristic iteratively examines pairs of edges in the tour. If swapping two edges reduces the overall path length, the swap is performed. This process continues until no further improvements can be made, effectively eliminating inefficient connections and enhancing tour optimality.
    \item \textbf{Monte Carlo Tree Search (MCTS):} MCTS explores alternative configurations of the tour by leveraging the heatmap scores as guidance. Using \(k\)-opt transformations, it balances the exploration of new solutions and the exploitation of promising candidates. MCTS iteratively refines the tour, often leading to significant quality improvements over the initial solution.
\end{itemize}



