\section{Related Work}
\label{sec:related_work}

\paragraph{Learning about Code Execution}
The topic of learning code execution has existed long before the era of LLMs ____. However, most related works focus solely on the output prediction task itself when learning from code execution ____. Other works seek to utilize code execution, either through the final feedback ____ or the intermediate trace ____, to improve code generation abilities. There are also specific benchmarks designed to evaluate a model's ability to predict execution results, such as CRUXEval ____ and LiveCodeBench-Exec ____. Unlike the above works, which set a narrow scope within code-related tasks, we are the first to train LLMs on large-scale, diverse code input-output predictions and demonstrate its efficacy in improving general reasoning ability beyond code.

\paragraph{Inference Time Scaling}
% Though of great importance, there is still no ultimate solution to enhance the reasoning capabilities of language models (LMs). Some previous researchers have pointed out that continual pre-training on code can improve reasoning abilities to some extent ____. However, its effectiveness is questioned when the base model is already strong or when it exhibits significant diminishing returns (i.e., reaching a point where further improvement requires an enormous amount of additional data). 
A very recent approach to enhance reasoning is inference-time scaling, such as OpenAI's o1 ____ or DeepSeek's R1 ____, which typically encourages models to generate ultra-long reasoning process to solve problems through large-scale reinforcement learning. Such methods are pushing models to new limits on massive challenge tasks, while also significantly altering the output patterns of models. We believe that \codeio{} is orthogonal to these methods, and we hope it can provide a better basis to further incentivize the reasoning abilities of LLMs.
% Though of great importance, there is still not ultimate solution to enhance LM reasoning. Some previous researchers point out that continual pre-training on code can improve reasoning capabilities to some extent ____, but its effectiveness is questioned when the base model is already strong or with large edge effort. Another recent effective path is inference-time scaling, such as OpenAI's o1 ____ or DeepSeek's R1 ____, which usually encourage the models to generate ultra long CoT to solve problems by large scale reinforcement learning. Methods like are making models pushing new limits on massive challenge benchmarks like AIME or codeforces, and also greatly change the output pattern of models. We believe \ccodeio{} is onthogonal to this type of methods, and we hope it can provide better model to further incentize the intrinsic ability.
% \paragraph{Mid-Training: Bridging Pre- and Post-Training}
% The most classical example of mid-training is continual pre-training ____, which typically involves enhancing the model's ability by training on raw documents of a specific targeted domain, such as math ____, code ____, or agents ____. Among these, code has been shown to improve reasoning capabilities to some extent ____; however, its effectiveness is questioned when the base model is already strong. More recently, large-scale supervised fine-tuning ____ has also emerged as an additional stage before general instruction tuning. Our work can be regarded as an extension of these efforts. However, instead of pursuing performance in a single domain, we aim to enhance generalizable reasoning ability across multiple scenarios by predicting code inputs and outputs as mid-training.

% \paragraph{Towards Generlizable Reasoning}
% ____
% ____