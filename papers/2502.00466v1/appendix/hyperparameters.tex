\section{Hyperparameters}
\label{appendix:hyper}

\begin{table}[h]
\caption{Hyperparameters for EDELINE.}
\label{tab:hyperparameters}
\centering
\small
\begin{tabular}{lll}
\toprule
Hyperparameter & Symbol & Value \\
\midrule
\multicolumn{3}{l}{\textbf{General}} \\
Number of epochs & --- & 1000 \\
Training steps per epoch & --- & 400 \\
Environment steps per epoch & --- & 100 \\
Batch size & --- & 32 \\
Sequence Length & $T$ & 19 \\
Epsilon (greedy) for collection & $\epsilon$ & 0.01 \\
Observation shape & (h,w,c) & (64,64,3) \\
\midrule
\multicolumn{3}{l}{\textbf{Actor Critic}} \\
Imagination horizon & $H$ & 15 \\
Discount factor & $\gamma$ & 0.985 \\
Entropy weight & $\eta$ & 0.001 \\
$\lambda$-returns coefficient & $\lambda$ & 0.95 \\
LSTM dimension & --- & 512 \\
Residual blocks layers & --- & [1,1,1,1] \\
Residual blocks channels & --- & [32,32,64,64] \\
\midrule
\multicolumn{3}{l}{\textbf{World Model}} \\
Number of conditioning observations & $L$ & 4 \\
Burn-in length & $B$ & 4 \\
Hidden embedding dimension & d\_model & 512 \\
Reward / Termination Model Hidden Units & --- & 512 \\
\midrule
\multicolumn{3}{l}{\textbf{Mamba}} \\
Mamba layers & n\_layers & 3 \\
Mamba state dimension & d\_state & 16 \\
Expand factor & --- & 2 \\
1D Convolution Dimension & d\_conv & 4 \\
Residual blocks layers & --- & [1,1,1,1] \\
Residual blocks channels & --- & [64,64,64,64] \\
Action embedding dimenstion & --- & 128 \\
\midrule
\multicolumn{3}{l}{\textbf{Diffusion}} \\
Sampling method & --- & Euler \\
Number of denoising steps & --- & 3 \\
Condition embedding dimension & --- & 256 \\
Residual blocks layers & --- & [2,2,2,2] \\
Residual blocks channels & --- & [64,64,64,64] \\
\midrule
\multicolumn{3}{l}{\textbf{Optimization}} \\
Optimizer & --- & AdamW \\
Learning rate & $\alpha$ & 1e-4 \\
Epsilon & --- & 1e-8 \\
Weight decay (World Model) & --- & 1e-2 \\
Weight decay (Actor-Critic) & --- & 0 \\
Max grad norm (World Model) & --- & 1.0 \\
Max grad norm (Actor-Critic) & --- & 100.0 \\
\bottomrule
\end{tabular}
\end{table}