\section{Harmonizers Ablation Results}
\label{appendix:harmony_ablation}

\begin{figure}[h]
\centering
\subfigure[BankHeist]{
\includegraphics[width=0.95\textwidth]{imgs/effect-of-harmony/harmony-qualitative-1.pdf}
\label{fig:harmony_bankheist}
}
\subfigure[RoadRunner]{
\includegraphics[width=0.4\textwidth]{imgs/effect-of-harmony/harmony-qualitative-2.pdf}
\label{fig:harmony_roadrunner}
}
\caption{Effect of harmonizers on world model predictions. (a) Without harmonizers, EDELINE fails to maintain consistent character modeling in BankHeist. (b) In RoadRunner, removal of harmonizers leads to loss of reward-relevant visual details. Colored boxes highlight successful (\textcolor{green}{green}) and failed (\textcolor{red}{red}) predictions of key game elements.}
\label{fig:harmony_qualitative}
\end{figure}

\input{tables/atari100k_harmony_table}

Table~\ref{table:atari_100k_harmony} presents quantitative performance comparison between EDELINE with and without harmonizers. The ablation results demonstrate significant performance degradation across multiple environments when harmonizers are removed, with particularly notable drops in games requiring precise reward related visual detail retention (BankHeist and RoadRunner). Qualitative analysis on these two environments, which showed the largest performance improvements with harmonizers, reveals how harmonizers contribute to world model performance. In BankHeist (Fig.~\ref{fig:harmony_bankheist}), removing harmonizers causes the world model to lose track of game characters, failing to maintain consistent agent representation across prediction sequences. Similarly, in RoadRunner (Fig.~\ref{fig:harmony_roadrunner}), the model without harmonizers fails to capture reward-relevant visual details, degrading its ability to model critical game state information.

These results demonstrate how harmonizers help achieve a crucial balance between observation modeling and reward prediction. Without harmonizers, the world model struggles with fine-grained task-relevant observations in both environments - tracking small character sprites in BankHeist and capturing critical game state details in RoadRunner. By maintaining this dynamic equilibrium between observation and reward modeling, harmonizers enable EDELINE to effectively learn compact task-centric dynamics while preserving essential visual details for sample-efficient learning.