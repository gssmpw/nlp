\section{Introduction}
\vspace{-0.5em}
World models~\cite{NEURIPS2018_2de5d166}, which simulate environment dynamics to enable agent planning and reasoning, represent a cornerstone of modern reinforcement learning (RL). The ability to learn compressed environment representations~\cite{hafner2024DreamerV3, Schrittwieser_2020} enables policy optimization through imagined trajectories and improves sample efficiency~\cite{NEURIPS2021_d5eca8dc} compared to traditional RL methods. This capability proves particularly valuable for real-world applications, such as robotics and autonomous systems. Recent advances in world modeling demonstrate remarkable success across diverse environments, including real-world tasks~\cite{wu2022daydreamer}.

Existing world models can be broadly categorized into two paradigms: latent-space models and generative models. Latent-space approaches, such as~\cite{Hafner2020Dreamer, hafner2021DreamerV2, hafner2024DreamerV3}, leverage recurrent neural networks (RNNs) or their variants to predict future states in a compressed latent space, which enables efficient policy optimization. However, this compression often results in information loss, which compromises both generality and reconstruction quality. On the other hand, generative models, particularly diffusion-based approaches like~\cite{alonso2024diamond}, have revolutionized world modeling by producing high-fidelity visual predictions through noise-reversal processes. Nevertheless, prior generative models rely on fixed-length observation-action windows, which truncate historical context and fail to capture extended temporal dependencies. This limitation becomes particularly problematic in partially observable environments, where agents must retain and reason over long sequences of observations to make informed decisions. Moreover, the architectural separation of reward prediction, termination signals, and observation modeling in existing frameworks can lead to suboptimal representation sharing and optimization conflicts, further hindering performance.

In order to mitigate the long sequence dependency issues, recent emergence of state space models (SSMs), such as~\cite{gu2022efficiently, gu2022parameterizationinitializationdiagonalstate, smith2023simplified, gu2024mamba, dao2024transformersssmsgeneralizedmodels} offer a complementary advantage as they are tailored to model long-term dependencies efficiently. With linear-time complexity and selective state updates~\cite{gu2024mamba}, SSMs can theoretically process unbounded sequences while preserving critical historical information. This capability is particularly valuable for world modeling, where accurate trajectory prediction often necessitates retaining and reasoning over extended observation-action histories.

Motivated by these considerations, we introduce EDELINE (\textbf{E}nhancing \textbf{D}iffusion-bas\textbf{E}d world models via \textbf{LINE}ar-time sequence modeling), a unified framework that synthesizes the advantages of diffusion models and SSMs. EDELINE advances the state-of-the-art through three key innovations: (1) \textbf{Memory Enhancement}: A recurrent embedding module (REM) based on Mamba SSMs for processing unbounded observation-action sequences to enable adaptive memory retention beyond fixed-context limitations, (2) \textbf{Unified Framework}: Direct conditioning of reward and termination prediction on REM hidden states for eliminating separate networks for efficient representation sharing, and (3) \textbf{Dynamic Loss Harmonization}: Adaptive weighting of observation, reward, and termination losses for addressing scale disparities in multi-task optimization. To validate our approach, we provide theoretical and experimental justifications to support that hidden information can preserve enhanced detail for more accurate imaginary compared with stacked frames inputs. To further demonstrate EDELINE's capabilities, we conduct extensive validation across various benchmarks. The experimental results reveal EDELINE's superior performance with 1.866 human normalized scores in Atari100K, which surpasses all current model-based approaches. To substantiate EDELINE's ability to preserve long temporal information for consistent predictions, we evaluate performance on MiniGrid and VizDoom environments. Both qualitative and quantitative results demonstrate superior temporal consistency in modeling and imaginary quality across 2D and 3D environments. Our ablation studies validate the effectiveness of each architectural component for world modeling performance. Our contributions are summarized as follows:\vspace{-0.5em}
\begin{enumerate} [itemsep=3pt, parsep=0pt]
    \item We introduce a unified architecture that integrates a Next-Frame Predictor for future state imaginary, a Recurrent Embedding Module for temporal sequence processing, as well as a Reward/Termination Predictor.
    \item Theoretical guarantees demonstrate that EDELINE retains strictly more information than fixed-context approaches, with advantages growing linearly over time.
    \item Experimental results in various benchmarks validate EDELINE's precise prediction of reward-critical elements that prior models exhibit structural inaccuracies.
\end{enumerate}

