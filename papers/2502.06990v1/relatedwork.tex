\section{Related Work}
\noindent \textbf{In-Context Learning} \cite{brown2020language} has become a popular paradigm for enhancing the capabilities of LLMs across a wide range of tasks. 
Previous work has extensively focused on optimizing demonstrations, particularly through the selection \cite{liu-etal-2022-makes,rubin-etal-2022-learning,li2023unified} and ranking \cite{pmlr-v139-zhao21c,lu-etal-2022-fantastically} of in-context examples. 
In this paper, we shift the focus from demonstration optimization to the LLM and the target query themselves, highlighting the inherent in-context learnability of LLMs on individual queries. 
Our study complements these works, contributing to a holistic understanding of what makes ICL (un)successful.
Another line of research explores how the ICL capability emerges and functions, with various hypotheses proposed, such as task recognition \cite{xie2022incontext, 10.5555/3666122.3666809}, composition \cite{li-etal-2024-language}, meta-gradient learning \cite{garg2022can,akyurek2023what}. 
This paper also aims to understand ICL but from an empirical perspective by collecting, analyzing, and predicting ICL behaviors.

\vspace{1.5mm}
\noindent \textbf{Adoption of IRT in NLP.}
IRT is a set of statistical models used in educational assessments to measure the latent abilities of individuals through standardized testing \cite{lord2008statistical, santor1998progress}. 
In recent years, it has become increasingly popular in NLP. 
\citet{byrd2022predicting} uses IRT to estimate question difficulty and model
skills. 
\citet{gor2024great} proposes a content-aware and identifiable IRT to analyze human-AI complementarity. 
\citet{polo2024tinybenchmarks} argues for the adoption of IRT to build benchmarks for efficient evaluation.
In this work, we use IRT to predict LLM in-context learnability on individual queries (conceptualized as ZPD) by capturing the behavior of LLMs before and after (in-context) learning.

\vspace{1.5mm}
\noindent \textbf{Curriculum Learning} \cite{bengio2009curriculum} is the approach that organizes the training examples such that the model converges faster and better, which has been successfully applied in various NLP tasks \cite{tay2019simple,platanios2019competence,sachan2016easy}. 
Typically, curriculum learning algorithms organize training examples in increasing order of difficulty. 
Conversely, there is another line of research that works in the opposite way to start with hard examples, namely Hard Example Mining \cite{shrivastava2016training,jin2018unsupervised}. 
In this paper, we propose a ZPD-based curriculum that strikes a middle point between the two techniques: prioritizing training examples that are challenging and yet learnable (i.e., within the model's ZPD).
Similar strategies have been proven effective in various scenarios \cite{mindermann2022prioritized}. 
However, this paper proposes a new framework for discovering such desired examples, which can be incorporated into existing approaches.