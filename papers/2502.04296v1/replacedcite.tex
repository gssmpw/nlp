\section{Related Works}
\label{sec:related_works}

\paragraph{World Models.}
 World models ____, or dynamic models ____, are computer programs that evolve based on agents' behaviors. Different from simulator software, learned dynamic models predict future states or reward functions based on past observations and then apply to model-based reinforcement settings ____ or robotics ____. Notably, since ground truth states are often unavailable in decision-making, dynamic models need to handle high-dimensional video data and low-dimensional grounded physical actions. Full-sequence diffusion and autoregressive models are two primary approaches for generative tasks across languages, images, and videos____. In particular, 1xGPT____ uses masked autoregression for video generation and MAR____ applies diffusion losses with masked autoregression for image generation, and Diffuser ____ uses diffusion models to jointly model the full state and action sequences in planning. Our work focuses on masked autoregression over full-sequence diffusion ____, aiming to create efficient and interactive world models.
 
\paragraph{Steering Video Models with Actions.}
Video models ____ can be applied to a wide range of video data including curated videos, human videos, synthetic videos, and robot videos. Interactive video models usually rely on language instructions ____, latent actions ____, or sketches to guide the video or image models.  However, video controllability is still an issue when \textbf{fine-grained details and low-level motion controls} are  used as prompts ____. In particular, IRASim ____ applies DiT ____ to several robotic datasets and demonstrates high-quality video simulation qualities. Unlike previous works that apply such models to a single task or embodiment or use natural languages as actions, our work investigates action-conditioned video models across heterogeneous embodied settings and their scaling behaviors.  

\paragraph{Visual Generative Models for Robotics.}
Visual generative models have been explored extensively for robotic applications such as policy learning, planning, and synthetic data generation. Synthesized goals and subgoals ____ have been used to improve end-to-end manipulation policies. Video predictions such as visual foresight ____ have been used to guide policy executions. Video language planning ____ achieves long-horizon planning tasks through model-predictive control and search. In the context of robotics, diffusion methods have been used to augment images 
 ____ and 3D generative methods have been used to generate synthetic data from novel views ____. In this work, we use learned dynamic models for policy evaluation and synthetic data generation in policy learning.  Moreover, the dynamics model can act as policies for action predictions.