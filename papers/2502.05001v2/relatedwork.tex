\section{Related Works}
\label{sec:related_works}
% This section reviews various works on parameter and index tuning. We emphasize the techniques in automatic parameter tuning specific to this domain.

% \begin{table*}[ht]
%     \centering
%     \begin{tabular}{l l p{9cm}}
%         \hline
%         \textbf{Method} & \textbf{Parameter Selection/Tuning Method} & \textbf{Weakness and differences} \\
%         \hline
%         B-trees \cite{comer1979ubiquitous} & Fixed & No search for optimal fanout \\
%         RMI \cite{kraska2018case} & Fixed & No hyperparameter tuning, fixed two-layer structure \\
%         ALEX/APEX \cite{ding2020alex} & Grid-search and expert selection & No end-to-end latency optimization \\
%         CDFShop \cite{marcus2020cdfshop} & Heuristic-based searches; Pareto front & Inconclusive tuning, not latency-optimized \\
%         AirIndex \cite{chockchowwat2023airindex} & Heuristic + graph-based & Optimizes lookup over updates, high tuning costs and limited scalability  \\
%         RusKey \cite{mo2023learning} & Vanilla DRL (DDPG) & Tuned specifically for LSM-trees, not generalizable, high tuning costs \\
%         Ours & Safe RL approach & Stable and efficient tuning under shifts of workloads and data \\
%         \hline
%     \end{tabular}
%     \caption{Summary of Existing Indexing and Tuning Works}
%     \label{tab:index_methods}
%     \vspace{-15pt}
% \end{table*}




\subsection{Parameter Tuning for System}
\label{sec:PT}
Parameter tuning is a common practice to optimize systems. For example, knob tuning in database systems, where specific values or knobs can be adjusted to optimize for specific query operators and improve data access efficiency~\cite{zhao2023automatic}. Traditional search strategies include using random and grid search to find the optimal parameters for a given workload. Advanced frameworks such as GPTune \cite{liu2021gptune}, Spearmint \cite{snoek2012practical}, and Sequential Model-Based Optimization (SMBO) \cite{ozaki2020multiobjective} attempt to refine this process through Bayesian Optimization, integrating multi-task and transfer learning. However, these methods struggle with accuracy and computational efficiency, as they require starting anew with each shift in workload or data distribution. The inefficiencies amplify when faced with real-time tuning requirements for learned indexes~\cite{feurer2015initializing}.

\subsection{Deep Reinforcement Learning for Parameter Tuning}
\label{sec:TD}
Recently, Deep reinforcement learning (DRL) has shown promising results in optimizing complex systems under dynamic conditions~\cite{kamthe2018data,chua2018deep}. Notably, CDBTune \cite{zhang2019end} uses deep deterministic policy gradients (DDPG~\cite{lillicrap2015continuous}) to automatically navigate and tune the high-dimensional continuous space of database configurations. It has shown the adaptability and efficiency of DRL methods over traditional tuning tools and expert DBA interventions for handling dynamic conditions. However, CDBTune cannot easily adapt to the unique challenges in index tuning, not present database configuration tuning. Index tuning requires rapid and precise adjustments without system resets or prolonged downtime while answering queries and updating records within dynamic data distributions and workload patterns. Misconfiguration has severe consequences for performance and must be avoided. \textsc{LITune}, on the other hand, efficiently tackles these challenges while keeping the full advantages of DRL tuning.

% \subsection{Index Tuning}
% Tuning indexes with traditional methods has been studied for years~\cite{chockchowwat2023airindex}. Recently, reinforcement learning techniques have also been incorporated into tuning index structures. RusKey \cite{mo2023learning} employed reinforcement learning to optimize an LSM-tree-based key-value store. Gu et al.\cite{gueffectively} applied reinforcement learning techniques to optimize R-Tree. These existing works demonstrate the successful application of RL to index tuning; our work, \textsc{LITune}, seeks to extend this to learned index tuning.

% \vspace{-5pt}


% \vspace{-5pt}
\subsection{Learned Index Tuning}


Learned indexes \cite{kraska2018case} replace traditional indexing algorithms (like B+Trees) with models that predict the approximate location of a key using the Empirical Cumulative Distribution Function (CDF), potentially reducing search operations. Research on both static \cite{kraska2018case, kipf2020radixspline, ferragina2020pgm, stoian2021towards} and updatable indexes \cite{galakatos2019fiting, ferragina2020pgm, ding2020alex, zhang2021carmi, wu2021updatable, yang2023flirt, liang2024swix, li2021finedex, tang2020xindex} demonstrates that performance heavily depends on data distribution, and to achieve the best performance, the indexes must be "tuned" according to the data distribution.


Currently, there are two approaches for considering data distributions when designing learned indexes: (1) exposing parameters for adjustment by users or future research, as seen in \cite{kraska2018case, ferragina2020pgm, zhang2021carmi}, and (2) implementing self-tuning mechanisms through cost models, utilized by indexes such as \cite{ding2020alex, yang2023flirt, liang2024swix}. In both approaches, the default parameter settings are crucial, with index designers asserting that tuning is unnecessary for satisfactory performance. However, this assumption only holds when the empirical cost of the default parameters is effective \cite{lu2021apex, li2021finedex, tang2020xindex}, and for updatable learned indexes, the insert cost model must also be valid \cite{ding2020alex, liang2024swix}. Early studies like \cite{sun2023learned} use grid search to find optimal default parameters but fail to capture the complexities of tuning learned indexes. Automating this tuning process remains under-explored and is fundamental to our work with \textsc{LITune}. This challenge is exacerbated for indexes supporting dynamic workloads, which must be reorganized to maintain model accuracy as data distributions shift. Unlike traditional indexes, learned index parameters depend not only on dataset size but also on rapidly changing data distributions. Additionally, updatable indexes require structural modifications—such as gaps \cite{ding2020alex, liang2024swix}, hierarchical structures \cite{ferragina2020pgm, wu2021lipp}, and buffers \cite{galakatos2019fiting, liang2024swix}—to mitigate the impact of distribution shifts. These complexities create intricate dependencies between parameters (as shown in Figure \ref{Perf}(a)), making automated tuning particularly challenging.

% CDFShop~\cite{marcus2020cdfshop} automates the optimization of learned indexes by fine-tuning cumulative distribution function (CDF) models specifically for the RMI index. It adjusts high-level hyperparameters and model architectures, such as model type and branching factors. However, CDFShop is limited to RMI and cannot be applied to tuning generic learned indexes, relying on iterative, game-theoretic, and heuristic exploration methods, which can be time-consuming and less scalable for more complex indexes or larger datasets. Additionally, it lacks safety-aware mechanisms for ensuring stable performance. Due to these constraints, we exclude CDFShop from our baselines and instead compare \textsc{LITune} with more general Bayesian Optimization and heuristic-based methods that better align with our comprehensive tuning objectives.

% AirIndex~\cite{chockchowwat2023airindex} employs a graph-based optimization approach to automatically tune its learned index structures. However, graph-based methods like AirIndex often have limited exploration capabilities, potentially missing optimal configurations by focusing only on the top-K candidates based on heuristics. They also incur significant computational overhead despite parallelization, reducing scalability for large datasets or complex index hierarchies. Moreover, these methods typically handle high-dimensional parameter spaces, complicating optimization under limited tuning budgets. These challenges highlight the difficulties in balancing exploration breadth and computational efficiency, explaining why our \textsc{LITune} framework outperforms existing methods in our evaluations.





% Recently, RL has been leveraged to tune learned indexes. Specifically, RusKey \cite{mo2023learning} uses Reinforcement Learning (RL) to optimize LSM-tree-based key-value stores \cite{sutton2018reinforcement}. RusKey signifies a first in applying RL to guide LSM-tree transformations, particularly under dynamic workloads. Unlike traditional methods that utilize white-box cost models focusing on I/O complexities, RusKey's RL-based approach offers a more holistic view of system performance. Their approach of treating the system as a black box aligns with \textsc{LITune}'s strategy for learned index structures \cite{dayan2018dostoevsky}. However, RusKey is designed to tune one parameter specifically for LSM trees and cannot be directly applied to learned index tuning. 
{\color{black}
CDFShop~\cite{marcus2020cdfshop} automates learned index optimization by fine-tuning cumulative distribution function (CDF) models specifically for the RMI index, adjusting high-level hyperparameters (e.g., model type, branching factors). However, it is confined to RMI, lacks safety-aware mechanisms, and relies on iterative, game-theoretic, and heuristic exploration methods that can be time-consuming and less scalable for complex indexes or larger datasets. Consequently, we exclude CDFShop from our baselines, comparing \textsc{LITune} instead with more general Bayesian Optimization and heuristic-based methods. AirIndex~\cite{chockchowwat2023airindex} employs a graph-based approach to automatically tune learned index structures but often has limited exploration by focusing on top-$K$ heuristics, incurring high overhead despite parallelization and complicating optimization in high-dimensional parameter spaces. Recently, Reinforcement Learning (RL) has been applied to tuning learned indexes: RusKey~\cite{mo2023learning} optimizes LSM-tree-based key-value stores~\cite{sutton2018reinforcement}, marking the first RL-driven LSM-tree transformations under dynamic workloads. Unlike white-box cost models centered on I/O complexities, RusKey’s black-box RL approach offers a holistic view similar to \textsc{LITune}~\cite{dayan2018dostoevsky}, yet it tunes only a single parameter and thus cannot be directly used for general learned index tuning. 
}



To clarify our selection criteria and highlight the key tuning methods utilized in prior research, we have summarized relevant studies in Table~\ref{tab:index_methods}. We observe that irrespective of the specific index type being targeted, the underlying tuning methods are generally transferable across different contexts. Consequently, we have extracted these transferable methods and adopted them as baselines for our experiments. This approach allows us to systematically evaluate the effectiveness of our proposed tuning system against established methodologies.


\begin{table}[t]
    \centering
    \captionsetup{font=small}
    \small
    \begin{tabular}{l l p{9cm}}
        \hline
        \textbf{Method} & \textbf{Parameter Selection/Tuning Method}  \\
        \hline
        B-trees \cite{comer1979ubiquitous} & Expert selection,  Heuristics \\
        RMI \cite{kraska2018case} &  Expert selection,  Heuristics \\
        ALEX \cite{ding2020alex} & Heuristic cost model, Grid search \\
        SWIX \cite{liang2024swix} & Heuristic cost model, Grid search \\
        CARMI \cite{zhang2021carmi} & Expert selection, Hardware-aware \\
        CDFShop \cite{marcus2020cdfshop} & Heuristics; Pareto front \\
        AirIndex \cite{chockchowwat2023airindex} & Heuristics, Graph-based search  \\
        RusKey \cite{mo2023learning} & Vanilla DRL (DDPG)  \\
        Ours & Safe RL approach\\
        \hline
    \end{tabular}
    \caption{Summary of Existing Indexing and Tuning Works}
    \label{tab:index_methods}
    % \vspace{-18pt}
\end{table}

% \vspace{-5pt}
\subsection{Index Advisor}
Index advisors are tools used in physical database design to help administrators select optimal indexes at the schema level based on query workloads~\cite{chaudhuri1997efficient, valentin2000db2}. They focus on recommending which columns or combinations of columns should be indexed to improve query execution times and overall system efficiency. Recent RL-based index selection methods~\cite{kossmann2022swirl, zhou2024breaking, siddiqui2024ml, wang2024leveraging} continue this approach by automating the index selection process but still operate at the schema level. In contrast, our work operates on a fundamentally different level by tuning the internal parameters of learned index structures themselves rather than selecting which indexes to create. Learned indexes leverage machine learning models to predict data positions within a dataset~\cite{kraska2018case}, and their performance heavily depends on hyperparameters and model configurations. Traditional index advisors do not address the challenges associated with optimizing these internal parameters. Therefore, our DRL-based tuning framework enhances the performance of learned indexes through dynamic internal optimization, offering adaptability and efficiency improvements that traditional index advising methods do not provide. This distinction underscores that we are addressing a different problem space, focusing on the internal mechanics of learned indexes rather than on schema-level index selection.



%