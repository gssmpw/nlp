@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@misc{minaee2024largelanguagemodelssurvey,
      title={Large Language Models: A Survey}, 
      author={Shervin Minaee and Tomas Mikolov and Narjes Nikzad and Meysam Chenaghlu and Richard Socher and Xavier Amatriain and Jianfeng Gao},
      year={2024},
      eprint={2402.06196},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.06196}, 
}
@misc{naveed2024comprehensiveoverviewlargelanguage,
      title={A Comprehensive Overview of Large Language Models}, 
      author={Humza Naveed and Asad Ullah Khan and Shi Qiu and Muhammad Saqib and Saeed Anwar and Muhammad Usman and Naveed Akhtar and Nick Barnes and Ajmal Mian},
      year={2024},
      eprint={2307.06435},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.06435}, 
}
@misc{zhao2024surveylargelanguagemodels,
      title={A Survey of Large Language Models}, 
      author={Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
      year={2024},
      eprint={2303.18223},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.18223}, 
}
@misc{hendrycks2020pretrainedtransformersimproveoutofdistribution,
      title={Pretrained Transformers Improve Out-of-Distribution Robustness}, 
      author={Dan Hendrycks and Xiaoyuan Liu and Eric Wallace and Adam Dziedzic and Rishabh Krishnan and Dawn Song},
      year={2020},
      eprint={2004.06100},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2004.06100}, 
}
@inproceedings{10.5555/3666122.3669203,
author = {Dziri, Nouha and Lu, Ximing and Sclar, Melanie and Li, Xiang Lorraine and Jiang, Liwei and Lin, Bill Yuchen and West, Peter and Bhagavatula, Chandra and Le Bras, Ronan and Hwang, Jena D. and Sanyal, Soumya and Welleck, Sean and Ren, Xiang and Ettinger, Allyson and Harchaoui, Zaid and Choi, Yejin},
title = {Faith and fate: limits of transformers on compositionality},
year = {2023},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Transformer large language models (LLMs) have sparked admiration for their exceptional performance on tasks that demand intricate multi-step reasoning. Yet, these models simultaneously show failures on surprisingly trivial problems. This begs the question: Are these errors incidental, or do they signal more substantial limitations? In an attempt to demystify transformer LLMs, we investigate the limits of these models across three representative compositional tasks—multi-digit multiplication, logic grid puzzles, and a classic dynamic programming problem. These tasks require breaking problems down into sub-steps and synthesizing these steps into a precise answer. We formulate compositional tasks as computation graphs to systematically quantify the level of complexity, and break down reasoning steps into intermediate sub-procedures. Our empirical findings suggest that transformer LLMs solve compositional tasks by reducing multi-step compositional reasoning into linearized subgraph matching, without necessarily developing systematic problem-solving skills. To round off our empirical study, we provide theoretical arguments on abstract multi-step reasoning problems that highlight how autoregressive generations' performance can rapidly decay with increased task complexity.},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {3081},
numpages = {40},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@misc{qian2022limitationslanguagemodelsarithmetic,
      title={Faith and Fate: Limits of Transformers on Compositionality}, 
      author={Jing Qian and Hong Wang and Zekun Li and Shiyang Li and Xifeng Yan},
      year={2022},
      eprint={2208.05051},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2208.05051}, 
}

@misc{nogueira2021investigatinglimitationstransformerssimple,
      title={Investigating the Limitations of Transformers with Simple Arithmetic Tasks}, 
      author={Rodrigo Nogueira and Zhiying Jiang and Jimmy Lin},
      year={2021},
      eprint={2102.13019},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2102.13019}, 
}
@misc{chowdhery2022palmscalinglanguagemodeling,
      title={PaLM: Scaling Language Modeling with Pathways}, 
      author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
      year={2022},
      eprint={2204.02311},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.02311}, 
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}
@misc{anil2022exploringlengthgeneralizationlarge,
      title={Exploring Length Generalization in Large Language Models}, 
      author={Cem Anil and Yuhuai Wu and Anders Andreassen and Aitor Lewkowycz and Vedant Misra and Vinay Ramasesh and Ambrose Slone and Guy Gur-Ari and Ethan Dyer and Behnam Neyshabur},
      year={2022},
      eprint={2207.04901},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2207.04901}, 
}@inproceedings{zhang2022delving,
  title={Delving deep into the generalization of vision transformers under distribution shifts},
  author={Zhang, Chongzhi and Zhang, Mingyuan and Zhang, Shanghang and Jin, Daisheng and Zhou, Qiang and Cai, Zhongang and Zhao, Haiyu and Liu, Xianglong and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition},
  pages={7277--7286},
  year={2022}
}@article{liu2022transformers,
  title={Transformers learn shortcuts to automata},
  author={Liu, Bingbin and Ash, Jordan T and Goel, Surbhi and Krishnamurthy, Akshay and Zhang, Cyril},
  journal={arXiv preprint arXiv:2210.10749},
  year={2022}
}@article{geirhos2020shortcut,
  title={Shortcut learning in deep neural networks},
  author={Geirhos, Robert and Jacobsen, J{\"o}rn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A},
  journal={Nature Machine Intelligence},
  volume={2},
  number={11},
  pages={665--673},
  year={2020},
  publisher={Nature Publishing Group UK London}
}
@inproceedings{li2023transformers,
  title={Transformers as algorithms: Generalization and stability in in-context learning},
  author={Li, Yingcong and Ildiz, Muhammed Emrullah and Papailiopoulos, Dimitris and Oymak, Samet},
  booktitle={International Conference on Machine Learning},
  pages={19565--19594},
  year={2023},
  organization={PMLR}
}
@article{jiang2019avoiding,
  title={Avoiding reasoning shortcuts: Adversarial evaluation, training, and model development for multi-hop QA},
  author={Jiang, Yichen and Bansal, Mohit},
  journal={arXiv preprint arXiv:1906.07132},
  year={2019}
}
@misc{zhang2023unveilingtransformerslegosynthetic,
      title={Unveiling Transformers with LEGO: a synthetic reasoning task}, 
      author={Yi Zhang and Arturs Backurs and Sébastien Bubeck and Ronen Eldan and Suriya Gunasekar and Tal Wagner},
      year={2023},
      eprint={2206.04301},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.04301}, 
}@misc{kojima2023largelanguagemodelszeroshot,
      title={Large Language Models are Zero-Shot Reasoners}, 
      author={Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
      year={2023},
      eprint={2205.11916},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2205.11916}, 
}
@article{zhu2024deductive,
  title={Deductive beam search: Decoding deducible rationale for chain-of-thought reasoning},
  author={Zhu, Tinghui and Zhang, Kai and Xie, Jian and Su, Yu},
  journal={COLM},
  year={2024}
}

@inproceedings{fu2022complexity,
  title={Complexity-based prompting for multi-step reasoning},
  author={Fu, Yao and Peng, Hao and Sabharwal, Ashish and Clark, Peter and Khot, Tushar},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}@inproceedings{
li2024how,
title={How Do Nonlinear Transformers Acquire Generalization-Guaranteed CoT Ability?},
author={Hongkang Li and Meng Wang and Songtao Lu and Xiaodong Cui and Pin-Yu Chen},
booktitle={High-dimensional Learning Dynamics 2024: The Emergence of Structure and Reasoning},
year={2024},
url={https://openreview.net/forum?id=8pM8IrT6Xo}
}
@misc{hu2024unveilingstatisticalfoundationschainofthought,
      title={Unveiling the Statistical Foundations of Chain-of-Thought Prompting Methods}, 
      author={Xinyang Hu and Fengzhuo Zhang and Siyu Chen and Zhuoran Yang},
      year={2024},
      eprint={2408.14511},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.14511}, 
}
@misc{kim2023cotcollectionimprovingzeroshot,
      title={The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning}, 
      author={Seungone Kim and Se June Joo and Doyoung Kim and Joel Jang and Seonghyeon Ye and Jamin Shin and Minjoon Seo},
      year={2023},
      eprint={2305.14045},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.14045}, 
}
@article{nguyen2023cof,
  title={CoF-CoT: Enhancing large language models with coarse-to-fine chain-of-thought prompting for multi-domain NLU tasks},
  author={Nguyen, Hoang H and Liu, Ye and Zhang, Chenwei and Zhang, Tao and Yu, Philip S},
  journal={arXiv preprint arXiv:2310.14623},
  year={2023}
}
@inproceedings{chu-etal-2025-towards,
    title = "Towards Faithful Multi-step Reasoning through Fine-Grained Causal-aware Attribution Reasoning Distillation",
    author = "Chu, Zheng  and
      Chen, Jingchang  and
      Wang, Zhongjie  and
      Tang, Guo  and
      Chen, Qianglong  and
      Liu, Ming  and
      Qin, Bing",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.157/",
    pages = "2291--2315",
    abstract = "Despite the remarkable reasoning capabilities demonstrated by large language models (LLM), the substantial computational overhead limits their practices. Some efforts have been directed toward distilling multi-step reasoning capabilities into smaller models through chain-of-thought (CoT). While CoT facilitates multi-step reasoning, the dependencies between reasoning steps are not always clearly discernible, which may lead to inconsistent reasoning. In this paper, we introduce fine-grained attribution reasoning distillation (FARD), which incorporates grounded citations to consolidate the relationships between reasoning steps. Specifically, FARD distills attribution reasoning rationales from LLMs to substitute CoT reasonings, which clarifies the dependencies among reasoning steps. Besides, we regularize the model`s attention pattern by leveraging the causal dependencies between reasoning steps, thereby enhancing the consistency of reasoning. Grounded attribution reasoning also enhances interpretability and verifiability, thereby facilitating faithful reasoning. We evaluate FARD on mathematical and general reasoning benchmarks. The experimental results indicate that FARD outperforms CoT distillation methods in mathematical reasoning, demonstrating its effectiveness. Furthermore, the small models trained with FARD have shown outstanding performance in out-of-distribution reasoning, proving strong generalization capabilities."
}
@misc{kaplan2020scalinglawsneurallanguage,
      title={Scaling Laws for Neural Language Models}, 
      author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
      year={2020},
      eprint={2001.08361},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2001.08361}, 
}
@misc{hoffmann2022trainingcomputeoptimallargelanguage,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.15556}, 
}
@misc{
taori2020when,
title={When Robustness Doesn{\textquoteright}t Promote Robustness: Synthetic vs. Natural Distribution Shifts on ImageNet},
author={Rohan Taori and Achal Dave and Vaishaal Shankar and Nicholas Carlini and Benjamin Recht and Ludwig Schmidt},
year={2020},
url={https://openreview.net/forum?id=HyxPIyrFvH}
}
@misc{li2024chainthoughtempowerstransformers,
      title={Chain of Thought Empowers Transformers to Solve Inherently Serial Problems}, 
      author={Zhiyuan Li and Hong Liu and Denny Zhou and Tengyu Ma},
      year={2024},
      eprint={2402.12875},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.12875}, 
}@inproceedings{
anonymous2025chainofthought,
title={Chain-of-Thought Provably Enables Learning the (Otherwise) Unlearnable},
author={Anonymous},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=N6pbLYLeej}
}@inproceedings{Xu_2024, series={IJCAI-2024},
   title={It Ain’t That Bad: Understanding the Mysterious Performance Drop in OOD Generalization for Generative Transformer Models},
   url={http://dx.doi.org/10.24963/ijcai.2024/727},
   DOI={10.24963/ijcai.2024/727},
   booktitle={Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence},
   publisher={International Joint Conferences on Artificial Intelligence Organization},
   author={Xu, Xingcheng and Pan, Zihao and Zhang, Haipeng and Yang, Yanqing},
   year={2024},
   month=aug, pages={6578–6586},
   collection={IJCAI-2024} }
@misc{micelibarone2022distributionallyrobustrecurrentdecoders,
      title={Distributionally Robust Recurrent Decoders with Random Network Distillation}, 
      author={Antonio Valerio Miceli-Barone and Alexandra Birch and Rico Sennrich},
      year={2022},
      eprint={2110.13229},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.13229}, 
}
@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{kumari2022multi,
  title={Multi-Concept Customization of Text-to-Image Diffusion},
  author={Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  journal={arXiv preprint arXiv:2212.04488},
  year={2022}
}
@article{venkat2023geometry,
  title={Geometry-biased Transformers for Novel View Synthesis},
  author={Venkat, Naveen and Agarwal, Mayank and Singh, Maneesh and Tulsiani, Shubham},
  journal={arXiv preprint arXiv:2301.04650},
  year={2023}
}
@article{chang2015shapenet,
  title={Shapenet: An information-rich 3d model repository},
  author={Chang, Angel X and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and others},
  journal={arXiv preprint arXiv:1512.03012},
  year={2015}
}

@inproceedings{suhail2022generalizable,
  title={Generalizable patch-based neural rendering},
  author={Suhail, Mohammed and Esteves, Carlos and Sigal, Leonid and Makadia, Ameesh},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXII},
  pages={156--174},
  year={2022},
  organization={Springer}
}

@inproceedings{yu2021pixelnerf,
  title={pixelnerf: Neural radiance fields from one or few images},
  author={Yu, Alex and Ye, Vickie and Tancik, Matthew and Kanazawa, Angjoo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4578--4587},
  year={2021}
}


@inproceedings{lindell2022bacon,
  title={Bacon: Band-limited coordinate networks for multiscale scene representation},
  author={Lindell, David B and Van Veen, Dave and Park, Jeong Joon and Wetzstein, Gordon},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16252--16262},
  year={2022}
}

@article{Lin2023SwiftSageAG,
  title={SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks},
  author={Bill Yuchen Lin and Yicheng Fu and Karina Yang and Prithviraj Ammanabrolu and Faeze Brahman and Shiyu Huang and Chandra Bhagavatula and Yejin Choi and Xiang Ren},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.17390},
  url={https://api.semanticscholar.org/CorpusID:258960143}
}

@article{muller2022instant,
  title={Instant neural graphics primitives with a multiresolution hash encoding},
  author={M{\"u}ller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
  journal={ACM Transactions on Graphics (ToG)},
  volume={41},
  number={4},
  pages={1--15},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@inproceedings{riegler2020free,
  title={Free view synthesis},
  author={Riegler, Gernot and Koltun, Vladlen},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XIX 16},
  pages={623--640},
  year={2020},
  organization={Springer}
}

@inproceedings{riegler2021stable,
  title={Stable view synthesis},
  author={Riegler, Gernot and Koltun, Vladlen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12216--12225},
  year={2021}
}

@article{chan2023generative,
  title={Generative Novel View Synthesis with 3D-Aware Diffusion Models},
  author={Chan, Eric R and Nagano, Koki and Chan, Matthew A and Bergman, Alexander W and Park, Jeong Joon and Levy, Axel and Aittala, Miika and De Mello, Shalini and Karras, Tero and Wetzstein, Gordon},
  journal={arXiv preprint arXiv:2304.02602},
  year={2023}
}

@article{zhang2021ners,
  title={NeRS: neural reflectance surfaces for sparse-view 3D reconstruction in the wild},
  author={Zhang, Jason and Yang, Gengshan and Tulsiani, Shubham and Ramanan, Deva},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29835--29847},
  year={2021}
}

@inproceedings{niemeyer2022regnerf,
  title={Regnerf: Regularizing neural radiance fields for view synthesis from sparse inputs},
  author={Niemeyer, Michael and Barron, Jonathan T and Mildenhall, Ben and Sajjadi, Mehdi SM and Geiger, Andreas and Radwan, Noha},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5480--5490},
  year={2022}
}

@article{mildenhall2021nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  number={1},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}

@misc{torch-ngp,
    Author = {Jiaxiang Tang},
    Year = {2022},
    Note = {https://github.com/ashawkey/torch-ngp},
    Title = {Torch-ngp: a PyTorch implementation of instant-ngp}
}

@inproceedings{sajjadi2022scene,
  title={Scene representation transformer: Geometry-free novel view synthesis through set-latent scene representations},
  author={Sajjadi, Mehdi SM and Meyer, Henning and Pot, Etienne and Bergmann, Urs and Greff, Klaus and Radwan, Noha and Vora, Suhani and Lu{\v{c}}i{\'c}, Mario and Duckworth, Daniel and Dosovitskiy, Alexey and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6229--6238},
  year={2022}
}

@article{sitzmann2021light,
  title={Light field networks: Neural scene representations with single-evaluation rendering},
  author={Sitzmann, Vincent and Rezchikov, Semon and Freeman, Bill and Tenenbaum, Josh and Durand, Fredo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={19313--19325},
  year={2021}
}

@inproceedings{zhang2022iron,
  title={Iron: Inverse rendering by optimizing neural sdfs and materials from photometric images},
  author={Zhang, Kai and Luan, Fujun and Li, Zhengqi and Snavely, Noah},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5565--5574},
  year={2022}
}

@inproceedings{hore2010image,
  title={Image quality metrics: PSNR vs. SSIM},
  author={Hore, Alain and Ziou, Djemel},
  booktitle={2010 20th international conference on pattern recognition},
  pages={2366--2369},
  year={2010},
  organization={IEEE}
}

@article{tumanyan2022plug,
  title={Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation},
  author={Tumanyan, Narek and Geyer, Michal and Bagon, Shai and Dekel, Tali},
  journal={arXiv preprint arXiv:2211.12572},
  year={2022}
}

@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@inproceedings{wang2021ibrnet,
  title={Ibrnet: Learning multi-view image-based rendering},
  author={Wang, Qianqian and Wang, Zhicheng and Genova, Kyle and Srinivasan, Pratul P and Zhou, Howard and Barron, Jonathan T and Martin-Brualla, Ricardo and Snavely, Noah and Funkhouser, Thomas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4690--4699},
  year={2021}
}

@article{sitzmann2020metasdf,
  title={Metasdf: Meta-learning signed distance functions},
  author={Sitzmann, Vincent and Chan, Eric and Tucker, Richard and Snavely, Noah and Wetzstein, Gordon},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={10136--10147},
  year={2020}
}

@inproceedings{chen2021mvsnerf,
  title={Mvsnerf: Fast generalizable radiance field reconstruction from multi-view stereo},
  author={Chen, Anpei and Xu, Zexiang and Zhao, Fuqiang and Zhang, Xiaoshuai and Xiang, Fanbo and Yu, Jingyi and Su, Hao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14124--14133},
  year={2021}
}

@inproceedings{trevithick2021grf,
  title={Grf: Learning a general radiance field for 3d representation and rendering},
  author={Trevithick, Alex and Yang, Bo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15182--15192},
  year={2021}
}




@inproceedings{tancik2021learned,
  title={Learned initializations for optimizing coordinate-based neural representations},
  author={Tancik, Matthew and Mildenhall, Ben and Wang, Terrance and Schmidt, Divi and Srinivasan, Pratul P and Barron, Jonathan T and Ng, Ren},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2846--2855},
  year={2021}
}

@article{niklaus20193d,
  title={3d ken burns effect from a single image},
  author={Niklaus, Simon and Mai, Long and Yang, Jimei and Liu, Feng},
  journal={ACM Transactions on Graphics (ToG)},
  volume={38},
  number={6},
  pages={1--15},
  year={2019},
  publisher={ACM New York, NY, USA}
}


@inproceedings{tucker2020single,
  title={Single-view view synthesis with multiplane images},
  author={Tucker, Richard and Snavely, Noah},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={551--560},
  year={2020}
}




@inproceedings{jang2021codenerf,
  title={Codenerf: Disentangled neural radiance fields for object categories},
  author={Jang, Wonbong and Agapito, Lourdes},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12949--12958},
  year={2021}
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{sitzmann2019scene,
  title={Scene representation networks: Continuous 3d-structure-aware neural scene representations},
  author={Sitzmann, Vincent and Zollh{\"o}fer, Michael and Wetzstein, Gordon},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{zhou2016view,
  title={View synthesis by appearance flow},
  author={Zhou, Tinghui and Tulsiani, Shubham and Sun, Weilun and Malik, Jitendra and Efros, Alexei A},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part IV 14},
  pages={286--301},
  year={2016},
  organization={Springer}
}

@inproceedings{tatarchenko2016multi,
  title={Multi-view 3d models from single images with a convolutional network},
  author={Tatarchenko, Maxim and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part VII 14},
  pages={322--337},
  year={2016},
  organization={Springer}
}


@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}

@article{liu2023zero,
  title={Zero-1-to-3: Zero-shot One Image to 3D Object},
  author={Liu, Ruoshi and Wu, Rundi and Van Hoorick, Basile and Tokmakov, Pavel and Zakharov, Sergey and Vondrick, Carl},
  journal={arXiv preprint arXiv:2303.11328},
  year={2023}
}


@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@article{lombardi2019neural,
  title={Neural volumes: Learning dynamic renderable volumes from images},
  author={Lombardi, Stephen and Simon, Tomas and Saragih, Jason and Schwartz, Gabriel and Lehrmann, Andreas and Sheikh, Yaser},
  journal={arXiv preprint arXiv:1906.07751},
  year={2019}
}

@inproceedings{sitzmann2019deepvoxels,
  title={Deepvoxels: Learning persistent 3d feature embeddings},
  author={Sitzmann, Vincent and Thies, Justus and Heide, Felix and Nie{\ss}ner, Matthias and Wetzstein, Gordon and Zollhofer, Michael},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2437--2446},
  year={2019}
}

@article{zhou2018stereo,
  title={Stereo magnification: Learning view synthesis using multiplane images},
  author={Zhou, Tinghui and Tucker, Richard and Flynn, John and Fyffe, Graham and Snavely, Noah},
  journal={arXiv preprint arXiv:1805.09817},
  year={2018}
}

@article{pearson1901liii,
  title={LIII. On lines and planes of closest fit to systems of points in space},
  author={Pearson, Karl},
  journal={The London, Edinburgh, and Dublin philosophical magazine and journal of science},
  volume={2},
  number={11},
  pages={559--572},
  year={1901},
  publisher={Taylor \& Francis}
}

@inproceedings{saharia2022palette,
  title={Palette: Image-to-image diffusion models},
  author={Saharia, Chitwan and Chan, William and Chang, Huiwen and Lee, Chris and Ho, Jonathan and Salimans, Tim and Fleet, David and Norouzi, Mohammad},
  booktitle={ACM SIGGRAPH 2022 Conference Proceedings},
  pages={1--10},
  year={2022}
}

@article{saharia2022image,
  title={Image super-resolution via iterative refinement},
  author={Saharia, Chitwan and Ho, Jonathan and Chan, William and Salimans, Tim and Fleet, David J and Norouzi, Mohammad},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  publisher={IEEE}
}

@article{baranchuk2021label,
  title={Label-efficient semantic segmentation with diffusion models},
  author={Baranchuk, Dmitry and Rubachev, Ivan and Voynov, Andrey and Khrulkov, Valentin and Babenko, Artem},
  journal={arXiv preprint arXiv:2112.03126},
  year={2021}
}


@inproceedings{flynn2019deepview,
  title={Deepview: View synthesis with learned gradient descent},
  author={Flynn, John and Broxton, Michael and Debevec, Paul and DuVall, Matthew and Fyffe, Graham and Overbeck, Ryan and Snavely, Noah and Tucker, Richard},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2367--2376},
  year={2019}
}

@inproceedings{flynn2016deepstereo,
  title={Deepstereo: Learning to predict new views from the world's imagery},
  author={Flynn, John and Neulander, Ivan and Philbin, James and Snavely, Noah},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5515--5524},
  year={2016}
}




@article{agarwal2011building,
  title={Building rome in a day},
  author={Agarwal, Sameer and Furukawa, Yasutaka and Snavely, Noah and Simon, Ian and Curless, Brian and Seitz, Steven M and Szeliski, Richard},
  journal={Communications of the ACM},
  volume={54},
  number={10},
  pages={105--112},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@inproceedings{goesele2007multi,
  title={Multi-view stereo for community photo collections},
  author={Goesele, Michael and Snavely, Noah and Curless, Brian and Hoppe, Hugues and Seitz, Steven M},
  booktitle={2007 IEEE 11th International Conference on Computer Vision},
  pages={1--8},
  year={2007},
  organization={IEEE}
}

@incollection{snavely2006photo,
  title={Photo tourism: exploring photo collections in 3D},
  author={Snavely, Noah and Seitz, Steven M and Szeliski, Richard},
  booktitle={ACM siggraph 2006 papers},
  pages={835--846},
  year={2006}
}

@inproceedings{schonberger2016structure,
  title={Structure-from-motion revisited},
  author={Schonberger, Johannes L and Frahm, Jan-Michael},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4104--4113},
  year={2016}
}


@article{metzer2022latent,
  title={Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures},
  author={Metzer, Gal and Richardson, Elad and Patashnik, Or and Giryes, Raja and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2211.07600},
  year={2022}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={arXiv preprint arXiv:2210.08402},
  year={2022}
}

% ############ Diffusion Model for 3D reconstruction ############
@article{wang2022score,
  title={Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation},
  author={Wang, Haochen and Du, Xiaodan and Li, Jiahao and Yeh, Raymond A and Shakhnarovich, Greg},
  journal={arXiv preprint arXiv:2212.00774},
  year={2022}
}
@inproceedings{zhou2023sparsefusion,
  title={SparseFusion: Distilling View-conditioned Diffusion for 3D Reconstruction}, 
  author={Zhizhuo Zhou and Shubham Tulsiani},
  booktitle={CVPR},
  year={2023}
}

@article{robinson2021can,
  title={Can contrastive learning avoid shortcut solutions?},
  author={Robinson, Joshua and Sun, Li and Yu, Ke and Batmanghelich, Kayhan and Jegelka, Stefanie and Sra, Suvrit},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={4974--4986},
  year={2021}
}

@article{kim2024transformers,
  title={Transformers Provably Solve Parity Efficiently with Chain of Thought},
  author={Kim, Juno and Suzuki, Taiji},
  journal={arXiv preprint arXiv:2410.08633},
  year={2024}
}

@article{welsh2016prediction,
  title={Prediction of cardiovascular disease risk by cardiac biomarkers in 2 United Kingdom cohort studies: does utility depend on risk thresholds for treatment?},
  author={Welsh, Paul and Hart, Carole and Papacosta, Olia and Preiss, David and McConnachie, Alex and Murray, Heather and Ramsay, Sheena and Upton, Mark and Watt, Graham and Whincup, Peter and others},
  journal={Hypertension},
  volume={67},
  number={2},
  pages={309--315},
  year={2016},
  publisher={Am Heart Assoc}
}

@article{lightman2023let,
  title={Let's verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}

@article{kim2023cot,
  title={The cot collection: Improving zero-shot and few-shot learning of language models via chain-of-thought fine-tuning},
  author={Kim, Seungone and Joo, Se June and Kim, Doyoung and Jang, Joel and Ye, Seonghyeon and Shin, Jamin and Seo, Minjoon},
  journal={arXiv preprint arXiv:2305.14045},
  year={2023}
}

@article{huang2024pokergpt,
  title={PokerGPT: An End-to-End Lightweight Solver for Multi-Player Texas Hold'em via Large Language Model},
  author={Huang, Chenghao and Cao, Yanbo and Wen, Yinlong and Zhou, Tao and Zhang, Yanru},
  journal={arXiv preprint arXiv:2401.06781},
  year={2024}
}

@article{zhang2024agent,
  title={Agent-pro: Learning to evolve via policy-level reflection and optimization},
  author={Zhang, Wenqi and Tang, Ke and Wu, Hai and Wang, Mengna and Shen, Yongliang and Hou, Guiyang and Tan, Zeqi and Li, Peng and Zhuang, Yueting and Lu, Weiming},
  journal={arXiv preprint arXiv:2402.17574},
  year={2024}
}

@article{guo2023suspicion,
  title={Suspicion-agent: Playing imperfect information games with theory of mind aware gpt-4},
  author={Guo, Jiaxian and Yang, Bo and Yoo, Paul and Lin, Bill Yuchen and Iwasawa, Yusuke and Matsuo, Yutaka},
  journal={arXiv preprint arXiv:2309.17277},
  year={2023}
}

@article{saha2024language,
  title={Language Models are Crossword Solvers},
  author={Saha, Soumadeep and Chakraborty, Sutanoya and Saha, Saptarshi and Garain, Utpal},
  journal={arXiv preprint arXiv:2406.09043},
  year={2024}
}

@article{giadikiaroglou2024puzzle,
  title={Puzzle Solving using Reasoning of Large Language Models: A Survey},
  author={Giadikiaroglou, Panagiotis and Lymperaiou, Maria and Filandrianos, Giorgos and Stamou, Giorgos},
  journal={arXiv preprint arXiv:2402.11291},
  year={2024}
}

@article{verma2024adaptagent,
  title={Adaptagent: Adapting multimodal web agents with few-shot learning from human demonstrations},
  author={Verma, Gaurav and Kaur, Rachneet and Srishankar, Nishan and Zeng, Zhen and Balch, Tucker and Veloso, Manuela},
  journal={arXiv preprint arXiv:2411.13451},
  year={2024}
}

@article{qinghong2024showui,
  title={ShowUI: One Vision-Language-Action Model for GUI Visual Agent},
  author={Qinghong Lin, Kevin and Li, Linjie and Gao, Difei and Yang, Zhengyuan and Wu, Shiwei and Bai, Zechen and Lei, Weixian and Wang, Lijuan and Shou, Mike Zheng},
  journal={arXiv e-prints},
  pages={arXiv--2411},
  year={2024}
}

@article{shen2024falcon,
  title={Falcon-UI: Understanding GUI Before Following User Instructions},
  author={Shen, Huawen and Liu, Chang and Li, Gengluo and Wang, Xinlong and Zhou, Yu and Ma, Can and Ji, Xiangyang},
  journal={arXiv preprint arXiv:2412.09362},
  year={2024}
}

@article{yang2024aria,
  title={Aria-UI: Visual Grounding for GUI Instructions},
  author={Yang, Yuhao and Wang, Yue and Li, Dongxu and Luo, Ziyang and Chen, Bei and Huang, Chao and Li, Junnan},
  journal={arXiv preprint arXiv:2412.16256},
  year={2024}
}

@article{wang2024gui,
  title={Gui agents with foundation models: A comprehensive survey},
  author={Wang, Shuai and Liu, Weiwen and Chen, Jingxuan and Gan, Weinan and Zeng, Xingshan and Yu, Shuai and Hao, Xinlong and Shao, Kun and Wang, Yasheng and Tang, Ruiming},
  journal={arXiv preprint arXiv:2411.04890},
  year={2024}
}

@article{liao2023text,
  title={Text-driven Visual Synthesis with Latent Diffusion Prior},
  author={Liao, Ting-Hsuan and Ge, Songwei and Xu, Yiran and Lee, Yao-Chih and AlBahar, Badour and Huang, Jia-Bin},
  journal={arXiv preprint arXiv:2302.08510},
  year={2023}
}
@article{liao2023textsyndiffusionprior,
      title   = {Text-driven Visual Synthesis with Latent Diffusion Prior},
      author  = {Liao, Ting-Hsuan and Ge Songwei and Xu Yiran and Lee, Yao-Chih and AlBahar Badour and Huang, Jia-Bin},
      journal = {arXiv preprint arXiv:},
      year    = {2023}
    }    
@article{li20223ddesigner,
  title={3DDesigner: Towards Photorealistic 3D Object Generation and Editing with Text-guided Diffusion Models},
  author={Li, Gang and Zheng, Heliang and Wang, Chaoyue and Li, Chang and Zheng, Changwen and Tao, Dacheng},
  journal={arXiv preprint arXiv:2211.14108},
  year={2022}
}
@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}


@article{claude2,
  title={Model card and evaluations for claude models.},
  author={Models, C.},
  journal={https://www-files.anthropic.com/production/images/
Model-Card-Claude-2.pdf.},
  year={2023}
}

@misc{dai2023instructblip,
      title={InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning}, 
      author={Wenliang Dai and Junnan Li and Dongxu Li and Anthony Meng Huat Tiong and Junqi Zhao and Weisheng Wang and Boyang Li and Pascale Fung and Steven Hoi},
      year={2023},
      eprint={2305.06500},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}


@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{chen2023agentverse,
  title={AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents},
  author={Chen, Weize and Su, Yusheng and Zuo, Jingwei and Yang, Cheng and Yuan, Chenfei and Qian, Chen and Chan, Chi-Min and Qin, Yujia and Lu, Yaxi and Xie, Ruobing and others},
  journal={arXiv preprint arXiv:2308.10848},
  year={2023}
}

@misc{gong2023mindagent,
      title={MindAgent: Emergent Gaming Interaction}, 
      author={Ran Gong and Qiuyuan Huang and Xiaojian Ma and Hoi Vo and Zane Durante and Yusuke Noda and Zilong Zheng and Song-Chun Zhu and Demetri Terzopoulos and Li Fei-Fei and Jianfeng Gao},
      year={2023},
      eprint={2309.09971},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{bang2023multitask,
  title={A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
  journal={arXiv preprint arXiv:2302.04023},
  year={2023}
}



@article{mckenna2023sources,
  title={Sources of Hallucination by Large Language Models on Inference Tasks},
  author={McKenna, Nick and Li, Tianyi and Cheng, Liang and Hosseini, Mohammad Javad and Johnson, Mark and Steedman, Mark},
  journal={arXiv preprint arXiv:2305.14552},
  year={2023}
}



@article{zhang2023siren,
  title={Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models},
  author={Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
  journal={arXiv preprint arXiv:2309.01219},
  year={2023}
}





@inproceedings{zhang2018unreasonable,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={586--595},
  year={2018}
}
@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and others},
  journal={arXiv preprint arXiv:2205.11487},
  year={2022}
}
@article{yu2022scaling,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  journal={arXiv preprint arXiv:2206.10789},
  year={2022}
}


@article{agentgpt,
  title={Agentgpt},
  author={Reworkd},
  journal={https://github.com/reworkd/AgentGPT},
  year={2023}
}

@article{autogpt,
  title={Auto-GPT},
  author={Toran Bruce Richards and others},
  journal={https:
//github.com/Significant-Gravitas/Auto-GPT},
  year={2023}
}
@article{richardson2023texture,
  title={Texture: Text-guided texturing of 3d shapes},
  author={Richardson, Elad and Metzer, Gal and Alaluf, Yuval and Giryes, Raja and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2302.01721},
  year={2023}
}

@article{ho2020denoising,
    title={Denoising Diffusion Probabilistic Models},
    author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
    year={2020},
    journal={arXiv preprint arxiv:2006.11239}
}
@article{song2020denoising,
  title={Denoising Diffusion Implicit Models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv:2010.02502},
  year={2020},
  month={October},
  abbr={Preprint},
  url={https://arxiv.org/abs/2010.02502}
}
@misc{rombach2021highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{poole2022dreamfusion,
  author = {Poole, Ben and Jain, Ajay and Barron, Jonathan T. and Mildenhall, Ben},
  title = {DreamFusion: Text-to-3D using 2D Diffusion},
  journal = {arXiv},
  year = {2022},
}
@inproceedings{zeng2022lion,
    title={LION: Latent Point Diffusion Models for 3D Shape Generation},
    author={Xiaohui Zeng and Arash Vahdat and Francis Williams and Zan Gojcic and Or Litany and Sanja Fidler and Karsten Kreis},
    booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
    year={2022}
}
@inproceedings{Zhou_2021_ICCV,
    author    = {Zhou, Linqi and Du, Yilun and Wu, Jiajun},
    title     = {3D Shape Generation and Completion Through Point-Voxel Diffusion},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {5826-5835}
}

@article{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Agrawala, Maneesh},
  journal={arXiv preprint arXiv:2302.05543},
  year={2023}
}

@inproceedings{lin2023magic3d,
  title={Magic3D: High-Resolution Text-to-3D Content Creation},
  author={Lin, Chen-Hsuan and Gao, Jun and Tang, Luming and Takikawa, Towaki and Zeng, Xiaohui and Huang, Xun and Kreis, Karsten and Fidler, Sanja and Liu, Ming-Yu and Lin, Tsung-Yi},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition ({CVPR})},
  year={2023}
}
@article{xu2022dream3d,
  author    = {Xu, Jiale and Wang, Xintao and Cheng, Weihao and Cao, Yan-Pei and Shan, Ying and Qie, Xiaohu and Gao, Shenghua},
  title     = {Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models},
  journal   = {arXiv preprint arXiv:2212.14704},
  year      = {2022},
}
@article{nam20223d,
  title={3D-LDM: Neural Implicit 3D Shape Generation with Latent Diffusion Models},
  author={Nam, Gimin and Khlifi, Mariem and Rodriguez, Andrew and Tono, Alberto and Zhou, Linqi and Guerrero, Paul},
  journal={arXiv preprint arXiv:2212.00842},
  year={2022}
}

@article{muller2022diffrf,
  title={DiffRF: Rendering-Guided 3D Radiance Field Diffusion},
  author={M{\"u}ller, Norman and Siddiqui, Yawar and Porzi, Lorenzo and Bul{\`o}, Samuel Rota and Kontschieder, Peter and Nie{\ss}ner, Matthias},
  journal={arXiv preprint arXiv:2212.01206},
  year={2022}
}
@article{chou2022diffusionsdf,
title={DiffusionSDF: Conditional Generative Modeling of Signed Distance Functions},
author={Gene Chou and Yuval Bahat and Felix Heide},
journal={arXiv preprint arXiv:2211.13757},
year={2022}
}
@inproceedings{meng2021sdedit,
  title={Sdedit: Guided image synthesis and editing with stochastic differential equations},
  author={Meng, Chenlin and He, Yutong and Song, Yang and Song, Jiaming and Wu, Jiajun and Zhu, Jun-Yan and Ermon, Stefano},
  booktitle={International Conference on Learning Representations},
  year={2021}
}
@article{tyszkiewicz2023gecco,
  title={GECCO: Geometrically-Conditioned Point Diffusion Models},
  author={Tyszkiewicz, Micha{\l} J and Fua, Pascal and Trulls, Eduard},
  journal={arXiv preprint arXiv:2303.05916},
  year={2023}
}
@inproceedings{
    Liu2023MeshDiffusion,
    title={MeshDiffusion: Score-based Generative 3D Mesh Modeling},
    author={Zhen Liu and Yao Feng and Michael J. Black and Derek Nowrouzezahrai and Liam Paull and Weiyang Liu},
    booktitle={International Conference on Learning Representations},
    year={2023},
    url={https://openreview.net/forum?id=0cpM2ApF9p6}
}
@inproceedings{luo2021diffusion,
  author = {Luo, Shitong and Hu, Wei},
  title = {Diffusion Probabilistic Models for 3D Point Cloud Generation},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2021}
}
@article{anciukevicius2022renderdiffusion,
	title        = {{RenderDiffusion}: Image Diffusion for {3D} Reconstruction, Inpainting and Generation},
	author       = {Titas Anciukevicius and Zexiang Xu and Matthew Fisher and Paul Henderson and Hakan Bilen and Mitra, Niloy J. and Paul Guerrero},
	year         = 2022,
	journal      = {arXiv}
}

% ############ Novel View generation with few views ############
@InProceedings{TDB16a,
author       = "M. Tatarchenko and A. Dosovitskiy and T. Brox",
title        = "Multi-view 3D Models from Single Images with a Convolutional Network",
booktitle    = "European Conference on Computer Vision (ECCV)",
year         = "2016"
}

@misc{rombach2021geometryfree,
      title={Geometry-Free View Synthesis: Transformers and no 3D Priors},
      author={Robin Rombach and Patrick Esser and Björn Ommer},
      year={2021},
      eprint={2104.07652},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{kulhanek2022viewformer,
  title={ViewFormer: NeRF-free Neural Rendering from Few Images Using Transformers},
  author={Kulh{\'a}nek, Jon{\'a}{\v{s}} and Derner, Erik and Sattler, Torsten and Babu{\v{s}}ka, Robert},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2022},
}
@article{watson2022novel,
  title={Novel view synthesis with diffusion models},
  author={Watson, Daniel and Chan, William and Martin-Brualla, Ricardo and Ho, Jonathan and Tagliasacchi, Andrea and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:2210.04628},
  year={2022}
}
@inproceedings{yu2020pixelnerf,
      title={{pixelNeRF}: Neural Radiance Fields from One or Few Images},
      author={Alex Yu and Vickie Ye and Matthew Tancik and Angjoo Kanazawa},
      year={2021},
      booktitle={CVPR},
}

@article{seo2023let,
  title={Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation},
  author={Seo, Junyoung and Jang, Wooseok and Kwak, Min-Seop and Ko, Jaehoon and Kim, Hyeonsu and Kim, Junho and Kim, Jin-Hwa and Lee, Jiyoung and Kim, Seungryong},
  journal={arXiv preprint arXiv:2303.07937},
  year={2023}
}
@inproceedings{reizenstein2021common,
  title={Common objects in 3d: Large-scale learning and evaluation of real-life 3d category reconstruction},
  author={Reizenstein, Jeremy and Shapovalov, Roman and Henzler, Philipp and Sbordone, Luca and Labatut, Patrick and Novotny, David},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10901--10911},
  year={2021}
}
@inproceedings{reizenstein21co3d,
	Author = {Reizenstein, Jeremy and Shapovalov, Roman and Henzler, Philipp and Sbordone, Luca and Labatut, Patrick and Novotny, David},
	Booktitle = {International Conference on Computer Vision},
	Title = {Common Objects in 3D: Large-Scale Learning and Evaluation of Real-life 3D Category Reconstruction},
	Year = {2021},
}

@inproceedings{NEURIPS2019_b5dc4e5d,
 author = {Sitzmann, Vincent and Zollhoefer, Michael and Wetzstein, Gordon},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations},
 url = {https://proceedings.neurips.cc/paper/2019/file/b5dc4e5d9b495d0196f61d45b26ef33e-Paper.pdf},
 volume = {32},
 year = {2019}
}


@article{deng2022nerdi,
  title={NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as General Image Priors},
  author={Deng, Congyue and Jiang, Chiyu and Qi, Charles R and Yan, Xinchen and Zhou, Yin and Guibas, Leonidas and Anguelov, Dragomir and others},
  journal={arXiv preprint arXiv:2212.03267},
  year={2022}
}
@inproceedings{alwala2022pre,
  title={Pre-train, self-train, distill: A simple recipe for supersizing 3d reconstruction},
  author={Alwala, Kalyan Vasudev and Gupta, Abhinav and Tulsiani, Shubham},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3773--3782},
  year={2022}
}
@InProceedings{Jain_2021_ICCV,
  author = {Jain, Ajay and Tancik, Matthew and Abbeel, Pieter},
  title = {Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  month = {October},
  year = {2021},
  pages = {5885-5894}
}
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}



@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{holmstrom1983efficient,
  title={Efficient and durable decision rules with incomplete information},
  author={Holmstr{\"o}m, Bengt and Myerson, Roger B},
  journal={Econometrica: Journal of the Econometric Society},
  pages={1799--1819},
  year={1983},
  publisher={JSTOR}
}

@article{gray2020human,
  title={Human-level performance in no-press diplomacy via equilibrium search},
  author={Gray, Jonathan and Lerer, Adam and Bakhtin, Anton and Brown, Noam},
  journal={arXiv preprint arXiv:2010.02923},
  year={2020}
}

@article{meta2022human,
  title={Human-level play in the game of Diplomacy by combining language models with strategic reasoning},
  author={Meta Fundamental AI Research Diplomacy Team and Bakhtin, Anton and Brown, Noam and Dinan, Emily and Farina, Gabriele and Flaherty, Colin and Fried, Daniel and Goff, Andrew and Gray, Jonathan and Hu, Hengyuan and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1067--1074},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{brown2019solving,
  title={Solving imperfect-information games via discounted regret minimization},
  author={Brown, Noam and Sandholm, Tuomas},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={1829--1836},
  year={2019}
}

@inproceedings{brown2017dynamic,
  title={Dynamic thresholding and pruning for regret minimization},
  author={Brown, Noam and Kroer, Christian and Sandholm, Tuomas},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={31},
  number={1},
  year={2017}
}

@article{brown2018superhuman,
  title={Superhuman AI for heads-up no-limit poker: Libratus beats top professionals},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={359},
  number={6374},
  pages={418--424},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{brown2019deep,
  title={Deep counterfactual regret minimization},
  author={Brown, Noam and Lerer, Adam and Gross, Sam and Sandholm, Tuomas},
  booktitle={International conference on machine learning},
  pages={793--802},
  year={2019},
  organization={PMLR}
}


@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{brown2020combining,
  title={Combining deep reinforcement learning and search for imperfect-information games},
  author={Brown, Noam and Bakhtin, Anton and Lerer, Adam and Gong, Qucheng},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17057--17069},
  year={2020}
}

@article{de2013much,
  title={How much does it help to know what she knows you know? An agent-based simulation study},
  author={De Weerd, Harmen and Verbrugge, Rineke and Verheij, Bart},
  journal={Artificial Intelligence},
  volume={199},
  pages={67--92},
  year={2013},
  publisher={Elsevier}
}

@article{hurley2008shared,
  title={The shared circuits model (SCM): How control, mirroring, and simulation can enable imitation, deliberation, and mindreading},
  author={Hurley, Susan},
  journal={Behavioral and brain sciences},
  volume={31},
  number={1},
  pages={1--22},
  year={2008},
  publisher={Cambridge University Press}
}


@article{nichols2003mindreading,
  title={Mindreading: An integrated account of pretence, self-awareness, and understanding other minds},
  author={Nichols, Shaun and Stich, Stephen P},
  year={2003}
}


@article{davies1994mental,
  title={The mental simulation debate},
  author={Davies, Martin},
  journal={Philosophical Issues},
  volume={5},
  pages={189--218},
  year={1994},
  publisher={JSTOR}
}


@article{zinkevich2007regret,
  title={Regret minimization in games with incomplete information},
  author={Zinkevich, Martin and Johanson, Michael and Bowling, Michael and Piccione, Carmelo},
  journal={Advances in neural information processing systems},
  volume={20},
  year={2007}
}

@article{harsanyi1968games,
  title={Games with incomplete information played by “Bayesian” players part II. Bayesian equilibrium points},
  author={Harsanyi, John C},
  journal={Management Science},
  volume={14},
  number={5},
  pages={320--334},
  year={1968},
  publisher={INFORMS}
}

@article{brown2019superhuman,
  title={Superhuman AI for multiplayer poker},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={365},
  number={6456},
  pages={885--890},
  year={2019},
  publisher={American Association for the Advancement of Science}
}



@article{moravvcik2017deepstack,
  title={Deepstack: Expert-level artificial intelligence in heads-up no-limit poker},
  author={Morav{\v{c}}{\'\i}k, Matej and Schmid, Martin and Burch, Neil and Lis{\`y}, Viliam and Morrill, Dustin and Bard, Nolan and Davis, Trevor and Waugh, Kevin and Johanson, Michael and Bowling, Michael},
  journal={Science},
  volume={356},
  number={6337},
  pages={508--513},
  year={2017},
  publisher={American Association for the Advancement of Science}
}

@article{zhou2022decisionholdem,
  title={DecisionHoldem: safe depth-limited solving with diverse opponents for imperfect-information games},
  author={Zhou, Qibin and Bai, Dongdong and Zhang, Junge and Duan, Fuqing and Huang, Kaiqi},
  journal={arXiv preprint arXiv:2201.11580},
  year={2022}
}

@article{tammelin2014solving,
  title={Solving large imperfect information games using CFR+},
  author={Tammelin, Oskari},
  journal={arXiv preprint arXiv:1407.5042},
  year={2014}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{hagendorff2023machine,
  title={Machine psychology: Investigating emergent capabilities and behavior in large language models using psychological methods},
  author={Hagendorff, Thilo},
  journal={arXiv preprint arXiv:2303.13988},
  year={2023}
}

@article{guo2023gpt,
  title={GPT Agents in Game Theory Experiments},
  author={Guo, Fulin},
  journal={arXiv preprint arXiv:2305.05516},
  year={2023}
}

@article{heinrich2016deep,
  title={Deep reinforcement learning from self-play in imperfect-information games},
  author={Heinrich, Johannes and Silver, David},
  journal={arXiv preprint arXiv:1603.01121},
  year={2016}
}

@inproceedings{burch2014solving,
  title={Solving imperfect information games using decomposition},
  author={Burch, Neil and Johanson, Michael and Bowling, Michael},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={28},
  number={1},
  year={2014}
}

@inproceedings{tian2019elf,
  title={Elf opengo: An analysis and open reimplementation of alphazero},
  author={Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, Larry},
  booktitle={International conference on machine learning},
  pages={6244--6253},
  year={2019},
  organization={PMLR}
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@article{frith2005theory,
  title={Theory of mind},
  author={Frith, Chris and Frith, Uta},
  journal={Current biology},
  volume={15},
  number={17},
  pages={R644--R645},
  year={2005},
  publisher={Elsevier}
}

@article{heyes2014cultural,
  title={The cultural evolution of mind reading},
  author={Heyes, Cecilia M and Frith, Chris D},
  journal={Science},
  volume={344},
  number={6190},
  pages={1243091},
  year={2014},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{aher2023using,
  title={Using large language models to simulate multiple humans and replicate human subject studies},
  author={Aher, Gati V and Arriaga, Rosa I and Kalai, Adam Tauman},
  booktitle={International Conference on Machine Learning},
  pages={337--371},
  year={2023},
  organization={PMLR}
}

@article{sel2023algorithm,
  title={Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models},
  author={Sel, Bilgehan and Al-Tawaha, Ahmad and Khattar, Vanshaj and Wang, Lu and Jia, Ruoxi and Jin, Ming},
  journal={arXiv preprint arXiv:2308.10379},
  year={2023}
}


@article{besta2023graph,
  title={Graph of Thoughts: Solving Elaborate Problems with Large Language Models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Podstawski, Michal and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  journal={arXiv preprint arXiv:2308.09687},
  year={2023}
}


@article{yao2023tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2305.10601},
  year={2023}
}


@article{southey2012bayes,
  title={Bayes' bluff: Opponent modelling in poker},
  author={Southey, Finnegan and Bowling, Michael P and Larson, Bryce and Piccione, Carmelo and Burch, Neil and Billings, Darse and Rayner, Chris},
  journal={arXiv preprint arXiv:1207.1411},
  year={2012}
}

@article{shinn2023reflexion,
  title={Reflexion: an autonomous agent with dynamic memory and self-reflection},
  author={Shinn, Noah and Labash, Beck and Gopinath, Ashwin},
  journal={arXiv preprint arXiv:2303.11366},
  year={2023}
}

@article{wang2023describe,
  title={Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents},
  author={Wang, Zihao and Cai, Shaofei and Liu, Anji and Ma, Xiaojian and Liang, Yitao},
  journal={arXiv preprint arXiv:2302.01560},
  year={2023}
}

@article{liu2023agentbench,
  title={AgentBench: Evaluating LLMs as Agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  journal={arXiv preprint arXiv:2308.03688},
  year={2023}
}

@article{guo2022images,
  title={From images to textual prompts: Zero-shot vqa with frozen large language models},
  author={Guo, Jiaxian and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Li, Boyang and Tao, Dacheng and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2212.10846},
  year={2022}
}

@article{ganguli2023capacity,
  title={The capacity for moral self-correction in large language models},
  author={Ganguli, Deep and Askell, Amanda and Schiefer, Nicholas and Liao, Thomas and Luko{\v{s}}i{\=u}t{\.e}, Kamil{\.e} and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and Olsson, Catherine and Hernandez, Danny and others},
  journal={arXiv preprint arXiv:2302.07459},
  year={2023}
}

@article{huang2022large,
  title={Large language models can self-improve},
  author={Huang, Jiaxin and Gu, Shixiang Shane and Hou, Le and Wu, Yuexin and Wang, Xuezhi and Yu, Hongkun and Han, Jiawei},
  journal={arXiv preprint arXiv:2210.11610},
  year={2022}
}


@inproceedings{montes2022combining,
  title={Combining Theory of Mind and Abduction for Cooperation Under Imperfect Information},
  author={Montes, Nieves and Osman, Nardine and Sierra, Carles},
  booktitle={European Conference on Multi-Agent Systems},
  pages={294--311},
  year={2022},
  organization={Springer}
}

@article{roska2008theory,
  title={Theory theory (Simulation theory, theory of mind)},
  author={R{\"o}ska-Hardy, Louise},
  year={2008}
}

@article{wu2023spring,
  title={SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning},
  author={Wu, Yue and Min, So Yeon and Prabhumoye, Shrimai and Bisk, Yonatan and Salakhutdinov, Ruslan and Azaria, Amos and Mitchell, Tom and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2305.15486},
  year={2023}
}

@article{zha2019rlcard,
  title={Rlcard: A toolkit for reinforcement learning in card games},
  author={Zha, Daochen and Lai, Kwei-Herng and Cao, Yuanpu and Huang, Songyi and Wei, Ruzhe and Guo, Junyu and Hu, Xia},
  journal={arXiv preprint arXiv:1910.04376},
  year={2019}
}


@article{kosinski2023theory,
  title={Theory of mind may have spontaneously emerged in large language models},
  author={Kosinski, Michal},
  journal={arXiv preprint arXiv:2302.02083},
  year={2023}
}

@article{kim2023language,
  title={Language models can solve computer tasks},
  author={Kim, Geunwoo and Baldi, Pierre and McAleer, Stephen},
  journal={arXiv preprint arXiv:2303.17491},
  year={2023}
}

@article{schuurmans2023memory,
  title={Memory augmented large language models are computationally universal},
  author={Schuurmans, Dale},
  journal={arXiv preprint arXiv:2301.04589},
  year={2023}
}

@article{fan2022minedojo,
  title={Minedojo: Building open-ended embodied agents with internet-scale knowledge},
  author={Fan, Linxi and Wang, Guanzhi and Jiang, Yunfan and Mandlekar, Ajay and Yang, Yuncong and Zhu, Haoyi and Tang, Andrew and Huang, De-An and Zhu, Yuke and Anandkumar, Anima},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={18343--18362},
  year={2022}
}



@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{xu2023rewoo,
  title={ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models},
  author={Xu, Binfeng and Peng, Zhiyuan and Lei, Bowen and Mukherjee, Subhabrata and Liu, Yuchen and Xu, Dongkuan},
  journal={arXiv preprint arXiv:2305.18323},
  year={2023}
}

@article{zeng2022glm,
  title={Glm-130b: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={arXiv preprint arXiv:2210.02414},
  year={2022}
}


@article{baby2023y,
  title={Babyagi},
  author={Y. Nakajima},
  journal={https://github. com/yoheinakajima/babyagi},
  year={2023}
}

@article{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@inproceedings{zha2021douzero,
  title={Douzero: Mastering doudizhu with self-play deep reinforcement learning},
  author={Zha, Daochen and Xie, Jingru and Ma, Wenye and Zhang, Sheng and Lian, Xiangru and Hu, Xia and Liu, Ji},
  booktitle={international conference on machine learning},
  pages={12333--12344},
  year={2021},
  organization={PMLR}
}


@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}


@article{dua2019drop,
  title={DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs},
  author={Dua, Dheeru and Wang, Yizhong and Dasigi, Pradeep and Stanovsky, Gabriel and Singh, Sameer and Gardner, Matt},
  journal={arXiv preprint arXiv:1903.00161},
  year={2019}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{sakaguchi2021winogrande,
  title={Winogrande: An adversarial winograd schema challenge at scale},
  author={Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},
  journal={Communications of the ACM},
  volume={64},
  number={9},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{clark2018think,
  title={Think you have solved question answering? try arc, the ai2 reasoning challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal={arXiv preprint arXiv:1803.05457},
  year={2018}
}

@article{zellers2019hellaswag,
  title={Hellaswag: Can a machine really finish your sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  journal={arXiv preprint arXiv:1905.07830},
  year={2019}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}


@article{scao2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}



@article{anil2023palm,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}

@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@article{sanh2021multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={arXiv preprint arXiv:2110.08207},
  year={2021}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{longpre2023flan,
  title={The flan collection: Designing data and methods for effective instruction tuning},
  author={Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and others},
  journal={arXiv preprint arXiv:2301.13688},
  year={2023}
}


@misc{lu2023scorebased,
  title={Score-Based Equilibrium Learning in Multi-Player Finite Games with Imperfect Information}, 
  author={Runyu Lu and Yuanheng Zhu and Dongbin Zhao},
  year={2023},
  eprint={2306.00350},
  archivePrefix={arXiv},
  primaryClass={cs.GT}
}


@Article{electronics12112453,
  AUTHOR = {Ouyang, Xin and Zhou, Ting},
  TITLE = {Imperfect-Information Game AI Agent Based on Reinforcement Learning Using Tree Search and a Deep Neural Network},
  JOURNAL = {Electronics},
  VOLUME = {12},
  YEAR = {2023},
  NUMBER = {11},
  ARTICLE-NUMBER = {2453},
  URL = {https://www.mdpi.com/2079-9292/12/11/2453},
  ISSN = {2079-9292},
  DOI = {10.3390/electronics12112453}
}

@book{roughgarden2016twenty,
  title={Twenty lectures on algorithmic game theory},
  author={Roughgarden, Tim},
  year={2016},
  publisher={Cambridge University Press}
}

@article{Chatterjee_2007,
  doi = {10.2168/lmcs-3(3:4)2007},
  url = {https://doi.org/10.2168%2Flmcs-3%283%3A4%292007},
  year = 2007,
  month = {jul},
  publisher = {Centre pour la Communication Scientifique Directe ({CCSD})},
  volume = {Volume 3, Issue 3},
  author = {Krishnendu Chatterjee and Laurent Doyen and Thomas A. Henzinger and Jean-Francois Raskin},
  title = {Algorithms for Omega-Regular Games with Imperfect Information},
  journal = {Logical Methods in Computer Science}
}

@article{KROER2020103218,
  title = {Limited lookahead in imperfect-information games},
  journal = {Artificial Intelligence},
  volume = {283},
  pages = {103218},
  year = {2020},
  issn = {0004-3702},
  doi = {https://doi.org/10.1016/j.artint.2019.103218},
  url = {https://www.sciencedirect.com/science/article/pii/S000437021930044X},
  author = {Christian Kroer and Tuomas Sandholm},
  keywords = {Game theory, Equilibrium finding, Limited lookahead, Imperfect-information game, Nash equilibrium, Stackelberg equilibrium},
}

@misc{sokota2023abstracting,
  title={Abstracting Imperfect Information Away from Two-Player Zero-Sum Games}, 
  author={Samuel Sokota and Ryan D'Orazio and Chun Kai Ling and David J. Wu and J. Zico Kolter and Noam Brown},
  year={2023},
  eprint={2301.09159},
  archivePrefix={arXiv},
  primaryClass={cs.GT}
}

@misc{brown2018depthlimited,
  title={Depth-Limited Solving for Imperfect-Information Games}, 
  author={Noam Brown and Tuomas Sandholm and Brandon Amos},
  year={2018},
  eprint={1805.08195},
  archivePrefix={arXiv},
  primaryClass={cs.GT}
}

@misc{gupta2023chatgpt,
  title={Are ChatGPT and GPT-4 Good Poker Players? -- A Pre-Flop Analysis}, 
  author={Akshat Gupta},
  year={2023},
  eprint={2308.12466}, archivePrefix={arXiv}, 
  primaryClass={cs.CL}
}

@misc{xu2023exploring,
  title={Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf}, 
  author={Yuzhuang Xu and Shuo Wang and Peng Li and Fuwen Luo and Xiaolong Wang and Weidong Liu and Yang Liu},
  year={2023},
  eprint={2309.04658},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@misc{akata2023playing,
  title={Playing repeated games with Large Language Models}, 
  author={Elif Akata and Lion Schulz and Julian Coda-Forno and Seong Joon Oh and Matthias Bethge and Eric Schulz},
  year={2023},
  eprint={2305.16867},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@article{frank2001theoretical,
  title={A theoretical and empirical investigation of search in imperfect information games},
  author={Frank, Ian and Basin, David},
  journal={Theoretical Computer Science},
  volume={252},
  number={1-2},
  pages={217--256},
  year={2001},
  publisher={Elsevier}
}

@article{kreps1982reputation,
  title={Reputation and imperfect information},
  author={Kreps, David M and Wilson, Robert},
  journal={Journal of economic theory},
  volume={27},
  number={2},
  pages={253--279},
  year={1982},
  publisher={Elsevier}
}

@article{huang2022towards,
  title={Towards Reasoning in Large Language Models: A Survey},
  author={Huang, Jie and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint arXiv:2212.10403},
  year={2022}
}

@article{premack_woodruff_1978, 
  title={Does the chimpanzee have a theory of mind?}, volume={1}, 
  DOI={10.1017/S0140525X00076512}, 
  number={4}, 
  journal={Behavioral and Brain Sciences}, 
  publisher={Cambridge University Press}, 
  author={Premack, David and Woodruff, Guy}, 
  year={1978}, 
  pages={515–526}
}

@inproceedings{10.5555/2031678.2031702,
  author = {Wunder, Michael and Kaisers, Michael and Yaros, John Robert and Littman, Michael},
  title = {Using Iterated Reasoning to Predict Opponent Strategies},
  year = {2011},
  isbn = {0982657161},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  address = {Richland, SC},
  booktitle = {The 10th International Conference on Autonomous Agents and Multiagent Systems - Volume 2},
  pages = {593–600},
  numpages = {8},
  keywords = {iterated reasoning, POMDPs, cognitive models, repeated games, multiagent systems},
  location = {Taipei, Taiwan},
  series = {AAMAS '11}
}

@article{CRAWFORD2018219,
  title = {“Fatal Attraction” and Level-k thinking in games with Non-neutral frames},
  journal = {Journal of Economic Behavior and Organization},
  volume = {156},
  pages = {219-224},
  year = {2018},
  issn = {0167-2681},
  doi = {https://doi.org/10.1016/j.jebo.2018.10.008},
  url = {https://www.sciencedirect.com/science/article/pii/S016726811830283X},
  author = {Vincent P. Crawford},
  keywords = {Behavioral game theory, Experimental game theory, Strategic thinking, Level models, Coordination, Salience},
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv preprint arXiv:2302.04761},
  year={2023}
}



@article{lu2023chameleon,
  title={Chameleon: Plug-and-play compositional reasoning with large language models},
  author={Lu, Pan and Peng, Baolin and Cheng, Hao and Galley, Michel and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.09842},
  year={2023}
}


@misc{wang2023survey,
  title={A Survey on Large Language Model-based Autonomous Agents}, 
  author={Lei Wang and Chen Ma and Xueyang Feng and Zeyu Zhang and Hao Yang and Jingsen Zhang and Zhiyuan Chen and Jiakai Tang and Xu Chen and Yankai Lin and Wayne Xin Zhao and Zhewei Wei and Ji-Rong Wen},
  year={2023},
  eprint={2308.11432},
  archivePrefix={arXiv},
  primaryClass={cs.AI}
}

@misc{wang2023tpe,
  title={TPE: Towards Better Compositional Reasoning over Conceptual Tools with Multi-persona Collaboration}, 
  author={Hongru Wang and Huimin Wang and Lingzhi Wang and Minda Hu and Rui Wang and Boyang Xue and Hongyuan Lu and Fei Mi and Kam-Fai Wong},
  year={2023},
  eprint={2309.16090},
  archivePrefix={arXiv},
  primaryClass={cs.AI}
}

@misc{patil2023gorilla,
  title={Gorilla: Large Language Model Connected with Massive APIs}, 
  author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
  year={2023},
  eprint={2305.15334},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@inproceedings{farina2019stable,
 author = {Gabriele Farina and Christian Kroer and Noam Brown and Tuomas Sandholm},
 booktitle = {ICML},
 date = {2019-06},
 title = {Stable-Predictive Optimistic Counterfactual Regret Minimization},
 url = {https://arxiv.org/abs/1902.04982},
 year = {2019}
}

@inbook{10.5555/3454287.3454756,
author = {Farina, Gabriele and Kroer, Christian and Sandholm, Tuomas},
title = {Optimistic Regret Minimization for Extensive-Form Games via Dilated Distance-Generating Functions},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {469},
numpages = {11}
}

@inproceedings{10.1007/978-3-031-20862-1_7,
author = {Jiang, Huacong and Liu, Weiming and Li, Bin},
title = {Faster Optimistic Online Mirror Descent for Extensive-Form Games},
year = {2022},
isbn = {978-3-031-20861-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-20862-1_7},
doi = {10.1007/978-3-031-20862-1_7},
booktitle = {PRICAI 2022: Trends in Artificial Intelligence: 19th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2022, Shanghai, China, November 10–13, 2022, Proceedings, Part I},
pages = {90–103},
numpages = {14},
keywords = {Counterfactual regret minimization, Adaptive optimistic online mirror descent, Extensive-form games, Nash equilibrium},
location = {Shangai, China}
}

% ############ Novel View generation with few views ############

% ############ Diffusion Model for 3D reconstruction ############

@misc{feng2023revealingmysterychainthought,
      title={Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective}, 
      author={Guhao Feng and Bohang Zhang and Yuntian Gu and Haotian Ye and Di He and Liwei Wang},
      year={2023},
      eprint={2305.15408},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.15408}, 
}
@misc{ton2024understandingchainofthoughtllmsinformation,
      title={Understanding Chain-of-Thought in LLMs through Information Theory}, 
      author={Jean-Francois Ton and Muhammad Faaiz Taufiq and Yang Liu},
      year={2024},
      eprint={2411.11984},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.11984}, 
}
@misc{abbe2024fartransformersreasonglobality,
      title={How Far Can Transformers Reason? The Globality Barrier and Inductive Scratchpad}, 
      author={Emmanuel Abbe and Samy Bengio and Aryo Lotfi and Colin Sandon and Omid Saremi},
      year={2024},
      eprint={2406.06467},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.06467}, 
}
@misc{kudo2024thinktotalktalktothinkllmscome,
      title={Think-to-Talk or Talk-to-Think? When LLMs Come Up with an Answer in Multi-Step Reasoning}, 
      author={Keito Kudo and Yoichi Aoki and Tatsuki Kuribayashi and Shusaku Sone and Masaya Taniguchi and Ana Brassard and Keisuke Sakaguchi and Kentaro Inui},
      year={2024},
      eprint={2412.01113},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.01113}, 
}
@misc{yu2025llmsreallythinkstepbystep,
      title={Do LLMs Really Think Step-by-step In Implicit Reasoning?}, 
      author={Yijiong Yu},
      year={2025},
      eprint={2411.15862},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.15862}, 
}
@misc{chen2024alphamathzeroprocesssupervision,
      title={AlphaMath Almost Zero: Process Supervision without Process}, 
      author={Guoxin Chen and Minpeng Liao and Chengxi Li and Kai Fan},
      year={2024},
      eprint={2405.03553},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.03553}, 
}

@misc{men2024baseropeboundscontext,
      title={Base of RoPE Bounds Context Length}, 
      author={Xin Men and Mingyu Xu and Bingning Wang and Qingyu Zhang and Hongyu Lin and Xianpei Han and Weipeng Chen},
      year={2024},
      eprint={2405.14591},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.14591}, 
}