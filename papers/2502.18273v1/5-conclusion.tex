\vspace{-0.2em}
\section{Conclusion}
In this paper, through controllable systematic experimentation and theoretical analysis in compound tasks, we demonstrate that (1) Direct QA-trained models exhibit dramatic performance degradation under shifts despite high in-distribution accuracy with even 100k data in the single task, (2) CoT granularity directly governs generalization strength, with fine-grained reasoning steps enabling higher OOD accuracy, and (3) CoT training achieves comparable performance to QA paradigms with much less data, underscoring its sample efficiency. Theoretically, we prove that compound tasks inherently permit spurious correlations in QA data, while CoT enforces structured reasoning paths, a process amplified by transformer positional embeddings through subtask condition recurrence. These findings provide a reliable guide for data
collection practices when leveraging LMs for novel tasks. We will explore automated CoT generation and dynamic granularity adaptation to further reduce annotation costs in the future work. 