\subsection{Experiments}
\subsubsection{LIS}
Chain of thought is like the following: 
\[
\begin{aligned}
    &48 \quad 49 \quad 26 \quad 47 <sep> \\
    &48 | <empty> = 48 \quad 1 : 1 \rightarrow 1 <sep>\\
    &49 | 48 \quad 1 = 49 \quad 2 : 1 \rightarrow 2 <sep> \\
    &26 | <empty> = 26 \quad 1 : 2 \rightarrow 2 <sep>\\
    &47 | 26 \quad 1 = 47 \quad 2 : 2 \rightarrow 2
    \end{aligned}
\]

\subsubsection{MPC}
Chain of thought is like following:
\[
\begin{aligned}
 &0 \quad 1 \quad 1 \quad 0 \quad 0 \quad 1 \quad 1 0 , 8 <sep> \\
 &1 , 0 , 1 \rightarrow 0 <sep> \\
 &2 , 1 , 1 \quad 0 \rightarrow 1 <sep> \\
 &3 , 1 , 1 \quad 0 \quad 1 \rightarrow 2 <sep> \\
 &4 , 0 , 0 \quad 1 \quad 2 \rightarrow 0 <sep> \\
 &5 , 0 , 1 \quad 2 \quad 0 \rightarrow 0 <sep> \\
 &6 , 1 , 2 \quad 0 \quad 0 \rightarrow 2 <sep> \\
 &7 , 1 , 0 \quad 0 \quad 2 \rightarrow 2 <sep> \\
 &8 , 0 , 0 \quad 2 \quad 2 \rightarrow 0
\end{aligned}
\]
\subsubsection{Equation Restoration and Variable Computation}
Input is:
Data:
$data_1: Condor = 6, Cheetah = 1.$ \\
$data_2: Condor = 12, Cheetah = 3.$ \\
Question:
Assume all relations between variables are linear combinations. If the number of Cheetah equals 5, then what is the number of Condor?

Question:
Assume all relations between variables are linear combinations. If the number of Leopard equals 5, the number of Rhino equals 3, the number of Koala equals 6, then what is the number of Black\_Bear?
%\vspace{-\baselineskip}
%\begin{equation}

\textbf{Solution\:}

\textbf{Defining Variables} \\
\textit{Known Variables:} \\
Cheetah as \( c_1 = 5 \) \\

\textit{Unknown Variables:} \\
Target Variable: Condor as \( c_2 \) \\

\textbf{Restoring Relations} \\
\textit{List all variable names in each data point:} \([c_2, c_1], [c_2, c_1]\) \\
\textit{Deduplicate them:} \([c_2, c_1]\) \\
There is 1 distinct group, implying 1 distinct linear relationship to be determined. \\
\textit{Examining each relationship:} \\

\textbf{Relation 1:} \\
Exploring relation for \( c_2 \): \\
There are 2 variables in the data beginning with \( c_2 \): Hence, 2 coefficients are required, and at least 2 data points are needed. \\

Let the coefficients on the right side of the equation be \( K_1 \) and \( K_2 \). \\
\textit{Recap variables:} \(['c_2', 'c_1']\) \\
\textit{Define the equation of relation 1:} \\
\( c_2 = K_1 \cdot c_1 + K_2 \) \\

Using data points \( \text{data}_1 \) and \( \text{data}_2 \): \\
\( \text{data}_1: c_2 = 6, c_1 = 1 \) \\
Equation 1: \( 6 = K_1 \cdot 1 + K_2 \) \\
\( \text{data}_2: c_2 = 12, c_1 = 3 \) \\
Equation 2: \( 12 = K_1 \cdot 3 + K_2 \) \\

\textbf{Solve the system of equations using Gaussian Elimination:} \\
\textit{Initialize:} \\
Equation 1: \( 1 \cdot K_1 + 1 \cdot K_2 = 6 \) \\
Equation 2: \( 3 \cdot K_1 + 1 \cdot K_2 = 12 \) \\

Swap Equation 1 with Equation 2: \\
Equation 1: \( 3 \cdot K_1 + 1 \cdot K_2 = 12 \) \\
Equation 2: \( 1 \cdot K_1 + 1 \cdot K_2 = 6 \) \\

Multiply Equation 1 by 1 and subtract 3 times Equation 2: \\
\((\text{Equation 1}) \cdot 1: 3 \cdot K_1 + 1 \cdot K_2 = 12 \) \\
\((\text{Equation 2}) \cdot 3: 3 \cdot K_1 + 3 \cdot K_2 = 18 \) \\
New Equation 2: \( -2 \cdot K_2 = -6 \) \\

\textit{Recap updated equations:} \\
Equation 1: \( 3 \cdot K_1 + 1 \cdot K_2 = 12 \) \\
Equation 2: \( -2 \cdot K_2 = -6 \) \\

\textbf{Solve for \( K_2 \):} \\
\( -2 \cdot K_2 = -6 \) \\
\( K_2 = \frac{-6}{-2} = 3 \) \\

\textbf{Solve for \( K_1 \):} \\
\( 3 \cdot K_1 = 12 - 1 \cdot K_2 \) \\
\( 3 \cdot K_1 = 12 - 3 = 9 \) \\
\( K_1 = \frac{9}{3} = 3 \) \\

\textit{Recap the equation:} \\
\( c_2 = K_1 \cdot c_1 + K_2 \) \\
Estimated coefficients: \( K_1 = 3, K_2 = 3 \) \\
Final equation: \( c_2 = 3 \cdot c_1 + 3 \) \\

\textbf{Calculation with Restored Relations:} \\
Using the equation \( c_2 = 3 \cdot c_1 + 3 \): \\
\textit{Known variables:} \( c_1 = 5 \) \\
\( c_2 = 3 \cdot 5 + 3 = 15 + 3 = 18 \) \\

\textbf{Recap Target Variable:} \\
Condor (\( c_2 \)) = 18 \\

\textbf{Conclusion:} The number of Condor equals 18.
%\end{equation}

\subsection{Out-of-distribution Comparison Across Input length}
The comparison \ref{fig:ood_detail} reveals the critical role of Chain-of-Thought prompting in improving models' OOD generalization. Both MPC (a) and LIS (b) demonstrate substantially higher accuracy when equipped with 100\% COT (blue lines) compared to without COT. This performance gap is particularly pronounced in out-of-domain regions, where models without COT show severe degradation (dropping below 0.2 accuracy). The consistent superior performance of COT-enabled models, especially in maintaining accuracy above 0.8 across different sequence lengths, underscores how COT prompting serves as a crucial mechanism for enhancing models' ability to generalize beyond their training distribution.
\begin{figure}[]
\centering
\subfigure[]{
    \includegraphics[width=0.8\linewidth]{figure/ood_figure_mpc.pdf}
}\hfill
\subfigure[]{
    \includegraphics[width=0.8\linewidth]{figure/lis_figure_mpc.pdf}}
\caption{Comparison of Out-Of-Distribution (OOD) performance between MPC and LIS models under different Chain-of-Thought (COT) conditions across varying sequence lengths.}
\label{fig:ood_detail}
\end{figure}