

\subsection{Additional results on MNIST, CIFAR-10, and ImageNet-32}
\label{sec:add_results}
Here we show additional results for experiments with MNIST, CIFAR-10, and ImageNet-32 data. From \cref{tab:training_image,tab:infer_time_image,tab:performance}, we can observe the following: For MNIST, our model is comparable in size, comparable in training times, and comparable in inference times, while  outperforming the baseline. For CIFAR-10 and ImageNet-32, our model is $1.25\times$ larger and has a slower inference time. However, as shown in \cref{tab:performance}, it still outperforms the baseline. We believe that the modest trade-off in model size and inference time is acceptable given the performance gains.

\begin{table}[t]
\centering
\resizebox{1.0\columnwidth}{!}{
\begin{tabular}{ccccccc}
\toprule
\textbf{Training} 
& \multicolumn{2}{c}{\textbf{MNIST}} 
& \multicolumn{2}{c}{\textbf{CIFAR-10}}
& \multicolumn{2}{c}{\textbf{ImageNet-32}}\\
\cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7}
& \textbf{RF (1.08M)} & \textbf{HRF2 (1.07M)} & \textbf{RF (35.75M)} & \textbf{HRF2 (44.81M)} &
\textbf{RF (37.06M)} & \textbf{HRF2 (46.21M)}\\
\midrule
Time (s/iter) & 0.1 & 0.1 & 0.3 & 0.4 & 0.7 & 0.8 \\
Memory (MB) & 3935 & 3931 & 8743 & 10639 & 27234 & 33838 \\
Param.\ Counts & 1,075,361 & 1,065,698 & 35,746,307 & 44,807,843 & 37,064,707 & 46,210,083\\
\bottomrule
\end{tabular}
}
\caption{Computational requirements during training on image datasets. }
\label{tab:training_image}
\end{table}

\begin{table}[t]
\centering
\resizebox{1.0\columnwidth}{!}{
\begin{tabular}{ccccccc}
\toprule
\textbf{Inference time (s)} 
& \multicolumn{2}{c}{\textbf{MNIST}} 
& \multicolumn{2}{c}{\textbf{CIFAR-10}}
& \multicolumn{2}{c}{\textbf{ImageNet-32}}\\
\cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7}
\textbf{Total NFEs} & 
\textbf{RF (1.08M)} & \textbf{HRF2 (1.07M)} & 
\textbf{RF (35.75M)} & \textbf{HRF2 (44.81M)} &
\textbf{RF (37.06M)} & \textbf{HRF2 (46.21M)} \\
\midrule
5 & 0.084 ± 0.001 & 0.085 ± 0.001 & 0.221 ± 0.000 & 0.295 ± 0.000 & 0.229 ± 0.000 & 0.301 ± 0.000 \\
10 & 0.168 ± 0.000 & 0.169 ± 0.000 & 0.441 ± 0.001 & 0.589 ± 0.001 & 0.458 ± 0.000 & 0.601 ± 0.000 \\
20 & 0.336 ± 0.000 & 0.339 ± 0.000 & 0.889 ± 0.001 & 1.176 ± 0.001 & 0.918 ± 0.001 & 1.207 ± 0.001 \\
50 & 0.843 ± 0.001 & 0.851 ± 0.002 & 2.229 ± 0.001 & 2.953 ± 0.004 & 2.302 ± 0.002 & 3.029 ± 0.004 \\
100 & 1.693 ± 0.002 & 1.706 ± 0.003 & 4.471 ± 0.004 & 5.921 ± 0.003 & 4.618 ± 0.003 & 6.100 ± 0.014 \\
500 & 8.538 ± 0.030 & 8.598 ± 0.010 & 22.375 ± 0.011 & 29.701 ± 0.011 & 23.110 ± 0.005 & 30.863 ± 0.083 \\
\bottomrule
\end{tabular}
}
\caption{Inference time comparison for MNIST, CIFAR-10, and ImageNet-32 datasets using a varying total NFEs budget. For HRF2 on MNIST we used sampling step combinations: $(1,5),(2,5),(5,4),(5,10),(5,20),(5,100)$. For HRF2 on CIFAR-10 and ImageNet-32 we used sampling step combinations: $(1,5),(1,10),(1,20),(1,50),(2,50),(2,250)$. All experiments are conducted with a batch size of 128. }
\label{tab:infer_time_image}
\end{table}

\begin{table}[t]
\centering
\resizebox{1.0\columnwidth}{!}{
\begin{tabular}{ccccccc}
\toprule
\textbf{Performance (FID)} 
& \multicolumn{2}{c}{\textbf{MNIST}} 
& \multicolumn{2}{c}{\textbf{CIFAR-10}}
& \multicolumn{2}{c}{\textbf{ImageNet-32}}\\
\cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7}
\textbf{Total NFEs} & 
\textbf{RF (1.08M)} & \textbf{HRF2 (1.07M)} & 
\textbf{RF (35.75M)} & \textbf{HRF2 (44.81M)} & 
\textbf{RF (37.06M)} & \textbf{HRF2 (46.21M)} \\
\midrule

5 & 19.187 ± 0.188 & \textbf{15.798 ± 0.151} & 36.209 ± 0.142 & \textbf{30.884 ± 0.104} & 69.233 ± 0.166 & \textbf{48.933 ± 0.177} \\
10 & 7.974 ± 0.119 & \textbf{6.644 ± 0.076} & 14.113 ± 0.092 & \textbf{12.065 ± 0.024} & 21.744 ± 0.045 & \textbf{20.286 ± 0.022} \\
20 & 6.151 ± 0.090 & \textbf{3.408 ± 0.076} & 8.355 ± 0.065 & \textbf{7.129 ± 0.027} & \textbf{12.411 ± 0.002} & 12.492 ± 0.100 \\
50 & 5.605 ± 0.057 & \textbf{2.664 ± 0.058} & 5.514 ± 0.034 & \textbf{4.847 ± 0.028} & \textbf{8.910 ± 0.137} & 9.024 ± 0.112 \\
100 & 5.563 ± 0.049 & \textbf{2.588 ± 0.075} & 4.588 ± 0.013 & \textbf{4.334 ± 0.054} & 7.873 ± 0.110 & \textbf{7.679 ± 0.022} \\
500 & 5.453 ± 0.047 & \textbf{2.574 ± 0.121} & 3.887 ± 0.035 & \textbf{3.706 ± 0.043} & 6.962 ± 0.087 & \textbf{6.503 ± 0.035} \\
\bottomrule
\end{tabular}
}
\caption{Performance comparison for MNIST, CIFAR-10, and ImageNet-32 datasets using a varying total NFEs budget. For HRF2 on MNIST we used sampling step combinations: $(5,1),(10,1),(5,4),(10,5),(10,10),(100,5)$. For HRF2 on CIFAR-10 and ImageNet-32 we used sampling step combinations: $(1,5),(1,10),(1,20),(1,50),(2,50),(2,250)$. \textbf{Bold} for lower mean. }
\label{tab:performance}
\end{table}
