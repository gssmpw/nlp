
\begin{figure*}[!htbp]
\centering
\includegraphics[width=0.98\textwidth]{Images/idea_comp.pdf}
\caption{\label{figure2}
The pipeline consists of Ideation and Composition components, structured around the summarized workflow and design space. The Ideation component offers knowledge-based guidance, allowing designers to explore and select content that aligns with their intent to form ideas. These ideas are then fed into multi-modal models within the Composition component, which retrieves and generates related content as references. This exploration of references empowers users to arrange reference and plan cut-out areas, facilitating the composition of their own paper-cutting designs.}
\Description{This figure shows the pipeline consists of Ideation and Composition components, structured around the summarized design space and workflow. The Ideation component offers knowledge-based guidance, allowing designers to explore and select content that aligns with their intent to form ideas. These ideas are then fed into multi-modal models within the Composition component, which retrieves and generates related content as references. This exploration of references empowers users to arrange reference and plan cut-out areas, facilitating the composition of their own paper-cutting designs.}
\end{figure*}

\section{HarmonyCut}\label{sec:harmonycut}
Drawing from the design space and the derived design goals, we introduced a two-component pipeline (\autoref{figure2}) to guide the development of HarmonyCut (\autoref{figure3}), a GenAI-aided design prototype system. This system can assist users in designing paper-cuttings by allowing them to explore and edit related references, such as knowledge, existing paper-cutting works, and patterns, ensuring alignment with both visual form and cultural meaning. HarmonyCut consists of two main components in the pipeline, corresponding to stages in the GenAI-aided paper-cutting design workflow: ideation (DG1) using LLMs and composition (DG2) employing Text-to-Image models~\autoref{figure2}. Each component is connected to the domain knowledge base we have summarized and supports editing and iteration, thereby enhancing the controllability of the design process (DG3).

% \wang{NEED TO emphasize that paper-cutting design is different from creation, do not need high-fidelity final output as results?}
% 详细叙述对于系统，是怎样具体实现这几个阶段的

% \subsection{Technical Evaluation}  这部分放到下面三部分写
% 1. Pattern Classifcication
% 2. Requirement - Paper-cutting Retrieval

\begin{figure*}[!htbp]
\centering
\includegraphics[width=\textwidth]{Images/interface.pdf}
\caption{\label{figure3}
The interface of HarmonyCut supports user creative paper-cutting design through several panels with guidance and exploration. (a) In the Idea Prompting panel, the system guides users through idea navigation using four factors: function, subject matter, style, and method of expression. It also provides related patterns with interpretations. Users can select suggested content that aligns with their intent or manually edit ideas. (b) The Interactive Mood Board panel allows users to arrange all references, including contours and patterns, for composition. (c) In the Reference Exploration panel, users explore system-suggested content, both retrieved and generated, to select contours and plan pattern layouts, thereby gaining ideas for their paper-cutting designs.}
\Description{This figure shows an interface of HarmonyCut that supports user creative paper-cutting design through several panels through guidance and exploration. (a) In the Idea Prompting panel, the system guides users through idea navigation using four factors: function, subject matter, style, and method of expression. It also provides related patterns with interpretations. Users can select suggested content that aligns with their intent or manually edit ideas. (b) The Interactive Mood Board panel allows users to arrange all references, including contours and patterns, for composition. (c) In the Reference Exploration panel, users explore system-suggested content, both retrieved and generated, to select contours and plan pattern layouts, thereby gaining ideas for their paper-cutting designs.}
\end{figure*}

\subsection{Ideation Component}
Based on the paper-cutting design space we summarized, which includes taxonomies of ideation factors and the pattern, along with annotation information from 140 works grounded in this design space, we leverage the robust language understanding and reasoning capabilities of GLM-4~\cite{Teamglm:2024:chatglm}, an LLM that supports the construction of specific knowledge bases. By integrating these annotations, 140 paired question-answering prompt templates derived from these annotations, and the design space as domain knowledge for the model's few-shot learning, users can input their preliminary design intent in text and specify the design factor types that meet their needs (\autoref{figure2}). This enables the system to initially provide content recommendations, knowledge, and interpretations derived from both the model and annotations, based on the user's input within the context of our design space. For example, if a user selects the expression method ``\textit{symbolism,}'' HarmonyCut not only suggests relevant objects and patterns but also provides their symbolic meanings, allowing users to verify alignment with their intent. This approach ensures coherence between form and connotation. It not only facilitates the development of users' design ideas but also deepens their understanding of valuable connotative insights. Through a three-step exploration process including factor selection, suggested content, and knowledge exploration, users ultimately form a textual description of ideas.

\subsection{Composition Component}
The composition component aims to guide the user to explore the reference and translate the user's conceptual idea into visual form with a mood board. It encompasses three fundamental stages: related content selection, interested and inspired content arrangement, and cut-out area layout.  All elements in the mood board are presented in SVG format, enabling flexible configuration and editing, including operations such as grouping, flipping, and copy-pasting, which accommodate user preferences and design needs.
\subsubsection{Selection} 
% To retrieve related paper-cuttings as references, we employed the Chinese version of CLIP~\cite{Yang:2023:chineseclip, Radford:2021:clip}, which was initially pre-trained on approximately 2 million text-image pairs. We further fine-tuned this model using our annotated dataset of 4031 text-image pairs, derived from 140 annotated paper-cuttings as detailed in \autoref{sec:content}. Following 30 epochs of training with 80\% of the dataset, and validation on the remaining 20\%, the fine-tuned Chinese CLIP achieved recall@1 of 63.46\%, recall@5 of 87.24\%, and recall@10 of 94.93\%. These metrics demonstrate that the model effectively maintains the relevance between idea descriptions and paper-cutting references.
% To generate images that are more rational and reflective of the Chinese paper-cutting style using DALL-E-3, prompts can be automatically generated from carefully crafted templates \wang{TODO} or edited by the user to include more specific requirements. All paper-cutting works, including both retrieved and generated content, are displayed within the same panel to facilitate user exploration.
To ensure the quality of paper-cutting references, we employed advanced multi-modal models for retrieval and generating, enabling the system to maintain and reflect the intricate style and thematic relevance of Chinese paper-cutting.
To retrieve related paper-cuttings as references, we used the Chinese version of CLIP~\cite{Yang:2023:chineseclip, Radford:2021:clip}, initially pre-trained on approximately two million text-image pairs. We fine-tuned this model using our annotated dataset of 4,031 text-image pairs, derived from 140 annotated paper-cuttings as detailed in \autoref{sec:content}. Following 30 epochs of training with 80\% of the dataset and validation on the remaining 20\%, the fine-tuned Chinese CLIP achieved recall@1 of 63.46\%, recall@5 of 87.24\%, and recall@10 of 94.93\% on the validation set. These metrics demonstrate that the model effectively maintains the relevance between idea descriptions and paper-cutting references. \revisedtext{To prevent cognitive overload and enhance user navigation within the exploration process, HarmonyCut is designed to retrieve the top 20 most relevant paper-cuttings as references.}
To generate images that are more rational and reflective of the Chinese paper-cutting style using DALL-E-3, prompts can be automatically generated from a carefully crafted template based on object requirements or be edited by the user to include more specific requirements. All paper-cutting works, including both retrieved and generated content, are displayed within the same panel as shown in \autoref{figure3} (c) to facilitate user exploration.

\subsubsection{Arrangement} % SAM
Upon exploring and selecting idea-related references, the composition stage necessitates the precise spatial arrangement of paper-cutting contours. Segment Anything Model (SAM)~\cite{Kirillov:2023:sam}, with its visual prompt points, enables the accurate segmentation of these contours, allowing users to extract content effortlessly. HarmonyCut provides the functionality for users to click on objects and backgrounds, using two labels to prompt segmentation according to their preferences, which is illustrated in the \textit{``contour segmentation''} of \autoref{figure3}. Then, all extracted contours, whether used as design material for combination or as design reference to inspire ideas, are converted into SVG format to facilitate subsequent interactions, and they are compiled within HarmonyCut's central mood board, enabling users to explore various potential combinations of the selected content.


\begin{figure*}[!htbp]
\centering
\includegraphics[width=\textwidth]{Images/detailed_system.pdf}
\caption{\label{figure:detail system}
The detailed process of design with each view and result in HarmonyCut. (a) The idea description from the former ideation. (b.1) The reference generation view based on the prompt; (b.2 and b.3) the contour segmentation view for the selected references and their contours; (b.4) cut-outs from original or other paper cuttings used in the design. (c) The final design is displayed on the mood board.}
\Description{This Figure shows the detailed process of design with each view and result in HarmonyCut. (a) The idea description from the former ideation. (b.1) The reference generation view based on the prompt; (b.2 and b.3) the contour segmentation view for the selected references and their contours; (b.4) cut-outs from original or other paper cuttings used in the design. (c) The final design is displayed on the mood board.}
\end{figure*}

\subsubsection{Cut-out Area} % VIT classification and opencv for pattern extraction
As key elements of paper-cutting, these patterns contribute to the unique symbols and styles characteristic of this hollowed-out art form. Each individual varies in the types of patterns used, as well as the density and intricacy in depicting textures, light, and lines. Therefore, the design of pattern layouts is particularly important, as it represents the designer's own unique style.
To effectively plan cut-out areas, it is crucial to extract patterns from paper-cuttings and provide users with insights akin to those offered in the ideation component, where an LLM interprets suggested composite patterns. This requires two primary preprocessing tasks: unit-pattern extraction and classification, which is shown in \autoref{figure2}.
In the preparation of unit patterns for paper-cutting design, we begin by extracting these patterns as masks using OpenCV\footnote{\url{https://github.com/opencv/opencv}}. These masks are then converted into SVG format, which facilitates the subsequent integration of contours and unit patterns. This process is vital for recognizing and employing the basic elements that contribute to composite patterns. Unlike standalone designs, these elements emphasize the content and texture of paper-cutting works. By utilizing SVG-formatted patterns, the system ensures the preservation of the unique symbols and styles inherent to this hollowed-out art form.
To improve pattern recognition and utilization, we fine-tuned the Vision Transformer (ViT)~\cite{Dosovitskiy:2021:vit} with 1,279 annotated unit patterns and labeled all 63,452 unit patterns from 140 paper-cuttings. This resulted in achieving 71\% precision, 60.43\% recall@1, and an F1 score of 63.20\% on the validation dataset, thereby enhancing the model's ability to effectively identify patterns and support the overall design process.
% To effectively plan cut-out areas, it is essential to extract patterns from paper-cuttings and provide users with an understanding similar to the ideation component, where an LLM interprets suggested composite patterns. Consequently, two main preprocessing tasks are necessary: unit-pattern extraction and classification.
% In preparing unit patterns for paper-cutting design, we first extract these patterns as masks using OpenCV. These masks are converted into SVG format, facilitating the subsequent combination of contours and unit patterns. This step is essential for recognizing and utilizing the fundamental elements that contribute to composite patterns, which, unlike standalone designs, highlight the content and texture of paper-cutting works. By employing these SVG-formatted patterns, the system preserves the unique symbols and styles integral to this hollowed-out art form.
% For enhanced pattern recognition and utilization, we fine-tuned the Vision Transformer (ViT)~\cite{Dosovitskiy:2021:vit} using 1279 annotated unit patterns from 140 paper-cuttings and reach the 71\% precision and 60.43\% recall@1, 63.20\% F1 on validation dataset.

% % This enables effective pattern identification, supporting the overall design process. By integrating these elements, HarmonyCut ensures a cohesive and culturally resonant design outcome, facilitating user exploration and creativity within the paper-cutting domain.\

\subsection{User Scenario}
In HarmonyCut, the components aligned with the design workflow and the goals are arranged within a three-panel interface, with the primary mood board centrally positioned, as illustrated in~\autoref{figure3}. \revisedtext{To demonstrate our system, we present a scenario~\cite{Fulton:2000:usagescenario, Kraft:2012:usagescenario} involving a persona, Tom, a paper-cutting enthusiast who is skilled in cutting but less experienced in composition.} Tom uses HarmonyCut to generate ideas and translate them into visual representations for his design task. With the ``Spring Art Exhibition'' approaching at his school, he hopes to leverage HarmonyCut to design a paper-cutting-themed piece called ``Welcoming Spring'' and improve his composition skills.

\subsubsection{Guide User Ideation with Suggestion}
To get some ideas from our system, Tom first input his rough intent of design as ``\textit{paper-cutting with meaning of welcoming spring}'', function as \textit{evoking a festive atmosphere}, subject matter as \textit{flora and fauna}, style as \textit{abstract}, and expression method as \textit{symbolism} to system in~\autoref{figure3} (a.1). HarmonyCut displays objects and patterns related to his intent, including peony, magpie, butterfly, Phoenix, etc. (\autoref{figure3}~(a.2)), as well as the background, structure, common combinations with other patterns, and their corresponding meanings for each recommended pattern. Among the recommended options, Tom still believed that the magpie and peony, two of the most commonly used elements, best suit the design theme. He realized that with this subject, creativity will largely depend on the composition, which is his weak point. Therefore, he prefers to explore others' compositions to guide his design. He then finalized the editable idea description (\autoref{figure3}~(a.3)) and clicks the ``Confirm'' button.

\subsubsection{Exploration on Related Design Reference}
As Tom confirmed his final idea description, the Reference Exploration panel (\autoref{figure3}~(c)) provides two parts of related paper-cutting suggestions, including retrieved and generated paper-cuttings from models.
% 一1： c.1, c.3,  + find composition reference (two symmetric birds and a potted flower), 
% 同时，Tom还在这些reference中看到一幅对称的雏鸡剪纸，这激发了他将雏鸡剪纸与盆花喜鹊剪纸结合的灵感，通过富有新鲜活力的小生命来表达春天的到来，因此这幅雏鸡剪纸也被选中。
% 二1： c.2 - c.3. 设计感很足，但Tom更在前一步选择的是抽象风格，可是模型总是给出的是国画风格或写实风格，即使他尝试调整了输入的prompt，不过他们的构图都很有趣，所以Tom将两个DALL-E-3生成的内容用SAM 扣下来以后放到mood board里做参考。
% 三1：另外， Tom 认为 选中的鸟轮廓、羽毛以及眼睛的的纹样使用太过简单，因此又从其他作品中提取了其他形态的锯齿纹，
In \autoref{figure3}~(c.1) view, Tom first found a reference that inspired him on how to structure his composition (two symmetrical birds and a potted flower, as shown in~\autoref{figure2}~(B)). Thus, he explores other magpies and potted flowers as the composition elements. 
Meanwhile, Tom also came across a symmetrical baby chicken paper-cutting \autoref{figure2}~(B) among the suggestions, which inspired him to combine the baby chicken design with the potted flower and magpie paper-cutting. He envisioned using the fresh, lively image of the baby chicken to symbolize the arrival of spring. As a result, this baby chicken paper-cutting was also selected.
Then, Tom browsed paper-cutting images generated by DALL-E-3~(\autoref{figure3}~(c.2) and \autoref{figure:detail system}~(b.1)). Although these images had a strong traditional style and sense of design, Tom had selected an \textit{abstract} style and \textit{paper-cutting image} in the ideation stage, the model kept generating images in traditional Chinese painting or realistic styles, even after he tried adjusting the input prompts. Nevertheless, he found the compositions of these images quite interesting, particularly the idea that “\textit{peonies are blossoming on the back of the magpie.}”
Additionally, Tom felt that the patterns used in the magpie paper-cutting (\autoref{figure3}~(c.4)) he selected—such as the contours, feathers, and eyes—were too simplistic. As a result, he extracted various sawtooth patterns from other retrieved works (\autoref{figure:detail system}~(b.4)).

\subsubsection{Mood Board with Contour and Cut-out}
% 一2：then,  copy and flip the select magpie and put them on another potted flower, to express the spring coming with a positive and energetic vitality, two 小鸡 in retrieved paper-cutting are selected them.
% 二2：参考了 genAI图里的鸟上背花的灵感，Tom也将4个锯齿纹组成的梅花纹放到右边的喜鹊身上。
% 三2：并进行修改组合后，分别放到两只鸟的轮廓中。

% Tom根据他在前一步探索到的reference，首先用SAM 最为灵感来源的剪纸和要作为构图元素的剪纸轮廓都分割下来放到mood board 的canvas上。然后，按照提供他构图灵感的作品，他将自己选取的喜鹊复制并反转，然后将两只喜鹊对称置于另一个盆花剪纸上。并将之前选中的对称小鸡剪纸的轮廓至于整个设计图的底部。
% 对于剪纸设计的纹样，Tom参考了生成图里鸟上生花的灵感，他从其他在c.1中剪纸作品的将锯齿纹提取出来，选择了4个锯齿纹组成梅花纹样，放到了右边的喜鹊身上。
% 最后，在将所有想添加的纹样布置完成后。就得到了b.1中的final design.

Based on the references Tom explored in the previous step, he first used SAM by adding visual prompts to segment both the paper-cutting that served as his source of inspiration and the paper-cutting contours he wanted to use as compositional elements~(\autoref{figure:detail system}~(b.2-3)). He placed these onto the mood board canvas. Following the composition of the reference artwork that inspired him, he duplicated and flipped the magpie he selected, symmetrically positioning the two magpies over another potted flower paper-cutting. He then placed the contour of the symmetrical baby chicken paper-cutting, previously selected, at the bottom of the entire design.
For the patterns in the paper-cutting design, Tom drew inspiration from the generated images where flowers blossom on birds. He extracted the sawtooth patterns from other paper-cutting works in~\autoref{figure:detail system}~(b.4), selecting four sawtooth patterns to form a plum blossom pattern, which he placed on the right magpie~(\autoref{figure3}~(c.1)).
Finally, after arranging all the patterns he wanted to add, he completed the final design, shown in~\autoref{figure3}~(b.1).

\subsection{Implementation Details}
Our system utilizes a Flask\footnote{\url{https://flask.palletsprojects.com}}-based back-end, integrated with the GLM-4 APIs for text processing and DALL-E-3 for paper-cutting image generation. The front-end is built using Vite + Vue, with additional support from Element Plus for UI components, Pinia for state management, and Tailwind CSS for styling.
A fine-tuned CLIP model for multi-modal retrieval, ViT-base-16 and RoBERTa-wwm-base are used for visual and text encoding.
For image segmentation, we extended the segment-anything-web UI\footnote{\url{https://github.com/Kingfish404/segment-anything-webui}} framework, which enables extraction and manipulation of image components. The backend supports the use of SAM-ViT-base\footnote{\url{https://github.com/facebookresearch/segment-anything}}~\cite{Kirillov:2023:sam} by default, with flexible configurations for alternative models.
Additionally, a fine-tuned pre-trained ViT (ViT-base-16, pre-trained on ImageNet-21k) is employed for unit-pattern classification.
The frontend supports dynamic SVG manipulation and bitmap-to-SVG conversion using Fabric\footnote{\url{https://fabricjs.com/}} and Potrace\footnote{\url{https://potrace.sourceforge.net/}} libraries. We also implemented custom features such as object dragger and pattern editor, integrated with the overall canvas design interface. \rrtext{The related datasets, comprising 140 paper-cutting images, 4,031 text-image pairs for fine-tuning the multi-modal retrieval model and 1,279 annotated images for fine-tuning the unit pattern recognition model, are detailed in the supplementary material.}