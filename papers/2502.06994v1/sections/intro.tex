


\section{Introduction}
\label{Section: Introduction}


\begin{figure}[H]
\begin{center}
\begin{small}
    \vspace{-0.3em}    % Adjust vertical spacing before figure if needed
    \includegraphics[width=1\linewidth]{sections/figs/figure1.png}
    \vspace{-1.8em}  % Reduces space below the figure
    \caption{
    \small
    \textbf{The \textit{Out-of-Sync} Challenge.} At \colorbox{fig1_pass}{\textcolor{fig1_white}{$\mathbf{T}_{\bm{i}}$}}, \textcolor{fig1_agent}{\textbf{Agent}} and \textcolor{fig1_human}{\textbf{Human}} work on respective tasks. During \textcolor{fig1_agent}{\textbf{Agent}}'s task completion from \colorbox{fig1_pass}{\textcolor{fig1_white}{$\mathbf{T}_{\bm{i}}$}} to \colorbox{fig1_fail}{\textcolor{fig1_white}{$\mathbf{T}_{\bm{k}}$}}, \textcolor{fig1_human}{\textbf{Human}} updates \textbf{\textless repo\textgreater} at \colorbox{fig1_pass}{\textcolor{fig1_white}{$\mathbf{T}_{\bm{j}}$}} that \textcolor{fig1_agent}{\textbf{Agent}} is unaware of due to being occupied with its own task. This leads \textcolor{fig1_agent}{\textbf{Agent}} to become \textit{out-of-sync} at \colorbox{fig1_fail}{\textcolor{fig1_white}{$\mathbf{T}_{\bm{k}}$}} as a result of \textcolor{fig1_human}{$\bm{S_k}$} $\neq$ \textcolor{fig1_agent}{$\bm{B_k}$}.}
    \vspace{-1.5em}    % Adjust vertical spacing after figure
    \label{fig:figure 1}
\end{small}
\end{center}
\end{figure}



\begin{figure*}[!t]
\begin{center}
\begin{small}
\vspace{-0.5em}
\includegraphics[width=1\linewidth]{sections/figs/figure8.png}
    \vspace{-2em}  % Reduces space below the figure
    \caption{\textbf{Typical Causes of \textit{Out-of-Sync}.} Examples of \textit{out-of-sync} scenarios in our benchmark.}
    \label{fig:figure 8 (Typical Causes)}
    \vspace{-1.6em}
\end{small}
\end{center}
\end{figure*}









Collaborative systems---whether involving humans, AI agents, or both---boost efficiency and capabilities by combining complementary strengths.
% 
Recent advances have demonstrated impressive capabilities of AI agents in collaborative tasks~\cite{unleashing2024}, from conversational AI assistants, like ChatGPT \cite{ai_assistant_chatgpt}, Claude \cite{ai_assistant_claude}, that effectively assist users in daily problem-solving, to coding agents, like Devin \cite{ai_assistant_devin}, OpenHands \cite{OpenHands}, that can actively collaborate with humans on software development. 
% \xw{heng: consider expand background}



% However, maintaining this synchronization becomes challenging in dynamic environments where rapid changes occur while collaborators are engaged in their tasks.

% \xw{I think maybe we should move up the statement that we study software engineer in this paper to this paragraph.}
These collaborative coding agents are typically designed and evaluated in static environments where the workspace remains fixed throughout task execution~\cite{jimenez2023swe, yang2024swe}. 
% 
However, real-world collaborative software engineering (CSE) fundamentally operates in dynamic environments, where effective teamwork depends on team members \textit{maintaining synchronized awareness of workspace states}â€”a core challenge in the field~\cite{agent_alignment}.
% 
% However, \textit{dynamic} environments in real-world  often violate this assumption. 
% Software engineering is a notable example of such a dynamic environment.
% , version_control_PredictingMC, version_control_NanoVC
% they typically only consider \textit{syntactic code changes}. 
While version control systems~\cite{version_control_git} can detect surface-level code conflicts, they cannot identify semantic inconsistencies that require manual resolution. This includes scenarios where agents must resolve dependency updates, modify existing functions to align with newly imported modules, and so on (\fref{fig:figure 8 (Typical Causes)}).


% Version control systems  can only detect superficial merge conflicts in source code, requiring agents to resolve semantic conflicts and ensure logical consistency. 
% humans may execute system-level commands that create unintended side-effects impacting AI's performance, such as updating library dependencies or moving around data/code.



% it can be insufficient for human-AI collaborative software engineering scenarios \cite{OpenHands}, where humans may execute system-level commands that create unintended side-effects impacting AI's performance, such as updating dependencies or backend upgrades.
% (original) revising dependencies or upgrading packages
% \zoey{The example here makes the problem seem too trivial (even if our dataset contains many of these cases). I would imagine a case where I could be a backend developer and my AI assistant is helping me write up the front end. I want the agent to update the displayed data based on my new code, but I'm not an expert so I can't resolve all issues on my own, so I need the agent to recognize that it is out-of-sync and recover.}
% recognizing and resolving semantic inconsistencies requires sophisticated reasoning about code changes and their implications. \xw{maybe say smth like: real-world human-AI interactions as seen in Devin/OpenHands are typically not checked into version control system.}
% 
% This reveals a fundamental challenge in real-world collaboration neglected by existing systems: \textit{maintaining collaborative synchronization as the workspace evolves}.

In this work, we introduce \textbf{\textit{SyncMind}} (\Sref{Section: framework}), a framework that systematically defines the agent \textbf{\textit{out-of-sync}} problem in CSE (\fref{fig:figure 2}), where multiple collaborators frequently modify and update shared codebases.
% 
This occurs when a collaborator's belief state ($B_k$) deviates from the actual world state ($S_k$) at time $T_k$, resulting in collaboration failures due to outdated information.
% \footnote{
% \label{Footnote: Human Role}
% Simulating human-AI CSE (\fref{fig:figure 1}-\ref{fig:figure 2}), we design the \textcolor{fig1_human}{\textbf{Human}} role generalizable to both human and AI agents (\Sref{Section: LLM-simulated Collaborators}).}
Consider a human-AI collaboration scenario in~\fref{fig:figure 1}:
while an \textcolor{fig1_agent}{\textit{Agent}} implements changes based on its understanding at time $T_i$, the \textcolor{fig1_human}{\textit{Human}} modifies the codebase at $T_j$ ($T_i<T_j<T_k$). 
% 
The \textcolor{fig1_agent}{\textit{Agent}}'s subsequent update at $T_k$ becomes incompatible with the current state $S_k$ due to its outdated belief state $B_k$. 
% 
This raises the key challenge: \textit{How can collaborators effectively recognize their belief being \textit{out-of-sync} ($B_k \neq S_k$), diagnose the root causes, and recover their belief $B_k$ to match the world state $S_k$}? 
% \yy{to xuehang: please check whether my rephrased concise version match your original meaning}



% where a human
% developer collaborates with an AI agent on a shared repository: 
% during \textcolor{fig1_agent}{\textit{Agent}}'s implementation of a design ($T_i-T_k$) based on its understanding of the codebase at time $T_i$, \textcolor{fig1_human}{\textit{Human}} commits changes at $T_j$ (where $T_i<T_j<T_k$).

% \textcolor{fig1_agent}{\textit{Agent}}'s update at $T_k$, therefore, becomes incompatible with the actual codebase state ($S_k$) due to the inconsistency between its world belief ($B_k$) and $S_k$.
% This is because agent's mental model remains synchronized with the prior world state at $T_i$ rather than the updated world state at $T_j$. 
% This temporal divergence raises the fundamental concern in addressing \textit{out-of-sync}: \textit{How can collaborators effectively recognize their belief being \textit{out-of-sync} ($B_k \neq S_k$), diagnose the root causes, and recover their belief $B_k$ to match the world state $S_k$}? 

% \xw{can we consider merge the above two paragraph into one? maybe it is more clear to say it in the second paragraph that `collaborative systems were built on the assumption of static env -- but real-world is dynamic, especially software engineering. Therefore we focus on studying the collaborative in software engineering in this paper.}
% \yy{fixed now. I'm not going from a typical collabotiave setting to a special case of SE. I directly discuss the topic of CSE since it's big enough and it's major focus of this paper. }


\textit{SyncMind} facilitates multi-dimensional evaluation of collaborative coding agents: 
\begin{itemize}[noitemsep,topsep=0pt,parsep=2pt,partopsep=0pt,leftmargin=*]
\vspace{-5pt}

\item \textbf{\textit{Out-of-sync} recovery effectiveness} (\Sref{Section: Agent Recovery Capabilities}): We evaluate how agents detect and resolve state misalignments via exploring the environment and consulting fellow developers, enabling them to understand system changes and resynchronize after failures. 

% to understand system changes and get re-synchronized to correct previous failures.


\item \textbf{Collaborative tendency and effectiveness} (\Sref{Section: Collaborative Effectiveness}): We measure agents' tendency to engage in productive interactions with collaborators, a critical problem in CSE. 
% 
By analyzing the assistance seeking rate and the performance difference in independent and collaborative working settings, we measure agents' recovery effectiveness in CSE. 
% effectively agents contribute to the collective development process rather than working in isolation. 
% \yy{to xuehang: pls check the description of evaluation. I'm not sure the concrete evaluation protocol and metric.}

\item \textbf{Environmental awareness and resource allocation} (\Sref{Section: Resource Awareness}): 
We examine how agents balance independent problem-solving (\textit{i.e.,} exploring environment) with collaborative assistance. 
While excessive self-reliance in debugging can strain computational resources, over-dependence on peer support can burden collaborators through repetitive cycles of assistance requests, revisions, and testing. 
We evaluate resource allocation strategies in \textit{out-of-sync} recovery by analyzing recovery efficiency, considering computing time and expense budget.




% 

 
%  In practice, developers who rely solely on independent debugging consume computational resources, while those dependent overly on collaborator assistance without independent problem-solving create a significant burden for their colleagues through repeated cycles of help-seeking, revision, and testing.
% % 
% This presents another indispensable concern for resource-efficient collaboration: \textit{How can we build AI agents that minimize resource consumption while maintaining effective synchronization}?
\end{itemize}


% collaborator influence (\Sref{Section: Beneficial Collaborator Influence Limited By Disadvantageous Agent Initiative})
% Effectively handling \textit{out-of-sync} connects essentially to the theory of mind (ToM)---collaborators' abilities to model and reason about other's knowledge, beliefs, and intents \cite{Review_ToM_in_LLM}.
% 
% When encountering $B_k \neq S_k$ at time $T_k$, human developers typically follow two complementary paths to update $B_k$: \textbf{(1) \textit{independently explore the environment to understand changes}}; \textbf{(2) \textit{consulting fellow developers about specific updates}}.
% 
% Once having gathered sufficient knowledge, developers can re-synchronize and correct failures.



% This is particularly crucial in sustained collaborations where frequent synchronizations are necessary.



%
%%%%%%%%%% SyncMind %%%%%%%%%%
%
% To systematically address these concerns in tackling agent \textit{out-of-sync}, we develop our evaluation framework, \textbf{\textit{SyncMind}} (\Sref{Section: framework}), by simulating agent \textit{out-of-sync}
% (\fref{fig:figure 1})
% in human-AI CSE (\fref{fig:figure 2}).



% \textit{SyncMind} enables systematic measuring of agents' 
% \xw{collaborator initiative is a bit vague? maybe rephrase it as "agent's willingness to collaborate"}
%
%%%%%%%%%% SyncBench %%%%%%%%%%

Based on \textit{SyncMind}, we construct \textbf{\textit{SyncBench}} (\Sref{Section: Benchmark}), a testbed to assess agent \textit{out-of-sync} recovery in CSE.
% 
Built upon 21 \github repositories, \textit{SyncBench} simulates real-world agent \textit{out-of-sync} through commit history traversal and multi-level filtering to obtain 24,332 instances with executable testing environments.
% whose Python files and unit tests are leveraged to construct agent \textit{out-of-sync} datasets and executable testing environments.
The construction pipeline is fully open-source and scalable, enabling seamless integration with additional repositories and supporting future development of CSE agents.
% 
% Meeting necessary prerequisites, \textit{SyncBench} is scalable to accommodate custom use (\Sref{Section: Benchmark Construction}).
% \xw{what do you want to say here? SyncBench can be automatically extended to more repos? consider rephrase}
% , \textit{out-of-sync} scenarios are instantiated through extracting functions based on their associated unit tests, followed by tracing \textit{Git} history backwards to identify commits with execution failures ($B_k \neq S_k$). Each instance then goes through multi-level filtering to ensure its task quality. 
% (i.e., with \textit{Python} as the primary language, possessing necessary environment setup files and well-developed unit tests),
%
%
%
%
%
%
% \xw{Don't talk about the LLMs yet here -- introduce the dataset first, e.g., we crawled X repos, configured an executable testing environments, obtained Y samples, and briefly explain how we created these data (e.g. how we play with commit update/rollback).} 
% \xw{then as a final paragraph, say we evaluate existing LLMs on this SyncBench, we get the following results:}
% By designing novel metrics tailored for multi-dimensional evaluation of \textit{out-of-sync} recovery (\Sref{Section: Evaluation Metrics}), 
Through systematic evaluation (\Sref{Section: Evaluation Metrics}), our experiments on \textit{SyncBench} reveal fundamental patterns in existing LLM-based software agents (\Sref{Section: Experiments}):
% in agents' recovery performance, collaboration effectiveness, and resource utilization
% that generalize beyond human-AI to broader collaborative systems:

\begin{itemize}[noitemsep,topsep=0pt,parsep=2pt,partopsep=0pt,leftmargin=*]
\vspace{-5pt}

\item \textbf{\textit{Out-of-sync} recovery capabilities:} Evaluated by five metrics (\Sref{Section: Evaluation Metrics}) focusing on dissimilar aspects of agents' abilities, we observe substantial ability gaps among LLM agents that persist in their performance despite varying types of recovery actions and task complexity (\Sref{Section: Agent Recovery Capabilities}).
%
% (e.g., $SR$: from \textit{Llama-3.1-8B}'s $0.33\%$ to \textit{Claude-3.5-Sonnet}'s $33.70\%$) even with the ability to collaborate with an oracle human-simulator, \xw{what you are trying to say here? can we make it clearer?:}which persist in agents' \textit{out-of-sync} recoveries despite different recovery channels or varying task complexity (\Sref{Section: Agent Recovery Capabilities}).
%
This highlights the significance of strong multifaceted capabilities for effective \textit{out-of-sync} recoveries (\Sref{Section: Multifaceted Abilities for Effective Recoveries}).
% These gaps widen in more complex scenarios where \textit{Claude-3.5-Sonnet} maintains robust recovery ($\geq 30.94\%$) while other agents' performance degrades by over $23.07\%$ (\Sref{Section: Agent Recovery Capabilities}).

\item \textbf{Collaboration willingness and abilities:} Collaborator assistance generally improves agents' recovery performance ($0.33\% \leq \Delta_{\textit{\text{collaborator}}} \leq 5.52\%$), while its effectiveness varies significantly with agentsâ€™ collaboration willingness (\Sref{Section: Beneficial Collaborator Influence Limited By Disadvantageous Agent Initiative}) and communication abilities (\Sref{Section: Collaborative Effectiveness}-\ref{Section: Effects of Task Complexity}).
% As LLM agents exhibit their notable lack of willingness to collaborate (\textit{assistance-seeking} $\leq 4.86\%$), our investigation further reveals the positive correlation between early-stage assistance seeking and recovery success \Sref{Section: Collaborative Effectiveness}.

\item \textbf{Resource awareness and adaptive utilization:} Our experiments reveal critical limitations in agents' resource awareness and adaptive utilization to efficiently utilize available resources when provided with various temporal and financial resource constraints (\Sref{Section: Resource Awareness}).
% : (1) tripling available budget yields minimal increase in \textit{assistance-seeking} ($\leq 1.06\%$); (2) cost variations show negligible impact on strategy adjustment (\textit{solution proposals} $\leq 1.72\%$, \textit{assistance-seeking} $\leq 0.46\%$); (3) extending the total available time for recovery provides inconsistent influence on different agents ($-1.00\% \leq \Delta_\textit{Time} \leq +4.66\%$).

% Successful recoveries benefit from early-stage repository exploration. For instance, \textit{Claude-3.5-Sonnet} allocates $93.62\%$ assistance seeking and $79.03\%$ \textit{Env} interaction in the first $50\%$ time among all success recoveries.

\end{itemize}


% \xw{please cite and discuss existing collaborative system: e.g., AI assistant like chatGPT and claude with tool usage, AI agents like Devin and OpenHands that can work with human on a particular software engineering task.}

% \chihan{should we better motivate by saying that current systems haven't considered syncing instead of saying they are challenging (which raises the question of how current systems perform)?}
% 

% \xw{i think we can probably make this more succint, but not urgent to do it now.}

% The \textit{out-of-sync} problem represents a fundamental challenge in collaborative work: collaborators must not only maintain accurate modeling of the workspace state, but also reason about potential divergences between their own mental models and those of their collaborators.

% \xw{this is something similar to merge conflict, consider cite some related work from SE that've worked on this problem before: search here: \url{https://openscholar.allen.ai/}} 
% \xw{I think we should expand a little bit here: As human developer, to recover from this out-of-sync scenario, we typically try to understand understand the situation via one of these methods: (1) explore the codebase ourselves, try to understand the changes, and (2) just ask fellow developer about their changes. Once we understood everything, we went ahead and made changes to our codebase. consider talk about this with (1) below.}




% \begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt,leftmargin=18pt]
% \item[(1) ] \textit{Detection and Recovery from Out-of-Sync States}: Unlike the static environment assumption in most existing work, real-world collaborative environments are dynamic, where the workspace can change while a collaborator is engaged in a task. This temporal divergence creates a critical challenge: How can collaborators efficiently detect when their belief state has become \textit{out-of-sync} ($B_{T} \neq S_{T}$) and effectively recover to $S_{T}$?

% \item[(2) ] \textit{Resource-Aware Synchronization}: \xw{this needs to be better motivated and connected to the previous point: Even though a human/AI developer can recover by interaction with environment (e.g., explore code base by themselves) OR keep ask fellow human developer, we don't really like a fellow developer that does no independent thinking, but instead keep asking questions. Therefore `How can collaborators minimize resource consumption while maintaining effective synchronization? ' is an important problem} Recovery from \textit{out-of-sync} states requires various resources---time spent in exploring changes, cognitive effort in understanding updates, computational costs for execution and validation, etc. This raises an important question: How can collaborators minimize resource consumption while maintaining effective synchronization? This is particularly crucial in sustained collaborations where frequent synchronizations are necessary.
% \end{itemize}



% \xw{instead of using bullet, i'd suggest weave these content together into two paragraph with one running example (e.g., figure 1), and walk through it: out of sync happens, how we can recover (2 methods), why it matters to account in resource usage for these recovery}











% Investigating these challenges, we introduce our evaluation framework (\Sref{Section: framework}) and agent \textit{out-of-sync} benchmark (\Sref{Section: Benchmark}), focusing on state-of-the-art (SOTA) LLMs to study agent \textit{out-of-sync} recovery in collaborative software engineering.
% 
% While our findings have implications for human-human, human-agent, and general multi-agent collaboration, LLM agents provide an ideal testbed given their tractable belief states $B_T$ and controllable experimental conditions. \xingyao{suggest remove this}
% Our benchmark and framework enable systematic evaluation of:
% \begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt,leftmargin=18pt]
%     \item Out-of-sync recovery capabilities and resource sensitivity of various SOTA LLM agents, providing insights into fundamental synchronization strategies;
%     \item Detection and recovery mechanisms through both autonomous exploration and interactive communication, applicable across different collaborative contexts;
%     \item Resource utilization patterns and their impact on recovery success, revealing general principles for efficient synchronization;
%     \item The role of proactive high-quality communication in facilitating efficient recovery, with implications for improving diverse collaboration scenarios.
% \end{itemize}

% \xw{consider re-write these three paragraphs follow the new proposed order in the abstract. Consider shrink these result down as well - see abstract for suggestion.} 

% Through extensive experiments on our benchmark, we evaluate seven SOTA LLM agents across 300 diverse collaboration scenarios derived from 21 popular GitHub repositories. Our experiments and findings reveal fundamental patterns in re-synchronization success, communication effectiveness, and resource utilization that generalize beyond LLM agents to broader collaborative systems:

% \begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt,leftmargin=18pt]
%     \item \textbf{Out-of-sync Recovery Capabilities:} We observe substantial performance gaps among different LLM agents that highlights the significance of superior technical capabilities in maintaining collaborative synchronization. \textit{Llama-3.1} agents show limited recovery capabilities ($<3.33\%$), with \textit{Llama-3.1-8B} notably underperforming ($<1.33\%$) than other LLM agents. In contrast, \textit{Claude-3.5-Sonnet} achieves $33.70\%$, demonstrating more sophisticated detection and recovery strategies. This performance gap widens in complex scenarios involving dependency tracing, where \textit{Claude-3.5-Sonnet} maintains robust recovery ($>38.67\%$) while other agents' performance degrades by over $23.07\%$.
%    \item \textbf{Collaboration and Communication Patterns:} While collaborator assistance generally improves \textit{out-of-sync} recovery performance (+$\Delta_{\textit{\text{collaborator}}}: 0.33\%-5.52\%$), the effectiveness varies significantly with LLM agentsâ€™ collaboration willingness and communication abilities. Never exceeding $5\%$ proactive assistance seeking, LLM agents exhibit their lack of willingness to collaborate, despite strategic communication. For example, \textit{Claude-3.5-Sonnet}, with $4.86\%$ assistance seeking, achieves higher gains (+$\Delta_{\textit{\text{collaborator}}}>5.52\%$). Our investigation further reveals the positive correlation between early-stage assistance seeking and recovery success.
%    \item \textbf{Resource Awareness and Strategic Utilization:} Our experiments reveal critical limitations in agents' resource management capabilities through varying resource constraints: (1) tripling the available budget yields minimal increase in assistance-seeking ($<1.07\%$); (2) cost variations ($\pm50\%$) show negligible impact on strategy adjustment (solution proposals$<0.67\%$, proactive collaborations$<2.30\%$); (3) Successful recoveries benefit from early-stage repository exploration. For instance, \textit{Claude-3.5-Sonnet} allocates $93.62\%$ assistance seeking and $79.03\%$ \textit{Env} interaction in the first $50\%$ time among all success recoveries.
% \end{itemize}



% Our findings highlight a crucial gap in current LLM architectures: while technically capable, they lack both willingness to proactively collaborate with collabrators and inherent resource-sensitivity alignment, which are particularly critical in collaborative scenarios where effective coordination and efficient resource utilization directly impact sustained performance.



\begin{figure*}[!t]  % [!t] places it at top of the page
\begin{center}
\begin{small}
    \vspace{-0.2em}    % Adjust vertical spacing before figure if needed
    \centering
    \includegraphics[width=1\textwidth]{sections/figs/figure2.png}
    \vspace{-1.8em}  % Adjust vertical spacing before caption
    \caption{\textbf{\textit{SyncMind} for Measuring Agent \textit{Out-of-Sync} Recovery.} Depending on agentâ€™s initiative, an agent updates its world belief ($B_2 \to B_n$) by \textcolor{fig2_env}{\textbf{interacting with \textit{Env}}}, \textcolor{fig2_code}{\textbf{proposing solutions}}, and \textcolor{fig2_ask}{\textbf{seeking collaborator assistance}}.}
    \label{fig:figure 2}
    \vspace{-1.2em}
\end{small}
\end{center}
\end{figure*}



% we collaborate w/ agent to solve more challenging tasks - agent's proactive interaction capability would be important.



% % 
% Contributions:
% \begin{itemize}
%     \item Define out-of-sync problem: e.g., how to recover from out-of-sync state via environment \& proactive interaction (human-AI collaboration)
%     \item Build dataset that measures out-of-sync
%     \item Design metrics to measure the ability to recover from Out-of-Sync. Environment-only, Mixed environment + human.
% \end{itemize}

% Measurement: 

% \xingyao{one paragraph to describe framework in detail, dataset, and metrics}
% targeting at human-AI collaborative code generation 




% \xingyao{one paragraph to describe results from experiments}



% (optional) Also, making these AI agents resource-aware (e.g., time, cost) is another important topic.

% As AI agents become increasingly powerful, they likely become more involved in humans' existing day-to-day workflow. 
% For example, an AI agent may help human developers write unit tests to test humans' code while humans working on it.
% However, an important issue arises from human-AI collaboration:  



