\documentclass[lettersize,journal]{IEEEtran}
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{array}
% \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
% \usepackage{caption}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{pifont}
\usepackage{blindtext}
\usepackage{hyperref}
\usepackage{diagbox}
\usepackage{bbding}
\usepackage{amsthm}
\usepackage{makecell}
\usepackage{algpseudocode}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{pifont}
\usepackage{mathtools}
\usepackage{tabularx}
\usepackage[table]{xcolor}
\definecolor{customblue}{HTML}{BDD7EE}
\definecolor{deepblue}{HTML}{0070C0}
\usepackage{colortbl}
% \hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}

\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{tikz}
\newcommand*\emptycirc[1][1ex]{\tikz\draw (0,0) circle (#1);} 
\newcommand*\halfcirc[1][1ex]{%
	\begin{tikzpicture}
	\draw[fill] (0,0)-- (90:#1) arc (90:270:#1) -- cycle ;
	\draw (0,0) circle (#1);
	\end{tikzpicture}}
\newcommand*\fullcirc[1][1ex]{\tikz\fill (0,0) circle (#1);}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
% \newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}{Assumption}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{proposition}{Proposition}
\newtheorem*{proposition*}{Proposition}

\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021

% \hypersetup{
%   colorlinks   = true,    % Colours links instead of ugly boxes
%   urlcolor     = blue,    % Colour for external hyperlinks
%   linkcolor    = blue,    % Colour of internal links
%   citecolor    = blue      % Colour of citations
% }
\hypersetup{
  colorlinks   = true,    % Colours links instead of ugly boxes
  urlcolor     = deepblue,    % Colour for external hyperlinks
  linkcolor    = deepblue,    % Colour of internal links
  citecolor    = deepblue      % Colour of citations
}

\newcommand{\name}{\texttt{EGGV}\xspace}

\begin{document}

\title{The Gradient Puppeteer: Adversarial Domination in Gradient Leakage Attacks through Model Poisoning}

\author{Kunlan~Xiang,
        Haomiao~Yang,~\IEEEmembership{Senior Member,~IEEE,}
        Meng Hao,~\IEEEmembership{Member,~IEEE,}
        Shaofeng Li,~\IEEEmembership{Member,~IEEE,}
        Haoxin Wang,
        Zikang Ding,
        Wenbo Jiang,~\IEEEmembership{Member,~IEEE,}
        Tianwei~Zhang,~\IEEEmembership{Member,~IEEE,}
        % and~Hongwei~Li,~\IEEEmembership{Fellow,~IEEE}

    \IEEEcompsocitemizethanks{
        \IEEEcompsocthanksitem K. Xiang, H. Yang, Z. Ding, and W. Jiang
        % , and H. Li
        are with the School of Computer Science and Engineering, University of Electronic Science and Technology of China. E-mail: klxiang@std.uestc.edu.cn; haomyang@uestc.edu.cn; dzkang0312@163.com; wenbo\_jiang@uestc.edu.cn.
        % hongweili@uestc.edu.cn.
        \IEEEcompsocthanksitem M. Hao is a research scientist at Singapore Management University. E-mail: menghao303@gmail.com.
        \IEEEcompsocthanksitem S. Li is an assistant professor at the School of Computer Science and Engineering at Southeast University. E-mail: shaofengli2013@gmail.com.
        \IEEEcompsocthanksitem H. Wang is with the Sichuan University. E-mail: whx1122@stu.scu.edu.cn.
        \IEEEcompsocthanksitem T. Zhang is with the School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798. E-mail: tianwei.zhang@ntu.edu.sg.
        \IEEEcompsocthanksitem Corresponding author: Haomiao Yang.
        % \IEEEcompsocthanksitem
        \IEEEcompsocthanksitem This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.
    }      
}

% <-this % stops a space
% \thanks{This paper was produced by the IEEE Publication Technology Group. They are in Piscataway, NJ.}% <-this % stops a space
% \thanks{Manuscript received April 19, 2021; revised August 16, 2021.}

% The paper headers
% \markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2021}%
% {Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}

% \IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\begin{abstract}
In Federated Learning (FL), clients share gradients with a central server while keeping their data local. However, malicious servers could deliberately manipulate the models to reconstruct clients' data from shared gradients, posing significant privacy risks. Although such active gradient leakage attacks (AGLAs) have been widely studied, they suffer from two severe limitations: (i) coverage: no existing AGLAs can reconstruct all samples in a batch from the shared gradients; (ii) stealthiness: no existing AGLAs can evade principled checks of clients. In this paper, we address these limitations with two core contributions. First, we introduce a new theoretical analysis approach, which uniformly models AGLAs as backdoor poisoning. This analysis approach reveals that the core principle of AGLAs is to bias the gradient space to prioritize the reconstruction of a small subset of samples while sacrificing the majority, which theoretically explains the above limitations of existing AGLAs. Second, we propose \underline{E}nhanced \underline{G}radient \underline{G}lobal \underline{V}ulnerability (EGGV), the first AGLA that achieves complete attack coverage while evading client-side detection. In particular, EGGV employs a gradient projector and a jointly optimized discriminator to assess gradient vulnerability, steering the gradient space toward the point most prone to data leakage. Extensive experiments show that EGGV achieves complete attack coverage and surpasses state-of-the-art (SOTA) with at least a 43\% increase in reconstruction quality (PSNR) and a 45\% improvement in stealthiness (D-SNR).
\end{abstract}
\begin{IEEEkeywords}
Federated learning, gradient leakage attack, model poisoning, and malicious attack.
\end{IEEEkeywords}


\section{Introduction}
\input{tex/introduction}

\section{Related Work}
\label{sec:related-work}
\input{tex/related_work}

\section{Background}
\label{sec:background}
\input{tex/background}

% \section{Background}
% \label{preliminary}
% \input{preliminary}

\section{Backdoor-theoretical Analysis}
\label{sec:backdoor-analysis}
\input{tex/rethink}

\section{Enhanced Gradient Global Vulnerability}
\label{sec:EGGV}
\input{tex/method}

\section{Experimental Evaluation}
\label{sec:experiments}
\input{tex/exp}

\section{Conclusion}
\label{sec:conclusion}
\input{tex/conclusion}


%{\appendix[Experimental validation for Proposition \ref{cal_loss_yue}]
%\input{appendix}}

\bibliographystyle{IEEEtran}
\bibliography{reference.bib}
\input{tex/bio}

\end{document}


