\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}
\usepackage{enumerate}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% % Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{dsfont}

\usepackage[normalem]{ulem}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}
\usepackage{xcolor}

% Math macros:
\newcommand{\E}{\mathbb{E}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\ind}{\mathds{1}}
\newcommand{\filt}{\mathcal{F}}
\newcommand{\cond}{\ |\ }
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\TV}{\mathrm{TV}}
\newcommand{\indep}{\perp\!\!\!\perp}
\newcommand{\Lip}{\mathrm{Lip}}
\newcommand{\dif}{\mathrm{d}}

\newcommand{\std}{\mathrm{std}}
\newcommand{\ppi}{\mathrm{ppi}}
\newcommand{\imputed}{\mathrm{imputed}}
\newcommand{\batch}{\mathrm{batch}}

\newcommand{\Sloppy}[1]{\textcolor{red}{#1}}

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
% \icmltitlerunning{Anytime-Valid Active Prediction-Powered Inference}
\icmltitlerunning{Prediction-Powered E-Values}

\begin{document}

\twocolumn[
\icmltitle{Prediction-Powered E-Values}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Daniel Csillag}{emap}
\icmlauthor{Claudio Jos√© Struchiner}{emap}
\icmlauthor{Guilherme Tegoni Goedert}{emap}
\end{icmlauthorlist}

\icmlaffiliation{emap}{School of Applied Mathematics, Getulio Vargas Foundation, Rio de Janeiro, Brazil}

\icmlcorrespondingauthor{Daniel Csillag}{daniel.csillag@fgv.br}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML, E-values, Prediction-Powered Inference, Statistical Inference, Distribution-Free Methods}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
    Quality statistical inference requires a sufficient amount of data, which can be missing or hard to obtain.
    To this end, prediction-powered inference has risen as a promising methodology, but existing approaches are largely limited to Z-estimation problems such as inference of means and quantiles.
    In this paper, we apply ideas of prediction-powered inference to e-values.
    By doing so, we inherit all the usual benefits of e-values -- such as anytime-validity, post-hoc validity and versatile sequential inference -- as well as greatly expand the set of inferences achievable in a prediction-powered manner.
    In particular, we show that every inference procedure that can be framed in terms of e-values has a prediction-powered counterpart, given by our method.
    We showcase the effectiveness of our framework across a wide range of inference tasks, from simple hypothesis testing and confidence intervals to more involved procedures for change-point detection and causal discovery, which were out of reach of previous techniques.
    Our approach is modular and easily integrable into existing algorithms, making it a compelling choice for practical applications.
\end{abstract}

% TLDR: We apply prediction-powered inference to e-values, vastly expanding the set of inference tasks achievable in a prediction-powered manner while also benefiting from the usual virtues of e-values.

\section{Introduction} \label{sec:introduction}

Statistical inference is ubiquitous in many critical areas of application, such as medicine and economics.
Central to their use is the availability of moderate amounts of data to empower our inferences. However, such data can be expensive to obtain, which complicates matters.

A common strategy is to simply collect a smaller amount of data, in order to minimize costs. Unfortunately, this generally leads to more uncertain inferences.
Alternatively, there are methods that leverage auxiliary cheap-to-obtain data to `compensate' for the missing expensive data. Classical works in this direction include single imputation and multiple imputation methods \cite{little-missing-data}, but they generally lack any strong guarantee of correctness.
More recently, \cite{ppi} proposed prediction-powered inference, which allows for versatile procedures that benefit from strong correctness guarantees, notably including unbiasedness and type-I error control under very light assumptions.

At its heart, the idea of prediction-powered inference is simple: we leverage a predictive model (which can be arbitrarily complex, e.g., large neural networks) to predict the expensive data from the cheap data.
We can then use our whole dataset to perform our inference by imputing missing expensive data with predictions from our model, while leveraging the available expensive data to quantify our model's inaccuracies, debiasing our inference.

Prediction-powered inference has already inspired a large amount of literature, both methodology-wise (e.g., \cite{active-ppi,ppi-pp,ppi-cv,ppi-local}), as well as in applications such as language model evaluations \cite{ppi-llm-ranking,ppi-model-evaluation}, genome-wide association studies \cite{ppi-genomewide} and more.
However, throughout, the inference tasks considered are fairly limited;
previous works are essentially restricted to problems that can be framed in terms of Z-estimation,\footnote{A Z-estimation problem is one in which we seek to infer a parameter $\theta^\star \in \Theta$ such that $\E_Z[\psi(Z; \theta^\star)] = 0$, for some known function $\psi$.} which includes many common tasks such as inference of means, quantiles and regression coefficients, but not much more.
In this paper, we significantly expand this frontier by applying prediction-powered inference to e-values.

E-values are a recent enticing alternative to p-values.
Formally, an e-value for a null hypothesis $H_0$ is a nonnegative real random variable $E$ such that, if $H_0$ holds, then $\E[E] \leq 1$; by Markov's inequality, it is then unlikely that the e-value $E$ is high under the null, and thus a high e-value ($\gg 1$) provides evidence against the null hypothesis.
Though simple, this is a very powerful notion: e-values allow for powerful procedures under very lax assumptions (e.g., not even i.i.d., nonparametric and nonasymptotic)~\cite{evalue-nonasymptotic}, naturally handle sequential and anytime-valid inference~\cite{savi}, naturally fit into multiple testing and post-selective inference \cite{e-values-ebh,e-values-post-selection-inference} and allows for significance levels to be chosen a posteriori~\cite{koning-posthoc,grunwald-posthoc} -- properties that are notoriously challenging to obtain with the more standard p-values, if not outright impossible, especially in conjunction.
Furthermore, e-values are rather universal: any e-value can be converted to a p-value by simply taking its reciprocal, and any p-value can be converted to an e-value by a process termed calibration~\cite{e-value-calibration}, albeit at a slight loss of power.

By working atop e-values, our procedure gains a great amount of versatility.
We show that \textbf{any inference procedure that operates in terms of e-values has a prediction-powered counterpart}, given by our method.
Moreover, our procedure naturally inherits all of the usual virtues of e-values, in particular including anytime-validity and post-hoc validity.
In fact, the sequential nature of our procedure further empowers prediction-powered inference methods, allowing us to arbitrarily improve our predictive model and data collection policy over the course of the inference, whereas previous methods require us to fix it a priori, or learn it from a separate data split.

We illustrate our procedure in four case studies.
First, we use it for a simple problem of estimating prevalence of diabetes on a population from readily available survey data.
Secondly, we apply our method for a problem of anytime-valid testing of the hypothesis that a deployed model's risk does not exceed a certain safety level, for the purpose of continuous risk monitoring.
We then turn to more involved inference tasks.
On the same context of continuous risk monitoring, we apply our method for detection of change-points, in which we seek to identify points in time where some aspect of the time series has changed.
Finally, we consider how our method enables powerful procedures for causal discovery under missing (costly) data.

\paragraph{Our contributions}
\begin{enumerate}
    \item We present a new method for prediction-powered inference based on e-values. Besides being applicable to a much more general setting than the ones previously considered in the literature, it inherits all the usual benefits of e-values, including sequential inference that is valid under arbitrary optional stopping and post-hoc validity. Moreover, it allows for the underlying predictive model to be updated over the course of the inference, yielding much better data efficiency compared to prior work (which require the model to be fit on a separate data split);
    \item We show how the base method can be extended from simple hypothesis testing with e-values to more involved procedures, first considering confidence intervals/sequences and then general algorithms based on e-values. In particular, we show that simply substituting the base e-values by our prediction-powered e-values yields valid prediction-powered procedures that are statistically powerful, leading to a modular and widely applicable technique.
    \item We showcase our method in four case studies ranging from simple mean estimation and hypothesis testing to change-point detection and causal discovery. This highlights the wide applicability of our approach, and we consistently note its much improved performance compared to baselines in spite of massive (often 100x-1000x) reductions in data acquisition costs.
\end{enumerate}

\section{A General Method} \label{sec:general-method}

We will first present how we can transform a standard e-value into a prediction-powered one in the context of hypothesis testing.
This mechanism can then be leveraged to transform more complex procedures powered by e-values into prediction-powered ones; we first thoroughly instantiate this for confidence sequences, and then more generally in the context of general e-value-powered algorithms.

\subsection{Hypothesis testing}

Our goal is to test some null hypothesis $H_0$, and for this purpose have a stream of data $(X_i, Y_i)_{i=1}^\infty$. The $X_\ast$ correspond to `cheap' data that we will always have access to, while the $Y_\ast$ correspond to data that is expensive to obtain, and as such we have little access to -- but, ultimately, the hypothesis we want to test is over the distribution of the $Y_\ast$.s

Data acquisition costs aside, a sound approach to perform such a hypothesis test is to leverage an e-value $E_n$ -- i.e., a nonnegative random variable that is a function of the first $n$ data points, such that under the null $H_0$ it holds that $\E[E_n] \leq 1$.
In particular, we consider e-values of the form
\begin{equation}\label{eq:prod-evalue}
    E_n := \prod_{i=1}^n e_i (Y_i),
\end{equation}
where $(e_i)_{i=1}^\infty$ is a predictable sequence of the `components' of the e-value, i.e., each $e_i$ can be arbitrarily dependent on the samples before time $i$ (but nothing else).
We will further require that the e-value's components be predictably bounded: for all $i$, $e_i (\cdot) \in [a_i, b_i]$ for some predictable sequences $(a_i)_{i=1}^\infty$ and $(b_i)_{i=1}^\infty$, and with $a_i > 0$ for all $i$.

Most e-values in the literature are already of this form (e.g., \cite{evalue-mean,evalue-twosample-1,evalue-twosample-2,evalue-ope,evalue-testtimeadapt-yaniv}), or can factored into it. The boundedness assumption can be enforced by simple rescaling and clipping, albeit at a slight loss of power.

Should we have access to \emph{perfect} models $\mu_i^\star : \mathcal{X} \to \R$, i.e., such that $\mu_i^\star(X_i) = Y_i$ almost surely,
then we could instead only use the predictions atop the cheaper data, $\mu_i^\star(X_i)$, to construct the e-value by its components:
\begin{equation*}
    E^\imputed_n := \prod_{i=1}^n e_i (\mu_i^\star(X_i)).
\end{equation*}
However, in the much more realistic scenario that the model is not perfect, $E^\imputed_n$ will not be a valid e-value.

We can, however, debias $E^\imputed_n$ as per prediction-powered inference~\cite{ppi} and active statistical inference~\cite{active-ppi}.
First, endow the data stream with additional random variables $\xi_i \sim \mathrm{Bern}(\pi_i (X_i))$ denoting whether we have access to the more expensive data $Y_i$, where $\pi_1, \pi_2, \ldots : \mathcal{X} \to [1 - a_i/b_i, 1]$ is a predictable (i.e., possibly arbitrarily dependent on data prior to $i$, but independent of all from $i$ onwards) sequence of functions that produce the probability of data collection.

With this augmented data stream $(X_i, Y_i, \pi_i, \xi_i)_{i=1}^\infty$, we can form a new `prediction-powered' sequence of e-values, with form similar to that of the active prediction-powered estimators of \cite{active-ppi}:
\begin{gather*}\label{eq:ppi-evalue}
    e^\ppi_i := e_i (\mu_i(X_i)) + \bigl[ e_i (Y_i) - e_i (\mu_i(X_i)) \bigr] \cdot \frac{\xi_i}{\pi_i (X_i)},
    \\
    E^\ppi_n := \prod_{i=1}^n e^\ppi_i,
    \qquad\quad \left( \xi_i \sim \mathrm{Bern}(\pi_i (X_i)) \right).
\end{gather*}

This construction is motivated by the fact that, conditional on all data prior to the time point $i$, the prediction-powered e-value components $e^\ppi_i$ match the non-prediction-powered ones $e_i$ in expectation:
\begin{align*}
    &\E_i\!\left[ e_i (\mu_i(X_i)) + \bigl[ e_i (Y_i) - e_i (\mu_i(X_i)) \bigr] \cdot \frac{\xi_i}{\pi_i (X_i)} \right]
    \\ &= \E_i\!\left[ e_i (\mu_i(X_i)) \right]
    \\ &\, + \E_i\!\left[ \bigl[ e_i (Y_i) - e_i (\mu_i(X_i)) \bigr] \cdot \frac{\xi_i}{\pi_i (X_i)} \cond \xi_i = 1 \right] \P_i[\xi_i = 1]
    \\ &\, + \E_i\!\left[ \bigl[ e_i (Y_i) - e_i (\mu_i(X_i)) \bigr] \cdot \frac{\xi_i}{\pi_i (X_i)} \cond \xi_i = 0 \right] \P_i[\xi_i = 0]
    \\ &= \E_i\!\left[ e_i (\mu_i(X_i)) \right] + \E_i\!\left[ e_i (Y_i) - e_i (\mu_i(X_i)) \right]
    = \E_i\!\left[ e_i (Y_i) \right].
\end{align*}
Furthermore, the boundedness of the e-values' components and on the $\pi$ ensure that the quantity is always nonnegative. Using these facts along with a backward induction argument, one can prove:
\begin{theorem}\label{thm:hypothesis-testing-valid}
    $E^\ppi_n$ is a valid e-value for the null $H_0$. \\ Additionally:
    \begin{enumerate}[(i)]
        \item If $(E_0, E_1, \ldots)$ form a test supermartingale -- i.e., a nonnegative supermartingale with $\E[E_0] \leq 1$ under the null $H_0$ -- then so is $(E^\ppi_0, E^\ppi_1, \ldots)$;
        \item More generally, if $(E_0, E_1, \ldots)$ form an e-process -- i.e., a nonnegative stochastic process such that for all stopping times $\tau$, the null $H_0$ implies that $\E[E_\tau] \leq 1$ -- then so is $(E^\ppi_0, E^\ppi_1, \ldots)$ for all finite stopping times.
    \end{enumerate}
\end{theorem}
Besides having valid e-values -- which assures us of type-I error control -- one should check whether they are efficient/powerful. We can check that, under mild assumptions, our e-process has good power in terms of the expected growth rate \cite{kelly} as long as the models $\mu_i$ match the true data $Y_i$ sufficiently well:
\begin{theorem}\label{thm:hypothesis-testing-power}
    Suppose that the $e_i(\cdot)$ are each $L_i$-Lipschitz, and that $\pi_i(X_i) \geq 1 - a_i/b_i + \epsilon_i$ for some $\epsilon_i > 0$, for all $i$. Then there exists some constant $c > 0$ independent of $n$ such that
    \begin{align*}
        \E\left[ \frac{1}{n} \log E^\ppi_n \right]
        \geq \E\left[ \frac{1}{n} \log E_n \right] - \frac{c}{n} \sum_{i=1}^n \E[ W(\mu_i(X_i) \Vert Y_i) ],
    \end{align*}
    where $W(\mu_i(X_i) \Vert Y_i)$ is the Wasserstein distance between $\mu_i(X_i)$ and $Y_i$, conditional on all else prior.
\end{theorem}

More general and precise statements are also possible, but less compact; see Theorems~\ref{thm:suppl-hypothesis-testing-power-1} in the appendix.

The sequential nature of the prediction-powered e-values -- which holds regardless of whether the original e-values were of sequential nature -- allows for an extremely versatile procedure.
For instance, in contrast to most existing prediction-powered inference procedures, we are able to update both our underlying prediction model and our data collection rule over the course of our inference process, with no restrictions other than not using future information and having to satisfy the boundedness assumptions.

The resulting algorithm for hypothesis testing is remarkably simple to implement, given its generality. The pseudocode can be found in Algorithm~\ref{alg:protocol}.

\begin{algorithm}[tb]
    \caption{Prediction-Powered E-Values}
    \label{alg:protocol}
    \begin{algorithmic}
        \STATE {\bfseries Input:} base e-value components $(e_1 (\cdot), e_2 (\cdot), \ldots)$
        \STATE {\bfseries Output:} prediction-powered e-values $(E^\ppi_0, E^\ppi_1, \ldots)$
        \STATE $E^\ppi_0 \gets 1$
        \STATE Initialize $\mu : \mathcal{X} \to \mathcal{Y}$ and $\pi : \mathcal{X} \to [1 - a_1/b_1, 1]$
        \FOR{each $i = 1, 2, \ldots$}
            \STATE Get `cheap' data $X_i$
            \STATE Sample $\xi_i \sim \mathrm{Bern}(\pi(X_i))$
            \IF{$\xi_i = 1$}
                \STATE Collect `expensive' data $Y_i$
                \STATE $E^\ppi_i \gets E^\ppi_{i-1} \cdot \frac{e_i(Y_i) - (1-\pi(X_i)) e_i(\mu(X_i))}{\pi(X_i)}$
            \ELSE
                \STATE $E^\ppi_i \gets E^\ppi_{i-1} \cdot e_i(\mu(X_i))$
            \ENDIF
            \STATE Optionally update $\pi$ and $\mu$ % using information so far
        \ENDFOR
    \end{algorithmic}
\end{algorithm}

\subsection{From hypothesis testing to confidence intervals}

With prediction-powered e-values in hand, we can easily produce prediction-powered confidence intervals/sequences by considering a family of e-values indexed by the parameter in question.

Suppose we want to produce a confidence interval/sequence for a parameter $\theta^\star \in \Theta$ of the data generating process, and consider the family of nulls $H_0^{(\theta)} : \theta^\star = \theta$, indexed by $\theta$.
For each such null, we can construct a corresponding prediction-powered e-value $E^{\ppi-(\theta)}_n$ and then consider the set
\[ C^{\ppi-(\alpha)}_n := \left\{ \theta \in \Theta : E^{\ppi-(\theta)} < 1/\alpha \right\}. \]
By the standard duality between hypothesis tests and confidence sets, it then holds that:
\begin{proposition} \label{thm:confidence-interval-valid}
    $C^{\ppi-(\alpha)}_n$ is a valid confidence interval -- i.e., $\P[\theta^\star \in C^{\ppi-(\alpha)}_n] \geq 1 - \alpha$.
    Moreover:
    \begin{enumerate}[(i)]
        \item If the underlying e-values form a nonnegative supermartingale, then the prediction-powered intervals are anytime-valid (also known as confidence sequences): $\P[\forall n \in \N,\ \theta^\star \in C^{\ppi-(\alpha)}_n] \geq 1 - \alpha$;
        \item More generally, if the underlying e-values form e-processes, then the prediction-powered intervals are valid at arbitrary stopping times: $\P[\theta^\star \in C^{\ppi-(\alpha)}_\tau] \geq 1 - \alpha$ for any stopping time $\tau$.
    \end{enumerate}
\end{proposition}
Again, we are also interested in how efficient these confidence sequences are. Just like before, as long as our predictive models are good, we get more concentrated intervals, as measured by the area under the log-p-landscape:
\begin{proposition} \label{thm:confidence-interval-power}
    Under the assumptions of Theorem~\ref{thm:hypothesis-testing-power},
    let $\nu$ be a measure over the parameter space $\Theta$. Then there exists some $c$ for which
    \begin{align*}
        \E\left[\int \frac{1}{n} \log \frac{1}{E^{\ppi-(\theta)}_n} \dif\nu(\theta)\right]
        &\leq \E\left[\int \frac{1}{n} \log \frac{1}{E^{(\theta)}_n} \dif\nu(\theta)\right]
        \\ &+ \frac{\nu(\Theta)c}{n} \sum_{i=1}^n W(\mu_i(X_i) \Vert Y_i).
    \end{align*}
\end{proposition}
These results may be mapped to the actual measure of the confidence interval, but this is nontrivial; see the Appendix.

\subsection{General e-value-powered algorithms}

Beyond simple hypothesis testing and confidence sequences, e-values can also be used as components of more elaborate inference procedures, for example in causal discovery (e.g. \cite{peters-book}), change point detection~\cite{evalue-change-point-1,evalue-change-point-2,evalue-change-point-3} and test-time adaptation~\cite{evalue-testtimeadapt-yaniv}.
Our prediction-powered e-values can also be seamlessly integrated into such procedures.

Consider that we have a family of e-values $E^{(\gamma)}_n$ for respective nulls $H^{(\gamma)}_0$, indexed by $\gamma \in \Gamma$, and our overall algorithm is of the form $\mathcal{A}((E^{(\gamma)}_n)_{\gamma \in \Gamma})$.
Moreover, our algorithm comes endowed with some `validity' property, and is such that this validity depends only on the inputted e-values being valid:
\begin{assumption}\label{assump:algo-validity}
    If $E^{(\gamma)}_n$ is a valid e-value for the null $H^{(\gamma)}_0$ for every $\gamma \in \Gamma$, then $\mathcal{A}((E^{(\gamma)}_n)_{\gamma \in \Gamma})$ is \emph{valid}.
\end{assumption}
It is then easy to show that by simply replacing the input e-values by their prediction-powered counterparts, the validity property is maintained:
\begin{proposition} \label{thm:general-algo-valid}
    Under Assumption~\ref{assump:algo-validity}, it holds that
    $\mathcal{A}((E^{\ppi-(\gamma)}_n)_{\gamma \in \Gamma})$ is also \emph{valid}.
    If the underlying e-values are e-processes, then it further holds that $\mathcal{A}((E^{\ppi-(\gamma)}_\tau)_{\gamma \in \Gamma})$ is \emph{valid} for any finite stopping time $\tau$.
\end{proposition}
It is still also of interest to consider some notion of `power' or `efficiency' of the resulting prediction-powered procedure. However, such an analysis needs to consider more of the particular algorithm in principle, and so should be done on a case-by-case basis.
Similarly, the appropriate notion of anytime-validity (which would be implied by the underlying e-values forming test supermartingales) depends on the particular definition of validity for the algorithm in question and so should be considered in a case-by-case basis. Nevertheless, the case of an e-process still holds generally.

\subsection{The Asymptotic Case}

Though typically considered in the context of nonasymptotic statistics, e-values also have asymptotic analogues \cite{asymp-evalue,evalue-book}. We focus on the main text only on nonasymptotic e-values, but our ideas directly map to the asymptotic setting just as well; see Appendix~\ref{suppl:asymptotic}.

\section{Experiments and Case Studies} \label{sec:experiments}

In this section we present four case studies where we use our method, highlighting the modifications made to the base methods in the process of prediction-empowerment.

\subsection{Estimation of a Mean: Prevalence of Diabetes from Survey Data} \label{sec:experiment-1}

In this first case study we seek to estimate the prevalence of diabetes on a cohort, upon which we work atop the dataset of \cite{diabetes-dataset}. This estimation is key to the scaling of resources in health systems, as this medical condition can be very common and very costly to treat in many populations.% https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators


Actually assessing the presence of diabetes can be somewhat costly, requiring through analysis of individual medical records.
On the other hand, we have readily available data in the form of short survey responses, consisting of simple questions such as ``do you have high blood pressure?'', ``do you have high cholesterol?'', ``have you smoked at least 100 cigarettes in your entire life?'', and so on (see Appendix~\ref{suppl:datasets} for the full list).
Considering that these questions capture health indicators that are fairly predictive of diabetes, it is appealing to leverage them in a prediction-powered manner.

More formally, we have a data stream $(X_i, Y_i)_{i=1}^\infty$ where the $X_i$ correspond to the responses to our survey questions, and the $Y_i$ correspond to a binary indicator of whether the individual is diabetic.
For the sake of evaluation, our dataset includes all $Y_i$, but in a real-world setting it would be expected that they would be largely missing; we will simulate this missingness.
Our goal is to infer the mean
\[ \text{prevalence of diabetes} = \E[\ind[Y_i = \text{diabetic}]]. \]
This is the mean of a random variable bounded in $[0, 1]$, and so we can use the e-value-based method for inference of bounded means of \cite{evalue-mean}. Our confidence interval/sequence is thus given by the set
\[ C^{(\alpha)}_n = \left\{ \theta \in [0,1] : E^{(\theta)}_n < 1/\alpha \right\}, \]
for
\begin{align*}
    E^{(\theta)}_n = \prod_{i=1}^n \biggl( 1 + \lambda_i \Bigl( \ind[Y_i = \text{diabetic}] - m \Bigr) \biggr),
\end{align*}
where $(\lambda_i)_{i=1}^\infty$ is a predictable sequence of bets bounded in $(-\frac{1}{1-\theta}, \frac{1}{\theta})$.
In particular, each $E^{(\theta)}_n$ is a test supermartingale -- and thus a sequence of e-values -- for a corresponding null $H^{(\theta)}_0 : \text{prevalence of diabetes} = \theta$ \cite{evalue-mean}.

These e-values are already in our required form of Equation~\eqref{eq:prod-evalue}, but additional care needs to be taken with regards to the bounds of the e-values' components. As-is, the components are bounded just in $[0, 1 + \max\{ \theta/(1-\theta), (1-\theta)/\theta \}]$.
This means that we would require the data collection probabilities $\pi_i(X_i)$ to be bounded in $[1, 1]$ -- i.e., we would always need to collect data; this is clearly insufficient for our purposes.

\begin{figure}
    \includegraphics[width=\columnwidth]{figures/fig1-trim.png}
    \vspace{-0.5cm}
    \caption{\textbf{Prediction-powered confidence sequences.} The plot shows the p-landscape (i.e., parameter on the x-axis, reciprocal of the e-value on the y-axis) for the confidence sequence generated by our method (green), along with those for inference using only labelled samples (purple) and by using an imputation approach. The 95\% confidence intervals for each p-landscape (i.e., region where the p-landscape is above 0.05) is shaded. Our method provides the tightest valid intervals -- using only the labelled samples or vanilla PPI \cite{ppi} yields weaker inferences, and using imputation fails to cover the true mean.} \label{fig:confseq}
\end{figure}

Fortunately, we have a direct way of controlling these bounds by the means of the bets $(\lambda_i)$.
If, instead of requiring them to be bounded in $(-\frac{1}{1-\theta}, \frac{1}{\theta})$, we require them to be bounded in $(-\frac{c}{1-\theta}, \frac{c}{\theta})$ for some $0 < c \leq 1$, then we have that the components are bounded in $[1-c, 1 + c \max\{ \theta/(1-\theta), (1-\theta)/\theta \}]$, which now leads to nontrivial bounds on the $\pi_i(X_i)$.
In particular, for any desired lower bound $\pi_{\inf}$ for $\pi_i(X_i)$, we can now solve for some $c$ for which
\begin{equation}\label{eq:truncated-bets-mean}
    1 - \frac{1-c}{1 + c \max\{ \theta/(1-\theta), (1-\theta)/\theta \}} \leq \pi_{\inf},
\end{equation}
satisfying our requirements; we use $\pi_{\inf} = 1\%$.

We then have the following methods for doing inference with a fixed labelling budget $\pi_{\inf}$:\\
$\bullet$~\textbf{Only labelled samples:} collect $\lfloor \pi_{\inf} \cdot n \rfloor$ labelled samples, and use the standard, non-prediction-powered e-values of \cite{evalue-mean} to estimate the mean. For the bets $\lambda_i$, we use the aGRAPA method proposed by \cite{evalue-mean}, bounded to $(-\frac{1}{1-\theta}, \frac{1}{\theta})$;\\
$\bullet$~\textbf{Prediction-powered (ours):} use our prediction-powered e-values method atop the e-value with bets truncated as per Equation~\eqref{eq:truncated-bets-mean}. The predictive model is updated over the course of the inference, whenever we get a new data label. For the collection probabilities $\pi_i$, we always yield $\pi_{\inf}$, the lowest possible value, in an effort to minimize data collection costs.\\
$\bullet$~\textbf{Active prediction-powered (ours):} same as the previous `prediction-powered' method, but with a different choice of collection probabilities $\pi_i$. This time, rather than opting for constant, always as low as possible, probabilities, we follow an approximately optimal choice which takes into consideration the $X_i$, as delineated in Appendix~\ref{suppl:approx-optimal-pi}. This gives an `active inference'/`active learning' flavor to our method.\\
$\bullet$~\textbf{Imputation:} we simply learn a predictive model to predict the missing $Y_i$ from the available $X_i$, and impute the missing $Y_i$ with it without any care to use some prediction-powered inference method. This will often yield invalid inferences, but is very common in practice and thus a relevant baseline.\\
$\bullet$~\textbf{Vanilla prediction-powered:} for the sake of comparison to prior work, we also consider the method of \cite{ppi}. This method requires the prediction model to be fixed a priori, so we first split the collected labels in a training set to train it, and use the remaining labels for their prediction-powered inference method. For confidence intervals, we use CLT-based ones as proposed by the authors.

Figure~\ref{fig:confseq} shows the result of our experiment.
Our prediction-powered methods provides valid confidence intervals that are tighter and more concentrated around the true mean in comparison to only using labelled samples, while the imputation approach is strongly concentrated away from the true mean, and would lead to invalid conclusions.
In comparison to the method of \cite{ppi}, our method provides tighter intervals in spite of its nonasymptotic nature, likely due to its ability to train the predictive model without a data split.

\subsection{Testing the Online Risk: Online Monitoring of a Deployed Model for Forest Cover Prediction} \label{sec:experiment-2}

For our second experiment, we consider the task of monitoring the risk of a predictive model for forest cover types online.
Forest cover prediction is of wide use in remote sensing tasks and particularly for tracking of deforestation and land use, which is, in turn, very useful for climate research.
Moreover, online risk monitoring is ubiquitous and applicable to any setting where a predictive model is involved.

Again we have a data stream $(X_i, Y_i)_{i=1}^\infty$, where $X_i$ indicate input variables to our predictive model -- in this case, corresponding to data from satellite images -- and $Y_i$ are the labels denoting the corresponding cover type (which is a categorical variable).
Naturally, $Y_i$ is generally missing -- after all, if it weren't, then we would have no need to predict it.
In our experiment, we work on the dataset of \cite{dataset-covtype}. For the sake of evaluation, we have access to all $Y_i$, but will simulate the missingness.
The notion of risk in which we are interested is given by the 0-1 loss: $\text{Risk}_i(f) = \E[\ind[f(X_i) \neq Y_i]]$.
We have already trained the predictive model $f$ independent of our data stream (in the case of our experiment, in a separate training split) and have similarly evaluated it on a separate validation set, also independent of our data stream, upon which we obtained a validation 0-1 loss of $\text{ValRisk}$.
For continuous risk monitoring, we want to test the null hypothesis that
\[ H_0 : \text{Risk}_i(f) \leq \text{ValRisk} + \epsilon_\mathrm{tol}, \quad \text{for all }i = 1, 2, \ldots, \]
for some tolerance level $\epsilon_\mathrm{tol}$, for example equal to $0.05$.
In particular, we would like for this hypothesis test to be anytime-valid, so that at any point we can reach safe conclusions from it.

\begin{figure}
    \includegraphics[width=\columnwidth]{figures/fig2-trim.png}
    \vspace{-0.5cm}
    \caption{\textbf{Prediction-powered anytime-valid hypothesis testing.} The plot shows the e-values over time for testing two null hypotheses -- one on the bottom, which should be rejected, and one on top, which should not be rejected. Our prediction-powered e-values provide the strongest valid signal for rejection ($E\geq20$ for a significance level of 95\%, marked by the dashed lines), as the imputation approach rejects before the null is actually violated; for non-rejection ($E<20$), all the methods appear valid, but ours still attains the highest e-value.} \label{fig:hyptest}
\end{figure}

\begin{figure*}
    \includegraphics[width=\textwidth]{figures/fig3.png}
    \vspace{-2em}
    \caption{\textbf{Prediction-powered change-point detection via e-values.} The plot shows the exponential moving average of a time series (in blue), with the few collected labels denoted by the scattered Xs. Our prediction-powered methods detect the change-point accurately, while the base method that only considers the labelled data points does not detect any change-point.}%
    \label{fig:changepoint}
\end{figure*}

Inspired by the work of \cite{evalue-online-risk-monitoring}, we consider the following e-value:
\begin{equation} \label{eq:base-evalue-experiment-2}
    E_n := \prod_{i=1}^n \biggl( 1 + \lambda_i \Bigl( \ind[f(X_i) \neq Y_i] - (\text{ValRisk} + \epsilon_\mathrm{tol}) \Bigr) \biggr),
\end{equation}
where $(\lambda_i)_{i=1}^\infty$ is a predictable sequence of bets bounded in $\bigl[ 0, 1/(\text{ValRisk} + \epsilon_\mathrm{tol}) \bigr)$. This forms a test supermartingale for the null $H_0$.

Much like in the example of inference of the prevalence of diabetes in Section~\ref{sec:experiment-1}, the e-values are already of the desired form, but additional care must be taken with regard to the limits of the components.
As-is, they are bounded in $[0, 1+\max\{1/(\text{ValRisk} + \epsilon_\mathrm{tol}) - 1, 0\}]$, meaning that our collection probabilities would have to be within $[1, 1]$.
Similarly to what we did in Section~\ref{sec:experiment-1}, we tweak the bounds for the bets $\lambda_i$ to make them bounded within $\bigl[0, c/(\text{ValRisk} + \epsilon_\mathrm{tol})\bigr)$ for some $0 < c \leq 1$, leading to components bounded in $[1-c, 1+c \max\{1/(\text{ValRisk} + \epsilon_\mathrm{tol}) - 1, 0\}]$. We can then solve for the $c$ that satisfies
\begin{equation}\label{eq:truncated-bets-mean-onesided}
    1 - \frac{1-c}{1 + c \max\{1/(\text{ValRisk} + \epsilon_\mathrm{tol}) - 1, 0\}} \leq \pi_{\inf},
\end{equation}
for a desired labelling budget $\pi_{\inf}$, which we take to be equal $0.5\%$.

The methods we consider for our experiment are akin to those of Section~\ref{sec:experiment-1}:\\
$\bullet$~\textbf{Only labelled samples} at every data point $i$, we sample $\xi_i \sim \mathrm{Bern}(\pi_{\inf})$. If $\xi_i = 1$, then we collect that data point and update the non-prediction-powered e-value in Equation~\eqref{eq:base-evalue-experiment-2}. Since the data collection is sampled independently of all else, this is a valid e-value, and forms a test supermartingale; moreover, only about $\approx \pi_{\inf} \cdot n$ samples will be collected. However, only data points where $\xi_i = 1$ are used for inference.\\
$\bullet$~\textbf{Prediction-powered (ours):} we compute the prediction-powered e-value atop the base-evalue in Equation~\eqref{eq:base-evalue-experiment-2} tweaked to satisfy the boundedness conditions as per Equation~\eqref{eq:truncated-bets-mean-onesided}. We then have two predictive models: one which is the predictive model whose risk we want to monitor -- $\mu$ -- and another which is used for prediction-powered inference, which receives $X_i$ and predicts the 0-1 loss for that point, $\ind[\mu(X_i) \neq Y_i]$. The first model $\mu$ is held static over the course of the inference, while the one for prediction-powered inference is updated whenever we collect a new label. Collection probabilities $\pi_i(X_i)$ are held constant at $\pi_{\inf}$, leading to label collection matching the baseline of only using labelled samples.\\
$\bullet$~\textbf{Active prediction-powered (ours):} the same as our `non-active' prediction-powered method, but label collection probabilities are given by the approximately optimal choice presented in Appendix~\ref{suppl:approx-optimal-pi}.\\
$\bullet$~\textbf{Imputation:} as a final baseline, we consider simply imputing the 0-1 loss at points where we have not collected the true label, with no regard to prediction-powreed inference. This is invalid in general, but commonly used in practice.

Note that standard prediction-powered inference methods (e.g., from \cite{ppi}) are no longer directly applicable due to the requirement of anytime-validity, as well as the fact that our hypothesis test does not come from a two-sided test for a mean (which would then be an instance of simple Z-estimation).

To fully assess the hypothesis test, we consider two settings here.
In the first setting, there is no change in distribution: the data stream for the inference follows the exact same distribution as training and validation, and thus the null hypothesis should hold.
For the second setting, we increasingly poison the labels over the course of time to simulate distribution drift.

The results can be seen in Figure~\ref{fig:hyptest}.
Without data poisoning, none of the methods reject the hypothesis, which is appropriate; though it is interesting to note that our prediction-powered methods were the ones with the highest e-values, managing to stay at around 1.
Under data poisoning, both of our prediction-powered methods detect the distribution drift extremely quicker than the method that only uses labelled samples, despite both having access to the same labelled samples.
The active prediction-powered method seems to reject the hypothesis a tiny bit earlier and yields larger e-values (i.e., with more evidence towards rejection), at the cost of just a tiny bit more data.
The imputation method seemingly detects the shift even earlier, but does so before the null hypothesis is actually falsified; thus, it produces a false alarm with extremely high confidence.

\subsection{Change-Point Detection: Detecting Changes in the Quality of a Deployed Model} \label{sec:experiment-3}

Still in the context of testing the cover prediction model of Section~\ref{sec:experiment-2}, we now consider not just detecting when the risk goes below a certain level, but detecting \emph{any} change.
E-values have seen good use in the change-point detection literature \cite{evalue-change-point-1,evalue-change-point-2,evalue-change-point-3}; we opt here for the method proposed in \cite{evalue-change-point-2}, where change-point detection is reduced to a simple algorithm atop confidence sequences initialized at each time step.
For the underlying confidence sequences, we use the same ones as in Section~\ref{sec:experiment-1}.
Compared to Section~\ref{sec:experiment-2}, the only change we make to the data is the introduction of a crisp change-point for better visualization.

Figure~\ref{fig:changepoint} displays a high-frequency exponentially moving average of our data (to give a notion of the underlying data stream) that uses data at all points, regardless of whether they are accessible to the analyst; scattered throughout are the few data points that were labelled and that the analyst does have access to.
Our prediction-powered method detects the change-point accurately while retaining the strong guarantees of \cite{evalue-change-point-2}, whereas the non-prediction-powered baseline that uses only available labelled data fails to detect any change-point.

\subsection{Causal Discovery: Constraint-Based Structure Learning with Costly Covariates} \label{sec:experiment-4}

\begin{figure}
    \includegraphics[width=.58\columnwidth]{figures/fig4-1.png}%
    {\raisebox{2cm}{%
        \includegraphics[width=.41\columnwidth]{figures/fig4-2.png}}}
    \vspace{-2em}
    \caption{\textbf{Prediction-powered causal discovery with e-values.} We compare our prediction-powered causal discovery method with one that uses only labelled data. The lighter nodes correspond to the costly variables, while the darker nodes correspond to cheaper readily-available ones. The standard base method does not detect any edges in the causal graph (denoted by the dashed edges), while ours detects as many edges as the `best possible' method, which uses all the data points regardless of data acquisition costs.} \label{fig:causal-discovery}
\end{figure}

Causal inference is of essence to any area where one plans interventions, but the usual methods require knowledge of a DAG describing (a simplified version of) the data generating process.
Causal discovery (a.k.a. causal structure learning) methods seek to learn this from data.
Some particularly common methods for causal learning include the PC \cite{algo-pc} and FCI \cite{algo-fci} algorithms; all of these belong to the class of so called `constraint-based' structure learning, where the DAG is inferred by the means of many hypothesis tests for conditional independencies.
In spite of potential multiple comparison concerns, these algorithms are generally said to be valid as long as the underlying hypothesis tests are valid (i.e., control type-I error).

In this section we consider the problem of causal discovery with the PC algorithm \cite{algo-pc} with some costly covariates, which will be generally missing.
As is usual in the causal discovery literature, we evaluate on synthetic data generated with a randomly generated DAG, in order to have access to the true DAG.
Our DAG features 6 variables, of which 3 are considered costly.
Overall, our cheap data $X_i$ consists of the 3 always-available variables, whereas the costly data $Y_i$ consists of the 6 full variables. For constraint-based causal learning, we need to be able to test hypotheses of the form
\[ H_0^{(A,B,C)} : A \indep B \mid C, \]
where $A$, $B$ and $C$ consist of subsets of our 6 variables, possibly empty.

There do exist sequential e-value tests for conditional independence \cite{evalue-conditional-independence-1,evalue-conditional-independence-2}, but they work under the Model-X framework, which requires knowledge of conditionals that are typically inaccessible in the context of causal discovery. We thus opt instead for Fisher's z-transformation of partial correlation test, which is commonly used in causal discovery implementations (e.g., \cite{pcalg,causal-learn}). But it is based on p-values, is not of sequential nature, is asymptotic, and works atop rather heavy normality assumptions.

We first need to adapt it to our required form, following Equation~\eqref{eq:prod-evalue}.
To do so, we first rearrange our data stream $(X_i, Y_i)_{i=1}^\infty$ to arrive in batches of $B$ samples, $(X^\batch_j, Y^\batch_j)_{j=1}^\infty$; these batches will be the unit of data for our prediction-powered procedure.
We can then compute the test's p-value for each batch, and calibrate this p-value into an e-value by the means of the following $\text{PToE}$ calibrator \cite{e-value-calibration}:
\[ \text{PToE}(p) = \frac{1 - p + p \log p}{p (-\log p)^2}. \]
To ensure that our e-values' components are appropriately bounded, we first clip the p-values (prior to calibration) to lie within $(10^{-7}, 1]$ (so that they are bounded at all; this clipping preserves the validity of the p-values), and then rescale the calibrated e-values by the means of a rescaling function
\[ \mathrm{rescale}_\eta (e) := \eta \cdot (e - 1) + 1, \]
with $\eta$ chosen so as to satisfy a labelling budget of $\pi_{\inf} = 10\%$ (as in the previous sections).
Because the p-values are only valid asymptotically, the batch size $B$ cannot be too small; we use $B=100$.

The results can be seen in Figure~\ref{fig:causal-discovery}.
When using only labelled data according to our data collection budget, the causal discovery method identifies no edges at all.
By using our prediction-powered e-values, we detect over half of the edges, matching the best possible scenario (i.e., what would happen if we had access to the whole dataset).

\section*{Impact Statement}

This paper presents work whose goal is to advance the field of 
Machine Learning and Statistics. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here.


% % In the unusual situation where you want a paper to appear in the
% % references without citing it in the main text, use \nocite
% \nocite{langley00}

\bibliography{paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\section{Proofs} \label{suppl:proofs}

Throughout, we denote by $\filt_i$ the $i$-th element of the underlying data filtration.

\begin{theorem}[Theorem~\ref{thm:hypothesis-testing-valid} in the main text]
    $E^\ppi_n$ is a valid e-value for the null $H_0$. \\ Additionally:
    \begin{enumerate}[(i)]
        \item If $(E_0, E_1, \ldots)$ form a test supermartingale -- i.e., a nonnegative supermartingale with $\E[E_0] \leq 1$ under the null $H_0$ -- then so is $(E^\ppi_0, E^\ppi_1, \ldots)$;
        \item More generally, if $(E_0, E_1, \ldots)$ form an e-process -- i.e., a nonnegative stochastic process such that for all stopping times $\tau$, the null $H_0$ implies that $\E[E_\tau] \leq 1$ -- then so is $(E^\ppi_0, E^\ppi_1, \ldots)$ for all finite stopping times.
    \end{enumerate}
\end{theorem}

\begin{proof}
    First, note that $E^\ppi_n$ is always nonnegative for all $n \in \N$: by induction, it holds for $n = 0$ (where $E^\ppi_n = E^\ppi_0 = 1$), and, for the inductive step,
    \begin{align*}
        &E^\ppi_{n+1} = E^\ppi_{n} \cdot \left( e_{n+1} (\mu_{n+1}(X_{n+1})) + \bigl[ e_{n+1} (Y_{n+1}) - e_{n+1} (\mu_{n+1}(X_{n+1})) \bigr] \cdot \frac{\xi_{n+1}}{\pi_{n+1} (X_{n+1})} \right) \geq 0
        \\ &\iff e_{n+1} (\mu_{n+1}(X_{n+1})) + \bigl[ e_{n+1} (Y_{n+1}) - e_{n+1} (\mu_{n+1}(X_{n+1})) \bigr] \cdot \frac{\xi_{n+1}}{\pi_{n+1} (X_{n+1})} \geq 0;
    \end{align*}
    If $\xi_{n+1} = 0$, then the left-hand-side equals $e_{n+1}(\mu_{n+1}(X_{n+1})) \geq a_{n+1} > 0$.
    Otherwise, it equals
    \begin{align*}
        &\frac{e_{n+1}(Y_{n+1}) - (1 - \pi_{n+1}(X_{n+1})) e_{n+1}(\mu_{n+1}(X_{n+1}))}{\pi_{n+1}(X_{n+1})}
        \geq \frac{a_{n+1} - (1 - \pi_{n+1}(X_{n+1})) b_{n+1}}{\pi_{n+1}(X_{n+1})} \geq 0
        \\ &\iff a_{n+1} - (1 - \pi_{n+1}(X_{n+1})) b_{n+1} \geq 0
        \iff a_{n+1} \geq (1 - \pi_{n+1}(X_{n+1})) b_{n+1}
        \\ &\iff 1 - a_{n+1}/b_{n+1} \leq \pi_{n+1}(X_{n+1}),
    \end{align*}
    which holds by construction.

    So all that remains is to show that its properties under the null hold. Hence, from here on out, we assume that the null $H_0$ is true.

    We will first show that, for any $n \in \N$, $\E[E^\ppi_n] \leq 1$.
    To do so, we will first prove the following lemma by backward induction:
    \begin{lemma}\label{thm:lemma-backwardsinduction}
        Let $n \in \N$ and $A$ denote an event.
        Then, for any $1 \leq k \leq n$, it holds that $\E[\prod_{i=k}^n e^\ppi_i \cond A, \filt_k] = \E[\prod_{i=k}^n e_i(Y_i) \cond A, \filt_k]$
    \end{lemma}
    \begin{proof}
        The base case is when $k = n$. Then
        \begin{align*}
            \E\left[ \prod_{i=k}^n e^\ppi_i \cond A, \filt_k \right]
            &= \E\left[ e^\ppi_n \cond A, \filt_n \right]
            = \E\left[ e_n(\mu_n(X_n)) + \frac{\xi_n}{\pi_n(X_n)} \left( e_n(Y_n) - e_n(\mu_n(X_n)) \right) \cond A, \filt_n \right]
            \\ &= \E\left[ e_n(\mu_n(X_n)) \cond A, \filt_n \right]
                + \E\left[ \frac{\xi_n}{\pi_n(X_n)} \left( e_n(Y_n) - e_n(\mu_n(X_n)) \right) \cond \xi_n = 1, A, \filt_n \right] \P[\xi_n = 1 \cond A, \filt_n]
                \\ &\qquad+ \E\left[ \frac{\xi_n}{\pi_n(X_n)} \left( e_n(Y_n) - e_n(\mu_n(X_n)) \right) \cond \xi_n = 0, A, \filt_n \right] \P[\xi_n = 0 \cond A, \filt_n]
            \\ &= \E\left[ e_n(\mu_n(X_n)) \cond A, \filt_n \right]
                + \E\left[ \frac{1}{\pi_n(X_n)} \left( e_n(Y_n) - e_n(\mu_n(X_n)) \right) \cond A, \filt_n \right] \pi_n(X_n)
            \\ &= \E\left[ e_n(\mu_n(X_n)) \cond A, \filt_n \right]
                + \E\left[ e_n(Y_n) - e_n(\mu_n(X_n)) \cond A, \filt_n \right]
            \\ &= \E\left[ e_n(Y_n) \cond A, \filt_n \right] = \E\left[ \prod_{i=k}^n e_i(Y_i) \cond A, \filt_k \right].
        \end{align*}

        For the induction step, given that the hypothesis holds for $k+1 \leq n$, we want to show that it holds for $k$. It follows, using the law of total expectation:

        \begin{align*}
            \E\left[ \prod_{i=k}^n e^\ppi_i \cond A, \filt_k \right]
            &= \E\left[ e^\ppi_k \prod_{i=k+1}^n e^\ppi_i \cond A, \filt_k \right]
            = \E\left[ \E\left[ e^\ppi_k \prod_{i=k+1}^n e^\ppi_i \cond A, \filt_{k+1} \right] \cond A, \filt_k \right]
            \\ &= \E\left[ e^\ppi_k \ \E\left[ \prod_{i=k+1}^n e^\ppi_i \cond A, \filt_{k+1} \right] \cond A, \filt_k \right]
            = \E\left[ e^\ppi_k \ \E\left[ \prod_{i=k+1}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond A, \filt_k \right]
            \\ &= \E\left[ \left( e_k(\mu_k(X_k)) + \frac{\xi_k}{\pi_k(X_k)} \left( e_k(Y_k) - e_k(\mu_k(X_k)) \right) \right) \ \E\left[ \prod_{i=k+1}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond A, \filt_k \right]
            \\ &= \E\left[ e_k(\mu_k(X_k)) \ \E\left[ \prod_{i=k+1}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond A, \filt_k \right]
                \\ &\quad + \E\left[ \frac{\xi_k}{\pi_k(X_k)} \left( e_k(Y_k) - e_k(\mu_k(X_k)) \right) \ \E\left[ \prod_{i=k+1}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond \xi_k = 1, A, \filt_k \right] \P[\xi_k = 1 \cond A, \filt_k]
                \\ &\quad + \E\left[ \frac{\xi_k}{\pi_k(X_k)} \left( e_k(Y_k) - e_k(\mu_k(X_k)) \right) \ \E\left[ \prod_{i=k+1}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond \xi_k = 0, A, \filt_k \right] \P[\xi_k = 0 \cond A, \filt_k]
            \\ &= \E\left[ e_k(\mu_k(X_k)) \ \E\left[ \prod_{i=k+1}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond A, \filt_k \right]
                \\ &\quad + \E\left[ \frac{1}{\pi_k(X_k)} \left( e_k(Y_k) - e_k(\mu_k(X_k)) \right) \ \E\left[ \prod_{i=k+1}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond A, \filt_k \right] \pi_k(X_k)
            \\ &= \E\left[ e_k(\mu_k(X_k)) \ \E\left[ \prod_{i=k+1}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond A, \filt_k \right]
                \\ &\quad + \E\left[ \left( e_k(Y_k) - e_k(\mu_k(X_k)) \right) \ \E\left[ \prod_{i=k+1}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond A, \filt_k \right]
            \\ &= \E\left[ e_k(Y_k) \ \E\left[ \prod_{i=k+1}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond A, \filt_k \right]
            = \E\left[ \E\left[ e_k(Y_k) \prod_{i=k+1}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond A, \filt_k \right]
            \\ &= \E\left[ \E\left[ \prod_{i=k}^n e_i(Y_i) \cond A, \filt_{k+1} \right] \cond A, \filt_k \right]
            = \E\left[ \prod_{i=k}^n e_i(Y_i) \cond A, \filt_k \right],
        \end{align*}
        as we desired.
    \end{proof}

    By picking $k = 1$ and $A$ to be a trivial event in Lemma~\ref{thm:lemma-backwardsinduction}, we conclude that $\E[E^\ppi_n] = \E[\prod_{i=1}^n e^\ppi_i \cond \filt_1] = \E[\prod_{i=1}^n e_i(Y_i) \cond \filt_1] = \E[E_n] \leq 1$, and so $E^\ppi_n$ is a valid e-value.

    Now let us show that, if the underlying e-values form a test supermartingale, then so is the prediction-powered process. By definition $E^\ppi_0 = E_0 = 1$, and so all we need to do is to show that $\E[E^\ppi_{n+1} \cond \filt_n] \leq E^\ppi_n$. It follows:

    \begin{align*}
        \E[E^\ppi_{n+1} \cond \filt_n]
        &= \E[e^\ppi_{n+1} \cdot E^\ppi_n \cond \filt_n]
        = \E[e^\ppi_{n+1} \cond \filt_n] \cdot E^\ppi_n
        \\ &= \E\left[ e_{n+1}(\mu_{n+1}(X_{n+1})) + \frac{\xi_{n+1}}{\pi_{n+1}(X_{n+1})} \left( e_{n+1}(Y_{n+1}) - e_{n+1}(\mu_{n+1}(X_{n+1})) \right) \cond \filt_n \right] \cdot E^\ppi_n
        \\ &= \E\left[ e_{n+1}(\mu_{n+1}(X_{n+1})) \cond \filt_n \right] \cdot E^\ppi_n
            \\ &\qquad + \E\left[ \frac{\xi_{n+1}}{\pi_{n+1}(X_{n+1})} \left( e_{n+1}(Y_{n+1}) - e_{n+1}(\mu_{n+1}(X_{n+1})) \right) \cond \xi_{n+1} = 1, \filt_n \right] \P[\xi_{n+1} = 1 \cond \filt_n] \cdot E^\ppi_n
            \\ &\qquad + \E\left[ \frac{\xi_{n+1}}{\pi_{n+1}(X_{n+1})} \left( e_{n+1}(Y_{n+1}) - e_{n+1}(\mu_{n+1}(X_{n+1})) \right) \cond \xi_{n+1} = 0, \filt_n \right] \P[\xi_{n+1} = 0 \cond \filt_n] \cdot E^\ppi_n
        \\ &= \E\left[ e_{n+1}(\mu_{n+1}(X_{n+1})) \cond \filt_n \right] \cdot E^\ppi_n
            \\ &\qquad + \E\left[ \frac{1}{\pi_{n+1}(X_{n+1})} \left( e_{n+1}(Y_{n+1}) - e_{n+1}(\mu_{n+1}(X_{n+1})) \right) \cond \xi_{n+1} = 1, \filt_n \right] \pi_{n+1}(X_{n+1}) \cdot E^\ppi_n
        \\ &= \E\left[ e_{n+1}(\mu_{n+1}(X_{n+1})) \cond \filt_n \right] \cdot E^\ppi_n
            + \E\left[ e_{n+1}(Y_{n+1}) - e_{n+1}(\mu_{n+1}(X_{n+1})) \cond \xi_{n+1} = 1, \filt_n \right] \cdot E^\ppi_n
        \\ &= \E\left[ e_{n+1}(Y_{n+1}) \cond \filt_n \right] \cdot E^\ppi_n
        \\ &= \E\left[ e_{n+1}(Y_{n+1}) \cond \filt_n \right] \cdot E_n \cdot \frac{E^\ppi_n}{E_n}
        \\ &\leq E_n \cdot \frac{E^\ppi_n}{E_n} = E^\ppi_n.
    \end{align*}

    Finally, we assume that the underlying e-values form an e-process for finite stopping times. We want to show that, for any finite stopping time $\tau$, $\E[E^\ppi_\tau] \leq 1$. Well,

    \[ \E[E^\ppi_\tau] = \E[\E[E^\ppi_\tau \cond \tau]]; \]

    When $\tau = n$ for each $n \in \N$, by Lemma~\ref{thm:lemma-backwardsinduction} with $k = n$ and $A = \{ \tau = n \}$, it holds that $\E[E^\ppi_n \cond \tau = n] = \E[\prod_{i=1}^n e^\ppi_i \cond \tau = n, \filt_1] = \E[\prod_{i=1}^n e_i(Y_i) \cond \tau = n, \filt_1] = \E[E_n \cond \tau = n]$.

    Thus
    \[ \E[E^\ppi_\tau] = \E[\E[E^\ppi_\tau \cond \tau]] = \E[\E[E_\tau \cond \tau]] = \E[E_\tau] \leq 1, \]

    and so $E^\ppi$ is an e-process.
\end{proof}


To prove the main theorem about power of our prediction-powered e-values, we will use the following change-of-measure lemma based on the Wasserstein distance:

\begin{lemma}\label{thm:wasserstein-lemma}
    For any distributions $P$ and $Q$ over some space $\mathcal{Z}$ and any $L$-Lipschitz function $\phi : \mathcal{Z} \to \R$,
    \[ \lvert \E_P[\phi] - \E_Q[\phi] \rvert \leq L\,W(P \Vert Q), \]
    where $W(P \Vert Q)$ is the Wasserstein distance between $P$ and $Q$.
\end{lemma}

\begin{proof}
    The proof follows immediately from the representation of the Wasserstein distance as an IPM. The Wasserstein distance, written as an IPM, is
    \[ W(P \Vert Q) = \sup_{\|f\|_\Lip = 1} \lvert \E_P[f] - \E_Q[f] \rvert. \]
    If $\phi$ is $L$-Lipschitz, then $\phi/L$ is 1-Lipschitz, and so
    \[
        \lvert \E_P[\phi] - \E_Q[\phi] \rvert
        = \lvert L \E_P[\phi/L] - L \E_Q[\phi/L] \rvert
        = L \lvert \E_P[\phi/L] - \E_Q[\phi/L] \rvert
        \leq L \sup_{\|f\|_\Lip = 1} \lvert \E_P[f] - \E_Q[f] \rvert
        = L\,W(P \Vert Q).
    \]
\end{proof}

\begin{theorem}[Theorem~\ref{thm:hypothesis-testing-power} in the main text]
    Suppose that the $e_i(\cdot)$ are each $L_i$-Lipschitz, and that $\pi_i(X_i) \geq 1 - a_i/b_i + \epsilon_i$ for some $\epsilon_i > 0$, for all $i$. Then there exists some constant $c > 0$ independent of $n$ such that
    \begin{align*}
        \E\left[ \frac{1}{n} \log E^\ppi_n \right]
        \geq \E\left[ \frac{1}{n} \log E_n \right] - \frac{c}{n} \sum_{i=1}^n \E[ W(\mu_i(X_i) \Vert Y_i) ].
    \end{align*}
    where $W(\mu_i(X_i) \Vert Y_i)$ is the Wasserstein distance between $\mu_i(X_i)$ and $Y_i$, conditional on all else prior.
\end{theorem}

\begin{proof}
    First, note that
    \begin{align*}
        \E\left[ \frac{1}{n} \log E^\ppi_n \right]
        &= \E\left[ \frac{1}{n} \log \prod_{i=1}^n e^\ppi_i \right]
        = \frac{1}{n} \sum_{i=1}^n \E\left[ \log e^\ppi_i \right]
        \\ &= \frac{1}{n} \sum_{i=1}^n \E\left[ \log \left( e_i(\mu_i(X_i)) + \frac{\xi_i}{\pi_i(X_i)} [ e_i(Y_i) - e_i(\mu_i(X_i)) ] \right) \right].
        \\ &= \frac{1}{n} \sum_{i=1}^n \E\left[ \E\left[ \log \left( e_i(\mu_i(X_i)) + \frac{\xi_i}{\pi_i(X_i)} [ e_i(Y_i) - e_i(\mu_i(X_i)) ] \right) \cond Y_i, \xi_i, \pi_i(X_i), \filt_i \right] \right].
    \end{align*}
    The inner expectation in the last line is random only over $\mu_i(X_i)$.
    Moreover, thanks to our assumptions, the value we are taking the expectation over is Lipschitz as a function of $\mu_i(X_i)$: because of the lower bound on the $\pi_i(X_i)$ with positive margins $\epsilon_i$, the value within the log is bounded away from zero, and so the log becomes Lipschitz with some constant $u > 0$.
    \[
        \left\lVert \log \left( e_i(\cdot) + \frac{\xi_i}{\pi_i(X_i)} [ e_i(Y_i) - e_i(\cdot) ] \right) \right\rVert_\Lip
        \leq u \left\lVert e_i(\cdot) + \frac{\xi_i}{\pi_i(X_i)} [ e_i(Y_i) - e_i(\cdot) ] \right\rVert_\Lip;
    \]
    If $\xi_i = 0$, then this equals $u \left\lVert e_i(\cdot) \right\rVert_\Lip = u \cdot L_i$.
    Otherwise, this equals
    \begin{align*}
        u \left\lVert e_i(\cdot) + \frac{\xi_i}{\pi_i(X_i)} [ e_i(Y_i) - e_i(\cdot) ] \right\rVert_\Lip
        &= u \left\lVert \frac{e_i(Y_i) - (1 - \pi_i(X_i)) e_i(\cdot)}{\pi_i(X_i)} \right\rVert_\Lip
        \\ &= u \frac{1}{\pi_i(X_i)} \left\lVert e_i(Y_i) - (1 - \pi_i(X_i)) e_i(\cdot) \right\rVert_\Lip
        \\ &= u \frac{1}{\pi_i(X_i)} \left\lVert - (1 - \pi_i(X_i)) e_i(\cdot) \right\rVert_\Lip
        \\ &= u \frac{(1 - \pi_i(X_i))}{\pi_i(X_i)} \left\lVert e_i(\cdot) \right\rVert_\Lip
        = u \cdot L_i \cdot \frac{(1 - \pi_i(X_i))}{\pi_i(X_i)}.
    \end{align*}
    In either case, this Lipschitz constant is upper bounded by $c := u \cdot L_i \cdot \max \left\{ \frac{(1 - \pi_i(X_i))}{\pi_i(X_i)}, 1 \right\}$ (which does not depend on $n$). Hence, by Lemma~\ref{thm:wasserstein-lemma},
    \begin{align*}
        &\frac{1}{n} \sum_{i=1}^n \E\left[ \E\left[ \log \left( e_i(\mu_i(X_i)) + \frac{\xi_i}{\pi_i(X_i)} [ e_i(Y_i) - e_i(\mu_i(X_i)) ] \right) \cond Y_i, \xi_i, \pi_i(X_i), \filt_i \right] \right].
        \\ &\geq \frac{1}{n} \sum_{i=1}^n \E\left[ \E\left[ \log \left( e_i(Y_i) + \frac{\xi_i}{\pi_i(X_i)} [ e_i(Y_i) - e_i(Y_i) ] \right) \cond Y_i, \xi_i, \pi_i(X_i), \filt_i \right] - c\,W(\mu_i(X_i) \Vert Y_i) \right].
        \\ &= \frac{1}{n} \sum_{i=1}^n \E\left[ \E\left[ \log e_i(Y_i) \cond Y_i, \xi_i, \pi_i(X_i), \filt_i \right] - c\,W(\mu_i(X_i) \Vert Y_i) \right].
        \\ &= \frac{1}{n} \sum_{i=1}^n \E\left[ \log e_i(Y_i) \right] - \frac{1}{n} \sum_{i=1}^n \E\left[ c\,W(\mu_i(X_i) \Vert Y_i) \right].
        \\ &= \E\left[ \frac{1}{n} \log E_n \right] - \frac{c}{n} \sum_{i=1}^n \E\left[ W(\mu_i(X_i) \Vert Y_i) \right].
    \end{align*}
\end{proof}

The following is a more precise statement about the growth rate of our prediction-powered e-values, albeit less directly interpretable:

\begin{theorem} \label{thm:suppl-hypothesis-testing-power-1}
    It holds that
    \[ \E\left[ \frac{1}{n} \log E^\ppi_n \right] = \E\biggl[ \frac{1}{n} \sum_{i=1}^n (1 - \pi_i(X_i)) \log e_i (\mu_i(X_i)) \biggr] + \E\biggl[ \frac{1}{n} \sum_{i=1}^n \pi_i(X_i) \log \left( e_i (\mu_i(X_i)) + \frac{e_i (Y_i) - e_i (\mu_i(X_i))}{\pi_i (X_i)} \right) \biggr]. \]
\end{theorem}

\begin{proof}
    \begin{align*}
        \E\left[ \frac{1}{n} \log E^\ppi_n \right]
        &= \E\left[ \frac{1}{n} \log \prod_{i=1}^n e^\ppi_i \right]
        = \frac{1}{n} \sum_{i=1}^n \E\left[ \log e^\ppi_i \right]
        \\ &= \frac{1}{n} \sum_{i=1}^n \E\left[ \log \left( e_i (\mu_i(X_i)) + \bigl[ e_i (Y_i) - e_i (\mu_i(X_i)) \bigr] \cdot \frac{\xi_i}{\pi_i (X_i)} \right) \right]
        \\ &= \frac{1}{n} \sum_{i=1}^n \E\left[ \E\left[ \log \left( e_i (\mu_i(X_i)) + \bigl[ e_i (Y_i) - e_i (\mu_i(X_i)) \bigr] \cdot \frac{\xi_i}{\pi_i (X_i)} \right) \cond \filt_i \right] \right]
        \\ &= \frac{1}{n} \sum_{i=1}^n \E\biggl[ \E\left[ \log \left( e_i (\mu_i(X_i)) + \bigl[ e_i (Y_i) - e_i (\mu_i(X_i)) \bigr] \cdot \frac{\xi_i}{\pi_i (X_i)} \right) \cond \xi_i = 1, \filt_i \right] \P[\xi_i = 1 \cond \filt_i]
            \\ &\qquad\qquad + \E\left[ \log \left( e_i (\mu_i(X_i)) + \bigl[ e_i (Y_i) - e_i (\mu_i(X_i)) \bigr] \cdot \frac{\xi_i}{\pi_i (X_i)} \right) \cond \xi_i = 0, \filt_i \right] \P[\xi_i = 0 \cond \filt_i] \biggr]
        \\ &= \frac{1}{n} \sum_{i=1}^n \E\biggl[ \E\left[ \log \left( e_i (\mu_i(X_i)) + \bigl[ e_i (Y_i) - e_i (\mu_i(X_i)) \bigr] \cdot \frac{1}{\pi_i (X_i)} \right) \cond \filt_i \right] \pi_i(X_i)
            \\ &\qquad\qquad + \E\left[ \log e_i (\mu_i(X_i)) \cond \filt_i \right] (1 - \pi_i(X_i)) \biggr]
        \\ &= \frac{1}{n} \sum_{i=1}^n \E\biggl[ \pi_i(X_i) \log \left( e_i (\mu_i(X_i)) + \bigl[ e_i (Y_i) - e_i (\mu_i(X_i)) \bigr] \cdot \frac{1}{\pi_i (X_i)} \right) + (1 - \pi_i(X_i)) \log e_i (\mu_i(X_i)) \biggr]
        \\ &= \E\biggl[ \frac{1}{n} \sum_{i=1}^n (1 - \pi_i(X_i)) \log e_i (\mu_i(X_i)) \biggr] + \E\biggl[ \frac{1}{n} \sum_{i=1}^n \pi_i(X_i) \log \left( e_i (\mu_i(X_i)) + \frac{e_i (Y_i) - e_i (\mu_i(X_i))}{\pi_i (X_i)} \right) \biggr].
    \end{align*}
\end{proof}


To prove the next result we will make use of Ville's inequality:

\begin{theorem}[Ville's inequality \cite{ville,ville-ramdas}] \label{thm:ville}
    For any nonnegative supermartingale $(L_t)$ and any $x > 1$, define the (possibly infinite) stopping time
    $ N := \inf{ t \geq 1 : L_t \geq x } $
    and denote the expected overshoot when $L_t$ surpasses $x$ as
    \[ o = \E\left[ \frac{L_N}{x} \cond N < \infty \right] \geq 1. \]
    Then,
    \[ \P[ \exists t : L_t \geq x ] \leq \frac{\E[L_0]}{o x} \geq \frac{\E[L_0]}{x}. \]
\end{theorem}


\begin{proposition}[Proposition~\ref{thm:confidence-interval-valid} in the main text]
    $C^{\ppi-(\alpha)}_n$ is a valid confidence interval -- i.e., $\P[\theta^\star \in C^{\ppi-(\alpha)}_n] \geq 1 - \alpha$.
    Moreover:
    \begin{enumerate}[(i)]
        \item If the underlying e-values form a nonnegative supermartingale, then the prediction-powered intervals are anytime-valid (also known as confidence sequences): $\P[\forall n \in \N,\ \theta^\star \in C^{\ppi-(\alpha)}_n] \geq 1 - \alpha$;
        \item More generally, if the underlying e-values form e-processes, then the prediction-powered intervals are valid at arbitrary stopping times: $\P[\theta^\star \in C^{\ppi-(\alpha)}_\tau] \geq 1 - \alpha$ for any stopping time $\tau$.
    \end{enumerate}
\end{proposition}

\begin{proof}
    By construction, $\P[\theta^\star \in C^{\ppi-(\alpha)}_n] = \P[E^{\ppi-(\theta^\star)}_n \leq 1/\alpha] = 1 - \P[E^{\ppi-(\theta^\star)}_n > 1/\alpha]$. By Markov, considering that the null $H_0^{\theta^\star}$ holds and using Theorem~\ref{thm:hypothesis-testing-valid},
    \[
        1 - \P[E^{\ppi-(\theta^\star)}_n > 1/\alpha] \geq 1 - \frac{\E[E^{\ppi-(\theta^\star)}]}{1/\alpha} \geq 1 - \frac{1}{1/\alpha} = 1 - \alpha.
    \]

    If the underlying e-values form a test supermartingale, then by Theorem~\ref{thm:hypothesis-testing-valid} so do the prediction-powered e-values; then, using Ville's inequality,
    \begin{align*}
        \P[\forall n \in \N,\ \theta^\star \in C^{\ppi-(\alpha)}_n]
        &= \P[\forall n \in \N,\ E^{\ppi-(\theta^\star)}_n \leq 1/\alpha]
        = \P[\sup_n \ E^{\ppi-(\theta^\star)}_n \leq 1/\alpha]
        \\ &= 1 - \P[\sup_n \ E^{\ppi-(\theta^\star)}_n > 1/\alpha]
        \geq 1 - \frac{\E[E^{\ppi-(\theta^\star)}_0]}{1/\alpha}
        = 1 - \frac{1}{1/\alpha} = 1 - \alpha.
    \end{align*}

    Finally, if the underlying e-values form an e-process, thenby Theorem~\ref{thm:hypothesis-testing-valid} so do the prediction-powered e-values (for finite stopping times), and so, by Markov,
    \begin{align*}
        \P[\theta^\star \in C^{\ppi-(\alpha)}_\tau]
        &= \P[E^{\ppi-(\theta^\star)}_\tau \leq 1/\alpha]
        = 1 - \P[E^{\ppi-(\theta^\star)}_\tau > 1/\alpha]
        \\ &\geq 1 - \frac{\E[E^{\ppi-(\theta^\star)}_\tau]}{1/\alpha}
        \geq 1 - \frac{1}{1/\alpha}
        = 1 - \alpha.
    \end{align*}
\end{proof}

\begin{proposition}[Proposition~\ref{thm:confidence-interval-power} in the main text]
    Under the assumptions of Theorem~\ref{thm:hypothesis-testing-power},
    let $\nu$ be a measure over the parameter space $\Theta$. Then there exists some $c$ for which
    \[ \E\left[\int \frac{1}{n} \log \frac{1}{E^{\ppi-(\theta)}_n} \dif\nu(\theta)\right] \leq \E\left[\int \frac{1}{n} \log \frac{1}{E^{(\theta)}_n} \dif\nu(\theta)\right] + \frac{\nu(\Theta)c}{n} \sum_{i=1}^n W(\mu_i(X_i) \Vert Y_i). \]
\end{proposition}

\begin{proof}
    By Fubini,
    \[ \E\left[\int \frac{1}{n} \log 1/E^{\ppi-(\theta)}_n \dif\nu(\theta)\right] = \int \E\left[\frac{1}{n} \log 1/E^{\ppi-(\theta)}_n\right] \dif\nu(\theta) \]
    And now we apply Theorem~\ref{thm:hypothesis-testing-power}:
    \begin{align*}
        \int \E\left[\frac{1}{n} \log 1/E^{\ppi-(\theta)}_n\right] \dif\nu(\theta)
        &= -\int \E\left[\frac{1}{n} \log E^{\ppi-(\theta)}_n\right] \dif\nu(\theta)
        \leq -\int \left( \E\left[\frac{1}{n} \log E^{(\theta)}_n\right] - \frac{c}{n} \sum_{i=1}^n W(\mu_i(X_i) \Vert Y_i) \right) \dif\nu(\theta)
        \\ &\leq \int \left( \E\left[\frac{1}{n} \log 1/E^{(\theta)}_n\right] + \frac{c}{n} \sum_{i=1}^n W(\mu_i(X_i) \Vert Y_i) \right) \dif\nu(\theta)
        \\ &= \int \E\left[\frac{1}{n} \log 1/E^{(\theta)}_n\right] \dif\nu(\theta) + \frac{\nu(\Theta) c}{n} \sum_{i=1}^n W(\mu_i(X_i) \Vert Y_i)
        \\ &= \E\left[\int \frac{1}{n} \log 1/E^{(\theta)}_n \dif\nu(\theta)\right] + \frac{\nu(\Theta) c}{n} \sum_{i=1}^n W(\mu_i(X_i) \Vert Y_i).
    \end{align*}
\end{proof}

Considering that the object of interest is a confidence interval, it is desirable to further bound the \emph{measure} of the interval.
We were unable to prove any sufficiently general result that was (i) nonvacuous, and (ii) decayed reasonably fast as $n$ increased, and imagine that heavy assumptions are necessary; this may be best done on a case-by-case basis.
Nevertheless, here is one possible somewhat straightforward result.

\begin{proposition}\label{thm:hacky-confidence-interval-measure}
    Under the same conditions of Proposition~\ref{thm:confidence-interval-power}, suppose that the prediction-powered e-values are bounded from above by $M^\ppi$ (i.e., for all $\theta \in \Theta$, $E^{\ppi-(\theta)}_n < M^\ppi$ almost surely), and similarly for the non-prediction powered e-values by $M$ (i.e., for all $\theta \in \Theta$, $E^{(\theta)}_n < M$ almost surely). Then:
    Then
    \[
        \E[\nu(C^\ppi)] \leq \frac{\E[\int \log 1/E^{\ppi-(\theta)} \dif \nu(\theta)] + \nu(\Theta) M^\ppi}{\log \alpha + \log M^\ppi},
        \qquad\qquad
        \E[\nu(C)] \leq \frac{\E[\int \log 1/E^{(\theta)} \dif \nu(\theta)] + \nu(\Theta) M}{\log \alpha + \log M}.
    \]
\end{proposition}

\begin{proof}
    Consider the measure $\tilde{\nu}(A) = \nu(A)/\nu(\Theta)$; it is a probability measure. Then:
    \[
        \tilde{\nu}(C^\ppi)
        = \P_{\theta\sim\tilde{\nu}}[ E^{\ppi-(\theta)} < 1/\alpha ]
        = \P_{\theta\sim\tilde{\nu}}[ 1/E^{\ppi-(\theta)} > \alpha ]
        = \P_{\theta\sim\tilde{\nu}}[ \log 1/E^{\ppi-(\theta)} > \log \alpha ];
    \]
    We want to apply Markov. To do that, we need the left-hand side to be nonnegative; to do so, we add $\log M^\ppi$ to both sides, which yields
    \begin{align*}
        \P_{\theta\sim\tilde{\nu}}[ \log 1/E^{\ppi-(\theta)} > \log \alpha ];
        &= \P_{\theta\sim\tilde{\nu}}[ \log 1/E^{\ppi-(\theta)} + \log M^\ppi > \log \alpha + \log M^\ppi ]
        \\ &\leq \frac{ \E_{\theta\sim\tilde{\nu}}[ \log 1/E^{\ppi-(\theta)} + \log M^\ppi ] }{ \log \alpha + \log M^\ppi }
        \\ &\leq \frac{ \int \log 1/E^{\ppi-(\theta)} \dif \tilde{\nu}(\theta) + \log M^\ppi }{ \log \alpha + \log M^\ppi }.
        \\ &\leq \frac{ [\nu(\Theta)]^{-1} \int \log 1/E^{\ppi-(\theta)} \dif \nu(\theta) + \log M^\ppi }{ \log \alpha + \log M^\ppi }.
    \end{align*}
    So, multiplying everything by $\nu(\Theta)$, we get that
    \[ \tilde{\nu}(C^\ppi) \cdot \nu(\Theta) = \nu(C^\ppi) \leq \nu(\Theta) \cdot \frac{ [\nu(\Theta)]^{-1} \int \log 1/E^{\ppi-(\theta)} \dif \nu(\theta) + \log M^\ppi }{ \log \alpha + \log M^\ppi } = \frac{ \int \log 1/E^{\ppi-(\theta)} \dif \nu(\theta) + \nu(\Theta) \log M^\ppi }{ \log \alpha + \log M^\ppi }. \]
    Finally, taking the expectation on both sides, we get that
    \[ \E[\tilde{\nu}(C^\ppi)] \leq \E\left[ \frac{ \int \log 1/E^{\ppi-(\theta)} \dif \nu(\theta) + \nu(\Theta) \log M^\ppi }{ \log \alpha + \log M^\ppi } \right] = \frac{ \E[ \int \log 1/E^{\ppi-(\theta)} \dif \nu(\theta) ] + \nu(\Theta) \log M^\ppi }{ \log \alpha + \log M^\ppi }, \]
    as we desired.

    The same can be done for the non-prediction-powered e-values, replacing $E^\ppi$ with $E$ and $M^\ppi$ with $M$.
\end{proof}

Most terms in the inequality depend on $n$, so it's a bit hard to intuit. But, if the dependence on the $n$ in the expectation of the log is good enough, then this should be nonvacuous, at least.



\begin{proposition}[Proposition~\ref{thm:general-algo-valid} in the main text]
    Under Assumption~\ref{assump:algo-validity}, it holds that
    $\mathcal{A}((E^{\ppi-(\gamma)}_n)_{\gamma \in \Gamma})$ is also \emph{valid}.
    If the underlying e-values are e-processes, then it further holds that $\mathcal{A}((E^{\ppi-(\gamma)}_\tau)_{\gamma \in \Gamma})$ is \emph{valid} for any finite stopping time $\tau$.
\end{proposition}

\begin{proof}
    To prove that $\mathcal{A}((E^{\ppi-(\gamma)}_n)_{\gamma \in \Gamma})$ is valid, by Assumption~\ref{assump:algo-validity}, it suffices to show that $E^{\ppi-(\gamma)}_n$ is valid for every $\gamma \in \Gamma$; and by Theorem~\ref{thm:hypothesis-testing-valid}, this is indeed the case.

    Now suppose that the underlying e-values $(E^{(\gamma)}_n)_{\gamma \in \Gamma}$ form e-processes; then so do the prediction-powered e-values $(E^{\ppi-(\gamma)}_n)_{\gamma \in \Gamma}$ for finite stopping times, by Theorem~\ref{thm:hypothesis-testing-valid}.
    Then, to prove that $\mathcal{A}((E^{\ppi-(\gamma)}_\tau)_{\gamma \in \Gamma})$ is valid for any finite stopping time $\tau$, again by Assumption~\ref{assump:algo-validity} it suffices to show that $E^{\ppi-(\gamma)}_\tau$ is valid, which is indeed the case since they form e-processes for finite stopping times.
\end{proof}


\section{Additional Results}

\subsection{The Asymptotic Setting} \label{suppl:asymptotic}

E-values, though usually defined in non-asymptotic terms, have asymptotic analogues. In particular, a (sequential) asymptotic e-value is defined as a (sequence of) nonnegative random variable(s) $E_n$ such that, under the null $H_0$, it holds that $\limsup_{n \to \infty} \E[E_n] \leq 1$ \cite{evalue-book}.
We briefly show here that the core points of the theory we build in the main text can be directly applied here.
Most results whose analogues we do not prove still hold, and are just omitted for conciseness.

\begin{proposition}
    If $E_n$ is an asymptotic e-value, then so is its prediction-powered analogue $E^\ppi_n$.
\end{proposition}
\begin{proof}
    We want to prove that $E^\ppi_n$ is an asymptotic e-value. It follows, by Theorem~\ref{thm:hypothesis-testing-valid}:
    \[ \limsup_{n \to \infty} \E[E^\ppi_n] = \limsup_{n \to \infty} \E[E_n] \leq 1. \]
\end{proof}

\begin{proposition}
    If $E^{(\theta)}_n$ is an asymptotic e-value for each $\theta in \Theta$, then $C^{\ppi-(\alpha)}_n := \{\theta \in \Theta : E^{\ppi-(\theta)}_n < 1/\alpha\}$ is an asymptotic confidence interval, i.e., $\limsup_{n \to \infty} \P[\theta^\star \not\in C^{\ppi-(\alpha)}_n] \leq \alpha$.
\end{proposition}

\begin{proof}
    It holds that
    \[ \limsup_{n \to \infty} \P[\theta^\star \not\in C^{\ppi-(\alpha)}_n] = \limsup_{n \to \infty} \P[E^{\ppi-(\theta^\star)}_n \geq 1/\alpha]; \]
    By Markov,
    \[ \limsup_{n \to \infty} \P[E^{\ppi-(\theta^\star)}_n \geq 1/\alpha] \leq \limsup_{n \to \infty} \frac{\E[E^{\ppi-(\theta^\star)}_n]}{1/\alpha} = \alpha \limsup_{n \to \infty} \E[E^{\ppi-(\theta^\star)}_n] \leq \alpha. \]
\end{proof}

The results related to power (e.g., Theorem~\ref{thm:hypothesis-testing-power}) apply to asymptotic e-values without any modification necessary.

\subsection{An approximately optimal choice for $\pi_i$}\label{suppl:approx-optimal-pi}

Our prediction-powered e-values have, at their core, the customizeable choice of data collection probabilities $\pi_i(X_i)$.
While selecting a constant $\pi_i(X_i) = \pi_{\inf}$, where $\pi_{\inf}$ is the lowest possible value possible (so as to minimize data collection costs) is a reasonable approach, it ignores the versatility that the probability can take into account the `cheap' data $X_i$, which could significantly improve statistical power when used correctly.
In an effort to seek a better strategy, we try to identify an `approximately optimal' choice of $\pi_i$.

The optimality is in the sense that, at point $i$ in time, the data collection probability function $\pi_i(\cdot)$ should be chosen so as to maximize the expected log of the e-value, as per \cite{kelly}; this is also similar, e.g., to the GRAPA and aGRAPA strategies of \cite{evalue-mean}.
However, the $\pi$ also have additional constraints:
\begin{enumerate}[(i)]
    \item Its image must be bounded: $\pi_i : \mathcal{X} \to [1 - a_i/b_i, 1]$. I.e., for all $x \in \mathcal{X}$, $1 - a_i/b_i \leq \pi_i(x) \leq 1$.
    \item It must respect some particular maximal data collection budget: $\E[\pi_i(X_i)] \leq \mathrm{Budget}$.
\end{enumerate}
So we seek to solve the following constrained functional optimization problem:
\begin{align*}
    \pi_i^\star = &\argmax_{\pi \in L^2} \E[\log E^\ppi_n \cond \filt_i] = \argmin_{\pi \in L^2} \E[-\log e^\ppi_n \cond \filt_i]
    \\ &\text{subject to}
    \\ &\qquad 1 - a_i/b_i \leq \pi_i(x) \leq 1 \quad \text{for (almost) all }x \in \mathcal{X}
    \\ &\qquad \E[\pi(X_i) \cond \filt_i] \leq \mathrm{Budget},
\end{align*}
where we assume that the domain of $\pi$ is bounded (so that there are functions that satisfy the first domain, since $\pi$ is always positive).

Our approximate solution to this is as follows: the functional gradient of our (unconstrained) loss is given by
\[ \pi \mapsto \E\left[ h\left( \frac{e_i(Y_i) - (1 - \pi(X_i)) e_i(\mu_i(X_i))}{e_i(\mu_i(X_i)) \cdot \pi(X_i)} - \log  \right) - 1 \cond X_i, \filt_i \right], \]
where $h(t) = 1/t - \log 1/t = 1/t + \log t$.
The $h$ function is a bit inconvenient for solving this problem in closed form, so, inspired by \cite{evalue-mean}, we do a Taylor approximation around some point $a$ (which turns out to later combine with the parameter to control the budget constraint); this leads to the following approximate functional gradient:
\[ \pi \mapsto \alpha_a + \beta_a/\pi_{\inf} \E\left[ \frac{e_i(Y_i)}{e_i(\mu_i(X_i))} \cond X_i, \filt_i \right] - \beta_a \frac{1 - \pi_{\inf}}{\pi_{\inf}}, \]
where $\alpha_a = \log a + 2/a - 2$ and $\beta_a = (a-1) / a^2$.

The uncontsrained solution is then given by
\[ \pi^\star(X_i) \approx -\left( \E\left[ \frac{e_i(Y_i)}{e_i(\mu_i(X_i))} \cond X_i, \filt_i \right] - 1 \right) / (\alpha_a/\beta_a + 1), \]
and KKT conditions give (in a slightly handwavy manner) that:
\begin{itemize}
    \item If the unconstrained optimum above satisfies the boundedness constraint, then that is the optimal choice;
    \item If $\alpha_a + \beta_a (\E\left[ \frac{e_i(Y_i)}{e_i(\mu_i(X_i))} \cond X_i, \filt_i \right]/\pi_{\inf} - (1 - \pi_{\inf})/\pi_{\inf}) \leq 0$, then $\pi^\star(X_i) = \pi_{\inf}$;
    \item Otherwise, $\pi^\star(X_i) = 1$.
\end{itemize}

\section{Datasets} \label{suppl:datasets}

\subsection{For Section~\ref{sec:experiment-1}}

We use the dataset of \cite{diabetes-dataset}.
It is a tabular dataset, where each row corresponds to an individual;
the targets $Y_i$ in the original dataset denote whether the individual was (i) diabetic, (ii) pre-diabetic, or (iii) neither.
For the purposes of our experiment, we only look for whether they were diabetic or not.
The covariates are effectfully responses to the following simple survey questions:

\begin{itemize}
    \item ``do you have high blood pressure?''
    \item ``do you have high cholesterol?''
    \item ``how long has it been since the last time you have checked your cholesterol levels?''
    \item ``what is your body mass index (BMI)?''
    \item ``have you smoked at least 100 cigarettes in your entire life?''
    \item ``has you ever been told you had a stroke?''
    \item ``have you been diagnosed with coronary heart disease (CHD) or myocardial infarction (MI)?''
    \item ``how much physical activity have you done in the past 30 days (excluding job)?''
    \item ``how often do you consume fruit?''
    \item ``how often do you consume vegetables?''
    \item ``how often do you consume alcohol?''
    \item ``do you have health care coverage, including health insurance, prepaid plans such as HMO, etc.?''
    \item ``Was there a time in the past 12 months when you needed to see a doctor but could not because of cost?''
    \item ``Would you say that in general your health is: [excellent / very good / good / fair / poor]''
    \item ``Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good?''
    \item ``Now thinking about your physical health, which includes physical illness and injury, for how many days during the pat 30 days was your physical health not good?''
    \item ``Do you have serious difficulty walking or climbing stairs?''
    \item ``What is your age?''
    \item ``What is your highest level of education?''
    \item ``What is your level of income?''
\end{itemize}

\subsection{For Sections~\ref{sec:experiment-2} and \ref{sec:experiment-3}}

We use the dataset of \cite{dataset-covtype}.
Upon this dataset, in a training split, we train a simple random forest classification model.
We also separate a validation split to compute the validation loss in Section~\ref{sec:experiment-2}.
At evaluation time:

\begin{itemize}
    \item For the `non-poisoned' data stream in Section~\ref{sec:experiment-2}, where the null should \emph{not} be rejected, we just use the data remaining after the training and validation splits.
    \item For the `poisoned' data stream in Section~\ref{sec:experiment-2}, we switch the label with a probability of
        \[ \mathrm{clamp}_{[0,1]}\left( \left(\frac{t}{0.5}\right)^2 \right), \]
        % poisoning_probs = (np.linspace(0, 1, len(y_later)) / 0.5)**2
        for time $t \in [0, 1]$.
    \item For the data stream in Section~\ref{sec:experiment-3}, we switch the label with a probability of
        \[ \ind[t \geq 0.3] \cdot \mathrm{clamp}_{[0,1]}\left( \left(\frac{t + 1}{5} + 0.2\right)^2 \right), \]
        for time $t \in [0, 1]$. The indicator causes a visible change in the time series, good for visualization. The remaining bit is done differently from in the previous section so that the change in the distribution is not too drastic.
\end{itemize}

\subsection{For Section~\ref{sec:experiment-4}}

We generate a random DAG with 6 nodes using the Erd√∂s-Renyi procedure, and mark the last three of these nodes as `costly'.
Relations between the nodes are given by linear functions, whose weights and biases are sampled randomly, with additional independence gaussian noise with a standard deviation of 0.4.

\end{document}
