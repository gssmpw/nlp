@inproceedings{10.1145/3583780.3615036,
 abstract = {Discovering entity mentions that are out of a Knowledge Base (KB) from texts plays a critical role in KB maintenance, but has not yet been fully explored. The current methods are mostly limited to the simple threshold-based approach and feature-based classification, and the datasets for evaluation are relatively rare. We propose BLINKout, a new BERT-based Entity Linking (EL) method which can identify mentions that do not have corresponding KB entities by matching them to a special NIL entity. To better utilize BERT, we propose new techniques including NIL entity representation and classification, with synonym enhancement. We also apply KB Pruning and Versioning strategies to automatically construct out-of-KB datasets from common in-KB EL datasets. Results on five datasets of clinical notes, biomedical publications, and Wikipedia articles in various domains show the advantages of BLINKout over existing methods to identify out-of-KB mentions for the medical ontologies, UMLS, SNOMED CT, and the general KB, WikiData.},
 address = {New York, NY, USA},
 author = {Dong, Hang and Chen, Jiaoyan and He, Yuan and Liu, Yinan and Horrocks, Ian},
 booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
 doi = {10.1145/3583780.3615036},
 isbn = {9798400701245},
 keywords = {WikiData, biomedical ontologies, entity linking, knowledge base enrichment, language models},
 location = {Birmingham, United Kingdom},
 numpages = {11},
 pages = {452–462},
 publisher = {Association for Computing Machinery},
 series = {CIKM '23},
 title = {{Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity Linking}},
 year = {2023}
}

@article{10.3233/SW-170273,
 abstract = {Named Entity Disambiguation is the task of assigning entities from a Knowledge Graph (KG) to mentions of such entities in a textual document. The state-of-the-art for this task balances two disparate sources of similarity: lexical, defined as the pairwise similarity between mentions in the text and names of entities in the KG; and semantic, defined through some graph-theoretic property of a subgraph of the KG induced by the choice of entities for each mention. Departing from previous work, our notion of semantic similarity is rooted in Information Theory and is defined as the mutual information between random walks on the disambiguation graph induced by choice of entities for each mention. We describe an iterative algorithm based on this idea, and show an extension that uses learning-to-rank, which yields further improvements. Our experimental evaluation demonstrates that this approach is robust and very competitive on well-known existing benchmarks. We also justify the need for new and more difficult benchmarks, and provide an extensive experimental comparison of our method and previous work on these new benchmarks.},
 address = {NLD},
 author = {Alani, Harith and Guo, Zhaochen and Barbosa, Denilson},
 doi = {10.3233/SW-170273},
 issn = {1570-0844},
 issue_date = {2018},
 journal = {Semantic Web Journal},
 keywords = {random walk, benchmarking, entity linking, entity disambiguation, Named entities, relatedness measure},
 month = {January},
 number = {4},
 numpages = {21},
 pages = {459–479},
 publisher = {IOS Press},
 title = {{Robust Named Entity Disambiguation with Random Walks}},
 url = {https://doi.org/10.3233/SW-170273},
 volume = {9},
 year = {2018}
}

@inproceedings{Christmann2022clocq,
author = {Christmann, Philipp and Saha Roy, Rishiraj and Weikum, Gerhard},
title = {Beyond NED: Fast and Effective Search Space Reduction for Complex Question Answering over Knowledge Bases},
year = {2022},
isbn = {9781450391320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3488560.3498488},
doi = {10.1145/3488560.3498488},
abstract = {Answering complex questions over knowledge bases (KB-QA) faces huge input data with billions of facts, involving millions of entities and thousands of predicates. For efficiency, QA systems first reduce the answer search space by identifying a set of facts that is likely to contain all answers and relevant cues. The most common technique for doing this is to apply named entity disambiguation (NED) on the question, and retrieve KB facts for the disambiguated entities. This work presents CLOCQ, an efficient method that prunes irrelevant parts of the search space using KB-aware signals. CLOCQ uses a top-k query processor over score-ordered lists of KB items that combine signals about lexical matching, relevance to the question, coherence among candidate items, and connectivity in the KB graph. Experiments with two recent QA benchmarks for complex questions demonstrate the superiority of CLOCQ over state-of-the-art baselines with respect to answer presence, size of the search space, and runtimes.},
booktitle = {Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining},
pages = {172–180},
numpages = {9},
keywords = {question answering, knowledge bases, entity linking},
location = {Virtual Event, AZ, USA},
series = {WSDM '22}
}

@misc{Gabrilovich2013,
 author = {Evgeniy Gabrilovich and Michael Ringgaard and Amarnag Subramanya},
 howpublished = {Web Download},
 month = {June},
 note = {Available at \url{http://lemurproject.org/clueweb09/} and \url{http://lemurproject.org/clueweb12/}},
 title = {{FACC1: Freebase annotation of ClueWeb corpora, Version 1 (Release date 2013-06-26, Format version 1, Correction level 0)}},
 year = {2013}
}

@misc{Graff2002Aquaint,
 author = {David Graff},
 publisher = {Linguistic Data Consortium},
 title = {The AQUAINT Corpus of English News Text},
 url = {https://catalog.ldc.upenn.edu/LDC2002T31},
 year = {2002}
}

@inproceedings{HIPE2020ExtOverview,
 address = {Thessaloniki, Greece},
 author = {Ehrmann, Maud and Romanello, Matteo and Fluckiger, Alex and Clematide, Simon},
 booktitle = {Working Notes of CLEF 2020 - Conference and Labs of the Evaluation Forum},
 doi = {10.5281/zenodo.4117566},
 pages = {38},
 title = {Extended {{Overview}} of {{CLEF HIPE}} 2020: {{Named Entity Processing}} on {{Historical Newspapers}}},
 volume = {2696},
 year = {2020}
}

@inproceedings{HIPE2020Overview,
author = {Ehrmann, Maud and Romanello, Matteo and Fl\"{u}ckiger, Alex and Clematide, Simon},
title = {{Overview of CLEF HIPE 2020: Named Entity Recognition and Linking on Historical Newspapers}},
year = {2020},
isbn = {978-3-030-58218-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-030-58219-7_21},
abstract = {This paper presents an overview of the first edition of HIPE (Identifying Historical People, Places and other Entities), a pioneering shared task dedicated to the evaluation of named entity processing on historical newspapers in French, German and English. Since its introduction some twenty years ago, named entity (NE) processing has become an essential component of virtually any text mining application and has undergone major changes. Recently, two main trends characterise its developments: the adoption of deep learning architectures and the consideration of textual material originating from historical and cultural heritage collections. While the former opens up new opportunities, the latter introduces new challenges with heterogeneous, historical and noisy inputs. In this context, the objective of HIPE, run as part of the CLEF 2020 conference, is threefold: strengthening the robustness of existing approaches on non-standard inputs, enabling performance comparison of NE processing on historical texts, and, in the long run, fostering efficient semantic indexing of historical documents. Tasks, corpora, and results of 13 participating teams are presented.},
booktitle = {Experimental IR Meets Multilinguality, Multimodality, and Interaction: 11th International Conference of the CLEF Association, CLEF 2020, Thessaloniki, Greece, September 22–25, 2020, Proceedings},
pages = {288–310},
numpages = {23},
keywords = {Named entity recognition and classification, Entity linking, Historical texts, Information extraction, Digitized newspapers, Digital humanities},
location = {Thessaloniki, Greece}
}

@inproceedings{HIPE2022Overview,
 abstract = {We present the HIPE-2022 shared task on named entity processing in multilingual historical documents. Following the success of the first CLEF-HIPE-2020 evaluation lab, this edition confronts systems with the challenges of dealing with more languages, learning domainspecific entities, and adapting to diverse annotation tag sets. HIPE-2022 is part of the ongoing efforts of the natural language processing and digital humanities communities to adapt and develop appropriate technologies to efficiently retrieve and explore information from historical texts. On such material, however, named entity processing techniques face the challenges of domain heterogeneity, input noisiness, dynamics of language, and lack of resources. In this context, the main objective of the evaluation lab is to gain new insights into the transferability of named entity processing approaches across languages, time periods, document types, and annotation tag sets.},
 address = {{Cham}},
 author = {Ehrmann, Maud and Romanello, Matteo and Doucet, Antoine and Clematide, Simon},
 booktitle = {Advances in Information Retrieval},
 doi = {10.1007/978-3-030-99739-7_44},
 editor = {Hagen, Matthias and Verberne, Suzan and Macdonald, Craig and Seifert, Christin and Balog, Krisztian and N{\o}rv{\aa}g, Kjetil and Setty, Vinay},
 file = {files/231/Ehrmann et al. - 2022 - Introducing the HIPE 2022 Shared Task Named Entit.pdf},
 isbn = {978-3-030-99738-0 978-3-030-99739-7},
 keywords = {notion},
 langid = {english},
 pages = {347--354},
 publisher = {{Springer International Publishing}},
 shorttitle = {Introducing the {{HIPE}} 2022 {{Shared Task}}},
 title = {Introducing the {{HIPE}} 2022 {{Shared Task}}: {{Named Entity Recognition}} and {{Linking}} in {{Multilingual Historical Documents}}},
 urldate = {2023-02-01},
 volume = {13186},
 year = {2022}
}

@inproceedings{Hamdi2021,
 abstract = {Named entity processing over historical texts is more and more being used due to the massive documents and archives being stored in digital libraries. However, due to the poor annotated resources of historical nature, information extraction performances fall behind those on contemporary texts. In this paper, we introduce the development of the NewsEye resource, a multilingual dataset for named entity recognition and linking enriched with stances towards named entities. The dataset is comprised of diachronic historical newspaper material published between 1850 and 1950 in French, German, Finnish, and Swedish. Such historical resource is essential in the context of developing and evaluating named entity processing systems. It evenly allows enhancing the performances of existing approaches on historical documents which enables adequate and efficient semantic indexing of historical documents on digital cultural heritage collections.},
 address = {New York, NY, USA},
 author = {Hamdi, Ahmed and Linhares Pontes, Elvys and Boros, Emanuela and Nguyen, Thi Tuyet Hai and Hackl, G\"{u}nter and Moreno, Jose G. and Doucet, Antoine},
 booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 doi = {10.1145/3404835.3463255},
 isbn = {9781450380379},
 keywords = {multilingual, diachronic historical newspapers, stance detection, entity linking, datasets, named entity recognition},
 location = {Virtual Event, Canada},
 numpages = {7},
 pages = {2328–2334},
 publisher = {Association for Computing Machinery},
 series = {SIGIR '21},
 title = {{A Multilingual Dataset for Named Entity Recognition, Entity Linking and Stance Detection in Historical Newspapers}},
 year = {2021}
}

@inproceedings{KORE2012,
 abstract = {Measuring the semantic relatedness between two entities is the basis for numerous tasks in IR, NLP, and Web-based knowledge extraction. This paper focuses on disambiguating names in a Web or text document by jointly mapping all names onto semantically related entities registered in a knowledge base. To this end, we have developed a novel notion of semantic relatedness between two entities represented as sets of weighted (multi-word) keyphrases, with consideration of partially overlapping phrases. This measure improves the quality of prior link-based models, and also eliminates the need for (usually Wikipedia-centric) explicit interlinkage between entities. Thus, our method is more versatile and can cope with long-tail and newly emerging entities that have few or no links associated with them. For efficiency, we have developed approximation techniques based on min-hash sketches and locality-sensitive hashing. Our experiments on semantic relatedness and on named entity disambiguation demonstrate the superiority of our method compared to state-of-the-art baselines.},
 address = {New York, NY, USA},
 author = {Hoffart, Johannes and Seufert, Stephan and Nguyen, Dat Ba and Theobald, Martin and Weikum, Gerhard},
 booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
 doi = {10.1145/2396761.2396832},
 isbn = {9781450311564},
 keywords = {semantic relatedness, locality-sensitive hashing, entity relatedness, entity disambiguation},
 location = {Maui, Hawaii, USA},
 numpages = {10},
 pages = {545–554},
 publisher = {Association for Computing Machinery},
 series = {CIKM '12},
 title = {{KORE: keyphrase overlap relatedness for entity disambiguation}},
 year = {2012}
}

@misc{Mitchell2005,
 address = {Philadelphia},
 author = {Alexis Mitchell and Stephanie Strassel and Shudong Huang and Ramez Zakhary},
 howpublished = {Web Download},
 publisher = {Linguistic Data Consortium},
 title = {ACE 2004 Multilingual Training Corpus LDC2005T09},
 year = {2005}
}

@inproceedings{Orlando2024,
    title = "{R}e{L}i{K}: Retrieve and {L}in{K}, Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget",
    author = "Orlando, Riccardo  and
      Huguet Cabot, Pere-Llu{\'\i}s  and
      Barba, Edoardo  and
      Navigli, Roberto",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.839",
    pages = "14114--14132",
    abstract = "Entity Linking (EL) and Relation Extraction (RE) are fundamental tasks in Natural Language Processing, serving as critical components in a wide range of applications. In this paper, we propose ReLiK, a Retriever-Reader architecture for both EL and RE, where, given an input text, the Retriever module undertakes the identification of candidate entities or relations that could potentially appear within the text. Subsequently, the Reader module is tasked to discern the pertinent retrieved entities or relations and establish their alignment with the corresponding textual spans. Notably, we put forward an innovative input representation that incorporates the candidate entities or relations alongside the text, making it possible to link entities or extract relations in a single forward pass and to fully leverage pre-trained language models contextualization capabilities, in contrast with previous Retriever-Reader-based methods, which require a forward pass for each candidate. Our formulation of EL and RE achieves state-of-the-art performance in both in-domain and out-of-domain benchmarks while using academic budget training and with up to 40x inference speed compared to competitors. Finally, we show how our architecture can be used seamlessly for Information Extraction (cIE), i.e. EL + RE, and setting a new state of the art by employing a shared Reader that simultaneously extracts entities and relations.",
}

@inproceedings{REL2020,
author = {van Hulst, Johannes M. and Hasibi, Faegheh and Dercksen, Koen and Balog, Krisztian and de Vries, Arjen P.},
title = {REL: An Entity Linker Standing on the Shoulders of Giants},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397271.3401416},
doi = {10.1145/3397271.3401416},
abstract = {Entity linking is a standard component in modern retrieval system that is often performed by third-party toolkits. Despite the plethora of open source options, it is difficult to find a single system that has a modular architecture where certain components may be replaced, does not depend on external sources, can easily be updated to newer Wikipedia versions, and, most important of all, has state-of-the-art performance. The REL system presented in this paper aims to fill that gap. Building on state-of-the-art neural components from natural language processing research, it is provided as a Python package as well as a web API. We also report on an experimental comparison against both well-established systems and the current state-of-the-art on standard entity linking benchmarks.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2197–2200},
numpages = {4},
keywords = {toolkit, entity linking, entity disambiguation, NER},
location = {Virtual Event, China},
series = {SIGIR '20}
}

@inbook{Sonar2021,
 address = {Berlin, Boston},
 author = {Sina Menzel and Hannes Schnaitter and Josefine Zinck and Vivien Petras and Clemens Neudecker and Kai Labusch and Elena Leitner and Georg Rehm},
 booktitle = {Qualität in der Inhaltserschließung},
 doi = {doi:10.1515/9783110691597-012},
 editor = {Michael Franke-Maier and Anna Kasprzik and Andreas Ledl and Hans Schürmann},
 isbn = {9783110691597},
 lastchecked = {2024-07-01},
 pages = {229--258},
 publisher = {De Gruyter Saur},
 title = {Named Entity Linking mit Wikidata und GND – Das Potenzial handkuratierter und strukturierter Datenquellen für die semantische Anreicherung von Volltexten},
 year = {2021}
}

@inproceedings{TAC2010,
 author = {Heng Ji and Ralph Grishman and H.T. Dang and K. Griffit and J. Ellis},
 booktitle = {Proceedings of the 2010 Text Analysis Conference},
 language = {English (US)},
 title = {Overview of the TAC 2010 knowledge base population track},
 year = {2010}
}

@inproceedings{agarwal-etal-2018-dianed,
    title = "dia{NED}: Time-Aware Named Entity Disambiguation for Diachronic Corpora",
    author = {Agarwal, Prabal  and
      Str{\"o}tgen, Jannik  and
      del Corro, Luciano  and
      Hoffart, Johannes  and
      Weikum, Gerhard},
    editor = "Gurevych, Iryna and Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = "July",
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/P18-2109",
    pages = "686--693",
    abstract = "Named Entity Disambiguation (NED) systems perform well on news articles and other texts covering a specific time interval. However, NED quality drops when inputs span long time periods like in archives or historic corpora. This paper presents the first time-aware method for NED that resolves ambiguities even when mention contexts give only few cues. The method is based on computing temporal signatures for entities and comparing these to the temporal contexts of input mentions. Our experiments show superior quality on a newly created diachronic corpus.",
}

@inproceedings{ayoola-etal-2022-improving,
 abstract = {Recent work in entity disambiguation (ED) has typically neglected structured knowledge base (KB) facts, and instead relied on a limited subset of KB information, such as entity descriptions or types. This limits the range of contexts in which entities can be disambiguated. To allow the use of all KB facts, as well as descriptions and types, we introduce an ED model which links entities by reasoning over a symbolic knowledge base in a fully differentiable fashion. Our model surpasses state-of-the-art baselines on six well-established ED datasets by 1.3 F1 on average. By allowing access to all KB information, our model is less reliant on popularity-based entity priors, and improves performance on the challenging ShadowLink dataset (which emphasises infrequent and ambiguous entities) by 12.7 F1.},
 address = {Seattle, United States},
 author = {Ayoola, Tom  and
Fisher, Joseph  and
Pierleoni, Andrea},
 booktitle = {Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
 doi = {10.18653/v1/2022.naacl-main.210},
 editor = {Carpuat, Marine  and
de Marneffe, Marie-Catherine  and
Meza Ruiz, Ivan Vladimir},
 month = {July},
 pages = {2899--2912},
 publisher = {Association for Computational Linguistics},
 title = {Improving Entity Disambiguation by Reasoning over a Knowledge Base},
 year = {2022}
}

@inproceedings{barba-etal-2022-extend,
    title = "{E}xt{E}n{D}: Extractive Entity Disambiguation",
    author = "Barba, Edoardo  and
      Procopio, Luigi  and
      Navigli, Roberto",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2022.acl-long.177",
    pages = "2478--2488",
    abstract = "Local models for Entity Disambiguation (ED) have today become extremely powerful, in most part thanks to the advent of large pre-trained language models. However, despite their significant performance achievements, most of these approaches frame ED through classification formulations that have intrinsic limitations, both computationally and from a modeling perspective. In contrast with this trend, here we propose ExtEnD, a novel local formulation for ED where we frame this task as a text extraction problem, and present two Transformer-based architectures that implement it. Based on experiments in and out of domain, and training over two different data regimes, we find our approach surpasses all its competitors in terms of both data efficiency and raw performance. ExtEnD outperforms its alternatives by as few as 6 F1 points on the more constrained of the two data regimes and, when moving to the other higher-resourced regime, sets a new state of the art on 4 out of 4 benchmarks under consideration, with average improvements of 0.7 F1 points overall and 1.1 F1 points out of domain. In addition, to gain better insights from our results, we also perform a fine-grained evaluation of our performances on different classes of label frequency, along with an ablation study of our architectural choices and an error analysis. We release our code and models for research purposes at \url{https://github.com/SapienzaNLP/extend}.",
}

@inproceedings{benkhedda-etal-2024-enriching,
 abstract = {Digital archive collections that have been contributed by communities, known as community-generated digital content (CGDC), are important sources of historical and cultural knowledge. However, CGDC items are not easily searchable due to semantic information being obscured within their textual metadata. In this paper, we investigate the extent to which state-of-the-art, general-domain entity linking (EL) models (i.e., BLINK, EPGEL and mGENRE) can map named entities mentioned in CGDC textual metadata, to Wikidata entities. We evaluate and compare their performance on an annotated dataset of CGDC textual metadata and provide some error analysis, in the way of informing future studies aimed at enriching CGDC metadata using entity linking methods.},
 address = {St. Julians, Malta},
 author = {Benkhedda, Youcef  and
Skapars, Adrians  and
Schlegel, Viktor  and
Nenadic, Goran  and
Batista-Navarro, Riza},
 booktitle = {Proceedings of the 8th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature (LaTeCH-CLfL 2024)},
 editor = {Bizzoni, Yuri  and
Degaetano-Ortlieb, Stefania  and
Kazantseva, Anna  and
Szpakowicz, Stan},
 month = {March},
 pages = {213--220},
 publisher = {Association for Computational Linguistics},
 title = {Enriching the Metadata of Community-Generated Digital Content through Entity Linking: An Evaluative Comparison of State-of-the-Art Models},
 url = {https://aclanthology.org/2024.latechclfl-1.20},
 year = {2024}
}

@inproceedings{blouin-etal-2024-dataset-named,
 abstract = {In this study, we present a novel historical Chinese dataset for named entity recognition, entity linking, coreference and entity relations. We use data from Chinese newspapers from 1872 to 1949 and multilingual bibliographic resources from the same period. The period and the language are the main strength of the present work, offering a resource which covers different styles and language uses, as well as the largest historical Chinese NER dataset with manual annotations from this transitional period. After detailing the selection and annotation process, we present the very first results that can be obtained from this dataset. Texts and annotations are freely downloadable from the GitHub repository.},
 address = {Torino, Italia},
 author = {Blouin, Baptiste  and
Armand, C{\'e}cile  and
Henriot, Christian},
 booktitle = {Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
 editor = {Calzolari, Nicoletta  and
Kan, Min-Yen  and
Hoste, Veronique  and
Lenci, Alessandro  and
Sakti, Sakriani  and
Xue, Nianwen},
 month = {May},
 pages = {385--394},
 publisher = {ELRA and ICCL},
 title = {A Dataset for Named Entity Recognition and Entity Linking in {C}hinese Historical Newspapers},
 url = {https://aclanthology.org/2024.lrec-main.35},
 year = {2024}
}

@inproceedings{boros2020robust,
  author    = {Emanuela Boros and
               Elvys Linhares Pontes and
               Luis Adri{\'a}n Cabrera-Diego and
               Ahmed Hamdi and
               Jose G. Moreno and
               Nicolas Sid{\`e}re and
               Antoine Doucet},
  title     = {Robust Named Entity Recognition and Linking on Historical Multilingual Documents},
  booktitle = {Working Notes of {CLEF} 2020},
  volume    = {2696},
  pages     = {1--17},
  year      = {2020},
  url       = {https://ceur-ws.org/Vol-2696/paper\_171.pdf}
}

@inproceedings{borosKnowledgebasedContextsHistorical,
  title = {Knowledge-based Contexts for Historical Named Entity Recognition and Linking},
  author = {Emanuela Boros and Carlos-Emiliano González-Gallardo and Edward Giamphy and Ahmed Hamdi and Jose G. Moreno 0001 and Antoine Doucet},
    month = {September},
  year = {2022},
  url = {http://ceur-ws.org/Vol-3180/paper-84.pdf},
  pages = {1064-1078},
  booktitle = {Proceedings of the Working Notes of CLEF 2022 - Conference and Labs of the Evaluation Forum},
  editor = {Guglielmo Faggioli and Nicola Ferro and Allan Hanbury and Martin Potthast},
  volume = {3180},
  series = {CEUR Workshop Proceedings},
  publisher = {CEUR-WS.org},
address = {Bologna, Italy}
}

@article{de-cao-etal-2022-multilingual,
    title = "Multilingual Autoregressive Entity Linking",
    author = "De Cao, Nicola  and
      Wu, Ledell  and
      Popat, Kashyap  and
      Artetxe, Mikel  and
      Goyal, Naman  and
      Plekhanov, Mikhail  and
      Zettlemoyer, Luke  and
      Cancedda, Nicola  and
      Riedel, Sebastian  and
      Petroni, Fabio",
    editor = "Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "10",
    year = "2022",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2022.tacl-1.16",
    doi = "10.1162/tacl_a_00460",
    pages = "274--290",
    abstract = "We present mGENRE, a sequence-to- sequence system for the Multilingual Entity Linking (MEL) problem{---}the task of resolving language-specific mentions to a multilingual Knowledge Base (KB). For a mention in a given language, mGENRE predicts the name of the target entity left-to-right, token-by-token in an autoregressive fashion. The autoregressive formulation allows us to effectively cross-encode mention string and entity names to capture more interactions than the standard dot product between mention and entity vectors. It also enables fast search within a large KB even for mentions that do not appear in mention tables and with no need for large-scale vector indices. While prior MEL works use a single representation for each entity, we match against entity names of as many languages as possible, which allows exploiting language connections between source input and target name. Moreover, in a zero-shot setting on languages with no training data at all, mGENRE treats the target language as a latent variable that is marginalized at prediction time. This leads to over 50{\%} improvements in average accuracy. We show the efficacy of our approach through extensive evaluation including experiments on three popular MEL benchmarks where we establish new state-of-the-art results. Source code available at \url{https://github.com/facebookresearch/GENRE}.",
}

@inproceedings{decao2021autoregressive,
 author = {Nicola {De Cao} and
Gautier Izacard and
Sebastian Riedel and
Fabio Petroni},
 booktitle = {9th International Conference on Learning Representations},
 publisher = {OpenReview.net},
 title = {Autoregressive Entity Retrieval},
 url = {https://openreview.net/forum?id=5k8F6UU39V},
address = {Online, Austria},
month = {May},
 year = {2021}
}

@inproceedings{ehrmann2016diachronic,
 address = {Bochum, Germany},
 author = {Ehrmann, Maud and Colavizza, Giovanni and Rochat, Yannick and Kaplan, Frédéric},
 booktitle = {Proceedings of the 13th Conference on Natural Language Processing (KONVENS 2016)},
 editor = {Dipper, Stephanie and Neubarth, Friedrich and Zinsmeister, Heike},
 keywords = {named entities; evaluation; historical newspapers; digital humanities; natural language processing},
 month = {September 19--21},
 pages = {97--107},
 publisher = {Bochum, Germany, Bochumer Linguistische Arbeitsberichte},
 title = {{Diachronic Evaluation of NER Systems on Old Newspapers}},
 url = {https://infoscience.epfl.ch/record/221391?v=pdf},
 year = {2016}
}

@article{ehrmannNamedEntityRecognition2023,
 abstract = {After decades of massive digitisation, an unprecedented number of historical documents are available in digital format, along with their machine-readable texts. While this represents a major step forward with respect to preservation and accessibility, it also opens up new opportunities in terms of content mining and the next fundamental challenge is to develop appropriate technologies to efficiently search, retrieve, and explore information from this ‘big data of the past’. Among semantic indexing opportunities, the recognition and classification of named entities are in great demand among humanities scholars. Yet, named entity recognition (NER) systems are heavily challenged with diverse, historical, and noisy inputs. In this survey, we present the array of challenges posed by historical documents to NER, inventory existing resources, describe the main approaches deployed so far, and identify key priorities for future developments.},
 address = {New York, NY, USA},
 articleno = {27},
 author = {Ehrmann, Maud and Hamdi, Ahmed and Pontes, Elvys Linhares and Romanello, Matteo and Doucet, Antoine},
 doi = {10.1145/3604931},
 issn = {0360-0300},
 issue_date = {February 2024},
 journal = {ACM Computing Surveys},
 keywords = {digital humanities, natural language processing, historical documents, Named entity recognition and classification},
 month = {sep},
 number = {2},
 numpages = {47},
 publisher = {Association for Computing Machinery},
 title = {Named Entity Recognition and Classification in Historical Documents: A Survey},
 url = {https://doi.org/10.1145/3604931},
 volume = {56},
 year = {2023}
}

@article{guellilEntityLinkingEnglish2024c,
 abstract = {Extracting named entities text forms the basis for many crucial tasks such as information retrieval and extraction, machine translation, opinion mining, sentiment analysis and question answering. This paper presents a survey of the research literature on named entity linking, including named entity recognition and disambiguation. We present 200 works by focusing on 43 papers (5 surveys and 38 research works). We also describe and classify 56 resources, including 25 tools and 31 corpora. We focus on the most recent papers, where more than 95\% of the described research works are after 2015. To show the efficiency of our construction methodology and the importance of this state of the art, we compare it to other surveys presented in the research literature, which were based on different criteria (such as the domain, novelty and presented models and resources). We also present a set of open issues (including the dominance of the English language in the proposed studies and the frequent use of NER rather than the end-to-end systems proposing NED and EL) related to entity linking based on the research questions that this survey aims to answer.},
 author = {Guellil, Imane and {Garcia-Dominguez}, Antonio and Lewis, Peter R. and Hussain, Shakeel and Smith, Geoffrey},
 doi = {10.1007/s10115-023-02059-2},
 issn = {0219-3116},
 journal = {Knowledge and Information Systems},
 month = {July},
 number = {7},
 pages = {3773--3824},
 title = {Entity Linking for {{English}} and Other Languages: A Survey},
 volume = {66},
 year = {2024}
}

@inproceedings{hoffart-etal-2011-robust,
 address = {Edinburgh, Scotland, UK.},
 author = {Hoffart, Johannes  and
Yosef, Mohamed Amir  and
Bordino, Ilaria  and
F{\"u}rstenau, Hagen  and
Pinkal, Manfred  and
Spaniol, Marc  and
Taneva, Bilyana  and
Thater, Stefan  and
Weikum, Gerhard},
 booktitle = {Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing},
 month = {July},
 pages = {782--792},
 publisher = {Association for Computational Linguistics},
 title = {Robust Disambiguation of Named Entities in Text},
 url = {https://aclanthology.org/D11-1072},
 year = {2011}
}

@inproceedings{kolitsas-etal-2018-end,
 abstract = {Entity Linking (EL) is an essential task for semantic text understanding and information extraction. Popular methods separately address the Mention Detection (MD) and Entity Disambiguation (ED) stages of EL, without leveraging their mutual dependency. We here propose the first neural end-to-end EL system that jointly discovers and links entities in a text document. The main idea is to consider all possible spans as potential mentions and learn contextual similarity scores over their entity candidates that are useful for both MD and ED decisions. Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features. Empirically, we show that our end-to-end method significantly outperforms popular systems on the Gerbil platform when enough training data is available. Conversely, if testing datasets follow different annotation conventions compared to the training set (e.g. queries/ tweets vs news documents), our ED model coupled with a traditional NER system offers the best or second best EL accuracy.},
 address = {Brussels, Belgium},
 author = {Kolitsas, Nikolaos  and
Ganea, Octavian-Eugen  and
Hofmann, Thomas},
 booktitle = {Proceedings of the 22nd Conference on Computational Natural Language Learning},
 doi = {10.18653/v1/K18-1050},
 editor = {Korhonen, Anna  and
Titov, Ivan},
 month = {October},
 pages = {519--529},
 publisher = {Association for Computational Linguistics},
 title = {End-to-End Neural Entity Linking},
 year = {2018}
}

@article{linharespontes2022melhissa,
 author = {E. Linhares Pontes and L. A. Cabrera-Diego and J. G. Moreno and E. Boros and A. Hamdi and A. Doucet and N. Sid{\`e}re and M. Coustaty},
 journal = {International Journal on Digital Libraries},
 pages = {133--160},
 title = {Melhissa: a multilingual entity linking architecture for historical press articles},
 volume = {23},
 year = {2022}
}

@article{mollerSurveyEnglishEntity2022,
 abstract = {Wikidata is a frequently updated, community-driven, and multilingual knowledge graph. Hence, Wikidata is an attractive basis for Entity Linking, which is evident by the recent increase in published papers. This survey focuses on four subjects: (1) Wh},
 author = {M{\"o}ller, Cedric and Lehmann, Jens and Usbeck, Ricardo},
 doi = {10.3233/SW-212865},
 file = {files/1122/Möller et al. - 2022 - Survey on English Entity Linking on Wikidata Data.pdf},
 issn = {1570-0844},
 journal = {Semantic Web},
 langid = {english},
 month = {January},
 number = {6},
 pages = {925--966},
 publisher = {{IOS Press}},
 shorttitle = {Survey on {{English Entity Linking}} on {{Wikidata}}},
 title = {Survey on {{English Entity Linking}} on {{Wikidata}}: {{Datasets}} and Approaches},
 urldate = {2023-04-21},
 volume = {13},
 year = {2022}
}

@article{plekhanov2023multilingual,
 author = {Plekhanov, Mikhail and Kassner, Nora and Popat, Kashyap and Martin, Louis and Merello, Simone and Kozlovskii, Borislav and Dreyer, Fr{\'e}d{\'e}ric A and Cancedda, Nicola},
 journal = {arXiv preprint arXiv:2306.08896},
 title = {Multilingual end to end entity linking},
 year = {2023}
}

@inproceedings{provatorova-etal-2021-robustness,
 abstract = {Entity disambiguation (ED) is the last step of entity linking (EL), when candidate entities are reranked according to the context they appear in. All datasets for training and evaluating models for EL consist of convenience samples, such as news articles and tweets, that propagate the prior probability bias of the entity distribution towards more frequently occurring entities. It was shown that the performance of the EL systems on such datasets is overestimated since it is possible to obtain higher accuracy scores by merely learning the prior. To provide a more adequate evaluation benchmark, we introduce the ShadowLink dataset, which includes 16K short text snippets annotated with entity mentions. We evaluate and report the performance of popular EL systems on the ShadowLink benchmark. The results show a considerable difference in accuracy between more and less common entities for all of the EL systems under evaluation, demonstrating the effect of prior probability bias and entity overshadowing.},
 address = {Online and Punta Cana, Dominican Republic},
 author = {Provatorova, Vera  and
Bhargav, Samarth  and
Vakulenko, Svitlana  and
Kanoulas, Evangelos},
 booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
 doi = {10.18653/v1/2021.emnlp-main.820},
 editor = {Moens, Marie-Francine  and
Huang, Xuanjing  and
Specia, Lucia  and
Yih, Scott Wen-tau},
 month = {November},
 pages = {10501--10510},
 publisher = {Association for Computational Linguistics},
 title = {{Robustness Evaluation of Entity Disambiguation Using Prior Probes: the Case of Entity Overshadowing}},
 year = {2021}
}

@inproceedings{santini2022vasari,
 author = {Cristian Santini and
Mary Ann Tan and
Oleksandra Bruns and
Tabea Tietz and
Etienne Posthumus and
Harald Sack},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/qurator/SantiniTBTPS22.bib},
 booktitle = {Proceedings of the Third Conference on Digital Curation Technologies
(Qurator 2022)},
 editor = {Adrian Paschke and
Georg Rehm and
Clemens Neudecker and
Lydia Pintscher},
 publisher = {CEUR-WS.org},
 series = {{CEUR} Workshop Proceedings},
 timestamp = {Fri, 10 Mar 2023 16:22:53 +0100},
 title = {Knowledge Extraction for Art History: the Case of Vasari's The Lives
of The Artists},
 url = {https://ceur-ws.org/Vol-3234/paper7.pdf},
 volume = {3234},
address = {Berlin, Germany},
month = {September},
 year = {2022}
}

@article{sevgiliNeuralEntityLinking2022,
 abstract = {This survey presents a comprehensive description of recent neural entity linking (EL) systems developed since 2015 as a result of the ''deep learning revolution'' in natural language processing. Its goal is to systemize design features of neural entity},
 author = {Sevgili, {\"O}zge and Shelmanov, Artem and Arkhipov, Mikhail and Panchenko, Alexander and Biemann, Chris},
 doi = {10.3233/SW-222986},
 file = {files/1120/Sevgili et al. - 2022 - Neural entity linking A&nbsp\;survey of models bas.pdf},
 issn = {1570-0844},
 journal = {Semantic Web},
 langid = {english},
 month = {January},
 number = {3},
 pages = {527--570},
 publisher = {{IOS Press}},
 shorttitle = {Neural Entity Linking},
 title = {{Neural Entity Linking: A Survey of Models Based on Deep Learning}},
 urldate = {2023-04-21},
 volume = {13},
 year = {2022}
}

@inproceedings{tedeschi-etal-2021-named-entity,
 abstract = {Entity Linking (EL) systems have achieved impressive results on standard benchmarks mainly thanks to the contextualized representations provided by recent pretrained language models. However, such systems still require massive amounts of data {--} millions of labeled examples {--} to perform at their best, with training times that often exceed several days, especially when limited computational resources are available. In this paper, we look at how Named Entity Recognition (NER) can be exploited to narrow the gap between EL systems trained on high and low amounts of labeled data. More specifically, we show how and to what extent an EL system can benefit from NER to enhance its entity representations, improve candidate selection, select more effective negative samples and enforce hard and soft constraints on its output entities. We release our software {--} code and model checkpoints {--} at \url{https://github.com/Babelscape/ner4el}.},
 address = {Punta Cana, Dominican Republic},
 author = {Tedeschi, Simone  and
Conia, Simone  and
Cecconi, Francesco  and
Navigli, Roberto},
 booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2021},
 doi = {10.18653/v1/2021.findings-emnlp.220},
 editor = {Moens, Marie-Francine  and
Huang, Xuanjing  and
Specia, Lucia  and
Yih, Scott Wen-tau},
 month = {November},
 pages = {2584--2596},
 publisher = {Association for Computational Linguistics},
 title = {{N}amed {E}ntity {R}ecognition for {E}ntity {L}inking: {W}hat Works and What{'}s Next},
 year = {2021}
}

@inproceedings{zhu-etal-2023-learn,
 abstract = {Entity linking models have achieved significant success via utilizing pretrained language models to capture semantic features. However, the NIL prediction problem, which aims to identify mentions without a corresponding entity in the knowledge base, has received insufficient attention. We categorize mentions linking to NIL into Missing Entity and Non-Entity Phrase, and propose an entity linking dataset NEL that focuses on the NIL prediction problem.NEL takes ambiguous entities as seeds, collects relevant mention context in the Wikipedia corpus, and ensures the presence of mentions linking to NIL by human annotation and entity masking. We conduct a series of experiments with the widely used bi-encoder and cross-encoder entity linking models, results show that both types of NIL mentions in training data have a significant influence on the accuracy of NIL prediction. Our code and dataset can be accessed at \url{https://github.com/solitaryzero/NIL_EL}.},
 address = {Toronto, Canada},
 author = {Zhu, Fangwei  and
Yu, Jifan  and
Jin, Hailong  and
Hou, Lei  and
Li, Juanzi  and
Sui, Zhifang},
 booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
 doi = {10.18653/v1/2023.findings-acl.690},
 editor = {Rogers, Anna  and
Boyd-Graber, Jordan  and
Okazaki, Naoaki},
 month = {July},
 pages = {10846--10860},
 publisher = {Association for Computational Linguistics},
 title = {Learn to Not Link: Exploring {NIL} Prediction in Entity Linking},
 year = {2023}
}

