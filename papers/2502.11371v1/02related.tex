\subsection{Retrieval-Augmented Generation}
Retrieval-Augmented Generation (RAG) has been widely applied to enhance the performance of Large Language Models (LLMs) by retrieving relevant information from external sources, addressing the limitation of LLMs' restricted context windows, improving factual accuracy, and mitigating hallucinations~\cite{fan2024survey, gao2023retrieval}. Most RAG systems primarily process text data by first splitting it into chunks~\cite{finardi2024chronicles}. When a query is received, RAG retrieves relevant chunks either through lexical search~\cite{ram2023context} or by computing semantic similarity~\cite{karpukhin2020dense}, embeddings both the query and text chunks into a shared vector space. Advanced techniques, such as pre-retrieval processing~\cite{ma2023query, zheng2023take} and post-retrieval processing~\cite{dong2024don, xu2023recomp}, as well as fine-tuning strategies~\cite{li2023structure}, have further enhanced RAG’s effectiveness across various domains, including QA)~\cite{yan2024corrective}, dialogue generation~\cite{izacard2023atlas}, and text summarization~\cite{jiang2023active}.

Several studies have evaluated the effectiveness of RAG systems across various tasks~\cite{yu2024evaluation, chen2024benchmarking, es2023ragas}, such as multi-hop question answering~\cite{tang2024multihop}, biomedical question answering~\cite{xiong2024benchmarking}, and text generation~\cite{liu2023recall}. However, no existing study has simultaneously and systematically evaluated and compared RAG and GraphRAG on these general text-based tasks.
% \yu{However, no existing study has simultaneously and systematically evaluated and compared RAG and GraphRAG on these general tasks. Add simultaneously to highlight our novelty is not evaluate any of them but at the same time and so we can compare.}

\begin{figure*}[!htb]
    \centering
   \includegraphics[width=\linewidth]{figures/RAGGraphRAG1.pdf}
    \caption{The illustration of RAG, KG-based GraphRAGs and Community-based GraphRAGs.}
    \label{fig:framework}
    \vspace{-0.2in}
\end{figure*}

\subsection{Graph Retrieval-Augmented Generation}
While RAG primarily processes text data, many real-world scenarios involve graph-structured data, such as knowledge graphs (KGs), social graphs, and molecular graphs~\cite{xia2021graph, ma2021deep}. GraphRAG~\cite{han2024retrieval, peng2024graph} aims to retrieve information from various types of graph-structured data. The inherent structure of graphs enhances retrieval by capturing relationships between connected nodes. For example, hyperlinks between documents can improve retrieval effectiveness in question answering tasks\cite{li2022dynamic}.  Currently, most GraphRAG studies focus on retrieving information from existing KGs for downstream tasks such as KG-based QA~\cite{tian2024graph, yasunaga2021qa} and Fact-Checking~\cite{kim2023factkg}. 
% The retrieved information can be subgraphs~\cite{he2024g} relevant to the query or reasoning paths~\cite{luo2023reasoning} that facilitate inference. 

Despite leveraging the existing graphs, recent studies have explored incorporating graph construction into GraphRAG to enhance text-based tasks. For example, \citet{dong2024don} construct document graphs using Abstract Meaning Representation (AMR) to improve document ranking. \citet{edge2024local} construct graphs from documents using LLMs, where nodes represent entities and edges capture relationships between them. Based on these graphs, they generate hierarchical communities and corresponding community summaries or reports. Their approach focuses on the global query summarization task, retrieving information from both the constructed graphs and their hierarchical communities. Additionally, \citet{han2025reasoning} propose an iterative graph construction approach using LLMs to improve reasoning tasks.
% \yu{Here I feel we spend so much context on introducing graph-based GraphRAG. However, the motivation of this work (also in the introduction part) is more around the issue of GraphRAG applied on text data. So it might be better to  emphasize more on that aspect}

These studies highlight the potential of GraphRAG in processing text-based tasks by constructing graphs from textual data.
However, their focus is limited to specific tasks and evaluation settings. It remains unclear how GraphRAG performs on general text-based tasks compared to RAG. More importantly, when and how should GraphRAG be applied to such tasks for optimal effectiveness? Our work aims to bridge this gap by systematically evaluating GraphRAG and comparing it with RAG on general text-based tasks.


% However, most existing studies focus on specific tasks and datasets, and there is no systematic evaluation—like those conducted for RAG—to assess the effectiveness of GraphRAG on text-based tasks using widely adopted datasets and evaluation metrics.\yu{I think here the thing is if we spend so much context on graph-based GraphRAG, then our evaluation should also be in that regard. However, our systematically evaluation is on GraphRAG for traditional text data. It might be better to focus our narratives more on that perspective.} Our work aims to fill this gap by systematically evaluating GraphRAG and comparing it with RAG.