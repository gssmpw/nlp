In this section, we introduce the details of our evaluation framework. We primarily evaluate one representative RAG system and two representative GraphRAG systems, as illustrated in Figure~\ref{fig:framework}.

% \jt{briefly intro figure 1 here}

\subsection{RAG}
\vspace{-0.1in}
We adopt a representative semantic similarity-based retrieval approach as our RAG method~\cite{karpukhin2020dense}. Specifically, we first split the text into chunks, each containing approximately 256 tokens. For indexing, we use OpenAIâ€™s text-embedding-ada-002 model, which has demonstrated effectiveness across various tasks~\cite{nussbaum2024nomic}. For each query, we retrieve chunks with Top-10 similarity scores. To generate responses, we employ two open-source models of different sizes: Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct~\cite{dubey2024llama}.

For single-document tasks, we generate a separate RAG system for each document, ensuring that queries corresponding to a specific document are processed within its respective indexed chunk pool. For multi-document tasks, we use a shared RAG system by indexing all documents together.

\vspace{-0.1in}
\subsection{GraphRAG}

We select two representative GraphRAG methods for a comprehensive evaluation, as shown in Figure~\ref{fig:framework}, namely KG-based GraphRAG and Community-based GraphRAG.

In the KG-based GraphRAG (KG-GraphRAG)~\cite{Liu_LlamaIndex_2022}, a knowledge graph is first constructed from text chunks using LLMs through triplet extraction. When a query is received, its entities are extracted and matched to those in the constructed KG using LLMs. The retrieval process then traverses the graph from the matched entities and gathers triplets \textit{(head, relation, tail)} from their multi-hop neighbors as the retrieved content. Additionally, for each triplet, we can retrieve the corresponding text associated with it. We define two variants of KG-GraphRAG: {\bf (1)} {\it KG-GraphRAG (Triplets)}, which retrieves only the triplets, and {\bf (2)} {\it KG-GraphRAG (Triplets+Text)}, which retrieves both the triplets and their associated source text. We implement the KG-GraphRAG methods using LlamaIndex~\cite{Liu_LlamaIndex_2022}~\footnote{https://www.llamaindex.ai/}.


For the Community-based GraphRAG~\cite{edge2024local}, in addition to generating KGs using LLMs, hierarchical communities are constructed using graph community detection algorithms, as shown in Figure~\ref{fig:framework}. Each community is associated with a corresponding text summary or report, where lower-level communities contain detailed information from the original text. The higher-level communities further provide summaries of the lower-level communities. Due to the hierarchical community structure, there are two primary retrieval methods for retrieving relevant information given a query: {\bf Local Search and Global Search}.  In Local Search, entities, relations, their descriptions, and lower-level community reports are retrieved based on entity matching between the query's extracted entities and the constructed graph. We refer to this method as {\it Community-GraphRAG (Local)}. In Global Search, only high-level community summaries are retrieved based on semantic similarity to the query. We refer to this method as {\it Community-GraphRAG (Global)}. The Community-GraphRAG methods are implemented using Microsoft GraphRAG~\cite{edge2024local}\footnote{https://microsoft.github.io/graphrag}. 
% \yu{Would it be more clear if we can also visualize such second-level ablation in Figure 1, e.g., KG-GraphRAG(Triplets)/KG-GraphRAG(Triplets+Text)/Community-GraphRAG(Global)/Community-GraphRAG.}

To ensure a fair comparison, we adopt the same settings for both RAG and GraphRAG methods. This includes the chunking strategy, embedding model, and LLMs. We select two representative RAG tasks, i.e., Question Answering and Query-based Summarization, to evaluate RAG and GraphRAG simultaneously.

% \yu{missing something?}

