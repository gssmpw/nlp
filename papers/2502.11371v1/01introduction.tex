Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to enhance downstream tasks by retrieving relevant knowledge from external data sources. It has achieved remarkable success in various real-world applications, such as healthcare~\citep{xu2024ram}, law~\citep{wiratunga2024cbr}, finance~\citep{zhang2023enhancing}, and education~\citep{miladi2024leveraging}. This success has been further amplified with the advent of Large Language Models (LLMs), as integrating RAG with LLMs significantly improves their faithfulness
% \yu{reliabiltiy is more referring to uncertainty quantification, here probably a better word is "faithfulness/accuracy"} 
by mitigating hallucinations, reducing privacy risks, and enhancing robustness~\cite{zhao2023survey, huang2023survey}. In most existing RAG systems, retrieval is primarily conducted from text databases using lexical and semantic search.

Graphs, as a fundamental data structure, encode rich relational information and have been extensively utilized across real-world domains, including knowledge representation, social network analysis, and biomedical research~\cite{wu2020comprehensive, ma2021deep, wu2023survey}. Motivated by this, GraphRAG has recently gained attention for retrieving graph-structured data, 
% \yu{structured graph data sounds weird, maybe graph-structured data?}
such as knowledge graphs (KGs) and molecular graphs~\citep{han2024retrieval, peng2024graph}. Beyond leveraging existing graphs, GraphRAG has also demonstrated its effectiveness for text-based tasks after
% \yu{since GraphRAG has never include any techniques on constructing graphs, probably change by with after?} 
structuring implicit knowledge from text into graph representations, benefiting applications such as global summarization~\cite{edge2024local, zhang2024graph}, planning~\cite{lin2024graph} and reasoning~\cite{han2025reasoning}. 

% While these studies highlight the potential of GraphRAG for text-based tasks, GraphRAG research has largely been limited to specific tasks and datasets
% \yu{If we aim to motivate our study on whether we should do GraphRAG on text data, why we need to say "GraphRAG research has largely been limited to specific tasks and datasets?"}. 
% While these studies highlight the potential of GraphRAG for text-based tasks, they mainly focus on specific tasks and datasets.
% For instance, \citet{edge2024local} generates general queries using LLMs for evaluating global summarization but does not consider other types of queries. Additionally, the use of LLM-based evaluation methods may introduce position bias, as discussed in Section~\ref{} \yu{Again here, I am not sure the connection between "there are some problems limiting GraphRAG usage" and the main objective "when to use GraphRAG and when use, how to build the graph."}. These task-specific limitations and evaluation biases leave GraphRAGâ€™s general effectiveness and broader applicability underexplored \harry{Think we need to be clearer that we're talking about cases where the graph is automatically constructed and not given (I know this is mentioned earlier). As such, the natural question is whether we should even be converting it to a graph in the first place and if so how should we be? Currently I think some people may get confused}  Therefore, it is unclear when to choose RAG or GraphRAG for general tasks, as their relative advantages across different scenarios have not been systematically analyzed. \yu{I share the same feeling here as it is still unclear to me what the question we are aiming to answer here. Are we referring to "Whether we should use GraphRAG" or "Whether we should transform the problem into graph and use GraphRAG"? Also I slightly feel some of the above claims are not so relevant to the questions we aim to solve.}

% \hy{This paragraph needs to be further checked.}
% While previous studies highlight the potential of GraphRAG for text-based tasks, they primarily focus on specific tasks and well-designed datasets \harry{Not obvious what the problem with this is. Maybe we can say that these datasets are too well-designed and not representative of the performance GraphRAG in real-world scenarios. Because in real applications we don't have clean datasets}. However, it remains unclear whether this success can generalize to broader text-based tasks where sequential text data is converted into graph-structured representations and processed using GraphRAG. Additionally, what types of scenarios benefit from the use of GraphRAG compared to a traditional RAG? \harry{this second sentence seems a little random. Has nothing to do with the previous sentence. Probably could use a better segue}


While previous studies have demonstrated the potential of GraphRAG for text-based tasks by converting sequential text into graphs, most of them primarily focus on specific tasks and well-designed datasets. Consequently, the applicability of GraphRAG to broader, real-world text-based tasks remains unclear, particularly when compared to RAG, which has seen widespread adoption across diverse applications. This raises a critical question: {\it What are the advantages and disadvantages of applying GraphRAG to general text-based tasks compared to RAG?}

To bridge this gap, we systematically evaluate the performance of RAG and GraphRAG on general text-based tasks using widely adopted datasets, including Question Answering and Query-based Summarization. Specifically, we assess two representative GraphRAG methods: {\bf (1)} Knowledge Graph-based GraphRAG~\cite{Liu_LlamaIndex_2022}, which extracts a Knowledge Graph (KG) from text and performs retrieval solely based on the KG and {\bf (2)} Community-based GraphRAG~\citep{edge2024local}, which retrieves information not only from the constructed KG but also from hierarchical communities within the graph. For the Question Answering task, we conduct experiments on both single-hop and multi-hop QA under single-document and multi-document scenarios. Similarly, for the Query-based Summarization task, we evaluate both single-document and multi-document summarization to comprehensively assess the effectiveness of RAG and GraphRAG.

Based on our comprehensive evaluation, we conduct an in-depth analysis of the strengths and weaknesses of RAG and GraphRAG across different tasks. Our findings reveal that RAG and GraphRAG are complementary, each excelling in different aspects. 
% For instance\yu{Can we remove the "For instance" but just draw the following general conclusion and insights?} \harry{Agree with Yu. We can say - ``For the task of QA, we observe that ...''}, 
For the Question Answering task, we observe that RAG performs better on single-hop questions and those requiring detailed information, while GraphRAG is more effective for multi-hop questions. In the Query-based Summarization task, RAG captures fine-grained details, whereas GraphRAG generates more diverse and multi-faceted summaries. Building on these insights, we investigate two strategies from different perspectives to integrate their unique strengths and enhance the overall performance. Our main contributions are as follows:
\begin{itemize}[leftmargin=*, itemsep=1pt, parsep=0pt]
    \item \textbf{Systematical Evaluation }: This is the very first work to systematically evaluate and compare RAG and GraphRAG on text-based tasks using widely adopted datasets and evaluations. 
    % \yu{not sure but I somehow feel this cannot be our novelty as many works conduct RAG evaluation and many other works conduct GraphRAG evaluation. Probably, we can consider merge the first and second one saying this is the very first work systematically evaluate and compare RAG and GraphRAG on text-based tasks, demonstrating their complementary advantages across different queries targeting different goals.}
    \item \textbf{Task-Specific Insights}: We provide an in-depth analysis of the distinct strengths of RAG and GraphRAG, demonstrating their complementary advantages across different types of queries and objectives.
    \item \textbf{Hybrid Retrieval Strategies:} Based on our findings on the unique strengths of RAG and GraphRAG, we propose two strategies to improve overall performance: (1) Selection, where queries are dynamically assigned to either RAG or GraphRAG based on their characteristics, and (2) Integration, where both methods are integrated to leverage their complementary strengths.
    % \yu{Can we be a little bit more concrete here, e.g., how based on our findings, we propose what kind of two strategies? Not so specific but also current one feel a little bit more general.}
    \item \textbf{Challenges and Future Directions:} We discuss the limitations of current GraphRAG approaches and outline potential future research directions for broader applicability.
\end{itemize}
