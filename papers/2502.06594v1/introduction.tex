\section{Introduction}
\label{sec:intro}
The market introduction of SAE-Level-3 automated driving systems in the European Union and the UK requires active regulatory acts to enable and implement type approval, commercial operation, as well as public-road testing.
The type approval system is often referred to as a way to ensure a ``safe'' market introduction of new technologies, while having a reputation of potentially slowing down innovation processes.

For automated vehicles, the need for a-priori enabling regulation creates three main challenges:
First, regulatory bodies must create laws \emph{before} a technology can be introduced in the regulated market.
This can become a competitive disadvantage when compared to target markets, such as the US, that employ a system of self-certification.
Second, regulatory bodies must establish an appropriate level of technical expertise.
This ensures that the enacted laws and regulations support the introduction of new technologies, rather than hindering them unintentionally due to lacking technical feasibility.
Third, the laws and acts must be written in a way that provides sufficient legal certainty for companies developing automated vehicles while avoiding overregulation, which could cause additional competitive disadvantages compared to other markets.

This paper will focus on the third challenge.
Concretizing regulation can be done in several ways.
One option is to provide concrete metrics and checklists that must be delivered by manufacturers to prove that the systems are ``safe enough''.
A second way of concretization is to introduce concise terminology regarding the concepts of ``safety'' and ``risk'':
One of the goals related to the type approval system, is to bind companies by regulation to prove that their systems are ``safe'' \emph{before} market introduction.

However, in everyday language, ``safety'' and ``risk'' constitute so-called ``open'' or ``empty signifiers'' \parencite{fleischer2023, buchanan2010} (cf. \cref{sec:related-work}) which means that the words do not carry precise semantic meanings in general language.
Different stakeholders in transdisciplinary (or even inter- and intradisciplinary) discussions may thus attribute their own understanding to both terms.
In consequence, stakeholders involved in discussions can seemingly agree on the importance of ``safe'' automated vehicles while having different understandings of what ``safe'' actually means.
In this regard, precise regulation requires the clear definition of such floating signifiers to ensure a common understanding of terms between regulators. 

While this understanding is key between engineers and regulators, even in engineering disciplines, the established technical notions of ``safety'' and ``risk'', derived from hazards to the health and life of humans (in short: physical harm), are currently coming under scrutiny \parencite{koopman2024}:
As automated vehicles are part of a larger sociotechnical system of systems \parencite{koopman2024,salem2024}, there are arguments that also technical notions should, e.g., include ethical or legal considerations that go beyond physical harm.

We want to raise awareness of potential issues that can be caused by differing (implied) understandings regarding the concepts of safety and risk and provide recommendations to regulators how terminology can be improved.

 This paper is organized as follows: \Cref{sec:related-work} gives an overview of current discussions regarding the perception of the concepts of ``safety'' and ``risk'' in the field of automated driving.
Based on the findings from the literature, we review current European regulation (\Cref{sec:analysis}), including the ``EU Implementing Act'' (Regulation (EU) 2022/1426 \parencite{eu1426}), the German Implementing Regulation (AFGBV \parencite{afgbv}), as well as the 2024 UK Automated Vehicles Act \parencite{ukav2024} (``UK AV Act'') regarding their understandings of the concepts of ``safety'' and ``risk''.
\Cref{sec:conclusion} provides concluding recommendations for making  regulation more concise and less prone to misunderstandings.
