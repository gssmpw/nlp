\section{Related Work}
\label{sec:related-work}
The need for clear terminology when it comes to communication about ``risk'' and ``safety'' is not particular to the field of automated driving.
A core concern in the fields of risk research and risk communication \parencite{renn1998} is to establish well-grounded, ideally commonly understandable \parencite{sellnow2009}, terminology between different stakeholders, e.g., the general public, regulatory bodies, policymakers, industry, or public institutions such as non-governmental organizations (NGOs) \parencite{fischhoff1984,renn1998,christensen2003}.
In this context, \citeauthor{fischhoff1984} demand ``[\ldots] an explicit and accepted definition of the term `risk'[\ldots]'' \parencite[123]{fischhoff1984}, noting that the definition of ``risk'' is ``inherently controversial'' \parencite[124]{fischhoff1984}.

\citeauthor{christensen2003} note that deviating terminology between stakeholders can derail discussions from their ``core issue(s)'' \parencite[182]{christensen2003}.
They specifically include terminology that is related to ``identifying, estimating, regulating, and communicating risk'' \parencite[182]{christensen2003}, hence including all the above-mentioned stakeholders in their argument.
The authors analyze several references from different regulatory bodies and NGOs such as the European Commission, the UN/OECD, the US-EPA, or ISO/IEC (specifically ISO/IEC Guide 51 \parencite{iso51}).
\citeauthor{christensen2003} \parencite{christensen2003} discuss, explain, and clarify applications of terms and views related to risk associated sciences to facilitate communication between stakeholder groups.
By not providing a fully consolidated terminology, they acknowledge that, while there must be a fundamental consensus among stakeholders, communication always has to be tailored to the communicating parties.
In the following sections of the paper, we will mainly consider regulators communicating to industry who is implementing automated driving technology.

The need for clear and consistent communication about risks related to autonomous systems in general is highlighted in \parencite{wmg2023}.
The report emphasizes that it is crucial to identify \emph{who} communicates \emph{how} about \emph{what} related to the communication about safety-critical autonomous systems.
As \parencite{christensen2003}, the authors explicitly stress that messages related to safety assurance and their content should be tailored to the relevant audiences.
According to \parencite{wmg2023}, this is particularly important for calibrating the expectations of different stakeholders and for raising awareness for the limitations of autonomous systems' capabilities.

Different concepts of ``risk'' and ``safety'' for automated driving systems have, e.g., been discussed in \parencite{koopman2024} or \parencite{salem2024}.
\citeauthor{koopman2024} \parencite{koopman2024} review automotive safety standards (ISO~26262:2018 \parencite{iso2018}, ISO~21448:2022 \parencite{iso21448}, ANSI/UL4600 \parencite{ul4600}) and additional resources from the German Ethics Commission \parencite{difabio2017} to the US National Highway Traffic Safety Administration for their conceptualizations of ``safety''.
They provide additional examples of ``safety problems'' related to automated driving systems which are not covered by the purely technical definitions assumed in ISO~26262 and ISO~21448.
The authors discuss that risk and safety for automated vehicles should be discussed in a more nuanced way than only considering technical definitions grounded in ``net (physical or monetary) harm''.
However, the discussion related to ``risk'' falls slightly short, not acknowledging that existing risk definitions (e.g., \parencite{fischhoff1984,renn1998}) already allow for broader discussions beyond ``net harm''.
While the newly proposed risk definition does include the influence of ``importance for stakeholders'', which allows a more interdisciplinary view on risk, the risk definition is slightly derailed by the introduction of the additional term ``loss''.
``Loss'' is defined in a slightly broader sense, compared to harm in ISO Guide~51 (see below), including ``negative societal externalities'' and ``injury and death of animals''.
While this extends technical notions of risk, it mainly shifts complexity in the terminology, addressing rather the effects of inflicted harm than the harm (violated stakeholder needs and values) itself.

In previous publications (\parencite{salem2024, nolte2024}), we discuss possible conceptualizations of risk and safety, considering a broader view of defining ``safety'' and ``risk'', particularly addressing ethical questions and stakeholder values.
While we provide a similar assessment of technical standards as \citeauthor{koopman2024}, we include general safety and risk management standards such as IEC~61508 \parencite{iec61508}, ISO~31000 \parencite{iso31000}, or ISO Guide 51 \parencite{iso51} to avoid a narrow technical focus.
Particularly, we consider ethical questions for defining ``risk'' and ``safety'' by relating harm to stakeholder values\footnote{When compared to \citeauthor{koopman2024}, harmed stakeholder values are a potential root cause for negative societal externalities that express non-acceptance of the technology.}.

Considering this body of related work, several distinctions can be made when assessing definitions for ``safety'' and ``risk'':
Notions of ``safety'' and ``risk'' can be separated by underlying ``risk sources''\footnote{E.g., E/E-failures as per ISO~26262 or functional insufficiencies as per ISO~21448.} (as per \parencite{christensen2003}; we'll argue in \cref{sec:analysis}, why we prefer the term ``hazard sources'') or the considered types of ``harm''\footnote{Such as physical or monetary harm.}
In the following, we will give definitions and perspectives on ``safety'' and ``risk'' that will be used for assessing the terminology provided in the regulatory documents.

\section{Safety \& Risk -- Terminology}
\label{sec:terminology}
For the most part, discussing ``safety'' and ``risk'' independently is impossible, as ``safety'' is typically defined with the help of ``risk''.
Safety can hence be understood as the ``freedom from (unacceptable/not tolerable/unreasonable) risk''.
Note that depending on the prefix (``unreasonable'' as in ISO~26262 \parencite[p.~21, def.~3.132]{iso2018}, ``unacceptable'' as in IEC~61508 \parencite{iec61508}), ``safety'' can take an absolute (as in ``no risk is tolerable'') or a relative (as in ``a sufficiently low risk is tolerable'') notion.

The most general ``risk'' definition is the ``effect of uncertainty on objectives'' \parencite{iso31000}.
In technical domains, this uncertainty is often reflected in terms of \emph{probability}.
The effect on objectives is considered as \emph{harm} with a certain \emph{severity}.
This yields a technical definition of ``risk'' as the ``combination of the probability of occurrence of harm [\ldots] and the severity of that harm'' \parencite[p.~2, def.~3.9]{iso51}, with ``harm'' being the ``injury or damage to the health of people, or damage to property or the environment'' \parencite[p.~1, def.~3.1]{iso51}.\footnote{Note that this still is the more materialistic interpretation of ``harm'' as criticized in \parencite{koopman2024}.}
As noted in \parencite{salem2024, nolte2024}, this technical risk definition already allows additional dimensions of ``risk'' when broadening the concept of ``harm'' to, e.g., include violations of stakeholder values such as mobility or legality.

Regarding the understanding of ``safety'' in the context of technical systems, the ``freedom from untolerable risk'' is a generally accepted notion among engineers.
Safety-related technical standards refer to a probability of harm, which suggests that, in engeinnering disciplines, it is clear that complex technical systems will never be infallible.
In addition, the general public is indeed willing to accept certain risks, as long as they see sufficient benefit from this acceptance \parencite{grunwald2016} -- How much risk is ``tolerable'', is then subject to the definition of (``risk'') acceptance criteria.
However, this willingness to accept risk can also be dependent on how professional actors communicate about the risks involved in a technology.

In this respect, other disciplines and the general public may tend towards more absolute notions of ``safety'':
The Cambridge Dictionary defines safety as ``a state in which or a place where you are safe and not in danger or at risk'' \parencite{cambridge2025}.
Despite the cyclic definition of safety by ``safe'', it is clear, that ``not being at risk'' suggests an absolute understanding regarding the absence of risk.
Ballantine's Law Dictionary defines ``safe'' as ``out of harm's way'', pointing to concepts such as ``reasonably safe'' or ``adequately safe'' for more relaxed definitions.
With that, the basic definition proposes no chance of occurring harm and no possible relaxation of the concept of ``safety'' that can be related to risk.
In German jurisprudence, \parencite{peine1999} defines that a risk is given by a ``theoretically possible, but practically unlikely'' harm, also pointing to a rather absolute notion of safety.

Regarding automated driving systems, these nuances are important:
In addition to the risks caused by failures in complex technical systems, automated vehicles are operating in a practically open world. \parencite{nolte2024, koopman2024} 
Developers thus cannot foresee every possible scenario or required system reaction at design time.
Implementing overly cautious vehicle behavior as a safety measure would sacrifice mobility \parencite{graubohm2023} and by that reduce to utility of the technology.
If automated vehicles shall provide mobility to their users, developers need to find a balance between a system design that is sufficiently safe and provides mobility at the same time.
This means, however, that the risk incurred by automated driving systems can only be mitigated (to a tolerable degree), but never be fully eliminated.

Regulation that is written with an absolute notion of safety in mind can hence a) cause legal insecurity for the developers of automated vehicles who must strike that balance between safety and mobility or b) in the worst case hinder the introduction of the technology completely.









