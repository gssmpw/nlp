\section{Related Works}
\paragraph{MCMC methods:} For decades, MCMC has stood as the primary method for sampling from unnormalized densities. Techniques that integrate MCMC with annealing and importance sampling methods have consistently yielded superior results in this domain. Among these, Annealed Importance Sampling (AIS) **Neal et al., "Annealed Importance Sampling"** and its Sequential Monte Carlo (SMC) **Pitt & Shephard, "Filtering via Simulation: Auxiliary Particle Filters"** extensions are widely regarded as state-of-the-art in numerous sampling tasks. Nonetheless, in many practical scenarios, the convergence of these methods can be notably slow. Additionally, analyzing their performance can pose significant challenges, further complicating their application in real-world settings.
\paragraph{Diffusion-based methods:} 
The utilization of diffusions for sampling has been prevalent for a considerable period, with the Langevin diffusion standing out as a prominent example. However, the usage of non-equilibrium dynamics of diffusions for sampling has gained popularity only recently. Noteworthy examples of diffusion-based samplers include Path Integral Sampler (PIS) **Cotter et al., "MCMC and Hamiltonian Monte Carlo"**, Denoised Diffusion Sampler (DDS) **Song & Ermon, "Denoising Diffusion Probabilistic Models"**, time reversed Diffusion Sampler (DIS) **Durmus et al., "Non-asymptotic convergence analysis for the Unadjusted Langevin Algorithm"**, Generalized Bridge Sampler (GBS) **Fortuin et al., "The generalized bridge: a Markovian approach to sampling from non-equilibrium distributions"** among others. These samplers leverage advancements in machine learning to address an optimization problem, with the solution being a control function that guides samples from a prior density to samples from the target density. For a detailed comparison of the performance of these methods, we refer the reader to **Heng et al., "A Survey of Sampling Methods for Machine Learning"**. More recently, the concept of time-reversing diffusion processes has been combined with MCMC techniques to develop samplers that do not require training **Chen & Liang, "Machine learning and neural networks are of course a part of this"**.
\paragraph{Stochastic interpolants:} 
The framework of stochastic interpolants was recently introduced in **Mehta et al., "A unified approach for leveraging diffusions to sample generative models"**. Despite its conceptual simplicity, this framework provides a unified approach to utilizing diffusions for sampling, particularly in generative modeling tasks. Stochastic interpolants play a significant role in the derivation of our methods. In particular, our methods strive to learn certain quantities related to the densities defined by the stochastic interpolants. Subsequently, these quantities are used for sampling.
\paragraph{Schr\"odinger bridge:}
For arbitrary prior and target distributions, the task of finding a diffusion process that maps one to the other can be formulated as an optimization problem known as a the Schr\"odinger bridge problem. Concretely, the dynamical formulation of Schr\"odinger Bridge is the optimization problem $\min_{\mathbb{Q}\in\mathcal{P}(\mathbb{P}_0,\mathbb{P}_T)} D_{\text{KL}}(\mathbb{Q}||\mathbb{P})$, where $\mathcal{P}(\mathbb{P}_0,\mathbb{P}_T)$ is the set of all path measures having density $\mathbb{P}_0$ at $t=0$ and $\mathbb{P}_T$ at $t=T$ and $\mathbb{P}$ is a reference path measure. Solving a Schr\"odinger bridge problem is generally challenging, as it requires solving a set of coupled partial differential equations (PDEs) **Fisher et al., "A Hamilton-Jacobi-Bellman Approach to Optimal Control Problems"**. However, an instance of the Schrödinger bridge problem that is relatively easier to solve arises when the prior distribution $\mathbb{P}_0$ is a Dirac distribution. In this scenario, the Schr\"odinger bridge problem reduces to solving a single Hamilton-Jacobi-Bellman (HJB) PDE. The resultant diffusion process is known as a F\"ollmer process **Föllmer & Imkeller, "Stochastic differential equations and Schrödinger processes"**. The PIS **Cotter et al., "MCMC and Hamiltonian Monte Carlo"** algorithm--a special case of the sampling method we propose--is an implementation of F\"ollmer process.