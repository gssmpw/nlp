\section{Discussion and Future Work}\label{sec:discussion}
We presented a class of diffusion-based algorithms for sampling from unnormalized densities that can obtain samples in finite time. An existing diffusion-based method that can achieve the same is the Path Integral Sampler (PIS) \cite{zhang_path_2022}. However, PIS is obliged to have a Dirac distribution as its prior. On the other hand, diffusion-based samplers such as DDS \cite{vargas_denoising_2022} and DIS \cite{berner_optimal_2023} are more closely related to score-based generative modeling techniques. They can accommodate non-Dirac distributions as their prior, but ideally require an infinite amount of time for convergence. Our method circumvents these limitations.  Our approach which is based on the stochastic interpolants framework permits Gaussian initial distribution on top of producing samples in finite time. We would like to point out that the F\"ollmer process that the PIS implements is same as the diffusion process that our half interpolant-based method realizes when the interpolant functions take the form $g(t)= f(t)$ and $r(t) = \sqrt{f(t)}$ for some positive function $f$ with $f(0)=0$.

The training phase of PIS, DDS, and DIS involves computing gradients over the paths generated by an SDE (Neural SDE), which can become computationally expensive as we decrease the discretization step-size of the SDE. However, our method does not suffer from this limitation as we detach the process (\ref{eqn:fbsde_init_process}) from the computational graph, and also the discretization step-size of the ODE \ref{eqn:fbsde_init_process} does not significantly impact the final accuracy. An extension of DIS presented in \cite{richter_improved_2023} also detaches path gradients from the computational graph, making it computationally less expensive. This is achieved by using log-variance divergence as the loss function.

A limitation of our method currently is that it is not evident if our construction allows for the computation of important weights required to correct the estimates obtained using the samples. This is an important aspect for further investigation. Lastly, we mention that the performance of our sampler can vary significantly based on the values of the hyperparameters used in the implementation. Our primary focus in this work is to present ideas that offer a class of more versatile diffusion-based sampling algorithms, while also offering a fresh perspective on the existing ones. 


 