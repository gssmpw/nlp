@misc{albergo_stochastic_2023,
	title = {Stochastic {Interpolants}: {A} {Unifying} {Framework} for {Flows} and {Diffusions}},
	shorttitle = {Stochastic {Interpolants}},
	url = {http://arxiv.org/abs/2303.08797},
	doi = {10.48550/arXiv.2303.08797},
	abstract = {A class of generative models that unifies flow-based and diffusion-based methods is introduced. These models extend the framework proposed in Albergo \& Vanden-Eijnden (2023), enabling the use of a broad class of continuous-time stochastic processes called `stochastic interpolants' to bridge any two arbitrary probability density functions exactly in finite time. These interpolants are built by combining data from the two prescribed densities with an additional latent variable that shapes the bridge in a flexible way. The time-dependent probability density function of the stochastic interpolant is shown to satisfy a first-order transport equation as well as a family of forward and backward Fokker-Planck equations with tunable diffusion coefficient. Upon consideration of the time evolution of an individual sample, this viewpoint immediately leads to both deterministic and stochastic generative models based on probability flow equations or stochastic differential equations with an adjustable level of noise. The drift coefficients entering these models are time-dependent velocity fields characterized as the unique minimizers of simple quadratic objective functions, one of which is a new objective for the score of the interpolant density. We show that minimization of these quadratic objectives leads to control of the likelihood for generative models built upon stochastic dynamics, while likelihood control for deterministic dynamics is more stringent. We also discuss connections with other methods such as score-based diffusion models, stochastic localization processes, probabilistic denoising techniques, and rectifying flows. In addition, we demonstrate that stochastic interpolants recover the Schr{\textbackslash}"odinger bridge between the two target densities when explicitly optimizing over the interpolant. Finally, algorithmic aspects are discussed and the approach is illustrated on numerical examples.},
	urldate = {2023-12-21},
	publisher = {arXiv},
	author = {Albergo, Michael S. and Boffi, Nicholas M. and Vanden-Eijnden, Eric},
	month = nov,
	year = {2023},
	note = {arXiv:2303.08797 [cond-mat]},
	keywords = {Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks, Mathematics - Probability},
}

@article{berner_optimal_2023,
	title = {An optimal control perspective on diffusion-based generative modeling},
	issn = {2835-8856},
	url = {https://openreview.net/forum?id=oYIjw37pTP},
	abstract = {We establish a connection between stochastic optimal control and generative models based on stochastic differential equations (SDEs), such as recently developed diffusion probabilistic models. In particular, we derive a Hamilton--Jacobi--Bellman equation that governs the evolution of the log-densities of the underlying SDE marginals. This perspective allows to transfer methods from optimal control theory to generative modeling. First, we show that the evidence lower bound is a direct consequence of the well-known verification theorem from control theory. Further, we can formulate diffusion-based generative modeling as a minimization of the Kullback--Leibler divergence between suitable measures in path space. Finally, we develop a novel diffusion-based method for sampling from unnormalized densities -- a problem frequently occurring in statistics and computational sciences. We demonstrate that our time-reversed diffusion sampler (DIS) can outperform other diffusion-based sampling approaches on multiple numerical examples.},
	language = {en},
	urldate = {2024-05-22},
	journal = {Transactions on Machine Learning Research},
	author = {Berner, Julius and Richter, Lorenz and Ullrich, Karen},
	month = oct,
	year = {2023},
}

@misc{blessing_beyond_2024,
	title = {Beyond {ELBOs}: {A} {Large}-{Scale} {Evaluation} of {Variational} {Methods} for {Sampling}},
	shorttitle = {Beyond {ELBOs}},
	url = {http://arxiv.org/abs/2406.07423},
	abstract = {Monte Carlo methods, Variational Inference, and their combinations play a pivotal role in sampling from intractable probability distributions. However, current studies lack a unified evaluation framework, relying on disparate performance measures and limited method comparisons across diverse tasks, complicating the assessment of progress and hindering the decision-making of practitioners. In response to these challenges, our work introduces a benchmark that evaluates sampling methods using a standardized task suite and a broad range of performance criteria. Moreover, we study existing metrics for quantifying mode collapse and introduce novel metrics for this purpose. Our findings provide insights into strengths and weaknesses of existing sampling methods, serving as a valuable reference for future developments. The code is publicly available here.},
	language = {en},
	urldate = {2024-08-03},
	publisher = {arXiv},
	author = {Blessing, Denis and Jia, Xiaogang and Esslinger, Johannes and Vargas, Francisco and Neumann, Gerhard},
	month = jun,
	year = {2024},
	note = {arXiv:2406.07423 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{chen_likelihood_2021,
	title = {Likelihood {Training} of {Schrödinger} {Bridge} using {Forward}-{Backward} {SDEs} {Theory}},
	url = {https://openreview.net/forum?id=nioAdKCEdXB},
	abstract = {Schrödinger Bridge (SB) is an entropy-regularized optimal transport problem that has received increasing attention in deep generative modeling for its mathematical flexibility compared to the Scored-based Generative Model (SGM). However, it remains unclear whether the optimization principle of SB relates to the modern training of deep generative models, which often rely on constructing log-likelihood objectives.This raises questions on the suitability of SB models as a principled alternative for generative applications. In this work, we present a novel computational framework for likelihood training of SB models grounded on Forward-Backward Stochastic Differential Equations Theory – a mathematical methodology appeared in stochastic optimal control that transforms the optimality condition of SB into a set of SDEs. Crucially, these SDEs can be used to construct the likelihood objectives for SB that, surprisingly, generalizes the ones for SGM as special cases. This leads to a new optimization principle that inherits the same SB optimality yet without losing applications of modern generative training techniques, and we show that the resulting training algorithm achieves comparable results on generating realistic images on MNIST, CelebA, and CIFAR10. Our code is available at https://github.com/ghliu/SB-FBSDE.},
	language = {en},
	urldate = {2024-05-22},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Chen, Tianrong and Liu, Guan-Horng and Theodorou, Evangelos},
	month = oct,
	year = {2021},
}

@article{del_moral_sequential_2006,
	title = {Sequential {Monte} {Carlo} samplers},
	volume = {68},
	issn = {1467-9868},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2006.00553.x},
	doi = {10.1111/j.1467-9868.2006.00553.x},
	abstract = {Summary. We propose a methodology to sample sequentially from a sequence of probability distributions that are defined on a common space, each distribution being known up to a normalizing constant. These probability distributions are approximated by a cloud of weighted random samples which are propagated over time by using sequential Monte Carlo methods. This methodology allows us to derive simple algorithms to make parallel Markov chain Monte Carlo algorithms interact to perform global optimization and sequential Bayesian estimation and to compute ratios of normalizing constants. We illustrate these algorithms for various integration tasks arising in the context of Bayesian inference.},
	language = {en},
	number = {3},
	urldate = {2024-05-12},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Del Moral, Pierre and Doucet, Arnaud and Jasra, Ajay},
	year = {2006},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2006.00553.x},
	keywords = {Importance sampling, Markov chain Monte Carlo methods, Ratio of normalizing constants, Resampling, Sequential Monte Carlo methods, Simulated annealing},
	pages = {411--436},
}

@inproceedings{follmer_time_1986,
	address = {Berlin, Heidelberg},
	title = {Time reversal on {Wiener} space},
	isbn = {978-3-540-39703-8},
	doi = {10.1007/BFb0080212},
	language = {en},
	booktitle = {Stochastic {Processes} — {Mathematics} and {Physics}},
	publisher = {Springer},
	author = {Föllmer, H.},
	editor = {Albeverio, Sergio A. and Blanchard, Philippe and Streit, Ludwig},
	year = {1986},
	keywords = {Duality Equation, Stochastic Differential Equation, Time Reversal, Wiener Process, Wiener Space},
	pages = {119--129},
}

@misc{grenioux_stochastic_2024,
	title = {Stochastic {Localization} via {Iterative} {Posterior} {Sampling}},
	url = {https://arxiv.org/abs/2402.10758v2},
	abstract = {Building upon score-based learning, new interest in stochastic localization techniques has recently emerged. In these models, one seeks to noise a sample from the data distribution through a stochastic process, called observation process, and progressively learns a denoiser associated to this dynamics. Apart from specific applications, the use of stochastic localization for the problem of sampling from an unnormalized target density has not been explored extensively. This work contributes to fill this gap. We consider a general stochastic localization framework and introduce an explicit class of observation processes, associated with flexible denoising schedules. We provide a complete methodology, \${\textbackslash}textit\{Stochastic Localization via Iterative Posterior Sampling\}\$ (SLIPS), to obtain approximate samples of this dynamics, and as a by-product, samples from the target distribution. Our scheme is based on a Markov chain Monte Carlo estimation of the denoiser and comes with detailed practical guidelines. We illustrate the benefits and applicability of SLIPS on several benchmarks of multi-modal distributions, including Gaussian mixtures in increasing dimensions, Bayesian logistic regression and a high-dimensional field system from statistical-mechanics.},
	language = {en},
	urldate = {2024-10-09},
	journal = {arXiv.org},
	author = {Grenioux, Louis and Noble, Maxence and Gabrié, Marylou and Durmus, Alain Oliviero},
	month = feb,
	year = {2024},
}

@misc{huang_reverse_2023,
	title = {Reverse {Diffusion} {Monte} {Carlo}},
	url = {https://arxiv.org/abs/2307.02037v3},
	abstract = {We propose a Monte Carlo sampler from the reverse diffusion process. Unlike the practice of diffusion models, where the intermediary updates -- the score functions -- are learned with a neural network, we transform the score matching problem into a mean estimation one. By estimating the means of the regularized posterior distributions, we derive a novel Monte Carlo sampling algorithm called reverse diffusion Monte Carlo (rdMC), which is distinct from the Markov chain Monte Carlo (MCMC) methods. We determine the sample size from the error tolerance and the properties of the posterior distribution to yield an algorithm that can approximately sample the target distribution with any desired accuracy. Additionally, we demonstrate and prove under suitable conditions that sampling with rdMC can be significantly faster than that with MCMC. For multi-modal target distributions such as those in Gaussian mixture models, rdMC greatly improves over the Langevin-style MCMC sampling methods both theoretically and in practice. The proposed rdMC method offers a new perspective and solution beyond classical MCMC algorithms for the challenging complex distributions.},
	language = {en},
	urldate = {2024-10-09},
	journal = {arXiv.org},
	author = {Huang, Xunpeng and Dong, Hanze and Hao, Yifan and Ma, Yi-An and Zhang, Tong},
	month = jul,
	year = {2023},
}

@article{neal_annealed_2001,
	title = {Annealed importance sampling},
	volume = {11},
	issn = {1573-1375},
	url = {https://doi.org/10.1023/A:1008923215028},
	doi = {10.1023/A:1008923215028},
	abstract = {Simulated annealing—moving from a tractable distribution to a distribution of interest via a sequence of intermediate distributions—has traditionally been used as an inexact method of handling isolated modes in Markov chain samplers. Here, it is shown how one can use the Markov chain transitions for such an annealing sequence to define an importance sampler. The Markov chain aspect allows this method to perform acceptably even for high-dimensional problems, where finding good importance sampling distributions would otherwise be very difficult, while the use of importance weights ensures that the estimates found converge to the correct values as the number of annealing runs increases. This annealed importance sampling procedure resembles the second half of the previously-studied tempered transitions, and can be seen as a generalization of a recently-proposed variant of sequential importance sampling. It is also related to thermodynamic integration methods for estimating ratios of normalizing constants. Annealed importance sampling is most attractive when isolated modes are present, or when estimates of normalizing constants are required, but it may also be more generally useful, since its independent sampling allows one to bypass some of the problems of assessing convergence and autocorrelation in Markov chain samplers.},
	language = {en},
	number = {2},
	urldate = {2024-05-12},
	journal = {Statistics and Computing},
	author = {Neal, Radford M.},
	month = apr,
	year = {2001},
	keywords = {estimation of normalizing constants, free energy computation, sequential importance sampling, tempered transitions},
	pages = {125--139},
}

@misc{richter_improved_2023,
	title = {Improved sampling via learned diffusions},
	url = {http://arxiv.org/abs/2307.01198},
	abstract = {Recently, a series of papers proposed deep learning-based approaches to sample from unnormalized target densities using controlled diffusion processes. In this work, we identify these approaches as special cases of the Schr{\textbackslash}"odinger bridge problem, seeking the most likely stochastic evolution between a given prior distribution and the specified target. We further generalize this framework by introducing a variational formulation based on divergences between path space measures of time-reversed diffusion processes. This abstract perspective leads to practical losses that can be optimized by gradient-based algorithms and includes previous objectives as special cases. At the same time, it allows us to consider divergences other than the reverse Kullback-Leibler divergence that is known to suffer from mode collapse. In particular, we propose the so-called log-variance loss, which exhibits favorable numerical properties and leads to significantly improved performance across all considered approaches.},
	urldate = {2024-03-11},
	publisher = {arXiv},
	author = {Richter, Lorenz and Berner, Julius and Liu, Guan-Horng},
	month = jul,
	year = {2023},
	note = {arXiv:2307.01198 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Mathematics - Probability, Statistics - Machine Learning},
}

@inproceedings{vargas_denoising_2022,
	title = {Denoising {Diffusion} {Samplers}},
	url = {https://openreview.net/forum?id=8pvnfTAbu1f},
	abstract = {Denoising diffusion models are a popular class of generative models providing state-of-the-art results in many domains. One adds gradually noise to data using a diffusion to transform the data distribution into a Gaussian distribution. Samples from the generative model are then obtained by simulating an approximation of the time-reversal of this diffusion initialized by Gaussian samples. Practically, the intractable score terms appearing in the time-reversed process are approximated using score matching techniques. We explore here a similar idea to sample approximately from unnormalized probability density functions and estimate their normalizing constants. We consider a process where the target density diffuses towards a Gaussian. Denoising Diffusion Samplers (DDS) are obtained by approximating the corresponding time-reversal. While score matching is not applicable in this context, we can leverage many of the ideas introduced in generative modeling for Monte Carlo sampling. Existing theoretical results from denoising diffusion models also provide theoretical guarantees for DDS. We discuss the connections between DDS, optimal control and Schr{\textbackslash}"odinger bridges and finally demonstrate DDS experimentally on a variety of challenging sampling tasks.},
	language = {en},
	urldate = {2024-05-22},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Vargas, Francisco and Grathwohl, Will Sussman and Doucet, Arnaud},
	month = sep,
	year = {2022},
}

@misc{zhang_path_2022,
	title = {Path {Integral} {Sampler}: a stochastic control approach for sampling},
	shorttitle = {Path {Integral} {Sampler}},
	url = {http://arxiv.org/abs/2111.15141},
	abstract = {We present Path Integral Sampler{\textasciitilde}(PIS), a novel algorithm to draw samples from unnormalized probability density functions. The PIS is built on the Schr{\textbackslash}"odinger bridge problem which aims to recover the most likely evolution of a diffusion process given its initial distribution and terminal distribution. The PIS draws samples from the initial distribution and then propagates the samples through the Schr{\textbackslash}"odinger bridge to reach the terminal distribution. Applying the Girsanov theorem, with a simple prior diffusion, we formulate the PIS as a stochastic optimal control problem whose running cost is the control energy and terminal cost is chosen according to the target distribution. By modeling the control as a neural network, we establish a sampling algorithm that can be trained end-to-end. We provide theoretical justification of the sampling quality of PIS in terms of Wasserstein distance when sub-optimal control is used. Moreover, the path integrals theory is used to compute importance weights of the samples to compensate for the bias induced by the sub-optimality of the controller and time-discretization. We experimentally demonstrate the advantages of PIS compared with other start-of-the-art sampling methods on a variety of tasks.},
	urldate = {2024-03-08},
	publisher = {arXiv},
	author = {Zhang, Qinsheng and Chen, Yongxin},
	month = mar,
	year = {2022},
	note = {arXiv:2111.15141 [cs]},
	keywords = {Computer Science - Machine Learning},
}

