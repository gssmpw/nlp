\section{Introduction}

Probabilistic modeling is at the heart of modern machine learning, where data is often conceptualized as samples drawn from a probability distribution in a high-dimensional space. 
%In this context, a common objective in machine learning is regression, where we predict a subset of variables based on the values of other variables. 
%Whereas, 
In this context, the field of generative modeling, which focuses on drawing new samples from probability distributions given a few samples from the distribution, has witnessed spectacular advancements in recent years, empowering researchers to create synthetic images, videos, and other data with astonishing quality. A concept that has catalyzed significant progress in generative modeling is score-based diffusion modeling \cite{song_generative_2019,song_score-based_2021,ho_denoising_2020}. This technique incrementally introduces noise to the data until it reaches a state of pure noise, all while learning how to reverse this process effectively. 

These new ideas have found applications in the classical sampling problem, wherein the objective is to generate samples from a probability distribution given only its unnormalized density \cite{zhang_path_2022,berner_optimal_2023,vargas_denoising_2022,richter_improved_2023,grenioux_stochastic_2024,huang_reverse_2023}. 
%The classical sampling problem amounts to drawing samples from a probability distribution given its unnormalized probability density. 
In the realm of computational science and statistics, sampling techniques play a pivotal role in various applications ranging from Bayesian inference to machine learning algorithms. The ability to efficiently sample from complex probability distributions underpins the success of numerous computational methodologies, and traditional sampling methods, such as Markov Chain Monte Carlo (MCMC), have been widely employed for this purpose. However, these methods often encounter challenges in high-dimensional spaces or distributions with intricate geometries. Moreover, MCMC methods, which construct a Markov chain with a stationary distribution aligned with the target distribution, often suffer from slow convergence due to long mixing times.

In light of the effectiveness of diffusion processes in generative modeling, there is significant interest in leveraging these processes for sampling.
The aim is to find diffusion processes such that starting with the samples from a tractable distribution such as Gaussian, the diffusion process should produce a sample from the desired distribution at the final time. Unlike conventional MCMC methods, diffusion-based approaches do not require tuning of proposal distributions or acceptance probabilities. Furthermore, diffusion-based methods seem to mitigate the slow convergence of MCMC methods.

Traditional score-based generative modeling generates samples from a target distribution by learning how to reverse a forward diffusion process that maps the target distribution to a prior distribution. Ideally, these diffusion processes require an infinite time horizon for convergence.
%Typically, the forward processes in diffusion models converge exponentially fast to the prior distribution. Consequently, running the diffusion process for only a finite amount of time still provides a reasonably good approximation for sampling from the target distribution. 
In this work, we design computationally efficient diffusion-based samplers using ideas from the \textit{stochastic interpolants} framework, and \textit{forward-backward SDEs}, to generate exact samples from the target distribution within a finite time.
\\[4pt]
%In this work, we study diffusion-based methods for sampling from high-dimensional probability distributions.
%Due to the significant amount of time required for conventional methods to generate samples from the target distribution, there is a pressing need for techniques capable of sampling from probability distributions within \textit{finite time}. 
%In light of the effectiveness of diffusion processes in generative modeling, there is significant interest in using diffusion processes for sampling.
%Traditional score-based generative modeling generates samples from a target distribution by learning how to reverse a forward diffusion process that maps the target distribution to a prior distribution. 
%Typically, these forward processes require an infinite duration to traverse from the target distribution to the prior distribution. Consequently, this method remains approximate, as ideally, simulating the diffusion process for an infinite duration would be necessary. Whereas, diffusion processes capable of generating samples from the target distribution in a finite time remains largely unexplored. Our study precisely focuses on this aspect.
%{\color{blue}Typically, the forward processes in diffusion models converge exponentially fast to the prior distribution. Consequently, running the diffusion process for only a finite amount of time still provides a reasonably good approximation for sampling from the target distribution. 
%Building on this, our study focuses on diffusion processes designed to generate exact samples from the target distribution within finite time.
%Taking a step further, we design computationally efficient diffusion processes using the stochastic interpolant framework that can generate exact samples from the target distribution within a finite time.}
%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Problem Statement:}
We are interested in sampling from a probability distribution $\pi$ with support on $\R^d$ by constructing diffusion processes which run for a finite time. We are given an unnormalized probability density function $\hat{\pi}$, such that $\pi(x) = \frac{\hat{\pi}(x)}{\int\hat{\pi}(x)dx}$.

\textbf{Notations:}
We denote a Gaussian distribution (and its density) with mean $\mu$ and covariance $\Sigma$ by $\cN{\mu,\Sigma}$. A uniform random variable in the interval $[0,T]$ is denoted by $U([0,T])$. A derivative  of a scalar function $f$ with respect to time $t\in \mathbb{R}_+$ is denoted by $\dot{f}$. A gradient with respect to the space variables $x\in \mathbb{R}^d$ is denoted with $\nabla$, and $\Delta$ denotes the Laplacian. We use $\Vert\cdot\Vert$ for the  Euclidean norm in $\mathbb{R}^d$.
%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Our Contributions}

There are infinitely many diffusion processes that can drive samples from a prior distribution to a target distribution in a finite time. However, computationally tractable ways to find and simulate diffusions that have distributions other than Dirac distribution at the initial time and given target distribution at finite time are still unknown to the best of our knowledge. We take a step towards this by providing a principled approach for generating such diffusions when the prior distribution is Gaussian. \emph{Specifically, we propose a class of diffusion-based sampling methods that, starting with samples from the Gaussian distribution, can produce samples from a target distribution in finite time given its unnormalized density.} We achieve this by taking an approach based on the stochastic interpolants framework \cite{albergo_stochastic_2023}. To the best of our knowledge, this is the first time that stochastic interpolants have been used for classical sampling. Our approach reduces the sampling problem to solving Hamilton-Jacobi-Bellman (HJB) equations; a class of well-studied partial differential equations (PDEs) that arise frequently in the field of optimal control. Traditionally, HJB PDEs are solved by minimizing the corresponding control costs \cite{zhang_path_2022}. Instead, for important reasons that will become clear later (see the discussion in Section~\ref{sec:solving_fbsde}), \emph{our approach uses the theory of forward-backward stochastic differential equations (FBSDE) that connects solutions of HJB PDEs (more generally, nonlinear parabolic PDEs) to solutions of a certain set of stochastic differential equations called FBSDEs}. 
%We will explain some of the advantages of this approach later on. 
Moreover, we solve these FBSDEs using machine learning-based methods \cite{han_solving_2018,e_algorithms_2022,raissi_forward-backward_2018}. One of the advantages of our methods is that they allow solving HJB PDEs without the need to compute computationally expensive Neural SDE gradients \cite{zhang_path_2022,berner_optimal_2023}. The techniques that we develop to solve HJB PDEs using FBSDEs can be of independent interest.  
%We start by defining a time dependent density function satisfying the constraints that at $t=0$ it has a density of a Gaussian and at $t=T$, it has the density of the target distribution. Thereafter, we develop methods to implement a stochastic process with above defined marginal density. We then identify that certain quantities related to the density satisfies certain HJB PDEs. We use a method based on FBSDEs and machine learning to solve the PDEs.
%We present here glimpses of the numerical results for our linear interpolant-based sampler. 

\subsection{Our Techniques}
We draw inspiration from the stochastic interpolants framework, which begins with a family of time-indexed random variables defining the density of the diffusion process at each time instant $t$, and then explores methods to realize such a diffusion process. Such a collection of random variables that have desired probability distribution at the time boundaries are known as stochastic interpolants \cite{albergo_stochastic_2023}. 
%We study a specific case known as the linear one-sided stochastic interpolants (linear interpolants in short). 
To illustrate our techniques, in this section we restrict our focus to one of our methods based on \textit{half interpolants}. 
%The half interpolant-based method and another based on linear interpolant will be presented later in detail. 
A half interpolant is a collection of random variables $\{x_t\}_{t\in[0,T]}$ given by $x_t = g(t)x^*+r(t)z,$ for $0\le t\le T$, where $g,r:[0,T]\rightarrow \R_+$ are functions such that $\frac{g}{r}$ is a non-decreasing. Furthermore, $g$ satisfies the boundary condition $g(0)=0$. Here, $x^*\sim\nu$ and $z\sim\cN{0,I_d}$ are independent random variables.

 Our aim is to implement a diffusion process $\{S_t\}_{t\in[0,T]}$ such that the distribution of $S_t$ is same as $x_t$ for all $t\in[0,T]$ and also enforce the constraint that $x_T,S_T\sim\pi$ (thereby implicitly choosing $\nu$). If realized, such a diffusion process can drive samples $S_0\sim\cN{0,r^2(0)I_d}$ to $S_T\sim\pi$. 
 
 Let $\rho(t,\cdot)$ denote the probability density of $x_t$ and let $s(t,x) := \nabla\log{\rho(t,x)}$ denote the so-called score function of density $\rho$. Lemma~\ref{lemma:pde_density} shows that $\rho$ satisfies a ``Fokker-Planck'' PDE given by
\begin{equation}\label{eqn:FPE_tech}
    \partial_t\rho-\frac{\eps^2(t)}{2}\Delta\rho+\nabla\cdot\left(\left(b(t,x)+\frac{\eps^2(t)}{2}s(t,x)\right)\rho\right) = 0,%\quad \rho(0,\cdot) \equiv \cN{0,r^2(0)I_d}.
\end{equation}
with initial condition $\rho(0,\cdot) \equiv \cN{0,r^2(0)I_d}$, where $b(t,x) = \dot g(t)\expectCond{x^*}{x_t=x}-r(t)\dot r(t)s(t,x)$ and $\eps:[0,T]\rightarrow \R_+$ is an arbitrary function.

Equation~\ref{eqn:FPE_tech} suggests that we can realize a process $S_t$ with density $\rho$ by simulating a stochastic differential equation (SDE) given by:
\begin{equation}\label{eqn:SDEforSampling_tech}
   dS_t = \left(b(t,S_t)+\frac{\eps^2(t)}{2}s(t,S_t)\right)dt+\eps(t)dW_t,%;\quad S_0\sim\cN{0,r^2(0)I_d}, 
\end{equation}
with $S_0\sim\cN{0,r^2(0)I_d}$, where $\{W_t\}_{t\in{0,T}}$ is a standard Brownian motion.
Therefore, it suffices to have access to functions $b$ and $s$ (responsible for the drift term) to implement a process $S_t$ that has the same marginal distribution as $x_t$. We will show (Lemma~\ref{lemma:b_and_s}) that both $b$ and $s$ can be expressed in terms of $\expectCond{x^*}{x_t=x}$. Thus, it is sufficient to learn the function $\expectCond{x^*}{x_t=x}$. Towards this, for some $\beta:[0,T]\rightarrow\R_+$, we consider a function $u:[0,T]\times\R^d\rightarrow\R$ given by
\begin{align}\label{eqn:velocity_denf_tech}
    u(t,x) &= \log\frac{\rho(t,\beta(t)x)}{\psi(t,\beta(t)x)}\\ &= \log\int_{\R^d}\nu(x^*)e^{\frac{\beta(t)g(t)}{r^2(t)}<x,x^*>-\frac{g^2(t)}{2r^2(t)}\norm{x^*}^2}dx^*,\nonumber
\end{align}
where $\psi(t,\cdot)$ is the density of the isotropic Gaussian with variance $r^2(t)$. Taking the gradient of (\ref{eqn:velocity_denf_tech}), we note that $\expectCond{x^*}{x_t=x} = \frac{r^2(t)}{\beta(t)g(t)}\nabla u(t,\frac{x}{\beta(t)})$. Hence, a feasible way to obtain $\expectCond{x^*}{x_t=x}$ is to compute $\nabla u$. A direct calculation (Lemma~\ref{lemma:velociyt_HJB_PDE}) shows that $u$ satisfies the following HJB equation:
\begin{equation}\label{eqn:velocity_pde_tech}
    \partial_t u + \frac{\sigma^2}{2}\Delta u + \frac{\sigma^2}{2}\norm{\nabla u}^2-\partial_t\log\left(\frac{\beta(t)g(t)}{r^2(t)}\right)x^T\nabla u = 0,
\end{equation}
where $\sigma^2(t) = 2\frac{r^2(t)}{\beta^2(t)}\partial_t\log\frac{g(t)}{r(t)}$. The condition that $\frac{g}{r}$ is non-decreasing assures that $\sigma^2$ is a positive function. 
Observe that (\ref{eqn:velocity_pde_tech}) is a backward Kolmogorov PDE and can be solved given a terminal condition. To satisfy the constraint $x_T\sim\pi$, we want $\rho(T,\cdot)=\pi(\cdot)$, which gives the terminal condition $u(T, x)= \varphi(x) \equiv \log\frac{\pi(\beta(T)x)}{\psi(T,\beta(T)x)}$. The function $\beta$ is a design parameter, which we can choose such that the coefficients of the PDE are well-defined for $t\in[0,T]$. 

There are several ways to obtain the solution $u$ (more importantly $\nabla u$) of HJB PDE (\ref{eqn:velocity_pde_tech}) under the terminal condition $\varphi$. In the optimal control literature, a prominent approach for solving HJB PDEs involves minimizing the sum of control costs and the terminal cost (see Lemma~\ref{lemma_app:oc_optimization}). %However, for reasons that will become clear later, we opt not to pursue this route. 
Instead, we exploit the connections between the solutions of non-linear PDEs and solutions to the corresponding FBSDE to solve (\ref{eqn:velocity_pde_tech}). The remainder of our approach then relies on machine learning-based techniques to solve an FBSDE associated with the PDE (\ref{eqn:velocity_pde_tech}). Solving the FBSDE gives us access to the function $\nabla u$ on an appropriate domain. Once we have the $\nabla u$, subsequently we obtain functions $b$ and $s$. We then can realize the process $S_t$ using (\ref{eqn:SDEforSampling_tech}). Figure~\ref{fig:trajectory_tech} shows sample trajectories of the diffusion process thus obtained when the target distribution is a mixture of Gaussians.

\begin{figure}
  \centering
  \includegraphics[scale = 0.3]{images/trajectory.png}
  \caption{Sample trajectories of diffusion process for sampling from Gaussian mixture.}
  \label{fig:trajectory_tech}
\end{figure}

\subsection{Related Works}
\paragraph{MCMC methods:} For decades, MCMC has stood as the primary method for sampling from unnormalized densities. Techniques that integrate MCMC with annealing and importance sampling methods have consistently yielded superior results in this domain. Among these, Annealed Importance Sampling (AIS) \cite{neal_annealed_2001} and its Sequential Monte Carlo (SMC) \cite{del_moral_sequential_2006} extensions are widely regarded as state-of-the-art in numerous sampling tasks. Nonetheless, in many practical scenarios, the convergence of these methods can be notably slow. Additionally, analyzing their performance can pose significant challenges, further complicating their application in real-world settings.
\paragraph{Diffusion-based methods:} 
The utilization of diffusions for sampling has been prevalent for a considerable period, with the Langevin diffusion standing out as a prominent example. However, the usage of non-equilibrium dynamics of diffusions for sampling has gained popularity only recently. Noteworthy examples of diffusion-based samplers include Path Integral Sampler (PIS) \cite{zhang_path_2022}, Denoised Diffusion Sampler (DDS) \cite{vargas_denoising_2022}, and time reversed Diffusion Sampler (DIS) \cite{berner_optimal_2023}, Generalized Bridge Sampler (GBS) \cite{richter_improved_2023}, among others. These samplers leverage advancements in machine learning to address an optimization problem, with the solution being a control function that guides samples from a prior density to samples from the target density. For a detailed comparison of the performance of these methods, we refer the reader to \cite{blessing_beyond_2024}. More recently, the concept of time-reversing diffusion processes has been combined with MCMC techniques to develop samplers that do not require training \cite{grenioux_stochastic_2024,huang_reverse_2023}.
\paragraph{Stochastic interpolants:} 
The framework of stochastic interpolants was recently introduced in \cite{albergo_stochastic_2023}. Despite its conceptual simplicity, this framework provides a unified approach to utilizing diffusions for sampling, particularly in generative modeling tasks. Stochastic interpolants play a significant role in the derivation of our methods. In particular, our methods strive to learn certain quantities related to the densities defined by the stochastic interpolants. Subsequently, these quantities are used for sampling.
\paragraph{Schr\"odinger bridge:}
For arbitrary prior and target distributions, the task of finding a diffusion process that maps one to the other can be formulated as an optimization problem known as a the Schr\"odinger bridge problem. Concretely, the dynamical formulation of Schr\"odinger Bridge is the optimization problem $\min_{\mathbb{Q}\in\mathcal{P}(\mathbb{P}_0,\mathbb{P}_T)} D_{\text{KL}}(\mathbb{Q}||\mathbb{P})$, where $\mathcal{P}(\mathbb{P}_0,\mathbb{P}_T)$ is the set of all path measures having density $\mathbb{P}_0$ at $t=0$ and $\mathbb{P}_T$ at $t=T$ and $\mathbb{P}$ is a reference path measure. Solving a Schr\"odinger bridge problem is generally challenging, as it requires solving a set of coupled partial differential equations (PDEs) \cite{chen_likelihood_2021}. However, an instance of the Schrödinger bridge problem that is relatively easier to solve arises when the prior distribution $\mathbb{P}_0$ is a Dirac distribution. In this scenario, the Schrödinger bridge problem reduces to solving a single Hamilton-Jacobi-Bellman (HJB) PDE. The resultant diffusion process is known as a F\"ollmer process \cite{follmer_time_1986}. The PIS \cite{zhang_path_2022} algorithm--a special case of the sampling method we propose--is an implementation of F\"ollmer process.

