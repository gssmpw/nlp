\documentclass[sigconf,natbib=true]{acmart}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

% 解决图片浮动问题
\usepackage{float}


\usepackage{booktabs}
\usepackage{array}
\usepackage{balance} 
% \usepackage{lipsum}
\usepackage{multirow}
\usepackage[normalem]{ulem}
\usepackage{color}
\definecolor{lightgray}{RGB}{215,215,215}
\definecolor{myred}{RGB}{210,109,91}
\usepackage{colortbl}  %彩色表格需要加载的宏包
\usepackage{xcolor}
\useunder{\uline}{\ul}{}
\usepackage{subfigure}
% \usepackage{subcaption}
\usepackage{algorithm}  
\usepackage{algorithmicx}  
\usepackage[noend]{algpseudocode}  
% \usepackage[noend]{algorithmic}

\usepackage{amsmath}  
\usepackage{enumitem}
\usepackage{tabularx}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{bm}
\newcommand{\ie}{\emph{i.e., }}
\newcommand{\eg}{\emph{e.g., }}
\newcommand{\etal}{\emph{et al. }}
\newcommand{\st}{\emph{s.t. }}
\newcommand{\etc}{\emph{etc.}}
\newcommand{\wrt}{\emph{w.r.t. }}
\newcommand{\cf}{\emph{cf. }}
\newcommand{\aka}{\emph{a.k.a. }}
\newcommand{\todo}[1]{\textcolor{red}{todo: #1}}

% for algorithm
\newlength\myindent
\setlength\myindent{2em}
\newcommand\bindent{%
    \begingroup
    \setlength{\itemindent}{\myindent}
    \addtolength{\algorithmicindent}{\myindent}
}
\newcommand\eindent{\endgroup}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
% \newtheorem{lemma}[theorem]{Lemma}

\floatname{algorithm}{Algorithm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}} 
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\clubpenalty=10000
\widowpenalty = 10000
\hyphenpenalty=2000
\tolerance=7000

% \copyrightyear{2022}
% \acmYear{2022}
% \setcopyright{acmcopyright}\acmConference[WWW '22]{Proceedings of the ACM Web Conference 2022}{April 25--29, 2022}{Virtual Event, Lyon, France}
% \acmBooktitle{Proceedings of the ACM Web Conference 2022 (WWW '22), April 25--29, 2022, Virtual Event, Lyon, France}
% \acmPrice{15.00}
% \acmDOI{10.1145/3485447.3512251}
% \acmISBN{978-1-4503-9096-5/22/04}


\begin{document}

\title{Order-agnostic Identifier for Large Language Model-based Generative Recommendation}


\author{Xinyu Lin}
\email{xylin1028@gmail.com}
\affiliation{
\institution{National University of Singapore}
\city{}
\country{Singapore}
}

\author{Haihan Shi}
\email{shh924@mail.ustc.edu.cn}
\affiliation{
\institution{University of Science and Technology of China}
\city{Hefei}
\country{China}
}

\author{Wenjie Wang}
\email{wenjiewang96@gmail.com}
\affiliation{
\institution{University of Science and Technology of China}
\city{Hefei}
\country{China}
}

\author{Fuli Feng}
\email{fulifeng93@gmail.com}
% \authornote{Corresponding author. This work is supported by the CCCD Key Lab of Ministry of Culture and Tourism.}
\affiliation{
\institution{University of Science and Technology of China}
\city{Hefei}
\country{China}
}

\author{Qifan Wang}
\email{wqfcr@meta.com}
\affiliation{
\institution{Meta AI}
\city{Menlo Park}
\country{USA}
}

\author{See-Kiong Ng}
\email{seekiong@nus.edu.sg}
\affiliation{
\institution{National University of Singapore}
\city{}
\country{Singapore}
}


\author{Tat-Seng Chua}
\email{dcscts@nus.edu.sg}
\affiliation{
\institution{National University of Singapore}
\city{}
\country{Singapore}
}
% \def\thefootnote{*}\footnotetext{Corresponding author. This work is supported by the CCCD Key Lab of Ministry of Culture and Tourism.}

% \thanks{$*$ }
\renewcommand{\shortauthors}{Xinyu Lin et al.}


\begin{abstract}
% Leveraging Large Language Models (LLMs) for generative recommendation has garnered significant research interest. 
% A pivotal step is item tokenization, which assigns identifiers to items for user history encoding and item decoding. 
% Existing identifiers broadly fall into two categories: token-sequence-based identifiers, which represent items as discrete token sequences, and single-token-based identifiers, which use either ID or semantic embedding. 
% However, token-sequence-based identifiers suffer from the local optima issue in beam search and low generation efficiency due to step-by-step generation. 
% Conversely, single-token-based identifiers neither overlook the rich semantics beneficial for long-tailed users/items, nor the collaborative information crucial to recommendation, thus leading to suboptimal performance. 
Leveraging Large Language Models (LLMs) for generative recommendation has attracted significant research interest, where item tokenization is a critical step. 
It involves assigning item identifiers for LLMs to encode user history and generate the next item. 
Existing approaches leverage either token-sequence identifiers, representing items as discrete token sequences, or single-token identifiers, using ID or semantic embeddings. Token-sequence identifiers face issues such as the local optima problem in beam search and low generation efficiency due to step-by-step generation.
In contrast, single-token identifiers fail to capture rich semantics or encode Collaborative Filtering (CF) information, resulting in suboptimal performance. 


% To address these issues, we highlight two fundamental principles for identifier design. 
% 1) Integration of both collaborative and semantic information aims to fully leverage multidimensional item information, and 
% 2) order-agnostic identifier emphasizes eliminating dependencies of tokens within items. 
% In this work, we introduce a novel set identifier paradigm for LLM-based generative recommendation, which leverages a set of order-agnostic tokens to represent each item and has simultaneous token generation ability. 
% To achieve this, 
% we propose a method called SETRec, 
% which utilizes CF and semantic tokenizers to obtain order-agnostic multidimensional tokens. 
% For next-item generation, SETRec introduces a sparse attention mask to disregard dependencies within items. 
% Moreover, to ensure LLMs generate tokens aligning with each dimension accurately, SETRec introduces a query-guided simultaneous generation mechanism to guide LLMs for token generation.
% % To enhance efficiency, we design a sparse attention mask that mitigates redundant computations during decoding. 
% Lastly, we instantiate SETRec on T5 and Qwen (from 1.5B to 7B). 
% Results on four real-world datasets demonstrate the superiority of SETRec under various settings (\eg warm- and cold-start settings, and item groups with different popularity) with significantly improved efficiency, and show promising scalability on cold-start items by expanding model sizes. 


To address these issues, we propose two fundamental principles for item identifier design:
1) integrating both CF and semantic information to fully capture multi-dimensional item information, and
2) designing order-agnostic identifiers without token dependency, mitigating the local optima issue and achieving simultaneous generation for generation efficiency. 
Accordingly, we introduce a novel \textit{set identifier} paradigm for LLM-based generative recommendation, representing each item as a set of order-agnostic tokens. 
To implement this paradigm, we propose SETRec, which leverages CF and semantic tokenizers to obtain order-agnostic multi-dimensional tokens. 
To eliminate token dependency, SETRec uses a sparse attention mask for user history encoding and a query-guided generation mechanism for simultaneous token generation.
We instantiate SETRec on T5 and Qwen (from 1.5B to 7B). 
Extensive experiments on four datasets demonstrate its effectiveness across various scenarios (\eg full ranking, warm- and cold-start ranking, and various item popularity groups). 
Moreover, results validate SETRec's superior efficiency and show promising scalability on cold-start items as model sizes increase. 



\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
% \vspace{-2pt}
\begin{CCSXML}
% <ccs2012>
% <concept>
% <concept_id>10002951.10003260.10003261.10003271</concept_id>
% <concept_desc>Information systems~Personalization</concept_desc>
% <concept_significance>500</concept_significance>
% </concept>
<concept>
<concept_id>10002951.10003317.10003347.10003350</concept_id>
<concept_desc>Information systems~Recommender systems</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}
% \ccsdesc[500]{Information systems~Personalization}
\ccsdesc[500]{Information systems~Recommender systems}
% \vspace{-2pt}
\keywords{Item Tokenization, Set Identifier, LLM-based Recommendation}



\maketitle

% \def\thefootnote{*}\footnotetext{Corresponding author. This work is supported by the CCCD Key Lab of Ministry of Culture and Tourism.}

\input{1_intro}
\input{2_0_task}
\input{2_1_method}
\input{3_exp}
\input{4_related_work}
\input{5_conclusion}

% \clearpage
% \appendix
% \input{6_SI}


{
\tiny
\bibliographystyle{ACM-Reference-Format}
\balance
\bibliography{bibfile}
}

\newpage
% \appendix
% \input{6_SI}


\end{document}
\endinput

