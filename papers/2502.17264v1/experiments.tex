\section{Experiments}
We empirically evaluate the conditional coverage of Kandinsky conformal prediction on real-world tasks with natural groups: income prediction across US states~\citep{DingHMS21} and toxic comment detection across demographic groups~\citep{BDSTV19,Koh21}. The data is divided into a training set for learning the base predictor, a calibration set for learning the conformal predictor, and a test set for evaluation. We repeat all experiments 100 times with reshuffled calibration and test sets.
\paragraph{Algorithms.}  We implement Kandinsky conformal prediction as described in Algorithms~\ref{alg:quantile_reg} and \ref{alg:pred_set} for probabilistic groups. According to \Cref{cor: fract-cov}, we estimate the basis function $\Phi_G$~(see \Cref{eq:Phi_XY}) using a Gradient Boosting Tree classifier. \emph{Kandinsky (XY)} uses the covariates and the label as input to learn the basis ($\phi=(X,Y)$), while \emph{Kandinsky (FY)} uses the output of the predictor and the label ($\phi=(f(X),Y)$). We compare this approach with \emph{split} conformal prediction, \emph{class-conditional} conformal prediction~\citep{LBLJ15} (where labels are discrete), and \emph{conservative} conformal prediction~\citep{BCRT21}, which estimates the $(1-\alpha)$-quantile of scores for each group and constructs sets using the score threshold determined by the maximum quantile. 
\paragraph{Metrics.} Given $m$ test samples, we measure the group-conditional miscoverage $\operatorname{M}(G, \calC)$ for a group $G$ and a prediction set $\calC$.
\begin{align*}
\operatorname{M}(G,\calC) \coloneqq \frac{\sum_{i=n+1}^{n+m} \11\sth{Y_{i} \not\in\calC(X_i)}\cdot\11\sth{Z_i\in G}}{\sum_{i=n+1}^{n+m} \11\sth{Z_i\in G}}.
\end{align*}
We compute the group average coverage deviation $\operatorname{CD}(\calC)$.
\begin{align*}
    \operatorname{CD}(\calC) \coloneqq \frac{1}{|\calG|}\sum_{G\in\calG} \left|\operatorname{M}(G,\calC) - \alpha\right|.
\end{align*}
We also evaluate the prediction set size. For real-valued labels, we divide the label domain into 100 evenly spaced bins. We count the number of bin midpoints that fall within the prediction set and estimate its size by multiplying this number by the bin width.

\subsection{ACSIncome: A Regression Example}
We predict personal income using US Census data collected from different states, aiming to achieve the target coverage conditioned on each state. The state attribute is omitted from the covariates and labels of the test points. We investigate the scalability of the algorithms by varying the number of groups in the calibration and test set, while controlling the number of samples per group. Specifically, we sample 10,000 individuals per state to train a base Gradient Boosting Tree regressor and the basis weight functions for our method. We sample 4,000 individuals per state for calibration and 2,000 individuals for testing. The experiment is performed over 31 states, each with at least 16,000 samples. We use the Conformalized Quantile Regression score function (CQR) \citep{RPC19}. For further details, see \Cref{subsec:app_acs}.

Kandinsky conformal prediction achieves the best group average coverage deviation, as shown in \Cref{fig:main_a}. Weight functions based on predictors and labels (FY) slightly outperform those based on covariates and labels (XY), as learning a group classifier with lower-dimensional input is easier with finite samples. Both Kandinsky algorithms maintain stable average coverage deviation as the number of groups increases. \Cref{fig:main_b} shows that our approach achieves the minimum difference between the maximum and minimum miscoverage across various groups. All algorithms exhibit a larger gap with more groups, aligned with the universal bound on the maximum group coverage deviation (\Cref{cor: fract-cov}), which scales inversely with the relative proportion of subgroups. Kandinsky (XY) produces prediction sets with moderate and stable sizes for various groups numbers, while the size of Kandinsky (FY) scales with the number of groups, as shown in \Cref{fig:main_c}. This reveals a tradeoff between the computational efficiency of learning a weight function class and the effectiveness of the prediction set. 

\subsection{CivilComments: A Classification Example}
The task is to detect whether comments on online articles contain toxic content.  Demographic attributes, such as gender, religion, race, and sexual orientation, are sometimes mentioned in the comments. According to the \citet{Koh21} benchmark, there are 16 overlapping groups jointly defined by eight demographic attributes and two labels. We consider a setup where the conformal prediction algorithm has only indirect access to the training data through a given base predictor, a DistilBERT model finetuned on the training split. Kandinsky conformal prediction (XY) cannot be applied, and the weight functions of Kandinsky (FY) are trained on the calibration set. We use the randomized Adaptive Prediction Sets (APS) score function \citep{RSC20,DABJT23}. We also evaluate the algorithmsâ€™ adaptability to varying calibration sample sizes by redistributing samples between the calibration and test sets. See \Cref{subsec:app_civil} for more details.

Kandinsky conformal prediction achieves the best group average coverage deviation when the calibration set contains an average of over 500 samples per group, as shown in \Cref{fig:main_d}. Class-conditional conformal prediction achieves the best performance with 250 samples per group. However, unlike our approach, its coverage deviation does not improve with larger sample sizes. This is because Kandinsky considers the full set of groups, which are more fine-grained than classes. In \Cref{fig:main_e,fig:main_f}, we examine conditional miscoverage and prediction set sizes for each group under the setting of 4000 group average samples. Overall, Kandinsky generates prediction sets with conditional miscoverage closest to the target level for most groups while maintaining moderate sizes. We achieve the best calibrated coverage for groups with more than 2000 samples.




\ifarxiv
\begin{figure}[t]
    \centering
    \subfigure[\parbox{0.4\linewidth}{ACSIncome. The distribution of group average coverage deviation across 100 runs.}]
    {
    \includegraphics[height=3.2cm]{figures/acsincome_summary_deviation.pdf}
    \label{fig:main_a}
    }
    \hspace{-0.4cm} % Adjust this value to control horizontal space
    % \hspace{0cm} % Adjust this value to control horizontal space
    \subfigure[\parbox{0.9\linewidth}{ACSIncome. The distribution of group conditional miscoverage (mean over 100 runs) across different groups. Whiskers extend to min and max values. Target miscoverage is 0.1.}]{
        \includegraphics[height=3.2cm]{figures/acsincome_summary_minmax.pdf}
        \label{fig:main_b}
    }
     \subfigure[\parbox{0.4\linewidth}{ACSIncome. The distribution of average prediction set sizes across 100 runs.}]{
        \includegraphics[height=3.2cm]{figures/acsincome_summary_size.pdf}
        \label{fig:main_c}
    }
    \hspace{-0.4cm}
    % \vskip 1ex % Adjust vertical space between rows
    \subfigure[\parbox{0.9\linewidth}{CivilComments. The distribution of group average coverage deviation across 100 runs.}]{
        \includegraphics[height=3.2cm]{figures/civilcomments_separate_propensity_val_summary_sample_coverage.pdf}
        \label{fig:main_d}
    }
    % Adjust this value to control horizontal space
    % \subfigure[Subfigure 5]{
    %     \includegraphics[height=4cm]{figures/icml_numpapers.pdf}
    % }
    % \hspace{0cm} % Adjust this value to control horizontal space
    % \subfigure[Subfigure 6]{
    %     \includegraphics[height=4cm]{figures/icml_numpapers.pdf}
    % }
    \subfigure[\parbox{1\linewidth}{CivilComments. Conditional miscoverage for each group. Target miscoverage is 0.1. Error bars are standard deviations of 100 runs.}]{
        \includegraphics[height=4.5cm]{figures/civilcomments_separate_propensity_val_summary_miscoverage.pdf}
        \label{fig:main_e}
    }
    \subfigure[\parbox{1\linewidth}{CivilComments. Average prediction set sizes for each group. Error bars are standard deviations of 100 runs.}]{
        \includegraphics[height=4.5cm]{figures/civilcomments_separate_propensity_val_summary_size.pdf}
        \label{fig:main_f}
    }
    \caption{Results. (a)(b)(c) ACSIncome. We vary the number of groups in calibration and test sets while controlling samples per group. (d) CivilComments. We redistribute samples between calibration and test sets to vary the number of calibration samples. (e)(f) CivilComments. There are 4000 calibration samples per group on average. We annotate the calibration sample size for each group. Groups with positive labels (toxic) are represented by y:1.} 
    \label{fig:mainfigure}
\end{figure}
\else
\begin{figure*}[t]
    \centering
    \subfigure[\parbox{0.4\linewidth}{ACSIncome. The distribution of group average coverage deviation across 100 runs.}]
    {
    \includegraphics[height=3.4cm]{figures/acsincome_summary_deviation.pdf}
    \label{fig:main_a}
    }
    \hspace{-0.4cm} % Adjust this value to control horizontal space
    % \hspace{0cm} % Adjust this value to control horizontal space
    \subfigure[\parbox{0.45\linewidth}{ACSIncome. The distribution of group conditional miscoverage (mean over 100 runs) across different groups. Whiskers extend to min and max values. Target miscoverage is 0.1.}]{
        \includegraphics[height=3.4cm]{figures/acsincome_summary_minmax.pdf}
        \label{fig:main_b}
    }
     \subfigure[\parbox{0.4\linewidth}{ACSIncome. The distribution of average prediction set sizes across 100 runs.}]{
        \includegraphics[height=3.4cm]{figures/acsincome_summary_size.pdf}
        \label{fig:main_c}
    }
    \hspace{-0.4cm}
    % \vskip 1ex % Adjust vertical space between rows
    \subfigure[\parbox{0.45\linewidth}{CivilComments. The distribution of group average coverage deviation across 100 runs.}]{
        \includegraphics[height=3.4cm]{figures/civilcomments_separate_propensity_val_summary_sample_coverage.pdf}
        \label{fig:main_d}
    }
    \hspace{0cm} % Adjust this value to control horizontal space
    % \subfigure[Subfigure 5]{
    %     \includegraphics[height=4cm]{figures/icml_numpapers.pdf}
    % }
    % \hspace{0cm} % Adjust this value to control horizontal space
    % \subfigure[Subfigure 6]{
    %     \includegraphics[height=4cm]{figures/icml_numpapers.pdf}
    % }
    \subfigure[\parbox{1\linewidth}{CivilComments. Conditional miscoverage for each group. Target miscoverage is 0.1. Error bars are standard deviations of 100 runs.}]{
        \includegraphics[height=5cm]{figures/civilcomments_separate_propensity_val_summary_miscoverage.pdf}
        \label{fig:main_e}
    }
    \subfigure[\parbox{1\linewidth}{CivilComments. Average prediction set sizes for each group. Error bars are standard deviations of 100 runs.}]{
        \includegraphics[height=5cm]{figures/civilcomments_separate_propensity_val_summary_size.pdf}
        \label{fig:main_f}
    }
    \caption{Results. (a)(b)(c) ACSIncome. We vary the number of groups in calibration and test sets while controlling samples per group. (d) CivilComments. We redistribute samples between calibration and test sets to vary the number of calibration samples. (e)(f) CivilComments. There are 4000 calibration samples per group on average. We annotate the calibration sample size for each group. Groups with positive labels (toxic) are represented by y:1.} 
    \label{fig:mainfigure}
\end{figure*}
\fi

