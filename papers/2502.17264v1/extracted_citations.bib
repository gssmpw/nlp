@article{ABB24,
  title={Theoretical foundations of conformal prediction},
  author={Angelopoulos, Anastasios N and Barber, Rina Foygel and Bates, Stephen},
  journal={arXiv preprint arXiv:2411.11824},
  year={2024}
}

@article{ABMJ20,
  title={Uncertainty sets for image classifiers using conformal prediction},
  author={Angelopoulos, Anastasios and Bates, Stephen and Malik, Jitendra and Jordan, Michael I},
  journal={arXiv preprint arXiv:2009.14193},
  year={2020}
}

@inproceedings{ACDR24,
  author       = {Felipe Areces and
                  Chen Cheng and
                  John C. Duchi and
                  Kuditipudi Rohith},
  editor       = {Shipra Agrawal and
                  Aaron Roth},
  title        = {Two fundamental limits for uncertainty quantification in predictive
                  inference},
  booktitle    = {The Thirty Seventh Annual Conference on Learning Theory, June 30 -
                  July 3, 2023, Edmonton, Canada},
  series       = {Proceedings of Machine Learning Research},
  volume       = {247},
  pages        = {186--218},
  publisher    = {{PMLR}},
  year         = {2024}
}

@book{AlgorithmicLearning2005,
  author    = {Vladimir Vovk and Alexander Gammerman and Glenn Shafer},
  title     = {Algorithmic Learning in a Random World},
  publisher = {Springer},
  year      = {2005},
  isbn      = {978-0-387-22825-8}
}

@article{BCRT21,
  title={The limits of distribution-free conditional predictive inference},
  author={Barber, Rina Foygel and Candes, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
  journal={Information and Inference: A Journal of the IMA},
  volume={10},
  number={2},
  pages={455--482},
  year={2021},
  publisher={Oxford University Press}
}

@book{BHV14,
  title={Conformal prediction for reliable machine learning: theory, adaptations and applications},
  author={Balasubramanian, Vineeth and Ho, Shen-Shyang and Vovk, Vladimir},
  year={2014},
  publisher={Newnes}
}

@inproceedings{DABJT23,
  author       = {Tiffany Ding and
                  Anastasios Angelopoulos and
                  Stephen Bates and
                  Michael I. Jordan and
                  Ryan J. Tibshirani},
  title        = {Class-Conditional Conformal Prediction with Many Classes},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023}
}

@article{G23,
  title={Localized conformal prediction: A generalized inference framework for conformal prediction},
  author={Guan, Leying},
  journal={Biometrika},
  volume={110},
  number={1},
  pages={33--50},
  year={2023},
  publisher={Oxford University Press}
}

@article{GAO24,
  title={Adjusting regression models for conditional uncertainty calibration},
  author={Gao, Ruijiang and Yin, Mingzhang and Mcinerney, James and Kallus, Nathan},
  journal={Machine Learning},
  pages={1--24},
  year={2024},
  publisher={Springer}
}

@article{GCC2023,
  title={Conformal prediction with conditional guarantees},
  author={Gibbs, Isaac and Cherian, John J and Cand{\`e}s, Emmanuel J},
  journal={arXiv preprint arXiv:2305.12616},
  year={2023}
}

@article{HB24,
  title={Conformal prediction with local weights: randomization enables robust guarantees},
  author={Hore, Rohan and Barber, Rina Foygel},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  pages={qkae103},
  year={2024},
  publisher={Oxford University Press UK}
}

@inproceedings{HKRR18,
  author       = {{\'{U}}rsula H{\'{e}}bert{-}Johnson and
                  Michael P. Kim and
                  Omer Reingold and
                  Guy N. Rothblum},
  editor       = {Jennifer G. Dy and
                  Andreas Krause},
  title        = {Multicalibration: Calibration for the (Computationally-Identifiable)
                  Masses},
  booktitle    = {Proceedings of the 35th International Conference on Machine Learning,
                  {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
                  10-15, 2018},
  series       = {Proceedings of Machine Learning Research},
  volume       = {80},
  pages        = {1944--1953},
  publisher    = {{PMLR}},
  year         = {2018}
}

@inproceedings{IzbickiSS20,
  author       = {Rafael Izbicki and
                  Gilson Y. Shimizu and
                  Rafael Bassi Stern},
  editor       = {Silvia Chiappa and
                  Roberto Calandra},
  title        = {Flexible distribution-free conditional predictive bands using density
                  estimators},
  booktitle    = {The 23rd International Conference on Artificial Intelligence and Statistics,
                  {AISTATS} 2020, 26-28 August 2020, Online [Palermo, Sicily, Italy]},
  series       = {Proceedings of Machine Learning Research},
  volume       = {108},
  pages        = {3068--3077},
  publisher    = {{PMLR}},
  year         = {2020}
}

@inproceedings{JNRR2023,
  author       = {Christopher Jung and
                  Georgy Noarov and
                  Ramya Ramalingam and
                  Aaron Roth},
  title        = {Batch Multivalid Conformal Prediction},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023}
}

@inproceedings{KGZ19,
  author       = {Michael P. Kim and
                  Amirata Ghorbani and
                  James Y. Zou},
  editor       = {Vincent Conitzer and
                  Gillian K. Hadfield and
                  Shannon Vallor},
  title        = {Multiaccuracy: Black-Box Post-Processing for Fairness in Classification},
  booktitle    = {Proceedings of the 2019 {AAAI/ACM} Conference on AI, Ethics, and Society,
                  {AIES} 2019, Honolulu, HI, USA, January 27-28, 2019},
  pages        = {247--254},
  publisher    = {{ACM}},
  year         = {2019}
}

@article{KKGKR22,
author = {Michael P. Kim  and Christoph Kern  and Shafi Goldwasser  and Frauke Kreuter  and Omer Reingold },
title = {Universal adaptability: Target-independent inference that competes with propensity scoring},
journal = {Proceedings of the National Academy of Sciences},
volume = {119},
number = {4},
pages = {e2108097119},
year = {2022}}

@inproceedings{KNRW19,
author = {Kearns, Michael and Neel, Seth and Roth, Aaron and Wu, Zhiwei Steven},
title = {An Empirical Study of Rich Subgroup Fairness for Machine Learning},
year = {2019},
isbn = {9781450361255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Kearns, Neel, Roth, and Wu [ICML 2018] recently proposed a notion of rich subgroup fairness intended to bridge the gap between statistical and individual notions of fairness. Rich subgroup fairness picks a statistical fairness constraint (say, equalizing false positive rates across protected groups), but then asks that this constraint hold over an exponentially or infinitely large collection of subgroups defined by a class of functions with bounded VC dimension. They give an algorithm guaranteed to learn subject to this constraint, under the condition that it has access to oracles for perfectly learning absent a fairness constraint. In this paper, we undertake an extensive empirical evaluation of the algorithm of Kearns et al. On four real datasets for which fairness is a concern, we investigate the basic convergence of the algorithm when instantiated with fast heuristics in place of learning oracles, measure the tradeoffs between fairness and accuracy, and compare this approach with the recent algorithm of Agarwal, Beygelzeimer, Dudik, Langford, and Wallach [ICML 2018], which implements weaker and more traditional marginal fairness constraints defined by individual protected attributes. We find that in general, the Kearns et al. algorithm converges quickly, large gains in fairness can be obtained with mild costs to accuracy, and that optimizing accuracy subject only to marginal fairness leads to classifiers with substantial subgroup unfairness. We also provide a number of analyses and visualizations of the dynamics and behavior of the Kearns et al. algorithm. Overall we find this algorithm to be effective on real data, and rich subgroup fairness to be a viable notion in practice.},
booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
pages = {100–109},
numpages = {10},
keywords = {Subgroup Fairness, Fairness Auditing, Fair Classification, Algorithmic Bias},
location = {Atlanta, GA, USA},
series = {FAT* '19}
}

@article{LBLJ15,
  author       = {Tuve L{\"{o}}fstr{\"{o}}m and
                  Henrik Bostr{\"{o}}m and
                  Henrik Linusson and
                  Ulf Johansson},
  title        = {Bias reduction through conditional conformal prediction},
  journal      = {Intell. Data Anal.},
  volume       = {19},
  number       = {6},
  pages        = {1355--1375},
  year         = {2015}
}

@article{LGRTW18,
  title={Distribution-free predictive inference for regression},
  author={Lei, Jing and G’Sell, Max and Rinaldo, Alessandro and Tibshirani, Ryan J and Wasserman, Larry},
  journal={Journal of the American Statistical Association},
  volume={113},
  number={523},
  pages={1094--1111},
  year={2018},
  publisher={Taylor \& Francis}
}

@article{LeiRW2013,
  title={Distribution-free prediction sets},
  author={Lei, Jing and Robins, James and Wasserman, Larry},
  journal={Journal of the American Statistical Association},
  volume={108},
  number={501},
  pages={278--287},
  year={2013},
  publisher={Taylor \& Francis}
}

@article{PNI24,
  title={Training-Conditional Coverage Bounds under Covariate Shift},
  author={Pournaderi, Mehrdad and Xiang, Yu},
  journal={arXiv preprint arXiv:2405.16594},
  year={2024}
}

@inproceedings{PPVG02,
  title={Inductive confidence machines for regression},
  author={Papadopoulos, Harris and Proedrou, Kostas and Vovk, Volodya and Gammerman, Alex},
  booktitle={Machine learning: ECML 2002: 13th European conference on machine learning Helsinki, Finland, August 19--23, 2002 proceedings 13},
  pages={345--356},
  year={2002},
  organization={Springer}
}

@inproceedings{PR21,
  title={Distribution-free uncertainty quantification for classification under label shift},
  author={Podkopaev, Aleksandr and Ramdas, Aaditya},
  booktitle={Uncertainty in artificial intelligence},
  pages={844--853},
  year={2021},
  organization={PMLR}
}

@article{QDT23,
  title={Prediction sets adaptive to unknown covariate shift},
  author={Qiu, Hongxiang and Dobriban, Edgar and Tchetgen Tchetgen, Eric},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={85},
  number={5},
  pages={1680--1705},
  year={2023},
  publisher={Oxford University Press US}
}

@article{RBSC20,
  title={With malice toward none: Assessing uncertainty via equalized coverage},
  author={Romano, Yaniv and Barber, Rina Foygel and Sabatti, Chiara and Cand{\`e}s, Emmanuel},
  journal={Harvard Data Science Review},
  volume={2},
  number={2},
  pages={4},
  year={2020},
  publisher={MIT Press-Journals}
}

@article{RO22,
  title={Uncertain: Modern topics in uncertainty estimation},
  author={Roth, Aaron},
  journal={Unpublished Lecture Notes},
  pages={2},
  year={2022}
}

@inproceedings{RPC19,
  author       = {Yaniv Romano and
                  Evan Patterson and
                  Emmanuel J. Cand{\`{e}}s},
  editor       = {Hanna M. Wallach and
                  Hugo Larochelle and
                  Alina Beygelzimer and
                  Florence d'Alch{\'{e}}{-}Buc and
                  Emily B. Fox and
                  Roman Garnett},
  title        = {Conformalized Quantile Regression},
  booktitle    = {Advances in Neural Information Processing Systems 32: Annual Conference
                  on Neural Information Processing Systems 2019, NeurIPS 2019, December
                  8-14, 2019, Vancouver, BC, Canada},
  pages        = {3538--3548},
  year         = {2019}
}

@inproceedings{RSC20,
  author       = {Yaniv Romano and
                  Matteo Sesia and
                  Emmanuel J. Cand{\`{e}}s},
  title        = {Classification with Valid and Adaptive Coverage},
  booktitle    = {Advances in Neural Information Processing Systems 33: Annual Conference
                  on Neural Information Processing Systems 2020, NeurIPS 2020, December
                  6-12, 2020, virtual},
  year         = {2020}
}

@article{SLW19,
  title={Least ambiguous set-valued classifiers with bounded error levels},
  author={Sadinle, Mauricio and Lei, Jing and Wasserman, Larry},
  journal={Journal of the American Statistical Association},
  volume={114},
  number={525},
  pages={223--234},
  year={2019},
  publisher={Taylor \& Francis}
}

@article{SV08,
  title={A tutorial on conformal prediction.},
  author={Shafer, Glenn and Vovk, Vladimir},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={3},
  year={2008}
}

@inproceedings{TBCR19,
  author       = {Ryan J. Tibshirani and
                  Rina Foygel Barber and
                  Emmanuel J. Cand{\`{e}}s and
                  Aaditya Ramdas},
  editor       = {Hanna M. Wallach and
                  Hugo Larochelle and
                  Alina Beygelzimer and
                  Florence d'Alch{\'{e}}{-}Buc and
                  Emily B. Fox and
                  Roman Garnett},
  title        = {Conformal Prediction Under Covariate Shift},
  booktitle    = {Advances in Neural Information Processing Systems 32: Annual Conference
                  on Neural Information Processing Systems 2019, NeurIPS 2019, December
                  8-14, 2019, Vancouver, BC, Canada},
  pages        = {2526--2536},
  year         = {2019}
}

@article{VLNG03,
  title={Mondrian confidence machine},
  author={Vovk, Vladimir and Lindsay, David and Nouretdinov, Ilia and Gammerman, Alex},
  journal={Technical Report},
  year={2003}
}

@article{XIE24,
  title={Boosted Conformal Prediction Intervals},
  author={Xie, Ran and Barber, Rina Foygel and Cand{\`e}s, Emmanuel J},
  journal={arXiv preprint arXiv:2406.07449},
  year={2024}
}

@article{YKT24,
  title={Doubly robust calibration of prediction sets under covariate shift},
  author={Yang, Yachong and Kuchibhotla, Arun Kumar and Tchetgen Tchetgen, Eric},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  pages={qkae009},
  year={2024},
  publisher={Oxford University Press US}
}

@article{ZHG24,
  title={Posterior conformal prediction},
  author={Zhang, Yao and Cand{\`e}s, Emmanuel J},
  journal={arXiv preprint arXiv:2409.19712},
  year={2024}
}

@InProceedings{kearns18a,
  title = 	 {Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness},
  author =       {Kearns, Michael and Neel, Seth and Roth, Aaron and Wu, Zhiwei Steven},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2564--2572},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  abstract = 	 {The most prevalent notions of fairness in machine learning fix a small collection of pre-defined groups (such as race or gender), and then ask for approximate parity of some statistic of the classifier (such as false positive rate) across these groups. Constraints of this form are susceptible to fairness gerrymandering, in which a classifier is fair on each individual group, but badly violates the fairness constraint on structured subgroups, such as certain combinations of protected attribute values. We thus consider fairness across exponentially or infinitely many subgroups, defined by a structured class of functions over the protected attributes. We first prove that the problem of auditing subgroup fairness for both equality of false positive rates and statistical parity is computationally equivalent to the problem of weak agnostic learning — which means it is hard in the worst case, even for simple structured subclasses. However, it also suggests that common heuristics for learning can be applied to successfully solve the auditing problem in practice. We then derive an algorithm that provably converges in a polynomial number of steps to the best subgroup-fair distribution over classifiers, given access to an oracle which can solve the agnostic learning problem. The algorithm is based on a formulation of subgroup fairness as a zero-sum game between a Learner (the primal player) and an Auditor (the dual player). We implement a variant of this algorithm using heuristic oracles, and show that we can effectively both audit and learn fair classifiers on a real dataset.}
}

