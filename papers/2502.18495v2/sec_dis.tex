
\label{sec:dis}
\section{Discussion and Future Directions}
The introduction of CIR tasks has garnered significant interest due to its requirement for joint reasoning over visual and textual information, making it a challenging endeavor. To better retrieve the target image within the database, the CIR model should comprehend both the image's prototype information and semantic information of modification text. Existing methods in this domain can be broadly categorized into two main groups: supervised CIR and ZS-CIR. We first discuss the issues inherent in each category and point out the possible technological trends of each type. Additionally, we briefly discuss the related tasks of CIR. 

\subsection{Supervised Composed Image Retrieval}
The future work directions for supervised CIR are given as follows.
\begin{itemize}
    \item \textbf{Benchmark Dataset Construction.} As mentioned earlier, most existing CIR datasets are limited to specific domains, \textit{e.g.}, fashion or bird species. Additionally, the false negative issue is prevalent in current datasets due to the data annotation strategy, which first identifies potential image pairs and then annotates the modification text for each pair. Although the open-domain dataset CIRR has been released to address the false negative issue, it still faces two main challenges. First, previous studies~\cite{pic2word,searle} have shown that in many cases, simply relying on the modification text is sufficient to accurately identify the target image in CIRR. Second, CIRR provides only one-to-one query-target correspondence, which does not align with real-world scenarios where multiple images in the dataset may satisfy the retrieval requirements. Creating open-domain CIR datasets with multiple ground-truth target images while mitigating false negatives remains an open challenge requiring further exploration. Furthermore, the scale of existing public datasets is limited; the largest dataset contains only approximately $18.8$M samples. According to the scaling law~\cite{scalinglaw}, the performance and generalization capabilities of CIR improve with larger-scale datasets.  Nevertheless, we must acknowledge that constructing large-scale triplet datasets is both resource-intensive and time-consuming. In fact, MagicLens has made an attempt in this regard by devising a pipeline to generate triplets from web pages in a self-supervised manner, yielding $36.7$M triplets. Unfortunately, this dataset is neither publicly accessible nor sufficiently large. Therefore, we advocate for the development of publicly accessible, large-scale triplet datasets, as such resources would inject new vitality into the field of CIR.
    \item \textbf{LLM-based Image-Text Fusion.} 
    % Existing CIR methods primarily employ traditional neural networks (\textit{e.g.}, MLP and attention mechanisms) to perform image-text fusion. While the reasoning capabilities of LLMs or MLLMs have been explored for pseudo triplet generation to address the ZS-CIR task, limited supervised CIR efforts~\cite{zhong2024compositional} have investigated their potential in encoding input image/text queries and achieving image-text fusion. It has been demonstrated that LLMs can be fine-tuned for specific downstream tasks to enhance their encoding capabilities~\cite{mcl,finetunellama}. \textcolor{red}{These approaches aim to leverage the strong reasoning capabilities of LLMs to address CIR tasks.} However, a key issue is that improving the encoding capabilities of LLMs may compromise their inherent reasoning abilities. Developing fine-tuning strategies that enhance the encoding capabilities of LLMs while preserving their native reasoning abilities is a critical direction that warrants further investigation. 
    Existing CIR methods have made efforts to devise diverse image-text fusion strategies as reviewed above. While the reasoning capabilities of LLMs or MLLMs have been explored for pseudo triplet generation to address the ZS-CIR task, limited CIR efforts~\cite{zhong2024compositional,mcl} have investigated their potential in encoding input image/text queries and achieving image-text fusion. 
    These approaches use <reference image, modification text, target caption> triplets, generated by their data generation pipelines, for contrastive learning to fine-tune and align the model's encoding capabilities for CIR tasks, while the encoding output is regarded as the fused query embedding. 
    Despite their promising progress, a key issue they suffer from is that improving the encoding capabilities of LLMs may compromise their inherent reasoning abilities. Developing advanced fine-tuning strategies that enhance the encoding capabilities of LLMs while preserving their native reasoning abilities is a critical direction that warrants further investigation.
    \item \textbf{Target Matching with Noisy Data}. 
    Due to the complex nature of the CIR task, manually annotated datasets may contain noisy triplets. For instance, we have empirically observed that some triplets in existing CIR datasets are nonsensical, such as mismatched images and textual descriptions or modification text descriptions unrelated to the corresponding images. Such noisy triplets can mislead the model and hinder its ability to accurately match queries with targets. To address this issue, the model should be capable of learning query-target matching robustly under noisy data conditions. This necessitates the development of adaptive mechanisms that can selectively utilize useful information from the training data while disregarding noise. In conclusion, building a robust CIR model that can effectively handle noisy data remains an open and valuable research direction.
    \item \textbf{Target Matching with Biased Data}. As mentioned earlier, to avoid false negative samples, the annotation of modification text in existing open-domain datasets may sometimes be overly specific. This can lead to scenarios where simply using the text query can correctly retrieve the target image. Consequently, the conventional target matching paradigm may overfit spurious correlations between the text query and the target image while failing to accurately learn the matching relationship between the multimodal query and the target image. This limitation can negatively impact the model's generalization capabilities. To address this issue, the key challenge lies in mitigating the harmful effects while preserving the beneficial contributions of the text query in the context of CIR. Investigating the causal relationships among elements in CIR presents a promising research direction to tackle this challenge.
    \item \textbf{Efficient Reranking.} To enhance the ranking of target images, existing reranking methods in the CIR domain typically conduct more sophisticated point-wise evaluations on the retrieved candidate set, which inherently incurs a high time cost. To ensure that the desired target image can be retrieved, the size of the candidate set for reranking cannot be too small. Consequently, the time cost associated with reranking becomes significant and cannot be overlooked. To make reranking suitable for real-world retrieval scenarios, developing efficient reranking methods is essential and should be a key focus for future research. Furthermore, current reranking and retrieval stages operate independently, with limited correlation. Investigating how these stages can be better integrated to mutually enhance one another represents another promising research avenue.
     \item \textbf{Model Interpretability.} As CIR models grow increasingly complex, their interpretability decreases, making it challenging to understand how decisions are made during the retrieval process. This lack of transparency poses significant challenges for debugging and improving models, as well as for building user trust. Future research directions could focus on designing hybrid models that integrate deep learning with interpretable components or on utilizing post-hoc explanation techniques to shed light on the decision-making process. 
     \item \textbf{Task Synergy.} The triplets in CIR also pertain to other related tasks. For example, text-based image editing~\cite{imageediting1, imageediting2} necessitates a reference image along with a modification text to synthesize the desired target image, which bears a high degree of relevance to the format of CIR. Ideally, integrating retrieval and generation in one framework~\cite{unifashion} would mutually enhance both, achieving a ``kill two birds with one stone'' effect. Specifically, during generation, the model needs to comprehensively envision the desired target image, which would be beneficial for CIR. Moreover, generated low-quality images can be regarded as a type of hard negative, boosting the metric learning in retrieval. Additionally, the retrieval task mainly centers around discriminative features rather than pixel-level generation. Consequently, its complexity is lower and the model converges more readily. This, in turn, can contribute to the continuous learning of the generative process. Moreover, with retrieval capabilities, one can utilize retrieved images as references to attain a retrieval-augmented generation (RAG) effect in the image generation domain. This unified framework also affords users the flexibility to obtain either the retrieved real images or the synthesized ones based on one query. 
\end{itemize}

\subsection{Zero-shot Composed Image Retrieval}
Compared to supervised CIR methods, ZS-CIR approaches eliminate the need for annotated training triplets. Instead, they leverage readily available pre-trained data or utilize modular combinations in a training-free manner to build models. While significant progress has been achieved, several challenges and open questions remain.
\begin{itemize}
    \item \textbf{Pseudo Triplets Generation.}
    Some researchers have explored the automatic generation of pseudo triplets, enabling CIR model training without the need for manually annotated triplets. However, current methods typically use an existing captioning model to convert an image into a caption and then generate the modification text with LLMs. These approaches may suffer from information loss during the modality transformation, as the generated image captions often capture only coarse-grained attributes (\textit{e.g.}, the color of a dress) while missing fine-grained visual details (\textit{e.g.}, the logo on the dress). This limitation has two main adverse effects: it constrains the identification of potential reference-target image pairs and results in coarse-grained modifications, failing to capture more challenging fine-grained variations. Furthermore, using uniform prompts to generate all triplets can reduce the diversity of generated samples. In contrast, real-world users often express modification requirements in various styles. As a result, building high-quality pseudo triplets for training CIR models remains a significant challenge.
 \item \textbf{MLLM-based Training-free Methods.} Without additional design of pre-training tasks, training-free methods present themselves as straightforward and promising options in this field. Typically, existing training-free methods predominantly utilize LLMs to summarize the caption of the reference image along with the modification text, thereby transforming the task into text-to-image retrieval. However, relying on second-hand information on the reference image might lead to bottlenecks and only attain suboptimal performance. With the rapid development of MLLMs, a promising research avenue is to explore the direct utilization of MLLMs to process multimodal queries for ZS-CIR.
    \item \textbf{Efficient Retrieval.} The current evaluation protocol primarily concentrates on retrieval efficacy while neglecting retrieval efficiency. Consequently, the devised methods merely focus on enhancing retrieval performance. However, such approaches might not be practical in real-world scenarios. For example, certain methods~\cite{ldre, seize} make LLM reason about the multimodal query multiple times to enhance the retrieval effect, yet this incurs a high time cost. Therefore, striking a balance between efficacy and efficiency is crucial to ensure that the research not only remains relevant in academia but also holds potential application value. This entails two aspects. Firstly, the method itself ought to be lightweight. Secondly, during the similarity computing process, some accelerated retrieval techniques, such as hash learning~\cite{hash} and index structure~\cite{index}, should also be explored.
    %Current Training-free ZS-CIR methods often depend on LLMs to re-summarize multi-modal queries into pure text or use MLLMs for unified reasoning across modalities. While these approaches achieve impressive results due to the capabilities of powerful LLMs, their inference efficiency is compromised by the substantial computational resources required. Therefore, striking a balance between the model's retrieval efficiency and retrieval performance is a key area for future exploration. 
    
  %  \item \textbf{Flexible Text Instruction.} In real-world scenarios, users' search demands are diverse, ranging from looking for visually similar images with conditioned modification to seeking logically related images for a given reference image (such as a different view of a building). Currently, CIR models mainly treat the text query as a modification text. In fact, the text query can be treated as an open-ended instruction~\cite{zhang2024magiclens}. %  Meanwhile, users may simply use a single-modal query or utilize a multimodal composite query for searching. %Meanwhile, apart from the similarity-oriented searching, users may perform compatibility-oriented searching, i.e., the text query indicates the users want a compatable image
   % Therefore, techniques that enable flexible retrieval to handle users' various searching requirements will be vital to enhancing the applicability of ZS-CIR models in diverse real-world scenarios.   Therefore, future research could focus on developing retrieval frameworks that can flexibly handle users' various searching intents.
   

%\item \textbf{Multi-Task CIR Methods} \textcolor{red}{HBH: Existing CIR works often focus on designing specialized models to handle specific CIR tasks. However, in real-world scenarios, users' search needs are diverse, including text-to-image, image-to-image, and even combined text+image-to-text+image~\cite{} searches. Current methods typically do not address unifying all these retrieval tasks into a single model. Exploring how to develop CIR methods capable of handling Multi-Task Retrieval is a promising research direction.  
%Even further, users may also require multimodal generation tasks alongside retrieval. Building a unified model that can balance both retrieval and generation tasks is likely to become a key research focus in the future.
%}
   \item \textbf{Few-shot CIR.} The generalization ability of existing supervised CIR models is often limited by the small scale of available datasets, while ZS-CIR completely avoids using labeled triplets. In practice, however, annotating a small number of samples is often feasible. Consequently, some pioneering studies~\cite{wu2023few,hou2024pseudo} have started to investigate the few-shot CIR task, which leverages a limited number of annotated triplets to enhance model training. A key research question in this area is how to select high-quality samples for annotation to maximize the benefits of manual annotation efforts.

% Existing supervised CIR models' generalization ability is typically constrained by the limited scale of the dataset, while ZS-CIR totally discards labeled triplets. As a matter of fact, in practice, annotating a small number of samples is often feasible. Therefore, some pioneer studies~\cite{wu2023few,hou2024pseudo} have begun to explore the few-shot CIR task, which can incorporate a few annotated triplets for enhancing the model training. A key research question in this area is how to select high-quality samples for annotation to maximize the benefits of manual annotation efforts.

\end{itemize}



%The mainstream supervised CIR methods are typically implemented using early fusion. These methods initially rely on existing image and text feature extraction backbone to obtain features from input queries. Subsequently, they use well-designed multi-modal fusion modules to integrate the information from both modalities. Finally, target-matching strategies are applied to retrieve images that fulfill the query requirements. Despite significant strides, several challenges and open questions remain. 1) Modality Discrepancy. The inherent differences between visual and textual modalities pose significant challenges for seamless integration and understanding. These discrepancies can lead to suboptimal fusion and retrieval performance. While current methods have introduced techniques like mutual information and uncertainty modeling to alleviate this issue, a deeper understanding of the interaction between different modalities remains an ongoing challenge. Future research could leverage the capabilities of advanced Multi-Modal Language Models (MLLMs) or VLMs to further address these discrepancies, aiming for more cohesive multi-modal representations. 2) Retrieval Accuracy: Achieving high retrieval accuracy is a persistent challenge, particularly when faced with ambiguous or complex queries. The precision of retrieval largely depends on the effectiveness of feature extraction and fusion modules. To enhance matching accuracy, future efforts might focus on refining multi-modal representation learning methods, adopting more effective fusion modules, or introducing appropriate target matching strategies.  



% 1) Large-scale triplet dataset. 
% The scale of existing CIR datasets is rather limited. Although there are several automatically constructed datasets, the largest among them only contains \textasciitilde $18.8$M samples. In light of the proposal and evidence of the scaling law~\cite{scalinglaw}, the performance and generalization capabilities of CIR can also be enhanced with larger-scale datasets. 

% This principle can be directly transferred from the image-text retrieval task, which can be regarded as a highly related yet relatively easier variant of CIR. In the early stage of image-text retrieval, the number of image-text pairs is also scarce. For instance, representative datasets such as MS COCO has \textasciitilde $0.6$M image-text pairs, and Flickr has \textasciitilde $0.16$M. Accordingly,  numerous ingeniously designed methods were devised to tackle this task, just like the current stage of CIR. However, in recent years, with the emergence of CLIP, a seemingly simple yet powerful method pre-trained on a vast image-text pair dataset (400 million samples), it has completely dominated the field and killed the game. CLIP has demonstrated extremely promising image-text retrieval performance and robust zero-shot capabilities in various downstream tasks. Notably, leveraging contrastive learning on large-scale image-text pairs has also laid the foundation for the vision component of mainstream MLLMs. Inspired by this, with a large-scale triplet dataset, CIR might follow a similar path where even the simplest method design could yield groundbreaking results, rendering elaborate image-text fusion or target matching strategies unnecessary. Moreover, since the query encompasses both image and text, well-trained retrieval methods could potentially serve as competitive alternatives to the mainstream ``CLIP-like'' approaches in the vision part of MLLMs. This is because they have been thoroughly trained to understand both modalities, thus possessing greater potential for achieving precise image-text alignment. 

% Nevertheless, we must acknowledge that constructing large-scale triplet datasets is both resource-intensive and time-consuming. In fact, MagicLens has made an attempt in this regard by devising a pipeline to generate triplets from web pages in a self-supervised manner, yielding $36.7$ M triplets. Unfortunately, this dataset is neither publicly accessible nor extensive enough. Therefore, we anticipate the availability of more publicly accessible, large-scale triplet datasets, which we believe will inject new vitality into the field of CIR. Moreover, we are eager to witness the advent of a ``CLIP era'' within the context of CIR, where revolutionary breakthroughs and rapid advancements similar to what CLIP brought could be replicated. 

% 2) Integrated with LLM/MLLM. 
% LLM/MLLM has showcased remarkable performance across numerous fields and have witnessed widespread application in CIR, particularly within the zero-shot scenario. Nevertheless, the majority of existing approaches are largely confined to leveraging LLM/MLLM solely for understanding multimodal queries. We argue that how to integrate with LLM/MLLM without undermining their original capabilities and the world knowledge they possess is of vital importance. The reason lies in the fact that the language processing and understanding prowess, along with the inherent world knowledge of LLM/MLLM, empower users to make more precise and refined modifications in the natural language form. Moreover, the outstanding multi-round dialogue ability of LLM/MLLM can be directly exploited to realize multi-round interactive image retrieval, which holds substantial potential for intelligent shopping guides on e-commerce platforms. 
% A promising strategy is to employ the tool calling technique~\cite{tool1, tool2}, regarding the CIR models as tools that can be invoked by LLM/MLLM. Through this means, seamless integration can be accomplished without negatively impacting the performance of the LLM/MLLM itself.

% 3) Balance between efficacy and efficiency. 
% The current evaluation protocol primarily concentrates on retrieval efficacy while neglecting retrieval efficiency. Consequently, the devised methods merely focus on enhancing retrieval performance. However, such approaches might not be practical in real-world scenarios, considering that the gallery can be extremely large and users generally demand low retrieval latency. For instance, certain methods design additional re-ranking strategies to further boost the retrieval effect or heavily rely on LLMs to handle multimodal queries, but these are unacceptable in real-world applications. Therefore, striking a balance between efficacy and efficiency is crucial to ensure that the research not only remains relevant in academia but also holds potential application value. This entails two aspects. Firstly, the model itself ought to be lightweight. Secondly, during the similarity computing process, some accelerated retrieval techniques, such as hash learning~\cite{hash} and index structure~\cite{index}], should also be explored within the framework of CIR.






\subsection{Relation Tasks of Composed Image Retrieval}
For the related tasks of CIR, current methods remain underdeveloped and require further refinement to fully leverage the unique attributes of each specific sub-task. This indicates a substantial opportunity for improvement by tailoring approaches more closely to the distinct characteristics and requirements of these tasks. 
In addition to refining current methodologies, exploring a broader range of novel and innovative sub-tasks presents an exciting avenue for future research. Expanding CIR tasks could lead to groundbreaking advancements in the field, opening up new possibilities for application and enhancing our understanding of CIR as a whole. Future research should focus on developing sophisticated models that are capable of seamlessly incorporating diverse modalities, thereby enriching the retrieval process and improving the accuracy and relevance of results across a variety of contexts. 

