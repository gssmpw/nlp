\label{sec: intro}
\section{Introduction}

Image retrieval has been a fundamental task in computer vision and database management since the 1970s~\cite{datta2008image}, serving as a cornerstone for various applications, such as face recognition~\cite{fu2021dvg}, fashion retrieval~\cite{yang2020generative}, and person re-identification~\cite{li2019pose}. Traditional image retrieval systems primarily rely on unimodal queries, using either text or images to convey a user's search intent~\cite{chua1994content, qu2021dynamic, qu2020context, rao2022does}. However, users often struggle to clearly express their search intent through a single text query or to find the perfect image that accurately represents it.
To address these limitations and provide greater flexibility, composed image retrieval~(CIR)~\cite{vo2019tirg} emerged in 2019, which allows users to express their search intent by a reference image combined with a textual description specifying the desired modifications. By enabling users to utilize more nuanced search queries, CIR offers significant potential to enhance search experiences across domains, such as e-commerce~\cite{du2023multi} and internet search engines~\cite{jandial2022sac,wu2021fiq,weicom, shf}. 


\begin{figure}[!t]
		\centering
		\includegraphics[scale=0.55]{img/num_paper.pdf}
         
	    \caption{The number of papers trending on the task of composed image retrieval and its related task since 2019.}\label{paper_num}
          % \vspace{-1.0em}
\end{figure}

The concept of CIR, which allows users to utilize a multimodal query to express their search intent, can be easily adapted for various real-world retrieval scenarios. For example, the reference image could be replaced with a reference video to enable composed video retrieval, or single-turn CIR could evolve into dialog-based multi-turn image retrieval. Since its introduction in 2019, CIR has garnered increasing research attention due to its potential value across various domains. As illustrated in Figure~\ref{paper_num}, the number of publications on CIR is increasing rapidly. 
To summarize the past and current achievements in this rapidly developing field, we present a comprehensive overview of work conducted up to November 2024. Existing studies primarily focus on addressing the following key challenges.
1) \textbf{Multimodal Query Fusion.} In CIR, the modification text and reference image play complementary roles in conveying the user's search intent. The modification text typically specifies changes in certain attributes of the reference image. For instance, given the modification requirement, ``I want the dress to be black and more professional'', only the color and style of the dress in the reference image should be changed, while other attributes of the reference image should be kept unchanged. Due to this nature, how to achieve an effective multimodal fusion for accurately comprehending the multimodal query poses the first challenge.
2) \textbf{Target Images Matching.} The semantic gap between the multimodal query and target images presents a significant challenge due to their heterogeneous representations. Additionally, the brevity of modification texts can lead to ambiguity. For example, the text ``I want to change the dress to longer sleeves and yellow in color'' could have multiple interpretations: the sleeves could change from sleeveless to either short or long, and the color could range from light to dark yellow. Such ambiguity suggests that multiple target images could satisfy the given query. Therefore, bridging this semantic gap and managing the one-to-many query-to-target matching relationship is crucial for accurate query-target matching.
3) \textbf{Scale of Training Data}. Training CIR models typically requires triplets in the form of <reference image, modification text, target image>. For each triplet, the reference-target image pair is often generated using a heuristic strategy, while the modification text is usually annotated by humans. Creating such training samples is both costly and labor-intensive, which significantly restricts the size of benchmark datasets. Consequently, addressing the issue of insufficient training data to improve the model's generalization capabilities remains a significant challenge.
%4) \textbf{False Negative Samples}. Mainstream methods directly treat the target images in all the other triplets as negative samples for optimizing the model with the batch-based classification loss. Nevertheless, as aforementioned, the triplet construction strategies in the existing composed image retrieval benchmark datasets inevitably cause false negative samples, since they cannot guarantee that all the target images are annotated for a given multimodal query. Accordingly, how to address the issue of false negative samples remains the last challenge. 


Existing work in this area can be broadly divided into two main categories: supervised learning-based approaches and zero-shot learning-based approaches. The key distinction between these methods lies in the availability of annotated training triplets. Supervised approaches rely on annotated triplets from the dataset to train the model, while zero-shot approaches leverage large-scale, easily accessible data, such as image-text pairs, for pre-training without requiring annotated triplets for optimization.
To facilitate deeper analysis, we establish a fine-grained taxonomy for each category. For supervised CIR approaches, we summarize existing methods based on the four key components of the general framework: feature extraction, image-text fusion, target matching, and data augmentation. For zero-shot composed image retrieval (ZS-CIR) approaches, we classify methods into three groups: textual-inversion-based, pseudo-triplet-based, and training-free.
As previously mentioned, the concept of using a composed multimodal query can be adapted for various scenarios. Beyond the primary task of CIR, several related tasks also involve composed queries, such as reference image plus attribute manipulation, sketch plus modification text, and video plus modification text. Since these tasks are closely related to CIR, we include their recent advancements to provide a comprehensive review of the topic. Based on the type of multimodal query, we categorize these related tasks into five groups: attribute-based, sketch-based, remote sensing-based, dialog-based, and video-based.
\begin{figure}[!t]
		\centering
		\includegraphics[scale=0.45]{img/organization.pdf}
         % \vspace{-1.0em}
	    \caption{Organization of the present survey.}\label{organization}
           
\end{figure}

In summary, our main contributions are as follows:
\begin{itemize}[leftmargin=20pt]
	\item To the best of our knowledge, this paper presents the first comprehensive review of CIR, incorporating over 120 primary studies. It aims to provide a timely and insightful overview to guide future research in this rapidly advancing field.
        \item We systematically organize research findings, technical approaches, benchmarks, and experiments to deepen the understanding of this field. Additionally, we propose an elaborate taxonomy of methods, catering to the diverse needs of readers.
        \item CIR remains an emerging area of research. Based on the surveyed literature, we identify several key research challenges and propose potential future directions, offering forward-looking guidance for researchers in this domain.
\end{itemize}

The remainder of this paper is organized as depicted in Figure~\ref{organization}. Sections~$2$ and $3$ review supervised CIR models and zero-shot CIR models, respectively. Section~$4$ introduces  tasks related to CIR. Section~$5$ describes the currently available datasets, evaluation metrics used, and experimental results from existing approaches. Finally, we discuss possible future research directions in Section~$6$ and conclude the work in Section~$7$. 