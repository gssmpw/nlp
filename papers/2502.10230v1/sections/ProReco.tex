\section{ProReco: A Process Discovery Recommender System}\label{sec:ProReco}
The backend of \texttt{ProReco} is developed in Python, to leverage the capabilities of the PM4py\footnote{\url{https://pm4py.fit.fraunhofer.de/}} package. 
The package provides a comprehensive suite of algorithms and tools for process mining. 
The source code for \texttt{ProReco} can be found on a GitHub repository\footnote{\url{https://github.com/TarekJunied/ProReco}}, which provides detailed instruction for installation. 
% The frontend of \texttt{ProReco} is developed using the React\footnote{\url{https://react.dev/}} framework. 
% Lastly, the Petri net viewer 
In the following, we introduce the structure and the main functions of \texttt{ProReco}. 
Additionally, a demo video of \texttt{ProReco} is available\footnote{\url{https://bit.ly/prorecodemo}}. 
\subsection{Structure}\label{subsec:ProReco-structure}
The overall structure of \texttt{ProReco} is shown in Fig.~\ref{fig:structure}. 
To recommend the most prominent discovery algorithm for event log $L$, \texttt{ProReco} takes a vector of weights $W$ representing the importance of different measures in addition to $L$. 
The weights (within the interval [0,100]) are given by the users and will be used to calculate the final score of the algorithm. 

\begin{figure}[h!]
    \vspace{-1.5em}
    \centering
    \includegraphics[width=0.8\linewidth]{figs/structure.png}
    \caption{
        General structure of \texttt{ProReco}
    } \label{fig:structure}
    \vspace{-1.5em}
\end{figure}

The output of \texttt{ProReco} is a ranking for each discovery algorithm in our portfolio, as well as the corresponding score calculated based on the weighted sum of the quality measures. 
% The higher the score, the better the algorithm is toward the users' preferences. 
The higher the score, the better the algorithm adapts to the users' preferences. 
In the following, we briefly describe the target quality dimensions used in \texttt{ProReco}.  

As we aim to quantify the most common quality measures of a process model, the four primary quality measures~\cite{Aalst16PMbook} (\emph{fitness}, \emph{simplicity}, \emph{precision}, and \emph{generalization}) are used. 
%A model with good fitness allows for behaviors seen in the log.
A model with good fitness represents (and can replay) behavior seen in the log. 
The simplicity dimension refers to the complexity of the model. 
%In the context of process mining, this means the simpler the model the better as long as it can explain the behaviors seen in the log. 
In the context of process mining, this means that a simpler model is advantageous, as long as it can explain the behaviors seen in the log. 
A precise process model does not allow too much unseen behavior, as it is trivial to create a model that allows any behavior (the flower model~\cite{Aalst16PMbook}). 
%Lastly, a generalized model doesn't restrict the behaviors to only the ones in the log. 
Lastly, a model with good generalization can represent behavior unseen in the event log. 
Since the four quality dimensions compete with each other, a single ideal model often does not exist~\cite{Aalst16PMbook}. 
The ideal model highly depends on the use case of the users. 
This motivates the use of weights to incorporate the user preferences w.r.t. the importance of the four quality measures. 

Next, we introduce each component (the feature extractor and the machine learning predictor) in more detail. 

\subsubsection{Feature Extractor}
Based on previous work~\cite{RibeiroCMS14Recommend,TavaresJD22MetaRecommend,Zandkarimi2021Fig4PM}, we extract an initial pool of various features. 
Moreover, the initial pool is filtered considering two criteria. 
First, we remove the computationally expensive features. 
As efficiency is one of the motivations for developing such a recommender system, using features that are expensive to compute does counteract the benefit. 
% Therefore, several graph-based features from~\cite{Zandkarimi2021Fig4PM} are removed. 
Second, we remove redundant features. 
Features are considered redundant if there is already another feature representing the same concept. 
For instance, the feature representing the number of trace variants is implemented as \texttt{n\_unique\_traces} in~\cite{TavaresJD22MetaRecommend} and as “Number of distinct traces” in~\cite{RibeiroCMS14Recommend}. 
These redundancies lead to higher execution time and adversely affect the performance of some machine learning models. 
Thus, we remove such redundancies using the Pearson correlation coefficient. 
Lastly, we add ten Directly-Follows Graph (DFG)- and footprint matrix-based features. 
In the end, 162 features were extracted. 
The introduction to all features is out of scope. 
The corresponding function (called \textit{Featurer}) providing insight for all features is available in \texttt{ProReco} and introduced in Sec.~\ref{subsec:ProReco-functions} in more detail. 

\subsubsection{Machine Learning Predictor}
As shown in Fig.~\ref{fig:ML-predictor}, the machine learning predictor consists of a score predictor for each algorithm in the algorithm portfolio, which consists of Alpha Miner, Alpha-Plus Miner, Heuristics Miner, Inductive Miner (classic, infrequent, direct), ILP Miner, and Split Miner. 
% As our algorithm portfolio consists of eight discovery algorithms (Alpha Miner, Alpha-Plus Miner, Heuristics Miner, Inductive Miner (classic, infrequent, direct), ILP Miner, and Split Miner), there are 32 machine learning predictors in total. 
% Inside the score predictor for each algorithm, there is a predictor for each measure (fitness, precision, generalization, and simplicity). 
% Therefore, we have $8\times 4=32$ measure predictors in the end.

% These predictors receive as input a feature vector representing an event log, along with the measure weights, to generate a score specific to the algorithm. 
% The score is determined by computing a weighted (based on the provided measure weights) sum of the predicted measure values. 


\begin{figure}[h!]
    \vspace{-2em}
    \centering
        \begin{subfigure}[b]{.9\linewidth}
            \includegraphics[width=\linewidth]{figs/ML-predictor.png}
            \caption{
                Machine learning predictor component.
            } \label{fig:ML-predictor}
        \end{subfigure}
        % \hspace{0.5em} % for more space between subfigures
        \begin{subfigure}[b]{.9\linewidth}
            \includegraphics[width=\linewidth]{figs/alpha-predictor.png}
                \caption{
                    Score predictor for a single algorithm (Alpha Miner as an example)
                } \label{fig:alpha-predictor}
        \end{subfigure}
    \caption{Machine learning predictor and its sub-components: score predictors.}
    \label{fig:ML-predictor-component}
    \vspace{-1.5em}
\end{figure}


% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.8\linewidth]{figs/ML-predictor.png}
%     \caption{
%         Machine learning predictor component.
%     } \label{fig:ML-predictor}
%     % \vspace{-2em}
% \end{figure}
The structure for an algorithm score predictor is shown in Fig.~\ref{fig:alpha-predictor} using Alpha Miner as an instance. 
The Score Predictor consists of individual predictors for each of the four measures (fitness, precision, generalization, and simplicity). 
Each measure predictor accepts a feature vector derived from the event log as input and forecasts the value of the corresponding measure for the process model that would have been generated based on the provided event log. 
The measure weights $W$ provided by the user are then used for the final computation of the overall score for a discovery algorithm. 
During this computation, each predicted measure value is multiplied by its corresponding measure weight and subsequently aggregated. 

% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.8\linewidth]{figs/alpha-predictor.png}
%     \caption{
%         Score predictor for a single algorithm (Alpha Miner as an example)
%     } \label{fig:alpha-predictor}
%     \vspace{-1em}
% \end{figure}

The choice of the predictor to predict the measure values for each algorithm is of little importance here, as it is flexible to switch among different predictors whenever suitable. 
In \texttt{ProReco}, we adopt the \texttt{xgboost}~\cite{ChenG16XGBoost} regressor as an instantiation for the predictor. 
To train the predictors, we included 12 real-life event logs from the 4TU repository\footnote{\url{https://data.4tu.nl/}} and 785 synthetic event logs generated by the \texttt{PLG} tool\footnote{\url{https://plg.processmining.it/}}. 
The data is available for download\footnote{\url{http://bit.ly/allEventLogsProReco}}. 
We used 5-fold cross-validation for each experiment with an 80/20 training/test split.

\subsection{ProReco's Functions}\label{subsec:ProReco-functions}
In this section, we introduce the main functions of \texttt{ProReco}. 
% Additionally, a demo video of \texttt{ProReco} is available\footnote{\url{https://bit.ly/prorecodemo}}. 

\vspace{-0.5em}
\subsubsection{Recommendation}
As a recommender system for process discovery, \texttt{ProReco} recommends the most prominent algorithm for the user according to the predicted weighted sum of the four quality measures discussed in Sec.~\ref{subsec:ProReco-structure}. 
The inputs are an event log $L$ and the user preferences w.r.t. measure weights $W$.

To initiate the recommendation, users have to upload an event log (\texttt{.xes} format) as input. 
Then, they are redirected to a page where they have to provide the weights for each of the four quality measures. 
Once the measure weights are submitted, users are redirected to the recommendation page, where a ranking of the algorithm portfolio, the score for each algorithm, and the predicted measure values for each algorithm and measure are available. 
Additionally, \texttt{ProReco} provides users the possibility to mine a process model with the recommended process discovery algorithms. 
The discovered process model is then displayed through an interactive Petri net viewer. 

\vspace{-0.5em}
\subsubsection{Feature Insights}
\texttt{ProReco} offers insights into the features extracted from event logs. 
The \textit{"Featurer"} (shown in Fig.~\ref{fig:feature-insights}) is accessible through the navigation bar. 
\textit{Featurer} provides the user with detailed information about the features. 
By searching for a specific feature name, users can access the following information, as shown in Fig.~\ref{fig:feature-insights}:
\begin{itemize}
    \item Description: a brief description of the feature.
    \item From: the source of the feature.
    \item Used in: the number of regressors that use this feature.
    \item Most important for: the regressor that gains the most advantage from the feature.
    \item Ranking: the importance of the feature among all features.
    \item Feature Score: a metric used to determine the feature’s ranking.
\end{itemize}

\begin{figure}[h!]
    % \vspace{-1.5em}
    \centering
    \includegraphics[width=0.9\linewidth]{figs/feature-insights.png}
    \caption{
        The user interface for the feature insights. 
    } \label{fig:feature-insights}
    % \vspace{-2em}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.9\linewidth]{figs/feature-explanation.png}
    \caption{
        The user interface for explaining an individual recommendation.
    } \label{fig:feature-exaplanation}
    \vspace{-2em}
\end{figure}

\subsubsection{Explainable Recommendation}
As recommendations without explanations can hinder the transparency, trustworthiness, and satisfaction of a recommender system~\cite{ZhangC20XRecommendation}, \texttt{ProReco} incorporates techniques from explainable AI (XAI) to provide explanations for individual predictions made by the regressors. 
Users can access the explanations by clicking on “Explain the Predictions” on the resulting recommendation page. 
Then, users will be redirected to an interactive plot based on SHAP values~\cite{LundbergL17SHAP}. 
The plot begins at the bottom, displaying the expected measure for the selected algorithm. 
As each feature is added, its effect on the prediction is shown. 
A shift to the left indicates a decrease in the measure, while a shift to the right indicates an increase. 
The interactive plot offers insights and explanations for the recommendations.