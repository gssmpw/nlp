\section{Related work}
\label{subsec:related}

This paper's technical contributions bridge the broad literature on prophet inequalities and mechanism design with the smaller but still substantial literature on Pandora's Box.
Conceptually, it is related to work on bandit superprocesses.

\subsubsection{Superprocesses and index theorems.}
A superprocess~\cite{nash1973optimal} or \emph{alternative decision process} consists of a set of Markov Decision Processes (MDPs).
The problem is to sequentially select an MDP and take an action in it, receiving a cost or reward, and repeat.
An MDP whose decision set is only ``advance'' or ``pause'' is called a \emph{bandit}, and the special case where all MDPs are bandits is the Multi-Armed Bandit setting of e.g. Gittins.
Unlike with most works involving MDPs, our Markov Search Processes only allow for search costs (not rewards), we do not have any time-discounting, and we require processes to halt in order to eventually claim a reward.
Moreover, we consider combinatorial constraints on which rewards can be claimed.

Nevertheless, our work is closely related conceptually to work on superprocesses, which generally focuses on sufficient conditions for index theorems (efficient local rules that enable globally optimal algorithms).
The most famous is the Gittins index~\citep[e.g.]{gittins1979bandit}, but many others along this line have been proposed and studied, some allowing for limited decisionmaking or other relaxations of the bandit setting~\citep{glazebrook1976profitability,whittle1980multi,nash1980generalized,glazebrook1982sufficient,granot1991optimal,glazebrook1993indices,dumitriu2003playing,keller2003branching}.
Applications in AI and reinforcement learning include \citep{brown2013optimal,hadfield-menell2015multi}.
Our main question is relevant to this literature: we ask, in a somewhat different setting, how to construct robust and approximate local strategies when index theorems are unavailable.

\subsubsection{Prophet inequalities}
There is a substantial existing literature on prophet inequalities.
\citet{krengel1978semiamarts} first proposed prophet inequalities, and \citet{samuelcahn1984comparison} first proposed a thresholding algorithm.
Various extensions allowing for the selection of multiple items, particularly under matroid constraints, have been studied by  \citet{chawla2010multi}, \citet{yan2011mechanism}, \citet{kleinberg2012matroid}, \citet{feldman2016online}, \citet{dutting2020prophet}, and \citet{chawla2024non}.
\citet{lee2018optimal} used ex ante relaxations to analyze prophet inequalities with matroid selection constraints, a technique we employ heavily.
Other extensions of prophet inequalities have also been analyzed.
\citet{rubinstein2017combinatorial} studies combinatorial valuations of the items, \citet{ezra2023prophet} studies a different objective (expected ratio rather than ratio of expectations), and \citet{immorlica2020prophet} studies correlated values.

Prophet inequalities have natural applications to incentive-compatible mechanism design, in particular posted price auctions (\citet{chawla2010multi} and subsequent literature; see \citet{lucier2017economic}).
\citet{alaei2022descending} and \citet{kleinberg2016descending} study connections to descending price auctions.
Many of the aforementioned papers discuss these economic connections, and \citet{lucier2017economic} provides a survey.

\subsubsection{Pandora's box}
The Pandora's Box problem -- and its polynomial-time, optimal solution -- were posed by \citet{weitzman1979optimal}.
For a full survey of Pandora's Box problems and recent developments, we refer to \citet{beyhaghi2024recent}.
Various models of multistage Pandora's Box, and similar settings, have been studied in \citet{guha2007information}, \citet{aouad2020pandora}, \citet{gupta2019markovian}, \citet{ke2019optimal}, and \citet{bowers2024matching}.
Another well-studied variation on Pandora's Box which figures in our work is ``non-obligatory inspection,'' first posed by \citet{doval2018whether}. \citet{beyhaghi2019pandora} provides a $1-\frac{1}{e}$-approximation for the problem
using techniques from \citet{asadpour2016maximizing}.
These techniques can be extended to our ``cabinets'' setting, as discussed in Appendix \ref{app:complexity}.
\citet{fu2023pandora} established that non-obligatory Pandora's Box is an NP-hard problem, unlike the original and multistage versions of the problem and, along with \citet{beyhaghi2023pandora} independently, provide a PTAS.
Other extensions have been studied such as combinatorial selection constraints in \citet{singla2018price}, order constraints in \citet{boodaghians2020pandora}, correlations between boxes in \citet{chawla2020pandoras}, and applications to matching and mechanism design in \citet{immorlica2020information},  \citet{bowers2023high}, and \citet{bowers2024matching}.

Among all papers, perhaps closest to our model is \citet{gupta2019markovian}, who studied what we call the \emph{bandits} special case of our problem in an offline setting, showing, among other results, that ``frugal'' algorithms for combinatorial optimization extend with the same approximation guarantees.
We focus on a significantly more general Markov Search Process model that allows at each time for a choice between multiple possible decisions with different costs and transition functions.
We do not know of works in this literature that have considered more adaptive decisionmaking processes such as our cabinets and DAGs models.