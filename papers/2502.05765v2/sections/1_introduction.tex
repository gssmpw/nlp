Empirical scaling laws have established clear relationships between model performance and three key factors: compute, data, and model size~\cite{Hestness2017DeepLS, Kaplan2020ScalingLF}. These relationships have driven remarkable improvements across computer vision, language processing, speech recognition, reinforcement learning, and healthcare applications~\cite{sun2017revisiting,mahajan2018exploring,brown2020language,hoffmann2022training,park2019specaugment,zhang2020pushing,ashvin2020accelerating,reed2022generalist,sheller2020federated,mckinney2020international}. Beyond simple scaling, the diversity of training data has proven crucial for enhancing model robustness to distribution shifts and mitigating performance disparities across demographic groups~\cite{shen2024data,miller2021accuracy}.

However, access to data varies significantly across entities and domains. While large tech companies have the data and compute resources to train the foundational models that now dominate general tasks, smaller players often lack such access.  Domain-specific data is also becoming increasingly valuable for fine-tuning these general models~\cite{alsentzer2019publicly,gururangan2020don,lee2020biobert}, creating a competitive advantage for the data owners. As a result, entities with domain-specific data are more reluctant to share it for free, opting instead to sell it in emerging data markets~\cite{acemoglu2022too,huang2021toward,liang2018survey}. This dynamic particularly disadvantages smaller organizations, which often lack both the resources to purchase data and the leverage to negotiate favorable sharing agreements.

Scaling datasets in regulated domains is particularly challenging due to legal constraints and unpredictable outcomes from altering the training data composition. In healthcare, for example, patient data is heavily regulated by laws such as the Health Insurance Portability and Accountability Act (HIPAA), which imposes strict data-sharing constraints to protect patient privacy. Moreover, accumulating data from multiple sources introduces the risk of domain shift, where data from different distributions may degrade model performance instead of improving it~\cite{koh2021wilds,wang2022generalizing,taori2020measuring}. Contrary to the intuition that more data always leads to better performance, combining datasets does not guarantee improvements --- in fact, performance can decrease when incorporating additional data sources~\cite{bradley2021unrepresentative,meng2018statistical,shen2024data}. This non-monotonic behavior means that carefully selecting which datasets to combine is crucial, as using all available data may actually perform worse than using an optimal subset.

While existing methods aim to identify datasets combinations that can improve performance, they often assume access to all relevant datasets~\cite{shen2024data,ilyas2022datamodels}. However, this is impractical because entities are reluctant to share their data due to privacy risks or the competitive value they associate with it. This reluctance to share creates a bottleneck in improving model performance. In high-stakes settings like healthcare, this bottleneck is particularly detrimental, as access to diverse data has the potential to drive significant advancements in patient care and outcomes~\cite{beam2018big,ghassemi2019practical,chen2020treating,beaulieu2019trends}. 

To address these challenges, we propose SecureKL, a privacy-preserving approach for guiding dataset combinations without requiring direct data or model sharing. Our work makes three primary technical contributions:

\begin{enumerate}
\item We introduce a framework for practical secure data combination that enables organizations to evaluate potential partnerships while maintaining data privacy. Our framework categorizes existing approaches by their privacy leakage risks and provides a systematic way to assess the trade-offs between data utility and privacy preservation.
\item We extend KL-XY score~\cite{shen2024data} with a secure multiparty protocol that enables privacy-preserving evaluation of potential data partnerships. Our protocol maintains strong privacy guarantees while utilizing the complete underlying datasets, achieving $>90\%$ correlation with plaintext computations.
\item  Through extensive evaluation in low-data, high-stakes settings, we demonstrate that our method successfully identifies beneficial data partnerships for intensive care unit (ICU) mortality prediction, improving classifier performance for the source hospital.

\item In experimental scenarios requiring selection of three partner hospitals, Private-KL-XY outperforms alternative selection strategies including demographic-based selection (using gender, race, and age), and limited-sample plaintext selection.
\end{enumerate}

We argue that our method presents an appealing trade-off of privacy and utility by preserving privacy for both parties while using all the underlying data.
