\subsection{Experimental Setup}
We validate our method and demonstrate its applicability using the eICU Collaborative Research Dataset~\cite{Pollard2018TheEC}, which contains over $200,000$ admissions from $208$ hospitals across the United States. Following the data cleaning and exclusion criteria outlined by \cite{Water2023YetAI} and \cite{shen2024data}, we selected the $12$ hospitals with the highest number of patient visits (each with at least $2000$ patients) as our $\mathbf{H}$. Each strategy would compute with the same $K=3000$ records, as the total available data per hospital.

We simulate the problem setup for each hospital with the $24$-hour mortality prediction task.
The strategy comparisons described in Section \ref{sec:methods} are implemented using $1500$ samples and the AUC is evaluated on $400$ samples for all of our experiments unless otherwise noted. This follows training and evaluation protocols in Yet Another ICU Benchmark \cite{Water2023YetAI}. For the data combination experiments that compute AUC change $\delta_i$ or $\delta_T$, to match ~\priorp, we take $1500$ random samples from each selected dataset and combine it with $1500$ samples from $\Do$ (fixed across all experiments).

Implementing $\mathrm{Secure}\KLXY$ to be privacy-preserving requires training logistic regression model in private. This is used in the private setting to estimate $g_\mathrm{SKL}$ -- $\mathrm{Score}([X])$ or $\mathrm{Score}([X,Y])$ -- for each pair of hospitals.
Our experiments train encrypted logistic regression in CrypTen~\cite{knott2021crypten} using the library's SGD optimizer. To ensure a fair comparison between the scores obtained through plaintext and encrypted settings, we re-implement plaintext Score($X$) and Score($X,Y$) using logistic regression with SGD in PyTorch~\cite{paszke2019pytorch}. This is because encrypted version of L-BFGS --  the optimizer prior work \priorp uses in plaintext-only with Scikit-Learn~\cite{scikit-learn}-- is not available in CrypTen, though it leads to better downstream performance. Hyper-parameter tuning for SGD in private and plain text are performed independently, with the details in Appendix \ref{app:exp_details}.

%We find that even with hyperparameter tuning SGD, we are not able to have a better perforamnce as better optimzers like LBFGS. 
% To simulate hospital acquiring additional data  we take measure the AUC change between the 6000 examples using the Top3 hospitals using X strategy and the anchor hospital and 1500 from the anchor hospital. We then take the average AUC change across all the hospitals. 

\subsection{Experimental Questions}
We ask three sets of questions:
\begin{enumerate}
\item \textbf{Consistency:} Does using multiparty implementation sacrifice original measure's effectiveness?  
Practically, we evaluate this through the analysis of private and plaintext scores. For our selected metrics, we expect AUC change to be negatively with KL-based measures---meaning the closer the additional target dataset is to the source hospital, the more the AUC will improve compared to other potential target datasets.
Section~\ref{sec:consistency} tests the correlation of our private scores and plaintext scores with full access (setting $k=K$). In addition to computing Spearman's rank correlation coefficient of the KL-scores, we probe the discrepancy of the downstream effect between  $\{\delta_i|i=\pi_s(n=1, k=K)\}$ using plaintext $\KLX, \KLXY$ with all the underlying data and $\{\delta_i|\pi=\pi_p\}$ using $\mathrm{Secure}\KLX, \mathrm{Secure}\KLXY$ for each source hospital $H_o\in \mathbf{H}$.
\item \textbf{Positivity:}
Does our method pick hospitals that reliably improve performance? If source dataset $D_o$ can only add data from $n$ more hospitals, does our measure lead to eventual AUC improvements?
In Section~\ref{sec:positivity}, we test our framework on a multi-dataset combination experiment and find that it successful improves the source hospital's downstream outcome. Specifically, when selecting a single additional data source ($n=1$), all but 2 hospitals improves, and when selecting top 2 or 3, all hospitals see a positive AUC change. This shows a consistent added benefit.

Lastly, Section~\ref{sec:strategies_discuss} compare with different strategies proposed in Section~\ref{sec:methods}, and Section~\ref{sec:skl_discuss} analyze the benefits of using private dataset combination $\mathrm{SKL}$.
%but not strongly preferred over $\pi_d$, because some demographic information -- though potentially sensitive e.g. gender -- can give good insight.
% When $n=3$, $\mathbb{E}[\delta_{T}(T={\pi_p(n=3)}]>0$. Interestingly, $\pi_s(n=3, k=30)$ using a few samples do well in eICU for some hospitals, which can be an alternative.
%Does our method pick hospitals that reliably improve performance? If $D_o$ can only add data from $n$ more hospitals, does our measure lead to eventual AUC improvements?
%In Section~\ref{sec:positivity}, we show that when $n=3$, $\mathbb{E}[\delta_i]>0$ for $i\in [1, N]$, but not strongly preferred over $\pi_d$, because some demographic information -- though potentially sensitive e.g. gender -- can give good insight.%When $n=3$, $\mathbb{E}[\delta_{T}(T={\pi_p(n=3)}]>0$. Interestingly, $\pi_s(n=3, k=30)$ using a few samples do well in eICU for some hospitals, which can be an alternative.$
\item \textbf{Error analysis:} If our privacy-preserving method is not the dominant strategy against alternatives including limited data accessibility, why is that? Section~\ref{sec:limits} performs additional analyses on (a) hospitals with low $\mathrm{Secure}\KLXY$ and $\KLXY$ correlations, and (b) hospitals lagging AUC improvements using the random strategy $\pi_0$ or limited-sample strategy $\pi_s$ for selecting $n=3$ candidate hospitals.
\end{enumerate}

Lastly, we note engineering hurdles to scale to the real-world in Section~\ref{sec:eng-limits}. We hereby detail our results.

\subsection{Consistency Between Plaintext and Encrypted Computations}
\label{sec:consistency}
Our encrypted computations are programmed with CrypTen, when the plaintext counterpart is PyTorch-only. We show using $\mathrm{Secure}\KLXY$ and $\mathrm{Secure}\KLX$ lead to highly comparable behavior as $\KLXY$ and $\KLX$, respectively.

\paragraph{Spearman's Rank Correlation Coefficient for Underlying Scores}
For each source hospital $H_o$, use all full samples for $\Di$. Between $\KLXY$ and $\mathrm{Secure}\KLXY$ on $\Do$ and $\Di$ for all remaining hospitals $H_i$, $\mathbb{E}_{H_o\sim \mathbf{H}}[\rho] = 0.908$ with a range of $[0.691,1.0]$, obtaining $p < 0.02$ across all hospitals.
Between $\mathrm{Secure}\KLX$ and $\KLX$, $\mathbb{E}_{H_o\sim \mathbf{H}}[\rho]=0.9303$ with a range of $[0.455,0.991]$, with 11 of 12 hospitals achieving p-values below $0.05$. After applying Hochberg false discovery rate correction \cite{Benjamini1995ControllingTF}, our p-values remain significant. This range is an artifact of sweeping hyperparameters independently in plaintext and encrypted optimisations. When we unify the SGD hyperparameters, we indeed get a tighter range. For all 12 hospitals, see appended Appendix~\ref{app:score_corr} for details.

\paragraph{Downstream Model Improvements}
%In addition to consistency between $\mathrm{Secure}\KLXY$ and $\KLXY$, we care to show that scores have a correlation with $\delta_i$. 
 % shows the effects of adding a hospital's data to a source hospital for different strategies by measuring the correlaion between AUC chance and scores
We further simulate the effect by \emph{adding} encryption through its impact on the downstream AUC. This examines whether there will be a shift in the full hospital ranking, if we switch from a plaintext setup to encrypted. For $H_o\sim\mathbf{H}$, we measure $\delta_i$ that results from adding $\Di$ to $\Do$ for all $i$. This correlates all target hospitals $\{H_i\}$ with their ground truths $\{\delta_i\}$ in the case of picking a single target hospital. 
We find the linear coefficient for encrypted $\mathrm{Secure}\KLXY$ to be $-0.182$ and plaintext $\KLXY$ to be $-0.184$ ($99\%$ matching). Both $\mathrm{Secure}\KLX$ and $\KLX$ have a linear coefficient of $-0.164$ with $\delta_i$.
For all strategies' correlations with ground truth at $n=1$, see Appendix~\ref{app:k_corr}. %When using a subset of the dataset of size $k \in \{3,30,300,3000 \}$ to estimate $\KLXY$. We find that $\KLXY$ is negatively correlated with AUC change only when using the entire plaintext dataset. 
%We find the Pearson correlation between $\mathrm{Secure}\KLXY$ and $\delta_i$ to be  $3.47e-02$, whereas $r$ for $\KLXY$ and $\delta_i$ is  $3.65e-02$. We also measure the correlation between $\delta_i$ and other scores, and we find that other scores have not significant correlation. This means that lower $\mathrm{Secure}\KLXY$ and $\KLXY$ are strongly correlated with an increase in AUC in $\Do$. Table \ref{app:auc_corr} shows the $r$ and p-values for all other scores.

%While $\KLXY$ might be a useful metric, access to the full dataset is not always feasible as described in \autoref{sec:intro}. \autoref{app:k_corr} report the Pearson correlation between 

%In Table~\ref{tab: encrypted_scores}, we show the effects of adding a hospital's data to a source hospital for different strategies by measuring the correlaion between AUC chance and scores.

% Using the full data, encrypted and plaintext are strongly correlated. We demonstrate first that the KL-based score itself is consistent between plaintext and encrypted computation. Then we show that plaintext and encrypted \emph{scores} give same hospital rankings and state rankings in eICU respectively.
% \textcolor{red}{details the setup, how many are compared, what are the numbers}.
% First, each hospital trains their own model and obtains AUC. Then the scores are computed with encrypted and plaintext methods. Finally, each of the target hospitals' data is folded into the source hospital, from which the ground truth $\delta_i$ is computed. The encrypted scores given to the hospitals are indeed correlated with AUC change that is given by the plaintext scores. 


% \textcolor{red}{Keren Explain experiment setup and various baseline strategies, maybe at the top of the section. List the figures, use consistent notation}
% \begin{figure}
%\begin{minipage}[t]{0.48\textwidth}
% \begin{figure}[t]
%   \centering
%   \includegraphics[width=0.85\linewidth]{figures/vp_demo.pdf}
%   \caption{Top: AUC change comparison across $\mathrm{Secure}\KLXY$, demographic (left) and subset-based $\KLXY$ strategies (right) averaged across all hospitals. Each plot show the median, the interquartile range (IQR), and the min and max within the IQR. }
%   \Description{ Comparing SecureKL with random and demographic-based strategies.}
%   \label{fig:demographic_strat}
% \end{figure}
\begin{figure}[t]
    \begin{minipage}{0.42\textwidth}
        \subcaption{\label{left}  }
        \label{fig:demo_strats}
    \end{minipage}
    \begin{minipage}{0.42\textwidth}
        \subcaption{\label{right} }
     \label{fig:p_strats}
    \end{minipage}
  \centering
  \includegraphics[width=0.85\linewidth, trim={0 0 {.5} 0}, clip]{figures/bp_demo.pdf}
  % \includegraphics[width=\textwidth, trim={left lower right upper}, clip]{your_image.pdf}
  \caption{AUC change $\delta_T$, after including top-$3$ hospital per strategy, over all source hospitals. Our private strategy $\pi_p$ is compared with (a) demographic-based $\pi_d$ for gender, age, and race. (b) plain text limited-sample $\pi_s(k=K)$ for $k=300$ (10\%) and $k=30$ (1\%).}%$k\in\{300, 30\}$, corresponding to using 10\% and 1\% of available data. }
\end{figure}
% \begin{minipage}[t]{0.48\textwidth}
%   \centering
%   \includegraphics[width=0.85\linewidth]{figures/sample_strat.pdf}
%   \caption{Sampling strategies}
%   \Description{\color{red}{NEED UPDATING} more samples are better. encrypted-kl uses all samples.}
%   \label{fig:sample_strat}
% \end{minipage}



% \begin{figure}
% \begin{minipage}[t]{0.48\textwidth}
%   \centering
%   \includegraphics[width=0.85\linewidth]{figures/folktable_strat.pdf}
%   \caption{Comparing Encrypted-KL with random and demographic-based strategies}
%   \Description{\color{red}{NEED UPDATING} some conclusion and description}
%   \label{fig:folktable_demographic_strat}
% \end{minipage}
% \hfill
% \begin{minipage}[t]{0.48\textwidth}
%   \centering
%   \includegraphics[width=0.85\linewidth]{figures/forktable_sample_strat.pdf}
%   \caption{Sampling strategies}
%   \Description{\color{red}{NEED UPDATING} More data is better.}
%   \label{fig:folktable_sample_strat}
% \end{minipage}
% \end{figure}

\subsection{Positivity of SecureKL and Practical Implications}
\label{sec:positivity}
\label{sec:exp_kl}
\paragraph{Overall Positivity} We evaluate the practical utility of SecureKL by applying it in a multi-source data combination experiment, where $n\in \{1,2,3\}$. For $n=1$, we find that $\pi_p$ improves AUC in 10 out of the 12 hospitals. When $n=2$ and $n=3$, we find that using $\pi_p$ consistently improves AUC for all hospitals. Overall, 34 out of the 36 dataset combinations we evaluate on have an AUC improvement $\delta_T > 0$, suggesting that $\pi_p$ is a reasonable strategy for selecting hospital dataset combinations with a high expected return $\mathbb{E}[P_{H_o\sim \mathbf{H}}(\delta_T > 0)]$ for the source hospital from using our strategy. 

\subsubsection{Comparing With Alternative Strategies}
\label{sec:strategies_discuss}
Other strategies -- $\pi_0$, $\pi_d$, and $\pi_s$ -- can also arrive at positive datasets. Comparing private method $\pi_p(n=3)$ to other strategies at $n=3$, we find the following results, illustrated in Figure \ref{fig:p_strats}:
\begin{enumerate}
% a mean $\delta_T$ of $0.024$,, and a positive Bowley’s skewness of $0.085$.
\item $\pi_p$ (our method based on $\mathrm{Secure}\KLXY$) has a median $\delta_T$ of $0.020$, and a standard deviation of $0.015$. Our results indicate that for $50$\% of the hospitals, $\pi_p$ gives a $\delta_T >= .02$. Compared to other strategies, $\pi_p$ has the highest median, the lowest standard deviation, and it is one of two strategies that improves performance for all hospitals. 

\item Demographic-based strategies underperform compared to $\pi_p$ on average. However, we observe that $\pi_d$-gender can be highly effective for a subset of hospitals, as it achieves the highest 75th percentile (Q3) of $0.033$ among all strategies. This indicates that for 25\% of hospitals, $\delta_T \geq 0.033$. Despite this, $\pi_d$-gender has a lower median value of $0.012$ compared to $\pi_p$, exhibits a high standard deviation ($0.022$), and degrades the performance for certain hospitals. Similarly, $\pi_d$-age has a median of $0.014$, and $\pi_d$-race has a median of $0.008$, both lower than $\pi_p$'s median.
% positive Bowley’s skewness of $0.583$.
% While $\pi_d$-gender a positive Bowley’s skewness of $0.583$.
% \item $\pi_d$-gender a median of $0.012$, and a Our results indicate that gender can be a great strategy for a subset of hospitals, as it has the highest maximum $\delta_T$ among all strategies and a positive skewness. 
% However, it performs worse than $\pi_p$ on average, it has a high standard deviation ($0.022$), and it can degrade the performance of some hospitals.
%has a maximum $\delta_T$ of $0.068$, the trade-off lacks robustness, as this strategy has higher variability and degrades AUC a subset of hospitals. 

% \item $\pi_d$-age has a minimum $\delta_T$ of $-0.026$ and a median $\delta_T$ of $0.014$. Compared to other strategies, $\pi_d$-age has the lowest minimum value. 
% \item $\pi_d$-race has a median value of $0.008$. Our results indicate that for $50$\% of the hospitals, $\pi_d$ provides minimal improvements ($\delta_T < .008$).
\item Plaintext small-sample strategies, $\pi_s$, outperform all demographic-based methods but slightly underperform relative to $\pi_p$. For instance, $\pi_s(k=300)$ has a median $\delta_T$ of $0.0178$, and although it achieves $\delta_T > 0$ across all hospitals, it performs worse on average compared to $\pi_p$ and exhibits a higher standard deviation ($0.017$).
$\pi_s(k=30)$ has a median $\delta_T$ of $0.0165$. Compared to other strategies, it has the largest standard deviation ($0.024$), and it degrades the performance for some hospitals.
%$\pi_s(k=30)$ has a median $\delta_T$ of $0.0165$.  

% \item $\pi_s(k=300)$ has a median $\delta_T$ of $0.0178$ and a standard deviation of $0.017$. Compared to $\pi_p$, this strategy also results in $\delta_T > 0$ for all hospitals, but it performs worse on average and it has a higher standard deviation. 
% \item $\pi_s(k=30)$ has a median $\delta_T$ of $0.0165$, and a standard deviation of $0.024$. Compared to other strategies, it has the largest standard deviation, and it degrades the performance of a subset of hospitals.
\end{enumerate}

In summary, our method $\pi_p$ achieves the highest AUC improvement on average with the lowest standard deviation, demonstrating consistent improvement for all hospitals. In contrast, demographic-based and plaintext small-sample strategies exhibit greater variability, with some strategies improving performance for specific subsets of hospitals but underperforming or degrading results in others.
 % We visualize the impact of different strategies in Figure \ref{fig:demographic_strat} by measuring $\delta_i$. A positive $\delta$ means that a strategy $\pi$ improved the original performance of the model, while a negative $\delta_i$ means the AUC degraded after increasing the initial data fourfold. 
 
 %We find that $\pi_p$ has a higher median and minimum $\delta$ than $\pi_d$, suggesting that $\pi_p$ not only performs better on average but also provides better worst-case performance, making it a more reliable strategy across hospitals. The gender-based $\pi_d$ strategy has a higher maximum $\delta$ for a subset of hospitals, indicating that it can result in substantial performance gains in certain cases. However, the trade-off is its lack of robustness, as it significantly degrades performance for other hospitals. Similarly, age-based and race-based strategies degrade AUC for a subset of the hospitals. While the $\pi_s(k=300)$ strategy performs similarly to $\pi_p$ on average, $\pi_p$ skews positively, indicating it tends to improve performance across most hospitals. In contrast, $\pi_s(k=30)$ skews negatively, suggesting it often results in worse performance, even below the original baseline, making it a less reliable strategy.
%While $\pi_s$ strategies have a similar AUC change as $\pi_p$ on average, $\pi_p$ skews positively and  $\pi_s(k=30)$ and $\pi_s(k=300)$ skews negatively, with $\pi_s(k=30)$ skew below the original baseline. 
\subsubsection{SecureKL Analysis}
\label{sec:skl_discuss}
After establishing that $\pi_p$ with $\mathrm{Secure}\KLXY$is a robust strategy in practical downstream performance, we hereby synopsize the benefits of $\mathrm{SecureKL}$ and elaborate on their practical implications.

\textbf{A Principled Approach To Data Minimization.}
Our major contribution is to match plaintext performance with no data sharing. Using MPC provides \emph{input privacy}, meaning that if both hospitals only want to know the resulting score, the computation can be done without leaking original data. This strong guarantee can significantly ease the tension related to privacy and compliance in setting up a collaboration, leading to a practical "data appraisal stage" in data-limited high stakes domains. 

In the case where that output can be sensitive, i.e., when hospitals query each other multiple times and accrue information through the score function, the \emph{output} can also be made privacy-preserving through differentially private data releases, such as using randomized response~\cite{dwork2014algorithmic}.

In theory, any data combination method (if Turing-complete) can be made private; yet, in practice, balancing the right trade-off of utility and privacy is non-trivial.
Barring engineering difficulties, not all algorithms readily adapt efficiently in private. Prior work ~\cite{xu2022data} included the trained model and test data in private; while relatively exact, complex methods would exacerbate the same operational limitations discussed in Section~\ref{sec:eng-limits}.

\textbf{Gain from Data Availability.}
In contrast to limited-sample approaches, a key advantage for our method $\pi_p$ is that it takes advantage of all of the underlying data -- generally impossible with non-secure methods for private data in heavily regulated domains. The general intuition is that data is localized; therefore, once a good target hospital is identified, we should acquire all of the data. It may be tempting to assert that we prefer the highest $k$ for data addition algorithms as well. In our experiments, while this is generally true, the smaller $k$ sometimes outperform larger $k$ in plaintext strategy $\pi_s$, which we investigate in Section~\ref{sec:limits} and in Figure~\ref{fig:hos_auc}. This occasionally non-monotonic behavior mirrors the challenge of data combination itself: even within one source dataset for the same estimator, more data is not necessarily better. This suggests a domain-specific alternative to sharing a large amount of data for some source hospital, and points to future directions to using secure computation on a minimal-sized sample dataset for minimal performance overhead while remaining private.
\subsection{Error Analysis}
\label{sec:limits}
\subsubsection{Underlying Score Limitations}
Data addition algorithms underpin the effectiveness of our method.
Even if $\Do$ obtains access to all the plaintext data, there is no guarantee that $\pi_p$ can correctly predict whether the data is useful. As seen in Figure~\ref{fig:corr_poor}, Hospital 243's utility when acquiring another data set is badly correlated with plaintext and encrypted KL-XY scores. This leads to its bad strategy for acquiring the top 3 hospitals, as seen in the middle pane of Figure~\ref{fig:hos_auc}. Interestingly, for this hospital, no other informational strategy excels, either, so choosing a random 3 may be preferred.

This behavior stems from the underlying measure, not from adding secure computation: in Figure~\ref{fig:corr_good} and Figure~\ref{fig:hos_auc}, the encrypted performance closely follows that of plaintext performance, for both good and bad downstream correlations.

\subsubsection{Sometimes, Not All Underlying Data Is Needed}
Relatedly, when seeing a few samples can successfully identify useful candidate hospitals, $\pi_p$ does not always outperform $\pi_s$ on small samples.

In the right panel of Figure~\ref{fig:hos_auc}, hospital 199, the smaller sample sizes achieve a score that better reflects ground truth as a data addition strategy. In that case, the hospital may not need the full sample to know which target hospitals to collaborate with. 

This behavior is specific to the interaction of the data and the underlying score, and does not affect the general insight that adding private computation preserves privacy (and eases privacy-related risks that hinder data sharing). We further note that our method still clearly applies to encrypted computation on a smaller data set under data minimization.


%% Changing to hospital 243, as results for 264 changed. 
\begin{figure}[h]
\begin{minipage}[t]{0.48\textwidth}
  \centering
  \includegraphics[width=0.85\linewidth]{figures/243_corr.pdf}
  \caption{Hospital 243: Underlying KL-score performs poorly}
  % \Description{\textcolor{red}{NEED UPDATING} some conclusion and description}
  \label{fig:corr_poor}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
  \centering
  \includegraphics[width=0.85\linewidth]{figures/420_corr.pdf}
  \caption{Hospital 420: Underlying KL-score performs well}
  % \Description{\textcolor{red}{NEED UPDATING} }
  \label{fig:corr_good}
\end{minipage}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/ind_hospital_demo.pdf}
  \caption{Left: $\mathrm{Secure}\KLXY$ outperforms $\pi_p(k=30)$ and $\pi_0$. Middle: All strategies perform similarly. Right: $\pi_p(k=300)$ outperforms $\mathrm{Secure}\KLXY$. In all panels, the bars represent the standard deviation.}
  % \Description{\color{red}{NEED UPDATING} }
  \label{fig:hos_auc}
\end{figure}
% \begin{minipage}[t]{0.33\textwidth}
%   \centering
%   \includegraphics[width=0.95\linewidth]{figures/hos_443.pdf}
%   \caption{Hospital 443: Encrypted KL-metric performs well}
%   \Description{\textcolor{red}{NEED UPDATING}}
%   \label{fig:ekl_good}
% \end{minipage}
% \begin{minipage}[t]{0.33\textwidth}
%   \centering
%   \includegraphics[width=0.95\linewidth]{figures/hos_443.pdf}
%   \caption{Hospital 443: Encrypted KL-metric performs well}
%   \Description{\textcolor{red}{NEED UPDATING}}
%   \label{fig:ekl_good}
% \end{minipage}
% \hfill
% \begin{minipage}[t]{0.33\textwidth}
%   \centering
%   \includegraphics[width=0.95\linewidth]{figures/hos_199.pdf}
%   \caption{Hospital 199: Small samples perform better.}
%   \Description{\textcolor{red}{NEED UPDATING} }
%   \label{fig:sample_good}
% \end{minipage}
% \begin{minipage}[t]{0.33\textwidth}
%   \centering
%   \includegraphics[width=0.95\linewidth]{figures/hos_264.pdf}
%   \caption{Hospital 264: Random strategy is better.}
%   \Description{\textcolor{red}{NEED UPDATING} erratic}
%   \label{fig:random_good}
% \end{minipage}

\subsubsection{Encrypted Computation Limitations}
\label{sec:eng-limits}
Engineering a secure system for machine learning requires both machine learning and software engineering knowledge. We share our our code and method, but also note potential challenges with deploying our secure computation:
\begin{enumerate}
    \item \textbf{Operational}: engineering personnel limitations. While our implementation requires little cryptographic knowledge to deploy, it still needs technically-trained staff at each participating hospital to collaborate and maintain.
    \item \textbf{Engineering}: Extending any MPC protocol is non-trivial, as security engineering is a specialized skill. While $\mathrm{SecureKL}$ applies broadly to other underlying scores in multi-party setups, every new algorithm requires software engineering - prototyping, tuning, debugging ---which can be especially costly for hospitals.
    \item \textbf{Framework Limitation}: While CrypTen is designed to accommodate PyTorch, it is a research tool where not all plain text functionalities are implemented. Writing optimizers -- such as L-BFGS --  and custom operators that are not readily available requires both machine learning and cryptography knowledge. %This prevented us from matching the exact implementation of \priorp.
    \item \textbf{Inherent to Secure Computation}: When the method requires significant hyper-parameter tuning, such as using SGD on small batch data with learning rate schedules, plaintext tuning may not transfer perfectly. As detailed in Appendix ~\ref{app:exp_details}, our hyperparameters for SGD are indeed different in encrypted and plaintext settings. However, encrypted computation \emph{hides} loss curves and training details by default, complicating development.
\end{enumerate}
