@article{ahn2023transformers,
  title={Transformers learn to implement preconditioned gradient descent for in-context learning},
  author={Ahn, Kwangjun and Cheng, Xiang and Daneshmand, Hadi and Sra, Suvrit},
  journal={Conference on Neural Information Processing Systems},
  volume={36},
  pages={45614--45650},
  year={2023}
}

@inproceedings{anil2024many,
  title={Many-shot jailbreaking},
  author={Anil, Cem and Durmus, Esin and Rimsky, Nina and Sharma, Mrinank and Benton, Joe and Kundu, Sandipan and Batson, Joshua and Tong, Meg and Mu, Jesse and Ford, Daniel J and others},
  booktitle={Conference on Neural Information Processing Systems},
  year={2024}
}

@article{anwar2024adversarial,
  title={Adversarial Robustness of In-Context Learning in Transformers for Linear Regression},
  author={Anwar, Usman and Von Oswald, Johannes and Kirsch, Louis and Krueger, David and Frei, Spencer},
  journal={arXiv preprint arXiv:2411.05189},
  year={2024}
}

@article{casper2024defending,
  title={Defending Against Unforeseen Failure Modes with Latent Adversarial Training},
  author={Casper, Stephen and Schulze, Lennart and Patel, Oam and Hadfield-Menell, Dylan},
  journal={arXiv preprint arXiv:2403.05030},
  year={2024}
}

@article{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023}
}

@article{chen2024aligning,
  title={Aligning {LLMs} to Be Robust Against Prompt Injection},
  author={Chen, Sizhe and Zharmagambetov, Arman and Mahloujifar, Saeed and Chaudhuri, Kamalika and Guo, Chuan},
  journal={arXiv preprint arXiv:2410.05451},
  year={2024}
}

@article{chen2024transformers,
  title={How transformers utilize multi-head attention in in-context learning? {A} case study on sparse linear regression},
  author={Chen, Xingwu and Zhao, Lei and Zou, Difan},
  journal={arXiv preprint arXiv:2408.04532},
  year={2024}
}

@article{frei2024trained,
  title={Trained transformer classifiers generalize and exhibit benign overfitting in-context},
  author={Frei, Spencer and Vardi, Gal},
  journal={arXiv preprint arXiv:2410.01774},
  year={2024}
}

@article{garg2022can,
  title={What can transformers learn in-context? a case study of simple function classes},
  author={Garg, Shivam and Tsipras, Dimitris and Liang, Percy S and Valiant, Gregory},
  journal={Conference on Neural Information Processing Systems},
  year={2022}
}

@article{goodfellow2015explaining,
  title={Explaining and Harnessing Adversarial Examples}, 
  author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
  journal={arXiv preprint arXiv:1412.6572},
  year={2015},
}

@inproceedings{guo2021gradientbased,
  title={Gradient-based Adversarial Attacks against Text Transformers},
  author={Guo, Chuan and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e} and Kiela, Douwe},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2021}
}

@inproceedings{hayase2024querybased,
  title={Query-Based Adversarial Prompt Generation},
  author={Jonathan Hayase and Ema Borevkovi{\'c} and Nicholas Carlini and Florian Tram{\`e}r and Milad Nasr},
  booktitle={Conference on Neural Information Processing Systems},
  year={2024},
}

@article{huang2023context,
  title={In-context convergence of transformers},
  author={Huang, Yu and Cheng, Yuan and Liang, Yingbin},
  journal={arXiv preprint arXiv:2310.05249},
  year={2023}
}

@inproceedings{jin2024jailbreaking,
  title={Jailbreaking Large Language Models Against Moderation Guardrails via Cipher Characters},
  author={Haibo Jin and Andy Zhou and Joe D. Menke and Haohan Wang},
  booktitle={Conference on Neural Information Processing Systems},
  year={2024},
}

@inproceedings{liao2024amplegcg,
  title={Ample{GCG}: {Learning} a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed {LLM}s},
  author={Zeyi Liao and Huan Sun},
  booktitle={Conference on Language Modeling},
  year={2024},
}

@inproceedings{lin2024transformers,
  title={Transformers as Decision Makers: {Provable} In-Context Reinforcement Learning via Supervised Pretraining},
  author={Licong Lin and Yu Bai and Song Mei},
  booktitle={International Conference on Learning Representations},
  year={2024},
}

@inproceedings{liu2024autodan,
  title={{AutoDAN}: {Generating} Stealthy Jailbreak Prompts on Aligned Large Language Models},
  author={Xiaogeng Liu and Nan Xu and Muhao Chen and Chaowei Xiao},
  booktitle={International Conference on Learning Representations},
  year={2024},
}

@article{liu2024turbo,
  title={AutoDAN-Turbo: {A} lifelong agent for strategy self-exploration to jailbreak {LLMs}},
  author={Liu, Xiaogeng and Li, Peiran and Suh, Edward and Vorobeychik, Yevgeniy and Mao, Zhuoqing and Jha, Somesh and McDaniel, Patrick and Sun, Huan and Li, Bo and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2410.05295},
  year={2024}
}

@article{lu2024asymptotic,
  title={Asymptotic theory of in-context learning by linear attention},
  author={Lu, Yue M and Letey, Mary I and Zavatone-Veth, Jacob A and Maiti, Anindita and Pehlevan, Cengiz},
  journal={arXiv preprint arXiv:2405.11751},
  year={2024}
}

@inproceedings{madry2018towards,
  title={Towards Deep Learning Models Resistant to Adversarial Attacks},
  author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
  booktitle={International Conference on Learning Representations},
  year={2018},
}

@article{magen2024benign,
  title={Benign overfitting in single-head attention},
  author={Magen, Roey and Shang, Shuning and Xu, Zhiwei and Frei, Spencer and Hu, Wei and Vardi, Gal},
  journal={arXiv preprint arXiv:2410.07746},
  year={2024}
}

@inproceedings{mahankali2024one,
  title={One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention},
  author={Arvind V. Mahankali and Tatsunori Hashimoto and Tengyu Ma},
  booktitle={International Conference on Learning Representations},
  year={2024},
}

@article{mazeika2024harmbench,
  title={{HarmBench}: {A} standardized evaluation framework for automated red teaming and robust refusal},
  author={Mantas Mazeika and Long Phan and Xuwang Yin and Andy Zou and Zifan Wang and Norman Mu and Elham Sakhaee and Nathaniel Li and Steven Basart and Bo Li and David Forsyth and Dan Hendrycks},
  journal={arXiv preprint arXiv:2402.04249},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Conference on Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{paulus2024advprompter,
  title={AdvPrompter: {Fast} adaptive adversarial prompting for {LLMs}},
  author={Paulus, Anselm and Zharmagambetov, Arman and Guo, Chuan and Amos, Brandon and Tian, Yuandong},
  journal={arXiv preprint arXiv:2404.16873},
  year={2024}
}

@inproceedings{qi2024finetuning,
  title={Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!},
  author={Xiangyu Qi and Yi Zeng and Tinghao Xie and Pin-Yu Chen and Ruoxi Jia and Prateek Mittal and Peter Henderson},
  booktitle={International Conference on Learning Representations},
  year={2024},
}

@article{qi2024safety,
  title={Safety Alignment Should Be Made More Than Just a Few Tokens Deep}, 
  author={Xiangyu Qi and Ashwinee Panda and Kaifeng Lyu and Xiao Ma and Subhrajit Roy and Ahmad Beirami and Prateek Mittal and Peter Henderson},
  journal={arXiv preprint arXiv:2406.05946},
  year={2024},
}

@article{rafailov2023direct,
  title={Direct preference optimization: {Your} language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Conference on Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@InProceedings{sadasivan2024fast,
  title={Fast Adversarial Attacks on Language Models In One {GPU} Minute},
  author={Sadasivan, Vinu Sankar and Saha, Shoumik and Sriramanan, Gaurang and Kattakinda, Priyatham and Chegini, Atoosa and Feizi, Soheil},
  booktitle={International Conference on Machine Learning},
  year={2024},
}

@inproceedings{schwinn2024soft,
  title={Soft Prompt Threats: {Attacking} Safety Alignment and Unlearning in Open-Source {LLM}s through the Embedding Space},
  author={Leo Schwinn and David Dobre and Sophie Xhonneux and Gauthier Gidel and Stephan G{\"u}nnemann},
  booktitle={Conference on Neural Information Processing Systems},
  year={2024},
}

@article{sheshadri2024latent,
  title={Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in {LLMs}},
  author={Sheshadri, Abhay and Ewart, Aidan and Guo, Phillip and Lynch, Aengus and Wu, Cindy and Hebbar, Vivek and Sleight, Henry and Stickland, Asa Cooper and Perez, Ethan and Hadfield-Menell, Dylan and Casper, Stephen},
  journal={arXiv preprint arXiv:2407.15549},
  year={2024}
}

@inproceedings{shi2024why,
  title={Why Larger Language Models Do In-context Learning Differently?},
  author={Zhenmei Shi and Junyi Wei and Zhuoyan Xu and Yingyu Liang},
  booktitle={International Conference on Machine Learning},
  year={2024},
}

@inproceedings{shin2020autoprompt,
  author={Taylor Shin and Yasaman Razeghi and Robert L. Logan IV and Eric Wallace and Sameer Singh},
  title={{AutoPrompt}: Eliciting Knowledge from Language Models with Automatically Generated Prompts},
  booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
  year={2020}
}

@article{szegedy2014intriguing,
  title={Intriguing properties of neural networks}, 
  author={Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
  journal={arXiv preprint arXiv:1312.6199},
  year={2014},
}

@inproceedings{von2023transformers,
  title={Transformers learn in-context by gradient descent},
  author={Von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Jo{\~a}o and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max},
  booktitle={International Conference on Machine Learning},
  pages={35151--35174},
  year={2023},
  organization={PMLR}
}

@inproceedings{wang2024incontext,
  title={In-context Learning on Function Classes Unveiled for Transformers},
  author={Zhijie Wang and Bo Jiang and Shuai Li},
  booktitle={International Conference on Machine Learning},
  year={2024},
}

@inproceedings{wei2023jailbroken,
  title={Jailbroken: {How} Does {LLM} Safety Training Fail?},
  author={Alexander Wei and Nika Haghtalab and Jacob Steinhardt},
  booktitle={Conference on Neural Information Processing Systems},
  year={2023},
}

@inproceedings{wu2024how,
  title={How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?},
  author={Jingfeng Wu and Difan Zou and Zixiang Chen and Vladimir Braverman and Quanquan Gu and Peter Bartlett},
  booktitle={International Conference on Learning Representations},
  year={2024},
}

@inproceedings{xhonneux2024efficient,
  title={Efficient Adversarial Training in {LLM}s with Continuous Attacks},
  author={Sophie Xhonneux and Alessandro Sordoni and Stephan G{\"u}nnemann and Gauthier Gidel and Leo Schwinn},
  booktitle={Conference on Neural Information Processing Systems},
  year={2024},
}

@inproceedings{xu2024bag,
  title={Bag of Tricks: {Benchmarking} of Jailbreak Attacks on {LLMs}},
  author={Zhao Xu and Fan Liu and Hao Liu},
  booktitle={Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2024},
}

@inproceedings{yang2024incontext,
  title={In-Context Learning with Representations: {Contextual} Generalization of Trained Transformers},
  author={Tong Yang and Yu Huang and Yingbin Liang and Yuejie Chi},
  booktitle={Conference on Neural Information Processing Systems},
  year={2024},
}

@article{yu2024robust,
  title={Robust {LLM} safeguarding via refusal feature adversarial training},
  author={Yu, Lei and Do, Virginie and Hambardzumyan, Karen and Cancedda, Nicola},
  journal={arXiv preprint arXiv:2409.20089},
  year={2024}
}

@article{zhang2024trained,
  title={Trained transformers learn linear models in-context},
  author={Zhang, Ruiqi and Frei, Spencer and Bartlett, Peter L},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={49},
  pages={1--55},
  year={2024}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

