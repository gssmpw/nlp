\section{Introduction}
The maxim, ``Better to remain silent and be thought a fool than to speak and to remove all doubt,'' offers a compelling perspective on the strategic value of withholding information. While often invoked in interpersonal contexts, it resonates surprisingly well in the context of Generative AI (GenAI) systems like ChatGPT. These systems are designed to answer user queries immediately, yet one might wonder: Are there situations where the system should remain silent?



One such scenario arises when the system hallucinates. Hallucinations, defined as the generation of incorrect or fabricated information, are an intrinsic property of generative models that cannot be entirely avoided \cite{kalai2024calibrated}. Another scenario involves questions concerning safety and ethics, with potentially life-threatening consequences \cite{Shin2023, MelloGuha2023, li2024inference}. However, as we argue in this paper, it can be advantageous for both GenAI operators and users if the system avoids responding indiscriminately to every prompt, especially when addressing emerging technologies and novel content.

%However, it may still be suboptimal for both generative AI operators and users if the system responds indiscriminately to every prompt, especially when addressing emerging technologies and novel content.

To illustrate, consider GenAI's competitive relationship with a human-driven platform like Stack Overflow. Users may direct their questions to either GenAI or Stack Overflow, seeking solutions to their problems. Posting a code-related question on Stack Overflow generates clarification questions in the comments, solutions offered by experts, feedback from other users (upvotes) and the original poster (acceptance flag), etc. Such valuable data could significantly enhance GenAI,  improving its performance. In contrast, querying GenAI can lead to quicker user satisfaction and increased engagement with GenAI, potentially enhancing its revenue streams. On the downside, the lack of community interaction may result in less comprehensive solutions and reduce the opportunity for generating rich, labeled data that community-driven platforms like Stack Overflow thrive on. This absence of dynamic, user-generated content and in-depth discussions can be detrimental to user welfare in the long term, as GenAI's ability to provide high-quality answers depends on such data. 



Motivated by the issue above, this paper pioneers the framework of \emph{selective response}. Namely, strategically choosing when, if, and how to engage with user queries, particularly those involving emerging topics and novel technologies. We explicitly suggest that when a new topic emerges, GenAI could strategically decide to provide lower-quality answers than what it can or even disclaim to have not enough data to respond. We represent such behavior abstractly by modeling GenAI as not responding or ``remaining silent''. Clearly, selective response has a short-term negative impact; however, as we show, an appropriate selective response would lead to an improved data generation process, benefiting the long term for both GenAI's revenue and user social welfare.

\paragraph{Our contribution} 
 % 1. conceptual - propose the idea that answering all the time might be suboptimal + we modeled it as an action of GenAI in [0, 1] and modeled its interplay with data generation.
 % 2. we start by studying how withholding answers affects GenAI's revenue. we first show that there are instances where indiscriminately answering is suboptimal, show the reason why it might happen.
 % 3. We then show that finding the optimal scheme that maximizes the revenue is a not trivial and propose an approximation algorithm.
 % 4. we then move on to show that always answering might also be suboptimal for the users and show how withholding affects the users' social welfare.
 % 5. we show that the same withholding scheme can simultaneously make both genAI and the users better off and provide conditions for that.
 % 6. we finish by proposing an efficient approximately optimal algorithm to maximize GenAI's revenue under the constraint that the users would be better off then the were if GenAI answered all the time.

Our contribution is two-fold. The first is conceptual: Our paper is the first to explore selective response for GenAI. We present a stylized model of an ecosystem that evolves sequentially, featuring two platforms: A generative AI-based platform called GenAI and a human-driven Q\&A platform named Forum. GenAI generates revenue by engaging with users and can adopt a \emph{selective response strategy}: Determining the proportion of users it responds to in each round. Here, ``not responding'' represents a broad spectrum of possible behaviors—such as strategically withholding data, providing lower-quality answers than GenAI can produce, or claiming insufficient data, ultimately driving users to seek answers on Forum.\footnote{In real-world scenarios, multiple GenAI systems vie for user traffic, making the analysis of such competition significantly more complex. We address this complexity in Section~\ref{sec:discussion}.} We treat these behaviors collectively as ``selective response,'' which abstracts them for conceptual clarity. In contrast, Forum operates as a non-strategic player. 

Users decide between GenAI and Forum based on the utility they derive from each platform. Those who choose Forum contribute to the creation of new data, which GenAI can later incorporate during retraining. Crucially, GenAI's quality in each round depends on the cumulative data generated since the beginning of the interaction. Our novel model allows us to explore the dynamics of content creation, welfare, and revenue from a game-theoretic lens.

%To explore this idea, we model an ecosystem featuring two platforms: a generative AI-based platform called GenAI and a human-driven Q\&A platform named Forum. GenAI generates revenue by engaging users and can adopt a \emph{selective response strategy}—a vector that specifies the proportion of users it chooses to respond to in each round. In contrast, Forum operates as a non-strategic player. Users decide between GenAI and Forum based on the utility they derive from each platform. Those who choose Forum contribute to the creation of new data, which GenAI can later incorporate during retraining. GenAI’s utility in each round is influenced by the cumulative data generated from the beginning of the interaction to that round.

Our second contribution is technical: We begin by demonstrating that selective response can   Pareto-dominate the always-responding approach. Specifically, we establish the following result.
\begin{theorem}[Informal statement of Observation~\ref{obs: withholding impact}] 
Compared to the case where GenAI always answers, selective response strategies can improve user welfare, GenAI's revenue, and even both.
\end{theorem}
We also quantify the extent to which selective response can improve revenue and welfare w.r.t. the always-responding approach.

Next, we analyze the long-term effects of selective response, revealing that it leads to higher proportions of users choosing GenAI and increased data generation (Theorem~\ref{thm: not answering increase proportions}). Building on this result, we devise an approximately optimal solution to GenAI's revenue maximization problem. 
\begin{theorem} [Informal statement of Theorem~\ref{thm: alg guarantees fixed actions}]
Let $\varepsilon$ be a small positive constant and let $A$ be a finite set of selective responses. There exists an algorithm guaranteeing an additive $ O(\varepsilon T^2)$ approximation of GenAI's optimal revenue, and its runtime is $O\left(\frac{T^2 \left| A \right|}{\varepsilon}\right)$.
\end{theorem}
We extend this result to the case where GenAI is constrained to meet an exogenously given social welfare threshold.

Finally, we analyze the impact of selective response on social welfare. We provide valuable insights into how a one-round intervention affects the data generation process and its implications on welfare. We leverage these insights to demonstrate how regulators that aim to enhance social welfare can have successful one-round interventions, improving user welfare while ensuring a bounded impact on GenAI's revenue.

Altogether, our work challenges the conventional notion that GenAI should always provide answers. Despite its theoretical nature, the messages our paper conveys can translate into practical considerations for both GenAI companies and regulators and influence how forum-GenAI collaborations should form.


\subsection{Related Work}

The literature on generative AI is growing at an immense pace. Most research focuses on mitigating hallucinations \cite{ji2023survey}, performance \cite{frieder2024mathematical, kocon2023chatgpt, li2024more, chow2024inference}, and expanding applications \cite{kasneci2023chatgpt, liu2024your}. Our work connects to the emerging body of research on foundation models and game theory \cite{raghavan2024competition, laufer2024fine, conitzerposition, dean2024accounting}. This literature studies competition between generative AI models and human content creators \cite{yao2024human, esmaeili2024strategize}, the impact of generative AI on content diversity \cite{raghavan2024competition}, and works motivated by social choice and mechanism design \cite{conitzerposition, sun2024mechanism}. 

The most closely related work to ours is that of \citet{taitler2024braess}, which examines whether the existence of generative AI is beneficial to users. In their model, the generative AI platform decides when to train, and they propose a regulatory approach to ensure social welfare for users. In contrast, our model introduces a different approach, where the generative AI chooses a portion of queries to answer, demonstrating that responding selectively can benefit both the generative AI platform and its users.

Our notion of selective response is also inspired by the economic literature on information design~\cite{bergemann2019information,bergemann2015limits}, which explores how the strategic disclosure and withholding of information can influence agents' behavior within a system. Another related concept is signaling~\cite{crawford1982strategic,milgrom1981good}, referring to strategic communication used by agents to potentially improve outcomes \cite{babichenko2023algorithmic, lu2023adversarial}. Similarly, cheap talk~\cite{lo2023cheap, crandall2018cooperating} can be used for fostering cooperation. 
Our notion of selective response can be observed as an information design problem. GenAI strategically manages information disclosure to influence user behavior and ultimately optimize its revenue. 

Finally, since our model includes an ecosystem with two platforms (GenAI and Forum), it relates to a growing body of work on competition between platforms \cite{rietveld2021platform, karle2020segmentation, bergemann2024data, Tullock1980}. Previous works explore the effects of competition in marketplaces on users' social welfare \cite{jagadeesan2023competition, feldman2013competition}, as we do in this paper. 