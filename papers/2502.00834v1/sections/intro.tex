

\section{Introduction}

% In the field of adversarial robustness,
In adversarial machine learning, most works have demonstrated their effectiveness in safeguarding deep neural networks by refining the geometry and landscape of parameter space, including robust training~\citep{madry2017towards,zhang2019theoretically,gowal2021improving} and regularization~\citep{cisse2017parseval,zheng2016improving}.
Especially in the visual domain, adversarial training methods
powered by generative AI ~\cite{wang2023better,gowal2021improving}
have achieved remarkable success and dominated the robustness leaderboard~\cite{croce2020robustbench}. 
However, their success increasingly relies on extensive synthetic training data crafted by generative models and increasing networks capacity, posing critical challenges to breaking through the plateau in adversarial robustness.

% \red{focus training strategy}



In fact, adversarially trained neural networks improve robustness and generalization largely by memorizing adversarial perturbations during training~\cite{madry2017towards}. While increasing the backbone model size can enhance memorization capacity, adversarial training methods often suffer from  catastrophic \emph{robust overfitting} problem~\cite{rice2020overfitting}. Existing methods aim to mitigate robust overfitting from various perspectives, including regularization~\cite{andriushchenko2020understanding,qin2019adversarial,sriramanan2020guided}, data augmentation~\cite{devries2017improved,zhang2017mixup,carmon2019unlabeled,zhai2019adversarially}, and generative modeling techniques~\cite{wang2023better,gowal2021improving}
% . For example, early stopping~\cite{rice2020overfitting} is a simple yet effective strategy to prevent overfitting during adversarial training. Regularization techniques~\cite{andriushchenko2020understanding,qin2019adversarial,sriramanan2020guided} have also proven effective by penalizing model complexity. Data augmentation approaches, such as Cutout~\cite{devries2017improved}, Mixup~\cite{zhang2017mixup}, and semi-supervised learning techniques~\cite{carmon2019unlabeled, zhai2019adversarially}, are commonly used to reduce overfitting in deep networks~\cite{schmidt2018adversarially}. Moreover, generative modeling techniques~\cite{wang2023better,gowal2021improving} have demonstrated significant success in generating substantial training datasets. 
However, all these methods incrementally contribute along a similar trajectory by refining the training strategy, making it difficult to achieve further groundbreaking advancements with the same network capacity.

% \red{plot a figure to show structural prior importance}

% Instead
In this work, we propose to explore an orthogonal direction for innovation
upon the finding that most state-of-the-art approaches largely ignore the \emph{structural prior} in deep neural networks. 
% In fact, structural prior knowledge plays a pivotal role in guiding representation learning to 
% offer better interpretability and improve the memory and computational efficiency. 
% For instance, CNNs~\cite{lecun1998gradient} and RNNs~\cite{rumelhart1986learning} incorporate structural priors into neural networks to capture spatial structures for images and temporal dependencies for sequences, respectively.
% ResNets~\cite{he2016deep} have achieved groundbreaking success by introducing the residual connection prior to avoid degradation problem in the deep neural networks. 
% \xr{I do not think these examples like CNN, RNN, ResNet represent that kind of structure prior we talk about. It is better to focus on the discussion of diction structure to avoid disatractions}
Several works~\citep{papyan2017convolutional, cazenavette2021architectural, mahdizadehaghdam2019deep, li2022revisiting} have explored building robust architectures based on sparse coding or dictionary learning priors, assuming that a signal can be sparsely represented as a linear superposition of atoms from a convolutional dictionary. This approach enables natural image patterns to be captured by the sparse code while effectively denoising corruptions. However, their effectiveness has only been validated in scenarios involving weak random corruptions and universal perturbations. Its full potential remains unexplored in the pursuit of stronger adversarial robustness and improved generalization.



% However, structural priors have yet to be fully exploited in the pursuit of stronger adversarial robustness and generalization.

% Although certain works~\citep{papyan2017convolutional, cazenavette2021architectural, mahdizadehaghdam2019deep, li2022revisiting} have attempted to build robust architectures based on sparse coding or dictionary learning prior, their effectiveness has been validated only in scenarios involving weak random corruptions or universal perturbations.
% While robust dictionary learning has exceled in conventional signal and image processing with strong interpretability and  theoretical guarantees, its potential in adversarially robust deep learning
% % , particularly against adaptively crafted
% % adversarial attacks, 
% remains underexplored.

To fill this research gap, we revisit dictionary learning in deep learning, which uncovers its inability in handling adaptive adversarial attacks, supported by both empirical evidence and theoretical reasoning.
To overcome these limitations, we propose a novel elastic dictionary learning (Elastic DL) framework that complements existing adversarial training methods to achieve superior robustness and generalization.
Our contributions are as follows:
\begin{itemize}[left=0pt]
    \item We revisit convolutional dictionary learning in deep learning, highlighting its failures under adaptive attacks, and provide theoretical insights into these limitations.
    \item  We first propose a robust dictionary learning approach via $\ell_1$-reconstruction and highlight its lower natural performance and the challenges in handling adaptive attacks. Furthermore, we introduce a novel Elastic Dictionary Learning (Elastic DL) framework to enable a better trade-off between natural and robust performance.
    \item We develop an efficient reweighted iterative  shrinkage thresholding algorithm (RISTA) to approximate the non-smooth Elastic DL objective with theoretical convergence guarantees. The algorithm can be seamlessly integrated into deep learning models as a replacement for conventional convolutional layers.
    \item Extensive experiments demonstrate that our proposed Elastic DL framework can significantly improves adversarial  robustness and generalization. 
    Notably, our Elastic DL can achieve state-of-the-art performance, significantly outperforming the previous best defense PORT~\cite{sehwag2021robust} on leaderboard across various budgets under $\ell_\infty$-norm and $\ell_2$-norm attacks.
\end{itemize}



