\onecolumn

\section{Overview of Elastic Dictionary Learning}
\label{sec:overview_edl}


% \begin{figure}[h!]
%     \centering
%     \begin{subfigure}[b]{0.67\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/overview.pdf} % Replace with your image path
%         \caption{Overview of Elastic DL neural networks.} % Subfigure caption
%         \label{fig:edl_nets}
%     \end{subfigure}
%     \hfill
%     % Subfigure (b)
%     \begin{subfigure}[b]{0.32\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/edl.pdf} % Replace with your image path
%         \caption{Exploded view of Elastic DL layer.}
%         \label{fig:edl_layer}
%     \end{subfigure}


%     % \includegraphics[width=0.9\linewidth]{figures/overview.pdf}

    
% \caption{ (a) Overview of Elastic DL neural networks. Elastic DL neural networks consist of multiple stacked Elastic DL (EDL) layers. During the forward pass, the input $\bx$ is fed into the model, generating a series of hidden codes $\{\bz^{(l)}\}_{l=1}^{L}$ through EDL layers. During the backward pass, the model parameters are updated, including kernel weights $\{\vA^{(l)}\}_{l=0}^{L-1}$, layer-wise balance weights $\{\beta^{(l)}\}_{l=0}^{L-1}$, and classifier parameters $\vW$. (b) Exploded view of Elastic DL (EDL) layer. Each EDL layer is unrolled using the proposed RISTA algorithm, which approximates the solution for elastic dictionary learning objective.}

%     \label{fig:overview}
% \end{figure}

\textbf{Overview of Elastic DL neural networks.} Here we plot a figure to show the overall pipeline of incorporating Elastic DL structural prior into adversarial training as in Figure~\ref{fig:edl_nets}.
\begin{figure}[h!]
        \centering
        \includegraphics[width=0.9\textwidth]{figures/overview_adv.pdf} % Replace with your image path
        % \caption{Overview of Elastic DL neural networks.} % Subfigure caption
       
\caption{ Overview of Elastic DL neural networks in adversarial training.  Elastic DL neural networks consist of multiple stacked Elastic DL (EDL) layers. During the forward pass, the input $\bx$ is fed into the model, generating a series of hidden codes $\{\bz^{(l)}\}_{l=1}^{L}$ through EDL layers. During the backward pass, the model parameters are updated, including kernel weights $\{\vA^{(l)}\}_{l=0}^{L-1}$, layer-wise balance weights $\{\beta^{(l)}\}_{l=0}^{L-1}$, and classifier parameters $\vW$.
}
 \label{fig:edl_nets}

    \end{figure}


% To address the aforementioned research gap and make a breakthrough, we propose a novel adverarial dictionary training framework by incorporating our noise-adaptive dictionary learning architecture to adversarial training.
Consider a  model with $\{\vA^{(l)}\}_{l=0}^{L-1}$ and $\{\beta^{(l)}\}_{l=0}^{L-1}$ in the $L$ EDL layers  and $\vW$ in the classifier. 
%Then this model can be represented as: $$f(\bx)=f^{(L-1)}_{\vA^{(L-1)},\beta^{(L-1)}}\circ \cdots \circ f^{(l)}_{\vA^{(l)},\beta^{(l)}} \circ \cdots\circ  f^{(1)}_{\vA^{(1)},\beta^{(1)}}(\bx) ,$$
%where $ f^{(l)}_{\vA^{(l)},\beta^{(l)}} (\bx)$ is the implicit layer as in Algorithm~\ref{alg:irls-ista}. For simplicity, we exclude the notations of the additional modules (e.g., pooling, fully-connected linear layers, etc.). 
Then, the adversarial training framework with EDL can be formulated as:
\begin{align*}
    &\min_{\{\vA^{(l)}, \beta^{(l)}\}_{l=0}^{L-1}}  \mathbb{E}_{(\bx,\by)\sim \cD}\left[ \max_{\bx'\in\cB(\bx)}  \ell(\bz^{*(L)},y)\right]  \\
    \text{s.t. }& \bz^{*(l+1)} = \argmin_\bz \ell_{NADL}(\bz, \vA^{(l)},\bz^{*(l)}), \\
    &\ell_{NADL}^{(l)}(\bz,\vA,\bx) \text{ is defined in Eq.~\eqref{eq:robust_dictionary_learning}}, \\
    &\bz^{*(0)}=\bx',\\
    &\text{for } l=0,\cdots, L-1.\\
\end{align*}
Its overall pipeline can be divided into three main steps as in Figure~\ref{fig:edl_nets}:
\begin{itemize}
    \item Step 1 (Attack): leverage adversarial attack  algorithm (e.g., PGD) to generate worst-case perturbation $\bx'$.
    \item Step 2 (Forward): input $\bx'$ as $\bz^{*(0)}$ into model to obtain a series of  hidden codes for each layer $\{\bz^{(l)}\}_{l=1}^{L}$ by optimizing dictionary learning loss in Eq.~\eqref{eq:robust_dictionary_learning}.
    \item Step 3 (Backward): update the model parameters including kernel weights $\{\vA^{(l)}\}_{l=0}^{L-1}$, layer-wise balance weight $\{\beta^{(l)}\}_{l=0}^{L-1}$, and other parameters $\vW$.
    
\end{itemize}



\newpage
\textbf{Exploded view of Elastic DL layer.} We also provide an exploded view of each Elastic DL layer as in Figure~\ref{fig:edl_layer}. The input signal $\bz^{(k)}$ can be represented by a linear superposition of several atoms $\{\balpha_{dc}\}$ from a convolutional dictionary $\vA^{(l)}$. 
Each EDL layer is unrolled using the proposed RISTA algorithm, which approximates the solution for elastic dictionary learning objective.




    \begin{figure}[h!]
        \centering
        \includegraphics[width=\textwidth]{figures/edl_layer_v2.png} % Replace with your image path
        % \caption{Exploded view of Elastic DL layer.}
        
        \caption{ Exploded view of Elastic DL (EDL) layer. }
        \label{fig:edl_layer}
    \end{figure}


% \textbf{Pseudo code in PyTorch style.} To fure

% The pseudo code is presented in Algorithm~\ref{alg:irls}. 


% \begin{algorithm}[H]
% % \caption{Robust NRPM-MLPs}
% \caption{Elastic DL Layer}
% \label{alg:irls}
% \begin{small}
% \begin{minted}[escapeinside=||,mathescape=true,linenos=true, numbersep=-3pt, framesep=3mm]{Python}
% class ElasticDL(nn.Module):
%     def __init__(self, )
%  def ElasticDL(X, A, eps = 1e-3, L = 3):
%      AX = X.unsqueeze(-1) * A
%      D = X.shape[0]
%      Z = torch.matmul(X, A) # Initialization as LPM-estimation
%      For _ in range(K):
%         DIST = torch.abs(KX - Z/D) # Distance
%         W = 1/(DIST + eps)
%         W = normalize(W, p=1, dim=0) 
%         Z = D*(W*AX).sum(dim=0) # Update
%     return Z
% \end{minted}
% \end{small}
% \end{algorithm}





\newpage

\section{Theoretical Proof}

% You can have as much text here as you want. The main body must be at most $8$ pages long.
% For the final version, one more page can be added.
% If you want, you can use an appendix like this one.  

% The $\mathtt{\backslash onecolumn}$ command above can be kept in place if you prefer a one-column appendix, or can be removed if you prefer a two-column appendix.  Apart from this possible change, the style (font size, spacing, margins, page numbering, etc.) should be kept the same as the main body.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Proof of Lemma~\ref{lemma:local_upper_bound}}
\label{sec:proof_local_upper_bound}




\begin{proof}
    
Since $\sqrt{a}\leq\frac{a}{2\sqrt{b}}+\frac{\sqrt{b}}{2}$ and the equlity holds when $a=b$, by replacemnet as $a=(\bx[i,j,c]-\cA^*(\bz)[i,j,c])^2$ and $b=(\bx[i,j,c]-\cA^*(\bz_*)[i,j,c])^2$, then
\begin{align*}
    |\bx[i,j,c]-\cA^*(\bz)[i,j,c]|&\leq \frac{1}{2}\cdot \frac{1}{|\bx[i,j,c]-\cA^*(\bz_*)[i,j,c]|}\cdot (\bx[i,j,c]-\cA^*(\bz)[i,j,c])^2+\frac{1}{2}|\bx[i,j,c]-\cA^*(\bz_*)[i,j,c]|\\
    &=\bw[i,j,c]\cdot (\bx[i,j,c]-\cA^*(\bz)[i,j,c])^2+\frac{1}{2}|\bx[i,j,c]-\cA^*(\bz_*)[i,j,c]|
\end{align*}


Sum up the items on both sides, we obtain 
\begin{align*}
\cE(\bz)&=\|\bx-\cA^*(\bz)\|_1 = \sum_{i,j,c}|\bx[i,j,c]-\cA^*(\bz)[i,j,c]|\\ 
   &\leq
    \sum_{i,j,c}\bw[i,j,c]\cdot (\bx[i,j,c]-\cA^*(\bz)[i,j,c])^2+\frac{1}{2} \sum_{i,j,c}|\bx[i,j,c]-\cA^*(\bz_*)[i,j,c]|\\
  &=\|\bw^{1/2}\odot (\bx-\cA^*(\bz))\|_2^2+\cE(\bz_*)\\
  &=\cU(\bz,\bz_*)
\end{align*}

and the equality holds at $a=b$ ($\bz=\bz_*$):
\begin{equation}
\label{eq:local_equality}
    \cU(\bz_*,\bz_*) = \cE(\bz_*).
\end{equation}

\end{proof}


\subsection{Proof of Algorithm Iteration in Eq.~\eqref{eq:algo_iteration_l1}}
\label{sec:proof_algo_iteration}

% $$\bz_{t+1}=\argmin_\bz  \lambda\|\bz\|_1 + \frac{\beta}{2}\|\bx - \cA^*(\bz)\|_2^2 +\frac{1-\beta}{2} \|(\bw^{(t)})^{1/2} \odot \left(\bx - \cA^*(\bz)\right)\|_2^2$$ 


% \begin{equation}
%     \begin{aligned}
%         &\nabla = \cA \left(\left(\beta \mathbf{1} + (1-\beta) \bw^{(t)}\right)\odot\left(\bx - \cA^*(\bz_t)\right)\right)\\
%         &\bz_{t+1} = \mathcal{T}_{\lambda t} \left( \bz_t + t \cdot \nabla  \right),
%         % \label{eq:algo_iteration}
%     \end{aligned}
% \end{equation}

Here, we derive the algorithm for general elastic dictionary learning (Elastic DL), the $\ell_1$-based robust dictionary learning (Robust DL) can be consider as the special case with $\beta=0$.
\begin{proof}
For convex objective: 
$$f(\bz)=\frac{\beta}{2}\|\bx - \cA^*(\bz)\|_2^2 +\frac{1-\beta}{2} \|(\bw^{(t)})^{1/2} \odot \left(\bx - \cA^*(\bz)\right)\|_2^2,$$
we can achieve the optima via the first-order gradient descent:
$$ \bz_{t+1}=\bz_t-t\nabla f(\bz_t),$$
or equivalently,
$$\bz_{t+1}=\argmin_\bz\{f(\bz_t)+\langle\bz-\bz_t,\nabla f(\bz_t)\rangle+\frac{1}{2t}\|\bz-\bz_t\|^2\}.$$

Then, for the corresponding $\ell_1$-regularized problem:
$$\min_\bz f(\bz) + \lambda \|\bz\|_1,$$ we have:
\begin{align*}
   \bz_{t+1}&=\argmin_\bz\{ f(\bz_t)+\langle\bz-\bz_t,\nabla f(\bz_t)\rangle+\frac{1}{2t}\|\bz-\bz_t\|^2+\lambda\|\bz\|_1\} \\
   &= \argmin_\bz\{\frac{1}{2t}\|\bz-(\bz_t-t\nabla f(\bz_t))\|^2+\lambda\|\bz\|_1\}\\
   &= \argmin_\bz\{g(\bz):=\frac{1}{2t}\|\bz-\by\|^2+\lambda\|\bz\|_1\} \quad (\by=\bz_t-t\nabla f(\bz_t))
\end{align*}
Then,  the optimality condition is:
\begin{align*}
    &0\in\partial_\bz g(\bz^*) =  \frac{1}{t}(\bz^*-\by)+\lambda \text{sign}(\bz^*)\\
    \Leftrightarrow \quad  & \by \in \bz^* + \lambda t \text{sign}(\bz^*) \\
    \Leftrightarrow \quad  & \by \in \left(\text{Id} + \lambda t \text{sign}(\cdot)\right)(\bz^*) \\
    \Leftrightarrow \quad  & \bz^* = \cT_{\lambda t}(\by) := \left(\text{Id} + \lambda t \text{sign}(\cdot)\right)^{-1}(\by) = \text{sign}(\by) \left(|\by-\lambda t|\right)_+.\\
\end{align*}
Since 
\begin{align*}
\nabla f(\bz)&=-\beta\cA(\bx - \cA^*(\bz)) - (1-\beta)\cA( \bw^{(t)} \odot \left(\bx - \cA^*(\bz)\right)\\
&=-\cA \left(\left(\beta \mathbf{1} + (1-\beta) \bw^{(t)}\right)\odot\left(\bx - \cA^*(\bz_t)\right)\right),
\end{align*}
Then 
$$\bz_{t+1}=\bz^*=\mathcal{T}_{\lambda t}\left(\by \right)=\mathcal{T}_{\lambda t} \left( \bz_t - t \cdot \nabla f(\bz)  \right)=\mathcal{T}_{\lambda t} \left( \bz_t + t \cdot \cA \left(\left(\beta \mathbf{1} + (1-\beta) \bw^{(t)}\right)\odot\left(\bx - \cA^*(\bz_t)\right)\right)   \right)$$


\end{proof}



\subsection{Proof of Theorem~\ref{thm:influence_function}}
\label{sec:proof_influence_function}


\begin{proof}


Let $\bx_t :=t\Delta + (1-t)\bx, \bw_t=\frac{1}{2(|\cE(\bx_t)|+\epsilon)}$, then 

\begin{align*}
&IF(\Delta; \cP_{\text{vanilla}}, \bx)\\
=&\lim_{t\to 0^+} \frac{\cP_{\text{vanilla}}(\bx_t) - \cP_{\text{vanilla}}(\bx)}{t}\\
=&\lim_{t\to 0^+}\frac{\cE(\bx_t)-\cE(\bx)}{t}\\
=&\lim_{t\to 0^+}\frac{\cE(t\Delta + (1-t)\bx)-\cE(\bx)}{t}\\
=&\cE(\Delta-\bx)
\end{align*}



Given a small enough $t$, we can have $\text{sign}(\cE(\bx_t)) = \text{sign}(\cE(\bx))$, then 
\begin{align*}
&\bw_t-\bw\\
=&\frac{1}{2(|\cE(\bx_t)|+\epsilon)}-\frac{1}{2(|\cE(\bx)|+\epsilon)}\\
=&\frac{|\cE(\bx)|-|\cE(\bx_t)|}{2(|\cE(\bx_t)|+\epsilon)(|\cE(\bx)|+\epsilon)}\\
=&-\frac{\text{sign} (\cE(\bx))\odot (\cE(\bx_t)-\cE(\bx))}{2(|\cE(\bx_t)|+\epsilon)(|\cE(\bx)|+\epsilon)}\\
\end{align*}

So $$\lim_{t\to 0^+}\frac{\bw_t-\bw}{t} = \lim_{t\to 0^+}-\frac{\text{sign} (\cE(\bx))\odot (\cE(\bx_t)-\cE(\bx))}{2t(|\cE(\bx_t)|+\epsilon)(|\cE(\bx)|+\epsilon)} = -\frac{\text{sign} (\cE(\bx))\odot (\cE(\Delta-\bx))}{2(|\cE(\bx)|+\epsilon)^2}  $$




Since
\begin{align*}
&\cP_{\text{robust}}(\bx_t) - \cP_{\text{robust}}(\bx)\\
=&\bw_t\odot\cE(\bx_t)-\bw\odot\cE(\bx)\\
=&(\bw_t-\bw)\odot\cE(\bx)+\bw\odot(\cE(\bx_t)-\cE(\bx))+(\bw_t-\bw)\odot(\cE(\bx_t)-\cE(\bx))
\end{align*}


Then we have 
\begin{align*}
&IF(\Delta; \cP_{\text{robust}}, \bx)\\
=&\lim_{t\to 0^+} \frac{\cP_{\text{robust}}(\bx_t) - \cP_{\text{robust}}(\bx)}{t}\\
=&\lim_{t\to 0^+} \frac{\bw_t-\bw}{t}\odot\cE(\bx)+\bw\odot\lim_{t\to 0^+}\frac{\cE(\bx_t)-\cE(\bx)}{t}+0\\
=&-\frac{\text{sign} (\cE(\bx))\odot \cE(\Delta-\bx)}{2(|\cE(\bx)|+\epsilon)^2}\odot \cE(\bx) + \bw \odot \cE(\Delta-\bx) \\
=&-\frac{|\cE(\bx)|}{2(|\cE(\bx)|+\epsilon)^2}\odot \cE(\Delta-\bx) + \frac{1}{2(|\cE(\bx)|+\epsilon)} \odot \cE(\Delta-\bx) \\
=&2\epsilon \bw^2 \odot \cE(\Delta-\bx),\\
\end{align*}


and

\begin{align*}
&IF(\Delta; \cP_{\text{elastic}}, \bx)\\
=&\lim_{t\to 0^+} \frac{\cP_{\text{elastic}}(\bx_t) - \cP_{\text{elastic}}(\bx)}{t}\\
=&\beta IF(\Delta; \cP_{\text{vanilla}}, \bx) + (1-\beta) IF(\Delta; \cP_{\text{robust}}, \bx)\\
=&(\beta \mathbf{1} + 2(1-\beta)\epsilon \bw^2) \odot \cE(\Delta-\bx).\\
\end{align*}

    
\end{proof}



\newpage
\section{Related Works}
\label{sec:related_works_app}
\subsection{Adversarial Attacks} 
Adversarial attacks are typically classified into two main categories: \textit{white-box} and \textit{black-box} attacks. In white-box attacks, the attacker has full knowledge of the target neural network, including its architecture, parameters, and gradients. Common examples of white-box attacks include gradient-based methods such as FGSM~\citep{goodfellow2014explaining}, DeepFool~\citep{moosavi2016deepfool}, PGD~\citep{madry2017towards}, and the C\&W attack~\citep{carlini2017towards}. 
In contrast, black-box attacks operate under limited information, where the attacker can only interact with the model through its input-output behavior without direct access to internal details. Examples of black-box methods include surrogate model-based approaches~\citep{papernot2017practical}, zeroth-order optimization techniques~\citep{chen2017zoo}, and query-based methods~\citep{andriushchenko2020square, alzantot2019genattack}.

Here we list the detailed information of attacks we use in the main paper:
\begin{itemize}[left=0.0em]
    \item Fast Gradient Sign Method (FGSM)~\citep{goodfellow2014explaining}: FGSM is one of the earliest and most widely used adversarial attack methods. It generates adversarial examples by using the gradient of the loss function with respect to the input data to craft small but purposeful perturbations that lead the model to make incorrect predictions.
    \item Projected Gradient Descent (PGD)~\citep{madry2017towards}: PGD is an iterative and more robust extension of FGSM. It repeatedly applies small perturbations within a defined range (or epsilon ball) to maximize the model's loss. PGD is often considered a strong adversary in the evaluation of model robustness.
    \item Carlini \& Wagner Attack (C\&W)~\citep{carlini2017towards}: This attack focuses on crafting adversarial examples by optimizing a custom loss function designed to minimize perturbations while ensuring the generated adversarial samples are misclassified.
    \item AutoAttack~\cite{croce2020reliable}: AutoAttack is an ensemble of adversarial attack methods that automatically evaluates the robustness of models. It combines various attacks to provide a strong, reliable benchmark for adversarial robustness without manual tuning.
    \item SparseFool~\cite{modas2019sparsefool}: SparseFool is a sparse adversarial attack designed to generate adversarial examples by perturbing only a few pixels in the input image. It highlights how minimal changes can significantly alter model predictions.
\end{itemize}



\subsection{Adversarial Defenses}


% \textbf{Adversarial Defenses.} 
% \textbf{Adversarial robustness.}
Significant efforts have been devoted to enhancing model robustness through a variety of strategies, including detection techniques~\citep{metzen2017detecting,feinman2017detecting,grosse2017statistical,sehwag2021robust,rade2022reducing,addepalli2022scaling}, purification-based approaches~\citep{ho2022disco,nie2022diffusion,shi2021online,yoon2021adversarial}, robust training methods~\citep{madry2017towards,zhang2019theoretically,gowal2021improving,li2023wat}, and regularization-based techniques~\citep{cisse2017parseval,zheng2016improving}. Among these, adversarial training-based  methods~\citep{sehwag2021robust,rade2022reducing,addepalli2022scaling} have proven highly effective against adaptive adversarial attacks, consistently leading the robustness leaderboard (RobustBench)~\citep{croce2020robustbench}. 
Despite their success, most existing methods rely heavily on extensive synthetic training data generated by advanced models, larger network architectures, and empirically driven training strategies. These dependencies pose substantial challenges to advancing beyond the current plateau in adversarial robustness. 
In this work, we introduce an elastic dictionary framework that incorporates structural priors into model design. This approach is fully orthogonal to existing methods and offers a complementary pathway to further enhance robustness when integrated with current techniques.

Here are we list the detailed information of adversarial training based methods we use in the main paper:
\begin{itemize}[left=0.0em]
    \item PGD-AT~\citep{madry2017towards}: Projected Gradient Descent Adversarial Training (PGD-AT) is a fundamental adversarial training approach that enhances model robustness by iteratively generating adversarial examples using PGD and training the model on them.
    
    \item TRADES~\citep{zhang2019theoretically}: TRADES (Tradeoff-inspired Adversarial Defense via Surrogate Loss Minimization) balances robustness and accuracy by introducing a regularization term that penalizes the discrepancy between natural and adversarial predictions.
    
    \item MART~\citep{wang2019improving}: Misclassification-Aware Adversarial Training (MART) improves robustness by assigning higher weights to misclassified examples, emphasizing correctly classified samples' robustness.
    
    \item SAT~\citep{huang2020self}: Self-Adaptive Training (SAT) refines adversarial training by adjusting the training process based on the model’s confidence, mitigating the effects of incorrect labels and improving generalization.
    
    \item AWP~\citep{wu2020adversarial}: Adversarial Weight Perturbation (AWP) enhances robustness by perturbing model parameters within a constrained space to improve the worst-case performance against adversarial attacks.
    
    \item Consistency~\citep{tack2022consistency}: Consistency training leverages perturbation-invariant representations to enhance robustness by enforcing consistent predictions across different transformations of inputs.
    
    \item DYNAT~\citep{liu2024dynamic}: Dynamic Adversarial Training (DYNAT) adapts training strategies dynamically based on model performance, balancing robustness and generalization efficiency.
    
    \item PORT~\citep{sehwag2021robust}: Proxy Distribution-based Robust Training (PORT) leverages data from proxy distributions, such as those generated by advanced generative models, to enhance adversarial robustness. By formally analyzing robustness transfer and optimizing training, PORT demonstrates significant improvements in robustness under various threat models.
    
    \item HAT~\citep{rade2022reducing}: Helper-based Adversarial Training (HAT) mitigates the accuracy-robustness trade-off by incorporating additional incorrectly labeled examples during training. This approach reduces excessive margin changes along certain adversarial directions, improving accuracy without compromising robustness and achieving a better trade-off compared to existing methods.
\end{itemize}


\subsection{Robust Architectures from Robust Statistics Perspective}
Several studies have explored constructing robust architectures from the perspective of robust statistics. For instance, RUNG~\citep{hou2024robustgraphneuralnetworks} develops robust graph neural networks through unbiased aggregation.
\citet{han2024designing} design robust transformers using robust kernel density estimation. ProTransformer~\citep{hou2024protransformerrobustifytransformersplugandplay} introduces a novel robust attention mechanism with a robust estimator applied to token embeddings. Additionally, \citet{hou2024robustness} propose a universal hybrid architecture inspired by robust statistics, which can be flexibly deployed through robustness reprogramming.


\newpage
\section{Additional Experiments }

\subsection{Preliminary Studies}
\label{sec:pre_study}

\textbf{Preliminary in SDNet18.}
We evaluate Vanilla DL (with both fixed and tuned $\lambda$) under random impulse noise and adaptive PGD adversarial attacks~\cite{madry2017towards}. As illustrated in Figure~\ref{fig:pre_sdnet18_various_lambda}, increasing the noise level and intensifying the distribution tail degradation lead to a decline in Vanilla DL's accuracy. While tuning the sparsity weight $\lambda$ enhances resilience to random noise, models with any $\lambda$ suffer a sharp performance drop under adaptive PGD attacks, with accuracy nearing zero.




\begin{figure}[h!]
    \centering
% \includegraphics[width=0.50\textwidth]{figures/Heavy-tailed_Test.png} 
    % \centering
\includegraphics[width=0.4\textwidth]{figures/impulse_lambda.png}
\caption{Performance of SDNet18 (Vanilla DL) under random Impulse noise with different levels.}
    \label{fig:pre_sdnet18_various_lambda}
\end{figure}


\newpage
\subsection{Adversarial Training Curves}

\subsubsection{Training Curves of Each Method}
\label{sec:training_curves_each_method}

\textbf{Training curve of our Elastic DL.} From  Figure~\ref{fig:adv_train_curve}, we can observe that during the 100th - 150th epochs, the Vanilla DL model exhibits a severe \emph{robust overfitting} phenomenon: while training performance improves, the test robust accuracy drops significantly. After incorporating our Elastic DL structural prior at the 150th epoch, both training and testing robustness improve substantially. Although there is a slight drop in natural performance during the initial switching period, it recovers quickly within a few epochs. This phenomenon highlights the promising potential of the Elastic DL structural prior in breaking through the bottleneck of adversarial robustness and generalization.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/adv_train_curve_v2.png}
    \caption{Adversarial training curve of our Elastic DL.  During the 100th to 150th epochs, the model experiences a catastrophic \emph{robust overfitting} problem. By introducing the Elastic DL structural prior at the 150th epoch and fine-tuning, we effectively mitigate overfitting and achieve significantly improved robustness and generalization.  }
    \label{fig:adv_train_curve}
\end{figure}


\newpage 
\textbf{Training curves of baseline methods.}
We track the training curves of  the baselines including regularization ($\ell_1$, $\ell_2$ regularizations and their combination), Cutout~\cite{devries2017improved}, Mixup~\cite{zhang2017mixup} in Figure~\ref{fig:training_curves_each_method}.



\begin{figure}[h!]
    \centering
    \begin{subfigure}[b]{0.36\textwidth}
        \centering
    \includegraphics[width=\textwidth]{figures/training_curves/curve_resnet10.png} 
        \caption{Vanilla} % 
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.36\textwidth}
        \centering
    \includegraphics[width=\textwidth]{figures/training_curves/curve_resnet10_l1.png} 
        \caption{$\ell_1$-Regularization} % 
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.36\textwidth}
        \centering
\includegraphics[width=\textwidth]{figures/training_curves/curve_resnet10_l2.png} 
        \caption{$\ell_2$-Regularization} % 
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.36\textwidth}
        \centering
    \includegraphics[width=\textwidth]{figures/training_curves/curve_resnet10_l2_l1.png} 
        \caption{$\ell_2$ and $\ell_1$-Regularization} % 
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.36\textwidth}
        \centering
    \includegraphics[width=\textwidth]{figures/training_curves/curve_resnet10_cutout.png} 
        \caption{Cutout} % 
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.36\textwidth}
        \centering
    \includegraphics[width=\textwidth]{figures/training_curves/curve_resnet10_mixup.png} 
        \caption{Mixup} % 
    \end{subfigure}
    % \hfill
    % \begin{subfigure}[b]{0.36\textwidth}
    %     \centering
    % \includegraphics[width=\textwidth]{figures/training_curves/curve_resnet10.png} 
    %     \caption{CIFAR10} % 
    % \end{subfigure}
    % \hfill
    % \begin{subfigure}[b]{0.36\textwidth}
    %     \centering
    % \includegraphics[width=\textwidth]{figures/adv_train_curve.png} 
    %     \caption{CIFAR10} % 
    % \end{subfigure}
    % \hfill


    \caption{Training curves of baselines.} 
    \label{fig:training_curves_each_method}
\end{figure}



\newpage
\subsubsection{Comparison of All Methods}
\label{sec:curves_comparison_all_method}
To make a comparison of all the methods, we compare the natural and robust performance in the training and testing dataset through the training curve in Figure~\ref{fig:comparison_training_curves_all_methods}. The figures show the consisente advantage of our Elastic DL over other methods.



\begin{figure}[h!]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
    \includegraphics[width=\textwidth]{figures/training_curves/curve_resnet10_all_acc_train.png} 
        \caption{Natural (Train)} % 
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
    \includegraphics[width=\textwidth]{figures/training_curves/curve_resnet10_all_adv_acc_train.png} 
        \caption{Robust (Train)} % 
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
    \includegraphics[width=\textwidth]{figures/training_curves/curve_resnet10_all_acc_test.png} 
        \caption{Natural (Test)} % 
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
    \includegraphics[width=\textwidth]{figures/training_curves/curve_resnet10_all_adv_acc_test.png} 
        \caption{Robust (Test)} % 
    \end{subfigure}


    \caption{Comparison of training curves of all methods.} 
    \label{fig:comparison_training_curves_all_methods}
\end{figure}





\newpage
\subsection{Ablation Studies}
\label{sec:ablation_app}


\subsubsection{Universality}
\label{sec:universality}


\textbf{Universality across various backbones, datasets and attacks.}
We conduct ablation studies on different backbones, datasets, and attacks in Table~\ref{tab:diff_backbone_cifar10}, Table~\ref{tab:diff_backbone_cifar100}, and Table~\ref{tab:diff_backbone_imagenet}. Our proposed method shows consistent effectiveness under various settings.

\begin{table}[h!]
\centering
\caption{Adversarial robsustness on CIFAR10 with different backbones.
}

\vspace{0.1in}
\begin{center}
\begin{sc}
\resizebox{0.6\textwidth}{!}{

\begin{tabular}{c|c|ccccccccc}
\toprule
\textbf{Method}
&Natural&PGD&FGSM&C\&W&AA\\
\hline

Vanilla DL + ResNwt10&81.55&45.48 & 52.53 & 45.85 & 41.60\\
Elastic DL + ResNet10  &82.69&49.54 & 64.52 & 57.37 & 46.30\\
\hline
Vanilla DL + ResNwt18&83.28&45.64&53.88&41.22&43.70&\\
Elastic DL + ResNet18  &83.57&53.22&69.35&60.8&52.90 &\\
\hline
Vanilla DL + ResNwt34&82.45&45.37 & 54.32 & 42.12 & 44.40\\
Elastic DL + ResNet34  &82.95&55.88&70.19&61.74&53.80&\\
\hline
Vanilla DL + ResNwt50&81.22&46.83&53.75&43.64&45.10&&\\
Elastic DL + ResNet50  &81.07&58.33&69.38&64.87&56.70&&\\

\bottomrule
\end{tabular}
}

\end{sc}
\end{center}



\label{tab:diff_backbone_cifar10}
\end{table}





\begin{table}[h!]
\centering
\caption{Adversarial robsustness on CIFAR100 with different backbones.
}

\vspace{0.1in}
\begin{center}
\begin{sc}
\resizebox{0.6\textwidth}{!}{

\begin{tabular}{c|c|ccccccccc}
\toprule
\textbf{Method}
&Natural&PGD&FGSM&C\&W&AA\\
\hline
Vanilla DL + ResNwt10&55.94&22.45&26.57&18.9&21.00\\
Elastic DL + ResNet10  &55.20&26.30&35.34&26.45&22.60\\
\hline
Vanilla DL + ResNwt18&57.24&22.17&26.81&17.43&21.60\\
Elastic DL + ResNet18  &57.70&27.27&37.62&28.87&26.30\\
\hline
Vanilla DL + ResNwt34&56.18&21.77&26.14&16.38&20.80\\
Elastic DL + ResNet34  &56.38&32.67&43.39&39.34&29.20\\
\hline
Vanilla DL + ResNwt50&54.01&22.39&26.4&18.4&20.90\\
Elastic DL + ResNet50  &54.64&30.29&41.48&35.24&28.10\\

\bottomrule
\end{tabular}
}

\end{sc}
\end{center}



\label{tab:diff_backbone_cifar100}
\end{table}



 \begin{table}[h!]
\centering
\caption{Adversarial robsustness on Tiny-Imagenet with different backbones.
}

\vspace{0.1in}
\begin{center}
\begin{sc}
\resizebox{0.6\textwidth}{!}{

\begin{tabular}{c|c|ccccccccc}
\toprule
\textbf{Method}
&Natural&PGD&FGSM&C\&W&AA\\
\hline

Vanilla DL + ResNwt10&49.6 & 27.17 & 32.46 & 37.91 & 20.20\\
Elastic DL + ResNet10  &50.12 & 32.93 & 39.64 & 40.10 & 24.90\\
\hline
Vanilla DL + ResNwt18&50.22 & 31.45 & 36.46 & 39.02 & 30.90\\
Elastic DL + ResNet18  &50.52 & 37.6 & 43.1 & 46.64 & 36.30\\
\hline
Vanilla DL + ResNwt34&50.03 & 33.54 & 37.24 & 37.19 & 29.30\\
Elastic DL + ResNet34 &50.40 & 34.8 & 41.75 & 44.72 & 34.60\\
\hline
Vanilla DL + ResNwt50&50.35 & 34.42 & 37.63 & 38.86 & 31.20\\
Elastic DL + ResNet50 &50.39 & 37.38 & 42.06 & 41.09 & 35.40\\

\bottomrule
\end{tabular}
a}

\end{sc}
\end{center}



\label{tab:diff_backbone_imagenet}
\end{table}




% \begin{table}[h!]
% \centering
% \caption{Adversarial robsustness on CIFAR10 with different adversarial training.
% }

% \vspace{0.1in}
% \begin{center}
% \begin{sc}
% \resizebox{0.5\textwidth}{!}{

% \begin{tabular}{l|c|ccccccccc}
% \toprule
% \textbf{Method}
% &Natural&PGD&FGSM&C\&W&AA\\
% \hline

% PGD-AT & 80.90 & 44.35 & 58.41 & 46.72 & 42.14 \\
% +DL&83.28&45.64&53.88&41.22&43.70\\
% +NADL (Ours)  &83.57&53.22&69.35&60.80&52.90 \\
% \hline
% TRADES-2.0&82.80&48.32&51.67&40.65&36.40\\
% +DL&79.05 &40.64&47.12&41.49&34.90\\
% +NADL (Ours) &79.85&49.32&58.68&49.47&47.20\\
% \hline
% TRADES-0.2&85.74&32.63&44.26&26.70&19.00\\
% +DL&82.55 & 25.37&44.48&30.3&15.30\\
% +NADL (Ours) &84.75&33.61&57.86&40.68&28.10\\
% \hline
% HAT&85.95&56.29&61.17&49.52&53.16\\
% +DL&86.42&57.79&62.67&51.61&54.30\\
% +NADL (Ours) &86.84&\textbf{62.48}&\textbf{71.46}&\textbf{59.90}&\textbf{59.07}\\


% \bottomrule
% \end{tabular}
% }

% \end{sc}
% \end{center}



% \label{tab:ablation_diff_adv_train_cifar10}
% \end{table}


\newpage
\subsubsection{Orthogonality to adversarial training.} 
\label{sec:orthogonality}
Our proposed Elastic DL framework incorporates structural priors into neural networks, complementing existing adversarial training techniques. As shown in Table~\ref{tab:cifar10-main} and Figure~\ref{fig:diff_adv_train}, Elastic DL can be integrated with various adversarial training methods (PGD-AT, TRADES-2.0/0.2, HAT) to consistently enhance performance.

    % % Subfigure (a)
    \begin{figure}[h!] % Set the width of the subfigure
    \centering
    \includegraphics[width=0.45\textwidth]{figures/Adversarial_Robustness_Diff_Adv_Train.png} % Replace with your image path
    \caption{Different adversarial training. Our Elastic DL is orthogonal to existing adversarial training methods and can be combined with them to further improve the performance. }
    \label{fig:diff_adv_train}
    \end{figure}



\subsubsection{Different Budget Measurement}
\label{sec:diff_measurement}
In addition to $\ell_\infty$-norm attack (PGD-$\ell_\infty$), we also validate the consistent effectiveness of our Elastic DL with $\ell_2$-norm (PGD-$\ell_2$) and $\ell_1$-norm (SparseFool) attacks in the Figure~\ref{fig:diff_measure} and  Table~\ref{tab:diff_budget_norm}.




% Subfigure (b)
\begin{figure}[h!]
\centering
\includegraphics[width=0.7\textwidth]{figures/diff_norm_budget.png} % Replace with your image path
\caption{Different attack measurements. Our Elastic DL consistently outperforms Vanilla DL across attacks (PGD-$\ell_\infty$, PGD-$\ell_2$, SparseFool) evaluated under various metrics ($\ell_\infty,\ell_2,\ell_0$ norms).}
\label{fig:diff_measure}
\end{figure}   




 \begin{table}[h!]
\centering
\caption{Adversarial robustness on CIFAR10 with different budget measurements.
}

\vspace{0.1in}
\begin{center}
\begin{sc}
\resizebox{0.7\textwidth}{!}{

\begin{tabular}{c|cccccccccc}
\toprule
PGD
$\|\cdot\|_\infty$ $\backslash$ Budget&0&2/255&4/255&8/255&12/255&16/255&32/255\\
\hline
Vanilla DL + ResNwt18&83.29&75.86 & 66.52 & 45.66 & 27.5 & 15.48 & 2.89\\
PGD-AT+ EDL - ResNet18  &83.57&78.76 & 71.01 & 53.29 & 41.1 & 34.13 & 23.84\\
\hline
PGDL2
$\|\cdot\|_2^2$ $\backslash$ Budget&0&0.1&0.5&1.0&2.0&3.0&5.0&\\
\hline
Vanilla DL + ResNwt18&83.29&79.67 & 59.64 & 34.86 & 14.91 & 12.75 & 11.05\\
PGD-AT+ EDL - ResNet18 &83.57 &81.83 & 70.55 & 59.95 & 57.03 & 56.65 & 55.62\\
% \hline
% EADL1
% $\|\cdot\|_1$&\\
% Vanilla DL + ResNwt18&\\
% PGD-AT+ EDL - ResNet18 &\\
\hline
SparseFool
$\|\cdot\|_0$ $\backslash$ lam &0&3&5&7&9&12&15&20\\\hline
Vanilla DL + ResNwt18&83.29&65.83 & 54.11 & 51.12 & 44.63 & 42.14 & 42.89 & 41.39\\
PGD-AT+ EDL - ResNet18&83.57 &66.83 & 55.61 & 55.11 & 51.37&50.87  & 47.38 & 47.13\\

\bottomrule
\end{tabular}
}

\end{sc}
\end{center}



\label{tab:diff_budget_norm}
\end{table}


\newpage
\subsubsection{Hidden Embedding Visualization}
\label{sec:hidden_embedding_all}
We conduct visualization analyses on the hidden embedding to obtain better insight into the effectiveness of our proposed Elastic DL. We begin by quantifying the relative difference between clean embeddings ($\bx$ or $\bz_i$) and attacked embeddings ($\bx'$ or $\bz'_i$) across all layers. As shown 
in Figure~\ref{fig:hidden_embed_visualization_all_part1} and Figure~\ref{fig:hidden_embed_visualization_all_part2}, the presence of adversarial perturbations can disrupt the hidden embedding patterns, leading to incorrect predictions in the case of Vanilla DL. 
In contrast, our Elastic DL appears to lessen the effects of such perturbations and maintain predicting groundtruth label. 

Here are instances of CAT, SHIP, FROG, AUTOMOBILE, and TRUCK:
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/hidden_embeding/hidden_visualization_all_part1_compressed.pdf}
    \caption{Hidden embedding visualization. (Part 1)}
    \label{fig:hidden_embed_visualization_all_part1}
\end{figure}

\newpage
Here are instances of BIRD, HORSE, AIRPLANE, DEER and DOG:

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/hidden_embeding/hidden_visualization_all_part2_compressed.pdf}
    \caption{Hidden embedding visualization. (Part 2)}
    \label{fig:hidden_embed_visualization_all_part2}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \begin{figure}[h!]
%     \centering
%     % Subfigure (a)
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx0_hidden_visualization_resnet.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx0_hidden_visualization_adv_resnet.png}
%         \caption{CAT (Vanilla DL)} % Subfigure caption
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx0_hidden_visualization_L1.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx0_hidden_visualization_adv_L1.png}
%         \caption{CAT (Our EDL)} % Subfigure caption
%     \end{subfigure}
%     \hfill


%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx1_hidden_visualization_resnet.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx1_hidden_visualization_adv_resnet.png}
%         \caption{SHIP (Vanilla DL)} % Subfigure caption
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx1_hidden_visualization_L1.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx1_hidden_visualization_adv_L1.png}
%         \caption{SHIP (Our EDL)} % Subfigure caption
%     \end{subfigure}
%     \hfill


%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx4_hidden_visualization_resnet.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx4_hidden_visualization_adv_resnet.png}
%         \caption{FROG (Vanilla DL)} % Subfigure caption
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx4_hidden_visualization_L1.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx4_hidden_visualization_adv_L1.png}
%         \caption{FROG (Our EDL)} % Subfigure caption
%     \end{subfigure}
%     \hfill


%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=1.03\textwidth]{figures/hidden_embeding/idx6_hidden_visualization_resnet.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx6_hidden_visualization_adv_resnet.png}
%         \caption{AUTOMOBILE (Vanilla DL)} % Subfigure caption
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=1.03\textwidth]{figures/hidden_embeding/idx6_hidden_visualization_L1.png}
%         \includegraphics[width=1.03\textwidth]{figures/hidden_embeding/idx6_hidden_visualization_adv_L1.png}
%         \caption{AUTOMOBILE (Our EDL)} % Subfigure caption
%     \end{subfigure}
%     \hfill


%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx11_hidden_visualization_resnet.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx11_hidden_visualization_adv_resnet.png}
%         \caption{TRUCK (Vanilla DL)} % Subfigure caption
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx11_hidden_visualization_L1.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx11_hidden_visualization_adv_L1.png}
%         \caption{TRUCK (Our EDL)} % Subfigure caption
%     \end{subfigure}
%     \hfill



%     \caption{Hidden embedding visualization (Part 1).} % Main figure caption
%     \label{fig:hidden_embed_visualization_all_part1}
% \end{figure}




% \begin{figure}[h!]
%     \centering
%     % Subfigure (a)
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx65_hidden_visualization_resnet.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx65_hidden_visualization_adv_resnet.png}
%         \caption{BIRD (Vanilla DL)} % Subfigure caption
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx65_hidden_visualization_L1.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx65_hidden_visualization_adv_L1.png}
%         \caption{BIRD (Our EDL)} % Subfigure caption
%     \end{subfigure}
%     \hfill


%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx17_hidden_visualization_resnet.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx17_hidden_visualization_adv_resnet.png}
%         \caption{HORSE (Vanilla DL)} % Subfigure caption
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx17_hidden_visualization_L1.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx17_hidden_visualization_adv_L1.png}
%         \caption{HORSE (Our EDL)} % Subfigure caption
%     \end{subfigure}
%     \hfill


%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=1.02\textwidth]{figures/hidden_embeding/idx21_hidden_visualization_resnet.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx21_hidden_visualization_adv_resnet.png}
%         \caption{AIRPLANE (Vanilla DL)} % Subfigure caption
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=1.02\textwidth]{figures/hidden_embeding/idx21_hidden_visualization_L1.png}
%         \includegraphics[width=1.02\textwidth]{figures/hidden_embeding/idx21_hidden_visualization_adv_L1.png}
%         \caption{AIRPLANE (Our EDL)} % Subfigure caption
%     \end{subfigure}
%     \hfill


%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx26_hidden_visualization_resnet.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx26_hidden_visualization_adv_resnet.png}
%         \caption{DEER (Vanilla DL)} % Subfigure caption
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx26_hidden_visualization_L1.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx26_hidden_visualization_adv_L1.png}
%         \caption{DEER (Our EDL)} % Subfigure caption
%     \end{subfigure}
%     \hfill


%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx39_hidden_visualization_resnet.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx39_hidden_visualization_adv_resnet.png}
%         \caption{DOG (Vanilla DL)} % Subfigure caption
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.48\textwidth} % Set the width of the subfigure
%         \centering
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx39_hidden_visualization_L1.png}
%         \includegraphics[width=\textwidth]{figures/hidden_embeding/idx39_hidden_visualization_adv_L1.png}
%         \caption{DOG (Our EDL)} % Subfigure caption
%     \end{subfigure}
%     \hfill



%     \caption{Hidden embedding visualization (Part 2).} % Main figure caption
%     \label{fig:hidden_embed_visualization_all_part2}
% \end{figure}










\newpage


\subsubsection{Reconstruction Process}
\label{sec:reconstruction_process}


\textbf{Image \& noise reconstruction.} In conventional feedforward neural networks, adding a perturbation $\bepsilon$ to the input can lead the model to make incorrect predictions. However, as illustrated in Figure~\ref{fig:reconstruction_process}, our approach aims to reconstruct both the clean image $\bx$ and the perturbation $\bepsilon$ through a dictionary learning process. To evaluate the effectiveness of our method, we quantify the reconstruction error between the recovered noise $\hat{\bepsilon}$ in our Elastic DL framework and noise generated by various methods (random noise, transfer noise from ResNet/Vanilla DL, and adaptive noise from Elastic DL). As shown in Table~\ref{tab:reconstruction}, the recovered noise from our approach exhibits the smallest difference compared to the adaptive noise in Elastic DL. This result demonstrates that our proposed framework more effectively reconstructs the noise and mitigates its impact on predictions.

\begin{table}[h!]
\centering
\caption{ Reconstruction Error. We quantify the reconstruction error between the recovered noise $\hat{\bepsilon}$ and various input noises, including random noise ($\bepsilon_{\text{random}}$), transfer noise from ResNet ($\bepsilon_{\text{resnet}}$) and Vanilla DL ($\bepsilon_{\text{vanilla}}$), as well as adaptive noise from our Elastic DL ($\bepsilon_{\text{elastic}}$). Our Elastic DL demonstrates the smallest reconstruction error, indicating that our approach can adaptively recover and neutralize the input perturbation, thereby mitigating its impact.
}
\label{tab:reconstruction}

\vspace{0.1in}
\begin{center}
\begin{sc}
\resizebox{0.5\textwidth}{!}{
% \setlength{\tabcolsep}{1.8pt}
\rowcolors{2}{gray!20}{white}
\begin{tabular}{c|c|c|ccccccc}
\hline
\rowcolor[HTML]{C0C0C0}
\textbf{Error} &$\|\cdot\|_1$&$\|\cdot\|_2$&$\|\cdot\|_\infty$ \\\hline
$\bepsilon_{\text{random}}-\hat{\bepsilon}$&1294.75 ± 406.78 & 26.09 ± 7.04 &  0.901 ± 0.10\\\hline
$\bepsilon_{\text{resnet}}-\hat{\bepsilon}$&131.51 ± 10.53 &  2.93 ± 0.22 &  0.163 ± 0.01\\\hline
$\bepsilon_{\text{vanilla}}-\hat{\bepsilon}$& 129.07 ± 13.22 &  2.85 ± 0.26 &  0.157 ± 0.01\\\hline
$\bepsilon_{\text{elastic}}-\hat{\bepsilon}$ &\textbf{122.62 ± 9.92} &  \textbf{2.69 ± 0.22} &  \textbf{0.149 ± 0.01}\\\hline

\end{tabular}

}

\end{sc}
\end{center}

\end{table}



\begin{figure}[h!]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/reconstruction_process.pdf}
    \caption{Reconstruction process. }
    \label{fig:reconstruction_process}
\end{figure}

% \newpage
% Here are instances of reconstruction process in ImageNet:
% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.9\linewidth]{figures/reconstruction/reco_imgnet_all_1.pdf}
%     \caption{Reconstruction process (ImageNet)}
%     \label{fig:reconstruction_process_part1}
% \end{figure}


% \newpage
% Here are instances of reconstruction process in CIFAR10 (Part1):
% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.9\linewidth]{figures/reconstruction/reconstruction_all_1.pdf}
%     \caption{Reconstruction process (CIFAR10, Part 1)}
%     \label{fig:reconstruction_process_part1}
% \end{figure}


% \newpage
% Here are instances of reconstruction process in CIFAR10 (Part2):

% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.9\linewidth]{figures/reconstruction/reconstruction_all_2.pdf}
%     \caption{Reconstruction process (CIFAR10, Part 2)}
%     \label{fig:reconstruction_process_part2}
% \end{figure}
