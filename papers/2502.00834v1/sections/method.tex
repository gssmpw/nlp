
% \begin{figure*}[htbp]
%     \centering
%     \begin{subfigure}[b]{0.62\textwidth} 
%         \centering
%         \includegraphics[width=\textwidth]{figures/overview.pdf} 
%         \caption{} 
%         \label{fig:overall_process} 
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.36\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/dictionary_learning.png} 
%         \caption{} 
%         \label{fig:dictionary_learning} 
%     \end{subfigure}
%     \caption{Overview: (a) During forward propagation, we leverage IRLS-ISTA algorithm to obtain the hidden code; During backpropagation}
%     \label{fig:overview}
% \end{figure*}









% Although some researchers have attempted to address this problem using either sophisticated penalties~\cite{yang2011robust} or error source decomposition~\cite{chen2013robust}, all the aforementioned approaches fall into one or more of the following pitfalls:
% \begin{itemize}
%     \item No one has proposed a layer-wise combination of $\ell_2$ and $\ell_1$ fidelities that accommodates both light-tailed and heavy-tailed noise. Furthermore, performing a grid-based brute-force search to determine the optimal layer-wise combination entails substantial computational complexity of $\mathcal{O}(N^{2L})$, where $N$ is the grid size and $L$ is the number of model layers.
%     \red{consequence, only work on natural noise, not work under adversarial attack, provide some pre study section (not work under adv attacks.), with evidence. 
%     do not mix dictionary learning in convention and deep learning.}
    
%     \red{only talk about deep learning, L2 can only work under natural noise and transfer attack, do not work under adaptive attack, }

%     \red{do not whether can be compatible with adv train, actiual they don't improve with adv train}

%     \red{vanilla only replace one layer to denoise}
    
%     \item 
%     Existing evaluations of robust dictionary learning are quite outdated and typically focus on scenarios involving random occlusions or corruptions. It remains unclear whether these methods can withstand stronger adaptive adversarial attacks (e.g., PGD or AutoAttack).
    
%     \item Most importantly, there remains a significant research gap, as no one has achieved the optimal robustness potential of structure-guided robust dictionary learning, which highlights a great opportunity to make a breakthrough in state-of-the-art robustness via adversarial training.
    

% \end{itemize}








% \subsection{ Tail-Adaptive Learning for Optimal
% Robustness (TAILOR) }
% To address the research gap highlighted in the previous section, we propose a novel tail-adaptive dictionary learning architecture that is highly compatible with adversarial training to achieve state-of-the-art robustness. In this section, we first introduce an elastic dictionary learning objective designed to accommodate both light-tailed and heavy-tailed noise. Then, we present an effective IRLS-ISTA algorithm, which can be unrolled as an TAILOR layer. 









\subsection{Elastic Dictionary Learning}
\label{sec:edl}


From previous section, we can see that it is not trivial to design an optimal dictionary learning framework 
   with  either $\ell_2$ or $\ell_1$ reconstruction alone.
% As both $\ell_2$-based Vanilla DL and $\ell_1$-based Robust DL methods assume one single noise distribution and easily fail under adaptive attack, 
To this end, we propose an elastic dictionary learning (Elastic DL) to achieve
well-balanced trade-off between natural and robust performance:
% capable of accommodating both light-tailed and heavy-tailed noise distributions:
\begin{equation}
\min_\bz \frac{\beta}{2}\|\bx - \cA^*(\bz)\|_2^2 + \frac{1-\beta}{2}\|\bx - \cA^*(\bz)\|_1 + \lambda\|\bz\|_1,
\label{eq:robust_dictionary_learning}
\end{equation}
where $\beta$ is a layer-wise learnable parameter to adaptively balance the two fidelity terms. 
Similarly, we can generalize the RISTA algorithm from Robust DL to Elastic DL as in Appendix~\ref{sec:proof_algo_iteration}. 
The RISTA algorithm for the Elastic DL layer is presented in Algorithm~\ref{alg:irls-ista}, and an overview of the entire EDLNet architecture is shown in Figure~\ref{fig:overview_edlnets}.

% According to Lemma~\ref{lemma:local_upper_bound}, instead of directly solving Eq.~\eqref{eq:robust_dictionary_learning}, we can also 
% alternatively optimize:
% \begin{equation}
% \begin{aligned}
% \bz_{t+1}&=\argmin_\bz  \lambda\|\bz\|_1 + \frac{\beta}{2}\|\bx - \cA^*(\bz)\|_2^2 \\
% &+\frac{1-\beta}{2} \|\bw_t^{1/2} \odot \left(\bx - \cA^*(\bz)\right)\|_2^2 ,
% \label{eq:alternative_objective}
% \end{aligned}
% \end{equation}
% where 
% % $
% % \bw_t_i = \frac{\tilde{\bw}_t_i}{\frac{1}{N}\sum_{i=1}^N \tilde{\bw}_t_i}, \quad \tilde{\bw}_t = \frac{1}{|\bx - \cA^*(\bz_t)|} \in \mathbb{R}^N, \quad N = H \times W \times C.
% % $
% $
% \bw_t =  \frac{1}{2|\bx - \cA^*(\bz_t)|} \in \mathbb{R}^{H \times W \times C}.
% $
% Similarly, we can apply our RISTA algorithm as:
% % optimize the $\ell_1$-regularized problem in Eq.~\eqref{eq:alternative_objective} instead of original Eq.~\eqref{eq:robust_dictionary_learning} by our reweighted iterative  shrinkage thresholding algorithm (RISTA) :
% \begin{equation}
%     \begin{aligned}
%         &\br_t = \left(\beta \mathbf{1} + (1-\beta) \bw_t\right)\odot\left(\bx - \cA^*(\bz_t)\right)\\
%         &\bz_{t+1} = \mathcal{T}_{\lambda t} \left( \bz_t + t \cdot \cA \left(\br_t\right)  \right),
%         \label{eq:algo_iteration}
%     \end{aligned}
% \end{equation}
% where $\mathcal{T}_{\lambda t}(\bz)=\text{sign}(\bz) \left(|\bz-\lambda t|\right)_+$ represents the soft thresholding operator. The detailed derivation of Eq.~\eqref{eq:algo_iteration} is provided in Appendix~\ref{sec:proof_algo_iteration}. The RISTA algorithm for Eq.~\eqref{eq:alternative_objective}, unrolled as a forward layer, is presented in Algorithm~\ref{alg:irls-ista}  and Figure~\ref{fig:edl_layer}.

\begin{algorithm}[h!]
   \caption{RISTA for Elastic DL Layer}
   \label{alg:irls-ista}
\begin{algorithmic}
   \STATE {\bfseries Input:} input signal $\bx$, kernel $\vA$, 
   % \REPEAT
   \STATE Initialize $\bz_0\leftarrow\cA(\bx)$
   \FOR{$t=1$ {\bfseries to} $T-1$}
    % \STATE $\br_t\leftarrow \bx-\cA^*(\bz_t)$
    \STATE $\bw_t\leftarrow\frac{1}{2|\bx-\cA^*(\bz_t)|}$
    % \STATE $\tilde{\bw}_t\leftarrow\frac{1}{|\bx-\cA^*(\bz_t)|}$
    % \STATE $\bw_t_i\leftarrow \frac{\tilde{\bw}_t_i}{\frac{1}{N}\sum_{i=1}^N\tilde{\bw}_t_i}$ for $i=1,...,N$ 
    \STATE $\br_t$ $\leftarrow $ $\left(\beta \mathbf{1} + (1-\beta) \bw_t\right)\odot\left(\bx-\cA^*(\bz_t)\right)$
    \STATE $\bz_{t+1}\leftarrow\mathcal{T}_{\lambda t} \left( \bz_t+t\cdot \cA\left( \br_t\right)\right)$
   \ENDFOR
   % \FOR{$t=1$ {\bfseries to} $T-1$}
   %  \STATE $\bw_t^{(l)}\leftarrow\frac{1}{\left|\bz^{(l)}-\cA^{*(l)}\left(\bz_t^{(l+1)}\right)\right|}$
   %  \STATE $\nabla$ $\leftarrow $ $\cA^{(l)}\left(\left(\beta^{(l)} \mathbf{1} + (1-\beta^{(l)}) \bw_t\right)\odot\left(\bz^{(l)}-\cA^{*(l)}(\bz^{(l+1)}_t)\right)\right)$
   %  \STATE $\bz^{(l+1)}_{t+1}\leftarrow\mathcal{T}_{\lambda t} \left( \bz_t^{(l)}+t\cdot \nabla \right)$
   % \ENDFOR
    \STATE {\bfseries Output:} sparse code $\bz_T$
   % \UNTIL{$noChange$ is $true$}
\end{algorithmic}
\end{algorithm}



% \xr{we have to put the figures back to emphasize this is used in deep learning such as ResNets not just dictionary learning}





% $$\bz=f(\by)=\mathcal{T}_{\lambda t}\left(\by+t\cA\left(\left(\beta \mathbf{1} + (1-\beta) \bw\right)\odot\left(\bx-\cA^*(\by)\right) \right)\right)$$
% $$f(\by)=\bx-\cA^*(\by)$$
% $$g(\by)=\bw\odot(\bx-\cA^*(\by))$$
% $$\bw=\frac{1}{|\bx-\cA^*(\by)|}$$






% \subsection{Adversarial Dictionary Training} 
% To address the aforementioned research gap and make a breakthrough, we propose a novel adverarial dictionary training framework by incorporating our noise-adaptive dictionary learning architecture to adversarial training.
% Consider a  model with $\{\vA^{(l)}\}_{l=0}^{L-1}$ and $\{\beta^{(l)}\}_{l=0}^{L-1}$ in the $L$ NA-CSC layers  and $\vW$ in the classifier. 
% %Then this model can be represented as: $$f(\bx)=f^{(L-1)}_{\vA^{(L-1)},\beta^{(L-1)}}\circ \cdots \circ f^{(l)}_{\vA^{(l)},\beta^{(l)}} \circ \cdots\circ  f^{(1)}_{\vA^{(1)},\beta^{(1)}}(\bx) ,$$
% %where $ f^{(l)}_{\vA^{(l)},\beta^{(l)}} (\bx)$ is the implicit layer as in Algorithm~\ref{alg:irls-ista}. For simplicity, we exclude the notations of the additional modules (e.g., pooling, fully-connected linear layers, etc.). 
% Then, the adversarial dictionary training framework can be formulated as:
% \begin{align*}
%     &\min_{\{\vA^{(l)}, \beta^{(l)}\}_{l=0}^{L-1}}  \mathbb{E}_{(\bx,\by)\sim \cD}\left[ \max_{\bx'\in\cB(\bx)}  \ell(\bz^{*(L)},y)\right]  \\
%     \text{s.t. }& \bz^{*(l+1)} = \argmin_\bz \ell_{NADL}(\bz, \vA^{(l)},\bz^{*(l)}), \\
%     &\ell_{NADL}^{(l)}(\bz,\vA,\bx) \text{ is defined in Eq.~\eqref{eq:robust_dictionary_learning}}, \\
%     &\bz^{*(0)}=\bx',\\
%     &\text{for } l=0,\cdots, L-1.\\
% \end{align*}
% Its overall pipeline can be divided into three main steps as in Figure~\ref{fig:overview}:
% \begin{itemize}
%     \item Step 1 (Attack): leverage adversarial attack  algorithm (e.g., PGD) to generate worst-case perturbation $\bx'$.
%     \item Step 2 (Forward): input $\bx'$ as $\bz^{*(0)}$ into model to obtain a series of  hidden codes for each layer $\{\bz^{(l)}\}_{l=1}^{L}$ by optimizing dictionary learning loss in Eq.~\eqref{eq:robust_dictionary_learning}.
%     \item Step 3 (Backward): update the model parameters including kernel weights $\{\vA^{(l)}\}_{l=0}^{L-1}$, layer-wise balance weight $\{\beta^{(l)}\}_{l=0}^{L-1}$, and other parameters $\vW$.
    
% \end{itemize}





% \textbf{Theoretical robustness analysis.}
\subsection{Theoretical Robustness Analysis}
\label{sec:analysis}

To gain theoretical insight, we conduct a robustness analysis on vanilla, robust, and our elastic dictionary learning using the influence function~\citep{law1986robust}, which measures the sensitivity of an operator to perturbations.
For simplicity, we consider a single-step case for our RISTA algorithm ($T=1$) and focus on the analysis of core part $\br_t$. 
We derive 
their influence functions 
in Theorem~\ref{thm:influence_function} to demonstrate their sensitivity against input perturbations, with a proof presented in Appendix~\ref{sec:proof_influence_function}.     


\begin{theorem}[Robustness Analysis via Influence Function]
\label{thm:influence_function} 

The influence function is defined as the sensitivity of the estimate to a small contamination at $\Delta$:
\[
IF( \Delta ; \cP, \by) = \lim_{t\to 0^+} \frac{\cP(t\Delta + (1-t)\by) - \cP(\by)}{t}.
\]
Let the reconstruction operator is defined as $\cE(\cdot):=(\mathbf{I}-\cA^*\circ\cA)(\cdot)$, then the Vanilla, Robust, and Elastic DL operators are 
 $\cP_{\text{vanilla}}(\bx)=\cE(\bx)$, $\cP_{\text{robust}}(\bx) = \bw\odot\cE(\bx)$, and $\cP_{\text{elastic}}(\bx) =\left(\beta \mathbf{1} + (1-\beta) \bw\right)\odot\cE(\bx)$, where $\bw=\frac{1}{2(|\cE(\bx)|+\epsilon)}$ and $\epsilon$ is set to avoid zero residual values.
Then, we have:
\vspace{-0.1in}
\[
IF(\Delta; \cP_{\text{vanilla}}, \bx) = \cE(\Delta-\bx),
\] 
\[
IF(\Delta; \cP_{\text{robust}}, \bx) = 2\epsilon \bw^2 \odot \cE(\Delta-\bx),
\]
% and 
\[
IF(\Delta; \cP_{\text{elastic}}, \bx) = (\beta \mathbf{1} + 2(1-\beta)\epsilon \bw^2) \odot \cE(\Delta-\bx). \]
\end{theorem}
\begin{proof}
    Please refer to Appendix~\ref{sec:proof_influence_function}.
\end{proof}


Theorem~\ref{thm:influence_function} offers several insights into the robustness of different dictionary learning methods:
\vspace{-0.1in}
\begin{itemize}[left=0.0em] 
\item For Vanilla DL, the influence function is expressed as $\cE(\Delta - \bx)$, indicating that the sensitivity of Vanilla DL is determined by the difference between the noisy sample $\Delta$ and the clean sample $\bx$.
\item For Robust DL, the influence function is given by $2\epsilon \bw^2 \odot \cE(\Delta - \bx)$. The instances with large residuals $|\cE(\bx)|$ are treated as outliers and downweighted by $\bw$. Moreover, while a small $\epsilon$ can significantly reduce overall sensitivity, it may also suppress the impact of input variations,  leading to natural performance degradation.

% While the robustness of Robust DL is still influenced by the difference $\Delta - \bx$, the impact can be significantly mitigated by $\epsilon$. Additionally, instances with large residuals $|\cE(\bx)|$ are treated as outliers and downweighted by $\bw$. However, the influence score becomes highly sensitive to the choice of $\epsilon$, which can result in suboptimal performance in scenarios with light-tailed noise or clean data.

\item 
For Elastic DL, the layerwise parameter $\beta$ can be learned to balance Vanilla and Robust DL, adaptively achieving a better trade-off between natural and robust performance.


% provides the flexibility to balance between the robustness characteristics of Vanilla DL and Robust DL, allowing adaptive control over the trade-off.
\end{itemize}

% These analyses offer valuable insights and a theoretical explanation for the robust nature of the proposed technique.