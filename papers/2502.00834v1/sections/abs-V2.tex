\begin{abstract}



% Adversarial training methods have dominated robustness benchmarks, but they heavily reply on extensive training data, substantial computation resources, and large model backbones while suffering from strong overfitting and a noticeable performance plateau over the years. 

This work investigates a 
novel approach to boost adversarial robustness and generalization by incorporating structural prior into the design of deep learning models.
Specifically, our study surprisingly reveals that existing dictionary learning-inspired convolutional neural networks (CNNs) provide a false sense of security against adversarial attacks. To address this, we propose Elastic Dictionary Learning Networks (EDLNets), a novel ResNet architecture that significantly enhances adversarial robustness and generalization. This novel and effective approach is supported by a theoretical robustness analysis using influence functions. Moreover, extensive and reliable experiments demonstrate consistent and significant performance improvement on open robustness leaderboards such as RobustBench, surpassing state-of-the-art baselines. To the best of our knowledge, this is the first work to discover and validate that structural prior can reliably enhance deep learning robustness under strong adaptive attacks, unveiling a promising direction for future research. 
% Our implementation is available at \url{https://anonymous.4open.science/r/ElasticDL-E9DB}.
% and will be make publicly available.

% To break this stagnation, we advocate an orthogonal and promising avenue by introducing structural priors into neural network design. Specifically, we revisit dictionary learning in deep learning and identify its limitations under light-tailed noise and adaptive attacks. 
% As a countermeasure, we present a novel elastic dictionary learning framework and solve it using an efficient RISTA algorithm, which can be readily integrated into model layer.  
% Our structural prior can effectively mitigate the robust overfitting problem in adversarial training, achieving remarkable robustness and improved generalization. Furthermore, our method
% is complementary to existing adversarial training approaches  and can be integrated with them to achieve state-of-the-art robustness, significantly surpassing top baselines in RobustBench in terms of both natural and robust performance.
% \xr{need to highlight how good our model is in the abstract}

\end{abstract}