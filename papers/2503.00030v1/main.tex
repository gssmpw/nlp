\documentclass{article}



\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}

\usepackage{xcolor}  
\usepackage{colortbl}
% colors
\usepackage{subfigure}
\usepackage{bbm}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{amsmath}
\usepackage{amsthm}

\usepackage{cleveref}
\usepackage{multirow}
\usepackage{bm}
% \usepackage[noend]{algpseudocode}


%%%%% ADDED NEW %%%%%%%%
\usepackage{wrapfig} 
% \usepackage{subcaption}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{innercustomprop}{Proposition}
\newenvironment{customprop}[1]
{\renewcommand\theinnercustomprop{#1}\innercustomprop}{\endinnercustomprop}



\title{Game-Theoretic Regularized Self-Play Alignment of Large Language Models}

%\date{September 9, 1985}	% Here you can change the date presented in the paper title
%\date{} 					% Or removing it

% \author{    {Xiaohang Tang\thanks{Equal contribution. Codebase: \url{https://github.com/xiaohangt/ardt/tree/master}}} 
% \\    University College London
% \\    \texttt{xiaohang.tang.20@ucl.ac.uk} 
% 	%% examples of more authors
% \And {Afonso Marques} 
% \\  University College London 
% \\  \texttt{afonso.marques.22@ucl.ac.uk}
% \And  {Parameswaran Kamalaruban} 
% \\  Featurespace
% \\  \texttt{kamal.parameswaran@featurespace.co.uk}
% \And 
%     {Ilija Bogunovic} \\
% 	 University College London\\
% 	  \texttt{bogunovic.ilija@gmail.com}
	%% \AND
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
% \author{ 
% Xiaohang Tang \\
% University College London \\
% \texttt{xiaohang.tang.20@ucl.ac.uk} \\
% \AND Sangwoong Yoon\\
% University College London \\
% \AND Seongho Son  \\
% University College London \\
% \AND Huizhuo Yuan  \\
% University of California, Los Angeles \\
% \AND Quanquan Gu  \\
% University of California, Los Angeles \\
% \AND Ilija Bogunovic  \\
% University College London \\
% \texttt{i.bogunovic@ucl.ac.uk}
% }
% \author{Xiaohang Tang$^{*{\dagger}}$ 
% \And Sangwoong Yoon$^{* \text{\S}}$
% \And Seongho Son$^{\P}$
% \And Huizhuo Yuan$^{\clubsuit}$
% \And Quanquan Gu$^{\spadesuit}$ 
% \And Ilija Bogunovic$^{\diamondsuit}$
% }

\author{ Xiaohang Tang$^*$ \\
 University College London \\ \texttt{xiaohang.tang.20@ucl.ac.uk} 
\\	%% examples of more authors
\And {Sangwoong Yoon\thanks{Equal Contribution}} \\
University College London  \\
\texttt{sangwoong.yoon@ucl.ac.uk} 
\\
\And  {Seongho Son}
\\  University College London \\ \texttt{seong.son.22@ucl.ac.uk}
\And  {Huizhuo Yuan} 
\\  University of California, Los Angeles \\
\texttt{hzyuan@cs.ucla.edu}
\And  {Quanquan Gu} 
\\  University of California, Los Angeles \\
\texttt{qgu@cs.ucla.edu}
\And {Ilija Bogunovic} 
\\ University College London \\ \texttt{i.bogunovic@ucl.ac.uk}
}




% Uncomment to remove the date
\date{}

% Uncomment to override  the `A preprint' in the header
%\renewcommand{\headeright}{Technical Report}
\renewcommand{\undertitle}{}
\renewcommand{\shorttitle}{Regularized Self-Play Policy Optimization}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={A template for the arxiv style},
pdfsubject={q-bio.NC, q-bio.QM},
pdfauthor={Xiaohang Tang, Afonso Marques, Parameswaran Kamalaruban, Ilija Bogunovic},
}

\begin{document}
\maketitle

% \author{Xiaohang Tang$^{*{\dagger}}$ 
% \And Sangwoong Yoon$^{* \text{\S}}$
% \And Seongho Son$^{\P}$
% \And Huizhuo Yuan$^{\clubsuit}$
% \And Quanquan Gu$^{\spadesuit}$ 
% \And Ilija Bogunovic$^{\diamondsuit}$
% }



% \footnotetext{
%     $^*$Equal Contribution  \\
%     $^\dagger$Department of Statistical Science, University College London \& UCL Centre for AI;  \texttt{xiaohang.tang.20@ucl.ac.uk} \\
%     $^\S$Department of Electronic and Electrical Engineering, University College London \& UCL Centre for AI;  \texttt{sangwoong.yoon@ucl.ac.uk} \\
%     $^\P$Department of Computer Science, University College London \& UCL Centre for AI; \texttt{seong.son.22@ucl.ac.uk}  \\
%     $^\clubsuit$Department of Computer Science, University of California, Los Angeles;  \texttt{hzyuan@cs.ucla.edu}
%     \\
%     $^\spadesuit$Department of Computer Science,   University of California, Los Angeles;  \texttt{qgu@cs.ucla.edu}
%     \\
%     $^\diamondsuit$Department of Electronic and Electrical Engineering, University College London \& UCL Centre for AI;  \texttt{i.bogunovic@ucl.ac.uk}

% }

\begin{abstract}
Self-play alignment algorithms have been developed as effective methods for fine-tuning large language models (LLMs), formulating preference optimization as a two-player game. However, the regularization with respect to the reference policy, which is crucial for mitigating over-optimization, has been insufficiently investigated in self-play alignment. In this paper, we show that our regularization method can improve the unregularized self-play significantly. To study the impact of different regularizations in self-play alignment, we propose Regularized Self-Play Policy Optimization (RSPO). This generalized framework regularizes the self-play by simply adding a chosen regularization term into the loss while maintaining provable last-iterate convergence to the Nash Equilibrium of the corresponding regularized game. Surprisingly, empirical evaluations using the Mistral-7B-Instruct base model reveal that forward KL divergence regularization reduces response length in RSPO, whereas reverse KL divergence markedly improves raw win rates. RSPO with a linear combination of forward and reverse KL divergence regularization substantially increases the length-controlled win rate in AlpacaEval-2, elevating the unregularized self-play alignment method (SPPO) from $28.53\%$ to $35.44\%$. Finally, we show that RSPO also improves the response diversity.
\end{abstract}

\input{introduction}


\input{background}


\input{framework}


\input{algorithm}

\input{experiment}


\bibliographystyle{unsrtnat}
\bibliography{ref}  %%% Uncomment this line and comment out the ``thebibliography'' section below to use the external .bib file (using bibtex) .


\input{appendix}

%%% Uncomment this section and comment out the \bibliography{references} line above to use inline references.
% \begin{thebibliography}{1}

% 	\bibitem{kour2014real}
% 	George Kour and Raid Saabne.
% 	\newblock Real-time segmentation of on-line handwritten arabic script.
% 	\newblock In {\em Frontiers in Handwriting Recognition (ICFHR), 2014 14th
% 			International Conference on}, pages 417--422. IEEE, 2014.

% 	\bibitem{kour2014fast}
% 	George Kour and Raid Saabne.
% 	\newblock Fast classification of handwritten on-line arabic characters.
% 	\newblock In {\em Soft Computing and Pattern Recognition (SoCPaR), 2014 6th
% 			International Conference of}, pages 312--318. IEEE, 2014.

% 	\bibitem{hadash2018estimate}
% 	Guy Hadash, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour, and Alon
% 	Jacovi.
% 	\newblock Estimate and replace: A novel approach to integrating deep neural
% 	networks with existing applications.
% 	\newblock {\em arXiv preprint arXiv:1804.09028}, 2018.

% \end{thebibliography}


\end{document}
