@misc{narayanan_kapoor_2023_ai_safety,
  author       = {Narayanan, Arvind and Kapoor, Sayash},
  title        = {AI Safety is Not a Model Property},
  howpublished = {\url{https://www.aisnakeoil.com/p/ai-safety-is-not-a-model-property}},
  month        = aug,
  year         = {2023},
  note         = {Accessed: 2024-12-10}
}

@article{tufekci2015algorithmic,
  title={Algorithmic harms beyond Facebook and Google: Emergent challenges of computational agency},
  author={Tufekci, Zeynep},
  journal={Colo. Tech. LJ},
  volume={13},
  pages={203},
  year={2015},
  publisher={HeinOnline}
}

@inproceedings{bellini2023paying,
  title={Paying the price: When intimate partners use technology for financial harm},
  author={Bellini, Rosanna},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--17},
  year={2023}
}



@article{marconi2024challenges,
  title={The Challenges and Promises of Artifcial Intelligence in the Contemporary Society: A Critical Perspective},
  author={Marconi, L and Cabitza, F and others},
  journal={URBANIANA UNIVERSITY JOURNAL},
  volume={2},
  pages={83--104},
  year={2024}
}

@MISC{ReutersUnknown-lu,
  title        = {Thomson Reuters Risk \& Fraud Solutions for financial
                  institutions},
  author       = {{Reuters}},
  journaltitle = {Reuters},
  abstract     = {Confirm information across different areas of your business
                  through one solution with CLEAR, a public record technology
                  tool},
  urldate      = {2024-08-15},
  language     = {en}
}

@MISC{De-Vynck2024-ua,
  title        = {Duolingo cuts workers as it relies more on {AI}},
  author       = {De Vynck, Gerrit},
  journaltitle = {The Washington Post},
  publisher    = {The Washington Post},
  date         = {2024-01-10},
  abstract     = {Former contract workers at the language app say they were cut
                  as the company uses more AI tools to create lessons.},
  urldate      = {2024-09-12}
}

@VIDEO{USATODAY_Duolingo,
  title     = {Duolingo lays off workers as it leans into {AI} integration},
  publisher = {USA TODAY},
  date      = {2024-04-05},
  abstract  = {Language-learning giant Duolingo announced a 10\% reduction in
               contractors as it integrates artificial intelligence into its
               operations.},
  urldate   = {2024-08-29}
}

@ONLINE{Team-Duolingo2023-bs,
  title     ={Introducing Duolingo Max, a learning experience powered by
               {GPT}-4},
  author    = {{Team Duolingo}},
  booktitle = {Duolingo Blog},
  date      = {2023-03-14},
  abstract  = {Duolingo's newest subscription, Duolingo Max, offers a powerful
               AI-backed learning experience.},
  urldate   = {2024-08-14},
  language  = {en}
}

@article{jackson2014rethinking,
  title={Rethinking repair},
  author={Jackson, Steven J},
  year={2014}
}



@misc{Merken2023-pz,
	title = {New {York} lawyers sanctioned for using fake {ChatGPT} cases in legal brief {\textbar} {Reuters}},
        author={Merken, Sara},
	url = {https://www.reuters.com/legal/new-york-lawyers-sanctioned-using-fake-chatgpt-cases-legal-brief-2023-06-22/},
	urldate = {2025-02-14},
        month={June},
        year={2023},
	file = {New York lawyers sanctioned for using fake ChatGPT cases in legal brief | Reuters:files/5323/new-york-lawyers-sanctioned-using-fake-chatgpt-cases-legal-brief-2023-06-22.html:text/html},
}


@article{saxena2021framework,
  title={A framework of high-stakes algorithmic decision-making for the public sector developed through a case study of child-welfare},
  author={Saxena, Devansh and Badillo-Urquiola, Karla and Wisniewski, Pamela J and Guha, Shion},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={5},
  number={CSCW2},
  pages={1--41},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{de2020case,
  title={A case for humans-in-the-loop: Decisions in the presence of erroneous algorithmic scores},
  author={De-Arteaga, Maria and Fogliato, Riccardo and Chouldechova, Alexandra},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2020}
}

@incollection{schaffner2016parallel,
  title={Parallel texts in translation},
  author={Sch{\"a}ffner, Christina},
  booktitle={Unity in diversity},
  pages={83--90},
  year={2016},
  publisher={Routledge}
}

@article{AIAAIC_pedestrian,
  title={Pedestrian following Google Maps hit by motorcyclist},
  author={AI, Algorithmic, and Automation Incidents and Controversies (AIAAIC) database},
  journal={https://shorturl.at/bL6NC},
  volume={},
  pages={},
  year={2009},
  publisher={}
}

@article{AIAAIC_driver,
  title={US man dies driving off collapsed bridge while following Google Maps},
  author={AI, Algorithmic, and Automation Incidents and Controversies (AIAAIC) database},
  journal={https://shorturl.at/7peNd},
  volume={},
  pages={},
  year={2022},
  publisher={}
}

@article{leal2024algorithms,
  title={Algorithms, Creditworthiness, and Lending Decisions Check for updates},
  author={Leal, Ana Alves},
  journal={Legal Aspects of Autonomous Systems: A Comparative Approach},
  volume={4},
  pages={321},
  year={2024},
  publisher={Springer Nature}
}

@article{brown2023hiring,
  title={Hiring Discrimination by Algorithm: A New Frontier for Civil Rights and Labor Law.},
  author={Brown, Lydia XZ},
  journal={Human Rights},
  volume={49},
  number={1-2},
  pages={16--16},
  year={2023},
  publisher={HeinOnline}
}

@article{rezende2020facial,
  title={Facial recognition in police hands: Assessing the ‘Clearview case’from a European perspective},
  author={Rezende, Isadora Neroni},
  journal={New Journal of European Criminal Law},
  volume={11},
  number={3},
  pages={375--389},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{kleinberg2018human,
  title={Human decisions and machine predictions},
  author={Kleinberg, Jon and Lakkaraju, Himabindu and Leskovec, Jure and Ludwig, Jens and Mullainathan, Sendhil},
  journal={The quarterly journal of economics},
  volume={133},
  number={1},
  pages={237--293},
  year={2018},
  publisher={Oxford University Press}
}

@article{ludwig2021fragile,
  title={Fragile algorithms and fallible decision-makers: lessons from the justice system},
  author={Ludwig, Jens and Mullainathan, Sendhil},
  journal={Journal of Economic Perspectives},
  volume={35},
  number={4},
  pages={71--96},
  year={2021},
  publisher={American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203-2418}
}

@article{crawford_2017,
  title={The trouble with bias},
  author={Crawford, Kate},
  journal={In Conference on Neural Information Processing Systems (NeurIPS)},
  year={2017}
}

@article{epic_report_2023,
  title={Outsourced and Automated: How AI Companies Have Taken Over Government Decision-Making},
  author={Fergusson, Grant},
  journal={EPIC.ORG},
  year={2023},
  publisher={IElectronic Privacy Information Center}
}

@article{davis2016ai,
  title={AI amusements: the tragic tale of Tay the chatbot},
  author={Davis, Ernest},
  journal={AI Matters},
  volume={2},
  number={4},
  pages={20--24},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@article{rudin2020age,
  title={The age of secrecy and unfairness in recidivism prediction},
  author={Rudin, Cynthia and Wang, Caroline and Coker, Beau},
  journal={Harvard Data Science Review},
  volume={2},
  number={1},
  pages={1},
  year={2020}
}

@article{parasuraman2000model,
  title={A model for types and levels of human interaction with automation},
  author={Parasuraman, Raja and Sheridan, Thomas B and Wickens, Christopher D},
  journal={IEEE Transactions on systems, man, and cybernetics-Part A: Systems and Humans},
  volume={30},
  number={3},
  pages={286--297},
  year={2000},
  publisher={IEEE}
}

@article{lai2021towards,
  title={Towards a science of human-ai decision making: a survey of empirical studies},
  author={Lai, Vivian and Chen, Chacha and Liao, Q Vera and Smith-Renner, Alison and Tan, Chenhao},
  journal={arXiv preprint arXiv:2112.11471},
  year={2021}
}

@article{hager2024evaluation,
  title={Evaluation and mitigation of the limitations of large language models in clinical decision-making},
  author={Hager, Paul and Jungmann, Friederike and Holland, Robbie and Bhagat, Kunal and Hubrecht, Inga and Knauer, Manuel and Vielhauer, Jakob and Makowski, Marcus and Braren, Rickmer and Kaissis, Georgios and others},
  journal={Nature medicine},
  pages={1--10},
  year={2024},
  publisher={Nature Publishing Group US New York}
}

@inproceedings{zimmerman2007research,
  title={Research through design as a method for interaction design research in HCI},
  author={Zimmerman, John and Forlizzi, Jodi and Evenson, Shelley},
  booktitle={Proceedings of the SIGCHI conference on Human factors in computing systems},
  pages={493--502},
  year={2007}
}

@inproceedings{yang2019unremarkable,
  title={Unremarkable AI: Fitting intelligent decision support into critical, clinical decision-making processes},
  author={Yang, Qian and Steinfeld, Aaron and Zimmerman, John},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--11},
  year={2019}
}

@inproceedings{shen2022model,
  title={The model card authoring toolkit: Toward community-centered, deliberation-driven AI design},
  author={Shen, Hong and Wang, Leijie and Deng, Wesley H and Brusse, Ciell and Velgersdijk, Ronald and Zhu, Haiyi},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={440--451},
  year={2022}
}

@inproceedings{suresh2022towards,
  title={Towards intersectional feminist and participatory ML: A case study in supporting Feminicide Counterdata Collection},
  author={Suresh, Harini and Movva, Rajiv and Dogan, Amelia Lee and Bhargava, Rahul and Crux{\^e}n, Isadora and Cuba, {\'A}ngeles Martinez and Taurino, Guilia and So, Wonyoung and D'Ignazio, Catherine},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={667--678},
  year={2022}
}

@inproceedings{klumbyte2022critical,
  title={Critical tools for machine learning: Working with intersectional critical concepts in machine learning systems design},
  author={Klumbyt{\.e}, Goda and Draude, Claude and Taylor, Alex S},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1528--1541},
  year={2022}
}

@inproceedings{blodgett2022responsible,
  title={Responsible language technologies: Foreseeing and mitigating harms},
  author={Blodgett, Su Lin and Liao, Q Vera and Olteanu, Alexandra and Mihalcea, Rada and Muller, Michael and Scheuerman, Morgan Klaus and Tan, Chenhao and Yang, Qian},
  booktitle={CHI Conference on Human Factors in Computing Systems Extended Abstracts},
  pages={1--3},
  year={2022}
}

@article{blodgett2020language,
  title={Language (technology) is power: A critical survey of" bias" in nlp},
  author={Blodgett, Su Lin and Barocas, Solon and Daum{\'e} III, Hal and Wallach, Hanna},
  journal={arXiv preprint arXiv:2005.14050},
  year={2020}
}

@inproceedings{lee2024don,
  title={“I Don’t Know If We’re Doing Good. I Don’t Know If We’re Doing Bad”: Investigating How Practitioners Scope, Motivate, and Conduct Privacy Work When Developing AI Products},
  author={Lee, Hao-Ping Hank and Gao, Lan and Yang, Stephanie and Forlizzi, Jodi and Das, Sauvik},
  booktitle={Proceeding of the 33rd USENIX Security Symposium},
  year={2024}
}

@inproceedings{deng2023understanding,
  title={Understanding Practices, Challenges, and Opportunities for User-Engaged Algorithm Auditing in Industry Practice},
  author={Deng, Wesley Hanwen and Guo, Boyuan and Devrio, Alicia and Shen, Hong and Eslami, Motahhare and Holstein, Kenneth},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--18},
  year={2023}
}

@article{wong2023seeing,
  title={Seeing like a toolkit: How toolkits envision the work of AI ethics},
  author={Wong, Richmond Y and Madaio, Michael A and Merrill, Nick},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={7},
  number={CSCW1},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@book{buxton2010sketching,
  title={Sketching user experiences: getting the design right and the right design},
  author={Buxton, Bill},
  year={2010},
  publisher={Morgan kaufmann}
}

@article{boyarskaya2020overcoming,
  title={Overcoming failures of imagination in AI infused system development and deployment},
  author={Boyarskaya, Margarita and Olteanu, Alexandra and Crawford, Kate},
  journal={arXiv preprint arXiv:2011.13416},
  year={2020}
}

@inproceedings{laufer2022four,
  title={Four years of FAccT: A reflexive, mixed-methods analysis of research contributions, shortcomings, and future prospects},
  author={Laufer, Benjamin and Jain, Sameer and Cooper, A Feder and Kleinberg, Jon and Heidari, Hoda},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={401--426},
  year={2022}
}

@inproceedings{lupetti2024making,
  title={(Un) making AI Magic: A Design Taxonomy},
  author={Lupetti, Maria Luce and Murray-Rust, Dave},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--21},
  year={2024}
}

@inproceedings{jansen2023mix,
  title={Mix \& Match Machine Learning: An Ideation Toolkit to Design Machine Learning-Enabled Solutions},
  author={Jansen, Anniek and Colombo, Sara},
  booktitle={Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction},
  pages={1--18},
  year={2023}
}

@inproceedings{fiebrink2010wekinator,
  title={The Wekinator: a system for real-time, interactive machine learning in music},
  author={Fiebrink, Rebecca and Cook, Perry R},
  booktitle={Proceedings of The Eleventh International Society for Music Information Retrieval Conference (ISMIR 2010)(Utrecht)},
  volume={3},
  pages={2--1},
  year={2010},
  organization={Citeseer}
}

@inproceedings{benjamin2021machine,
  title={Machine learning uncertainty as a design material: A post-phenomenological inquiry},
  author={Benjamin, Jesse Josua and Berger, Arne and Merrill, Nick and Pierce, James},
  booktitle={Proceedings of the 2021 CHI conference on human factors in computing systems},
  pages={1--14},
  year={2021}
}

@inproceedings{yildirim2022experienced,
  title={How experienced designers of enterprise applications engage AI as a design material},
  author={Yildirim, Nur and Kass, Alex and Tung, Teresa and Upton, Connor and Costello, Donnacha and Giusti, Robert and Lacin, Sinem and Lovic, Sara and O'Neill, James M and Meehan, Rudi O'Reilly and others},
  booktitle={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2022}
}

@inproceedings{hope2017accelerating,
  title={Accelerating innovation through analogy mining},
  author={Hope, Tom and Chan, Joel and Kittur, Aniket and Shahaf, Dafna},
  booktitle={Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={235--243},
  year={2017}
}

@article{kittur2019scaling,
  title={Scaling up analogical innovation with crowds and AI},
  author={Kittur, Aniket and Yu, Lixiu and Hope, Tom and Chan, Joel and Lifshitz-Assaf, Hila and Gilon, Karni and Ng, Felicia and Kraut, Robert E and Shahaf, Dafna},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={6},
  pages={1870--1877},
  year={2019},
  publisher={National Acad Sciences}
}

@article{kang2022augmenting,
  title={Augmenting scientific creativity with an analogical search engine},
  author={Kang, Hyeonsu B and Qian, Xin and Hope, Tom and Shahaf, Dafna and Chan, Joel and Kittur, Aniket},
  journal={ACM Transactions on Computer-Human Interaction},
  volume={29},
  number={6},
  pages={1--36},
  year={2022},
  publisher={ACM New York, NY}
}

@article{holmquist2017intelligence,
  title={Intelligence on tap: artificial intelligence as a new design material},
  author={Holmquist, Lars Erik},
  journal={interactions},
  volume={24},
  number={4},
  pages={28--33},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@inproceedings{dove2017ux,
  title={UX design innovation: Challenges for working with machine learning as a design material},
  author={Dove, Graham and Halskov, Kim and Forlizzi, Jodi and Zimmerman, John},
  booktitle={Proceedings of the 2017 chi conference on human factors in computing systems},
  pages={278--288},
  year={2017}
}


@inproceedings{barocas2017problem,
  title={The problem with bias: Allocative versus representational harms in machine learning},
  author={Barocas, Solon and Crawford, Kate and Shapiro, Aaron and Wallach, Hanna},
  booktitle={9th Annual conference of the special interest group for computing, information and society},
  pages={1},
  year={2017},
  organization={New York, NY}
}

@inproceedings{wang2022measuring,
  title={Measuring representational harms in image captioning},
  author={Wang, Angelina and Barocas, Solon and Laird, Kristen and Wallach, Hanna},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={324--335},
  year={2022}
}

@inproceedings{kallus2018residual,
  title={Residual unfairness in fair machine learning from prejudiced data},
  author={Kallus, Nathan and Zhou, Angela},
  booktitle={International Conference on Machine Learning},
  pages={2439--2448},
  year={2018},
  organization={PMLR}
}

@inproceedings{dutta2020there,
  title={Is there a trade-off between fairness and accuracy? a perspective using mismatched hypothesis testing},
  author={Dutta, Sanghamitra and Wei, Dennis and Yueksel, Hazar and Chen, Pin-Yu and Liu, Sijia and Varshney, Kush},
  booktitle={International conference on machine learning},
  pages={2803--2813},
  year={2020},
  organization={PMLR}
}

@book{weiner2022ai,
  title={Why AI/data science projects fail: how to avoid project pitfalls},
  author={Weiner, Joyce},
  year={2022},
  publisher={Springer Nature}
}

@inproceedings{yildirim2023creating,
  title={Creating design resources to scaffold the ideation of AI concepts},
  author={Yildirim, Nur and Oh, Changhoon and Sayar, Deniz and Brand, Kayla and Challa, Supritha and Turri, Violet and Crosby Walton, Nina and Wong, Anna Elise and Forlizzi, Jodi and McCann, James and others},
  booktitle={Proceedings of the 2023 ACM Designing Interactive Systems Conference},
  pages={2326--2346},
  year={2023}
}

@inproceedings{selbst2019fairness,
  title={Fairness and abstraction in sociotechnical systems},
  author={Selbst, Andrew D and Boyd, Danah and Friedler, Sorelle A and Venkatasubramanian, Suresh and Vertesi, Janet},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={59--68},
  year={2019}
}

@inproceedings{wang2023designing,
  title={Designing responsible ai: Adaptations of ux practice to meet responsible ai challenges},
  author={Wang, Qiaosi and Madaio, Michael and Kane, Shaun and Kapania, Shivani and Terry, Michael and Wilcox, Lauren},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2023}
}

@INPROCEEDINGS{Raji2022-ls,
  title     = "The Fallacy of {AI} Functionality",
  author    = "Raji, Inioluwa Deborah and Kumar, I Elizabeth and Horowitz, Aaron
               and Selbst, Andrew",
  booktitle = "2022 ACM Conference on Fairness, Accountability, and Transparency",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "959--972",
  month     =  jun,
  year      =  2022
}

@INPROCEEDINGS{Stapleton2022-eb,
  title     = "Imagining new futures beyond predictive systems in child welfare:
               A qualitative study with impacted stakeholders",
  author    = "Stapleton, Logan and Lee, Min Hun and Qing, Diana and Wright,
               Marya and Chouldechova, Alexandra and Holstein, Ken and Wu,
               Zhiwei Steven and Zhu, Haiyi",
  booktitle = "2022 ACM Conference on Fairness, Accountability, and Transparency",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1162--1177",
  series    = "Discussion Paper Series 85",
  month     =  jun,
  year      =  2022
}

@INPROCEEDINGS{Holten-Moller2020-fe,
  title     = "Shifting Concepts of Value: Designing Algorithmic
               Decision-Support Systems for Public Services",
  author    = "Holten Møller, Naja and Shklovski, Irina and Hildebrandt, Thomas
               T",
  booktitle = "Proceedings of the 11th Nordic Conference on Human-Computer
               Interaction: Shaping Experiences, Shaping Society",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1--12",
  month     =  oct,
  year      =  2020
}

@INPROCEEDINGS{Moon2024-si,
  title     = "A Human-Centered Review of Algorithms in Homelessness Research",
  author    = "Moon, Erina Seh-Young and Guha, Shion",
  booktitle = "Proceedings of the CHI Conference on Human Factors in Computing
               Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1--15",
  month     =  may,
  year      =  2024
}

@INPROCEEDINGS{Saxena2020-qh,
  title     = "A Human-Centered Review of Algorithms used within the {U}.{S}.
               Child Welfare System",
  author    = "Saxena, Devansh and Badillo-Urquiola, Karla and Wisniewski,
               Pamela J and Guha, Shion",
  booktitle = "Proceedings of the 2020 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1--15",
  month     =  apr,
  year      =  2020
}

@ARTICLE{Razi2022-gz,
  title     = "A Human-Centered Approach to Improving Adolescent Online Sexual
               Risk Detection Algorithms",
  author    = "Razi, Afsaneh",
  publisher = "stars.library.ucf.edu",
  abstract  = "Computational risk detection has the potential to protect
               especially vulnerable populations from online victimization.
               Conducting a comprehensive literature review on computational
               approaches for online sexual risk detection led to the
               identification that the majority of this work has focused on
               identifying sexual predators after-the-fact. Also, many studies
               rely on public datasets and third-party annotators to establish
               ground truth and train their algorithms, which do not accurately
               represent young social media users and their perspectives to
               prevent victimization. To address these gaps, this dissertation
               integrated human-centered approaches to both creating
               representative datasets and developing sexual risk detection
               machine learning models to ensure the broader societal impacts of
               this important work. In order to understand what and how
               adolescents talk about their online sexual interactions to inform
               study designs, a thematic content analysis of posts by
               adolescents on an online peer support mental health was
               conducted. Then, a user study and web-based platform, Instagram
               Data Donation (IGDD), was designed to create an ecologically
               valid dataset. Youth could donate and annotate their Instagram
               data for online risks. After participating in the study, an
               interview study was conducted to understand how youth felt
               annotating data for online risks. Based on private conversations
               annotated by participants, sexual risk detection classifiers were
               created. The results indicated Convolutional Neural Network (CNN)
               and Random Forest models outperformed in identifying sexual risks
               at the conversation-level. Our experiments showed that
               classifiers trained on entire conversations performed better than
               message-level classifiers. We also trained classifiers to detect
               the severity risk level of a given message with CNN outperforming
               other models. We found that contextual (eg, age, gender, and
               relationship type) and psycho-linguistic features contributed the
               most to accurately detecting sexual conversations. Our analysis
               provides insights into the important factors that enhance
               automated detection of sexual risks within youths' private
               conversations.",
  year      =  2022
}

@ARTICLE{Kittur2019-eu,
  title     = "Scaling up analogical innovation with crowds and {AI}",
  author    = "Kittur, Aniket and Yu, Lixiu and Hope, Tom and Chan, Joel and
               Lifshitz-Assaf, Hila and Gilon, Karni and Ng, Felicia and Kraut,
               Robert E and Shahaf, Dafna",
  journal   = "Proc. Natl. Acad. Sci. U. S. A.",
  publisher = "Proceedings of the National Academy of Sciences",
  volume    =  116,
  number    =  6,
  pages     = "1870--1877",
  abstract  = "Analogy-the ability to find and apply deep structural patterns
               across domains-has been fundamental to human innovation in
               science and technology. Today there is a growing opportunity to
               accelerate innovation by moving analogy out of a single person's
               mind and distributing it across many information processors, both
               human and machine. Doing so has the potential to overcome
               cognitive fixation, scale to large idea repositories, and support
               complex problems with multiple constraints. Here we lay out a
               perspective on the future of scalable analogical innovation and
               first steps using crowds and artificial intelligence (AI) to
               augment creativity that quantitatively demonstrate the promise of
               the approach, as well as core challenges critical to realizing
               this vision.",
  month     =  feb,
  year      =  2019,
  keywords  = "AI; analogy; crowdsourcing; innovation; machine learning",
  language  = "en"
}

@INPROCEEDINGS{Yu2014-pr,
  title     = "Distributed analogical idea generation: inventing with crowds",
  author    = "Yu, Lixiu and Kittur, Aniket and Kraut, Robert E",
  booktitle = "Proceedings of the SIGCHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  apr,
  year      =  2014,
  language  = "en"
}

@INPROCEEDINGS{Hope2017-np,
  title     = "Accelerating innovation through analogy mining",
  author    = "Hope, Tom and Chan, Joel and Kittur, Aniket and Shahaf, Dafna",
  booktitle = "Proceedings of the 23rd ACM SIGKDD International Conference on
               Knowledge Discovery and Data Mining",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  aug,
  year      =  2017
}

@BOOK{Meehl1954-ee,
  title     = "Clinical versus statistical prediction: A theoretical analysis
               and a review of the evidence",
  author    = "Meehl, Paul E",
  publisher = "University of Minnesota Press",
  address   = "Minneapolis",
  abstract  = "This monograph is an expansion of lectures given in the years
               1947-1950 to graduate colloquia at the universities of Chicago,
               Iowa, and Wisconsin, and of a lecture series delivered to staff
               and trainees at the Veterans Administration Mental Hygiene Clinic
               at Ft. Snelling, Minnesota. Perhaps a general remark in
               clarification of my own position is in order. Students in my
               class in clinical psychology have often reacted to the lectures
               on this topic as to a protective technique, complaining that I
               was biased either for or against statistics (or the clinician),
               depending mainly on where the student himself stood! This I have,
               of course, found very reassuring. One clinical student suggested
               that I tally the pro-con ratio for the list of honorific and
               derogatory adjectives in Chapter 1 (page 4), and the reader will
               discover that this unedited sample of my verbal behavior puts my
               bias squarely at the midline. The style and sequence of the paper
               reflect my own ambivalence and real puzzlement, and I have
               deliberately left the document in this discursive form to retain
               the flavor of the mental conflict that besets most of us who do
               clinical work but try to be scientists. I have read and heard too
               many rapid-fire, once-over-lightly ``resolutions'' of this
               controversy to aim at contributing another such. The thing is
               just not that simple. I was therefore not surprised to discover
               that the same sections which one reader finds obvious and
               over-elaborated, another singles out as especially useful for his
               particular difficulties. My thesis in a nutshell: ``There is no
               convincing reason to assume that explicitly formalized
               mathematical rules and the clinician's creativity are equally
               suited for any given kind of task, or that their comparative
               effectiveness is the same for different tasks. Current clinical
               practice should be much more critically examined with this in
               mind than it has been.'' (PsycInfo Database Record (c) 2022 APA,
               all rights reserved)",
  year      =  1954
}

@ARTICLE{AEgisdottir2006-op,
  title     = "The meta-analysis of clinical judgment project: Fifty-six years
               of accumulated research on clinical versus statistical prediction",
  author    = "Ægisdóttir, Stefanía and White, Michael J and Spengler, Paul M
               and Maugherman, Alan S and Anderson, Linda A and Cook, Robert S
               and Nichols, Cassandra N and Lampropoulos, Georgios K and Walker,
               Blain S and Cohen, Genna and Rush, Jeffrey D",
  journal   = "Couns. Psychol.",
  publisher = "SAGE Publications",
  volume    =  34,
  number    =  3,
  pages     = "341--382",
  abstract  = "Clinical predictions made by mental health practitioners are
               compared with those using statistical approaches. Sixty-seven
               studies were identified from a comprehensive search of 56 years
               of research; 92 effect sizes were derived from these studies. The
               overall effect of clinical versus statistical prediction showed a
               somewhat greater accuracy for statistical methods. The most
               stringent sample of studies, from which 48 effect sizes were
               extracted, indicated a 13\% increase in accuracy using
               statistical versus clinical methods. Several variables influenced
               this overall effect. Clinical and statistical prediction accuracy
               varied by type of prediction, the setting in which predictor data
               were gathered, the type of statistical formula used, and the
               amount of information available to the clinicians and the
               formulas. Recommendations are provided about when and under what
               conditions counseling psychologists might use statistical
               formulas as well as when they can rely on clinical methods.
               Implications for clinical judgment research and training are
               discussed.",
  month     =  may,
  year      =  2006,
  language  = "en"
}

@ARTICLE{Dawes1989-um,
  title     = "Clinical versus actuarial judgment",
  author    = "Dawes, R M and Faust, D and Meehl, P E",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science (AAAS)",
  volume    =  243,
  number    =  4899,
  pages     = "1668--1674",
  abstract  = "Professionals are frequently consulted to diagnose and predict
               human behavior; optimal treatment and planning often hinge on the
               consultant's judgmental accuracy. The consultant may rely on one
               of two contrasting approaches to decision-making--the clinical
               and actuarial methods. Research comparing these two approaches
               shows the actuarial method to be superior. Factors underlying the
               greater accuracy of actuarial methods, sources of resistance to
               the scientific findings, and the benefits of increased reliance
               on actuarial approaches are discussed.",
  month     =  mar,
  year      =  1989,
  language  = "en"
}

@ARTICLE{Grove2000-ym,
  title     = "Clinical versus mechanical prediction: A meta-analysis",
  author    = "Grove, William M and Zald, David H and Lebow, Boyd S and Snitz,
               Beth E and Nelson, Chad",
  journal   = "Psychol. Assess.",
  publisher = "American Psychological Association (APA)",
  volume    =  12,
  number    =  1,
  pages     = "19--30",
  abstract  = "The process of making judgments and decisions requires a method
               for combining data. To compare the accuracy of clinical and
               mechanical (formal, statistical) data-combination techniques, we
               performed a meta-analysis on studies of human health and
               behavior. On average, mechanical-prediction techniques were about
               10\% more accurate than clinical predictions. Depending on the
               specific analysis, mechanical prediction substantially
               outperformed clinical prediction in 33\%–47\% of studies
               examined. Although clinical predictions were often as accurate as
               mechanical predictions, in only a few studies (6\%–16\%) were
               they substantially more accurate. Superiority for
               mechanical-prediction techniques was consistent, regardless of
               the judgment task, type of judges, judges' amounts of experience,
               or the types of data being combined. Clinical predictions
               performed relatively less well when predictors included clinical
               interview data. These data indicate that mechanical predictions
               of human behaviors are equal or superior to clinical prediction
               methods for a wide range of circumstances. (PsycINFO Database
               Record (c) 2016 APA, all rights reserved)",
  year      =  2000,
  language  = "en"
}

@ARTICLE{Shanks2024-bt,
  title    = "Enhancing clinical documentation workflow with ambient artificial
              intelligence: Clinician perspectives on work burden, burnout, and
              job satisfaction",
  author   = "Shanks, Denton and Shah, Tina and Hudson, Taina and Thompson,
              Jeffrey and Filardi, Tanya and Wright, Kelli and Ator, Greg and
              Smith, Timothy Ryan and Albrecht, Michael",
  journal  = "bioRxiv",
  abstract = "ABSTRACTObjectiveThis study assessed the effects of an ambient
              artificial intelligence (AI) documentation platform on clinicians’
              perceptions of documentation workflow.Materials and MethodsA pre-
              and post-implementation survey evaluated ambulatory clinician
              perceptions on impact of Abridge, an ambient AI documentation
              platform. Outcomes included clinical documentation burden, work
              after-hours, clinician burnout, work satisfaction, and patient
              access. Data were analyzed using descriptive statistics and
              proportional odds logistic regression to compare changes for
              concordant questions across pre- and post-surveys. Covariate
              analysis examined effect of specialty type and duration of use of
              the AI tool.ResultsSurvey response rates were 51.1\% (94/181)
              pre-implementation and 75.9\% (101/133) post-implementation.
              Clinician perception of ease of documentation workflow (OR = 6.91,
              95\% CI: 3.90 to 12.56, pDiscussionClinician experience and
              efficiency was dramatically improved with use of Abridge across a
              breadth of specialties.ConclusionAn ambient AI documentation
              platform had tremendous impact on improving clinician experience
              within a short time frame. Future studies should utilize validated
              instruments for clinician efficiency and burnout and compare
              impact across AI platforms.",
  month    =  aug,
  year     =  2024
}

@ARTICLE{Elisco2024-bu,
  title     = "Natural Language Processing Unlocks the {DatainCase} Notes",
  author    = "Elisco, M",
  journal   = "Children's Voice Magazine",
  publisher = "go.gale.com",
  volume    =  33,
  number    =  1,
  pages     = "22--24",
  year      =  2024
}

@INPROCEEDINGS{Wallat2024-nw,
  title     = "Temporal blind spots in large language models",
  author    = "Wallat, Jonas and Jatowt, Adam and Anand, Avishek",
  booktitle = "Proceedings of the 17th ACM International Conference on Web
               Search and Data Mining",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  mar,
  year      =  2024
}

@MISC{Unknown2024-uk,
  title     = "Duolingo lays off workers as it leans into {AI} integration",
  publisher = "USA TODAY",
  abstract  = "Language-learning giant Duolingo announced a 10\% reduction in
               contractors as it integrates artificial intelligence into its
               operations.",
  month     =  apr,
  year      =  2024
}

@ARTICLE{Bommasani2021-rl,
  title         = "On the opportunities and risks of foundation models",
  author        = "Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and
                   Altman, Russ and Arora, Simran and von Arx, Sydney and
                   Bernstein, Michael S and Bohg, Jeannette and Bosselut,
                   Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch,
                   Shyamal and Card, Dallas and Castellon, Rodrigo and
                   Chatterji, Niladri and Chen, Annie and Creel, Kathleen and
                   Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and
                   Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and
                   Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and
                   Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and
                   Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha,
                   Neel and Hashimoto, Tatsunori and Henderson, Peter and
                   Hewitt, John and Ho, Daniel E and Hong, Jenny and Hsu, Kyle
                   and Huang, Jing and Icard, Thomas and Jain, Saahil and
                   Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti,
                   Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab,
                   Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay
                   and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal
                   and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent,
                   Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu
                   and Malik, Ali and Manning, Christopher D and Mirchandani,
                   Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj
                   and Narayan, Avanika and Narayanan, Deepak and Newman, Ben
                   and Nie, Allen and Niebles, Juan Carlos and Nilforoshan,
                   Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and
                   Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris
                   and Portelance, Eva and Potts, Christopher and Raghunathan,
                   Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and
                   Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré,
                   Christopher and Sadigh, Dorsa and Sagawa, Shiori and
                   Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and
                   Tamkin, Alex and Taori, Rohan and Thomas, Armin W and Tramèr,
                   Florian and Wang, Rose E and Wang, William and Wu, Bohan and
                   Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga,
                   Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang,
                   Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui
                   and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy",
  journal       = "arXiv [cs.LG]",
  abstract      = "AI is undergoing a paradigm shift with the rise of models
                   (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at
                   scale and are adaptable to a wide range of downstream tasks.
                   We call these models foundation models to underscore their
                   critically central yet incomplete character. This report
                   provides a thorough account of the opportunities and risks of
                   foundation models, ranging from their capabilities (e.g.,
                   language, vision, robotics, reasoning, human interaction) and
                   technical principles(e.g., model architectures, training
                   procedures, data, systems, security, evaluation, theory) to
                   their applications (e.g., law, healthcare, education) and
                   societal impact (e.g., inequity, misuse, economic and
                   environmental impact, legal and ethical considerations).
                   Though foundation models are based on standard deep learning
                   and transfer learning, their scale results in new emergent
                   capabilities,and their effectiveness across so many tasks
                   incentivizes homogenization. Homogenization provides powerful
                   leverage but demands caution, as the defects of the
                   foundation model are inherited by all the adapted models
                   downstream. Despite the impending widespread deployment of
                   foundation models, we currently lack a clear understanding of
                   how they work, when they fail, and what they are even capable
                   of due to their emergent properties. To tackle these
                   questions, we believe much of the critical research on
                   foundation models will require deep interdisciplinary
                   collaboration commensurate with their fundamentally
                   sociotechnical nature.",
  month         =  aug,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@INPROCEEDINGS{Smith-Renner2020-um,
  title     = "No explainability without accountability: An empirical study of
               explanations and feedback in interactive {ML}",
  author    = "Smith-Renner, Alison and Fan, Ron and Birchfield, Melissa and Wu,
               Tongshuang and Boyd-Graber, Jordan and Weld, Daniel S and
               Findlater, Leah",
  booktitle = "Proceedings of the 2020 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  apr,
  year      =  2020
}

@ARTICLE{Ehsan2024-zv,
  title     = "Explainability pitfalls: Beyond dark patterns in explainable {AI}",
  author    = "Ehsan, Upol and Riedl, Mark O",
  journal   = "Patterns (N. Y.)",
  publisher = "Elsevier BV",
  volume    =  5,
  number    =  6,
  pages     =  100971,
  abstract  = "To make explainable artificial intelligence (XAI) systems
               trustworthy, understanding harmful effects is important. In this
               paper, we address an important yet unarticulated type of negative
               effect in XAI. We introduce explainability pitfalls (EPs),
               unanticipated negative downstream effects from AI explanations
               manifesting even when there is no intention to manipulate users.
               EPs are different from dark patterns, which are intentionally
               deceptive practices. We articulate the concept of EPs by
               demarcating it from dark patterns and highlighting the challenges
               arising from uncertainties around pitfalls. We situate and
               operationalize the concept using a case study that showcases how,
               despite best intentions, unsuspecting negative effects, such as
               unwarranted trust in numerical explanations, can emerge. We
               propose proactive and preventative strategies to address EPs at
               three interconnected levels: research, design, and
               organizational. We discuss design and societal implications
               around reframing AI adoption, recalibrating stakeholder
               empowerment, and resisting the ``move fast and break things''
               mindset.",
  month     =  jun,
  year      =  2024,
  language  = "en"
}

@INPROCEEDINGS{Cooper2021-ft,
  title     = "Emergent Unfairness in Algorithmic Fairness-Accuracy Trade-Off
               Research",
  author    = "Cooper, A Feder and Abrams, Ellen and Na, N A",
  booktitle = "Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and
               Society",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "46--54",
  month     =  jul,
  year      =  2021
}

@ARTICLE{Nahar2021-dg,
  title         = "Collaboration challenges in building {ML}-enabled systems:
                   Communication, documentation, engineering, and process",
  author        = "Nahar, Nadia and Zhou, Shurui and Lewis, Grace and Kästner,
                   Christian",
  journal       = "arXiv [cs.SE]",
  abstract      = "The introduction of machine learning (ML) components in
                   software projects has created the need for software engineers
                   to collaborate with data scientists and other specialists.
                   While collaboration can always be challenging, ML introduces
                   additional challenges with its exploratory model development
                   process, additional skills and knowledge needed, difficulties
                   testing ML systems, need for continuous evolution and
                   monitoring, and non-traditional quality requirements such as
                   fairness and explainability. Through interviews with 45
                   practitioners from 28 organizations, we identified key
                   collaboration challenges that teams face when building and
                   deploying ML systems into production. We report on common
                   collaboration points in the development of production ML
                   systems for requirements, data, and integration, as well as
                   corresponding team patterns and challenges. We find that most
                   of these challenges center around communication,
                   documentation, engineering, and process and collect
                   recommendations to address these challenges.",
  month         =  oct,
  year          =  2021,
  archivePrefix = "arXiv",
  primaryClass  = "cs.SE"
}

@ARTICLE{Passi2018-cl,
  title     = "Trust in data science: Collaboration, translation, and
               accountability in corporate data science projects",
  author    = "Passi, Samir and Jackson, Steven J",
  journal   = "Proc. ACM Hum. Comput. Interact.",
  publisher = "Association for Computing Machinery (ACM)",
  volume    =  2,
  number    = "CSCW",
  pages     = "1--28",
  abstract  = "The trustworthiness of data science systems in applied and
               real-world settings emerges from the resolution of specific
               tensions through situated, pragmatic, and ongoing forms of work.
               Drawing on research in CSCW, critical data studies, and history
               and sociology of science, and six months of immersive
               ethnographic fieldwork with a corporate data science team, we
               describe four common tensions in applied data science work:
               (un)equivocal numbers, (counter)intuitive knowledge, (in)credible
               data, and (in)scrutable models. We show how organizational actors
               establish and re-negotiate trust under messy and uncertain
               analytic conditions through practices of skepticism, assessment,
               and credibility. Highlighting the collaborative and heterogeneous
               nature of real-world data science, we show how the management of
               trust in applied corporate data science settings depends not only
               on pre-processing and quantification, but also on negotiation and
               translation. We conclude by discussing the implications of our
               findings for data science research and practice, both within and
               beyond CSCW.",
  month     =  nov,
  year      =  2018,
  language  = "en"
}

@ARTICLE{Kross2021-fb,
  title     = "Orienting, framing, bridging, magic, and counseling: How data
               scientists navigate the outer loop of client collaborations in
               industry and academia",
  author    = "Kross, Sean and Guo, Philip",
  journal   = "Proc. ACM Hum. Comput. Interact.",
  publisher = "Association for Computing Machinery (ACM)",
  volume    =  5,
  number    = "CSCW2",
  pages     = "1--28",
  abstract  = "Data scientists often collaborate with clients to analyze data to
               meet a client's needs. What does the end-to-end workflow of a
               data scientist's collaboration with clients look like throughout
               the lifetime of a project? To investigate this question, we
               interviewed ten data scientists (5 female, 4 male, 1 non-binary)
               in diverse roles across industry and academia. We discovered that
               they work with clients in a six-stage outer-loop workflow, which
               involves 1) laying groundwork by building trust before a project
               begins, 2) orienting to the constraints of the client's
               environment, 3) collaboratively framing the problem, 4) bridging
               the gap between data science and domain expertise, 5) the inner
               loop of technical data analysis work, 6) counseling to help
               clients emotionally cope with analysis results. This novel
               outer-loop workflow contributes to CSCW by expanding the notion
               of what collaboration means in data science beyond the
               widely-known inner-loop technical workflow stages of acquiring,
               cleaning, analyzing, modeling, and visualizing data. We conclude
               by discussing the implications of our findings for data science
               education, parallels to design work, and unmet needs for tool
               development.",
  month     =  oct,
  year      =  2021,
  language  = "en"
}

@ARTICLE{P-PirolliUnknown-zs,
  title  = "The sensemaking process and leverage points for analyst technology
            as identified through cognitive task analysis",
  author = "P Pirolli, S Card"
}

@ARTICLE{Cabrera2022-ng,
  title     = "What did my {AI} learn? How data scientists make sense of model
               behavior",
  author    = "Cabrera, Ángel Alexander and Ribeiro, Marco Tulio and Lee,
               Bongshin and DeLine, Rob and Perer, Adam and Drucker, Steven M",
  journal   = "ACM Trans. Comput. Hum. Interact.",
  publisher = "Association for Computing Machinery (ACM)",
  abstract  = "Data scientists require rich mental models of how AI systems
               behave to effectively train, debug, and work with them. Despite
               the prevalence of AI analysis tools, there is no general theory
               describing how people make sense of what their models have
               learned. We frame this process as a form of sensemaking and
               derive a framework describing how data scientists develop mental
               models of AI behavior. To evaluate the framework, we show how
               existing AI analysis tools fit into this sensemaking process and
               use it to design AIFinnity , a system for analyzing
               image-and-text models. Lastly, we explored how data scientists
               use a tool developed with the framework through a think-aloud
               study with 10 data scientists tasked with using AIFinnity to pick
               an image captioning model. We found that AIFinnity ’s sensemaking
               workflow reflected participants’ mental processes and enabled
               them to discover and validate diverse AI behaviors.",
  month     =  jun,
  year      =  2022,
  language  = "en"
}

@INPROCEEDINGS{Kim2016-zl,
  title     = "The emerging role of data scientists on software development
               teams",
  author    = "Kim, Miryung and Zimmermann, Thomas and DeLine, Robert and Begel,
               Andrew",
  booktitle = "Proceedings of the 38th International Conference on Software
               Engineering",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "96--107",
  month     =  may,
  year      =  2016
}

@ARTICLE{Zhang2020-ru,
  title         = "How do data science workers collaborate? Roles, workflows,
                   and tools",
  author        = "Zhang, Amy X and Muller, Michael and Wang, Dakuo",
  journal       = "arXiv [cs.HC]",
  abstract      = "Today, the prominence of data science within organizations
                   has given rise to teams of data science workers collaborating
                   on extracting insights from data, as opposed to individual
                   data scientists working alone. However, we still lack a deep
                   understanding of how data science workers collaborate in
                   practice. In this work, we conducted an online survey with
                   183 participants who work in various aspects of data science.
                   We focused on their reported interactions with each other
                   (e.g., managers with engineers) and with different tools
                   (e.g., Jupyter Notebook). We found that data science teams
                   are extremely collaborative and work with a variety of
                   stakeholders and tools during the six common steps of a data
                   science workflow (e.g., clean data and train model). We also
                   found that the collaborative practices workers employ, such
                   as documentation, vary according to the kinds of tools they
                   use. Based on these findings, we discuss design implications
                   for supporting data science team collaborations and future
                   research directions.",
  month         =  jan,
  year          =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.HC"
}

@ARTICLE{UnknownUnknown-ax,
  title    = "Thomson Reuters Risk \& Fraud Solutions for financial institutions",
  journal  = "Reuters",
  abstract = "Confirm information across different areas of your business
              through one solution with CLEAR, a public record technology tool",
  language = "en"
}

@ARTICLE{UnknownUnknown-ly,
  title    = "Improve fraud detection and prevention with Fraud Detect",
  journal  = "Reuters",
  abstract = "Fraud Detect from Thomson Reuters uses state-of-the-art software
              to provide in-depth analytics to help you identify potential
              fraud.",
  language = "en"
}

@ARTICLE{UnknownUnknown-su,
  title    = "Risk \& fraud",
  journal  = "Reuters",
  abstract = "Discover our risk and fraud solutions built for corporations and
              government agencies.",
  language = "en"
}

@MISC{Ujlaki2024-ok,
  title        = "How To Watch The Star Wars Movies and Shows in Order",
  author       = "Ujlaki, Olivia",
  booktitle    = "Wishes \& Wayfinding",
  abstract     = "Find the best way to watch the Star Wars movies and series in
                  order, including chronological, release, and machete.",
  month        =  jul,
  year         =  2024,
  howpublished = "\url{https://www.wishesandwayfinding.com/post/how-to-watch-star-wars-movies-in-order}",
  note         = "Accessed: 2024-8-14",
  language     = "en"
}

@ARTICLE{Xu2024-jq,
  title         = "Knowledge conflicts for {LLMs}: A survey",
  author        = "Xu, Rongwu and Qi, Zehan and Guo, Zhijiang and Wang, Cunxiang
                   and Wang, Hongru and Zhang, Yue and Xu, Wei",
  journal       = "arXiv [cs.CL]",
  abstract      = "This survey provides an in-depth analysis of knowledge
                   conflicts for large language models (LLMs), highlighting the
                   complex challenges they encounter when blending contextual
                   and parametric knowledge. Our focus is on three categories of
                   knowledge conflicts: context-memory, inter-context, and
                   intra-memory conflict. These conflicts can significantly
                   impact the trustworthiness and performance of LLMs,
                   especially in real-world applications where noise and
                   misinformation are common. By categorizing these conflicts,
                   exploring the causes, examining the behaviors of LLMs under
                   such conflicts, and reviewing available solutions, this
                   survey aims to shed light on strategies for improving the
                   robustness of LLMs, thereby serving as a valuable resource
                   for advancing research in this evolving area.",
  month         =  mar,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@MISC{Unknown2023-ej,
  title        = "Introducing Duolingo Max, a learning experience powered by
                  {GPT}-4",
  booktitle    = "Duolingo Blog",
  abstract     = "Duolingo's newest subscription, Duolingo Max, offers a
                  powerful AI-backed learning experience.",
  month        =  mar,
  year         =  2023,
  howpublished = "\url{https://blog.duolingo.com/duolingo-max/}",
  note         = "Accessed: 2024-8-14",
  language     = "en"
}

@MISC{Bicknell2020-it,
  title        = "Learning how to help you learn: Introducing Birdbrain!",
  author       = "Bicknell, Klinton",
  booktitle    = "Duolingo Blog",
  abstract     = "What makes a great teacher, versus simply a good teacher?
                  Well, a good teacher knows the material well so that they can
                  explain it to you. But a great teacher also knows what you
                  know, so that they can teach you exactly what you need to know
                  next. Personalizing your",
  month        =  oct,
  year         =  2020,
  howpublished = "\url{https://blog.duolingo.com/learning-how-to-help-you-learn-introducing-birdbrain/}",
  note         = "Accessed: 2024-8-14",
  language     = "en"
}

@MISC{Henry2023-vm,
  title        = "How Duolingo uses {AI} to create lessons faster",
  author       = "Henry, Parker",
  booktitle    = "Duolingo Blog",
  abstract     = "Artificial intelligence allows Duolingo learning experts to
                  create new lessons faster than ever. Here's how the humans
                  behind the lessons use new technology to improve the app.",
  month        =  jun,
  year         =  2023,
  howpublished = "\url{https://blog.duolingo.com/large-language-model-duolingo-lessons/}",
  note         = "Accessed: 2024-8-14",
  language     = "en"
}

@MISC{VaithianathanUnknown-nl,
  title        = "Implementing the Hello Baby Prevention Program in Allegheny
                  County",
  author       = "Vaithianathan, Rhema and Putnam-Hornstein, Emily and
                  Benavides-Prad, Diana",
  howpublished = "\url{https://www.alleghenycountyanalytics.us/wp-content/uploads/2020/12/Hello-Baby-Methodology-v6.pdf\#page=2.29}"
}

@MISC{PonderaUnknown-db,
  title  = "\textit{FraudCaster Master Design Document for Department of Human
            Services District of Columbia}",
  author = "Pondera, Thomson Reuters"
}

@INPROCEEDINGS{Lee2024-rc,
  title     = "Deepfakes, phrenology, surveillance, and more! A taxonomy of {AI}
               privacy risks",
  author    = "Lee, Hao-Ping (hank) and Yang, Yu-Ju and Von Davier, Thomas
               Serban and Forlizzi, Jodi and Das, Sauvik",
  booktitle = "Proceedings of the CHI Conference on Human Factors in Computing
               Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  volume    =  79,
  pages     = "1--19",
  month     =  may,
  year      =  2024
}

@MISC{Narayanan2024-dt,
  title        = "{AI} safety is not a model property",
  author       = "Narayanan, Arvind and Kapoor, Sayash",
  booktitle    = "AI Snake Oil",
  abstract     = "Trying to make an AI model that can’t be misused is like
                  trying to make a computer that can’t be used for bad things",
  month        =  mar,
  year         =  2024,
  howpublished = "\url{https://www.aisnakeoil.com/p/ai-safety-is-not-a-model-property}",
  note         = "Accessed: 2024-8-13",
  language     = "en"
}

@MISC{Rao2022-ad,
  title        = "The Dutch Tax Authority Was Felled by {AI—What} Comes Next?",
  author       = "Rao, Rahul",
  booktitle    = "IEEE Spectrum",
  abstract     = "European regulation hopes to rein in ill-behaving algorithms",
  month        =  may,
  year         =  2022,
  howpublished = "\url{https://spectrum.ieee.org/artificial-intelligence-in-government}",
  note         = "Accessed: 2024-8-12",
  language     = "en"
}

@MISC{Heikkila2022-dx,
  title        = "Dutch scandal serves as a warning for Europe over risks of
                  using algorithms",
  author       = "Heikkilä, Melissa",
  booktitle    = "POLITICO",
  abstract     = "The Dutch tax authority ruined thousands of lives after using
                  an algorithm to spot suspected benefits fraud — and critics
                  say there is little stopping it from happening again.",
  month        =  mar,
  year         =  2022,
  howpublished = "\url{https://www.politico.eu/article/dutch-scandal-serves-as-a-warning-for-europe-over-risks-of-using-algorithms/}",
  note         = "Accessed: 2024-8-12",
  language     = "en"
}

@ARTICLE{UnknownUnknown-hy,
  title = "Complaint and Request for Investigation, Injunction, and Other Relief
           Submitted by The Electronic Privacy Information Center ({EPIC})"
}

@MISC{Quinlan2024-iy,
  title        = "Nonprofit behind {FTC} complaint about automated
                  fraud-detection software hopes for more responsible {AI} use",
  author       = "Quinlan, Keely",
  booktitle    = "StateScoop",
  abstract     = "Grant Fergusson, an author of a recent Federal Trade
                  Commission complaint against Thomson Reuters, urged
                  governments to be careful about which information they provide
                  to powerful AI algorithms.",
  month        =  jan,
  year         =  2024,
  howpublished = "\url{http://statescoop.com/nonprofit-ftc-complaint-automated-benefits-responsible-ai/}",
  note         = "Accessed: 2024-8-12",
  language     = "en"
}

@ARTICLE{UnknownUnknown-ji,
  title    = "What does Thomson Reuters do?",
  journal  = "Reuters",
  abstract = "Thomson Reuters provides trusted data and information to
              professionals across 4 different industries: financial \& risk;
              legal; tax and accounting; and media. Here are some examples of
              how we impact each of these industries.",
  language = "en"
}

@MISC{Christian2023-ap,
  title        = "Magazine Publishes Serious Errors in First {AI}-Generated
                  Health Article",
  author       = "Christian, Jon",
  booktitle    = "Futurism",
  abstract     = "The owners of Sports Illustrated and Men’s Journal promised to
                  be virtuous with AI. Then they bungled their very first AI
                  story.",
  month        =  feb,
  year         =  2023,
  howpublished = "\url{https://futurism.com/neoscope/magazine-mens-journal-errors-ai-health-article}",
  note         = "Accessed: 2024-8-11",
  language     = "en"
}

@MISC{Sato2023-bm,
  title        = "{CNET} is overhauling its {AI} policy and updating past
                  stories",
  author       = "Sato, Mia",
  booktitle    = "The Verge",
  abstract     = "CNET is clarifying its policy around how AI tools are used in
                  the newsroom. The policy comes months after the outlet came
                  under fire for quietly using AI tools to produce stories.",
  month        =  jun,
  year         =  2023,
  howpublished = "\url{https://www.theverge.com/2023/6/6/23750761/cnet-ai-generated-stories-policy-update}",
  note         = "Accessed: 2024-8-11",
  language     = "en"
}

@MISC{Ho2022-jj,
  title        = "An algorithm that screens for child neglect raises concerns",
  author       = "Ho, Sally and Burke, Garance",
  booktitle    = "AP News",
  abstract     = "Inside a cavernous stone fortress in downtown Pittsburgh,
                  attorney Robin Frank defends parents at one of their lowest
                  points – when they risk losing their children.",
  month        =  apr,
  year         =  2022,
  howpublished = "\url{https://apnews.com/article/child-welfare-algorithm-investigation-9497ee937e0053ad4144a86c68241ef1}",
  note         = "Accessed: 2024-8-8",
  language     = "en"
}

@MISC{Ho2023-wy,
  title        = "Child welfare algorithm faces Justice Department scrutiny",
  author       = "Ho, Sally and Burke, Garance",
  booktitle    = "AP News",
  abstract     = "PITTSBURGH (AP) — The Justice Department has been scrutinizing
                  a controversial artificial intelligence tool used by a
                  Pittsburgh-area child protective services agency following
                  concerns that the tool could lead to discrimination against
                  families with disabilities, The Associated Press has learned.",
  month        =  feb,
  year         =  2023,
  howpublished = "\url{https://apnews.com/article/justice-scrutinizes-pittsburgh-child-welfare-ai-tool-4f61f45bfc3245fd2556e886c2da988b}",
  note         = "Accessed: 2024-8-8",
  language     = "en"
}

@ARTICLE{VaithianathanUnknown-ci,
  title  = "Developing predictive models to support child maltreatment hotline
            screening decisions: Allegheny County methodology and implementation",
  author = "Vaithianathan, {R and Putnam-Hornstein, E and Jiang, N and Maloney},
            T"
}

@BOOK{Glantz2014-zr,
  title     = "Multi-asset risk modeling: Techniques for a global economy in an
               electronic and algorithmic trading era",
  author    = "Glantz, Morton and Kissell, Robert",
  publisher = "Academic Press",
  abstract  = "Multi-Asset Risk Modeling describes, in a single volume, the
               latest and most advanced risk modeling techniques for equities,
               debt, fixed income, futures and derivatives, commodities, and
               foreign exchange, as well as advanced algorithmic and electronic
               risk management. Beginning with the fundamentals of risk
               mathematics and quantitative risk analysis, the book moves on to
               discuss the laws in standard models that contributed to the 2008
               financial crisis and talks about current and future banking
               regulation. Importantly, it also explores algorithmic trading,
               which currently receives sparse attention in the literature. By
               giving coherent recommendations about which statistical models to
               use for which asset class, this book makes a real contribution to
               the sciences of portfolio management and risk management. Covers
               all asset classes Provides mathematical theoretical explanations
               of risk as well as practical examples with empirical data
               Includes sections on equity risk modeling, futures and
               derivatives, credit markets, foreign exchange, and commodities",
  month     =  may,
  year      =  2014
}

@ARTICLE{Haltaufderheide2024-ju,
  title     = "The ethics of {ChatGPT} in medicine and healthcare: a systematic
               review on Large Language Models ({LLMs})",
  author    = "Haltaufderheide, Joschka and Ranisch, Robert",
  journal   = "NPJ Digit. Med.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  7,
  number    =  1,
  pages     =  183,
  abstract  = "With the introduction of ChatGPT, Large Language Models (LLMs)
               have received enormous attention in healthcare. Despite potential
               benefits, researchers have underscored various ethical
               implications. While individual instances have garnered attention,
               a systematic and comprehensive overview of practical applications
               currently researched and ethical issues connected to them is
               lacking. Against this background, this work maps the ethical
               landscape surrounding the current deployment of LLMs in medicine
               and healthcare through a systematic review. Electronic databases
               and preprint servers were queried using a comprehensive search
               strategy which generated 796 records. Studies were screened and
               extracted following a modified rapid review approach.
               Methodological quality was assessed using a hybrid approach. For
               53 records, a meta-aggregative synthesis was performed. Four
               general fields of applications emerged showcasing a dynamic
               exploration phase. Advantages of using LLMs are attributed to
               their capacity in data analysis, information provisioning,
               support in decision-making or mitigating information loss and
               enhancing information accessibility. However, our study also
               identifies recurrent ethical concerns connected to fairness,
               bias, non-maleficence, transparency, and privacy. A distinctive
               concern is the tendency to produce harmful or convincing but
               inaccurate content. Calls for ethical guidance and human
               oversight are recurrent. We suggest that the ethical guidance
               debate should be reframed to focus on defining what constitutes
               acceptable human oversight across the spectrum of applications.
               This involves considering the diversity of settings, varying
               potentials for harm, and different acceptable thresholds for
               performance and certainty in healthcare. Additionally, critical
               inquiry is needed to evaluate the necessity and justification of
               LLMs' current experimental use.",
  month     =  jul,
  year      =  2024,
  language  = "en"
}

@INPROCEEDINGS{Holstein2019-ez,
  title     = "Improving fairness in machine learning systems: What do industry
               practitioners need?",
  author    = "Holstein, Kenneth and Wortman Vaughan, Jennifer and Daumé, III,
               Hal and Dudik, Miro and Wallach, Hanna",
  booktitle = "Proceedings of the 2019 CHI Conference on Human Factors in
               Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  may,
  year      =  2019
}

@ARTICLE{Verma2023-dk,
  title     = "How an {AI}-written Star Wars story created chaos at Gizmodo",
  author    = "Verma, Pranshu",
  journal   = "The Washington Post",
  publisher = "The Washington Post",
  abstract  = "A Gizmodo story on Star Wars, generated by artificial
               intelligence, was riddled with errors. The irony that the problem
               happened at a tech publication was undeniable.",
  month     =  jul,
  year      =  2023
}

@MISC{UnknownUnknown-fh,
  title        = "Incident 574: {AI}-Generated Articles at {G}/{O} Media
                  Allegedly Diminishes Reputation of Human Staff",
  abstract     = "G/O Media began publishing AI-generated articles, against
                  staff advice, that contained errors and quality issues. The
                  first such article, a list of Star Wars movies, failed to
                  maintain chronological order, causing internal concerns over
                  journalistic credibility and ethics. Staff expressed that the
                  AI was ``actively hurting our reputations and credibility''
                  and accused management of ``wasting everyone's time.''",
  howpublished = "\url{https://incidentdatabase.ai/cite/574/}",
  note         = "Accessed: 2024-8-2",
  language     = "en"
}

@ARTICLE{Elkassem2023-yv,
  title     = "Potential use cases for {ChatGPT} in radiology reporting",
  author    = "Elkassem, Asser Abou and Smith, Andrew D",
  journal   = "AJR Am. J. Roentgenol.",
  publisher = "American Roentgen Ray Society",
  volume    =  221,
  number    =  3,
  pages     = "373--376",
  abstract  = "Large language models (LLMs) such as ChatGPT are advanced
               artificial intelligence models that are designed to process and
               understand human language. LLMs have the potential to improve
               radiology reporting and patient engagement by automating
               generation of the clinical history and impression of a radiology
               report, creating layperson reports, and providing patients with
               pertinent questions and answers about findings in radiology
               reports. However, LLMs are error prone, and human oversight is
               needed to reduce the risk of patient harm.",
  month     =  sep,
  year      =  2023,
  keywords  = "ChatGPT; artificial intelligence; health care; large language
               models; radiology reports",
  language  = "en"
}

@ARTICLE{Akinci-D-Antonoli2024-oy,
  title     = "Large language models in radiology: fundamentals, applications,
               ethical considerations, risks, and future directions",
  author    = "Akinci D'Antonoli, Tugba and Stanzione, Arnaldo and Bluethgen,
               Christian and Vernuccio, Federica and Ugga, Lorenzo and Klontzas,
               Michail E and Cuocolo, Renato and Cannella, Roberto and Koçak,
               Burak",
  journal   = "Diagn. Interv. Radiol.",
  publisher = "Galenos Yayinevi",
  volume    =  30,
  number    =  2,
  pages     = "80--90",
  abstract  = "With the advent of large language models (LLMs), the artificial
               intelligence revolution in medicine and radiology is now more
               tangible than ever. Every day, an increasingly large number of
               articles are published that utilize LLMs in radiology. To adopt
               and safely implement this new technology in the field,
               radiologists should be familiar with its key concepts, understand
               at least the technical basics, and be aware of the potential
               risks and ethical considerations that come with it. In this
               review article, the authors provide an overview of the LLMs that
               might be relevant to the radiology community and include a brief
               discussion of their short history, technical basics, ChatGPT,
               prompt engineering, potential applications in medicine and
               radiology, advantages, disadvantages and risks, ethical and
               regulatory considerations, and future directions.",
  month     =  mar,
  year      =  2024,
  keywords  = "ChatGPT; Large language models; artificial intelligence; deep
               learning; natural language processing",
  language  = "en"
}

@INCOLLECTION{Stanley2022-ad,
  title     = "Disproportionate subgroup impacts and other challenges of
               fairness in artificial intelligence for medical image analysis",
  author    = "Stanley, Emma A M and Wilms, Matthias and Forkert, Nils D",
  booktitle = "Ethical and Philosophical Issues in Medical Imaging, Multimodal
               Learning and Fusion Across Scales for Clinical Decision Support,
               and Topological Data Analysis for Biomedical Imaging",
  publisher = "Springer Nature Switzerland",
  address   = "Cham",
  pages     = "14--25",
  series    = "Lecture notes in computer science",
  year      =  2022
}

@ARTICLE{Kaushal2020-lp,
  title     = "Geographic distribution of {US} cohorts used to train deep
               learning algorithms",
  author    = "Kaushal, Amit and Altman, Russ and Langlotz, Curt",
  journal   = "JAMA",
  publisher = "American Medical Association",
  volume    =  324,
  number    =  12,
  pages     = "1212--1213",
  abstract  = "This study describes the US geographic distribution of patient
               cohorts used to train deep learning algorithms in published
               radiology, ophthalmology, dermatology, pathology,
               gastroenterology, and cardiology machine learning articles
               published in 2015-2019.",
  month     =  sep,
  year      =  2020,
  keywords  = "deep learning; machine learning; cardiology; dermatology;
               gastroenterology; ophthalmology; radiology specialty",
  language  = "en"
}

@ARTICLE{McGregor2022-fy,
  title         = "Indexing {AI} risks with incidents, issues, and variants",
  author        = "McGregor, Sean and Paeth, Kevin and Lam, Khoa",
  journal       = "arXiv [cs.CY]",
  abstract      = "Two years after publicly launching the AI Incident Database
                   (AIID) as a collection of harms or near harms produced by AI
                   in the world, a backlog of ``issues'' that do not meet its
                   incident ingestion criteria have accumulated in its review
                   queue. Despite not passing the database's current criteria
                   for incidents, these issues advance human understanding of
                   where AI presents the potential for harm. Similar to
                   databases in aviation and computer security, the AIID
                   proposes to adopt a two-tiered system for indexing AI
                   incidents (i.e., a harm or near harm event) and issues (i.e.,
                   a risk of a harm event). Further, as some machine
                   learning-based systems will sometimes produce a large number
                   of incidents, the notion of an incident ``variant'' is
                   introduced. These proposed changes mark the transition of the
                   AIID to a new version in response to lessons learned from
                   editing 2,000+ incident reports and additional reports that
                   fall under the new category of ``issue.''",
  month         =  nov,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CY"
}

@ARTICLE{Kellogg2020-rs,
  title     = "Algorithms at Work: The New Contested Terrain of Control",
  author    = "Kellogg, Katherine C and Valentine, Melissa A and Christin,
               Angéle",
  journal   = "ANNALS",
  publisher = "journals.aom.org",
  volume    =  14,
  number    =  1,
  pages     = "366--410",
  month     =  jan,
  year      =  2020
}

@ARTICLE{Elish2020-ch,
  title   = "A Study of Integrating {AI} in Clinical Care",
  author  = "Elish, Madeleine Clare and Watkins, Elizabeth",
  journal = "Data and Society",
  year    =  2020
}

@article{saxena2024algorithmic,
  title={Algorithmic harms in child welfare: Uncertainties in practice, organization, and street-level decision-making},
  author={Saxena, Devansh and Guha, Shion},
  journal={ACM Journal on Responsible Computing},
  volume={1},
  number={1},
  pages={1--32},
  year={2024},
  publisher={ACM New York, NY}
}

@inproceedings{haque2024we,
  title={Are We Asking the Right Questions?: Designing for Community Stakeholders’ Interactions with AI in Policing},
  author={Haque, MD Romael and Saxena, Devansh and Weathington, Katy and Chudzik, Joseph and Guha, Shion},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--20},
  year={2024}
}

@article{roemmich2023values,
  title={Values in emotion artificial intelligence hiring services: Technosolutions to organizational problems},
  author={Roemmich, Kat and Rosenberg, Tillie and Fan, Serena and Andalibi, Nazanin},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={7},
  number={CSCW1},
  pages={1--28},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@article{garcia2024algorithmic,
  title={Algorithmic discrimination in the credit domain: what do we know about it?},
  author={Garcia, Ana Cristina Bicharra and Garcia, Marcio Gomes Pinto and Rigobon, Roberto},
  journal={AI \& SOCIETY},
  volume={39},
  number={4},
  pages={2059--2098},
  year={2024},
  publisher={Springer}
}

@inproceedings{saxena2023rethinking,
  title={Rethinking" Risk" in Algorithmic Systems Through A Computational Narrative Analysis of Casenotes in Child-Welfare},
  author={Saxena, Devansh and Moon, Erina Seh-Young and Chaurasia, Aryan and Guan, Yixin and Guha, Shion},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--19},
  year={2023}
}

@inproceedings{saxena2022unpacking,
  title={Unpacking invisible work practices, constraints, and latent power relationships in child welfare through casenote analysis},
  author={Saxena, Devansh and Moon, Seh Young and Shehata, Dahlia and Guha, Shion},
  booktitle={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  pages={1--22},
  year={2022}
}

@ARTICLE{Wong2021-zv,
  title     = "External validation of a widely implemented proprietary sepsis
               prediction model in hospitalized patients",
  author    = "Wong, Andrew and Otles, Erkin and Donnelly, John P and Krumm,
               Andrew and McCullough, Jeffrey and DeTroyer-Cooley, Olivia and
               Pestrue, Justin and Phillips, Marie and Konye, Judy and Penoza,
               Carleen and Ghous, Muhammad and Singh, Karandeep",
  journal   = "JAMA Intern. Med.",
  publisher = "American Medical Association (AMA)",
  volume    =  181,
  number    =  8,
  pages     = "1065--1070",
  abstract  = "Importance: The Epic Sepsis Model (ESM), a proprietary sepsis
               prediction model, is implemented at hundreds of US hospitals. The
               ESM's ability to identify patients with sepsis has not been
               adequately evaluated despite widespread use. Objective: To
               externally validate the ESM in the prediction of sepsis and
               evaluate its potential clinical value compared with usual care.
               Design, Setting, and Participants: This retrospective cohort
               study was conducted among 27 697 patients aged 18 years or older
               admitted to Michigan Medicine, the academic health system of the
               University of Michigan, Ann Arbor, with 38 455 hospitalizations
               between December 6, 2018, and October 20, 2019. Exposure: The ESM
               score, calculated every 15 minutes. Main Outcomes and Measures:
               Sepsis, as defined by a composite of (1) the Centers for Disease
               Control and Prevention surveillance criteria and (2)
               International Statistical Classification of Diseases and Related
               Health Problems, Tenth Revision diagnostic codes accompanied by 2
               systemic inflammatory response syndrome criteria and 1 organ
               dysfunction criterion within 6 hours of one another. Model
               discrimination was assessed using the area under the receiver
               operating characteristic curve at the hospitalization level and
               with prediction horizons of 4, 8, 12, and 24 hours. Model
               calibration was evaluated with calibration plots. The potential
               clinical benefit associated with the ESM was assessed by
               evaluating the added benefit of the ESM score compared with
               contemporary clinical practice (based on timely administration of
               antibiotics). Alert fatigue was evaluated by comparing the
               clinical value of different alerting strategies. Results: We
               identified 27 697 patients who had 38 455 hospitalizations (21
               904 women [57\%]; median age, 56 years [interquartile range,
               35-69 years]) meeting inclusion criteria, of whom sepsis occurred
               in 2552 (7\%). The ESM had a hospitalization-level area under the
               receiver operating characteristic curve of 0.63 (95\% CI,
               0.62-0.64). The ESM identified 183 of 2552 patients with sepsis
               (7\%) who did not receive timely administration of antibiotics,
               highlighting the low sensitivity of the ESM in comparison with
               contemporary clinical practice. The ESM also did not identify
               1709 patients with sepsis (67\%) despite generating alerts for an
               ESM score of 6 or higher for 6971 of all 38 455 hospitalized
               patients (18\%), thus creating a large burden of alert fatigue.
               Conclusions and Relevance: This external validation cohort study
               suggests that the ESM has poor discrimination and calibration in
               predicting the onset of sepsis. The widespread adoption of the
               ESM despite its poor performance raises fundamental concerns
               about sepsis management on a national level.",
  month     =  aug,
  year      =  2021,
  language  = "en"
}


@ARTICLE{Addy2024-lv,
  title     = "Machine learning in financial markets: A critical review of
               algorithmic trading and risk management",
  author    = "Addy, Wilhelmina Afua and Ajayi-Nifise, Adeola Olusola and Bello,
               Binaebi Gloria and Tula, Sunday Tubokirifuruar and Odeyemi,
               Olubusola and Falaiye, Titilola",
  journal   = "Int. J. Sci. Res. Arch.",
  publisher = "GSC Online Press",
  volume    =  11,
  number    =  1,
  pages     = "1853--1862",
  abstract  = "The integration of machine learning (ML) techniques in financial
               markets has revolutionized traditional trading and risk
               management strategies, offering unprecedented opportunities and
               challenges. This paper provides a comprehensive and critical
               review of the application of ML in algorithmic trading and risk
               management within the realm of financial markets. The review
               begins by exploring the evolution of algorithmic trading,
               highlighting the paradigm shift from traditional rule-based
               strategies to ML-driven approaches. Various ML algorithms,
               including neural networks, decision trees, and ensemble methods,
               are examined in the context of their application to predictive
               modeling, pattern recognition, and signal generation for trading
               purposes. The paper also delves into the challenges and
               limitations associated with the adoption of ML in financial
               markets. Issues such as overfitting, data bias, and model
               interpretability are discussed, emphasizing the importance of
               addressing these concerns to ensure robust and reliable trading
               systems. Furthermore, ethical considerations and potential
               regulatory implications of ML-driven trading strategies are
               considered in the context of market fairness and stability. In
               the realm of risk management, the review scrutinizes the role of
               ML in assessing and mitigating financial risks. The paper
               evaluates the effectiveness of ML models in identifying market
               trends, measuring portfolio risk, and optimizing asset
               allocation. Additionally, it examines the potential impact of ML
               on systemic risk and the need for adaptive risk management
               frameworks in dynamic market conditions. The synthesis of
               findings underscores the transformative impact of ML on financial
               markets, showcasing its potential to enhance trading strategies
               and risk management practices. However, the review also
               highlights the importance of addressing inherent challenges and
               ethical considerations to ensure the responsible and sustainable
               integration of ML in the financial domain. This critical review
               provides valuable insights into the current state of machine
               learning in financial markets, offering a foundation for future
               research directions and the development of best practices in
               algorithmic trading and risk management.",
  month     =  feb,
  year      =  2024
}

@ARTICLE{Zhou2023-cf,
  title     = "Generative {AI}, human creativity, and art",
  author    = "Zhou, Eric and Lee, Dokyun",
  journal   = "SSRN Electron. J.",
  publisher = "Elsevier BV",
  abstract  = "Recent artificial intelligence (AI) tools have demonstrated their
               ability to produce outputs traditionally considered creative. One
               such system is text-to-image",
  month     =  oct,
  year      =  2023,
  keywords  = "Generative AI, Human-AI Collaboration, Creative Workflow, Impact
               of AI Adoption, Art",
  language  = "en"
}

@INPROCEEDINGS{Wadinambiarachchi2024-en,
  title     = "The Effects of Generative {AI} on Design Fixation and Divergent
               Thinking",
  author    = "Wadinambiarachchi, Samangi and Kelly, Ryan M and Pareek, Saumya
               and Zhou, Qiushi and Velloso, Eduardo",
  booktitle = "Proceedings of the CHI Conference on Human Factors in Computing
               Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1--18",
  month     =  may,
  year      =  2024
}

@ARTICLE{Liu2024-oa,
  title     = "Smart ``Error''! Exploring Imperfect {AI} to Support Creative
               Ideation",
  author    = "Liu, Fang and Lv, Junyan and Cui, Shenglan and Luan, Zhilong and
               Wu, Kui and Zhou, Tongqing",
  journal   = "Proc. ACM Hum.-Comput. Interact.",
  publisher = "dl.acm.org",
  volume    =  8,
  number    = "CSCW1",
  pages     = "1--28",
  month     =  apr,
  year      =  2024
}

@ARTICLE{Faheem2023-ky,
  title     = "Artificial intelligence failure at {IBM} 'Watson for oncology'",
  author    = "Faheem, Hadiyapreview Author Details; Dutta",
  journal   = "IUP Journal of Knowledge Management",
  publisher = "search.proquest.com",
  volume    =  21,
  number    =  3,
  pages     = "47--75",
  month     =  jul,
  year      =  2023
}

@BOOK{Buolamwini2023-xl,
  title     = "Unmasking {AI}: My mission to protect what is human in a world of
               machines",
  author    = "Buolamwini, Joy",
  publisher = "Random House",
  address   = "New York, NY",
  abstract  = "NATIONAL BESTSELLER • “The conscience of the AI revolution”
               (Fortune) explains how we’ve arrived at an era of AI harms and
               oppression, and what we can do to avoid its pitfalls.“Dr. Joy
               Buolamwini has been an essential figure in bringing
               irresponsible, profit-hungry tech giants to their knees. If
               you’re going to read only one book about AI, this should be
               it.”—Darren Walker, president of the Ford Foundation A LOS
               ANGELES TIMES BEST BOOK OF THE YEAR • Shortlisted for the Inc.
               Non-Obvious Book AwardTo most of us, it seems like recent
               developments in artificial intelligence emerged out of nowhere to
               pose unprecedented threats to humankind. But to Dr. Joy
               Buolamwini, who has been at the forefront of AI research, this
               moment has been a long time in the making.After tinkering with
               robotics as a high school student in Memphis and then developing
               mobile apps in Zambia as a Fulbright fellow, Buolamwini followed
               her lifelong passion for computer science, engineering, and art
               to MIT in 2015. As a graduate student at the “Future Factory,”
               she did groundbreaking research that exposed widespread racial
               and gender bias in AI services from tech giants across the
               world.Unmasking AI goes beyond the headlines about existential
               risks produced by Big Tech. It is the remarkable story of how
               Buolamwini uncovered what she calls “the coded gaze”—the evidence
               of encoded discrimination and exclusion in tech products—and how
               she galvanized the movement to prevent AI harms by founding the
               Algorithmic Justice League. Applying an intersectional lens to
               both the tech industry and the research sector, she shows how
               racism, sexism, colorism, and ableism can overlap and render
               broad swaths of humanity “excoded” and therefore vulnerable in a
               world rapidly adopting AI tools. Computers, she reminds us, are
               reflections of both the aspirations and the limitations of the
               people who create them.Encouraging experts and non-experts alike
               to join this fight, Buolamwini writes, “The rising frontier for
               civil rights will require algorithmic justice. AI should be for
               the people and by the people, not just the privileged few.”",
  month     =  oct,
  year      =  2023,
  language  = "en"
}

@ARTICLE{Schuetz2021-xg,
  title     = "Fly in the face of bias: Algorithmic bias in law enforcement's
               facial recognition technology and the need for an adaptive legal
               framework",
  author    = "Schuetz, P",
  journal   = "Law \& Ineq.",
  publisher = "HeinOnline",
  volume    =  39,
  pages     =  8,
  year      =  2021
}

@ARTICLE{Liu2022-cp,
  title         = "Lost in translation: Reimagining the machine learning life
                   cycle in education",
  author        = "Liu, Lydia T and Wang, Serena and Britton, Tolani and Abebe,
                   Rediet",
  journal       = "arXiv [cs.AI]",
  abstract      = "Machine learning (ML) techniques are increasingly prevalent
                   in education, from their use in predicting student dropout,
                   to assisting in university admissions, and facilitating the
                   rise of MOOCs. Given the rapid growth of these novel uses,
                   there is a pressing need to investigate how ML techniques
                   support long-standing education principles and goals. In this
                   work, we shed light on this complex landscape drawing on
                   qualitative insights from interviews with education experts.
                   These interviews comprise in-depth evaluations of ML for
                   education (ML4Ed) papers published in preeminent applied ML
                   conferences over the past decade. Our central research goal
                   is to critically examine how the stated or implied education
                   and societal objectives of these papers are aligned with the
                   ML problems they tackle. That is, to what extent does the
                   technical problem formulation, objectives, approach, and
                   interpretation of results align with the education problem at
                   hand. We find that a cross-disciplinary gap exists and is
                   particularly salient in two parts of the ML life cycle: the
                   formulation of an ML problem from education goals and the
                   translation of predictions to interventions. We use these
                   insights to propose an extended ML life cycle, which may also
                   apply to the use of ML in other domains. Our work joins a
                   growing number of meta-analytical studies across education
                   and ML research, as well as critical analyses of the societal
                   impact of ML. Specifically, it fills a gap between the
                   prevailing technical understanding of machine learning and
                   the perspective of education researchers working with
                   students and in policy.",
  month         =  sep,
  year          =  2022,
  archivePrefix = "arXiv",
  primaryClass  = "cs.AI"
}

@ARTICLE{Eubanks2018-dk,
  title     = "Automating Inequality: How high-tech tools profile, police, and
               punish the poor",
  author    = "Eubanks, Virginia E",
  publisher = "books.google.com",
  abstract  = "Naomi Klein: ``This book is downright scary.''Ethan Zuckerman,
               MIT: ``Should be required reading.''Dorothy Roberts, author of
               Killing the Black Body: ``A must-read.''Astra Taylor, author of
               The People's Platform: ``The single most important book about
               technology you will read this year.''Cory Doctorow:
               ``Indispensable.''A powerful investigative look at data-based
               discriminationand how technology affects civil and human rights
               and economic equity The State of Indiana denies one million
               applications for healthcare, foodstamps and cash benefits in
               three yearsbecause a new computer system interprets any mistake
               as failure to cooperate. In Los Angeles, an algorithm calculates
               the comparative vulnerability of tens of thousands of homeless
               people in order to prioritize them for an inadequate pool of
               housing resources. In Pittsburgh, a child welfare agency uses a
               statistical model to try to predict which children might be
               future victims of abuse or neglect. Since the dawn of the digital
               age, decision-making in finance, employment, politics, health and
               human services has undergone revolutionary change. Today,
               automated systemsrather than humanscontrol which neighborhoods
               get policed, which families attain needed resources, and who is
               investigated for fraud. While we all live under this new regime
               of data, the most invasive and punitive systems are aimed at the
               poor. In Automating Inequality, Virginia Eubanks systematically
               investigates the impacts of data mining, policy algorithms, and
               predictive risk models on poor and working-class people in
               America. The book is full of heart-wrenching and eye-opening
               stories, from a woman in Indiana whose benefits are literally cut
               off as she lays dying to a family in Pennsylvania in daily fear
               of losing their daughter because they fit a certain statistical
               profile. The U.S. has always used its most cutting-edge science
               and technology to contain, investigate, discipline and punish the
               destitute. Like the county poorhouse and scientific charity
               before them, digital tracking and automated decision-making hide
               poverty from the middle-class public and give the nation the
               ethical distance it needs to make inhumane choices: which
               families get food and which starve, who has housing and who
               remains homeless, and which families are broken up by the state.
               In the process, they weaken democracy and betray our most
               cherished national values. This deeply researched and passionate
               book could not be more timely.",
  month     =  jan,
  year      =  2018
}

@ARTICLE{Obermeyer2019-vk,
  title     = "Dissecting racial bias in an algorithm used to manage the health
               of populations",
  author    = "Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and
               Mullainathan, Sendhil",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science (AAAS)",
  volume    =  366,
  number    =  6464,
  pages     = "447--453",
  abstract  = "Health systems rely on commercial prediction algorithms to
               identify and help patients with complex health needs. We show
               that a widely used algorithm, typical of this industry-wide
               approach and affecting millions of patients, exhibits significant
               racial bias: At a given risk score, Black patients are
               considerably sicker than White patients, as evidenced by signs of
               uncontrolled illnesses. Remedying this disparity would increase
               the percentage of Black patients receiving additional help from
               17.7 to 46.5\%. The bias arises because the algorithm predicts
               health care costs rather than illness, but unequal access to care
               means that we spend less money caring for Black patients than for
               White patients. Thus, despite health care cost appearing to be an
               effective proxy for health by some measures of predictive
               accuracy, large racial biases arise. We suggest that the choice
               of convenient, seemingly effective proxies for ground truth can
               be an important source of algorithmic bias in many contexts.",
  month     =  oct,
  year      =  2019,
  language  = "en"
}

@INPROCEEDINGS{Shelby2023-ff,
  title     = "Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy
               for Harm Reduction",
  author    = "Shelby, Renee and Rismani, Shalaleh and Henne, Kathryn and Moon,
               Ajung and Rostamzadeh, Negar and Nicholas, Paul and Yilla-Akbari,
               N'mah and Gallegos, Jess and Smart, Andrew and Garcia, Emilio and
               Virk, Gurleen",
  booktitle = "Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and
               Society",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "723--741",
  month     =  aug,
  year      =  2023
}

@article{metaxa2021auditing,
  title={Auditing algorithms: Understanding algorithmic systems from the outside in},
  author={Metaxa, Dana{\"e} and Park, Joon Sung and Robertson, Ronald E and Karahalios, Karrie and Wilson, Christo and Hancock, Jeff and Sandvig, Christian and others},
  journal={Foundations and Trends{\textregistered} in Human--Computer Interaction},
  volume={14},
  number={4},
  pages={272--344},
  year={2021},
  publisher={Now Publishers, Inc.}
}

@inproceedings{delgado2023participatory,
  title={The participatory turn in AI design: Theoretical foundations and the current state of practice},
  author={Delgado, Fernando and Yang, Stephen and Madaio, Michael and Yang, Qian},
  booktitle={Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization},
  pages={1--23},
  year={2023}
}

@inproceedings{hutchinson2022evaluation,
  title={Evaluation gaps in machine learning practice},
  author={Hutchinson, Ben and Rostamzadeh, Negar and Greer, Christina and Heller, Katherine and Prabhakaran, Vinodkumar},
  booktitle={Proceedings of the 2022 ACM conference on fairness, accountability, and transparency},
  pages={1859--1876},
  year={2022}
}



@inproceedings{deng2023investigating,
  title={Investigating Practices and Opportunities for Cross-functional Collaboration around AI Fairness in Industry Practice},
  author={Deng, Wesley Hanwen and Yildirim, Nur and Chang, Monica and Eslami, Motahhare and Holstein, Kenneth and Madaio, Michael},
  booktitle={Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
  pages={705--716},
  year={2023}
}

@inproceedings{kuo2023understanding,
  title={Understanding Frontline Workers’ and Unhoused Individuals’ Perspectives on AI Used in Homeless Services},
  author={Kuo, Tzu-Sheng and Shen, Hong and Geum, Jisoo and Jones, Nev and Hong, Jason I and Zhu, Haiyi and Holstein, Kenneth},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--17},
  year={2023}
}

@inproceedings{subramonyam2021towards,
  title={Towards a process model for co-creating AI experiences},
  author={Subramonyam, Hariharan and Seifert, Colleen and Adar, Eytan},
  booktitle={Proceedings of the 2021 ACM Designing Interactive Systems Conference},
  pages={1529--1543},
  year={2021}
}


@ARTICLE{Logan2016-of,
  title    = "Policing Criminal Justice Data",
  author   = "Logan, Wayne A and Ferguson, A and Ferguson, A",
  journal  = "Minnesota Law Review",
  volume   =  101,
  number   =  2,
  pages    =  541,
  abstract = "This article addresses a matter of fundamental importance to the
              criminal justice system: the presence of erroneous information in
              government databases and the limited government accountability and
              legal remedies for the harm that it causes individuals. While a
              substantial literature exists on the liberty and privacy perils of
              large multi-source data assemblage, often termed ``big data,''
              this article addresses the risks associated with the collection,
              generation and use of ``small data'' (i.e., individual-level,
              discrete data points). Because small data provides the building
              blocks for all data-driven systems, enhancing its quality will
              have a significant positive effect on the criminal justice system
              as a whole. The article examines the many contexts in which
              criminal justice data errors arise and offers institutional and
              legislative solutions designed both to lessen their occurrence and
              afford relief to those suffering the significant harms they cause.",
  month    =  apr,
  year     =  2016,
  language = "en"
}

@ARTICLE{Botsis2010-ac,
  title     = "Secondary use of {EHR}: Data quality issues and informatics
               opportunities",
  author    = "Botsis, Taxiarchis and Hartvigsen, Gunnar and Chen, Fei and Weng,
               Chunhua",
  journal   = "Summit On Translat. Bioinforma.",
  publisher = "American Medical Informatics Association",
  volume    =  2010,
  pages     = "1--5",
  abstract  = "Given the large-scale deployment of Electronic Health Records
               (EHR), secondary use of EHR data will be increasingly needed in
               all kinds of health services or clinical research. This paper
               reports some data quality issues we encountered in a survival
               analysis of pancreatic cancer patients. Using the clinical data
               warehouse at Columbia University Medical Center in the City of
               New York, we mined EHR data elements collected between 1999 and
               2009 for a cohort of pancreatic cancer patients. Of the 3068
               patients who had ICD-9-CM diagnoses for pancreatic cancer, only
               1589 had corresponding disease documentation in pathology
               reports. Incompleteness was the leading data quality issue; many
               study variables had missing values to various degrees. Inaccuracy
               and inconsistency were the next common problems. In this paper,
               we present the manifestations of these data quality issues and
               discuss some strategies for using emerging informatics
               technologies to solve these problems.",
  month     =  mar,
  year      =  2010,
  language  = "en"
}

@ARTICLE{Allard2018-hu,
  title     = "State agencies’ use of administrative data for improved practice:
               Needs, challenges, and opportunities: State agencies’ use of
               administrative data for improved practice: Needs, challenges, and
               opportunities",
  author    = "Allard, Scott W and Wiegand, Emily R and Schlecht, Colleen and
               Datta, A Rupa and Goerge, Robert M and Weigensberg, Elizabeth",
  journal   = "Public Adm. Rev.",
  publisher = "Wiley",
  volume    =  78,
  number    =  2,
  pages     = "240--250",
  abstract  = "Growing interest in the use of administrative data to answer
               questions around program implementation and effectiveness has led
               to greater discussion of how government agencies can develop the
               necessary internal data infrastructure, analytic capacity, and
               office culture. However, there is a need for more systematic
               research into how states find different pathways and strategies
               to build administrative data capacity. Drawing on interviews with
               almost 100 human service agency staff and their data partners,
               the authors examine the realities of administrative data use.
               They summarize the experiences of data users in order to address
               two main challenges: limited analytic capacity and challenges to
               linking or sharing data resources. The article concludes by
               examining a range of approaches that government agencies take to
               improve data quality and capacity to analyze that data.",
  month     =  mar,
  year      =  2018,
  language  = "en"
}

@INPROCEEDINGS{Kawakami2022-ez,
  title     = "“Why do {I} care what’s similar?” Probing challenges in
               {AI}-assisted child welfare decision-making through worker-{AI}
               interface design concepts",
  author    = "Kawakami, Anna and Sivaraman, Venkatesh and Stapleton, Logan and
               Cheng, Hao-Fei and Perer, Adam and Wu, Zhiwei Steven and Zhu,
               Haiyi and Holstein, Kenneth",
  booktitle = "Designing Interactive Systems Conference",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  jun,
  year      =  2022
}

@inproceedings{yang2019sketching,
  title={Sketching nlp: A case study of exploring the right things to design with language intelligence},
  author={Yang, Qian and Cranshaw, Justin and Amershi, Saleema and Iqbal, Shamsi T and Teevan, Jaime},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2019}
}

@inproceedings{yang2020re,
  title={Re-examining whether, why, and how human-AI interaction is uniquely difficult to design},
  author={Yang, Qian and Steinfeld, Aaron and Ros{\'e}, Carolyn and Zimmerman, John},
  booktitle={Proceedings of the 2020 chi conference on human factors in computing systems},
  pages={1--13},
  year={2020}
}

@INPROCEEDINGS{Kawakami2022-tx,
  title     = "Improving Human-{AI} Partnerships in Child Welfare: Understanding
               Worker Practices, Challenges, and Desires for Algorithmic
               Decision Support",
  author    = "Kawakami, Anna and Sivaraman, Venkatesh and Cheng, Hao-Fei and
               Stapleton, Logan and Cheng, Yanghuidi and Qing, Diana and Perer,
               Adam and Wu, Zhiwei Steven and Zhu, Haiyi and Holstein, Kenneth",
  booktitle = "CHI Conference on Human Factors in Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  pages     = "1--18",
  month     =  apr,
  year      =  2022
}

@INPROCEEDINGS{Cheng2022-ya,
  title     = "How child welfare workers reduce racial disparities in
               algorithmic decisions",
  author    = "Cheng, Hao-Fei and Stapleton, Logan and Kawakami, Anna and
               Sivaraman, Venkatesh and Cheng, Yanghuidi and Qing, Diana and
               Perer, Adam and Holstein, Kenneth and Wu, Zhiwei Steven and Zhu,
               Haiyi",
  booktitle = "CHI Conference on Human Factors in Computing Systems",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  apr,
  year      =  2022
}

@ARTICLE{Kleinberg2016-fd,
  title         = "Inherent trade-offs in the fair determination of risk scores",
  author        = "Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish",
  journal       = "arXiv [cs.LG]",
  abstract      = "Recent discussion in the public sphere about algorithmic
                   classification has involved tension between competing notions
                   of what it means for a probabilistic classification to be
                   fair to different groups. We formalize three fairness
                   conditions that lie at the heart of these debates, and we
                   prove that except in highly constrained special cases, there
                   is no method that can satisfy these three conditions
                   simultaneously. Moreover, even satisfying all three
                   conditions approximately requires that the data lie in an
                   approximate version of one of the constrained special cases
                   identified by our theorem. These results suggest some of the
                   ways in which key notions of fairness are incompatible with
                   each other, and hence provide a framework for thinking about
                   the trade-offs between them.",
  month         =  sep,
  year          =  2016,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Chouldechova2017-aj,
  title     = "Fair prediction with disparate impact: A study of bias in
               recidivism prediction instruments",
  author    = "Chouldechova, Alexandra",
  journal   = "Big Data",
  publisher = "liebertpub.com",
  volume    =  5,
  number    =  2,
  pages     = "153--163",
  abstract  = "Recidivism prediction instruments (RPIs) provide decision-makers
               with an assessment of the likelihood that a criminal defendant
               will reoffend at a future point in time. Although such
               instruments are gaining increasing popularity across the country,
               their use is attracting tremendous controversy. Much of the
               controversy concerns potential discriminatory bias in the risk
               assessments that are produced. This article discusses several
               fairness criteria that have recently been applied to assess the
               fairness of RPIs. We demonstrate that the criteria cannot all be
               simultaneously satisfied when recidivism prevalence differs
               across groups. We then show how disparate impact can arise when
               an RPI fails to satisfy the criterion of error rate balance.",
  month     =  jun,
  year      =  2017,
  keywords  = "bias; disparate impact; fair machine learning; recidivism
               prediction; risk assessment",
  language  = "en"
}

@ARTICLE{Wang2024-cj,
  title     = "Against Predictive Optimization: On the Legitimacy of
               Decision-making Algorithms That Optimize Predictive Accuracy",
  author    = "Wang, Angelina and Kapoor, Sayash and Barocas, Solon and
               Narayanan, Arvind",
  journal   = "ACM J. Responsib. Comput.",
  publisher = "dl.acm.org",
  volume    =  1,
  number    =  1,
  pages     = "1--45",
  month     =  mar,
  year      =  2024
}

@INPROCEEDINGS{Jacobs2021-of,
  title     = "Measurement and Fairness",
  author    = "Jacobs, Abigail Z and Wallach, Hanna",
  booktitle = "Proceedings of the 2021 ACM Conference on Fairness,
               Accountability, and Transparency",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  mar,
  year      =  2021
}





@misc{doe_ews_2016, 
url={https://www2.ed.gov/rschstat/eval/high-school/early-warning-systems-brief.pdf}, journal={"Issue Brief: Early Warning Systems"},
publisher={"U.S. Department of Education Office of Planning, Evaluation and Policy Development Policy and Program Studies Service"},
year=2016} 

@article{johnson2020mimic,
  title={Mimic-iv},
  author={Johnson, Alistair and Bulgarelli, Lucas and Pollard, Tom and Horng, Steven and Celi, Leo Anthony and Mark, Roger},
  journal={PhysioNet. Available online at: https://physionet. org/content/mimiciv/1.0/(accessed August 23, 2021)},
  pages={49--55},
  year={2020}
}

@article{goldberger2000physiobank,
  title={PhysioBank, PhysioToolkit, and PhysioNet: components of a new research resource for complex physiologic signals},
  author={Goldberger, Ary L and Amaral, Luis AN and Glass, Leon and Hausdorff, Jeffrey M and Ivanov, Plamen Ch and Mark, Roger G and Mietus, Joseph E and Moody, George B and Peng, Chung-Kang and Stanley, H Eugene},
  journal={circulation},
  volume={101},
  number={23},
  pages={e215--e220},
  year={2000},
  publisher={Am Heart Assoc}
}

@article{ingels2004education,
  title={Education Longitudinal Study of 2002: Base Year Data File User's Manual. NCES 2004-405.},
  author={Ingels, Steven J and Pratt, Daniel J and Rogers, James E and Siegel, Peter H and Stutts, Ellen S},
  journal={National Center for Education Statistics},
  year={2004},
  publisher={ERIC}
}


@article{rachatasumrit2021toward,
  title={Toward Improving Student Model Estimates through Assistance Scores in Principle and in Practice.},
  author={Rachatasumrit, Napol and Koedinger, Kenneth R},
  journal={International Educational Data Mining Society},
  year={2021},
  publisher={ERIC}
}

@article{kleinberg2018human,
  title={Human decisions and machine predictions},
  author={Kleinberg, Jon and Lakkaraju, Himabindu and Leskovec, Jure and Ludwig, Jens and Mullainathan, Sendhil},
  journal={The quarterly journal of economics},
  volume={133},
  number={1},
  pages={237--293},
  year={2018},
  publisher={Oxford University Press}
}

@article{de2021leveraging,
  title={Leveraging expert consistency to improve algorithmic decision support},
  author={De-Arteaga, Maria and Dubrawski, Artur and Chouldechova, Alexandra},
  journal={arXiv preprint arXiv:2101.09648},
  year={2021}
}

@article{obermeyer2019dissecting,
  title={Dissecting racial bias in an algorithm used to manage the health of populations},
  author={Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
  journal={Science},
  volume={366},
  number={6464},
  pages={447--453},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{passi2019problem,
  title={Problem formulation and fairness},
  author={Passi, Samir and Barocas, Solon},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={39--48},
  year={2019}
}

@inproceedings{bansal2019beyond,
  title={Beyond accuracy: The role of mental models in human-AI team performance},
  author={Bansal, Gagan and Nushi, Besmira and Kamar, Ece and Lasecki, Walter S and Weld, Daniel S and Horvitz, Eric},
  booktitle={Proceedings of the AAAI conference on human computation and crowdsourcing},
  volume={7},
  pages={2--11},
  year={2019}
}

@inproceedings{guerdan2023ground,
  title={Ground (less) truth: A causal framework for proxy labels in human-algorithm decision-making},
  author={Guerdan, Luke and Coston, Amanda and Wu, Zhiwei Steven and Holstein, Kenneth},
  booktitle={Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
  pages={688--704},
  year={2023}
}

@article{sansone2019beyond,
  title={Beyond early warning indicators: high school dropout and machine learning},
  author={Sansone, Dario},
  journal={Oxford bulletin of economics and statistics},
  volume={81},
  number={2},
  pages={456--485},
  year={2019},
  publisher={Wiley Online Library}
}

@article{alyahyan2020predicting,
  title={Predicting academic success in higher education: literature review and best practices},
  author={Alyahyan, Eyman and D{\"u}{\c{s}}teg{\"o}r, Dilek},
  journal={International Journal of Educational Technology in Higher Education},
  volume={17},
  number={1},
  pages={3},
  year={2020},
  publisher={Springer}
}

@article{gardner2018student,
  title={Student success prediction in MOOCs},
  author={Gardner, Josh and Brooks, Christopher},
  journal={User Modeling and User-Adapted Interaction},
  volume={28},
  pages={127--203},
  year={2018},
  publisher={Springer}
}

@article{faria2017getting,
  title={Getting Students on Track for Graduation: Impacts of the Early Warning Intervention and Monitoring System after One Year. REL 2017-272.},
  author={Faria, Ann-Marie and Sorensen, Nicholas and Heppen, Jessica and Bowdon, Jill and Taylor, Suzanne and Eisner, Ryan and Foster, Shandu},
  journal={Regional Educational Laboratory Midwest},
  year={2017},
  publisher={ERIC}
}

@techreport{haimovich2021scalable,
  title={Scalable early warning systems for school dropout prevention: Evidence from a 4.000-school randomized controlled trial},
  author={Haimovich, Francisco and Vazquez, Emmanuel and Adelman, Melissa},
  year={2021},
  institution={Documento de Trabajo}
}

@article{mac2019efficacy,
  title={An efficacy study of a ninth-grade early warning indicator intervention},
  author={Mac Iver, Martha Abele and Stein, Marc L and Davis, Marcia H and Balfanz, Robert W and Fox, Joanna Hornig},
  journal={Journal of Research on Educational Effectiveness},
  volume={12},
  number={3},
  pages={363--390},
  year={2019},
  publisher={Taylor \& Francis}
}

@article{miles2020using,
  title={Using machine-learning risk prediction models to triage the acuity of undifferentiated patients entering the emergency care system: a systematic review},
  author={Miles, Jamie and Turner, Janette and Jacques, Richard and Williams, Julia and Mason, Suzanne},
  journal={Diagnostic and prognostic research},
  volume={4},
  pages={1--12},
  year={2020},
  publisher={Springer}
}

@article{sanchez2022machine,
  title={Machine learning methods applied to triage in emergency services: A systematic review},
  author={S{\'a}nchez-Salmer{\'o}n, Roc{\'\i}o and G{\'o}mez-Urquiza, Jos{\'e} L and Albend{\'\i}n-Garc{\'\i}a, Luis and Correa-Rodr{\'\i}guez, Mar{\'\i}a and Martos-Cabrera, Mar{\'\i}a Bego{\~n}a and Velando-Soriano, Almudena and Suleiman-Martos, Nora},
  journal={International Emergency Nursing},
  volume={60},
  pages={101109},
  year={2022},
  publisher={Elsevier}
}

@article{raita2019emergency,
  title={Emergency department triage prediction of clinical outcomes using machine learning models},
  author={Raita, Yoshihiko and Goto, Tadahiro and Faridi, Mohammad Kamal and Brown, David FM and Camargo, Carlos A and Hasegawa, Kohei},
  journal={Critical care},
  volume={23},
  pages={1--13},
  year={2019},
  publisher={Springer}
}

@inproceedings{watson2023multi,
  title={Multi-Target Multiplicity: Flexibility and Fairness in Target Specification under Resource Constraints},
  author={Watson-Daniels, Jamelle and Barocas, Solon and Hofman, Jake M and Chouldechova, Alexandra},
  booktitle={Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
  pages={297--311},
  year={2023}
}

@article{heckathorn2011comment,
  title={Comment: Snowball versus respondent-driven sampling},
  author={Heckathorn, Douglas D},
  journal={Sociological methodology},
  volume={41},
  number={1},
  pages={355--366},
  year={2011},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{saunders2018saturation,
  title={Saturation in qualitative research: exploring its conceptualization and operationalization},
  author={Saunders, Benjamin and Sim, Julius and Kingstone, Tom and Baker, Shula and Waterfield, Jackie and Bartlam, Bernadette and Burroughs, Heather and Jinks, Clare},
  journal={Quality \& quantity},
  volume={52},
  pages={1893--1907},
  year={2018},
  publisher={Springer}
}

@article{braun2006using,
  title={Using thematic analysis in psychology},
  author={Braun, Virginia and Clarke, Victoria},
  journal={Qualitative research in psychology},
  volume={3},
  number={2},
  pages={77--101},
  year={2006},
  publisher={Taylor \& Francis}
}

@article{clarke2017thematic,
  title={Thematic analysis},
  author={Clarke, Victoria and Braun, Virginia},
  journal={The journal of positive psychology},
  volume={12},
  number={3},
  pages={297--298},
  year={2017},
  publisher={Taylor \& Francis}
}

@article{kross2021orienting,
  title={Orienting, framing, bridging, magic, and counseling: How data scientists navigate the outer loop of client collaborations in industry and academia},
  author={Kross, Sean and Guo, Philip},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={5},
  number={CSCW2},
  pages={1--28},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{coston2023validity,
  title={A validity perspective on evaluating the justified use of data-driven decision-making algorithms},
  author={Coston, Amanda and Kawakami, Anna and Zhu, Haiyi and Holstein, Ken and Heidari, Hoda},
  booktitle={2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)},
  pages={690--704},
  year={2023},
  organization={IEEE}
}

@article{drost2011validity,
  title={Validity and reliability in social science research},
  author={Drost, Ellen A},
  journal={Education Research and perspectives},
  volume={38},
  number={1},
  pages={105--123},
  year={2011},
  publisher={University of Western Australia, Department of Education [Nedlands, WA]}
}

@inproceedings{jacobs2021measurement,
  title={Measurement and fairness},
  author={Jacobs, Abigail Z and Wallach, Hanna},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={375--385},
  year={2021}
}

@inproceedings{passi2019problem,
  title={Problem formulation and fairness},
  author={Passi, Samir and Barocas, Solon},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={39--48},
  year={2019}
}

@inproceedings{milli2021optimizing,
  title={From optimizing engagement to measuring value},
  author={Milli, Smitha and Belli, Luca and Hardt, Moritz},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={714--722},
  year={2021}
}

@article{stray2021you,
  title={What are you optimizing for? aligning recommender systems with human values},
  author={Stray, Jonathan and Vendrov, Ivan and Nixon, Jeremy and Adler, Steven and Hadfield-Menell, Dylan},
  journal={arXiv preprint arXiv:2107.10939},
  year={2021}
}

@article{goyal2022your,
  title={Is your toxicity my toxicity? exploring the impact of rater identity on toxicity annotation},
  author={Goyal, Nitesh and Kivlichan, Ian D and Rosen, Rachel and Vasserman, Lucy},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={6},
  number={CSCW2},
  pages={1--28},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@inproceedings{mullainathan2021inequity,
  title={On the inequity of predicting A while hoping for B},
  author={Mullainathan, Sendhil and Obermeyer, Ziad},
  booktitle={AEA Papers and Proceedings},
  volume={111},
  pages={37--42},
  year={2021},
  organization={American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203}
}

@article{campbell2017factors,
  title={Factors relevant to the validity of experiments in social settings},
  author={Campbell, Donald T},
  journal={Sociological methods},
  pages={243--263},
  year={2017},
  publisher={Routledge}
}

@incollection{gergle2014experimental,
  title={Experimental research in HCI},
  author={Gergle, Darren and Tan, Desney S},
  booktitle={Ways of Knowing in HCI},
  pages={191--227},
  year={2014},
  publisher={Springer}
}

@article{
o2005measuring,
  title={Measuring diagnoses: ICD code accuracy},
  author={O'malley, Kimberly J and Cook, Karon F and Price, Matt D and Wildes, Kimberly Raiford and Hurdle, John F and Ashton, Carol M},
  journal={Health services research},
  volume={40},
  number={5p2},
  pages={1620--1639},
  year={2005},
  publisher={Wiley Online Library}
}
@book{allen2001introduction,
  title={Introduction to measurement theory},
  author={Allen, Mary J and Yen, Wendy M},
  year={2001},
  publisher={Waveland Press}
}

@article{van2016pre,
  title={Pre-registration in social psychology—A discussion and suggested template},
  author={Van't Veer, Anna Elisabeth and Giner-Sorolla, Roger},
  journal={Journal of experimental social psychology},
  volume={67},
  pages={2--12},
  year={2016},
  publisher={Elsevier}
}

@article{xie2022benchmarking,
  title={Benchmarking emergency department prediction models with machine learning and public electronic health records},
  author={Xie, Feng and Zhou, Jun and Lee, Jin Wee and Tan, Mingrui and Li, Siqi and Rajnthern, Logasan S/O and Chee, Marcel Lucas and Chakraborty, Bibhas and Wong, An-Kwok Ian and Dagan, Alon and others},
  journal={Scientific Data},
  volume={9},
  number={1},
  pages={658},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{wu2010measurement,
  title={Measurement, sampling, and equating errors in large-scale assessments},
  author={Wu, Margaret},
  journal={Educational measurement: issues and practice},
  volume={29},
  number={4},
  pages={15--27},
  year={2010},
  publisher={Wiley Online Library}
}

@book{latour2013laboratory,
  title={Laboratory life: The construction of scientific facts},
  author={Latour, Bruno and Woolgar, Steve},
  year={2013},
  publisher={Princeton university press}
}

@article{suchman1993categories,
  title={Do categories have politics? The language/action perspective reconsidered},
  author={Suchman, Lucy},
  journal={Computer supported cooperative work (CSCW)},
  volume={2},
  pages={177--190},
  year={1993},
  publisher={Springer}
}
@book{latour2013laboratory,
  title={Laboratory life: The construction of scientific facts},
  author={Latour, Bruno and Woolgar, Steve},
  year={2013},
  publisher={Princeton university press}
}

@book{bowker2000sorting,
  title={Sorting Things Out: Classification and Its Consequences},
  author={Bowker, Geoffrey C},
  year={2000},
  publisher={MIT press}
}


@inproceedings{pine2015politics,
  title={The politics of measurement and action},
  author={Pine, Kathleen H and Liboiron, Max},
  booktitle={Proceedings of the 33rd annual ACM conference on human factors in computing systems},
  pages={3147--3156},
  year={2015}
}

@inproceedings{harvey2024cadaver,
  title={The Cadaver in the Machine: The Social Practices of Measurement and Validation in Motion Capture Technology},
  author={Harvey, Emma and Sandhaus, Hauke and Jacobs, Abigail Z and Moss, Emanuel and Sloane, Mona},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--23},
  year={2024}
}

@book{porter1996trust,
  title={Trust in numbers: The pursuit of objectivity in science and public life},
  author={Porter, Theodore M},
  year={1996},
  publisher={Princeton University Press}
}

@book{crosby1997measure,
  title={The measure of reality: Quantification in Western Europe, 1250-1600},
  author={Crosby, Alfred W},
  year={1997},
  publisher={Cambridge University Press}
}

@book{hacking1999social,
  title={The social construction of what?},
  author={Hacking, Ian},
  year={1999},
  publisher={Harvard university press}
}

@book{mol2002body,
  title={The body multiple: Ontology in medical practice},
  author={Mol, A},
  year={2002},
  publisher={Duke University Press}
}

@article{suchman1993categories,
  title={Do categories have politics? The language/action perspective reconsidered},
  author={Suchman, Lucy},
  journal={Computer supported cooperative work (CSCW)},
  volume={2},
  pages={177--190},
  year={1993},
  publisher={Springer}
}

@inproceedings{abdu2023empirical,
  title={An empirical analysis of racial categories in the algorithmic fairness literature},
  author={Abdu, Amina A and Pasquetto, Irene V and Jacobs, Abigail Z},
  booktitle={Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1324--1333},
  year={2023}
}

@inproceedings{mickel2024racial,
  title={Racial/Ethnic Categories in AI and Algorithmic Fairness: Why They Matter and What They Represent},
  author={Mickel, Jennifer},
  booktitle={The 2024 ACM Conference on Fairness, Accountability, and Transparency},
  pages={2484--2494},
  year={2024}
}


@article{hofman2023pre,
  title={Pre-registration for predictive modeling},
  author={Hofman, Jake M and Chatzimparmpas, Angelos and Sharma, Amit and Watts, Duncan J and Hullman, Jessica},
  journal={arXiv preprint arXiv:2311.18807},
  year={2023}
}

@article{dingen2018regressionexplorer,
  title={RegressionExplorer: Interactive exploration of logistic regression models with subgroup analysis},
  author={Dingen, Dennis and van't Veer, Marcel and Houthuizen, Patrick and Mestrom, Eveline HJ and Korsten, Erik HHM and Bouwman, Arthur RA and Van Wijk, Jarke},
  journal={IEEE transactions on visualization and computer graphics},
  volume={25},
  number={1},
  pages={246--255},
  year={2018},
  publisher={IEEE}
}

@inproceedings{bhattacharya2024exmos,
  title={EXMOS: Explanatory Model Steering Through Multifaceted Explanations and Data Configurations},
  author={Bhattacharya, Aditya and Stumpf, Simone and Gosak, Lucija and Stiglic, Gregor and Verbert, Katrien},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--27},
  year={2024}
}

@article{passi2018trust,
  title={Trust in data science: Collaboration, translation, and accountability in corporate data science projects},
  author={Passi, Samir and Jackson, Steven J},
  journal={Proceedings of the ACM on human-computer interaction},
  volume={2},
  number={CSCW},
  pages={1--28},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{nahar2022collaboration,
  title={Collaboration challenges in building ml-enabled systems: Communication, documentation, engineering, and process},
  author={Nahar, Nadia and Zhou, Shurui and Lewis, Grace and K{\"a}stner, Christian},
  booktitle={Proceedings of the 44th international conference on software engineering},
  pages={413--425},
  year={2022}
}

@article{mao2019data,
  title={How data scientistswork together with domain experts in scientific collaborations: To find the right answer or to ask the right question?},
  author={Mao, Yaoli and Wang, Dakuo and Muller, Michael and Varshney, Kush R and Baldini, Ioana and Dugan, Casey and Mojsilovi{\'c}, Aleksandra},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={3},
  number={GROUP},
  pages={1--23},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{zhang2020data,
  title={How do data science workers collaborate? roles, workflows, and tools},
  author={Zhang, Amy X and Muller, Michael and Wang, Dakuo},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={4},
  number={CSCW1},
  pages={1--23},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@inproceedings{kim2016emerging,
  title={The emerging role of data scientists on software development teams},
  author={Kim, Miryung and Zimmermann, Thomas and DeLine, Robert and Begel, Andrew},
  booktitle={Proceedings of the 38th International Conference on Software Engineering},
  pages={96--107},
  year={2016}
}

@article{alspaugh2018futzing,
  title={Futzing and moseying: Interviews with professional data analysts on exploration practices},
  author={Alspaugh, Sara and Zokaei, Nava and Liu, Andrea and Jin, Cindy and Hearst, Marti A},
  journal={IEEE transactions on visualization and computer graphics},
  volume={25},
  number={1},
  pages={22--31},
  year={2018},
  publisher={IEEE}
}

@article{alspaugh2018futzing,
  title={Futzing and moseying: Interviews with professional data analysts on exploration practices},
  author={Alspaugh, Sara and Zokaei, Nava and Liu, Andrea and Jin, Cindy and Hearst, Marti A},
  journal={IEEE transactions on visualization and computer graphics},
  volume={25},
  number={1},
  pages={22--31},
  year={2018},
  publisher={IEEE}
}

@article{kandel2012enterprise,
  title={Enterprise data analysis and visualization: An interview study},
  author={Kandel, Sean and Paepcke, Andreas and Hellerstein, Joseph M and Heer, Jeffrey},
  journal={IEEE transactions on visualization and computer graphics},
  volume={18},
  number={12},
  pages={2917--2926},
  year={2012},
  publisher={IEEE}
}


@article{wongsuphasawat2019goals,
  title={Goals, process, and challenges of exploratory data analysis: An interview study},
  author={Wongsuphasawat, Kanit and Liu, Yang and Heer, Jeffrey},
  journal={arXiv preprint arXiv:1911.00568},
  year={2019}
}

@inproceedings{muller2019data,
  title={How data science workers work with data: Discovery, capture, curation, design, creation},
  author={Muller, Michael and Lange, Ingrid and Wang, Dakuo and Piorkowski, David and Tsay, Jason and Liao, Q Vera and Dugan, Casey and Erickson, Thomas},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--15},
  year={2019}
}

@article{guo2024vmc,
  title={VMC: A Grammar for Visualizing Statistical Model Checks},
  author={Guo, Ziyang and Kale, Alex and Kay, Matthew and Hullman, Jessica},
  journal={arXiv preprint arXiv:2408.16702},
  year={2024}
}

@article{kale2023evm,
  title={Evm: Incorporating model checking into exploratory visual analysis},
  author={Kale, Alex and Guo, Ziyang and Qiao, Xiao Li and Heer, Jeffrey and Hullman, Jessica},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2023},
  publisher={IEEE}
}

@inproceedings{ribeiro2018anchors,
  title={Anchors: High-precision model-agnostic explanations},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott},
  journal={arXiv preprint arXiv:1705.07874},
  year={2017}
}

@inproceedings{tramer2017fairtest,
  title={Fairtest: Discovering unwarranted associations in data-driven applications},
  author={Tramer, Florian and Atlidakis, Vaggelis and Geambasu, Roxana and Hsu, Daniel and Hubaux, Jean-Pierre and Humbert, Mathias and Juels, Ari and Lin, Huang},
  booktitle={2017 IEEE European Symposium on Security and Privacy (EuroS\&P)},
  pages={401--416},
  year={2017},
  organization={IEEE}
}

@article{bellamy2019ai,
  title={AI Fairness 360: An extensible toolkit for detecting and mitigating algorithmic bias},
  author={Bellamy, Rachel KE and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovi{\'c}, Aleksandra and others},
  journal={IBM Journal of Research and Development},
  volume={63},
  number={4/5},
  pages={4--1},
  year={2019},
  publisher={IBM}
}

@article{weerts2023fairlearn,
  title={Fairlearn: Assessing and improving fairness of ai systems},
  author={Weerts, Hilde and Dud{\'\i}k, Miroslav and Edgar, Richard and Jalali, Adrin and Lutz, Roman and Madaio, Michael},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={257},
  pages={1--8},
  year={2023}
}

@article{saleiro2018aequitas,
  title={Aequitas: A bias and fairness audit toolkit},
  author={Saleiro, Pedro and Kuester, Benedict and Hinkson, Loren and London, Jesse and Stevens, Abby and Anisfeld, Ari and Rodolfa, Kit T and Ghani, Rayid},
  journal={arXiv preprint arXiv:1811.05577},
  year={2018}
}

@article{liu2024faircompass,
  title={FairCompass: Operationalising fairness in machine learning},
  author={Liu, Jessica and Chen, Huaming and Shen, Jun and Choo, Kim-Kwang Raymond},
  journal={IEEE Transactions on Artificial Intelligence},
  year={2024},
  publisher={IEEE}
}

@article{liu2024faircompass,
  title={FairCompass: Operationalising fairness in machine learning},
  author={Liu, Jessica and Chen, Huaming and Shen, Jun and Choo, Kim-Kwang Raymond},
  journal={IEEE Transactions on Artificial Intelligence},
  year={2024},
  publisher={IEEE}
}
@article{johnson2023fairkit,
  title={Fairkit, fairkit, on the wall, who’s the fairest of them all? Supporting fairness-related decision-making},
  author={Johnson, Brittany and Bartola, Jesse and Angell, Rico and Witty, Sam and Giguere, Stephen and Brun, Yuriy},
  journal={EURO Journal on Decision Processes},
  volume={11},
  pages={100031},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{cabrera2019fairvis,
  title={FairVis: Visual analytics for discovering intersectional bias in machine learning},
  author={Cabrera, {\'A}ngel Alexander and Epperson, Will and Hohman, Fred and Kahng, Minsuk and Morgenstern, Jamie and Chau, Duen Horng},
  booktitle={2019 IEEE Conference on Visual Analytics Science and Technology (VAST)},
  pages={46--56},
  year={2019},
  organization={IEEE}
}
@article{ahn2019fairsight,
  title={Fairsight: Visual analytics for fairness in decision making},
  author={Ahn, Yongsu and Lin, Yu-Ru},
  journal={IEEE transactions on visualization and computer graphics},
  volume={26},
  number={1},
  pages={1086--1095},
  year={2019},
  publisher={IEEE}
}
@article{wexler2019if,
  title={The what-if tool: Interactive probing of machine learning models},
  author={Wexler, James and Pushkarna, Mahima and Bolukbasi, Tolga and Wattenberg, Martin and Vi{\'e}gas, Fernanda and Wilson, Jimbo},
  journal={IEEE transactions on visualization and computer graphics},
  volume={26},
  number={1},
  pages={56--65},
  year={2019},
  publisher={IEEE}
}

@inproceedings{holstein2019improving,
  title={Improving fairness in machine learning systems: What do industry practitioners need?},
  author={Holstein, Kenneth and Wortman Vaughan, Jennifer and Daum{\'e} III, Hal and Dudik, Miro and Wallach, Hanna},
  booktitle={Proceedings of the 2019 CHI conference on human factors in computing systems},
  pages={1--16},
  year={2019}
}

@article{hou2017hacking,
  title={Hacking with NPOs: collaborative analytics and broker roles in civic data hackathons},
  author={Hou, Youyang and Wang, Dakuo},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={1},
  number={CSCW},
  pages={1--16},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{payne2005generalization,
  title={Generalization in qualitative research},
  author={Payne, Geoff and Williams, Malcolm},
  journal={Sociology},
  volume={39},
  number={2},
  pages={295--314},
  year={2005},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{gala2024fairtargetsim,
  title={FairTargetSim: An Interactive Simulator for Understanding and Explaining the Fairness Effects of Target Variable Definition},
  author={Gala, Dalia and Phillips-Brown, Milo and Goel, Naman and Prunkl, Carinal and Jubete, Laura Alvarez and Eitel-Porter, Ray and others},
  journal={arXiv preprint arXiv:2403.06031},
  year={2024}
}

@article{myers2016programmers,
  title={Programmers are users too: Human-centered methods for improving programming tools},
  author={Myers, Brad A and Ko, Amy J and LaToza, Thomas D and Yoon, YoungSeok},
  journal={Computer},
  volume={49},
  number={7},
  pages={44--52},
  year={2016},
  publisher={IEEE}
}

@inproceedings{kawakami2024situate,
  title={The Situate AI Guidebook: Co-Designing a Toolkit to Support Multi-Stakeholder, Early-stage Deliberations Around Public Sector AI Proposals},
  author={Kawakami, Anna and Coston, Amanda and Zhu, Haiyi and Heidari, Hoda and Holstein, Kenneth},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={1--22},
  year={2024}
}

@inproceedings{hazzan2004human,
  title={Human aspects of software engineering: The case of extreme programming},
  author={Hazzan, Orit and Tomayko, Jim},
  booktitle={International Conference on Extreme Programming and Agile Processes in software Engineering},
  pages={303--311},
  year={2004},
  organization={Springer}
}

@book{seffah2005human,
  title={Human-centered software engineering-integrating usability in the software development lifecycle},
  author={Seffah, Ahmed and Gulliksen, Jan and Desmarais, Michel C},
  volume={8},
  year={2005},
  publisher={Springer Science \& Business Media}
}

@article{ko2011state,
  title={The state of the art in end-user software engineering},
  author={Ko, Amy J and Abraham, Robin and Beckwith, Laura and Blackwell, Alan and Burnett, Margaret and Erwig, Martin and Scaffidi, Chris and Lawrance, Joseph and Lieberman, Henry and Myers, Brad and others},
  journal={ACM Computing Surveys (CSUR)},
  volume={43},
  number={3},
  pages={1--44},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@inproceedings{guo2011proactive,
  title={Proactive wrangling: Mixed-initiative end-user programming of data transformation scripts},
  author={Guo, Philip J and Kandel, Sean and Hellerstein, Joseph M and Heer, Jeffrey},
  booktitle={Proceedings of the 24th annual ACM symposium on User interface software and technology},
  pages={65--74},
  year={2011}
}

@inproceedings{kandel2011wrangler,
  title={Wrangler: Interactive visual specification of data transformation scripts},
  author={Kandel, Sean and Paepcke, Andreas and Hellerstein, Joseph and Heer, Jeffrey},
  booktitle={Proceedings of the sigchi conference on human factors in computing systems},
  pages={3363--3372},
  year={2011}
}

@inproceedings{cabrera2023zeno,
  title={Zeno: An interactive framework for behavioral evaluation of machine learning},
  author={Cabrera, {\'A}ngel Alexander and Fu, Erica and Bertucci, Donald and Holstein, Kenneth and Talwalkar, Ameet and Hong, Jason I and Perer, Adam},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--14},
  year={2023}
}

@article{wongsuphasawat2015voyager,
  title={Voyager: Exploratory analysis via faceted browsing of visualization recommendations},
  author={Wongsuphasawat, Kanit and Moritz, Dominik and Anand, Anushka and Mackinlay, Jock and Howe, Bill and Heer, Jeffrey},
  journal={IEEE transactions on visualization and computer graphics},
  volume={22},
  number={1},
  pages={649--658},
  year={2015},
  publisher={IEEE}
}

@inproceedings{yan2021tessera,
  title={Tessera: Discretizing data analysis workflows on a task level},
  author={Yan, Jing Nathan and Gu, Ziwei and Rzeszotarski, Jeffrey M},
  booktitle={Proceedings of the 2021 CHI conference on human factors in computing systems},
  pages={1--15},
  year={2021}
}

@book{rattenbury2017principles,
  title={Principles of data wrangling: Practical techniques for data preparation},
  author={Rattenbury, Tye and Hellerstein, Joseph M and Heer, Jeffrey and Kandel, Sean and Carreras, Connor},
  year={2017},
  publisher={" O'Reilly Media, Inc."}
}

@inproceedings{mitchell2019model,
  title={Model cards for model reporting},
  author={Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={220--229},
  year={2019}
}

@article{gebru2021datasheets,
  title={Datasheets for datasets},
  author={Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Iii, Hal Daum{\'e} and Crawford, Kate},
  journal={Communications of the ACM},
  volume={64},
  number={12},
  pages={86--92},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{pushkarna2022data,
  title={Data cards: Purposeful and transparent dataset documentation for responsible ai},
  author={Pushkarna, Mahima and Zaldivar, Andrew and Kjartansson, Oddur},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1776--1826},
  year={2022}
}

@inproceedings{kery2018story,
  title={The story in the notebook: Exploratory data science using a literate programming tool},
  author={Kery, Mary Beth and Radensky, Marissa and Arya, Mahima and John, Bonnie E and Myers, Brad A},
  booktitle={Proceedings of the 2018 CHI conference on human factors in computing systems},
  pages={1--11},
  year={2018}
}

@article{pang2020deep,
  title={Deep learning with tensorflow: A review},
  author={Pang, Bo and Nijkamp, Erik and Wu, Ying Nian},
  journal={Journal of Educational and Behavioral Statistics},
  volume={45},
  number={2},
  pages={227--248},
  year={2020},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@incollection{gergle2014experimental,
  title={Experimental research in HCI},
  author={Gergle, Darren and Tan, Desney S},
  booktitle={Ways of Knowing in HCI},
  pages={191--227},
  year={2014},
  publisher={Springer}
}

@book{everett2013introduction,
  title={An introduction to latent variable models},
  author={Everett, B},
  year={2013},
  publisher={Springer Science \& Business Media}
}



@inproceedings{koh2021wilds,
  title={Wilds: A benchmark of in-the-wild distribution shifts},
  author={Koh, Pang Wei and Sagawa, Shiori and Marklund, Henrik and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and others},
  booktitle={International conference on machine learning},
  pages={5637--5664},
  year={2021},
  organization={PMLR}
}

@article{rambachan2022robust,
  title={Robust Design and Evaluation of Predictive Algorithms under Unobserved Confounding},
  author={Rambachan, Ashesh and Coston, Amanda and Kennedy, Edward},
  journal={arXiv preprint arXiv:2212.09844},
  year={2022}
}

@inproceedings{muller2021designing,
  title={Designing ground truth and the social life of labels},
  author={Muller, Michael and Wolf, Christine T and Andres, Josh and Desmond, Michael and Joshi, Narendra Nath and Ashktorab, Zahra and Sharma, Aabhas and Brimijoin, Kristina and Pan, Qian and Duesterwald, Evelyn and others},
  booktitle={Proceedings of the 2021 CHI conference on human factors in computing systems},
  pages={1--16},
  year={2021}
}

@article{chen2023judgment,
  title={Judgment sieve: Reducing uncertainty in group judgments through interventions targeting ambiguity versus disagreement},
  author={Chen, Quan Ze and Zhang, Amy X},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={7},
  number={CSCW2},
  pages={1--26},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@inproceedings{bragg2018sprout,
  title={Sprout: Crowd-powered task design for crowdsourcing},
  author={Bragg, Jonathan and Mausam and Weld, Daniel S},
  booktitle={Proceedings of the 31st annual acm symposium on user interface software and technology},
  pages={165--176},
  year={2018}
}

@inproceedings{chang2017revolt,
  title={Revolt: Collaborative crowdsourcing for labeling machine learning datasets},
  author={Chang, Joseph Chee and Amershi, Saleema and Kamar, Ece},
  booktitle={Proceedings of the 2017 CHI conference on human factors in computing systems},
  pages={2334--2346},
  year={2017}
}

@inproceedings{k2019taskmate,
  title={Taskmate: A mechanism to improve the quality of instructions in crowdsourcing},
  author={K. Chaithanya Manam, V and Jampani, Dwarakanath and Zaim, Mariam and Wu, Meng-Han and J. Quinn, Alexander},
  booktitle={Companion Proceedings of The 2019 World Wide Web Conference},
  pages={1121--1130},
  year={2019}
}

@inproceedings{manam2018wingit,
  title={Wingit: Efficient refinement of unclear task instructions},
  author={Manam, VK and Quinn, Alexander},
  booktitle={Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
  volume={6},
  pages={108--116},
  year={2018}
}


@inproceedings{desmond2021increasing,
  title={Increasing the speed and accuracy of data labeling through an ai assisted interface},
  author={Desmond, Michael and Muller, Michael and Ashktorab, Zahra and Dugan, Casey and Duesterwald, Evelyn and Brimijoin, Kristina and Finegan-Dollak, Catherine and Brachman, Michelle and Sharma, Aabhas and Joshi, Narendra Nath and others},
  booktitle={Proceedings of the 26th International Conference on Intelligent User Interfaces},
  pages={392--401},
  year={2021}
}
@misc{doccano,
  title={{doccano}: Text Annotation Tool for Human},
  url={https://github.com/doccano/doccano},
  note={Software available from https://github.com/doccano/doccano},
  author={
    Hiroki Nakayama and
    Takahiro Kubo and
    Junya Kamura and
    Yasufumi Taniguchi and
    Xu Liang},
  year={2018},
}

@inproceedings{daudert2020web,
  title={A web-based collaborative annotation and consolidation tool},
  author={Daudert, Tobias},
  booktitle={Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages={7053--7059},
  year={2020}
}


@inproceedings{greis2017designing,
  title={Designing for uncertainty in hci: When does uncertainty help?},
  author={Greis, Miriam and Hullman, Jessica and Correll, Michael and Kay, Matthew and Shaer, Orit},
  booktitle={Proceedings of the 2017 CHI conference extended abstracts on human factors in computing systems},
  pages={593--600},
  year={2017}
}
@inproceedings{bhatt2021uncertainty,
  title={Uncertainty as a form of transparency: Measuring, communicating, and using uncertainty},
  author={Bhatt, Umang and Antor{\'a}n, Javier and Zhang, Yunfeng and Liao, Q Vera and Sattigeri, Prasanna and Fogliato, Riccardo and Melan{\c{c}}on, Gabrielle and Krishnan, Ranganath and Stanley, Jason and Tickoo, Omesh and others},
  booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={401--413},
  year={2021}
}

@inproceedings{kay2016ish,
  title={When (ish) is my bus? user-centered visualizations of uncertainty in everyday, mobile predictive systems},
  author={Kay, Matthew and Kola, Tara and Hullman, Jessica R and Munson, Sean A},
  booktitle={Proceedings of the 2016 chi conference on human factors in computing systems},
  pages={5092--5103},
  year={2016}
}


@inproceedings{lakkaraju2017selective,
  title={The selective labels problem: Evaluating algorithmic predictions in the presence of unobservables},
  author={Lakkaraju, Himabindu and Kleinberg, Jon and Leskovec, Jure and Ludwig, Jens and Mullainathan, Sendhil},
  booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={275--284},
  year={2017}
}


@inproceedings{fogliato2020fairness,
  title={Fairness evaluation in presence of biased noisy labels},
  author={Fogliato, Riccardo and Chouldechova, Alexandra and G’Sell, Max},
  booktitle={International conference on artificial intelligence and statistics},
  pages={2325--2336},
  year={2020},
  organization={PMLR}
}


@inproceedings{fernandez2018aurum,
  title={Aurum: A data discovery system},
  author={Fernandez, Raul Castro and Abedjan, Ziawasch and Koko, Famien and Yuan, Gina and Madden, Samuel and Stonebraker, Michael},
  booktitle={2018 IEEE 34th International Conference on Data Engineering (ICDE)},
  pages={1001--1012},
  year={2018},
  organization={IEEE}
}


@article{nargesian2019data,
  title={Data lake management: challenges and opportunities},
  author={Nargesian, Fatemeh and Zhu, Erkang and Miller, Ren{\'e}e J and Pu, Ken Q and Arocena, Patricia C},
  journal={Proceedings of the VLDB Endowment},
  volume={12},
  number={12},
  pages={1986--1989},
  year={2019},
  publisher={VLDB Endowment}
}

@article{paton2023dataset,
  title={Dataset discovery and exploration: A survey},
  author={Paton, Norman W and Chen, Jiaoyan and Wu, Zhenyu},
  journal={ACM Computing Surveys},
  volume={56},
  number={4},
  pages={1--37},
  year={2023},
  publisher={ACM New York, NY, USA}
}


@inproceedings{bogatu2020dataset,
  title={Dataset discovery in data lakes},
  author={Bogatu, Alex and Fernandes, Alvaro AA and Paton, Norman W and Konstantinou, Nikolaos},
  booktitle={2020 ieee 36th international conference on data engineering (icde)},
  pages={709--720},
  year={2020},
  organization={IEEE}
}

@article{gala2024fairtargetsim,
  title={FairTargetSim: An Interactive Simulator for Understanding and Explaining the Fairness Effects of Target Variable Definition},
  author={Gala, Dalia and Phillips-Brown, Milo and Goel, Naman and Prunkl, Carinal and Jubete, Laura Alvarez and Eitel-Porter, Ray and others},
  journal={arXiv preprint arXiv:2403.06031},
  year={2024}
}

@article{de2021leveraging,
  title={Leveraging expert consistency to improve algorithmic decision support},
  author={De-Arteaga, Maria and Jeanselme, Vincent and Dubrawski, Artur and Chouldechova, Alexandra},
  journal={arXiv preprint arXiv:2101.09648},
  year={2021}
}

@inproceedings{lau2020design,
  title={The design space of computational notebooks: An analysis of 60 systems in academia and industry},
  author={Lau, Sam and Drosos, Ian and Markel, Julia M and Guo, Philip J},
  booktitle={2020 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
  pages={1--11},
  year={2020},
  organization={IEEE}
}

@inproceedings{johnson2022fairkit,
  title={Fairkit-learn: a fairness evaluation and comparison toolkit},
  author={Johnson, Brittany and Brun, Yuriy},
  booktitle={Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
  pages={70--74},
  year={2022}
}

@inproceedings{deng2022exploring,
  title={Exploring how machine learning practitioners (try to) use fairness toolkits},
  author={Deng, Wesley Hanwen and Nagireddy, Manish and Lee, Michelle Seng Ah and Singh, Jatinder and Wu, Zhiwei Steven and Holstein, Kenneth and Zhu, Haiyi},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={473--484},
  year={2022}
}


@article{wang2019data,
  title={How data scientists use computational notebooks for real-time collaboration},
  author={Wang, April Yi and Mittal, Anant and Brooks, Christopher and Oney, Steve},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={3},
  number={CSCW},
  pages={1--30},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{rule2018exploration,
  title={Exploration and explanation in computational notebooks},
  author={Rule, Adam and Tabard, Aur{\'e}lien and Hollan, James D},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2018}
}


@article{sharma2020dowhy,
  title={DoWhy: An end-to-end library for causal inference},
  author={Sharma, Amit and Kiciman, Emre},
  journal={arXiv preprint arXiv:2011.04216},
  year={2020}
}

@inproceedings{pirolli2005sensemaking,
  title={The sensemaking process and leverage points for analyst technology as identified through cognitive task analysis},
  author={Pirolli, Peter and Card, Stuart},
  booktitle={Proceedings of international conference on intelligence analysis},
  volume={5},
  pages={2--4},
  year={2005},
  organization={McLean, VA, USA}
}

@article{cabrera2023did,
  title={What did my AI learn? How data scientists make sense of model behavior},
  author={Cabrera, {\'A}ngel Alexander and Tulio Ribeiro, Marco and Lee, Bongshin and Deline, Robert and Perer, Adam and Drucker, Steven M},
  journal={ACM Transactions on Computer-Human Interaction},
  volume={30},
  number={1},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY}
}

@article{rahwan2019machine,
  title={Machine behaviour},
  author={Rahwan, Iyad and Cebrian, Manuel and Obradovich, Nick and Bongard, Josh and Bonnefon, Jean-Fran{\c{c}}ois and Breazeal, Cynthia and Crandall, Jacob W and Christakis, Nicholas A and Couzin, Iain D and Jackson, Matthew O and others},
  journal={Nature},
  volume={568},
  number={7753},
  pages={477--486},
  year={2019},
  publisher={Nature Publishing Group UK London}
}



@article{turque2012creative,
  title={Creative... motivating’and fired},
  author={Turque, Bill},
  journal={The Washington Post},
  volume={6},
  year={2012}
}

@article{maitlis2014sensemaking,
  title={Sensemaking in organizations: Taking stock and moving forward},
  author={Maitlis, Sally and Christianson, Marlys},
  journal={Academy of management annals},
  volume={8},
  number={1},
  pages={57--125},
  year={2014},
  publisher={Routledge}
}