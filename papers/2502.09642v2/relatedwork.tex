\section{Related Work and Background}
There have been rapid advancements in the field of AI since the Transformers \cite{vaswani2023attention} came out. It has led to notable increase in endeavors dedicated to constructing versatile conversational AI systems adept at comprehending and engaging with users across multiple topics and open ended conversations. 

General purpose LLMs are fundamentally changing how software and applications are being built which is further dramatically changing user experiences. Some of the most popular LLMs which have lead to this change are GPT-3.5 \cite{achiam2023gpt, brown2020language}, LLaMA \cite{touvron2023llama}, Gemini \cite{geminiteam2023gemini}, Anthropic Claude \cite{claude}, Mistral \cite{jiang2023mistral}, Inflection \cite{inflection}, and Grok-1 \cite{grok}. 

Brown et al.\cite{brown2020language} demonstrated the feasibility of generating coherent and contextually relevant responses in various languages, including Indic languages, using large language models.
% Furthermore, Kadavath and Askell et al.'s contributions to the field are evident in series of their `Anthropic papers` \cite{Askell2021AGL}, \cite{kadavath2022language}, where it discusses the unique challenges and opportunities in leveraging transformer-based architectures for conversational AI. Anthropic's insights have spurred further exploration into the application of advanced neural network models for enhancing conversational agents accepting very large context windows without sacrificing much on latency.
Building upon the success of GPTs and Claude \cite{claude, Askell2021AGL, kadavath2022language}, subsequent research endeavors have further propelled the development of conversational AI in the Indic language domain. One notable participant in this progression is Gemini/Bard project \cite{geminiteam2023gemini}. It has significantly advanced the state-of-the-art in conversational AI by leveraging large-scale pre-training techniques. Gemini/Bard's approach has led to substantial improvements in language understanding and generation, particularly in low-resource languages such as Hindi, Bengali and Tamil. Mistral \cite{jiang2023mistral} addressed low performance in European languages by collecting and prioritizing European languages along with English.

As most of these LLMs are trained on English or high resource languages, there are several limitations in adapting them for regional or local use cases, both at knowledge level (pre-training) and inference level (high token to word ratio).  Performance of these state-of-the-art models on Indic languages is far from the performance on English and European languages and therefore remained an open problem. Furthermore, most of these LLMs are biased towards non-Indic regions due to significantly lower volume of Indic data and therefore do not work for countries like India that have a rich and diverse landscape, culture and languages. 

Several Indian-origin fine-tuned versions of LLMs have emerged, presenting a promising array of open-source models such as OpenHathi tuned Airavata \cite{gala2024airavata}, Gemma based Navarsa \cite{NavarasaTeluguLLMLabs}, Kannada LLaMA, Tamil LLaMA \cite{balachandran2023tamilllama}, Odia LLaMA \cite{kohli2023building}, and other vernacular models. These models are constructed upon the open source Llama2 architecture, leveraging cutting-edge techniques like Parameter Efficient Fine-tuning (PEFT) \cite{houlsby2019parameter,hu2021lora}. However, a predominant characteristic/limitations of these models is their focus on monolingual or bilingual generation capabilities and lack of Indic knowledge and sentence construction.

Furthermore, initiatives such as Perplexity AI \cite{perplexity}, BingChat \cite{bing} and You.com \cite{you} have also made noteworthy strides in advancing conversational AI by providing concise answers with source links for verification, making it noteworthy for more factual research and getting factual information by having robust Web search with Retrieval Augmented Generation (WebRAG) pipelines. These efforts emphasises the importance of AI assistants being more personalized, truthful, accurate, and transparent.

In the landscape of natural language processing models, particularly in the realm of Indian languages, there exists a noticeable gap in understanding the nuances of the Indian context, including local vernacular dialects, socio-economic structures, and cultural intricacies. Many existing models lack the depth required to effectively cater to these specific requirements. Thus, the necessity arises to develop indigenous systems tailored to the needs of Indian users.

In light of these advancements, the Krutrim LLM endeavors to enhance both accuracy and speed, positioning itself as a versatile and efficient general-purpose chat assistant. By synthesizing insights from existing Indian-origin LLMs and incorporating innovative methodologies, Krutrim aims to bridge the gap between state-of-the-art language models and the unique linguistic and cultural landscape of India.

In this report, we undertake an examination of current LLMs and frameworks, accentuating their attributes, capabilities, and constraints related to Indic use cases. We offer a comparative analysis, elucidating how Krutrim LLM, enhanced by WebRAG integration, stands in relation to these existing solutions.

% TODO:

% Comparison against general purpose LLM
% Transformer paper
% Instruct GPT paper
% Anthropic
% Mistral Lay app
% Groq
% Inflection AI
% perplexity AI
% PT and CPT papers for techniques
% Llama
% Gemma
% Yi 
% jais
% Qwen
% Mistral
% Multi lingual openhathi, tamil llama, kan llama, odia llama.