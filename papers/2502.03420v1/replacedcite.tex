\section{RELATED WORK}
\label{sec:related_work}

Face aging research focuses on transforming a person’s face to predict how they might look at different ages. Most approaches rely on generative models, particularly Generative Adversarial Networks (GANs)____. While these models produce compelling results, they often struggle to preserve identity details throughout the aging process. To address this, Wang et al.____ proposed IPCGANs, which incorporate identity-preserving constraints by ensuring output images retain essential CNN-extracted features of the input face.

A persistent challenge in face aging is the reliance on age-labeled datasets, which frequently exhibit skewed age distributions that undermine both accuracy and realism. Chen et al.____ introduced FADING to mitigate this issue using diffusion-based models and large language–image pretraining. Although FADING reduces reliance on biased datasets, it can still inherit biases from the underlying diffusion model. Despite this limitation, FADING achieves more realistic facial transformations and better identity preservation.

For 3D-aware face aging, Wahid et al.____ proposed a two-step pipeline. First, they generate multi-view synthetic aging data using StyleGAN2____, a CLIP-based____ age guidance mechanism, and a 3D-aware generator for consistent aging across various angles. 
%In the second step, a diffusion-based aging model takes an input face and a target age, preserving both identity and multi-view coherence. The authors further report improved results when employing a pretrained age predictor to guide the aging process.

Although synthetic face-aging techniques have shown promise in enhancing age-invariant facial recognition____, there is comparatively little work exploring whether generative approaches genuinely benefit age estimation or regression within biometric contexts. Existing studies largely concentrate on aging transformations rather than evaluating how such synthetic data might improve the performance of age estimation models. In this paper, we aim to address these gaps by systematically examining how generative text-to-image models represent diverse demographic attributes—including age, nationality, and gender—and assessing the reliability of these synthetic portraits for training and benchmarking in age estimation tasks. Our findings, supported by extensive evaluations across 212 nationalities, 30 different ages, and balanced gender representation, highlight both the potential and the limitations of current generative techniques in accurately depicting age across varied demographics.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%