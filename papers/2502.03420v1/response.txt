\section{RELATED WORK}
\label{sec:related_work}

Face aging research focuses on transforming a person’s face to predict how they might look at different ages. Most approaches rely on generative models, particularly Generative Adversarial Networks (GANs)**Goodfellow et al., "Generative Adversarial Networks"**. While these models produce compelling results, they often struggle to preserve identity details throughout the aging process. To address this, **Wang et al., "Identity-Preserving Conditional GANs with Invertible Latents"** proposed IPCGANs, which incorporate identity-preserving constraints by ensuring output images retain essential CNN-extracted features of the input face.

A persistent challenge in face aging is the reliance on age-labeled datasets, which frequently exhibit skewed age distributions that undermine both accuracy and realism. **Chen et al., "Fading: A Diffusion-Based Framework for Realistic Face Aging"** introduced FADING to mitigate this issue using diffusion-based models and large language–image pretraining. Although FADING reduces reliance on biased datasets, it can still inherit biases from the underlying diffusion model. Despite this limitation, FADING achieves more realistic facial transformations and better identity preservation.

For 3D-aware face aging, **Wahid et al., "3D-Aware Face Aging with Synthetic Data Generation"** proposed a two-step pipeline. First, they generate multi-view synthetic aging data using StyleGAN2**Karras et al., "Analyzing and Improving the Statistical Regularities of Generative Adversarial Networks"**, a CLIP-based **Radford et al., "Learning to Generate Long-Term Image Sequences with a Conditional Random Field Model"** age guidance mechanism, and a 3D-aware generator for consistent aging across various angles. 

Although synthetic face-aging techniques have shown promise in enhancing age-invariant facial recognition**Suo et al., "A Survey on Face Aging and Face Recognition: A Comprehensive Review"**, there is comparatively little work exploring whether generative approaches genuinely benefit age estimation or regression within biometric contexts. Existing studies largely concentrate on aging transformations rather than evaluating how such synthetic data might improve the performance of age estimation models. In this paper, we aim to address these gaps by systematically examining how generative text-to-image models represent diverse demographic attributes—including age, nationality, and gender—and assessing the reliability of these synthetic portraits for training and benchmarking in age estimation tasks. Our findings, supported by extensive evaluations across 212 nationalities, 30 different ages, and balanced gender representation, highlight both the potential and the limitations of current generative techniques in accurately depicting age across varied demographics.