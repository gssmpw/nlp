\section{Additional Material}
\label{app:additional_material}

% \begin{figure}[!t]
%     \centering
%     \includegraphics[width=0.7\columnwidth, trim={0 0 0 1cm},clip]{Figures/Distribution_of_topics.png}
%     \caption{Distribution of notes' topics, with and without a fact-checking source.}
%     \label{fig:topics}
% \end{figure}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{Figures/notes_per_month.png}
    \caption{A histogram of the number of community notes written every month and their rating (\textit{helpful}, \textit{not helpful}, or \textit{needs more data}. The grey vertical line (December 2022) indicates the date when the community notes became visible worldwide.}
    \label{fig:notes_per_month}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{Figures/link_types_only_helpful.png}
    \caption{The categories of links used by Community notes' authors as a source, filtering for notes rated as ``helpful''.}
    \label{fig:link_types_helpful}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\textwidth]{Figures/link_types_only_not_helpful.png}
    \caption{The categories of links used by Community notes' authors as a source, filtering for notes rated as ``not helpful''.}
    \label{fig:link_types_not_helpful}
\end{figure*}


\begin{figure*}
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/ratings_of_notes_2.png}
    \caption{Community ratings of notes with and without fact-checking source.}
    \label{fig:notes_individual_ratings}
\end{figure*}

\begin{table*}
 \resizebox{1.0\textwidth}{!}
 {%
 \fontsize{8}{8}\selectfont
 \sisetup{table-format = 3.2, group-minimum-digits=3}
    \begin{tabular}{llll}
        \toprule
        Name & URL & Language & Region/domain \\
        \midrule
        Lead stories & leadstories.com & English & Global \\
        AFP Factuel & factuel.afp.com & French & Global \\
        AAP FactCheck & aap.com.au/factcheck & English & Australia \\
        Full Fact & fullfact.org & English & Global \\
        Science Feedback & science.feedback.org & English & Science \\
        Politifact & politifact.com & English, Spanish & USA \\
        HoaxEye & hoaxeye.wordpress.com & English & Images \\
        Logically Facts & logicallyfacts.com & Multiple & Europe/India \\
        FactCheckNI & factcheckni.org & English & North Ireland \\
        DFRLab & dfrlab.org & English & Global \\
        FactReview & factreview.gr & Greek & Global \\
        Lupa & lupa.uol.com.br/jornalismo & Portuguese & Global \\
        Check your fact & checkyourfact.com & English & Global \\
        Climate feedback & climatefeedback.org & English & Climate \\
        Factcheck & factcheck.org & English & USA \\
        Health feedback & healthfeedback.org & English & Health \\
        Snopes & snopes.com & English & US \\
        aosfatos & aosfatos.org & Portuguese & Global \\
        Demagog & demagog.org.pl/fake\_news & Polish & Poland \\
        FakeReporter & fakereporter.net & Hebrew & Israel \\
        litmus factcheck & litmus-factcheck.jp & Japanese & Japan \\
        Climate Feedback & climatefeedback.org & English & Global \\
        AFP & factcheck.afp.com & English & Global \\
        USA Today & usatoday.com/story/news/factcheck & English & USA \\
        Statesman & statesman.com & English & USA \\
        Dallas News & dallasnews.com/news/politifact & English & USA \\
        Google Fact Check & toolbox.google.com/factcheck & English & Global \\
        MediaBias/FactCheck & mediabiasfactcheck.com & English & Global \\
        MedDMO & meddmo.eu & English, Greek & Greece, Cyprus, Malta \\
        Poynter & poynter.org/fact-checking & English & USA \\
        Newsmeter & newsmeter.in/fact-check & English, Tamil & India \\
        Africa Check & africacheck.org & English & Africa \\
        Fact Crescendo India & english.factcrescendo.com & English & India \\
        Factseeker & factseeker.lk & English & Sri Lanka \\
        Fact Crescendo Thailand & thailand.factcrescendo.com & Thai & Thailand \\
        Fact Crescendo Afghanistan & afghanistan.factcrescendo.com & Persian & Afghanistan \\
        Only Fact & onlyfact.in & English & India \\
        Factly & factly.in & English & India \\
        Fact Crescendo Sri Lanka & srilanka.factcrescendo.com & Sinhala & Sri Lanka \\
        Fact Crescendo Cambodia & cambodia.factcrescendo.com & Cambodian & Cambodia \\
        Becid & becid.eu & Baltic langs & Baltic \\
        Fact Hunt & facthunt.in & English & India \\
        Tec Arp & techarp.com & English & Global (based in Malaysia) \\
        10 news & 10news.com/news/fact-or-fiction & English & USA \\
        RMIT Fact Check & rmit.edu.au & English & Australia \\
        Gigafact & gigafact.org & English & USA \\
        Ayupp & ayupp.com/fact-check & English & India \\
        The Journal & thejournal.ie & English & Ireland \\
    \bottomrule
    \end{tabular}
}
\caption{List of professional fact-checking organisations and their URLs.}
\label{tab:fact_check_orgs}
\end{table*}

\begin{table*}
    \centering
    \resizebox{1.0\textwidth}{!}
    {%
    \fontsize{8}{8}\selectfont
    \sisetup{table-format = 3.2, group-minimum-digits=3}
    \begin{tabular}{ll|ll}
    \toprule
    \textbf{Domain} & \textbf{Category} & \textbf{Domain} & \textbf{Category} \\
    \midrule
    x.com & social media           & thehill.com & news \\
    twitter.com & social media     & amp.theguardian.com & news \\
    youtube.com & social media     & whitehouse.gov & government \\
    youtu.be & social media        & news.sky.com & news \\
    un.org & organisation          & merriam-webster.com & reference \\
    u.today & news                 & techarp.com & news \\
    t.co & social media            & cbc.ca & news \\
    snopes.com & fact checking     & politifact.com & fact checking \\
    en.m.wikipedia.org & reference & pbs.org & commercial \\
    en.wikipedia.org & reference   & telegraph.co.uk & news \\
    google.com & search engine     & businessinsider.com & news \\
    instagram.com & social media   & time.com & news \\
    britannica.com & reference     & justice.gov & government \\
    reuters.com & news             & cnbc.com & news \\
    bbc.co.uk & news               & wsj.com & news \\
    apnews.com & news              & sciencedirect.com & academic \\
    bbc.com & news                 & msn.com & news \\
    nytimes.com & news             & statista.com & reference \\
    theguardian.com & news         & business.x.com & commercial \\
    vice.com & news                & amp.cnn.com & news \\
    usatoday.com & news            & congress.gov & government \\
    factcheck.org & fact checking  & factcheck.afp.com & fact checking \\
    cnn.com & news                 & yahoo.com & search engine \\
    washingtonpost.com & news      & timesofindia.indiatimes.com & news \\
    ncbi.nlm.nih.gov & academic    & thelancet.com & academic \\
    nbcnews.com & news             & hrw.org & organisation \\
    help.twitter.com & reference   & healthfeedback.org & fact checking \\
    cdc.gov & government           & fda.gov & government \\
    npr.org & news                 & m.youtube.com & social media \\
    forbes.com & news              & law.cornell.edu & academic \\
    newsweek.com & news            & medium.com & blog post \\
    fullfact.org & fact checking   & healthfeedback.org & fact checking \\
    dailymail.co.uk & news         & who.int & organisation \\
    cbsnews.com & news             & haaretz.com & news \\
    web3antivirus.io & database    & axios.com & news \\
    timesofisrael.com & news       & mayoclinic.org & commercial \\
    help.x.com & reference         & nejm.org & academic \\
    nypost.com & news              & scienceexchange.caltech.edu & academic \\
    aljazeera.com & news           & indiatoday.in & news \\
    reddit.com & social media      & bloomberg.com & news \\
    independent.co.uk & news       & pewresearch.org & academic \\
    usgs.gov & academic            & jamanetwork.com & academic \\
    abcnews.go.com & news          & leadstories.com & news \\
    nature.com & academic          & dictionary.cambridge.org & reference \\
    gov.uk & government            & jpost.com & news \\
    web.archive.org & database     & archive.ph & database \\
    foxnews.com & news             & healthline.com & commercial \\
    tiktok.com & social media      & abc.net.au & news \\
    edition.cnn.com & news         & france24.com & news \\
    \bottomrule
    \end{tabular}
    }
    \caption{List of top 100 most common domains found in the community notes dataset, and their categorization.}
    \label{tab:top_domains}
\end{table*}

\begin{table*}

\begin{tabular}{lp{14cm}}
\toprule
ID & summary \\
\midrule
0 & This claim ruled mostly false. \url{https://www.politifact.com/factchecks/2020/may/07/facebook-posts/facebook-post-cites-doctors-widely-disputed-calcul/} \\
1 & The RedState article claims ``the shots do not stop transmission of the virus. This is false.    ''``Vaccines provide significant protection from 'getting it' – infection – and 'spreading it' – transmission – even against the delta variant.''    Source:    \url{https://www.usatoday.com/story/news/factcheck/2021/11/17/fact-check-covid-19-vaccines-protect-against-infection-transmission/6403678001/} \\
2 & There is no proof of this, the photo is real, it's not the last photo of the child.  But snoops say there is a tenuous link the parents used the same law firm to represent them as Maxwell      \url{https://www.snopes.com/fact-check/ghislaine-maxwell-jonbenet-ramsey/} \\
3 & unfounded    \url{https://www.snopes.com/fact-check/ashley-biden-diary-afraid/}   \\
4 & The mRNA vaccine does not cause cancer:  \url{https://www.factcheck.org/2024/05/still-no-evidence-covid-19-vaccination-increases-cancer-risk-despite-posts/} \\
5 & Many of the details in this popular essay are inaccurate and too numerous to list here.  The essay was fact checked by Snopes in 2005:  \url{https://www.snopes.com/fact-check/the-price-they-paid/}   \\
6 & POLITIFACT - rates False.   The report analysed a small sample of 128 temp stations out of several thousand volunteer-run stations, then extrapolated results. NOAA uses 2 programs to record daily temps. The report did not look at the 900 more sophisticated automated stations.   \url{https://www.politifact.com/factchecks/2022/aug/19/facebook-posts/fact-checking-talking-point-about-corrupted-climat/}   \\
7 & There is no verifiable evidence of campaign espionage in either the 2020 or the 2016 presidential elections.    \url{https://www.snopes.com/fact-check/obama-spying-trump-campaign/}  \url{https://www.washingtonpost.com/politics/2019/05/06/whats-evidence-spying-trumps-campaign-heres-your-guide/} \\
8 & Ladapo did get caught altering COVID vaccine study findings. Ladapo replaced the language from an earlier study draft that found no significant risk from COVID vaccines, to then state there was a high risk    \url{https://healthfeedback.org/claimreview/analysis-florida-department-health-surgeon-general-joseph-ladopo-contains-multiple-methodological-problems-covid-19-mrna-vaccines/}    \url{https://healthexec.com/topics/clinical/COVID-19/florida-surgeon-general-altered-covid-19-study-findings} \\
\bottomrule
\end{tabular}
\caption{Examples of community notes containing fact-checking sources that are rated as having \textit{notHelpfulSourcesMissingOrUnreliable}.}
\label{tab:notes_with_bad_source.}
\end{table*}

This section details additional results or material referenced from the paper's main body.

% \noindent \textbf{\Cref{fig:topics}} Distribution of notes' topics, with and without a fact-checking source.

\noindent \textbf{\Cref{fig:notes_per_month}} A histogram of the number of community notes written every month and their rating (\textit{helpful}, \textit{not helpful}, or \textit{needs more data}).

\noindent \textbf{\Cref{fig:link_types_helpful}} The categories of links used by Community notes' authors as a source, filtering for notes rated as ``helpful''.

\noindent \textbf{\Cref{fig:link_types_not_helpful}} The categories of links used by Community notes' authors as a source, filtering for notes rated as ``not helpful''.

% \noindent \textbf{\Cref{fig:annotations}} Mean scores of community annotations of misleading posts.

\noindent \textbf{\Cref{fig:notes_individual_ratings}} Community ratings of notes with and without fact-checking source.

\noindent \textbf{\Cref{tab:fact_check_orgs}} List of professional fact-checking organisations and their URLs.

\noindent \textbf{\Cref{tab:fact_check_orgs}} List of top 100 most common domains found in the community notes dataset, and their categorization.

\noindent \textbf{\Cref{tab:notes_with_bad_source.}} Examples of community notes containing fact-checking sources that are rated as having \textit{notHelpfulSourcesMissingOrUnreliable}.

% \noindent \textbf{\Cref{tab:community_annotation_example}} A sample of tweets, notes, and their community annotations, as well as whether the note contains a fact-checking link.

\section{Reproducibility}
\label{app:reproducibility}


\begin{figure*}[t]
\begin{lstlisting}[label=lst:prompt_link, caption=The prompt used to classify URLs into categories., numbers=none]
SYSTEM PROMPT
You are a professional IT system who has a vast knowledge of the internet and its content. Your goal is simple, but very important: Classify URLs into categories. Choose only from the provided categories!


USER PROMPT
Read the following URLs.
Your goal is to categorize each url into one of the pre-defined categories.

Chose from the following list of categories: 
Categories = 
[
    "social media",  # Social media sites like Facebook, Twitter, Youtube etc.
    "news",  # Websites of news outlets or other organisations that report current events, such as the nytimes, the guardian, etc.
    "government",  # Government agencies and organisations, as well as websites related to policies and guidelines,  such as the CDC, department of education, FDA, etc.
    "academic",  # Academic sources, journals, and magazines, such as pubmed, nature, sciencedirect, etc.
    "blog post",  # Independent blog posts about various topics, including cooking, travel, home improvement, fandom, reviews, etc.
    "fact checking",  # professional fact checking organisations
    "database",  # Public databases such as google drive, archive.com, dropbox, etc.
    "commercial",  # Webpages of commercial organisations such as BMW, Delta, Nike, etc.
    "reference",  # Public resources such as encyclopedias, dictionaries, advocacy sources, guides, DIYs, statistics, religious sources, travel information, usage guidelines, Q&As, terms of services, etc.
    "organisation",  # non-commercial and non-government organisations such as WHO, the UN, Greenpeace, LA-Lakers, etc.
    "other",  # Any other website that does not fit into one of the previous categories.
    "unknown",  # if it is impossible to determine the category of the webpage.
]

Output format example:
[
    {
        id: <ID>,
        url: <URL>,
        category: <CATEGORY>,
    }
]


URLs:
<URLS>
\end{lstlisting}
\label{prompt_link}
\end{figure*}



\begin{figure*}[t]
\begin{lstlisting}[label=lst:prompt_conspiracy, caption=The prompt used to classify tweets and notes into broader narratives and conspiracy theories., numbers=none]
SYSTEM PROMPT
You are a professional fact-checker who specializes in analyzing misinformation spread on social media. 
Your goal is to analyse a tweet and a community note written about the tweet and decide whether the tweet spread misinformation related to a known conspiracy theory or a misleading wider narrative, and if so, which one is it.



USER PROMPT
Read the following tweets and community notes written about them.\nYour goal is to analyse them and decide whether each tweet spread misinformation related to a known conspiracy theory or a similar misleading wider narrative, and if so (and only if so!), which one.
Include your reasoning. Output the results as a json file. If a tweet does not relate to a conspiracy theory or a misleading wider narrative, output "none" in the json.

- Tweets *do not* discuss a wider narrative if the misleading information is tied to a specific singular event that is not connected to major topics on the public discourse. 
They do discuss a wider narrative if the misleading information is tied to a known conspiracy theory or to major topics on the public discorse.

Chose from the following list of theories and wider narrative: 
CONSPIRACY_THEORIES = 
[
    September 11,
    October 7,
    the great replacement,
    COVID was intentionally spread,
    the COVID outbreak is fake,
    2020 election fraud,
    vaccines cause autism,
    5G towers,
    Russian invasion of Ukraine,
    flat earth,
    chemtrails,
    Q-Anon and deep state,
    Epstein files,
    Barack Obama was not born in the USA,
    Michelle Obama is a man,
    LGBT grooming,
    fluorite in the water,
    climate change,
    Holocaust denial,
    Hunter Biden and Ukraine,
    other,
]

Output format example:
[
    {
        id: <ID>,
        is_related_to_conspiracy: <True/False>,
        conspiracy: <CONSOIRACY (or None)>,
        reasoning: <REASONING>\
    }
]

    Tweets and notes: 
    <TWEETS_AND_NOTED>

\end{lstlisting}
\label{prompt_conspiracy}
\end{figure*}

\noindent \textbf{\Cref{lst:prompt_link}} The prompt used to classify URLs into categories.

\noindent \textbf{\Cref{lst:prompt_conspiracy}} The prompt used to classify tweets and notes into broader narratives and conspiracy theories.

\subsection{Manual Annotation Setup}
\label{app:manual_annotation_setup}


\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{Figures/annotation_setup.jpeg}
    \caption{Our annotation setup.}
    \label{fig:annotation_setup}
\end{figure*}

We annotate 400 $(\text{tweet}, \text{note})$ pairs from $\mathcal{S}_\text{text}$ with 12 binary attributes. Each $(\text{tweet}, \text{note})$ pair was annotated in a multi-label fashion, i.e., more than one attribute can be selected at the same time. \cref{fig:annotation_setup} depict our simple annotation setup, with the 12 attributes being as follows. 

\begin{description}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
    \item[Broader narrative] Whether the $(\text{tweet}, \text{note})$ pair is related to a broader narrative or a conspiracy theory.
    \item[Discredit source of claim] If the community note describes the source shared by the original post as non-credible.
    \item[Add missing context] If the community note provides some missing context to refute a claim.
    \item[Highlight AI generated] If the community note claims that the post shared AI-generated content.
    \item[Highlight edited media] If the community note claims that the post shared some media that was edited (edited with Photoshop, the clip was cut, etc.).
    \item[Link to direct source] If the community note shares a link to a source where an entity says that a claim made about them is false.
    \item[Link official source] If the community note shares a link to an official source such as a government website.
    \item[Link scientific source] If the community note shares a link to some scientific article or website.
    \item[Link world knowledge] If the community note shares a link to some reference resources such as Wikipedia.
    \item[Link fact-checking] If the community note shares a link to a professional fact-checking organisation.
    \item[In-note fact-checking] If the community note performs an in-note fact-check by cross-referencing several sources and constructing a compelling argument.
\end{description}