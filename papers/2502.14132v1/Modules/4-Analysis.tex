




\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{Figures/annotations_of_notes_narrow.png}
    \caption{Mean scores of community annotations of misleading posts.}
    \label{fig:annotations}
\end{figure}

We analyse the dataset prepared in \cref{sec:dataset} to answer the two research questions defined in \cref{sec:introduction}.

\subsection{RQ1: To what degree do community notes rely on fact-checkers?}
\label{sec:analysis_rq1}

According to \cref{fig:link_types}, at least 5\% of all English community notes contain an external link to professional fact-checkers. This number grows to 7\% when only considering notes rated as `helpful' (\cref{fig:link_types_helpful} in \cref{app:additional_material}). Conversely, only 1\% of notes rated as `not helpful' contain a fact-checking source (\cref{fig:link_types_not_helpful} in \cref{app:additional_material}). These figures are significantly larger than what was reported in previous studies (1.2\% \citep{kangur_who_2024}), possibly because \citet{kangur_who_2024} utilise a smaller dataset of fact-checking agencies and classify fact-checking divisions of popular journals as ``news''. The results imply that notes incorporating fact-checking sources are generally considered more helpful. 

We further assess whether notes with fact-checking sources are perceived to be of higher quality by analysing individual user ratings of notes both with and without such sources. Specifically, we collect user ratings for a balanced
(i.e., including of a fact-checking source or not) sample of 20K notes rated by at least 50 users, 
% , with half containing a link to professional fact-checking and the other half without.
and calculated the average ratings for the notes. As can be seen in \cref{fig:notes_individual_ratings} in \cref{app:additional_material}, community notes with fact-checking sources are generally rated higher than their counterparts. Interestingly, while notes with fact-checking links are more likely to be regarded as having a good source (higher \textit{HelpfulGoodSources}), they are also more likely to be rated as \textit{notHelpfulSourcesMissingOrUnreliable}.  \cref{tab:notes_with_bad_source.} in \cref{app:additional_material} contains a sample of such notes. 


\subsection{RQ2: What are the traits of posts and notes that rely on fact-checking sources?}
\label{sec:analysis_rq2}

\begin{table*}
    \centering
    \resizebox{1.0\textwidth}{!}
    {%
    \fontsize{8}{8}\selectfont
    \sisetup{table-format = 3.2, group-minimum-digits=3}
    \begin{tabular}{p{5cm}p{7cm}rrrrr}
    \toprule
    Tweet & Note & \rotatebox[origin=r]{270}{misleadingUnverifiedClaimAsFact} & \rotatebox[origin=r]{270}{misleadingOutdatedInformation} & \rotatebox[origin=r]{270}{misleadingFactualError} & \rotatebox[origin=r]{270}{misleadingSatire} & \rotatebox[origin=r]{270}{Fact Checking source} \\ \midrule
    The NASA War Document is absolutely terrifying \url{https://t.co/...} & misrepresenting a presentation by NASA scientist Dennis Bushnell, The lecture was not detailing plans by NASA to attack the world it was a lecture for defense industry professionals, and how defense tactics might rise to meet evolving threats in the future.   \url{https://leadstories.com/hoax-alert/2021/06/fact-check-the-future-is-now-is-not-a-nasa-war-document-plan-for-world-domination-and-phasing-out-of-humans.html} & \cmark & \xmark & \xmark & \xmark & \cmark \\ \addlinespace
    BREAKING NEWS: International Criminal Investigation calls on every public citizen to recommend indictments for Bill Gates, Anthony Fauci, Pfizer, BlackRock, Tedros and Christian Drosten for pushing everyone to receive the ineffective highly dangerous lethal experimental vaccines... & Video has been fact-checked by USA Today, was found to be misleading, and promotes a conspiracy theory about COVID ... \url{https://ca.movies.yahoo.com/movies/fact-check-viral-video-promotes-204414488.html} & \cmark & \xmark & \xmark & \xmark & \cmark \\ \addlinespace
    1) California is RED.
    It is just because of the MASSIVE Election Fraud that stupid, brainwashed people believe Calif. is blue. Joe Biden won only in the SFO Bay area ... & The map shows the results of Reagan's reelection in 1984, not Biden's election in 2020.  \url{https://en.wikipedia.org/wiki/1984\_United\_States\_presidential\_election\_in\_California} & \xmark & \cmark & \xmark & \xmark & \xmark \\ \addlinespace
    Davis blows up \$100,000 fireworks in Kai Cenat setup During the Mr Beast Stream ... & The second photo is from a house fire in Atlanta in 2019. \url{https://www.11alive.com/article/news/local/woodland-brook-drive-cause-of-house-fire/85-ecb7df9b-5f65-44e9-bf9d-8c162d36c334} & \xmark & \cmark & \xmark & \xmark & \xmark \\ \addlinespace
    @cnviolations I swear community notes are the only good thing Elon added since he bought Twitter. & Community notes was first launched under former Twitter CEO Jack Dorsey in 2021 under the name of ``Birdwatch''. The only thing Elon Musk did was that he renamed the feature to community notes.    \url{https://blog.twitter.com/en\_us/topics/product/2021/introducing-birdwatch-a-community-based-approach-to-misinformation}    \url{https://www.reuters.com/article/factcheck-elon-birdwatch-idUSL1N31Z2VG/} &
     \xmark & \xmark & \cmark & \xmark & \cmark \\ \addlinespace
    Thailand will become the first country to make the contract null and void, meaning that Pfizer will become responsible for all vaccine injuries ... & Thailand has no plans to void its Pfizer COVID vaccine contract, an official with the country’s National Vaccine Institute said. Thailand’s Department of Disease Control also rejected the claims as ``fake news.'' ...  \url{https://apnews.com/article/fact-check-covid-vaccine-pfizer-thailand-203948163859} & \xmark & \xmark & \cmark & \xmark & \cmark \\ \addlinespace
    Hilarious tweets by footballers, A thread: 1. Virgil Van Dijk [Current Liverpool Captain] \url{https://t.co/...} & Virgil Van Dijk did not tweet this, the tweet was made by a fan account in his name.    \url{https://www.pinkvilla.com/sports/fact-check-did-virgil-van-dijk-really-root-for-man-u-because-no-one-likes-liverpool-in-resurfaced-viral-tweet-1287250} & \xmark & \xmark & \xmark & \cmark & \cmark \\ \addlinespace
    Rob Reiner announces he’s on the Epstein Client List and Epstein Flight logs. What a fool! When a lawyer tells me to STFU, I STFU! \url{https://t.co/...} & This is a digitally altered photo that might be misinterpreted even if used as a joke.    The name Rob Reiner is misspelled, and the text is not on Reiner's X timeline.    \url{https://twitter.com/robreiner?t=iqu43-NszIW5oOM\_KqRSpw} & \xmark & \xmark & \xmark & \cmark & \xmark \\
    \bottomrule
    \end{tabular}
    }
    \caption{A sample of tweets, notes, and their community annotations, as well as whether the note contains a fact-checking link.}
    \label{tab:community_annotation_example}
\end{table*}

\begin{figure}[!t]
    \centering
    \includegraphics[width=1\columnwidth]{Figures/manual_annotation.png}
    \caption{(a) strategies in debunking claims related to broader narratives. (b) the different ways in which fact-checking sources are used to debunk claims.}
    \label{fig:manual_annotation}
\end{figure}
% \begin{table}[h]
%     \centering
%     \begin{tabular}{p{2cm}lcc}
     
%        & & \multicolumn{2}{c}{Fact-check source} \\
        
%       & & Yes & No \\
%       \cline{3-4}
%         \multirow{2}{*}{\shortstack[l]{Related to a\\conspiracy} } & Yes & 0.216 & 0.112 \\
%         & No & 0.279 & 0.39 \\
%     \end{tabular}
%     \caption{Your table caption here}
%     \label{tab:fact_check}
% \end{table}


\def\arrvline{\hfil\kern\arraycolsep\vline\kern-\arraycolsep\hfilneg}

\begin{table}[!t]
% \fontsize{9}{9}\selectfont
    \centering
    \begin{tabular}{llc|c}
     
       & & \multicolumn{2}{c}{FC source} \\ 
       
      & & \cmark & \xmark \\
       \cmidrule(l){3-4}
      % \cmidrule(r){3-3}\cmidrule(l){4-4}
       \multirow{2}{*}{\rotatebox[origin=r]{90}{\parbox[r]{0.5cm}{\centering Conspi-racy}}} & \cmark \arrvline &  22\% & 11\% \\
       \cmidrule(l){2-4}
        & \xmark \arrvline & 28\% & 39\% \\
    \end{tabular}
    \caption{Percentage of samples related to a broader narrative or conspiracy vs. have a fact-checking source.}
    \label{tab:conspiracies_model_results}
\end{table}


We begin by performing a topic analysis, comparing topics of posts whose notes reference fact-checking sources to those citing other sources. To this end, we apply a strong zero-shot text classification model\footnote{\url{https://huggingface.co/r-f/ModernBERT-large-zeroshot-v1} with default settings.} to our $\mathcal{S}_\text{text}$ subset by classifying spans of the form ``\texttt{Tweet:<POST TEXT>; Note <NOTE TEXT>}'' into one of 13 classes. The authors manually evaluated the quality of the classification results and considered it satisfactory. Notably (\cref{fig:topics}), fact-checking sources are more likely to be included in posts related to high-stakes issues such as health, science, and scams and less likely to be included in posts on tech or sports.

We then analyse annotations (binary attributes explaining the warrant for the note) by community note authors.
% When writing a note, the author labels the original post with 
\cref{fig:annotations} contains the full breakdown of annotations for notes with and without fact-checking sources. Notes containing a link to fact-checking sources are overrepresented in posts where unverified information is presented as a fact or when the post contains a factual error. Conversely, they are under-represented in posts with outdated information or satirical content. \cref{tab:community_annotation_example} contains a sample of such notes. 

These results indicate that community note-writers adapt their strategies based on the stakes and scope of the claim, and the depth of research needed to counter misinformation. We hypothesise that they are more likely to rely on external fact-checking when refuting complex or unverifiable claims \citep{wuehrl-etal-2024-makes}, as well as claims related to broader narratives or conspiracy theories which cannot be fully addressed in the scope of a note.\footnote{For example, the claim ``Michelle Obama is a male''.} Conversely, claims involving misleading media can often be debunked with examples alone, making fact-checking sources unnecessary. To investigate this hypothesis, the authors of this paper manually annotated 400 $<\text{post}, \text{note}>$ pairs from $\mathcal{S}_\text{text}$ with attributes related to the complexity of the claims and how community notes address them. (See \cref{app:manual_annotation_setup} for annotation guidelines). The results (\cref{fig:manual_annotation}.a) support our hypothesis. Claims related to broader narratives or conspiracy theories are much more likely to include a link to a fact-checking source.
In contrast, other types of claims are more likely to be addressed by providing missing context or by invalidating the credibility of the claim's source. 
Additionally, \cref{fig:manual_annotation}.b depicts the different ways in which fact-checking sources are used to debunk claims. It demonstrates how such sources are rarely used to provide missing context but rather focus on discrediting sources of claims and providing scientific evidence.

\begin{figure}[!t]
    \centering
    \includegraphics[width=1\columnwidth]{Figures/Distribution_of_topics_vertical.png}
    \caption{Distribution of notes' topics, with and without a fact-checking source.}
    \label{fig:topics}
\end{figure}

We extend the manual annotation to an LLM-based analysis of 8K balanced $(\text{post}, \text{note})$ pairs from $\mathcal{S}_\text{text}$. We task OpenAI's GPT-4\footnote{Version \texttt{gpt-4o-2024-08-06}.} with determining whether a pair relates to a broader narrative or a conspiracy theory. \Cref{lst:prompt_conspiracy} in \cref{app:reproducibility} details the prompt used. To evaluate model accuracy, two authors independently labelled 100 balanced pairs, achieving an agreement rate of $0.88$ and resolving disagreements through discussion. The model attained an 
$F_1$ score of $0.85$---strong performance for this challenging task. The results (\cref{tab:conspiracies_model_results}) support our hypothesis: pairs related to a broader narrative or conspiracy theory are \textit{twice} as likely to cite fact-checking sources compared to other sources. In contrast, other pairs are nearly 30\% less likely to do so. These findings also highlight the prevalence of such claims and further underscore the importance of fact-checking in combating complex misinformation narratives.




