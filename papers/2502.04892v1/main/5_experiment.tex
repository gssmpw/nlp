\section{Experiments}
\label{sec:main:experiment}


In this section, we present empirical results that demonstrate the effectiveness of BDO as a brain dynamics foundation model. BDO was pre-trained using the large-scale UK Biobank (UKB) dataset in a self-supervised manner, leveraging resting-state fMRI recordings and medical records from 41,072 participants~\citep{alfaro2018image}. To evaluate its applicability, we conducted experiments across various downstream tasks, including demographics prediction, trait prediction, and psychiatric diagnosis classification. These experiments were performed on five datasets: Human Connectome Project in Aging (HCP-A; \citealp{bookheimer2019lifespan}), Autism Brain Imaging Data Exchange (ABIDE; \citealp{di2014autism}), Attention Deficit Hyperactivity Disorder 200 (ADHD200; \citealp{brown2012adhd}), Human Connectome Project for Early Psychosis (HCP-EP; \citealp{jacobs2024introduction,Prunier2021-ao}), and Transdiagnostic Connectome Project (TCP; \citealp{chopra2024transdiagnostic}). All fMRI data in the experiments was preprocessed by dividing brain activity into 450 distinct ROIs, using Schaefer-400 for cortical regions and Tian-Scale III for subcortical areas~\citep{10.1093/cercor/bhx179, Tian2020}.


To evaluate the effectiveness of \textbf{BDO}, we compared our performance against both training-from-scratch (TFS) models and foundation models. Specifically, we compared BDO with three deep learning architectures: BrainNetCNN~\citep{kawahara2017brainnetcnn}, BrainGNN~\citep{li2021braingnn}, and BrainNetTF~\citep{kan2022brain}, as well as two foundation models for brain dynamics: BrainLM~\citep{caro2024brainlm} and BrainJEPA~\citep{dong2024brain}. We denote \(\text{BDO}_{\texttt{LP}}\) as the linear probing (LP) performance of the pre-trained BDO, where the encoder remains frozen and a linear head is trained on top for downstream tasks. In contrast, \( \text{BDO}_{\texttt{FT}} \) represents the fine-tuned (FT) performance, where the entire model, including the pre-trained encoder, is updated during task-specific training. Note that the reported performance for both BrainLM and BrainJEPA is based solely on fine-tuning. For a fair comparison, all results are averaged over three runs with different data splits. The best-performing results are highlighted in \BF{bold}, while the second-best results are shown in \blue{blue} for clarity. Additional experimental details are provided in Appendix~\ref{sec:app:details}.


\begin{table}
\centering
\scriptsize
  \caption{Internal prediction tasks on UKB 20\% held-out.}
  \vspace{-2mm}
  \label{tab:internal}
    \begin{tabular}{l cc cc}
        
        \toprule
        \multirow{2}{*}{Methods} 
        & \multicolumn{2}{c}{Age} 
        & \multicolumn{2}{c}{Gender} 
        \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5} 
        
        & MSE $\downarrow$ & $\rho$ $\uparrow$ 
        & ACC (\%) $\uparrow$ & F1 (\%) $\uparrow$ 
        \\
        \midrule
        



        BrainNetCNN
        & 0.648 \PM .018 & 0.621 \PM .012
        & 90.89 \PM 0.14 & 90.87 \PM 0.12
        \\
        
        BrainGNN
        & 0.914 \PM .024 & 0.430 \PM .010
        & 79.07 \PM 1.08 & 79.03 \PM 1.09
        \\

        BrainNetTF
        & 0.561 \PM .004 & 0.673 \PM .003
        & \blue{91.19 \PM 0.51} & \blue{91.17 \PM 0.50}
        \\

        \midrule
        
        BDO$_{\texttt{LP}}$
        & 0.600 \PM .004 & 0.635 \PM .005
        & 88.25 \PM 0.78 & 88.21 \PM 0.79
        \\
        \midrule

        BrainLM
        & 0.649 \PM .008 & 0.618 \PM .005 
        & 89.28 \PM 0.72 & 89.26 \PM 0.71
        \\
                
        BrainLM$^\dag$
        & 0.612 \PM .041 & 0.632 \PM .020
        & 86.47 \PM 0.74 & 86.84 \PM 0.43
        \\
        
        BrainJEPA$^\dag$
        & \blue{0.501 \PM .034} & \blue{0.718 \PM .021}
        & 88.17 \PM 0.06 & 88.58 \PM 0.11
        \\
        \midrule

        BDO$_{\texttt{FT}}$
        & \BF{ 0.481 \PM .010 } & \BF{ 0.722 \PM .007 }
        & \BF{ 92.59 \PM 0.68 } & \BF{ 92.57 \PM 0.69 }
        \\

        \bottomrule
    \end{tabular}
    
    \begin{tablenotes}
        \item {$\dag$ Results from~\citep{dong2024brain};  BrainLM$^{\dag}$ results also included to compare with our reproduced BrainLM results.}
    \end{tablenotes}
\vspace{-6mm}
\end{table}

\footnotetext{Unfortunately, despite following open-source code and available preprocessing pipelines, our BrainJEPA results may have deviated due to potentially \textbf{undocumented data preprocessing}. Consequently, for a fair comparison, it was infeasible to directly reproduce the performance reported in their paper.}



\subsection{Internal and External Evaluation}

\begin{table*}[ht]
\centering
\scriptsize
  \caption{External tasks for demographics and trait prediction on HCP-A.}
  \label{tab:hcpa}
  \centering
    \vspace{-2mm}
    \begin{tabular}{clcccccccc}
        \toprule
        \multirow{2}{*}{} 
        & \multirow{3}{*}{Methods} 
        & \multicolumn{2}{c}{Age} 
        & \multicolumn{2}{c}{Gender} 
        & \multicolumn{2}{c}{Neuroticism} 
        & \multicolumn{2}{c}{Flanker} \\ 
        \cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-10}

        &
        & MSE $\downarrow$ & $\rho$ $\uparrow$ 
        & ACC (\%) $\uparrow$ & F1 (\%) $\uparrow$ 
        & MSE $\downarrow$ & $\rho$ $\uparrow$ 
        & MSE $\downarrow$ & $\rho$ $\uparrow$ \\
        \midrule

        \multirow{3}{*}{\shortstack{TFS}}
        & BrainNetCNN 
        & 0.472 \PM .054 & 0.727 \PM .040 
        & 72.36 \PM 3.66 & 71.42 \PM 4.03 
        & 1.039 \PM .093 & 0.076 \PM .094 
        & 1.001 \PM .097 & 0.310 \PM .083 \\

        & BrainGNN
        & 0.570 \PM .050 & 0.657 \PM .031 
        & 66.81 \PM 2.54 & 65.22 \PM 2.14 
        & 1.076 \PM .069 & 0.094 \PM .044 
        & 1.137 \PM .049 & 0.229 \PM .051 \\
        
        & BrainNetTF %
        & 0.389 \PM .038 & 0.780 \PM .036 
        & 75.00 \PM 2.28 & 74.06 \PM 2.78 
        & 1.209 \PM .051 & 0.015 \PM .055 
        & 0.959 \PM .058 & 0.357 \PM .071 \\


        \midrule
        \multirow{3}{*}{LP}
        & BDO$_{\texttt{LP}}$ (5M)
        & 0.594 \PM .040 & 0.635 \PM .031 
        & 64.12 \PM 0.65 & 63.06 \PM 0.47
        & 0.991 \PM .020  & 0.091 \PM .049
        & 0.929 \PM .029 & 0.365 \PM .031 \\        

        & BDO$_{\texttt{LP}}$ (21M)
        & 0.461 \PM .013 & 0.729 \PM .011
        & 70.37 \PM 0.87 & 68.68 \PM 0.78
        & 0.945 \PM .016 & 0.209 \PM .037
        & 0.904 \PM .024 & 0.387 \PM .041 \\

        & BDO$_{\texttt{LP}}$ (85M)
        & 0.404 \PM .010 & 0.768 \PM .008
        & 72.00 \PM 2.95 & 71.30 \PM 2.19
        & 0.986 \PM .023 & 0.131 \PM .037
        & \blue{0.856 \PM .049} & 0.450 \PM .072 \\        


        \midrule
        \multirow{5}{*}{FT}
        & BrainLM (86M)
        & 0.340 \PM .019 & 0.818 \PM .012 
        & 72.78 \PM 2.12 & 72.36 \PM 2.22
        & 1.093 \PM .085 & 0.132 \PM .064
        & 0.859 \PM .010 & \blue{0.461 \PM .015} \\

        
        & BrainLM$^\dag$ (86M)
        & 0.331 \PM .018 & 0.832 \PM .028 
        & 74.39 \PM 1.55 & 77.51 \PM 1.13
        & 0.942 \PM .082 & 0.231 \PM .012
        & 0.971 \PM .054 & 0.318 \PM .048 \\
        
        & BrainJEPA$^\dag$ (86M)
        & \blue{0.298 \PM .017} & \blue{0.844 \PM .030}
        & \BF{81.52 \PM 1.03} & \BF{84.26 \PM 0.82}
        & \blue{0.897 \PM .055} & \BF{0.307 \PM .006}
        & 0.972 \PM .038 & 0.406 \PM .027 \\
        
        \cmidrule(lr){2-10}
        & BDO$_{\texttt{FT}}$ (85M)
        & \BF{0.273 \PM .010} & \BF{0.851 \PM .006}
        & \blue{79.40 \PM 4.07} & \blue{78.98 \PM 4.38}
        & \BF{0.894 \PM .001} & \BF{0.307 \PM .017}
        & \BF{0.847 \PM .037} & \BF{0.464 \PM .072} \\

        \bottomrule
    \end{tabular}
    \begin{tablenotes}
    \item \scriptsize{
        \hspace{4mm} 
        $\dag$ Results from~\citep{dong2024brain}.
        TFS: Training from scratch, LP: Linear probing, FT: Fine-tuning.
        }
    \end{tablenotes}
\vspace{-3mm}
\end{table*}
    
\begin{table*}[ht]
\centering
\scriptsize
  \caption{Psychiatric diagnosis prediction on clinical fMRI datasets.}
  \label{tab:disease}
  \centering
    \vspace{-2mm}
    \begin{tabular}{clcccccccc}
        \toprule
        \multirow{2}{*}{} 
        & \multirow{3}{*}{Methods} 
        & \multicolumn{2}{c}{ABIDE} 
        & \multicolumn{2}{c}{ADHD200} 
        & \multicolumn{2}{c}{HCP-EP}
        & \multicolumn{2}{c}{TCP}
        \\ 
        \cmidrule(lr){3-4} 
        \cmidrule(lr){5-6} 
        \cmidrule(lr){7-8} 
        \cmidrule(lr){9-10}

        &
        & ACC (\%) $\uparrow$ & F1 (\%) $\uparrow$ 
        & ACC (\%) $\uparrow$ & F1 (\%) $\uparrow$ 
        & ACC (\%) $\uparrow$ & F1 (\%) $\uparrow$ 
        & ACC (\%) $\uparrow$ & F1 (\%) $\uparrow$ 
        \\
        
        \midrule

        \multirow{3}{*}{TFS}
        & BrainNetCNN %
        & 64.39 \PM 2.17 & 64.23 \PM 2.27
        & 55.49 \PM 4.39 & 53.62 \PM 5.15
        & 70.29 \PM 6.90 & 58.07 \PM 9.52
        & 56.96 \PM 7.33 & 50.73 \PM 7.59
        \\

        & BrainGNN
        & 56.82 \PM 3.40 & 56.73 \PM 3.43
        & 52.78 \PM 3.27 & 51.59 \PM 2.89
        & \blue{73.14 \PM 6.90} & \blue{65.46 \PM 9.06}
        & 53.04 \PM 2.22 & 48.24 \PM 7.41
        \\
        
        & BrainNetTF %
        & \blue{66.36 \PM 3.66} & \blue{66.30 \PM 3.67} 
        & 54.29 \PM 3.02 & 50.90 \PM 3.18 
        & 71.43 \PM 6.52 & 61.26 \PM 10.32
        & \blue{62.17 \PM 5.60} & \blue{55.41 \PM 5.69}
        \\
        
        
        \midrule
        \multirow{3}{*}{LP}
        & BDO$_{\texttt{LP}}$ (5M)
        & 62.42 \PM 2.68 & 62.30 \PM 2.61
        & 59.65 \PM 2.32 & 56.90 \PM 1.70
        & 73.33 \PM 7.50 & 64.35 \PM 13.9
        & 60.14 \PM 3.69 & 42.04 \PM 5.02 \\        

        & BDO$_{\texttt{LP}}$ (21M)
        & 63.79 \PM 1.83 & 63.67 \PM 1.71
        & \blue{61.15 \PM 1.97} & \BF{59.71 \PM 2.66}
        & 71.43 \PM 4.04 & 64.95 \PM 5.07
        & 60.87 \PM 0.00 & 53.68 \PM 1.53 \\

        & BDO$_{\texttt{LP}}$ (85M) %
        & \BF{66.67 \PM 1.13} & \BF{66.58 \PM 1.02}
        & \BF{61.40 \PM 1.97} & \blue{59.52 \PM 2.87}
        & \BF{75.24 \PM 3.56} & \BF{67.23 \PM 6.22}
        & \BF{63.77 \PM 2.05} & \BF{56.88 \PM 3.45}

        
        \\



        
        
        \bottomrule
    \end{tabular}
\vspace{-5mm}
\end{table*}


\BF{Internal tasks: Age and Gender Prediction. }
To assess the generalization capabilities of BDO, we evaluated its performance on a held-out 20$\%$ subset of the UKB dataset, which was excluded from pre-training. The evaluation focused on two tasks: age regression and gender classification. As shown in~\cref{tab:internal}, BDO achieved state-of-the-art performance, surpassing baseline models, including both TFS and foundation models. Improvements were consistent across all evaluation metrics, demonstrating the robustness and transferability of the universal feature $\bbA$ of BDO. %


\BF{External tasks: Trait and Diagnosis Prediction. }
For external validation, we evaluated BDO on both individual trait prediction and psychiatric diagnosis classification tasks using multiple datasets, including HCP-A, ABIDE, ADHD200, HCP-EP, and TCP. The demographics and trait prediction tasks, conducted on the HCP-A dataset, involved predicting individual characteristics such as age, gender, neuroticism, and flanker scores. In ~\cref{tab:hcpa}, BDO exhibited strong transfer learning capabilities, with larger variants achieving superior performance.

BDO also demonstrated strong applicability to psychiatric diagnosis classification across diverse datasets, as detailed in~\cref{tab:disease}. These tasks included autism spectrum disorder (ASD) classification with ABIDE, attention-deficit/hyperactivity disorder (ADHD) classification with ADHD200, psychotic disorder with HCP-EP, and psychiatric disorder with TCP. Across all datasets, BDO consistently outperformed baseline models, achieving superior classification accuracy and F1 scores. These findings highlight the robustness of BDO in modeling complex relationships between brain dynamics and individual traits, as well as its efficacy in psychiatric diagnosis classification. 



The LP performance of BDO showcased remarkable scalability and transferability, demonstrating its efficacy as a foundation model for brain dynamics. Notably, on HCP-A, its LP performance was comparable to TFS models, highlighting its ability to generalize across unseen datasets. Impressively, BDO achieved state-of-the-art results in psychiatric diagnosis classification, outperforming existing baselines across multiple clinical datasets.
\begin{figure}[t]
\centering
\includegraphics[width=0.46\textwidth,]{figure/age_scalability_experiment_subplots_remove_tfs.pdf}
\vspace{-3mm}
\caption{Scalability results of HCP-A age regression in LP.}\label{fig:scalability}
\vspace{-8mm}
\end{figure}

We believe the outstanding LP performance of BDO comes from its principled modeling of temporal dynamics via SSM, which enables BDO to effectively capture the complex and evolving nature of brain activity. Specifically, our SSM formulation introduces a strong inductive bias for time-series modeling, allowing BDO to learn structured latent representations without relying solely on a data-driven way. This structured design not only facilitates the development of a more efficient model by reducing the number of parameters compared to purely data-driven methods~\citep{caro2024brainlm, dong2024brain} which depend solely on \textit{learning} temporal dependencies, but also enhances the robustness of representation learning for meaningful representations.









\begin{figure*}[t]
\centering
\includegraphics[width=0.9\textwidth,]{figure/age_interpretability_combined_plasma_r.png}
\vspace{-3mm}
\caption{BDO captures a latent space that encodes clinically relevant information from fMRI recordings. For each fMRI scan, a universal feature $\bbA$ is extracted as a summary representation. The $\bbA$ is then projected into a 2D space using PCA and UMAP. The resulting embedding reveals a structured organization across both internal and external datasets.}\label{fig:interpretability}
\vspace{-4mm}
\end{figure*}


        
        








        


\BF{Interpretability of the universal feature $\bbA$. } In order to evaluate whether the extracted universal feature $\bbA$ effectively encodes critical information related to clinical variables in fMRI recordings, we visualize $\bbA$ by embedding it into a 2D space using PCA and UMAP, as shown in~\cref{fig:interpretability}. PCA reveals a clear linear separation based on age distribution, while UMAP preserves this separation, indicating that the learned representations capture biologically meaningful, age-related variations. Accurate age estimation is vital, as deviations from typical aging trajectories can signal early risks for cognitive and psychiatric conditions~\citep{davatzikos2009longitudinal, han2021brain, elliott2021brain}. In this regard, our results suggest that BDO effectively learns representations that reflect meaningful neural changes related to aging, enhancing its utility for downstream applications.






\subsection{Scalability and Efficiency}


We conducted scalability experiments to assess how model performance evolves with increasing model complexity or data availability. Our analysis focuses on both the benefits of scaling and the trade-offs in runtime and memory usage. 

\BF{Scalability. } To evaluate model scalability, we developed four BDO variants with increasing parameter sizes: Tiny (5M), Small (21M), and Base (85M). As depicted in ~\cref{fig:scalability}, performance trajectories over pre-training epochs indicate that larger models consistently reach higher performance plateaus, highlighting the scalability of BDO. 

Additionally, we examined the effect of pre-training data volume, we trained BDO (85M) on progressively larger subsets (25\%, 50\%, 75\%, and 100\%) of the UKB pre-training dataset. As shown in ~\cref{fig:scalability}, performance improved with dataset size, with the full dataset yielding the best results.

\BF{Efficiency. } As shown in~\cref{fig:scalability_gpu}, BDO significantly outperforms other foundation models in both resource and parameter efficiency. Remarkably, even the smallest BDO variant (5M) achieves performance comparable to other foundation models~\citep{caro2024brainlm, dong2024brain}. A detailed explanation of the underlying factors contributing to the efficiency of BDO is provided in Appendix~\ref{sec:source_efficiency}.


\subsection{Ablation Study}
\label{sec:main:experiment:ablation study}

\BF{Balancing factor $\tau$. } To analyze the impact of the regularization term, we introduce $\tau = \frac{(1-\lambda) \sigma^2_{\gamma}}{\sigma^2_q}$\footnote{See the rescaled objective function in~\eqref{eq:rescaled training objective} in Appendix.}, which represents the weight of the regularization loss. As shown in ~\cref{fig:ablation}, incorporating the regularizer ($\tau > 0$) leads to improved performance compared to the fully reconstruction-based setting ($\tau = 0$). This highlights the importance of regularization in our framework. However, $\tau$ setting too high results in a decline in performance ($\tau > 0.03$), likely due to excessive regularization overpowering the primary objective. 

\BF{Mask ratio $\gamma$. } ~\cref{fig:ablation} illustrates the effect of the mask ratio $\gamma$ on performance. We find that the optimal masking ratio is 75\%, which aligns with the findings in~\citet{he2022masked}. The Pearson correlation increases as $\gamma$ increases, reaching a peak at the optimal ratio. However, beyond this point, performance begins to degrade, likely due to excessive information loss hindering the reconstruction.




\begin{figure}
\centering
\includegraphics[width=0.47\textwidth,]{figure/combined_ablation_plots.pdf}
    \caption{(Left) Training curve (Right) Pearson correlation $\rho$ as the mask ratio $\gamma$ and balancing factor $\tau$ are varied.}\label{fig:ablation}
\vspace{-4mm}
\end{figure}