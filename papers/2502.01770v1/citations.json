[
  {
    "index": 0,
    "papers": [
      {
        "key": "longformer",
        "author": "Beltagy, Iz and Peters, Matthew E and Cohan, Arman",
        "title": "Longformer: The long-document transformer"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "bigbird",
        "author": "Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others",
        "title": "Big bird: Transformers for longer sequences"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "reformer",
        "author": "Kitaev, Nikita and Kaiser, {\\L}ukasz and Levskaya, Anselm",
        "title": "Reformer: The efficient transformer"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "mamba",
        "author": "Gu, Albert and Dao, Tri",
        "title": "Mamba: Linear-time sequence modeling with selective state spaces"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "bnn",
        "author": "Hubara, Itay and Courbariaux, Matthieu and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua",
        "title": "Binarized neural networks"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bin_cnn",
        "author": "Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali",
        "title": "Xnor-net: Imagenet classification using binary convolutional neural networks"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "pbllm",
        "author": "Yuan, Zhihang and Shang, Yuzhang and Dong, Zhen",
        "title": "PB-LLM: Partially Binarized Large Language Models"
      },
      {
        "key": "onebit",
        "author": "Xu, Yuzhuang and Han, Xu and Yang, Zonghan and Wang, Shuo and Zhu, Qingfu and Liu, Zhiyuan and Liu, Weidong and Che, Wanxiang",
        "title": "OneBit: Towards Extremely Low-bit Large Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "bivit",
        "author": "He, Yefei and Lou, Zhenyu and Zhang, Luoming and Liu, Jing and Wu, Weijia and Zhou, Hong and Zhuang, Bohan",
        "title": "Bivit: Extremely compressed binary vision transformers"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "bit",
        "author": "Liu, Zechun and Oguz, Barlas and Pappu, Aasish and Xiao, Lin and Yih, Scott and Li, Meng and Krishnamoorthi, Raghuraman and Mehdad, Yashar",
        "title": "Bit: Robustly binarized multi-distilled transformer"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "tanh_bin",
        "author": "Lahoud, Fayez and Achanta, Radhakrishna and M{\\'a}rquez-Neila, Pablo and S{\\\"u}sstrunk, Sabine",
        "title": "Self-binarizing networks"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "rastegari2016xnor",
        "author": "Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali",
        "title": "{XNOR-Net}: ImageNet Classification Using Binary Convolutional Neural Networks"
      },
      {
        "key": "lee2022power",
        "author": "Lee, In-Seok and Kim, Hyeongsu and Park, Min-Kyu and Hwang, Joon and Koo, Ryun-Han and Kim, Jae-Joon and Lee, Jong-Ho",
        "title": "Power and Area-Efficient XNOR-AND Hybrid Binary Neural Networks Using TFT-Type Synaptic Devices"
      },
      {
        "key": "garg2013array",
        "author": "Garg, Riya and Kaur, Navneet",
        "title": "Array Multiplier Using XNOR"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "pim",
        "author": "Chi, Ping and Li, Shuangchen and Xu, Cong and Zhang, Tao and Zhao, Jishen and Liu, Yongpan and Wang, Yu and Xie, Yuan",
        "title": "Prime: A novel processing-in-memory architecture for neural network computation in reram-based main memory"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "modern_hop",
        "author": "Demircigil, Mete and Heusel, Judith and L{\\\"o}we, Matthias and Upgang, Sven and Vermet, Franck",
        "title": "On a model of associative memory with huge storage capacity"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "hopfield_is",
        "author": "Ramsauer, Hubert and Sch{\\\"a}fl, Bernhard and Lehner, Johannes and Seidl, Philipp and Widrich, Michael and Adler, Thomas and Gruber, Lukas and Holzleitner, Markus and Pavlovi{\\'c}, Milena and Sandve, Geir Kjetil and others",
        "title": "Hopfield networks is all you need"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "scaling",
        "author": "Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario",
        "title": "Scaling laws for neural language models"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "bigbird",
        "author": "Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others",
        "title": "Big bird: Transformers for longer sequences"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "longformer",
        "author": "Beltagy, Iz and Peters, Matthew E and Cohan, Arman",
        "title": "Longformer: The long-document transformer"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "sparse_att_filter",
        "author": "Guo, Zihan and Han, Dezhi",
        "title": "Sparse co-attention visual question answering networks based on thresholds"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "sparse_att_acc",
        "author": "Liu, Liu and Qu, Zheng and Chen, Zhaodong and Ding, Yufei and Xie, Yuan",
        "title": "Transformer acceleration with dynamic sparse attention"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "sparse_asic",
        "author": "Song, Linghao and Chi, Yuze and Sohrabizadeh, Atefeh and Choi, Young-kyu and Lau, Jason and Cong, Jason",
        "title": "Sextans: A streaming accelerator for general-purpose sparse-matrix dense-matrix multiplication"
      },
      {
        "key": "sparse_gpu",
        "author": "Shi, Shaohuai and Wang, Qiang and Chu, Xiaowen",
        "title": "Efficient sparse-dense matrix-matrix multiplication on GPUs using the customized sparse storage format"
      }
    ]
  }
]