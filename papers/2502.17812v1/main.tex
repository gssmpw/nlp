%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}
 

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{main}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
% \usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% Packages added by me
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{nicematrix,booktabs}
\usepackage{multirow}
\usepackage{ragged2e}
\usepackage{tabularx}
\usepackage{tcolorbox}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{transparent}
\usepackage{listings}
\usepackage{multicol}
\usepackage{boldline}
\usepackage{arydshln}
\usepackage{diagbox}
\usepackage{amssymb}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{changepage}
\usepackage{multirow}
\renewcommand{\thefootnote}{}

\tcbset{
  aibox/.style={
    width=\columnwidth,
    top=10pt,
    colback=gray!20,
    colframe=gray,
    colbacktitle=gray,
    % enhanced,
    center,
    % attach boxed title to top left={yshift=-0.1in,xshift=0.15in},
    % boxed title style={boxrule=0pt,colframe=white,},
  }
}
\newtcolorbox{AIbox}[2][]{aibox,title=#2,#1}

\definecolor{LightCyan}{RGB}{232,241,255}
\definecolor{LightRed}{RGB}{255,235,235}
\definecolor{LightPink}{RGB}{255,235,255}
\definecolor{LightGreen}{RGB}{218,255,234}
\definecolor{LightYellow}{RGB}{255,255,235}
\definecolor{LightGray}{RGB}{242,242,242}
\definecolor{Red}{RGB}{253, 239, 242}
\definecolor{Yellow}{RGB}{255, 255, 204}
\definecolor{Pink}{RGB}{255, 243, 254}
\definecolor{Gray}{RGB}{249, 249, 249}
\definecolor{Green}{RGB}{230, 255, 241}
\definecolor{Blue1}{RGB}{218, 232, 245}
\definecolor{Blue2}{RGB}{239, 248, 253}
\definecolor{Blue3}{RGB}{136, 190, 220}
\definecolor{Blue4}{RGB}{83, 157, 204}
\definecolor{Blue5}{RGB}{42, 122, 185}
\definecolor{Blue6}{RGB}{11, 85, 159}
\definecolor{GreenCheck}{RGB}{0, 102, 51}
\definecolor{LightBack}{RGB}{247,249,251}

% Define a custom color
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{mygreen}{HTML}{88EABB}
\definecolor{OliveGreen}{HTML}{00693E}
\definecolor{markgreen}{rgb}{0.3, 0.73, 0.09}
\definecolor{markred}{rgb}{0.8, 0.0, 0.0}
\definecolor{deepred}{RGB}{152, 1, 0}

\definecolor{uscred}{RGB}{153, 27, 30} % USC Trojans Red
\newcommand{\yz}[1]{\textcolor{uscred}{Yue: #1}}
\newcommand{\xxx}[1]{\textcolor{blue}{Xiongxiao: #1}}
\newcommand{\m}{\textsc{VisualTimeAnomaly}}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Can Multimodal LLMs Perform Time Series Anomaly Detection?}

\begin{document}

\twocolumn[
% \icmltitle{\includegraphics[width=0.06\textwidth]{figure/llama.pdf}Can Multimodal LLMs Perform Time Series Anomaly Detection?}

\icmltitle{Can Multimodal LLMs Perform Time Series Anomaly Detection?}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
% \icmlsetsymbol{equal}{*}

\vspace{-0.5cm}
\begin{icmlauthorlist}
\textbf{Xiongxiao Xu}$^1$
\quad\textbf{Haoran Wang}$^2$
\quad\textbf{Yueqing Liang}$^1$
\quad\textbf{Philip S. Yu}$^3$
\quad\textbf{Yue Zhao}$^4$
\quad\textbf{Kai Shu}$^2$
\\
\vspace{0.2cm}
\textcolor{deepred}{Project Website: https://mllm-ts.github.io}
\vspace{0.3cm}
\end{icmlauthorlist}

\icmlkeywords{Multimodal Large Language Models, Time Series}

{%
\renewcommand\twocolumn[1][]{#1}%
\vspace{-0.3cm}
\begin{center}
    \centering
    \captionsetup{type=figure}
    \begin{minipage}{\textwidth}
        \centering
        \begin{subfigure}
            \centering
            \includegraphics[width=0.49\textwidth]{figure/framework.pdf}
        \end{subfigure}
        \begin{subfigure}
            \centering
            \includegraphics[width=0.49\textwidth]{figure/radar.pdf}
        \end{subfigure}
        \vspace{-0.2cm}
        \captionof{figure}{Left: the workflow of {\m}. TSI: time series images.
        Right: the performance comparison across various setting. Varing anomaly granularities in different scenarios: \textit{Point-wise} (Univariate), \textit{Range-wise} (Univariate), and \textit{Variate-wise} (Multivariate). Distinct base time series: Synthetic and Real-world. Irr: time series with irregularity.}
        \label{fig:framework_radar}
        \vspace{-0.5cm}
    \end{minipage}
\end{center}%
}

\vskip 0.3in
]

\footnotetext{$^1$Department of Computer Science, Illinois Institute of Technology, Chicago, IL, US
$^2$Department of Computer Science, Emory University, Atlanta, GA, US
$^3$Department of Computer Science, University of Illinois Chicago, Chicago, IL, US
$^4$Department of Computer Science, University of Southern California, Los Angeles, CA, US.
Correspondence to: Kai Shu \textless kai.shu@emory.edu\textgreater}

\begin{abstract}
Large language models (LLMs) have been increasingly used in time series analysis. However, the potential of multimodal LLMs (MLLMs), particularly vision-language models, for time series remains largely under-explored. 
One natural way for humans to detect time series anomalies is through visualization and textual description. Motivated by this, we raise a critical and practical research question: \textit{Can multimodal LLMs perform time series anomaly detection?} To answer this, we propose {\m} benchmark to evaluate MLLMs in time series anomaly detection (TSAD). 
Our approach transforms time series numerical data into the image format and feed these images into various MLLMs, including proprietary models (GPT-4o and Gemini-1.5) and open-source models (LLaVA-NeXT and Qwen2-VL), each with one larger and one smaller variant.
In total, {\m} contains 12.4k time series images spanning 3 scenarios and 3 anomaly granularities with 9 anomaly types across 8 MLLMs. Starting with the univariate case (\textit{point-} and \textit{range-wise} anomalies), we extend our evaluation to more practical scenarios, including multivariate and irregular time series scenarios, and \textit{variate-wise} anomalies. Our study reveals several key insights: 
1) MLLMs detect \textit{range-} and \textit{variate-wise} anomalies more effectively than \textit{point-wise} anomalies; 
2) MLLMs are highly robust to irregular time series, even with 25\% of the data missing; 
3) open-source MLLMs perform comparably to proprietary models in TSAD. While open-source MLLMs excel on univariate time series, proprietary MLLMs demonstrate superior effectiveness on multivariate time series. 
Finally, we discuss the broader implications of our findings for general time series analysis in the era of MLLMs. To the best of our knowledge, this is the first work to comprehensively investigate MLLMs for TSAD, particularly for multivariate and irregular time series scenarios.
We release our dataset and code at \href{https://github.com/mllm-ts/VisualTimeAnomaly}{\textcolor{deepred}{HERE}} to support future research.
\end{abstract}

\section{Introduction}
Large language models (LLMs) have gained attention across diverse applications~\cite{kaddour2023challenges,ge2024openagi}, including language-based anomaly detection~\cite{yang2024ad} and time series anomaly detection (TSAD). Recent TSAD research~\cite{liu2024large,dong2024can} shows that LLMs can provide desirable accuracy in identifying anomalies within time series. 
However, another study~\cite{alnegheimish2024large} reports that LLMs still lag behind traditional deep learning models by approximately $30\%$ in performance, indicating that pure text-based LLMs may not be optimal for the challenging TSAD problem.

In parallel, progress in multimodal LLMs (MLLMs)~\cite{yin2023survey} has extended LLMs to handle both visual and textual input. 
MLLMs represent an important step toward AGI (Artificial General Intelligence) 
by combining vision and language, which are two fundamental ways humans perceive and interact with the world~\cite{huang2024survey,clark2013whatever}. 
Notably, MLLMs have demonstrated near-human performance on various vision-language tasks~\cite{han2024comparative,wu2024multimodal,li2023seed}. 
Yet the potential of MLLMs in time series analysis has remained under-explored. In many real situations, people detect time series anomalies through a mix of visualization and language. For example, AIOps (Artificial Intelligence for IT Operations) practitioners~\cite{li2022constructing} interpret visual representations of metrics such as CPU usage over time and correlate them with textual information on system conditions. 
Motivated by this and the success of MLLMs, we pose the question: \textbf{\textit{Can multimodal LLMs perform time series anomaly detection?}}

To answer this question, we propose {\m} to comprehensively evaluate MLLMs in TSAD as shown in Figure~\ref{fig:framework_radar}. We convert large volumes of time series data into images, making them compatible with advanced MLLMs. 
Our study evaluates both proprietary models (GPT-4o~\cite{achiam2023gpt} and Gemini-1.5~\cite{team2024gemini}) and open-source models (LLaVA-NeXT~\cite{li2024llavanext-strong} and Qwen2-VL~\cite{wang2024qwen2}) with large-scale and relatively small model variants.
We begin with the simpler univariate scenario and progress to more complex multivariate and irregular time series, reflecting real-world challenges. The anomaly granularities evolve from \textit{point-} and \textit{range-wise} to \textit{variate-wise}. 
In total, {\m} comprises 12.4k time series images spanning 3 real-world scenarios and 3 anomaly granularities with 9 anomaly types for 8 MLLMs.
To the best of our knowledge, this is the first comprehensive examinations of MLLMs for TSAD, particularly for multivariate and irregular time series setting.
\\\textbf{Key Takeaways.} Our systematic exploration (Figure~\ref{fig:framework_radar}) uncovers several key findings that advance the understanding of both MLLMs and TSAD.
1) MLLMs detect \textit{range-} and \textit{variate-wise} anomalies better than \textit{point-wise} anomalies, suggesting that they respond better to coarse-grained patterns like humans.
2) MLLMs exhibit strong robustness to challenges posed by irregularity in time series, demonstrating that visual representations allow them to track overall patterns and detect anomalies even with $25\%$ of data missing.
3) Open-source MLLMs perform comparably to proprietary MLLMs in TSAD. Open-source models excel in univariate scenarios, while proprietary models show more effectiveness on multivariate data. 
\\\textbf{Contributions.} In summary, the paper makes the following key contributions:
\begin{itemize}
    \vspace{-0.3cm}
    \item We introduce \textbf{the first comprehensive benchmark for MLLMs in TSAD}, covering diverse scenarios (univariate, multivariate, irregular) and varying anomaly granularities (\textit{point-}, \textit{range-}, \textit{variate-wise}).
    \vspace{-0.1cm}
    \item We discuss several critical insights through a systematic and in-depth experimental analysis. These findings and their broader implications \textbf{significantly advance the understanding of both MLLMs and TSAD}.
    \vspace{-0.1cm}
    \item We \textbf{construct a large-scale dataset including 12.4k time series images, and release the dateset and code to the public} (\href{https://github.com/mllm-ts/VisualTimeAnomaly}{\textcolor{deepred}{HERE}}), fostering future research at the intersection of MLLMs and TSAD. 
\end{itemize}

\vspace{-0.6cm}
\section{Related Work}\label{sec:related}
\vspace{-0.2cm}
This work is primarily related to three lines of research (1) LLMs for time series anomaly detection, (2) time series as images, and (3) multimodal LLMs.
\\\textbf{Time Series as Images.}
Time series analysis~\cite{lee2024z,xu2024sst,du2024tsi,huang2024graph}, typically including classification, forecasting, anomaly detection, and imputation, involves multiple techniques. One recent technique is to visualize time series as image, and feed these images into powerful computer vision models for effective pattern recognition. The efforts on this area remain relatively unexplored. \cite{li2024time} finetunes vision transformer to perform medical classification on the time series images. \cite{yang2024vitime} and \cite{chen2024visionts} utilizes vision transformer and masked autoencoder to obtain enhanced forecasting performance. The most related literature are \cite{zhuang2024see} and \cite{zhou2024can} which use MLLMs to detect anomaly detection by visualizing time series. However, they (Table~\ref{tab:related}) only focus on the univariate scenario and does not touches on variate-wise anomalies. Starting from the basic univariate scenario with point- and range-wise anomalies, our work takes the first step towards complex multivariate and irregular scenarios with variate-wise anomalies, proving the systematic exploration of MLLMs for TSAD.

\textbf{LLMs for Time Series Anomaly Detection.}
The emergence of LLMs brings new paradigms for TSAD, especially in data-efficient scenarios. \cite{liu2024largekd} regards LLMs as a teacher network to guide training of the prototype-based Transformer student network. \cite{liu2024large,dong2024can} employs in-context learning and chain-of-thought to mimic expert logic for enhanced anomaly detection performance. The above work indicates promising performance of LLMs in TSAD. However, the later work~\cite{alnegheimish2024large} shows LLMs-based methods are still inferior to traditional SOTA deep learning models by $30\%$ on F1-Score. It suggests TSAD still remains a challenging task for LLMs which are pre-trained on only language. Additionally, \cite{zhou2024can} and \cite{dong2024can} indicate that the visual representation of time series facilitates anomaly detection, which demonstrates further the importance of trasnforming time series into images. Different form the existing work, our study takes the first attempt to comprehensively examine the potential of MLLMs for TSAD, covering univariate, multivaraite, and irregular scenarios with point-, range- and variate-wise anomalies.  
\begin{table}[!t]
\renewcommand{\arraystretch}{1.2}%
    \centering
    \setlength{\tabcolsep}{4pt}
    \resizebox{0.99\linewidth}{!}{%
        \begin{Tabular}{lccc|ccc}
        \hline
        
        \textbf{Work} & \textbf{Univariate} & \textbf{Multivariate} & \textbf{Irregular} & \textbf{Point} & \textbf{Range} & \textbf{Variate}\\ \hline
        
        \cite{zhou2024can} & \textcolor{markgreen}{\cmark} & \textcolor{markred}{\xmark} & \textcolor{markred}{\xmark} & \textcolor{markred}{\xmark} & \textcolor{markgreen}{\textbf{\cmark}} & \textcolor{markred}{\xmark}\\

        \cite{zhuang2024see} & \textcolor{markgreen}{\cmark} & \textcolor{markred}{\xmark} & \textcolor{markred}{\xmark} & \textcolor{markgreen}{\cmark} & \textcolor{markgreen}{\cmark} & \textcolor{markred}{\xmark}\\
        
        % \hline
        \textbf{Ours} & \textcolor{markgreen}{\textbf{\cmark}} & \textcolor{markgreen}{\textbf{\cmark}} & \textcolor{markgreen}{\textbf{\cmark}} & \textcolor{markgreen}{\textbf{\cmark}} & \textcolor{markgreen}{\textbf{\cmark}} & \textcolor{markgreen}{\textbf{\cmark}} \\ \hline
        \end{Tabular}
    }
\caption{Comparison between our work and the existing two works that utilize MLLMs for TSAD.}
\label{tab:related}
\vspace{-0.7cm}
\end{table}
\begin{figure*}[th!]
    \centering
    \vspace{-0.3cm}
    \subfigure[\textit{Point-wise} and \textit{Range-wise} anomalies]{
        \begin{minipage}{0.49\textwidth}
            \includegraphics[width=1\textwidth]{figure/comb_uni_anomaly.pdf}
        \end{minipage}\label{fig:univariate_anomaly}
    }
    \hspace{-0.2cm}
    \subfigure[\textit{Variate-wise} anomalies]{
        \begin{minipage}{0.49\textwidth}
            \includegraphics[width=1\textwidth]{figure/comb_multi_dim11_anomaly.pdf}
        \end{minipage}\label{fig:multivariate_anomaly}
    }
    \vspace{-0.3cm}
    \caption{The illustration of \textit{point-wise}, \textit{range-wise}, and \textit{variate-wise} anomalies. In Figure~\ref{fig:univariate_anomaly}, dashed lines and highlighted intervals represent global, contextual, seasonal, trend, and shapelet anomalies, respectively, from left to right. Figure~\ref{fig:multivariate_anomaly} illustrates \textit{variate-wise} anomalies (and the construction of multivariate time series images). From left to right and top to bottom, time series marked by the red color indicate triangle, square, sawtooth, and random anomalies, respectively.}
    \label{fig:anomaly}
    \vspace{-0.5cm}
\end{figure*}
\\\textbf{Multimodal LLMs.}
Multimodal large language models (MLLMs)~\cite{yin2023survey} refer to LLMs-based models with the ability to process multimodal information, such as text~\cite{liang2024taxonomy,huang2024can}, images~\cite{liu2024visual,hu2024bliva}, audio~\cite{deshmukh2023pengi,zhang2023speechgpt}, and video~\cite{he2024ma,fu2024video}, and table~\cite{sui2024table,wang2024piecing}. A significant amount of endeavors~\cite{hilal2022financial,black2024pi_0} have been put into grounding natural languages and visual images in MLLMs, i.e., vision-language models. According to accessibility of code, MLLMs can be categorized into two classes: propriety and open-source. Proprietary MLLMs are not publicly accessible but can be utilized via APIs provided by companies, consisting of GPT-4~\cite{achiam2023gpt}, Gemini-1.5~\cite{team2024gemini}, etc. In contrast, open-source MLLMs allow researchers and developers to access and modify the codes, subject to the terms of their respective licenses, including LLaVA-NeXT~\cite{li2024llavanext-strong} and Qwen2-VL~\cite{wang2024qwen2}, etc. Compared to numerous vision-language models, the alignment among vision, language, and time series is significantly less explored. Our work gives an intuitive way to bridge image, text, and time series into MLLMs.

\section{{\m}: Time Series Anomaly Detection based on Image}
We present {\m}, a new image-based TSAD benchmark that covers univariate, multivariate, and irregular time series. 
First, we define time series anomalies at different granularities across these scenarios. Next, we outline the methodology for constructing time series images. We finally describe utlized MLLMs, prompts, and metrics.

\vspace{-0.3cm}
\subsection{Time Series Scenarios}
\vspace{-0.2cm}
This work begins with base time series and then considers three common types in practice~\cite{zamanzadeh2024deep}: univariate, multivariate, and irregular time series.
\noindent\textbf{Base time series} is the starting point for all scenarios. It is assumed to follow either an explicit or an implicit generative function $G(x)$. 
An explicit generative function has a closed-form expression (e.g., \textit{sine} and \textit{cosine} waves). An implicit generative function captures complex real-world time series~\cite{dau2019ucr,bagnall2018uea} that lack a definitive functional form. Both types are used to generate univariate, multivariate, and irregular time series.

\noindent\textbf{Univariate time series} is a sequence of values over time, denoted as $\mathbf{x}=\{x_1,x_2,\dots,x_T\}$ with $T$ timestamps, where $x_t\in\mathbb{R}$ represents the value at the $t^\text{th}$ timestamp. 
For the explicit generative function, we use \textit{sine} waves, and for the implicit one, we use the Symbols dataset from the UCR archive~\cite{dau2019ucr}.
\\\textbf{Multivariate time series} carries multiple features at a timestamp. Formally, a multivariate time series can be denoted as $\mathbf{X}=\{\mathbf{x}^1,\mathbf{x}^2,...,\mathbf{x}^M\}$ with $M$ variables, where $\mathbf{x}^m\in\mathbb{R}^T$ is a $T$-dimensional vector at the $m^{th}$ variate. The multivariate time series $\mathbf{X}$ can also be expressed as $\mathbf{X}=\{\mathbf{x}_1,\mathbf{x_2},...,\mathbf{x_T}\}$ with $T$ timestamps, where $\mathbf{x}_t\in\mathbb{R}^M$ carries $M$ features at the $t^{th}$ timestamp. The explicit generative function adopts \textit{sine} and \textit{cosine} waves, and the implicit generative function adopts the ArticularyWordRecognition dataset in the UEA time series multivariate archive~\cite{bagnall2018uea}.
\\\textbf{Irregular time series} refers to univariate/multivariate time series with irregular sampled data points, which naturally arises in domains such as biology and healthcare~\cite{shukla2020survey}. Formally, an irregular univariate time series can be represented as $\mathbf{x}_{irr}=\{x_1,...,x_{i-1},x_{i+2}...,x_T\}$ with $S$ $(S<T)$ timestamps, where the point $x^i$ at the $i^{th}$ timestamp is missing. Similarly, an irregular multivaraite time series is $\mathbf{X}_{irr}=\{\mathbf{x}_{irr}^1,\mathbf{x}_{irr}^2,...,\mathbf{x}_{irr}^M\}$, where $\mathbf{x}_{irr}^m$ is a $S$-dimensional vector at the $m^{th}$ variate. We define the irregularity ratio as $r=1-\frac{S}{T}$ for irregular univariate/multivariate time series scenarios. We obtain the irregular univariate/multivariate scenario by randomly dropping data points for the above univariate/multivariate time series.

\vspace{-0.3cm}
\subsection{Anomaly Definition}
\vspace{-0.2cm}
In this subsection, we define time series anomalies of varying granularities in univariate and multivariate time series, including \textit{point-wise}, \textit{range-wise}, and \textit{variate-wise} anomalies, and introduce these in the irregular scenario.

As shown in Figure~\ref{fig:univariate_anomaly}, univariate time series anomalies can be classified into \textit{point-wise} and \textit{range-wise} anomalies~\cite{zamanzadeh2024deep,lai2021revisiting}.
\\\textbf{\textit{Point-wise anomalies}} are defined as unexpected incidents at individual time points:
\begin{equation}\label{eq:point_anomaly}
    |x_t-\hat{x_t}| > \delta
\end{equation}
where $\hat{x_t}$ is the expected value at timestamp $t$, which can be the output of a regression model, or the global mean value or mean value of a context window, and $\delta$ is the threshold.
\\\textbf{Global anomalies} are data points that significantly deviate from the rest of the series. They are usually spikes or dips in time series. The threshold can be defined as $\delta = \lambda\cdot\sigma(\mathbf{x})$, where $\sigma(\mathbf{x})$ is the standard deviation of the time series and $\lambda$ controls the threshold level. 
\\\textbf{Contextual anomalies} refer to the points that deviate from the neighboring time points within certain ranges. They exist usually in the form of small glitches in time series. The threshold $\delta = \lambda\cdot\sigma(\mathbf{x}_{t-k,t+k})$, where $\mathbf{x}_{t-k,t+k}$ is the context window of the data points $x_t$ with size $k$.

\textbf{\textit{Range-wise anomalies}} represent anomalous subsequences characterized by changes in seasonality, trend, or shape. Formally, within a time series $\mathbf{x}$, an underlying subsequence $\mathbf{x}_{i:j}$ from timestamp $i$ to $j$ can be considered anomalous if:
\begin{equation}\label{eq:context_anomaly}
    diss(\mathbf{x}_{i,j}, \hat{\mathbf{x}}_{i,j}) > \delta
\end{equation}
where $diss$ is a function measuring the dissimilarity between two subsequences regarding to seasonality, trend or shape, such as dynamic time warping~\cite{berndt1994using}, and $\hat{\mathbf{x}}_{i,j}$ is the expected subsequence regarding to seasonality, trend or shapelet.
\\\textbf{Seasonal anomalies} are subsequences with unusual seasonalities compared to the overall seasonality, despite the normal trends and shapes of time series.
\\\textbf{Trend anomalies} refer to subsequences which significantly alter the trend of the time series while retaining basic shapelet and seasonality.
\\\textbf{Shapelet anomalies} indicate the subsequences with dissimilar basic shapelet compared with the normal shapelet.

Figure~\ref{fig:multivariate_anomaly} illustrates \textit{variate-wise} anomalies of the multivariate time series scenario. In multivariate time series images, we only focus on \textit{variate-wise} anomalies as finer-granularity anomalies are too subtle for MLLMs and even human to detect.
\\\textbf{\textit{Variate-wise anomalies}} are the entire time series of some variates which significantly deviate from other variates within multivariate time series. We assume each variate $m$ is governed by a generative function $G(x)_m$. We define the \textit{variate-wise} anomalies as follows:
\begin{equation}\label{eq:context_anomaly}
    diss(G(x)_m, \hat{G}(x)_m) > \delta
\end{equation}
where $diss$ is utilized to measure the dissimilarity between two sequences of univariate time series, and $\hat{G}(x)_m$ denotes the expected generative function or the majority generative functions among variates, such as \textit{sine} or \textit{cosine} waves.
% \\\textbf{Inter-variate Anomalies} denote the subsequences whose behaviors significantly change compared to other variates within multivariate time series.
\\\textbf{Triangle anomalies} denote variates exhibiting the anomalous behavior that follows a triangular wave pattern, with linear ascents and descents.
\\\textbf{Square anomalies} are anomalous sequences whose anomalies manifest as abrupt transitions between high and low states, forming a square wave pattern.
\\\textbf{Sawtooth anomalies} refer to variates displaying periodic anomalies with a gradual rise and a sharp drop, characteristic of a sawtooth wave.
\\\textbf{Random anomalies} are variates driven by stochastic processes, exhibiting erratic changes of a random walk.

\textbf{\textit{Irregular anomalies}} are defined based on the irregular univariate/multivariate time series. To introduce irregularity, we randomly drop data points in univariate/multivariate time series, leading to irregular anomalies. For univariate time series, we skip contextual anomalies as dropping points around the anomalies will damage the context window. We also exclude seasonal anomalies when base time series employs an implicit generative function, as determining the seasonalities of real-world time series dataset (such as Symbol dataset) is challenging.

\begin{figure}[t]
\begin{AIbox}{Prompt for Variate-Wise Time Series Anomalies}
\vspace{-0.2cm}
{
    \textbf{Input Image}: 
    \begin{center}
        \includegraphics[width=1\textwidth]{figure/indi_square_anomaly.pdf}
    \end{center}
    
    \textbf{Prompt}: Detect univaraite time series of anomalies in this multivariate time series, in terms of ID of univaraite time series. The image is a multivariate time series including multiple subimages to indicate multiple univariate time series. From left to right and top to bottom, the ID of each subimage increases by 1, starting from 0. List one by one in a list. For example, if ID=0, 2, and 5 are anomalous univaraite time series, then output "[0, 2, 5]". If there are no anomalies, answer with an empty list [].
    
    \textbf{Response}: [1, 7]
}
\end{AIbox}
\vspace{-0.4cm}
\caption{The prompt for \textit{variate-wise} anomalies.}
\vspace{-0.8cm}
\label{fig:prompt_variate}
\end{figure}

\vspace{-0.3cm}
\subsection{Time Series Images Construction}
\vspace{-0.2cm}
One crucial element of enabling MLLMs to detect time series anomalies lies in the construction of time series images (TSI). In this subsection, we detail the process of transforming numerical time series data into corresponding TSI.
\\\textbf{Univariate TSI Construction.}
We first inject two types of \textit{point-wise} anomalies and three types of \textit{range-wise} anomalies into univairate time series. Then we convert them into the image format with the x-axis helping MLLMs identify the positions of anomalies. As shown in Figure~\ref{fig:univariate_anomaly}, we derive five types of univariate TSI datasets corresponding to five anomaly categories: global, contextual, seasonal, trend, and shapelet. Each type of dataset consists of 100 different TSI with varying noise. 
\\\textbf{Multivaraite TSI Construction.}
The construction of multivaraite TSI is non-trivial considering the multiple dimensions of time series and limited input context of MLLMs. To effectively represent multivariate time series in a single image, we convert each variable of a multivariate time series into a subimage, and arrange these subimages in a grid format. This concise representation allows MLLMs to capture inter-variable correlations within a single image. We omit coordinate axes as they are not crucial for detecting \textit{variate-wise} anomalies, which emphasize deviations in the overall patterns of time series. Specifically, we place $M$ variables of a multivaraite time series in a grid of size $n \times n$ if $n \times (n-1) < M \leq n \times n$, or a grid of size $n \times (n+1)$ if $n \times n < M \leq n \times (n+1)$. We leave a blank if there exists extra spaces ($M < n \times n$ or $M < n \times (n+1)$). For example, a multivariate time series with 9 variates is arranged in a grid of $3\times3$; a 11-variates time series is arranged in a grid of $3\times4$, with an additional subimage blank. Figure~\ref{fig:multivariate_anomaly} illustrates an example of 11-variates time series.
\\We synthesize four types of multivaraite TSI datasets corresponding to four \textit{variate-wise} anomaly types: triangle, square, sawtooth, and random. Each dataset comprises of 100 multivaraite TSI with varying noise.
\\\textbf{Irregular TSI Construction.}
We build irregular TSI datasets by inheriting from the univariate/multivariate TSI datasets. We randomly omit data points in the univariate/multivariate TSI datasets, and leave the omitted points blank in the visualization. 
\\Examples of univariate, multivariate, and irregular time series images can be found in Appendix~\ref{appendix:TSIexmaple}.


\vspace{-0.3cm}
\subsection{Multimodal LLMs, Prompts, and Metrics}
\vspace{-0.2cm}
In this subsection, we introduce the adopted multimodal LLMs, prompts, and evaluation metrics.
\\\textbf{Multimodal LLMs.} We conduct experiments on the representative multimodal LLMs, including both proprietary and open-source MLLMs. For each MLLM family, we select one larger and one smaller model to ensure a comprehensive evaluation. The proprietary models include GPT-4 (GPT-4o and GPT-4o mini) and Gemini-1.5 (Gemini-1.5-pro and Gemini-1.5-flash); the open-source models consist of LLaVA-NeXT (LLaVA-NeXT-72B and LLaVA-NeXT-8B) and Qwen2-VL (Qwen2-VL-72B-Instruct and Qwen2-VL-7B-Instruct). The details of the MLLMs are in Appendix~\ref{appendix:mllms}.
\\\textbf{Prompts.} We design different prompts for \textit{point-}, \textit{range-}, and \textit{variate-wise} anomalies, respectively. We illustrate the prompt example for \textit{variate-wise} anomalies in Figure~\ref{fig:prompt_variate} as the prompt is more challenging for MLLMs to understand. Other prompt examples can be found in Appendix~\ref{appendix:prompt}.
\\\textbf{Evaluation Metrics.} The performance of TSAD is commonly quantified by precision, recall, and F1 score~\cite{lai2021revisiting}. However, \cite{huet2022local} emphasizes these metrics are unaware of the temporal adjacency and events durations within time series. Instead, for \textit{point-wise} and \textit{range-wise} anomalies, we report precision, recall, and F1 score based on the concept of affiliation as defined in~\cite{huet2022local} for robust evaluation. For \textit{variate-wise} anomalies, we employ vanilla precision, recall, and F1 score to assess MLLMs because \textit{variate-wise} anomalies do not involve temporal adjacency or events durations among variates. We report them in the format of percentage in the discussion.


\begin{table*}[t]
\centering
\caption{Performance on \textit{point-wise} anomalies. The best and the second best performance are bold and underlined.}
\scalebox{0.92}{
\begin{tabular}{l|cccccc|cccccc}
\hline
\textbf{Base Time Series} & \multicolumn{6}{c|}{\textbf{\textit{Sine}}} & \multicolumn{6}{c}{\textbf{Symbols}} \\ 
\textbf{Anomaly Type} & \multicolumn{3}{c}{\textbf{Global}} & \multicolumn{3}{c|}{\textbf{Contextual}} & \multicolumn{3}{c}{\textbf{Global}} & \multicolumn{3}{c}{\textbf{Contextual}}\\
\textbf{Evaluation Metrics} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1}\\ \hline
GPT-4o & 55.71 & \underline{13.19} & 17.91 & 19.26 & 2.91 & 4.66 & 26.97 & 5.95 & 8.53 & 4.67 & 0.92 & 1.30 \\
GPT-4o-mini & 41.03 & 12.85 & 19.09 & 23.84 & 9.17 & 12.99 & 44.10 & 13.79 & 20.07 & 27.94 & 11.26 & 15.04 \\
Gemini-1.5-Pro & \textbf{62.00} & 12.37 & 19.76 & 45.27 & 6.05 & 10.38 & 48.67 & 9.62 & 15.30 & 41.52 & 5.05 & 8.73 \\
Gemini-1.5-Flash  & \underline{58.57} & 8.67 & 14.79 & 21.41 & 1.82 & 3.32 & \underline{49.84} & 7.16 & 12.21 & 17.54 & 1.54 & 2.78 \\
LLaVA-NeXT-72B & 46.26 & 8.64 & 14.01 & 45.82 & 4.26 & 7.68 & 47.92 & 10.90 & 17.33 & 46.56 & 10.91 & 17.33 \\
LLaVA-NeXT-8B & 52.06 & 12.96 & \textbf{20.63} & \underline{49.51} & \textbf{11.38} & \textbf{18.48} & 47.86 & \underline{15.42} & \underline{22.94} & 46.56 & \underline{13.89} & \underline{20.85} \\
Qwen2-VL-72B-Instruct & 51.79 & \textbf{13.44} & \underline{19.93} & \textbf{51.15} & \underline{10.51} & \underline{16.80} & \textbf{51.64} & \textbf{23.89} & \textbf{28.77} & \textbf{51.71} & \textbf{29.92} & \textbf{33.04} \\
Qwen2-VL-7B-Instruct & 47.77 & 8.02 & 13.68 & 49.16 & 7.77 & 13.19 & 45.27 & 8.47 & 14.13 & \underline{47.00} & 9.21 & 14.92 \\
\hline
\end{tabular}
}
% \vspace{-0.3cm}
\label{tab:point}
\end{table*}

\begin{table*}[t]
\centering
\caption{Performance on \textit{range-wise} anomalies. The best and the second best performance are bold and underlined.}
\scalebox{0.77}{
\begin{tabular}{l|ccccccccc|cccccc}
\hline
\textbf{Base Time Series} & \multicolumn{9}{c|}{\textbf{\textit{Sine}}} & \multicolumn{6}{c}{\textbf{Symbols}} \\
\textbf{Anomaly Type} & \multicolumn{3}{c}{\textbf{Seasonal}} & \multicolumn{3}{c}{\textbf{Trend}} & \multicolumn{3}{c|}{\textbf{Shapelet}} & \multicolumn{3}{c}{\textbf{Trend}} & \multicolumn{3}{c}{\textbf{Shapelet}}\\
\textbf{Evaluation Metrics} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1}\\
\hline
GPT-4o & \textbf{55.54} & \textbf{54.11} & \textbf{52.89} & \underline{80.13} & 72.47 & 73.48 & \textbf{82.50} & 68.86 & \underline{72.92} & 50.29 & 42.03 & 44.28 & 43.23 & 32.86 & 36.19 \\
GPT-4o-mini & 15.93 & 22.99 & 18.38 & 48.72 & 61.52 & 52.32 & 44.96 & 60.88 & 50.11 & 50.27 & 60.33 & 52.58 & 47.18 & 68.02 & 54.06 \\
Gemini-1.5-Pro & 50.36 & 45.51 & 46.27 & 78.67 & \underline{78.51} & \underline{75.60} & 78.34 & 66.51 & 69.87 & 53.36 & 48.90 & 48.88 & 42.72 & 33.78 & 36.34 \\
Gemini-1.5-Flash  & 34.26 & 31.17 & 31.79 & \textbf{86.86} & 76.10 & \textbf{78.71} & 78.72 & \underline{70.48} & 72.59 & 54.87 & 44.58 & 47.59 & 42.27 & 34.16 & 36.57 \\
LLaVA-NeXT-72B & 35.44 & 39.95 & 36.15 & 53.11 & 57.22 & 53.29 & 35.81 & 33.80 & 33.55 & 57.00 & 57.83 & 55.55 & 58.11 & 68.18 & 61.11 \\
LLaVA-NeXT-8B & \underline{55.30} & \underline{51.92} & \underline{51.62} & 52.75 & \textbf{83.35} & 62.58 & 51.37 & 60.10 & 53.21 & 7.84 & 11.92 & 8.99 & 30.04 & 53.24 & 37.90 \\
Qwen2-VL-72B-Instruct & 24.44 & 26.27 & 24.92 & 78.32 & 70.82 & 71.63 & \underline{80.66} & \textbf{79.24} & \textbf{78.32} & \textbf{86.98} & \underline{80.17} & \textbf{81.10} & \textbf{91.23} & \textbf{94.28} & \textbf{92.19} \\
Qwen2-VL-7B-Instruct & 38.99 & 43.06 & 40.20 & 51.61 & 49.31 & 48.59 & 23.62 & 27.13 & 24.75 & \underline{73.63} & \textbf{84.83} & \underline{77.56} & \underline{75.08} & \underline{81.76} & \underline{77.70} \\
\hline
\end{tabular}
}
% \vspace{-0.3cm}
\label{tab:range}
\end{table*}

\begin{table*}[h!]
\centering
\caption{Performance on \textit{variate-wise} anomalies ($M=9$) reported in Precision and F1. The best and the second best performance are bold and underlined. The complete results are in Appendix~\ref{appendix:results}.}
\scalebox{0.73}{\begin{tabular}{l|cccccccc|cccccccc}
\hline
\textbf{Base Time Series} & \multicolumn{8}{c|}{\textbf{Sine/Cosine}} & \multicolumn{8}{c}{\textbf{ArticularyWordRecognition}} \\
\textbf{Anomaly Type} & \multicolumn{2}{c}{\textbf{Triangle}} & \multicolumn{2}{c}{\textbf{Square}} & \multicolumn{2}{c}{\textbf{Sawtooth}} & \multicolumn{2}{c|}{\textbf{Random}} & \multicolumn{2}{c}{\textbf{Triangle}} & \multicolumn{2}{c}{\textbf{Square}} & \multicolumn{2}{c}{\textbf{Sawtooth}} & \multicolumn{2}{c}{\textbf{Random}}\\
\textbf{Evaluation Metrics} & \textbf{P} & \textbf{F1} & \textbf{P} & \textbf{F1} & \textbf{P} & \textbf{F1} & \textbf{P} & \textbf{F1} & \textbf{P} & \textbf{F1} & \textbf{P} & \textbf{F1} & \textbf{P} & \textbf{F1} & \textbf{P} & \textbf{F1}\\
\hline
GPT-4o & \underline{39.59} & \underline{47.12} & 56.88 & 63.28 & 43.02 & 53.58 & \underline{84.52} & \underline{86.79} & 46.99 & 54.59 & \underline{81.93} & \underline{86.18} & 43.54 & 48.54 & \underline{23.05} & \textbf{27.64} \\
GPT-4o-mini & 8.46 & 11.82 & 20.68 & 27.82 & 8.13 & 11.26 & 32.92 & 40.79 & 18.19 & 28.35 & 19.23 & 29.08 & 17.13 & 26.56 & 16.78 & 26.15 \\
Gemini-1.5-Pro & \textbf{53.05} & \textbf{51.15} & \textbf{81.42} & \textbf{82.52} & \textbf{80.25} & \textbf{80.47} & \textbf{92.07} & \textbf{92.54} & \textbf{60.92} & \textbf{66.81} & \textbf{87.92} & \textbf{90.34} & \textbf{73.09} & \textbf{79.17} & 13.66 & 16.37 \\
Gemini-1.5-Flash  & 37.57 & 39.21 & \underline{70.58} & \underline{70.70} & \underline{62.67} & \underline{61.94} & 81.67 & 79.94 & \underline{51.86} & \underline{55.87} & 70.26 & 75.15 & \underline{67.42} & \underline{73.44} & \textbf{23.83} & 24.82 \\
LLaVA-NeXT-72B & 15.24 & 23.20 & 16.38 & 24.66 & 14.06 & 21.36 & 18.66 & 25.27 & 19.10 & 28.01 & 16.34 & 25.06 & 15.58 & 23.74 & 18.01 & \underline{26.86} \\
LLaVA-NeXT-8B & 15.25 & 22.19 & 15.25 & 22.19 & 15.25 & 22.19 & 15.08 & 21.99 & 16.05 & 21.14 & 17.87 & 24.14 & 15.80 & 21.29 & 17.26 & 22.85 \\
Qwen2-VL-72B-Instruct & 32.57 & 37.49 & 29.48 & 35.57 & 36.73 & 40.67 & 64.83 & 66.27 & 18.47 & 23.45 & 23.69 & 29.90 & 22.10 & 27.93 & 12.93 & 16.54 \\
Qwen2-VL-7B-Instruct & 21.79 & 22.32 & 26.87 & 29.00 & 20.04 & 21.68 & 39.69 & 39.22 & 19.32 & 24.50 & 19.32 & 24.50 & 19.32 & 24.50 & 19.32 & 24.50 \\
\hline
\end{tabular}
}
% \vspace{-0.5cm}
\label{tab:variate}
\end{table*}



\vspace{-0.4cm}
\section{Results and Analysis}
\vspace{-0.2cm}
\subsection{Scenario 1: Univariate Time Series}\label{sec:uni}
\vspace{-0.2cm}
The univariate time series represents a fundamental scenario in TSAD, where observations are sequentially recorded for a single variable over time. Despite its simplicity, it serves as a critical foundation for assessing MLLM performance before addressing more complex situations.

Table~\ref{tab:point} and Table~\ref{tab:range} compare the MLLMs across \textit{point-} and \textit{range-wise} anomalies, respectively. Accordingly, we have the following observations:
\\\textbf{\textit{Range-wise} anomalies are easier to detect than \textit{point-wise} anomalies}. Specifically, the ranking of anomaly categories w.r.t. detection performance is: \textit{trend}$>$\textit{shapelet}$>$\textit{seasonal}$>$\textit{global}$>$\textit{contextual}. The former three are \textit{range-wise}, and the latter two belong to \textit{point-wise}. For example, GPT-4o obtains recall score $72.47$, $68.86$, $54.11$, $13.19$, and $2.91$ on trend, shapelet, seasonal, global, and contextual, respectively, for \textit{sine} waves as base time series. The primary reason is that \textit{range-wise} anomalies, consisting of sequences of point anomalies that significantly deviate from normal patterns, are more distinguishable than dispersed \textit{point-wise} anomalies. 
This observation is further supported by Figure~\ref{fig:univariate_anomaly}.
\\\textbf{Open-source MLLMs outperform proprietary models in detecting \textit{point-wise} and \textit{range-wise} anomalies}. Qwen2-VL-72B-Instruct, the SOTA open-source MLLM, achieves the highest or second-highest F1 score on \textit{point-wise} anomalies and demonstrates comparable or superior effectiveness to other MLLMs across most \textit{range-wise} anomalies. For example, when base time series employs Symbols dataset, Qwen2-VL-72B-Instruct attains F1 scores of $28.77$, $33.04$, $81.10$, and $92.19$ on global, contextual, trend, and shapelet anomalies, respectively, outperforming all other MLLMs.
\\\textbf{Real-world time series does not increase the difficulty of time series anomaly detention.} We do not observe significant performance degradation when base time series transitions from classical \textit{sine} waves to the real-world dataset. For instance, GPT-4o family and Gemini-1.5 family exhibit reduced effectiveness, whereas Qwen2-VL family shows improved performance in detecting trend and shapelet anomalies when shifting from \textit{sine} waves to real-world dataset.

\begin{center}
% \vspace{-5mm}
\begin{tcolorbox}[width=0.99\linewidth, boxrule=3pt, colback=gray!20, colframe=gray!20]
\textbf{Insight 1:} 
(1) MLLMs are more effective at detecting coarse-granularity (\textit{range-wise}) than fine-granularity (\textit{point-wise}) anomalies in univaraite time series; (2) Open-source MLLMs outperform proprietary models in the univaraite scenario.
\end{tcolorbox}
% \vspace{-1mm}
\end{center}


\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{figure/bar_multi.pdf}
     \vspace{-0.8cm}
     \caption{The impact of number of dimensions $M$ on MLLMs for \textit{variate-wise} anomalies}
     \vspace{-0.5cm}
    \label{fig:bar_multi}
\end{figure*}

\vspace{-0.4cm}
\subsection{Scenario 2: Multivariate Time Series}
\vspace{-0.2cm}
Multivariate time series is composed of multiple variables (features) recorded over time. Unlike univariate time series, which tracks a single variable, multivariate time series involve multiple interdependent variables that may influence or correlate with each other. Multivariate time series is ubiquitous in real-world applications such as urban analytics~\cite{tabassum2021actionable}, scientific computing~\cite{xu2024surrogate}, and climate modeling~\cite{zhu2023weather2k}. For example, in climate modeling, the recorded features might consist of temperature, humidity, wind speed, and rainfall observed at regular time intervals like hourly or daily.

Table~\ref{tab:variate} compares MLLMs on \textit{variate-wise anomalies}. We observe the below findings:
\\\textbf{The \textit{variate-wise} anomalies can be generally identified by MLLMs}. The SOTA MLLM, Gemini-1.5-Pro, is capable of achieving the maximum F1 score $92.54$ and $90.34$ on synthetic and real-world dataset, respectively. The impressive results demonstrates that MLLMs can capture inter-variables relationship in multivariate TSI and thus lead to enhanced detection performance. It also suggests that, compared to \textit{point-} and \textit{range-wise}, \textit{variate-wise} anomalies can be detected with the highest performance as they exhibit the coarsest granularity.
\\\textbf{Proprietary MLLMs are superior to open-source models in detecting \textit{variate-wise} anomalies.} We clearly observe that almost all the best and the second best performance lies in the proprietary MLLMs. It indicates that proprietary models are capable of understanding multivariate TSI and capturing inter-variable relationship, leading to enhanced anomaly detection performance.
\\\textbf{The detection of \textit{variate-wise} anomalies heavily depends on patterns of the majority of variables within a multivaraite time series}. On time series governed by \textit{sine}/\textit{cosine} waves, Gemini-1.5-Pro attains the highest F1 score $92.54$ for random anomalies. However, for the same anomaly type in real-world time series, its performance drops significantly to an F1 score of $16.37$. This discrepancy arises as the random walk pattern deviates substantially from \textit{sine}/\textit{cosine} waves, whereas most time series in the ArticularyWordRecognition dataset closely resemble a random walk.

\textbf{Impact of Variates M.} We also investigate the impact of the number of variates $M$ in multivariate TSI. Intuitively, as $M$ increases, the information density that MLLMs must process grows. Moreover, this comes at the cost of reduced resolution for each subimage (variate). Consequently, \textbf{the effectiveness of MLLMs decreases as $M$ increases}. Figure~\ref{fig:bar_multi} illustrates this effect, showing a gradual decline in detection performance from $M=4$ to $M=36$, which aligns with our intuition. For instance, Gemini-1.5-Pro achieves an impressive F1 score of $100$ at $M=4$, but this drops significantly to $33.2$ when $M=36$.

\textbf{Hallucination.} We find that MLLMs, particularly small-scale open-source models such as LLaVA-NeXT-8B and Qwen2-VL-7B-Instruct, are prone to generating hallucinated responses when handling multivariate TSI. For example, when given a 9-dimensional time series as input, LLaVA-NeXT-8B may produce an ungrounded sequence such as "[0, 1, 2, \dots, 100, 101, 102, \dots]" until reaching the maximum token limit. This hallucination arises because prompts for variate-wise anomalies pose significantly greater challenges to MLLMs' comprehension capabilities compared to \textit{point-} and \textit{range-wise} anomalies. Small-scale open-source models, in particular, often fail to fully grasp the complexity of such prompts. 

\begin{center}
\vspace{-2mm}
\begin{tcolorbox}[width=0.99\linewidth, boxrule=3pt, colback=gray!20, colframe=gray!20]
\textbf{Insight 2:} 
(1) MLLMs generally can effectively detect \textit{variate-wise} anomalies in multivariate time series.  
(2) Proprietary MLLMs outperform open-source models in the multivariate scenario.  
(3) MLLMs are sensitive to dimensionality and can generate hallucination for multivariate time series.
\end{tcolorbox}
\end{center}


\begin{figure*}[!t]
    \centering
    \includegraphics[width=\textwidth]{figure/line_irr.pdf}
     \vspace{-0.8cm}
     \caption{The impact of the irregularity ratio $r$ on MLLMs for \textit{point-wise}, \textit{range-wise}, and \textit{variate-wise} anomalies.}
     \vspace{-0.5cm}
    \label{fig:irregular}
\end{figure*}

\vspace{-0.3cm}
\subsection{Scenario 3: Irregular Time Series}\label{sec:irr}
Irregular time series are characterized by unevenly spaced observations. Unlike regular time series, which assume consistent sampling intervals, irregular time series naturally arise in domains where data collection is influenced by external factors. For instance, in healthcare domain~\cite{li2024time}, sensor readings from wearable devices may be recorded at irregular intervals due to the patient activity or device connectivity. These irregularities pose unique challenges for traditional time series analysis, as standard techniques often assume fixed sampling rates. 

We conduct irregular time series experiments by changing the irregularity ratio $r$ from $5\%$ to $25\%$. Figure~\ref{fig:irregular} compares MLLMs on irregular univariate/multivariate time series. 
\\We clearly observe that \textbf{MLLMs exhibit strong robustness against the challenges posed by irregularity.} Irregular time series, characterized by inherent inconsistencies, are often more challenging and can degrade the performance of traditional TSAD algorithms. However, MLLMs effectively mitigate the negative effects of irregularity by representing the entire time series with leaving missed values blank. This intuitive visualization approach preserves the overall patterns of time series, enabling MLLMs to detect anomalies. For example, on \textit{point-wise} anomalies, the maximum performance degradation (Gemini-1.5-Flash) among all MLLMs is only a $4.89$ decrease of F1 score. This result underscores the effectiveness of visualization and capability of MLLMs to handle time series irregularities.

\begin{center}
% \vspace{-5mm}
\begin{tcolorbox}[width=0.99\linewidth, boxrule=3pt, colback=gray!20, colframe=gray!20]
\textbf{Insight 3:} 
Visualizing time series as images is a highly effective way to represent irregular time series. This approach enables MLLMs to demonstrate strong robustness against challenges posed by irregularity.
\end{tcolorbox}
\vspace{-1mm}
\end{center}

\section{Implications on Time Series Anomaly Detection in the Era of Multimodal LLMs}
% \vspace{-0.2cm}
Our empirical analysis have key implications on TSAD and general time series tasks in the era of multimodal LLMs. First, our findings imply that \textbf{MLLMs excel at identifying broader patterns and dependencies within time series data.} This capability is crucial for applications where anomalies manifest as broader patterns such as financial market trends. Second, the robustness of MLLMs to irregular time series, even with significant data dopped, highlights that \textbf{MLLMs have great potential in real-world applications with compromised data quality.} This resilience makes MLLMs a viable option for domains like healthcare, IoT, and environmental monitoring, where missing or irregularly sampled data is common. 
Finally, \textbf{there is a paradigm shift of time series tasks from numerical data into multimodal format.} By integrating multimodal capabilities, models can understand multimodal information (e.g., text, images, or domain knowledge) to enhance detection accuracy. We call for future research to explore how multimodal inputs can be further leveraged to improve not only time series anomaly detection but also general time series tasks such as forecasting, classification, and imputation. 

\vspace{-0.1cm}
\section{Conclusion and Future Work}
% \vspace{-0.2cm}
In this paper, we address the research question: \textit{Can multimodal LLMs perform time series anomaly detection?} We introduce a novel image-based benchmark, {\m}, which provides a comprehensive evaluation of MLLMs for TSAD, offering valuable insights into their strengths and limitations across diverse scenarios. 
Our findings reveal several key insights: 
1) MLLMs exhibit stronger capabilities in detecting \textit{range-} and \textit{variate-wise} anomalies than \textit{point-wise} anomalies; 2) MLLMs demonstrate robustness against the irregularity of time series; 3) open-source models excel in univariate scenarios, whereas proprietary models perform more effectively on multivariate data. Our work paves the way for further research at the intersection of MLLMs and time series analysis.

Despite these valuable contributions, we encounter challenges that inspire future research. For instance, small-scale open-source MLLMs such as LLaVA-NeXT-8B exhibit a tendency to generate hallucinations for multivariate time series. Mitigating hallucinations of MLLMs for time series anomaly detection presents an exciting research direction. Moreover, exploring more effective approaches to visualize time series as images, particularly for high-diemensional multivariate time series is promising.

\section*{Impact Statement}
This paper presents work whose goal is to advance the field of multimodal LLMs and time series analysis. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
% \nocite{langley00}

\bibliography{main}
\bibliographystyle{main}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\input{appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
