\section{Related Works}
\subsection{Frame semantic parsing}
The literature on frame parsing can be broadly divided into two main approaches: methods that frame the task as a sequence-to-sequence (Seq2Seq) generation problem and methods based on representation learning. 

Seq2Seq approaches \citep{sutskever2014sequence,raffel2020exploring,kalyanpur2020open,chanin2023open} define frame parsing as a generative task, decomposing it into subtasks such as trigger identification, frame classification, and argument extraction. These methods leverage pre-trained language models and task-specific optimizations to balance the subtask distributions and mitigate data scarcity \citep{kalyanpur2020open,chanin2023open}. As illustration, models like T5 \citep{raffel2020exploring} are pre-trained on PropBank \citep{kingsbury2002treebank, kingsbury2003propbank} and FrameNet exemplars, with text augmentation techniques applied to improve robustness and FrameNet lexical units incorporated to enhance frame classification accuracy. Then, they are fine-tuned on each of the aforementioned sub-tasks. 
For exemple, \citep{kalyanpur2020open} adopt a shared encoder with specialized decoders for each sub-task, enabling the model to leverage a common representation while handling each task independently within the same architecture. The Seq2Seq methods share a focus on utilizing the flexibility of generative models to capture the sequential nature of frame parsing tasks. 

Representation learning approaches, in contrast, focus on constructing enriched embeddings that align sentence-level context (or just the target span) with candidate frames \citep{hartmann2017out, jiang2021exploiting}. They often employ graph-based techniques, such as Graph Neural Networks (GNNs) \citep{wu2020comprehensive}, or contrastive learning \citep{ju2024towards} to incorporate external knowledge and enhance the robustness of frame representations. These methods also emphasize semantic alignment through embedding techniques that integrate knowledge from FrameNet's structure. Graph-based methods, for instance, exploit relationships between frames and frame elements \citep{su2021knowledge, zheng2022double, tamburini2022combining}, while contrastive learning approaches align contextual representations of target span with frame embeddings to refine predictions  \citep{hartmann2017out,jiang2021exploiting,an2023coarse}.

A key limitation that hinders these approaches from generalizing effectively and being applicable in real-world scenarios is their reliance on both the context (text/sentence) and a target, which has to be specified at input. For instance, consider the sentence: \textit{"We help people train for and find jobs that make it possible for them to get off of welfare."}. To detect the frame \textit{"Assistance,"} these approaches require information about the position of the target span %specifically \(target_{start} = 1\) and \(target_{end} = 1\), which correspond to the span
\textit{"help"}. This dependency restricts their flexibility and reduces their practical utility in settings where only raw text without predefined targets is available.

To address the computational challenges in frame detection, we propose an approach to reduce the search space by first retrieving a subset of potential candidate frames that are likely to be evoked by the sentence. By limiting the frame search space, we aim to decrease the number of frame evaluations for each word, thereby reducing overall complexity.

\subsection{SPARQL queries generation}
One interesting task that can benefit from the same semantic representation for diverse natural language formulations is the task of SPARQL query generation from natural language questions. The existing literature on SPARQL query generation from natural language predominantly centers around the use of pretrained language models \citep{diallo2024comprehensive, reyd2023assessing, banerjee2022modern, emonet2024llm, zahera2024generating}. Small Language Models (SLMs) are commonly fine-tuned in an end-to-end manner, often incorporating mechanisms such as copy strategies to minimize errors in generating URIs within the final queries \citep{diallo2024comprehensive, banerjee2022modern}. In contrast, Large Language Models (LLMs) are partially employed to generate answers directly by grounding facts from knowledge bases, bypassing the intermediate step of explicit query generation \citep{shavarani2024entity, alawwad2024enhancing, muennighoff2022sgpt}. Another line of research explores various prompt engineering techniques during fine-tuning, with or without demonstrations, and sometimes incorporates additional contextual information such as the URIs required in the generated SPARQL queries \citep{diallo2024comprehensive, muennighoff2022sgpt, luo2023chatkbqa}. Notable examples include models such as Code Llama v2 7B \citep{roziere2023code}, Mistral 7B v0.3 \citep{jiang2023mistral7b}, and Mistral 7B Instruct v0.3\footnote{https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3}. Despite leveraging large pretrained models, these approaches often neglect a detailed examination of their performance on various formulations of the same question, or try to include paraphrases to produce more robust models. A simple comparison between performance on template questions and reformulated questions in the LCQuAD 2 dataset shows that natural questions are poorly handled by models \citep{diallo2024comprehensive, reyd2023assessing}.   

By leveraging frame semantic parsing to represent natural language questions as structured representations, our approach seeks to enhance generalization on template-free or reformulated questions.