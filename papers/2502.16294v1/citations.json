[
  {
    "index": 0,
    "papers": [
      {
        "key": "attention_is_all_you_need",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \\L ukasz and Polosukhin, Illia",
        "title": "Attention is All you Need"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "haoyietal-informer-2021",
        "author": "Haoyi Zhou and\nShanghang Zhang and\nJieqi Peng and\nShuai Zhang and\nJianxin Li and\nHui Xiong and\nWancai Zhang",
        "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting"
      },
      {
        "key": "wu2021autoformer",
        "author": "Haixu Wu and Jiehui Xu and Jianmin Wang and Mingsheng Long",
        "title": "Autoformer: Decomposition Transformers with {Auto-Correlation} for Long-Term Series Forecasting"
      },
      {
        "key": "zhou2022fedformer",
        "author": "Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong",
        "title": "{FEDformer}: Frequency enhanced decomposed transformer for long-term series forecasting"
      },
      {
        "key": "logtrans",
        "author": "Li, Shiyang and Jin, Xiaoyong and Xuan, Yao and Zhou, Xiyou and Chen, Wenhu and Wang, Yu-Xiang and Yan, Xifeng",
        "title": "Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting"
      },
      {
        "key": "Yuqietal-2023-PatchTST",
        "author": "Nie, Yuqi and\nH. Nguyen, Nam and\nSinthong, Phanwadee and \nKalagnanam, Jayant",
        "title": "A Time Series is Worth 64 Words: Long-term Forecasting with Transformers"
      },
      {
        "key": "liu2022pyraformer",
        "author": "Liu, Shizhan and Yu, Hang and Liao, Cong and Li, Jianguo and Lin, Weiyao and Liu, Alex X and Dustdar, Schahram",
        "title": "Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting"
      },
      {
        "key": "zhang2023crossformer",
        "author": "Yunhao Zhang and Junchi Yan",
        "title": "Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "liu2023itransformer",
        "author": "Liu, Yong and Hu, Tengge and Zhang, Haoran and Wu, Haixu and Wang, Shiyu and Ma, Lintao and Long, Mingsheng",
        "title": "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zhou2022fedformer",
        "author": "Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong",
        "title": "{FEDformer}: Frequency enhanced decomposed transformer for long-term series forecasting"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "Yuqietal-2023-PatchTST",
        "author": "Nie, Yuqi and\nH. Nguyen, Nam and\nSinthong, Phanwadee and \nKalagnanam, Jayant",
        "title": "A Time Series is Worth 64 Words: Long-term Forecasting with Transformers"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "wav2vec",
        "author": "Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael",
        "title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations"
      },
      {
        "key": "hsu_conv",
        "author": "Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman",
        "title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "liu2023itransformer",
        "author": "Liu, Yong and Hu, Tengge and Zhang, Haoran and Wu, Haixu and Wang, Shiyu and Ma, Lintao and Long, Mingsheng",
        "title": "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "orozco",
        "author": "Bernardo P{\\'{e}}rez Orozco and\nStephen J. Roberts",
        "title": "Zero-shot and few-shot time series forecasting with ordinal regression\nrecurrent neural networks"
      },
      {
        "key": "Oreshkin_Carpov_Chapados_Bengio_2021",
        "author": "Oreshkin, Boris N. and Carpov, Dmitri and Chapados, Nicolas and Bengio, Yoshua",
        "title": "Meta-Learning Framework with Applications to Zero-Shot Time-Series Forecasting"
      },
      {
        "key": "domain-adapt",
        "author": "Jin, Xiaoyong and Park, Youngsuk and Maddix, Danielle and Wang, Hao and Wang, Yuyang",
        "title": "Domain Adaptation for Time Series Forecasting via Attention Sharing"
      },
      {
        "key": "dooley2023forecastpfn",
        "author": "Dooley, Samuel and Khurana, Gurnoor Singh and Mohapatra, Chirag and Naidu, Siddartha V and White, Colin",
        "title": "ForecastPFN: Synthetically-trained zero-shot forecasting"
      },
      {
        "key": "ansari2024chronos",
        "author": "Ansari, Abdul Fatir and Stella, Lorenzo and Turkmen, Caner and Zhang, Xiyuan and Mercado, Pedro and Shen, Huibin and Shchur, Oleksandr and Rangapuram, Syama Syndar and Pineda Arango, Sebastian and Kapoor, Shubham and Zschiegner, Jasper and Maddix, Danielle C. and Wang, Hao and Mahoney, Michael W. and Torkkola, Kari and Gordon Wilson, Andrew and Bohlke-Schneider, Michael and Wang, Yuyang",
        "title": "Chronos: Learning the Language of Time Series"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "ansari2024chronos",
        "author": "Ansari, Abdul Fatir and Stella, Lorenzo and Turkmen, Caner and Zhang, Xiyuan and Mercado, Pedro and Shen, Huibin and Shchur, Oleksandr and Rangapuram, Syama Syndar and Pineda Arango, Sebastian and Kapoor, Shubham and Zschiegner, Jasper and Maddix, Danielle C. and Wang, Hao and Mahoney, Michael W. and Torkkola, Kari and Gordon Wilson, Andrew and Bohlke-Schneider, Michael and Wang, Yuyang",
        "title": "Chronos: Learning the Language of Time Series"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "dooley2023forecastpfn",
        "author": "Dooley, Samuel and Khurana, Gurnoor Singh and Mohapatra, Chirag and Naidu, Siddartha V and White, Colin",
        "title": "ForecastPFN: Synthetically-trained zero-shot forecasting"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "muller2022transformers",
        "author": "Samuel M{\\\"u}ller and Noah Hollmann and Sebastian Pineda Arango and Josif Grabocka and Frank Hutter",
        "title": "Transformers Can Do Bayesian Inference"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "verdenius2024lat",
        "author": "Verdenius, Stijn and Zerio, Andrea and Wang, Roy LM",
        "title": "LaT-PFN: A Joint Embedding Predictive Architecture for In-context Time-series Forecasting"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "bhethanabhotla2024mamba4castefficientzeroshottime",
        "author": "Sathya Kamesh Bhethanabhotla and Omar Swelam and Julien Siems and David Salinas and Frank Hutter",
        "title": "Mamba4Cast: Efficient Zero-Shot Time Series Forecasting with State Space Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "gu2024mambalineartimesequencemodeling",
        "author": "Albert Gu and Tri Dao",
        "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"
      }
    ]
  }
]