% !TEX root = ../top.tex
% !TEX spellcheck = en-US

\section{Related Work}
\label{sec:related}

Over the last several decades, the evolution of traditional CAD systems has reflected a fundamental tension between simplicity and expressiveness. Early approaches relied on basic geometric primitives such as spheres, cylinders, and NURBS surfaces~\cite{Piegl91}, offering mathematical precision but limited representational power. Recent years have witnessed a shift toward more sophisticated primitives, from simple cuboids~\cite{Tulsiani17b, Niu18, Sun19b, Kluger21} to learned deep representation, which we briefly review here. We start with generic 3D shape representations learned from data and continue with more-flexible part-based approaches. 
% \cite{Tulsiani17b, Zou17a, Niu18, Sun19b, Smirnov20, Kluger21}

%-------------------------------------------------------------------------
\subsection{Learned 3D Shape Representation}

Learning-based methods for 3D shape representation have evolved significantly, beginning with explicit approaches such as voxel grids, point clouds, and meshes. Voxel-based methods~\cite{Wu15b, Wu16b, Choy16b, Dai17a} partition 3D space into grids, but are memory-intensive at finer resolutions, which can be mitigated using octrees~\cite{Riegler17, Tatarchenko17}, but only up to a point. Point clouds reduce memory costs by representing shapes as surface points but ignore connectivity, which can compromise topological consistency~\cite{Fan17a, Yang18a, Achlioptas18b, Peng21a, Zeng22}. Meshes, though well-suited for detailed surface representation, impose a rigid topology that is difficult to modify~\cite{Groueix18a, Kanazawa18b, Wang18e, Pan19}.
% \cite{Wu15b, Wu16b, Choy16b, Brock16, Dai17a}
% \cite{Riegler17, Tatarchenko17, Hane17}
% \cite{Fan17a, Yang18a, Achlioptas18b, Yang19d, Peng21a, Zeng22}
% \cite{Litany18, Groueix18a, Kanazawa18b, Pan19, Wang18e, Wen19a}

Implicit Neural Representations (INRs) offer a flexible alternative, defining shapes as continuous functions of the 3D space that encode  the surface implicitly~\cite{Park19c, Mescheder19, Chen19c, Xu19b}. It can then be recovered explicitly using meshing algorithms~\cite{Lorensen87, Lewiner03, Ju02}. Even though these meshing algorithms may not be themselves differentiable, differentiability can be preserved by relying on the implicit function theorem~\cite{Guillard24a}, enabling back-propagation from the explicit surface, for example when optimizing a shape to maximize its aerodynamic performance~\cite{Baque18}. Extensions enable shape manipulation~\cite{Hao20a}, point-cloud reconstruction~\cite{Peng20c}, and training directly from point data~\cite{Atzmon20, Gropp20}. Newer works~\cite{Sitzmann20, Takikawa21} improve the accuracy further with new latent representations, such as irregular grids~\cite{Zhang22b} or unordered sets~\cite{Zhang23d}.

%-------------------------------------------------------------------------
\input{fig/pipeline}

\subsection{Part Based Models}

As effective as they are, the INRs described above model 3D shapes as single entities, limiting their capacity to represent structured, part-based composite objects. This requires decomposing the shapes into their component parts, which can be done in a supervised or unsupervised manner. 

\parag{Unsupervised Part Decomposition.}

Early unsupervised approaches learn shape abstractions using local primitives such as cuboids~\cite{Tulsiani17b, Zou17a, Sun19b, Smirnov20, Yang21a}, superquadrics~\cite{Paschalidou19, Paschalidou20}, anisotropic Gaussians~\cite{Genova19}, or convexes~\cite{Deng20c}, approximating complex shapes as combinations of simpler parts. More recently, complex objects are better represented by predicting and deforming primitives~\cite{Paschalidou21, Shuai23}, creating deformable part templates~\cite{Hui22, Chen24b}, or performing part-based co-segmentation, which consistently divides shapes into parts across a dataset without relying on labeled boundaries~\cite{Hertz22} or does so for only a subset of the data~\cite{Chen19i}. For shape manipulation, SPAGHETTI~\cite{Hertz22} utilizes a transformer to predict Gaussian parts from a global latent vector and reconstructs them into a single cohesive object. This approach supports interactive editing of user-defined parts and can be combined with \SALAD~\cite{Koo23}, which employs a cascaded diffusion model for part generation.
% \cite{Tulsiani17b, Zou17a, Niu18, Sun19b, Kluger21, Smirnov20, Yang21a}
%
However, the parts learned by these methods are typically arbitrary and lack semantic meaning, making them unsuitable for tasks requiring specific, predefined part structures.

%-------------------------------------------------------------------------
\parag{Supervised Part Representation.}

Supervised methods leverage known part decompositions to create explicit, structured representations of composite shapes. HybridSDF~\cite{Vasu22} mixes INRs with geometric primitives to represent and manipulate shapes, while ANISE~\cite{Petrov23} learns to assemble implicit parts for reconstruction from images and point clouds. Instead, ProGRIP~\cite{Deng22b}, \PQNET~\cite{Wu20c}, and PASTA~\cite{Li24c} focus on composite shape generation. ProGRIP relies on shape programs to produce composite INR shapes, while \PQNET{} uses a GRU-based RNN~\cite{Cho14b} as an auto-encoder for sequences of parts, with latentGANs~\cite{Achlioptas18b} for generation. PASTA employs an auto-regressive transformer to predict part bounding boxes that are decoded into a single global shape, similarly to SPAGHETTI.

While effective for shape generation, these supervised methods forgo part consistency across shapes and continuous shape parametrization. Thus, there is a need for an approach that leverages part supervision to produce modular, flexible representations that can output composite shapes by parts and act as part and shape priors in backward tasks such as optimization. \PSDF{} aims to fulfill that need.

%--------------------------
% OLD
%--------------------------
\iffalse


% Local implicit representations decompose shapes into simpler components for flexible representation and manipulation. Early approaches learn shape abstractions using local primitives such as cuboids~\cite{Tulsiani17b, Zou17a, Niu18, Sun19b, Kluger21, Smirnov20, Yang21a}, superquadrics~\cite{Paschalidou19, Paschalidou20}, anisotropic Gaussians~\cite{Genova19}, or convexes~\cite{Deng20c}, approximating complex shapes as combinations of simpler parts. To better represent complex objects, some works predict and deform primitives~\cite{Paschalidou21, Shuai23} or create deformable part templates~\cite{Hui22, Chen24b}.
%

CAD systems~\cite{OnShape,SolidWorks,TopSolid}  are routinely used  to create, modify, analyze, and optimize object designs. These systems enable users to assemble shape primitives to create complex models that satisfy a number of design constraints. Their parameters can then be tuned to maximize performance criteria or reconstruct object from images. 

In addition to simple primitives such as spheres and cylinders, more sophisticated ones such as cuboids~\cite{Tulsiani17b, Zou17a, Niu18, Sun19b, Kluger21, Smirnov20}, superquadrics~\cite{Paschalidou19, Paschalidou20}, anisotropic Gaussians~\cite{Genova19}, or convexes~\cite{Deng20c} have been proposed. All these works rely on a single primitive type to represent the entire shape. Hence, for complex shapes, reconstruction accuracy directly depends on the number of primitives used. To improve on this, the approach of~\cite{Paschalidou21} defines a bijective function between traditional spherical primitives and a corresponding set of deformed shapes that can be arbitrarily complex. In recent years, there has been increasing interest in using deep-learning techniques for automated generation of such models from images and point clouds~\cite{Para21,Willis22,Yu22b}. Unfortunately, a limitation is that these models contain symbolic elements that cannot be differentiated through, which makes them difficult to use as part of a deep-learning pipeline designed for shape optimization. Some recent methods work around this problem by fitting differentiable primitives to the descriptions~\cite{Uy22,Lambourne22,Deng22b} but still lack generic mechanisms to guarantee that arbitrary design constraints remain satisfied when changing the model parameters. This may be achieved through post-processing~\cite{Uy22}, which is also difficult to incorporate into an end-to-end trainable pipeline. 

\PF{Mention Spaghetti and related approaches here? Contrast to yours?}



%% 3D Shape representations
%Advancement in the field: from voxels to PC to mesh to implicit representations. Can introduce here SDF and INR (Implicit Neural Representation).
%
%Voxels: \cite{Wu15b, Wu16b, Choy16b, Brock16, Dai17a} (Octree: \cite{Riegler17, Tatarchenko17, Hane17})
%Point clouds: (PC processing \cite{Qi17a, Qi17b, Wang18b}) \cite{Fan17a, Yang18a, Achlioptas18b, Yang19d, Peng21a, Zeng22}
%Meshes: \cite{Litany18, Groueix18a, Kanazawa18b, Pan19, Wang18e, Wen19a}
%
%INR (initial): DeepSDF, IM-Net, Occ, DISN \cite{Park19c, Mescheder19, Chen19c, Xu19b}
%DualSDF \cite{Hao20a}
%Convocc \cite{Peng20c} (noisy PC recon)
%SAL \cite{Atzmon20} (no sign needed with good init)
%IGR \cite{Gropp20} (trained from (oriented) PC)
%SIREN \cite{Sitzmann20} (improved details)
%nglod \cite{Takikawa21} (level of details)
%3DILG \cite{Zhang22b} ()
%3DS2VS \cite{Zhang23d} (new latent repr and model)
%
%Meshing algorithm MC/DC \cite{Lorensen87, Lewiner03, Ju02}, and diff through it MeshSDF \cite{Remelli20b}, for optimization Baqu√© \cite{Baque18}.
%
%In this work: parametrize part-aware shapes as part-INR.

%% Unsupervised part decomp
%Different branch of works focused on local representations that contribute to a single global shape, like convexes or local patches.
%
%This also made unsupervised decomposition emerged as a solution: co-segmentation, learning a part decomposition for manipulability, part based generation... Attempt to extract meaningful parts, though consistency and interpretability are still a challenge
%
%TO CITE:
%Cvx \cite{Deng20c}
%unsup cuboid decomposition \cite{Yang21a}
%ProGRIP \cite{Deng22b} (repeatable parts (based on unsup decomp))
%Neural Template \cite{Hui22} (learn deformable templates)
%SPAGHETTI (SALAD)  \cite{Hertz22, Koo23} (transfo \cite{Vaswani17}) (enable manipulation through transformer between parts (gaussian based))
%PartNeRF  \cite{Tertikas23} (use?)
%DPF-Net  \cite{Shuai23} (prim deform to learn good shape abstraction)
%DAE-NET \cite{Chen24b} (deformed templates for co-seg)
%
%In this work: unlike these who learn a decomposition to increase representation, add local manipulation, or learn to segment shapes (in arbitrary manner), we focus on existing decomposition to create a part-aware shape prior.

%% Supervised part repr
%Works focusing on (known) composite shapes, meaning that use part labels. They leverage prior knowledge for meaningful part decomposition, mostly used as a generative tool. We also want to keep the use of our model as a shape prior.
%
%TO CITE:
%BAE-NET \cite{Chen19i}
%PQ-NET \cite{Wu20c} (latentGAN: \cite{Achlioptas18b})
%ANISE  \cite{Petrov23}
%Part-aware gen [...] \cite{Huang24} (?)
%PASTA  \cite{Li24c} (generate a *single* shape, conditioned on part cuboids)
%
%In this work: consider shapes as a \textit{consistent} assembly of parts. Instead of focusing on their generation only, we aim to provide a flexible parametrization to be used for many purpose, such as shape prior for optimization. Our work can be seen as a "direct" extension of DeepSDF in the multi-part case.


\fi