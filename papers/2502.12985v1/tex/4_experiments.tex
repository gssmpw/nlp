% !TEX root = ../top.tex
% !TEX spellcheck = en-US

\section{Experiments}
\label{sec:experiments}

\input{table/recon}  % moved earlier


In this section, we  demonstrate how our method can be applied to various tasks and compare it to several part-based baselines.
Further experimental details and additional results are available in \cref{sec:supp-impl} and \ref{sec:supp-results}, respectively.

\parag{Datasets} Obtaining high-quality composite shape data is challenging as many detailed datasets tend to remain private. Public datasets, such as ShapeNet~\cite{Chang15} and PartNet~\cite{Mo19}, often suffer from over-segmentation and inconsistencies in part definitions across samples, or provide only coarse semantic segmentations that lack the granularity needed for precise part manipulation. To remedy this, we use three curated datasets that offer consistent and well-defined part decompositions: (1) \textit{Car}, a hand-processed subset of ShapeNet in which the wheels of the cars are separated from the main body; (2) \textit{Mixer}, a set of  liquid mixers made of a central helix within a tube and two attach points~\cite{Vasu22}; and (3) \textit{Chair}, a cleaned subset of ShapeNet chairs, segmented with PartNet’s semantic labels and further divided into individual legs and arms. There are 1046, 1949, and 1332 shapes in each dataset with 5, 4, and 8 parts, respectively. We use $80\%$ of the data for training and the remaining $20\%$ as the unseen test set.
%We use $80\%$ of the data for training and the remaining $20\%$ for testing.
%Each dataset is split into train and test sets ($80\%/20\%$). Model hyperparameters are tuned using the train and validation sets, and final models, as reported below, are trained on train+validation and evaluated on the test set. Part poses are obtained by fitting each part with a cuboid or a cylinder.

\parag{Baselines.} 
%
For part-based baselines, we have unfortunately found no publicly available code for modern architectures such as ProGRIP~\cite{Deng22b}, SPAGHETTI~\cite{Hertz22} and PASTA~\cite{Li24c}. We therefore use \DAENET~\cite{Chen24b} that learns deformable part template in an \textit{unsupervised} manner, \BAENET~\cite{Chen19i} that uses \textit{weak supervision} with 8 labeled shapes, and \PQNET~\cite{Wu20c}, a \textit{fully-supervised} approach that supports shape generation. 
As these part-based baselines are several years old, we also compare against the state-of-the-art \VecSet{}, or \VecSetShort{} for short~\cite{Zhang23d}. It is not ideal because, not being part-based, it is not suitable for engineering design. However, it gives an upper bound on the accuracy that can currently be obtained if one ignores the part decomposition, which typically allows for higher precision than when enforcing it. 
%We run all baselines using the data preprocessing methods recommended by their respective authors.


%We compare against a part-agnostic baseline, \DSDFp{}, an updated version of \DSDF~\cite{Park19c} with latent modulation added. 

\parag{Metrics.} Reconstruction accuracy is assessed using three different metrics: Chamfer-Distance (CD) for surface accuracy, Intersection over Union (IoU) for volume, and Image Consistency (IC)~\cite{Guillard22b} for shape appearance and normals. Part reconstruction is evaluated by averaging the per-part IoU and, as we do not make the assumption that parts must be watertight, we compute part occupancies using the same strategy as for  our training losses in \cref{sec:method-train}. For generation, we report Minimum Matching Distance (MMD) and Coverage Score (COV)~\cite{Achlioptas18b}, using CD as the distance metric.

%-------------------------------------------------------------------------
\subsection{Shape and Part Reconstruction}
\label{sec:exp-recon}

% Reconstruction: can initialize with average shape/poses and optimize for SDF. Can try part SDF to see if present in model, and only global to see if can retrieve without. Also: encoder (PC or auto-decoder from global) to get initial guess / global prior
%In order to evaluate the ability of our model to encode unseen shape, we reconstruct new shapes from a separate test set. For this, we perform an auto-decoding with frozen model weights, and optimize for the latents and, if applicable, poses.
%Two options:
%1) assume we know the part decomposition, thus can supervise the parts and use correct poses. In practice, the part decomposition of a new shape might be unknown, but it gives an nice idea of what's the "upper bound" capability of our model to encode unknown shapes in the best scenario.
%2) If the decomposition is not known at test time, we can only optimize for the global SDF. We use a point encoder on a surface point cloud to get an initial estimation of part latents and poses. Then, we optimize all of them w.r.t. to the global SDF. \NT{PC encoder might be necessary as for more complex part decompositions, our model do not necessarily find the correct parts with only the global SDF.}

\input{fig/recon}

We evaluate the accuracy of shape and part reconstruction across all datasets and methods. To encode new test shapes at inference time, our model relies on auto-decoding: It remains frozen while reconstruction losses are minimized with respect to the latent vectors. We also report results for \PSDF{} with a single part, \ie, using our decoder in a part-agnostic manner, and refer to it as \DSDFp{}. We reconstruct meshes using Marching Cubes~\cite{Lorensen87, Lewiner03} at a resolution of $256$ for all methods. We report quantitative results in \cref{tab:recon}, with qualitative ones shown in \cref{fig:recon}. Across all metrics, our method achieves the best results on cars and chairs, and equivalent results on mixers to \DSDFp{}, which does not reconstruct individual parts. We note that \VecSet{} particularly struggles on this data, creating spurious floating surfaces and missing the central helices. Other part-based methods fall significantly behind on both surface and volume metrics.

One thing that handicaps part-aware baselines is their reliance on voxelized data despite being INR-based: For speed and memory, the data is binarized and voxelized at $64^3$, which delivers efficient and fast models but greatly limits accuracy. This is particularly visible in the case of the thin helix of the mixers or the equally thin chair parts: They tend to either disappear or be inflated. Instead, \PSDF{} is trained with samples directly obtained from the original shape $\mathcal{S}$ and yields superior accuracy, capturing detailed part-specific geometry and structure.
It is likely that approaches relying on more complex architectures~\cite{Deng22b,Hertz22,Li24c} would be more competitive in reconstruction accuracy. However, as discussed in~\cref{sec:related}, they are not designed to provide composite shape priors  usable for tasks such as part-based optimization.

To illustrate that part encoder models can be used in conjunction with \PSDF{}, we also reconstruct the test set in a part agnostic manner: We encode each shape's surface point cloud to obtain initial latents and poses, which are then refined with our auto-decoding strategy but \textit{without} $\mathcal{L}_\text{part}$. As encoder, we use \VecSet{} of reduced size, without the final cross-attention and, to produce an \textit{ordered} set of latents and poses, learnable queries at the shape encoding level.  As can be seen in the last row of \cref{tab:recon}, this allows us to accurately recover shapes and their parts, even though the thin structures of the mixers are more challenging.


%-------------------------------------------------------------------------
\subsection{Shape Generation}
\label{sec:exp-gen}

\input{table/gen}

\input{fig/gen}

We compare \PSDF{}'s shape generation abilities against those of \VecSet{} and \PQNET{}. The former relies on a diffusion model and the latter on a latentGAN~\cite{Achlioptas18b} to yield latent vectors from which shape or parts are decoded.
For \PSDF{}, we leverage \SALAD~\cite{Koo23}, a cascaded diffusion model that first generates part poses and then part latents conditioned on these poses. This also enables us to generate shapes fitting specified pose decompositions, something that \PQNET{} cannot do with its single latent space. We report MMD and COV metrics in \cref{tab:gen} and show generated examples in \cref{fig:gen}. \PSDF{} achieves consistently better results than \PQNET{}, with more detailed composite shapes. 
%
Our results are also  better than, or on-par with, those \VecSet{}, with the added bonus that our models are part-aware whereas those of  \VecSet{} are not, and therefore not usable for engineering design. Furthermore, it  requires training different models for shape reconstruction and generation, while we use only one for both.

\input{fig/manip}
% Here for earlier flushing
\input{fig/optim}

%-------------------------------------------------------------------------
\subsection{Part Manipulation}
\label{sec:exp-manip}

We evaluate our model’s ability to perform part-specific shape manipulation by editing part latent vectors and poses in \cref{fig:manip}. Both latents and poses can be edited conjointly in \PSDF{}, we do so separately here for visualization purposes.
When modifying part latents, the appearance of the corresponding parts is changed but the shape's structure and parts layout remain fixed. On the other hand, when changing poses, the parts layout adapts and their general appearance is unchanged. In all cases, the resulting composite shape preserves its overall consistency while fitting the editions.
%
These qualitative results emphasize the flexibility of our part-based representation, showing that our model can adapt individual parts independently while preserving overall shape integrity.

%-------------------------------------------------------------------------
\subsection{Part Optimization}
\label{sec:exp-optim}

To demonstrate the effectiveness of \PSDF{} as a part-aware shape prior for downstream tasks, we address a key engineering problem: Refining the shape of a car to reduce the drag induced by air flowing over its surface $\mathcal{S}$, \textit{without} editing the wheels. Drag can be computed as the surface integral of the air pressure
%
\begin{equation} \label{eq:p-drag}
	\text{drag}_p(\mathcal{S}) = \oiint\limits_\mathcal{S} -n_x(\mathbf{x}) \cdot p(\mathbf{x}) \ d\mathcal{S}(\mathbf{x}) \; ,
\end{equation}
%
where $p(\mathbf{x})$ is the pressure and $\mathbf{n}(\mathbf{x})$ the surface normal at point $\mathbf{x}$, with $n_x$ its component along the $x$ axis, which is directed along the car from front to back. This value is then normalized to get the drag coefficient $C_d$~\cite{Munson13}. For simplicity, we ignore the \textit{friction} drag that tends to be negligible for cars.
To compute a \textit{differentiable} estimate of the surface pressure $\hat{p}(\mathbf{x})$ and resulting drag, we use a GCNN surrogate model~\cite{Baque18}. More specifically, we use a GraphSage Convolution GNN~\cite{Hamilton17, Bonnet22} to predict $\hat{p}(\mathbf{x})$ on the mesh's surface, using simulation data obtained with OpenFOAM~\cite{OpenFoam}. 

Shape optimization can then be achieved by minimizing
%
\begin{align} \label{eq:optim}
	\mathcal{L}_\text{drag} &=  C_d\left(\mathcal{S}\right) + \mathcal{L}_\text{reg}\left( \bZ, \bP\right) \; , \\ 
	\mathcal{S} & = \text{MC}(f_\theta, \bZ, \bP) \; , \nonumber 
\end{align}
%
with respect to $\left(\bZ,\bP\right)$, where $\mathcal{L}_\text{reg}$ are optional regularization terms and $\text{MC}$ is the Marching Cubes algorithm~\cite{Lewiner03}. Importantly, gradients can be computed through the meshing step~\cite{Remelli20b}. 
%
In practice, we minimize $\mathcal{L}_\text{drag}$ over the \PSDF{} latents $\bZ$ and pose parameters $\bP$, starting from their values for an existing car. In the example of Fig.~\ref{fig:optim}, we optimize the shapes of several cars while keeping their wheels unchanged, which is something that our part-based approach allows and can not be done with a global representation such as the one of \DSDFp{} or \VecSet{}~\cite{Zhang23d}. \nt{While they may achieve lower final drag, the shapes don't respect design constraints, which is undesirable. For instance, in the second and last row of \cref{fig:optim}, results with \DSDFp{} tend to converge to an average car, ignoring the specificity of the initial cars and their wheels.} We provide more details and results in \cref{sec:supp-optim}.


%Our part-aware approach enables targeted optimization by modifying only specific parts, unlike the part-agnostic version, which alters the entire shape. While the latter may lead to lower final drag, this is undesirable in settings where only few components can be edited.
