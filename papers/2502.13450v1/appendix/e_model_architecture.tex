\section{Model Architecture: More Details}
\label{app:sec:model_arch}

Figure \ref{fig:disco_network} gives a high level overview of the proposed Dis-Co DiT architecture. Just like DiT, we feed in the discrete tokens and corresponding discrete time as input to the Dis-Co DiT block; however, we now also feed in the continuous vector inputs and corresponding continuous time. Also note that time is now the tuple $(t, k)$, where $t$ is the sequence time and $k$ is the element time. For discrete elements $k = 0$ always. Time is now embedded through an embedding layer similar to DiT; discrete tokens are also embedded through an embedding layer. Continuous vectors are projected using a linear layer into the same space as the discrete embeddings; these projected vectors are referred to as continuous embeddings. Discrete embeddings, continuous embeddings and their corresponding time embeddings are then passed into the Dis-Co DiT blocks. Following DiT, the outputs from the Dis-Co DiT blocks are then processed using adaptive layer normalization and a linear layer to obtain the discrete logits and continuous predictions.

Figure \ref{fig:disco_block} details the structure of a single Dis-Co DiT block. The discrete and continuous time embeddings are processed by an MLP and are used for adaptive layer normalization, adaLN-Zero, following DiT. The discrete and continuous embedding vectors, after appropriate adaptive layer normalization, are concatenated and passed to the Multi-Head Self Attention Block. The output from the Self Attention block is again split into discrete and continuous parts, and the process is then repeated with a Pointwise Feedforward network instead of Self Attention. This output is then added with the output from Self Attention (after scaling) to get the final output from the Dis-Co DiT block.


\paragraph{Generating Time Embeddings:}
Assume you are embedding the time tuple $(t, k)$ ($k = 0$ for discrete). Following DiT, we compute the vector $d$ whose $i^{th}$ element is given by:
$$ d[i] = k*f^{\frac{-i}{d_{in}-1}} $$
where $k$ is the element time, $f$ is the frequency parameter (set to $10000$ in all our experiments) and $d_{in}$ is the time embedding input dimension (set to $256$ in all our experiments). Similarly, we compute the vector $c$ whose $i^{th}$ element is given by:
$$ c[i] = t*(T_C f)^{\frac{-i}{d_{in}-1}} $$
where $t$ is the sequence time, $T_C$ is a frequency multiplier designed to account for the fact that multiple continuous noising steps happen for a single discrete flip. In our experiments, we set $T_C = K_{i_t}^t$. Once we have these vectors, we construct the following vector:
$$ y = [\sin(d)\; \cos(d)\; \sin(c)\; \cos(c)\; ] $$
i.e., we concatenate the vectors after applying $\sin$ and $\cos$ elementwise. This vector $y$ is then passed through 2 MLP layers to get the final time embedding.

\newpage
