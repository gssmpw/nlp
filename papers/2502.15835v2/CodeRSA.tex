% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage{acl}
\usepackage{amsmath}
% Standard package includes
\usepackage{times}
\usepackage{latexsym}

\usepackage{booktabs}    % For professional-looking tables
\usepackage{multirow}    % For multi-row cells
\usepackage{caption}     % For customizing captions
\usepackage{listings}    % For code formatting
\usepackage{xcolor}      % For color customization
\usepackage{tcolorbox}   % For colored boxes (optional, for annotations)
\usepackage{graphicx} 
\usepackage{subcaption} 
\usepackage{paralist}
\usepackage[T1]{fontenc}
\usepackage{float}
\usepackage{stmaryrd}

\usepackage{cuted}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}
% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

\usepackage{widetext}
\usepackage{flushend}
\usepackage{cuted}


\title{Pragmatic Reasoning improves LLM Code Generation} %Re-ranking LLMs' Code Generation Results Based on the Rational Speech Act (RSA) Framework **Tentative**}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\usepackage{authblk}
\author{
  \textbf{Zhuchen Cao}\textsuperscript{1},
  \textbf{Sven Apel}\textsuperscript{2},
  \textbf{Adish Singla}\textsuperscript{3},
  \textbf{Vera Demberg}\textsuperscript{1,2}\\
  \textsuperscript{1}Max Planck Institute for Informatics, Saarland Campus\\
  \textsuperscript{2}Computer Science, Saarland University\\
  \textsuperscript{3}Max Planck Institute for Software Systems, Saarland Campus\\
  \small{\textbf{Correspondence:} \texttt{zcao@mpi-inf.mpg.de, apel@cs.uni-saarland.de, adishs@mpi-sws.org, vera@coli.uni-saarland.de}}
}


%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
Large Language Models (LLMs) have demonstrated impressive potential in translating natural language (NL) instructions into program code. However, user instructions often contain inherent ambiguities, making it challenging for LLMs to generate code that accurately reflects the user’s true intent. To address this challenge, researchers have proposed to produce multiple candidates of the program code and then rerank them to identify the best solution. In this paper, we propose CodeRSA, a novel code candidate reranking mechanism built upon the Rational Speech Act (RSA) framework, designed to guide LLMs toward more comprehensive pragmatic reasoning about user intent. We evaluate CodeRSA using one of the latest LLMs on a popular code generation dataset. Our experiment results show that CodeRSA consistently outperforms common baselines, surpasses the state-of-the-art approach in most cases, and demonstrates robust overall performance. These findings underscore the effectiveness of integrating pragmatic reasoning into code candidate reranking, offering a promising direction for enhancing code generation quality in LLMs.
\end{abstract}


\section{Introduction}
Recent  advances in generative large language models (LLMs) have demonstrated their impressive ability to generate program code from user-provided natural language instructions \citep{liu2024your,coignion2024performance}. However, given the intrinsic complexities of coding and the potential ambiguities in user input, producing code in a single attempt may fail to explore the vast solution space,  overlooking correct or higher-quality solutions \citep{liu2024exploring}. A standard practice to address this shortcoming is to sample multiple solutions, which we refer to as ``code candidates'' \citep{chen2021evaluatinglargelanguagemodels, brown2024largelanguagemonkeysscaling}, and to rerank them. %Nevertheless, generating multiple candidates poses substantial challenges in evaluating their quality, underscoring the need for effective reranking strategies.
%
Researchers have proposed various reranking strategies for code candidates, broadly divided into \emph{execution-driven} and \emph{content-driven} approaches. 
Due to the safety-risks associated with execution-driven approaches \citep{yeticstiren2023evaluating}, we here focus on content-driven methods. These evaluate the generated text, often relying on token-level probabilities. For example, \emph{Coder reranking} scores each candidate based on the cumulative probability of its tokens, sometimes however favoring ``degenerate solutions'' (generic or repetitive code) with disproportionately high token probabilities \citep{zhang2022coderreviewerrerankingcode}.
\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{Image/CodeRSA10.png}
  \caption{A comparison of our approach CodeRSA (top) compared to the CoderReviewer method (bottom).}
  \label{fig:fig1}
\end{figure*}

When viewing code generation as a communicative process in which an LLM listens to the user’s intentions \citep{ouyang2022training}, Coder reranking evaluates candidate solutions solely from the listener’s perspective. Yet, research on human communication suggests that effective listeners reason about the speaker (who in turn reasons about the listener) \cite{grice1975logic}. Frank and Goodman (\citeyear{frank2012predicting}; \citeyear{goodman2016pragmatic}) provided a principled method for quantifying this process based on a probabilistic framework based on game-theoretic notions, called the Rational Speech Act (RSA) framework. %RSA posits that a pragmatic listener considers  the speaker’s motives for selecting an utterance and infers the underlying intentions. 
\citet{pu2020program,pmlr-v235-pu24c} demonstrated the RSA framework’s effectiveness on program generation for a simple domain, while \citet{schuster2024spreadnala} reported negative results on a spreadsheet domain. %; however, their experiments were conducted on a simplified model that only supports a narrow range of input and output scenarios. 
One aspect that has held back RSA models from scaling up to realistic use cases is the computational overhead \citep{pmlr-v235-pu24c}: it requires reasoning about the set of alternative instructions that the speaker could have given and about the set of alternative pieces of code that could solve the problem, which is very computationally expensive. \citet{zhang2022coderreviewerrerankingcode} therefore proposed \emph{CoderReviewer reranking} as a simplified scalable approach that simplifies these probability estimation processes over alternatives. However, it comes at the cost of not fully modelling the dialogic, interactive reasoning that can emerge when speaker and listener exchange information.
%, which adds a reviewer (speaker) role to the coder (listener) role. Their approach multiplies the probability of the candidate, given the instruction, by the probability of the instruction, given the candidate, mitigating the Coder's selection bias (see Fig.~\ref{fig:fig1}). However, while CoderReviewer measures bidirectional alignment between code candidates and instructions, it does not model the dialogic, interactive reasoning that can emerge when speaker and listener exchange information.


This work proposes CodeRSA, enabling LLMs to reason as pragmatic listeners and rank code candidates based on the user's underlying intentions. It addresses the probability estimates for the set of alternative code candidates and alternative utterances via a sampling approach. %At its core, CodeRSA employs  sampling to approximate the Bayesian probability model in the RSA framework, more rationally reranking code candidates.
CodeRSA generates multiple code candidates, and then generates additional instructions for each candidate, forming a set of potential instructions (including the original one), as illustrated in Fig.~\ref{fig:fig1}: the literal listener $L_0$ estimates the probability of each code candidate given each instruction from the potential instruction set. The pragmatic speaker $S_1$ then applies a special normalization on these probabilities to quantify how 
specifically an instruction fits the generated code. 
%well an instruction aligns with a candidate, called  the pragmatic speaker score. 
By comparing these pragmatic speaker scores for the original instruction across all candidates, the pragmatic listener identifies the code candidate that most closely matches the original instruction from the speaker’s perspective, finalizing the reranking process (see Fig.~\ref{fig:fig1}).

We conducted experiments using CodeRSA with Llama-3-8B-Instruct, one of the latest language models from the Llama family \citep{grattafiori2024llama3herdmodels} on Open\-AI's HumanEval benchmark \citep{chen2021evaluatinglargelanguagemodels}. Our experiment results reveal that CodeRSA reliably outperforms the Coder and CoderReviewer reranking methods. Our qualitative analysis illustrates how the CodeRSA reranking enables better candidate selection,
%shows that, although CodeRSA is based on several idealized assumptions, it still adheres to and benefits from the core principles of RSA, thereby optimizing reranking performance. 
%These findings suggest that introducing the RSA framework into large language models 
promoting a more comprehensive understanding of user intent. % and thereby improving the generation of program code from natural language instructions.

\section{Related Work}
\label{sec:background}
\textbf{Natural Language to Code.} 
Previous research has extensively explored generating code from natural language using neural network models \citep{ling2016latent,rabinovich2017abstract,hayati2018retrieval}. Recently, large language models (LLMs) have propelled significant advances in this area, driven by the transformer \cite{vaswani2017attention} architecture and large-scale pretraining. Their performance on code generation tasks often surpasses that of traditional models, and in many cases even rivals human programmers \citep{ni2024l2ceval,becker2023programming}. Moreover, a recent study shows that LLMs also exhibit strong performance in code summarization, effectively translating code snippets into text \citep{akib2024analysis}.\\

\noindent\textbf{Diversity Sampling in Code Generation.} In a prior study, \citet{chen2021evaluatinglargelanguagemodels} found  that allowing the model to generate more candidates significantly raises the probability of yielding a correct answer. This practice, which encourages the model to produce a broader range of potential outputs, is often referred to as diversity sampling.\\

\noindent\textbf{Code Reranking Methods.} When LLMs generate multiple code candidates in response to the user instruction, execution-driven reranking methods 
such as CodeT \citep{chen2022codetcodegenerationgenerated} and AgentCoder \citep{huang2024agentcodermultiagentbasedcodegeneration} involve running test cases to gauge each candidate’s correctness. Although often effective, execution-driven approach can introduce additional safety risks and practical obstacles, such as the potential for malicious code execution, environment setup overhead, and resource constraints \citep{yeticstiren2023evaluating,khoury2023secure}. In contrast, content-driven reranking methods are far more versatile because they do not rely on execution and are not even confined to coding tasks.\\

\noindent\textbf{Coder reranking.} In prior work, \citet{chen2021evaluatinglargelanguagemodels} reranked code candidates by estimating \(\text{P}(c \mid i) \), where \( c \) denotes the generated code candidate and \( i \) denotes the given instruction. This process can also be called Coder reranking because the LLM is a mere Coder that estimates the candidate probability based on the corresponding instruction.

When using an LLM to estimate conditional probabilities, we compute the probability of each token iteratively. For example, in Coder reranking, the model processes candidate's tokens from left to right: at each step, it calculates the probability of the current token given the instruction and the previously generated tokens, then appends that token to the context before moving on. The product of these sequential probabilities across all tokens yields the overall probability of the code candidate under the given instruction:

\[
\text{P}(c \mid i_0) \;=\; \prod_{t=1}^{|c|} \text{P}_{\text{LLM}}\bigl(c^{(t)} \mid i_0, c^{(<t)}\bigr),
\]
where $c^{(t)}$ denotes the token at position $t$ in the sequence $c$, and $c^{(<t)}$ represents the sequence of all tokens before position $t$.

\paragraph{CoderReviewer reranking.} \citet{zhang2022coderreviewerrerankingcode} added the concept of a reviewer to Coder reranking (i.e.,  reassessing whether the instruction matches the generated code candidate). Formally, CoderReviewer metric is represented as follows: 
\[
\begin{aligned}
\text{CoderReviewer} &=  \text{P}(c \mid i) \cdot \text{P}(i \mid c) \\
&\quad \text{ \footnotesize (Coder) \hspace{1.2em} (Reviewer)}
\end{aligned}
\]

The prompt positions of the instruction and code candidates are reversed in the reviewer's implementation. Thus, the code-generation task is reformulated as an instruction-generation task to calculate the probability of a given instruction. The CoderReviewer metric is also considered a specialized form of maximum mutual information \citep{li2016mutualinformationdiversedecoding}, measuring the bidirectional alignment between the generated code and the input instruction.

%When introducing the SpreadNaLa dataset, \citet{schuster2024spreadnala} also explored using an RSA-based reranking method, but its posted performance was lower than the baseline. This outcome suggests that the approach remains in a nascent, prototype stage and merits further investigation and refinement.

\section {CodeRSA}
\label{section:CodeRSA}
This section introduces CodeRSA, an approach that employs the Rational Speech Act (RSA) framework to enhance the reranking of candidate code snippets. CodeRSA extends the models proposed by \citet{cohn2019incremental} and \citet{schuster2024spreadnala}. The core innovation in CodeRSA arises from the pragmatic listener, which is responsible for selecting and reranking code candidates. It does so by imagining how a ``pragmatic speaker'' would choose an instruction that best distinguishes the intended code among various potential instructions.

A pragmatic speaker evaluates how effectively a potential instruction communicates the intended code candidate. Within the RSA framework, this evaluation process necessitates an explicit calculation of probabilities. However, given the infinite combinations of possible instructions and code candidates, developing a robust and comprehensive probability estimation strategy becomes essential. To address this challenge, CodeRSA generates additional instructions for each candidate, thereby constructing an expanded set of potential instructions (including the original). Finally, by considering the potential instruction set, a pragmatic speaker can select the most appropriate instruction for each code candidate based on the motivation to effectively convey the message to a literal listener.

At the foundation of CodeRSA is the literal listener, who estimates the probability of each code candidate by interpreting the user’s instruction word for word, without inferring deeper speaker intent.\\

\noindent\textbf{Literal Listener.} A literal listener (denoted \(L_0\)) represents the simplest level of reasoning in the RSA framework. It interprets utterances solely according to their literal meaning, without any higher-level pragmatic reasoning. Theoretically, let \( c \) be a candidate code and \( i \) be an instruction, then:
\[\text{P}_{L_0}(c \mid i)\propto \llbracket i \rrbracket(c),\]
where \(\text{P}_{L_0}(c \mid i)\) denotes the literal listener’s estimation of probability of candidate \(c\) given instruction \(i\). The interpretation function \( \llbracket i \rrbracket \) maps an instruction \( i \) to a function that takes a code candidate \( c \) and returns 1 if \( c \) correctly implements \( i \), and 0 otherwise.  

Likewise, most LLMs generate code by conditioning only on the user’s input instruction, which motivates CodeRSA’s use of an LLM to instantiate this literal listener:
\[
\text{P}_{L_0}(c \mid i) = \text{P}_{\text{LLM}}(c \mid i),
\]

The literal listener provides CodeRSA's baseline interpretation of user instructions, serving as the foundation for all subsequent reasoning. Note that the Coder reranking can also be considered a literal listener. For convenience, we refer to the logarithm of \(\text{P}_{L_0}(c \mid i)\) as the Coder score.\\

\noindent\textbf{Pragmatic Speaker.} In the RSA framework, the pragmatic speaker (denoted \(S_1\)) is primarily responsible for determining whether an instruction \(i\) effectively conveys the intended meaning of a candidate code \(c\) to the literal listener. Formally, a pragmatic speaker can be defined as:
\[\text{P}_{S_1}(i \mid c)=\frac{\exp \left(\log \text{P}_{L_0}(c \mid i)-C(i)\right)}{\sum_{i^{\prime}} \exp \left(\log \text{P}_{L_0}\left(c \mid i^{\prime}\right)-C\left(i^{\prime}\right)\right)},\]
Here, \( \operatorname{C}(i) \) denotes a cost function that quantifies the ``expense'' of employing a particular instruction. This formula quantifies the pragmatic speaker's estimation of the probability that a particular instruction will be used to describe a code candidate, as interpreted from the literal listener's perspective. Note that an idealized RSA approach would consider every possible instruction \(i^{\prime}\), which is infeasible in practice. Instead, CodeRSA leverages the fact that ambiguities in the original instruction often surface in the code candidates generated by LLMs, thereby enabling a sample-based estimation. 

Given a user-provided instruction \(i_0\), we request multiple candidate solutions \(\{c_1, \dots, c_n\}\) from the LLM. Each candidate \(c_j\) may capture a slightly different interpretation of \(i_0\). We then derive one or more instructions from each candidate \(c_j\), forming a set of potential instructions \(\{i_0, i_1, \ldots, i_m\}\), which we denote by \(I\). This approach ensures that we sample relevant alternative instructions directly tied to how the model interprets the original instruction. Potential instructions then constitute a finite sample set that approximates the otherwise infinite instruction space for pragmatic speaker estimation.

To simplify the model and focus on core pragmatic reasoning, we assume a uniform cost for all instructions, which effectively cancels out during normalization. However, a more detailed modeling of the cost function may provide additional insights, a point we further discuss in the Section~\ref{section:Discussion}. A pragmatic speaker then can be defined in a simplified form as:

\[
\text{P}_{S_1}(i \mid c) 
= \frac{\text{P}_{L_0}(c \mid i)}{\sum_{i'\in I} \text{P}_{L_0}(c \mid i')},
\]

In practice, the distribution of \(\text{P}_{L_0}(c \mid i)\) is often highly skewed, with a few high probability candidates dominating and a large spread in probability estimates. To address this, we here propose to instead work with log probabilities, which in practice brings low probability alternatives closer together and gives more weight to the relative trends among instruction–code pairs. The pragmatic speaker's preference score for a given instruction is hence quantified as: 

\[
\text{R}_{S_1}(i \mid c) 
= -\frac{\log \text{P}_{L_0}(c \mid i)}{\sum_{i'\in I} \log \text{P}_{L_0}(c \mid i')}\;,
\]
\[
\text{R}_{S_1}(i \mid c) \;\in\; (-1,\,0).
\]

In log space, after normalizing with respect to log probabilities, smallest numbers will now correspond to the events with the highest probability. Therefore, we invert the sign to negative in order to still choose maximal score instructions. 
%The negative sign ensures that higher pragmatic speaker scores correspond to a better match between the instruction and candidate, which is more intuitive. Meanwhile, \(\sum_{i'\in I} \log \text{P}_{L_0}(c \mid i')\) acts as a normalizing factor across all possible instructions. 
Notably, if \(c\) is overly generic or appears plausible under multiple instructions, then the denominator \(\sum_{i'\in I} \log \text{P}_{L_0}(c \mid i')\) increases, resulting in a lower overall score. This log-based metric prevents inflated scores for candidates that might superficially fit many different instructions, thereby ensuring that each instruction is evaluated on a relatively fair basis. An ablation study (Appendix~\ref{Appendix:Ablation Study}) confirmed that omitting the logarithmic transformation significantly degrades normalization and impairs CodeRSA's reranking capability, with Appendix~\ref{Appendix:Geometric} offering geometric mean–based theoretical support.

Overall, at the pragmatic speaker level, CodeRSA leverages the code candidates themselves to sample potential instructions, capturing the diversity of possible interpretations. It then uses the literal listener’s estimation to quantify how effectively each potential instruction reflects the meaning of a code candidate.\\

\noindent\textbf{Pragmatic Listener.} The pragmatic listener (denoted \(L_1\)) re-examines the original instruction \(i_0\) across all candidates, completing the backward reasoning guided by the pragmatic speaker’s preferences. In prior work, \citet{degen2023rational} defined a pragmatic listener as:
\[\text{P}_{L_1}(c \mid i) \propto \text{P}_{S_1}(i \mid c) \cdot \text{P}(c),\]
Here, \(\text{P}(c)\) denotes the prior probability of a given code candidate. We make the simplifying assumption that all candidates are equally likely a priori, which allows us to treat \(\text{P}(c)\) as a constant and omit it from the calculations. Note that this uniform prior assumption may not hold in real-world scenarios, as some code might be inherently more common than others. We will discuss this assumption further in Section~\ref{section:Discussion}. Consequently, in CodeRSA, the pragmatic listener reranks candidates by their pragmatic speaker scores:
\[
\text{P}_{L_1}(c \mid i) \propto \text{R}_{S_1}(i \mid c),
\]
so that the candidate with the highest pragmatic speaker score for \(i_0\) is selected as optimal.

From CodeRSA's reasoning process, it follows that, for each candidate, the LLM is invoked \(m+1\) times, where \(m\) represents the number of generated instructions. Consequently, the overall computational complexity of CodeRSA is \(\mathcal{O}\bigl(n(m+1)\bigr)\), which grows quadratically when both \(n\) and \(m\) increase equally. %To balance running time and limited computing resources, we therefore restrict the reranking procedure to 10 candidates per question and generate one additional instruction per candidate in our experiments.


\section {Experiment Setup}
\label{sec:experiment}
To analyze the merits of CodeRSA, we evaluate the performance of the three reranking methods (Coder, CoderReviewer, and CodeRSA) on a standard program code generation dataset using one of the latest language models. Since the strength of content-driven methods is their generality, we skipped extensive parameter tuning and simply used the default or commonly used parameters throughout our experiments.


\subsection{Dataset and Model}
The manually crafted HumanEval evaluation dataset \citep{chen2021evaluatinglargelanguagemodels} was designed to assess a model’s ability to convert natural language instructions into program code. It comprises 164 questions, each framed as an unfinished Python function starting with a brief instruction that describes how the  function's code should be completed.

We selected HumanEval for its proven role in code generation evaluation and balanced difficulty. For example, simpler datasets like CoNaLa \citep{yin2018mining} already yield near-perfect performance for the Coder model, leaving little room for reranking improvements. In contrast, more challenging datasets such as Bigcodebench \citep{zhuo2024bigcodebench} often produce many unsolvable instances, suggesting that more powerful models or improved problem modeling is needed.

Despite the availability of HumanEval for code generation, no dedicated and reliable benchmark currently exists for reranking generated code—a specialized subtask within code generation. Accordingly, the benchmark setup in our experiments involves three key stages: program code generation, testing (only for evaluation purposes), and reranking. Because LLM-based code generation is highly sensitive to hyperparameters and hardware configurations, we adopt a multi-sampling strategy. Specifically, for each of the 164 HumanEval problems, we first generate 300 candidate solutions at a temperature of 0.7. Then, we randomly select 50 problems, sample 10 candidates per problem, and repeat this process 10 times. Finally, we evaluate three different reranking methods on each resulting subset to measure their effectiveness.

In our experiments, we focus on the Llama-3-8B-Instruct variant, which comprises 8 billion parameters and is fine-tuned for instruction-following tasks \cite{grattafiori2024llama3herdmodels}. Llama-3-8B-Instruct is renowned for its lightweight design and robust performance, effectively balancing computational requirements with high-quality generation. Moreover, the HumanEval dataset poses a moderate challenge to the model, ensuring that it is neither overwhelmed by difficulty nor under-challenged. These characteristics render the model particularly suitable for evaluating the effectiveness of reranking methods in practical scenarios.

Additionally, we evaluated Llama-2-70b-chat \cite{touvron2023llama} on a subset of HumanEval; however, its limited performance in code and instruction generation (and related poor probability estimates) led to its exclusion.

\subsection{Implementation of Reranking Methods}
\noindent\textbf{Baselines.}
The Coder reranking method provides a straightforward way to compare the probability of a code candidate \(c\) given the original instruction \(i\). Specifically, it concatenates the instruction and code candidate in order (see Fig.~\ref{fig:fig3}, part A), prompting the language model to output token probabilities for the candidate sequentially. The product of these token probabilities then yields the cumulative probability of the entire code snippet. As mentioned in Section~\ref{section:CodeRSA}, Coder reranking can also be considered a literal listener-level approximation to \( \text{P}(c \mid i) \); therefore, we use it  as a baseline. 

Another baseline, ``random'', is defined as the ratio of correct candidates to total candidates in each subset. By using the expected proportion of correct codes, this approach minimizes the impact of random seeds and naturally reflects the inherent difficulty of each sub-dataset.

\noindent\textbf{State-of-the-art Method.}
%Even without executing the generated code, 
\citet{zhang2022coderreviewerrerankingcode} showed that CoderReviewer reranking (see Section \ref{sec:background} for details) outperforms Coder reranking and rivals execution-driven methods such as CodeT. %Given a code candidate \(c\) and its original instruction \(i\), the CoderReviewer approach reranks candidates by multiplying the probabilities \(\text{P}(c \mid i)\) and \(\text{P}(i \mid c)\). This reflects both how well \(c\) adheres to the instruction and how well the instruction follows from \(c\). 
%
\begin{figure}[t]
    \centering
    \includegraphics[scale = 0.26]{Image/Code-LORI.png}
    \caption{The prompts used to calculate Coder score and generate additional instructions.}
    \label{fig:fig3}
\end{figure}

In practice, we use the same prompt format as in Coder reranking to compute \(\text{P}(c \mid i)\). To compute \(\text{P}(i \mid c)\), the order of the instruction and the generated code snippet is reversed in the prompt (see Appendix~\ref{app:reviewer-prompt}).

\noindent\textbf{CodeRSA.} 
To balance running time and limited computing resources, we restrict the RSA reranking procedure in our experiments to 10 candidates per question. We then apply a one-shot prompt (see Fig.~\ref{fig:fig3}, part B) to the LLM to generate one instruction for each candidate, yielding a set of potential instructions \(\{i_0, i_1, \ldots, i_{10}\}\), where \(i_0\) is the original instruction. Consistent with Coder reranking's input prompt, we then compute the probability of each code candidate \(c'\) under each potential instruction \(i'\), forming an \(11 \times 10\) Coder score matrix. Then, we derive pragmatic speaker scores for each candidate with respect to the original instruction by contrasting how the candidate performs under \(i_0\) versus under the other generated instructions. Finally, we use these pragmatic scores to rerank the candidates, selecting the one with the highest pragmatic speaker score for \(i_0\).
\section{Results}
\subsection{Quantitative Analysis}

In this section, we quantitatively evaluate three reranking methods, including CodeRSA, in terms of accuracy using ten subsets sampled from the HumanEval dataset and their corresponding generated code candidates.
\begin{figure}[ht]
    \centering
    \includegraphics[scale = 0.38]{Image/box4.png}
    \caption{Box plot of accuracy for the reranking methods. The orange line indicates the mean accuracy.}
    \label{fig:fig4}
\end{figure}

\noindent Here, accuracy is defined as the fraction of candidates selected by a reranking method that pass all test cases relative to the total number of candidates in the subset. Fig.~\ref{fig:fig4} presents box plots comparing the accuracy distributions of the three reranking methods and a random baseline. Variance is estimated from bootstrapping across ten subsets. %The orange line within each box represents the mean accuracy, while the top and bottom edges of the box mark the 75th and 25th percentiles, respectively. 
CodeRSA attains the highest mean accuracy, with relatively narrow interquartile ranges indicating consistent performance. CoderReviewer shows moderate accuracy, with a mean exceeding Coder’s but still below CodeRSA. Coder reranking exhibits a relatively large variance, indicating that its performance is less stable and more prone to fluctuations, likely due to its tendency to favor overly generic solutions. %Meanwhile, the random approach had the worst overall results, the lowest mean, and a narrower box, confirming that non-trivial modeling of code probability is beneficial in reranking.

\begin{figure*}[!t]
    \centering
    % Large image on top with subcaption
    \begin{minipage}{1\textwidth}
        \centering        \includegraphics[width=\textwidth,height=0.4\textwidth]{Image/casestudy8.png}
        \subcaption{Details of question and two generated examples} % Add subcaption for the big image
        \label{example:a}
    \end{minipage}
    \vspace{0.2cm} % Add vertical spacing

    % Small images in the bottom
    \begin{minipage}{0.43\textwidth}
        \centering
        \includegraphics[scale = 0.36]{Image/before_norm3.png}
        \subcaption{Coder Score Comparison}
        \label{example:b}
    \end{minipage}
    \hspace{0.2cm}
    \begin{minipage}{0.43\textwidth}
        \centering
        \includegraphics[scale = 0.36]{Image/after_norm_3.png}
        \subcaption{Pragmatic Score Comparison}
        \label{example:c}
    \end{minipage}

    % Add main caption at the bottom
    \caption{Two code candidates along with relevant information}
    \label{fig:example}
\end{figure*}

Coder's lower performance suggests that relying solely on a literal listener perspective is insufficient for effective reranking and that
%. Incorporating modeling of the speaker improves reranking performance. Although CoderReviewer and CodeRSA share the same underlying motivation of reasoning about the speaker on top of the listener perspective, CoderReviewer merely combines Reviewer and Coder scores, whereas 
CodeRSA's more complex reasoning leads to superior performance, demonstrating the benefits of a comprehensive RSA modeling approach.






\subsection{Qualitative Analysis}
Although our experiments show that CodeRSA achieves stable performance, it relies on certain idealized assumptions and an abstract reasoning process. To provide a more intuitive perspective, we include a qualitative analysis that examines how CodeRSA aligns with core RSA intuitions, thereby enhancing reranking quality.

\citet{zhang2022coderreviewerrerankingcode} observed that language models often generate “degenerate” programs—overly generic yet repetitive code candidates. In our analysis, we observe that Coder reranking indeed favors these degenerate outputs because it evaluates the cumulative token likelihood of a candidate \(c\), given the original instruction \(i_0\): 

\[
\text{P}(c \mid i_0) \;=\; \prod_{t=1}^{|c|} \text{P}_{\text{LLM}}\bigl(c^{(t)} \mid i_0, c^{(<t)}\bigr),
\]
where \(c^{(t)}\) denotes  the token at position \(t\), and \(c^{(<t)}\) represents the sequence of the preceding tokens. Each factor \(\text{P}_\text{LLM}(c^{(t)} \mid i_0, c^{(<t)})\) is strictly less than 1; thus, longer sequences accumulate a lower overall probability, biasing Coder reranking towards shorter, potentially degenerate code. Nonetheless, differences in token-level probabilities can offset this bias: a longer but logically correct candidate may achieve a higher overall probability if each token is assigned a sufficiently high probability.


With recent advances in LLMs, generating degenerate programs has become less common, although incomplete functionality remains a concern. For example, in Fig.~\ref{example:a}, the original instruction requires returning the greatest integer above zero whose frequency is, at least, its own value, or \(-1\) if none exists. Nevertheless, \(\texttt{code\_09}\) omits the “greatest” integer requirement and the \(-1\) fallback, making it shorter and  more likely to be highly ranked by Coder.

Fig.~\ref{example:b} presents  the Coder scores \(\log \text{P}_{L_0}(c \mid i)\) for \(\texttt{function\_01}\) and \(\texttt{function\_09}\) under all potential instructions (including \(i_0\)). Additionally, \(\texttt{code\_01}\) achieves a log-probability of \(-29.24\) for \(i_0\), whereas \(\texttt{code\_09}\) reaches \(-21.12\). Consequently, Coder reranking selects the incomplete \(\texttt{code\_09}\). The Reviewer component alone is insufficient to offset \(\texttt{code\_09}\)'s higher Coder score; hence CoderReviewer also prefers \(\texttt{code\_09}\). The difference between Coder and Reviewer scores highlights a major flaw in the CoderReviewer method. Since these scores often differ significantly, treating them as equally important is not optimal. Additionally, trying to adjust their weights can add more complexity and uncertainty.

Fig.~\ref{example:c} reports the pragmatic speaker scores \(\text{R}_{S_1}(i \mid c)\) for each instruction–code pair. Notably, \(\texttt{code\_01}\) receives a score of \(-0.0458\) with \(i_0\), whereas  \(\texttt{code\_09}\) has \(-0.0533\). Acting as a pragmatic listener, CodeRSA selects \(\texttt{code\_01}\), which more closely aligns with \(i_0\) from a pragmatic speaker's perspective.

Although the score calculation in our method uses log probabilities, two observations confirm that our method still achieves the core intuitions put forward by the RSA framework:

Firstly, as can be seen in Fig.~\ref{example:b}, \(\texttt{code\_01}\) has a lower overall Coder score than \(\texttt{code\_09}\), likely because it is longer and more complicated. However, under \(i_0\), \(\texttt{code\_01}\) obtains a higher Coder score relative to other possible instructions, which then translates into a higher pragmatic speaker score after normalization. This process shows that CodeRSA examines each candidate's relative scores across all potential instructions to verify whether it truly ranks highly under the original instruction.

Secondly, as shown in Fig.~\ref{example:b}, \texttt{code\_09} receives multiple high Coder scores, especially under the instruction generated by itself. From the literal listener’s perspective, the self-generated instruction more precisely describes \texttt{code\_09}, raising its overall Coder scores. Crucially, because the speaker’s score is normalized by the sum of log probabilities across all instructions for a given candidate, a higher Coder score on the self-generated instruction will reduce the relative weight assigned to the original instruction. Consequently, the pragmatic speaker will prefer to use another instruction for \texttt{code\_09} instead of the user's original instruction. Moreover, as can be seen in Fig.~\ref{example:a}, the self-generated instruction for \texttt{code\_09} matches its details more closely.

%\end{compactenum}

\section{Discussion}
\label{section:Discussion}
Our proposed CodeRSA approach contains a number of simplifications compared to the original RSA model, which has been developed for describing human-human communication: (1) we assumed a uniform speaker cost for the instructions. While this simplification makes the analysis more tractable, it means that our model does not currently take into account effects related to how ``costly'' an instruction would be to produce for the human speaker. Future work should investigate variable cost structures to better capture these nuances. 
  
We also assume that all code candidates are equally likely a priori, effectively omitting the candidate prior \(\text{P}(c)\) from our calculations. Although this assumption allows us to concentrate solely on the pragmatic speaker's score, it might not reflect real-world scenarios where some code candidates are more common due to usage frequency, domain-specific patterns, or contextual relevance. Future work should explore the use of non-uniform priors to better capture candidate plausibility. %For example, candidate frequencies derived from available data could be used to inform these priors.

In section \ref{sec:experiment}, we argued that our approach, as a reranking approach, is most beneficial in situations where 
%the competence of the model and the difficulty of the dataset ``fit together'' such that 
the dataset is not too easy (when a simple Coder model already achieves ceiling performance) and not too difficult, such that we can still obtain a high quality probability distribution over instructions and over code candidates. This raises the question of the relevance of pragmatic reasoning for code generation, and more generally in communication. Research on human communication has demonstrated the importance of pragmatic reasoning in communication despite its apparent computational overhead, while at the same time suggesting that humans may also learn to use simple heuristics or amortized estimates \citep{pmlr-v235-pu24c} to not engage in iterative reasoning in easy cases, while still being able to employ the full reasoning procedure in more difficult cases where it is necessary. 

\section{Conclusion}
This work introduces CodeRSA, a candidate reranking algorithm for the generation of program code grounded in the Rational Speech Act framework. By modeling the iterative reasoning of a pragmatic listener about a pragmatic speaker, CodeRSA consistently outperforms the Coder reranking baseline and surpasses the state-of-the-art CoderReviewer approach. A qualitative analysis further reveals that, even when incorporating certain idealized assumptions and variations, CodeRSA remains faithful to the core principles of the RSA framework. These results highlight the effectiveness of applying well-established linguistic frameworks to enhance reasoning in language models, opening new avenues for research and development in code-related tasks.

\section{Limitations}
\label{section:Limitations}


A known limitation of RSA approaches is their computational complexity and associated resource consumption. For example, on a single NVIDIA Tesla A100 (PCIe 4.0, 80GB HBM2e, 300W), performing complete CodeRSA inference on 500 instances takes nearly 8 hours. Our approach compares each potential instruction with every candidate, leading to a quadratic increase in complexity as the number of candidates grows. Although CodeRSA can theoretically handle many candidates, we limited our experiments to ten candidates per question to keep runtime and hardware usage manageable. This restriction inevitably narrows the variety of solutions and may affect how well the approach generalizes to larger-scale scenarios.

Reducing the computational overhead is a major goal for our future work. One promising direction is to design more lightweight scoring mechanisms or to adopt a multi-stage pipeline. For instance, a coarse filtering step could quickly discard low-probability solutions before applying CodeRSA’s full RSA-based reasoning to a smaller top-ranked subset. Alternatively, approximate models could reduce the number of token-level evaluations required, thereby preserving much of CodeRSA’s pragmatic reasoning benefits at a fraction of the computational cost. Such improvements would allow CodeRSA to scale more effectively and broaden its applicability to larger code generation tasks.

Another limitation is that while we employed a multi-sampling strategy to mitigate uncertainty, we have only utilized a single dataset and one model so far. We are currently working on incorporating several balanced-difficulty datasets—such as MBPP \citep{austin2021program} and DS-1000 \citep{pmlr-v202-lai23b}—along with additional open-source models like Mistral \citep{jiang2023mistral} and Qwen \citep{bai2023qwen}. This expansion will allow us to further assess the effectiveness of different reranking methods across diverse scenarios, ultimately leading to a more robust evaluation of our approach.



% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\appendix

\section{Appendix}
\subsection{A Conjecture: Explaining CoderReviewer from an RSA Perspective}

In the RSA framework, a pragmatic listener's posterior over a candidate \(c\) given an instruction \(i\) is commonly expressed as:
\[
\text{P}_{L_1}(c \mid i) \propto \text{P}_{S_1}(i \mid c) \cdot \text{P}(c),
\]
where \(\text{P}_{S_1}(i \mid c)\) represents how likely a pragmatic speaker would be to produce instruction \(i\) when the correct candidate is \(c\), and \(\text{P}(c)\) is the prior likelihood of \(c\). 

Translating this perspective to LLMs, we hypothesize that when generating instructions (the “Reviewer” role), it is relatively straightforward for the model to produce abstract instructions from concrete code. Since code is unambiguous, the LLM can approximate a pragmatic speaker:
\[
\text{P}_{\text{LLM}}(i \mid c) \approx \text{P}_{S_1}(i \mid c).
\]
However, generating code from abstract instructions (the “Coder” role) is substantially more difficult. In this setting, the LLM may effectively revert to estimating a prior over possible candidates, thereby approximating:
\[
\text{P}_{\text{LLM}}(c \mid i) \approx \text{P}(c).
\]

From this RSA standpoint, the CoderReviewer paradigm can be considered a simplified, yet broad, modeling of a pragmatic listener.

\subsection{More Details of Results}
 Table~\ref{tab:results} summarizes the average accuracy and standard deviation across ten sampled subsets.

\begin{table}[ht]
\centering
\caption{Mean accuracy (with standard deviation) across 10 subsamples for each reranking method.}
\label{tab:results}
\begin{tabular}{lcc}
\toprule
Method & Mean Accuracy & Std. Dev.\\
\midrule
Coder     & 0.48 & 0.059 \\
CoderReviewer & 0.51 & 0.043 \\
CodeRSA        & 0.55 & 0.044 \\
random         & 0.43 & 0.030 \\
\bottomrule
\end{tabular}
\end{table}

As shown in Table~\ref{tab:results}, CodeRSA achieves the highest average accuracy (0.55), outperforming Coder (0.48), CoderReviewer (0.51), and the random baseline (0.43). This indicates that CodeRSA provides stronger overall performance compared to the other methods. From a standard-deviation perspective, CoderReviewer and CodeRSA both exhibit relatively stable performance across different subsamples. By contrast, Coder has the highest standard deviation (0.059), suggesting greater sensitivity to varying combinations of coding problems.


\begin{figure}[ht]
    \centering
    \includegraphics[scale = 0.55]{Image/compare3.png}
    \caption{Performance difference between CodeRSA and CoderReviewer.}
    \label{fig:fig6}
\end{figure}

Fig.~\ref{fig:fig6} depicts the per-trial accuracy difference between CodeRSA and CoderReviewer (i.e., CodeRSA accuracy minus CoderReviewer accuracy). Bars above zero indicate that CodeRSA outperforms CoderReviewer, while the single negative bar (Trial 2) represents the only instance where CodeRSA yields a lower accuracy. In most trials, CodeRSA demonstrates gains of up to 10\%, highlighting its consistent advantage.

\subsection{Ablation Study}
\label{Appendix:Ablation Study}
\begin{figure}[ht]
    \centering
    \includegraphics[scale = 0.38]{Image/eb2.png}
    \caption{Box plot of accuracy in ablation study.}
    \label{fig:fig7}
\end{figure}
To investigate the impact of the log transformation in the calculation of the pragmatic speaker score, we conducted an ablation study comparing the CodeRSA's modeling of pragmatic speaker score: 
\[
\text{R}_{S_1}(i \mid c) 
= -\frac{\log \text{P}_{L_0}(c \mid i)}{\sum_{i'\in I} \log \text{P}_{L_0}(c \mid i')}\;,
\]
\[
\text{R}_{S_1}(i \mid c) \;\in\; (-1,\,0).
\]
against a variant that directly utilizes the normalized probability:
\[
\text{P}_{S_1}(i \mid c) 
= \frac{\text{P}_{L_0}(c \mid i)}{\sum_{i'\in I} \text{P}_{L_0}(c \mid i')},
\]
referred to as CodeRSA\_nolog.

Fig.~\ref{fig:fig7} displays the box plots of accuracy for different methods on ten subsets. From the results, CodeRSA achieves the highest mean accuracy with a narrow interquartile range, indicating stable performance. In contrast, CodeRSA\_nolog shows a marked decrease in accuracy, evidenced by a lowest mean and a compressed interquartile range.  This observation aligns with previous findings by \citet{schuster2024spreadnala}, which reported that the basic RSA model underperforms the baseline on their SpreadNaLa dataset. These results suggest that applying a logarithmic transformation to expand the probability intervals can substantially enhance overall performance.

\subsection{A Geometric Mean Perspective on the Log-Normalization Formula}
\label{Appendix:Geometric}
In our proposed CodeRSA model, we define the pragmatic speaker score as follows:
\[
\text{R}_{S_1}(i \mid c) 
= -\frac{\log \text{P}_{L_0}(c \mid i)}{\sum_{i'\in I} \log \text{P}_{L_0}(c \mid i')}\;,
\]
\[
\text{R}_{S_1}(i \mid c) \;\in\; (-1,\,0).
\]
where \(\text{P}_{L_0}(c \mid i)\) is the probability estimated by the literal listener for candidate code \(c\) given instruction \(i\), and \(I\) denotes the set of potential instructions.
The geometric mean of the set \(\{\text{P}_{L_0}(c \mid i'): i' \in I\}\) is defined as:
\[
\text{GM} = \left( \prod_{i' \in I} \text{P}_{L_0}(c \mid i') \right)^{\frac{1}{|I|}},
\]
and its logarithm is given by:
\[
\log \text{GM} = \frac{1}{|I|} \sum_{i' \in I} \log \text{P}_{L_0}(c \mid i').
\]
Thus:
\[
\text{R}_{S_1}(i \mid c) = -\frac{\log \text{P}_{L_0}(c \mid i)}{|I| \cdot \log \text{GM}} \;.
\]
In this sense, normalizing the log probability for a particular instruction \(i\) by the sum over all potential instructions can be seen as a way of capturing its relative contribution in a manner analogous to the geometric mean.


\onecolumn

\subsection{Prompt Used}
\subsubsection{For Generating the Additional Instruction:}

\begin{lstlisting}[basicstyle=\sffamily, frame=single, framesep=5pt, rulecolor=\color{black}, breaklines=true, breakatwhitespace=true, breakindent=0pt, columns=fullflexible]
##Write an instruction for given python function## 
### Function start ###
def any_int(x, y, z):
    if isinstance(x,int) and isinstance(y,int) and isinstance(z,int): 
        if (x+y==z) or (x+z==y) or (y+z==x): 
            return True 
        return False 
    return False 
### Function end ###

### instruction start ###
Create a function that takes 3 numbers. Returns true if one of the numbers is equal to the sum of the other two, and all numbers are integers. Returns false in any other cases.
### instruction end ###

### Function start ###
any function
### Function end ###

###instruction start###

\end{lstlisting}

\subsubsection{For Calculating the Reviewer Score (An Example):}
\label{app:reviewer-prompt}

\begin{lstlisting}[basicstyle=\sffamily, frame=single, framesep=5pt, rulecolor=\color{black}, breaklines=true, breakatwhitespace=true, breakindent=0pt, columns=fullflexible]

def any_int(x, y, z):
    if isinstance(x,int) and isinstance(y,int) and isinstance(z,int): 
        if (x+y==z) or (x+z==y) or (y+z==x): 
            return True 
        return False 
    return False 

# Write a docstring for the above function
Create a function that takes 3 numbers. Returns true if one of the numbers is equal to the sum of the other two, and all numbers are integers. Returns false in any other cases.



\end{lstlisting}

\onecolumn


\end{document}
