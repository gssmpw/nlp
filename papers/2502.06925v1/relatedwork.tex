\section{Related work}
\label{related works}
The idea behind transferability estimation is simple: to estimate which model from a zoo would perform best after fine-tuning the model. Transferability estimation as a field is fairly new, the H-Score~\cite{Hscore} and NCE~\cite{NCE} can be considered as early works on this topic, introducing the evaluation of transferability, and the assignment of models corresponding to an estimate of their transferability, for a given target task. 

There are two widely accepted problem scenarios for transferability estimation: source-dependent transferability estimation (where one has access to the source and target dataset) and source-independent transferability estimation (where one does not have access to the source dataset). 
\subsection{Source Dependent Transferability Estimation (SDTE)}
The SDTE scenario assumes access to the source data sets where the models have been pre-trained.
Apart from the fact that this assumption is often not met, a drawback of common SDTE metrics, they use distribution matching methods like optimal transport~\cite{otce}, which are typically very expensive to compute. In addition, SDTE metrics are usually not reliable when the discrepancy between the source and target dataset is very high, for example, when comparing entire the ImageNet21K~\cite{imagenet} to Cars~\cite{cars} or Plants~\cite{plantvillage} dataset.


\subsection{Source Independent Transferability Estimation(SITE)}
The Source Independent Transferability Estimation (SITE) assumes access to the source model but not the source training data. This is a more realistic transferability estimation as we might not always have access to the source dataset, nor have the capacity to store the typically very large source datasets like ImageNet~\cite{imagenet} or LAION~\cite{schuhmann2022laionb} in our local setup. SITE methods typically rely on evaluating the feature representation of the source model on the target dataset and its relationship with target labels. 

%The last few years are suggested in this category that look at the problem from different perspectives. 
There are several transferability metrics inspired by various viewpoints. LogME~\cite{logme} formalizes the transferability
estimation as the maximum label marginalized likelihood
and adopts a directed graphical model to solve it. SFDA~\cite{SFDA} proposes a self-challenging mechanism, it first maps the features and then calculates the sum of log-likelihood as the metric.  ETran~\cite{ETran} and PED~\cite{PED} treat the problem of SITE with an energy function, ETran uses energy-based models to detect whether a target dataset is in-distribution or out of distribution for a given pre-trained model whereas PED utilizes potential energy function to modify feature representations to aid other transferability metrics like LogMe and SFDA. NCTI~\cite{NCTI} treats it as a nearest centroid classifier problem and measures how close the geometry of the target features is to their hypothetical state in the
terminal stage of the fine-tuned model. LEEP~\cite{leep} is the average log-likelihood of the log-expected empirical predictor, which is a non-parameter classifier based on the joint distribution of the source and target distribution, N-LEEP~\cite{NLEEP} is a further improvement on LEEP by substituting the output layer with a Gaussian
mixture model. TransRate~\cite{TransRate} treats SITE from an information theory point of view by measuring the transferability as the mutual information between features of target examples extracted by a pre-trained model and their labels. We suggest the survey by \citet{ding2024modeltransfersurveytransferability} for a complete view of transferability metrics. 

Of these existing methods, the approach of NCTI is closest to ours. NCTI checks to which extent the neural collapse criteria~\cite{neuralcollapse} are satisfied on the target embedding. %In particular, NCTI evaluates the proximity of embedded data points within one class: the closer the embedded data points are to their class mean, the higher the estimated transferability. 
We argue (in Section \ref{sec:clustering}) that neural collapse is a byproduct of properties of the loss function, that incentivize in later training stages the embedded points of one class to collapse to their mean. However, if we want to assess the transferability, checking for effects taking place late in training might not be a failproof approach.