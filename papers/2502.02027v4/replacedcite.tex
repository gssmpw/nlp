\section{Related Work}
\label{sec:related_work}
Advancements in navigation and detection under low-visibility conditions have leveraged sensor fusion, visual cue integration, and computational techniques. Aircraft landing studies have explored sensor fusion of visible and virtual imagery ____ and visual-inertial navigation using runway features ____. Multi-sensor fusion algorithms have improved odometry in GPS-denied environments ____, while research on depth visualization has enhanced navigation and obstacle avoidance ____. Synthetic Vision Systems and full-windshield Head-Up Displays aid drivers and pilots in low visibility ____. Image enhancement techniques for low-light conditions ____ and the fusion of visual cues with wireless communication improve road safety ____. Studies have also emphasized the role of geometrical shapes and colors in driving perception via Head-Up Displays ____.

Despite these advances, challenges persist, including computational complexity ____, performance issues under extreme conditions ____, overfitting due to limited datasets ____, and insufficient real-world validation ____. Some works lack rigorous validation ____.

In visual recognition, research has explored human-like processing in computational models. Studies on brain mechanisms highlight hierarchical, feedforward object recognition ____, while comparisons with deep neural networks (DNNs) reveal human superiority in handling distortions and attention mechanisms ____. Eye-tracking data has been used to guide DNN attention with limited success ____. Approaches such as adversarial learning for feature discrimination ____, biologically inspired top-down and bottom-up models ____, and retina-mimicking models for dehazing ____ have been proposed. Foveal-peripheral dynamics have also been explored to balance computational efficiency and high-resolution perception ____.

Recent research has tackled low-visibility challenges like fog, low light, and sandstorms. The YOLOv5s FMG algorithm improves small-target detection with enhanced modules ____, while novel MLP-based networks refine image clarity in hazy and sandstorm conditions ____. The PKAL approach integrates adversarial learning and feature priors for robust recognition ____. Deformable convolutions and attention mechanisms enhance pedestrian and vehicle detection in poor visibility ____. Reviews highlight the limitations of non-learning and meta-heuristic dehazing methods in real-time applications ____, emphasizing the need for integrated low-level and high-level vision techniques ____. Innovations such as spatiotemporal attention for video sequences ____, the PDE framework for simultaneous detection and enhancement ____, spatial priors for saliency detection ____, and early visual cues for object boundary detection ____ further contribute to the field.

Despite advances, existing methods struggle with joint optimization of object detection and image enhancement, detection of low-contrast objects, and adaptation to dynamic visibility changes. This paper addresses these challenges by integrating human visual cues, such as attention mechanisms and contextual understanding, into object detection, enhancing both robustness and efficiency. Traditional approaches process entire images uniformly, increasing computational load, and sometimes degrading clear regions. Our method selectively enhances regions of interest, reducing unnecessary computations and improving responsiveness under varying conditions.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%