@article{mao2014detecting,
  title={Detecting foggy images and estimating the haze degree factor},
  author={Mao, Jun and Phommasak, Uthai},
  journal={Journal of Computer Science \& Systems Biology},
  volume={7},
  number={06},
  year={2014},
  publisher={OMICS Publishing Group}
}
@article{huang2024degradation,
  title={Degradation Type-Aware Image Restoration for Effective Object Detection in Adverse Weather},
  author={Huang, Xiaochen and Wang, Xiaofeng and Teng, Qizhi and He, Xiaohai and Chen, Honggang},
  journal={Sensors},
  volume={24},
  number={19},
  pages={6330},
  year={2024},
  publisher={MDPI}
}
@article{fan2024friendnet,
  title={FriendNet: Detection-Friendly Dehazing Network},
  author={Fan, Yihua and Wang, Yongzhen and Wei, Mingqiang and Wang, Fu Lee and Xie, Haoran},
  journal={arXiv preprint arXiv:2403.04443},
  year={2024}
}

@article{b1,
  author={C. Liu and Q. Zhao and Y. Zhang and K. Tan},
  title={Runway Extraction in Low Visibility Conditions Based on Sensor Fusion Method},
  journal={IEEE Sensors Journal},
  volume={14},
  number={6},
  pages={1980-1987},
  month={June},
  year={2014},
  doi={10.1109/JSEN.2014.2306911}
}

@inproceedings{b2,
  author={L. Zhang and Z. Zhai and L. Bai and Y. Li and W. Niu and L. Yuan},
  title={Visual-inertial State Estimation for the Civil Aircraft Landing in Low Visibility Conditions},
  booktitle={2018 International Conference on Networking and Network Applications (NaNA)},
  year={2018},
  pages={292-297},
  address={Xi'an, China},
  doi={10.1109/NANA.2018.8648726}
}

@inproceedings{b3,
  author={S. Khattak and C. Papachristos and K. Alexis},
  title={Visual-Thermal Landmarks and Inertial Fusion for Navigation in Degraded Visual Environments},
  booktitle={2019 IEEE Aerospace Conference},
  year={2019},
  pages={1-9},
  address={Big Sky, MT, USA},
  doi={10.1109/AERO.2019.8741787}
}

@inproceedings{b4,
  author={P. Lieby and others},
  title={Substituting depth for intensity and real-time phosphene rendering: Visual navigation under low vision conditions},
  booktitle={2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
  year={2011},
  pages={8017-8020},
  address={Boston, MA, USA},
  doi={10.1109/IEMBS.2011.6091977}
}

@inproceedings{b5,
  author={L. J. Kramer and others},
  title={Using vision system technologies to enable operational improvements for low visibility approach and landing operations},
  booktitle={2014 IEEE/AIAA 33rd Digital Avionics Systems Conference (DASC)},
  year={2014},
  pages={2B2-1-2B2-17},
  address={Colorado Springs, CO, USA},
  doi={10.1109/DASC.2014.6979422}
}

@inproceedings{b6,
  author={Y. Atom and M. Ye and L. Ren and Y. Tai and X. Liu},
  title={Color-wise Attention Network for Low-light Image Enhancement},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year={2020},
  pages={2130-2139},
  address={Seattle, WA, USA},
  doi={10.1109/CVPRW50498.2020.00261}
}

@article{b7,
  author={M. Boban and T. T. V. Vinhoza and O. K. Tonguz and J. Barros},
  title={Seeing is Believing—Enhancing Message Dissemination in Vehicular Networks Through Visual Cues},
  journal={IEEE Communications Letters},
  volume={16},
  number={2},
  pages={238-241},
  month={February},
  year={2012},
  doi={10.1109/LCOMM.2011.122211.112093}
}

@article{b8,
  author={Vassilis Charissis and Stylianos Papanastasiou},
  title={Human–machine collaboration through vehicle head up display interface},
  journal={Cognition, Technology Work},
  volume={12},
  pages={41-50},
  year={2010},
  doi={10.1007/s10111-008-0117-0}
}

@article{b9,
  author={Yu-Wei Zhan and Fan Liu and Xin Luo and Liqiang Nie and Xin-Shun Xu and Mohan Kankanhalli},
  title={Generating Human-Centric Visual Cues for Human-Object Interaction Detection via Large Vision-Language Models},
  journal={arXiv},
  year={2023},
  note={arXiv:2311.16475}
}

@article{b10,
  author={Rong Tang and Qian Li and Shaoen Tang},
  title={Comparison of Visual Features for Image-Based Visibility Detection},
  journal={Journal of Atmospheric and Oceanic Technology},
  volume={39},
  year={2022},
  doi={10.1175/JTECH-D-21-0170.1}
}

@article{b11,
  author={J. J. DiCarlo and D. Zoccolan and N. C. Rust},
  title={How does the brain solve visual object recognition?},
  journal={Neuron},
  volume={73},
  number={3},
  pages={415-434},
  year={2012},
  doi={10.1016/j.neuron.2012.01.010}
}

@inproceedings{b12,
  author={S. Dodge and L. Karam},
  title={A study and comparison of human and deep learning recognition performance under Visual distortions},
  booktitle={2017 26th International Conference on Computer Communication and Networks (ICCCN)},
  year={2017},
  doi={10.1109/icccn.2017.8038465}
}

@article{b13,
  author={L. E. van Dyck and R. Kwitt and S. J. Denzler and W. R. Gruber},
  title={Comparing object recognition in humans and deep convolutional neural networks: An eye-tracking study},
  journal={Frontiers in Neuroscience},
  volume={15},
  year={2021},
  doi={10.3389/fnins.2021.750639}
}

@article{b14,
  author={L. E. van Dyck and S. J. Denzler and W. R. Gruber},
  title={Guiding visual attention in deep convolutional neural networks based on human eye movements},
  journal={Frontiers in Neuroscience},
  volume={16},
  year={2022},
  doi={10.3389/fnins.2022.975639}
}

@article{b15,
  author={J. Yang and J. Yang and L. Luo and Y. Wang and S. Wang and J. Liu},
  title={Robust visual recognition in poor visibility conditions: A prior knowledge-guided adversarial learning approach},
  journal={Electronics},
  volume={12},
  number={17},
  pages={3711},
  year={2023},
  doi={10.3390/electronics12173711}
}

@article{b16,
  author={D. Malowany and H. Guterman},
  title={Biologically Inspired Visual System Architecture for object recognition in Autonomous Systems},
  journal={Algorithms},
  volume={13},
  number={7},
  pages={167},
  year={2020},
  doi={10.3390/a13070167}
}

@article{b17,
  author={X.-S. Zhang and S.-B. Gao and C.-Y. Li and Y.-J. Li},
  title={A retina inspired model for enhancing visibility of hazy images},
  journal={Frontiers in Computational Neuroscience},
  volume={9},
  year={2015},
  doi={10.3389/fncom.2015.00151}
}

@article{b18,
  author={H. Lukanov and P. König and G. Pipa},
  title={Biologically inspired deep learning model for efficient foveal-peripheral vision},
  journal={Frontiers in Computational Neuroscience},
  volume={15},
  year={2021},
  doi={10.3389/fncom.2021.746204}
}

@article{b19,
  author={I. I. Groen and E. H. Silson and C. I. Baker},
  title={Contributions of low- and high-level properties to neural processing of visual scenes in the human brain},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={372},
  number={1714},
  year={2017},
  doi={10.1098/rstb.2016.0102}
}

@incollection{b20,
  author={M.K. Ebrahimpour and J.B. Falandays and S. Spevack and D.C. Noelle},
  title={Do Humans Look Where Deep Convolutional Neural Networks “Attend”?},
  booktitle={Advances in Visual Computing. ISVC 2019. Lecture Notes in Computer Science},
  volume={11845},
  year={2019},
  publisher={Springer, Cham},
  doi={10.1007/978-3-030-33723-0\_5}
}

@article{b21,
  author={Y. Zheng and Y. Zhan and X. Huang and G. Ji},
  title={YOLOv5s FMG: An Improved Small Target Detection Algorithm Based on YOLOv5 in Low Visibility},
  journal={IEEE Access},
  volume={11},
  pages={75782-75793},
  year={2023},
  doi={10.1109/ACCESS.2023.3297218}
}

@article{b22,
  author={Y. Gao and W. Xu and Y. Lu},
  title={Let You See in Haze and Sandstorm: Two-in-One Low-Visibility Enhancement Network},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={72},
  pages={1-12},
  year={2023},
  doi={10.1109/TIM.2023.3304668}
}

@article{b23,
  author={J. Yang and J. Yang and L. Luo and Y. Wang and S. Wang and J. Liu},
  title={Robust Visual Recognition in Poor Visibility Conditions: A Prior Knowledge-Guided Adversarial Learning Approach},
  journal={Electronics},
  volume={12},
  pages={3711},
  year={2023},
  doi={10.3390/electronics12173711}
}

@inproceedings{b24,
  author={X. Wu and Z. Gao},
  title={Based on the Improved YOLOv8 Pedestrian and Vehicle Detection Under Low-Visibility Conditions},
  booktitle={2023 2nd International Conference on Artificial Intelligence and Intelligent Information Processing (AIIIP)},
  year={2023},
  pages={297-300},
  address={Hangzhou, China},
  doi={10.1109/AIIIP61647.2023.00063}
}

@inproceedings{b25,
  author={S. Krishna B V and B. Rajalakshmi and U. Dhammini and M. K. Monika and C. Nethra and K. Ashok},
  title={Image De-hazing techniques for Vision based applications - A survey},
  booktitle={2023 International Conference for Advancement in Technology (ICONAT)},
  year={2023},
  pages={1-5},
  address={Goa, India},
  doi={10.1109/ICONAT57137.2023.10080156}
}

@article{b26,
  author={W. Yang and others},
  title={Advancing Image Understanding in Poor Visibility Environments: A Collective Benchmark Study},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={5737-5752},
  year={2020},
  doi={10.1109/TIP.2020.2981922}
}

@inproceedings{b27,
  author={Yun Zhai and Mubarak Shah},
  title={Visual attention detection in video sequences using spatiotemporal cues},
  booktitle={Proceedings of the 14th ACM international conference on Multimedia (MM '06)},
  year={2006},
  pages={815-824},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  doi={10.1145/1180639.1180824}
}

@article{b28,
  author={Zhiying Li and Shuyuan Lin and Zhongming Liang and Yongjia Lei and Zefan Wang and Hao Chen},
  title={PDE: A Real-Time Object Detection and Enhancing Model under Low Visibility Conditions},
  journal={International Journal of Advanced Computer Science and Applications(IJACSA)},
  volume={13},
  number={12},
  year={2022},
  doi={10.14569/IJACSA.2022.0131299}
}

@article{b29,
  author={M. Jian and J. Wang and H. Yu and G. Wang and X. Meng and L. Yang and J. Dong and Y. Yin},
  title={Visual saliency detection by integrating spatial position prior of object with background cues},
  journal={Expert Systems With Applications},
  volume={168},
  pages={114219},
  year={2021},
  doi={10.1016/j.eswa.2020.114219}
}

@article{b30,
  author={D. A. Mély and J. Kim and M. McGill and Y. Guo and T. Serre},
  title={A systematic comparison between visual cues for boundary detection},
  journal={Vision Research},
  volume={120},
  pages={93-107},
  year={2016},
  doi={10.1016/j.visres.2015.11.007}
}

@article{b31,
  author={C. Sakaridis and D. Dai and L. Van Gool},
  title={Semantic Foggy Scene Understanding with Synthetic Data},
  journal={International Journal of Computer Vision},
  volume={126},
  pages={973-992},
  year={2018},
  doi={10.1007/s11263-018-1072-8}
}

@article{b32,
  author={B. Li and others},
  title={Benchmarking Single-Image Dehazing and Beyond},
  journal={IEEE Transactions on Image Processing},
  volume={28},
  number={1},
  pages={492-505},
  year={2019},
  doi={10.1109/TIP.2018.2867951}
}

@article{b33,
  author={X. Meng and Y. Liu and L. Fan and J. Fan},
  title={YOLOv5s-Fog: An Improved Model Based on YOLOv5s for Object Detection in Foggy Weather Scenarios},
  journal={Sensors},
  volume={23},
  pages={5321},
  year={2023},
  doi={10.3390/s23115321}
}

@inproceedings{b34,
  author={B. Li and X. Peng and Z. Wang and J. Xu and D. Feng},
  title={Aod-net: All-in-one dehazing network},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  year={2017},
  pages={4770-4778}
}

@inproceedings{b35,
  author={H. Zhang and V.M. Patel},
  title={Densely connected pyramid dehazing network},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2018},
  pages={3194-3203}
}

@inproceedings{b36,
  author={Y.-W. Lee and L.-K. Wong and J. See},
  title={Image Dehazing With Contextualized Attentive U-NET},
  booktitle={2020 IEEE International Conference on Image Processing (ICIP)},
  year={2020},
  pages={1068-1072},
  address={Abu Dhabi, United Arab Emirates},
  doi={10.1109/ICIP40778.2020.9190725}
}

@article{b37,
  author={B. Cai and X. Xu and K. Jia and C. Qing and D. Tao},
  title={Dehazenet: An end-to-end system for single image haze removal},
  journal={IEEE transactions on image processing},
  volume={25},
  number={11},
  pages={5187-5198},
  year={2016}
}
@inproceedings{li2017aod,
  title={Aod-net: All-in-one dehazing network},
  author={Li, Boyi and Peng, Xiulian and Wang, Zhangyang and Xu, Jizheng and Feng, Dan},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4770--4778},
  year={2017}
}
@article{cai2016dehazenet,
  title={Dehazenet: An end-to-end system for single image haze removal},
  author={Cai, Bolun and Xu, Xiangmin and Jia, Kui and Qing, Chunmei and Tao, Dacheng},
  journal={IEEE transactions on image processing},
  volume={25},
  number={11},
  pages={5187--5198},
  year={2016},
  publisher={IEEE}
}
@article{zhou2024dehaze,
  title={Dehaze-UNet: A Lightweight Network Based on UNet for Single-Image Dehazing},
  author={Zhou, Hao and Chen, Zekai and Li, Qiao and Tao, Tao},
  journal={Electronics},
  volume={13},
  number={11},
  pages={2082},
  year={2024},
  publisher={MDPI}
}
