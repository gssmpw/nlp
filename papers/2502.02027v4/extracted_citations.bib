@article{b1,
  author={C. Liu and Q. Zhao and Y. Zhang and K. Tan},
  title={Runway Extraction in Low Visibility Conditions Based on Sensor Fusion Method},
  journal={IEEE Sensors Journal},
  volume={14},
  number={6},
  pages={1980-1987},
  month={June},
  year={2014},
  doi={10.1109/JSEN.2014.2306911}
}

@article{b10,
  author={Rong Tang and Qian Li and Shaoen Tang},
  title={Comparison of Visual Features for Image-Based Visibility Detection},
  journal={Journal of Atmospheric and Oceanic Technology},
  volume={39},
  year={2022},
  doi={10.1175/JTECH-D-21-0170.1}
}

@article{b11,
  author={J. J. DiCarlo and D. Zoccolan and N. C. Rust},
  title={How does the brain solve visual object recognition?},
  journal={Neuron},
  volume={73},
  number={3},
  pages={415-434},
  year={2012},
  doi={10.1016/j.neuron.2012.01.010}
}

@inproceedings{b12,
  author={S. Dodge and L. Karam},
  title={A study and comparison of human and deep learning recognition performance under Visual distortions},
  booktitle={2017 26th International Conference on Computer Communication and Networks (ICCCN)},
  year={2017},
  doi={10.1109/icccn.2017.8038465}
}

@article{b13,
  author={L. E. van Dyck and R. Kwitt and S. J. Denzler and W. R. Gruber},
  title={Comparing object recognition in humans and deep convolutional neural networks: An eye-tracking study},
  journal={Frontiers in Neuroscience},
  volume={15},
  year={2021},
  doi={10.3389/fnins.2021.750639}
}

@article{b14,
  author={L. E. van Dyck and S. J. Denzler and W. R. Gruber},
  title={Guiding visual attention in deep convolutional neural networks based on human eye movements},
  journal={Frontiers in Neuroscience},
  volume={16},
  year={2022},
  doi={10.3389/fnins.2022.975639}
}

@article{b15,
  author={J. Yang and J. Yang and L. Luo and Y. Wang and S. Wang and J. Liu},
  title={Robust visual recognition in poor visibility conditions: A prior knowledge-guided adversarial learning approach},
  journal={Electronics},
  volume={12},
  number={17},
  pages={3711},
  year={2023},
  doi={10.3390/electronics12173711}
}

@article{b16,
  author={D. Malowany and H. Guterman},
  title={Biologically Inspired Visual System Architecture for object recognition in Autonomous Systems},
  journal={Algorithms},
  volume={13},
  number={7},
  pages={167},
  year={2020},
  doi={10.3390/a13070167}
}

@article{b17,
  author={X.-S. Zhang and S.-B. Gao and C.-Y. Li and Y.-J. Li},
  title={A retina inspired model for enhancing visibility of hazy images},
  journal={Frontiers in Computational Neuroscience},
  volume={9},
  year={2015},
  doi={10.3389/fncom.2015.00151}
}

@article{b18,
  author={H. Lukanov and P. König and G. Pipa},
  title={Biologically inspired deep learning model for efficient foveal-peripheral vision},
  journal={Frontiers in Computational Neuroscience},
  volume={15},
  year={2021},
  doi={10.3389/fncom.2021.746204}
}

@inproceedings{b2,
  author={L. Zhang and Z. Zhai and L. Bai and Y. Li and W. Niu and L. Yuan},
  title={Visual-inertial State Estimation for the Civil Aircraft Landing in Low Visibility Conditions},
  booktitle={2018 International Conference on Networking and Network Applications (NaNA)},
  year={2018},
  pages={292-297},
  address={Xi'an, China},
  doi={10.1109/NANA.2018.8648726}
}

@article{b21,
  author={Y. Zheng and Y. Zhan and X. Huang and G. Ji},
  title={YOLOv5s FMG: An Improved Small Target Detection Algorithm Based on YOLOv5 in Low Visibility},
  journal={IEEE Access},
  volume={11},
  pages={75782-75793},
  year={2023},
  doi={10.1109/ACCESS.2023.3297218}
}

@article{b22,
  author={Y. Gao and W. Xu and Y. Lu},
  title={Let You See in Haze and Sandstorm: Two-in-One Low-Visibility Enhancement Network},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={72},
  pages={1-12},
  year={2023},
  doi={10.1109/TIM.2023.3304668}
}

@article{b23,
  author={J. Yang and J. Yang and L. Luo and Y. Wang and S. Wang and J. Liu},
  title={Robust Visual Recognition in Poor Visibility Conditions: A Prior Knowledge-Guided Adversarial Learning Approach},
  journal={Electronics},
  volume={12},
  pages={3711},
  year={2023},
  doi={10.3390/electronics12173711}
}

@inproceedings{b24,
  author={X. Wu and Z. Gao},
  title={Based on the Improved YOLOv8 Pedestrian and Vehicle Detection Under Low-Visibility Conditions},
  booktitle={2023 2nd International Conference on Artificial Intelligence and Intelligent Information Processing (AIIIP)},
  year={2023},
  pages={297-300},
  address={Hangzhou, China},
  doi={10.1109/AIIIP61647.2023.00063}
}

@inproceedings{b25,
  author={S. Krishna B V and B. Rajalakshmi and U. Dhammini and M. K. Monika and C. Nethra and K. Ashok},
  title={Image De-hazing techniques for Vision based applications - A survey},
  booktitle={2023 International Conference for Advancement in Technology (ICONAT)},
  year={2023},
  pages={1-5},
  address={Goa, India},
  doi={10.1109/ICONAT57137.2023.10080156}
}

@article{b26,
  author={W. Yang and others},
  title={Advancing Image Understanding in Poor Visibility Environments: A Collective Benchmark Study},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={5737-5752},
  year={2020},
  doi={10.1109/TIP.2020.2981922}
}

@inproceedings{b27,
  author={Yun Zhai and Mubarak Shah},
  title={Visual attention detection in video sequences using spatiotemporal cues},
  booktitle={Proceedings of the 14th ACM international conference on Multimedia (MM '06)},
  year={2006},
  pages={815-824},
  publisher={Association for Computing Machinery},
  address={New York, NY, USA},
  doi={10.1145/1180639.1180824}
}

@article{b28,
  author={Zhiying Li and Shuyuan Lin and Zhongming Liang and Yongjia Lei and Zefan Wang and Hao Chen},
  title={PDE: A Real-Time Object Detection and Enhancing Model under Low Visibility Conditions},
  journal={International Journal of Advanced Computer Science and Applications(IJACSA)},
  volume={13},
  number={12},
  year={2022},
  doi={10.14569/IJACSA.2022.0131299}
}

@article{b29,
  author={M. Jian and J. Wang and H. Yu and G. Wang and X. Meng and L. Yang and J. Dong and Y. Yin},
  title={Visual saliency detection by integrating spatial position prior of object with background cues},
  journal={Expert Systems With Applications},
  volume={168},
  pages={114219},
  year={2021},
  doi={10.1016/j.eswa.2020.114219}
}

@inproceedings{b3,
  author={S. Khattak and C. Papachristos and K. Alexis},
  title={Visual-Thermal Landmarks and Inertial Fusion for Navigation in Degraded Visual Environments},
  booktitle={2019 IEEE Aerospace Conference},
  year={2019},
  pages={1-9},
  address={Big Sky, MT, USA},
  doi={10.1109/AERO.2019.8741787}
}

@article{b30,
  author={D. A. Mély and J. Kim and M. McGill and Y. Guo and T. Serre},
  title={A systematic comparison between visual cues for boundary detection},
  journal={Vision Research},
  volume={120},
  pages={93-107},
  year={2016},
  doi={10.1016/j.visres.2015.11.007}
}

@inproceedings{b4,
  author={P. Lieby and others},
  title={Substituting depth for intensity and real-time phosphene rendering: Visual navigation under low vision conditions},
  booktitle={2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
  year={2011},
  pages={8017-8020},
  address={Boston, MA, USA},
  doi={10.1109/IEMBS.2011.6091977}
}

@inproceedings{b5,
  author={L. J. Kramer and others},
  title={Using vision system technologies to enable operational improvements for low visibility approach and landing operations},
  booktitle={2014 IEEE/AIAA 33rd Digital Avionics Systems Conference (DASC)},
  year={2014},
  pages={2B2-1-2B2-17},
  address={Colorado Springs, CO, USA},
  doi={10.1109/DASC.2014.6979422}
}

@inproceedings{b6,
  author={Y. Atom and M. Ye and L. Ren and Y. Tai and X. Liu},
  title={Color-wise Attention Network for Low-light Image Enhancement},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year={2020},
  pages={2130-2139},
  address={Seattle, WA, USA},
  doi={10.1109/CVPRW50498.2020.00261}
}

@article{b7,
  author={M. Boban and T. T. V. Vinhoza and O. K. Tonguz and J. Barros},
  title={Seeing is Believing—Enhancing Message Dissemination in Vehicular Networks Through Visual Cues},
  journal={IEEE Communications Letters},
  volume={16},
  number={2},
  pages={238-241},
  month={February},
  year={2012},
  doi={10.1109/LCOMM.2011.122211.112093}
}

@article{b8,
  author={Vassilis Charissis and Stylianos Papanastasiou},
  title={Human–machine collaboration through vehicle head up display interface},
  journal={Cognition, Technology Work},
  volume={12},
  pages={41-50},
  year={2010},
  doi={10.1007/s10111-008-0117-0}
}

@article{b9,
  author={Yu-Wei Zhan and Fan Liu and Xin Luo and Liqiang Nie and Xin-Shun Xu and Mohan Kankanhalli},
  title={Generating Human-Centric Visual Cues for Human-Object Interaction Detection via Large Vision-Language Models},
  journal={arXiv},
  year={2023},
  note={arXiv:2311.16475}
}

