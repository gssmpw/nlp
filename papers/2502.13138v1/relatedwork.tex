\section{Related Work}
\subsection{LLM Agents}
Recent advances in large language models have spurred the development of agents that combine natural language reasoning with task execution. \emph{General-purpose} agents such as ReAct \citep{Yao2023} and HuggingGPT \citep{Shen2023} interleave planning with action selection to perform tasks ranging from information retrieval to multi-modal processing. In contrast, \emph{specialized} agents like Voyager \citep{voyager} and AlphaCode \citep{alphacode} are tailored to specific domains such as embodied reasoning and competitive code generation. These systems integrate execution feedback into the LLM's reasoning process, enabling iterative refinement of candidate solutions.

\subsection{Automated Machine Learning}
Automated Machine Learning (AutoML) aims to eliminate manual intervention in model selection, hyperparameter tuning, and pipeline configuration. Early frameworks such as Auto-WEKA \citep{autoweka-kdd} and TPOT \citep{tpot} employed Bayesian optimization and genetic programming, respectively, to search over predefined model spaces. Later systems like Auto-Sklearn \citep{autosklearn} and AutoGluon \citep{autogluon} have leveraged meta-learning and ensemble techniques to further improve performance. Despite their success, many conventional AutoML methods rely on static search spaces and lack the dynamic adaptability required for more complex problem settings.

\subsection{Neural Architecture Search}
Neural Architecture Search (NAS) focuses on automatically designing neural network topologies. Initial methods based on reinforcement learning \citep{Zoph2017} and evolutionary strategies \citep{Real2019} demonstrated that automated search could yield competitive architectures. Differentiable approaches such as DARTS \citep{Liu2019} have reduced the computational cost by enabling gradient-based optimization over a relaxed search space. However, NAS still faces challenges in computational expense and search space design. 
AIDE, on the other hand, avoids such problems above with code space search and efficient design exploration powered by LLMs.