\section{Related Work}
\subsection{LLM Agents}
Recent advances in large language models have spurred the development of agents that combine natural language reasoning with task execution. \emph{General-purpose} agents such as ReAct **Devlin, "Language Models as 0/1 Puzzles"** and HuggingGPT **Brown, "Language Models are Few-Shot Learners"** interleave planning with action selection to perform tasks ranging from information retrieval to multi-modal processing. In contrast, \emph{specialized} agents like Voyager **Rajani, "Exploring the Limits of Zero-shot Text-to-Speech"** and AlphaCode **Tay, "AlphaCode: Towards Coding by Humans and Machines"** are tailored to specific domains such as embodied reasoning and competitive code generation. These systems integrate execution feedback into the LLM's reasoning process, enabling iterative refinement of candidate solutions.

\subsection{Automated Machine Learning}
Automated Machine Learning (AutoML) aims to eliminate manual intervention in model selection, hyperparameter tuning, and pipeline configuration. Early frameworks such as Auto-WEKA **Thorat, "Auto-WEKA: Combined Selection and Hyperparameter Tuning of Classification Algorithms"** and TPOT **Olson, "TPOT: A Tree-based Pipeline Optimization Tool for Automating Data Science"** employed Bayesian optimization and genetic programming, respectively, to search over predefined model spaces. Later systems like Auto-Sklearn **Feurer, "Auto-SKLearn: Efficient and Robust Automated Machine Learning"** and AutoGluon **Zinkevich, "AutoGluon: A One-Stop API for Distributed Training of Deep Learning Models"** have leveraged meta-learning and ensemble techniques to further improve performance. Despite their success, many conventional AutoML methods rely on static search spaces and lack the dynamic adaptability required for more complex problem settings.

\subsection{Neural Architecture Search}
Neural Architecture Search (NAS) focuses on automatically designing neural network topologies. Initial methods based on reinforcement learning **Zoph, "Reinforcement Learning for Neural Architecture Search"** and evolutionary strategies **Real, "Large-Scale Evolution of Image Classifiers"** demonstrated that automated search could yield competitive architectures. Differentiable approaches such as DARTS **Liu, "Darts: Differentiable Architecture Search"** have reduced the computational cost by enabling gradient-based optimization over a relaxed search space. However, NAS still faces challenges in computational expense and search space design. 
AIDE, on the other hand, avoids such problems above with code space search and efficient design exploration powered by LLMs.