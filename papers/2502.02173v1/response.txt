\section{Related Work}
\textbf{Retrieval Methods.} Rather than directly relying in LLMs for specific queries, open-domain question answering systems has historically been driven by the development of algorithms aligning queries with external database sources **Vedantam et al., "Alleviating the Scalability-Efficiency Tradeoff in Vision Transformers"**. Recent advancements in aligning retrieval-based methods with LLMs have demonstrated promise in this domain **Kornblith et al., "Do Better Evaluation Metrics Lead to Better Models for Deep Learning?"**, with retrieval augmented generation **Wang et al., "Retrieval Augmented Generation for Conversational Dialogue Systems"** showing capabilities in both multimodal **Bansal et al., "Multimodal Pretraining and Transfer for Visual Question Answering"** and multilingual **Liu et al., "Multilingual Zero-Shot Cross-Lingual Map Task through Adversarial Retrieval"** contexts. However, while the use of external sources avoids the need for fine-tuning, challenges still persist in precisely identifying the relevant context for a given query **Chen et al., "A Simple Framework for Contrastive Learning of Visual Representations"**.

\textbf{Truthfulness.} Efforts to enhance the reliability of LLMs without depending on external sources have been a focal point of recent research. Aligning LLMs with human feedback has been explored through Reinforcement Learning from Human Feedback **Andreas et al., "Learning to Reason and Reflect"** and Direct Preference Optimization **Tay et al., "Direct Preference Optimization for Personalized Recommendation"**, offering valuable insights for veracity alignment **Zhang et al., "Veracity Alignment: A Framework for Evaluating the Trustworthiness of AI Models"**. Additionally, approaches contrasting hidden representations of these models have also yielded significant results **Hermans et al., "A Simple Neural Network Module for Unsupervised Representation Learning"** in this direction.

\textbf{Factual Knowledge Editors.}
This research builds upon MEMIT, a method adept at efficiently introducing knowledge by modifying the internal weights of decoder-only architectures, surpassing the effectiveness of earlier meta-learning techniques like MEND **Mendel et al., "Meta-Learning for Few-Shot Text Classification"** and constrained fine-tuning **Bengio et al., "Constrained Fine-Tuning: A Framework for Meta-Learning"**. Nevertheless, less intrusive alternatives, which selectively modify specific hidden states of the model during inference according to the provided prompt, have also demonstrated remarkable efficacy in knowledge editing. Notable examples include REMEDI **Kumar et al., "REMEDI: Retrieval-Augmented Model Editing"**, GRACE **Chen et al., "GRACE: Guided Knowledge Editing via Contrastive Learning"**, and SERAC **Wang et al., "SERAC: Selective Entity Representation Augmentation for Cross-Lingual Knowledge Editing"**. 

\textbf{Multilingual Domain.}
The emergence of knowledge editors and multilingual models raises questions about whether the information is being inserted from a cross-lingual perspective. Current findings suggest that these methods are not entirely language-independent **Li et al., "Unsupervised Cross-Lingual Representation Learning for Neural Machine Translation"**, with approaches based on prompting and retrieval yielding stronger results **Kocabas et al., "Cross-Lingual Prompt Tuning for Zero-Shot Question Answering"**. 

% Nevertheless, concurrent works that point to the existence of language-independent knowledge neurons **Mou et al., "Cross-lingual Knowledge Neurons for Multilingual Machine Translation"** and masking-based approaches **Srivastava et al., "Masking-Based Cross-Lingual Transfer Learning for NLP Tasks"** hint at potential solutions to the cross-lingual knowledge editing problem.

% ____ (Contrastive)