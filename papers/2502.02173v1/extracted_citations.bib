@article{Aging,
  title={Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adaptors},
  author={Hartvigsen, Thomas and Sankaranarayanan, Swami and Palangi, Hamid and Kim, Yoon and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:2211.11031},
  year={2022}
}

@article{BM25,
  title={The probabilistic relevance framework: BM25 and beyond},
  author={Robertson, Stephen and Zaragoza, Hugo and others},
  journal={Foundations and Trends{\textregistered} in Information Retrieval},
  volume={3},
  number={4},
  pages={333--389},
  year={2009},
  publisher={Now Publishers, Inc.}
}

@article{Chen_multimodal,
  title={Murag: Multimodal retrieval-augmented generator for open question answering over images and text},
  author={Chen, Wenhu and Hu, Hexiang and Chen, Xi and Verga, Pat and Cohen, William W},
  journal={arXiv preprint arXiv:2210.02928},
  year={2022}
}

@article{Chen_multimodal2,
  title={Re-imagen: Retrieval-augmented text-to-image generator},
  author={Chen, Wenhu and Hu, Hexiang and Saharia, Chitwan and Cohen, William W},
  journal={arXiv preprint arXiv:2209.14491},
  year={2022}
}

@article{Contrastive_L,
  title={Contrastive decoding: Open-ended text generation as optimization},
  author={Li, Xiang Lisa and Holtzman, Ari and Fried, Daniel and Liang, Percy and Eisner, Jason and Hashimoto, Tatsunori and Zettlemoyer, Luke and Lewis, Mike},
  journal={arXiv preprint arXiv:2210.15097},
  year={2022}
}

@misc{CrossLingual,
      title={Cross-Lingual Knowledge Editing in Large Language Models}, 
      author={Jiaan Wang and Yunlong Liang and Zengkui Sun and Yuxuan Cao and Jiarong Xu},
      year={2023},
      eprint={2309.08952},
      archivePrefix={arXiv},
}

@article{DOLA,
  title={Dola: Decoding by contrasting layers improves factuality in large language models},
  author={Chuang, Yung-Sung and Xie, Yujia and Luo, Hongyin and Kim, Yoon and Glass, James and He, Pengcheng},
  journal={arXiv preprint arXiv:2309.03883},
  year={2023}
}

@article{DPO,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

@article{FT_normal,
  title={Modifying memories in transformer models},
  author={Zhu, Chen and Rawat, Ankit Singh and Zaheer, Manzil and Bhojanapalli, Srinadh and Li, Daliang and Yu, Felix and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:2012.00363},
  year={2020}
}

@article{GAR,
  title={Generation-augmented retrieval for open-domain question answering},
  author={Mao, Yuning and He, Pengcheng and Liu, Xiaodong and Shen, Yelong and Gao, Jianfeng and Han, Jiawei and Chen, Weizhu},
  journal={arXiv preprint arXiv:2009.08553},
  year={2020}
}

@article{GRATH,
  title={GRATH: Gradual Self-Truthifying for Large Language Models},
  author={Chen, Weixin and Li, Bo},
  journal={arXiv preprint arXiv:2401.12292},
  year={2024}
}

@misc{IKE,
      title={Can We Edit Factual Knowledge by In-Context Learning?}, 
      author={Ce Zheng and Lei Li and Qingxiu Dong and Yuxuan Fan and Zhiyong Wu and Jingjing Xu and Baobao Chang},
      year={2023},
      eprint={2305.12740},
      archivePrefix={arXiv},
}

@misc{JourneyCenterKnowledge,
      title={Journey to the Center of the Knowledge Neurons: Discoveries of Language-Independent Knowledge Neurons and Degenerate Knowledge Neurons}, 
      author={Yuheng Chen and Pengfei Cao and Yubo Chen and Kang Liu and Jun Zhao},
      year={2023},
      eprint={2308.13198},
      archivePrefix={arXiv},
}

@misc{LanguageAnisotropic,
      title={Language Anisotropic Cross-Lingual Model Editing}, 
      author={Yang Xu and Yutai Hou and Wanxiang Che and Min Zhang},
      year={2023},
      eprint={2205.12677},
      archivePrefix={arXiv},
}

@misc{MEND,
      title={Fast Model Editing at Scale}, 
      author={Eric Mitchell and Charles Lin and Antoine Bosselut and Chelsea Finn and Christopher D. Manning},
      year={2022},
      eprint={2110.11309},
      archivePrefix={arXiv},
}

@misc{PolyglotOrNot,
      title={Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models}, 
      author={Tim Schott and Daniel Furman and Shreshta Bhat},
      year={2023},
      eprint={2305.13675},
      archivePrefix={arXiv},
}

@misc{RAG,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{RAG_surv,
  title={Retrieval-augmented generation for large language models: A survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  journal={arXiv preprint arXiv:2312.10997},
  year={2023}
}

@article{RAGmultimodal,
  title={Retrieval-augmented multimodal language modeling},
  author={Yasunaga, Michihiro and Aghajanyan, Armen and Shi, Weijia and James, Rich and Leskovec, Jure and Liang, Percy and Lewis, Mike and Zettlemoyer, Luke and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2211.12561},
  year={2022}
}

@misc{REMEDI,
      title={Inspecting and Editing Knowledge Representations in Language Models}, 
      author={Evan Hernandez and Belinda Z. Li and Jacob Andreas},
      year={2023},
      eprint={2304.00740},
      archivePrefix={arXiv},
}

@inproceedings{RETRO,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Van Den Driessche, George Bm and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  booktitle={International conference on machine learning},
  pages={2206--2240},
  year={2022},
  organization={PMLR}
}

@article{RLHF,
  title={Training language models to follow instructions with human feedback, 2022},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={URL https://arxiv. org/abs/2203.02155},
  volume={13},
  year={2022}
}

@article{RLHF2,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@article{dense_passage,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2004.04906},
  year={2020}
}

@article{retrievalMulti,
  title={Retrieval-augmented Multilingual Knowledge Editing},
  author={Wang, Weixuan and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:2312.13040},
  year={2023}
}

@article{ripple_effects,
  title={Evaluating the ripple effects of knowledge editing in language models},
  author={Cohen, Roi and Biran, Eden and Yoran, Ori and Globerson, Amir and Geva, Mor},
  journal={arXiv preprint arXiv:2307.12976},
  year={2023}
}

@misc{serac,
      title={Memory-Based Model Editing at Scale}, 
      author={Eric Mitchell and Charles Lin and Antoine Bosselut and Christopher D. Manning and Chelsea Finn},
      year={2022},
      eprint={2206.06520},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

