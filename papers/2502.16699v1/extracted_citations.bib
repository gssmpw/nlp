@misc{aaronson_my_2022,
  title = {My {{AI Safety Lecture}} for {{UT Effective Altruism}}},
  author = {Aaronson, Scott},
  year = {2022},
  month = nov,
  journal = {Shtetl-Optimized},
  url = {https://scottaaronson.blog/?p=6823},
  urldate = {2023-01-12},
  abstract = {Two weeks ago, I gave a lecture setting out my current thoughts on AI safety, halfway through my year at OpenAI. I was asked to speak by UT Austin's Effective Altruist club. You can watch the\ldots},
  langid = {american}
}

@inproceedings{abdelnabi2021adversarial,
  title={Adversarial watermarking transformer: Towards tracing text provenance with data hiding},
  author={Abdelnabi, Sahar and Fritz, Mario},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)},
  pages={121--140},
  year={2021},
  organization={IEEE}
}

@article{alshammari2024toward,
  title={Toward Robust Arabic AI-Generated Text Detection: Tackling Diacritics Challenges},
  author={Alshammari, Hamed and Elleithy, Khaled},
  journal={Information},
  volume={15},
  number={7},
  pages={419},
  year={2024},
  publisher={MDPI}
}

@article{chang2024postmark,
  title={PostMark: A Robust Blackbox Watermark for Large Language Models},
  author={Chang, Yapei and Krishna, Kalpesh and Houmansadr, Amir and Wieting, John and Iyyer, Mohit},
  journal={arXiv preprint arXiv:2406.14517},
  year={2024}
}

@inproceedings{christ2024undetectable,
  title={Undetectable watermarks for language models},
  author={Christ, Miranda and Gunn, Sam and Zamir, Or},
  booktitle={The Thirty Seventh Annual Conference on Learning Theory},
  pages={1125--1139},
  year={2024},
  organization={PMLR}
}

@article{dathathri2024scalable,
  title={Scalable watermarking for identifying large language model outputs},
  author={Dathathri, Sumanth and See, Abigail and Ghaisas, Sumedh and Huang, Po-Sen and McAdam, Rob and Welbl, Johannes and Bachani, Vandana and Kaskasoli, Alex and Stanforth, Robert and Matejovicova, Tatiana and others},
  journal={Nature},
  volume={634},
  number={8035},
  pages={818--823},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{gehrmann2019gltr,
  title={Gltr: Statistical detection and visualization of generated text},
  author={Gehrmann, Sebastian and Strobelt, Hendrik and Rush, Alexander M},
  journal={arXiv preprint arXiv:1906.04043},
  year={2019}
}

@article{he2024can,
  title={Can watermarks survive translation? on the cross-lingual consistency of text watermark for large language models},
  author={He, Zhiwei and Zhou, Binglin and Hao, Hongkun and Liu, Aiwei and Wang, Xing and Tu, Zhaopeng and Zhang, Zhuosheng and Wang, Rui},
  journal={arXiv preprint arXiv:2402.14007},
  year={2024}
}

@article{hou2023semstamp,
  title={Semstamp: A semantic watermark with paraphrastic robustness for text generation},
  author={Hou, Abe Bohan and Zhang, Jingyu and He, Tianxing and Wang, Yichen and Chuang, Yung-Sung and Wang, Hongwei and Shen, Lingfeng and Van Durme, Benjamin and Khashabi, Daniel and Tsvetkov, Yulia},
  journal={arXiv preprint arXiv:2310.03991},
  year={2023}
}

@article{hou2024k,
  title={k-SemStamp: A Clustering-Based Semantic Watermark for Detection of Machine-Generated Text},
  author={Hou, Abe Bohan and Zhang, Jingyu and Wang, Yichen and Khashabi, Daniel and He, Tianxing},
  journal={arXiv preprint arXiv:2402.11399},
  year={2024}
}

@article{kirchenbauer2023reliability,
  title={On the reliability of watermarks for large language models},
  author={Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Shu, Manli and Saifullah, Khalid and Kong, Kezhi and Fernando, Kasun and Saha, Aniruddha and Goldblum, Micah and Goldstein, Tom},
  journal={arXiv preprint arXiv:2306.04634},
  year={2023}
}

@inproceedings{kirchenbauer2023watermark,
  title={A watermark for large language models},
  author={Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Katz, Jonathan and Miers, Ian and Goldstein, Tom},
  booktitle={International Conference on Machine Learning},
  pages={17061--17084},
  year={2023},
  organization={PMLR}
}

@article{kuditipudi2023robust,
  title={Robust distortion-free watermarks for language models},
  author={Kuditipudi, Rohith and Thickstun, John and Hashimoto, Tatsunori and Liang, Percy},
  journal={arXiv preprint arXiv:2307.15593},
  year={2023}
}

@article{lee2023wrote,
  title={Who wrote this code? watermarking for code generation},
  author={Lee, Taehyun and Hong, Seokhee and Ahn, Jaewoo and Hong, Ilgee and Lee, Hwaran and Yun, Sangdoo and Shin, Jamin and Kim, Gunhee},
  journal={arXiv preprint arXiv:2305.15060},
  year={2023}
}

@article{lu2024entropy,
  title={An Entropy-based Text Watermarking Detection Method},
  author={Lu, Yijian and Liu, Aiwei and Yu, Dianzhi and Li, Jingjing and King, Irwin},
  journal={arXiv preprint arXiv:2403.13485},
  year={2024}
}

@article{mitchell_detectgpt_2023,
  title = {{{DetectGPT}}: {{Zero-Shot Machine-Generated Text Detection}} Using {{Probability Curvature}}},
  shorttitle = {{{DetectGPT}}},
  author = {Mitchell, Eric and Lee, Yoonho and Khazatsky, Alexander and Manning, Christopher D. and Finn, Chelsea},
  year = {2023},
  month = jan,
  doi = {10.48550/arXiv.2301.11305},
  url = {https://arxiv.org/abs/2301.11305v1},
  urldate = {2023-01-27},
  abstract = {The fluency and factual knowledge of large language models (LLMs) heightens the need for corresponding systems to detect whether a piece of text is machine-written. For example, students may use LLMs to complete written assignments, leaving instructors unable to accurately assess student learning. In this paper, we first demonstrate that text sampled from an LLM tends to occupy negative curvature regions of the model's log probability function. Leveraging this observation, we then define a new curvature-based criterion for judging if a passage is generated from a given LLM. This approach, which we call DetectGPT, does not require training a separate classifier, collecting a dataset of real or generated passages, or explicitly watermarking generated text. It uses only log probabilities computed by the model of interest and random perturbations of the passage from another generic pre-trained language model (e.g, T5). We find DetectGPT is more discriminative than existing zero-shot methods for model sample detection, notably improving detection of fake news articles generated by 20B parameter GPT-NeoX from 0.81 AUROC for the strongest zero-shot baseline to 0.95 AUROC for DetectGPT. See https://ericmitchell.ai/detectgpt for code, data, and other project information.},
  langid = {english}
}

@misc{tian_gptzero_2023,
  type = {Substack Newsletter},
  title = {Gptzero Update V1},
  author = {Tian, Edward},
  year = {2023},
  month = jan,
  journal = {GPTZero},
  url = {https://gptzero.substack.com/p/gptzero-update-v1},
  urldate = {2023-01-12},
  abstract = {General Updates: Thank you sincerely for signing up for the GPTzero beta. I'm completely awestruck by the support this app has generated. In the past day, over 4000+ people have signed up for the beta (via this substack) and 10,000+ more have tried and tested it out on the Streamlit}
}

@article{zhao2023provable,
  title={Provable robust watermarking for ai-generated text},
  author={Zhao, Xuandong and Ananth, Prabhanjan and Li, Lei and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:2306.17439},
  year={2023}
}

