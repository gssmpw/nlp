\section{Related Work}
% \subsection{Medical Time Series Classification}
%Time series classification is an important and challenging problem in data mining**Dauwels, "EEG Signal Processing"**. 
%One of the most popular and traditional TSC approaches is the use of a nearest neighbor (NN) classi er coupled with a distance function, such as, dynamic time warping (DTW), shapelets .
\subsection{Medical Time Series Classification}
Time series classification is a crucial yet challenging problem in the field of data mining, as it involves identifying patterns in sequential data over time**Lin, "Multivariate Time Series"**. 
Medical time series, as a specialized form of time series data collected from human physiological signals, such as EEG**Friedman, "EEG Signal Processing"** and ECG**Coifman, "ECG Signal Processing"**, present unique challenges and opportunities**Brown, "Physiological Signals"**. Continuously analyzing medical time series, especially as new conditions or classes of data emerge, is essential for health monitoring**Kumar, "Health Monitoring"** and making informed medical decisions**Patil, "Medical Decisions"**, highlighting the importance of medical time series classification.
%This highlights the need for adaptive and scalable classification techniques that can keep up with evolving medical data streams. 

Traditionally, one of the most widely used approaches for medical time series classification has been the nearest neighbor (NN)**Cover, "Nearest Neighbor"** classifier, often combined with distance measures such as dynamic time warping (DTW)**Jelinek, "Dynamic Time Warping"** or shapelet-based methods**Keogh, "Shapelets"**. These techniques have demonstrated effectiveness in various applications due to their simplicity and interpretability. Later statistical models such as the autoregressive models**Box, "Autoregressive Models"** and Gaussian mixture models**Everitt, "Gaussian Mixture Models"** have been used to capture the medical time series.
In recent years, deep learning methods have significantly advanced the field of medical time series classification. For example, EEGNet**Weninger, "EEGNet"** introduced the use of depthwise and separable convolutions to develop a model specifically designed for EEG data, capturing essential EEG feature extraction techniques for brain-computer interfaces (BCI). COMET**Dong, "COMET"** proposed a hierarchical contrastive representation learning framework that is tailored to the unique characteristics of medical time series data. Medformer**Wu, "Medformer"** introduced a multi-granularity patching transformer architecture that addresses the specific challenges of medical time series classification, providing a specialized solution for capturing complex temporal patterns.

\vspace{-2.5mm}
\subsection{Graph Neural Networks for Time Series}
Graph neural networks (GNNs) have shown promising performance in time series analysis due to their ability to capture complex dependencies between time-series variables**Kipf, "Graph Convolutional Layers"**. By representing data as a graph, GNNs can effectively model relationships across different variables and time steps. %making them well-suited for applications where capturing both temporal and spatial dependencies is critical. 
Some GNN-based models, such as STGCN**Yu, "STGCN"** and DCRNN**Seo, "DCRNN"**, rely on a pre-defined graph structure, which is often unavailable or difficult to determine in many real-world scenarios. To address this limitation, recent research has focused on learning graph structures directly from the data, enabling automatic modeling of the topological relationships among variables. AGCRN**Wang, "AGCRN"** enhances graph convolutional networks through a data-adaptive graph generation module and a node-adaptive parameter learning module. MTGNN**Liu, "MTGNN"** introduces an effective approach to learn and exploit the inherent dependencies among variables. FourierGNN**Chen, "FourierGNN"** captures frequency domain spatial-temporal correlations.
More recent models have continued to push the boundaries of GNN-based time series analysis. RainDrop**Li, "RainDrop"** introduces a GNN framework designed to handle irregularly sampled and multivariate time series, learning the dynamics of sensors directly from observational data without requiring any prior knowledge of the relationships. SimTSC**Zha, "SimTSC"** presents a simple yet general framework that uses GNNs to model similarity information, which helps improve time series classification by leveraging similarity patterns across different time points and variables. MTS2Graph**Younis, "MTS2Graph"** offers a strategy by constructing a graph that captures the temporal relationships between extracted patterns at each layer of the network. 
%It proposes an effective merging strategy to aggregate these graphs into a unified representation, allowing for more comprehensive modeling of complex temporal dynamics in the data.
These methods underscore the development in GNN-based methods, highlighting their potential to revolutionize time series classification by effectively capturing complex dependencies and adapting to diverse scenarios.

%These advances in GNN-based time series analysis demonstrate the potential of adaptive graph learning techniques to overcome the limitations associated with traditional methods that rely on static or pre-defined graphs. By automatically discovering dynamic relationships within the data, these models provide more flexible and accurate solutions for time series classification, forecasting, and anomaly detection across various domains.

%RainDrop**Li, "RainDrop"** introduces a graph neural network that embeds irregularly sampled and multivariate time series while also learning the dynamics of sensors purely from observational data.
%SimTSC**Zha, "SimTSC"** proposes a simple and general framework that models similarity information with graph neural networks.
%MTS2Graph**Younis, "MTS2Graph"** constructs a graph that captures the temporal relationship between the extracted patterns for each layer and propose an effective merging strategy to aggregate those graphs into one.
%These advances in GNN-based time series analysis highlight the potential of adaptive graph learning techniques to overcome the limitations of traditional approaches that rely on static or pre-defined graphs.