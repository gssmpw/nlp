\vspace{-1.5mm}
\section{Experiments}
In this section, we perform extensively experiments with five real-world medical time series benchmarks to assess the performance of our proposed MedGNN.
% Multi-resolution Spatiotemporal Adaptive Graph Learning (MSAGL) framework. 
Furthermore, we conduct thorough analytical experiments and visualization studies concerning the different components of the MedGNN framework.



\vspace{-2mm}
\subsection{Experimental Settings}

% \paragraph{\textbf{Datasets.}} 
\subsubsection{Datasets}
We conduct empirical analyses on five representative medical datasets,
i.e., ADFD~\cite{miltiadous2023dataset}, APAVA~\cite{escudero2006analysis}, TDBRAIN~\cite{van2022two}, PTB~\cite{physiobank2000physionet}, and PTB-XL~\cite{wagner2020ptb}. 
These datasets include three EEG datasets and two ECG datasets.
The data preprocessing and train-validation-test split are following the previous work~\cite{wang2024medformer}.
For further details on the datasets, please refer to the Appendix~\ref{appendix_dataset}.
% For further details on the dataset, including information on the data, train-validation-test splits across various setups, and data preprocessing methods, please refer to the Appendix~\ref{}.


% \paragraph{\textbf{Baselines.}} 
\subsubsection{Baselines}
We compare our proposed MedGNN with the representative and state-of-the-art models for time series classification. 
We choose the baseline methods from two categories: (1) GNN-based models, which include TodyNet~\cite{liu2024todynet}, SimTSC~\cite{zha2022towards}, FourierGNN~\cite{yi2024fouriergnn}, and CrossGNN~\cite{huang2023crossgnn}; (2) Transformer-based models, including iTransformer~\cite{liu2023itransformer}, PatchTST~\cite{nie2022time}, FEDformer~\cite{zhou2022fedformer}, Crossformer~\cite{zhang2022crossformer}, Autoformer~\cite{wu2021autoformer} and more recent Medformer~\cite{wang2024medformer}. Further details about the baselines can be found in Appendix \ref{appendix_baseline}.


% \paragraph{\textbf{Implementation Details.}} 
\subsubsection{Implementation Details}
All experiments are implemented using Pytorch 2.2~\cite{paszke2019pytorch} and conducted on 4 GeForce RTX 4090 GPUs. We employ cross-entropy loss as the loss function and present five metrics: accuracy, precision, recall, F1 score, and AUROC. Further implementation details are presented in Appendix \ref{appendix_evaluation_metrics} and \ref{appendix_implementation}.

\input{tables/Abla_differential}


\vspace{-1mm}
\subsection{Main Results}
We present results of our proposed MedGNN compared to several representative baselines with two different experimental setup (e.g., sample-based and subject-based evaluation) in Tables~\ref{tab:sub-dep} and \ref{tab:sub-indep}.
Note that the percentage symbol (\%) is omitted in the experimental results, and this will not be repeated below.

\subsubsection{Sample-based Evaluation}
In this setup, the training, validation, and test sets are divided based on test samples. Samples from different subjects are randomly shuffled and then assigned to the corresponding sets. It is a reasonable setting in real-world medical scenarios because many patients return for multiple visits even though it might have the information leakage problem from the perspective deep learning. Since this setting is easier than the subject-based evaluation, we only assess the ADFD dataset to enable a simple comparison for reference. Table \ref{tab:sub-dep} has shown the overall results sample-based evaluation of MedGNN compared with several baseline algorithms. We can easily observe that our proposed MedGNN outperforms all the baselines as illustrated in and achieves the best performance in five different metrics. %Also, we notice that Medformer can achieve very good performances but our MedGNN can still outperform it.


% from Medformer
% In this setup, the training, validation, and test sets are split based on samples. All samples from all subjects are randomly shuffled and distributed into the training, validation, and test sets according to a predetermined ratio, allowing samples from the same subject to appear in three sets simultaneously. As discussed in the Preliminaries section 3, this setup has limited applicability for medical time-series-based disease diagnosis in real-world scenarios. However, it can be utilized to evaluate whether the dataset exhibits cross-subject features quickly. The results obtained from this setup are typically much higher than those from the subject-independent setup, showing a dataset’s upper limit of learnability.

\vspace{-1mm}
\subsubsection{Subject-based Evaluation} The training, validation, and test sets are split based on subjects (patients) under this setup. Each subject, along with their corresponding samples, is assigned to one of the three sets (training, validation, or test) according to a predefined ratio or subject IDs. This ensures that samples from the same subject only appear in one set, preventing overlap between the sets.
Table \ref{tab:sub-indep} presents the results on five datasets under the subject-based setup. Overall, our model achieves leading perfomance on most datasets, achieving 22 top-1 and 2 top-2 out of 25 in total across five datasets. 
% Notably, MSAGL ranks first in terms of F1 score across all five datasets, indicating that MSAGL is not only accurate but also achieves a good balance between precision and recall. 
Notably, MedGNN ranks first in terms of F1 score across all five datasets, demonstrating that MedGNN is not only accurate but also achieves a good balance between precision and recall, indicating its exceptional robustness in handling classification tasks.
This balance is particularly important in critical applications such as medical diagnosis, where both false positives (misclassifying healthy individuals as sick) and false negatives (misclassifying sick individuals as healthy) can have serious consequences.

\begin{figure}[!t]
    \vspace{-2mm}
    \centering
    \subfigure[ADFD-Subject]
    {
        \centering
        \includegraphics[width=0.46\linewidth]{figures/Abl_GNN_ADFD_Indep_v2.pdf}
    }
    \subfigure[APAVA-Subject]
    {
        \centering
        \includegraphics[width=0.46\linewidth]{figures/Abl_GNN_APAVA_Indep_v2.pdf}
    }
    \vspace{-5mm}
    \caption{Ablation study of Multi-Resolution Graph Learning (MRGL) under the Subject-based setup.}
    \label{fig:abl_GNN}
    \vspace{-5mm}
\end{figure}

% \subsection{Model Analysis}
\vspace{-2mm}
\subsection{Ablation Studies}
% We analyze the effectiveness of three key components of MSAGL 
% We conduct experiments to delve into a thorough exploration of our proposed MSAGL, including their modeling capabilities, comparisons among different types of frequency filters, and the various factors impacting their performance.



% \paragraph{\textbf{Multi-Resolution Graph Transformer.}}
% \paragraph{\textbf{Multi-Resolution Graph Learning Study.}} 
\subsubsection{Study of the Multi-Resolution Graph Learning}
We explore the impact of multi-resolution graph learning (MRGL) on MedGNN's performance across various metrics. To assess its effectiveness, we compare two versions of the model: one with MRGL enabled and one without it. 
% As shown in Figure \ref{fig:abl_GNN}, with the inclusion of MRGL, the average improvement in classification results across the experimental datasets is as follows: Accuracy by 9.32\%, Precision by 8.65\%, Recall by 12.78\%, F1 Score by 12.23\%, and AUROC by 9.08\%.
The MRGL-enhanced version demonstrates substantial performance gains as shown in Figure \ref{fig:abl_GNN}, particularly in recall and F1 score, indicating the model's improved ability to detect and balance positive predictions with accurate classifications. This improvement highlights MRGL's capacity to capture multi-resolution dependencies effectively, improving the model's robustness in handling complex medical time series.



% \paragraph{\textbf{Frequency Learning Study.}}
\subsubsection{Study of the Frequency Convolution Networks.} 
% Frequency domain techniques benefit from the global perspective and energy compression properties of the Fourier transform, enabling the model to efficiently capture long-term dependencies. 
% We conduct ablation experiments on the role of Frequency Convolution Block (FCB) within MSAGL, as shown in Figure \ref{fig:abl_FCB}, where w/o FCB refers to the version without FCB. Clearly, the inclusion of FCB enhances MSAGL's performance across all metrics on the experimental datasets.
%Frequency domain techniques leverage the global perspective and energy compression properties of the Fourier transform, enabling models to efficiently capture long-term dependencies. 
To evaluate the impact of the Frequency Convolution Networks (FCN) within MedGNN, we perform ablation experiments, as shown in Figure \ref{fig:abl_FL}, where "w/o FCN" denotes the version without FCN. The results clearly demonstrate that incorporating FCN improves MedGNN’s performance across all metrics on the experimental datasets. Moreover, frequency convolution helps prevent potential information loss from relying solely on difference attention, further enhancing the temporal representation.


\begin{figure}[!t]
    \vspace{-4mm}
    \centering
    \subfigure[TDBRAIN-Subject]
    {
        \centering
        \includegraphics[width=0.32\linewidth]{figures/Abla_TDBRAIN_Indep_FreqConv.pdf}
    }
    \hspace{-4mm}
    \subfigure[ADFD-Subject]
    {
        \centering
        \includegraphics[width=0.32\linewidth]{figures/Abla_ADFD_Indep_FreqConv.pdf}
    }
    \hspace{-4mm}
    \subfigure[PTB-Subject]
    {
        \centering
        \includegraphics[width=0.32\linewidth]{figures/Abla_PTB_Indep_FreqConv.pdf}
    }
    \vspace{-4mm}
    \caption{Ablation study of Frequency Convolution Networks (FCN) under the Subject-based setup.}
    \label{fig:abl_FL}
    \vspace{-4mm}
\end{figure}


% \iffalse
%\paragraph{\textbf{Difference Attention Study.}} 
\subsubsection{Study of the Difference Attention Networks.} In this section, we aim to investigate the effectiveness of the difference attention in the MedGNN framework. Table \ref{tab:abl_differential} has shown the performance comparison of the variant on two EEG datasets (APAVA, TDBRAIN) and one ECG dataset. The version equipped with difference attention achieves improvements of 23.65\%, 27.02\%, 24.17\%, and 25.10\% in the metrics of Accuracy, Precision, Recall, and F1 score on EEG datasets in average, while 6.54\%, 10.35\%, 9.02\% , and 8.52\% respectively on ECG. 
% It demonstrates that difference attention can help the model focus on the sharp fluctuations that serve as the basis for disease diagnosis by eliminating common artifacts in medical time series, rather than wasting effort on slow fluctuations caused by incidental factors unrelated to the disease.
This indicates that difference attention can enhance the model's performance in medical time series classification tasks by minimizing the impact of slow baseline drifts and bringing important patterns to the forefront. %By focusing on differences within the temporal embeddings, the model more effectively captures relevant temporal dynamics, while being less influenced by constant offsets or slow fluctuations. %, ultimately improving the analysis of temporal dynamics in medical time series.

% \fi


\begin{figure}[!h]
    \vspace{-3mm}
    \centering
    \subfigure[APAVA-Subject]
    {
        \centering
        \includegraphics[width=0.45\linewidth]{figures/Efficiency_APAVA.pdf}
    }
    \subfigure[TDBRAIN-Subject]
    {
        \centering
        \includegraphics[width=0.45\linewidth]{figures/Efficiency_TDBRAIN.pdf}
    }
    \vspace{-4mm}
    \caption{Model effectiveness and efficiency comparison on two datasets under the Subject-based setup.}
    \label{fig:efficiency}
    \vspace{-4mm}
\end{figure}

\vspace{-1mm}
\subsection{Additional Experiments}


\begin{figure*}[!h]
    \vspace{-2mm}
    \centering
    \subfigure[resolution=2]
    {
        \centering
        \includegraphics[width=0.235\linewidth]{figures/APAVA-Indep_0.pdf}
    }
    \subfigure[resolution=4]
    {
        \centering
        \includegraphics[width=0.235\linewidth]{figures/APAVA-Indep_1.pdf}
    }
    \subfigure[resolution=6]
    {
        \centering
        \includegraphics[width=0.235\linewidth]{figures/APAVA-Indep_2.pdf}
    }
    \subfigure[resolution=8]
    {
        \centering
        \includegraphics[width=0.235\linewidth]{figures/APAVA-Indep_3.pdf}
    }
    \vspace{-4.5mm}
    \caption{Adjacent matrices of multi-resolution graphs learned from APAVA dataset.}
    \label{fig:Adj_APAVA}
    \vspace{-3mm}
\end{figure*}



\begin{figure*}[!h]
    \vspace{-3mm}
    \centering
    \subfigure[resolution=2]
    {
        \centering
        \includegraphics[width=0.187\linewidth]{figures/TDBRAIN-Indep_0.pdf}
    }
    \subfigure[resolution=4]
    {
        \centering
        \includegraphics[width=0.187\linewidth]{figures/TDBRAIN-Indep_1.pdf}
    }
    \subfigure[resolution=6]
    {
        \centering
        \includegraphics[width=0.187\linewidth]{figures/TDBRAIN-Indep_2.pdf}
    }
    \subfigure[resolution=8]
    {
        \centering
        \includegraphics[width=0.187\linewidth]{figures/TDBRAIN-Indep_3.pdf}
    }
    \subfigure[resolution=10]
    {
        \centering
        \includegraphics[width=0.187\linewidth]{figures/TDBRAIN-Indep_4.pdf}
    }
    \vspace{-4.5mm}
    \caption{Adjacent matrices of multi-resolution graphs learned from TDBRAIN dataset.}
    \label{fig:Adj_TDBRAIN}
    \vspace{-3mm}
\end{figure*}


\begin{figure}[!h]
    \vspace{-3mm}
    \centering
    \subfigure[APAVA-Subject]
    {
        \centering
        \includegraphics[width=0.47\linewidth]{figures/APAVA_res_nums.pdf}
    }
    \subfigure[TDBRAIN-Subject]
    {
        \centering
        \includegraphics[width=0.47\linewidth]{figures/PTB_res_nums.pdf}
    }
    \vspace{-4.5mm}
    \caption{Effect of different numbers of resolutions.}
    \label{fig:parameter_res_nums}
    \vspace{-5mm}
\end{figure}

\subsubsection{Efficiency Analysis}
We comprehensively evaluate the model efficiency from three aspects: classification performance (Accuracy), training speed, and memory footprint. Specifically, we choose two different sizes of datasets: the APAVA (23 subjects, 5,967 16-channel samples) and TDBRAIN (72 subjects, 6,240 33-channel samples) datasets. The closer a marker is to the upper-left corner of Figure \ref{fig:efficiency}, the higher the model's accuracy and the faster its training speed. Additionally, the smaller the marker’s area, the lower the memory usage during training. Therefore, we can conclude that although MedGNN's training time and memory footprint are at a moderate level among all baselines, its classification performance is the best. %Moreover, when compared specifically with other GNN-based models, MedGNN takes the lead in all three aspects.


\subsubsection{Visualizations}
Figures \ref{fig:Adj_APAVA} and Figure \ref{fig:Adj_TDBRAIN} present visualizations of the learned adjacency matrices across different resolutions, providing insights into what the model captures at each resolution. Overall, the matrices tend to be sparse, indicating that MedGNN focuses on learning meaningful correlations from the data rather than relying on superficial variable aggregation. We also find that the weight distributions of adjacency matrices vary across different resolutions within the same dataset, indicating that the relationships between variables learned through graph learning differ at each resolution. This is significant for practical applications, as the relationships between variables are often not fixed but instead vary depending on the scale or context.



%\subsection{Parameter Sensitivity Analysis}
% \paragraph{\textbf{Numbers of Resolutions.}} 
\subsubsection{Study of Numbers of Resolutions}
Figure \ref{fig:parameter_res_nums} shows the effect of the number of resolutions on classification performance. It suggests that appropriately increasing the number of resolutions has the potential to improve performance across various metrics. However, introducing overly coarse resolutions, where the receptive field becomes too large, may harm performance because excessive aggregation can lead to the loss of important fine-grained information and reduce the model's ability to capture subtle but critical patterns.


\begin{figure}[!t]
    \vspace{-4mm}
    \centering
    \subfigure[PTB-Subject]
    {
        \centering
        \includegraphics[width=0.47\linewidth]{figures/PTB-Indep_node_dim.pdf}
    }
    \subfigure[APAVA-Subject]
    {
        \centering
        \includegraphics[width=0.47\linewidth]{figures/APAVA-Indep_node_dim.pdf}
    }
    \vspace{-4.5mm}
    \caption{Effect of different graph node dimension.}
    \label{fig:parameter_node_dim}
    \vspace{-5.5mm}
\end{figure}


% \paragraph{\textbf{Graph Node Dimension.}}
\subsubsection{Study of the Size of Graph Node Dimensions.} Figure \ref{fig:parameter_node_dim} displays the effect of different graph node dimensions in multi-resolution graph learning. It indicates that larger graph node dimensions do not necessarily lead to better performance. This is understandable given that we employ a multi-resolution graph learning strategy, meaning the learning burden at each resolution is relatively light, making smaller node dimensions sufficient. In contrast, larger graph node dimensions may introduce data sparsity issues and increase computational overhead, hindering the model's learning ability. %further hindering the model's ability to learn meaningful semantic embeddings efficiently.



