% \clearpage
\appendix
\section{Experimental Details}

\subsection{Datasets}\label{appendix_dataset}
The ADFD~\cite{miltiadous2023dataset} dataset includes 88 subjects and contains 69,762 multivariate EEG samples, each recorded from 19 channels. Every sample represents a one-second time sequence with 256 time points, captured at a sampling rate of 256Hz. Each sample is labeled with one of three classes, indicating whether the subject is Healthy, has Dementia, or has Alzheimer's disease.
The APAVA~\cite{escudero2006analysis} dataset includes 23 subjects and contains 5,967 multivariate EEG samples, each recorded across 16 channels. Each sample represents a one-second time sequence with 256 time points, recorded at a sampling rate of 256Hz. Every sample is accompanied by a binary label indicating whether the subject has been diagnosed with Alzheimer’s disease. 
The TDBRAIN~\cite{van2022two} dataset consists of 72 subjects and provides 6,240 EEG samples, each recorded across 33 channels. These samples represent one-second time sequences, containing 256 data points, recorded at a frequency of 256Hz. Each sample is tagged with a binary label that indicates whether the subject has Parkinson's disease. 
The PTB~\cite{physiobank2000physionet} dataset consists of 198 subjects and includes 64,356 multivariate ECG samples, each recorded across 15 channels. Each sample corresponds to a heartbeat represented by 300 time points, recorded at a sampling rate of 250Hz. A binary label accompanies each sample, indicating whether the subject has experienced a Myocardial Infarction.
The PTB-XL~\cite{wagner2020ptb} dataset comprises 17,596 subjects and includes 191,400 multivariate ECG samples, each recorded across 12 channels. Each sample represents a one-second time sequence with 250 time points, captured at a sampling rate of 250Hz. Each sample is labeled with one of five classes, representing different heart conditions.

\subsection{Baselines}\label{appendix_baseline}
We choose ten well-acknowledged and state-of-the-art models for comparison to evaluate the effectiveness of our proposed MedGNN for medical time series classification, including GNN-based models and Transformer-based models. We introduce these models as follows:

Medformer~\cite{wang2024medformer} introduces three innovative mechanisms to utilize the distinctive properties of medical time series. These include cross-channel patching for learning multi-timestamp and multi-channel features, multi-granularity embedding for capturing features at various scales, and a two-stage multi-granularity self-attention mechanism to capture features both within and across granularities. The official implementation is available at \url{https://github.com/DL4mHealth/Medformer}.

iTransformer~\cite{liu2023itransformer} reverses the structure of the Transformer by encoding individual series into variate tokens, allowing the attention mechanism to capture multivariate correlations, while applying feed-forward networks to each token for nonlinear representation learning. The official implementation is available at this repository: \url{https://github.com/thuml/iTransformer}.

PatchTST~\cite{nie2022time} segments time series into subseries-level patches, which serve as input tokens to the Transformer. These patch tokens replace traditional attention tokens, and a channel-independent structure further boosts efficiency. The official implementation is available at this repository: \url{https://github.com/yuqinie98/PatchTST}.

FEDformer~\cite{zhou2022fedformer} utilizes sparse attention with low-rank approximation in the frequency domain, achieving linear computational complexity and memory efficiency. It also introduces a mixture of expert decomposition to manage distribution shifts in time series~\cite{fan2023Dish}. The official implementation is available at this repository: \url{https://github.com/MAZiqing/FEDformer}.

Crossformer~\cite{zhang2022crossformer} embeds input data into a 2D vector array using Dimension-Segment-Wise embedding to retain time and dimension information, and employs a Two-Stage Attention layer to capture cross-time and cross-dimension dependencies efficiently. The official implementation is available at this repository: \url{https://github.com/Thinklab-SJTU/Crossformer}.

Autoformer~\cite{wu2021autoformer} uses an auto-correlation mechanism instead of self-attention and incorporates a decomposition block to separate trend and seasonal components, enhancing learning. The official implementation is available at this repository: \url{https://github.com/thuml/Autoformer}.

FourierGNN~\cite{yi2024fouriergnn} introduces a hypervariate graph, treating each series value as a node and representing sliding windows as space-time fully-connected graphs. It stacks Fourier Graph Operators (FGO) for matrix multiplications in Fourier space, providing high expressiveness with reduced complexity for efficient modeling. The official implementation is available at this repository: \url{https://github.com/aikunyi/FourierGNN}.

CrossGNN~\cite{huang2023crossgnn} refines both cross-scale and cross-variable interaction for multivariate time series with a linear complexity. Cross-scale GNN captures the scales with clearer trend and weaker noise, while cross-variable GNN maximally exploits the homogeneity and heterogeneity between different variables. The official implementation is available at this repository: \url{https://github.com/hqh0728/CrossGNN}.

TodyNet~\cite{liu2024todynet} captures hidden spatiotemporal dependencies without relying on a predefined graph structure. It introduces a temporal graph pooling layer to generate a global graph-level representation, leveraging learnable temporal parameters for graph learning. The official implementation is available at this repository: \url{https://github.com/liuxz1011/TodyNet}.

SimTSC~\cite{zha2022towards} frames time series classification (TSC) as a node classification problem on graphs. It introduces a graph construction strategy and a batch training algorithm with negative sampling to enhance training efficiency. The official implementation is available at this repository: \url{https://github.com/daochenzha/SimTSC}.


\subsection{Evaluation metrics}\label{appendix_evaluation_metrics}
To comprehensively and fairly evaluate the performance of each model in the classification task, we select five evaluation metrics: Accuracy, Precision, Recall, F1 score, and AUROC. The definitions and specific calculation formulas for each metric are presented below:

Accuracy measures the proportion of correct predictions out of the total number of predictions. It's calculated as:
\begin{equation}
    \text { Accuracy }=\frac{\text { Number of correct predictions }}{\text { Total number of predictions }}.
\end{equation}
This metric is useful when the classes are balanced but may be misleading in cases of class imbalance.

Precision focuses on the quality of positive predictions and measures the proportion of correctly predicted positive instances out of all instances predicted as positive. It’s especially useful when false positives need to be minimized. The formula is: 
\begin{equation}
    \text { Precision }=\frac{\text { True Positives }}{\text { True Positives }+ \text { False Positives }}.
\end{equation}

Recall measures the proportion of actual positive instances that were correctly identified. It’s important when false negatives are costly. The formula is:
\begin{equation}
    \text { Recall }=\frac{\text { True Positives }}{\text { True Positives }+ \text { False Negatives }}.
\end{equation}
It shows how well the model captures all relevant instances.

The F1 score is the harmonic mean of precision and recall, balancing the two when one is more important than the other. It’s particularly useful when dealing with imbalanced datasets, as it accounts for both false positives and false negatives. The formula is:
\begin{equation}
    \text { F1 Score }=2 \times \frac{\text { Precision } \times \text { Recall }}{\text { Precision }+ \text { Recall }}.
\end{equation}
It gives a single metric that reflects both precision and recall performance.

AUROC measures the model’s ability to distinguish between classes, regardless of the decision threshold. The ROC curve plots the true positive rate (recall) against the false positive rate (FPR), and AUROC is the area under this curve. A value of 1 indicates perfect classification, while 0.5 represents random guessing. It is a useful metric when the dataset is imbalanced and provides insight into how well the model separates the classes.

\subsection{Implementation Details}\label{appendix_implementation}
We follow the same data processing and train-validation-test set split protocol employed in Medformer~\cite{medformer_2024}. All the experiments are implemented in PyTorch 2.2.2~\cite{paszke2019pytorch} and conducted on a server equipped with four GeForce RTX 4090 GPUs, each with 24GB of memory. We utilize
ADAM~\cite{kingma2014adam} optimizer with an uniform initial learning rate $lr = 10^{-4}$ and cross-entropy loss for the model optimization. The batch size is selected from $\left\{32, 64, 128, 256\right\}$ and the number of training epochs is fixed to 10. We choose a subset from $\left\{2, 4, 6, 8, 10, 12, 14, 16\right\}$ as the multiple resolutions. The number of EncoderLayer $L$ is selected from $ \left\{4, 6\right\}$ and the dimension of embedding D is set from $\left\{256, 512\right\}$. And the graph node dimension is picked from $\left\{ 6, 8, 10\right\}$. We also report the standard deviation of MedGNN’s performance over five runs with different seeds, as shown in Table \ref{tab:sub-dep} and \ref{tab:sub-indep}, demonstrating the stability of its performance.
