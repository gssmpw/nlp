\vspace{-1mm}
\section{Methodology}
To address the aforementioned challenges of medical time series classification, in this section, we elaborate on our proposed \textit{MedGNN}, a Multi-resolution Spatiotemporal Graph Learning framework.
The overall architecture of MedGNN is illustrated in Figure \ref{fig:framework}. It mainly consists of multi-resolution graph construction, difference attention networks, frequency convolution networks and multi-resolution graph transformer. For the medical time series, multi-resolution graph construction is utilized to learn the dynamic spatiotemporal representations, and then difference attention networks and frequency convolution networks are designed to capture the comprehensive temporal dynamics. Finally, multi-resolution graph transformer is employed to model the dynamic spatial dependencies from different resolutions.
In the following, %we first present an overview of this framework and how it works with the specific learning procedure in Section \ref{sec:overview}, and subsequently  
we elaborate on the core components of MedGNN from Section \ref{sec:1} to Section \ref{sec:4}.%, respectively.
%we elaborate on the three four components of the framework, including multi-resolution data transformation in Section \ref{sec:1}, difference attention learning in Section \ref{sec:2}, multi-review frequency learning in Section \ref{sec:3}, and multi-resolution graph transformer in Section \ref{sec:4}.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.94\linewidth]{figures/framework_v5.pdf}
    \vspace{-2mm}
    \caption{The overall architecture of MedGNN. (a) Multi-resolution graph construction is utilized to learn the dynamic spatiotemporal representations. (b) Frequency convolution networks are applied to provide a multi-view perspective of the temporal dynamics by applying convolutions in the frequency domain. (c) Difference attention networks are employed to capture key temporal patterns while mitigating the impact of baseline wander. (d) Multi-resolution graph transformer is leveraged to model the dynamic spatial dependencies and and fuse the information from different resolutions.}
    \label{fig:framework}
    \vspace{-2mm}
\end{figure*}

% \vspace{-2mm}
% \subsection{Overview}\label{sec:overview}
% The overall architecture of MedGNN is illustrated in Figure \ref{fig:framework}. It mainly consists of multi-resolution graph construction, difference attention networks, frequency convolution networks and multi-resolution graph transformer. For the medical time series, multi-resolution graph construction is utilized to learn the dynamic spatiotemporal representations, and then difference attention networks and frequency convolution networks are designed to capture the comprehensive temporal dynamics. Finally, multi-resolution graph transformer is employed to model the dynamic spatial dependencies from different resolutions.

\vspace{-2mm}
\subsection{Multi-resolution Graph Construction with Multi-scale Embedding Learning}\label{sec:1}

Medical time series typically consist of multiple channels that are often closely correlated. For example, in EEG signals, different brain regions may exhibit synchronization patterns, indicating real functional connectivity in the brain~\cite{teplan2002fundamentals}; in ECG signals, different leads can provide complementary information about the cardiac electrical activity~\cite{berkaya2018survey}. This motivates us to construct explicit structures to model channel-level dynamics and temporal dynamics for medical time series. To this end, we propose a novel Multi-resolution Adaptive Graph Structure Learning approach to model different levels of dynamics. This approach mainly consists of two main steps: 1) learning multi-resolution embeddings, and 2) constructing multi-resolution graphs based on the learned embeddings. 
%using 2D convolution networks with different kernel sizes
\subsubsection{Multi-scale Embedding Learning}
Given a medical time series sample $\mathbf{X}^{i}_{P_n} \in \mathbb{R}^{T \times C}$, we aim to learn multi-scale temporal embeddings that capture the local patterns and dynamics at different time scales. To achieve this, we employ a set of 1-\textit{d} convolution networks for different resolutions. Let ${\mathbf{K}_1, \cdots, \mathbf{K}_M}$ denote a series of $M$ kernel sizes, where each kernel $\mathbf{K}_m \in \mathbb{R}^{k_m \times 1}$ has a size of $k_m$ along the time dimension for different channels.
The multi-scale embeddings are obtained by applying the 1-\textit{d} convolution operations with different kernel sizes, formally by:
\begin{equation}
\mathbf{Z}^{i (m)} = \text{Conv1D}(\mathbf{X}^{i}_{P_n}, \mathbf{K}_m), \quad m = 1, \cdots, M,
\end{equation}
where $\mathbf{Z}^{i (m)} \in \mathbb{R}^{T_m \times C}$ represents the learned embeddings at the $m$-th resolution for $i$-th sample where we drop $P_n$ for brevity, $T_m = [T / k_m]$ is the size of transformed temporal embeddings, and $C$ is the number of  channels.

\subsubsection{Multi-resolution Graph Construction}
After obtaining the multi-resolution embeddings, we then aim to construct  multi-resolution graphs for structure learning. Specifically,  we create a series graphs $\{\mathcal{G}^{i (1)}, \cdots, \mathcal{G}^{i (M)}\}$, where each graph $\mathcal{G}^{i (m)} = ({A}^{i(m)}, {X}^{i(m)})$ initialized as a fully-connected graph corresponds to a specific resolution.  ${A}^{i(m)} \in \mathbb{R}^{C*C} $ represents the adjacency matrix, 
and for each graph $\mathcal{G}^{i(m)}$, the node set $\mathcal{V}^{i(m)}$ consists of $C$ nodes, where each node $v^{i(m)}_c \in \mathcal{V}^{i(m)}$ corresponds to a channel in the original series. The node feature matrix ${X}^{i(m)} \in \mathbb{R}^{C \times T_m}$ is formed by the learned embeddings at the $m$-th resolution:
\begin{equation}
{X}^{i(m)} = (\mathbf{Z}^{i (m)})^{\top}.
\end{equation}
The edge set $\mathcal{E}^{i(m)}$ represents the dependencies and correlations among the channels. We initialize the adjacency matrix ${A}^{i(m)} \in \mathbb{R}^{C \times C}$ as a learnable matrix to capture the edge weights between pairs of nodes. The edge weights can be learned adaptively to reflect the dynamic channel correlations at different resolutions.


By constructing multi-resolution graphs, we could obtain a hierarchical representation that captures both channel-level and temporal dynamics at different time scales for the medical time series. This rich representation allows for modeling the complex local and longer contextual spatiotemporal patterns in medical time series.

\vspace{-2mm}
\subsection{Difference Attention Networks for the Baseline Wander in Temporal Dynamics}\label{sec:2}
For the physiological time series in the medical domain, the baseline wander~\cite{MoyYSAA21} - the constant offsets or slow drifts towards baseline measurements - is a common artifact in ECG and EEG recordings. This could make the model capture the less meaningful patterns, i.e., the slow fluctuations around the baseline that may be caused by  accidental factors such as patient movement or respiration. To address this problem, we further propose a new architecture, Difference Attention Networks, to learn the temporal dynamics of medical time series in a more focused fashion. The basic idea is to incorporate the concept of \textit{finite difference} into the attention mechanisms. Note that the difference operates on the temporal dimension  of the input data. 

Specifically, instead of directly applying self-attention to the node features, we compute the differences along the temporal dimension and apply self-attention to these differences.
We first add paddings to the temporal embedding dimensions to get ${X'}^{i(m)} \in \mathbb{R}^{C \times T_m+1}$ obtained from the adaptive graph learning module at the $m$-th resolution, we first compute the first-order finite difference along the temporal dimension:
\begin{equation}
{D}^{i(m)}{(t)} = {X'}^{i(m)}{(t+1)} - {X'}^{i(m)}{(t)}, \quad t = 1, \cdots, T_m,
\end{equation}
where ${D}^{i(m)} \in \mathbb{R}^{C}$ represents the first-order difference of series representation at time step $t$, and ${X'}^{i(m)}{(t)}$ represents the value of ${X'}^{i(m)}$ at $t$.
We then apply the multi-head self-attention mechanism to the difference representations ${D}^{i(m)}$ to learn the temporal dependencies. The self-attention is calculated as:
\begin{equation}
{Attn}^{i(m)} = \text{Softmax}\left(\frac{ {D}^{i(m)} W ^{i(m)}_Q ( {D}^{i(m)} W ^{i(m)}_K )^{\top}}{\sqrt{d}}\right) {D}^{i(m)} W ^{i(m)}_V, 
\end{equation}
where $W^{i(m)}_Q, W^{i(m)}_K$ are learnable weight matrices for queries and keys.
% The final outputs of difference attention networks are as:
The outputs of difference self-attention are as:
\begin{equation}
 {X}^{i(m)}_{DSA} = \text{DifferenceAttention}({X}^{i(m)}) =  Linear_{DA}( {Attn}^{i(m)}  ),
\end{equation}
where $Linear_{DA}(\cdot)$ represents the final linear layers for output, and $W^{i(m)}_V$ are learnable weight matrices for values in self-attention.
The final outputs of Difference Attention Networks are formed as:
\begin{equation}
    {X}^{i(m)}_{DA} = {X}^{i(m)}_{DSA} + {X'}^{i(m)}.
\end{equation}
%By applying the Difference Attention Networks to each multi-resolution graph, we obtain node features that capture the temporal dynamics of the medical time series at different resolutions while mitigating the impact of baseline wander. These features can be further processed and integrated with the adaptive graph learning modules.
The Difference Attention Networks provide a novel way to focus on the temporal changes in medical time series, reducing the influence of slow baseline drifts and highlighting the meaningful patterns. 
%By operating on the differences along the temporal embeddings, the model can better capture the relevant temporal dynamics while being less sensitive to constant offsets or slow fluctuations, to enhance the modeling of temporal dynamics in medical time series analysis.

\vspace{-2mm}
\subsection{Frequency Convolution Networks for the Multi-view Temporal Representations}\label{sec:3}

Though the difference attention network can help address the baseline wander problem, the processed representations are in the ``difference space'' and it might lose some information in the original data space. To better capture the multi-view information of medical time series signals, we further introduce the frequency convolution networks to enhance the temporal representations~\cite{yi2024frequency,fan2024deep,kunyi_2023survey,fan2022depts}. Note that the temporal convolution networks are operated in parallel with Difference Attention Networks for multi-view information. 

Specifically, given the node feature matrix ${X}^{i(m)} \in \mathbb{R}^{C \times T_m}$ obtained from the multi-resolution graph construction at the $m$-th resolution, we first apply the Fourier transform to convert the temporal signals from the time domain to the frequency domain:
\begin{equation}
\mathcal{X}^{i(m)} = \mathcal{F}({X}^{i(m)}) = \int_{-\infty}^{\infty} {X}^{i(m)}(t) e^{-j2\pi ft} \mathrm{d}t,
\end{equation}
where $\mathcal{F}$ denotes the Fourier transform, $f$ is the frequency variable, $t$ is the integral variable, and $j$ is the imaginary unit. The resulting $\mathcal{X}^{i(m)} \in \mathbb{C}^{C \times S}$ represents the frequency domain representation, where $S$ is the number of frequency components.
Next, we apply Fourier convolution layers to the frequency domain representations to capture the dependencies and patterns in the frequency space:
\begin{equation}
\mathcal{H}^{i(m)} = \text{FourierConvolution}(\mathcal{X}^{i(m)}) = \mathcal{X}^{i(m)} \odot \mathcal{W}^{i(m)},
\end{equation}
where $\mathcal{W}^{i(m)} \in \mathbb{C}^{C \times S}$ represents the learnable convolution kernels in the frequency domain, and $\odot$ denotes the element-wise multiplication.
The resulting $\mathcal{H}^{i(m)} \in \mathbb{C}^{C \times S}$ represents the convolved frequency domain representations.
Finally, we apply the inverse Fourier transform to recover the temporal representations from the frequency domain back to the time domain:
\begin{equation}
{X}^{i(m)}_{FC} = \mathcal{F}^{-1}(\mathcal{H}^{i(m)}) = \int_{-\infty}^{\infty} \mathcal{H}^{i(m)}(f) e^{j2\pi ft} \mathrm{d}f,
\end{equation}
where $\mathcal{F}^{-1}$ denotes the inverse Fourier transform, and ${X}^{i(m)}_{FC} \in \mathbb{R}^{C \times T_m}$ represents the recovered temporal representations.
The frequency convolution networks provide a complementary view of the temporal dynamics by operating in the frequency domain. 
%By applying Fourier convolutions, the model can capture frequency-specific patterns and dependencies that may be ignored in the time domain of EEG or ECG signals. 


\subsection{Learning Spatial Dynamics with Multi-resolution Graph Transformer}\label{sec:4}

% The recovered temporal representations ${H}^{i(m)}$ can be combined with the outputs of the Difference Attention Networks ${X}^{i(m)}_{DA}$ to obtain multi-view temporal representations:
% \begin{equation}
% {X}^{i(m)}{MV} = \text{Concat}({X}^{i(m)}{DA}, {H}^{i(m)}),
% \end{equation}
% where $\text{Concat}$ denotes the concatenation operation along the feature dimension, and ${X}^{i(m)}_{MV} $ represents the multi-view temporal representations at the $m$-th resolution.
% By incorporating the frequency convolution networks in parallel with the Difference Attention Networks, the proposed approach can capture both the temporal dynamics in the difference space and the frequency-specific patterns in the original data space. This multi-view learning enhances the representational power of the model and allows for a more comprehensive understanding of the complex temporal patterns in medical time series.

After obtaining the temporal representations from the Difference Attention Networks ${X}^{i(m)}_{DA}$ and the Frequency Convolution Networks ${X}^{i(m)}_{FC}$ at each resolution $m$, we aim to further capture the inter-series (spatial) dependencies based on the explicit structures of multi-resolution graphs. For this aim, we propose the multi-resolution graph transformer model for spatial dependency learning.
% Specifically, first, for each resolution, we fuse the two learned temporal representations ${X}^{i(m)}_{DA}$ and ${X}^{i(m)}_{FC}$ by mapping them together through linear layers:
% \begin{equation}
% {X}^{i(m)}_{fused} = {Linear}_{fusion}({X}^{i(m)}_{DA} + {X}^{i(m)}_{FC}),
% \end{equation}
% where ${Linear}_{fusion}$ are learnable linear layers that project and fuse the multi-veiw representations, and ${X}^{i(m)}_{fused} \in \mathbb{R}^{C \times T_m}$ represents the fused representations at the $m$-th resolution.
Specifically, first, for each resolution, we sum the two learned temporal representations ${X}^{i(m)}_{DA}$ and ${X}^{i(m)}_{FC}$ to obtain the fused multi-view representations at the $m$-th resolution:
\begin{equation}
{X}^{i(m)}_{fused} = {X}^{i(m)}_{DA} + {X}^{i(m)}_{FC}.
\end{equation}

\input{tables/Sub_Dep}
\input{tables/Sub_Indep}


Next, inspired by Graph Transformer~\cite{gt_survey}, we apply the local attention mechanisms first and then pass the representations to the graph neural networks for processing. Specifically,
the local attention for graph processing is first computed as:
\begin{equation}
    \alpha_{pq} = \frac{\exp(g(\mathbf{x}_p, \mathbf{x}_q) \cdot b_{pq})}{\sum_{k \in \mathcal{N}(v_p)}\exp(g(\mathbf{x}_p, \mathbf{x}_k) \cdot b_{pk})},
\end{equation}
where $\alpha_{pq}$ is the attention score, $x_p$ and $x_q$ are their node features, $g$ is a function that computes the similarity between two nodes, i.e., the dot-product. $b_{pq}$ is a local attention bias term. Note that the neighborhood is dynamically learned in Section \ref{sec:1}. Then we can calculate the graph representations by:
\begin{equation}
{X}^{i(m)}_{GA} = \text{LocalAttention}({X}^{i(m)}_{fused}) = \mathbf{\alpha} {X}^{i(m)}_{fused},
\end{equation}
where ${X}^{i(m)}_{GA} \in \mathbb{R}^{C \times T_m}$ represents the spatially attended representations. The multi-head self-attention allows the model to attend to different spatial locations and capture the dependencies among different time series channels.
After obtaining the spatially attended representations, we apply graph convolution networks to further incorporate the graph structure information at each resolution. Given the constructed graph $\mathcal{G}^{i(m)} = ({A}^{i(m)}, {X}^{i(m)}_{GA})$ at the $m$-th resolution, we perform graph convolution as follows:
% \begin{equation}
% {X}^{i(m)}_{GT} = \text{ReLU}(\hat{{A}}^{i(m)} {X}^{i(m)}_{GA} {W}^{i(m)}_{GT}),
% \end{equation}
\begin{equation}
{X}^{i(m)}_{GT} = \text{GraphConv}(\hat{{A}}^{i(m)},  {X}^{i(m)}_{GA}, {W}^{i(m)}_{GT}),
\end{equation}
where $\hat{{A}}^{i(m)} = \tilde{{D}}^{-\frac{1}{2}} \tilde{{A}}^{i(m)} \tilde{{D}}^{-\frac{1}{2}}$ is the normalized adjacency matrix, $\tilde{{A}}^{i(m)} = {A}^{i(m)} + {I}$ is the adjacency matrix with self-loops, ${I}$ is the identity matrix, $\tilde{{D}}$ is the diagonal degree matrix of $\tilde{{A}}^{i(m)}$, ${W}^{i(m)}_{GT} \in \mathbb{R}^{T_m \times T_m}$ is the learnable weight matrix for graph convolution.
% , \textcolor{red}{and $\text{ReLU}(\cdot)$ is the rectified linear unit activation function. }
The resulting ${X}^{i(m)}_{GT} \in \mathbb{R}^{C \times T_m}$ represents the graph convoluted representations at the $m$-th resolution.
Since we have multiple resolutions, we need to fuse the representations obtained from different resolutions to capture the multi-resolution dynamics. We achieve this by applying average pooling  across the resolution dimension:
\begin{equation}
{X}^{i}_{MRFused} = \text{AvgPool}({{X}^{i(1)}_{GT}, \ldots, {X}^{i(M)}_{GT}}),
\end{equation}
where $\text{AvgPool}(\cdot)$ denotes the average pooling operation, and the output ${X}^{i}_{MRFused} \in \mathbb{R}^{C \times T}$ represents the fused multi-resolution representations.
Finally, we feed the fused multi-resolution representations ${X}^{i}_{MRFused}$ into a linear or fully-connected layer followed by a softmax activation function for classification:
\begin{equation}
\hat{{y}}^{i} = \text{Softmax}(\text{Linear}_{GT}({X}^{i}_{MRFused})),
\end{equation}
where $\text{Linear}_{GT}(\cdot)$ is a learnable linear layer that maps the fused representations to the output space, and $\hat{{y}}^{i} \in \mathbb{R}^{K}$ represents the predicted probabilities for the $K$ classes.
%By integrating graph convolution and spatial attention mechanisms, the proposed approach can effectively capture the multi-resolution dynamics and spatial dependencies in medical time series. The graph convolution operation allows the model to incorporate the graph structure information and learn the interactions among different time series channels, while the spatial attention mechanism enables the model to focus on the most relevant spatial locations and capture the inter-series dependencies. The fusion of representations from multiple resolutions provides a comprehensive understanding of the temporal and spatial patterns at different scales, leading to improved classification performance.

\iffalse
\subsection{Adaptive Graph Learning}
With the constructed multi-resolution graphs, we employ graph neural networks (GNNs) to learn the adaptive graph structures and update the node representations. Specifically, for each graph $\mathcal{G}^{i(m)}$, we apply a graph convolution operation followed by a gating mechanism to update the node features and adjacency matrix:
\begin{align}
\mathbf{H}^{i(m)} &= \text{ReLU}(\mathbf{A}^{i(m)} \mathbf{X}^{i(m)} \mathbf{W}^{(m)}), \
\mathbf{G}^{i(m)} &= \text{Sigmoid}(\mathbf{A}^{i(m)} \mathbf{X}^{i(m)} \mathbf{U}^{(m)}), \
\mathbf{X}^{i(m)}{new} &= \mathbf{G}^{i(m)} \odot \mathbf{H}^{i(m)} + (1 - \mathbf{G}^{i(m)}) \odot \mathbf{X}^{i(m)}, \
\mathbf{A}^{i(m)}{new} &= \text{Softmax}(\mathbf{H}^{i(m)} (\mathbf{H}^{i(m)})^{\top}),
\end{align}
where $\mathbf{W}^{(m)} \in \mathbb{R}^{T_m \times D}$ and $\mathbf{U}^{(m)} \in \mathbb{R}^{T_m \times D}$ are learnable weight matrices, $D$ is the hidden dimension, $\odot$ denotes element-wise multiplication, and $\text{Softmax}(\cdot)$ is applied row-wise to obtain a normalized adjacency matrix.
The gating mechanism allows the model to adaptively combine the learned node representations $\mathbf{H}^{i(m)}$ with the original node features $\mathbf{X}^{i(m)}$, enabling the model to retain relevant information from previous layers. The updated adjacency matrix $\mathbf{A}^{i(m)}_{new}$ captures the dynamic correlations among the channels based on the learned node representations.
By applying the adaptive graph learning module to each multi-resolution graph, we obtain updated node representations and adjacency matrices that encode the spatiotemporal dynamics at different time scales:
\begin{equation}
{\mathbf{X}^{i(1)}{new}, \mathbf{A}^{i(1)}{new}, \cdots, \mathbf{X}^{i(M)}{new}, \mathbf{A}^{i(M)}{new}} = \text{AdaptiveGraphLearning}({\mathcal{G}^{i(1)}, \cdots, \mathcal{G}^{i(M)}}).
\end{equation}
These updated representations can be further processed using pooling or readout operations to obtain a compact representation for each resolution. The representations from different resolutions can be concatenated or fused to form a final feature vector for downstream tasks, such as classification or prediction.
\subsection{Model Training and Inference}
The proposed Multi-resolution Adaptive Graph Structure Learning approach can be integrated into various deep learning architectures for medical time series analysis. The model parameters, including the convolution kernels, graph learning modules, and downstream layers, can be learned through end-to-end training using standard optimization techniques and suitable loss functions based on the specific task.
During inference, given a new medical time series sample, the trained model can generate multi-resolution embeddings, construct the corresponding graphs, and perform adaptive graph learning to obtain the final representation. This representation can be used for various downstream tasks, such as disease diagnosis or patient stratification.
The proposed approach provides a powerful framework for modeling the complex spatiotemporal dynamics in medical time series data by learning adaptive graph structures at multiple resolutions. It captures the channel-level correlations and temporal dependencies, enabling effective representation learning and predictive modeling in various medical domains.
\fi