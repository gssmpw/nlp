@inproceedings{agrawal-etal-2023-multimodal,
    title = "Multimodal Persona Based Generation of Comic Dialogs",
    author = "Agrawal, Harsh  and
      Mishra, Aditya  and
      Gupta, Manish  and
      Mausam",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.791/",
    doi = "10.18653/v1/2023.acl-long.791",
    pages = "14150--14164",
    abstract = "We focus on the novel problem of persona based dialogue generation for comic strips. Dialogs in comic strips is a unique and unexplored area where every strip contains utterances from various characters with each one building upon the previous utterances and the associated visual scene. Previous works like DialoGPT, PersonaGPT and other dialog generation models encode two-party dialogues and do not account for the visual information. To the best of our knowledge we are the first to propose the paradigm of multimodal persona based dialogue generation. We contribute a novel dataset, ComSet, consisting of 54K strips, harvested from 13 popular comics available online. Further, we propose a multimodal persona-based architecture, MPDialog, to generate dialogues for the next panel in the strip which decreases the perplexity score by {\textasciitilde}10 points over strong dialogue generation baseline models. We demonstrate that there is still ample opportunity for improvement, highlighting the importance of building stronger dialogue systems that are able to generate persona-consistent dialogues and understand the context through various modalities."
}

@inproceedings{ahn-etal-2023-mpchat,
    title = "{MPCHAT}: Towards Multimodal Persona-Grounded Conversation",
    author = "Ahn, Jaewoo  and
      Song, Yeda  and
      Yun, Sangdoo  and
      Kim, Gunhee",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.189/",
    doi = "10.18653/v1/2023.acl-long.189",
    pages = "3354--3377",
    abstract = "In order to build self-consistent personalized dialogue agents, previous research has mostly focused on textual persona that delivers personal facts or personalities. However, to fully describe the multi-faceted nature of persona, image modality can help better reveal the speaker`s personal characteristics and experiences in episodic memory (Rubin et al., 2003; Conway, 2009). In this work, we extend persona-based dialogue to the multimodal domain and make two main contributions. First, we present the first multimodal persona-based dialogue dataset named MPCHAT, which extends persona with both text and images to contain episodic memories. Second, we empirically show that incorporating multimodal persona, as measured by three proposed multimodal persona-grounded dialogue tasks (i.e., next response prediction, grounding persona prediction, and speaker identification), leads to statistically significant performance improvements across all tasks. Thus, our work highlights that multimodal persona is crucial for improving multimodal dialogue comprehension, and our MPCHAT serves as a high-quality resource for this research."
}

@inproceedings{chen-etal-2023-large,
    title = "Large Language Models Meet Harry Potter: A Dataset for Aligning Dialogue Agents with Characters",
    author = "Chen, Nuo  and
      Wang, Yan  and
      Jiang, Haiyun  and
      Cai, Deng  and
      Li, Yuhan  and
      Chen, Ziyang  and
      Wang, Longyue  and
      Li, Jia",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.570/",
    doi = "10.18653/v1/2023.findings-emnlp.570",
    pages = "8506--8520",
    abstract = "In recent years, Dialogue-style Large Language Models (LLMs) such as ChatGPT and GPT4 have demonstrated immense potential in constructing open-domain dialogue agents. However, aligning these agents with specific characters or individuals remains a considerable challenge due to the complexities of character representation and the lack of comprehensive annotations. In this paper, we introduce the Harry Potter Dialogue (HPD) dataset, designed to advance the study of dialogue agents and character alignment. The dataset encompasses all dialogue sessions (in both English and Chinese) from the Harry Potter series and is annotated with vital background information, including dialogue scenes, speakers, character relationships, and attributes. These extensive annotations may empower LLMs to unlock character-driven dialogue capabilities. Furthermore, it can serve as a universal benchmark for evaluating how well can a LLM aligning with a specific character. We benchmark LLMs on HPD using both fine-tuning and in-context learning settings. Evaluation results reveal that although there is substantial room for improvement in generating high-quality, character-aligned responses, the proposed dataset is valuable in guiding models toward responses that better align with the character of Harry Potter."
}

@article{chen2024persona,
  title={From persona to personalization: A survey on role-playing language agents},
  author={Chen, Jiangjie and Wang, Xintao and Xu, Rui and Yuan, Siyu and Zhang, Yikai and Shi, Wei and Xie, Jian and Li, Shuang and Yang, Ruihan and Zhu, Tinghui and others},
  journal={arXiv preprint arXiv:2404.18231},
  year={2024}
}

@article{chen2024roleinteract,
  title={RoleInteract: Evaluating the Social Interaction of Role-Playing Agents},
  author={Chen, Hongzhan and Chen, Hehong and Yan, Ming and Xu, Wenshen and Gao, Xing and Shen, Weizhou and Quan, Xiaojun and Li, Chenliang and Zhang, Ji and Huang, Fei and others},
  journal={arXiv preprint arXiv:2403.13679},
  year={2024}
}

@article{dai2024mmrole,
  title={Mmrole: A comprehensive framework for developing and evaluating multimodal role-playing agents},
  author={Dai, Yanqi and Hu, Huanran and Wang, Lei and Jin, Shengjie and Chen, Xu and Lu, Zhiwu},
  journal={arXiv preprint arXiv:2408.04203},
  year={2024}
}

@inproceedings{gao-etal-2023-livechat,
    title = "{L}ive{C}hat: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming",
    author = "Gao, Jingsheng  and
      Lian, Yixin  and
      Zhou, Ziyi  and
      Fu, Yuzhuo  and
      Wang, Baoyuan",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.858/",
    doi = "10.18653/v1/2023.acl-long.858",
    pages = "15387--15405",
    abstract = "Open-domain dialogue systems have made promising progress in recent years. While the state-of-the-art dialogue agents are built upon large-scale social media data and large pre-trained models, there is no guarantee these agents could also perform well in fast-growing scenarios, such as live streaming, due to the bounded transferability of pre-trained models and biased distributions of public datasets from Reddit and Weibo, etc. To improve the essential capability of responding and establish a benchmark in the live open-domain scenario, we introduce the LiveChat dataset, composed of 1.33 million real-life Chinese dialogues with almost 3800 average sessions across 351 personas and fine-grained profiles for each persona. LiveChat is automatically constructed by processing numerous live videos on the Internet and naturally falls within the scope of multi-party conversations, where the issues of Who says What to Whom should be considered. Therefore, we target two critical tasks of response modeling and addressee recognition and propose retrieval-based baselines grounded on advanced techniques. Experimental results have validated the positive effects of leveraging persona profiles and larger average sessions per persona. In addition, we also benchmark the transferability of advanced generation-based models on LiveChat and pose some future directions for current challenges."
}

@article{ge2024scaling,
  title={Scaling synthetic data creation with 1,000,000,000 personas},
  author={Ge, Tao and Chan, Xin and Wang, Xiaoyang and Yu, Dian and Mi, Haitao and Yu, Dong},
  journal={arXiv preprint arXiv:2406.20094},
  year={2024}
}

@article{li2021dialogue,
  title={Dialogue history matters! personalized response selection in multi-turn retrieval-based chatbots},
  author={Li, Juntao and Liu, Chang and Tao, Chongyang and Chan, Zhangming and Zhao, Dongyan and Zhang, Min and Yan, Rui},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={39},
  number={4},
  pages={1--25},
  year={2021},
  publisher={ACM New York, NY}
}

@article{li2023chatharuhi,
  title={Chatharuhi: Reviving anime character in reality via large language model},
  author={Li, Cheng and Leng, Ziang and Yan, Chenxi and Shen, Junyi and Wang, Hao and Mi, Weishi and Fei, Yaying and Feng, Xiaoyang and Yan, Song and Wang, HaoSheng and others},
  journal={arXiv preprint arXiv:2308.09597},
  year={2023}
}

@inproceedings{lu-etal-2024-large,
    title = "Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment",
    author = "Lu, Keming  and
      Yu, Bowen  and
      Zhou, Chang  and
      Zhou, Jingren",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.423/",
    doi = "10.18653/v1/2024.acl-long.423",
    pages = "7828--7840",
    abstract = "Considerable efforts have been invested in augmenting the role-playing proficiency of open-source large language models (LLMs) by emulating proprietary counterparts. Nevertheless, we posit that LLMs inherently harbor role-play capabilities, owing to the extensive knowledge of characters and potential dialogues ingrained in their vast training corpora. Thus, we introduce Ditto, the first self-alignment method for role-play, which encourages an instruction-following LLM to simulate role-play dialogues as a variant of reading comprehension, and creates a role-play training set comprising 4000 characters, surpassing the scale of currently available datasets by tenfold regarding the number of roles. Subsequently, we fine-tune the LLM using this self-generated dataset to augment its role-playing capabilities. Upon evaluating our meticulously constructed role-play benchmark and the roleplay subset of MT-Bench, Ditto, in various parameter scales, consistently maintains a consistent role identity and provides accurate role-specific knowledge in multi-turn role-play conversations, outperforming all open-source role-play baselines. Furthermore, we present the first cross-supervision role-play experiment, revealing that the role-play styles can be easily acquired, while the intrinsic capabilities of LLMs confine the knowledge within role-play."
}

@article{openai2023gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{shao2023character,
  title={Character-llm: A trainable agent for role-playing},
  author={Shao, Yunfan and Li, Linyang and Dai, Junqi and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2310.10158},
  year={2023}
}

@article{shen2023roleeval,
  title={Roleeval: A bilingual role evaluation benchmark for large language models},
  author={Shen, Tianhao and Li, Sun and Tu, Quan and Xiong, Deyi},
  journal={arXiv preprint arXiv:2312.16132},
  year={2023}
}

@article{tu2024charactereval,
  title={Charactereval: A chinese benchmark for role-playing conversational agent evaluation},
  author={Tu, Quan and Fan, Shilong and Tian, Zihang and Yan, Rui},
  journal={arXiv preprint arXiv:2401.01275},
  year={2024}
}

@article{wang2023rolellm,
  title={Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models},
  author={Wang, Zekun Moore and Peng, Zhongyuan and Que, Haoran and Liu, Jiaheng and Zhou, Wangchunshu and Wu, Yuhan and Guo, Hongcheng and Gan, Ruitong and Ni, Zehao and Yang, Jian and others},
  journal={arXiv preprint arXiv:2310.00746},
  year={2023}
}

@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhou2023characterglm,
  title={Characterglm: Customizing chinese conversational ai characters with large language models},
  author={Zhou, Jinfeng and Chen, Zhuang and Wan, Dazhen and Wen, Bosi and Song, Yi and Yu, Jifan and Huang, Yongkang and Peng, Libiao and Yang, Jiaming and Xiao, Xiyao and others},
  journal={arXiv preprint arXiv:2311.16832},
  year={2023}
}

