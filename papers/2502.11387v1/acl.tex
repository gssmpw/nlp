% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{bm}
\usepackage{pifont}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{multirow} 
\usepackage{color}
\DeclareMathOperator*{\argmax}{argmax}
\usepackage{newfloat}
\usepackage{listings}
\usepackage{enumitem} % Make sure this package is included

\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{multirow}

\usepackage[most]{tcolorbox}
\usepackage{fontawesome5}
\definecolor{yellow}{HTML}{F6BD60}
\usepackage{multicol}

\definecolor{lightgreen}{rgb}{0.55, 0.71, 0.0}
\definecolor{bisque}{rgb}{0.87, 0.72, 0.53}
\definecolor{lightyellow}{rgb}{0.99, 0.76, 0.0}
\definecolor{lightblue}{rgb}{0.36, 0.54, 0.66}
\definecolor{darkgray}{rgb}{0.66, 0.66, 0.66}
\definecolor{salmon}{rgb}{0.98, 0.50, 0.45}
\definecolor{deeppurple}{rgb}{0.4, 0.0, 0.4}


\definecolor{yellow}{HTML}{F6BD60}
\definecolor{white}{HTML}{FFE0C1}
\definecolor{pink}{HTML}{F5CAC3}
\definecolor{tale}{HTML}{84A59D}
\definecolor{red}{HTML}{F28080}
\definecolor{orange}{HTML}{FF7F00}
\definecolor{green1}{HTML}{72C3A3}
\definecolor{green2}{HTML}{70B48F}
\definecolor{orange}{HTML}{FE8019}
\definecolor{grey}{HTML}{EBDBB2}
\definecolor{brain}{HTML}{FFABBE}
\definecolor{blue}{HTML}{A3B7CA}
\definecolor{purple}{HTML}{5861AC}
\definecolor{narrative}{HTML}{458588}
\definecolor{white2}{HTML}{F8F5E9}
% \definecolor{tablewhite}{HTML}{E4E0E1}
\definecolor{tablewhite}{HTML}{E5E1DA}
\definecolor{verylightgrey}{HTML}{CDCDCD}

% NOTE: custom command
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\newcommand{\tabopenai}[1]{\colorbox{green1}{#1}}
\newcommand{\tabroleplay}[1]{\colorbox{red}{#1}}
\newcommand{\tabllama}[1]{\colorbox{blue}{#1}}
\newcommand{\tabqwen}[1]{\colorbox{purple}{#1}}


\usepackage[switch]{lineno}

\linespread{0.98}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

% \title{Invisible Alignment Tax of Human Preference Optimization for LLMs: Deteriorated Multi-turn Instruction-following Capacity}

\title{RoleMRC: A Fine-Grained Composite Benchmark for Role-Playing and Instruction-Following}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{\makecell{Junru Lu$^{1*}$, Jiazheng Li$^2$\thanks{Equal Contribution.}, Guodong Shen$^3$, Lin Gui$^2$, Siyu An$^1$, Yulan He$^{2,3,4}$, Di Yin$^1$, Xing Sun$^1$} \\
  $^1$Tencent YouTu Lab\quad\quad $^2$King's College London \\$^3$University of Warwick\quad\quad $^4$The Alan Turing Institute\\
  \texttt{\{junrulu, siyuan, endymecyyin, winfredsun\}@tencent.com}\\
  \texttt{guodong.shen@warwick.ac.uk}, \texttt{\{jiazheng.li, lin.gui, yulan.he\}@kcl.ac.uk}}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
Role-playing is important for Large Language Models (LLMs) to follow diverse instructions while maintaining role identity and the role's pre-defined ability limits. %: LLMs should respond correctly, and highlight the role characteristics, while not exceeding the role's ability boundaries. The 
Existing role-playing datasets mostly contribute to controlling role style and knowledge boundaries, but overlook role-playing in instruction-following scenarios. %For the first time, 
We introduce a fine-grained role-playing and instruction-following composite benchmark, named RoleMRC, including: (1) Multi-turn dialogues between ideal roles and humans, including free chats or discussions upon given passages; (2) Role-playing machine reading comprehension, involving response, refusal, and attempts according to passage answerability and role ability; (3) More complex scenarios with nested, multi-turn and prioritized instructions. % by further enriching the system prompts or appending new questions based on (2). 
The final RoleMRC features a 10.2k role profile meta-pool, 37.9k well-synthesized role-playing instructions, and 1.4k testing samples. We develop a pipeline to quantitatively evaluate the fine-grained role-playing and instruction-following capabilities of several mainstream LLMs, as well as models that are fine-tuned on our data. %from their base versions. 
Moreover, cross-evaluation on external role-playing datasets confirms that models fine-tuned on RoleMRC enhances instruction-following without compromising general role-playing and reasoning capabilities. We also probe the neural-level activation maps of different capabilities over post-tuned LLMs
\footnote{Access to our RoleMRC, RoleMRC-mix and Codes: \url{https://github.com/LuJunru/RoleMRC}.}.
\end{abstract}

\input{1_introduction}
\input{2_related_work}
\input{3_methodology}
\input{4_experiments}
\input{5_interpretability}

\section{Conclusion}
\label{sec:conclusion}
We introduce RoleMRC, a large-scale fine-grained benchmark designed to improve and evaluate the role-playing and instruction-following abilities of LLMs. RoleMRC uniquely integrates role-specific multi-turn dialogues, MRC, and complex instruction-following scenarios. Experiments show that RoleMRC-aligned models outperform existing baselines in both reference-based and reference-free evaluations, and also perform well on both OOD role-playing and general-purpose benchmarks. We further conduct a neuron-level analysis to identify specific neurons with significant activation changes and apply targeted constraints to alleviate the alignment tax, thereby improving evaluation metrics without additional retraining.

\clearpage
\section*{Limitations}
\label{sec:limit}
While RoleMRC significantly enhances the role-playing and instruction-following capabilities of LLMs, some limitations remain:
\begin{itemize}[leftmargin=*,noitemsep,topsep=0pt]
    \item While the role profiles in the dataset are diverse, system-level prompts used in the synthesized instructions are somewhat similar, which may limit the generalizability of downstream models.
    \item The reliance on synthetic data generated by models such as gpt-4o may introduce biases inherent in these models, affecting the performance and fairness of fine-tuned LLMs.
    \item While effective, mitigating the ``alignment tax'' on multi-turn instruction-following through neuron-level constraints may have a negative impact on other capabilities, suggesting that further interpretability research is needed.
\end{itemize}

\section*{Ethics Statement}
The RoleMRC dataset is constructed with a strong commitment to ethical AI. The dataset does not contain any personal, sensitive, or identifiable information. Additionally, all role-playing interactions are designed to be safe and free from harmful, offensive, or misleading content. The dataset strictly adheres to responsible AI guidelines by avoiding the generation or reinforcement of biased, discriminatory, or deceptive narratives. %Furthermore, RoleMRC’s role-playing and instruction-following tasks are developed with controlled ability boundaries to prevent the promotion of misinformation or unethical behaviors.

\section*{Acknowledgment}
This work was supported by Tencent YouTu Lab and King's College London (KCL). The data team of Tencent supported the batch requesting of gpt-4o during data synthesis, and the e-Research team of KCL supported the resources of model training upon the CREATE platform\,\cite{server}.

\bibliography{acl}

\appendix
% \setcounter{table}{0}
% \renewcommand{\thetable}{A\arabic{table}}
% \setcounter{figure}{0}
% \renewcommand{\thefigure}{A\arabic{figure}}

\input{6_appendix}

\end{document}
