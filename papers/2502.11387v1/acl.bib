% InstructGPT
@inproceedings{ouyang2022training,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      booktitle={Thirty-Sixth Conference on Neural Information Processing Systems},
      year={2022}
}

% DPO
@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

%IPO
@article{azar2023general,
  title={A general theoretical paradigm to understand learning from human preferences},
  author={Azar, Mohammad Gheshlaghi and Rowland, Mark and Piot, Bilal and Guo, Daniel and Calandriello, Daniele and Valko, Michal and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:2310.12036},
  year={2023}
}

%Hinge DPO
@article{zhao2023slic,
  title={Slic-hf: Sequence likelihood calibration with human feedback},
  author={Zhao, Yao and Joshi, Rishabh and Liu, Tianqi and Khalman, Misha and Saleh, Mohammad and Liu, Peter J},
  journal={arXiv preprint arXiv:2305.10425},
  year={2023}
}

%KTO
@article{ethayarajh2024kto,
  title={KTO: Model Alignment as Prospect Theoretic Optimization},
  author={Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe},
  journal={arXiv preprint arXiv:2402.01306},
  year={2024}
}

% bco
@article{jung2024binary,
  title={Binary Classifier Optimization for Large Language Model Alignment},
  author={Jung, Seungjae and Han, Gunsoo and Nam, Daniel Wontae and On, Kyoung-Woon},
  journal={arXiv preprint arXiv:2404.04656},
  year={2024}
}

% orpo
@article{hong2024reference,
  title={Reference-free monolithic preference optimization with odds ratio},
  author={Hong, Jiwoo and Lee, Noah and Thorne, James},
  journal={arXiv preprint arXiv:2403.07691},
  year={2024}
}

% GPT4
@article{openai2023gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

% deepseek
@article{bi2024deepseek,
  title={Deepseek llm: Scaling open-source language models with longtermism},
  author={Bi, Xiao and Chen, Deli and Chen, Guanting and Chen, Shanhuang and Dai, Damai and Deng, Chengqi and Ding, Honghui and Dong, Kai and Du, Qiushi and Fu, Zhe and others},
  journal={arXiv preprint arXiv:2401.02954},
  year={2024}
}

% qwen
@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

% llama3
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

% sampo
@inproceedings{sampo,
    title = "Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled {KL} Divergence",
    author = "Lu, Junru  and
      Li, Jiazheng  and
      An, Siyu  and
      Zhao, Meng  and
      He, Yulan  and
      Yin, Di  and
      Sun, Xing",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    year = "2024",
    url = "https://aclanthology.org/2024.emnlp-main.60",
}

% Alignment Tax 1
@article{lin2023speciality,
  title={Speciality vs generality: An empirical study on catastrophic forgetting in fine-tuning foundation models},
  author={Lin, Yong and Tan, Lu and Lin, Hangyu and Zheng, Zeming and Pi, Renjie and Zhang, Jipeng and Diao, Shizhe and Wang, Haoxiang and Zhao, Han and Yao, Yuan and others},
  journal={arXiv preprint arXiv:2309.06256},
  year={2023}
}

% Alignment Tax 2
@article{li2024multi,
  title={Multi-modal preference alignment remedies regression of visual instruction tuning on language model},
  author={Li, Shengzhi and Lin, Rongyu and Pei, Shichao},
  journal={arXiv preprint arXiv:2402.10884},
  year={2024}
}

% SQuAD
@article{rajpurkar2018know,
  title={Know what you don't know: Unanswerable questions for SQuAD},
  author={Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
  journal={arXiv preprint arXiv:1806.03822},
  year={2018}
}

% DROP
@article{dua2019drop,
  title={DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs},
  author={Dua, Dheeru and Wang, Yizhong and Dasigi, Pradeep and Stanovsky, Gabriel and Singh, Sameer and Gardner, Matt},
  journal={arXiv preprint arXiv:1903.00161},
  year={2019}
}

% HellaSwag
@article{zellers2019hellaswag,
  title={Hellaswag: Can a machine really finish your sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  journal={arXiv preprint arXiv:1905.07830},
  year={2019}
}

% WMT15
@inproceedings{bojar-etal-2015-findings,
    title = "Findings of the 2015 Workshop on Statistical Machine Translation",
    author = "Bojar, Ond{\v{r}}ej  and
      Chatterjee, Rajen  and
      Federmann, Christian  and
      Haddow, Barry  and
      Huck, Matthias  and
      Hokamp, Chris  and
      Koehn, Philipp  and
      Logacheva, Varvara  and
      Monz, Christof  and
      Negri, Matteo  and
      Post, Matt  and
      Scarton, Carolina  and
      Specia, Lucia  and
      Turchi, Marco",
    editor = "Bojar, Ond{\v{r}}ej  and
      Chatterjee, Rajan  and
      Federmann, Christian  and
      Haddow, Barry  and
      Hokamp, Chris  and
      Huck, Matthias  and
      Logacheva, Varvara  and
      Pecina, Pavel",
    booktitle = "Proceedings of the Tenth Workshop on Statistical Machine Translation",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W15-3001/",
    doi = "10.18653/v1/W15-3001",
    pages = "1--46"
}

% ARC-E/C
@article{clark2018think,
  title={Think you have solved question answering? try arc, the ai2 reasoning challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal={arXiv preprint arXiv:1803.05457},
  year={2018}
}

% RACE
@article{lai2017race,
  title={Race: Large-scale reading comprehension dataset from examinations},
  author={Lai, Guokun and Xie, Qizhe and Liu, Hanxiao and Yang, Yiming and Hovy, Eduard},
  journal={arXiv preprint arXiv:1704.04683},
  year={2017}
}

% PIQA
@inproceedings{bisk2020piqa,
  title={Piqa: Reasoning about physical commonsense in natural language},
  author={Bisk, Yonatan and Zellers, Rowan and Gao, Jianfeng and Choi, Yejin and others},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  pages={7432--7439},
  year={2020}
}

% WMT14
@inproceedings{bojar2014findings,
  title={Findings of the 2014 workshop on statistical machine translation},
  author={Bojar, Ond{\v{r}}ej and Buck, Christian and Federmann, Christian and Haddow, Barry and Koehn, Philipp and Leveling, Johannes and Monz, Christof and Pecina, Pavel and Post, Matt and Saint-Amand, Herve and others},
  booktitle={Proceedings of the ninth workshop on statistical machine translation},
  pages={12--58},
  year={2014}
}

% Simpo
@article{meng2024simpo,
  title={Simpo: Simple preference optimization with a reference-free reward},
  author={Meng, Yu and Xia, Mengzhou and Chen, Danqi},
  journal={arXiv preprint arXiv:2405.14734},
  year={2024}
}

% mmlu
@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

% gsm8k
@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

% deepseek r1
@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

% kimi 1.5
@article{team2025kimi,
  title={Kimi k1. 5: Scaling Reinforcement Learning with LLMs},
  author={Team, Kimi and Du, Angang and Gao, Bofei and Xing, Bowei and Jiang, Changjiu and Chen, Cheng and Li, Cheng and Xiao, Chenjun and Du, Chenzhuang and Liao, Chonghua and others},
  journal={arXiv preprint arXiv:2501.12599},
  year={2025}
}

% narrative play eacl
@inproceedings{narrativeplay_eacl,
    title = "{N}arrative{P}lay: Interactive Narrative Understanding",
    author = "Zhao, Runcong  and
      Zhang, Wenjia  and
      Li, Jiazheng  and
      Zhu, Lixing  and
      Li, Yanran  and
      He, Yulan  and
      Gui, Lin",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations",
    year = "2024",
    url = "https://aclanthology.org/2024.eacl-demo.10/"
}

% narrative play aaai
@article{narrativeplay_aaai, 
    title={NarrativePlay: An Automated System for Crafting Visual Worlds in Novels for Role-Playing}, 
    url={https://ojs.aaai.org/index.php/AAAI/article/view/30589}, 
    journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
    author={Zhao, Runcong and Zhang, Wenjia and Li, Jiazheng and Zhu, Lixing and Li, Yanran and He, Yulan and Gui, Lin}, 
    year={2024}, 
}

% role-play survey 1
@article{chen2024persona,
  title={From persona to personalization: A survey on role-playing language agents},
  author={Chen, Jiangjie and Wang, Xintao and Xu, Rui and Yuan, Siyu and Zhang, Yikai and Shi, Wei and Xie, Jian and Li, Shuang and Yang, Ruihan and Zhu, Tinghui and others},
  journal={arXiv preprint arXiv:2404.18231},
  year={2024}
}

% role-play survey 2
@article{chen2024oscars,
  title={The oscars of ai theater: A survey on role-playing with language models},
  author={Chen, Nuo and Wang, Yan and Deng, Yang and Li, Jia},
  journal={arXiv preprint arXiv:2407.11484},
  year={2024}
}

% role-play survey 3
@inproceedings{tseng-etal-2024-two,
    title = "Two Tales of Persona in {LLM}s: A Survey of Role-Playing and Personalization",
    author = "Tseng, Yu-Min  and
      Huang, Yu-Chao  and
      Hsiao, Teng-Yun  and
      Chen, Wei-Lin  and
      Huang, Chao-Wei  and
      Meng, Yu  and
      Chen, Yun-Nung",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.969/",
    doi = "10.18653/v1/2024.findings-emnlp.969",
    pages = "16612--16631",
    abstract = "The concept of *persona*, originally adopted in dialogue literature, has re-surged as a promising framework for tailoring large language models (LLMs) to specific context (*e.g.*, personalized search, LLM-as-a-judge). However, the growing research on leveraging persona in LLMs is relatively disorganized and lacks a systematic taxonomy. To close the gap, we present a comprehensive survey to categorize the current state of the field. We identify two lines of research, namely (1) *LLM Role-Playing*, where personas are assigned to LLMs, and (2) *LLM Personalization*, where LLMs take care of user personas. Additionally, we introduce existing methods for LLM personality evaluation. To the best of our knowledge, we present the first survey for role-playing and personalization in LLMs under the unified view of persona. We continuously maintain a paper collection to foster future endeavors."
}

% Refusal
@article{liu2024tell,
  title={Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing},
  author={Liu, Wenhao and An, Siyu and Lu, Junru and Wu, Muling and Li, Tianlong and Wang, Xiaohua and Zheng, Xiaoqing and Yin, Di and Sun, Xing and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2409.16913},
  year={2024}
}

% rpa 1: video assistant
@inproceedings{lei-etal-2022-assistsr,
    title = "{A}ssist{SR}: Task-oriented Video Segment Retrieval for Personal {AI} Assistant",
    author = "Lei, Weixian  and
      Gao, Difei  and
      Wang, Yuxuan  and
      Mao, Dongxing  and
      Liang, Zihan  and
      Ran, Lingmin  and
      Shou, Mike Zheng",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.24/",
    doi = "10.18653/v1/2022.findings-emnlp.24",
    pages = "319--338",
    abstract = "It is still a pipe dream that personal AI assistants on the phone and AR glasses can assist our daily life in addressing our questions like {\textquotedblleft}how to adjust the date for this watch?{\textquotedblright} and {\textquotedblleft}how to set its heating duration? (while pointing at an oven){\textquotedblright}. The queries used in conventional tasks (i.e. Video Question Answering, Video Retrieval, Moment Localization) are often factoid and based on pure text. In contrast, we present a new task called Task-oriented Question-driven Video Segment Retrieval (TQVSR). Each of our questions is an image-box-text query that focuses on affordance of items in our daily life and expects relevant answer segments to be retrieved from a corpus of instructional video-transcript segments. To support the study of this TQVSR task, we construct a new dataset called AssistSR. We design novel guidelines to create high-quality samples. This dataset contains 3.2k multimodal questions on 1.6k video segments from instructional videos on diverse daily-used items. To address TQVSR, we develop a simple yet effective model called Dual Multimodal Encoders (DME) that significantly outperforms several baseline methods while still having large room for improvement in the future. Moreover, we present detailed ablation analyses. Code and data are available at https://github.com/StanLei52/TQVSR."
}

% rpa2: human behaviors
@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th annual acm symposium on user interface software and technology},
  pages={1--22},
  year={2023}
}

% rp3: drama
@article{chen2024hollmwood,
  title={HoLLMwood: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing},
  author={Chen, Jing and Zhu, Xinyu and Yang, Cheng and Shi, Chufan and Xi, Yadong and Zhang, Yuxiang and Wang, Junjie and Pu, Jiashu and Zhang, Rongsheng and Yang, Yujiu and others},
  journal={arXiv preprint arXiv:2406.11683},
  year={2024}
}

% less is more
@article{zhong2022less,
  title={Less is more: Learning to refine dialogue history for personalized dialogue generation},
  author={Zhong, Hanxun and Dou, Zhicheng and Zhu, Yutao and Qian, Hongjin and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2204.08128},
  year={2022}
}

% memochat
@article{lu2023memochat,
  title={Memochat: Tuning llms to use memos for consistent long-range open-domain conversation},
  author={Lu, Junru and An, Siyu and Lin, Mingbao and Pergola, Gabriele and He, Yulan and Yin, Di and Sun, Xing and Wu, Yunsheng},
  journal={arXiv preprint arXiv:2308.08239},
  year={2023}
}

% chatharuhi
@article{li2023chatharuhi,
  title={Chatharuhi: Reviving anime character in reality via large language model},
  author={Li, Cheng and Leng, Ziang and Yan, Chenxi and Shen, Junyi and Wang, Hao and Mi, Weishi and Fei, Yaying and Feng, Xiaoyang and Yan, Song and Wang, HaoSheng and others},
  journal={arXiv preprint arXiv:2308.09597},
  year={2023}
}

% rpa: social
@article{xu2024character,
  title={Character is Destiny: Can Large Language Models Simulate Persona-Driven Decisions in Role-Playing?},
  author={Xu, Rui and Wang, Xintao and Chen, Jiangjie and Yuan, Siyu and Yuan, Xinfeng and Liang, Jiaqing and Chen, Zulong and Dong, Xiaoqing and Xiao, Yanghua},
  journal={arXiv preprint arXiv:2404.12138},
  year={2024}
}

% rpa: comic
@inproceedings{agrawal-etal-2023-multimodal,
    title = "Multimodal Persona Based Generation of Comic Dialogs",
    author = "Agrawal, Harsh  and
      Mishra, Aditya  and
      Gupta, Manish  and
      Mausam",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.791/",
    doi = "10.18653/v1/2023.acl-long.791",
    pages = "14150--14164",
    abstract = "We focus on the novel problem of persona based dialogue generation for comic strips. Dialogs in comic strips is a unique and unexplored area where every strip contains utterances from various characters with each one building upon the previous utterances and the associated visual scene. Previous works like DialoGPT, PersonaGPT and other dialog generation models encode two-party dialogues and do not account for the visual information. To the best of our knowledge we are the first to propose the paradigm of multimodal persona based dialogue generation. We contribute a novel dataset, ComSet, consisting of 54K strips, harvested from 13 popular comics available online. Further, we propose a multimodal persona-based architecture, MPDialog, to generate dialogues for the next panel in the strip which decreases the perplexity score by {\textasciitilde}10 points over strong dialogue generation baseline models. We demonstrate that there is still ample opportunity for improvement, highlighting the importance of building stronger dialogue systems that are able to generate persona-consistent dialogues and understand the context through various modalities."
}

% rpa: digital man
@article{tian2023chatplug,
  title={Chatplug: Open-domain generative dialogue system with internet-augmented instruction tuning for digital human},
  author={Tian, Junfeng and Chen, Hehong and Xu, Guohai and Yan, Ming and Gao, Xing and Zhang, Jianhai and Li, Chenliang and Liu, Jiayi and Xu, Wenshen and Xu, Haiyang and others},
  journal={arXiv preprint arXiv:2304.07849},
  year={2023}
}

% rolellm
@article{wang2023rolellm,
  title={Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models},
  author={Wang, Zekun Moore and Peng, Zhongyuan and Que, Haoran and Liu, Jiaheng and Zhou, Wangchunshu and Wu, Yuhan and Guo, Hongcheng and Gan, Ruitong and Ni, Zehao and Yang, Jian and others},
  journal={arXiv preprint arXiv:2310.00746},
  year={2023}
}

% characterLLM
@article{shao2023character,
  title={Character-llm: A trainable agent for role-playing},
  author={Shao, Yunfan and Li, Linyang and Dai, Junqi and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2310.10158},
  year={2023}
}

% characterglm
@article{zhou2023characterglm,
  title={Characterglm: Customizing chinese conversational ai characters with large language models},
  author={Zhou, Jinfeng and Chen, Zhuang and Wan, Dazhen and Wen, Bosi and Song, Yi and Yu, Jifan and Huang, Yongkang and Peng, Libiao and Yang, Jiaming and Xiao, Xiyao and others},
  journal={arXiv preprint arXiv:2311.16832},
  year={2023}
}

% charactereval
@article{tu2024charactereval,
  title={Charactereval: A chinese benchmark for role-playing conversational agent evaluation},
  author={Tu, Quan and Fan, Shilong and Tian, Zihang and Yan, Rui},
  journal={arXiv preprint arXiv:2401.01275},
  year={2024}
}

% DITTO
@inproceedings{lu-etal-2024-large,
    title = "Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment",
    author = "Lu, Keming  and
      Yu, Bowen  and
      Zhou, Chang  and
      Zhou, Jingren",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.423/",
    doi = "10.18653/v1/2024.acl-long.423",
    pages = "7828--7840",
    abstract = "Considerable efforts have been invested in augmenting the role-playing proficiency of open-source large language models (LLMs) by emulating proprietary counterparts. Nevertheless, we posit that LLMs inherently harbor role-play capabilities, owing to the extensive knowledge of characters and potential dialogues ingrained in their vast training corpora. Thus, we introduce Ditto, the first self-alignment method for role-play, which encourages an instruction-following LLM to simulate role-play dialogues as a variant of reading comprehension, and creates a role-play training set comprising 4000 characters, surpassing the scale of currently available datasets by tenfold regarding the number of roles. Subsequently, we fine-tune the LLM using this self-generated dataset to augment its role-playing capabilities. Upon evaluating our meticulously constructed role-play benchmark and the roleplay subset of MT-Bench, Ditto, in various parameter scales, consistently maintains a consistent role identity and provides accurate role-specific knowledge in multi-turn role-play conversations, outperforming all open-source role-play baselines. Furthermore, we present the first cross-supervision role-play experiment, revealing that the role-play styles can be easily acquired, while the intrinsic capabilities of LLMs confine the knowledge within role-play."
}

% personahub
@article{ge2024scaling,
  title={Scaling synthetic data creation with 1,000,000,000 personas},
  author={Ge, Tao and Chan, Xin and Wang, Xiaoyang and Yu, Dian and Mi, Haitao and Yu, Dong},
  journal={arXiv preprint arXiv:2406.20094},
  year={2024}
}

% mmrole
@article{dai2024mmrole,
  title={Mmrole: A comprehensive framework for developing and evaluating multimodal role-playing agents},
  author={Dai, Yanqi and Hu, Huanran and Wang, Lei and Jin, Shengjie and Chen, Xu and Lu, Zhiwu},
  journal={arXiv preprint arXiv:2408.04203},
  year={2024}
}

% character100
@article{wang2024characteristic,
  title={Characteristic AI Agents via Large Language Models},
  author={Wang, Xi and Dai, Hongliang and Gao, Shen and Li, Piji},
  journal={arXiv preprint arXiv:2403.12368},
  year={2024}
}


% BLEU
@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

% Rouge
@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

% Recommend BertScore
@article{alva2021suitability,
  title={The (un) suitability of automatic evaluation metrics for text simplification},
  author={Alva-Manchego, Fernando and Scarton, Carolina and Specia, Lucia},
  journal={Computational Linguistics},
  volume={47},
  number={4},
  pages={861--889},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

% Checking BertScore
@article{devaraj2022evaluating,
  title={Evaluating Factuality in Text Simplification},
  author={Devaraj, Ashwin and Sheffield, William and Wallace, Byron C and Li, Junyi Jessy},
  journal={arXiv preprint arXiv:2204.07562},
  year={2022}
}

% BertScore
@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}

% METEOR
@inproceedings{meteor,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
    author = "Banerjee, Satanjeev  and
      Lavie, Alon",
    booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
    year = "2005",
    url = "https://aclanthology.org/W05-0909/",
}

% rlhflow
@article{dong2024rlhf,
  title={Rlhf workflow: From reward modeling to online rlhf},
  author={Dong, Hanze and Xiong, Wei and Pang, Bo and Wang, Haoxiang and Zhao, Han and Zhou, Yingbo and Jiang, Nan and Sahoo, Doyen and Xiong, Caiming and Zhang, Tong},
  journal={arXiv preprint arXiv:2405.07863},
  year={2024}
}

% ultrafeedback
@article{cui2023ultrafeedback,
  title={Ultrafeedback: Boosting language models with high-quality feedback},
  author={Cui, Ganqu and Yuan, Lifan and Ding, Ning and Yao, Guanming and Zhu, Wei and Ni, Yuan and Xie, Guotong and Liu, Zhiyuan and Sun, Maosong},
  year={2023},
  journal={arXiv preprint},
}

% roleeval
@article{shen2023roleeval,
  title={Roleeval: A bilingual role evaluation benchmark for large language models},
  author={Shen, Tianhao and Li, Sun and Tu, Quan and Xiong, Deyi},
  journal={arXiv preprint arXiv:2312.16132},
  year={2023}
}

% socialbench
@article{chen2024roleinteract,
  title={RoleInteract: Evaluating the Social Interaction of Role-Playing Agents},
  author={Chen, Hongzhan and Chen, Hehong and Yan, Ming and Xu, Wenshen and Gao, Xing and Shen, Weizhou and Quan, Xiaojun and Li, Chenliang and Zhang, Ji and Huang, Fei and others},
  journal={arXiv preprint arXiv:2403.13679},
  year={2024}
}

% HPD
@inproceedings{chen-etal-2023-large,
    title = "Large Language Models Meet Harry Potter: A Dataset for Aligning Dialogue Agents with Characters",
    author = "Chen, Nuo  and
      Wang, Yan  and
      Jiang, Haiyun  and
      Cai, Deng  and
      Li, Yuhan  and
      Chen, Ziyang  and
      Wang, Longyue  and
      Li, Jia",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.570/",
    doi = "10.18653/v1/2023.findings-emnlp.570",
    pages = "8506--8520",
    abstract = "In recent years, Dialogue-style Large Language Models (LLMs) such as ChatGPT and GPT4 have demonstrated immense potential in constructing open-domain dialogue agents. However, aligning these agents with specific characters or individuals remains a considerable challenge due to the complexities of character representation and the lack of comprehensive annotations. In this paper, we introduce the Harry Potter Dialogue (HPD) dataset, designed to advance the study of dialogue agents and character alignment. The dataset encompasses all dialogue sessions (in both English and Chinese) from the Harry Potter series and is annotated with vital background information, including dialogue scenes, speakers, character relationships, and attributes. These extensive annotations may empower LLMs to unlock character-driven dialogue capabilities. Furthermore, it can serve as a universal benchmark for evaluating how well can a LLM aligning with a specific character. We benchmark LLMs on HPD using both fine-tuning and in-context learning settings. Evaluation results reveal that although there is substantial room for improvement in generating high-quality, character-aligned responses, the proposed dataset is valuable in guiding models toward responses that better align with the character of Harry Potter."
}

% weibo
@article{li2021dialogue,
  title={Dialogue history matters! personalized response selection in multi-turn retrieval-based chatbots},
  author={Li, Juntao and Liu, Chang and Tao, Chongyang and Chan, Zhangming and Zhao, Dongyan and Zhang, Min and Yan, Rui},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={39},
  number={4},
  pages={1--25},
  year={2021},
  publisher={ACM New York, NY}
}

% reddit
@inproceedings{ahn-etal-2023-mpchat,
    title = "{MPCHAT}: Towards Multimodal Persona-Grounded Conversation",
    author = "Ahn, Jaewoo  and
      Song, Yeda  and
      Yun, Sangdoo  and
      Kim, Gunhee",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.189/",
    doi = "10.18653/v1/2023.acl-long.189",
    pages = "3354--3377",
    abstract = "In order to build self-consistent personalized dialogue agents, previous research has mostly focused on textual persona that delivers personal facts or personalities. However, to fully describe the multi-faceted nature of persona, image modality can help better reveal the speaker`s personal characteristics and experiences in episodic memory (Rubin et al., 2003; Conway, 2009). In this work, we extend persona-based dialogue to the multimodal domain and make two main contributions. First, we present the first multimodal persona-based dialogue dataset named MPCHAT, which extends persona with both text and images to contain episodic memories. Second, we empirically show that incorporating multimodal persona, as measured by three proposed multimodal persona-grounded dialogue tasks (i.e., next response prediction, grounding persona prediction, and speaker identification), leads to statistically significant performance improvements across all tasks. Thus, our work highlights that multimodal persona is crucial for improving multimodal dialogue comprehension, and our MPCHAT serves as a high-quality resource for this research."
}

% livechat
@inproceedings{gao-etal-2023-livechat,
    title = "{L}ive{C}hat: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming",
    author = "Gao, Jingsheng  and
      Lian, Yixin  and
      Zhou, Ziyi  and
      Fu, Yuzhuo  and
      Wang, Baoyuan",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.858/",
    doi = "10.18653/v1/2023.acl-long.858",
    pages = "15387--15405",
    abstract = "Open-domain dialogue systems have made promising progress in recent years. While the state-of-the-art dialogue agents are built upon large-scale social media data and large pre-trained models, there is no guarantee these agents could also perform well in fast-growing scenarios, such as live streaming, due to the bounded transferability of pre-trained models and biased distributions of public datasets from Reddit and Weibo, etc. To improve the essential capability of responding and establish a benchmark in the live open-domain scenario, we introduce the LiveChat dataset, composed of 1.33 million real-life Chinese dialogues with almost 3800 average sessions across 351 personas and fine-grained profiles for each persona. LiveChat is automatically constructed by processing numerous live videos on the Internet and naturally falls within the scope of multi-party conversations, where the issues of Who says What to Whom should be considered. Therefore, we target two critical tasks of response modeling and addressee recognition and propose retrieval-based baselines grounded on advanced techniques. Experimental results have validated the positive effects of leveraging persona profiles and larger average sessions per persona. In addition, we also benchmark the transferability of advanced generation-based models on LiveChat and pose some future directions for current challenges."
}

% llm-as-a-judge
@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

% ms marco
@article{bajaj2016ms,
  title={Ms marco: A human generated machine reading comprehension dataset},
  author={Bajaj, Payal and Campos, Daniel and Craswell, Nick and Deng, Li and Gao, Jianfeng and Liu, Xiaodong and Majumder, Rangan and McNamara, Andrew and Mitra, Bhaskar and Nguyen, Tri and others},
  journal={arXiv preprint arXiv:1611.09268},
  year={2016}
}

% sfr-2
@misc{SFR-embedding-2,
  title={SFR-Embedding-2: Advanced Text Embedding with Multi-stage Training},
  author={Meng, Rui and Liu, Ye and Joty, Shafiq Rayhan and Xiong, Caiming and Zhou, Yingbo and Yavuz, Semih},
  year={2024},
  url={https://huggingface.co/Salesforce/SFR-Embedding-2_R}
}

% catastrophic forgetting
@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}


%
@inproceedings{tang-etal-2024-language,
    title = "Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models",
    author = "Tang, Tianyi  and
      Luo, Wenyang  and
      Huang, Haoyang  and
      Zhang, Dongdong  and
      Wang, Xiaolei  and
      Zhao, Xin  and
      Wei, Furu  and
      Wen, Ji-Rong",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2024",
    url = "https://aclanthology.org/2024.acl-long.309/",
}

% qwen2.5
@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

% judge bias
@article{wataoka2024self,
  title={Self-preference bias in llm-as-a-judge},
  author={Wataoka, Koki and Takahashi, Tsubasa and Ri, Ryokan},
  journal={arXiv preprint arXiv:2410.21819},
  year={2024}
}

% gpt4o
@misc{gpt4o,
  author = {openai},
  title = {gpt4o},
  year = {2024},
  howpublished = {\url{https://openai.com/index/hello-gpt-4o/}}
}

% huminish
@misc{huminish,
  author = {Gallego, Victor},
  title = {Humanish-Roleplay-Llama-3.1-8B},
  year = {2024},
  howpublished = {\url{https://huggingface.co/vicgalle/Humanish-Roleplay-Llama-3.1-8B}}
}

% Peach
@misc{peach-rp,
  author = {Peach},
  title = {Peach-9B-8k-Roleplay},
  year = {2024},
  howpublished = {\url{https://huggingface.co/ClosedCharacter/Peach-9B-8k-Roleplay}}
}

% gpt4-turbo
@misc{gpt4turbo,
  author = {openai},
  title = {gpt4turbo},
  year = {2024},
  howpublished = {\url{https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo}}
}

@misc{gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{llama3,
  title={Llama 3 Model Card},
  author={AI@Meta},
  year={2024},
  howpublished = {\url{https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}}
}

@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

% lm-eval-harness
@misc{eval-harness,
  author       = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = 07,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {v0.4.3},
  doi          = {10.5281/zenodo.12608602},
  url          = {https://zenodo.org/records/12608602}
}

% ifeval
@article{zhou2023instructionfollowing,
  title={Instruction-Following Evaluation for Large Language Models},
  author={Jeffrey Zhou and Tianjian Lu and Swaroop Mishra and Siddhartha Brahma and Sujoy Basu and Yi Luan and Denny Zhou and Le Hou},
  journal={arXiv preprint arXiv:2311.07911},
  year={2023},
}

% math
@article{hendrycksmath2021,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
  journal={NeurIPS},
  year={2021}
}

% gpqa
@misc{rein2023gpqa,
      title={GPQA: A Graduate-Level Google-Proof Q\&A Benchmark},
      author={David Rein and Betty Li Hou and Asa Cooper Stickland and Jackson Petty and Richard Yuanzhe Pang and Julien Dirani and Julian Michael and Samuel R. Bowman},
      year={2023},
      eprint={2311.12022},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

% mmlu-pro
@misc{wang2024mmluprorobustchallengingmultitask,
      title={MMLU-Pro: A More Robust and Challenging Multi-Task Language
      Understanding Benchmark},
      author={Yubo Wang and Xueguang Ma and Ge Zhang and Yuansheng Ni and Abhranil Chandra and Shiguang Guo and Weiming Ren and Aaran Arulraj and Xuan He and Ziyan Jiang and Tianle Li and Max Ku and Kai Wang and Alex Zhuang and Rongqi Fan and Xiang Yue and Wenhu Chen},
      year={2024},
      eprint={2406.01574},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.01574},
}

% truthfulqa
@inproceedings{lin-etal-2022-truthfulqa,
    title = "{T}ruthful{QA}: Measuring How Models Mimic Human Falsehoods",
    author = "Lin, Stephanie  and
      Hilton, Jacob  and
      Evans, Owain",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.229/",
    doi = "10.18653/v1/2022.acl-long.229",
    pages = "3214--3252",
    abstract = "We propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a T5-based model. The best model was truthful on 58{\%} of questions, while human performance was 94{\%}. Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans. The largest models were generally the least truthful. This contrasts with other NLP tasks, where performance improves with model size. However, this result is expected if false answers are learned from the training distribution. We suggest that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web."
}

% musr
@misc{sprague2024musrtestinglimitschainofthought,
      title={MuSR: Testing the Limits of Chain-of-thought with Multistep Soft
      Reasoning},
      author={Zayne Sprague and Xi Ye and Kaj Bostrom and Swarat Chaudhuri and Greg Durrett},
      year={2024},
      eprint={2310.16049},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.16049},
}

% chatglm
@article{glm2024chatglm,
  title={Chatglm: A family of large language models from glm-130b to glm-4 all tools},
  author={GLM, Team and Zeng, Aohan and Xu, Bin and Wang, Bowen and Zhang, Chenhui and Yin, Da and Zhang, Dan and Rojas, Diego and Feng, Guanyu and Zhao, Hanlin and others},
  journal={arXiv preprint arXiv:2406.12793},
  year={2024}
}

% yi
@article{young2024yi,
  title={Yi: Open foundation models by 01. ai},
  author={Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Wang, Guoyin and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and others},
  journal={arXiv preprint arXiv:2403.04652},
  year={2024}
}

@inproceedings{ji-etal-2022-achieving,
    title = "Achieving Reliable Human Assessment of Open-Domain Dialogue Systems",
    author = "Ji, Tianbo  and
      Graham, Yvette  and
      Jones, Gareth  and
      Lyu, Chenyang  and
      Liu, Qun",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2022",
    url = "https://aclanthology.org/2022.acl-long.445/",
}

@MISC{server,
  title     = "King's computational research, engineering and technology
               environment ({CREATE})",
  author    = "{King's College London e-Research team}",
  publisher = "King's College London",
  year      =  2022
}
