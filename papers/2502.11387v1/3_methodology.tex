\section{RoleMRC}
\label{sec:method}

In this section, we build RoleMRC. Figure\,\ref{fig:method} illustrates the overall pipeline of RoleMRC from top to bottom, which is divided into three steps.

\subsection{A Meta-pool of 10k Role Profiles}
\label{sec:meta_pool}
We first collect a meta-pool of 10k role profile using two open-source datasets, with Step 1 and 2.

\paragraph{Step 1: Persona Sampling.} We randomly sample 10.5k one-sentence demographic persona description from PersonaHub\,\cite{ge2024scaling}, such as ``\emph{A local business owner interested in economic trends}'', as shown at the top of Figure\,\ref{fig:method}. 

\paragraph{Step 2: Role Profile Standardization.} Next, we use a well-crafted prompt with gpt-4o\,\cite{gpt4o} to expand each sampled persona into a complete role profile, in reference to the 1-shot standardized example. Illustrated in the middle of Figure\,\ref{fig:method}, we require a standardized role profile consisting of seven components: \emph{Role Name and Brief Description}, \emph{Specific Abilities and Skills}, \emph{Speech Style}, \emph{Personality Characteristics}, \emph{Past Experience and Background}, \emph{Ability and Knowledge Boundaries} and \emph{Speech Examples}. %Setting standard specifications helps convert the generated role profiles into formatted records, which is beneficial for the post quality control. 
Standardizing these profiles ensures structured formatting, simplifying quality control. 
After manual checking and format filtering, we remove 333 invalid responses from gpt-4o, resulting in 10.2k final role profiles. We report complete persona-to-profile standardization prompt and structure tree of final role profiles in Appendix\,\ref{sec:app_prompt_1} and \,\ref{sec:app_tree}, respectively.

Machine Reading Comprehension (MRC) is one of the core tasks for LLMs to interact with human users. Consequently, we choose to synthesize fine-grained role-playing instruction-following data based on MRC. We first generate a retrieval pool containing 808.7k MRC data from the MSMARCO training set\,\cite{bajaj2016ms}. By leveraging SFR-Embedding\,\cite{SFR-embedding-2}, we perform an inner product search to identify the most relevant and least relevant MRC triplets (Passages, Question, Answer) for each role profile. For example, the middle part of Figure\,\ref{fig:method} shows that for the role \emph{Jessica Thompson, a resilient local business owner}, the most relevant question is about \emph{the skill of resiliency}, while the least relevant question is \emph{converting Fahrenheit to Celsius}. After review, we categorise the most relevant MRC triplet as within a role's knowledge boundary, and the least relevant MRC triplet as beyond their expertise.

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/step3.png}
    \caption{The strategy of gradually synthesizing finer role-playing instructions in step 3 of Figure\,\ref{fig:method}.}
    \vspace{-1.0em}
    \label{fig:step3}
\end{figure}

\subsection{38k Role-playing Instructions}
Based on the role profiles, we then adopt \textbf{Step 3: Multi-stage Dialogue Synthesis} to generate 38k role-playing instructions, progressively increasing granularity across three categories %including three types with gradually finer granularity 
(Figure\,\ref{fig:step3}):
%\begin{itemize}
%[leftmargin=*,noitemsep,topsep=0pt]

\noindent \textbf{\underline{Free Chats.}} The simplest dialogues, free chats, are synthesized at first. Here, we ask gpt-4o to simulate and generate multi-turn open-domain conversations between the role and an imagined user based on the standardized role profile. When synthesizing the conversation, we additionally consider two factors: the \textbf{initial speaker} in the starting round of the conversation, and whether the role's speech has \textbf{a narration wrapped in brackets} at the beginning (e.g., \emph{(Aiden reviews the network logs, his eyes narrowing as he spots unusual activity) I found it!}). The narration refers to a short, vivid description of the role's speaking state from an omniscient perspective, which further strengthens the sense of role's depth and has been adopted in some role-playing datasets\,\cite{tu2024charactereval}. 

As shown on the left side of Figure\,\ref{fig:step3}, based on the aforementioned two factors, we synthesize four variations of Free Chats. In particular, when  narration is omitted, we deleted all the 
narration content in the speech examples from the role profile; %and for the case that 
when narration is allowed, we retain the narration content, and also add instructions to allow appropriate insertion of narration in the task prompt of gpt-4o. It worth to note that, in narration-allowed dialogues, not every response of the role has narration inserted to prevent overfitting. All categories of data in RoleMRC incorporate narration insertion and follow similar control mechanisms. The following sections will omit further details on narration.

\noindent \textbf{\underline{On-scene MRC Dialogues.}} The synthesis of on-scene MRC dialogues can be divided into two parts. The first part is similar to the free chats. As shown by the {\color{lightgreen}{green round rectangle}} in the upper part of Figure\,\ref{fig:step3}, we ask gpt-4o to synthesize a conversation (lower left corner of Figure\,\ref{fig:step3}) between the role and the user focusing on relevant passages. This part of the synthesis and the Free Chats share the entire meta-pool, so each consisting of 5k dialogues.

The remaining part forms eight types of single-turn role-playing Question Answering (QA). In the middle of Figure\,\ref{fig:step3}, we randomly select a group of roles and examined the most relevant MRCs they matched: if the question in the MRC is answerable, then the ground truth answer is stylized to match the role profile; otherwise, a seed script of ``unanswerable'' is randomly selected then stylized. The above process generates four groups of 1k data from type ``[1]'' to type``[4]''. According to the middle right side of Figure\,\ref{fig:step3}, we also select a group of roles and ensure that the least relevant MRCs they matched contain answerable QA pairs. Since the most irrelevant MRCs are outside the knowledge boundary of the roles, the role-playing responses to these questions are ``out-of-mind'' refusal or ``let-me-try'' attempt, thus synthesizing four groups of 1k data, from type ``[5]'' to type ``[8]''.

\noindent \textbf{\underline{Ruled Chats.}} We construct Ruled Chats by extending On-scene MRC Dialogues in categories ``[1]'' to ``[8]'' with incorporated three additional rules, as shown in the right bottom corner of Figure\,\ref{fig:step3}. For the \textbf{multi-turn rules}, we apply them to the four unanswerable scenarios ``[3]'', ``[4]'', ``[5]'', and ``[6]'', adding a user prompt that  forces the role to answer. Among them, data ``[3]'' and ``[4]'' maintain refusal since the questions in MRC are unanswerable; while ``[5]'' and ``[6]'' are transformed into attempts to answer despite knowledge limitations. For the \textbf{nested formatting rules}, we add new formatting instructions to the four categories of data ``[1]'', ``[2]'', ``[3]'', and ``[4]'', such as requiring emojis,  capitalization, specific punctuation marks, and controlling the total number of words, then modify the previous replies accordingly. For the last \textbf{prioritized rules}, we apply them to subsets ``[1]'' and ``[2]'' that contain normal stylized answers, inserting a  global refusal directive from the system, and thus creating a conflict between system instructions and the role's ability boundary.
%\end{itemize}

\begin{table}[t]
\resizebox{\columnwidth}{!}{%
  \begin{tabular}{c|c|c|c|c|c}
    \toprule
    & & \textbf{S*} & \textbf{P*} & \textbf{\#Turns} & \textbf{\#Words} \\ 
    \midrule
    \multirow{13.5}{*}{\textbf{RoleMRC}} 
    & \multicolumn{5}{c|}{\textbf{Free Chats}} \\ 
    \cmidrule(lr){2-6}
    & Chats & 5k & / & 9.47 & 38.62 \\ 
    \cmidrule(lr){2-6}
    & \multicolumn{5}{c|}{\textbf{On-scene MRC Dialogues}} \\ 
    \cmidrule(lr){2-6} 
    & On-scene Chats & 5k & / & 9.2 & 43.18 \\
    & Answer & 2k & 2k & 1 & 39.45 \\ 
    & No Answer & 2k & 2k & 1 & 47.09 \\ 
    & Refusal & 2k & 2k & 1 & 48.41 \\ 
    & Attempt & 2k & 2k & 1 & 47.92 \\ 
    \cmidrule(lr){2-6}
    & \multicolumn{5}{c|}{\textbf{Ruled Chats}} \\ 
    \cmidrule(lr){2-6}
    & Multi-turn & 2k & 2k & 2 & 42.47 \\ 
    & Nested & 1.6k & 1.6k & 1 & 46.17 \\ 
    & Prioritized & 2.4k & 2.4k & 1 & 42.65 \\ 
    \midrule
    & \textbf{Total} & 24k & 14k & 3.5 & 40.6 \\ 
    \midrule
    \multirow{3}{*}{\textbf{-mix}} 
    & RoleBench & 16k & / & 1 & 23.95 \\ 
    & RLHFlow & 40k & / & 1.39 & 111.79 \\ 
    & UltraFeedback & / & 14k & 1 & 199.28 \\ 
    \midrule
    & \textbf{Total} & 80k & 28k & 2 & 67.1 \\ 
    \bottomrule
  \end{tabular}}
  \vspace{-2mm}
  \caption{Statistics of RoleMRC. In particular, the column names S*, P*, \#Turns, and \#Words, stands for size of single-label data, size of pair-label data, average turns, and average number of words per reply, respectively. RoleMRC-mix expands RoleMRC by adding existing role-playing data.}
 \vspace{-3mm}
  \label{tab:roleMRC}
\end{table}

\subsection{Integration and Mix-up}
All the seed scripts and prioritized rules used for constructing On-scene Dialogues and Ruled Chats are reported in Appendix\,\ref{sec:app_scripts}. These raw responses are logically valid manual answers that remain unaffected by the roles' speaking styles, making them suitable as negative labels to contrast with the stylized answers. Thanks to these meticulous seed texts, we obtain high-quality synthetic data with stable output from gpt-4o. After integration, as shown in Table\,\ref{tab:roleMRC}, the final RoleMRC contains 24k single-label data for Supervised Fine-Tuning (SFT) and 14k pair-label data for Human Preference Optimization (HPO)\,\cite{ouyang2022training,rafailov2023direct,sampo,hong2024reference}. Considering that fine-tuning LLMs with relatively fixed data formats may lead to catastrophic forgetting\,\cite{kirkpatrick2017overcoming}, we create RoleMRC-mix as a robust version by incorporating external role-playing data (RoleBench\,\cite{wang2023rolellm}) and general instructions (RLHFlow\,\cite{dong2024rlhf}, UltraFeedback\,\cite{cui2023ultrafeedback}).
