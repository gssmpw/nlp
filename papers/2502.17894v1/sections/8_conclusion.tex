\section{Conclusions}
This paper introduces \textbf{FetchBot}, a sim-to-real framework designed for safe object fetching in densely cluttered shelves. By integrating large-scale synthetic data generation, dynamics-aware policy learning, and unified multi-view 3D representations, FetchBot achieves zero-shot generalization to real-world scenarios with minimal disturbance to surrounding objects. Specifically, we propose \textbf{UniVoxGen} to overcome data scarcity by generating high-density, geometrically diverse scene layouts in voxel space, enabling state-based policy training. Through oracle-guided trajectory distillation and integration with depth foundation models, FetchBot mitigates sim-to-real discrepancies while preserving geometric fidelity for collision avoidance. The architecture of our 3D vision policy focuses on local occupancy prediction and view-consistent 3D scene understanding significantly improves performance in restricted motion spaces and occluded views. In simulation, FetchBot outperforms motion planning and state-of-the-art learning-based methods, achieving an average success rate of 81.46\%. In real-world experiments, it demonstrates a 76.67\% success rate across 30 diverse retail scenarios with over 40+ distinct retail items. These results highlight the viability of simulation-driven approaches augmented with foundation models and geometry-aware representations for developing safe, efficient, and generalizable robotic systems. Future work will explore non-suction manipulation and more complex shelf dynamic environments to further bridge the gap between simulation and real-world deployment.
