\section{Background \& Related Work}

\subsection{Autonomous Underwater Cave Exploration}
Exploring underwater caves remains a perilous and demanding endeavor, even for experienced scuba divers, due to confined spaces, little to no natural lights, and a high risk of disorientation~\cite{buzzacott2009american}. Thus, ROVs and AUVs play a crucial role in tasks such as mapping and sample collection~\cite{soares2024mapping}. While SOTA AUVs are proficient in executing fully autonomous missions, their deployments have primarily been constrained to open water environments~\cite{sahoo2019advancements}, where obstacles are minimal. Underwater caves, however, present unique and formidable navigation challenges, including overhead and surrounding obstacles, narrow passageways, and complex topologies. Early efforts to address these challenges include the work of Mallios~\etal~\cite{mallios2016toward}, where manually operated AUVs collected acoustic data for offline mapping. Similarly, Weidner~\etal~\cite{WeidnerICRA2017,WeidnerMSc2017} utilized stereo camera systems to generate high-resolution 3D reconstructions of cave walls, floors, and ceilings.

\begin{figure*}[t]
% \vspace{-4mm}
     \centering
     \includegraphics[width=0.49\linewidth]{figures/Fig3_Structure_a.png}
     \includegraphics[width=0.49\linewidth]{figures/Fig3_b.png}
     %\vspace{-2mm}
     \caption{The proposed CavePI system design is shown; (a) isometric 3D view of the robot; (b) side-view and top-view displaying the outer shell, sonar, and thrusters' positions; (c) cross-sectional view presenting the assembly of the electronic components inside the computational enclosure; (d) the fully assembled system. CavePI is one-person deployable, weighs $8.8$\,kg, and has a depth rating of $65$ meters ($213$\,ft).}%
     \vspace{-3mm}
     \label{fig:system_design}
 \end{figure*}

Vision-based state estimation and navigation in underwater caves pose significant challenges due to factors such as lighting variability, backscattering effects, and image degradation~\cite{JoshiIROS2019}. To overcome these obstacles, Rahman~\etal~\cite{RahmanICRA2018,RahmanIJRR2022} proposed a data fusion framework that integrates visual, acoustic, inertial, and water depth measurements, enabling robust trajectory estimation and sparse representations of underwater cave environments. Advances such as shadow-based mapping~\cite{RahmanIROS2019b}, contour extraction~\cite{massone2020contour}, and real-time stereo reconstruction~\cite{WangICRA2023} have further enhanced the density and fidelity of cave mapping techniques. More recently, visual learning-based approaches have shown promise for autonomous visual servoing within underwater caves~\cite{abdullah2023caveseg,yu2023weakly}. Other contemporary works with the Sunfish autonomous underwater vehicle (AUV)~\cite{richmond2020autonomous} has demonstrated effective navigation capabilities in these environments by employing Doppler Velocity Log (DVL)-based dead reckoning and sonar-based SLAM algorithms to navigate and map complex underwater cave systems. 


%These developments highlight the increasing potential of integrating data fusion, visual learning, and advanced mapping techniques for addressing the unique challenges of underwater cave exploration.
%\JI{Talk about CL-ViT, CaveSeg, and ICMLA papers! double-blind review but still you gotta mention them}


% State-of-the-art autonomous features for atomic tasks such as hovering~\cite{jin2022hovering}, following navigation guidelines (\eg, cavelines inside underwater caves~\cite{yu2023weakly,MohammadiICMLA2023}), gripping objects~\cite{manjunatha2018low,lensgraf2023buoyancy}


 
\subsection{Robot Navigation by Semantic Guidance}

Terrestrial and aerial robotic systems benefit from their feature-rich surroundings, leveraging semantic knowledge for navigation; examples include detecting road lanes~\cite{ding2020lane}, traffic signs~\cite{bruno2017image}, power lines~\cite{ceron2018onboard,alexiou2023visual} riverbanks~\cite{yang2022image}, and sea horizon lines~\cite{gershikov2013horizon}. Traditional approaches for extracting such features include edge detection~\cite{lee2014outdoor} and line segment analysis~\cite{yang2022image}. Advanced learning-based methods employ conditional random fields (CRFs)~\cite{zhan2020adaptive}, convolutional neural networks (CNNs)~\cite{steccanella2019deep}, and Vision Transformers (ViTs)~\cite{du2021vtnet,panda2023agronav} for robust semantic scene parsing. More recently, vision-language models, such as CLIP~\cite{radford2021learning} and its variants~\cite{shah2023lm,sontakke2024roboclip}, have been utilized to generate semantically meaningful embeddings for high-level scene comprehension and robot navigation~\cite{huang2023visual,dorbala2022clip}.


However, underwater environments are typically low-light, turbid, cluttered, and unstructured, thereby deprived of distinct semantic features~\cite{islam2024computer}. Underwater robots rely on multi-modal sensing \eg, scanning sonars for additional cues and navigation guidance~\cite{caccia2001sonar,teixeira2019dense,yu2019segmentation}. To this end, semantic knowledge representation of targets~\cite{patron2008semantic} has been proven effective for path planning and real-time decision-making of AUVs in partially-known dynamic environments~\cite{patron2010semantic}. Additionally, semantic mapping techniques using laser scanners are employed for subsea pipeline following, inspection, and intervention~\cite{vallicrosa2021semantic}. Recent studies also utilize 3D laser/sonar point clouds for underwater landmark recognition~\cite{himri2018semantic} and eventually integrate them in semantic SLAM pipelines~\cite{song2024experimental}. 


For navigating underwater caves safely, learning-based frameworks have been developed for detecting and following cavelines~\cite{yu2023weakly} and other navigation markers~\cite{abdullah2023caveseg}. However, these computationally intensive models require further optimization to achieve real-time deployments~\cite{mohammadi2024edge}. Additionally, their onboard semantic segmentation performance and decision-making capabilities remain underexplored. We address this gap by conducting comprehensive real-world evaluations using our CavePI robotic platform, demonstrating its effectiveness for real-time semantic segmentation and navigation in underwater cave environments.

% However, While fully autonomous navigation is difficult to achieve, ROVs have been equipped with advanced sensors for perception and semantic scene understanding [cite].



% \newpage