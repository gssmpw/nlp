\begin{abstract}
Enabling autonomous robots to safely and efficiently navigate, explore, and map underwater caves is of significant importance to water resource management, hydrogeology,  archaeology, and marine robotics. In this work, we demonstrate the system design and algorithmic integration of a visual servoing framework for semantically guided autonomous underwater cave exploration. We present the hardware and edge-AI design considerations to deploy this framework on a novel AUV (Autonomous Underwater Vehicle) named \textbf{CavePI}. The guided navigation is driven by a computationally light yet robust deep visual perception module, delivering a rich semantic understanding of the environment. Subsequently, a robust control mechanism enables CavePI to track the semantic guides and navigate within complex cave structures. We evaluate the system through field experiments in natural underwater caves and spring-water sites and further validate its ROS (Robot Operating System)-based digital twin in a simulation environment. Our results highlight how these integrated design choices facilitate reliable navigation under feature-deprived, GPS-denied, and low-visibility conditions.

\vspace{1.5mm}
\noindent
\textbf{Keywords.} Autonomous Underwater Vehicles (AUVs); Guided Navigation; Underwater Cave Exploration.
%Enabling autonomous robots to navigate, explore, and map underwater caves safely and efficiently is of significant importance to marine robotics and archaeology. In this work, we demonstrate the system design and algorithmic integration of a visual servoing capability for semantically guided autonomous underwater cave exploration. We present the hardware and edge-AI design choices required to enable this feature on a novel 6-DOF autonomous robot named CavePI. We demonstrate that the recent advancements in semantic parsing of underwater cave scenes can be distilled on low-power edge devices with careful design considerations. We analyze these design choices and evaluate the visual serving algorithm on several natural underwater caves and spring-water sites. We also simulate the CavePI capabilities on a ROS-based digital twin environment for comprehensive validations. Building on that, our field robotics deployments reveal crucial insights into the XX and YYY to ensure safe navigation in feature-deprived, GPS-denied, and adverse visibility conditions inside underwater caves. The hardware and software design, relevant code, and training data is available at our project website: \tt{\textit{removed-for-blind-review}}.
\end{abstract}