@inproceedings{Mikolov2013EfficientEO,
  title={Efficient Estimation of Word Representations in Vector Space},
  author={Tomas Mikolov and Kai Chen and Gregory S. Corrado and Jeffrey Dean},
  booktitle={International Conference on Learning Representations},
  year={2013},
}

@inproceedings{alam2021crisisbench,
  title={CrisisBench: Benchmarking crisis-related social media datasets for humanitarian information processing},
  author={Alam, Firoj and Sajjad, Hassan and Imran, Muhammad and Ofli, Ferda},
  booktitle={Proceedings of ICWSM},
  volume={15},
  pages={923--932},
  year={2021}
}

@article{cotfas2021longest,
  title={The longest month: analyzing COVID-19 vaccination opinions dynamics from tweets in the month following the first vaccine announcement},
  author={Cotfas, Liviu-Adrian and Delcea, Camelia and Roxin, Ioan and Ioan{\u{a}}{\c{s}}, Corina and Gherai, Dana Simona and Tajariol, Federico},
  journal={IEEE Access},
  volume={9},
  pages={33203--33223},
  year={2021},
  publisher={IEEE}
}

@article{devaraj2020machine,
  title={Machine-learning methods for identifying social media-based requests for urgent help during hurricanes},
  author={Devaraj, Ashwin and Murthy, Dhiraj and Dontula, Aman},
  journal={International Journal of Disaster Risk Reduction},
  volume={51},
  pages={101757},
  year={2020},
  publisher={Elsevier}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{dutt2019utilizing,
  title={Utilizing microblogs for assisting post-disaster relief operations via matching resource needs and availabilities},
  author={Dutt, Ritam and Basu, Moumita and Ghosh, Kripabandhu and Ghosh, Saptarshi},
  journal={Information Processing \& Management},
  volume={56},
  number={5},
  pages={1680--1697},
  year={2019},
  publisher={Elsevier}
}

@article{gong2014compressing,
  title={Compressing deep convolutional networks using vector quantization},
  author={Gong, Yunchao and Liu, Liu and Yang, Ming and Bourdev, Lubomir},
  journal={arXiv preprint arXiv:1412.6115},
  year={2014}
}

@article{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1510.00149},
  year={2015}
}

@article{hayawi2022anti,
  title={ANTi-Vax: a novel Twitter dataset for COVID-19 vaccine misinformation detection},
  author={Hayawi, Kadhim and Shahriar, Sakib and Serhani, Mohamed Adel and Taleb, Ikbal and Mathew, Sujith Samuel},
  journal={Public health},
  volume={203},
  pages={23--30},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{he2017signals,
  title={The signals and noise: actionable information in improvised social media channels during a disaster},
  author={He, Xingsheng and Lu, Di and Margolin, Drew and Wang, Mengdi and Idrissi, Salma El and Lin, Yu-Ru},
  booktitle={Proceedings of the 2017 ACM on web science conference},
  pages={33--42},
  year={2017}
}

@article{hinton2015distillingknowledgeneuralnetwork,
      title={Distilling the Knowledge in a Neural Network}, 
      author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
      year={2015},
      eprint={1503.02531},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1503.02531}, 
}

@article{jiao2019tinybert,
  title={Tinybert: Distilling bert for natural language understanding},
  author={Jiao, Xiaoqi and Yin, Yichun and Shang, Lifeng and Jiang, Xin and Chen, Xiao and Li, Linlin and Wang, Fang and Liu, Qun},
  journal={arXiv preprint arXiv:1909.10351},
  year={2019}
}

@article{koshy2023multimodal,
  title={Multimodal tweet classification in disaster response systems using transformer-based bidirectional attention model},
  author={Koshy, Rani and Elango, Sivasankar},
  journal={Neural Computing and Applications},
  volume={35},
  number={2},
  pages={1607--1627},
  year={2023},
  publisher={Springer}
}

@article{lamsal2024crisistransformers,
  title={CrisisTransformers: Pre-trained language models and sentence encoders for crisis-related social media texts},
  author={Lamsal, Rabindra and Read, Maria Rodriguez and Karunasekera, Shanika},
  journal={Knowledge-Based Systems},
  volume={296},
  pages={111916},
  year={2024},
  publisher={Elsevier}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{myint2024unveiling,
  title={Unveiling the dynamics of crisis events: Sentiment and emotion analysis via multi-task learning with attention mechanism and subject-based intent prediction},
  author={Myint, Phyo Yi Win and Lo, Siaw Ling and Zhang, Yuhao},
  journal={Information Processing \& Management},
  volume={61},
  number={4},
  pages={103695},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{nazer2016finding,
  title={Finding requests in social media for disaster relief},
  author={Nazer, Tahora H and Morstatter, Fred and Dani, Harsh and Liu, Huan},
  booktitle={2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
  pages={1410--1413},
  year={2016},
  organization={IEEE}
}

@article{nguyen2020bertweet,
  title={BERTweet: A pre-trained language model for English Tweets},
  author={Nguyen, Dat Quoc and Vu, Thanh and Nguyen, Anh Tuan},
  journal={arXiv preprint arXiv:2005.10200},
  year={2020}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@inproceedings{poddar2022winds,
  title={Winds of Change: Impact of COVID-19 on Vaccine-related Opinions of Twitter users},
  author={Poddar, Soham and Mondal, Mainack and Misra, Janardan and Ganguly, Niloy and Ghosh, Saptarshi},
  booktitle={ICWSM},
  volume={16},
  pages={782--793},
  year={2022}
}

@article{prasad2023identification,
  title={Identification and classification of transportation disaster tweets using improved bidirectional encoder representations from transformers},
  author={Prasad, Rajesh and Udeme, Akpan Uyime and Misra, Sanjay and Bisallah, Hashim},
  journal={International Journal of Information Management Data Insights},
  volume={3},
  number={1},
  pages={100154},
  year={2023},
  publisher={Elsevier}
}

@article{purohit2014emergency,
  title={Emergency-relief coordination on social media: Automatically matching resource requests and offers},
  author={Purohit, Hemant and Castillo, Carlos and Diaz, Fernando and Sheth, Amit and Meier, Patrick},
  journal={First Monday},
  year={2014}
}

@misc{sanh2020distilbertdistilledversionbert,
      title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}, 
      author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
      year={2020},
      eprint={1910.01108},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.01108}, 
}

@article{song2020mpnet,
  title={Mpnet: Masked and permuted pre-training for language understanding},
  author={Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={16857--16867},
  year={2020}
}

@article{sun2019patient,
  title={Patient knowledge distillation for bert model compression},
  author={Sun, Siqi and Cheng, Yu and Gan, Zhe and Liu, Jingjing},
  journal={arXiv preprint arXiv:1908.09355},
  year={2019}
}

@article{suwaileh2023idrisi,
  title={IDRISI-RE: A generalizable dataset with benchmarks for location mention recognition on disaster tweets},
  author={Suwaileh, Reem and Elsayed, Tamer and Imran, Muhammad},
  journal={Information Processing \& Management},
  volume={60},
  number={3},
  pages={103340},
  year={2023},
  publisher={Elsevier}
}

@article{turc2019well,
  title={Well-read students learn better: On the importance of pre-training compact models},
  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1908.08962},
  year={2019}
}

@article{ullah2021rweetminer,
  title={RweetMiner: Automatic identification and categorization of help requests on twitter during disasters},
  author={Ullah, Irfan and Khan, Sharifullah and Imran, Muhammad and Lee, Young-Koo},
  journal={Expert Systems with Applications},
  volume={176},
  pages={114787},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Proceedings of NIPS},
  pages={5998--6008},
  year={2017}
}

@article{zhou2022victimfinder,
  title={VictimFinder: Harvesting rescue requests in disaster response from social media with BERT},
  author={Zhou, Bing and Zou, Lei and Mostafavi, Ali and Lin, Binbin and Yang, Mingzheng and Gharaibeh, Nasir and Cai, Heng and Abedin, Joynal and Mandal, Debayan},
  journal={Computers, Environment and Urban Systems},
  volume={95},
  pages={101824},
  year={2022},
  publisher={Elsevier}
}

