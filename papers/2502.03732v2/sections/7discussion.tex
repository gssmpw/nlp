\section{Discussion}
 
In the following sections, we first discuss the use of AI-RPM technologies in the remote monitoring of patient mental health symptoms.
Then, we talked about collaborative design in AI-RPM systems for enhancing usability and effectiveness.
Finally, we conclude with collaborative emergency management with AI-RPM systems. 
Our work contributes to CSCW and HCI research at the intersection of health, RPM, and human-AI decision-making.


\subsection{Unraveling Patients' Intertwined Mental Health and Concussion Symptoms}

In clinical scenarios, it is not uncommon to have multiple illnesses intertwined with each other.
For instance, ~\citet{wu2024cardioai} discovered that cancer oncologists need to collaborate with cardiologists to adjust the cancer treatment plan and be constantly aware of patients' cardiotoxicity.
%during cancer treatment.
Nevertheless, the concussion-mental health scenario and the cancer-cardiotoxicity scenario are fundamentally different.
Concussion clinicians, according to our study, do not collaborate with mental health specialists, and neither do they diagnose mental health disorders. 
In most clinical practices, concussion clinicians assess whether a patient's mental health symptoms exceed a certain severity threshold during in-person visits. Based on this assessment, they adjust the treatment plan accordingly.




We believe that AI-RPM technologies have the potential to give clinicians insights into the severity of patients' mental health symptoms.
First, LLM-based CAs could provide insight into patients' mental health symptoms, such as the level of anxiety. 
Moreover, AI-based predictive models could help assess the likelihood of developing mental health sequelae, which can offer valuable and actionable insights into patients' mental health conditions.
As suggested by \citet{bennett2012ehrs, zhang2024rethinking}, utilizing AI predictive models to provide actionable insights can increase the usefulness of AI in clinicians' workflow. 
Future research could explore the design of AI-RPM technologies for collecting and distinguishing youth patients’ overlapping symptoms.




%\iffalse
%\subsubsection{Remote Monitoring of Objective Patient Data}

%Our study revealed significant challenges for concussion clinicians in assessing mental health conditions among youth concussion patients. 
%Some youth patients and their parents often avoid openly discussing mental health concerns due to the stigma of being labeled with mental health disorders. 
%Consequently, clinicians use mental health self-evaluation questionnaires or direct observation of patients' behaviors during clinical visits to assess their mental health condition. 
%However, if patients do not want to disclose their mental health conditions, the validity of questionnaires can be compromised, leaving observation during clinical visits as the only viable option. 
%Yet this in-clinic observation is inherently limited from the geographical perspective.
%Once patients leave the clinic, concussion clinicians can hardly track patients' mental health status in a timely and effective manner.
% they are beyond the clinician's ability to monitor. 
%Even if patients are willing to faithfully and openly discuss their at-home information about mental health, it's different for patients to report their information (e.g., sleep patterns and heart rate) in a detailed and accurate way. 
% about following recommendations—such as maintaining sufficient daily activity and sleep—tends to be inaccurate.


%We suggest that AI-RPM technologies, particularly wearable devices like smartwatches, could help address the aforementioned limitations.
%Wearable devices can collect and provide key physiological metrics such as sleep patterns, physical activities, and heart rate to clinicians in real-time.
%Prior research demonstrated the feasibility and advantages of using wearable in monitoring objective patient physiological metrics outside the clinic~\cite{mendel2024advice, frazier2023six, su2019novel, wu2024cardioai}. 
%These metrics are objective and can faithfully reflect patients' mental health conditions.
%For instance, elevated anxiety levels may be inferred through reduced physical activity or disrupted sleep patterns, while a stable resting heart rate could indicate recovery progress. 
%Concussion clinicians could use such data for clinical decision-making such as scheduling timely follow-up visits or initiating referrals to mental health specialists as needed.
%Moreover, given that the patients in our setting are youth aged 13 to 17, wearable devices can monitor patients' status in a non-intrusive way, and they can be seamlessly integrated into patients' daily routines.
%This will not only prevent patients from experiencing physical pain but also minimize reminders of their concussion as much as possible, which is good for their recovery.

%\fi




\subsection{Augmenting Objective Data With Subjective Experience}
Traditional RPM technologies, such as wearables, have already been used to remotely monitor concussion patients' objective data~\cite{yang2020bidirectional}.
However, collecting objective data alone is not enough in our scenarios.
%Our study focuses uniquely on mental health sequelae in youth patients after a concussion.
As we discussed in the last section, it is critical to monitor the severity of mental health symptoms, such as anxiety and suicidal ideation.
However, these symptoms are more subjective experiences that can hardly be captured by traditional RPM technologies.
%because the data collected by wearables are standardized objective physiological measurements.
To address this gap, we propose using LLM-based CAs to gather patients' anxiety levels and other mental health conditions at home. 
%LLM-powered CAs have the ability to engage in free-form natural language conversations with patients about their subjective experiences.
LLM-based CAs could automatically detect key psychological risk factors such as suicidal thoughts from patients' conversations and generate a summary reportfor the day, which has been demoed in various prior research works in other scenarios~\cite{bartle2023machine, bartle2022second, wang2023enabling, simpson2020daisy, ma2024understanding, yang2023integrating}.


We believe that subjective information collected from LLM-powered CAs serves not only as supplementary information but also as contextual information for objective data (i.e., heart rate).
Prior HCI and CSCW research has highlighted the principle that technology design should incorporate context into data~\cite{dourish2004we, yoo2024missed}.
By combining subjective information and objective data in AI-RPM systems, clinicians could use the system to assess patients' situations more accurately and avoid unnecessary concern over what might otherwise appear to be worrisome in objective metrics alone. 
%For example, if wearable data shows that a patient had very low physical activity on a given day, the information from the LLM-powered CA might reveal that the low activity was only due to a family gathering at home. 
%Future work can explore the use of LLM-powered CAs and wearables to remotely monitor patients' subjective as well as objective data in other clinical settings to assist clinicians and caregivers.


%Compared with traditional RPM approaches, natural conversation significantly reduces the requirement of patients' technical literacy to engage with the devices, enables flexible patient self-reporting, and can be further designed to conduct regular health check-ins through pre-set question lists. 




%%%%%\subsubsection{Patient Privacy Consideration With AI-RPM Technologies}
%When designing such an AI-RPM system, it is essential to underscore protecting patient privacy and ensuring data security. 
%This issue has been widely discussed in many studies and is recognized as a core challenge in AI system design~\cite{gawankar2024patient, bala2024ensuring, korobenko2024towards}. 
%However, in our research context, the target population comprises youth patients aged 11–17, whose privacy needs are uniquely sensitive. 
%The privacy of youth patients is not only a concern for the patients themselves but is also critical to their parents, who often play a key role in the medical process. 
%Parents typically expect to have transparency and informed consent about how their child's data is collected and used~\cite{sisk2020parental, haley2024attitudes}. 
%Therefore, future research could explore methods to effectively safeguard youth health data while simultaneously increasing engagement and building trust among parents in the data collection and use process. 








\subsection{Collaborative Design in AI-RPM Systems for Enhanced Usability and Effectiveness}

When presenting objective and subjective data in an AI-RPM system, it is important to prioritize the data presentation to the usability of the system. 
Concussion clinicians are already overwhelmed by existing EHR systems, and introducing an AI-RPM system with additional data could further increase their workload and strain limited healthcare resources.
Nevertheless, clinicians expressed a willingness to briefly review AI-RPM data before each visit to better prepare for patient consultations.
%Introducing another AI-RPM system with additional data could significantly increase clinicians' workload and reduce the number of available weekly appointment slots, which further strain already limited healthcare resources. 
%However, concussion clinicians expressed the willingness to quickly review AI-RPM systems before each clinical visit to better prepare for patient consultations.
To provide information without increasing workload, designers need to collaborate with clinicians to prioritize data based on the importance of AI-RPM systems. 
%customized and personalized~\cite{amershi2019guidelines}
Key data should be upfront while keeping secondary information hidden but accessible.
Our work offers a refined system design that presents a clear information hierarchy in a visually intuitive manner (Fig. \ref{fig:refined_system_design}), serving as a reference for future development.




Moreover, domain knowledge is essential for defining thresholds of mental health symptom severity in AI-RPM system design.
Without clear definitions of severity, AI-RPM systems may either underreport or overemphasize symptoms, leading to delayed interventions or unnecessary concerns. 
Thus, researcher and designers should closely collaborate with clinicians to establish clear thresholds for the severity of mental health symptoms so that clinicians get alert by the system only when necessary.
Such a collaborative approach among clinicians, researchers, and designers could enhance the usability and effectiveness of clinician-facing AI-RPM systems.
In the future, researchers and designers should focus on the key thresholds that influence clinician decisions.













\subsection{Collaborative Emergency Management With AI-RPM Systems}
Beyond the design of AI-RPM systems, it is also important to consider how the systems support clinicians during emergency situations in real-world practice.

In our study, concussion clinicians view AI as an important collaborative partner to support their decisions, which aligns with precious research in HCI and CSCW communities~\cite{zhang2024rethinking, hao2024advancing, yang2019unremarkable, zhang2020effect}, 
%Our study highlighted that concussion clinicians view AI as an important collaborative partner to support their decisions,
%rather than relying solely on AI-generated results, 
%which aligns with the research in the HCI and CSCW communities ~\cite{zhang2024rethinking, hao2024advancing, yang2019unremarkable, zhang2020effect}.
However, they expressed two main concerns in emergencies.
The first concern is the potential false alert of "suicidal ideation" in the system. 
%While clinicians recognize the importance of such alerts in handling emergencies, they are concerned about the accuracy of the alert.
%—not only in terms of technical capabilities but also regarding the reliability of self-reported data from youth concussion patients. 
Youth patients may often experience mood swings and express emotions with exaggeration, which could lead to false alarms.
%If a youth patient says, “I want to hurt myself,” it may not reflect true intent, but the AI-RPM system could misclassify it as a high-risk alert, leading to false alarms.
%The implications of such false alarms are multifaceted. 
%First, 
As a result, a false alert could waste clinicians' valuable time and critical medical resources that could be allocated to other patients. 
Moreover, if false alarms occur frequently, clinicians could lose trust in the system, which eventually leads to the abandonment of such a system~\cite{liao2020questioning, amershi2019guidelines}. 
Another concern is the ambiguity of accountability that AI-RPM systems introduce. 
%This issue was also raised in our study. 
When an AI-RPM system triggers an emergency alert (e.g., suicidal ideation), clinicians may face time or resource constraints that delay their response. 
Such delays can lead to serious outcomes and raise questions about accountability, which may affect system adoption.

% This lack of clarity in the allocation of responsibility leaves clinicians feeling uneasy, as they remain solely liable for the consequences despite relying on AI assistance.


In high-risk, uncertain cases involving youth, it’s challenging to verify alerts and balance response with accountability.
We believe that addressing these two challenges requires collaboration among a broader set of stakeholders and clarifying accountability~\cite{goodman2017european} before implementing the system. 
%Although the previous studies have highlighted the phenomenon where clinicians, as final decision-makers, have full responsibility for medical outcomes, we suggest that responsibility needs to depend on different clinical situations and discussion with other departments such as legal or leadership teams.
Previous HCI research has primarily focused on involving clinicians and patients in emergency management with AI systems~\cite{wu2024cardioai, hao2024advancing}. 
We propose involving the youth patient’s family in the decision-making process alongside clinicians to manage emergencies. 
If suicidal ideation is detected, both the clinician and the patient’s family should be notified. 
Since family members are often nearby, they can respond quickly, while clinicians provide timely professional guidance.
%For example, if a patient's suicidal ideation is detected, the AI-RPM system should notify not only the clinician but also the patient’s family immediately.
%This allows family members to respond quickly, as they are often nearby or have better access to the patient.
%During this process, clinicians could collaborate with the family by providing timely professional guidance. 
Such collaboration helps mitigate risks from delayed responses while ensuring shared responsibility in emergencies.
Future research could explore parent-facing systems that integrate with clinicians' systems to enhance remote youth patient care.
