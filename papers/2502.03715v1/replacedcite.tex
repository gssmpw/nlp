\section{Related Works}
Related works can be divided into two main categories: KG-based recommendations and unifying KGs and LLMs.

\subsection{KG-based Recommendations}
Existing KG-based approaches can be roughly classified into three categories: embedding-based, path-based, and GNN-based methods. 
Embedding-based techniques, such as CKE____, enhance recommendation performance by integrating collaborative filtering with modeling of diverse item-related side information.
Path-based approaches like KPRN____ employ LSTM____ networks to model relational meta-paths from KGs. However, the fixed design of these meta-paths limit their scalability and general applicability.
% KGAT, KGIN, KGCL, KGRec
Currently, GNN-based methods are considered the forefront KG-based recommendation endeavors with remarkable efficiency. For example, KGAT____ employs graph attention networks____ to prioritize neighbor aggregation based on their relative importance, while KGIN____ enhances this approach by integrating user-specific relational embeddings into the aggregation process. Similarly, KGCL____ introduces KG semantics to mitigate data noise in recommendation systems through knowledge-guided contrastive learning, utilizing KG-aware data augmentation to probe the influence of items on user modeling. KGRec____ implements an knowledge rationalization mechanism that assesses triplets with rationale scores, subsequently integrating them into MAE-based ____ reconstruction learning and building contrastive objectives. However, these methods are limit in fixed KG, inhibiting their ability to capture and leverage the useful dynamic semantic information extracted by LLMs.

\vspace{-0.2cm}\subsection{Unifying KGs and LLMs} 
The integration of LLMs and KGs can be categorized into three primary approaches: KG-enhanced LLMs, LLM-augmented KGs, and synergistic combinations. 
KG-enhanced LLMs, exemplified by Think-on-graph____, utilize KGs to guide LLMs in producing reasoned outputs. Conversely, LLM-augmented KGs leverage LLMs' knowledge editing capabilities to enhance KG performance in downstream tasks, as demonstrated by MPIKGC____ which query LLMs to enriches context in knowledge graph completion task. 
Synergistic approaches, such as GreaseLM____, aim to create frameworks where LLMs and KGs mutually enhance each other's capabilities. In the recommendation domain, methods like LKPNR____ exploit LLMs' text processing abilities to improve content personalization. On the contrary, we propose to integrate LLMs and KGs bidirectionally, using LLMs to augment KG-based recommenders while leveraging the enriched KGs to guide LLMs in generating explanations.

\begin{figure*}[t]
\vspace{-0.4cm}
 \centering
  \includegraphics[width=0.9\textwidth]{Figures/pipeline.pdf}
  \caption{The overview of the proposed CKG-LLMA framework for knowledge graph based recommendations.}
  \vspace{-0.4cm}
  \label{fig:pipeline}
  \vspace{-0.2cm}
\end{figure*}

\vspace{-0.2cm}