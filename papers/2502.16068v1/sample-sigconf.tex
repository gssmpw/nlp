%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}
%%
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{subfigure}
\usepackage{balance}

%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright} 

%% These commands are for a PROCEEDINGS abstract or paper.
\copyrightyear{2025}
\acmYear{2025}
\setcopyright{acmlicensed}\acmConference[WWW '25]{Proceedings of the ACM
Web Conference 2025}{April 28-May 2, 2025}{Sydney, NSW, Australia}
\acmBooktitle{Proceedings of the ACM Web Conference 2025 (WWW '25), April
28-May 2, 2025, Sydney, NSW, Australia}
\acmDOI{10.1145/3696410.3714860}
\acmISBN{979-8-4007-1274-6/25/04}


\newcommand{\nosection}[1]{\vspace{2pt}\noindent\textbf{#1.}}

\newcommand{\modelname}{\textbf{SIEOUG}}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Joint Similarity Item Exploration and Overlapped User Guidance for Multi-Modal Cross-Domain Recommendation}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Weiming Liu}
\affiliation{
\institution{College of Computer Science, Zhejiang University \city{Hangzhou} \country{China}}
}
\email{21831010@zju.edu.cn}

\author{Chaochao Chen}
\authornote{Chaochao Chen is the corresponding author.}
\affiliation{
\institution{College of Computer Science, Zhejiang University \city{Hangzhou}  \country{China}}
}
\email{zjuccc@zju.edu.cn}

\author{Jiahe Xu}
\affiliation{
\institution{College of Computer Science, Zhejiang University \city{Hangzhou}  \country{China}}
}
\email{jiahexu@zju.edu.cn}

\author{Xinting Liao}
\affiliation{
\institution{College of Computer Science, Zhejiang University \city{Hangzhou}  \country{China}}
}
\email{xintingliao@zju.edu.cn}

\author{Fan Wang}
\affiliation{
\institution{College of Computer Science, Zhejiang University \city{Hangzhou} \country{China}}
}
\email{fanwang97@zju.edu.cn}

\author{Xiaolin Zheng}
\affiliation{
\institution{College of Computer Science, Zhejiang University \city{Hangzhou} \country{China}}
}
\email{xlzheng@zju.edu.cn}

\author{Zhihui Fu}
\affiliation{
\institution{OPPO Research Institute  \city{Shenzhen} \country{China}}
}
\email{hzzhzzf@gmail.com}


\author{Ruiguang Pei}
\affiliation{
\institution{OPPO Research Institute  \city{Shenzhen} \country{China}}
}
\email{peiruiguang@gmail.com}

\author{Jun Wang}
\affiliation{
\institution{OPPO Research Institute \city{Shenzhen} \country{China}}
}
\email{junwang.lu@gmail.com}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Weiming Liu et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract} 
%
Cross-Domain Recommendation (CDR) has been widely investigated for solving long-standing data sparsity problem via knowledge sharing across domains.
%
In this paper, we focus on the Multi-Modal Cross-Domain Recommendation (MMCDR) problem where different items have multi-modal information while few users are overlapped across domains.
%
MMCDR is particularly challenging in two aspects: fully exploiting diverse multi-modal information within each domain and leveraging useful knowledge transfer across domains.
%
However, previous methods fail to cluster items with similar characteristics while filtering out inherit noises within different modalities, hurdling the model performance.
%
What is worse, conventional CDR models primarily rely on overlapped users for domain adaptation, making them ill-equipped to handle scenarios where the majority of users are non-overlapped.
%
To fill this gap, we propose Joint Similarity Item Exploration and Overlapped User Guidance (\modelname) for solving the MMCDR problem. 
%
\modelname~first proposes similarity item exploration module, which not only obtains pair-wise and group-wise item-item graph knowledge, but also reduces irrelevant noise for multi-modal modeling.
%
Then \modelname~proposes user-item collaborative filtering module to aggregate user/item embeddings with the attention mechanism for collaborative filtering.
%
Finally \modelname~proposes overlapped user guidance module with optimal user matching for knowledge sharing across domains.
%
Our empirical study on Amazon dataset with several different tasks demonstrates that \modelname~significantly outperforms the state-of-the-art models under the MMCDR setting.
\end{abstract}


%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

% Information systemsInformation retrievalRetrieval tasks and goalsRecommender systems

\ccsdesc[500]{Information systems~Recommender systems} 

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Cross-Domain Recommendation, Multi-Modal Cross-Domain Recommendation, Domain Adaptation, Optimal Transport}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\setlength{\floatsep}{4pt plus 4pt minus 1pt}
\setlength{\textfloatsep}{4pt plus 2pt minus 2pt}
\setlength{\intextsep}{4pt plus 2pt minus 2pt}
\setlength{\dbltextfloatsep}{3pt plus 2pt minus 1pt}
\setlength{\dblfloatsep}{3pt plus 2pt minus 1pt}
\setlength{\abovecaptionskip}{3pt}
\setlength{\belowcaptionskip}{2pt}
\setlength{\abovedisplayskip}{2pt plus 1pt minus 1pt}
\setlength{\belowdisplayskip}{2pt plus 1pt minus 1pt}


\section{Introduction}

% 1. Background. The importance of the research topic (e.g., CDR), why is it needed?

% 2. Problem description. What is the specific problem we want to solve in this paper (e.g., cold-start problem in CDR), may use a motivating example to explain. 

% 3. Challenges (not necessary). What are the challenges in the above problem? 

% 4. Existing work. Can existing work solve the above challenges? If yes, what are the shortcomings?

% 5. Our proposal. How do we solve the challenges and shortcomings? Motivation and Technical solution in high-level. 

% 6. Results. Summarize the key results, e.g., improvements against SOTA.

% 7. Contributions. Simply summarize main contributions. 

Recommender systems become more and more attractive with the big data explosion in recent years \cite{rec_survey,cf2008, steck2019markov,lv2024intelligent,lv2024semantic,lv2025collaboration,lv2023duet,liureducing,liu2024learning,liu2023federated,liu2024user,liu2023joint}.
%
Users may participate in multiple domains, e.g., picking fashion clothes in \textit{Ebay} and buying sport outlets in \textit{Amazon} platforms.
%
Meanwhile items on different domains also inherit useful diverse multi-modal visual or text information.
%
However, users may have limited rating interactions across different domains, leading to data sparsity issues in each domain.
% 
% \xenia{Recently, some studies enrich user prefrence with multi-modal data..., while it suffers from...}
%
Thus how to enhance model performance across domains by leveraging multi-modal information with knowledge sharing still needs more investigation.
 


In this paper, we focus on Multi-Modal Cross-Domain Recommendation (MMCDR) problem as shown in Fig.1.
%
That is, users among different domains are partially overlapped with sparse user-item rating interactions.
%
Meanwhile items on different domains are heterogeneous and they also contain multi-modal information including text and image descriptions.
%
Item multi-modal information is rather valuable since it is extra information reflecting the users tastes beyond rating interactions.
%
For instance, when we discover the user who prefers luxury clothes via multi-modal item information, he/she may also have great interests in fashion sport outlets as shown in Fig.1.
%
There are two main challenges for solving MMCDR: (1) \textbf{CH1}: How to better exploit and utilize diverse multi-modal item information within each domain? 
%
(2) \textbf{CH2}: How to leverage useful knowledge among these partially overlapped users to alleviate data sparsity problem across domains?
%


However, previous methods cannot better solve MMCDR problem well.
%
On the one hand, previous multi-modal recommendation models \cite{he2016vbpr,zhang2021mining} mainly focus on exploring item similarity information from a perspective of pair-wise item-item similarity. 
%
However, different modalities may inherit noises \cite{zhang2021mining} that prevents previous approaches from constructing more precise and discriminative item-item similarity graph.
%
Moreover, conventional approaches always neglect group-wise item information (e.g., a item cluster containing items with similar attributes), which is critical for enhancing efficiency on message passing.
%
Although latest multi-modal recommendation model \textbf{LGMRec} \cite{guo2024lgmrec} employed hypergraph to exploit group-wise item information, the adopted Gumbel-Softmax mechanism is sensitive to the temperature and may fail to effectively cluster similar items.\cite{jang2016categorical,herrmann2020channel,shen2021variational}.
%
Hence it will inevitably incur coarse and meaningless hyperedges among group-wise item hypergraphs, leading to the limited model potentials.
%
Therefore traditional multi-modal recommendation models cannot solve \textbf{CH1} well.
%
On the other hand, previous cross-domain recommendation models \cite{conet,liu2020exploiting} fully rely on the overlapped users for knowledge sharing across domains.
%
These approaches may not achieve satisfactory results especially when only relatively few users are overlapped \cite{duration,recdan,choi2022based}.
%
Meanwhile some latest models (e.g., \textbf{MOTKD} \cite{yang2023multimodal}) could involve optimal transport techniques with Wasserstein distance \cite{courty2016optimal,villani2008optimal} for domain adaptation.
%
Nonetheless, these approaches fail to consider the useful prior knowledge in domain adaptation, leading to coarse and inaccurate matching solutions \cite{luo2023mot,han2024learning,gu2022keypoint}.
%
Therefore these strategies could result in negative transfer phenomenon \cite{xu2020reliable,zhang2022survey} and thus they cannot solve \textbf{CH2} well.
%
In conclusion, previous recommendation models cannot provide satisfactory results on tackling MMCDR problem.

 
To address the aforementioned issues, in this paper, we propose Joint Similarity Item Exploration and Overlapped User Guidance model (\modelname), a multi-modal cross-domain recommendation model for solving MMCDR problem.
%
\modelname~includes three main modules, i.e., \textit{similarity item exploration module}, \textit{user-item collaborative filtering module} and \textit{overlapped user guidance module}.
%
In the similarity item exploration module, we aim to leverage pair-wise item similarity graph with proposed robust item similarity graph fusion to reduce inherit noise and achieve more reliable results.
%
Moreover, we propose sparse item similarity hypergraph exploration in the item similarity exploration module to construct a group-wise item similarity hypergraph which enhances the efficiency of messaging passing by clustering items based on their characteristics via Gromov-Wasserstein metric.
%
The user-item collaborative filtering module is designed to integrate graph and hypergraph information to address \textbf{CH1} and achieve user/item embeddings within each domain.
%
In the overlapped user guidance module, we propose guidance-based optimal user matching algorithm to identify similar user pairs from a global perspective for solving \textbf{CH2}.
%
By incorporating these three modules, \modelname~can better exploit and utilize multi-modal item information, meanwhile \modelname~can also fully transfer knowledge across domains sufficiently. 
%
We summarize our main contributions as follows:
%
(1) We propose a novel framework, i.e., \modelname, for solving MMCDR problem, which contains similarity item exploration module, user-item collaborative filtering module, and overlapped user guidance module.
%
(2) To our best knowledge, this is the first attempt in the literature to jointly explore pair-wise and group-wise item similarity via proposed robust item similarity graph aggregation and sparse item similarity hypergraph exploration.
%
Moreover, it the first attempt to involve overlapped user guidance into knowledge transfer across domains.
%
(3) Extensive empirical experiments on multiple tasks in Amazon datasets demonstrate the proposed \modelname~significantly improves the state-of-the-art models under the MMCDR setting.




\begin{figure}
\centering
\includegraphics[width=1\linewidth]{pic/wwwssaw_3.pdf}
% \vspace{-0.3cm} 
\caption{The problem definition of MMCDR. }
\vspace{-0.3cm} 
\label{fig:model}
\end{figure}



\section{Related Work}

\nosection{Multi-Modal Recommendation}
%
Multi-Modal recommendation is set to involve multi-modal information (e.g., the item image and text descriptions) for user-item modelling \cite{zhu2024multimodal,zhong2024mirror,liu2023multimodal,mu2022learning,tao2022self}.
%
Conventional work \cite{he2016vbpr,zhang2019deep,wei2019mmgcn} directly fused the visual/style contents with their ID embeddings with Bayesian personalized ranking \cite{bpr} for collaborative filtering.
%
Nowadays, with the fast development of graph neural network \cite{lightgcn}, more researchers started to utilize the message passing mechanism among knowledge aggregation across different modalities \cite{wei2019mmgcn,wang2021dualgnn,wei2020graph}.
%
For instance, \textbf{LATTICE} \cite{zhang2021mining} first constructs an pair-wise item-item relation graph within each modality and then aggregates them to form a global item-item graph.
%
Recently some work \cite{zhou2023bootstrap} also adopt contrastive learning strategy \cite{wang2022towards} with attention mechanism to further boost the model performance.
%
Latest work \textbf{LGM3Rec} \cite{guo2024lgmrec} has even adopted Gumbel-Softmax with hypergraph relationships to enhance the model's performance by capturing group-wise high-order semantic information.
%
However, current multi-modal recommendation models fail to extract or cluster item with similar characteristics in the group-wise perspectives, which is vital for user-item modelling.  






\nosection{Cross-Domain Recommendation}
%
Cross Domain Recommendation (CDR) models are set to tackle the data sparsity problem by leveraging useful knowledge across domains \cite{khan2017cross,cao2022cross,ddtcdr,dml,zhao2023cross,du2024identifiability}.
%
Traditional CDR models mainly rely on the overlapped users to realize the knowledge transfer \cite{zang2022survey,chen2024survey,li2024aiming,xu2024rethinking}.
%
For instance, \textbf{CoNet} \cite{conet} and \textbf{ACDN} \cite{liu2020exploiting} adopted the cross-connection unit with attention mechanism in the deep neural network for snitching the message from different domains.
%
However these approaches cannot handle the general case when few users are overlapped \cite{recdan,tdar,cdrsurvey}.
%
Recently some work \cite{darec,zhang2021learning} start to investigate that scenario with domain adaptation strategies including adversarial training \cite{gan} or distribution co-clustering \cite{vade}.
%
Meanwhile, only a few papers focus on addressing the multi-modal cross-domain recommendation problem, as multi-modal information amplifies domain discrepancies, making the task even more challenging.
%
Latest, \textbf{MOTKD} \cite{yang2023multimodal} is the first to attempt solving the MMCDR problem using an optimal transport approach \cite{gu2022keypoint,courty2016optimal,khamis2024scalable,li2022gromov,damodaran2018deepjdot}.
%
Nonetheless, the above methods typically separate domain adaptation for overlapped and non-overlapped users, neglecting the matching guidance provided by the overlapped users.
%
Therefore, they may lead to negative transfer, resulting in suboptimal solutions that hinder model performance.


 

\begin{figure*}
\centering
\includegraphics[width=0.95\linewidth]{pic/wwwuuu_6.pdf}
% \vspace{-0.7cm} 
\caption{The model framework of proposed \modelname~for solving MMCDR problem.}
% \xenia{indicate group, A is used for hypergraph, scalar $\alpha$}}
% \vspace{-0.5cm} 
\label{fig:sig}
\end{figure*}



\section{Modeling for \modelname}
%
In this section, we will introduce the details of our proposed method \modelname~for solving MMCDR problem.
%
We assume there are two domains, i.e., a source domain $\mathcal{S}$ and a target domain $\mathcal{T}$.
%
There exists $N_{\boldsymbol{U}}^\mathcal{S}$, $N_{\boldsymbol{U}}^\mathcal{T}$ users and $N_{\boldsymbol{V}}^\mathcal{S}$, $N_{\boldsymbol{V}}^\mathcal{T}$ items in source and target domains respectively.
%
$\boldsymbol{R}^\mathcal{S} \in \mathbb{R}^{N_{\boldsymbol{U}}^\mathcal{S} \times N_{\boldsymbol{V}}^\mathcal{S}}$ and $\boldsymbol{R}^\mathcal{T} \in \mathbb{R}^{N_{\boldsymbol{U}}^\mathcal{T} \times N_{\boldsymbol{V}}^\mathcal{T}}$ denote the user-item rating matrix in source and target domains respectively.
%
Source and target domains inherit the origin user-item interaction graphs $\boldsymbol{O}^{\mathcal{S}}$ and $\boldsymbol{O}^{\mathcal{T}}$ which are given as $\boldsymbol{O}^{\mathcal{S}} =  \left[ 
\begin{matrix}
\boldsymbol{0} & \boldsymbol{R}^{\mathcal{S}}\\
(\boldsymbol{R}^{\mathcal{S}})^{\top} & \boldsymbol{0}
\end{matrix}
\right]$ and $\boldsymbol{O}^{\mathcal{T}} =  \left[ 
\begin{matrix}
\boldsymbol{0} & \boldsymbol{R}^{\mathcal{T}}\\
(\boldsymbol{R}^{\mathcal{T}})^{\top} & \boldsymbol{0}
\end{matrix}
\right]$ respectively.
%
Meanwhile items in different domains have multi-modal visual and text features.
%
We adopt the CLIP model \cite{radford2021learning} to generate corresponding multi-modal visual and text features as $\boldsymbol{x}^{\mathcal{S},{\rm visual}}$, $\boldsymbol{x}^{\mathcal{T},{\rm visual}}$ and $\boldsymbol{x}^{\mathcal{S},{\rm text}}$, $\boldsymbol{x}^{\mathcal{T},{\rm text}}$ respectively.
%
Not all users are overlapped across domains and we adopt $\mathcal{K}_u \in (0,1)$ as the overlapped user ratio to measure how many users are concurrence among different domains following \cite{vade}.
%



The framework of \modelname~is shown in Fig.\ref{fig:sig}.
%
\modelname~mainly has three modules, i.e., \textit{similarity item exploration module}, \textit{user-item collaborative filtering module} and \textit{overlapped user guidance module}.
%
Similarity item exploration module is set to exploit multi-modal  information with vision and text features for different items within each domain.
%
User-item collaborative filtering module aims to model user and item preferences based on user-item ratings. 
%
Overlapped user guidance module is set to transfer and aggregate useful knowledge across different domains.
%
Combining similarity item exploration module and overlapped user guidance module, \modelname~can better explore both intra-domain multi-modal information and inter-domain user sharing information.
 



%If the space is still not fill, write incomplete multi-modal cdr.


%similarity modelling 




\subsection{Similarity Item Exploration Module}
%
To start with, we first introduce similarity item exploration module in \modelname.
%
Similarity item exploration module includes two main steps, i.e., \textit{pair-wise item similarity graph construction} and \textit{group-wise item similarity hypergraph construction}.
%
Pair-wise item similarity graph construction aims to denoise pair-wise item relationship among diverse multi-modal information.
%
Group-wise item similarity hypergraph construction aims to cluster items based on their characteristics to enhance the efficiency on message passing. 
%
By combining item similarity graph and hypergraph construction, the intra-domain model can fully explore item characteristics for enhancing the performance.

\nosection{Pair-Wise Item Similarity Graph Construction}
%
Following previous multi-modal work \cite{zhang2021mining,zhou2023tale}, we should calculate the item pair-wise similarity $S^{d,m}_{ij}$ among different modality in the first step of robust item similarity graph construction, i.e., for each modality $m$:
%
\begin{equation} 
\begin{aligned}
\label{equ:J}
S^{d,m}_{ij} = \exp \left[ \frac{( \boldsymbol{x}^{d,m}_{i} )^{\top} \boldsymbol{x}^{d,m}_{j} }{\| \boldsymbol{x}^{d,m}_{i} \|_2 \|\boldsymbol{x}^{d,m}_{j} \|_2} \right] = \mathscr{S}(\boldsymbol{x}^{d,m}_{i}, \boldsymbol{x}^{d,m}_{j}), 
\end{aligned}
\end{equation}
%
where $d = \{\mathcal{S}, \mathcal{T}\}$ indicates the domain index and $m = \{\rm visual, text\}$ denotes the visual and text features.
%
$\boldsymbol{x}^{d,m}$ denotes the $m$ modality of features in domain $d$ and $\mathscr{S}(\cdot)$ denotes the similarity calculation.
%
Then we adopt top-$z$ sparsification method to obtain sparse similarity results via filtering out irrelevant item-item relationships: 
%
\begin{equation}
\widehat{S}^{d,m}_{i j} = \begin{cases}1, & S^{d,m}_{i j}  \in \text {top}_z\left(S_{i*}^{d,m}\right) \\ 0, & \text { otherwise. }\end{cases}
\end{equation}
%
We can obtain different sparse similarity results $\widehat{\boldsymbol{S}}^{d,m}$ according to different modalities in domain $d$.
%
Since different modalities may inherit complex and heterogeneous information \cite{zhou2023tale}, we should aggregate them to figure out general pair-wise item similarity $\boldsymbol{A}^d \in \mathbb{R}^{N \times N}$.
%
To fulfill this task, we propose Robust Item Similarity Graph Fusion (RISGF) method to find $\boldsymbol{A}^d$ which can be shown as: 
%
\begin{equation} 
\begin{aligned}
\label{equ:J}
&\min_{\boldsymbol{A}^d, \boldsymbol{\Delta}^{d,m} } Q^{d} = \frac{1}{ M} \sum_{m=1}^M  \left( \frac{1}{2} \left\|\left(\boldsymbol{A}^d + \boldsymbol{\Delta}^{d,m}\right) - \widehat{\boldsymbol{S}}^{d,m} \right\|_2^2 + \mu \left\| \boldsymbol{\Delta}^{d,m} \right\|_1 \right)   \\
&s.t.\,\, A^d_{ij} \in [0,1],
\end{aligned}
\end{equation}
%
where $\boldsymbol{\Delta}^{d,m} \in \mathbb{R}^{N \times N}$ denotes modality-specific information in each domain and $\mu$ denotes the balanced hyper parameter.
%
Ideally, pair-wise item similarity within each modality $\widehat{\boldsymbol{S}}^{d,m}$ can be viewed as the combination of general pair-wise item similarity $\boldsymbol{A}^d$ with modality-specific information $\boldsymbol{\Delta}^{d,m}$.
%
Thus RISGF can exploit more relevant pair-wise item similarity while filtering out irrelevant bias or noise in $\widehat{\boldsymbol{S}}^{d,m}$.
%
Inspired by previous works \cite{candes2011robust,xu2010robust}, we adopt L1-norm on $\widehat{\boldsymbol{S}}^{d,m}$ to make the result of $\boldsymbol{A}^d$ more robust.

\nosection{\underline{Optimization}}
%
We provide the optimization details on RISGF as below.
%
Firstly, we fix $\boldsymbol{A}^d$ and update modality-specific information $\boldsymbol{\Delta}^{d,m}$ via proximal gradient descent \cite{nitanda2014stochastic} accordingly: 
% 
\begin{equation}
\label{equ:4}
{\Delta}^{d,m}_{ij} = \mathscr{T}_{\mu}(\widehat{{S}}^{d,m}_{ij} - A^d_{ij}) =
\begin{cases}
\widehat{{S}}^{d,m}_{ij} - A^d_{ij}  - \mu, &  \widehat{{S}}^{d,m}_{ij} \ge A^d_{ij} + \mu \\ 
\widehat{{S}}^{d,m}_{ij}  - A^d_{ij} + \mu, & \widehat{{S}}^{d,m}_{ij} \le A^d_{ij} - \mu\\
0, & {\rm otherwise},
\end{cases}
\end{equation}
%
where $\mathscr{T}_{\mu}(\cdot)$ denotes the proximal projection operator.
%
Then we can fix $\boldsymbol{\Delta}^{d,m}$ and update $\boldsymbol{A}^d$ as below:
%
\begin{equation}
\label{equ:5}
\boldsymbol{A}^d = \left[ \frac{1}{M} \sum_{m=1}^M \left( \widehat{{S}}^{d,m}_{ij}  - \boldsymbol{\Delta}^{d,m} \right) \right]_*,
\end{equation}
%
where $[y]_* = \max(\min(y, 1),0)$ denotes the projected operation.
%
We can adopt Eq.\eqref{equ:4} and Eq.\eqref{equ:5} iteratively to solve RISGA for obtaining the optimal solution on $\boldsymbol{A}^d$ and $\boldsymbol{\Delta}^{d,m}$.
%
At that time, the general pair-wise item similarity $\boldsymbol{A}^d$ can effectively incorporate multi-modal information with enhanced robustness for modelling.



\nosection{Group-Wise Item Similarity Hypergraph Construction}
%
Although pair-wise item similarity graph construction has provided item similarity matrix $\boldsymbol{A}^d$, it still mainly relies on pair-wise information with low efficiency for messaging passing \cite{yu2021self}.
%
Therefore, it is essential to further explore group-wise item similarity relationship.
%
That is, we should figure out the items with similar characteristics to construct the corresponding hypergraph $\boldsymbol{\gamma}^{d}$ via the group-wise item clustering.
%
Hence we propose Sparsity Item  Similarity Hypergraph Exploration (SISHE) method to find $\boldsymbol{\gamma}^{d}$ accordingly: 
%
\begin{equation} 
\begin{aligned}
\label{equ:J1}
&\min_{\boldsymbol{\gamma}^{d} } Q^{d} = - \left \langle {\boldsymbol{A}}^{d} \boldsymbol{\gamma}^{d}\boldsymbol{I}_K, \boldsymbol{\gamma}^{d}  \right \rangle + \frac{\eta}{2} || \boldsymbol{\gamma}^{d}||_2^2  \\
&s.t.\,\, \sum_{i=1}^N \gamma^{d}_{ij} = \frac{N}{K}, \quad \sum_{j=1}^K \gamma^{d}_{ij} = 1, \quad \gamma^{d}_{ij} \ge 0,
\end{aligned}
\end{equation}
%
where $\eta$ denotes the hyper parameter.
%
$\boldsymbol{I}_K \in \mathbb{R}^{K \times K}$ denotes the identity matrix and $K$ denotes the number of clusters.
%
$\boldsymbol{\gamma}^d \in \mathbb{R}^{N \times K}$ is the clustering matrix for constructing group-wise item similarity hypergraph.
%
SISHE aims to balance cluster items based on the pair-wise item similarity graph $\boldsymbol{A}^d$ via optimizing Eq.\eqref{equ:J1}.
%


\nosection{\underline{Optimization}}
%
To start with, we first initialize $({\gamma}^{d})^{(0)}_{ij} = \frac{1}{K}$.
%
Then we regard $(-{\boldsymbol{A}}^{d} (\boldsymbol{\gamma}^{d})^{(l)}\boldsymbol{I}_K) = \mathcal{Y}^{(l)}$ as the constant during the $l$-th iteration.
%
We can provide the Lagrange multipliers of Eq.\eqref{equ:J1} at the $l$-th iteration as follows:
%
\begin{equation} 
\begin{aligned}
\label{equ:J}
&\min_{(\boldsymbol{\gamma}^{d})^{(l+1)} } (J^{d})^{(l+1)}   =  \left \langle \mathcal{Y}^{(l)}, (\boldsymbol{\gamma}^{d})^{(l+1)}  \right \rangle + \frac{\eta}{2} || (\boldsymbol{\gamma}^{d})^{(l+1)} ||_2^2  \\
& - \sum_{j=1}^K g_j \left( \sum_{i=1}^N (\boldsymbol{\gamma}^{d})^{(l+1)} - \frac{N}{K} \right) - \sum_{i=1}^N f_i \left( \sum_{j=1}^K (\boldsymbol{\gamma}^{d})^{(l+1)} - 1  \right),
\end{aligned}
\end{equation}
%
where $\boldsymbol{f}$ and $\boldsymbol{g}$ denote the Lagrange multipliers.
%
By taking the differentiation w.r.t. on $(\boldsymbol{\gamma}^{d})^{(l+1)}_{ij}$ and set it as 0, we can obtain the following equations:
%
\begin{equation} 
\small
\begin{aligned}
\label{equ:J}
(\boldsymbol{\gamma}^{d})^{(l+1)}_{ij} = \left[ \left(f_i + g_j - \mathcal{Y}^{(l)}_{ij} \right)/\eta  \right]_+,
\end{aligned}
\end{equation}
%
where $\left[ e\right]_+ = \max(0,e)$.
%
Specifically, we first fix $\boldsymbol{g}$ and update $\boldsymbol{f}$ via solving the equation $\phi(f_i) = \sum_{j=1}^K [ f_i - (\mathcal{Y}^{(l)}_{ij} - g_j) ]_+ = \eta$.
%
That is, we sort $(\mathcal{Y}^{(l)}_{ij} - g_j)$ in ascending order and define it as the reordered vector $\mathcal{G}^{(l)}$, i.e, $\mathcal{G}^{(l)}_{o} \leq \mathcal{G}^{(l)}_{o+1} \forall_o$.
%
Therefore, the result of $\boldsymbol{f}$ can be shown as:
%
\begin{equation} 
\begin{aligned}
\small
\label{equ:9}
f_i =\begin{cases}
\frac{\eta + \sum\limits_{i=1}^{\kappa} \mathcal{G}^{(l)}_i}{\kappa}, \,\, {\rm where} \,\,\frac{\eta + \sum\limits_{i=1}^{\kappa} \mathcal{G}^{(l)}_i}{\kappa} \in [\mathcal{G}^{(l)}_{\kappa}, \mathcal{G}^{(l)}_{{\kappa}+1}), \kappa = \{1,\cdots,K-1\} \\ 
\frac{\eta + \sum\limits_{i=1}^{K} \mathcal{G}^{(l)}_i}{K}, \,\, {\rm where} \,\,\frac{\eta + \sum\limits_{i=1}^{K} \mathcal{G}^{(l)}_i}{K} \in [\mathcal{G}^{(l)}_{K}, +\infty).  
\end{cases} 
\end{aligned}
\end{equation}
%
Likewise, we then fix $\boldsymbol{f}$ and update $\boldsymbol{g}$ via solving the equation $\psi(g_j) = \sum_{i=1}^N [ g_j - (\mathcal{Y}^{(l)}_{ij} - f_i) ]_+ = \eta\frac{N}{K}$.
%
That is, we sort $(\mathcal{Y}^{(l)}_{ij} - f_i)$ in ascending order and define the reordered vector as $\mathcal{F}^{(l)}$.
%
Hence the result of $\boldsymbol{g}$ can be shown as:
%
\begin{equation} 
\begin{aligned}
\small
\label{equ:10}
g_j =\begin{cases}
\frac{\eta\frac{N}{K} + \sum\limits_{i=1}^{n} \mathcal{F}^{(l)}_i}{n}, \,\, {\rm where} \,\,\frac{\eta\frac{N}{K} + \sum\limits_{i=1}^{n} \mathcal{F}^{(l)}_i}{n} \in [\mathcal{F}^{(l)}_{n}, \mathcal{F}^{(l)}_{{n}+1}), n = \{1,\cdots,N-1\}  \\ 
\frac{\eta\frac{N}{K} + \sum\limits_{i=1}^{N} \mathcal{F}^{(l)}_i}{N}, \,\, {\rm where} \,\,\frac{\eta\frac{N}{K} + \sum\limits_{i=1}^{N} \mathcal{F}^{(l)}_i}{N} \in [\mathcal{F}^{(l)}_{N}, +\infty).  
\end{cases} 
\end{aligned}
\end{equation}
%
After several inner iterations via Eq.\eqref{equ:9} and Eq.\eqref{equ:10}, we can obtain the optimal solutions on $\boldsymbol{f}$ and $\boldsymbol{g}$ for $(\boldsymbol{\gamma}^{d})^{(l+1)}$.
%
Then we should update the term $(-{\boldsymbol{A}}^{d} (\boldsymbol{\gamma}^{d})^{(l+1)}\boldsymbol{I}_K) = \mathcal{Y}^{(l+1)}$ for the outer iteration to solve $(\boldsymbol{\gamma}^{d})^{(l+2)}$.
%
Finally we can reach the optimal coupling matrix $\boldsymbol{\gamma}^d$ in each domain $d$.
%
The pseudo algorithm for SISHE is provided in Appendix A.
%
Indeed, $\boldsymbol{\gamma}^d$ denotes the clustering results of items and thus $\boldsymbol{\gamma}^d$ can be regarded as the item-item hypergraph and each hyperedge represents the items with similar characteristics. 
%
% The whole optimization procedure is provided in Algorithm ??.
%
Moreover, SISHE with Gromov-Wasserstein metric \cite{memoli2014gromov,peyre2016gromov,xu2019gromov} can avoid coarse and inaccurate relationships comparing when compared to prior methods \cite{xu2019scalable,gong2022gromov} that mainly rely on the Gumbel-Softmax mechanism \cite{xu2020gromov,herrmann2020channel,shen2021variational}. 
%
In summary, the group-wise item hypergraph can aggregate more information compared to the pairwise item similarity graph through the message passing procedure, as illustrated in Fig.\ref{fig:example1}(a)-(b).
%
Therefore adopting group-wise item hypergraph can further enhance the model performance.
 

\subsection{User-Item Collaborative Filtering Module}
%
After we obtain user-item interaction graph $\boldsymbol{O}^{d}$, item-item similarity graph $\boldsymbol{A}^d$ and item-item clustering hypergraph $\boldsymbol{\gamma}^d$ in each domain, we should combine these useful information for user-item modelling.
%
Therefore, we propose user-item collaborative filtering module to fully exploit user and item embeddings for the recommendation.
%
Specifically, we set the user/item initialize ID embeddings as $\boldsymbol{u}_d^{(0)}$ and $\boldsymbol{v}_d^{(0)}$ via the learnable lookup table in domain $d$ with dimension $\mathcal{D}$ respectively.
%
Firstly, we adopt the graph neural network on user-item interaction graph $\boldsymbol{O}^{d}$ at the $l$-th layer as follows:
%
\begin{equation}
\begin{aligned}
\boldsymbol{e}_d^{(l+1)} = (\boldsymbol{D}_O^d)^{-\frac{1}{2}}\boldsymbol{O}^d(\boldsymbol{D}_O^d)^{-\frac{1}{2}}\boldsymbol{e}_d^{(l)},
\end{aligned}
\end{equation}
%
where $\boldsymbol{e}_d^{(l)} = \boldsymbol{u}_d^{(l)} \|\, \boldsymbol{v}_d^{(l)}$ and $\|$ denotes the concatenate operation.
%
$\boldsymbol{D}_O^d = {\rm diag}({\boldsymbol{O}}^{{d}}\boldsymbol{1})$ denotes degree matrix of $\boldsymbol{O}^d$.
%
The user/item rating preference embeddings after $\ell$-layered graph neural network is given as $\boldsymbol{u}^d = \frac{1}{\ell+1}\sum_{l=0}^{\ell} \boldsymbol{u}_d^{(\ell)}$ and $\boldsymbol{v}^d = \frac{1}{\ell+1}\sum_{l=0}^{\ell} \boldsymbol{v}_d^{(\ell)}$ respectively.
%
Meanwhile we should further utilize multi-modal information among intra-domain items.
%
That is we conduct the graph convolution according to item-item similarity graph $\boldsymbol{A}^d$ as:
%
\begin{equation}
\begin{aligned}
\boldsymbol{\widehat{v}}_d^{(l+1)} = (\boldsymbol{D}_S^d)^{-\frac{1}{2}}\boldsymbol{A}^d(\boldsymbol{D}_S^d)^{-\frac{1}{2}}\boldsymbol{\widehat{v}}_d^{(l)},
\end{aligned}
\end{equation}
%
where $\boldsymbol{\widehat{v}}_d^{(0)} = \boldsymbol{{v}}_d^{(0)}$ and $\boldsymbol{D}_S^d = {\rm diag}({\boldsymbol{A}}^{{d}}\boldsymbol{1})$ denotes degree matrix of $\boldsymbol{A}^d$.
%
Likewise, we can obtain the item similarity-based embedding via $\boldsymbol{\widehat{v}}^d = \frac{1}{\ell+1}\sum_{l=0}^{\ell} \boldsymbol{\widehat{v}}_d^{(\ell)}$.
%
Moreover, we conduct the hypergraph based on $\boldsymbol{\gamma}^d$ to aggregate group-wise information as follows:
%
\begin{equation} 
\begin{aligned}
\boldsymbol{\widetilde{v}}_d^{(l+1)}  &= {\rm HyperGraph}( \boldsymbol{\gamma}^d, \boldsymbol{\widetilde{v}}_d^{(l)}, \boldsymbol{W}^{(l)}_d)  \\ &= (\boldsymbol{D}^{d}_V)^{-\frac{1}{2}} (\boldsymbol{\gamma}^d)\ (\boldsymbol{D}^{d}_E)^{-\frac{1}{2}}(\boldsymbol{\gamma}^d)^{\top} (\boldsymbol{D}^{d}_V)^{-\frac{1}{2}} \boldsymbol{\widetilde{v}}_d^{(l)} \boldsymbol{W}^{(l)}_d, 
\end{aligned} 
\end{equation}
%
where $\boldsymbol{\widetilde{v}}_d^{(0)} = \boldsymbol{{v}}_d^{(0)}$ and $\boldsymbol{D}^{d}_V \in \mathbb{R}^{N \times N}$ and $\boldsymbol{D}^{d}_E \in \mathbb{R}^{K \times K}$ are vertex degrees and hyperedges degrees of items to cluster hypergraphs.
%
$\boldsymbol{W}^{(l)}_d \in \mathbb{R}^{N \times \mathcal{D}}$ denotes the learnable weights at the $l$-th layer in hypergraph.
%
We can obtain the item cluster-based embedding via $\boldsymbol{\widetilde{v}}^d = \frac{1}{\ell+1}\sum_{l=0}^{\ell} \boldsymbol{\widetilde{v}}_d^{(\ell)}$.
%
Therefore we can achieve user and item embedding $\boldsymbol{\mathcal{U}}^d$ and $\boldsymbol{\mathcal{V}}^d$ by joining multi-modal information as:
%
\begin{equation} 
\begin{aligned}
\boldsymbol{\mathcal{U}}^d = \boldsymbol{u}^d, \quad \boldsymbol{\mathcal{V}}^d = \alpha^d\boldsymbol{v}^d + \widehat{\alpha}^d\boldsymbol{\widetilde{v}}^d + \widetilde{\alpha}^d\boldsymbol{\widehat{v}}^d,
\end{aligned} 
\end{equation}
%
where $\alpha^d$, $\widehat{\alpha}^d$ and $\widetilde{\alpha}^d$ denotes the normalized adaptive weights as $\alpha^d + \widehat{\alpha}^d + \widetilde{\alpha}^d = 1$.
%
Using $\alpha^d$ as an example, it can be calculated as:
%
\begin{equation} 
\begin{aligned}
\alpha^d = \frac{\exp(\boldsymbol{W}_u^d\boldsymbol{u}^d + \boldsymbol{W}_v^d\boldsymbol{v}^d)}{\sum_{\chi \in \{\boldsymbol{v}, \boldsymbol{\widetilde{v}}, \boldsymbol{\widehat{v}}\}} \exp(\boldsymbol{W}_u^d\boldsymbol{u}^d + \boldsymbol{W}_\chi^d\boldsymbol{\chi}^d)},
\end{aligned} 
\end{equation}
%
where $\boldsymbol{W}_u^d$, $\boldsymbol{W}_v^d$, $\boldsymbol{W}_{\widehat{v}}^d$ and $\boldsymbol{W}_{\widetilde{v}}^d$ denote the learnable weights.
%
After that, we can adopt the commonly-used contrastive collaborative filtering loss for modelling intra-domain user-item ratings:
%
\begin{equation} 
\small
\begin{aligned}
\min L^d_{\rm R} = -\log (\mathscr{S} (\boldsymbol{\mathcal{U}}^d_i, \boldsymbol{\mathcal{V}}^d_j))+ \log \left( \sum\limits_{\boldsymbol{\mathcal{V}}^d_k \in \mathcal{N}(\boldsymbol{\mathcal{U}}^d_i)} \mathscr{S} (\boldsymbol{\mathcal{U}}^d_i, \boldsymbol{\mathcal{V}}^d_k) \right).  
\end{aligned} 
\end{equation}
%
That is, we aim to can pull the positive items close and push the negative items away for a certain user according to his/her preference in each domain $d$ via the loss function $L^d_{\rm R}$. 

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{pic/wwwyyyss_2.pdf}
% \vspace{-0.3cm} 
\caption{The illustrations on message passing on item-item similarity graph and hypergraph. Obviously, hypergraph can aggregate more useful information during the procedure.}
\vspace{-0.2cm} 
\label{fig:example1}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{pic/wwwoot_2.pdf}
% \vspace{-0.3cm} 
\caption{Illustrations on overlapped user guidance. When we involve prior overlapped users as the guidance, we can avoid mismatches between users with different preferences.}
\vspace{-0.2cm} 
\label{fig:example2}
\end{figure}


\subsection{Overlapped User Guidance Module}
%
Although combining similarity item exploration module and user-item collaborative filtering module can enhance intra-domain model performance, it still cannot share and transfer useful knowledge across different domains with limited overlapped users.
%
Hence we further propose overlapped user guidance module to utilize inter-domain information for tackling data sparsity problem in each domain.
%
Previous CDR methods \cite{conet,liu2020exploiting} mainly focus on the knowledge sharing via limited overlapped users and neglecting the majority part of non-overlapped users.
%
Thus these conventional approaches  cannot better resolve the issue of knowledge transfer well. 
%
Therefore, \modelname~should leverage knowledge transfer among all users by utilizing overlapping users as the useful guidance from a global optimal perspective.
%
Specifically, we first propose Guidance-based Optimal User Matching (GOUM) method among the whole source and target users during the training procedure:
%
\begin{equation}
\small
\begin{aligned}
&\min_{\boldsymbol{\pi} \ge 0} J_{\rm agn} = \langle \boldsymbol{\pi}, \boldsymbol{C} \odot \boldsymbol{M} \rangle  =  \langle \boldsymbol{\pi},  \boldsymbol{\mathcal{Q}} \rangle \quad s.t.\,\, \sum_{j=1}^N \pi_{ij} = 1, \sum_{i=1}^N \pi_{ij} = 1 ,
\end{aligned}
\end{equation}
%
where $C_{ij} = || \boldsymbol{\mathcal{U}}^\mathcal{S}_i - \boldsymbol{\mathcal{U}}^\mathcal{T}_j||_2^2$ denotes the embedding distance between the source and target users and $\boldsymbol{\pi} \in \mathbb{R}^{N \times N}$ denotes the user-user matching matrix.
%
$\mathcal{\boldsymbol{M}} \in \mathbb{R}^{N \times N}$ denotes the masked matrix which can be calculated as $\mathcal{M}_{ij} = 1- \delta(u^{\mathcal{S}}_i, u^{\mathcal{T}}_j)$ where $\delta(u^{\mathcal{S}}_i, u^{\mathcal{T}}_j)$ denotes whether $u^{\mathcal{S}}_i$ and $u^{\mathcal{T}}_j$ are overlapped users.
%
Specifically, if $u^{\mathcal{S}}_i$ and $u^{\mathcal{T}}_j$ are overlapped users, $\delta(u^{\mathcal{S}}_i, u^{\mathcal{T}}_j) = 1$ and otherwise $\delta(u^{\mathcal{S}}_i, u^{\mathcal{T}}_j) = 0$.
%
$\mathcal{\boldsymbol{M}}$ can guarantee that the overlapped users should get matched which conforms to our anticipation and it can further provides useful prior information as the guidance signal in solving GOUM. 
%
As we show an example in Fig.\ref{fig:example2}(a) where we will obtain mismatch user matching with different preferences when we do not consider any prior knowledge (e.g., overlapped users) as guidance.
%
When we consider the overlapped user as guidance via the masked matrix during the matching procedure with the red line segments, we can achieve clear results as shown in Fig.\ref{fig:example2}(b).
 

\nosection{\underline{Optimization}}
%
To start with, we first figure out the Lagrange multipliers of GOUM as below:
%
\begin{equation}
\small
\begin{aligned}
\max_{\boldsymbol{\omega}, \boldsymbol{\kappa}} \min_{\boldsymbol{\pi}} \widehat{J}_{\rm agn} &= \langle \boldsymbol{\pi}, \boldsymbol{\mathcal{Q}} \rangle - \langle \boldsymbol{\omega}, \boldsymbol{\pi}\boldsymbol{1}_N - \boldsymbol{1}_N \rangle  - \langle \boldsymbol{\kappa}, \boldsymbol{\pi}^{\top}\boldsymbol{1}_N - \boldsymbol{1}_N \rangle ,
\end{aligned}
\end{equation}
%
where $\boldsymbol{\omega}$ and $\boldsymbol{\kappa}$ denote the Lagrange multipliers.
%
% Meanwhile $\boldsymbol{s}$ satisfies $s_{ij} \ge 0$ and $s_{ij}\pi_{ij} = 0$ according to the KKT conditions.
%
Therefore, it is obvious to achieve the dual form of GOUM:
%
\begin{equation}
\label{equ:agn}
\begin{aligned}
&\max_{\boldsymbol{\omega}, \boldsymbol{\kappa}}  \mathcal{J}  = \langle \boldsymbol{\omega},  \boldsymbol{a}\rangle + \langle \boldsymbol{\kappa},  \boldsymbol{b}\rangle, \quad  s.t.\,\, \omega_i + \kappa_j \le  \mathcal{Q}_{ij}.
\end{aligned}
\end{equation}
%
That is, we can adopt $c$-transform to obtain $\kappa_j = \inf_{k\in [N]} ( \mathcal{Q}_{kj} - \omega_k  ) $.
%
Although we should only need to optimize variable $\boldsymbol{\omega}$ in Eq.\eqref{equ:agn}, the optimization problem is non-smooth.
%
Hence we should adopt the smoothness approximation \cite{nesterov2005smooth} on $\boldsymbol{\kappa}$ to facilitate the following procedure: 
\begin{equation}
\label{equ:jielun}
\begin{aligned}
\inf_{k \in [N]} \left(  \mathcal{Q}_{kj} - \omega_k  \right) = -\lim_{\epsilon  \rightarrow 0} \left[ \epsilon \log \left[ \sum_{i=1}^N \exp \left( \frac{\omega_i - \mathcal{Q}_{ij}}{\epsilon} \right) \right] \right].
\end{aligned}
\end{equation}
%
At that time, the optimization in Eq.\eqref{equ:agn} can be rewritten with the following approximate but smoothness expression: 
\begin{equation}
\label{equ:22}
\begin{aligned}
\min_{\boldsymbol{\widehat{\omega}}} \mathcal{J}_{\rm KP} & = \sum_{j=1}^N \left\{ \epsilon \log \left[ \sum_{i=1}^N \exp \left( \frac{\widehat{\omega}_i - \mathcal{Q}_{ij}}{\epsilon} \right) \right] \right\} -\sum_{i=1}^N \widehat{\omega}_i  ,
\end{aligned}
\end{equation}
%
where $\widehat{\boldsymbol{\omega}}$ denotes the approximation on  ${\boldsymbol{\omega}}$.
%
When $\epsilon \rightarrow 0$, $\widehat{\boldsymbol{\omega}}$ will be relatively close to the true value of  ${\boldsymbol{\omega}}$ \cite{an2022efficient}.
%
Then we innovatively propose the Wasserstein Alternative Fixed-point Iteration (WAFI) algorithm to optimize Eq.\eqref{equ:22} efficiently for achieving the optimal solution on $\widehat{\boldsymbol{\omega}}$.
%
The optimization details are provided in Appendix B.
%
Therefore we can finally obtain the final results on $\boldsymbol{\pi}$:
% Note that ideally when $\widehat{{s}}_{ij} = 0$, it indicates that $\pi_{ij} = 1$ according to the KKT theorem.
% %
% In practice, we select the smallest value of $\widehat{{s}}_{i*}$ for the $i$-th row as the actual matching results: 
%
\begin{equation}
\begin{aligned}
\pi_{ij} = \frac{ \exp((\boldsymbol{\widehat{\omega}}_i - \mathcal{Q}_{ij})/\epsilon)}{\sum\limits_{k=1}^N   \exp((\boldsymbol{\widehat{\omega}}_k - \mathcal{Q}_{kj})/\epsilon)}. 
\end{aligned}
\end{equation}
%
% where $\varrho$ denotes a relatively large number and we set $\varrho = 10^4$.
%
% The pseudo algorithm for GOUM is provided in Appendix B.
%
After we obtain the user-user matching matrix $\boldsymbol{\pi}^*$, we can determine the most relevant users across domains among the whole set of users.
%
That is for the source user $\boldsymbol{\mathcal{U}}^{\mathcal{S}}$, the most relevant target users is given as $\boldsymbol{\pi}\boldsymbol{\mathcal{U}}^{\mathcal{T}}$.
%
Likewise, for the target user $\boldsymbol{\mathcal{U}}^{\mathcal{T}}$, the most relevant source users is given as $\boldsymbol{\pi}^{\top}\boldsymbol{\mathcal{U}}^{\mathcal{S}}$.
%
Therefore, we further propose guidance user contrastive loss across domains:
%
\begin{equation} 
\small
\begin{aligned}
\min L_{\rm C} &= -\sum_{i=1}^N \left[ \log (\mathscr{S} (\boldsymbol{\mathcal{U}}^{\mathcal{S}}_i, [\boldsymbol{\pi}\boldsymbol{\mathcal{U}}^{\mathcal{T}}]_i)) -  \log ( \sum\limits_{\boldsymbol{\mathcal{U}}^{\mathcal{T}}_k \in \mathcal{H}(\boldsymbol{\mathcal{U}}^{\mathcal{S}}_i)} \mathscr{S} (\boldsymbol{\mathcal{U}}^{\mathcal{S}}_i, \boldsymbol{\mathcal{U}}^{\mathcal{T}}_k) ) \right]\\
& -\sum_{j=1}^N \left[ \log (\mathscr{S} (\boldsymbol{\mathcal{U}}^{\mathcal{T}}_j, [\boldsymbol{\pi}^{\top}\boldsymbol{\mathcal{U}}^{\mathcal{S}}]_j)) - \log ( \sum\limits_{\boldsymbol{\mathcal{U}}^{\mathcal{S}}_k \in \mathcal{H}(\boldsymbol{\mathcal{U}}^{\mathcal{T}}_j)} \mathscr{S} (\boldsymbol{\mathcal{U}}^{\mathcal{T}}_j, \boldsymbol{\mathcal{U}}^{\mathcal{S}}_k) ) \right],
\end{aligned} 
\end{equation}
%
where $\mathcal{H}(\boldsymbol{\mathcal{U}}^{\mathcal{S}}_i) = \boldsymbol{\mathcal{U}}^{\mathcal{T}} \setminus [\boldsymbol{\pi}\boldsymbol{\mathcal{U}}^{\mathcal{T}}]_i$ and $\mathcal{H}(\boldsymbol{\mathcal{U}}^{\mathcal{T}}_j) = \boldsymbol{\mathcal{U}}^{\mathcal{S}} \setminus [\boldsymbol{\pi}^{\top}\boldsymbol{\mathcal{U}}^{\mathcal{S}}]_j$ denote irrelevant users which act as the negative samples.
%
The guidance contrastive loss can enforce users with similar characteristics across domains to move closer in the embedding space. 
%
Thus the inter-domain knowledge can enhance the model training. 

\subsection{Putting Together}
%
The total loos of \modelname~can be obtained by the contrastive collaborative filtering loss and guidance user contrastive loss on source and target domains.
%
That is, the loss of \modelname~is given as:  
\begin{equation}
\begin{aligned}
\min L = L_{\rm R}^{\mathcal{S}} + L_{\rm R}^{\mathcal{T}} + \lambda  L_{\rm C}, 
\end{aligned}
\end{equation}
%
where $\lambda$ denotes the balanced hyper parameters.
%
By doing this, \modelname~can not only model items with diverse modalities, but also aggregate useful knowledge among the guidance of overlapped users across domains.
%
Note that we pre-calculate the pair-wise item-item similarity graph $\boldsymbol{A}^d$ via RISGF beforehand and freeze them during the training stage to reduce the computation burden. 
 



% \begin{algorithm}[t]
% \begin{algorithmic}[1]
% {
%     \STATE {
%     \textbf{Input:} $\boldsymbol{R}^\mathcal{S}$, $\boldsymbol{R}^\mathcal{T}$: Rating matrix in source and target domains; $\boldsymbol{x}^{\mathcal{S},\rm visual},\boldsymbol{x}^{\mathcal{S},\rm text}$: Multi-modal item information in source domain; $\boldsymbol{x}^{\mathcal{T},\rm visual},\boldsymbol{x}^{\mathcal{T},\rm text}$: Multi-modal item information in target domain.
%     } 
%     \FOR{$i=1$ to $T$}
%         \STATE{Sample $N$ number of user-item . }
        
%         \STATE{ Calculate the matrix $\boldsymbol{K} = \exp( - \boldsymbol{C} / \epsilon )$. }
%         \STATE{ Fix $\boldsymbol{\nu}$ and solve $\nabla_{\boldsymbol{f}} J_P = 0 $ to update $\boldsymbol{f}$ on Eq. \eqref{equ:UPDATE}. }
%         \STATE{ Fix $\boldsymbol{f}$ and solve $\nabla_{\boldsymbol{\nu}} J_P = 0 $ to update $\boldsymbol{\nu}$ on Eq. \eqref{equ:UPDATE}. }
%     \ENDFOR
%     \STATE{\textbf{Return}: $\boldsymbol{\chi}^* = \exp ( (\boldsymbol{f} + \boldsymbol{\nu} - \boldsymbol{C}) /  \epsilon )$. }
% }
% \end{algorithmic}
% \caption{The optimization scheme of \modelname.}
% \end{algorithm}




\section{Empirical Study}

% \begin{table}[t]
% \small
%   \centering
%   \caption{Statistics on Douban and Amazon datasets.}
%     % \vspace{-0.3cm}
%     \begin{tabular}{cccccc}
%     \hline
    
%     \multicolumn{2}{c}{ \textbf{Datasets} } & \textbf{Users} & \textbf{Items} &  \textbf{Ratings} & \textbf{Sparsity}\\
    
%     \hline
    
%     \multirow{2}{*}{\textbf{Task 1}} & Amazon Clothes & \multirow{2}{*}{9,202} & 10,652     & 83,130    & 99.92\% \\
%           & Amazon Sports &       & 10,219    & 84,013    & 99.91\% \\

% \hline

%     \multirow{2}{*}{\textbf{Task 2}} & Amazon Clothes & \multirow{2}{*}{6,548} &  7,266     &  55,789     & 99.88\% \\
%          & Amazon Home  &       &  8,418     &  71,171     & 99.87\% \\
    
%     \hline
    
%     \multirow{2}{*}{\textbf{Task 3}} & Amazon Food & \multirow{2}{*}{9,815} &  9,949     &  135,634     & 99.86\%  \\
%          &Amazon Kitchen  &       & 14,680      &  154,152     & 99.89\% \\
    
%     \hline 

%     \end{tabular}%
%   \label{tab:datasetss}%
% \end{table}%

 


% % Table generated by Excel2LaTeX from sheet 'Sheet7'
% \begin{table*}[!t]
% \small
% % \myfont
% \centering
% \caption{Experimental results on datasets. }
% % \vspace{-0.3cm}
% \label{tab:douban1}
% \begin{tabular}{ccccccccccccc}
% \toprule
% \multirow{2}{*}{Top$@5$}
% & \multicolumn{3}{c}{ML-1M}
% & \multicolumn{3}{c}{ML-10M}
% & \multicolumn{3}{c}{Amazon-Electronic}
% & \multicolumn{3}{c}{Yelp}\\
% \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13}
% &HR &Recall &NDCG
% &HR &Recall &NDCG
% &HR &Recall &NDCG
% &HR &Recall &NDCG\\

% \midrule
% BPR & .6981 & .6045 & .6930 & .7027 & .6038 & .6942 & .1210 & .0703 & .0784  & .5262 & .4025 & .4968\\ 
% NeuMF & .6929 & .5976 & .6779 & .7013 & .5963 & .6763 & .1167 & .0619 & .0705   & .5209 & .3932 & .4764\\ 
% DELF & .6995 & .5992 & .6886 & .7065 & .6020 & .6921 & .1224 & .0683 & .0763   & .5271 & .4045 & .4998\\
% MacridVAE & .6978 & .6031 & .6909 & .7082 & .6052 & .6943 & .1246 & .0720 & .0787   & .5320 & .4083 & .4986\\
% LightGCN & .7087 & .6064 & .6935 & .7139 & .6073 & .6950 & .1289 & .0715 & .0821   & .5424 & .4164 & .5073\\
% SimpleX & .7132 & .6113 & .6986 & .7177 & .6195 & .7002 & .1343 & .0760 & .0882   & .5515 & .4217 & .5125\\
% \midrule
% % NeuMF-PU & .7244 & .6267 & .7013 & .7266 & .6368 & .7036 & .1478 & .0854 & .0997   & .5674 & .4336 & .5196\\
% SCF & .7325 & .6314 & .7085 & .7298 & .6407 & .7096 & .1540 & .0879 & .1032   & .5723 & .4422 & .5334\\
% NBPO & .7286 & .6361 & .7108 & .7304 & .6423 & .7119 & .1642 & .0921 & .1065   & .5787 & .4554 & .5406 \\
% POT & .7311 & .6340 & .7124 & .7312 & .6453 & .7133 & .1605 & .0906 & .1070   & .5842 & .4565 & .5378\\
% PURE & .7384 & .6395 & .7163 & .7358 & .6481 & .7174 & .1628 & .0932 & .1064  & .5821 & .4530 & .5398\\
% \midrule 
% \modelname-Base & .7190 & .6188 & .7029 & .7202 & .6274 & .7045 & .1416 & .0812 & .0923   & .5593 & .4273 & .5207\\
% \modelname-nnPU & .7245 & .6267 & .7013 & .7266 & .6368 & .7036 & .1478 & .0854 & .0997   & .5674 & .4336 & .5269\\
% \modelname-UOT & .7416 & .6416 & .7198 & .7393 & .6502 & .7234 & .1697 & .0978 & .1084   & .5830 & .4621 & .5434\\
% \midrule
% \modelname-PUOT & .7503 & .6529 & .7320 & .7481 & .6696 & .7348 & .1783 & .1083 & .1146   & .5965 & .4748 & .5596\\
% \modelname-SEPUOT & \textbf{.7558} & \textbf{.6604} & \textbf{.7487} & \textbf{.7615} & \textbf{.6752} & \textbf{.7505} & \textbf{.1891} & \textbf{.1135} & \textbf{.1198}   & \textbf{.6014} & \textbf{.4859} & \textbf{.5682}\\
% \midrule

% \multirow{2}{*}{Top$@10$}
% & \multicolumn{3}{c}{ML-1M}
% & \multicolumn{3}{c}{ML-10M}
% & \multicolumn{3}{c}{Amazon-Electronic}
% & \multicolumn{3}{c}{Yelp}
% \\
% \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13}
% &HR &Recall &NDCG
% &HR &Recall &NDCG
% &HR &Recall &NDCG
% &HR &Recall &NDCG\\

% \midrule
% BPR & .8024 & .7107 & .7710 & .8043 & .7138 & .7705 & .2089 & .1075 & .1221  & .6332 & .4963 & .5918\\ 
% NeuMF & .7973 & .7032 & .7604 & .8025 & .7114 & .7696 & .2033 & .1049 & .1185   & .6310 & .4916 & .5758\\ 
% DELF & .8013 & .7091 & .7685 & .8077 & .7165 & .7728 & .2146 & .1088 & .1236   & .6335 & .4977 & .5843\\
% MacridVAE & .8041 & .7129 & .7708 & .8095 & .7187 & .7730 & .2182 & .1102 & .1264   & .6372 & .4991 & .5894\\
% LightGCN & .8086 & .7136 & .7743 & .8114 & .7201 & .7761 & .2230 & .1123 & .1311   & .6426 & .5030 & .5916\\
% SimpleX & .8108 & .7145 & .7732 & .8169 & .7197 & .7805 & .2274 & .1156 & .1350   & .6478 & .5145 & .6020\\
% \midrule
% % NeuMF-PU & .8250 & .7274 & .7845 & .8306 & .7331 & .7983 & .2382 & .1267 & .1474   & .6563 & .5289 & .6084\\
% SCF & .8314 & .7318 & .7906 & .8390 & .7382 & .8029 & .2443 & .1304 & .1509   & .6604 & .5323 & .6178\\
% NBPO & .8389 & .7360 & .7967 & .8451 & .7403 & .8072 & .2465 & .1370 & .1556   & .6689 & .5384 & .6237\\
% POT & .8362 & .7426 & .8013 & .8434 & .7420 & .8125 & .2471 & .1363 & .1548   & .6642 & .5416 & .6286\\
% PURE & .8415 & .7334 & .8025 & .8489 & .7435 & .8103 & .2496 & .1395 & .1582  & .6730 & .5455 & .6302\\
% \midrule 
% \modelname-Base & .8186 & .7202 & .7794 & .8210 & .7268 & .7860 & .2334 & .1202 & .1413   & .6511 & .5218 & .6115\\
% \modelname-nnPU & .8250 & .7274 & .7845 & .8306 & .7331 & .7983 & .2382 & .1267 & .1474   & .6563 & .5289 & .6184\\
% \modelname-UOT & .8427 & .7413 & .8081 & .8505 & .7468 & .8154 & .2538 & .1418 & .1591   & .6727 & .5462 & .6331\\
% \midrule
% \modelname-PUOT & .8603 & .7595 & .8320 & .8689 & .7632 & .8293 & .2691 & .1521 & .1665   & .6803 & .5596 & .6475\\
% \modelname-SEPUOT & \textbf{.8715} & \textbf{.7687} & \textbf{.8465} & \textbf{.8763} & \textbf{.7704} & \textbf{.8412} & \textbf{.2793} & \textbf{.1586} & \textbf{.1714}   & \textbf{.6876} & \textbf{.5647} & \textbf{.6569}\\
% \bottomrule

% \end{tabular}
% %}
% \end{table*}

\begin{table*}[t]
\renewcommand\arraystretch{0.5}
\centering
% \small
\caption{Experimental results on Amazon datasets.}
% \vspace{-0.2cm}
\resizebox{0.98\linewidth}{!}{
\begin{tabular}{ccccccccccccc}
\toprule
% &HR@5 &MRR@5 &NDCG@5 &HR@20 &MRR@20 &NDCG@20 &HR@5 &MRR@5 &NDCG@5 &HR@20 &MRR@20 &NDCG@20\\
% \cmidrule(lr){2-7} \cmidrule(lr){8-13}
\multirow{4}{*}{Clothes \& Sports}
& \multicolumn{2}{c}{\textbf{ Clothes} ($\mathcal{K}_u = 10\%$)}
& \multicolumn{2}{c}{\textbf{ Sports} ($\mathcal{K}_u = 10\%$)}
& \multicolumn{2}{c}{\textbf{ Clothes} ($\mathcal{K}_u = 50\%$)}
& \multicolumn{2}{c}{\textbf{ Sports} ($\mathcal{K}_u = 50\%$)} 
& \multicolumn{2}{c}{\textbf{ Clothes} ($\mathcal{K}_u = 90\%$)}
& \multicolumn{2}{c}{\textbf{ Sports} ($\mathcal{K}_u = 90\%$)} \\
% \cmidrule(lr){2-7} \cmidrule(lr){8-13}
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13} 
&HR@10 &NDCG@10 
&HR@10 &NDCG@10  
&HR@10 &NDCG@10
&HR@10 &NDCG@10
&HR@10 &NDCG@10
&HR@10 &NDCG@10
\\
\midrule
NeuMF & 0.0383 & 0.0131 & 0.0490 & 0.0275 & 0.0564 & 0.0202 & 0.0779 & 0.0265 & 0.0870 & 0.0316 & 0.1112 & 0.0488 \\

LightGCN & 0.0429 & 0.0205 & 0.0573 & 0.0316 & 0.0682 & 0.0264 & 0.0851 & 0.0396 & 0.0968 & 0.0403 & 0.1184 & 0.0573 \\

LATTICE & 0.0558 & 0.0297 & 0.0626 & 0.0364 & 0.0753 & 0.0341 & 0.0930 & 0.0471 & 0.1003 & 0.0489 & 0.1256 & 0.0668 \\ 

FREEDOM & 0.0636 & 0.0354 & 0.0725 & 0.0404 & 0.0779 & 0.0374 & 0.0954 & 0.0527 & 0.1031 & 0.0542 & 0.1283 & 0.0707 \\

LGM3Rec & 0.0645 & 0.0363 & 0.0739 & 0.0421 & 0.0806 & 0.0417 & 0.0992 & 0.0543 & 0.1054 & 0.0568 & 0.1307 & 0.0723 \\


DisenCDR & 0.0565 & 0.0252 & 0.0667 & 0.0341 & 0.0780 & 0.0389 & 0.0968 & 0.0526 & 0.1097 & 0.0592 & 0.1361 & 0.0740 \\

ETL & 0.0594 & 0.0286 & 0.0701 & 0.0378 & 0.0812 & 0.0405 & 0.1013 & 0.0540 & 0.1066 & 0.0564 & 0.1347 & 0.0751 \\

VDEA & 0.0653 & 0.0351 & 0.0724 & 0.0402 & 0.0846 & 0.0432 & 0.1039 & 0.0575 & 0.1102 & 0.0587 & 0.1368 & 0.0743 \\

% SER & \\

DURation & 0.0641 & 0.0338 & 0.0742 & 0.0439 & 0.0875 & 0.0423 & 0.1057 & 0.0601 & 0.1124 & 0.0610 & 0.1395 & 0.0762 \\

CL-DTCDR & 0.0679 & 0.0368 & 0.0755 & 0.0472 & 0.0903 & 0.0441 & 0.1084 & 0.0612 & 0.1136 & 0.0621 & 0.1408 & 0.0775 \\

MOTKD & 0.0705 & 0.0375 & 0.0781 & 0.0493 & 0.0939 & 0.0452 & 0.1114 & 0.0623 & 0.1167 & 0.0640 & 0.1432 & 0.0806 \\

\midrule 

\modelname-O & 0.0684 & 0.0390 & 0.0769 & 0.0467 & 0.0892 & 0.0437 & 0.1061 & 0.0578 & 0.1115 & 0.0603 & 0.1364 & 0.0776\\

\modelname-M & 0.0722 & 0.0403 & 0.0805 & 0.0517 & 0.0961 & 0.0498 & 0.1174 & 0.0650 & 0.1250 & 0.0676 & 0.1535 & 0.0884\\

\modelname-G & 0.0740 & 0.0409 & 0.0826 & 0.0531 & 0.0972 & 0.0503 & 0.1185 & 0.0661 & 0.1254 & 0.0667 & 0.1528 & 0.0875\\

\modelname & \textbf{0.0808}& \textbf{0.0437} & \textbf{0.0873} & \textbf{0.0595} & \textbf{0.1034} & \textbf{0.0543} & \textbf{0.1276} & \textbf{0.0716} & \textbf{0.1292} & \textbf{0.0692} & \textbf{0.1551} & \textbf{0.0899} \\


\toprule
% &HR@5 &MRR@5 &NDCG@5 &HR@20 &MRR@20 &NDCG@20 &HR@5 &MRR@5 &NDCG@5 &HR@20 &MRR@20 &NDCG@20\\
% \cmidrule(lr){2-7} \cmidrule(lr){8-13}
\multirow{4}{*}{Clothes \& Home}
& \multicolumn{2}{c}{\textbf{ Clothes} ($\mathcal{K}_u = 10\%$)}
& \multicolumn{2}{c}{\textbf{ Home} ($\mathcal{K}_u = 10\%$)}
& \multicolumn{2}{c}{\textbf{ Clothes} ($\mathcal{K}_u = 50\%$)}
& \multicolumn{2}{c}{\textbf{ Home} ($\mathcal{K}_u = 50\%$)} 
& \multicolumn{2}{c}{\textbf{ Clothes} ($\mathcal{K}_u = 90\%$)}
& \multicolumn{2}{c}{\textbf{ Home} ($\mathcal{K}_u = 90\%$)} \\
% \cmidrule(lr){2-7} \cmidrule(lr){8-13}
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13} 
&HR@10 &NDCG@10 
&HR@10 &NDCG@10  
&HR@10 &NDCG@10
&HR@10 &NDCG@10
&HR@10 &NDCG@10
&HR@10 &NDCG@10
\\
\midrule
NeuMF & 0.0498 & 0.0181 & 0.0234 & 0.0113 & 0.0755 & 0.0269 & 0.0517 & 0.0173 & 0.1084 & 0.0536 & 0.0702 & 0.0245 \\

LightGCN & 0.0635 & 0.0267 & 0.0392 & 0.0178 & 0.0843 & 0.0381 & 0.0664 & 0.0254 & 0.1196 & 0.0605 & 0.0827 & 0.0363 \\

LATTICE & 0.0747 & 0.0354 & 0.0511 & 0.0259 & 0.0970 & 0.0463 & 0.0739 & 0.0325 & 0.1304 & 0.0682 & 0.0916 & 0.0421 \\ 

FREEDOM & 0.0810 & 0.0404 & 0.0578 & 0.0312 & 0.1062 & 0.0557 & 0.0796 & 0.0369 & 0.1353 & 0.0739 & 0.0943 & 0.0488  \\

LGM3Rec & 0.0843 & 0.0429 & 0.0602 & 0.0336 & 0.1091 & 0.0586 & 0.0835 & 0.0404 & 0.1372 & 0.0768 & 0.0961 & 0.0510 \\

DisenCDR & 0.0825 & 0.0407 & 0.0584 & 0.0306 & 0.1094 & 0.0581 & 0.0843 & 0.0412 & 0.1390 & 0.0781 & 0.0987 & 0.0515\\

ETL & 0.0851 & 0.0426 & 0.0597 & 0.0324 & 0.1125 & 0.0590 & 0.0863 & 0.0435 & 0.1406 & 0.0795 & 0.0998 & 0.0519 \\

VDEA & 0.0886 & 0.0450 & 0.0617 & 0.0345 & 0.1138 & 0.0603 & 0.0872 & 0.0446 & 0.1417 & 0.0810 & 0.1003 & 0.0524\\

DURation & 0.0906 & 0.0472 & 0.0630 & 0.0369 & 0.1158 & 0.0626 & 0.0891 & 0.0454 & 0.1425 & 0.0817 & 0.1021 & 0.0532 \\

CL-DTCDR & 0.0924 & 0.0493 & 0.0636 & 0.0381 & 0.1175 & 0.0642 & 0.0914 & 0.0475 & 0.1442 & 0.0831 & 0.1053 & 0.0547 \\

MOTKD & 0.0935 & 0.0506 & 0.0664 & 0.0389 & 0.1192 & 0.0651 & 0.0923 & 0.0487 & 0.1464 & 0.0842 & 0.1078 & 0.0559 \\

\midrule  

\modelname-O & 0.0902 & 0.0486 & 0.0641 & 0.0375 & 0.1169 & 0.0637 & 0.0898 & 0.0468 & 0.1423 & 0.0814 & 0.1050 & 0.0538 \\

\modelname-M & 0.0949 & 0.0521 & 0.0675 & 0.0413 & 0.1231 & 0.0682 & 0.0958 & 0.0502 & 0.1507 & 0.0874 & 0.1126 & 0.0594 \\

\modelname-G & 0.0958 & 0.0530 & 0.0692 & 0.0427 & 0.1244 & 0.0689 & 0.0971 & 0.0508 & 0.1511 & 0.0865 & 0.1117 & 0.0586\\

\modelname &  \textbf{0.1031} & \textbf{0.0595} & \textbf{0.0763} & \textbf{0.0476} & \textbf{0.1296} & \textbf{0.0724} & \textbf{0.1007} & \textbf{0.0530} & \textbf{0.1555} & \textbf{0.0889} & \textbf{0.1158} & \textbf{0.0612}\\


\toprule
% &HR@5 &MRR@5 &NDCG@5 &HR@20 &MRR@20 &NDCG@20 &HR@5 &MRR@5 &NDCG@5 &HR@20 &MRR@20 &NDCG@20\\
% \cmidrule(lr){2-7} \cmidrule(lr){8-13}
\multirow{4}{*}{Food \& Kitchen}
& \multicolumn{2}{c}{\textbf{ Food} ($\mathcal{K}_u = 10\%$)}
& \multicolumn{2}{c}{\textbf{ Kitchen} ($\mathcal{K}_u = 10\%$)}
& \multicolumn{2}{c}{\textbf{ Food} ($\mathcal{K}_u = 50\%$)}
& \multicolumn{2}{c}{\textbf{ Kitchen} ($\mathcal{K}_u = 50\%$)} 
& \multicolumn{2}{c}{\textbf{ Food} ($\mathcal{K}_u = 90\%$)}
& \multicolumn{2}{c}{\textbf{ Kitchen} ($\mathcal{K}_u = 90\%$)}\\
% \cmidrule(lr){2-7} \cmidrule(lr){8-13}
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13} 
&HR@10 &NDCG@10 
&HR@10 &NDCG@10  
&HR@10 &NDCG@10
&HR@10 &NDCG@10
&HR@10 &NDCG@10
&HR@10 &NDCG@10
\\
\midrule
NeuMF & 0.0533 & 0.0119 & 0.0174 & 0.0102 & 0.1263 & 0.0381 & 0.0496 & 0.0215 & 0.1437 & 0.0658 & 0.0602 & 0.0331  \\

LightGCN & 0.0770 & 0.0221 & 0.0253 & 0.0184 & 0.1451 & 0.0469 & 0.0512 & 0.0293 & 0.1505 & 0.0716 & 0.0767 & 0.0446 \\

LATTICE & 0.0994 & 0.0338 & 0.0391 & 0.0243 & 0.1366 & 0.0556 & 0.0585 & 0.0304 & 0.1575 & 0.0772 & 0.0827 & 0.0508 \\ 

FREEDOM & 0.1045 & 0.0442 & 0.0456 & 0.0301 & 0.1396 & 0.0578 & 0.0640 & 0.0383 & 0.1617 & 0.0864 & 0.0859 & 0.0532 \\

LGM3Rec & 0.1078 & 0.0475 & 0.0471 & 0.0345 & 0.1421 & 0.0609 & 0.0673 & 0.0426 & 0.1644 & 0.0892 & 0.0887 & 0.0556\\

DisenCDR & 0.0982 & 0.0384 & 0.0393 & 0.0294 & 0.1375 & 0.0601 & 0.0656 & 0.0410 & 0.1686 & 0.0907 & 0.0915 & 0.0563 \\

ETL & 0.1019 & 0.0403 & 0.0422 & 0.0317 & 0.1404 & 0.0618 & 0.0679 & 0.0423 & 0.1709 & 0.0924 & 0.0923 & 0.0574\\

VDEA & 0.1026 & 0.0435 & 0.0504 & 0.0330 & 0.1419 & 0.0627 & 0.0705 & 0.0445 & 0.1712 & 0.0931 & 0.0928 & 0.0589 \\ 

DURation & 0.1071 & 0.0494 & 0.0525 & 0.0363 & 0.1437 & 0.0646 & 0.0723 & 0.0468 & 0.1730 & 0.0939 & 0.0942 & 0.0585 \\

CL-DTCDR & 0.1115 & 0.0537 & 0.0566 & 0.0384 & 0.1454 & 0.0679 & 0.0728 & 0.0481 & 0.1738 & 0.0945 & 0.0964 & 0.0593 \\ 

MOTKD & 0.1164 & 0.0596 & 0.0603 & 0.0417 & 0.1482 & 0.0685 & 0.0749 & 0.0506 & 0.1753 & 0.0968 & 0.0989 & 0.0617 \\

\midrule  

% \modelname-Base &  \\

\modelname-O & 0.1141 & 0.0565 & 0.0588 & 0.0392 & 0.1463 & 0.0668 & 0.0701 & 0.0474 & 0.1707 & 0.0936 & 0.0941 & 0.0573\\

\modelname-M & 0.1183 & 0.0602 & 0.0627 & 0.0425 & 0.1556 & 0.0754 & 0.0774 & 0.0539 & 0.1781 & 0.1012 & 0.1005 & 0.0641 \\

\modelname-G & 0.1202 & 0.0611 & 0.0649 & 0.0437 & 0.1570 & 0.0776 & 0.0788 & 0.0545 & 0.1774 & 0.0998 & 0.1001 & 0.0636\\

\modelname & \textbf{0.1279}& \textbf{0.0663} & \textbf{0.0726} & \textbf{0.0498} & \textbf{0.1625} & \textbf{0.0833} & \textbf{0.0854} & \textbf{0.0586} & \textbf{0.1813} & \textbf{0.1031} & \textbf{0.1033} & \textbf{0.0659} \\

\bottomrule

\end{tabular}
%}
}

\label{tab:xxx}
\end{table*}




In this section, we conduct experiments on several real-world datasets to answer the following questions: (1) \textbf{RQ1}: How does the proposed model
\modelname~perform compared with the state-of-the-art recommendation methods? (2) \textbf{RQ2}: How do the similarity item exploration and overlapped user guidance contribute to performance improvement? (3) \textbf{RQ3}: Can proposed method be extended to collaborate with other recommendation models? (4) \textbf{RQ4}: How does the performance of \modelname~vary with different values of the hyper-parameters? 


% In this section, we conduct experiments on several real-world datasets to answer the following questions: 
% %
% (1) \textbf{RQ1}: How does our approach method \textbf{\modelname} perform compared with the state-of-the-art PUR methods?
% %
% (2) \textbf{RQ2}: How does the performance of \modelname~vary with different values of the hyper-parameters?
% %
% (3) \textbf{RQ3}: How does the running time of \textbf{\modelname} compare with other PUR models?



\subsection{Datasets and Tasks} 
%
We conduct extensive experiments on commonly used real-world \textbf{Amazon} datasets.
%
The \textbf{Amazon} dataset \cite{amazon} has five domains, i.e., Clothing Shoes and Jewelry (Clothes), Sports and Outdoors (Sports), Tools and Home Improvement (Home), Grocery and Gourmet Food (Food), and Home and Kitchen (Kitchen).
%
Each datasets includes user-item rating interactions, item text descriptions and item image information.
%
Specifically, we conduct three different tasks on MMCDR, e.g., (Task 1) Clothes $\leftrightarrow$ Sports, (Task 2) Clothes $\leftrightarrow$ Home, (Task 3) Food $\leftrightarrow$ Kitchen.
%
For each dataset, we binarize the ratings higher or equal to 4 as 1 and the rest as 0 following \cite{vade}.
%
Then we filter the users and items with less than 10 interactions.
%
The detailed datasets statistics after prepossessing are shown in Appendix.C.
%
 




% \begin{figure}
% \centering
% \includegraphics[width=\linewidth]{pic/POCDR.pdf}
% \caption{\lwm{The experiment settings on building up the POCDR problems. $\mathcal{K}_u$ denotes the overlapped user ratio.} \ccc{move the section III.A?}}
% \label{fig:pocde_setup}
% \end{figure}
\subsection{Experiment Settings}
% 
We randomly divide the user-item rating data into training, validation, and test sets with a ratio of 8:1:1 following \cite{zhou2023tale}.
%
We also adjust the overlapped user ratio $\mathcal{K}_u$ in $\{10\%,50\%,90\%\}$ to verify the effectiveness our model following \cite{vade,sscdr}.
%
When $\mathcal{K}_u$ is larger (e.g., $\mathcal{K}_u = 90\%$), the problem is much easier due to the ample guidance provided by the overlapping users.
%
In contrast, when $\mathcal{K}_u$ is smaller (e.g., $\mathcal{K}_u = 10\%$), the problem becomes significantly more challenging.  
%
We set batch size $N = 256$ for training in both source and target domains.
%
% Then we adopt pretrained CLIP model \cite{} to obtain the item visual and text features accordingly.
%
We set $z = 5$ for the top-$z$ sparsification in the pair-wise item similarity graph construction.
%
We set $\mu = 0.1$ and $\eta = 0.1$ for RISGF and SISHE respectively.
%
Meanwhile we set the number of item clusters as $K=15$ for constructing the item hypergraph.
%
The number of layers for both graph and hypergraph convolution networks are set to 3.
%
The latent dimension of user and item embeddings are given as $D = 128$.
%
We set $\epsilon = 0.01$ for GOUM in the overlapped user guidance module.
%
Finally we set $\lambda = 0.6$ for the loss function in \modelname.
%
For all the experiments, we perform five random experiments and report the average results.
%
We choose Adam \cite{Adam} as optimizer, and adopt HR$@k$ and NDCG$@k$ \cite{kat} as the ranking evaluation metrics with $k = 10$.
%
 


\nosection{Baseline}
%
We compare our proposed \textbf{\modelname~}with the following state-of-the-art models, i.e., \textbf{NeuMF} \cite{neumf}, \textbf{LightGCN} \cite{lightgcn}, \textbf{LATTICE} \cite{zhang2021mining}, \textbf{FREEDOM} \cite{zhou2023tale}, \textbf{LGM3Rec} \cite{guo2024lgmrec}, \textbf{DisenCDR} \cite{cao2022disencdr}, \textbf{ETL} \cite{etl}, \textbf{VDEA} \cite{vade}, \textbf{DURation} \cite{duration}, \textbf{CL-DTCDR} \cite{lu2023contrastive} and \textbf{MOTKD} \cite{yang2023multimodal}.  
%
The baseline details are provided in Appendix.

 


% \subsection{Implementation Details}


%
%For the \textit{embedding alignment module}, we set the balance hyper-parameters $\eta = ?$.

%

%
% For the \textit{variational rating reconstruction module}, we adopt the heuristic strategy for selecting the disentangle factor $\beta$ by starting from $\beta = 0$ and gradually increasing to $\beta = 1$ through KL annealing \cite{multvae,anneal}. 
% %
% Empirically, we set the cluster number as $K = 5$.
% %
% Meanwhile, we set hyper-parameters $\epsilon = 0.1$ for co-clustering distribution optimal transport.
% %
% For \newmodelname~model, we set the balance hyper-parameters as $\lambda_{VL} = 0.7$ and $\lambda_{VG} = 1.0$.






% \begin{table*}[!t]
% \centering
% \caption{Experimental results on Douban and Amazon datasets.}
% \label{tab:douban1}
% \begin{tabular}{cccccccccc}
% \toprule
% \multirow{}{}{}
% & \multicolumn{3}{c}{(Amazon) Movie\&Book$\rightarrow$Video}
% & \multicolumn{3}{c}{(Amazon) Movie\&Book$\rightarrow$Music}
% & \multicolumn{3}{c}{(Douban) Movie\&Book$\rightarrow$Music}\\
% \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} 
% &HR &Recall &NDCG
% &HR &Recall &NDCG
% &HR &Recall &NDCG\\

% \midrule

% \bottomrule

% \end{tabular}
% %}
% \end{table*}

% \begin{figure} 
%     \centering
%         \subfigure[Effects of $\lambda_{O}$]{
%     \begin{minipage}[t]{0.47\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=4.2cm]{pic/666.pdf}
%     \end{minipage}
% }
%         \subfigure[Effects of $\lambda_{A}$]{
%     \begin{minipage}[t]{0.47\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=4.2cm]{pic/999.pdf}
%     \end{minipage}
% }
% \vspace{-0.3cm}
% 	  \caption{(a)-(b) show the effect of hyper-parameters $\lambda_{O}$ and $\lambda_{A}$ on model performance.}
% 	  \label{fig1:param}
% \vspace{-0.3cm}
% \end{figure}



% \begin{figure*} 
%     \centering
%         \subfigure[$d_\mathcal{A}$ on (Amazon) Movie $\rightarrow$ Music]{
%     \begin{minipage}[t]{0.235\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=4.4cm]{pic/yc.pdf}
%     \end{minipage}
% }
% \centering
%         \subfigure[$d_\mathcal{A}$ on (Douban) Movie $\rightarrow$ Music]{
%     \begin{minipage}[t]{0.235\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=4.4cm]{pic/xxxc.pdf}
%     \end{minipage}
% }
% \centering
%         \subfigure[Effects of $\lambda_{O}$]{
%     \begin{minipage}[t]{0.235\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=4.4cm]{pic/Figure_1.pdf}
%     \end{minipage}
% }
% \centering
%         \subfigure[Effects of $\lambda_{A}$]{
%     \begin{minipage}[t]{0.235\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=4.4cm]{pic/Figure_2.pdf}
%     \end{minipage}
% }
% \vspace{-0.2cm}
% 	  \caption{(a)-(b) show the results of distribution discrepancy test. (c)-(d) show the effect of hyper-parameters $\lambda_{O}$ and $\lambda_{A}$ on model performance. }
% 	  \label{fig1:param}
% 	 \vspace{-0.1cm} 
% \end{figure*}




% \begin{figure} 
% \centering
%         \subfigure[Effects of $\lambda_{R}$]{
%     \begin{minipage}[t]{0.235\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=6.4cm]{pic/Figure_1.pdf}
%     \end{minipage}
% }
% \centering
%         \subfigure[Effects of $\mathcal{H}$]{
%     \begin{minipage}[t]{0.235\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=6.4cm]{pic/Figure_2.pdf}
%     \end{minipage}
% }
% \vspace{-0.2cm}
% 	  \caption{(a)-(b) show the results of ablation test. (c)-(d) show the effect of hyper-parameters $\lambda_{R}$ and $\mathcal{H}$ on model performance. }
% 	  \label{fig1:param}
% 	 \vspace{-0.1cm} 
% \end{figure}




\subsection{Recommendation Performance}
%
\nosection{Results and discussion} 
%
The comparison results on different datasets are shown in Table.\ref{tab:xxx}. 
%
From that we can observe: (1) Single domain multi-modal recommendation models (e.g., \textbf{LATTICE} and \textbf{FREEDOM}) can enhance the model performance against conventional recommendation models (e.g., \textbf{LightGCN}).
%
However, these single-domain models cannot leverage useful knowledge across different domains and thus limits the model potentials.
%
(2) Conventional cross-domain recommendation models (e.g., \textbf{DisenCDR}) can provide better results than most of single-domain recommendation models (e.g., \textbf{LightGCN}) indicates the importance of leveraging useful knowledge across domains.
%
However, these methods did not incorporate multi-modal information, resulting in less expressive item embeddings. 
%
(3) Some latest multi-modal cross-domain recommendation models (e.g., \textbf{MOTKD}) achieve much better results against other baselines.
%
Nonetheless, \textbf{MOTKD} did not fully consider the guidance among these overlapped users for domain adaptation via optimal transport, and thus it may lead to ambiguous matching solutions and deteriorate the model performance.
%
(4) Our proposed \modelname~reaches state-of-the-art performance demonstrates the efficacy of similarity item exploration and overlapped user guidance.
%
Moreover, \modelname~can boost model performance even in cases where only relatively few users are overlapped (e.g., $\mathcal{K}_u = 10\%$) among different three tasks which is rather challenging. 
%
Furthermore, we collect HR@10 and NDCG@10 of the runner-up model \textbf{MOTKD} and our proposed \modelname~for Amazon Clothes and Amazon Sports with $\mathcal{K}_u = 90\%$ as shown in Fig.\ref{fig:exp1}.
%
We can observe that \modelname~reaches much better performance during the whole training epoch, showing the stability of \modelname. 




\begin{figure*}
\centering
\includegraphics[width=1\linewidth]{pic/wwwexp42_2.pdf}
% \vspace{-0.3cm} 
\caption{The experimental results on method extension.}
% \vspace{-0.2cm} 
\label{fig:exp2}
\end{figure*}

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{pic/wwwexpp_5.pdf}
% \vspace{-0.3cm} 
\caption{HR@10 and NDCG@10 of MOTKD and SIEOUG for Amazon Clothes and Amazon Sports with $\mathcal{K}_u = 90\%$.}
% \vspace{-0.3cm} 
\label{fig:exp1}
\end{figure}


\begin{figure}
\centering
\includegraphics[width=1\linewidth]{pic/wwws3_3.pdf}
% \vspace{-0.3cm} 
\caption{The experimental results on hyper parameters.}
% \vspace{-0.2cm} 
\label{fig:exp3}
\end{figure}


% \vspace{-0.2cm}


% \begin{figure*} 
%     \centering
    
%     \subfigure[Effects of $\tau$]{
%     \begin{minipage}[t]{0.23\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=4.4cm]{pic/kdd_exp1.pdf}
%     \end{minipage}
% }
%     \subfigure[Effects of $\epsilon$]{
%     \begin{minipage}[t]{0.23\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=4.4cm]{pic/kdd_exp3.pdf}
%     \end{minipage}
% }
%     \subfigure[Effects of $\kappa$]{
%     \begin{minipage}[t]{0.23\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=4.4cm]{pic/kdd_exp5.pdf}
%     \end{minipage}
% }
%     \subfigure[Effects of $\gamma$]{
%     \begin{minipage}[t]{0.23\linewidth} %0.23为minipage的宽度，可以调节子图间的距离
%     \includegraphics[width=4.4cm]{pic/kdd_exp7.pdf}
%     \end{minipage}
% }
%       \vspace{-0.2cm}
% 	  \caption{The hyper-parameters of $\tau$, $\epsilon$, $\kappa$, and $\gamma$ on \textbf{Movielens-1M} and \textbf{Yelp}.}
% 	  \vspace{-0.2cm}
% 	  \label{fig:tsne} 
% \end{figure*}


\subsection{Analysis (for RQ2 and RQ4)}

% \begin{table}[!t]
% \small
% \renewcommand\arraystretch{0.2}
% \centering
% \caption{Experimental results on method extension. }
% % \vspace{-0.3cm}
% \label{tab:douban12}
% \begin{tabular}{ccccccccc}
% \toprule
% \multirow{2}{*}{}
% & \multicolumn{2}{c}{\textbf{ Clothes} ($\mathcal{K}_u = 0\%$)}
% & \multicolumn{2}{c}{\textbf{ Sport} ($\mathcal{K}_u = 0\%$)} \\
% \cmidrule(lr){2-3} \cmidrule(lr){4-5} 
% &HR$@10$ &NDCG$@10$
% &HR$@10$ &NDCG$@10$\\

% \midrule
% % Duration &   \\ 
% CL-DTCDR & 0.0635 & 0.0312 & 0.0707 & 0.0424 \\ 
% MOTKD & 0.0680 & 0.0336 & 0.0754 & 0.0469 \\
% \modelname & 0.0769 & 0.0405 & 0.0841 & 0.0572  \\
% \bottomrule
% \end{tabular}
% %}
% \end{table}


\nosection{Ablation}
%
To study how does each module of \textbf{\modelname~}contribute on the final performance, we compare \textbf{\modelname}~with its several variants, including  \textbf{\modelname}-O, \textbf{\modelname}-M, and \textbf{\modelname}-G. 
%
\textbf{\modelname}-O does not involve overlapped user guidance module which means it functions as a single-domain recommendation model with $\lambda = 0$.
%
\textbf{\modelname}-M simply adopts the user contrastive loss among overlapped users.
%
\textbf{\modelname}-G replaces GOUM with conventional fused Gromov-Wasserstein optimal transport without guidance among source and target users.
%
The comparison results are shown in Table.\ref{tab:xxx}.
%
From it, we can observe that: (1) \textbf{\modelname}-O outperforms other single-domain recommendation models (e.g., \textbf{FREEDOM}) indicates our proposed similarity item exploration module can better exploit multi-modal information for solving \textbf{CH1} within each domains.
%
(2) By comparing the performance results of \textbf{\modelname} and \textbf{\modelname}-O, it shows that the results of \textbf{\modelname}-O are inferior to that of \textbf{\modelname} since it fails to transfer useful knowledge across domains via the overlapped users.
%
(3) \textbf{\modelname}-M and \textbf{\modelname}-G achieve much better performance than \textbf{\modelname}-O and other CDR baselines (e.g., \textbf{MOTKD}).
%
However, \textbf{\modelname}-M is limited by the number of overlapped users especially when $\mathcal{K}_u$ is much smaller.
%
Meanwhile \textbf{\modelname}-G fails to consider the guidance among the overlapped users and thus it could lead to negative transfer.
%
(4) \textbf{\modelname} achieves the better performance than \textbf{\modelname}-M, showing the proposed overlapped user guidance module can sufficiently share useful knowledge across domains for tackling \textbf{CH2}.  


% \nosection{Model Extension}
% %
% We further analyse the general extension of \modelname~on the scenario that source and target users are totally non-overlapped.
% %
% This implies that $\mathcal{K}_u = 0\%$, making this task quite challenging.
% %
% We conduct the corresponding experiments on Amazon Clothes $\leftrightarrow$ Amazon Sport and report the results in Table.???. 
% %
% We can observe that our proposed \modelname~still achieves the best performance against \textbf{MOTKD} and \textbf{CL-DTCDR}.
% %
% It shows that \modelname~can even handle the worst case when 


\nosection{Method Extension}
%
We further analyse the general extension of our proposed GOUM algorithm with guidance user contrastive loss in \modelname.
%
Specifically, we aim to integrate GOUM into the single-domain multi-modal recommendation models \textbf{LATTICE} and \textbf{LGM3Rec}, resulting in \textbf{LATTICE}+GOUM and \textbf{LGM3Rec}+GOUM.
%
Then we conduct the experiments on Amazon Food $\leftrightarrow$ Amazon Kitchen and Amazon Clothes $\leftrightarrow$ Amazon Home and report the results in Fig.\ref{fig:exp2}(a).
%
From this, we can observe that both \textbf{LATTICE}+GOUM and \textbf{LGM3Rec}+GOUM outperform the original models, indicating that the proposed method has strong generalization capabilities.  
%
Moreover, we analyse the extension of our proposed Similarity Item Exploration Module (SIEM) with item-item graph and hypergraph on \textbf{DURation} and \textbf{MOTKD} to construct \textbf{DURation}+SIEM and \textbf{MOTKD}+SIEM.
%
The results are shown in Fig.\ref{fig:exp2}(b) and both \textbf{DURation}+SIEM and \textbf{MOTKD}+SIEM boost the model performance, showing SIEM can be also applied to other models.

% \nosection{Visualization}
%




\nosection{Effect of hyper-parameters}
%
We finally study the effects of hyper-parameters on model performance in Amazon Clothes $\leftrightarrow$ Amazon Sport with user overlapped ratio $\mathcal{K}_u = 10\%$.
%
Specifically, we vary $\lambda$ in range of $\{0.2, 0.4, 0.5, 0.6, 0.8, 1.0\}$ and report the results of HR@10 and NDCG@10 in Fig.\ref{fig:exp3}(a).
%
We can observe that when $\lambda$ is smaller (e.g., $\lambda = 0.2$), the guidance user contrastive loss is less effective for knowledge transfer.
%
Meanwhile when $\lambda$ is larger (e.g., $\lambda = 1$), it may negatively impact the contrastive collaborative filtering loss in each domain, leading to deteriorated results.
%
Therefore we set $\lambda = 0.6$ empirically.
%
Moreover, we conduct the experiments on varying $\epsilon$ in range of $\{0.001, 0.01, 0.1, 1, 10, 100\}$ on GOUM and report the results of HR@10 and NDCG@10 in Fig.\ref{fig:exp3}(b).
%
We can conclude that the model can obtain better performance when $\epsilon$ is smaller which aligns with the limitation results in Eq.\eqref{equ:jielun}.
%
However, when $\epsilon$ increases, the approximate calculations may result in inaccurate matching solutions, compromising the overall accuracy.
%
Therefore we set $\epsilon = 0.1$ empirically for \modelname.

% \vspace{-0.3cm}


\section{Conclusion}
%
In this paper, we Joint Similarity Item Exploration and Overlapped User Guidance model (\textbf{\modelname}) for solving the Multi-Modal Cross-Domain Recommendation (MMCDR) problem, which includes the \textit{similarity item exploration module}, \textit{user-item collaborative filtering module}, and the \textit{overlapped user guidance module}.
%
Similarity item exploration module constructs item-item graph and hypergraph via proposed RISGF and SISHE algorithm from pair-wise and group-wise perspectives.
%
User-item collaborative filtering module further aggregates multi-modal information for user-item modeling within each domain.
%
Overlapped user guidance module realizes the knowledge transfer among the source and target users via GOUM with optimal matching accordingly.
%
By incorporating these three modules, \modelname~can not only fully exploit and utilize multi-modal item information, but also sharing useful knowledge to tackle data sparsity problem.
%
We also conduct extensive experiments on Amazon datasets to demonstrate the superior performance of our proposed \modelname~on several tasks under different overlapped user ratio.

\section{Acknowledgement}
%
This research was supported by Zhejiang Provincial Natural Science Foundation of China under Grant No.ZYQ25F020004.





 







\balance
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

\newpage

\appendix

% \section{Notation Table}

\begin{center}
    {\LARGE \textbf{Appendix}}
\end{center}

\section{Sparsity Item Similarity Hypergraph Exploration}

The algorithm of Sparsity Item Similarity Hypergraph Exploration (SISHE) is provided in Alg.1.

\begin{algorithm}[!h]
\begin{algorithmic}[1]
{
    \STATE {\textbf{Input:} $\boldsymbol{A}^d$: pair-wise item similarity graph in domain $d$; $K$: Number of clusters for constructing group-wise item hypergraph.
    }
    \STATE {Initialize the clustering matrix as $({\gamma}^{d})^{(0)}_{ij} = \frac{1}{K}$.}
    \FOR{$l = 0$ to $T-1$}
        \STATE {Calculate the matrix $(-{\boldsymbol{A}}^{d} (\boldsymbol{\gamma}^{d})^{(l)}\boldsymbol{I}_K) = \mathcal{Y}^{(l)}$.}
        
                \STATE {Update the value of  Lagrange multiplier $\boldsymbol{f}$ via Eq.\eqref{equ:9}. }
        
        \STATE {Update the value of  Lagrange multiplier $\boldsymbol{g}$ via Eq.\eqref{equ:10}. }
         \STATE {Update the clustering matrix via:
         \begin{equation} \nonumber
\begin{aligned} 
(\boldsymbol{\gamma}^{d})^{(l+1)}_{ij} = \left[ (f_i + g_j - \mathcal{Y}^{(l)}_{ij})/\eta \right]_+
\end{aligned}
\end{equation}
         }
        
    \ENDFOR
    
\STATE {\textbf{Return}: 
The clustering matrix $\boldsymbol{\gamma}^{d}$.}
}
\end{algorithmic}
\caption{The procedure scheme of Sparsity Item Similarity Hypergraph Exploration.}
\end{algorithm}


\begin{algorithm}[!h]
\begin{algorithmic}[1]
{
    \STATE {\textbf{Input:} $\epsilon$: The hyper parameter; $\boldsymbol{\mathcal{C}}$: The cost matrix; $\boldsymbol{\mathcal{M}}$: The guidance mask matrix.
    }
    \STATE {Adding the mask into the cost matrix via $\mathcal{C}_{ij} \odot \mathcal{M}_{ij} = \mathcal{Q}_{ij}$.}

    \STATE {Initialize $\widehat{\omega}^{(0)} = (0, \cdots,0)$.}
    

    \FOR{$\ell = 0$ to $T$}

    \STATE{Update $\widehat{\omega}^{(\ell+1)}$ via Eq.\eqref{equ:wafi1}.}

     

    \ENDFOR

     

   
 \STATE {Obtain the user-user matching results:
 \begin{equation}\nonumber
 \small
\begin{aligned}
\pi_{ij} = \frac{ \exp((\boldsymbol{\widehat{\omega}}_i - \mathcal{Q}_{ij})/\epsilon)}{\sum_{k=1}^N  \exp((\boldsymbol{\widehat{\omega}}_k - \mathcal{Q}_{kj})/\epsilon)}
\end{aligned}
\end{equation}
 }

 
\STATE {\textbf{Return}: 
The user-user matching matrix $\boldsymbol{\pi}$.}
}
\end{algorithmic}
\caption{The procedure scheme of Guidance-based Optimal User Matching.}
\end{algorithm}


\section{Guidance-based Optimal User Matching}

To start with, we first provide the optimization details on our proposed the Wasserstein Alternative Fixed-point Iteration (WAFI) approach.
%
That is, WAFI involves the fixed-point iteration method on solving $\boldsymbol{\widehat{\omega}}$ at the $\ell$-th epoch as shown below:
%
\begin{equation}  
\label{equ:6}
\begin{aligned}
&\left(\boldsymbol{\widehat{\omega}}^{(\ell+1)}_1, \cdots   \boldsymbol{\widehat{\omega}}^{(\ell+1)}_{N} \right) = \arg \min_{\boldsymbol{\widehat{\omega}}} \mathcal{J}_{\rm KP} \left(\boldsymbol{\widehat{\omega}}^{(\ell)}_1, \cdots, \boldsymbol{\widehat{\omega}}^{{\rm (\ell)}}_{N} \right)\\
&s.t.\,\,\boldsymbol{\widehat{\omega}}^{(\ell+1)}_{N} = \boldsymbol{\widehat{\omega}}^{(\ell)}_{N} = 0 = {\rm constant}
\end{aligned}
\end{equation}
%
Note that $\boldsymbol{\widehat{\omega}}^{(\ell+1)}_{N} = \boldsymbol{\widehat{\omega}}^{(\ell)}_{N} = 0$ is set to avoid multiple solutions on $\mathcal{J}_{\rm KP}$.
%
Specifically, the optimal solution on $\widehat{\omega}^{(\ell)}_i$ can be obtained via considering $\frac{\partial \mathcal{J}_{\rm KP}}{\partial \widehat{\omega}^{(\ell)}_i} = 0$ as follows:
%
\begin{equation} 
\label{equ:kpx}
\begin{aligned}
\exp \left( \frac{\widehat{\omega}_i  }{\epsilon}  \right)\sum_{j=1}^N  \left[\frac{ b_j \exp \left( -\frac{ \mathcal{Q}_{ij}}{\epsilon}  \right)}{\sum_{k=1}^N \exp \left( \frac{\widehat{\omega}_k - \mathcal{Q}_{kj}}{\epsilon}  \right) } \right]  = a_i 
\end{aligned}
\end{equation}
%
That is, the first step of WAFI calculation is shown as (when $i \neq N$):
%
\begin{equation}
\label{equ:wafi1}
\begin{aligned}
\widehat{\omega}^{(\ell+1)}_i & = \epsilon \left[ \log \left(a_i \right) - \log \left(  \sum_{j=1}^N   \left[ \frac{ b_j\exp \left( -\frac{ \mathcal{Q}_{ij}}{\epsilon} \right) }{\sum\limits_{k=1}^N \exp \left( \frac{\widehat{\omega}^{(\ell)}_k - \mathcal{Q}_{kj}}{\epsilon} \right) } \right]  \right) \right] \\& = \mathscr{F}_i \left(\widehat{\omega}^{(\ell)}_1,  \cdots, \widehat{\omega}^{(\ell)}_i, \cdots, \widehat{\omega}^{{\rm (\ell)}}_{N} \right)\\
& = \mathscr{F}_i\left(\boldsymbol{\widehat{\omega}}^{(\ell)} \right)
\end{aligned}
\end{equation}
%
When $i = N$ we have:
\begin{equation}
\label{equ:wafi2}
\begin{aligned}
\widehat{\omega}^{(\ell+1)}_N = 0
\end{aligned}
\end{equation}

\nosection{Convergence Analysis}
%
We first take the differentiation on $\mathscr{F}_1 $ w.r.t. $\widehat{\omega}^{(\ell)}_1$ accordingly:
%
\begin{equation}  
\begin{aligned}
&\frac{\partial \mathscr{F}_1  }{\partial \widehat{\omega}^{(\ell)}_1}  = -\epsilon \frac{1}{\sum\limits_{j=1}^N   \left[ \frac{ b_j \exp \left( -\frac{ \mathcal{Q}_{1j}}{\epsilon} \right) }{ \mathcal{M}_{\rm Kernel} } \right] } \frac{\partial  }{\partial \widehat{\omega}^{(\ell)}_1} \left( \sum\limits_{j=1}^N   \left[ \frac{ b_j \exp \left( -\frac{ \mathcal{Q}_{1j}}{\epsilon} \right) }{ \mathcal{M}_{\rm Kernel} } \right] \right) \\
& =   \frac{1}{\sum\limits_{j=1}^N   \left[ \frac{ b_j \exp \left( -\frac{ \mathcal{Q}_{1j}}{\epsilon} \right) }{ \mathcal{M}_{\rm Kernel} } \right] } \sum_{j=1}^N \left[ \frac{b_j \exp \left( -\frac{ \mathcal{Q}_{1j}}{\epsilon} \right)  }{  \mathcal{M}_{\rm Kernel} } \cdot \frac{ \exp \left(  \frac{ \widehat{\omega}^{(\ell)}_1 - \mathcal{Q}_{1j}}{\epsilon} \right)}{  \mathcal{M}_{\rm Kernel} }  \right]\\&   \in (0,1)
\end{aligned}
\end{equation}
%
where $\mathcal{M}_{\rm Kernel} = \sum\limits_{k=1}^N \exp \left( \frac{\widehat{\omega}^{(\ell)}_k - \mathcal{Q}_{kj}}{\epsilon}  \right)$ and we can observe that $\frac{\partial \mathscr{F}_u }{\partial \widehat{\omega}^{(\ell)}_v} \in (0,1)$.
%
Here we should notice that:
\begin{equation}  
\begin{aligned}
\frac{\partial \mathscr{F}_1 }{\partial \widehat{\omega}^{(\ell)}_N} = 0
\end{aligned}
\end{equation}
%
Finally we can obtain that:
\begin{equation}  
\begin{aligned}
0 < \left|\frac{\partial \mathscr{F}_1  }{\partial \widehat{\omega}^{(\ell)}_1}\right| +  \left|\frac{\partial \mathscr{F}_1  }{\partial \widehat{\omega}^{(\ell)}_2}\right| + \cdots + \left|\frac{\partial \mathscr{F}_1  }{\partial \widehat{\omega}^{(\ell)}_N}\right| < 1
\end{aligned}
\end{equation}
%
Therefore, we can conclude that the proposed method guarantees convergence according to Theorem 2.9 in \cite{mathews2004numerical}.
The algorithm of Guidance-based Optimal User Matching (GOUM) with WAFI is provided in Alg.2.


% \section{Experiments}

\begin{table}[!h]
\small
  \centering
  \caption{Statistics on Douban and Amazon datasets.}
    % \vspace{-0.3cm}
    \begin{tabular}{cccccc}
    \hline
    
    \multicolumn{2}{c}{ \textbf{Datasets} } & \textbf{Users} & \textbf{Items} &  \textbf{Ratings} & \textbf{Sparsity}\\
    
    \hline
    
    \multirow{2}{*}{\textbf{Task 1}} & Amazon Clothes & \multirow{2}{*}{9,202} & 10,652     & 83,130    & 99.92\% \\
          & Amazon Sports &       & 10,219    & 84,013    & 99.91\% \\

\hline

    \multirow{2}{*}{\textbf{Task 2}} & Amazon Clothes & \multirow{2}{*}{6,548} &  7,266     &  55,789     & 99.88\% \\
         & Amazon Home  &       &  8,418     &  71,171     & 99.87\% \\
    
    \hline
    
    \multirow{2}{*}{\textbf{Task 3}} & Amazon Food & \multirow{2}{*}{9,815} &  9,949     &  135,634     & 99.86\%  \\
         &Amazon Kitchen  &       & 14,680      &  154,152     & 99.89\% \\
    
    \hline 

    \end{tabular}%
  \label{tab:datasetss}%
\end{table}%


\section{EMPIRICAL STUDY} 

\nosection{Datasets and Tasks}
%
We conduct extensive experiments on commonly used real-world \textbf{Amazon} datasets.
%
The \textbf{Amazon} dataset \cite{amazon} has five domains, i.e., Clothing Shoes and Jewelry (Clothes), Sports and Outdoors (Sports), Tools and Home Improvement (Home), Grocery and Gourmet Food (Food), and Home and Kitchen (Kitchen). 
%
For each dataset, we binarize the ratings higher or equal to 4 as 1 and the rest as 0 following \cite{vade}.
%
Then we filter the users and items with less than 10 interactions.
%
The detailed datasets statistics after prepossessing are shown in Table \ref{tab:datasetss}.
%

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{pic/wwweee.pdf}
% \vspace{-0.3cm} 
\caption{The experimental results on number of clusters $K$.}
% \vspace{-0.2cm} 
\label{fig:expx}
\end{figure}

\nosection{Baseline}
%
We compare our proposed \textbf{\modelname~}with the following state-of-the-art models. 
%
(1) \textbf{NeuMF} \cite{neumf} first utilizes deep neural networks for collaborative filtering in the single domain.
%
(2) \textbf{LightGCN} \cite{lightgcn} first adopts graph convolution network to further enhance intra-domain model performance.
%
(3) \textbf{LATTICE} \cite{zhang2021mining} first exploits the similarity graph among multi-modal item information for user-item modeling.
%
(4) \textbf{FREEDOM} \cite{zhou2023tale} further aggregates multi-modal information with denoising mechanism.
%
(5) \textbf{LGM3Rec} \cite{guo2024lgmrec} utilizes local and global graph learning methods for multimodal recommendation.
%
(6) \textbf{DisenCDR} \cite{cao2022disencdr} adopts variational disentangle mechanism for cross domain recommendation among overlapped users.
%
(7) \textbf{ETL} \cite{etl} utilizes dual autoencoder framework with equivalent transformation component across domains.
%
(8) \textbf{VDEA} \cite{vade} exploits domain-invariant user preferences with co-clustering methods across domains.
%
(9) \textbf{DURation} \cite{duration} adopts distribution variance and correlation alignment to obtain unified representations. 
%
(10) \textbf{CL-DTCDR} \cite{lu2023contrastive} adopt dual-target contrastive learning method for cross domain recommendation.
%
(11) \textbf{MOTKD} \cite{yang2023multimodal} is the state-of-the-art model which adopting optimal transport for multi-modal cross domain recommendation.
%

\nosection{Effect of hyper-parameters}
%
We also vary the number of cluster $K$ in range of $K \in \{5,10,15,20,30\}$ in Amazon Clothes and Home with $\mathcal{K}_u = 50\%$ and report the results (HR and NDCG) in Fig.\ref{fig:expx}.
%
We observe that as the number of clusters increases, performance improves significantly.
%
However, when the number of clusters reaches a certain value as $K=15$, its growth effect slows down.
%
Meanwhile, a large number of clusters can also lead to increased computational burdens.
%
Therefore we set $K = 15$ empirically.

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
