\section{Related Work}
\nosection{Multi-Modal Recommendation}
%
Multi-Modal recommendation is set to involve multi-modal information (e.g., the item image and text descriptions) for user-item modelling \cite{zhu2024multimodal,zhong2024mirror,liu2023multimodal,mu2022learning,tao2022self}.
%
Conventional work \cite{he2016vbpr,zhang2019deep,wei2019mmgcn} directly fused the visual/style contents with their ID embeddings with Bayesian personalized ranking \cite{bpr} for collaborative filtering.
%
Nowadays, with the fast development of graph neural network \cite{lightgcn}, more researchers started to utilize the message passing mechanism among knowledge aggregation across different modalities \cite{wei2019mmgcn,wang2021dualgnn,wei2020graph}.
%
For instance, \textbf{LATTICE} \cite{zhang2021mining} first constructs an pair-wise item-item relation graph within each modality and then aggregates them to form a global item-item graph.
%
Recently some work \cite{zhou2023bootstrap} also adopt contrastive learning strategy \cite{wang2022towards} with attention mechanism to further boost the model performance.
%
Latest work \textbf{LGM3Rec} \cite{guo2024lgmrec} has even adopted Gumbel-Softmax with hypergraph relationships to enhance the model's performance by capturing group-wise high-order semantic information.
%
However, current multi-modal recommendation models fail to extract or cluster item with similar characteristics in the group-wise perspectives, which is vital for user-item modelling.  






\nosection{Cross-Domain Recommendation}
%
Cross Domain Recommendation (CDR) models are set to tackle the data sparsity problem by leveraging useful knowledge across domains \cite{khan2017cross,cao2022cross,ddtcdr,dml,zhao2023cross,du2024identifiability}.
%
Traditional CDR models mainly rely on the overlapped users to realize the knowledge transfer \cite{zang2022survey,chen2024survey,li2024aiming,xu2024rethinking}.
%
For instance, \textbf{CoNet} \cite{conet} and \textbf{ACDN} \cite{liu2020exploiting} adopted the cross-connection unit with attention mechanism in the deep neural network for snitching the message from different domains.
%
However these approaches cannot handle the general case when few users are overlapped \cite{recdan,tdar,cdrsurvey}.
%
Recently some work \cite{darec,zhang2021learning} start to investigate that scenario with domain adaptation strategies including adversarial training \cite{gan} or distribution co-clustering \cite{vade}.
%
Meanwhile, only a few papers focus on addressing the multi-modal cross-domain recommendation problem, as multi-modal information amplifies domain discrepancies, making the task even more challenging.
%
Latest, \textbf{MOTKD} \cite{yang2023multimodal} is the first to attempt solving the MMCDR problem using an optimal transport approach \cite{gu2022keypoint,courty2016optimal,khamis2024scalable,li2022gromov,damodaran2018deepjdot}.
%
Nonetheless, the above methods typically separate domain adaptation for overlapped and non-overlapped users, neglecting the matching guidance provided by the overlapped users.
%
Therefore, they may lead to negative transfer, resulting in suboptimal solutions that hinder model performance.


 

\begin{figure*}
\centering
\includegraphics[width=0.95\linewidth]{pic/wwwuuu_6.pdf}
% \vspace{-0.7cm} 
\caption{The model framework of proposed \modelname~for solving MMCDR problem.}
% \xenia{indicate group, A is used for hypergraph, scalar $\alpha$}}
% \vspace{-0.5cm} 
\label{fig:sig}
\end{figure*}