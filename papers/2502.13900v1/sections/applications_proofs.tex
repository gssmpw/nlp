\section{Omitted proofs for Section~\ref{sec:application}}
\label{app:proof_IL}

To improve readability, we define the feature expectation vector as $\lambda(\pi) = \phim_r\transpose \mu(\pi)$ for any policy $\pi$, where $\mu(\pi_k)$ denotes the occupancy measure of policy $\pi_k$. This notation will be used in the following proofs.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Proof of Theorem~\ref{thm:FraUpper} (guarantee for the output of Algorithm~\ref{alg:fra})}

\FraUpper*

\begin{proof}
    Using the decomposition presented in \Cref{sec:application}, we can express the regret as
    %
    \begin{equation*}
        (1 - \gamma) \regretIL = \underbrace{\sum^K_{k=1} \innerprod{r_k}{\mu\brr{\expert} - \mu\brr{\pi_k}}}_{(1-\gamma)\regretK^\pi(\mu\brr{\expert})} + \underbrace{\sum^K_{k=1} \innerprod{\Phi\transpose\mu(\pi_k) - \Phi\transpose\mu(\expert)}{w_k - w_{\mathrm{true}}}}_{(1-\gamma)\regretK^w(w_{\mathrm{true}})} \label{eq:dec}\,.
    \end{equation*}
    %
    By bounding $\regret^w(w_{\mathrm{true}})$ and $\regret^\pi(\mu(\expert))$ using \Cref{thm:reward_regret_bound} and \Cref{thm:main}, respectively, we obtain that with probability $1 - 3 \delta$
    %
    \begin{align*}
        \frac{1}{K} \regretIL &\leq  10 H (B \WMAX+\RMAX) \sqrt{ \frac{\log \delta^{-1}}{K}} + 24 H\WMAX B \sqrt{\frac{ \log\brr{\frac{1}{\delta}}}{\tau_E}} \\&\phantom{=}+ \tilde{\mathcal{O}}(d^{3/2}(1 - \gamma)^{-9/4} \log^{1/2} \abs{\aspace} K^{-1/2})\,.
    \end{align*}
    %
    Therefore, by considering $B$ and $\RMAX$ as constants and choosing $K = \widetilde{\mathcal{O}}\brr{\frac{ d^{3} \log (\abs{\aspace}\delta^{-1})}{(1 - \gamma)^{4.5}\varepsilon^2}}$ and $\tau_E = \widetilde{\mathcal{O}}\brr{\frac{ \WMAX^2 \log(1/\delta)}{(1 - \gamma)^2\varepsilon^2}}$ we have that with probability $1 - 3 \delta$ it holds that
    %
    \begin{equation*}
        \frac{1}{K} \regretIL \leq 4 \epsilon\,.
    \end{equation*}
    %
    Since $\frac{1}{K} \regretIL$ is a random variable bounded by $(1-\gamma)^{-1}$ almost surely, in expectation we have the following bound
    %
    \begin{equation*}
        \bbE_{\mathrm{Alg}} \bs{\frac{1}{K} \regretIL} \leq \frac{3 \delta}{1-\gamma} + 4 \varepsilon\,.
    \end{equation*}
    %
    Thus, by choosing $\delta \leq \nicefrac{\varepsilon}{3(1-\gamma)}$ we can conclude that
    %
    \begin{equation*}
        \bbE_{\mathrm{Alg}} \bs{\frac{1}{K} \regretIL} \leq 5 \varepsilon\,.
    \end{equation*}
    %
    Finally, by selecting $\pi^{\mathrm{out}}$ uniformly at random from the policies generated by \Cref{alg:fra} 
    we have that
    \begin{equation*}
        \bbE_{\mathrm{Alg}} \innerprod{\initial}{V_{\true}^{\expert} - V_{\true}^{\pi^{\mathrm{out}}}} \leq 5 \varepsilon\,.
    \end{equation*}
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Proof of Theorem~\ref{thm:reward_regret_bound} (regret bound for the reward player)}

\begin{restatable}{theorem}{regretreward} \label{thm:reward_regret_bound}
    Assume that $w_{\mathrm{true}} \in \cW$ for some non-empty closed convex set $\cW$ and that for any $w \in \cW$, $\norm{w}\leq \WMAX$. Then, OGD with $\eta_r = \nicefrac{\WMAX}{B \sqrt{K}}$ ran for $K$ iterations satisfies with probability at least $1 - 2 \delta$ that
    %
    \begin{equation*}
        \regretK^w(w_{\mathrm{true}}) \leq 10 H (B \WMAX + \RMAX) \sqrt{K \log 1 / \delta} + 24 H \WMAX K B \sqrt{\frac{\log\brr{\frac{1}{\delta}}}{\tau_E}}\,.
    \end{equation*}
\end{restatable}

\begin{proof}
    Given the definition of the feature expectation vector $\lambda (\pi)$, we can rewrite the regret for the reward player as follows
    %
    \begin{equation*}
        \spr{1 - \gamma} \regret^w(w_{\mathrm{true}}) = \sum^K_{k=1} \innerprod{\lambda(\pi_k) - \lambda(\expert)}{w_k - w_{\mathrm{true}}}\,.
    \end{equation*}
    %
    Then, adding and subtracting the estimators for the occupancy measures, we get
    %
    \begin{align*}
        (1-\gamma) \regret^w(w_{\mathrm{true}}) &= \sum^K_{k=1} \innerprod{\phi_\cost(X_k, A_k) - \widehat{\lambda(\expert)}}{w_k - w_{\mathrm{true}} } \\
        &\phantom{=}+ \sum^K_{k=1} \innerprod{\lambda(\pi_k) - \phi_\cost(X_k, A_k)}{w_k - w_{\mathrm{true}}} \\
        &\phantom{=}+ \sum^K_{k=1} \innerprod{\widehat{\lambda(\expert)} - \lambda(\expert)}{ w_k-w_{\mathrm{true}}}\,.
    \end{align*}
    %
    Now, using the regret bound for OGD \citep{Zin03}, we can bound the first term in the decomposition above as
    %
    \begin{align*}
        \sum^K_{k=1} &\innerprod{\phi_\cost(X_k, A_k) - \widehat{\lambda(\expert)}}{w_k-w_{\mathrm{true}} } \\&\leq  \frac{\max_{w\in\mathcal{W}}\norm{w_{\mathrm{true}} - w_1}_2^2}{2 \eta_r} + \frac{\eta_r}{2} \sum^K_{k=1} \norm{\widehat{\lambda(\expert)} - \phi_\cost(X_k, A_k)}_2^2 \\
        &\leq \frac{2 \WMAX^2}{\eta_r} + 2 \eta_r B^2 K\,,
    \end{align*}
    %
    Looking at the term $\sum^K_{k=1} \innerprod{\lambda (\pi_k) - \phi_\cost (X_k, A_k)}{w_k - w_{\mathrm{true}}}$, we notice that
    %
    \begin{equation*}
        \psi_k = \innerprod{\lambda(\pi_k) - \phi_\cost(X_k, A_k)}{w_k - w_{\mathrm{true}}}
    \end{equation*}
    %
    is a martingale difference sequence such that
    %
    \begin{equation*}
        \abs{\innerprod{\lambda(\pi_k) - \phi_\cost(X_k, A_k)}{w_k - w_{\mathrm{true}}}} \leq  4 \RMAX\,.
    \end{equation*}
    %
    Applying Azuma-Hoeffding's inequality, we have that with probability $1 - \delta$
    %
    \begin{equation*}
        \sum^K_{k=1} \innerprod{\lambda(\pi_k) - \phi_\cost(X_k, A_k)}{w_k - w_{\mathrm{true}}} \leq \RMAX \sqrt{8  K \log \brr{\frac{1}{\delta}}}.
    \end{equation*}
    %
    Then, plugging in this bound in the regret decomposition we obtain
    %
    \begin{align*}
        (1-\gamma) \regret^w(w_{\mathrm{true}}) &\leq \frac{2 \WMAX^2}{\eta_r} + 2 \eta_r B^2 K + \RMAX \sqrt{8K \log 1 / \delta} \\
        &\phantom{=}+ \sum^K_{k=1} \innerprod{\widehat{\lambda(\expert)} - \lambda(\expert)}{ w_k-w_{\mathrm{true}}}\,.
    \end{align*}
    %
    Then, we treat the last term using Cauchy-Schwartz's inequality
    %
    \begin{align*}
        \sum^K_{k=1} \innerprod{\widehat{\lambda(\expert)} - \lambda(\expert)}{ w_k-w_{\mathrm{true}}} &\leq \sum^K_{k=1}\norm{w_{\mathrm{true}}-w^k}_{2}\norm{\widehat{\lambda(\expert)} - \lambda(\expert)}_2 \\
        &\leq 2 \WMAX K \norm{\widehat{\lambda(\expert)} - \lambda(\expert)}_2\,.
    \end{align*}
    %
    It remains to find a high probability (dimension-free) upper bound on $\norm{\widehat{\lambda(\expert)} - \lambda(\expert)}_{2}$. First, notice that $\norm{\widehat{\lambda(\expert)} - \lambda(\expert)}_{2} = \norm{(\tau_E)^{-1} \brr{\sum^{\tau_E}_{i=1} \phi_\cost(X^i_E,A^i_E) - \lambda(\expert) }}_2$. Then, we use the notation $u_{x,a} = \phi_\cost(x,a) - \lambda(\expert) $ for all state action pairs $x,a$ and using that for all $x, a \in \cX \times \cA$, $\norm{\phi_\cost(x, a)}_2 \leq B$, we have
    %
    \begin{equation*}
        \sum^{\tau_E}_{i=1} \mathbb{E}\bs{\norm{u_{X^i_E,A^i_E}}_2^2} \leq \sum^{\tau_E}_{i=1} \mathbb{E}\bs{\norm{\phi_\cost(X^i_E, A^i_E) - \lambda(\expert)}_2^2} \leq 4\tau_E B^2\,.
    \end{equation*}
    %
    Moreover, for any $x, a \in \cX \times \cA$, $\norm{u_{x,a}} \leq 2 B$ and $\bbE \bs{u_{X^i_E, A^i_E}} = 0$ because of the distribution of the dataset $\mathcal{D}_\expert $. Thus, by applying \cite[Proposition 2]{hsu2012tail}, it holds that for all $t > 0$
    %
    \begin{equation*}
        \mathbb{P}\bs{\norm{\sum^{\tau_E}_{i=1} u_{X^i_E, A^i_E}} > \sqrt{4 \tau_E} B + \sqrt{32 \tau_E t} B + (8/3)2Bt} \leq e^{-t}
    \end{equation*}
    %
    Therefore, choosing $t = \log \frac{1}{\delta}$, we obtain that with probability $1 - \delta$
    %
    \begin{align*}
        \norm{\sum^{\tau_E}_{i=1} \phi_\cost(X^i_E, A^i_E) - \lambda(\expert)} &\leq \sqrt{4 \tau_E} B + \sqrt{32 \tau_E \log\brr{\frac{1}{\delta}}} B + \frac{16 B}{3}  \log\brr{\frac{1}{\delta}} \\
        &\leq 6 B \sqrt{\tau_E \log\brr{\frac{1}{\delta}}} + \frac{16 B}{3} \log \brr{\frac{1}{\delta}}\,.
    \end{align*}
    %
    Then, dividing by $\tau_E$ we obtain that
    %
    \begin{align*}
        \norm{\widehat{\lambda(\expert)} - \lambda(\expert)}_{2} \leq 6 B \sqrt{\frac{\log\brr{\frac{1}{\delta}}}{\tau_E}} + \frac{16 B}{3 \tau_E} \log\brr{\frac{1}{\delta}}\,.
    \end{align*}
    %
    Then, for $\tau_E \geq \frac{64}{18^2} \log \frac{1}{\delta}$, we have that
    %
    \begin{equation*}
        6 \sqrt{\frac{\log\brr{\frac{1}{\delta}}}{\tau_E}} \geq \frac{8}{3 \tau_E} \log\brr{\frac{1}{\delta}}\,,
    \end{equation*}
    %
    and hence that with probability $1 - \delta$,
    %
    \begin{align*}
        \norm{\widehat{\lambda(\expert)} - \lambda(\expert)}_{2} \leq 12 B \sqrt{\frac{\log\brr{\frac{1}{\delta}}}{\tau_E}}\,.
    \end{align*}
    Thus, by a union bound and choosing $\eta_r = \nicefrac{\WMAX}{B \sqrt{K}}$, we have that with probability $1 - 2 \delta$,
    \begin{align*}
        (1-\gamma) \regret^w(w_{\mathrm{true}}) &= 4 B \WMAX \sqrt{K} +  \RMAX\sqrt{8 K \log \delta^{-1}} + 24 \WMAX B K \sqrt{ \frac{\log\brr{\frac{1}{\delta}}}{\tau_E}} \\
        &\leq 10 (B \WMAX + \RMAX) \sqrt{K \log \delta^{-1}} + 24 \WMAX K B \sqrt{\frac{\log \brr{\frac{1}{\delta}}}{\tau_E}}\,.
    \end{align*}
\end{proof}
