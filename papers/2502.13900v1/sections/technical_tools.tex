\section{Technical tools}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reinforcement learning}

\begin{proposition}\label{prop:flow}
  The occupancy measure $\mu(\pi)$ of any policy $\pi$ satisfies the following system of equations:
  %
  \begin{equation}\label{eq:flow}
      E\transpose \mu \spr{\pi} = \gamma P\transpose \mu \spr{\pi} + \spr{1 - \gamma} \nu_0\,.
  \end{equation}
\end{proposition}

\begin{proof}
  Define the transition kernel induced by policy $\pi$ as $P_\pi$, with $P_\pi(\cdot|x) = \mathbb{E}_{A\sim\pi(\cdot|x)}\sbr{P(\cdot|x,A)}$. The proof follows from the following standard calculation:
  \begin{align*}
    E\transpose \mu \spr{\pi} &= (1-\gamma) \sum_{\tau=0}^\infty \pa{\gamma P_\pi\transpose}^\tau \nu_0 \\
    &= (1-\gamma) \sum_{\tau=1}^\infty \pa{\gamma P_\pi\transpose}^\tau \nu_0 + (1-\gamma) \nu_0 \\
    &= \gamma P_\pi (1-\gamma) \sum_{\tau=0}^\infty \pa{\gamma P_\pi\transpose}^\tau \nu_0 + (1-\gamma) \nu_0 \\
    &= \gamma P_\pi E\transpose \mu \spr{\pi} + (1-\gamma) \nu_0 \\
    &= \gamma P \mu \spr{\pi} + (1-\gamma) \nu_0,
  \end{align*}
  %
  where the last step follows from the easily-checked fact that $P \mu \spr{\pi} = P_\pi E\transpose \mu \spr{\pi}$.
\end{proof}


\begin{lemma}\label{lem:from-ev-to-q}
  Let $\pi$ be any policy, $Q \in \bbR^{\cX \times \cA}$ be any function defined on $\cX \times \cA$, and $V \in \bbR^\cX$ be such that for any $x$, $V \spr{x} = \bbE_{A \sim \pi \spr{\cdot \given x}} \sbr{Q \spr{x, A}}$. Then
  %
  \begin{equation*}
    \inp{\mu \spr{\pi}, \opE V} = \inp{\mu \spr{\pi}, Q}\,.
  \end{equation*}
\end{lemma}

\begin{proof}
  We have
  %
  \begin{align*}
    \inp{\mu \spr{\pi}, \opE V} &= \sum_{x \in \cX} \nu \spr{\pi, x} V \spr{x} \\
    &= \sum_{x \in \cX} \sum_{a \in \cA} \nu \spr{\pi, x} \pi \spr{a \given x} Q \spr{x, a} \\
    &= \sum_{x \in \cX} \sum_{a \in \cA} \mu \spr{\pi, x, a} Q \spr{x, a} \\
    &= \inp{\mu \spr{\pi}, Q}\,,
  \end{align*}
  %
  where the second equality follows from the definition of the function $V$ and the first equality from the definition of the state-action occupancy measure.
\end{proof}

\begin{lemma}\label{lem:ineq-kl-entropy}
    Let $\pi$ and $\pi'$ be two policies. Then,
    %
    \begin{equation*}
      \KL \spr{\mu \spr{\pi} \middle\| \mu \spr{\pi'}} \leq \frac{1}{1 - \gamma} \inp{\nu \spr{\pi}, \KL \spr{\pi \| \pi'}}\,.
    \end{equation*}
  \end{lemma}
  
\begin{proof}
  Using the chain rule of the relative entropy, we write
  %
  \begin{equation*}
      \KL \spr{\mu \spr{\pi} \middle\| \mu \spr{\pi'}} = \KL \spr{\nu \spr{\pi} \middle\| \nu \spr{\pi'}} + \inp{\nu \spr{\pi}, \KL \spr{\pi \middle\| \pi'}}\,.
  \end{equation*}
  %
  By the flow constraints and the joint convexity of the relative entropy, we bound the first term as
  %
  \begin{align*}
    \KL \spr{\nu \spr{\pi} \middle\| \nu \spr{\pi'}} &= \KL \spr{\gamma P\transpose \mu \spr{\pi} + \spr{1 - \gamma} \nu_0 \middle\| \gamma P\transpose \mu \spr{\pi'} + \spr{1 - \gamma} \nu_0} \\
    &\leq \spr{1 - \gamma} \KL \spr{\nu_0 \middle\| \nu_0} + \gamma \KL \spr{P\transpose \mu \spr{\pi} \middle\| P\transpose \mu \spr{\pi'}} \\
    &= \gamma \KL \spr{P\transpose \mu \spr{\pi} \middle\| P\transpose \mu \spr{\pi'}} \\
    &\leq \gamma \KL \spr{\mu \spr{\pi} \middle\| \mu \spr{\pi'}}\,,
  \end{align*}
  %
  where we also used the data-processing inequality in the last step. The proof is concluded by reordering the terms.
\end{proof}

\begin{lemma} \label{lem:mass-reduced}
  For any MDP $\cM$, any ascension function $p^\upplus$, and any policy $\pi$, we have for any state-action pair $\spr{x, a} \in \cX \times \cA$,
  %
  \begin{equation*}
    \mu^\upplus \spr{\pi, x, a} \leq \mu \spr{\pi, x, a}\,,
  \end{equation*}
  %
  where $\mu^\upplus \spr{\pi}$ denotes the state-action occupancy of $\pi$ in $\cM^\upplus$, the optimistically augmented MDP induced by $p^\upplus$.
\end{lemma}

\begin{proof}
  Let us consider a process  $\spr{X_\tau, A_\tau}_{\tau \in \bbN}$ generated by the policy $\pi$ in the MDP $\cM$, that is, such that $X_0 \sim \initial$, and for any $\tau \in \bbN$, $A_\tau \sim \pi \spr{\cdot \given X_\tau}$, and $X_{\tau+1} \sim P \spr{\cdot \given X_\tau, A_\tau}$. Additionally, we define a process $\spr{X_\tau^\upplus, A_\tau^\upplus}_{\tau \in \bbN}$ coupled to the process defined above as follows. At the first stage, we set $X_\tau^\upplus = X_0$. Then for any $\tau \geq 1$, the coupled process evolves as
  %
  \begin{equation*}
    X_{\tau+1}^\upplus, A_{\tau+1}^\upplus =
    \begin{cases}
        X_{\tau+1}, A_{\tau+1} \quad &\text{w.p.} \quad 1 - p^\upplus \spr{X_\tau, A_\tau} \quad \text{if} \quad  X_\tau^\upplus, A_\tau^\upplus = X_\tau, A_\tau \\
        x^\upplus, a \quad & \text{w.p.} \quad p^\upplus \spr{X_\tau, A_\tau} \quad \text{if} \quad  X_\tau^\upplus, A_\tau^\upplus = X_\tau, A_\tau \\
        x^\upplus, a \quad & \text{if} \quad X_\tau^\upplus, A_\tau^\upplus \neq X_\tau, A_\tau
    \end{cases}\,.
  \end{equation*}
  %
  It is straightforward to check that this process follows the dynamics of the optimistically augmented MDP $\cM^\upplus(r,p^\upplus)$ (since its transitions obey the kernel $P^\upplus$). By definition, for any state-action pair $\spr{x, a} \in \cX \times \cA$, we have
  %
  \begin{align*}
    \mu^\upplus \spr{\pi, x, a} &= \spr{1 - \gamma} \sum_{\tau=0}^\infty \gamma^\tau \bbP \sbr{X_\tau^\upplus = x, A_\tau^\upplus = a} \\
    &= \spr{1 - \gamma} \sum_{\tau=0}^\infty \gamma^\tau \spr{\bbP \sbr{X_\tau^\upplus = x, A_\tau^\upplus = a, X_\tau^\upplus \neq x^\upplus} + \bbP \sbr{X_\tau^\upplus = x, A_\tau^\upplus = a, X_\tau^\upplus = x^\upplus}} \\
    &= \spr{1 - \gamma} \sum_{\tau=0}^\infty \gamma^\tau \spr{\bbP \sbr{X_\tau = x, A_\tau = a, X_\tau^\upplus \neq x^\upplus} + 0} \\
    &\leq \spr{1 - \gamma} \sum_{\tau=0}^\infty \gamma^\tau \bbP \sbr{X_\tau = x, A_\tau = a} \\
    &= \mu \spr{\pi, x, a}\,.
  \end{align*}
  %
  In the third equality, the second term within the sum is equal to zero because $x \neq x^\upplus$, and in the other term we replaced $\spr{X_\tau^\upplus, A_\tau^\upplus}$ by $\spr{X_\tau, A_\tau}$ because the two coincide long as $X^\upplus_\tau \neq x^+$. This concludes the proof.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Linear algebra and analysis}

\begin{lemma} \label{lemma:number-epochs-bound}
    Under the event $\cE_L$, the number of epochs $E \spr{K}$ in Algorithm~\ref{alg:linear-rmax-ravi-ucb} is bounded as
    %
    \begin{equation*}
      E \spr{K} \leq 5 d \log \spr{1 + \frac{B^2 T}{d}}\,.
    \end{equation*}
    %
    where $T = \LMAX K = \frac{\log \spr{\frac{K}{\delta}} K}{1 - \gamma}$.
\end{lemma}

\begin{proof}
    In the following, we denote $\phi_t = \phi \spr{x_t, a_t}$ for any $t$. The bound on the number of epochs is derived observing that since the determinant of the matrix $\Lambda_k$ can grow at most linearly then the condition is triggered at most a logarithmic number of times. In particular notice that
    %
    \begin{equation*}
        \det \spr{\Lambda_{t_{E \spr{K}}}} \geq 2 \det \spr{\Lambda_{t_{E \spr{K} - 1}}} \geq 2^2 \det \spr{\Lambda_{t_{E \spr{K} - 2}}} \geq 2^{E \spr{K} - 1} \det \spr{I} = 2^{E \spr{K} - 1}\,.
    \end{equation*}
    %
    Hence, it holds that $E \spr{K} - 1 \leq \frac{1}{\log 2} \log \spr{\det \Lambda_{t_{E \spr{K}}}}$. Then, denoting $T_{K+1} = T_K + L_K$ where $L_K$ is the length of episode $K$, we have that
    %
    \begin{align*}
        E \spr{K} &\leq 1 + \frac{1}{\log 2} \log \spr{\det \spr{\Lambda_{T_{K+1}}}} & \spr{\Lambda_{t_{E \spr{K}}} \preceq \Lambda_{T_{K+1}}} \\
        &\leq 1 + \frac{d}{\log 2} \log \brr{\frac{\optrace \spr{\Lambda_{T_{K+1}}}}{d}} & \text{(trace-determinant inequality)}\,.
    \end{align*}
    %
    By definition of the covariance matrix,
    %
    \begin{align*}
        E \spr{K} & \leq 1 + \frac{d}{\log 2} \log \spr{\frac{\optrace \spr{\sum_{t \in \sbr{T_{K+1}}} \phi_t \phi_t\transpose} + d}{d}} \\
        &= 1 + \frac{d}{\log 2} \log \spr{1 + \frac{\sum_{t \in \sbr{T_{K+1}}} \norm{\phi_t}_2^2}{d}}
        \\
        &\leq 1 + \frac{d}{\log 2} \log \spr{1 + \frac{B^2 T}{d}} \\
        &\leq 5 d \log \spr{1 + \frac{B^2 T}{d}}\,,
    \end{align*}
    %
    where the first equality follows from properties of the trace and the second inequality follows from $\norm{\phi_t}_2 \leq B$ and $T_{K+1} \leq T$ which holds under $\cE_L$.
\end{proof}

The following lemma is a generalization of Lemma~19 of \citet{cassel2024warmupfree} for an arbitrary threshold $\omega \geq 0$.
%
\begin{lemma} \label{lem:sigmoid-bound}
  For all $z \geq 0$, $\omega \geq 0$ it holds that $\sigma \spr{z - \omega} \leq 2 \spr{z^2 + \exp \spr{- \omega}}$.
\end{lemma}

\begin{proof}
  Let us consider the function $g: z \mapsto \sigma \spr{z - \omega} - \spr{z + \frac{1}{e^{\omega/2}}}^2$. Note that for any $z$, we have $\sigma' \spr{z} = \sigma \spr{z} \sigma \spr{- z}$. Thus, the first two derivatives of $g$ are given by
  %
  \begin{align*}
    g' \spr{z} &= \sigma \spr{z - \omega} \sigma \spr{\omega - z} - 2 \spr{z + \frac{1}{e^{\omega / 2}}}\,, \\
    g'' \spr{z} &= \sigma \spr{z - \omega} \sigma \spr{\omega - z}^2 - \sigma \spr{z - \omega}^2 \sigma \spr{\omega - z} - 2 \,.
  \end{align*}
  %
  Since $\sigma \spr{z} \in \spr{0, 1}$ for any $z$, the second derivative of $g$ is nonpositive, $g'' \spr{z} \leq 0$, and $g$ is concave. By the first order condition, for any $z \geq 0$,
  %
  \begin{equation*}
    g \spr{z} \leq g \spr{0} + g' \spr{0} z\,.
  \end{equation*}
  %
  Furthermore, note that
  %
  \begin{equation*}
    g \spr{0} = \sigma \spr{- \omega} - \frac{1}{e^\omega} = \frac{1}{1 + e^\omega} - \frac{1}{e^\omega} \leq 0\,,
  \end{equation*}
  %
  and
  %
  \begin{align*}
    g' \spr{0} &= \frac{1}{1 + e^\omega} \frac{1}{1 + e^{- \omega}} - \frac{2}{e^{\omega / 2}} \\
    &\leq \frac{1}{1 + e^\omega} - \frac{2}{e^{\omega / 2}} \\
    &\leq - \frac{1}{e^{\omega / 2}} \\
    &\leq 0\,,
  \end{align*}
  %
  where we first used that $e^{- \omega} \geq 0$ for any $\omega \geq 0$ and then that $x + 1 \geq \sqrt{x}$ for any $x \geq 0$. Thus, it holds that $g \spr{z} \leq 0$ for all $z \geq 0$, \ie $\sigma \spr{z - \omega} \leq \spr{z + \frac{1}{e^{\omega / 2}}}^2$. Using $\spr{a+b}^2 \leq 2 \spr{a^2 + b^2}$, it holds that
  %
  \begin{equation*}
    \sigma \spr{z - \omega} \leq 2 \spr{z^2 + e^{- \omega}}\,.
  \end{equation*}
\end{proof}

We present a variant of Lemma~18 of \citet{cassel2024warmupfree} which is valid for $\omega \geq 2$ instead of $\omega \geq 0$, but is sharper by a factor of $2$.
%
\begin{lemma} \label{lem:sigmoid-bound2}
  For all $\omega \geq 2$, it holds that
  \begin{equation*}
    \max_{z \geq 0} z \cdot \sigma \spr{\omega - \alpha z} \leq \frac{\omega}{\alpha}\,.
  \end{equation*}
\end{lemma}

\begin{proof}
  Let $\alpha > 0$, $\omega \geq 2$, and $g: z \geq 0 \mapsto z \cdot \sigma \spr{\omega - \alpha z}$. We recall that the derivative of the sigmoid function is given for any $z$ by $\sigma' \spr{z} = \sigma \spr{z} \sigma \spr{- z}$, and that $\sigma \spr{- z} = 1 - \sigma \spr{z}$. $g$ is twice differentiable. Its first derivative is given by
  %
  \begin{align*}
    g' \spr{z} &= \sigma \spr{\omega - \alpha z} - \alpha z \sigma \spr{\omega - \alpha z} \sbr{1 - \sigma \spr{\omega - \alpha z}} \\
    &= \sigma \spr{\omega - \alpha z} \sbr{1 - \alpha z \spr{1 - \sigma \spr{\omega - \alpha z}}}\,.
  \end{align*}
  %
  We set the derivative to zero and solve the equation to find the critical points. We have
  %
  \begin{align}
    g' \spr{z} = 0 &\quad\text{iff}\quad \alpha z = \frac{1}{1 - \sigma \spr{\omega - \alpha z}} \label{eq:critical-point-prop} \\
    &\quad\text{iff}\quad \alpha z = 1 + e^{\omega - \alpha z} \nonumber \\
    &\quad\text{iff}\quad \spr{\alpha z - 1} e^{\alpha z - 1} = e^{\omega - 1}\,. \nonumber
  \end{align}
  %
  For $x > 0$, the equation $w e^w = x$ has exactly one positive solution $w = W \spr{x}$ which increases with $x$ and where $W$ denotes the Lambert function. Thus, $g' \spr{z} = 0$ if and only if $\alpha z - 1 = W \spr{e^{\omega - 1}}$, \ie $z^\star = \frac{W \spr{e^{\omega - 1}} + 1}{\alpha}$. We check that $z^\star$ is a local maximum. The second derivative of $g$ is given by
  %
  \begin{align*}
    g'' \spr{z} &= - 2 \alpha \sigma \spr{\omega - \alpha z} \sbr{1 - \sigma \spr{\omega - \alpha z}} \\
    &\phantom{=}+ \alpha^2 z \sigma \spr{\omega - \alpha z} \sbr{1 - \sigma \spr{\omega - \alpha z}}^2 \\
    &\phantom{=}- \alpha^2 z \sigma \spr{\omega - \alpha z}^2 \sbr{1 - \sigma \spr{\omega - \alpha z}} \\
    &= - 2 \alpha \sigma \spr{\omega - \alpha z} \sbr{1 - \sigma \spr{\omega - \alpha z}} \\
    &\phantom{=}+ \alpha^2 z \sigma \spr{\omega - \alpha z} \sbr{1 - \sigma \spr{\omega - \alpha z}} \sbr{1 - 2 \sigma \spr{\omega - \alpha z}}\,.
  \end{align*}
  %
  We evaluate it at the critical point $z^\star$ and simplify the expression using Equation~\ref{eq:critical-point-prop}
  %
  \begin{align*}
    g'' \spr{z^\star} &= - 2 \alpha \sigma \spr{\omega - \alpha z^\star} \sbr{1 - \sigma \spr{\omega - \alpha z^\star}} \\
    &\phantom{=}+ \alpha \sigma \spr{\omega - \alpha z^\star} \sbr{1 - 2 \sigma \spr{\omega - \alpha z^\star}} \\
    &= - \alpha \sigma \spr{\omega - \alpha z^\star} \\
    &< 0\,,
  \end{align*}
  %
  thus $z^\star > 0$ is a local maximum. Since $g \spr{0} = 0$, $\lim_{z \rightarrow + \infty} g \spr{z} = 0$, $g \spr{z^\star}$ and $z^\star$ is the only positive critical point, this means $z^\star$ is a global maximum. We evaluate $g$ to get the maximum
  %
  \begin{align*}
    g \spr{z^\star} &= \frac{W \spr{e^{\omega - 1}} + 1}{\alpha} \frac{1}{1 + \exp \spr{W \spr{e^{\omega - 1}}} e^{1 - \omega}} \\
    &= \frac{W \spr{e^{\omega - 1}} + 1}{\alpha} \frac{W \spr{e^{\omega - 1}}}{W \spr{e^{\omega - 1}} + W \spr{e^{\omega - 1}} \exp \spr{W \spr{e^{\omega - 1}}} e^{1 - \omega}} \\
    &= \frac{W \spr{e^{\omega - 1}}}{\alpha}\,,
  \end{align*}
  %
  where we used $W \spr{e^{\omega - 1}} \exp \spr{W \spr{e^{\omega - 1}}} = e^{\omega - 1}$ in the third equality. We now upper bound the Lambert function. Taking the log of the equation that defines it, we have $W \spr{x} = \log x - \log W \spr{x}$ for any $x > 0$. Note that $W \spr{e} = 1$ and that $W$ is increasing, so for any $x > e$, we have $W \spr{x} > 1$ and thus $W \spr{x} < \log x$. Using it on $g \spr{z^\star}$, we further have
  %
  \begin{equation*}
    g \spr{z^\star} \leq \frac{\omega - 1}{\alpha} \leq \frac{\omega}{\alpha}\,,
  \end{equation*}
  %
  where we used $\omega \geq 2$. This concludes the proof.
\end{proof}


\begin{lemma} \label{lem:lse-lipschitz}
  Let $n \in \bbR^n$, and define $\LSE: \bbR^n \rightarrow \bbR$ the function defined for any $x \in \bbR^n$ as
  %
  \begin{equation*}
    \LSE \spr{x} = \log \sum_{i=1}^n e^{x_i}\,.
  \end{equation*}
  %
  Then $\LSE$ is 1-Lipschitz with respect to the norm $\norm{\cdot}_\infty$, \ie for any $x, y \in \bbR^n$,
  %
  \begin{equation*}
    \abs{\LSE \spr{x} - \LSE \spr{y}} \leq \norm{x - y}_\infty\,.
  \end{equation*}
\end{lemma}

\begin{proof}
  For any $i \in \sbr{n}$ and any $x \in \bbR^n$, the gradient of $\LSE$ is given by
  %
  \begin{equation*}
    \nabla \LSE \spr{x} = \frac{e^{x}}{\inp{e^{x}, \bfone}}\,.
  \end{equation*}
  %
  Let $y \in \bbR^n$. By the intermediate mean value theorem, there exists a $z$ on the segment $\sbr{x, y}$ such that
  %
  \begin{align*}
    \abs{\LSE \spr{x} - \LSE \spr{y}} &= \abs{\inp{\nabla \LSE \spr{z}, x - y}} \\
    &\leq \norm{\nabla \LSE \spr{z}}_1 \norm{x - y}_\infty \\
    &= \norm{x - y}_\infty\,,
  \end{align*}
  %
  where the inequality follows from HÃ¶lder's inequality.
\end{proof}


\begin{lemma}[\citealp{cohen2019learning}, Lemma~27] \label{lem:det-elliptical-bound}
  If $0 \prec M \preceq N$ then for any vector $v$,
  %
  \begin{equation*}
    \norm{v}_N^2 \leq \frac{\det N}{\det M} \norm{v}_M^2\,.
  \end{equation*}
\end{lemma}


\begin{lemma}[\citealp{sherman2023}, Lemma~15] \label{lemma:beta_bound}
    Let $R, z \geq 1$, then $\beta \geq 2 z \log \spr{R z}$ ensures $\beta \geq z \log \spr{R \beta}$.
\end{lemma}

\begin{lemma}[\citealp{rosenberg2020near}, Lemma~D.4] \label{lem:concentration-ineq-cond-exp}
  Let $\bc{X_k}_{k \in [K]}$ be a sequence of random variables adapted to the filtration $\bc{\mathcal{F}_k}_{k\in[K]}$ and suppose that $0 \leq X_k \leq X_{\max}$ almost surely. Then, with probability at least $1-\delta$, the following holds for all $k \geq 1$ simultaneously
  \begin{equation*}
    \sum^K_{k=1} \mathbb{E}\bs{X_k | \mathcal{F}_{k-1}} \leq 2 \sum^K_{k=1} X_k + 4 X_{\max} \log \frac{2 K}{\delta}\,.
  \end{equation*}
\end{lemma}

\begin{lemma}[\citealp{jin2019provably}, Lemma~D.2] \label{lem:bound-elliptical-potential}
  Let $\scbr{\phi_t}_{t \geq 0}$ be a bounded sequence in $\bbR^d$ satisfying $\sup_{t \geq 0} \norm{\phi_t} \leq 1$. Let $\Lambda_0 \in \bbR^{d \times d}$ be a positive definite matrix. For any $t \geq 0$, we define $\Lambda_t = \Lambda_0 + \sum_{j=1}^t \phi_j \phi_j\transpose$. Then, if the smallest eigenvalue of $\Lambda_0$ satisfies $\lambda_{\mathrm{min}} \spr{\Lambda_0} \geq 1$, we have
  \begin{equation*}
    \sum_{j=1}^t \phi_j \Lambda_{j-1}^{-1} \phi_j \leq 2 \log \spr{\frac{\det \Lambda_t}{\det \Lambda_0}}\,.
  \end{equation*}
\end{lemma}