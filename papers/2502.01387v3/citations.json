[
  {
    "index": 0,
    "papers": [
      {
        "key": "liu2024cooperative",
        "author": "Liu, Jiaqi and Hang, Peng and Na, Xiaoxiang and Huang, Chao and Sun, Jian",
        "title": "Cooperative decision-making for cavs at unsignalized intersections: A marl approach with attention and hierarchical game priors"
      },
      {
        "key": "xu2018reinforcement",
        "author": "Xu, Xin and Zuo, Lei and Li, Xin and Qian, Lilin and Ren, Junkai and Sun, Zhenping",
        "title": "A reinforcement learning approach to autonomous decision making of intelligent vehicles on highways"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "schulman2017proximal",
        "author": "Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg",
        "title": "Proximal policy optimization algorithms"
      },
      {
        "key": "mnih2013playing",
        "author": "Mnih, Volodymyr",
        "title": "Playing atari with deep reinforcement learning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "sun2023aligning",
        "author": "Sun, Zhiqing and Shen, Sheng and Cao, Shengcao and Liu, Haotian and Li, Chunyuan and Shen, Yikang and Gan, Chuang and Gui, Liang-Yan and Wang, Yu-Xiong and Yang, Yiming and others",
        "title": "Aligning large multimodal models with factually augmented rlhf"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "yu2024rlhf",
        "author": "Yu, Tianyu and Yao, Yuan and Zhang, Haoye and He, Taiwen and Han, Yifeng and Cui, Ganqu and Hu, Jinyi and Liu, Zhiyuan and Zheng, Hai-Tao and Sun, Maosong and others",
        "title": "Rlhf-v: Towards trustworthy mllms via behavior alignment from fine-grained correctional human feedback"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "liu2024cooperative",
        "author": "Liu, Jiaqi and Hang, Peng and Na, Xiaoxiang and Huang, Chao and Sun, Jian",
        "title": "Cooperative decision-making for cavs at unsignalized intersections: A marl approach with attention and hierarchical game priors"
      },
      {
        "key": "xu2018reinforcement",
        "author": "Xu, Xin and Zuo, Lei and Li, Xin and Qian, Lilin and Ren, Junkai and Sun, Zhenping",
        "title": "A reinforcement learning approach to autonomous decision making of intelligent vehicles on highways"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "schulman2017proximal",
        "author": "Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg",
        "title": "Proximal policy optimization algorithms"
      },
      {
        "key": "mnih2013playing",
        "author": "Mnih, Volodymyr",
        "title": "Playing atari with deep reinforcement learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "li2022decision",
        "author": "Li, Guofa and Yang, Yifan and Li, Shen and Qu, Xingda and Lyu, Nengchao and Li, Shengbo Eben",
        "title": "Decision making of autonomous vehicles in lane change scenarios: Deep reinforcement learning approaches with risk awareness"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "kiran2021deep",
        "author": "Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Al Sallab, Ahmad A and Yogamani, Senthil and P{\\'e}rez, Patrick",
        "title": "Deep reinforcement learning for autonomous driving: A survey"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zhu2021survey",
        "author": "Zhu, Zeyu and Zhao, Huijing",
        "title": "A survey of deep RL and IL for autonomous driving policy learning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "sun2023aligning",
        "author": "Sun, Zhiqing and Shen, Sheng and Cao, Shengcao and Liu, Haotian and Li, Chunyuan and Shen, Yikang and Gan, Chuang and Gui, Liang-Yan and Wang, Yu-Xiong and Yang, Yiming and others",
        "title": "Aligning large multimodal models with factually augmented rlhf"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "yu2024rlhf",
        "author": "Yu, Tianyu and Yao, Yuan and Zhang, Haoye and He, Taiwen and Han, Yifeng and Cui, Ganqu and Hu, Jinyi and Liu, Zhiyuan and Zheng, Hai-Tao and Sun, Maosong and others",
        "title": "Rlhf-v: Towards trustworthy mllms via behavior alignment from fine-grained correctional human feedback"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "fang2024towards",
        "author": "Fang, Shiyu and Liu, Jiaqi and Ding, Mingyu and Cui, Yiming and Lv, Chen and Hang, Peng and Sun, Jian",
        "title": "Towards interactive and learnable cooperative driving automation: a large language model-driven decision-making framework"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "sha2023languagempc",
        "author": "Sha, Hao and Mu, Yao and Jiang, Yuxuan and Chen, Li and Xu, Chenfeng and Luo, Ping and Li, Shengbo Eben and Tomizuka, Masayoshi and Zhan, Wei and Ding, Mingyu",
        "title": "Languagempc: Large language models as decision makers for autonomous driving"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "fu2024drive",
        "author": "Fu, Daocheng and Li, Xin and Wen, Licheng and Dou, Min and Cai, Pinlong and Shi, Botian and Qiao, Yu",
        "title": "Drive like a human: Rethinking autonomous driving with large language models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wen2023dilu",
        "author": "Wen, Licheng and Fu, Daocheng and Li, Xin and Cai, Xinyu and Ma, Tao and Cai, Pinlong and Dou, Min and Shi, Botian and He, Liang and Qiao, Yu",
        "title": "Dilu: A knowledge-driven approach to autonomous driving with large language models"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "fang2024towards",
        "author": "Fang, Shiyu and Liu, Jiaqi and Ding, Mingyu and Cui, Yiming and Lv, Chen and Hang, Peng and Sun, Jian",
        "title": "Towards interactive and learnable cooperative driving automation: a large language model-driven decision-making framework"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "sha2023languagempc",
        "author": "Sha, Hao and Mu, Yao and Jiang, Yuxuan and Chen, Li and Xu, Chenfeng and Luo, Ping and Li, Shengbo Eben and Tomizuka, Masayoshi and Zhan, Wei and Ding, Mingyu",
        "title": "Languagempc: Large language models as decision makers for autonomous driving"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "fu2024drive",
        "author": "Fu, Daocheng and Li, Xin and Wen, Licheng and Dou, Min and Cai, Pinlong and Shi, Botian and Qiao, Yu",
        "title": "Drive like a human: Rethinking autonomous driving with large language models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "wen2023dilu",
        "author": "Wen, Licheng and Fu, Daocheng and Li, Xin and Cai, Xinyu and Ma, Tao and Cai, Pinlong and Dou, Min and Shi, Botian and He, Liang and Qiao, Yu",
        "title": "Dilu: A knowledge-driven approach to autonomous driving with large language models"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "cui2024survey",
        "author": "Cui, Can and Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Zhou, Yang and Liang, Kaizhao and Chen, Jintai and Lu, Juanwu and Yang, Zichong and Liao, Kuei-Da and others",
        "title": "A survey on multimodal large language models for autonomous driving"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "liu2024language",
        "author": "Liu, Jiaqi and Xu, Chengkai and Hang, Peng and Sun, Jian and Ding, Mingyu and Zhan, Wei and Tomizuka, Masayoshi",
        "title": "Language-Driven Policy Distillation for Cooperative Driving in Multi-Agent Reinforcement Learning"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "zhang2024large",
        "author": "Zhang, Danyang and Chen, Lu and Zhang, Situo and Xu, Hongshen and Zhao, Zihan and Yu, Kai",
        "title": "Large language models are semi-parametric reinforcement learning agents"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "trirat2024automl",
        "author": "Trirat, Patara and Jeong, Wonyong and Hwang, Sung Ju",
        "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "ma2023eureka",
        "author": "Ma, Yecheng Jason and Liang, William and Wang, Guanzhi and Huang, De-An and Bastani, Osbert and Jayaraman, Dinesh and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima",
        "title": "Eureka: Human-level reward design via coding large language models"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "liu2024language",
        "author": "Liu, Jiaqi and Xu, Chengkai and Hang, Peng and Sun, Jian and Ding, Mingyu and Zhan, Wei and Tomizuka, Masayoshi",
        "title": "Language-Driven Policy Distillation for Cooperative Driving in Multi-Agent Reinforcement Learning"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "zhang2024large",
        "author": "Zhang, Danyang and Chen, Lu and Zhang, Situo and Xu, Hongshen and Zhao, Zihan and Yu, Kai",
        "title": "Large language models are semi-parametric reinforcement learning agents"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "trirat2024automl",
        "author": "Trirat, Patara and Jeong, Wonyong and Hwang, Sung Ju",
        "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "ma2023eureka",
        "author": "Ma, Yecheng Jason and Liang, William and Wang, Guanzhi and Huang, De-An and Bastani, Osbert and Jayaraman, Dinesh and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima",
        "title": "Eureka: Human-level reward design via coding large language models"
      }
    ]
  }
]