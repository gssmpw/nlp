\section{Classification, One-Inclusion Graphs, and Bipartite Matching}
\label{sec:class}

A \emph{classification problem} is a supervised learning problem with the 0-1 loss function $\ell_{0-1}(y',y)=[y' \neq y]$, which evaluates to $1$ when $y' \neq y$ and to $0$ when $y'=y$. It is important to note that this allows for an arbitrary domain $\X$, an arbitrary label set $\Y$, and an arbitrary hypothesis class $\H \sse \Y^\X$.  Classification therefore forms a rich and expressive class of problems,  garnering the lion's share of theoretical work on supervised learning (particularly in the PAC model), and featuring in essentially every application domain of machine learning. %. Classification problems are also prolific in practice, appearing in essentially every application domain of machine learning.
%
When there are only two labels, canonically $\Y= \set{0,1}$, we have a \emph{binary classification} problem.  More generally, \emph{multiclass classification} problems can have any number of labels, even infinitely many of any cardinality.

I will discuss classification problems in the transductive model, emboldened by its close relationship to the PAC model as described in Section~\ref{sec:trans}. I will start with a primer on one-inclusion graphs (OIGs), which encode transductive classification exactly  as a combinatorial optimization problem. I will then reinterpret this problem as bipartite matching, and discuss some recently-discovered implications of this interpretation.

It's worth noting that the transductive perspective is of perhaps limited utility for binary classification, where empirical risk minimization (ERM) has almost optimal PAC sample complexity~\cite{shalev-shwartz_understanding_2014}. It is in multiclass classification where transductive learners truly shine, in particular as the number of labels grows large. In fact, ERM can fail to learn entirely even for learnable multiclass problems~\cite{daniely_multiclass_2011}, as can SRM and any proper learner \cite{daniely_optimal_2014}.  To my knowledge, all known general-purpose learners for multiclass classification factor through the transductive model and  OIGs~\cite{daniely_optimal_2014, brukhim_characterization_2022,aden-ali_optimal_2023,asilis_regularization_2024}.





\subsection{One-Inclusion Graphs}
\label{sec:oig}
% Though transduction is most useful for multiclass problems, we start with binary classification for illustrative purposes.

The \emph{one-inclusion graph (OIG)} is a mathematical representation of classification in the transductive model of learning. OIGs were proposed by  \citet{haussler_predicting_1994} to model  realizable binary classification, and have since been  extended to realizable multiclass classification by \citet{rubinstein_shifting_2009}, and  to the agnostic setting by~\citet{asilis_regularization_2024}. As we will see shortly, OIGs represent these learning tasks exactly, with their \emph{orientations} in one-to-one correspondence with transductive learners. 

\paragraph{Realizable Binary Classification.} I will start by describing OIGs in their original form, restricted to realizable binary classification. Fix a domain $\X$ and a hypothesis class $\H \sse \set{0,1}^\X$. Recall that, in the  realizable setting of the transductive model, a collection of $n$  unlabeled datapoints $S=(x_1,\ldots,x_n) \in \X^n$ is chosen by an adversary, and provided to the learner at the outset. The adversary also selects a \emph{ground truth} hypothesis $h^* \in \H$,  then the learner is asked to predict the label $h^*(x_i)$ of a randomly-chosen test datapoint $x_i$ from the labels $h^*|_{S_{-i}}$ of the remaining $n-1$ datapoints.


\begin{wrapfigure}{R}{0.42\textwidth}
%\vspace{-0.3cm}
  \centering
  \input{figures/oig.tikz}
  \caption{Example OIG for realizable binary classification on three~datapoints.}
  \label{fig:binaryoig}
\end{wrapfigure}
The OIG is an undirected graph $G(\H,S)$  determined by the hypothesis class $\H$ and the unlabeled datapoints  $S$, both of which are known to the learner. The nodes correspond to the possible labelings $\H|_S$  of the datapoints $S$ by hypotheses in $\H$, of which there can be at most $2^n$.\footnote{A tighter bound is given by the \emph{growth function} $\Phi_d(n) = \sum_{i=0}^d \binom{n}{i}$, where $d$ is the VC dimension of $\H$.} %\footnote{For a binary hypothesis class of VC dimension $d$,  a tight upper bound on the number of possible labelings of $n$ datapoints, and hence the number of nodes of the OIG,  is given by the \emph{growth function} $\Phi_d(n) = \sum_{i=0}^d \binom{n}{i}$.} In other words, each node is a labeling $(y_1, \ldots, y_n) \in \set{-1,+1}^n$, with $y_i$ the label for $x_i$, consistent with some hypothesis $h \in \H$. 
  An edge is included between two labelings if they differ on exactly a single datapoint. Another perspective is that the OIG is simply the subgraph of the $n$-dimensional hypercube induced by $\H|_S$. An example OIG is depicted in Figure~\ref{fig:binaryoig}.


  
  Now consider a learner trying to predict the label of $x_i$ from labels $\set{y_j}_{j \neq i}$ provided for all the other datapoints. If there is a single node $(y_1, \ldots, y_i, \ldots, y_n)$  in $G$ that is consistent with the provided labels, then there is nothing to decide: $y_i$ must be the correct label for $x_i$. The interesting case is when there are two such nodes, one of which labels $x_i$ with a $0$ and the other with a~$1$. These two nodes, in differing only on $x_i$, must share an edge $e$ in the OIG. In such a situation, a learner predicting a label for $x_i$ chooses one of the two nodes to ``go with'', effectively \emph{orienting} $e$   towards the chosen prediction. In specifying a prediction for every such scenario, a learner orients all the edges of the OIG, turning it into a directed graph.  %In other words, the learner \emph{orients} the edge by imbuing it with a direction, turning it into a directed graph.
To summarize, learners are  in one-to-one correspondence with \emph{orientations} of the OIG.\footnote{More accurately, this is the case for deterministic learners. Randomized learners correspond to randomized orientations. This distinction is not especially consequential, so I blur it in this article.} 

  % outdegree
Given this graph-theoretic view of a transductive learner, we can also describe its error guarantee  in graph-theoretic terms: it is proportional to the maximum \emph{out-degree} of a node in the oriented graph. To see this, observe that each node  represents a possible ground truth labeling $\y=(y_1, \ldots, y_n)$ of the datapoints, and each edge represents an ambiguity faced by the learner looking to predict some $y_i$. When an edge is directed out of $\y$, this corresponds to a ``mistake'' by the learner when $\y$ happens to be the ground truth. Since the test datapoint~$x_i$ is chosen uniformly at random, and we evaluate error in the worst case over possible ground truths, we can conclude that the learner's error (i.e., worst-case misclassification rate) equals the maximum outdegree divided by $n$. Since each edge results in a mistake for one of its endpoints, one can think of transductive learning as seeking to ``spread the error around'' as evenly as possible among all possible ground truths.



% multiclass
\paragraph{Realizable Multiclass Classification.} One-inclusion graphs generalize naturally to multiclass classification, as articulated by \cite{rubinstein_shifting_2009}. For a set $\Y$ of labels, which may be finite or infinite, the nodes of the OIG are still the  ground truth labelings $\y=(y_1,\ldots,y_n) \in \Y^n$ consistent with some hypothesis. The edges, however, turn into hyper-edges, with a collection of nodes sharing a hyper-edge precisely when they all disagree on \emph{the same} $y_i$, and no other.  An OIG involving  three datapoints and three labels  is depicted in Figure~\ref{fig:oig}. %It will be sometimes convenient to identify a  hyper-edge with a \emph{partial labeling} $(y_1,\ldots, ? , \ldots y_n)$ with $y_j \in \Y$ for all but a single ``?'', where all nodes agreeing with the partial labeling on all but the ``?'' are included in the hyper-edge.
The hyper-edges again correspond to the ambiguities faced by the learner, where multiple predictions (up to $|\Y|$ many) are consistent with provided data. A learner can therefore be seen as orienting a hyper-edge towards the node corresponding to its prediction, and away from the others. As before, a ground truth incurs one ``mistake'' for every incident edge directed away from it.  Defining the out-degree of a node as the number of its incident edges directed away from it, the learner's error is again the maximum out-degree divided by $n$.

\input{figures/bothoig.tex}


\paragraph{Agnostic Multiclass Classification.} 
OIGs were recently further generalized to the agnostic setting of multiclass classification by  \citet{asilis_regularization_2024}, building on a closely-related definition employed by \citet{long_complexity_1999} for a different model of learning. This \emph{agnostic OIG}, denoted $G^\ag(\H,S)$, is as follows.  Since the ground truth labeling of the given datapoints $S=(x_1,\ldots,x_n)$ may now be completely arbitrary, we include all labelings $\Y^n$ as nodes of $G^\ag$.  As in the realizable case, a collection of nodes share a hype-edge precisely when they disagree on the same $y_i$ and no other.   Also as in the realizable case, a learner is an orientation of the hyper-edges, and the learner's error is related to out-degrees of all the nodes.

But what of the hypothesis class $\H$? Since we are in the agnostic setting, $\H$ serves merely as a benchmark for our learner. Therefore, in defining the OIG orientation problem we now ``discount'' the out-degree of each node  $\y=(y_1,\ldots,y_n)$ of $G^\ag$ by its \emph{Hamming distance} $\dist(y,\H)$ from $\H|_S$.\footnote{The Hamming distance between two vectors is the number of entries on which they differ. For the distance to a set of vectors, we minimize over that set appropriately.} %For error rate $\epsilon$, each labeling $\y$ on the right side of $G_\bp^\ag$ must be ``matched'' at least $(1-\epsilon)n - d(\y,\H)$ times, where $d(\y,\H)$ is the aforementioned discount for node $\y$.
This is quite natural, as the more the ground truth deviates from our benchmark class $\H$, the more we are ``off the hook'' for making accurate predictions. 



% computation, brute force, parsimonious need
\paragraph{A Note on Computational Complexity.} Some remarks are in order with regard to the computational complexity of working with the OIG. Even for binary classification with a finite VC dimension $d$, the OIG can have on the order of $n^d$ nodes. This is prohibitively large for all but the smallest values of $d$. In multiclass classification the situation can be even more dire. In fact, there are learnable problems with infinitely many labels and  OIGs of infinite size! It is therefore unsurprising that OIGs have usually not been thought of as a practical data structure for learning, but rather as abstractions for its mathematical study. In some sense, orienting the OIG can be viewed as ``brute-forcing'' the learning task: a representation of the algorithm's entire input/output behavior, at least with respect to labelings, is computed before even looking at the labels in the training data!  This stands in contrast to practical approaches  such as ERM and SRM (see Section~\ref{sec:background}), %, such as empirical risk minimization and structural risk minimization,
which represent the task parsimoniously and reason locally, input by input. Nonetheless, I will argue in this article that insights emanating from OIGs, and extensions of them, can  point the way to such tenable algorithms.



\subsection{The Matching Perspective}
\label{subsec:matching}

One inclusion graphs transform multiclass learning to what is essentially a combinatorial optimization problem on orientations, albeit one that is described implicitly. From here, a simple shift in perspective articulated by \cite{asilis_regularization_2024}, employing the classical connection between orientation and matching problems (see e.g. \cite{Schrijver_2003}), yields an equivalent bipartite matching problem. I will describe this next.

Let $G$ be an OIG associated with hypothesis class $\H \sse \Y^\X$ and unlabeled dataset $S=(x_1,\ldots,x_n)$. The transformation is essentially identical whether we let $G$ be the realizable or agnostic OIG, but I recommend the reader keep the realizable OIG in mind to keep things simple. On the right we have the  nodes of $G$, corresponding to possible ground-truth labelings $\y=(y_1,\ldots,y_n)$ of  $(x_1,\ldots,x_n)$ . On the left we have \emph{partial labelings} which occlude a single label from some ground truth. We represent these as a vector $(y_1, \ldots, ?, \ldots, y_n)$,  where $y_i \in \Y$ for all but a single ``?'' entry corresponding to the occluded label. An edge is included between a partial labeling on the left and a full labeling on the right if they agree on all but occluded label. 
In graph-theoretic terms,  the bipartite OIG $G_{\bp}$ is essentially  the \emph{edge-vertex incidence graph} of $G$, were $G$ to first be augmented with self-loops (i.e., singleton hyper-edges) so that every node has degree exactly~$n$. %We sometimes refer to $G_{\bp}$ as the \emph{bipartite OIG} for convenience.
A bipartite OIG for the realizable setting is depicted in Figure~\ref{fig:bpoig}.

The  left side nodes of $G_{\bp}$ --- the partial labelings --- represent the scenarios faced by the learner, where one label is omitted and the learner is asked to ``fill in the blank.'' Edges of $G_{\bp}$ encode the consistency relationship between the partial labelings on the left and the (full) labelings on the right. A learner, in having to predict each occluded label, can be viewed as an \emph{assignment} mapping each node on the left to one of its neighbors on the right. Note that each node on the right has degree exactly $n$ in $G_{\bp}$, one for each possible position of the ``?'',  whereas nodes on the left may have degree up to the number of labels $|\Y|$ (exactly $|\Y|$ in the agnostic setting). % with a corresponding learner in  Figure~\ref{fig:??}. %original OIG, corresponding bipartite OIG, highlighted 


Given this perspective on learners as assignments in the bipartite OIG, what of their error? It is easier to take a complementary perspective and describe the learner's \emph{accuracy}: the probability it correctly classifies the test point, in the worst case over ground truths. For a particular ground truth labeling $\y=(y_1,\ldots,y_n)$ on the right side of $G_{\bp}$, the learner faces $n$ equally likely scenarios, one for each left node $\tilde{\y} = (y_1, \ldots, ? , \ldots, y_n)$ incident on $\y$. The learner correctly classifies the test point precisely when it assigns $\tilde{\y}$ to  $\y$. Therefore, viewing a learner as a left to right assignment in $G_{\bp}$, its accuracy is its minimum degree to a node on the right, divided by $n$.  In the realizable setting, the error  is of course the complementary probability. In the agnostic setting, we discount each degree of a node $\y$ on the right by its Hamming distance $\dist(\y,\H)$ to the hypothesis class, then proceed identically to arrive at the agnostic error. 

We can now cast learning  as a  bipartite matching problem. To obtain error $\epsilon$, each node $\y$ on the right side of $G_{\bp}$ must be assigned --- we say \emph{matched} --- at least $(1-\epsilon) n$ times in the realizable case, and at least $(1-\epsilon) n - \dist(\y,\H)$ times in the agnostic case. This is what is referred to in combinatorial optimization as a  bipartite \emph{$b$-matching problem}, a generalization of bipartite matching where nodes can be prescribed a minimum required number of matches. This generalization is exclusively for convenience, as a bipartite $b$-matching problem can be equivalently posed as  a run-of-the-mill  maximum bipartite matching problem by appropriately cloning nodes that require multiple matches. It must be noted, however, that $G_{\bp}$ can like $G$ be an  infinite graph, and even when finite is typically prohibitively large for invoking matching algorithms directly.

What, then, does this matching perspective on classification  buy us? Quite a bit, as it turns out. I will describe some recent consequences  of this viewpoint next.


\subsection{Implication of Matching: A Compact Graph-Theoretic Characterization}
%We now describe a shift in perspective articulated in the PI's recent joint work \cite{asilis_regularization_2023}, one which reframes  realizable classification  as a bipartite matching problem. This new lens, while remarkably simple,  allows us to bring to bear tools from combinatorics, matching theory, and optimization to the analysis of learning. Furthermore, it sets the stage for generalizations of the OIG that go beyond realizable classification.
\label{sec:hall}



Characterizing the optimal sample complexity of  learning  is a chief concern of learning theory. Given the simplicity of the transductive model, one might hope for a crisp and interpretable expression for the sample complexity, or equivalently the error rate, of the optimal transductive learner. Such an expression would approximate the performance of the optimal PAC learner, as per the relationships described  in Section \ref{subsec:pac_trans}. The matching perspective yields such a graph-theoretic expression which captures the transductive  error rate ``on the nose'' \cite{asilis_regularization_2024}. Moreover, this expression refers only to  \emph{finite projections} of the learning problem.


%\begin{figure}
\begin{wrapfigure}{R}{0.41\textwidth}
%  \vspace{-0.5cm}
  \centering
  \scalebox{1}{\input{figures/infinite_matching.tikz}}
  \caption{Matching on infinite bipartite graphs absent degree constraints.}
  \label{fig:infinite_matching}
\end{wrapfigure}
%\end{figure}
The starting point here is Philip Hall's classic \emph{marriage theorem}~\cite{hall1987representatives}, which characterizes exactly when one side of a \emph{finite} bipartite graph can be matched to the other. Let $L$ and $R$ denote the left and right side nodes of the graph, respectively, and consider whether there is a matching which matches every node on the right. The original marriage theorem states that such a matching exists  if and only if every set $R' \sse R$ of right side nodes has at least $|R'|$ neighbors between them (on the left, naturally). Whereas this \emph{Hall condition} characterizes matching on finite bipartite graphs, it fails to extend to all infinite bipartite graphs, where it is necessary but not sufficient in general. This can be seen by way of a simple example, illustrated in Figure~\ref{fig:infinite_matching}.% as evidenced by a simple example.\footnote{Suppose $L=\set{\ell_1,\ell_2,\ldots}$ is indexed by the positive integers, $R=\set{r_0,r_1,r_2,\ldots}$ is indexed by the nonnegative integers, and the edges include $(\ell_i,r_i)$ and $(\ell_i,0)$ for all positive integers $i$. The Hall condition holds for all finite~$R' \sse R$. However, there is no matching for all of $R$: if $r_0$ is matched to some $\ell_i$, then $r_i$ can not be matched.  }


The ``troublemaker'' in Figure~\ref{fig:infinite_matching} is the infinite-degree node $0$ on the right. If we assume that the nodes we intend to match --- the right side nodes $R$, in our discussion --- have finite degrees, the marriage theorem can be recovered:  we can match  $R$ if and only if we can match every finite $R' \sse R$, which in turn is possible precisely when each finite $R' \sse R$ has at least $|R'|$ neighbors (the Hall condition). This holds for infinite graphs of arbitrary, even uncountable, cardinality, so long as the degrees on the right are all finite (not necessarily bounded); degrees on the left may be arbitrary, even uncountable. This \emph{infinite marriage theorem} was first established by Marshall Hall~\cite{jr_distinct_1948} by way of a quite sophisticated proof,\footnote{No relation to Philip Hall, coincidentally.}  though somewhat simpler proofs have since been discovered (e.g. \cite{halmos_marriage_1950,rado_note_1967}). The infinite marriage theorem also extends naturally to  $b$-matching by a simple cloning argument, under the same requirement of finite right-side degrees: If each node on the left can be matched at most once, whereas each node $r$ on the right requires at least $b_r$ matches, then this is possible if and only if it is possible for every finite $R' \sse R$, which in turn is possible if and only if each finite $R' \sse R$ has at least $b(R') = \sum_{r \in R'} b_r$ neighbors. In showing that an infinite graph admits a matching of a particular form precisely when the same holds for some of its finite subgraphs, M. Hall's infinite marriage theorem is what is referred to as a \emph{compactness} result.

This now brings us naturally to bipartite OIGs, which encode classification as a matching problem. In the realizable setting, a learner with error $\epsilon$ corresponds to a $b$-matching on $G_{\bp}$ with $b=(1-\epsilon)n$ for every right side side node $\y=(y_1, \ldots, y_n)$. The infinite marriage theorem then implies that this is possible precisely when every finite family $R'$ of full labelings on the right side of $G_{\bp}$ is incident on at least $(1-\epsilon)n \cdot |R'|$ partial labelings. This yields a precise expression of the optimal error as a function of the sample size $n$,  as the worst-case  ``matchability'' of finite subgraphs of a bipartite OIG. This graph-theoretic expression, stated precisely in \cite{asilis_regularization_2024}, is called the \emph{Hall complexity} of the hypothesis class. The expression is easily adapted to the agnostic setting by appropriately discounting the matching requirement of each node $\y$ in the agnostic OIG by $\dist(\y,\H)$. 

Much like in the case of matching, we now have a compactness result for classification. The Hall complexity expresses the optimal transductive error rate of a classification problem as the worst-case learning rate of its \emph{finite projections}: those problems which can be obtained by restricting attention to finite subsets of the domain $\X$ and finite subsets $\H' \sse \H$ of the hypothesis space. To see this, note that  each bipartite OIG is a function of a finite subdomain $x_1,\ldots,x_n$, and a finite subset of its right side nodes corresponds to finitely many hypotheses.  By exactly relating the matchability in the bipartite OIG to the same matchability in some of its finite subgraphs, we can conclude that the maximal obstructions to transductive classification are finite in nature. %Th compact characterization approximately extends to PAC learning, in black box fashion as described  in Section \ref{subsec:pac_trans}.


\paragraph{Bibliographic Remarks.} Simple and \emph{compact} expressions for the optimal error, or equivalently the sample complexity, have long been sought in learning theory. For realizable binary classification, the sample complexity is characterized in terms of the VC dimension both in the transductive \cite{haussler_predicting_1994,li_one-inclusion_2001} and PAC (see e.g. \cite{shalev-shwartz_understanding_2014}) models.    For multiclass classification, the \emph{DS dimension} of \citet{daniely_optimal_2014} yields an approximation of the optimal error in the realizable setting up to a constant in the exponent, as was recently shown by \citet{brukhim_characterization_2022}. Outside of  \emph{dimensions}, a quantity derived from the (classical) one-inclusion graph $G$ gives a constant factor approximation: the maximum average degree of a subgraph of $G$, divided by $n$, is with a factor of~$2$ of the optimal error in the realizable setting. The Hall complexity can be viewed as ``sharpening'' the maximum-average degree into an exact characterization, and extending it to the agnostic setting.

The most sought-after characterizations of learning are \emph{dimensions} such as the VC dimension, DS dimension, and others. Intuitively, a dimension measures the size of the ``largest obstruction'' to learning, with an infinite dimension implying unlearnability, and a finite dimension yielding a bound on the sample complexity by way of a simple expression. Compactness results of the sort provided by the Hall complexity are a weaker requirement than the existence of a dimension capturing optimal learning. I will elaborate on the relationship between compactness and dimensions in Section~\ref{sec:compactness}.  %I will note, however, that compactness is by no means ``trivial'': recent work of \citet{ben-david_learnability_2019} demonstrates a natural supervised learning problem --- in the proper setting not considered in this article ---  where compactness fails.\footnote{We note that \cite{ben-david_learnability_2019} do not pose their non-compact problem, which they term \emph{EMX learning}, as a supervised learning problem. However, it is not difficult to see that it can be rephrased as such.}



\subsection{Implication of Matching: An Algorithmic Template for Classification}
Another important concern of learning theory is identifying algorithmic approaches that are broadly successful for a large swath of learning problems, and moreover simple enough to describe, implement, and explore. Perhaps the best example of this is empirical risk minimization (ERM), as described in Section~\ref{sec:background}. ERM and closely related approaches such as structural risk minimization (SRM) pervade the practice of machine learning, and in some cases are also accompanied by theoretical guarantees.  Most notably, for binary classification problems in the PAC model, it has long been known that ERM characterizes learnability and moreover has almost-optimal sample complexity (see e.g. \cite{shalev-shwartz_understanding_2014}).

Such theoretical optimality guarantees  for ERM  tend to fall by the wayside as one moves beyond binary classification.  In fact, ERM can entirely fail to learn in some settings where learning is possible, as shown by \citet{shalev-shwartz_learnability_2010}.   This failure manifests   in multiclass classification as shown by \citet{daniely_multiclass_2011}, and in a slight generalization of binary classification as shown by \citet{alon_theory_2021}. Even in bounded agnostic linear regression, the sample complexity of ERM was recently shown to be quite suboptimal by \citet{vaskevicius_suboptimality_2023}.\footnote{That said, ERM characterizes learnability for bounded regression  in the coarse sense, disregarding sample complexity~\cite{alon_scale-sensitive_1997}.}  %Whereas a body of work has made significant progress in describing optimal learners for such general problems (e.g. \cite{daniely_optimal_2014,brukhim_characterization_2022}), the existence of an algorithmic template or principle which captures optimal learning remains open.

In settings where ERM fails to characterize optimal learning, the algorithms which do succeed in theory are often far removed from any parsimonious description or any heuristic employed in practice.  This is most apparent in multiclass classification, where the known near-optimal algorithms \cite{daniely_optimal_2014,brukhim_characterization_2022} involve explicitly-described orientations of the one-inclusion graph. Can the bipartite matching interpretation simplify these OIG-based algorithms? Bipartite matching tends to respond well to ``simple'' heuristics such as greedy algorithms, primal-dual approaches, and others --- can the same hold true for learning?


 \begin{figure}
  % \input{arXiv_version_2/figures/local_regularizer.tikz}
\centering
\input{figures/local_regularizer.tikz}
\caption{\emph{ %Hypotheses $h_1$ and $h_2$, depicted in yellow and blue respectively.
    A  local regularizer may favor the simplicity of $h_1$ on test points drawn from the right region of the domain, and the simplicity of $h_2$ on test points drawn from the left region.}}
\label{fig:local}
% \captionof{figure}{}
% This should be adjusted to not overlap once the manuscript is finished.
%\vspace{-6em}
%\caption{Hypotheses $h_0$ and $h_1$, depicted in blue and yellow respectively. A  local regularizer may favor the simplicity of $h_0$ on test points drawn from the right region of the domain, and the simplicity of $h_1$ on test points drawn from the left region.}
\end{figure}

The answer to both questions turns out to be yes, as shown recently by~\citet{asilis_regularization_2024}. Through primal-dual analysis of a certain convex program over matchings in the bipartite OIG, we derive a near-optimal learner for multiclass classification of a particular instructive form. In particular, this learner implements a variation of the SRM template from Section~\ref{sec:background}, relaxed on two fronts: (1) It employs  a  \emph{local} regularization function  $\psi(h,x_{\tst})$ that  measures predictor complexity differently depending on the test point, and  (2) it incorporates an unsupervised pre-training stage which learns this regularization function.

These relaxed SRMs --- derived from the connection to bipartite matching --- provide a  simpler template for optimal learning which is quite natural, and is reminiscent of approaches discovered to be useful in practice. Relaxing to local regularization is well-motivated, since different hypotheses may be simple in some areas of the domain and complex in others; this is illustrated in Figure~\ref{fig:local}. It is therefore not altogether surprising that this result is predated by applications of local regularization to image classification and restoration~\cite{wolf_local_2008,prost_learning_2021}. The second relaxation is in line with much of the recent empirical and theoretical evidence on the utility of an unsupervised learning stage. Indeed, unsupervised pre-training has seen widespread application to  computer vision, natural language processing, and speech recognition (see the discussion in \cite{ge_provable_2024}). 



%%%Local Variables:
%%% mode: latex
%%% TeX-master: "learning_matching"
%%% End:
