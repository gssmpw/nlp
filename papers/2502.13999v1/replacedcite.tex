\section{Related Work}
\subsection{Personilized Text-to-Image Generation} Diffusion models ____ have attracted widespread attention from both industry and academia due to their outstanding performance and high fidelity. This progress has spurred rapid development in customized image generation techniques. Currently, mainstream customized image generation methods can be categorized into two types. The first type relies on fine-tuning during test-time, with representative works including Dreambooth ____, Textual Inversion ____, Custom Diffusion ____, and LoRA ____. Despite their advancements, these methods often require collecting multiple images to ensure learning performance and necessitate individual fine-tuning for each example, which is time-consuming and labor-intensive, thus limiting their practicality. The second type employs tuning-free techniques, skipping the additional fine-tuning or inversion process. Representative works include IP-Adapter ____, FastComposer ____, PhotoMaker ____, Face-Diffuser ____, InstantID ____, ConsistentID  ____, PuLID ____ and Infinite-ID ____. This type of method achieves the customized generation using only an image in a single forward process. Even with improved computational efficiency, these methods often struggle to achieve both high-fidelity generation and high text consistency simultaneously. They either offer excellent text consistency but at the cost of fidelity ____, or high fidelity but with reduced text consistency ____. In contrast, our approach excels in both metrics by using a unique dual-pathway processing and collaboration mechanism.


\subsection{Adapter for Diffusion Models}
Originated from Natural Language Processing ____, adapter technology has also been applied to diffusion models. ControlNet ____ and T2I-Adapter ____ pioneered the use of adapters to integrate more spatial signals for controllable generation. IP-Adapter ____ introduces a decoupled, trainable cross-attention module that receives image prompts, enabling the generation of images similar to the input images. 
In this paper, we propose DP-Adapter, a novel dual-pathway image adapter. Unlike existing methods, each adapter in DP-Adapter has a distinct learning objective: one aims to enhance text consistency, while the other focuses on maintaining high-fidelity identity preservation. By employing a fine-grained feature-level blending module, we achieve an organic integration of these two adapter, resulting in image generation that is both high-fidelity and textually consistent.



\subsection{Diffusion Blending}

Diffusion Blending is widely used in the field of image local editing. Most current methods ____ perform blending operations directly in the noisy image latents space. However, empirical experiments have shown that this approach may introduce artifacts and inconsistencies into the results. This is because the information in the intermediate noisy images lacks the necessary semantics to achieve consistent and seamless fusion. Therefore, we propose a fine-grained feature-level blending (FFB) module, which combines hierarchical semantic features from the two pathways, resulting in more natural and coherent synthesis results.