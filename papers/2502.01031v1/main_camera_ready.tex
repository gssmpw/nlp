\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS

\pdfinfo{/TemplateVersion (2025.1)}

\usepackage{makecell}
\usepackage{placeins}

\setcounter{secnumdepth}{2}





%%%%%%%%%%%%%%%%%%%\input{dfn}%%%%%%%%%%%%%%%%%%%
\usepackage{enumitem}
\usepackage[ruled,linesnumbered,noend]{algorithm2e}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{mathtools}
\usepackage{microtype}
\usepackage{amsthm}
\usepackage{bigstrut}
\usepackage[bb=dsserif]{mathalpha}

\newcommand{\influenceMinimization}{IMIN\xspace}

\newcommand{\methods}{\textsc{RumorGuard} variants\xspace}
\newcommand{\method}{\textsc{DiffIM}\xspace}

\newcommand{\naive}{\textsc{DiffIM}\xspace}
\newcommand{\adv}{\textsc{DiffIM+}\xspace}
\newcommand{\advp}{\textsc{DiffIM++}\xspace}
\newcommand{\advn}{\textsc{DiffIM+(+)}\xspace}

\newcommand{\NAIVE}{\textsc{DiffIM}\xspace}
\newcommand{\ADV}{\textsc{DiffIM+}\xspace}
\newcommand{\ADVP}{\textsc{DiffIM++}\xspace}

\newcommand{\act}{\textt{A}}
\newcommand{\inact}{\textt{I}}
\newcommand{\GNN}{\operatorname{GNN}}

\newcommand{\EL}{\textt{ET}\xspace}
\newcommand{\CL}{\textt{CL}\xspace}
\newcommand{\WL}{\textt{WC}\xspace}

\newcommand{\MDS}{\textsc{MDS}\xspace}
\newcommand{\KED}{\textsc{KED}\xspace}
\newcommand{\BPM}{\textsc{BPM}\xspace}
\newcommand{\Greedy}{\textsc{Greedy}\xspace}
\newcommand{\MBPM}{\textsc{MBPM}\xspace}
\newcommand{\RIS}{\textsc{RIS}\xspace}

\newcommand{\textt}[1]{\scalebox{1.0}{\texttt{#1}}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{problem}{Problem}
\newtheorem{example}{Example}
\newtheorem{remark}{Remark}

\SetAlFnt{\small}

\def\mydefbb#1{\expandafter\def\csname bb#1\endcsname{\ensuremath{\mathbb{#1}}}}
\def\mydefallbb#1{\ifx#1\mydefallbb\else\mydefbb#1\expandafter\mydefallbb\fi}
\mydefallbb ABCDEFGHIJKLMNOPQRSTUVWXYZ\mydefallbb

\def\mydefcal#1{\expandafter\def\csname cal#1\endcsname{\ensuremath{\mathcal{#1}}}}
\def\mydefallcal#1{\ifx#1\mydefallcal\else\mydefcal#1\expandafter\mydefallcal\fi}
\mydefallcal ABCDEFGHIJKLMNOPQRSTUVWXYZ\mydefallcal

\newcommand{\Abs}[1]{\lvert #1 \rvert}
\newcommand{\Set}[1]{\{#1\}}

\newcommand{\citepnop}[1]{\citeauthor{#1} \citeyear{#1}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\title{\method: Differentiable Influence Minimization with\\Surrogate Modeling and Continuous Relaxation}
\author{
    Junghun Lee, 
    Hyunju Kim, 
    Fanchen Bu, 
    Jihoon Ko, 
    Kijung Shin 
}
\affiliations{
    KAIST, Daejeon, South Korea\\
    \{junghun.lee, hyunju.kim, boqvezen97, jihoonko, kijungs\}@kaist.ac.kr
}

\begin{document}

\maketitle





\begin{abstract}
In social networks, people \textit{influence} each other through social links, which can be represented as propagation among nodes in graphs.
\textit{Influence minimization} (\influenceMinimization) is the problem of manipulating the structures of an input graph (e.g., removing edges) to reduce the propagation among nodes.
\influenceMinimization can represent time-critical real-world applications, such as rumor blocking, but \influenceMinimization is theoretically difficult and computationally expensive.
Moreover, the \textit{discrete} nature of \influenceMinimization hinders the usage of powerful machine learning techniques, which requires \textit{differentiable} computation.
In this work, we propose \method, a novel method for \influenceMinimization with two \textit{differentiable} schemes for acceleration:
(1) \textit{surrogate modeling} for efficient influence estimation, which avoids time-consuming simulations (e.g., Monte Carlo), and
(2) the \textit{continuous relaxation} of decisions, which avoids the evaluation of individual discrete decisions (e.g., removing an edge).
We further propose a third accelerating scheme, \textit{gradient-driven selection}, that chooses edges \textit{instantly based on gradients} without optimization (spec., gradient descent iterations) on each test instance.
Through extensive experiments on real-world graphs, we show that each proposed scheme significantly improves speed with little (or even no) \influenceMinimization performance degradation.
Our method is Pareto-optimal (i.e., no baseline is faster \textit{and} more effective than it) and typically several orders of magnitude (spec., up to 15,160$\times$) faster than the most effective baseline while being more effective. 
\end{abstract}

\begin{links}
     \link{Code, datasets and online appendix}{https://github.com/junghunl/DiffIM}
\end{links}



\section{Introduction}
\label{sec:intro}
In both online and offline social networks, a common phenomenon is \textit{influence}.
That is, people influence other people through social links.
Typical examples include the spread of information (e.g., rumors) and the contagion of a disease (e.g., COVID-19).
We can model social networks as graphs and use the propagation among nodes to simulate such processes~\citep{kempe2005influential}, and
several \textit{diffusion models} mathematically model such propagation.

While the problem of influence maximization has been widely studied, prior research has also explored  \textit{influence minimization} (\influenceMinimization), where one aims to manipulate graph structures to reduce the propagation among nodes.
\influenceMinimization is relevant to real-world scenarios, such as blocking the spread of rumors or diseases, and it has been studied with several different formulations~\citep{yan2019rumor,ni2023misinformation}.
In this work, we mainly focus on a formulation with edge removal under the independent cascade (IC) model~\citep{kempe2003maximizing}, due to its realisticness and generality; and we provide discussions and experiments on other models, spec., the linear threshold (LT) model~\citep{kempe2003maximizing} and the general Markov chain susceptible-infected-recovered (G-SIR) model~\citep{yi2022edge}, in Appendix~B.
Specifically, the IC model is realistic and widely considered for modeling the spread of information~\citep{tripathy2010study} 
and diseases~\citep{borgs2014maximizing}; 
and edge removal is general, including node removal, another widely considered graph manipulation, as a special case.
For such real-world scenarios, we need timely actions since any delay could witness an exponential explosion in the spread of information~\citep{jin2013epidemiological} and diseases~\citep{platto2021history}.

However, this problem is NP-hard, and even simply computing influence under the IC model is computationally expensive (spec., \#P-hard; \citepnop{chen2010scalable}).
Therefore, several ideas, including Monte Carlo (MC) simulation, bond percolation~\citep{Kimura2009blocking}, reverse influence sampling~\cite{borgs2014maximizing,yi2022edge}, and marginal-decrement heuristics~\citep{yan2019rumor}, are available for influence estimation.
However, they offer limited speed improvements (e.g., due to extensive sampling requirements) and/or rely on assumptions (e.g., acyclic input graphs) that do not generally hold in practice.

Notably, existing methods approach the \influenceMinimization problem as a \textit{discrete} optimization problem, which hinders the application of powerful continuous-optimization (e.g., gradient descent) and machine-learning (e.g., neural networks) techniques.

Instead, we propose a novel method for \influenceMinimization, called \method, with two main \textit{differentiable} schemes:
(1) \textit{surrogate modeling} for efficient influence estimation, 
and (2) \textit{continuous relaxation} of edge removal.
To the best of our knowledge, we are the first to approach influence minimization using \textit{differentiable learning} instead of discrete optimization.

\paragraph{Surrogate modeling.}
First, we propose an efficient scheme for influence estimation.
Inspired by~\citet{ko2020monstor}, we propose to train graph neural networks (GNNs) to ``predict'' the influence when given an input graph and seed nodes (i.e., the nodes where the propagation starts).
Such surrogate modeling leverages the efficiency of GNNs and avoids time-consuming MC simulations or other estimation methods.
Although GNN training introduces additional overhead, it is affordable because once trained in advance, the GNN efficiently estimates the influence of unseen graphs and/or seed nodes.

\paragraph{Continuous relaxation.}
Second, to further enhance speed, we propose to relax the edge removal decisions, so that we can directly optimize continuous (i.e., probabilistic) decisions without evaluating individual edge removal.
Specifically, for each edge, instead of considering a binary decision (to remove it or not), we consider a probabilistic decision representing the probability of removing it.
Such relaxation also allows us to incorporate powerful machine-learning techniques, which typically use gradient descent and thus cannot be naively applied to the original discrete problem.

\paragraph{Gradient-driven selection.}
These two schemes enable us to compute gradients w.r.t. the probabilistic decisions on removing edges, and the gradient of each edge is naturally interpreted as its ``sensitivity''.
Specifically, with influence as the objective, the influence is more sensitive to the edges with higher gradients, and removing such edges is expected to reduce the influence more effectively.
Hence, we further propose our third speed-up scheme, \textit{gradient-driven selection}, that removes edges based on their gradients, without further optimization (spec., gradient descent iterations).

\begin{table}[t!]
    \setlength{\tabcolsep}{1mm}
    \centering
    \begin{adjustbox}{max width=\linewidth}
    \begin{tabular}{c|l}
        \toprule
        \textbf{Symbol} & \textbf{Definition} \\
        \midrule
        $G=(V, E)$ & a graph with a node set $V$ and  an edge set $E$ \\
        $p: E \to [0, 1]$ & activation probabilities \\
        $S \subseteq V$ & a seed set \\
        $\pi(v; G, p, S)$ & the influenced probability of $v$ under $\operatorname{IC}(G, p, S)$ \\
        $\sigma(S; G, p)$ & the expected influence of $S$ under $\operatorname{IC}(G, p, S)$ \\
        $\GNN_\theta(v; G, p, S)$ & the predicted influenced probability of $v$ by $\GNN_\theta$ \\
    \bottomrule
    \end{tabular}
    \end{adjustbox}
    \caption{Frequently-used notations}
    \label{tab:notation}
\end{table}

With the three proposed schemes, we propose three versions, \NAIVE, \ADV, and \ADVP, equipped with the first scheme, the first two schemes, and all three schemes, respectively. More schemes result in faster speed, with little (or even no) \influenceMinimization performance degradation.

Through extensive experiments on three real-world graphs, we show the superiority of the \method family over baselines.
Specifically, all the versions of \method are Pareto-optimal (i.e., no baseline is faster \textit{and} more effective than any version of \method), and they are typically orders of magnitude faster (spec., up to 15,160$\times$) than the most effective baseline, while also being more effective.
We also show their ability to perform well when trained and tested on different graphs.

{In short, our main contributions are three-fold:}
\begin{itemize}  
    \item \textbf{Differentiable learning based approach:} 
    To the best of our knowledge, we are the first to tackle \influenceMinimization using differentiable learning, instead of discrete combinatorial optimization.
    We make this approach feasible by leveraging GNNs as surrogate models and employing the continuous relaxation of edge removal.
    \item \textbf{Gradient-driven acceleration:} We propose another speed-up scheme, \textit{gradient-driven selection}, that selects edges based on their gradients without additional test-time optimization (spec., gradient descent iterations).
    \item \textbf{Extensive experiments:} 
    We demonstrate the empirical superiority of our methods over baselines in \influenceMinimization on real-world graphs, in terms of both speed and effectiveness.
\end{itemize}





\section{Preliminaries}
\label{sec:prelim}
\paragraph{Basic concepts.}
Refer to Table~\ref{tab:notation} for frequently-used notations.
Let $\bbN$ be the set of positive integers, and let $[n]$ be $\{1,\dots, n\}$.
A graph $G=(V, E)$ is defined by a node set $V$ and an edge set $E$.
We consider \textit{directed} edges, i.e.,
each edge $e = (u, v) \in E$ is a directed link from $u \in V$ to $v \in V$.

\begin{definition}[Independent cascade (IC) model]\label{def:IC}
    Given 
    (1) a graph $G = (V, E)$,
    (2) activation probabilities $p: E \rightarrow [0,1]$,
    (3) a seed set $S \subseteq V$, the IC model 
    $\operatorname{IC}(G, p, S)$ is a stochastic process defined as follows:
    \begin{itemize} 
        \item \textbf{Initialization:}         
        At time step $t = 0$, each seed node $v_S \in S$ is activated and each non-seed node remains inactive.
        \item \textbf{Diffusion steps:}
        At each step $t \geq 1$,
        each node $v$ that is activated \textit{in the previous step} $t - 1$ 
        activates each of its inactive out-neighbor $u$ with activation probability $p(v, u)$.\footnote{The set of \textit{out-neighbors} of a node $v$ is $\{u\in V: (v, u)\in E\}$.}
        That is, each activated node remains active for the whole process but can only activate other nodes one step after its activation.
        The process terminates when no node is activated in the previous step.
    \end{itemize}
\end{definition}

As shown in Def.~\ref{def:IC}, the process is stochastic and the states of nodes at the termination are thus probabilistic.

\begin{definition}[Influenced probabilities and expected influence]\label{def:act_prob_and_exp_inf}
    Given $G = (V, E)$, $p: E \to [0, 1]$, and $S \subseteq V$,
    for each node $v \in V$,
    the \textit{influenced probability} of $v$, denoted by $\pi(v; G, p, S)$, is the probability of $v$ being influenced (i.e., active) when the process of $\operatorname{IC}(G, p, S)$ terminates,
    and the expected influence of the seed set $S$,
    denoted by $\sigma(S; G, p)$,
    is defined as the expected number of finally influenced nodes, i.e., $\sigma(S; G, p) \coloneqq \sum_{v \in V} \pi(v; G, p, S)$.
\end{definition}

\paragraph{Graph neural networks (GNNs).}
In GNNs, there are two main types of operators on the node features: feature transformation and propagation~\citep{zhu2021interpreting}.
A feature transformation operator transforms node features at each layer into the next layer via nonlinear transformation.
A propagation operator passes the features of a node to its neighbors,
and updates the feature of each node by aggregating the features of its neighbors,
typically in the form of $H \gets \Tilde{A}H$, where 
$H$ is a node feature matrix, and
$\Tilde{A}$ is a normalized adjacency matrix.
The strength of different edges (i.e., edge weights or edge probabilities) can be incorporated in the entries of $\Tilde{A}$.





\section{Related Work}
\label{sec:related}
\paragraph{Influence estimation.}
As mentioned in Sec.~\ref{sec:intro},
exactly computing the influence under the IC model is costly, and thus
several methods have been proposed for influence estimation.
The most related approach is by~\citet{ko2020monstor}, where graph neural networks (GNNs) are used to learn the influence under the IC model.
The Monte Carlo (MC) simulation (i.e., taking the mean value of samplings) has been a common practice for influence computation~\citep{zhou2013ublf,yang2019influence,manouchehri2021temporal}.
\citet{Kimura2009blocking} used the bond percolation method, and \citet{yi2022edge} used the reverse influence sampling instead of MC, but samplings are still required.

\paragraph{Influence minimization.}
Influence minimization (\influenceMinimization) has been widely studied, and it has several different variants.
Researchers have considered node removal~\citep{zhu2021misinformation, ni2023misinformation}
and edge removal~\citep{Kimura2009blocking, tong2012gelling};
and different models other than IC~\citep{dai2022minimizing} have also been considered (note that we also considered other models; see Appendix~B).
Moreover, prior studies have explored blocking propagation to specific targets~\citep{jiang2022rumordecay,wang2020efficient} and/or without specific seed sets~\citep{zareie2022rumour}, as well as
active defense by propagating opposite information~\citep{budak2011limiting, luo2014time}.
In this work, we consider edge removal under the IC model. While
\citet{yan2019rumor} used the same problem formulation, their analysis, and proposed method were limited to acyclic graphs.
Due to the difficulty of influence computation or even estimation, different heuristics without direct influence estimation have also been considered.
They proposed considering the incremental differences when removing each edge, assuming that the input graph is acyclic.
\citet{tong2012gelling} proposed to choose the edges according to the leading eigenvalues of the adjacency matrix, but the effect of seed nodes is not considered in the method.
See Appendix~D 
for more details on existing \influenceMinimization methods.
Note that no existing method for \influenceMinimization has considered a differentiable learning scheme, which is a novel approach introduced in this work.





\section{Problem Statement and Hardness}
\label{sec:pro_state_hard}

As mentioned in Sec.~\ref{sec:related}, there are different problem formulations for influence minimization (\influenceMinimization).
One can consider different graph manipulation (edge removal or node removal) and different diffusion models.
In this work, we consider the formulation with \textit{edge removal} under the \textit{independent cascade} (IC) model (see Sec.~\ref{sec:prelim}) due to the following reasons:
\begin{itemize}  %[leftmargin=*,topsep=0pt]
    \item The formulation with edge removal is more \textit{general} than that with node removal.
    Specifically, node removal can be seen as edge removal with additional constraints that the edges incident to a node should be all kept or all removed.
    \item Blocking spread between users (i.e., edge removal), such as through contact restriction, is often more feasible than completely removing a user (i.e., node removal).
    \item Regarding the diffusion model, the IC model has been widely considered for the spread of information (e.g., rumors)~\citep{tripathy2010study,xu2015scalable,shelke2019source}
    due to its simple yet realistic nature.   
    However, note that \textbf{our proposed approach is not limited to the IC model} but can be applied to more diffusion models, spec., the linear threshold (LT) model~\citep{kempe2003maximizing} and the general Markov chain susceptible-infected-recovered (G-SIR) model~\citep{yi2022edge}, as explored in Appendix~B. %~\ref{sec:diff_model}.
\end{itemize}
Hereafter, we simply call the considered problem \textit{influence minimization} when no confusion is likely.
\begin{problem}[influence minimization]\label{problem:rumor_blocking} \
\begin{itemize}%[leftmargin=*,topsep=0pt]
    \item \textbf{Given:} 
    a graph $G = (V, E)$, 
    activation probabilities $p: E \to [0, 1]$, 
    a seed set $S \subseteq V$, 
    and a budget $b \in \bbN$,
    \item \textbf{Find:} a set $\calE$ of $b$ edges, i.e., $\calE \subseteq E$ and $|\calE| = b$,
    \item \textbf{to Minimize:} the expected influence of $S$ after removing the edges in $\calE$ from G, i.e., $\sigma(S; G_{\setminus\mathcal{E}}, p_{\setminus\mathcal{E}})$ with $G_{\setminus\mathcal{E}} \coloneqq (V, E\setminus \mathcal{E})$ and
    % and $p_{\setminus\mathcal{E}}: E\setminus \mathcal{E} \to [0, 1]$ with 
    $p_{\setminus\mathcal{E}}(e) = p(e), \forall e \in E\setminus \mathcal{E}$.
\end{itemize}
\end{problem}

We show the NP-hardness of influence minimization (see Appendix~A.1), %~\ref{app:proof:np_hard}), 
and \citet{yan2019rumor} proved that influence minimization is non-submodular.
\begin{theorem}\label{thm:np_hard}
    Influence minimization (Problem~\ref{problem:rumor_blocking}) is NP-hard.
\end{theorem}

\begin{theorem}[\citepnop{yan2019rumor}] \label{thm:non_subm}
    Influence minimization is non-submodular, i.e., $f(\calE; G,$ $p, S) \coloneqq 
\sigma(S; G, p) - 
\sigma(S; G_{\setminus\mathcal{E}}, p_{\setminus\mathcal{E}})$ is not submodular w.r.t. $\calE$. %See Example 4.1 by \citet{yan2019rumor}
\end{theorem}





\section{Proposed Method}
\label{sec:method}

Thms.~\ref{thm:np_hard}-\ref{thm:non_subm} show the non-triviality of influence minimization (\influenceMinimization; Problem~\ref{problem:rumor_blocking}).
Below, we further analyze the challenges in \influenceMinimization and propose our method, \method, to address them.

\subsection{Naive algorithms and their problems}\label{subsec:method:naive_greedy}
Before introducing our method \method, we {discuss} some naive algorithms,
and analyze their problems.

A naive enumeration algorithm evaluates all possible combinations of $b$ edges and chooses the best combination.
This requires computing influence for $\binom{\Abs{E}}{b} = \Theta(\Abs{E}^{b})$ times, which is computationally prohibitive.
One can reduce the frequency of influence computation by adapting it in an incremental manner.
There are $b$ rounds in total, and in each round, we choose an edge whose removal reduces the expected influence of $S$ most.
See Alg.~2 
in Appendix~C 
for the pseudo-code of such an incremental greedy algorithm.
Although such an idea requires computing influence for only $O(b\Abs{E})$ times, as discussed in Secs.~\ref{sec:intro} \& \ref{sec:related}, the exact computation of expected influence is computationally prohibitive,
and the existing estimation methods, e.g., Monte Carlo (MC) simulation, are still time-consuming because they require extensive sampling.
Below, we shall propose multiple schemes to speed up the process of choosing each edge.

\subsection{\NAIVE: Surrogate modeling for efficient influence estimation without simulation}
\label{subsec:method:ours_greedy}
We shall first address the problem of time-consuming estimation of influence.
We propose to use graph neural networks (GNNs), which are computationally efficient.

The high-level idea is to use a GNN as a {surrogate model} (neural approximation) of the influenced probabilities $\pi(\cdot)$ (see Def.~\ref{def:act_prob_and_exp_inf}).
That is, we see $\pi$ as a black-box function,
and we aim to train a $\GNN_{\theta}$ parameterized by $\theta$ such that
$\GNN_{\theta}(v; G, p, S) \approx \pi(v; G, p, S), \forall G, p, S, v$.
{Specifically, $p$ is used as edge weights and $S$ is represented by one-dimensional binary node features.}
Although GNN training introduces additional overhead, it is affordable since it can be done once in advance on existing {or randomly generated} data.
Once trained, $\GNN_\theta$ efficiently estimates the influenced probabilities $\GNN_{\theta}(v'; G', p', S') \approx \pi(v'; G', p', S')$ of new unseen cases (see Sec.~\ref{sec:anal} for complexity analysis), avoiding time-consuming MC simulation or other estimation methods (see Sec.~\ref{sec:related} for examples).

Notably, even with a single input graph, we are able to generate multiple data points by generating different seed sets,
and the training process can be easily extended to multiple graphs.
We first obtain the influence of each training seed set by MC simulation 
and use it as the ``ground-truth'' influence, 
and then update the parameters of the GNN w.r.t. the difference between the predicted influence by the GNN and the ``ground-truth'' {influence.}
Specifically, for each seed set $S_i$, the L2-loss is used, i.e.,
\begin{multline*}
    \mathcal{L}(\GNN_\theta; \Tilde{\pi}, \Set{S_i}, G, p) \\ \coloneqq \sqrt{\sum\nolimits_{v \in V} (\GNN_\theta(v; G, p, S_i) - \Tilde{\pi}(v; G, p, S_i))^2}.
\end{multline*}
The final loss function is averaged over seed sets, i.e.,
\begin{equation*}\label{eq:gnn}
   \resizebox{1.0\hsize}{!}{%
    $\mathcal{L}(\GNN_\theta; \Tilde{\pi}, \calS, G, p) \coloneqq \frac{1}{\Abs{\calS}} {\sum_{S_i \in \calS}{\mathcal{L}(\GNN_\theta; \Tilde{\pi}, \Set{S_i}, G, p)}}$.
  }
\end{equation*}
After training, we can use the trained GNN as a {surrogate model} for each test instance $\calT = (G, p, S, b)$ (see Problem~\ref{problem:rumor_blocking}), while still following an incremental greedy scheme, i.e., choosing the edges one by one with the highest effect estimated by the trained GNN, which results in \NAIVE.
See Alg.~\ref{algo:adv} for pseudo-code of \naive, and see
Alg.~3
in Appendix~C
for that of GNN training.


\subsection{\ADV: Continuous relaxation of edge removal without individual removal evaluation}\label{subsec:method:ours_optim}
Although \naive accelerates influence estimation using GNNs as a surrogate model, \naive still needs to evaluate each individual edge removal (spec., compute the estimated influence when each edge is removed), which can still take considerable time even with efficient influence estimation.
To this end, we propose to use \textit{continuous relaxation} of edge removal to avoid individual edge-removal evaluation.

\paragraph{Continuous relaxation.}
The high-level idea is that, for each edge $e = (v, u)$, instead of a binary decision $r(v, u) = \mathbb{1}((v, u) \notin \calE) \in \Set{0, 1}$ (i.e., to keep it or not; recall $\calE$ is the set of edges to be removed), we consider a \textit{probabilistic} decision
$\Tilde{r}(v, u) = \Pr[(v, u) \notin \calE] \in [0, 1]$, i.e., the probability of keeping $e$.
Such relaxation can be readily incorporated into our surrogate-model-based influence estimation.
Specifically, by the multiplication rule:
$\Pr[\text{$v$ activates $u$ via $(v, u)$}] = 
\Pr[\text{$v$ activates $u$} \land \text{$(v, u)$ is kept}] = p(v, u) \tilde{r}(v, u)$.

\begin{algorithm}[t]
    \caption{\NAIVE~/ \ADV / \ADVP}\label{algo:adv}
    \SetKwInput{KwInput}{Input}
    \SetKwInput{KwOutput}{Output}    
    \KwInput{(1) $G =  (V, E)$: an input graph \\
    \quad\quad\quad (2) $p: E \to [0, 1]$: activation probabilities \\
    \quad\quad\quad (3) $S \subseteq V$: a seed set \\
    \quad\quad\quad (4) $b$: an edge-removal budget \\
    \quad\quad\quad (5) $\GNN_{\theta}$: a trained GNN \\
    \quad\quad\quad (6) $\Tilde{r}: E \to [0, 1]$: initial probabilistic decisions
    
    
    \hspace*{0pt}\hfill $\triangleright$\ For \ADV and \ADVP \\
    \quad\quad\quad (7) $n_{ep}$: the number of epochs for each removal 
    
    \hspace*{0pt}\hfill $\triangleright$\  For \ADV only \\
    }
    \KwOutput{$\mathcal{E} \subseteq E$: a set of edges chosen to be removed}    
    $\calT \leftarrow (G, p, S, b)$ \hspace*{0pt}\hfill $\triangleright$\ {Initialize the \influenceMinimization problem instance $\calT$}\\
    $\mathcal{E} \leftarrow \emptyset$ \hspace*{0pt}\hfill $\triangleright$\ {Initialize the set of edges to be removed} \\
    \For{$i = 1, 2, \ldots, b$}{        
        $e=$ \texttt{EdgeSelection()} or \texttt{EdgeSelection+()} or \texttt{EdgeSelection++()}
        \hspace*{0pt}\hfill $\triangleright$\ {Select an edge} \\
        $E \leftarrow E\setminus \{e\}$;        $\mathcal{E}\leftarrow\mathcal{E}\cup\{e\}$ \hspace*{0pt}\hfill $\triangleright$\ {Remove the edge} \\
        $G \leftarrow (V, E)$;
        $\calT \leftarrow (G, p, S, b)$
        \hspace*{0pt}\hfill $\triangleright$\ {Update the graph}
        \\
    }
    \Return $\mathcal{E}$
    \label{algo:adv:end}
    
    \vspace{1mm}
    
    \SetKwFunction{FMain}{EdgeSelection}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMain{}}{
        \Return $\arg\min_{e\in E } \sum_{v \in V} \GNN_{\theta}(v; G, p_{\setminus \calE}, S)$\label{algo:naive:find} \\ 
    } 
    
    \vspace{1mm}
    
    \SetKwFunction{FMainp}{EdgeSelection+}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMainp{}}{
        \For{$j = 1, 2, \ldots, n_{ep}$}{
            Compute the derivative $\nabla_{\Tilde{r}} \calL := \frac{\partial \calL_{O}(\Tilde{r}; \calT, \GNN_{\theta})}{\partial \Tilde{r}}$ \label{algo:adv:compute} \\
            Update $\Tilde{r}$ via gradient descent {w.r.t. $\nabla_{\Tilde{r}} \calL$}
            \label{algo:adv:update}\\
        }
        \Return $\arg\min_{e\in E} \tilde{r}(e)$ \\
    }
    
    \vspace{1mm}
    
    \SetKwFunction{FMainpp}{EdgeSelection++}
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\FMainpp{}}{
        $\nabla_{\tilde{r}}(e)=\frac{\partial \sum_{v \in V} \GNN_{\theta}(v; G, p_{\setminus \calE}, S)}{\partial \tilde{r}(e)}, \forall e \in E$\\
        \Return $\arg\max_{e\in E} \nabla_{\tilde{r}}(e)$\\
    }
\end{algorithm}

Therefore, given 
activation probabilities $p: E \to [0, 1]$ and
probabilistic decisions $\tilde{r}: E \to [0, 1]$ on the edges,
we obtain the \textit{modified activation probabilities} 
$\Tilde{p}_{\Tilde{r}}: E \to [0, 1]$
by
$\tilde{p}_{\Tilde{r}}(v, u) \coloneqq p(v, u) \Tilde{r}(v, u), \forall (v, u) \in E$.
Specifically, given 
a graph $G = (V, E)$, 
activation probabilities $p$,
a seed set $S \subseteq V$,
a trained $\GNN_{\theta}$, 
and probabilistic edge-removal decisions $\Tilde{r}$,
the influenced probability of each node $v \in V$ is estimated as
$\GNN_{\theta}(v; G, \Tilde{p}_{\Tilde{r}}, S)$.
Notably, such an estimated influenced probability is differentiable w.r.t. $\Tilde{r}$.

\begin{lemma}\label{lem:gnn_diff}
    $\GNN_{\theta}(v; G, \Tilde{p}_{\Tilde{r}}, S)$ is differentiable w.r.t $\Tilde{r}$.
    
    \noindent \textit{Proof.} \normalfont{See Appendix~A.2.} 
    \qed
\end{lemma}


\paragraph{Differentiable optimization.}
After training $\GNN_{\theta}$, by Lemma~\ref{lem:gnn_diff}, we can now conduct \textit{differentiable} optimization on the probabilistic edge-removal decisions for each test instance $\calT = (G, p, S, b)$ of the \influenceMinimization problem (see Problem~\ref{problem:rumor_blocking}), which results in \ADV (see Alg.~\ref{algo:adv}).
The high-level process is as follows: we fix $\GNN_\theta$ after training, and only update $\Tilde{r}$ to minimize the loss $\calL_{O}$, which has three parts:
\begin{equation}\label{eq:loss_optimize}
    \calL_{O} := \mathcal{L}_\text{obj}
    +\alpha \calL_\text{budget}
    +\beta \calL_\text{certainty},
\end{equation}
where the loss coefficients, $\alpha$ and $\beta$, are hyperparameters.

The first part $\calL_{\text{obj}}$ is regarding the main optimization objective of \influenceMinimization (Problem~\ref{problem:rumor_blocking}), defined as
\begin{multline*}
    \calL_{\text{obj}}(\Tilde{r}; \calT, \GNN_\theta) \\
    := \textstyle{-\frac{\sum_{v \in V} (\GNN_\theta(v; G, p, S) - \GNN_\theta(v; G, \Tilde{p}_{\Tilde{r}}, S))}
    {\sum_{v \in V} \GNN_\theta(v; G, p, S) -\Abs{S}}},
\end{multline*}
which is the \textit{reduction ratio} in the estimated number of influenced non-seed nodes.
Specifically, the numerator is the estimated influence reduction after the probabilistic edge removal $\Tilde{r}$ is applied, and the denominator is the estimated number of influenced non-seed nodes before the edge removal.
When the surrogate model is perfectly accurate, minimizing $\calL_{\text{obj}}$ is equivalent to optimizing the objective of \influenceMinimization.

The second part $\calL_{\text{budget}}$ is regarding the budget constraint:
\begin{equation*}
\calL_{\text{budget}}(\Tilde{r}; \calT, \GNN_\theta) := ({\Abs{E} - \sum\nolimits_{e\in E} \Tilde{r}(e)-b})^2,
\end{equation*}
which is the squared difference between the expected number of removed {edges and the required budget.}
When the budget is exactly used, $\calL_{\text{obj}}$ is $0$, i.e., minimized.

The third part $\calL_{\text{certainty}}$ is regarding the certainty (i.e., closeness to binary) of the probabilistic decisions $\Tilde{r}$:
\begin{multline*}
    \mathcal{L}_\text{certainty}(\Tilde{r}; \calT, \GNN_\theta) \\ := \textstyle{\frac{\sum_{e\in E} (\Tilde{r}(e)\log r(e) - (1-\Tilde{r}(e))\log (1-\Tilde{r}(e)))}{\Abs{E}},}
\end{multline*}
which is inspired by the Shannon entropy,
and $\mathcal{L}_\text{certainty}$ is smaller when {each $\Tilde{r}(e)$ is closer to $0$ or $1$.}

Even with continuous relaxation, optimizing $\calL_O$ remains closely aligned with the \influenceMinimization problem, as discussed in Appendix~A.3.
In Alg.~\ref{algo:adv}, we show pseudo-code of \adv, where some details (e.g., how we initialize and normalize $\tilde{r}$) are omitted and will be deferred to Sec.~\ref{sec:experiments} when we describe the detailed experimental settings.
Given initial probabilistic decisions $\Tilde{r}$, in each iteration, we update it via gradient descent according to the loss function $\Tilde{L}_O$ (Eq.~\eqref{eq:loss_optimize}) and its derivative.
For each specified number $n_{ep}$ of epochs, the edge with the smallest $\tilde{r}(e)$ value is removed.


\subsection{\ADVP: Gradient-driven selection without test-time gradient-descent optimization}\label{subsec:method:ours_instant}
The previous two schemes entail differentiability, enabling us to compute gradients w.r.t. the probabilistic decisions on edges.
The gradient of each edge can be naturally interpreted as its ``sensitivity''.
Specifically, the influence is more sensitive to the edges with higher gradients, and removing such edges is expected to reduce the influence more effectively.
Hence, we propose \ADVP with \textit{gradient-driven edge selection}, which \textit{instantly} removes the edge with the largest gradient in each round, instead of performing optimization (spec., gradient descent) over many epochs.

Alg.~\ref{algo:adv} shows pseudo-code of \advp.
After training $\GNN_{\theta}$, for each test instance $\calT = (G = (V, E), p, S, b)$ of the \influenceMinimization problem,
we compute the derivatives on all edges,
\begin{center}
    $\nabla_{\tilde{r}}(e; \calT) \coloneqq \frac{\partial \sum_{v \in V} \GNN_\theta(v; G, p, S)}{\partial \Tilde{r}(e)}, \forall e \in E$,
\end{center}
and remove the edge with the largest $\nabla_{\tilde{r}}(e; \calT)$ in each round.

\paragraph{Discussion.}
For \ADV, instead of removing edges one by one after $n_{ep}$ epochs, one can choose the bottom-$b$ edges with the lowest $\Tilde{r}$ values at once. 
Similarly, for \ADVP, one can choose the top-$b$ edges with the largest gradient at once.
Empirically, we observe that choosing edges at once in such a way achieves similar or worse performance. 
See Appendix~G.3 
for more detailed results and discussions.


\subsection{Time and space complexities}\label{sec:anal} 
Given a test instance $\calT = (G = (V,E), p, S, b)$ of the \influenceMinimization problem,
assume that 
(1) we use graph convolutional networks (GCNs; \citepnop{kipf2016semi}) with a constant number of layers, as in our experiments, 
(2) the dimensions of hidden features are fixed as constant, which are indeed fixed and much smaller than the size of graphs in our experiments, and
(3) the input graph is sparse (specifically, $\Abs{E} = \Theta(\Abs{V})$), which is indeed true for the datasets in our experiments (see Table~\ref{tab:data}), 
we can derive the time and space complexity of \method based on existing results~\citep{chiang2019cluster,blakely2021time}.

\paragraph{\naive.}
A forward pass of GCN takes $O(\Abs{E})$ time.
In each round, we conduct $O(\Abs{E})$ forward passes, with $b$ rounds in total.
Thus, the time complexity of \naive is $O(b\Abs{E}^2)$.

\paragraph{\adv.}
A backward pass of GCN takes $O(\Abs{E})$ time,
and there are $b$ rounds each with $n_{ep}$ epochs (see Alg.~\ref{algo:adv}).
Therefore, the time complexity of \adv is $O(n_{ep}b\Abs{E})$.

\paragraph{\advp.}
We conduct one backward pass in each of the $b$ rounds, so
the time complexity of \advp is $O(b\Abs{E})$.

\paragraph{Note.}
Regarding the time complexity, 
\naive $>$ \adv $>$ \advp,
as intended.

\paragraph{Space complexity.}
For each version, it is 
$O(\Abs{E} + \Abs{V}) = O(\Abs{E})$, 
dominated by the space complexity of GCN.





\section{Experiments}
\label{sec:experiments}

\begin{table}[t]
    \centering
    \setlength{\tabcolsep}{1mm}
    \begin{tabular}{l|l|r|r|r|r}
        \hline
        \multirow{2}{*}{{dataset}} &\multirow{2}{*}{{abbr.}} &  \multicolumn{2}{c|}{{training graph}} & \multicolumn{2}{c}{{test graph}} \bigstrut \\
        \cline{3-6}        &&\textbf{$|V|$}&\textbf{$|E|$}&\textbf{$|V|$}&\textbf{$|E|$} \bigstrut\\
        \hline
        WannaCry & \WL & $16,246$ & $84,217$ & $19,381$ & $85,202$ \bigstrut[t]\\
        Celebrity & \CL & $7,848$ & $28,839$ & $7,336$ & $27,699$\\ 
        Extended & \EL & $5,636$ & $31,826$ & $5,413$ & $27,146$ \bigstrut[b]\\
        \hline
    \end{tabular}
    \caption{Basic statistics of the real-world datasets.}
    \label{tab:data}
\end{table}

We performed experiments on real-world graphs, 
aiming to answer the following questions:
\begin{itemize}  
    \item \textbf{Q1. Performance:} {How effectively and quickly does \method minimize influence?} 
    \item \textbf{Q2. Scalability:} How does the running time of \method grow with the budget $b$?
    \item \textbf{Q3. Influence estimation quality:} How well does the surrogate GNN model in \method estimate the influence?
    \item \textbf{Q4. Inductivity:} How does \method perform when trained and tested on different/same graphs? 
    \item \textbf{Q5. Ablation studies:} How does each component or algorithmic design affect the performance of \method?
\end{itemize}




\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.9\linewidth]{figure_performance.jpg}
    \caption{The effectiveness (the reduced ratio of influence) and running time of each method, with budget $b=5$ (top) and $b=10$ (bottom). 
    The baselines with outputs independent of seed sets were represented as horizontal lines.
    We compared the running time of the best baseline to one of our methods with the most similar reduced ratio, and in all cases, \method was
    30 $\times$ to 15,160 $\times$ faster.
    See  Appendix~G.1 for full results with standard deviations.}
    \label{fig:perf_6layer}
\end{figure*}




\subsection{Experimental settings}\label{subsec:exp:setting}

\paragraph{Datasets.} We used three real-world social-network datasets from~\citet{ko2020monstor}: \WL, \CL, and \EL, consisting of interactions logs, e.g., retweets among users~\citep{sabottke2015vulnerability}.
Such interactions naturally represent people's impact on others, i.e., influence.
We provided their basic statistics in Table~\ref{tab:data}.
Each dataset was split into training and test graphs based on a time threshold $t_{th}$: edges before $t_{th}$ were used for training, and those after were used for testing.

\paragraph{Baselines.} We considered the following baselines: 
\begin{enumerate}[align=left,leftmargin=*,topsep=0pt,itemsep=0pt]
    \item \textbf{\textsc{Random}} removes $b$ edges chosen uniformly at random.
    \item  \textbf{\textsc{OdC}} (Out-degree Centrality; \citepnop{kempe2003maximizing})
    removes the top-$b$ edges w.r.t. the sum of out-degrees of their two endpoints.\footnote{{The out-degree of each node $v \in V$ is $\lvert\{u\in V: (v, u)\in E\}\rvert$.}}
    \item \textbf{BC} (Betweenness Centrality; \citepnop{schneider2011suppressing})
    removes the top-$b$ edges w.r.t edge betweenness.
    \item \textbf{PR} (PageRank; \citepnop{page1998pagerank})
    removes the top-$b$ edges w.r.t. the sum of the PageRank scores of their endpoints.
    \item \textbf{\KED}~\cite{tong2012gelling} removes the $b$ edges {to minimize} the leading eigenvalue of the adjacency matrix.
    \item \textbf{\MDS}~\cite{yan2019rumor} greedily removes $b$ edges w.r.t. the importance scores estimated by influenced probability and rumor-spread ability of their endpoints.
    \item \textbf{BPM}~\cite{Kimura2009blocking} 
    removes the top-$b$ edges w.r.t. importance scores estimated using the bond percolation method (BPM).
    BPM does not consider specific seed nodes.
    \item \textbf{Modified \BPM (\MBPM)} is a modified version of \BPM that considers specific seed nodes.
    \item \textbf{\Greedy} removes $b$ edges greedily with influence estimated by Monte Carlo (MC) simulation.
    \item \textbf{\RIS}~\cite{yi2022edge} estimates the importance of each edge for propagating to other nodes using sampling, and removes the $b$ most important edges.
\end{enumerate}
For MBPM and \Greedy, a number after their names denotes the number of samplings (e.g., \Greedy-100 denotes \Greedy with $100$ samplings). 
For \RIS, a small $\epsilon$ increases sampling numbers and improves edge importance estimation accuracy.
Note that all these baselines approach \influenceMinimization as a discrete combinatorial optimization problem. See Appendix~E for more details on the baselines.





\paragraph{\method.}
For each training graph, we generated 1,000 random seed sets, using 800 for training and 200 for validation.
For each test graph, we generated 50 random seed sets and reported average performance, where we used 10,000 Monte Carlo simulations as the ``ground-truth'' influence, following the settings by~\citet{kempe2003maximizing}.
We consistently used a graph convolutional network (GCN) with six layers and a final fully connected layer.
For \adv, the probabilistic decisions $\Tilde{r}$ were optimized (see Alg.~\ref{algo:adv}) in $n_{ep}=100$ epochs for each removal with $\alpha = 0.1$ and $\beta = 1$.

\paragraph{Seed set generations.}
For each seed set,
the size was sampled uniformly between 10 and $\lfloor 0.01|V| \rfloor$ (inclusive),
and then the nodes were sampled uniformly.

\paragraph{Probabilistic decisions.}
The probabilistic decisions $\Tilde{r}$ were normalized by a sigmoid function $\sigma_\text{sigmoid}(x)=\frac{1}{1+e^{-x}} \in [0, 1]$. We used initial probabilistic decisions $\tilde{r}(e)=\sigma_\text{sigmoid}(x)=1-\frac{b}{|E|},\forall e\in E$, which makes the loss $\calL_{\text{budget}}$ regarding the budget constraint to be $0$ (see Sec.~\ref{subsec:method:ours_optim}).
See Appendix~F for more details of the experimental settings, e.g., hardware information.




\subsection{\textbf{Q1. Performance}}\label{sec:exp_perf}
We shall show that \method showed good performance in influence minimizing (IMIN; Problem~\ref{problem:rumor_blocking}) in terms of effectiveness (the reduced ratio of influence) and efficiency (the running time).
Formally, the reduced ratio $R_r$ is defined as
\begin{equation}\label{eq:reduced_ratio}
 R_r(\calE; G, p, S) \coloneqq \textstyle{\frac{\sigma(S; G, p)-\sigma(S; G_{\setminus{\mathcal{E}}},p_{\setminus{\mathcal{E}}})}{\sigma(S; G,p)-\Abs{S}}.}
\end{equation}
A higher $R_r$ implies higher effectiveness in \influenceMinimization.



\begin{figure}[t!]
    \centering
        \includegraphics[width=\linewidth]{figure_scalability.jpg}
        \includegraphics[width=0.4\linewidth]{figure_scalability_legend.jpg}
    \caption{The running time of each \method version when budget $b$ increases from $1$ to $10$. 
    The running time of each version grew linearly with $b$, showing good scalability.}
    \label{fig:budget_6layer}
\end{figure}

\begin{figure}[t!]
    \centering
        \includegraphics[width=1\linewidth]{figure_R.jpg}
    \caption{
    The Pearson correlation coefficients
    between the ground-truth influence of the validation sets and that estimated by MC simulation of a trained GNN.
    In all the cases, trained GNNs estimated influences near-perfectly.}
    \label{fig:Rvalue_6layer}
\end{figure}




In Fig.~\ref{fig:perf_6layer}, we reported the average reduced ratio of influence and running time across all the test seed sets for each dataset and method, using budgets $b \in \Set{5, 10}$.
Methods taking more than one hour on a single seed set were considered ``out of time'' and excluded.
Several baselines (\textsc{random}, \textsc{OdC}, BC, PR, \BPM, and \KED) do not depend on the seed set, and can be executed once for all seed sets.
Hence, we represented the performance of each of those methods as a horizontal line.
All the versions of \method were Pareto-optimal, i.e., no baseline was faster and more effective than any version, with at least one version outperforming all the baselines w.r.t. effectiveness in each case.
In most cases, all the versions outperformed all the baselines w.r.t. effectiveness.
Specifically, \method achieves 30 $\times$ to 15,160 $\times$ speed-up with similar effectiveness.
Notably, for \WL, \RIS-$\epsilon$ ran out of time for each $\epsilon \in \{0.2, 0.4, 0.6\}$.
As intended, the more proposed schemes we use, the higher speed we have (w.r.t. speed, \naive $<$ \adv $<$ \advp).
The effectiveness of different versions did not vary much, yet we observed an overall trend: \naive $>$ \adv $>$ \advp.
See Fig.~5 and Table~7 in Appendix~G.1 for the full results with standard deviations with different budgets $b \in \Set{3,5,7,10}$.






\subsection{\textbf{Q2. Scalability}}\label{sec:exp_sca}
In Fig.~\ref{fig:budget_6layer}, we reported the running time of all \method versions on each dataset with different budgets.
As the budget $b$ increased from 1 to 10, the running time increased almost linearly for all versions, which validated our analysis on the time complexity in Sec.~\ref{sec:anal}.
Our analysis in Sec.~\ref{sec:anal} also implies that \adv and \advp have better scalability w.r.t. the input graph size than \naive. % remove in Sec.~\ref{sec:anal}
Specifically, the time complexity of \naive is quadratic in $\Abs{E}$ while that of \adv and \advp is linear, which was also validated in Fig.~\ref{fig:budget_6layer},
where the running time gap between \naive and the other two versions increased on the larger dataset \WL.
In Table 9 in Appendix~G.2, for each method and each dataset, we provided the minimum budget $b$ for the method to run out of time (i.e., take more than one hour on a single seed set).




\subsection{Q3. Influence estimation quality}\label{sec:exp_train}
We shall show that our surrogate GNNs were trained well for influence estimation.
In Fig.~\ref{fig:Rvalue_6layer}, for the validation seed sets (recall that for each training graph, we generated 1,000 random seed sets, using 800 training and 200 for validation; see Sec.~\ref{subsec:exp:setting}), we reported the 
Pearson correlation coefficients (Pearson's $r$)
between the influence obtained by MC simulation (seen as the ground truth) and that estimated by the trained GNNs.
The estimation by the GNNs was highly correlated with the ground truth.
Specifically, the trained GNNs achieved a Pearson's $r$ of $0.999$ or higher on each dataset.
See Appendix~G.4 for more details, e.g., how the estimation errors decreased along training.

We reported the training times for GNNs in Table~\ref{tab:GNN_time_training} and compared the influence estimation times of GNNs with MC simulations in Table~\ref{tab:GNN_time_running}. 
Overall, the estimation times of GNNs were at least 100$\times$ faster than those of the MC simulations.

\begin{table}[t!]
    \centering  
    \begin{tabular}{c|r|r|r}
        \hline
        datasets & \multicolumn{1}{c|}{\WL}   & \multicolumn{1}{c|}{\CL}   & \multicolumn{1}{c}{\EL} \bigstrut \\
        \hline
        time (in seconds) &  17,227 & 7,390 & 6,818 \bigstrut \\
        \hline
    \end{tabular}
    \caption{Average training time (in seconds) for GNNs.}
    \label{tab:GNN_time_training}
\end{table}

\begin{table}[t!]
    \centering  
        \begin{tabular}{c|c|c|c}
        \hline
        estimation method   & \WL   & \CL   & \EL   \bigstrut \\
        \hline
        GNN & 0.0082 & 0.0056 & 0.0056 \bigstrut[b]  \bigstrut \\
        MC simulation & 3.7757 & 0.8276  & 0.7817 \bigstrut \\
        \hline
    \end{tabular}
    \caption{Average time (in seconds) to estimate influence for each seed set using GNNs and MC simulations. MC simulations were repeated 10,000 times for estimation.}
    \label{tab:GNN_time_running}
\end{table}

\begin{table*}[t!]
    \setlength{\tabcolsep}{1mm}
    \centering
    
    \begin{tabular}{l||c|c|c||c|c|c||c|c|c}
        \hline
         method & \multicolumn{3}{c||}{\naive} &\multicolumn{3}{c||}{\adv} & \multicolumn{3}{c}{\advp} \bigstrut \\ 
        \hline
        dataset & \WL & \CL & \EL & \WL & \CL & \EL & \WL & \CL & \EL  \bigstrut \\
        \hline
        transductive
        &0.4311 &0.6547 &0.5613 
        &0.3914 &0.6614 &0.5332 
        &0.3876 &0.6583 &0.4718 \bigstrut[t] \\
        inductive
        &0.4256 &0.6394 &0.5429 
        &0.3910 &0.6534 &0.5045 
        &0.3692 &0.6230 &0.5050 
        \\
        (difference)&(-1.3\%)&(-2.3\%)&(-3.3\%)
        &(-0.1\%)&(-1.2\%)&(-5.4\%)
        &(-4.7\%)&(-5.4\%)&(+7.0\%) \bigstrut[b]\\
        \hline
        \makecell[l]{strongest baseline (transductive)}
        &0.3160 &0.5591 &0.5284 
        &0.3160 &0.5591 &0.5284 
        &0.3160 &0.5591 &0.5284 
        \bigstrut \\
    \hline
    
    \end{tabular}
    \caption{The effectiveness (the reduced ratio of influence) of each \method version {when budget $b=5$}, and the comparison between the performance in transductive and inductive settings, with each percentage being the difference ratio (negative means the effectiveness in inductive settings was lower).
    In all the cases, the effectiveness of each \method version was only slightly lower (or even higher) in the inductive setting. Importantly, \method outperformed all the baselines in most cases in both transductive and inductive settings.
    \label{tab:induct_6layer}
    }
\end{table*}

\begin{table}[t]
    \centering
    \begin{tabular}{l|c|c|c}
        \hline
        loss & \WL & \CL & \EL  \bigstrut \\
        \hline
        original     &\textbf{0.3914} &\textbf{0.6614} &\textbf{0.5332} \bigstrut[t]\\
        $-\mathcal{L}_{\text{budget}}$     &0.0052 &0.0112 &0.0170 \\
        $-\mathcal{L}_{\text{certainty}}$  &0.3891 &0.6479 &0.5282 \bigstrut[b] \\
    \hline
    \end{tabular}
    \caption{The effectiveness (the reduced ratio of influence) of \adv on budget $b=5$ when removing different parts of the loss function (Eq.~\eqref{eq:loss_optimize}).
    Each part was helpful, and $\calL_{\text{budget}}$ was much more helpful than that of $\calL_{\text{certainty}}$.
    }
    \label{tab:ab_6layer}
\end{table}



\subsection{Q4. Inductivity}\label{sec:exp_induct}
In Table~\ref{tab:induct_6layer}, we compared the effectiveness (the reduced ratio of influence; see Eq.~\eqref{eq:reduced_ratio}) of all \method  versions in the transductive setting 
(trained and tested on the same dataset) 
and the inductive setting
(trained and tested on different datasets) {when budget $b=5$}.
Note that even for the transductive setting, the training and test graphs were different (spec., different timestamps), and the seed sets were different (see Sec.~\ref{subsec:exp:setting}).
In the inductive setting, on each dataset, we tested the two models that were trained on the other two datasets. 
The reported performance was the average of the results from these two models.
In most cases, the effectiveness of our methods was higher in the transductive setting than in the inductive setting.
From transductive to inductive settings, their effectiveness dropped by at most 5.4\%.
In most cases and settings, the effectiveness of our methods is higher than the most effective baseline (which was transductive and much slower than \adv and \advp), showing the good inductivity of our methods.












\subsection{Q5. Ablation studies}\label{subsec:exp:ablation}
We evaluated the importance of $\calL_{\text{budget}}$ and $\calL_{\text{certainty}}$ in the loss function of \adv (see Eq.~\eqref{eq:loss_optimize}).
In Table~\ref{tab:ab_6layer}, we compared the effectiveness (the reduced ratio of influence) of \adv on budget $b=5$ when using the whole loss function and when removing $\calL_{\text{budget}}$ or $\calL_{\text{certainty}}$.
We observed the effectiveness of \adv droped significantly without $\calL_{\text{budget}}$, showing the significance of $\calL_{\text{budget}}$.
{The effectiveness of $\calL_{\text{certainty}}$ was marginal, but it was necessary for theoretical guarantees (see Lem.~2 in Appendix~A.3).}




\subsection{Additional experiments}
We also conducted experiments on \textbf{two more influence diffusion models}, specifically, the linear threshold (LT) model~\citep{kempe2003maximizing} and the general Markov chain susceptible-infected-recovered (G-SIR) model~\citep{yi2022edge}.
On these models, \method still showed empirical superiority, being significantly faster than the most effective baseline, while achieving a similar reduced ratio of influence.
See Appendix~B for more details.

In addition, we conducted experiments on large-scale datasets.
Due to the absence of realistic activation probabilities, for these datasets, we used the weighted cascade model~\citep{kempe2003maximizing}, a special case of the IC model where the activation probability of each edge from node $u$ to $v$ is $1$ divided by the in-degree of $v$.
On these datasets, many strong baselines ran out of time or memory, and \method consistently outperformed those that completed within the given limits.
See Appendix~G.5 for details.

Furthermore, in Appendix~G, we presented additional experimental results on (1) the detailed trade-off between time and reduction ratio, (2) scalability w.r.t. budgets, and (3) comparisons with variants of \method missing certain components. Overall, we demonstrate the superiority of \method over baseline methods in terms of trade-offs and scalability, and the importance of each component in \method.





\section{Conclusions}
\label{sec:conclusion}
In this work, we studied influence minimization (\influenceMinimization) with edge removal under the independent cascade (IC) model, with more models discussed in Appendix~B.
We proposed \method (Sec.~\ref{sec:method}), which incorporates two key schemes:
\textit{surrogate modeling} for efficient influence estimation (Sec.~\ref{subsec:method:ours_greedy}) 
and \textit{continuous relaxation} of edge removal (Sec.~\ref{subsec:method:ours_optim}).
Additionally, we proposed \textit{gradient-driven edge selection} for instant edge selection without test-time gradient descent iterations (Sec.~\ref{subsec:method:ours_instant}).
Our extensive experiments demonstrated that all three schemes improved the speed of \method with little (or even no) \influenceMinimization performance degradation, in addition to its superior speed and effectiveness over baselines (Sec.~\ref{sec:exp_perf}). 
We also showed its scalability (Sec.~\ref{sec:exp_sca}) and 
ability to perform well when trained and tested on different graphs (Sec.~\ref{sec:exp_induct}). 

Our future work will extend our approach to other influence-related graph problems.
For example, our method can be adapted to the influence maximization problem~\citep{kempe2003maximizing}, whose objective is to identify the most influential seed set, by (1) introducing a global seed node linked to all existing nodes with 100\% activation probabilities and (2) selectively removing some of these new edges to maximize the influence of the seed node.

%\paragraph{Reproducibility.} Our code, datasets, and online appendix are available at \cite{appendix}.





\section*{Acknowledgements}
This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. RS-2024-00406985, 50\%). This work was supported by Institute of Information \& Communications Technology Planning \& Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2022-0-00871 / RS-2022-II220871, Development of AI Autonomy and Knowledge Enhancement for AI Agent Collaboration, 40\%) (No. RS-2019-II190075, Artificial Intelligence Graduate School Program (KAIST), 10\%).

\bibliography{aaai25}

\input{appendix/appendix}

\end{document}