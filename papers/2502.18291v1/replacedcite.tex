\section{Related work}
\subsection{Graph Neural Networks}
Graph Neural Networks use deep neural network techniques to learn effective graph representations. They are divided into two main types: spectral methods and spatial methods. Spectral methods define graph convolution operations based on graph spectral theory. For example, ____ uses the graph Laplacian's eigenvectors in the Fourier transform domain for graph convolution, ____ approximates $K$-order polynomial spectral filters using Chebyshev polynomials, and GCN ____ simplifies the Chebyshev polynomials to the first order for effective layer-by-layer propagation. In contrast, spatial methods define graph convolution by aggregating the spatial neighborhoods of nodes. For instance, GraphSAGE ____ samples and aggregates representations from local neighborhoods in an inductive framework, while GAT ____ introduces an attention mechanism to adaptively aggregate neighborhood representations of nodes.

\subsection{Graph Similarity Learning}
Graph similarity learning aims to find a function that measures the similarity between two graphs. Traditional methods like GED ____ and MCS ____ have exponential time complexity, limiting their use for large graphs. Graph kernel methods ____ offer an alternative but require high computational and storage costs. Recently, Graph Neural Networks (GNNs) have been used for graph similarity learning. SimGNN ____ uses histogram features and neural tensor networks ____ to model interactions at node and graph levels, respectively. GraphSim ____ extends SimGNN by incorporating convolutional neural networks to capture complex node-level interactions. GMN ____ propagates node representations within each graph and across attention-based neighbors from another graph. HGMN ____ compares node representations from one graph with the representation of the entire other graph to enable cross-graph interaction. H2MN introduces hypergraphs to model substructure similarity between graphs ____, and other works ____ segment graphs into subgroups for node-level comparisons.

____ proposed a learning-based method called Neural Supergraph Similarity Search (NSS) to address the hypergraph search problem. This method efficiently performs hypergraph search in the vector representation space by learning the representations of query and data graphs. In ____, a novel approach was introduced for efficient graph similarity search in large-scale graph databases, aiming to solve the graph similarity search problem under graph edit distance constraints. Similarly, ____ also introduced a technique focused on efficient graph similarity search in large graph databases, specifically addressing the challenge of graph similarity under edit distance constraints. ____ introduced C-MPGCN, a graph-based deep metric learning algorithm designed for regional similarity learning. This method aims to overcome the limitations of existing approaches, which often overlook spatial relationships and important features, by representing regions as graphs and using graph convolutional networks combined with contrastive learning to predict regional similarities. In ____, the authors proposed an algorithm named INFMCS (Similarity Computation via Maximum Common Subgraph Inference) for graph similarity computation. This algorithm seeks to address the lack of interpretability in existing learning methods for graph similarity measurement, by implicitly inferring the maximum common subgraph (MCS) to compute graph similarity, thereby making the process more interpretable.

\subsection{Graph Transformer}
The integration of Graph Neural Networks with Transformer architectures is increasingly being used to address challenges in graph networks. The existence of Graph Transformers has enhanced the performance of GNNs in handling long-range dependencies and large-scale graph data ____. The Simplified Graph Transformer (SGFormer) ____ significantly improves performance and computational speed with just one layer of attention. The extensive, robust, and scalable GPS ____ has expanded the model to various graph sizes and replaced the Transformer with a variant with linear computational complexity to enhance computational efficiency. Graph similarity calculation networks based on Graph Transformers ____ have also been proposed, where Transformer modules are used to facilitate cross-graph information interaction, with Key and Value from one graph and Query from another, to perform node-level interaction calculations.