\subsection{Related Works}\label{sec:related_works}
We categorize related works into three key aspects.
\paragraph{Guidance (a.k.a. test-time reward optimization) in diffusion models.} 

Most classical approaches involve classifier guidance \citep{dhariwal2021diffusion, song2021score}, which adds the gradient of reward models (or classifiers) during inference. As reviewed in \citep{uehara2025reward}, recently, derivative-free methods such as SMC-based guidance \citep{wu2024practical, dou2024diffusion, phillips2024particle,cardoso2023monte} or value-based sampling \citep{li2024derivative} have been proposed. However, these methods rely on single-shot generation from noisy states to denoised states. In contrast, we propose a novel iterative refinement approach that enables the optimization of complex reward functions, which can be challenging for single-shot reward-guided generation. 

Note while classifier-free guidance \citep{ho2022classifier} and RL-based fine-tuning~\citep{fan2023dpok,black2023training} also aim to address reward optimization in diffusion models, they are orthogonal to our work, as we focus on test-time techniques without any training.

\vspace{-2mm} \paragraph{Refinement in language models.}   

Refinement-style generation has been explored in the context of BERT-style masked language models and general language models \citep{novak2016iterative, guu2018generating, wang2019bert,welleck2022generating, padmakumar2023extrapolative}. However, our work is the first attempt to study iterative refinement in diffusion models. Note that while some readers may consider editing in diffusion models \citep{huang2024diffusion} to be relevant
, this is a distinct area, as the focus is not on reward optimization, unlike our work.

\vspace{-2mm}
\paragraph{Evolutionary algorithms and MCMC for biological sequence design.}

Refinement-based approaches with reward models, such as variants of Gibbs sampling and genetic algorithms, have been widely used for protein/DNA design \citep{anishchenko2021novo,jendrusch2021alphadesign,hie2022high,gosai2023machine,pacesa2024bindcraft}. However, most works do not address the integration of diffusion models. While some studies focus on integrating generative models \citep{hie2024efficient,chen2024llms}, we explore an approach tailored to diffusion models, given the recent success of diffusion models in protein and DNA sequence generation \citep{alamdari2023protein,wang2024dplm}.