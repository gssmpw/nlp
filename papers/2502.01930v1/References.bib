% books
@book{vapnik1995learning,
    author = {Vapnik, Vladimir N.},
    title = {The Nature of Statistical Learning Theory},
    year = {1995},
    isbn = {0387945598},
    publisher = {Springer-Verlag},
    address = {Berlin, Heidelberg}
}

@book{quinonero2022dataset,
  title={Dataset Shift in Machine Learning},
  author={Quinonero-Candela, Joaquin and Sugiyama, Masashi and Schwaighofer, Anton and Lawrence, Neil D},
  year={2022},
  publisher={MIT Press}
}


@article{taori2020measuring,
  title={Measuring robustness to natural distribution shifts in image classification},
  author={Taori, Rohan and Dave, Achal and Shankar, Vaishaal and Carlini, Nicholas and Recht, Benjamin and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18583--18599},
  year={2020}
}

@inproceedings{koh2021wilds,
  title={Wilds: A benchmark of in-the-wild distribution shifts},
  author={Koh, Pang Wei and Sagawa, Shiori and Marklund, Henrik and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and others},
  booktitle={International Conference on Machine Learning},
  pages={5637--5664},
  year={2021},
  organization={PMLR}
}

@incollection{kuhn2019wasserstein,
  title={Wasserstein distributionally robust optimization: Theory and applications in machine learning},
  author={Kuhn, Daniel and Esfahani, Peyman Mohajerin and Nguyen, Viet Anh and Shafieezadeh-Abadeh, Soroosh},
  booktitle={Operations research \& management science in the age of analytics},
  pages={130--166},
  year={2019},
  publisher={Informs}
}


@inproceedings{kumar2023policy,
title={Policy Gradient for Rectangular Robust Markov Decision Processes},
author={Navdeep Kumar and Esther Derman and Matthieu Geist and Kfir Yehuda Levy and Shie Mannor},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
}

@inproceedings{wang2022policy,
  title={Policy gradient method for robust reinforcement learning},
  author={Wang, Yue and Zou, Shaofeng},
  booktitle={International Conference on Machine Learning},
  pages={23484--23526},
  year={2022},
  organization={PMLR}
}


@inproceedings{grand2021scalable,
  title={Scalable first-order methods for robust MDPs},
  author={Grand-Cl{\'e}ment, Julien and Kroer, Christian},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={12086--12094},
  year={2021}
}


@InProceedings{wang2022convergence,  
  title = {Policy Gradient in Robust {MDP}s with Global Convergence Guarantee},  
  author = {Wang, Qiuhao and Ho, Chin Pang and Petrik, Marek}, booktitle =  {Proceedings of the 40th International Conference on Machine Learning}, year = {2023},  
  publisher = {PMLR},
}

@book{boucheron2013concentration,
    author = {Boucheron, Stéphane and Lugosi, Gábor and Massart, Pascal},
    title = "{Concentration Inequalities: A Nonasymptotic Theory of Independence}",
    publisher = {Oxford University Press},
    year = {2013},
}

@book{van2000asymptotic,
  title={Asymptotic statistics},
  volume={3},
  year={2000},
  publisher={Cambridge university press},
  author={Van der Vaart, AW},
}

@book{habib1998probabilistic,
  title={Probabilistic Methods for Algorithmic Discrete Mathematics},
  author={Habib, M. and McDiarmid, C. and Ramirez-Alfonsin, J. and Reed, B. and Graham, R.L. and Korte, B. and Lov{\'a}sz, L. and Wigderson, A. and Ziegler, G.M.},
  isbn={9783540646228},
  lccn={98036217},
  series={Algorithms and Combinatorics},
  url={https://books.google.com/books?id=Vx7FJy5JlcEC},
  year={1998},
  publisher={Springer}
}

@article{chen2020distributionally,
  title={Distributionally robust learning},
  author={Chen, Ruidi and Paschalidis, Ioannis Ch and others},
  journal={Foundations and Trends{\textregistered} in Optimization},
  volume={4},
  number={1-2},
  pages={1--243},
  year={2020},
  publisher={Now Publishers, Inc.}
}

@book{basu2011statistical,
  title={Statistical Inference: The Minimum Distance Approach},
  author={Basu, A. and Shioya, H. and Park, C.},
  isbn={9781420099669},
  lccn={2011021886},
  series={Chapman \& Hall/CRC Monographs on Statistics \& Applied Probability},
  year={2011},
  publisher={CRC Press}
}

@article{gibbs2002choosing,
  title={On choosing and bounding probability metrics},
  author={Gibbs, Alison L and Su, Francis Edward},
  journal={International statistical review},
  volume={70},
  number={3},
  pages={419--435},
  year={2002},
  publisher={Wiley Online Library}
}


% conference
@InProceedings{xu-panaganti-2023samplecomplexity,
  title = 	 {Improved Sample Complexity Bounds for  Distributionally Robust Reinforcement Learning },
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics},
  author =       {Xu, Zaiyan and Panaganti, Kishan and Kalathil, Dileep},
  publisher = 	 {Conference on Artificial Intelligence and Statistics},
  year = 	 {2023}
}

@article{zhou2024natural,
  title={Natural actor-critic for robust reinforcement learning with function approximation},
  author={Zhou, Ruida and Liu, Tao and Cheng, Min and Kalathil, Dileep and Kumar, PR and Tian, Chao},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}


% DRO
@article{shapiro-2017-dro,
  title={Distributionally robust stochastic programming},
  author={Shapiro, Alexander},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={4},
  pages={2258--2275},
  year={2017},
  publisher={SIAM}
}

@article{blanchet2019dro, 
  title={Robust Wasserstein profile inference and applications to machine learning}, 
  volume={56},
  DOI={10.1017/jpr.2019.49},
  number={3},
  journal={Journal of Applied Probability},
  publisher={Cambridge University Press},
  author={Blanchet, Jose and Kang, Yang and Murthy, Karthyek}, 
  year={2019}, 
  pages={830–857}
}


@article{gao-2022-distributionally,
  title={Distributionally robust stochastic optimization with Wasserstein distance},
  author={Gao, Rui and Kleywegt, Anton},
  journal={Mathematics of Operations Research},
  year={2022},
  publisher={INFORMS}
}

@article{chen2018robust,
  title={A robust learning approach for regression models based on distributionally robust optimization},
  author={Chen, Ruidi and Paschalidis, Ioannis Ch},
  journal={Journal of Machine Learning Research},
  volume={19},
  number={13},
  pages={1--48},
  year={2018}
}

@article{lambert2023entangled,
  title={Entangled preferences: The history and risks of reinforcement learning and human feedback},
  author={Lambert, Nathan and Gilbert, Thomas Krendl and Zick, Tom},
  journal={arXiv preprint arXiv:2310.13595},
  year={2023}
}


@inproceedings{moses2011further,
  title={Further results on geometric properties of a family of relative entropies},
  author={Moses, Ashok Kumar and Sundaresan, Rajesh},
  booktitle={2011 IEEE International Symposium on Information Theory Proceedings},
  pages={1940--1944},
  year={2011},
}

@article{cover1991information,
  title={Information theory and the stock market},
  author={Cover, Thomas M and Thomas, Joy A},
  journal={Elements of Information Theory. Wiley Inc., New York},
  pages={543--556},
  year={1991}
}

@book{bertsekas2019reinforcement,
  title={Reinforcement learning and optimal control},
  author={Bertsekas, Dimitri},
  year={2019},
  publisher={Athena Scientific}
}

@inproceedings{farnia2016drosupervised,
 author = {Farnia, Farzan and Tse, David},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {A Minimax Approach to Supervised Learning},
 year = {2016}
}

@article{blanchet2019robust,
  title={Robust Wasserstein profile inference and applications to machine learning},
  author={Blanchet, Jose and Kang, Yang and Murthy, Karthyek},
  journal={Journal of Applied Probability},
  volume={56},
  number={3},
  pages={830--857},
  year={2019},
  publisher={Cambridge University Press}
}



@article{namkoong2016stochastic,
  title={Stochastic gradient methods for distributionally robust optimization with f-divergences},
  author={Namkoong, Hongseok and Duchi, John C},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{duchi2018learning,
author = {John C. Duchi and Hongseok Namkoong},
title = {{Learning models with uniform performance via distributionally robust optimization}},
volume = {49},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1378 -- 1406},
year = {2021},
doi = {10.1214/20-AOS2004}
}

@article{hu2013kullback,
  title={Kullback-Leibler divergence constrained distributionally robust optimization},
  author={Hu, Zhaolin and Hong, L Jeff},
  journal={Available at Optimization Online},
  volume={1},
  number={2},
  pages={9},
  year={2013}
}


@article{shapiro2017distributionally,
  title={Distributionally robust stochastic programming},
  author={Shapiro, Alexander},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={4},
  pages={2258--2275},
  year={2017},
  publisher={SIAM}
}

@article{bertsimas2018dro,
author = {Bertsimas, Dimitris and Gupta, Vishal and Kallus, Nathan},
title = {Data-Driven Robust Optimization},
year = {2018},
issue_date = {February  2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {167},
number = {2},
issn = {0025-5610},
doi = {10.1007/s10107-017-1125-8},
journal = {Math. Program.},
month = {feb},
pages = {235–292},
numpages = {58},}
}


@InProceedings{hu2018drsl,
  title = 	 {Does Distributionally Robust Supervised Learning Give Robust Classifiers?},
  author =       {Hu, Weihua and Niu, Gang and Sato, Issei and Sugiyama, Masashi},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2029--2037},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
}



% article
@phdthesis {kakade-thesis,
	title = {On the Sample Complexity of Reinforcement Learning},
	year = {2003},
	type = {PhD thesis},
	abstract = {
	This thesis is a detailed investigation into the following question: how much data must an agent collect in order to perform "reinforcement learning" successfully? This question is analogous to the classical issue of the sample complexity in supervised learning, but is harder because of the increased realism of the reinforcement learning setting. This thesis summarizes recent sample complexity results in the reinforcement learning literature and builds on these results to provide novel algorithms with strong performance guarantees. We focus on a variety of reasonable performance criteria and sampling models by which agents may access the environment. For instance, in a policy search setting, we consider the problem of how much simulated experience is required to reliably choose a "good" policy among a restricted class of policies II (as in Kearns, Mansour, and Ng 2000]). In a more online setting, we consider the case in which an agent is placed in an environment and must follow one unbroken chain of experience with no access to "offline" simulation (as in Kearns and Singh 1998]). We build on the sample based algorithms suggested by Kearns, Mansour, and Ng 2000]. Their sample complexity bounds have no dependence on the size of the state space, an exponential dependence on the planning horizon time, and linear dependence on the complexity of II. We suggest novel algorithms with more restricted guarantees whose sample complexities are again independent of the size of the state space and depend linearly on the complexity of the policy class II, but have only a polynomial dependence on the horizon time. We pay particular attention to the tradeoffs made by such algorithms.
    },
	author = {Sham M. Kakade},
	school = {University of College London}
}

@article{panaganti-rfqi,
  title={Robust Reinforcement Learning using Offline Data},
  author= {Panaganti, Kishan and Xu, Zaiyan and Kalathil, Dileep and Ghavamzadeh, Mohammad},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}


@InProceedings{wong2018adversarial,
  title = 	 {Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope},
  author =       {Wong, Eric and Kolter, Zico},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {5286--5295},
  year = 	 {2018},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
}



@InProceedings{cohan2019randomsmoothing,
  title = 	 {Certified Adversarial Robustness via Randomized Smoothing},
  author =       {Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {1310--1320},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
}


@article {csisz-divergence,
    AUTHOR = {Csisz\'{a}r, Imre},
     TITLE = {Eine informationstheoretische {U}ngleichung und ihre
              {A}nwendung auf den {B}eweis der {E}rgodizit\"{a}t von
              {M}arkoffschen {K}etten},
   JOURNAL = {Magyar Tud. Akad. Mat. Kutat\'{o} Int. K\"{o}zl.},
  FJOURNAL = {A Magyar Tudom\'{a}nyos Akad\'{e}mia. Matematikai Kutat\'{o} Int\'{e}zet\'{e}nek
              K\"{o}zlem\'{e}nyei},
    VOLUME = {8},
      YEAR = {1963},
     PAGES = {85--108},
      ISSN = {0541-9514},
   MRCLASS = {60.65},
  MRNUMBER = {164374},
MRREVIEWER = {S. Kullback},
}

@misc{yang-2022,
  doi = {10.48550/ARXIV.2105.03863},
  url = {https://arxiv.org/abs/2105.03863},
  author = {Yang, Wenhao and Zhang, Liangyu and Zhang, Zhihua},
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Towards Theoretical Understandings of Robust Markov Decision Processes: Sample Complexity and Asymptotics},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{shi2024distributionally,
  title={Distributionally robust model-based offline reinforcement learning with near-optimal sample complexity},
  author={Shi, Laixi and Chi, Yuejie},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={200},
  pages={1--91},
  year={2024}
}

@misc{duchi2022distributionally,
      title={Distributionally Robust Losses for Latent Covariate Mixtures}, 
      author={John Duchi and Tatsunori Hashimoto and Hongseok Namkoong},
      year={2022},
      eprint={2007.13982},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
  
@article{dann2015sample,
  title={Sample complexity of episodic fixed-horizon reinforcement learning},
  author={Dann, Christoph and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}



@article{yang2022toward,
  title={Toward theoretical understandings of robust {M}arkov decision processes: Sample complexity and asymptotics},
  author={Yang, Wenhao and Zhang, Liangyu and Zhang, Zhihua},
  journal={The Annals of Statistics},
  volume={50},
  number={6},
  pages={3223--3248},
  year={2022},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{MaurerP09,
  author    = {Andreas Maurer and
               Massimiliano Pontil},
  title     = {Empirical Bernstein Bounds and Sample-Variance Penalization},
  booktitle = {{COLT} 2009 - The 22nd Conference on Learning Theory, Montreal, Quebec,
               Canada, June 18-21, 2009},
  year      = {2009},
}

% Simulation

@ARTICLE{scipy20,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@INPROCEEDINGS{emanuel2012mujoco,
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={MuJoCo: A physics engine for model-based control}, 
  year={2012},
  volume={},
  number={},
  pages={5026-5033},
  doi={10.1109/IROS.2012.6386109}
}

@misc{antonin2020rlzoo3,
  author = {Raffin, Antonin},
  title = {RL Baselines3 Zoo},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/DLR-RM/rl-baselines3-zoo}},
}

@article{kraft1988software,
  title={A software package for sequential quadratic programming},
  author={Kraft, Dieter},
  journal={Forschungsbericht- Deutsche Forschungs- und Versuchsanstalt fur Luft- und Raumfahrt},
  year={1988}
}


% Robust Tabular setting


@inproceedings{zhou2021finite,
  title={Finite-Sample Regret Bound for Distributionally Robust Offline Tabular Reinforcement Learning},
  author={Zhou, Zhengqing and Bai, Qinxun and Zhou, Zhengyuan and Qiu, Linhai and Blanchet, Jose and Glynn, Peter},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3331--3339},
  year={2021},
}



%% Meta learning + LFA
@inproceedings{wang2020global,
  title={On the global optimality of model-agnostic meta-learning},
  author={Wang, Lingxiao and Cai, Qi and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={9837--9846},
  year={2020},
}

@inproceedings{kong2020meta,
  title={Meta-learning for mixed linear regression},
  author={Kong, Weihao and Somani, Raghav and Song, Zhao and Kakade, Sham and Oh, Sewoong},
  booktitle={International Conference on Machine Learning},
  pages={5394--5404},
  year={2020},
  organization={PMLR}
}

%% Imitation Learning + LFA
@inproceedings{arora2020provable,
  title={Provable representation learning for imitation learning via bi-level optimization},
  author={Arora, Sanjeev and Du, Simon and Kakade, Sham and Luo, Yuping and Saunshi, Nikunj},
  booktitle={International Conference on Machine Learning},
  pages={367--376},
  year={2020},
  organization={PMLR}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={International Conference on Machine Learning},
  pages={1},
  year={2004}
}

@inproceedings{ziebart2008irl,
author = {Ziebart, Brian D. and Maas, Andrew and Bagnell, J. Andrew and Dey, Anind K.},
title = {Maximum Entropy Inverse Reinforcement Learning},
year = {2008},
isbn = {9781577353683},
publisher = {AAAI Press},
abstract = {Recent research has shown the benefit of framing problems of imitation learning as solutions to Markov Decision Problems. This approach reduces learning to the problem of recovering a utility function that makes the behavior induced by a near-optimal policy closely mimic demonstrated behavior. In this work, we develop a probabilistic approach based on the principle of maximum entropy. Our approach provides a well-defined, globally normalized distribution over decision sequences, while providing the same performance guarantees as existing methods.We develop our technique in the context of modeling real-world navigation and driving behaviors where collected data is inherently noisy and imperfect. Our probabilistic approach enables modeling of route preferences as well as a powerful new approach to inferring destinations and routes based on partial trajectories.},
booktitle = {Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 3},
pages = {1433–1438},
numpages = {6},
location = {Chicago, Illinois},
series = {AAAI'08}
}

@inproceedings{maas2011learning,
  title={Learning word vectors for sentiment analysis},
  author={Maas, Andrew and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies},
  pages={142--150},
  year={2011}
}


@inproceedings{ng2000irl,
author = {Ng, Andrew Y. and Russell, Stuart J.},
title = {Algorithms for Inverse Reinforcement Learning},
year = {2000},
isbn = {1558607072},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Seventeenth International Conference on Machine Learning},
pages = {663–670},
numpages = {8},
series = {ICML '00}
}

@inproceedings{bain1995bc,
  title={A Framework for Behavioural Cloning},
  author={Michael Bain and Claude Sammut},
  booktitle={Machine Intelligence 15},
  year={1995}
}

@inproceedings{finn2016irl,
author = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
title = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
year = {2016},
publisher = {JMLR.org},
abstract = {Reinforcement learning can acquire complex behaviors from high-level specifications. However, defining a cost function that can be optimized effectively and encodes the correct task is challenging in practice. We explore how inverse optimal control (IOC) can be used to learn behaviors from demonstrations, with applications to torque control of high-dimensional robotic systems. Our method addresses two key challenges in inverse optimal control: first, the need for informative features and effective regularization to impose structure on the cost, and second, the difficulty of learning the cost function under unknown dynamics for high-dimensional continuous systems. To address the former challenge, we present an algorithm capable of learning arbitrary nonlinear cost functions, such as neural networks, without meticulous feature engineering. To address the latter challenge, we formulate an efficient sample-based approximation for MaxEnt IOC. We evaluate our method on a series of simulated tasks and real-world robotic manipulation problems, demonstrating substantial improvement over prior methods both in terms of task complexity and sample efficiency.},
booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
pages = {49–58},
numpages = {10},
location = {New York, NY, USA},
series = {ICML'16}
}

@inproceedings{xu2022receding,
title={Receding Horizon Inverse Reinforcement Learning},
author={Yiqing Xu and Wei Gao and David Hsu},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=CgkjJaKBvkX}
}



%% Offline RL + LFA


@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}


@inproceedings{yang2020reinforcement,
  title={Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={10746--10756},
  year={2020},
  organization={PMLR}
}



@inproceedings{wang2021what,
title={What are the Statistical Limits of Offline {RL} with Linear Function Approximation?},
author={Ruosong Wang and Dean Foster and Sham M. Kakade},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{duan2020minimax,
	title={Minimax-optimal off-policy evaluation with linear function approximation},
	author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
	booktitle={International Conference on Machine Learning},
	pages={2701--2709},
	year={2020},
}



@inproceedings{pinto2017robust,
  title={Robust adversarial reinforcement learning},
  author={Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  booktitle={International Conference on Machine Learning},
  pages={2817--2826},
  year={2017},
}




@article{antos2008learning,
  title={Learning near-optimal policies with {B}ellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}


@article{liao2022batch,
  title={Batch policy learning in average reward Markov decision processes},
  author={Liao, Peng and Qi, Zhengling and Wan, Runzhe and Klasnja, Predrag and Murphy, Susan A},
  journal={The Annals of Statistics},
  volume={50},
  number={6},
  pages={3364--3387},
  year={2022},
  publisher={Institute of Mathematical Statistics}
}

@article{munos2007performance,
  title={Performance bounds in l\_p-norm for approximate value iteration},
  author={Munos, R{\'e}mi},
  journal={SIAM journal on control and optimization},
  volume={46},
  number={2},
  pages={541--561},
  year={2007},
  publisher={SIAM}
} 

@article{yang2019reinforcement,
  title={Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound},
  author={Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1905.10389},
  year={2019}
}



@inproceedings{paternain2018learning,
  title={Learning policies for {M}arkov decision processes in continuous spaces},
  author={Paternain, Santiago and Bazerque, Juan Andr{\'e}s and Small, Austin and Ribeiro, Alejandro},
  booktitle={2018 IEEE Conference on Decision and Control (CDC)},
  pages={4751--4758},
  year={2018},
  organization={IEEE}
}

@inproceedings{behzadian2019fast,
  title={Fast Feature Selection for Linear Value Function Approximation},
  author={Behzadian, Bahram and Gharatappeh, Soheil and Petrik, Marek},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={29},
  number={1},
  pages={601--609},
  year={2019}
}

@article{chuchro2017game,
  title={Game playing with deep q-learning using openai gym},
  author={Chuchro, Robert and Gupta, Deepak},
  journal={Semantic Scholar},
  year={2017}
}


@inproceedings{lillicrapHPHETS15,
  author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
  title={Continuous control with deep reinforcement learning.},
  year={2016},
  booktitle={ICLR (Poster)}
}

@book{borkar2009stochastic,
  title={Stochastic approximation: a dynamical systems viewpoint},
  author={Borkar, Vivek S},
  volume={48},
  year={2009},
  publisher={Springer}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020}
}

@inproceedings{jia2020model,
  title={Model-Based Reinforcement Learning with Value-Targeted Regression},
  author={Jia, Zeyu and Yang, Lin and Szepesvari, Csaba and Wang, Mengdi},
  year={2020}, pages = {666--686}, booktitle = {Proceedings of Machine Learning Research}
}



@inproceedings{yu2020mopo,
  title={MOPO: Model-based Offline Policy Optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}


@article{munos08a,
  author  = {R{{\'e}}mi Munos and Csaba Szepesv{{\'a}}ri},
  title   = {Finite-Time Bounds for Fitted Value Iteration},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  number  = {27},
  pages   = {815-857}
}

@inproceedings{liu2015finite,
  title={Finite-Sample Analysis of Proximal Gradient TD Algorithms.},
  author={Liu, Bo and Liu, Ji and Ghavamzadeh, Mohammad and Mahadevan, Sridhar and Petrik, Marek},
  booktitle={UAI},
  pages={504--513},
  year={2015},
  organization={Citeseer}
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11784--11794},
  year={2019}
}


@article{deramo2020mushroomrl,
      title={MushroomRL: Simplifying Reinforcement Learning Research},
      author={D'Eramo, Carlo and Tateo, Davide and Bonarini, Andrea and Restelli, Marcello and Peters, Jan},
      journal={arXiv preprint arXiv:2001.01102},
      year={2020},
      url={https://github.com/MushroomRL/mushroom-rl}
}

@article{nedic2003least,
  title={Least squares policy evaluation algorithms with linear function approximation},
  author={Nedi{\'c}, A and Bertsekas, Dimitri P},
  journal={Discrete Event Dynamic Systems},
  volume={13},
  number={1-2},
  pages={79--110},
  year={2003},
  publisher={Springer}
}

@inproceedings{tsitsiklis1997analysis,
  title={Analysis of temporal-difference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1075--1081},
  year={1997}
}




@article{wiesemann2013robust,
  title={Robust {M}arkov decision processes},
  author={Wiesemann, Wolfram and Kuhn, Daniel and Rustem, Ber{\c{c}}},
  journal={Mathematics of Operations Research},
  volume={38},
  number={1},
  pages={153--183},
  year={2013},
  publisher={INFORMS}
}

@inproceedings{xu2010distributionally,
  title={Distributionally robust {M}arkov decision processes},
  author={Xu, Huan and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2505--2513},
  year={2010}
}

@article{yu2015distributionally,
  title={Distributionally robust counterpart in {M}arkov decision processes},
  author={Yu, Pengqian and Xu, Huan},
  journal={IEEE Transactions on Automatic Control},
  volume={61},
  number={9},
  pages={2538--2543},
  year={2015},
  publisher={IEEE}
}


@inproceedings{tamar2014scaling,
  title={Scaling up robust MDPs using function approximation},
  author={Tamar, Aviv and Mannor, Shie and Xu, Huan},
  booktitle={International Conference on Machine Learning},
  pages={181--189},
  year={2014}
}


@inproceedings{lim2013reinforcement,
  title={Reinforcement learning in robust {M}arkov decision processes},
  author={Lim, Shiau Hong and Xu, Huan and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={701--709},
  year={2013}
}

@inproceedings{roy2017reinforcement,
  title={Reinforcement learning under model mismatch},
  author={Roy, Aurko and Xu, Huan and Pokutta, Sebastian},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3043--3052},
  year={2017}
}


@article{kaufman2013robust,
  title={Robust modified policy iteration},
  author={Kaufman, David L and Schaefer, Andrew J},
  journal={INFORMS Journal on Computing},
  volume={25},
  number={3},
  pages={396--410},
  year={2013},
  publisher={INFORMS}
}


@article{bertsekas2011approximate,
  title={Approximate policy iteration: A survey and some new methods},
  author={Bertsekas, Dimitri P},
  journal={Journal of Control Theory and Applications},
  volume={9},
  number={3},
  pages={310--335},
  year={2011},
  publisher={Springer}
}


@inproceedings{lim2019kernel,
  title={Kernel-based reinforcement learning in robust {M}arkov decision processes},
  author={Lim, Shiau Hong and Autef, Arnaud},
  booktitle={International Conference on Machine Learning},
  pages={3973--3981},
  year={2019}
}

@inproceedings{derman2018soft,
  title={Soft-robust actor-critic policy-gradient},
  author={Derman, Esther and Mankowitz, Daniel J and Mann, Timothy A and Mannor, Shie},
  booktitle={AUAI press for Association for Uncertainty in Artificial Intelligence},
  pages={208--218},
  year={2018}
}

@inproceedings{tessler2019action,
  title={Action Robust Reinforcement Learning and Applications in Continuous Control},
  author={Tessler, Chen and Efroni, Yonathan and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={6215--6224},
  year={2019}
}

@inproceedings{
Mankowitz2020Robust,
title={Robust Reinforcement Learning for Continuous Control with Model Misspecification},
author={Daniel J. Mankowitz and Nir Levine and Rae Jeong and Abbas Abdolmaleki and Jost Tobias Springenberg and Yuanyuan Shi and Jackie Kay and Todd Hester and Timothy Mann and Martin Riedmiller},
booktitle={International Conference on Learning Representations},
year={2020}
}



@book{BerBook12,
  title={Dynamic programming and optimal control, Vol - 2},
  author={Bertsekas, Dimitri P},
  year={2012},
  publisher={Athena scientific Belmont, MA}
}

@book{Puterman05,
  title={{M}arkov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Puterman, Martin L},
  year={2005},
  publisher={John Wiley \& Sons, Inc., NJ}
}


@article{bertsekas2009projected,
  title={Projected equation methods for approximate solution of large linear systems},
  author={Bertsekas, Dimitri P and Yu, Huizhen},
  journal={Journal of Computational and Applied Mathematics},
  volume={227},
  number={1},
  pages={27--50},
  year={2009},
  publisher={Elsevier}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={Journal of Machine Learning Research},
  volume={4},
  number={Dec},
  pages={1107--1149},
  year={2003}
}

@inproceedings{munos2003error,
  title={Error bounds for approximate policy iteration},
  author={Munos, R{\'e}mi},
  booktitle={ICML},
  volume={3},
  pages={560--567},
  year={2003}
}

@article{lazaric2012finite,
  title={Finite-sample analysis of least-squares policy iteration},
  author={Lazaric, Alessandro and Ghavamzadeh, Mohammad and Munos, R{\'e}mi},
  journal={Journal of Machine Learning Research},
  volume={13},
  number={Oct},
  pages={3041--3074},
  year={2012}
}




@inproceedings{modi2020sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2010--2020},
  year={2020},
  organization={PMLR}
}



@article{russel2019beyond,
  title={Beyond Confidence Regions: Tight Bayesian Ambiguity Sets for Robust MDPs},
  author={Russel, Reazul Hasan and Petrik, Marek},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@article{mannor2016robust,
  title={Robust MDPs with k-rectangular uncertainty},
  author={Mannor, Shie and Mebel, Ofir and Xu, Huan},
  journal={Mathematics of Operations Research},
  volume={41},
  number={4},
  pages={1484--1509},
  year={2016},
  publisher={INFORMS}
}

@inproceedings{derman2020bayesian,
  title={A bayesian approach to robust reinforcement learning},
  author={Derman, Esther and Mankowitz, Daniel and Mann, Timothy and Mannor, Shie},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={648--658},
  year={2020},
}

@inproceedings{abdolmaleki2018maximum,
  title={Maximum a Posteriori Policy Optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  booktitle={International Conference on Learning Representations},
  year={2018}
}


@InProceedings{panaganti2020robust,
  title = 	 {Robust Reinforcement Learning using Least Squares Policy Iteration with Provable Performance Guarantees},
  author =       {Panaganti, Kishan  and Kalathil, Dileep},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {511--520},
  year = 	 {2021},
}


@inproceedings{petrik2014raam,
  title={RAAM: The Benefits of Robustness in Approximating Aggregated MDPs in Reinforcement Learning.},
  author={Petrik, Marek and Subramanian, Dharmashankar},
  booktitle={NIPS},
  pages={1979--1987},
  year={2014}
}




@book{dullerud2013course,
  title={A course in robust control theory: a convex approach},
  author={Dullerud, Geir E and Paganini, Fernando},
  volume={36},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@book{zhou1996robust,
  title={Robust and optimal control},
  author={Zhou, Kemin and Doyle, John Comstock and Glover, Keith and others},
  volume={40},
  year={1996},
  publisher={Prentice hall New Jersey}
}



@inproceedings{zhang2020policy,
  author    = {Kaiqing Zhang and
               Bin Hu and
               Tamer Basar},
  title     = {Policy Optimization for {H}\({}_{\mbox{2}}\) Linear Control with {H}\({}_{\mbox{{\(\infty\)}}}\)
               Robustness Guarantee: Implicit Regularization and Global Convergence},
  booktitle = {Proceedings of the 2nd Annual Conference on Learning for Dynamics
               and Control, {L4DC} 2020, Online Event, Berkeley, CA, USA, 11-12 June
               2020},
  series    = {Proceedings of Machine Learning Research},
  volume    = {120},
  pages     = {179--190},
  year      = {2020}
}

@article{zhang2020stability,
  title={On the stability and convergence of robust adversarial reinforcement learning: A case study on linear quadratic systems},
  author={Zhang, Kaiqing and Hu, Bin and Basar, Tamer},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{borkar2002q,
  title={Q-learning for risk-sensitive control},
  author={Borkar, Vivek S},
  journal={Mathematics of operations research},
  volume={27},
  number={2},
  pages={294--311},
  year={2002},
  publisher={INFORMS}
}







%%%%%% GENERATIVE MODEL SAMPLE COMPLEXITY PAPERS

@article{singh1994upper,
  title={An upper bound on the loss from approximate optimal-value functions},
  author={Singh, Satinder P and Yee, Richard C},
  journal={Machine Learning},
  volume={16},
  number={3},
  pages={227--233},
  year={1994},
  publisher={Springer}
}


@article{AzarMK13,
  author    = {Mohammad Gheshlaghi Azar and
               R{\'{e}}mi Munos and
               Hilbert J. Kappen},
  title     = {Minimax {PAC} bounds on the sample complexity of reinforcement learning
               with a generative model},
  journal   = {Mach. Learn.},
  volume    = {91},
  number    = {3},
  pages     = {325--349},
  year      = {2013},
  url       = {https://doi.org/10.1007/s10994-013-5368-1},
  doi       = {10.1007/s10994-013-5368-1},
  timestamp = {Mon, 02 Mar 2020 16:28:55 +0100},
  biburl    = {https://dblp.org/rec/journals/ml/AzarMK13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
  }

@inproceedings{sidford2018near,
 author = {Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin and Ye, Yinyu},
 booktitle = {Advances in Neural Information Processing Systems},
 publisher = {Curran Associates, Inc.},
 title = {Near-Optimal Time and Sample Complexities for Solving Markov Decision Processes with a Generative Model},
 year = {2018}
}

@article{haskell2016empirical,
  title={Empirical dynamic programming},
  author={Haskell, William B and Jain, Rahul and Kalathil, Dileep},
  journal={Mathematics of Operations Research},
  volume={41},
  number={2},
  pages={402--429},
  year={2016},
}




@article{kalathil2021empirical,
  title={Empirical {Q}-{V}alue {I}teration},
  author={Kalathil, Dileep and Borkar, Vivek S and Jain, Rahul},
  journal={Stochastic Systems},
  volume={11},
  number={1},
  pages={1--18},
  year={2021},
}

@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020},
}

@inproceedings{li2020breaking,
 author = {Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {12861--12872},
 title = {Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model},
 volume = {33},
 year = {2020}
}

@article{li2021breaking,
  title={Breaking the sample complexity barrier to regret-optimal model-free reinforcement learning},
  author={Li, Gen and Shi, Laixi and Chen, Yuxin and Gu, Yuantao and Chi, Yuejie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17762--17776},
  year={2021}
}

@article{li2022minimax,
  title={Minimax-optimal multi-agent RL in zero-sum Markov games with a generative model},
  author={Li, Gen and Chi, Yuejie and Wei, Yuting and Chen, Yuxin},
  journal={arXiv preprint arXiv:2208.10458},
  year={2022}
}




%%% CLASSIC BOOKS

@book{vershynin2018high,
  title={High-Dimensional Probability: An Introduction with Applications in Data Science},
  author={Vershynin, Roman},
  volume={47},
  year={2018},
  publisher={Cambridge University press}
}

@book{wainwright2019high,
  title={High-dimensional statistics: A non-asymptotic viewpoint},
  author={Wainwright, Martin J},
  volume={48},
  year={2019},
  publisher={Cambridge university press}
}

@book{beck2014introduction,
  title={Introduction to nonlinear optimization: Theory, algorithms, and applications with MATLAB},
  author={Beck, Amir},
  year={2014},
  publisher={SIAM}
}

@book{beck2017first,
  title={First-order methods in optimization},
  author={Beck, Amir},
  year={2017},
  publisher={SIAM}
}



%%%% Introduction

@article{guastella2020learning,
  title={Learning-based methods of perception and navigation for ground vehicles in unstructured environments: A review},
  author={Guastella, Dario Calogero and Muscato, Giovanni},
  journal={Sensors},
  volume={21},
  number={1},
  pages={73},
  year={2020},
  publisher={MDPI}
}

@article{sunderhauf2018limits,
  title={The limits and potentials of deep learning for robotics},
  author={S{\"u}nderhauf, Niko and Brock, Oliver and Scheirer, Walter and Hadsell, Raia and Fox, Dieter and Leitner, J{\"u}rgen and Upcroft, Ben and Abbeel, Pieter and Burgard, Wolfram and Milford, Michael and others},
  journal={The International journal of robotics research},
  volume={37},
  number={4-5},
  pages={405--420},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{tobin2017domain,
  title={Domain randomization for transferring deep neural networks from simulation to the real world},
  author={Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2017 IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  pages={23--30},
  year={2017},
}



@inproceedings{peng2018sim,
  title={Sim-to-real transfer of robotic control with dynamics randomization},
  author={Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={3803--3810},
  year={2018},
  organization={IEEE}
}


@article{weng2019DR,
  title   = "Domain Randomization for Sim2Real Transfer",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2019",
}

@article{wang2021online,
  title={Online robust reinforcement learning with model uncertainty},
  author={Wang, Yue and Zou, Shaofeng},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={7193--7206},
  year={2021}
}

@article{choi2009reinforcement,
  title={Reinforcement learning and savings behavior},
  author={Choi, James J and Laibson, David and Madrian, Brigitte C and Metrick, Andrew},
  journal={The Journal of finance},
  volume={64},
  number={6},
  pages={2515--2534},
  year={2009},
  publisher={Wiley Online Library}
}

@inproceedings{schulman2013finding,
  title={Finding locally optimal, collision-free trajectories with sequential convex optimization.},
  author={Schulman, John and Ho, Jonathan and Lee, Alex X and Awwal, Ibrahim and Bradlow, Henry and Abbeel, Pieter},
  booktitle={Robotics: science and systems},
  volume={9},
  pages={1--10},
  year={2013},
  organization={Citeseer}
}


@inproceedings{xie2020q,
  title={Q* approximation schemes for batch reinforcement learning: A theoretical comparison},
  author={Xie, Tengyang and Jiang, Nan},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={550--559},
  year={2020},
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@inproceedings{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={1042--1051},
  year={2019},
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@inproceedings{buckman2021the,
title={The Importance of Pessimism in Fixed-Dataset Policy Optimization},
author={Jacob Buckman and Carles Gelada and Marc G Bellemare},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{lykouris2021corruption,
  title={Corruption-robust exploration in episodic reinforcement learning},
  author={Lykouris, Thodoris and Simchowitz, Max and Slivkins, Alex and Sun, Wen},
  booktitle={Conference on Learning Theory},
  pages={3242--3245},
  year={2021}
}


@inproceedings{si2020distributionally,
  title={Distributionally robust policy evaluation and learning in offline contextual bandits},
  author={Si, Nian and Zhang, Fan and Zhou, Zhengyuan and Blanchet, Jose},
  booktitle={International Conference on Machine Learning},
  pages={8884--8894},
  year={2020},
 }

@inproceedings{yang2023distributionally,
  title={Distributionally robust policy gradient for offline contextual bandits},
  author={Yang, Zhouhao and Guo, Yihong and Xu, Pan and Liu, Anqi and Anandkumar, Animashree},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={6443--6462},
  year={2023},
  organization={PMLR}
}
 
 @article{vinitsky2020robust,
  title={Robust reinforcement learning using adversarial populations},
  author={Vinitsky, Eugene and Du, Yuqing and Parvate, Kanaad and Jang, Kathy and Abbeel, Pieter and Bayen, Alexandre},
  journal={arXiv preprint arXiv:2008.01825},
  year={2020}
}

@inproceedings{zhang2020robust,
  title={Robust Reinforcement Learning on State Observations with Learned Optimal Adversary},
  author={Zhang, Huan and Chen, Hongge and Boning, Duane S and Hsieh, Cho-Jui},
  booktitle={International Conference on Learning Representations},
  year={2020}
}




@article{yang2019reinforcement,
  title={Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound},
  author={Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1905.10389},
  year={2019}
}



@inproceedings{paternain2018learning,
  title={Learning policies for {M}arkov decision processes in continuous spaces},
  author={Paternain, Santiago and Bazerque, Juan Andr{\'e}s and Small, Austin and Ribeiro, Alejandro},
  booktitle={2018 IEEE Conference on Decision and Control (CDC)},
  pages={4751--4758},
  year={2018},
  organization={IEEE}
}

@inproceedings{behzadian2019fast,
  title={Fast Feature Selection for Linear Value Function Approximation},
  author={Behzadian, Bahram and Gharatappeh, Soheil and Petrik, Marek},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={29},
  number={1},
  pages={601--609},
  year={2019}
}

@article{chuchro2017game,
  title={Game playing with deep q-learning using openai gym},
  author={Chuchro, Robert and Gupta, Deepak},
  journal={Semantic Scholar},
  year={2017}
}



@inproceedings{jia2020model,
  title={Model-Based Reinforcement Learning with Value-Targeted Regression},
  author={Jia, Zeyu and Yang, Lin and Szepesvari, Csaba and Wang, Mengdi},
  year={2020}, pages = {666--686}, booktitle = {Proceedings of Machine Learning Research}
}


@inproceedings{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}


@inproceedings{liu2015finite,
  title={Finite-Sample Analysis of Proximal Gradient TD Algorithms.},
  author={Liu, Bo and Liu, Ji and Ghavamzadeh, Mohammad and Mahadevan, Sridhar and Petrik, Marek},
  booktitle={UAI},
  pages={504--513},
  year={2015},
  organization={Citeseer}
}



@article{bertsekas1996temporal,
  title={Temporal {D}ifferences-{B}ased {P}olicy {I}teration and {A}pplications in {N}euro-{D}ynamic {P}rogramming},
  author={Bertsekas, Dimitri P and Ioffe, Sergey},
  journal={Lab. for Info. and Decision Systems Report LIDS-P-2349, MIT, Cambridge, MA},
  volume={14},
  year={1996},
  publisher={Citeseer}
}



@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}


@article{nilim2005robust,
  title={Robust control of {M}arkov decision processes with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  journal={Operations Research},
  volume={53},
  number={5},
  pages={780--798},
  year={2005},
  publisher={INFORMS}
}

@inproceedings{pomerleau1988il,
 author = {Pomerleau, Dean A.},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Touretzky},
 pages = {},
 publisher = {Morgan-Kaufmann},
 title = {ALVINN: An Autonomous Land Vehicle in a Neural Network},
 url = {https://proceedings.neurips.cc/paper/1988/file/812b4ba287f5ee0bc9d43bbf5bbe87fb-Paper.pdf},
 volume = {1},
 year = {1988}
}



%%%%%%%%.    RFQI


%% Books

@book{rockafellar2009variational,
  title={Variational analysis},
  author={Rockafellar, R Tyrrell and Wets, Roger J-B},
  volume={317},
  year={2009},
  publisher={Springer Science \& Business Media}
}






%%%%%%% Introduction 

@book{shalev2014understanding,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@article{yang2021generalized,
  title={Generalized out-of-distribution detection: A survey},
  author={Yang, Jingkang and Zhou, Kaiyang and Li, Yixuan and Liu, Ziwei},
  journal={arXiv preprint arXiv:2110.11334},
  year={2021}
} 

@article{robey2020model,
  title={Model-based robust deep learning: Generalizing to natural, out-of-distribution data},
  author={Robey, Alexander and Hassani, Hamed and Pappas, George J},
  journal={arXiv preprint arXiv:2005.10247},
  year={2020}
}

@article{levy2020large,
  title={Large-scale methods for distributionally robust optimization},
  author={Levy, Daniel and Carmon, Yair and Duchi, John C and Sidford, Aaron},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={8847--8860},
  year={2020}
}

@article{esfahani2015data,
  title={Data-driven distributionally robust optimization using the Wasserstein metric: performance guarantees and tractable reformulations},
  author={Mohajerin Esfahani, Peyman and Kuhn, Daniel},
  journal={Mathematical Programming},
  volume={171},
  number={1-2},
  pages={115--166},
  year={2018},
  publisher={Springer}
}



@inproceedings{zhang2021towards,
  author    = {Siyuan Zhang and
               Nan Jiang},
  title     = {Towards Hyperparameter-free Policy Selection for Offline Reinforcement
               Learning},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {12864--12875},
  year      = {2021},
}


@article{cheng2022adversarially,
  title={Adversarially Trained Actor Critic for Offline Reinforcement Learning},
  author={Cheng, Ching-An and Xie, Tengyang and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2202.02446},
  year={2022}
}

@misc{wang2023distributionally,
      title={Achieving the Minimax Optimal Sample Complexity of Offline Reinforcement Learning: A DRO-Based Approach}, 
      author={Yue Wang and Jinjun Xiong and Shaofeng Zou},
      year={2023},
      eprint={2305.13289},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inproceedings{precup2000eligibility,
  author    = {Doina Precup and
               Richard S. Sutton and
               Satinder Singh},
  title     = {Eligibility Traces for Off-Policy Policy Evaluation},
  booktitle = {Proceedings of the Seventeenth International Conference on Machine
               Learning},
  pages     = {759--766},
  year      = {2000},
}

@inproceedings{gordon1995stable,
  author    = {Geoffrey J. Gordon},
  editor    = {Armand Prieditis and
               Stuart Russell},
  title     = {Stable Function Approximation in Dynamic Programming},
  booktitle = {Machine Learning, Proceedings of the Twelfth International Conference
               on Machine Learning, 1995},
  pages     = {261--268},
  year      = {1995},
}




@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  pages={503--556},
  year={2005},
  publisher={Microtome Publishing}
}



@inproceedings{szepesvari2005finite,
  title={Finite time bounds for sampling based fitted value iteration},
  author={Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={880--887},
  year={2005}
}


@article{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Advances in Neural Information Processing Systems},
  volume={23},
  year={2010}
}






@inproceedings{liu2020provably,
  author    = {Yao Liu and Adith Swaminathan and  Alekh Agarwal and               Emma Brunskill},
  title     = {Provably Good Batch Off-Policy Reinforcement Learning Without Great
               Exploration},
  booktitle = {Neural Information Processing Systems},
  year      = {2020}
}



@article{xie2021bellman,
  title={Bellman-consistent pessimism for offline reinforcement learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}


@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019},
}



@article{fujimoto2021minimalist,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}

@inproceedings{kostrikov2021offline,
  title={Offline reinforcement learning with fisher divergence critic regularization},
  author={Kostrikov, Ilya and Fergus, Rob and Tompson, Jonathan and Nachum, Ofir},
  booktitle={International Conference on Machine Learning},
  pages={5774--5783},
  year={2021},
  organization={PMLR}
}








%%%%    Robust RL papers
@inproceedings{
gadot2024bring,
title={Bring Your Own (Non-Robust) Algorithm to Solve Robust {MDP}s by Estimating The Worst Kernel},
author={Uri Gadot and Kaixin Wang and Navdeep Kumar and Kfir Yehuda Levy and Shie Mannor},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}

@InProceedings{panaganti22a,
  title = 	 { Sample Complexity of Robust Reinforcement Learning with a Generative Model },
  author =       {Panaganti, Kishan and Kalathil, Dileep},
  booktitle = 	 {International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages = 	 {9582--9602},
  year = 	 {2022},
}




%% Misc. classic papers

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{huber1965robust,
  title={A robust version of the probability ratio test},
  author={Huber, Peter J},
  journal={The Annals of Mathematical Statistics},
  pages={1753--1758},
  year={1965},
  publisher={JSTOR}
}


@article{csiszar1967information,
  title={Information-type measures of difference of probability distributions and indirect observation},
  author={Csisz{\'a}r, Imre},
  journal={studia scientiarum Mathematicarum Hungarica},
  volume={2},
  pages={229--318},
  year={1967}
}

@article{kis2014reptile,
author = {Kis, Anna and Huber, Ludwig and Wilkinson, Anna},
year = {2014},
month = {09},
pages = {},
title = {Social learning by imitation in a reptile (Pogona vitticeps)},
volume = {18},
journal = {Animal cognition},
doi = {10.1007/s10071-014-0803-7}
}


%% Robust FQI


@article{agarwal2019reinforcement,
  title={Reinforcement learning: Theory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M and Sun, Wen},
  journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
  year={2019}
}



% Simulation

@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}


@misc{rl-zoo3,
  author = {Raffin, Antonin},
  title = {RL Baselines3 Zoo},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/DLR-RM/rl-baselines3-zoo}},
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
}

@inproceedings{fujimoto2018addressing,
  title={Addressing Function Approximation Error in Actor-Critic Methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning},
  pages={1582--1591},
  year={2018}
}


% Robust Tabular setting

@book{dudley2002real,
  title={Real analysis and {P}robability},
  author={Dudley, Richard M},
  year={2002},
  publisher={Cambridge University Press}
}



@article{huang2022robust,
  title={Robust Reinforcement Learning as a Stackelberg Game via Adaptively-Regularized Adversarial Training},
  author={Huang, Peide and Xu, Mengdi and Fang, Fei and Zhao, Ding},
  journal={arXiv preprint arXiv:2202.09514},
  year={2022}
}

@inproceedings{zhang2021provably,
  title={Provably Efficient Actor-Critic for Risk-Sensitive and Robust Adversarial RL: A Linear-Quadratic Case},
  author={Zhang, Yufeng and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2764--2772},
  year={2021},
}




@article{yang2019reinforcement,
  title={Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound},
  author={Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1905.10389},
  year={2019}
}



@inproceedings{paternain2018learning,
  title={Learning policies for {M}arkov decision processes in continuous spaces},
  author={Paternain, Santiago and Bazerque, Juan Andr{\'e}s and Small, Austin and Ribeiro, Alejandro},
  booktitle={2018 IEEE Conference on Decision and Control (CDC)},
  pages={4751--4758},
  year={2018},
  organization={IEEE}
}

@inproceedings{behzadian2019fast,
  title={Fast Feature Selection for Linear Value Function Approximation},
  author={Behzadian, Bahram and Gharatappeh, Soheil and Petrik, Marek},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={29},
  number={1},
  pages={601--609},
  year={2019}
}

@article{chuchro2017game,
  title={Game playing with deep q-learning using openai gym},
  author={Chuchro, Robert and Gupta, Deepak},
  journal={Semantic Scholar},
  year={2017}
}




@inproceedings{jia2020model,
  title={Model-Based Reinforcement Learning with Value-Targeted Regression},
  author={Jia, Zeyu and Yang, Lin and Szepesvari, Csaba and Wang, Mengdi},
  year={2020}, pages = {666--686}, booktitle = {Proceedings of Machine Learning Research}
}


@inproceedings{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}


@inproceedings{liu2015finite,
  title={Finite-Sample Analysis of Proximal Gradient TD Algorithms.},
  author={Liu, Bo and Liu, Ji and Ghavamzadeh, Mohammad and Mahadevan, Sridhar and Petrik, Marek},
  booktitle={UAI},
  pages={504--513},
  year={2015},
  organization={Citeseer}
}




@inproceedings{ho2018fast,
  title={Fast Bellman updates for robust MDPs},
  author={Ho, Chin Pang and Petrik, Marek and Wiesemann, Wolfram},
  booktitle={International Conference on Machine Learning},
  pages={1979--1988},
  year={2018},
  organization={PMLR}
}

@inproceedings{ho2022robust,
  title={Robust $\phi$-Divergence MDPs.},
  author={Ho, Chin Pang and Petrik, Marek and Wiesemann, Wolfram},
  booktitle={NeurIPS},
  year={2022}
}




@inproceedings{abdolmaleki2018maximum,
  title={Maximum a Posteriori Policy Optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  booktitle={International Conference on Learning Representations},
  year={2018}
}








@article{prashanth2016variance,
  author    = {L. A. Prashanth and
               Mohammad Ghavamzadeh},
  title     = {Variance-constrained actor-critic algorithms for discounted and average
               reward MDPs},
  journal   = {Mach. Learn.},
  volume    = {105},
  number    = {3},
  pages     = {367--417},
  year      = {2016},
}

@inproceedings{fei2021exponential,
  author    = {Yingjie Fei and
               Zhuoran Yang and
               Yudong Chen and
               Zhaoran Wang},
  title     = {Exponential Bellman Equation and Improved Regret Bounds for Risk-Sensitive
               Reinforcement Learning},
  booktitle = {Annual Conference
               on Neural Information Processing Systems 2021},
  pages     = {20436--20446},
  year      = {2021},
}


@techreport{van2014probability,
  title={Probability in {H}igh {D}imension},
  author={van Handel, Ramon},
  year={2014},
  institution={Princeton University NJ}
}


@article{muller1997integral,
  title={Integral probability metrics and their generating classes of functions},
  author={M{\"u}ller, Alfred},
  journal={Advances in applied probability},
  volume={29},
  number={2},
  pages={429--443},
  year={1997},
  publisher={Cambridge University Press}
}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%       Future research citations


@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  booktitle={Advances in neural information processing systems},
  volume={14},
  pages={1531--1538},
  year={2001}
}

@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}


@InProceedings{wang22policygradient,
  title = 	 {Policy Gradient Method For Robust Reinforcement Learning},
  author =       {Wang, Yue and Zou, Shaofeng},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  year = 	 {2022}
}

@article{li2022first,
  title={First-order Policy Optimization for Robust Markov Decision Process},
  author={Li, Yan and Zhao, Tuo and Lan, Guanghui},
  journal={arXiv preprint arXiv:2209.10579},
  year={2022}
}

@inproceedings{brantley2019disagreement,
  title={Disagreement-regularized imitation learning},
  author={Brantley, Kiante and Sun, Wen and Henaff, Mikael},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{rajaraman2020toward,
  title={Toward the fundamental limits of imitation learning},
  author={Rajaraman, Nived and Yang, Lin and Jiao, Jiantao and Ramchandran, Kannan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2914--2924},
  year={2020}
}


@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={661--668},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}


@article{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{xu2020error,
  title={Error bounds of imitating policies and environments},
  author={Xu, Tian and Li, Ziniu and Yu, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15737--15749},
  year={2020}
}

@article{schweizer1992mean,
  title={Mean-variance hedging for general claims},
  author={Schweizer, Martin},
  journal={The annals of applied probability},
  pages={171--179},
  year={1992},
  publisher={JSTOR}
}

@article{fang2019survey,
  title={Survey of imitation learning for robotic manipulation},
  author={Fang, Bin and Jia, Shidong and Guo, Di and Xu, Muhua and Wen, Shuhuan and Sun, Fuchun},
  journal={International Journal of Intelligent Robotics and Applications},
  volume={3},
  number={4},
  pages={362--369},
  year={2019},
  publisher={Springer}
}

@article{rajaraman2021provably,
  title={Provably breaking the quadratic error compounding barrier in imitation learning, optimally},
  author={Rajaraman, Nived and Han, Yanjun and Yang, Lin F and Ramchandran, Kannan and Jiao, Jiantao},
  journal={arXiv preprint arXiv:2102.12948},
  year={2021}
}



%%%%%% Intro first paragraph general ML/RL



@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}


@article{mirhoseini2021graph,
  title={A graph placement methodology for fast chip design},
  author={Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and Jiang, Joe Wenjie and Songhori, Ebrahim and Wang, Shen and Lee, Young-Joon and Johnson, Eric and Pathak, Omkar and Nazi, Azade and others},
  journal={Nature},
  volume={594},
  number={7862},
  pages={207--212},
  year={2021},
  publisher={Nature Publishing Group}
}


@article{akkaya2019solving,
  title={Solving rubik's cube with a robot hand},
  author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal={arXiv preprint arXiv:1910.07113},
  year={2019}
}



@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}




@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M and Nasrabadi, Nasser M},
  volume={4},
  number={4},
  year={2006},
  publisher={Springer}
}


@book{meyn2022control,
  title={Control Systems and Reinforcement Learning},
  author={Meyn, Sean},
  year={2022},
  publisher={Cambridge University Press}
}

@misc{ucb-robotics,
  title={{B}erkeley {A}rtificial {I}ntelligence {R}esearch},
  url={https://bair.berkeley.edu/software.html},
}

@INPROCEEDINGS{Kumar_ROBEL, 

     AUTHOR = {Michael Ahn AND Henry Zhu AND Kristian Hartikainen AND Hugo Ponte AND Abhishek Gupta AND Sergey Levine AND Vikash Kumar}, 

     TITLE = "{ROBEL: RObotics BEnchmarks for Learning with low-cost robots}", 

     BOOKTITLE = {Conference on Robot Learning (CoRL)}, 

     YEAR = {2019}, }
     
     
@article{muzero, 
year = {2020}, 
title = {{Mastering Atari, Go, chess and shogi by planning with a learned model}}, 
author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David}, 
journal = {Nature}, 
issn = {0028-0836}, 
doi = {10.1038/s41586-020-03051-4}, 
pages = {604--609}, 
number = {7839}, 
volume = {588}
}



@article{dreamer,
  title={Dream to Control: Learning Behaviors by Latent Imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@misc{ibm-watson,
  title={{IBM} {W}atson {H}ealth},
  url={https://www.ibm.com/watson-health},
}

@article{dulac2021challenges,
  title={Challenges of real-world reinforcement learning: definitions, benchmarks and analysis},
  author={Dulac-Arnold, Gabriel and Levine, Nir and Mankowitz, Daniel J and Li, Jerry and Paduraru, Cosmin and Gowal, Sven and Hester, Todd},
  journal={Machine Learning},
  volume={110},
  number={9},
  pages={2419--2468},
  year={2021},
  publisher={Springer}
}

@article{berkenkamp2017safe,
  title={Safe model-based reinforcement learning with stability guarantees},
  author={Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela and Krause, Andreas},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{lutjens2020certified,
  title={Certified adversarial robustness for deep reinforcement learning},
  author={L{\"u}tjens, Bj{\"o}rn and Everett, Michael and How, Jonathan P},
  booktitle={Conference on Robot Learning},
  pages={1328--1337},
  year={2020},
  organization={PMLR}
}

@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}

@article{kiran2021deep,
  title={Deep reinforcement learning for autonomous driving: A survey},
  author={Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Al Sallab, Ahmad A and Yogamani, Senthil and P{\'e}rez, Patrick},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2021},
  publisher={IEEE}
}

@article{singh2021reinforcement,
  title={Reinforcement learning in robotic applications: a comprehensive survey},
  author={Singh, Bharat and Kumar, Rajesh and Singh, Vinay Pratap},
  journal={Artificial Intelligence Review},
  pages={1--46},
  year={2021},
  publisher={Springer}
}

@article{ghosh2021generalization,
  title={Why generalization in rl is difficult: Epistemic pomdps and implicit partial observability},
  author={Ghosh, Dibya and Rahme, Jad and Kumar, Aviral and Zhang, Amy and Adams, Ryan P and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={25502--25515},
  year={2021}
}

@inproceedings{da2020uncertainty,
  title={Uncertainty-aware action advising for deep reinforcement learning agents},
  author={Da Silva, Felipe Leno and Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={5792--5799},
  year={2020}
}

@inproceedings{lockwood2022review,
  title={A Review of Uncertainty for Deep Reinforcement Learning},
  author={Lockwood, Owen and Si, Mei},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume={18},
  number={1},
  pages={155--162},
  year={2022}
}

@inproceedings{kwon2020principled,
  title={Principled learning method for wasserstein distributionally robust optimization with local perturbations},
  author={Kwon, Yongchan and Kim, Wonyoung and Won, Joong-Ho and Paik, Myunghee Cho},
  booktitle={International Conference on Machine Learning},
  pages={5567--5576},
  year={2020},
  organization={PMLR}
}


@ARTICLE{sim2real-1,
  author={Salvato, Erica and Fenu, Gianfranco and Medvet, Eric and Pellegrino, Felice Andrea},
  journal={IEEE Access}, 
  title={Crossing the Reality Gap: A Survey on Sim-to-Real Transferability of Robot Controllers in Reinforcement Learning}, 
  year={2021},
  volume={9},
  number={},
  pages={153171-153187},
  doi={10.1109/ACCESS.2021.3126658}}
  
  @inproceedings{sim2real-2,
  title={Retinagan: An object-aware approach to sim-to-real transfer},
  author={Ho, Daniel and Rao, Kanishka and Xu, Zhuo and Jang, Eric and Khansari, Mohi and Bai, Yunfei},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={10920--10926},
  year={2021},
  organization={IEEE}
}

@misc{sim2real-industry-1,
  title={{C}losing the {S}imulation-to-{R}eality Gap for {D}eep {R}obotic {L}earning},
  url={https://ai.googleblog.com/2017/10/closing-simulation-to-reality-gap-for.html},
}

@misc{sim2real-industry-2,
  title={{C}losing the {S}im2{R}eal {G}ap with {NVIDIA} {I}saac Sim and {NVIDIA} {I}saac Replicator},
  url={https://developer.nvidia.com/blog/closing-the-sim2real-gap-with-nvidia-isaac-sim-and-nvidia-isaac-replicator/},
}

@misc{sim2real-acad-1,
  title={{C}losing the {R}eality {G}ap in {S}im2{R}eal Transfer for Robotics},
  url={https://sim2real.github.io/},
}

@misc{sim2real-acad-2,
  title={A Framework for Curriculum Schema Transfer from Low-Fidelity to High-Fidelity Environments},
  author={Shukla, Yash and Sinpov, Jivko}
}

@article{sim2real-acad-3,
  title={Toward Real-World Implementation of Deep Reinforcement Learning for Vision-Based Autonomous Drone Navigation with Mission},
  author={Navardi, Mozhgan and Dixit, Prakhar and Manjunath, Tejaswini and Waytowich, Nicholas R and Mohsenin, Tinoosh and Oates, Tim},
  journal={UMBC Student Collection},
  year={2022}
}


@article{dasgupta2021off,
  title={Off-Policy Evaluation Using Information Borrowing and Context-Based Switching},
  author={Dasgupta, Sutanoy and Niu, Yabo and Panaganti, Kishan and Kalathil, Dileep and Pati, Debdeep and Mallick, Bani},
  journal={arXiv preprint arXiv:2112.09865},
  year={2021}
}

@article{panaganti2020bounded,
  title={Bounded Regret for Finitely Parameterized Multi-Armed Bandits},
  author={Panaganti, Kishan and Kalathil, Dileep},
  journal={IEEE Control Systems Letters},
  volume={5},
  number={3},
  pages={1073--1078},
  year={2020},
  publisher={IEEE}
}

@article{maghakian2022interaction,
  title={Interaction-Grounded Learning for Recommender Systems},
  author={Maghakian, Jessica and Panaganti, Kishan and Mineiro, Paul and Saran, Akanksha and Tan, Cheng},
  journal={Online Recommender Systems and User Modeling ACM RecSys Workshop},
  year={2022}
}

@article{maghakian2022prl,
  title={Personalized Reward Learning with Interaction-Grounded Learning ({IGL})},
  author={Maghakian, Jessica and Mineiro, Paul and Panaganti, Kishan and Rucker, Mark and Saran, Akanksha and Tan, Cheng},
  journal={arXiv preprint arXiv:2211.15823},
  year={2022}
}

@article{pirotta2015policy,
  title={Policy gradient in lipschitz markov decision processes},
  author={Pirotta, Matteo and Restelli, Marcello and Bascetta, Luca},
  journal={Machine Learning},
  volume={100},
  number={2},
  pages={255--283},
  year={2015},
  publisher={Springer}
}

@article{chang2021mitigating,
  title={Mitigating Covariate Shift in Imitation Learning via Offline Data With Partial Coverage},
  author={Chang, Jonathan and Uehara, Masatoshi and Sreenivas, Dhruv and Kidambi, Rahul and Sun, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={965--979},
  year={2021}
}

@inproceedings{mei2020global,
  title={On the global convergence rates of softmax policy gradient methods},
  author={Mei, Jincheng and Xiao, Chenjun and Szepesvari, Csaba and Schuurmans, Dale},
  booktitle={International Conference on Machine Learning},
  pages={6820--6829},
  year={2020},
  organization={PMLR}
}

@article{o2020making,
  title={Making sense of reinforcement learning and probabilistic inference},
  author={O'Donoghue, Brendan and Osband, Ian and Ionescu, Catalin},
  journal={arXiv preprint arXiv:2001.00805},
  year={2020}
}

@article{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{chow2018path,
  title={Path consistency learning in tsallis entropy regularized mdps},
  author={Chow, Yinlam and Nachum, Ofir and Ghavamzadeh, Mohammad},
  booktitle={International conference on machine learning},
  pages={979--988},
  year={2018},
  organization={PMLR}
}


@misc{isaac-sim2real-2021,
title={Closing the Sim2Real Gap with NVIDIA Isaac Sim and NVIDIA Isaac Replicator},
author={NVIDIA Corporation},
year={2021},
url={https://developer.nvidia.com/blog/closing-the-sim2real-gap-with-nvidia-isaac-sim-and-nvidia-isaac-replicator/}
}

@article{power-system-expert,
AUTHOR = {Meinecke, Steffen and Thurner, Leon and Braun, Martin},
TITLE = {Review of Steady-State Electric Power Distribution System Datasets},
JOURNAL = {Energies},
VOLUME = {13},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {4826},
URL = {https://www.mdpi.com/1996-1073/13/18/4826},
ISSN = {1996-1073},
DOI = {10.3390/en13184826}
}

@article{waymo-expert,
  title={Large Scale Interactive Motion Forecasting for Autonomous Driving : The
  Waymo Open Motion Dataset},
  author={Scott Ettinger and Shuyang Cheng and Benjamin Caine and Chenxi Liu and Hang Zhao and Sabeek Pradhan and Yuning Chai and Ben Sapp and Charles Qi and Yin Zhou and Zoey Yang and Aurelien Chouard and Pei Sun and Jiquan Ngiam and Vijay Vasudevan and Alexander McCauley and Jonathon Shlens and Dragomir Anguelov},
  journal={arXiv},
  year={2021}
}

@misc{healthcare-expert,
title={10 Best Healthcare Data Sets \& Examples},
author={Maxwell Travers},
year={2021},
url={https://www.cprime.com/resources/blog/10-best-healthcare-data-sets-examples/}
}

@inproceedings{eysenbach2022maximum,
  title={Maximum Entropy RL (Provably) Solves Some Robust RL Problems},
  author={Eysenbach, Benjamin and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{bashiri2021distributionally,
  title={Distributionally Robust Imitation Learning},
  author={Bashiri, Mohammad Ali and Ziebart, Brian and Zhang, Xinhua},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={24404--24417},
  year={2021}
}



%% Model-free offline RL papers

@article{jiang2020minimax,
  title={Minimax value interval for off-policy evaluation and policy optimization},
  author={Jiang, Nan and Huang, Jiawei},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2747--2758},
  year={2020}
}

@article{foster2021offline,
  title={Offline reinforcement learning: Fundamental barriers for value function approximation},
  author={Foster, Dylan J and Krishnamurthy, Akshay and Simchi-Levi, David and Xu, Yunzong},
  journal={arXiv preprint arXiv:2111.10919},
  year={2021}
}

@article{rashidinejad2022optimal,
  title={Optimal conservative offline rl with general function approximation via augmented lagrangian},
  author={Rashidinejad, Paria and Zhu, Hanlin and Yang, Kunhe and Russell, Stuart and Jiao, Jiantao},
  journal={arXiv preprint arXiv:2211.00716},
  year={2022}
}

@inproceedings{shi2022pessimistic,
  title={Pessimistic q-learning for offline reinforcement learning: Towards optimal sample complexity},
  author={Shi, Laixi and Li, Gen and Wei, Yuting and Chen, Yuxin and Chi, Yuejie},
  booktitle={International Conference on Machine Learning},
  pages={19967--20025},
  year={2022},
  organization={PMLR}
}

@article{zanette2022bellman,
  title={Bellman residual orthogonalization for offline reinforcement learning},
  author={Zanette, Andrea and Wainwright, Martin J},
  journal={arXiv preprint arXiv:2203.12786},
  year={2022}
}

@inproceedings{zhan2022offline,
  title={Offline reinforcement learning with realizability and single-policy concentrability},
  author={Zhan, Wenhao and Huang, Baihe and Huang, Audrey and Jiang, Nan and Lee, Jason},
  booktitle={Conference on Learning Theory},
  pages={2730--2775},
  year={2022},
  organization={PMLR}
}

@article{ozdaglar2022revisiting,
  title={Revisiting the Linear-Programming Framework for Offline RL with General Function Approximation},
  author={Ozdaglar, Asuman and Pattathil, Sarath and Zhang, Jiawei and Zhang, Kaiqing},
  journal={arXiv preprint arXiv:2212.13861},
  year={2022}
}

@article{zhu2023importance,
  title={Importance Weighted Actor-Critic for Optimal Conservative Offline Reinforcement Learning},
  author={Zhu, Hanlin and Rashidinejad, Paria and Jiao, Jiantao},
  journal={arXiv preprint arXiv:2301.12714},
  year={2023}
}

@inproceedings{xie2021batch,
  title={Batch value-function approximation with only realizability},
  author={Xie, Tengyang and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={11404--11413},
  year={2021},
  organization={PMLR}
}

@article{xie2022armor,
  title={ARMOR: A Model-based Framework for Improving Arbitrary Baseline Policies with Offline Data},
  author={Xie, Tengyang and Bhardwaj, Mohak and Jiang, Nan and Cheng, Ching-An},
  journal={arXiv preprint arXiv:2211.04538},
  year={2022}
}




%% Offline RL 

@article{cabi2019scaling,
  title={Scaling data-driven robotics with reward sketching and batch reinforcement learning},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and Zolna, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

@article{li2019aads,
  title={AADS: Augmented autonomous driving simulation using data-driven algorithms},
  author={Li, Wei and Pan, CW and Zhang, Rong and Ren, JP and Ma, YX and Fang, Jin and Yan, FL and Geng, QC and Huang, XY and Gong, HJ and others},
  journal={Science robotics},
  volume={4},
  number={28},
  pages={eaaw0863},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{amini2020learning,
  title={Learning robust control policies for end-to-end autonomous driving from data-driven simulation},
  author={Amini, Alexander and Gilitschenski, Igor and Phillips, Jacob and Moseyko, Julia and Banerjee, Rohan and Karaman, Sertac and Rus, Daniela},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={1143--1150},
  year={2020},
  publisher={IEEE}
}

@article{hu2016data,
  title={Data driven analytics for personalized healthcare},
  author={Hu, Jianying and Perer, Adam and Wang, Fei},
  journal={Healthcare Information Management Systems: Cases, Strategies, and Solutions},
  pages={529--554},
  year={2016},
  publisher={Springer}
}

@article{dang2020data,
  title={Data-driven structural health monitoring using feature fusion and hybrid deep learning},
  author={Dang, Hung V and Tran-Ngoc, Hoa and Nguyen, Tung V and Bui-Tien, Thanh and De Roeck, Guido and Nguyen, Huan X},
  journal={IEEE Transactions on Automation Science and Engineering},
  volume={18},
  number={4},
  pages={2087--2103},
  year={2020},
  publisher={IEEE}
}

@article{li2022settling,
  title={Settling the sample complexity of model-based offline reinforcement learning},
  author={Li, Gen and Shi, Laixi and Chen, Yuxin and Chi, Yuejie and Wei, Yuting},
  journal={arXiv preprint arXiv:2204.05275},
  year={2022}
}



@inproceedings{jin2021pessimism,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{gabbianelli2023offline,
  title={Offline Primal-Dual Reinforcement Learning for Linear MDPs},
  author={Gabbianelli, Germano and Neu, Gergely and Okolo, Nneka and Papini, Matteo},
  journal={arXiv preprint arXiv:2305.12944},
  year={2023}
}

@inproceedings{xiong2022nearly,
  title={Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game},
  author={Xiong, Wei and Zhong, Han and Shi, Chengshuai and Shen, Cong and Wang, Liwei and Zhang, Tong},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}




@article{rashidinejad2022bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={IEEE Transactions on Information Theory},
  volume={68},
  number={12},
  pages={8156--8196},
  year={2022},
  publisher={IEEE}
}



@inproceedings{uehara2021pessimistic,
  title={Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage},
  author={Uehara, Masatoshi and Sun, Wen},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{yin2022near,
title={Near-optimal Offline Reinforcement Learning with Linear Representation: Leveraging Variance Information with Pessimism},
author={Ming Yin and Yaqi Duan and Mengdi Wang and Yu-Xiang Wang},
booktitle={International Conference on Learning Representations},
year={2022},
}

@article{ma2022distributionally,
  title={Distributionally robust offline reinforcement learning with linear function approximation},
  author={Ma, Xiaoteng and Liang, Zhipeng and Xia, Li and Zhang, Jiheng and Blanchet, Jose and Liu, Mingwen and Zhao, Qianchuan and Zhou, Zhengyuan},
  journal={arXiv preprint arXiv:2209.06620},
  year={2022}
}

@article{sriperumbudur2009integral,
  title={On integral probability metrics,$\backslash$phi-divergences and binary classification},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
  journal={arXiv preprint arXiv:0901.2698},
  year={2009}
}


@InProceedings{cheng2022adversarially,
  title = 	 {Adversarially Trained Actor Critic for Offline Reinforcement Learning},
  author =       {Cheng, Ching-An and Xie, Tengyang and Jiang, Nan and Agarwal, Alekh},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {3852--3878},
  year = 	 {2022},
}



@inproceedings{precup2000eligibility,
  author    = {Doina Precup and
               Richard S. Sutton and
               Satinder Singh},
  title     = {Eligibility Traces for Off-Policy Policy Evaluation},
  booktitle = {Proceedings of the Seventeenth International Conference on Machine
               Learning},
  pages     = {759--766},
  year      = {2000},
}

@article{canonne2020short,
  title={A short note on learning discrete distributions},
  author={Canonne, Cl{\'e}ment L},
  journal={arXiv preprint arXiv:2002.11457},
  year={2020}
}

@article{massart1990tight,
  title={The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality},
  author={Massart, Pascal},
  journal={The annals of Probability},
  pages={1269--1283},
  year={1990},
  publisher={JSTOR}
}

@article{kumar2022efficient,
  title={Efficient policy iteration for robust markov decision processes via regularization},
  author={Kumar, Navdeep and Levy, Kfir and Wang, Kaixin and Mannor, Shie},
  journal={arXiv preprint arXiv:2205.14327},
  year={2022}
}

@book{cormen2022introduction,
  title={Introduction to algorithms},
  author={Cormen, Thomas H and Leiserson, Charles E and Rivest, Ronald L and Stein, Clifford},
  year={2022},
  publisher={MIT press}
}

@inproceedings{bhattacharyya2021near,
  title={Near-optimal learning of tree-structured distributions by Chow-Liu},
  author={Bhattacharyya, Arnab and Gayen, Sutanu and Price, Eric and Vinodchandran, NV},
  booktitle={Proceedings of the 53rd annual acm SIGACT symposium on theory of computing},
  pages={147--160},
  year={2021}
}

@article{arora2023near,
  title={Near-Optimal Degree Testing for Bayes Nets},
  author={Arora, Vipul and Bhattacharyya, Arnab and Canonne, Cl{\'e}ment L and Yang, Joy Qiping},
  journal={arXiv preprint arXiv:2304.06733},
  year={2023}
}

@article{fournier2015rate,
  title={On the rate of convergence in Wasserstein distance of the empirical measure},
  author={Fournier, Nicolas and Guillin, Arnaud},
  journal={Probability theory and related fields},
  volume={162},
  number={3-4},
  pages={707--738},
  year={2015},
  publisher={Springer}
}

@article{hsu2012tail,
author = {Daniel Hsu and Sham Kakade and Tong Zhang},
title = {{A tail inequality for quadratic forms of subgaussian random vectors}},
journal = {Electronic Communications in Probability},
publisher = {Institute of Mathematical Statistics and Bernoulli Society},
year = {2012},
}


@article{lei2020convergence,
author = {Jing Lei},
title = {{Convergence and concentration of empirical measures under Wasserstein distance in unbounded functional spaces}},
volume = {26},
journal = {Bernoulli},
number = {1},
publisher = {Bernoulli Society for Mathematical Statistics and Probability},
pages = {767 -- 798},
year = {2020},
}

@book{villani2009optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric and others},
  volume={338},
  year={2009},
  publisher={Springer}
}

@book{villani2021topics,
  title={Topics in optimal transportation},
  author={Villani, C{\'e}dric},
  volume={58},
  year={2021},
  publisher={American Mathematical Soc.}
}


@inproceedings{zhang2022corruption,
  title={Corruption-robust offline reinforcement learning},
  author={Zhang, Xuezhou and Chen, Yiding and Zhu, Xiaojin and Sun, Wen},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={5757--5773},
  year={2022},
  organization={PMLR}
}

@article{diamond2016cvxpy,
  title={CVXPY: A Python-embedded modeling language for convex optimization},
  author={Diamond, Steven and Boyd, Stephen},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2909--2913},
  year={2016},
  publisher={JMLR. org}
}

% Contextual Bandits

@article{ren2023dynamic,
  title={Dynamic batch learning in high-dimensional sparse linear contextual bandits},
  author={Ren, Zhimei and Zhou, Zhengyuan},
  journal={Management Science},
  year={2023},
  publisher={INFORMS}
}

@article{han2020sequential,
  title={Sequential batch learning in finite-action linear contextual bandits},
  author={Han, Yanjun and Zhou, Zhengqing and Zhou, Zhengyuan and Blanchet, Jose and Glynn, Peter W and Ye, Yinyu},
  journal={arXiv preprint arXiv:2004.06321},
  year={2020}
}

@article{yue2012k,
  title={The k-armed dueling bandits problem},
  author={Yue, Yisong and Broder, Josef and Kleinberg, Robert and Joachims, Thorsten},
  journal={Journal of Computer and System Sciences},
  volume={78},
  number={5},
  pages={1538--1556},
  year={2012},
  publisher={Elsevier}
}

@inproceedings{dudik2015contextual,
  title={Contextual dueling bandits},
  author={Dud{\'\i}k, Miroslav and Hofmann, Katja and Schapire, Robert E and Slivkins, Aleksandrs and Zoghi, Masrour},
  booktitle={Conference on Learning Theory},
  pages={563--587},
  year={2015},
  organization={PMLR}
}

% RLHF/Learning from human preferences
@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

@article{wang2024secrets,
  title={Secrets of rlhf in large language models part ii: Reward modeling},
  author={Wang, Binghai and Zheng, Rui and Chen, Lu and Liu, Yan and Dou, Shihan and Huang, Caishuang and Shen, Wei and Jin, Senjie and Zhou, Enyu and Shi, Chenyu and others},
  journal={arXiv preprint arXiv:2401.06080},
  year={2024}
}


@inproceedings{zhu2023principled,
  title={Principled reinforcement learning with human feedback from pairwise or k-wise comparisons},
  author={Zhu, Banghua and Jordan, Michael and Jiao, Jiantao},
  booktitle={International Conference on Machine Learning},
  pages={43037--43067},
  year={2023},
  organization={PMLR}
}





@InProceedings{go2023aligning,
  title = 	 {Aligning Language Models with Preferences through $f$-divergence Minimization},
  author =       {Go, Dongyoung and Korbak, Tomasz and Kruszewski, Germ\`{a}n and Rozen, Jos and Ryu, Nahyeon and Dymetman, Marc},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {11546--11583},
  year = 	 {2023},
}

@article{korbak2022reinforcement,
  title={On reinforcement learning and distribution matching for fine-tuning language models with no catastrophic forgetting},
  author={Korbak, Tomasz and Elsahar, Hady and Kruszewski, Germ{\'a}n and Dymetman, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16203--16220},
  year={2022}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}


@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}



@inproceedings{zhao2024group,
  title={Group Preference Optimization: Few-Shot Alignment of Large Language Models},
  author={Zhao, Siyan and Dang, John and Grover, Aditya},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{durmus2023towards,
  title={Towards measuring the representation of subjective global opinions in language models},
  author={Durmus, Esin and Nyugen, Karina and Liao, Thomas I and Schiefer, Nicholas and Askell, Amanda and Bakhtin, Anton and Chen, Carol and Hatfield-Dodds, Zac and Hernandez, Danny and Joseph, Nicholas and others},
  journal={arXiv preprint arXiv:2306.16388},
  year={2023}
}


@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}


@inproceedings{
zheng2024improving,
title={Improving Generalization of Alignment with Human Preferences through Group Invariant Learning},
author={Rui Zheng and Wei Shen and Yuan Hua and Wenbin Lai and Shihan Dou and Yuhao Zhou and Zhiheng Xi and Xiao Wang and Haoran Huang and Tao Gui and Qi Zhang and Xuanjing Huang},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}


@InProceedings{azar2024ageneral,
  title = 	 { A General Theoretical Paradigm to Understand Learning from Human Preferences },
  author =       {Gheshlaghi Azar, Mohammad and Daniel Guo, Zhaohan and Piot, Bilal and Munos, Remi and Rowland, Mark and Valko, Michal and Calandriello, Daniele},
  booktitle = 	 {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {4447--4455},
  year = 	 {2024},
  volume = 	 {238},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
}

@inproceedings{christiano2017deep,
 author = {Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Deep Reinforcement Learning from Human Preferences},
 volume = {30},
 year = {2017}
}

@inproceedings{
wang2024beyond,
title={Beyond Reverse {KL}: Generalizing Direct Preference Optimization with Diverse Divergence Constraints},
author={Chaoqi Wang and Yibo Jiang and Chenghao Yang and Han Liu and Yuxin Chen},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@inproceedings{
hejna2024contrastive,
title={Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning},
author={Joey Hejna and Rafael Rafailov and Harshit Sikchi and Chelsea Finn and Scott Niekum and W. Bradley Knox and Dorsa Sadigh},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@inproceedings{gao2023scaling,
  title={Scaling laws for reward model overoptimization},
  author={Gao, Leo and Schulman, John and Hilton, Jacob},
  booktitle={International Conference on Machine Learning},
  pages={10835--10866},
  year={2023},
  organization={PMLR}
}

@inproceedings{
tang2024generalized,
title={Generalized Preference Optimization: A Unified Approach to Offline Alignment},
author={Yunhao Tang and Zhaohan Daniel Guo and Zeyu Zheng and Daniele Calandriello and Remi Munos and Mark Rowland and Pierre Harvey Richemond and Michal Valko and Bernardo Avila Pires and Bilal Piot},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}

@inproceedings{
sharma2024towards,
title={Towards Understanding Sycophancy in Language Models},
author={Mrinank Sharma and Meg Tong and Tomasz Korbak and David Duvenaud and Amanda Askell and Samuel R. Bowman and Esin DURMUS and Zac Hatfield-Dodds and Scott R Johnston and Shauna M Kravec and Timothy Maxwell and Sam McCandlish and Kamal Ndousse and Oliver Rausch and Nicholas Schiefer and Da Yan and Miranda Zhang and Ethan Perez},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@inproceedings{song2024preference,
  title={Preference ranking optimization for human alignment},
  author={Song, Feifan and Yu, Bowen and Li, Minghao and Yu, Haiyang and Huang, Fei and Li, Yongbin and Wang, Houfeng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2024}
}

@article{hartmann2023,
title = {More than a Feeling: Accuracy and Application of Sentiment Analysis},
journal = {International Journal of Research in Marketing},
year = {2023},
author = {Jochen Hartmann and Mark Heitmann and Christian Siebert and Christina Schamp},
}

@article{gunasekar2023textbooks,
  title={Textbooks are all you need},
  author={Gunasekar, Suriya and Zhang, Yi and Aneja, Jyoti and Mendes, Caio C{\'e}sar Teodoro and Del Giorno, Allie and Gopi, Sivakanth and Javaheripi, Mojan and Kauffmann, Piero and de Rosa, Gustavo and Saarikivi, Olli and others},
  journal={arXiv preprint arXiv:2306.11644},
  year={2023}
}


@inproceedings{
ethayarajh2024model,
title={Model Alignment as Prospect Theoretic Optimization},
author={Kawin Ethayarajh and Winnie Xu and Niklas Muennighoff and Dan Jurafsky and Douwe Kiela},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}


@article{zhao2023slic,
  title={Slic-hf: Sequence likelihood calibration with human feedback},
  author={Zhao, Yao and Joshi, Rishabh and Liu, Tianqi and Khalman, Misha and Saleh, Mohammad and Liu, Peter J},
  journal={arXiv preprint arXiv:2305.10425},
  year={2023}
}


@inproceedings{stiennon2020learning,
 author = {Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {3008--3021},
 title = {Learning to summarize with human feedback},
 volume = {33},
 year = {2020}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@inproceedings{
an2023direct,
title={Direct Preference-based Policy Optimization without Reward Modeling},
author={Gaon An and Junhyeok Lee and Xingdong Zuo and Norio Kosaka and Kyung-Min Kim and Hyun Oh Song},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
}

@inproceedings{
zhan2023provable,
title={Provable Offline Reinforcement Learning with Human Feedback},
author={Wenhao Zhan and Masatoshi Uehara and Nathan Kallus and Jason D. Lee and Wen Sun},
booktitle={ICML 2023 Workshop The Many Facets of Preference-Based Learning},
year={2023},
url={https://openreview.net/forum?id=AY1dsKpNTu}
}

% Robust RLHF
@article{mandal2024corruption,
  title={Corruption Robust Offline Reinforcement Learning with Human Feedback},
  author={Mandal, Debmalya and Nika, Andi and Kamalaruban, Parameswaran and Singla, Adish and Radanovi{\'c}, Goran},
  journal={arXiv preprint arXiv:2402.06734},
  year={2024}
}

% Wasserstein DRO and regularization
@article{shafieezadeh2019regularization,
  title={Regularization via mass transportation},
  author={Shafieezadeh-Abadeh, Soroosh and Kuhn, Daniel and Esfahani, Peyman Mohajerin},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={103},
  pages={1--68},
  year={2019}
}

@inproceedings{petzka2018regularization,
  title={On the regularization of Wasserstein GANs},
  author={Petzka, Henning and Fischer, Asja and Lukovnikov, Denis},
  booktitle={International Conference on Learning Representations},
  year={2018}
}


@article{gao2022wasserstein,
  title={Wasserstein distributionally robust optimization and variation regularization},
  author={Gao, Rui and Chen, Xi and Kleywegt, Anton J},
  journal={Operations Research},
  year={2022},
  publisher={Informs}
}

@article{ramesh2024group,
  title={Group Robust Preference Optimization in Reward-free RLHF},
  author={Ramesh, Shyam Sundhar and Hu, Yifan and Chaimalas, Iason and Mehta, Viraj and Sessa, Pier Giuseppe and Ammar, Haitham Bou and Bogunovic, Ilija},
  journal={arXiv preprint arXiv:2405.20304},
  year={2024}
}

@article{bukharin2024robust,
  title={Robust reinforcement learning from corrupted human feedback},
  author={Bukharin, Alexander and Hong, Ilgee and Jiang, Haoming and Li, Zichong and Zhang, Qingru and Zhang, Zixuan and Zhao, Tuo},
  journal={arXiv preprint arXiv:2406.15568},
  year={2024}
}

@article{yan2024reward,
  title={Reward-robust rlhf in llms},
  author={Yan, Yuzi and Lou, Xingzhou and Li, Jialian and Zhang, Yiping and Xie, Jian and Yu, Chao and Wang, Yu and Yan, Dong and Shen, Yuan},
  journal={arXiv preprint arXiv:2409.15360},
  year={2024}
}



@article{gao2023finite,
  title={Finite-sample guarantees for Wasserstein distributionally robust optimization: Breaking the curse of dimensionality},
  author={Gao, Rui},
  journal={Operations Research},
  volume={71},
  number={6},
  pages={2291--2306},
  year={2023},
  publisher={INFORMS}
}

@inproceedings{
chowdhury2024provably,
title={Provably Robust {DPO}: Aligning Language Models with Noisy Feedback},
author={Sayak Ray Chowdhury and Anush Kini and Nagarajan Natarajan},
booktitle={Forty-first International Conference on Machine Learning},
year={2024}
}

@article{padmakumar2024beyond,
  title={Beyond the binary: Capturing diverse preferences with reward regularization},
  author={Padmakumar, Vishakh and Jin, Chuanyang and Kirk, Hannah Rose and He, He},
  journal={arXiv preprint arXiv:2412.03822},
  year={2024}
}

@article{huang2024correcting,
  title={Correcting the Mythos of KL-Regularization: Direct Alignment without Overoptimization via Chi-Squared Preference Optimization},
  author={Huang, Audrey and Zhan, Wenhao and Xie, Tengyang and Lee, Jason D and Sun, Wen and Krishnamurthy, Akshay and Foster, Dylan J},
  journal={arXiv preprint arXiv:2407.13399},
  year={2024}
}

@inproceedings{
chakraborty2024maxmin,
title={MaxMin-{RLHF}: Alignment with Diverse Human Preferences},
author={Souradip Chakraborty and Jiahao Qiu and Hui Yuan and Alec Koppel and Dinesh Manocha and Furong Huang and Amrit Bedi and Mengdi Wang},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}

@inproceedings{yangrewards,
  title={Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment},
  author={Yang, Rui and Pan, Xiaoman and Luo, Feng and Qiu, Shuang and Zhong, Han and Yu, Dong and Chen, Jianshu},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024},
}


@inproceedings{oren2019distributionally,
  title={Distributionally Robust Language Modeling},
  author={Oren, Yonatan and Sagawa, Shiori and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={4227--4237},
  year={2019}
}

% Wasserstein GAN
@article{gulrajani2017improved,
  title={Improved training of wasserstein gans},
  author={Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

@inproceedings{
nika2024reward,
title={Reward Model Learning vs. Direct Policy Optimization: A Comparative Analysis of Learning from Human Preferences},
author={Andi Nika and Debmalya Mandal and Parameswaran Kamalaruban and Georgios Tzannetos and Goran Radanovic and Adish Singla},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}

@article{shah2016estimation,
  title={Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence},
  author={Shah, Nihar B and Balakrishnan, Sivaraman and Bradley, Joseph and Parekh, Abhay and Ramch, Kannan and Wainwright, Martin J and others},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={58},
  pages={1--47},
  year={2016}
}





% robust rlhf/dpo
@article{wu2024towards,
  title={Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization},
  author={Wu, Junkang and Xie, Yuexiang and Yang, Zhengyi and Wu, Jiancan and Chen, Jiawei and Gao, Jinyang and Ding, Bolin and Wang, Xiang and He, Xiangnan},
  journal={arXiv preprint arXiv:2407.07880},
  year={2024}
}

@misc{mitchell2023note,
  title={A note on DPO with noisy preferences \& relationship to IPO},
  author={Mitchell, Eric},
  year={2023}
}

% robust learning
@inproceedings{dukler2019wasserstein,
  title={Wasserstein of Wasserstein loss for learning generative models},
  author={Dukler, Yonatan and Li, Wuchen and Lin, Alex and Mont{\'u}far, Guido},
  booktitle={International conference on machine learning},
  pages={1716--1725},
  year={2019},
  organization={PMLR}
}

% Wasserstein DRO in ML
@article{volpi2018generalizing,
  title={Generalizing to unseen domains via adversarial data augmentation},
  author={Volpi, Riccardo and Namkoong, Hongseok and Sener, Ozan and Duchi, John C and Murino, Vittorio and Savarese, Silvio},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{blanchet2019quantifying,
  title={Quantifying distributional model risk via optimal transport},
  author={Blanchet, Jose and Murthy, Karthyek},
  journal={Mathematics of Operations Research},
  volume={44},
  number={2},
  pages={565--600},
  year={2019},
  publisher={INFORMS}
}
@article{shafieezadeh2015distributionally,
  title={Distributionally robust logistic regression},
  author={Shafieezadeh Abadeh, Soroosh and Mohajerin Esfahani, Peyman M and Kuhn, Daniel},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}
@inproceedings{
sinha2018certifiable,
title={Certifiable Distributional Robustness with Principled Adversarial Training},
author={Aman Sinha and Hongseok Namkoong and John Duchi},
booktitle={International Conference on Learning Representations},
year={2018},
}

@article{
shen2024wasserstein,
title={Wasserstein Distributionally Robust Policy Evaluation and Learning for Contextual Bandits},
author={Yi Shen and Pan Xu and Michael Zavlanos},
journal={Transactions on Machine Learning Research},
year={2024},
note={Featured Certification}
}

% Dataset
@inproceedings{saravia-etal-2018-carer,
    title = "{CARER}: Contextualized Affect Representations for Emotion Recognition",
    author = "Saravia, Elvis  and
      Liu, Hsien-Chi Toby  and
      Huang, Yen-Hao  and
      Wu, Junlin  and
      Chen, Yi-Shin",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    year = "2018",
    publisher = "Association for Computational Linguistics",
    pages = "3687--3697",
}

@article{liu2024rrm,
  title={Rrm: Robust reward model training mitigates reward hacking},
  author={Liu, Tianqi and Xiong, Wei and Ren, Jie and Chen, Lichang and Wu, Junru and Joshi, Rishabh and Gao, Yang and Shen, Jiaming and Qin, Zhen and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2409.13156},
  year={2024}
}
@misc{farquhar2025monamyopicoptimizationnonmyopic,
      title={MONA: Myopic Optimization with Non-myopic Approval Can Mitigate Multi-step Reward Hacking}, 
      author={Sebastian Farquhar and Vikrant Varma and David Lindner and David Elson and Caleb Biddulph and Ian Goodfellow and Rohin Shah},
      year={2025},
      eprint={2501.13011},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.13011}, 
}




%%%%%%%Intro references

@article{zhang2024diverging,
  title={Diverging Preferences: When do Annotators Disagree and do Models Know?},
  author={Zhang, Michael JQ and Wang, Zhilin and Hwang, Jena D and Dong, Yi and Delalleau, Olivier and Choi, Yejin and Choi, Eunsol and Ren, Xiang and Pyatkin, Valentina},
  journal={arXiv preprint arXiv:2410.14632},
  year={2024}
}

@article{skalse2022defining,
  title={Defining and characterizing reward gaming},
  author={Skalse, Joar and Howe, Nikolaus and Krasheninnikov, Dmitrii and Krueger, David},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={9460--9471},
  year={2022}
}

@article{eisenstein2023helping,
  title={Helping or herding? reward model ensembles mitigate but do not eliminate reward hacking},
  author={Eisenstein, Jacob and Nagpal, Chirag and Agarwal, Alekh and Beirami, Ahmad and D'Amour, Alex and Dvijotham, DJ and Fisch, Adam and Heller, Katherine and Pfohl, Stephen and Ramachandran, Deepak and others},
  journal={arXiv preprint arXiv:2312.09244},
  year={2023}
}

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@article{casper2023open,
  title={Open problems and fundamental limitations of reinforcement learning from human feedback},
  author={Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\'e}r{\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others},
  journal={arXiv preprint arXiv:2307.15217},
  year={2023}
}

@article{levine2023baseline,
  title={A Baseline Analysis of Reward Models' Ability To Accurately Analyze Foundation Models Under Distribution Shift},
  author={LeVine, Will and Pikus, Benjamin and Chen, Anthony and Hendryx, Sean},
  journal={arXiv preprint arXiv:2311.14743},
  year={2023}
}

@inproceedings{kirk2024understanding,
  title={Understanding the Effects of RLHF on LLM Generalisation and Diversity},
  author={Kirk, Robert and Mediratta, Ishita and Nalmpantis, Christoforos and Luketina, Jelena and Hambro, Eric and Grefenstette, Edward and Raileanu, Roberta},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}
