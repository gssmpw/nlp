\documentclass[11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{setspace} % [onehalfspacing]
\linespread{1.1}
% fonts
\usepackage{lmodern}
% \usepackage{mathpazo}
% \usepackage{stix}
% \usepackage{mathptmx}
\usepackage{libertine}
% \usepackage{newpxtext} 
% \usepackage[euler-digits]{eulervm}

\usepackage[pagebackref=true]{hyperref}
\usepackage{url}

\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage[nice]{nicefrac} % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
% \usepackage{cite}
\let\proof\relax
\let\endproof\relax
\usepackage{textcomp}
\usepackage{xcolor}
% comment colors
\newcommand{\dk}[1]{{[\color{purple}DK: #1}]} 
\newcommand{\zx}[1]{{[\color{gray}ZX: #1}]}
\newcommand{\kpb}[1]{{[\color{blue}KP: #1}]}
% \bibliographystyle{abbrvnat}

\usepackage{amsmath,amsthm,amstext,amsfonts,amssymb,mathrsfs,mathtools}
\usepackage{graphicx,caption,subcaption,color,algorithm,algorithmic} 
\usepackage{bbm}
\usepackage{wrapfig,dsfont,booktabs,enumerate}

\usepackage[capitalize]{cleveref}
\usepackage{marvosym}
\usepackage{changepage}
\usepackage{parskip}
\usepackage{shortcuts}
\usepackage[round]{natbib}
\usepackage{authblk}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}

% Make institutions appear on a single line
\makeatletter
\patchcmd{\AB@affilsepx}{\\}{, \quad}{}{}
\makeatother

\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

% If you use BibTeX in apalike style, activate the following line:
\bibliographystyle{apalike}

\title{Distributionally Robust Direct Preference Optimization}

\author[1]{Zaiyan Xu}
\author[1]{Sushil Vemuri}
\author[2]{Kishan Panaganti}
\author[1]{Dileep Kalathil} 
\author[3]{\\Rahul Jain}
\author[3]{Deepak Ramachandran}
\affil[1]{Texas A\&M University}
\affil[2]{Caltech}
\affil[3]{Google DeepMind}


\date{}

\begin{document}


\maketitle

\begin{abstract}
A major challenge in aligning large language models (LLMs) with human preferences is the issue of \textit{distribution shift}. LLM alignment algorithms rely on static preference datasets, assuming that they accurately represent real-world user preferences. However, user preferences vary significantly across geographical regions, demographics, linguistic patterns, and evolving cultural trends. This preference distribution shift leads to catastrophic alignment failures in many real-world applications.  We address this problem using the principled framework of distributionally robust optimization, and develop two novel distributionally robust direct preference optimization (DPO) algorithms, namely, Wasserstein DPO (WDPO) and Kullbackâ€“Leibler DPO (KLDPO). We characterize the sample complexity of learning the optimal policy parameters for WDPO and KLDPO. Moreover, we propose scalable gradient descent-style learning algorithms by developing suitable approximations for the challenging minimax loss functions of  WDPO and KLDPO.  Our empirical experiments demonstrate the superior performance of  WDPO and KLDPO in substantially improving the alignment when there is a preference distribution shift. 
\end{abstract}

\input{01-introduction}
\input{02-related-work}
\input{03-preliminaries}
\input{04-wasserstein-dpo}
\input{05-theoretical-analysis}
\input{06-empirical-algorithm}
\input{07-experiments}
\input{08-conclusion}


\newpage
\bibliography{References} 

\input{appendix}

\end{document}
