[
  {
    "index": 0,
    "papers": [
      {
        "key": "bai2022training",
        "author": "Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others",
        "title": "Training a helpful and harmless assistant with reinforcement learning from human feedback"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "chakraborty2024maxmin",
        "author": "Souradip Chakraborty and Jiahao Qiu and Hui Yuan and Alec Koppel and Dinesh Manocha and Furong Huang and Amrit Bedi and Mengdi Wang",
        "title": "MaxMin-{RLHF}: Alignment with Diverse Human Preferences"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "padmakumar2024beyond",
        "author": "Padmakumar, Vishakh and Jin, Chuanyang and Kirk, Hannah Rose and He, He",
        "title": "Beyond the binary: Capturing diverse preferences with reward regularization"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "yan2024reward",
        "author": "Yan, Yuzi and Lou, Xingzhou and Li, Jialian and Zhang, Yiping and Xie, Jian and Yu, Chao and Wang, Yu and Yan, Dong and Shen, Yuan",
        "title": "Reward-robust rlhf in llms"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "bukharin2024robust",
        "author": "Bukharin, Alexander and Hong, Ilgee and Jiang, Haoming and Li, Zichong and Zhang, Qingru and Zhang, Zixuan and Zhao, Tuo",
        "title": "Robust reinforcement learning from corrupted human feedback"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "huang2024correcting",
        "author": "Huang, Audrey and Zhan, Wenhao and Xie, Tengyang and Lee, Jason D and Sun, Wen and Krishnamurthy, Akshay and Foster, Dylan J",
        "title": "Correcting the Mythos of KL-Regularization: Direct Alignment without Overoptimization via Chi-Squared Preference Optimization"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "ramesh2024group",
        "author": "Ramesh, Shyam Sundhar and Hu, Yifan and Chaimalas, Iason and Mehta, Viraj and Sessa, Pier Giuseppe and Ammar, Haitham Bou and Bogunovic, Ilija",
        "title": "Group Robust Preference Optimization in Reward-free RLHF"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "chowdhury2024provably",
        "author": "Sayak Ray Chowdhury and Anush Kini and Nagarajan Natarajan",
        "title": "Provably Robust {DPO}: Aligning Language Models with Noisy Feedback"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wu2024towards",
        "author": "Wu, Junkang and Xie, Yuexiang and Yang, Zhengyi and Wu, Jiancan and Chen, Jiawei and Gao, Jinyang and Ding, Bolin and Wang, Xiang and He, Xiangnan",
        "title": "Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "chen2018robust",
        "author": "Chen, Ruidi and Paschalidis, Ioannis Ch",
        "title": "A robust learning approach for regression models based on distributionally robust optimization"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "namkoong2016stochastic",
        "author": "Namkoong, Hongseok and Duchi, John C",
        "title": "Stochastic gradient methods for distributionally robust optimization with f-divergences"
      },
      {
        "key": "duchi2018learning",
        "author": "John C. Duchi and Hongseok Namkoong",
        "title": "{Learning models with uniform performance via distributionally robust optimization}"
      },
      {
        "key": "levy2020large",
        "author": "Levy, Daniel and Carmon, Yair and Duchi, John C and Sidford, Aaron",
        "title": "Large-scale methods for distributionally robust optimization"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "esfahani2015data",
        "author": "Mohajerin Esfahani, Peyman and Kuhn, Daniel",
        "title": "Data-driven distributionally robust optimization using the Wasserstein metric: performance guarantees and tractable reformulations"
      },
      {
        "key": "kuhn2019wasserstein",
        "author": "Kuhn, Daniel and Esfahani, Peyman Mohajerin and Nguyen, Viet Anh and Shafieezadeh-Abadeh, Soroosh",
        "title": "Wasserstein distributionally robust optimization: Theory and applications in machine learning"
      },
      {
        "key": "gao2022wasserstein",
        "author": "Gao, Rui and Chen, Xi and Kleywegt, Anton J",
        "title": "Wasserstein distributionally robust optimization and variation regularization"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "chen2018robust",
        "author": "Chen, Ruidi and Paschalidis, Ioannis Ch",
        "title": "A robust learning approach for regression models based on distributionally robust optimization"
      },
      {
        "key": "namkoong2016stochastic",
        "author": "Namkoong, Hongseok and Duchi, John C",
        "title": "Stochastic gradient methods for distributionally robust optimization with f-divergences"
      },
      {
        "key": "levy2020large",
        "author": "Levy, Daniel and Carmon, Yair and Duchi, John C and Sidford, Aaron",
        "title": "Large-scale methods for distributionally robust optimization"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "si2020distributionally",
        "author": "Si, Nian and Zhang, Fan and Zhou, Zhengyuan and Blanchet, Jose",
        "title": "Distributionally robust policy evaluation and learning in offline contextual bandits"
      },
      {
        "key": "yang2023distributionally",
        "author": "Yang, Zhouhao and Guo, Yihong and Xu, Pan and Liu, Anqi and Anandkumar, Animashree",
        "title": "Distributionally robust policy gradient for offline contextual bandits"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "panaganti-rfqi",
        "author": "Panaganti, Kishan and Xu, Zaiyan and Kalathil, Dileep and Ghavamzadeh, Mohammad",
        "title": "Robust Reinforcement Learning using Offline Data"
      },
      {
        "key": "zhou2024natural",
        "author": "Zhou, Ruida and Liu, Tao and Cheng, Min and Kalathil, Dileep and Kumar, PR and Tian, Chao",
        "title": "Natural actor-critic for robust reinforcement learning with function approximation"
      },
      {
        "key": "shi2024distributionally",
        "author": "Shi, Laixi and Chi, Yuejie",
        "title": "Distributionally robust model-based offline reinforcement learning with near-optimal sample complexity"
      },
      {
        "key": "yang2022toward",
        "author": "Yang, Wenhao and Zhang, Liangyu and Zhang, Zhihua",
        "title": "Toward theoretical understandings of robust {M}arkov decision processes: Sample complexity and asymptotics"
      }
    ]
  }
]