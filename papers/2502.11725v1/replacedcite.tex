\section{Related Work}
\label{sec:related}

\textbf{Perceptual metrics.}
Low-level pixel-based $\ell_p$-metrics and structural similarity SSIM ____ do not capture well higher-order semantic similarity.
These are outperformed by metrics based on features extracted from neural networks trained on ImageNet, such as
LPIPS ____, 
PIE-APP ____ and DISTS ____. 
More recently, it has been shown that metrics induced by the features extracted by models trained on larger datasets and via self-supervised training, like CLIP ____, DINO ____ or MAE ____, are well aligned with human perception regarding semantic similarity ____. 
DreamSim ____ is a recent fine-tuned ensemble of three of these models on the 2AFC dataset NIGHTS which shows the best alignment with human preferences on NIGHTS.
\rev{In our work we show how to improve the performance of CLIP- and DINO-based perceptual metrics.}
\\

\textbf{Adversarial robustness of perceptual metrics.}
Virtually all vision tasks tackled via neural networks are vulnerable to adversarial examples ____, 
and attacks in several threat models exist ____.
The main empirical defense which works across different vision tasks is adversarial training ____. However, the price of having a robust model is typically a drop in performance.
Not surprisingly, perceptual metrics, including LPIPS and DreamSim, are also not robust to adversarial perturbations ____.
In order to get a robust version R-LPIPS of the popular LPIPS metric, Ghazanfari et al. ____ perform adversarial training on the 2AFC 
fine-tuning task of the Berkeley-Adobe Perceptual Patch Similarity dataset (BAPPS) ____.
LipSim ____ distills from DreamSim ____ a 1-Lipschitz network, and then fine-tunes it on the NIGHTS dataset ____
to achieve certified adversarial robustness.
\rev{Conversely, we will leverage recent techniques for robust zero-shot classification with CLIP to obtain perceptual metrics with SOTA adversarial robustness.}
\\

\textbf{
\rev{Interpretability} of adversarially robust models.}
Feature inversion, i.e. finding an image which matches given features at the output layer, can be used to understand the inner workings of a network. However, it often yields highly distorted images without much semantic content ____.
Notably, adversarially robust models suffer significantly less from this problem,
and can be used to generate semantically meaningful images when maximizing the probability of a specific class ____.
This 
can be even exploited to generate visual counterfactuals (instance-specific explanations) for modern image classifiers____.
\rev{Similarly, robust classifiers are known to have more interpretable gradients than standard ones ____}.
\rev{Our work illustrates that such properties yield more interpretable perceptual metrics.}