\section{Related work}
\label{sec:sec2}
In this section, we first introduce the frontier research of graph neural networks. Then we review some related works in deep learning-based age estimation. Finally, we briefly describe the reinforcement learning.

\subsection{Graph Neural Networks}
Graph Neural Networks (GNNs) have achieved impressive results in the field of processing non-Euclidean data and become a popular research. \textcolor{black}{
They have been widely applied in several tasks such as recommendation systems \citep{cui2024rakcr}, image retrieval \citep{qin2024heterogeneous}, action recognition \citep{qiu2024multi}, and multi-modal emotion recognition \citep{meng2024deep}.
}

There are several variants developed from GNNs, such as Graph Convolutional Neural Networks (GCNs) \citep{kipf2016semi}, Graph Attention Networks (GATs) \citep{velivckovic2017graph}, GraphSAGE \citep{hamilton2017inductive} and so on. For the most commonly used GCNs, existing work mainly focuses on two streams: spectral-based \citep{henaff2015deep} and spatial-based \citep{atwood2016diffusion, niepert2016learning}. However, they utilized the shallow networks that limit their representation capabilities, while deep GCNs are prone to over-smoothing which results in a rapid decrease in node differentiation. To get over this weakness, the mainstream attempts are two-fold:  \citet{li2019deepgcns} proposed DeepGCN similar to DeepCNN utilizing dilated convolutions, dense or residual connections to improve the expressive power. \citet{abu2019mixhop} proposed MixHop which involved discerning neighborhood connections at different distances by iteratively mixing the feature embedding. 

\textcolor{black}{
Following the former, we integrate a multi-head attention mechanism with a deep residual graph convolutional network fusing adaptive initial residuals and dynamic developmental residuals to obtain robust and comprehensive facial representation.
}

\subsection{Age Estimation}
Age estimation stands as a crucial and difficult task within the realm of computer vision. 
\textcolor{black}{
Current age estimation methods usually work on designing more robust face representation networks \citep{kuprashevich2023mivolo, shou2025masked, zhang2024groupface} or more efficient age estimation techniques \citep{shin2022moving, wang2023exploiting, chen2023daa}.
}

\textcolor{black}{
\citet{shin2022moving} proposed moving window regression (MWR), which formed a search window through two reference instances and then estimated the rho-rank. \citet{chen2023daa} proposed the Delta Age AdaIN (DAA), utilizing binary code mapping and age encoder-decoder.  \citet{kuprashevich2023mivolo} proposed Multi Input VOLO (MiVOLO) utilizing the newest vision transformer for age and gender estimation in the wild. \citet{wang2023exploiting} utilized meta-learning paradigm to built an unfair filtering network that reduce category bias in age estimation. \citet{zhang2024groupface} proposed GroupFace, integrating a multi-hop attention GCN with a group-aware margin strategy, which is effective in imbalanced age estimation. \citet{shou2025masked} proposed a Masked Contrastive Graph Representation Learning (MCGRL) to capture the rich structural information of the face, which outperforms the CNN and Transformer based methods. However, these methods is sufficient in capturing latent relations.
}

\textcolor{black}{
In this novel, we design the multi-head attention mechanism with a deep GCN to capturing latent relations effectively and efficiently.}



\subsection{Reinforcement Learning}
Reinforcement learning (RL) has become a new paradigm in artificial intelligence technology, which has also gained high speed in recent years. RL has shown a broad application prospect in the fields of finance, gaming, automation, robotics, and so on. The RL aims to train intelligence to make autonomous decisions by maximizing future cumulative rewards, which can effectively optimize image classification and regression. \citet{lin2020deep} considered imbalanced data classification as a Markov decision process, where samples are states, classification is actions, and rewards are based on the match between predicted and true values. \citet{wen2021building} modeled the decision tree generation as a Markov decision process and achieved significant results by guiding tree construction through reinforcement learning. \citet{yang2023deep} further optimized the original reinforcement learning algorithm to avoid overestimation of values and improve the training effectiveness. 

In this novel, the Double Deep Q Network (DDQN) is introduced to reinforcement learning for achieving better classification and prediction results, which identifies high-level features using a reward function that distinguishes between different classes, i.e., punish minorities more harshly or reward them more generously.