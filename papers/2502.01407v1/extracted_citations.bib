@misc{Springer_policy,
  author       = {{Springer Nature}},
  title        = {Research data policy},
  year         = 2016,
  publisher    = {Springer Nature},
  url          = {https://www.springernature.com/gp/authors/research-data-policy}
}

@article{armeni2021towards,
  title={Towards wide-scale adoption of open science practices: The role of open science communities},
  author={Armeni, Kristijan and Brinkman, Loek and Carlsson, Rickard and Eerland, Anita and Fijten, Rianne and Fondberg, Robin and Heininga, Vera E and Heunis, Stephan and Koh, Wei Qi and Masselink, Maurits and others},
  journal={Science and Public Policy},
  volume={48},
  number={5},
  pages={605--611},
  year={2021},
  publisher={Oxford University Press UK}
}

@misc{australia_policy,
	title = {Outline of a Research Data Management Policy for Australian Universities / Institutions},
	url = {https://alliancecan.ca/sites/default/files/2022-03/institutional-research-data-management-policies.pdf},
    year = {2011},
    author = {Australian National Data Service}
}

@article{belter_measuring_2014,
	title = {Measuring the {Value} of {Research} {Data}: {A} {Citation} {Analysis} of {Oceanographic} {Data} {Sets}},
	volume = {9},
	issn = {1932-6203},
	shorttitle = {Measuring the {Value} of {Research} {Data}},
	url = {https://dx.plos.org/10.1371/journal.pone.0092590},
	doi = {10.1371/journal.pone.0092590},
	abstract = {Evaluation of scientific research is becoming increasingly reliant on publication-based bibliometric indicators, which may result in the devaluation of other scientific activities - such as data curation – that do not necessarily result in the ...},
	language = {en},
	number = {3},
	urldate = {2024-11-05},
	journal = {PLoS ONE},
	author = {Belter, Christopher W.},
	month = mar,
	year = {2014},
	pmid = {24671177},
	
	pages = {e92590},

}

@article{besanccon2021open,
  title={Open science saves lives: lessons from the COVID-19 pandemic},
  author={Besan{\c{c}}on, Lonni and Peiffer-Smadja, Nathan and Segalas, Corentin and Jiang, Haiting and Masuzzo, Paola and Smout, Cooper and Billy, Eric and Deforet, Maxime and Leyrat, Cl{\'e}mence},
  journal={BMC Medical Research Methodology},
  volume={21},
  number={1},
  pages={117},
  year={2021},
  publisher={Springer}
}

@misc{bromley_policy_1991,
	type = {Text},
	title = {Policy {Statements} on {Data} {Management} for {Global} {Change} {Research}},
	copyright = {Public},
	url = {https://digital.library.unt.edu/ark:/67531/metadc11862/},
	abstract = {This document is the final version of the "Data Management for Global Change Research Policy Statements." The overall purpose of these policy statements is to facilitate full open access to quality data for global change research. They were prepared in consonance with the goal of the U.S. Global Change Research Program and represent the U.S. Government's position on the access to global change research data.},
	language = {English},
	urldate = {2024-11-05},
	journal = {UNT Digital Library},
	author = {Bromley, Allan},
	month = feb,
	year = {1991},
	

}

@misc{cao_rise_2023,
	title = {The {Rise} of {Open} {Science}: {Tracking} the {Evolution} and {Perceived} {Value} of {Data} and {Methods} {Link}-{Sharing} {Practices}},
	shorttitle = {The {Rise} of {Open} {Science}},
	url = {http://arxiv.org/abs/2310.03193},
	abstract = {In recent years, funding agencies and journals increasingly advocate for open science practices (e.g. data and method sharing) to improve the transparency, access, and reproducibility of science. However, quantifying these practices at scale has proven difficult. In this work, we leverage a large-scale dataset of 1.1M papers from arXiv that are representative of the fields of physics, math, and computer science to analyze the adoption of data and method link-sharing practices over time and their impact on article reception. To identify links to data and methods, we train a neural text classification model to automatically classify URL types based on contextual mentions in papers. We find evidence that the practice of link-sharing to methods and data is spreading as more papers include such URLs over time. Reproducibility efforts may also be spreading because the same links are being increasingly reused across papers (especially in computer science); and these links are increasingly concentrated within fewer web domains (e.g. Github) over time. Lastly, articles that share data and method links receive increased recognition in terms of citation count, with a stronger effect when the shared links are active (rather than defunct). Together, these findings demonstrate the increased spread and perceived value of data and method sharing practices in open science.},
	urldate = {2024-11-05},
	publisher = {arXiv},
	author = {Cao, Hancheng and Dodge, Jesse and Lo, Kyle and McFarland, Daniel A. and Wang, Lucy Lu},
	month = oct,
	year = {2023},
	
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Digital Libraries, Physics - History and Philosophy of Physics, Physics - Physics and Society},

}

@article{chawinga_global_2019,
	title = {Global perspectives of research data sharing: {A} systematic literature review},
	volume = {41},
	issn = {0740-8188},
	shorttitle = {Global perspectives of research data sharing},
	url = {https://www.sciencedirect.com/science/article/pii/S074081881830330X},
	doi = {10.1016/j.lisr.2019.04.004},
	
	language = {en},
	number = {2},
	urldate = {2023-05-15},
	journal = {Library \& Information Science Research},
	author = {Chawinga, Winner Dominic and Zinn, Sandy},
	month = apr,
	year = {2019},
	pages = {109--122},
	
}

@misc{china____policy,
	title = {Notification by the General Office of the State Council on the issuance of scientific data management practices.},
	url = {https://www.gov.cn/zhengce/content/2018-04/02/content_5279272.htm},
	author = {{General Office of the State Council of the People's Republic of China}},
    year = {2018}
}

@article{cousijn_data_2018,
	title = {A data citation roadmap for scientific publishers},
	volume = {5},
	copyright = {2018 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata2018259},
	doi = {10.1038/sdata.2018.259},
	abstract = {This article presents a practical roadmap for scholarly publishers to implement data citation in accordance with the Joint Declaration of Data Citation Principles (JDDCP), a synopsis and harmonization of the recommendations of major science policy bodies. It was developed by the Publishers Early Adopters Expert Group as part of the Data Citation Implementation Pilot (DCIP) project, an initiative of FORCE11.org and the NIH BioCADDIE program. The structure of the roadmap presented here follows the “life of a paper” workflow and includes the categories Pre-submission, Submission, Production, and Publication. The roadmap is intended to be publisher-agnostic so that all publishers can use this as a starting point when implementing JDDCP-compliant data citation. Authors reading this roadmap will also better know what to expect from publishers and how to enable their own data citations to gain maximum impact, as well as complying with what will become increasingly common funder mandates on data transparency.},
	language = {en},
	number = {1},
	urldate = {2024-08-26},
	journal = {Scientific Data},
	author = {Cousijn, Helena and Kenall, Amye and Ganley, Emma and Harrison, Melissa and Kernohan, David and Lemberger, Thomas and Murphy, Fiona and Polischuk, Patrick and Taylor, Simone and Martone, Maryann and Clark, Tim},
	month = nov,
	year = {2018},
	keywords = {Publishing, Research data, Data publication and archiving},
	pages = {180259},

}

@article{danchev_evaluation_2021,
	title = {Evaluation of {Data} {Sharing} {After} {Implementation} of the {International} {Committee} of {Medical} {Journal} {Editors} {Data} {Sharing} {Statement} {Requirement}},
	volume = {4},
	issn = {2574-3805},
	url = {https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2775667},
	doi = {10.1001/jamanetworkopen.2020.33972},
	abstract = {The benefits of responsible sharing of individual-participant data (IPD) from clinical studies are well recognized, but stakeholders often disagree on how to align those benefits with privacy risks, costs, and incentives for clinical trialists and sponsors. The International Committee of Medical Journal Editors (ICMJE) required a data sharing statement (DSS) from submissions reporting clinical trials effective July 1, 2018. The required DSSs provide a window into current data sharing rates, practices, and norms among trialists and sponsors.To evaluate the implementation of the ICMJE DSS requirement in 3 leading medical journals: JAMA, Lancet, and New England Journal of Medicine (NEJM).This is a cross-sectional study of clinical trial reports published as articles in JAMA, Lancet, and NEJM between July 1, 2018, and April 4, 2020. Articles not eligible for DSS, including observational studies and letters or correspondence, were excluded. A MEDLINE/PubMed search identified 487 eligible clinical trials in JAMA (112 trials), Lancet (147 trials), and NEJM (228 trials). Two reviewers evaluated each of the 487 articles independently.Publication of clinical trial reports in an ICMJE medical journal requiring a DSS.The primary outcomes of the study were declared data availability and actual data availability in repositories. Other captured outcomes were data type, access, and conditions and reasons for data availability or unavailability. Associations with funding sources were examined.A total of 334 of 487 articles (68.6\%; 95\% CI, 64\%-73\%) declared data sharing, with nonindustry NIH-funded trials exhibiting the highest rates of declared data sharing (89\%; 95\% CI, 80\%-98\%) and industry-funded trials the lowest (61\%; 95\% CI, 54\%-68\%). However, only 2 IPD sets (0.6\%; 95\% CI, 0.0\%-1.5\%) were actually deidentified and publicly available as of April 10, 2020. The remaining were supposedly accessible via request to authors (143 of 334 articles [42.8\%]), repository (89 of 334 articles [26.6\%]), and company (78 of 334 articles [23.4\%]). Among the 89 articles declaring that IPD would be stored in repositories, only 17 (19.1\%) deposited data, mostly because of embargo and regulatory approval. Embargo was set in 47.3\% of data-sharing articles (158 of 334), and in half of them the period exceeded 1 year or was unspecified.Most trials published in JAMA, Lancet, and NEJM after the implementation of the ICMJE policy declared their intent to make clinical data available. However, a wide gap between declared and actual data sharing exists. To improve transparency and data reuse, journals should promote the use of unique pointers to data set location and standardized choices for embargo periods and access requirements.},
	language = {en},
	number = {1},
	urldate = {2024-11-05},
	journal = {JAMA Network Open},
	author = {Danchev, Valentin and Min, Yan and Borghi, John and Baiocchi, Mike and Ioannidis, John P. A.},
	month = jan,
	year = {2021},
	
	pages = {e2033972},

}

@book{eu_openscience,
author = {European Commission and Directorate-General for Research and Innovation},
title = {Horizon Europe, open science : early knowledge and data sharing, and open collaboration},
publisher = {Publications Office of the European Union},
year = {2021},
doi = {doi/10.2777/18252}}

@article{gajbe_evaluation_2021,
	title = {Evaluation and analysis of {Data} {Management} {Plan} tools: {A} parametric approach},
	volume = {58},
	issn = {0306-4573},
	shorttitle = {Evaluation and analysis of {Data} {Management} {Plan} tools},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306457320309699},
	doi = {10.1016/j.ipm.2020.102480},
	abstract = {This paper explores the openly available DMP tools and forms a comparative analysis aimed at assisting researchers and data managers to formulate effective data management plans. Based on a literature review 14 DMP tools were selected and were evaluated using 45 selected parameters. The study enlists and enunciates the features of DMP tools, spots several gaps in DMP practices, and provides a few recommendations that can improve the existing tools and DMP practices. Compared to other related works, present work sheds extra light on percentage coverage of parameters by each tool and percentage coverage of tools by each parameter. It is identified that selected tools cover 50\%–84\% parameters, whereas 78\% parameters are covered by half the selected DMP tools. Moreover, 28\% of the tools cover 60\% of the DMP assisting parameters. Additionally, co-occurrence of parameters and correlation among the tools are illustrated using matrices. It was found that co-occurrence of data description/summary/collection, documentation and metadata, findability, and accessibility parameters are relatively higher and all the selected tools are positively correlated to each other. The study is impactful for the researchers, librarians, data managers, and funding agencies for selecting an appropriate DMP tool as per their requirement.},
	language = {en},
	number = {3},
	urldate = {2024-11-05},
	journal = {Information Processing \& Management},
	author = {Gajbe, Sagar Bhimrao and Tiwari, Amit and {Gopalji} and Singh, Ranjeet Kumar},
	month = may,
	year = {2021},
	keywords = {Data Life Cycle, Data Management Plan, Data Management Plan tools, Research Data Management},
	pages = {102480},

}

@article{gopal2018adherence,
  title={Adherence to the International Committee of Medical Journal Editors’(ICMJE) prospective registration policy and implications for outcome integrity: a cross-sectional analysis of trials published in high-impact specialty society journals},
  author={Gopal, Anand D and Wallach, Joshua D and Aminawung, Jenerius A and Gonsalves, Gregg and Dal-R{\'e}, Rafael and Miller, Jennifer E and Ross, Joseph S},
  journal={Trials},
  volume={19},
  pages={1--13},
  year={2018},
  publisher={Springer}
}

@article{gorgolewski2016practical,
  title={A practical guide for improving transparency and reproducibility in neuroimaging research},
  author={Gorgolewski, Krzysztof J and Poldrack, Russell A},
  journal={PLoS biology},
  volume={14},
  number={7},
  pages={e1002506},
  year={2016},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{helbig_supporting_2015,
	title = {Supporting {Data} {Citation}: {Experiences} and {Best} {Practices} of a {DOI} {Allocation} {Agency} for {Social} {Sciences}},
	volume = {3},
	issn = {2162-3309},
	shorttitle = {Supporting {Data} {Citation}},
	url = {https://jlsc-pub.org/article/10.7710/2162-3309.1220/},
	doi = {10.7710/2162-3309.1220},
	abstract = {INTRODUCTION As more and more research data becomes better and more easily available, data citation gains in importance. The management of research data has been high on the agenda in academia for more than five years. Nevertheless, not all data policies include data citation, and problems like versioning and granularity remain. SERVICE DESCRIPTION da{\textbar}ra operates as an allocation agency for DataCite and offers the registration service for social and economic research data in Germany. The service is jointly run by GESIS and ZBW, thereby merging experiences on the fields of Social Sciences and Economics. The authors answer questions pertaining to the most frequent aspects of research data registration like versioning and granularity as well as recommend the use of persistent identifiers linked with enriched metadata at the landing page. NEXT STEPS The promotion of data sharing and the development of a citation culture among the scientific community are future challenges. Interoperability becomes increasingly important for publishers and infrastructure providers. The already existent heterogeneity of services demands solutions for better user guidance. Building information competence is an asset of libraries, which can and should be expanded to research data.},
	language = {en},
	number = {2},
	urldate = {2024-11-05},
	journal = {Journal of Librarianship and Scholarly Communication},
	author = {Helbig, Kerstin and Hausstein, Brigitte and Toepfer, Ralf},
	month = sep,
	year = {2015},
	
	pages = {1220},

}

@article{hossain2016state,
  title={State-of-the-art in open data research: Insights from existing literature and a research agenda},
  author={Hossain, Mohammad Alamgir and Dwivedi, Yogesh K and Rana, Nripendra P},
  journal={Journal of organizational computing and electronic commerce},
  volume={26},
  number={1-2},
  pages={14--40},
  year={2016},
  publisher={Taylor \& Francis}
}

@article{huang2024open,
  title={Open access research outputs receive more diverse citations},
  author={Huang, Chun-Kai and Neylon, Cameron and Montgomery, Lucy and Hosking, Richard and Diprose, James P and Handcock, Rebecca N and Wilson, Katie},
  journal={Scientometrics},
  volume={129},
  number={2},
  pages={825--845},
  year={2024},
  publisher={Springer}
}

@article{jiao_data_2024,
	title = {Data sharing practices across knowledge domains: {A} dynamic examination of data availability statements in {PLOS} {ONE} publications},
	volume = {50},
	issn = {0165-5515},
	shorttitle = {Data sharing practices across knowledge domains},
	url = {https://doi.org/10.1177/01655515221101830},
	doi = {10.1177/01655515221101830},
	abstract = {As the importance of research data gradually grows in sciences, data sharing has come to be encouraged and even mandated by journals and funders in recent years. Following this trend, the data availability statement has been increasingly embraced by academic communities as a means of sharing research data as part of research articles. This article presents a quantitative study of which mechanisms and repositories are used to share research data in PLOS ONE articles. We offer a dynamic examination of this topic from the disciplinary and temporal perspectives based on all statements in English-language research articles published between 2014 and 2020 in the journal. We find a slow yet steady growth in the use of data repositories to share data over time, as opposed to sharing data in the article and/or supplementary materials; this indicates improved compliance with the journal’s data sharing policies. We also find that multidisciplinary data repositories have been increasingly used over time, whereas some disciplinary repositories show a decreasing trend. Our findings can help academic publishers and funders to improve their data sharing policies and serve as an important baseline dataset for future studies on data sharing activities.},
	language = {en},
	number = {3},
	urldate = {2024-08-26},
	journal = {Journal of Information Science},
	author = {Jiao, Chenyue and Li, Kai and Fang, Zhichao},
	month = jun,
	year = {2024},
	
	pages = {673--689},

}

@article{kafkas_database_2015,
	title = {Database citation in supplementary data linked to {Europe} {PubMed} {Central} full text biomedical articles},
	volume = {6},
	issn = {2041-1480},
	url = {http://www.jbiomedsem.com/content/6/1/1},
	doi = {10.1186/2041-1480-6-1},
	abstract = {In this study, we present an analysis of data citation practices in full text research articles and their corresponding supplementary data files, made available in the Open Access set of articles from Europe PubMed Central. Our aim is to investigate whether supplementary data files should be considered as a source of information for integrating the literature with biomolecular databases.},
	language = {en},
	number = {1},
	urldate = {2024-11-05},
	journal = {Journal of Biomedical Semantics},
	author = {Kafkas, Senay and Kim, Jee-Hyub and Pi, Xingjun and McEntyre, Johanna R.},
	year = {2015},
	
	keywords = {Accession number, Molecular biology databases, Supplementary data, Text mining},
	pages = {1},

}

@article{khan_measuring_2021,
	title = {Measuring the impact of biodiversity datasets: data reuse, citations and altmetrics},
	volume = {126},
	issn = {0138-9130},
	shorttitle = {Measuring the impact of biodiversity datasets},
	url = {https://link.springer.com/10.1007/s11192-021-03890-6},
	doi = {10.1007/s11192-021-03890-6},
	abstract = {Despite growing evidence of open biodiversity data reuse by scientists, information about how data is reused and cited is rarely openly accessible from research data repositories. This study explores data citation and reuse practices in biodiversity by using openly available metadata for 43,802 datasets indexed in the Global Biodiversity Information Facility (GBIF) and content analyses of articles citing GBIF data. Results from quantitative and content analyses suggest that even though the number of studies making use of openly available biodiversity data has been increasing steadily, best practice for data citation is not yet common. It is encouraging, however, that an increasing number of recent articles (16 out of 23 in 2019) in biodiversity cite datasets in a standard way. A content analysis of a random sample of unique citing articles (n = 100) found various types of background (n = 18) and foreground (n = 81) reuse cases for GBIF data, ranging from combining with other data sources to create species distribution modelling to software testing. This demonstrates some unique research opportunities created by open data. Among the citing articles, 27\% mentioned the dataset in references and 13\% in data access statements in addition to the methods section. Citation practice was inconsistent especially when a large number of subsets (12 {\textasciitilde} 50) were used. Even though many GBIF dataset records had altmetric scores, most posts only mentioned the articles linked to those datasets. Among the altmetric mentions of datasets, blogs can be the most informative, even though rare, and most tweets and Facebook posts were for promotional purposes.},
	language = {en},
	number = {4},
	urldate = {2024-11-05},
	journal = {Scientometrics},
	author = {Khan, Nushrat and Thelwall, Mike and Kousha, Kayvan},
	month = feb,
	year = {2021},
	
	keywords = {Altmetrics, Citation analysis, Citation practice, Data reuse, Open biodiversity data},
	pages = {3621--3639},

}

@book{los_riding_2010,
	title = {Riding the wave {How} {Europe} can gain from the rising tide of scientific data {Final} report of the {High} {Level} {Expert} {Group} on {Scientific} {Data} {A} submission to the {European} {Commission}},
    publisher={European Union},
	abstract = {The report of a high-level advisory group is presenting its view on the future of scientific data and of an emerging data infrastructure.},
	author = {Los, Wouter},
	month = jan,
	year = {2010},
	
}

@article{markiewicz_openneuro_2021,
	title = {The {OpenNeuro} resource for sharing of neuroscience data},
	volume = {10},
	issn = {2050-084X},
	url = {https://elifesciences.org/articles/71774},
	doi = {10.7554/eLife.71774},
	abstract = {The sharing of research data is essential to ensure reproducibility and maximize the impact of public investments in scientific research. Here, we describe OpenNeuro, a BRAIN Initiative data archive that provides the ability to openly share data from a broad range of brain imaging data types following the FAIR principles for data sharing. We highlight the importance of the Brain Imaging Data Structure standard for enabling effective curation, sharing, and reuse of data. The archive presently shares more than 600 datasets including data from more than 20,000 participants, comprising multiple species and measurement modalities and a broad range of phenotypes. The impact of the shared data is evident in a growing number of published reuses, currently totalling more than 150 publications. We conclude by describing plans for future development and integration with other ongoing open science efforts.},
	language = {en},
	urldate = {2024-11-05},
	journal = {eLife},
	author = {Markiewicz, Christopher J and Gorgolewski, Krzysztof J and Feingold, Franklin and Blair, Ross and Halchenko, Yaroslav O and Miller, Eric and Hardcastle, Nell and Wexler, Joe and Esteban, Oscar and Goncavles, Mathias and Jwa, Anita and Poldrack, Russell},
	editor = {Kahnt, Thorsten and Baker, Chris I and Dosenbach, Nico and Hawrylycz, Michael J and Svoboda, Karel},
	month = oct,
	year = {2021},
	
	keywords = {data sharing, EEG, MEG, MRI, neuroimaging, open science},
	pages = {e71774},

}

@article{mckiernan_how_2016,
	title = {How open science helps researchers succeed},
	volume = {5},
	issn = {2050-084X},
	url = {https://elifesciences.org/articles/16800},
	doi = {10.7554/eLife.16800},
	abstract = {Open access, open data, open source and other open scholarship practices are growing in popularity and necessity. However, widespread adoption of these practices has not yet been achieved. One reason is that researchers are uncertain about how sharing their work will affect their careers. We review literature demonstrating that open research is associated with increases in citations, media attention, potential collaborators, job opportunities and funding opportunities. These findings are evidence that open research practices bring significant benefits to researchers relative to more traditional closed practices.},
	language = {en},
	urldate = {2024-11-04},
	journal = {eLife},
	author = {McKiernan, Erin C and Bourne, Philip E and Brown, C Titus and Buck, Stuart and Kenall, Amye and Lin, Jennifer and McDougall, Damon and Nosek, Brian A and Ram, Karthik and Soderberg, Courtney K and Spies, Jeffrey R and Thaney, Kaitlin and Updegrove, Andrew and Woo, Kara H and Yarkoni, Tal},
	editor = {Rodgers, Peter},
	month = jul,
	year = {2016},
	
	keywords = {open access, open data, open science, open source, research},
	pages = {e16800},

}

@article{mcnaught_changing_2015,
	title = {The {Changing} {Publication} {Practices} in {Academia}: {Inherent} {Uses} and {Issues} in {Open} {Access} and {Online} {Publishing} and the {Rise} of {Fraudulent} {Publications}},
	volume = {18},
	issn = {1080-2711},
	shorttitle = {The {Changing} {Publication} {Practices} in {Academia}},
	url = {http://hdl.handle.net/2027/spo.3336451.0018.308},
	doi = {10.3998/3336451.0018.308},
	abstract = {Open access and online publishing present significant changes to the Australian higher education sector in a climate demanding increasing research outputs from academic staff. Today’s researchers struggle to discern credible journals from a new wave of ‘low credibility,’ counterfeit, and predatory journals. A New York Times article on the issue resulted in hundreds of anonymous posts, having a whistleblower effect. An analysis of reader posts, examined in this paper, demonstrated that fear and cynicism were dominant, and that unscrupulous publishing practices were often rewarded. A lack of quality control measures to assist researchers to choose reputable journals and avoid fraudulent ones is becoming evident as universities’ funding and workforce development become increasingly dependent on research outputs. Online publishing is also redefining traditional notions of academic prestige. Adapting to the twenty-first century online publishing landscape requires the higher education sector to meet these challenges with a combination of academic rigour and innovative tools that support researchers, so as to maintain quality and integrity within changing academic publishing practice.},
	language = {en},
	number = {3},
	urldate = {2024-11-05},
	journal = {The Journal of Electronic Publishing},
	author = {McNaught, Keith},
	month = jun,
	year = {2015},
	

}

@article{milham_assessment_2018,
	title = {Assessment of the impact of shared brain imaging data on the scientific literature},
	volume = {9},
	copyright = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-018-04976-1},
	doi = {10.1038/s41467-018-04976-1},
	abstract = {Data sharing is increasingly recommended as a means of accelerating science by facilitating collaboration, transparency, and reproducibility. While few oppose data sharing philosophically, a range of barriers deter most researchers from implementing it in practice. To justify the significant effort required for sharing data, funding agencies, institutions, and investigators need clear evidence of benefit. Here, using the International Neuroimaging Data-sharing Initiative, we present a case study that provides direct evidence of the impact of open sharing on brain imaging data use and resulting peer-reviewed publications. We demonstrate that openly shared data can increase the scale of scientific studies conducted by data contributors, and can recruit scientists from a broader range of disciplines. These findings dispel the myth that scientific findings using shared data cannot be published in high-impact journals, suggest the transformative power of data sharing for accelerating science, and underscore the need for implementing data sharing universally.},
	language = {en},
	number = {1},
	urldate = {2024-11-05},
	journal = {Nature Communications},
	author = {Milham, Michael P. and Craddock, R. Cameron and Son, Jake J. and Fleischmann, Michael and Clucas, Jon and Xu, Helen and Koo, Bonhwang and Krishnakumar, Anirudh and Biswal, Bharat B. and Castellanos, F. Xavier and Colcombe, Stan and Di Martino, Adriana and Zuo, Xi-Nian and Klein, Arno},
	month = jul,
	year = {2018},
	
	keywords = {Cognitive neuroscience, Databases, Policy},
	pages = {2818},

}

@article{niemeyer_challenge_2016,
	title = {The {Challenge} and {Promise} of {Software} {Citation} for {Credit}, {Identification}, {Discovery}, and {Reuse}},
	volume = {7},
	issn = {1936-1955},
	url = {https://dl.acm.org/doi/10.1145/2968452},
	doi = {10.1145/2968452},
	language = {en},
	number = {4},
	urldate = {2024-11-05},
	journal = {Journal of Data and Information Quality},
	author = {Niemeyer, Kyle E. and Smith, Arfon M. and Katz, Daniel S.},
	month = oct,
	year = {2016},
	
	pages = {1--5},

}

@article{open2015estimating,
  title={Estimating the reproducibility of psychological science},
  author={Open Science Collaboration},
  journal={Science},
  volume={349},
  number={6251},
  pages={aac4716},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@article{park_examination_2017,
	title = {An examination of research data sharing and re-use: implications for data citation practice},
	volume = {111},
	issn = {1588-2861},
	shorttitle = {An examination of research data sharing and re-use},
	url = {https://doi.org/10.1007/s11192-017-2240-2},
	doi = {10.1007/s11192-017-2240-2},
	abstract = {This study examines characteristics of data sharing and data re-use in Genetics and Heredity, where data citation is most common. This study applies an exploratory method because data citation is a relatively new area. The Data Citation Index (DCI) on the Web of Science was selected because DCI provides a single access point to over 500 data repositories worldwide and to over two million data studies and datasets across multiple disciplines and monitors quality research data through a peer review process. We explore data citations for Genetics and Heredity, as a case study by examining formal citations recorded in the DCI and informally by sampling a selection of papers for implicit data citations within publications. Citer-based analysis is conducted in order to remedy self-citation in the data citation phenomena. We explore 148 sampled citing articles in order to identify factors that influence data sharing and data re-use, including references, main text, supplementary data/information, acknowledgments, funding information, author information, and web/author resources. This study is unique in that it relies on a citer-based analysis approach and by analyzing peer-reviewed and published data, data repositories, and citing articles of highly productive authors where data sharing is most prevalent. This research is intended to provide a methodological and practical contribution to the study of data citation.},
	language = {en},
	number = {1},
	urldate = {2024-08-26},
	journal = {Scientometrics},
	author = {Park, Hyoungjoo and Wolfram, Dietmar},
	month = apr,
	year = {2017},
	keywords = {Citation analysis, Research data, 62-07 data analysis, C02 mathematical methods, Citer-based analysis, Data citation, Data re-use, Data sharing},
	pages = {443--461},

}

@article{park_informal_2018,
	title = {Informal data citation for data sharing and reuse is more common than formal data citation in biomedical fields},
	volume = {69},
	copyright = {© 2018 ASIS\&T},
	issn = {2330-1643},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.24049},
	doi = {10.1002/asi.24049},
	abstract = {Data citation, where products of research such as data sets, software, and tissue cultures are shared and acknowledged, is becoming more common in the era of Open Science. Currently, the practice of formal data citation—where data references are included alongside bibliographic references in the reference section of a publication—is uncommon. We examine the prevalence of data citation, documenting data sharing and reuse, in a sample of full text articles from the biological/biomedical sciences, the fields with the most public data sets available documented by the Data Citation Index (DCI). We develop a method that combines automated text extraction with human assessment for revealing candidate occurrences of data sharing and reuse by using terms that are most likely to indicate their occurrence. The analysis reveals that informal data citation in the main text of articles is far more common than formal data citations in the references of articles. As a result, data sharers do not receive documented credit for their data contributions in a similar way as authors do for their research articles because informal data citations are not recorded in sources such as the DCI. Ongoing challenges for the study of data citation are also outlined.},
	language = {en},
	number = {11},
	urldate = {2024-08-26},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Park, Hyoungjoo and You, Sukjin and Wolfram, Dietmar},
	year = {2018},
	pages = {1346--1354},

}

@misc{peters_research_2015,
	title = {Research {Data} {Explored}: {Citations} versus {Altmetrics}},
	shorttitle = {Research {Data} {Explored}},
	url = {http://arxiv.org/abs/1501.03342},
	doi = {10.48550/arXiv.1501.03342},
	abstract = {The study explores the citedness of research data, its distribution over time and how it is related to the availability of a DOI (Digital Object Identifier) in Thomson Reuters' DCI (Data Citation Index). We investigate if cited research data "impact" the (social) web, reflected by altmetrics scores, and if there is any relationship between the number of citations and the sum of altmetrics scores from various social media-platforms. Three tools are used to collect and compare altmetrics scores, i.e. PlumX, ImpactStory, and Altmetric.com. In terms of coverage, PlumX is the most helpful altmetrics tool. While research data remain mostly uncited (about 85\%), there has been a growing trend in citing data sets published since 2007. Surprisingly, the percentage of the number of cited research data with a DOI in DCI has decreased in the last years. Only nine repositories account for research data with DOIs and two or more citations. The number of cited research data with altmetrics scores is even lower (4 to 9\%) but shows a higher coverage of research data from the last decade. However, no correlation between the number of citations and the total number of altmetrics scores is observable. Certain data types (i.e. survey, aggregate data, and sequence data) are more often cited and receive higher altmetrics scores.},
	urldate = {2024-11-05},
	publisher = {arXiv},
	author = {Peters, Isabella and Kraker, Peter and Lex, Elisabeth and Gumpenberger, Christian and Gorraiz, Juan},
	month = apr,
	year = {2015},
	
	keywords = {Computer Science - Digital Libraries},

}

@article{piwowar_beginning_2011,
	title = {Beginning to track 1000 datasets from public repositories into the published literature},
	volume = {48},
	copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
	issn = {0044-7870},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/meet.2011.14504801337},
	doi = {10.1002/meet.2011.14504801337},
	abstract = {Data sharing provides many potential benefits, although the amount of actual data reused is unknown. Here we track the reuse of data from three data repositories (NCBI’s Gene Expression Omnibus, PANGAEA, and TreeBASE) by searching for dataset accession number or unique identifier in Google Scholar and using ISI Web of Science to find articles that cited the data collection article. We found that data reuse and data attribution patterns vary across repositories. Data reuse appears to correlate with the number of citations to the data collection article. This preliminary investigation has demonstrated the feasibility of this method for tracking data reuse.},
	language = {en},
	number = {1},
	urldate = {2024-11-05},
	journal = {Proceedings of the American Society for Information Science and Technology},
	author = {Piwowar, Heather A. and Carlson, Jonathan D. and Vision, Todd J.},
	year = {2011},
	
	pages = {1--4},

}

@article{piwowar_data_2013,
	title = {Data reuse and the open data citation advantage},
	volume = {1},
	issn = {2167-8359},
	url = {https://peerj.com/articles/175},
	doi = {10.7717/peerj.175},
	abstract = {Background. Attribution to the original contributor upon reuse of published data is important both as a reward for data creators and to document the provenance of research findings. Previous studies have found that papers with publicly available datasets receive a higher number of citations than similar studies without available data. However, few previous analyses have had the statistical power to control for the many variables known to predict citation rate, which has led to uncertain estimates of the “citation benefit”. Furthermore, little is known about patterns in data reuse over time and across datasets. Method and Results. Here, we look at citation rates while controlling for many known citation predictors and investigate the variability of data reuse. In a multivariate regression on 10,555 studies that created gene expression microarray data, we found that studies that made data available in a public repository received 9\% (95\% confidence interval: 5\% to 13\%) more citations than similar studies for which the data was not made available. Date of publication, journal impact factor, open access status, number of authors, first and last author publication history, corresponding author country, institution citation history, and study topic were included as covariates. The citation benefit varied with date of dataset deposition: a citation benefit was most clear for papers published in 2004 and 2005, at about 30\%. Authors published most papers using their own datasets within two years of their first publication on the dataset, whereas data reuse papers published by third-party investigators continued to accumulate for at least six years. To study patterns of data reuse directly, we compiled 9,724 instances of third party data reuse via mention of GEO or ArrayExpress accession numbers in the full text of papers. The level of third-party data use was high: for 100 datasets deposited in year 0, we estimated that 40 papers in PubMed reused a dataset by year 2, 100 by year 4, and more than 150 data reuse papers had been published by year 5. Data reuse was distributed across a broad base of datasets: a very conservative estimate found that 20\% of the datasets deposited between 2003 and 2007 had been reused at least once by third parties. Conclusion. After accounting for other factors affecting citation rate, we find a robust citation benefit from open data, although a smaller one than previously reported. We conclude there is a direct effect of third-party data reuse that persists for years beyond the time when researchers have published most of the papers reusing their own data. Other factors that may also contribute to the citation benefit are considered. We further conclude that, at least for gene expression microarray data, a substantial fraction of archived datasets are reused, and that the intensity of dataset reuse has been steadily increasing since 2003.},
	language = {en},
	urldate = {2024-08-26},
	journal = {PeerJ},
	author = {Piwowar, Heather A. and Vision, Todd J.},
	month = oct,
	year = {2013},
	
	pages = {e175},

}

@article{piwowar_sharing_2007,
	title = {Sharing {Detailed} {Research} {Data} {Is} {Associated} with {Increased} {Citation} {Rate}},
	volume = {2},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0000308},
	doi = {10.1371/journal.pone.0000308},
	abstract = {BackgroundSharing research data provides benefit to the general scientific community, but the benefit is less obvious for the investigator who makes his or her data available.Principal FindingsWe examined the citation history of 85 cancer microarray clinical trial publications with respect to the availability of their data. The 48\% of trials with publicly available microarray data received 85\% of the aggregate citations. Publicly available data was significantly (p = 0.006) associated with a 69\% increase in citations, independently of journal impact factor, date of publication, and author country of origin using linear regression.SignificanceThis correlation between publicly available data and increased literature impact may further motivate investigators to share their detailed research data.},
	language = {en},
	number = {3},
	urldate = {2024-11-05},
	journal = {PLOS ONE},
	author = {Piwowar, Heather A. and Day, Roger S. and Fridsma, Douglas B.},
	month = mar,
	year = {2007},
	
	keywords = {Bibliometrics, Cancers and neoplasms, Citation analysis, Clinical trials (cancer treatment), Linear regression analysis, Microarrays, Open data, Scientific publishing},
	pages = {e308},

}

@misc{plos_policy,
  author       = {{PLOS One}},
  title        = {PLOS One Data availability},
  month        = dec,
  year         = 2019,
  publisher    = {PLOS One},
  url          = {https://journals.plos.org/plosone/s/data-availability}
}

@article{robinson-garcia_analyzing_2016,
	title = {Analyzing data citation practices using the data citation index},
	volume = {67},
	copyright = {© 2015 ASIS\&T},
	issn = {2330-1643},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.23529},
	doi = {10.1002/asi.23529},
	abstract = {We present an analysis of data citation practices based on the Data Citation Index (DCI) (Thomson Reuters). This database launched in 2012 links data sets and data studies with citations received from the other citation indexes. The DCI harvests citations to research data from papers indexed in the Web of Science. It relies on the information provided by the data repository. The findings of this study show that data citation practices are far from common in most research fields. Some differences have been reported on the way researchers cite data: Although in the areas of science and engineering \& technology data sets were the most cited, in the social sciences and arts \& humanities data studies play a greater role. A total of 88.1\% of the records have received no citation, but some repositories show very low uncitedness rates. Although data citation practices are rare in most fields, they have expanded in disciplines such as crystallography and genomics. We conclude by emphasizing the role that the DCI could play in encouraging the consistent, standardized citation of research data—a role that would enhance their value as a means of following the research process from data collection to publication.},
	language = {en},
	number = {12},
	urldate = {2024-08-26},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Robinson-García, Nicolas and Jiménez-Contreras, Evaristo and Torres-Salinas, Daniel},
	year = {2016},
	
	keywords = {scientometrics},
	pages = {2964--2975},

}

@article{robson2021promoting,
  title={Promoting open science: a holistic approach to changing behaviour},
  author={Robson, Samuel G and Baum, Myriam A and Beaudry, Jennifer L and Beitner, Julia and Brohmer, Hilmar and Chin, Jason M and Jasko, Katarzyna and Kouros, Chrystyna D and Laukkonen, Ruben E and Moreau, David and others},
  journal={Collabra: Psychology},
  volume={7},
  number={1},
  pages={30137},
  year={2021},
  publisher={University of California Press}
}

@article{schultz2021all,
  title={All the research that’s fit to print: Open access and the news media},
  author={Schultz, Teresa},
  journal={Quantitative Science Studies},
  volume={2},
  number={3},
  pages={828--844},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{shahin2020open,
  title={Open data revolution in clinical research: opportunities and challenges},
  author={Shahin, Mohamed H and Bhattacharya, Sanchita and Silva, Diego and Kim, Sarah and Burton, Jackson and Podichetty, Jagdeep and Romero, Klaus and Conrado, Daniela J},
  journal={Clinical and Translational Science},
  volume={13},
  number={4},
  pages={665--674},
  year={2020},
  publisher={Wiley Online Library}
}

@article{silvello_theory_2017,
	title = {Theory and practice of data citation},
	volume = {69},
	copyright = {© 2017 ASIS\&T},
	issn = {2330-1635},
	url = {https://asistdl.onlinelibrary.wiley.com/doi/10.1002/asi.23917},
	doi = {10.1002/asi.23917},
	abstract = {Citations are the cornerstone of knowledge propagation and the primary means of assessing the quality of research, as well as directing investments in science. Science is increasingly becoming “data‐intensive,” where large volumes of data are collected and analyzed to discover complex patterns through simulations and experiments, and most scientific reference works have been replaced by online curated data sets. Yet, given a data set, there is no quantitative, consistent, and established way of knowing how it has been used over time, who contributed to its curation, what results have been yielded, or what value it has. The development of a theory and practice of data citation is fundamental for considering data as first‐class research objects with the same relevance and centrality of traditional scientific products. Many works in recent years have discussed data citation from different viewpoints: illustrating why data citation is needed, defining the principles and outlining recommendations for data citation systems, and providing computational methods for addressing specific issues of data citation. The current panorama is many‐faceted and an overall view that brings together diverse aspects of this topic is still missing. Therefore, this paper aims to describe the lay of the land for data citation, both from the theoretical (the why and what) and the practical (the how) angle.},
	language = {en},
	number = {1},
	urldate = {2024-11-04},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Silvello, Gianmaria},
	month = sep,
	year = {2017},
	pages = {6--20},

}

@inproceedings{smith2012institutional,
  title={Institutional perspectives on credit systems for research data},
  author={Smith, Mackenzie},
  booktitle={For attribution: Developing scientific data attribution and citation practices and standards: Summary of an international workshop},
  pages={77--80},
  year={2012}
}

@inproceedings{spengler2012data,
  title={Data citation and attribution: A funder’s perspective},
  author={Spengler, S},
  booktitle={For attribution: Developing scientific data attribution and citation practices and standards: Summary of an international workshop},
  pages={177--188},
  year={2012}
}

@article{stodden_empirical_2018,
	title = {An empirical analysis of journal policy effectiveness for computational reproducibility},
	volume = {115},
	issn = {0027-8424},
	url = {https://pnas.org/doi/full/10.1073/pnas.1708290115},
	doi = {10.1073/pnas.1708290115},
	abstract = {A key component of scientific communication is sufficient information for other researchers in the field to reproduce published findings. For computational and data-enabled research, this has often been interpreted to mean making available the raw data from which results were generated, the computer code that generated the findings, and any additional information needed such as workflows and input parameters. Many journals are revising author guidelines to include data and code availability. This work evaluates the effectiveness of journal policy that requires the data and code necessary for reproducibility be made available postpublication by the authors upon request. We assess the effectiveness of such a policy by (i) requesting data and code from authors and (ii) attempting replication of the published findings. We chose a random sample of 204 scientific papers published in the journal Science after the implementation of their policy in February 2011. We found that we were able to obtain artifacts from 44\% of our sample and were able to reproduce the findings for 26\%. We find this policy—author remission of data and code postpublication upon request—an improvement over no policy, but currently insufficient for reproducibility.},
	language = {en},
	number = {11},
	urldate = {2024-11-05},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Stodden, Victoria and Seiler, Jennifer and Ma, Zhaokun},
	month = mar,
	year = {2018},
	
	pages = {2584--2589},

}

@article{strcic_open_2022,
	title = {Open data and data sharing in articles about {COVID}-19 published in preprint servers {medRxiv} and {bioRxiv}},
	volume = {127},
	issn = {0138-9130},
	url = {https://link.springer.com/10.1007/s11192-022-04346-1},
	doi = {10.1007/s11192-022-04346-1},
	abstract = {This study aimed to analyze the content of data availability statements (DAS) and the actual sharing of raw data in preprint articles about COVID-19. The study combined a bibliometric analysis and a cross-sectional survey. We analyzed preprint articles on COVID-19 published on medRxiv and bioRxiv from January 1, 2020 to March 30, 2020. We extracted data sharing statements, tried to locate raw data when authors indicated they were available, and surveyed authors. The authors were surveyed in 2020–2021. We surveyed authors whose articles did not include DAS, who indicated that data are available on request, or their manuscript reported that raw data are available in the manuscript, but raw data were not found. Raw data collected in this study are published on Open Science Framework (https://osf.io/6ztec/). We analyzed 897 preprint articles. There were 699 (78\%) articles with Data/Code field present on the website of a preprint server. In 234 (26\%) preprints, data/code sharing statement was reported within the manuscript. For 283 preprints that reported that data were accessible, we found raw data/code for 133 (47\%) of those 283 preprints (15\% of all analyzed preprint articles). Most commonly, authors indicated that data were available on GitHub or another clearly specified web location, on (reasonable) request, in the manuscript or its supplementary files. In conclusion, preprint servers should require authors to provide data sharing statements that will be included both on the website and in the manuscript. Education of researchers about the meaning of data sharing is needed.},
	language = {en},
	number = {5},
	urldate = {2024-11-05},
	journal = {Scientometrics},
	author = {Strcic, Josip and Civljak, Antonia and Glozinic, Terezija and Pacheco, Rafael Leite and Brkovic, Tonci and Puljak, Livia},
	month = mar,
	year = {2022},
	
	keywords = {Coronavirus, COVID-19, Data sharing, Open data, Preprint server, SARS-CoV-2},
	pages = {2791--2802},

}

@article{tedersoo_data_2021,
	title = {Data sharing practices and data availability upon request differ across scientific disciplines},
	volume = {8},
	copyright = {2021 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-021-00981-0},
	doi = {10.1038/s41597-021-00981-0},
	language = {en},
	number = {1},
	urldate = {2023-05-15},
	journal = {Scientific Data},
	author = {Tedersoo, Leho and Küngas, Rainer and Oras, Ester and Köster, Kajar and Eenmaa, Helen and Leijen, Äli and Pedaste, Margus and Raju, Marju and Astapova, Anastasiya and Lukner, Heli and Kogermann, Karin and Sepp, Tuul},
	month = jul,
	year = {2021},
	
	keywords = {Genetic databases, Molecular ecology},
	pages = {192},
}

@article{tenopir_changes_2015,
	title = {Changes in {Data} {Sharing} and {Data} {Reuse} {Practices} and {Perceptions} among {Scientists} {Worldwide}},
	volume = {10},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0134826},
	doi = {10.1371/journal.pone.0134826},
	abstract = {The incorporation of data sharing into the research lifecycle is an important part of modern scholarly debate. In this study, the DataONE Usability and Assessment working group addresses two primary goals: To examine the current state of data sharing and reuse perceptions and practices among research scientists as they compare to the 2009/2010 baseline study, and to examine differences in practices and perceptions across age groups, geographic regions, and subject disciplines. We distributed surveys to a multinational sample of scientific researchers at two different time periods (October 2009 to July 2010 and October 2013 to March 2014) to observe current states of data sharing and to see what, if any, changes have occurred in the past 3–4 years. We also looked at differences across age, geographic, and discipline-based groups as they currently exist in the 2013/2014 survey. Results point to increased acceptance of and willingness to engage in data sharing, as well as an increase in actual data sharing behaviors. However, there is also increased perceived risk associated with data sharing, and specific barriers to data sharing persist. There are also differences across age groups, with younger respondents feeling more favorably toward data sharing and reuse, yet making less of their data available than older respondents. Geographic differences exist as well, which can in part be understood in terms of collectivist and individualist cultural differences. An examination of subject disciplines shows that the constraints and enablers of data sharing and reuse manifest differently across disciplines. Implications of these findings include the continued need to build infrastructure that promotes data sharing while recognizing the needs of different research communities. Moving into the future, organizations such as DataONE will continue to assess, monitor, educate, and provide the infrastructure necessary to support such complex grand science challenges.},
	language = {en},
	number = {8},
	urldate = {2024-11-05},
	journal = {PLOS ONE},
	author = {Tenopir, Carol and Dalton, Elizabeth D. and Allard, Suzie and Frame, Mike and Pjesivac, Ivanka and Birch, Ben and Pollock, Danielle and Dorsett, Kristina},
	month = aug,
	year = {2015},
	
	keywords = {Age groups, Chi square tests, Data management, Ecology and environmental sciences, Metadata, Regional geography, Scientists, Surveys},
	pages = {e0134826},

}

@article{tenopir_data_2011,
	title = {Data {Sharing} by {Scientists}: {Practices} and {Perceptions}},
	volume = {6},
	issn = {1932-6203},
	shorttitle = {Data {Sharing} by {Scientists}},
	url = {https://dx.plos.org/10.1371/journal.pone.0021101},
	doi = {10.1371/journal.pone.0021101},
	abstract = {Background Scientific research in the 21st century is more data intensive and collaborative than in the past. It is important to study the data practices of researchers – data accessibility, discovery, re-use, preservation and, particularly, data sharing. Data sharing is a valuable part of the scientific method allowing for verification of results and extending research from prior results. Methodology/Principal Findings A total of 1329 scientists participated in this survey exploring current data sharing practices and perceptions of the barriers and enablers of data sharing. Scientists do not make their data electronically available to others for various reasons, including insufficient time and lack of funding. Most respondents are satisfied with their current processes for the initial and short-term parts of the data or research lifecycle (collecting their research data; searching for, describing or cataloging, analyzing, and short-term storage of their data) but are not satisfied with long-term data preservation. Many organizations do not provide support to their researchers for data management both in the short- and long-term. If certain conditions are met (such as formal citation and sharing reprints) respondents agree they are willing to share their data. There are also significant differences and approaches in data management practices based on primary funding agency, subject discipline, age, work focus, and world region. Conclusions/Significance Barriers to effective data sharing and preservation are deeply rooted in the practices and culture of the research process as well as the researchers themselves. New mandates for data management plans from NSF and other federal agencies and world-wide attention to the need to share and preserve data could lead to changes. Large scale programs, such as the NSF-sponsored DataNET (including projects like DataONE) will both bring attention and resources to the issue and make it easier for scientists to apply sound data management principles.},
	language = {en},
	number = {6},
	urldate = {2024-11-05},
	journal = {PLOS ONE},
	author = {Tenopir, Carol and Allard, Suzie and Douglass, Kimberly and Aydinoglu, Arsev Umur and Wu, Lei and Read, Eleanor and Manoff, Maribeth and Frame, Mike},
	month = jun,
	year = {2011},
	
	keywords = {Data management, Ecology and environmental sciences, Europe, Medicine and health sciences, Metadata, Scientists, Social sciences, Surveys},
	pages = {e21101},

}

@article{tenopir_data_2020,
	title = {Data sharing, management, use, and reuse: {Practices} and perceptions of scientists worldwide},
	volume = {15},
	issn = {1932-6203},
	shorttitle = {Data sharing, management, use, and reuse},
	url = {https://dx.plos.org/10.1371/journal.pone.0229003},
	doi = {10.1371/journal.pone.0229003},
	abstract = {Background With data becoming a centerpiece of modern scientific discovery, data sharing by scientists is now a crucial element of scientific progress. This article aims to provide an in-depth examination of the practices and perceptions of data management, including data storage, data sharing, and data use and reuse by scientists around the world. Methods The Usability and Assessment Working Group of DataONE, an NSF-funded environmental cyberinfrastructure project, distributed a survey to a multinational and multidisciplinary sample of scientific researchers in a two-waves approach in 2017–2018. We focused our analysis on examining the differences across age groups, sub-disciplines of science, and sectors of employment. Findings Most respondents displayed what we describe as high and mediocre risk data practices by storing their data on their personal computer, departmental servers or USB drives. Respondents appeared to be satisfied with short-term storage solutions; however, only half of them are satisfied with available mechanisms for storing data beyond the life of the process. Data sharing and data reuse were viewed positively: over 85\% of respondents admitted they would be willing to share their data with others and said they would use data collected by others if it could be easily accessed. A vast majority of respondents felt that the lack of access to data generated by other researchers or institutions was a major impediment to progress in science at large, yet only about a half thought that it restricted their own ability to answer scientific questions. Although attitudes towards data sharing and data use and reuse are mostly positive, practice does not always support data storage, sharing, and future reuse. Assistance through data managers or data librarians, readily available data repositories for both long-term and short-term storage, and educational programs for both awareness and to help engender good data practices are clearly needed.},
	language = {en},
	number = {3},
	urldate = {2024-11-05},
	journal = {PLOS ONE},
	author = {Tenopir, Carol and Rice, Natalie M. and Allard, Suzie and Baird, Lynn and Borycz, Josh and Christian, Lisa and Grant, Bruce and Olendorf, Robert and Sandusky, Robert J.},
	month = mar,
	year = {2020},
	
	keywords = {Data management, Employment, Librarians, Metadata, Open data, Psychological attitudes, Scientists, Surveys},
	pages = {e0229003},

}

@misc{torres-salinas_how_2014,
	title = {How many citations are there in the {Data} {Citation} {Index}?},
	url = {http://arxiv.org/abs/1409.0753},
	abstract = {Descriptive analysis on the citation distribution of the Thomson Reuters' Data Citation Index by publication type and four broad areas: Science, Engineering \& Technology, Humanities \& Arts and Social Sciences.},
	urldate = {2024-11-05},
	publisher = {arXiv},
	author = {Torres-Salinas, Daniel and Jiménez-Contreras, Evaristo and Robinson-García, Nicolas},
	month = sep,
	year = {2014},
	
	keywords = {Computer Science - Digital Libraries},

}

@misc{uk_policy,
	title = {Concordat on open research data},
	url = {https://www.ukri.org/wp-content/uploads/2020/10/UKRI-020920-ConcordatonOpenResearchData.pdf},
    year = {2016},
    author = {Research Councils UK}
}

@article{walton_data_2010,
	title = {Data {Citation} - {Moving} to {New} {Norms}},
	volume = {22},
	issn = {0954-1020},
	url = {https://www.cambridge.org/core/product/identifier/S0954102010000520/type/journal_article},
	doi = {10.1017/S0954102010000520},
	abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0954102010000520/resource/name/firstPage-S0954102010000520a.jpg},
	language = {en},
	number = {4},
	urldate = {2024-11-05},
	journal = {Antarctic Science},
	author = {Walton, David W. H.},
	month = aug,
	year = {2010},
	pages = {333--333},

}

@article{woelfle2011open,
  title={Open science is a research accelerator},
  author={Woelfle, Michael and Olliaro, Piero and Todd, Matthew H},
  journal={Nature chemistry},
  volume={3},
  number={10},
  pages={745--748},
  year={2011},
  publisher={Nature Publishing Group UK London}
}

@article{yang2024open,
  title={Open access improves the dissemination of science: insights from Wikipedia},
  author={Yang, Puyu and Shoaib, Ahad and West, Robert and Colavizza, Giovanni},
  journal={Scientometrics},
  pages={1--24},
  year={2024},
  publisher={Springer}
}

@article{zhao_data_2018,
	title = {Data set mentions and citations: {A} content analysis of full-text publications},
	volume = {69},
	copyright = {© 2017 ASIS\&T},
	issn = {2330-1643},
	shorttitle = {Data set mentions and citations},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.23919},
	doi = {10.1002/asi.23919},
	abstract = {This study provides evidence of data set mentions and citations in multiple disciplines based on a content analysis of 600 publications in PLoS One. We find that data set mentions and citations varied greatly among disciplines in terms of how data sets were collected, referenced, and curated. While a majority of articles provided free access to data, formal ways of data attribution such as DOIs and data citations were used in a limited number of articles. In addition, data reuse took place in less than 30\% of the publications that used data, suggesting that researchers are still inclined to create and use their own data sets, rather than reusing previously curated data. This paper provides a comprehensive understanding of how data sets are used in science and helps institutions and publishers make useful data policies.},
	language = {en},
	number = {1},
	urldate = {2024-08-26},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Zhao, Mengnan and Yan, Erjia and Li, Kai},
	year = {2018},
	
	pages = {32--46},

}

