\documentclass{article}
\usepackage{makecell}
\usepackage{float}
\usepackage{amsmath}
\DeclareUnicodeCharacter{2606}{}
\usepackage{multirow}
\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}



\title{Research Data in Scientific Publications: A Cross-Field Analysis}

%\date{September 9, 1985}	% Here you can change the date presented in the paper title
%\date{} 					% Or removing it

\author{ Puyu Yang \\
	Institute for Logic, Language and Computation (ILLC)\\
	University of Amsterdam\\
    1098XH, Amsterdam, The Netherlands.\\
	\texttt{p.yang2@uva.nl} \\
	%% examples of more authors
	\And
	Giovanni Colavizza\thanks{Giovanni Colavizza is also affiliated at the University of Bologna, Department of Classical and Italian Philology, Italy} \\
	Department of Communication\\
	University of Copenhagen\\
	Karen Blixens Plads 8, Copenhagen, Danmark \\
	\texttt{colavizza@hum.ku.dk} \\
	%% \AND
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}

% Uncomment to remove the date
%\date{}

% Uncomment to override  the `A preprint' in the header
\renewcommand{\headeright}{}
%\renewcommand{\undertitle}{Technical Report}
\renewcommand{\shorttitle}{Research Data in Scientific Publications: A Cross-Field Analysis}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={A template for the arxiv style},
pdfsubject={q-bio.NC, q-bio.QM},
pdfauthor={David S.~Hippocampus, Elias D.~Striatum},
pdfkeywords={First keyword, Second keyword, More},
}

\begin{document}
\maketitle

\begin{abstract}
	Data sharing is fundamental to scientific progress, enhancing transparency, reproducibility, and innovation across disciplines. Despite its growing significance, the variability of data-sharing practices across research fields remains insufficiently understood, limiting the development of effective policies and infrastructure. This study investigates the evolving landscape of data-sharing practices, specifically focusing on the intentions behind data release, reuse, and referencing. Leveraging the PubMed open dataset, we developed a model to identify mentions of datasets in the full-text of publications. Our analysis reveals that data release is the most prevalent sharing mode, particularly in fields such as Commerce, Management, and the Creative Arts. In contrast, STEM fields, especially the Biological and Agricultural Sciences, show significantly higher rates of data reuse. However, the humanities and social sciences are slower to adopt these practices. Notably, dataset referencing remains low across most disciplines, suggesting that datasets are not yet fully recognized as research outputs. A temporal analysis highlights an acceleration in data releases after 2012, yet obstacles such as data discoverability and compatibility for reuse persist. Our findings can inform institutional and policy-level efforts to improve data-sharing practices, enhance dataset accessibility, and promote broader adoption of open science principles across research domains.
\end{abstract}


% keywords can be removed
\keywords{open science \and data sharing \and data reuse\and research data}


\section{Introduction}
Open Science, emerging from a diverse array of cultural and technological initiatives at the turn of the twenty-first century, has evolved into a transformative movement within the scientific community~\citep{willinsky2005unacknowledged, moore2017genealogy}. At its core, Open Science aims to make scientific research more transparent, accessible, and inclusive, fostering collaboration across disciplines and encouraging broader societal engagement. One influential definition characterizes Open Science as “transparent and accessible knowledge that is shared and developed through collaborative networks,” highlighting both the outputs of scientific endeavors and the processes involved in their creation~\citep{vicente2018open,leonelli2023philosophy}. Expanding on this perspective, UNESCO defines Open Science as “an inclusive construct that combines various movements and practices aiming to make multilingual scientific knowledge openly available, accessible, and reusable for everyone, to increase scientific collaborations and sharing of information for the benefits of science and society, and to open the processes of scientific knowledge creation, evaluation, and communication to societal actors beyond the traditional scientific community”~\citep{moller2023unesco}.

In practice, Open Science goes beyond providing open access to scientific publications; it also encompasses a wide range of activities, including the sharing of research data, software, and methodologies, all aimed at enhancing transparency and fostering collaboration~\citep{ramachandran_open_2021, mauthner_open_2013}. Among these practices, data sharing has garnered significant attention. Specifically, data sharing refers to the release of data in formats that enable reuse by others~\citep{pasquetto_reuse_2017}. This practice can take many forms, ranging from private exchanges between researchers to more formal mechanisms such as depositing datasets in archives, repositories, domain-specific collections, or library collections. Additionally, researchers may share data by attaching supplemental materials to journal articles or posting datasets on laboratory websites~\citep{wallis_if_2013}.

Data sharing practices offer substantial benefits to both the scientific community and individual researchers. For instance, the free availability of Landsat series data resulted in a twentyfold increase in downloads from the United States Geological Survey between 2009 and 2017, accompanied by a fourfold rise in its use in annual publications~\citep{zhu2019benefits}. This increased accessibility has advanced research applications in land monitoring, enabling studies on surface changes, coastal erosion rates, and glacier fluctuations~\citep{kennedy2014bringing,roy2014landsat,wulder2012opening}.

In addition to broadening research opportunities, data sharing correlates with higher citation rates. For example, \cite{piwowar_data_2013} analyzed 10,555 studies utilizing gene expression microarray data and identified a 9\% citation advantage for papers that shared data. This citation boost varies by discipline. In astronomy, articles linked to open datasets showed a 20\% increase in citation rates~\citep{henneken2011linking}, while paleoclimatology papers with publicly available data experienced a 35\% citation advantage~\citep{sears2011data}. In the social sciences, ~\cite{gleditsch2003posting} examined articles in the Journal of Peace Research and found that those providing data, regardless of format, were cited twice as often as similar articles without accessible data.

Beyond citation impacts, data sharing improves research productivity. A study of over 7,000 NSF and NIH-funded projects found that those with archived data produced a median of 10 publications, compared to only 5 for projects without archived data~\citep{pienta2011enduring}. Additionally, data sharing facilitates peer review and reproducibility, which are essential for verifying research findings and fostering scientific reliability~\citep{peng_reproducible_2011}.


Despite these advantages, there remain open questions on data sharing. One major challenge lies in detecting data-sharing behaviors within publications. Many studies focus on limited datasets or specific disciplines, failing to provide a comprehensive view of data-sharing practices across the scientific community~\citep{zhao_data_2018,koesten_dataset_2020,khan_measuring_2021,stodden_empirical_2018}. For instance, ~\cite{cao_rise_2023} analyzed 1,062,586 arXiv papers in LaTeX format published between 2011 and 2021, but their study focused solely on computer science, physics, and mathematics, leaving other disciplines unexplored. Another limitation arises from the reliance on data availability statements (DAS) as the primary indicator of data sharing~\citep{colavizza_citation_2020,jiao_data_2024,strcic_open_2022}. While useful, DAS are not universally required across fields or journals, creating substantial gaps in understanding the variations in data-sharing practices. Furthermore, as dataset reference standards evolve, mentions of datasets are no longer confined to DAS alone but may appear in other sections of publications~\citep{cao_rise_2023}. 

To address these gaps, our study employs large-scale full-text analysis to investigate data sharing and reuse patterns comprehensively. We aim to answer the following questions:
\begin{itemize}
    \item To what extent is research data released, reused, and referenced across scientific disciplines?
    \item How do releases, reuses, and references change across fields and over time?
\end{itemize}

Our analysis uses the PubMed Open Access (OA) collection, consisting of over 5.7 million full-text articles. To identify the datasets referenced in the publications, we relied on the repository list provided by the European Research Council (ERC) \url{https://zenodo.org/records/7728016}~\citep{jahn_2023_7728016}. This repository encompasses all research funded by the ERC, offering valuable insights into the availability and characteristics of data repositories across diverse research disciplines. 
For their work, the authors considered 220 repositories, identifying 137 trusted data repositories and 74 trusted literature repositories. For our investigation, we rely on the ERC data repositories list to detect and extract mentions to datasets in the full text of papers, as our primary emphasis lies in understanding the availability and nature of repositories across various research fields. Through natural language processing (NLP), this study categorizes data citation intent, such as release, reuse, and reference. This approach provides a nuanced understanding of data citation practices and offers an innovative methodology for analyzing data reuse intentions within scientific literature.

Our findings are expected to shed light on how research data repositories are utilized across diverse scientific fields. By providing insights into data citation patterns, this research aims to guide repository development strategies and contribute to the advancement of open science.


\section{Previous Work}
\label{sec:headings}

\subsection{Open science and research data}
Interest in open science has been growing steadily, with a noticeable increase in the adoption and enforcement of open science practices across disciplines. For instance, funding organizations such as the European Commission require grant recipients to comply with open-access publishing policies under frameworks like Horizon Europe, aiming to enhance the accessibility and dissemination of research outputs to broader audiences~\citep{eu_openscience}. Similarly, numerous academic journals and institutions now mandate practices such as data sharing and methodological transparency as part of their publication and evaluation processes~\citep{robson2021promoting,gorgolewski2016practical}. Moreover, open science communities play a pivotal role in facilitating the large-scale transition of researchers toward open science practices~\citep{armeni2021towards}.

Open science practices extend beyond open-access publishing and include the early sharing of research outputs. For example, platforms like arXiv and bioRxiv enable the dissemination of preprints, fostering early access to findings. Furthermore, open science encourages the public sharing of data and code, often hosted on online repositories such as Zenodo and GitHub, thereby improving research reproducibility and scalability. Open science also promotes rigorous and transparent research design, exemplified by practices like study preregistration~\citep{gopal2018adherence}. 

Substantial evidence indicates that open science practices offer significant advantages over traditional closed practices~\citep{mckiernan_how_2016}. Open-access articles, for example, not only garner broader academic attention and higher citation rates~\citep{huang2024open} but also attract greater engagement from the general public and news media compared to paywalled articles~\citep{schultz2021all,yang2024open}. Furthermore, open science has been shown to accelerate scientific discovery in specific fields~\citep{woelfle2011open}, enhance research transparency, and improve reproducibility~\citep{besanccon2021open}. These benefits play a critical role in addressing challenges associated with the reproducibility crisis~\citep{open2015estimating}.

In today’s data-driven research landscape, the collection, analysis, and interpretation of large datasets are critical to scientific discovery. Among the pillars of open science, research data is particularly vital for promoting transparency and reproducibility. Access to well-documented research data facilitates independent verification of results, supports secondary analyses, and fosters interdisciplinary collaboration, thereby amplifying the impact of scientific inquiry~\citep{hossain2016state,milham_assessment_2018}. There is evidence that integrated data sets have been instrumental in driving biomedical discoveries and drug development~\citep{shahin2020open}.

The advantages of sharing research data are far-reaching, enhancing both the visibility and reuse of research outputs while maximizing the impact of funding agencies' investments~\citep{los_riding_2010}. Recognizing these benefits, governments and funding bodies worldwide have implemented policies to incentivize open data practices. The United States pioneered such efforts as early as 1991~\citep{bromley_policy_1991}, with countries like China, the United Kingdom, and Australia subsequently strengthening their data management frameworks~\citep{china____policy,uk_policy,australia_policy}. In Europe, the Horizon 2020 initiative introduced the Open Research Data Pilot (ODP) to improve data accessibility and establish credibility in data-sharing practices. Leading funding agencies, including the NSF, NIH, and the UK’s Economic and Social Research Council, now require grant applicants to submit data management plans as part of their application process~\citep{smith2012institutional,spengler2012data}. Publishers such as Elsevier, PLOS, Springer, and Nature have also adopted policies that encourage or mandate data citation within reference lists, promoting transparency and accountability in scientific research~\citep{cousijn_data_2018,walton_data_2010,plos_policy,Springer_policy}.

For researchers, open data practices offer additional benefits: they facilitate the development of scientific software~\citep{niemeyer_challenge_2016}, increase research productivity~\citep{mcnaught_changing_2015}, and promote a collaborative data-sharing culture within the scientific community~\citep{belter_measuring_2014}. By aligning incentives for researchers, funders, and publishers, these policies collectively strengthen the foundation for transparent, reproducible, and impactful research.


However, significant barriers continue to hinder the widespread adoption of open data. These include limited incentives, inconsistent citation practices, concerns about data quality, and researchers' reluctance to relinquish control over their data. Additionally, a lack of awareness and insufficient support mechanisms exacerbate these challenges~\citep{chawinga_global_2019,gajbe_evaluation_2021}. Practical issues such as time constraints, inadequate funding, and insufficient institutional support further impede progress~\citep{tenopir_data_2011,tenopir_data_2020}. Deficiencies in archival standards and infrastructure also contribute to low rates of data sharing~\citep{markiewicz_openneuro_2021}. For example, studies that sought to obtain data directly from authors reported low success rates—ranging from 27\% to 59\%, depending on the discipline and geographical context~\citep{tedersoo_data_2021}. Even among papers with data availability statements claiming “data available upon request,” compliance remains low. A 2018 study revealed that only 44\% of authors shared their data when requested~\citep{stodden_empirical_2018}, a finding corroborated by subsequent research~\citep{strcic_open_2022,danchev_evaluation_2021}. 

\subsection{Sharing and reuse of research data}
Research on data sharing and reuse remains in an exploratory stage, with scholars using various data sources and quantitative methods to analyze and discuss data reuse and sharing behaviors in publications.

Disciplinary differences in data citation practices have been a focal point. For instance, ~\cite{park_informal_2018} examined samples from biological and biomedical sciences in the Data Citation Index (DCI), revealing that informal citations within article text are more prevalent than formal citations in reference sections. Similarly, ~\cite{robinson-garcia_analyzing_2016} also utilized DCI data to examine the varying uses of datasets and data studies across disciplines. Their analysis found that datasets were most frequently cited in the fields of science and engineering \& technology, whereas data studies played a more prominent role in the social sciences and arts \& humanities. ~\cite{park_examination_2017} analyzed 148 articles from the Web of Science Data Citation Index to identify factors influencing data sharing and reuse. They found that formal data citation remains relatively uncommon, while informal references in the main text are more typical.

Certain factors have been found to influence researchers' willingness and ability to share and reuse datasets. Studies suggest a correlation between dataset sharing and higher citation rates~\citep{piwowar_data_2013,piwowar_sharing_2007}. Authors also tend to reuse their own shared data, resulting in higher self-citation rates~\citep{robinson-garcia_analyzing_2016}. Data-sharing practices vary notably by discipline, suggesting a need for tailored approaches for each field~\citep{helbig_supporting_2015,torres-salinas_how_2014}. Furthermore, data-sharing rates vary by scientific field~\citep{tenopir_data_2011}, and researchers’ data-sharing behaviors and perceptions differ across age groups and geographical locations~\citep{tenopir_changes_2015}. Certain data types, such as survey, aggregated, and sequence data, receive more frequent citations and higher altmetric scores~\citep{peters_research_2015}.

Studies of data-sharing behavior highlight the impact of shared data on research practices. For instance, an analysis of 600 articles across PLOS journals showed that 74\% of studies rely on datasets created by authors, with fewer reusing prior datasets~\citep{zhao_data_2018}. In biodiversity research, studies using Global Biodiversity Information Facility (GBIF) data demonstrate a rise in open data use, though best practices for data citation remain underutilized~\citep{khan_measuring_2021}.

In addition, journal compliance policies for data sharing have improved, with an increase in the use of repositories instead of supplementary materials for data storage~\citep{jiao_data_2024}. However, data availability statements (DAS) remain inconsistent, especially in COVID-19 research, where only a quarter of preprints provide explicit data-sharing statements~\citep{strcic_open_2022}.

Despite these findings, certain gaps in data-sharing and reuse research remain, particularly in the context of cross-disciplinary data-sharing practices. Most studies are based on samples or case studies from specific fields or repositories, lacking comprehensive cross-disciplinary insights~\citep{kafkas_database_2015, piwowar_beginning_2011, zhao_data_2018,khan_measuring_2021,cao_rise_2023}. Furthermore, the use of data availability statements to accurately identify datasets in academic publications remains limited~\citep{jiao_data_2024,strcic_open_2022}. Some studies suggest that datasets are more commonly cited informally within the text, as opposed to formal citations in references~\citep{belter_measuring_2014,kafkas_database_2015}. While some researchers use the Data Citation Index (DCI) to examine dataset usage, the DCI's focus on natural sciences results in limited coverage across disciplines~\citep{silvello_theory_2017,park_informal_2018,park_examination_2017}, with citation patterns that remain incomplete~\citep{robinson-garcia_analyzing_2016}.

One related study, \cite{cao_rise_2023} investigated the adoption of data and method-sharing practices by analyzing a dataset of 1.1 million arXiv papers, concentrating on physics, mathematics, and computer science. They utilized regular expression matching to extract URLs from the LaTeX-formatted full text of these papers, classifying the URLs as ``data URLs'' or ``method URLs'' using manual annotation and a fine-tuned SciBERT model. Their findings highlighted a growing trend in link-sharing for methods and data, with an increasing number of papers incorporating such URLs over time. They also noted a rise in the reuse of the same links across papers, particularly in computer science, indicating a possible expansion of reproducibility efforts. Furthermore, the analysis revealed a consolidation of links within fewer web domains, such as GitHub, over time. Importantly, papers featuring shared links tended to have a higher citation impact, especially when the links remained active, underscoring the practical benefits of data-sharing practices.

While this study represents a valuable contribution by leveraging full-text analysis on a large dataset, it has notable limitations. Its focus on preprint articles and specific disciplines (physics, mathematics, and computer science) may restrict the generalizability of its findings. Preprints are not universally utilized across all academic disciplines, meaning the dataset may not adequately capture fields where preprint culture is less established. Moreover, the exclusion of formally published articles leaves unanswered questions about potential differences in data-sharing practices between preprints and peer-reviewed publications. Considering the diverse adoption rates of data-sharing practices across scientific disciplines, expanding this research to include formally published articles and additional fields would offer a more comprehensive understanding of how data-sharing practices vary and evolve.


To deepen our understanding of data-sharing and reuse practices, further work across disciplines is essential. Our study seeks to provide a more comprehensive perspective on data use across scientific fields, filling gaps left by previous research that focused on specific disciplines or datasets. By broadening the scope of analysis, the study aims to offer practical insights into the factors influencing data-sharing practices and the variability observed across disciplines. These insights can help foster the adoption of standardized practices and promote a more widespread culture of data-sharing within the research community, ultimately enhancing collaboration, reproducibility, and the overall impact of scientific research.


\section{Methodology}
\label{sec:Methodology}
The data utilized in this study was obtained from the PubMed Open Access collection\footnote{\url{https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/}} as of March 2024. The total number of publications considered in this dataset is N = 5,704,648 (3,772,464 of oa\_comm,1,502,488 of oa\_noncomm, 429,696 of oa\_other)\footnote{Commercial Use Allowed (oa\_comm): CC0, CC BY, CC BY-SA, and CC BY-ND licenses;
Non-Commercial Use Only (oa\_noncomm): CC BY-NC, CC BY-NC-SA, CC BY-NC-ND;
Other (oa\_other): no machine-readable license, no license, or a custom license. \url{https://pmc.ncbi.nlm.nih.gov/tools/ftp/}}. To enhance the dataset with additional information such as publication dates, citation counts, and disciplines, we queried the Dimensions API (March 2024).

To extract the relevant data repositories mentioned in each paper, we implemented a series of processing steps.

Firstly, we employed regular expression (regex) matching to identify repositories from the full text based on their URLs. Our approach involved applying a unified rule across all URLs to strip away the protocol (http, https) and subdomain (www). For example, from the URL `https://meertens.knaw.nl/en/collections/', we retained `meertens.knaw.nl/en/collections'. Preliminary evidence suggests that this approach enhances resource availability compared to relying solely on data availability statements~\citep{federer_long-term_2022,cao_rise_2023}. The comprehensive list of repository links is available in our repository\footnote{\url{https://github.com/alsowbdxa/Research_Data_in_Scientific_Publications/blob/main/Codes/dataset_urls.xlsx}}. Secondly, to ensure consistency in the repository names or URLs, we converted the entire text of the paper and our domain list to lowercase during the matching process.

After matching, we successfully extracted 69,090 articles (1.2\%) from the PubMed Open Access collection dataset that included at least one repository link. Figure \ref{fig:top10_repo} illustrates the top 10 repositories appearing in the dataset, ranked by frequency.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{Figure_1.png}
    \caption{Top 10 repositories by frequency.}
    \label{fig:top10_repo}
\end{figure}

Subsequently, these 69,090 papers served as the foundation for constructing our annotation dataset used in model training. Based on our observations and experience, we found that the intention of usage of the repository is typically conveyed within the core sentence (the sentence containing the repository link) and one or two sentences around it. To maximize the information captured while maintaining simplicity, we adopted the same method as a previous study, which incorporates the sentences immediately preceding and following the core sentence to provide additional context ~\citep{zhang2022towards}. Specifically, we retained the two sentences preceding and the two sentences following the core sentence as the context. This context, often regarded as crucial, provides additional information to better identify and classify the intended use of the mentioned datasets~\citep{koesten_dataset_2020}.  Using this method, we processed all the papers and randomly selected 1,000 articles (1.4\% of the 69,090 papers) for annotation.

The manual annotation of these contexts was carried out using Label Studio. We classified the intention of contexts into four categories: 
\begin{itemize}
    \item \textbf{Release}
    The context of the repository mentioned indicates that the paper releases a new dataset on the repository, or generates a dataset by integrating diverse published datasets and releasing it on the repository. A repository ID is typically provided alongside the mention or in the paper.
    
        \begin{quote}
        Example 1: \textit{The datasets are currently for private access during this review period, which can be accessed through: \url{https://datadryad.org/stash/share/yRDf1Kmj9_hR_IIGg_vukBVNUmmB9tm_j8v1BZ721A}.}
        \end{quote}
        
        \begin{quote}
        Example 2: \textit{Raw microarray data have been deposited in compliance to MIAME guidelines at ArrayExpress database (\url{http://www.ebi.ac.uk/arrayexpress}), with accession number E-TABM-1215 release date June 11, 2012. Gene subsets corresponding to each combination of responses analyzed by microarrays were defined from Venn diagrams indicating the number of the included genes.}
        \end{quote}
        
    \item \textbf{Reuse}
    The context surrounding the repository mentioned reveals that the paper directly employed a published dataset hosted on the repository. A repository ID is typically provided alongside the mention or in the paper.
        \begin{quote}
        Example 1: \textit{The European Commission do not accept any responsibility for use that may be made of the information it contains. All data used in the current study is publicly available. Summary statistics for IBS can be download from European Bioinformatics Institute GWAS Catalog (\url{https://www.ebi.ac.uk/gwas/)}. Summary statistics for neuroticism can be downloaded from \url{https://ctg.cncr.nl/software/summary\_statistics} and \url{http://www.ccace.ed.ac.uk}. Summary statistics for depression can be downloaded from \url{https://datashare.ed.ac.uk/handle/10283/3203}.}
        \end{quote}

        \begin{quote}
        Example 2: \textit{The land use data were obtained from the 30-m annual land cover datasets and its dynamics in China from 1990 to 2020 (\url{https://zenodo.org/record/5210928\#.Y9TDU3ZBxD}).}
        \end{quote}

    \item \textbf{Reference}
    The context surrounding the repository mentioned indicates that the paper references the repository, possibly to compare different datasets or for context. Importantly, the authors' work is not reliant on this dataset, nor have they produced a new dataset based on it.
        \begin{quote}    
        Example 1: \textit{Furthermore, in Table S3, we also list the top 20 ranked potential phosphorylation sites for MAPK1, in which Tyr325 and Tyr331 of FOS (P01100) has been confirmed to be modified by this kinase (\url{http://www.uniprot.org/uniprot/P01100\#ptm\_processing}).}
        \end{quote}

        \begin{quote}
        Example 2: \textit{Some of the resources used an ontology, e.g., Disease Ontology, a taxonomy such as MeSH [24], or cross-referenced another resource such as OMIM. Diseases and phenotypes are often mixed in the same resource and sometimes in the same category annotation. For example, the European Variation Archive (\url{EVA – http://www.ebi.ac.uk/eva/}) [25] trait names’ labeling uses a mixed set of vocabularies from HP, SNOMED-CT, OMIM, and non-standardized local identifiers used internally at source from the ClinVar records. The identifiers of the record’s cross-references for each trait name are not equivalently represented - e.g., trait name ‘congenital adrenal hyperplasia’ in EVA contains identifiers for SNOMED-CT, HP, but not for OMIM. This trait name also links to a non-standardized internal identifier used at the Office of Rare Disease.}
        \end{quote}

    \item \textbf{Nothing}
    Occasionally, we encountered erroneous or non-related hits. While using repository links to identify repositories within the full text, we found that sometimes these links did not solely indicate repositories but could also convey other meanings. In such cases, we labelled it as `Nothing.'

        \begin{quote}
        Example 1: \textit{The following link will take you to the Dryad record for your article, so you won't have to re-enter its bibliographic information, and can upload your files directly: \url{http://datadryad.org/submit?journalID=pgenetics\&manu=PGENETICS-D-19-01831R2} More information about depositing data in Dryad is available at \url{http://www.datadryad.org/depositing}.}
        \end{quote}

        \begin{quote}
        Example 2: \textit{Assessing the impact of autologous neutralizing antibodies on viral rebound in postnatally SHIV-infected ART-treated infant rhesus macaques  14 9 2023 2023.07.22.550159 \url{http://biorxiv.org/lookup/doi/10.1101/2023.07.22.550159} Abstract  While the benefits of early antiretroviral therapy (ART) initiation in perinatally infected infants are well documented, early ART initiation is not always possible in postnatal pediatric HIV infections, which account for the majority of pediatric HIV cases worldwide. The timing of onset of ART initiation is likely to affect the size of the latent viral reservoir established, as well as the development of adaptive immune responses, such as the generation of neutralizing antibody responses against the virus.}
        \end{quote}
    
\end{itemize}

Following the definition of these four intentions, we manually annotate the annotation subset (1,000 articles with 1328 contexts), and we get 670 contexts with the label `Release,' 119 contexts with `Reference,' 453 contexts with `Reuse' and 86 contexts with `Nothing.' Then we use this subset to train the model.

For model training, we utilized pre-trained models from Hugging Face,  specifically BertForSequenceClassification `bert-base-uncased' for BERT and RobertaForSequenceClassification `roberta-base' for RoBERTa, this model has been validated as delivering optimal performance in most NLP tasks~\citep{devlin2018bert}. Before training, we mapped the original labels to distinct integers, assigning `Release' as label 0, `Reuse' as label 1, `Reference' as label 2, and `Nothing' as label 3. The dataset was then partitioned into training, testing, and validation subsets in an 80-10-10\% split.

To prepare the textual data for modeling, we performed tokenization using BERT and RoBERTa tokenizers respectively, considering a maximum sequence length of 512 tokens, for each sentence. If the total number of tokens is less than 512 (the model's maximum limit), the entire sentence is retained. However, if it exceeds 512 tokens, we employ four different truncation methods:
\begin{itemize}
    \item Method 1
        If it exceeds 512 tokens, we truncate it by retaining the first 512 tokens.
    \item Method 2
        If it exceeds 512 tokens, we truncate it by preserving the last 512 tokens.
    \item Method 3
         If it exceeds 512 tokens, we truncate it by keeping the central 512 tokens. For instance, if it has 1000 tokens, we remove the first 244 and last 244 tokens.
    \item Method 4
         If it exceeds 512 tokens, we truncate it by keeping the first 256 tokens and the last 256 tokens.
\end{itemize}

For each model, we employ each truncation method and evaluate the model based on the F1 score. Additionally, we incorporate the early stopping mechanism in the training process. Specifically, if the F1 score on the validation set shows no improvement over 10 epochs, and the model’s performance starts to degrade, we terminate the training

We present an overview of the performance results achieved by various methods when applied to either the RoBERTa and BERT models\ref{tab:Performance of models by methods}. We see that RoBERTa, specifically when employed with method 2, outperforms the other configurations, boasting a F1 score of 0.902. Building upon this outcome, we further enhance the model's efficacy by merging the training and test subsets. Leveraging the RoBERTa model in conjunction with truncation method 2, we conduct fine-tuning to optimize its performance. The resultant refined model is subsequently subjected to testing on the validation dataset. 


\begin{table}[H]
\centering
\resizebox{0.7\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|}
\hline
          &          & Accuracy & Precision & Recall  & F1      \\ \hline
\multirowcell{4}{RoBERTa}   & Method 1 & 0.896             & 0.897              & 0.896           & 0.894 \\
\cline{2-6}
          & Method 2 & \textbf{0.902}             & \textbf{0.902}              & \textbf{0.902}          &\textbf{0.902} \\
\cline{2-6}          & Method 3 & 0.886             & 0.885              & 0.886           & 0.885 \\
\cline{2-6}          & Method 4  & 0.885             & 0.890              & 0.890           & 0.886 \\ 
\hline     \cline{2-6}      
\multirowcell{4}{BERT}      & Method 1 & 0.876             & 0.882              & 0.876           & 0.876 \\
\cline{2-6} 
          & Method 2 & 0.876             & 0.874              & 0.876           & 0.874 \\
\cline{2-6}          & Method 3 & 0.870             & 0.873              & 0.870           & 0.871 \\
\cline{2-6}          & Method 4 & 0.855             & 0.864              & 0.855           & 0.857  \\ \hline
\end{tabular}%
}
\caption{Performance of models by methods}
\label{tab:Performance of models by methods}
\end{table}



Following the training phase, we deploy the trained model to predict the intention for each context within the entire dataset (69,090 articles with 92,267 contexts). The distribution of intentions across the entire dataset is illustrated in Figure \ref{fig:predicted_label_distribution}. 

Specifically, we observe that 55,680 contexts (60.3\%) are labeled as `Release,' 24,809 contexts (26.9\%) as `Reuse,' 8,597 contexts (9.3\%) as `Reference,' and 3,181 contexts (3.5\%) as `Nothing.'
    
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{Figure_2.png}
    \caption{Predicted label distribution}
    \label{fig:predicted_label_distribution}
\end{figure}

We visualize the top 20 repositories along with their respective usage intentions in the figure below:
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{Figure_3.png}
    \caption{Distribution of intentions by repository.}
    \label{fig: Distribution of using intentions by keyword}
\end{figure}

The patterns of using intentions across repositories are highlighted in Figure \ref{fig: Distribution of using intentions by keyword}. The figure further validates the accuracy of our classification to some extent. Repositories such as Figshare and Zenodo, often utilized for publishing datasets, demonstrate a higher frequency of the `Release' type. Conversely, repositories like Uniport\footnote{A prominent free-access collection of protein sequences and their annotations, supporting fields like biology, medicine, and biotechnology. \url{https://pmc.ncbi.nlm.nih.gov/articles/PMC4384041/}} and ebi.ac.uk\footnote{The world’s most comprehensive suite of freely available data resources and tools for life science research. \url{https://www.ebi.ac.uk/about}}, dedicated to supplying datasets for research analysis, display a predilection for the `Reuse' type.

\section{Results}
We start by providing a description of our findings, followed by an in-depth discussion in the subsequent section.

Figure \ref{fig:discipline2intention} presents the proportional distribution of three intentions across various academic disciplines. The horizontal bar plot includes 22 disciplines, each represented on the y-axis, while the x-axis shows the proportion of each intention relative to the total papers for that field, which is calculated based on fractional counting. 

In most disciplines, the `release' intention dominates, indicating a strong preference for openly sharing data. Specifically, the top five disciplines for releasing datasets are `Commerce, Management, Tourism and Services', `Studies in Creative Arts and Writing', `Studies in Human Society', `Psychology and Cognitive Sciences' and `Economics'. Conversely, the proportions of released datasets are lowest in `Biological Sciences', `Information and Computing Sciences' and `Agricultural and Veterinary Sciences'.

Regarding the intention of reuse, STEM-related fields generally exhibit a higher proportion of reuse. Notably, `Agricultural and Veterinary Sciences', `Technology', `Chemical Sciences', `Biological Sciences', `Medical and Health Sciences' have over 30\% of mentions indicating dataset reuse.

For reference intention, datasets are referenced less frequently across all disciplines, with two exceptions: `Information and Computing Sciences' and `Philosophy and Religious Studies'.


\begin{figure}[htpb]
    \centering
    \includegraphics[width=0.8\linewidth]{Figure_4.png}
    \caption{Distribution of intentions across disciplines.}
    \label{fig:discipline2intention}
\end{figure}

Furthermore, figure \ref{fig:Distribution of Intention Over Time} shows the distribution of different mention intentions in the dataset (`reuse,' `release,' and `reference') over time, with the x-axis representing the years and the y-axis showing the percentage of each intention.

The figure reveals trends in dataset usage across publications. From 2007 to 2012, the intention to reuse datasets increased, while the intention to release datasets remained relatively low and even declined slightly. However, starting in 2012, the trends shifted. The intention to release datasets sharply increased and consistently remained high (around 60\%), while the intention to reuse datasets decreased significantly, dropping from 50\% to approximately 30\%.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{Figure_5.png}
    \caption{Distribution of intention over time.}
    \label{fig:Distribution of Intention Over Time}
\end{figure}



To explore the disciplinary interconnections in the contexts of release, reuse, and reference intentions, we constructed co-occurrence networks for each intention via VOSviewer. Specifically, a publication may encompass multiple disciplines, the co-occurrence of macro disciplines associated with that publication is treated as a co-occurrence instance. The co-occurrence distribution for each intention network is subsequently calculated using fractional counting. In these networks, nodes represent disciplines, edges represent the co-occurrence of two disciplines within the same article, and the color means the cluster identified based the VOSviewer\citep{van2010software}. The strength of connections is determined by the frequency of such co-occurrences.

The co-occurrence network for the release intention (Figure \ref{fig:co-occuarance_network_release}) underscores the pivotal role of Biological Sciences and Medical and Health Sciences, which form strong connections with related disciplines such as Agricultural and Veterinary Sciences, Environmental Sciences, and Chemical Sciences. 

For the reuse intention (Figure \ref{fig:co-occuarance_network_reuse}), the network displays a more dispersed pattern of connections. While Biological Sciences and Medical and Health Sciences remain central, the network highlights strong links with Information and Computing Sciences and Mathematical Sciences, illustrating the growing importance of computational and data-driven approaches in reused research. Additionally, significant connections to social science disciplines, such as Studies in Human Society and Education, suggest that data reuse is becoming increasingly relevant across diverse academic contexts.

The reference intention network (Figure \ref{fig:co-occuarance_network_reference}) exhibits a distinct structure, with Biological Sciences maintaining a central role but with more dispersed connections compared to the other two intentions. 


\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{Figure_6.png}
    \caption{Co-occurrence network of release}
    \label{fig:co-occuarance_network_release}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{Figure_7.png}
    \caption{Co-occurrence network of reuse}
    \label{fig:co-occuarance_network_reuse}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{Figure_8.png}
    \caption{Co-occurrence network of reference}
    \label{fig:co-occuarance_network_reference}
\end{figure}

\section{Discussion}
\subsection{Extent of data release, reuse, and reference across disciplines}

Our analysis reveals that the release intention is the dominant mode of data sharing across most disciplines. This prevalence is likely driven by the widespread influence of open science policies, the growing emphasis on transparency and reproducibility, and the expanding availability of data repositories. Public repositories such as Zenodo and Figshare, as well as discipline-specific platforms like UniProt and CCDC, have made data sharing more accessible. Moreover, the relatively lower technical and cognitive barriers to releasing data, compared to reusing or citing datasets, further contribute to its widespread adoption. This trend is particularly pronounced in disciplines such as `Commerce, Management, Tourism and Services', `Studies in Creative Arts and Writing', `Studies in Human Society', `Psychology and Cognitive Sciences' and `Economics', where data release accounts for over 80\% of all mentions. Such dominance suggests a strong alignment with open science principles in these disciplines. Previous research similarly highlights the prominent role of data studies in the social sciences and arts and humanities ~\citep{jimenez2015analyzing}. These findings are consistent with studies emphasizing the positive impact of open science in fostering transparency, reproducibility, and collaborative research ~\citep{tenopir_changes_2015}.

Conversely, disciplines such as `Biological Sciences', `Information and Computing Sciences' and `Agricultural and Veterinary Sciences' exhibit lower levels of data release, likely due to field-specific challenges, including ethical considerations, sensitivity of data, and proprietary restrictions. Prior studies underscore these barriers, highlighting the complexities associated with consent, privacy, and intellectual property in these fields ~\citep{tenopir_changes_2015, huang2012willing, oushy2015share}. Addressing these challenges requires robust infrastructure and governance mechanisms to ensure compliance. Thus, while the overall trend supports open science initiatives, significant variation persists across disciplines due to these domain-specific barriers and norms.

In contrast, the reuse intention is more prevalent in STEM-related fields such as `Agricultural and Veterinary Sciences', `Technology', `Chemical Sciences', `Biological Sciences', `Medical and Health Sciences', where over 30\% of mentions involve the reuse of existing datasets. This prevalence can be attributed to the availability of shared databases, such as UniProt and CCDC, and the methodological reliance on pre-existing data in these disciplines ~\citep{jimenez2015analyzing}. However, the relatively low reuse proportions in humanities and social sciences suggest that data reuse practices are less institutionalized in these fields. This discrepancy likely arises from variations in data availability, research methodologies, and the perceived value of reusing datasets ~\citep{kim2017scientists}.

The reference intention remains consistently low across most disciplines, with notable exceptions in `Information and Computing Sciences' and `Philosophy and Religious Studies'. This overall low level of dataset referencing highlights a critical issue in academic publishing: datasets are not yet widely recognized as formal research outputs in many fields ~\citep{silvello_theory_2017}. While dataset citation practices are gaining traction in Information and Computing Sciences ~\citep{force2014force}, other disciplines lag behind due to a lack of standardized citation practices and limited awareness of the benefits of dataset citation ~\citep{kratz2014data}. As previous studies suggest, data citation not only provides credit to data creators but also enhances transparency and reproducibility, underscoring its significance in advancing open science ~\citep{altman2015introduction, piwowar_data_2013}.

In addition, Biological Sciences and Medical and Health Sciences play a pivotal role in the connection among disciplines, which consistently serve as hubs across all intentions. These fields highlight the inherently interdisciplinary nature of research, particularly in data release practices, as evidenced by strong connections within the life and health sciences cluster. This observation aligns with previous findings that 86\% of research data published in biological sciences journals are cited by articles from disciplines outside the biological sciences domain in the Web of Science ~\citep{park2022interdisciplinarity}.

\subsection{Temporal trends in releases, reuses, and references}

Temporal trends in data-sharing practices show a clear evolution. From 2007 to 2012, the rise in reuse intentions marked the early stages of data-sharing adoption, driven by large-scale repositories and a growing emphasis on data-driven research ~\citep{tenopir_changes_2015}. The post-2012 surge in data release intentions may align with global open science initiatives, such as the U.S. White House memorandum in 2013, which required federal agencies to increase public access to research results, and the Plan S initiative in 2018, which set standards for immediate open access publication across Europe ~\citep{holdren2013memorandum, plans2018}. These policies have had a substantial societal impact, making millions of academic publications freely accessible to the public and fostering a shift toward collaborative, open science.

Since 2018, all disciplines have seen significant growth in data release activity, with STEM fields showing steady growth in reuse and reference intentions. This signals the increasing normalization of data-driven research practices. However, the delayed adoption of these practices in the humanities suggests ongoing cultural and infrastructural shifts, compounded by challenges such as non-standardized data formats and discipline-specific attitudes toward open science ~\citep{fuhr2021digital}.

Despite the success of open access policies, the decline in reuse intentions highlights ongoing challenges in data discoverability, compatibility, and a lack of incentives for reuse. Issues such as insufficient metadata, unclear licensing terms, and the technical complexity of integrating datasets may continue to hinder effective reuse in new research contexts ~\citep{borgman_conundrum_2012, mayernik2017open}.

We acknowledge certain limitations in our study. First, while we attempted to match dataset mentions in the full text with the repository list provided by the European Research Council, some dataset mentions may have been missed. These could include instances where datasets were not associated with URLs or were not included in the repository list. Additionally, our analysis relies on full-text data, and although we worked with a substantial corpus of millions of publications across disciplines, it should be noted that the dataset mostly represents biomedical and life sciences journal literature. As a result, our findings may not fully capture data-sharing practices in fields where such datasets are less prevalent or not yet widely integrated into the research ecosystem. 

\section{Conclusion}
This study highlights the evolving landscape of data-sharing practices across disciplines, focusing on the intentions of data release, reuse, and reference. The findings indicate that the release intention is the dominant mode of data sharing, with notable variations across disciplines. Fields such as Commerce, Management, and Creative Arts show high levels of data release, reflecting a strong alignment with open science principles, while disciplines like Biological Sciences and Agricultural Sciences face unique challenges related to ethical, legal, and privacy concerns. The reuse intention is particularly prevalent in STEM-related disciplines, emphasizing the growing reliance on shared datasets and computational methodologies in research. However, humanities and social sciences show a delayed adoption of data reuse practices, likely due to factors like limited data availability and infrastructure.

The analysis also reveals a low proportion of dataset referencing across most fields, suggesting that datasets are not yet fully recognized as formal research outputs, despite their increasing role in the research process. Temporal trends indicate that recent open science initiatives have accelerated data release practices, particularly post-2012, yet challenges persist, especially in terms of data discoverability and compatibility for reuse. The findings further highlight the central role of the Biological and Medical Sciences in fostering interdisciplinary data sharing.

This study provides a comprehensive understanding of how data is utilized across different scientific disciplines and offers valuable insights to help institutions and publishers develop better data policies. By identifying trends in data release, reuse, and citation, it can inform strategies to enhance data sharing practices and improve the accessibility and discoverability of datasets. These findings will assist in creating more effective support systems for researchers and encourage broader adoption of open science practices across various fields.







% \subsection{Citations}
% Citations use \verb+natbib+. The documentation may be found at
% \begin{center}
% 	\url{http://mirrors.ctan.org/macros/latex/contrib/natbib/natnotes.pdf}
% \end{center}

% Here is an example usage of the two main commands (\verb+citet+ and \verb+citep+): Some people thought a thing \citep{kour2014real, hadash2018estimate} but other people thought something else \citep{kour2014fast}. Many people have speculated that if we knew exactly why \citet{kour2014fast} thought this\dots

% \subsection{Figures}
% \lipsum[10]
% See Figure \ref{fig:fig1}. Here is how you add footnotes. \footnote{Sample of the first footnote.}
% \lipsum[11]

% \begin{figure}
% 	\centering
% 	\fbox{\rule[-.5cm]{4cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
% 	\caption{Sample figure caption.}
% 	\label{fig:fig1}
% \end{figure}

% \subsection{Tables}
% See awesome Table~\ref{tab:table}.

% The documentation for \verb+booktabs+ (`Publication quality tables in LaTeX') is available from:
% \begin{center}
% 	\url{https://www.ctan.org/pkg/booktabs}
% \end{center}


% \begin{table}
% 	\caption{Sample table title}
% 	\centering
% 	\begin{tabular}{lll}
% 		\toprule
% 		\multicolumn{2}{c}{Part}                   \\
% 		\cmidrule(r){1-2}
% 		Name     & Description     & Size ($\mu$m) \\
% 		\midrule
% 		Dendrite & Input terminal  & $\sim$100     \\
% 		Axon     & Output terminal & $\sim$10      \\
% 		Soma     & Cell body       & up to $10^6$  \\
% 		\bottomrule
% 	\end{tabular}
% 	\label{tab:table}
% \end{table}


\bibliographystyle{unsrtnat}
\bibliography{references}  %%% Uncomment this line and comment out the ``thebibliography'' section below to use the external .bib file (using bibtex) .


%%% Uncomment this section and comment out the \bibliography{references} line above to use inline references.
% \begin{thebibliography}{1}

% 	\bibitem{kour2014real}
% 	George Kour and Raid Saabne.
% 	\newblock Real-time segmentation of on-line handwritten arabic script.
% 	\newblock In {\em Frontiers in Handwriting Recognition (ICFHR), 2014 14th
% 			International Conference on}, pages 417--422. IEEE, 2014.

% 	\bibitem{kour2014fast}
% 	George Kour and Raid Saabne.
% 	\newblock Fast classification of handwritten on-line arabic characters.
% 	\newblock In {\em Soft Computing and Pattern Recognition (SoCPaR), 2014 6th
% 			International Conference of}, pages 312--318. IEEE, 2014.

% 	\bibitem{hadash2018estimate}
% 	Guy Hadash, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour, and Alon
% 	Jacovi.
% 	\newblock Estimate and replace: A novel approach to integrating deep neural
% 	networks with existing applications.
% 	\newblock {\em arXiv preprint arXiv:1804.09028}, 2018.

% \end{thebibliography}


\end{document}
