@article{marot2022perspectives,
  title={Perspectives on future power system control centers for energy transition},
  author={Marot, Antoine and Kelly, Adrian and Naglic, Matija and Barbesant, Vincent and Cremer, Jochen and Stefanov, Alexandru and Viebahn, Jan},
  journal={Journal of Modern Power Systems and Clean Energy},
  volume={10},
  number={2},
  pages={328--344},
  year={2022},
  publisher={SGEPRI}
}

@article{viebahn2022potential,
  title={Potential and challenges of AI-powered decision support for short-term system operations},
  author={Viebahn, Jan and Naglic, Matija and Marot, Antoine and Donnot, Benjamin and Tindemans, Simon H},
  journal={CIGRE Session 2022},
  year={2022}
}

@inproceedings{marot2021learning,
  title={Learning to run a power network challenge: a retrospective analysis},
  author={Marot, Antoine and Donnot, Benjamin and Dulac-Arnold, Gabriel and Kelly, Adrian and Oâ€™Sullivan, Aidan and Viebahn, Jan and Awad, Mariette and Guyon, Isabelle and Panciatici, Patrick and Romero, Camilo},
  booktitle={NeurIPS 2020 Competition and Demonstration Track},
  pages={112--132},
  year={2021},
  organization={PMLR}
}

@article{marot2020towards,
  title={Towards an AI assistant for power grid operators},
  author={Marot, Antoine and Rozier, Alexandre and Dussartre, Matthieu and Crochepierre, Laure and Donnot, Benjamin},
  journal={arXiv preprint arXiv:2012.02026},
  year={2020}
}

@article{kelly2020reinforcement,
  title={Reinforcement learning for electricity network operation},
  author={Kelly, Adrian and O'Sullivan, Aidan and de Mars, Patrick and Marot, Antoine},
  journal={arXiv preprint arXiv:2003.07339},
  year={2020}
}

@article{lehna2023managing,
  title={Managing power grids through topology actions: A comparative study between advanced rule-based and reinforcement learning agents},
  author={Lehna, Malte and Viebahn, Jan and Marot, Antoine and Tomforde, Sven and Scholz, Christoph},
  journal={Energy and AI},
  volume={14},
  pages={100276},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{subramanian2021exploring,
  title={Exploring grid topology reconfiguration using a simple deep reinforcement learning approach},
  author={Subramanian, Medha and Viebahn, Jan and Tindemans, Simon H and Donnot, Benjamin and Marot, Antoine},
  booktitle={2021 IEEE Madrid PowerTech},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@misc{manczak2023hierarchical,
  title={Hierarchical Reinforcement Learning for Power Network Topology Control},
  author={Blazej Manczak and Jan Viebahn and Herke van Hoof},
  year={2023},
  note={\url{https://arxiv.org/abs/2311.02129}}
}

@article{SUTTON1999181,
title = {Between {MDP}s and semi-{MDP}s: A framework for temporal abstraction in reinforcement learning},
journal = {Artificial Intelligence},
volume = {112},
number = {1},
pages = {181-211},
year = {1999},
issn = {0004-3702},
doi = {https://doi.org/10.1016/S0004-3702(99)00052-1},
url = {https://www.sciencedirect.com/science/article/pii/S0004370299000521},
author = {Richard S Sutton and Doina Precup and Satinder Singh},
keywords = {Temporal abstraction, Reinforcement learning, Markov decision processes, Options, Macros, Macroactions, Subgoals, Intra-option learning, Hierarchical planning, Semi-Markov decision processes},
}

@article{Baykal2010,
author = {Melike Baykal-Gursoy},
journal = {Wiley Encyclopedia of Operations Research and Management Science},
title = {Semi-Markov Decision Processes},
year = {2010},
doi = {https://doi.org/10.1002/9780470400531.eorms0757}
}

@misc{van2023multi,
      title={Multi-Agent Reinforcement Learning for Power Grid Topology Optimization}, 
      author={Erica van der Sar and Alessandro Zocca and Sandjai Bhulai},
      year={2023},
      eprint={2310.02605},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.02605}
}

@inproceedings{yoon2020winning,
  title={Winning the l2rpn challenge: Power grid management via semi-markov afterstate actor-critic},
  author={Yoon, Deunsol and Hong, Sunghoon and Lee, Byung-Jun and Kim, Kee-Eung},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{kendall2019learning,
  title={Learning to drive in a day},
  author={Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8248--8254},
  year={2019},
  organization={IEEE}
}

@article{li2019transforming,
  title={Transforming cooling optimization for green data center via deep reinforcement learning},
  author={Li, Yuanlong and Wen, Yonggang and Tao, Dacheng and Guan, Kyle},
  journal={IEEE transactions on cybernetics},
  volume={50},
  number={5},
  pages={2002--2013},
  year={2019},
  publisher={IEEE}
}

@misc{mai2018electrification,
  title={Electrification futures study: scenarios of electric technology adoption and power consumption for the United States},
  author={Mai, Trieu T and Jadun, Paige and Logan, Jeffrey S and McMillan, Colin A and Muratori, Matteo and Steinberg, Daniel C and Vimmerstedt, Laura J and Haley, Benjamin and Jones, Ryan and Nelson, Brent},
  year={2018},
  institution={National Renewable Energy Lab.(NREL), Golden, CO (United States)}
}

@article{panciatici2012operating,
  title={Operating in the fog: Security management under uncertainty},
  author={Panciatici, Patrick and Bareux, Gabriel and Wehenkel, Louis},
  journal={IEEE Power and Energy Magazine},
  volume={10},
  number={5},
  pages={40--49},
  year={2012},
  publisher={IEEE}
}

@article{marot2020learning,
  title={Learning to run a power network challenge for training topology controllers},
  author={Marot, Antoine and Donnot, Benjamin and Romero, Camilo and Donon, Balthazar and Lerousseau, Marvin and Veyrin-Forrer, Luca and Guyon, Isabelle},
  journal={Electric Power Systems Research},
  volume={189},
  pages={106635},
  year={2020},
  publisher={Elsevier}
}

@misc{actionspacered,
    author = {AsprinChina},
    title = {L2RPN NIPS 2020 a PPO Solution},
    year = {2020},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/AsprinChina/L2RPN_NIPS_2020_a_PPO_Solution
}},
}

@misc{icapswinner,
    author = {polixer},
    title = {Winner of L2RPN ICAPS 2021},
    year = {2020},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/polixir/L2RPN_2021}},
}

@ARTICLE{pandapower.2018,
author={L. Thurner and A. Scheidler and F. Schafer and J. H. Menke and J. Dollichon and F. Meier and S. Meinecke and M. Braun},
journal={IEEE Transactions on Power Systems},
title={pandapower - an Open Source Python Tool for Convenient Modeling, Analysis and Optimization of Electric Power Systems},
year={2018},
doi={10.1109/TPWRS.2018.2829021},
url={https://arxiv.org/abs/1709.06743},
ISSN={0885-8950}
}

@misc{1606.01540,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{chauhan2023powrl,
  title={Powrl: A reinforcement learning framework for robust management of power networks},
  author={Chauhan, Anandsingh and Baranwal, Mayank and Basumatary, Ansuma},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  pages={14757--14764},
  year={2023}
}

@article{pena2017extended,
  title={An extended IEEE 118-bus test system with high renewable penetration},
  author={Pena, Ivonne and Martinez-Anido, Carlo Brancucci and Hodge, Bri-Mathias},
  journal={IEEE Transactions on Power Systems},
  volume={33},
  number={1},
  pages={281--289},
  year={2017},
  publisher={IEEE}
}

@phdthesis{ryan2002hierarchical,
  title={Hierarchical reinforcement learning: a hybrid approach},
  author={Ryan, Malcolm Ross Kinsella},
  year={2002},
  school={UNSW Sydney}
}

@article{TRPO,
  author       = {John Schulman and
                  Sergey Levine and
                  Philipp Moritz and
                  Michael I. Jordan and
                  Pieter Abbeel},
  title        = {Trust Region Policy Optimization},
  journal      = {CoRR},
  volume       = {abs/1502.05477},
  year         = {2015},
  url          = {http://arxiv.org/abs/1502.05477},
  eprinttype    = {arXiv},
  eprint       = {1502.05477},
  timestamp    = {Mon, 13 Aug 2018 16:48:08 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/SchulmanLMJA15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{KL,
 ISSN = {00034851},
 URL = {http://www.jstor.org/stable/2236703},
 author = {S. Kullback and R. A. Leibler},
 journal = {The Annals of Mathematical Statistics},
 number = {1},
 pages = {79--86},
 publisher = {Institute of Mathematical Statistics},
 title = {On Information and Sufficiency},
 urldate = {2023-06-15},
 volume = {22},
 year = {1951}
}

@inproceedings{zhang2018fully,
  title={Fully decentralized multi-agent reinforcement learning with networked agents},
  author={Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Basar, Tamer},
  booktitle={International Conference on Machine Learning},
  pages={5872--5881},
  year={2018},
  organization={PMLR}
}

@inproceedings{marot2018expert,
  title={Expert system for topological remedial action discovery in smart grids},
  author={Marot, Antoine and Donnot, Benjamin and Tazi, Sami and Panciatici, Patrick},
  booktitle={Mediterranean Conference on Power Generation, Transmission, Distribution and Energy Conversion (MEDPOWER 2018)},
  pages={1--6},
  year={2018},
  organization={IET}
}

@misc{acm, 
  title={Report congestion revenues TenneT TSO B.V. for the period January 2022 - December 2022}, 
  howpublished="\url{https://www.acm.nl/system/files/documents/report-auction-receipts-tennet-tso-2022.pdf.}", 
  journal={ACM.nl}, 
  author={ACM}, 
  year={2023}, 
  month={Feb},
  note = "[Online; accessed 09-07-2024]"
}


@article{marot2022learning,
  title={Learning to run a power network with trust},
  author={Marot, Antoine and Donnot, Benjamin and Chaouache, Karim and Kelly, Adrian and Huang, Qiuhua and Hossain, Ramij-Raja and Cremer, Jochen L},
  journal={Electric Power Systems Research},
  volume={212},
  pages={108487},
  year={2022},
  publisher={Elsevier}
}

@article{yu2022surprising,
  title={The surprising effectiveness of ppo in cooperative multi-agent games},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24611--24624},
  year={2022}
}

@inproceedings{christianos2021scaling,
  title={Scaling multi-agent reinforcement learning with selective parameter sharing},
  author={Christianos, Filippos and Papoudakis, Georgios and Rahman, Muhammad A and Albrecht, Stefano V},
  booktitle={International Conference on Machine Learning},
  pages={1989--1998},
  year={2021},
  organization={PMLR}
}

@article{liaw2018tune,
    title={Tune: A Research Platform for Distributed Model Selection and Training},
    author={Liaw, Richard and Liang, Eric and Nishihara, Robert
            and Moritz, Philipp and Gonzalez, Joseph E and Stoica, Ion},
    journal={arXiv preprint arXiv:1807.05118},
    year={2018}
}

@article{liang2017ray,
  title={Ray rllib: A composable and scalable reinforcement learning library},
  author={Liang, Eric and Liaw, Richard and Nishihara, Robert and Moritz, Philipp and Fox, Roy and Gonzalez, Joseph and Goldberg, Ken and Stoica, Ion},
  journal={arXiv preprint arXiv:1712.09381},
  volume={85},
  year={2017},
  publisher={ArXiv}
}

@misc{grid2op,
    author = {Benjamin Donnot},
    title = {{Grid2op- A testbed platform to model sequential decision making in power systems}},
    year = {2020},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://GitHub.com/rte-france/grid2op}},
}

@misc{l2rpnbaselines,
    author = {Benjamin Donnot},
    title = {{L2RPN Baselines- Repository hosting reference baselines for the L2RPN challenge}},
    year = {2020},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/Grid2op/l2rpn-baselines/}},
}


@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{dayan1992feudal,
  title={Feudal reinforcement learning},
  author={Dayan, Peter and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={5},
  year={1992}
}

@article{morimoto2001acquisition,
  title={Acquisition of stand-up behavior by a real robot using hierarchical reinforcement learning},
  author={Morimoto, Jun and Doya, Kenji},
  journal={Robotics and Autonomous Systems},
  volume={36},
  number={1},
  pages={37--51},
  year={2001},
  publisher={Elsevier}
}

@incollection{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine learning proceedings 1994},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}

@article{koglin1982corrective,
  title={Corrective switching: a new dimension in optimal load flow},
  author={Koglin, Hans-Jurgen and M{\"u}ller, Holger},
  journal={International Journal of Electrical Power \& Energy Systems},
  volume={4},
  number={2},
  pages={142--149},
  year={1982},
  publisher={Elsevier}
}

@article{gridoptions,
    author = {Viebahn, Jan and Kop, Sjoerd and van Dijk, Joost and Budaya, Hariadi and Streefland, Marja and Barbieri, Davide and Champion, Paul and Jothy, Mario and Renault, Vincent and Tindemans, Simon},
    title = {GridOptions Tool: Real-World Day-Ahead Congestion Management using Topological Remedial Actions},
    journal = {CIGRE Session 2024},
    year = {2024},
    howpublished = {\url{https://cse.cigre.org/cse-n035/c2-gridoptions-tool-real-world-day-ahead-congestion-management-using-topological-remedial-actions.html}},
}

@inproceedings{lan2020ai,
  title={AI-based autonomous line flow control via topology adjustment for maximizing time-series ATCs},
  author={Lan, Tu and Duan, Jiajun and Zhang, Bei and Shi, Di and Wang, Zhiwei and Diao, Ruisheng and Zhang, Xiaohu},
  booktitle={2020 IEEE Power \& Energy Society General Meeting (PESGM)},
  pages={1--5},
  year={2020},
  organization={IEEE}
}

@article{dorfer2022power,
  title={Power grid congestion management via topology optimization with AlphaZero},
  author={Dorfer, Matthias and Fuxj{\"a}ger, Anton R and Kozak, Kristian and Blies, Patrick M and Wasserer, Marcel},
  journal={arXiv preprint arXiv:2211.05612},
  year={2022}
}

@article{ruiz2016security,
  title={Security-constrained transmission topology control MILP formulation using sensitivity factors},
  author={Ruiz, Pablo Ariel and Goldis, Evgeniy and Rudkevich, Aleksandr M and Caramanis, Michael C and Philbrick, C Russ and Foster, Justin M},
  journal={IEEE Transactions on Power Systems},
  volume={32},
  number={2},
  pages={1597--1605},
  year={2016},
  publisher={IEEE}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@inproceedings{little2021optimal,
  title={Optimal transmission topology for facilitating the growth of renewable power generation},
  author={Little, Emily and Bortolotti, Sandrine and Bourmaud, Jean-Yves and Karangelos, Efthymios and Perez, Yannick},
  booktitle={2021 IEEE Madrid PowerTech},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@article{heidarifar2021optimal,
  title={An optimal transmission line switching and bus splitting heuristic incorporating AC and N-1 contingency constraints},
  author={Heidarifar, Majid and Andrianesis, Panagiotis and Ruiz, Pablo and Caramanis, Michael C and Paschalidis, Ioannis Ch},
  journal={International Journal of Electrical Power \& Energy Systems},
  volume={133},
  pages={107278},
  year={2021},
  publisher={Elsevier}
}

@article{de2024imitation,
  title={Imitation Learning for Intra-Day Power Grid Operation through Topology Actions},
  author={de Jong, Matthijs and Viebahn, Jan and Shapovalova, Yuliya},
  journal={arXiv preprint arXiv:2407.19865},
  year={2024}
}

@article{beinert2023power,
  title={Power flow forecasts at transmission grid nodes using Graph Neural Networks},
  author={Beinert, Dominik and Holzh{\"u}ter, Clara and Thomas, Josephine M and Vogt, Stephan},
  journal={Energy and AI},
  volume={14},
  pages={100262},
  year={2023},
  publisher={Elsevier}
}
@misc{huawei,
    author = {EI Innovation Lab, Huawei Cloud, Huawei Technologies},
    title = {NeurIPS Competition 2020: Learning to Run a Power Network (L2RPN) - Robustness Track},
    year = {2020},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/AsprinChina/L2RPN_NIPS_2020_a_PPO_Solution}},
}

@article{osband2014near,
  title={Near-optimal reinforcement learning in factored mdps},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}

@misc{polimifactorization,
      title={State and Action Factorization in Power Grids}, 
      author={Gianvito Losapio and Davide Beretta and Marco Mussi and Alberto Maria Metelli and Marcello Restelli},
      year={2024},
      eprint={2409.04467},
      archivePrefix={arXiv},
      primaryClass={eess.SY},
      url={https://arxiv.org/abs/2409.04467}, 
}