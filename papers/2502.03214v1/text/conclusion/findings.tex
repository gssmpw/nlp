Our findings demonstrate that VLMs struggle with spatial reasoning in 3D vision and that there are significant performance differences between the tested VLMs. While they understand the task and manage to outperform random agents in simple spatial tasks, they struggle with more complex configurations and intricate problem properties. Interestingly, VLMs demonstrate stronger performance in 2D vision representations compared to text-based tasks. This suggests that visual alignment for 3D spatial reasoning continues to pose a significant challenge, underscoring persistent gaps in VLM capabilities and highlighting barriers to achieving human-level cognitive performance.