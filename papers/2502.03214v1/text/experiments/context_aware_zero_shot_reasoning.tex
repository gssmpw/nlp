The models employ Chain-of-Thought (CoT) reasoning \cite{wei2022chain} to break down complex problems into smaller sub-tasks, enhancing accuracy and interpretability (Appendix \ref{interaction}). We constrain VLMs’ context windows to the past two steps, incorporating state representations alongside the model’s action responses. This approach prioritizes extracting maximum value from limited experience to preserve the models’ sequential coherence and minimize computational overhead (Appendix \ref{sec:experiment_configs}). Operating within this context-aware zero-shot reasoning framework, the models interpret task requirements without examples,  drawing exclusively from pretrained knowledge, task instructions, and limited past interactions. 