We evaluate a selection of open- and closed-source VLMs that scored high on OpenCompass\footnote{OpenCompass Official Rankings: \\ \href{https://rank.opencompass.org.cn/leaderboard-multimodal}{https://rank.opencompass.org.cn/leaderboard-multimodal}} and which support multi-image inputs and a minimum context length of 800 tokens. Selected models are: Sonnet-3.5 \cite{claudesonnet35}, Gemini-2.0-flash \cite{gemini20flash}, GPT-4o \cite{gpt4o}, InternVL2.5-78B \cite{chen2024expanding}, LLaVA-OneVision-72B \cite{li2024llava}, Qwen2-72B \cite{Qwen2VL}. We use a temperature of 1.0, top-p of 0.95, and top-k of 50 for all open-source models. An overview of all models and their details can be found in the Appendix~\ref{app:models}.


