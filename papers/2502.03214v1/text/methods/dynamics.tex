\textbf{Game dynamics}\hspace{.3cm} In each episode, agents receive observations of the start and goal states, accompanied by task instructions. Agents apply move actions to geoms by referencing their unique color and shape combination and specifying the direction of intended movement. Geoms can be moved in cardinal directions (\textit{LEFT, RIGHT, UP, DOWN}), with actions formatted as "move $<$color$>$ $<$shape$>$ $<$direction$>$”:

\begin{verbatim}
"move blue sphere right"
\end{verbatim}

Actions are validated and applied if legal, with agents receiving updated board states regardless of the action’s success after each move command. Effective
and ineffective actions both result in valid new board states
but, respectively, decrease or increase the path length to
the goal state. Invalid moves, such as occupied destination
and out-of-bounds actions, fail to alter the board state, as
do illegal commands, which violate the instructed action
format. This action-perception loop repeats until the goal state is achieved or a step limit is reached. Due to limited context windows, VLM agents receive task instructions at each time step. System prompt instructions and a sample agent-environment interaction is provided in Appendix \ref{interaction}.
