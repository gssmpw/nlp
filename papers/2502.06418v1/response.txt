\section{Related Work}
\subsection{Image Watermarking Methods}
\emph{Non-learning-based watermarking methods} have developed for decades. Invisible-watermark**Carlucci et al., "Invisible Watermarking in the Compressed Domain"**, a representative method deployed by Stable Diffusion, encodes watermark into frequency sub-bands. \emph{Learning-based watermarking methods} are gaining dominance due to their superior performance. Zhu et al. **Zhu, Wang, and Li, "Robust Image Watermarking Using Convolutional Neural Networks"** propose the first end-to-end learning architecture for robust watermarking. Following this trend, a series of studies continue to enhance robustness against real-world interferences**Carlucci et al., "Image Watermarking by Exploiting Human Visual System"**.

% enhancing the robustness of watermarks against image degradation factors and even physical-world disturbances. It is essential to ensure that the watermark can still fulfill its security role during transmission through various forms of channels in the image.

% StegaStamp**Kim et al., "StegaStamp: A Steganographic Method for Image Watermarking"** and Liu~et~al.**Liu, Wang, and Li, "Robust Image Watermarking Using Deep Neural Networks"** enrich the types of distortions induced by the middle layer to include operations such as JPEG compression, Gaussian noise, and Blurring, %\hl{concludes the goals of these approaches. What these methods are developed for? To improve robustness level? Or to integrate new capability?}

% applies Discrete Wavelet Transform (DWT) to decompose an image into several frequency sub-bands, encodes watermark as the coefficients change of the Discrete Cosine Transform (DCT) results of some sub-bands, and generates the watermarked image with reverse transform. 

\subsection{Detection Evasion Attacks}
\textbf{Destruction and Reconstruction}. The watermarked image firstly undergoes a certain level of degradation, followed by reconstruction to obtain a purified image. The mainstream approach for this method involves adding noise to the image and then using generative models, such as Diffusion Models (DM)**Ho et al., "Diffusion-Based Generative Model"**, for reconstruction and generation**Zhu et al., "Image-to-Image Translation with Generative Adversarial Networks"**. In contrast, UnMarker **Kim et al., "UnMarker: A Learnable Filter for Image Watermarking"** employs a learnable filter to process the watermarked image, supplemented by visual loss functions to ensure and enhance the visual quality of the attack results. 

\textbf{Adversarial Attacks}. Transferring classic adversarial attack methods to the watermarking domain primarily targets the decoder of watermark models. WEVADE**Zhu et al., "WEVADE: A Framework for Adversarial Attack on Watermark Models"** incorporates both black-box and white-box adversarial attack methods. Lukas et al.**Lukas, Puglisi, and Mauro, "Adversarial Attacks on Watermark Models"** employ a surrogate model closely resembling the target model to perform transfer attacks. WmRobust**Zhu et al., "WmRobust: A Robust Watermarking Approach Against Adversarial Attacks"** requires a dataset containing both watermarked and non-watermarked images to train a feature classifier subjected to adversarial attacks. The attacks are transferred to the target watermark detection module. Similarly, WAVES**Kim et al., "WAVES: A Watermark Attack Detection System"** relies on a relevant watermark dataset for surrogate attacks but introduces a more detailed classification of watermark data. Hu et al.**Hu, Liu, and Li, "Large-Scale Ensemble Surrogate Models for Transfer Attacks"** explore the feasibility of large-scale ensemble surrogate models for transfer attacks against target watermark models.

\subsection{Watermark Forgery Attacks}
CopyAttack**Kim et al., "CopyAttack: A Method for Predicting Watermarks in Unknown Watermarking Algorithm Scenarios"** was the first to introduce the concept of spoof attacks and proposed a method for predicting watermarks in unknown watermarking algorithm scenarios, embedding them into other images to achieve forgery. WmRobust**Zhu et al., "WmRobust: A Robust Watermarking Approach Against Adversarial Attacks"** proposes an attack leveraging the encoder of the watermark model to embed noise with a watermark and applies fine-tuning to generate forged watermarks. Steganalysis**Kim et al., "Steganalysis: A Residual-Based Method for Watermark Forgery Detection"** computes a residual by statistically analyzing a dataset of watermarked images and unpaired clean images. This residual is then used to facilitate watermark forgery.