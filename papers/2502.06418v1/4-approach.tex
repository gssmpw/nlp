\section{DAPAO Attacks}
In this section, first, we present the feasibility study, demonstrating our observation of information leakage in robust watermarks. Next, we provide the theoretical analysis for method validation. Last, we introduce evasion and forgery attacks based on the observation.

% We empirically discover that learning-based watermarking systems mitigate distortion effects (e.g., compression) by expanding the regions where the watermark pattern is embedded or increasing its magnitude, ensuring the remaining watermark remains detectable. Besides the encoding part, the system trains the watermark decoder to extract watermarks more effectively, which can be understood as increasing the model's attention weight on watermark signals.

\subsection{Feasibility Study}\label{sec:pilot}
We empirically find that learning-based robust watermarking systems counteract distortion effects (e.g., compression) by expanding the regions where the watermark pattern is embedded or amplifying its magnitude, ensuring that the watermark remains detectable. Beyond the encoding process, these systems also train the watermark decoder to enhance extraction effectiveness, effectively increasing the model's attention to watermark signals.

We conduct a feasibility study to explore: \emph{If the strengthened watermark results in leakage that can be captured from images using a feature extraction network?} We embed watermarks in multiple images with the same robust watermarking algorithm and then input these watermarked images into a feature extraction network.

% figure
\begin{figure}[!t]
    \centering
    % Custom font size
    \includegraphics[width=\linewidth]{pics/feasiblity.png}   
    \vspace{-6mm}
    \caption{Demonstration of our feasibility study.}
    \label{fig:feasibility}
    \vspace{-3mm}
\end{figure}

As shown in Figure ~\ref{fig:feasibility}, we found that:
\begin{itemize}
    \item The multi-channel features obtained after feature extraction can capture patterns not easily noticeable by the human eye.
    \item These patterns are similar across different images.
    \item Not all features contain such leakage information.
\end{itemize}
% Based on the above experimental observations, we \underline{\textbf{D}}elve into the \underline{\textbf{A}}spect of the \underline{\textbf{PA}}radox \underline{\textbf{O}}f Robust Watermarks and propose the \textbf{DAPAO} attack.

The results shed light on learning watermark characteristics from distinguished patterns probably related to the watermark.

\begin{figure}[!t]
    \centering
    % Custom font size
    \includegraphics[width=\linewidth]{pics/overview.png} 
    
    % \vspace{-3mm}
    \caption{An overview of our attack.} 
    \label{fig:method-overview}
    \vspace{-3mm}
\end{figure}

\subsection{Robustness and Invisibility Trade-off}\label{sec:Method_Theory}
% \begin{definition}
% \label{def:inj}
% A encoder $\mathcal{E}:\mathcal{I} \times W \to Y$ is injective if for any $x,y\in X$ different, $f(x)\ne f(y)$.
% \end{definition}
As mentioned earlier Sec.~\ref{sec:background}, a complete watermarking framework can be divided into three components: encoder $\mathcal{E}$, decoder $\mathcal{D}$, and distortion layer $\mathcal{T}$. The decoder takes only a single watermarked image $I_{wm}$ as input. To achieve correct verification, the decoder must implicitly disentangle the image content from the embedded watermark information and correctly associate them to extract the watermark successfully.



% the decoder must implicitly decompose the watermarked image into image information and watermark information, matching the two to successfully extract the watermark information.

\begin{definition}
An image and watermark information: $I$, $wm \ \subset \{0,1\}^k$, the encoder is:
$$\mathcal{E}(I, wm)=I+\epsilon \cdot \underbrace{\phi(I,wm)}_W$$
the decoder is:
$$\mathcal{D}(I_{wm}) \to \underbrace{(\hat{I}, \hat{W})}_{{match}} \to \hat{wm}$$



$\epsilon$ is the embedding strength.The feature space of the image $\mathcal{P} = \{p_1, p_2,...,p_n\}$ consists of two subspaces for embedding information: 
$$\mathcal{P} = \mathcal{P}_r \bigoplus \mathcal{P}_c$$

Due to joint training, the encoder exhibits a similar implicit decomposition behavior, projecting the input image $I$ into two feature spaces, named as $P_r$ and $P_c$. The former is a more suitable embedding space for information hiding, while the latter is not. 

The encoder performs this mapping $\mathcal{E}(I,wm) \to I_{wm}$ by:
$$\phi(I,wm) = \mathop{\min}_{p\in \mathcal{P}_r}||wm - \mathcal{D}(\mathcal{E}(p,wm))||^2+\lambda||\mathcal{E}(p,wm)||$$

However, as robustness requirements are introduced and continuously strengthened, the encoder must encode more information to ensure the watermarkâ€™s resistance to attacks. When the $P_r$   space is fully utilized, the encoder is forced to use $P_c$ for watermark embedding, polluting the $P_c$ space.

\end{definition}

\begin{definition}
An intuitive definition of embeddable threshold is:
\begin{gather*}
C(I) = \sup_{W \in \mathcal{P}_r}{\frac{||W||_2}{||I||_2}} \\\\
s.t. PNSR(I, I+W) \ge TV
\end{gather*}
$TV$ represents the lower bound of the visual quality.
\end{definition}

\begin{proposition}
When the robustness requirement exceeds $C(I)$, a decline in visual quality is inevitable.
\end{proposition}

\begin{proof}
Let the distortion layer $\mathcal{T}$ introduce noise $\eta \sim \mathcal{T}$, with the requirement that
$$||wm-\mathcal{D}(I_{wm} + \eta)|| \le \mathcal{B}$$
$\mathcal{B}$ is the bit error rate. Considering the channel capacity as:
$$R=\frac{1}{2}\log(1+\frac{\epsilon^2||W||^2}{\delta_{\eta}^2})$$
% \vspace{-3mm}
To achieve $R\ge H(wm)$, the following conditions must be met:
$$
\epsilon||W|| \le \sqrt{(2^{2H(wm)}-1)\delta_{\eta^2}}
$$
$H(wm)$ represents the entropy of $wm$. 

When $\sqrt{(2^{2H(wm)}-1)\delta_{\eta^2}} > C(I)||I||_2$, the system cannot simultaneously satisfy both, and it is necessary to increase $C(I)$, introducing visual artifacts into the image. Detailed proof is provided in Appendix~\ref{sec:Appendix_Proofs}.
\end{proof}
% \vspace{-3mm}
The artifacts introduced by sacrificing invisibility contain watermark information, creating a security vulnerability where watermark information leakage occurs.

%\hl{lack of proof of artifacts contain watermark information }
% This, however, compromises visual quality, leading to more detectable visual artifacts. Moreover, these artifacts also contain watermark information, creating a security vulnerability where watermark information leakage occurs.

\subsection{Detection Evasion}\label{sec:Method_Evasion Attack}
Our method is illustrated in Figure~\ref{fig:method-overview}, Suppose we have an image $I_{wm}$, embedded with an unknown watermark $wm$. This image is fed into a feature extraction module $\mathcal{F}(\cdot)$, resulting in multi-channel features $\mathcal{F}(I_{wm})$. To automate the selection of features that capture potential information leakage, we perform clustering on the multi-channel features. Among the resulting clusters, we identify the two clusters with the smallest number of samples and extract their corresponding feature channel positions $\mathcal{W}$.

To achieve the goal of an evasion attack, we need to disrupt the leaked watermark information captured from $I_{wm}$.We formulate this process as an optimization problem: finding a perturbation $\delta$ that disrupts the leaked information while preserving the visual quality of the image. The formulation is as follows:
\begin{equation}
\label{eq:1}
\begin{split}
    \mathop{\min}_{\delta}-\mathcal{L}(\mathcal{W} \cdot \mathcal{F}(I_{wm}), \mathcal{W}\cdot \mathcal{F}(I_{wm} + \delta)) \\
    \mathrm{ s.t.} ||\delta||_{\infty} < \epsilon
\end{split}
\end{equation}

where $\mathcal{L}(\cdot,\cdot)$ is the loss function that measures the distance between two features, and $\epsilon$ is a perturbation budget.

We use Projected Gradient Descent (PGD)~\cite{PGD} to solve the optimization problem in Eq~\ref{eq:1}. Finally, we complete the attack through $I_{wm} + \delta$.

Our detailed algorithm is shown as 
 Algorithm~\ref{alg:evasion algo}.
 %in Appendix~\ref{sec:Appendix_Implementation Details}.

 % Similar to Sec~\ref{sec:Method_Evasion Attack}, as shown in Figure ~\ref{fig:method-overview},

\subsection{Forgery Attack}
As shown in Figure~\ref{fig:method-overview}, we first use the feature extraction module and clustering algorithm to extract features containing leaked watermark information, from $I_{wm}$. To achieve the goal of spoofing, we still need to extract the leaked information. Therefore, this process can be formulated as the following optimization problem:
\begin{equation}
\label{eq:2}
\begin{split}
     \mathop{\min}_{\delta}-\mathcal{L}(\mathcal{W} \cdot \mathcal{F}(I_{wm}), \mathcal{W}\cdot \mathcal{F}(I_{wm} + \delta)) \\
    \mathrm{ s.t.} ||\delta||_{\infty} < \epsilon
\end{split}
\end{equation}
\vspace{-4mm}

where $\epsilon$ is a perturbation budget, and 
 this process is identical to the above evasion attack, referred to as Stage \uppercase\expandafter{\romannumeral1}.
However, the learned $\delta$ alone cannot fulfill the forgery purpose for \emph{semantic watermarking}. Based on the theory discussed earlier (See Sec.~\ref{sec:Method_Theory}), we need to consider the coupling effect between the semantics and watermark. After the optimization in Eq~\ref{eq:2} is completed, an additional optimization term should be included to further find another perturbation, $\delta_s$, which can be described as:
\begin{equation}
\label{eq:3}
\begin{split}
     \mathop{\min}_{\delta}\mathcal{L}((1-\mathcal{W}) \cdot \mathcal{F}(I_{wm}+\delta), (1-\mathcal{W})\cdot \mathcal{F}(I' + \delta_s)) \\
    \mathrm{ s.t.} ||\delta_s||_{\infty} < \epsilon
\end{split}
\end{equation}
This process is referred to as Stage \uppercase\expandafter{\romannumeral2}.
We use Projected Gradient Descent (PGD)~\cite{PGD} to solve the optimization problem in Eq~\ref{eq:2} and Eq~\ref{eq:3}.
Finally, we complete the attack through $\{I' - \delta\}$ or $\{I' - \delta + \delta_s \}$.

Our detailed algorithm is shown as Algorithm~\ref{alg:spoof algo}
%in Appendix~\ref{sec:Appendix_Implementation Details}.