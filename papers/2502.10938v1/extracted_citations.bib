@article{Goedel1931,
  added-at = {2010-07-22T15:48:09.000+0200},
  author = {Gödel, Kurt},
  biburl = {https://www.bibsonomy.org/bibtex/2a87070d102ce701aa6f8d59bd537a432/voj},
  interhash = {8c9b154775c8f13dc1d3c9e638386bfc},
  intrahash = {a87070d102ce701aa6f8d59bd537a432},
  journal = {Monatshefte für Mathematik und Physik},
  keywords = {foundations mathematics},
  number = 1,
  pages = {173--198},
  timestamp = {2010-07-22T15:48:09.000+0200},
  title = {Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme},
  volume = 38,
  year = 1931
}

@article{Hilbert1926,
author = {Hilbert, D.},
journal = {Mathematische Annalen},
language = {ger},
pages = {161-190},
title = {Über das Unendliche},
url = {http://eudml.org/doc/159124},
volume = {95},
year = {1926},
}

@article{Kleene-recursive,
 ISSN = {00029947, 10886850},
 URL = {http://www.jstor.org/stable/1990131},
 author = {S. C. Kleene},
 journal = {Transactions of the American Mathematical Society},
 number = {1},
 pages = {41--73},
 publisher = {American Mathematical Society},
 title = {Recursive Predicates and Quantifiers},
 urldate = {2025-01-24},
 volume = {53},
 year = {1943}
}

@book{algo,
author = {Kleinberg, Jon and Tardos, Eva},
title = {Algorithm Design},
year = {2005},
isbn = {0321295358},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
address = {USA}
}

@book{arora_complexity,
author = {Arora, Sanjeev and Barak, Boaz},
title = {Computational Complexity: A Modern Approach},
year = {2009},
isbn = {0521424267},
publisher = {Cambridge University Press},
address = {USA},
edition = {1st},
abstract = {This beginning graduate textbook describes both recent achievements and classical results of computational complexity theory. Requiring essentially no background apart from mathematical maturity, the book can be used as a reference for self-study for anyone interested in complexity, including physicists, mathematicians, and other scientists, as well as a textbook for a variety of courses and seminars. More than 300 exercises are included with a selected hint set.}
}

@misc{hao2024planningrigorgeneralpurposezeroshot,
      title={Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming}, 
      author={Yilun Hao and Yang Zhang and Chuchu Fan},
      year={2024},
      eprint={2410.12112},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.12112}, 
}

@article{liu2023llmp,
  title={LLM+P: Empowering Large Language Models with Optimal Planning Proficiency},
  author={Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
  journal={arXiv preprint arXiv:2304.11477},
  year={2023}
}

@inproceedings{pal,
author = {Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
title = {PAL: program-aided language models},
year = {2023},
publisher = {JMLR.org},
abstract = {Large language models (LLMs) have demonstrated an impressive ability to perform arithmetic and symbolic reasoning tasks, when provided with a few examples at test time ("few-shot prompting"). Much of this success can be attributed to prompting methods such as "chain-of-thought", which employ LLMs for both understanding the problem description by decomposing it into steps, as well as solving each step of the problem. While LLMs seem to be adept at this sort of step-by-step decomposition, LLMs often make logical and arithmetic mistakes in the solution part, even when the problem is decomposed correctly. In this paper, we present Program-Aided Language models (PAL): a novel approach that uses the LLM to read natural language problems and generate programs as the intermediate reasoning steps, but offloads the solution step to a runtime such as a Python interpreter. With PAL, decomposing the natural language problem into runnable steps remains the only learning task for the LLM, while solving is delegated to the interpreter. We demonstrate this synergy between a neural LLM and a symbolic interpreter across 13 mathematical, symbolic, and algorithmic reasoning tasks from BIG-Bench Hard and others. In all these natural language reasoning tasks, generating code using an LLM and reasoning using a Python interpreter leads to more accurate results than much larger models. For example, PAL using CODEX achieves state-of-the-art few-shot accuracy on GSM8K, surpassing PaLM-540B which uses chain-of-thought by absolute 15\% top-1.},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {435},
numpages = {36},
location = {Honolulu, Hawaii, USA},
series = {ICML'23}
}

@article{turing1936computable,
  title={On computable numbers, with an application to the Entscheidungsproblem},
  author={Turing, Alan Mathison and others},
  journal={J. of Math},
  volume={58},
  number={345-363},
  pages={5},
  year={1936},
  publisher={Wiley Online Library}
}

