\section{Related Works}

% do we need a small section to introduce EDA, RTL, and why RTL understanding and generation is important
\textbf{Register Transfer Level in EDA.} 
% this part needs more refinement
% we may need some cites here
Register Transfer Level (RTL) is a critical abstraction in EDA that describes the flow of data between registers and the logical operations on that data. This level is typically expressed using HDLs, with Verilog being the most widely used HDL in the industry.
Consequently, the terms HDL and Verilog are used interchangeably in this work.
In modern hardware design, engineers begin with specifications in natural language, which are then manually translated into HDLs before synthesizing circuit elements~\citep{blocklove2023chip}. This manual translation process is prone to human errors, leading to potential design flaws and inefficiencies. Automating this translation can significantly reduce errors and streamline the design process.
Recent developments in artificial intelligence (AI) have enabled machine-based end-to-end translations, making this automation possible. And the ability to understand and generate Verilog code is crucial for advancing this automation in hardware design.
For an introduction of Verilog, please refer to Appendix~\ref{appendix:verilog_introduction}.


\textbf{LLMs for EDA.} 
Recent advancements in LLMs have significantly impacted EDA, marking a transformative shift in hardware design~\citep{chen2024dawn}. Researchers have examined the utilization of LLMs for Verilog code generation, with benchmarking results presented in~\citet{thakur2023benchmarking,liu2023verilogeval,lu2024rtllm} showing the potential of these models to mitigate the design challenges faced by hardware developers.
% need more check and refinement
Furthermore, significant achievements have been achieved in fine-tuning for Verilog code generation~\citep{chang2024data,thakur2024verigen}, general RTL generation~\citep{blocklove2023chip}, and EDA tool script generation~\citep{liu2023chipnemo,wu2024chateda}.
% we also need to mention eda script generation: chipnemo
By reducing the need for extensive expertise in specific hardware, LLMs enable hardware developers to quickly design intricate hardware systems~\citep{fu2023gpt4aigchip}.


\textbf{Fine-tuning LLMs for Verilog Generation.} 
Despite the great potential of state-of-the-art (SOTA) LLMs, \textit{e.g.}, OpenAI's GPT-4~\citep{achiam2023gpt}, in generating Verilog code, relying solely on them is insufficient due to the proprietary nature of hardware design. Besides, they are still limited in their ability to generate practical hardware designs~\citep{fu2023gpt4aigchip}.
To address these limitations, recent studies have fine-tuned open-source LLMs on curated hardware design datasets~\citep{liu2023verilogeval,chang2024data,thakur2024verigen,zhang2024mg}, which has been shown to improve LLMs' performance in generating Verilog code. 
However, effective use of LLMs in hardware design requires high-quality, domain-specific data.
Unfortunately, existing publicly available hardware datasets are often limited in size, complexity, or detail, hindering the effectiveness of LLMs in hardware design tasks.
For example, datasets used in~\citet{thakur2023benchmarking,lu2024rtllm} contain fewer than 200 data points, making them suitable only for benchmarking rather than effectively fine-tuning.
Meanwhile, other datasets, such as those employed in ~\citet{liu2023verilogeval,thakur2024verigen}, 
% may lack detailed descriptions, providing only high-level descriptions for each code piece. 
are overly simplistic, which hinder effective fine-tuning of LLMs.
% we may need some paragraphs to describe 'data is all you need' and 'mgverilog'
To improve alignment between natural language and Verilog code, \citet{chang2024data} translate Verilog files to an AST and then map nodes to natural language with a predefined template.
However, this method is limited to line-level Verilog code and the template-based descriptions lack semantic information. 
Furthermore, the MG-Verilog dataset~\citep{zhang2024mg}, despite featuring multi-level descriptions alongside code samples, is limited in size and its reliance on LLaMA2-70B-Chat for annotations raises quality concerns about the dataset.
% MG-Verilog~\citet{zhang2024mg} features multi-level descriptions alongside with code samples, but it is limited in size, and the reliance on LLaMA2-70B-Chat for annotation raises concerns about the quality of the dataset.
These alignment issues may hinder the fine-tuned LLMs' performance, leading to the generation of non-synthesizable or non-functional hardware source code.
% This weak alignment between natural language and Verilog code may hinder the fine-tuned LLMs' performance, resulting the generation of non-synthesizable or non-functional hardware source code.
% also, we may need to introduce 'natural language is not enough' here
To address the limitations of previous studies, we introduce a novel high-quality dataset that aligns natural language with Verilog code at multiple levels: line, block, and module. It includes both detailed and high-level descriptions, integrating open-source and proprietary code to enhance its diversity and applicability. Unlike prior efforts focused solely on Verilog generation, we are the first to consider the crucial task of Verilog understanding. This comprehensive dataset enables the development of a unified representation model, DeepRTL, which excels in both Verilog understanding and generation, paving the way for significant advancements in hardware design automation.
% Our work addresses the limitations of previous studies by introducing a novel high-quality dataset that aligns natural language with Verilog code at multiple levels: line, block, and module. It includes both detailed and high-level descriptions, integrating open-source and proprietary code to enhance its diversity and applicability. Unlike prior efforts focused solely on Verilog generation, we are the first to consider the crucial task of Verilog understanding. This comprehensive dataset enables the development of a unified representation model, DeepRTL, which excels in both Verilog understanding and generating, paving the way for significant advancements in hardware design automation.

\textbf{Curriculum Learning.} Curriculum learning is a training strategy inspired by human learning, where models are exposed to simpler tasks before advancing to more complex ones. This approach has been shown to accelerate convergence and improve model performance, particularly for tasks with hierarchical difficulty levels. Initially introduced in~\citet{bengio2009curriculum}, curriculum learning has been applied to various domains, including natural language processing~\citep{xu2020curriculum}, computer vision~\citep{wang2023efficienttrain}, and reinforcement learning~\citep{narvekar2020curriculum}. Recent work has demonstrated its efficacy in fine-tuning LLMs, where progressively increasing task complexity helps the models better capture intricate patterns~\citep{campos2021curriculum}. Notably, \citet{na2024curriculum} apply curriculum learning to code language models, achieving significant improvements in the accuracy of code execution tasks. In this work, we adapt curriculum learning to train DeepRTL, utilizing our structured dataset with descriptions at varying levels of detail. This approach significantly enhances the model's capabilities in both Verilog understanding and generation.