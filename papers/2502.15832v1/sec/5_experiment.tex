\section{Experimental Results}



\subsection{Baseline Models}
For the baseline models, we select OpenAI's GPT-4-turbo (GPT-4) and GPT-3.5-turbo (GPT-3.5), as well as the o1-preview model, OpenAI's latest reasoning model designed to address complex problems across diverse domains, including programming.
These models are chosen for their status as the most advanced general-purpose LLMs currently available, with demonstrated excellence in Verilog generation~\citep{chang2024data, thakur2024verigen, liu2024rtlcoder}. For a comparison with models specifically fine-tuned on Verilog, please refer to Appendix~\ref{appendix:comparison}.
% We do not select previously fine-tuned LLMs as baselines because they are either not open-sourced~\citep{pei2024betterv}, or their performance is only comparable or inferior to that of GPT-3.5~\citep{liu2023verilogeval,chang2024data,thakur2024verigen}. Additionally, it is non-trivial to reproduce their results.

\begin{table}[!ht]
    \centering
    \caption{Evaluation results on Verilog generation. Each cell displays the percentage of code samples, out of five trials, that successfully pass compilation (syntax column) or functional unit tests (function column). Best results are highlighted in bold.}
    \vspace{5pt}
    {\tiny
    \begin{tabular}{@{}|c|l|c|c|c|c|c|c|c|c|c|c|@{}}
    \hline
        \multicolumn{2}{|c|}{\multirow{2}{*}{Benchmark}} & \multicolumn{2}{|c|}{GPT-3.5} & \multicolumn{2}{|c|}{GPT-4} & \multicolumn{2}{|c|}{o1-preview} & \multicolumn{2}{|c|}{DeepRTL-220m} & \multicolumn{2}{|c|}{DeepRTL-16b} \\ \cline{3-12}
        \multicolumn{1}{|}{~} & ~ & syntax & function & syntax & function & syntax & function & syntax & function & syntax & function \\ \hline
        \multirow{10}{*}{Logic} & Johnson\_Counter & 40\% & 0\% & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% \\ \cline{2-12}
        ~ & alu & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% \\ \cline{2-12}
        ~ & edge\_detect & 60\% & 20\% & 100\% & 100\% & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% \\ \cline{2-12}
        ~ & freq\_div & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% \\ \cline{2-12}
        ~ & mux & 100\% & 100\% & 100\% & 40\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% \\ \cline{2-12}
        ~ & parallel2serial & 80\% & 0\% & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% \\ \cline{2-12}
        ~ & pulse\_detect & 60\% & 40\% & 100\% & 20\% & 100\% & 40\% & 100\% & 100\% & 100\% & 100\% \\ \cline{2-12}
        ~ & right\_shifter & 60\% & 60\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% \\ \cline{2-12}
        ~ & serial2parallel & 60\% & 0\% & 100\% & 0\% & 100\% & 20\% & 100\% & 0\% & 100\% & 0\% \\ \cline{2-12}
        ~ & width\_8to16 & 100\% & 0\% & 20\% & 0\% & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% \\ \hline
        \multirow{11}{*}{Arithmetic} & accu & 100\% & 0\% & 40\% & 0\% & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% \\ \cline{2-12}
        ~ & adder\_16bit & 40\% & 0\% & 20\% & 20\% & 40\% & 40\% & 100\% & 0\% & 60\% & 0\% \\ \cline{2-12}
        ~ & adder\_16bit\_csa & 80\% & 80\% & 0\% & 0\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% \\ \cline{2-12}
        ~ & adder\_32bit & 100\% & 0\% & 40\% & 0\% & 100\% & 0\% & 80\% & 0\% & 100\% & 0\% \\ \cline{2-12}
        ~ & adder\_64bit & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% & 100\% & 0\% \\ \cline{2-12}
        ~ & adder\_8bit & 100\% & 100\% & 40\% & 40\% & 100\% & 100\% & 80\% & 20\% & 100\% & 80\% \\ \cline{2-12}
        ~ & div\_16bit & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% \\ \cline{2-12}
        ~ & multi\_16bit & 80\% & 0\% & 100\% & 20\% & 100\% & 100\% & 100\% & 0\% & 100\% & 0\% \\ \cline{2-12}
        ~ & multi\_booth & 100\% & 0\% & 60\% & 0\% & 80\% & 40\% & 60\% & 0\% & 100\% & 0\% \\ \cline{2-12}
        ~ & multi\_pipe\_4bit & 60\% & 20\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% \\ \cline{2-12}
        ~ & multi\_pipe\_8bit & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% \\ \hline
        \multirow{10}{*}{Advanced} & 1x2nocpe & 40\% & 40\% & 80\% & 80\% & 100\% & 100\% & 100\% & 80\% & 100\% & 100\% \\ \cline{2-12}
        ~ & 1x4systolic & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% \\ \cline{2-12}
        ~ & 2x2systolic & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% \\ \cline{2-12}
        ~ & 4x4spatialacc & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% \\ \cline{2-12}
        ~ & fsm & 60\% & 0\% & 100\% & 0\% & 100\% & 20\% & 100\% & 100\% & 100\% & 100\% \\ \cline{2-12}
        ~ & macpe & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% & 0\% \\ \cline{2-12}
        ~ & 5state\_fsm & 100\% & 0\% & 100\% & 60\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% \\ \cline{2-12}
        ~ & 3state\_fsm & 20\% & 0\% & 80\% & 20\% & 100\% & 100\% & 100\% & 100\% & 100\% & 100\% \\ \cline{2-12}
        ~ & 4state\_fsm & 60\% & 40\% & 100\% & 80\% & 100\% & 20\% & 100\% & 100\% & 100\% & 100\% \\ \cline{2-12}
        ~ & 2state\_fsm & 80\% & 20\% & 100\% & 80\% & 100\% & 0\% & 100\% & 20\% & 0\% & 0\% \\ \hline
        \multicolumn{2}{|c|}{Success Rate} & 60.65\% & 20.00\% & 63.87\% & 27.74\% & \textbf{78.06\%} & \textbf{38.06}\% & \textbf{78.06\%} & 36.13\% & 76.13\% & \textbf{38.06}\% \\ \hline
        \multicolumn{2}{|c|}{Pass@1} & 32.26\% & 19.35\% & 51.61\% & 29.03\% & \textbf{74.19\%} & \textbf{35.48\%} & 70.97\% & 32.26\% & \textbf{74.19\%} & \textbf{35.48\%} \\ \hline
        \multicolumn{2}{|c|}{Pass@5} & \textbf{80.65\%} & 35.48\% & 77.42\% & 45.16\% & \textbf{80.65\%} & \textbf{51.61\%} & \textbf{80.65\%} & 41.94\% & 77.42\% & 38.71\% \\ \hline
    \end{tabular}
    }
    \label{tab:generation_results}
\end{table}

\subsection{Verilog Understanding}

As shown in Table~\ref{tab:understanding_results}, DeepRTL consistently outperforms GPT-4 across all evaluation metrics. Traditional metrics like BLEU and ROUGE offer inconsistent assessments due to their inability to capture semantic similarity accurately: while DeepRTL-16b excels in BLEU-4 and ROUGE-L, DeepRTL-220m leads in ROUGE-1 and ROUGE-2. In contrast, embedding similarity and GPT score provide a more accurate assessment of the models' capabilities in understanding Verilog code.
Compared to CodeT5+, the performance of DeepRTL-direct, which is trained directly without curriculum learning, highlights the effectiveness of our dataset. And the subsequent improvements when employing the curriculum learning strategy underscore its benefits.
Additionally, the poor performance of LLaMA2-70B-Chat underscores the unreliability of the MG-Verilog annotations~\cite{zhang2024mg}. 
To further validate our model's performance, we have conducted human evaluations, which show that DeepRTL-220m, GPT-4, and o1-preview achieve accuracies of 78\%, 72\%, and 67\%, respectively. These results align closely with the embedding similarity and GPT score metrics, further affirming the effectiveness of these evaluation methods.
We find that DeepRTL-220m outperforms DeepRTL-16b, likely due to the CodeT5+-220mâ€™s pre-training on a large corpus of paired software code and natural language data, which fosters better alignment between code and language. In contrast, CodeT5+-16b is primarily pre-trained on software code data and then fine-tuned on synthetic instruction data, lacking robust code-language alignment.
Moreover, despite its smaller size, DeepRTL-220m surpasses many billion-parameter models, underscoring the high quality of our dataset and the effectiveness of the curriculum learning strategy.


\subsection{Verilog Generation}
Given the inferior performance of models like CodeT5+ and DeepRTL-direct in the Verilog understanding task, our comparison focuses on the GPT series models.
As shown in Table~\ref{tab:generation_results}, OpenAI's o1-preview, the latest model designed to tackle complex tasks including programming, achieves the highest performance across all metrics. Nevertheless, our DeepRTL model exhibits comparable performance to o1-preview on several metrics and significantly surpasses GPT-4 in syntax correctness, Pass@1 functional accuracy, and overall functional success rate.
Notably, DeepRTL consistently generates highly accurate code in successful cases, often achieving a $100\%$ pass rate among the five generated samples, which underscores its reliability for practical applications. Furthermore, considering that OpenAI's models benefit from vast parameter sizes and extensive pre-training across diverse datasets, the performance of our more compact DeepRTL model is particularly impressive.
