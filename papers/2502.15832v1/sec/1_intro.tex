\section{Introduction}

% draft
The development of powerful large language models (LLMs), such as OpenAI's GPT-4~\citep{achiam2023gpt}, has brought transformative benefits to diverse fields~\citep{wei2024editable,jin2023adapt}, % do we need more cites here?
including electronic design automation (EDA).
% need more refinement
These models help streamline the hardware design process by generating hardware description language (HDL) code, like Verilog, from user-defined specifications~\citep{pearce2020dave,chang2023chipgpt}. 
The use of LLMs in EDA has opened new avenues for agile chip design, wherein hardware designers can specify requirements through natural language prompts, potentially boosting both creativity and efficiency in chip design processes.

Despite the adaptability of commercial LLMs like GPT-4 in the EDA domain, the proprietary nature of many designs necessitates the development of a tailored model, which requires fine-tuning a specialized model to ensure data security and customization for specific needs. Recent studies have attempted fine-tuning open-source LLMs for Verilog generation, demonstrating great potential for automated generation of Verilog code from high-level prompts~\citep{thakur2024verigen,chang2024data,zhang2024mg}. However, these efforts often focus solely on Verilog generation, neglecting the equally critical task of Verilog understanding, \textit{i.e.}, summarizing high-level functionality from Verilog code snippets using natural language. This capability is essential for effective communication among hardware designers, as it helps decipher complex code written by others, facilitating collaboration and comprehension. 
Moreover, even for Verilog generation, these works fail to establish a strong alignment between natural language and Verilog code, which potentially harms the models' performance.
% need more check and refinement
For example, \citet{thakur2024verigen} do not incorporate paired data of natural language and Verilog code in their dataset. 
\citet{chang2024data} propose mapping the Verilog Abstract Syntax Tree (AST) directly to natural language, but this approach is limited to line-level translation and produces descriptions that lack high-level semantics. 
To further bridge this gap, \citet{zhang2024mg} introduce the MG-Verilog dataset with multi-level descriptions alongside corresponding code samples, but its small size and reliance on LLaMA2-70B-Chat for annotations raise quality concerns.
Such poor alignment between natural language and Verilog code can degrade the generation performance, leading to generation of non-synthesizable or non-functional Verilog code.

To address these challenges, we introduce DeepRTL, a unified representation model that bridges Verilog understanding and generation. Achieving this requires an extensive collection of high-quality, hardware-specific datasets, which are scarce in the open-source community. To this end, we have meticulously curated a comprehensive Verilog dataset that ensures strong alignment between Verilog code and natural language across multiple levels. This dataset includes both open-source and proprietary Verilog design data. For the open-source data, we adopt the chain-of-thought (CoT) approach and use GPT-4, the most advanced model available, to generate precise natural language descriptions of the Verilog code. 
Human evaluations have verified that these annotations are approximately $90\%$ accurate, underscoring the dataset's high quality and reliability for training. 
For the proprietary data, we engage a team of professional hardware designers to provide detailed annotations, which capture intricate design features and further boost the dataset's quality.
This comprehensive dataset enables us to develop DeepRTL capable of both understanding and generating Verilog code. By integrating high-quality annotations, the model enhances efficiency and accuracy in various design tasks.

We are the first to integrate the task of Verilog understanding into our model, addressing a significant gap left by previous works that focus exclusively on Verilog generation. These earlier efforts lack benchmarks to evaluate LLMs' understanding capabilities of Verilog code, prompting us to introduce the first benchmark for Verilog understanding.
% need more check
Our benchmark comprises one hundred diverse, high-quality Verilog designs and we have collaborated with professional engineers to develop precise high-level functional descriptions, which have been meticulously cross-checked by multiple designers to ensure their accuracy.
% need more check and refinement
In the software domain, traditional metrics like BLEU~\citep{papineni2002bleu} and ROUGE~\citep{lin2004rouge} scores % cite
have been commonly used to assess the similarity between generated code summaries and ground truth annotations~\citep{wang2023codet5+}. % maybe we need more cites here 
However, these metrics focus primarily on lexical overlap and often fail to capture the true semantic meaning of the descriptions. 
To tackle this issue, we take the initiative to apply embedding similarity and GPT score for evaluation, both of which assess semantic similarity more effectively.
% To tackle this issue, we introduce two novel metrics, embedding similarity and GPT score, that measure the semantic similarity of descriptions. 
Embedding similarity utilizes vector representations for semantic alignment, while GPT score uses advanced LLMs to assess the semantic coherence between descriptions. 
These metrics provide a more accurate means of evaluating generated descriptions against the ground truth annotations.
% These metrics offer a more accurate way to evaluate the generated descriptions, ensuring they are assessed more effectively against the ground truth annotations. 

In our work, we employ CodeT5+~\citep{wang2023codet5+}, a family of encoder-decoder code foundation LLMs pre-trained on extensive software code, as the foundation to fine-tune on our dataset. 
% need more check and refinement
% This architecture offers flexibility in task design, making it suitable for a wide range of code understanding and generation applications. For example, the encoder can generate embeddings for code snippets and natural language summaries, which can be utilized in various downstream tasks. 
Since the dataset includes hierarchical code summaries across multiple levels—line, block, and module, providing both detailed and high-level functional descriptions—we adapt curriculum learning for training.
% we implement a progressive training strategy.
This begins with fine-tuning on line-level and block-level data, subsequently advancing to more complex module-level content. Such a structured approach enables the model to incrementally build foundational knowledge, which significantly enhances its performance in both Verilog understanding and generation tasks.
% need more check and refinement
In Verilog understanding, DeepRTL significantly outperforms GPT-4 across all metrics on the newly established understanding benchmark. In Verilog generation, it achieves comparable performance to OpenAI's o1-preview, the latest model designed for complex reasoning tasks including programming on the latest generation benchmark by~\citet{chang2024natural}.