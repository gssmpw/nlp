@inproceedings{sotopia-pi,
    title = "{SOTOPIA}-{\mbox{$\pi$}}: Interactive Learning of Socially Intelligent Language Agents",
    author = "Wang, Ruiyi  and
      Yu, Haofei  and
      Zhang, Wenxin  and
      Qi, Zhengyang  and
      Sap, Maarten  and
      Bisk, Yonatan  and
      Neubig, Graham  and
      Zhu, Hao",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics"
}

@article{sotopia-steering,
  title={Dialogue Action Tokens: Steering Language Models in Goal-Directed Dialogue with a Multi-Turn Planner},
  author={Li, Kenneth and Wang, Yiming and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:2406.11978},
  year={2024}
}

@inproceedings{
zhou2024sotopia,
title={{SOTOPIA}: Interactive Evaluation for Social Intelligence in Language Agents},
author={Xuhui Zhou and Hao Zhu and Leena Mathur and Ruohong Zhang and Haofei Yu and Zhengyang Qi and Louis-Philippe Morency and Yonatan Bisk and Daniel Fried and Graham Neubig and Maarten Sap},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@misc{2023opencompass,
    title={OpenCompass: A Universal Evaluation Platform for Foundation Models},
    author={OpenCompass Contributors},
    howpublished = {\url{https://github.com/open-compass/opencompass}},
    year={2023}
}

@article{zhang2024imperative,
  title={The imperative of conversation analysis in the era of llms: A survey of tasks, techniques, and trends},
  author={Zhang, Xinghua and Yu, Haiyang and Li, Yongbin and Wang, Minzheng and Chen, Longze and Huang, Fei},
  journal={arXiv preprint arXiv:2409.14195},
  year={2024}
}

@inproceedings{zhou-etal-2024-real,
    title = "Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With {LLM}s",
    author = "Zhou, Xuhui  and
      Su, Zhe  and
      Eisape, Tiwalayo  and
      Kim, Hyunwoo  and
      Sap, Maarten",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics"
}

@article{zhang2024revealing,
  title={Revealing the Challenge of Detecting Character Knowledge Errors in LLM Role-Playing},
  author={Zhang, Wenyuan and Sheng, Jiawei and Nie, Shuaiyi and Zhang, Zefeng and Zhang, Xinghua and He, Yongquan and Liu, Tingwen},
  journal={arXiv preprint arXiv:2409.11726},
  year={2024}
}

@inproceedings{shao-etal-2023-character,
    title = "Character-{LLM}: A Trainable Agent for Role-Playing",
    author = "Shao, Yunfan  and
      Li, Linyang  and
      Dai, Junqi  and
      Qiu, Xipeng",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics"
}

@article{de2023advancing,
  title={Advancing theorizing about fast-and-slow thinking},
  author={De Neys, Wim},
  journal={Behavioral and Brain Sciences},
  volume={46},
  pages={e111},
  year={2023}
}

@article{lin2024swiftsage,
  title={Swiftsage: A generative agent with fast and slow thinking for complex interactive tasks},
  author={Lin, Bill Yuchen and Fu, Yicheng and Yang, Karina and Brahman, Faeze and Huang, Shiyu and Bhagavatula, Chandra and Ammanabrolu, Prithviraj and Choi, Yejin and Ren, Xiang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{li2023metaagents,
  title={Metaagents: Simulating interactions of human behaviors for llm-based task-oriented coordination via collaborative generative agents},
  author={Li, Yuan and Zhang, Yixuan and Sun, Lichao},
  journal={arXiv preprint arXiv:2310.06500},
  year={2023}
}

@inproceedings{ijcai2024p890,
  title     = {Large Language Model Based Multi-agents: A Survey of Progress and Challenges},
  author    = {Guo, Taicheng and Chen, Xiuying and Wang, Yaqi and Chang, Ruidi and Pei, Shichao and Chawla, Nitesh V. and Wiest, Olaf and Zhang, Xiangliang},
  booktitle = {Proceedings of the Thirty-Third International Joint Conference on
               Artificial Intelligence, {IJCAI-24}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Kate Larson},
  pages     = {8048--8057},
  year      = {2024},
  month     = {8},
  note      = {Survey Track},
}

@inproceedings{ziems2023normbank,
  title={NormBank: A Knowledge Bank of Situational Social Norms},
  author={Ziems, Caleb and Dwivedi-Yu, Jane and Wang, Yi-Chia and Halevy, Alon and Yang, Diyi},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={7756--7776},
  year={2023}
}

@inproceedings{liu2024emollms,
  title={Emollms: A series of emotional large language models and annotation tools for comprehensive affective analysis},
  author={Liu, Zhiwei and Yang, Kailai and Xie, Qianqian and Zhang, Tianlin and Ananiadou, Sophia},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={5487--5496},
  year={2024}
}

@article{underwood1982perspective,
  title={Perspective-taking and altruism.},
  author={Underwood, Bill and Moore, Bert},
  journal={Psychological bulletin},
  volume={91},
  number={1},
  pages={143},
  year={1982},
  publisher={American Psychological Association}
}

@article{trotschel2011perspective,
  title={Perspective taking as a means to overcome motivational barriers in negotiations: When putting oneself into the opponent's shoes helps to walk toward agreements.},
  author={Tr{\"o}tschel, Roman and H{\"u}ffmeier, Joachim and Loschelder, David D and Schwartz, Katja and Gollwitzer, Peter M},
  journal={Journal of personality and social psychology},
  volume={101},
  number={4},
  pages={771},
  year={2011},
  publisher={American Psychological Association}
}

@article{min2024imitate,
  title={Imitate, explore, and self-improve: A reproduction report on slow-thinking reasoning systems},
  author={Min, Yingqian and Chen, Zhipeng and Jiang, Jinhao and Chen, Jie and Deng, Jia and Hu, Yiwen and Tang, Yiru and Wang, Jiapeng and Cheng, Xiaoxue and Song, Huatong and others},
  journal={arXiv preprint arXiv:2412.09413},
  year={2024}
}

@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@article{mou2024agentsense,
  title={Agentsense: Benchmarking social intelligence of language agents through interactive scenarios},
  author={Mou, Xinyi and Liang, Jingcong and Lin, Jiayu and Zhang, Xinnong and Liu, Xiawei and Yang, Shiyue and Ye, Rong and Chen, Lei and Kuang, Haoyu and Huang, Xuanjing and others},
  journal={arXiv preprint arXiv:2410.19346},
  year={2024}
}

@article{jones2024people,
  title={People cannot distinguish GPT-4 from a human in a Turing test},
  author={Jones, Cameron R and Bergen, Benjamin K},
  journal={arXiv preprint arXiv:2405.08007},
  year={2024}
}

@article{sejnowski2023large,
  title={Large language models and the reverse turing test},
  author={Sejnowski, Terrence J},
  journal={Neural computation},
  volume={35},
  number={3},
  pages={309--342},
  year={2023},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{huang2023humanity,
  title={On the humanity of conversational ai: Evaluating the psychological portrayal of llms},
  author={Huang, Jen-tse and Wang, Wenxuan and Li, Eric John and Lam, Man Ho and Ren, Shujie and Yuan, Youliang and Jiao, Wenxiang and Tu, Zhaopeng and Lyu, Michael},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}



@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th annual acm symposium on user interface software and technology},
  pages={1--22},
  year={2023}
}

@article{KIM2023107512,
title = {Anthropomorphic response: Understanding interactions between humans and artificial intelligence agents},
journal = {Computers in Human Behavior},
volume = {139},
pages = {107512},
year = {2023},
issn = {0747-5632},
author = {Joohee Kim and Il Im},
keywords = {Anthropomorphic response, Anthropomorphism, Artificial intelligence, Human and nonhuman interaction, Perceived cognitive intelligence, Perceived emotional intelligence},
abstract = {This study of anthropomorphic response to artificial intelligence begins with an extensive review of the literature and an identification of conceptual distinctions between anthropomorphism and anthropomorphic response. The authors develop an instrument for measuring how users form anthropomorphic response to interactions with AI chatbots. Amazon MTurk is used to recruit 120 users for a pilot study and 303 users for the main study. Participants respond to six scenarios depicting interactions with banking service chatbots of varying appearance and intelligence. Results show that anthropomorphic response depend on perceptions of agent appearance, cognitive intelligence, and emotional intelligence. Users perceive more humanness in highly intelligent but disembodied agents rather than in highly intelligent agents that have poorly designed appearances. And users who have strong tendencies to anthropomorphize non-sentient entities are less likely to form anthropomorphic response when interacting with agents with high cognitive intelligence. The study enhances understandings about human/AI interactions. It provides directions for future research regarding anthropomorphic response and provide directions for future research on designing and using artificial agents.}
}

@inproceedings{choi-etal-2023-llms,
    title = "Do {LLM}s Understand Social Knowledge? Evaluating the Sociability of Large Language Models with {S}oc{KET} Benchmark",
    author = "Choi, Minje  and
      Pei, Jiaxin  and
      Kumar, Sagar  and
      Shu, Chang  and
      Jurgens, David",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    pages = "11370--11403",
    abstract = "Large language models (LLMs) have been shown to perform well at a variety of syntactic, discourse, and reasoning tasks. While LLMs are increasingly deployed in many forms including conversational agents that interact with humans, we lack a grounded benchmark to measure how well LLMs understand social language. Here, we introduce a new theory-driven benchmark, SocKET, that contains 58 NLP tasks testing social knowledge which we group into five categories: humor {\&} sarcasm, offensiveness, sentiment {\&} emotion, and trustworthiness. In tests on the benchmark, we demonstrate that current models attain only moderate performance but reveal significant potential for task transfer among different types and categories of tasks, which were predicted from theory. Through zero-shot evaluations, we show that pretrained models already possess some innate but limited capabilities of social language understanding and training on one category of tasks can improve zero-shot testing on others. Our benchmark provides a systematic way to analyze model performance on an important dimension of language and points to clear room for improvement to build more socially-aware LLMs. The resources are released at https://github.com/minjechoi/SOCKET."
}

@inproceedings{sap2022neural,
  title={Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs},
  author={Sap, Maarten and Le Bras, Ronan and Fried, Daniel and Choi, Yejin},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={3762--3780},
  year={2022}
}

@article{mou2024individual,
  title={From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents},
  author={Mou, Xinyi and Ding, Xuanwen and He, Qi and Wang, Liang and Liang, Jingcong and Zhang, Xinnong and Sun, Libo and Lin, Jiayu and Zhou, Jie and Huang, Xuanjing and others},
  journal={arXiv preprint arXiv:2412.03563},
  year={2024}
}

@article{chen2023money,
      title={Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena}, 
      author={Jiangjie Chen and Siyu Yuan and Rong Ye and Bodhisattwa Prasad Majumder and Kyle Richardson},
      year={2023},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{lan-etal-2024-llm,
    title = "{LLM}-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay",
    author = "Lan, Yihuai  and
      Hu, Zhiqiang  and
      Wang, Lei  and
      Wang, Yang  and
      Ye, Deheng  and
      Zhao, Peilin  and
      Lim, Ee-Peng  and
      Xiong, Hui  and
      Wang, Hao",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    pages = "128--145",
    abstract = "This paper explores the open research problem of understanding the social behaviors of LLM-based agents. Using Avalon as a testbed, we employ system prompts to guide LLM agents in gameplay. While previous studies have touched on gameplay with LLM agents, research on their social behaviors is lacking. We propose a novel framework, tailored for Avalon, features a multi-agent system facilitating efficient communication and interaction. We evaluate its performance based on game success and analyze LLM agents' social behaviors. Results affirm the framework`s effectiveness in creating adaptive agents and suggest LLM-based agents' potential in navigating dynamic social interactions. By examining collaboration and confrontation behaviors, we offer insights into this field`s research and applications."
}


@inproceedings{sap-etal-2022-neural,
    title = "Neural Theory-of-Mind? On the Limits of Social Intelligence in Large {LM}s",
    author = "Sap, Maarten  and
      Le Bras, Ronan  and
      Fried, Daniel  and
      Choi, Yejin",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    pages = "3762--3780",
    abstract = "Social intelligence and Theory of Mind (TOM), i.e., the ability to reason about the different mental states, intents, and reactions of all people involved, allows humans to effectively navigate and understand everyday social interactions. As NLP systems are used in increasingly complex social situations, their ability to grasp social dynamics becomes crucial.In this work, we examine the open question of social intelligence and Theory of Mind in modern NLP systems from an empirical and theorybased perspective. We show that one of today`s largest language models (GPT-3; Brown et al., 2020) lacks this kind of social intelligence out-of-the box, using two tasks: SocialIQa (Sap et al., 2019), which measure models' ability to understand intents and reactions of participants of social interactions, and ToMi (Le, Boureau, and Nickel, 2019), which measures whether models can infer mental states and realities of participants of situations.Our results show that models struggle substantially at these Theory of Mind tasks, with well-below-human accuracies of 55{\%} and 60{\%} on SocialIQa and ToMi, respectively. To conclude, we draw on theories from pragmatics to contextualize this shortcoming of large language models, by examining the limitations stemming from their data, neural architecture, and training paradigms. Challenging the prevalent narrative that only scale is needed, we posit that person-centric NLP approaches might be more effective towards neural Theory of Mind."
}

@inproceedings{duan2024reta,
  title={ReTA: Recursively Thinking Ahead to Improve the Strategic Reasoning of Large Language Models},
  author={Duan, Jinhao and Wang, Shiqi and Diffenderfer, James and Sun, Lichao and Chen, Tianlong and Kailkhura, Bhavya and Xu, Kaidi},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={2232--2246},
  year={2024}
}

@inproceedings{deng2023plug,
  title={Plug-and-play policy planner for large language model powered dialogue agents},
  author={Deng, Yang and Zhang, Wenxuan and Lam, Wai and Ng, See-Kiong and Chua, Tat-Seng},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{chang-chen-2024-injecting,
    title = "Injecting Salesperson`s Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning",
    author = "Chang, Wen  and
      Chen, Yun-Nung",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "3798--3812",
    abstract = "Recent research in dialogue systems focuses on two main categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD systems help users complete specific tasks, while open-domain systems aim to create engaging conversations. However, user intents often emerge during interactions. A recent study introduced SalesBot, simulating dialogues that transition from chit-chat to task-oriented scenarios to train sales agents. Unfortunately, the initial data lacked smooth transitions and coherent long dialogues, resulting in unnatural interactions. This paper presents SalesBot 2.0, an improved dataset leveraging commonsense knowledge from large language models (LLMs) through strategic prompting. Additionally, we introduce SalesAgent, a novel model trained on salesperson interactions using chain-of-thought (CoT) reasoning. This model excels in transitioning topics, understanding user intents, and selecting appropriate strategies.Experiments with diverse user simulations validate our method`s effectiveness in controlling dialogue strategies in LLMs. SalesBot 2.0 enhances coherence and reduces aggression, improving model learning for sales-customer interactions."
}

@inproceedings{feng2023towards,
  title={Towards LLM-driven Dialogue State Tracking},
  author={Feng, Yujie and Lu, Zexin and Liu, Bo and Zhan, Liming and Wu, Xiao-Ming},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={739--755},
  year={2023}
}

@inproceedings{chiang2024enhancing,
  title={Enhancing AI-Assisted Group Decision Making through LLM-Powered Devil's Advocate},
  author={Chiang, Chun-Wei and Lu, Zhuoran and Li, Zhuoyan and Yin, Ming},
  booktitle={Proceedings of the 29th International Conference on Intelligent User Interfaces},
  pages={103--119},
  year={2024}
}

@article{galin2009proposal,
  title={Proposal sequence and the endowment effect in negotiations},
  author={Galin, Amira},
  journal={International Journal of Conflict Management},
  volume={20},
  number={3},
  pages={212--227},
  year={2009},
  publisher={Emerald Group Publishing Limited}
}

@book{thompson2015mind,
  title={The mind and heart of the negotiator},
  author={Thompson, Leigh L},
  year={2015},
  publisher={Pearson}
}

@misc{deutsch1973resolution,
  title={The resolution of conflict: Constructive and destructive processes},
  author={Deutsch, Morton},
  year={1973},
  publisher={Yale University Press}
}

@book{thompson2006negotiation,
  title={Negotiation theory and research},
  author={Thompson, Leigh L},
  year={2006},
  publisher={Psychology Press}
}

@book{korobkin2024negotiation,
  title={Negotiation theory and strategy},
  author={Korobkin, Russell},
  year={2024},
  publisher={Aspen Publishing}
}

@article{smith1987conflict,
  title={Conflict and negotiation: Trends and emerging issues},
  author={Smith, William P},
  journal={Journal of Applied Social Psychology},
  volume={17},
  number={7},
  pages={641--677},
  year={1987},
  publisher={Wiley Online Library}
}

@article{froman1970compromise,
  title={Compromise and logroll: Comparing the efficiency of two bargaining processes},
  author={Froman Jr, Lewis A and Cohen, Michael D},
  journal={Behavioral Science},
  volume={15},
  number={2},
  pages={180--183},
  year={1970},
  publisher={Wiley Online Library}
}

@article{tripp1992evaluation,
  title={An evaluation of dependent variables in experimental negotiation studies: Impasse rates and Pareto efficiency},
  author={Tripp, Thomas M and Sondak, Harris},
  journal={Organizational Behavior and Human Decision Processes},
  volume={51},
  number={2},
  pages={273--295},
  year={1992},
  publisher={Elsevier}
}

@article{kang2024mindstar,
  title={Mindstar: Enhancing math reasoning in pre-trained llms at inference time},
  author={Kang, Jikun and Li, Xin Zhe and Chen, Xi and Kazemi, Amirreza and Sun, Qianyi and Chen, Boxing and Li, Dong and He, Xu and He, Quan and Wen, Feng and others},
  journal={arXiv preprint arXiv:2405.16265},
  year={2024}
}

@inproceedings{bain1995framework,
  title={A Framework for Behavioural Cloning.},
  author={Bain, Michael and Sammut, Claude},
  booktitle={Machine Intelligence 15},
  pages={103--129},
  year={1995}
}

@article{isloor1980deadlock,
  title={The Deadlock Problem: An Overview.},
  author={Isloor, Sreekaanth S and Marsland, T Anthony},
  journal={Computer},
  volume={13},
  number={9},
  pages={58--78},
  year={1980},
  publisher={Citeseer}
}

@article{wu2024thinking,
  title={Thinking llms: General instruction following with thought generation},
  author={Wu, Tianhao and Lan, Janice and Yuan, Weizhe and Jiao, Jiantao and Weston, Jason and Sukhbaatar, Sainbayar},
  journal={arXiv preprint arXiv:2410.10630},
  year={2024}
}

@inproceedings{stasaski2020cima,
  title={CIMA: A large open access dialogue dataset for tutoring},
  author={Stasaski, Katherine and Kao, Kimberly and Hearst, Marti A},
  booktitle={Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications},
  pages={52--64},
  year={2020}
}

@inproceedings{he2018decoupling,
  title={Decoupling Strategy and Generation in Negotiation Dialogues},
  author={He, He and Chen, Derek and Balakrishnan, Anusha and Liang, Percy},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={2333--2343},
  year={2018}
}

@inproceedings{yang-etal-2021-improving,
    title = "Improving Dialog Systems for Negotiation with Personality Modeling",
    author = "Yang, Runzhe  and
      Chen, Jingxiao  and
      Narasimhan, Karthik",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pages = "681--693",
    abstract = "In this paper, we explore the ability to model and infer personality types of opponents, predict their responses, and use this information to adapt a dialog agent`s high-level strategy in negotiation tasks. Inspired by the idea of incorporating a theory of mind (ToM) into machines, we introduce a probabilistic formulation to encapsulate the opponent`s personality type during both learning and inference. We test our approach on the CraigslistBargain dataset (He et al. 2018) and show that our method using ToM inference achieves a 20{\%} higher dialog agreement rate compared to baselines on a mixed population of opponents. We also demonstrate that our model displays diverse negotiation behavior with different types of opponents."
}

@inproceedings{stasaski-etal-2020-cima,
    title = "{CIMA}: A Large Open Access Dialogue Dataset for Tutoring",
    author = "Stasaski, Katherine  and
      Kao, Kimberly  and
      Hearst, Marti A.",
    editor = "Burstein, Jill  and
      Kochmar, Ekaterina  and
      Leacock, Claudia  and
      Madnani, Nitin  and
      Pil{\'a}n, Ildik{\'o}  and
      Yannakoudakis, Helen  and
      Zesch, Torsten",
    booktitle = "Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = jul,
    year = "2020",
    address = "Seattle, WA, USA {\textrightarrow} Online",
    publisher = "Association for Computational Linguistics",
    pages = "52--64",
    abstract = "One-to-one tutoring is often an effective means to help students learn, and recent experiments with neural conversation systems are promising. However, large open datasets of tutoring conversations are lacking. To remedy this, we propose a novel asynchronous method for collecting tutoring dialogue via crowdworkers that is both amenable to the needs of deep learning algorithms and reflective of pedagogical concerns. In this approach, extended conversations are obtained between crowdworkers role-playing as both students and tutors. The CIMA collection, which we make publicly available, is novel in that students are exposed to overlapping grounded concepts between exercises and multiple relevant tutoring responses are collected for the same input. CIMA contains several compelling properties from an educational perspective: student role-players complete exercises in fewer turns during the course of the conversation and tutor players adopt strategies that conform with some educational conversational norms, such as providing hints versus asking questions in appropriate contexts. The dataset enables a model to be trained to generate the next tutoring utterance in a conversation, conditioned on a provided action strategy."
}

@inproceedings{zheng2024llamafactory,
  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  address={Bangkok, Thailand},
  publisher={Association for Computational Linguistics},
  year={2024},
}

@inproceedings{hulora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{li2024measuring,
  title={Measuring and controlling instruction (in) stability in language model dialogs},
  author={Li, Kenneth and Liu, Tianle and Bashkansky, Naomi and Bau, David and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  booktitle={First Conference on Language Modeling},
  year={2024}
}

@inproceedings{bleu,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {BLEU: a method for automatic evaluation of machine translation},
year = {2002},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.},
booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
pages = {311–318},
numpages = {8},
location = {Philadelphia, Pennsylvania},
series = {ACL '02}
}

@inproceedings{meteor,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
    author = "Banerjee, Satanjeev  and
      Lavie, Alon",
    editor = "Goldstein, Jade  and
      Lavie, Alon  and
      Lin, Chin-Yew  and
      Voss, Clare",
    booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    pages = "65--72"
}

@inproceedings{rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    pages = "74--81"
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@article{zhang2023wider,
  title={Wider and deeper llm networks are fairer llm evaluators},
  author={Zhang, Xinghua and Yu, Bowen and Yu, Haiyang and Lv, Yangyu and Liu, Tingwen and Huang, Fei and Xu, Hongbo and Li, Yongbin},
  journal={arXiv preprint arXiv:2308.01862},
  year={2023}
}

@article{hao2024llm,
  title={LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models},
  author={Hao, Shibo and Gu, Yi and Luo, Haotian and Liu, Tianyang and Shao, Xiyan and Wang, Xinyuan and Xie, Shuhua and Ma, Haodi and Samavedhi, Adithya and Gao, Qiyue and others},
  journal={arXiv preprint arXiv:2404.05221},
  year={2024}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@inproceedings{liu-etal-2024-mathbench,
    title = "{M}ath{B}ench: Evaluating the Theory and Application Proficiency of {LLM}s with a Hierarchical Mathematics Benchmark",
    author = "Liu, Hongwei  and
      Zheng, Zilong  and
      Qiao, Yuxuan  and
      Duan, Haodong  and
      Fei, Zhiwei  and
      Zhou, Fengzhe  and
      Zhang, Wenwei  and
      Zhang, Songyang  and
      Lin, Dahua  and
      Chen, Kai",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "6884--6915",
    abstract = "Recent advancements in large language models (LLMs) have showcased significant improvements in mathematics. However, traditional math benchmarks like GSM8k offer a unidimensional perspective, which fall short in providing a holistic assessment of the LLMs' math capabilities. To address this gap, we introduce MathBench, a new benchmark that rigorously assesses the mathematical capabilities of large language models. MathBench spans a wide range of mathematical disciplines, offering a detailed evaluation of both theoretical understanding and practical problem-solving skills. The benchmark progresses through five distinct stages, from basic arithmetic to college mathematics, and is structured to evaluate models at various depths of knowledge. Each stage includes theoretical questions and application problems, allowing us to measure a model`s mathematical proficiency and its ability to apply concepts in practical scenarios. MathBench aims to enhance the evaluation of LLMs' mathematical abilities, providing a nuanced view of their knowledge understanding levels and problem solving skills in a bilingual context."
}

@article{liu2024your,
  title={Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation},
  author={Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhou2023instruction,
  title={Instruction-following evaluation for large language models},
  author={Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le},
  journal={arXiv preprint arXiv:2311.07911},
  year={2023}
}

@article{tu2023characterchat,
  title={Characterchat: Learning towards conversational ai with personalized social support},
  author={Tu, Quan and Chen, Chuanqi and Li, Jinpeng and Li, Yanran and Shang, Shuo and Zhao, Dongyan and Wang, Ran and Yan, Rui},
  journal={arXiv preprint arXiv:2308.10278},
  year={2023}
}

@article{wang2023does,
  title={Does role-playing chatbots capture the character personalities? assessing personality traits for role-playing chatbots},
  author={Wang, Xintao and Fei, Yaying and Leng, Ziang and Li, Cheng},
  journal={arXiv preprint arXiv:2310.17976},
  year={2023}
}



@inproceedings{wang-etal-2024-incharacter,
    title = "{I}n{C}haracter: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews",
    author = "Wang, Xintao  and
      Xiao, Yunze  and
      Huang, Jen-tse  and
      Yuan, Siyu  and
      Xu, Rui  and
      Guo, Haoran  and
      Tu, Quan  and
      Fei, Yaying  and
      Leng, Ziang  and
      Wang, Wei  and
      Chen, Jiangjie  and
      Li, Cheng  and
      Xiao, Yanghua",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "1840--1873",
    abstract = "Role-playing agents (RPAs), powered by large language models, have emerged as a flourishing field of applications. However, a key challenge lies in assessing whether RPAs accurately reproduce the personas of target characters, namely their character fidelity. Existing methods mainly focus on the knowledge and linguistic patterns of characters. This paper, instead, introduces a novel perspective to evaluate the personality fidelity of RPAs with psychological scales. Overcoming drawbacks of previous self-report assessments on RPAs, we propose InCharacter, namely **In**terviewing **Character** agents for personality tests. Experiments include various types of RPAs and LLMs, covering 32 distinct characters on 14 widely used psychological scales. The results validate the effectiveness of InCharacter in measuring RPA personalities. Then, with InCharacter, we show that state-of-the-art RPAs exhibit personalities highly aligned with the human-perceived personalities of the characters, achieving an accuracy up to 80.7{\%}."
}

@inproceedings{sadeq-etal-2024-mitigating,
    title = "Mitigating Hallucination in Fictional Character Role-Play",
    author = "Sadeq, Nafis  and
      Xie, Zhouhang  and
      Kang, Byungkyu  and
      Lamba, Prarit  and
      Gao, Xiang  and
      McAuley, Julian",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    pages = "14467--14479",
    abstract = "Role-playing has wide-ranging applications in customer support, embodied agents, and computational social science. The influence of parametric world knowledge of large language models (LLMs) often causes role-playing characters to act out of character and to hallucinate about things outside the scope of their knowledge. In this work, we focus on the evaluation and mitigation of hallucination in fictional character role-play. We introduce a dataset with over 2,000 characters and 72,000 interviews, including 18,000 adversarial questions. We propose RoleFact, a role-playing method that mitigates hallucination by modulating the influence of parametric knowledge using a pre-calibrated confidence threshold. Experiments show that the proposed method improves the factual precision of generated responses by 18{\%} for adversarial questions with a 44{\%} reduction in temporal hallucination for time-sensitive interviews. The code and the dataset are available at \url{https://github.com/NafisSadeq/rolefact.git}."
}

@inproceedings{chen-etal-2024-socialbench,
    title = "{S}ocial{B}ench: Sociality Evaluation of Role-Playing Conversational Agents",
    author = "Chen, Hongzhan  and
      Chen, Hehong  and
      Yan, Ming  and
      Xu, Wenshen  and
      Xing, Gao  and
      Shen, Weizhou  and
      Quan, Xiaojun  and
      Li, Chenliang  and
      Zhang, Ji  and
      Huang, Fei",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "2108--2126",
    abstract = "Large language models (LLMs) have advanced the development of various AI conversational agents, including role-playing agents that mimic diverse characters and human behaviors. While prior research has predominantly focused on enhancing the conversational capability, role-specific knowledge and style of these agents, there has been a noticeable gap in assessing their social intelligence. In this paper, we introduce SocialBench, the first benchmark designed to systematically evaluate the sociality of role-playing agents at both individual and group levels of social interactions. SocialBench is constructed from various sources and covers a wide range of 500 characters and over 6,000 question prompts and 30,800 multi-turn role-playing utterances. We conduct comprehensive evaluations on this benchmark using mainstream LLMs. We find that agents excelling in individual level does not imply their proficiency in group level. Experimental results on SocialBench confirm its significance as a testbed for assessing the social interaction of role-playing agents. The benchmark is publicly accessible at https://github.com/X-PLUG/RoleInteract."
}

@article{wang2023rolellm,
  title={Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models},
  author={Wang, Zekun Moore and Peng, Zhongyuan and Que, Haoran and Liu, Jiaheng and Zhou, Wangchunshu and Wu, Yuhan and Guo, Hongcheng and Gan, Ruitong and Ni, Zehao and Yang, Jian and others},
  journal={arXiv preprint arXiv:2310.00746},
  year={2023}
}

@inproceedings{bai-etal-2024-mt,
    title = "{MT}-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues",
    author = "Bai, Ge  and
      Liu, Jie  and
      Bu, Xingyuan  and
      He, Yancheng  and
      Liu, Jiaheng  and
      Zhou, Zhanhui  and
      Lin, Zhuoran  and
      Su, Wenbo  and
      Ge, Tiezheng  and
      Zheng, Bo  and
      Ouyang, Wanli",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "7421--7454",
    abstract = "The advent of Large Language Models (LLMs) has drastically enhanced dialogue systems. However, comprehensively evaluating the dialogue abilities of LLMs remains a challenge. Previous benchmarks have primarily focused on single-turn dialogues or provided coarse-grained and incomplete assessments of multi-turn dialogues, overlooking the complexity and fine-grained nuances of real-life dialogues. To address this issue, we introduce MT-Bench-101, specifically designed to evaluate the fine-grained abilities of LLMs in multi-turn dialogues. By conducting a detailed analysis of real multi-turn dialogue data, we construct a three-tier hierarchical ability taxonomy comprising 4208 turns across 1388 multi-turn dialogues in 13 distinct tasks. We then evaluate 21 popular LLMs based on MT-Bench-101, conducting comprehensive analyses from both ability and task perspectives and observing differing trends in LLMs performance across dialogue turns within various tasks. Further analysis indicates that neither utilizing common alignment techniques nor chat-specific designs has led to obvious enhancements in the multi-turn abilities of LLMs. Extensive case studies suggest that our designed tasks accurately assess the corresponding multi-turn abilities. The data and code are available at https://github.com/mtbench101/mt-bench-101."
}
@inproceedings{deng-etal-2024-multi,
    title = "On the Multi-turn Instruction Following for Conversational Web Agents",
    author = "Deng, Yang  and
      Zhang, Xuan  and
      Zhang, Wenxuan  and
      Yuan, Yifei  and
      Ng, See-Kiong  and
      Chua, Tat-Seng",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "8795--8812",
    abstract = "Web agents powered by Large Language Models (LLMs) have demonstrated remarkable abilities in planning and executing multi-step interactions within complex web-based environments, fulfilling a wide range of web navigation tasks. Despite these advancements, the potential for LLM-powered agents to effectively engage with sequential user instructions in real-world scenarios has not been fully explored. In this work, we introduce a new task of Conversational Web Navigation, which necessitates sophisticated interactions that span multiple turns with both the users and the environment, supported by a specially developed dataset named Multi-Turn Mind2Web (MT-Mind2Web). To tackle the limited context length of LLMs and the context-dependency issue of the conversational tasks, we further propose a novel framework, named self-reflective memory-augmented planning (Self-MAP), which employs memory utilization and self-reflection techniques. Extensive experiments are conducted to benchmark the MT-Mind2Web dataset, and validate the effectiveness of the proposed method."
}

@inproceedings{sun-etal-2024-parrot,
    title = "Parrot: Enhancing Multi-Turn Instruction Following for Large Language Models",
    author = "Sun, Yuchong  and
      Liu, Che  and
      Zhou, Kun  and
      Huang, Jinwen  and
      Song, Ruihua  and
      Zhao, Xin  and
      Zhang, Fuzheng  and
      Zhang, Di  and
      Gai, Kun",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "9729--9750",
    abstract = "Humans often interact with large language models (LLMs) in multi-turn interaction to obtain desired answers or more information. However, most existing studies overlook the multi-turn instruction following ability of LLMs, in terms of training dataset, training method, and evaluation benchmark. In this paper, we introduce Parrot, a solution aiming to enhance multi-turn instruction following for LLMs. First, we introduce an efficient but effective method for collecting multi-turn instructions that feature human-like queries, such as anaphora and ellipsis. Second, we propose a context-aware preference optimization strategy to further enhance LLMs for complex queries in multi-turn interaction. Moreover, to quantitatively evaluate LLMs in multi-turn instruction following, we manually build a multi-turn benchmark derived from existing ones. Extensive experiments show that Parrot improves current LLMs by up to 7.2{\%} in multi-turn instruction following. Our dataset and codes will be open-sourced to facilitate future research."
}

@inproceedings{
fan2025fairmtbench,
title={Fair{MT}-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational {LLM}s},
author={Zhiting Fan and Ruizhe Chen and Tianxiang Hu and Zuozhu Liu},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
}

@article{duan2023botchat,
  title={BotChat: Evaluating LLMs' Capabilities of Having Multi-Turn Dialogues},
  author={Duan, Haodong and Wei, Jueqi and Wang, Chonghua and Liu, Hongwei and Fang, Yixiao and Zhang, Songyang and Lin, Dahua and Chen, Kai},
  journal={arXiv preprint arXiv:2310.13650},
  year={2023}
}

@inproceedings{zhang2024comprehensive,
  title={A Comprehensive Analysis of the Effectiveness of Large Language Models as Automatic Dialogue Evaluators},
  author={Zhang, Chen and D'Haro, Luis Fernando and Chen, Yiming and Zhang, Malu and Li, Haizhou},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={19515--19524},
  year={2024}
}

@inproceedings{mendonca-etal-2024-soda,
    title = "Soda-Eval: Open-Domain Dialogue Evaluation in the age of {LLM}s",
    author = "Mendon{\c{c}}a, John  and
      Trancoso, Isabel  and
      Lavie, Alon",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    pages = "11687--11708",
    abstract = "Although human evaluation remains the gold standard for open-domain dialogue evaluation, the growing popularity of automated evaluation using Large Language Models (LLMs) has also extended to dialogue. However, most frameworks leverage benchmarks that assess older chatbots on aspects such as fluency and relevance, which are not reflective of the challenges associated with contemporary models. In fact, a qualitative analysis on Soda. (Kim et al., 2023), a GPT-3.5 generated dialogue dataset, suggests that current chatbots may exhibit several recurring issues related to coherence and commonsense knowledge, but generally produce highly fluent and relevant responses.Noting the aforementioned limitations, this paper introduces Soda-Eval, an annotated dataset based on Soda that covers over 120K turn-level assessments across 10K dialogues, where the annotations were generated by GPT-4. Using Soda-Eval as a benchmark, we then study the performance of several open-access instruction-tuned LLMs, finding that dialogue evaluation remains challenging. Fine-tuning these models improves performance over few-shot inferences, both in terms of correlation and explanation."
}

@inproceedings{ferron-etal-2023-meep,
    title = "{MEEP}: Is this Engaging? Prompting Large Language Models for Dialogue Evaluation in Multilingual Settings",
    author = "Ferron, Amila  and
      Shore, Amber  and
      Mitra, Ekata  and
      Agrawal, Ameeta",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    pages = "2078--2100",
    abstract = "As dialogue systems become more popular, evaluation of their response quality gains importance. Engagingness highly correlates with overall quality and creates a sense of connection that gives human participants a more fulfilling experience. Although qualities like coherence and fluency are readily measured with well-worn automatic metrics, evaluating engagingness often relies on human assessment, which is a costly and time-consuming process. Existing automatic engagingness metrics evaluate the response without the conversation history, are designed for one dataset, or have limited correlation with human annotations. Furthermore, they have been tested exclusively on English conversations. Given that dialogue systems are increasingly available in languages beyond English, multilingual evaluation capabilities are essential. We propose that large language models (LLMs) may be used for evaluation of engagingness in dialogue through prompting, and ask how prompt constructs and translated prompts compare in a multilingual setting. We provide a prompt-design taxonomy for engagingness and find that using selected prompt elements with LLMs, including our comprehensive definition of engagingness, outperforms state-of-the-art methods on evaluation of engagingness in dialogue across multiple languages."
}

@inproceedings{siro2024rethinking,
  title={Rethinking the evaluation of dialogue systems: Effects of user feedback on crowdworkers and LLMs},
  author={Siro, Clemencia and Aliannejadi, Mohammad and de Rijke, Maarten},
  booktitle={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1952--1962},
  year={2024}
}


@article{zhang2024cfbench,
  title={Cfbench: A comprehensive constraints-following benchmark for llms},
  author={Zhang, Tao and Shen, Yanjun and Luo, Wenjing and Zhang, Yan and Liang, Hao and Yang, Fan and Lin, Mingan and Qiao, Yujing and Chen, Weipeng and Cui, Bin and others},
  journal={arXiv preprint arXiv:2408.01122},
  year={2024}
}

@article{zhang2024iopo,
  title={IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization},
  author={Zhang, Xinghua and Yu, Haiyang and Fu, Cheng and Huang, Fei and Li, Yongbin},
  journal={arXiv preprint arXiv:2411.06208},
  year={2024}
}

@inproceedings{lu-etal-2024-large,
    title = "Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment",
    author = "Lu, Keming  and
      Yu, Bowen  and
      Zhou, Chang  and
      Zhou, Jingren",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "7828--7840",
    abstract = "Considerable efforts have been invested in augmenting the role-playing proficiency of open-source large language models (LLMs) by emulating proprietary counterparts. Nevertheless, we posit that LLMs inherently harbor role-play capabilities, owing to the extensive knowledge of characters and potential dialogues ingrained in their vast training corpora. Thus, we introduce Ditto, the first self-alignment method for role-play, which encourages an instruction-following LLM to simulate role-play dialogues as a variant of reading comprehension, and creates a role-play training set comprising 4000 characters, surpassing the scale of currently available datasets by tenfold regarding the number of roles. Subsequently, we fine-tune the LLM using this self-generated dataset to augment its role-playing capabilities. Upon evaluating our meticulously constructed role-play benchmark and the roleplay subset of MT-Bench, Ditto, in various parameter scales, consistently maintains a consistent role identity and provides accurate role-specific knowledge in multi-turn role-play conversations, outperforming all open-source role-play baselines. Furthermore, we present the first cross-supervision role-play experiment, revealing that the role-play styles can be easily acquired, while the intrinsic capabilities of LLMs confine the knowledge within role-play."
}


@inproceedings{tseng-etal-2024-two,
    title = "Two Tales of Persona in {LLM}s: A Survey of Role-Playing and Personalization",
    author = "Tseng, Yu-Min  and
      Huang, Yu-Chao  and
      Hsiao, Teng-Yun  and
      Chen, Wei-Lin  and
      Huang, Chao-Wei  and
      Meng, Yu  and
      Chen, Yun-Nung",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    pages = "16612--16631",
    abstract = "The concept of *persona*, originally adopted in dialogue literature, has re-surged as a promising framework for tailoring large language models (LLMs) to specific context (*e.g.*, personalized search, LLM-as-a-judge). However, the growing research on leveraging persona in LLMs is relatively disorganized and lacks a systematic taxonomy. To close the gap, we present a comprehensive survey to categorize the current state of the field. We identify two lines of research, namely (1) *LLM Role-Playing*, where personas are assigned to LLMs, and (2) *LLM Personalization*, where LLMs take care of user personas. Additionally, we introduce existing methods for LLM personality evaluation. To the best of our knowledge, we present the first survey for role-playing and personalization in LLMs under the unified view of persona. We continuously maintain a paper collection to foster future endeavors."
}

@inproceedings{zhang-etal-2024-strength,
    title = "Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation",
    author = "Zhang, Tong  and
      Huang, Chen  and
      Deng, Yang  and
      Liang, Hongru  and
      Liu, Jia  and
      Wen, Zujie  and
      Lei, Wenqiang  and
      Chua, Tat-Seng",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    pages = "424--444",
    abstract = "We investigate non-collaborative dialogue agents, which are expected to engage in strategic conversations with diverse users, for securing a mutual agreement that leans favorably towards the system`s objectives. This poses two main challenges for existing dialogue agents: 1) The inability to integrate user-specific characteristics into the strategic planning, and 2) The difficulty of training strategic planners that can be generalized to diverse users. To address these challenges, we propose TRIP to enhance the capability in tailored strategic planning, incorporating a user-aware strategic planning module and a population-based training paradigm. Through experiments on benchmark non-collaborative dialogue tasks, we demonstrate the effectiveness of TRIP in catering to diverse users."
}


@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}


@article{houthakker1950revealed,
  title={Revealed preference and the utility function},
  author={Houthakker, Hendrik S},
  journal={Economica},
  volume={17},
  number={66},
  pages={159--174},
  year={1950},
  publisher={JSTOR}
}

@article{slantchev2012game,
  title={Game theory: preferences and expected utility},
  author={Slantchev, Branislav L},
  journal={Technical Report, Political Science Courses},
  year={2012},
  publisher={University of California}
}

@book{narlikar2010deadlocks,
  title={Deadlocks in multilateral negotiations: causes and solutions},
  author={Narlikar, Amrita},
  year={2010},
  publisher={Cambridge University Press}
}

@article{van2023emotion,
  title={Emotion contagion in agent-based simulations of crowds: a systematic review},
  author={Van Haeringen, ES and Gerritsen, Charlotte and Hindriks, Koen V},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={37},
  number={1},
  pages={6},
  year={2023},
  publisher={Springer}
}

@inproceedings{
abdelnabi2024llmdeliberation,
title={{LLM}-Deliberation: Evaluating {LLM}s with Interactive Multi-Agent Negotiation Game},
author={Sahar Abdelnabi and Amr Gomaa and Sarath Sivaprasad and Lea Sch{\"o}nherr and Mario Fritz},
booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
year={2024},
}

@article{clark2023social,
  title={Social robots as depictions of social agents},
  author={Clark, Herbert H and Fischer, Kerstin},
  journal={Behavioral and Brain Sciences},
  volume={46},
  pages={e21},
  year={2023},
  publisher={Cambridge University Press}
}

@article{richards2023principlist,
  title={A principlist-based study of the ethical design and acceptability of artificial social agents},
  author={Richards, Deborah and Vythilingam, Ravi and Formosa, Paul},
  journal={International Journal of Human-Computer Studies},
  volume={172},
  pages={102980},
  year={2023},
  publisher={Elsevier}
}

@article{chiang2024over,
  title={Over-reasoning and redundant calculation of large language models},
  author={Chiang, Cheng-Han and Lee, Hung-yi},
  journal={arXiv preprint arXiv:2401.11467},
  year={2024}
}

@inproceedings{yangrewards,
  title={Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment},
  author={Yang, Rui and Pan, Xiaoman and Luo, Feng and Qiu, Shuang and Zhong, Han and Yu, Dong and Chen, Jianshu},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@misc{he2024donthalflistencapturingkeypart,
      title={Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning}, 
      author={Yongquan He and Xuancheng Huang and Minghao Tang and Lingxun Meng and Xiang Li and Wei Lin and Wenyuan Zhang and Yifu Gao},
      year={2024},
      eprint={2403.10056},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}