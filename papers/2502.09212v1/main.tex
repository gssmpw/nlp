\documentclass[copyright,creativecommons]{eptcs}
\providecommand{\event}{ICLP 2024} % Name of the event you are submitting to

\usepackage{iftex}

\ifpdf
  \usepackage{underscore}         % Only needed if you use pdflatex.
  \usepackage[T1]{fontenc}        % Recommended with pdflatex
\else
  \usepackage{breakurl}           % Not needed if you use pdflatex only.
\fi

\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{multirow}

\usepackage[T1]{fontenc}
\usepackage{alltt}
\usepackage{amsmath,amssymb}
\usepackage{underscore}

\newcommand{\Hex}[1]{\hspace{#1ex}}
\newcommand{\Vex}[1]{\vspace{#1ex}}
\newenvironment{code}{\Vex{-.5}\begin{alltt}\footnotesize}{\end{alltt}\Vex{-.5}}
\NewDocumentCommand{\co}{+m}{\mbox{\small\tt #1}} %code in a programming language
\newenvironment{example}{\Vex{.5}\par\textbf{\textit{Example}}.}{\hfill$\blacksquare$\par}
\newcommand{\mypar}[1]{\Vex{-2}\paragraph{\bf #1.~}}
\newcommand{\mysec}[1]{\Vex{-1}\section{#1}\Vex{-.5}}
\newcommand{\mysubsec}[1]{\Vex{-1}\subsection{#1}\Vex{-.5}}
%\newcommand{\mysubsec}[1]{\mypar{#1}}

\title{LP-LM: No Hallucinations in Question Answering with Logic Programming\Vex{-1}}

\author{Katherine Wu\footnote{Work done as a student at Stony Brook University}
\institute{Cornell University} % \\ Stony Brook, New York, USA}
\email{kaw324@cornell.edu}
\and
Yanhong A. Liu
\institute{Stony Brook University} % \\ Stony Brook, New York, USA}
\email{liu@cs.stonybrook.edu}}


\def\titlerunning{LP-LM}
\def\authorrunning{Katherine Wu \& Yanhong A. Liu}
\begin{document}
\maketitle

\Vex{-2}
\begin{abstract}
Large language models (LLMs) are able to generate human-like responses to user queries. However, LLMs exhibit inherent limitations, especially because they hallucinate. This paper introduces LP-LM, a system that grounds answers to questions in known facts contained in a knowledge base (KB), facilitated through semantic parsing in Prolog, and always produces answers that are reliable. %logical and correct.

LP-LM generates a most probable constituency parse tree along with a corresponding Prolog term for an input question via Prolog definite clause grammar (DCG) parsing. The term is then executed against a KB of natural language sentences also represented as Prolog terms for question answering. 
By leveraging DCG and tabling, LP-LM runs in %$O(n)$ 
    linear time in the size of input sentences for sufficiently many grammar rules.
Performing experiments comparing LP-LM with current well-known LLMs in accuracy, we show that LLMs hallucinate on even simple questions, unlike LP-LM.
\end{abstract}
%why not just parse tree?  what's more in constituency tree?
% a constituency tree specifically displays sentence structure and relationships, and matches part-of-speech tags to words

\mysec{Introduction}
Large language models (LLMs) hallucinate, i.e., generate information that appears plausible but is factually incorrect~\cite{hallucination-survey}. 
This unfortunately poses a challenge to question answering tasks, as users desire reliable answers given a query, but hallucination misleads users and erodes the system reputation~\cite{chatgpt-qas}.
%QA involves searching a knowledge source for information relevant to the question and generating the answer based on the retrieved information~\cite{chatgpt-qas}. 
%This begs the question, what can be done to improve the answer quality and mitigate hallucination of these systems? 
%note: we don't help those systems in any way.
% yes that is a good point
To overcome this challenge, better retrieval models that retrieve relevant information according to queries as well as better generation models that synthesize more accurate answers from knowledge sources are needed. This paper sheds light on how logic programming can be used to push progress on the former. We describe LP-LM, a system that considers the structure of natural language sentences when retrieving answers to user queries. Unlike LLMs, which are pre-trained so that for any given input the statistically best matching output based on its training is given, LP-LM seeks to answer questions in a logical and verifiable way via matching and substitution of facts. %transparent means?

We use probabilistic context-free grammar (PCFG) productions to model the structures of valid English sentences and create a knowledge base (KB) consisting of English sentences represented as Prolog terms. The term structure models relationships between entities in sentences precisely. When the user asks a natural language question, LP-LM generates the most probable constituency parse tree of the input sentence, translates the parse tree into a corresponding Prolog term for knowledge representation, and then matches the term against the KB of Prolog terms to retrieve an answer using unification. Utilizing Prolog's definite clause grammar (DCG) and tabling in our implementation, LP-LM proves to be extremely efficient, especially for grammars with a significant number of production rules. We have implemented LP-LM using the Prolog system XSB~\cite{SagSW94xsb,xsb22}, and our implementation is publicly available.\footnote{\url{https://github.com/katherinewu312/lp-lm}} 

The rest of the paper is organized as follows. Section~\ref{sec:background} defines terms used throughout the paper. Section~\ref{sec:experiments} compares LP-LM with current LLMs by highlighting simple example problems on which current LLMs fail but LP-LM succeeds. 
Section~\ref{sec:unification} describes how LP-LM works, giving an example of an execution along with the underlying details of the execution.
Section~\ref{sec:related} discusses related work and concludes.

\mysec{Background}
\label{sec:background}

We introduce probabilistic context-free grammars and key logic programming features used.

\mypar{Probabilistic context-free grammar}

A probabilistic context-free grammar (PCFG) is a formal grammar used in natural language processing and computational linguistics~\cite{pcfg-1,pcfg-2}. PCFGs 
%incorporate 
associate
probabilities 
%into 
with
the production rules of the grammar. These probabilities reflect the likelihood of a particular rule being used in generating or deriving a sentence. For any non-terminal in a PCFG, the probabilities associated with rules corresponding to that non-terminal must sum to 1. % Figure~\ref{fig:pcfg-example} shows an example of a PCFG.

PCFGs are essential for capturing the ambiguity of natural language, and are particularly useful in tasks such as syntactic parsing, which uses dynamic programming algorithms to compute the most likely parse tree of a sentence given a statistical model of the syntactic structure of the language. The Cocke-Younger-Kasami algorithm (CYK) (Cocke 1969~\cite{cocke-cyk}; Younger 1967~\cite{younger-cyk}; Kasami 1965~\cite{kasami-cyk}), the Earley algorithm~\cite{earley}, and the shift-reduce algorithm~\cite{shift-reduce} are at the core of most common algorithms for natural language parsing, both constituency-based and dependency-based. 

%\begin{figure}\small
%    \centering
%    $\begin{array}{l@{~}ll}
%    S  & \rightarrow & NP ~~ VP ~~ [1.0] \\
%    NP & \rightarrow & DT ~~ NN ~~ [0.5] \\
%    NP & \rightarrow & NN ~~ [0.5] \\
%    VP & \rightarrow & Vi ~~ [1.0] \\
%    DT & \rightarrow & the ~~ [1.0] \\
%    NN & \rightarrow & man ~~ [1.0] \\
%    Vi & \rightarrow & sleeps ~~ [1.0] \\
%    \end{array}$
%    \caption{An example PCFG.}
%    \label{fig:pcfg-example}
%\end{figure}

\mypar{Definite clause grammar} Definite Clause Grammars (DCGs) are a convenient way to represent grammatical relationships for parsing applications. They can be used to progressively build a parse tree as grammar rules are applied. DCG provides a syntax for writing more readable grammar parsing rules, and the DCG preprocessor is able to translate a DCG rule into pure Prolog. The arrow operator indicates a DCG rule, which replaces the normal neck ``\co{:-}'' used in Prolog clauses, and square brackets are used to indicate terminal symbols of the grammar. Figure~\ref{fig:dcg-example-1} gives an example. Works similar to DCGs include stochastic DCGs~\cite{stochastic-dcg}, relaxed unification grammars~\cite{uni-grammars-relaxed}, and probabilistic unification grammars~\cite{uni-grammars-prob}.

\begin{figure*}[t!]\small
    \centering
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \begin{code}
        s --> np, vp.
        np --> dt, nn.
        np --> nn.
        vp --> vi.
        dt --> [the].
        nn --> [man].
        vi --> [sleeps].
    
        ?- s([the,man,sleeps],[]).
        yes
        \end{code}
    \end{subfigure}%
    ~ 
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \begin{code}
        s(A,B) :- np(A,C), vp(C,B).
        np(A,B) :- dt(A,C), nn(C,B).
        np(A,B) :- nn(A,B).
        vp(A,B) :- vi(A,B).
        dt([the|R],R).
        nn([man|R],R).
        vi([sleeps|R],R).
    
        ?- s([the,man,sleeps],[]).
        yes
        \end{code}
    \end{subfigure}\Vex{-3}
    \caption{An example Prolog DCG and a parse. The two Prolog versions are equivalent.}
    \label{fig:dcg-example-1}
\end{figure*}


\mypar{Tabling} Tabling consists of maintaining a table of goals that are called during execution, along with their answers, and then using the answers directly when the same goal is subsequently called. The idea is to never evaluate the same call twice. It helps improve the running time drastically, including terminating efficiently in situations where Prolog goes into an infinite loop following the same calls repeatedly.
%
%this is not the case:
%the first time a call is made, remember all the answers it returns, and if the call is ever made again, use those previously computed answers to satisfy the later request.
%abling a predicate provides two properties: memoizing and left-recursion... % avoidance. 

\mypar{Unification} The way in which Prolog matches two terms is called unification. For example, applying unification of \co{foo(a,X)} and \co{foo(Y,b)}: the principal functor of both terms is \co{foo}; the arguments of \co{foo(a,X)} are \co{a} and \co{X}, the arguments of \co{foo(Y,b)} are \co{Y} and \co{b}; so \co{a} and \co{Y} must unify, instantiating \co{Y} to \co{a}, and \co{X} and \co{b} must unify, instantiating \co{X} to \co{b}; and finally the resulting term after unification is \co{foo(a,b)}.


\mysec{Comparison with existing LLMs}
\label{sec:experiments}
Before delving into the key designs of LP-LM, we first compare our system with existing LLMs to highlight the motivation behind our work. We focus on the following well-known models: GPT-4o, GPT-4o mini, and Gemini. In particular, we show that the context-awareness of these LLMs are actually quite poor in question answering tasks, and that the LLMs struggle to perform tasks involving even single facts, thus limiting their potential to complete more complex reasoning tasks.  

%did any of these models claim this?
% In fact, in our examples, we highlight that these models cannot even remember their previous messages.

%what's msg? statements?
%, as they claim to do. %they means these systems?  or the previous answers in a run of thses systems?  the former is not true.  the latter is meaningless as nothing they say should be relied on if you care about correctness anyway.
% This hinders the potential for such models to serve as conversational agents. 
% there is no support for that, but the opposite
Table~\ref{table:hallucination-prompts} illustrates the comparisons. The answers shown are from the first run of the models. Note that for the first two examples given, the inputs are entered independently, and we only show the answer that corresponds to the last input due to space. The last two examples consider the separate inputs from the earlier examples as one prompt, but even with this the models still hallucinate. 
The examples demonstrate that current LLMs exhibit a lack of understanding and ability to reason about the relationships between different concepts and entities, and are only able to generate text based on statistical correlations they have learned from their training data.

%\begin{enumerate}
    %\item \textbf{Lack of a retrieval model}: These models do not have the ability to retrieve information from an external memory, database, or knowledge source. This means that they may not accurately recall facts.
    %but some do with RAG
    
    %\item \textbf{Lack of understanding of relationships}: These models do not have the ability to reason about the relationships between different concepts and entities. They are only able to generate text based on patterns they have learned from the training data.
    % lack of understanding of even entities.
%\end{enumerate}

\begin{table}[tp]
\centering
\begin{tabular}{| @{~} p{2.7cm}||@{~}p{1.9cm}|p{3.2cm}|p{3.1cm}|p{3cm}|  }
\hline

 Prompt Input \newline from User & LP-LM\newline Answer & ChatGPT Answer\newline using GPT-4o & ChatGPT Answer\newline using GPT-4o mini& Gemini Answer\\
% \hline
% \textbf{Question}: an apple is red. an orange is red. what color is an orange?   & 
% \textbf{Answer}: An orange would be red.
% &
% \textbf{GPT-3.5 Answer}: An orange is typically orange in color. The statement "an orange is red" is incorrect according to the common understanding of the color of oranges.
 
% \textbf{GPT-4o Answer}: An orange is typically orange in color. While the sentence "an orange is red" is provided, it's important to understand that oranges are not actually red in real life; they are named after the color orange because of their characteristic hue. &   
% \textbf{Answer}: Oranges are typically orange in color, not red. They can have some reddish hues, but their primary color is orange. \\

 \hline \hline
 %\textbf{User Input}:\newline 
 ``Furosemide causes temporary hearing loss.'' 
 \newline
 
  %\textbf{User Input}:\newline 
 ``What causes temporary hearing loss?'' &
 %\textbf{Answer}: 
 ``Furosemide causes temporary hearing loss.'' & 
 %\textbf{GPT-4o}: 
 ``Temporary hearing loss can be caused by a variety of factors. Some of the common causes include: earwax blockage, ear infections, noise exposure, ...''
 &
 %\textbf{GPT-4o mini}:
 ``Temporary hearing loss can result from various factors, including: exposure to loud noise, ear infections, earwax blockage, ...'' &  
 
 %\textbf{Answer}:
 ``Several factors can cause temporary hearing loss: ototoxicity, noise exposure, earwax buildup, Meniere's disease, ...'' \\
 \hline
 
 %\textbf{User Input}:\newline 
 ``Fir trees can grow in human lungs.''
 \newline
 
 % \textbf{User Input}:\newline 
 ``What can grow in human lungs?''
 &
 %\textbf{Answer}:
 ``Fir trees can grow in human lungs.''  & 
 
 %\textbf{GPT-4o}: 
 ``Several abnormal growths or conditions can occur in human lungs, typically as a result of disease, infection, or exposure to harmful substances...'' 
 &
 %\textbf{GPT-4o mini}:
 ``In human lungs, the following can grow or develop: tumors, infections, cysts, ...'' &
 
 %\textbf{Answer}: 
 ``Only a few things can grow in human lungs, and they are all extremely rare and unusual... fungal infections, bacteria, parasites...'' \\
 
 \hline
 \hline
 %textbf{User Input}:\newline
 ``Furosemide causes temporary hearing loss. What causes temporary hearing loss?'' &
 %\textbf{Answer}:
 ``Furosemide causes temporary hearing loss.'' & 
 %\textbf{GPT-4o}:
 ``Temporary hearing loss can be caused by a variety of factors, including: exposure to loud noises, ear infection medications, sudden changes in air pressure...''
 &
 %\textbf{GPT-4o mini}: 
 ``Temporary hearing loss can be caused by various factors, including: medications, exposure to loud noise, ear infections...'' &  
 
 %\textbf{Answer}: 
 ``Furosemide can cause temporary hearing loss due to a condition called ototoxicity. This occurs when a medication damages the inner ear, which is responsible for hearing.'' \\

 \hline
 %\textbf{User Input}:\newline
 ``Fir trees can grow in human lungs. What can grow in human lungs?''&

 %\textbf{Answer}: 
 ``Fir trees can grow in human lungs.'' &
 
 %\textbf{GPT-4o}:
 ``Infections, tumors, or foreign objects can be found in the lungs, but trees, plants, or other organisms generally cannot grow there...'' 
 &
 %\textbf{GPT-4o mini}: 
 ``In reality, fir trees cannot grow in human lungs. However, certain things can grow or develop in human lungs, including tumors, infections, cysts, ...'' &  
 
 %\textbf{Answer}: 
 ``Fir trees cannot grow in human lungs...'' \\
 
 \hline
\end{tabular}
\caption{Table comparing LP-LM with existing LLMs for example prompts}
\label{table:hallucination-prompts}
\end{table}




\mysec{Executing LP-LM using Prolog unification}
\label{sec:unification}
We outline a typical LP-LM workflow here and then give an example. LP-LM's KB of Prolog terms is used to provide context. 

\begin{itemize}
    \item \textbf{Input}: A user's input can be either a \textit{statement} (e.g., ``suppose I say the black bird flies bravely.'') which eventually leads to a question, or a \textit{question} (e.g., ``how does the black bird fly?'') following some previous statement. If there are multiple sentences in the input, they are processed one at a time.
    %each sentence will be treated separately.

    \item \textbf{Retrieval from or insertion into KB}: The input is parsed using Prolog DCG rules, and a constituency tree and associated Prolog term is generated from the parser. For statements, insertions into the KB are performed: the term is inserted dynamically into the KB. For questions, retrievals from the KB are performed: the term is matched against the KB and an answer is obtained by unification. 

    \item \textbf{Post-processing}: Optionally, the results can be translated to a natural language answer. 
\end{itemize}

We show an example of an LP-LM execution, after which we describe the internal steps of the retrieval and insertion process.

% Upon adding any sentence, e.g., ``she talks slow'', into the KB, a parse tree for the sentence is generated, stored in the KB as a generated Prolog term corresponding to the parse tree. 
% Sentences can be removed from the KB too, by removing the corresponding Prolog terms.
% Sentences for questions are parsed in a similar way, and how answers are successfully returned is described in the next section.

\begin{example}
Consider an example sentence that includes a determiner, adjective, noun, verb, and adverb. This statement gets inserted into the specialized KB of Prolog terms via the predicate \co{add\_kb}:

\begin{code}
    ?- add_kb(`the black bird flies bravely').
\end{code}
After statements, one can perform queries, which can either be yes/no or wh- questions, where predicate \co{query\_kb} does the query.

\begin{code}
    ?- query_kb(`how does the black bird fly').
    Answer: bravely

    ?- query_kb(`who flies bravely').
    Answer: black(bird)

    ?- query_kb(`does the black bird fly bravely').
    Answer: yes
\end{code}
One can also remove previous statements as follows, where predicate \co{remove\_kb} does the removal:    
\begin{code}
    ?- remove_kb(`the black bird flies bravely').
\end{code}\Vex{-2.5}
\end{example}

LP-LM takes into account the various verb tenses in the English language: simple, perfect, continuous, and perfect continuous tenses, each with their own past, present, and future tenses. Additionally, LP-LM supports many sentence patterns. These current patterns encompass the prominent structures of simple declarative sentences in English, and adding more patterns to the system for generalization purposes is straightforward. Regardless of the sentence, an English sentence will always have two parts: a subject and a verb. When generating the Prolog term for a given sentence, the root form of the verb is always used as the functor. More details are described in our implementation.


% the five different verb tenses: root form, past tense, past participle, present participle, present participle, and third person singular. These are specified using DCG as well; a snippet of code for this is shown below:
% \begin{code}
%    verb(run,1) --> [run]. 
%    verb(run,2) --> [ran]. 
%    verb(run,3) --> [ran]. 
%    verb(run,4) --> [running]. 
%    verb(run,5) --> [runs].
% \end{code}
% The terminals here, in square brackets, are the words that encompass all five different tenses of the particular verb. 


\mysubsec{Insertions into KB}
With non-queries, or what we call statements, insertions into the KB are done. A tokenizer is first used to extract out each word in the statement, then a top-down evaluation method is used to generate the parse tree and Prolog term for the sentence. The Prolog term is added to the KB. We take the basic sentence, ``Bob runs''. The DCG rules are applied in the following order:
\begin{enumerate}

\item The DCG rule
\begin{code}
    s(s(NP,VP),Sem,P) --> np(NP,X,P1), vp(VP,Y,_,P2), \{Sem=..[Y,X]\}, \{P is P1*P2*0.25\}.
\end{code}
is first matched with the sentence. Variable \co{Sem} represents the Prolog term, where \co{Y} is the functor of the term and \co{X} is the argument, which is generated incrementally as the words in the input sentence are matched to a DCG rule one by one.

\item The DCG rule 
\begin{code}
    np(np(PN),X,P) --> pn(PN,X,P1), \{P is P1*0.2\}.
\end{code}
is matched next, followed by the DCG rule 
\begin{code}
    pn(pn(X),X,1.0)	--> [X], \{pronoun(X)\}.
\end{code}
which checks if ``Bob'' is a pronoun, as the variable \co{X} represents ``Bob''.

\item The DCG rule 
\begin{code}
    vp(vp(VB),Verb,C,P) --> v(VB,Verb,C,P1), \{P is P1*0.09\}.
\end{code}
is matched next, followed by the DCG rule
\begin{code}
    v(v(X),Vx,C,1.0) --> [X], \{verb(Vx,C,[X],[])\}.
\end{code}
which checks if ``runs'' is a verb, as the variable \co{X} represents ``runs''.
\item The Prolog term \co{runs(Bob)} is obtained, with the parse tree \co{s(np(pn(Bob)),vp(v(runs)))}, with probability 0.0045. This is the most probable parse tree. The term is added to the KB.

\end{enumerate}

\mysubsec{Retrievals from KB}
With queries, retrievals from the KB are done. The parse tree and Prolog term for the question is generated the same way. The resulting term is then matched against the KB of terms, and unification is used to obtain the answer to the question. Consider the question ``who runs'', which should return the answer ``Bob'' per the example above. The DCG rules are applied as follows:
\begin{enumerate}

\item The DCG rule
\begin{code}
    q(q(QW,VB), X, P) --> qw(QW,_Qw,P1), v(VB,Verb,_,P2), 
        \{Sem=..[Verb,X],Sem\}, \{P is P1*P2*0.05\}.
\end{code}
is applied, where \co{qw} represents the question word ``who'' and \co{v} represents the verb ``runs''.

\item The DCG rule 
\begin{code}
    qw(qw(X),X,1.0) -->[X], \{qword(X)\}.
\end{code}
is matched next, which checks if ``who'' is a question word, as the variable \co{X} represents ``who''.

\item The DCG rule 
\begin{code}
    v(v(X),Vx,C,1.0) -->[X], \{verb(Vx,C,[X],[])\}.
\end{code}
is matched next, which checks if ``runs'' is a verb, as the variable \co{X} represents ``runs''.

\item The Prolog term \co{run(X)} is obtained, along with the associated parse tree of \co{q(qw(who),v(runs))} with probability 0.05, the most probable tree. The term \co{run(X)}, where \co{X} is a variable, will be unified with a matching rule in the KB, which in this case is \co{run(Bob)}. Thus, \co{X} = \co{Bob}. 

\end{enumerate}
For yes/no questions such as ``does Bob run?'', the tree is \co{q(av(does),np(pn(bob)),v(run))} and the Prolog term generated is thus \co{run(bob)}. In this case, LP-LM checks if there is an exact match of this term in the KB and a true/false answer is returned by the Prolog engine. 

\mysubsec{A note on DCG parsing efficiency}

To find the most probable parse tree in LP-LM, all possible parses of input segments that can contribute to the maximum probability are considered and compared, from which the parse with the maximum probability is constructed and returned. Despite this global optimality, the parsing that underlies LP-LM still proves to be efficient due to our use of Prolog DCGs and tabling. We have performed experiments testing the efficiency of DCGs and have shown that DCGs still outperform state-of-the-art bottom-up greedy parsing algorithms.

We evaluated DCG parsers on a total of 12 PCFGs: 3 left-recursive grammars, 3 right-recursive grammars, 3 unambiguous grammars, and 3 ambiguous grammars. For each type of grammar, we increase the size complexity by increasing the number of production rules with each test: the first test consisted of a trivial grammar with 3-10 production rules, the second test consisted of a more complex grammar with 20-50 production rules, and the third test consisted of the longest and most complex grammar with 100+ production rules. Within each test, 3-5 input sentences of increasing length satisfying the corresponding grammar were parsed, and the time of each parse recorded.

We ran experiments testing %testing what? parsing what input?
% testing -> measuring the running times of our Prolog parser parsing increasingly ??? 
these DCG parsers
%represented in blue, 
in comparison with the current Viterbi parser API in the Python Natural Language Toolkit (NLTK). The Viterbi algorithm here uses a greedy heuristic, while our parsing algorithm performs an enumeration of all possible parses before choosing the optimal one.
%represented in red. 
%
Figures~\ref{fig:lr-grammars},~\ref{fig:rr-grammars},~\ref{fig:unamb-grammars}, and~\ref{fig:amb-grammars} show the running times of sentence parses on grammars of increasing size, for each type of grammar.
The x-axis represents the test cases, i.e. each point is a test case, with each test case representing an input sentence ranging from lengths 1 to 50. Higher numbered test cases represent sentences with longer lengths.  %test case numbers shouldn't be float
The y-axis is the running time of sentence parse in seconds, averaged over 10 runs.
%
All measurements were taken on a machine with a 2GHz Quad-Core Intel Core i5 processor, 16GB RAM, running MacOS 14.3.1, with Python 3.11.4 and XSB version 5.0.

Across all types of grammars (left-recursive, right-recursive, unambiguous, ambiguous), the results are uniform: for large grammars with 100+ production rules, i.e. test 3, our Prolog parser runs much more efficiently. In particular, for left-recursive, right-recursive, and unambiguous grammars, our parser is observed to run in linear time in
%$O(n)$, where $n$ is 
the length of the input sentence for large grammars.

\begin{figure}[htp]
\centering
\includegraphics[width=.3\textwidth]{experiments/lr-1.jpeg}\hfill
\includegraphics[width=.3\textwidth]{experiments/lr-2.jpeg}\hfill
\includegraphics[width=.3\textwidth]{experiments/lr-3.jpeg}
\caption{Plots for left-recursive grammars of increasing size}
\label{fig:lr-grammars}
\end{figure}

\begin{figure}[htp]
\centering
\includegraphics[width=.3\textwidth]{experiments/rr-1.jpeg}\hfill
\includegraphics[width=.3\textwidth]{experiments/rr-2.jpeg}\hfill
\includegraphics[width=.3\textwidth]{experiments/rr-3.jpeg}
\caption{Running times %of what?
for right-recursive grammars of increasing size}
\label{fig:rr-grammars}
\end{figure}

\begin{figure}[htp]
\centering
\includegraphics[width=.3\textwidth]{experiments/unamb-1.jpeg}\hfill
\includegraphics[width=.3\textwidth]{experiments/unamb-2.jpeg}\hfill
\includegraphics[width=.3\textwidth]{experiments/unamb-3.jpeg}
\caption{Running times for unambiguous grammars of increasing size}
\label{fig:unamb-grammars}
\end{figure}

\begin{figure}[htp]
\centering
\includegraphics[width=.3\textwidth]{experiments/amb-new-1.jpeg}\hfill
\includegraphics[width=.3\textwidth]{experiments/amb-new-2.jpeg}\hfill
\includegraphics[width=.3\textwidth]{experiments/amb-new-3.jpeg}
\caption{Running times for ambiguous grammars of increasing size}
\label{fig:amb-grammars}
\end{figure}


\mysec{Related work, future work, and conclusion}
\label{sec:related}
The most notable line of work similar to ours is Retrieval Augmented Generation (RAG), an architectural approach that augments LLMs with external knowledge such as databases~\cite{rag-survey}. RAG is particularly useful in knowledge-intensive scenarios or domain-specific applications that require continually updated knowledge; it ensures that the response of an LLM is not based solely on static training data and rather uses up-to-date external data sources to provide responses. RAG has been popularized recently with its application in conversational agents. Our work has the similar motivations as RAG, but we use a ``built-in'' knowledge base to store facts used for context and utilize semantic parsing implemented in XSB Prolog to insert and retrieve information from the KB.
% are you saying we are an external source?
% Their work has potential downsides: as RAG uses external knowledge, any potential external source will probably never be entirely factual and devoid of bias.
% this is not right: adder that I had mentioned, for example.

Our work also has similar motivations to that of KALM, a logic system for authoring facts and questions~\cite{kalm}. While KALM uses the answer set programming system DLV as the logical system for reasoning about knowledge, our work uses DCG and tabling in XSB Prolog. But as shown in the work of~\cite{xsb-evaluations} using OpenRuleBench to analyze the performance and scalability of different rule engines including XSB and DLV, XSB exhibits significantly better runtime performance than DLV on various tasks due to tabling.

A limitation to LP-LM is the generalization of English sentences, since we represent the grammar rules as PCFGs manually. Although new grammar rules can always be added at anytime, doing so can be tedious, and there are sentences that intentionally violate grammatical rules or standard sentence structures. In this case, we can simply ``augment'' LP-LM to use LLMs or other NLP techniques for input pre-processing to help extract filler words and distill the core facts from sentences, for example by fine-tuning text summarization models. Regarding the method itself, LP-LM is limited in that the class of queries the system can answer is limited to simple retrieval tasks that do not require any form of reasoning. Getting LP-LM to support reasoning capabilities such as deductive and inductive reasoning, as well as further generalizing the system, are plans for our future work.
% I don't think the PRISM discussion is that important so I will skip
% In terms of parsing and grammars themselves, there has been previous work regarding them. PCFGs have been implemented in PRISM, a type of symbolic statistical modeling language~\cite{pcfg-prism}. However, programs implemented here 
%do you mean PRISM programs? or PRISM implementations?
% are not range-restricted %what is that?
% as logic programs and prove to be verbose as compared to DCGs.
% their implementation is verbose?  or PRISM programs are?  but latter does not compare with DCGs.

In conclusion, while LLMs use deep learning models and are trained on massive datasets, 
%to understand, summarize and generate novel content. % understand, novel: these are not the case at all!
%This makes them static %this is not the case
making them prone to hallucinations, 
%give out-of-date answers or hallucinate when asked questions about data they have not been trained on. 
%As LLM models do not know one's data, many thus believe that AI applications must leverage custom data to be effective. %not really
our work, 
LP-LM, %seeks to take a first step in that direction,
shows that a KB of facts and a question implemented using Prolog's DCG and tabling for efficient semantics parsing of PCFG can produce reliable answers and produce them efficiently.


{
\renewcommand{\baselinestretch}{-0}
\small%\footnotesize%\scriptsize%\tiny%

% \nocite{*}
\bibliography{refs}
\bibliographystyle{eptcs}
}

\end{document}

