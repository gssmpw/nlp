\section{Related Work}\label{sec:RelatedWork}

\subsection{Trust and Acceptance in Robotic Procedures}

Robotic procedures have become increasingly prevalent in modern healthcare from minimally invasive surgeries~\cite{mack2001minimally,vitiello2012emerging} to autonomous diagnostic tasks~\cite{roshan2022robotic,jiang2023robotic}. However, the integration of these technologies introduces a new set of challenges, particularly in the areas of trust and acceptance, which are critical for both surgeons and patients.
Traditionally, the robot-surgeon relationship has been the primary focus of research in robotic-assisted procedures~\cite{mcdermott2020gender,sierra2021expectations,vichitkraivin2021factors}. Surgeons are often required to trust the accuracy and responsiveness of robotic systems to perform high-stakes operations. Studies have shown that trust between surgeons and robotic systems is built on factors such as system reliability, ease of use, and predictability during procedures~\cite{devito2010clinical,benmessaoud2011facilitators,chatterjee2024advancements,patel2024technical}. However, as robotic systems become more autonomous, the robot-patient relationship is gaining increasing attention~\cite{szabo2024robots}. Acceptance plays an even more critical role when robots interact with fully conscious patients. Studies from Bodenhagen et al.~\cite{bodenhagen2017influence} and Fischer et al.~\cite{fischer2018increasing} showed that transparency enhances trust, which can be increased through clear communication between the robot and patient. Weigelin et al.~\cite{weigelin2018trust} suggested to use verbal cues in addition to kinesthetic interactions to foster trust more effectively. For robotic ultrasound system, Eilers et al.~\cite{eilers2023importance} indicated that pre-examination interactions can lower patient stress levels and significantly enhance the patient acceptance. However, their study did not incorporate AR or VR visualizations, which could further impact patient comfort and trust. 

In addition to direct interactions with the robot, trust can also be affected by other factors. \replaced{Adams et al.\cite{adams2003trust} identified multiple influences on trust in automated systems, including the properties of the automated system, as well as the user’s propensity to trust and the context in which the system is used.}{Adams et al. \cite{adams2003trust} identified three key dimensions affecting trust in automated systems: properties of the system itself, the user’s propensity to trust, and the context of system use.} \replaced{Similarly, Hancock et al.~\cite{hancock2011meta} proposed a triadic model of trust that classifies the factors influencing trust into three categories: human, robot, and environmental characteristics.}{Expanding on this, Hancock et al. \cite{hancock2011meta} proposed a triadic model of trust, categorizing influencing factors into human, robot, and environmental characteristics.} Although robot characteristics, especially performance-based factors, were found to have the greatest impact on perceived trust in Human-Robot Interaction (HRI), environmental factors also moderately affect trust. By incorporating AR and VR environments during robotic procedures, we aim to explore how these additional contextual factors affect trust and acceptance in robotic medical procedures. This is the first work to integrate immersive visualizations in a robotic ultrasound system, providing real-time feedback and interaction to enhance patient trust, comfort, and overall acceptance.

\subsection{Virtual Agents}

Virtual agents, which are digital entities designed to simulate human-like interactions, have become a vital interface for bridging human-machine communication~\cite{cassell2001embodied,nass2000machines}. The embodiment of virtual agents, particularly their visual appearance and behavior, is crucial in fostering user engagement. Ring et al.~\cite{ring2014right} suggest that design rules for an agent's appearance vary by the application domain. Participants found the cartoon character (e.g. enlarged head) friendlier, but the human-proportioned character more appropriate for medical discussions. Studies by Latoschik et al.~\cite{latoschik2017effect} and Zibrek et al.~\cite{zibrek2018effect} further confirmed the benefits as realistic embodiments enhance users’ subjective experiences and increase immersion.

The effectiveness of virtual agents also extends beyond appearance. The integration of verbal and non-verbal behaviors, such as speech, gaze, and gestures, is critical to making interactions feel natural and engaging. As Cowell et al.~\cite{cowell2005manipulation} found, agents displaying nonverbal cues like eye contact and blinking elicit higher levels of trust compared to those lacking these behaviors. Potdevin et al.~\cite{potdevin2021virtual} highlighted how Embodied Conversational Agents (ECA) improve user engagement and intimacy by using voice and animated interactions, which are more effective than text-based methods. Kopp et al.~\cite{kopp2008modeling} emphasized the importance of integrating multimodal behaviors in ECAs. They demonstrated how these behaviors, alongside verbal interactions, create a more cohesive and lifelike communication experience, making the agent more relatable and engaging for users. 
 
 In healthcare applications, virtual agents play an increasingly important role. Nadarzynski et al.~\cite{nadarzynski2019acceptability} explored the acceptability of AI-led chatbot systems for healthcare and came to the conclusion that due to absence of empathy and a professional human touch made the chatbots to some users less acceptable. This highlights the possibility of extending a chatbot with a human-like virtual agent to increase the acceptance of the system. Philip et al.~\cite{philip2017virtual} studied the acceptability of an ECA in a face-to-face clinical interview done to diagnose major depressive disorders. Patients rated the interview with the ECA as highly acceptable, indicating that the ECA can convey empathy, build patient trust, lessen feelings of judgment from a human, and lower emotional barriers to sharing their affective state. The system incorporated a speech synthesizer for the ECA and a speech recognizer for the patient's answers but lacks the ability to freely generate the virtual human's responses~\cite{philip2014could}. Lucas et al.~\cite{lucas2017reporting} also demonstrated that virtual human interviewers can enhance service members' disclosure of mental health symptoms. Moreover, virtual agents in mixed reality environments offer unique opportunities for blending virtual and physical interactions~\cite{holz2011mira,norouzi2020systematic}. For example, Kim et al.~\cite{kim2019blowing} demonstrated how subtle environmental interactions, such as airflow influencing both virtual and real objects, can increase the sense of social presence in mixed reality environments by making virtual agents seem more aware of and connected to the physical space around them. This highlights the potential of agents that can perceive and interact with both digital and physical elements in healthcare settings. These agents could further enhance patient trust by offering real-time feedback during complex procedures, such as robotic surgeries or autonomous diagnostic tasks~\cite{juravle2020trust}.
However, as reviewed by Laranjo et al.~\cite{laranjo2018conversational}, the use of conversational agents  with unconstrained natural language input capabilities in healthcare is still in the early stages of investigation. This highlights the importance of advancing the integration of conversational, non-verbal, and empathetic behaviors to make these agents more effective in scenarios where patient comfort, trust, and clear communication are critical. In the context of robotic ultrasound procedures, we believe that virtual agents have the potential to significantly humanize interactions. By offering real-time feedback and guidance, we aim to show they can bridge the gap between automation and human empathy, ultimately improving patient acceptance and overall user experience.


%Regarding nonverbal behaviours of an avatar Cowell et al.~\cite{cowell2005manipulation} discovered that users who interacted with an avatar displaying these cues (eye contact, blinking) had higher levels of trust compared to those engaging with an avatar that lacked them.

%Ho et al.~\cite{ho2010revisiting} stated that the more human-like an embodied conversational agents (ECA) appears, the stronger the sense of eeriness it evokes. Thaler et al.~\cite{thaler2020agent} confirmed these results in a study comparing a less realistic rendering style of a human avatar to a more realistic rendering. With increased realism, the viewer’s affinity with the ECA decreased.

\subsection{Effects of Level of Immersion}

\revised{Milgram's} mixed reality continuum~\cite{milgram1995augmented} introduces a spectrum that ranges from fully real environments to fully virtual environments, with varying levels of augmented and mixed realities in between. Understanding the effects of immersion is crucial for designing systems that optimize user experience, particularly in healthcare, where patient comfort and engagement are paramount.

Past works have analyzed the impacts that different levels of immersion have on the user in a various contexts. Mania et al.~\cite{mania2001effects} compared four different conditions including real, 3D desktop, 3D head mounted display (HMD) and audio-only for a 15-minute seminar presentation, studying how levels of immersion affect memory recall, memory awareness, and perceptions of the experimental space and sense of presence. While higher presence did not always correlate with accurate memory recall, both presence and semantic memory recall were significantly higher in the ``real'' condition. Ragan et al.~\cite{ragan2010effects} compared low and high immersion in a procedure memorization task by differing field of view of the user directly and of the software and the field of regard. They found that higher levels of immersion resulted in better performance, while specifically stating that lower-cost VR systems showed statistically significant performance improvements compared to conditions with lower immersion levels. Pollard et al.~\cite{pollard2020level} implemented three different levels of  immersive technology: a desktop monitor and a static audio source (low level), a partially occlusive, mid-grade HMD with supra-aural headphones (medium level) and a fully occlusive HMD with circumaural headphones (high level). For the task of an ordered scavenger hunt followed by questions about observed objects and their spatial relationships in the environment, the high immersion condition was found to improve object recognition compared to the medium and low level.
Liberatore and Wagner’s systematic review~\cite{liberatore2021virtual} further supports the importance of immersion by aggregating results from multiple empirical studies, showing that fully immersive VR is effective in creating stress-relief environments or in treating phobias, while AR tends to be more useful in situations where a mix of virtual and real elements are needed, such as rehabilitation tasks.
Drawing from previous studies, we aim to understand how these levels of immersion could affect patient trust, comfort, and acceptance during robotic procedures.
