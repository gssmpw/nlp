\section{Discussion}\label{Sec:GeneralDiscussion}

\subsection{Hypotheses}
\textbf{\textit{H1.}} Our results demonstrate a significant increase in trust scores across all the proposed visualizations featuring the conversational virtual agent, compared to \textbf{RUS}. This finding strongly supports the hypothesis that the presence of the virtual agent contributes to reducing discomfort and increasing acceptance during the robotic ultrasound procedure. Participants were able to ask questions, receive feedback, and feel reassured by the agent’s presence, which appears to have played a key role in fostering trust. Notably, several participants highlighted the hand animation of the virtual assistant holding the ultrasound probe, describing it as a crucial factor in building trust. This subtle yet meaningful interaction gave participants the impression that the virtual agent was aware of the ongoing procedure, making the system appear more intelligent and responsive. By simulating the action of guiding the probe, the virtual assistant conveyed a sense of human control, reducing the perceived detachment often associated with autonomous systems. This visual synchronization between the agent’s actions and the real-world procedure helped humanize the experience, further enhancing confidence in the system’s accuracy and reliability.
Moreover, the usability of the system also improved across all the proposed methods featuring the virtual agent, although significant improvements in usability were only observed with \textbf{AR-VG}. The perceived workload was also reduced in both \textbf{AR-VG} and \textbf{\revised{AV}-VG}. The agent’s conversational abilities, particularly in offering explanations and responding to patient inputs, likely reduced the cognitive burden and made the system easier to navigate.

\textbf{\textit{H2.}} Our results provide partial support for the hypothesis that reducing the visibility of the robot will reduce stress and improve acceptance. When comparing the three immersive visualization methods, \textbf{FV-VG} showed the highest RMSSD values among all conditions in both the resting and execution phases, with the smallest change between these phases. This suggests that participants experienced the least increase in stress during the procedure in the fully immersive environment, potentially due to the absence of the robot’s visual presence, which could reduce feelings of intimidation or anxiety. \add{However, the lack of statistical significance across conditions indicates that the visualization methods may primarily influence psychological perceptions—such as reduced anxiety and improved comfort—rather than inducing measurable changes in physiological stress responses. Additionally, a larger sample size may increase the power of statistical analyses and reveal trends not observed in this study.}
Participant feedback also highlighted the varied reactions to the lack of robot visibility. One participant with no prior experience in robotic procedures noted that in \textbf{FV-VG}, the environment felt like “an animated world,” allowing them to focus less on the procedure itself. This participant expressed a sense of relief and detachment from the robotic aspect, commenting that “before you realize it, the procedure is done.” This suggests that for those unfamiliar with robotic systems, full immersion may help reduce anxiety by removing any focus on the technical aspects of the procedure.
However, several participants with more experience in robotics, especially those with development experience, expressed discomfort with not being able to see the robot’s movements. These participants indicated they would prefer to observe the robot, as they were concerned about the possibility of malfunction or errors. This feedback aligns with the lower trust scores for \textbf{FV-VG}, compared to \textbf{AR-VG} and \textbf{\revised{AV}-VG}, despite the reduced physiological stress. The misalignment between the real and virtual bodies in \textbf{FV-VG}, combined with the complete absence of visual cues from the robot, likely contributed to a lower sense of control and trust in the system.
In contrast, \textbf{AR-VG}, where the robot is visible alongside the virtual agent, had the highest trust scores. This suggests that for many participants, being able to observe the robot’s actions provided reassurance and increased their trust in the system. Similarly, \textbf{\revised{AV}-VG}, where the robot was hidden but the patient’s real arm was visible, performed well in terms of trust, though slightly lower than \textbf{AR-VG}. These findings indicate that while reducing the robot’s visibility may lower stress, maintaining some visual connection to the real world, whether through the robot or the patient’s body, is crucial for building trust.

\textbf{\textit{H3.}} Our results indicate support for the hypothesis that the level of immersion influences patient workload and usability. Among the three immersive visualization methods, \textbf{AR-VG} demonstrated the highest usability and the lowest perceived workload. This supports the hypothesis that AR, by maintaining a connection to the real world, allows for greater situational awareness, which makes the system easier to navigate and reduces cognitive effort. Participants could see their surroundings and the virtual agent, making the experience more intuitive and less mentally taxing. The blend of real-world context with virtual elements likely contributed to both the higher usability and the lower workload.
\textbf{\revised{AV}-VG} also performed well in terms of both usability and workload, though slightly below \textbf{AR-VG}. The passthrough window, which allowed participants to see their real arm during the procedure, offered a partial connection to the real world while still immersing them in a virtual environment. This balance between immersion and real-world visibility may have helped reduce mental load compared to \textbf{FV-VG}, as participants were reassured by seeing part of their real body. However, the higher level of immersion compared to \textbf{AR-VG} might have slightly increased cognitive effort, resulting in a moderate workload and usability score.
In contrast, \textbf{FV-VG} demonstrated the lowest usability and the highest perceived workload among the three methods. The fully immersive environment removed all real-world visual cues, requiring participants to rely entirely on the virtual environment and the virtual agent for orientation and guidance. This complete detachment from the real world may have contributed to a sense of disorientation, which in turn negatively impacted usability and increased increased cognitive demand, as participants had to adapt to the fully virtual setting.


\subsection{Insights}


\textbf{Context-aware Communication.}
The importance of context-aware communication from the virtual agent was a key finding in this study, and it aligns with broader research in human-robot interaction~\cite{chevalier2022context}. In medical settings, patients often feel anxious or disconnected from autonomous systems due to the perceived lack of transparency and control. By embedding a conversational agent that is aware of the procedure’s stages—beginning, execution, and ending—our system ensured that patients were continuously informed and reassured. This type of communication reduces uncertainty, which is crucial in maintaining trust and comfort, as seen in other works that emphasize the role of transparency in fostering trust in autonomous systems~\cite{ososky2014determinants,pynadath2018transparency}. Context-aware systems that adjust feedback based on the current state of the procedure, as we implemented, align with research suggesting that timely, relevant communication enhances user experience and trust~\cite{lisetti2015now}. Moreover, while automating feedback can reduce patient cognitive load, it is important to avoid over-automation, as excessive automation can lead to a loss of sense of agency (SoA)~\cite{haggard2012sense,ueda2021influence} and potentially increase stress, especially in medical contexts where patient involvement is critical.

 
\textbf{Balancing Immersion and Real-World Context.}
One of the key insights from our study is the delicate balance between immersion and real-world context in patient experience during robotic ultrasound. While participants generally preferred \textbf{AR-VG} and \textbf{\revised{AV}-VG}, the stress levels were actually lower in \textbf{FV-VG}. This suggests that while a highly immersive environment can reduce physiological stress, it may also disconnect patients from critical real-world cues, such as the robot’s actions, which are crucial for maintaining trust and confidence. Research has shown that users tend to feel more comfortable when they have some level of real-world feedback, particularly in medical settings, where understanding the procedure is important for reducing anxiety~\cite{burghardt2018non,weisfeld2021dealing}. To address this, a potential future design could combine the benefits of both approaches. For instance, in a fully immersive VR environment, or even a calm, relaxing virtual setting, abstract representations of the robot’s state could be introduced. This would allow patients to enjoy the calming benefits of the VR environment while still being aware of the robot’s movements, thus providing both stress reduction and a sense of control. Such a hybrid visualization approach could balance immersion with real-world awareness, enhancing both comfort and trust in autonomous medical procedures.

\textbf{Patient-Centered Design.}
\add{This study represents a first step toward integrating conversational virtual agents and immersive visualizations into robotic ultrasound systems.}
%As a foundational exploration, it highlights the potential of these technologies to humanize robotic medical procedures and improve patient trust and comfort.
A key takeaway from this study is the importance of designing immersive visualizations with the patient’s experience at the forefront, particularly in procedures where patients remain conscious. Our findings emphasize that immersive technologies should not merely serve as technical enhancements but must also be tailored to meet the emotional and psychological needs of patients. The inclusion of a conversational virtual agent, for example, not only humanized the procedure but also helped reduce feelings of isolation and discomfort by providing constant reassurance.
A patient-centered approach can extend beyond medical robotics to other fields where human interaction with autonomous systems is critical. For example, future designs should prioritize personalization~\cite{athanasiou2014towards}, allowing systems to adapt to individual patient preferences, whether through adjusting levels of immersion, offering more or less transparency during the procedure, or tailoring communication styles to the patient’s comfort level. Additionally, systems can be designed to remember previous interactions, enabling the virtual agent to build rapport by referencing past experiences. For instance, when a patient returns for a follow-up visit, the system could greet them and mention something from the previous session, helping to create a more familiar and personalized interaction. Ultimately, this approach ensures that patients remain active participants in their own care, which is essential for fostering long-term trust and acceptance of autonomous technologies.

\subsection{Limitations}
\revised{While the study demonstrates promising results as a proof-of-concept, several limitations and trade-offs should be addressed in future work.}

First, tracking inaccuracies in \textbf{FV-VG} affected user confidence, with some participants reporting misalignment between their real and virtual bodies. This issue stems from two factors: 1) inaccurate hand tracking from the HMD, and 2) the IK solver estimating the arm pose based solely on the hand and head positions. To mitigate this, adding additional sensors to the arm could improve tracking accuracy. However, this would increase the complexity of the setup, which could negatively impact usability. \add{Additionally, these inaccuracies may have introduced biases, placing \textbf{FV-VG} at a disadvantage compared to other conditions. Caution is warranted when interpreting its results, as differences may stem from technical issues rather than the visualization method itself. Future studies should refine tracking mechanisms to ensure fair comparisons and address this imbalance.}

Second, while participants appreciated the conversational abilities of the virtual agent, some reported delays in communication, leading to uncertainty about whether their input was received. To address this, incorporating a visual indicator, such as the avatar nodding its head, or audio feedback, like the avatar quickly responding with a verbal acknowledgment such as “uh-hum,” could help reassure users that their input has been recognized. Additionally, the LLM powering the virtual agent could be further enhanced by training it on more specific data. This would enable the agent to provide more professional and accurate answers during interactions, improving the overall user experience.

Third, in the \textbf{\revised{AV}-VG} implementation, due to technical limitations, virtual elements are not visible in the passthrough window. This is because the Unity Meta Quest SDK only allows the virtual layer to be rendered either above or below the real-world layer, but not mixed. This impacts usability and overall experience, as participants felt less confident without being able to see the avatar holding the ultrasound probe. Exploring other headsets or custom rendering engines that offer more flexibility in how virtual and real-world content is layered might provide a better user experience.

Furthermore, participants noted a depth perception issue in both AR and VR visualizations. The ultrasound image attached to the probe always appeared on top of the patient’s arm, causing patients to misjudge the probe’s position. This misjudgement led to doubts about the system’s accuracy. In the future, improving the visualization of the ultrasound image—such as by adjusting its transparency when it intersects with the arm—could help resolve this issue and provide a more realistic and reassuring experience.
\add{Finally, the participant pool was skewed toward participants with prior knowledge of robotics platforms. While this demographic provided valuable insights into the usability and technical aspects of the system, it may not fully represent the target population—patients with limited exposure to robotic systems. This may have influenced the trust and acceptance measures observed in the study. Additionally, participants’ acceptance of wearing an HMD during the procedure was not separately measured but was included in overall acceptance and trust ratings for the visualizations. Another limitation is the inability to separate the effects of the virtual avatar from those of the ultrasound probe visualization. For example, trust may have increased due to the avatar, the probe visualization, or their combined effects, while usability in \textbf{VP-VG} may have been impacted by physical-virtual alignment errors. Future studies should recruit a more diverse participant pool and explore alternative methods of delivering immersive visualizations to ensure broader applicability.}