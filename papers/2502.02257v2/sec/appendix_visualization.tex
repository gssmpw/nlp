\section{More visualizations.}
\label{app:more_visualization}

We provide additional visualization results in this section. \figref{fig:query_attn_cl} shows the attention maps of different supervised and CL methods of various sizes. The comparison of attention maps between MAE and UNIP is displayed in \figref{fig:distill_query_attn} and \figref{fig:texture_query_attn}. The attention maps of RGB image inputs are visualized in \figref{fig:query_attn_rgb}, exhibiting nearly identical attention pattern distribution with infrared images in \figref{fig:query_attn}.


\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{figures/add_query_attn_v4.pdf}
\vspace{-22pt}
\caption{Visualizations of attention maps in supervised and CL models. The attention maps are averaged over different heads. All CL and supervised methods share similar attention pattern distribution across layers.}
\label{fig:query_attn_cl}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{figures/distill_query_attn_v2.pdf}
\vspace{-22pt}
\caption{Visualizations of layerwise attention maps in MAE and UNIP-S distilled from MAE-L. The \textit{hybrid} patterns emerge in the later layers of UNIP-S but in the middle layers of MAE-L.}
\label{fig:distill_query_attn}
\end{figure}


\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{figures/texture_query_attn_v1.pdf}
\vspace{-22pt}
\caption{Visualizations of attention maps in MAE and UNIP distilled from MAE-L. Attention maps from the 12th layer of MAE-S, the 18th layer of MAE-L, and the 12th layer of UNIP-S are displayed, respectively. Compared to MAE-S and MAE-L, UNIP-S exhibits reduced texture bias, emphasizing shape information over textures.}
\label{fig:texture_query_attn}
\vspace{-15pt}
\end{figure}


\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{figures/query_attn_rgb.pdf}
\vspace{-24pt}
\caption{Attention maps of RGB image inputs for different query tokens in three representative layers. Each query token's attention map corresponds to a row in the attention matrix, averaged over different heads. Images are from ImageNet \citep{imagenet}.}
\label{fig:query_attn_rgb}
\vspace{-14pt}
\end{figure}
