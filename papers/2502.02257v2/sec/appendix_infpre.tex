\section{Pre-training Dataset.}
\label{app:pretraining_dataset}
\subsection{The InfPre dataset.}
\label{app:infpre}

The InfPre dataset is constructed by collecting images from 23 infrared-related visual datasets. The details of the extracted datasets are presented in \tabref{tab:infpre}. To reduce the redundancy in images with similar backgrounds, we employ two sampling methods: fixed-interval sampling and similarity-based sampling. For datasets containing diverse image sequences with different backgrounds, frames are sampled at fixed intervals (\eg 2, 5, and 10) within each sequence. For datasets captured in the same location, we only sample frames that are less similar to each other. The cosine similarity of image embeddings extracted by DINO-B is used as the similarity metric. Images with high similarity to those already sampled images will be discarded. The Faiss \citep{faiss} library is utilized to accelerate the sampling process.

\input{tab_tex/infpre}

\subsection{The InfMix dataset.}


\begin{table}[t]
    \centering
    \caption{The cosine similarity between pre-training and infrared segmentation datasets. The embeddings of images are extracted by DINO-B. The similarity is averaged over all pairwise images from different datasets.}
    \label{tab:domain_gap}
    \vspace{1mm}
    \scriptsize
    \setlength{\tabcolsep}{1.5mm}{
    \scalebox{1.1}{
    \begin{tabular}{l c c c c}
        \toprule
        \multirow{2}{*}{Pre-training dataset} & \multicolumn{4}{c}{Downstream dataset} \\
        \cmidrule(lr){2-5} 
        & SODA & MFNet-T & SCUT-Seg & Mean \\
        \midrule
        ImageNet-1K \citep{imagenet} & 0.083 & 0.074 & 0.081 & 0.079 \\
        COCO \citep{coco} & 0.111 & 0.101 & 0.106 & 0.106 \\
        InfMix & 0.200 & 0.227 & 0.236 & 0.221 \\
        InfMix (gray) & \textbf{0.216} & \textbf{0.246} & \textbf{0.254} & \textbf{0.239} \\
        \bottomrule
    \end{tabular}}}
    \vspace{-3mm}
\end{table}

The InfMix dataset combines the InfPre, the subset of ImageNet-1k \citep{imagenet}, and the training set of COCO \citep{coco}, totaling 859,375 images. \tabref{tab:domain_gap} compares the similarity between various pre-training datasets and three infrared segmentation datasets used in our benchmark. Notably, compared to RGB datasets like ImageNet-1k and COCO, the mixed dataset exhibits higher similarity with infrared downstream tasks, thereby mitigating the representation shift between pre-training and downstream data. Moreover, converting RGB images to grayscale further enhances this similarity, resulting in better fine-tuning performance, as shown in \tabref{tab:dataset_composition_ablation}.

