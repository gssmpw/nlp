\begin{table}[t]
    \caption{The layerwise linear probing (LLP) performance on RGB and depth datasets. Training epochs are 30 for ADE20K and 100 for others.}
    \label{tab:rgb_llp}
    \vspace{1mm}
    \centering
    \scriptsize
    \setlength{\tabcolsep}{0.8mm}{
    \scalebox{1.0}{
    \begin{tabular}{l c c c c c c}
        \toprule
        \multirow{3}{*}{Modality} & \multirow{3}{*}{Dataset} & \multicolumn{2}{c}{DINO-S} & \multicolumn{2}{c}{DeiT-S} \\
        \cmidrule(lr){3-4} \cmidrule(lr){5-6}
        & & Layer 9 & Layer 12  & Layer 9 & Layer 12 \\
        & & \textcolor{gray}{(\textit{Hybrid})} & \textcolor{gray}{(\textit{Global})} & \textcolor{gray}{(\textit{Hybrid})} & \textcolor{gray}{(\textit{Global})} \\
        \midrule
        \multirow{2}{*}{RGB} & ADE20K \citep{ade20k} & \textbf{26.11} & 23.15 & \textbf{24.35} & 22.68  \\
        & MFNet-RGB \citep{mfnet} & \textbf{38.94} & 37.53  & \textbf{30.43} & 29.44 \\
        \midrule
        \multirow{2}{*}{Depth} & NYUDepthv2 \citep{nyuv2} & \textbf{17.25} & 15.29 & \textbf{5.55} & 5.15 \\
        & SUN-RGBD \citep{sunrgbd} & \textbf{13.17} & 11.41 & \textbf{5.61} & 4.94 \\
        \bottomrule
    \end{tabular}}}
    \vspace{-6mm}
\end{table}