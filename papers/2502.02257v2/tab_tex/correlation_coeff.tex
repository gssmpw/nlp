\begin{table}[t]
  \begin{minipage}{0.49\linewidth}
    \caption{Correlation coefficients between the average fine-tuning performance and other metrics.}
    \label{tab:correlation_coeff}
    \centering
    \scriptsize
    \setlength{\tabcolsep}{0.8mm}{
    \scalebox{0.95}{
    \begin{tabular}{c c c c c c}
        \toprule
        Performance Metric & Correlation metric & Small & Base & Large & Mean \\
        \midrule
        \multirow{2}{*}{Linear probe} & Pearson & 0.89 & 0.93 & 0.89 & 0.90  \\
        & Spearman & 1.00 & 1.00 & 1.00 & 1.00 \\
        \midrule
        \multirow{2}{*}{ImageNet Acc} & Pearson & 0.78 & 0.12 & -0.90 & 0.00 \\
        & Spearman & 0.83 & 0.64 & -1.00 & 0.16 \\
        \bottomrule
    \end{tabular}}}
    \vspace{-4mm}
    \end{minipage}
  \hfill
  \begin{minipage}{0.49\linewidth}
  \caption{The LLP performance on RGB datasets. Training epochs are 30 and 100 for ADE20K and MFNet-RGB.}
    \label{tab:rgb_llp}
    \centering
    \scriptsize
    \setlength{\tabcolsep}{0.9mm}{
    \scalebox{0.95}{
    \begin{tabular}{c c c c c c}
        \toprule
        \multirow{2}{*}{Datasets} & \multicolumn{2}{c}{DINO-Small} & \multicolumn{2}{c}{DeiT-Small} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5}
        & Layer 9 & Layer 12 & Layer 9 & Layer 12 \\
        \midrule
        ADE20K \citep{ade20k} & \textbf{26.11} & 23.15 & \textbf{24.35} & 22.68  \\
        MFNet-RGB \citep{mfnet} & \textbf{38.94} & 37.53  & \textbf{30.43} & 29.44 \\
        \bottomrule
    \end{tabular}}}
    \vspace{-4mm}
  \end{minipage}
\end{table}