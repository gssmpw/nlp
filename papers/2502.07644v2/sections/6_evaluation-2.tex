

\subsection{Comparison with Baselines}
\label{sec:compare}

%\bolditalicparagraph{Methodology.}

\subsubsection{Methodology}
Since the large dataset lacks ``\emph{ground-truth}'' 
labels and 
cannot assess violation coverage, we 
create a small, ground-truth dataset to compare \Tool{} with existing auditing solutions.
Specifically, we randomly select 30 ERC20 contracts 
audited by the Ethereum Commonwealth Security 
Department (ECSD), a group of experts who handle auditing requests 
submitted as GitHub issues and release audit results in response~\cite{humanaudited}. 
These contracts and their audit results enable a comparison between automated techniques
and expert reviews. 
%
%The selection criteria are: 
%1)	Solidity source code provided, 2) approval by Solidity programmers 
%with the ``approved'' tag, 
%3) ERC rule violations identified, 
%and 4) all code in a single contract file.
For ERC721 and ERC1155, we only find one contract for each of them from ECSD's GitHub. Additionally, 
we randomly sample eight more contracts for the two ERCs 
from the website of ERCx~\cite{ERCx}.

In total, the ground-truth dataset contains 40 contracts, including 30 ERC20 contracts, 5 ERC721 contracts, and 5 ERC1155 contracts. Each contract contains an average of 553 lines of code. 
These contracts are either audited by ECSD from January 2019 
to October 2023
or analyzed by ERCx 
from May 2024 to December 2024. 
Since some contracts are written in 
outdated Solidity versions and cannot be analyzed by certain baseline 
techniques, we update all contracts to Solidity version 0.8.20. 
This involves renaming contract constructors, adding necessary visibility specifiers, 
and 
saving extra return values to ``\texttt{-}''.
Our modifications do not introduce or remove any rule violations. 
We carefully inspect the contracts and 
identify 159 rule violations, including 28 with high-security impact, 55 with a 
medium-security impact, and 76 with a low-security impact.




\if 0

We perform a head-to-head comparison between \Tool{}
and the five baseline solutions using the ground-truth dataset.
We execute \Tool{}, SCE, GPT-All, GPT-One, and GPT-A 
on the ground-truth dataset.
We manually examine their results and the auditing reports 
from ECSD security experts
to count true positives, false positives, 
and false negatives for each tool.
We assess the solutions’ effectiveness 
and accuracy based on these measures.


The second dataset is a \emph{ground-truth} dataset 
with 30 ERC20 contracts. 
This dataset aims to evaluate whether \Tool{} has a 
comprehensive violation coverage.
All these contracts undergo manual auditing by the Ethereum Commonwealth 
Security Department, a process where Solidity programmers submit an auditing 
request by filing an issue on GitHub, 
and the department subsequently provides the auditing results by responding
to the issue~\cite{humanaudited}.
To form this dataset, we select the most recent 30 auditing requests 
meeting the following criteria: 1) providing the Solidity source code, 
2) approved by the Solidity programmers with the ``approved’’ tag, 
3) containing ERC rule violations, 
and 4) having all code in one contract file. 
On average, each contract file contains 260.9 lines of 
Solidity source code. 
We carefully inspect these contracts and 
identify \shihao{139} ERC rule violations.
Among them, 27 violations have a high-security impact, 
\shihao{48} have a medium-security 
impact, and 64 have a low-security impact.


\bolditalicparagraph{Baseline Techniques.}

\fi

We select six automated techniques as baselines: 
two static analysis tools, Slither-check-erc (\textit{SCE})~\cite{slither-erc} 
and ZepScope (\textit{ZS})~\cite{ZepScope}; 
one dynamic analysis tool, \textit{ERCx}~\cite{ERCx}; 
and three GPT-based methods. 
The GPT-based techniques vary in their configurations. 
\textit{GPT-All} prompts ChatGPT to audit the entire contract for ERC compliance 
in one request, while \textit{GPT-O} verifies each ERC rule individually, 
providing the rule description, relevant public function code, 
called functions, and accessed contract fields. 
Both GPT-All and GPT-O use the same model as \Tool{}. 
The third GPT-based technique, \textit{GPT-A}, uses a customized version of 
ChatGPT (``Smart Contract Auditor'' developed 
by Ryan Harvey~\cite{GPT-RyanHarvey}) to audit the entire contract 
in a single prompt. GPT-A is based on GPT-4. 
These baseline techniques rely either entirely on program analysis or 
LLMs, making comparisons with \Tool{} valuable for highlighting 
the advantages of combining both approaches. Furthermore,
ZS, published in 2024, and ERCx, a commercial service, 
represent the state of the art in smart-contract analysis. 
Additionally, we compare \Tool{} with 
ECSD using all contracts from ECSD’s GitHub, 
as ECSD is the only service for which we have access to auditing results.

\input{tables/tbl-compare}


%\bolditalicparagraph{Experimental Results.}

\subsubsection{Experimental Results}

As shown in Table~\ref{tab:compare}, \Tool{} detects 157 out of the 158 violations, 
\emph{far surpassing the six baseline techniques,} though it reports 29 false positives.

\italicparagraph{\Tool{}} 
accurately identifies all 28 violations with a high-security impact. 
Among them, 27 violations result from failing to throw an exception
when the sender of a transfer lacks sufficient balance, 
the message caller lacks the required privilege, 
or the destination of a transfer is zero. 
One ERC20 rule requires function \texttt{approve(address \_spender, uint256 \_value)} to overwrite \texttt{\_spender}'s allowance
with the input \texttt{\_value}.
The remaining violation incorrectly increases \texttt{\_spender}'s allowance by \texttt{\_value}.
%The remaining violation with a high security is due to not throw an exception
Additionally, \Tool{} identifies 54 medium impact violations, 
including 11 related to missing required functions, 
21 with API declarations 
not meeting ERCs' requirements, 
and 22 allowing or not allowing zero-value inputs and contrary
to ERCs' requirements.
%for \texttt{transfer()} 
%or \texttt{transferFrom()} of ERC20 contracts \shihao{and erc721's balanceOf and ownerOf}. 
Moreover, \Tool{} detects all low-security impact violations, 
64 of which result from failing to emit a required event, 
while the remaining 12 are due to missing event declarations 
or mismatches between the declarations and the requirements. 
%Overall, \textit{\Tool{} effectively identifies ERC rule violations for a variety of reasons.}



\if 0

accurately identifies all the 27\mengting{28} violations with a high-security impact. 
Among them, 12 violations result from neglecting 
to check if the sender holds a sufficient balance 
when transferring tokens. Notably, Solidity 
introduced the underflow check for subtractions 
in version 0.8.0. Consequently, Solidity 
programmers must explicitly compare the balance with 
the transferred amount for versions predating 0.8.0, 
and failing to do so leads to the 12 identified 
violations.
Another 14 violations stem from a failure to verify whether the message caller possesses the required privilege, as mandated by ERC20,
mirroring the violation in Figure~\ref{fig:20-high}. 
One ERC20 rule requires function \texttt{approve(address \_spender, uint256 \_value)} to overwrite the allowance value of \texttt{\_spender}
with the input \texttt{\_value}.
The remaining violation incorrectly increases the allowance of \texttt{\_spender} by \texttt{\_value}. \mengting{the remaining one: throw if \_to is the zero address.} 
Additionally, \Tool{} identifies \shihao{48} \mengting{52?} medium-security impact violations, 
including \shihao{eight} related to missing required functions, 
\shihao{21} with APIs not meeting ERC20's requirements, 
and 19 instances of not allowing zero-value inputs for \texttt{transfer()} 
or \texttt{transferFrom()}. Moreover, \Tool{} detects all low-security impact violations, 
58 of which result from failing to emit a required event, 
while the remaining six are due to missing event declarations 
or mismatches between the declarations and the requirements. 
Overall, \textit{\Tool{} effectively identifies ERC rule violations for a variety of reasons.}

\fi


%\commentty{Missing results
%of the individual components, e.g., rule extraction and rule 
%translation. Section 4.2 shows
%many rules are not successfully
%translated. Is this the same situation in this dataset?} 
%\shihao{yes, it remains the same situation.}

\Tool{} reports 29 false positives when analyzing the ground-truth dataset. Among them, 28 false positives are due to rules not required 
by ERC721 or ERC1155, but mistakenly extracted by \Tool{}. 
Those rules cause false positives for every ERC721 or ERC1155 contract, 
unless the contract does not have the related function. 
The remaining false positive happens when analyzing 
the implementation of \texttt{transferFrom(address \_from, address \_to, uint256 \_value)} of an ERC20 contract,
whose code pattern also causes a false positive when evaluating the large dataset
in Section~\ref{sec:large}.
The implementation compares \texttt{\_from} with the message caller and if they are equal, 
the authorization check is skipped.
Although \Tool{} flags this as a violation due to the bypassed authorization check, we consider it a false positive because this bypass cannot be exploited.



\Tool{} fails to detect one violation 
where the rule requires \texttt{totalSupply()} to return the total quantity of 
supplied tokens, but the implementation incorrectly returns the result of 
subtracting the balance of the zero address from the supplied tokens. 
\Tool{} does not verify compliance with  
rules that govern how to generate return values, leading to this oversight. 
Despite missing this single violation, 
the tool successfully detects all other 158 violations, \textit{demonstrating its strong coverage of ERC rule violations.}










\italicparagraph{SCE.}
As explained in Section~\ref{tab:compare}, 
the functionality of SCE is relatively 
straightforward, leading it only to identify 39 violations. 
All these violations are also identified by 
\Tool{}. 
Among these violations, 26 involve 
instances where a function mandated by an ERC is 
either not implemented or does not match the required API.
The remaining 13 violations are 
event-related. Given that the rules covered by SCE 
are uncomplicated, SCE does not generate any false positives.

\italicparagraph{ZepScope (ZS)}
reports 49 cases where a check required by OpenZeppelin's code is missing. However, only two cases
 where the functions \texttt{ownerOf()} and \texttt{balanceOf()} 
of an ERC721 contract fail to check whether their inputs are zero are true bugs. 
These checks are also required by ERC721 and the two issues are also 
detected by \Tool{}. All other reports are false positives. 
37 are cases where the check exists in the contract, 
but ZS mistakenly identifies it as missing. 
For the remaining ten cases, while the contract lacks the check, 
we believe there is no security or functionality issue. For example, ZS 
flags \texttt{approve()} of an ERC721 contract for not checking if the 
input address is not the message sender. 
However, we see no issue with a caller allowing itself to manage its own tokens, although 
it already has such a privilege.

On the other hand, ZS misses 157 violations, 
demonstrating that relying solely on rules inferred from 
OpenZeppelin’s code is insufficient for detecting ERC violations.



%\shihao{ZepScope exhibits limited efficacy, identifying only two true positives due to its inability to recognize OpenZeppelin functions across different versions of Solidity accurately. Its detection capabilities are confined to missing checks within these functions. However, violations of the ERC standards frequently occur in customized functions, which fall outside ZepScope’s purview. Moreover, ERC violations encompass a broader range of issues beyond mere checks, including event emissions following balance alterations, specific function invocations, and value assignments, none of which ZepScope is equipped to detect. It reported 27 false positives due to its inability to differentiate between the absence of OpenZeppelin's checks and actual violations of ERC standards. }

\italicparagraph{ERCx}
identifies 12 true violations, 
including five cases of non-compliance with ERC API requirements, 
six instances where zero input values are prohibited by the 
implementations but explicitly allowed by ERC20, 
and one case where \texttt{getApproved(uint256 \_tokenID)} of an ERC721 contract 
fails to validate its input \texttt{\_tokenID}. 
%All these violations are detected by \Tool{}.
On the other hand, 
the significant number of missed violations is primarily 
due to ERCx’s unit tests not being comprehensive 
enough to dynamically trigger the violations.

ERCx reports 23 false positives. Among them, 
six cases result from misunderstanding ERC rules, 
such as incorrectly identifying four APIs as non-compliant with ERC requirements, 
even though these APIs are not required by the ERCs.
The remaining 17 cases are due to ERCx’s incomplete or incorrect unit tests.
For example, 
ERCx reports two cases where safeBatchTransferFrom() fails 
to call a required function under ERC1155. However, this function call is only 
required when transferring to a contract, and ERCx’s tests do not trigger this scenario.




\if 0

\shihao{ERCx identifies a mere 13 true positives including interface and check violation. 146 false negatives attributable to a series of constraints inherent in its design. Firstly, ERCx, which operates on a test-suite approach, mandates that contract constructors be parameter-free. This requirement is unmet by nearly half of the contracts, which necessitate parameters to integrate essential dependencies such as router addresses or other interactive contracts. Secondly, its testing framework is structured such that each test method validates only a single expected behavior, whereas many ERC standards necessitate simultaneous adherence to multiple behaviors, thus limiting the scope of its verification capabilities. Thirdly, as a human-maintained test suite, ERCx lacks comprehensive coverage, with numerous ERC rules having no corresponding test methods. Lastly, its ability to assess compliance is restricted solely to ERC-specific functions, leaving non-ERC functions untested, which may lead to overlooked vulnerabilities or compliance issues in broader contract functionalities.

Two false positives likely arose from incomplete test cases. Specifically, in an ERC1155 test case designed to assess whether safeBatchTransferFrom executes successfully when transferring to a smart contract that implements onERC1155BatchReceived but throws an error, the observed issue pertains to the function's behavior with empty input arrays. If the input array is empty, safeBatchTransferFrom exits without executing the transfer and does not invoke onERC1155BatchReceived. Conversely, if the array contains elements, the function proceeds to call onERC1155BatchReceived. This distinction in function behavior based on input conditions was not adequately captured in the test scenarios, leading to the false positives. }

\fi


\italicparagraph{GPT-All, GPT-O \& GPT-A.}
GPT-All, GPT-O, and GPT-A detect 23, 88, and 35 violations, respectively --- 
significantly fewer compared to the violations identified by \Tool{}. 
%Additionally, all of them are also identified by \Tool{}. 
All the three techniques produce a certain number of false positives 
and false negatives,  mainly due to ChatGPT’s misinterpretation of the prompts, 
the rules, and the smart contract code, along with 
unintended discussions of vulnerabilities unrelated to ERCs 
(\eg, reentrancy attacks). 
%These results highlight \textit{the advantage 
%of combining large language models with 
%symbolic execution for smart contract auditing.}





\if 0

GPT-All detects fewer violations and reports fewer false 
positives than GPT-O. 
This is mainly because GPT-All interacts with 
ChatGPT only once per contract, and ChatGPT limits its 
output tokens, resulting in incomplete inspection of the 
contract. 
%In the GPT-All setting, for the 30 contracts 
%analyzed, ChatGPT mentions 369 rules in its responses. In 
%contrast, GPT-One requests ChatGPT to check compliance for 
%3,356 rules 
%on the corresponding contract code.
The analysis results of GPT-A are similar to those of GPT-All, primarily because both of them 
analyze the entire contract with a single prompt.

\fi

\italicparagraph{Comparing with the ECSD auditing service.}
We compare \Tool{} with ECSD using the 32 contracts from ECSD's GitHub.
ECSD identifies 68 violations and
\Tool captures all of them. Additionally, 
\Tool{} identifies another 70 violations that 
the auditing service cannot detect. 
The service has 12 false positives. 
Two false positives occur because auditors are unaware that Solidity automatically generates getter functions for contract fields, leading them to mistakenly believe two required APIs are not implemented. 
ERC20 mandates \texttt{transfer()} to check if the token owner 
has enough balance for the transfer, but no such rule applies to \texttt{transferFrom()}. However, security auditors mistakenly assume a similar rule exists for \texttt{transferFrom()}, resulting in the remaining ten false positives.


%\songlh{XXXX}
%\shihao{ }


\begin{tcolorbox}[size=title]
{\textbf{Answer to advancement:} 
\Tool{} identifies far more violations than the baselines, 
with fewer or comparable false positives, 
highlighting its superiority over existing auditing solutions 
and the advantages of combining symbolic execution with LLMs.}
\end{tcolorbox}


%\mengting{Slither-check-erc could check the erc's conformance. We ran this tool on the small dataset. It reported 40 inconsistencies. All of them were real inconsistencies. 12 of them were mismatch of return types of optional functions such as decimals. For example, DSToken defines decimals in uint256, but it should be uint8. 9 of them were functions like transfer not returning bool. 6 of them were missing functions. 7 of them were missing event. 4 of them were not emitting required event in functions. The other 2 were parameters of event Transfer were not indexed. All these can be detected by our tool.}


% \input{figures/fig-fp}