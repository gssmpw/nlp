\section{Evaluation}
\label{sec:eva}

\bolditalicparagraph{Implementation.}
We utilize the GPT-4 Turbo model~\cite{gpt4turbo} of ChatGPT 
as the LLM in \Tool{}, and interact 
with it via OpenAI's APIs. 
The remaining functionality is developed in Python, 
including %tasks such as 
generating prompts to automatically extract rules from ERC 
documents and translate natural language rules into the EBNF grammar, 
synthesizing constraints, and performing symbolic execution.

The symbolic execution engine is built using Slither~\cite{slither}. 
It inspects each public function, along with its called functions, 
to verify compliance with the rules specified for it in the ERC. 
We employ the SSA form during symbolic execution, 
ensuring a clear distinction between values defined prior to 
function execution and those defined within the function. 
%We iterate each loop at most three times to avoid path explosion.





%\bolditalicparagraph{Benchmarks.}













\bolditalicparagraph{Research Questions.}
Our experiments are designed to answer the following research questions:
%
\begin{itemize}[noitemsep, topsep=0pt, leftmargin=.25in]
%\itemsep 0em 

\item  \emph{Effectiveness}: Can \Tool{} accurately pinpoint ERC rule violations? 
\item  \emph{Advancement}: Does \Tool{} outperform existing auditing solutions?
\item  \emph{Cost}: What are the monetary and time costs of using \Tool{}?
\item  \emph{Generality}: Can \Tool{} detect violations for ERCs beyond those 
studied in Section~\ref{sec:study}?

\end{itemize}





\bolditalicparagraph{Experimental Setting.}
We configure the temperature parameter to zero to make our experimental results
stable when interacting with the LLM. 
%
%Rules missed or incorrectly extracted by the steps of rule 
%extraction and translation
%are manually fixed before performing the subsequent steps. 
%
All our experiments are performed on a server machine, with Intel(R) Xeon(R) Silver 4110 CPU @ 2.10GHz, 256GB RAM, and Red Hat Enterprise Linux 9. 
 






