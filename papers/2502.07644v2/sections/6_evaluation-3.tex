\vspace{-0.1in}

\subsection{Necessity of \Tool{} design points}

\bolditalicparagraph{Methodology.}
To comprehend the significance of individual design points, 
namely ERC rule sequentialization, prompt specialization, 
code slicing, one-shot, and breaking down compound rules, 
we utilize \Tool{} on the ground-truth dataset with each design point deactivated. 
We then count the number of true positives and false positives 
in each experimental setting.
%\songlh{XXX}

\input{figures/fig-TPFP-bar1}
% \input{figures/fig-TPFP-bar2}

\bolditalicparagraph{Experimental Results.}
As shown in Figure~\ref{fig:tp-fp-bar}, the full-featured \Tool{} identifies
the highest number of violations and reports the fewest false positives, 
thereby showcasing \emph{the rationale behind each design point of \Tool{}.} 
Additionally, the full-featured version detects all violations identified by other versions, 
except for one. This particular violation stems from the failure 
to check the returned Boolean value of an external call. 
While the full-featured version misses it, the version with disabled code 
slicing captures it, indicating that a more advanced setting does not necessarily yield better results in all cases.

Both ERC rule sequentialization transforms the process of examining 
the entire ERC20 document (with 35 rules in total) 
into scrutinizing individual rules. 
Similarly, code slicing breaks down the entire contract 
into individual functions. Both approaches simplify the auditing problem 
within a single prompt. Consequently, disabling either of them 
would lead to \Tool{} missing the most violations among all settings. 
%
Prompt specialization reduces the difficulty for the LLM to understand a ERC rule 
and aids the LLM in comprehending when the rule is violated. 
Without it, \Tool{} reports the largest number of false positives among all settings.
Five ERC20 rules require a specific action when a condition is 
met. Without breaking down compound rules, \Tool{} considers many cases where 
a condition does not exist as rule violations, leading to 182 false positives.
One shot assists the LLM in understanding what constitutes a violation for a particular rule with a concrete example. It helps reduce 19 false negatives and 56 false positives.



\if 0


{\color{red} Disable design points of \Tool{} and run the disabled version
on the small dataset.}

\boldparagraph{Compare With Human}


\input{tables/tbl-human}

{\color{red} which repo do you use to get the contracts? 
Are all the contracts erc20?
How long does the human auditor use to audit each contract?
How much money does the programmers pay?
}

\shihao {
  Some Github repositories are used to publish smart contract vulnerability reports. We chose one popular repository~\cite{humanaudited} with hundreds of requests for auditing 
  and collected 30 ERC20 smart contract vulnerability reports 
  
  that claimed to be audited by humans from Github and compared them with our tool. By carefully reviewing these 30 smart contracts, there are 119 ERC-related violations. The human auditors reported 84 true positives and 1 false positive ERC-related violations. In contrast, our tool found 117 true positives and 0 false positives for ERC-related violations at 100\% precision. Our tool even correctly reports the true negative for one violation that was reported by the human auditors mistakenly. The mistakenly reported violation is about missing an ERC20 required function "balanceOf". The cause of the false positive is due to the human auditor does not know the Solidity compiler will automatically generate the getter function for the public state variable with the exact same name.
  Furthermore, our tool's 98\% recall rate significantly outperforms the 71\% recall rate of human auditors. This infers that there are 35 ERC-related violations that are missed by the human auditor. 
  
  From the violation severity perspective, there are 63 medium violations and 53 low violations. Of 84 true positives identified by the human auditor, 46 are medium and 38 are low.
  
  From the money cost perspective, the popular price for a vulnerability report is around \$1000+, actual price can be increased depending on the size of the smart contract. The average cost for our tool to audit an ERC20 contract is \$0.8.
  
  From the time perspective, the human auditing process can last 1-7 days depends on the size of the smart contracts. Our tool can finish in several minutes (0.2-0.3 secs per prompt).
  
  Of 117 true positives reported by our tool, 62 are medium and 53 are low. 
  Our tool beats the human auditors in precision, recall, severity, time and cost.

  
}


\boldparagraph{Auditing Real-world Smart Contracts}

\input{tables/tbl-realworld}

\shihao {
    etherscan.io and polyscan.com are the most popular block explorers and analytics platforms for Ethereum and its sidechain Polygon.
    We collected 200 most recent Solidity smart contracts from etherscan.io and polyscan.com, including 100 ERC20 smart contracts, 50 ERC721 smart contracts, and 50 ERC1155 smart contracts. Most of ERC20 smart contracts are from Ethereum and ERC721 and ERC1155 smart contracts are from Polygon. 

    

    In the table \ref{tab:token_type_analysis}, a comprehensive analysis of different Ethereum token types, specifically ERC20, ERC721, and ERC1155, is conducted with a focus on their performance metrics. For 100 ERC20 smart contracts, the True Positives (TP) are recorded at 79, with False Positives (FP) being relatively low at 10. The distribution across risk categories shows 1 in High, a majority of 55 in Medium, and 23 in Low, indicating a significant concentration in the Medium risk category. 50 ERC721 smart contracts, on the other hand, demonstrate a higher TP of 109 and a slightly lower FP of 9. For the 50 ERC1155 smart contracts, there are 34 True Positives and merely 1 False Positives. Notably, there is 1 high severity violation found.

    Listing \ref{lst:erc20-high} is a piece of ERC20 smart contract Solidity code where our tool found the high severity violation, which allows "anyone can transfer anybody's money to anyone". The ERC20 rule, "the function transferFrom should throw unless the \_from account has deliberately authorized the sender of the message via some mechanism", explicitly requires the transferFrom function should have some mechanism to check the authorization of the caller. However, the function transferFrom in listing \ref{lst:erc20-high} does not check anything related to "from" authorization. 

    Listing \ref{lst:erc1155-high} is a piece of ERC1155 smart contract Solidity code where our tool found the other high severity violation. Similar to the ERC20, the ERC1155 rule for function safeTransferFrom, "Caller must be approved to manage the tokens being transferred out of the `\_from` account", clearly define the function 
    safeTransferFrom should check the authorization of the address "from". However, in listing \ref{lst:erc1155-high}, there is no such checking exists. The function safeTransferFrom simply calls the function \_update and it merely checks the address "from" is not equal to zero, which is completely irrelevant to the authorization checking.

    % todo: explain FP
    % 
}

\fi