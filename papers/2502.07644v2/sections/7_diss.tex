
\if 0
\section{Discussion} 
\songlh{XXX}
Threats to validity arise from two primary sources. First, we randomly sample smart contracts 
for our experiments, and we donâ€™t particularly include contracts 
with intricate control flow or data dependence relations. We anticipate LLMs might exhibit worse performance when auditing code with such complexities. 
Second, our empirical study is confined to four ERCs, 
and our experiments only encompass three of them. 
Consequently, the findings and observations from our study and experiments 
may not be generalized to other ERCs. 
Evaluating \Tool{} with more intricate code and 
additional ERCs remains a topic for future investigation.

\fi


%\mengting{
%The main internal threat to validity comes from the complexity of the code. ChatGPT does not understand complex code well. If the code is too long or has a complex structure, ChatGPT has a higher possibility of giving a wrong answer. Another internal threat comes from the quality of ERC, specifically,  standardization and accuracy. \\
%The main external threat comes from the lack of diversity in ERC. AuditGPT only audits ERC-20, ERC-721, and ERC-1155 tokens. It may not generalize to other ERC tokens.\\
%It can also be extended to check code compliance and policy compliance. Extract rules from code specifications of other programming languages and ask ChatGPT to analyze code and identify violations. Extract rules from policies in other areas such as finance and health and ask ChatGPT to analyze records or reports and identify issues. 
%}

\section{Conclusion}

In this paper, we present an empirical study of the implementation rules specified in ERCs, 
examining three key aspects: their content, security implications, and the detailed 
specifications provided in the ERCs. Based on our findings, we have developed an automated 
tool called \Tool{}, which integrates an LLM with symbolic execution to 
evaluate whether smart contracts comply with ERC requirements. \Tool{} has proven effective 
in identifying numerous rule violations and outperforms six baseline techniques and a manual auditing service. 
We anticipate that this research will enhance the understanding of 
ERC rules and their violations, fostering further exploration in this field. Additionally, our work 
highlights the benefits of combining LLMs with formal methods and encourages continued 
research in this area.




%\shihao{
 %   In conclusion, the findings presented in this paper demonstrate the significant potential of Large Language Models (LLMs), specifically GPT-4 Turbo, in revolutionizing the process of auditing smart contracts, particularly those conforming to the ERC standard. The ability of these models to alleviate the burden on human experts by efficiently and cost-effectively performing such complex and often tedious tasks is clearly evident. This research underscores that GPT-4 Turbo possesses the requisite intelligence to not only comprehend the rules in the natural language involved in ERC but also to accurately interpret their corresponding code implementations.

%A key takeaway from this study is the strategy of breaking down complex tasks like smart contract auditing into smaller, more manageable components. This approach significantly enhances the effectiveness of LLMs in handling intricate tasks, thereby optimizing their potential in practical applications. The promising results of this study suggest a broader applicability of this methodology. It is anticipated that the principles and techniques outlined here can be effectively generalized to other scenarios that involve different forms of rule-implementation pairs. The implications of this research extend beyond smart contract auditing, paving the way for the wider adoption of LLMs in various fields where complex rule-based tasks are prevalent. This paves the path for future research and development in the domain of artificial intelligence, highlighting the transformative impact of LLMs in automating and enhancing complex cognitive tasks.
%}