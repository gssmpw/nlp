\documentclass[11pt]{article}
\usepackage[margin=0.8in]{geometry}
\usepackage{enumitem}
\usepackage{microtype}
\usepackage{parskip}
\usepackage{times}
\usepackage{xcolor}
\usepackage{url}
\usepackage{hyperref}

\definecolor{light-blue}{rgb}{0.95,0.95,1.0}

\begin{document}
\thispagestyle{empty}

\noindent\textbf{Paper \#6419}: voc2vec: A Foundation Model for Non-Verbal Vocalization

\noindent\textbf{Response to Reviewers}
\noindent We thank all reviewers for their constructive feedback. We address each reviewer's concerns below:

\vspace{2mm}
\noindent\colorbox{light-blue}{\parbox{\dimexpr\linewidth-2\fboxsep}{\textbf{Reviewer \#1}}}
\noindent We really appreciate the reviewer's recognition of our work. We address the concerns raised:

\begin{enumerate}[leftmargin=*,nosep]
\item \textbf{Model Comparison:} We acknowledge the reviewer's concern about fairness in comparison. The additional pre-training step required to create voc2vec models is computationally expensive, making it impractical to replicate for all baseline models. Instead, we provided direct comparisons of wav2vec2 initialized from both LibriSpeech and AudioSet for a fair analysis of different pre-training strategies.

\item \textbf{Experimental Protocol and Methodology:} The protocol and the methodology is consistent across all baselines. We will enhance the paper with clearer details about the experimental setup, including data splits, feature extraction, and evaluation procedures.
\end{enumerate}

\vspace{1mm}
\noindent\colorbox{light-blue}{\parbox{\dimexpr\linewidth-2\fboxsep}{\textbf{Reviewer \#2}}}
\noindent Thank you for the detailed feedback and recognition of our work's value. We address your specific points:

\begin{enumerate}[leftmargin=*,nosep]
\item \textbf{Model Architecture Choice:} The choice of wav2vec base architecture was driven by computational efficiency considerations, as the additional pre-training step is resource-intensive. Given our encouraging results, we agree that exploring larger architectures is a valuable next step.

\item \textbf{Dataset Selection:} NNIME was selected specifically because it contains natural dyadic interactions with reactions, unlike acted databases such as IEMOCAP. This aligns with our focus on capturing genuine non-verbal expressions.
\end{enumerate}

We appreciate your suggestions for future work and are grateful for recognizing the foundation we've established for advancing research in this domain.

\vspace{1mm}
\noindent\colorbox{light-blue}{\parbox{\dimexpr\linewidth-2\fboxsep}{\textbf{Reviewer \#3}}}
\noindent We appreciate the feedback and address the concerns:

\begin{enumerate}[leftmargin=*,nosep]
\item \textbf{Novelty Beyond Training Data:} Our contribution extends beyond data curation. The ablation study in Table III demonstrates that our pre-training strategy significantly improves performance compared to models pre-trained on speech or general audio. The consistent outperformance across diverse downstream tasks validates our approach.

\item \textbf{AudioSet Pre-training:} We actually did experiment with AudioSet pre-training (voc2vec-as in Table III). However, as shown in our results, initializing from LibriSpeech proved more effective. This suggests that speech pre-training provides better foundational features for non-verbal vocalization tasks.
\end{enumerate}

\end{document}