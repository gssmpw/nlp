\begin{algorithm}[H]
\caption{\texttt{Abstract-Skill-RRT}}\label{algo:Abstract-skill-rrt}
\begin{algorithmic}[1]
\State \textbf{Input:} initial and goal config $(q^{\text{obj}}_0, q^{\text{obj}}_{\text{goal}})$, skill library $\mathcal{O}$ \\
Metric function $d$ to calculate distance between object poses, Goal sample probability $p_g$

\State $T=\emptyset$    \Comment{Initialize empty tree}
\State $v_{0} \gets \{ q^{\text{obj}}_{0}\}$ \Comment{Create a start node}
% \State $v_\text{goal} \gets \{ q^{\text{obj}}_\text{goal}\}$ \Comment{Create a goal node}
\State $T$.AddNode($v_{0}$)

\While{True}
    \State ${o_\alpha}, {q}^{\text{obj}}_{sg} \gets $\hyperref[algo:SampleSkillAndPose]{\texttt{SampleSkillAndSubgoal}}($\mathcal{O}, p_g$)
    \State ${v}_{\text{near}} \gets$ \hyperref[algo:NearestNode]{\texttt{CheckPreAndNearestNode}}($T, o_\alpha, q^{\text{obj}}_{sg}, d$)
    \State $T \leftarrow $ \hyperref[algo:AbstractExtend]{\texttt{AbstractExtend}}$(T, v_{\text{near}}, o_\alpha, {q}^{\text{obj}}_{sg})$
    \If{$q^{\text{obj}}_{\text{goal}} \in \bigcup_{v \in T.V} \{ v.q^{\text{obj}}_{\text{sg}} \}$}
        \State $v_{\text{goal}} \gets v \in T.V \ \text{s.t.} \ v.q^{\text{obj}}_{\text{sg}} = q^{\text{obj}}_{\text{goal}}$
        \State \textbf{break}
    \EndIf
\EndWhile

\State $\tau^\text{abstract}_{\text{skill}} \gets []$ \Comment{Initialize an empty list}
\While{$v_{\text{goal}} \neq v_0$}
    \State $\tau^\text{abstract}_{\text{skill}}.\text{append}(v_{\text{goal}})$
    \State $v_{\text{goal}} \gets v_{\text{goal}}.\text{parent}$
\EndWhile
\State $\tau^\text{abstract}_{\text{skill}} \gets \tau^\text{abstract}_{\text{skill}}[::-1]$ \Comment{Reverse the list}
\State \Return $\tau^\text{abstract}_{\text{skill}}$

\end{algorithmic}
\end{algorithm}
% {\footnotesize
%\textbf{Algorithm \ref{algo:skill-rrt} Explanation} â€” The Skill-RRT algorithm plans a path from an initial configuration $(q^{\text{obj}}_0, q^{\text{robot}}_0)$ to a goal configuration $q^{\text{obj}}_{\text{goal}}$ using a library of skills $\mathcal{O}$ and connectors $C$. It initializes a tree $T$ with the start node $v_0$ and iteratively samples skills and subgoal configurations. The nearest feasible node in $T$ is identified, and the tree is extended toward the subgoal with skill simulation. If the goal configuration is reached within $N_{max}$ attempts, the path is returned; otherwise, the algorithm fails.}