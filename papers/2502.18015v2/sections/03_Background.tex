\subsection{Rapidly-Exploring Random Tree (RRT)}
RRT is a widely used sampling-based algorithm for efficiently exploring nonconvex, high-dimensional spaces in robotics and motion planning. It incrementally builds a tree, \(T\), rooted at an initial state \(q_\text{init}\), to explore the configuration space \(\mathcal{C}\). RRT leverages the property of voronoi bias \cite{kuffner2000efficient}, which naturally guides the exploration towards large unexplored regions in \(\mathcal{C}\), making it particularly effective for complex spaces.

The algorithm follows three main steps: \texttt{Sample}, \texttt{NearestNeighbor}, and \texttt{Extend}, iteratively growing the tree \(T\). In the \texttt{Sample} step, a random state \(q_\text{rand}\) is drawn from the configuration space \(\mathcal{C}\). Sampling is usually uniform but can be biased toward specific regions, such as \(q_\text{goal}\), to improve efficiency. voronoi bias ensures the tree naturally expands into less-explored regions, promoting uniform coverage of the space. Next, the \texttt{NearestNeighbor} step identifies the closest node \(q_\text{near}\) in the tree \(T\) to \(q_\text{rand}\) using a distance metric $d(q, q') = ||q - q'||$, often the Euclidean distance. Finally, in the \texttt{Extend} step, the algorithm attempts to connect \(q_\text{near}\) to \(q_\text{rand}\) with a straight-line path. If the path lies entirely within the collision-free configuration space \(\mathcal{C}_\text{free}\), \(q_\text{rand}\) is added to \(T\) as a new node. Otherwise, the step is discarded, and the process repeats.

The RRT iterates these steps until a termination condition is met, such as reaching the goal state \(q_\text{goal}\), exceeding a maximum number of iterations, or constructing a sufficiently dense tree. The complete algorithm is summarized in Algorithm~\ref{alg:rrt}.

\input{algos/skill-RRT/Trad_RRT}

% \subsection{Reinforcement Learning}

% \subsection{Imitation Learning}