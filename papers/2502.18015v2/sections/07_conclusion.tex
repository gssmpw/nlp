In this work, we present a framework for long-horizon PNP problems that consists of (1) \skillrrt, a novel planner that extends RRT to PNP problems, (2) connectors, which are used to make transitions between skills, and (3) distillation of \skillrrt{} to a diffusion policy. We demonstrate the effectiveness of our framework in challenging real-world problems, and show that it outperforms the state-of-the-art learning algorithm, MAPLE, and \skillrrt.


%data generation by sequencing independently trained skills using planning and distilling then into IL to address PNP problems. At its core is a novel planning method, \texttt{Skill-RRT}, which extends the RRT algorithm to operate over object poses and skills. This method enables the training of \textit{connectors} that link the resulting state of one skill to the initiation set of the next skill. Additionally, it identifies \textit{skill plans} that can be effectively chained together to solve complex problems. By leveraging RRT-based planning, we demonstrate that our IL policy outperforms RL approaches designed for PAMDPs. Our integrated planning and IL framework effectively handles multi-modality and ensures the generation of high-quality data through a diffusion policy and a novel filtering rule that leverages simulator stochasticity. This robust combination significantly enhances the success rate of manipulation tasks while enabling efficient execution in practical time.