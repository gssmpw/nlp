In this section, we present a detailed setup for real-world experiments, covering the environment configuration and perception systems for three domains: card flip, bookshelf, and kitchen.

\textbf{Environment Configuration} We utilize the Franka Research 3 robot and its gripper across three domains. To enhance the gripper's effectiveness in non-prehensile manipulation, rubber is added to the gripper fingers to increase surface friction. The environment setups are illustrated in Figure \ref{fig:real_setup}.

\begin{itemize}
    \item \textbf{Card Flip} For the real-world card flip domain, we construct a 30x30x40 cm table identical to the simulation table. The 5x7x0.5 cm card (cuboid shape) is textured with colors to break symmetry in its shape.
    
    \item \textbf{Bookshelf} In the real-world bookshelf domain, we build a bookshelf similar to the one used in simulation and utilize a 14x20x3 cm book (cuboid shape). To facilitate book toppling, sandpaper is affixed to the top surface of the book to enhance shear contact force.
    
    \item \textbf{Kitchen} The kitchen domain utilizes the IKEA DUKTIG play kitchen and a cup with a body that cannot be grasped. To enhance grasping stability, the cup handle is filled with foamboard.
\end{itemize}

\textbf{Perception System} The perception modules are used to estimate object poses in the real world. To address potential occlusions caused by the robot, multiple RealSense D435 cameras are installed, as shown in Figure \ref{fig:real_setup}. For object pose estimation, we use FoundationPose \cite{ornek2025foundpose}, an off-the-shelf RGB-D-based object pose estimator. During each episode, we select the camera with the best visibility, determined by the largest object segmentation mask. The object segmentation mask is initially generated using SAM \cite{kirillov2023segment} and subsequently updated over time using Cutie \cite{cheng2024putting}.

\newpage

\begin{figure*}[ht!]
\centering
\resizebox{\textwidth}{!}{
    \includegraphics{figures/object/real_setup.png}
}
\caption{The real-world setup for each domain is illustrated, with blue polygons representing the target objects and red circles indicating the camera locations.}\label{fig:real_setup}
% \vspace{-1mm}
\end{figure*}



% To address the sim-to-real gap, we increase the friction of the gripper’s fingertips to match the friction characteristics between the simulation and the real world. For the cup-arrangement task, grasping the cup by its handle using the gripper is inherently unstable in real-world scenarios. To resolve this, we fill the cup’s handle with foamboard to ensure a stable grasp. Additionally, two lighting sources are employed during the cup-arrangement task to enhance visibility and ensure consistent RGB-D image capture. \textbf{(failure cases for cup and bookshelf)} Failure cases in the cup-arrangement tasks primarily occur during the execution of the connector $\pi_C$ that leads to prehensile skill $K_{\text{P}}$. Due to the limited manipulation space, the robot often struggles to pull out of the cup without causing the object to move, resulting in infeasible grasp positions (e.g., when the cup handle is too close to the sink wall). Additionally, failures during the execution of $K_{\text{P}}$ are caused by the gripper opening prematurely, leading to the cup being dropped. The results of the real experiment are summarized in Table \ref{table:real_world_result}.

% We conclude with an evaluation of real-world replicas of the card-flipping, book-arrangement in bookshelf, and cup-arrangement in kitchen tasks (see Fig. \ref{fig:CPNP_tasks}). Using IsaacGym, we train \ourmethod{} on simulated versions of these tasks, and the resulting policies were successfully deployed in the real-world environment in a zero-shot manner. We utilize the Franka Research 3 robotic arm for our experiments. The foundation pose is used to estimate both the position and orientation of objects. RealSense D435 cameras are employed to capture RGB-D images. Specifically, four cameras are used for the card-flipping and book-arrangement tasks, while three are used for the cup-arrangement task. To address the sim-to-real gap, we increase the friction of the gripper’s fingertips to match the friction characteristics between the simulation and the real world. For the cup-arrangement task, grasping the cup by its handle using the gripper is inherently unstable in real-world scenarios. To resolve this, we fill the cup’s handle with foamboard to ensure a stable grasp. Additionally, two lighting sources are employed during the cup-arrangement task to enhance visibility and ensure consistent RGB-D image capture. \textbf{(failure cases for cup and bookshelf)} Failure cases in the cup-arrangement tasks primarily occur during the execution of the connector $\pi_C$ that leads to prehensile skill $K_{\text{P}}$. Due to the limited manipulation space, the robot often struggles to pull out of the cup without causing the object to move, resulting in infeasible grasp positions (e.g., when the cup handle is too close to the sink wall). Additionally, failures during the execution of $K_{\text{P}}$ are caused by the gripper opening prematurely, leading to the cup being dropped. The results of the real experiment are summarized in Table \ref{table:real_world_result}.