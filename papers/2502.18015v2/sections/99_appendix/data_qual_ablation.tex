
In this section, we assess the impact of the parameter \( m \) and the effectiveness of our data filtering mechanism. As highlighted by ~\citet{mandlekar2022matters}, the quality of the training dataset plays a crucial role in the performance of imitation learning policies. We demonstrate that our filtering method significantly improves data quality, leading to better policy performance. Baseline Without Replay uses 15,000 skill plans to train a diffusion policy, without filtering, with a trajectory per skill plan. On the other hand, Replay $(m=0.1)$ and Replay $(m=0.9)$ filter out skill plans that do not meet their respective replay success rate threshold $m$. A skill plan's replay success rate is measured by
\[
\frac{\text{Number of successful replays of }\skillplan: N_{success}}{\text{Total number of replays of }\skillplan: N}
\]
as mentioned in Section~\ref{method:IL}. To measure the success rate, we replay each skill plan \( N = 400 \) times and collect the successful trajectories for each skill plan. If a skill plan's \( N_{success} \) exceeds 40, it is included in the Replay with \( m = 0.1 \). If a skill plan's \( N_{success} \) exceeds 360, it is included in the Replay with \( m = 0.9 \). Both methods collect 500 skill plans. From these, we randomly select 30 trajectories from the successful executions for each skill plan. While all successful trajectories can be used, each method collects a total of 15,000 trajectories to ensure a fair comparison when training the distillation policy. After collecting trajectories, we train the distillation policy (Diffusion Policy~\cite{chi2023diffusion}) using trajectories filtered by their respective methods. The training and test settings, as well as the measurement of the success rate for each distillation policy, are identical to those described in Appendix~\ref{Appendix:IL_ablation}.

Table~\ref{table:ablation_dataQ} presents a comparison of three different filtering methods: Without Replay, Replay with \( m = 0.1 \), and Ours (Replay with \( m = 0.9 \)). The table shows several metrics, including the characteristics, the number of skill plans collected, the number of trajectories generated from each skill plan, and the success rates for each domain across the three filtering methods. As shown in the table, our filtering method (Replay with $(m=0.9)$) achieves the highest success rates compared to all other methods.

% the number of skill plans, data collection time, and success rate for three different filtering methods: Without Replay, Replay with $m=0.1$, and Ours (Replay with $m=0.9$). Each method's results are broken down across three domains: Card Flip, Bookshelf, and Kitchen. For each method, the table shows several key metrics: the success rate of the distillation policy, the collection time per plan, the total time spent collecting the plans for each method, and the number of filtered plans that did not meet the replay success rate threshold $m$.

% we provide the detailed results of the ablation experiments on filtering methods, as shown in Figure~\ref{fig:ablation_filtering_success}. % \Romannum{3} in the main paper.
% ~\ref{fig:ablation_filtering_success}.

\input{tables/ablation/ablation_IL_dataQual}

% As shown in the table, our filtering method (Replay with $(m=0.9)$) achieves the highest success rates compared to all other methods. % However, due to the high replay success rate threshold, a significant number of skill plans are discarded. This results in a larger total collection time for our method.

We analyze the skill plans collected by each filtering method in two different ways. First, we examine the distribution of the skill plans' replay success rate, as shown in Figure~\ref{fig:replay_success_dataQ}. Second, we analyze the desired object pose in the skill plans collected by each filtering method in each domain, considering the domain characteristics. The analysis of the skill plans collected by each filtering method in the Card Flip, Bookshelf, and Kitchen domains is described in Figures~\ref{fig:card_y_position_histograms}, \ref{fig:book_thetay_position_histograms}, and \ref{fig:cup_theta_position_histograms}, respectively. Each figure is explained in detail in the following paragraphs.

\begin{figure}[h!] % Adjust to fit within a single column
\centering
% \vspace{-10mm}
\includegraphics[width=0.8\columnwidth]{figures/results/replay_comparison_histograms.png}
\caption{Compare collected skill plan's replay success rate for each filtering method} % Adjust caption text if needed
\label{fig:replay_success_dataQ} % Place the label after the caption
\end{figure}

In Figure~\ref{fig:replay_success_dataQ}, we compare the replay success rates of skill plans collected by each filtering method. The figure's y-axis shows the frequency of skill plans, while the x-axis represents the replay success rate. The replay success rate of all skill plans is measured by replaying \( N = 400 \) times in the parallel simulator, IsaacGym. Filtering with \( m = 0.9 \) prioritizes the collection of high-quality skill plans by selecting those with a higher likelihood of successful replay. As a result, the skill plans collected using the \( m=0.9 \) threshold exhibit a significantly higher average replay success rate compared to those collected with other methods.  % This underscores the importance of applying stricter filtering criteria to ensure the quality and reliability of the collected skill plans, which directly influences their replay success rates.

\begin{figure}[h] % Adjust to fit within a single column
\centering
% \vspace{-10mm}
\includegraphics[width=1.0\columnwidth]{figures/results/card_y_position_with_simul.png}
\caption{The charts on the left and center compare the absolute value of the \(y\)-position of the desired card pose for the slide skill (before the P skill) across each filtering method. The chart on the right shows the graspability of the card pose based on the \(y\)-position in the simulation.} % Adjust caption text if needed
\label{fig:card_y_position_histograms} % Place the label after the caption
\end{figure}

The left and center charts of Figure~\ref{fig:card_y_position_histograms} compare the \(y\)-position of the desired card pose for the slide skill, which is executed before the prehensile skill, as extracted from skill plans collected by each filtering method. The figure's y-axis shows the frequency of the desired card pose for the slide skill, while the x-axis represents the $y$ position's absolute value of the desired card pose in the card flip domain.
For successful grasping, the card should be positioned near the edge of the table (\( y = 0.15 \) or \( -0.15 \)). However, placing the card too close to the edge increases the risk of it falling off, leading to task failure. To balance task feasibility and safety, the desired absolute value of the \( y \)-position for the slide skill should be slightly smaller than 0.15, while still keeping a portion of the card within grasp. This is illustrated on the right side of Figure~\ref{fig:card_y_position_histograms}. The plot shows that skill plans with higher success rates achieve this balance by positioning the card further inward (with smaller absolute \( y \)-values), reducing the risk of it falling while maintaining successful grasping.

\begin{figure}[h] % Adjust to fit within a single column
\centering
% \vspace{-10mm}
\includegraphics[width=1.0\columnwidth]{figures/results/book_theta_with_simul.png}
\caption{The charts on the left and center compare the \( \theta_z \) (yaw) angle of the desired book pose for the Topple skill across each filtering method. The chart on the right shows that higher values of \( \theta_z \) are riskier for the book to fall down in the simulation.} % Adjust caption text if needed
\label{fig:book_thetay_position_histograms} % Place the label after the caption
\end{figure}

The left and center charts of Figure \ref{fig:book_thetay_position_histograms} compare the $\theta_z$ (yaw) angle of the desired book pose for the topple skill, as extracted from skill plans collected by each filtering method. The figure's y-axis shows the frequency of the desired book pose, while the x-axis represents the $\theta_z$ yaw angle for the topple skill in the bookshelf domain.
The toppling angle has a significant impact on task success. A larger toppling angle increases the risk of the book falling, which can lead to task failure, as shown on the right side of Figure~\ref{fig:book_thetay_position_histograms}. Skill plans with higher replay success rates typically constrain the toppling angle to smaller values, ensuring greater stability and reducing the likelihood of failure. In contrast, skill plans with lower replay success rates allow larger toppling angles, increasing the risk of instability and failure. These results demonstrate that our filtering methods produce skill plans with safer and more efficient desired book poses.
 % , while lenient methods lead to suboptimal poses that are more prone to failure.

\begin{figure}[h] % Adjust to fit within a single column
\centering
% \vspace{-10mm}
\includegraphics[width=1.0\columnwidth]{figures/results/cup_theta_with_simul.png}
\caption{The charts on the left and center compare the \( \theta_z \) (yaw) angle values of the desired cup pose for the Sink skill across each filtering method. The chart on the right shows the graspability based on the \( \theta_z \) (yaw) angle of the Sink skill's desired cup pose in the simulation.
} % Adjust caption text if needed
\label{fig:cup_theta_position_histograms} % Place the label after the caption
\end{figure}

The left and center charts of Figure~\ref{fig:cup_theta_position_histograms} compare the $\theta_z$ (yaw) angle of the desired cup pose for the sink skill, as extracted from skill plans collected by each filtering method. The figure's y-axis shows the frequency of the desired cup pose, while the x-axis represents the $\theta_z$ yaw angle for the sink skill in the kitchen domain.
For efficient execution of sink skill, the yaw angle of the cup should ideally lie between \( \pi/2 \) and \( 3\pi/4 \), as shown on the right side of Figure~\ref{fig:cup_theta_position_histograms}. If the handle is not oriented toward the robot, grasping becomes difficult. However, if the handle is directly facing the robot, finding a valid inverse kinematics (IK) solution can also be challenging. The optimal desired pose for the sink skill positions the cup's handle toward the robot with a slight rotation. These intermediate poses are easy to grasp and are usually IK-feasible, which is required for the applicability checker of the P skill. The histogram indicates that skill plans with high replay success rates tend to have desired cup poses within the range \( [\pi/2, 3\pi/4] \), while skill plans with low replay success rates often allow a wider range of angles, leading to suboptimal intermediate poses.

% collection time
However, while filtering with a high replay success threshold of \( m = 0.9 \) leads to robust performance of the distillation policy, it also results in increased collection time, as shown in Table~\ref{table:ablation_dataQ_time}. Due to the high replay success rate threshold, a significant number of skill plans that fail to meet the \( m = 0.9 \) criterion are discarded. Therefore, our filtering method has the longest collection time for collecting a single skill plan. To mitigate this, we generate multiple successful trajectories (30 trajectories per skill plan) from the same skill plan by replay, each with different state-action pairs caused by the simulator's stochasticity and the actions generated from varying observations (domain randomization adds noise to the state). This approach is more time-efficient compared to collecting a large number of skill plans, as in the Without Replay.

\input{tables/ablation/ablation_IL_dataQual_time}
