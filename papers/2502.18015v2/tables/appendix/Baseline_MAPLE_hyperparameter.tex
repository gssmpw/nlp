\begin{table}[h!]
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Hyperparameter} & \textbf{Value} \\ \hline
Hidden sizes (all networks) & 1024, 512, 256, 256 \\ \hline
Q network and policy activation & ReLU \\ 
Q network output activation & None \\ 
Policy network output activation & tanh \\ \hline
Optimizer & Adam \\ 
Batch Size & 4096 \\ 
Learning rate (all networks) & 3e-5 \\ 
Target network update rate \( \tau \) & 5e-4 \\ \hline
\# Training steps per epoch & 1000 \\ 
Replay buffer size & 1e6 \\ 
 \hline
Discount factor & 0.99 \\ 
Reward scale & 100.0 \\ 
Automatic entropy tuning & True \\ 
Target Task Policy Entropy & \( 0.50 \times \log(k), k \text{ is number of skills} \) \\ 
Target Parameter Policy Entropy & \( -\max_a d_a \) \\ \hline
\end{tabular}
\caption{Hyperparameters for the baseline \texttt{MAPLE}}\label{tab:baseline_maple_hyperparams}
\end{table}