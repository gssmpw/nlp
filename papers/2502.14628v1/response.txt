\section{Related Work}
\textbf{Order Sensitivity in In-context Learning} 
Despite the huge success of ICL, its robustness to demonstration permutations remains an unresolved challenge 
Bertug, "Improving In-Context Learning through Robustness Enhancement".


Most \textbf{\textit{training-stage methods}} focus on improving general performance in ICL  Liang et al., "Training Stage Methods for Improving General Performance in In-Context Learning" while neglecting the lack of robustness to the permutations of demonstrations. Recent studies suggest that this phenomenon stems from the autoregressive nature of transformer language models Vinyals et al., "Recurrent Neural Network Regularization by Autoregressive Nature" .
InfoAC  Li et al., "InfoAC: Contrastive Learning for In-Context Learning through Robustness Enhancement" introduces contrastive learning during fine-tuning to break the autoregressive constraint and enable bidirectional token visibility; however, their approach achieves limited success and is restricted to classification tasks. Preliminary work of Zhang et al., "Exploring Permutation Invariance in DeepSet Architecture for Language Modeling Tasks" shows the DeepSet architecture exhibits better permutation invariance than transformer; however, this MLP-based new architecture is too small to solve complex language modeling tasks.
\textit{Our approach falls within the category of training-stage methods but proposes a general learning framework that enhances permutation robustness in LLMs without modifying the Transformer architecture or its autoregressive objective, thereby preserving scalability}.

\textbf{\textit{Inference-stage methods}} can be categorized into four types: 
(1) demonstration selection  Li et al., "Demonstration Selection for Improving In-Context Learning Robustness" , 
which improves normal-case performance but lacks worst-case guarantees under permutations; 
(2) output calibration  Zhang et al., "Output Calibration for Enhancing In-Context Learning Robustness" , which are effective for classification but is less applicable to generation tasks due to sequence calibration challenges; (3) order optimization  Wang et al., "Order Optimization for Enhancing In-Context Learning Robustness" , which finds the best ordering during inference but suffers from exponential complexity; and (4) prediction ensembling: 
A recent work Li et al., "Transforming n-Shot ICL into n One-Shot Predictions for Ensembling Results" transforms n-shot ICL into n one-shot predictions and ensembles resultsâ€”effective for classification but harms generation.
In summary, inference-stage methods mitigate order sensitivity via pre/post-processing, often introducing additional inference overhead. Moreover, most methods target classification and underperform on generation tasks.
\textit{In contrast, our training-stage solution complements inference-stage methods, enhancing LLM robustness without additional inference costs while remaining broadly applicable to various tasks}.


\noindent \textbf{Distributionally Robust Optimization}.
Distributionally robust optimization optimizes the objective function over ambiguity sets, often defined as balls centered on the empirical distribution Ben-Tal et al., "Robust Optimization" . 
Prior applications of DRO have primarily addressed distributional shifts, including label shift  Hardt et al., "Adversarial Training for Adversarial Training"  and data source shift  Sra et al., "Risk-Averse Optimization Using the Empirical Distribution"  and group shift  Kuhn et al., "Distributionally Robust Optimization with Group Shifts" . 
To the best of our knowledge, we are the first to apply DRO to enhance the ICL robustness of LLMs by defining the ambiguity set over all possible permutations of the empirical distribution, thereby providing performance guarantees.

\noindent \textbf{Optimal Transport}. 
Optimal transport is a fundamental mathematical discipline established by Kantorovich et al., "The Optimal Transportation Problem" . It defines a metric for measuring distances between probability distributions, known as the Wasserstein distance, and has been widely employed in machine learning for distribution matching  Cuturi et al., "Sinkhorn Distance: A Non-Asymptotic Formulation of Gradient Regularized Optimization" . 
Our work extends the concept of learning permutation structures through neural networks, as explored in Carmona-Gallego et al., "Learning to Sort Numbers and Solve Jigsaw Puzzles with Neural Networks"  for learning to sort numbers or solve jigsaw puzzles. 
However, we apply OT in the context of LLMs and design a neural network, P-Net, equipped with the Sinkhorn operator to generate challenging permutations, enabling LLMs to undergo DRO training and thereby enhancing their ICL robustness.