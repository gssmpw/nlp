%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Template for USENIX papers.
%
% History:
%
% - TEMPLATE for Usenix papers, specifically to meet requirements of
%   USENIX '05. originally a template for producing IEEE-format
%   articles using LaTeX. written by Matthew Ward, CS Department,
%   Worcester Polytechnic Institute. adapted by David Beazley for his
%   excellent SWIG paper in Proceedings, Tcl 96. turned into a
%   smartass generic template by De Clarke, with thanks to both the
%   above pioneers. Use at your own risk. Complaints to /dev/null.
%   Make it two column with no page numbering, default is 10 point.
%
% - Munged by Fred Douglis <douglis@research.att.com> 10/97 to
%   separate the .sty file from the LaTeX source template, so that
%   people can more easily include the .sty file into an existing
%   document. Also changed to more closely follow the style guidelines
%   as represented by the Word sample file.
%
% - Note that since 2010, USENIX does not require endnotes. If you
%   want foot of page notes, don't include the endnotes package in the
%   usepackage command, below.
% - This version uses the latex2e styles, not the very ancient 2.09
%   stuff.
%
% - Updated July 2018: Text block size changed from 6.5" to 7"
%
% - Updated Dec 2018 for ATC'19:
%
%   * Revised text to pass HotCRP's auto-formatting check, with
%     hotcrp.settings.submission_form.body_font_size=10pt, and
%     hotcrp.settings.submission_form.line_height=12pt
%
%   * Switched from \endnote-s to \footnote-s to match Usenix's policy.
%
%   * \section* => \begin{abstract} ... \end{abstract}
%
%   * Make template self-contained in terms of bibtex entires, to allow
%     this file to be compiled. (And changing refs style to 'plain'.)
%
%   * Make template self-contained in terms of figures, to
%     allow this file to be compiled. 
%
%   * Added packages for hyperref, embedding fonts, and improving
%     appearance.
%   
%   * Removed outdated text.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix}
\usepackage{cite}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{filecontents}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{ulem}
\usepackage{pifont}
\usepackage{color}
\usepackage{soul}
\newcommand{\cc}[1]{\textcolor{blue}{[#1 -cc]}}
\newcommand{\ccc}[1]{\textcolor{red}{[comment: #1 -cc]}}
\definecolor{cd}{RGB}{0, 173, 164}


% 定义自定义命令
\newcommand{\blackcircle}{%
    \begin{tikzpicture}
        \fill[black] (0,0) circle (0.15);
    \end{tikzpicture}%
}

\newcommand{\halfcircle}{%
    \begin{tikzpicture}
        \draw (0,0) circle (0.15);
        \fill[black] (0,0) -- (0.15,0) arc[start angle=0, end angle=90, radius=0.15] -- cycle;
        \fill[black] (0,0) -- (0.15,0) arc[start angle=0, end angle=-90, radius=0.15] -- cycle;
    \end{tikzpicture}%
}



\newcommand{\whitecircle}{%
    \begin{tikzpicture}
        \draw (0,0) circle (0.15);
    \end{tikzpicture}%
}


%-------------------------------------------------------------------------------
\begin{filecontents}{\jobname.bib}
%-------------------------------------------------------------------------------
% @Book{arpachiDusseau18:osbook,
%   author =       {Arpaci-Dusseau, Remzi H. and Arpaci-Dusseau Andrea C.},
%   title =        {Operating Systems: Three Easy Pieces},
%   publisher =    {Arpaci-Dusseau Books, LLC},
%   year =         2015,
%   edition =      {1.00},
%   note =         {\url{http://pages.cs.wisc.edu/~remzi/OSTEP/}}
% }
% @InProceedings{waldspurger02,
%   author =       {Waldspurger, Carl A.},
%   title =        {Memory resource management in {VMware ESX} server},
%   booktitle =    {USENIX Symposium on Operating System Design and
%                   Implementation (OSDI)},
%   year =         2002,
%   pages =        {181--194},
%   note =         {\url{https://www.usenix.org/legacy/event/osdi02/tech/waldspurger/waldspurger.pdf}}}
\end{filecontents}

%-------------------------------------------------------------------------------
\begin{document}
%-------------------------------------------------------------------------------

%don't want date printed
\date{}

% make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Comprehensive Assessment and Analysis for NSFW Content Erasure in Text-to-Image Diffusion models}

%for single author (just remove % characters)
\author{
{\rm Die Chen}\\
East China Normal University
\and
{\rm Zhiwen Li}\\
East China Normal University
\and
{\rm Cen Chen}\\
East China Normal University
\and
{\rm Xiaodan Li}\\
East China Normal University
\and
{\rm Jinyan Ye}\\
East China Normal University
} % end author

\maketitle

%-------------------------------------------------------------------------------
\begin{abstract}
% %-------------------------------------------------------------------------------
% \subsection*{Abstract}

%However, due to the possible inclusion of NSFW (Not Safe for Work) content in training datasets, these models have unintentionally learned to generate such content,
%Nevertheless, the unintentional inclusion of NSFW (Not Safe for Work) content in their training datasets has inadvertently led these models to generate such content,
Text-to-image (T2I) diffusion models have gained widespread application across various domains, demonstrating remarkable creative potential. 
However, the strong generalization capabilities of these models can inadvertently led they to generate NSFW content even with efforts on filtering NSFW content from the training dataset, posing risks to their safe deployment. 
While several concept erasure methods have been proposed to mitigate this issue, a comprehensive evaluation of their effectiveness remains absent. 
To bridge this gap, we present the first systematic investigation of concept erasure methods for NSFW content and its sub-themes in text-to-image diffusion models. At the task level, we provide a holistic evaluation of 11 state-of-the-art baseline methods with 14 variants. Specifically, we analyze these methods from six distinct assessment perspectives, including three conventional perspectives, \textit{i.e.}, erasure proportion, image quality, and semantic alignment, and three new perspectives, \textit{i.e.}, excessive erasure, the impact of explicit and implicit unsafe prompts, and robustness. At the tool level, we perform a detailed toxicity analysis of NSFW datasets and compare the performance of different NSFW classifiers, offering deeper insights into their performance alongside a compilation of comprehensive evaluation metrics. 
Our benchmark not only systematically evaluates concept erasure methods, but also delves into the underlying factors influencing their performance at the insight level. By synthesizing insights from various evaluation perspectives, we provide a deeper understanding of the challenges and opportunities in the field, offering actionable guidance and inspiration for advancing research and practical applications in concept erasure.
% % \textcolor{red}{WARNING: This paper contains model outputs that may be offensive in nature.}



% This paper presents the first systematic investigation of NSFW content erasure in text-to-image diffusion models.
% Specifically,We begin with an exploratory analysis of the evaluation tools. For datasets, we delved into prompt datasets and explored the toxicity correlations between prompts and the images they generate. 
% Regarding NSFW classifiers, we observe that both human and classifiers exhibit varying interpretations of images, along with differing levels of tolerance and openness. 
% %Since our erasure target is NSFW content,
% As our primary focus is the erasure of NSFW content, we classify it into five distinct themes and conduct experiments on each theme, as well as on the overall NSFW category.

% From these perspectives, we have gained critical insights into the effectiveness and methodology of current erasure methods. 
% Our findings offer a roadmap for future advancements in this field. 
%\textcolor{red}{WARNING: This paper contains model outputs that may be offensive in nature.}

\end{abstract}

%\input{Sections/0-Abstract}
\input{Sections/1-Introduction}
\input{Sections/2-0-Related}
\input{Sections/2-1-Taxonomy}
\input{Sections/3-Framework}
\input{Sections/4-Tool}
\input{Sections/5-Effect}
\input{Sections/6-Discussion}
\input{Sections/7-Conclusions}


% %-------------------------------------------------------------------------------
% \section{Introduction}
% %-------------------------------------------------------------------------------

% A paragraph of text goes here. Lots of text. Plenty of interesting
% text. Text text text text text text text text text text text text text
% text text text text text text text text text text text text text text
% text text text text text text text text text text text text text text
% text text text text text text text.
% More fascinating text. Features galore, plethora of promises.

% %-------------------------------------------------------------------------------
% \section{Footnotes, Verbatim, and Citations}
% %-------------------------------------------------------------------------------

% Footnotes should be places after punctuation characters, without any
% spaces between said characters and footnotes, like so.%
% \footnote{Remember that USENIX format stopped using endnotes and is
%   now using regular footnotes.} And some embedded literal code may
% look as follows.

% \begin{verbatim}
% int main(int argc, char *argv[]) 
% {
%     return 0;
% }
% \end{verbatim}

% Now we're going to cite somebody. Watch for the cite tag. Here it
% comes. Arpachi-Dusseau and Arpachi-Dusseau co-authored an excellent OS
% book, which is also really funny~\cite{arpachiDusseau18:osbook}, and
% Waldspurger got into the SIGOPS hall-of-fame due to his seminal paper
% about resource management in the ESX hypervisor~\cite{waldspurger02}.

% The tilde character (\~{}) in the tex source means a non-breaking
% space. This way, your reference will always be attached to the word
% that preceded it, instead of going to the next line.

% And the 'cite' package sorts your citations by their numerical order
% of the corresponding references at the end of the paper, ridding you
% from the need to notice that, e.g, ``Waldspurger'' appears after
% ``Arpachi-Dusseau'' when sorting references
% alphabetically~\cite{waldspurger02,arpachiDusseau18:osbook}. 

% It'd be nice and thoughtful of you to include a suitable link in each
% and every bibtex entry that you use in your submission, to allow
% reviewers (and other readers) to easily get to the cited work, as is
% done in all entries found in the References section of this document.

% Now we're going take a look at Section~\ref{sec:figs}, but not before
% observing that refs to sections and citations and such are colored and
% clickable in the PDF because of the packages we've included.

% %-------------------------------------------------------------------------------
% \section{Floating Figures and Lists}
% \label{sec:figs}
% %-------------------------------------------------------------------------------


% %---------------------------
% \begin{figure}
% \begin{center}
% \begin{tikzpicture}
%   \draw[thin,gray!40] (-2,-2) grid (2,2);
%   \draw[<->] (-2,0)--(2,0) node[right]{$x$};
%   \draw[<->] (0,-2)--(0,2) node[above]{$y$};
%   \draw[line width=2pt,blue,-stealth](0,0)--(1,1)
%         node[anchor=south west]{$\boldsymbol{u}$};
%   \draw[line width=2pt,red,-stealth](0,0)--(-1,-1)
%         node[anchor=north east]{$\boldsymbol{-u}$};
% \end{tikzpicture}
% \end{center}
% \caption{\label{fig:vectors} Text size inside figure should be as big as
%   caption's text. Text size inside figure should be as big as
%   caption's text. Text size inside figure should be as big as
%   caption's text. Text size inside figure should be as big as
%   caption's text. Text size inside figure should be as big as
%   caption's text. }
% \end{figure}
% %% %---------------------------


% Here's a typical reference to a floating figure:
% Figure~\ref{fig:vectors}. Floats should usually be placed where latex
% wants then. Figure\ref{fig:vectors} is centered, and has a caption
% that instructs you to make sure that the size of the text within the
% figures that you use is as big as (or bigger than) the size of the
% text in the caption of the figures. Please do. Really.

% In our case, we've explicitly drawn the figure inlined in latex, to
% allow this tex file to cleanly compile. But usually, your figures will
% reside in some file.pdf, and you'd include them in your document
% with, say, \textbackslash{}includegraphics.

% Lists are sometimes quite handy. If you want to itemize things, feel
% free:

% \begin{description}
  
% \item[fread] a function that reads from a \texttt{stream} into the
%   array \texttt{ptr} at most \texttt{nobj} objects of size
%   \texttt{size}, returning returns the number of objects read.

% \item[Fred] a person's name, e.g., there once was a dude named Fred
%   who separated usenix.sty from this file to allow for easy
%   inclusion.
% \end{description}

% \noindent
% The noindent at the start of this paragraph in its tex version makes
% it clear that it's a continuation of the preceding paragraph, as
% opposed to a new paragraph in its own right.


% \subsection{LaTeX-ing Your TeX File}
% %-----------------------------------

% People often use \texttt{pdflatex} these days for creating pdf-s from
% tex files via the shell. And \texttt{bibtex}, of course. Works for us.

% %-------------------------------------------------------------------------------
\section*{Ethics Considerations}
%-------------------------------------------------------------------------------

In this work, we aim to comprehensively assess the performance of the text-to-image diffusion model erasure method in erasing NSFW content. This study will help promote research on the security and robustness of generative models. We do not seek to create, promote or disseminate any harmful or inappropriate content. The acquisition and use of the datasets used in this work strictly abide by relevant ethical guidelines and laws and regulations. The datasets do not contain any personal or identifiable information, and all data are used for research purposes only. During the research, we try to minimize researchers' direct exposure to unsafe content, while also providing mental health resources to team members to ensure the well-being of the research team as much as possible. We conduct our training and evaluation on open source models, not on online real-time systems. In general, our research work did not violate relevant ethical standards.

%-------------------------------------------------------------------------------
\section*{Open Science}
%-------------------------------------------------------------------------------

We provide anonymized links to our framework code in the paper. If the paper is accepted, we will open source our framework, including all code implementations, evaluation scripts, model weights, etc. Since our dataset may involve some unsafe content, we will release it after careful screening and without violating the community agreement.

%-------------------------------------------------------------------------------
\bibliographystyle{plain}
% \bibliography{ref}
\begin{thebibliography}{10}

\bibitem{bedapudinudenet}
{\sc Bedapudi, P.}
\newblock Nudenet: lightweight nudity detection, 2022.

\bibitem{zhiyi2024p4d}
{\sc Chin, Z., Jiang, C., Huang, C., Chen, P., and Chiu, W.}
\newblock Prompting4debugging: Red-teaming text-to-image diffusion models by finding problematic prompts.
\newblock In {\em Forty-first International Conference on Machine Learning, {ICML} 2024, Vienna, Austria, July 21-27, 2024\/} (2024), OpenReview.net.

\bibitem{sd1-4}
{\sc {CompVis}}.
\newblock {Stable Diffusion 2.0}.
\newblock \url{https://huggingface.co/CompVis/stable-diffusion-v1-4}.

\bibitem{Einstein}
{\sc Einstein, A.}
\newblock {Zur Elektrodynamik bewegter K{\"o}rper}. ({German}) [{On} the electrodynamics of moving bodies].
\newblock {\em Annalen der Physik 322}, 10 (1905), 891--921.

\bibitem{eu-cybercrime}
{\sc {European Commision}}.
\newblock {Draft United Nations convention against cybercrime}.
\newblock \url{https://commission.europa.eu/strategy-and-policy/priorities-2019-2024/europe-fit-digital-age/digital-services-act_en}.

\bibitem{fan2023salun}
{\sc Fan, C., Liu, J., Zhang, Y., Wong, E., Wei, D., and Liu, S.}
\newblock Salun: Empowering machine unlearning via gradient-based weight saliency in both image classification and generation.
\newblock {\em arXiv preprint arXiv:2310.12508\/} (2023).

\bibitem{rinon2023animage}
{\sc Gal, R., Alaluf, Y., Atzmon, Y., Patashnik, O., Bermano, A.~H., Chechik, G., and Cohen{-}Or, D.}
\newblock An image is worth one word: Personalizing text-to-image generation using textual inversion.
\newblock In {\em The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023\/} (2023), OpenReview.net.

\bibitem{gandikota2023erasing-esd}
{\sc Gandikota, R., Materzynska, J., Fiotto-Kaufman, J., and Bau, D.}
\newblock Erasing concepts from diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision\/} (2023), pp.~2426--2436.

\bibitem{gandikota2024unified-uce}
{\sc Gandikota, R., Orgad, H., Belinkov, Y., Materzy{\'n}ska, J., and Bau, D.}
\newblock Unified concept editing in diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision\/} (2024), pp.~5111--5120.

\bibitem{gebru2021datasheets}
{\sc Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J.~W., Wallach, H., Iii, H.~D., and Crawford, K.}
\newblock Datasheets for datasets.
\newblock {\em Communications of the ACM 64}, 12 (2021), 86--92.

\bibitem{google-generate-ai-policy}
{\sc {Google}}.
\newblock {Generative AI Prohibited Use Policy}.
\newblock \url{https://policies.google.com/terms/generative-ai/use-policy}.

\bibitem{pers-api}
{\sc {Google}}.
\newblock {Perspective API}.
\newblock \url{https://perspectiveapi.com/}.

\bibitem{Martin2017fid}
{\sc Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S.}
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock In {\em Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, {USA}\/} (2017), I.~Guyon, U.~von Luxburg, S.~Bengio, H.~M. Wallach, R.~Fergus, S.~V.~N. Vishwanathan, and R.~Garnett, Eds., pp.~6626--6637.

\bibitem{hine2017kek}
{\sc Hine, G., Onaolapo, J., De~Cristofaro, E., Kourtellis, N., Leontiadis, I., Samaras, R., Stringhini, G., and Blackburn, J.}
\newblock Kek, cucks, and god emperor trump: A measurement study of 4chan’s politically incorrect forum and its effects on the web.
\newblock In {\em Proceedings of the International AAAI Conference on Web and Social Media\/} (2017), vol.~11, pp.~92--101.

\bibitem{Hive}
{\sc {Hive}}.
\newblock {Hive}.
\newblock \url{https://docs.thehive.ai/docs/visual-content-moderation}.

\bibitem{ho2020denoising}
{\sc Ho, J., Jain, A., and Abbeel, P.}
\newblock Denoising diffusion probabilistic models.
\newblock {\em Advances in neural information processing systems 33\/} (2020), 6840--6851.

\bibitem{ho2022classifier}
{\sc Ho, J., and Salimans, T.}
\newblock Classifier-free diffusion guidance.
\newblock {\em arXiv preprint arXiv:2207.12598\/} (2022).

\bibitem{hu2021lora}
{\sc Hu, E.~J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., and Chen, W.}
\newblock Lora: Low-rank adaptation of large language models.
\newblock {\em arXiv preprint arXiv:2106.09685\/} (2021).

\bibitem{deepfake}
{\sc Korshunov, P., and Marcel, S.}
\newblock {DeepFakes}: a new threat to face recognition? {A}ssessment and detection.
\newblock {\em CoRR abs/1812.08685\/} (2018).

\bibitem{kumari2023ablating-ca}
{\sc Kumari, N., Zhang, B., Wang, S.-Y., Shechtman, E., Zhang, R., and Zhu, J.-Y.}
\newblock Ablating concepts in text-to-image diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision\/} (2023), pp.~22691--22702.

\bibitem{Lexica}
{\sc {Lexica}}.
\newblock {Lexica}.
\newblock \url{https://lexica.art/}.

\bibitem{li2024self-selfd}
{\sc Li, H., Shen, C., Torr, P., Tresp, V., and Gu, J.}
\newblock Self-discovering interpretable diffusion latent directions for responsible text-to-image generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\/} (2024), pp.~12006--12016.

\bibitem{lin2014microsoft-coco}
{\sc Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll{\'a}r, P., and Zitnick, C.~L.}
\newblock Microsoft coco: Common objects in context.
\newblock In {\em Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13\/} (2014), Springer, pp.~740--755.

\bibitem{Zhiqiu2024vqa}
{\sc Lin, Z., Pathak, D., Li, B., Li, J., Xia, X., Neubig, G., Zhang, P., and Ramanan, D.}
\newblock Evaluating text-to-visual generation with image-to-text generation.
\newblock In {\em Computer Vision - {ECCV} 2024 - 18th European Conference, Milan, Italy, September 29-October 4, 2024, Proceedings, Part {IX}\/} (2024), A.~Leonardis, E.~Ricci, S.~Roth, O.~Russakovsky, T.~Sattler, and G.~Varol, Eds., vol.~15067 of {\em Lecture Notes in Computer Science}, Springer, pp.~366--384.

\bibitem{lu2024mace}
{\sc Lu, S., Wang, Z., Li, L., Liu, Y., and Kong, A. W.-K.}
\newblock Mace: Mass concept erasure in diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\/} (2024), pp.~6430--6440.

\bibitem{lyu2024one-spm}
{\sc Lyu, M., Yang, Y., Hong, H., Chen, H., Jin, X., He, Y., Xue, H., Han, J., and Ding, G.}
\newblock One-dimensional adapter to rule them all: Concepts diffusion models and erasing applications.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\/} (2024), pp.~7559--7568.

\bibitem{meta}
{\sc {Meta}}.
\newblock {Meta}.
\newblock \url{https://transparency.meta.com/en-us/policies/community-standards/}.

\bibitem{llama-guard}
{\sc {meta-llama}}.
\newblock {meta-llama/Llama-Guard-3}.
\newblock \url{https://huggingface.co/meta-llama/Llama-Guard-3-8B}.

\bibitem{moon2024holistic}
{\sc Moon, S., Lee, M., Park, S., and Kim, D.}
\newblock Holistic unlearning benchmark: A multi-faceted evaluation for text-to-image diffusion model unlearning.
\newblock {\em arXiv preprint arXiv:2410.05664\/} (2024).

\bibitem{alexander2022glide}
{\sc Nichol, A.~Q., Dhariwal, P., Ramesh, A., Shyam, P., Mishkin, P., McGrew, B., Sutskever, I., and Chen, M.}
\newblock {GLIDE:} towards photorealistic image generation and editing with text-guided diffusion models.
\newblock In {\em International Conference on Machine Learning, {ICML} 2022, 17-23 July 2022, Baltimore, Maryland, {USA}\/} (2022), K.~Chaudhuri, S.~Jegelka, L.~Song, C.~Szepesv{\'{a}}ri, G.~Niu, and S.~Sabato, Eds., vol.~162 of {\em Proceedings of Machine Learning Research}, {PMLR}, pp.~16784--16804.

\bibitem{openai-safety-updates}
{\sc {OpenAI}}.
\newblock {OpenAI safety update}.
\newblock \url{https://openai.com/index/openai-safety-update/}.

\bibitem{openai-usage-policies}
{\sc {OpenAI}}.
\newblock {Usage policies}.
\newblock \url{https://openai.com/policies/usage-policies/}.

\bibitem{papasavva2020raiders}
{\sc Papasavva, A., Zannettou, S., De~Cristofaro, E., Stringhini, G., and Blackburn, J.}
\newblock Raiders of the lost kek: 3.5 years of augmented 4chan posts from the politically incorrect board.
\newblock In {\em Proceedings of the international AAAI conference on web and social media\/} (2020), vol.~14, pp.~885--894.

\bibitem{minh2024circumventing}
{\sc Pham, M., Marshall, K.~O., Cohen, N., Mittal, G., and Hegde, C.}
\newblock Circumventing concept erasure methods for text-to-image generative models.
\newblock In {\em The Twelfth International Conference on Learning Representations, {ICLR} 2024, Vienna, Austria, May 7-11, 2024\/} (2024), OpenReview.net.

\bibitem{qu2023evolution-meme}
{\sc Qu, Y., He, X., Pierson, S., Backes, M., Zhang, Y., and Zannettou, S.}
\newblock On the evolution of (hateful) memes by means of multimodal contrastive learning.
\newblock In {\em 2023 IEEE Symposium on Security and Privacy (SP)\/} (2023), IEEE, pp.~293--310.

\bibitem{qu2023unsafe}
{\sc Qu, Y., Shen, X., He, X., Backes, M., Zannettou, S., and Zhang, Y.}
\newblock Unsafe diffusion: On the generation of unsafe images and hateful memes from text-to-image models.
\newblock In {\em Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security\/} (2023), pp.~3403--3417.

\bibitem{Alec2021clip}
{\sc Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., and Sutskever, I.}
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em Proceedings of the 38th International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event\/} (2021), M.~Meila and T.~Zhang, Eds., vol.~139 of {\em Proceedings of Machine Learning Research}, {PMLR}, pp.~8748--8763.

\bibitem{Javier2022redteaming}
{\sc Rando, J., Paleka, D., Lindner, D., Heim, L., and Tram{\`{e}}r, F.}
\newblock Red-teaming the stable diffusion safety filter.
\newblock {\em CoRR abs/2210.04610\/} (2022).

\bibitem{rombach2022high}
{\sc Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.}
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition\/} (2022), pp.~10684--10695.

\bibitem{t2ieffect1}
{\sc Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E.~L., Ghasemipour, K., Gontijo~Lopes, R., Karagol~Ayan, B., Salimans, T., Ho, J., Fleet, D.~J., and Norouzi, M.}
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock {\em Advances in Neural Information Processing Systems 35\/} (2022), 36479--36494.

\bibitem{patrick2023safe}
{\sc Schramowski, P., Brack, M., Deiseroth, B., and Kersting, K.}
\newblock Safe latent diffusion: Mitigating inappropriate degeneration in diffusion models.
\newblock In {\em {IEEE/CVF} Conference on Computer Vision and Pattern Recognition, {CVPR} 2023, Vancouver, BC, Canada, June 17-24, 2023\/} (2023), {IEEE}, pp.~22522--22531.

\bibitem{schuhmann2022laion5b}
{\sc Schuhmann, C., Beaumont, R., Vencu, R., et~al.}
\newblock {LAION}-{5B}: An open large-scale dataset for training next generation image-text models.
\newblock {\em Advances in Neural Information Processing Systems 35\/} (2022), 25278--25294.

\bibitem{zhan2020improving}
{\sc Shi, Z., Zhou, X., Qiu, X., and Zhu, X.}
\newblock Improving image captioning with better use of caption.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, {ACL} 2020, Online, July 5-10, 2020\/} (2020), D.~Jurafsky, J.~Chai, N.~Schluter, and J.~R. Tetreault, Eds., Association for Computational Linguistics, pp.~7454--7464.

\bibitem{t2i1}
{\sc Sohl{-}Dickstein, J., Weiss, E.~A., Maheswaranathan, N., and Ganguli, S.}
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In {\em Proceedings of the 32nd International Conference on Machine Learning ({ICML})\/} (2015), pp.~2256--2265.

\bibitem{Stable-Diffusion-2.0}
{\sc {Stability AI }}.
\newblock {Stable Diffusion 2.0}.
\newblock \url{https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/stable_diffusion_2}.

\bibitem{yu2024ring}
{\sc Tsai, Y., Hsu, C., Xie, C., Lin, C., Chen, J., Li, B., Chen, P., Yu, C., and Huang, C.}
\newblock Ring-a-bell! how reliable are concept removal methods for diffusion models?
\newblock In {\em The Twelfth International Conference on Learning Representations, {ICLR} 2024, Vienna, Austria, May 7-11, 2024\/} (2024), OpenReview.net.

\bibitem{un-cybercrime}
{\sc {United Nations}}.
\newblock {Draft United Nations convention against cybercrime}.
\newblock \url{https://documents.un.org/doc/undoc/ltd/v24/055/06/pdf/v2405506.pdf}.

\bibitem{ai-pimping}
{\sc {Wired}}.
\newblock {lnside the Booming 'Al Pimping' lndustry}.
\newblock \url{https://www.wired.com/story/ai-pimping-industry-deepfakes-instagram/}.

\bibitem{Jiazheng2023ImageReward}
{\sc Xu, J., Liu, X., Wu, Y., Tong, Y., Li, Q., Ding, M., Tang, J., and Dong, Y.}
\newblock Imagereward: Learning and evaluating human preferences for text-to-image generation.
\newblock In {\em Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023\/} (2023), A.~Oh, T.~Naumann, A.~Globerson, K.~Saenko, M.~Hardt, and S.~Levine, Eds.

\bibitem{zhang2024forget-fmn}
{\sc Zhang, G., Wang, K., Xu, X., Wang, Z., and Shi, H.}
\newblock Forget-me-not: Learning to forget in text-to-image diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition\/} (2024), pp.~1755--1764.

\bibitem{Richard2018LPIPs}
{\sc Zhang, R., Isola, P., Efros, A.~A., Shechtman, E., and Wang, O.}
\newblock The unreasonable effectiveness of deep features as a perceptual metric.
\newblock In {\em 2018 {IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR} 2018, Salt Lake City, UT, USA, June 18-22, 2018\/} (2018), Computer Vision Foundation / {IEEE} Computer Society, pp.~586--595.

\bibitem{zhang2024defensive-au}
{\sc Zhang, Y., Chen, X., Jia, J., Zhang, Y., Fan, C., Liu, J., Hong, M., Ding, K., and Liu, S.}
\newblock Defensive unlearning with adversarial training for robust concept erasure in diffusion models.
\newblock {\em arXiv preprint arXiv:2405.15234\/} (2024).

\bibitem{yimeng2024unlearndiffatk}
{\sc Zhang, Y., Jia, J., Chen, X., Chen, A., Zhang, Y., Liu, J., Ding, K., and Liu, S.}
\newblock To generate or not? safety-driven unlearned diffusion models are still easy to generate unsafe images ... for now.
\newblock In {\em Computer Vision - {ECCV} 2024 - 18th European Conference, Milan, Italy, September 29-October 4, 2024, Proceedings, Part {LVII}\/} (2024), A.~Leonardis, E.~Ricci, S.~Roth, O.~Russakovsky, T.~Sattler, and G.~Varol, Eds., vol.~15115 of {\em Lecture Notes in Computer Science}, Springer, pp.~385--403.

\bibitem{zhang2024unlearncanvas}
{\sc Zhang, Y., Zhang, Y., Yao, Y., Jia, J., Liu, J., Liu, X., and Liu, S.}
\newblock Unlearncanvas: {A} stylized image dataset to benchmark machine unlearning for diffusion models.
\newblock {\em CoRR abs/2402.11846\/} (2024).

\end{thebibliography}


\input{Sections/Appendix}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%  LocalWords:  endnotes includegraphics fread ptr nobj noindent
%%  LocalWords:  pdflatex acks