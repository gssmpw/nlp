\section{Introduction}
Text-to-image~(T2I) diffusion models \cite{t2i1,alexander2022glide} are capable of generating images from textual descriptions and have found extensive applications in art, design, and business, offering unparalleled creativity and flexibility \cite{t2ieffect1}. However, the potential inclusion of a large number of NSFW (Not Safe for Work) images in the training datasets \cite{schuhmann2022laion5b,rombach2022high} has inadvertently led these models to associate with and generate such content \cite{deepfake,ai-pimping}.
To mitigate this issue, various concept erasure methods have been proposed, such as dataset filtering, parameter fine-tuning, and post-hoc corrections, for suppressing NSFW concepts~\cite{patrick2023safe,gandikota2023erasing-esd,lyu2024one-spm,gandikota2024unified-uce,zhang2024defensive-au,lu2024mace,kumari2023ablating-ca,zhang2024forget-fmn,li2024self-selfd,fan2023salun}. 
%However, due to inconsistencies in training and generation conditions of different methods, it is challenging to compare them fairly.
% \textcolor{cd}{And even if comparisons between erasure methods are conducted, they are only evaluated on nudity concept,} thereby highlighting the necessity for a comprehensive evaluation framework.
%\textcolor{red}{Among them, risk concept erasing is one of parameter fine-tuning methods that \textbf{[CD to do]} and has gradually become a research hotspot due to its low cost and stable performance in safety enhancement for T2I models.[some reference here]}
These concept erasure methods has gradually become a research hotspot due to its importance in safety enhancement for T2I models. 
% \textcolor{red}{[citexxx]}
Given this context, the establishment of a comprehensive benchmark for concept erasing is essential to provide clear guidelines for practical applications, ensuring that researchers and practitioners can effectively harness this method for enhancing the safety and reliability of T2I models.
%\cc{Nevertheless, the intrinsic diversity present in the training processes and generation conditions associated with these erasure methods complicates their direct comparison.Additionally, existing evaluations of these erasure methods have predominantly focused on the nudity concept, thus overlooking the necessity for a more comprehensive assessment.}

Existing evaluations of concept erasure methods mainly focused on object and style erasing tasks~\cite{zhang2024unlearncanvas,moon2024holistic}. The only safety-related evaluation focuses on the nudity concept \cite{lyu2024one-spm,fan2023salun}, overlooking the need for a comprehensive evaluation framework that accommodates a broader range of assessments related to NSFW contents.
While existing benchmarks \cite{qu2023unsafe} for evaluating T2I models do consider various risk concepts, such as violence and obscenity, 
% they cannot be directly applied to assess the effectiveness of concept erasing methods due to their limitations in the evaluation targets and the differences in metrics.
seldom have them considered the evaluation for erasure methods.
% the absence of detailed indicators for analyzing the relationship between the prompts and the unsafe images they generate.
To address this gap, our work provides the first comprehensive investigation into the erasure of NSFW content erasure in T2I diffusion models.


%\sout{Prior research has established benchmarks for the content safety of generative models \cite{qu2023unsafe}.\textcolor{cd}{Such benchmarks do not specifically explore effectiveness of content security solutions, which is concept erasure methods.
%In addition, there are also some benchmarks for comparing concept erasure methods ~\cite{zhang2024unlearncanvas,moon2024holistic}. It is known that the important background for concept erasure methods is the existence of NSFW content, but they did not discuss the erasing effect of NSFW concepts, and only evaluated it on object and style erasing tasks, leaving a critical gap in this area.
%}
%Unfortunately, the erasure methods proposed for NSFW content have not been thoroughly evaluated on this critical issue. 
% However, existing methods targeting the erasure of NSFW content remain insufficiently evaluated, leaving a critical gap in this area. 
%Our work aims to fill this gap by being the first to explore NSFW content erasure in text-to-image diffusion models.To address this gap, our work provides the first comprehensive investigation into the erasure of NSFW content erasure in text-to-image diffusion models.}

%After organizing the definitions and specific themes of NSFW content and categorizing the concept erasure methods, we present our framework in Figure \ref{fig:framework}.
Building upon our systematic organization of definitions and specific themes pertinent to NSFW content, as well as the categorization of concept erasure methods, we introduce our benchmark framework, as illustrated in Figure \ref{fig:framework}.
%For assessment tools, we find that current NSFW-related datasets lack or provide only a rudimentary analysis 
%\textcolor{cd}{
We begin by focusing on evaluation tools, conducting an in-depth analysis of both datasets and NSFW classifiers.
%Our analysis of existing NSFW datasets reveals that 
Our examination of existing NSFW datasets reveals significant limitations, as
they are either insufficient or provide only a rudimentary examination of specific unsafe content related to text prompts and generated images. Therefore, we analyze the toxicity of prompts within the datasets and their corresponding generated images, 
%analyzing the association between the two to assess the inevitability of unsafe prompts resulting in unsafe images.
assessing the correlation between the two to evaluate the likelihood of unsafe prompts leading to unsafe images.
In order to better evaluate the NSFW classifiers, we compare their classification results with human annotations, uncovering divergent interpretations of images and varying levels of openness between human and classifiers. We select the % VQA \cite{Zhiqiu2024vqa} 
classifier that best matches human preferences for subsequent experiments.
%}
%Additionally, we obtain the concept erasure methods with different versions according to the amount of data required, setting five specific NSFW themes and overall NSFW as our erasure targets. 
Subsequently, we conduct extensive experiments involving 11 state-of-the-art concept erasure baselines with 14 variants in total, targeting five specific NSFW themes alongside overall NSFW content for erasure. 
We then propose evaluate these methods from six distinct perspectives. The three conventional perspectives, namely, erasure proportion, image quality, and semantic alignment, 
facilitate an in-depth analysis of the trade-off between the effectiveness of concept erasure and the generative capabilities of these methods.
Meanwhile, the three novel perspectives, namely, excessive erasure, the impact of explicit and implicit unsafe prompts, and robustness, provide critical insights into their performance in targeted erasure and their resilience in challenging scenarios.
%help analyze the balance between concept erasure effectiveness and the generation capability of these methods. 

This benchmark not only assesses current erasure methods but also offers practical guidance for future research, enabling more informed decision-making in real-world applications. By open-sourcing this framework, we provide the community with a flexible, extensible platform and a broader analytical perspective.
% Through evaluation and analysis, we provide a comprehensive assessment of the methods, distill valuable insights and methodologies, and discuss the field's limitations and future directions.
Our contributions are summarized as follows:
\begin{itemize}
[itemsep=0pt]
    \item Task-Level: As the first assessment of concept erasure methods for NSFW and its sub-themes in text-to-image diffusion models, we design a framework to analyze the performance of 11 methods across 14 baselines, considering 6 themes and 6 assessment perspectives.
    \item Tool-Level: We conduct a toxicity analysis of NSFW datasets and compare the accuracy of classifiers, providing deeper insights into their performance and compiling comprehensive evaluation metrics.
    \item Insight-Level: We analyze the results and their underlying causes across various evaluation aspects, summarize our findings, and provide insights and methodologies to inspire future work in the field.
\end{itemize}


