
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \begin{table*}[]
% \small
% \caption{Properties and references of concept erasure methods}
% \label{table:methods}
% \centering
% \scalebox{0.9}{
% \setlength{\tabcolsep}{4pt}
% \begin{tabular}{c|cl|c|c|c}
% \toprule
% \textbf{Stage}            & \multicolumn{2}{c|}{\textbf{Required Data Types}}                                               & \textbf{Core Principles}                  & \textbf{Parameters Involved} & \textbf{Reference}    \\ 
% \midrule
% \makecell{Dataset \\ Cleaning}                       & \multicolumn{2}{c|}{No data required}                                                           & /                                         & /                            & Stable Diffusion v2.0 \cite{Stable-Diffusion-2.0}                \\

% \midrule

% \multirow{6}{*}{\makecell{Parameter \\ Fine-Tuning}} & \multicolumn{2}{c|}{\multirow{3}{*}{Only target text concepts (Mode 1)}}                       & \multirow{2}{*}{Away from target concept} & Unet                         & \makecell{ESD\cite{gandikota2023erasing-esd}, SPM\cite{lyu2024one-spm}}               \\ 

% \cline{5-12} 
%                                        & \multicolumn{2}{c|}{}                              &                                                                                       & Encoder                      & \makecell{AU\cite{zhang2024defensive-au}}                    \\ 
% \cline{4-6} 
%                                        & \multicolumn{2}{c|}{}                                                                           & Close replacement concept                 & Unet                         & \makecell{UCE\cite{gandikota2024unified-uce}}                   \\
% \cline{2-6} 
%                                        & \multicolumn{1}{c|}{\multirow{3}{*}{\makecell{Images \\ (Mode 2)}}} & Safe images opposite to target concepts & Close replacement concept                 & Unet                         & \makecell{AC\cite{kumari2023ablating-ca}, SelfD\cite{li2024self-selfd} }             \\ 
% \cline{3-6}

%                                        & \multicolumn{1}{c|}{}                                 & Unsafe images related to target concept & Other                                     & Unet                         & \makecell{FMN\cite{zhang2024forget-fmn}, MACE\cite{lu2024mace}}              \\ 
% \cline{3-6} 
%                                        & \multicolumn{1}{c|}{}                                 & Both safe and unsafe images             & Close replacement concept                 & Unet                         & \makecell{SalUn\cite{fan2023salun}}                 \\ 
% \midrule
% \makecell{Post-hoc \\ Correction}                    & \multicolumn{2}{c|}{Only target text concepts}                                                  & Away from target concept                  & /                            & \makecell{SLD\cite{patrick2023safe}, SD-NP\cite{ho2022classifier}, \\ Safety Checker\cite{sd1-4}} \\ 
% \bottomrule
% \end{tabular}
% }
% \end{table*}
% \usepackage{multirow}


\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.88\textwidth]{Images/framework.pdf}
    \vspace{-1em}
    \caption{Our benchmark framework consists of three parts: assessment tools, assessment targets, and assessment content. In terms of assessment tools, we conduct toxicity analysis on the NSFW dataset and compare the accuracy of classifiers. These tools are used in assessment experiments for concept erasure methods, which are divided into two modes. To analyze the specific data requirements of each method, we differentiate between different versions of the methods. For assessment content, we categorize specific themes under NSFW and perform the analysis from six different perspectives.}
    \label{fig:framework}
\end{figure*}


\subsection{Safety Benchmarks for Diffusion Models}
Recently, the community has proposed several benchmarks to evaluate the safety of generative diffusion models. For instance, UnsafeD\cite{qu2023unsafe} constructed four unsafe datasets and trained a multi-headed safety classifier to assess the safety of text-to-image models. However, this work primarily focuses on image editing methods and hateful meme generation, without addressing concept erasure methods. 
% Similarly, SLD\cite{patrick2023safe} released the I2P dataset, which comprises real-world unsafe text prompts containing various unsafe concepts. However, it only provides a prompt set without a precise and comprehensive evaluation framework.
% In another example, 
UCANVAS\cite{zhang2024unlearncanvas} introduced a stylized image dataset specifically for assessing style forgetting, but it does not address NSFW concepts. HUB\cite{moon2024holistic} evaluates concept erasure methods from multiple perspectives, such as effectiveness on targets and faithfulness of generated images, but their focus is limited to the erasure of objects. In contrast, our work compiles and organizes multiple unsafe prompt sets and systematically evaluates state-of-the-art concept erasure methods for different NSFW themes in diffusion models.
% We classify these methods and conduct a thorough evaluation of their ability to erase fine-grained NSFW concepts. 
Table \ref{tab:benchmarks} demonstrates the advantages of our approach compared to other benchmarks.




