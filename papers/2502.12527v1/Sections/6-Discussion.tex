\section{Discussion and Limitations}
\label{discuss}
In Section \ref{sixperspectie}, we answer the \textbf{RQ1}-\textbf{RQ3} and provide a comprehensive conclusion of concept erasure methods in Section \ref{effect}. To better address \textbf{RQ4}, we also reflect on the experiences, methodologies, and even the field.
% 8.1 Experience and lessons learned from the method summary, and its impact on the follow-up

% 8.2 Thoughts based on our framework xxxxx

% 8.3 Limitations: The methods in this field are still based on SD1.4, but the latest is 3.5, but the structure has changed and it is difficult to conduct experimental comparisons. Some methods are also deployed in intermediate versions, such as fmn's results on 2.1. Although our framework has unified the comparison conditions as much as possible, it is difficult to make each method exactly achieve the optimal effect.
\subsection{Strategies in NSFW Concept Erasure}
Our benchmark provides a diverse perspective for comparing concept erasure methods.

When erasing different NSFW themes, we observe that concept erasure methods tend to perform better on these with distinct characteristics, such as political or sexually explicit content, while achieving lower success rates on more abstract or nuanced themes.
Here, we also find that some methods, such as ESD, can adapt to different theme erasure tasks by fine-tuning different modules in the model.

Analyzing from the perspective of required data offers valuable insights. For Mode 1, which relies on textual erasure targets, we experiment with different keyword sets (fewer and more keywords versions). We find that the more keyword version yields higher erasure scores, while the fewer keyword version helps preserve the model's generation quality.
For Mode 2, which requires images, we explore how varying the number of images impacts erasure performance. Our findings reveal that some methods have learning capacity limitations, where increasing the number of images does not improve the erasure score. For methods sensitive to the number of images, increasing the image count enhances erasure performance but significantly degrades image quality and semantic alignment. This highlights the need for careful adjustment of guidance strength to balance these trade-offs.


% During the erasure process, we align different themes with specific keywords for target theme removal. Through keyword generalization analysis, we identify the most representative words that are directly associated with each theme. 

% We found that erasing these few representative keywords achieves a high erasure score, and using fewer words may also help preserve the generative quality of the model. For those erasure methods that require images, we also explored the impact of varying the number of images on erasure performance. We found that some methods have a learning capacity limit, and increasing the number of images does not improve the erasure rate. For methods that are sensitive to the number of images, while increasing the training image count can enhance erasure performance, it also significantly impacts both the generated image quality and semantic alignment. Considering all evaluation perspective, we observe that semantic guidance during inference can effectively achieve concept erasure. 

Robustness serves as another critical evaluation perspective. Based on the performance of each method, enhancing robustness can be achieved through adversarial training or by identifying unsafe image features directly in the image space. However, adversarial training often risks model collapse, significantly impacting semantic alignment. In contrast, directly operating in the pixel space proves to be more stable.

Our benchmark is the first to address the issue of excessive erasure in concept erasure methods. 
We observe that some baselines result in genital regions being erased less than other regions. Interestingly, this phenomenon reflects varying levels of openness across strategies. Further exploration in this direction may lead to more adaptable methods tailored to different scenarios.

In practical applications, we recommend selecting erasure methods based on specific use cases. We believe these unique and valuable insights provide the community with a broader perspective and pave the way for advancements in the field.

 % Additionally, intervening during the inference process does not target specific words in the input prompt, offering higher robustness. This is because we found that simply separating relevant words from the concepts to be erased may not be a reliable strategy. Another approach to enhancing erasure robustness is using adversarial training for erasure. However, adversarial training is prone to model collapse, which significantly impacts semantic alignment. A more cost-effective and stable strategy may be to only modify the core parameters of the model. For example, fine-tuning the key/value projection matrices in the cross-attention layers can effectively perform concept erasure while preserving the modelâ€™s original capabilities to the greatest extent. Operating directly in the pixel space of images may help reduce dependence on text. For example, some methods use image masks during training, making them less sensitive to the prompt and enabling them to handle implicit unsafe prompt scenarios. In practical applications, we recommend selecting different erasure methods based on the specific context. Moreover, our findings provide meaningful insights for future research directions and will help the community develop more refined erasure methods. 

\subsection{Availability of Our Benchmark}
Our framework offers a convenient and flexible platform for introducing new datasets to generate images, integrating novel concept erasure methods, and training various baseline versions.
%With concise, easy-to-understand code, it simplifies usage and is available as an open-source project at \url{https://anonymous.4open.science/r/ErasureBenchmark-7BBB}.
The code is designed to be concise and user-friendly, which is accessible at \url{https://anonymous.4open.science/r/ErasureBenchmark-7BBB}.
% However, it is important to note a key limitation: concept erasure methods often depend on diverse packages such as diffusers and transformers, which have undergone rapid iteration in recent years. As a result, the environments required by concept erasure methods proposed at different times are often incompatible, leading to significant challenges in practical use.

\subsection{Limitations}
% We also acknowledge that there are some limitations in our work. Most of the methods in this field are still based on the original Stable Diffusion v1.4, while the latest Stable Diffusion model has reached version 3.5. As the model architecture has significantly changed, it is challenging to directly compare erasure methods across these different model versions. Additionally, some methods are deployed on intermediate versions; for example, the open-source version of FMN is based on Stable Diffusion v2.1. Although our framework has made efforts to standardize the comparison conditions, achieving optimal performance for each method remains a difficult task.  
During the benchmarking process, we identify several limitations in this field. Most existing methods are still based on the original Stable Diffusion v1.4, while the latest Stable Diffusion model has already reached version 3.5. Differences in model architectures make it challenging to directly adapt these methods to newer versions. Furthermore, no novel methods specifically designed for Stable Diffusion v3.5 have been proposed, likely due to the larger model size and increased difficulty in triggering its safety mechanisms.
%%%%%%

Additionally, the industry continues to rely on supervised fine-tuning to address content safety issues, highlighting a disconnect between current research and practical applications. We hope future efforts will focus on adapting methods to newer models and expanding their applicability to broader markets, fostering active and sustainable growth within the community.




% In addition to introducing new evaluation perspectives, our work also provides a comprehensive toolkit, which integrates all the evaluation tools, datasets, and erasure methods we used, enabling us to assess all erasure methods under unified conditions. We have also adapted the toolkit to accommodate the different dependency libraries required by various methods. As diffusion models are rapidly evolving, different methods may be built upon different versions of dependency libraries. During the development of the code, we adopted a modular design approach, ensuring the framework's usability and reusability. For instance, users can customize datasets and easily evaluate new methods. Although we currently focus on evaluating NSFW themes, our framework can be easily extended to assess other concepts with minimal code changes and by defining new datasets. This flexibility is important because many erasure methods are currently only evaluated on one or a few specific themes. We hope our framework will help researchers develop more comprehensive and effective concept erasure methods for text-to-image models.
