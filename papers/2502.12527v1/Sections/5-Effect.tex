%\section{Effect Analysis}
\section{Benchmark Results and Analysis}
\label{sixperspectie}
We evaluate 14 baselines derived from 9 concept erasure methods, all trained or inferred using the original Stable Diffusion v1.4. These include 9 baselines in Mode 1, which require only text erasure targets (each with two versions), and 5 baselines in Mode 2, which require images as input (each with three versions).
For the I2P dataset, one image is generated per prompt, while for the 4chan and Lexica prompt datasets, three images are generated per prompt. For Template prompt dataset, twenty images are generated per prompt. The diffusion process is 40 steps for image generation.


\subsection{Erasure Proportion}
\label{erasure-proportion}
We let all the baselines generate images on four NSFW-related datasets and performed binary classification on them across five themes using VQA. 
Figure \ref{fig:erase} shows the statistical results of the erasure scores for these baselines. The larger the coverage area of the radar chart, the better the baseline is at erasing NSFW content. More specific numerical values are provided in Table \ref{tab:alldatasetscore} of Appendix \ref{erasure-on-all-datasets}. Then we can analyze the results from the aspects of method, version, and theme.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.75\textwidth]{Images/erase.pdf}
    \vspace{-1em}
    \caption{Erasure scores ($\uparrow$) of different methods on five themes in two modes. Different versions of the method generate corresponding images for four NSFW datasets, and after classification using VQA, the erasure scores for each theme are calculated. A larger method coverage area indicates better performance.}
    \label{fig:erase}
\end{figure*}


\noindent\textbf{Method Aspect.} In Mode 1, where only textual keywords are required, SLD-Max performs the best. It also outperforms all other methods and achieves a uniform erasure effect across various themes. As a post-hoc method, SLD gradually increases the guidance scales during the inference process to move further away from the target concept, as evidenced by the incremental trend observed in the erasure scores of SLD-Med, SLD-Str, and SLD-Max. Methods that require training, such as ESD-u, ESD-x, SPM, UCE, and AU, generally perform worse than the four post-hoc methods. This may be because training for different target concepts requires fine-tuning hyperparameters, whereas we set unified hyperparameters here. SPM, the method with the lowest erasure score, includes a semantic distance computation step during generation, which minimizes the effect on prompts that are semantically distant. This may limit its erasure effectiveness. 

In Mode 2, where images are used for fine-tuning, SalUn achieves the highest erasure score. FMN performs the worst, possibly due to its attention decoupling mechanism, which is less suitable for scenarios involving multiple keywords.

\begin{table*}[t!]
\centering
\small
\caption{Results of different methods for erasing overall NSFW in terms of erasure score, image quality, and semantic alignment.There are two sources of NSFW. In Mode 1, one is the concatenation of words in our more keywords version, and the other is the 20 words provided by SLD. For the method of Mode 2, our definition of overall NSFW and a NSFW image dataset composed of 200 images of each theme be used.}
\label{table:nsfw}
\scalebox{0.75}{
\setlength{\tabcolsep}{3pt}
\begin{tabular}{c|c|ccccccccc|c|c|cccccc}
\toprule
                   \textbf{Metric}          & \textbf{Source}      & \textbf{SD-NP}  & \textbf{SLD-Med} & \textbf{SLD-Str} & \textbf{SLD-Max} & \textbf{ESD-u}  & \textbf{ESD-x}  & \textbf{SPM}    & \textbf{UCE}    & \textbf{AU}     &      \textbf{Metric}     & \textbf{Source}                                                              & \textbf{AC}& \textbf{FMN}                     & \textbf{SalUn}                   & \textbf{SelfD}                   & \textbf{MACE}                     \\
\toprule
\multirow{2}{*}{\makecell{Erasure \\ Score ($\uparrow$)}}        & \makecell{ Ours} & 0.66~  & 0.53~   & 0.76~   & \textbf{0.90~}   & 0.12~  & 0.11~  & 0.05~  & 0.30~  & 0.71~  & \multirow{2}{*}{\makecell{Erasure \\ Score ($\uparrow$)}}      & \multirow{2}{*}{\makecell{Ours}} & \multirow{2}{*}{0.26~}  & \multirow{2}{*}{0.01~}  & \multirow{2}{*}{0.52~}  & \multirow{2}{*}{\textbf{0.64~}}  & \multirow{2}{*}{0.36~}   \\
\cline{2-11}

                             & \makecell{SLD}    & 0.42~  & 0.34~   & 0.51~   & \textbf{0.63~}   & 0.05~  & 0.13~  & 0.00~  & -0.04~ & 0.57~  &                            &                                                                      &                         &                         &                         &                         &                          \\
% \cline{3-11} \cline{14-18}
\midrule
\multirow{2}{*}{FID ($\downarrow$)}         & \makecell{Ours} & 26.32~ & 24.02~  & 27.72~  & 33.43~  & \textbf{17.77~} & 18.64~ & 19.40~ & 33.67~ & 22.24~ & \multirow{2}{*}{FID ($\downarrow$)}       & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Ours\end{tabular}} & \multirow{2}{*}{\textbf{19.26~}} & \multirow{2}{*}{18.43~} & \multirow{2}{*}{24.70~} & \multirow{2}{*}{30.01~} & \multirow{2}{*}{51.24~}  \\
\cline{2-11}
                             & \makecell{SLD}    & 24.27~ & 22.60~  & 25.46~  & 29.64~  & 20.08~ & \textbf{18.90~} & 19.22~ & \textbf{}18.47~ & 24.04~ &                            &                                                                      &                         &                         &                         &                         &                          \\
\midrule
\multirow{2}{*}{LPIPS ($\downarrow$)}       & \makecell{Ours} & 0.49~  & 0.48~   & 0.49~   & 0.50~   & \textbf{0.46~}  & 0.47~  & 0.48~  & 0.50~  & 0.48~  & \multirow{2}{*}{LPIPS ($\downarrow$)}     & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Ours\end{tabular}} & \multirow{2}{*}{\textbf{0.47~}}  & \multirow{2}{*}{\textbf{0.47~}}  & \multirow{2}{*}{0.48~}  & \multirow{2}{*}{0.48~}  & \multirow{2}{*}{0.49~}   \\
\cline{2-11}
                             & \makecell{SLD}    & 0.48~  & 0.47~   & 0.48~   & 0.49~   & \textbf{0.46~}  & 0.47~  & 0.48~  & 0.47~  & 0.48~  &                            &                                                                      &                         &                         &                         &                         &                          \\
\midrule
\multirow{2}{*}{CLIPScore ($\uparrow$)}   & \makecell{Ours} & 25.05~ & 25.47~  & 24.66~  & 23.75~  & 24.70~ & 25.11~ & \textbf{26.29~} & 23.58~ & 23.20~ & \multirow{2}{*}{CLIPScore ($\uparrow$)} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Ours\end{tabular}} & \multirow{2}{*}{26.02~} & \multirow{2}{*}{\textbf{26.16~}} & \multirow{2}{*}{24.64~} & \multirow{2}{*}{24.59~} & \multirow{2}{*}{16.39~}  \\
\cline{2-11}
                             & \makecell{SLD}    & 25.20~ & 25.53~  & 24.80~  & 23.97~  & 24.51~ & 25.17~ & 26.29~ & \textbf{26.43~} & 23.30~ &                            &                                                                      &                         &                         &                         &                         &                          \\
\midrule
\multirow{2}{*}{ImageReward ($\uparrow$)} & \makecell{Ours} & -0.06~ & 0.02~   & -0.11~  & -0.31~  & -0.30~ & -0.17~ & \textbf{0.09~}  & -0.76~ & -0.65~ & \multirow{2}{*}{ImageReward ($\uparrow$)}      & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Ours\end{tabular}} & \multirow{2}{*}{\textbf{0.03~}}  & \multirow{2}{*}{0.00~}  & \multirow{2}{*}{-0.19~} & \multirow{2}{*}{-0.58~} & \multirow{2}{*}{-1.88~}  \\
\cline{2-11}
                             & \makecell{SLD}    & 0.01~  & 0.05~   & -0.05~  & -0.20~  & -0.38~ & -0.14~ & 0.10~  & \textbf{0.17~}  & -0.60~ &                            &                                                                      &                         &                         &                         &                         &          \\
\bottomrule
\end{tabular}
}
\end{table*}


\noindent\textbf{Version Aspect.} In Mode 1, the fewer keywords version and the more keywords version show identical results on the Hateful and Political themes due to the consistent keywords adopted for lack of generalization. For other themes, the erasure scores of the methods related to Mode 1 do not differ significantly between the two versions, indicating that our generalization experiment successfully extracted effective and fewer keywords. UCE is relatively more sensitive to versions, which may be because of its deep involvement in the linear transformation of the attention mechanism in cross-attention, where the target concept is replaced with an empty string, thus making the model more sensitive to changes in its own understanding.

In Mode 2, AC, FMN, and MACE demonstrate similar erasure capabilities regardless of the number of training images. In contrast, SelfD and SalUn show improved erasure scores as the number of images increases. This indicates that different training methods may vary in their ability to understand the images. Some methods reach a saturation point in their image understanding, while others enhance their erasure effectiveness through a deeper comprehension.
\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.75\textwidth]{Images/nudenet.pdf}
    \vspace{-1em}
    \caption{Erasure scores ($\uparrow$) of different methods on the sexually explicit theme, obtained using the NudeNet classifier for body part recognition. Negative scores mean the result after erasing is worse. For methods related to Mode 1, we selected the more keyword version, and for methods related to Mode 2, we selected the 200 images version. A larger erasure score indicates better erasure performance of the method.}
    \label{fig:nudenet}
\end{figure*}

\noindent\textbf{Theme Aspect}. ESD-u and ESD-x are results of fine-tuning the same method on different modules, which is why they show varying levels of erasure ability across different tasks. ESD-u is more focused on tangible erasure targets such as sexually explicit, political, and hateful content, while ESD-x is better suited for erasing content related to atmosphere, such as violent or disturbing content. For the same reason, the Political theme in Mode 1 shows the best overall results, while other themes perform worse or are less effective. In Mode 2, methods require different types of images—some need safe images, others require unsafe images—resulting in varying performance across different themes.


\noindent\textbf{Overall NSFW Erasure}.
In addition to specific NSFW themes, we select the more keywords version from Mode 1 and the 200 images version from Mode 2.combining them to create an overall NSFW keyword set for the erasure experiment.
Since the NSFW keyword set from \cite{patrick2023safe}, which includes "hate, harassment, violence, suffering, humiliation, harm, suicide, sexual, nudity, bodily fluids, blood, obscene gestures, illegal activity, drug use, theft, vandalism, weapons, child abuse, brutality, and cruelty" is widely used in other works, we used this set as the erasure target for comparison in the methods related to Mode 1. From Table \ref{table:nsfw}, we observe that our overall NSFW keyword set performs better, and the effectiveness of each method is similar to the results above.

\subsection{Excessive Erasure}
We use NudeNet to more accurately showcase the best version of each method in each mode, identifying specific body parts and calculating erasure scores. As shown in Figure \ref{fig:nudenet}, SLD-Max remains the best method. FMN shows a counterproductive effect, which is because the excessive number of keywords used for training limits the effectiveness of erasure during attention decoupling, as mentioned above. Based on these results, we evaluate whether each method specifically erases genital body parts. To do this, we calculate Genital Ratio Difference, which is the difference in the ratio of these body parts before and after erasure, relative to all detected parts. A larger Genital Ratio Difference indicates that the method achieved more targeted erasure, which translates to better performance.



% Please add the following required packages to your document preamble:
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}
\begin{table*}[t!]
\small
\centering
\caption{Experimental results of excessive erasure for different methods}
\label{table:excess}
\scalebox{0.75}{
\setlength{\tabcolsep}{4pt}
\begin{tabular}{c|ccccccccc|ccccc}
\toprule
                         & \multicolumn{1}{c}{\textbf{SD-NP}} & \multicolumn{1}{c}{\textbf{SLD-Med}} & \multicolumn{1}{c}{\textbf{SLD-Str}} & \multicolumn{1}{c}{\textbf{SLD-Max}} & \multicolumn{1}{c}{\textbf{ESD-u}} & \multicolumn{1}{c}{\textbf{ESD-x}} & \multicolumn{1}{c}{\textbf{SPM}} & \multicolumn{1}{c}{\textbf{UCE}} & \multicolumn{1}{c|}{\textbf{AU}} & \textbf{AC}         & \textbf{FMN}        & \textbf{SalUn}      & \textbf{SelfD}      & \textbf{MACE}       \\

\textbf{Metric}                  & \makecell{more \\ keywords}             & \makecell{more \\ keywords}                        & \makecell{more \\ keywords}                        & \makecell{more \\ keywords}                        & \makecell{more \\ keywords}                      & \makecell{more \\ keywords}                      & \makecell{more \\ keywords}                    & \makecell{more \\ keywords}                    & \makecell{more \\ keywords}                   & \makecell{200 \\ images} & \makecell{200 \\ images} & \makecell{200 \\ images} & \makecell{200 \\ images} & \makecell{200 \\ images} \\
\toprule
\makecell{Genital Ratio \\ Difference ($\uparrow$)} & 9.85\%                    & 7.08\%                               & 14.15\%                              & \textbf{19.27\%}                              & -2.52\%                            & 1.42\%                             & -0.68\%                          & 1.17\%                           & 10.87\%                         & 5.62\%     & -2.00\%    & -22.39\%   & 1.47\%     & 1.27\%  \\
\bottomrule
\end{tabular}
}
\end{table*}

\begin{table*}[t!]
\small
\centering
\caption{The erasure scores ($\uparrow$) of different methods on explicit and implicit unsafe prompts across four NSFW datasets, with all methods erasing our custom overall NSFW keyword set.}
\label{tab:implicit}
\scalebox{0.78}{
\setlength{\tabcolsep}{3pt}
\begin{tabular}{c|ccccccccc|ccccc} 
\toprule
    \multirow{2}{*}{\textbf{\makecell{Types}}}   & \textbf{SD-NP}   & \textbf{SLD-Med} & \textbf{SLD-Str} & \textbf{SLD-Max} & \textbf{ESD-u}   & \textbf{ESD-x}   & \textbf{SPM}     & \textbf{UCE}    & \textbf{AU}      & \textbf{AC}      & \textbf{FMN}     & \textbf{SelfD}   & \textbf{SalUn}   & \textbf{MACE}     \\ 

      & \makecell{more \\ keywords}             & \makecell{more \\ keywords}                        & \makecell{more \\ keywords}                        & \makecell{more \\ keywords}                        & \makecell{more \\ keywords}                      & \makecell{more \\ keywords}                      & \makecell{more \\ keywords}                    & \makecell{more \\ keywords}                    & \makecell{more \\ keywords}                   & \makecell{200 \\ images} & \makecell{200 \\ images} & \makecell{200 \\ images} & \makecell{200 \\ images} & \makecell{200 \\ images} \\
    
\toprule
\makecell{Explicit Unsafe \\ Prompts}    & 73.26\% & 55.87\% & 76.96\% & \textbf{95.00\%} & 46.52\% & 42.17\% & 31.30\% & 56.52\% & 80.00\% & 51.30\% & 29.13\% & 68.04\% & 83.26\% & 56.52\%  \\ 

\midrule
  \makecell{Implicit Unsafe \\ Prompts} & 67.72\% & 56.37\% & 78.51\% & \textbf{90.66\%} & 37.16\% & 34.26\% & 29.73\% & 53.50\% & 83.38\% & 41.41\% & 30.13\% & 62.32\% & 70.31\% & 65.83\%  \\
\bottomrule
\end{tabular}
}
\end{table*}

As shown in Table \ref{table:excess}, SLD-Max exhibits the highest value while ESD-u, SPM, FMN, and SalUn show weaker values. We also find that methods related to Mode 1 are more likely to target genital body parts for erasure compared to those related to Mode 2. This may be because Mode 1 directly utilizes the model's inherent textual priors, but Mode 2 requires the model to relearn features corresponding to the sexually explicit theme from the given images.

\subsection{Explicit and Implicit Unsafe Prompts}
% Based on the analysis in Section \ref{Analysis-of-Datasets}, we calculated the erasure score of different methods on explicit and implicit unsafe prompts, as shown in Table \ref{tab:implicit}. 
% We use a classifier to detect whether the generated images are unsafe and report the results of all methods for erasing the overall NSFW theme composed of more keywords.
Section \ref{Analysis-of-Datasets} defines explicit and implicit unsafe prompts. In this subsection, we examine the erasure scores of these prompts across different baselines to evaluate their adaptability to various types of unsafe prompts. Here we use the results of each baseline trained on overall NSFW and show erase scores in Table \ref{tab:implicit}.

SLD-Max achieves the highest erasure score on implicit unsafe prompts, although it is slightly lower than the erasure score for explicit unsafe prompts. We observe that only FMN, AU, and MACE achieve better performance on implicit unsafe prompts compared to explicit unsafe prompts. 
We analyzed this phenomenon and obtained the following inferences. MACE directly uses image masks during training to erase unsafe concepts in pixel space, making it less sensitive to text prompts and more effective on implicit unsafe prompts. AU improves its adaptability to unsafe prompts through adversarial training. FMN exhibits poor overall erasure performance, with similar erasure scores for both explicit and implicit prompts.


% However, FMN demonstrates a low erasure score across both prompt sets. MACE uses image masking during training, and its operations in the pixel space make it less sensitive to text, thus performing well on implicit unsafe prompts. Meanwhile, AU employs adversarial training to erase learned adversarial concepts, which are implicit in nature.
 % while AU and MACE exhibit similar behavior to the conclusions drawn in the robustness analysis, indicating that they may be insensitive to the input prompt. The robustness prompts generally do not contain the target keywords explicitly. 
% Combining the robustness analysis, we can conclude that the current approach of decoupling specific keywords from the concepts to be erased may not be the most reliable strategy.

\subsection{Image Quality}
\label{image-quality}
We conduct a generative image quality evaluation on the COCO-10K dataset for all baselines, including different versions of each method. The results are presented on the left side of Figure \ref{fig:quanlityandalignment}, where methods positioned closer to the lower-left corner indicate better image quality. More specific value results are provided in Appendix \ref{quality-on-all-datasets}. Both ESD-u and ESD-x showed the best image quality, but the image quality of ESD-x is slightly worse than that of ESD-u. This difference might be attributed to ESD-u fine-tuning the unconditional layers, whereas ESD-x fine-tunes the cross-attention layers in the UNet, which may potentially impact its text understanding capability. The two versions of SLD-Max and the 1000 images version of SelfD generate images of very poor quality, which is inversely proportional to their effectiveness in concept erasure. 
% This suggests that while significant semantic guidance during inference is effective for concept erasure, directly manipulating the intermediate states of generated images can substantially degrade image quality.

In Mode 1, using fewer keywords generally results in slightly better image quality. In Mode 2, the number of training images used by methods like FMN, AC, and MACE does not significantly affect image quality. However, as mentioned earlier, different methods have varying capabilities in learning from images. For SelfD and SalUn, using more images results in poorer quality.
We also conduct experiments on the overall NSFW theme, as shown in Table \ref{table:nsfw}. When the methods related to Model 1 use the 20 words provided by SLD, they perform better in terms of image quality. Methods in Mode 2 may have a more significant impact on image quality when erasing the overall NSFW theme. 

Overall, we observe that improving the erasure effect often leads to a loss in image quality, which aligns with common expectations. Striking a balance between these two factors will be a key challenge for future work.


\subsection{Semantic Alignment}
\label{semantic-alignment}
The right side of Figure \ref{fig:quanlityandalignment} illustrates a comparison of the semantic alignment result achieved by various methods on the COCO-10k dataset. And methods closer to the upper-right corner indicate better semantic alignment. The complete results can be found in Appendix \ref{quality-on-all-datasets}. 

The two versions of SPM achieve good alignment, likely because SPM trains an adaptor specifically to handle the target words, with minimal impact on unrelated words. 
Both versions of AU exhibit poor semantic alignment, possibly due to the use of adversarial training, where the model continuously generates and erases adversarial concepts during training. 
However, this adversarial training approach often leads to model collapse, causing significant interference with other concepts.

Methods in Mode 1 exhibit better semantic alignment than those in Mode 2. Additionally, within Mode 1, the version of fewer keywords demonstrates better semantic alignment than the more keywords version. For SelfD and SalUn in Mode 2, increasing the number of training images has a significant impact on semantic alignment. 
Additionally, we observe that semantic alignment and image quality do not always correlate. For example, AU generates images of medium quality, yet its semantic alignment is poor, highlighting the importance of evaluating methods from multiple perspectives.


\subsection{Robustness}
Table \ref{tab:robustness} compares the performance of different methods on the RAB dataset and four NSFW datasets (4-NSFW). Methods in Mode 1 use the more keywords version, while methods in Mode 2 use the version with 200 training images. If the baseline performs better on RAB than on the four NSFW datasets, we consider the baseline to be more robust.
Except for SLD-Max, AU, and MACE, most methods perform poorly on robustness prompts. This suggests that many existing erasure methods only separate relevant words from the target theme and do not fully eliminate theme from the model. Although SLD-Max extensively guides semantics in the noise space, thereby mitigating the impact of toxic prompts, its general performance has been compromised. AU targets adversarial prompts for erasure; and may have overfitted to these prompts, leading to better erasure results on the RAB dataset compared to general NSFW prompts. Meanwhile, MACE also performs well on the RAB dataset, likely because it uses masks for training and operates directly in the pixel space, making it less sensitive to text prompts. Across different modes, there is no significant difference in robustness. 
% While intuitively, methods that use images may effectively combat toxic text, they often still rely on keywords during training, which means they also separate the relevant words within the model.




\subsection{Overall Analysis}
\label{effect}
In the previous subsections, we thoroughly analyze the performance of all erasure methods across various evaluation perspectives. To derive a comprehensive conclusion, we average the results of different versions and tasks for each baseline on the same metric to obtain its final performance. We then categorize the methods into three levels based on their performance: the top three performing baselines are assigned to level 1, the bottom three to level 3, and the remaining methods to level 2. The final results are summarized in Table \ref{tab:comprehensive-analysis}.

Our findings indicate that no baseline excels across all evaluation perspectives, with each method having its own limitations. Overall, SLD-Str and UCE are relatively stable, as they effectively reduce the generation of target concepts while maintaining image quality and semantic alignment. Their performance remains strong even in challenging scenarios, such as robustness datasets and implicit unsafe prompts. While SLD-Max performs well in erasure score, robustness, and excessive erasure, it suffers from poor image quality and semantic alignment. In contrast, methods like ESD-u, ESD-x, FMN, SPM, and AC show weak performance in erasure scores. SD-NP, SLD-Med, and SalUn deliver moderate results across all metrics. AU and MACE excel mainly in robustness and implicit unsafe prompt erasure. Finally, SelfD has the poorest overall performance across all metrics.

\begin{table*}[t!]
\centering
\small
\caption{Comprehensive comparison of different methods across various evaluation metrics. Based on the average results from different versions of each method, the methods are ranked and categorized into three levels:  
$\blackcircle$ represents Level 1 (best performance),  
halfcircle represents Level 2 (moderate performance), and 
whitecircle represents Level 3 (poorest performance).}
\label{tab:comprehensive-analysis}
\scalebox{0.75}{
\setlength{\tabcolsep}{4pt} 
\begin{tabular}{cccccccccccccccc}
\toprule
\textbf{Perspective}                & \textbf{Metric}          & \textbf{SD-NP} & \textbf{SLD-Med} & \textbf{SLD-Str} & \textbf{SLD-Max} & \textbf{ESD-u} & \textbf{ESD-x} & \textbf{SPM} & \textbf{UCE} & \textbf{AU} & \textbf{AC} & \textbf{FMN} & \textbf{SelfD} & \textbf{SalUn} & \textbf{MACE}  \\
\toprule
Erasure Proportion                  & Erasure Score            & $\blackcircle$            & $\halfcircle$                 & $\blackcircle$                 & $\blackcircle$                 & $\whitecircle$               & $\halfcircle$               & $\whitecircle$             & $\halfcircle$             & $\halfcircle$            & $\halfcircle$            & $\whitecircle$             & $\halfcircle$               & $\halfcircle$               & $\halfcircle$               \\
\midrule
Excessive Erasure                   & \makecell{Genital Ratio \\ Difference} & $\halfcircle$            & $\halfcircle$                 & $\blackcircle$                 & $\blackcircle$                 & $\whitecircle$               & $\halfcircle$               & $\halfcircle$             & $\halfcircle$             & $\blackcircle$            & $\halfcircle$            & $\whitecircle$             & $\whitecircle$               & $\halfcircle$               & $\halfcircle$               \\
\midrule
\makecell{Impact of Explicit and \\ Implicit Unsafe Prompts}                    & Erasure Score            & $\halfcircle$            & $\halfcircle$                 & $\blackcircle$                 & $\blackcircle$                 & $\halfcircle$               & $\whitecircle$               & $\whitecircle$             & $\halfcircle$             & $\blackcircle$            & $\halfcircle$            & $\whitecircle$             & $\halfcircle$               & $\halfcircle$               & $\halfcircle$               \\
\midrule
\multirow{2}{*}{Image Quality}      & FID                      & $\halfcircle$            & $\halfcircle$                 & $\whitecircle$                 & $\whitecircle$                 & $\blackcircle$               & $\halfcircle$               & $\blackcircle$             & $\halfcircle$             & $\halfcircle$            & $\halfcircle$            & $\blackcircle$             & $\whitecircle$               & $\halfcircle$               & $\halfcircle$               \\
                                    & LPIPS                    & $\whitecircle$            & $\halfcircle$                 & $\halfcircle$                 & $\whitecircle$                 & $\blackcircle$               & $\halfcircle$               & $\blackcircle$             & $\halfcircle$             & $\halfcircle$            & $\blackcircle$            & $\halfcircle$             & $\whitecircle$               & $\halfcircle$               & $\halfcircle$               \\
\midrule
\multirow{2}{*}{Semantic Alignment} & CLIPScore                & $\halfcircle$            & $\halfcircle$                 & $\halfcircle$                 & $\whitecircle$                 & $\halfcircle$               & $\halfcircle$               & $\halfcircle$             & $\blackcircle$             & $\whitecircle$            & $\blackcircle$            & $\blackcircle$             & $\halfcircle$               & $\halfcircle$               & $\whitecircle$               \\
                                    & ImageReward              & $\halfcircle$            & $\halfcircle$                 & $\halfcircle$                 & $\halfcircle$                 & $\halfcircle$               & $\halfcircle$               & $\blackcircle$             & $\blackcircle$             & $\whitecircle$            & $\halfcircle$            & $\blackcircle$             & $\whitecircle$               & $\halfcircle$               & $\whitecircle$               \\
\midrule
Robustness                          & Erasure Score            & $\halfcircle$            & $\halfcircle$                 & $\halfcircle$                 & $\blackcircle$                 & $\halfcircle$               & $\halfcircle$               & $\whitecircle$             & $\halfcircle$             & $\blackcircle$            & $\halfcircle$            & $\whitecircle$             & $\whitecircle$               & $\halfcircle$               & $\blackcircle$      \\
\bottomrule
\end{tabular}
}
\end{table*}

\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.9\textwidth]{Images/quanlityandalignment.pdf}
    \vspace{-1em}
    \caption{Different versions of different methods generate images using the COCO-10k dataset. We use FID and LPIPS to calculate image quality, and CLIP score and Image Reward to calculate semantic alignment. For image quality, smaller values of the metrics are better, while for semantic alignment, larger values are better.}
    \label{fig:quanlityandalignment}
\end{figure*}

\begin{table*}[t!]
\small
\centering
\caption{The erasure scores ($\uparrow$) of different methods for Sexually Explicit and Violent themes on the RAB dataset and four NSFW datasets. Methods related to Mode 1 use the more keywords version, while methods related to Mode 2 use the 200 images version}
\label{tab:robustness}
\scalebox{0.78}{
\setlength{\tabcolsep}{3pt} 
\begin{tabular}{c|c|ccccccccc|ccccc} 
\toprule
\multirow{2}{*}{\textbf{\makecell{\\Theme}}}                            & \multirow{2}{*}{\textbf{\makecell{\\Dataset}}}    & \textbf{SD-NP}      & \textbf{SLD-Med} & \textbf{SLD-Str} & \textbf{SLD-Max} & \textbf{ESD-u}   & \textbf{ESD-x}   & \textbf{SPM}     & \textbf{UCE}     & \textbf{AU}      & \textbf{AC}      & \textbf{FMN}      & \textbf{SelfD}   & \textbf{SalUn}   & \textbf{MACE}     \\ 
&                & \makecell{more \\ keywords}             & \makecell{more \\ keywords}                        & \makecell{more \\ keywords}                        & \makecell{more \\ keywords}                        & \makecell{more \\ keywords}                      & \makecell{more \\ keywords}                      & \makecell{more \\ keywords}                    & \makecell{more \\ keywords}                    & \makecell{more \\ keywords}                   & \makecell{200 \\ images} & \makecell{200 \\ images} & \makecell{200 \\ images} & \makecell{200 \\ images} & \makecell{200 \\ images} \\
\midrule
\multirow{2}{*}{\makecell{ Sexually \\ Explicit}} & RAB        & 6.02\%  & 2.97\%  & 51.45\% & \textbf{93.85\%} & 44.33\% & 10.86\% & 1.31\%  & 49.45\% & 92.05\% & 4.01\%  & 0.00\%   & 9.61\%  & 73.72\% & 91.91\%  \\ 
\cline{2-16}
                                 & \makecell{4-NSFW} & 83.02\% & 64.95\% & 90.56\% & \textbf{96.76\%} & 68.77\% & 47.86\% & 8.29\%  & 66.34\% & 72.77\% & 52.49\% & -10.89\% & 74.10\% & 82.68\% & 64.02\%  \\ 
\midrule
\multirow{2}{*}{\makecell{\\ Violent}}         & RAB        & 51.00\% & 51.96\% & 89.44\% & \textbf{99.96\%} & 14.92\% & 18.41\% & 7.07\%  & 48.52\% & 99.69\% & 39.01\% & 8.38\%   & 12.43\% & 54.19\% & 91.71\%  \\ 
\cline{2-16}
                                 & \makecell{4-NSFW} & 92.86\% & 87.00\% & 96.57\% & \textbf{99.00\%} & 14.43\% & 41.29\% & 12.29\% & 62.86\% & 94.71\% & 78.57\% & 18.57\%  & 58.29\% & 77.43\% & 66.71\%  \\ 
\bottomrule
\end{tabular}
}
\end{table*}





% We present here a comprehensive analysis of the performance of all erasure methods from various evaluation perspectives.  For each method, we average the results of different versions on the same metric to obtain its final performance on that metric. We roughly categorize the ratings for each metric into three levels: the top three performing methods are assigned to Level 1, the bottom three methods to Level 3, and the remaining methods to Level 2. The final results are shown in Table \ref{tab:comprehensive-analysis}.  We find that none of the methods performs well across all evaluation perspectives, and each has its own limitations.  On the whole, SLD-Str and UCE are relatively stable, as they can reduce the generation of target concepts while maintaining image quality and semantic alignment. Furthermore, their performance does not degrade significantly when faced with challenging scenarios, such as robustness datasets and implicit unsafe prompts.   While SLD-Max performs well in terms of erasure score, robustness, and excessive erasure, it exhibits poor image quality and semantic alignment. In contrast, ESD-u, ESD-x, FMN, SPM, and AC show weaker performance in terms of erasure score. SD-NP, SLD-Med, and SalUn perform at an intermediate level across all metrics, while AU and MACE perform well only in robustness and implicit unsafe prompt erasure. Finally, SelfD has the poorest average performance across all metrics. 




% \begin{table*}[ht]
% \centering
% \small
% \caption{Comprehensive comparison of different methods across various evaluation metrics. Based on the average results from different versions of each method, the methods are ranked and categorized into three levels: $\blackcircle$ represents Level 1 (best performance), $\halfcircle$ represents Level 2 (moderate performance), and $\whitecircle$ represents Level 3 (poorest performance).}
% \label{tab:comprehensive-analysis}
% \scalebox{0.9}{\begin{tabular}{ccccccccccccccc} 
% \toprule
% Perspective        & SD-NP & SLD-Med & SLD-Str & SLD-Max & ESD-u & ESD-x & SPM & UCE & AU & AC & FMN & SelfD & SalUn & MACE  \\ 
% \midrule
% Erasure Proportion & $\blackcircle$   & $\halfcircle$       & $\blackcircle$        & $\blackcircle$        & $\whitecircle$     & $\halfcircle$     & $\whitecircle$   & $\halfcircle$   & $\halfcircle$  & $\halfcircle$  & $\whitecircle$   & $\halfcircle$     & $\halfcircle$     & $\halfcircle$     \\ 
% \midrule
% Excessive Erasure  & $\halfcircle$  & $\halfcircle$       & $\blackcircle$        & $\blackcircle$        & $\whitecircle$     & $\halfcircle$     & $\halfcircle$   & $\halfcircle$   & $\blackcircle$   & $\halfcircle$  & $\whitecircle$   & $\whitecircle$     & $\halfcircle$     & $\halfcircle$     \\ 
% \midrule
% FID                & $\halfcircle$  & $\halfcircle$       & $\whitecircle$       & $\whitecircle$       & $\blackcircle$      & $\halfcircle$     & $\blackcircle$    & $\halfcircle$   & $\halfcircle$  & $\halfcircle$  & $\blackcircle$    & $\whitecircle$     & $\halfcircle$     & $\halfcircle$     \\ 

% LPIPS              & $\whitecircle$  & $\halfcircle$       & $\halfcircle$       & $\whitecircle$       & $\blackcircle$      & $\halfcircle$     & $\blackcircle$    & $\halfcircle$   & $\halfcircle$  & $\blackcircle$   & $\halfcircle$   & $\whitecircle$     & $\halfcircle$     & $\halfcircle$     \\ 
% \midrule
% CLIPScore          & $\halfcircle$  & $\halfcircle$       & $\halfcircle$       & $\whitecircle$       & $\halfcircle$     & $\halfcircle$     & $\halfcircle$   & $\blackcircle$    & $\whitecircle$  & $\blackcircle$   & $\blackcircle$    & $\halfcircle$     & $\halfcircle$     & $\whitecircle$     \\ 

% ImageReward        & $\halfcircle$  & $\halfcircle$       & $\halfcircle$       & $\halfcircle$       & $\halfcircle$     & $\halfcircle$     & $\blackcircle$    & $\blackcircle$    & $\whitecircle$  & $\halfcircle$  & $\blackcircle$    & $\whitecircle$     & $\halfcircle$     & $\whitecircle$     \\ 
% \midrule
% Robustness         & $\halfcircle$  & $\halfcircle$       & $\halfcircle$       & $\blackcircle$        & $\halfcircle$     & $\halfcircle$     & $\whitecircle$   & $\halfcircle$   & $\blackcircle$   & $\halfcircle$  & $\whitecircle$   & $\whitecircle$     & $\halfcircle$     & $\blackcircle$      \\ 
% \midrule
% \makecell{Implicit Unsafe \\ Prompt Erasure}   & $\halfcircle$  & $\halfcircle$       & $\blackcircle$        & $\blackcircle$        & $\halfcircle$     & $\whitecircle$     & $\whitecircle$   & $\halfcircle$   & $\blackcircle$   & $\halfcircle$  & $\whitecircle$   & $\halfcircle$     & $\halfcircle$     & $\halfcircle$     \\
% \midrule
% \end{tabular}
% }
% \end{table*}



% \usepackage{multirow}

