@inproceedings{samuelsson2023towards,
  title={Towards a Visual Language for Sketched Expression of Software IDE Commands},
  author={Samuelsson, Sigurdur Gauti and Book, Matthias},
  booktitle={2023 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
  pages={115--123},
  year={2023},
  organization={IEEE}
}

@inproceedings{sutherland1964sketch,
  title={Sketch pad a man-machine graphical communication system},
  author={Sutherland, Ivan E},
  booktitle={Proceedings of the SHARE design automation workshop},
  pages={6--329},
  year={1964}
}

@inproceedings{landay1995interactive,
  title={Interactive sketching for the early stages of user interface design},
  author={Landay, James A and Myers, Brad A},
  booktitle={Proceedings of the SIGCHI conference on Human factors in computing systems},
  pages={43--50},
  year={1995}
}

@inproceedings{renom2022exploring,
  title={Exploring technical reasoning in digital tool use},
  author={Renom, Miguel A and Caramiaux, Baptiste and Beaudouin-Lafon, Michel},
  booktitle={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  pages={1--17},
  year={2022}
}

@inproceedings{10.1145/1324892.1324935,
author = {Chen, Xiaofan and Plimmer, Beryl},
title = {CodeAnnotator: digital ink annotation within Eclipse},
year = {2007},
isbn = {9781595938725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1324892.1324935},
doi = {10.1145/1324892.1324935},
abstract = {Programming environments do not support ink annotation. Yet, annotation is the most effective way to actively read and review a document. This paper describes a tool, CodeAnnotator, which integrates annotation support inside an Integrated Development Environment (IDE). This tool is designed and developed to support direct annotation of program code with digital ink in the IDE. Programmers will benefit from a more intuitive interaction space to record notes and comments just as they would on paper documents.},
booktitle = {Proceedings of the 19th Australasian Conference on Computer-Human Interaction: Entertaining User Interfaces},
pages = {211–214},
numpages = {4},
keywords = {sketch, digital ink annotation, annotation, Eclipse},
location = {Adelaide, Australia},
series = {OZCHI '07}
}

@INPROCEEDINGS{1698771,
  author={Plimmer, B. and Grundy, J. and Hosking, J. and Priest, R.},
  booktitle={Visual Languages and Human-Centric Computing (VL/HCC'06)}, 
  title={Inking in the IDE: Experiences with Pen-based Design and Annotatio}, 
  year={2006},
  volume={},
  number={},
  pages={111-115},
  keywords={Software design;Unified modeling language;Collaborative work;Ink;Collaborative software;User interfaces;Computer science;Inspection;Keyboards;Web pages},
  doi={10.1109/VLHCC.2006.28}}


@article{sutherland2016freeform,
  title={Freeform digital ink annotations in electronic documents: A systematic mapping study},
  author={Sutherland, Craig J and Luxton-Reilly, Andrew and Plimmer, Beryl},
  journal={Computers \& Graphics},
  volume={55},
  pages={1--20},
  year={2016},
  publisher={Elsevier}
}

@inproceedings{lichtschlag2014codegraffiti,
  title={CodeGraffiti: Using hand-drawn sketches connected to code bases in navigation tasks},
  author={Lichtschlag, Leonhard and Spychalski, Lukas and Bochers, Jan},
  booktitle={2014 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
  pages={65--68},
  year={2014},
  organization={IEEE}
}


@inproceedings{sutherland2015observational,
  title={An observational study of how experienced programmers annotate program code},
  author={Sutherland, Craig J and Luxton-Reilly, Andrew and Plimmer, Beryl},
  booktitle={Human-Computer Interaction--INTERACT 2015: 15th IFIP TC 13 International Conference, Bamberg, Germany, September 14-18, 2015, Proceedings, Part II 15},
  pages={177--194},
  year={2015},
  organization={Springer}
}

@article{samuelsson2020eliciting,
  title={Eliciting Sketched Expressions of Command Intentions in an IDE},
  author={Samuelsson, Sigurdur Gauti and Book, Matthias},
  journal={Proceedings of the ACM on Human-Computer Interaction},
  volume={4},
  number={ISS},
  pages={1--25},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@INPROCEEDINGS{9680034,
  author={Teng, Zhongwei and Fu, Quchen and White, Jules and Schmidt, Douglas C.},
  booktitle={2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Sketch2Vis: Generating Data Visualizations from Hand-drawn Sketches with Deep Learning}, 
  year={2021},
  volume={},
  number={},
  pages={853-858},
  keywords={Training;Deep learning;Codes;Conferences;Data visualization;Transformers;Software;Transformer;Visualization;Automation},
  doi={10.1109/ICMLA52953.2021.00141}}


@inproceedings{10.1145/3526113.3545619,
author = {Arawjo, Ian and DeArmas, Anthony and Roberts, Michael and Basu, Shrutarshi and Parikh, Tapan},
title = {Notational Programming for Notebook Environments: A Case Study with Quantum Circuits},
year = {2022},
isbn = {9781450393201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526113.3545619},
doi = {10.1145/3526113.3545619},
booktitle = {Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
articleno = {62},
numpages = {20},
keywords = {computational notebooks, pen-based interfaces, programming paradigms, quantum computing},
location = {Bend, OR, USA},
series = {UIST '22}
}


@ARTICLE{4302611,
  author={Davis, Randall},
  journal={Computer}, 
  title={Magic Paper: Sketch-Understanding Research}, 
  year={2007},
  volume={40},
  number={9},
  pages={34-41},
  keywords={Keyboards;Mice;Shape;Unified modeling language;magic paper;sketch-understanding systems;Tablet PCs;computers in education},
  doi={10.1109/MC.2007.324}}


@inproceedings{10.1145/1281500.1281527,
author = {Alvarado, Christine and Davis, Randall},
title = {Resolving ambiguities to create a natural computer-based sketching environment},
year = {2007},
isbn = {9781450318235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1281500.1281527},
doi = {10.1145/1281500.1281527},
abstract = {Current computer-based design tools for mechanical engineers are not tailored to the early stages of design. Most designs start as pencil and paper sketches, and are entered into CAD systems only when nearly complete. Our goal is to create a kind of "magic paper" capable of bridging the gap between these two stages. We want to create a computer-based sketching environment that feels as natural as sketching on paper, but unlike paper, understands a mechanical engineer's sketch as it is drawn. One important step toward realizing this goal is resolving ambiguities in the sketch--- determining, for example, whether a circle is intended to indicate a wheel or a pin joint---and doing this as the user draws, so that it doesn't interfere with the design process. We present a method and an implemented program that does this for freehand sketches of simple 2-D mechanical devices.},
booktitle = {ACM SIGGRAPH 2007 Courses},
pages = {16–es},
location = {San Diego, California},
series = {SIGGRAPH '07}
}

@article{myers1986nd,
  title={An O (ND) difference algorithm and its variations},
  author={Myers, Eugene W},
  journal={Algorithmica},
  volume={1},
  number={1},
  pages={251--266},
  year={1986},
  publisher={Springer}
}

@inproceedings{10.1145/1879211.1879217,
author = {Parnin, Chris and G\"{o}rg, Carsten and Rugaber, Spencer},
title = {CodePad: interactive spaces for maintaining concentration in programming environments},
year = {2010},
isbn = {9781450300285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1879211.1879217},
doi = {10.1145/1879211.1879217},
abstract = {When software developers work with a program's source code, the structure of the source code often requires that they split their attention simultaneously across several documents and artifacts. Disruptions to programmers' concentration caused by overwhelmed capacity can then lead to programming errors and increases in the time to perform a task. We suggest the addition of peripheral interactive spaces to programming environments for supporting developers in maintaining their concentration. We introduce the novel concept of a CodePad, a peripheral, multi-touch enabled display that allows developers to engage with and manipulate multiple programming artifacts. We illustrate visualizations built for a CodePad that support multiple development scenarios and we describe how developers can coordinate the interaction and communication between a CodePad and a programming environment in personal and collaborative tasks. Additionally, we propose a design space for other visualization tools and detail our initial prototype},
booktitle = {Proceedings of the 5th International Symposium on Software Visualization},
pages = {15–24},
numpages = {10},
keywords = {CodePad, code cues, multi-device interactions},
location = {Salt Lake City, Utah, USA},
series = {SOFTVIS '10}
}


@misc{tldraw,
  author       = {Steve Ruiz and tldraw contributors},
  title        = {tldraw},
  year         = {2024},
  howpublished = {\url{https://github.com/tldraw/tldraw}},
  note         = {Accessed: 2024-08-26}
}


@inproceedings{parnin2006building,
  title={Building usage contexts during program comprehension},
  author={Parnin, Chris and Gorg, Carsten},
  booktitle={14th IEEE International Conference on Program Comprehension (ICPC'06)},
  pages={13--22},
  year={2006},
  organization={IEEE}
}

@INPROCEEDINGS{5069490,
  author={Maalej, Walid and Happel, Hans-Jorg},
  booktitle={2009 6th IEEE International Working Conference on Mining Software Repositories}, 
  title={From work to word: How do software developers describe their work?}, 
  year={2009},
  volume={},
  number={},
  pages={121-130},
  keywords={Switches;Collaborative work;Project management;Software engineering;Programming;Costs;Computer bugs;Open source software;Instruments},
  doi={10.1109/MSR.2009.5069490}}


@ARTICLE{4782972,
  author={Storey, Margaret-Anne and Ryall, Jody and Singer, Janice and Myers, Del and Cheng, Li-Te and Muller, Michael},
  journal={IEEE Transactions on Software Engineering}, 
  title={How Software Developers Use Tagging to Support Reminding and Refinding}, 
  year={2009},
  volume={35},
  number={4},
  pages={470-483},
  keywords={Tagging;Navigation;Programming profession;Software maintenance;Software tools;Software engineering;Filters;Software development management;Maintenance engineering;Computer science;Annotations;software navigation;software tagging;tags;software development tools.},
  doi={10.1109/TSE.2009.15}}



@inproceedings{10.1145/1294211.1294238,
author = {Wobbrock, Jacob O. and Wilson, Andrew D. and Li, Yang},
title = {Gestures without libraries, toolkits or training: a \$1 recognizer for user interface prototypes},
year = {2007},
isbn = {9781595936790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1294211.1294238},
doi = {10.1145/1294211.1294238},
abstract = {Although mobile, tablet, large display, and tabletop computers increasingly present opportunities for using pen, finger, and wand gestures in user interfaces, implementing gesture recognition largely has been the privilege of pattern matching experts, not user interface prototypers. Although some user interface libraries and toolkits offer gesture recognizers, such infrastructure is often unavailable in design-oriented environments like Flash, scripting environments like JavaScript, or brand new off-desktop prototyping environments. To enable novice programmers to incorporate gestures into their UI prototypes, we present a "$1 recognizer" that is easy, cheap, and usable almost anywhere in about 100 lines of code. In a study comparing our $1 recognizer, Dynamic Time Warping, and the Rubine classifier on user-supplied gestures, we found that $1 obtains over 97\% accuracy with only 1 loaded template and 99\% accuracy with 3+ loaded templates. These results were nearly identical to DTW and superior to Rubine. In addition, we found that medium-speed gestures, in which users balanced speed and accuracy, were recognized better than slow or fast gestures for all three recognizers. We also discuss the effect that the number of templates or training examples has on recognition, the score falloff along recognizers' N-best lists, and results for individual gestures. We include detailed pseudocode of the $1 recognizer to aid development, inspection, extension, and testing.},
booktitle = {Proceedings of the 20th Annual ACM Symposium on User Interface Software and Technology},
pages = {159–168},
numpages = {10},
keywords = {user interfaces, unistrokes, symbols, strokes, statistical classifiers, rubine, recognition rates, rapid prototyping, marks, gesture recognition, dynamic time warping},
location = {Newport, Rhode Island, USA},
series = {UIST '07}
}

@article{hartmanis1994turing,
  title={Turing award lecture on computational complexity and the nature of computer science},
  author={Hartmanis, Juris},
  journal={Communications of the ACM},
  volume={37},
  number={10},
  pages={37--43},
  year={1994},
  publisher={ACM New York, NY, USA}
}


@inproceedings{10.1145/3526113.3545617,
author = {Suh, Sangho and Zhao, Jian and Law, Edith},
title = {CodeToon: Story Ideation, Auto Comic Generation, and Structure Mapping for Code-Driven Storytelling},
year = {2022},
isbn = {9781450393201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526113.3545617},
doi = {10.1145/3526113.3545617},
abstract = {Recent work demonstrated how we can design and use coding strips, a form of comic strips with corresponding code, to enhance teaching and learning in programming. However, creating coding strips is a creative, time-consuming process. Creators have to generate stories from code (code↦story) and design comics from stories (story↦comic). We contribute CodeToon, a comic authoring tool that facilitates this code-driven storytelling process with two mechanisms: (1) story ideation from code using metaphor and (2) automatic comic generation from the story. We conducted a two-part user study that evaluates the tool and the comics generated by participants to test whether CodeToon facilitates the authoring process and helps generate quality comics. Our results show that CodeToon helps users create accurate, informative, and useful coding strips in a significantly shorter time. Overall, this work contributes methods and design guidelines for code-driven storytelling and opens up opportunities for using art to support computer science education.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
articleno = {13},
numpages = {16},
keywords = {comics, coding strip, code-driven storytelling, authoring tool},
location = {Bend, OR, USA},
series = {UIST '22}
}


@INPROCEEDINGS{9127262,
  author={Suh, Sangho and Lee, Martinet and Xia, Gracie and law, Edith},
  booktitle={2020 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Coding Strip: A Pedagogical Tool for Teaching and Learning Programming Concepts through Comics}, 
  year={2020},
  volume={},
  number={},
  pages={1-10},
  abstract={The abstract nature of programming makes learning to code a daunting undertaking for many novice learners. In this work, we advocate the use of comics—a medium capable of presenting abstract ideas in a concrete, familiar way—for introducing programming concepts. Particularly, we propose a design process and related tools to help students and teachers create coding strips, a form of comic strips that are associated with a piece of code. We conducted two design workshops with students and high school computer science teachers to evaluate our design process and tools. We find that our design process and tools are effective at supporting the design of coding strips and that both students and teachers are excited about using coding strip as a tool for learning and teaching programming concepts.},
  keywords={Strips;Visualization;Codes;Conferences;Education;Encoding;Programming profession;comics;coding strip;visual language;computing education;concreteness fading;computational thinking},
  doi={10.1109/VL/HCC50065.2020.9127262},
  ISSN={1943-6106},
  month={Aug},}


@article{bff9b250-7640-39e2-8f34-329fd1552822,
 ISSN = {00093920, 14678624},
 URL = {http://www.jstor.org/stable/1130388},
 abstract = {The goal of this research is to clarify the development of metaphor by using structure-mapping theory to make distinctions among kinds of metaphors. In particular, it is proposed that children can understand metaphors based on shared object attributes before those based on shared relational structure. This predicts (1) early ability to interpret metaphors based on shared attributes, (2) a developmental increase in ability to interpret metaphors based on shared relational structure, and (3) a shift from primarily attributional to primarily relational interpretations for metaphors that can be understood in either way. 2 experiments were performed to test these claims. There were 3 kinds of metaphors, varying in whether the shared information forming the basis for the interpretation was attributional, relational, or both. In Experiment 1, children aged 5-6 and 9-10 and adults produced interpretations of the 3 types of metaphors. The attributionality and relationality of their interpretations were scored by independent judges. In Experiment 2, children aged 4-5 and 7-8 and adults chose which of 2 interpretations-relational or attributional-of a metaphor they preferred. In both experiments, relational responding increased significantly with age, but attributional responding did not. These results indicate a developmental shift toward a focus on relational structure in metaphor interpretation.},
 author = {Dedre Gentner},
 journal = {Child Development},
 number = {1},
 pages = {47--59},
 publisher = {[Wiley, Society for Research in Child Development]},
 title = {Metaphor as Structure Mapping: The Relational Shift},
 urldate = {2024-08-31},
 volume = {59},
 year = {1988}
}


@article{10.1145/3468505,
author = {Beaudouin-Lafon, Michel and B\o{}dker, Susanne and Mackay, Wendy E.},
title = {Generative Theories of Interaction},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {6},
issn = {1073-0516},
url = {https://doi.org/10.1145/3468505},
doi = {10.1145/3468505},
abstract = {Although Human–Computer Interaction research has developed various theories and frameworks for analyzing new and existing interactive systems, few address the generation of novel technological solutions, and new technologies often lack theoretical foundations. We introduce Generative Theories of Interaction, which draw insights from empirical theories about human behavior in order to define specific concepts and actionable principles, which, in turn, serve as guidelines for analyzing, critiquing, and constructing new technological artifacts. After introducing and defining Generative Theories of Interaction, we present three detailed examples from our own work: Instrumental Interaction, Human–Computer Partnerships, and Communities \& Common Objects. Each example describes the underlying scientific theory and how we derived and applied HCI-relevant concepts and principles to the design of innovative interactive technologies. Summary tables offer sample questions that help analyze existing technology with respect to a specific theory, critique both positive and negative aspects, and inspire new ideas for constructing novel interactive systems.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = {nov},
articleno = {45},
numpages = {54},
keywords = {generative theory, generative principles, Theory}
}

@inproceedings{10.1145/3025453.3025765,
author = {Hornb\ae{}k, Kasper and Oulasvirta, Antti},
title = {What Is Interaction?},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025765},
doi = {10.1145/3025453.3025765},
abstract = {The term interaction is field-defining, yet surprisingly confused. This essay discusses what interaction is. We first argue that only few attempts to directly define interaction exist. Nevertheless, we extract from the literature distinct and highly developed concepts, for instance viewing interaction as dialogue, transmission, optimal behavior, embodiment, and tool use. Importantly, these concepts are associated with different scopes and ways of construing the causal relationships between the human and the computer. This affects their ability to inform empirical studies and design. Based on this discussion, we list desiderata for future work on interaction, emphasizing the need to improve scope and specificity, to better account for the effects and agency that computers have in interaction, and to generate strong propositions about interaction.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5040–5052},
numpages = {13},
keywords = {theories, scientific progress, models, interaction, human-computer interaction, concepts},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@ARTICLE{910894,
  author={Landay, J.A. and Myers, B.A.},
  journal={Computer}, 
  title={Sketching interfaces: toward more human interface design}, 
  year={2001},
  volume={34},
  number={3},
  pages={56-64},
  abstract={Researchers at University of California, Berkeley and Carnegie Mellon University have designed, implemented, and evaluated SILK (Sketching Interfaces Like Krazy), an informal sketching tool that combines many of the benefits of paper-based sketching with the merits of current electronic tools. With SILK, designers can quickly sketch an interface using an electronic pad and stylus, and SILK recognizes widgets and other interface elements as the designer draws them. Unlike paper-based sketching, however, designers can exercise these elements in their sketchy state. For example, a sketched scroll-bar is likely to contain an elevator or thumbnail, the small rectangle a user drags with a mouse. In a paper sketch, the elevator would just sit there, but in a SILK sketch, designers can drag it up and down, which lets them test component or widget behavior. SILK also supports the creation of storyboards-the arrangement of sketches to show how design elements behave, such as how a dialog box appears when the user activates a button. Storyboards are important because they give designers a way to show colleagues, customers, or end users early on how an interface will behave.},
  keywords={Humans;Testing;Mice;Computer interfaces;Elevators;Prototypes;Text recognition;Writing;Usability;Liquid crystal displays},
  doi={10.1109/2.910894},
  ISSN={1558-0814},
  month={March},}


@inproceedings{10.1145/332040.332486,
author = {Lin, James and Newman, Mark W. and Hong, Jason I. and Landay, James A.},
title = {DENIM: finding a tighter fit between tools and practice for Web site design},
year = {2000},
isbn = {1581132166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332040.332486},
doi = {10.1145/332040.332486},
abstract = {Through a study of web site design practice, we observed that web site designers design sites at different levels of refinement—site map, storyboard, and individual page—and that designers sketch at all levels during the early stages of design. However, existing web design tools do not support these tasks very well. Informed by these observations, we created DENIM, a system that helps web site designers in the early stages of design. DENIM supports sketching input, allows design at different refinement levels, and unifies the levels through zooming. We performed an informal evaluation with seven professional designers and found that they reacted positively to the concept and were interested in using such a system in their work.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {510–517},
numpages = {8},
keywords = {Web design, informal, pen-based computers, rapid prototyping, sketching, zooming user interface (ZUI)},
location = {The Hague, The Netherlands},
series = {CHI '00}
}

@inproceedings{10.1145/3220134.3220135,
author = {Beltramelli, Tony},
title = {pix2code: Generating Code from a Graphical User Interface Screenshot},
year = {2018},
isbn = {9781450358972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220134.3220135},
doi = {10.1145/3220134.3220135},
abstract = {Transforming a graphical user interface screenshot created by a designer into computer code is a typical task conducted by a developer in order to build customized software, websites, and mobile applications. In this paper, we show that deep learning methods can be leveraged to train a model end-to-end to automatically reverse engineer user interfaces and generate code from a single input image with over 77\% of accuracy for three different platforms (i.e. iOS, Android and web-based technologies).},
booktitle = {Proceedings of the ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
articleno = {3},
numpages = {6},
keywords = {User Interface Reverse Engineering, Deep Neural Networks, Automated Software Engineering},
location = {Paris, France},
series = {EICS '18}
}

@misc{microsoft_sketch2code,
  author       = {Microsoft AI Lab},
  title        = {{Sketch2Code}: Transform Hand-drawn Designs into HTML Code using AI},
  howpublished = {\url{https://github.com/microsoft/ailab/tree/master/Sketch2Code}},
  year         = {2018},
  note         = {Accessed: 2024-09-02}
}


@inproceedings{10.1145/3290607.3312994,
author = {Suleri, Sarah and Sermuga Pandian, Vinoth Pandian and Shishkovets, Svetlana and Jarke, Matthias},
title = {Eve: A Sketch-based Software Prototyping Workbench},
year = {2019},
isbn = {9781450359719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290607.3312994},
doi = {10.1145/3290607.3312994},
abstract = {Prototyping involves the evolution of an idea into various stages of design until it reaches a certain level of maturity. These design stages include low, medium and high fidelity prototypes. Workload analysis of prototyping using NASA-TLX showed an increase in workload specifically in frustration, temporal demand, effort, and decline in performance as the participants progressed from low to high fidelity. Upon reviewing numerous commercial and academic tools that directly or indirectly support software prototyping in one aspect or another, we identified a need for a comprehensive solution to support the entire software prototyping process. In this paper, we introduce Eve, a prototyping workbench that enables the users to sketch their concept as low fidelity prototype. It generates the consequent medium and high fidelity prototypes by means of UI element detection and code generation. We evaluated Eve using SUS with 15 UI/UX designers; the results depict good usability and high learnability (Usability score: 78.5). In future, we aim to study the impact of Eve on subjective workload experienced by users during software prototyping.},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {user interface design, user centered design, software prototyping process, rapid application development, interface design prototyping, graphical user interfaces},
location = {Glasgow, Scotland Uk},
series = {CHI EA '19}
}


@software{synectic,
  title = {Synectic Integrated Development Environment},
  author = {EPICLab},
  year = {2023},
  url = {https://epiclab.github.io/synectic/},
  note = {A novel IDE supporting a human-centered approach to programming by enhancing context-specific functionality and supporting programmers' cognitive processes.}
}


@inproceedings{10.1145/1866218.1866260,
author = {Lichtschlag, Leonhard and Borchers, Jan},
title = {CodeGraffiti: communication by sketching for pair programmers},
year = {2010},
isbn = {9781450304627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866218.1866260},
doi = {10.1145/1866218.1866260},
abstract = {In pair programming, two software developers work on their code together in front of a single workstation, one typing, the other commenting. This frequently involves pointing to code on the screen, annotating it verbally, or sketching on paper or a nearby whiteboard, little of which is captured in the source code for later reference. CodeGraffiti lets pair programmers simultaneously write their code, and annotate it with ephemeral and persistent sketches on screen using touch or pen input. We integrated CodeGraffiti into the Xcode software development environment, to study how these techniques may improve the pair programming workflow.},
booktitle = {Adjunct Proceedings of the 23nd Annual ACM Symposium on User Interface Software and Technology},
pages = {439–440},
numpages = {2},
keywords = {code annotation, pair programming, pen input},
location = {New York, New York, USA},
series = {UIST '10}
}

@inproceedings{murphy2011restructuring,
  title={Restructuring software with gestures},
  author={Murphy-Hill, Emerson and Ayazifar, Moin and Black, Andrew P},
  booktitle={2011 ieee symposium on visual languages and human-centric computing (vl/hcc)},
  pages={165--172},
  year={2011},
  organization={IEEE}
}

@inproceedings{tillmann2012touchdevelop,
  title={TouchDevelop: app development on mobile devices},
  author={Tillmann, Nikolai and Moskal, Michal and De Halleux, Jonathan and Fahndrich, Manuel and Burckhardt, Sebastian},
  booktitle={Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
  pages={1--2},
  year={2012}
}

@article{li2008algosketch,
  title={AlgoSketch: Algorithm Sketching and Interactive Computation.},
  author={Li, Chuanjun and Miller, Timothy S and Zeleznik, Robert C and LaViola Jr, Joseph J},
  journal={SBIM},
  volume={8},
  pages={175--182},
  year={2008}
}

@inproceedings{10.1145/1281500.1281546,
author = {Hammond, Tracy and Davis, Randall},
title = {LADDER, a sketching language for user interface developers},
year = {2007},
isbn = {9781450318235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1281500.1281546},
doi = {10.1145/1281500.1281546},
abstract = {Sketch recognition systems are currently being developed for many domains, but can be time consuming to build if they are to handle the intricacies of each domain. In order to aid sketch-based user interface developers, we have developed tools to simplify the development of a new sketch recognition interface. We created LADDER, a language to describe how sketched diagrams in a domain are drawn, displayed, and edited. We then automatically transform LADDER structural descriptions into domain specific shape recognizers, editing recognizers, and shape exhibitors for use in conjunction with a domain independent sketch recognition system, creating a sketch recognition system for that domain. We have tested our framework by writing several domain descriptions and automatically generating a domain specific sketch recognition system from each description.},
booktitle = {ACM SIGGRAPH 2007 Courses},
pages = {35–es},
keywords = {vision and scene understanding, user-centered design, shape, representations, representation languages, object recognition, object modeling, knowledge representation, hierarchical scene analysis},
location = {San Diego, California},
series = {SIGGRAPH '07}
}

@inproceedings{10.1145/237091.237119,
author = {Gross, Mark D. and Do, Ellen Yi-Luen},
title = {Ambiguous intentions: a paper-like interface for creative design},
year = {1996},
isbn = {0897917987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/237091.237119},
doi = {10.1145/237091.237119},
booktitle = {Proceedings of the 9th Annual ACM Symposium on User Interface Software and Technology},
pages = {183–192},
numpages = {10},
keywords = {ambiguity and imprecision, design environments, drawing, graphical techniques, pen based systems},
location = {Seattle, Washington, USA},
series = {UIST '96}
}

@inproceedings{haught2003creativity,
  title={Creativity and constraints: The production of novel sentences},
  author={Haught, Catrinel and Johnson-Laird, Philip N},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={25},
  number={25},
  year={2003}
}


@ARTICLE{6922572,
  author={Mangano, Nicolas and LaToza, Thomas D. and Petre, Marian and van der Hoek, André},
  journal={IEEE Transactions on Software Engineering}, 
  title={How Software Designers Interact with Sketches at the Whiteboard}, 
  year={2015},
  volume={41},
  number={2},
  pages={135-156},
  keywords={Encoding;Cognition;Software design;Visualization;Syntactics;Videos;Interaction styles;systems analysis and design;user-centered design;Interaction styles;systems analysis and design;user-centered design},
  doi={10.1109/TSE.2014.2362924}}


@inproceedings{tversky2002sketches,
  title={What do sketches say about thinking},
  author={Tversky, Barbara},
  booktitle={2002 AAAI Spring Symposium, Sketch Understanding Workshop, Stanford University, AAAI Technical Report SS-02-08},
  volume={148},
  pages={151},
  year={2002}
}

@misc{goel1995sketches,
  title={Sketches of thought},
  author={Goel, V},
  year={1995},
  publisher={The MIT Press}
}


@article{10.1145/22339.22349,
author = {Myers, B. A.},
title = {Visual programming, programming by example, and program visualization: a taxonomy},
year = {1986},
issue_date = {April 1986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {0736-6906},
url = {https://doi.org/10.1145/22339.22349},
doi = {10.1145/22339.22349},
abstract = {There has been a great interest recently in systems that use graphics to aid in the programming, debugging, and understanding of computer programs. The terms “Visual Programming” and “Program Visualization” have been applied to these systems. Also, there has been a renewed interest in using examples to help alleviate the complexity of programming. This technique is called “Programming by Example.” This paper attempts to provide more meaning to these terms by giving precise definitions, and then uses these definitions to classify existing systems into a taxonomy. A number of common unsolved problems with most of these systems are also listed.},
journal = {SIGCHI Bull.},
month = {apr},
pages = {59–66},
numpages = {8}
}

@inproceedings{10.1145/22627.22349,
author = {Myers, B. A.},
title = {Visual programming, programming by example, and program visualization: a taxonomy},
year = {1986},
isbn = {0897911806},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/22627.22349},
doi = {10.1145/22627.22349},
abstract = {There has been a great interest recently in systems that use graphics to aid in the programming, debugging, and understanding of computer programs. The terms “Visual Programming” and “Program Visualization” have been applied to these systems. Also, there has been a renewed interest in using examples to help alleviate the complexity of programming. This technique is called “Programming by Example.” This paper attempts to provide more meaning to these terms by giving precise definitions, and then uses these definitions to classify existing systems into a taxonomy. A number of common unsolved problems with most of these systems are also listed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {59–66},
numpages = {8},
location = {Boston, Massachusetts, USA},
series = {CHI '86}
}




@ARTICLE{6065018,
  author={Walny, Jagoda and Carpendale, Sheelagh and Henry Riche, Nathalie and Venolia, Gina and Fawcett, Philip},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Visual Thinking In Action: Visualizations As Used On Whiteboards}, 
  year={2011},
  volume={17},
  number={12},
  pages={2508-2517},
  abstract={While it is still most common for information visualization researchers to develop new visualizations from a data- or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design.},
  keywords={Data visualization;Encoding;Image color analysis;Visualization;diagrams;whiteboards;observational study.},
  doi={10.1109/TVCG.2011.251},
  ISSN={1941-0506},
  month={Dec},}



@inproceedings{10.1145/3399715.3399821,
author = {McGuffin, Michael J. and Fuhrman, Christopher P.},
title = {Categories and Completeness of Visual Programming and Direct Manipulation},
year = {2020},
isbn = {9781450375351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3399715.3399821},
doi = {10.1145/3399715.3399821},
abstract = {Recent innovations in visual programming and the use of direct manipulation for programming have demonstrated promise, but also raise questions about how far these approaches can be generalized. To clarify these issues, we present a categorization of systems for visual programming, programming-by-example, and similar systems. By examining each category, we elucidate the advantages, limitations, and ways to extend systems in each category. Our work makes it easier for researchers and designers to understand how visual programming languages (VPLs) and similar systems relate to each other, and how to extend them. We also indicate directions for future research.},
booktitle = {Proceedings of the 2020 International Conference on Advanced Visual Interfaces},
articleno = {7},
numpages = {8},
keywords = {direct manipulation, output-directed programming, programming by demonstration, programming by example, taxonomy, visual programming languages},
location = {Salerno, Italy},
series = {AVI '20}
}

@article{noone2018visual,
  title={Visual and textual programming languages: a systematic review of the literature},
  author={Noone, Mark and Mooney, Aidan},
  journal={Journal of Computers in Education},
  volume={5},
  pages={149--174},
  year={2018},
  publisher={Springer}
}

@inproceedings{pollock2024designing,
  title={Designing for Semi-Formal Programming with Foundation Models},
  author={Pollock, Josh and Arawjo, Ian and Berger, Caroline and Satyanarayan, Arvind},
  booktitle={PLATEAU: 14th Annual Workshop at the Intersection of PL and HCI},
  year={2024}
}

@article{tovey2003sketching,
  title={Sketching, concept development and automotive design},
  author={Tovey, Michael and Porter, S and Newman, Robert},
  journal={Design studies},
  volume={24},
  number={2},
  pages={135--153},
  year={2003},
  publisher={Elsevier}
}

@misc{victor2013media,
  author       = {Victor, Bret},
  title        = {Media for Thinking the Unthinkable},
  year         = {2013},
  howpublished = {\url{https://worrydream.com/MediaForThinkingTheUnthinkable/}},
  note         = {Accessed: 2024-09-10}
}


%% Added literature review
@article{knuth1984literate,
  title={Literate programming},
  author={Knuth, Donald Ervin},
  journal={The computer journal},
  volume={27},
  number={2},
  pages={97--111},
  year={1984},
  publisher={Oxford University Press}
}

@article{bobrow1964natural,
  title={Natural language input for a computer problem solving system},
  author={Bobrow, Daniel and others},
  year={1964}
}

@article{weizenbaum1966eliza,
  title={ELIZA—a computer program for the study of natural language communication between man and machine},
  author={Weizenbaum, Joseph},
  journal={Communications of the ACM},
  volume={9},
  number={1},
  pages={36--45},
  year={1966},
  publisher={ACM New York, NY, USA}
}


@article{desilets2001voicegrip,
  title={VoiceGrip: a tool for programming-by-voice},
  author={Desilets, Alain},
  journal={International Journal of Speech Technology},
  volume={4},
  pages={103--116},
  year={2001},
  publisher={Springer}
}
@inproceedings{arnold2000programming,
  title={Programming by voice, VocalProgramming},
  author={Arnold, Stephen C and Mark, Leo and Goldthwaite, John},
  booktitle={Proceedings of the fourth international ACM conference on Assistive technologies},
  pages={149--155},
  year={2000}
}

@article{offenwanger2024datagarden,
  title={DataGarden: Formalizing Personal Sketches into Structured Visualization Templates},
  author={Offenwanger, Anna and Tsandilas, Theophanis and Chevalier, Fanny},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2024},
  publisher={IEEE}
}

@inproceedings{xia2018dataink,
  title={DataInk: Direct and creative data-oriented drawing},
  author={Xia, Haijun and Henry Riche, Nathalie and Chevalier, Fanny and De Araujo, Bruno and Wigdor, Daniel},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2018}
}

@inproceedings{xia2017writlarge,
  title={WritLarge: Ink Unleashed by Unified Scope, Action, \& Zoom.},
  author={Xia, Haijun and Hinckley, Ken and Pahud, Michel and Tu, Xiao and Buxton, Bill},
  booktitle={CHI},
  volume={17},
  pages={3227--3240},
  year={2017}
}

@misc{inkbase,
  author       = {James Lindenbaum and Szymon Kaliski and Joshua Horowitz},
  title        = {Inkbase: Programmable Ink},
  year         = 2022,
  month        = nov,
  url          = {https://www.inkandswitch.com/inkbase/},
  note         = {Accessed: 2024-12-07},
  institution  = {Ink \& Switch},
}


@inproceedings{10.1145/1294211.1294256,
author = {Olsen, Dan R.},
title = {Evaluating user interface systems research},
year = {2007},
isbn = {9781595936790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1294211.1294256},
doi = {10.1145/1294211.1294256},
abstract = {The development of user interface systems has languished with the stability of desktop computing. Future systems, however, that are off-the-desktop, nomadic or physical in nature will involve new devices and new software systems for creating interactive applications. Simple usability testing is not adequate for evaluating complex systems. The problems with evaluating systems work are explored and a set of criteria for evaluating new UI systems work is presented.},
booktitle = {Proceedings of the 20th Annual ACM Symposium on User Interface Software and Technology},
pages = {251–258},
numpages = {8},
keywords = {user interface systems evaluation},
location = {Newport, Rhode Island, USA},
series = {UIST '07}
}
@inproceedings{russell_cost_1993,
    address = {New York, NY, USA},
    series = {{CHI} '93},
    title = {The cost structure of sensemaking},
    isbn = {978-0-89791-575-5},
    url = {https://dl.acm.org/doi/10.1145/169059.169209},
    doi = {10.1145/169059.169209},
    abstract = {Making sense of a body of data is a common activity in any kind of analysis. Sensemaking is the process of searching for a representation and encoding data in that representation to answer task-specific questions. Different operations during sensemaking require different cognitive and external resources. Representations are chosen and changed to reduce the cost of operations in an information processing task. The power of these representational shifts is generally under-appreciated as is the relation between sensemaking and information retrieval. We analyze sensemaking tasks and develop a model of the cost structure of sensemaking. We discuss implications for the integrated design of user interfaces, representational tools, and information retrieval systems.},
    urldate = {2023-12-24},
    booktitle = {Proceedings of the {INTERACT} '93 and {CHI} '93 {Conference} on {Human} {Factors} in {Computing} {Systems}},
    publisher = {Association for Computing Machinery},
    author = {Russell, Daniel M. and Stefik, Mark J. and Pirolli, Peter and Card, Stuart K.},
    month = may,
    year = {1993},
    keywords = {cost structure, information access, learning loop, representation search, representation shift, sensemaking},
    pages = {269--276},
}

@article{zhang2023repocoder,
  title={Repocoder: Repository-level code completion through iterative retrieval and generation},
  author={Zhang, Fengji and Chen, Bei and Zhang, Yue and Keung, Jacky and Liu, Jin and Zan, Daoguang and Mao, Yi and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2303.12570},
  year={2023}
}

@article{horowitz2023live,
  title={Live, Rich, and Composable: Qualities for Programming Beyond Static Text},
  author={Horowitz, Joshua and Heer, Jeffrey},
  journal={arXiv preprint arXiv:2303.06777},
  year={2023}
}

@inproceedings{10.1145/3654777.3676357,
author = {Yen, Ryan and Zhu, Jiawen Stefanie and Suh, Sangho and Xia, Haijun and Zhao, Jian},
title = {CoLadder: Manipulating Code Generation via Multi-Level Blocks},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676357},
doi = {10.1145/3654777.3676357},
abstract = {This paper adopted an iterative design process to gain insights into programmers’ strategies when using LLMs for programming. We proposed CoLadder, a novel system that supports programmers by facilitating hierarchical task decomposition, direct code segment manipulation, and result evaluation during prompt authoring. A user study with 12 experienced programmers showed that CoLadder is effective in helping programmers externalize their problem-solving intentions flexibly, improving their ability to evaluate and modify code across various abstraction levels, from their task’s goal to final code implementation.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {11},
numpages = {20},
keywords = {Code Generation, Dynamic Abstraction, Programming Interface},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3672539.3686324,
author = {Yen, Ryan and Zhao, Jian and Vogel, Daniel},
title = {Code Shaping: Iterative Code Editing with Free-form Sketching},
year = {2024},
isbn = {9798400707186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672539.3686324},
doi = {10.1145/3672539.3686324},
abstract = {We present an initial step towards building a system for programmers to edit code using free-form sketch annotations drawn directly onto editor and output windows. Using a working prototype system as a technical probe, an exploratory study (N = 6) examines how programmers sketch to annotate Python code to communicate edits for an AI model to perform. The results reveal personalized workflow strategies and how similar annotations vary in abstractness and intention across different scenarios and users.},
booktitle = {Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {101},
numpages = {3},
keywords = {ink-based sketching, programming interface},
location = {Pittsburgh, PA, USA},
series = {UIST Adjunct '24}
}

@inproceedings{10.1145/3411764.3445460,
author = {Saquib, Nazmus and Kazi, Rubaiat Habib and Wei, Li-yi and Mark, Gloria and Roy, Deb},
title = {Constructing Embodied Algebra by Sketching},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445460},
doi = {10.1145/3411764.3445460},
abstract = {Mathematical models and expressions traditionally evolved as symbolic representations, with cognitively arbitrary rules of symbol manipulation. The embodied mathematics philosophy posits that abstract math concepts are layers of metaphors grounded in our intuitive arithmetic capabilities, such as categorizing objects and part-whole analysis. We introduce a design framework that facilitates the construction and exploration of embodied representations for algebraic expressions, using interactions inspired by innate arithmetic capabilities. We instantiated our design in a sketch interface that enables construction of visually interpretable compositions that are directly mappable to algebraic expressions and explorable through a ladder of abstraction [47]. The emphasis is on bottom-up construction, with the user sketching pictures while the system generates corresponding algebra. We present diverse examples created by our prototype system. A coverage of the US Common Core curriculum and playtesting studies with children point to the future direction and potential for a sketch-based design paradigm for mathematics.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {428},
numpages = {16},
keywords = {embodied cognition, embodied math, math modeling, sketching},
location = {Yokohama, Japan},
series = {CHI '21}
}



@article{green1996usability,
  title={Usability analysis of visual programming environments: a ‘cognitive dimensions’ framework},
  author={Green, Thomas R. G. and Petre, Marian},
  journal={Journal of Visual Languages \& Computing},
  volume={7},
  number={2},
  pages={131--174},
  year={1996},
  publisher={Elsevier}
}