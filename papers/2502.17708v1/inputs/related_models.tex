\subsection{Related Models}
\label{sec:relatedmodels}

A growing body of scholarship has developed models for joint analysis of texts and citation networks \citep{chang2010hrtm, liu2009topic, bai2018neural, le2014probabilistic, zhang2020topic}. 
Early LDA-based approaches leverage citations to improve topic estimation, with semantically similar documents more likely to be connected through citations \citep{chang2010hrtm, liu2009topic, nallapati2008joint}. 
More recent advances employ deep learning techniques to represent texts and citations in lower-dimensional latent embedding spaces \citep{bai2018neural, zhang2022dynamic}. 
The PCTM extends this growing literature in three substantive ways.

First, the PCTM assigns topics to paragraphs rather than individual tokens. 
This modeling strategy stems partly from the observation that paragraphs written by trained professionals often represent coherent units of idea, but more importantly, it is the modeling choice that allows researchers to identify the semantic context of each citation by finding a topic (i.e., a distribution of words) within which the citation is embedded.
Existing models, by contrast, do not have direct connections between a citation and words around it.
In \citet{chang2010hrtm} and \citet{liu2009topic}, the generative process of citations is based on the mixture of topics in the entire document, rather than assigning topics to individual citations.
The Pairwise Link-LDA model and the Link-PLSA-LDA model developed by \citet{nallapati2008joint} assign topics to individual citations, but these topics are conditionally independent of the topics assigned to words given the document-level parameters.
The PCTM is unique in that it explicitly takes into account the proximity of citations to words in the same paragraph, allowing for a more nuanced understanding of the semantic context of citations.

Second, the PCTM allows a document to send multiple citations---possibly of different topics---to another document. 
Past research has focused on topic estimation in document networks, treating citations primarily as binary linkages between documents. 
Consequently, the semantic context of individual citations has remained largely unaddressed in existing models.
While we build on previous work by utilizing citations to enhance topic estimation, our approach differs by explicitly modeling the semantic context of each citation.
Specifically, the PCTM assigns topics to each paragraph and its embedded citations, allowing citations within the same document to represent distinct topics.

Finally, the PCTM models paragraph-level citation propensities through a regression framework, offering researchers flexibility in modeling strategic citation dynamics. 
This approach aligns with social science studies that emphasize how social and political processes influence citation patterns and frequency \citep{hansford2006politics,lupu2013strategic,pelc2014politics}. 
In its current form, our model's regression layer incorporates both precedential authority and topic similarity between citing paragraphs and cited documents. 
Researchers can include any variables at the paragraph, document, or paragraph-document dyadic level to model strategic citation behavior.\footnote{In this sense, our model is similar to the Structural Topic Model (STM) by \cite{roberts2013structural} where exogenous covariates shape the topic prevalence of documents through a generalized linear model. One can imagine our model as a variation of STM where the regression layer includes endogenous processes of citation formation.}

