\section{Constructing SCOTUS Paragraph-document Citation Network}
\label{sec:data}

We construct a new dataset of the SCOTUS opinions that combines text and citation networks. 
The original data is obtained from the Caselaw Access Project, which allows public access to all official and published opinions at all levels of the US courts \citep{caselaw}.
The data contains the full text of majority and minority opinions in addition to their metadata, such as decision dates, reporter names, volumes in the reporter, and page numbers. 
We decided to focus on the text of majority opinions and discard minority opinions since minority opinions rarely receive recognition as legal precedents.
In total, the population data contains 24,000 cases with 749,888 paragraphs with the year ranging from 1834 to 2013. 

The document networks of the SCOTUS consist of two forms of datasets: text and citation networks. 
With respect to the text, we construct a ``paragraph''-feature matrix based on the population corpus. 
A paragraph feature matrix is similar to a common document-feature matrix, where a $(i,j)$ element of the matrix corresponds to the number of times a unique feature $j$ appears in a document $i$.
The only difference is that a paragraph-feature matrix uses paragraphs instead of documents as a unit. 
This is because our proposed model uses paragraphs as a unit of analysis. 
After tokenizing the corpus, we removed punctuations, symbols, special characters, numbers, and common English stopwords.\footnote{We used the set of English stopwords provided in \texttt{quanteda} package in \textsf{R} \citep{quanteda}.}
In addition to the common list of stopwords, we also removed legal terms that are common across the documents in our data such as ``court", ``state", ``law'' and, ``trial''.
After removing too frequent words and too rare words, the population paragraph-feature matrix contains 32,644 unique features.

The other component is a citation network.
While previous studies have constructed citation networks of the SCOTUS cases \citep{fowler2007network, clark2012genealogy}, their unit of analysis is at the document level while ours is at the paragraph level.
In other words, we want to form an adjacency matrix of $G\times N$ where $G$ is the number of paragraphs and $N$ is the number of documents, and the $(ip, j)$ element of the matrix is 1 if paragraph $p$ of document $i$ cites document $j$, and 0 otherwise. 
Since such data is not readily available, we constructed our own citation network of the SCOTUS cases by extracting citations from the text via regular expression matching. 
One of the challenges of this approach is that a citation is recorded by multiple reporters and appears in the paragraph as many times as the number of reporters.
To avoid complication, we focused on the citations to the official reporter, \textit{the United States Reports}, because this is the recommended and the most dominant citation method.
A citation to a case in the United States Reports typically has a relatively consistent format and thus is easier to be extracted through regular expression matching. 
For instance, a citation to \textit{Roe v. Wade} is typically written as \textit{Row v. Wade, 410 U.S. 113 (1973)}. 
Since we focus on the SCOTUS cases only, citations to and from outside of the corpus (e.g. citations to and from the Courts of Appeals and State courts) were discarded. 
This results in 191,173 citations in total.  

In this paper, we focus on a subset of this dataset for our applications. 
For our application, we decided to focus on cases on the Privacy issue area, which includes decisions about abortion and public disclosure of private information.
We chose this as our primary application data since existing literature on citation networks of the SCOTUS cases often focuses on this issue \citep{fowler2007network, clark2012genealogy}.
It is also an important application given the recent controversial decision that overruled the landmark case on constitutional rights to abortion. 
After we subset the data, we performed more preprocessing based on the term frequency within the subset.
More details of data pre-processing for each subset are available in the Supplementary Information document, Section A. 
This subset on the Privacy issue area consists of 106 documents with 4,669 paragraphs, 5,838 unique words, and 452 citations.

Results of topic models can be highly sensitive to how data is preprocessed \citep{denny2018text}. In addition to the simple preprocessing steps we introduced in Section 2, we removed words that appear very commonly across documents. The list of these words are ``Statue",``Supp",``Ann",``Rev",``Stat",``Judgment",``Reverse",``Follow",``Certiorari" and ``Opinion". While words such as ``Follow" or ``Reverse" could convey certain contexts, in legal opinions they are typically used to define how the drafted opinion stands in relation to precedents, and we believe they do not contain useful information with respect to topic discovery. In addition, words such as ``Supp" or ``Ann" are short words for Supplementary and Annex, which are specific collection of legal documents and thus removed for a better detection of topics. 

Since common terms can vary by different subsets, we made additional preprocessing for each subset we used for application of our model. For each subset, we removed terms that appear too frequently as well as terms that appear too infrequently. Terms too common across documents for Privacy subset include ``agent", ``month",``level" and ``unfair" and for Voting Rights subset the removed words include``Vote", ``Voter",``Elect" and ``Candid". For both subsets, terms that were too uncommon turned out to be simple typos or names of people or institutions such as ``Rawlinson".  The above process removed about 40\% of the terms. 
