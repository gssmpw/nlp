[
  {
    "index": 0,
    "papers": [
      {
        "key": "hinton2015distillingknowledgeneuralnetwork",
        "author": "Geoffrey Hinton and Oriol Vinyals and Jeff Dean",
        "title": "Distilling the Knowledge in a Neural Network"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "xu2023wizardlm",
        "author": "Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Daxin Jiang",
        "title": "WizardLM: Empowering Large Language Models to Follow Complex Instructions"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhang2024distillation",
        "author": "Zhang, Hanyu and Wang, Xiting and Ao, Xiang and He, Qing",
        "title": "Distillation with Explanations from Large Language Models"
      },
      {
        "key": "kang2023knowledgeaugmented",
        "author": "Minki Kang and Seanie Lee and Jinheon Baek and Kenji Kawaguchi and Sung Ju Hwang",
        "title": "Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks"
      },
      {
        "key": "li2022explanations",
        "author": "Shiyang Li and Jianshu Chen and Yelong Shen and Zhiyu Chen and Xinlu Zhang and Zekun Li and Hong Wang and Jing Qian and Baolin Peng and Yi Mao and Wenhu Chen and Xifeng Yan",
        "title": "Explanations from Large Language Models Make Small Reasoners Better"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "luo2023wizardcoderempoweringcodelarge",
        "author": "Ziyang Luo and Can Xu and Pu Zhao and Qingfeng Sun and Xiubo Geng and Wenxiang Hu and Chongyang Tao and Jing Ma and Qingwei Lin and Daxin Jiang",
        "title": "WizardCoder: Empowering Code Large Language Models with Evol-Instruct"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "hsieh2023distilling",
        "author": "Cheng-Yu Hsieh and Chun-Liang Li and Chih-Kuan Yeh and Hootan Nakhost and Yasuhisa Fujii and Alexander Ratner and Ranjay Krishna and Chen-Yu Lee and Tomas Pfister",
        "title": "Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes"
      },
      {
        "key": "ho2022large",
        "author": "Ho, Namgyu and Schmid, Laura and Yun, Se-Young",
        "title": "Large language models are reasoning teachers"
      },
      {
        "key": "magister-etal-2023-teaching",
        "author": "Magister, Lucie Charlotte  and\nMallinson, Jonathan  and\nAdamek, Jakub  and\nMalmi, Eric  and\nSeveryn, Aliaksei",
        "title": "Teaching Small Language Models to Reason"
      },
      {
        "key": "fu2023specializing",
        "author": "Fu, Yao and Peng, Hao and Ou, Litu and Sabharwal, Ashish and Khot, Tushar",
        "title": "Specializing smaller language models towards multi-step reasoning"
      },
      {
        "key": "ranaldi-freitas-2024-aligning",
        "author": "Ranaldi, Leonardo  and\nFreitas, Andre",
        "title": "Aligning Large and Small Language Models via Chain-of-Thought Reasoning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "trinh2024solving",
        "author": "Trinh, Trieu H and Wu, Yuhuai and Le, Quoc V and He, He and Luong, Thang",
        "title": "Solving olympiad geometry without human demonstrations"
      },
      {
        "key": "ranaldi-freitas-2024-aligning",
        "author": "Ranaldi, Leonardo  and\nFreitas, Andre",
        "title": "Aligning Large and Small Language Models via Chain-of-Thought Reasoning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "ren2024learn",
        "author": "Ren, Xuan  and\nWu, Biao  and\nLiu, Lingqiao",
        "title": "{I} Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with {LLM}-Generated Responses"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "gonen2022demystifying",
        "author": "Gonen, Hila and Iyer, Srini and Blevins, Terra and Smith, Noah A and Zettlemoyer, Luke",
        "title": "Demystifying prompts in language models via perplexity estimation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "de2022bertin",
        "author": "De la Rosa, Javier and Ponferrada, Eduardo G and Villegas, Paulo and Salas, Pablo Gonzalez de Prado and Romero, Manu and Grandury, Mar{\\i}a",
        "title": "Bertin: Efficient pre-training of a spanish language model using perplexity sampling"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "xu2024detecting",
        "author": "Xu, Zhenyu and Sheng, Victor S",
        "title": "Detecting AI-Generated Code Assignments Using Perplexity of Large Language Models"
      },
      {
        "key": "hu2020systematic",
        "author": "Hu, Jennifer and Gauthier, Jon and Qian, Peng and Wilcox, Ethan and Levy, Roger P",
        "title": "A systematic assessment of syntactic generalization in neural language models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "mekala2024smaller",
        "author": "Mekala, Dheeraj and Nguyen, Alex and Shang, Jingbo",
        "title": "Smaller language models are capable of selecting instruction-tuning training data for larger language models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "li-etal-2024-quantity",
        "author": "Li, Ming  and\nZhang, Yong  and\nLi, Zhitao  and\nChen, Jiuhai  and\nChen, Lichang  and\nCheng, Ning  and\nWang, Jianzong  and\nZhou, Tianyi  and\nXiao, Jing",
        "title": "From Quantity to Quality: Boosting {LLM} Performance with Self-Guided Data Selection for Instruction Tuning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "xu2024strongermodelsstrongerteachers",
        "author": "Zhangchen Xu and Fengqing Jiang and Luyao Niu and Bill Yuchen Lin and Radha Poovendran",
        "title": "Stronger Models are NOT Stronger Teachers for Instruction Tuning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "kim2024evaluatinglanguagemodelssynthetic",
        "author": "Seungone Kim and Juyoung Suk and Xiang Yue and Vijay Viswanathan and Seongyun Lee and Yizhong Wang and Kiril Gashteovski and Carolin Lawrence and Sean Welleck and Graham Neubig",
        "title": "Evaluating Language Models as Synthetic Data Generators"
      }
    ]
  }
]