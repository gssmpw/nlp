\begin{table*}
    \centering
    \footnotesize
    % \setlength{\tabcolsep}{17pt}
    \renewcommand{\arraystretch}{1.0}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{lccccc}
    \toprule
    \textbf{Model} & \textbf{Model Size} & \textbf{Access} & \textbf{Context Length} & \textbf{Creator} \\ \midrule
    
    \href{https://openai.com/index/hello-gpt-4o/}{\texttt{GPT-4o}} & \multirow{3}{*}{Undisclosed} & \multirow{3}{*}{API} & \multirow{3}{*}{128K}  & \multirow{3}{*}{OpenAI}    \\
    \href{https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/}{\texttt{GPT-4o-mini}} &  &  &  &  \\
    \href{https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo}{\texttt{GPT-4-Turbo-2024-04-09}} & & & &  \\
    \midrule
    
    \href{https://www.anthropic.com/news/claude-3-5-sonnet}{\texttt{Claude-3.5-Sonnet}} & \multirow{2}{*}{Undisclosed}  &  \multirow{2}{*}{API} & \multirow{2}{*}{200K} &  \multirow{2}{*}{Anthropic} \\
    \href{https://www.anthropic.com/claude/haiku}{\texttt{Claude-3.5-Haiku}} & & & & \\ \midrule
    
    \href{https://deepmind.google/technologies/gemini/pro/}{\texttt{Gemini-1.5-Pro}} & \multirow{2}{*}{Undisclosed} & \multirow{2}{*}{API} & 2M  & \multirow{2}{*}{DeepMind} \\
    \href{https://deepmind.google/technologies/gemini/flash/}{\texttt{Gemini-1.5-Flash}} &  &  & 1M &  \\ \midrule

    \href{https://bigmodel.cn/dev/howuse/glm-4}{\texttt{GLM-4-Plus}} & Undisclosed & API & \multirow{2}{*}{128K} & \multirow{2}{*}{Tsinghua \& Zhipu} \\
    \href{https://huggingface.co/THUDM/glm-4-9b-chat-hf}{\texttt{GLM4-9B-Chat}} & 9B & Weights & & \\ \midrule
    
    \href{https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct}{\texttt{Llama3.1-8B-Instruct}} & 8B & \multirow{2}{*}{Weights} & \multirow{2}{*}{128K} & \multirow{2}{*}{Meta} \\
    \href{https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct}{\texttt{Llama3.1-70B-Instruct}} & 70B & & &  \\ \midrule
    
    \href{https://huggingface.co/Qwen/Qwen2.5-7B-Instruct}{\texttt{Qwen2.5-7B-Instruct}} & 7B & \multirow{2}{*}{Weights} & \multirow{2}{*}{128K}  & \multirow{2}{*}{Alibaba} \\
    \href{https://huggingface.co/Qwen/Qwen2.5-72B-Instruct}{\texttt{Qwen2.5-72B-Instruct}} & 72B & & & \\ \midrule

    \href{https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3}{\texttt{Mistral-7B-Instruct-v0.3}} & 7B & \multirow{2}{*}{Weights} & \multirow{2}{*}{32K} & \multirow{2}{*}{Mistral AI} \\
    \href{https://huggingface.co/mistralai/Mixtral-8x7B-v0.1}{\texttt{Mixtral-8x7B-v0.1}} & 46B & & &  \\ \midrule

    \href{https://huggingface.co/internlm/internlm2_5-7b-chat}{\texttt{Internlm2.5-7B-Chat}} & 7B & Weights & 1M & Shanghai AI Laboratory \\
    \bottomrule
    \end{tabular}
    }
    
    \caption{Long-context LLMs evaluated in this paper.}
    \label{tab:app_models}
\end{table*}