\subsection{Long Context Models}



Recent advancements in processing lengthy sequences \cite{sun2023length, su2024roformer, DBLP:conf/iclr/XiaoTCHL24, DBLP:conf/iclr/ChenQTLL0J24} have significantly enhanced the effectiveness of LLMs to understand and generate long contexts \cite{achiam2023gpt, glm2024chatglm}. To comprehensively assess these long-context models, numerous benchmarks have been specifically developed. LongBench \cite{bai2024longbench} evaluates the long context understanding capabilities of LLMs in a bilingual setting. InfiniteBench \cite{zhang2024bench} incorporates data surpassing 100k tokens, enabling assessment on longer contexts. RULER \cite{hsieh2024ruler} introduces novel tasks to measure LLMs' abilities beyond context searching. However, research focusing on long-context safety evaluation remains under-explored, despite safety flaws identified in long-context scenarios \cite{anil2024many, upadhayay2024cognitive}. This highlights an urgent need for safety benchmarks specially designed for long-context tasks.


\subsection{Safety Benchmarks}


Existing safety benchmarks have significantly advanced the safety evaluation of LLMs. For instance, SafetyBench \cite{zhang2023safetybench} evaluates a broad spectrum of safety issues, while benchmarks like Red Team \cite{ganguli2022red} and Advbench \cite{zou2023universal} specifically concentrate on red teaming tasks. Additionally, SALAD-Bench \cite{li-etal-2024-salad} integrates diverse tasks including both LLM attack and defense methods into evaluation. Nevertheless, these benchmarks typically involve short queries without context, limiting their applicability to assess LLMs in long-context tasks. LongSafetyBench \cite{huang2024longsafetybench} extends safety evaluation to long-context LLMs through multiple-choice questions. However, this format fails to assess the generation safety, which is more critical for generative models. To address these limitations, we propose \benchmark, the first safety evaluation benchmark tailored to open-ended long-context tasks with a wide variety of safety issues and task types, enabling a comprehensive assessment on safety capabilities of long-context LLMs.