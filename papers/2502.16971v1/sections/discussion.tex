The results from \benchmark demonstrate that long sequences significantly impair the safety performance of current LLMs. To delve deeper into the underlying factors of safety degradation in long-context tasks, we investigate two key aspects: context content (\S\ref{dis:content}) and input length (\S\ref{dis:length}), providing valuable insights for future research.

\subsection{Influence of Context Content}
\label{dis:content}

We design four distinct settings to evaluate how content of context influences safety performance: (1) the input consists solely of an instruction \textbf{without} context, (2) the context is formed by words \textbf{randomly} sampled from a large vocabulary, (3) the instruction is paired with an \textbf{irrelevant} context drawn from contexts with different safety issues in \benchmark, (4) the instruction is associated with the original \textbf{relevant} context. To construct these settings, we randomly sample 400 instances from our benchmark, ensuring consistent context length for each instruction in the latter three settings to eliminate confounding factors. As presented in Figure \ref{fig:content_ablation}, all four models exhibit the lowest safety rates in relevant setting, while showing comparable performance in random and irrelevant context types. This highlights that instructions associated with relevant contexts are more likely to elicit potential safety risks in LLMs. Notably, compared with GPT-4o series, Llama-3.1 series maintain relatively minor changes in safety rate among the latter three settings, underscoring discrepant effect of context content on different models.
% in terms of long-context safety.



\begin{figure}[!t]
    \centering
    \setlength{\abovecaptionskip}{0mm}
    \includegraphics[width=0.95\linewidth]{figures/content_ablation.pdf}
    \caption{The safety rate in four content settings.}
    \label{fig:content_ablation}
    \vspace{-5mm}
\end{figure}

\subsection{Influence of Context Length}
\label{dis:length}

We investigate the impact of context length through pairing instructions with contexts of varying length. We randomly sample 200 instances with context length surpassing 8k words from \benchmark, segmenting the context into paragraphs of 100 words each. Afterwards, we utilize GPT-4o mini to assign a relevance score to the safety keyword for each paragraph, and concatenate paragraphs with highest scores as contexts with different lengths to minimize information loss caused by shortened context. The results, illustrated in Figure \ref{fig:length_ablation}, reveal a continuous decline in safety rates on Llama3.1 series models as context length increases, indicating that extended context negatively affect their safety capabilities. In contrast, the safety rates of GPT-4o and GPT-4o mini exbihit a sharp drop from 0k to 0.5k, but show minimal variation across longer contexts. Since the contexts in the 0.5k setting comprises the most relevant content to the keyword associated with the instruction, we hypothesize that content relevance exerts a more substantial influence on these model than context length, which aligns with our findings in \S\ref{dis:content}.

In summary, both the content and length of the context tend to elicit safety risks within long-context models, with varied influence on different models. These findings provide valuable insights for enhancing long-context safety, such as filtering contents related to harmful topics and reducing input length through distillation of main points. We conduct a  case study exploring the safety degradation in long-context scenarios in Appendix \ref{app:case_study}, and we advocate further research to advance understanding and improvement of long-context safety.

\begin{figure}[!t]
    \centering
    \setlength{\abovecaptionskip}{0mm}
    \includegraphics[width=0.95\linewidth]{figures/length_ablation.pdf}
    \caption{The safety rate in varied length settings.}
    \label{fig:length_ablation}
    \vspace{-5mm}
\end{figure}