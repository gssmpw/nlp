\section{Related work}
Due to the importance of the digitisation of historical archives and the challenges faced, there has been substantial research in the area of OCR and automated page layout analysis **Manning et al., "Introduction to Information Retrieval"**. However, whilst there are many recent OCR and Layout models **Shotton et al., "Real-Time Tracking and 3D Reconstruction of Human Body"**, most of them are designed for extracting text from benchmarks such as scientific articles **Bouraoui et al., "Deep learning-based approaches for handwritten word recognition"**, receipts **Kumar et al., "Automatic receipt processing using deep learning"**, or forms **Li et al., "An End-to-End Approach for Document Layout Analysis"**, not historical documents. This is an important distinction as historical documents have dense text-heavy layouts **Su et al., "Text Extraction from Historical Documents via Deep Learning"**, resulting in poor layout parsing and text extraction. 

Post-OCR correction using text-to-text autoregressive Language Models has recently gained traction as an approach to dealing with the poor OCR of historical documents **Wang et al., "A Survey on Post-OCR Correction for Historical Documents"**. This approach is based on the ability of the transformer architecture to maintain long-range dependencies across the text **Vaswani et al., "Attention Is All You Need"**, its ability to have a representation of language **Brown et al., "Language Models as Zero-Shot Learners"**, and its skill at infilling **Radford et al., "Improving Language Understanding by Generative Models"** and crucially generative power. Whilst this has had some success, seeing reductions of over 50\% in error rates **Li et al., "A Deep Learning-Based Framework for Post-OCR Correction"**, this approach is inherently limited as it uses the corrupted output of the OCR process as opposed to the original images. 

The increasing prevalence and ability of multi-modal language models **Chen et al., "Multimodal Machine Reading Comprehension"**, allows the input of images and the return of text. Many of these models have shown the ability to detect and read text; however, as yet, their ability to cope with the challenges posed by historical documents is under-explored. The value they provide is the ability to respond to prompts made of interleaved text and images and then draw on both the spatial context within the image and the broader knowledge context embedded in their parameters to provide relevant responses. 

Such an ability means image-to-text models are not restricted to simply extracting text but can also be used to embed the entire image and query the embedding **Dosovitskiy et al., "An Image is Worth 16x16 Words"**; in many ways, this allows issues related to layout and OCR to be entirely circumvented. However, OCR reduces the image to its core information, that is, the words on the page, which are easily verifiable, can be searched and read by a human and require very little storage space. This is not to say that there is no place for image embedding in the digitisation of historical documents, but the vast majority of the value they contain is not related to the image and layout but to the writing itself. As such, this paper focuses on OCR.

Figure \ref{fig:importance_earnest} provides an example of how combining an image with a prompt which requires the knowledge stored in the model's parameters to infer culturally specific meaning. The figure shows an image provided to various language models **Hendricks et al., "Localizing Actions"** models. The image alludes to ``The Importance of Being Earnest" by Oscar Wilde, a culturally significant play in Britain. Given the prompt ``Looking at the attached image to which 19th-century comedy play does it refer? and why?" the models generally returned the correct answer, a typical response and explanation from **Krause et al., "A Survey on Visual Question Answering"** is as follows\newline

\textit{This image appears to reference Oscar Wilde's ``The Importance of Being Earnest" (1895). The emoji equation shows a baby + handbag = shocked face, which refers to the play's plot point about a baby being accidentally left in a handbag at Victoria Station. This is a crucial element of the play's story, where it's revealed that one of the main characters was found as a baby in a handbag at the railway station's cloakroom. This mix-up forms one of the play's most famous and absurd plot points, leading to the memorable line about being found in ``a handbag" delivered with shock and horror by Lady Bracknell.}
\newline

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{importance_earnest.jpg}
    \caption{Multi-modal Language models can interleave text and images, allowing them to infer image based cultural references from textual cues. This is essential for effective OCR. }
    \label{fig:importance_earnest}
\end{figure}


This response demonstrates the importance of inter-leaving text and images. It is this ability to understand context and cultural references that makes multi-modal language models particularly promising for historical document OCR. It is these abilities that this paper attempts to leverage to accurately extract the text from the images stored in the NCSE dataset given the context of the prompt and text itself.