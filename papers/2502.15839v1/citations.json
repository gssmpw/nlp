[
  {
    "index": 0,
    "papers": [
      {
        "key": "zhang2020multi",
        "author": "Zhang, Chuxu and Jiang, Meng and Zhang, Xiangliang and Ye, Yanfang and Chawla, Nitesh V",
        "title": "Multi-modal network representation learning"
      },
      {
        "key": "liu2020recent",
        "author": "Liu, Zitao and Yang, Songfan and Tang, Jiliang and Heffernan, Neil and Luckin, Rose",
        "title": "Recent advances in multimodal educational data mining in k-12 education"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "xia2021multi",
        "author": "Xia, Lianghao and Huang, Chao and Xu, Yong and Dai, Peng and Lu, Mengyin and Bo, Liefeng",
        "title": "Multi-behavior enhanced recommendation with cross-interaction collaborative relation modeling"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "shi2023lhmm",
        "author": "Shi, Weijie and Xu, Jiajie and Fang, Junhua and Chao, Pingfu and Liu, An and Zhou, Xiaofang",
        "title": "LHMM: A Learning Enhanced HMM Model for Cellular Trajectory Map Matching"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ouyang2023harmony",
        "author": "Ouyang, Xiaomin and Xie, Zhiyuan and Fu, Heming and Cheng, Sitong and Pan, Li and Ling, Neiwen and Xing, Guoliang and Zhou, Jiayu and Huang, Jianwei",
        "title": "Harmony: Heterogeneous multi-modal federated learning through disentangled model training"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chen2022mm",
        "author": "Chen, Jiawei and Ho, Chiu Man",
        "title": "MM-ViT: Multi-modal video transformer for compressed video action recognition"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "mroueh2015deep",
        "author": "Mroueh, Youssef and Marcheret, Etienne and Goel, Vaibhava",
        "title": "Deep multimodal learning for audio-visual speech recognition"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "lu2018r",
        "author": "Lu, Pan and Ji, Lei and Zhang, Wei and Duan, Nan and Zhou, Ming and Wang, Jianyong",
        "title": "R-VQA: learning visual relation facts with semantic attention for visual question answering"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zheng2023autofed",
        "author": "Zheng, Tianyue and Li, Ang and Chen, Zhe and Wang, Hongbo and Luo, Jun",
        "title": "Autofed: Heterogeneity-aware federated multimodal learning for robust autonomous driving"
      },
      {
        "key": "mcmahan2017communication",
        "author": "McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera",
        "title": "Communication-efficient learning of deep networks from decentralized data"
      },
      {
        "key": "ouyang2023harmony",
        "author": "Ouyang, Xiaomin and Xie, Zhiyuan and Fu, Heming and Cheng, Sitong and Pan, Li and Ling, Neiwen and Xing, Guoliang and Zhou, Jiayu and Huang, Jianwei",
        "title": "Harmony: Heterogeneous multi-modal federated learning through disentangled model training"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "park2023attfl",
        "author": "Park, JaeYeon and Lee, Kichang and Lee, Sungmin and Zhang, Mi and Ko, JeongGil",
        "title": "Attfl: A personalized federated learning framework for time-series mobile and embedded sensor data processing"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "feng2023fedmultimodal",
        "author": "Feng, Tiantian and Bose, Digbalay and Zhang, Tuo and Hebbar, Rajat and Ramakrishna, Anil and Gupta, Rahul and Zhang, Mi and Avestimehr, Salman and Narayanan, Shrikanth",
        "title": "Fedmultimodal: A benchmark for multimodal federated learning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "zheng2023autofed",
        "author": "Zheng, Tianyue and Li, Ang and Chen, Zhe and Wang, Hongbo and Luo, Jun",
        "title": "Autofed: Heterogeneity-aware federated multimodal learning for robust autonomous driving"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "ouyang2023harmony",
        "author": "Ouyang, Xiaomin and Xie, Zhiyuan and Fu, Heming and Cheng, Sitong and Pan, Li and Ling, Neiwen and Xing, Guoliang and Zhou, Jiayu and Huang, Jianwei",
        "title": "Harmony: Heterogeneous multi-modal federated learning through disentangled model training"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "ouyang2023harmony",
        "author": "Ouyang, Xiaomin and Xie, Zhiyuan and Fu, Heming and Cheng, Sitong and Pan, Li and Ling, Neiwen and Xing, Guoliang and Zhou, Jiayu and Huang, Jianwei",
        "title": "Harmony: Heterogeneous multi-modal federated learning through disentangled model training"
      },
      {
        "key": "le2024cross",
        "author": "Le, Huy Q and Thwal, Chu Myaet and Qiao, Yu and Tun, Ye Lin and Nguyen, Minh NH and Hong, Choong Seon",
        "title": "Cross-Modal Prototype based Multimodal Federated Learning under Severely Missing Modality"
      },
      {
        "key": "yang2024cross",
        "author": "Yang, Xiaoshan and Xiong, Baochen and Huang, Yi and Xu, Changsheng",
        "title": "Cross-Modal Federated Human Activity Recognition"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "xiong2023client",
        "author": "Xiong, Baochen and Yang, Xiaoshan and Song, Yaguang and Wang, Yaowei and Xu, Changsheng",
        "title": "Client-Adaptive Cross-Model Reconstruction Network for Modality-Incomplete Multimodal Federated Learning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "ouyang2023harmony",
        "author": "Ouyang, Xiaomin and Xie, Zhiyuan and Fu, Heming and Cheng, Sitong and Pan, Li and Ling, Neiwen and Xing, Guoliang and Zhou, Jiayu and Huang, Jianwei",
        "title": "Harmony: Heterogeneous multi-modal federated learning through disentangled model training"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "yang2024cross",
        "author": "Yang, Xiaoshan and Xiong, Baochen and Huang, Yi and Xu, Changsheng",
        "title": "Cross-Modal Federated Human Activity Recognition"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "xiong2023client",
        "author": "Xiong, Baochen and Yang, Xiaoshan and Song, Yaguang and Wang, Yaowei and Xu, Changsheng",
        "title": "Client-Adaptive Cross-Model Reconstruction Network for Modality-Incomplete Multimodal Federated Learning"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "ouyang2023harmony",
        "author": "Ouyang, Xiaomin and Xie, Zhiyuan and Fu, Heming and Cheng, Sitong and Pan, Li and Ling, Neiwen and Xing, Guoliang and Zhou, Jiayu and Huang, Jianwei",
        "title": "Harmony: Heterogeneous multi-modal federated learning through disentangled model training"
      }
    ]
  }
]