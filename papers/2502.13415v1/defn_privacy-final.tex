\section{Preliminaries}
\label{sec:prelim}

We first describe the problem setting and the adversary model.

\noindent \textbf{Problem Setup.} The order of each user~$i$ has a type $\tau_i \in {\mathsf{buy}, \mathsf{sell}}$, a price~$p_i \in \mathbb{R}+$, and a \textbf{positive} quantity~$x_i \in \mathbb{Z}_+$. An input configuration $C := {(\tau_i, p_i, x_i): i \in [n]}$ consists of users' orders. One unit of a buy order can be matched to one unit of a sell order if the buying price is at least the selling price. The goal is to design matching protocols that maximize the total number of matched units while preserving the privacy of users' data.




\noindent \textbf{Adversarial Model.}
The server can observe the most amount of information,
which is modeled as an adversary that is semi-honest, i.e.,
it will follow the protocol and try to learn about users' data.
Observe that when one unit of a buy order is matched
to a sell order, the identities of both the buyer and the seller,
as well as their bidding prices, must be revealed.
Here are possible privacy concepts.

\begin{compactitem}

\item Given the bid $(\tau_i, p_i, x_i)$
of a user~$i$, the type~$\tau_i$ and the price~$p_i$ are public information,
but the number~$x_i$ of units is private.
However, the identity of the user~$i$ is known, and because it is placing a bid,
it is also known that $x_i \geq 1$.

We will develop a new privacy notion that only hides the value of~$x_i$
when the bid cannot be fully executed. This theoretical privacy guarantee
will mainly focus on this new notion.

\item In practice, perhaps a user may not even want its presence in the system
to be known if no unit of its bid is executed. We will later describe
how this can be easily achieved by encrypting the user id, but this is
not the main technical focus.

\end{compactitem}

\ignore{
In the differential privacy framework, we specify the neighboring relation that describes what scenarios the adversary cannot tell apart.
}

\begin{definition}[Neighboring Input Configurations] 
Two input configurations $C$ and $\widehat{C}$ are neighboring if except for one user~$i$, all orders of other users are identical, and for user~$i$, only the quantity may differ by at most 1, i.e. $|x_i - \widehat{x}_i| \leq 1$. We denote $C \sim_i \widehat{C}$ in this case. 
\end{definition}





We review some basic probability tools that are commonly used in differential privacy~\cite{DBLP:conf/icalp/Dwork06}. A divergence is used to quantify how close two distributions on the same sample space are to each other.

\begin{definition} [Symmetric Hockey-Stick Divergence] 
Given distributions $P$ and $Q$ on the same sample space $\Omega$ and $\gamma \geq 0$, the symmetric hockey-stick divergence is defined as:

$$ \HS_\gamma(P \| Q) := \sup_{S \subseteq \Omega} \max\{ Q(S) - \gamma \cdot P(S), P(S) - \gamma \cdot Q(S)\}.$$

\end{definition}

\begin{remark} The hockey-stick divergence is related to the well-known $(\epsilon, \delta)$-differential privacy inequality. 

Specifically, $\HS_{e^\epsilon} (P | Q) \leq \delta$ if and only if for all subsets $S \subseteq \Omega$, 

$Q(S) \leq e^\epsilon \cdot P(S) + \delta$ and $P(S) \leq e^\epsilon \cdot Q(S) + \delta$. \end{remark}

\begin{definition}[Differential Privacy] Suppose when a matching protocol is run on a configuration $C$, the adversary can observe some information that is denoted by some random object $\msf{View}(C)$. Then, the protocol is $(\epsilon, \delta)$-differentially private if for all neighboring input configurations $C$ and $\widehat{C}$,

$\HS_{e^\epsilon}(\msf{View}(C) | \msf{View}(\widehat{C})) \leq \delta$. \end{definition}


Note that the maximum number of matched units can differ by 1 for neighboring input configurations. Therefore, to use the conventional notion of differential privacy, the matching protocol cannot guarantee that an optimal number of matched units is returned. In fact, it is not hard to see that to achieve $(\epsilon, \delta)$-DP, the protocol will need to match the number of units that is about $O(\frac{1}{\epsilon} \log \frac{1}{\delta})$ smaller than the maximum possile value.

\ignore{
This is consistent with the fact that the truncated geometric distribution can be used to achieve $(\epsilon, \delta)$-DP for two quantities that differ by at most 1.
}



\noindent \textbf{Truncated geometric distribution.} Let $Z$ 
be an even integer,
and $\alpha > 1$. The truncated geometric distribution $\Geom^Z(\alpha)$ has support with the integers in $[0..Z]$ such that its probability mass function at $x \in [0..Z]$ is proportional to $\alpha^{-| \frac{Z}{2} - x |}$. Specifically, the probability mass function at $x \in [0..Z]$ is 
\[
\frac{\alpha - 1}{\alpha + 1 - 2 \alpha^{-\frac{Z}{2}}} \cdot \alpha^{-\left|\frac{Z}{2} - x \right|}.
\]

\begin{fact}[Geometric Distribution and DP]
\label{fact:geom_dp}
For $\epsilon > 0$ and $0 \leq \delta < 1$, 
suppose $N$ is a random variable with distribution $\Geom^Z(e^\epsilon)$,
where $Z \geq \ceil{\frac{2}{\epsilon} \ln \frac{1}{\delta}}$ is even.
Then, for any integer~$n$,

$\HS_{e^\epsilon}(n+N \| n+1 + N) \leq \delta$.
\end{fact}


\subsection{Indifferential Privacy: A Relaxed Notion}\label{sec:IDP}


\noindent \textbf{High-Level Goal.} We would like to design a protocol that always returns the optimal number of matched units, but we will relax the conventional notion of differential privacy such that the bidding quantity~$x_i$ of a user~$i$ does not need privacy protection if the order is fully executed.

\noindent \textbf{Closest Refinement Pair.} To describe this new privacy notion, we will need some technical notation. The recent work~\cite{DBLP:journals/corr/abs-2406-17964} considers finite sample spaces which are sufficient for our purposes.


\begin{definition}[Refinement]
Suppose $\Omega_0$ and $\Omega_1$ are sample spaces
and $\mcal{F} \subseteq \Omega_0 \times \Omega_1$ is a binary relation,
which can also be interpreted as a bipartite graph $(\Omega_0 \cup \Omega_1, \mcal{F})$.
Given a distribution $\mathsf{P}_0$ on $\Omega_0$,
a refinement $\widehat{\mathsf{P}}_0$ of $\mathsf{P}_0$ (with respect to $\mcal{F}$)
is a distribution on $\mcal{F}$ such that
for every $i \in \Omega_0$, $\mathsf{P}_0(i) = \sum_{j: (i,j) \in \mcal{F}} \widehat{\mathsf{P}}_0(i,j)$.

A refinement for a distribution on $\Omega_1$ is a distribution on $\mcal{F}$ defined analogously.
\end{definition}


\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\columnwidth]{./refinement.pdf}  % Replace with the path to your figure file
    \caption{\textbf{Refinement Pair.} \textnormal{The figure
		shows an example of a bipartite graph $(\Omega_0, \Omega_1; \mcal{F})$, where each node has a probability mass.  Each subfigure shows
		the probability distribution refinement on each side.}}
    \label{fig:refinement}
\end{figure}



\begin{definition}[Closest Refinement Pair]
Given distributions $\mathsf{P}_0$ and $\mathsf{P}_1$
on sample spaces that are equipped with some relation $\mcal{F}$
and a divergence notion $\mathsf{D}$,
the divergence between $\mathsf{P}_0$ and $\mathsf{P}_1$ with respect to $\mcal{F}$
is defined to be:

$$\mathsf{D}^{\mcal{F}}(\mathsf{P}_0 \| \mathsf{P}_1) =
\inf_{(\widehat{\mathsf{P}}_0, \widehat{\mathsf{P}}_1)} \mathsf{D}(\widehat{\mathsf{P}}_0 \| \widehat{\mathsf{P}}_1),$$

where the infimum is taken over all refinements 
$\widehat{\mathsf{P}}_0$ and $\widehat{\mathsf{P}}_1$
of $\mathsf{P}_0$ and $\mathsf{P}_1$, respectively.
\end{definition}

\begin{remark}
As we shall see, in our dark pool application,
the relation $\mcal{F}$ in $\Omega_0 \times \Omega_1$,
is actually much simpler.
In particular, each node from one side
has at most one neighbor on the other side.
Hence, for the distribution on each side, there is only one possible
refinement.
Even though the concept of closest refinement pair is not needed for this application,
we still give a more general Definition~\ref{defn:idp} which may be relevant
in future applications.
\end{remark}


\begin{fact}[Universal Closest Refinement Pair~\cite{DBLP:journals/corr/abs-2406-17964}]
Given the above distributions 
 $\mathsf{P}_0$ and $\mathsf{P}_1$, together with the relation $\mcal{F}$ on
their corresponding sample spaces,
there exists a universal refinement pair
$(\widehat{\mathsf{P}}_0, \widehat{\mathsf{P}}_1)$ that minimizes
$\mathsf{D}(\widehat{\mathsf{P}}_0 \| \widehat{\mathsf{P}}_1)$ for all
divergences $\mathsf{D}$ satisfying the data-processing 
inequality\footnote{
A divergence $\mathsf{D}$ satisfies
the data processing inequality if for 
any pair of joint distributions $(X_0, Y_0)$ and $(X_1, Y_1)$,
the corresponding marginal distributions satisfy
$\mathsf{D}(X_0 \| X_1)
\leq \mathsf{D}((X_0, Y_0) \| (X_1, Y_1))$.
} 
(which includes the hockey-stick divergence $\HS$).
\end{fact}




\noindent \textbf{Intuition.} To fit the above notation to
our problem, let us consider a pair of neighboring input configurations
$C_0$ and $C_1$, in which the quantities of some user~$i$ differ by 1.
For instance, in $C_0$, the user~$i$ has $n_0 > 0$ units, while in $C_1$,
the user has $n_1 = n_0 + 1$ units.

For those two input configurations,
the corresponding sample spaces of the adversary's views
are $\Omega_0$ and $\Omega_1$, which may not be the same,
because the supports of the views for the two configurations may be different.

Next, let us look at each point in the sample space more carefully.
As the protocol is being executed, the adversary gains more information step-by-step.
Hence, each point~$\sigma$ in the sample space is
a time-series sequence $\sigma = (\sigma_1, \sigma_2, \ldots)$.

\begin{definition}[Indifference Relation]
\label{defn:indifference}
Given the sample spaces $\Omega_0$ and $\Omega_1$ of
the adversary's views corresponding
to neighboring input configurations~$C_0$ and $C_1$ as above,
we define an indifference relation $\mcal{F} \subseteq \Omega_0 \times \Omega_1$
as follows, where a pair of time sequences $(\sigma^{(0)}, \sigma^{(1)}) \in \mcal{F}$ is related \emph{iff}

\begin{compactitem}

\item  The two sequences $\sigma^{(0)} = \sigma^{(1)}$ are the same; or

\item The two time sequences $\sigma^{(0)}$ and $\sigma^{(1)}$
have a maximal common prefix $\rho$ such that $\rho$ implies that
$n_0$ units of user~$i$'s order have been matched, i.e.,
in $C_0$, the order of user~$i$ is fully executed.
\end{compactitem}

\end{definition}

With the mathematical concepts formalized,
we are ready to introduce our new notion of privacy.


\begin{definition}[Indifferential Privacy (IDP)]
\label{defn:idp}
Suppose when a matching protocol is run on a configuration $C$,
the adversary can observe some information that is denoted by 
some random object $\msf{View}(C)$.
Then, the protocol is $(\epsilon, \delta)$-indifferentially private (IDP)
if for all neighboring input configurations $C$ and $\widehat{C}$
with the appropriate indifference relation~$\mcal{F}$ defined,

$\HS^{\mcal{F}}_{e^\epsilon}(\msf{View}(C) \| \msf{View}(\widehat{C})) \leq \delta$.
\end{definition}





\noindent \textbf{Intuition.}
In Definition~\ref{defn:indifference},
if we only have the first bullet $\sigma^{(0)} = \sigma^{(1)}$,
then this reduces to the usual differential privacy.
The second bullet says the indifference relation specifies when 
the user~$i$ is indifferent
about whether the adversary can distinguish between the 
two views in a pair $(\sigma^{(0)}, \sigma^{(1)}) \in \mcal{F}$.

In our application scenario, this captures the idea
that when a user's order is fully executed, then the privacy of its bidding quantity
no longer needs protection.



\noindent \textbf{Information Theoretic vs Computational IDP.}
When we describe our protocol,
we will use the ideal functionality of cryptographic
primitives and prove the privacy under
Definition~\ref{defn:idp} that is information theoretic.
If we replace the ideal functionality with
the real-world cryptographic construct,
we can achieve the following notion of
computational IDP that is analogous to SIM-CDP 
introduced in Mironov et al.~\cite{DBLP:conf/crypto/MironovPRV09}.

\begin{definition}[Computational IDP (CIDP)]
\label{defn:cidp}
A protocol $\Pi$ is $(\epsilon, \delta)$-CIDP
if there exists a protocol $\Pi'$ that
is $(\epsilon, \delta)$-IDP such that
$\Pi$ and $\Pi'$ are computationally indistinguishable.
\end{definition}

\noindent \textbf{Technical Focus.}
In this work, we focus on showing
our protocol using ideal functionality of cryptographic primitives satisfies Definition~\ref{defn:idp}.
It is straightforward to apply standard hybrid arguments~\cite{DBLP:conf/crypto/MironovPRV09}
to replace an ideal functionality with the real-world cryptographic
primitive to show that the resulting protocol
satisfies Definition~\ref{defn:cidp}.




\ignore{

\begin{definition}[Multiplicative Neighboring Relation]
For $\rho \geq 0$, two positive numbers $x$ and $x'$ are $\rho$-multiplicative neighboring, if
$| \ln \frac{x}{x'}| \leq \rho$.

\end{definition}


\begin{definition}[Truncated Laplace Distribution]
The truncated Laplace distribution $\mathsf{Lap}(\mu, b, C)$
has a support in $[\mu - C, \mu + C]$
and for $t \in [\mu - C, \mu + C]$,
its probability density function is proportional to: $\exp(- \frac{|t - \mu|}{b})$.
\end{definition}


\begin{fact}
Let $\epsilon \geq 0$ and $0 < \delta < 1$.
Suppose $x$ and $x'$ are $\rho$-multiplicative neighboring,
and $Z$ is a random variable have truncated Laplace distribution
$\mathsf{Lap}(\mu, b, C)$,
where $b = \frac{\rho}{\epsilon}$ and $\mu = C = b \ln \frac{1}{\delta}$.

Then, the two distributions $x \cdot \exp(Z)$ and $x' \cdot \exp(Z)$ are $(\epsilon, \delta)$-close.

$\exp(Z) \in [1, (\frac{1}{\delta})^{ \frac{2 \rho}{\epsilon} }]$


Social welfare suffers by a factor 
of $(\frac{1}{\delta})^{ \frac{4 \rho}{\epsilon}}$
\end{fact}

}





\ignore{

\begin{definition}[Conditional Differential Privacy]
A mechanism $\mathsf{M}$
is $(\epsilon, \delta)$-conditional differentially private if
for all neighboring input configurations $C \sim_i \widehat{C}$ such that
some specified condition $\mathcal{U}_i$ 
(that may depend on~$i$) has non-zero probability in both scenarios,
we have for any subset $S$ of outputs,

$\Pr[\mathsf{M}(C) \in S \, | \mathcal{U}_i]
\leq e^\epsilon \cdot \Pr[\mathsf{M}(\widehat{C}) \in S \, | \mathcal{U}_i] + \delta$.

\end{definition}
}
