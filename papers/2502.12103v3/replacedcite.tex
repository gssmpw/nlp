\section{Related Work}
\label{sec:related_work}

\texttt{CriteoPrivateAds} is versatile enough to be leveraged to assess the offline performance of both non-private and private advertising approaches. 
Regarding the latter, benchmarks of bidding models based on differential privacy (DP), or other obfuscation techniques such as aggregation and signal quantisation (e.g. restricting user signals to a few bits) are of relevant interest, being both studied in the academic and industrial research and engineering communities.
Since DP stands for the workhorse methodology to derive private training frameworks, we will focus primarily on DP and show how this open-source release is necessary to benchmark private advertising systems with respect to current open-source bidding datasets.\\

\begin{table}[ht]
\centering
\renewcommand{\arraystretch}{1.2} % Increases row height for better readability
\footnotesize
\begin{tabular}{|p{2cm}|p{1cm}|p{3.3cm}|}
\hline
\textbf{Data} & \textbf{Rows} & \textbf{Features} \\ \hline 
KDD Cup Track 2 ____ & 5M & Search engine context, with queryn ad features, user id and click information.\\ \hline
Criteo-Kaggle Display Advertising Challenge ____ 
& 100K  &  Over 7 days of live traffic, 39 features hashed and fully undisclosed, click label.  \\ \hline
Avazu dataset ____ & 40M & Over 11 days of live traffic, 9 anonymised features, 6 contextual features, 5 user device features, click label. \\ \hline
Criteo 1TB Click Logs dataset ____
 & 4B  & Over 7 days of live traffic, 39 features hashed and fully undisclosed, click label. Similar to the dataset in Criteo-Kaggle-Display challenge. \\ \hline
 Criteo Attribution Modeling for Bidding Dataset ____
 & 16.5M  & Over 30 days of live traffic, 9 contextual features, attribution data, user and campaigns ids, click and conversion labels. \\ \hline
\end{tabular}
\caption{Public Datasets for Bidding.}
\label{tab:dataset_overview}
\end{table}

\noindent \textbf{Differential Privacy and APIs.} Differential privacy (DP) has gained popularity over the last two decades due to its strong mathematical properties and privacy guarantees ____. 
As DP is envisioned to be implemented at scale in ad measurement systems to replace third-party cookies ____, it may become one of the largest real-world deployment of DP, impacting daily queries and users. 
Local differential privacy (LDP) adds noise to individual data points before they are sent to a statistician or report collector. 
While this avoids dependence on a trusted entity, LDP tends to degrade utility due to the large amount of noise required ____. Within the Privacy Sandbox context, the Attribution Reporting API (ARA) supplies locally DP-ed event-level reports.  
On the other hand, global differential privacy (GDP) operates by aggregating data across multiple users before noise is applied, which minimises the individual contributions and then lowers the noise. Though, it relies on a trusted aggregator who collects and aggregates data from multiple sources and ensures that the privacy guarantees are maintained throughout the process. 
As an illustration, the Privacy Sandbox by Google Chrome introduces the Private Aggregation Service that provides aggregated and globally DP-ed reports ____. 
Recently, Chrome proposed another path, albeit still in research phase, to learn bidding models by using differentially private stochastic gradient descent (DP-SGD), a GDP variant of SGD ____. 
It adds Gaussian noise to the gradients during training, which are clipped to control their range and then the privacy budget. This algorithm demonstrates good empirical performance, while incurring a reasonable privacy cost ____. Though, in the Privacy Sandbox setting, running DP-SGD necessitates access to a trusted server, for instance leveraging an execution environment (TEE), for the computation of gradients, their aggregation, the addition of noise and the management of privacy accounting.\\


\noindent \textbf{Bidding Public Datasets and Competitions.}
Advertising click-through-rate (CTR) prediction models have been assessed using various benchmarks ____. 
The most frequently used public datasets are summarised in \Cref{tab:dataset_overview}.
Unfortunately, none of them can be used to evaluate the impact of private model training on CTR prediction based on browser vendors APIs constraints. 
Indeed, those datasets do not include sufficient information about features types (e.g., contextual, cross-domain, single-domain), availability at inference time and associated sensitivity from browser vendors lens, limiting their use for relevant benchmarking.
In complement to open-source datasets, some public competitions and challenges have been organised in order to assess the utility of private bidding model training methodologies, such as using noisy label proportions ____.