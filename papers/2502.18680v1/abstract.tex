GPGPU-based clusters and supercomputers have become extremely popular in the
last ten years. There is a large number of GPGPU hardware counters exposed to
the users, however, very little analysis has been done regarding insights they
might offer about workloads running on them.  In this work, we address this gap
by analyzing previously unexplored GPU hardware counters collected via
Lightweight Distributed Metric Service on Perlmutter, a leadership-class
supercomputer. We examine several hardware counters related to utilization of
GPU cores and memory and present a detailed spatial and temporal analysis of
GPU workloads.  We investigate spatial imbalance -- uneven GPU usage across
multiple GPUs within a job.  Our temporal study examines how GPU usage
fluctuates during a jobâ€™s lifetime, introducing two new metrics -- burstiness
(the irregularity of large utilization changes) and temporal imbalance
(deviations from mean utilization over time). Additionally, we compare machine
learning and traditional high performance computing jobs.  Our findings uncover
inefficiencies and imbalances that can inform workload optimization and future
HPC system design.
