\section{Motivation and Background}
\label{sec:motive}
    Achieving an immersive mobile augmented reality (MAR) experience presents unique challenges \cite{bib:networkar,bib:locar}. Conventional data caching and prefetching policies, designed for general-purpose applications, might not be optimal for MAR due to its inherent characteristics\cite{bib:archaract}. Compared to other edge-native applications \cite{bib:edgenative}, MAR applications require significant computational resources and sophisticated data management strategies to handle the large volume of spatial data and real-time interactions. 

    \subsection{Motivating AR Scenarios}
    \begin{figure}
        \centering
        \includegraphics[scale=0.13]{images/motive/motiveapp.png}
        \caption{Grocery and tourist scenarios}
        \label{fig:motiveapp}
        \vspace{-6mm}
    \end{figure}
    Figure \ref{fig:motiveapp} shows two example application scenarios for AR. In a grocery store scenario\cite{bib:phara}, users interact with virtual objects of the store items to receive information about their ingredients, manufacturing details, price variations, recipes, and so on. The items are typically placed on racks in aisles based on their categories, and there is a well defined order of placement. The Field of View (FoV) of a user will have multiple items at their location in the store, from which the user might be interested in a few. 
    
    In the case of a tourist scenario, \cite{bib:dublin}, attractions are typically scattered across a region (such as a city block, campus, or neighborhood). The virtual objects may contain historical facts, 3D representations of buildings, informative audio/video, and so on. A tourist would visit the attractions based on multiple factors like user interests, transportation availability, accessibility, guide recommendations, and so on. The FoV of the user in this case would likely consist of only a few items in their vinicity, and the user will have to explore the region more to find the next attraction. 

    %\subsection{MAR challenges}
    %There are multiple MAR specific challenges when 
    %Serving users in 
    Such MAR scenarios face the following challenges:
    
    \noindent$\bullet$ {\em Limited device storage and large object sizes}:  While current virtual objects are typically under 20MB \cite{bib:carsar, bib:objaverse}, increasing interaction complexity and 3D objects will lead to larger object sizes.  Storing all objects locally on the device  becomes impractical as object size and complexity grow.
    
    \noindent$\bullet$ {\em High cloud latency and strict AR latency requirements}: Average cloud latency (around 60ms \cite{bib:clatency, bib:clt1, bib:clt2}) exceeds the sub-20ms threshold required for immersive AR experience \cite{bib:20ms}.  On-demand fetching of objects from the cloud introduces significant latency \cite{bib:delayhits}, negatively impacting user experience.  
    %Anticipating user needs and preemptively caching data at the edge enables rapid availability and efficient sharing among users.
    %Achieving such low latency necessitates the use of 
    %a combined approach utilizing 5G/6G networks and 
    %edge infrastructure.
    
    \if 0
        \noindent$\bullet$ On-demand fetch inefficiency: On-demand fetching of objects from the cloud introduces significant latency \cite{bib:delayhits}, negatively impacting user experience.  Anticipating user needs and preemptively caching data at the edge enables rapid availability and efficient sharing among users.

    
    \noindent 4. Power Consumption and Data Transfer:  On-demand fetching leads to inefficient bandwidth usage, increased data transfer latency, and higher power consumption \cite{bib:energy}.  Intelligent prefetching methods are crucial to proactively store virtual objects, minimize power consumption and improve efficiency.
    \fi

    % The key challenges in mobile AR caching for application scenarios discussed above are:
    
    % \noindent 1. Limited Device Storage and High Object Sizes:  While most current virtual objects are under 20MB \cite{bib:carsar, bib:objaverse}, as interaction complexity increases, the size will also increase. Storing all objects locally or fetching them on-demand from the cloud becomes impractical as object sizes and complexity grow.

    % \noindent 2. High Cloud Latency and Strict Latency Requirements:  Average cloud latency hovers around 60ms \cite{bib:clatency, bib:clt1, bib:clt2}, exceeding the sub-20ms latency threshold required for an immersive AR experience \cite{bib:20ms}. Only a combined approach utilizing 5G/6G networks and edge infrastructure can potentially achieve this low latency target.

    % \noindent 3. On-Demand Fetch Inefficiency:  The on-demand fetching of objects from the cloud can introduce significant latency, negatively impacting user experience. By anticipating user needs and preemptively storing data at the edge, we can ensure rapid availability and facilitate efficient sharing among users with similar interests.
    
    % \noindent 4. Power Consumption and Data Transfer:The inefficiencies inherent to on-demand fetching can result in missed opportunities to reduce bandwidth usage, subsequently leading to elevated data transfer latencies and increased power consumption \cite{bib:archaract}. To mitigate these effects, intelligent prefetching methods are required to proactively store virtual objects anticipated to be accessed in the near future, thereby minimizing power consumption.

\subsection{Edge caching}
    Edge infrastructure is well placed to meet these challenges by expanding on the limited on-device storage capacity, while reducing the user latency. The use of the edge in an MAR context necessitates novel data management policies that consider both AR-specific data characteristics and edge/cloud parameters. 
    %Achieving such low latency necessitates while meeting the storage requirements of AR objects the use of 
    %a combined approach utilizing 5G/6G networks and 
    %edge infrastructure.
    
    Recent research on MAR architecture and applications \cite{bib:edgearch, bib:carsar, bib:sear,bib:localcache,bib:slamshare} partitions data and tasks across mobile devices and edge servers to leverage resources at both locations and facilitate data sharing. Caching is crucial for improving AR application performance, and partitioning the cache across devices and edge servers has shown potential for increasing hit rates and reducing latency~\cite{bib:carsar, bib:sear}. 
    
    However, existing approaches often neglect critical AR-specific factors: (1) \textit{Increasing Object Sizes}: Caching strategies must adapt to the growing size and complexity of virtual objects. (2) \textit{Occlusion and User Proximity}: Virtual objects can be occluded by physical objects in AR environments. Additionally, users are more likely to interact with nearby objects. These spatial considerations, along with object access patterns, can inform more effective caching strategies. (3) \textit{Object Relevance and User Associations}: User interactions with virtual objects often exhibit predictable patterns (e.g., a user interacting with a milk carton may subsequently interact with nearby eggs or bread). However, caching strategies must assess the relevance of potential interactions to avoid unnecessary cache pollution.

    % These challenges necessitate novel data management policies that consider both AR-specific data characteristics and edge cloud parameters. Recent research on mobile AR architecture and applications \cite{bib:edgearch, bib:carsar, bib:sear,bib:localcache,bib:slamshare}, partitions data and tasks across mobile devices and edge servers to leverage resources at both locations and facilitate data sharing. Caching is a crucial aspect for improving AR application performance, and partitioning cache across local devices and edge servers has shown promise in increasing hit rates and reducing response latency \cite{bib:carsar, bib:sear}.  However, existing approaches often overlook AR-specific factors such as (1) \textit{Increasing Object Sizes}: Caching strategies need to adapt to the growing size and complexity of virtual objects. (2) \textit{Occlusion and User Proximity}: In AR environments, virtual objects may be obscured by physical objects positioned in front of them (occlusion). Furthermore, users are significantly more likely to interact with objects within their immediate vicinity compared to those farther away. These spatial considerations, in conjunction with object access patterns, can inform more effective caching strategies. (3) \textit{Object Relevance and User Associations}: A user interacting with a virtual milk carton in a grocery store scenario may be more likely to subsequently interact with nearby eggs, bread, or other related items. However, to avoid unnecessary cache pollution, the relevance of these potential interactions should be assessed before preemptively caching associated objects.
    
   % This paper proposes \spaarc, a prefetching policy that addresses these limitations by incorporating both the proximity of virtual objects to users and object associations to make informed decisions on edge server caching.
    %\vspace{-1.5mm}
    \subsubsection*{The need for Prefetch}
        %The increasing use of mobile devices to interact with large virtual objects presents challenges due to limited device storage. 
        Edge caching offers a promising solution by storing frequently accessed objects closer to the user, reducing cloud traffic and improving access times. However, efficient cache management is crucial given the limited and heterogeneous nature of edge resources.  Traditional cache eviction algorithms (e.g., LRU, LFU, FIFO, etc.) can be employed on the edge cache, but relying solely on reactive retrieval from the cloud upon cache misses can still introduce significant latency. Predictive prefetching based on access patterns can anticipate future requests and proactively cache necessary objects at the edge, reducing cache misses and enhancing user experience at the potential expense of increased network usage.
        
    \vspace{-1.5mm}
    \subsection{Associations and Spatial Proximity}
        Association rule mining (ARM) \cite{bib:arm}, a technique widely used in recommender systems to predict user-item interactions, offers a promising approach for AR prefetching. ARM has proven successful in various domains, including e-commerce \cite{bib:phara}, tourism \cite{bib:dublin}, fraud detection \cite{bib:fraud}, and social network analysis\cite{bib:sna}. For example, in online grocery shopping, purchasing milk and eggs often triggers recommendations for bread and jam. However, the direct application of ARM for prefetching in AR remains an underexplored area.  The rule generation process, particularly with frequent updates, can be computationally expensive, posing a challenge for latency-sensitive AR applications. This work explores adapting ARM to the specific needs of AR, aiming to achieve efficient prefetching while minimizing computational overhead. While ARM effectively identifies related virtual objects, it may not prioritize those most relevant to the user's current location. Prefetching objects far from the user's field of view (FoV) provides limited value in AR. Therefore, this work emphasizes incorporating spatial awareness into the prefetching process. By prioritizing objects near the user's FoV, we aim to optimize cache utilization and enhance the user experience.
        
        % Association rule mining (ARM) \cite{bib:arm}, a well-established technique in recommender systems for predicting user interactions with items, offers a promising approach. ARM has demonstrated success in various domains, including e-commerce \cite{bib:phara}, tourism \cite{bib:dublin}, fraud detection \cite{bib:fraud}, and social network analysis\cite{bib:sna}. For instance, in online grocery shopping, purchasing milk and eggs often leads to recommendations for bread and jam. However, directly applying ARM for prefetching/caching in AR applications is still an area to be explored. The rule generation process can be computationally expensive, especially when frequent updates are required. This becomes problematic for latency-sensitive applications like AR, where rapid response times are paramount. Therefore, this work explores methods to adapt ARM specifically for the needs of AR applications, aiming to achieve efficient prefetching while maintaining low computational overhead.While ARM can effectively identify related virtual objects, it may not prioritize those most relevant to the user's current location. Prefetching objects situated far from the user's field of view (FoV) would offer minimal value in an AR experience.  Therefore, this work emphasizes the importance of incorporating spatial awareness into the prefetching process. By prioritizing objects in close proximity to the user's FoV, we aim to optimize cache utilization and enhance the overall user experience.
    % \vspace{-1.5mm}
    % \subsection{Association rule mining}
    % \label{ssec:arm}

    %     Association rule mining (ARM) \cite{bib:armorig, bib:arm} identifies relationships between items in a transaction database by discovering frequent itemsetsâ€”groups of items that frequently co-occur in transactions. The support $(S)$ of an itemset indicates the proportion of transactions containing that itemset, with frequent itemsets exceeding a predefined minimum support threshold. Based on these frequent itemsets, ARM generates association rules of the form  $A \implies B$, where $A$ (antecedent) and $B$ (consequent) are disjoint itemsets. The confidence $(C)$ of a rule represents the conditional probability of observing the consequent in transactions containing the antecedent, controlled by a minimum confidence threshold.  The lift $(L)$ of a rule measures the strength of the association between the antecedent and consequent, quantifying how much more likely they are to co-occur than if they were statistically independent.
        
        % Association rule mining \cite{bib:armorig, bib:arm} discovers relationships between items in a transaction database by identifying frequent itemsets. An itemset represents a group of items that frequently co-occur in transactions. The support of an itemset signifies the proportion of transactions containing the itemset. Frequent itemsets are those that exceed a minimum support threshold. Based on these frequent itemsets, ARM generates a set of association rules expressed as $A \implies C$, where $A$ and $C$ are disjoint itemsets referred to as antecedents and consequents, respectively. The confidence of a rule reflects the conditional probability of encountering the consequent within transactions containing the antecedent.  A minimum confidence threshold allows control over the quality of generated rules. The lift of a rule measures how much more likely two itemsets are to occur together than if they were statistically independent. In simpler terms, it quantifies the strength of the association between the itemsets.
        % Support of an itemset $X$ ($S(X)$), confidence of a rule $A \implies B$ ($C(A \implies B)$) and lift of the rule ($L(A \implies B)$) are formally represented as follows:
        % \begin{align}
        %     S(X) & = \frac{T(X)}{T} \\
        %     C(A \implies B) & = \frac{S(A \implies B)}{S(A)}\\
        %     L(A \implies B) &= \frac{S(A \cup B)}{S(A) * S(B)}
        % \end{align}
        % where $T(X)$ and $T$ are the number of transactions containing $X$ and the total number of transactions respectively.
        % It is important to emphasize that minimum support and minimum confidence are employed as thresholds rather than fixed values in ARM. Increasing these thresholds reduces the number of generated association rules.  In extreme cases, where the desired rule quality cannot be achieved with the specified thresholds, no rules may be generated, as will be further explored in the evaluation section (Section \ref{sec:eval}).