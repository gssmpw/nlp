\section{Related Work}
\label{sec:related}
    Mobile augmented reality (MAR) applications \cite{bib:arsurvey1} enhance user perception by integrating virtual objects into their view. These applications typically employ a distributed architecture across mobile devices, edge servers, and the cloud \cite{bib:edgearch, bib:arena, bib:iotarch}.  Efficiently partitioning compute- and data-intensive operations across these tiers is crucial. While MAR applications initially relied on local storage on mobile devices for rapid retrieval and rendering of virtual objects \cite{bib:localcache}, on-demand fetching from the cloud has become prevalent with increasing application complexity \cite{bib:cloudar1, bib:cloudar2, bib:cloudar3, bib:cloudar4}. However, this approach faces challenges in delivering immersive experiences due to increasing object sizes and high cloud latency.
    % Mobile augmented reality (MAR) applications \cite{bib:arsurvey1} integrate virtual objects into a user's view to enhance perception. These applications typically leverage a distributed architecture spanning mobile devices, edge servers, and the cloud \cite{bib:edgearch, bib:arena, bib:iotarch}.. A critical design choice in such architectures involves partitioning compute-intensive and data-intensive operations across these tiers. Traditionally, MAR applications relied on local storage on mobile devices for fast retrieval and rendering of virtual objects \cite{bib:localcache}. However, with increasing application complexity, fetching objects on-demand from the cloud became a common solution \cite{bib:cloudar1, bib:cloudar2, bib:cloudar3, bib:cloudar4}. Unfortunately, this approach struggles to deliver an immersive experience due to growing object sizes and high cloud latency.

    Edge caching has emerged as a promising solution for AR applications \cite{bib:cachemec, bib:artactile}, reducing latency and offering greater storage capacity compared to mobile devices.  Existing research explores various edge caching strategies. Cachier \cite{bib:cachier} employs a latency-minimizing model that balances load distribution between cloud and edge, considering network conditions and request locality. Agar \cite{bib:agar} uses dynamic programming to identify popular data chunks for caching. CEDC-O \cite{bib:onlinecoll} formulates edge data caching as an optimization problem considering caching cost, migration cost, and quality-of-service penalties.
    
    % Edge caching has emerged as a promising solution for AR applications \cite{bib:cachemec, bib:artactile}. By storing frequently accessed data at the edge, it reduces end-to-end latency and offers greater storage capacity compared to mobile devices. Existing works explore various caching strategies at the edge. Cachier \cite{bib:cachier} employs a latency-minimizing caching model that balances load distribution between the cloud and edge, while considering online network conditions and request locality. Agar \cite{bib:agar} utilizes dynamic programming to identify data chunks for caching based on popularity. CEDC-O \cite{bib:onlinecoll} formulates edge data caching as an optimization problem that factors in caching cost, migration cost, and quality-of-service penalties.

    While CARS \cite{bib:carsar} and SEAR \cite{bib:sear} utilize Device-to-Device (D2D) communication for sharing cached virtual objects, they lack prefetching mechanisms. DreamStore \cite{bib:dreamstore} allows devices to store virtual objects and employs a publish-subscribe model for data updates, incorporating location-based prefetching but without considering object relevance. Precog \cite{bib:precog} and \cite{bib:arwmnedge} utilize Markov models for query prediction but do not account for inter-object relationships, a key aspect of \spaarc{}.
    
    While CARS \cite{bib:carsar} and SEAR \cite{bib:sear} leverage Device-to-Device (D2D) communication to share cached virtual objects with nearby users, they lack prefetching capabilities. DreamStore \cite{bib:dreamstore} allows user devices to store virtual objects and employs a publish-subscribe mechanism for data updates. It also incorporates a location-based prefetching mechanism, but fails to consider object relevance to the user. Precog \cite{bib:precog} and \cite{bib:arwmnedge} utilize a Markov model to predict user queries, but do not account for relationships between objects in a region, which is a key strength of \spaarc{}.

    Other research efforts focus on caching content for different media types at the edge. Works like \cite{bib:coopec, bib:tile,bib:cubist} explore caching tiles of 360$^\circ$ videos to enable processing reuse. Space \cite{bib:space} and Leap \cite{bib:leap} investigate prefetching video segments for users at the edge. EdgeBuffer \cite{bib:edgebuffer} leverages user mobility patterns across access points to prefetch data to anticipated locations.

    Association rule mining (ARM) \cite{bib:armorig, bib:arm} has established itself as a valuable technique for prefetching data in various domains, including e-commerce recommendation systems, fraud detection, and social network analysis. For instance, Mithril \cite{bib:mithril} leverages historical patterns of cache requests within cloud applications to derive item association rules using a variant of ARM called sporadic-ARM. Similarly, web prefetching, which involves caching web objects in anticipation of user requests, is a well-researched area \cite{bib:webcache}. However, the potential of ARM for prefetching in augmented reality (AR) applications remains largely unexplored.