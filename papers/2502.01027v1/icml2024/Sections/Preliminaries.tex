\section{Preliminaries}


\paragraph{Multi-task scenario.} \label{prel:multi}
We consider a multi-task setting that addresses both classification and regression problems simultaneously. Let \(\mathcal{X}\) denote the input space, \(\mathcal{Y} = \{1, \ldots, n\}\) represent the set of \(n\) distinct classes for classification, and \(\mathcal{T} \subseteq \mathbb{R}\) denote the target space for regression. Each data point is represented as a triplet \(z = (x, y, t) \in \mathcal{Z}\), where \(\mathcal{Z} = \mathcal{X} \times \mathcal{Y} \times \mathcal{T}\). We assume the data is drawn independently and identically distributed (i.i.d.) from an underlying distribution \(\mathcal{D}\) over \(\mathcal{Z}\). To model this multi-task problem, we introduce a \emph{backbone} \(w \in \mathcal{W}\), which acts as a shared feature extractor. The backbone maps inputs \(x \in \mathcal{X}\) to a latent feature representation \(q \in \mathcal{Q}\), via the function \(w: \mathcal{X} \to \mathcal{Q}\). Building upon this backbone, we define a \emph{classifier} \(h \in \mathcal{H}\), representing all possible classification heads. Formally, \(h: \mathcal{Q} \times \mc{Y} \to \mb{R}\) is a scoring function, with predictions computed as \(h(q) = \arg\max_{y \in \mathcal{Y}} h(q, y)\). Similarly, we define a \emph{regressor} \(f \in \mathcal{F}\), which maps latent features to real-valued targets, \(f: \mathcal{Q} \to \mathcal{T}\). These components are integrated into a single multi-head network \(g \in \mathcal{G}\), defined as $\mathcal{G} = \{ g : g(x) = (h \circ w(x), f \circ w(x)) \mid w \in \mathcal{W}, h \in \mathcal{H}, f \in \mathcal{F} \}$.
\paragraph{Consistency in classification:}  
In classification, the primary objective is to identify a classifier \( h \in \mathcal{H} \) that minimizes the true error \(\mathcal{E}_{\ell_{01}}(h)\), defined as \(\mathcal{E}_{\ell_{01}}(h) = \mathbb{E}_{(x,y)} [\ell_{01}(h,x,y)]\). The Bayes-optimal error is expressed as \(\mathcal{E}^B_{\ell_{01}}(\mathcal{H}) = \inf_{h \in \mathcal{H}} \mathcal{E}_{\ell_{01}}(h)\). However, minimizing \(\mathcal{E}_{\ell_{01}}(h)\) directly is challenging due to the non-differentiability of the \textit{true multiclass} 0-1 loss \citep{Statistical, Steinwart2007HowTC, Awasthi_Mao_Mohri_Zhong_2022_multi}.  To address this challenge, surrogate losses are employed as convex, non-negative upper bounds on \( \ell_{01} \). A notable family of multiclass surrogate losses is the comp-sum \citep{Foundations, mao2023crossentropylossfunctionstheoretical}, which we refer to as a family of \textit{multiclass surrogate} losses:
\begin{equation}\label{eq:multi}
    \Phi_{01}^u(h, x, y) = \Psi^u\Big(\sum_{y' \neq y} \Psi_{\text{e}}(h(x, y) - h(x, y'))\Big),
\end{equation}
where \(\Psi_{\text{e}}(v) = \exp(-v)\), which defines the cross-entropy family. For \( u > 0 \), the transformation is given by:
\begin{equation}
    \Psi^{u}(v) = \begin{cases}
         \log(1 + v) & \text{if } u = 1, \\
        \frac{1}{1 - u} \left[(1 - v)^{1 - u} - 1\right] & \text{if } u > 0 \land u \neq 1.
    \end{cases}
\end{equation}
This formulation generalizes several well-known loss functions, including the sum-exponential loss \citep{weston1998multi}, logistic loss \citep{Ohn_Aldrich1997-wn}, generalized cross-entropy \citep{zhang2018generalizedcrossentropyloss}, and  mean absolute error loss \citep{Ghosh}. The corresponding true error for \( \Phi_{01}^u \) is defined as \(\mathcal{E}_{\Phi_{01}^u}(h) = \mathbb{E}_{(x, y)} [\Phi_{01}^u(h, x, y)]\), with its optimal value expressed as \(\mathcal{E}^\ast_{\Phi_{01}^u}(\mathcal{H}) = \inf_{h \in \mathcal{H}} \mathcal{E}_{\Phi_{01}^u}(h)\).

A key property of a surrogate loss is \textit{Bayes-consistency}, which ensures that minimizing the surrogate excess risk leads to minimizing the true excess risk \citep{Statistical, bartlett1, Steinwart2007HowTC, tewari07a}. Formally, \(\Phi_{01}^u\) is Bayes-consistent with respect to \(\ell_{01}\) if, for any sequence \(\{h_k\}_{k \in \mathbb{N}} \subset \mathcal{H}\), the following implication holds:
\begin{equation}
\begin{aligned}\label{bayes-consi}
    & \mathcal{E}_{\Phi_{01}^u}(h_k) - \mathcal{E}_{\Phi_{01}^u}^\ast(\mathcal{H}) \xrightarrow{k \to \infty} 0 \\
    & \implies \mathcal{E}_{\ell_{01}}(h_k) - \mathcal{E}_{\ell_{01}}^B(\mathcal{H}) \xrightarrow{k \to \infty} 0.
\end{aligned}
\end{equation}

This property typically assumes \(\mathcal{H} = \mathcal{H}_{\text{all}}\), which may not hold for restricted hypothesis classes such as \(\mathcal{H}_{\text{lin}}\) or \(\mathcal{H}_{\text{ReLU}}\) \citep{pmlr-v28-long13, Awasthi_Mao_Mohri_Zhong_2022_multi, mao2024h}. To characterize consistency with a particular hypothesis set, \citet{Awasthi_Mao_Mohri_Zhong_2022_multi} introduced \(\mathcal{H}\)-consistency bounds, which rely on a non-decreasing function \(\Gamma: \mathbb{R}^+ \to \mathbb{R}^+\) and take the following form:
\begin{equation}\label{mhbc}
\begin{aligned}
     & \mathcal{E}_{\Phi_{01}^u}(h) - \mathcal{E}_{\Phi_{01}^u}^\ast(\mathcal{H}) + \mathcal{U}_{\Phi_{01}^u}(\mathcal{H}) \geq \\
     & \Gamma\Big(\mathcal{E}_{\ell_{01}}(h) - \mathcal{E}_{\ell_{01}}^B(\mathcal{H}) + \mathcal{U}_{\ell_{01}}(\mathcal{H})\Big),
\end{aligned}
\end{equation}
where the minimizability gap \(\mathcal{U}_{\ell_{01}}(\mathcal{H})\) quantifies the difference between the best-in-class excess risk and the expected pointwise minimum error: $\mathcal{U}_{\ell_{01}}(\mathcal{H}) = \mathcal{E}_{\ell_{01}}^B(\mathcal{H}) - \mathbb{E}_{x} \left[ \inf_{h \in \mathcal{H}} \mathbb{E}_{y \mid x} \left[ \ell_{01}(h,x,y) \right] \right]$. 
The gap vanishes when \(\mathcal{H} = \mathcal{H}_{\text{all}}\) \citep{Steinwart2007HowTC, Awasthi_Mao_Mohri_Zhong_2022_multi}. In the asymptotic limit, inequality \eqref{mhbc} ensures recovery of Bayes-consistency \eqref{bayes-consi}.



\paragraph{Adversarial robustness:} 
Adversarial robust classification aims to train classifiers that are robust to small, imperceptible perturbations of the input \citep{goodfellow2014explaining, Madry2017TowardsDL}. The objective is to minimize the \textit{true multiclass loss} $\ell_{01}$ evaluated on an adversarial input $x'=x+\delta$ \citep{ Gowal2020UncoveringTL, Awasthi_Mao_Mohri_Zhong_2022_multi}.  A perturbation $\delta$ is constrained by its magnitude, and we define the adversarial region around $x$ as \( B_p(x, \gamma) = \{ x' \mid \|x' - x\|_p \leq \gamma \} \), where \(\| \cdot \|_p\) is the \(p\)-norm and \(\gamma \in (0,1)\) specifies the maximum allowed perturbation. The \textit{adversarial true multiclass loss} $\widetilde{\ell}_{01}: \mathcal{H} \times \mathcal{X} \times \mathcal{Y} \to \{0,1\}$ is given by:
\begin{equation}
    \widetilde{\ell}_{01}(h,x,y) = \sup_{x' \in B_p(x, \gamma)} \ell_{01}(h(x'), y).
\end{equation}
Similarly to classification, minimizing \(\widetilde{\ell}_{01}\) is computationally infeasible \citep{Zhang, bartlett1, Awasthi_Mao_Mohri_Zhong_2022_multi}. To address this, we introduce the family of \textit{adversarial margin surrogate} losses \(\widetilde{\Phi}^{\rho,u}_{01}\) from the comp-sum \(\rho\)-margin family, which approximate the \textit{adversarial true multiclass loss} \(\widetilde{\ell}_{01}\). This family is defined as:
\begin{equation}\label{eq:family_sup}
    \widetilde{\Phi}^{\rho,u}_{01}(h,x,y) = \mspace{-23mu} \sup_{x'\in B_p(x,\gamma)} \mspace{-20mu}\Psi^u \Big(\mspace{-5mu}\sum_{y'\not =y}\mspace{-5mu}\Psi_\rho (h(x',y') - h(x',y))\mspace{-5mu}\Big).
\end{equation}
Here, \(\Psi^u\) and \(\Psi_\rho\) represent transformations that characterize the behavior of the family, where the non-convex transformation is defined as \(\Psi_\rho(v) = \min\left\{\max\left(0, 1 - \frac{v}{\rho}\right), 1\right\}\). Recent studies have demonstrated that algorithms employing smooth regularized variants of the comp-sum \(\rho\)-margin losses achieve \(\mathcal{H}\)-consistency, thereby offering strong theoretical guarantees \citep{Awasthi_Mao_Mohri_Zhong_2022_multi, Grounded, mao2023crossentropylossfunctionstheoretical}.



\paragraph{Two-stage Learning-to-Defer:} 
The Learning-to-Defer framework assigns queries \( x \in \mathcal{X} \) to the most confident \textit{agent}, aiming to enhance performance by leveraging the strengths of multiple agents. The agents consist of a primary model and \( J \) experts, denoted by the set \( \mathcal{A} = \{0\} \cup [J] \), where \( 0 \) corresponds to the primary model \( g \) defined in Section \ref{prel:multi}. Each expert \( \text{M}_j \) provides a prediction pair \( m_j(x) = (m_j^h(x), m_j^f(x)) \), where \( m_j^h(x) \in \mathcal{Y} \) is a categorical prediction and \( m_j^f(x) \in \mc{T} \) is a regression estimate. The combined predictions of all \( J \) experts are represented as \( m(x) = \big(m_1(x), \dots, m_J(x)\big) \), which lies in the joint prediction space \( \mathcal{M} \). In the two-stage setting, all agents are trained offline, and the framework focuses on \textit{query allocation}, keeping agent parameters fixed.

A rejector function \( r \in \mathcal{R} \), defined as \( r: \mathcal{X} \times \mathcal{A} \to \mathbb{R} \), is learned to assign a query \( x \) to the agent \( j \in \mathcal{A} \) with the highest rejection score \( r(x) = \arg\max_{j \in \mathcal{A}} r(x, j) \), as described by \citet{mao2024regressionmultiexpertdeferral, mao2023twostage, montreuil2024twostagelearningtodefermultitasklearning}.

\begin{restatable}[Two-Stage L2D losses]{definition}{l2d}\label{def_l2d} 
Let an input \( x\in\mc{X} \), for any \( r\in\mc{R} \), we have the \textit{true deferral loss}:
\begin{equation*}
    \begin{aligned} 
    \ell_{\text{def}}(r,g,m,z) & = \sum_{j=0}^Jc_j(g(x),m_j(x),z)1_{r(x)=j},
    \end{aligned}
\end{equation*}
and its family of convex, non-negative, upper-bound \textit{surrogate deferral losses}:
\begin{equation*}
    \begin{aligned}
    \Phi_{\text{def}}^u(r,g,m,z) & = \sum_{j=0}^J\tau_j(g(x),m(x),z)\Phi_{01}^u(r,x,j),
    \end{aligned}
\end{equation*}
\end{restatable}
where \( c_j \) denotes the non-negative bounded cost of assigning a decision to agent \( j \in \mathcal{A} \) \citep{madras2018predict}. If the rejector \( r \in \mathcal{R} \) assigns \( r(x) = 0 \), the query is handled by the primary model \( g \), which predicts \( g(x) = (h(w(x)), f(w(x))) \) and incurs a general cost \( c_0(g(x), z) = \psi(g(x), z) \). Here, \(\psi:\mc{Y}\times\mc{T}\times\mc{Z}\to \mb{R}^+\) is a general measure used to quantify the prediction quality of \( g \) with respect to \( z \). If \( r(x) = j \) for some \( j > 0 \), the query is deferred to expert \( j \), incurring a cost \( c_j(m_j(x), z) = \psi(m_j(x), z) + \beta_j \), where \( \beta_j \) represents the consultation cost associated with expert \( j \). The aggregated cost across all agents is then defined as:
\begin{equation}\label{eq:tau}
    \tau_j(g(x),m(x), z) =  \sum_{i=0}^J c_i(g(x),m_i(x), z) 1_{i \neq j}
\end{equation}
recovering the formulation from \citet{mao2024regressionmultiexpertdeferral} and \citet{montreuil2024twostagelearningtodefermultitasklearning}. Note that in the case of classification, the function $\psi$ corresponds to the $\ell_{01}$ loss. 

% Building on this, we will introduce adversarial robustness to Learning-to-Defer. 