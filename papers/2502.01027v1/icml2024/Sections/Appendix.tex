% \clearpage
% \onecolumn
% \appendix
% % \DoToC
\clearpage
\onecolumn
% \appendix
% \setcounter{theorem}{0}
% \renewcommand{\thetheorem}{1} 
% \setcounter{lemma}{0}
\begin{appendices}
% \DoToC
\section{Notation and Preliminaries for the Appendices}

We summarize the key notations and concepts introduced in the main text:

\paragraph{Input Space and Outputs:}
\begin{itemize}
    \item \( \mathcal{X} \): Input space for \( x \in \mathcal{X} \).
    \item \( \mathcal{Q} \): Latent representation \( q \in \mathcal{Q} \).
    \item \( \mathcal{Y} = \{1, \dots, n\} \): Categorical output space for classification tasks.
    \item \( \mathcal{T} \subseteq \mathbb{R} \): Continuous output space for regression tasks.
    \item \( \mathcal{Z} = \mathcal{X} \times \mathcal{Y} \times \mathcal{T} \): Combined space of inputs and labels.
\end{itemize}


\paragraph{Learning-to-Defer Setting:}
\begin{itemize}
    \item \( \mathcal{A} = \{0\} \cup [J] \): Set of agents, where \( 0 \) refers to the primary model \( g = (h, f) \), and \( J \) denotes the number of experts.
    \item \( m_j(x) = (m_j^h(x), m_j^f(x)) \): Predictions by expert \( j \), where \( m_j^h(x) \in \mathcal{Y} \) is a categorical prediction and \( m_j^f(x) \in \mc{T} \) is a regression estimate.
    \item $c_0(g(x), z) = \psi(g(x),z)$: The cost associated to the multi-task model.
    \item $c_{j>0}(m(x), z) = \psi(m(x),z) + \beta_j$: The cost associated to the expert $j$ with query cost $\beta_j\geq0$.
    \item $\psi: \mc{Y}\times\mc{T}\times\mc{Z}\to\mb{R}^+$: Quantify the prediction's quality. 
\end{itemize}

\paragraph{Hypothesis Sets:}
\begin{itemize}
    \item \(\mathcal{W}\): Set of backbones $w: \mc{X}\to\mc{Q}$.  
    \item \( \mathcal{H} \): Set of classifiers \( h: \mathcal{Q}\times\mc{Y} \to \mb{R} \).
    \item \( \mathcal{F} \): Set of regressors \( f: \mathcal{Q} \to \mc{T} \).
    \item $\mc{G}$: Single multi-head network $\mathcal{G} = \{ g : g(x) = (h \circ w(x), f \circ w(x)) \mid w \in \mathcal{W}, h \in \mathcal{H}, f \in \mathcal{F} \}$.
    \item $\mc{R}$: Set of rejectors $r:\mc{X}\rightarrow\mc{A}$. 
\end{itemize}

\paragraph{Adversarial Definitions:}
\begin{itemize}
    \item $x_j' \in B_p(x,\gamma)$: the adversarial input for the agent $j\in\mc{A}$ in the $p$-norm ball \( B_p(x, \gamma) = \{ x_j' \in \mathcal{X} \mid \|x_j' - x\|_p \leq \gamma \} \)
    \item \( \widetilde{\ell}_{01}^j(r,x,j) = \sup_{x_j' \in B_p(x, \gamma)} \ell_{01}(r,x_j', j) \): $j$-th Adversarial multiclass loss.
    \item \( \widetilde{\Phi}_{01}^{\rho,u,j}(r, x, j) = \sup_{x_j' \in B_p(x, \gamma)} \Psi^u \left( \sum_{j' \neq j} \Psi_\rho \big( r(x_j', j') - r(x_j', j) \big) \right)\): $j$-th Adversarial margin surrogate losses, providing a differentiable proxy for \( \widetilde{\ell}_{01}^j \).
\end{itemize}


This notation will be consistently used throughout the appendices to ensure clarity and coherence in theoretical and empirical discussions.
\newpage

\section{Attacks Illustration}\label{attacks}

\subsection{Untargeted Attack}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{images/AI_based_Model-51.pdf}
    \caption{Untargeted Attack: The malicious attacker perturbs the input to increase the probability that the query is assigned to a less accurate expert, thereby maximizing classification errors. Rather than targeting a specific expert, the attack injects adversarial noise to disrupt the expert allocation process, leading to erroneous routing and degraded decision-making.}
    \label{fig:untargeted}
\end{figure}

\subsection{Targeted Attack}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{images/AI_based_Model-50.pdf}
    \caption{Targeted Attack: The malicious attacker perturbs the input to increase the probability that the query is assigned to its associated agent. By manipulating the L2D system to systematically route queries to this associate, the adversary ensures that the associate receives a higher volume of queries, thereby increasing its earnings.}
    \label{fig:targeted}
\end{figure}



\section{Algorithm}\label{appendix:algo}

\begin{algorithm}[H]
   \caption{\name{} Algorithm}
   \label{alg:l2d}
\begin{algorithmic}
   \STATE {\bfseries Input:} Dataset $\{(x_k, y_k, t_k)\}_{k=1}^K$, multi-task model $g\in\mc{G}$, experts $m\in\mc{M}$, rejector $r\in\mc{R}$, number of epochs $\text{EPOCH}$, batch size BATCH, adversarial parameters $(\rho, \nu)$, regularizer parameter $\eta$, learning rate $\lambda$.
   \STATE {\bfseries Initialization:} Initialize rejector parameters $\theta$.
   \FOR{$i=1$ to $\text{EPOCH}$}
       \STATE Shuffle dataset $\{(x_k, y_k, t_k)\}_{k=1}^K$.
       \FOR{each mini-batch $\mathcal{B} \subset \{(x_k, y_k, t_k)\}_{k=1}^K$ of size BATCH}
           \STATE Extract input-output pairs $z=(x, y, t) \in \mathcal{B}$.
           \STATE Query model $g(x)$ and experts $m(x)$. \hfill\COMMENT{Agents have been trained offline and fixed}
           \STATE Evaluate costs $c_0(g(x),z)$ and $c_{j>0}(m(x),z)$. \hfill\COMMENT{Compute costs}
           \FOR{$j=0$ to $J$}
                \STATE Evaluate rejector score $r(x,j)$. \hfill\COMMENT{Rejection score of agent $j$}
                \STATE Generate adversarial input $x'_j = x + \delta_j$ with $\delta_j \in B_p(x, \gamma)$. \hfill\COMMENT{$\ell_p$-ball perturbation for agent $j$}
                \STATE Run PGD attack on $x'_j$: 
                \STATE \hspace{1em} $\sup_{x_j^\prime \in B_p(x, \gamma)} \| \overline{\Delta}_r(x_j', j) - \overline{\Delta}_r(x, j) \|_2$. \hfill\COMMENT{Smooth robustness evaluation}
                \STATE Compute Adversarial Smooth surrogate losses $\widetilde{\Phi}_{01}^{\text{smth}, u}(r, x, j)$. 
           \ENDFOR
           \STATE Compute the regularized empirical risk minimization:
           \STATE \hspace{1em} $\widehat{\mc{E}}_{\Phi_{\text{def}}}^{\,\Omega}(r;\theta) = \frac{1}{\text{BATCH}} \sum_{z \in \mathcal{B}} \Big[ \widetilde{\Phi}_{\text{def}}^{\text{smth}, u}(r,g,m, z) \Big] + \eta \Omega(r)$.
           \STATE Update parameters $\theta$:
           \STATE \hspace{1em} $\theta \leftarrow \theta - \lambda \nabla_\theta \widehat{\mc{E}}_{\Phi_{\text{def}}}^{\,\Omega}(r;\theta)$. \hfill\COMMENT{Gradient update}
       \ENDFOR
   \ENDFOR
   \STATE \textbf{Return:} trained rejector model $r^\ast$.
\end{algorithmic}
\end{algorithm}



\section{Proof Adversarial Robustness in Two-Stage Learning-to-Defer}

\subsection{Proof Lemma \ref{lemma:deferral}}

\label{appendix:deferral}

\deferral* 
\begin{proof}
In adversarial training, the objective is to optimize the worst-case scenario of the objective function under adversarial inputs \( x' \in B_p(x, \gamma) \). For our case, we start with the standard L2D loss for the two-stage setting \citep{mao2024regressionmultiexpertdeferral, montreuil2024twostagelearningtodefermultitasklearning}:
\begin{equation} \label{eq:1}
\begin{aligned}
    \ell_{\text{def}}(r, g,m,z) & = \sum_{j=0}^J c_j(g(x),m_j(x),z) 1_{r(x) = j} \\
    & = \sum_{j=0}^J \tau_j(g(x),m(x),z) 1_{r(x) \neq j} + (1-J) \sum_{j=0}^J c_j(g(x),m_j(x),z)
\end{aligned}
\end{equation}
using \begin{equation}
    \tau_j(g(x),m(x),z) =  \begin{cases}
         \sum_{i=1}^J c_i(m_i(x), z) & \text{if } j=0 \\
        c_0(g(x), z) + \sum_{i=1}^J c_i(m_i(x), z) 1_{i \neq j} & \text{otherwise}
    \end{cases}
\end{equation}
Next, we derive an upper bound for Equation~\eqref{eq:1} by considering the supremum over all adversarial perturbations \( x' \in B_p(x, \gamma) \), under the fact that the attack is solely on the rejector \( r \in \mathcal{R} \):
\begin{equation} \label{eq:2}
    \ell_{\text{def}}(r, g,m,z) \leq \sup_{x' \in B_p(x, \gamma)} \Big( \sum_{j=0}^J \tau_j(g(x),m(x),z) 1_{r(x') \neq j} \Big) + (1-J) \sum_{j=0}^J c_j(g(x),m_j(x),z)
\end{equation}

However, the formulation in Equation~\eqref{eq:2} does not fully capture the worst-case scenario in L2D. Specifically, this formulation might not result in a robust approach, as it does not account for the adversarial input \( x'_j \in B_p(x, \gamma) \) that maximizes the loss for every agent \( j \in \mathcal{A} \). Incorporating this worst-case scenario, we obtain:
\begin{equation}
\begin{aligned}
    \ell_{\text{def}}(r,g,m,z) & \leq \sum_{j=0}^J \tau_j(g(x),m(x),z) \sup_{x_j' \in B_p(x, \gamma)} 1_{r(x_j') \neq j} + (1-J) \sum_{j=0}^J c_j(g(x),m_j(x),z)
\end{aligned}
\end{equation}

Thus, formulating with the margin loss $\rho_r(x,j) = r(x,j) - \max_{j'\not=j}r(x,j')$, leads to the desired result:
\begin{equation}
\begin{aligned}
    \widetilde{\ell}_{\text{def}}(r, g,m,z) & = \sum_{j=0}^J \tau_j(g(x),m(x),z) \sup_{x_j' \in B_p(x, \gamma)} 1_{\rho_r(x_j', j) \leq 0} + (1-J) \sum_{j=0}^J c_j(g(x),m_j(x),z) \\
    & = \sum_{j=0}^J \tau_j(g(x),m(x),z) \widetilde{\ell}^j_{01}(r,x,j) + (1-J) \sum_{j=0}^J c_j(g(x),m_j(x),z)
\end{aligned}
\end{equation}
with $\widetilde{\ell}^j_{01}(r,x,j) = \sup_{x_j'\in B_p(x,\gamma)}1_{\rho_r(x'_j,j)\leq0}$
\end{proof}

\subsection{Proof Lemma \ref{lemma:deferralmargin}} \label{proof:margindeferral}
\margindeferral*
\begin{proof}
    Referring to adversarial true deferral loss defined in Lemma \ref{lemma:deferral}, we have:
\begin{equation*}
\begin{aligned}
    \widetilde{\ell}_{\text{def}}(r, g,m,z) & = \sum_{j=0}^J \tau_j(g(x),m(x),z) \mspace{-10mu} \sup_{x_j' \in B_p(x, \gamma)} \mspace{-10mu} 1_{\rho_r(x_j', j) \leq 0} + (1-J) \sum_{j=0}^J c_j(g(x),m_j(x),z) \\
    & = \sum_{j=0}^J \tau_j(g(x),m(x),z) \widetilde{\ell}^j_{01}(r,x,j) + (1-J) \sum_{j=0}^J c_j(g(x),m_j(x),z)
\end{aligned}
\end{equation*}

By definition, \(\widetilde{\Phi}^{\rho,u,j}_{01}\) upper bounds the $j$-th adversarial classification loss \(\widetilde{\ell}_{01}^j\), leading to:
\begin{equation}
    \widetilde{\ell}_{\text{def}}(r, g,m,z) \leq \sum_{j=0}^J \tau_j(g(x),m(x),z) \widetilde{\Phi}^{\rho,u,j}_{01}(r, x, j) + (1-J) \sum_{j=0}^J c_j(g(x),m_j(x),z)
\end{equation}
Then, dropping the term that does not depend on $r\in\mc{R}$, leads to the desired formulation:
\begin{equation}
    \widetilde{\Phi}^{\rho, u}_{\text{def}}(r, g,m,z) = \sum_{j=0}^J \tau_j(g(x),m(x),z) \widetilde{\Phi}^{\rho,u,j}_{01}(r, x, j)
\end{equation}

\end{proof}

\subsection{Proof Lemma \ref{lemma:surrogate_class}} \label{appendix:smooth}
\surrogatemulti*
\begin{proof}
Let \( x \in \mathcal{X} \) denote an input  and \( x_j' \in B_p(x, \gamma) \) an adversarially perturbed input within an \( \ell_p \)-norm ball of radius \( \gamma \) for each agent. Let \( r \in \mathcal{R} \) be a rejector. We now define the composite-sum \(\rho\)-margin losses for both clean and adversarial scenarios:
\begin{equation}
\begin{aligned}
    \Phi^{\rho, u}_{01}(r, x, j) & = \Psi^u \left( \sum_{j' \neq j} \Psi_\rho \big(r(x, j') - r(x, j)\big) \right) \\
    \widetilde{\Phi}^{\rho,u,j}_{01}(r, x, j) & = \sup_{x_j' \in B_p(x, \gamma)} \Psi^u \left( \sum_{j' \neq j} \Psi_\rho \big(r(x_j', j') - r(x_j', j)\big) \right)
\end{aligned}
\end{equation}
where \(\Psi_{\text{e}}(v) = \exp(-v)\). For \( u > 0 \), the transformation \(\Psi^u\) is defined as:
\[
\Psi^{u=1}(v) = \log(1 + v), \quad \Psi^{u \neq 1}(v) = \frac{1}{1 - u} \left[(1 - v)^{1 - u} - 1\right]
\]
It follows that for all \( u>0 \) and \( v \geq 0 \), we have \( \left| \frac{\partial \Psi^u}{\partial v}(v) \right| = \frac{1}{(1+v)^u} \leq 1 \)  ensuring that \(\Psi^u\) is 1-Lipschitz over \(\mathbb{R}^+\) \citep{mao2023crossentropylossfunctionstheoretical}. 

Define \( \Delta_r(x, j, j') = r(x, j) - r(x, j') \) and let \( \overline{\Delta}_r(x, j) \) denote the \( J \)-dimensional vector:
\[
\overline{\Delta}_r(x, j) = \big( \Delta_r(x, j, 0), \ldots, \Delta_r(x, j, j-1), \Delta_r(x, j, j+1), \ldots, \Delta_r(x, j, J) \big)
\]
For any \( u>0 \), with \(\Psi^u\) non-decreasing and 1-Lipschitz:
\begin{equation}
    \widetilde{\Phi}_{01}^{\rho, j}(r, x, j) \leq \Phi_{01}^{\rho, u}(r, x, j) + \sup_{x_j' \in B_p(x, \gamma)} \sum_{j' \neq j} \Big( \Psi_\rho \big(-\Delta_r(x_j', j, j')\big) - \Psi_\rho \big(-\Delta_r(x, j, j')\big) \Big)
\end{equation}
Since \(\Psi_\rho(z)\) is \(\frac{1}{\rho}\)-Lipschitz, by the Cauchy-Schwarz inequality and for \(\nu \geq \frac{\sqrt{n-1}}{\rho} \geq \frac{1}{\rho}\):
\begin{equation}
\begin{aligned}
    \widetilde{\Phi}_{01}^{\rho,u,j}(r, x, j) & \leq \Phi_{01}^{\rho, u}(r, x, j) + \nu \sup_{x_j' \in B_p(x, \gamma)} \| \overline{\Delta}_r(x_j', j) - \overline{\Delta}_r(x, j) \|_2
\end{aligned}
\end{equation}

Using \(\Phi_{01}^u(r, x, y) = \Psi^u\big(\sum_{y' \neq y} \Psi_{\text{e}}(r(x, y) - r(x, y'))\big)\) with \(\Psi_{\text{e}}(v) = \exp(-v)\) and the fact that \(\Psi_{\text{e}}(v / \rho) \geq \Psi_\rho(v)\), we obtain:
\begin{equation}
\begin{aligned}
    \widetilde{\Phi}_{01}^{\rho,u,j}(r, x, j) & \leq \Phi_{01}^u\left(\frac{r}{\rho}, x, j\right) + \nu \sup_{x_j' \in B_p(x, \gamma)} \| \overline{\Delta}_r(x_j', j) - \overline{\Delta}_r(x, j) \|_2
\end{aligned}
\end{equation}

Finally, we have the desired smooth surrogate losses upper-bounding $ \widetilde{\Phi}_{01}^{\text{smth}, u} \geq \widetilde{\Phi}_{01}^{\rho,u,j}$:
\begin{equation}
    \widetilde{\Phi}_{01}^{\text{smth}, u}(r, x, j) = \Phi_{01}^u\left(\frac{r}{\rho}, x, j\right) + \nu \sup_{x_j' \in B_p(x, \gamma)} \| \overline{\Delta}_r(x_j', j) - \overline{\Delta}_r(x, j) \|_2
\end{equation}
\end{proof}


\subsection{Proof Lemma \ref{lemma:surrogate}}\label{proof:surrogate}
\robustsurrogate*
\begin{proof}
Using Lemma \ref{lemma:deferralmargin}, we have:
\begin{equation}
    \widetilde{\Phi}^{\rho, u}_{\text{def}}(r, g,m,z) = \sum_{j=0}^J \tau_j(g(x),m(x),z) \widetilde{\Phi}^{\rho, j}_{01}(r, x, j) 
\end{equation}
Since \(\widetilde{\Phi}^{\rho,u,j}_{01} \leq \widetilde{\Phi}^{\text{smth}, u}_{01}\) by Lemma \ref{lemma:surrogate_class}, we obtain:
\begin{equation}
    \widetilde{\Phi}^{\text{smth}, u}_{\text{def}}(r, g,m,z) = \sum_{j=0}^J \tau_j(g(x),m(x),z) \widetilde{\Phi}^{\text{smth}, u}_{01}(r, x, j)
\end{equation}
\end{proof}






\subsection{Proof Lemma \ref{lemma:rconsistency}}
\rconsistency* \label{proof:rconsistency}

\begin{proof}

We define the margin as $\rho_r(x, j) = r(x, j) - \max_{j' \neq j} r(x, j')$, which quantifies the difference between the score of the $j$-th dimension and the highest score among all other dimensions. Starting from this, we can define a space $\overline{\mc{R}}_{\gamma}(x) = \{r\in\mc{R}: \inf_{x^\prime \in B_p(x,\gamma)}\rho_r(x^\prime, r(x))>0\}$ for $B_p(x, \gamma) = \{ x' \mid \|x' - x\|_p \leq \gamma \}$ representing hypothesis that correctly classifies the adversarial input. By construction, we have that $x_j^\prime \in B_p(x,\gamma)$. 

In the following, we will make use of several notations. Let $p(x) = (p(x, 0), \ldots, p(x, J))$ denote the probability distribution over $\mc{A}$ at point $x \in \mathcal{X}$. We sort these probabilities $\{p(x,j):j\in\mc{A}\}$ in increasing order $p_{[0]}(x) \leq p_{[1]}(x) \leq \cdots \leq p_{[J]}(x)$. Let $\mathcal{R}$ be a hypothesis class for the rejector $r\in\mc{R}$ with $r:\mc{X}\times\mc{A}\rightarrow\mb{R}$. We assume this hypothesis class to be \textit{symmetric} implying that for any permutation $\pi$ of $\mathcal{A}$ and any $r \in \mathcal{R}$, the function $r^\pi$ defined by $r^\pi(x, j) = r(x, \pi(j))$ is also in $\mathcal{R}$ for $j\in\mc{A}$. We similarly have $r\in\mc{R}$, such that $r(x,\{0\}_x^r), r(x,\{1\}_x^r), \cdots, r(x,\{J\}_x^r)$ sorting the scores $\{ r(x,j): j\in\mc{A}\}$ in increasing order.

% Furthermore, we assume $\mc{R}$ to be \textit{locally $\rho$-consistent} implying that for any $x \in \mathcal{X}$ and $r \in \mathcal{R}$, there exists $\delta > 0$ such that for all $x'$ with $\|x - x'\| \leq \delta$ (or $B_p(x,\gamma)$), it holds that $|r(x', j) - r(x', j')| \geq \rho$ for all $j \neq j'$. 

For $\mc{R}$ symmetric and locally $\rho$-consistent, there exists $r^*\in\mc{R}$ with the same ordering of the $j\in\mc{A}$, regardless of any $x_j' \in B_p(x,\gamma)$. This implies  $\inf_{x'_j \in B_p(x,\gamma)}|r^*(x'_j, q) - r^*(x'_j, q')| \geq \rho$ for $\forall q' \neq q \in \mc{A}$. Using the symmetry of $\mc{R}$, we can find a $r^\ast$ with the same ordering of $j\in\mc{A}$, i.e. $p(x,\{k\}_{x}^{r^\ast}) = p_{[k]}(x)$ for any $k\in\mc{A}$:
\begin{equation}
   \forall j \in \mc{A}, \quad r^\ast(x'_j, \{0\}_{x'_j}^{r^\ast}) \leq r^\ast(x'_j, \{1\}_{x'_j}^{r^\ast}) \leq \cdots \leq r^\ast(x'_j, \{J\}^{r^\ast}_{x'_j})
\end{equation}
We introduce a new notation $\xi_k'=x'_{\{k\}}$ corresponding to the $k$-th ordered adversarial input. For instance, if we have an ordered list $\{r^*(x'_2,2), r^*(x'_0, 0), r^*(x'_1,1)\}$, using the notation we have $\{r^*(\xi_0', \{0\}_{\xi_0'}^{r^\ast}), r^*(\xi_1', \{1\}_{\xi_1'}^{r^\ast}), r^*(\xi_2', \{2\}_{\xi_2'}^{r^\ast}) \}$.  

% \begin{equation}
%     \{k\}_{\xi_k'}^{r^\ast} = \{k\}_{x}
% \end{equation}
% with .  

We define a conditional risk $\mathcal{C}_{\widetilde{\Phi}_{01}^{\rho,u,j}}$  parameterized by the probability \( p_j \in \Delta^{|\mathcal{A}|} \) along with its optimum:
\begin{equation}
\begin{aligned}
    \mathcal{C}_{\widetilde{\Phi}_{01}^{\rho,u,j}}(r, x) & = \sum_{j \in \mathcal{A}} p_j \widetilde{\Phi}_{01}^{\rho,u,j}(r, x, j) \\
    \mathcal{C}^\ast_{\widetilde{\Phi}_{01}^{\rho,u,j}}(\mathcal{R}, x) & = \inf_{r \in \mathcal{R}} \sum_{j \in \mathcal{A}} p_j \widetilde{\Phi}_{01}^{\rho,u,j}(r, x, j)
\end{aligned}
\end{equation}

The optimum \( \mathcal{C}^\ast_{\widetilde{\Phi}_{01}^{\rho,u,j}} \) is challenging to characterize directly. To address this, we instead derive an upper bound by analyzing \( \mathcal{C}_{\widetilde{\Phi}_{01}^{\rho,u,j}}(r^\ast, x) \). In what follows, the mapping from \( j \) to \( i \) is defined based on the rank of \( p(x, j) \) within the sorted list \( \{p_{[i]}(x)\} \).
\begin{equation}
    \begin{aligned}
        \mc{C}^\ast_{\widetilde{\Phi}_{01}^{\rho,u,j}}(\mc{R}, x) & \leq  \mc{C}_{\widetilde{\Phi}_{01}^{\rho,u,j}}(r^\ast, x) \\
     &= \sum_{j \in \mathcal{A}} p(x, j) \sup_{x'_j \in B_p(x, \gamma)} \Psi^u \Bigg( \sum_{\substack{j' \in \mathcal{A} \\ j' \neq j}} \Psi_\rho\Big( r^*(x'_j, j) - r^*(x'_j, j') \Big)\Bigg) \\
     & = \sum_{i=0}^J \sup_{\xi_i' \in B_p(x,\gamma)} p(x,\{i\}_{\xi_i'}^{r^\ast}) \Psi^u \Bigg(\sum_{j=0}^{i-1} \Psi_\rho \Big(r^\ast(\xi_i', \{i\}^{r^\ast}_{\xi_i'}) - r^\ast(\xi'_i, \{j\}^{r^\ast}_{\xi_i'})\Big)  \\
     & \quad \quad \quad + \sum_{j=i+1}^{J} \Psi_\rho \Big(r^\ast(\xi_i', \{i\}^{r^\ast}_{\xi_i'}) - r^\ast(\xi'_i, \{j\}^{r^\ast}_{\xi_i'})\Big) \Bigg)  \\
     & = \sum_{i=0}^J \sup_{\xi_i' \in B_p(x,\gamma)} p(x,\{i\}_{\xi_i'}^{r^\ast}) \Psi^u \Bigg(\sum_{j=0}^{i-1} \Psi_\rho \Big(r^\ast(\xi_i', \{i\}^{r^\ast}_{\xi_i'}) - r^\ast(\xi'_i, \{j\}^{r^\ast}_{\xi_i'})\Big) + J-i\Bigg) \quad \text{($\Psi_\rho(t)=1,  \forall t\leq 0$)} \\
     & = \sum_{i=0}^J \sup_{\xi_i' \in B_p(x,\gamma)} p(x,\{i\}_{\xi_i'}^{r^\ast}) \Psi^u(J-i) \quad \text{($\Psi_\rho(v)=0, \forall v\geq \rho$ and $\inf_{x'_j \in B_p(x,\gamma)}|r^*(x'_j, q) - r^*(x'_j, q')| \geq \rho$)} \\
     & = \sum_{i=0}^J p_{[i]}(x)\Psi^u(J-i) \quad \text{($r^\ast$ and $p(x)$ same ordering of $j\in\mc{A}$)}
    \end{aligned}
\end{equation}

Then, assuming $\overline{\mc{R}}_\gamma(x)\not=\emptyset$ and $\mc{R}$ symmetric, we have:
\begin{equation}
    \begin{aligned}
    \Delta \mc{C}_{\widetilde{\Phi}_{01}^{\rho,u,j}}(r,x) & = \mc{C}_{\widetilde{\Phi}_{01}^{\rho,u,j}}(r,x) -  \mc{C}^\ast_{\widetilde{\Phi}_{01}^{\rho,u,j}}(\mc{R}, x) \geq \mc{C}_{\widetilde{\Phi}_{01}^{\rho,u,j}}(r,x) -  \mc{C}_{\widetilde{\Phi}_{01}^{\rho,u,j}}(r^\ast, x) \\
    & \geq \sum_{i=0}^J \sup_{\xi_i' \in B_p(x,\gamma)} p(x,\{i\}_{\xi_i'}^{r}) \Psi^u\Bigg(\sum_{j=0}^{i-1} \Psi_\rho \Big(r(\xi_i', \{i\}_{\xi_i'}) - r(\xi'_i, \{j\}_{\xi_i'})\Big) + J-i\Bigg) - \Big(\sum_{i=0}^J p_{[i]}(x)\Psi^u(J-i)\Big) \\
    \end{aligned}
\end{equation}
Then, for $\Psi_\rho$ non negative, $\Psi_\rho(v)=1$ for $v\leq0$,  and $\Psi^u$ non-decreasing, we have that:
\begin{equation}
\begin{aligned}
     \Delta \mc{C}_{\widetilde{\Phi}_{01}^{\rho,u,j}}(r,x)   &\geq \Psi^u (1)p(x, r(x)) 1_{r \notin \overline{\mc{R}}_\gamma(x)} + \sum_{i=0}^J  \sup_{\xi_i' \in B_p(x,\gamma)} \mspace{-20mu} p(x, \{i\}^r_{\xi_i'}) \Psi^u (J - i) - \Big(\sum_{i=0}^J p_{[i]}(x)\Psi^u(J-i)\Big)  \\
     & \geq \Psi^u(1)p(x, r(x)) 1_{r \notin \overline{\mc{R}}_\gamma(x)} - \sum_{i=0}^J  p_{[i]}(x)\Psi^u(J-i) + \sum_{i=0}^J p(x, \{i\}^r_x) \Psi^u (J-i) \quad (\text{sup}_{\xi_i' \in B_p(x,\gamma)} p(x, \{i\}^r_{\xi_i'}) \geq p(x, \{i\}^r_x)) \notag \\
    &= \Psi^u(1)p(x, r(x)) 1_{r \notin \overline{\mc{R}}_\gamma(x)} + \Psi^u(1) \Bigg(\max_{j \in \mathcal{A}} p(x, j) - p(x, r(x))\Bigg) + 
\begin{bmatrix}
    \Psi^u(1) \\
    \Psi^u(1) \\
    \Psi^u(2) \\
    \vdots \\
    \Psi^u(J)
\end{bmatrix}
\cdot
\begin{bmatrix}
    p(x, \{J\}^r_x) \\
    p(x, \{J-1\}^r_x) \\
    p(x, \{J-2\}^r_x) \\
    \vdots \\
    p(x, \{0\}^r_x)
\end{bmatrix}
 \\
 & \quad -
\begin{bmatrix}
    \Psi^u(1) \\
    \Psi^u(1) \\
    \Psi^u(2) \\
    \vdots \\
    \Psi^u(J)
\end{bmatrix}
\cdot
\begin{bmatrix}
    p_{[J]}(x) \\
    p_{[J-1]}(x) \\
    p_{[J-2]}(x) \\
    \vdots \\
    p_{[0]}(x)
\end{bmatrix}
\end{aligned}
\end{equation}

Rearranging terms for $\Psi^u(1)\leq \Psi^u(1) \leq \Psi^u(2)\leq \cdots \leq \Psi^u(J)$ and similarly for probabilities $p_{[J]}(x)\geq \cdots\geq p_{[0]}(x)$, leads to:
\begin{equation}
    \begin{aligned}
   \Delta \mc{C}_{\widetilde{\Phi}_{01}^{\rho,u,j}}(r,x) &\geq \Psi^u(1) p(x, r(x)) 1_{r \notin \overline{\mc{R}}_\gamma(x)} + \Psi^u(1) \Bigg(\max_{j \in \mathcal{A}} p(x, j) - p(x, r(x)) \Bigg) \\
    &= \Psi^u(1) \Bigg(\max_{j \in \mathcal{A}} p(x, j) - p(x, r(x)) 1_{r \in \overline{\mc{R}}_\gamma(x)}\Bigg)
    \end{aligned}
\end{equation}


for any $r\in\mc{R}$, we have:

\begin{align}
    \Delta \mc{C}_{\widetilde{\ell}_{01}^j}(r, x) &= \mc{C}_{\widetilde{\ell}_{01}^j}(r, x) - \mc{C}_{\widetilde{\ell}_{01}^j}^B(\mc{R}, x) \notag \\
    &= \sum_{j \in \mathcal{A}} p(x, j) \sup_{x_j' \in B_p(x,\gamma)} 1_{\rho_r(x'_j, j) \leq 0} - \inf_{r \in \mathcal{R}} \sum_{j \in \mathcal{A}} p(x, j) \sup_{x_j' \in B_p(x,\gamma)} 1_{\rho_r(x'_j, j) \leq 0} \notag \\
    &= (1 - p(x, r(x))) 1_{r \in \overline{\mathcal{R}}_\gamma(x)} + 1_{r \notin \overline{\mathcal{R}}_\gamma(x)} - \inf_{r \in \mathcal{R}} \big[(1 - p(x, r(x))) 1_{r \in \overline{\mathcal{R}}_\gamma(x)} + 1_{r \notin \overline{\mathcal{R}}_\gamma(x)}\big] \notag \\
    &= (1 - p(x, r(x))) 1_{r \in \overline{\mathcal{R}}_\gamma(x)} + 1_{r \notin \overline{\mathcal{R}}_\gamma(x)} - \bigg(1 - \max_{j \in \mathcal{A}} p(x, j)\bigg) \quad (\mathcal{R} \text{ is symmetric and } \overline{\mathcal{R}}_\gamma(x) \neq \emptyset) \notag \\
    &= \max_{j \in \mathcal{A}} p(x, j) - p(x, r(x)) 1_{r \in \overline{\mathcal{R}}_\gamma(x)}
\end{align}

We therefore have proven that:
\begin{equation}
\begin{aligned}
  \Delta \mc{C}_{\widetilde{\ell}_{01}^j}(r,x) & \leq   \Psi^u(1) \Big(\Delta\mathcal{C}_{\widetilde{\Phi}_{01}^{\rho,u,j}}(r,x)\Big) \\
  \sum_{j\in\mc{A}} p_j \widetilde{\ell}_{01}^j(r,x,j) - \inf_{r\in\mc{R}} \sum_{j\in\mc{A}} p_j \widetilde{\ell}_{01}^j(r,x,j) &  \leq  \Psi^u(1)\Big( \sum_{j\in\mc{A}} p_j  \widetilde{\Phi}^{\rho,u,j}_{01}(r,x,j) - \inf_{r\in\mc{R}} \sum_{j\in\mc{A}} p_j  \widetilde{\Phi}^{\rho,u,j}_{01}(r,x,j)\Big)
\end{aligned}
\end{equation}
\end{proof}


\subsection{Proof Theorem \ref{theo:consistency}}
\consistency* \label{proof:consistency}
\begin{proof}
Using Lemma \ref{lemma:deferralmargin}, we have:
\begin{equation}
\widetilde{\Phi}^{\rho, u}_{\text{def}}(r, g,m,z) = \sum_{j=0}^J \tau_j(g(x),m(x),z)  \widetilde{\Phi}^{\rho, j}_{01}(r,x, j) 
\end{equation}
We define several important notations. For a quantity $\omega \in \mb{R}$, we note $\overline{\omega}(g(x),x) = \mb{E}_{y,t|x}[\omega(g,z=(x,y,t))]$, an optimum $\omega^\ast(z)=\inf_{g\in\mc{G}}[\omega(g,z)]$, and the combination $\overline{w}^\ast(x) = \inf_{g\in\mc{G}}\mb{E}_{y,t|x}[w(g,z)]$:
\begin{equation}
   c_j^\ast(m_j(x),z) =  \begin{cases}
      c_0^\ast(z) = \inf_{g\in\mc{G}}[c_0(g(x),z)] & \text{if } j=0\\
      c_j(m_j(x),z) & \text{otherwise}
    \end{cases}
\end{equation}
Referring to (\ref{eq:tau}), we have:
\begin{equation}
   \tau_j^\ast(m(x),z) =  \begin{cases}
      \tau_0(m(x),z) = \sum_{k=1}^Jc_k(m_k,z) & \text{if } j=0\\
      \inf_{g\in\mc{G}}[\tau_j(g(x),m(x),z)] = c_0^\ast(z) + \sum_{k=1}^J c_k(m_k(x),z)1_{k\not=j} & \text{otherwise}
    \end{cases}
\end{equation}

Next, we define the conditional risk $\mc{C}_{\widetilde{\ell}_{\text{def}}}$ associated to the adversarial true deferral loss. 
\begin{equation}
    \begin{aligned}
        \mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x) & =  \mb{E}_{y,t|x}\Bigg[ \sum_{j=0}^J \tau_j(g(x),m(x),z)\widetilde{\ell}_{01}^j(r,x,j) + (1-J)\sum_{j=0}^J c_j(g(x),m_j(x),z) \Bigg] \\
        & = \sum_{j=0}^J \overline{\tau}_j(g(x),m(x),x)\widetilde{\ell}_{01}^j(r,x,j) + (1-J)\sum_{j=0}^J \overline{c}_j(g(x), m_j(x),x)
    \end{aligned}
\end{equation}
Now, we assume $r\in\mc{R}$ symmetric and define the space $\overline{\mc{R}}_{\gamma}(x) = \{r\in\mc{R}: \inf_{x^\prime \in B_p(x,\gamma)}\rho_r(x^\prime, r(x))>0\}$. Assuming $\overline{\mc{R}}_{\gamma}(x) \not= \emptyset$, it follows:
\begin{equation}
   \mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x) = \sum_{j=0}^J \Big(\overline{\tau}_j(g(x),m(x),x)[1_{r(x)\not=j}1_{r\in\overline{\mc{R}}_{\gamma}(x)} + 1_{r\not\in\overline{\mc{R}}_{\gamma}(x)}]\Big) + (1-J)\sum_{j=0}^J \overline{c}_j(g(x), m_j(x),x)
\end{equation}
Intuitively, if $r\not\in\mc{R}_{\gamma}(x)$, this means that there is no $r$ that correctly classifies $x^\prime\in B_p(x,\gamma)$ inducing an error of $1$. It follows at the optimum:    
\begin{equation}\label{eq:conditional}
    \begin{aligned}
        \mc{C}_{\widetilde{\ell}_{\text{def}}}^B(\mc{R}, \mc{G},x) & = \inf_{g\in\mc{G},r\in\mc{R}}\Big[\sum_{j=0}^J \Big(\overline{\tau}_j(g(x),m(x),x)[1_{r(x)\not=j}1_{r\in\overline{\mc{R}}_{\gamma}(x)} + 1_{r\not\in\overline{\mc{R}}_{\gamma}(x)}]\Big) + (1-J)\sum_{j=0}^J \overline{c}_j(g(x), m_j(x),x)\Big] \\
        & = \inf_{r\in\mc{R}}\Big[\sum_{j=0}^J \Big(\overline{\tau}_j^\ast(m(x),x)[1_{r(x)\not=j}1_{r\in\overline{\mc{R}}_{\gamma}(x)} + 1_{r\not\in\overline{\mc{R}}_{\gamma}(x)}]\Big)\Big] + (1-J)\sum_{j=0}^J \overline{c}^\ast_j(m_j(x),x)\\
        & =  \inf_{r\in\mc{R}}\sum_{j=0}^J \Big(\overline{\tau}_j^\ast(m(x),x)1_{r(x)\not=j}\Big) + (1-J)\sum_{j=0}^J \overline{c}^\ast_j(m_j(x),x)  \quad \text{($\overline{\mc{R}}_{\gamma}(x)\not=\varnothing$, then $\exists r \in \overline{\mc{R}}_{\gamma}(x)$)} \\
        & = \sum_{j=0}^J \overline{\tau}_j^\ast(m(x),x)(1-\sup_{r\in\mc{R}}1_{r(x)=j}) + (1-J)\sum_{j=0}^J \overline{c}^\ast_j(m_j(x),x)\\
        & = \sum_{j=0}^J \overline{\tau}_j^\ast(m(x),x) - \max_{j\in\mc{A}}\overline{\tau}_j^\ast(m(x),x) + (1-J)\sum_{j=0}^J \overline{c}^\ast_j(m_j(x),x)
        % & = \min_{j\in\mc{A}}\overline{c}_j^\ast(m_j(x),x) \quad \text{(with some manipulation c.f below)}
    \end{aligned}
\end{equation}
We can still work on making the last expression simpler: 
\begin{equation} \label{eq:4}
    \begin{aligned}
\sum_{j=0}^J\overline{\tau}_j^\ast(m(x),x) & = \sum_{j=1}^J\overline{c}_j(m_j(x),x) + \sum_{j=1}^J\Big(\overline{c}_0^\ast(x) + \sum_{k=1}^J \overline{c}_k(m_k(x),x) 1_{k\not=j}\Big) \\
& = J\overline{c}_0^\ast(x) + \sum_{j=1}^J\Big(\overline{c}_j(m_j(x),x) + \sum_{k=1}^J \overline{c}_k(m_k(x),x) 1_{k\not=j} \Big) \\
& = J\overline{c}_0^\ast(x) + \sum_{j=1}^J\Big(\overline{c}_j(m_j(x),x) + \sum_{k=1}^J \overline{c}_k(m_k(x),x) (1-1_{k=j}) \Big)  \\
& = J\overline{c}_0^\ast(x) + \sum_{j=1}^J\sum_{k=1}^J\overline{c}_k(m_k(x),x) \\
& = J\Big(\overline{c}_0^\ast(x) +\sum_{j=1}^J \overline{c}_j(m_j(x),x)\Big)
\end{aligned}
\end{equation}
Then, reinjecting (\ref{eq:4}) in (\ref{eq:conditional}) gives:
\begin{equation}
    \begin{aligned}
        \mc{C}_{\widetilde{\ell}_{\text{def}}}^B(\mc{R}, \mc{G},x) & = \sum_{j=0}^J\overline{c}_j^\ast(m_j(x),x) - \max_{j\in\mc{A}}\overline{\tau}_j^\ast (m(x),x) 
    \end{aligned}
\end{equation}
if $j=0$: 
\begin{equation}
    \begin{aligned}
        \mc{C}_{\widetilde{\ell}_{\text{def}}}^B(\mc{R}, \mc{G},x) & = \sum_{j=0}^J\overline{c}_j^\ast(m_j(x),x) - \overline{\tau}_0(m(x),x)  \\
        &= \sum_{j=0}^J\overline{c}_j^\ast(m_j(x),x) - \sum_{j=1}^J \overline{c}_j(m_j(x),x) \\
        & = \overline{c}^\ast_0(x)
    \end{aligned}
\end{equation}

if $j\not=0$:
\begin{equation}
    \begin{aligned}
        \mc{C}_{\widetilde{\ell}_{\text{def}}}^B(\mc{R}, \mc{G},x) & = \sum_{j=0}^J\overline{c}_j^\ast(m_j(x),x) - \overline{\tau}_{j>0}^\ast(m(x),x) \\
        & =\sum_{j=0}^J\overline{c}_j^\ast(m_j(x),x) - \Big( \overline{c}_0^\ast(x) + \sum_{k=1}^J \overline{c}_k(m_k(x),x) 1_{k\not=1}\Big) \\
        & = \overline{c}_{j>0}(m_j(x),x)
    \end{aligned}
\end{equation}

Therefore, it can be reduced to:
\begin{equation}
    \mc{C}_{\widetilde{\ell}_{\text{def}}}^B(\mc{R}, \mc{G},x) = \min_{j\in\mc{A}}\overline{c}_j^\ast(m_j(x),x) = \min_{j\in\mc{A}}\Big\{ \overline{c}_0^\ast(x), \overline{c}_{j>0}(m_j(x),x)\Big\}
\end{equation}

We can write the calibration gap as $\Delta\mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x):= \mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x) - \mc{C}_{\widetilde{\ell}_{\text{def}}}^B(\mc{R}, \mc{G},x)\geq0$, it follows:
\begin{equation}\label{eq:AB}
    \begin{aligned}
        \Delta\mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x) & = \mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x) - \min_{j\in\mc{A}}\overline{c}_j^\ast(m_j(x),x) \\
        & = \underbrace{\mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x) - \min_{j\in\mc{A}}\overline{c}_j(g(x), m_j(x),x)}_{A}  + \underbrace{\Big(\min_{j\in\mc{A}}\overline{c}_j(g(x), m_j(x),x) - \min_{j\in\mc{A}}\overline{c}_j^\ast(m_j(x),x) \Big)}_{B}
    \end{aligned}
\end{equation}
% Note that: $\min_{j\in\mc{A}}\overline{c}_j^\ast(m_j(x),x) = \inf_{g\in\mc{G}}\Big(\min_{j\in\mc{A}}\overline{c}_j(g(x), m_j(x),x)\Big) =\min\Big\{\overline{c}^\ast_0(x), \min_{j\in[J]}\overline{c}_j(m_j(x),x)\Big\}$. 

\paragraph{Term $B$:} Let's first focus on $B$. We can write the following inequality:
\begin{equation}
    B = \min_{j\in\mc{A}}\overline{c}_j(g(x), m_j(x),x) - \min_{j\in\mc{A}}\overline{c}^\ast_j(m_j(x),x) \leq \overline{c}_0(g(x),x) - \overline{c}^\ast_0(x)
\end{equation}
Indeed, we have the following relationship:
\begin{enumerate}
    \item if $\overline{c}_0(g(x),x) < \min_{j\in[J]}\overline{c}_{j}(m_j(x),x) \implies B = \overline{c}_0(g(x),x) - \overline{c}^\ast_0(x)$
    \item if $\overline{c}_0(g(x),x) > \min_{j\in[J]}\overline{c}_j(m_j(x),x)  \text{ and } \overline{c}^\ast_0(x) \leq \min_{j\in[J]}\overline{c}_{j}(m_j(x),x) \\
    \quad \quad \quad \implies B = \min_{j\in[J]}\overline{c}_{j}(m_j(x),x) - \overline{c}^\ast_0(x)\leq \overline{c}_0(g(x),x) - \overline{c}^\ast_0(x)$
\end{enumerate}
\paragraph{Term $A$:} Then using the term $A$:
\begin{equation}
    \begin{aligned}
        A & = \mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x) - \min_{j\in\mc{A}}\overline{c}_j(m_j(x),x) \\
        & = \mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x) - \inf_{r\in\mc{R}} \mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x) \\
        & = \sum_{j=0}^J \Big(\overline{\tau}_j(g(x),m(x),x)\widetilde{\ell}_{01}^j(r,x,j)\Big) - \inf_{r\in\mc{R}}\sum_{j=0}^J \Big(\overline{\tau}_j(g(x),m(x),x)\widetilde{\ell}_{01}^j(r,x,j)\Big)
    \end{aligned}
\end{equation}
Now, we introduce a change of variables to define a probability distribution \( p = (p_0, \cdots, p_j) \in \Delta^{|\mathcal{A}|} \), accounting for the fact that \( \tau_j \) does not inherently represent probabilities. Consequently, for each \( j \in \mathcal{A} \), we obtain the following expression:
\begin{equation}
    p_j = \frac{\overline{\tau}_j(g(x),m(x),x)}{\sum_{j=0}^J \overline{\tau}_j(g(x),m(x),x)}  = \frac{\overline{\tau}_j}{\|\boldsymbol{\tau}\|_1} \quad \text{(for $\boldsymbol{\tau}=\{\tau_j\geq 0\}_{j\in\mc{A}}$)} 
\end{equation}


We then, have:
\begin{equation}
    A = \|\boldsymbol{\tau}\|_1 \Bigg(\sum_{j=0}^J \Big(p_j\widetilde{\ell}_{01}^j(r,x,j)\Big) - \inf_{r\in\mc{R}}\sum_{j=0}^J \Big(p_j\widetilde{\ell}_{01}^j(r,x,j)\Big)\Bigg)
\end{equation}
Then, using Lemma \ref{lemma:rconsistency}, it leads to:
\begin{equation}
    \begin{aligned}
        A & \leq \|\boldsymbol{\tau}\|_1 \Psi^u(1) \Bigg[\sum_{j=0}^J \Big(p_j\widetilde{\Phi}^{\rho,u,j}_{01}(r,x,j)\Big) - \inf_{r\in\mc{R}}\sum_{j=0}^J \Big(p_j\widetilde{\Phi}^{\rho,u,j}_{01}(r,x,j)\Big)\Bigg] \\
        & = \|\boldsymbol{\tau}\|_1 \Psi^u(1)\frac{1}{\|\boldsymbol{\tau}\|_1} \Bigg[\sum_{j=0}^J \Big(\overline{\tau}_j(g(x),m(x),x)\widetilde{\Phi}^{\rho,u,j}_{01}(r,x,j)\Big) - \inf_{r\in\mc{R}}\sum_{j=0}^J \Big(\overline{\tau}_j(g(x),m(x),x)\widetilde{\Phi}^{\rho,u,j}_{01}(r,x,j)\Big)\Bigg] \\
        & =  \Psi^u(1) \Bigg[\sum_{j=0}^J \Big(\overline{\tau}_j(g(x),m(x),x)\widetilde{\Phi}^{\rho,u,j}_{01}(r,x,j)\Big) - \inf_{r\in\mc{R}}\sum_{j=0}^J \Big(\overline{\tau}_j(g(x),m(x),x)\widetilde{\Phi}^{\rho,u,j}_{01}(r,x,j)\Big)\Bigg] \\
        & = \Psi^u(1) \Big[\mc{C}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(r,x) - \mc{C}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}^\ast(\mc{R},x)\Big]
    \end{aligned}
\end{equation}
Then, adding $B$ leads to:
\begin{equation}
    \begin{aligned}
        \Delta\mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x) & = A + B \quad \text{(using Eq. \ref{eq:AB}}) \\
        & \leq \Psi^u(1) \Big[\mc{C}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(r,x) - \mc{C}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}^\ast(\mc{R},x)\Big] + \overline{c}_0(g(x),x) - \overline{c}^\ast_0(x) \\
    \end{aligned}
\end{equation}
By construction, we have $\overline{c}_0(g(x),x)=\mb{E}_{y,t|x}[c_0(g(x),z)]$ with $c_0(g(x),z) =\psi(g(x), z)$ and $\overline{c}^\ast_0(x)=\inf_{g\in\mc{G}}\mb{E}_{y,t|x}[c_0(g(x),z)]$. Therefore, we can write for $g\in\mc{G}$ and the cost $c_0$:
\begin{equation}
    \Delta\mc{C}_{c_0}(g,x) = \overline{c}_0(g(x),x) - \overline{c}^\ast_0(x)
\end{equation}
Then,
\begin{equation}
    \begin{aligned}
        \Delta\mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x) & \leq \Psi^u(1) \Big[\mc{C}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(r,x) - \mc{C}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}^\ast(\mc{R},x)\Big] + \Delta\mc{C}_{c_0}(g(x),x) \\
        & = \Psi^u(1) \Big[\Delta\mc{C}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(r,x) \Big] + \Delta\mc{C}_{c_0}(g,x) \\
    \end{aligned}
\end{equation}
Therefore, by definition:
\begin{equation}\label{eq:proof}
    \begin{aligned}
        \mathcal{E}_{\widetilde{\ell}_{\text{def}}}(r,g)  - \mathcal{E}^*_{\widetilde{\ell}_{\text{def}}}(\mc{R}, \mathcal{G}) + \mathcal{U}_{\widetilde{\ell}_{\text{def}}}(\mc{R}, \mathcal{G}) & = \mb{E}_x[\Delta\mc{C}_{\widetilde{\ell}_{\text{def}}}(r,g,x)] \\
        & \leq \Psi^u(1) \mb{E}_x\Big[\Delta\mc{C}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(r,x) \Big] + \mb{E}_x\Big[\Delta\mc{C}_{c_0}(g(x),x)\Big] \\
        & = \Psi^u(1)\Big(\mathcal{E}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(r) - \mathcal{E}^*_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(\mc{R}) + \mathcal{U}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(\mc{R})\Big) \\
        & \quad + \mb{E}_x\Big[\Delta\mc{C}_{c_0}(g(x),x)\Big] \\
        & = \Psi^u(1)\Big(\mathcal{E}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(r) - \mathcal{E}^*_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(\mc{R}) + \mathcal{U}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(\mc{R})\Big) \\
        & \quad + \mb{E}_x[\overline{c}_0(g(x),x)] - \mb{E}_x[\overline{c}^\ast_0(x)] \\
        & = \Psi^u(1)\Big(\mathcal{E}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(r) - \mathcal{E}^*_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(\mc{R}) + \mathcal{U}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(\mc{R})\Big) \\
        & \quad + \Delta\mathcal{E}_{c_0}(g)
    \end{aligned}
\end{equation}
where \( \Delta\mathcal{E}_{c_0}(g) = \mathcal{E}_{c_0}(g) - \mathcal{E}_{c_0}^B(\mathcal{G}) + \mathcal{U}_{c_0}(\mathcal{G}) \).

In the special case of the log-softmax ($u=1$), we have that $\Psi^u(1)=\log(2)$. 

% For a multi-classification surrogate $\phi_{01}$ that admits a $\mc{H}$-consistency bounds we have by \citet{montreuil2024twostagelearningtodefermultitasklearning} for $g=(h,f)$:

% \begin{equation*}
%     \begin{aligned}
%      \mb{E}_x\Big[\Delta\mc{C}_{c_0}(g(x),x)\Big] = \mathcal{E}_{c_0}(h,f) - \mathcal{E}^B_{c_0}(\mathcal{H}, \mathcal{F}) + \mathcal{U}_{c_0}(\mathcal{H}, \mathcal{F}) & \leq \Gamma \Big(\mathcal{E}_{\phi_{01}}(h) - \mathcal{E}^*_{\phi_{01}}(\mathcal{H}) + \mathcal{U}_{\phi_{01}}(\mathcal{H})\Big) \\
%      & + \mathcal{E}_{\ell_{\text{\text{reg}}}}(f) -  \mathcal{E}^\ast_{\ell_{\text{\text{reg}}}}(\mathcal{F}) + \mathcal{U}_{\ell_{\text{\text{reg}}}}(\mathcal{F})
%     \end{aligned}
% \end{equation*}

% When the right-hand side vanishes, the left-hand side is bounded above by zero. Since the minimization of $\phi_{01}$ and $\ell_{\text{\text{reg}}}$ is done independently, it is straightforward to demonstrate that this implies that $\mathcal{E}_{c_0}(h, f) -  \mathcal{E}^B_{c_0}(\mathcal{H}, \mc{F}) + \mathcal{U}_{c_0}(\mathcal{H}, \mc{F})$ vanishes, implying both $(\mc{H},\mc{F})$ and Bayes-consistency.  

% Going back to inequality (\ref{eq:proof}), we have shown that the surrogate is consistent when using the surrogate $\widetilde{\Phi}^{\rho,u,j}_{01}$. However, this loss is non-convex and then, harder to optimize. Using the inequality $\widetilde{\Phi}^{\rho,u,j}_{01}\leq\widetilde{\Phi}^{\text{smth}, u}_{01}$, it leads to the desired theorem using inequality (\ref{eq:surrogate}): 

% \begin{equation}
%     \begin{aligned}
%         \mathcal{E}_{\widetilde{\ell}_{\text{def}}}(r, g)  - \mathcal{E}^*_{\widetilde{\ell}_{\text{def}}}(\mc{R}, \mathcal{G}) + \mathcal{U}_{\widetilde{\ell}_{\text{def}}}(\mc{R}, \mathcal{G})
%         &  \leq \Psi^u(1)\Big(\mathcal{E}_{\widetilde{\Phi}^{\text{smth}, u}_{\text{def}}}(r, g) - \mathcal{E}^*_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(\mc{R}, \mathcal{G})  + \mathcal{U}_{\widetilde{\Phi}^{\rho, u}_{\text{def}}}(\mc{R}, \mathcal{G})\Big) + \Delta\mc{E}_{c_0}(g)
%     \end{aligned}
% \end{equation}

% with $ \Delta\mc{E}_{c_0}(g) = \mathcal{E}_{c_0}(g) -  \mathcal{E}^B_{c_0}(\mathcal{G}) + \mathcal{U}_{c_0}(\mathcal{G})$


\end{proof}




\section{Experiments details}\label{appendix:details}
We present empirical results comparing the performance of state-of-the-art Two-Stage Learning-to-Defer frameworks \citep{mao2023twostage, mao2024regressionmultiexpertdeferral, montreuil2024twostagelearningtodefermultitasklearning} with our robust \name{} algorithm. To the best of our knowledge, this is the first study to address adversarial robustness within the context of Learning-to-Defer. 

All baselines use the log-softmax surrogate for $\Phi_{01}$ with $\Psi^{u=1}(v)=\log(1+v)$ and $\Psi_e(v)=\exp(-v)$. Adversarial attacks and supremum evaluations over the perturbation region \( B_p(x, \gamma) \) are evaluated using Projected Gradient Descent \citep{Madry2017TowardsDL}. For each experiment, we report the mean and standard deviation over four independent trials to account for variability in results. Experiments are conducted on one NVIDIA H100 GPU. Additionally, we make our scripts publicly available.


\subsection{Multiclass Classification Task}
\label{exp_appendix:class}
\paragraph{Experts:} We assigned categories to three distinct experts: expert M$_1$ is more likely to be correct on 58 categories, expert M$_2$ on 47 categories, and expert M$_3$ on 5 categories. To simulate a realistic scenario, we allow for overlapping expertise, meaning that for some $x \in \mc{X}$, multiple experts can provide correct predictions. On assigned categories, an expert has a probability $p=0.94$ to be correct, while following a uniform probability if the category is not assigned.  

Agent costs are defined as \( c_0(h(x), y) = \ell_{01}(h(x), y) \) for the model and \( c_{j > 0}(m_j^h(x), y) = \ell_{01}(m_j^h(x), y) \), consistent with \citep{mozannar2021consistent, Mozannar2023WhoSP, Verma2022LearningTD, Cao_Mozannar_Feng_Wei_An_2023, mao2023twostage}.  We report respective accuracies of experts in Table \ref{table:agent_cifar}.

\paragraph{Model:} We train the classifier offline using a ResNet-4 architecture~\citep{he2015deepresiduallearningimage} for 100 epochs with the Adam optimizer~\citep{kingma2017adammethodstochasticoptimization}, a learning rate of $0.1$, and a batch size of $64$. The checkpoint corresponding to the lowest empirical risk on the validation set is selected. Corresponding performance is indicated in Table \ref{table:agent_cifar}. 

\begin{table}[ht]
\centering\resizebox{0.5\textwidth}{!}{ 
\begin{tabular}{@{}ccccc@{}}
\toprule
 & Model & Expert M$_1$ & Expert M$_2$ & Expert M$_3$  \\
\midrule
Accuracy &  $61.0$ & $53.9$ & $45.1$ & $5.8$ \\
\bottomrule
\end{tabular}}
\caption{Agent accuracies on the CIFAR-100 validation set. Since the training and validation sets are pre-determined in this dataset, the agents' knowledge remains fixed throughout the evaluation.}
\label{table:agent_cifar}
\end{table}

\paragraph{Baseline \citep{mao2023twostage}:} We train a rejector using a ResNet-4 \citep{he2015deepresiduallearningimage} architecture for $500$ epochs, a learning rate of $0.005$, a cosine scheduler, Adam optimizer \citep{kingma2017adammethodstochasticoptimization}, and a batch size of $2048$. We report performance of the checkpoints corresponding to the lower empirical risk on the validation set. 

\paragraph{\name{}:} We train a rejector using the ResNet-4 architecture~\citep{he2015deepresiduallearningimage} for 1500 epochs with a learning rate of $0.005$, a cosine scheduler, the Adam optimizer~\citep{kingma2017adammethodstochasticoptimization} with L2 weight decay of $10^{-4}$ acting as regularizer, and a batch size of $2048$. The hyperparameters are set to $\rho = 1$ and $\nu = 0.01$. The supremum component from the adversarial inputs is estimated using PGD40~\citep{Madry2017TowardsDL} with $\epsilon = 8/255$, the $\ell_\infty$ norm, and a step size of $\epsilon / 40$, following the approach in~\citep{mao2023crossentropylossfunctionstheoretical, Grounded}.

 
\begin{table}[ht]
\centering\resizebox{0.8\textwidth}{!}{ 
\begin{tabular}{@{}ccccccc@{}}
\toprule
Baseline & Clean & Untarg. & Targ. Model & Targ. M$_1$ & Targ. M$_2$ & Targ. M$_3$  \\
\midrule
\citet{mao2023twostage} &  $72.8\pm 0.4$ & $17.2\pm0.2$ & $61.1\pm 0.1$ & $54.4\pm 0.1$   &$45.4\pm 0.1$ & $13.4\pm 0.1$ \\
\midrule
Our &  $67.0\pm 0.4$ & $49.8\pm0.3$ & $64.8\pm0.2$ & $62.4\pm0.3$  &   $62.1\pm0.2$ &  $64.8\pm0.3$   \\
\bottomrule
\end{tabular}}
\caption{Comparison of accuracy results between the proposed \name{} and the baseline \citep{mao2023twostage} on the CIFAR-100 validation set, including clean and adversarial scenarios.}
\end{table}

\subsection{Regression Task}\label{exp_appendix:reg}
\paragraph{Experts:} We train three experts offline with three layers MLPs (128, 64, 32), each specializing in a specific subset of the dataset based on a predefined localization criterion. The first expert M$_1$ trains on Southern California (latitude lower than 36), the second expert M$_2$ on Central California  (latitude between 36 and 38.5), and the last in Northern California (otherwise) representing a smaller area. MLPs are trained using a ReLU, an Adam optimizer \citep{kingma2017adammethodstochasticoptimization}, a learning rate of $0.001$, and $500$ epochs. Agent costs are defined as \( c_0(f(x), t) = \text{RMSE}(g(x), t) \) for the model and \( c_{j > 0}(m_j^f(x), t) = \text{RMSE}(m_j(x), t) \), consistent with \citep{mao2024regressionmultiexpertdeferral}.  We report respective RMSE of experts in Table \ref{agent:housing}.

\paragraph{Model:} We train a regressor using a two-layer MLP with hidden dimensions (64, 32) on the full training set. The model uses ReLU activations, the Adam optimizer~\citep{kingma2017adammethodstochasticoptimization}, a learning rate of $0.001$, and is trained for 500 epochs. We report performance of the checkpoints corresponding to the lower empirical risk on the validation set. The model performance is reported in Table~\ref{agent:housing}.

\begin{table}[ht]\label{agent:housing}
\centering\resizebox{0.5\textwidth}{!}{ 
\begin{tabular}{@{}ccccc@{}}
\toprule
 & Model & Expert M$_1$ & Expert M$_2$ & Expert M$_3$  \\
\midrule
RMSE &  $0.27\pm .01$ & $1.23\pm .02$ & $1.85\pm .02$ & $0.91\pm .01$ \\
\bottomrule
\end{tabular}}
\caption{Agent RMSE on the California Housing validation set ($20$\% of the dataset).}
\end{table}

\paragraph{Baseline \citep{mao2024regressionmultiexpertdeferral}:} We train a rejector using a MLP (8,16) for 100 epochs, a learning rate of $0.01$, a cosine scheduler, Adam optimizer \citep{kingma2017adammethodstochasticoptimization}, and a batch size of 8096. We report performance of the checkpoints corresponding to the lower empirical risk on the validation set.

\paragraph{\name{}:}  We train a rejector using a MLP (8,16) for 400 epochs, a learning rate of $0.01$, a cosine scheduler, Adam optimizer \citep{kingma2017adammethodstochasticoptimization} with L2 weight decay of $10^{-4}$ acting as regularizer, and a batch size of $8096$. The hyperparameters are set to $\rho = 1$ and $\nu = 0.05$. The supremum component from the adversarial inputs is estimated using PGD10~\citep{Madry2017TowardsDL} with $\epsilon$ equal to 25\% of the variance of dataset's features, the $\ell_\infty$ norm, and a step size of $\epsilon / 10$, following the approach in~\citep{mao2023crossentropylossfunctionstheoretical, Grounded}.

\begin{table}[ht]
\centering\resizebox{0.8\textwidth}{!}{ 
\begin{tabular}{@{}ccccccc@{}}
\toprule
Baseline & Clean & Untarg. & Targ. Model & Targ. M$_1$ & Targ. M$_2$ & Targ. M$_3$  \\
\midrule
\citet{mao2024regressionmultiexpertdeferral} &  $0.17 \pm 0.01$ & $0.29\pm0.3$ & $0.19 \pm 0.01$ & $0.40 \pm 0.02$ & $0.21 \pm 0.01$ & $0.41\pm 0.05$  \\
\midrule
Our &  $0.17\pm0.01$ & $0.17 \pm 0.01$ & $0.17 \pm 0.01$ & $0.18 \pm 0.01 $ & $0.18\pm 0.01 $ & $0.18\pm 0.01 $ \\
\bottomrule
\end{tabular}}
\caption{Performance comparison of \name{} with the baseline \citep{mao2024regressionmultiexpertdeferral} on the California Housing dataset. The table reports Root Mean Square Error (RMSE) under clean and adversarial scenarios.}
\end{table}

\subsection{Multi Task}\label{exp_appendix:multi}

\paragraph{Experts:} We train two specialized experts using a Faster R-CNN \cite{ren2016fasterrcnnrealtimeobject} architecture with a MobileNet \cite{howard2017mobilenetsefficientconvolutionalneural} backbone. The first expert, M$_1$, is trained on images containing \textit{animals}, while the second expert, M$_2$, is trained on images containing \textit{vehicles}. Both experts are trained using the Adam optimizer \citep{kingma2017adammethodstochasticoptimization} with a learning rate of $0.005$, a batch size of $128$, and trained for $50$ epochs. Agent costs are defined as \( c_0(g(x), z) = \text{mAP}(g(x), z) \) for the model and \( c_{j > 0}(m_j(x), z) = \text{mAP}(m_j(x), z) \), consistent with \citep{montreuil2024twostagelearningtodefermultitasklearning}.  We report respective mAP of experts in Table \ref{agent_pascal}.

\paragraph{Model:} We train an object detection model using a larger Faster R-CNN \citep{ren2016fasterrcnnrealtimeobject} with  ResNet-50 FPN \citep{he2015deepresiduallearningimage} backbone. We train this model with Adam optimizer \citep{kingma2017adammethodstochasticoptimization}, a learning rate of $0.005$, a batch size of $128$, and trained for $50$ epochs. We report performance of the checkpoints corresponding to the lower empirical risk on the validation set. The model performance is reported in Table~\ref{agent_pascal}.


\begin{table}[ht]\label{agent_pascal}
\begin{tabular}{@{}ccccc@{}}
\toprule
 & Model & Expert M$_1$ & Expert M$_2$   \\
\midrule
mAP &  39.5 & 17.2 & 20.0  \\
\bottomrule
\end{tabular}
\centering
\caption{Agents mAP Pascal VOC validation set. Since the training and validation sets are pre-determined in this dataset, the agents' knowledge remains fixed throughout the evaluation.}
\end{table}

\paragraph{Baseline \citep{montreuil2024twostagelearningtodefermultitasklearning}:} We train a rejector using a Faster R-CNN~\citep{ren2016fasterrcnnrealtimeobject} with a MobileNet backbone~\citep{howard2017mobilenetsefficientconvolutionalneural} and a classification head. We train this rejector for $70$ epochs, a learning rate $5e^{-4}$, a cosine scheduler, Adam optimizer \citep{kingma2017adammethodstochasticoptimization}, and a batch size of $256$. We report performance of the checkpoints corresponding to the lower empirical risk on the validation set. 

\paragraph{\name{}:} We train a rejector using a Faster R-CNN~\citep{ren2016fasterrcnnrealtimeobject} with a MobileNet backbone~\citep{howard2017mobilenetsefficientconvolutionalneural} and a classification head for 70 epochs with a learning rate of $0.001$, a cosine scheduler, the Adam optimizer~\citep{kingma2017adammethodstochasticoptimization} with L2 weight decay of $10^{-4}$ acting as regularizer, and a batch size of $64$. The hyperparameters are set to $\rho = 1$ and $\nu = 0.01$. The supremum component from the adversarial inputs is estimated using PGD20~\citep{Madry2017TowardsDL} with $\epsilon = 8/255$, the $\ell_\infty$ norm, and a step size of $\epsilon / 20$, following the approach in~\citep{mao2023crossentropylossfunctionstheoretical, Grounded}.



\begin{table}[H]
\centering\resizebox{0.7\textwidth}{!}{ 
\begin{tabular}{@{}cccccc@{}}
\toprule
Baseline & Clean  & Untarg. & Targ. Model & Targ. M$_1$ & Targ. M$_2$   \\
\midrule
\citet{montreuil2024twostagelearningtodefermultitasklearning} &  $44.4\pm0.4$ & $9.7 \pm 0.1$ & $39.5\pm0.1$ & $17.4\pm0.2$ & $20.4 \pm 0.2$ \\
\midrule
Our &  $43.9\pm 0.4$ & $39.0\pm0.3$ &  $39.5\pm0.1$ & $39.7\pm0.3$ &  $39.6\pm0.1$ \\
\bottomrule
\end{tabular}}
\caption{Performance comparison of \name{} with the baseline \citep{montreuil2024twostagelearningtodefermultitasklearning} on the Pascal VOC dataset. The table reports mean Average Precision (mAP) under clean and adversarial scenarios.}
\end{table}


\end{appendices}