\section{Related Works}
% Learning-to-Defer is a direct extension of Learning-from-Abstention, where a predictor can choose to abstain from making a decision when uncertain \citep{Chow_1970, cortes}.

% However, in Learning-to-Defer, instead of abstaining, the query is routed to the most accurate agent in the system.

\paragraph{Learning-to-Defer:}  
The first \textit{single-stage} L2D approach was introduced by \citet{madras2018predict}, training both the predictor and the rejector, which were built upon the framework established in \citet{cortes}. In a seminal work, \citet{mozannar2021consistent} proposed the first approach proven to be Bayes-consistent, ensuring optimal allocation. \citet{Verma2022LearningTD} presented an alternative formulation based on one-versus-all surrogates, also proven to be Bayes-consistent, and later extended to a broader family of losses by \citet{charusaie2022sample}. More recently, \citet{Cao_Mozannar_Feng_Wei_An_2023} proposed an asymmetric softmax surrogate to improve probability estimation between agents, addressing limitations in both \citet{mozannar2021consistent} and \citet{Verma2022LearningTD}. Furthermore, \citet{Mozannar2023WhoSP} demonstrated that the approaches from \citet{mozannar2021consistent, Verma2022LearningTD} are not realizable-\(\mc{H}\)-consistent, leading to suboptimal performance for some distributions. \citet{mao2024principledapproacheslearningdefer} generalized the work of \citet{mozannar2021consistent} proving both Bayes and \(\mc{H}\)-consistency, while \citet{mao2024realizablehconsistentbayesconsistentloss} extended it to realizable-\(\mc{H}\)-consistency. 

In the \textit{two-stage} setting, where agents are already trained offline, \citet{mao2023twostage} introduced the first classification approach that guarantees both Bayes-consistency and \( \mathcal{H} \)-consistency. This work was further extended by \citet{mao2024regressionmultiexpertdeferral}, who adapted the two-stage framework to regression tasks while maintaining these consistency guarantees. Additionally, \citet{montreuil2024twostagelearningtodefermultitasklearning} generalized the approach to multi-task learning. 

\paragraph{Adversarial Robustness:}
The robustness of neural networks against adversarial perturbations has been extensively studied, with foundational work highlighting their vulnerabilities \citep{Biggio_2013, szegedy2014intriguingpropertiesneuralnetworks, goodfellow2014explaining, Madry2017TowardsDL}. A key focus in recent research has been on developing consistency frameworks for formulating robust defenses. \citet{bao2021calibratedsurrogatelossesadversarially} proposed a Bayes-consistent surrogate loss tailored for adversarial training, which was further analyzed and extended in subsequent works \citep{meunier2022consistencyadversarialclassification, awasthi2021calibrationconsistencyadversarialsurrogate}. Beyond Bayes-consistency, $\mc{H}$-consistency has been explored to address robustness in diverse settings. Notably, \citet{Awasthi_Mao_Mohri_Zhong_2022_multi} derived $\mc{H}$-consistency bounds for several surrogate families, and \citet{mao2023crossentropylossfunctionstheoretical} conducted an in-depth analysis of the cross-entropy family. Building on these theoretical advancements, \citet{Grounded} introduced a smooth algorithm that leverages consistency guarantees to enhance robustness in adversarial settings. 

Our work builds upon recent advancements in consistency theory to further improve adversarial robustness in two-stage L2D.
