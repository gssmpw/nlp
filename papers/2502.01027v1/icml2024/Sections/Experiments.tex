\section{Experiments}
We evaluate the robustness of \name{} against state-of-the-art two-stage L2D frameworks across three tasks: classification, regression, and multi-task learning. Our experiments reveal that while existing baselines achieve slightly higher performance under clean conditions, they suffer from severe performance degradation under adversarial attacks. In contrast, \name{} consistently maintains high performance, demonstrating superior robustness to both untargeted and targeted attacks.  To the best of our knowledge, this is the first study to address adversarial robustness within the context of Learning-to-Defer. 



\subsection{Multiclass Classification Task}
We compare our robust \name{} formulation against the method introduced by \citet{mao2023twostage} on the CIFAR-100 dataset \citep{krizhevsky2009learning}.

\paragraph{Setting:} Categories were assigned to three experts with a correctness probability \( p = 0.94 \), while the remaining probability was uniformly distributed across the other categories, following the approach in \citep{mozannar2021consistent, Verma2022LearningTD, Cao_Mozannar_Feng_Wei_An_2023}. To further evaluate robustness, we introduced a weak expert  M\(_3 \), with only a few assigned categories, and assumed that the attacker is aware of this weakness. Agent costs are defined as \( c_0(h(x), y) = \ell_{01}(h(x), y) \) for the model and \( c_{j > 0}(m_j^h(x), y) = \ell_{01}(m_j^h(x), y) \), aligned with \citep{mozannar2021consistent, Mozannar2023WhoSP, Verma2022LearningTD, Cao_Mozannar_Feng_Wei_An_2023, mao2023twostage}.  Both the model and the rejector were implemented using ResNet-4 \citep{he2015deepresiduallearningimage}. The agents' performance, additional training details, and experimental results are provided in Appendix~\ref{exp_appendix:class}. 



\begin{table}[ht]\label{table:results_cifar}
\centering\resizebox{0.75\textwidth}{!}{ 
\begin{tabular}{@{}cccccc@{}}
\toprule
Baseline & Clean & Untarg. & Targ. M$_1$ & Targ. M$_2$ & Targ. M$_3$  \\
\midrule
\citet{mao2023twostage} &  $72.8\pm 0.4$ & $17.2\pm0.2$ & $54.4\pm 0.1$ & $45.4\pm 0.1$ & $13.4\pm 0.1$ \\
\midrule
Our &  $67.0\pm 0.4$ & $49.8\pm0.3$ & $62.4\pm0.3$  &  $62.1\pm0.2$ &  $64.8\pm0.3$   \\
\bottomrule
\end{tabular}}
\caption{Comparison of accuracy results between the proposed \name{} and the baseline \citep{mao2023twostage} on the CIFAR-100 validation set, including clean and adversarial scenarios.}
\end{table}
%clean 11148: https://wandb.ai/yannis98/cifar100_rejector_cluster_robust_v28_humans/runs/u5e66e97?nw=nwuseryannis98 
%robust 6038: https://wandb.ai/yannis98/cifar100_rejector_cluster_robust_v28_humans/runs/s0ndbqlc?nw=nwuseryannis98
\paragraph{Results:} The results in Table \ref{table:results_cifar} underscore the robustness of our proposed \name{} algorithm. While the baseline achieves a higher clean accuracy (72.8\% vs. 67.0\%), this comes at the cost of extreme vulnerability to adversarial attacks. In contrast, \name{} prioritizes robustness, significantly outperforming the baseline under adversarial conditions. Specifically, in the presence of untargeted attacks, \name{} retains an accuracy of 49.8\%, a 2.9 times improvement over the baseline's sharp decline to 17.2\%. Similarly, under targeted attacks aimed at the weak expert M$_3$, our method achieves 64.8\% accuracy, a stark contrast to the baseline’s 13.4\%, highlighting \name{}’s ability to counteract adversarial exploitation of weak experts. These findings validate the efficacy of \name{} in preserving performance across diverse attack strategies.

\subsection{Regression Task}
We evaluate the performance of \name{} against the method proposed by \citet{mao2024regressionmultiexpertdeferral} using the California Housing dataset involving median house price prediction \citep{KELLEYPACE1997291}.

\paragraph{Setting:} We train three experts, each implemented as an MLP, specializing in a specific subset of the dataset based on a predefined localization criterion. Among these, expert  M\(_3 \) is designed to specialize in a smaller region, resulting in comparatively weaker overall performance. Agent costs for regression are defined as \( c_0(f(x), t) = \text{RMSE}(f(x), t) \) for the model and \( c_{j > 0}(m_j^f(x), t) = \text{RMSE}(m_j^f(x), t) \), aligned with \citep{mao2024regressionmultiexpertdeferral}.  Both the model and the rejector are trained on the full dataset using MLPs. We provide detailed agent performance results, training procedures, and additional experimental details in Appendix~\ref{exp_appendix:reg}. 


\begin{table}[ht]\label{table:results_housing}
\centering\resizebox{0.75\textwidth}{!}{ 
\begin{tabular}{@{}cccccc@{}}
\toprule
Baseline & Clean & Untarg. & Targ. M$_1$ & Targ. M$_2$ & Targ. M$_3$  \\
\midrule
\citet{mao2024regressionmultiexpertdeferral} &  $0.17 \pm 0.01$ & $0.29\pm0.3$ & $0.40 \pm 0.02$ & $0.21 \pm 0.01$ & $0.41\pm 0.05$  \\
\midrule
Our &  $0.17\pm0.01$ & $0.17 \pm 0.01$ & $0.18 \pm 0.01 $ & $0.18\pm 0.01 $ & $0.18\pm 0.01 $ \\
\bottomrule
\end{tabular}}
\caption{Performance comparison of \name{} with the baseline \citep{mao2024regressionmultiexpertdeferral} on the California Housing dataset. The table reports Root Mean Square Error (RMSE).}
\end{table}%clean 976: https://wandb.ai/yannis98/housing_v3/runs/aw8qbcrx?nw=nwuseryannis98
%robust: https://wandb.ai/yannis98/housing_v3/runs/n9x4gdkv
\paragraph{Results:} Table~\ref{table:results_housing} presents the comparative performance of the baseline and \name{} under clean and adversarial conditions. Under clean settings, both approaches achieve similar performance with an RMSE of \(0.17\). However, under adversarial attacks—both untargeted and targeted at specific experts (e.g., M\(_3\))—\name{} demonstrates significant robustness, maintaining an RMSE of \(0.18\) across all conditions. In contrast, the baseline's performance degrades substantially, with RMSE values increasing to \(0.29\) and \(0.41\) under untargeted and M\(_3\)-targeted attacks, respectively.


\subsection{Multi-Task}
We evaluate the performance of our robust \name{} algorithm against the baseline introduced by \citet{montreuil2024twostagelearningtodefermultitasklearning} on the Pascal VOC dataset \citep{pascal}, a benchmark for object detection tasks combining both interdependent classification and regression objectives.
\paragraph{Setting:} We train two Faster R-CNN models \citep{ren2016fasterrcnnrealtimeobject} as experts, each specializing in a distinct subset of the dataset. Expert  M\(_1 \) is trained exclusively on images containing animals, while expert  M\(_2 \) focuses on images with vehicles. Agent costs are defined as \( c_0(g(x), z) = \text{mAP}(g(x), z) \) for the model and \( c_{j > 0}(m_j(x), z) = \text{mAP}(m_j(x), z) \), aligned with \citep{montreuil2024twostagelearningtodefermultitasklearning}. The primary model and the rejector are implemented as lightweight versions of Faster R-CNN using MobileNet \citep{howard2017mobilenetsefficientconvolutionalneural}. We provide detailed performance results, training procedures, and additional experimental details in Appendix~\ref{exp_appendix:multi}. 
\begin{table}[ht]\label{table:results_multi}
\centering\resizebox{0.75\textwidth}{!}{ 
\begin{tabular}{@{}ccccc@{}}
\toprule
Baseline & Clean  & Untarg. & Targ. M$_1$ & Targ. M$_2$   \\
\midrule
\citet{montreuil2024twostagelearningtodefermultitasklearning} &  $44.4\pm0.4$ & $9.7 \pm 0.1$ & $17.4\pm0.2$ & $20.4 \pm 0.2$ \\
\midrule
Our &  $43.9\pm 0.4$ & $39.0\pm0.3$ & $39.7\pm0.3$ &  $39.5\pm0.3$ \\
\bottomrule
\end{tabular}}
\caption{Performance comparison of \name{} with the baseline \citep{montreuil2024twostagelearningtodefermultitasklearning} on the Pascal VOC dataset. The table reports mean Average Precision (mAP) under clean and adversarial scenarios.}
\end{table}%clean: https://wandb.ai/yannis98/pascal_attack6/runs/y67rc1sh
%robust: https://wandb.ai/yannis98/pascal_attack6/runs/bzet88jt?nw=nwuseryannis98
\paragraph{Results:} Table~\ref{table:results_multi} presents the performance comparison between \name{} and the baseline under clean and adversarial scenarios. Both methods perform comparably in clean conditions, with the baseline achieving a slightly higher mAP of 44.4 compared to 43.9 for \name{}. However, under adversarial scenarios, the baseline experiences a significant performance drop, with mAP decreasing to 9.7 in untargeted attacks and 17.4 in targeted attacks on M\(_1\). In contrast, \name{} demonstrates strong robustness, maintaining mAP scores close to the clean setting across all attack types. Specifically, \name{} achieves an mAP of 39.0 under untargeted attacks and 39.7 when targeted at M\(_1\), highlighting its resilience to adversarial perturbations.

