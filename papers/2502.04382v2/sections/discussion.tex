\section{Conclusion}

We propose \ourmethod, a scalable method to generate interpretable hypotheses from black-box representations.
On three synthetic and three real-world social science tasks, \ourmethod outperforms a topic model and state-of-the-art LLM baselines, at less than 10$\times$ the time and cost of the latter. The method applies naturally to many tasks in social science \citep{ziems_can_2024}, healthcare \citep{hsu_clinical_2023, robitschek_large_2025, pierson_using_2025}, and biology \citep{vig_bertology_2021}.
More generally, there are many applications where we can accurately \textit{predict} a target variable, but producing new scientific insights remains difficult. Our work helps bridge this gap.

    

