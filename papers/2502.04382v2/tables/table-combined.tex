\begin{table*}[!htb]
\centering
\fontsize{7.5}{9}\selectfont
\begin{sc}
\begin{tabular}{lccccccccccccccc}
\toprule
& \multicolumn{3}{c}{Wiki, $H=5$} & \multicolumn{3}{c}{Wiki, $H=15$} & \multicolumn{3}{c}{Bills, $H=5$} & \multicolumn{2}{c}{Headlines} & \multicolumn{2}{c}{Yelp} & \multicolumn{2}{c}{Congress} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-12} \cmidrule(lr){13-14} \cmidrule(lr){15-16}
Method & F1 & Surf. & AUC & F1 & Surf. & AUC & F1 & Surf. & AUC & Ct. & AUC & Ct. & $R^2$ & Ct. & AUC \\
\midrule
\ourmethod & \textbf{0.58} & \textbf{0.70} & \textbf{0.84} & \textbf{0.47} & \textbf{0.61} & \textbf{0.84} & \textbf{0.67} & 0.78 & \textbf{0.89} & \textbf{15} & \textbf{0.69} & \textbf{15} & 0.76 & \textbf{15} & \textbf{0.70} \\
\bertopic & 0.48 & 0.48 & 0.77 & 0.40 & 0.43 & 0.79 & 0.65 & \textbf{0.88} & 0.85 & 1 & 0.62 & 12 & 0.65 & 10 & 0.64 \\
\nlparam & 0.15 & 0.30 & 0.69 & 0.16 & 0.34 & 0.77 & 0.32 & 0.50 & 0.74 & 5 & 0.66 & 11 & 0.58 & 8 & 0.65 \\
\hypogenic & 0.15 & 0.20 & 0.60 & 0.12 & 0.39 & 0.64 & 0.25 & 0.30 & 0.70 & 3 & 0.65 & 12 & \textbf{0.78} & 5 & 0.68 \\
\bottomrule
\end{tabular}
\end{sc}
\caption{\ourmethod performs best at recovering reference human-annotated topics on \wiki-5, \wiki-15, and \bills. We also evaluate on three real-world datasets: \headlines, \yelp, and \congress. ``Ct.'' refers to the count of significant hypotheses, out of 20 candidates; \ourmethod generates the most significant hypotheses.}
\label{tab:metrics-comb}
\vskip -0.1in
\end{table*}

