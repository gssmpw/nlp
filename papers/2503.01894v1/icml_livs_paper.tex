%%%%%%%% ICML 2025 %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} 
\usepackage[most]{tcolorbox}



% hyperref makes hyperlinks in the resulting PDF.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}



\icmltitlerunning{LIVS: A Pluralistic Alignment Dataset for Inclusive Public Spaces}

\begin{document}

\twocolumn[
\icmltitle{LIVS: A Pluralistic Alignment Dataset for Inclusive Public Spaces}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% If accepted, you can specify the authors and their affiliations here using:
% \icmlsetsymbol{equal}{*}
%
\begin{icmlauthorlist}
\icmlauthor{Rashid Mushkani}{udem,mila}
\icmlauthor{Shravan Nayak}{udem,mila}
\icmlauthor{Hugo Berard}{udem}
\icmlauthor{Allison Cohen}{mila}
\icmlauthor{Shin Koseki}{udem,mila}
\icmlauthor{Hadrien Bertrand}{mila}
\end{icmlauthorlist}
%
\icmlaffiliation{udem}{Université de Montréal}
\icmlaffiliation{mila}{Mila–Quebec AI Institute}


\icmlcorrespondingauthor{Rashid Mushkani}{rashid.ahmad.mushkani@umontreal.ca}

\icmlkeywords{Pluralistic Alignment, Text-to-Image Diffusion, Human-Centered AI, Intersectionality, Urban Planning, DPO, Inclusivity, Safety, Accessibility}

\vskip 0.3in
]

\printAffiliationsAndNotice{} 
 
%=========================
%Abstract
%=========================
\begin{abstract}
We introduce the \emph{\textbf{L}ocal \textbf{I}ntersectional \textbf{V}isual \textbf{S}paces} (LIVS) dataset, a benchmark for multi-criteria alignment of text-to-image (T2I) models in inclusive urban planning. Developed through a two-year participatory process with 30 community organizations, LIVS encodes diverse spatial preferences across 634 initial concepts, consolidated into six core criteria—Accessibility, Safety, Comfort, Invitingness, Inclusivity, and Diversity—through 37,710 pairwise comparisons. Using Direct Preference Optimization (DPO) to fine-tune Stable Diffusion XL, we observed a measurable increase in alignment with community preferences, though a significant proportion of neutral ratings highlights the complexity of modeling intersectional needs. Additionally, as annotation volume increases, accuracy shifts further toward the DPO-tuned model, suggesting that larger-scale preference data enhances fine-tuning effectiveness. LIVS underscores the necessity of integrating context-specific, stakeholder-driven criteria into generative modeling and provides a resource for evaluating AI alignment methodologies across diverse socio-spatial contexts.
\end{abstract}

\begin{center}
    \raisebox{-0.2ex}{\includegraphics[width=1.5ex, height=1.5ex]{web.png}} \hspace{0.5em}
    \url{https://mid-space.one}
\end{center}


%=========================
\section{Introduction}
\label{sec:intro}
%=========================

Recent advances in text-to-image (T2I) generative modeling have significantly improved image quality and diversity \cite{bai2022rlhf,podell2023sdxlimprovinglatentdiffusion, zhang2024t2i-survey}. These developments can benefit communities by democratizing design processes in architecture, urban planning, and environmental visualization \cite{corner1999, Dubey2024}. However, aligning T2I models with the specific needs of local communities remains an open challenge \cite{Qadri2023representation, kannen2024aesthetics, kirk2024prism}, particularly when addressing subjective concepts such as \emph{inclusivity} or \emph{safety}.

Existing alignment frameworks often rely on large-scale, global data and crowdwork, which may not capture the nuanced objectives of smaller communities \cite{Dzieza2023, Anthropic2023, openai2024gpt4, kirk2024prism}. Moreover, T2I alignment research has often centered on broad aesthetic or content moderation goals \cite{kirstain2023pickapic,pressmancrowson2022}, while paying limited attention to diverse local criteria in domains where multiple social identities intersect. This gap poses a risk that generative models could systematically exclude or misrepresent historically marginalized groups in depictions of public spaces \cite{wan2024survey, perrak2024}.

To address these limitations, we propose a \emph{pluralistic alignment} approach, wherein alignment explicitly accommodates multiple coexisting norms and values rather than seeking a single universal solution \cite{Sorensen2024}. We introduce the \emph{Local Intersectional Visual Spaces}~(LIVS) dataset, which integrates intersectional, community-driven feedback on T2I-generated images of urban public spaces. Over a two-year period, we collaborated with 30 community organizations through workshops and interviews, initially collecting 634 criteria for inclusive public space design. Through iterative co-creation, these were distilled into six broader categories: \emph{Accessibility}, \emph{Safety}, \emph{Comfort}, \emph{Invitingness}, \emph{Inclusivity}, and \emph{Diversity}.

We collected 35,510 multi-criteria preference annotations, each covering one to three criteria, to fine-tune a Stable Diffusion XL model using Direct Preference Optimization (DPO) \cite{wallace2023, rafailov2024}. We then tested the fine-tuned model with 2,200 additional annotations, comparing it to the baseline model. In these comparisons, 700 favored the DPO model, 300 favored the baseline, and about 1,100 were neutral, highlighting the subjective and plural nature of alignment in this setting. Our experiments reveal how multi-criteria feedback can guide T2I models toward locally meaningful outputs, while illustrating that no single objective can fully capture the complexity of community priorities. Moreover, we observe that as the number of annotations increases, accuracy improves toward DPO, with criteria receiving more annotations showing a stronger preference for the fine-tuned model.

\textbf{Contributions:}
\vspace{-10pt}
\begin{itemize}
    \item We introduce the \emph{Local Intersectional Visual Spaces} (LIVS) dataset, developed through a participatory methodology that captures diverse, community-generated dimensions of inclusive public space design \cite{Berditchevskaia2021,sloane2022}.
    \item We propose a pluralistic alignment framework for text-to-image (T2I) generative models, focusing on intersectional and locally specific criteria within urban public space contexts. This framework underpins the construction of the LIVS dataset, tailored for the urban planning domain.
    \item We provide empirical evidence that DPO fine-tuning can modulate image generation according to multi-criteria feedback, revealing varying preferences across intersectional identities and a significant proportion of neutral responses, highlighting areas where preferences are balanced or where further refinement is needed to accommodate complex intersectional needs \cite{fan2023dpok,casper2023open,li2024aligningdistributional,rafailov2024}.
    \item We demonstrate the influence of participant identities on model preferences and compare human-authored and AI-generated prompts, highlighting the importance of accommodating local pluralism and human creativity in T2I alignment.
\end{itemize}
\vspace{-2pt}
We envision our approach bridging the gap between purely global alignment strategies and the need for more fine-grained methods that incorporate local, intersectional values in real-world applications. In the following sections, we contextualize related work, detail our methodology, describe our alignment experiments, and discuss broader implications for the field of machine learning.

%=========================
\section{Related Work}
\label{sec:related}
%=========================
\subsection{Alignment of Generative Models} Multiple datasets have supported alignment efforts in text-to-image (T2I) generation. For instance, Simulacra Aesthetic Captions \citep{pressmancrowson2022} offers 238{,}000 synthetic images rated for aesthetics, and Pic-a-Pic \citep{kirstain2023pickapic} comprises over 500{,}000 preference data points. ImageReward \citep{xu2023imagereward} extends these efforts by capturing ratings on alignment, fidelity, and harmlessness, while HPS \citep{wu2023hps2} and HPS v2 \citep{wu2023hps2} propose large-scale binary preference pairs to train reward models reflecting human judgments. Related work in language models has explored moral decision-making in multilingual contexts \citep{jin2024} and contextual preferences across diverse demographics \citep{kirk2024prism}, highlighting the importance of subjective, multicultural perspectives in alignment processes.

Studies on T2I alignment often focus on aesthetic preferences \citep{pressmancrowson2022,kirstain2023pickapic,wu2023hps2} or content policy compliance. However, they typically assume a single, global notion of “goodness” or “suitability.” Pluralistic alignment, in contrast, recognizes that social values are heterogeneous and context-dependent \citep{Alexey2019,kirk2024prism,Sorensen2024}. Our work extends beyond purely global alignment by collecting specialized, multi-criteria annotations grounded in local, intersectional community knowledge for urban public space design.

Fewer efforts target image-based generative models compared to alignment in large language models \citep{bai2022rlhf,Huang2024}. Prior research has primarily utilized reward modeling and reinforcement learning from human feedback \citep{stiennon2022,ouyang2022}, with a focus on single-objective tasks such as helpfulness or factual correctness \citep{kirk2024prism,jin2024}. In contrast, our approach applies multi-criteria preference learning \citep{fan2023dpok,Chakraborty2024} to T2I outputs within an urban planning context, capturing nuanced trade-offs among accessibility, safety, comfort, invitingness, inclusivity, and diversity.

\subsection{Intersectionality and Local Knowledge} Intersectionality recognizes that individuals may experience multiple, overlapping forms of marginalization, affecting how they engage with public spaces and technology \cite{crenshaw1989,CostanzaChock2020}. In generative modeling, this perspective is often overlooked, with systems calibrated to an “average” user profile that can obscure the distinct needs of marginalized groups \cite{BenjaminRhua2019,algorithmicinjustice2021,gebru2021,kirk2024prism,Murgia2024}. For urban planning tasks, ignoring intersectionality risks overlooking critical insights related to accessibility, safety, or cultural expression. Integrating local knowledge adds further granularity, accounting for the historical, spatial, and communal context that global datasets typically lack \cite{Fischer2000,Nekoto2020,decoloniaAI2020,Datafeminism}. While some studies acknowledge the importance of localized, context-specific input \cite{Aroyo2015,Sloane2024,Sieber2024CivicParticipation}, few systematically address intersectionality in T2I alignment. By weaving intersectional considerations into local community-driven annotations, our approach endeavors to reflect a broader range of perspectives and needs, moving beyond singular, one-size-fits-all criteria in generative modeling. 

\subsection{Visual Generative Modeling for Urban Spaces} Urban planning and design have long leveraged visualizations to communicate design objectives and gather feedback from stakeholders \cite{corner1999,Dubey2024,guridi2024fake}. T2I models offer the promise of more rapid prototyping and inclusive deliberation, especially when non-experts can directly prompt a model to generate conceptual designs of a plaza, park, or street \cite{Carranza2023,guridi2024fake,Dubey2024,Agnew_2024}. Yet, generative models frequently default to learned global priors, potentially reproducing biases or neglecting local cultural markers \cite{hanna2024,jin2024,kirk2024prism,Sorensen2024}. Our LIVS dataset is explicitly curated to capture local, intersectional preferences in a domain where the geometry, aesthetics, and sociocultural elements of a public space are all crucial \cite{janejacob,GehlSvarre2013,MitrasinovicMehta2021,Conitzer2024,guridi2024fake,Dubey2024,Agnew_2024}. This approach aids in systematically evaluating how T2I alignment can be guided by multiple, sometimes conflicting, user-defined criteria.

\subsection{Multi-Criteria Preference Learning} Beyond single-objective alignment, multi-criteria preference learning integrates multiple attributes into a unified training signal \cite{liu2019multiple,bhatia2021multi,fan2023dpok,Chakraborty2024}. This approach has been explored in text-based RLHF, where models are optimized for multiple constraints, such as helpfulness and safety \cite{kirk2024prism,jin2024}. Recent advancements extend this paradigm to T2I generation by incorporating diverse human preferences.

Prior work has demonstrated the efficacy of multi-dimensional preference learning in T2I. Zhang et al.\ \cite{zhang2024multidimensionalhp} introduced the Multi-dimensional Preference Score (MPS), a model trained on over 918{,}000 human preference choices across more than 607{,}000 images, capturing multiple evaluation criteria such as aesthetics, semantic alignment, detail quality, and overall assessment. Similarly, Xu et al.\ \cite{xu2023imagereward} proposed \emph{ImageReward}, a reward model trained on 137{,}000 expert comparisons to encode human preferences and optimize diffusion models for improved alignment with human expectations. Furthermore, Kuhlmann-Joergensen et al.\ \cite{Kuhlmann-Joergensen2025} emphasized the limitations of simplistic preference annotations, advocating for richer human feedback mechanisms to refine T2I model performance and safety.

Building on these developments, we extend multi-criteria preference learning to intersectional urban design goals. We employ the DPO method \cite{wallace2023,rafailov2024} to fine-tune a T2I model using pairwise preference data that account for accessibility, safety, comfort, invitingness, inclusivity, and diversity. By integrating structured human feedback across multiple criteria, we aim to align generative models with complex societal values in urban planning.

%=========================
\section{Methodology: Building the LIVS Dataset}
\label{sec:methodology}
%=========================

We employed a community-based participatory approach to integrate the local perspectives and experiences that are often absent in top-down, universal datasets \cite{Sieber2024PublicsEngaging,kirk2024prism,Hosking2024-goldstandard}. This methodology positions community members as collaborators, allowing for the identification of context-specific needs and priorities, such as nuanced understandings of accessibility and safety \cite{Arnstein1969,AnttiroikoDeJong2020}. By involving diverse local organizations throughout the process, we aimed to capture intersectional viewpoints and mitigate the risk of imposing external definitions of inclusive design \cite{IRCGM2018,CostanzaChock2020}. This approach also fosters mutual learning, wherein participants gain insights into AI technologies while researchers obtain domain-specific knowledge critical for aligning generative models with real-world public space requirements \cite{Engestrom2014}.

\subsection{Community Outreach and Engagement}
\paragraph{Initial Contacts.}
We contacted 100 community organizations in a mid-sized city (Montreal, population $\sim$2 million) \cite{StatCan2022}. These organizations included neighborhood councils, disability-focused nonprofits, faith-based groups, youth advocacy networks, and other civic stakeholders. Our objective was to obtain a demographically diverse set of participants who frequently interact with local public spaces \cite{IRCGM2018,Creswell2022}.
\vspace{-5pt}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{0_self_declared_participants.png}
    \vspace{-20pt}
    \caption{\textbf{Distribution of Participants’ Self-Declared Demographics.} This figure summarizes the demographic profiles (e.g., age, gender, race/ethnicity, and disability) of the individuals who participated in workshops and annotation activities.}
    \vspace{-10pt}
    \label{fig:self_declared_ids}
\end{figure}
\vspace{-10pt}

\paragraph{Workshops \& Interviews.}
Over two years, we conducted multiple forms of engagement: eleven workshops, five batches of annotations, and 34 interviews. The process began in 2023 with three multi-stakeholder workshops aimed at defining what ``equitable design'' means for local public spaces. Participants from diverse backgrounds reviewed images of Montreal’s public spaces and discussed attributes they considered most important for inclusion.
\vspace{-5pt}
\begin{itemize}
    \item \emph{Introductory Sessions (2 workshops, 25–35 participants each):} Provided an introduction to AI and T2I technology. Participants shared open-ended feedback on the study, AI, and their experiences in local public spaces.
    \item \emph{Criteria Brainstorming (6 workshops, 28 participants total):} We projected 16 images of existing public spaces in pairwise comparisons and asked participants to describe their reactions. This process generated 634 initial concepts related to inclusivity, accessibility, safety, and other aspects of urban design (see Appendix \ref{sec:apen-methodology} for additional details). 
    \item \emph{Validation (1 workshop, 18 participants + 34 interviews):} The 634 concepts were consolidated into 35 intermediate criteria through merging and semantic grouping. Participants then ranked and refined these, producing six final criteria based on perceived importance and local relevance.
\end{itemize}

\paragraph{Prompting and Early Feedback.}
\vspace{-3pt}
\begin{itemize}
    \item \emph{Prompting (1 workshop, 24 participants):} Five groups, each composed of 2-3 citizens, a computer scientist, and an urban architect, collaboratively generated 440 prompts reflecting a variety of public-space scenarios and features. For instance, one group focused on designing prompts for pedestrian promenades with green spaces and safe-street initiatives in historical neighborhoods (see Appendix \ref{prompting} for additional details).
    \item \emph{Tutorial and Feedback (1 workshop, 20 participants):} Using prompts from the previous workshop, we generated initial images with Stable Diffusion XL \cite{podell2023sdxlimprovinglatentdiffusion}. Four groups, each comprising 3–4 citizens and an urban architect, tested the annotation platform and provided preliminary feedback on visual fidelity and representation before the larger-scale annotation phase (see Appendix \ref{appendix:human}, Figure \ref{fig:web} for annotation platform).
\end{itemize}

\paragraph{Annotations and Evaluation.}
\vspace{-3pt}
\begin{itemize}
    \item \emph{Annotations (5 batches, 18 participants):} The annotation tasks were divided into five batches, each lasting two weeks and containing approximately 750 pairwise comparisons per participant, totaling 42,235 raw comparisons. In each task, two images were displayed side by side with three randomly selected criteria from the six. Annotators used a slider ranging from $-1$ (strong preference for the left image) to $+1$ (strong preference for the right image), with 0 indicating neutrality. An open-source annotation platform was developed to facilitate this process, featuring a user-friendly slider interface to accommodate diverse backgrounds (see Appendix \ref{protocol} for additional details). A multi-stage data-cleaning process refined the dataset, resulting in 35,510 high-quality annotations \cite{Prabhakaran2021-annotators}.
    \item \emph{Evaluation (1 workshop):} After the annotation phase, we fine-tuned Stable Diffusion XL using these data. Participants then evaluated the fine-tuned model’s outputs, discussing alignment with local norms and values.
\end{itemize}

\subsection{Criteria Consolidation}
The original 634 concepts spanned physical, social, and psychological attributes of public spaces (e.g., lighting, presence of diverse user groups, multilingual signage, seating). Through merging, voting, and iterative discussion, participants identified six \emph{core criteria} (Figure~\ref{fig:distilling-method} illustrates this process):

\textbf{Accessibility:} Physical and cognitive usability for people of all abilities, including ramps, tactile indicators, and clear signage.  
\newline
\textbf{Safety:} Freedom from crime, hazards, or harassment, often reflected in well-lit areas, clear visibility, or protective barriers.  
\newline
\textbf{Comfort:} Availability of amenities (e.g., seating, shade) and mitigation of environmental conditions (e.g., noise, temperature).  
\newline
\textbf{Invitingness:} Features that encourage people to enter and remain, such as greenery, open layouts, or visible communal areas.  
\newline
\textbf{Inclusivity:} Avoidance of exclusionary design; support for cultural or religious needs; signage in multiple languages.  
\newline
\textbf{Diversity:} Representation of different demographic groups and a range of potential uses.

\vspace{-5pt}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{method.png}
    \vspace{-20pt}
    \caption{\textbf{Distilling the Initial Concepts into Six Core Criteria.} The figure shows how 634 distinct ideas were iteratively merged, discussed, and ranked to arrive at final high-level categories.}
    \vspace{-5pt}
    \label{fig:distilling-method}
    \vspace{-5pt}
\end{figure}

Participants viewed these six criteria as sufficiently comprehensive to represent inclusive urban design \cite{AnttiroikoDeJong2020,MitrasinovicMehta2021}, while emphasizing that intersectional dimensions (e.g., disability + race/ethnicity) were woven throughout each category.

\subsection{Prompt and Image Preparation}
\label{sec:annotation}
\paragraph{Prompt Collection.}
Initially, a total of 440 textual prompts describing local public-space scenarios were collected from the \textit{Prompting} workshop. Figure~\ref{fig:prompts-distribution} presents a word cloud that illustrates the distribution of keywords within these prompts. To expand the dataset and ensure a sufficient variety of prompts, we utilized workshop transcripts and employed a large language model (GPT-4o \cite{openai2024gpt4}) with three distinct prompting strategies (see Appendix \ref{appendix:prompt} for additional details). This process generated approximately 2,910 synthetic prompts, encompassing diverse public-space typologies, amenities, and contexts. We assessed the differences between human-written and LLM-generated prompts using Jensen-Shannon Divergence \cite{plank2011jsd}, which indicated that all three strategies produced diverse outputs and contributed to a comprehensive range of scenarios.

\vspace{-5pt}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{0_word-cloud-prompts.png}
    \vspace{-20pt}
    \caption{Word cloud depicting the frequency of various concepts within the 440 collected prompts. The size of each word reflects its prevalence, highlighting key themes such as \textit{public-space typologies}, \textit{amenities}, and \textit{contextual scenarios}. This distribution underscores the diversity and comprehensiveness of the prompt dataset.}
    \label{fig:prompts-distribution}
    \vspace{-5pt}
\end{figure}

\paragraph{Image Generation.}
To maximize image diversity and avoid comparisons between images that are too similar, we generated for each prompt up to 20 images using Stable Diffusion XL \cite{podell2023sdxlimprovinglatentdiffusion}. We then selected the four most distinct images per prompt using a greedy algorithm based on CLIP similarity scores (see Appendix \ref{alg:diverse_selection} for additional details). In total, 16,693 images were generated, with a subset set aside for quality checks (see Appendix \ref{protocol} for additional details), leaving 13,462 images for annotation. 

For each image pair, participants were randomly assigned three of the six criteria and required to annotate at least one criterion. This modification, implemented following feedback from the evaluation workshop, ensured that each criterion had an equal opportunity to be evaluated. However, participants reported that certain criteria, such as \textit{Inclusivity}, were more subjective, leading to fewer distinct preferences and a higher incidence of neutral or equal annotations. Consequently, while each criterion had an equal chance of being selected, some received fewer definitive annotations compared to others. This is reflected in Figure~\ref{fig:num-annotations}, where \textit{Inclusivity} received the fewest annotations, whereas \textit{Comfort} and \textit{Invitingness} were annotated more frequently. Overall, the annotation process yielded 37{,}710 image-level comparisons across multiple criteria, amounting to approximately 113{,}130 annotations when divided per criterion. While the dataset size is modest by machine learning standards, the methodology prioritizes data quality, which helps mitigate limitations related to quantity.

\vspace{-5pt}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{criteria_distribution.png}
    \vspace{-20pt}
    \caption{Distribution of annotation frequencies for each criterion after data cleaning. Red indicates neutral or equal preferences, while blue represents distinct preferences.}
    \label{fig:num-annotations}
    \vspace{-5pt}
\end{figure}

\subsection{Ethical Considerations}  
All activities were approved by a research ethics board and followed a co-production methodology with community organizations \cite{IRCGM2018}. As part of a knowledge exchange and capacity-building process, we learned about public space use and perception from participants, while they gained insights into AI and its applications in urban contexts. Participants were compensated for their involvement and provided written informed consent for data collection. Personally identifiable information was anonymized to ensure confidentiality \cite{Creswell2022}. During the annotation sessions, some AI-generated images exhibited biases or inaccuracies \cite{Hosking2024-goldstandard,Turchin2019-valueDoNOtExist}, prompting revisions to the data-collection protocol. To promote equitable participation, we developed an accessible web interface that accommodated annotators from diverse backgrounds, including those with disabilities, ensuring effective evaluation of images.


%=========================
\section{Experiments with LIVS}
\label{sec:experiments}
%=========================

We present four case studies examining how multi-criteria feedback from \textsc{LIVS} can guide text-to-image (T2I) alignment. Detailed implementation notes (including hyperparameters, prompt generation, and data processing) appear in the Appendix \ref{appendix:experiment}.

%-------------------------
\subsection{Case Study I: Does Multi-Criteria DPO Improve Alignment?}
\label{sec:exp-dpo}
%-------------------------
\paragraph{Setup.}
We fine-tuned Stable Diffusion XL (SDXL; \citealt{podell2023sdxlimprovinglatentdiffusion}) using DPO; \citealt{rafailov2024}. We treated each pairwise comparison in \textsc{LIVS} as a binary “preferred” vs.\ “not preferred” signal, collapsing multi-criteria feedback via majority voting if annotators gave split ratings (e.g., preferring the left image for \emph{Safety} but the right image for \emph{Inclusivity}). Model outputs were then generated for a held-out set of prompts and compared against the SDXL baseline.

\paragraph{Results.}
Out of 2{,}200 new comparisons, annotators chose the DPO-aligned model in 700 (32\%) instances and the baseline in 300 (14\%), marking the remaining 1{,}100 (50\%) as neutral (See Appendix \ref{sec:extra}). Criteria with more training annotations (e.g., \emph{Comfort}, \emph{Invitingness}) showed stronger improvements under DPO, whereas \emph{Inclusivity} and \emph{Diversity} had higher neutral ratings. Qualitative inspections indicated that DPO led to clearer walkways and seating configurations but did not consistently render detailed features (e.g., ramps, tactile features, multilingual signage) (Figure~\ref{fig:T}). Overall, the results suggest that multi-criteria DPO can align T2I outputs to local preferences while retaining considerable variability across criteria (see Appendix \ref{sec:qualitative_obs} for additional details).

\paragraph{Additional Observations.} Comparing Figure~\ref{fig:num-annotations} (overall dataset) with Figure~\ref{fig:T} (evaluation set) suggests a similar distribution of annotations and neutral responses: criteria with more training annotations (e.g., \textit{Comfort}, \textit{Invitingness}) generally exhibit stronger DPO preference in the evaluation. This pattern indicates that additional data may further improve multi-criteria alignment through DPO. However, we currently do not leverage neutral labels, and majority voting in multi-criterion comparisons may overlook nuanced disagreements across criteria. Future work could explore methods for incorporating neutral ratings and resolving multi-label conflicts without collapsing them into binary outcomes. Further analysis of criterion-level variance is provided in the Appendix \ref{sec:extra}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.45\textwidth]{total-responses-eval.png}
    \vspace{-6pt}
    \caption{Criteria distribution on the new evaluation dataset. Neutral ratings were more common for \emph{Inclusivity} and \emph{Diversity}, indicating subtler or more subjective distinctions in these categories.}
    \label{fig:T}
    \vspace{-3pt}
\end{figure}

\vspace{-5pt}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{exp1.png}
    \vspace{-20pt}
    \caption{Three variants of SDXL outputs generated with the same prompt, seed, and hyperparameters. \textbf{Left:} Baseline SDXL lacks cohesive pathways and shows minimal accessibility features. \textbf{Middle:} An inclusivity-finetuned model adds partial signage and barriers but still has uneven paths. \textbf{Right:} A multi-criteria finetuned model shows smoother transitions, clearer walkways, and additional seating.}
    \label{fig:exp1}
    \vspace{-6pt}
\end{figure}

%-------------------------
\subsection{Case Study II: Do Preferences Vary Across Identities?}
\label{sec:exp-identities}
%-------------------------

\paragraph{Setup.}
We examined whether participant demographics (e.g., disability status, age) influenced choices between DPO-finetuned and baseline outputs. We aggregated each individual’s total count of DPO-favoring versus baseline-favoring comparisons across the six \textsc{LIVS} criteria.

\paragraph{Results.}
Most participants showed a modest preference for DPO, although two late-joining individuals rated the baseline and DPO models similarly (Figure~\ref{fig:B}). These participants joined the study after the core workshops and did not participate in earlier collaborative sessions that established the six final criteria. Their equal preference may indicate that less involvement in the knowledge-exchange process can lead to different or less pronounced alignment perceptions. Some annotators who reported mobility challenges were more likely to favor the DPO outputs, suggesting that DPO captured partial accessibility-related cues. However, no single demographic factor dominated preferences. This variation underscores the importance of collecting intersectional data rather than applying a universal alignment rule.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{user_variation.png}
    \vspace{-15pt}
    \caption{Boxplot of participant preferences. A score of 1 indicates a tendency towards DPO, while a score of -1 indicates a tendency towards the base model. Two late-joining participants (asterisks) showed no clear preference, whereas most favored DPO to some extent. One participant with a disability indicated a smaller margin of preference for DPO, reflecting individual-level variability.}
    \label{fig:B}
    \vspace{-3pt}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=0.45\textwidth]{prompt-performance.png}
\vspace{-6pt}
\caption{Rates of neutral annotations for human-written (Methods 0) versus GPT-4o-generated prompts (Methods 1-4). Method 0 indicates that human-authored prompts elicited more decisive preferences (fewer neutral annotations), suggesting clearer visual distinctions}
\label{fig:C}
\vspace{-3pt}
\end{figure}
\vspace{-3pt}

%-------------------------
\subsection{Case Study III: Does Prompt Composition Affect Rating Consistency?}
\label{sec:exp-prompting}
%-------------------------

\paragraph{Setup.}
We compared images generated from 440 human-authored prompts with four GPT-4o-generated prompt sets. Both baseline SDXL and the DPO-finetuned model were used for each prompt. Annotators then compared image pairs on a random subset of three criteria.

\paragraph{Results.}
Human-authored prompts led to fewer neutral ratings, suggesting they produced more visually distinct outcomes (Figure~\ref{fig:C}). GPT-4o-generated prompts exhibited higher neutrality, possibly due to less contextual specificity. These findings indicate that prompt design can influence annotators’ perceptions of alignment differences.


%-------------------------
\subsection{Case Study IV: Do Intersectional Identities Rate SDXL Outputs Differently?}
\label{sec:exp-scoring}
%-------------------------
\paragraph{Setup.}
We explored whether different intersectional identities (e.g., disability status $\times$ race/ethnicity) assigned systematically distinct raw scores to images across \textsc{LIVS} criteria. Each participant rated images for multiple criteria in separate annotation tasks.

\paragraph{Results.}
We observed that individuals from various intersectional groups (e.g., participants with mobility challenges) typically assigned lower \emph{Accessibility} or \emph{Safety} scores. This variation underscores the need for local, intersectional feedback in T2I alignment for urban planning, as a single global objective cannot capture such diverse preferences. See Appendix Section~\ref{sec:case-study-iv-appendix}, Figures~\ref{fig:dataset-scoring-pattern} and ~\ref{fig:eval-dataset-scoring-pattern} for further details.


%=========================
\section{Implications}
\label{sec:discussion}
%=========================

Our findings contribute to ongoing discourse on trustworthy and multi-objective machine learning. Below we highlight several implications:

\textbf{Multi-Criteria Overlaps and Conflicts.} Some participants valued certain criteria (like Diversity) above others (such as Comfort). Others perceived Safety and Comfort as interlinked, finding it hard to separate physical hazards from environmental conditions. Future alignment methods might benefit from hierarchical or weighted objective formulations, capturing partial dependencies among criteria \cite{ref40,stray2020,li2024aligningdistributional,Sorensen2024}.

\textbf{Neutral Annotations as a Signal.} Approximately half of the final evaluations were rated as neutral, with participants commenting that neither image fully captured local expectations. Rather than viewing these neutral responses as alignment failures, we interpret them as indications that the alignment adjustments were either too subtle or insufficient to reflect the complexity of participant feedback. Prompt variations also influenced these outcomes, as some prompts elicited more ambiguous or less distinct visual differences. Taken together, neutral ratings highlight the importance of richer, context-specific alignment methods that account for both the prompt and the underlying multi-criteria data, including contradictory user needs, and underscore the need for further research \cite{Hosking2024-goldstandard,Sorensen2024}.

\textbf{Intersectionality and Local Variation.} The variations in preference highlight the potential shortcoming of single-objective alignment. Pluralistic alignment attempts to unify multiple local perspectives, but fully reconciling them may be infeasible in a single model. One potential future direction is the development of \emph{user-personalized alignment layers}, where a single base T2I model can adapt to specific subgroups or contexts \cite{jang2023,kirk2024prism,Sorensen2024}.

\textbf{Comparison with Overton and Distributional Pluralism.} Sorensen et al.~\cite{Sorensen2024} propose Overton pluralism, steerable alignment, and distributional pluralism to address heterogeneous human values. Our multi-criteria, participatory framework echoes Overton pluralism by capturing a broad range of locally valid design norms, while intersectional feedback supports distributional coverage for varied subgroups. Unlike text-only methods, visuals can convey subtle spatial details (e.g., ramps or diverse crowds) that reduce ambiguity and highlight group-specific preferences. By combining these signals with DPO, we also advance Overton’s commitment to retaining multiple permissible viewpoints, although roughly half of our comparisons remained neutral—reflecting persistent tensions and underscoring that no single, static alignment fully resolves all local conflicts.

\textbf{Broader Relevance.} While our application domain is urban planning, the core methodology—community-centered, multi-criteria preference data, and DPO-based fine-tuning—applies broadly to scenarios where local norms matter (e.g., cultural heritage preservation, healthcare, educational content creation) \cite{kirk2024prism,huang_2024,Hosking2024-goldstandard,harland2024adaptivealignmentdynamicpreference}.


%=========================
\section{Conclusion}
\label{sec:conclusion}
%=========================
We presented \emph{LIVS}, a dataset and methodology for pluralistic alignment of T2I models centered on intersectional, local feedback for inclusive public spaces. Our experiments with DPO fine-tuning on Stable Diffusion XL revealed moderate preference gains relative to a base model, especially under criteria such as Invitingness or Accessibility. Nonetheless, roughly half of the annotations were neutral, underscoring the complexity of reconciling diverse criteria and identities in a single generative alignment objective.

\textbf{Contributions.} We introduced a multi-year, participatory process that established six locally validated criteria for inclusive urban design, demonstrated how DPO can incorporate multi-criteria signals, and provided empirical evidence of partial alignment success. Additionally, we showcased how intersectional feedback can highlight local or demographic nuances that global alignment schemes may overlook. The LIVS dataset and model enable two key use cases: first, supporting empirical research on what constitutes inclusivity in urban design by providing structured annotations on comfort, accessibility, and other public space attributes; and second, facilitating democratic deliberation in public space renovation projects through visualizations that allow policymakers and communities to explore context-specific interventions. These use cases illustrate how generative models aligned with LIVS can bridge technical capabilities with situated local knowledge, fostering equitable and participatory urban design. See Appendix~\ref{sec:use_cases} for more details.

\textbf{Limitations.} Our dataset concentrates on one mid-sized, multicultural city, which is well-suited for pluralistic alignment but restricts the range of local norms represented. Other contexts may have profoundly different needs or design principles. Additionally, the total number of participants was relatively low, and our final test set of 2,200 annotations remains modest compared to the complexity of T2I generation. Although our results show promising alignment gains, scalability to larger, more diverse regions or to other policy domains is not guaranteed.

\textbf{Future Work.} Future research might explore multi-objective optimization by extending beyond pairwise DPO to address correlated or competing criteria, such as Comfort and Safety, potentially using methods like Pareto optimality or weighted objectives \cite{Chakraborty2024}. Investigating neutral annotations could involve developing refined strategies, such as partial reward signals, to interpret neutral feedback more effectively instead of discarding it as non-informative. Additionally, developing tools for policy integration in collaboration with urban planning agencies may facilitate the application of T2I alignment in real-world policy decisions through interactive tools for stakeholders. Enhancing personalization by experimenting with adaptive alignment tailored to specific subgroups or contexts, especially where intersectional dimensions are important, might improve model relevance and inclusivity. Overall, our findings suggest that a pluralistic alignment paradigm could be promising for creating locally grounded, inclusive generative AI systems by acknowledging intersectional viewpoints and supporting multi-criteria feedback loops to better serve diverse community needs.

\textbf{Availability.} The \textsc{LIVS} dataset, including citizens' self-identification markers (with consent), will be made available for research purposes. This release aims to establish a benchmark for pluralistic alignment in text-to-image generation and supports both criterion-specific and user-specific customization. Future work can leverage these granular annotations to develop personalized models and adaptive fine-tuning strategies that more effectively address the unique needs of diverse user groups.


%=========================
\section*{Impact Statement}
%=========================
This study adapts T2I alignment to an urban context, aiming to better represent diverse demographic perspectives. The dataset and results may facilitate more inclusive public-space design. However, there is a risk of oversimplifying complex social challenges by attempting to visualize inclusivity and diversity, which are multifaceted. Moreover, potential biases in the annotated data could affect how the model prioritizes certain user groups. We view our approach as one step toward more fine-grained, democratically informed generative AI, while recognizing that deeper societal involvement and critical oversight remain essential.

%=========================
%\section*{Acknowledgements}
%=========================
%We thank the community organizations ....

\bibliography{icml_bibliography}
\bibliographystyle{icml2025}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDICES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\appendix
\onecolumn

%=========================
\section{LIVS Dataset Viewer}
\label{sec:apen-datasetV}
%=========================
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{0_livs-viewer.jpg}
    \caption{An overview of the dataset, illustrating pairs of images for each prompt alongside corresponding preference scores.}
    \label{fig:livs}
\end{figure}

\clearpage
%=========================
\section{Use Cases}
\label{sec:use_cases}
%=========================
The multi-criteria alignment approach described in the main paper can be adapted for various real-world scenarios in urban planning and beyond. Below, we outline specific applications in which intersectional alignment and rapid text-to-image generation may offer practical benefits.

\paragraph{Community Consultations.} Local governments or urban planners often conduct participatory design sessions for proposed public spaces. The aligned model can generate visual scenarios that reflect multiple local criteria, such as accessibility or safety. Community members can then provide feedback on which visualizations best meet their needs, potentially reducing barriers for stakeholders unfamiliar with technical planning diagrams.

\paragraph{Peer-to-Peer Discussion.} Community members can use the model to explore differing priorities in contested designs. By quickly producing multiple variations of a layout, participants can discuss trade-offs (e.g., balancing comfort with affordability) without relying on professional mediators.

\paragraph{Rapid Visualization of Ideas.} Urban designers and architects can employ the model to iterate on design concepts at an early stage, generating a variety of sketches that incorporate multi-criteria feedback (e.g., inclusivity or invitingness). This process can reveal overlooked aspects before substantial resources are committed.

\paragraph{Teaching and Education.} In architecture or urban-planning courses, students can interact with the model to see how different prompts and annotation signals affect output images. This hands-on experience can clarify alignment methods and potential biases in generative models.

\paragraph{Amplifying Marginalized Voices.} Historically excluded groups (e.g., people with disabilities, marginalized ethnic communities) can utilize the model to communicate spatial requirements, such as multilingual signage or wheelchair accessibility. Visual prototypes allow direct articulation of needs and can lead to more inclusive design outcomes.

\clearpage
%=========================
\section{Further Details on Methodology: Building the LIVS Dataset}
\label{sec:apen-methodology}
%=========================

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{0_634-critiera.png}
    \caption{Word cloud of the 634 collected public-space attributes that were consolidated into six high-level criteria. Larger words appear more frequently among the original attributes.}
    \label{fig:criteria-distribution}
\end{figure}

\subsection{Prompt Augmentation}
\label{appendix:prompt}

We collected 440 prompts from annotators, each representing distinct scenarios related to public space typologies, amenities, and ambiances in Montreal. To expand the dataset, we supplemented these with synthetic captions generated by GPT-4o \cite{openai2024gpt4}. To ensure diversity, we incorporated a wide range of concepts drawn from public space literature, such as typologies like parks and wide walkways, amenities such as seating areas and streetlights, natural elements like forests and vegetation, locations such as suburban Montreal and old industrial ports, people such as First Nations and children, architectural elements like duplexes and houses, transportation modes including bike lanes and trams, artistic features such as street murals and art sculptures, different times like winter, nighttime, and Christmas, and animals such as dogs and raccoons. These concepts were used to increase the diversity of the concepts in the generated prompts. We employed three distinct prompting strategies to ensure that the synthetic prompts retained similarity to those generated by humans while covering a wide range of topics relevant to public space design. The specific strategies and prompts used for the LLM are outlined below.

\paragraph{Method 1} We randomly sampled 8-16 prompts from the human-generated set and used them as in-context examples for the LLM to generate new prompts.

\begin{tcolorbox}[colback=gray!5!white, % Background color of the box
                  colframe=gray!75!black, % Frame color
                  title=System prompt used Method 1, % Box title
                  fonttitle=\bfseries, % Bold title font
                  sharp corners=all] % Sharp corners
Your task is to craft detailed and imaginative prompts suitable for diffusion models like Stable Diffusion. These prompts should generate images illustrating the variety of Montreal's public spaces, capturing the community's diverse aspirations and values.

Each prompt must be rooted in a specific scenario related to Montreal's public spaces. You will be provided with the scenario, keywords, and examples of prompts related to these scenarios. Using this information, your task is to create a series of diverse, con¯textually rich, and relevant prompts following a style similar to the ones given as examples. These should aim to generate images showcasing Montreal's public spaces from varied perspectives.
\end{tcolorbox}

\paragraph{Method 2} We provided the LLM with a detailed scenario which was also provided to the annotators during the initial prompt collection phase. Along with this we also provided several keywords related to the public space concepts mentioned earlier. Additionally, we included 8 randomly selected in-context samples relevant to the scenario guiding the model to generate new prompts based on these concepts.

\begin{tcolorbox}[colback=gray!5!white, % Background color of the box
                  colframe=gray!75!black, % Frame color
                  title=System prompt used Method 2, % Box title
                  fonttitle=\bfseries, % Bold title font
                  sharp corners=all] % Sharp corners
Your task is to craft detailed and imaginative prompts suitable for diffusion models like Stable Diffusion. These prompts should generate images illustrating the variety of Montreal's public spaces, capturing the community's diverse aspirations and values. To achieve this, you will construct prompts using specific keywords provided for the following categories:\\
Typology: The type of spaces you want to depict\\
Elements: Distinct elements to include in your scene\\
Context: The scenarios in which your elements are placed\\
Style: The artistic style or technique that the image should emulate, defining its visual appearance\\
Mood: The overall mood or atmosphere of the image\\

You will also be given a few examples that have been generated using these keywords. Using all this information create a complete, coherent prompt similar in style to the examples. Aim for creativity and diversity in your prompts, ensuring they cover several aspects of the keywords given. These should aim to generate images showcasing Montreal's public spaces from varied perspectives.\\

Note: \\
1. Ensure your prompts integrate some of the provided keywords to encapsulate the community's desired visions of Montreal's public spaces but ensure that style and length is same as the examples.\\
2. Do not mention the style and mood explicitly. Use keywords that bring out these attributes naturally.\\
3. The style and the length of the prompts should be similar to the examples given. The prompt should be less than 77 tokens.
\end{tcolorbox}

\paragraph{Method 3} This method used a template-based approach where specific keywords related to public space concepts in the original prompts were masked. We instructed the LLM to replace these masked keywords with concepts from a wide variety of public space themes. This ensured the prompts closely followed the structure of the human-generated ones while incorporating a diverse range of concepts.

\begin{tcolorbox}[colback=gray!5!white, % Background color of the box
                  colframe=gray!75!black, % Frame color
                  title=System prompt and incontext sample used Method 3, % Box title
                  fonttitle=\bfseries, % Bold title font
                  sharp corners=all] % Sharp corners
Your task is to craft detailed and imaginative prompts suitable for diffusion models like Stable Diffusion. These prompts should generate images illustrating the variety of Montreal's public spaces, capturing the community's diverse aspirations and values.\\

For this task, you will be provided with a templated sentence containing several placeholders. Each placeholder represents a specific category (e.g., [Typology], [Location], [Activity], [Amenity]). Alongside the templated sentence, you will receive a list of words or phrases corresponding to each category. Your objective is to select the most appropriate word or phrase from each list to fill in the placeholders, creating a meaningful and grammatically correct sentence.\\

The structure of the templated sentence might require minimal modifications to ensure grammatical correctness and cohesiveness once the placeholders are filled.
\\

Example 1:\\

Template: a [Typology] for [People] in [Location]\\

Keywords:\\
Typology: artistic eco friendly park, pedestrian street, all identities, two-story residential street, park, neighbourhood public space, urban square, wide walkway\\
People: elderly person, adults, first nations, children, teenagers, adults and elderly people, black and white families, a mother and her child, people, various ethnicities\\
Location: plateau, wellington neighbourhood, old port, montreal `s chinatown, old montreal, Montreal, downtown montreal, mont royal street\\

Output: A neighbourhood public space for children, teenagers, adults and elderly people in Montreal\\

<more examples>
\end{tcolorbox}

To measure deviation from human-written prompts, we computed the Jensen-Shannon Divergence (JSD) \cite{plank2011jsd}. Methods 1 and 2 produced slightly higher JSD scores (0.53 and 0.58) than Method 3 (0.40), indicating that all three approaches contributed diverse scenarios, with Method 3 aligning more closely with human style.

\subsection{Image Generation}
\label{appendix:image}

We used Stable Diffusion XL to generate 20 images per prompt, varying hyperparameters (seed, guidance scale, steps). Because initial user feedback indicated difficulty in differentiating images, we applied a greedy selection strategy to choose the 4 most distinct images based on CLIP similarity scores. Algorithm~\ref{alg:diverse_selection} details this procedure.


\subsection{Annotation Details}
\label{appendix:human}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{0_aipithet.png} 
    \caption{Annotation interface for \textsc{LIVS}. Users compared two images on a slider, optionally clicking on the purple dot next to each criterion for its definition.}
    \label{fig:web}
\end{figure}

Figure~\ref{fig:web} shows the web-based annotation interface. Users rated each image pair by moving a slider to the left or right, indicating their preference strength or neutrality. They could rate up to three randomly assigned criteria per comparison, consulting embedded definitions as needed.

\begin{algorithm}[ht]
\caption{Selecting the 4 Most Diverse Images Using CLIP Similarity Scores}
\label{alg:diverse_selection}
\begin{algorithmic}[1]

\STATE \textbf{Input:} Similarity matrix $S$ (size $n \times n$), number of images $k=4$
\STATE \textbf{Output:} Indices of the $k$ selected images, $selected\_indices$

\STATE $n \gets \text{len}(S)$
\STATE $selected\_indices \gets []$

\STATE $first\_index \gets \arg\min \bigl(\text{mean}(S, \text{axis}=1)\bigr)$
\STATE Append $first\_index$ to $selected\_indices$

\FOR{$j = 1$ to $(k-1)$}
    \STATE $min\_similarity \gets \infty$
    \STATE $next\_index \gets -1$

    \FOR{$i = 0$ to $(n - 1)$}
        \IF{$i \notin selected\_indices$}
            \STATE $current\_similarity \gets \max(S[selected\_indices, i])$
            \IF{$current\_similarity < min\_similarity$}
                \STATE $min\_similarity \gets current\_similarity$
                \STATE $next\_index \gets i$
            \ENDIF
        \ENDIF
    \ENDFOR

    \STATE Append $next\_index$ to $selected\_indices$
\ENDFOR

\STATE \textbf{return} $selected\_indices$

\end{algorithmic}
\end{algorithm}


\clearpage 
\section{LIVS - Annotation Protocol}
\label{protocol}
Your help is crucial for creating an AI model that understands what makes Montreal's public spaces good for everyone. This guide will assist you in comprehending the labeling process, how to conduct labeling, and what to look for during this exercise.

\subsection{Before You Start}
\begin{itemize}
    \item \textbf{Read the criteria definitions:} Understand what each criterion (like safety or comfort) signifies before you begin. (See the definitions below.)
    \item \textbf{Take breaks:} Avoid attempting to do too many annotations at once. It's preferable to return refreshed.
    \item \textbf{Take your time:} Ensure the annotations are of high quality. On average, each comparison should take between 15 to 30 seconds.
    \item \textbf{Use a computer:} This task is more manageable on a computer than on a phone or tablet.
\end{itemize}

\subsection{The Labeling Process}
\begin{itemize}
    \item \textbf{Evaluating image pairs:} You will assess each pair of images based on three specific criteria displayed on the webpage. For each criterion, adjust the slider to indicate if the image on the right or left better aligns with that criterion. If neither image fits or both are equally suitable, you may position the slider in the center. However, be aware that center positions provide no distinct preference data.
    \item \textbf{Personal perspective:} Annotate based on your own judgment, experience, and perspective. We value your individual insight and are not seeking an objective assessment.
    \item \textbf{Focus on urban space characteristics:} Your decision should be based solely on the characteristics of the urban space rather than the presence of people or animals.
    \item \textbf{Handling distorted images:} Do not spend additional time making sense of disfigured or unclear images, as these are common with AI-produced imagery.
    \item \textbf{Utilize the commenting feature:} This allows you to add nuances or context to your annotations. Remember, this is voluntary and does not count towards the total number of annotations.
    \item \textbf{Asking questions:} If you're ever unsure about anything, please send us an email at \href{mailto:hugo.berard@umontreal.ca}{hugo.berard@umontreal.ca}.
\end{itemize}

\subsection{Labeling Duration}
You can label the images on a web platform accessible from any location. A code will be sent to your email for access. Simply create a profile using your email and a chosen password. Below is the schedule for image annotation:

\begin{itemize}
    \item \textbf{Duration:} The labeling spans 8 weeks, organized into four 2-week batches.
    \item \textbf{Task:} Each batch requires the annotation of 750 images.
    \item \textbf{Start date:} The labeling begins on 01 May 2024.
    \item \textbf{End date:} Please try to finish 750 annotations before the deadline for each batch. The deadlines are indicated below.
\end{itemize}

Please note that the platform limits users to 90 annotations per session, with each session lasting about 25 minutes. Completing all annotations for each batch is estimated to take around 4 hours.

\subsection{Labeling Timeline}
\begin{itemize}
    \item \textbf{First batch:} 01 April – 14 May
    \item \textbf{Second batch:} 15 May – 28 May
    \item \textbf{Third batch:} 29 May – 11 June
    \item \textbf{Fourth batch:} 12 June – 20 June
\end{itemize}

\subsection{Definitions}
\begin{itemize}
    \item \textbf{Public space:} Public space is an area where everyone can go, like parks and streets, designed for people to meet, play, and relax together in cities and towns.
    \item \textbf{Inclusion (Inclusive):} Spaces where everyone is welcome and feels respected. These are places that do not discriminate against anyone.
    \item \textbf{Safe / Secure:} Spaces where public safety is ensured through various measures. Spaces where one feels calm and safe, free from dangers related to physical elements, pollution, or any other concerns that could diminish a sense of security.
    \item \textbf{Comfortable:} Well-equipped spaces with quality facilities that provide material comfort; places where one feels at ease and protected from the elements.
    \item \textbf{Inviting:} Spaces that attract and engage people through appealing elements and activities; places that encourage community participation and interaction.
    \item \textbf{Diverse:} Spaces that cater to the diversity of social groups and to the variety of services, activities, and functions. These are places offering a range of uses and meeting the needs of different cultures, ages, and abilities.
    \item \textbf{Accessibility:} Urban spaces that are easily accessible and navigable for everyone, regardless of physical ability. These include features such as ramps, wide walkways, clear signage, and tactile indicators for safe and convenient access throughout the area.
\end{itemize}


\section{Prompting Workshop Details}
\label{prompting}
\subsection*{Questions for the Prompt Creation}
\begin{itemize}
    \item What are the surroundings?
    \item What decorative features and objects does the place have?
    \item Is there nature present, and if yes, what kind?
    \item How are the weather and light conditions?
    \item What is the composition of the image?
    \item What materials and surfaces are present?
    \item How would you describe the atmosphere?
    \item What amenities should be present in the space?
\end{itemize}

\subsection*{Questions for the Evaluation of the Images}
\begin{itemize}
    \item Can you imagine using the public space yourself?
    \item Does the public space match what you had imagined when creating the prompt?
    \item Are you satisfied with the image?
    \item Can you see the image being used as a design for a public space in real life?
\end{itemize}

\subsection*{Groups}
\subsection*{Group 1}
\begin{itemize}
    \item First hands-on session – Scenario A
    \item Second hands-on session – Scenario B
    \item Optional – Scenario F
\end{itemize}

\subsection*{Group 2}
\begin{itemize}
    \item First hands-on session – Scenario B
    \item Second hands-on session – Scenario C
    \item Optional – Scenario G
\end{itemize}

\subsection*{Group 3}
\begin{itemize}
    \item First hands-on session – Scenario C
    \item Second hands-on session – Scenario D
    \item Optional – Scenario H
\end{itemize}

\subsection*{Group 4}
\begin{itemize}
    \item First hands-on session – Scenario D
    \item Second hands-on session – Scenario E
    \item Optional – Scenario I
\end{itemize}

\subsection*{Group 5}
\begin{itemize}
    \item First hands-on session – Scenario E
    \item Second hands-on session – Scenario A
    \item Optional – Scenario J
\end{itemize}

\section*{Scenarios List}

\subsection*{Scenario A}
\textbf{Visualize this public space with provided tools:}
\begin{itemize}
    \item Public space typology: Park
    \item Amenities: Sitting space, green space
    \item Location: Less dense suburban Montreal
\end{itemize}

\subsection*{Scenario B}
\textbf{Visualize this public space with provided tools:}
\begin{itemize}
    \item Public space typology: Pedestrian promenades
    \item Amenities: Safe streets, community engagement spaces, green spaces
    \item Location: Historical neighborhood in Montreal
\end{itemize}

\subsection*{Scenario C}
\textbf{Visualize this public space with provided tools:}
\begin{itemize}
    \item Public space typology: Street space
    \item Amenities: All ages-, all genders-, all abilities-, all identities-friendly environments
    \item Location: Residential neighborhood in Montreal
\end{itemize}

\subsection*{Scenario D}
\textbf{Visualize this public space with provided tools:}
\begin{itemize}
    \item Public space typology: Downtown plaza
    \item Amenities: Meeting spaces, sitting area, rest areas, versatile use space
    \item Location: Downtown Montreal
\end{itemize}

\subsection*{Scenario E}
\textbf{Visualize this public space with provided tools:}
\begin{itemize}
    \item Public space typology: Park
    \item Amenities: Rest areas, community engagement spaces, waterfront area
    \item Location: Dense urban area in Montreal
\end{itemize}

\subsection*{Optional Scenarios}

\subsection*{Scenario F}
\textbf{Visualize this urban space:}
\begin{itemize}
    \item Public space typology: Urban garden
    \item Amenities: Educational programs, community gardening spaces
    \item Location: Near universities and colleges in Montreal
\end{itemize}

\subsection*{Scenario G}
\textbf{Visualize this urban environment:}
\begin{itemize}
    \item Public space typology: Waterfront sidewalk
    \item Amenities: Outdoor cafes, art installations, pedestrian paths, bike lanes
    \item Location: Along a river or lake in a mixed-use (residential and commercial uses) area of Montreal
\end{itemize}

\subsection*{Scenario H}
\textbf{Visualize this community space:}
\begin{itemize}
    \item Public space typology: Neighborhood square
    \item Amenities: Playgrounds, outdoor fitness equipment, community noticeboards, seasonal markets
    \item Location: Residential area in Montreal, possibly near schools and local businesses
\end{itemize}

\subsection*{Scenario I}
\textbf{Visualize this communal area:}
\begin{itemize}
    \item Public space typology: Transit plaza
    \item Amenities: Sheltered seating, transit information displays, public art, bike-share stations
    \item Location: Key transit hub in Montreal, adjacent to a metro station or major bus interchange
\end{itemize}

\subsection*{Scenario J}
\textbf{Visualize this urban setting:}
\begin{itemize}
    \item Public space typology: Alleyway
    \item Amenities: Street murals, pedestrian lighting, small business kiosks
    \item Location: Back alleys commercial district of Montreal
\end{itemize}


%=========================
\section{Experiment Details}
\label{appendix:experiment}
%=========================

We fine-tuned Stable Diffusion XL using Direct Preference Optimization (DPO; \citealt{rafailov2024}), closely following the original hyperparameters:

\begin{itemize}
    \item \textbf{Batch Size:} 64
    \item \textbf{Learning Rate:} $1\times10^{-8}$ with 20\% linear warmup
    \item \textbf{Beta $(\beta)$:} 5{,}000
    \item \textbf{Training Steps:} 500 for smaller subsets; 1{,}500 when combining the entire preference dataset
    \item \textbf{Hardware:} Single NVIDIA A100 80GB GPU
\end{itemize}

All preference values (continuous slider results) were discretized to binary labels (preferred vs.\ not preferred) for DPO compatibility. While a majority-voting procedure resolved multi-criteria conflicts, future work could explore methods that retain richer preference signals.

%=========================
\section{Qualitative Observations}
\label{sec:qualitative_obs}
%=========================
\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{exp3.png}
\caption{\textbf{Bike Path Scenario Focused on Safety.} From left to right: baseline SDXL output with minimal barriers; a safety-tuned version with stronger separation but lacking comfort features; and a multi-criteria DPO version featuring wider lanes and smoother transitions, though certain amenities remain missing.}
\label{fig:exp_bike_path}
\end{figure}

Figures~\ref{fig:exp_bike_path}, \ref{fig:exp_mall}, and \ref{fig:exp_diversity} compare baseline SDXL images against versions finetuned on specific or multiple \textsc{LIVS} criteria. While DPO alignment often improves features such as smooth surfaces or clearer paths, certain elements (e.g., ramps, multilingual signage) appear inconsistently, indicating the model's limited capacity for rendering specialized details.

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{exp4.png}
\caption{\textbf{Shopping Mall Scenario Emphasizing Accessibility.} From left: baseline SDXL with limited ramps; an accessibility-tuned version that adds more stairs; and a multi-criteria DPO output showing wider walkways but still struggling with ramp clarity.}
\label{fig:exp_mall}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=1\textwidth]{exp2.png}
\caption{\textbf{Metro Station Scenario Emphasizing Diversity.} From left: baseline SDXL with limited demographic variety; a diversity-focused model offering modestly varied individuals; and the DPO-tuned version showing slightly broader representation, though cultural markers (e.g., multilingual signs) remain muted.}
\label{fig:exp_diversity}
\end{figure}

%=========================
\section{Additional Analysis: Intersectional Scoring}
\label{sec:int_scoring}
%=========================

\subsection{Case Study IV: Scoring Patterns of SDXL Images by Intersectional Identities}
\label{sec:case-study-iv-appendix}

Figures~\ref{fig:dataset-scoring-pattern} and \ref{fig:eval-dataset-scoring-pattern} plot average raw scores from intersectional groups (e.g., disability status $\times$ race/ethnicity) for SDXL-generated images across the six \textsc{LIVS} criteria. Participants with mobility challenges generally assigned lower \emph{Accessibility} and \emph{Safety} scores, highlighting the importance of soliciting localized, intersectional feedback in T2I alignment for public-space design.

\begin{figure}[ht]
    \centering
    \includegraphics[height=0.9\textheight]{dataset-scoring-pattern.png}
    \caption{Main dataset: SDXL-scored public-space images, grouped by intersectional identity. Participants with mobility constraints often assigned lower \emph{Accessibility} ratings.}
    \label{fig:dataset-scoring-pattern}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[height=0.8\textheight]{eval-dataset-scoring-pattern.png}
    \caption{Evaluation dataset: SDXL-scored images, again grouped by intersectional identity. Patterns parallel those observed in the main dataset, with lower \emph{Accessibility} or \emph{Safety} scores among some groups.}
    \label{fig:eval-dataset-scoring-pattern}
\end{figure}






\begin{figure}[ht]
\section{Variance}
\label{sec:extra}
\centering
\includegraphics[width=1\textwidth]{total-responses.png}
\caption{\textbf{Preference Distribution for DPO vs.\ Baseline.} Each bar represents the share of 2{,}200 final annotations favoring the DPO-aligned model, the baseline, or indicating neutrality. Neutral selections suggest subtle differences or partial fulfillment of criteria by both images.}
\label{fig:preference_total}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=1\textwidth]{dataset-variance.png}
\caption{Main dataset: neutral ratings and variance by criterion. Higher variance in some criteria (e.g., \emph{Inclusivity}) may reflect subjective or difficult-to-visualize concepts.}
\label{fig:preference_dist}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=1\textwidth]{eval-rating.png}
\caption{Evaluation set: neutral rating and variance by criterion. Similar patterns of higher neutrality persist for \emph{Inclusivity} and \emph{Diversity}.}
\label{fig:variance}
\end{figure}




\end{document}



% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.

