\subsection{Relations vs. Concepts}
We saw in Figure    \ref{fig:neuron_overlap} that the
storage of relations is generally well separated, but that
there are exceptions. We can view a relation as relating two
\textbf{concepts}, e.g.,     
\texttt{company\_ceo} relates instances of the ``subject'' concept
``company'' to instances of the ``object'' concept ``CEO''. From this
perspective, the exceptions in Figure
\ref{fig:neuron_overlap}, i.e., cases where a relation $r_1$
overlaps with a relation $r_2$, are 
generally cases where the concepts of $r_1$ and $r_2$  are
the same or overlap. For example, \texttt{company\_ceo}
and \texttt{company\_hq} have the same subject concept.

\enote{fy}{concept ? or argument ? or entity ?}
\enote{yl}{i guess here we need to be a a bit more consistent. I would interpret the "concept" as an abstract notion that many "entities" belong to, e.g., CEO. I am not sure if the "argument" here means something similar, or, it means the actual entity, e.g., "Jason Huang" (an actual CEO).}

To further explore this hypothesis empirically, 
we again use the method applied in
\secref{method} to relations, but now use it for
concepts; that is
we identify sets of
\textbf{concept-specific neurons}.
We group the LRE dataset 
triples by 
subject concept,
resulting in 11 different concepts. 
We create a set of triples with novel relations
such as ``can'' and ``has a'', balanced across
positive and negative
samples. This ensures that
the model's completion for a prompt like
(``Lincoln has a'') depends on the concept instance
(``Lincoln''), not on the relation (``has a'').


Figure \ref{fig:entity_neuron_overlap} shows the
overlap between relation neurons and concept neurons for 
13B. Most of the cells with large counts support our
hypothesis that 
the overlaps we observe are rooted in relations being
representationally associated  with their subject and
object concepts.
Clear examples include
\texttt{company\_ceo} and its subject concept
\texttt{company}; 
\texttt{company\_hq} and its object concept 
\texttt{city} (assuming that \texttt{hq} is a subcategory of
\texttt{city});
and \texttt{landmark\_continent} and its subject concept
\texttt{landmark}. There is little overlap of
\texttt{person} with relations like \texttt{person\_mother},
potentially because \texttt{person} is a more general and
semantically unspecific concept than the others. Note that
several concepts do not match a specific relation, e.g.,
\texttt{superhero}, and therefore are not strongly associated
with any relation. Recall that we picked the concepts
according to the availability of annotated data in LRE.
However, most
identified neurons
are only concept neurons or only relation neurons,
suggesting that
relational and conceptual representations are largely separate.

%general relational activation
%patterns are mostly disjunct of the concepts the subject
%stands in connection to.



%associated with a specific
%concept and those specialized in relations. Some overlap is
%observed in both models, particularly between the neuron
%experts of a concept and a relation applied on subjects from
%that concept, this can be for example observed between the
%concept \texttt{star} and the corresponding relation
%\texttt{star\_constellation}. Additionally, concepts more
%closely associated with the notion of location, such as
%\texttt{city} and \texttt{landmark}, exhibit overlap with
%location-related relations, including
%\texttt{landmark\_country} and \texttt{company\_hq}.  This
%pattern is comparatively more prominent in the 13b model,
%which aligns to the previously discussed drop of accuracy
%for location-based relations within this model, as shown on
%the right side in Figure \ref{fig:inter-relation}.

\enote{hs}{didn't udnerstand this. reintgrate?
This
shows the connection between \textbf{neuron versatility} and
the occurrence of a shared concept represented over a
certain group of neurons for different relations.}

\enote{lh}{the thought was to bring together findings from the section on neuron versatility and this section. In figure 4. there is accuracy drop in many relations around the notion of location upon an ablation of such a relation. There is a strong overlap between those relations (as shown in figure 13) and now we observe the same pattern around concepts concerned with locations here.}




%Introduction sentence & Motication

%- relations and concepts can be closely related
%  we saw it in our expoerimetn with realtions
%  now we can explain that
%  we see dditional evidence for that
%- person is a very general concept
%- we have concepts where indstances occur but not
%as intsance of tht concept
%- we subject contecpts vs object condtpetws (city)
%some realtion very speicfic to spdecif cocnpets
%an d they are stored togegther
%- star\_constellation

%and analyze their overlap
%with relation-specific neurons to determine potential
%dependencies between them.
%where the concepts of $r_1$ and $r_2$  are
%the same or overlap.




%Method


%The evaluation is performed on a test set derived from factually correct prompts in the LRE dataset.


%Overlap results 



\begin{figure}[tb]
    \centering
   \setlength{\abovecaptionskip}{-0.05cm}
   \setlength{\belowcaptionskip}{-0.5cm}
%\includegraphics[width=0.46\textwidth]{figs/entity_neurons/neuron_overlaps_top3000_llama-2-7b-hf.pdf}
\includegraphics[width=0.42\textwidth]{figs/entity_neurons/neuron_overlaps_top3000_13b_new.pdf}
    \caption{Overlap between the top 3000 neurons of
      relations and  concepts in the 13B model.}
    \label{fig:entity_neuron_overlap}
\end{figure}

