% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}
\usepackage{microtype}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage{listings}
\usepackage{url}
\usepackage{CJKutf8}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{supertabular}
\usepackage{subfigure}
\usepackage{dcolumn,booktabs}
\usepackage{tikz}
\usepackage{xspace}
\usepackage{authblk}
\usepackage{graphicx}

% Define colors for prompt table
\usepackage{xcolor}
\definecolor{forestgreen}{RGB}{34, 139, 34} 
\definecolor{darkmagenta}{RGB}{139, 0, 139} 

% If the title and author information does not fit in the area allocated, uncomment the following
%
\setlength\titlebox{5.5cm}
%
% and set <dim> to something 5cm or larger.

\title{On Relation-Specific Neurons in Large Language Models}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author[1,2,*]{\bf Yihong Liu}
\author[3,*]{\bf Runsheng Chen}
\author[1]{\bf Lea Hirlimann}
\author[1,2]{\\ \bf Ahmad Dawar Hakimi}
\author[1,2,4]{\bf Mingyang Wang}
\author[1,2]{\bf Amir Hossein Kargaran}
\author[5,$\dag$]{\\ \bf Sascha Rothe}
\author[6,$\dag$]{\bf François Yvon}
\author[1,2,$\dag$]{\bf Hinrich Sch\"utze}

\affil[]{Center for Information and Language Processing, LMU Munich \protect\\ $^{2}$Munich Center for Machine Learning (MCML) \protect\\ $^{3}$Technical University of Munich \  $^{4}$Bosch Center for Artificial Intelligence \protect\\ $^{5}$Google DeepMind, Zürich, Switzerland \ $^{6}$Sorbonne Université, CNRS, ISIR, France
 \protect\\ \texttt{\{yihong, hirlimann\}@cis.lmu.de} \ \ \ \ \ \ \ \texttt{runsheng.chen@tum.de}} 

% \affil[1]{Center for Information and Language Processing, LMU Munich} 
% \affil[]{Munich Center for Machine Learning (MCML)} 
% \affil[3]{Technical University of Munich}
% \affil[4]{Bosch Center for Artificial Intelligence}
% \affil[5]{Google DeepMind, Zürich, Switzerland}
% \affil[6]{Sorbonne Université, CNRS, ISIR, France
%  \protect\\ \texttt{\{yihong, mingyang\}@cis.lmu.de}} 

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\def\shortpar#1{\textbf{#1}}
\def\secref#1{\S\ref{sec:#1}}
\def\seclabel#1{\label{sec:#1}}
\newcommand{\tempcitation}{[\textbf{citation}]\xspace}

\newcounter{notecounter}
\newcommand{\enotesoff}{\long\gdef\enote##1##2{}}
\newcommand{\enoteson}{\long\gdef\enote##1##2{{
\stepcounter{notecounter}
{\large\bf
\hspace{0cm}\arabic{notecounter} $<<<$ ##1: ##2
$>>>$\hspace{1cm}}}}}

\enoteson
\enotesoff


\begin{document}
\maketitle

\def\thefootnote{*}\footnotetext{Equal contribution.}\def\thefootnote{\arabic{footnote}}
\def\thefootnote{$\dag$}\footnotetext{Equal advising.}\def\thefootnote{\arabic{footnote}}

\begin{abstract}

% In large language models (LLMs), certain neurons can store distinct pieces of knowledge learned during pretraining. While knowledge typically appears as a combination of relations and entities, it remains unclear whether some neurons focus on a relation itself -- independent of any entity. We hypothesize such neurons detect a relation in the input text and guide generation involving such a relation. To investigate this, we study the Llama-2 family on a chosen set of relations with a statistics-based method. Our experiments demonstrate the existence of relation-specific neurons. We measure the effect of selectively deactivating candidate neurons specific to relation $r$ on the LLM's ability to handle (1) facts whose relation is $r$ and (2) facts whose relation is a different relation $r' \neq r$. With respect to their capacity for encoding relation information, we give evidence for the following three properties of relation-specific neurons.
% (i) Neuron cumulativity.
% The neurons for $r$ present a cumulative effect so that deactivating a larger portion of them results in the degradation of more facts in $r$.
% (ii) Neuron versatility.
% Neurons can be shared across multiple closely related as well as less related relations. Some relation neurons transfer across languages.
% (iii) Neuron interference.
% Deactivating neurons specific to one relation can improve LLM generation performance for facts of other relations.


In large language models (LLMs), certain \emph{neurons} can store distinct pieces of knowledge learned during pretraining. 
While knowledge typically appears as a combination of \emph{relations} and \emph{entities}, it remains unclear whether some neurons focus on a relation itself -- independent of any entity. 
We hypothesize such neurons \emph{detect} a relation in the input text and \emph{guide} generation involving such a relation.
To investigate this, we study the Llama-2 family on a chosen set of relations with a \textit{statistics}-based method.
Our experiments demonstrate the existence of relation-specific neurons.
We measure the effect of selectively deactivating candidate neurons specific
to relation $r$ on the LLM's ability to handle (1) facts 
whose relation is $r$ and (2) facts whose relation is a
different relation $r' \neq r$.
%We have the following hypotheses based on our findings.
%\enote{hs}{i am confused whether these are hypotheses or findings
%-- you worded them as findings  so that's what i called
%   them}
%\enote{yh}{i think the ``properties'' that you name is good}
With respect to their capacity for encoding relation
information, we give evidence for the following three properties
of relation-specific neurons.
\textbf{(i) Neuron cumulativity.}
The neurons for $r$ present a cumulative effect so that deactivating a larger portion of them
results in the degradation of more facts in $r$.
% Within the same relation, facts are differentially sensitive to the neurons, with some facts degrading after the deactivation of a few neurons while others remain robust until many more are deactivated.
\textbf{(ii) Neuron versatility.}
Neurons can be shared across multiple closely related as
well as less related relations. 
Some relation neurons transfer across languages.
\textbf{(iii) Neuron interference.} 
%Not all neurons are necessary for processing a given
%relation; in fact, d
Deactivating neurons specific to one relation can  improve
LLM generation performance for facts of other relations.
We will make our code publicly available at \url{https://github.com/cisnlp/relation-specific-neurons}.
\end{abstract}

% at \url{url}.

\enote{hs}{Yihong and I discussed
neuron sensitivity and we think we need to modify this part
of the paper.
The intuition is that for the storage of each fact $i$, $k$
relation neurons are involved. This could be either
redundant storage (each of the $k$ relation neurons by
itself can produce the fact) or ``cumulative'' storage (you
need a large enough subset of the $k$ to produce the
fact). We're thinking about additional experiments to
show that it's cumulative. We will also then need a name
as a replacement for ``neuron sensitivity''.}
\enote{yl}{I changed the term to neuron cumulativity}
\enote{fy}{the formulation of cumulativity remains a bit unclear - what are ``these neurons''? }
\enote{yl}{``these neurons'' are relation-specific neurons. i added "relation-specific neurons" in the preceding sentence so i guess it would be more clear.}

\section{Introduction}

Large text corpora like Wikipedia contain abundant
factual knowledge. LLMs, pretrained
on such corpora, can function as knowledge bases that
retrieve information and generate text involving factual
content \citep{petroni-etal-2019-language,jiang-etal-2020-know}.
Recent studies suggest that some knowledge is parameterized
by
LLMs \citep{dai-etal-2022-knowledge,geva-etal-2023-dissecting},
especially within the feed-forward layers of the Transformer
architecture
\citep{transformer2017vaswani}, which act as
key-value memory \citep{geva-etal-2021-transformer}.
Factual knowledge is often expressed as a relational fact in
triple form: \emph{subject}, \emph{relation},
and \emph{object}, e.g.,
(\texttt{NVIDIA}, \texttt{company\_ceo}, \texttt{Jensen
Huang}).  However, it remains unclear whether each fact is
stored and processed separately through \emph{knowledge
neurons} \citep{dai-etal-2022-knowledge}, or if there
exist \emph{relation-specific neurons} that focus on the
relation itself and guide generating the object once
the subject and relation of a triple have been
detected. 

In this work, we examine the existence of relation-specific
neurons in decoder-only LLMs.  Our study focuses on the
Llama-2 family (7B and
13B) \citep{touvron2023llama2openfoundation} and examines
factual knowledge grouped into 12 types of relations. To
pinpoint relation-specific neurons for these relations, we adopt the neuron identification
method proposed by \citet{neuron2022Cuadros}, which
identifies the neurons that are uniquely activated in one
group of sentences (positive examples) while not in another
(negative examples). \citet{kojima-etal-2024-multilingual}
successfully applied this method to uncover
\emph{language-specific neurons}.
% -- neurons that
% activate in one language but not in other
% languages. 
Following this line of work, we construct
zero-shot prompts featuring a specific relation for the
positive examples and prompts with other relations for the
negative examples. 
Neurons whose activation patterns are positively correlated with positive examples are regarded as relation-specific neurons.
% The statistically activated neurons in
% LLMs for positive examples are regarded as relation-specific
% neurons.
\enote{fy}{Statistically activated ?}
\enote{yl}{Statistically activated refers to the phenomena where the neurons are mostly always activated in the positive examples. i guess ``Statistically activated'' is not a good term?}
\enote{fy}{My suggestion: Neurons whose activation patterns are positively correlated with positive examples are regarded as relation-specific neurons.}
\enote{yl}{sounds good to me, updated.}

To understand the impact of these neurons, we perform
question-answering on new held-out prompts.  These prompts
for each relation share the same relation as the positive
examples used for identification but have no entity
overlap; this disentangles the effects of entities
and relations.  
For each relation, we compare performance
between the original model and the model in which the
% relation-specific
neurons for that relation are deactivated
-- intra-relation results.  We also study how deactivating
the neurons for one relation influences performance on other
relations -- inter-relation results.  Our experiments reveal
several key properties of these neurons:
% relation-specific neurons:
% with respect to how they
% store factual knowledge.

\textbf{Neuron cumulativity}.
These neurons present a cumulative effect so that deactivating a larger portion of them
results in the degradation of more facts, suggesting LLM  distributes relational knowledge
across neurons in a manner that can vary significantly from fact to fact.
This property aligns with the evidence of the existence of redundant or self-repair neurons \citep{dalvi-etal-2020-analyzing,mcgrath2023hydraeffectemergentselfrepair,he2024matterstransformersattentionneeded}.
Our analysis suggests the frequency of a fact in the pretraining data is associated with its sensitivity to a given subset.
% Different facts can exhibit varying sensitivity
% Within the same relation, different facts can exhibit varying sensitivity to relation-specific neurons -- some degrade after the deactivation of a few neurons while others remain robust until many more are deactivated. 
% Our analysis suggests that the effect may be associated with the frequency of the fact in the pretraining data.
\enote{fy}{Here, 'sensitivity' is back}
\enote{yl}{yes, because i want to refer to the phenomena where we find some facts are sensitive to a given set of neurons while some are not -- shown in \secref{frequency}; such a ``sensitivity'' is related to the frequency; do you think we should not mention sensitivity at all? or do you have other good ways of expressing this in mind?}

\textbf{Neuron versatility}. 
Because the total number of neurons is finite while the
number of possible relations is vast, some neurons strongly
associate with multiple relations.  Surprisingly, these
relations need not be closely linked -- two ``less related''
relations can share a group of neurons, leading to
performance drops in both relations if those neurons are
deactivated. 
Such neurons also generalize across
languages. This property aligns with recent
findings showcasing that some neurons are shared across
languages and
tasks \citep{wang2024sharing,tang-etal-2024-language,kojima-etal-2024-multilingual}.

\textbf{Neuron interference}. 
Some relation-specific neurons appear to ``confuse'' the
model when it processes other relations. Deactivating such
neurons can yield improved performance on these other
relations. This property aligns with broader evidence
that \emph{sub-networks} or \emph{circuits} within LLMs may
serve several
different  functional roles \citep{wang2023circuit,bayazit-etal-2024-discovering,mondorf2024circuit}.

% the following to be restored maybe? for saving space

% To the best of our knowledge, this is the first study
% that investigates the existence of \emph{relation-specific neurons} inside LLMs -- disentangled from the influence of entities and analyzes the impact of these neurons on how LLMs process a variety of relations.
% Our findings offer novel insights into the internal mechanisms underlying LLMs’ handling of relational facts and therefore significantly contribute to the interpretability of these models.

\section{Methodology}\seclabel{method}

\subsection{Dataset Manipulation}\seclabel{manipulation}

We use the factual knowledge dataset from \citet{lre2024Hernandez} for this research, which contains 25 relations. Each relation has a different number of facts. Each fact can be represented as a \emph{subject-relation-object} triple $(s, r_i, o)$.
\enote{fy}{What does $k$ index? is this the kth subject for $r_i$, so should it be be $s_{i,k}$?}
\enote{yl}{i just realized i delete something here that may result in confusion; originally here $k$ refers to the $k$th pair of subject-object in relation $r_i$. maybe we just remove $k$, so $(s, r_i, o)$ because $k$ is used again as the number of neurons.}
We only consider relations that have more than 300 facts
to ensure the reliability of our findings.
% \footnote{Enough pairs are needed to act as positive examples, otherwise the method is not robust \citep{neuron2022Cuadros}.}
This results in \textbf{12} relations. We refer to the set of triples for relation $r_i$ as $\mathcal{D}_{r_i}$.
We then perform the following steps for each relation $r_i$ to construct the data used to identify its relation-specific neurons.

\shortpar{Step 1: Creating Evaluation Data.} For each triple set $\mathcal{D}_{r_i}$, we randomly select \textbf{50 triples} as a held-out set for evaluation.
(cf. \secref{controlled}). 
We refer to the selected triples as $\mathcal{D}_{r_i}^{\text{eva}}$ (for evaluation) and the remaining triples as $\mathcal{D}_{r_i}^{\text{det}}$ (for detection). 

\shortpar{Step 2: Formulating Prompts.} For each triple $(s, r_i, o)$ in $\mathcal{D}_{r_i}^{\text{det}}$, we create prompts concerning the subject $s$ and the relation $r_i$ using the templates provided by \citet{lre2024Hernandez}. For example, we construct a zero-shot prompt ``\texttt{The CEO of NVIDIA is? Answer:}'' for the triple $(\texttt{NVIDIA}, \texttt{company\_CEO}, \texttt{Jensen Huang})$ with an expected answer ``\texttt{Jensen Huang}''.
% \footnote{A few demonstrations can be used in the prompt and can lead to better accuracy. However, additional information is introduced and therefore the neuron identified can also be related to this information. We show such analysis in \secref{shots}.} 
We also create prompts for $\mathcal{D}_{r_i}^{\text{eva}}$ in the same way. We refer to the resulting prompt sets as $\mathcal{P}_{r_i}^{\text{det}}$ and $\mathcal{P}_{r_i}^{\text{eva}}$.

\shortpar{Step 3: Validating Prompts.} We hypothesize that the model will leverage relation-specific neurons to generate the correct answer, i.e., the object.
% for a prompt containing a specific relation. 
Therefore, such neurons should be ``fired'' in those prompts for which \textbf{the model answers correctly}.
% \footnote{Of course, if the model cannot answer correctly, we cannot say the relations-specific neurons are not ``fired''.}
% Slightly different from previous Similar to the setup used by 
% \textbf{cite one or two papers that do this} 
% \citet{wendler-etal-2024-llamas}, 
We feed the prompt to the model and set the maximum length of the generation to be 2. 
We then check if the generated tokens are the same as the object (first two tokens): 
% compare the first \textbf{two} token generated: 
if they are the same, we regard the output as being correct. 
We exclude prompts that the model answers wrongly from $\mathcal{P}_{r_i}^{\text{det}}$.

%\enote{hs}{but you don't exclude them from
%$\mathcal{P}_{r_i}^{\text{eva}}$ ? }
%\enote{yh}{no, $\mathcal{P}_{r_i}^{\text{eva}}$ is kind of approximate a ``test set'', so we kind of want no prior knowledge of the accuracy on it.}


\subsection{Relation-Specific Neuron Identification}\seclabel{identification}
Following \citep{neuron2022Cuadros}, we identify the relation-specific neurons using statistical association measures. This method
% We adopt the statistics-based method proposed by \citep{neuron2022Cuadros} to identify the relation-specific neurons. The method 
assigns a score for each neuron, representing its level of ``expertise'' in distinguishing a specific relation from others.

\shortpar{Defining Neurons.} A neural network, or specifically a Transformer \citep{transformer2017vaswani}, consists of many weight matrices. 
For a single weight matrix $\boldsymbol{W}\in\mathbb{R}^{d_1\times d_2}$, we define a neuron as a column, 
% in the matrix,
mapping a representation from $\mathbb{R}^{d_1}$ to $\mathbb{R}$.
% Therefore, there are $d_2$ neurons in $\boldsymbol{W}$.
% \enote{fy: not so obvious that a d1-dimensional vector is a also a mapping from $R^{d1}$ into R. A vector is a vector, no? I understand that the typical use in a FF is to input a $(1 \times d_1)$ vector, and obtain $d_2$ activations, but perhaps it would be clearer to say: "column the matrix; each neuron $W_{.,j}$ can be viewed as a mapping from $R^{d_1}$ to $\mathbb{R}$ computing the neuron's activation on input $v$ as $v^T W_{.,j}$.}
% Following \citet{neuron2022Cuadros} and \citet{kojima-etal-2024-multilingual}, 
We assign a unique index $m \in M$ to each neuron and investigate its output value.
We only consider the neurons in \textbf{feed-forward networks (FFNs)}, i.e., neurons in \texttt{up\_proj}, \texttt{gate\_proj}, and \texttt{down\_proj}, since previous studies have shown that knowledge is mostly stored there \citep{dai-etal-2022-knowledge}.
\enote{fy}{perhaps \texttt{up\_proj} would look better.}
\enote{yl}{sure, updated.}

\shortpar{Grouping Prompts.} For each relation $r_i$, we collect positive and negative examples. Specifically, we regard $\mathcal{P}_{r_i}^{\text{det}}$ as positive examples and randomly sample $4 \times |\mathcal{P}_{r_i}^{\text{det}}|$ prompts from 
% $\bigcup_{\forall j\neq i} \mathcal{P}_{r_j}^{\text{det}}$, i.e., the prompt 
the prompt sets of other relations as negative examples.\footnote{We also sample negative examples with different seeds in our preliminary experiments. The neurons for each relation show little change, suggesting the stability of the neurons.}
% \footnote{Note that we do not sample from $\mathcal{P}_{r_j}^{\text{det, c}}$ for other relations since the correctness of answering prompts does not influence the fact that these prompts have nothing to do with relation $r_i$.} 
For simplicity, the positive and negative examples selected for relation $r_i$ are referred to as $\mathcal{E}^{+}_{{r_i}}$ and $\mathcal{E}^{-}_{{r_i}}$ respectively.
The final data used to detect the relation-specific neurons for relation ${r_i}$ is then $\mathcal{E}_{r_i} = \mathcal{E}^{+}_{r_i} + \mathcal{E}^{-}_{r_i}$. 
For each individual example $e^{j}_{r_i}$, we assign a binary label $b^{j}_{r_i}$ to it: 1 if $e^{j}_{r_i} \in \mathcal{E}^{+}_{r_i}$ and 0 otherwise.

\enote{fy}{So there is the activation value (for a token) and the output value (average over tokens). As both terms are use we may need to clarify ?}
\enote{yl}{we actually do not use the real activation value -- just the output of a neuron. we observe the value for each token in the prompt and then average the output values, regarded as the output value for a prompt.}

\shortpar{Neuron Output Values.}
Let $o^{m,j,n}_{r_i}$ be the output value of neuron $m$ for the $n$-th token in $e^{j}_{r_i}$ when feeding the example to the model. 
Following \citet{kojima-etal-2024-multilingual}, we average the outputs over tokens to form the final output value of neuron $m$ for the entire example $e^{j}_{r_i}$: $o^{m,j}_{r_i} = \frac{1}{T} \sum_{n=1}^{T} o^{m,j,n}_{r_i}$, where $T$ is the number of effective tokens in $e^{j}_{r_i}$ -- the output values of [PAD] tokens are regarded as noise and therefore ignored in the computation.

\shortpar{Computing Experts.}
The level of expertise of each neuron for relation ${r_i}$ is computed by formulating a classification task. 
Specifically, we regard the output value $o^{m,j}_{r_i}$ as the prediction score with $e^{j}_{r_i}$ as input and $b^{j}_{r_i}$ as its ground-truth label.
In this way, for an individual neuron $m$, we have the following data: $\{o^{m,j}_{r_i}, b^{j}_{r_i}\}_{j=1}^{|\mathcal{E}_{r_i}|}$.
We then measure this neuron's performance by setting all output values as classification thresholds and comparing the predictions with the ground truth labels.
Average precision ($AP$) is used as the metric (the area under the precision-recall curve).
By doing this, we obtain $AP^m_{{r_i}}$ for all $m \in M$, allowing us to rank them by their level of expertise in differentiating relation ${r_i}$ from others. 
The top $k$ neurons are regarded as relation-specific neurons in descending order.

\enote{hs}{i don't think that AP and area under the
precision recall curve are the same -- i assume this is from
the original apper where they also equated the two?}
\enote{yl}{The original paper has the following claim: ``We can measure the performance of neuron $m$ for the task using its average precision ($AP_m = AP(z_m, b) \in [0, 1]$), which is the
area under the precision-recall curve with different
prediction thresholds.'', and we checked on wiki:%{https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision}
}

\subsection{Controlled Generation}\seclabel{controlled}

For each relation ${r_i}$, we want to investigate the impact of the identified top-$k$ relation-specific neurons. Therefore, we control text generation by overriding the
output values with 0 during inference, aiming to deactivate or suppress these neurons.
% \footnote{Our preliminary experiments show that it does not make much difference by leveraging 0 or the median value observed in negative examples, so we use 0 by default in our study.} 
Specifically, we feed
$\mathcal{P}_{r_i}^{\text{eva}}$,
the prompts from the held-out evaluation prompt set for relation $r_i$, into the model. During inference, we simply set the output values of all top-$k$ relation-specific neurons for $r_i$ to a constant 0 and let the model generate two tokens, regarded as the model's answer to the question. The answer is then compared to the first two tokens of the correct answer, i.e., the object.

\section{Experimental Setup\label{sec:exp_setup}}

\begin{table}
% \setlength{\abovecaptionskip}{0cm}
\setlength{\belowcaptionskip}{-0.4cm}
\footnotesize
\centering
\setlength{\tabcolsep}{0.8mm}{}
\begin{tabular}{lrrr}
\toprule
Model & \#Layers & \#Neurons (FFNs) & \#Neurons (total)\\
\midrule
Llama-2-7B & 32 & 835,584 & 1,359,872 \\
Llama-2-13B & 40 & 1,310,720 & 2,129,920 \\
\bottomrule
% \bottomrule
\end{tabular}
\caption{LLama-2 model statistics}\label{tab:model_info}
\end{table}


\subsection{Models}

We consider the 7B and 13B models from the LLama-2 family \citep{touvron2023llama2openfoundation}. 
% Llama-2 models are pretrained on 2 trillion tokens of data, around 90\% of which is from English. From this point of view, LLama-2 models are English-centric LLMs. However, despite a small
% percentage of non-English data, the absolute number of tokens in other languages is still abundant. For example, there are 3.4B German tokens, 3.2B French tokens, and 2.6B Chinese tokens. Therefore, LLama-2 models are still considered multilingual LLMs.
As mentioned in \secref{identification}, we consider the neurons in \textbf{FFNs} 
% (containing up\_proj, gate\_proj, and down\_proj matrices), 
which account for more than half of neurons in both 7B and 13B, as shown in Table \ref{tab:model_info}. We also report our preliminary results when considering other types of neurons (e.g., \texttt{up\_proj}) in \secref{neuron_type}. 
% In the main content, by default, the results of using FFNs are reported. 

\begin{figure*}
    \centering
    \setlength{\abovecaptionskip}{-0.2cm}
    \setlength{\belowcaptionskip}{-0.2cm}
    \begin{tabular}{c}
    % \hspace{-0.3cm}
    \includegraphics[width=0.48\textwidth]{figs/perf_test.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.48\textwidth]{figs/perf_train.pdf}
    \end{tabular}
    \caption{Intra-relation results. The left (resp.\  right)
    figure displays the results of held-out evaluation prompt
    set $\mathcal{P}_{r_i}^{\text{eva}}$
    (resp.\  identification prompt set
    $\mathcal{P}_{r_i}^{\text{det}}$). We report the
    performance of the original model (without any
    deactivation), e.g., \texttt{7b-original}, the model
    with 3,000 random neurons deactivated (averaged over 10 seeds), e.g., \texttt{7b-random}, and the model with relation-specific neurons deactivated, e.g., \texttt{7b-relation}.}
    \label{fig:intra-relation}
\end{figure*}

\subsection{Datasets}\seclabel{datasets}

We manipulate the relational knowledge datasets from \citet{lre2024Hernandez} using the procedure described in \secref{manipulation}. 
Recall that we cover 12 relations in our experiments.
Prompt sets $\mathcal{P}_{r_i}^{\text{det}}$ (for 
% relation-specific
neuron identification) and $\mathcal{P}_{r_i}^{\text{eva}}$ (for evaluation) are constructed for each relation.
$|\mathcal{P}_{r_i}^{\text{det}}|$ varies for different
relations.\footnote{$|\mathcal{P}_{r_i}^{\text{det}}|$ can
be different for 7B and 13B models because the number of
prompts excluded in the validating prompt step (described
in \secref{manipulation}) can be different.} 
$\mathcal{P}_{r_i}^{\text{eva}}$ is constructed by randomly selecting \textbf{50 triples} for each relation.
Since these 50 triples are not used when creating $\mathcal{P}_{r_i}^{\text{det}}$, this setup ensures \textbf{no subject overlap between $\mathcal{P}_{r_i}^{\text{det}}$ and $\mathcal{P}_{r_i}^{\text{eva}}$ for the same relation $r_i$}. 
In addition, we ensure \textbf{minimal subject overlap across relations} 
(mostly 0 
% or less than 10 
between $\mathcal{P}_{r_i}^{\text{det}}$ and $\mathcal{P}_{r_j}^{\text{det}}$). The only exception is between \texttt{person\_mother}
and \texttt{person\_father}, which share a lot of subjects.
A detailed entity overlap analysis 
% across relations
is presented in \secref{entity_overlap}.
% , allowing us to focus solely on the effect of relation.

\begin{figure}
    \centering
    % \setlength{\abovecaptionskip}{-0.02cm}
    \setlength{\belowcaptionskip}{-0.2cm}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/company_ceo_limited_3000_top_mlp.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/company_hq_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/landmark_continent_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/landmark_country_limited_3000_top_mlp.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/person_father_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/person_mother_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/person_occupation_limited_3000_top_mlp.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/person_plays_instrument_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/person_pro_sport_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/person_sport_position_limited_3000_top_mlp.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/product_company_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-7b-hf/star_constellation_limited_3000_top_mlp.pdf}
    \caption{Distribution of relation-specific neurons
    across layers. Most 
    % identified relation-specific neurons 
    are located in the middle layers.}
    \label{fig:layer_dist}
\end{figure}

\section{Results and Discussion}\seclabel{results}

We apply our identification method to both 7B and 13B models
for all 12 relations. We regard the \textbf{top 3,000}
neurons with the highest $AP$ values as the
relation-specific neurons, as for this threshold,
we achieve good coverage of relation-specific neurons with a
set of neurons that is not too large. 
We discuss the impact of this meta-parameter 
% how different thresholds influence the effectiveness 
in~\secref{neuron_number}.

\subsection{Identified Relation-Specific Neurons}\seclabel{neurons}

\shortpar{Distribution Across Layers.} We display the distribution of relation-specific 
neurons across layers in the 7B model in Figure~\ref{fig:layer_dist} (see \secref{13b_analysis} for the 13B model).
Most neurons are located in the model's \textbf{middle layers}. Such a distribution differs from language-specific neurons, which are mostly located in the first and last few layers \citep{kojima-etal-2024-multilingual}.
% We hypothesize that relational knowledge requires structured, conceptual understanding rather than surface-level input and output weight matrices, which encode language specificities.
We hypothesize that relational knowledge requires more than surface-level information that is mainly encoded and processed in the first and last few layers.
\enote{fy}{not a big fan of "conceptual understanding" - the previous sentences mixes multiples notions (structure, understanding) while we really talk about is weight vectors. The following text is clearer.}
\enote{yl}{yes, but usually the weight vectors in the first layers and the final layers are regarded to capture the surface-level information. i updated the sentence above and removed talking too much about the less relevant notions.}
Therefore, these relation-specific neurons naturally emerge in the middle layers, where the model has integrated enough lexical and syntactic signals to model and process the relation. This finding is consistent with several studies that show that mapping vectors with certain functions can be extracted from the middle layers \citep{merullo-etal-2024-language,lre2024Hernandez,Todd2024functon}.

\shortpar{Overlap Across Relations.} 
We display the overlap of relation-specific neurons across relations for the 7B model in Figure \ref{fig:neuron_overlap} (
% the corresponding graph for the
13B is in \secref{13b_analysis}). 
We see that \texttt{person\_mother}
and \texttt{person\_father} share a large share of neurons,
possibly due to the large overlap between their subjects, 
(see in \secref{entity_overlap}).
However, even though there is almost no subject overlap between any other relations, 
% for other pairs of relations
% even though there are ver
many relations still share some neurons with others. 
% Among them, \texttt{person\_mother}
% and \texttt{person\_father} share substantial neurons,
% possibly due to the large subject overlap 
% as shown in \secref{entity_overlap}.
% On the other hand, we can also observe that a relation can
% share some neurons with other relations even though they do
% not share any entity overlap,
For instance, \texttt{person\_occupation}
and \texttt{person\_sport\_position} share $297$ neurons, possibly because they are similar relations -- a sport is
roughly also an occupation.
\enote{hs}{but i would very strongly assume that there is a
lot of entity overlap!!!}
\enote{yl}{actually no... Figure \ref{fig:subject_object_overlap_7b} shows that no subject is shared, the distinct subjects for \texttt{person\_occupation}
and \texttt{person\_sport\_position} are $323$ and $384$ respectively.}
Extensive neuron overlap can also be observed when two relations are mapping \textbf{from the same type of subjects}, e.g., \texttt{company\_ceo} and  \texttt{company\_hq}, or mapping \textbf{to the same type of objects}, e.g., \texttt{company\_ceo} and  \texttt{person\_father}.
However, we show in \secref{inter_results} that a high neuron overlap does not necessarily imply a high level of mutual interference.
% obvious influence on one relation when the neurons of the other relation are deactivated.
\enote{fy}{the previous sentence is hard to process - can you not just say "does not necessarily imply that a high level of interference". And leave it for the next sections to discuss how interference is measured through deactivation ?}
\enote{yh}{good point, i updated the sentence above -- i added the word "mutual", which might be more accurate.}
% Therefore, we hypothesize there are a few atom neurons in LLMs that are responsible for some basic functionality and therefore are shared for dealing with some related relations. 

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{-0.2cm}
    \setlength{\belowcaptionskip}{-0.5cm}
    \includegraphics[width=0.45\textwidth]{figs/neuron_overlaps_top_3000_mlp_7b.pdf}
    \caption{Overlap of the relation-specific neurons across 12 relations. For example, 2053 indicates the number of neurons shared between the 3,000 identified neurons for \texttt{person\_father} and the 3,000 for \texttt{person\_mother}.}
    \label{fig:neuron_overlap}
\end{figure}

\begin{figure*}
    \centering
    \setlength{\abovecaptionskip}{-0.1cm}
    \setlength{\belowcaptionskip}{-0.5cm}
    \begin{tabular}{c}
    % \hspace{-0.3cm}
    \includegraphics[width=0.47\textwidth]{figs/accuracy_drops_heatmap_llama-2-7b-hf_top_3000_mlp_zero.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.47\textwidth]{figs/accuracy_drops_heatmap_llama-2-13b-hf_top_3000_mlp_zero.pdf}
    \end{tabular}
    \caption{Inter-relation results for the 7B model (left)
    and the 13B model (right). The number in cell $(r_i, r_j)$ indicates the accuracy drop of relation $r_i$ when deactivating the relation-specific neurons of relation $r_j$.}
    \label{fig:inter-relation}
\end{figure*}

\subsection{Controlled Generation}\seclabel{generation}

For each relation, we set the output values of its identified 3,000 relation-specific neurons to 0, and observe how the deactivation impacts the relation itself and other relations in terms of accuracy.

\subsubsection{Intra-Relation Results}\seclabel{intra_results}
In addition to intra-relation results, i.e., deactivating the 3,000 identified relation-specific neurons for a relation and evaluating the same relation, we also create a baseline by \textbf{randomly} deactivating 3,000 neurons in the model. We report the results of the original models, the results of the baseline, and the intra-relation results in Figure \ref{fig:intra-relation}.

We can observe a clear performance drop on the identification prompt set $\mathcal{P}_{r_i}^{\text{det}}$ when comparing the accuracy of the original model and the model whose relation-specific neurons are deactivated.\footnote{For some relations, the drop is moderate, e.g., \texttt{product\_company}. We show in \secref{neuron_number} that the drop can become noticeable when we deactivate more than 3,000 neurons.} 
On the other hand, the model with randomly 3,000 deactivated neurons does not show much difference compared with the original model,
indicating the 3,000 relation neurons are closely associated with the facts included in  $\mathcal{P}_{r_i}^{\text{det}}$.
% These findings indicate that the identified 3,000 neurons for each relation are closely associated with the factual knowledge included in its identification set $\mathcal{P}_{r_i}^{\text{det}}$. 
% \enote{hs}{don't you need to say something here about the
% relations where there doesn't seem to be a big drop if the
% 3000 neurons are deactivated?}
% \enote{yl}{I added a footnote above.}
On the evaluation set $\mathcal{P}_{r_i}^{\text{eva}}$, we also observe a notable accuracy drop across models for most relations. Since $\mathcal{P}_{r_i}^{\text{eva}}$ and $\mathcal{P}_{r_i}^{\text{det}}$ do not share any entities, the accuracy drop can only be attributed to the fact that deactivating 3,000 neurons affects the relation itself -- the common characteristic between $\mathcal{P}_{r_i}^{\text{eva}}$ and $\mathcal{P}_{r_i}^{\text{det}}$. Therefore, we argue that \textbf{relation-specific neurons do exist in LLMs}. These neurons are entity-irrelevant, rather, they focus on a specific relation. 
% detecting that relation in the input text and guiding the generation of an object when a particular subject is present.

\enote{hs}{above: sounds very good! but let's discuss to
make sure this is really ironclad}
\enote{yl}{we will add the cumulative effect results (deactivating new 2000 neurons) in \secref{neuron_number}. Lea will add a subsection in Analysis about the entity type.}

On the other hand, the accuracy does not drop to 0 for any relation (except \texttt{landmark\_country} in the 13B model) when its identified relation-specific neurons are deactivated. 
This indicates these 3,000 neurons do not equally influence all facts that belong to a certain relation.
We therefore have the \textbf{neuron cumulativity} hypothesis: 
The relation-specific neurons are associated with different facts belonging to the concerned relation.
These neurons present a cumulative effect so that deactivating a small number of them (in this case, 3,000) results in the degradation of some (not all) facts, whereas more facts are affected when a larger portion is disabled.
% different facts exhibit varying degrees of reliance on the same population of relation-specific neurons. 
% Some facts degrade when a small number of these neurons are deactivated (in this case, 3,000), whereas others remain robust unless a larger portion is disabled. 
This disparity highlights that LLMs do not uniformly encode all facts that belong to a given relation, but rather distribute relational knowledge across neurons in a manner that can vary significantly from fact to fact.
We validate this by demonstrating that the accuracy further
drops by deactivating more neurons
in \secref{neuron_number}. We also show that the sensitivity of a fact to a given population of neurons may correlate with how frequently the fact appears in the pretraining data in \secref{frequency}.

\subsubsection{Inter-Relation Results}\seclabel{inter_results}

To understand the effect of how these neurons influence the model's ability to answer 
% zero-shot 
prompts across multiple relations, we use \textbf{accuracy drop} as a metric:
$\text{acc\_drop}_{r_i, r_j} = \frac{\text{acc}^\text{original}_{r_i} - \text{acc}^{\text{deactivated-}{r_j}}_{r_i}}{\text{acc}^\text{original}_{r_i}}$,
where $\text{acc}^\text{original}_{r_i}$ is the accuracy of the original model for $\mathcal{P}_{r_i}^\text{eva}$ and $\text{acc}^{\text{deactivated-}{r_j}}_{r_i}$ is the accuracy for $\mathcal{P}_{r_i}^\text{eva}$ when the relation-specific neurons of $r_j$ are deactivated.
Results are displayed in Figure \ref{fig:inter-relation}. 

\begin{figure*}
    \centering
    \setlength{\abovecaptionskip}{-0.05cm}
    \setlength{\belowcaptionskip}{-0.5cm}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/company_ceo.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/company_hq.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/landmark_continent.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/landmark_country.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/person_father.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/person_mother.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/person_occupation.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/person_plays_instrument.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/person_pro_sport.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/person_sport_position.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/product_company.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-7b-hf/star_constellation.pdf}
    \caption{Influence of deactivating different numbers of relation-specific neurons for each relation. The variation of accuracy on the relation itself and the average accuracy on other relations is shown. Increasing the number clearly affects the relation itself, but the effect on other relations is obvious only until 3,000 or 10,000 neurons.}
    \label{fig:neuron_num}
\end{figure*}


When we compare the 7B and 13B models, no consistent pattern emerges across relations.
This indicates that, though being trained on the same data, 
differences in model size and parameter initialization appear to substantially change the functionality of neurons. 
% In particular, the 13B model tends to show fewer accuracy drops when neurons of other relations are deactivated, likely because its larger parameter space allows more distributed representations of different relations.
In particular, most relations in the 13B model are less influenced when neurons of other relations are deactivated than in the 7B model except in the following cases:
\enote{fy}{Is this so clear visually ? I see more red in for the 13B model than for the 7B. Can we measure this more precisely?}
\enote{yl}{yeah, it might not be very clear. but when we "remove" the relations in the following examples, we generally see a relation is less influenced by the deactivation of others in 13B model.
I updated the sentence above.
}
deactivating neurons of \texttt{landmark\_country} strongly affects several other relations concerning the notion of ``location''; \texttt{person\_mother} and \texttt{person\_occupation} are sensitive to the deactivation of neurons of other relations. 
Despite these divergences, we propose two hypotheses that hold across both models.

\shortpar{Neuron versatility.}
We observe that deactivating relation-specific neurons for one relation can strongly affect not only that relation but also others, whether they are \textbf{``closely'' or only ``loosely'' related}. 
For example, disabling \texttt{person\_pro\_sport} neurons has a large effect on \texttt{person\_sport\_position} (but not vice versa) in both 7B and 13B models, likely because the model first needs to understand ``sport'' before inferring ``position''. 
Similarly, deactivating \texttt{person\_father} neurons reduces accuracy on \texttt{person\_mother}, as both share the concept of an immediate parental relationship. 
Even more loosely related relations can exhibit a clear accuracy drop: deactivating \texttt{star\_constellation} neurons affects \texttt{landmark\_continent} in both models, possibly because both involve the abstract notion of ``location''.

\shortpar{Neuron interference.}
Deactivating the relation-specific neurons of one relation can sometimes \textbf{improve} the accuracy for other relations -- a phenomenon more pronounced in the 7B model, likely because its smaller parameter space is less capable of isolating different relations. 
In the 7B model, several relations frequently benefit from this effect: for instance, \texttt{person\_mother} improves when neurons from 5 out of 11 other relations -- mostly ``less related'' ones -- are deactivated. 
This effect is also observed for closely related relations: disabling \texttt{company\_ceo} neurons offers a small accuracy boost to \texttt{company\_hq} for both models, while deactivating \texttt{landmark\_country} neurons benefits \texttt{landmark\_continent} in the 7B model. Interestingly, the 13B model shows the opposite effect for \texttt{landmark\_continent} when disabling \texttt{landmark\_country}, implying that country information can help predict a continent for the larger model. 
These findings indicate that neuron interference happens across model sizes, but its specific patterns vary -- potentially due to factors such as parameter initialization, pretraining data order, or other hyperparameters.

\enote{hs}{the above is really interesting, but the
explanation could be much clearer and more insightful}
\enote{yl}{i give a hypothesis above.}

\section{Further Analysis}\seclabel{analysis}

\subsection{Influence of the Numbers of Neurons}\seclabel{neuron_number}

% Based on our preliminary experiments, we use 3,000 as the threshold for the identified relation-specific neurons in \secref{results}. 
In this section, we investigate the effect of varying the number of relation-specific neurons
on the 7B model
(see \secref{13b_analysis} for 13B).
Specifically, we consider \textbf{ten} values: 10, 50, 200, 500, 1,000, 3,000, 10,000, 20,000, and 50,000. 
When deactivating varying numbers of neurons for a relation, we report the variation of accuracy for that relation and the \textbf{average accuracy} for all other relations in Figure \ref{fig:neuron_num}. The variation in individual relations is in Figure \ref{fig:neuron_num_all}.

% \shortpar{Different relations may require varying numbers of ``effective'' Relation-specific neurons.}
\shortpar{Relation-specific neurons of different relations present a varying degree of cumulative effect.}
Although the accuracy for most relations drops substantially once 3,000 or 10,000 neurons are deactivated, some relations are far more sensitive to a smaller-scale deactivation.
For example, disabling only 50 neurons reduces the accuracy from 80\% to 50\% for \texttt{star\_constellation}, and a similar decline occurs for \texttt{person\_plays\_instrument}.
We hypothesize that this sensitivity reflects how many distinct objects each relation maps to: if a relation has fewer unique objects, fewer neurons may be critical.
By contrast, relations like \texttt{person\_occupation} display lower sensitivity, retaining about 20\% accuracy even after 50,000 neurons are deactivated.

\begin{table}
% \setlength{\abovecaptionskip}{-0.01cm}
\setlength{\belowcaptionskip}{-0.6cm}
\tiny
\centering
\setlength{\tabcolsep}{2.5mm}{}
\begin{tabular}{lrr}
\toprule
Relation & \#total & \#affected \\
\midrule
\texttt{company\_ceo}              & 11 & 2 \\
\texttt{company\_hq}               & 5  & 0 \\
\texttt{landmark\_continent}       & 6  & 2 \\
\texttt{landmark\_country}         & 6  & 0 \\
\texttt{person\_father}            & 6  & 2 \\
\texttt{person\_mother}            & 7  & 5 \\
\texttt{person\_occupation}        & 8  & 1 \\
\texttt{person\_plays\_instrument} & 3  & 0 \\
\texttt{person\_pro\_sport}        & 8  & 0 \\
\texttt{person\_sport\_position}   & 20 & 11 \\
\texttt{product\_company}          & 9  & 2 \\
\texttt{star\_constellation}       & 14 & 0 \\
\bottomrule
\end{tabular}
\caption{Case study. Out of the prompts (\#total) where the model answers correctly when deactivating 1,000 but not when deactivating 3,000 neurons, few of them are affected when deactivating the difference (2,000).}
\label{tab:cumulative_effect}
\end{table}

\shortpar{Validation of the cumulative effect.} However, it remains unclear whether the further accuracy drop between two thresholds in Figure \ref{fig:neuron_num} is driven by \textbf{the newly deactivated neurons} or \textbf{the cumulative effect of all deactivated neurons}. To further investigate our neuron cumulativity hypothesis, we conduct a case study using 1,000 and 3,000 deactivated neurons. Specifically, we identify prompts from $\mathcal{P}_{r_i}^{\text{eva}}$ where the model answers correctly with 1,000 deactivated neurons but fails when 3,000 are deactivated. We then deactivate only the 2,000 additional neurons and measure the number of affected prompts, as shown in Table \ref{tab:cumulative_effect}. The results support the cumulative effect for most relations: the degradation of more facts primarily stems from the collective deactivation of all 3,000 neurons.

% Our findings highlight the varying degrees of \textbf{neuron sensitivity} across different relations.

\shortpar{Deactivating relation-specific neurons has a marginal effect on other relations until certain thresholds are reached.} 
Typically, these thresholds occur around 3,000 or 10,000, below which the 
% average 
accuracy on other relations remains stable -- supporting the choice of 3,000 neurons.
% for each relation. 
Once more neurons are deactivated, other relations also deteriorate, consistent with our \textbf{neuron versatility} hypothesis. 
This effect is clearer among closely related relations (e.g., \texttt{person\_pro\_sport} and \texttt{person\_sport\_position}), as displayed in  Figure~\ref{fig:neuron_num_all}. 
Even deactivating up to 50,000 neurons seldom reduces other relations to near-zero accuracy, suggesting a high degree of relation-specificity.
One exception is \texttt{company\_hq}, for which disabling 50,000 neurons causes all relations’ accuracies to approach zero -- possibly because some of these neurons underlie more general generation capabilities of the model \citep{sun2024massive,yu2024superweight}.

\enote{hs}{we should say more here and think hard about a
plausible explanation}
\enote{yl}{i think the superweights are a good explanation. such weights affect an LLM's ability to generate text so they naturally affects all relations.}
\enote{fy}{but then why do we see this for just one relation ?}
\enote{yl}{as the algorithm just sorts the neuron's importance to the relation, i guess some neurons by chance within 50,000 are ``superweights''. these superweights are important to the \texttt{company\_hq} relation, and simultaneously responsible for the general generation capabilities.}

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{-0.05cm}
    \setlength{\belowcaptionskip}{-0.5cm}
\includegraphics[width=0.48\textwidth]{figs/multilingual_results_7b.pdf}
    \caption{Accuracy on 12 relations across 6 languages. The upper bars (resp.\  lower bars) show the accuracy before (resp.\  after) the deactivation of 3,000 relations-specific neurons. Even though these neurons are identified using English, they usually influence other languages, indicating multilinguality of these neurons.}
    \label{fig:multilingual}
\end{figure}

\enote{hs}{fig:multilingual: but there are many relatinos
    that are *not* affected! this needs to be acknowedged}
\enote{yl}{sure, done. in caption I changed to ``usually'' and updated the text in the corresponding section.}

\subsection{Are These Neurons Multilingual?}

Recent studies suggest that some neurons encoding factual knowledge or handling specific tasks are 
% inherently
multilingual \citep{stanczak-etal-2022-neurons,zhang2024multilingual,wang2024sharing}. 
A natural question is whether 
% our 
relation-specific neurons -- identified solely via English prompts -- also function across languages.
To explore this, we translate $\mathcal{P}_{r_i}^{\text{eva}}$ to 5 languages: German (\textbf{deu}), Spanish (\textbf{esp}), French (\textbf{fra}), Chinese (\textbf{zho}), and Japanese (\textbf{jpn}) (see \secref{translation} for details).
We then deactivate the previously identified 3,000
% previously identified relation-specific 
neurons in the 7B model and measure the effect on these languages, as shown in Figure~\ref{fig:multilingual}. 
% presents the results.


Although the model’s accuracy is generally lower in non-English languages, it still achieves decent results for most relations (except for jpn and zho). 
Once the neurons for a given relation are deactivated, the accuracy drops across nearly all languages -- supporting our \textbf{neuron versatility} hypothesis. 
Our findings align with recent explanations that LLMs tend to translate the input text from any language into English for task solving in the middle layers based on a shared representation space \citep{wendler-etal-2024-llamas,dumas2024llamas,zhao2024multilingualism}.
As a result, deactivating ``English'' neurons naturally disrupts this shared space, impairing the model’s capability to generalize across languages for the affected relation.

\subsection{Fact Frequencies vs. Neuron Cumulativity}\seclabel{frequency}

We now examine our \textbf{neuron cumulativity} hypothesis by asking: \emph{why do some facts show higher sensitivity to a given set of relation neurons than others?}
We hypothesize that the frequency of a fact in the pretraining data can be a key factor, as more frequent facts may be memorized more robustly and thus remain less sensitive to deactivation.

Because the pretraining data for Llama 2 is not publicly available, we approximate it using Dolma \citep{soldaini-etal-2024-dolma}, a 3 trillion-token open-source corpus.
For each relation, we split the facts into two groups: (\textbf{a}) \emph{resilient facts}, for which the 7B (or 13B) model correctly predicts the object \textbf{both before and after} deactivating 3,000 relation-specific neurons. (\textbf{b}) \emph{sensitive facts}, for which the model is correct \textbf{before but not after} these neurons are deactivated.\footnote{We do not consider other numbers 
of 
relation-specific neurons 
because (1) if \#neurons < 3,000, there are not enough facts whose predictions change, and (2) if \#neurons > 3,000, facts belonging to other relations will also be influenced a lot.}
We then count how many documents in Dolma contain \textbf{both the subject and object} of each fact, calling this the \emph{fact frequency}.\footnote{We use ElasticSearch API from WIMBD \citep{elazar2024wimbd}
% a platform that 
that allows for 
% efficient 
counting 
and searching 
% in the contents of
in large 
% text
corpora. 
% An online demo is available at: \url{https://wimbd.apps.allenai.org/}.
}
Finally, we compute the average frequency for resilient and sensitive facts in each relation $r_i$, denoted respectively as  $\text{group}^{(\text{a})}_{r_i}$ and $\text{group}^{(\text{b})}_{r_i}$.

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{-0.1cm}
    \setlength{\belowcaptionskip}{-0.5cm}
\includegraphics[width=0.46\textwidth]{figs/frequency_vis_average_3000_llama-2-7b-hf.pdf}
\includegraphics[width=0.46\textwidth]{figs/frequency_vis_average_3000_llama-2-13b-hf.pdf}
    \caption{Relative difference between the average fact
    frequencies of the group (a) \emph{resilient facts} and (b) \emph{sensitive facts} for each relation
    in 7B (top) and 13B (bottom) models. Resilient facts generally appear more often than sensitive facts in most relations in the pertaining data.}
    \label{fig:relative_diff}
\end{figure}

Relative difference: $\text{diff}_{r_i} = \frac{\text{group}^{(\text{b})}_{r_i} - \text{group}^{(\text{a})}_{r_i}}{\text{group}^{(\text{b})}_{r_i}}$ for each relation $r_i$ is reported in Figure \ref{fig:relative_diff}.
We find that resilient facts generally appear more often in Dolma than sensitive facts, with only 3 exceptions in the 7B model and 2 exceptions in the 13B model (note that \texttt{landmark\_country} is omitted for the 13B model because no facts fall into group~(\textbf{a})).
We evaluate this difference with the Wilcoxon Signed-Rank Test \citep{woolson2005wilcoxon} and obtain $p$-values of respectively 0.11 and 0.03 for the 7B and the 13B models.\footnote{We use a nonparametric test because the difference 
% of average fact frequencies
across relations does not follow a Gaussian distribution.} These results show that there is a difference (statistically significant in the 13B model at the 5\% level) between the two groups, supporting our hypothesis that
\textbf{more frequent facts are generally less sensitive to the deactivation of a given set of relation-specific neurons}.

\enote{hs}{very interesting, but requires some analysis}
\enote{yl}{do you have any additional analysis we can do in mind?}

\input{concepts}


\section{Conclusion}

This work highlights the existence of relation-specific neurons in LLMs -- neurons that focus on relations rather than entities. 
Our experiments show these neurons primarily reside in the middle layers and can be shared across multiple relations. 
Through systematic deactivation, we reveal their influence on both the targeted and other relations, leading to three key hypotheses:
\textbf{neuron cumulativity} (deactivating a larger
portion of relation-specific neurons results in the degradation of more facts belonging to the concerning relation),
\textbf{neuron versatility} (neurons are shared across relations and languages), and
\textbf{neuron interference} (neurons from one relation can disrupt the processing of another).
These findings shed new light on how LLMs handle relational facts at the neuron level, contributing to the interpretability of LLMs.

\section*{Limitations}

While our findings provide valuable insights, several limitations remain and offer opportunities for future research.
First, this work focuses on factual knowledge grouped into 12 relations. Although this selection does not diminish the validity of our findings and hypotheses, it represents a relatively narrow set of relations. Future work can explore a broader range of relations and analyze how relation-specific neurons behave across a more diverse set of relations.
Second, our multilingual analysis includes only five languages. While these languages demonstrate neuron versatility, they do not fully capture linguistic diversity. Future research could investigate additional languages, particularly low-resource ones, to determine whether relation-specific neurons exhibit similar relational functionality across these languages.
Lastly, we observe that more frequent facts tend to be more robust to the deactivation of relation-specific neurons in both the 7B and 13B models. Fact frequency is approximated using the Dolma corpus \citep{soldaini-etal-2024-dolma} in this study. However, LLama-2 models may incorporate a larger and more diverse pretraining dataset, potentially leading to some discrepancies between these approximated fact frequencies and their actual frequencies.

\section*{Acknowledgments}

This research was supported by DFG (grant SCHU 2246/14-1). We gratefully acknowledge support from Google through a generous research grant. We appreciate suggestions and comments from other members of CIS, LMU Munich. We want to thank Lixi Liu’s suggestions for figure design.


\bibliography{custom}

\appendix

\section{Related Work}

Mechanistic interpretability (MI) is a growing subfield of interpretability that aims to understand LLMs by breaking them down into smaller components and fundamental computations. It has gained significant attention for studying how LLMs recall factual knowledge learned during pretraining \citep{meng2022locating,dai-etal-2022-knowledge,geva-etal-2023-dissecting,yu-etal-2023-characterizing,lv2024interpreting,wang-etal-2024-unveiling}. 
Following \citet{olah2020zoom, rai2024practical}, MI research can be categorized into two areas: the study of \textbf{features} and the study of \textbf{circuits}, based on the type of decomposed components. Features refer to human-interpretable properties encoded in model representations or represented by model components, such as neurons and attention heads \citep{elhage2022solu, gurnee2023finding}. Circuits are subgraphs of the model's computation graph responsible for implementing specific behaviors 
% in the language model 
\citep{wang2022interpretability, elhage2021mathematical}.

In this work, we focus on neuron-level feature-based interpretability analysis to localize relation-specific neurons, which are responsible for encoding and recalling specific types of factual knowledge. Existing studies have utilized various approaches for neuron interpretation, each offering unique advantages and limitations \cite{sajjad-etal-2022-neuron, rai2024practical}. The \textit{visualization} method \citep{olsson2022context, elhage2022solu, lieberum2023does, bills2023language,liu-etal-2024-unraveling} involves visualizing neuron activations and manually identifying the underlying concept across input text. While being straightforward, it relies heavily on human effort and risks overgeneralization. \textit{Statistics}-based methods \citep{Bau2019Identifying,neuron2022Cuadros,kojima-etal-2024-multilingual,yu-ananiadou-2024-neuron,tang-etal-2024-language,wang-etal-2024-unveiling}, on the other hand, aggregate activation statistics across data to establish connections between neurons and concepts, identifying patterns through the co-occurrence of neuron activation values and specific input features. \textit{Probing}-based methods \citep{dalvi2019one,  durrani-etal-2020-analyzing, antverg2021pitfalls, gurnee2024universal} train diagnostic classifiers on neuron activations to identify neurons associated with predefined concepts. These methods are scalable, enabling the discovery of neuron sets across large datasets, though they depend on supervised data annotations. \textit{Causation}-based methods \citep{vig2020investigating, meng2022locating, meng2022mass, kramar2024atp,song-etal-2024-large} take a different approach by directly varying the values of specific neurons or components and analyzing changes in model behavior; significant changes indicate the importance of these neurons or components to particular functionalities. 

Building on this foundation, our work adopts the statistics-based method proposed by \citet{neuron2022Cuadros} to identify relation-specific neurons -- neurons uniquely ``fired'' for queries concerning facts sharing the same relation. This approach facilitates a scalable and targeted analysis of neuron behavior in relation to factual knowledge recall.


% \shortpar{Interpreting Factual Recall in LLMs}

% There has been a growing interest recently in interpreting how LLMs recall factual knowledge learned from their pretraining stage \citep{meng2022locating,dai-etal-2022-knowledge,geva-etal-2023-dissecting,yu-etal-2023-characterizing,lv2024interpreting,wang-etal-2024-unveiling}.
% Depending on the objects to investigate, this line of studies can be roughly classified into \emph{representation-level} analysis and \emph{neuron-level} analysis \citep{sajjad-etal-2022-neuron}.
% Representation-level analysis aims to understand how knowledge is represented in the token embedding space and the dynamics of representations leading to language-based predictions \citep{li-etal-2021-implicit,meng2022locating,geva-etal-2022-transformer,Hase2023localization,merullo-etal-2024-language,lre2024Hernandez,fierro2024multilingualmodelsrememberinvestigating}.
% Neuron-level analysis aims to interpret the factual recall behavior at a more granular level by analyzing neurons. This usually involves identifying and investigating the functionality of neurons in specific elements of the model architectures, such as attention heads \citep{hao2021self,yu-etal-2023-characterizing,elhelo2024inferring} and feed-forward networks \citep{geva-etal-2021-transformer,dai-etal-2022-knowledge,wang2024sharing,wang-etal-2024-unveiling}.

% % \shortpar{Locating Knowledge Neurons.} 
% In many neuron-level analysis studies, one core question is how to locate the neurons that are relevant to specific concepts \citep{sajjad-etal-2022-neuron}. \emph{Activation-based} methods focus on the forward pass and try to solve the question by investigating the neuron activation patterns \citep{Li2023lazyneuron,voita-etal-2024-neurons,gurnee2024universal}. \emph{Gradient-based} methods look at the backward pass and measure the sensitivity of model outputs to different neurons in response to specific inputs \citep{dai-etal-2022-knowledge,Lundstrom2022Rigorous,chen2024identifying,chen2024journey}. Alternatively, some studies propose methods based on saliency scores -- some aggregated statistics that indicate neurons' importance to a group of queries that share common characteristics \citep{Bau2019Identifying,neuron2022Cuadros,kojima-etal-2024-multilingual,yu-ananiadou-2024-neuron,tang-etal-2024-language,wang-etal-2024-unveiling}. Our work adopts the method proposed by \citet{neuron2022Cuadros} and identifies relation-specific neurons -- neurons that are uniquely ``fired'' in queries concerning facts sharing the same relation.

\enote{hs}{related work sonds good -- but is very short. are
you sure this covers everything?}
\enote{yh}{no i am not very sure -- i tried to cover the papers that i found and classified them into different categories. probably we need dawar and mingyang to double check.}

\section{Entity Overlap Across Relations}\seclabel{entity_overlap}

\begin{figure*}
    \centering
    % \setlength{\abovecaptionskip}{-0.2cm}
    % \setlength{\belowcaptionskip}{-0.4cm}
    \begin{tabular}{c}
    % \hspace{-0.3cm}
    \includegraphics[width=0.48\textwidth]{figs/entity_overlap/subject_overlaps_train.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.48\textwidth]{figs/entity_overlap/object_overlaps_train.pdf}
    \end{tabular}
    \caption{Subject (left) and object (right) overlap across 12 relations obtained from the 7B model. The diagonal in each figure shows the number of distinct subjects or objects for each relation. It can be seen that factual knowledge from different relations has almost no entity overlap except for \texttt{person\_mother} and \texttt{person\_father}, which are mostly celebrities.}
    \label{fig:subject_object_overlap_7b}
\end{figure*}


\begin{figure*}
    \centering
    % \setlength{\abovecaptionskip}{0cm}
    % \setlength{\belowcaptionskip}{-0.4cm}
    \begin{tabular}{c}
    % \hspace{-0.3cm}
    \includegraphics[width=0.48\textwidth]{figs/entity_overlap/subject_overlaps_train_llama-2-13b-hf.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.48\textwidth]{figs/entity_overlap/object_overlaps_train_llama-2-13b-hf.pdf}
    \end{tabular}
    \caption{Subject (left) and object (right) overlap across 12 relations obtained from the 13B model. The trend is very similar to that in the 7B model: \texttt{person\_mother} and \texttt{person\_father} share many subjects.}
    \label{fig:subject_object_overlap_13b}
\end{figure*}

\begin{figure*}
    \centering
    % \setlength{\abovecaptionskip}{0cm}
    % \setlength{\belowcaptionskip}{-0.4cm}
    \begin{tabular}{c}
    % \hspace{-0.3cm}
    \includegraphics[width=0.48\textwidth]{figs/entity_overlap/subject_overlaps_test.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.48\textwidth]{figs/entity_overlap/object_overlaps_test.pdf}
    \end{tabular}
    \caption{Subject (left) and object (right) overlap across 12 relations in the held-out evaluation prompt set $\mathcal{P}_{r_i}^{\text{eva}}$. Almost no two relations share any subjects or objects.}
    \label{fig:subject_object_overlap_test}
\end{figure*}

\begin{figure}
    \centering
    % \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{-0.5cm}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/company_ceo_limited_3000_top_mlp.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/company_hq_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/landmark_continent_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/landmark_country_limited_3000_top_mlp.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/person_father_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/person_mother_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/person_occupation_limited_3000_top_mlp.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/person_plays_instrument_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/person_pro_sport_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/person_sport_position_limited_3000_top_mlp.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/product_company_limited_3000_top_mlp.pdf}
    \includegraphics[width=0.15\textwidth]{figs/layer_dist/llama-2-13b-hf/star_constellation_limited_3000_top_mlp.pdf}
    \caption{Distribution of relation-specific neurons
    across layers for the 13B model. Similar to Figure \ref{fig:layer_dist}, identified relation-specific neurons are mostly located in the middle layers, except for \texttt{person\_mother}.}
    \label{fig:layer_dist_13b}
\end{figure}

We show the number of \textbf{distinct subjects (resp. objects)} in each relation and the number of \textbf{overlapping subjects (resp. objects)} between any two relations 
in the identification prompt set $\mathcal{P}_{r_i}^{\text{det}}$
of the 7B model and the 13B model in Figure \ref{fig:subject_object_overlap_7b} and \ref{fig:subject_object_overlap_13b} respectively.
Most two relations have no common or very limited overlapping (less than 11) subjects, except for \texttt{person\_mother} and \texttt{person\_father}, which are mostly celebrities, possibly resulting in extensive neuron overlap between the two relations as we show in \secref{neurons}.
Similarly, no two relations share many objects.
Additionally, we show the number of overlapping entities in the evaluation set $\mathcal{P}_{r_i}^{\text{eva}}$ (the 7B and 13B models share the same evaluation set) in Figure \ref{fig:subject_object_overlap_test}.
The results also show almost no entity overlap across different relations: among all relations, only \texttt{person\_mother} and \texttt{person\_father} share \textbf{one} subject and the rest of the relations do not share any subject or object overlap. 
The entity analysis suggests that entities are not a confounding factor in our experiments and the identified relation-specific neurons are only concerning the relation itself but not entities. 

\section{Analysis On the 13B Model}\seclabel{13b_analysis}

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{-0.1cm}
    \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=0.45\textwidth]{figs/neuron_overlaps_top_3000_mlp_13B.pdf}
    \caption{Overlap of the relation-specific neurons across 12 relations in the 13B model. The overlap distribution is not similar to what we observe for the 7B model shown in Figure \ref{fig:neuron_overlap}, explaining the difference in inter-relation results (cf. Table \ref{fig:inter-relation}).}
    \label{fig:neuron_overlap_13b}
\end{figure}

We perform a similar analysis on the 13B model as we do for the 7B model.  We first show how the identified 3,000 relation-specific neurons are distributed across layers for each relation in Figure \ref{fig:layer_dist_13b}. The trend is similar to what we observe in the 7B model (cf. Figure \ref{fig:layer_dist}). Most of the relation-specific neurons are distributed in the middle layers. 
Then we show the overlap of relation-specific neurons across relations in Figure \ref{fig:neuron_overlap_13b}. Surprisingly, the overlap pattern is very different from what we observe in the 7B model. First, it seems that many relations that share a concept of ``location'' share extensive neurons, e.g., \texttt{company\_hq}, \texttt{landmark\_country}, \texttt{landmark\_country} and \texttt{star\_constellation}. This explains the difference in inter-relation results between the models (cf. Figure \ref{fig:inter-relation}) where we see deactivating neurons of \texttt{landmark\_country} significantly influence other relations also concerning location for the 13B model but not for the 7B model.

\begin{figure}
    \centering
    % \setlength{\abovecaptionskip}{-0.05cm}
    % \setlength{\belowcaptionskip}{-0.5cm}
\includegraphics[width=0.48\textwidth]{figs/multilingual_results_13b.pdf}
    \caption{Accuracy on 12 relations across 6 languages from the 13B model. The upper bars (resp.\  lower bars) show the accuracy before (resp.\  after) the deactivation of 3,000 relations-specific neurons.}
    \label{fig:multilingual_13b}
\end{figure}

We then demonstrate the effect of varying numbers of relation-specific neurons using the same numbers: 10, 50, 200, 500, 1,000, 3,000, 10,000, 20,000, and 50,000. Figure \ref{fig:neuron_num_13b} presents the results. The global trend is similar to what we observe for the 7B model: deactivating more neurons results in a further drop in accuracy across all relations. This indicates the \textbf{neuron cumulativity} is universal across models. 
Relation-specific neurons for most relations present a similar cumulative effect to the 13B model. The original two outliers in the 7B model (\texttt{person\_occupation} and \texttt{product\_company} where the accuracy does not drop to 0 in the 7B model) even show a plateau, i.e., the accuracy remains almost unchanged or only slightly decreases. This might suggest that facts belonging to these two relations might be well-memorized by the models and are less sensitive to the deactivation of relation-specific neurons.

Lastly, we show whether the identified relation-specific neurons from the 13B model are also multilingual. We use the same translated prompt sets as we use for the 7B model. We deactivate the 3,000 neurons identified using English and see how this affects the performance in other languages: German (\textbf{deu}), Spanish (\textbf{esp}), French (\textbf{fra}), Chinese (\textbf{zho}), and Japanese (\textbf{jpn}). The results are presented in Figure \ref{fig:multilingual_13b}. We observe similar results as from the 7B model: when we deactivate the relation-specific neurons identified using English prompts, many relations are influenced across languages, suggesting models with different sizes also have multilingual relational neurons. We also see some interesting counterexamples: deactivating \texttt{landmark\_country} neurons completely deteriorates the relation in English but not in German. This indicates while some neurons have multilingual relational functionalities, there are still some relations dealt with in a language-specific manner.

\begin{figure*}
    \centering
    % \setlength{\abovecaptionskip}{-0cm}
    \setlength{\belowcaptionskip}{-0.5cm}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/company_ceo.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/company_hq.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/landmark_continent.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/landmark_country.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/person_father.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/person_mother.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/person_occupation.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/person_plays_instrument.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/person_pro_sport.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/person_sport_position.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/product_company.pdf}
    \includegraphics[width=0.23\textwidth]{figs/neuron_num/llama-2-13b-hf/star_constellation.pdf}
    \caption{Influence of deactivating different numbers of relation-specific neurons for each relation (\textbf{the 13B model}). The variation of accuracy on the relation itself and the average accuracy on other relations is shown.}
    \label{fig:neuron_num_13b}
\end{figure*}

\begin{figure*}
    \centering
    % \setlength{\abovecaptionskip}{-0cm}
    % \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/company_ceo_all.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/company_hq_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/landmark_continent_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/landmark_country_all.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/person_father_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/person_mother_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/person_occupation_all.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/person_plays_instrument_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/person_pro_sport_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/person_sport_position_all.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/product_company_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-7b-hf/star_constellation_all.pdf}
    \caption{Influence of deactivating different numbers of
    relation-specific neurons in the 7B model for each
    relation. The variation of accuracy on the relation
    itself (noted with ``*'' and a dashed line style) and
    the accuracy on all other relations is shown in each
    figure. Similar to Figure \ref{fig:neuron_num},
    increasing the number of neurons clearly affects the
    relation itself, but the effect on other individual
    relations does not become clearly noticeable until 3,000--10,000 neurons.}
    \label{fig:neuron_num_all}
\end{figure*}


\begin{figure*}
    \centering
    % \setlength{\abovecaptionskip}{-0cm}
    % \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/company_ceo_all.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/company_hq_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/landmark_continent_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/landmark_country_all.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/person_father_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/person_mother_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/person_occupation_all.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/person_plays_instrument_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/person_pro_sport_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/person_sport_position_all.pdf}
    % \hspace{-0.3cm}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/product_company_all.pdf}
    \includegraphics[width=0.32\textwidth]{figs/neuron_num/llama-2-13b-hf/star_constellation_all.pdf}
    \caption{Influence of deactivating different numbers of
    relation-specific neurons in the 13B model for each
    relation. The variation of accuracy on the relation
    itself (noted with ``*'' and a dashed line style) and
    the accuracy on all other relations is shown in each
    figure.}
    \label{fig:neuron_num_all_13b}
\end{figure*}

% \newpage
\section{Translation Process}\seclabel{translation}

We take a \textbf{two-step} approach to ensure the translation quality of individual prompts from English into the target languages across relations. 

\paragraph{Translating subject-object pairs.} The first step concerns mapping entities, i.e., subject and object pairs into the target language. The default way of doing this is by identifying if the entity is available in Wikidata and the target language using the Wikidata API.\footnote{\url{https://www.wikidata.org/w/api.php}}
If the entity of interest is available in the target language, we directly take the entity name in that language.
If the entity is not available, we then resort to Google Translate to translate the entity from English to the target language.\footnote{\url{https://translation.googleapis.com/language/translate/v2}}. By performing this step, we obtain the subject-object pairs in all target languages and all relations.

\paragraph{Translating prompt templates.} We take the prompt templates of different relations written in English and use Google Translate to translate them into target languages. We then investigate how the LLama-2 7B model performs on these prompts using $\mathcal{P}_{r_i}^{\text{eva}}$ in the target languages. If the model performs suboptimally (<30\% accuracy) for a relation in a specific language, then we manually check the prompt template in that language and update the template accordingly until satisfactory accuracy (>30\%) is achieved. For Chinese and Japanese, we do not ensure more than 30\% accuracy because the models perform very badly for some relations even if we have tried many prompt templates.


% \footnote{We first translate the subject-object pairs using Wikipedia or Google Translate. We then manually translate the prompt templates for each $r_i$ to ensure their quality. See \secref{translation} for details.}

\section{Influence of Neuron Type}\seclabel{neuron_type}

\begin{figure}
    \centering
    % \setlength{\abovecaptionskip}{0cm}
    % \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=0.46\textwidth]{figs/neuron_type/llama-2-7b-hf_3000_top_dist.pdf}
    \caption{The distribution of the neuron types in the identified 3,000 neurons for the variety \textbf{\texttt{all}} across all relations.}
\label{fig:neuron_type_dist}
\end{figure}

We consider the neurons in the FFNs (including up\_proj, gate\_proj, and down\_proj matrices) as our major setup. In this section, we explore the individual effects of different types of neurons. Specifically,
we consider five additional different varieties when selecting the top 3,000 neurons for the 7B model: \textbf{\texttt{all}} (neurons in any matrices), \textbf{\texttt{self\_attn}} (neurons in self-attention matrices), \textbf{\texttt{up\_proj}} (neurons in up\_proj matrices), \textbf{\texttt{gate\_proj}} (neurons in gate\_proj matrices), \textbf{\texttt{down\_proj}} (neurons in down\_proj matrices). We first draw the distribution of the neuron types across relations for variety \textbf{\texttt{all}} in Figure \ref{fig:neuron_type_dist} and report the inter-relation results in Figure \ref{fig:neuron_type_all} (\textbf{\texttt{all}}), \ref{fig:neuron_type_self_attn} (\textbf{\texttt{self\_attn}}), \ref{fig:neuron_type_up_proj} (\textbf{\texttt{up\_proj}}), \ref{fig:neuron_type_gate_proj} (\textbf{\texttt{gate\_proj}}), and \ref{fig:neuron_type_down_proj} (\textbf{\texttt{down\_proj}}).

According to the results, we observe that simply considering \textbf{\texttt{self\_attn}} does not offer a consistent accuracy drop for the relation itself (by looking at the diagonal: some relations are not influenced too much). This can be explained by the fact the \textbf{\texttt{self\_attn}} is shared across relations (as shown by \citet{elhelo2024inferring}) and facts are mainly stored in the FFNs. Only considering \textbf{\texttt{down\_proj}} offer similar results as \textbf{\texttt{self\_attn}}. Interestingly, deactivating \textbf{\texttt{up\_proj}} neurons does not influence all relations much in general, indicating it does not make sense to consider \textbf{\texttt{up\_proj}} alone. Considering \textbf{\texttt{all}} or \textbf{\texttt{gate\_proj}} neurons offer similar results compared to considering neurons in FFNs (shown in Figure \ref{fig:intra-relation}). However, by considering neurons in FFNs (i.e., \textbf{\texttt{up\_proj}}, \textbf{\texttt{gate\_proj}} and \textbf{\texttt{down\_proj}}), we see a more obvious inter-relation accuracy drop as shown on the diagonal in Figure \ref{fig:intra-relation}. Therefore, our additional analysis supports our choice of considering neurons in FFNs.

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{-0.1cm}
    % \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=0.48\textwidth]{figs/neuron_type/accuracy_drops_heatmap_llama-2-7b-hf_top_3000_zero.pdf}
    \caption{Inter-relation results of the 7B model when considering the neuron type variety as \textbf{\texttt{all}}.}
    \label{fig:neuron_type_all}
\end{figure}

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{-0.1cm}
    % \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=0.48\textwidth]{figs/neuron_type/accuracy_drops_heatmap_llama-2-7b-hf_top_3000_self_attn_zero.pdf}
    \caption{Inter-relation results of the 7B model when considering the neuron type variety as \textbf{\texttt{self\_attn}}.}
    \label{fig:neuron_type_self_attn}
\end{figure}

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{-0.1cm}
    % \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=0.48\textwidth]{figs/neuron_type/accuracy_drops_heatmap_llama-2-7b-hf_top_3000_up_proj_zero.pdf}
    \caption{Inter-relation results of the 7B model when considering the neuron type variety as \textbf{\texttt{up\_proj}}.}
    \label{fig:neuron_type_up_proj}
\end{figure}

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{-0.1cm}
    % \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=0.48\textwidth]{figs/neuron_type/accuracy_drops_heatmap_llama-2-7b-hf_top_3000_gate_proj_zero.pdf}
    \caption{Inter-relation results of the 7B model when considering the neuron type variety as \textbf{\texttt{gate\_proj}}.}
    \label{fig:neuron_type_gate_proj}
\end{figure}

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{-0.1cm}
    % \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=0.48\textwidth]{figs/neuron_type/accuracy_drops_heatmap_llama-2-7b-hf_top_3000_down_proj_zero.pdf}
    \caption{Inter-relation results of the 7B model when considering the neuron type variety as \textbf{\texttt{down\_proj}}.}
    \label{fig:neuron_type_down_proj}
\end{figure}
\input{concept_appendix}
\section{Experimental Environment}\seclabel{env}

We run all experiments on NVIDIA RTX A6000 GPUs. The Python environment we use is the same as \citet{kojima-etal-2024-multilingual}.\footnote{\citet{kojima-etal-2024-multilingual}'s GitHub repository is available at \url{https://github.com/kojima-takeshi188/lang_neuron}} 

% \clearpage
\input{prompts}

\end{document}
