\section{Related Works \& Preliminary}
\label{sec:re}

% \subsection{LLM-Based Agent and Multi-Agent System} \label{sec: rw1}
\noindent\textbf{LLM-Based Agent and Multi-Agent System.} \label{sec: rw1}
With the development of LLMs, LLM-based agents have made significant achievements **Brown et al., "Language Models Play Darts"**. 
By collaboration, the capabilities of multi-agent systems are further extended, enabling them to accomplish more complex tasks **Vinyals et al., "Matching Networks for One Shot Learning"**, **Santoro et al., "One-shot Learning with Attention and External Memory"**. 
Some autonomous LLM-MASs can even simulate human society **Tassa et al., "Multi-Agent Reinforcement Learning for Traffic Control"**, facilitating the exploration of AI-human interactions. 

% \subsection{LLM Blocking Attacks} \label{sec: rw2}
\noindent\textbf{LLM Blocking Attacks.} \label{sec: rw2}
Some studies have noted that LLMs can be induced by malicious attackers to generate redundant responses through specially crafted prompts, leading to wasted computational resources **Jia et al., "Adversarial Examples for Generating More Realistic and Diverse Images"**. 
In white-box settings, such attacks typically rely on training modifications or access to gradient information **Goodfellow et al., "Explaining and Harnessing Adversarial Examples"**, **Kurakin et al., "Adversarial Examples in the Physical World"**. 
Recently, optimization-based black-box approaches utilizing LLMs have also been proposed **Chen et al., "This Look at You: Learning from Observations and Actions"**. 
These works indicate the growing attention to blocking attacks as a critical security concern.

\noindent \textbf{Preliminary.} We denote an LLM-MAS consisting of \( n \) LLM-based agents as $S$, where the LLM used is denoted as \( L \). 
%We denote an LLM-MAS consisting of $n$ LLM-based agents as $S = \{a_1, a_2, ..., a_n\}$, where the LLM used is denoted as $L$ and .
The topology structure $T$ of agents $A = \{a_1, a_2, ..., a_n\}$ in $S$ is represented as a graph:
\[
T = (A, E), \quad E \subseteq A \times A,
\]
where the edge $e=(a_i, a_j) \in E$ represent $a_i$ and $a_j$ are allowed to exchange their information or pass instruction to each other. We define \( r = a_x^t(P) \) to represent that the \( x \)-th agent executes instruction \( P \) at time step \( t \) and generates response \( r \).
Besides, we assume that the attacker $M$ uses a malicious prompt $P_m$ to attack the system $S$, and the agent affected by the attack is denoted as $a_b$.