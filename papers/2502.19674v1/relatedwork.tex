\section{Related Works}
This section briefly reviews some related works on multimodal learning, modality-specific noise removal, and cross-modality noise removal.
\subsection{Multimodal Learning}
Multimodal learning integrates information from different types of data, achieving effective representation learning with a wide range of applications in real-world scenarios \cite{baltruvsaitis2018multimodal,ramachandram2017deep,wang2020deep}. Based on the fusion strategy, multimodal learning can be classified into early fusion \cite{poria2015deep}, intermediate fusion \cite{tsai2019multimodal,hang2021multi,lee2021variational,kiela2019supervised,huang2021makes,huang2020multimodal,hu2021unit,hong2020more,arevalo2017gated}, and decision fusion \cite{wang2021mogonet,subedar2019uncertainty,simonyan2014two,natarajan2012multimodal}. Early fusion directly integrates various modalities at the data level to utilize the correlation and interaction between low-level features \cite{poria2015deep}. Still, it cannot fully exploit the complementary between multiple modal data and may suffer from information redundancy. Intermediate fusion, widely adopted in multimodal learning, integrates modalities at the intermediate feature level, capturing the complementary relationships between high-level features of each modality \cite{tsai2019multimodal,hang2021multi,lee2021variational,kiela2019supervised,huang2021makes,huang2020multimodal,hu2021unit,hong2020more,arevalo2017gated}. Decision fusion, involves extracting features from each modality and obtaining predictions from individual classifiers for each modality, which are then integrated to obtain the final multi-modal prediction result \cite{wang2021mogonet,subedar2019uncertainty,simonyan2014two,natarajan2012multimodal}.

\subsection{Modality-Specific Noise Removal}
Many studies have developed reliable multimodal classification methods to remove modality-specific noise. Federici et al. \cite{federici2020learning} proposed the multi-view information bottleneck, which improved the generalization and robustness of multi-view learning by retaining information shared by each view. Han et al. 
 \cite{han2020trusted} parameterized the evidence of different modality features using Dirichlet distribution and fused each modality at the evidence level using Dempster-Shafer theory. Geng et al. \cite{geng2021uncertainty} proposed the DUA-Nets, which achieved uncertainty-based multimodal representation learning through reconstruction. Han et al. \cite{han2022multimodal} modeled informativeness at the feature and modality levels, achieving trustworthy multimodal feature fusion. Zhang et al. \cite{zhang2023provable} achieved more robust and generalized multimodal fusion by dynamically assigning weights to each modality based on uncertainty estimation. Zheng
et al. \cite{zheng2023multi} achieved trustworthy multimodal classification via integrating feature and label-level confidence. Zou et al. \cite{zou2023dpnet} proposed a novel dynamic poly-attention Network that integrated global structural information for trustworthy multimodal classification. Zhou et al. \cite{zhou2023calm} introduced a trustworthy multi-view classification framework by enhancing multi-view encoding and confidence-aware fusion. Cao et al. \cite{cao2024predictive} proposed the Predictive Dynamic Fusion method, which provides theoretical guarantees for reducing the upper bound of generalization error in dynamic multimodal fusion.

\subsection{Cross-Modality Noise Removal}
Many studies have focused on identifying or realigning misaligned sample pairs or achieving reliable multimodal learning using incomplete sample pairs. These methods can be categorized into rules-based filtering, model-based rectifying, and noise-robust regularization. Rules-based filtering refers to methods for data cleaning through the design of a set of rules. Representative works include those by Radenovic et al. \cite{radenovic2023filtering}, Gadre et al. \cite{gadre2024datacomp}, and Sharma et al. \cite{sharma2018conceptual}. Model-based rectifying methods design models to filter or rectify misaligned samples, such as NCR \cite{huang2021learning}, ALBEF \cite{li2021align}, and BLIP \cite{li2022blip}. Noise robust regularization methods mitigate the impact of misaligned samples on the model by designing regularization, such as NLIP \cite{huang2023nlip} and OSCAR \cite{li2020oscar}. Some studies also design reliable learning methods that do not rely on paired samples, such as SMILE \cite{zeng2023semantic}.


%