\section{Related Works}
This section briefly reviews some related works on multimodal learning, modality-specific noise removal, and cross-modality noise removal.
\subsection{Multimodal Learning}
Multimodal learning integrates information from different types of data, achieving effective representation learning with a wide range of applications in real-world scenarios ____. Based on the fusion strategy, multimodal learning can be classified into early fusion ____, intermediate fusion ____, and decision fusion ____. Early fusion directly integrates various modalities at the data level to utilize the correlation and interaction between low-level features ____. Still, it cannot fully exploit the complementary between multiple modal data and may suffer from information redundancy. Intermediate fusion, widely adopted in multimodal learning, integrates modalities at the intermediate feature level, capturing the complementary relationships between high-level features of each modality ____. Decision fusion, involves extracting features from each modality and obtaining predictions from individual classifiers for each modality, which are then integrated to obtain the final multi-modal prediction result ____.

\subsection{Modality-Specific Noise Removal}
Many studies have developed reliable multimodal classification methods to remove modality-specific noise. Federici et al. ____ proposed the multi-view information bottleneck, which improved the generalization and robustness of multi-view learning by retaining information shared by each view. Han et al. 
 ____ parameterized the evidence of different modality features using Dirichlet distribution and fused each modality at the evidence level using Dempster-Shafer theory. Geng et al. ____ proposed the DUA-Nets, which achieved uncertainty-based multimodal representation learning through reconstruction. Han et al. ____ modeled informativeness at the feature and modality levels, achieving trustworthy multimodal feature fusion. Zhang et al. ____ achieved more robust and generalized multimodal fusion by dynamically assigning weights to each modality based on uncertainty estimation. Zheng
et al. ____ achieved trustworthy multimodal classification via integrating feature and label-level confidence. Zou et al. ____ proposed a novel dynamic poly-attention Network that integrated global structural information for trustworthy multimodal classification. Zhou et al. ____ introduced a trustworthy multi-view classification framework by enhancing multi-view encoding and confidence-aware fusion. Cao et al. ____ proposed the Predictive Dynamic Fusion method, which provides theoretical guarantees for reducing the upper bound of generalization error in dynamic multimodal fusion.

\subsection{Cross-Modality Noise Removal}
Many studies have focused on identifying or realigning misaligned sample pairs or achieving reliable multimodal learning using incomplete sample pairs. These methods can be categorized into rules-based filtering, model-based rectifying, and noise-robust regularization. Rules-based filtering refers to methods for data cleaning through the design of a set of rules. Representative works include those by Radenovic et al. ____, Gadre et al. ____, and Sharma et al. ____. Model-based rectifying methods design models to filter or rectify misaligned samples, such as NCR ____, ALBEF ____, and BLIP ____. Noise robust regularization methods mitigate the impact of misaligned samples on the model by designing regularization, such as NLIP ____ and OSCAR ____. Some studies also design reliable learning methods that do not rely on paired samples, such as SMILE ____.


%