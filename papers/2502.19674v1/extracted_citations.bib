@article{arevalo2017gated,
  title={Gated multimodal units for information fusion},
  author={Arevalo, John and Solorio, Thamar and Montes-y-G{\'o}mez, Manuel and Gonz{\'a}lez, Fabio A},
  journal={arXiv preprint arXiv:1702.01992},
  year={2017}
}

@article{baltruvsaitis2018multimodal,
  title={Multimodal machine learning: A survey and taxonomy},
  author={Baltru{\v{s}}aitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={2},
  pages={423--443},
  year={2018},
  publisher={IEEE}
}

@article{gadre2024datacomp,
  title={Datacomp: In search of the next generation of multimodal datasets},
  author={Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{geng2021uncertainty,
  title={Uncertainty-aware multi-view representation learning},
  author={Geng, Yu and Han, Zongbo and Zhang, Changqing and Hu, Qinghua},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={9},
  pages={7545--7553},
  year={2021}
}

@inproceedings{han2020trusted,
  title={Trusted multi-view classification},
  author={Han, Zongbo and Zhang, Changqing and Fu, Huazhu and Zhou, Joey Tianyi},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{han2022multimodal,
  title={Multimodal dynamics: Dynamical fusion for trustworthy multimodal classification},
  author={Han, Zongbo and Yang, Fan and Huang, Junzhou and Zhang, Changqing and Yao, Jianhua},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={20707--20717},
  year={2022}
}

@article{hang2021multi,
  title={Multi-modal multi-instance learning using weakly correlated histopathological images and tabular clinical information in Medical Image Computing and Computer Assisted Intervention--MICCAI 2021: 24th International Conference, Strasbourg, France, September 27--October 1, 2021},
  author={Hang, Li and Fan, Yang and Xiaohan, Xing and others},
  journal={Proceedings, Part VIII},
  volume={24},
  pages={529--539Springer},
  year={2021}
}

@article{hong2020more,
  title={More diverse means better: Multimodal deep learning meets remote-sensing imagery classification},
  author={Hong, Danfeng and Gao, Lianru and Yokoya, Naoto and Yao, Jing and Chanussot, Jocelyn and Du, Qian and Zhang, Bing},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={59},
  number={5},
  pages={4340--4354},
  year={2020},
  publisher={IEEE}
}

@inproceedings{hu2021unit,
  title={Unit: Multimodal multitask learning with a unified transformer},
  author={Hu, Ronghang and Singh, Amanpreet},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1439--1449},
  year={2021}
}

@inproceedings{huang2020multimodal,
  title={Multimodal transformer fusion for continuous emotion recognition},
  author={Huang, Jian and Tao, Jianhua and Liu, Bin and Lian, Zheng and Niu, Mingyue},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3507--3511},
  year={2020},
  organization={IEEE}
}

@article{huang2021learning,
  title={Learning with noisy correspondence for cross-modal matching},
  author={Huang, Zhenyu and Niu, Guocheng and Liu, Xiao and Ding, Wenbiao and Xiao, Xinyan and Wu, Hua and Peng, Xi},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29406--29419},
  year={2021}
}

@article{huang2021makes,
  title={What makes multi-modal learning better than single (provably)},
  author={Huang, Yu and Du, Chenzhuang and Xue, Zihui and Chen, Xuanyao and Zhao, Hang and Huang, Longbo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={10944--10956},
  year={2021}
}

@inproceedings{huang2023nlip,
  title={Nlip: Noise-robust language-image pre-training},
  author={Huang, Runhui and Long, Yanxin and Han, Jianhua and Xu, Hang and Liang, Xiwen and Xu, Chunjing and Liang, Xiaodan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={1},
  pages={926--934},
  year={2023}
}

@article{kiela2019supervised,
  title={Supervised multimodal bitransformers for classifying images and text},
  author={Kiela, Douwe and Bhooshan, Suvrat and Firooz, Hamed and Perez, Ethan and Testuggine, Davide},
  journal={arXiv preprint arXiv:1909.02950},
  year={2019}
}

@inproceedings{lee2021variational,
  title={A variational information bottleneck approach to multi-omics data integration},
  author={Lee, Changhee and Van der Schaar, Mihaela},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1513--1521},
  year={2021},
  organization={PMLR}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX 16},
  pages={121--137},
  year={2020},
  organization={Springer}
}

@article{li2021align,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{natarajan2012multimodal,
  title={Multimodal feature fusion for robust event detection in web videos},
  author={Natarajan, Pradeep and Wu, Shuang and Vitaladevuni, Shiv and Zhuang, Xiaodan and Tsakalidis, Stavros and Park, Unsang and Prasad, Rohit and Natarajan, Premkumar},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1298--1305},
  year={2012},
  organization={IEEE}
}

@inproceedings{poria2015deep,
  title={Deep convolutional neural network textual features and multiple kernel learning for utterance-level multimodal sentiment analysis},
  author={Poria, Soujanya and Cambria, Erik and Gelbukh, Alexander},
  booktitle={Proceedings of the 2015 conference on empirical methods in natural language processing},
  pages={2539--2544},
  year={2015}
}

@inproceedings{radenovic2023filtering,
  title={Filtering, distillation, and hard negatives for vision-language pre-training},
  author={Radenovic, Filip and Dubey, Abhimanyu and Kadian, Abhishek and Mihaylov, Todor and Vandenhende, Simon and Patel, Yash and Wen, Yi and Ramanathan, Vignesh and Mahajan, Dhruv},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6967--6977},
  year={2023}
}

@article{ramachandram2017deep,
  title={Deep multimodal learning: A survey on recent advances and trends},
  author={Ramachandram, Dhanesh and Taylor, Graham W},
  journal={IEEE signal processing magazine},
  volume={34},
  number={6},
  pages={96--108},
  year={2017},
  publisher={IEEE}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2556--2565},
  year={2018}
}

@article{simonyan2014two,
  title={Two-stream convolutional networks for action recognition in videos},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{subedar2019uncertainty,
  title={Uncertainty-aware audiovisual activity recognition using deep bayesian variational inference},
  author={Subedar, Mahesh and Krishnan, Ranganath and Meyer, Paulo Lopez and Tickoo, Omesh and Huang, Jonathan},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6301--6310},
  year={2019}
}

@inproceedings{tsai2019multimodal,
  title={Multimodal transformer for unaligned multimodal language sequences},
  author={Tsai, Yao-Hung Hubert and Bai, Shaojie and Liang, Paul Pu and Kolter, J Zico and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
  booktitle={Proceedings of the conference. Association for computational linguistics. Meeting},
  volume={2019},
  pages={6558},
  year={2019},
  organization={NIH Public Access}
}

@article{wang2020deep,
  title={Deep multimodal fusion by channel exchanging},
  author={Wang, Yikai and Huang, Wenbing and Sun, Fuchun and Xu, Tingyang and Rong, Yu and Huang, Junzhou},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={4835--4845},
  year={2020}
}

@article{wang2021mogonet,
  title={MOGONET integrates multi-omics data using graph convolutional networks allowing patient classification and biomarker identification},
  author={Wang, Tongxin and Shao, Wei and Huang, Zhi and Tang, Haixu and Zhang, Jie and Ding, Zhengming and Huang, Kun},
  journal={Nature communications},
  volume={12},
  number={1},
  pages={3445},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{zeng2023semantic,
  title={Semantic invariant multi-view clustering with fully incomplete information},
  author={Zeng, Pengxin and Yang, Mouxing and Lu, Yiding and Zhang, Changqing and Hu, Peng and Peng, Xi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@inproceedings{zhang2023provable,
  title={Provable dynamic fusion for low-quality multimodal data},
  author={Zhang, Qingyang and Wu, Haitao and Zhang, Changqing and Hu, Qinghua and Fu, Huazhu and Zhou, Joey Tianyi and Peng, Xi},
  booktitle={International conference on machine learning},
  pages={41753--41769},
  year={2023},
  organization={PMLR}
}

@inproceedings{zheng2023multi,
  title={Multi-level confidence learning for trustworthy multimodal classification},
  author={Zheng, Xiao and Tang, Chang and Wan, Zhiguo and Hu, Chengyu and Zhang, Wei},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={9},
  pages={11381--11389},
  year={2023}
}

@inproceedings{zhou2023calm,
  title={CALM: An Enhanced Encoding and Confidence Evaluating Framework for Trustworthy Multi-view Learning},
  author={Zhou, Hai and Xue, Zhe and Liu, Ying and Li, Boang and Du, Junping and Liang, Meiyu and Qi, Yuankai},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={3108--3116},
  year={2023}
}

@inproceedings{zou2023dpnet,
  title={DPNET: Dynamic Poly-attention Network for Trustworthy Multi-modal Classification},
  author={Zou, Xin and Tang, Chang and Zheng, Xiao and Li, Zhenglai and He, Xiao and An, Shan and Liu, Xinwang},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={3550--3559},
  year={2023}
}

