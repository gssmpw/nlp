@inproceedings{radenovic2023filtering,
  title={Filtering, distillation, and hard negatives for vision-language pre-training},
  author={Radenovic, Filip and Dubey, Abhimanyu and Kadian, Abhishek and Mihaylov, Todor and Vandenhende, Simon and Patel, Yash and Wen, Yi and Ramanathan, Vignesh and Mahajan, Dhruv},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6967--6977},
  year={2023}
}

@inproceedings{
Federici2020Learning,
title={Learning Robust Representations via Multi-View Information Bottleneck},
author={Marco Federici and Anjan Dutta and Patrick Forré and Nate Kushman and Zeynep Akata},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=B1xwcyHFDr}
}

@inproceedings{han2020trusted,
  title={Trusted multi-view classification},
  author={Han, Zongbo and Zhang, Changqing and Fu, Huazhu and Zhou, Joey Tianyi},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{geng2021uncertainty,
  title={Uncertainty-aware multi-view representation learning},
  author={Geng, Yu and Han, Zongbo and Zhang, Changqing and Hu, Qinghua},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={9},
  pages={7545--7553},
  year={2021}
}

@inproceedings{han2022multimodal,
  title={Multimodal dynamics: Dynamical fusion for trustworthy multimodal classification},
  author={Han, Zongbo and Yang, Fan and Huang, Junzhou and Zhang, Changqing and Yao, Jianhua},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={20707--20717},
  year={2022}
}

@inproceedings{zhang2023provable,
  title={Provable dynamic fusion for low-quality multimodal data},
  author={Zhang, Qingyang and Wu, Haitao and Zhang, Changqing and Hu, Qinghua and Fu, Huazhu and Zhou, Joey Tianyi and Peng, Xi},
  booktitle={International conference on machine learning},
  pages={41753--41769},
  year={2023},
  organization={PMLR}
}

@inproceedings{zheng2023multi,
  title={Multi-level confidence learning for trustworthy multimodal classification},
  author={Zheng, Xiao and Tang, Chang and Wan, Zhiguo and Hu, Chengyu and Zhang, Wei},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={9},
  pages={11381--11389},
  year={2023}
}

@inproceedings{zou2023dpnet,
  title={DPNET: Dynamic Poly-attention Network for Trustworthy Multi-modal Classification},
  author={Zou, Xin and Tang, Chang and Zheng, Xiao and Li, Zhenglai and He, Xiao and An, Shan and Liu, Xinwang},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={3550--3559},
  year={2023}
}

@inproceedings{zhou2023calm,
  title={CALM: An Enhanced Encoding and Confidence Evaluating Framework for Trustworthy Multi-view Learning},
  author={Zhou, Hai and Xue, Zhe and Liu, Ying and Li, Boang and Du, Junping and Liang, Meiyu and Qi, Yuankai},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={3108--3116},
  year={2023}
}

@inproceedings{
cao2024predictive,
title={Predictive Dynamic Fusion},
author={Bing Cao and Yinan Xia and Yi Ding and Changqing Zhang and Qinghua Hu},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=LYpGLrC4oq}
}

@article{zheng2024global,
  title={Global and cross-modal feature aggregation for multi-omics data classification and application on drug response prediction},
  author={Zheng, Xiao and Wang, Minhui and Huang, Kai and Zhu, En},
  journal={Information Fusion},
  volume={102},
  pages={102077},
  year={2024},
  publisher={Elsevier}
}

@article{zhang2024multimodal,
  title={Multimodal fusion on low-quality data: A comprehensive survey},
  author={Zhang, Qingyang and Wei, Yake and Han, Zongbo and Fu, Huazhu and Peng, Xi and Deng, Cheng and Hu, Qinghua and Xu, Cai and Wen, Jie and Hu, Di and others},
  journal={arXiv preprint arXiv:2404.18947},
  year={2024}
}

@article{baysoy2023technological,
  title={The technological landscape and applications of single-cell multi-omics},
  author={Baysoy, Alev and Bai, Zhiliang and Satija, Rahul and Fan, Rong},
  journal={Nature Reviews Molecular Cell Biology},
  volume={24},
  number={10},
  pages={695--713},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{vandereyken2023methods,
  title={Methods and applications for single-cell and spatial multi-omics},
  author={Vandereyken, Katy and Sifrim, Alejandro and Thienpont, Bernard and Voet, Thierry},
  journal={Nature Reviews Genetics},
  volume={24},
  number={8},
  pages={494--515},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{wang2024progress,
  title={Progress in single-cell multimodal sequencing and multi-omics data integration},
  author={Wang, Xuefei and Wu, Xinchao and Hong, Ni and Jin, Wenfei},
  journal={Biophysical Reviews},
  volume={16},
  number={1},
  pages={13--28},
  year={2024},
  publisher={Springer}
}

@article{zhu2020single,
  title={Single-cell multimodal omics: the power of many},
  author={Zhu, Chenxu and Preissl, Sebastian and Ren, Bing},
  journal={Nature methods},
  volume={17},
  number={1},
  pages={11--14},
  year={2020},
  publisher={Nature Publishing Group US New York}
}

@article{vinoth2024multi,
  title={Multi-sensor fusion and segmentation for autonomous vehicle multi-object tracking using deep Q networks},
  author={Vinoth, K and Sasikumar, P},
  journal={Scientific Reports},
  volume={14},
  number={1},
  pages={31130},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{huang2022multi,
  title={Multi-modal sensor fusion for auto driving perception: A survey},
  author={Huang, Keli and Shi, Botian and Li, Xiang and Li, Xin and Huang, Siyuan and Li, Yikang},
  journal={arXiv preprint arXiv:2202.02703},
  year={2022}
}

@article{yeong2021sensor,
  title={Sensor and sensor fusion technology in autonomous vehicles: A review},
  author={Yeong, De Jong and Velasco-Hernandez, Gustavo and Barry, John and Walsh, Joseph},
  journal={Sensors},
  volume={21},
  number={6},
  pages={2140},
  year={2021},
  publisher={MDPI}
}

@article{tian2024multi,
  title={Multi-sensor Information Fusion in Internet of Vehicles Based on Deep Learning: A Review},
  author={Tian, Di and Li, Jiabo and Lei, Jingyuan},
  journal={Neurocomputing},
  pages={128886},
  year={2024},
  publisher={Elsevier}
}

@article{wang2023multi,
  title={Multi-sensor fusion technology for 3D object detection in autonomous driving: A review},
  author={Wang, Xuan and Li, Kaiqiang and Chehri, Abdellah},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2023},
  publisher={IEEE}
}

@article{zhang2024ninerec,
  title={Ninerec: A benchmark dataset suite for evaluating transferable recommendation},
  author={Zhang, Jiaqi and Cheng, Yu and Ni, Yongxin and Pan, Yunzhu and Yuan, Zheng and Fu, Junchen and Li, Youhua and Wang, Jie and Yuan, Fajie},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@ARTICLE{10461053,
  author={Zhang, Jiaqi and Cheng, Yu and Ni, Yongxin and Pan, Yunzhu and Yuan, Zheng and Fu, Junchen and Li, Youhua and Wang, Jie and Yuan, Fajie},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={NineRec: A Benchmark Dataset Suite for Evaluating Transferable Recommendation}, 
  year={2024},
  volume={},
  number={},
  pages={1-12},
  keywords={Videos;Biological system modeling;Benchmark testing;Visualization;Natural language processing;Computational modeling;Behavioral sciences;Benchmark;dataset;fine-tuning;modality-based recommendation;pre-training;transferable recommendation},
  doi={10.1109/TPAMI.2024.3373868}}

@inproceedings{guo2024lgmrec,
  title={LGMRec: Local and Global Graph Learning for Multimodal Recommendation},
  author={Guo, Zhiqiang and Li, Jianjun and Li, Guohui and Wang, Chaoyang and Shi, Si and Ruan, Bin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={8},
  pages={8454--8462},
  year={2024}
}

@inproceedings{changpinyo2021conceptual,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3558--3568},
  year={2021}
}

@inproceedings{zhang2019weakly,
  title={Weakly aligned cross-modal learning for multispectral pedestrian detection},
  author={Zhang, Lu and Zhu, Xiangyu and Chen, Xiangyu and Yang, Xu and Lei, Zhen and Liu, Zhiyong},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={5127--5137},
  year={2019}
}


@article{huang2021learning,
  title={Learning with noisy correspondence for cross-modal matching},
  author={Huang, Zhenyu and Niu, Guocheng and Liu, Xiao and Ding, Wenbiao and Xiao, Xinyan and Wu, Hua and Peng, Xi},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29406--29419},
  year={2021}
}

@article{li2021align,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{huang2023nlip,
  title={Nlip: Noise-robust language-image pre-training},
  author={Huang, Runhui and Long, Yanxin and Han, Jianhua and Xu, Hang and Liang, Xiwen and Xu, Chunjing and Liang, Xiaodan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={1},
  pages={926--934},
  year={2023}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX 16},
  pages={121--137},
  year={2020},
  organization={Springer}
}

@inproceedings{nakada2023understanding,
  title={Understanding multimodal contrastive learning and incorporating unpaired data},
  author={Nakada, Ryumei and Gulluk, Halil Ibrahim and Deng, Zhun and Ji, Wenlong and Zou, James and Zhang, Linjun},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4348--4380},
  year={2023},
  organization={PMLR}
}

@article{zeng2023semantic,
  title={Semantic invariant multi-view clustering with fully incomplete information},
  author={Zeng, Pengxin and Yang, Mouxing and Lu, Yiding and Zhang, Changqing and Hu, Peng and Peng, Xi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@article{han2022trusted,
  title={Trusted multi-view classification with dynamic evidential fusion},
  author={Han, Zongbo and Zhang, Changqing and Fu, Huazhu and Zhou, Joey Tianyi},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={2},
  pages={2551--2566},
  year={2022},
  publisher={IEEE}
}

@inproceedings{cheng2019noise,
  title={Noise-aware unsupervised deep lidar-stereo fusion},
  author={Cheng, Xuelian and Zhong, Yiran and Dai, Yuchao and Ji, Pan and Li, Hongdong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6339--6348},
  year={2019}
}

@inproceedings{yang2024test,
  title={Test-time Adaptation against Multi-modal Reliability Bias},
  author={Yang, Mouxing and Li, Yunfan and Zhang, Changqing and Hu, Peng and Peng, Xi},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{a2012overview,
  title={Overview and findings from the religious orders study},
  author={A Bennett, David and A Schneider, Julie and Arvanitakis, Zoe and S Wilson, Robert},
  journal={Current Alzheimer Research},
  volume={9},
  number={6},
  pages={628--645},
  year={2012},
  publisher={Bentham Science Publishers}
}

@misc{de2018multi,
  title={A multi-omic atlas of the human frontal cortex for aging and Alzheimer’s disease research. Sci Data 5: 180142},
  author={De Jager, PL and Ma, Y and McCabe, C and Xu, J and Vardarajan, BN and Felsky, D and Klein, HU and White, CC and Peters, MA and Lodgson, B and others},
  year={2018}
}

@article{wah2011caltech,
  title={The caltech-ucsd birds-200-2011 dataset},
  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  year={2011},
  publisher={California Institute of Technology}
}

@inproceedings{wang2015recipe,
  title={Recipe recognition with large multimodal food dataset},
  author={Wang, Xin and Kumar, Devinder and Thome, Nicolas and Cord, Matthieu and Precioso, Frederic},
  booktitle={2015 IEEE International Conference on Multimedia \& Expo Workshops (ICMEW)},
  pages={1--6},
  year={2015},
  organization={IEEE}
}

@misc{lingle9cancer,
  title={The cancer genome atlas breast invasive carcinoma collection (TCGA-BRCA)(Version 3)[Data set]. Cancer Imag. Arch.(2016)},
  author={Lingle, W and others}
}

@article{mukherjee2015religious,
  title={Religious Orders Study/Memory and Aging Project Investigators; Alzheimer’s Disease Genetics Consortium},
  author={Mukherjee, S and Walter, S and Kauwe, JSK and Adult Changes in Thought Study Investigators and others},
  journal={Genetically predicted body mass index and Alzheimer’s disease-related phenotypes in three large samples: Mendelian randomization analyses. Alzheimers Dement},
  volume={11},
  number={12},
  pages={1439--1451},
  year={2015}
}

@article{baltruvsaitis2018multimodal,
  title={Multimodal machine learning: A survey and taxonomy},
  author={Baltru{\v{s}}aitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={2},
  pages={423--443},
  year={2018},
  publisher={IEEE}
}

@article{ramachandram2017deep,
  title={Deep multimodal learning: A survey on recent advances and trends},
  author={Ramachandram, Dhanesh and Taylor, Graham W},
  journal={IEEE signal processing magazine},
  volume={34},
  number={6},
  pages={96--108},
  year={2017},
  publisher={IEEE}
}

@article{wang2020deep,
  title={Deep multimodal fusion by channel exchanging},
  author={Wang, Yikai and Huang, Wenbing and Sun, Fuchun and Xu, Tingyang and Rong, Yu and Huang, Junzhou},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={4835--4845},
  year={2020}
}

@inproceedings{poria2015deep,
  title={Deep convolutional neural network textual features and multiple kernel learning for utterance-level multimodal sentiment analysis},
  author={Poria, Soujanya and Cambria, Erik and Gelbukh, Alexander},
  booktitle={Proceedings of the 2015 conference on empirical methods in natural language processing},
  pages={2539--2544},
  year={2015}
}

@inproceedings{tsai2019multimodal,
  title={Multimodal transformer for unaligned multimodal language sequences},
  author={Tsai, Yao-Hung Hubert and Bai, Shaojie and Liang, Paul Pu and Kolter, J Zico and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
  booktitle={Proceedings of the conference. Association for computational linguistics. Meeting},
  volume={2019},
  pages={6558},
  year={2019},
  organization={NIH Public Access}
}

@article{hang2021multi,
  title={Multi-modal multi-instance learning using weakly correlated histopathological images and tabular clinical information in Medical Image Computing and Computer Assisted Intervention--MICCAI 2021: 24th International Conference, Strasbourg, France, September 27--October 1, 2021},
  author={Hang, Li and Fan, Yang and Xiaohan, Xing and others},
  journal={Proceedings, Part VIII},
  volume={24},
  pages={529--539Springer},
  year={2021}
}

@inproceedings{lee2021variational,
  title={A variational information bottleneck approach to multi-omics data integration},
  author={Lee, Changhee and Van der Schaar, Mihaela},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1513--1521},
  year={2021},
  organization={PMLR}
}

@article{kiela2019supervised,
  title={Supervised multimodal bitransformers for classifying images and text},
  author={Kiela, Douwe and Bhooshan, Suvrat and Firooz, Hamed and Perez, Ethan and Testuggine, Davide},
  journal={arXiv preprint arXiv:1909.02950},
  year={2019}
}

@article{huang2021makes,
  title={What makes multi-modal learning better than single (provably)},
  author={Huang, Yu and Du, Chenzhuang and Xue, Zihui and Chen, Xuanyao and Zhao, Hang and Huang, Longbo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={10944--10956},
  year={2021}
}

@inproceedings{huang2020multimodal,
  title={Multimodal transformer fusion for continuous emotion recognition},
  author={Huang, Jian and Tao, Jianhua and Liu, Bin and Lian, Zheng and Niu, Mingyue},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3507--3511},
  year={2020},
  organization={IEEE}
}

@inproceedings{hu2021unit,
  title={Unit: Multimodal multitask learning with a unified transformer},
  author={Hu, Ronghang and Singh, Amanpreet},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1439--1449},
  year={2021}
}

@article{hong2020more,
  title={More diverse means better: Multimodal deep learning meets remote-sensing imagery classification},
  author={Hong, Danfeng and Gao, Lianru and Yokoya, Naoto and Yao, Jing and Chanussot, Jocelyn and Du, Qian and Zhang, Bing},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={59},
  number={5},
  pages={4340--4354},
  year={2020},
  publisher={IEEE}
}

@article{arevalo2017gated,
  title={Gated multimodal units for information fusion},
  author={Arevalo, John and Solorio, Thamar and Montes-y-G{\'o}mez, Manuel and Gonz{\'a}lez, Fabio A},
  journal={arXiv preprint arXiv:1702.01992},
  year={2017}
}

@article{wang2021mogonet,
  title={MOGONET integrates multi-omics data using graph convolutional networks allowing patient classification and biomarker identification},
  author={Wang, Tongxin and Shao, Wei and Huang, Zhi and Tang, Haixu and Zhang, Jie and Ding, Zhengming and Huang, Kun},
  journal={Nature communications},
  volume={12},
  number={1},
  pages={3445},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{subedar2019uncertainty,
  title={Uncertainty-aware audiovisual activity recognition using deep bayesian variational inference},
  author={Subedar, Mahesh and Krishnan, Ranganath and Meyer, Paulo Lopez and Tickoo, Omesh and Huang, Jonathan},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6301--6310},
  year={2019}
}

@article{simonyan2014two,
  title={Two-stream convolutional networks for action recognition in videos},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{natarajan2012multimodal,
  title={Multimodal feature fusion for robust event detection in web videos},
  author={Natarajan, Pradeep and Wu, Shuang and Vitaladevuni, Shiv and Zhuang, Xiaodan and Tsakalidis, Stavros and Park, Unsang and Prasad, Rohit and Natarajan, Premkumar},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1298--1305},
  year={2012},
  organization={IEEE}
}

@article{gadre2024datacomp,
  title={Datacomp: In search of the next generation of multimodal datasets},
  author={Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2556--2565},
  year={2018}
}
