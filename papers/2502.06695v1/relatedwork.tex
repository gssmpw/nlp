\section{Related Work}
\label{sec:related_work}
Methods have been proposed to fight against spurious correlation. 

\subsection{Using Training Group Information} Most methods that fight against spurious correlation assume to have training group annotations. Some approaches directly modify ERM; for example, groupDRO~\citep{sagawa2019distributionally} and its variant CVaRDRO~\citep{duchi2021learning} aim to minimize the worst group error rather than the average error used by ERM. Similarly, when group information is available, methods from out-of-distribution generalization~\citep{arjovsky2019invariant,krueger2021out,wald2021calibration,krueger2021out} can be framed to learn more robust-to-spurious-correlation features. Other approaches use training group information to synthetically augment minority group samples through generative modeling \citep{goel2020model}. Reweighting and subsampling techniques can also be used to balance majority and minority groups~\citep{sagawa2020investigation,byrd2019effect}. However, all these works share a major limitation:  they rely on group information, which is difficult to obtain for large datasets. Indeed, manually annotating group labels requires task-specific expertise, making it prohibitively costly.

\subsection{Without Using Training Group Information} Given the expensive cost of manual group annotation, there has been a growing interest in combating spurious correlation without group annotations in the training set. Some methods observe the training dynamics of SGD and introduce margin-based regularization terms to promote more robust feature learning~\citep{pezeshki2021gradient, puli2023don}. Among the most popular approaches are two-stage algorithms that do not assume prior group annotation for the training set; these methods typically begin with ERM to infer minority group samples. In the second stage, robustness to spurious correlations is enhanced, for instance through contrastive learning~\citep{zhang2022correct} or by up-weighting the inferred minority group samples~\citep{qiu2023simple, liu2021just}. A recent study~\citep{kirichenko2022last} underscores the importance of the first stage ERM, by showing that ERM learns both spurious and \textit{core} (or robust-to -spurious-correlation) features. It then proposes retraining only the classifier head in a second stage using a group-balanced validation set. This approach has been extended to HTT-DFR~\citep{hameed2024not}, where the second phase retrains a sparse network. Inspired by ERM’s ability to capture core features, our work aims to reduce the reliance on spurious correlations by focusing on memorizing neurons, offering a simpler alternative to computationally demanding two-stage methods.
%Reweighting schemes
%Group inference

\subsection{Memorization and Generalization Links} Recent research has made strides in understanding the relationship between generalization and memorization in deep learning. Memorization is often defined as the model's capacity to correctly predict \textit{atypical} examples with potentially wrong patterns~\citep{maini2023can}. Several studies, such as~\citet{jiang2021characterizing, carlini2019distribution}, have introduced metrics to quantify the degree to which an example is regular or atypical. Some initial works observed that memorization primarily occurs in later layers of the network~\citep{baldock2021deep, stephenson2021geometry}, while recent findings from~\citet{maini2023can} suggest that memorization can emerge at any depth within a network. Additionally, \citet{maini2023can} introduces a method for localizing memorization by determining the minimum number of neurons required to change a model’s predictions. Our work builds on this method, applying it beyond the context of label noise, as in the original study, to address spurious correlations. Various studies on mechanistic interpretability further reveal that certain neurons in deep networks specialize in capturing specific patterns, often associated with spurious features~\citep{zenke2017continual,cheung2019superposition,hendel2023context,kalibhat2023identifying}.
%Where do deep neural network memorization
%When do dnn memorize
%How do we