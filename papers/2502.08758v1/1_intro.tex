The deployment of \gls{DL} models in \gls{mMIMO} systems has shown great potential to advance wireless communication, particularly to optimize beamforming strategies. \Gls{DNN}s can dynamically adjust the beamforming to achieve better performance than traditional methods. However, the large size and overparameterization of these networks present challenges for practical deployment, especially on resource-constrained edge devices where memory, energy consumption, and processing latency are critically limited.

Designing energy-efficient communication systems is critical for the realization of \gls{mMIMO} systems. However, finding a precoding solution that maximizes energy efficiency under low-resolution quantizer constraints remains a significant challenge\cite{choi2022energy}. Quantized \glspl{CNN} are a popular choice for reducing hardware complexity. In \glspl{CNN}, quantization can be applied to inputs, weights, and activations~\cite{9150443}. Typically, weights and activations are represented using 32-bit or 64-bit floating-point formats, but they can be quantized to lower-precision fixed-point representations, such as 2-bit or even 1-bit precision, to further reduce computational and memory requirements. Lowering the precision leads to a smaller model size; however, it can also reduce accuracy, so choosing the number of precision bits is a non-trivial task.

These constraints hinder the direct application of DNNs in real-world mMIMO systems.
% , particularly when compared to more computational methods like Zero Forcing (ZF)~\cite{wiesel2008zero} and the \gls{WMMSE} algorithm~\cite{shi2023robust}. 
The celebrated \gls{WMMSE} algorithm proposed in~\cite{shi2011iteratively} is based on the equivalence between the gls{SINR} and mean square error, which is then solved using the block coordinate descent method. The WMMSE algorithm provides state-of-the-art performance and is widely used as a benchmark in the literature. However, existing iterative algorithms like WMMSE face challenges due to their computational complexity, which grows rapidly with the number of antennas and the network size. This increase in complexity leads to higher latency, making such algorithms less suitable for real-time applications or large-scale systems where rapid decision-making is critical.

To address these resource limitations, quantization techniques have emerged as an effective solution. Quantization reduces the complexity of neural networks by lowering the bit-width of model weights and activations, which decreases memory usage and energy consumption. Common approaches such as \gls{PTQ} and \gls{QAT} apply uniform precision across the entire network to optimize performance on resource-constrained platforms~\cite{720541, DBLP:journals/corr/HanMD15}. However, these methods often fail to account for the varying sensitivity of different network layers to quantization, leading to inefficiencies and potential performance loss when aggressive quantization is applied uniformly.

In contrast, \gls{MPQ} provides a more flexible approach by allowing different layers to use varying bit-widths, enabling a better balance between accuracy and energy efficiency~\cite{DBLP:journals/corr/abs-1805-06085}. By leveraging search algorithms such as Exhaustive Search, mixed-precision quantization can optimize bit-width allocation for specific layers, leading to significant reductions in energy consumption while maintaining high performance. This approach is particularly advantageous for complex models like \gls{DNN}s, which are widely used in energy-efficient tasks such as real-time signal processing in mMIMO systems.

This paper proposes a mixed-precision quantization framework, augmented with Neural Architecture Search (NAS)\cite{elsken2019neural}, to optimize energy consumption in DL models used for mMIMO beamforming. Our approach employs a streamlined neural architecture with a single CNN layer followed by three fully connected layers, designed to balance computational complexity and \gls{SINR} performance. Additionally, by adapting our quantization strategy to site-specific conditions using ray-tracing datasets, we further enhance the model's energy efficiency without sacrificing accuracy or SINR performance.

In this paper, we address the challenge of enhancing energy efficiency in \gls{DL}-based beamforming for \gls{mMIMO} systems. We propose a mixed-precision quantization-aware framework that significantly reduces energy consumption compared to standard deep learning methods while maintaining competitive sum rate performance. This approach achieves results comparable to traditional techniques such as \gls{ZF} and \gls{WMMSE}, with a strong emphasis on energy efficiency.
Additionally, we introduce site-specific model compression, a scalable method designed to adapt to unique site conditions. By leveraging site-specific ray-tracing datasets, this approach enables adaptive quantization that accounts for environmental factors, enhancing energy efficiency without compromising accuracy. 
This work establishes a solid foundation for advancing energy-efficient deep learning-based beamforming, offering a compelling alternative to conventional methods like ZF and WMMSE, particularly in scenarios where energy consumption is a critical concern.
