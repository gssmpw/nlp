\section{Related Work}
\subsection{Recommender System}
% first introduce CRS - on hold

Sequential recommendation methods~\citep{gru4rec,bert4rec,sasrec,ning2024information} primarily focus on developing temporal encoders to capture both short- and long-term user interests. The evolution of these encoders has progressed from GRU units~\citep{gru4rec}, to more advanced architectures such as self-attention mechanisms (e.g., SASRec~\citep{sasrec}), bidirectional encoders (e.g., BERT4Rec~\citep{bert4rec} with masked item training), graph neural networks~\citep{he2020lightgcn,nmcdr,xu2024rethinking}, and other Transformer-based models~\citep{xu2024towards}.
In the context of embracing large language models, generative recommenders~\citep{p5,kai-lightlm,metaRec} treat item indices as tokens and predict them in a generative manner. Meanwhile, LLMs~\citep{e4srec,slmrec} are utilized to play as a sequential embedding extractor to improve the recommendation performance. In our framework design, all recommendation models can be considered as components of the tools.

Before large language model become popular, conversational recommendation system (CRS)~\citep{2018CRS,zhang2018CRS,qu2019bert} aims at designing better dialogue understanding models or incorporating reinforcement learning for multiple dialogues answering. Due to the capacity of the conventional language model, it lose the flexibility of the dialogue including the dialogue format and number of turns. To resolve this problem, some researchers~\citep{LLM+CRSgoogle,LLM+CRS2} leverage the power of LLM to better understand the intention of user. 

% echo chamber based on the popularity and filtering of our work | introduce fairness yunqi to introduce to protect  | from protecting of irrevalant item / long-tailed items / 

The echo chamber effect occurs when individuals are exposed only to information and opinions that reinforce their existing beliefs within their social networks~\citep{echoeffect1,echoeffect2,echoeffect3}, leading to a lack of diverse perspectives and increased polarization~\citep{polar1,polar2,polar3}. In the context of recommender systems, researchers have begun to study echo chambers and feedback loops~\citep{echochamber,echochamber2,chamberother1,chamberother2,chamberother3,chamberotherkdd}. Kalimeris et al.~\citep{chamberotherkdd} propose a matrix factorization-based recommender system with a theoretical framework for modeling dynamic user interests, while $\partial$CCF~\citep{echoeffect2} employs counterfactual reasoning to mitigate echo chambers.

\subsection{Personal Language-based Agent}
In the early stages, some researchers~\citep{zhang2018personalizing, park2023generative, shanahan2023role} in the NLP field developed dialogue agents with personas to enhance dialogue quality. Language models~\citep{park2023generative} are prompted with role descriptions to simulate realistic interactions by storing experiences, synthesizing memories, and dynamically planning actions, resulting in believable individual and social behaviors within interactive environments. 
% webshop mind2web, travel agent or other agents
% recagent
WebShop~\citep{webshop} attempts to understand product attributes from human-provided text instructions using reinforcement learning and imitation learning. Similar to traditional conversational recommender systems (CRS)~\citep{zhang2018CRS}, it is impractical for users to describe each product attribute every time. With the advancement of large language models (such as GPTs~\citep{gpt4}), many researchers~\citep{webagent,mind2web,travelagent,mei2024aios} have begun designing domain-specific agents that integrate various tool learning and memory mechanisms.

More recently, recommendation agents (RecAgent)~\citep{toolrec,wang2023recmind,generativerecagent,agentcf,wang2024macrec,huang2023recommender} have been developed to simulate user behaviors and predict user-item interactions. A common design feature among these agents is the use of historical interaction information as user memory~\citep{toolrec,wang2023recmind,huang2023recommender}, with LLMs utilized to generate the ranking results. Unlike platform-side RecAgents, $\model$ and $\modelplus$ are the first to operate on the user side, generating re-ranking results based on user instructions and individual memory, unaffected by the influence of advantaged users.

% 1. [improve performance] trainable reranker or utilize existing ranking model as tools but combine with existing personalized memory mechanism.

% 2. [fair comparison] long-text more negative samples fair comparison. 

% 3. [More Interpretable]

% 4. [Agents interact with RecSys / autonomus interaction/ mutual learning ]


% 1. Rank as tools / 

% 2. Multimodal information input

% 3. Long-context more negative samples.

% 4. User agent and RecSys mutual learning/improvement

% 5. Next generation rec promote trustworthy recsys, more interpretable (text saved memory â€“ dynamic process accessible.), fairness (user instruction guided), | connect other task such as social network


% \bibliography{iclr2025_conference}
% \bibliographystyle{iclr2025_conference}
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-sigconf}
% \newpage

\clearpage
\onecolumn