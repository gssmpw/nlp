\section{Relationship Specification}

\tool~focuses on proposing a reading-optimized design for \final{presenting relationships, rather than specifying them. 
Additionally, we have developed a simple stand-alone proof-of-concept notebook plugin for specifying relationships}
through direct manipulations.
In this plugin users can select relevant text or code and draw a bounding box or freehand sketch on the output to indicate that selected cells or segments are related.
\final{The plugin then records the relationships specified through users' interactions in a text file}, formatted according to the defined formulation.
Using this relationship file, \tool further visualizes and presents the relationships, as described in~\autoref{sec:system_design}.
Please refer to the supplementary material for more details.

% To demonstrate this process, we have implemented a simple, \final{stand-alone proof-of-concept notebook plugin} and have included it in the supplementary material.
% Details can be found in the supplementary material.
% But we have implemented a simple \final{stand-alone proof-of-concept notebook plugin, a authoring tool to support relationship specification, rather than the authoring operation optimized} and have included it in the supplementary material.


\begin{figure*}[t!]
\textbf  \centering
  \includegraphics[width=1.0\textwidth,alt={This figure illustrates an example comprehension question from the user study and how participants could navigate and use \tool to arrive at the correct answer. Part (A) displays a multiple-choice question: "What operations were performed on TotalBsmtSF before applying the log transformation, and why were these steps taken?" The options include: replacing missing values with the feature's mean to address accuracy issues (A), replacing zero values with the feature's mean to avoid logarithmic transformation issues (B), deleting all records where TotalBsmtSF values were zero as erroneous entries (C), creating a new variable named HasBsmt to distinguish cases where TotalBsmtSF is zero to handle logarithmic transformations (D, the correct answer highlighted in red), and the option "I don't know" (E).
Part (B) contains the corresponding notebook content needed to answer the question, displayed in three sections. The first section (b1) highlights the code performing the log transformation on TotalBsmtSF, specifying that it only applies to non-zero values. The second section (b2) provides textual commentary that the log transformation ignores zero values. The third section (b3) displays the preceding code that creates the variable HasBsmt to distinguish whether TotalBsmtSF is zero. The final section (b4) offers a textual explanation (via hover interaction) confirming that HasBsmt is used to handle zero values, allowing the log transformation to proceed correctly.
Through these steps, participants can logically deduce that the correct answer is D.}]{figures/example_question.png}
  \caption{\yanna{An example question from the user study and a potential process to get the correct answer using \tool. (A) displays the question, while (B) provides the relevant information needed to answer it. 
 % The alphanumeric system such as (b1) is used to identify portions of the figures.
  To get the correct answer, participants could first locate the cell performing the log transformation on \textit{TotalBsmtSF} (b1), \final{and} identify that the log operation excludes values of zero (b2). They would then examine the preceding code (b3) and hover over it to access the textual explanation (b4), revealing that a new variable, \textit{HasBsmt}, was created to distinguish whether \textit{TotalBsmtSF} is zero or not. Based on this process, participants could identify the correct answer as \textit{D}.}}
  \label{fig:example_question}
  \vspace{-1em}
\end{figure*}



\section{Evaluation}

We conducted a within-subject user study with 12 participants to evaluate the usability and effectiveness of \tool in  \final{facilitating identifying and navigating relationships between text, code, and outputs in notebooks}.
Participants were tasked with 
answer\final{ing} questions based on provided notebooks, using both \tool and the traditional Jupyter notebook interface as \final{a} baseline for comparison.
The study setting is detailed in~\autoref{sec:study_setup}, followed by an analysis of the results in~\autoref{sec:results}.


\subsection{Study Setup}
\label{sec:study_setup}

\textbf{Participants.}
We recruited 12 participants (P1-P12, 6 men and 6 women, 22-31 years old, average age 25.1) through social media and word-of-mouth advertisements.
They were two software engineers, nine postgraduate researchers, and one postdoctoral researcher with diverse backgrounds, including visualization, human-computer interaction, database management, programming languages, geographic information systems, and computer vision.
\yanna{Participants reported average familiarity scores of 3.7 for Jupyter Notebook and 4.2 for Python, on a scale from 1 (not at all familiar) to 5 (extremely familiar).}
Each participant received compensation of US \$10/hour for completing the user study.


\textbf{Study materials.}
We first selected two notebooks,~\ie~the \textit{House} notebook\footnote{https://www.kaggle.com/code/pmarcelino/comprehensive-data-exploration-with-python} 
and \textit{Titanic} notebook\footnote{https://www.kaggle.com/code/startupsci/titanic-data-science-solutions},
from the popular Kaggle competitions~\cite{wang2022documentation}.
They have been widely used to evaluate the effectiveness and usability of the computational notebook plugins~\cite{li2023notable, wang2024outlinespark, zheng2022nb2slides}.
Specifically, \textit{House} notebook contains 55 text cells and 32 code cells with 24 output cells, while \textit{Titanic} notebook contains 49 text cells and 52 code cells with 49 output cells.

\revise{We invited two participants from the formative study (FP2 and FP4), each to help identify the relationship set $R$ for one of the notebooks in the format mentioned in \autoref{sec:relationship_formulation}.
We asked them to assume they were the authors of the notebook preparing their content to share their notebook with a wide audience. 
This task involved annotating the relationships between the information they believed would facilitate understanding the notebooks.}
Subsequently, we utilized \tool to display these relationships, and invited FP2 and FP4 to review and, if necessary, refine the relationships. 
Through this iterative process, the \textit{House} notebook contains 56 relationships, while the \textit{Titanic} notebook contains 100 relationships.
The specifics of these relationships, along with their distribution across different types, are reported in the supplementary material. 


We designed eight questions for each notebook to encompass eight distinct relationship types.
\yanna{Following the questions design in~\cite{wang2020callisto}, we designed the questions according to the Bloom's taxonomy~\cite{armstrong2010bloom} to assess \final{how well participants could identify and navigate relationships}.
The answer to each question required information from at least two cells, requiring participants to identify \final{and navigate} the relationships between different pieces of information.
\autoref{fig:example_question} presents one example choice-based question, where participants are required to \textit{identify} the operations performed before applying a log transformation and \textit{explain} the rationale behind those steps using information from three cells.
}
Choice-based questions were chosen over open-ended questions to mitigate issues observed during a pilot study with researchers out of this project:
1) Participants spent most of their time retrieving information rather than engaging in deep understanding.
When asked to answer questions using textual descriptions and providing evidence via screenshots, they often copied and pasted answers linked by \tool, without making an effort to \final{read and understand} the content; and
2) Evaluating answers to open-ended questions is challenging, introducing subjectivity and potential bias.
\yanna{Distractor answer items were generated using GPT-4~\cite{openai2023gpt4}, prompted to create plausible yet incorrect options based on the given question and correct answers.}
Details of questions can be found in the supplementary material.


\begin{figure}[t!]
\textbf  \centering
  \includegraphics[width=\linewidth,alt={A series of four box plots comparing task performance metrics between a baseline tool, represented by gray triangles, and InterLink, represented by black triangles. From left to right, the metrics are task accuracy, confidence level, average time spent on tasks, and IES Score. A star above the comparisons indicates a statistically significant difference with a p-value less than 0.05. The first and last box plots, representing accuracy and IES score, show significant improvements when using InterLink over the baseline, as indicated by the stars. The confidence depicts higher medians while time box plots depict lower medians for 'InterLink', suggesting marginally improved average time and confidence levels when using this tool.}]{figures/task_performance.png}
  \caption{Task performance metrics between baseline and \tool, including task accuracy, confidence level, average time, and IES score, with * indicating $p<0.05$. Overall, participants using \tool demonstrated significantly higher task accuracy and \yanna{lower} IES score, along with marginally improved average time and confidence levels.}
  \Description{A series of four box plots comparing task performance metrics between a baseline tool, represented by gray triangles, and InterLink, represented by black triangles. From left to right, the metrics are task accuracy, confidence level, average time spent on tasks, and IES Score. A star above the comparisons indicates a statistically significant difference with a p-value less than 0.05. The first and last box plots, representing accuracy and IES score, show significant improvements when using InterLink over the baseline, as indicated by the stars. The confidence depicts higher medians while time box plots depict lower medians for 'InterLink', suggesting marginally improved average time and confidence levels when using this tool.}
  \label{fig:task_performance}
  \vspace{-1em}
\end{figure}




\textbf{Tasks.}
In our study, participants were tasked with \final{reading} two provided notebooks and completing a test using two interfaces:~\tool and baseline (\ie~the traditional JupyterLab interface).
In each interface, participants \yanna{had} five minutes to overview the notebooks.
\yanna{They then answered eight questions to \final{assess how well they could identify and navigate relationships}, with the notebook remaining visible to \final{avoid the need for demanding memorization}~\cite{kong2019understanding}.
}
Participants completed tasks using the two interfaces across two distinct notebooks.
The experiment included all possible combinations of the two interfaces and two notebooks. To reduce learning effects, the order of the two interfaces was counterbalanced.


\textbf{Procedure.}
The user study lasted approximately 1.5 hours and was conducted through individual online meetings. 
Initially, we presented the project's background and procedures, followed by obtaining the participants' consent to record the sessions.
Regarding \tool, participants undertook a brief tutorial session to familiarize themselves with \tool's components and functionalities, subsequently practicing with \tool using a sample Kaggle notebook
\footnote{https://www.kaggle.com/code/mohitkr05/spotify-data-visualization}. 
The tutorial session concluded once participants indicated they felt sufficiently familiar to use the tool, typically within 15 minutes.
After that, participants would answer 2 questions related to the sample notebook. This is to help them be more familiar with the tasks.
Participants were required to explain their answers for us to check and reinforce the requirement that answers should be based solely on notebook content instead of personal knowledge.
Following the tutorial, participants \final{completed} the formal tasks of using two interfaces sequentially.
Answers were recorded along with the time taken and participants' self-reported confidence levels (on a five-point Likert Scale).
Upon completing the tasks with each interface, participants filled out the questionnaire assessing the effectiveness of the interface in  \final{identifying and navigating relationships} on a five-point Likert scale in a think-aloud protocol.
The details of the questionnaire are shown in the~\autoref{fig:quantitative_result}, where a rating of 1 means ``strongly disagree'' and a rating of 5 means ``strongly agree''. 
For \tool, participants also completed the System Usability Scale (SUS) questionnaire~\cite{brooke1996sus} to assess its usability. 
The study concluded with a semi-structured interview discussing \tool's advantages and disadvantages and its effect on \final{participants' identification and navigation experience of relationships and their understanding of the notebooks}.



\subsection{Results}
\label{sec:results}

In this section, we report the quantitative results and qualitative user feedback of the user study.

\subsubsection{Quantitative Results}

\label{sec:quantitative_analysis}

Next, we describe the quantitative results across three aspects, \ie overall task performance, effectiveness, and usability, with results shown in ~\autoref{fig:task_performance} and ~\autoref{fig:quantitative_result}.




\textbf{Overall performance.}
We measured the task performance of participants using task completion time, task accuracy, confidence levels, and the Inverse Efficiency Score (IES)~\cite{townsend1983ies, zhi2019linking, shi2020calliope}.
Task accuracy was determined by the proportion of correct responses.
Considering that participants may focus on arriving at correct answers while sacrificing time, \final{the} IES was used to balance accuracy and time costs.
It was calculated by dividing the task completion time by the task accuracy.




The results of task performance are shown in~\autoref{fig:task_performance}.
Participants using \tool complete\final{d} tasks \final{13.6\%} more accurately ($0.92\pm0.07$ for \tool and $0.81\pm0.14$ for baseline) and demonstrated a \yanna{lower} IES score ($134\pm19.5$ for \tool and $158\pm28.1$ for baseline), with \yanna{paired t-test} suggesting that the differences are statistically significant (both $p<0.05$).
\tool also showed slight improvements in the average time taken to answer each question (122 seconds for \tool and 128 seconds for baseline) and in self-reported confidence levels (4.3 for \tool and 4.2 for baseline). These differences, however, were not statistically significant.
\revise{Furthermore, participants reported no significant differences in performance when interacting with various notebooks across all aspects (all $p > 0.05$).}

\begin{figure}[t!]
\textbf  \centering
  \includegraphics[width=\linewidth,alt={This figure presents user ratings for effectiveness, with statistical significance indicated by double asterisks denoting a p-value less than 0.01. It compares the effectiveness of InterLink against a baseline tool, showing InterLink as superior in all measured aspects through stacked horizontal bar charts for five questions, Q1 through Q5, with colors ranging from dark red to dark blue indicating rating levels from 1 to 5.}]{figures/quantitative_result.png}
  \caption{This figure presents user ratings for effectiveness of \tool compared to the baseline, with ** indicating $p<0.01$. It demonstrates that \tool significantly outperforms the baseline across all aspects, with all $p<0.01$.}
  \Description{This figure presents user ratings for effectiveness, with statistical significance indicated by double asterisks denoting a p-value less than 0.01. It compares the effectiveness of InterLink against a baseline tool, showing InterLink as superior in all measured aspects through stacked horizontal bar charts for five questions, Q1 through Q5, with colors ranging from dark red to dark blue indicating rating levels from 1 to 5.}
  \label{fig:quantitative_result}
  \vspace{-1em}
\end{figure}



\textbf{Effectiveness.}
\yanna{\autoref{fig:quantitative_result} shows that \tool received significantly higher user ratings for effectiveness in helping \final{users identify and navigate relationships in notebooks} compared to the baseline interface.}
Specifically, \tool significantly \yanna{facilitated participants} to infer the existence of relationships within the notebook (Q1), locate related information more efficiently (Q2), integrate related information for a comprehensive understanding (Q3), and delve into the relationships and related information at various levels of detail (Q4), thereby improving overall notebook understanding (Q5). 
Each of these improvements was statistically significant, with all p-values less than 0.01.
Participants appreciated the effectiveness of \tool in aiding these aspects, with average scores exceeding 4 on a 5-point Likert scale.


\textbf{Usability.}
The usability of \tool, as measured by the System Usability Scale (SUS), indicates a score of 76.5, positioning it as acceptable and better than approximately 80\% of applications~\cite{sauro2016quantifying, bangor2008empirical}. 
Participants generally rated positively framed SUS questions (the odd-numbered ones) above 4 and negatively framed questions (the even-numbered ones) below 2 on average. 
The exception was (Q4), with an average rating of 2.9, indicating that some participants needed technical support in using the system.
More details of the usability ratings are in the supplementary material.



\subsubsection{User Feedback}
\label{sec:qualitative_analysis}
This section presents participants' qualitative feedback about the advantages and limitations of~\tool.

\revise{
\textbf{\tool allows users to focus on \final{understanding by streamlining the retrieval of related contents}.}
Participants generally appreciated how \tool enables \final{them to identify and navigate relationships, making it intuitive and easy to integrate the related contents.}
This \final{reduced their effort spent on} retrieving and recalling related information, allowing them to devote more time \final{to reading and therefore} deepening their understanding. 
For instance, P1 commented, ``\textit{I can spend more time on understanding rather than searching for related information, which is really tedious and annoying}''.
Similarly, P6 noted, ``\textit{I don't need to think about where the related content is anymore—it's right there, and all I need to do is just understanding.}''
Moreover, some participants (P5, P9, and P12) expressed a desire for the tool to be open-sourced and integrated into their existing platforms.
P12 specifically noted, ``\textit{I hope to use this tool in my JupyterLab soon.
Moreover, extending this functionality to other platforms with interconnected contents, such as PowerPoint or Word documents, would be highly valuable.}''
}


\textbf{The relationship visualization of \tool facilitates locating and focusing on related content in computational notebooks.}
All participants recognized that explicit lines and visual cues in \tool significantly ease the process of inferring and locating related information within computational notebooks. 
This feature effectively reduces the need to filter irrelevant information, allowing readers to direct their limited attention to areas that warrant closer examination and avoid unnecessary distractions. 
For example, P1 noted that ``\textit{This design let me have a quick idea of what is related, so I can focus on the critical parts, significantly boosting my productivity}''.
P9 further underscored the utility of such visual aids, noting, ``\textit{such visualizations cohere loosely connected information, enhancing my overall comprehension}''.
Additionally, P2 expressed relief provided by these visual elements, stating, ``\textit{the lines alleviate my concern \final{about} overlooking vital information}''.
Furthermore, participants particularly valued the finer granularity of information provided by visual cues, recognizing its crucial role in clarifying precise and accurate connections across cells. 
This detailed guidance is particularly valuable when the relevant text or \yanna{code} is merely minor parts of a larger cell or in understanding the complex visualizations (as mentioned by P1, P2, P5, P6, P7, P10).
For example, P5 stated that such granularity is critical in ``\textit{enabling a quick grasp of information and significantly reducing the time I spend reading extensive texts and the effort needed to interpret the visualizations}''.
Despite the advantages, P11 voiced a concern about potentially overlooking information not highlighted by visual cues.


% \textbf{The interactions of \tool are intuitive and  facilitate efficient exploration and integration of dispersed information.}
% All participants agreed that the interactions of \tool helped them locate, explore, and integrate the related information efficiently.
\textbf{The hover-to-highlight and click-to-fix interactions are praised for their intuitiveness.}
\tool's interaction design was praised for its intuitiveness, particularly hover-to-highlight and click-to-fix, aligning well with readers' typical information retrieval habits. 
For example, P6 mentioned that ``\textit{
The interaction feels really seamless and helps me know how things are connected in the notebook. 
Especially the part where you hover to highlight things and click to keep them visible – it's super intuitive and just what I'd expect when I'm trying to find and link up information}''.
While P7 appreciated the bidirectional capability for not disrupting the reading flow, stating, ``\textit{The two-way interaction respects my mental model to locate and explore the related information. 
Following the notebook's reading order previously (in \final{the} traditional interface) enforced a forward retrieval of information, since the backward retrieval would disrupt my reading flow}''.
% While P5 appreciated the click-to-fix interaction, stating, ``the cell related multiple cells is always on the screen, making ''

\textbf{The focus mode of \tool facilitates the integration of dispersed information.}
Most participants, except P3, highly praised the focus mode for integrating all related information into a compact, in-situ format on a single page that optimized screen space usage.
This compact presentation was particularly appreciated for reducing cognitive load by minimizing the need to remember and filter unrelated details to find relevant connections, which happens frequently when using the traditional layout (P4, P5, P6, P7).
P4 and P6 further emphasized the benefit of in-situ information presentation in accessing related information while maintaining reading flow from being disrupted by excessive scrolling.
In contrast, P3 thought the focused mode to be redundant, preferring scrolling methods supported by click-to-fix features.
Though useful, some participants complained that the activation of the focus mode through the ``Shift'' key was not inherently intuitive (P1, P7-P10).
This may lead to a reliance on technical assistance to use \tool~(Q4).
Future work should explore alternative intuitive methods that do not clash with existing JupyterLab commands.



\textbf{The side-by-side layout promotes a holistic view and focused attention for \final{identifying and navigating relationships in notebooks}.}
Most participants echoed that the side-by-side layout of \tool, separating text from \yanna{code} and outputs, significantly enhances the \final{identification} and navigation experience \final{of relationships} within computational notebooks. 
P12 stated that ``\textit{the side-by-side \final{layout} is really intuitive and may be the only solution to show the relationship between different \final{elements}}''.
This layout was appreciated for supporting the holistic view of \final{relationships} and enhancing focus.
It promoted a comprehensive grasp of the notebook's structure, with P3 stating, ``\textit{the text on the left serves as a guide, systematically organizing code and output cells, thereby illuminating the purpose of each code block. 
I can quickly get the entire structural composition and the functionality of each block}''.
P5 gave similar comments: ``\textit{The one-to-many relationships in the side-by-side layout make the function and organization of \final{the} \yanna{code} more apparent.
I can easily grasp the notebook's overall structure and the specific roles of different code blocks}''.
Moreover, participants praised that the layout ensured text was always adjacent to \yanna{code} and outputs, thus providing instantaneous access to additional information as needed.
P7 commented, ``\textit{I can grasp both the holistic structure and local details, transitioning between them seamlessly}''.
P6 added, ``\textit{I can easily get information when confusion arises, facilitating the understanding of explanations}''.
Participants also highlighted how this layout augments their focus on specific aspects of computational notebooks.
P2 and P7 underscore the layout's ability to allow a focused understanding of either text or \yanna{code}, thus minimizing distractions and fostering a clearer overview of the notebook.
P6 remarked, ``\textit{This layout really aligns with users' mindset of going through shared notebooks. It starts with a quick summary of the text, \final{and} then lets you dive in deeper if you need to, which really helps understand the \yanna{code}.}''
Despite the overall positive reception, 
a minority of participants mentioned a learning curve when adapting to this new layout (P8, P9, and P11). 
However, they also recognized the potential of the layout to improve \final{reading notebook} with increased familiarity.
For example, P9 mentioned ``\textit{While I am more accustomed to the traditional linear layout due to years of usage, I perceive the new layout as highly beneficial and anticipate its long-term advantages once fully accustomed}''.