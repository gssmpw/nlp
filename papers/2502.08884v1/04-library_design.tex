\begin{figure*}[t!]
\centering
  \includegraphics[width=\linewidth]{figs/shapelib_method_v1.pdf}
   \caption{Method overview. We design a function library in four steps, starting from a user intent (light blue) that consists of function descriptions and a set of seed shapes. First, (a) we prompt an LLM to create function interfaces that define parameters and annotate the function's purpose. Then, (b) the LLM is prompted to propose multiple applications of the functions that reconstruct the seed shapes. Next, (c) we use this information to guide the LLM to propose multiple function implementations. The library is finalized with a validation step (d) that searches for pairs of  applications and implementations that best reconstruct the seed shapes. We can use the library to extend beyond the seed shapes by guiding the LLM to author a synthetic data generator with the library functions, and using the resulting paired data to train a recognition network for visual program induction.
   } 
  \label{fig:method_fig}
\end{figure*}


\section{Library Design}
\label{sec:lib_design}

\methodname~converts design intent into a library of functions through a series of steps, which we depict in Figure~\ref{fig:method_fig}.
The interface creation step converts function descriptions into a library interface (Section~\ref{sec:lib_interface}). 
The application proposal step identifies which library functions should model which seed set shapes (Section~\ref{sec:prop_apps}).
The implementation proposal step generates candidate function implementations (Section~\ref{sec:prop_impls}).
The library is then finalized with a validation step that checks combinations of proposed function applications and implementations against seed set examples (Section~\ref{sec:lib_validation}). 


\subsection{Interface Creation}
\label{sec:lib_interface}

\methodname~first converts user function descriptions into a library interface (Fig.~\ref{fig:method_fig}, a).
We prompt an LLM to produce a structured interface, where for each function it produces a typed signature and an accompanying doc-string.

We provide the LLM with two default classes: a `Part' class that creates primitives that abstract detailed geometry and a `CoordFrame' class that defines a local bounding volume.
Our prompt contains task instructions and in-context expert demonstrations sourced from different categories.
By default, we use axis-aligned cuboid primitives, though this design decision could be generalized by modifying prompt instructions and examples.

The LLM produces function signatures that expose parametric handles, e.g. the numbers of bars in a ladder back or the height of base runner.
Each function is instructed to take in a special first parameter, \textit{CF}, a `CoordFrame' that specifies the expected extents of the functions outputs. 
Functions are typed so that they return a List of `Part' objects.

Through our in-context examples and instructions, we prompt the doc-string to have a particular structure. 
First, it defines a \textit{description} field to explain the high-level goals of the function.
Then, it defines a \textit{parts} field, that specifies what parts should be produced depending on the input parameters.
Finally, it defines a \textit{parameter} field, that explains how they should affect the output structure.
This interface is then used to guide the library development.

\subsection{Proposing Function Applications}
\label{sec:prop_apps}

As LLMs are prone to hallucinate, we do not directly implement each function following the prior step. 
Instead, we would like to ground each function implementation by referencing structures from the seed set.
To find such references, we propose programs that apply library functions that explain exemplar shapes (Fig.~\ref{fig:method_fig}, b).

This step begins by sampling a shape from the seed set.
We ask a VLM to describe the parts that is sees from a render of the shape.
We also convert the 3D semantic part annotations into a list of labeled `Part' objects.
We combine these inputs together, and task an LLM with deciding what parts should be explained by which library functions (even though these functions lack implementations).
The LLM outputs this decision by authoring a `program()' function that proposes library function applications (along with parameters).
We ask the LLM to use a special `group\_parts' function when constructing this program, that consumes a list of input `Part' objects and returns a bounding `CoordFrame' object.
In this way, the `program' provides information about which parts of the input shape should be explained by which library functions.

As we later demonstrate empirically, the accuracy of individual LLM calls has a high variance which makes them hard to trust. 
Therefore, instead of finding a single program for each shape, we run this procedure K times for each shape in the seed set (K=5).


\subsection{Propose Function Implementations}
\label{sec:prop_impls}

\methodname~now has the information from the prior steps it needs to author good function implementations: typed signatures, doc-string guidance, and input-output examples.
These input-output example pairs can be automatically found from the proposed function applications.
From this input, we ask the LLM to complete the implementation of each function so that it matches the signature type, meets the doc-string specification, and respects the observed patterns present in the usage examples (Fig.~\ref{fig:method_fig}, c). 

Of note, we find that the LLM predictions in the previous application proposal step do a good job of identifying which functions should explain which parts, but do a much worse job at predicting parameter values. With this in mind, we mask out parameter values with a special token `?' in all input-output examples.
We do this for every parameter value, except for the first \textit{CF} `CoordFrame', as the correct value for this parameter can be found automatically with the `group\_parts' function.


Similar to previous step, we find that some implementations produced by the LLM produce better or worse matches against the input specification.
So for each function in our library, we propose K different ways that it could be implemented (K=4).

\subsection{Library Validation}
\label{sec:lib_validation}

At this point we are close to having a fully realized library.
From the prior steps we have (a) function doc-strings and signatures, (b) proposals of how the functions should be applied to explain groups of parts in seed-set shapes, and (c) proposals of how the function should be implemented.
This validation step is responsible for deciding which of these proposals are `good', and not just LLM hallucinations
(Fig~\ref{fig:method_fig}, d).

To make this decision, we search over pairs of proposed implementations and parameterizations, and record those that geometrically match structures present in the seed set shapes.
For each  proposed function implementation from (c) we check which of proposed part groups from (b) this implementation can explain.
Specifically, we try executing the function with the proposed parameterizations sourced from (b), calculate the observed error between the target parts and function output, and record the parameterization that achieves the best error.
Our error metric compares corner-to-corner distances between sets of geometric primitives, and mark function applications as invalid  if the paired structures are not similar enough (see the appendix for details).

At this point, for each group of parts from (b) we know which implementation from (c) best matches the observed part structure.
We keep the implementation that achieves the \textit{best} error across the \textit{most} part groups, and remove all others proposals.
If this \textit{best} implementation found valid applications across multiple seed set shapes, we update the library interface entry with its implementation logic. 
Otherwise, we remove the function entry from the interface.

