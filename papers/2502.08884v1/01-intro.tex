\section{Introduction}

3D shapes are central to many visual computing problems.
A variety of stakeholders, from entertainment and gaming systems to robotics and manufacturing depend on the ability to edit, manipulate, analyze, and synthesize 3D assets. 
Procedural models, which are structured programs that produce geometry when executed, are an appealing representation for 3D shapes that provide natural support for these operations in contrast with alternative representations such as meshes, point clouds, or voxels. 
Well-designed procedural models expose (semantic) handles that end-users can interpret and use to easily manipulate output geometry. These programs, however, are expensive to author or acquire.

Expert-designed procedural models~\cite{wonka2003instant, muller2006procedural, pearl2022geocode} are useful because they are often composed of functions from a shape library that exposes the `right' level of abstraction for a particular domain.
Whereas a single procedural model can typically represent a distribution of shapes through parameter variations, a shape function library provides a set of elementary functions that can be \textit{reused} across many procedural model instantiations. 
For instance, authoring a good procedural model of a building, while maintaining an interpretable interface, might require functions that tile windows over a facade~\cite{wonka2003instant}, or automatically extrude common types of roofing patterns from a boundary~\cite{muller2006procedural}.
Access to this sort of domain-specific library allows procedural models to realize the many benefits of this representational paradigm.
Unfortunately, designing a good library of procedural modeling functions is even more difficult compared with authoring a single procedural model.

Despite the difficulty of this problem, some work has investigated how to automatically discover good libraries of procedural shape functions.
These methods use data-driven approaches to optimize a compression-based objective.
They operate in a `bottom-up' fashion, starting from a base modeling language with elementary functions, and gradually grow their library, in a greedy manner, by defining new and more domain-specific abstraction functions based on how much they help to compress shapes from a large dataset. 
While these approaches can successfully optimize their compression objective, 
they base their library development solely on compressing out common geometric patterns over a large shape dataset, without any semantic `top-down' guidance. 
As a result, the functions they produce can only align to shape semantics by chance, making them difficult to interpret and meaningfully manipulate.

As an alternative, we investigate how Large Language Models (LLMs) can help with this procedural language design problem.
LLMs have demonstrated remarkable success over a surprisingly diverse range of tasks, from 3D layout synthesis~\cite{hu2024scenecraft} to general code generation~\cite{jiang2024survey}.
There are reasons to believe they might be useful in helping to design procedural models. 
They have top-down world knowledge about the semantic relationships of parts within shapes and they are proficient at writing code.
Despite these properties, LLMs also have limitations that temper their procedural modeling capabilities.
As we demonstrate experimentally, latest frontier LLMs still struggle to understand complex geometric layouts and often misinterpret or misattribute constraints and relations between parametric controls.
Their mistakes manifest as hallucinations, leading to implausible geometry or structures that cannot represent assets in existing 3D datasets.

We propose \methodname, a hybrid system that guides an LLM through the creation of a library of procedural abstraction functions from a specified design intent.
An expert user provides this design intent to our system with two modalities: (i) function descriptions in natural language, and (ii) a seed set of exemplar shapes.
The two modalities are complementary: the first mode allows the user to specify the kinds of functions they would like to interface with; while the second mode provides geometric references that guide and constrain library development.

\methodname breaks the complex library design process into a series of sub-problems.
First, we use an LLM to design the library interface with a prompting workflow conditioned on the function descriptions.
Next, we task an LLM with proposing applications of these functions to explain shapes from the seed set (from the interface only, without any actual implementations).
We then use these proposed applications to automatically formulate input/output examples that guide the LLM to propose implementations of each function.
We finalize the library with a validation step that performs a geometric analysis over the proposed function implementations and applications.
To apply these functions to represent shapes beyond the seed set, we additionally train a recognition network that learns to map input shapes to output programs written with the library functions.
To train this network, we create a synthetic data generator by prompting an LLM with the finalized library implementation and asking it to produce a function that randomly generates an input shape using the abstraction functions.
In this way, even starting from only a small seed set, \methodname can find programs that use these abstraction functions to explain a much larger collection of shapes (see \Cref{fig:teaser}). 



We evaluate \methodname by using it to design libraries of procedural functions over multiple shape categories (\texttt{chair}, \texttt{table}, \texttt{storage}, \texttt{lamp}, \texttt{faucet}).
We find that our method generates functions that (i)~adhere to the top-down semantics provided by the natural language descriptions, and (ii)~produce geometric outputs that reflect structures observed from the exemplar shapes. 
Beyond this, we experimentally validate that our discovered library helps us to realize the benefits of representing shapes procedurally along a number of axes. 
\textit{Generalization~(a)}: they are useful for modeling shapes outside of the seed set; 
\textit{Interpretability~(b)}: they are aligned with semantics and expose a small number of parameters that produce predictable edits; 
\textit{Plausibility~(c)}: they constrain outputs to maintain shape semantics under manipulation.

We compare against alternative problem framings, and find that our dual modality design intent is crucial for our success.
When semantic information from (i) is missing, systems like ShapeCoder~\cite{jones2023shapecoder} find abstractions that improve compression, but lack interpretability and do not maintain plausibility. 
When reference geometry from (ii) is missing, LLMs design sensible library interfaces, but produce function implementations that can not generalize across shape distributions.

In summary, our contributions are:
 
\begin{enumerate}[(1)]
    \denselist
    \item \methodname, a pipeline that guides an LLM through the development of a library of procedural functions while adhering to specified design intent.
    \item A recognition network that learns to infer programs that use library functions to explain input shapes, trained with a synthetic data sampler authored by an LLM.     
    \item Demonstrations that our library better realizes the benefits of procedural representations over alternative approaches.
\end{enumerate}

We will release code upon publication.