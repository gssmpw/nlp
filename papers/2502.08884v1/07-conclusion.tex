\section{Conclusion}

We have presented \methodname as the first method that combines general semantic priors from LLMs with domain-specific information in the form of small seed set of shapes to produce a function library that \emph{generalizes} to a full category of shapes and exposes \emph{interpretable} parameters that produce \emph{plausible} results under manipulation.
This addresses the long-standing problem in visual program induction to create programs that are not only compact, but also semantically well-aligned and thus easy to work with for both humans and LLMs.

Several limitations indicate possible directions for future work: our current shape representation does not model precise part orientations. This could be addressed by modifying the prompts and seed set with oriented parts, but would likely increase the number of proposals needed to find good implementations. Our function libraries currently only model a single shape class. More generic functions that apply to multiple classes may be found by providing more examples in longer prompts.

Other interesting directions for future work include 
(i) guiding the LLM to create a procedural generator that more closely aligns with the semantics of a shape class by refining our synthetic data generator with programs found by our recognition network;
(ii)~training a generative module that produces detailed geometry from our coarse structural representation, by learning the correlation between structure and geometry;
(iii) making functions differentiable by asking the LLM to use PyTorch, enabling gradient-based parameter fitting during program inference;
and (iv) using other modalities to convey design intent, like examples of expert-crafted procedures from Infinigen~\cite{infinigen2024indoors}. 

