\appendix
\clearpage
% \setcounter{page}{1}
\maketitlesupplementary
\renewcommand{\thesection}{\Alph{section}}

\section{Prompt for Pseudo Label Generation}
\label{supp:sec:prompt}
Table~\ref{tab:spatial} provides the prompt template for generating pseudo spatial labels.
We uniformly sample $n=128$ frames and use the prompt template to obtain a score for each frame independently. We use the logit to generate the word ``True'' or ``False'' after ``Evaluation:'' to compute the score using Equation~\ref{eq:spl}. In a few cases, the \ac{mllm} response may not follow the instruction and does not contain the text ``Evaluation: True'' or ``Evaluation: False''. We manually add `Evaluation: True'' to the end of the response and use the logit to generate the word ``True'' to compute the score.
\begin{table}[ht]
\centering
\begin{tabular}{l}
\toprule
The image is a video frame from a video. A question \\
about the video is:\\
\{question\}\\
Evaluate whether the video frame provides useful \\
information to answer this question about the video.\\
First explain your reasoning. Then generate a\\ Boolean evaluation of the frame's usefulness. For \\
example:\\
Evaluation: True
\\\bottomrule
\end{tabular}
\caption{Prompt template for spatial pseudo labels}
\label{tab:spatial}
\end{table}


\noindent Table~\ref{tab:temporal} provides the prompt template for generating pseudo temporal labels. We first use the \ac{mllm} to generate a concise caption for $n=128$ uniformly sampled frames. Then we use the prompt in Table~\ref{tab:temporal} to generate a list of frame indexes containing the most helpful frames.

\begin{table}[ht]
\centering
\begin{tabular}{l}
\toprule
I need to answer a question based on a long video. To \\
do this, I have uniformly sampled 128 frames from \\
the video, each with a corresponding caption. The question \\
I need to answer is:\\
\{question\}\\
Below is the list of frames and their captions:\\

Frame 1 : \{caption1\} \\
Frame 2 : \{caption2\} \\
$\cdots$\\
Frame 128 : \{caption128\}\\

Please provide a list of 8 frames that would be most \\
helpful for answering this question.\\
Rule: ONLY provide a Python List without extra text.
\\\bottomrule
\end{tabular}
\caption{Prompt template for temporal pseudo labels}
\label{tab:temporal}
\end{table}

\begin{table}[ht]
    \centering
    \resizebox{\linewidth}{!}{
    \scalebox{.50}{
        \begin{tabular}{lrr}
        \hline
        \ac{mllm} & ANet-QA  &  NExT-QA \\
        \hline
        No pseudo-labels & 53.5 & 62.4 \\
        LLaVA-NeXT 7B    & 53.9 & 62.8 \\
        Idefics2 8B      & 53.8 & 63.2 \\
        Qwen2 VL 7B      & 54.2 & 63.6 \\
        \hline
        \end{tabular}
        }
    }
    \caption{Performance of LLaVA-NeXT-Video 7B on ActivityNet (ANet) and NExT QA with different spatial pseudo-labels}
    \label{tab:appendix:1}
\end{table}

\begin{table}[ht]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{lrr}
    \hline
    \ac{mllm} & EgoSchema  &  LongVideoBench \\
    \hline
    Uniform 4 frames & 45.8 & 45.3 \\
    $16\rightarrow4$ & 47.8 & 46.0 \\
    $32\rightarrow4$ & 48.2 & 48.9 \\
    $128\rightarrow4$ & 49.0 & 49.5 \\
    \hline
    \end{tabular}
    }
    \caption{Performance of selecting different number of frames on EgoSchema and LongVideoBench with LLaVA-NeXT-Video 34B as downstream video-LLM.}
    \label{tab:appendix:2}
\end{table}

\vspace{-18pt}
\section{Additional Results}
\paragraph{Pseudo Label Geneation with different \ac{mllm}} Qwen2-VL serves as the prompting \ac{mllm} for spatial pseudo-labels generation as detailed in Section~\ref{sec:method.3}. We investigate the influence of alternative \ac{mllms} on video QA performance. Table~\ref{tab:appendix:1} compares the performance of LLaVA-Next-Video 7B on ActivityNet and NExt-QA using frames selected based on spatial pseudo-labels generated by different prompting \ac{mllms}. A stronger \ac{mllm} produces higher-quality pseudo-labels.

\vspace{-12pt}
\paragraph{Number of frames before selection} Existing frame selection methods~\citep{yu2024self, ranasinghe2024understanding} typically sample $16\sim32$ frames from a video and then perform frame selection on these frames. In contrast, our method samples a significantly larger list of 128 frames prior to the frame selection process. We posit that a larger number of frames is essential for long video QA. To evaluate this, we assessed the video QA performance of LLaVA-NeXT-Video 34B taking 4 frames selected from different number of frames. Table~\ref{tab:appendix:2} summarizes the results on the long-video QA benchmarks EgoSchema and LongVideoBench. The improvement on QA performance from $16\rightarrow4$ to $128\rightarrow4$ is significant, showing the necessity of have a large frame selection candidate pool.

\section{More Visualization Results} \label{supp:sec:viz}
Figure~\ref{fig:visual1} and Figure~\ref{fig:visual2} are the zoom-in for Figure~\ref{fig:visualazation}. Figure~\ref{fig:visual3} and Figure~\ref{fig:visual4} are additional visualization results.


\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{sec/figures/visual/v1.pdf}
    \caption{One visualization example of the frame selection results.}
    \label{fig:visual1}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{sec/figures/visual/v4.pdf}
    \caption{One visualization example of the frame selection results.}
    \label{fig:visual2}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{sec/figures/visual/v2.pdf}
    \caption{One visualization example of the frame selection results.}
    \label{fig:visual3}
\end{figure*}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{sec/figures/visual/v3.pdf}
    \caption{One visualization example of the frame selection results.}
    \label{fig:visual4}
\end{figure*}