\begin{table*}[ht]
\centering
\caption{Pairwise LLM-as-a-Judge Prompts for SCIR.}
\label{tab:judge_prompts_scir}
\scalebox{0.9}{
\begin{tabular}{p{15cm}}
\toprule
\textbf{LLM-as-a-Judge Prompt 1 for Self-Consistent Internal Rewards Training}\\
\midrule
You are a highly efficient assistant, who evaluates and selects the best large language model (LLMs) based on the quality of their responses to a given instruction. This process will be used to create a leaderboard reflecting the most accurate and human-preferred answers. 
I require a leaderboard for various large language models. I'll provide you with prompts given to these models and their corresponding outputs. Your task is to assess these responses, and select the model that produces the best output from a human perspective. Here is the prompt: \\
\{ ``instruction'': ``\texttt{\{instruction\}}'', \} \\
Here are the outputs of the models: \\
\{ ``model'': ``m'', ``answer'': ``\texttt{\{response\_1\}}'' \} \\
\{ ``model'': ``M'', ``answer'': ``\texttt{\{response\_2\}}'' \} \\
Evaluate the models based on the quality and relevance of their outputs, and select the model that generated the best output. Answer by providing the model identifier of the best model. We will use your output as the name of the best model, so make sure your output only contains one of the following model identifiers: [[m]] or [[M]]. \\
\midrule
\midrule

\textbf{LLM-as-a-Judge Prompt 2 for Self-Consisent Internal Rewards Training} \\
\midrule
Please act as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user question displayed below. 
You should choose the assistant that follows the user's instructions and answers the user's question better. Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of their responses. Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. Do not allow the length of the responses to influence your evaluation. Do not favor certain names of the assistants. Be as objective as possible. \\
\#\#\# Instruction: \\
\texttt{\{instruction\}} \\
\#\#\# Response m: \\
\texttt{\{response\_1\}} \\
\#\#\# Response M: \\
\texttt{\{response\_2\}} \\
Output your final verdict by strictly following this format: "[[m]]" if Response m is better than Response M, "[[M]]" if Response M is better than Response m.\\
\bottomrule
\end{tabular}
}
\end{table*}
