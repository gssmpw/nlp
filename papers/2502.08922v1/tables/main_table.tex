
\begin{table*}[t!]
\centering
\small
\caption{Experimental results on Mistral-7B.  $M_0$ is the supervised fine-tuned LLM. $M_1$, $M_2$ and $M_3$ are the model after $i$ iterations of training. The best performance among all models is marked in bold.}
\label{tab:main_results}
\vskip 0.15in
    % \resizebox{0.8\linewidth}{!}{
    \begin{tabular}{lccccccccccccccccc}
    \toprule 
    % Arena-Hard
    \multirow{2}{*}{\textbf{Model}}  &  \multicolumn{3}{c}{\textbf{Alpaca-Eval 2.0}} & \multicolumn{3}{c}{\textbf{MT-Bench}} & \textbf{MMLU} & \textbf{GSM8K} \\
    % \cline{2-4} 
    & \textbf{LC} & \textbf{WR} & \textbf{Length} & \textbf{Turn 1} & \textbf{Turn 2} & \textbf{Score} & \textbf{Acc.} & \textbf{EM} \\
    \midrule
    \multicolumn{9}{c}{\textbf{\textit{Self-Rewarding (LLM-as-Judge)}}} \\
    % Self-Rewarding (LLM-as-Judge) \\
    $M_0$ & 10.65 & 6.35 & 965 & 6.68 & 4.68 & 5.68 & 59.61 & 35.41 \\
    $M_1$ & 12.58 & 7.33 & 1027 & 6.63 & 4.42 & 5.53  & 59.51 & 35.03\\
    $M_2$ & 11.37 & 7.58 & 1125 & 6.67 & 4.55 & 5.61 & 59.41 & 35.78 \\
    $M_3$ & 10.74 & 7.22 & 1192 & 6.17 & 4.92 & 5.55 & 59.30 & 35.63 \\
    \midrule
    \multicolumn{9}{c}{\textbf{\textit{Self-Rewarding (Implicit Reward Model)}}} \\
    % Self-Rewarding (Implicit Reward Model) \\
    $M_0$ & 10.66 & 6.35 & 952  & 6.62 & 4.55 & 5.58 & 59.65 & 37.45 \\
    $M_1$ & 10.43 & 7.08 & 1097  & 6.45 & 4.73 & 5.59 & 59.72 & 37.76 \\
    $M_2$ & 12.52 & 8.82 & 1218  &  6.43 & 4.98 & 5.70 & 59.76 & 37.45 \\
    $M_3$ & 14.15 & 11.43 & 1390  & 6.82 & 5.01 & 5.91 & 59.61 & \textbf{37.68}\\
    \midrule
    \multicolumn{9}{c}{\textbf{\textit{External Reward Model (Skywork-reward-7B)}}} \\
    % External Reward Model (Skywork-reward-7B) \\
    $M_0$ & 10.18 & 5.89 & 945 &  6.36 & 4.47 & 5.41 & 59.34 & 37.23 \\
    $M_1$ & 12.09 & 6.45 & 1147 & 6.73 & 5.13 & 5.93 & 59.33 & 36.32\\
    $M_2$ & 14.09 & 9.78 & 1271   & 6.71 & 4.93 & 5.82 & 59.35 & 36.24\\
    $M_3$ & 15.91 & 10.68 & 1291 & 6.75 & 4.85 & 5.80 & 59.39 & 35.10\\
    \midrule
    \multicolumn{9}{c}{\textbf{\textit{Self-Consistent Internal Rewards (Ours)}}} \\
    % Self-Consistent Internal Rewards (Ours) \\
    $M_0$ & 10.81 & 5.96 & 953 & 6.43 & 4.35 & 5.39 & \textbf{59.96} & 36.62\\
    $M_1$ & 14.51 & 11.06 & 1332 & \textbf{6.82} & 5.28 & 6.05 & 59.92 &  36.32\\
    $M_2$ & 18.49 & 17.02 & 1753 & 6.80 & 5.32 & 6.06 & 59.78 & 36.32\\
    $M_3$ & \textbf{24.92} & \textbf{23.85} & 1941 & 6.81 & \textbf{5.55 }& \textbf{6.18} & 59.73 & 36.47\\
    \bottomrule
    \end{tabular}
    \vskip -0.1in
\end{table*}



% \begin{table*}[t!]
% \caption{Alignment performance}
% \label{tab:main_results}
%     \resizebox{\linewidth}{!}{
%     \begin{tabular}{lccccccccccccc}
%     \toprule 
%     % Arena-Hard
%     \multirow{3}{*}{\textbf{Model}} & \multicolumn{6}{c}{\textbf{Mistral-7b-base}} & & \multicolumn{6}{c}{\textbf{Mistral-7b-Instruct}}
%     \\
%     \cline{2-7} \cline{9-14} 
%      &  \multicolumn{2}{c}{\textbf{Alpaca-Eval 2.0}} & \textbf{Arena-Hard} & \textbf{MT-Bench} & \textbf{MMLU} & \textbf{GSM8K}  &  &
%      \multicolumn{2}{c}{\textbf{Alpaca-Eval 2.0}} & \textbf{Arena-Hard} & \textbf{MT-Bench} & \textbf{MMLU} & \textbf{GSM8K} \\ 
%     & \textbf{LC} & \textbf{WR} & \textbf{WR} & \textbf{Score} & \textbf{ACC.} & \textbf{EM} & &
%     \textbf{LC} & \textbf{WR} & \textbf{WR} & \textbf{Score} & \textbf{ACC.} & \textbf{EM} \\
%     \midrule
%     % Mixtral-7B-instruct-v0.3 & 27.70 & 23.72 & 1686 \\
%     % \midrule
%      \multicolumn{13}{c}{\textit{Self-Rewarding (LLM-as-Judge)}} \\
%     $M_0$ & 10.65 & 6.35 & 965  \\
%     $M_1$ & 12.58 & 7.33 & 1027  \\
%     $M_2$ & 11.37 & 7.58 & 1125  \\
%     $M_3$ & - & - & -  \\
%     \midrule
%     \multicolumn{13}{c}{\textit{Self-Rewarding (Implicit Reward Model)}} \\
%     $M_0$ & - & - & -  \\
%     $M_1$ & 10.43 & 7.08 & 1097  \\
%     $M_2$ & 12.52 & 8.82 & 1218  \\
%     $M_3$ & 14.15 & 11.43 & 1390  \\
%     \midrule
%     \multicolumn{13}{c}{\textit{External Reward Model (Skywork-reward-7B)}} \\
%     $M_0$ & - & - & -  \\
%     $M_1$ & - & - & -  \\
%     $M_2$ & - & - & -  \\
%     $M_3$ & 15.91 & 10.68 & 1291 \\
%     \midrule
%     \multicolumn{13}{c}{\textit{Internal Rewards Consistency (Ours)}} \\
%     $M_0$ & 10.81 & 5.96 & 953  \\
%     $M_1$ & 14.51 & 11.06 & 1332  \\
%     $M_2$ & 18.49 & 17.02 & 1753  \\
%     $M_3$ & 22.90 & 21.49 & 1797  \\
%     \bottomrule
%     \end{tabular}
%     }
% \end{table*}
