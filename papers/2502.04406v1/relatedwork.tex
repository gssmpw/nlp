\section{Related Work}
Recently, CP, as a method of performing UQ, has been gaining popularity for usage with spatio-temporal data \citet{sun2022conformal}. Several works have explored the inductive CP framework for spatial and sequential data \citep{conformaltimeserires,cp_dynamic_timeseries,CP_Wildfire}, including in the operator space \citep{ma2024calibrated}. In \citet{gopakumar2024uncertaintyquantificationsurrogatemodels}, the marginal-CP framework is extended to pre-trained as well as to fine-tuned surrogate models for physical system modelling across an infinite-dimensional setting. Alternatively, error bounds for PDE surrogates have been devised by \citet{gray2025guaranteedconfidencebandenclosurespde} using set propagation to project the singular value decomposition of the prediction error to the prediction space. 

\begin{figure}[h!]
    \centering
    \includegraphics[width=\columnwidth]{Images/framework.pdf}
    \caption{Schematic of physics-informed uncertainty quantification workflow. Initial conditions generate neural PDE predictions autoregressively, over which physics residual errors are estimated. Calibration via marginal and joint conformal prediction yields error bars - pointwise for marginal-CP and domain-wide for joint-CP.}
    \label{fig: layout}
    % \vspace{-10pt}
\end{figure}


The usage of PDE residuals under the guise of Physics-Informed Machine Learning (PIML) \citep{PIML} was made popular as an optimisation strategy for Physics-Informed Neural Networks  (PINNs) \citep{Raissi2019PINNs} and has found application in optimising neural operators \citep{LiPino2024} and soft/hard enforcement of the physical constraints to deep learning models \citep{du2024neural,chalapathi2024scaling}. However, they have rarely been used as a tool for providing UQ to the surrogate models, and where they have found application, UQ remained uncalibrated \citep{ZhuPCDLUQ2019}. The majority of literature in UQ for neural PDE solvers has been looking at Bayesian methods, such as dropout, Bayesian neural networks, and Monte Carlo methods \citep{GENEVA2020109056, zou2022neuraluq, Psaros2023}, which lack guarantees or are computationally expensive.