\section{Related Work}
In this section, we provide an overview of recent advancements relevant to the topics of this paper, including image restoration and dynamic networks. 
\subsection{Image Restoration}
\textbf{Image Restoration for Single Degradation.} Traditional image restoration techniques mainly target at a specific type of degradation, such as blur, noise, or haze. These approaches~\cite{R_Girish_Ambasamudram_2019,Xu_Zhang_Zhang_Feng_2017,Luo2015RemovingRF,Malhotra2016SingleIH,Dong2010ImageDA}, optimized for specific problems, can often achieve good results in the corresponding degradation scenario. For example, Mohan~et al.~\cite{R_Girish_Ambasamudram_2019} propose a model-based approach for addressing blur caused by camera shake. However, such approaches typically rely on specific prior degradation models, such as linear blur or motion blur. These model-based approaches may be severely limited when the actual degradation process does not match the assumed one. Recently, with the advancement of deep learning, numerous image restoration approaches based on deep learning have emerged  and performed excellently across various image restoration tasks, such as denoising~\cite{Guo_Yan_Zhang_Zuo_Zhang_2019,Zhang_Zuo_Chen_Meng_Zhang_2017,Wang_Liu_Li_Han,yao2023towards,Zhang_Zhou_Jiang_Fu_2023}, deblurring~\cite{Asim_Shamshad_Ahmed_2018,Nah_Kim_Lee_2017,Pan_Ren_Hu_Yang_2018,Sree2023AdaptiveOD,Wu2023BroadSI}, deraining~\cite{Xiao2022ImageDT,Li2018RecurrentSC,Jiang2020MultiScalePF,Fu2016ClearingTS,Jiang2021MultiScaleHF,10336721}, dehazing~\cite{Engin2018CycleDehazeEC,Wu2021ContrastiveLF,Qu2019EnhancedPD,Zhao2021RefineDNetAW}, and low-light enhancement~\cite{Frants2023QCNNHSD,Ma2022TowardFF,Ma2022TowardFF,Fu2023LearningAS,Xu2023LowLightIE,Wang2021LowLightIE,Xu2022SNRAwareLI}. However, constrained by model architectures designed for single tasks, they tend to perform exceptionally well in single degradation removal tasks but struggle to deal with other types of degradation.
\\
\textbf{Image Restoration for Multiple Degradations.} When considering multiple degradation factors, the problem becomes more complex as each type of degradation may require 
a special strategy. To address this challenge, researchers begin to explore the multi-task learning architecture that uses specific prior information~\cite{Chen2020PreTrainedIP,Li2020AllIO,Jose_Valanarasu_Yasarla_Patel_2022,Liu2022TAPETP}. For example, Chen~et al.~\cite{Chen2020PreTrainedIP} use a multi-head and multi-tail architecture to address multiple degradations. However, these approaches not only introduce additional model parameters but also increase the complexity of model training. Recently, several works have explored unified models for all-in-one image restoration tasks. Li~et al.~\cite{Li2022AllInOneIR} propose a method using contrastive learning to distinguish different types of degradation, requiring explicit degradation classification constraints. Zhang~et al.~\cite{Zhang2023IngredientorientedML} introduce a two-stage ingredient-oriented multi-degradation learning framework to reformulate degradation, but their approach necessitates the manual definition of degradation types and prior knowledge.

Prompt-based methods have also been introduced into all-in-one image restoration. For example, Potlapalli et al.~\cite{PromptIR_NIPS2024} propose a method that relies on global average pooling to generate prompt weights. The coarse-grained prompts generated by such global methods may struggle to capture local degradation features, making them insufficient to handle spatially varying degradations. Consequently, when dealing with complex degradation patterns that cannot be effectively summarized by global statistics, their restoration performance deteriorates.

Similarly, Conde et al.~\cite{conde2024instructir} propose a method utilizing predefined degradation texts to guide multiple degradation types. However, this approach does not deeply model the inherent degradation features within the images. By focusing solely on user-provided textual instructions without in-depth analysis of degradation patterns in the images, it may overlook critical details necessary for optimal restoration, especially when degradations are subtle or intertwined.

In contrast, our method leverages the proposed cross-domain degradation analyzer to facilitate deep interactions between frequency-domain degradation features and spatial-domain image features. This interaction enhances the model's capacity to effectively capture local and complex degradation patterns, thereby improving its ability to represent fine-grained spatial variations in degradation. 
\subsection{Dynamic Networks}
The research on dynamic networks has gradually garnered attention in the academic community, with the objective of reducing computational complexity while ensuring model performance. In recent years, researchers introduce various methodologies to achieve this goal. For example, ~\cite{Park2015BiglittleDN} introduces the groundbreaking BL-DNN approach, which concatenates two distinct deep CNNs with varying depths. When the softmax prediction accuracy of the first CNN surpasses a predefined threshold, the network terminates prematurely to reduce computational complexity. Subsequent works~\cite{Zhu_Han_Wu_Zhang_Nie_Lan_Wang_2021, Li_Wang_Wang_Liang_Li_Chang_2021, Wu_Nagarajan_Kumar_Rennie_Davis_Grauman_Feris_2018, Yu_Wang_Dong_Tang_Loy_2021} have also improved recognition tasks based on this concept.
Moreover, some researchers develop methods that dynamically adjust convolutional kernel weights~\cite{Yang2019CondConvCP,Chen2019DynamicCA,Harley2017SegmentationAwareCN,Su2019PixelAdaptiveCN} and kernel shapes~\cite{Dai2017DeformableCN,Zhu2018DeformableCV,Gao2019DeformableKA} during inference based on their inputs. However, due to their irregular memory access and computation patterns, these methods are limited in further efficiency improvement. Diverging from most existing dynamic networks, we design a degradation prompt-based dynamic decomposition mechanism that dynamically selects appropriate image restoration strategies.
\begin{figure*}[t] 
\centering 
\includegraphics[width=0.98\textwidth]{Fig/architecture1.pdf} 
\caption{The architecture of D$^3$Net, which consists of a restoration reconstruction branch and a degradation decomposition branch.} 
\label{fig:2} 
\end{figure*}