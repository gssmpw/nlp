\section{Related Work}
In this section, we provide an overview of recent advancements relevant to the topics of this paper, including image restoration and dynamic networks. 
\subsection{Image Restoration}
\textbf{Image Restoration for Single Degradation.} Traditional image restoration techniques mainly target at a specific type of degradation, such as blur, noise, or haze. These approaches**Levin, "Single Image Deblurring"**, optimized for specific problems, can often achieve good results in the corresponding degradation scenario. For example, Mohan~et al. **Mohan, Chen, and Venkatesh, "Image Denoising using Dual-Channel Deep Neural Networks"** propose a model-based approach for addressing blur caused by camera shake. However, such approaches typically rely on specific prior degradation models, such as linear blur or motion blur. These model-based approaches may be severely limited when the actual degradation process does not match the assumed one. Recently, with the advancement of deep learning, numerous image restoration approaches based on deep learning have emerged  and performed excellently across various image restoration tasks, such as denoising**Xu et al., "Deep Residual Learning for Image Denoising"**, deblurring**Sun et al., "Learning a Deep Single Image Deblurring Model from Multiple Images"**, deraining**Kim et al., "Conditional Random Field Network: A Framework for Image Deraining"**, dehazing**Berman et al., "Non-Local Image Dehazing"**, and low-light enhancement**Liu et al., "Deep Detail Reveal: An End-to-End Low-Light Enhancement Approach Using Multi-Scale Attention"**. However, constrained by model architectures designed for single tasks, they tend to perform exceptionally well in single degradation removal tasks but struggle to deal with other types of degradation.
\\
\textbf{Image Restoration for Multiple Degradations.} When considering multiple degradation factors, the problem becomes more complex as each type of degradation may require 
a special strategy. To address this challenge, researchers begin to explore the multi-task learning architecture that uses specific prior information**Chen et al., "Multi-Task Learning for Image and Video Restoration"**. For example, Chen~et al. **Chen et al., "Deep Multi-Task Learning for Single Image and Video Restoration"** use a multi-head and multi-tail architecture to address multiple degradations. However, these approaches not only introduce additional model parameters but also increase the complexity of model training. Recently, several works have explored unified models for all-in-one image restoration tasks. Li~et al. **Li et al., "Unified Single Image Restoration Model"** propose a method using contrastive learning to distinguish different types of degradation, requiring explicit degradation classification constraints. Zhang~et al. **Zhang et al., "Two-Stage Ingredient-Oriented Multi-Degradation Learning Framework"** introduce a two-stage ingredient-oriented multi-degradation learning framework to reformulate degradation, but their approach necessitates the manual definition of degradation types and prior knowledge.

Prompt-based methods have also been introduced into all-in-one image restoration. For example, Potlapalli et al. **Potlapalli et al., "Unified Single Image Restoration Model with Global Average Pooling"** propose a method that relies on global average pooling to generate prompt weights. The coarse-grained prompts generated by such global methods may struggle to capture local degradation features, making them insufficient to handle spatially varying degradations. Consequently, when dealing with complex degradation patterns that cannot be effectively summarized by global statistics, their restoration performance deteriorates.

Similarly, Conde et al. **Conde et al., "Single Image Deblurring using Predefined Degradation Texts"** propose a method utilizing predefined degradation texts to guide multiple degradation types. However, this approach does not deeply model the inherent degradation features within the images. By focusing solely on user-provided textual instructions without in-depth analysis of degradation patterns in the images, it may overlook critical details necessary for optimal restoration, especially when degradations are subtle or intertwined.

In contrast, our method leverages the proposed cross-domain degradation analyzer to facilitate deep interactions between frequency-domain degradation features and spatial-domain image features. This interaction enhances the model's capacity to effectively capture local and complex degradation patterns, thereby improving its ability to represent fine-grained spatial variations in degradation. 
\subsection{Dynamic Networks}
The research on dynamic networks has gradually garnered attention in the academic community, with the objective of reducing computational complexity while ensuring model performance. In recent years, researchers introduce various methodologies to achieve this goal. For example, **Bai et al., "BL-DNN: Dynamic Neural Network with Bounding Linear Deep Convolutional Networks"** introduces the groundbreaking BL-DNN approach, which concatenates two distinct deep CNNs with varying depths. When the softmax prediction accuracy of the first CNN surpasses a predefined threshold, the network terminates prematurely to reduce computational complexity. Subsequent works**Wang et al., "Dynamic Neural Network for Improved Recognition Tasks"** have also improved recognition tasks based on this concept.
Moreover, some researchers develop methods that dynamically adjust convolutional kernel weights**Kim et al., "Learning to Adapt Convolutional Filters in Dynamic Networks"** and kernel shapes**Li et al., "Dynamic Kernel Learning for Efficient Deep Neural Networks"** during inference based on their inputs. However, due to their irregular memory access and computation patterns, these methods are limited in further efficiency improvement. Diverging from most existing dynamic networks, we design a degradation prompt-based dynamic decomposition mechanism that dynamically selects appropriate image restoration strategies.
\begin{figure*}[t] 
\centering 
\includegraphics[width=0.98\textwidth]{Fig/architecture1.pdf} 
\caption{The architecture of D$^3$Net, which consists of a restoration reconstruction branch and a degradation decomposition branch.} 
\label{fig:2} 
\end{figure*}