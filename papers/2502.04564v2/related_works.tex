%\sandra{Hal comment: There's a LOT of work by Christina Harrington that should be cited here, not just Consilio. also check if Gloria Washington has anything.SS: I think we incorporated some Harrington, may need to still incorporate Washington}

\subsection*{Attitudes and Perceptions of AAE Speakers Towards Technology} %\hal{the norm is usually: (A) what other people did; (B) how we're different .... right now it's the other way around in most of these paragraphs}\sandra{I am addressing this.}
%\sandra{we may want to incorporate a Gloria Washington reference here yet per Hal note} 
%\citet{consilio} studied varied attitudes of AAE speakers toward technology under a specific classroom setting and found that AAE speakers' confidence and performance with technology suffered when they felt pressure to conform to MUSE in their use of a system. 
\citet{Cunningham2024Impacts} examine the invisible labor AAE speakers undertake to be understood by language technologies. Their findings show that AAE speakers often have to proactively adapt their speech, which leads to significant frustration and alienation when interacting with these systems.
\citet{harrington} further discuss how Black older adults anticipate and experience substantial challenges with voice assistants, exacerbating their reluctance to use these devices for tasks like health information seeking. Our study explores the idea that Black Americans may prefer AAE options in their interactions with speech or language-based AI technologies. We build on these lines of research by exploring Black Americans' preferences for AAE representation in specific contextual settings.

%perceived benefits and harms for AAE representation in specific contextual settings, and understanding their prioritization of these settings.

% We also extend the ideas from Harrington et al.'s "Deconstructing Community-Based Collaborative Design" by conducting two pilot studies. The first study actively engages members of the AAE community, allowing them to suggest modifications to the technology, ensuring that their linguistic and cultural needs are met 
%\sandra{Hal comment for next section: i think this subsection tries to cover too much stuff, much of which is not really relevant to our study. try to pare down to just things that are directly related and speak to the work we're doing. SS: Hal is this addressed sufficiently?}

\subsection*{Current State of AAE in Technology}

\citet{hill1998language} and \citet{smokoski2016voicing} highlight the issue of AAE in social media as not always true AAE, but rather non-Black Americans mimicking or mocking AAE. Thus, one of our objectives for this study was to begin to understand some of the constraints that generative AAE must adhere to, to stay within the bounds of acceptability to the AAE community, such that the language is not seen as mocking individuals who use the language and remains relatable and respectful to their specific use context. Consequently, we address the idea of whether the AAE generated by LLMs could be construed as mocking or offensive in our study.

%\sandra{Hal comment for the following to address: This might be a good place to introduce code-switching and cite Christina Harrington, and the labor that that requires and cite Jay.}


With respect to the importance of language diversity being reflected in chat-based AI technologies, \citet{Harrington2019DeconstructingCC} critique how participatory design often overlooks historical inequities, further marginalizing AAE speakers. This reflects broader systemic issues in technology design that fail to accommodate linguistic diversity. 

\citet{santiago2022disambiguation} highlight the critical role of morphosyntactic features in AAE, such as the invariant `be', demonstrating how leveraging these features improves the disambiguation of syntactic constructs, and mitigates the risks of discrimination in Automatic Speech Recognition (ASR) systems when misrepresented. In the context of large language models, \citet{HYFIN}'s `Black GPT' is an example of an AI technology that has been developed with recognition of the value of AAE, and thereby promotes inclusion and representation of Black Americans %through partnerships with Historically Black Colleges and Universities (HBCUs) 
\cite{previlon-etal-2024-leveraging-syntactic}.\looseness=-1

Despite recent efforts to provide inclusive technologies that meet the needs of Black Americans, \citet{pinhanez2024creating} highlight the ongoing challenges to developing systems that authentically represent AAE. In particular, they look at text-to-speech systems, uncovering latent biases that prevent broad recognition and acceptance without resorting to stereotypes. Issues in ASR have been documented for systems from Apple, Amazon, Google, and IBM, which exhibit error rates for Black speakers of 35\%, nearly double those for White speakers at 19\% \cite{Koenecke2020}.

This discrepancy highlights a systemic oversight in AI design that fails to consider AAE’s unique linguistic features, necessitating that AAE speakers frequently engage in code-switching. This adaptation requires significant invisible labor and can lead to alienation and frustration, as illustrated by Harrington's examination of Black older adults using voice assistants \cite{harrington} and Cunningham's insights into the emotional toll of such adjustments \cite{Cunningham2024Impacts}.

Unfortunately, the impacts of design oversights extend to chatbots and LLMs as well. \citet{hofmann2024dialect} expose how LLMs covertly perpetuate dialect prejudice, with their Matched Guise Probing approach, highlighting that even when trained with human feedback, these systems still enforce negative stereotypes, impacting judgments on employability and criminality.

In our study, we strive to uncover if LLMs are able to generate AAE effectively as judged by Black Americans themselves, and if they suffer from some of the same biases as speech recognition AI technologies according to our study participants. We note the distinction of the large language model-based chatbots we study here as being tasked to generate AAE, in contrast to speech recognition technologies which should understand AAE. 



%Other works like \citet{deas-etal-2023-evaluation}, \citet{Bender2021}, and \citet{Blodgett2017} explore the LLMs to understand their biases with their interpretation and generation of  AAE with respect to MUSE.
%Our study seeks to bridge the gap between the technical capabilities of LLMs to handle AAE and the community’s expectations and needs, ensuring that advancements in AI not only promote linguistic diversity but also enhance practical usability and cultural sensitivity.
%\hal{i'm not sure that this paragraph is really needed. i'm cutting because it's generally about bias - not even always for llms - not about AAE production specifically}