In our study, we explore how an underserved population,  Black Americans in the United States, regards increasingly ubiquitous text-based AI tools in terms of their preferred functionalities and with respect to the authenticity of the language produced by these systems, given their unique needs.
We specifically investigate the research questions:
\begin{enumerate}[nolistsep,noitemsep]
\item \emph{Do Black Americans\footnote{%
We use \textit{Black Americans} to describe those who identify as American with ancestral roots to Black African ethnic groups.}
%Our choice of terms "Black Americans" and "African American English" was partially informed by our survey results, where a plurality of survey participants preferred the term "Black" for self-identification, with African American and Black American in the top three terms. We compromise between Black and Black American to use Black American for specificity. African American English is one of many ways to describe the language Black Americans speak \cite{green2002african},\cite{wolfram2015american},\cite{rickford2016language}, \cite{king2020african},\cite{becker2013ethnolect}; our survey demonstrates that other popular preferred terms include African American Vernacular English, Black Slang or Black English. We stress that this diverse population does not have a single preferred identification term, nor description for or way of regarding the language as seen in Figure\ref{fig:identifying_term} and Figure \ref{fig:language variety term}.}
want generative AI technologies to produce African American English? If so, in what contexts?}; and
\item \emph{How effective are large language models (LLMs) at generating authentic African American English (AAE)\footnote{%
African American English is ``the grammatically patterned variety of English used by many, but not all and not exclusively, African Americans in the United States'' \cite{grieser2022black}; AAE has many alternative names, including African American Language, African American Vernacular of English, Black English, (Black) Slang, and Ebonics
\cite{green2002african,wolfram2015american,rickford2016language,king2020african,becker2013ethnolect}. In our study, participants could choose the terminology they preferred. %, our survey demonstrates that other popular preferred terms include African American Vernacular English, Black Slang or Black English.
}
when prompted to do so?}
\end{enumerate}

\noindent
The Black American population makes up approximately 13.6\% of the United States total population in 2022 (\citealp{USCensus2022,Moslimani2023}) and represents a major stakeholder population of text-based AI technologies. 
%\sandra{might be a good place to address this comment from Hal: In related work, or in the intro, we should discuss the private/professional distinctions with relevant cites.} 
AAE, while predominantly a spoken language variety, is seeing increased representation in speech-like media such as texting and social media \cite{blodgett2016demographic}. 
Its use has become synonymous with the cultural identity of some Black Americans \cite{BashirAli2006} with the language evolving over an extended period of time dating as far back as the period of Black enslavement in the United States. In spite of the cultural importance of AAE, Black Americans have had good reason to be hesitant to use the language outside of personal contexts due to widespread linguistic discrimination: racial identification and discrimination based on speech or writing in the work place and in schools~\cite{baugh2005linguistic}. In addition, the use of AAE may be associated with poverty or lower socioeconomic class \cite{rickford2015neighborhood}, which could influence Black Americans to be cautious about the circumstances under which it should be used.

AAE is predominantly 
identified by grammatical patterns such as the use of double negatives, variable subject-verb agreement, and omission of verbal copulas. These patterns distinguish it sharply from Mainstream U.S. English (MUSE)\footnote{We refer to the most prevalent variety of American English as Mainstream U.S. English  \cite{baker2020dismantling,harris2022exploring}; as with AAE, other names exist, such as Standard American English and White Mainstream English~\cite{wolfram2015american}.}.   
%Some sociolinguists term AAE a sociolect defined by Oxford Languages as a dialect of a social group \cite{Sociolect2023}.
Despite its distinct linguistic characteristics and the large proportion (80-90\%) of the Black American society that speaks AAE in the United States (\citealp{Holt2018, OQuin2021,Farrington2021}), prior studies have shown that AI technologies often fail to accommodate its nuances, especially in the context of speech recognition (\autoref{sec:related_works}).



%This oversight in the design and implementation of speech-AI technologies  motivated us to investigate whether there may be similar issues related to quality of service for Black Americans with respect to chat-based LLMs, specifically around inclusivity and fairness.

In this paper, we investigate the research questions listed above in the context of large language models. We conduct an online study (\autoref{sec:methodology}) among Black Americans ($n=$ 104) consisting of both a survey---to understand what is wanted out of this technology---and data annotation---to understand the efficacy of current LLMs at producing authentic AAE.
%questions regarding if Black Americans desire chat-based AI technologies to communicate with them and understand them in AAE, as well as how effective these systems are in performing these tasks, by conducting an online study to gather: 1) Black American perspectives on how they expect generative AI-technologies to produce or reflect AAE across different personal and professional scenarios, and 2) Black American judgments of AAE text, with these ratings recorded through data annotation of both Black American-transcribed speech and LLM-generated texts across a series of questions. The latter helped us to gauge and compare the authenticity of the AAE between the texts. 
In the survey (\autoref{subsec:survey}), we aim to understand in what social contexts Black Americans would want (the option of) having an LLM use AAE, including both professional and personal settings, and including both continuation behavior (e.g., email autocomplete) and reply behavior (e.g., AI assistants).
In the data annotation task (\autoref{subsec:data_annotations}), we ask Black Americans ($n=$ 228 who provided 8,654 judgments for 1,357 examples) to judge text generated by three different LLMs---GPT 4o-mini, Llama 3, and Mixtral---along axes like coherence, the explicit presence of AAE features, and offensiveness.
Our main contributions (\autoref{sec:results}) include:
\begin{enumerate}[nolistsep,noitemsep]
\item We find that Black Americans favor the use of MUSE in more formal or task-specific interactions, but are open to LLM generation of AAE in personal or casual settings, preferring the autonomy to switch to AAE as desired.
\item We find that Black Americans judged the LLM AAE generations as equally authentic to the human baseline (Black American transcribed interviews), and they did not consider them to be mocking or offensive.
\item We contribute a dataset of linguistic judgments from Black American annotators on both AAE and MUSE texts, drawn both from human- and LLM-produced text. In addition, we share the dataset and a selection of our code for the project here: \url{https://github.com/smelliecat/AAEMime.git}
\end{enumerate}
% \item We find that Black Americans favor the use of MUSE in more formal or task-specific interactions, but are open to LLM generation of AAE in personal or casual settings, preferring the autonomy to switch to AAE as desired.
% \item We find that Black Americans judged the LLM AAE generations as equally authentic to the human baseline (Black American transcribed interviews), and they did not consider them to be mocking or offensive.
% \item We contribute a dataset of linguistic judgments from Black American annotators on both AAE and MUSE texts, drawn both from human- and LLM-produced text. 

%To generate the text completions that were later annotated by our study participants, we prompted three popular large language models (LLMs): GPT 3.5, Llama 3 and Mixtral  (\citealp{brown2020language}; \citealp{llama3modelcard}; \citealp{jiang2024mixtral}). 

%We conduct surveys and several experiments. See Appendix
% \chris{I think people usually reference this with the appendix section they fall under} \kac{Using the acl template, this is what you get when you cite via the label}

%~\nameref{apdx:prompts}, to find the best system prompt to evaluate how AI systems handle AAE, focusing primarily on the responses of the systems rather than the input by the users. 

