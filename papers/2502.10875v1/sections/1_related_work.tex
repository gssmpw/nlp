\section{Related Work}
\label{sec:related work}
% \subsection{Box Embeddings}
% \citet{hard_box} also proposed a probabilistic interpretation of box embeddings, where the volume of a box could be trained to represent the probability of an associated binary random variable, and intersections of boxes would be trained to capture the joint probabilities. 
% %If the embedding space was normalized (\eg constraining the boxes to be within a unit hypercube) this can be shown to provide a valid probability distribution. This work demonstrated this probabilistic interpretation on MovieLens, representing associating each movie with a binary random variable with marginal probability proportional to the number of users who rated the movie, and similarly defining the joint probability of two such binary random variables as proportional to the number of users who rated both.\mb{Maybe this belongs in the related work.}\\
% % a directed graph such that boxes of parents contain their children with an energy function
% Some of the recent works have tried to incorporate box embeddings in a recommendation systems setup.\citet{InBox, box-diverse, users-as-box} use the side-length of the box embeddings as a preference range to obtain diverse set recommendations for users, \citet{box-efficient-ranking} utilizes the axis parallel nature of the box embeddings for faster retrieval for recommendation systems. \citet{faithful_emb, sun2020guessing, query2box} are some of the recent works that focus on logical query over knowledge bases (KB).\citet{box-for-collaborative-resoning} uses \citet{query2box} and add a volumetric contrastive loss as a regularizer. However, in this work, we frame collaborative filtering as a set-theoretic matrix completion problem, which helps us to achieve better generalization for the composition of personalized queries.

\subsection{Context Aware Recommendation}
{The concept of context-aware recommendation, as introduced in \cite{context-aware-rec-user-context}, provides a general framework where "context" is broadly defined as any auxiliary information. This framework emphasizes that user preferences for items can vary based on the context in which interactions occur, reflecting a user-centric view of contextual information.\\
Building on this foundation, recent works have explored specific instances of context-aware recommendation, such as "attribute-aware recommendation." These approaches often leverage item or user attributes as contextual information to address various goals, including improving user profiling \citep{context-aware-rec-user-context}, predicting missing item attributes \citep{attribute-aware-rec-gcn, attribute-aware-rec-multi-view-graph}, enhancing recommendations for cold-start scenarios\citep{attribute-aware-rec-cold-start-problems}, or providing attribute-based explanations for recommendations \citep{attribute-aware-rec-explainability}.}

{Our work differs significantly in its focus and objectives. we term "attribute-constrained recommendation," which involves generating recommendations explicitly constrained by logical combinations of attributes. Unlike attribute-aware approaches, which aim to improve recommendation quality by incorporating attribute information as auxiliary data, our work directly targets the task of satisfying explicit attribute-based constraints posed by users.} 
%To achieve this, we not only craft an experimental framework around attributes but also extend beyond the provided metadata to identify more fine-grained attributes and their realistic combinations. This effort ensures our experimental setup reflects real-world queries, such as "a pizza place that has Wi-Fi and accepts cash," which require explicit reasoning over combinations of attributes.}


\subsection{Compositional Queries with Vector Embeddings}
It is common in machine learning to represent discrete entities such as items or attributes by vectors~\cite{bengio2013representation} and to learn them by fitting the training data. Besides semantic similarity, some have claimed that learned vectors have compositional properties through vector arithmetic, for example in the empirical analysis of word2vec~\cite{mikolov2013efficient} and GLOVE~\cite{pennington2014glove}, and some theoretical analysis~\cite{levy2014neural,arora2018linear}.  However, anecdotally, many have found that the compositional behavior of vectors is far from reliable \cite{rogers-etal-2017-many}.  Our paper provides a comprehensive evaluation of vector embeddings on compositional queries and compares the results to a region-based alternative.


