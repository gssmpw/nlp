\section{Introduction}
\label{sec:introduction}
Recommendation systems are a standard component of most online platforms, providing personalized suggestions for products, movies, articles, and more.
In addition to generic recommendation, these platforms often present the option for the user to search for items, either via natural language or structured queries.
While collaborative filtering methods like matrix factorization have proven successful in addressing data sparsity for unconditional generation, they often fall short when attempting to combine them with more complicated queries. 
This is not unexpected, as vector embeddings, while effectively capturing linear relationships, are ill-equipped to handle the complex set-theoretic relationships. Even advanced neural network-based approaches, which are designed to capture intricate relationships, have been shown to struggle with set-theoretic compositionally that underlie many real-world preferences. 

% Consider the common scenario where a user desires a movie that is both a "comedy" and "action," but not a "romance."
% This demonstrates a need for a recommendation model capable of handling set operations such as conjunction and negation.

% Recommending items according some logical constraints of their attributes is a key problem in many modern applications, such as e-commerce and video/music streaming platforms. These facets are invoked by simple user queries, which typically correspond to categories, tags, or attributes of the items. While some user queries are straightforward, like "comedy movies," more often they are complex, such as "comedy but not romantic comedies." 

Let us consider an example where a user named Bob wants to watch a comedy which is not a romantic comedy.
Assuming we have a prior watch history for users, standard collaborative filtering techniques (e.g. low-rank matrix factorization) would yield a learned score function $\score(m, \Bob)$ for each movie $m$.
% , however this does not incorporate Bob's search request.
If we also have movie-attribute annotations, we could form the set of comedies $C$ and set of romance movies $R$ and simply filter to those movies in $C \setminus R$, however this assumes that the movie-attribute annotations are complete, which is rarely the case.

A standard approach in a setting with sparse data is to learn a low-rank approximation for the {attribute $\times$ movie} matrix $\mathbf A$, yielding a dense matrix $\hat {\mathbf A}$. We can then form sets of movies based on this dense matrix using an (attribute-specific) threshold, \eg $\hat C \defeq \{m \mid \hat A_{\comedy, m} > \tau_\comedy\}$ and $\hat R \defeq \{m \mid \hat A_{\romance, m} > \tau_\romance\}$, and then rank movies $m \in \hat C \setminus \hat R$ according to $\score(m, \Bob)$. While this approach does allow for performing the sort of queries we are after, it suffers from three fundamental issues:

% \begin{figure}[h!]
%   \centering
%   \subfloat[Standard matrix completion assumes you are given partial information about the user $\times$ movie matrix $\mathbf U$, and potentially incomplete information about the attribute $\times$ movie matrix $\mathbf A$, and asks you to recover any unobserved entries. The task of set-theoretic matrix completion extends this to being able to predict the entries of arbitrary set-theoretic combinations of these rows.]{
%     \includegraphics[width=0.45\textwidth]{pictures/set-theoretic matrix completion.jpg}
%     \label{figure: set-theoretic matrix completion}
%   }
%   \hfill
%   \subfloat[Box embeddings represent the movies, users, and attributes as "boxes" (Cartesian products of intervals) in $\mathbb R^n$. The score for a specific movie in relation to a given query is determined by the proportion of the movie box's volume that falls within the corresponding region. During training, this membership score for a movie, w.r.t the $U$ and $A$ are optimized, creating a set-geometric representation of the matrix.]{
%     \includegraphics[width=0.45\textwidth]{pictures/box depiction.jpg}
%     \label{figure: box depiction}
%   }
%   \caption{Set-theoretic matrix completion for movies, users, and attributes, illustrating how box embeddings, trained in a set-theoretic manner, address this task.}
% \end{figure}
\begin{figure}[]
    \centering
    \includegraphics[width=0.8\columnwidth]{pictures/set-theoretic_matrix_completion.jpg}
    \caption{Standard matrix completion assumes you are given partial information about the user $\times$ movie matrix $\mathbf U$, and potentially incomplete information about the attribute $\times$ movie matrix $\mathbf A$.}
    \label{fig:set_theoretic_mc}
\end{figure}

\begin{figure}[]
    \centering
    \includegraphics[width=0.8\columnwidth]{pictures/box_depiction.jpg}
    \caption{Box embeddings represent the movies, users, and attributes as "boxes" (Cartesian products of intervals) in $\mathbb R^n$.}
    \label{fig:box_depiction}
\end{figure}


% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.8\textwidth]{ICLR 2025 Template/pictures/set-theoretic matrix completion.png} % Adjust width as necessary
%     \caption{The task of set-theoretic matrix completion depicted in the setting where users and attributes form the rows, and movies are the columns. Set-theoretic matrix completion is concerned with not simply filling in additional entries of the user $\times$ Movie matrix $\mathbf U$ or the attribute $\times$ movie matrix $\mathbf A$, but also being able to predict the entries of arbitrary set-theoretic combinations of these rows.}
%     \label{fig:side_caption_image}
% \end{figure}

\begin{enumerate}
    \item Limited user-attribute interaction:
    % separately classifying attributes and then ranking for each user does not take into account user-attribute interactions.
    Since the attribute classification is done independently from the user, any latent relationships between the user and attribute cannot be taken into account.
    \item Error compounding: Errors in the completion of attribute sets accumulate as the number of sets involved in the query increase.
    \item Mismatched inductive-bias: Our queries can be viewed as set-theoretic combinations of the rows, not linear combinations. As such, using a low-rank approximation of the matrix may be misaligned with the eventual use.
\end{enumerate}


% The recommender system has access to the ground truth of the set of movies Bob would like to watch (\textbf{Bob}), the set of comedy movies (\textbf{comedy}), and the set of romantic movies (\textbf{romance}). In this ideal scenario, the system would trivially return \textbf{Bob} $\cap$ \textbf{comedy} $\setminus$ \textbf{romance}. However, in practice, we can only construct these sets from item tags and user history, which are often incomplete and noisy. Consequently, the set operation might yield an inaccurate or empty set of items. This problem is exacerbated as the queries become more complex. (forward reference to experiment sections).

% A standard approach to mitigating the incompleteness issue is to learn representations of \Bob, \romance, and \comedy. One of the traditional yet most effective methods (cite) is to learn a low-rank approximation of the observed matrix $O$ which is the concatenation of the {User $\times$ Movie} interaction matrix $U$ and the {Tags $\times$ Movie} attribute matrix $A$. The learned representations can provide smooth score functions over all possible items for all users and attributes. In our example, we would be able to calculate $\score(\Bob, m)$, $\score(\comedy, m)$, and $\score(\romance, m)$ for all movies $m$ by calculating dot products between the vector representations for the each movie and the vector representations for \Bob, \comedy, and \romance.

% While these scores generalize to the incomplete part of the observed matrix $O$, they do not naturally allow us to compute set-theoretic queries. For example, consider how one might use these representations to address Bob's query from before. 

% This is not optimal for several reasons: the selection of the threshold is an ad-hoc process, and the prediction error for thresholding will snowball rapidly as query complexity increases (see Section ref). A better approach would be to devise a smooth score function for the entire query \textbf{Bob} $\cap$ \textbf{comedy} $\setminus$ \textbf{romance}. A common method to achieve this is by multiplying the scores corresponding to each query, e.g., $s(bob \cap comedy \cap \neg romance, m) = s(bob, m) \times s(comedy, m) \times (1 - s(romance, m))$. However, this approach ignores the interdependence between attributes and users, again resulting in suboptimal behavior for the recommender.\\

In this paper, we formulate the problem of attribute-specific recommendation as matrix completion where rows are not necessarily \emph{linear combinations} of each other but, rather, are \emph{set-theoretic combinations} of each other. More precisely, given some user $\times$ movie interaction matrix $\mathbf U$ and attribute $\times$ movie matrix $\mathbf A$, the queries we are considering are set-theoretic combinations of these rows (see \Cref{fig:set_theoretic_mc}). For example, the ground-truth data for comedies which are not romance movies which Bob likes would be the vector $x \in \{0,1\}^{|M|}$, where $x_m = 1$ if and only if $\mathbf U_{\Bob, m} = 1$ and $\mathbf A_{\comedy, m} = 1$ and $\mathbf A_{\romance, m} = 0$. Note that this is not a linear combination of the previous rows, and so while the inductive bias of low-rank factorization has proven immensely effective for collaborative filtering we should not expect it to be directly applicable in this setting.


% if the observed matrix $O$ is the concatenation of $[U; A]$, the query answering task essentially involves predicting the entries of the rows of the joint matrix $O_{q} = [U; A; U \cap A; U \cap \neg A; U \cap A \cap A; U \cap A \cap \neg A; \cdots]$. 

% Note that, the low-rank approximated vector model is capable of capturing linear dependencies between similar user or attribute rows or between movie columns. This inductive bias proves to be immensely effective for collaborative filtering. However, in our case the relationship amongst the rows of the $O_{q}$ is non-linear and strictly set-theoretic in nature, e.g., the row of \textbf{Bob} $\cap$ \textbf{comedy} is strictly an intersection between the individual rows of \textbf{Bob} and \textbf{comedy}. \\

Instead, we propose to learn representations for the users and attributes that are consistent with specific set-theoretic axioms. These representations must also be compactly parameterizable in a lower-dimensional space, differentiable with respect to some appropriate score function, and allow for efficient computation of various set operations.
% . Additionally, we need to define a measure (similar to vector dot products) to train these representations.
Box Embeddings \citep{hard_box, gumbel_box}, which are axis-parallel $n$-dimensional hyperrectangles, meet these criteria (see \Cref{fig:box_depiction}).
The volume of a box is easily calculated as the product of its side-lengths. Furthermore, box embeddings are closed under intersection (\ie the intersection of two boxes is another box). Inclusion-exclusion thus allows us to calculate the volume of arbitrary set-theoretic combinations of boxes.
% The simple axis-parallel geometry allows for the calculation of intersections of multiple boxes.
% The embedding space is closed under intersection (the intersection of two or more boxes is also a box) and the volume of a box is easily calculated as the product of its side lengths. Via inclusion-exclusion, this allows us to efficiently calculate arbitrary set-theoretic combinations of boxes.
% This ease of parameterization, along with straightforward volume and intersection calculations, makes box embeddings an excellent candidate for our purpose.


The contributions of our paper are as follows -
\begin{enumerate}
    \item We model the problem of attribute-specific query recommendation as "set-theoretic matrix completion", where attributes and users are treated as sets of items. We discuss the challenges faced by existing machine-learning approaches for this problem setup.
    \item We demonstrate the inconsistency of existing vector embedding models for this task. Additionally, we establish box embeddings as a suitable embedding method for addressing such set-theoretic problems.\mb{We don't do this, so we either need to or we need to weaken this claim.}
    \item We conduct an extensive empirical study comparing various vector and box embedding models for the task of set-theoretic query recommendation.
\end{enumerate}

Box embeddings, with their geometric set operations, significantly outperform all vector-based methods. We also evaluate score multiplication and threshold-based prediction for both vector and box embedding models, and find that performing set operations directly on the box embeddings performs best, solidifying our claim that the inductive bias of box embeddings provides the necessary generalization capabilities to address set-theoretic queries.