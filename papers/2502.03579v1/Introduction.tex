\section{Introduction}

The menopausal transition is a critical period for half the worldâ€™s population, marked by physical and psychosocial changes. Few resources exist to support this transition; menopause concerns are frequently ignored and the topic remains taboo in many communities ~\cite{kaunitz2015management}.
Increasingly, chatbots have been proposed as a means to enable conversations on reproductive health topics, by providing a space for on-demand conversations with a non-judgmental agent ~\cite{mills2023chatbots}. This approach has become even more viable with recent developments in Large Language Models (LLMs) ~\cite{park2024assessing}. Though several studies have demonstrated the effectiveness of chatbots in influencing behavioral changes ~\cite{pereira2019using}, challenges remain in standardizing evaluation metrics for health applications ~\cite{guo2020challenges}. Our work aims to address this gap, focusing on the context of information seeking on menopause.

Recent studies suggest the need for standardizing chatbot evaluation for critical clinical variables such as medical accuracy, patient safety, and outcomes ~\cite{beavers2023evaluation}, as well as non-clinical metrics ~\cite{abd2020technical}. They highlight the need for more methodical evaluation frameworks.
% and the role of online communities in supporting sensemaking around the menopausal experience ~\cite{lazar2019parting, arnot2021relationship}
In this study, we assess performance of five publicly available LLM-based chatbots in responding to commonly asked questions on menopause-related concerns. 
We use the S.C.O.R.E (safety, consensus, objectivity, reproducibility, and explainability) framework which covers typical evaluation metrics ~\cite{tan2024proposed}, and highlight both the promises and challenges of such frameworks to inform future evaluation approaches.