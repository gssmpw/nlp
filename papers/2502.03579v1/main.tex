
\documentclass{IOS-Book-Article}

\usepackage{mathptmx}
\usepackage{soul}\setuldepth{article}
\usepackage{multirow}
%\usepackage{times}
%\normalfont
%\usepackage[T1]{fontenc}
%\usepackage[mtplusscr,mtbold]{mathtime}
%
\def\hb{\hbox to 11.5 cm{}}
\usepackage{booktabs}

\begin{document}

\pagestyle{headings}
\def\thepage{}
\begin{frontmatter}              % The preamble begins here.


%\pretitle{Pretitle}
\title{A Mixed-Methods Evaluation of LLM-Based Chatbots for Menopause}

\markboth{}{April 2024\hb}
%\subtitle{Subtitle}

\author[A]{\fnms{Roshini} \snm{Deva}\orcid{0009-0005-9606-2613}%
\thanks{Corresponding Author: Roshini Deva; E-mail: droshin@emory.edu.}},
\author[A]{\fnms{Manvi} \snm{S}\orcid{0009-0003-1727-9511}},
\author[A]{\fnms{Jasmine} \snm{Zhou}\orcid{0009-0006-4355-4777}},
\author[A]{\fnms{Elizabeth Britton} \snm{Chahine}\orcid{0000-0002-6654-2537}},
\author[A]{\fnms{Agena} \snm{Davenport-Nicholson}\orcid{0009-0002-3885-5736}},
\author[A]{\fnms{Nadi Nina} \snm{Kaonga}\orcid{0000-0002-6900-9893}},
\author[A]{\fnms{Selen} \snm{Bozkurt}\orcid{0000-0003-1234-2158}},
and
\author[A]{\fnms{Azra} \snm{Ismail}\orcid{0000-0002-7570-9474}}

%\runningauthor{B.P. Manager et al.}
\address[A]{Emory University, Atlanta, GA, United States.}


\begin{abstract}
The integration of Large Language Models (LLMs) into healthcare settings has gained significant attention, particularly for question-answering tasks. 
Given the high-stakes nature of healthcare, it is essential to ensure that LLM-generated content is accurate and reliable to prevent adverse outcomes. However, the development of robust evaluation metrics and methodologies remains a matter of much debate. 
We examine the performance of publicly available LLM-based chatbots for menopause-related queries, using a mixed-methods approach to evaluate safety, consensus, objectivity, reproducibility, and explainability. 
Our findings highlight the promise and limitations of traditional evaluation metrics for sensitive health topics. 
We propose the need for customized and ethically grounded evaluation frameworks to assess LLMs to advance safe and effective use in healthcare.
% The growing adoption of LLM-based chatbots prompted researchers to evaluate their potential in public health contexts. 
% However, conventional metrics for chatbot evaluation are often limited for healthcare applications, which require advanced reasoning. 
% In this paper, we comprehensively evaluate the effectiveness and reliability of the publicly available chatbots for menopause-related queries using qualitative and quantitative methods to assess the safety, consensus, objectivity, reproducibility, and explainability of their responses. Our findings highlight varied performance and the limitations of traditional evaluation metrics for sensitive topics like menopause. Finally, we emphasize the importance of developing tailored evaluation frameworks to advance LLM-based health applications for specialized care topics.
\end{abstract}

\begin{keyword}
Menopause care\sep Large Language Models\sep
Chatbots
\end{keyword}
\end{frontmatter}
\markboth{April 2024\hb}{April 2024\hb}
%\thispagestyle{empty}
%\pagestyle{empty}


\newcommand{\mieadd}[1]{\textcolor{red}{#1}}
\newcommand{\mierm}[1]{\st{#1}}


\input{Introduction}
\input{methods}
\input{Results}
\input{Discussion}

\section{Conclusion}
Our study highlights the potential of LLM chatbots for delivering information on menopause. Our use of the S.C.O.R.E. evaluation framework revealed that GPT-4o and Menopause Coach consistently delivered precise and clinically aligned information, while Meta AI and Gemini struggled to provide responses that were well-organized, comprehensive, and empathetic.
% Our analysis also revealed that chatbots permed well on treatment related questions but frequently struggled when addressing more complex physical and emotional aspects of menopause. Explainability in particular became a crucial criteria, where even the best-performing chatbots displayed inconsistent responses. This suggests that response depth and clarity need to be improved, particularly for complex or multifaceted problems emotional health or hormonal changes.
Our findings also suggest the need for a more robust and specialized evaluation framework to assess LLM performance. 
% Though chatbots could bridge a significant knowledge gap about menopause, 
% their effectiveness is limited by their inability to 
% Current scoring approaches can be highlighted as subjective and static. 
Our qualitative analysis uncovered gaps in delivering accurate, empathetic, and reliable information, which were not adequately captured in the S.C.O.R.E. framework.
% In order to ensure that chatbots provide safe, unbiased, and repeatable health information and satisfy users' clinical and non-clinical needs, 
Future research should focus on creating and standardizing evaluation frameworks. 
 As chatbot technologies continue to evolve, ensuring reliability will be crucial for their integration in healthcare settings.

\bibliographystyle{vancouver.bst}
\bibliography{main}
\end{document}
