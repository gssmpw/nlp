\section{Discussion}
Our research demonstrates the potential of LLM chatbots for menopause but also highlights persistent challenges around explainability, objectivity/bias, and reproducibility.
In particular, explainability emerged
as a key differentiator across various chatbots. Some chatbots offered clickable and easily accessible references, while others did not provide direct links to their sources. While generally provided accurate and reliable answers, better-performing chatbots like ChatGPT-4o and Menopause Coach ability to justify and explain responses to more challenging questions was less consistent.
%Even the better-performing chatbots, like ChatGPT-4o and Menopause Coach, sometimes performed poorly on this metric. While they generally provided accurate and reliable answers, their ability to justify and explain their responses to more challenging questions was less consistent. 
Copilot was particularly good here and had a user-friendly approach, using in-text citations, clear disclaimers, and direct access to references, showing a potential for credibility than the rest.

Our evaluation process also revealed challenges with traditional evaluation metrics. We found differences in how raters assessed responses, based on how they understood the metric. With respect to reproducibility, R1's approach was more critical, focusing on areas like consistency and follow-up, while R2 had slightly higher ratings. These differences underscore that chatbot assessments depend heavily on the evaluator's expectations and judgments, making them susceptible to personal interpretation rather than a consistent, standardized evaluation.