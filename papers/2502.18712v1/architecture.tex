\section{Framework Architecture}
To integrate the reasoning abilities of LLMs into mobility simulation and model the activity-driven dynamics of human mobility, our framework consists of four primary modules:
\begin{enumerate}
    \item Persona: creating agents for mobility simulation;
    \item Activity: generating daily activities iteratively;
    \item Destination: selecting a location for the activity;
    \item Memory: modeling the long-term pattern of human mobility.
\end{enumerate}
Figure~\ref{fig:pipeline} illustrates the overall framework pipeline and interactions between the four modules.

\begin{figure} [h]
    \centering
    \includegraphics[width=1\linewidth]{img/pipeline.pdf}
    \caption{Overall Pipeline of TrajLLM}
    \Description{This is a figure showing the overall pipeline of TrajLLM. It shows the interactions between persona, activity, destination and memory modules during simulation.}
    \label{fig:pipeline}
\end{figure}

\subsection{Persona}
The first module of TrajLLM focuses on creating agents for mobility simulation. This consists of two phases: generating personas and generating daily activity-location list.

To effectively generate personas that align with real-world population distribution conditions, population statistics are collected from government websites and prompted into LLMs. The statistics are collected for attributes including age, gender, employment condition and occupation, which are assumed to be the key attributes that affect the agent's daily activity pattern. Inspired by the personality simulation capability of LLMs~\cite{personaLLM}, personas are also assigned with big five personality traits~\cite{big5}. This allows LLM-empowered agents to simulate mobility pattern differences between people with different personalities. As residences, workplaces (if the agent is an employee), and schools (if the agent is a student) are relatively constant in reality, each persona will have fixed primary locations assigned to them. These locations will serve as key anchors in their daily trajectories, ensuring a realistic representation of routine movements and interactions within the simulated environment.

Once personas are properly generated, each persona is assigned a unique daily activity-location list, which is generated by LLMs with the persona data.
The list details the specific activities the corresponding agent is likely to engage in, and their associated potential location categories. For example, an agent's `meal' activity may have a list of potential location categories: [`Cafe', `Casual Dining', `Home', `Restaurant'], which means one of these categories may be selected as the dining location for the agent.

This module serves as a pre-processing step before the actual operation of the mobility simulation. Once personas and their corresponding daily activity-location lists are generated, they are utilized as foundational attributes for the agents in the simulation. These attributes guide the agents' behavior, enabling realistic modeling of human mobility patterns based on diverse profiles and daily routines.

\subsection{Activity}
As illustrated in Figure~\ref{fig:pipeline}, after the persona module is pre-processed, the generated personas are passed into the activity module as the background for agents. 
For each LLM-empowered agent, the subsequent activity of the day is simulated iteratively based on a combination of persona attributes, potential activity and location categories, the agent's routine up to that point, and historical mobility patterns. This set of information is then used to create a prompt for the LLM, enabling the language model to reason and generate contextually appropriate activity predictions for the persona. The output data for each activity includes the type of activity, the corresponding location category, and its duration.

Once the location category for an agent's activity is determined by the output of the activity module, it is forwarded to the destination module, which selects a specific destination within the given category. After the destination is finalized, the activity module then starts generating the agent's next activity based on contextual factors and predefined rules. This iterative simulation continues until the end of the day (where the day's activities are all completed), at which point the process resets for the next agent.

\subsection{Destination}
In this section, we focus on determining the destinations for the generated daily activities. As illustrated in Figure~\ref{fig:pipeline}, we have designed two destination selection mechanisms: the first one driven by LLM and the other leveraging the physical model. Both of them take in the current location of the agent (as coordinate), location category for the activity and the agent's historical visiting data from memory.

\subsubsection{LLM-based Destination Selection}
This approach relies entirely on Large Language Models (LLMs) to generate contextually relevant destination recommendations. Historical visiting data is retrieved from the memory module, which stores detailed logs of previous activities and preferences. LLMs process this data to uncover patterns and create recommendations tailored to the persona's goals and behavioural history.

Once recommendations are generated, they serve as input prompts for LLMs to randomize a suitable destination within a specified radius and match the given location category. 
For example, if the activity is "sports and exercise" with a preference for "Gym," the LLM identifies relevant past visits and incorporates them to suggest a nearby gym from the Points of Interests (POIs) dataset.

This method ensures that destination selection is personalized and diverse, balancing historical relevance with real-time randomization. Additionally, the integration of historical activity data ensures that generated recommendations align closely with realistic behavioural patterns, providing a robust foundation for simulated agent movements.

\subsubsection{Physical Model based Destination Selection}
In this module, we consider using mechanistic methods and integrating spatial and historical factors through two primary modules: the Frequency Module and the Spatial Module. The Spatial Module models are based on the spatial interactions between POIs, while the Frequency Module is based on historical data which includes information about agents' preferences and historical patterns. By combining these two aspects, the model ensures that the generated trajectories closely mimic real-world mobility behaviors, achieving both coherence and representativeness in synthetic data generation.

We propose a potential-based spatial model inspired by spatial interaction theory and electromagnetic field principles. The original model is expressed as:
\begin{equation} 
    E(Y_{ij}) = K U_iV_jf(d_{ij})
\end{equation}
where $E(Y_{ij})$is the expected interaction, $U_i$ and $V_j$ are attraction factors, $K$ is a scaling coefficient, and $f(d_{ij})$ is the distance impedance function.

In our case, since we only need to predict the next location for a single agent, $U_i$ (the attraction factor for the origin) can be ignored. Moreover, we use $W_{ij}$ to generate the probability for each POI, so the scaling coefficient $K_{ij}$ is also omitted. As a result, in our spatial model weight of each POI is defined as:
\begin{equation}
    W^s_i =  \frac{P_i}{f(d_{l,i})}
\end{equation}
where $P_i$ represents the potential at location $l$, $W^s_i$ denotes the spatial weight (influence) of POI $i$, $f(d_{l,i})$ is the distance impedance function, and $ d_{l,i}$ is the distance between user current location $l$ and POI $i$ location .

We chose a truncated power law distribution \cite{gonzalez2008mobility} as the distance impedance function, which is defined as:

\begin{equation}
    f(d) = (d + r_0)^{-\beta}e^{-d/k}
\end{equation}
where $r_0$, $\beta$, and $k$ are parameters estimated from empirical data.

The model incorporates historical visits and personal preferences. To manage the large number of POIs in urban areas, we use the lossy count method to discard low-frequency POIs, conserving memory.  

To ensure interpretable predictions, input frequencies are adjusted using quantile mapping, aligning them with real-world distributions:
\begin{enumerate}
    \item \textbf{Rank normalization:} Standardize input frequencies $f_i$ using the inverse ECDF of check-in data:
    \begin{equation}
    z_i = F_c^{-1}\left(\frac{\text{rank}(f_i)}{|P_c|}\right)
    \end{equation}
    \item \textbf{Distribution mapping:} Map standardized values using a function $Psi$, resulting in adjusted frequencies:
    \begin{equation}
    f_i' = \Psi(z_i)
    \end{equation}
    \item \textbf{Weight normalization:} Calculate final weights by normalizing \(f_i'\) and introducing a noise factor $\sigma$:
    \begin{equation}
    W^f_i = (1-\sigma) \frac{f_i'}{\sum_{j \in P_c} f_j'} + \sigma \frac{1}{|P_c|}
    \end{equation}
\end{enumerate}


Unlike additive methods, experiments show that multiplicative integration better captures the complementary relationship between spatial and frequency weights. The probability for a POI is computed as:
\begin{equation}
   P_i = \frac{W^s_i \cdot W^f_i}{\sum_{j \in \mathcal{P_c}} W^s_j \cdot W^f_j}
\end{equation}
Here, $W^s_i$ and $W^f_i$ represent normalized spatial and frequency weights, ensuring a realistic balance between convenience and preference.

\subsection{Memory}
The memory module serves as a foundational component of the simulation framework, enabling efficient management of the vast data streams generated by agents. It employs a hierarchical structure, organizing raw daily activities into daily, weekly, and monthly summaries. This progressive summarization captures critical patterns and trends while minimizing redundancy, ensuring the system remains scalable even as interactions grow over time. 

A standout feature of the memory module is the use of weighted information density metrics to evaluate memory significance. Drawing inspiration from studies such as Holmes and Rahe’s (1967)~\cite{social} Social Readjustment Rating Scale and Tiwari and Deshpande’s (2023)~\cite{urban} urban stress evaluation, the system assigns weights to categories like events, entities, actions, and attributes to reflect their relative importance. While these references provided a conceptual basis for assigning weights, the actual numerical values were determined independently during development. Events and entities, often pivotal in contextualizing activities, are weighted higher to prioritize retention of meaningful details. 

The module calculates an importance score for each memory by combining weighted information density with recency and access frequency, normalized using a sigmoid function to produce a balanced, interpretable measure of relevance. This approach ensures that high-density memories remain prioritized while accommodating temporal factors like recentness and usage patterns. Through this scoring, the system identifies which memories to retain and which to prune, striking a balance between utility and storage efficiency. Extensive iterative testing helped establish a robust threshold score to dynamically prune memories, retaining those with actionable insights while discarding less critical ones. This ensures efficient and relevant memory management.

By balancing scalability with depth, the memory module adapts dynamically to agent needs, supporting realistic and adaptive simulations. Future improvements will refine the weighting system and incorporate personalized metrics to better align memory management with individual agent personas and their unique interactions.
