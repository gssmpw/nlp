%%
%% This is file `sample-sigconf-authordraft.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,authordraft')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf-authordraft.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain}

\usepackage{balance}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.

%% ---------
% \copyrightyear{2025}
% \acmYear{2025}
% \setcopyright{acmlicensed}\acmConference[WWW Companion '25]{Companion Proceedings of the ACM Web Conference 2025}{April 28-May 2, 2025}{Sydney, NSW, Australia}
% \acmBooktitle{Companion Proceedings of the ACM Web Conference 2025 (WWW Companion '25), April 28-May 2, 2025, Sydney, NSW, Australia}
% \acmDOI{10.1145/3701716.3715201}
% \acmISBN{979-8-4007-1331-6/25/04}

\acmConference[Preprint]{Preprint}{2025}{Sydney}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{TrajLLM: A Modular LLM-Enhanced Agent-Based Framework for Realistic Human Trajectory Simulation}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Chenlu Ju}
\authornote{All authors contributed equally to this work.}
\affiliation{%
  \institution{University of New South Wales}
  \city{Sydney}
  \state{NSW}
  \country{Australia}
}
\email{c.ju@student.unsw.edu.au}

\author{Jiaxin Liu}
\authornotemark[1]
\affiliation{%
  \institution{University of New South Wales}
  \city{Sydney}
  \state{NSW}
  \country{Australia}
}
\email{jiaxin.liu6@student.unsw.edu.au}

\author{Shobhit Sinha}
\authornotemark[1]
\affiliation{%
  \institution{University of Illinois Urbana-Champaign}
  \city{Champaign}
  \country{USA}}
\email{ss194@illinois.edu}

\author{Hao Xue}

\affiliation{%
 \institution{University of New South Wales}
 \city{Sydney}
 \state{NSW}
 \country{Australia}}
\email{hao.xue1@unsw.edu.au}

\author{Flora Salim}
\affiliation{%
  \institution{University of New South Wales}
  \city{Sydney}
  \state{NSW}
  \country{Australia}}
\email{flora.salim@unsw.edu.au}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.

\renewcommand{\shortauthors}{Chenlu Ju, Jiaxin Liu, Shobhit Sinha, Hao Xue, \& Flora Salim}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
This work leverages Large Language Models (LLMs) to simulate human mobility, addressing challenges like high costs and privacy concerns in traditional models. Our hierarchical framework integrates persona generation, activity selection, and destination prediction, using real-world demographic and psychological data to create realistic movement patterns. Both physical models and language models are employed to explore and demonstrate different methodologies for human mobility simulation. By structuring data with summarization and weighted density metrics, the system ensures scalable memory management while retaining actionable insights. Preliminary results indicate that LLM-driven simulations align with observed real-world patterns, offering scalable, interpretable insights for social problems such as urban planning, traffic management, and public health. The framework’s ability to dynamically generate personas and activities enables it to provide adaptable and realistic daily routines. This study demonstrates the transformative potential of LLMs in advancing mobility modeling for societal and urban applications. The source code and interactive demo for our framework are available at \url{https://github.com/cju0/TrajLLM}.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010178.10010179.10010182</concept_id>
       <concept_desc>Computing methodologies~Natural language generation</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10010405.10010481.10010487</concept_id>
       <concept_desc>Applied computing~Forecasting</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[300]{Computing methodologies~Natural language generation}
\ccsdesc[300]{Applied computing~Forecasting}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Large Language Models; Agent-based Simulation; Human Mobility Generation}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A comprehensive understanding of human mobility patterns is essential for the development of sustainable communities. It plays a pivotal role in the control of infectious diseases, in optimizing energy consumption, and in the formulation of urban planning strategies. However, direct utilization of real-world mobility data is often constrained by privacy concerns, as it encompasses sensitive information regarding individual movement patterns and personal behaviors. Furthermore, the collection of comprehensive mobility data is expensive. In this case, simulation of mobility data has emerged as a promising solution. 

Previous approaches to modeling human mobility can be broadly categorized into mechanistic and deep learning models. Mechanistic models leverage stochastic processes to characterize human mobility behaviors, while these models tend to be oversimplified and focus only on certain aspects of mobility behavior, failing to generate comprehensive and nuanced mobility patterns. In contrast, deep learning models are capable of learning and generating human mobility patterns from training data, but often fail to capture the underlying mechanisms driving mobility behavior. Additionally, they suffer from low sample efficiency when learning behavior distributions and tend to generate data that lacks semantic-aware intentions, limiting their interpretability and realism.

The advances in Large Language Models (LLMs) have shown promising capabilities in understanding and generating coherent intentions through techniques like chain-of-thought prompting and role-playing. It has demonstrated remarkable abilities in understanding humans and society, with applications in political science, economics, and other social science studies. In recent years, several models have been proposed to simulate human mobility data using LLMs, such as LLMob \cite{wang2024large} and CoPB \cite{CoPB}. LLMob relies solely on LLMs, utilizing historical data and personal profiles, while CoPB integrates LLMs with a gravity model to simulate mobility data.

Our framework TrajLLM combines the ability of LLMs to generate coherent and interpretable human activities with an innovative physical model for location mapping, minimizing reliance on real-world historical check-in data by leveraging static Point-of-Interest (POI) data. Additionally, we integrate a memory module to ensure agents exhibit consistent and realistic activity patterns over time, reflecting habitual behaviors. 
In comparison to existing solutions, this novel approach not only enables the activity-driven generation of daily mobility trajectories, but also further enhances agent alignment with human behaviors through the consolidation of agents' historical visitation data. Furthermore, the integration of fundamental physical models ensures TrajLLM's simulation efficiency, providing a balance between accuracy and performance.

\section{Framework Architecture}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To integrate the reasoning abilities of LLMs into mobility simulation and model the activity-driven dynamics of human mobility, our framework consists of four primary modules: persona, activity, destination, and memory.
Figure~\ref{fig:pipeline} illustrates the overall framework pipeline and interactions between the four modules.

\begin{figure} [ht]
    \centering
    \includegraphics[width=\linewidth]{img/pipeline_upgraded.pdf}
    \caption{Overall Pipeline of TrajLLM}
    \Description{This is a figure showing the overall pipeline of TrajLLM. It shows the interactions between persona, activity, destination and memory modules during simulation.}
    \label{fig:pipeline}
\end{figure}

To take both time and cost efficiency into account, we adopt LLAMA-3.1-8B-Instruct and GPT-4o-mini as LLM options to check the performance of these two models.

\subsection{Persona}
The first module of TrajLLM focuses on creating agents for mobility simulation. It consists of two phases: generating personas and generating daily activity-location lists.

To effectively generate personas that align with real-world population distribution conditions, population statistics are collected from government websites and prompted into LLMs. The statistics are collected for attributes including age, gender, employment condition, and occupation, which are assumed to be the key attributes that affect the agent's daily activity pattern. Inspired by the personality simulation capability of LLMs~\cite{personaLLM}, personas are also assigned with big five personality traits~\cite{big5}. This allows LLM-empowered agents to simulate mobility pattern differences between people with different personalities. As residences, workplaces (if the agent is an employee), and schools (if the agent is a student) are relatively constant in reality, each persona will have fixed primary locations assigned to them. These locations will serve as key anchors in their daily trajectories, ensuring a realistic representation of routine movements and interactions within the simulated environment.

Once personas are properly generated, each persona is assigned a unique daily activity-location list, which is generated by LLMs with the persona data.
The list details the specific activities the corresponding agent is likely to engage in, and their associated potential location categories. For example, an agent's `meal' activity may have a list of potential location categories: [`Cafe', `Casual Dining', `Home', `Restaurant'], which means one of these categories may be selected as the dining location for the agent.

This module is a pre-processing step before the actual operation of the mobility simulation. Once personas and their corresponding daily activity-location lists are generated, they are utilized as foundational attributes for the agents. These attributes guide the agents' behavior, enabling realistic modeling of human mobility patterns based on diverse profiles and daily routines.

\subsection{Activity}
As illustrated in Figure~\ref{fig:pipeline}, after the persona module is pre-processed, the generated personas are passed into the activity module as the agents' background information. 
For each LLM-empowered agent, the subsequent activity of the day is simulated iteratively based on a combination of persona attributes, potential activity and location categories, the agent's routine up to that point, and historical mobility patterns. This set of information is then used to create a prompt for the LLM, enabling the language model to reason and generate contextually appropriate activity predictions for the persona. The output data for each activity includes the type of activity, the corresponding location category, and its duration.

Once the location category for an agent's activity is determined by the output of the activity module, it is forwarded to the destination module, which selects a specific destination within the given category. After the destination is finalized, the activity module then starts generating the agent's next activity based on contextual factors and predefined rules. This iterative simulation continues until the end of the day (where the day's activities are all completed), at which point the process resets for the next agent.

\subsection{Destination}
In this section, we focus on determining the destinations for the generated daily activities. As illustrated in Figure~\ref{fig:pipeline}, we have designed two destination selection mechanisms: one is driven by LLM and the other utilizes physical models. Both of them take in the current location of the agent (as coordinate), location category for the activity and the agent's historical visiting data from memory.

\subsubsection{LLM-based Destination Selection}
This approach relies entirely on Large Language Models (LLMs) to generate contextually relevant destination recommendations. Historical visiting data is retrieved from the memory module, which stores detailed logs of previous activities and preferences. LLMs process this data to uncover patterns and create recommendations tailored to the persona's goals and behavioural history.

Once recommendations are generated, they serve as input prompts for LLMs to randomize a suitable destination matching a given location category within a specified radius. 
For example, if the activity is "sports and exercise" with a preference for "Gym," the LLM identifies relevant past visits and incorporates them to suggest a nearby gym from the Points of Interests (POIs) dataset.

This method ensures that destination selection is personalized and diverse, balancing historical relevance with real-time randomization. Additionally, the integration of historical activity data ensures that generated recommendations align closely with realistic behavioural patterns, providing a robust foundation for simulated agent movements.

\subsubsection{Physical Model based Destination Selection}
In this module, we consider using mechanistic methods and integrating spatial and historical factors through two primary modules: the Frequency Module and the Spatial Module. The Spatial Module models are based on the spatial interactions between POIs, while the Frequency Module is based on historical data which includes information about agents' preferences and historical patterns. By combining these two aspects, the model ensures that the generated trajectories closely mimic real-world mobility behaviors, achieving both coherence and representativeness in synthetic data generation.

We propose a potential-based spatial model inspired by spatial interaction theory and electromagnetic field principles. The original model is expressed as:
\begin{equation} 
    E(Y_{ij}) = K U_iV_jf(d_{ij})
\end{equation}
where $E(Y_{ij})$is the expected interaction of travel flow $Y_{ij}$ from user current location $i$ to next location $j$, $U_i$ and $V_j$ are attraction factors , $K$ is a scaling coefficient. $f(d_{ij})$ is the distance impedance function and $d_{ij}$ is the distance between the location $i$ and $j$.

In our case, since we only need to predict the next location for a single agent, we use spatial weight $W^s_{j}$ to represents the probability of the user moving from the current location to the next location  $j$. So the scaling coefficient $K$ and $U_i$ are omitted, and our spatial model weight of each POI is defined as:
\begin{equation}
    W^s_j =  \frac{V_j}{f(d_{ij})}
\end{equation}

We chose a truncated power law distribution \cite{gonzalez2008mobility} as the distance impedance function, which is defined as:

\begin{equation}
    f(d) = (d + r_0)^{-\beta}e^{-d/k}
\end{equation}
where $r_0$, $\beta$, and $k$ are parameters estimated from empirical data.

The model incorporates historical visits and personal preferences. To manage the large number of POIs in urban areas, we use the lossy count method to discard low-frequency POIs, conserving memory.  

To ensure interpretable predictions, input frequencies are adjusted via quantile mapping, aligning them with real-world distributions:
\begin{enumerate}
    \item \textbf{Rank normalization:} Standardize input frequencies $f_i$ using the inverse ECDF of check-in data:
    \begin{equation}
    z_i = F_c^{-1}\left(\frac{\text{rank}(f_i)}{|P_c|}\right)
    \end{equation}
    where $F^{-1}_c$ represents the inverse ECDF of the target distribution estimated from check-in data of POI category $c$, $P_c$ is the POI set of category $c$.
    \item \textbf{Distribution mapping:} Map standardized values using a function $\Psi$, resulting in adjusted frequencies:
    \begin{equation}
    f_i' = \Psi(z_i)
    \end{equation}
    \item \textbf{Weight normalization:} Calculate final weights by normalizing \(f_i'\) and introducing a noise factor $\sigma$:
    \begin{equation}
    W^f_i = (1-\sigma) \frac{f_i'}{\sum_{j \in P_c} f_j'} + \sigma \frac{1}{|P_c|}
    \end{equation}
    where $W^f_i$ represent normalized spatial and frequency weights.
\end{enumerate}

Unlike additive methods, experiments show that multiplicative integration better captures the complementary relationship between spatial and frequency weights. To ensuring a realistic balance between convenience and preference, The probability for POI $i$ is computed as:
\begin{equation}
   P_i = \frac{W^s_i \cdot W^f_i}{\sum_{j \in \mathcal{P_c}} W^s_j \cdot W^f_j}
\end{equation}


\subsection{Memory}
The memory module serves as a foundational component of the simulation framework, enabling efficient management of the vast data streams generated by agents. It employs a hierarchical structure, organizing raw daily activities into daily, weekly, and monthly summaries. This progressive summarization captures critical patterns and trends while minimizing redundancy, ensuring the system remains scalable even as interactions grow over time. 

A standout feature of the memory module is the use of weighted information density metrics to evaluate memory significance. Drawing inspiration from studies such as Holmes and Rahe’s (1967)~\cite{social} Social Readjustment Rating Scale and Tiwari and Deshpande’s (2023)~\cite{urban} urban stress evaluation, the system assigns weights to categories like events, entities, actions, and attributes to reflect their relative importance. While these references provided a conceptual basis for assigning weights, the actual numerical values were determined independently during development. Events and entities, often pivotal in contextualizing activities, are weighted higher to prioritize retention of meaningful details. 

The module calculates an importance score for each memory by combining weighted information density with recency and access frequency, normalized using a sigmoid function to produce a balanced, interpretable measure of relevance. This approach ensures that high-density memories remain prioritized while accommodating temporal factors like recentness and usage patterns. Through this scoring, the system identifies which memories to retain and which to prune, striking a balance between utility and storage efficiency. Extensive iterative testing helped establish a robust threshold score to dynamically prune memories, retaining those with actionable insights while discarding less critical ones. This ensures efficient and relevant memory management.

By balancing scalability with depth, the memory module adapts dynamically to agent needs, supporting realistic and adaptive simulations. Future improvements will refine the weighting system and incorporate personalized metrics to better align memory management with individual agent personas and their unique interactions.


\section{Demonstration}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Our solution integrates back-end processing and a dynamic front-end to create an intuitive simulation framework. It consists of two key components: (1) a Flask-based back-end server for handling simulation logic and managing agent activity data, and (2) a front-end web application built with HTML, CSS, JavaScript, and the Leaflet.js library for visualization.

The back-end server provides RESTful API endpoints, such as the \texttt{/start\_day} endpoint, which processes input parameters like the number of agents and start time to generate a JSON response with detailed agent activities and coordinates.
Its modular architecture enables easy integration with new data sources and generative models, ensuring scalability and adaptability.

% Interactive frontend
The front-end application offers a user-friendly interface for real-time interaction. Users can adjust parameters via sliders and input fields, visualize agent movements on a map, and access live activity logs with toggle-able controls. This combination ensures usability and interactivity, making it ideal for engaging demonstrations. The front-end HTML file is available in our GitHub repository for users to explore and interact with independently.

To ensure accessibility and usability during demonstrations, the framework is deployed on a web server using Flask. This setup allows conference attendees to interact with the simulation directly on their devices or via a dedicated terminal provided at the venue.

For the purpose of demonstration, we leverage the public check-ins dataset of Tokyo as the underlying POIs dataset for simulation (note that the proposed simulation platform supports other cities as well). Based on this, the personas for the agents are created using population statistics collected from local government
website\footnote{\url{https://www.stat.go.jp/english/data/index.html}}.
As illustrated in Figure~\ref{fig:demo}, the visualization presents a sample of one-day trajectories for ten agents in Tokyo.
This interface provides an intuitive layout with a map view for agent trajectories, sliders, and input fields for simulation parameters. The "Live Movement Updates" panel displays agent-specific details such as gender, occupation, activity, and location, highlighting the system's scalability, modularity, and ease of interaction.
This makes it an effective tool for showcasing dynamic simulations in academic and professional environments.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{img/frontend.pdf}
    \caption{Real-Time Simulation of Daily Activities in Tokyo}
    \Description{This is a figure showing the front-end demonstration for the simulation of one-day routines of 10 agents in Tokyo. Their movement for daily activities are represented on the map, with textual details of the activities.}
    \label{fig:demo}
\end{figure}


\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this paper, we propose an LLM-empowered agent-based modular mobility generation framework, TrajLLM. It utilizes iterative activity simulation and hybrid models destination selection mechanisms to allow memory-guided LLM agents to simulate effective human activity trajectories. Key contributions include the development of a modular framework that seamlessly integrates human behavioral and spatial-temporal dynamics into mobility simulation, significantly enhancing the realism and adaptability of generated long-term human movement patterns, while reducing the reliance on real-world data. In addition, our interactive web interface allows users to flexibly configure simulation parameters to visualize the daily trajectories of different numbers of agents at different times.

% Limitation
The limitations of LLMs in fully capturing the complexity of human behavior are undeniable, but our activity-driven trajectory simulation mechanism enhances overall accuracy. However, the potential biases embedded within the data sets present a persistent challenge that requires further mitigation. Furthermore, future research will focus on incorporating interactions between agents to refine the simulation's realism and generalizability.


\section{Ethical Use of Data}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

All datasets used in this research are composed of publicly available data obtained from credible sources. These datasets do not contain any personally identifiable information (PII), ensuring compliance with ethical standards for data usage. This study ensures that the data utilized is properly sourced, transparent, and used responsibly, with no potential for harm or privacy violations. 

TrajLLM-generated data should be indicated as synthetic to avoid misleading conclusions in usage and to ensure accountability and transparency.


\begin{acks}
We would like to thank the support of the National Computational Infrastructure, the ARC Center of Excellence for Automated Decision Making and Society (CE200100005), and OpenAI’s Researcher Access Program for providing API access to GPT models.
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\balance
\bibliography{reference}

\end{document}
