\section{Dataset Construction}
\input{table/dataset}



\subsection{Question Collection}
We collect Chinese questions from the sources:
\noindent \textbf{WebText} \cite{bright_xu_2019_3402023}: A large-scale Chinese community question-answering dataset spanning diverse topics.

\noindent \textbf{WebCPM} \cite{DBLP:conf/acl/QinCJYLZLHDWXQL23}: A Chinese long-form question-answering dataset focused on interactive web search contexts.

\noindent \textbf{Zhihu-KOL} \cite{zhihu-kol}: A high-quality question-answering dataset derived from Zhihu, a prominent Chinese QA platform.

\noindent \textbf{RGB} \cite{DBLP:conf/aaai/0011LH024}: A bilingual question-answering dataset based on news reports.

\noindent \textbf{TrickQA}: Questions with ambiguous, incorrect, or unverifiable premises (see Appendix~\ref{app:question} for details).

After collecting these questions, we input them into an open-sourced RAG system to simulate real-world question-answering scenarios and analyze how the system processes and responds to these diverse inputs. The RAG system retrieves five external documents and generates responses. Statements in the answers are annotated with citation marks (1â€“5), indicating alignment with information from the corresponding documents. On average, each statement spans 33.4 tokens, while each document averages 177.3 tokens. An original sample is formed by pairing a labeled statement with its cited documents, represented as a tuple (question, answer, statement, cited documents).


\subsection{Data Augmentation}

The goal of data augmentation is to create negative samples of high quality by making minor modifications to the cited documents in the original samples. Given the use of an industrial RAG system, the number of negative samples in the original samples is estimated to be insufficient. To construct a balanced training set, as well as a label-balanced dev set and test set for evaluation, successfully augmented negative samples can be used. The modified documents should not be inconsistent or incoherent, so as not to provide the trained model with a false basis for judging the negative samples.

We use GPT-4o \cite{openai2024gpt4technicalreport} for data augmentation. After providing the original sample to the LLM, it is asked to perform the following steps in sequence:

\noindent \textbf{Segments Identification}: Find all key segments in the cited document that directly support the information in the statement.

\noindent \textbf{Segments Grouping}: Group the key segments by the information they support, with each group containing key segments that support the same or related information in the statement.

\noindent \textbf{Segments Modification}: Select a group of key segments and modify them so that they do not support the corresponding information in the statement. 

The modification changes only the portion that relates to the supported information in the statement. This maintains logical flow and non-contradictory information within the key segments, and keep the key segments logical in the context of the document and non-contradictory to other information in the document. If there is more than one key segment in a group, the information in all of them should be consistent after the modification.

For each sample, the LLM is asked to try two methods of modification:

\noindent\textbf{Content Revision}: Alter specific details within a key segment without introducing direct contradictions to the original information.

\noindent \textbf{Structure Preservation}: Remove information from a key segment while ensuring the overall coherence and integrity of the segment remain intact.

After completing the LLM augmentation, each original sample is accompanied by the LLM-labeled key segment information and corresponds to the two augmented samples generated by the LLM using the two modification methods. The cost is 0.026\$ per sample. See Appendix~\ref{app:aug} for more details of the augmentation.


\subsection{Two-stage Manual Annotation}

The original samples need to be manually labeled as positive or negative samples before they can be used to form the dataset (examples are shown in Table~\ref{tab:dataset}). In the LLM augmentation phase, although we try to guide the LLM to augment negative samples with qualified quality, the LLM may generate some samples that do not meet the requirements. Therefore, the augmented samples also need to be manually labeled for compliance before they can be used to form the dataset. The goal of the two-stage manual annotation is to complete the manual annotation needed above.

In the first stage, the annotators (from the professional data annotation institution in China) need to label whether the original sample is a positive or negative sample, i.e., to determine whether the sum of the information provided by the cited documents fully supports the statement. In order to reduce the difficulty of labeling, the information of key segments labeled by LLM will be provided to the annotators as a reference. However, since the LLM labeling is not always accurate, if the annotators are unable to make a judgment after reading the key segments, they still need to read other parts of the documents to make a judgment. 
In this stage, the number of negative samples identified by the annotation is 1,006, with a negative sample rate of about 9\%. We randomly selected 2,000 samples (1,000 negative and 1,000 positive) and split them equally to create the development and test sets. The augmented samples corresponding to the positive samples in the remaining original samples will be labeled in the second stage.

In the second stage, the annotators need to determine whether an augmented sample is of acceptable quality and whether it is a negative sample. In order to reduce the difficulty of labeling, we show the annotator a comparison of the documents before and after the modification in the form of modification traces. Among the augmented samples that the annotators determine to be negative samples of acceptable quality, we select 2,449 samples that use the modification methods of changing information and deleting information respectively, totaling 4,898 samples. These augmented negative samples together with the 4,898 positive samples in the original samples identified by the first stage of annotation constitute the training set. The two-stage manual annotation costs 0.5\$ per sample. See Appendix~\ref{app:ann} for instructions for annotators.
