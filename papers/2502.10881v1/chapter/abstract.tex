\begin{abstract}


Citation faithfulness detection is critical for enhancing retrieval-augmented generation (RAG) systems, yet large-scale Chinese datasets for this task are scarce. Existing methods face prohibitive costs due to the need for manually annotated negative samples. To address this, we introduce the first large-scale Chinese dataset \textsc{CiteCheck} for citation faithfulness detection, constructed via a cost-effective approach using two-stage manual annotation. This method balances positive and negative samples while significantly reducing annotation expenses. \textsc{CiteCheck} comprises training and test splits. Experiments demonstrate that: (1) the test samples are highly challenging, with even state-of-the-art LLMs failing to achieve high accuracy; and (2) training data augmented with LLM-generated negative samples enables smaller models to attain strong performance using parameter-efficient fine-tuning. \textsc{CiteCheck} provides a robust foundation for advancing citation faithfulness detection in Chinese RAG systems. The dataset is publicly available at \url{https://github.com/xzy-xzy/CiteCheck} to facilitate research.
\end{abstract}
