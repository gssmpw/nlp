\section{Conclusion}
\label{sec:conclusion}

This paper presents a \textbf{Lo}w-\textbf{Ra}nk \textbf{T}est-\textbf{T}ime \textbf{T}raining (\name), a novel test-time training method for VLMs.
\name\ leverages LoRA, enabling effective adaptation to distribution shifts during test time without incurring catastrophic forgetting.
Additionally, we introduce a highly efficient reconstruction loss suited for TTT, which enhances the generalization and calibration performance of our method.
Extensive experiments on two benchmarks demonstrate that \name\ outperforms state-of-the-art text prompt tuning methods, while requiring less memory, runtime, and avoiding the need for external resources.
These results show that \name\ can be applied across a wide range of domains and applications, from high-stakes environments to edge devices.
We hope our work serves as a foundation for developing new TTT methods for foundation models, unlocking the potential of the image encoder.


% \section{acknowledgement}
% This research is supported by funding from Sony Semiconductor Solutions Corporation through the Visiting Industry Fellow program at the University of California, San Diego.
