\section{Related Work}

\subsection{Text-to-SQL Methods}

Recent Text-to-SQL methods primarily involve fine-tuning and LLM-prompting techniques. Fine-tuning approaches~\citep{wang2019rat, scholak2021picard, li2023resdsql, CodeS} focus on optimizing models for benchmarks by capturing schema representation, query formats, and logical relationships. In contrast, LLM-prompting~\citep{zhang2023act, gao2023text, pourreza2024din, talaei2024chess} leverages carefully crafted prompts, often in few-shot or zero-shot settings, to eliminate the need for task-specific fine-tuning. While these methods excel on simpler datasets like Spider 1.0~\citep{yu2018spider} and BIRD~\citep{li2024can}, they struggle with complex benchmarks such as Spider 2.0~\citep{lei2024spider} due to challenges in database comprehension, ambiguity resolution, and SQL dialect handling. To break down, schema linking, SQL generation, and iterative refinement are the core tasks in Text-to-SQL. Techniques like semantic matching~\citep{kothyari-etal-2023-crush4sql}, in-context examples~\citep{gao2023texttosqlempoweredlargelanguage}, sub-query decomposition~\citep{pourreza2024din}, and self-refinement with memory~\citep{shinn2024reflexion} have advanced SQL generation. Calibration techniques, such as using LLM log probabilities~\citep{ramachandran2024texttosqlcalibrationneedask} or direct yes/no validation~\citep{tian2023justaskcalibrationstrategies}, further enhance confidence in SQL correctness, demonstrating the increasing sophistication of Text-to-SQL methods.

\subsection{Coding Agents}
Coding agents enable LLMs to interact dynamically with their environment by using tools, executing commands, observing feedback, and planning actions. Early frameworks like ReAct~\citep{yao2023react} introduced reasoning and acting components, while Self-Debugging~\citep{chen2023teaching} and InterCode~\citep{yang2024intercode} showcased iterative problem-solving through debugging and lightweight reinforcement learning. Plan-and-Solve Prompting~\citep{wang2023plan} and multi-agent systems like CodeR~\citep{chen2024coder} and Reflexion~\citep{shinn2024reflexion} further enhanced task decomposition and iterative improvement. Specialized frameworks, such as Spider Agent~\citep{lei2024spider}, addressed domain-specific challenges like SQL query generation. However, coding agents often face limitations in specialized tasks, where domain-specific solutions may outperform generalized frameworks~\citep{xia2024agentless}.

Another line of agent research target on structured and predefined workflows that guide LLMs and tools for more reliable performance designed for specific tasks. Originating from concepts like Chain-of-Thought~\citep{wei2022chain} and Self-Consistency~\citep{wang2022self}, workflows have evolved with advancements such as Flows~\citep{josifoski2023flows}, AutoGen~\citep{wu2023autogen}, and FlowMind~\citep{zeng2023flowmind}, enabling modular, collaborative, and automated workflows. In code generation, frameworks like MetaGPT~\citep{hong2023metagpt} and AlphaCodium~\citep{ridnik2024code} have demonstrated the utility of structured workflows in coding tasks. While existing coding agents and workflows address iterative refinement and modular problem-solving, ReFoRCE uniquely integrates table compression, format restriction, and iterative column exploration as new weapons to tackle enterprise-scale SQL challenges.