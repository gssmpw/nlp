\section{Related Work}
\label{sec:soa}
Image up-scaling is a well-analyzed research field~\cite{singh2020survey,van2006image}, with Nearest-neighbor interpolation being one of the simplest approaches or other signal-based methods that are popular, as for example the Lanczos filter~\cite{duchon1979lanczos}.
The general problem is to provide a high-resolution image based on a low-resolution input image, considering e.g. the details and content of the image.
In the following, we focus on recently published DNN-based approaches for image up-scaling.

In general, the recent advances in deep learning showed promising results of using DNNs for various image processing tasks, where up-scaling is just one example.
For the problem of image up-scaling, also handled as super-resolution, such deep learning-based approaches can be categorized into CNN-based, RNN-CNN-based, and GAN-based models~\cite{ha2018deep} or even more fine granular~\cite{anwar2020deep}.
CNN-based models are, e.g., SRCNN~\cite{dong2014learning}, waifu2x~\cite{waifu2x}, neural-enhance~\cite{shi2016real} or VDSR~\cite{kim2016accurate}, here the low-resolution image is usually extended by features learned from a convolutional neural network and then fused together to form the up-scaled version.
The RNN-CNN-based approaches, such as MemNet~\cite{tai2017memnet}, use recurrent neural networks with memory to enhance the down-scaled image.
The last model group is GAN-based models, for example, models of this type are SRGAN~\cite{ledig2017photo}, Real-ESRGAN~\cite{wang2021realesrgan}, or BSRGAN~\cite{zhang2021designing}.
In general GAN-based models consist of two networks, a generative network and a discriminative network, where the generative network upsamples the image in case of super-resolution and the discriminative network is used to distinguish the ground truth and up-scaled images.
It is, e.g., shown that SRGAN~\cite{ledig2017photo} outperforms signal-based and CNN/RNN-CNN-based approaches.
Real-ESRGAN~\cite{wang2021realesrgan} has been trained on real-world content and also showed promising results compared to other models.
There are also models with mixed approaches, such as KXNet~\cite{fu2022kxnet}, or VDVAE-SR~\cite{chira2023image} available.
Furthermore, not all models, e.g., BSRDM~\cite{yue2022blind} are applicable for higher resolution input images with their provided open-source implementation, mainly because they are just trained and evaluated on smaller inputs as a proof-of-concept.
In addition, some proposed methods are just evaluated with low-resolution input images due to performance reasons.

In most cases, the evaluation focuses primarily on objective metrics such as SSIM, PSNR, or a few example images for demonstration purposes, which is for example the case for KXNet~\cite{fu2022kxnet}, BSRGAN~\cite{zhang2021designing}, or Real-ESRGAN~\cite{wang2021realesrgan}.
However, the complexity and generation of content using DNNs introduce new types of distortions, that the used image quality models cannot handle properly, because they have been developed with different distortions.
For pure performance reasons, it is clear, that PSNR or SSIM can be used for the evaluation to compare the generated image with the high-resolution version.
However, some of the models may still perform reasonably well even though they do not match perfectly the high-resolution reference image, considering that the introduced new content or artifacts may look appealing or real.
Objective quality models need re-training for such specific generated contents, as it is also shown for AI-generated images in~\cite{goering2023aiquality}.
More recent no-reference image quality models may be applicable to evaluate the quality, e.g., DBCNN~\cite{zhang2020blind}, HYPERIQA~\cite{su2020blindly}, Deimeq~\cite{goering2018Deimeq}, or NIMA~\cite{idealods2018imagequalityassessment}.
These image quality models are mostly based on DNNs combined with transfer learning and outperform for image compression and common distortions other state-of-the-art models.
Thus they may be able to handle and detect distortions of AI-generated content which will be covered in our evaluation.

To sum up, we identified three open points which we will be addressing in the following paper.
Firstly, there are only a few studies focusing on the comparison of several AI-based upscaling methods available.
Secondly, high resolution images are less often used for the evaluation.
And thirdly, the evaluation does usually not include human annotations for a wide range of images and modern objective models for AI-based artifacts.