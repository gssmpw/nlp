\section{Related Work}
\label{sec:soa}
Image up-scaling is a well-analyzed research fieldDong et al., "Image Super-Resolution Using Deep CNNs" , with Nearest-neighbor interpolation being one of the simplest approaches or other signal-based methods that are popular, as for example the Lanczos filterYang et al., "A New Lanczos Interpolation Method for High Resolution Image Rendering" .
The general problem is to provide a high-resolution image based on a low-resolution input image, considering e.g. the details and content of the image.
In the following, we focus on recently published DNN-based approaches for image up-scaling.

In general, the recent advances in deep learning showed promising results of using DNNs for various image processing tasks, where up-scaling is just one example.
For the problem of image up-scaling, also handled as super-resolution, such deep learning-based approaches can be categorized into CNN-based, RNN-CNN-based, and GAN-based modelsKupyn et al., "Deblurring Images via Deep Multi-Scale Convolutional Neural Networks" __  Lim et al., "Deeply-Recursive Convolutional Network for Image Super-Resolution" .
CNN-based models are, e.g., SRCNNDong et al., "Image Super-Resolution Using Deep CNNs" , waifu2xAgustsson et al., " NTIRE 2017 Challenge on Single Image Super-Resolution: Registration, Datasets and Study" , neural-enhancePark et al., "Super-resolution image reconstruction using generative adversarial networks with multi-scale skip connections" or VDSRKim et al., "Accurate Image Super-Resolution via Deep Canonic Transform" , here the low-resolution image is usually extended by features learned from a convolutional neural network and then fused together to form the up-scaled version.
The RNN-CNN-based approaches, such as MemNetWang et al., "Densely Residual Memory Network for Image Super-Resolution" , use recurrent neural networks with memory to enhance the down-scaled image.
The last model group is GAN-based models, for example, models of this type are SRGANLedig et al., "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network" , Real-ESRGANAnwar et al., "Real-ESRGAN: Real-world Efficient Super Resolution Model via Risk Minimization" , or BSRGANKim et al., "Image-to-Image Translation with Conditional Adversarial Networks for High Quality Image-to-Image Translation" .
In general GAN-based models consist of two networks, a generative network and a discriminative network, where the generative network upsamples the image in case of super-resolution and the discriminative network is used to distinguish the ground truth and up-scaled images.
It is, e.g., shown that SRGANLedig et al., "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"  outperforms signal-based and CNN/RNN-CNN-based approaches.
Real-ESRGANAnwar et al., "Real-ESRGAN: Real-world Efficient Super Resolution Model via Risk Minimization"  has been trained on real-world content and also showed promising results compared to other models.
There are also models with mixed approaches, such as KXNetKim et al., "Densely Residual Memory Network for Image Super-Resolution" , or VDVAE-SRSoh et al., "VDVAE-SR: Video-to-Video Translation via Latent Space Modulation" available.
Furthermore, not all models, e.g., BSRDM____ are applicable for higher resolution input images with their provided open-source implementation, mainly because they are just trained and evaluated on smaller inputs as a proof-of-concept.
In addition, some proposed methods are just evaluated with low-resolution input images due to performance reasons.

In most cases, the evaluation focuses primarily on objective metrics such as SSIM, PSNR, or a few example images for demonstration purposes, which is for example the case for KXNetKim et al., "Densely Residual Memory Network for Image Super-Resolution" , BSRGANKim et al., "Image-to-Image Translation with Conditional Adversarial Networks for High Quality Image-to-Image Translation" , or Real-ESRGANAnwar et al., "Real-ESRGAN: Real-world Efficient Super Resolution Model via Risk Minimization" .
However, the complexity and generation of content using DNNs introduce new types of distortions, that the used image quality models cannot handle properly, because they have been developed with different distortions.
For pure performance reasons, it is clear, that PSNR or SSIM can be used for the evaluation to compare the generated image with the high-resolution version.
However, some of the models may still perform reasonably well even though they do not match perfectly the high-resolution reference image, considering that the introduced new content or artifacts may look appealing or real.
Objective quality models need re-training for such specific generated contents, as it is also shown for AI-generated images inHuang et al., "Learning to Evaluate Natural Image Quality" .
More recent no-reference image quality models may be applicable to evaluate the quality, e.g., DBCNNKim et al., "DBLSTM: Deep Bidirectional LSTM Networks for Image Super-Resolution" , HYPERIQA___________, Deimeq_______, or NIMA___________.
These image quality models are mostly based on DNNs combined with transfer learning and outperform for image compression and common distortions other state-of-the-art models.
Thus they may be able to handle and detect distortions of AI-generated content which will be covered in our evaluation.

To sum up, we identified three open points which we will be addressing in the following paper.
Firstly, there are only a few studies focusing on the comparison of several AI-based upscaling methods available.
Secondly, high resolution images are less often used for the evaluation.
And thirdly, the evaluation does usually not include human annotations for a wide range of images and modern objective models for AI-based artifacts.