
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}

%%%%%%%%%%%%%%%%%%% my packages %%%%%%%%%%%%%%%%%%% 
% Self Defined macro
\usepackage{graphicx}
\usepackage[ruled, lined, linesnumbered, commentsnumbered, longend]{algorithm2e}
\usepackage{subcaption}
% \usepackage{natbib}
% \setcitestyle{square,comma,numbers}
\bibliographystyle{plainnat}
\usepackage{makecell}
\usepackage{diagbox}
\usepackage{soul}
\usepackage{amsmath}
\usepackage{outlines, wrapfig, lipsum, booktabs}
\usepackage{etoc}
\usepackage{multirow}
\usepackage{placeins}
\usepackage{enumitem}
\usepackage{amssymb}
\usepackage{amsthm}
% \DeclareMathOperator*{\argmax}{arg\,max}
% \DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{makecell}
\usepackage{dsfont}  % new
\usepackage{arydshln}  % new
\usepackage{xurl}

\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{statement}{Statement}
\newtheorem{example}{Example}
\newtheorem{notation}{Notation}

\newtheorem{remark}{Remark}


\newcommand{\slifinalblue}[1]{\textcolor{black}{#1}}  

\newcommand{\slirebuttalred}[1]{\textcolor{black}{#1}}   % red
 
\newcommand{\slirebuttalblue}[1]{\textcolor{black}{#1}}  % blue

% blue
\newcommand{\sliblue}[1]{\textcolor{black}{#1}}  
% red
\newcommand{\slired}[1]{\textcolor{black}{#1}}  % red
\usepackage{xargs} 
\usepackage{wrapfig}
% red
\newcommand{\colorr}[1]{\textcolor{black}{#1}}
% blue
\newcommand{\colorb}[1]{\textcolor{black}{#1}}

% orange
\newcommand{\cw}[1]{\textcolor{black}{#1}}

\title{Learning-Guided Rolling Horizon Optimization for Long-Horizon Flexible Job-Shop Scheduling}


% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Sirui Li, Wenbin Ouyang, Yining Ma \& Cathy Wu \\
MIT\\
\texttt{\{siruil,oywenbin,yiningma,cathywu\}@mit.edu}
}


\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle


\begin{abstract}

Long-horizon combinatorial optimization problems (COPs), such as the Flexible Job-Shop Scheduling Problem (FJSP), often involve complex, interdependent decisions over extended time frames, posing significant challenges for existing solvers. While Rolling Horizon Optimization (RHO) addresses this by decomposing problems into overlapping shorter-horizon subproblems, such overlap often involves redundant computations. In this paper, we present L-RHO, the first learning-guided RHO framework for COPs. L-RHO employs a neural network to intelligently fix variables that in hindsight did not need to be re-optimized, resulting in smaller and thus easier-to-solve subproblems. For FJSP, this means identifying operations with unchanged machine assignments between consecutive subproblems. Applied to FJSP, L-RHO accelerates RHO by up to 54\% while significantly improving solution quality, outperforming other heuristic and learning-based baselines. We also provide in-depth discussions and verify the desirable adaptability and generalization of L-RHO across numerous FJSP variates, distributions, online scenarios and benchmark instances. Moreover, we provide a theoretical analysis to elucidate the conditions under which learning is beneficial.

\end{abstract}

\section{Introduction}
\label{sec:introduction}

Enhancing the efficiency and scalability of \slirebuttalblue{solving} Combinatorial Optimization Problems (COPs) has been a central focus of both the Operations Research (OR)~\citep{schrijver2003combinatorial} and the emerging Neural Combinatorial Optimization (NCO) communities~\citep{bengio2021machine}. Numerous methods have been proposed to decompose large-scale problems into smaller, more tractable subproblems, with the majority focusing on spatial or structural decomposition of decision variables. Despite their success,  these methods often face limitations in addressing the unique temporal challenges of \emph{long-horizon} COPs - frequently encountered by industrial practitioners - which involve optimizing complex decisions over extended time horizons. Such unique challenges, coupled with the inherent NP-hardness and large-scale nature of the problems, call for advanced \emph{temporal decomposition} strategies~\citep{du1998handbook, hentenryck2006online, yang2013metaheuristics}.

Building on successes in control for complex dynamical systems~\citep{welikala2021event, franze2015receding, castaman2021receding}, Rolling Horizon Optimization (RHO) has emerged as a natural temporal decomposition technique for long-horizon COPs~\citep{glomb2022rolling}. RHO breaks the problem into overlapping subproblems with shorter planning horizons rolling forward over time, allowing for much better scalability. The key to RHO is its temporal overlap, which enhances decision-making at the boundaries of consecutive subproblems, mitigating myopic decisions and facilitating modelling interdependencies across the temporal dimension~\citep{sethi1991theory, mattingley2011receding}. However, such overlaps often lead to redundant computations that reduce the efficiency especially when only a small subset of variables needs re-optimization. This presents an opportunity to accelerate RHO by identifying such redundancies, an approach that, to our knowledge, has not yet been explored in the combinatorial optimization context.

To this end, this work introduces a novel learning-based RHO framework, termed L-RHO, designed to accelerate RHO for long-horizon COPs by identifying overlapping decision variables that do not need to be re-optimized between consecutive iterations. We demonstrate the effectiveness of our L-RHO on the long-horizon Flexible Job-Shop Scheduling Problem (FJSP), a proof-of-concept example with numerous applications in manufacturing~\citep{liu2017hybrid}, healthcare~\citep{addis2016operating}, transportation~\citep{zhang2012genetic}, and logistics~\citep{xie2019review}. Long-horizon FJSPs represent a complex class of COPs involving interdependent assignment and scheduling decisions over extended time horizons, significantly increasing the difficulty compared to the basic JSP variant. The core of L-RHO is to intelligently fix operations assigned to the same machine across successive RHO iterations. By employing a customized network with tailored contextual embeddings, L-RHO learns to imitate a look-ahead oracle, effectively reducing the size of subproblems, significantly improving solve times, and delivering notable improvements in solution quality.

Moreover, to gain deeper insights into the research question - \emph{``To what extent can machine learning accelerate RHO in the context of long-horizon COPs such as FJSP?"} - we validate and discuss our framework, L-RHO, through both computational experiments and theoretical analysis. Empirically, we show that \colorr{L-RHO reduces RHO solve times by up to 54\% and improves solution quality by up to 21\% compared to various heuristic and learning-based baselines (with and without decomposition), across a range of FJSP settings and distributions}. \colorr{Moreover, we further discuss the unique potential of our L-RHO in online FJSP settings, where FJSPs operate with limited initial information and require ongoing but more efficient re-optimization as new orders arrive with dynamic environments}. Theoretically, we formalize analytical criteria under which L-RHO outperforms the heuristic baselines; the analysis incorporates factors including the data distribution and the False Positive (FP) and False Negative (FN) Rates of the learning method, closely aligning with the empirical results. 

Our contributions are fourfold:
% \begin{itemize}
% \item 
(1) \slirebuttalblue{We introduce L-RHO, the first learning-guided rolling-horizon method for COPs; by learning which overlapping solutions in consecutive RHO iterations do not require re-optimization, it significantly reduces RHO subproblem sizes and solve times.}
% \item 
(2) \slirebuttalblue{Validated on long-horizon FJSP, L-RHO effectively accelerates RHO by up to 54\% while largely improving the solution quality.} 
% \item 
(3) \slirebuttalblue{Extensive experiments show that L-RHO consistently outperforms various state-of-the-art heuristic and learning-based baselines (w/ or w/o decomposition)}, and demonstrates robust effectiveness across diverse FJSP settings, distributions, and online scenarios.
% \item 
(4) We further provide a principled probabilistic analysis to identify conditions where L-RHO surpasses heuristic RHO baselines, offering theoretical justifications that are aligned with the empirical observations.
% \end{itemize}


\section{Related Works}
\label{sec:related_work}

\textbf{Decomposition for COPs.} Despite advances in traditional solvers~\citep{pisinger2019large,vidal2022hybrid,xiong2022survey}, learning-guided solvers~\citep{labassi2022learning, scavuzzo2022learning, wang2023linsatnet,li2024learning} and neural solvers~\citep{kool2018attention,ma2024learning,zhang2024let,ye2024deepaco} for COPs, scalability and adaptability to real-world complexities remain challenging. Various decomposition strategies have been explored by OR community, such as variable partitioning~\citep{helsgaun2017extension}, adaptive randomized decomposition (ARD)~\citep{pacino2011large}, and sub-problem constraint relaxation~\citep{pisinger2007using}. More recently, machine learning has been exploited to guide the decomposition by selecting subproblems~\citep{li2021learning, zong2022rbg, huang2022anytime} or to auto-regressively solve decomposed subproblems~\citep{wang2021multiobjective,ye2024glop,luo2024self}, leading to notable improvements. However, they primarily emphasize \emph{spatial} or \emph{problem-structural} decomposition (e.g., for routing problems), which is not suitable for long-horizon time-structured COPs involving complex, interdependent decision variables and constraints spanning extended time horizons. This highlights the need for effective \emph{temporal} decomposition. We note such temporal decomposition can be orthogonal to other existing ones, and future work could combine them to improve scalability and flexibility.

\textbf{RHO for Long-horizon COPs.}
RHO is a temporal decomposition method originating from Model Predictive Control (MPC)~\citep{garcia1989model}. It improves the scalability by dividing the time-structured problem into overlapping subproblems. While such overlap improves boundary decision-making, it can introduce redundant computations. Thus, many control and robotics studies leverage previous decisions to reduce the computations of the current subproblem. This is done, e.g., through hand-crafted methods, such as recording repeat computations~\citep{hespanhol2019structure} or tightening primal and dual bounds~\citep{marcucci2020warm}, and learning-based models that predict active constraints~\citep{bertsimas2022online} or solutions for discrete variables~\citep{cauligi2021coco}. However, these methods are not tailored for long-horizon COPs.
Recently, RHO has been initially adapted for long-horizon COPs, with wide applications such as scheduling~\citep{bischi2019rolling}, lot-sizing problems~\citep{glomb2022rolling}, railway platform scheduling~\citep{lu2022train}, stochastic supply chain management~\citep{fattahi2022data}, and pickup and delivery with time windows~\citep{kim2023rolling}. However, they often overlook the redundancies, and none of them have integrated machine learning to address this issue, leaving a gap in accelerating RHO for COPs.



\textbf{FJSPs.} 
FJSP is a complex class of COPs that involve interdependent assignment and scheduling decisions over extended time horizons, making it more challenging than the basic JSP, which only addresses scheduling~\citep{dauzere2023flexible}. Recently, learning-based solvers have shown power to outperform traditional methods such as Constraint Programming~\citep{cpsatlp} and genetic algorithms~\citep{li2016effective}; for example, see~\cite{zhang2020learning, zhang2024learning, zhang2024deep} for JSP and~\cite{wang2023learning, song2022flexible} for FJSP. However, they are typically limited to small-scale instances (fewer than 200 operations) and struggle to scale to real-world, long-horizon scenarios. Although decomposition (e.g., the above ARD) has been explored for FJSP, their efficiency remains constrained. Moreover, these methods are offline, requiring full problem information, limiting their use in online setting. While some works have studied dynamic, online FJSP~\cite {luo2021real, lei2023large}, they are still restricted to small-scale experiments. Consequently, large research gaps remain in developing more scalable and flexible decomposition methods for long-horizon (and online) FJSP.


\section{Preliminaries}
\label{sec:preliminary}
\textbf{FJSP Definition.} 
\label{sec:preliminary_fjsp}
 A FJSP instance consists of a set $\mathcal{T}$ of jobs, a set $\mathcal{M}$ of machines, and a set $\mathcal{O}$ of operations. Each job $j \in \mathcal{T}$ consists of a set of $n_j$ operations $\{O_{j, k}\}_{k=1}^{n_j} \subseteq \mathcal{O}$ required to be processed in a precedence order $O_{j, 1}\! \rightarrow\! O_{j, 2} \!\rightarrow\! ... \!\rightarrow\! O_{j, n_j}$. Each operation $O_{j, k}$ can be processed by any of the compatible machines $\mathcal{M}_{j, k} \subseteq \mathcal{M}$; the process duration of operation $O_{j, k}$ by \slirebuttalblue{machine $\bar{m} \in \mathcal{M}_{j, k}$ is denoted by $p_{j, k}^{\bar{m}}$}. A solution to the FJSP, denoted as $\Pi = (m, \pi)$, consists of (i) an \textbf{assignment} $m: \mathcal{O} \rightarrow \mathcal{M}$ that represents the machine assignment of each operation, with $m(O_{j, k}) \in \mathcal{M}_{j, k}$ for all $j, k$, and (ii) a \textbf{schedule} $\pi: \{O_{j, k}\;|\;\forall j, k\} \rightarrow \mathbb{N}$ that represents the process start time of each operation $O_{j, k}$ as $\pi(O_{j,k})$; with the process duration as $p_{j, k}^{m(O_{j, k})}$, the process end time of the corresponding operation is $\pi_t(O_{j,k}) := \pi(O_{j, k}) + p_{j, k}^{m(O_{j, k})}$. 
%
Many FJSP objectives exist in the literature, and we consider testing our method on a variety of objectives including makespan~\citep{xie2019review}, total start delays~\citep{pham2008surgical, lee2014reducing}, and end delays~\citep{zhou2009minimizing, andrade2020scheduling}. Formally, the \textit{makespan} objective can be expressed as $\max_{O_{j, k}}\pi_t(O_{j, k})$. For the delay-based objectives, let each operation $O_{j, k}$ be further associated with (i) a release time $s_{j, k}$ with a constraint $\pi(O_{j,k}) \geq s_{j, k}$ such that the operation can only be processed after the release time, and (ii) a target end time $t_{j, k}$; both respect the operations' precedence orders within the same job, that is, $\forall$ job $j$ and operations $k_1 < k_2$, we assume $s_{j, k_1} \leq s_{j, k_2}$ and $t_{j, k_1} \leq t_{j, k_2}$. The \textit{total start delay objective} is expressed as $\sum_{O_{j, k}} \pi(O_{j,k}) - s_{j, k}$, and the \textit{total end delay objective} as $\sum_{O_{j, k}} \max(\pi_t(O_{j,k}) - t_{j, k}, 0)$. Appendix~\ref{appendix_sec:notation} provides a detailed list of notations.

\begin{figure}[!t]
     \centering
     \includegraphics[width=0.85\textwidth]{figures/pipeline.png}
     \caption{\sliblue{\textbf{One iteration of our L-RHO pipeline.} (a) Construct a subproblem $P_r$ with $H$ non-executed operations in $\mathcal{O}_{plan,r}$. This includes a set of overlapping operations $ \mathcal{O}_{overlap,r} \subseteq \mathcal{O}_{plan, r}$, each associated with a solution from the previous iteration given by the assignment $m_{r-1}$ and the schedule $\pi_{r-1}$. (b) Identify operations $\mathcal{O}_{fix,r} \subseteq \mathcal{O}_{overlap,r}$ that in hindsight, their assignments did not need to be re-optimized; \textit{during training}, a Look-Ahead Oracle determines $\mathcal{O}_{fix,r}$ by solving $P_r$ for $Q$ times; \textit{During inference}, our learned neural network selects it. (c) Create a restricted subproblem $\hat{P}_r$ by fixing the machine assignments for  $\mathcal{O}_{fix,r}$. (d) Feed $\hat{P}_r$ to a subsolver, solve for up to $T$ seconds, and (e) Obtain an updated solution $\Pi_r = (m_r, \pi_r)$. (f) Execute a subset of $S$ operations in $\mathcal{O}_{exec, r} \subseteq \mathcal{O}_{plan, r}$ based on the solution $\Pi_r$. We then repeat steps (a)-(f).}}
    \label{fig:rho_pipeline}
\end{figure}

\textbf{RHO for Long-Horizon FJSP.}
\label{sec:preliminary_rho}
The temporal structure of FJSP enables the use of RHO to decompose a long-horizon FJSP into a sequence of shorter-horizon FJSP subproblems. 

Our RHO utilizes a planning window size $H$ but executes only a step size $S$ with $S \leq H$. \slirebuttalblue{Each sub-problem is limited to solving for $T$ seconds.} Given the long-horizon FJSP instance, we first sort the operations $\mathcal{O}$ into $\{O^{(1)}, ..., O^{(|\mathcal{O}|)}\}$ \sliblue{based on the precedence order within each job or the associated release time}. These operations are then divided into overlapping subproblems. Specifically, the $r^{th}$ RHO iteration considers a FJSP subproblem $P_r$ given by a subset of operations $\mathcal{O}_{plan, r}$, consisting of the next $H$ non-executed operations according to the sorted RHO sequence order; we introduce additional constraints in $P_r$ to handle boundary conditions -- for example, each operation in $\mathcal{O}_{plan, r}$ should start after all previously executed operations from the same job.
After solving $P_r$ under the time limit $T$, we obtain the subproblem solution $\Pi_r = (m_r, \pi_{r})$. 
We then execute the first $S$ operations with the earliest \textit{process start time $\pi_{r}(O)$} following the solution $\Pi_r$, while deferring the remaining $H-S$ operations for replanning in future iterations. The procedure is then repeated until we solve the full FJSP $P$, resulting in $|\mathcal{O}| / S$ subproblems. A detailed algorithm can be found in Appendix~\ref{appendix_sec:l2rho_alg}.
RHO is also well-suited for online settings with limited visibility, solving early operations while deferring the rest until future batches in the next iteration (\colorr{see Sec.~\ref{sec:experiment_additional_result}}).

\section{Learning-Guided Rolling Horizon Optimization (L-RHO)}
\label{sec:l_rho}



We now introduce our learning framework, L-RHO, that accelerates RHO for long-horizon FJSP. We refer to the original RHO, RHO for training data collection, and RHO for inference as $RHO_0$, $RHO_{data}$, and $RHO_{test}$.
In the standard $RHO_0$, each consecutive iterations $r$-$1$ and $r$ share \textbf{overlapping operations} $\mathcal{O}_{overlap, r} = \mathcal{O}_{plan, r}\cap \mathcal{O}_{plan, r-1}$.  While new operations $\mathcal{O}_{new, r} = \mathcal{O}_{plan, r} \setminus \mathcal{O}_{plan, r-1}$ in subproblem $P_r$ may change the solution of the overlap parts $\mathcal{O}_{overlap, r}$, we find \textbf{two key observations} that, for various FJSP distributions evaluated in Sec.~\ref{sec:experiment}:  
\begin{enumerate}[leftmargin=0.6cm, topsep=0pt,parsep=-2pt,partopsep=0pt]
\item[(1)] A significant subset of the \cw{overlapping} operations retain the same machine assignment between the consecutive optimizations. Formally, the \cw{\textbf{shared operations} are} given by $\mathcal{O}^*_{fix, r} = \{O \in \mathcal{O}_{overlap, r}\;|\; m_r(O) = m_{r-1}(O)\}$, where $\Pi_r = (m_r, \pi_{r})$ and $\Pi_{r-1} = (m_{r-1}, \pi_{r-1})$ are the solutions of the unrestricted subproblem $P_r$ and $P_{r-1}$ in $RHO_0$.
\item[(2)] Let $\hat{P}^*_r$ be the restricted subproblem where we leverage the solution of the $r-1^{th}$ RHO iteration and fix the machine assignments of the \cw{shared} operations $\mathcal{O}^*_{fix, r}$. The solve time of $\hat{P}^*_r$ is significantly reduced from that of the unrestricted subproblem $P_r$. 
\end{enumerate}

\textbf{Assignment-Based Subproblem Restriction.} 
\label{sec:l_rho_assignment}
Based on these observations, we propose restricting the subproblem by fixing machine assignments for a set of operations $\mathcal{O}_{fix, r} \subseteq \mathcal{O}_{overlap, r}$, selected through oracle, learning, or heuristic methods. This results in the restricted subproblem $\hat{P}_r$, \colorr{with a formal formulation provided in Appendix~\ref{appendix_sec:fjsp_formulation}}. Notably, this approach can be easily extended to other subproblem restriction methods, which we leave for future work.

\textbf{Our L-RHO Pipeline.} We design the L-RHO pipeline (which is shown in Fig.~\ref{fig:rho_pipeline}) as follows: First, we collect training data via a Look-Ahead Oracle by solving the unrestricted subproblem $P_r$ and identifying $\mathcal{O}^*_{fix, r}$ as the set of overlapping operations with the same assignments in $m_r$ and $m_{r-1}$. A neural network $f_\theta$ is then trained with such collected labels. During inference, $f_\theta$ predicts a subset $\mathcal{O}_{fix, r}$, from which we form the assignment-based restricted subproblem $\hat{P}_r$. This largly speeds up the inference time optimization by replacing the expensive $P_r$ with the easier-to-solve $\hat{P}_r$. 

\textbf{Training Data Collection ($\mathbf{RHO_{data}}$).}
\label{sec:l_rho_data_collection}
At each iteration $r$, we solve the unrestricted subproblem $P_r$ for $Q \geq 1$ times under a time limit, resulting in $Q$ possibly different solutions $\{\Pi^q_{r} = (m_r^q, \pi_{r}^q)\}_{q=1}^{Q}$.
We then use the highest overlapping machine assignment as the training labels. That is, let $q^* = \argmax_{q \in \{1, ..., Q\}} \sum_{O' \in \mathcal{O}_{overlap, r}} y^q_{O'}$, with $y^q_{O'} = \mathds{1}_{m^{q}_r(O') = m_{r-1}(O')}.$ We set the training labels as $y^*_O = y^{q^*}_O$ for each operation $O \in \mathcal{O}_{overlap, r}$.
\slirebuttalblue{Intuitively, the solve time of FJSP subproblem reduces when more assignemnts are fixed.} Empirically, we find the labels $\{y^*_O\}_{O \in \mathcal{O}_{overlap, r}}$ \slirebuttalblue{not only lead to short solve times but also high solution quality}. We then obtain the set $\mathcal{O}^*_{fix, r} = \{O \in \mathcal{O}_{overlap, r}\;|\;y^*_O = 1\}$ and construct the assignment-based restricted subproblem $\hat{P}^*_r$ accordingly. \sliblue{Fig.~\ref{fig:rho_pipeline} (b) top} illustrates the data collection procedure $RHO_{data}$. Comparing with $RHO_0$ that solves one unrestricted $P_r$ at each iteration, $RHO_{data}$ solves $P_r$ for $Q$ times and the restricted $\hat{P}_r$ one time, where $Q$ trades-off data collection efficiency and the training label quality.


\textbf{Input Features.}
\label{sec:l_rho_input_feature}
The state $\mathbf{s}_r$ at each RHO iteration $r$ consists of both the current FJSP subproblem $P_r$ and the previous solution $\Pi_{r-1}=(m_{r-1}, \pi_{r-1})$. We design a rich set of input features, capturing FJSP state details for overlapping operations $\mathcal{O}_{overlap, r}$, new operations $\mathcal{O}_{new, r}$, and machines $\mathcal{T}$. For $\mathcal{O}_{overlap, r}$ and $\mathcal{T}$, we further design features to capture the previous solution's information, including previous assignment, duration and end time (see Appendix~\ref{appendix_sec:input_feature} for details). 


\begin{wrapfigure}{r}{0.46\textwidth}
  \centering
  \vspace{-15pt}
  \includegraphics[width=0.95\linewidth]{figures/MLP_arch_small.png}
  \caption{\slirebuttalblue{\textbf{Our neural architecture $f_\theta$} to predict the probability of whether each overlapping operation should fix the assignment.}}
  \label{fig:main_architecture}
  \vspace{-10pt}
\end{wrapfigure}

\textbf{Neural Architecture.}
\label{sec:l_rho_architecture}
Our neural network $f_\theta$ \slirebuttalblue{predicts the probability of whether each overlapping operation $O \in \mathcal{O}_{overlap, r}$ should be fixed at each state $\mathbf{s}_r$. It consists of three parts: (1) \textbf{Input Embedding}: generate embeddings for each operation $\mathcal{O}_{overlap, r}\cup \mathcal{O}_{new, r}$ and each machine $\mathcal{M}$, with separate MLPs. (2) \textbf{Machine/Operation Concatenation}: concatenate the hidden feature of each overlapping operation $O \in \mathcal{O}_{overlap, r}$ with both the hidden feature of the previously assigned machine $m_{r-1}(O) \in  \mathcal{M}$, and a global feature obtained by a mean pooling. 
The concatenated features then pass through another MLP. 
(3) \textbf{Output}: each overlapping operation $\mathcal{O}_{overlap, r}$ is passed through a final MLP layer to output the probability prediction. Notably, the purpose of (2) is to augment each operation with both local information from the previously assigned machine, as well as global information from all entities, which include overlapping operations, new operations, and the machines.
The illustration of $f_\theta$ is depicted in Fig.~\ref{fig:main_architecture}. The current simple architecture shows strong performance, and our preliminary comparisons with advanced architectures, such as Multi-head Attention, show no significant improvement (see Appendix~\ref{appendix_sec:comp_attention}); we leave the exploration of more advanced designs in future work}.


\textbf{Loss Function.}
\label{sec:l_rho_loss}
\colorr{We use weighted binary cross-entropy loss where $w_{pos} > 0$ scales positive labels.}
\begin{equation}
l(f_\theta(\mathbf{s}_r; O), y_O) = -w_{pos} [y_O \log f_\theta(\mathbf{s}_r; O) + (1 - y_O) \log (1-f_\theta(\mathbf{s}_r; O))] 
\label{eq:loss}
\end{equation}
\slirebuttalblue{The weight $w_{pos}$ balances False Positive (FPR) and False Negative Rate (FNR). A lower $w_{pos}$ emphasizes avoiding predicting False Positives, i.e., cases where the network incorrectly fixes changing operations, which can improve the objective but may increase solve time (see our analysis in Sec.~\ref{sec:analysis}).}

\textbf{Inference ($\mathbf{RHO_{test}}$).} 
\label{sec:l_rho_inference}
The inference is illustrated in \sliblue{Fig.~\ref{fig:rho_pipeline} (b) bottom}, where we use the network $f_\theta$ to predict $\mathcal{O}_{fix, r}$: for each operation $O \in \mathcal{O}_{overlap, r}$, we predict $\tilde{y}_O = \mathds{1}_{f_\theta(\mathbf{s_r}; O) \geq 0.5}$, which results in the fixed operation set $\mathcal{O}_{fix, r} = \{O \in \mathcal{O}_{overlap, r}\;|\;\tilde{y}_O = 1\}$ and the associated assignment-based restricted subproblem $\hat{P}_r$ solved at RHO iteration $r$. By replacing the unrestricted $P_r$ with the restricted $\hat{P}_r$, the computation time can be greatly reduced in comparison with $RHO_0$. 


\section{Experiment}
\label{sec:experiment}
\sliblue{In Sec.~\ref{sec:experiment_offline}, we evaluate L-RHO in a standard offline setting, comparing it to various baselines for long-horizon FJSP.} \sliblue{Next, in Sec.~\ref{sec:experiment_additional_result}, we dive into detailed analysis of L-RHO under different FJSP variants including online settings.} \slirebuttalblue{We provide additional experimental results in Appendix~\ref{appendix_sec:additional_results}, including a deep dive on the architecture design and evaluation on a real-world dataset.} We aim to answer: (1) To what extent does L-RHO improve upon competitive offline baseline methods and RHO variants? (2) Can L-RHO adapt to different FJSP distributions and objectives? Moreover, a unique benefit of RHO is its adaptability to online settings with limited visibility. As a step toward realistic online settings, we then study (3) Is L-RHO robust under \sliblue{noisy observation of process durations? (4) is L-RHO reliable under machine breakdowns?} 

\textbf{FJSP Data Distribution and Solver.}
We generate synthetic large-scale FJSP instances following common procedure in~\citep{behnke2012test},  characterizes by $(|\mathcal{M}|, |\mathcal{T}|, n)$, where each job $j$ has $|\{\mathcal{O}_{j, k}\}_{k=1}^{n_j}| = n$ operations. The total number of operations $|\mathcal{O}|$ ranges from $600$ to $2000$. \colorr{Notably, the problem horizon in this work (e.g., $600$-$2000$) is \textbf{considerably larger} than those in previous studies~\citep{wang2023flexible, behnke2012test, dauzere1997integrated, hurink1994tabu, brandimarte1993routing}, which typically consider fewer than $500$ operations. Following the conventions~\citep{zhang2024deep, zhang2024learning}, we employ the competitive constraint programming (CP) solver OR-Tools CP-SAT~\citep{cpsatlp} to solve FJSP, with its detailed CP formulation provided in Appendix~\ref{appendix_sec:fjsp_formulation}. We consider \sliblue{makespan objective in Sec.~\ref{sec:experiment_offline}, and delay-based objectives in Sec.~\ref{sec:experiment_additional_result} (start and end delay)} for comprehensive evaluation.  More details are in Appendix~\ref{appendix_sec:instance_dist}.}

\textbf{Proposed Method (L-RHO) Setup.} We provide descriptions of the training set up in Appendix~\ref{appendix_sec:architecture}, and the details on the choices of RHO parameters in Appendix~\ref{appendix_sec:rho_param_search} and \ref{appendix:same_rho_param}.

\textbf{Baselines.}\setul{1pt}{.4pt} 
We include a range of traditional and learning-based baselines, with and without decomposition for comprehensive evaluation (see Appendix~\ref{appendix_sec:offline} for more details about baselines):
\begin{enumerate}[leftmargin=0.6cm, topsep=-1pt,parsep=-2pt,partopsep=0pt]
%%%%%%
\item[(1)] \textit{Traditional solver w/o decomposition} - We include the widely used benchmark solver \ul{\textbf{CP-SAT}}~\citep{ortools_routing} and \ul{\textbf{Genetic Algorithm (GA)}}~\citep{li2016effective}.
%%%%%%
\item[(2)] \textit{Learning-based solver w/o decomposition} - We compare with the state-of-the-art DRL constructive method for FJSP~\citep{wang2023flexible}, \slirebuttalblue{which we denote as \ul{\textbf{DRL-20K}} (using 20,000 training instances as in the original paper). We further compare with two recent learinng methods: \ul{\textbf{DRL-Echeverria}}~\citep{echeverria2023solving} and \ul{\textbf{DRL-Ho}}~\citep{ho2023residual}.}
%%%%%%
\item[(3)] \textit{Traditional solver w/ decomposition} - We include the time decomposition method \ul{\textbf{ARD-LNS (Time-based)}} and machine decomposition method \ul{\textbf{ARD-LNS (Machine-based)}} in~\citep{pacino2011large}, which decompose large neighborhood search (LNS) by randomly fixing temporal intervals or machine subsets as subproblems, respectively.
%%%%%%
\item[(4)] \textit{Learning-guided solver w/ decomposition} - While learning-guided decomposition exist, e.g, for routing problems~\citep{li2021learning}, they are not adaptable to long-horizon COPs like FJSP. We thus opt to include an \ul{\textbf{Oralcle-LNS (Time-based)}} baseline to estimate the upper bound of enhancing ARD-LNS. It samples $K$ subproblems and selects the best one by looking ahead.
%%%%%%
\item[(5)] \textit{RHO decomposition} - We include \textbf{Default RHO}, where each iteration solves an unrestricted FJSP subproblem $P_r$ without fixing any variables, and \textbf{Warm-Start RHO}, where previous machine assignments of overlapping operations $\{m_{r-1}(O)\;\forall \; O \in \mathcal{O}_{overlap, r}\}$ are provided as hints (not fixed) to CP-SAT as a warm start, akin to~\citep{hespanhol2019structure} in control systems.
\end{enumerate}

\textbf{Evaluation Metric.} We compare the objective and solve time in Table~\ref{tab:offline}. Objective improvement (OI\%) and time improvement (TI\%) over Default RHO are reported in Table~\ref{tab:detailed_result}. 
% Let $obj_0$ and $t_0$ denote the objective and solve time of Default.
For a solver with an objective $obj$ and a solve time $t$, its OI and TI are calculated as $(obj_0 - obj) / obj_0 \times 100\%$ and $(t_0 - t) / t_0 \times 100\%$, respectively, where negative values indicate degradation.

\begin{table}[!t]
\caption{\sliblue{Offline FJSP under Makespan Objective. Each column corresponds to a different FJSP size given by the format: total number of operations, followed by a tuple of $($number of machines $|\mathcal{M}|$, jobs $|\mathcal{T}|$, and operations per job $n$).
L-RHO outperforms all types of baselines.
}}
\centering
\scalebox{0.62}{
\begin{tabular}{lcccccccc}
\toprule
 & \multicolumn{2}{c}{\textbf{600} (10, 20, 30)} & \multicolumn{2}{c}{\textbf{800} (10, 20, 40)} & \multicolumn{2}{c}{\textbf{1200} (10, 20, 60)} & \multicolumn{2}{c}{\textbf{2000} (10, 20, 100), \textbf{Transfer}} \\
\cmidrule(r){2-3}  \cmidrule(r){4-5}  \cmidrule(r){6-7}
\cmidrule(r){8-9}
& Time (s) $\downarrow$ & Makespan $\downarrow$ & Time (s) $\downarrow$ & Makespan $\downarrow$ & Time (s) $\downarrow$ & Makespan $\downarrow$ & Time (s) $\downarrow$ & Makespan $\downarrow$ \\
\midrule
\slirebuttalblue{\textbf{CP-SAT (10 hours)}} & \slirebuttalblue{36000} & \slirebuttalblue{1583 $\pm$ 65} & \slirebuttalblue{36000} & \slirebuttalblue{2128 $\pm$ 75} & \slirebuttalblue{36000} & \slirebuttalblue{3206 $\pm$ 87} & \slirebuttalblue{36000} & \slirebuttalblue{18821 $\pm$ 1986}\\
\sliblue{\textbf{CP-SAT }} & 1800 & 2274 $\pm$ 147 & 1800 & 4017 $\pm$ 413 & 1800 & 10925 $\pm$ 1013 & 1800 & 39585 $\pm$ 2707\\
\sliblue{\textbf{GA}} & 1800 & \sliblue{3659 $\pm$ 87} & 1800 & \sliblue{5150 $\pm$ 92} & 1800 &  \sliblue{8086 $\pm$ 111} & 1800 & \sliblue{10406 $\pm$ 640} \\
\midrule
\textbf{ARD-LNS (Time-based)} & 300 & 2100 $\pm$ 269 & 400 & 3298 $\pm$ 365 & 600 & 5115 $\pm$ 558 & 1000 & 14258 $\pm$ 1522\\
\textbf{ARD-LNS (Machine-based)}  & 300 &  3974 $\pm$ 633 & 400 &  6594 $\pm$ 1227  & 600 &  12764 $\pm$ 4206  & 1000 &  52225 $\pm$ 1793 \\
\sliblue{\textbf{Oracle-LNS (Time-based)}} & 300 & \sliblue{1789 $\pm$ 104} & 400 & \sliblue{2663 $\pm$ 120} & 600 & \sliblue{4470 $\pm$ 151} & 1000 & \sliblue{7275 $\pm$ 785}\\
\midrule
\slirebuttalblue{\textbf{DRL-Echeverria, Greedy}} & \slirebuttalblue{84 $\pm$ 27} & \slirebuttalblue{2347 $\pm$ 189} & \slirebuttalblue{115 $\pm$ 32} & \slirebuttalblue{3105 $\pm$ 161} & \slirebuttalblue{105 $\pm$ 7} & \slirebuttalblue{4570 $\pm$ 218} & \slirebuttalblue{213 $\pm$ 10} &  \slirebuttalblue{7673 $\pm$ 356} \\
\slirebuttalblue{\textbf{DRL-Echeverria, Sampling}} & \slirebuttalblue{157 $\pm$ 8} & \slirebuttalblue{2351 $\pm$ 139} & \slirebuttalblue{217 $\pm$ 11} & \slirebuttalblue{3131 $\pm$ 165} & \slirebuttalblue{427 $\pm$ 20} & \slirebuttalblue{4657 $\pm$ 192} & \slirebuttalblue{603 $\pm$ 41} & \slirebuttalblue{7774 $\pm$ 271}\\
\slirebuttalblue{\textbf{DRL-Ho, Greedy}} & \slirebuttalblue{\textbf{4 $\pm$ 2}} & \slirebuttalblue{3030 $\pm$ 69} & \slirebuttalblue{\textbf{6 $\pm$ 4}} & \slirebuttalblue{4038 $\pm$ 87} & \slirebuttalblue{11 $\pm$ 6} & \slirebuttalblue{6045 $\pm$ 99} & \slirebuttalblue{22 $\pm$ 3} & \slirebuttalblue{10044 $\pm$ 115} \\
\slirebuttalblue{\textbf{DRL-Ho, Sampling}} & \slirebuttalblue{174 $\pm$ 1} & \slirebuttalblue{2907 $\pm$ 46} & \slirebuttalblue{168 $\pm$ 14} & \slirebuttalblue{3907 $\pm$ 56} & \slirebuttalblue{385 $\pm$ 12} & \slirebuttalblue{5870 $\pm$ 71} & \slirebuttalblue{517 $\pm$ 10} & \slirebuttalblue{9848 $\pm$ 92} \\
\textbf{DRL-20K, Greedy} & \color{gray}{\textbf{4 $\pm$ 0.02}} & 1628 $\pm$ 72 & \color{gray}{\textbf{6 $\pm$ 0.04}} & 2128 $\pm$ 80 & \color{gray}{\textbf{10 $\pm$ 0.1}} & 3141 $\pm$ 97 & \color{gray}{\textbf{16 $\pm$ 0.2}} & 5184 $\pm$ 114 \\
\textbf{DRL-20K, Sample 100} & 29 $\pm$ 0.3 & 1551 $\pm$ 60 & 47 $\pm$ 1 & 2048 $\pm$ 69 & 110 $\pm$ 3 & 3063 $\pm$ 81 & 302 $\pm$ 10 & 5082 $\pm$ 98 \\
\textbf{DRL-20K, Sample 500} & 146 $\pm$ 5 & 1537 $\pm$ 61 & 261 $\pm$ 8 & 2031 $\pm$ 68 & 597 $\pm$ 16 & 3045 $\pm$ 79 & 1738 $\pm$ 16 & 5062 $\pm$ 98 \\
\midrule
\slirebuttalblue{\textbf{Default RHO (Long)}} & \slirebuttalblue{599 $\pm$ 55} & \slirebuttalblue{1529 $\pm$ 58} & \slirebuttalblue{728 $\pm$ 98} & \slirebuttalblue{2044 $\pm$ 75} & \slirebuttalblue{1099 $\pm$ 108} & \slirebuttalblue{\textbf{3002 $\pm$ 87}} & \slirebuttalblue{2871 $\pm$ 244} & \slirebuttalblue{4994 $\pm$ 114}\\
\textbf{Default RHO} & 244 $\pm$ 21 & 1558 $\pm$ 73 & 348 $\pm$ 26 & 2103 $\pm$ 78 & 545 $\pm$ 36 & 3136 $\pm$ 91 & 862 $\pm$ 42 & 5207 $\pm$ 114 \\
\textbf{Warm Start RHO} & 203 $\pm$ 23 & 1521 $\pm$ 67 & 278 $\pm$ 22 & 2055 $\pm$ 75 & 420 $\pm$ 33 & 3081 $\pm$ 96 & 716 $\pm$ 41 & 5057 $\pm$ 106 \\
\\[-0.85em] \hdashline \\[-0.85em]
\textbf{L-RHO (450)} & \textbf{126 $\pm$ 19} & \textbf{1513 $\pm$ 70} & \textbf{160 $\pm$ 23} & \textbf{2015 $\pm$ 86} & \textbf{259 $\pm$ 37} & \textbf{3011 $\pm$ 106} & \textbf{473 $\pm$ 52} & \textbf{4982 $\pm$ 132} \\
\bottomrule
\end{tabular}
}
\label{tab:offline}
\end{table}
\subsection{Canonical Offline FJSP under Makespan Objective}
\label{sec:experiment_offline}

We consider the canonical offline FJSP with makespan as the objective, with horizons up to 2000 operations (significantly longer than literature), following a similar synthetic data distribution as in~\cite{wang2023flexible}. The number of jobs and machines are set to $20$ and $10$, respectively. For both L-RHO and DRL, we train separate models for $30$, $40$, and $60$ operations per job, testing each in its respective setting and transferring the 60 operations-per-job model to a large-scale test with 100 operations per job. Results are gathered in Table~\ref{tab:offline}. We highlight the following findings:

\textbf{Comparison with baseline solvers w/o decomposition.} L-RHO outperforms both traditional solvers (CP-SAT, GA) and the learning-based DRL solver in the standard (offline) FJSP setting. Specifically, (1)  L-RHO achieves the best objective, outperforming DRL and all heuristic baselines in both in-domain and zero-shot generalization to larger scales; \slirebuttalblue{(2) We find the performance of DRL-Echeverria and DRL-Ho poor; (3) Comparing with DRL-20K~\citep{wang2023flexible}, we see that} DRL Greedy is the fastest method but has a worse performance than Default RHO. (4) DRL Sampling improves its performance but significantly increases computational time, with DRL-20K (500 Samples) taking longer and performing worse than L-RHO. Additionally, the solve time of DRL heavily rely on batch-decoding and GPU availability, whereas our L-RHO has a competitive inference time even solely running on CPUs. \slirebuttalblue{(5) L-RHO requires significantly fewer training instances than DRL-20K, making it advantageous when obtaining FJSP instances is costly. }


\textbf{Comparison with baseline solvers w/ decomposition.} We first observe that, (1) for ARD-LNS, time-based decomposition outperforms the machine-based variant but still results in a worse makespan and longer solve time compared to Default RHO. This suggests that effective temporal decomposition is crucial for time-structured, long-horizon COPs. In contrast, (2) L-RHO significantly outperforms both LNS methods in terms of solving time and objective. Furthermore, 
(3) while Oracle-LNS improves performance by simulating learning-based decomposition, it still underperforms compared to Default RHO. This suggests that RHO is better suited for long-horizon FJSP, partly due to complex temporal dependencies as follows: \slired{LNS begins with a complete solution and refines it iteratively. However, the makespan objective only improves when the last operation on the critical path is included. This temporal delay in propagating local improvements contrasts with prior learning-based LNS methods for Mixed Integer Programming~\citep{huang2023searching} or Vehicle Routing~\citep{li2021learning}, where subproblem improvements directly impact the objective. In contrast, RHO builds the solution progressively, maintaining a tighter makespan by following the natural temporal order of operations.} Lastly, we note that L-RHO's temporal decomposition is orthogonal to other strategies and could be combined in future work to enhance scalability and flexibility.


\textbf{Discussion - RHO for online settings.} 
\slirebuttalblue{Unlike offline baselines (CP-SAT, GA, ARD, DRL) that require complete information, RHO constructs solutions progressively using only near-future information, making it suitable for online settings. Next, we explore FJSP variants, including observation noise and machine breakdowns, to evaluate the applicability of L-RHO to batch-online FJSP.} 

\begin{table}[!t]
\caption{Detailed Comparison of L-RHO with RHO variants under Start Time Delay Objective. We present the time and objective improvements (TI\%, OI\%) of RHO variants relative to Default RHO.
The best TI\% and OI\% are bolded. L-RHO significantly outperforms all baseline RHO variants.}
\label{tab:detailed_result}
\centering
\scalebox{0.645}{
\begin{tabular}{ccccccc}
\\[-0.65em] \toprule \\[-0.85em]
 & \multicolumn{2}{c}{\textbf{\slifinalblue{600}} (25, 25, \slifinalblue{24})}   & \multicolumn{2}{c}{\textbf{\slifinalblue{1050}} (35, 35, \slifinalblue{30})} & \multicolumn{2}{c}{\textbf{1600} (40, 40, 40)}    \\ \\[-0.85em]
\cmidrule(r){2-3}  \cmidrule(r){4-5}  \cmidrule(r){6-7}
& \textbf{TI \%$\uparrow$}    & \textbf{OI \%$\uparrow$}     & \textbf{TI \%$\uparrow$}       & \textbf{OI \%$\uparrow$}     & \textbf{TI \%$\uparrow$}       & \textbf{OI \%$\uparrow$} \\[-0.85em]  \\ \hline \\[-0.85em]
\textbf{Default RHO}           &  \begin{tabular}[c]{@{}c@{}}946.9s $\pm$ 31.6s\\ (0.0\% $\pm$ 0.0\%)\end{tabular} & \begin{tabular}[c]{@{}c@{}}1790.5 $\pm$ 145.3\\ (0.0\% $\pm$ 0.0\%)\end{tabular}     & \begin{tabular}[c]{@{}c@{}}1119.86s $\pm$ 35.5s\\ (0.0\% $\pm$ 0.0\%)\end{tabular} & \begin{tabular}[c]{@{}c@{}}2960.4 $\pm$ 215.7\\ (0.0\% $\pm$ 0.0\%)\end{tabular} & \begin{tabular}[c]{@{}c@{}}2349.3s $\pm$ 111.7s\\ (0.0\% $\pm$ 0.0\%)\end{tabular} & \begin{tabular}[c]{@{}c@{}}4148.6 $\pm$ 356.8\\ (0.0\% $\pm$ 0.0\%)\end{tabular}  \\ \\[-0.85em]
\textbf{Warm Start RHO}    & 38.6\% $\pm$ 1.0\%                                                              & -7.5\% $\pm$ 2.8\%                                                                    & -12.9\% $\pm$ 1.6\%                                                         & 11.2\% $\pm$ 2.7\%                                                      & 5.2\% $\pm$ 2.4\%                                                               & 6.8\% $\pm$ 4.8\%                                                                 \\ \\[-0.85em]
\textbf{First 20\%}    & 26.1\% $\pm$ 1.3\%                                                              & 2.9\% $\pm$ 2.5\%                                                                     & 10.2\% $\pm$ 1.7\%                                                               & -30.5\% $\pm$ 10.7\%                                                            & 31.0\% $\pm$ 2.4\%                                                              & -94.1\% $\pm$ 24.3\%                                                          \\ \\[-0.85em]
\textbf{First 30\%}    &33.6\% $\pm$ 1.3\%                                                              & -7.0\% $\pm$ 2.5\%                                                                    & 13.2\% $\pm$ 1.7\%                                                               & -48.9\% $\pm$ 7.2\%                                                             & 31.7\% $\pm$ 2.1\%                                                              & -129.4\% $\pm$ 19.1\%                                                                    \\ \\[-0.85em]
\textbf{First 40\%}    & 34.8\% $\pm$ 1.3\%                                                              & -32.3\% $\pm$ 3.7\%                                                                   & 14.1\% $\pm$ 2.1\%                                                               & -100.4\% $\pm$ 8.7\%                                                            & 34.7\% $\pm$ 3.0\%                                                              & -274.7\% $\pm$ 28.1\%                                                   \\ \\[-0.85em]
% \textbf{Fix first 50\%}    & 51.3\% $\pm$ 1.0\%                                                              & -129.7\% $\pm$ 8.0\%                                                                  & 32.9\% $\pm$ 2.0\%                                                               & -244.2\% $\pm$ 14.8\%                                                           & \textbf{49.7\% $\pm$ 2.5}\%                                                              & -535.6\% $\pm$ 40.8\%                                                                   \\ \\[-0.85em]
\textbf{Random 10\%}       & 23.0\% $\pm$ 1.3\%                                                        & -11.9\% $\pm$ 2.5\%                                  & -15.5\% $\pm$ 1.7\%                                                        & -12.9\% $\pm$ 3.4\%                                                    & 10.0\% $\pm$ 3.0\%                                                              & -55.2\% $\pm$ 9.6\%                                                            \\ \\[-0.85em]
\textbf{Random 20\%}       & 23.8\% $\pm$ 1.7\%                                                              & -27.6\% $\pm$ 3.4\%                                                                   & -2.0\% $\pm$ 2.6\%                                                               & -86.1\% $\pm$ 7.9\%                                                             & 10.2\% $\pm$ 3.5\%                                                              & -115.6\% $\pm$ 14.5\%                                                          \\ \\[-0.85em]
\textbf{L-RHO (Ours)}         & \textbf{53.0\% $\pm$ 1.0\%}                                                     & \textbf{16.0\% $\pm$ 1.9\%}                                                           & \textbf{35.1\% $\pm$ 1.3\%}                                                      & \textbf{21.0\% $\pm$ 2.4\%}                                                     & 47.3\% $\pm$ 2.2\%                                                     & \textbf{13.1\% $\pm$ 4.4\%}                                                               \\ \\[-0.85em]
\bottomrule
\end{tabular}
}
\end{table}

\subsection{Detailed Comparison with RHO Baselines Under Different FJSP Variants}
\label{sec:experiment_additional_result}

\sliblue{We now benchmark L-RHO against diverse RHO baselines across FJSP variants. We evaluate objectives such as makespan, start delay, and end delay, while also testing its adaptability under higher system congestion, observation noise, and machine breakdowns to simulate real-world dynamics.}

We include two more RHO baselines, \sliblue{following the $RHO_{test}$ procedure but obtaining the fixed operations} $\mathcal{O}_{fix, r}$ with the following heuristics: \textbf{(a) Random $\mathbf{\sigma_R \in [0, 1]}$}:  $\mathcal{O}_{fix, r}$ is obtained by selecting each operation in $\mathcal{O}_{overlap, r}$ with a probability $\sigma_R$ uniformly at random, \textbf{(b) First $\mathbf{\sigma_F \in [0, 1]}$}: $\mathcal{O}_{fix, r}$ is obtained as the first $\sigma_F$ fraction of operations in $\mathcal{O}_{overlap, r}$ with the earliest RHO sequence order based on the precedence order (for makespan) or release time (for delay-based objectives). 

\textbf{New Objective: Start Delay.} In Table~\ref{tab:detailed_result}, under the new start delay objective, our L-RHO consistently outperforms all RHO variants in both solve time and objective across time horizons. \colorr{Notably, it achieves a 35\% - 53\% speed up from Default RHO with a further 13\%-21\% improvement in the objective (total start delay)}, demonstrating the effectiveness of our learning method in accelerating RHO. Comparing with the baseline methods, we observe that: (1) Warm Start RHO does not significantly outperform Default RHO, indicating the inadequacy of simple warm start techniques for the complex long-horizon FJSP. (2) The assignment-based subproblem restriction heuristics, namely First and Random, improve the solve time from Default RHO, albeit at the expense of poorer objective. Moreover, First $\sigma_F$ emerges as a more effective heuristic than Random $\sigma_R$, with a better solve time and objective improvement when $\mathcal{O}_{fix, r}$ is of a comparable size ($\sigma_F = \sigma_R$). 


\begin{figure}[!t]
     \centering
    \includegraphics[width=\textwidth]{figures/plot_all_three_new.png}
    \caption{\textbf{L-RHO under different FJSP variants.} \textbf{Left: Increased Congestion level} with more jobs $|\mathcal{T}| \in \{30, 32, 34\}$.
    We circle the baselines for these three settings with green, yellow and red ellipsoids, using different markers to represent each setting. L-RHO is plotted in pink. \textbf{Middle: Multi-objective and Noisy Observation \sliblue{(online)}}. We analyze FJSP $(30, 30, \slifinalblue{24})$ with the (i) start delay objective (ii) start and end delay objective, and (iii) start and end delay objective plus observation noise. The arrows illustrate the performance changes of each method across (i)-(ii)-(iii). \sliblue{\textbf{Right: Machine Breakdown (online).} We simulate machine breakdowns during RHO's process, varying intensity (low, mid, high) by adjusting event frequency and machine availability.} }
    \label{fig:additional experiment}
\end{figure}

\textbf{Data Distribution: Higher Congestion.}
We raise the congestion level by increasing the number of jobs $|\mathcal{T}| \in \{30, 32, 34\}$ while keeping the number of machines $|\mathcal{M}| = 30$ and operations per machine to be $25$ under the start delay objective. This results in a higher job-to-machine ratio, with congestion build-up over time. In Fig.~\ref{fig:additional experiment} (left), we observe that L-RHO achieves solve time and objective improvements TI\% $\in\{41\%, 39\%, 28\%\}$ and OI\% $\in\{14\%, 20\%, 27\%\}$ across the different settings, demonstrating the robustness of the learning method to system congestion. In contrast, the baselines (First and Random) have limited solve time improvement and substantial objective degradation for all settings. This highlights L-RHO's ability to enhance system throughput by enabling the system to process more jobs than Default and baseline RHO methods.


\textbf{Multi-Objective: Start and End Delay.} 
While the total start delay objective emphasizes adhering to the release time, reducing the total end delay is crucial in many real world scenarios where following each operation's scheduled due time is important. Here, we use the sum of the start and end delay as the objective and generate random target end time for each operation (see Appendix~\ref{appendix_sec:instance_dist}). In Fig.~\ref{fig:additional experiment}, middle (ii), we observe that L-RHO maintains solve time and objective improvements with a TI\% of $39\%$ and OI\% of $4\%$ under this combined objective. 
Interestingly, Random and First also improve relative to Default RHO (better TI\% and OI\%, see Random 30\%, for example). \slired{Empirically, we find more overlapping operations maintain the same assignment under this distribution, our analysis in Sec.~\ref{sec:analysis} indicates the advantageous for Random and First under such a scenario.} 

\textbf{\sliblue{Online} FJSP: Observation Noise.} In real-world FJSP deployments, practitioners often face incomplete and noisy operation data. To simulate this, we introduce observation noise into the RHO process, moving towards a more realistic online FJSP. Specifically, we assume that in each RHO subproblem, only the durations of operations with earlier release times are accurately observed. For other operations, we only have access to noisy estimates, and RHO optimizes subproblems based on this noisy information. Thus, the observed durations in $\hat{P}_r$ may differ from the true execution duration during execution (see Appendix~\ref{appendix_sec:instance_dist} for details). In Fig.~\ref{fig:additional experiment}, middle (iii), the Random and First strategies degrade significantly under observation noise, with a more pronounced effect on First. \slired{Our analysis in Sec.~\ref{sec:analysis} captures such a behavior for First and Random, as the observation noise leads to (1) more overlapping operations changing assignments (2) a less informative distribution to determine which operation in the subproblem will change assignments.} In contrast, L-RHO remains effective under observation noise, with a TI\% of 25\% and OI\% of 4\% over Default RHO. 

\textbf{Online FJSP: Machine Breakdown.} In real-world FJSP scenarios, unexpected disruptions such as machine breakdowns can occur~\citep{zhang2017flexible}. We simulate breakdowns, and combine the periodic RHO optimization with event-based rescheduling: when a breakdown or recovery occurs, we re-optimize the RHO subproblem with updated machine availability. This leads to two major changes in the RHO pipeline (1) RHO subproblems are solved more frequently due to the breakdown (or recovery) events, and (2) operations with all compatible machines down are deferred until the breakdown ends, thereby resulting in longer scheduling horizon (see Appendix~\ref{appendix_sec:instance_dist} for details). In Fig.~\ref{fig:additional experiment} (Right), we test L-RHO under varying machine breakdown intensities by adjusting breakdown frequency and the proportion of downed machines, using makespan as the objective with 10 machines, 20 jobs, and 800 operations.
\colorr{Our L-RHO demonstrates significant time improvements TI\% $\in$ \{47\%, 52\%, 37\%\} over Default RHO across all intensity levels, while also achieving a better makespan}. This highlights L-RHO's reliability under unexpected disruptions. \slired{We also observe that, at high breakdown intensity, First loses its advantageous to Random. This can be similarly explained in our analysis next, as unexpected disruptions reduce the amount of information First can leverage.}



\section{Theoretical Probabilistic Analysis}
\label{sec:analysis}

\color{blue}
\color{black}
In this section, we present a theoretical probabilistic analysis to identify when RHO \cw{can benefit from machine learning}. 
Intuitively speaking, the more irregular the operations to be fixed ($\mathcal{O}^*_{fix}$), the more advantageous L-RHO can be, because of the greater potential gain from prediction. Also, L-RHO must balance both False Positive (FP) and False Negative (FN) errors: fixing something that should not have been (FP) harms the objective but helps the solve time, while failing to fix something that should have been (FN) harms the solve time and also indirectly harms the objective (under a fixed time limit). 
Thus, an ideal L-RHO method will balance the two errors (see Fig.~\ref{fig:analysis}). 

\textbf{Notation.} We analyze a generic subproblem $\hat{P}_r := \hat{P}$ at each iteration $r$, and drop the $r$ subscript for ease of notation. We consider a fixed set of RHO parameters and denote $W$ = $H - S$ = $|\mathcal{O}_{overlap}|$. Given $\mathcal{O}^*_{fix}$ and $\mathcal{O}_{fix}$ from the Oracle and a method in \{Random $\sigma_R$, First $\sigma_F$, L-RHO\}, \slirebuttalblue{we denote $\mathbb{E}[n^*_{fix}]$ = $\mathbb{E}[|\mathcal{O}^*_{fix}|]$, $\mathcal{O}_{fn}$ = $\mathcal{O}^*_{fix} \backslash \mathcal{O}_{fix}$, and $\mathcal{O}_{fp}$ = $\mathcal{O}_{fix} \backslash \mathcal{O}^*_{fix, r}$. We define the FN and FP \textit{errors} $\mathbb{E}[n_{fn}]$ = $\mathbb{E}[|\mathcal{O}_{fn}|]$ and $\mathbb{E}[n_{fp}]$ = $\mathbb{E}[|\mathcal{O}_{fp}|]$.} The (expected) FP and FN \textit{rates} of each method are $\mathbb{E}[n_{fp}] / \mathbb{E}[n^*_{fix}], \mathbb{E}[n_{fn}] / (W - \mathbb{E}[n^*_{fix}])$, with L-RHO's FPR and FNR denoted as $(\alpha, \beta)$.

\slirebuttalblue{We leverage an intuitive linear decay assumption,  validated in Appendix~\ref{appendix_sec:analysis_pfix}: in a given FJSP subproblem, the later an operation appears in the RHO sequence, the less likely its assignment should be fixed. This assumption allows us to formally relate the FP and FN errors of different methods (L-RHO versus Random versus First, see Prop.~\ref{prop:closed_form} and Fig.~\ref{fig:analysis} (middle)).}

\begin{assumption}[\cw{Linear Decay}] Let the probability that each operation $O^{(i)} \in \mathcal{O}_{overlap}$ is included in $\mathcal{O}^*_{fix}$ be denoted as $p^*_{fix}(i) \in [0, 1]$, where the index $i \in \{1, ..., W\}$ follows the RHO sequence order. We consider linearly decreasing $p^*_{fix}(i) = b - m \cdot \frac{i}{W}$, where constants $0 \leq b, m \leq 1$ reflect average behavior across RHO iterations. We have $\mathbb{E}[n_{fix}^*] = \sum_{i} p^*_{fix}(i) = (b - \frac{m}{2})W - \frac{m}{2}$.

\label{assump:linear_decrease}
\end{assumption}
\begin{proposition} 
    Under Assump.~\ref{assump:linear_decrease}, the FN and FP errors for each method is given in closed-form as 
    \begin{itemize}[leftmargin=0.5cm, noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
        \item \textbf{Random:} $\mathbb{E}[n^{\text{Random}}_{fn}] = (1-\sigma_R)\mathbb{E}[n_{fix}^*], \mathbb{E}[n^{\text{Random}}_{fp}] = \sigma_R (W - \mathbb{E}[n_{fix}^*])$ ;
        \item \textbf{First:} $\mathbb{E}[n^{\text{First}}_{fn}] = (1-\sigma_{F})(\mathbb{E}[n_{fix}^*] - \frac{m}{2}\sigma_{F}W), \mathbb{E}[n^{\text{First}}_{fp}] = \sigma_{F} \big(W - \mathbb{E}[n_{fix}^*] - \frac{m}{2}(1-\sigma_{F})W\big)$; 
        \item   \textbf{L-RHO:} $\mathbb{E}[n^{\text{L-RHO}}_{fn}] = \beta\mathbb{E}[n_{fix}^*], \mathbb{E}[n^{\text{L-RHO}}_{fp}] = \alpha (W - \mathbb{E}[n_{fix}^*])$.
\end{itemize}
Furthermore, ignoring the $\frac{m}{2}$ term in $\mathbb{E}[n_{fix}^*]$ for ease of exposition, the FP and FN Rates of First $\sigma_F$ and Random $\sigma_R$ are $(\alpha_F, \beta_F) = (\frac{\sigma_F (1 - b + \frac{m}{2}\sigma_F)}{1 - b + \frac{m}{2}}, 1 - \frac{\sigma_F (b - \frac{m}{2}\sigma_F)}{b - \frac{m}{2}})$ and $(\alpha_R, \beta_R) = (\sigma_R, 1-\sigma_R)$. \label{prop:closed_form}
\end{proposition}

\slirebuttalblue{\textbf{Interpretation.} The $p^*_{fix}(i)$ distribution determines the strength of the Random and First baselines and thus the potential for improvement by learning methods. (1) When $\mathbb{E}[n^*_{fix}]$ is close to 0 or 1, Random achieves low FP and FN errors by setting $\sigma_R$ close to $\mathbb{E}[n^*_{fix}]$ . (2) Our analysis captures the empirical observation that First often outperforms Random: with a strong linear decay (a large slope $m$), First further reduces the FP and FN errors from Random for each $\sigma_F = \sigma_R$. (3) L-RHO is advantageous when its FP and FN rates $(\alpha, \beta)$ is lower than those for First and Random, as given in the Prop. This can provide practitioners a valuable way to assess the effectiveness of the learned model prior to deployment. We refer to Appendix~\ref{appendix_sec:analysis} for detailed proofs and interpretation.} 

\begin{figure}[!t]
     \centering
    \includegraphics[width=\textwidth]{figures/analysis_all.png}
      \caption{\textbf{Left:} We analyze FN and FP errors of each RHO method relative to Oracle and interpret their impact on objective and solve time. \textbf{Middle:} We show the FN and FP errors for Random and First with $\sigma_R, \sigma_F \in [0, 1]$ under Assump.~\ref{assump:linear_decrease}, fixing $b - \frac{m}{2} = 0.5$ while increasing the slope $m$. Higher $m$ enhances the performance of First relative to Random (with equal $\sigma$) by reducing both errors. We plot $\sigma_R, \sigma_F \in \{0, 0.1, ..., 1\}$ using circles and squares, with darker colors for smaller values. \textbf{Right:} For FJSP $(25, 25, \slifinalblue{24})$ with the total start delay objective, we depict the FN and FP errors of \{Random, First, and L-RHO\} in the low FP region, using an empirically validated $p^*_{fix}(i)$ distribution. 
      By reducing both $\mathbb{E}[n_{fp}]$ and $\mathbb{E}[n_{fn}]$, L-RHO empirically outperforms First $\sigma_F \leq 60\%$ in solve time and all baselines in objective (pink region). Transforming the coordinates (right and top axes) can further reveal the FP and FN rates L-RHO should achieve for learning to be effective.
      }
      \label{fig:analysis}
\end{figure}

\section{Conclusion}
\label{sec:conclusion}
\slirebuttalblue{We contribute the first learning-guided rolling-horizon method for COPs, which we call L-RHO. By learning which overlapping solutions in consecutive RHO iterations do not need to be re-optimized, our method substantially reduces RHO subproblem sizes and thus accelerates their solve time.} L-RHO scales and accelerates RHO by up to 54\%, improves solution quality, and outperforms a wide range of baselines, both with and without decomposition. We also analyze L-RHO's performance across various FJSP settings, distributions, and online scenarios, highlighting its flexibility and adaptability. We further provide a probability analysis to identify conditions where learning-guided RHO is most beneficial. One limitation is that L-RHO alone may not achieve state-of-the-art performance when extended to other long-horizon COPs. \slirebuttalblue{Future work could extend L-RHO to - 1) other long-horizon COPs, e.g., multi-item inventory management and vehicle routing with time windows, 2) training on diverse distributions for better generalization, 3) integration with other decomposition or subproblem restriction methods, and 4) addressing more complex real-world online scenarios.} Our theoretical analysis may also guide the development of more effective RHO warm-start techniques with applications to control and robotics, e.g., accelerating Hybrid MPCs. We believe L-RHO offers a valuable tool for long-horizon COPs and will inspire future work in various domains.  \slifinalblue{Our code is publicly available at \url{https://github.com/mit-wu-lab/l-rho}.}

\section{Acknowledgement}
\slifinalblue{The authors would like to thank Sean Lo for insightful discussions. This work was supported by the National Science Foundation (NSF) CAREER award (\#2239566), MITs Research Support Committee, an Amazon Robotics Ph.D. Fellowship, and a gift from Mathworks. The authors acknowledge the MIT SuperCloud and Lincoln Laboratory Supercomputing Center for providing HPC resources that have contributed to the research results reported within this paper.}

\bibliography{cite}

\appendix
\section{Supplementary Material: \textit{Learning-Guided Rolling Horizon Optimization for Long-Horizon Flexible Job-Shop Scheduling}} 
\localtableofcontents


\clearpage
\newpage
\subsection{Notations}
\label{appendix_sec:notation}
We provide detailed lists of notations for the Flexible Job-shop Scheduling Problem (FJSP) and Rolling Horizon Optimization (RHO) in Table~\ref{appendix_tab:notation_fjsp} and Table~\ref{appendix_tab:notation_rho}.
\begin{table}[!ht]
\caption{Notations for the Flexible Job-shop Scheduling Problem (FJSP).}
\label{appendix_tab:notation_fjsp}
\centering
\scalebox{0.825}{
\begin{tabular}{lll}
\\[-0.7em] \hline \\[-0.7em]
\multicolumn{3}{c}{\textbf{FJSP Related}}                                    \\[-0.7em]\\ \hline \\[-0.7em]
\multirow{7}{*}{\textbf{Problem} $\mathbf{P}$}    & $\mathcal{M}$      & A set of machines. The machines are indexed by $m \in \mathcal{M}$.  \\[-0.7em]       \\  \\[-0.7em]       
     & $\mathcal{T}$    & A set of job. The jobs are indexed by $j \in \mathcal{T}$.   \\[-0.7em]        \\  \\[-0.7em]       
     & $\mathcal{O}$   & \begin{tabular}[c]{@{}l@{}}A set of operations. The operations are indexed by $O_{j, k} \in \mathcal{O}$.  \\ 
     Each job $j \in \mathcal{T}$ consists of a set of $n_j$ operations $\{O_{j, k}\}_{k=1}^{n_j} \subseteq \mathcal{O}$. \\ 
     required to be processed in a predefined precedence order \\
     $O_{j, 1} \rightarrow O_{j, 2} \rightarrow ... \rightarrow O_{j, n_j}$.\\
    After sorting the operations by their respective release time (see below), \\
    each operation $O^{(i)} \in \mathcal{O} = \{O^{(1)}, ..., O^{(|\mathcal{O}|)}\}$ is indexed by $i$.
    \end{tabular}  \\[-0.7em]        \\  \\[-0.7em]       
    & \begin{tabular}[c]{@{}l@{}}Compatible \\ Machines $\mathcal{M}_{j, k}$\end{tabular} & \begin{tabular}[c]{@{}l@{}}Each operation $O_{j, k}$ can be processed on any machine among \\
    a subset $\mathcal{M}_{j, k} \subseteq \mathcal{M}$ of compatible machines.\end{tabular}  \\[-0.7em]        \\  \\[-0.7em]       
    & Process Duration $p_{j, k}^{m}$     & $p_{j, k}^{m}$ denotes the process duration of operation $O_{j, k}$ on machine $m \in \mathcal{M}_{j, k}$.  \\[-0.7em]        \\  \\[-0.7em]       
    & \begin{tabular}[c]{@{}l@{}}Release Time $s_{j, k}$\\ (Target Start Time)\end{tabular}      & \begin{tabular}[c]{@{}l@{}}Under delay-based objectives, each operation $O_{j, k}$ has a release time $s_{j, k}$, \\  which respects the 
    precedence orders of operations within the same job:  \\for operations $O_{j, k_1}$ and $ O_{j, k_2}$ with $\forall k_1 < k_2$, we assume $s_{j, k_1} \leq s_{j, k_2}$. \\
    Each operation can only be processed after its release time. \\
    \end{tabular}  \\[-0.7em]          \\  \\[-0.7em]       
    & Target End Time $t_{j, k}$    & \begin{tabular}[c]{@{}l@{}} Under the total end delay objective, each operation $O_{j, k}$ is associated \\  with a target end time $t_{j, k}$,  which represents a target time to finish  \\ the operation and similarly respects the operation precedence orders.\end{tabular} \\[-0.7em] \\ \\[-0.7em] 
    & \begin{tabular}[c]{@{}l@{}}\sliblue{Operations' Ordering}\\ $\{\mathcal{O}^{(1)}, ..., \mathcal{O}^{(|O|)}\}$\end{tabular}  & \begin{tabular}[c]{@{}l@{}}Ordering of the operations $\mathcal{O} = \{O_{j, k}\}_{j, k}$ used to \\ divide the full operation set $\mathcal{O}$ into 
    overlapping RHO subproblems.  \\
    $\bullet$ For the \textit{makespan} objective, the operations are ordered by \\ their relative position in the jobs based on the precedence order: \\ For job $j$ with $n_j$ operations in precedence order  $O_{j, 1} \rightarrow ... \rightarrow O_{j, n_j}$, \\ we give operation $O_{j, k}$ a score of $k / n_j$,  and choose each RHO \\ subproblem as the first $H$ non executed operations with the lowest score. \\
    $\bullet$ For \textit{delay-based} objectives, the operations are ordered by \\ their release time 
    $s^{(1)} \leq ... \leq s^{(|\mathcal{O}|)}$. \end{tabular} \\[-0.7em] \\ \hline \\[-0.7em]
\multirow{4}{*}{\begin{tabular}[c]{@{}l@{}} \textbf{Solution} \\ $\mathbf{\Pi = (m, \pi)}$\end{tabular}}                                            & Assignment $m$     & \begin{tabular}[c]{@{}l@{}}$m: \mathcal{O} \rightarrow \mathcal{M}$ represents the machine assignment of each operation, \\ with $m(O_{j, k}) \in \mathcal{M}_{j, k}$ for all $j, k$.\end{tabular}                    \\[-0.7em]         \\  \\[-0.7em]       
    & \begin{tabular}[c]{@{}l@{}}Schedule $\pi$ \\ (Process Start Time) \end{tabular}       &  \begin{tabular}[c]{@{}l@{}}$\pi: \{O_{j, k}\;|\;\forall j, k\} \rightarrow \mathbb{N}$, where the process start time \\ of each operation $O_{j, k}$ satisfies $\pi(O_{j,k}) \geq s_{j, k}$.\end{tabular}                  \\[-0.7em]      \\  \\[-0.7em]       
    & Process End Time $\pi_t$          &   \begin{tabular}[c]{@{}l@{}}The process end time of operation $O_{j, k}$ is $\pi_t(O_{j,k}) := $\\ $\pi(O_{j, k}) + p_{j, k}^{m(O_{j, k})}$, where $p_{j, k}^{m(O_{j, k})}$ is the process duration. \end{tabular}     \\[-0.7em]        \\ \hline \\[-0.7em]
\multirow{2}{*}{\textbf{Objective}}
    & \begin{tabular}[c]{@{}l@{}}Makespan
    \end{tabular}        &   $\max\limits_{O_{j, k} \in \mathcal{O}} \pi_t(O_{j,k}) $, see Alg.~\ref{appendix_alg:fjsp_cp_full}.        \\[-0.7em]            \\  \\[-0.7em]  
    & \begin{tabular}[c]{@{}l@{}}Total Start Delay\end{tabular}        &   $\sum\limits_{O_{j, k} \in \mathcal{O}} \pi(O_{j,k}) - s_{j, k}$, see Alg.~\ref{appendix_alg:fjsp_cp_full}.        \\[-0.7em]            \\  \\[-0.7em]     
    & \begin{tabular}[c]{@{}l@{}}Total Start and End Delay \end{tabular}    & $\sum\limits_{O_{j, k} \in \mathcal{O}} \pi(O_{j,k}) - s_{j, k} +  \max(\pi_t(O_{j,k}) - t_{j, k}, 0)$, see Alg.~\ref{appendix_alg:fjsp_cp_full}.              \\[-0.7em]     \\ \hline 
\end{tabular}
}
\end{table}

\begin{table}[!ht]
\caption{Notations for the Rolling Horizon Optimization (RHO).}
\label{appendix_tab:notation_rho}
\centering
\scalebox{0.76}{
\begin{tabular}{lll}
\\[-0.7em] \hline \\[-0.7em]
\multicolumn{3}{c}{\textbf{RHO Related: RHO Iteration $r$}}         \\[-0.7em] \\ \hline \\[-0.7em] \multirow{7}{*}{\textbf{Parameters}}      & $H$     & A planning window size ($H$ operations in the current planning window). \\[-0.7em] \\ \\[-0.7em]
& $S$ & An execution step size ($S \leq H$ operations executed at each iteration). \\[-0.7em] \\ \\[-0.7em]
& $T$ & A solve time limit of $T$ seconds per RHO subproblem.  \\[-0.7em]\\ \\[-0.7em]
& $T_{es}$ & \begin{tabular}[c]{@{}l@{}}We early terminate the solver if the value of the best feasible solution  \\
does not improve within $T_{es}$ seconds. (see Appendix.~\ref{appendix_sec:rho_param_search}) \end{tabular}
 \\[-0.7em]  \\ \hline \\[-0.7em]
\multirow{4}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}FJSP \\Optim. \\ Subproblem\end{tabular}}}  & Unrestricted $P_r$      &   \begin{tabular}[c]{@{}l@{}}FJSP subproblem $P_r$ given by a subset of operations $\mathcal{O}_{plan, r}$, with \\  additional constraints to ensure $\mathcal{O}_{plan, r}$ are processed after the \\ previously executed operations  within the same job or the same \\ machine  (see Appendix~\ref{appendix_sec:fjsp_formulation} Alg.~\ref{appendix_alg:fjsp_cp_subp}).\end{tabular}            \\[-0.7em]  \\ \\[-0.7em]
  &   Restricted $\hat{P}_r$            &   \begin{tabular}[c]{@{}l@{}}Given a subset $O_{fix, r}$, we can construct a simpler, restricted FJSP\\ subproblem $\hat{P}_r$ from $P_r$ by setting the compatible machines \\ $M_{j, k} = \{m_{r-1}(O_{j, k})\}$ for $O_{j, k} \in \mathcal{O}_{fix, r}$.\end{tabular}    \\[-0.7em]     \\ \hline \\[-0.7em]
\multirow{16}{*}{\textbf{\begin{tabular}[c]{@{}l@{}}Relevant \\ Operations\\ Subset\end{tabular}}} & $\mathcal{O}_{plan, r}$          &    \begin{tabular}[c]{@{}l@{}}Operations included in the current RHO subproblem $P_r$ or $\hat{P}_r$:\\ The first $H$ non-executed operations with earliest RHO sequence order.\\
See Appendix Sec.~\ref{appendix_sec:l2rho_alg} Alg.~\ref{appendix_alg:get_plan_operation}.\end{tabular}     \\[-0.7em]           \\  \\[-0.7em]     
& $\mathcal{O}_{step, r}$      &   \begin{tabular}[c]{@{}l@{}}Executed operations based on the solution of $P_r$ or $\hat{P}_r$:\\ The first $S$ operations with the earliest process start time\\ $Earliest\_S\_Operations(\{\pi_r(O) | O \in \mathcal{O}_{plan, r}\})$. See Alg.~\ref{appendix_alg:get_step_operation}. \end{tabular}         \\[-0.7em]    \\  \\[-0.7em]       
 & $\mathcal{O}_{overlap, r}$          &   \begin{tabular}[c]{@{}l@{}} Overlapping operations in consecutive RHO iterations ($r-1$ and $r$):\\
 $\mathcal{O}_{overlap, r} = \mathcal{O}_{plan, r}\cap \mathcal{O}_{plan, r-1}$   \end{tabular}     \\[-0.7em]             \\  \\[-0.7em]       
& $\mathcal{O}_{new, r}$       &  \begin{tabular}[c]{@{}l@{}} New operations in iteration $r$ but not in $r-1$: \\
$\mathcal{O}_{new, r} = \mathcal{O}_{plan, r}\backslash \mathcal{O}_{plan, r-1}$ \end{tabular}  \\[-0.7em]         \\  \\[-0.7em]       
& $\mathcal{O}^*_{fix, r}$         &    \slirebuttalblue{ \begin{tabular}[c]{@{}l@{}}The (look-ahead Oracle) subset of operations in $\mathcal{O}_{overlap, r}$ with \\  the same machine assignment in the consecutive unrestricted \\ RHO subproblems $P_{r}$ and $P_{r-1}$: \\ $\mathcal{O}^*_{fix, r} = \{O \in \mathcal{O}_{overlap, r}\;|\; m_r(O) = m_{r-1}(O)\}$\\
That is, given the solution to the previous subproblem $P_{r-1}$, \\ we lookahead by solving the current subproblem $P_r$ \\
and identify operations with the same machine assignments.
\end{tabular}    }  \\[-0.7em]     \\  \\[-0.7em]       
& $\mathcal{O}_{fix, r}$       &   \begin{tabular}[c]{@{}l@{}}The fixed operations subset given by a specific method. Given \\
$\mathcal{O}_{fix, r} \subseteq \mathcal{O}_{overlap, r}$, we can construct $\hat{P}_r$ from $P_r$ by setting the \\ compatible machines $M_{j, k} = \{m_{r-1}(O_{j, k})\}$ for operations $O_{j, k} \in \mathcal{O}_{fix, r}$. \end{tabular}                      \\[-0.7em]       \\ \hline  \\[-0.7em]       
\multirow{4}{*}{\begin{tabular}[c]{@{}l@{}} \textbf{Subproblem} \\ \textbf{Solution} \\ $\mathbf{\Pi_r = (m_r, \pi_r)}$\end{tabular}}                                            & \begin{tabular}[c]{@{}l@{}} Subproblem \\ Assignment \end{tabular}  $m_r$    &  \begin{tabular}[c]{@{}l@{}}$m_r: \mathcal{O}_{plan, r} \rightarrow \mathcal{M}$ represents the machine assignment of each operation \\ in the subproblem, with $m(O_{j, k}) \in \mathcal{M}_{j, k}$ for all $O_{j, k} \in \mathcal{O}_{plan, r}$.\end{tabular}                                \\[-0.7em]         \\  \\[-0.7em]       
    & \begin{tabular}[c]{@{}l@{}} Subproblem \\ Schedule \end{tabular}  $\pi_{r}$         &      \begin{tabular}[c]{@{}l@{}}$\pi_{r}: \mathcal{O}_{plan, r} \rightarrow \mathbb{N}$, where the (solution) start time of each operation \\  in the subproblem $O_{j, k} \in \mathcal{O}_{plan, r}$ is $\pi(O_{j,k}) \geq s_{j, k}$.\end{tabular}           \\[-0.7em]        \\ \hline \\[-0.7em]
\multirow{20}{*}{\textbf{Methods}}                                 & Default (Cold Start)           &  \begin{tabular}[c]{@{}l@{}}   Each RHO iteration solves an \\ unrestricted FJSP subproblems $P_r$ from scratch (cold start, $\mathcal{O}_{fix, r} \in \emptyset$). \end{tabular}
% \item \textbf{Fix All}: 
  \\[-0.7em]           \\  \\[-0.7em]       
    & Random $\sigma_R$             &  \begin{tabular}[c]{@{}l@{}}  Each RHO iteration solves a restricted FJSP subproblem $\hat{P}_r$ associated with \\ the fixed operation set  $\mathcal{O}_{fix, r}$, constructed by sampling each operation \\ 
    in $\mathcal{O}_{overlap, r}$  with a probability $\sigma_R$ uniformly at random.  \end{tabular}  \\[-0.7em]  \\  \\[-0.7em]       
    & First $\sigma_F$     &    \begin{tabular}[c]{@{}l@{}}  Each RHO iteration solves a restricted FJSP subproblem $\hat{P}_r$ associated with \\ the fixed operation set $\mathcal{O}_{fix, r}$ obtained as the first $\sigma_F$ fraction \\
    of operations in $\mathcal{O}_{overlap, r}$ with the earliest RHO sequence order \\ (determined by 
    operation precedence for makespan \\
    or release time for delay-based objectives).  \end{tabular}    \\[-0.7em]    \\  \\[-0.7em]       
    & Warm Start     &  \begin{tabular}[c]{@{}l@{}}  At each RHO iteration, we apply CP-SAT's internal warm-start \\ techniques to solve the unrestricted FJSP subproblems $P_r$. Specifically,  \\ 
    we provide the machine assignments of the overlapping operations in the \\ 
    previous iteration $\{m_{r-1}(O)\;\forall \; O \in \mathcal{O}_{overlap, r}\}$ as \textit{hints} to the solver. \\
    See: ``https://developers.google.com/optimization/reference/\\
    python/sat/python/cp\_model\#addhint''.    \end{tabular}       \\[-0.7em]           \\  \\[-0.7em]       
    & Oracle    & \slirebuttalblue{\begin{tabular}[c]{@{}l@{}}  Follow our data collection pipeline (Fig.~\ref{fig:rho_pipeline} (b) top, omit the solve time for the \\
    unrestricted $P_r$),  where each RHO iteration solves a restricted FJSP \\ subproblem $\hat{P}_r$ associated with the \textit{oracle} fixed operation set $\mathcal{O}^*_{fix, r}$. \end{tabular}  }     \\[-0.7em]      \\  \\[-0.7em]  
    & L-RHO (Ours)   &   \begin{tabular}[c]{@{}l@{}}  Follow the inference procedure $RHO_{test}$ in Fig.~\ref{fig:rho_pipeline} (b) bottom,
    where each  \\ RHO iteration solves a restricted FJSP subproblem $\hat{P}_r$
    associated with \\ the fixed operation 
    set $\mathcal{O}_{fix, r}$ \textit{predicted} by the learning model $f_{\theta}$. \end{tabular}        \\[-0.7em]       \\ \hline
\end{tabular}
}
\end{table}

\clearpage
\newpage
\subsection{Algorithm: Learning-Guided Rolling Horizon Optimization}
\label{appendix_sec:l2rho_alg}
The inference procedure for the learning-guided rolling horizon algorithm (Fig.~\ref{fig:rho_pipeline}) is provided as follows, where at each RHO iteration, we use the neural network $f_\theta$ to identify a set of fixed operation $\mathcal{O}_{fix, r}$ (Line 10), resulting in the machine assignment-based restricted subproblem $\hat{P}_r$ (Line 15). We note that the heuristic RHO baselines considered in Sec.~\ref{sec:experiment} and~\ref{sec:analysis} (e.g. First $\sigma_F$ and Random $\sigma_R$), we follow the same algorithm but use the associated heuristics to find the set $\mathcal{O}_{fix, r}$ instead (Line 10).



% \begin{algorithm}[H]
% \caption{Learning-Guided Rolling Horizon Optimization for FJSP}
% \label{appendix_alg:main}
% \SetAlgoLined
% \KwIn{{FJSP problem instance 
% \(\scalebox{0.9}{
%     $\begin{aligned}[b]
%         P = (& \mathcal{M}, \mathcal{T}, \mathcal{O} = \{O^{(1)}, ..., O^{(|\mathcal{O}|)}\} \text{ ordered based on the precedence or release time (Table~\ref{appendix_tab:notation_fjsp})}, \\
%         & \text{ process duration } \{p_{j, k}^m\}_{\substack{O_{j, k} \in \mathcal{O}, \; m \in \mathcal{M}_{j, k}}}, \\
%         &\text{(optional) release time } \{s_{j, k}\}_{O_{j, k} \in \mathcal{O}}, \text{(optional) target end time } \{t_{j, k}\}_{O_{j, k} \in \mathcal{O}}), 
%     \end{aligned}$
% }\)
% RHO planning window size ($H$ operations), RHO execution step size ($S$ operations), and a solve time limit of $T$ seconds per subproblem}}
% \KwOut{Solution $\Pi = (m, \pi)$ of the FJSP problem instance $P$}
% Initialize $m \leftarrow \{\}, \pi \leftarrow \{\}$\\[0.1cm]
% \For{Iteration $r = 1: |\mathcal{O}| / S$}{
%     // Obtain the first $H$ non-executed operations in $\mathcal{O}$ based on the operation order  \\
%     $\mathcal{O}_{plan, r} \leftarrow \text{GetPlanOperations}(\mathcal{O}, H, r, m, \pi)$\\
%     // See Alg.~\ref{appendix_alg:fjsp_cp_subp} in Appendix~\ref{appendix_sec:fjsp_formulation} for the FJSP subproblem formulation \\
%     $P_r \leftarrow $ FJSP\_Subproblem($P$, $\mathcal{O}_{plan, r}$, $m$, $\pi$)\\
%     \uIf{Iteration $r \geq 2$}{
%         // Learn to identify operations $\mathcal{O}_{fix, r} \in \mathcal{O}_{overlap, r}$ to fix the machine assignments. \\
%     $\mathcal{O}_{fix, r} \leftarrow f_\theta(P_r, \mathcal{O}_{overlap, r}, P_{r-1}, m_{r-1}, \pi_{{r-1}})$ \\
%     }\Else{
%     $\mathcal{O}_{fix, r} \leftarrow \emptyset$
%     }
%     \\
%     // Obtain the assignment-based restricted FJSP subproblem. See Appendix~\ref{appendix_sec:fjsp_formulation}.\\
%     $\hat{P}_r \leftarrow$ Restricted\_FJSP\_Subproblem($P_r , \mathcal{O}_{fix, r}$)\\
%     $(m_r, \pi_{r}) \leftarrow \text{FJSP\_Solver}(\hat{P}_r; T)$ \quad     // Solve the restricted FJSP subproblem \\
%     // Execute the first $S$ operations in $\mathcal{O}_{plan, r}$ with the earliest process start times 
%     $\mathcal{O}_{step, r} \leftarrow \text{GetStepOperations}(\mathcal{O}_{plan, r}, S, r, m_r, \pi_{s,r})$\\
%     // Fix the final solution for the executed operations \\
%     \For{$O^{(i)} \in \mathcal{O}_{step, r}$ } {
%         $m(O^{(i)}) \leftarrow m_r(O^{(i)}); \pi(O^{(i)}) \leftarrow \pi_{r}(O^{(i)})$ 
%     }
% }
% \end{algorithm}

\begin{algorithm}[H]
\caption{Learning-Guided Rolling Horizon Optimization for FJSP}
\label{appendix_alg:main}
\SetAlgoLined

\KwIn{FJSP problem instance \( P = (\mathcal{M}, \mathcal{T}, \mathcal{O}, \{p_{j, k}^m\}, \{s_{j, k}\}, \{t_{j, k}\}) \),  
RHO planning window size \(H\) operations, execution step size \(S\) operations, and solve time limit \(T\) per subproblem.\;}

\KwOut{Solution \(\Pi = (m, \pi)\) of the FJSP problem instance \(P\)}

Initialize \(m \leftarrow \{\}, \pi \leftarrow \{\}\)\;

\For{Iteration \(r = 1: |\mathcal{O}| / S\)}{
    \tcp{Obtain first \(H\) non-executed operations}
    \(\mathcal{O}_{plan, r} \leftarrow \text{GetPlanOperations}(\mathcal{O}, H, r, m, \pi)\)\;

    \tcp{Generate FJSP subproblem (see Appendix~\ref{appendix_sec:fjsp_formulation})}
    \(P_r \leftarrow \text{FJSP\_Subproblem}(P, \mathcal{O}_{plan, r}, m, \pi)\)\;

    \uIf{Iteration \(r \geq 2\)}{
        \tcp{Learn to identify fixed operations in \(\mathcal{O}_{overlap, r}\)}
        \(\mathcal{O}_{fix, r} \leftarrow f_\theta(P_r, \mathcal{O}_{overlap, r}, P_{r-1}, m_{r-1}, \pi_{{r-1}})\)\;
    }
    \Else{
        \(\mathcal{O}_{fix, r} \leftarrow \emptyset\)\;
    }

    \tcp{Obtain the assignment-based restricted FJSP subproblem}
    \(\hat{P}_r \leftarrow \text{Restricted\_FJSP\_Subproblem}(P_r , \mathcal{O}_{fix, r})\)\;

    \tcp{Solve the restricted FJSP subproblem}
    \((m_r, \pi_{r}) \leftarrow \text{FJSP\_Solver}(\hat{P}_r; T)\)\;

    \tcp{Execute first \(S\) operations in \(\mathcal{O}_{plan, r}\) with earliest start times}
    \(\mathcal{O}_{step, r} \leftarrow \text{GetStepOperations}(\mathcal{O}_{plan, r}, S, r, m_r, \pi_{r})\)\;

    \tcp{Fix final solution for executed operations}
    \For{\(O^{(i)} \in \mathcal{O}_{step, r}\)} {
        \(m(O^{(i)}) \leftarrow m_r(O^{(i)})\)\;
        \(\pi(O^{(i)}) \leftarrow \pi_{r}(O^{(i)})\)\;
    }
}
\end{algorithm}



\begin{algorithm}[H]
\SetAlgoLined
\DontPrintSemicolon
\KwIn{Operations $\mathcal{O} = \{O^{(1)}, ..., O^{(|\mathcal{O}|)}\} \textit{ ordered based on the precedence or release time (Table~\ref{appendix_tab:notation_fjsp})}$, RHO planning window size ($H$ operations), RHO current iteration $r$, executed solutions $(m, \pi)$}
\KwOut{Operations in the current RHO planning window $\mathcal{O}_{plan, r}$}
\(\mathcal{O}_{plan, r} \leftarrow []; i \leftarrow 0\)\;
\tcp{select the first $H$ non-executed operations based on the sorted order}
\While{$|\mathcal{O}_{plan, r}| < H$ and $i < |\mathcal{O}|$}{
    \If{$O^{(i)} \notin (m, \pi)$ }{ 
        $\mathcal{O}_{plan, r}.append(O^{(i)})$
    }
    $i \leftarrow i + 1$
}
\caption{GetPlanOperations}
\label{appendix_alg:get_plan_operation}
\end{algorithm}

\begin{algorithm}[H]
\SetAlgoLined
\KwIn{Operations in the current window $\mathcal{O}_{plan, r}$, RHO execution step size ($S$ operations), RHO current iteration $r$, solution  $\Pi_r = (m_r, \pi_{s,r})$ of the $r^{th}$ FJSP subproblem}
\KwOut{Operations executed after the $r^{th}$ RHO iteration $\mathcal{O}_{step, r}$}
\tcp{select the first $S$ non-executed operations with the \textit{earliest process start time}}
$\tilde{\mathcal{O}}_{plan, r} \leftarrow \text{ Sort } \mathcal{O}_{plan, r} $ by the process start time $\{\pi_{s,r}(O^{(i)})\}_{O^{(i)} \in \mathcal{O}_{plan, r}}$ \\[0.1cm]
$\mathcal{O}_{step, r} \leftarrow \{\tilde{\mathcal{O}}_{plan, r}^{(1)}, ..., \tilde{\mathcal{O}}_{plan, r}^{(S)}\}$
\caption{GetStepOperations}
\label{appendix_alg:get_step_operation}
\end{algorithm}


\subsection{Input Features.} \label{appendix_sec:input_feature}
This section provides a detailed description of all input features, which can be categorized as the following three main parts:
\begin{enumerate}
    \item[(1)] For each operation in $\mathcal{O}_{plan, r} = \mathcal{O}_{overlap, r} \cup \mathcal{O}_{new, r}$, we design input features to capture the FJSP instance information such as the earliest process start time of the operation (considering previously executed operations within the same job), the duration (mean / min / max / std) to complete the operation by the compatible machines, and the operation's release time (for delay-based objectives); 
    \item[(2)] For each operation in $\mathcal{O}_{overlap, r}$, we design additional input features to encode the solution information from the previous RHO iteration, including the  duration, machine assignment of the operation and end time / delay.
    \item[(3)] For each machine in $\mathcal{M}$, we further design input features that include the earliest process start time of the machine (considering previously executed operations by the machine), and the duration (mean / min / max / std) of the overlapping operations $\mathcal{O}_{overlap, r}$ previously assigned to the machine. 
\end{enumerate}

As we consider the following different FJSP scenarios in our experiments (Sec.~\ref{sec:experiment}), we adjust the input features accordingly as follows
\begin{itemize}
    \item \textbf{Makespan objective without observation noise}: \sliblue{we use all input features as listed in Table~\ref{appendix_tab:input_feature_makespan}.}
    \item \textbf{Makespan objective under machine breakdowns}: we use all input features as listed in Table~\ref{appendix_tab:input_feature_makespan}, and the additional input features as listed in Table~\ref{appendix_tab:input_feature_makespan_breakdown} to incorporate the machine breakdown information.
    \item \textbf{Total Start Delay objective without observation noise}: we use all input features as listed in Table~\ref{appendix_tab:input_feature}, where the delay input feature is the start time delay for each operation based on the previous RHO iteration's solution, i.e. $\pi_{r-1}(O_{j, k}) - s_{j, k}$.
    \item \textbf{Total Start and End Delay objective without observation noise}: we use all input features as listed in Table~\ref{appendix_tab:input_feature}, where the delay input feature is the start and end time delay for each operation based on the previous RHO iteration's solution, i.e. $\pi_{r-1}(O_{j, k}) - s_{j, k} + \max(\pi_{t, r-1}(O_{j, k}) - t_{j, k}, 0)$ where $\pi_{r-1}(O_{j, k}) = \pi_{r-1}(O_{j, k}) + p_{j, k}^{m_{r-1}(O_{j, k})}$. We further consider the end time related input features as listed in Table~\ref{appendix_tab:input_feature_2}.
    \item \textbf{Total Start and End Delay objective with observation noise}: we use all input features in Table~\ref{appendix_tab:input_feature} and~\ref{appendix_tab:input_feature_2}. Additionally, as described in Appendix~\ref{appendix_sec:exp_details}, we obtain noisy observations of each operation's duration at each RHO iteration (the observation of the same operation may vary across different RHO iterations). That is, given the same machine assignment and start time  $(\tilde{m}_{r-1}, \tilde{\pi}_{r-1})$ from the previous ($r-1^{th}$) iteration, the observed duration and end time for each overlapping operation can differ between the previous ($r-1^{th}$) and current ($r^{th}$) iteration. As a result, we compute the delay and end time delay in Table~\ref{appendix_tab:input_feature} and~\ref{appendix_tab:input_feature_2} using the noisy observation from the previous RHO iteration, and we further re-evaluate the delay, duration, and end time for the overlapping operations based on the current RHO iteration's noisy observation, as detailed in Table~\ref{appendix_tab:input_feature_3}.
\end{itemize} 
We normalize all input features with mean and standard deviation computed on the training set $\mathcal{K}_{data}$.

\begin{table*}[!htb]
\centering
\caption{\sliblue{Input Features for the Operations and Machines for the makespan objective.}} \label{appendix_tab:input_feature_makespan}
\scalebox{0.75}{
\begin{tabular}{cll}
\toprule\\[-1.3em]
\textbf{Type} & \multicolumn{1}{l}{\textbf{Feature}} & \multicolumn{1}{l}{\textbf{Description}}   \\[-1em] \\ \hline \\[-1em]
\multirow{22}{*}{\textbf{Operations}}     & job\_start\_time   & \begin{tabular}[c]{@{}l@{}} The earliest start time of the job $j$ associated with the operation $O_{j, k}$, given by ... \\ \quad ...  the latest process end time of all executed operations for the same job \end{tabular}  \\
& avg\_dur   & Average duration of all compatible machine assignments for the operation    \\
& std\_dur    & Duration standard deviation of all compatible machine assignments for the operation  \\
& min\_dur   & Minimum duration of all compatible machine assignments for the operation   \\
& max\_dur   & Maximum duration of all compatible machine assignments for the operation  \\
& job\_id   & Job id for the operation ($j \in \{1, ... |\mathcal{T}|\}$ before normalization)  \\
& ops\_id    & Operation id for the operation ($k \in \{1, ... n_j\}$ before normalization) \\
& in\_overlap\  & \begin{tabular}[c]{@{}l@{}} The operation $O_{j, k} \in \mathcal{O}_{overlap, r}$  at the current RHO iteration $r$ \end{tabular}   \\[-1em]  \\
\cline{2-3} \\[-1em]
& \begin{tabular}[c]{@{}l@{}}  prev\_machine \\ (-1 if not in\_overlap)\end{tabular}   & \begin{tabular}[c]{@{}l@{}} Machine assignment of the operation in the solution of... \\ \quad ... the previous RHO iteration ($m(O_{j, k}) \in \{0, ... |\mathcal{M}-1|\}$ before normalization)\end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  prev\_duration \\ (-1 if not in\_overlap)\end{tabular} &  Operation's process duration given by the previous machine assignment $p_{j, k}^{m_{r-1}(O_{j, k})}$ \\
& \begin{tabular}[c]{@{}l@{}}  prev\_end\_time \\ (-1 if not in\_overlap)\end{tabular}   & \begin{tabular}[c]{@{}l@{}} End time of the operation in the solution of ... \\ \quad ... the previous RHO iteration ($\pi_{t, r-1}(O_{j, k})$)\end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  alt\_avg\_dur \\ (-1 if not in\_overlap)\end{tabular} & \begin{tabular}[c]{@{}l@{}} Average process duration of all other machines .. \\ \quad ... (not prev\_machine) to process the operation \end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  alt\_std\_dur \\ (-1 if not in\_overlap)\end{tabular} & \begin{tabular}[c]{@{}l@{}} Standard deviation of duration of all other machines ... \\ \quad ... (not prev\_machine) to process the operation \end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  alt\_min\_dur \\ (-1 if not in\_overlap)\end{tabular} & \begin{tabular}[c]{@{}l@{}} Minimum duration of all other machines ... \\ \quad ... (not prev\_machine) to process the operation \end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  alt\_max\_dur \\ (-1 if not in\_overlap)\end{tabular} & \begin{tabular}[c]{@{}l@{}} Maximum duration of all other machines ...\\
\quad ... (not prev\_machine) to process the operation \end{tabular}
\\[-1em]   \\ \hline \\[-1em]
\multirow{9}{*}{\textbf{Machines}} & machine\_start\_time  & \begin{tabular}[c]{@{}l@{}} The earliest start time of the machine $m$, given by the latest process ... \\ \quad ... end time of all executed operations assigned to machine $m$
\end{tabular}   \\
& num\_overlap    & \begin{tabular}[c]{@{}l@{}} Number of overlapping operations assigned to the machine $m$ ... \\ \quad ...  in the solution of the previous RHO iteration $\sum_{O \in \mathcal{O}_{overlap, r}} \mathds{1}\{m_{r-1}(O) = m\}$ \end{tabular}  \\[-1em] \\
\cline{2-3} \\[-1em]
& \begin{tabular}[c]{@{}l@{}} avg\_end\_time \\ (-1 if num\_overlap is 0) \end{tabular}   & \begin{tabular}[c]{@{}l@{}} Average end time of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration\end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  std\_end\_time \\ (-1 if num\_overlap is 0) \end{tabular} & \begin{tabular}[c]{@{}l@{}} Standard deviation of the end time of overlapping operations assigned to ... \\ \quad ... the machine in the solution of the previous RHO iteration\end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  max\_end\_time \\ (-1 if num\_overlap is 0) \end{tabular}    & \begin{tabular}[c]{@{}l@{}} Maximum end time of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration\end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  min\_end\_time \\ (-1 if num\_overlap is 0) \end{tabular} & \begin{tabular}[c]{@{}l@{}} Minimum end time of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration\end{tabular} \\
& \begin{tabular}[c]{@{}l@{}} avg\_duration \\ (-1 if num\_overlap is 0) \end{tabular}   & \begin{tabular}[c]{@{}l@{}} Average duration of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration\end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  std\_duration \\ (-1 if num\_overlap is 0) \end{tabular} & \begin{tabular}[c]{@{}l@{}} Standard deviation of the duration of overlapping operations assigned to ... \\ \quad ... the machine in the solution of the previous RHO iteration\end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  max\_duration \\ (-1 if num\_overlap is 0) \end{tabular}    & \begin{tabular}[c]{@{}l@{}} Maximum duration of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration\end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  min\_duration \\ (-1 if num\_overlap is 0) \end{tabular} & \begin{tabular}[c]{@{}l@{}} Minimum duration of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration\end{tabular} \\
 \\[-1.3em]  \bottomrule
\end{tabular}
}
\end{table*}

\begin{table*}[!h]
\centering
\caption{\sliblue{Additional Input Features for the Machine Breakdown.}} \label{appendix_tab:input_feature_makespan_breakdown}
\scalebox{0.8}{
\begin{tabular}{cll}
\toprule\\[-1.3em]
\textbf{Type} & \multicolumn{1}{l}{\textbf{Feature}} & \multicolumn{1}{l}{\textbf{Description}}   \\[-1em] \\ \hline \\[-1em]
\multirow{5}{*}{\textbf{Operations}}     &  is\_break\_down    & The current RHO subproblem has some machine breakdown   \\
\cline{2-3} \\[-1em]
& is\_ops\_break\_down    & \begin{tabular}[c]{@{}l@{}}The machine assigned to the operation in the previous RHO subproblem ... \\ \quad ... is broken down in the current RHO subproblem\end{tabular}  \\[-1em]  \\
& is\_ops\_recovered    & \begin{tabular}[c]{@{}l@{}}The operation's machine assignment choices was restricted ... \\ \quad ... in the previous RHO subproblem due to machine breakdown, ... \\ \quad ... but the breakdown is recovered in the current subproblme \end{tabular}  \\[-1em]  \\
 \\[-1.3em]  
 \midrule
 \multirow{5}{*}{\textbf{Machines}}     & is\_break\_down    & The current RHO subproblem has some machine breakdown  \\
& is\_machine\_break\_down    & The machine itself is broken down in the current RHO subproblem \\[-1em]  \\
\cline{2-3} \\[-1em]
& \begin{tabular}[c]{@{}l@{}}  prev\_start \\ (-1 if not in\_overlap)\end{tabular}   & \begin{tabular}[c]{@{}l@{}} Process start time of the operation in the solution of ... \\ \quad ... the previous RHO iteration $\pi_{r-1}(O_{j, k})$ \end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  prev\_end \\ (-1 if not in\_overlap)\end{tabular}   & \begin{tabular}[c]{@{}l@{}} Process end time of the operation in the solution of ... \\ \quad ... the previous RHO iteration $\pi_{t, r-1}(O_{j, k}) = \pi_{r-1}(O_{j, k}) + p_{j, k}^{m_{r-1}(O_{j, k})}$ \end{tabular} \\ 
 \\[-1.3em]  
 \bottomrule
\end{tabular}
}
\end{table*}

\begin{table*}[!htb]
\centering
\caption{Input Features for the Operations and Machines for delay-based objectives.} \label{appendix_tab:input_feature}
\scalebox{0.75}{
\begin{tabular}{cll}
\toprule\\[-1.3em]
\textbf{Type} & \multicolumn{1}{l}{\textbf{Feature}} & \multicolumn{1}{l}{\textbf{Description}}   \\[-1em] \\ \hline \\[-1em]
\multirow{22}{*}{\textbf{Operations}}     & job\_start\_time   & \begin{tabular}[c]{@{}l@{}} The earliest start time of the job $j$ associated with the operation $O_{j, k}$, given by ... \\ \quad ...  the latest process end time of all executed operations for the same job \end{tabular}  \\
& ops\_release\_time     & The release time $s_{j, k}$ of the operation $O_{j, k}$ \\ 
& avg\_dur   & Average duration of all compatible machine assignments for the operation    \\
& std\_dur    & Duration standard deviation of all compatible machine assignments for the operation  \\
& min\_dur   & Minimum duration of all compatible machine assignments for the operation   \\
& max\_dur   & Maximum duration of all compatible machine assignments for the operation  \\
& job\_id   & Job id for the operation ($j \in \{1, ... |\mathcal{T}|\}$ before normalization)  \\
& ops\_id    & Operation id for the operation ($k \in \{1, ... n_j\}$ before normalization) \\
& in\_overlap\  & \begin{tabular}[c]{@{}l@{}} The operation $O_{j, k} \in \mathcal{O}_{overlap, r}$  at the current RHO iteration $r$ \end{tabular}   \\[-1em]  \\
\cline{2-3} \\[-1em]
& \begin{tabular}[c]{@{}l@{}}  prev\_delay \\ (-1 if not in\_overlap)\end{tabular}   & \begin{tabular}[c]{@{}l@{}} Delay of the operation in the solution of ... \\ \quad ... the previous RHO iteration ($\pi_{r-1}(O_{j, k}) - s_{j, k}$)\end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  prev\_machine \\ (-1 if not in\_overlap)\end{tabular}   & \begin{tabular}[c]{@{}l@{}} Machine assignment of the operation in the solution of... \\ \quad ... the previous RHO iteration ($m(O_{j, k}) \in \{0, ... |\mathcal{M}-1|\}$ before normalization)\end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  prev\_duration \\ (-1 if not in\_overlap)\end{tabular} &  Operation's process duration given by the previous machine assignment $p_{j, k}^{m_{r-1}(O_{j, k})}$ \\
& \begin{tabular}[c]{@{}l@{}}  alt\_avg\_dur \\ (-1 if not in\_overlap)\end{tabular} & \begin{tabular}[c]{@{}l@{}} Average duration of all other machines ...\\
\quad ... (not prev\_machine) to process the operation \end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  alt\_std\_dur \\ (-1 if not in\_overlap)\end{tabular} & \begin{tabular}[c]{@{}l@{}} Standard deviation of duration of all other machines ...\\
\quad ... (not prev\_machine) to process the operation \end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  alt\_min\_dur \\ (-1 if not in\_overlap)\end{tabular} & \begin{tabular}[c]{@{}l@{}} Minimum duration of all other machines ...\\
\quad ... (not prev\_machine) to process the operation \end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  alt\_max\_dur \\ (-1 if not in\_overlap)\end{tabular} & \begin{tabular}[c]{@{}l@{}} Maximum duration of all other machines ...\\
\quad ... (not prev\_machine) to process the operation \end{tabular}
\\[-1em]   \\ \hline \\[-1em]
\multirow{9}{*}{\textbf{Machines}} & machine\_start\_time  & \begin{tabular}[c]{@{}l@{}} The earliest start time of the machine $m$, given by the latest process ... \\ \quad ... end time of all executed operations assigned to machine $m$
\end{tabular}   \\
& num\_overlap    & \begin{tabular}[c]{@{}l@{}} Number of overlapping operations assigned to the machine $m$ ... \\ \quad ...  in the solution of the previous RHO iteration $\sum_{O \in \mathcal{O}_{overlap, r}} \mathds{1}\{m_{r-1}(O) = m\}$ \end{tabular}  \\[-1em] \\
\cline{2-3} \\[-1em]
& \begin{tabular}[c]{@{}l@{}} avg\_delay \\ (-1 if num\_overlap is 0) \end{tabular}   & \begin{tabular}[c]{@{}l@{}} Average delay of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration\end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  std\_delay \\ (-1 if num\_overlap is 0) \end{tabular} & \begin{tabular}[c]{@{}l@{}} Standard deviation of the delay of overlapping operations assigned to ... \\ \quad ... the machine in the solution of the previous RHO iteration\end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  max\_delay \\ (-1 if num\_overlap is 0) \end{tabular}    & \begin{tabular}[c]{@{}l@{}} Maximum delay of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration\end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  min\_delay \\ (-1 if num\_overlap is 0) \end{tabular} & \begin{tabular}[c]{@{}l@{}} Minimum delay of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration\end{tabular} \\
 \\[-1.3em]  \bottomrule
\end{tabular}
}
\end{table*}
\begin{table*}[!h]
\centering
\caption{Additional Input Features for the Total Start and End Delay Objective.} \label{appendix_tab:input_feature_2}
\scalebox{0.8}{
\begin{tabular}{cll}
\toprule\\[-1.3em]
\textbf{Type} & \multicolumn{1}{l}{\textbf{Feature}} & \multicolumn{1}{l}{\textbf{Description}}   \\[-1em] \\ \hline \\[-1em]
\multirow{5}{*}{\textbf{Operations}}     & ops\_target\_due\_time    & The target due time $t_{j, k}$ of the operation $O_{j, k}$ \\[-1em]  \\
\cline{2-3} \\[-1em]
& \begin{tabular}[c]{@{}l@{}}  prev\_start \\ (-1 if not in\_overlap)\end{tabular}   & \begin{tabular}[c]{@{}l@{}} Process start time of the operation in the solution of ... \\ \quad ... the previous RHO iteration $\pi_{r-1}(O_{j, k})$ \end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  prev\_end \\ (-1 if not in\_overlap)\end{tabular}   & \begin{tabular}[c]{@{}l@{}} Process end time of the operation in the solution of ... \\ \quad ... the previous RHO iteration $\pi_{t, r-1}(O_{j, k}) = \pi_{r-1}(O_{j, k}) + p_{j, k}^{m_{r-1}(O_{j, k})}$ \end{tabular} \\ 
 \\[-1.3em]  \bottomrule
\end{tabular}
}
\end{table*}


\begin{table*}[!htb]
\centering
\caption{Additional Input Features for Observation Noise: given the solution from the previous RHO iteration, we \textit{re-evaluate} the delay, duration, end time of the overlapping operation based on the noisy observation  at the current RHO iteration.} \label{appendix_tab:input_feature_3}
\scalebox{0.8}{
\begin{tabular}{cll}
\toprule\\[-1.3em]
\textbf{Type} & \multicolumn{1}{l}{\textbf{Feature}} & \multicolumn{1}{l}{\textbf{Description}}   \\[-1em] \\ \hline \\[-1em]
\multirow{6}{*}{\textbf{Operations}}     & \begin{tabular}[c]{@{}l@{}}  prev\_duration\_reeval \\ (-1 if not in\_overlap)\end{tabular}   & \begin{tabular}[c]{@{}l@{}} Currently observed process duration of the operation $O$ ... \\ \quad ... (given the machine assignment from the previous RHO iteration)\end{tabular} \\[-1em] \\
& \begin{tabular}[c]{@{}l@{}}  prev\_end\_reeval \\ (-1 if not in\_overlap)\end{tabular}   & \begin{tabular}[c]{@{}l@{}} Process end time of the operation (given the machine ... \\ \quad ... assignment from the previous RHO iteration), \\
\quad ... \textit{reevaluated} based on the current observed process duration  \end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  prev\_delay\_reeval \\ (-1 if not in\_overlap)\end{tabular}   & \begin{tabular}[c]{@{}l@{}} Delay of the operation (given the machine ... \\ \quad 
... assignment from the previous RHO iteration) ... \\ \quad ... , \textit{reevaluated} based on the current observed process duration \end{tabular} \\
\hline \\[-1em]
\multirow{9}{*}{\textbf{Machines}} & \begin{tabular}[c]{@{}l@{}} avg\_delay\_reeval \\ (-1 if num\_overlap is 0) \end{tabular}   & \begin{tabular}[c]{@{}l@{}} Average delay of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration, ... \\ \quad ... , \textit{reevaluated} based on the current observed process duration \end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  std\_delay\_reeval \\ (-1 if num\_overlap is 0) \end{tabular} & \begin{tabular}[c]{@{}l@{}} Standard deviation of the delay of overlapping operations assigned to ... \\ \quad ... the machine  in the solution of the previous RHO iteration, ... \\ \quad ... , \textit{reevaluated} based on the current observed process duration\end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  max\_delay\_reeval \\ (-1 if num\_overlap is 0) \end{tabular}    & \begin{tabular}[c]{@{}l@{}} Maximum delay of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration, ... \\ \quad ... , \textit{reevaluated} based on the current observed process duration\end{tabular}  \\
& \begin{tabular}[c]{@{}l@{}}  min\_delay\_reeval \\ (-1 if num\_overlap is 0) \end{tabular} & \begin{tabular}[c]{@{}l@{}} Minimum delay of overlapping operations assigned to the machine ... \\ \quad ...  in the solution of the previous RHO iteration ... \\ \quad ... , \textit{reevaluated} based on the current observed process duration\end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  machine\_end\_time \\ (-1 if num\_overlap is 0) \end{tabular} & \begin{tabular}[c]{@{}l@{}} Maximum process end time of overlapping operations ... \\ \quad ... assigned to the machine in the solution of the previous RHO iteration, ... \\ \quad ... , based on the previous iteration's observed process duration\end{tabular} \\
& \begin{tabular}[c]{@{}l@{}}  machine\_end\_time\_reeval \\ (-1 if num\_overlap is 0) \end{tabular} & \begin{tabular}[c]{@{}l@{}} Maximum process end time of overlapping operations  ... \\ \quad ... assigned to the machine in the solution of the previous RHO iteration, ... \\ \quad ... , \textit{reevaluated} based on the current observed process duration\end{tabular} \\

 \\[-1.3em]  \bottomrule
\end{tabular}
}
\end{table*}



\clearpage
\newpage
\subsection{Architecture, train and evaluation setup.} \label{appendix_sec:architecture}
\begin{table*}
\begin{minipage}{.65\linewidth}
\centering
\caption{\textbf{Architecture hyperparameters.} The input dimensions $(d_o, d_m) = (15, 11), (18, 13), (16, 6), (19, 6), (22, 12)$ for the five settings detailed in Table~\ref{appendix_tab:input_feature_makespan},~\ref{appendix_tab:input_feature_makespan_breakdown}, ~\ref{appendix_tab:input_feature_2} and~\ref{appendix_tab:input_feature_3}.}
\scalebox{0.9}{
\begin{tabular}{cccc}
\toprule
Input Dimension &                                       & MLP Layers   & 2                       \\ \\[-0.85em]
Operation $|\mathcal{O}_{plan, r}| \times d_o$                                                    & $\mathbb{R}^{(H-S)\times d_o}$         & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Activation \end{tabular}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}ReLU \end{tabular}}   \\
Machine $|\mathcal{T}| \times d_m$                                                           & $\mathbb{R}^{|\mathcal{T}|\times d_m}$ &    &                      \\ \\[-0.7em]
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Embedding \\ dimension $d_{hidden}$\end{tabular}} & \multirow{2}{*}{64}                   & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Output\\ Dimension\end{tabular}}    & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}$\mathcal{R}^{(H-S)\times 1}$ \end{tabular}} \\
&    &      &    \\ \\[-0.85em]
\bottomrule
\end{tabular}
}
\label{appendix_tab:hyper1}
\end{minipage}%
\hspace*{\fill} 
\begin{minipage}{.3\linewidth}
\centering
\caption{\textbf{Training hyperparameters.}}
\begin{tabular}{cc}
\toprule % from booktabs package
Optimizer & Adam \\ [-0.85em] \\ 
Learning rate & $10^{-3}$  \\ [-0.85em] \\
Batch size & 64 \\ [-0.85em]\\
\begin{tabular}[c]{@{}c@{}}Positive Label \\ Weight $w_{pos}$\end{tabular} & 0.5 \\
\begin{tabular}[c]{@{}c@{}}Num. of \\ Gradient Steps\end{tabular}   & $5\times 10^5$ \\
\bottomrule
\end{tabular} \label{appendix_tab:hyper2}
\end{minipage} 
\end{table*}


We use the neural architecture $f_\theta$ in Fig.~\ref{fig:main_architecture} to identify the fixed operation subset $\mathcal{O}_{fix, r}$.
The network takes as input a set of input features associated with each operation and machine, with the aggregated size $\mathbb{R}^{|\mathcal{O}_{plan, r}|\times d_o}$ and $\mathbb{R}^{|\mathcal{T}|\times d_m}$, and outputs the predicted probability $f_\theta(\mathbf{s}_r) \in [0,1]^{|\mathcal{O}_{overlap, r}|}$ of whether each overlapping operation $O \in \mathcal{O}_{overlap, r}$ should be included in $\mathcal{O}_{fix, r}$. The architecture consists of the following four main components: 
\begin{enumerate}[leftmargin=0.6cm,label={(\arabic*)}]
    \item \textbf{Input Embedding}: We first embed the input vector of the operations $\mathcal{O}_{plan, r} = \mathcal{O}_{overlap, r} \cup \mathcal{O}_{new, r}$ and machines $\mathcal{T}$, each with a input dimension of $\mathbb{R}^{d_o}$ and $\mathbb{R}^{d_m}$, into hidden representations, each with a hidden dimension of $\mathbb{R}^{d_{hidden}}$. We use two separate MLPs for the operations and machines.
     \item \textbf{Machine/Operation Concatenation}: We then concatenate the hidden feature of each operation $O \in \mathcal{O}_{plan, r}$ with the hidden feature of the previously assigned machine $m_{r-1}(O)$ (the local feature), and a global feature obtained by a mean pooling on the hidden features from all operations and machines. The concatenation results in a hidden dimension of $\mathbb{R}^{3\cdot d_{hidden}}$ for each operation, and we apply another MLP to project the dimension down to $\mathbb{R}^{d_{hidden}}$. 
    % \item \textbf{Overlap/New Operation Cross Attention}: We then perform a Multi-head Cross Attention between the overlapping operations $\mathcal{O}_{overlap, r}$ (the queries $Q$) and the new operations $\mathcal{O}_{new, r}$ (the keys $K$ and values $V$), and we also include a residual connection for the overlapping operations. This results in a hidden dimension of $\mathbb{R}^{d_{hidden}}$ for each overlapping operation.
    \item \textbf{Output}: Lastly, we pass the hidden feature of each overlapping operation $\mathcal{O}_{overlap, r}$ through another MLP, which outputs the predicted probability that each operation $O \in \mathcal{O}_{overlap, r}$ should be included in $\mathcal{O}_{fix, r}$.
\end{enumerate}

We train the proposed architecture with Adam optimizer with a learning rate of $1e^{\text{-}3}$ and a batch size of $64$ for $500$ epochs with around $5\times 10^5$ gradient steps. All hyperparameters are selected on the validation set and frozen before evaluating on the test set. Table~\ref{appendix_tab:hyper1} and~\ref{appendix_tab:hyper2} provide a list of hyperparameters. 

\paragraph{Training and Evaluation Setup.} 
For each FJSP setting, we collect a small set $\mathcal{K}_{ps}$ of $10$ instances for parameter search on all RHO methods (default, baseline and learning), and a large training set $\mathcal{K}_{train}$ of $450$ instances for neural network training. By default, we hold out a validation set $\mathcal{K}_{val}$ of $20$ instances and a test set $\mathcal{K}_{test}$ of $100$ instances each. We collect data, train, validate and test all methods on a distributed compute cluster using nodes equipped with 48 Intel AVX512 CPUs. A Nvidia Volta V100 GPU is used to train all neural networks. The model training time is within $12$ hours for all FJSP settings. The parameter search for \textit{all} RHO methods (Appendix~\ref{appendix_sec:rho_param_search}) requires approximately $48$-$96$ hours for each FJSP setting in the experiment Sec.~\ref{sec:experiment}, based on the problem size. Furthermore, as the FJSP constraint programming solver CP-SAT allows multi-processing, we use $12$ CPUs when solving each RHO subproblem ($P_r$ / $\hat{P}_r$) for all RHO methods (Default, Baselines and Learning) for both training and testing; we also use $12$ CPUs to evaluate the Full FJSP baseline. When collecting training labels, we solve each unrestricted subproblem $P_r$ five times ($Q = 5$); the training data collection takes around $24$-$72$ hours for each FJSP setting based on the problem size. In the experiment section, we report the solve time for different methods on the test set $\mathcal{K}_{test}$  (Table~\ref{tab:offline}, Table~\ref{tab:detailed_result}, Fig.~\ref{fig:additional experiment}, and Appendix~\ref{appendix_sec:additional_results}). 



\newpage


\clearpage
\newpage
\subsection{Experimental Details}
\label{appendix_sec:exp_details}
\subsubsection{FJSP Instance Distribution, Machine Breakdown and Observation Noise.} \label{appendix_sec:instance_dist}

\textbf{Makespan-based Data Distribution.}

We follow the a similar data distribution as in the previous learning literature~\citep{wang2023flexible} but significantly increase the FJSP problem sizes from $200$ operations (previously) to up to $2000$ operations (this work). Each FJSP instance is generated by sampling the following attributes:

\begin{itemize}
    \item $(n_{machines}, n_{jobs}, n_{operations\_per\_job})  =(|\mathcal{M}|, |\mathcal{T}|, |\mathcal{O} / \mathcal{T}|)$: we fix $|\mathcal{M}| = 10, |\mathcal{T}| = 20$ and consider a range of $n_{operations\_per\_job} \in \{30, 40, 60, 100\}$. That is, we have  $ (|\mathcal{M}|, |\mathcal{T}|, |\mathcal{O} / \mathcal{T}|) \in \{(10, 20, 30), (10, 20, 40), (10, 20, 60), (10, 20, 100)\}$, with the total number of operations ranging from $600$ to $2000$. 
    \item Compatible Machines $\mathcal{M}_{j, k}$: For each operation $O_{j, k} \in \mathcal{O}$, we randomly select a subset of machines $\mathcal{M}_{j, k} \subseteq \mathcal{M}$ with size $|\mathcal{M}_{j, k} | \sim \text{Uniform}\{1, ..., |\mathcal{M}|\}$ as the compatible machines for the operation.
    \item Process Duration $p_{j, k}^{m}$: we sample the duration of operation $O_{j, k} \in \mathcal{O}$ processed by machine $m \in \mathcal{M}$ from a uniform distribution $U[1, 99]$.
\end{itemize}

\textbf{Machine Breakdown.}
As a step towards online / dynamics FJSP, ours experiments in Fig.~\ref{fig:additional experiment} (right) accounts for machine breakdowns during the RHO solution process. The intensity of machine breakdowns is determined by two factors: 1) the frequency of breakdowns 2) the proportion of unavailable machines during each breakdown. For each FJSP instance, we simulate a series of machine breakdown events represented by a set of time intervals $\{t^{b}_i\}_{i=1, 2, ...}$. For each breakdown event, we randomly sample a subset of machines $\mathcal{M}^{b}_i \subseteq \mathcal{M}$, which become unavailable during the event. Specifically, the first breakdown event starts at time $t^{b}_0 \sim U[50, 150]$ and lasts for a duration of $dur$. Each subsequent breakdown occurs at time $t^{b}_i \sim t^{b}_{i-1} + dur + U[w_{lb}, w_{ub}]$ and similarly lasts for a duration of $dur$. We sample the subset of breakdown machines $\mathcal{M}^{b}_i$ by selecting each machine in $\mathcal{M}$ i.i.d. with a probability $p^{b}$. In our experiments, we explore three levels of breakdown intensities : 1) \textbf{Low}: we set $dur = 100, w_{lb} = 400, w_{ub} = 600, p^{b} = 0.2$, 2)  \textbf{Mid}: we set $dur = 100, w_{lb} = 175, w_{ub} = 300, p^{b} = 0.35$, and 3)  \textbf{High}: we set $dur = 50, w_{lb} = 100, w_{ub} = 200, p^{b} = 0.5$. 

Following dynamic FJSP literature~\citep{zhang2017flexible}, we combine periodic RHO subproblem optimization with \textit{event-based rescheduling}: when a machine breakdown event starts or ends, we re-optimize the updated RHO subproblem using the updated machine availability. This event-based rescheduling affects (1) the RHO subproblem step size, which may be reduced due to breakdown-triggered re-optimizations. Specifically, for each RHO iteration, we execute the set of operations $\mathcal{O}_{exec, r}$ in order of their scheduled end times. If a breakdown occurs during an operation's execution window, we halt that operation and any subsequent ones, and reformulate the RHO subproblem with the updated set of the first $W$ unexecuted operations, incorporating the updated machine availability for re-optimization. (2) If all compatible machines for an operation are down, we defer that operation, along with any subsequent operations in the same job, until the breakdown ends. 

Implementation-wise, (1) is formally described in Alg.~\ref{appendix_alg:get_step_operation_machine_breakdown}, which replaces Alg.~\ref{appendix_alg:get_step_operation} for the RHO operation execution step; (2) is formally described in Alg.~\ref{appendix_alg:get_plan_operation_machine_breakdown}, which replaces Alg.~\ref{appendix_alg:get_plan_operation} to construct each RHO subproblem.

\textbf{Delay-based Data Distribution.} Following common FJSP instance generation procedure in the literature~\citep{behnke2012test}, we generate each FJSP instance by sampling the following attributes:
\begin{itemize}
    \item $(n_{machines}, n_{jobs}, n_{operations\_per\_job})  =(|\mathcal{M}|, |\mathcal{T}|, |\mathcal{O} / \mathcal{T}|)$: we consider a series of large scale settings $\{(25, 25, \slifinalblue{24}), (30, 30, \slifinalblue{24}), (35, 35, \slifinalblue{30}), (40, 40, 40)\}$, with the total number of operations ranging from $\slifinalblue{600}$ to $\slifinalblue{1600}$. We further set the compatible machines $\mathcal{M}_{j, k} = \mathcal{M}$ for all operations $O \in \mathcal{O}$. 
    \item Process Duration $p_{j, k}^{m}$: we sample the duration of operation $O_{j, k} \in \mathcal{O}$ processed by machine $m \in \mathcal{M}$ from a uniform distribution $U[l_{low}, l_{high}]$, with $l_{low} \sim \text{Uniform}(\{3, 5, 7, 9\})$ and $l_{high} \sim l_{low} + \text{Uniform}(\{9, 12, 15, 18, 21\})$, resulting in the duration range $p_{j, k}^{m} \in [3, 30]$;
    \item Release time: we sample the release time for all operations $\{O_{j, k}\}_{k=1}^{n_j}$ within each job $j$ as $s_{j, 1} \sim U([0, 15])$ and $s_{j, k} = s_{j, k-1} + U([0, 15])$ for all $k > 1$;
    \item Target end time: we sample the target end time for each operation $O_{j, k}$ as $t_{j, k} \sim s_{j, k} + U([0, 30])$; this attribute is used when the objective contains total end delay (Sec.~\ref{sec:experiment_additional_result}).
\end{itemize}

\textbf{Observation noise.} In the observation noise setting (Sec.~\ref{sec:experiment_additional_result}), we have noisy observation of the process duration $p_{j, k}^{m}$. Specifically, we generate the clean (true) process duration $p_{j, k}^{m}$ for all operations and machines (which is only partially observed) following the procedure described above. Then, at each RHO iteration, we perturb process duration as follows: consider the operations $\mathcal{O}_{plan, r} = \{O^{(1)}, ..., O^{(H)}\}$ (ordered by their release times) in the current iteration's planning horizon. We assume perfect observation of the first $S \leq H$ operations with earlier release times $\mathcal{O}_{clean, r} =  \{O^{(1)}, ..., O^{(S)}\}$, and we have noisy observation for a randomly selected subset $\mathcal{O}_{perturb, r}$ of the remaining operations with later release times, where we select each operation in $\mathcal{O}_{plan, r} \backslash \mathcal{O}_{clean, r}$ to be included in $\mathcal{O}_{perturb, r}$ uniformly at random with a probability of $\epsilon = 20\%$. We then set the noisy observation of the process duration for each operation $O_{j, k} \in \mathcal{O}_{plan, r}$ by machine $m \in \mathcal{M}_{j, k}$ at the current RHO iteration $r$ as:
\begin{equation*}
    \tilde{p}_{j, k}^{m, r} = \begin{cases}
        p_{j, k}^{m} & \text{if operation } O_{j, k} \in \mathcal{O}_{clean, r} \\
        \text{clip}(p_{j, k}^{m} + U[-5, 5], 3, 30) & \text{if operation } O_{j, k} \in \mathcal{O}_{perturb, r}.
    \end{cases}
\end{equation*}
Notably, we may have different noisy observations for the same overlapping operation in different RHO iterations. That is, we may have $\tilde{p}_{j, k}^{m, r-1} \neq \tilde{p}_{j, k}^{m, r}$ for the same operation $O_{j, k}$ and machine $m$.

\textbf{Operation execution under observation noise.} After obtaining the solutions $(\tilde{m}_r, \tilde{\pi}_{r})$ to the noisy FJSP subproblem, we execute a subset of $S$ operation and update the final full FJSP solution $(m, \pi)$ as follows (replacing Line 17-21 in Alg.~\ref{appendix_alg:main} with the procedure in Alg.~\ref{appendix_alg:get_step_operation_perturb}): We first determine $\mathcal{O}_{step, r}$ as the $S$ operations with the earliest process start time  according to the noisy solution $\tilde{\pi}_{r}$. Then, for each operation $O_{j, k} \in \mathcal{O}_{step, r}$ (ordered by the solution start time $\tilde{\pi}_{r}(O_{j, k})$), we assign the operation to the machine $m(O_{j, k}) := \tilde{m}_{r}(O_{j, k})$, which takes a \textit{true duration} of $p_{j, k}^{\tilde{m}_{r}(O_{j, k})}$ process the operation. Due to discrepancy between observed duration at planning and the actual duration at execution, the operation may not be able to start at its solution start time $\tilde{\pi}_{r}(O_{j, k})$ given by the solution. We hence further adjust the actual start time $\pi(O_{j, k})$ at execution to maintain solution feasibility. The detailed execution procedure is provided in Alg.~\ref{appendix_alg:get_step_operation_perturb}. 

\begin{algorithm}[H]
\SetAlgoLined
\KwIn{Operations $\mathcal{O} = \{O^{(1)}, ..., O^{(|\mathcal{O}|)}\} \textit{ ordered based on the precedence order or release time (Table~\ref{appendix_tab:notation_fjsp})}$, RHO planning window size ($H$ operations), RHO current iteration $r$, executed solutions $(m, \pi)$}
\KwOut{Operations in the current RHO planning window $\mathcal{O}_{plan, r}$}
$\mathcal{O}_{plan, r} \leftarrow []; i \leftarrow 0$\\[0.1cm]
$Ignored\_Jobs = Set()$ \\
\tcp{select the first $H$ non-executed operations based on the sorted order}
\While{$|\mathcal{O}_{plan, r}| < H$ and $i < |\mathcal{O}|$}{
    \If{$O^{(i)} \notin (m, \pi)$}{ 
        \If{All compatible machines of $O^{(i)}$ are down}{
            $Ignored\_Jobs.add(Job\_of\_O^{(i)}))$\\
            continue
        }
        \If{$Job\_of\_O^{(i)} \in Ignored\_Jobs$}{
            continue
        }
        $\mathcal{O}_{plan, r}.append(O^{(i)})$
    }
    $i \leftarrow i + 1$
}
\caption{GetPlanOperations Under Machine Breakdown}
\label{appendix_alg:get_plan_operation_machine_breakdown}
\end{algorithm}

\begin{algorithm}[H]
\SetAlgoLined
\KwIn{Operations in the current window $\mathcal{O}_{plan, r}$, RHO execution step size ($S$ operations), RHO current iteration $r$, solution  $\Pi_r = (m_r, \pi_{s,r})$ of the $r^{th}$ FJSP subproblem}
\KwOut{Operations executed after the $r^{th}$ RHO iteration $\mathcal{O}_{step, r}$}
$\tilde{\mathcal{O}}_{plan, r} \leftarrow \text{ Sort } \mathcal{O}_{plan, r} $ by the process start time $\{\pi_{s,r}(O^{(i)})\}_{O^{(i)} \in \mathcal{O}_{plan, r}}$ \\[0.1cm]
$\mathcal{O}_{step, r} \leftarrow []$\\
\For{$O_{j, k} \in \mathcal{O}_{step, r}$ (sorted by the solution process start time) } {
    \If{machine breakdown starts or ends during the operation's execution window $[\pi(O_{j, k}), \pi_t(O_{j, k})]$}{
        \tcp{End the current RHO subproblem. Do not execute any more operations.}
        break
    }\Else{
        $\mathcal{O}_{step, r}.append(O_{j, k})$
    }
}
% $\mathcal{O}_{step, r} \leftarrow \{\tilde{\mathcal{O}}_{plan, r}^{(1)}, ..., \tilde{\mathcal{O}}_{plan, r}^{(S)}\}$
\caption{Execute Operations Under Machine Breakdown}
\label{appendix_alg:get_step_operation_machine_breakdown}
\end{algorithm}



% \in \{10\%, 20\%, 30\%\}
\begin{algorithm}
\SetAlgoLined
\KwIn{Operations in the current window $\mathcal{O}_{plan, r}$; RHO execution step size ($S$ operations); RHO current iteration $r$; (partial) solution $\Pi = (m, \pi)$ of the full FJSP problem instance $P$ before the current iteration $r$; solution $\tilde{\Pi}_r = (\tilde{m}_r, \tilde{\pi}_{r})$ of the $r^{th}$ FJSP subproblem under the noisy observation; clean process duration $\{p_{j, k}^{m}\}_{\substack{m \in \mathcal{M} \\ O_{j, k} \in \mathcal{O}_{overlap, r} }}$}
\KwOut{Updated (partial) solution $\Pi = (m, \pi)$ of the FJSP problem instance $P$ after the current RHO iteration $r$ based on the clean process duration}

\tcp{Find executed operations for the current RHO iteration, using $(\tilde{m}_r, \tilde{\pi}_{r})$}
$\tilde{\mathcal{O}}_{plan, r} \leftarrow \text{ Sort } \mathcal{O}_{plan, r} $ by the process start time $\{\tilde{\pi}_{r}(O^{(i)})\}_{O^{(i)} \in \mathcal{O}_{plan, r}}$ \\
$\mathcal{O}_{step, r} \leftarrow \{\tilde{\mathcal{O}}_{plan, r}^{(1)}, ..., \tilde{\mathcal{O}}_{plan, r}^{(S)}\}$

\tcp{Auxiliary variables to track solution feasibility}
machine\_end\_time $\leftarrow$ \{$alt$: $\max\limits_{\substack{O_{j, k} \in (m, \pi), \\ m(O_{j, k}) = alt}} \pi_t(O_{j, k}) $ \quad \text{for} $each\; machine\;alt \in \mathcal{M}$\} \\[0.1cm]
job\_end\_time $\leftarrow$ \{$j$: $\max\limits_{\substack{O_{j, k} \in (m, \pi)}}\pi_t(O_{j, k}) $ \quad \text{for} $each\; job\;j \in \mathcal{T}$\}

\tcp{Fix the final solution for the executed operations based on the clean process duration}
\For{$O_{j, k} \in \mathcal{O}_{step, r}$ (sorted by the solution process start time) } {
    $m(O_{j, k}) \leftarrow \tilde{m}_r(O_{j, k})$
    
    \tcp{Update the process start time to the earliest feasible start time}
    $\pi(O_{j, k}) \leftarrow \max(\tilde{\pi}_{r}(O_{j, k}),\;\text{machine\_end\_time}[m(O_{j, k})],\;\text{job\_end\_time}[j])$ 
    
    \tcp{Re-evaluate the process end time based on the clean process duration}
    $\pi_t \leftarrow \pi(O_{j, k}) + p_{j, k}^{m(O_{j, k})}$ \\[0.1cm]
    
    \tcp{Update the auxiliary variables to track feasibility}
    $\text{machine\_end\_time}[m(O_{j, k})] \leftarrow \max\big(\text{machine\_end\_time}[m(O_{j, k})], \pi_t\big)$ \\
    $\text{job\_end\_time}[j] \leftarrow \max\big(\text{job\_end\_time}[j], \pi_t\big)$ \\
}
\caption{Execute Operations Under Observation Noise}
\label{appendix_alg:get_step_operation_perturb}
\end{algorithm}

\clearpage
\newpage
\subsubsection{FJSP Formulation} \label{appendix_sec:fjsp_formulation}
\label{appendix_sec:fjsp_formulation}
\textbf{Decision Variables.} Given a FJSP problem instance
\begin{equation}
    \begin{aligned}
        P = (\mathcal{M}, \mathcal{T}, \mathcal{O}, & \text{ process duration } \{p_{j, k}^m\}_{\substack{O_{j, k} \in \mathcal{O}\\m\in \mathcal{M}_{j, k}}}, \\
        & \text{ (optional) release time } \{s_{j, k}\}_{O_{j, k} \in \mathcal{O}}, \\
        & \text{ (optional) target end time } \{t_{j, k}\}_{O_{j, k} \in \mathcal{O}})
    \end{aligned}
\end{equation}

% The FJSP problem can be formulated as follows:
% \begin{equation}
% \begin{aligned}
% \min\limits_{m, \pi, \pi_t} \quad & 
% \sum\limits_{O_{j, k} \in \mathcal{O}} \big|\pi(O_{j, k}) - s(O_{j, k})\big| \\
% s.t. \quad & // \text{ Machine assignment definition} \\
% \quad & m(O_{j, k}) \in \mathcal{M}_{j, k} \\
% \quad & // \text{ Operation end time definition} \\
% \quad & \pi_t(O_{j,k}) = \pi(O_{j, k}) + p_{j, k}^{m(O_{j, k})}\\[0.1cm]
% \quad  & // \text{ Operation precedence constraint} \\
% \quad & \pi_t(O_{j, k}) \leq \pi(O_{j, k+1}) 
% \quad \forall\; j \in \mathcal{T}, k \in \{1, ..., n_j-1\} \\[0.1cm]
% \quad & // \text{ Non-overlapping solution interval constraint}\\
% \quad & \text{ For each machine } i \in \mathcal{M}:\\
% \quad & \quad\quad \text{ For each operation pair } O_{j_1, k_1}, O_{j_2, k_2} \in \mathcal{O} \; s.t. \; m(O_{j_1, k_1}) = m(O_{j_2, k_2}) = i: \\
% \quad & \quad\quad\quad\quad (\pi_t(O_{j_1,k_1}), \pi_t(O_{j_2,k_2})) \cap (\pi_t(O_{j,k}), \pi_t(O_{j,k})) = \emptyset 
% \end{aligned}
% \end{equation}
The constraint programming formulation for the FJSP is obtained by introducing additional boolean variables denoting whether an operation is assigned to a machine\footnote{Our implementation is based on the CP-SAT's Official FJSP implementation \url{https://github.com/google/or-tools/blob/stable/examples/python/flexible_job_shop_sat.py}.}. That is, we define the following set of decision variables
\begin{equation}
\scalebox{0.9}{$
\begin{aligned}[b]
X = \Big(& \{\pi(O_{j, k})\}_{O_{j, k} \in \mathcal{O}}, \{dur(O_{j, k})\}_{O_{j, k} \in \mathcal{O}}, \{\pi_t(O_{j, k})\}_{O_{j, k} \in \mathcal{O}}, \; // \text{ process start time, duration, and end time}\\
& \{l_{alt}(O_{j, k})\}_{\substack{O_{j, k} \in \mathcal{O} \\ alt \in \mathcal{M}_{j, k}}}, \quad // \text{ boolean variable: whether } O_{j, k} \text{ is assigned to machine } alt \\
& \{\pi_{alt}(O_{j, k})\}_{\substack{O_{j, k} \in \mathcal{O} \\ alt \in \mathcal{M}_{j, k}}}, \quad // \text{ process start time if } O_{j, k} \text{ is assigned to machine } alt \\
& \{dur_{alt}(O_{j, k})\}_{\substack{O_{j, k} \in \mathcal{O} \\ alt \in \mathcal{M}_{j, k}}}, \quad // \text{ process duration if } O_{j, k} \text{ is assigned to machine } alt \\
& \{\pi_{t, alt}(O_{j, k})\}_{\substack{O_{j, k} \in \mathcal{O} \\ alt \in \mathcal{M}_{j, k}}}\Big) \quad // \text{ process end time if } O_{j, k} \text{ is assigned to machine } alt
\end{aligned}$
}
\label{appendix_eq:decision_variables}
\end{equation}
where the target end time and the decision variables related to the process end time are only used when the objective contains total end delay. From the above decision variables, the machine assignment of operation $O_{j, k}$ can be found as $m(O_{j, k}) = alt \in \mathcal{M}_{j, k}$ wher $l_{alt}(O_{j, k}) = 1$, and the process start time of the operation can be found as $\pi(O_{j, k})$.

\textbf{FJSP Full and Subproblem Formuation.} Given the above decision variables, the Constraint Programming (CP) formulation for the full FJSP problem $P$ is given in Alg.~\ref{appendix_alg:fjsp_cp_full}. 
\begin{itemize}[leftmargin=0.5cm]
    \item \textbf{Unrestricted Subproblem $P_r$}:  Given the set of operations in the current planning horizon $\mathcal{O}_{plan, r}$, we can obtain the the subproblem instance $P_r$ and the set of decision variables $X_r$ associated with the restricted operation set $\mathcal{O}_{plan, r}$. Then we use the same CP formulation as in Alg.~\ref{appendix_alg:fjsp_cp_full} on the decision variables $X_r$; we additionally introduce new constraints in  Alg.~\ref{appendix_alg:fjsp_cp_subp}, which requires operations in $\mathcal{O}_{plan, r}$ to be processed after all previously executed operations within the same job or the same machine.
    \item \textbf{Assignment-Based Restricted Subproblem $\hat{P}_r$}: Given a set of operations in the current planning horizon $\mathcal{O}_{plan, r}$, we follow the same CP formulation in Alg.~\ref{appendix_alg:fjsp_cp_full} and~\ref{appendix_alg:fjsp_cp_subp} as for the unrestricted subproblem $P_r$. Given the fixed operations $\mathcal{O}_{fix, r} \subseteq \mathcal{O}_{overlap, r}$, we further restrict the compatible machines for each fixed operation as the single machine from the previous RHO iteration's solution, i.e. we restrict $\mathcal{M}_{j, k} = \{m_{r-1}(O_{j, k)}\}$ for all operations $O_{j, k} \in \mathcal{O}_{fix, r}$.
\end{itemize}

% \begin{algorithm}
% % \SetAlgoLined
% \textbf{Decision Variables: } $X$ (see Eq.~\eqref{appendix_eq:decision_variables})\\[0.1cm]
% \textbf{Objective:}
% \begin{equation}
% \begin{aligned}
% \text{Makespan: } \quad & \min \limits_{X} \max\limits_{O_{j, k} \in \mathcal{O}} \pi_t(O_{j, k}) \\
% \text{Total start delay: } \quad & \min\limits_{X} \sum\limits_{O_{j, k} \in \mathcal{O}} \pi(O_{j, k}) - s_{j, k}\\
% \text{Total start and end delay: } \quad & \min\limits_{X} \sum\limits_{O_{j, k} \in \mathcal{O}} \pi(O_{j, k}) - s_{j, k} + \max(\pi_t(O_{j, k}) - t_{j, k}, 0)
% \end{aligned}
% \end{equation} \\
% \textbf{Constraints:} \\
% \tcp{Machine assignment definition for each operation}
% \For{each operation $O_{j, k} \in \mathcal{O}$}{ 
%     // Operation end time definition
%     \begin{equation}
%     \pi_t(O_{j,k}) = \pi(O_{j, k}) + dur(O_{j, k})
%     \end{equation}
%     \For{each possible machine assignment $alt \in \mathcal{M}_{j, k}$}{
%         // Operation duration definition for the machine assignment alternative $alt$ 
%         \begin{equation}
%         dur_{alt}(O_{j, k}) = p_{j, k}^{alt}
%         \end{equation}
%         // Operation end time definition for the machine assignment alternative $\alt$
%         \begin{equation}
%         \pi_{t, alt}(O_{j,k}) = \pi_{alt}(O_{j, k}) + dur_{alt}(O_{j, k})
%         \end{equation}
%         // Enforce the linking of the solution alternative with the actual solution if $alt$ is selected 
%         \begin{equation}
%         (\pi(O_{j,k}) = \pi_{alt}(O_{j, k})).\text{EnforceIf}(l_{alt}(O_{j, k}) = 1)
%         \end{equation}
%         \begin{equation}
%         (dur(O_{j,k}) = dur_{alt}(O_{j, k})).\text{EnforceIf}(l_{alt}(O_{j, k}) = 1)
%         \end{equation}
%         \begin{equation}
%         (\pi_t(O_{j,k}) = \pi_{t, alt}(O_{j, k})).\text{EnforceIf}(l_{alt}(O_{j, k}) = 1)
%         \end{equation}
%     }
%     // Only one machine assignment alternative can be selected 
%     \begin{equation}
%     ExactlyOne(\{l_{alt}(O_{j, k}) = 1\}_{alt \in \mathcal{M}_{j, k}})
%     \end{equation}
% }

% \tcp{Operation precedence constraints for each job}
% \For{each job $j \in \mathcal{T}$}{
%     \For{each operation $O_{j, k}$ with $1 \leq k \leq n_j$}{
%     \begin{equation}
%         \pi_t(O_{j, k}) \leq \pi(O_{j, k+1})
%     \end{equation}
%     }
% }
% \tcp{Non-overlapping Operation constraints on each machine}
% \For{each machine $alt \in \mathcal{M}$}{
%     \begin{equation}
%     \text{NoOverlap}\Big(\{\text{Interval}[\pi_{alt}(O_{j, k}), \pi_{t,alt}(O_{j,k})]\}_{O_{j, k} \in \mathcal{O}}\Big)
%     \end{equation}
% }
% \caption{FJSP Constraint Programming Formulation}
% \label{appendix_alg:fjsp_cp_full}
% \end{algorithm}

\begin{algorithm}
\caption{FJSP Constraint Programming Formulation}
\label{appendix_alg:fjsp_cp_full}
\SetAlgoLined
\DontPrintSemicolon

\textbf{Decision Variables:} \(X\) (see Eq.~\eqref{appendix_eq:decision_variables})\;

\textbf{Objective:}
\begin{equation}
\begin{aligned}
\text{Makespan: } \quad & \min \limits_{X} \max\limits_{O_{j, k} \in \mathcal{O}} \pi_t(O_{j, k}) \\
\text{Total start delay: } \quad & \min\limits_{X} \sum\limits_{O_{j, k} \in \mathcal{O}} \pi(O_{j, k}) - s_{j, k}\\
\text{Total start and end delay: } \quad & \min\limits_{X} \sum\limits_{O_{j, k} \in \mathcal{O}} \pi(O_{j, k}) - s_{j, k} + \max(\pi_t(O_{j, k}) - t_{j, k}, 0)
\end{aligned}
\end{equation}

\textbf{Constraints:}\;

\tcp{Machine assignment definition for each operation}
\For{each operation \(O_{j, k} \in \mathcal{O}\)}{ 
    \tcp{Operation end time definition}
    \begin{equation}
    \pi_t(O_{j,k}) = \pi(O_{j, k}) + dur(O_{j, k})
    \end{equation}

    \For{each possible machine assignment \(alt \in \mathcal{M}_{j, k}\)}{
        \tcp{Operation duration definition for machine assignment}
        \begin{equation}
        dur_{alt}(O_{j, k}) = p_{j, k}^{alt}
        \end{equation}

        \tcp{Operation end time definition for alternative assignment}
        \begin{equation}
        \pi_{t, alt}(O_{j,k}) = \pi_{alt}(O_{j, k}) + dur_{alt}(O_{j, k})
        \end{equation}

        \tcp{Enforce solution linking if \(alt\) is selected}
        \begin{equation}
        (\pi(O_{j,k}) = \pi_{alt}(O_{j, k})).\text{EnforceIf}(l_{alt}(O_{j, k}) = 1)
        \end{equation}

        \begin{equation}
        (dur(O_{j,k}) = dur_{alt}(O_{j, k})).\text{EnforceIf}(l_{alt}(O_{j, k}) = 1)
        \end{equation}

        \begin{equation}
        (\pi_t(O_{j,k}) = \pi_{t, alt}(O_{j, k})).\text{EnforceIf}(l_{alt}(O_{j, k}) = 1)
        \end{equation}
    }

    \tcp{Only one machine assignment alternative can be selected}
    \begin{equation}
    ExactlyOne(\{l_{alt}(O_{j, k}) = 1\}_{alt \in \mathcal{M}_{j, k}})
    \end{equation}
}

\tcp{Operation precedence constraints for each job}
\For{each job \(j \in \mathcal{T}\)}{
    \For{each operation \(O_{j, k}\) with \(1 \leq k \leq n_j\)}{
        \begin{equation}
        \pi_t(O_{j, k}) \leq \pi(O_{j, k+1})
        \end{equation}
    }
}

\tcp{Non-overlapping Operation constraints on each machine}
\For{each machine \(alt \in \mathcal{M}\)}{
    \begin{equation}
    \text{NoOverlap}\Big(\{\text{Interval}[\pi_{alt}(O_{j, k}), \pi_{t,alt}(O_{j,k})]\}_{O_{j, k} \in \mathcal{O}}\Big)
    \end{equation}
}
\end{algorithm}


% \begin{algorithm}
% \caption{Additional Constraints for FJSP RHO Subproblems $P_r$}
% \label{appendix_alg:fjsp_cp_subp}
% \SetAlgoLined
% \textbf{Decision Variables: } $X_r$ for the  operation set $\mathcal{O}_{overlap, r}$ in the planning horizon (see Eq.~\eqref{appendix_eq:decision_variables})\\[0.1cm]
% \textbf{Solutions of Previously Executed Operations: } $(m, \pi)$ \\[0.1cm]
% \textbf{Additional Constraints:}
% \\[0.1cm]// Compliance with previously executed operations (if exists) \\
% \If{$(m, \pi)$ is not empty}{
%     prev\_machine\_end\_time $\leftarrow$ \{$alt$: $\max\limits_{\substack{O_{j, k} \in (m, \pi), \\ m(O_{j, k}) = alt}}\pi_t(O_{j, k}) $ \quad \text{for} $each\; machine\;alt \in \mathcal{M}$\} \\[0.1cm]
%     prev\_job\_end\_time $\leftarrow$ \{$j$: $\max\limits_{\substack{O_{j, k} \in (m, \pi)}}\pi_t(O_{j, k}) $ \quad \text{for} $each\; job\;j \in \mathcal{T}$\}
%     \\[0.1cm]
%     \For{each operation $O_{j, k} \in \mathcal{O}$}{
%         \\[0.2cm]
%         // Each operation should be processed after all executed operations within the same job \\\\[0.1cm]
%         $\pi(O_{j, k}) \geq \text{prev\_job\_end\_time}[j] $ \\[0.2cm]
%         // Each operation should be processed after all executed operations on the same machine\\
%         \\[0.1cm]
%         \For{each possible machine assignment $alt \in \mathcal{M}_{j, k}$}{
%             $\pi_{alt}(O_{j, k}) \geq \text{prev\_machine\_end\_time}[alt]$
%         }
%     }
% }
% \end{algorithm}
\begin{algorithm}
\caption{Additional Constraints for FJSP RHO Subproblems \(P_r\)}
\label{appendix_alg:fjsp_cp_subp}
\SetAlgoLined
\DontPrintSemicolon

\textbf{Decision Variables:} \(X_r\) for the operation set \(\mathcal{O}_{overlap, r}\) in the planning horizon (see Eq.~\eqref{appendix_eq:decision_variables})\;
\textbf{Solutions of Previously Executed Operations:} \((m, \pi)\)\;
\textbf{Additional Constraints:}\;

\tcp{Compliance with previously executed operations (if exists)}
\If{\((m, \pi)\) is not empty}{
    prev\_machine\_end\_time \(\leftarrow\) \(\{ \text{alt}: \max\limits_{\substack{O_{j, k} \in (m, \pi), \\ m(O_{j, k}) = \text{alt}}} \pi_t(O_{j, k}) \}\) for each machine \(\text{alt} \in \mathcal{M}\)\;
    prev\_job\_end\_time \(\leftarrow\) \(\{ j: \max\limits_{\substack{O_{j, k} \in (m, \pi)}} \pi_t(O_{j, k}) \}\) for each job \(j \in \mathcal{T}\)\;

    \For{each operation \(O_{j, k} \in \mathcal{O}\)}{
        \tcp{Ensure processing after all executed operations within the same job}
        \(\pi(O_{j, k}) \geq \text{prev\_job\_end\_time}[j] \)\;
        
        \tcp{Ensure processing after all executed operations on the same machine}
        \For{each possible machine assignment \(alt \in \mathcal{M}_{j, k}\)}{
            \(\pi_{alt}(O_{j, k}) \geq \text{prev\_machine\_end\_time}[alt]\)\;
        }
    }
}
\end{algorithm}



\newpage
\clearpage
\subsubsection{Baseline Details}
\label{appendix_sec:offline}


\paragraph{Traditional solver w/o decomposition} The CP-SAT and Genetic Algorithm (GA) results are, respectively, obtained by applying the competitive constraint programming solver OR-Tools CP-SAT~\citep{cpsatlp}, and the widely used hybrid genetic algorithm with tabu search metaheuristics~\citep{li2016effective}, to solve the full FJSPs without decomposition. These comparisons emphasize the significance of decomposition in solving long-horizon FJSP.


\paragraph{Learning-based solver w/o decomposition.} For each setting, we train a DRL model~\citep{wang2023learning} on the same set of 450 training instances as L-RHO and also on a larger set of 20,000 instances, following the original paper\footnote{We use the publicly available implementation from the authors at \url{https://github.com/wrqccc/FJSP-DRL}.}. At inference time, we decode the DRL model using Greedy and Sampling strategies (100 and 500 samples).

\begin{figure}[!t]
     \centering
     \includegraphics[width=0.7\textwidth]{figures/lns.png}
     \caption{The Large Neighborhood Search (LNS) Pipeline from~\citep{pacino2011large}. (a) At the $r^{th}$ LNS iteration, we start with a complete solution $\Pi$ for the full FJSP. The solution at the first iteration is given by solving the full FSJP for a short duration (30s). (b) We construct a FJSP subproblem by selecting a subset of FJSP operations to update their solution. Two subproblem selection methods are considered based on time and machine based decomposition methods. When constructing the FJSP subproblem, we include additional constraints on the operations start time and each machines available time so that the subproblems solution is compatible with the solution of the non-selected FJSP operations. (c) We feed the FJSP subproblem into a subsolver to get a new solution $\Pi_r$. The old solution of the subproblem is given to warm start the solve, as it empirically improves the performance. (d) We update the complete solution $\Pi$ with the new subproblems solution $\Pi_r$, and repeat (a)-(d).}
    \label{appendix_fig:offline_lns}
\end{figure}

\paragraph{Traditional solver w/ decomposition.} Fig.~\ref{appendix_fig:offline_lns} provides an illustration of the Large Neighborhood Search (LNS) algorithm that we compare as a baseline in the offline setting. In particular, \citep{pacino2011large} introduces Time Decomposition and Machine Decomposition to select different LNS neighborhoods for large-scale FJSP. The implementation details for each LNS iteration are as follows:

\begin{itemize}[leftmargin=0.5cm]
    \item The \textbf{ARD-LNS (Time-based)} leverages temporal locality to select a random start and end time of a contiguous time interval to define the LNS subproblem. It imposes additional machine availability constraints and operation precedence constraints in defining the subproblem. The former restricts the start and end time of each machine to be compatible of fixed operations, and the later restricts the start and end time of each selected operations to be compatible with the fixed operations within the same job.
    It further includes (1) adaptive LNS subproblem size: The contiguous time interval starts at a length of 20\% of the horizon. If no improvement is found within 5 iterations, the size of time window increases by 5\%, with the longest time window length capped at 50\%. If improvement is found, the size returns to 20\%. (2) New objective for each LNS subproblem: Instead of makespan, it instead maximizes the distance between each operations end time and its latest feasible completion time as the surrogate objective when solving each LNS subproblem. 
    \item The \textbf{ARD-LNS (Machine-based)} in each LNS iteration selects a subset of machines and define the subproblem as the set of operations on those machines. As we select all operations on each machine, the subproblem only requires the operation precedence constraint. The subproblem is solved with Makespan as the objective. 
\end{itemize}

In the original paper by \citep{pacino2011large}, the LNS procedures are benchmarked on the dataset from\slired{~\citep{hurink1994tabu}}, where the largest instance consists of $225$ operations ($15$ machines, $15$ jobs, and $15$ operations per job). We successfully reproduced their reported results on these instances; however, when applying their algorithm to the significantly larger-scale setting considered in Table~\ref{tab:offline}, we observed a dramatic degradation in LNS performance. In contrast, the RHO-based algorithm maintains competitive performance on these long-horizon FJSP instances.

\paragraph{Learning-guided solver w/ decomposition: Oracle-LNS (Time-based).} We use a LookAhead Oracle similar to the one in previous learning-guided LNS studies~\citep{huang2022anytime, li2021learning}. In each LNS iteration, we first select $K=10$ Time Decomposition LNS subproblems as candidates. We then look ahead by solving these subproblems and choose the one that gives the biggest improvement in makespan. We randomly decide whether to evaluate the improvement based on the local makespan (for the current subproblem) or the global makespan (for the full FJSP problem), as this approach works better than focusing on just one objective. The local objective helps LNS prioritize subproblems needing the most fine-tuning, even though updating them doesn't immediately impact the final makespan. Meanwhile, the global objective encourages selecting subproblems toward the end of the time horizon to optimize the overall makespan. This differs from prior studies on Vehicle Routing~\citep{li2021learning}, Multi-Agent Path Finding~\citep{huang2022anytime} or Graph-Based Mixed Integer Linear Programming~\citep{huang2023searching}, where improving the local subproblem directly enhances the global objective.

\paragraph{RHO decomposition.} Detailed descriptions of different RHO baselines (Default, Warm Start, Random, First) can be found in Table~\ref{appendix_tab:notation_rho}. \slirebuttalblue{In Table~\ref{tab:offline}, for Default RHO, Warm Start RHO, and L-RHO, we set the RHO parameters $(H, S, T, T_{es}) = (80, 30, 60, 3)$. That is, each RHO subproblem involves $H=80$ operations, and each execution steps move forward $S=30$ operations. The time limit of solving each RHO subproblem is $T=60s$, and we early terminate the CP-SAT (with a
callback) if the best objective does not change after $T_{es}=3s$. For Default RHO (Long), we use a more generous early stop time $T_{es} = 10s$, where we see the Default RHO's performance improves at the expense of substantially longer solve time. In Table~\ref{tab:detailed_result}, the RHO parameters are determined based on an extensive parameter grid search procedure, as described in Appendix~\ref{appendix_sec:rho_param_search}.}



\newpage
\begin{figure}[!t]
     \centering
     \hspace*{\fill} 
     \begin{subfigure}[b]{0.47\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/param_search_appendix/param_search_25_25_25.png}
     \end{subfigure}
     \begin{subfigure}[b]{0.47\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/param_search_appendix/param_search_30_30_25.png}
     \end{subfigure}
    \caption{The objective and solve time for a variety of methods and RHO parameter settings, average across a set $\mathcal{K}_{ps}$ of FJSP instances with sizes $(25, 25, \slifinalblue{24})$ on the left and $(30, 30, \slifinalblue{24})$ on the right. Each dot represents a method and a RHO parameter setting $(H, S, T, T_{es})$. We label the selected best parameter setting for each method with text.}
    \label{appendix_fig:param_search}
\end{figure}
\subsubsection{Rolling Horizon Parameter Search}\label{appendix_sec:rho_param_search}
We perform a grid search to find the best parameter setting for each RHO variant (default, baselines and our learning method). We consider the following four parameters as a joint parameter setting
\begin{equation*}
    \begin{aligned}
        & \text{\{
        RHO Planning Window Size } H, \;\;\; \text{RHO Execution Step Size } S, \\
        & \;\;\; \text{Time Limit } T \text{ of each RHO FJSP Subproblem}, \\
        & \;\;\; \text{Early Stopping Time } T_{es} \text{ for each RHO Subproblem\}}
    \end{aligned}
\end{equation*}
In particular, the Early Stopping Time $T_{es}$ represents the time to early terminate the CP-SAT (with a callback) if the best objective does not change after $T_{es}$ seconds. We introduce this parameter due to the empirical observation that under a (relaxed) time limit, the objective of the best feasible solution obtained by CP-SAT may stuck at a given value for a long period of time.

We perform a grid search to evaluate the performances on a set $\mathcal{K}_{ps}$ of FJSP instances for each FJSP data distribution in the experiment Sec.~\ref{sec:experiment}, on the following parameter settings
% performance, time
\begin{equation}
    \begin{aligned}
        \mathcal{H} = & (\text{Window Size}, \text{Step Size}) \times (\text{Time Limit}, \text{Early Stop Time})\\
        = &\{ (50, 15), (50, 20), (50, 25), (50, 30), \\
        & \quad (80, 20), (80, 25), (80, 30), (80, 35), (80, 40), \\
        & \quad  (100, 20), (100, 30), (100, 40), (100, 50)\} \\
        \times & \{(15s, 2s), (30s, 3s), (60s, 3s)\}
    \end{aligned}
\end{equation}
We visualize the objective and solve time for all methods and parameters in Fig.~\ref{appendix_fig:param_search}, where each dot represents the objective and solve time (averaged over $\mathcal{K}_{ps}$) of each method evaluated under a parameter setting. For each method, the dots of all parameters define a Pareto frontier for the objective and solve time trade-off. As we aim to reduce solve time with minimal impact on the objective, we use the following procedure to identify the individual best parameter setting of each method:

\begin{itemize}
\item Let $obj^*$ be the best objective across all methods and all parameter settings. We empirically find that $obj^*$ is typically achieved by our \textbf{Oracle} data collection method, which offer an objective improvement from default RHO.
\item For each method $M$, we perform a line search with a step size $r_s = 0.1$ to find the best parameter setting: starting with iteration $i = 0$, let $\mathcal{H}^M_i \subseteq \mathcal{H}$ be the parameters whose objectives are within the $i^{th}$ bucket $[(1 + r_s\times i)\times obj^*, (1 + r_s\times (i + 1)) \times obj^*]$. If $\mathcal{H}^M_i \neq \emptyset$, we then select the parameter setting $H^{M*} \in \mathcal{H}_i$ with the shortest solve time as the individual best parameter setting for the method $M$; if $\mathcal{H}^M_i = \emptyset$, we then move on to the next iteration $i + 1$ and repeat the procedure, until we find the individual best parameter setting.
\end{itemize}

The line search procedure ensures that if there are two parameter settings with similar objectives, but one results in a much shorter solve time than the other, we would select the parameter setting with a shorter solve time as the best parameter setting for the method. In Table~\ref{appendix_tab:param_search}, We provide a list of the best parameter setting for each method, identified through the line search procedure. 

In Table~\ref{tab:detailed_result}, we apply the best parameter setting selected for each RHO variant to evaluate the method's performance. L-RHO is evaluated using the same parameters as Oracle. \sliblue{Since the best parameters for Default, Warm Start, and Oracle are consistent across different settings, we use a fixed set of RHO parameters $(H, S, T, T_{es}) = (80, 30, 60, 3)$ in Table~\ref{tab:offline} to avoid additional computation for parameter search.}

\begin{table}[!ht]
\caption{Best RHO parameter settings $(H, S, T, T_{es})$ of various RHO methods for the different FJSP settings presented in Table~\ref{tab:detailed_result}. Parameter settings highlighted in bold are the same as the Oracle's best parameter setting for each FJSP setting. }
\label{appendix_tab:param_search}
\centering
\scalebox{0.8}{
\begin{tabular}{ccccc}
\\[-0.85em]  \hline \\[-0.85em] 
& \textbf{25, 25, \slifinalblue{24}}      & \textbf{30, 30, \slifinalblue{24}}      & \textbf{35, 35, \slifinalblue{30}}      & \textbf{40, 40, 40}      \\[-0.85em]  \\ \hline \\[-0.85em] 
\textbf{Default}        & (80, 20, 60, 3)          & \textbf{(80, 25, 60, 3)} & (80, 30, 60, 3)          & \textbf{(80, 20, 60, 3)} \\\\[-0.85em] 
\textbf{Warm Start} & (80, 35, 60, 3)          & \textbf{(80, 25, 60, 3)} & \textbf{(80, 25, 60, 3)} & \textbf{(80, 20, 60, 3)} \\\\[-0.85em] 
\textbf{Fix first 20\%} & (80, 20, 60, 3)          & (100, 30, 60, 3)         & (100, 40, 60, 3)         & (100, 40, 60, 3)         \\\\[-0.85em] 
\textbf{Fix first 30\%} & (80, 20, 60, 3)          & (100, 30, 60, 3)         & (100, 40, 60, 3)         & (100, 40, 60, 3)         \\\\[-0.85em] 
\textbf{Fix first 40\%} & (80, 20, 60, 3)          & (100, 30, 60, 3)         & (100, 30, 30, 3)         & (100, 30, 30, 3)         \\\\[-0.85em] 
\textbf{Fix first 50\%} & (80, 30, 30, 3)          & (100, 20, 30, 3)         & (100, 40, 30, 3)         & (100, 40, 30, 3)         \\\\[-0.85em]
\textbf{Random 10\%}    & \textbf{(80, 25, 60, 3)} & \textbf{(80, 25, 60, 3)} & \textbf{(80, 25, 60, 3)} & (80, 25, 60, 3)         \\\\[-0.85em] 
\textbf{Random 20\%}    & (80, 20, 30, 3)          & \textbf{(80, 25, 60, 3)} & (80, 25, 30, 3)          & (80, 25, 60, 3)         \\ \\[-0.85em] 
\textbf{Random 30\%}    & (80, 20, 30, 3)          & (80, 30, 60, 3)          & (100, 30, 30, 3)         & (80, 25, 30, 3)       \\[-0.85em]   \\ \hline \\[-0.85em]
\textbf{Oracle}         & \textbf{(80, 25, 60, 3)} & \textbf{(80, 25, 60, 3)} & \textbf{(80, 25, 60, 3)} & \textbf{(80, 20, 60, 3)} \\[-0.85em]\\ \hline
\end{tabular}
}
\end{table}

\subsubsection{Performance of RHO methods for FJSP $(30, 30, \slifinalblue{24})$.}
In Table~\ref{appendix_tab:fjsp30}, we provide the detailed results of all RHO baseline methods' performance under both the individual best RHO parameter setting (\textbf{Individual Best Param.}) and a fixed RHO parameter setting (the Oracle's best parameter, \textbf{Same Param.}) for FJSP $(30, 30, \slifinalblue{24})$ with the total start delay objective and no observation noise, which is used as the base setting in Fig.~\ref{fig:additional experiment} middle, (ii), of Sec.~\ref{sec:experiment_additional_result}.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[!h]
\caption{Time and Objective improvements (TI\%, OI\%) of different RHO variants for \textbf{FJSP} $\mathbf{(30, 30, \slifinalblue{24})}$ under the start delay objective. We report the mean values (higher the better, negative indicates degradation) and two standard errors. The best TI\% and OI\% among the RHO methods (excluding Oracle) are bold-faced. L-RHO significantly outperforms all baseline methods in the objective with substantially reduced solve time. Additionally, L-RHO closely aligns with the performance of the Look-Ahead Oracle, demonstrating its learning effectiveness.}
\label{appendix_tab:fjsp30}
\centering
\scalebox{0.65}{
\begin{tabular}{ccccc}
\\[-0.65em] \toprule \\[-0.85em]
\multirow{3}{*}{\textbf{30, 30, \slifinalblue{24}}}                                  & \multicolumn{2}{c}{\textbf{Individual Best Param.}}    & \multicolumn{2}{c}{\textbf{Same Param.}}        \\ \\[-0.85em]
    \cmidrule(r){2-3}  \cmidrule(r){4-5}  \\[-0.85em]
    & \textbf{TI \%}             & \textbf{OI \%}                 & \textbf{TI \%}             & \textbf{OI \%}       \\ \\[-0.85em]\hline \\[-0.85em]
% \textbf{\begin{tabular}[c]{@{}c@{}}Full FJSP \\ (Short)\end{tabular}} & \begin{tabular}[c]{@{}c@{}}206.1s $\pm$ 0.3s \\(75.3\% $\pm$ 0.8\%) \end{tabular}            & \begin{tabular}[c]{@{}c@{}}37144.8 $\pm$ 4752.4\\ (-2169.8\% $\pm$ 301.1\%)\end{tabular} &     -                       &         -             \\ \\[-0.85em]
% \textbf{\begin{tabular}[c]{@{}c@{}}Full FJSP \\ (Long)\end{tabular}}                                         & \begin{tabular}[c]{@{}c@{}} 1005.7 $\pm$ 0.2 \\ (-20.8\% $\pm$ 3.9\%) \end{tabular}          & \begin{tabular}[c]{@{}c@{}}6288.2 $\pm$ 296.3\\ (-277.0\% $\pm$ 14.7\%)\end{tabular}     &           -                 &     -             \\[-0.85em]    \\ \hline \\[-0.85em]
\textbf{Default}                                                      & \begin{tabular}[c]{@{}c@{}}853.9s $\pm$ 26.9s\\ (0.0\% $\pm$ 0.0\%)\end{tabular}           & \begin{tabular}[c]{@{}c@{}}1736.9 $\pm$ 116.8\\ (0.0\% $\pm$ 0.0\%)\end{tabular}         & 0.0\% $\pm$ 0.0\%           & 0.0\% $\pm$ 0.0\%     \\ \\[-0.85em]
\textbf{Warm Start All}                                               & -0.1\% $\pm$ 1.3\%          & 0.8\% $\pm$ 2.2\%                                                                        & -0.1\% $\pm$ 1.3\%          & 0.8\% $\pm$ 2.2\%      \\ \\[-0.85em]
\textbf{Fix first 20\%}                                               & 3.6\% $\pm$ 1.5\%           & -14.3\% $\pm$ 2.7\%                                                                    & 19.4\% $\pm$ 1.5\%          & -23.1\% $\pm$ 3.8\%   \\ \\[-0.85em]
\textbf{Fix first 30\%}                                               & 12.4\% $\pm$ 1.6\%          & -21.5\% $\pm$ 3.8\%                                                                     & 20.9\% $\pm$ 1.7\%          & -57.9\% $\pm$ 5.1\%   \\ \\[-0.85em]
\textbf{Fix first 40\%}                                               & 19.5\% $\pm$ 1.7\%          & -41.2\% $\pm$ 4.4\%                                                                     & 17.8\% $\pm$ 2.0\%          & -131.4\% $\pm$ 7.7\%  \\ \\[-0.85em]
\textbf{Fix first 50\%}                                               & 7.9\% $\pm$ 2.0\%           & -78.1\% $\pm$ 5.5\%                                                                     & 19.0\% $\pm$ 2.1\%          & -238.5\% $\pm$ 13.0\% \\ \\[-0.85em]
\textbf{Fix first 60\%}                                               & 33.6\% $\pm$ 1.7\%          & -225.8\% $\pm$ 11.8\%                                                                   & 26.9\% $\pm$ 2.3\%          & -416.0\% $\pm$ 19.9\% \\ \\[-0.85em]
\textbf{Fix first 80\%}                                               & \textbf{51.0\% $\pm$ 1.7\%} & -727.1\% $\pm$ 35.4\%                                                                   & 50.2\% $\pm$ 1.6\% & -874.8\% $\pm$ 46.3\% \\ \\[-0.85em]
\textbf{Random 10\%}                                                  & 1.8\% $\pm$ 1.7\%           & -20.2\% $\pm$ 3.1\%                                                                     & 1.80\% $\pm$ 1.69\%           & -20.2\% $\pm$ 3.1\%   \\ \\[-0.85em]
\textbf{Random 20\%}                                                  & 0.3\% $\pm$ 2.0\%           & -54.7\% $\pm$ 4.6\%                                                                     & 1.8\% $\pm$ 1.7\%           & -20.2\% $\pm$ 3.1\%   \\ \\[-0.85em]
\textbf{Random 30\%}                                                  & 9.9\% $\pm$ 2.3\%           & -153.6\% $\pm$ 8.1\%                                                                    & -0.3\% $\pm$ 2.4\%          & -103.8\% $\pm$ 7.2\%  \\ \\[-0.85em]
\textbf{Random 40\%}                                                  & -10.9\% $\pm$ 3.3\%         & -105.6\% $\pm$ 7.2\%                                                                    & 2.0\% $\pm$ 2.5\%           & -164.68\% $\pm$ 9.43\%  \\ \\[-0.85em]\hdashline \\[-0.85em]
\textbf{(Oracle)}     & (49.9\% $\pm$ 1.1\%)        & (15.3\% $\pm$ 2.22\%)   &    (49.9\% $\pm$ 1.1\%)        & (15.3\% $\pm$ 2.2\%)                    \\ \\[-0.85em] \hdashline  \\[-0.65em]
\textbf{L-RHO (Ours)}                                                 & 41.5\% $\pm$ 6.4\%  & \textbf{14.0\% $\pm$ 10.2\%}                    &                    41.5\% $\pm$ 6.4\%  & 14.0\% $\pm$ 10.2\%        \\[-0.85em] \\ \bottomrule
\end{tabular}
}
\end{table}


\subsubsection{Performance of RHO methods under the same RHO parameter.}
\label{appendix:same_rho_param}
In Table~\ref{appendix_tab:main}, we present the performance of all RHO variants under the same RHO parameter setting (the Oracle's best parameter), for all three FJSP settings in  Table~\ref{tab:detailed_result}. The TI\% and OI\% is relative to Default RHO under Default's best parameter (same as in Table~\ref{tab:detailed_result}). From Table~\ref{appendix_tab:fjsp30} and~\ref{appendix_tab:main}, we observe that although the First $\sigma_f$ baseline can substantially reduce the solve time when $\sigma_f$ is high, the associated objective drastically deteriorates at the same time. In contrast, our learning method L-RHO not only significantly significantly accelerates Default RHO, but it is also the only method that simultaneously achieves a notable improvement in the objective.

\begin{table}[!h]
\caption{Time and Objective improvements (TI\%, OI\%) of different RHO methods in comparison with Default RHO (with Default's best parameter) for three FJSP settings in Table~\ref{tab:detailed_result}; \textit{all the methods are evaluated on the same RHO parameter setting (\textbf{Oracle's best RHO parameter})}. We report the mean values (higher the better, negative indicates degradation) and two standard errors. The best TI\% and OI\% among the RHO methods (excluding Oracle) are bold-faced.  L-RHO significantly outperforms all baseline methods in the objective with substantially reduced solve time.}
\label{appendix_tab:main}
\centering
\scalebox{0.65}{
\begin{tabular}{ccccccc}
\\[-0.65em] \toprule \\[-0.85em]
& \multicolumn{2}{c}{\textbf{25, 25, \slifinalblue{24}}}                 & \multicolumn{2}{c}{\textbf{35, 35, \slifinalblue{30}}}                 & \multicolumn{2}{c}{\textbf{40, 40, 40}}          \\[-0.85em]        \\
\cmidrule(r){2-3}  \cmidrule(r){4-5}  \cmidrule(r){6-7}  \\[-0.85em]
                        & \textbf{TI \%}             & \textbf{OI \%}             & \textbf{TI \%}             & \textbf{OI \%}             & \textbf{TI \%}             & \textbf{OI \%}          \\[-0.85em]    \\ \hline  \\[-0.85em]
\textbf{Default}        & 17.6\% $\pm$ 1.3\%          & -6.9\% $\pm$ 4.3\%          & -16.0\% $\pm$ 2.1\%         & 5.1\% $\pm$ 3.8\%           & 0.0\% $\pm$ 0.0\%           & 0.0\% $\pm$ 0.0\%           \\  \\[-0.85em]
\textbf{Warm Start} & 20.0\% $\pm$ 1.3\%          & -1.7\% $\pm$ 2.5\%          & -12.9\% $\pm$ 1.6\%         & 11.2\% $\pm$ 2.7\%          & 5.2\% $\pm$ 2.4\%           & 6.8\% $\pm$ 4.8\%           \\  \\[-0.85em]
\textbf{Fix first 20\%} & 36.2\% $\pm$ 1.2\%          & -3.78\% $\pm$ 2.7\%          & 0.3\% $\pm$ 1.6\%           & -33.4\% $\pm$ 4.0\%         & 4.6\% $\pm$ 3.5\%           & -78.3\% $\pm$ 9.0\%         \\  \\[-0.85em]
\textbf{Fix first 30\%} & 41.6\% $\pm$ 1.2\%          & -14.6\% $\pm$ 3.0\%         & -0.9\% $\pm$ 1.7\%          & -91.5\% $\pm$ 5.4\%         & 1.5\% $\pm$ 4.2\%           & -207.7\% $\pm$ 17.3\%       \\  \\[-0.85em]
\textbf{Fix first 40\%} & 42.1\% $\pm$ 1.3\%          & -46.8\% $\pm$ 4.2\%         & -5.1\% $\pm$ 2.6\%          & -222.2\% $\pm$ 11.1\%       & 7.7\% $\pm$ 4.7\%           & -423.2\% $\pm$ 30.6\%       \\  \\[-0.85em]
\textbf{Fix first 50\%} & 43.8\% $\pm$ 1.2\%          & -100.9\% $\pm$ 6.8\%        & 3.2\% $\pm$ 3.0\%           & -359.2\% $\pm$ 16.6\%       & 24.5\% $\pm$ 3.7\%          & -748.0\% $\pm$ 46.2\%       \\  \\[-0.85em]
\textbf{Fix first 60\%} & 46.9\% $\pm$ 1.4\%          & -218.4\% $\pm$ 12.1\%       & 17.2\% $\pm$ 2.7\%          & -600.4\% $\pm$ 29.1\%       & 40.7\% $\pm$ 2.5\%          & -1118.0\% $\pm$ 80.6\%      \\  \\[-0.85em]
\textbf{Fix first 80\%} & \textbf{59.5\% $\pm$ 1.4\%} & -594.5\% $\pm$ 32.5\%       & \textbf{49.6\% $\pm$ 1.8\%} & -1105.2\% $\pm$ 55.3\%      & \textbf{73.2\% $\pm$ 1.1\%} & -1892.8\% $\pm$ 138.9\%     \\  \\[-0.85em]
\textbf{Random 10\%}    & 23.0\% $\pm$ 1.3\%          & -11.9\% $\pm$ 2.5\%         & -15.5\% $\pm$ 1.7\%         & -12.9\% $\pm$ 3.4\%         & -0.3\% $\pm$ 2.7\%          & -16.8\% $\pm$ 5.8\%         \\  \\[-0.85em]
\textbf{Random 20\%}    & 24.2\% $\pm$ 1.5\%          & -32.8\% $\pm$ 3.6\%         & -18.8\% $\pm$ 2.0\%         & -58.0\% $\pm$ 5.7\%         & -1.6\% $\pm$ 3.1\%          & -61.8\% $\pm$ 10.0\%         \\  \\[-0.85em]
\textbf{Random 30\%}    & 23.6\% $\pm$ 1.7\%          & -75.1\% $\pm$ 5.9\%         & -17.4\% $\pm$ 2.3\%         & -104.1\% $\pm$ 7.3\%        & -0.8\% $\pm$ 3.3\%          & -131.8\% $\pm$ 12.8\%       \\  \\[-0.85em]
\textbf{Random 40\%}             & 27.4\% $\pm$ 2.0\%          & -153.3\% $\pm$ 9.1\%        & -14.4\% $\pm$ 3.1\%         & -204.9\% $\pm$ 11.4\%       & 1.4\% $\pm$ 3.6\%           & -202.6\% $\pm$ 20.9\%     \\[-0.85em]   \\ \hdashline  \\[-0.85em]
\textbf{(Oracle)}       & (60.3\% $\pm$ 1.0\%)        & (18.5\% $\pm$ 1.7\%)        & (40.5\% $\pm$ 1.0\%)        & (22.4\% $\pm$ 2.3\%)        & (53.2\% $\pm$ 1.3\%)        & (12.8\% $\pm$ 4.4\%)        \\[-0.85em] \\ \hdashline  \\[-0.65em]
\textbf{L-RHO (Ours)}   & 53.0\% $\pm$ 1.0\%          & \textbf{16.0\% $\pm$ 1.9\%} & 35.1\% $\pm$ 1.3\%          & \textbf{21.0\% $\pm$ 2.4\%} & 47.3\% $\pm$ 2.2\%          & \textbf{13.13\% $\pm$ 4.4\%}   \\[-0.85em] \\ \bottomrule
\end{tabular}
}
\end{table}


\clearpage
\newpage

\subsection{Additional Experimental Results}\label{appendix_sec:additional_results}

\subsubsection{Performance on Real World Dataset (\cite{dauzere1997integrated}}

We find most of the traditional benchmarks on small scale ($<500$ operations). We benchmark the performance on \cite{dauzere1997integrated}, 1997, which is the largest traditional benchmarks available, containing 16 instances evenly divided to three different sizes (respectively, 196, 293, and 387 operations).  We exclude 4 instances from the dataset, which is simple and take $<2s$ for RHO methods to solve. To mimic large scale settings with more operations, We further replicate all operations for each job $k$ times, with $k=3,6,9$ to mimic long horizon scale settings with more operations. We provide the performance comparison in Table~\ref{tab:real_world}. For DRL and L-RHO, we both directly transfer the model learned on 600 operations (10, 20, 30) setting to the real world instances. The \textit{best known solution} for the Dauzere original setting has an average makespan of \textit{2120} with standard deviation $78$.

We find that the direct transfer setting, our L-RHO outperforms DRL in the real world dataset, achieving a close gap with respect to best known solution in the literature for the smallest non-augmented setting, and the performance advantage further holds for longer-horizon augmented settings. Furthermore, L-RHO significantly speeds up Default RHO in all settings, demonstrating the benefit of introducing learning to accelerate RHO. We further note there exists slight mismatch in the training distribution and the real world dataset, and it is an interesting future work is to train the model on a diverse set of distribution to further improve L-RHOs transfer learning performance. 


\begin{table}[!h]
\caption{Performance Comparison on the \cite{dauzere1997integrated} dataset. The best known solution of the original dataset (the first result column) has a makespan of $2120 \pm 78$. In the last three result column, we randomly sample (with replacement) $\times k$ operations for each job to mimic the long horizon settings.}
\label{tab:real_world}
\scalebox{0.65}{
\begin{tabular}{lcccccccc}
\toprule
      & \multicolumn{2}{c}{\textbf{Original}}  &  \multicolumn{2}{c}{\textbf{Augment 3}}   &    \multicolumn{2}{c}{\textbf{Augment 6}}    &    \multicolumn{2}{c}{\textbf{Augment 9}}    \\
      \cmidrule(r){2-3}\cmidrule(r){4-5}\cmidrule(r){6-7}\cmidrule(r){8-9}
      & \textbf{Time}         & \textbf{Makespan}       & \textbf{Time}           & \textbf{Makespan}    & \textbf{Time}     & \textbf{Makespan}        & \textbf{Time}   & \textbf{Makespan}  \\
      \midrule
DRL-20K (Wang) - Greedy      & 2 $\pm$ 0.1  & 2493 $\pm$ 44 & 6 $\pm$ 0.5     & 7279 $\pm$ 69 & 12 $\pm$ 1.0     & 14337 $\pm$ 218 & 22 $\pm$ 2.6      & 21218 $\pm$ 250 \\
DRL-20K (Wang) - Sample 100  & 8 $\pm$ 1  & 2279 $\pm$ 19 & 57 $\pm$ 9.6    & 6946 $\pm$ 83  & 235 $\pm$ 42   & 13935 $\pm$ 164 & 534 $\pm$  95.2   & 20784 $\pm$ 226 \\
DRL-20K (Wang) - Sample 500  & 35 $\pm$ 6  & 2253 $\pm$ 21 & 321 $\pm$ 58  & 6887 $\pm$ 79  & 1341 $\pm$ 231 & 13884 $\pm$ 162 & 3014 $\pm$ 516  & 20722 $\pm$ 216 \\
DRL-20K (Wang) - Sample 1000 & 72 $\pm$ 13 & 2247 $\pm$ 20 & 670 $\pm$ 116 & 6858 $\pm$ 83  & 2679 $\pm$ 458 & 13859 $\pm$ 156 & 6068 $\pm$ 1038 & 20706 $\pm$ 217 \\
\midrule
Default RHO                  & 83 $\pm$ 33 & 2174 $\pm$ 68 & 290 $\pm$ 84  & 6505 $\pm$ 232 & 509 $\pm$ 150  & 13085 $\pm$ 428 & 794 $\pm$ 241   & 19689 $\pm$ 592 \\
Warm Start RHO               & 75 $\pm$ 25 & 2167 $\pm$ 68 & 241 $\pm$ 67  & 6490 $\pm$ 237 & 450 $\pm$ 141  & 13034 $\pm$ 432 & 684 $\pm$ 210   & 19589 $\pm$ 609 \\
\textbf{L-RHO Transfer}      & 65 $\pm$ 23 & 2185 $\pm$ 66 & 199 $\pm$ 70  & 6499 $\pm$ 254 & 345 $\pm$ 134  & 13015 $\pm$ 504 & 492 $\pm$ 200   & 19593 $\pm$ 725\\
\bottomrule
\end{tabular}
}
\end{table}




\subsubsection{Accuracy, TPR, TNR, Precision, and Recall of the Learning Method.}

We provide the accuracy, true positive rate (TPR), true negative rate (TNR) precision, and recall of the learning architecture (Fig.~\ref{fig:main_architecture}) in Table~\ref{appendix_tab:accuracy}.

\begin{table}[!t]
\caption{\slirebuttalblue{Accuracy, True Positive Rate (TPR), True Negative Rate (TNR), Precision, and Recall of the learning architecture in Fig.~\ref{fig:main_architecture} on the hold out validation set for each setting in Table~\ref{tab:offline} and~\ref{tab:detailed_result}}.}
\label{appendix_tab:accuracy}
\centering
\scalebox{0.75}{
\begin{tabular}{lccccc}
\toprule
& Accuracy & True Positive Rate   & True Negative Rate   & Precision & Recall \\
\midrule
\multicolumn{6}{c}{Table~\ref{tab:offline}}     \\      
\midrule
600 (10, 20, 30)  & 0.77     & 0.81 & 0.67 & 0.86                        & 0.81                          \\
800 (10, 20, 40)  & 0.76     & 0.79 & 0.67 & 0.86                        & 0.79                          \\
1200 (10, 20, 60) & 0.76     & 0.77 & 0.73 & 0.87                        & 0.77                         \\
\midrule 
\multicolumn{6}{c}{Table~\ref{tab:detailed_result}}     \\
\midrule
625 (25, 25, 25)  & 0.78     & 0.71 & 0.85 & 0.83                        & 0.71                          \\
1225 (35, 35, 35) & 0.81     & 0.72 & 0.87 & 0.79                        & 0.72                          \\
1600 (40, 40, 40) & 0.81     & 0.69 & 0.90 & 0.83                        & 0.69   \\ 
\bottomrule
\end{tabular}
}
\end{table}



\subsubsection{Ablation Study: A Detailed Comparison with Attention-Based Architecture.}
\label{appendix_sec:comp_attention}

We compare the architecture in Fig.~\ref{fig:main_architecture} with a more advanced attention based architecture shown in Fig.~\ref{fig:architecture}. We make the following two modifications to obtain the new architecture:
\begin{itemize}[leftmargin=*]
    \item First, at the machine/operation concatenation block, for each new operation $O \in \mathcal{O}_{new, r}$ that does not have a machine assignment in $m_{r-1}$, we concatenate it a dummy machine embedding (all-zero feature) and the global embedding from mean pooling on all entities (operations and machines). 
    \item Then, after the machine/operation concatenation block of the original architecture, we perform a Multi-Head Attention between the overlapping operations $\mathcal{O}_{overlap, r}$ and the new operations $\mathcal{O}_{new, r}$ (with $4$ attention heads), and we also include a residual connection for the overlapping operations.
\end{itemize}

For the Multi-Head Attention, we take the overlapping operations' embeddings as queries ($Q$), and consider \textbf{the following three setup for the attention keys ($K$) and values ($V$)}: (1) New operations only, (2) Overlapping operations only, and (3) Both overlapping and new operations. 

In Table~\ref{appendix_tab:arch_comparison}, we find that for option (1) and (2) the introduction of the attention architecture leads to a slightly higher True Negative Rate (TNR) but lower True Positive Rate (TPR) and a slight reduction accuracy, when compared with the architecture without attention. Furthermore, when evaluating the performance on 600 operations FJSP (10, 20, 30) in Table~\ref{tab:offline}, we see that option (1) and (2) , results in a longer solve time but an improved makespan from the architecture without attention. We also note that option (3) is strictly dominated by the performance of the architecture without attention.
 
We note that the TNR-TPR tradeoff on the performance and solve time aligns with our theoretical analysis, as fixing something that should not have been (low TNR) harms the objective but helps the solve time, while failing to fix something that should have been (low TPR) harms the solve time and also indirectly harms the objective (under a fixed time limit). 


Due to the time benefit of the architecture without attention and the relatively competitive objective, we believe it makes sense to keep the simpler architecture without attention in the main paper.

\begin{figure*}[!h]
  \centering
    \includegraphics[width=0.9\linewidth]{figures/final_architecture.png}
    \caption{\textbf{Ablation neural architecture: Attention among the overlapping and new operations.} The architecture follows Fig.~\ref{fig:main_architecture}, but introduces an additional cross attention among the overlapping and new operations before output the predicted probability for each overlapping operation.}
  \label{fig:architecture}
\end{figure*}

\begin{table}[!h]
\caption{\slirebuttalblue{Comparison of the learning architecture in Fig.~\ref{fig:main_architecture} and the attention-based learning architecture in Fig.~\ref{fig:architecture} on the hold out validation set for the 600 operations setting (10, 20, 30) in Table~\ref{tab:offline}.}}
\label{appendix_tab:arch_comparison}
\centering
\scalebox{0.8}{
\begin{tabular}{lccccccc}
\toprule
& Accuracy & TPR   & TNR   & Precision & Recall & Time (s) & Makespan \\
\midrule
No Attention  & 0.77     & 0.81 & 0.67 & 0.86   & 0.81   &  \textbf{126 $\pm$ 19 } & 1513 $\pm$ 70     \\
\begin{tabular}[c]{@{}l@{}} Attention \\
($K\& V$: New Ops.)\end{tabular}  & 0.76      &     0.77 & 0.74 & 0.88 & 0.77     & 170 $\pm$ 18 & \textbf{1504 $\pm$ 68}               \\ 
\begin{tabular}[c]{@{}l@{}} Attention \\
($K\& V$: Overlapping Ops.)\end{tabular}  &  0.75 & 0.75 & 0.75 & 0.88 & 0.75 & 179 $\pm$ 21 & 1507 $\pm$ 57\\

\begin{tabular}[c]{@{}l@{}} Attention \\
($K\& V$: Overlapping   
and New Ops.) \end{tabular} &   0.76 & 0.76  & 0.74  &   0.88  & 0.76       & 133 $\pm$ 14 & 1527 $\pm$ 68           \\
\bottomrule
\end{tabular}
}
\end{table}

\begin{figure*}[!h]
  \centering
  \begin{subfigure}[b]{0.8\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/attn_new.png}
    \caption{Only the new operations as keys $K$ and values $V$.}
    \label{fig:attn_map_new}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.98\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/attn_prev.png}
    \caption{Only the overlapping operations as keys $K$ and values $V$.}
    \label{fig:attn_map_prev}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.98\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/attn_both.png}
    \caption{Both overlapping and new operations as keys $K$ and values $V$.}
    \label{fig:attn_map_both}
  \end{subfigure}
  \caption{\textbf{Comparison of Learned Attention Maps.} We set the overlapping operations as the query $Q$ (the rows) and consider three different types of keys $K$ and values $V$ (the columns).}
  \label{appendix_fig:attn_maps_combined}
\end{figure*}




\clearpage
\newpage
\subsubsection{Performance Comparison with DRL under the same number of FJSP training instance.}
In Table~\ref{appendix_tab:dlr_smaller}, we compare L-RHO with DRL~\citep{wang2023flexible} when training on the same set of 450 FJSP instances. We observe that DRLs performance  degrades with 450 training instances, especially at larger scales, highlighting L-RHO's unique advantage with a lighter training set. This can be beneficial under situations where FJSP training instances are harder to acquire.


\begin{table}[!h]
\caption{\sliblue{Compare L-RHO with DLR~\cite{wang2023flexible} under the same number of FJSP training instances (DRL-450). }}
\label{appendix_tab:dlr_smaller}
\centering
\scalebox{0.62}{
\begin{tabular}{lcccccccc}
\toprule
 & \multicolumn{2}{c}{\textbf{600} (10, 20, 30)} & \multicolumn{2}{c}{\textbf{800} (10, 20, 40)} & \multicolumn{2}{c}{\textbf{1200} (10, 20, 60)} & \multicolumn{2}{c}{\textbf{2000} (10, 20, 100), \textbf{Transfer}} \\
\cmidrule(r){2-3}  \cmidrule(r){4-5}  \cmidrule(r){6-7}
\cmidrule(r){8-9}
& Time (s) $\downarrow$ & Makespan $\downarrow$ & Time (s) $\downarrow$ & Makespan $\downarrow$ & Time (s) $\downarrow$ & Makespan $\downarrow$ & Time (s) $\downarrow$ & Makespan $\downarrow$ \\
\midrule
\sliblue{\textbf{CP-SAT }} & 1800 & 2274 $\pm$ 147 & 1800 & 4017 $\pm$ 413 & 1800 & 10925 $\pm$ 1013 & 1800 & 39585 $\pm$ 2707\\
\sliblue{\textbf{CP-SAT (10 hours)}} & 36000 & 1583 $\pm$ 65 & 1800 & 2128 $\pm$ 75 & 1800 & 3206 $\pm$ 87 & 1800 & 18821 $\pm$ 1986\\
\midrule
\textbf{DRL-450, Greedy} & \textbf{4 $\pm$ 0.04} & 1635 $\pm$ 75 & \textbf{6 $\pm$ 0.04} & 2178 $\pm$ 85 & \textbf{11 $\pm$ 0.2} & 3307 $\pm$ 115 & \textbf{17 $\pm$ 0.5} & 5415 $\pm$ 134 \\
\textbf{DRL-450, Sample 100} & 30 $\pm$ 1 & 1563 $\pm$ 62 & 48 $\pm$ 1 & 2093 $\pm$ 70 & 111 $\pm$ 3 & 3237 $\pm$ 91 & 301 $\pm$ 8 & 5341 $\pm$ 108 \\
\textbf{DRL-450, Sample 500} & 143 $\pm$ 4 & 1546 $\pm$ 50 & 261 $\pm$ 8 & 2070 $\pm$ 68 & 610 $\pm$ 25 & 3210 $\pm$ 94 & 1751 $\pm$ 30 & 5311 $\pm$ 111 \\\\[-0.85em]
\hdashline\\[-0.85em]
\textbf{DRL-20K, Greedy} & \color{gray}{\textbf{4 $\pm$ 0.02}} & 1628 $\pm$ 72 & \color{gray}{\textbf{6 $\pm$ 0.04}} & 2128 $\pm$ 80 & \color{gray}{\textbf{10 $\pm$ 0.1}} & 3141 $\pm$ 97 & \color{gray}{\textbf{16 $\pm$ 0.2}} & 5184 $\pm$ 114 \\
\textbf{DRL-20K, Sample 100} & 29 $\pm$ 0.3 & 1551 $\pm$ 60 & 47 $\pm$ 1 & 2048 $\pm$ 69 & 110 $\pm$ 3 & 3063 $\pm$ 81 & 302 $\pm$ 10 & 5082 $\pm$ 98 \\
\textbf{DRL-20K, Sample 500} & 146 $\pm$ 5 & 1537 $\pm$ 61 & 261 $\pm$ 8 & 2031 $\pm$ 68 & 597 $\pm$ 16 & 3045 $\pm$ 79 & 1738 $\pm$ 16 & 5062 $\pm$ 98 \\
\midrule
\textbf{Default RHO} & 244 $\pm$ 21 & 1558 $\pm$ 73 & 348 $\pm$ 26 & 2103 $\pm$ 78 & 545 $\pm$ 36 & 3136 $\pm$ 91 & 862 $\pm$ 42 & 5207 $\pm$ 114 \\
\textbf{Warm Start RHO} & 203 $\pm$ 23 & 1521 $\pm$ 67 & 278 $\pm$ 22 & 2055 $\pm$ 75 & 420 $\pm$ 33 & 3081 $\pm$ 96 & 716 $\pm$ 41 & 5057 $\pm$ 106 \\
\\[-0.85em] \hdashline \\[-0.85em]
\textbf{L-RHO (450)} & \textbf{126 $\pm$ 19} & \textbf{1513 $\pm$ 70} & \textbf{160 $\pm$ 23} & \textbf{2015 $\pm$ 86} & \textbf{259 $\pm$ 37} & \textbf{3011 $\pm$ 106} & \textbf{473 $\pm$ 52} & \textbf{4982 $\pm$ 132} \\
\bottomrule
\end{tabular}
}
\end{table}


\subsubsection{Performance of Default RHO with Longer Time Limits}
\label{appendix_sec:default_rho_longer_time}
As described in Appendix~\ref{appendix_sec:rho_param_search}, two parameters control the time limit per RHO subproblem: 1) total time limit, where solving terminates if the time exceeds $T$ seconds; 2) early stop time, where solving terminates early if the objective does not improve within $T_{es}$ seconds. In Table~\ref{tab_appendix:rho_time_span}, we evaluate the default RHO with increased $T$ and $T_{es}$. The results show that, as the time limit increases by over 10x, the default RHO achieves better objectives than our L-RHO, albeit with prohibitively long runtime. Our L-RHO delivers superior performance under practical time constraints, offering benefits especially in online cases. 


\begin{table}[!h]
\caption{Comparison of Default RHO's performance across different time limit parameters $T$ and $T_{es}$ for RHO.}
\centering
\scalebox{0.8}{
\begin{tabular}{lcccccc}
\toprule
\multicolumn{1}{c}{}  & \multicolumn{2}{c}{\textbf{600 (10, 20, 30)}} & \multicolumn{2}{c}{\textbf{800 (10, 20, 40)}} & \multicolumn{2}{c}{\textbf{1200 (10, 20, 60)}} \\
\cmidrule(r){2-3} \cmidrule(r){4-5} \cmidrule(r){6-7}   
$\mathbf{T, T_{es}}$ & \textbf{Time (s)}    & \textbf{Makespan}      & \textbf{Time (s)}    & \textbf{Makespan}      & \textbf{Time (s)}    & \textbf{Makespan}       \\
\midrule
60, 3 (reported)      & 244 $\pm$ 21            & 1558 $\pm$ 73             & 348 $\pm$ 26            & 2103 $\pm$ 78             & 545 $\pm$ 36            & 3136 $\pm$ 91              \\
60, 10                & 599$\pm$ 55             & 1529 $\pm$ 58             & 728 $\pm$ 98            & 2044 $\pm$ 75             & 1109 $\pm$ 108          & 3002 $\pm$ 87              \\
60, 30                & 923 $\pm$ 71            & 1502 $\pm$ 66             & 1099 $\pm$ 130          & 2028 $\pm$ 72             & 1697 $\pm$ 175          & 2963 $\pm$ 78              \\
60, 60                & 819 $\pm$ 117           & 1494 $\pm$ 67             & 1096 $\pm$ 156          & 2018 $\pm$ 71             & 1714 $\pm$ 154          & 2968 $\pm$ 89              \\
120, 60               & 1476 $\pm$ 312          & 1497 $\pm$ 70             & 1811 $\pm$ 241          & 1997 $\pm$ 70             & 2809 $\pm$ 308          & 2932 $\pm$ 75              \\
180, 120              & 2142 $\pm$ 461          & 1490 $\pm$ 70             & 2509 $\pm$ 346          & 1994 $\pm$ 76             & 3932 $\pm$ 590          & 2924 $\pm$ 83              \\
360, 180              & 3631 $\pm$ 816          & 1476 $\pm$ 64             & 3673 $\pm$ 797          & 1987 $\pm$ 68             & 5663 $\pm$ 900          & 2924 $\pm$ 86              \\
\textbf{L-RHO}        & 126 $\pm$ 19            & 1513 $\pm$ 70    & 160 $\pm$ 23            & 2015 $\pm$ 86    & 259 $\pm$ 37            & 3011 $\pm$ 106   \\
\bottomrule
\end{tabular}
}
\end{table}


\newpage 


\clearpage
\newpage
\subsection{Detailed Theoretical Probabilistic Analysis}\label{appendix_sec:analysis}
Following the main paper, we analyze a generic subproblem $\hat{P}_r := \hat{P}$ at each RHO iteration $r$. For ease of notation, we omit the $r$ subscript for the rest of this section when it is clear from the context.
\subsubsection{Details of all considered RHO methods} \label{appendix_sec:analysis_baselines}
We consider a set of assignment-based RHO warm start procedure, where we follow the $RHO_{test}$ procedure in Fig.~\ref{fig:rho_pipeline} (b), bottom but obtain $\mathcal{O}_{fix}$ at each RHO iteration with different methods described as follows. For tractability analysis, we consider the same RHO window size $H$ and step size $S$, which results in $H-S$ overlapping operations $|\mathcal{O}_{overlap}| = H-S$ in consecutive RHO iterations. 


\begin{itemize}[leftmargin=0.5cm]
    \item \textbf{Random $\mathbf{\sigma_R}$}: $\mathcal{O}_{fix}$ is obtained by selecting each operation in $\mathcal{O}_{overlap}$ with a probability $\sigma_R$ uniformly at random.
    \item \textbf{First $\mathbf{\sigma_F}$}: $\mathcal{O}_{fix}$ is obtained as the first $\sigma_F$ fraction of operations in $\mathcal{O}_{overlap}$ with the earliest RHO sequence order (determined by release time for delay-based objectives or operation precedence for makespan). Notably, Random/First $\sigma = 0$ exactly matches the default RHO procedure.
    \item \textbf{L-RHO (Ours)}: $\mathcal{O}_{fix}$ is \textit{predicted} by the learning model $f_{\theta}$ as described in Sec.~\ref{sec:l_rho_inference} (Fig.~\ref{fig:rho_pipeline}, (b) bottom).
    \item \textbf{Oracle}: the look-ahead Oracle with $\mathcal{O}^*_{fix}$, which is empirically obtained by applying the same procedure as \sliblue{in Fig.~\ref{fig:rho_pipeline} (b) top} but only includes the solve time of the restricted subproblem $\hat{P}^*$. As illustrated in Fig.~\ref{fig:analysis} (left), we analyze the performance of each method (Random, First, L-RHO) based on the closeness of $\mathcal{O}_{fix}$ to the Oracle $\mathcal{O}^*_{fix}$.
    % , as illustrated by Fig.~\ref{appendix_fig:analysis_illustration}.
\end{itemize}
% \textbf{Analysis Outline.} We analyze the performance of each method (Random, First, L-RHO) based on the closeness of $\mathcal{O}_{fix, r}$ to the Oracle $\mathcal{O}^*_{fix, r}$. As illustrated by Fig.~\ref{fig:analysis_illustration}, this analysis involves the following 3 pieces (i) we derive closed-form expressions of the False Negative (FN) and False Positive (FP) errors made by each RHO methods relative to Oracle, given by the size of $\mathcal{O}_{fp} = \mathcal{O}^*_{fix, r} \backslash \mathcal{O}_{fix, r}$ and $\mathcal{O}_{fn} = \mathcal{O}_{fix, r} \backslash \mathcal{O}^*_{fix, r}$, respectively. As detailed in Appendix.~\ref{appendix_sec:analysis_obj_time}, the FP and FN errors have significant effects on the objective and solve time,  which we derive conditions under which L-RHO outperforms the baselines. %  and roughly speaking, achieving competitive objective and solve time requires the RHO method to decrease the FP and FN errors simultaneously. 


\begin{figure*}[!t]
  \centering
    \begin{subfigure}[b]{0.32\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m25-j25-t30-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-w80-s25-t60-st3/train_pfix.png}
         \caption{$(25, 25, \slifinalblue{24})$ Start Delay}
     \end{subfigure}
         \begin{subfigure}[b]{0.32\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m30-j30-t30-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-w80-s25-t60-st3/train_pfix.png}
         \caption{$(30, 30, \slifinalblue{24})$ Start Delay}
     \end{subfigure}
     \begin{subfigure}[b]{0.32\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m30-j30-t30-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-optimtypedelay_and_tardiness-tlo0-thi30-w80-s25-t60-st3/train_pfix.png}
         \caption{$(30, 30, \slifinalblue{24})$ Start + End Delay}
     \end{subfigure}\\
     \begin{subfigure}[b]{0.32\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m30-j30-t30-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-optimtypedelay_and_tardiness-tlo0-thi30-w80-s25-t60-st3-perturbo0-perturbp0.2/train_pfix.png}
         \caption{$(30, 30, \slifinalblue{24})$  Start and End Delay \& Observation Noise}
     \end{subfigure}
        \begin{subfigure}[b]{0.32\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m35-j35-t38-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-w80-s25-t60-st3/train_pfix.png}
         \caption{$(35, 35, \slifinalblue{30})$\\Start Delay}
     \end{subfigure}
          \begin{subfigure}[b]{0.32\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m40-j40-t50-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-w80-s20-t60-st3/train_pfix.png}
         \caption{$(40, 40, 40)$\\Start Delay}
     \end{subfigure}
     % \includegraphics[width=\textwidth]{figures/paper_theory_plots/m25-j25-t30-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-w80-s25-t60-st3/val_pfix.png}
  \caption{\textbf{The empirical $p^*_{fix}(i)$ distribution across a variety of FJSP settings.} We plot the empirical distribution calculated by Eq.~\eqref{appendix_eq:pfix} with the solid green curve, and the fitted linear approximation $p^*_{fix}(i) = b - m \frac{i}{H-S}$ with the dashed red line. We also plot the empirical standard error (the shaded green area) computed across all RHO iterations, with $N_{iter}$ ranging from $20$ to $75$ (based on the FJSP problem size). We observe a consistent linear decreasing trend across all FJSP distributions, and the low standard errors further indicate consistency across RHO iterations.}
  \label{appendix_fig:pfix_dist}
\end{figure*}
\subsubsection{Empirical validation of the linear decay assumption for $p^*_{fix}(i)$} \label{appendix_sec:analysis_pfix}
We compute the distribution of $p^*_{fix}(i)$ using the training set $\mathcal{K}_{train}$. Specifically, for each FJSP training instance $P$ and RHO iteration $r$, we have a training label with the form $y^{P, r*} = \{y^{P, r*}_{O^{(i)}}\}_{O^{(i)} \in \mathcal{O}_{overlap, r}}$, where the index $i \in \{1, ..., H-S\}$ of each operations $O^{(i)}$ follows the RHO sequence order, and the associated $\mathcal{O}^*_{fix, r} = \{O^{(i)} \in \mathcal{O}_{overlap, r}: y_{O^{(i)}} = 1\}$. For each RHO iteration $r$, we calculate the empirical 
\begin{equation*}
    p^{*emp}_{fix, r}(i) = \frac{1}{N_P}\sum\limits_{\text{FJSP instance } P} y^{P, r*}_{O^{(i)}}, 
    \label{appendix_eq:pfix_r}
\end{equation*}
where $N_P$ is the number of training instances, from which we obtain the empirical distribution averaged across all RHO iterations and the associated standard error
\begin{equation}
    \begin{aligned}
        p^{*emp}_{fix}(i) & = \frac{1}{N_{iter}}\sum\limits_{\text{RHO iteration } r} p^{*emp}_{fix, r}(i), \\
        s.e.(p^{*emp}_{fix}(i)) &= s.t.d(\{p^{*emp}_{fix, r}(i)\}_{\text{RHO iteration } r}) / \sqrt{N_{iter}}, 
    \end{aligned}
    \label{appendix_eq:pfix}
\end{equation}
% \begin{equation}
%     p^{*emp}_{fix, r}(i) = \frac{1}{N_P N_{iter}}\sum\limits_{\substack{\text{FJSP instance } P \\ \text{RHO iteration r}}} y^{P, r*}_{O^{(i)}}, 
%     \label{appendix_eq:pfix}
% \end{equation}
where $N_{iter}$ is the number of RHO iterations. In Fig~\ref{appendix_fig:pfix_dist}, we visualize the empirical $p^{*emp}_{fix}(i)$ distributions (and the associated two standard errors) across a variety of FJSP settings, under the Oracle's best RHO parameter setting from grid search ($H = 80, S = 25$ for most settings). We also plot the linear approximation $p^*_{fix}(i) = b - m \frac{i}{H-S}$ through fitting the empirical distribution, resulting in $\mathbb{E}[n^*_{fix}] = \sum_{i=1}^{H-S}p^*_{fix}(i) = b - m \sum_{i=1}^{H-S}\frac{i}{H-S} = (b - \frac{m}{2})(H-S) - \frac{m}{2}.$

\textbf{Observations from the $p^*_{fix}$ distribution in Fig.~\ref{appendix_fig:pfix_dist}.} We observe a consistent linear decreasing trend across all distributions, with varying slopes and intercepts. The empirical distribution closely aligns with our fitted linear approximation, hence validating our Assump.~\ref{assump:linear_decrease}; the low standard error further reflects the consistency across RHO iterations. Intuitively, this is because the new operations $\mathcal{O}_{new}$ in the current RHO subproblem $\hat{P}$ are closer in the precedence order or release time with the later overlapping operations in $\mathcal{O}_{overlap}$, making them more likely to be scheduled around similar time and thus have more effect on each other's solution.

Moreover, $\mathbb{E}[n^*_{fix}$] is around $0.5(H-S)$ for all settings, with a higher $\mathbb{E}[n^*_{fix}$] in (c) for $(30, 30, \slifinalblue{24})$ with Start and End Delay, but lower $\mathbb{E}[n^*_{fix}]$ for larger FJSP sizes $(35, 35, \slifinalblue{30})$ and $(40, 40, 40)$ in (e) and (f). We have the following noteworthy comparisons: 

\begin{enumerate}[leftmargin=0.5cm]
\item Comparing FJSP $(30, 30, \slifinalblue{24})$ (c) Start and End Delay and (b) Start Delay, our analysis indicates that the larger number of Oracle fixed operations (high $\mathbb{E}[n^*_{fix}]$) in (c) enhances the performance of the Random and First heuristics (reducing performance gap relative to Default RHO) compared with (b). This aligns with our empirically observation when comparing (i) and (ii) of Fig~\ref{fig:additional experiment} (Right).
\item Comparing FJSP $(30, 30, \slifinalblue{24})$ (d) Start and End Delay \& Observation Noise with (c), our analysis indicates a performance decline of Random and First under observation noise, as (d) has a significantly lower $\mathbb{E}[n^*_{fix, r}]$ than (c). This is consistent with our empirical observation when comparing (iii) and (ii) in Fig~\ref{fig:additional experiment} (Right). Moreover, comparing (d) with (b), we see that (d) has a similar $\mathbb{E}[n^*_{fix, r}]$ but a notably lower slope $m$ than (b). Our analysis indicates that this reduces the performance advantage of First over Random, which is reflected by our empirical comparison of (iii) and (i) in Fig.~\ref{fig:additional experiment} (Right).
\end{enumerate}

\begin{table}[]
\caption{Closed-form expressions of $\mathbb{E}[n_{fp}]$ and $\mathbb{E}[n_{fn}]$ for Default, Random, First, and the learning method L-RHO with False Positive and Negative Rates $(\alpha, \beta)$.}
\label{appendix_tab:closed_form}
\centering
\scalebox{0.73}{
\begin{tabular}{lccc} 
\\[-0.7em] \hline \\[-0.7em]
& Random $\sigma_{R}$  & First $\sigma_{F}$    & L-RHO $(\alpha, \beta)$ \\\\[-0.7em]\hline\\[-0.7em]
\multicolumn{4}{c}{General $p^*_{fix}(i)$} \\[-0.7em]\\
\hline \\
$\mathbb{E}[n_{fp}]$  & $\sigma_{R}\sum\limits_{1\leq i \leq H-S}  (1-p^*_{fix}(i))$ & $\sum\limits_{1\leq i \leq \sigma_{F}(H-S)} (1-p^*_{fix}(i))$ & $\alpha \sum\limits_{1 \leq i \leq H-S} (1 - p^*_{fix}(i))$     \\ \\[-0.7em]
$\mathbb{E}[n_{fn}]$  & $(1-\sigma_{R})\sum\limits_{1 \leq  i \leq H-S} p^*_{fix}(i)$ & $\sum\limits_{\sigma_{F}(H-S)+1 \leq  i \leq (H-S)} p^*_{fix}(i)$ & $\beta\sum\limits_{1 \leq i \leq H-S} p^*_{fix}(i)$    \\[-0.7em] \\
\hline  \\[-0.7em]
\multicolumn{4}{c}{Linear Decreasing $p^*_{fix}(i) = b - m \frac{i}{H-S}$} \\[-0.7em]\\
\hline \\
$\mathbb{E}[n_{fp}]$  & $\sigma_{R} [(1-b + \frac{m}{2})(H-S) + \frac{m}{2}]$ & $\sigma_{F}[(1-b + \frac{m}{2}\sigma_{F})(H-S) + \frac{m}{2}]$ & $ \alpha [(1 - b + \frac{m}{2})(H-S) + \frac{m}{2}]$    \\\\ 
$\mathbb{E}[n_{fn}]$  & $(1-\sigma_R) [(b - \frac{m}{2})(H-S) - \frac{m}{2}]$    & $ (1-\sigma_F)[(b - \frac{m}{2} - \frac{m}{2}\sigma_F)(H-S) - \frac{m}{2}]$   & $\beta[(b-\frac{m}{2})(H-S) - \frac{m}{2}]$  \\[-0.7em]\\ 
\hdashline  \\[-0.7em]
\multicolumn{4}{c}{Equivalently, Given $\mathbb{E}[n_{fix}^*] = \sum_{i} p_{fix}^*(i) = (b - \frac{m}{2})(H-S) - \frac{m}{2}$} \\[-0.7em]\\
\hdashline \\
$\mathbb{E}[n_{fp}]$  & $\sigma_{R} \left(H-S-\mathbb{E}[n^*_{fix}]\right)$ & $\sigma_{F}\left(H-S-\mathbb{E}[n^*_{fix}] - \frac{m}{2}(1-\sigma_F)(H-S)\right)$ & $ \alpha \left(H-S-\mathbb{E}[n^*_{fix}]\right)$   \\\\ 
$\mathbb{E}[n_{fn}]$  & $(1-\sigma_R) \mathbb{E}[n^*_{fix}]$    & $ (1-\sigma_F)\left(\mathbb{E}[n^*_{fix}] - \frac{m}{2}\sigma_R(H-S)\right)$   & $\beta\mathbb{E}[n^*_{fix}]$
\\\\[-0.7em]\hline
\end{tabular}}
\end{table}

\subsubsection{Derivations of $\mathbb{E}[n_{fp}]$ and $\mathbb{E}[n_{fn}]$ for each method} \label{appendix_sec:analysis_fp_fn}
\textbf{Proposition 1.} \textit{The closed-form of $\mathbb{E}[n_{fp}]$ and $\mathbb{E}[n_{fn}]$ for Random $\sigma_R$, First $\sigma_F$ and L-RHO can be found in Table~\ref{appendix_tab:closed_form} for a general $p_{fix}^*(i)$ and a linearly decreasing $p_{fix}^*(i)$  distribution (Assump.~\ref{assump:linear_decrease}). Furthermore, ignoring an $\frac{m}{2}$ term in $\mathbb{E}[n^*_{fix}]$ for ease of exposition, The FPR and FNR of First $\sigma_F$ and Random $\sigma_R$ are $(\alpha_F, \beta_F) = (\frac{\sigma_F (1 - b + \frac{m}{2}\sigma_F)}{1 - b + \frac{m}{2}}, 1 - \frac{\sigma_F (b - \frac{m}{2}\sigma_F)}{b - \frac{m}{2}})$ and $(\alpha_R, \beta_R) = (\sigma_R, 1-\sigma_R)$.}
\begin{proof}
    See Appendix~\ref{appendix_sec:analysis_proof} for the detailed derivation of Table~\ref{appendix_tab:closed_form}. Since we have $\mathbb{E}[n_{fix}^*] = \sum_{i} p_{fix}^*(i) = (b - \frac{m}{2})(H-S) - \frac{m}{2}$, we can substitute the corresponding terms in the table with $\mathbb{E}[n_{fix}^*]$ and arrive at the last equivalent closed-forms as in the main paper Prop.~\ref{prop:closed_form}.
    
    Ignoring the $\frac{m}{2} \in [0, 1]$ term in $\mathbb{E}[n_{fix}^*]$, the coordinate transformation from the FP and FN errors $(\mathbb{E}[n_{fp}], \mathbb{E}[n_{fn}])$ to the FP and FN rates ($\alpha, \beta$) involves scaling the axes by $H-S -\mathbb{E}[n_{fix}^*] = (1-b+\frac{m}{2}) (H-S)$ and $\mathbb{E}[n_{fix}^*] = (b - \frac{m}{2})(H-S)$, respectively, from which we obtain the FPR and FNR for First $\sigma_F$ and Random $\sigma_R$. For example, 
    \begin{equation*}
        \begin{aligned}
            \beta_F & = \frac{\mathbb{E}[n_{fn}]}{\mathbb{E}[n^*_{fix}]} = \frac{(1-\sigma_F)(b - \frac{m}{2}- \frac{m}{2}\sigma_F)(H-S)}{(b-\frac{m}{2})(H-S)} = \frac{b - \frac{m}{2} - \frac{m}{2}\sigma_F - b\sigma_F + \frac{m}{s}\sigma_F + \frac{m}{2}\sigma_F^2}{b - \frac{m}{2}} \\
            & = \frac{b - \frac{m}{2} - b \sigma_F + \frac{m}{2}\sigma_F^2}{b - \frac{m}{2}} = 1 - \frac{\sigma_F(b - \frac{m}{2}\sigma_F)}{b - \frac{m}{2}}.
        \end{aligned}
    \end{equation*}
    % can similarly be obtained by dividing the respective FP and FN errors (e.g. $(\mathbb{E}[n^{First}_{fp, r}]), \mathbb{E}[n^{First}_{fn, r}])$) by the scaling factors $(H-S -\mathbb{E}[ n_{fix, r}^*])$ and $\mathbb{E}[n_{fix, r}^*]$.
    % For example, $\mathbb{E}[n^{\text{First }\sigma_F}_{fn, r}] = \sigma_F(1 - b + \frac{m}{2}\sigma_F)(H-S) +\epsilon^{F}_{fn}$ and $\mathbb{E}[n^{\text{First }\sigma_F}_{fn, r}] = \alpha (1-b+\frac{m}{2})(H-S) + \epsilon^{L}_{fn}$.   
    % Ignoring the negligible $\epsilon^{F}_{fn}$ and $\epsilon^{L}_{fn}$, we have $\alpha_F (1-b+\frac{m}{2})(H-S) = \frac{\sigma_F (1 - b + \frac{m}{2}\sigma_F)}{1 - b + \frac{m}{2}}(H-S) = \sigma_F(1 - b + \frac{m}{2}\sigma_F)(H-S)$. Hence, $\alpha_F = \frac{\sigma_F (1 - b + \frac{m}{2}\sigma_F)}{1 - b + \frac{m}{2}}$ is the equivalent L-RHO FNR for First $\sigma_F$.
\end{proof}



\subsubsection{Qualitative Relationship between ($\mathbb{E}[n_{fp}]$ and $\mathbb{E}[n_{fn}]$) and (objective, solve time)} 
\label{appendix_sec:analysis_obj_time}

Based on empirical observation and analytical insights, we interpret the effects of $\mathbb{E}[n_{fp}]$ and $\mathbb{E}[n_{fn}]$ on the objective and solve time in the table below (and also in Fig.~\ref{fig:analysis} left), where $+$ and $-$ reflects positive and negative correlations, respectively. 
% and (*) represents the more important factor for objective or solve time.
\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{ccc}
\hline \\[-0.7em] & \multicolumn{1}{c}{Objective} & \multicolumn{1}{c}{Solve Time} \\[-0.7em]\\ \hline \\[-0.7em]
$\mathbb{E}[n_{fp}]$ & $+$    &  \begin{tabular}[c]{@{}c@{}}$+$ (small $\mathbb{E}[n_{fp}]$) \\ or  \\ $-$ (large $\mathbb{E}[n_{fp}]$) \end{tabular}    \\[0.2cm]  \\ %  \hdashline \\[-0.7em] 
$\mathbb{E}[n_{fn}]$ & $+$              & $+$ \\[-0.7em]    \\ \hline
\end{tabular}
}
\end{table}
% the effect of $\mathbb{E}[n_{fp}]$ on the solve time (positive or negative) depends on its magnitude, and 

Specifically, 
% As $\mathbf{E}[n_{fp}]$ and $\mathbf{E}[n_{fn}]$ means the method incorrectly fixes assignments for operations 
\begin{itemize}[leftmargin=0.5cm]
    \item The objective is significantly affected by $\mathbb{E}[n_{fp}]$, the number of operations with incorrectly fixed machine assignments. A higher $\mathbb{E}[n_{fp}]$ indicates fixing more sub-optimal decision variables in the restricted subproblem $\hat{P}_r$, and hence worsens the objective value (often exponentially, as observed in Appendix~\ref{appendix_sec:additional_results} when $\sigma$ increases for Random / First). \textit{Therefore, reducing $\mathbb{E}[n_{fp}]$ improves the objective.}
    \item The solve time is heavily influenced by $\mathbb{E}[n_{fn}]$, the number of operations that have the same machine assignments but are failed to be identified. A higher $\mathbb{E}[n_{fn}]$ indicates a larger search space of the optimization subproblem $\hat{P}_r$, hence increasing the solve time (often exponentially, as observed when $\sigma$ decreases for Random / First). \textit{Hence, a lower $\mathbb{E}[n_{fn}]$ reduces the solve time.}
    % $\mathbb{E}[n_{fp}]$ represents the number of operations with incorrectly fixed machine assignment in the restricted subproblem $\hat{P}_r$. A high $\mathbb{E}[n_{fp}]$ leads to a suboptimal objective (primary effect), but it may reduce solve time by decreasing the subproblem size (secondary effect). 
    \item $\mathbb{E}[n_{fp}]$ has a mixed contribution to the solve time. On one hand, an increasing $\mathbb{E}[n_{fp}]$ reduces the size of the subproblem $\hat{P}_r$, which could reduce the solve time; on the other hand, an increasing $\mathbb{E}[n_{fp}]$ leads to more sub-optimal assignment fixing in $\hat{P}_r$, which potentially complicates the optimization landscapes and hence can increase the solve time, especially when $\mathbb{E}[n_{fp}]$ is small. \textit{Generally speaking, we observe that a higher $\mathbb{E}[n_{fp}]$ slightly increases the solve time in the low $\mathbb{E}[n_{fp}]$ regime (positive correlation) but reduces the solve time when $\mathbb{E}[n_{fp}]$ is close to $1$ (negative correlation).} Specifically, in Appendix~\ref{appendix_sec:additional_results}, we see that when $\mathbb{E}[n_{fp}]$ is low, L-RHO typically solves faster than First $\sigma_f$ baselines with a similar $\mathbb{E}[n_{fn}]$ but a higher $\mathbb{E}[n_{fp}]$; likewise, Oracle generally has a similar solve time as First $80\%$, whose $\mathbb{E}[n_{fp}]$ is much higher than Oracle.
    \item \textit{Reducing $\mathbb{E}[n_{fn}]$ can improve the objective under a given time limit}, as the correctly restricted subproblem $\hat{P}_r$ from a low $\mathbb{E}[n_{fn}]$ can simplify the optimization landscape. This effect is especialy evident  in the low $\mathbb{E}[n_{fp}]$ regime, where the baseline RHO methods often reach the time limit with a suboptimal solution, whereas our L-RHO with a lower $\mathbb{E}[n_{fn}]$ can often solve the subproblem $\hat{P}_r$ optimally with a shorter solve time. 
    % \item A high $\mathbb{E}[n_{fn}]$ indicates failure to identify and fix operations with the same machine assignment and hence failure to reduce the subproblem $\hat{P}_r$. This leads to a longer solve time due to the failure to reduce the subproblem size $\hat{P}_r$ (primary effect), which may further result in a worse objective because the optimization landscape becomes more challenging with a larger $\hat{P}_r$ under a given time limit (secondary effect). 
\end{itemize}

\textit{Therefore, to achieve objectives comparable to Default RHO while reducing the solve time, an effective RHO method should first \textbf{reduce $\mathbf{\mathbb{E}[n_{fp}]}$} to mitigate objective degradation, and subsequently \textbf{reduce $\mathbf{\mathbb{E}[n_{fn}]}$}, which can further reduces both solve time and objective in the small $\mathbb{E}[n_{fp}]$ regime.}

\textbf{More Visualizations.}
We provide additional visualizations of different FJSP variants in Fig.~\ref{appendix_fig:more_vis}, using the same plotting procedure as in Fig.~\ref{fig:analysis} (Right). The $(\alpha, \beta)$ of L-RHO is selected as the False Positive and Negative Rates on the validation set $\mathcal{K}_{val}$. Empirically, our L-RHO outperforms all baseline methods (Random, First, Default RHO) with a lower objective and has a similar solve time as First $60\%$; the pink regions in Fig.~\ref{appendix_fig:more_vis} illustrates the empirical dominance relationship of L-RHO over the respective First and Random baselines. Based on the above analysis, the effectiveness of our learning method L-RHO is due to its ability to simultaneously achieve a small $\mathbb{E}[n_{fp}]$ (which ensures a low objective) and a small $\mathbb{E}[n_{fn}]$ (which improves both the objective and solve time). In contrast, the heuristic baselines Random or First trades-off $\mathbb{E}[n_{fn}]$ and $\mathbb{E}[n_{fp}]$ by adjusting $\sigma$, but cannot obtain a low $\mathbb{E}[n_{fn}]$ and a $\mathbb{E}[n_{fp}]$ at the same time.

% \textit{Remark.} Our analysis focuses on the effect of the size $\mathbb{E}[n_{tn, r}]$ and $\mathbb{E}[n_{fp}]$ to the objective and solve time. While the analytical results closely align with empirical observations, the specific characteristics of each operation in $\mathcal{O}_{fn, r}$ and $\mathcal{O}_{fp, r}$ may have additional affect different for individual operations (e.g. there may exist an important overlapping operation subset with critical affects when incorrectly fixed or unfixed). We leave as an important future work to extend the analysis to incorporate the individual effects.


\begin{figure*}[!t]
  \centering
    \begin{subfigure}[b]{0.48\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m25-j25-t30-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-w80-s25-t60-st3/joint_analysis.png}
         \caption{$(25, 25, \slifinalblue{24})$ Start Delay}
     \end{subfigure}
         \begin{subfigure}[b]{0.48\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m30-j30-t30-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-w80-s25-t60-st3/joint_analysis.png}
         \caption{$(30, 30, \slifinalblue{24})$ Start Delay}
     \end{subfigure}\\
     \begin{subfigure}[b]{0.48\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m30-j30-t30-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-optimtypedelay_and_tardiness-tlo0-thi30-w80-s25-t60-st3/joint_analysis.png}
         \caption{$(30, 30, \slifinalblue{24})$ Start and End Delay}
     \end{subfigure}
     \begin{subfigure}[b]{0.48\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m30-j30-t30-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-optimtypedelay_and_tardiness-tlo0-thi30-w80-s25-t60-st3-perturbo0-perturbp0.2/joint_analysis.png}
         \caption{$(30, 30, \slifinalblue{24})$  Start and End Delay \& Obs. Noise}
     \end{subfigure}\\
        \begin{subfigure}[b]{0.48\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m35-j35-t38-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-w80-s25-t60-st3/joint_analysis.png}
         \caption{$(35, 35, \slifinalblue{30})$ Start Delay}
     \end{subfigure}
          \begin{subfigure}[b]{0.48\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/m40-j40-t50-p1-lo5-hi20-s0-h15-p-ct0.8-madapt-task-machine-cf3-w80-s20-t60-st3/joint_analysis.png}
         \caption{$(40, 40, 40)$ Start Delay}
     \end{subfigure}
  \caption{For a variety of FJSP distributions, we depict $\mathbb{E}[n_{fn}]$ and $\mathbb{E}[n_{fp}]$ of Random, First, and L-RHO in the low $\mathbb{E}[n_{fp}]$ region, using empirically validated $p^*_{fix}(i)$ distribution from Fig.~\ref{appendix_fig:pfix_dist} and L-RHO FPR-FNR $(\alpha, \beta)$ on the validation set. The pink region illustrates the empirical dominating region where our L-RHO has a better solve time and objective than all the baseline methods in the region; in particular, L-RHO has a better objective than all baseline methods, and a better solve time for a large range of $\sigma$ values (up to First $50\%-60\%$), as it can achieve low $\mathbb{E}[n_{fp}]$ and $\mathbb{E}[n_{fn}]$ simultaneously. Additionally, we can transform the coordinates to the FP and FN rates $(\alpha, \beta)$, as depicted by the right and top axes, to provide insights on what FP and FN rates should L-RHO achieve for learning to be effective.}
  \label{appendix_fig:more_vis}
\end{figure*}


\clearpage
\newpage
\subsubsection{Detailed Derivation of Table~\ref{appendix_tab:closed_form}.} \label{appendix_sec:analysis_proof}
\begin{proof}
\textbf{(1) General $p_{fix}^*(i)$ distribution.}
\begin{itemize}[leftmargin=0.3cm]
\item \textbf{Random $\sigma_{R}$:} by independence from the i.i.d. random sampling procedure, we have
\begin{equation*}
\scalebox{0.9}{$
\begin{aligned}[b]
\mathbb{E}[n^{\text{Random }\sigma_R}_{fp, r}] & = \sum\limits_{1 \leq  i \leq H-S} Pr(\text{operation } O^{i} \in 
\mathcal{O}_{fix, r} \text{ and } i \notin \mathcal{O}^*_{fix, r}),  \\
& = \sum\limits_{1 \leq  i \leq H-S} Pr(\text{operation } O^{(i)} \in 
\mathcal{O}_{fix, r})(1 - Pr(O^{(i)} \in \mathcal{O}^*_{fix, r})) \\
& = \sum\limits_{1 \leq  i \leq H-S} \sigma_R (1-p^*_{fix}(i)), \\
\mathbb{E}[n^{\text{Random }\sigma_R}_{fn, r}] & = \sum\limits_{1 \leq  i \leq H-S} Pr(\text{operation } O^{(i)} \notin 
\mathcal{O}_{fix, r} \text{ and } O^{(i)} \in  \mathcal{O}^*_{fix, r}) \\
& = \sum\limits_{1 \leq  i \leq H-S} Pr(\text{operation } O^{(i)} \notin 
\mathcal{O}_{fix, r})Pr(O^{(i)} \in  \mathcal{O}^*_{fix, r})\\
& = \sum\limits_{1 \leq  i \leq H-S} (1-\sigma_R) p^*_{fix}(i), \\
\end{aligned}$
}
\end{equation*}
where the sum is over all overlapping operations in $\mathcal{O}_{overlap, r}$.
\item \textbf{First $\sigma_F$}: as it always selects the first $\sigma_F(H-S)$ operations, we have
\begin{equation*}
\scalebox{0.9}{$
\begin{aligned}[b]
\mathbb{E}[n^{\text{First }\sigma_F}_{fp, r}] & = \sum\limits_{1\leq i \leq \sigma_F(H-S)} Pr(\text{operation } O^{(i)} \notin \mathcal{O}^*_{fix, r}) = \sum\limits_{1 \leq i \leq \sigma_F(H-S)} (1-p^*_{fix}(i)), \\
\mathbb{E}[n^{\text{First }\sigma_F}_{fn, r}] & = \sum\limits_{\sigma_F(H-S)\leq i \leq (H-S)} Pr(\text{operation } O^{(i)} \in \mathcal{O}^*_{fix, r}) = \sum\limits_{\sigma_F(H-S)\leq i \leq (H-S)} p^*_{fix}(i), \\
\end{aligned}$
}
\end{equation*}
where the sum is over the first $k(H-S)$ overlapping operations in $\mathcal{O}_{overlap, r}$.
\item \textbf{L-RHO $(\alpha, \beta)$}: Given the the relationship between FP, FN rates and FP, FN errors, we have
\begin{equation*}
\scalebox{0.9}{$
\begin{aligned}[b]
\mathbb{E}[n^{\text{L-RHO}}_{fp, r}] & = \alpha (H-S-\mathbb{E}[n^*_{fix, r}]) = \sum\limits_{1 \leq i \leq H-S} \alpha (1 - p^*_{fix}(i)),\\ 
\mathbb{E}[n^{\text{L-RHO}}_{fn, r}] & = \beta \mathbb{E}[n^*_{fix, r}] = \sum\limits_{1 \leq i \leq H-S} \beta \; p^*_{fix}(i). 
\end{aligned}$
}
\end{equation*}
\end{itemize}

\textbf{(2) Linearly decreasing $p^*_{fix}(i) = b - m\cdot \frac{i}{H-S}$.}

We have $1 - p^*_{fix}(i) = (1 - b) + m \cdot \frac{i}{H-S}$, and we first compute the following quantities 
\begin{equation*}
    \scalebox{0.9}{$
    \begin{aligned}[b]
        \sum\limits_{1\leq i\leq H-S} \frac{i}{H-S} & = \frac{1+H-S}{2}; \quad \sum\limits_{1\leq i\leq \sigma_F(H-S)} \frac{i}{H-S} = \frac{\sigma_F+\sigma_F^2(H-S)}{2}\\
        \sum\limits_{\sigma_F(H-S)\leq i\leq (H-S)} \frac{i}{H-S} & =  \sum\limits_{1\leq i\leq H-S} \frac{i}{H-S} - \sum\limits_{1\leq i\leq \sigma_F(H-S)} \frac{i}{H-S}= \frac{(1-\sigma_F)+(1-\sigma_F^2)(H-S)}{2}\\
        \sum\limits_{1\leq i \leq H-S} p^*_{fix}(i) & = \sum\limits_{1 \leq i \leq H-S} b - m \cdot \frac{i}{H-S} = (b - \frac{m}{2})(H-S) - \frac{m}{2} \\
        \sum\limits_{1\leq i \leq \sigma_F(H-S)} p^*_{fix}(i) & = \sum\limits_{1 \leq i \leq \sigma_F(H-S)} b - m \cdot \frac{i}{H-S} = \sigma_F(b-\frac{m}{2}\sigma_F)(H-S) - \sigma_F\frac{m}{2}\\
        \sum\limits_{\sigma_F(H-S) + 1\leq i \leq (H-S)}  p^*_{fix}(i) & = (1-\sigma_F)(b-\frac{m}{2} - \frac{m}{2}\sigma_F)(H-S) - (1-\sigma_F)\frac{m}{2}\\
        \sum\limits_{1\leq i \leq H-S}  (1-p^*_{fix}(i)) &  = \sum\limits_{1 \leq i \leq (H-S)} (1-b) + m \cdot \frac{i}{H-S} = (1-b + \frac{m}{2})(H-S) + \frac{m}{2} \\
        \sum\limits_{1\leq i \leq \sigma_F(H-S)}  (1-p^*_{fix}(i)) & = \sum\limits_{1 \leq i \leq \sigma_F(H-S)} (1-b) + m \cdot \frac{i}{H-S} = \sigma_F(1-b + \frac{m}{2}\sigma_F)(H-S) + \sigma_F\frac{m}{2} 
    \end{aligned}$
    }
\end{equation*}
We hence have
\begin{itemize}[leftmargin=0.3cm]
\item \textbf{Random $\sigma_{R}$:} 
\begin{equation*}
\begin{aligned}
\mathbb{E}[n_{fp}] & = \sum\limits_{1 \leq i \leq H-S} \sigma_R (1-p^*_{fix}(i)) = \sigma_R (1- b + \frac{m}{2})(H-S) + \sigma_R \frac{m}{2}, \\ 
\mathbb{E}[n_{fn}] & = \sum\limits_{1 \leq i \leq H-S} (1-\sigma_R) p^*_{fix}(i) = (1-\sigma_R) (b - \frac{m}{2})(H-S) - (1-\sigma_R) \frac{m}{2}.
\end{aligned}
\end{equation*}
\item \textbf{First $\sigma_{F}$}:
\begin{equation*}
\begin{aligned}
\mathbb{E}[n^{\text{First }\sigma_F}_{fp, r}] & = \sum\limits_{1 \leq i \leq \sigma_F(H-S)} (1-p^*_{fix}(i)) = \sigma_F(1-b + \frac{m}{2}\sigma_F)(H-S) + \sigma_F \frac{m}{2}, \\
\mathbb{E}[n^{\text{First }\sigma_F}_{fn, r}] & = \sum\limits_{\sigma_F(H-S) + 1 \leq i \leq (H-S)} p^*_{fix}(i) = (1-\sigma_F)(b-\frac{m}{2} - \frac{m}{2}\sigma_F)(H-S) - (1-\sigma_F) \frac{m}{2}.
\end{aligned}
\end{equation*}
\item \textbf{L-RHO $(\alpha, \beta)$}: 
\begin{equation*}
\begin{aligned}
\mathbb{E}[n^{\text{L-RHO}}_{fp, r}] & =  \sum\limits_{1 \leq i \leq H-S} \alpha (1 - p^*_{fix}(i)) =  \alpha (1 - b + \frac{m}{2})(H-S) +  \alpha \frac{m}{2}, \\
\mathbb{E}[n^{\text{L-RHO}}_{fn, r}] & =  \sum\limits_{1 \leq i \leq H-S} \beta \; p^*_{fix}(i) =  \beta  (b - \frac{m}{2})(H-S) - \beta \frac{m}{2}.
\end{aligned}
\end{equation*}
\end{itemize}
\end{proof}

\subsubsection{Interpretation of Prop.~\ref{prop:closed_form}}
\label{appendix_sec:analysis_interpretation}
We obtain the following insights by interpreting Prop.~\ref{prop:closed_form} .
\begin{enumerate}[leftmargin=0.5cm]
    \item The $p^*_{fix}(i)$ distribution determines the strength of the Random and First baselines and thus the potential for improvement by learning methods. Specifically, $\mathbb{E}[n^*_{fix}]$ governs the performance of Random: when $\mathbb{E}[n^*_{fix}] \approx 0.5$, Random suffers from either high FP error or high FN error across all $\sigma_R$, but when $\mathbb{E}[n^*_{fix}] = 0$ (or $1$), then Random $\sigma_R = 0$ (or $100\%$) can simultaneously achieve zero FP and FN errors. Moreover, the magnitude of the slope  $m$ indicates how much First can improve over Random, with a larger $m$ leading to greater improvement (Fig.~\ref{fig:analysis} (middle)).
    \item The qualitative relationship between the FP \& FN errors and objective \& solve time is illustrated in Fig.~\ref{fig:analysis} (left) and further elaborated in Appendix~\ref{appendix_sec:analysis_obj_time}. Specifically, the FP error represents sub-optimal assignments incorrectly fixed in $\hat{P}$, which harms the objective, whereas the FN error corresponds to (near)-optimal assignments failed to be fixed in $\hat{P}$, which negatively impacts both metrics (solve time and objective) when a time limit is imposed. Thus, effective RHO methods should maintain low a FP error for a competitive objective and a low FN error to further improve both metrics; this is indeed achieved by our L-RHO, as evident in Fig.~\ref{fig:analysis} (right). 
    \item We can further convert the FP and FN errors $(\mathbb{E}[n_{fp}], \mathbb{E}[n_{fn}])$ into the FP and FN rates $(\alpha, \beta)$, as shown by the right and top axes in Fig.~\ref{fig:analysis} (right). In this case, $\alpha_F$ and $\beta_F$ in Prop.~\ref{prop:closed_form} can be interpreted as the FPR and FNR that L-RHO's learned model should achieve to match the performance of First $\sigma_F$. This provides a valuable estimate to identify what $(\alpha, \beta)$ should we aim for when training L-RHO and to assess the effectiveness of the learned model before deployment.
\end{enumerate}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\newpage


\end{document}