\section{Introduction}

Tabular data, despite being one of the most prevalent data modalities in real-world applications \citep{benjelloun2020google}, often encounters several issues in practical use. These include imbalanced data categories \citep{cao2019learning}, privacy concerns \citep{gascon2016privacy} (as many tabular datasets contain sensitive personal information that cannot be directly shared), insufficient data quality \cite{lin2020missing}, and high data collection costs \citep{even2007economics}. Tabular generation is an important means to address these problems. Classic tabular generation methods such as GANs \citep{ctgan}, VAEs \citep{goggle}, and diffusion models \citep{stasy,codi,tabddpm,tabsyn} have two main limitations. First, they require large amounts of tabular data for training, which leads to a noticeable decline in performance in low-resource scenarios. This is particularly problematic considering that most real-world situations requiring tabular generation lack abundant data. Second, they need special preprocessing to handle heterogeneous data types, making them less flexible.


The rapid development of large language models (LLMs) brings new possibilities for solving table data generation problems with their powerful semantic understanding, reasoning, and generation capabilities. LLMs can understand and process various data types and structures without complicated data preprocessing, offering more flexible and principled solutions. Moreover, LLMs' few-shot learning ability may alleviate data scarcity issues, enabling excellent performance in low-resource scenarios. Previous works \citep{great, realtabformer, taptap, tabula, tabmt, Xu2024AreLN, Wang2024HARMONICHL} resort to fine-tuning general-purpose LLMs on target tables. While effective, fine-tuning requires substantial computational resources, making it inapplicable in resource-scarce scenarios. 

\begin{figure}[t!] 
    \centering

    \subfigure[No in-context Ex.]{\includegraphics[width=0.48\linewidth]{Figs/no_prompt.png}}
    \hfill
    \subfigure[Sampled in-context Ex.]{\includegraphics[width=0.48\linewidth]{Figs/cllm_ret.png}}
    
    \subfigure[Fixed in-context Ex.]{\includegraphics[width=0.48\linewidth]{Figs/simple.png}}
    \hfill
    \subfigure[Ground Truth]{\includegraphics[width=0.48\linewidth]{Figs/gt_2000.png}}
\caption{Comparison of samples generated with different in-context learning examples. Plots show the latitude and longitude coordinates of California housing, with the solid line representing the state boundary.
(a) 2000 samples generated by LLM with only the table header as input, \textbf{without} any in-context examples.
(b) 2000 samples generated by LLM, giving in-context examples sampled from the real dataset.
(c) 2000 synthetic samples generated by LLM, giving in-context examples with latitude and longitude in a fixed range. (d) 2000 samples from the ground truth training table.}
\label{fig:in-context-examples}
\vspace{-1em}
\end{figure}



In-context learning effectively solves such problems. By adding examples to the context, distribution characteristics can be provided to LLMs, guiding them to generate data that conforms to the target distribution without specific fine-tuning \citep{gao2023retrieval}. However, simple in-context learning strategies still face challenges. Figure \ref{fig:in-context-examples}(a) shows that even without in-context examples (see the full prompt at Appendix \ref{appendix:dummy_prompt}), LLMs can generate reasonable distributions, reflecting the influence of the LLM's pre-training distribution. Figure \ref{fig:in-context-examples}(b) demonstrates the strategy proposed by \citep{cllm}, which involves random sampling from Ground Truth as in-context examples. Although the generated results are closer to the Ground Truth shown in Figure \ref{fig:in-context-examples}(d) compared to Figure \ref{fig:in-context-examples}(a), they are still mainly influenced by the LLM's original distribution and struggle to fit the Ground Truth.

This phenomenon reveals the importance of choosing in-context examples. In this work, we propose \modelname, a dynamic in-context example selection method. 
Inspired by the observation in Figure \ref{fig:in-context-examples}(c), we found that using fixed range in-context examples leads to generated distributions closely mimicking those examples, significantly differing from the LLM's original distribution. This indicates in-context learning's ability to simulate distributions. By carefully selecting in-context examples, we can more effectively guide LLMs to generate distributions closer to the ground truth.
 
Central to our framework is the design of an automated strategy for selecting effective in-context examples while ensuring global consistency with the real data distribution. Our key idea is to utilize simple, discernible patterns in subsets of real samples, which can effectively guide LLMs in generating realistic tabular data. Specifically, \modelname identifies subsets of real samples that exhibit simple patterns and closely match the residual between the current generated data distribution and the real data distribution. This idea can be categorized as a novel residual-aware RAG technique, where we retrieve in-context examples based on the residual between the generated and real data distributions.

The residual-aware sampling measures the discrepancy between the generated and real data distributions, focusing on areas where the model needs improvement. This approach enables \modelname to progressively narrow the distribution gap while maintaining the use of easily learnable patterns in the in-context examples. Our sampling technique offers two key advantages: flexibility in selecting simple patterns for effective learning, and consistent generation through progressive distribution alignment. The contributions of this paper are as follows:
\begin{enumerate}[leftmargin=*]
    \item We propose \modelname, an in-context learning selection method that retrieves in-context examples by leveraging residual between currently generated samples and true data distributions.
    
    \item We conduct extensive experiments on five datasets, evaluated under three distinct groups of synthetic data evaluation metrics. Experiment results show that \modelname outperforms the previous in-context learning method by a margin of $3.5\%-42.2\%$ across multiple fidelity metrics. Notably, \modelname surpasses state-of-the-art deep generative models under the data-scarce scenarios.
\end{enumerate}


