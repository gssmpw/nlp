\begin{table}[h]
    \vspace{-1mm}
    \centering
    \begin{tabularx}{\linewidth}{>{\centering\arraybackslash}X | >{\centering\arraybackslash}X | c}
        \toprule
        \textbf{Model} & \textbf{Quality$\uparrow (\%)$} & \textbf{Rank} \\
        \midrule
        GPT-4o-mini       & $91.86${\tiny$\pm 0.008$}   & 3 \\
        GPT-4o            & $94.69${\tiny$\pm 0.006$}  & 1 \\
        Gemini-1.5-Flash  & $89.96${\tiny$\pm 0.017$}  & 4 \\
        Gemini-1.5-Pro    & $92.21${\tiny$\pm 0.033$}  & 2 \\
        Claude-3-Haiku    & $89.17${\tiny$\pm 0.031$}  & 5 \\
        Claude-3-Sonnet   & $88.97${\tiny$\pm 0.068$}  & 6 \\
        \bottomrule
    \end{tabularx}
    \caption{Effect of large language models on the performance of \modelname.}
    \vspace{-1em}
    \label{tbl:ablation_model}
\end{table}