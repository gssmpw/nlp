\section{Related Work}
\label{sec:related_works}
\subsection{Spectral-Based Methods}
\label{subsec:spectral_methods}
Spectral methods are grounded in the spectral theory and derive the low-dimensional embedding through eigenvalue decomposition. PCA____ decomposes the covariance matrix, and its embedding maximizes the variance within the subspace, which is considered to be the largest shadow of the data. Multidimensional scaling (MDS)____ provides a general framework that utilizes a distance matrix to derive the low-dimensional embedding, and Isomap____ is a variant of MDS that utilizes the geodesic distance. However, these methods do not consider the local structure, which results in crowded visualizations. Laplacian eigenmaps____ serve as an intermediate method by decomposing the Laplacian of the neighborhood graph where the neighborhood graph is estimated based on the point-wise distance. The relationship between the Laplacian Eigenmaps and the neighbor embedding methods is discussed in the literature____.

\subsection{Neighbor Embedding Methods}
\label{subsec:ne_methods}
Neighbor embedding methods attempt to minimize the loss of neighbor relations. t-SNE____ is considered a gold standard that employs KL divergence as the loss function. The t-SNE embedding is much more discriminative than previous spectral-based methods; thus it is particularly effective for data visualization. Numerous variants of t-SNE have been developed, e.g., parametric____, triplet____, and computationally efficient extensions____. However, KL divergence requires normalization of the neighborhood graph, which complicates scalable optimization. UMAP____ enhances the scalability of neighbor embedding algorithms by leveraging a fuzzy set cross-entropy loss that does not require normalization, similar to that of LargeVis____, thereby reducing the computational complexity. Both t-SNE and UMAP have become standard baselines for DR-based data visualization. 
\par
Recent studies have investigated the relationship between neighbor embedding methods and their improvement. The attraction-repulsion framework____ and contrastive learning-based analysis____ are valuable for uncovering their relations. The major problem with neighbor embedding methods is their inability to preserve the global structure, which has been considered in efforts for improvement. For example, PaCMAP____ introduces the middle neighbor similarity to preserve the global structure effectively. In addition, initialization-based improvements, particularly using PCA initialization, also play a crucial role____. However, while these improvements show promise, they remain limited. We incorporate the PCA embedding into the neighbor embedding to address this limitation.