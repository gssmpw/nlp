\section{Related Work}
\vspace{-1em}
The rapid proliferation of misinformation and disinformation has given rise to the development of automated fact-checking systems to combat them **Vrandeich, "Combating Misinformation"**. The automated fact-checking process involves three stages comprising \textit{claim detection}, which identifies salient spans to be fact-checked, 
followed by \textit{evidence retrieval} that focuses on identifying sources that support or refute claims and finally the fact-verification stage that uses the evidence collected to categorize the claims.

A significant challenge in verification includes source reliability **Kampylis, "Evaluating Source Reliability"**, hence fact-checking primarily relies on verified knowledge sources. Sources such as encyclopedias, policy documents, and scientific journals are common knowledge sources employed for retrieving information **Vrandeich, "Knowledge Sources"**. Recent advancements advocate a simplified two-step evidence retrieval approach: a context retriever selects a subset of passages that might contain the answer followed by a machine reader analyzing these passages to identify the correct answer. Initially, evidence retrieval relied on inverted indexes (e.g., TF-IDF, BM25) for keyword-based searches but these lack semantic understanding **Kampylis, "Semantic Understanding"**. The advances in representation learning have led to the rise of dense retrieval where queries and documents are projected to a continuous vector space  **Frommig, "Dense Retrieval"**. While existing approaches employ brute force search in the vector space to retrieve relevant documents for the queries, this is not scalable for web-scale search **Kampylis, "Scalability"**. Compact vector representations are crucial for efficiency, despite potential noise-induced performance drops **Frommig, "Noise-Induced Performance Drops"**. Efficient approaches like Approximate Nearest Neighbors (ANN) search in vector databases have emerged to reduce complexity and enhance similarity search accuracy **Kampylis, "ANN Search"**. Early on hash-based and tree-based methods were used but faced limitations in large-scale databases and semantic features. Recent advancements make use of quantization techniques, such as Product Quantization**Jegou, "Product Quantization"** and Optimized PQ (OPQ) **Gross, "Optimized PQ"**, to improve efficiency by vector dimension reduction with minimal performance loss.

    
% \textit{Fact verification} forms the third stage and entails assessing the veracity of the claim based on the retrieved evidence **Vrandeich, "Fact Verification"**, often employing binary or multi-class labels **Kampylis, "Binary/Multi-Class Labels"**. Automated fact-checking mainly uses supervised text classification methods **Kampylis, "Supervised Text Classification"**, which, while effective for some tasks, lack the broader world knowledge for comprehensive checking. Improving verdict interpretations is crucial **Vrandeich, "Verdict Interpretations"**, especially with black-box models, through highlighting salient evidence, designing transparent decision-making processes, and generating textual explanations. Large Language Models (LLMs) are increasingly used for natural language tasks due to their impressive performance **Kampylis, "Large Language Models"**. However, they often generate factually inconsistent outputs, or hallucinations, which look plausible but deviate from reality **Frommig, "Hallucinations"**. This issue hinders their use in critical applications like healthcare and legal fields, raising concerns about misinformation, safety, and privacy **Kampylis, "Misinformation Concerns"**. LLMs can encode vast amounts of information **Jegou, "Vast Information Encoding"** but struggle with dynamic, temporal knowledge **Gross, "Temporal Knowledge"**. To address this, efforts are being made to augment LLMs with external knowledge **Kampylis, "External Knowledge Augmentation"**. This includes two main approaches: 1) retrieve-and-generate models (e.g. RAG**Lewis, "RAG"**) which combine a knowledge retriever with a generative model, and 2) k-Nearest Neighbor LMs (e.g. RETOMATON**Jegou, "RETOMATON"**) which use K-NN models to improve token prediction. Additionally, post-hoc attribution and edit methods like RARR**Frommig, "RARR"** and PURR**Gross, "PURR"**, retrieve relevant evidence and edit outputs to ensure factual consistency. Existing benchmarks for evaluating factual consistency in LLM-generated texts, such as FactScore **Kampylis, "FactScore Benchmark"**, HaluEval  **Frommig, "HaluEval Benchmark"**, and LLM-augmenter **Gross, "LLM-Augmenter Benchmark"**, focus on fact verification rather than efficient evidence retrieval. 
Our contributions aim to explore efficient retrieval approaches to improve the efficiency of the fact-checking process, enhancing the practical applicability of these systems in real-world scenarios such as live fact-checking over large knowledge bases.



% In this section, we discuss prior work and recent advances.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The notion of fact-checking delves into the logic, coherence, and context of claims **Vrandeich, "Logic of Fact-Checking"**. In the fact-checking process, fact verification serves as a crucial preliminary step in acquiring and confirming facts, ensuring the trustworthiness of the information under consideration. The surge in demand for automated fact-checking has prompted rapid advancements in the development of tools and systems for it. Successful of these pipelines rely on efficient handling of large document collections, optimal text span granularity for detailed answers, contextual awareness for appropriate text granularity selection, and versatility across domains **Kampylis, "Fact-Checking Pipelines"**.  Currently, the typical fact-checking process involves three stages: (i) \textit{claim detection} involves identifying salient text spans from a large collection; (ii) \textit{evidence retrieval} focuses on finding sources that either support or refute the claim; and (iii) \textit{fact verification} entails assessing the veracity of the claim based on the retrieved evidence **Vrandeich, "Fact Verification"**. \\

% For the claim detection part, there is no formal definition of what constitutes a claim **Kampylis, "Claim Definition"**. Some existing work establishes check-worthiness as a possible concept **Frommig, "Check-Worthiness Concept"**. It determines a claim when one wants to know the truth of that assertion, which either requires binary classification or an importance-ranking to classify. Another method, used in social media settings, is whether text spans are detected for rumourness. Nonetheless, these two methods are quite subjective as the language understanding and importance of the concepts differs between social groups or even individuals **Jegou, "Subjective Methods"**. Furthermore, the information pertaining to the claim can change over time or have been debunked already, no longer necessitating the need for verification. A more objective approach is to classify text as an assertion if it's checkable with available evidence **Vrandeich, "Objective Approach"**. \\

% Early retrieval systems were typically complex, composed of numerous components **Kampylis, "Complex Retrieval Systems"**. However, recent advancements in reading comprehension models advocate for a simplified two-step approach: initially, a context retriever selects a subset of passages, some of which potentially contain the answer to the query, followed by a thorough analysis by a machine reader to identify the correct answer. Nonetheless, a notable challenge arises concerning the sources from which information is pulled **Frommig, "Information Sources"**. The task of fact-checking requires access to reliable and trustworthy knowledge sources that have been thoroughly verified. These sources serve as the foundation for retrieving evidence-based information. These include a diverse array of textual sources such as encyclopedia articles, policy documents, verified news articles, and scientific journals, which offer rich information for verifying claims **Kampylis, "Textual Sources"**. Additionally, knowledge graphs or fact databases provide structured canonical information about the world, though their limitations must be considered, as not all facts may be present in them **Jegou, "Knowledge Graphs"**. Social media and online content analysis offer insights into the veracity of claims, especially when traditional textual or structured knowledge sources are unavailable **Gross, "Social Media Analysis"**. \\

% Lastly, for fact verification, either binary classification using supported/refuted labels or Multi-class labels are utilized **Kampylis, "Fact Verification Labels"**. The latter mimicking journalistic fact-checking practices, to include more fine-grained classification schemes or indicate when not enough information could be retrieved. 
% Automated fact-checking primarily relies on supervised text classification methods, often using labelled data from fact-checking agencies **Frommig, "Supervised Text Classification"**. While effective for some tasks, it lacks the broader world knowledge necessary for comprehensive fact-checking. Other approaches include network analysis, Recognizing Textual Entailment, and distant relation extraction. Speaker profiling, such as analyzing the credit history of claim originators, can enhance accuracy but raises ethical concerns **Kampylis, "Speaker Profiling"**. To further improve the verdict interpretations, the justification procedure is important **Vrandeich, "Justification Procedure"**. Particularly in automated fact-checking where black-box models lack transparency. Strategies include highlighting salient evidence, designing understandable decision-making processes, and generating textual explanations **Gross, "Transparency Strategies"**.