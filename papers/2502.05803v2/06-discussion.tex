\section{Open Questions (Remove)}
 \label{open_questions}


The proposed framework \car{} comprises a rewriter and ranker. One possible research direction is to explore end-to-end fine-tuning of the rewriter and ranker based on feedback from downstream retrieval performance. In the proposed approach \car{}, the context in the prompt is derived from the relevant document for the query. However, we observe that for longer documents, providing a concise context by truncating the original document prevents topic drift and generates concise query rewrites which reflect the user information need. One possible direction is to explore principled and automated approaches for learning to select the most relevant context for constraining the LLM outputs and guiding them to generate queries that improve document ranking performance. Existing works like active sample selection \cite{zhang-etal-2022-active} for in-context learning explores the use of RL-based approaches for selecting demonstration samples. We posit that similar approaches could be leveraged to select relevant contexts to prompt the LLM for context-aware query reformulation.

 


% \subsection{Intent Diversification}
% An overarching goal of the proposed framework is to minimize the \textit{hard rewrites} discussed in Section \ref{sec:framework}. To ensure the generative model (rewriter) generates diverse queries, the training data must ensure high \textit{intent coverage}. This implies that the dataset contains diverse intents for each query. The coverage of intents is an important consideration when selecting datasets for fine-tuning the proposed rewriter or in case of in-context learning examples. It is also vital to ensure the dataset does not contain topic drifts.
% As proposed in this work, we have leveraged several data augmentation methods based on existing large language models and TREC datasets. However, the topic descriptions in TREC are not comprehensive enough in terms of coverage of different types of intent for the same query. Additionally LLMs have been found to hallucinate \cite{hallucination}, which might lead to misconstrued machine intent in the proposed pipeline. We propose potential directions to tackle this issue.
% Dataset distillation \cite{dataset_distillation} approaches could be explored for accomplishing the selection of informative samples. This method employs several metrics from information theory for quantifying the quality of training samples. The metric is used to filter out uninformative samples yielding a succinct training set which improves performance on intended tasks. The choice of metric for query rewriting would be \textit{intent diversity}. This would be a composite metric ensuring the natural language summaries of queries are not redundant and reflect different possible intents. Further, an external Knowledge Base (KB) could be employed to ground the possible intents for each query and filter out data which deviates from the KB. Several existing approaches like REALM and LM-CORE \cite{lm_core} retrieve relevant information from knowledge based like Wikipedia and Concept-Net to aid in text completion. They could be leveraged to decipher the possible intents for an ambiguous query and compute the coverage metric. 
% Though data distillation leads to informative samples, the sample selection is limited to the training data distribution. To learn the underlying manifold of informative samples, synthetic dataset generation approaches have been proposed \cite{dataset_condensation}. These approaches aim to synthesize a smaller set that achieves similar or better performance than the default training set through gradient matching approaches.
%\vspace{-3mm}
\subsection{Limitations} In our current approach, we choose ambiguous queries based on heuristics like the query length and specific types of queries like acronyms, entities with multiple meanings based on context. Though these heuristics reflect the nature of ambiguous queries, a more principled approach would help identify and filter ambiguous queries.
\label{limitations}

