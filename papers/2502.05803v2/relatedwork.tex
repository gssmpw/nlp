\section{Related Work}
\vspace{-1em}
The rapid proliferation of misinformation and disinformation has given rise to the development of automated fact-checking systems to combat them \cite{thorne2018fever,programfc,guo2022survey,v2024quantemprealworldopendomainbenchmark,questgen}. The automated fact-checking process involves three stages comprising \textit{claim detection}, which identifies salient spans to be fact-checked, 
followed by \textit{evidence retrieval} that focuses on identifying sources that support or refute claims and finally the fact-verification stage that uses the evidence collected to categorize the claims.

A significant challenge in verification includes source reliability \cite{guo2022survey}, hence fact-checking primarily relies on verified knowledge sources. Sources such as encyclopedias, policy documents, and scientific journals are common knowledge sources employed for retrieving information \cite{Lazarski2021nlpfact, thorne2018automated}. Recent advancements advocate a simplified two-step evidence retrieval approach: a context retriever selects a subset of passages that might contain the answer followed by a machine reader analyzing these passages to identify the correct answer. Initially, evidence retrieval relied on inverted indexes (e.g., TF-IDF, BM25) for keyword-based searches but these lack semantic understanding \cite{baranchuk2018revisiting, wei2022}. The advances in representation learning have led to the rise of dense retrieval where queries and documents are projected to a continuous vector space  \cite{karpukhin2020dense, zhao2022,Guo_2022}. While existing approaches employ brute force search in the vector space to retrieve relevant documents for the queries, this is not scalable for web-scale search \cite{bondarenko2021understanding, zhu2023survey, han2023comprehensive, wei2022,tas_b}. Compact vector representations are crucial for efficiency, despite potential noise-induced performance drops \cite{zhan2021jointly}. Efficient approaches like Approximate Nearest Neighbors (ANN) search in vector databases have emerged to reduce complexity and enhance similarity search accuracy \cite{han2023comprehensive, wei2022, zhao2023ann}. Early on hash-based and tree-based methods were used but faced limitations in large-scale databases and semantic features. Recent advancements make use of quantization techniques, such as Product Quantization\cite{jegou2011pq} and Optimized PQ (OPQ) \cite{ge2014opq}, to improve efficiency by vector dimension reduction with minimal performance loss.

    
% \textit{Fact verification} forms the third stage and entails assessing the veracity of the claim based on the retrieved evidence \cite{guo2022survey}, often employing binary or multi-class labels \cite{guo2022survey, thorne2018automated}. Automated fact-checking mainly uses supervised text classification methods \cite{thorne2018automated}, which, while effective for some tasks, lack the broader world knowledge for comprehensive checking. Improving verdict interpretations is crucial \cite{guo2022survey}, especially with black-box models, through highlighting salient evidence, designing transparent decision-making processes, and generating textual explanations. Large Language Models (LLMs) are increasingly used for natural language tasks due to their impressive performance \cite{openai2023gpt4,ouyang2022training,touvron2023llama}. However, they often generate factually inconsistent outputs, or hallucinations, which look plausible but deviate from reality \cite{azaria2023internal, ji2023, 2023arXiv230511747L, zhang2023sirens}. This issue hinders their use in critical applications like healthcare and legal fields, raising concerns about misinformation, safety, and privacy \cite{ji2023,roit2023factually, umapathi2023medhalt}. LLMs can encode vast amounts of information \cite{knowledge_base_2, knowledge_base_1} but struggle with dynamic, temporal knowledge \cite{li2023unlocking, temporal_aspect}. To address this, efforts are being made to augment LLMs with external knowledge \cite{guu2020realm,ram2023incontext,zhang2022retgen}. This includes two main approaches: 1) retrieve-and-generate models (e.g. RAG\cite{rag}) which combine a knowledge retriever with a generative model, and 2) k-Nearest Neighbor LMs (e.g. RETOMATON\cite{alon2022neurosymbolic}) which use K-NN models to improve token prediction. Additionally, post-hoc attribution and edit methods like RARR\cite{gao2023rarr} and PURR\cite{chen2023purr} retrieve relevant evidence and edit outputs to ensure factual consistency. Existing benchmarks for evaluating factual consistency in LLM-generated texts, such as FactScore \cite{min2023factscore}, HaluEval  \cite{2023arXiv230511747L}, and LLM-augmenter \cite{peng2023check}, focus on fact verification rather than efficient evidence retrieval. 
Our contributions aim to explore efficient retrieval approaches to improve the efficiency of the fact-checking process, enhancing the practical applicability of these systems in real-world scenarios such as live fact-checking over large knowledge bases.



% In this section, we discuss prior work and recent advances.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The notion of fact-checking delves into the logic, coherence, and context of claims \cite{thorne2018automated}. In the fact-checking process, fact verification serves as a crucial preliminary step in acquiring and confirming facts, ensuring the trustworthiness of the information under consideration. The surge in demand for automated fact-checking has prompted rapid advancements in the development of tools and systems for it. Successful of these pipelines rely on efficient handling of large document collections, optimal text span granularity for detailed answers, contextual awareness for appropriate text granularity selection, and versatility across domains \cite{ahmad2019}.  Currently, the typical fact-checking process involves three stages: (i) \textit{claim detection} involves identifying salient text spans from a large collection; (ii) \textit{evidence retrieval} focuses on finding sources that either support or refute the claim; and (iii) \textit{fact verification} entails assessing the veracity of the claim based on the retrieved evidence \cite{guo2022survey}. \\

% For the claim detection part, there is no formal definition of what constitutes a claim \cite{Lazarski2021nlpfact}. Some existing work establishes check-worthiness as a possible concept \cite{guo2022survey}. It determines a claim when one wants to know the truth of that assertion, which either requires binary classification or an importance-ranking to classify. Another method, used in social media settings, is whether text spans are detected for rumourness. Nonetheless, these two methods are quite subjective as the language understanding and importance of the concepts differs between social groups or even individuals \cite{guo2022survey, thorne2018automated}. Furthermore, the information pertaining to the claim can change over time or have been debunked already, no longer necessitating the need for verification. A more objective approach is to classify text as an assertion if it's checkable with available evidence. \\

% Early retrieval systems were typically complex, composed of numerous components \cite{karpukhin2020dense, zhao2022}. However, recent advancements in reading comprehension models advocate for a simplified two-step approach: initially, a context retriever selects a subset of passages, some of which potentially contain the answer to the query, followed by a thorough analysis by a machine reader to identify the correct answer. Nonetheless, a notable challenge arises concerning the sources from which information is pulled \cite{guo2022survey}. The task of fact-checking requires access to reliable and trustworthy knowledge sources that have been thoroughly verified. These sources serve as the foundation for retrieving evidence-based information. These include a diverse array of textual sources such as encyclopedia articles, policy documents, verified news articles, and scientific journals, which offer rich information for verifying claims \cite{Lazarski2021nlpfact, thorne2018automated}. Additionally, knowledge graphs or fact databases provide structured canonical information about the world, though their limitations must be considered, as not all facts may be present in them. Social media and online content analysis offer insights into the veracity of claims, especially when traditional textual or structured knowledge sources are unavailable. \\

% Lastly, for fact verification, either binary classification using supported/refuted labels or Multi-class labels are utilized \cite{guo2022survey, thorne2018automated}. The latter mimicking journalistic fact-checking practices, to include more fine-grained classification schemes or indicate when not enough information could be retrieved. 
% Automated fact-checking primarily relies on supervised text classification methods, often using labelled data from fact-checking agencies \cite{thorne2018automated}. While effective for some tasks, it lacks the broader world knowledge necessary for comprehensive fact-checking. Other approaches include network analysis, Recognizing Textual Entailment, and distant relation extraction. Speaker profiling, such as analyzing the credit history of claim originators, can enhance accuracy but raises ethical concerns. To further improve the verdict interpretations, the justification procedure is important \cite{guo2022survey}. Particularly in automated fact-checking where black-box models lack transparency. Strategies include highlighting salient evidence, designing understandable decision-making processes, and generating textual explanations. 

%