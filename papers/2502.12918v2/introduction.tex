\section{Introduction}
\label{sec:intro}

The SQL queries embedded in enterprise applications are often riddled with inefficiencies and redundancies, especially when machine-generated by modeling software such as ORM tools. Query optimizers are expected to, in principle, automatically remove such wasteful bloat while constructing efficient execution plans. However, in practice, they are often led astray by complex representations, resulting in poor response times. 

\input{ormquery}

As a case in point, consider the blog-processing query
shown in Figure~\ref{fig:BloatedQuery},
which computes a daily summary of rating metrics for highly-rated blogs. When this seemingly complex query is given to the current \pg engine (v16)~\cite{pgsql}, its execution plan essentially mimics the hierarchical structure of the query. This strategy leads to multiple scans and joins of the {\tt Blogs} and {Posts} tables,
making the query take several \emph{minutes} to complete.  However, 
the query can be equivalently rewritten (assuming \texttt{NOT NULL} column constraints)
in the ``lean'' flat version shown in Figure~\ref{fig:LeanQuery} -- this alternative requires only a single join, and runs more than an \emph{order-of-magnitude} faster, completing within seconds!

For such optimizer-failure scenarios, an alternative option to rectify slow-running queries is to carry out \emph{external tuning} -- in particular, DBAs typically resort to SQL-to-SQL {\bf (S2S)} \emph{query rewriting tools} in the hope that they may recommend performant alternatives.
For this context, a viable S2S query transformer should satisfy the following criteria: (1) A wide range of queries should be covered in its scope; (2) The transformed query should be semantically equivalent to the original; (3) The rewrite should ideally improve performance, but at least not cause regression; and (4) The transformation overheads must be practical for deployment.

\subsection*{Prior Work}
A variety of innovative \emph{Rule-based} (e.g.~Learned Rewrite~\cite{Learned_Rewrite}) and \emph{Model-based} (e.g.~Gen-Rewrite~\cite{Genrewrite}) approaches have been proposed in the literature for S2S transformations. Further, a recent vision paper~\cite{DBGPT} has persuasively advocated the use of LLMs for such query rewriting. These novel state-of-the-art (SOTA) techniques have foregrounded the potential benefits of query rewriting. However, as explained later in Section~\ref{sec:Related-Work}, their realization of these benefits is curtailed by: (a) restrictions in rewrite scope, (b) susceptibility to semantic and syntactic errors, and (c) transformations via the plan space rather than directly in query space -- the latter provides greater scope for candidate rewrites since only intent, and not implementation, is expressed.  In this paper, we address these lacuna and amplify the effectiveness of query rewriting.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\linewidth]{Figures/lithe-architecture.png}
    \caption{High-level architecture of \lithe}
    \label{fig:lithe}
    \vspace{-0.1in}
\end{figure}

\subsection*{The \lithe Rewriter}
\label{sec:LITHE REWRITE}

We propose \lithe (LLM Infused Transformations of HEfty queries), an LLM-based query rewriting assistant to aid DBAs in tuning slow-running queries that have entailed their intervention. As illustrated in the architectural diagram of Figure~\ref{fig:lithe}, \lithe takes as input the user query \qu and outputs a transformed query \qt, together with 
(a)~the \emph{expected} performance improvement, in terms of optimizer estimated cost, of \qt; 
(b)~a \textit{verification label} indicating the mechanism (provable or statistical) used to determine that \qt is semantically equivalent to \qu; and
(c) a \textit{reasoning} for why the LLM expects \qt to be helpful wrt performance.
Armed with this information, DBAs can leverage their expertise to decide whether or not to use \qt.

Our design of \lithe is based on a calibrated investigation of the suite of techniques described below:

\myparagraph{Basic Prompts.} 
We begin with a suite of generic prompts that cover a spectrum of detail, ranging from a single summary sentence to detailed instructions running to several paragraphs. Interestingly, we find that more information is not necessarily better wrt rewriting quality, and that the best prompt granularity is query-specific. Moreover, this basic prompt ensemble was found to itself deliver performance similar to the \sota techniques.

\myparagraph{Database-sensitive Prompts.}
%
To help the model adapt to different query patterns and structures, we next introduce rules in the prompts. Our rules are invoked directly in \emph{query space}, providing the LLM with the latitude to generalize the rule usage to a wide range of queries. This is in contrast to the hardwired and narrow rule application mechanisms (e.g. Calcite~\cite{Calcite} rules) typically used in existing rewrite systems,  which operate in \emph{plan space}. 

%
In particular, we work with two classes of rules:

\myparagraphem{\hspace*{0.1in} 1. Redundancy Removal Rules:} These rules are meant to eliminate repeated and redundant computations of the same output.  

\myparagraphem{\hspace*{0.1in} 2. Metadata-infused Rules:}
%
These rules make use of the rich metadata available in database environments, such as the logical schema (table definitions and constraints) and predicate selectivities, and include this information in the LLM prompts. To our knowledge, such metadata inclusion in prompts has not been considered before in the SQL rewrite context. As shown later in our experiments, it proves to be a powerful mechanism for ensuring performant rewrites across database environments.

\myparagraph{Token Probability Driven Rewrites.}
%
The above rewrite options are restricted to the standard prompt interface. Additionally, we leverage the rich telemetry provided by LLMs -- in particular, the  \emph{token probabilities} output at each step in the prediction sequence. Whenever the LLM lacks high confidence in the next token, we follow multiple alternative paths in the decision process. To ensure practical overheads on this enumerative approach, a Monte Carlo tree search (MCTS) technique is incorporated in our implementation. MCTS has previously demonstrated significant effectiveness in code generation exercises~\cite{CodeGen}.

\myparagraph{Semantic Equivalence Labels.}
After generating a rewrite, it is imperative to check for semantic equivalence to the original query. Unfortunately, the general problem of proving query equivalence is NP-complete~\cite{queryequivalence}. However, for restricted classes of queries, various \emph{logic-based} equivalence-proving tools are available, and
in \lithe, we use the recently developed QED tool~\cite{QED} to verify rewrite correctness for queries within its scope.

The remaining out-of-scope queries are checked, albeit not provably, by computing \emph{result equivalences} on a diverse cluster of databases constructed using down-sampled versions of the original database. Finally, result equivalence can be optionally tested on the original database itself. While these checks do not suffer from false negatives, they may (rarely) incur false positives. 

After carrying out the above exercise, \lithe provides a verification label -- \emph{provable} or \emph{statistical} -- regarding semantic equivalence. Ultimately, it is left to the DBA's discretion to determine the validity and utility of the rewrite.


\subsection*{Experimental Evaluation}
Our first set of experiments to evaluate {\lithe}'s performance is carried out on the industry standard TPC-DS benchmark~\cite{tpcds}, hosted on the \pg platform with \gpt used as the LLM. The evaluation focuses on slow queries taking more than a threshold time to complete. We compare the performance of \lithe against \sota techniques (specifically, Learned Rewrite~\cite{Learned_Rewrite}, \llmrsq~\cite{LLMR2}, GenRewrite~\cite{Genrewrite}, as well as a baseline LLM prompt~\cite{Genrewrite}).  The primary metrics are (a) reductions in optimizer-estimated costs, (b) run-time speedups, and (c) rewriting overheads. For LLM-based techniques, the number of tokens used is also monitored since the financial charges for LLM usage are typically dependent on this number. To understand the independent utility of the various components of \lithe, a systematic ablation study is carried out.
\subsubsection*{Generalizability.} In our second stage of experiments, we evaluate generalizability of the above outcomes in a variety of new scenarios, including (a) commercial database engines, (b) unseen database schemas, and (c) alternative LLM platforms. 
% Additional benchmarks are covered Section.

\myparagraph{Results.}
Our experiments demonstrate that \lithe achieves, for many slow queries, semantically correct transformations that significantly reduce the abstract costs.
In particular, for TPC-DS, \lithe constructed ``highly productive'' ($ > 1.5x$ estimated speedup) rewrites for as many as 26 queries, whereas SOTA promised such rewrites for only about half the number. Further, the GM (Geometric Mean) of \lithe's cost reductions reached {\bf 11.5}, almost double the {\bf 6.1} offered by SOTA.

We also evaluated whether the above cost reductions translated to real execution speedups. Here, we find that 
\lithe is indeed often substantively faster at run-time as well.  Specifically, the geometric mean of the runtime speedups for slow queries was as high as \textbf{18.4} over the native optimizer, whereas SOTA delivered \textbf{6} in comparison.  However, we also found that the well-known discrepancies between optimizer cost predictions and actual execution times~\cite{lohmanblog} could be exacerbated by an injudicious choice of rule formulations.
This separation suggests a future line of research to reduce the reasoning distance between language-based foundation models and statistics-based optimizer models.

Overall, \lithe is a promising step toward viable LLM-based advisory tools for ameliorating enterprise application performance.

\subsection*{Contributions}
In summary, our study makes the following contributions: 
\begin{enumerate} %\denselist
\item Assesses LLM suitability for S2S transformation. 
\item Transforms directly in query space instead of plan space intermediates, leading to performant rewrites.
\item Incorporates database-sensitive rules in LLM prompts, covering both schematic and statistical dimensions.
\item Leverages LLM token probabilities to guide navigation of the rewrite search space and minimize LLM errors.
\item Evaluates rewrite quality over a broad range of database environments, demonstrating substantial benefits over both SOTA and the native optimizer.
\item Identifies learnings that could help guide research directions for industrial-strength query rewriting.
\end{enumerate}


