\begin{center}
    {\LARGE \bf Appendix}
\end{center}

\section{Rewrite Quality (Other Benchmarks)}
\label{app:exp}

We also evaluated \lithe on the following set of benchmarks. 
\begin{enumerate}
\item DSB~\cite{DSB}: A TPC-DS variant with complex data distributions and  additional query templates featuring many-to-many joins and non-equi-joins.
\item ARCHER~\cite{ARCHER}: A Text-to-SQL benchmark spanning 10 databases with availability of ground-truth SQL queries.
%the 259 ground-truth SQL queries present in this Text-to-SQL benchmark spanning 10 databases.
\item JOB~\cite{cardest}: An optimizer stress-test benchmark featuring queries with large and complex join graphs.
\item StackOverflow~\cite{Stackoverflow}: A real-world benchmark with query templates modeling questions and answers from experts. A random instance of each template is taken.
\end{enumerate}
Note that the queries in these workloads (with the exception of DSB) are mostly \textit{fast running} (i.e. completing in less than 10 seconds). Therefore, with the primary goal to test the coverage of \lithe over a diverse variety of workloads (and not the deployment angle), we include all the queries in our analysis.
%
The number of \cprs produced and the cost speedup delivered by \lithe and \sota over these benchmarks are shown in Table~\ref{tab:different_benchmark_peformance}.

\begin{table}[h]
\footnotesize
\centering
\caption{Comparing \lithe with {\sota} on different benchmarks.}
\label{tab:different_benchmark_peformance}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Benchmark}}
& \multicolumn{3}{c|}{\textbf{\# \cpr}} 
& \multicolumn{2}{c|}{\textbf{\csgm}} \\
& \textbf{LITHE} & \textbf{SOTA} & \textbf{Union}
& \textbf{LITHE} & \textbf{SOTA} \\ \hline \hline
DSB           & \LitheProdDSB           & \SotaProdDSB           & 9 & \gmLitheProdDSB           & \gmSotaProdDSB           \\ \hline
ARCHER      & \LitheProdArcher        & \SotaProdArcher        & 22 & \gmLitheProdArcher        & \gmSotaProdArcher        \\ \hline
JOB          & \LitheProdJOB           & \SotaProdJOB           & 4 & \gmLitheProdJOB           & \gmSotaProdJOB           \\ \hline
StackOverflow & \LitheProdStackoverflow & \SotaProdStackoverflow & 2 & \gmLitheProdStackoverflow & \gmSotaProdStackoverflow \\ \hline
\end{tabular}
\end{table}

In case of DSB, \lithe produces \cpr for 9 queries resulting in a highly productive \csgm of \textbf{7.7}. Similar to the case with TPC-DS, \lithe performs better than \sota both with respect to its coverage, as well as the cost speedups.

Turning our attention to the other benchmarks (ARCHER, JOB, StackOverflow), the number of \cpr queries is smaller due to the predominance of flat SPJ formulations in these benchmarks, which limits the scope for productive rewriting. 
Nevertheless,  \lithe continues to achieve better \cpr coverage, whereas \sota misses quite a few opportunities. Further, the \csgm of \lithe is visibly better than \sota.


\newpage
\section{Overheads Reduction for \lithe}
\label{app:classifier}

\subsubsection*{Rule Selection Classifier}
Reducing the query rewrite time while still obtaining the same performance would be possible if we could directly use the MCTS-driven rewrite with the appropriate prompt. Towards this end, we build a classifier to pick the most appropriate rewrite rule for a given input query.
%
Specifically, the classifier identifies which, if any, of Rules R1--R6 is appropriate for a given query. If none are appropriate, then it falls back to just the set of basic prompts to identify the best prompt to be given as input to the MCTS module.
%
In addition to reducing the rewrite times, using a classifier can also reduce the financial costs of the rewrite.

We design an LLM based classifier to accomplish this as follows: The LLM is given the rewrite rules discussed so far, and additionally, for each rule, an example demonstrating when the rule can be applied and a counter-example demonstrating when the rule cannot be applied. For the database schema and statistics-based rules, the relevant information is also fed to the classifier so that it can make an informed decision. Then, given an input query, the classifier is tasked with selecting the most appropriate rewrite rule.

\begin{table}[h]
\footnotesize
\centering
\caption{Impact of Classifier (TPC-DS)}
\label{tab:classifier-tpcds}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Metrics} & \textbf{Without Classifier} & \textbf{With Classifier} \\ \hline \hline
\# \cpr & 26 & 23 \\ \hline
\csgm & 11.5 & 8.5 \\ \hline
Avg. Tokens & 18427 & 16003 \\ \hline
Avg. Time & 5~min & 2.4~min \\ \hline
\end{tabular}
\end{table}

Table~\ref{tab:classifier-tpcds} compares the performance of \lithe with and without the classifier. The time overheads do visibly go down by about 52 percent, and the tokens by about 13 percent. However, there is a price to be paid -- the \cpr is reduced to 24 and the \csgm comes down to 8.5. In our future work, we plan to look into whether a better tradeoff could be achieved between quality and overheads.

\subsubsection*{Pruning in MCTS}
%
A bottleneck in the MCTS-based exploration is the need to greedily expand a node (during the simulation stage) until an entire rewrite is output. In principle, if we could quickly check for semantic and syntactic correctness at intermediate stages, then unproductive paths could be terminated early. We are currently working on the design and implementation of such checks.

\newpage
\section{Query Equivalence Testing via Sampling}
\label{app:sampling-eq}

If the original query is not within the scope of the logic-based QED tool, we alternatively use a sampling-based approach to test equivalence. The idea here is to execute the queries on several small samples of the database and verify equivalence based on the sample results. 
%
However, while this test is a necessary condition for query equivalence, it is not a sufficient condition. That is, there are no false negatives, but there can be false positives. This is because the sampled database may not cover all the predicates present in the query. This can cause two types of problems: 
First, it is possible for two different queries to return the same result. This can happen when, for example, the entirety of the sampled data satisfies a predicate of one query, while the same predicate is not present in the other. Second, if the underlying sample does not satisfy any of the predicates in either query, then an empty result will be returned by both queries. This again does not imply that the queries are equivalent.

To statistically address the first problem (false positives), we create multiple samples of the database with different seeds, and run the test on all these samples. The goal is to reduce the likelihood of non-equivalent queries returning the same results. 

To minimize the occurrence of the second problem (empty results), the following approach is taken:
\begin{enumerate} \denselist
\item We use \textit{correlated sampling}~\cite{cs2} to sample the database. This technique leverages the join graph of the schema to produce a sample that maintains join integrity between the tables participating in the query.
\item To differentiate between inner and outer joins, we insert into the sample database, rows with appropriate values on the relevant columns such that they produce NULL values for outer joins.
\item Given a pair of queries to test for equivalence, we adjust the constants in the filter predicates to reduce the chances of an empty result. We make use of the rows in the sampled data for this purpose. For example, say an equality predicate is present in the query and the associated constant is absent in the sampled database. We then replace the query constant with a value already present in the sample. Similarly, the constants for other comparison operators are adjusted based on the ranges of the corresponding columns in the sampled database. 
%
Note that these modifications only change the selectivity of the query, but not its semantics.
\end{enumerate}

\newpage
\section{Detailed MCTS Algorithm}
\label{app:mcts}

{
\begin{algorithm}[!h]
\caption{Token-augmented Rewrite}
\label{alg:mcts_full}
\begin{algorithmic}[1]
\footnotesize
\REQUIRE 
\Statex $root$, \hspace{0.73cm} \# Start State; 
% \Statex $\beta$, \hspace{1.1cm} \# UCB exploration parameter
\Statex $k$, \hspace{1.1cm} \# Maximum number of child expansion
\Statex $\theta$, \hspace{1.1cm} \# Probability threshold for node expansion
\Statex $iter_{max}$, \hspace{0.28cm} \# Maximum number of iterations
\State $Potential$, $visits$, $V$ $\gets$ \textbf{empty Map}

\For{$i \gets 1, 2, \dots, iter_{max}$}
    \State $visits[root]$ $\gets$ $visits[root]$ + 1
    \State $n_{cur}$ $\gets$ $root$
    \State\textcolor{red}{\# Stage~1: Selection}
    \While{$len(n_{cur}.children) > 0$}
        \State $n_{cur}$ $\gets$ $\argmax_{a \in Actions(n_{cur}.children)}$ \textcolor{blue}{UCB}$(n, a)$
        \State $visits[n_{cur}]$ $\gets$ $visits[n_{cur}] + 1$
    \EndWhile
    \State\textcolor{red}{\# Stage~2: Expansion}
    \State $expand \gets$  True
    \While{$expand$}
        \State $tokens_{next}$, $P_{next}$ $\gets$ \textcolor{blue}{Model}($n_{cur},k$)
        \If{$tokens_{next}[0] = $`;'} 
            \State $expand \gets$ False
        \ElsIf{$P_{next} \leq \theta$}
            \For{$token \in tokens_{next}$}
                \State $state \gets n_{cur}.state \cdot token$
                \State $n_{new} \gets$ \textbf{new} $Node$ with \textbf{State} $state$
                \State \textbf{Append} $n_{new}$ to $n_{cur}.children$
            \EndFor
            \State $expand \gets$  False
        \Else
            \State $state \gets n_{cur}.state \cdot tokens_{next}[0]$ \# First Token
            \State $n_{new} \gets$ \textbf{new} $Node$ with \textbf{State} $state$
            \State \textbf{Append} $n_{new}$ to $n_{cur}.children$
            \State $n_{cur} \gets n_{new}$
        \EndIf
    \EndWhile
    \State\textcolor{red}{\# Stage~3: Simulation}
    \State $query \gets$ \textcolor{blue}{GreedyExpand}($n_{cur}$)
    \State\textcolor{red}{\# Compute the potential of  \textit{query} (returns 0 for invalid \textit{query})}
    \State $v \gets$ \textcolor{blue}{ComputePotential}($query$)
    \State $Potential[query] \gets v$
    \State\textcolor{red}{\# Stage~4: Backpropagation}
    \State $n \gets n_{cur}$
    \While{$n \neq$ Null}
        \If{$v > V[n]$}
            \State $V[n] \gets v$
        \EndIf
        \State $n \gets \text{Parent}(n)$
    \EndWhile
\EndFor
\State\textcolor{red}{\# Return valid rewrite with maximum $Potential > 1$}
\If{$\exists q \in Potential \mid Potential[q] > 1$}
    \State \textbf{return} $q$ having maximum value of $Potential[q]$
\Else
    \State \textbf{return} the original query
\EndIf
\end{algorithmic}
\end{algorithm}
}

\newpage

\begin{flushleft}
\section{Examples used in Prompts for Rules 1--6}
\label{app:rules-ex}

\vspace{0.1in}
\noindent \textcolor{blue}{\large \textbf{R1: Use CTEs (Common Table Expressions) to avoid repeated computation.}}

% \vspace{0.2in}
% \myparagraph{\underline{Original Query}}

%         \begin{verbatim}
% SELECT e.employee_id
% FROM   employee_bonus e
% WHERE  e.bonus_amount < 0.05 * (SELECT Min(f.bonus_amount)
%                                 FROM   employee_bonus f
%                                 WHERE  f.employee_id = e.employee_id)
%        AND e.join_year = 2000;

% \end{verbatim}

% %\newpage
% \myparagraph{\underline{Rewritten Query}}

% \begin{verbatim}
% WITH cte
%      AS (SELECT f.employee_id,
%                 Min(f.bonus_amount) AS min_bonus_amount
%          FROM   employee_bonus f
%          GROUP  BY f.employee_id)
% SELECT e.employee_id
% FROM   employee_bonus e,
%        cte
% WHERE  cte.employee_id = e.employee_id
%        AND e.bonus_amount < 0.05 * cte.min_bonus_amount
%        AND e.join_year = 2000;
%         \end{verbatim}

% \newpage

\vspace{0.2in}
\myparagraph{\underline{Original Query}}

        \begin{verbatim}
SELECT emp.employee_name,
       mgr.manager_name
FROM   employees emp,
       managers mgr
WHERE  emp.manager_id = mgr.manager_id
       AND emp.employee_id IN (SELECT manager_id
                               FROM   (SELECT manager_id,
                                              manager_name
                                       FROM   managers
                                       WHERE  job_id = 'IT_PROG'
                                              AND manager_id > 100))
       AND mgr.manager_name IN (SELECT manager_name
                                FROM   (SELECT manager_id,
                                               manager_name
                                        FROM   managers
                                        WHERE  job_id = 'IT_PROG'
                                               AND manager_id > 100)); 
\end{verbatim}

%\newpage
\myparagraph{\underline{Rewritten Query}}

\begin{verbatim}
WITH cte
     AS (SELECT manager_id,
                manager_name
         FROM   managers
         WHERE  job_id = 'IT_PROG'
                AND manager_id > 100)
SELECT emp.employee_name,
       mgr.manager_name
FROM   employees emp,
       managers mgr
WHERE  emp.manager_id = mgr.manager_id
       AND emp.employee_id IN (SELECT manager_id
                               FROM   it_prog_managers)
       AND mgr.manager_name IN (SELECT manager_name
                                FROM   it_prog_managers); 
        \end{verbatim}

\newpage
\noindent \textcolor{blue}{\large \textbf{R2: When multiple subqueries use the same base table, rewrite to scan the base table only once.}}

\vspace{0.2in}
\myparagraph{\underline{Original Query}}
        \begin{verbatim}
SELECT (SELECT Avg(salary)
        FROM   employees
        WHERE  department = 'Sales'
               AND experience_years BETWEEN 1 AND 5
               AND salary BETWEEN 50000 AND 60000) AS Sales_Avg,
       (SELECT Avg(salary)
        FROM   employees
        WHERE  department = 'HR'
               AND experience_years BETWEEN 5 AND 10
               AND salary BETWEEN 80000 AND 90000) AS HR_Avg; \end{verbatim}
\vspace{0.2in}
\myparagraph{\underline{Rewritten Query}}
\begin{verbatim}
SELECT avg(
       CASE
              WHEN department = 'Sales' THEN salary) AS sales_avg,
       avg(
       CASE
              WHEN department = 'HR' THEN salary) AS hr_avg
FROM   employees
WHERE  (
              department = 'Sales'
       AND    experience_years BETWEEN 1 AND    5
       AND    salary BETWEEN 50000 AND    60000)
OR     (
              department = 'HR'
       AND    experience_years BETWEEN 5 AND    10
       AND    salary BETWEEN 80000 AND    90000);
       \end{verbatim}

\newpage
\noindent \textcolor{blue}{\large \textbf{R3: Eliminate overlapping subqueries.}}

\vspace{0.2in}
\myparagraph{\underline{Original Query}}
        \begin{verbatim}
SELECT c.*
FROM   customer c
WHERE  c.address_id IN (SELECT a.address_id
                        FROM   address)
       AND c.address_id IN (SELECT a.address_id
                            FROM   address
                            WHERE  a.pin_code = '560012'); \end{verbatim}
\vspace{0.3in}
\myparagraph{\underline{Rewritten Query}}
\begin{verbatim}
SELECT c.*
FROM   customer c
WHERE  c.address_id IN (SELECT a.address_id
                        FROM   address
                        WHERE  a.pin_code = '560012'); \end{verbatim}

\newpage
\noindent \textcolor{blue}{\large \textbf{R4: Remove unnecessary joins between a primary key and a foreign key.}}

\vspace{0.2in}
\myparagraph{\underline{Schema}}
        \begin{verbatim}
CREATE TABLE products
  (
     p_product_id INTEGER NOT NULL,
     PRIMARY KEY (p_product_id)
  );

CREATE TABLE fact_sales
  (
     f_sales_id   INTEGER NOT NULL,
     f_units_sold INTEGER NOT NULL,
     f_product_id INTEGER NOT NULL,
     PRIMARY KEY (f_sales_id),
     FOREIGN KEY (f_product_id) REFERENCES products(p_product_id)
  ); 
  
  \end{verbatim}

        \item \textbf{\underline{Original Query}}
        \begin{verbatim}
SELECT p_product_id,
       f_units_sold
FROM   fact_sales,
       products
WHERE  f_product_id = p_product_id; \end{verbatim}

\vspace{0.2in}
\myparagraph{\underline{Rewritten Query}}
\begin{verbatim}
SELECT f_product_id,
       f_units_sold
FROM   fact_sales; 

\end{verbatim}
\newpage
\noindent \textcolor{blue}{\large \textbf{R5: Choose EXIST or IN based on subquery selectivity.}}

\vspace{0.2in}
\myparagraph{\underline{Original Query}}
        \begin{verbatim}
Select item.id, item.code, item.price 
from item 
where item.sourceid in (
    Select element.sourceid 
    from element 
    where element.zip > 1100
  ) 
order by item.id;\end{verbatim}

\vspace{0.1in}
\myparagraph{\underline{Statistics}}
    \begin{verbatim}
Selectivity of different predicates is given below : 
( 1 ) source_id > 1100 on table element :: 0.7385
    \end{verbatim}
    
\vspace{0.1in}
\myparagraph{\underline{Rewritten Query}}
\begin{verbatim}
Select item.id, item.code, item.price 
from item 
where exists(select 1 
    from element 
    where item.sourceid = element.sourceid 
      and element.sourceid > 1100
  ) 
order by item.id;
 \end{verbatim}
 
\newpage
\noindent\textcolor{blue}{\large \textbf{R6: Pre-filter tables that are involved in self-joins and have low selectivities on their filter and/or join predicates. Remove any redundant filters from the main query. Do not create explicit join statements.}}

\vspace{0.2in}
\myparagraph{\underline{Original Query}}
\begin{verbatim}
with total_price_cte as (  
    select item.id, colour.colorcode, sum(item.price) total_price  
    from item, color  
    where item.colorcode = colour.colorcode  
    group by item.id, colour.colorcode  
)  
select t_sec.id, t_first.colorcode  
from total_price_cte t_first, total_price_cte t_sec  
where t_sec.id = t_first.id  
    and t_first.colorcode = `R'  
    and t_sec.colorcode = `R'  
    and t_first.total_price > 0  
order by t_sec.id  
limit 100;
\end{verbatim}

\vspace{0.1in}
\myparagraph{\underline{Statistics}}
\begin{verbatim}
Selectivity of different predicates is given below : 
( 1 ) colour.colorcode = `R' :: 0.01
\end{verbatim}

\vspace{0.1in}
\myparagraph{\underline{Rewritten Query}}
\begin{verbatim}
with total_price_cte as (  
    select item.id, colour.colorcode, sum(item.price) total_price  
    from item, color  
    where item.colorcode = colour.colorcode  
    group by item.id, colour.colorcode  
),  
filtered_total_price_cte as (  
    select * from total_price_cte  
    where colorcode = `R'  
)  
select t_sec.id, t_first.colorcode  
from filtered_total_price_cte t_first, filtered_total_price_cte t_sec  
where t_sec.id = t_first.id  
    and t_first.total_price > 0  
order by t_sec.id  
limit 100;
 \end{verbatim}



\end{flushleft}
