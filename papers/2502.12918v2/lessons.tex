\section{The Road Ahead}
\label{sec:ll}

Based on our study, we now present a few observations with implications for the future design and deployment of rewriting tools.

\subsection{Rewrite Space Coverage by LLMs}

Given the decades-long research on database query optimization, we expected the potential for performance improvement via rewriting to be limited. What came as a surprise was the substantial scope for improvement still available, as showcased by the large \csgm and \tsgm values, even on commercial platforms. These results suggest that LLMs explore optimization spaces that are well outside the purview of contemporary database engines. Further, this enhanced space could be augmented, in a two-stage process, with the recent proposals for LLM-based ``plan hints'' that steer the optimizer in fruitful directions within a plan space~\cite{LLMplanhint}.

\subsection{Rewrite Migration to Optimizer}
The above demonstrated the potent exploratory power of LLMs. But from an overheads perspective, such rewrites should ideally be within the optimizer's native search space rather than recommended from outside. Therefore, it would be a useful exercise to try and distill fresh optimization rules from these instances, leveraging the extensibility features of contemporary optimizers~\cite{extoptbook} to facilitate their incorporation in existing systems.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\linewidth]{Figures/q90-sql.png}
    \vspace{-0.1in}
    \caption{Rewritten TPC-DS Q90}
    \label{fig:q90-rewrite}
    \vspace{-0.1in}
\end{figure}

On the flip side, there appears to be an ``impedance mismatch'' against such integration for certain classes of rewrites. 
%
For example, consider the TPC-DS Q90 rewrite in Figure~\ref{fig:q90-rewrite}. 
The original query individually computed  AM (morning) sales and PM (evening) sales, which were then used to compute the AM to PM ratio. The rewrite, however, 
extracted all relevant rows in one shot and computed the ratio using CASE statements -- encoding such transformations as generic rules in the optimizer appears challenging, given the combinatorial ways in which such transformations can occur.

Therefore, a fruitful area of future research could be achieving a middle-ground between the disparate world-views of LLMs and traditional optimizers.
%

\subsection{Revisiting Optimizer Plan Costing}
\label{sec:cost-mismatch}

As highlighted in Section~\ref{sec:exp}, there were instances of substantive differences between the promised speedup and that delivered at run-time. In fact, to the extent that speedups could even turn out to be regressions! This is due to the brittleness of optimizer plan costing in the new spaces explored by the LLM. As a case in point, during our \lithe design process, the prefiltering in Rule R6 (Table~\ref{tab:basic-prompt-exp}) had initially \emph{not} been restricted to self-joins. It resulted in the number of {\cpr}s (on PostgreSQL) being as high as 65, with an astonishing \csgm of 30.6! However, upon execution, most of these rewrites turned out to be regressions, which led to our inclusion of the restriction. But note that we are artificially modulating the rewrite, rather than fixing the plan costing module, which is the principled solution.  In sum, while plan cost modeling has been a long-standing area of research, there is now even more reason given the new rewrite spaces to study this topic further -- for instance, the operator cost model could be extended using calibration techniques similar to those advocated in \cite{wucostmodel}, while the operator cardinality model could be improved with attention-based techniques~\cite{alece}.

\subsection{Agentic LLMs for Query Rewriting}

An effective way to extend \lithe is to use an agentic LLM that actively interacts with the database environment. 
This would allow a ``\lithe agent" to leverage a memory store to log one or more of: (1)~query execution times; (2)~memory usages of slow queries; (3)~prior interactions with users; and (4)~useful/new rewrite rules  learnt over time. Additionally, the agent could be given database engine access so that it can directly request metadata such as query execution plans, database statistics, live query analyzers, etc. 
%
By following a structured workflow -- planning, acting, observing, and refining -- the agent would then iteratively enhance query performance. This adaptive workflow supports continuous learning, so that query rewriting can become more efficient over time.

\subsection{Scope of Semantic Equivalence Tools}
As seen in the experiments section, the coverage of logic-based query equivalence testing on industrial-strength queries is rather limited.
On the other hand, while it is highly likely that the statistics-verified rewrites are valid, it still requires the DBA to make a final call on the correctness. 
%
This limitation restricts the use of \lithe in a fully automated scenario, i.e., as a direct preprocessor to the query engine. Therefore, a key challenge is to improve logic-based coverage. 
