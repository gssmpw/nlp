\section{Token Probability Driven Rewrite}
\label{sec:mtcs-rewrite}

A key challenge when using LLMs is ``hallucinations'' -- the generation of responses that range from being mildly incorrect to completely made up. This is often due to the output tokens having low confidence, which in turn results in ``confusing" the LLM and generating suboptimal outputs.
%
In order to have a robust approach for such cases, 
%
we take inspiration from the code generation literature~\cite{CodeGen}.
Specifically, we propose a 
\textit{Monte Carlo Tree Search}~(MCTS) based decoding approach to search for a sequence of LLM-generated tokens that results in both a valid query rewrite as well as performance improvements.

This approach models the problem of query rewriting as a decision tree denoting a \textit{Markov Decision Process (MDP)}~\cite{mdp}. The root node of the tree corresponds to the initial prompt. 
An edge from a parent node to a child represents a possible token generated by the LLM and is associated with a value denoting the probability of generating this token given the path taken thus far.
Here, each edge can be considered as an \textit{action} of the MDP. A node is considered \textit{terminal} if the incoming edge corresponds to the “;” token, signalling end of the textual query.

The \textit{state} of a node $n$ 
is represented by the partial rewrite created by following the path from the root to $n$ -- it is obtained by concatenating the tokens on this path. The root's state is an empty rewrite, and each terminal node's state is a complete rewritten query. 
%

Given the hundreds of thousands of tokens in LLM vocabularies, it may be very expensive (both financially and computationally) to construct the entire tree. It is therefore essential to significantly reduce the token search space while exploring the tree for valid rewrites.
%
This is precisely the purpose of MCTS which applies an \textit{Upper Confidence Bound}~(UCB) heuristic~\cite{ucb} to identify the best paths in a tree without computing the entire tree.
%

\input{mcts-small-code}

\subsection{MCTS Search Process}
The pseudocode of the search procedure is shown in Algorithm~\ref{alg:mcts}. It consists of four stages -- Selection, Expansion, Simulation and Back Propagation -- that are repeated across $iter_{max}$ iterations:


\myparagraph{1.~Selection:} 
%
The first stage is responsible for identifying the most suitable node of the decision tree that is yet to be expanded (i.e., the tokens corresponding to this node have not yet been processed by the search procedure).
%
Starting from the root, this process greedily selects successive edges (actions) till an unprocessed non-terminal node is reached (Lines~6--8 in Algorithm~\ref{alg:mcts}). Actions are picked using a UCB that balances exploration and exploitation. The goal is to pick those actions that have either (1)~a higher potential to produce correct and faster rewrites~(exploitation); or (2)~been selected fewer times in the past~(exploration). 
%

Specifically, given a node $n$ and a set of possible actions $a \in A$, the next node in this traversal is chosen as:
\begin{equation}
n_{\text{next}} = \argmax_{a \in A} UCB(n, a)    
\end{equation}
where $UCB$ is a heuristic sourced from \cite{ucb}, modified to reflect our formulation where values are associated with nodes rather than edges in the tree. It is defined as follows:
\begin{equation}
UCB(n, a) = V(n') + \beta(n) * P_{LLM}(a|n.state) * \frac{\sqrt{log(visits[n])}}{1 + visits[n']}
\end{equation}
Here, $n'$ is the node reached from $n$ by taking action $a$, and the first component $V(n')$ represents the exploitation potential of $n'$ to produce correct and faster queries (this notion is formalized below in Stage~3).
%
The second component in the equation represents exploration -- it is higher for those child nodes of $n$ that are visited less often. Here, $P_{LLM}$ represents the next token probability, and $visits[n]$ is the number of times $n$ has been visited during the search process.
%
\(\beta\) is a function that controls the balance between exploration and exploitation. It depends on two hyperparameters $c_{base}$ and $c$ -- a higher value of $c_{base}$ makes the algorithm favor exploitation
, whereas a higher value of c increases the incentive to explore. \(\beta\) is defined as:
\begin{equation}
\beta(n) =  log(\frac{visits[n] + c_{base} + 1}{c_{base}}) + c
\end{equation}

\myparagraph{2.~Expansion:} 
The second stage is used to expand the unprocessed node $n_{cur}$ chosen by the Selection stage. Specifically, it retrieves from the LLM the top $k$ probable next tokens from $n_{cur}$'s state (Line~12), and expands the decision tree by adding $k$ new child nodes corresponding to these tokens.
%
To make the expansion tractable, multiple child nodes are added only if the probability of the highest token falls below a threshold $\theta$ (Line~13). In other words, when the highest token probability is below $\theta$, it means that the LLM itself is unsure of what the next token should be and therefore it is worth exploring additional options. 
%
On the other hand, if the highest token probability is greater than $\theta$, then the tokens are generated in a greedy fashion from the current node until a point where the LLM is again unsure of the next token, or it reaches a terminal node (i.e., completes a query rewrite).

\myparagraph{3.~Simulation:} Here, we determine the potential value, $V(n_{cur})$, to be assigned to 
$n_{cur}$. This node is expanded in a greedy fashion, based on the highest-probability tokens until a terminal node is reached (Line~21). Then, the complete rewritten query represented by the terminal node's state is used to compute the potential (Lines~22--23). For a valid rewrite, $V(n_{cur})$ is equal to the \textit{speedup} it provides with respect to the original query. However, if invalid (i.e. syntactically or semantically incorrect), $V(n_{cur})$ is assigned a zero value. 
%

After every simulation, the complete rewritten query obtained after the greedy expansion of $n_{cur}$ is cached along with $V(n_{cur})$ in a map, $Potential$. 

\myparagraph{4.~Back Propagation:} The $V$ value of the simulation for $n_{cur}$ is backpropagated to all its ancestor nodes. An ancestor node's $V$ value is updated if and only if the new value is higher than the existing value.

\myparagraph{Rewritten Query.}
%
At the end of all iterations, $q \in Potential$ with highest value $Potential[q]$ that is greater than 1 is returned as the rewritten query (Lines~29--30).
In case no such rewrite exists, implying that all the valid rewrites are slower than the original query, the original query itself is returned (Line~32).

\subsection{Input Prompt to MCTS}
%
The root state in Algorithm~\ref{alg:mcts} corresponds to the state just after the prompt is fed to the LLM. 
One way to use this algorithm is to execute it for all the various prompts discussed in the previous sections, and choose the rewrite that provides the best performance. 
This, however, is expensive both from the aspect of query rewrite time, as well as the number of LLM tokens used.
%
To minimize these costs, given a user query, the \lithe workflow first selects the prompt yielding the most effective rewrite from among the techniques of Sections~\ref{sec:basic-prompt} and \ref{sec:dbms-proficient-prompts}. It then employs this prompt to initiate the MCTS-based rewrite.
%
In case no prompt provides a lower-cost rewrite, baseline Prompt~1 of Section~\ref{sec:basic-prompt} is used as the fallback option.

\subsection{Performance}
We find that \lithe's performance with MCTS-based rewrites fully matches the human target, providing  \textbf{10} \cprs and the maximum \csgm of \textbf{11.84}. While these improvements, as compared to just prompting, might seem marginal at this stage, we wish to make two observations: (1)~MCTS helps extract the maximum improvement wherever possible; and (2)~As shown later in Section~\ref{sec:llama}, improvements due to MCTS become significant for smaller LLMs such as \llama.
%


