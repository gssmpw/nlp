

% \begin{table*}[!th]
%     \centering
%     \resizebox{0.9\textwidth}{!}{
%     \begin{tabular}{|l|r|r|r|l|r|r|r|} 
%        \cline{1-4} \cline{6-8}
%         & \multicolumn{3}{c|}{Retrieve} & &\multicolumn{3}{c|}{Retrieve + Rerank} \\ 
%                \cline{2-4} \cline{6-8}
%                &  \multicolumn{3}{c|}{Hits@10}   & & \multicolumn{2}{c|}{Hits@10}  & Speedup \\
% Dataset  &  Baseline  &  DE-2 Rand  & DE-2 CE  & & DE-2 CE &  Baseline &  \\
%        \cline{1-4} \cline{6-8}
% all nli \cite{bowman-etal-2015-large},\cite{N18-1101}  & 0.77 & 0.59 & 0.75 &  &\textbf{ 0.84} & 0.83 & 4.5x\\
% eli5 \cite{fan-etal-2019-eli5} & 0.43 & 0.12 & 0.29 &  & 0.43 & 0.49 & 5.4x \\
% gooaq \cite{Khashabi2021GooAQOQ} & 0.75 & 0.42 & 0.64 &  & 0.77 & 0.80 & 5.8x\\
% msmarco \cite{nguyen2016ms} & 0.95 & 0.81 & 0.89 &  & 0.96 & 0.98 & 5.1x \\
% \href{https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs}{quora duplicates}  & 0.68 & 0.48 & 0.65 &  &\textbf{ 0.68} & 0.68 & 5.1x\\
% natural ques. \cite{47761} & 0.77 & 0.37 & 0.61 &  & 0.61 & 0.64 & 5.4x \\
% sentence comp \cite{filippova-altun-2013-overcoming} & 0.95 & 0.83 & 0.93 &  & \textbf{0.97 }& 0.97 & 6.6x\\
% simplewiki \cite{coster-kauchak-2011-simple} & 0.97 & 0.93 & 0.97 &  &\textbf{ 0.97 }& 0.96 & 4.8x\\
% stsb \cite{cer-etal-2017-semeval} & 0.97 & 0.87 & 0.97 &  & \textbf{0.98} & 0.98 & 4.7x \\
% zeshel \cite{logeswaran2019zero}  & 0.22 & 0.16 & 0.20 &  & \textbf{0.21} & 0.19 & 4.8x\\
%        \cline{1-4} \cline{6-8}
%     \end{tabular}
%     }

% Please add the following required packages to your document preamble:
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}
\begin{table*}[!th]
\centering
     \resizebox{1\textwidth}{!}{ \begin{tabular}{|l|llllll|l|lllll|}
\cline{1-7} \cline{9-13}
\textbf{}                  & \multicolumn{6}{c|}{\textbf{Retrieve}}                                                                                                                                                                                         & \textbf{} & \multicolumn{5}{c|}{\textbf{Retrieve + Rerank}}                                                                                                                                    \\ 
\cline{2-7} \cline{9-13}
{\textbf{dataset}}           & \multicolumn{3}{c|}{\textbf{Hits@10}}                                                                                   & \multicolumn{3}{c|}{\textbf{MRR@10}}                                                                & \textbf{} & \multicolumn{2}{c|}{\textbf{Hits@10}}                                         & \multicolumn{2}{c|}{\textbf{MRR@10}}                                           & \textbf{Speedup} \\ 

                           
\cline{2-7} \cline{9-13} 
                           & \multicolumn{1}{l|}{\textbf{Baseline}} & \multicolumn{1}{l|}{\textbf{DE-2-Rand}} & \multicolumn{1}{l|}{\textbf{DE-2-CE}} & \multicolumn{1}{l|}{\textbf{Baseline}} & \multicolumn{1}{l|}{\textbf{DE-2-Rand}} & \textbf{DE-2-CE} & \textbf{} & \multicolumn{1}{l|}{\textbf{Baseline}} & \multicolumn{1}{l|}{\textbf{DE-2-CE}} & \multicolumn{1}{l|}{\textbf{Baseline}} & \multicolumn{1}{l|}{\textbf{DE-2-CE}} & \textbf{}        \\ 
                       \cline{1-7} \cline{9-13}
                       
msmarco/dev/small  & \multicolumn{1}{l|}{0.59}              & \multicolumn{1}{l|}{0.37}               & \multicolumn{1}{l|}{0.45}             & \multicolumn{1}{l|}{0.32}              & \multicolumn{1}{l|}{0.19}               & 0.24             &           & \multicolumn{1}{l|}{0.66}              & \multicolumn{1}{l|}{0.59}             & \multicolumn{1}{l|}{0.38}              & \multicolumn{1}{l|}{0.35}             & 5.1x             \\ \cline{1-7} \cline{9-13}
beir/quora/dev             & \multicolumn{1}{l|}{0.95}              & \multicolumn{1}{l|}{0.90}               & \multicolumn{1}{l|}{0.93}             & \multicolumn{1}{l|}{0.85}              & \multicolumn{1}{l|}{0.76}               & 0.81             &           & \multicolumn{1}{l|}{\textbf{0.96}}     & \multicolumn{1}{l|}{\textbf{0.96}}    & \multicolumn{1}{l|}{\textbf{0.74}}     & \multicolumn{1}{l|}{\textbf{0.74}}    & 5.3x             \\ \cline{1-7} \cline{9-13}
beir/scifact/test          & \multicolumn{1}{l|}{0.63}              & \multicolumn{1}{l|}{0.53}               & \multicolumn{1}{l|}{0.55}             & \multicolumn{1}{l|}{0.42}              & \multicolumn{1}{l|}{0.30}               & 0.36             &           & \multicolumn{1}{l|}{0.72}              & \multicolumn{1}{l|}{0.69}             & \multicolumn{1}{l|}{0.57}              & \multicolumn{1}{l|}{0.55}             & 4.7x             \\ \cline{1-7} \cline{9-13}
beir/fiqa/dev              & \multicolumn{1}{l|}{0.50}              & \multicolumn{1}{l|}{0.22}               & \multicolumn{1}{l|}{0.32}             & \multicolumn{1}{l|}{0.32}              & \multicolumn{1}{l|}{0.12}               & 0.18             &           & \multicolumn{1}{l|}{0.59}              & \multicolumn{1}{l|}{0.46}             & \multicolumn{1}{l|}{0.28}              & \multicolumn{1}{l|}{0.23}             & 5.3x             \\ \cline{1-7} \cline{9-13}
zeshel/test                & \multicolumn{1}{l|}{0.22}              & \multicolumn{1}{l|}{0.16}               & \multicolumn{1}{l|}{0.20}             & \multicolumn{1}{l|}{0.12}              & \multicolumn{1}{l|}{0.09}               & 0.11             &           & \multicolumn{1}{l|}{\textbf{0.20}}     & \multicolumn{1}{l|}{\textbf{0.19}}    & \multicolumn{1}{l|}{\textbf{0.11}}     & \multicolumn{1}{l|}{\textbf{0.10}}    & 4.8x             \\ \cline{1-7} \cline{9-13}
stsb/train                 & \multicolumn{1}{l|}{0.97}              & \multicolumn{1}{l|}{0.95}               & \multicolumn{1}{l|}{0.97}             & \multicolumn{1}{l|}{0.85}              & \multicolumn{1}{l|}{0.83}               & 0.85             &           & \multicolumn{1}{l|}{\textbf{0.98}}     & \multicolumn{1}{l|}{\textbf{0.98}}    & \multicolumn{1}{l|}{\textbf{0.88}}     & \multicolumn{1}{l|}{\textbf{0.88}}    & 4.7x             \\ \cline{1-7} \cline{9-13}
all-nli/train              & \multicolumn{1}{l|}{0.49}              & \multicolumn{1}{l|}{0.41}               & \multicolumn{1}{l|}{0.47}             & \multicolumn{1}{l|}{0.39}              & \multicolumn{1}{l|}{0.33}               & 0.36             &           & \multicolumn{1}{l|}{\textbf{0.55}}     & \multicolumn{1}{l|}{\textbf{0.54}}    & \multicolumn{1}{l|}{\textbf{0.47}}     & \multicolumn{1}{l|}{\textbf{0.46}}    & 4.5x             \\ \cline{1-7} \cline{9-13}
simplewiki/train           & \multicolumn{1}{l|}{0.97}              & \multicolumn{1}{l|}{0.98}               & \multicolumn{1}{l|}{0.98}             & \multicolumn{1}{l|}{0.92}              & \multicolumn{1}{l|}{0.93}               & 0.94             &           & \multicolumn{1}{l|}{\textbf{0.96}}     & \multicolumn{1}{l|}{\textbf{0.97}}    & \multicolumn{1}{l|}{\textbf{0.91}}     & \multicolumn{1}{l|}{\textbf{0.91}}    & 4.8x             \\ \cline{1-7} \cline{9-13}
natural-questions/train    & \multicolumn{1}{l|}{0.77}              & \multicolumn{1}{l|}{0.59}               & \multicolumn{1}{l|}{0.65}             & \multicolumn{1}{l|}{0.51}              & \multicolumn{1}{l|}{0.37}               & 0.42             &           & \multicolumn{1}{l|}{0.65}              & \multicolumn{1}{l|}{0.61}             & \multicolumn{1}{l|}{0.39}              & \multicolumn{1}{l|}{0.37}             & 5.4x             \\ \cline{1-7} \cline{9-13}
eli5/train                 & \multicolumn{1}{l|}{0.32}              & \multicolumn{1}{l|}{0.14}               & \multicolumn{1}{l|}{0.22}             & \multicolumn{1}{l|}{0.19}              & \multicolumn{1}{l|}{0.08}               & 0.12             &           & \multicolumn{1}{l|}{0.39}              & \multicolumn{1}{l|}{0.32}             & \multicolumn{1}{l|}{0.26}              & \multicolumn{1}{l|}{0.22}             & 5.4x             \\ \cline{1-7} \cline{9-13}
sentence compression/train & \multicolumn{1}{l|}{0.93}              & \multicolumn{1}{l|}{0.89}               & \multicolumn{1}{l|}{0.93}             & \multicolumn{1}{l|}{0.85}              & \multicolumn{1}{l|}{0.79}               & 0.84             &           & \multicolumn{1}{l|}{\textbf{0.96}}     & \multicolumn{1}{l|}{\textbf{0.96}}    & \multicolumn{1}{l|}{\textbf{0.93}}     & \multicolumn{1}{l|}{\textbf{0.94}}    & 6.6x             \\ \cline{1-7} \cline{9-13}
gooaq/train                & \multicolumn{1}{l|}{0.73}              & \multicolumn{1}{l|}{0.68}               & \multicolumn{1}{l|}{0.72}             & \multicolumn{1}{l|}{0.58}              & \multicolumn{1}{l|}{0.55}               & 0.58             &           & \multicolumn{1}{l|}{0.80}              & \multicolumn{1}{l|}{0.76}             & \multicolumn{1}{l|}{0.64}              & \multicolumn{1}{l|}{0.62}             & 5.2x             \\ \cline{1-7} \cline{9-13}
\end{tabular}
}
    \caption{Comparison of CE infused DE. \textbf{Baseline} is the pre-trained DE SBERT model.  \textbf{DE-2 Rand} is a trained two-layered DE initialized with random initial weights. \textbf{DE-2 CE} is a two-layered DE infused with initial weights from CE as explained in Fig~\ref{fig:dual_cross} and trained similar to DE-2. All the above models are trained on msmarco. Bold face numbers for DE-2 CE show where performance is at least within .01 of the baseline DE. \textbf{Speedup} is inference time gain for DE-2 CE over Baseline.}
    % \textbf{Retrieve + Rerank}: Columns 5-6 present Accuracy@10 and columns 7-8 present number of documents encoded per sec. Here, the documents retrieved using baseline and our approach are reranked using a CE.}
    \label{tab:comp}
\end{table*} 