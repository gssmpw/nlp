\documentclass[11pt]{article}
\include{macros.sty}

\usepackage[citestyle=alphabetic,bibstyle=alphabetic,minalphanames=5,maxalphanames=6, maxbibnames=99,url=false]{biblatex}
\addbibresource{ref.bib}


\newcommand{\fqn}{\mathbb{F}_q^n}

\newcommand{\qen}{q^{\frac{\varepsilon n}{1+\varepsilon}}}

\title{Let's Have Both! \\Optimal List-Recoverability via Alphabet Permutation Codes}

\ifauthors{
\author[1]{Sergey Komech}
\author[1]{Jonathan Mosheiff}
\affil[1]{Department of Computer Science, Ben-Gurion University}
\date{\small{\it{To the memory of Professor Boris Markovich Gurevich, with infinite gratitude and respect}}}
}
\else{
\author{Anoynmous Submission}
\date{}
}
\fi



\begin{document}
	
	\maketitle
	
	\ifauthors	\blfootnote{JM is supported by Israel Science Foundation grant 3450/24 and an Alon Fellowship. SK is supported by European Research Council Grant No. 949707.}
	\fi
	
	\thispagestyle{empty}	
	\begin{abstract}
        We construct a new family of codes that requires only polynomial randomness yet achieves \((\rho,\ell,L)\)-list-recoverability at a rate within \(\eps\) of capacity, with \(L \approx \tfrac{\ell}{\eps}\). In contrast, every previous construction using polynomial randomness required an exponentially larger list size. Our approach extends earlier work by Li and Wootters (2021) on the list-decodability of random linear binary codes.
	\end{abstract}




	
    \clearpage
	\setcounter{page}{1}


\section{Introduction}

\deffont{List-recoverability} is a central, widely studied notion in the theory of error-correcting codes. Let $\Sigma$ be a finite \deffont{alphabet} of size at least two, and let $C \subseteq \Sigma^n$ be a code for some $n \in \N$. We say that $C$ is \deffont{$\LR{\rho}{\ell}{L}$} if it contains no \deffont{$\Cl{\rho}{\ell}$} subset of size $L+1$. Here, a set $D \subseteq \Sigma^n$ is \deffont{$\Cl{\rho}{\ell}$} if there exist sets $Z_1, \dots, Z_n \subseteq \Sigma$, each of size at most $\ell$, such that every $x \in D$ differs from $(Z_1,\dots,Z_n)$ in at most $\rho n$ positions—formally,
\[
\bigl|\{\,i \in [n] : x_i \notin Z_i \}\bigr|
\;\le\;
\rho n
\quad
\forall\,x \in D.
\]


\sloppy
This definition subsumes several well-known notions. In particular, a code that is $\LR{0}{\ell}{L}$ is, equivalently, \deffont{$(\ell,L)$-list-recoverable without errors}. A code that is $\LR{\rho}{1}{L}$ is said to be \deffont{\LD \rho L}, and $\LRe{\rho}{1}{1}$ coincides with the classical notion of \deffont{unique-decodability up to radius~$\rho$}. 


Recall that the \deffont{rate} of a code $C \subseteq \Sigma^n$ is 
$R := \frac{\log_q \inabs{C}}{n}$, where
$q := \inabs{\Sigma}$. It is well known (see, e.g., \cite[Thm.\ 2.4.12]{Resch2020}) that the \deffont{capacity} for list-recoverability is 
$1 - h^*_{q,\ell}\inparen{\rho}$, where
$$
h^*_{q,\ell}\inparen{\rho}
:= \begin{cases}
\rho\,\log_q\!\inparen{\frac{q-\ell}{\rho}}
\;+\;
\bigl(1-\rho\bigr)\,\log_q\!\inparen{\frac{\ell}{1-\rho}}&\text{if }\rho \le 1-\frac \ell q \\
1 &\text{if }\rho > 1-\frac \ell q\eperiod
\end{cases}
$$
Concretely, for any $q \ge 2$, $\ell \in \N$, $0 \le \rho \le 1-\frac\ell q$, and $\eps > 0$, there exist \deffont{$q$-ary codes} (i.e., codes whose \deffont{alphabet} has cardinality $q$) of rate at least $1 - h_{q,\ell}\inparen{\rho} - \eps$ that are $\LR{\rho}{\ell}{O\!\inparen{\tfrac{\ell}{\eps}}}$. In particular, a \deffont{plain random code (PRC)} of alphabet $\Sigma$, length $n$, and rate $R$ is formed by uniformly choosing a subset $C \subseteq \Sigma^n$ of size $\inabs{\Sigma}^{R n}$. Such a code is $\LR{\rho}{\ell}{O\!\inparen{\tfrac{\ell}{\varepsilon}}}$ with high probability as $n \to \infty$. Conversely, any $q$-ary code whose rate exceeds $(\,1 - h_{q,\ell}\inparen{\rho}\,) + \varepsilon$ cannot be even $\LR{\rho}{\ell}{q^{o(n)}}$.

A substantial line of influential works~\cite{GR2008,GW2013,KRS+2018,LP2020,GLS+2021,GST2023,Tam24} has examined list-recoverability with the aim of constructing explicit codes that approach optimal parameters. Specifically, an important goal is to build codes of rate 
$R = 1 - h_q\inparen{\rho,\ell} - \eps$
that are 
$\LR{\rho}{\ell}{L}$
for small $L$ and $\eps$, ideally matching 
$L = O\!\inparen{\tfrac{\ell}{\eps}}$ 
(which \deffont{plain random codes} achieve with high probability). We refer to this target as the \deffont{Elias Bound for List Recovery}.\footnote{Named by analogy with Elias’s classical list-decodability result for plain random codes~\cite{Elias1957}. See also~\cite{MRSY24}.} The best known explicit constructions currently fall \emph{exponentially} short of this ideal when $\ell \ge 2$ ((as opposed to $\ell=1$, i.e.\ list-decodability), achieving 
$L = \inparenf\ell\eps^{O\inparen{\tfrac{1+\log \ell}{\eps}}}$ 
via \deffont{Folded Reed--Solomon Codes}~\cite{Tam24}.

Progress toward explicitly meeting the Elias Bound for list-recovery when $\ell \ge 2$ has recently experienced two significant obstacles. First, \cite{CZ24} showed that when the alphabet is not too small (namely, $q \ge 2^{\Omega\inparen{\tfrac{1}{\eps}}}$), any Folded or Plain Reed--Solomon code must satisfy 
$L \,\ge\, \ell^{\Omega\inparen{\tfrac{1}{\eps}}}.$
Subsequently, \cite{LMS2024} proved the same lower bound for \deffont{Random Linear Codes (RLCs)} and conjectured that it holds for every \deffont{linear code}. Ongoing work by the second author suggests that this negative result may extend even further, to all \deffont{additive codes} over a field $\F_q$ (i.e., codes that are closed to addition, or, equivalently, are linear over some subfield of~$\F_q$). 

Motivated by this gap, we construct codes that satisfy both of the following criteria:
\begin{enumerate}
  \item They require only a polynomial amount of randomness.
  \item They achieve the list size prescribed by the Elias Bound for list-recovery.
\end{enumerate}
Until now, every known construction fell exponentially short of at least one of these two conditions. Our main theorem is as follows.

\begin{theorem}[Main Theorem]\label{thm:introMainLR}
Let $q,\ell,L,n \in \N$ be integers with $q \ge 2$ and $\ell < \min\{q,L\}$. Suppose $0 \le \rho \le 1 - \tfrac{\ell}{q}$, and let 
$
\eta \;\ge\; \frac{2\,\log_q\!\bigl(2n/\ln2\bigr)}{n}
$ and $\delta > 0$. Write
\[ R :=
1
\;-\;
h_{q,\ell}\!\inparen{\rho}
\;-\;
\frac{\log_q \binom q\ell}{L+1}
\;-\;
\eta
\ecomma
\]
and suppose that $k := {R\cdot \log_2 q\cdot n}$ is an integer.

Then there exists a random code ensemble $\cC \subseteq \Sigma^n$ (where $\Sigma = \inset{1,\dots,q}$) of rate $R$, which requires only $O\!\inparen{nk\inparen{\ell\log q + \log \tfrac 1\delta}}$ random bits, and satisfies
\[
\PR{\cC \text{ is } \LR{\rho}{\ell}{L}}
\;\ge\;
1 \;-\;
\inparen{\sqrt 2\cdot k \cdot q^{-\tfrac{\eta n}{2}}}
\;-\;
\inparen{c\cdot \delta \cdot n\cdot k\cdot q^{4\ell}}
\ecomma
\]
for some universal constant $c > 0$.
\end{theorem}

Observe that \cref{thm:introMainLR} indeed yields codes satisfying the Elias Bound for list-recovery whenever $\frac \ell L \ge \omega\inparenf{\log_q (nk)}n$. As a concrete example, setting $\eta = \frac{2\log_q\inparen{nk}}{n}$ and $\delta =\frac {1}{c\cdot n^2\cdot k\cdot q^{4\ell}}$ uses $O\inparen{n^2\log q\inparen{\ell\log q  + \log n}}$ random bits to produce $\LR \rho \ell L$ codes of rate
$$
1 - h_{q,\ell}(\rho) -\frac{\log_q \binom q\ell}{L+1}
 - \eta - \frac 1 n \ge 1 - h_{q,\ell}(\rho) - \frac{\ell}{L+1} - \eta - \frac 1n \ge 1 - h_{q,\ell}(\rho) - \frac{\ell}{L+1}\inparen{1+o(1)}
$$
with probability $1-O\inparenf 1n$.

\subsection{Alphabet-Permutation Codes}
We now describe the codes that achieve \cref{thm:introMainLR}, which we term \deffont{Alphabet-Permutation (AP) Codes}. In light of the aforementioned negative conjectures, it is unsurprising that AP codes are generally neither \deffont{linear} nor even \deffont{additive}.

Fix $q,k,n \in \N$ with $k \le n \,\log_2 q$ and $q \ge 2$. Let $\Sigma := \inset{0,\dots,q-1}$, and let $\cS := \cS_{\Sigma}$ be the set of all permutations of $\Sigma$. We then choose a matrix $\Pi \in \cS^{k \times n}$ and define an encoding function 
\[
\enc_\Pi \colon \F_2^k \;\to\; \Sigma^n.
\]
Given $x \in \F_2^k$, let $t$ be the Hamming weight of $x$, and let $\Pi^x \in \cS^{t \times n}$ denote the submatrix of $\Pi$ consisting of rows where $x$ has 1s. For each $j \in [n]$, define 
\[
\pi_j^x \;:=\; \bigcirc_{r=1}^{t} \,\Pi^x_{r,j}\ecomma
\]
where $\bigcirc$ denotes composition. We then set $\enc_\Pi(x) = y$, where $y_j := \pi_j^x(0)$ for $1 \le j \le n$. In other words, each coordinate $y_j$ arises from applying the permutation $\pi_j^x$ (composed from the $j$-th column of~$\Pi^x$) to $0$. 

Finally, we define the \deffont{AP code} $\cC_\Pi$ as the image of $\enc_\Pi$. Since $\enc_\Pi$ may not be injective, we treat $\cC_\Pi$ as a multiset, thereby obtaining a code of rate
\[
R \;=\; \frac{k}{n \,\log_2 q}\eperiod
\]

To prove \cref{thm:introMainLR}, we show that for certain random ensembles of $\Pi$, the code $\cC_\Pi$ is $\LR{\rho}{\ell}{L}$ with high probability. Before describing these ensembles, we define \deffont{$m$-wise (almost) independent} families of permutations.

\begin{remark}
    As mentioned above, the encoding function $\enc_\Pi$ is not necessarily injective. A standard birthday argument shows that for sufficiently random $\Pi$ (as in our construction), a small number of collisions is likely whenever $R \ge \tfrac12$. In this sense, our codes are excellent for list-recovery but not well suited for unique-decoding.
\end{remark}

\subsection{$m$-wise (almost) independent permutation families}

\begin{definition}[Total Variation Distance]
  Let $D$ and $D'$ be probability distributions over the same finite set $\Omega$. Their \deffont{total variation distance} is
  $$
  \norm{D - D'}
  \;=\;
  \frac12 \,\sum_{\omega \in \Omega} \inabs{D(\omega) - D'(\omega)}\eperiod
  $$
  We say that $D$ and $D'$ are \deffont{$\delta$-close} if $\norm{D - D'} \le \delta$.
\end{definition}

\begin{definition}[$m$-wise (almost) independence of permutations]
  Let $\Sigma$ be a set with $\inabs{\Sigma} = q$, and let $1 \le m \le q$. Denote by $\Sigma_m$ the set of all $m$-tuples of distinct elements in $\Sigma$. Fix $\delta \ge 0$ and let $D$ be a distribution over $S_\Sigma$. 
  We say that $D$ is \deffont{$m$-wise $\delta$-dependent} if, for every $(x_1,\dots,x_m) \in \Sigma_m$, when $\pi$ is randomly drawn from $D$, the induced distribution of $(\pi(x_1),\dots,\pi(x_m))$ is $\delta$-close to the uniform distribution on $\Sigma_m$. If $\delta = 0$, then $D$ is called \deffont{$m$-wise independent}.

  A family of permutations $T\subseteq \cS_\Sigma$ is $m$-wise $\delta$-dependent (resp. $m$-wise independent) if the uniform distribution over $T$ is $m$-wise $\delta$-dependent (resp. $m$-wise independent).
\end{definition}

We will use two important theorems about $m$-wise independence. The first states that small $m$-wise $\delta$-dependent permutation families exist, while the second theorem provides a reduction from full independence to $\delta$-dependence for small enough $\delta$.

\begin{theorem}[{Existence of small $m$-wise $\delta$-dependent families \cite[Thm.\ 5.9]{KNR2009}}]\label{thm:KNR}
    Fix a nonempty finite set $\Sigma$ with $q := |\Sigma|$, let $1\le m\le q$ and $\delta > 0$. Then, there exists a $m$-wise $\delta$-dependent permutation family $T\subseteq \cS_\Sigma$ with $$\log_2|T| \le O\inparen{m\log q + \log \inparen{\frac 1 \delta}}\eperiod$$
    Furthermore, $T$ is explicit in the sense that each permutation in $T$ can be evaluated in time $\polylog(|T|)$. 
\end{theorem}

\begin{theorem}[Reduction from almost independence to full independence{\cite{AL2013}}]\label{thm:AL}
Let $D$ be an $m$-wise $\delta$-dependent distribution over $\cS_\Sigma$. Then, there exists an $m$-wise independent distribution over $\cS_\Sigma$ such that $$\norm{D-D'} \le O\inparen{\delta\cdot q^{4m}}\eperiod$$  
\end{theorem}

\subsection{Main results about list-recoverability of Alphabet-Permutation Codes}
We can now state our main result about alphabet-permutation codes.

\begin{theorem}\label{thm:MainTechnical}
    Fix $\ell, q,L, n\in \N$ and $\rho \ge 0$ such that $1\le \ell < q$ and $\rho < 1-\frac \ell q$. Let $\Sigma = \{0,\dots, q-1\}$ and fix an $\ell$-wise independent distribution $D$ over $\cS_\Sigma$. Let $k\in \N$ such that $$R:= \frac{k}{n\cdot \log_2 q} = 1 - h_{q,\ell}\!\inparen{\rho} - \frac {\log_q\binom q \ell+\frac 1n} {(L+1)} - \eta$$ for some \begin{equation}\label{eq:etaLowerBound}
        \eta \ge \frac{2\log_q(2\cdot n/\ln2)}n\eperiod
    \end{equation} Let $\Pi \in S_\Sigma^{k\times n}$ be a random matrix whose entries are sampled independently at random from $D$.    
    Then,
    $$\PR{\cC_\Pi \textrm{ is }\LR \rho \ell L} \ge 1 - \sqrt 2\cdot k\cdot q^{-\frac{\eta n} 2}\eperiod$$
\end{theorem}



We prove \cref{thm:MainTechnical} in \cref{sec:ProofMain} by generalizing a potential-function method originating in~\cite{GHS+2002}, which showed the existence of linear binary codes meeting the Elias Bound for list-decoding. This method was refined in~\cite{LW2021} to establish that random binary linear codes almost surely achieve conjecturally near-optimal list-decodability parameters, and then~\cite{GLM+2022} extended these results to \deffont{average-radius list-decodability}.

The uniform distribution over $S_\Sigma$ is evidently $\ell$-wise independent. Hence, by setting $D := \uniform\!\bigl(S_\Sigma\bigr)$, the codes in \cref{thm:MainTechnical} can be constructed using 
\[
n \cdot k \cdot \log_2 \inabs{S_\Sigma}
\;=\;
O\inparen{n \cdot k \cdot q \cdot \log_2 q}
\]
random bits. When $\ell \ll q$, \cref{thm:introMainLR} instead employs a distribution that is only \emph{almost} $\ell$-wise independent, thereby reducing the required randomness. This refinement is shown below, in the proof that \cref{thm:MainTechnical} implies \cref{thm:introMainLR}.


\begin{proof}[Proof of \cref{thm:introMainLR}]
Set $\delta := q^{-\ell}$ and let $T \subseteq \cS_\Sigma$ be an $\ell$-wise $\delta$-dependent family of permutations with $\log_2 \inabs{T} \le O\!\inparen{\ell \,\log q + \log \tfrac{1}{\delta}}$, as in \cref{thm:KNR}. Let $\Pi \in \cS_\Sigma^{k \times n}$ have independent entries each chosen uniformly from $T$. Observe that the code $\cC_\Pi$ is constructed using 
\[
O\!\bigl(n\,k\,\log \inabs{T}\bigr)
\;=\;
O\!\bigl(n^2 \,\log q \,\log \inabs{T}\bigr)
\;=\;
O\!\bigl(n^2 \,\log q \,\bigl(\ell \,\log q + \log \tfrac{1}{\delta}\bigr)\bigr)
\]
random bits.

Let $D'$ be an $\ell$-wise independent distribution on $\cS_\Sigma$ with $\norm{\uniform(T)-D'} \le c\,\delta \,q^{4\ell}$, guaranteed by \cref{thm:AL}. Let $\Pi' \in \cS_\Sigma^{k \times n}$ be a matrix whose entries are independently sampled from $D'$. By \cref{thm:MainTechnical},
\[
\PR{\cC_{\Pi'} \text{ is } \LR{\rho}{\ell}{L}}
\;\ge\;
1 \;-\; k\sqrt 2 \,q^{-\tfrac{\eta n}{2}}.
\]
Note that $\Pi$ and $\Pi'$ have total-variation distance at most $\norm{U(T)-D'}\cdot nk$. Thus, 
\begin{align*}
\PR{\cC_\Pi \text{ is } \LR{\rho}{\ell}{L}}
&\ge
\PR{\cC_{\Pi'} \text{ is } \LR{\rho}{\ell}{L}}
-
\norm{\uniform(T) - D'}\cdot nk
\\ &\ge
1 \;-\; \sqrt2\cdot k \cdot q^{-\tfrac{\eta n}{2}}
\;-\;
c\cdot\delta \cdot q^{4\ell}\cdot nk\eperiod
\end{align*}
\end{proof}

\subsection{Random $\F_2$-linear codes}
Fix $q := 2^t$ for some $t \in \N$. A code $\cC \subseteq \F_q^n$ is \deffont{$\F_2$-linear} (or \deffont{additive}) if it is a vector space over the subfield $\F_2$ of $\F_q$. A \deffont{random $\F_2$-linear code} of rate $R \in [0,1]$ is formed\footnote{There are other natural ways to define a random $\F_2$-linear code. One could sample uniformly from all such codes of rate $R$ (treating the code as either a multiset or a set), or sample it via a random parity-check matrix. This is analogous to the many ways of sampling a \deffont{random linear code (RLC)} over a given field. Fortunately, all these definitions coincide up to an exponentially small total-variation distance.} by taking a uniformly random matrix $G \in \F_q^{n \times k}$, where $k := R \cdot n \cdot t$, and setting
$$
\cC = \inset{Gx \mid x \in \F_2^k}\eperiod
$$

Interestingly, a random $\F_2$-linear code can also be obtained as a special case of an alphabet-permutation code. For each $a \in \F_q$, let $\pi_a:\F_q \to \F_q$ be the permutation $x \mapsto x+a$. Let $D$ be the uniform distribution over $\inset{\pi_a \mid a \in \F_q}$, and let $\Pi \in S_{\F_q}^{k\times n}$ have i.i.d.\ entries each sampled from $D$. Evidently, the alphabet-permutation code $\cC_\Pi$ is then a random $\F_2$-linear code of rate $R$.

Moreover, $D$ is $1$-wise independent, so \cref{thm:MainTechnical} applies to $\cC_\Pi$ with $\ell=1$. Recalling that $\LRe{\rho}{1}{L}$ is equivalent to $(\rho,L)$-list-decodability, we obtain:

\begin{corollary}\label{cor:linear}
Fix $t, L, n \in \N$. Set $q := 2^t$ and let $0 \le \rho \le 1 - \tfrac{1}{q}$. Let $k \in \N$ satisfy
$$
R := \frac{k}{n\,t} 
= 1 - h_q(\rho) - \frac{1 + \tfrac{1}{n}}{L+1} - \eta\eperiod
$$
for some 
$$
\eta \;\ge\; \frac{2\,\log_q\!\bigl(2\,n/\ln 2\bigr)}{n}\eperiod
$$
Let $\cC$ be a random $\F_2$-linear code in $\F_q^n$ of rate $R$. Then,
$$
\PR{\cC \text{ is } \LD{\rho}{L}}
\;\ge\;
1 - \sqrt{2}\,k \,q^{-\tfrac{\eta n}{2}}\eperiod
$$
\end{corollary}

When $t=1$, $\cC$ is simply a random linear code in $\F_2^n$, thus recovering (in spirit) the main result of~\cite{LW2021}. We note that~\cite{LW2021} achieves a somewhat smaller list size by exploiting the linearity of $\cC$, a method not applicable in the more general setting of alphabet-permutation codes, which need not be linear or additive.









\section{Proof of \cref{thm:MainTechnical}}\label{sec:ProofMain}
We define some notation, inspired by \cite{GHS+2002,LW2021}. Let $$P = \inset{\inparen{Z_1,\dots, Z_n}\mid \forall i ~~Z_i\subseteq \Sigma~\textrm{ and }~ |Z_i| = \ell}$$
and denote $p = \log_2 |P|$. 
Given a tuple $\bZ = (Z_1,\dots,Z_n)\in P$ and a code $\cC\subseteq \Sigma^n$, let 
$$L_\cC(\bZ) = \inabset{x\in \cC \mid \delta(x,\bZ)\le \rho}\ecomma$$
where
$$\delta(x,\bZ) = \frac{\inabset{i\in [n] \mid x_i\notin Z_i}}n\eperiod$$
Next, let
$$
A_\cC(\bZ) = q^{L_\cC(\bZ)\cdot \alpha n}
$$
where 
$$
\alpha = \frac {\log_q\binom q \ell+\frac 1n} {(L+1)}\eperiod
$$
Finally, we define the potential function
$$
K_\cC = \frac{1}{|P|}\sum_{\bZ\in P}A_\cC(\bZ)\eperiod
$$

\cref{thm:MainTechnical} is now an immediate consequence of the two following lemmas.






\begin{lemma} \label{lem:SmallPotentialImpliesLR}
    Suppose that a code $\cC\subseteq \Sigma^n$ satisfies $K_\cC < 2$. Then $\cC$ is $\LR \rho \ell L$.
\end{lemma}

\begin{lemma} \label{lem:smallPotentialLikely}
    $$\PR{K_{\cC_\Pi} < 2} \ge 1-\sqrt2\cdot k \cdot q^{-\frac{\eta n} 2}$$
\end{lemma}

The rest of this section is devoted to proving both lemmas.






\begin{proof}[Proof of \cref{lem:SmallPotentialImpliesLR}]
    \sloppy
    We prove the statement in its contrapositive form. Suppose that $\cC$ is not $\LR\rho\ell L$. Then, there exists distinct codewords $x_1,\dots, x_{L+1}\in \cC$, such that $$\delta(x_i,\bZ)\le \rho$$ for all $1\le i\le L+1$. Equivalently, $L_\cC(\bZ) \ge L+1$. Consequently,
    $$
    K_\cC = \frac{A_\cC(\bZ)}{|P|} + \frac{\sum_{\bZ'\in P\setminus\{\bZ\}} A_{\cC}(\bZ')}{|P|} \ge \frac{q^{(L+1)\alpha n}}{|P|} + \frac{\sum_{\bZ'\in P\setminus\{\bZ\}} A_{\cC}(\bZ')}{|P|}\ge \frac{q^{(L+1)\alpha n}}{|P|} = \frac{q^{(L+1)\alpha n}}{\binom q\ell^n} = q \ge 2\eperiod$$
\end{proof}

\begin{proof}[Proof of \cref{lem:smallPotentialLikely}]
    We consider a stochastic process in which the matrix $\Pi\in S^{k\times n}$ is constructed row-by-row. Concretely, let $\Pi^i \in S^{i\times n}$ (where $0\le i\le k$) denote the matrix consisting of the first $i$ rows of $\Pi$ and let $\cC_i$ denote the code $\cC_{\Pi^i} \subseteq \Sigma^n$ whose size is $2^i$. To prove the lemma we control the growth of the sequence $K_{\cC_0}, K_{\cC_1},\dots, K_{\cC_k}$, noting that $\cC_k = \cC_{\Pi^k} = \cC_\Pi$.

    Consider the sequence of real numbers $\lambda_0,\dots, \lambda_k$ defined by 
    \begin{align*}
        \lambda_0 &= q^{n\cdot \inparen{\alpha + h_{q,\ell}(\rho)-1}} \\
        \lambda_i &= 2\lambda_{i-1} + \lambda_{i-1}^{1.5} & \text{for }1\le i\le k\eperiod
    \end{align*}
    We claim that, with high probability, \begin{equation}\label{eq:lambdaBound}
        K_{\cC_i} \le 1 + \lambda_i\quad\quad \text{for all }0\le i\le k\eperiod
    \end{equation} 
    The following claim shows that \cref{eq:lambdaBound} holds deterministically for $i=0$.
    \begin{claim}\label{claim:FirstElement}
        $$K_{\cC_0} \le 1 + q^{n\cdot \inparen{\alpha + h_{q,\ell}(\rho)-1}}\eperiod$$
    \end{claim}
    \begin{proof}
        Note that $\cC_0$ is merely the code $\{0\}$. Thus,
        \begin{align*}K_{\cC_0} = \frac{1}{|P|}\sum_{\bZ\in P}A_{\{0\}}(\bZ) = \frac{1}{|P|}\inparen{\sum_{\substack{\bZ\in P \\ \delta(0,\bZ) > \rho}} q^{0} + \sum_{\substack{\bZ\in P \\ \delta(0,\bZ) \le \rho}} q^{\alpha n}}  &\le 1 + \frac{1}{|P|}\cdot \inparen{\sum_{\substack{\bZ\in P \\ \delta(0,\bZ) \le \rho}} q^{\alpha n}}\eperiod \\
        &= 1 + q^{\alpha n} \cdot \PROver{\bZ \sim \uniform(P)}{\delta(0,\bZ)\le \rho} 
        \end{align*}
        To bound the probability in the right-hand side, consider the bipartite graph in which the left-side is $P$, the right hand side is $\Sigma^n$, and there is an edge between $\bZ\in P$ and $x\in \Sigma^n$ if $\delta(x,\bZ)\le \rho$. Observe that this graph is biregular. Hence, fixing an arbitrary $\bZ'\in \cP$, we have
        $$\PROver{\bZ \sim \uniform(P)}{\delta(0,\bZ)\le \rho} = \PROver{x \sim \uniform(\Sigma^n)}{\delta(0,\bZ')\le \rho} = \frac{|\bZ'|}{|\Sigma^n|} \le q^{n\cdot \inparen{h_{q,\ell}(\rho)-1}}\ecomma$$
        where the last inequality is a standard estimation (\cite[Prop.\ 2.4.11]{Resch2020}). The claim follows.        
    \end{proof}
    We now prove that \cref{eq:lambdaBound} holds with high probability for any $1\le i\le k$, provided that it holds for $i-1$.
    \begin{claim}\label{claim:Step}
        Let $1\le i\le k$ and fix a matrix $\Pi^{i-1}\in S_\Sigma^{i\times n}$ such that $K_{\cC_{i-1}} \le 1 + \lambda_{i-1}$. Then, 
        $$\PROver{\Pi^i}{K_{\cC_i} > 1+\lambda_i\;\mid\;\Pi^{i-1}} \le \lambda_{i-1}^{1/2}$$
    \end{claim}

    \begin{proof}
    Recall that the matrix $\Pi^i$ is the fixed matrix $\Pi^{i-1}$ with an additional last row $\Pi_i \in S_\Sigma^n$, sampled independently at random from $D^n$. Thus, we can write 
    $$\cC_i = \enc_{\Pi^i}(\inset{x\in \F_2^i \mid x_i = 0}) \cup \enc_{\Pi^i}(\inset{x\in \F_2^i \mid x_i = 1}) = \cC_{i-1} \cup \cC'_{i-1}$$
    where
    $$\cC'_{i-1} = \inset{\inparen{\Pi_{i,1}(y_1),\dots,\Pi_{i,n}(y_n)} \mid y\in \cC_{i-1}}\eperiod$$
    Now, for any fixed $\bZ = (Z_1,\dots, Z_n) \in P$, conditioning on $\Pi_{i-1}$, we have
    \begin{align*}
        \Eover{\Pi_i}{A_{\cC_i}(\bZ)} &= \Eover{\Pi_i}{q^{\alpha\cdot n\cdot L_{\cC_i}(\bZ)}} \\ &= \Eover{\Pi_i}{q^{\alpha\cdot n\cdot L_{\cC_{i-1}}(\bZ)+L_{\cC'_{i-1}}(\bZ)}} \\ 
        &= A_{\cC_{i-1}}(\bZ)\cdot\Eover{\Pi_i}{ q^{\alpha\cdot n\cdot L_{\cC'_{i-1}}(\bZ)} } \\ 
        &= A_{\cC_{i-1}}(\bZ)\cdot\Eover{\Pi_i}{q^{\alpha\cdot n\cdot \inabset{x\in \cC'_{i-1} \mid \delta(x,\bZ)\le \rho}} } \\
        &= A_{\cC_{i-1}}(\bZ)\cdot\Eover{\Pi_i}{q^{\alpha\cdot n\cdot \inabset{y\in \cC_{i-1} \mid \delta\inparen{\inparen{\Pi_{i,1}(y_1),\dots,\Pi_{i,n}(y_n)},\bZ}\le \rho}} } \\
        &= A_{\cC_{i-1}}(\bZ)\cdot\Eover{\Pi_i}{q^{\alpha\cdot n\cdot \inabset{y\in \cC_{i-1} \mid \delta\inparen{y,\inparen{\Pi_{i,1}^{-1}(Z_1),\dots,\Pi_{i,n}^{-1}(Z_n)}}\le \rho}} } \\
        &= A_{\cC_{i-1}}(\bZ)\cdot\Eover{\Pi_i}{q^{\alpha\cdot n\cdot \inabset{y\in \cC_{i-1} \mid \delta\inparen{y,\inparen{\Pi_{i,1}^{-1}(Z_1),\dots,\Pi_{i,n}^{-1}(Z_n)}}\le \rho}} } \\
        &= A_{\cC_{i-1}}(\bZ)\cdot\Eover{\bZ' \sim \uniform(P)}{q^{\alpha\cdot n\cdot \inabset{y\in \cC_{i-1} \mid \delta\inparen{y,\bZ'}\le \rho}} } \\
        &= A_{\cC_{i-1}}(\bZ)\cdot\Eover{\bZ' \sim \uniform(P)}{A_{\cC_{i-1}}(\bZ') }\eperiod
    \end{align*}
    In the penultimate transition we took $\bZ' := \inparen{\Pi^{-1}_{i,1}(Z_1),\dots, \Pi^{-1}_{i,n}(Z_n)}$. Since the sets $Z_1,\dots, Z_n$ are of size at most $\ell$ and  $\Pi_{i,1},\dots, \Pi_{i,q}$ are sampled independently from an $\ell$-wise independent distribution, $\bZ'$ is indeed uniformly distributed over $P$. Now, still conditioning on $\Pi_{i-1}$, the following holds
    \begin{align*}
    \Eover{\Pi_i}{K_{\cC_i}} &= \Eover{\Pi_i}{\Eover{\bZ\sim \uniform(P)}{{A_{\cC_i}(\bZ)}}} =  \Eover{\bZ\sim \uniform(P)}{\Eover{\Pi_i}{{A_{\cC_i}(\bZ)}}}\\
    &=
    \Eover{\bZ\sim \uniform(P)}{A_{\cC_{i-1}}(\bZ)\cdot\Eover{\bZ'\sim \uniform(P)}{A_{\cC_{i-1}}(\bZ')}} \\
    &= \Eover{\bZ\sim U(P)}{A_{\cC_{i-1}}(\bZ)} \cdot \Eover{\bZ'\sim U(P)}{A_{\cC_{i-1}}(\bZ')} = \inparen{\Eover{\bZ\sim U(P)}{A_{\cC_{i-1}}(\bZ)}}^2 = K_{\cC_{i-1}}^2\eperiod
    \end{align*}

    Write $K_{\cC_{i-1}} = 1 + \beta$. By assumption, $0\le \beta \le \lambda_{i-1}$. Note that $K_{\cC_{i}} \ge 1 + 2\beta$ deterministically. Indeed,
    \begin{align*}
    0 &\le \Eover{\bZ\sim \uniform(P)}{(A_{\cC_{i-1}}(\bZ)-1)\cdot (A_{\cC'_{i-1}}(\bZ)-1)} \\&= \Eover{\bZ\sim \uniform(P)}{A_{\cC_{i-1}\cup \cC'_{i-1}}(\bZ) - A_{\cC_{i-1}}(\bZ) - A_{\cC'_{i-1}}(\bZ)} + 1  \\&= \Eover{\bZ\sim \uniform(P)}{A_{\cC_i}(\bZ) - A_{\cC_{i-1}}(\bZ) - A_{\cC'_{i-1}}(\bZ)} + 1 \\
    &= K_{\cC_i} - K_{\cC_{i-1}} + K_{\cC'_{i-1}} + 1 \\
    &= K_{\cC_i} - 2(1+\beta) + 1 = K_{\cC_i} - (1+2\beta)\eperiod
    \end{align*}
    Here, the  inequality is due to $A_{\cC}(\bZ) \ge 1$ for all $\cC$ and $\bZ$. The first equality is since, for any two codes $\cC$ and $\cC'$, there holds
    $$A_{\cC\cup \cC'}(\bZ) = q^{\alpha\cdot n\cdot\inabset{x\in \cC\cup\cC'\mid\delta(x,\bZ\le \rho)}} = q^{\alpha\cdot n\cdot\inparen{\inabset{x\in \cC\mid\delta(x,\bZ\le \rho)}+\inabset{x\in \cC'\mid\delta(x,\bZ\le \rho)}}} = A_{\cC}(\bZ) \cdot A_{\cC'}(\bZ)$$
    (recall that the codes are multisets).    
    The penultimate equality is by observing that $K_{\cC'_{i-1}} = K_{\cC_{i-1}}$ since $K$ is invariant to coordinate-wise alphabet permutations.
    Markov's inequality thus yields
    \begin{align*}
    \PROver{\Pi^i}{K_{\cC_i} > 1+\lambda_i} &= \PROver{\Pi^i}{K_{\cC_i} - (1+2\beta) > \lambda_i-2\beta} \le \frac{\Eover{\Pi^i}{K_{\cC_i}}-(1+2\beta)}{\lambda_i-2\beta} \\&\le \frac{K_{\cC_{i-1}}^2-(1+2\beta)}{\lambda_i-2\beta} = \frac{(1+\beta)^2-(1+2\beta)}{\lambda_i-2\beta} \\
    &= \frac{\beta^2}{\lambda_i - 2\beta}  = \frac{\beta^2}{2\lambda_{i-1}+\lambda_{i-1}^{1.5}-2\beta} \le \frac{\beta^2}{\lambda_{i-1}^{1.5}} \le \frac{\lambda_{i-1}^2}{\lambda_{i-1}^{1.5}} = \lambda_{i-1}^{1/2}\eperiod
    \end{align*}   
    \end{proof}

    By \cref{claim:FirstElement,claim:Step},
    \begin{align*}
        \PR{K_{\cC_k} > 1+\lambda_k} \le \sum_{i=1}^k \PR{K_{\cC_i} > 1+\lambda _i \;\mid\; K_{\cC_{i-1}}\le 1+\lambda_{i-1}} \le \sum_{i=1}^k \lambda_{i-1}^{1/2} \le k\cdot \lambda_k^{1/2}\eperiod \numberthis \label{eq:K_C}
    \end{align*}
    To conclude the lemma we need the inequality
    \begin{equation}\label{eq:deltak}
        \lambda_k \le 2^{k+1}\cdot \lambda_0 = 2\cdot q^{n\cdot\inparen{\alpha + h_{q,\ell}(\rho)-1+R}} = 2 \cdot q^{-\eta n}\le 1\ \eperiod
    \end{equation}
    Indeed, assuming that \cref{eq:deltak} holds, \cref{eq:K_C,eq:etaLowerBound} yield
    $$\PR{K_{\cC_\Pi} \ge 2} = \PR{K_{\cC_k} \ge 2} \le \PR{K_{\cC_\Pi} > 1+\lambda_k} \le k\cdot \lambda_k^{1/2} \le \sqrt2\cdot k\cdot q^{-\frac {\eta n}2}\eperiod$$
    
    We prove \cref{eq:deltak} as a special case of the more general claim that $\lambda_i \le 2^{i+1}\cdot \lambda_0$ for all $0\le i\le k$. We prove the latter by induction on $i$. The base case $i=0$ is immediate. For $1\le i\le k$, we have
    \begin{align*}\lambda_i &= 2\lambda_{i-1} + \lambda_{i-1}^{1.5} = 2\lambda_{i-1}\inparen{1 + \frac{\lambda_{i-1}^{1/2}}{2}} = 2^i\cdot \lambda_0\cdot\prod_{j=0}^{i-1}\inparen{1+\frac{\lambda_j^{1/2}}2} \leq 2^i\cdot \lambda_0\cdot \exp{\sum_{j=0}^{i-1} \frac{\lambda_j^{1/2}}2} \\
    &\le 2^i\cdot \lambda_0\cdot \exp{i\cdot 2^{\frac {i}{2}+1}\cdot \lambda_0^{\frac 12}} \le 2^i\cdot \lambda_0\cdot \exp{k\cdot 2\cdot q^{\frac n2\cdot \inparen{\alpha+h_{q,\ell}(\rho)-1+R}}}\le 2^i\cdot \lambda_0\cdot \exp{k\cdot 2\cdot q^{-\frac{\eta n}2}}\\&\le 2^{i+1}\cdot \lambda_0\eperiod
    \end{align*}
        Here, the second inequality is by the induction hypothesis and the last inequality is due to \cref{eq:etaLowerBound}.     
\end{proof}

    \ifauthors
    \section{Acknowledgement}
    The second author thanks Or Zamir for bringing \cite{AL2013} to his attention.
    \fi


	
\printbibliography
\end{document}
