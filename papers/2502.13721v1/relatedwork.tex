\section{Related works}
\label{sec:related_works}

\subsection{Time series modeling }

As a classical research problem with widespread applications, models constructed from the statistical approaches for time series modeling have been used from the 1970s. The representative models are autoregressive integrated moving average (ARIMA) \cite{box2015time}, exponential smoothing \cite{gardner1985exponential}, and structural models \cite{bollen1989structural}. The most significant characteristic for these methods is that they require significant domain expertise to build. With the development of machine learning (ML) \cite{biship2007pattern}, many ML techniques are introduced to time series modeling to reduce manual efforts. Gradient boosting regression tree (GBRT) \cite{drucker1994boosting,prokhorenkova2018catboost} gains popularity by learning the temporal dynamics of time series in a data-driven manner. However, these methods still require manual feature engineering and model designs. With the powerful representation learning capability of deep learning (DL) from large-scale data, various deep learning-based time series models are proposed in the literature \cite{lim2021time}, achieving better forecasting accuracy than traditional techniques in many cases. Before the era of Transformer \cite{vaswani2017attention}, the two popular DL architectures are: (a) Recurrent neural networks (RNNs) based methods \cite{Hochreiter1997LongSM}, which summarize the past information compactly in internal memory states and recursively update themselves for forecasting. (b) Convolutional neural networks (CNNs) based methods \cite{li2021survey}, wherein convolutional filters are used to capture local temporal features. More recently, multi-layer perceptron (MLP) based methods, like \cite{tang2025ts} and \cite{zeng2023transformers}, have raised attention in the research field, since these models are simple and light-weight.  




\subsection{Transformer architectures in time series}

The progressive advancements in natural language processing and computer vision have led to the development of sophisticated Transformer \cite{Vaswani2017AttentionIA} variants tailored for a wide array of time series forecasting applications \cite{zhou2021informer,wu2021autoformer}. Central to these innovations is the methodology by which Transformers handle time series data. For instance, iTransformer \cite{liu2023itransformer} treats each univariate time series as a distinct token, forming multivariate time series into sequences of such tokens. More recently, PatchTST \cite{nie2022time} adopts an assumption of channel independence, transforming a univariate time series into multiple patches, which are subsequently treated as tokens and processed through a Transformer encoder. Another important research direction is to design alternative Transformer architectures. This branch of works mainly devote themselves into manually designing novel attention mechanisms, including  Reformer \cite{kitaev2020reformer}, Informer \cite{zhou2021informer}, AutoFormer \cite{wu2021autoformer}, FEDformer\cite{zhou2022fedformer}. 


\subsection{Neural architecture search methods}

In the early attempts, NAS requires massive computations, like thousands of GPU days~\cite{Zoph2017NeuralAS,Zoph2018LearningTA,Liu2018ProgressiveNA}. Recently, a particular group of one-shot NAS, led by the seminal work DARTS~\cite{Liu2019DARTSDA} has attracted much attention. DARTS formulates the search space into a super-network that can adjust itself in a continuous space so that the network and architectural parameters can be optimized alternately (bi-level optimization) using gradient descent. A series of literature try to improve the performance and efficiency of DARTS, such as \cite{Xie2019SNASSN,Chen2021ProgressiveDB,Chu2021FairNASRE,Nayman2019XNASNA}. SNAS~\cite{Xie2019SNASSN} reformulate DARTS as a credit assignment task while maintaining the differentiability. \cite{Gao2020MTLNASTN} penalize the entropy of the architecture parameters to encourage discretization on the hyper-network. P-DARTS~\cite{Chen2021ProgressiveDB} analyze the issues during the DARTS bi-level optimization, and propose a series of modifications. PC-DARTS~\cite{Xu2021PartiallyConnectedNA} reduces the memory cost during search by sampling a portion of the channels in super-networks. FairDARTS~\cite{Chu2021FairNASRE} change the softmax operations in DARTS into sigmoid and introduce a zero-one loss to prune the architectural parameters. XNAS~\cite{Nayman2019XNASNA} dynamically wipes out inferior architectures and enhances superior ones.

Our work complements the literature by the following two aspects: (a) we conduct a pilot experiment to analyze the shortcomings of the current DNAS methods; (b) we propose a novel DNAS method that can achieve better search performances and search stability.