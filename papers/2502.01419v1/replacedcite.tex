\section{Related Work}
\subsection{Mitigating Hallucinations in MLLMs}  
MLLMs often generate hallucinations, where text is inconsistent with visual input, and numerous studies have aimed to address this issue through various methods____. Decoding-based methods tackle hallucination by penalizing uncertain token generations through techniques like text aggregation analysis____, corrupted visual inputs____. Self-refinement strategies are also employed to iteratively align generated captions with visual content____. In addition, research indicates that hallucinations often arise from an over-reliance on textual context while neglecting visual information____. To address this imbalance, decoding strategies and attention calibration techniques have been developed to enhance the utilization of relevant visual elements based on their importance____. Hallucination issues intensify with long-form text generation, as models rely more on text and less on image content____. Methods such as shortening text length____, segmenting refinement____, and leveraging image-only logits and contrastive decoding____ have been explored. Existing solutions have not effectively addressed the challenge of enhancing context-relevant visual information, as vision-related signals tend to weaken over longer contexts.

\subsection{Visual Attention in MLLMs}

MLLMs utilize transformer-based architectures with attention mechanisms to integrate visual and textual modalities____. During text generation, attention weights do not always focus on the most relevant visual tokens____. Prior studies have shown that enhancing image attention can help mitigate hallucinations by improving the model's ability to better align with relevant visual content____. Efforts to achieve this include increasing image attention, adjusting positional embeddings____, and correcting biases that direct attention to irrelevant regions.____.
Several approaches have been proposed, such as boosting overall image attention____ and reweighting key tokens____ to better focus on meaningful visual regions. Our findings show that as the model generates longer text, its focus on key visual tokens weakens, while sensitivity to irrelevant noise increases. Existing methods struggle to retain key visual tokens in such cases, making it difficult to preserve their relevance. In contrast, our approach reinforces key visual tokens during decoding, ensuring their continued importance. This improves caption detail and accuracy with minimal computational cost.