\section{Related Work}
%-------------------------------------------------------------------------------

Our work focuses primarily on the real-time and photo-realistic rendering of large-scale Gaussian splatting scenes, encompassing city-level scenes with several square kilometers. Although novel view synthesis based on neural rendering has made significant achievements in various applications in recent years, there remains a gap in meeting the demands of rendering performance, quality fidelity, and computational efficiency required for VR rendering. We provide a brief overview of the most relevant works, focusing on real-time photo-realistic rendering, large-scale novel view synthesis, and rendering framework optimizations.

\textbf{Real-Time Photo-realistic Rendering} VR rendering is computationally expensive, requiring high-speed and high-quality real-time rendering, which may be hindered by quality degradation and latency overhead in the general rendering pipeline\cite{song2023nerfplayer}. To achieve high-fidelity rendering with minimal latency under relatively low computation resources, various optimization methods have been proposed. Foveated rendering is a rendering accelerated method, the pioneer work~\cite{guenter2012foveated} providing a foundational theory and approach, the subsequent works~\cite{krajancich2021perceptual,mantiuk2021fovvideovdp,tursun2019luminance} etc., exploring different enhancements and applications. Leveraging eye-tracking technology, foveated rendering tends to allocate more computational resources in rendering the focus area of the images while less the periphery area~\cite{wang2023foveated}. 
To speed up the neural rendering like NeRF, in order to fulfill requirements for real-time rendering, including VR rendering, some works have shifted from pure implicit neural representation towards hybrid or explicit primitive-based neural representations and hardware-based acceleration~\cite{chen2023mobilenerf,tang2023delicate,hedman2021baking}. VR-NeRF~\cite{xu2023vr} achieves high-quality VR rendering using multiple GPUs for parallel computation, RT-NeRF~\cite{li2022rt} realize real-time VR rendering both on cloud and edge devices through efficient pipeline and dedicated hardware accelerator. Re-ReND~\cite{rojas2023re} presents a low resource consumption real-time NeRF rendering method available on resource-constrained devices.~\cite{yu2021plenoctrees, reiser2023merf, yariv2023bakedsdf} distill a pretrained NeRF into a sparse structure, enhancing the real-time rendering performance. 
Different from the aforementioned methods, to speed up neural rendering like 3DGS, another strategy for rendering acceleration involves model pruning and structuring for redundancy removal and effective spatial representation. Methods include ~\cite{fan2023lightGaussian, lee2024compact, lin2024rtgs} pruning Gaussians and reducing model parameters after reconstruction to accelerate the rendering pipeline. Scaffold-GS~\cite{lu2024scaffold} organizes Gaussians using a structured sparse voxel grid and attaches learnable features to each voxel center as an anchor, Octree-GS~\cite{ren2024octree} further employs a structured octree grid for anchors placement. 
%These two methods derive Gaussians from anchors in the rendering pipeline and achieve a balance between quality and speed but are restrained by scene scaling. 

%However, the rendering process of these existing real-time methods remains containing computation redundancy, and the scale of scenes that guarantee real-time performance is still limited. Instead, we propose a novel computation optimization method in our end-to-end real-time VR rendering framework which accelerates structured Gaussian derivation pipeline under different scales of scenes.



\textbf{Large 3D Model Inference} Neural reconstruction and rendering are also attributed to Novel View Synthesis. In large-scale scenes, it has been a long-standing problem in research and engineering. First of all, the fidelity of large-scale rendering is directly contingent upon the quality of the underlying 3D representation models, particularly when reconstructed from real-world scenes. Large-scale scene reconstruction primarily utilizes a divide-and-conquer strategy through scene decomposition methods to expand the capabilities of the model~\cite{tancik2022block, turki2022mega}, while Zip-NeRF~\cite{barron2023zip} and Grid-NeRF~\cite{xu2023grid} better refined the effectiveness and performance of representation for the large-scale scene. Except for the NeRF-based methods ~\cite{park2021instant} extracts semantic information from street-view images and employs panoramic texture mapping method in large-scale scenes novel view synthesis for realism reproduction. To ensure that novel view synthesis for VR real-time rendering maintains a stable frame rate under large-scale scenes, an effective method is the Level of Detail (LoD) strategy.  Guided by heuristic rules or specific resource allocation settings, LoD dynamically adjusts the level of detail layers rendered in real-time ~\cite{Luebke2012LevelOD}. ~\cite{takikawa2021neural} first introduced the concept of LoD into neural radiance fields and neural signed distance, Mip-NeRF~\cite{barron2021mip} and Variable Bitrate Neural Fields~\cite{takikawa2022variable} applying it in the context of multi-scale representation and geometry compressed streaming. LoD has also been employed in Gaussian-based representations, Hierarchy-GS~\cite{kerbl2024hierarchical} designed a hierarchical structure for multi-resolution representation to improve rendering speed. Other large-scale scene reconstruction and rendering works~\cite{xu2023vr, lu2024scaffold, ren2024octree, liu2025citygaussian} have also adopted LoD to accelerate the rendering pipeline.

%Nevertheless, the LoD will sacrifice rendering quality and introduce storage redundancy to some extent. Building and using LoD requires an overhaul in the training and rendering pipeline, and there is a certain trade-off between rendering quality and real-time rendering speed. We propose a generalized framework for structured Gaussian derivation computation and achieved stable performance of 120 FPS in aerial and 72 FPS in the street under city-level scenes ~\cite{li2023matrixcity} spanning \textit{2.7 kmÂ²}.



\textbf{Rendering Framework Optimization} In large-scale novel view synthesis and city-level scene rendering, the stability of high-speed rendering frame rates remains an intractable problem due to variations such as viewpoint and field of view (FOV), as well as the limitations of computational resources. However, little research has focused on optimizations for large-scale VR rendering from the perspective of a computation system, and most existing methods concentrate primarily on mesh-based rendering rather than neural rendering pipelines. MeshReduce ~\cite{jin2024meshreduce} optimizes communication strategy and efficiently converts the scene geometry into the meshes without restraints from computation and memory, yet the stability of rendering frame rates is still difficult to maintain. RT-NeRF~\cite{li2022rt} employs a hybrid sparse encoding method and proposes a NeRF-based storage optimization besides its dedicated hardware system. Post0-VR~\cite{wen2023post0} leverages data similarities to accelerate rendering by eliminating redundant computations and merging common visual effects into the standard rendering pipeline systematically. ~\cite{malkin2020cuda} utilizes shared memory and data reuse to enhance the performance of foveated rendering. 
%Our computation framework and optimization methods also adopt the concept of computation de-redundancy and reuse, but further attention is paid to the versatility between different rendering pipelines. Whereas existing methods still fail to effectively address the problem of frame rate fluctuations in real-time rendering, as few methods take into account the varying necessary computational demands of large-scale scene rendering.

%Eventually, for complete urban scene rendering from arbitrary VR viewpoints, 
Our work introduces a novel end-to-end rendering framework for large 3DGS models. Optimizations are applied by an innovative GPU scheduling method, a cache-centric rendering pipeline specifically tailored for Gaussian-based rendering, and dedicated CUDA kernels to stabilize high-speed rendering across immersive VR experiences.

%-------------------------------------------------------------------------------