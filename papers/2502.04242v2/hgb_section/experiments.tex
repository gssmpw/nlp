
\section{Experiments}
\label{sec:experi}
% 总experiment
% 数据集、mertics
% 实现细节

% 大表结果分析 accuracy
% 数据使用量的分析（epoch等各种考虑哪个有优势画哪个）+计算时间分析 efficient 

% ablation analysis
% 模型取数据与domain之间距离的关系
% 不仅fewshot可以，在大的数据量场景下也能work
% LoRA也可以work


\subsection{Experiments Settings}
\textbf{Benchmark Datasets.} 
\texttt{DomainNet} contains 586,575 samples of 345 classes from 6 domains (\textit{i.e.}, \textbf{C}: Clipart, \textbf{I}: Infograph, \textbf{P}: Painting, \textbf{Q}: Quickdraw, \textbf{R}: Real and \textbf{S}: Sketch). \texttt{Office-Home} benchmark contains 15588 samples of 65 classes, with 12 adaptation scenarios constructed from 4 domains:  Art, Clipart, Product and Real World (abbr. \textbf{Ar}, \textbf{Cl}, \textbf{Pr} and \textbf{Rw}). 
\texttt{Digits} contains four-digit sub-datasets: MNIST(mt), Synthetic(sy), SVHN(sv) and USPS(up), with each sub-dataset containing samples of numbers ranging from 0 to 9.

% \textbf{Implementation Details.} We employ the ViT-Small~\cite{rw2019timm_vits} model pre-trained on ImageNet21k~\cite{deng2009imagenet} as the backbone model on all datasets. We adopt Adam optimizer with $1e^{-5}$ learning rate, use 20\% of the dataset as the test set, and report the highest accuracies within 5 epoch early stops in all experiments. Following the standard protocol of few-shot learning, the training data for k-shot is k samples per class randomly selected from the target task. All the experiments are conducted on A800 GPUs.

\textbf{Implementation Details.} We employ the ViT-Small model \cite{rw2019timm_vits}, pre-trained on ImageNet-21k \cite{deng2009imagenet}, as the backbone for all datasets. The Adam optimizer is employed with a learning rate of $1e^{-5}$. We allocate 20\% of the dataset as the test set, and report the highest accuracies within 5 epoch early stops in all experiments. Following the standard few-shot learning protocol, the training data for k-shot consists of k randomly selected samples per class from the target task. All experiments are conducted on Nvidia A800 GPUs.

% The scope of compared methods includes: 
% 1) \textbf{Unsupervised Methods}: MSFDA\cite{shen2023balancingMSFDA}, DATE\cite{han2023discriminability_DATE}, M3SDA\cite{peng2019moment_M3SDA}.
% 2) \textbf{Few-Shot Methods with Parameter-Weighting}: H-ensemble\cite{wu2024h_Hensemble}, MCW\cite{lee2019learning_MCW}.
% 3) \textbf{Few-Shot Methods with Samples-Relation:} MADA\cite{zhang2024revisiting_MADA} , WADN\cite{shui2021aggregating_WADN}.
% 4) \textbf{Source Ablating}: Target-Only, Single-Source-Avg, Single-Source-Best, \allsource{}; 

% and considering few methods are designed for the few-shot data-efficient transfer setting

\textbf{Baselines.} For a general performance evaluation, we take SOTA works under similar settings as baselines.
% we unified the methods of existing works under similar settings as ours (with varied source data.) 
The scope of compared methods includes: 
1) Unsupervised Methods: MSFDA \cite{shen2023balancingMSFDA}, DATE \cite{han2023discriminability_DATE}, M3SDA \cite{peng2019moment_M3SDA}.
2) Few-Shot Methods Based on Model(Parameter)-Weighting: H-ensemble \cite{wu2024h_Hensemble}, MCW \cite{lee2019learning_MCW}.
3) Few-Shot Methods Based on Sample: MADA \cite{zhang2024revisiting_MADA},  WADN~\cite{shui2021aggregating_WADN} 
4) Source Ablating Methods: Target-Only, Single-Source-Avg/Single-Source-Best (average/best performance of single-source transfer), \allsource{} (all source \& target data in multi-source transfer).  
%The ResNet\cite{he2016deep_resnet} backbones they used are all pretrained on ImageNet21k. 
%Here, ``Single-$*$'' attaches one domain dataset from source to the target one for training together and evaluating on target testset while ‘‘\allsource{}’’ attaches all domain datasets, and $*$-Best/Avg stand for the best/average performance. Target-Only finetunes Imagenet-pretrained model on few-shot target data only. 
Note that MADA~\cite{zhang2024revisiting_MADA} leverages all unlabeled target data in conjunction with a limited amount of labeled target data, which is a hybrid approach combining unsupervised and supervised learning. 
%, which means all the target samples have been learned to some extent.
Due to the page limit, we provide detailed information on the experimental design and the results of an experiment adapted to the WADN settings on the \texttt{Digits} dataset in Appendix \ref{appendix:Experimental_Design_and_Model Adaptation}.
% Average W. replace the weighted sum in our framework with equal weights. MultiFinetune learns a fully connected classifier with the target extractor learned in Hensemble. The Prior SOTAs are the SOTAs with the closest problem setting (MSFDA).\\
% To ensure consistency in the experimental setup, we first evaluate the performance of different methods on the DomainNet and Office-Home datasets by adapting their settings to align with ours, such as the backbone, dataset, and early stopping criteria. Our method is adapted to the settings of [ ], equipped with a 3-layer MLP and evaluated on the Digits dataset.
% 再着重说一下他们adapt我们的时候效果不好的原因！！也有他们在officehome上效果好的原因，其实都是一个--10shot！











% Based on mixed dataset during dynamic training, to clarify the confusion about our method \ourmethod{} would take the samples for the introduced source task bias, we treat the ‘‘Static-$*$’’methods as the absolutely correct ones, namely reference on an ablation experiment. 


% When our method \ourmethod{} is launched, adding based on the  
% As our method \ourmethod{} can be executed on two situations, we first test two types of execution situations, and we find the dynamic one outperform others, so we choose dynamic type to do the rest experiments.


\subsection{Main Result}
%\subsection{Main Result: Quantity with Quality Over Only Quantity}
%\subsection{Main Result on Classification Tasks}
% 大表结果分析 accuracy
% 可分多个baseline针对性分析
% 这里的conditions要补！！
We evaluated our algorithm, \ourmethod{}, alongside baseline methods on the multi-source transfer learning tasks using the \texttt{DomainNet} and \texttt{Office-Home} datasets. The quantitative results are summarized in Table \ref{tab:major}. Since the unsupervised baselines are not designed for the supervised few-shot setting, we report their original results from the respective papers for reference.
We make the following observations:


\textbf{Overall Performance.} In general, compared to baseline methods, \ourmethod{} achieves the best performance on almost all the transfer scenarios on the two datasets. Specifically, \ourmethod{} outperforms the state-of-the-art (\allsource{}) by an average of $1.5\%$ on \texttt{DomainNet} and $1.0\%$ on \texttt{Office-Home}.

% aiming at finding a better model structure that can translate the source knowledge into target worth knowledge, tried complicated ways and just can not beat easily training the simple model using all the available samples.
% 2.对比supervised情况：大部分的supervised方法都是从模型的参数入手进行可迁移性的度量。在一样的数据情况下，可以看到仅仅从模型的参数入手，supervised的方法的表现并没有从数据的角度入手用all source数据集去训目标任务模型的效果好。

\textbf{Data Speaks Louder Than Model Weighting.} It is worth noting that on both datasets, samples-based methods utilizing both target and source samples to jointly train the model, such as WADN, MADA and \ourmethod{},
generally outperform model(parameter)-weighting approaches which construct the target model by weighting source models, such as H-ensemble and MCW. This observation suggests that sample-based approaches offer greater advantages over model-based methods, because they can fully leverage the relevant information from the source data for the target task.
%, except when constrained by source-free limitations.

% Using all the source samples and the same limited target samples, methods such as H-ensemble, MADA, MCW and WADN, attempts to design complex model structures to better transfer source knowledge to the target domain, but their sophisticated approaches fail to surpass the straightforward training of a simple model using all available data from the results about \allsource{} method on Table \ref{tab:major}.

% \textbf{Take, but only as much as you need.} At the Source-Ablation part of Table~\ref{tab:major} where we compare our results among Target-only, \allsource{}, and \ourmethod{}, we could observe that \ourmethod{} performed best in both datasets. This result confirmed our theory and demonstrated that benefits of searching for the sweet spot between the bias-variance trade-off. By choosing the right quantities of data samples from the source tasks, we could train the target model more accurately and efficiently. 

\textbf{Take, But Only as Much as You Need.} 
%At the Source-Ablation part of Table~\ref{tab:major} where we 
Comparing results in Table~\ref{tab:major} among Target-only, \allsource{}, and \ourmethod{}, we observe that \ourmethod{} achieves the best performance in both datasets by leveraging only a subset of data selected from all available sources based on model preference. This result validates our theory and highlights the benefits of identifying the optimal balance in the bias-variance trade-off. By choosing the right quantities of samples from the source tasks, we could train the target model more accurately. Furthermore, Figure \ref{fig:train_efficiency} shows that \ourmethod{} also significantly reduces the training time and sample usage, which validates its superiority in terms of data efficiency.

%using partial source samples
% \begin{table}[htbp]
% \centering
% \caption{Training Efficiency Until Converges Test.}
% % \caption{Mean Data Used on DomainNet.(×10$^{6}$)}
% \resizebox{0.48\textwidth}{!}{
% \begin{tabular}{@{}l cccccc c@{}}
% \toprule
% \textbf{Method} & \multicolumn{7}{c}{\textbf{DomainNet}}\\ 
% \cmidrule(lr){2-8} 
% & Clipart$\downarrow$ & Info$\downarrow$ & Paint$\downarrow$ & Quick$\downarrow$ & Photo$\downarrow$ &Sketch$\downarrow$ & \textbf{Avg$\downarrow$}\\ \midrule
% % \midrule
% \textit{Avg Used Data Per Epoch(×10$^{5}$):} &&&&&&\\
% % \textit{Supervised-10-shots Source-Ablation:} &&&&&\\
% % H-ensemble & - & - & - & - & - & - & -\\
% % MCW & - & - & - & - & - & - & -\\
% % WADN & - & - & - & - & - & - & -\\
% % MADA & - & - & - & - & - & - & -\\
% % All-Source  & 2.33 & 1.37 & 1.45 & 4.12 & 1.40 &1.88 & 2.09\\
% % \ourmethod{} (Ours)& \textbf{1.30} & \textbf{1.07} & \textbf{0.96} & \textbf{0.89} & \textbf{1.33} & \textbf{1.04} &\textbf{1.10}\\
% All-Source(10shot) & 4.35 & 4.32 & 4.15 & 3.35 &3.35 & 4.18 & 3.95\\
% \ourmethod{} (Ours-10shot)& \textbf{3.09} & \textbf{2.59} & \textbf{2.45} & \textbf{0.89} & \textbf{1.74} & \textbf{2.14} &\textbf{2.15}\\
% All-Source(mean shot)  & 2.33 & 1.37 & 1.45 & 4.12 & 1.40 &1.88 & 2.09\\
% \ourmethod{} (Ours)& \textbf{1.30} & \textbf{1.07} & \textbf{0.96} & \textbf{0.89} & \textbf{1.33} & \textbf{1.04} &\textbf{1.10}\\
% \midrule
% \textit{Training Time(s):} &&&&&&\\
% % H-ensemble & - & - & - & - & - & - & -\\
% % MCW & - & - & - & - & - & - & -\\
% % WADN & - & - & - & - & - & - & -\\
% % MADA & - & - & - & - & - & - & -\\
% % All-Source  & 2.33 & 1.37 & 1.45 & 4.12 & 1.40 &1.88 & 2.09\\
% % \ourmethod{} (Ours)& \textbf{1.30} & \textbf{1.07} & \textbf{0.96} & \textbf{0.89} & \textbf{1.33} & \textbf{1.04} &\textbf{1.10}\\
% All-Source(10shot)  & \textbf{4091} & \textbf{4805} & \textbf{4684} & 122139 & 12674 &\textbf{15390} & 27297\\
% \ourmethod{} (Ours)& 17923 & 6742 & 7944 & \textbf{13769} & \textbf{10610} & 15520 &\textbf{12085}\\


% All-Source(mean shot)  & 36121 & \textbf{5112} & \textbf{5088} & 24817 & \textbf{4713} &\textbf{6163} & 13669\\
% \ourmethod{} (Ours)& \textbf{7569} & 5627 & 5445 & \textbf{5684} & 11995 & 6456 &\textbf{7129}\\

% \bottomrule
% \end{tabular}
% }
% \label{tab:LoRA}
% \end{table}






% \textbf{Influences of Quantity and Diversity of Source Data.} From the Source-Ablation part of Table~\ref{tab:major}, it is evident that the Target-Only method relying solely on limited target samples, independent of source data, leads to the worst performance. Incorporating single-source data improves performance across different domains, with further enhancements observed when diverse types of source data are utilized. This demonstrates that both the quantity and diversity of source data positively impact performance to a significant extent. 
% This finding demonstrates the advantages of multi-source transfer learning over single-source transfer learning.

% it is observed that only rely on limited target samples being independent of source data would hit a worst performance. And with help of single source data, performance on different domain would get improved, and getting the better one while using different types of source data. It illustrates that the large number and the variety of source data make positive impact on performance to some extent. 
% 3.对比source ablation情况：从none的效果和all对比发现，使用source数据是有益于提高目标任务的表现的。并且从singlesource和allsource对比发现，单源所能提供的有效信息过于单一，并没有多源所能提供的有效信息多。
%
% 这里也要画个表
% 数据使用量的分析（epoch等各种考虑哪个有优势画哪个）+计算时间分析 efficient 
% \textbf{Quantity with Quality Over Only Quantity.} From the fourth and fifth row of the Source-Ablation part of Table~\ref{tab:major}, it shows that the \allsource{} fails to outperform our method, which leverages only a subset of data selected from all based on model preference. This indicates that excessive use of source data may shift the statistical bias of the target task towards source. Furthermore, table [] reveals that our method not only achieves better performance but also significantly reduces the training time required for the target task, making it more efficient overall.
% 4.对比all和ours情况：从大表上可以得到all使用了所有源任务的数据量的表现并没有ours使用了模型preference的部分数据量效果好，意味着过多的源任务数据量的使用会偏移目标任务bias。并且从数据使用量和计算时间分析发现，我们的方法除了表现效果更好外，训练目标任务的所需时间大大减少，更加efficient。


\textbf{Few-Shot Labels, Big Gains.} We make a comparison of the results of unsupervised and supervised methods. While other conditions remain the same, 
%except for the number of target samples used, 
Table \ref{tab:major} demonstrates that even if unsupervised methods like MSFDA and M3SDA take all the target data into account (up to 1.3×$10^5$ samples on Real domain of \texttt{DomainNet}), their performance still falls short compared to the supervised methods, which rely on only a limited number of samples (3450 samples). This illustrates the importance of having supervised information in multi-source transfer learning.\\
% 1.对比unsupervised方法：它们的shot需求太高。它们的方法使用了all-shots，虽然是没有label的目标任务数据，但是使用了targetdomain的所有数据（带入相比最夸张的domain的使用数据量），而在supervised的all的方法只使用了每类10shot的情况（目标任务使用数据量情况）只用到了少量的带有标签的shot，效果就已经超越了大部分unsupervised的情况。
% 需不需要只是无监督来个fewshot然后情况很糟

\subsection{Static vs. Dynamic Transfer Quantity} 
In our proposed Algorithm \ref{alg:ours_algorithm}, we employ a ‘‘Dynamic’’ strategy that dynamically determines the optimal transfer quantities and updates the resampled dataset during the joint training of target task. To validate the effectiveness of this strategy, 
we conducted comparative experiments using the ‘‘Static-\(*\)’’ methods. ‘‘Static-$*$’’ methods first simulate the distribution of target on target dataset only, and different types of Static such as ‘‘Under, Exact and Over’’ stands for different fitting levels. In ‘‘Static-\(*\)’’ methods, we only compute the optimal transfer quantity once to make the resampled dataset, and evaluated on it until target model converges. The results on Table \ref{tab:static_and_dynamic} demonstrate \ourmethod{} using dynamic transfer quantity achieved the best performance.
\begin{table}[htbp]
\centering
\caption{Static vs. Dynamic Transfer Quantity in \ourmethod{} on Office-Home. Arrows will transfer from the rest tasks.}
% \caption{\textbf{Dynamic \ourmethod{} Bias Ablation on Office-Home.} The arrows indicate transfering from the rest tasks.}
\resizebox{0.4\textwidth}{!}{
\begin{tabular}{l c ccccc}
\toprule
\multirow{2.5}{*}{\textbf{Method}} & \multirow{2.5}{*}{\textbf{Backbone}} & 
% \multirow{2.5}{*}{\textbf{All samples}} & 
\multicolumn{5}{c}{\textbf{Office-Home}}\\ 
\cmidrule(lr){3-7} 
&& $\to$Ar & $\to$Cl & $\to$Pr & $\to$Rw & Avg\\ 
\midrule
% \midrule
% \textit{Source-combine:} &&&&&&&&&&&&\\
% \textit{Supervised-10-shots Source-Ablation:} &&&&&\\
% None-Source(Vitb)  & 59.8 & 42.2 & 69.5 & 72.0 & 60.9 \\ 
% Single-Source-avg(Vitb)& 72.2  & 59.9 & 82.6 & 81.0 & 73.9 \\
% Single-Source-best(Vitb) & 74.4  & 61.8 & 84.9 & 81.9 & 75.8 \\ 
% \multicolumn{7}{l}{\textit{\textbf{Following settings of WADN:}}} \\
% 10604 9045 8991 9054
\multicolumn{7}{l}{\textit{\textbf{Supervised-10-shots:}}} \\
Static-Under & ViT-S & \underline{77.0} & \underline{62.3} & 84.9 & \underline{84.5} & \underline{77.2}\\
% 486 7139 8290 7948(0.79)
Static-Exact & ViT-S & 46.0 & 59.8  & \underline{85.1}  & 83.7  & 68.7\\
% 3730 
% 9792 5474 2351 2125
Static-Over & ViT-S & 76.8 & 61.9 & 78.6 & 68.6 & 71.5\\
% 3532
Dynamic & ViT-S & \textbf{78.1} & \textbf{64.5} & \textbf{85.2} & \textbf{84.9}  & \textbf{78.2} \\
\bottomrule
\end{tabular}
}
\label{tab:static_and_dynamic}
\vspace{-3mm} 
\end{table}

\subsection{Generality across Different Shot Settings}
%由上述的理论分析可知，我们的方法并没有受限于目标任务的使用数据量，我们紧接着还继续探究了在目标任务的shot继续增加时我们的方法的表现情况，通过上图可以发现我们的方法在目标任务shot继续增加的情况下还可以稳步比其他方法效果更好，体现了我们方法在数据使用量上的的generative，更多的情况看附录。
As discussed in the theoretical analysis of Theorem~\ref{thm:one_source}, our theoretical framework is applicable to any quantity of target samples. Therefore, \ourmethod{} exhibits shot generality, enabling it to avoid negative transfer across different shot settings.
To validate this, we increase the number of shots from 5 to 100 across methods including \allsource{}, Target-Only, and \ourmethod{}. 
As shown in Figure \ref{fig:all_increase_shots}, experimental results demonstrate that \ourmethod{} consistently outperforms other approaches across all shot settings. This highlights the generality and scalability of \ourmethod{} in terms of data utilization. %Further results and details are provided in the appendix.
%%% real_figure_1_16 !!!!
% \begin{figure}[htbp]
%     \centering
%     % 第一排的两个子图
%     \begin{minipage}[t]{0.45\linewidth} % 子图宽度为 45%
%         \centering
%         \includegraphics[width=0.8\linewidth]{hgb_1_30_figure/Idomain_1_30.pdf}\\ % 调整图片宽度
%         \textbf{(a)} Infograph % 手动添加子图标题
%     \end{minipage}
%     % \hfill
%     \hspace{-0.5cm}
%     \begin{minipage}[t]{0.45\linewidth}
%         \centering
%         \includegraphics[width=0.8\linewidth]{hgb_1_30_figure/Pdomain_1_30.pdf}\\
%         \textbf{(b)} Painting
%     \end{minipage}
%     \vspace{0.5em} % 第一排与第二排之间的间距

%     % 第二排的两个子图
%     \begin{minipage}[t]{0.45\linewidth}
%         \centering
%         \includegraphics[width=0.8\linewidth]{hgb_1_30_figure/Qdomain_1_30.pdf}\\
%         \textbf{(c)} Quickdraw
%     \end{minipage}
%     \hspace{-0.59cm}
%     \begin{minipage}[t]{0.45\linewidth}
%         \centering
%         \includegraphics[width=0.8\linewidth]{hgb_1_30_figure/Rdomain_1_30.pdf}\\
%         \textbf{(d)} Real
%     \end{minipage}

%     % \caption{Effectiveness with Increasing Target Data}
%     \caption{Performance comparison with increasing target shots up to 100 per class on DomainNet dataset (I, P, Q and R domains). \ourmethod{} (\textcolor{blue}{blue}) outperforms other methods.}
%     \label{fig:all_increase_shots}
% \end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{hgb_1_30_figure/ppt_increase_shot.pdf}
    \caption{Performance comparison with increasing target shots up to 100 per class on DomainNet dataset (I, P, Q and R domains). \ourmethod{} (\textcolor{blue}{blue}) outperforms other methods.}
    \label{fig:all_increase_shots}
    % \vspace{-3cm}
\end{figure}

% And from figure[], our experiments of evaluating the effectiveness of our method on the large shots have proved that our method continues to outperform other approaches steadily with target shots increasing. This demonstrates the generative capability of our method in terms of data utilization. Additional results and details can be found in the appendix.
% To further investigate this, we conducted experiments to evaluate the performance of our method as the number of shots in the target task increases. As shown in the figure, our method continues to outperform other approaches steadily, even as the number of target task shots increases. This demonstrates the generative capability of our method in terms of data utilization. Additional results and details can be found in the appendix.
\subsection{Data Efficiency Test} 
\label{section:data_efficient}
In this section, we demonstrate the advantage of \ourmethod{} in terms of data efficiency.
Specifically, we conduct experiments with MADA, \allsource{}, and \ourmethod{} across different shot settings, and for each shot setting, we accumulate the total sample used and time consumed until the highest accuracy is reached.
% We visualize the results of the average of all shot setting
% To better visualize the results, we show the average data used and time consumed of all shot setting on Figure \ref{fig:train_efficiency}, which demonstrates that \ourmethod{} requires significantly less data and training time while maintaining competitive performance. 
To better visualize the results, 
we present the average sample usage and training time across all shot settings in Figure~\ref{fig:train_efficiency}. %which demonstrates that \ourmethod{} requires significantly less data and training time while maintaining competitive performance.
To be specific, \ourmethod{} reduces the average training time by $35.19\%$ and the average sample usage by $47.85\%$ on \texttt{DomainNet}, compared to the \allsource{} method.




% Specifically, we accumulate all the data used and time consumed until the highest accuracy is reached for each shot in \allsource{} and \ourmethod{} strategies. 
% To better visualize the results we show the average of all shots on Figure \ref{fig:train_efficiency}, which demonstrates that \ourmethod{} requires significantly less data and training time while maintaining competitive performance.




% In this section, we demonstrate the advantage of \ourmethod{} in terms of data efficiency.
% Specifically, we accumulate all the data used and time consumed until the highest accuracy is reached for each shot in \allsource{} and \ourmethod{} strategies. To better visualize the results we show the average of all shots on Figure \ref{fig:train_efficiency}, which demonstrates that \ourmethod{} requires significantly less data and training time while maintaining competitive performance.  
% and more details for each shot are provided in the appendix.
% \definecolor{MADAvits}{cmyk}{0.918, 0, 0}
% \definecolor{MADAres50}{cmyk}{0, 0.918 ,0.918}
% \definecolor{allsources}{cmyk}{0.290, 0.486, 0.192}
% \definecolor{ours}{cmyk}{0, 0, 0.918}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{hgb_1_30_figure/data_1_30.pdf}
    \caption{Data efficiency comparison of average sample usage and training time on \texttt{DomainNet} dataset, the left vertical axis represents the amount of sample usage, with \textcolor{allsources}{green} bars indicating \allsource{} data counts, \textcolor{ours}{blue} bars about \ourmethod{}, \textcolor{MADAvits}{red} bars about MADA(ViT-S) and \textcolor{MADAres50}{azury} bars about MADA(Res50), while the right \textcolor{orange}{orange} vertical axis and lines represent training time. }
    % All the results in the figure are scaled by the natural logarithm.
    % , shown by the dashed yellow line for \allsource{} and the solid orange line for \ourmethod{}.}
    \label{fig:train_efficiency}
\end{figure}


\subsection{
Compatibility to Parameter-Efficient Training}
% partial parameters finetune efficient
% Applicability to Larger Model Architectures
% LoRA（Low-Rank Adaptation）是一种针对大模型的低秩适应方法，它冻结预训练模型权重，并在 Transformer 架构的每一层注入可训练的秩分解矩阵，大大减少了下游任务的可训练参数数量，在保证模型质量的同时提高了训练效率且不增加推理延迟。为了测试我们方法在大模型下的适用性和高效性，我们使用添加了LoRA框架的vit-b模型作为新的backbone，与上述一样的setting在OfficeHome数据集上进行测试，结果如下表所示可以看出我们的方法在大模型情况下也有效。

% To evaluate the applicability with larger models, we used a ViT-base model (three times larger than ViT-small) integrated with the LoRA framework as the backbone. 

To evaluate the applicability with parameter-efficient training, we used a ViT-Base model~\cite{dosovitskiy2020vit_vitb} integrated with the LoRA framework \cite{hu2021lora} as the backbone. 
%LoRA \cite{hu2021lora} is a framework designed for large models, which freezes the original model weights and injects trainable low-rank decomposition matrices into each Transformer architecture. 
This approach significantly reduces the number of trainable parameters for downstream tasks while ensuring model quality and improving training efficiency. 
In the experiments, we consider the trainable low-rank matrices and the classification head as the parametric model in our theoretical framework, while treating the remaining parameters as constants. Other experimental settings are the same as default.
Experiments were conducted on the \texttt{Office-Home} dataset.
%under the same settings as details described above. 
The results of Table~\ref{tab:LoRA} in Appendix demonstrate that our method remains effective.
% even with larger model architectures.
% 0.5978
% 0.4220
% 0.6953
% 0.7199
% 0.8108
% 0.6596
% 0.8802
% 0.8924
% 0.8151
% 0.6797
% 0.8919
% 0.9031

% \subsection{Tendency Towards Parameter-Similar Model}
% \subsection{Observation of the domains poverties}
\subsection{Analysis on Domain-specific Transfer Quantity }
% Preference for Parameter-Similar Models
% For understanding the domain preferacnce of \ourmethod{}, we compute the importance of source domains for each target domain. For each source domain we first count all the samples selected from this source domain until target model converges under 10-shot condition, and given` that the quantities of available for selection samples from different domains differ significantly, we divide the counts by these quantities, and we get the final importance about domain preference after we compute the importance of these devidance results.
% For understanding the domain preferacnce of \ourmethod{}, 
% We compute the importance of source domains to represent the domain preference of \ourmethod{} for each target domain by the number of selected samples.

% We visualize the source domain preference of \ourmethod{} for each target domain based on the proportion of selected samples. As shown in Figure \ref{fig:domain_choosing}(b), when the target domain is Clipart, \ourmethod{} mainly leverages samples from Real, Painting and Sketch, and Quickdraw contributes minimally to any target domain, which aligns with the findings in \cite{peng2019moment_M3SDA}.
To understand the domain preference of \ourmethod{}, we visualize the proportion of each source in the selected samples for each target domain. As shown in Figure~\ref{fig:domain_choosing}(b), when the target domain is Clipart, \ourmethod{} primarily leverages samples from Real, Painting, and Sketch. In addition, Quickdraw contributes minimally to any target domain. These observations align with the findings in \cite{peng2019moment_M3SDA}. To further clarify the selection process of \ourmethod{} during training, we visualize it in Figure \ref{fig:domain_choosing}(a). 
We observe that in the \texttt{Office-Home} dataset, Clipart initially selects all source domains but later focuses on Art and Real World. In the \texttt{DomainNet} dataset, Sketch predominantly selects Clipart, Painting, and Real throughout the training process.


%clarify


% % For understanding the domain preferacnce of \ourmethod{}, 
% We compute the importance of source domains to represent the domain preference of \ourmethod{} for each target domain by the number of selected samples.
% From the visualized domain preference of \texttt{DomainNet} in Figure \ref{fig:domain_choosing}(b) , we can find that when the target domain is Clipart, \ourmethod{} mainly leverages the data from Real, since they are more semantically similar, and Quickdraw does not help too much for Clipart, which is also observed by \cite{saito2018maximum_MCD}. Moreover, Quickdraw is not very helpful for any kind of other domains, the same obeservation with \cite{peng2019moment_M3SDA}. To clarify the selection process of \ourmethod{} during training, we visualize it in Figure \ref{fig:domain_choosing}(a). We observe that in the \texttt{Office-Home} dataset, Clipart initially selects all source domains but later focuses on Art and RealWorld. In the \texttt{DomainNet} dataset, Sketch predominantly selects Clipart, Painting, and Real throughout.










% For each source domain, we count the samples selected from it until the target model converges under the 10-shot condition. Since the quantities of available samples varies significantly across domains, we normalize the counts by these quantities. The final domain preference is then determined by computing the importance of these normalized values.
% From the visualized domain preference of \texttt{DomainNet} in Figure \ref{fig:domain_choosing}(b) , we can find that when the target domain is Clipart, \ourmethod{} mainly leverages the data from Real, since they are more semantically similar, and Quickdraw does not help too much for Clipart, which is also observed by \cite{saito2018maximum_MCD}. Moreover, Quickdraw is not very helpful for any kind of other domains, the same obeservation with \cite{peng2019moment_M3SDA}. 


% For example, when the target domain is SVHN,
% WADN mainly leverages the information from SYNTH,
% since they are more semantically similar, and MNIST does
% not help too much for SVHN, which is also observed by
% (Ganin et al., 2016). Besides, Fig. 4(b) visualizes the evolution of λ between WADN and recent principled approach
% DARN (Wen et al., 2020), which utilized the P(x) information and dynamic updating to find the similar domains.
% Compared with WADN, λ in DARN is unstable during
% updating under drifted label distribution
% 在我们方法的理论描述中，对源任务数据量的确定是与源任务和目标任务模型之间的距离息息相关的[]。如下图所示我们利用欧氏距离和cosine距离刻画了我们的方法训练过程中目标任务与其他源任务的距离。结合如下图所示的该训练过程中我们的方法所选取的其他源任务的数据量的结果，可以发现我们的方法更倾向于从模型距离更近的domain取样本，这也意味着模型距离和domain之间的距离存在一定的相关性。
% As the theoretical analysis concluded, the determination of the volume of source data is closely related to the distance between the source and target domain []. To visualize the relation between model and domain, we quantify the distances between the target model and various source models using Euclidean and cosine distance, and the selected volume of source data during the training process as illustrated in the figure [].
%  It is apparent that our method preferentially samples data from domains with smaller model distances. More importantly, this observation indicates a certain correlation between model distance and domain similarity.

% \begin{figure}[htbp]
%     \centering
%     % 左侧：两张图片垂直排列
%     \begin{minipage}{0.45\linewidth}
%         \centering
%         \begin{minipage}{\linewidth}
%             \centering
%             \includegraphics[width=\linewidth]{hgb_section/Officehomeblue_no_x.pdf}
%             % \caption{Caption for first image}
%             \label{fig:first-image}
%         \end{minipage}
%         \vspace{0.5cm} % 调整垂直间距
%         \begin{minipage}{\linewidth}
%             \centering
%             \includegraphics[width=\linewidth]{hgb_section/DomainNet_oranges_no_title.pdf}
%             \caption{Domain Selection}
%             \label{fig:second-image}
%         \end{minipage}
%     \end{minipage}
%     \hfill
%     % 右侧：单独一张图片
%     \begin{minipage}{0.45\linewidth}
%         \centering
%         \includegraphics[width=\linewidth]{hgb_section/Regularized_Samples_Values_tgtpcls10.pdf}
%         \caption{Caption for third image}
%         \label{fig:third-image}
%     \end{minipage}
% \end{figure}


%%%% real_figure!!!! 1_16
\begin{figure}[htbp]
    \centering
    % 左侧：两张图片垂直排列
    \begin{minipage}{0.45\linewidth}
        \centering
        % 第一张图片
        \includegraphics[width=\linewidth]{hgb_1_30_figure/ep_oh_1_30.pdf}
        % \vspace{0.5cm} % 调整图片与下方的间距
        % 第二张图片
        \includegraphics[width=\linewidth]{hgb_1_30_figure/ep_do_select_1_30.pdf}
        % \caption{Domain Selection}
        % \vspace{-0.7cm}
        \textbf{(a)} Domain Selection
        % \label{fig:second-image}
    \end{minipage}
    \hfill
    % 右侧：单独一张图片
    \begin{minipage}{0.45\linewidth}
        \centering
        \includegraphics[width=\linewidth]{hgb_1_30_figure/all_heap_1_30.pdf}
        % \caption{Caption for third image}
        \textbf{(b)} Domain preference
        % \label{fig:third-image}
    \end{minipage}
    
    \caption{Visualization of domain-specific transfer quantity under 10-shot setting. (a) Domain selection during training epochs (from left to right), where the \textcolor{blue}{blue} upper part represents
    the selection of target domain Clipart on \texttt{Office-Home}, and the \textcolor{orange}{orange} lower part represents
    the selection of target domain Sketch on \texttt{DomainNet}. Darker colors indicate stronger tendencies throughout the training process. (b) Source domain preferences of different target domains on \texttt{DomainNet}. Each row corresponds to a target domain while each column represents a source domain.}
    \label{fig:domain_choosing}
\end{figure}

%%%, highlighting the non-uniform and non-symmetric relationships between tasks



% distance:
% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=1\linewidth]{hgb_section/Cosine_Distance_Metrics_10.pdf}
%     \caption{Cosine distance}
%     \label{fig:enter-label}
% \end{figure}
% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=1\linewidth]{hgb_section/Euclidean_Distance_Metrics_10.pdf}
%     \caption{Euclidean distance}
%     \label{fig:enter-label}
% \end{figure}
% alpha:
% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=1\linewidth]{hgb_section/alpha_multi_bars_perepoch_10.pdf}
%     \caption{Alpha multibars}
%     \label{fig:enter-label}
% \end{figure}
% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=1\linewidth]{hgb_section/alpha_multi_onebar_perepoch_10.pdf}
%     \caption{Alpha onebar}
%     \label{fig:enter-label}
% \end{figure}
% using samples:
% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=1\linewidth]{hgb_section/multi_bar_perepoch_10.pdf}
%     \caption{Multibar usingsamples}
%     \label{fig:enter-label}
% \end{figure}
% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=1\linewidth]{hgb_section/each_domain_all_using_samples_10.pdf}
%     \caption{All epoch usingsamples}
%     \label{fig:enter-label}
% \end{figure}
 % As concluded in the theoretical analysis, the volume of source data is closely related to the distance between the source and target domains []. As shown in Figure [], we quantify the distances between the target model and various source models using both Euclidean and cosine distances, as well as the selected volume of source data during the training process. It is apparent that our approach preferentially samples data from domains with smaller model distances. This observation also indicates a potential correlation between model distance and domain similarity.






% \subsection{Independence from Task Types}
% Capability of Tasks Adaptation  \ to Diverse Tasks
% 不仅在classification task上能work，在 segmentation task上也可以work