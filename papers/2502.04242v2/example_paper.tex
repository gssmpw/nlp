%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

\newcommand{\ourmethod}{\text{OTQMS}}
\newcommand{\allsource}{\text{AllSources $\cup$ Target}}


% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} 
\usepackage{adjustbox}
% for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2025}

% For preprint,zqy write a version
\usepackage[preprintzqy]{icml2025}

% For theorems and such
\usepackage{amssymb}%amssymb 包应该在其他相关包之前加载，尤其是 amsmath
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{bbding}
\usepackage{float}
% \restylefloat{table}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

% hgb add↓
\newcommand{\mycomment}[1]{\hspace{\fill} \textcolor{black}{// #1}}
\makeatletter
\newcommand{\FORwithcomment}[2]{\FOR{#1} \hspace{\fill} \textcolor{black}{// #2}}
\makeatother
\usepackage{subcaption}
\usepackage{pifont}
% \usepackage{xcolor}
% \usepackage{algorithm}
% \usepackage{algorithmic}
% \usepackage{algpseudocode}
% \usepackage{tikz}
% \usepackage{setspace} 
\usepackage{booktabs}
\usepackage{float}
\usepackage{graphicx}
\usepackage{makecell}
% \usepackage[table,xcdraw,cmyk]{xcolor}
% \usepackage[cmyk]{xcolor}
\usepackage{tikz}
\usepackage{multirow}

\definecolor{MADAvits}{rgb}{0.918, 0, 0}
\definecolor{MADAres50}{rgb}{0, 0.918 ,0.918}
\definecolor{allsources}{rgb}{0.290, 0.486, 0.192}
\definecolor{ours}{rgb}{0, 0, 0.918}
% hgb add↑

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}


\input{iddef}
% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
%%%注意注意注意注意
% \icmltitlerunning{Submission and Formatting Instructions for ICML 2025}
\icmltitlerunning{Preprint. Under review.}


\begin{document}

%%% hgb add↓
\definecolor{darkgreen}{RGB}{0,100,0}  % 定义深绿色 (DarkGreen)  
%%% hgb add↑



\twocolumn[
%\icmltitle{Do We Really Need to Use All Source Samples \\in Multi-Source Transfer Learning?
%}
\icmltitle{
%Finding optimal transfer quantities for efficient multi-source transfer learning via Cramer-Rou bound
%How many samples should we use in   multi-source transfer learning? A mathematical model and practical algorithm 
%Data Efficient Multi-source Transfer Learning 
%\\
%or
%\\ 
% A Mathematical Framework for Data Efficient Multi-Source Transfer Learning 
% via Cram\'er-Rao Bound
%%%%%%%%%%%%%%%%%%%%%%%%%清越根据李阳老师改的的题目%%%%%%%%%%%%%%%%%%%%%%
A Theoretical Framework for Data Efficient Multi-Source Transfer Learning\\
Based on Cram\'er-Rao Bound \\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%清越一个题目%%%%%%%%%%%%%%%%%%%%%%%%
% or\\
% More is Not Always Better: Data Efficient Multi-source Transfer Learning
}


% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Qingyue Zhang}{equal,thusz}
\icmlauthor{Haohao Fu}{equal,thusz}
\icmlauthor{Guanbo Huang}{equal,thusz}
\icmlauthor{Yaoyuan Liang}{thusz}
\icmlauthor{Chang Chu}{thusz}
\icmlauthor{Tianren Peng}{thusz}
\icmlauthor{Yanru Wu}{thusz}
\icmlauthor{Qi Li}{thusz}
\icmlauthor{Yang Li}{thusz}
\icmlauthor{Shao-Lun Huang}{thusz}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}
\icmlaffiliation{thusz}{Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China}
% \icmlaffiliation{yyy}{Department of XXX, University of YYY, Location, Country}
% \icmlaffiliation{comp}{Company Name, Location, Country}
% \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

\icmlcorrespondingauthor{Shao-Lun Huang}{twn2gold@gmail.com}
\icmlcorrespondingauthor{Yang Li}{yangli@sz.tsinghua.edu.cn}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
% Multi-source transfer learning provides an effective solution to data scarcity in real-world  supervised learning scenarios, by leveraging multiple source tasks.
% % to enhance the learning of the target task
% Previous work attempts to improve data efficiency in multi-source transfer learning problem by sample re-weighting or curriculum learning, however, they are inefficient they still require iterating through all samples in sources in each epoch. %While various sample reweighting or selection  methods attempt to tackle this challenge,   
% There have not been a robust mathematical framework  that answers the question: what is the optimal quantity of source samples needed from each source task to jointly train the target model? 
% In this work, we propose a new generalization error measure that aligns more closely with cross-entropy loss, and we analyze it based on the Cram\'er-Rau Bound. The measure is then used to efficiently determine the optimal transfer quantity for each source task given model parameters. Additionally, we develop a practical 
%  and data-efficient algorithm \ourmethod{} to implement our theoretical results for  training   deep  multi-source transfer learning models  with dynamic source transfer quantity. Our model has been tested on diverse modern architectures  and three real-world benchmark datasets. We find that our proposed algorithm significantly outperforms state-of-the-art approaches  in both accuracy and data efficiency. Our analysis also yields practical insights on when to use transfer learning in favor of joint training. 
 
% Multi-source transfer learning provides an effective solution to data scarcity by leveraging multiple source tasks to enhance the learning of the target task. However, existing theoretical frameworks have poor correspondence with machine learning training processes and neglect cases where only partial samples from source tasks are utilized. 
%In this paper, we introduce an efficient transfer learning framework with task generality. Specifically, we propose a generalization error measure that aligns more closely with cross-entropy loss and present a method to determine the optimal transfer quantity for each source task. Additionally, we develop a practical 
%  and data-efficient algorithm \ourmethod{} to implement our theoretical results in the training of deep neural networks for multi-source transfer learning tasks. Extensive experiments show that our proposed method significantly outperforms state-of-the-art approaches on two real-world datasets. Supplementary experiments further validate the effectiveness and generality of our algorithm design.


%↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓2025_1_24 version3↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓%
% Multi-source transfer learning provides an effective solution to data scarcity in real-world  supervised learning scenarios by leveraging multiple source tasks.
% In this field, prior works attempt to improve data efficiency by sample re-weighting or curriculum learning, but they are still inefficient because they require iterating through all samples in sources in each epoch. 
% There have not been a robust mathematical framework  that answers the question: what is the optimal quantity of source samples needed from each source task to jointly train the target model? 
% In this work, we propose a new generalization error measure that aligns more closely with cross-entropy loss, and we analyze it based on the Cram\'er-Rau Bound. 
% The measure is then used to efficiently determine the optimal transfer quantity for each source task given model parameters. 
% Additionally, we develop a practical and data-efficient algorithm \ourmethod{} to implement our theoretical results for  training   deep  multi-source transfer learning models  with dynamic source transfer quantity. 
% Our model has been tested on diverse modern architectures  and three real-world benchmark datasets. 
% We find that our proposed algorithm significantly outperforms state-of-the-art approaches  in both accuracy and data efficiency. 
% Our analysis also yields practical insights on when to use transfer learning in favor of joint training. 
%↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑2025_1_24 version3↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑%

% Multi-source transfer learning provides an effective solution to data scarcity in real-world supervised learning scenarios by leveraging multiple source tasks.
% In this field, existing works 
% use methods including sample re-weighting and feature alignment, 
% but they are still inefficient considering that they require using all samples from sources in training.
% To address this, we propose 
% %There have not been
% a robust mathematical framework that answers the question: what is the optimal quantity of source samples needed from each source task to jointly train the target model? 
% %In this work, we propose a new 
% Specifically, we introduce a generalization error measure that aligns with cross-entropy loss  
% % , and we analyze it based on the Cram\'er-Rau Bound
%  to efficiently determine the optimal transfer quantity for each source task given model parameters. 
% Additionally, we develop an architecture-agnostic and data-efficient algorithm \ourmethod{} to implement our theoretical results 
% for training deep multi-source transfer learning models.  
% Experimental studies on diverse  architectures and two real-world benchmark datasets show that our proposed algorithm significantly outperforms state-of-the-art approaches in both accuracy and data efficiency. 

Multi-source transfer learning provides an effective solution to data scarcity in real-world supervised learning scenarios by leveraging multiple source tasks.
In this field, existing works typically use all available samples from sources in training, which constrains their training efficiency and may lead to suboptimal results.
To address this, we propose 
a theoretical framework that answers the question: what is the optimal quantity of source samples needed from each source task to jointly train the target model? 
Specifically, we introduce a generalization error measure that aligns with cross-entropy loss, and minimize it based on the Cram\'er-Rao Bound
to 
%efficiently
determine the optimal transfer quantity for each source task.
%given model parameters. 
Additionally, we develop an architecture-agnostic and data-efficient algorithm \ourmethod{} to implement our theoretical results 
for training deep multi-source transfer learning models.  
Experimental studies on diverse architectures and two real-world benchmark datasets show that our proposed algorithm significantly outperforms state-of-the-art approaches in both accuracy and data efficiency. The code and supplementary materials are available in \url{https://anonymous.4open.science/r/Materials}.


% This document provides a basic paper template and submission guidelines.
% Abstracts must be a single paragraph, ideally between 4--6 sentences long.
% Gross violations will trigger corrections at the camera-ready phase.
\end{abstract}
%文中名词对照
%transfer quantity 迁移数量
\section{Introduction}
\label{Introduction}
Nowadays, various machine learning algorithms have achieved remarkable success by leveraging large-scale labeled training data. However, in many practical scenarios, the limited availability of labeled data presents a significant challenge, where transfer learning emerges as an effective solution \cite{zhao2020review}. Transfer learning aims to leverage knowledge from tasks with abundant data or being well-trained, known as the source tasks, to improve the performance of a new learning task, known as the target task. Given its numerous applications, transfer learning has gained wide
popularity and seen success in a variety of fields, such as computer vision \cite{wang2018deep}, natural language processing \cite{sung2022vl}, recommendation system \cite{fu2024exploring} and anomaly detection \cite{vincent2020transfer}. Traditionally, transfer learning has focused on the transfer between a single source task and a target task. However, there is a growing emphasis on multi-source transfer learning, which leverages multiple source tasks to enhance the training of the target task \cite{sun2015survey}.
\begin{figure}[t]
    \centering    \includegraphics[width=0.85\linewidth]{hgb_1_30_figure/teaser_1_30.pdf}
    \caption{\textbf{More source samples does not always mean better performance.} Incorporating all source samples may bring negative impact, 
    which is illustrated by the comparison of 
    two strategies, using target with all source samples (\textcolor{blue}{blue}) and using target only (\textcolor{red}{red}), 
    evaluated on the equally divided 5-task CIFAR10 dataset. Theoretically, although incorporating more source samples reduces model variance by expanding the training data, the discrepancy between the source and target tasks introduces additional bias.} 
    \label{fig:teaser-cifar10}
    \vspace{-6mm} 
\end{figure}

\begin{table*}[t]
\setlength{\tabcolsep}{4pt}
    \renewcommand{\arraystretch}{0.76}
    \centering
    \caption{\textbf{Comparison across matching-based transfer learning method,} based on whether they are tailored to multi-sources, have task generality, have shot generality, and require target labels. The `\Checkmark' represents obtaining the corresponding aspects, while `\XSolidBrush' the opposite. Task generality denotes the ability to handle various target task types, and shot generality denotes the ability to avoid negative transfer in different target sample quantity settings including few-shot and non-few-shot.}
    \begin{tabular}{c c c c c}
        \toprule
         \textbf{Method} &  \textbf{Multi-Source}& \textbf{Task Generality}  & \textbf{Shot Generality} & \textbf{Target Label} \\
         \midrule
         % MTL \citep[]{sun2019meta} &  \XSolidBrush &  \Checkmark & \XSolidBrush & Few-shot \\
         MCW \citep[]{lee2019learning_MCW} &  \Checkmark & \XSolidBrush & \XSolidBrush & Supervised \\
         Leep \citep[]{nguyen2020leep} &  \XSolidBrush &  \Checkmark & \Checkmark & Supervised \\
         Tong \citep[]{tong2021mathematical} &  \Checkmark &  \XSolidBrush & \Checkmark &Supervised \\
         DATE \citep[]{han2023discriminability_DATE} & \Checkmark   &  \Checkmark & \Checkmark & Unsupervised \\
         H-ensemble \citep[]{wu2024h_Hensemble}  &  \Checkmark & \XSolidBrush & \XSolidBrush & Supervised \\ 
         \ourmethod{} (Ours)   &  \Checkmark &  \Checkmark &  \Checkmark & Supervised \\
         \bottomrule
    \end{tabular}
    \label{tab:comparison}
\end{table*}


% \begin{table*}[t]
% \setlength{\tabcolsep}{4pt}
%     \renewcommand{\arraystretch}{1.2}
%     \centering
%     \caption{\textbf{Comparison across related method,} based on whether they are tailored to multi-sources, have task generality, have shot generality, and require none or few-shot target labels. The `\Checkmark' represents obtaining the corresponding aspects, while `\XSolidBrush' the opposite. Task generality denotes the ability to handle the transfer learning of various target task types, and shot generality denotes the ability to avoid negative transfer in different target task sample quantity settings including few-shot and non-few-shot.}
%     \begin{tabular}{c c c c c}
%         \toprule
%          \textbf{Method} &  \textbf{Multi-Source}& \textbf{Task Generality}  & \textbf{Shot Generality} & \textbf{Target} \\
%          \midrule
%          % MTL \citep[]{sun2019meta} &  \XSolidBrush &  \Checkmark & \XSolidBrush & Few-shot \\
%          Leep \citep[]{nguyen2020leep} &  \XSolidBrush &  \Checkmark & \Checkmark & Few-shot \\
%          MCW \citep[]{lee2019learning_MCW} &  \Checkmark & \XSolidBrush & \XSolidBrush & Few-shot \\
%          Tong \citep[]{tong2021mathematical} &  \Checkmark &  \XSolidBrush & \Checkmark &Few-shot \\
%          DATE \citep[]{han2023discriminability_DATE} & \Checkmark   &  \Checkmark & \XSolidBrush & Unsupervised \\
%          H-ensemble \citep[]{wu2024h_Hensemble}  &  \Checkmark & \XSolidBrush & \XSolidBrush & Few-shot \\ 
%          \ourmethod{} (Ours)   &  \Checkmark &  \Checkmark &  \Checkmark & Few-shot \\
%          \bottomrule
%     \end{tabular}
%     \label{tab:comparison}
% \end{table*}

% \begin{table*}[t]
% \setlength{\tabcolsep}{8pt}
%     \renewcommand{\arraystretch}{1.2}
%     \centering
%     \caption{\textbf{Comparison across related method,} based on whether they are tailored to multi-sources, have task generality, have shot generality, and require none or few-shot target labels. The `\Checkmark' represents obtaining the corresponding aspects, while `\XSolidBrush' the opposite. Task generality denotes the ability to handle the transfer learning of various target task types, and shot generality denotes the ability to avoid negative transfer in different target task sample quantity settings including few-shot and non-few-shot.}
%     \begin{tabular}{c c c c}
%         \toprule
%          \textbf{Method} &  \textbf{Multi-Source}& \textbf{Task Generality}  & \textbf{Shot Generality} \\
%          \midrule
%          MTL \citep[]{sun2019meta} &  \XSolidBrush &  \Checkmark & \XSolidBrush  \\
%          MCW \citep[]{lee2019learning_MCW} &  \Checkmark & \XSolidBrush & \XSolidBrush  \\
%          Tong \citep[]{tong2021mathematical} &  \Checkmark &  \XSolidBrush & \Checkmark  \\
%          % DATE \citep[]{han2023discriminability_DATE} & \Checkmark   &  \Checkmark & \XSolidBrush & Unsupervised \\
%          H-ensemble \citep[]{wu2024h_Hensemble}  &  \Checkmark & \XSolidBrush & \XSolidBrush \\ 
%          \ourmethod{} (Ours)   &  \Checkmark &  \Checkmark &  \Checkmark  \\
%          \bottomrule
%     \end{tabular}
%     \label{tab:comparison}
% \end{table*}


% \begin{table}[t]
% \setlength{\tabcolsep}{4pt}
%     \renewcommand{\arraystretch}{1.2}
%     \centering
%     \caption{\textbf{Comparison across related method,} based on whether they are tailored to multi-sources, have task generality, have shot generality, and require none or few-shot target labels. The `\Checkmark' represents obtaining the corresponding aspects, while `\XSolidBrush' the opposite. Task generality denotes the ability to handle the transfer learning of various target task types, and shot generality denotes the ability to avoid negative transfer in different target task sample quantity settings including few-shot and non-few-shot.}
%     \begin{tabular}{c c c c c}
%         \toprule
%          \textbf{Method} &   \textbf{Task Generality}  & \textbf{Shot Generality}  \\
%          \midrule
%          MTL \citep[]{sun2019meta}  &  \Checkmark & \XSolidBrush \\
%          MCW \citep[]{lee2019learning_MCW}  & \XSolidBrush & \XSolidBrush  \\
%          Tong \citep[]{tong2021mathematical}  &  \XSolidBrush & \Checkmark  \\
%          % DATE \citep[]{han2023discriminability_DATE} & \Checkmark   &  \Checkmark & \olidBrush & Unsupervised \\
%          H-ensemble \citep[]{wu2024h_Hensemble}   & \XSolidBrush & \XSolidBrush  \\ 
%          \ourmethod{} (Ours)    &  \Checkmark &  \Checkmark  \\
%          \bottomrule
%     \end{tabular}
%     \label{tab:comparison}
% \end{table}

In multi-source transfer learning, traditional methods usually jointly train the target model using all available samples from sources without selection~\cite{zhang2024revisiting_MADA,shui2021aggregating_WADN,li2021dynamic}. This evidently poses a severe limitation to training efficiency, considering the vast number of available samples from various potential source tasks in real-world scenarios~\cite{peng2019moment_M3SDA}. Moreover, directly assuming the use of all available samples seriously constrains their solution space, which possibly leads to suboptimal results as illustrated in Figure~\ref{fig:teaser-cifar10}. %Therefore, it is meaningful to establish a theoretical framework and corresponding practical algorithm to get the optimal quantity of source samples needed from each source task in training.
Therefore, it is critical to establish a theoretical framework to answer the question: \textit{what is the optimal transfer quantity of source samples from each source task needed in training the target task?}



% Although transfer learning can reduce variance in the training process via expanding the training data using source samples, the domain shift between the source and target tasks may introduce additional bias. Therefore, a core challenge in transfer learning is determining which source tasks should be selected or assigned higher weight for effective knowledge transfer, known as the matching strategy. 
% In this field, many theoretical works propose and analyze new generalization error measures to compute optimal source tasks or source weights for transfer. However, most studies focus on methods that select every source tasks as a whole or directly use all samples from all sources, while relatively few investigate the approach of selecting partial samples from each source task for transfer, and theoretical work in this area is particularly lacking. This limitation not only constrains the data efficiency of their methods, but also restricts the selection space, which may prevent the model from achieving optimal performance as illustrated in Figure~\ref{fig:teaser-cifar10}. Moreover, the theoretical correspondence between these measures and the testing loss in machine learning has seldom been rigorously established. 


% Furthermore, some existing transfer learning studies have other limitations. Firstly, many works are limited to specific task scenarios. For example, the methods based on extractor-classifier framework is only applicable to the transfer between classification tasks~\cite{wu2024h}, which restricts their \emph{task generality}.
% Moreover, many transfer learning studies are mainly applicable to few-shot or data-scarce scenarios, and may suffer from negative transfer in non-few-shot settings. However, in real-world applications, the boundary of few-shot scenarios is not always well-defined across different problems, which limits their \emph{shot generality} across different shot settings. 
% Based on the aforementioned points, we compare existing transfer learning works across these four aspects and summarize the main differences in Table~\ref{tab:comparison}.





In this work, we establish a theoretical framework for the multi-source transfer learning problem. We formulate the transfer quantity of each source task as an optimization variable and propose a method to determine its optimal value. 
Specifically, we introduce the expectation of Kullback-Leibler (K-L) divergence between the distribution learned from training samples and the true distribution of target task samples as a measure of generalization error. This measure is then minimized based on the Cram\'er-Rao Bound to derive the optimal transfer quantity of each source task. 
Building on this, we propose a practical algorithm, named \textbf{O}ptimal \textbf{T}ransfer \textbf{Q}uantities for \textbf{M}ulti-\textbf{S}ource Transfer learning (\ourmethod{}), to implement our theoretical results for training deep multi-source transfer learning models. Notably, \ourmethod{} is data-efficient and compatible with various model architectures, including Vision Transformer (ViT) and Low-Rank Adaptation (LoRA). It also demonstrates advantages in \emph{task generality} and \emph{shot generality} (as illustrated in Table~\ref{tab:comparison}), since we establish our theoretical framework without restricting it to a specific target task type or limiting the range of target sample quantity.
% Besides, since we establish our theoretical framework without restricting it to a specific target task type or limiting the range of target sample quantity, the proposed algorithm also exhibit advantages in \emph{task generality} and \emph{shot generality}, as illustrated in Table~\ref{tab:comparison}.
% Moreover, we analyzed the properties of the proposed measure, which is jointly quantified by the transfer quantity, the similarity between source and target tasks, and the model complexity. 
% In particular, we demonstrate that the transfer quantity of a particular source task approaches 0 when the similarity between source and target tasks is very low, and approaches all samples when the similarity is very high.


In summary, our main contributions are as follows:
\begin{itemize}
\item[a)]
A novel theoretical framework that optimizes transfer quantities is introduced for multi-source transfer learning. We propose a new K-L divergence measure of the generalization error. By
minimizing it, we develop a method to determine the optimal transfer quantity of each source task.

\item[b)] Based on the framework, we propose \ourmethod{}, an architecture-agnostic and data-efficient algorithm for target model training in multi-source transfer learning.
%, which is appropriate for
% \item[b)]Moreover, we design an practical and data-efficient algorithm to validate our theory. 
%The  experimental framework is designed to be lightweight and easy to interpret and adapt, possible to serve as a \textit{plug-in} module. 

\item[c)]Experimental studies on two real-world datasets and various model architectures demonstrate that \ourmethod{} achieves significant improvements in both accuracy and data efficiency. In terms of accuracy,  \ourmethod{} outperforms state-of-the-art by an average of $1.5\%$ on \texttt{DomainNet} and $1.0\%$ on \texttt{Office-Home}. 
In terms of data efficiency, \ourmethod{} reduces the average training time by $35.19\%$ and the average sample usage by $47.85\%$ on \texttt{DomainNet}. 
Furthermore, extensive supplementary experiments demonstrate that our theory can facilitate both full model training and parameter-efficient training. 
% Extensive supplementary experiments present the generality of our methodology, and provide an analysis of the transfer quantity.  
\end{itemize}

\section{Related Work}
\subsection{Transfer Learning Theory}
Existing theoretical works can be categorized into two groups. The first group focuses on proposing measures to quantify the similarity between the target and source tasks. Within this group, some measures have been introduced, including $l_2$-distance  \cite{long2014transfer}, optimal transport cost  \cite{courty2016optimal}, 
% K-L divergence~\cite{ganin2016domain,tzeng2017adversarial}, 
LEEP~\cite{nguyen2020leep}, Wasserstein distance~\cite{shui2021aggregating_WADN}, and maximal correlations~\cite{lee2019learning_MCW}. 
This work belongs to the second group focusing on developing new generalization error measures. Within this group, the measures 
having been introduced include $f$-divergence~\cite{harremoes2011pairs},  mutual information 
~\cite{bu2020tightening}, $\X^2$-divergence~\cite{tong2021mathematical}, $\mathcal{H}$-score~\cite{bao2019information,wu2024h_Hensemble}. 
However, the potential of K-L divergence as a generalization error measure has not been sufficiently explored. 
% In addition, some theoretical studies yield target models with constrained spaces, such as a convex combination of source models~\cite{tong2021mathematical}. 


\subsection{Multi-source Transfer Learning}
%%%%%%%%长版本%%%%%%%%%%%%%%%%%%%%%%%
% Multi-source Transfer Learning uses knowledge transferred from multiple source domains to improve learning in a target domain. Multi-source transfer learning is primarily introduced due to insufficient labeled data in the target domain, and is therefore commonly used in scenarios such as unsupervised or few-shot learning. Existing multi-source transfer learning methods mainly focus on two aspects. The first aspect is the alignment strategy, which is used among the source and target domains to bridge the domain shift. In this field, representative methods include latent space transformation trying to learn domain-invariant features of different domains~\cite{li2021multi, wang2022self}, intermediate domain generation generating an intermediate adapted domain~\cite{zhao2021madan,he2021multi}, and task classifier refinement addressing the label shift~\cite{li2022dynamic}. The second aspect is the matching strategy, focusing on which source domains or samples should be chose or assigned higher weights for transfer. In this field, the domain pairing strategy identifies source domains that are more similar or relevant to the target domain to improve the transfer process~\cite{guo2020multi}, and the domain/sample weighting strategy
% %combine the features or predictions by multiple source domain models with different weights during inference, or 
% assigns importance weights to the models or samples of different source domains~\cite{shui2021aggregating}.
% However, most existing work directly use all samples from all sources or selects the source tasks in their entirety, while few studies explore the framework of transferring partial samples from each source task. Moreover, many transfer learning studies are mainly applicable to few-shot or data-scarce scenarios, and may suffer from negative transfer in non-few-shot settings. However, the boundary of few-shot scenarios is not always well-defined across different problems, which limits their~\emph{shot generality}.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Multi-source Transfer Learning uses knowledge transferred from multiple source domains to improve learning in a target domain. Multi-source transfer learning is primarily introduced due to insufficient labeled data in the target domain, and is therefore commonly used in scenarios such as unsupervised or few-shot learning. 


Classified by the object of transfer, existing multi-source transfer learning methods mainly focus on two types: model transfer vs sample transfer~\cite{zhuang2020comprehensive}. Model transfer assumes there is one or more pre-trained models on the source tasks and transfers their parameters to the target task via fine-tuning~\cite{wan2022uav}.  This work focuses on the latter, which is based on joint training of the source task samples with those of the target task~\cite{zhang2024revisiting_MADA,shui2021aggregating_WADN,li2021dynamic}. %Sample transfer can achieve better performance than model-based method as joint training takes full advantage of the information in the source data related to the target task. 
Classified by the strategy of transfer, existing methods mainly focus on two types: alignment strategy and matching-based strategy \cite{zhao2024more}. Alignment strategy aims to reduce the domain shift among source and target domains~\cite{li2021multi,zhao2021madan,li2021dynamic}. This work is more similar to the latter, focusing on determining which source domains or samples should be selected or assigned higher weights for transfer~\cite{guo2020multi,shui2021aggregating_WADN,tong2021mathematical,wu2024h_Hensemble}. 
However, most existing works either utilize all samples from all sources or perform task-level selection, whereas this work explores a framework that optimizes the transfer quantity of each source task.
% Moreover, many works are restricted to specific target tasks, such as classification, which limits their \emph{task generality}. 
% In addition, many studies are mainly applicable to few-shot scenarios, and may suffer from negative transfer in non-few-shot settings, which limits their~\emph{shot generality}, as illustrated in Table~\ref{tab:comparison}.

% In addition, many studies are mainly applicable to few-shot scenarios, and may suffer from negative transfer in non-few-shot settings, which limits their~\emph{shot generality}, as illustrated in Table~\ref{tab:comparison}.


% For dataset transfer, one category is the alignment method, which aligns feature or data among source and target domains to reducing domain shift~\cite{zhang2024revisiting_MADA,shui2021aggregating_WADN,li2021dynamic}. In another category, is matching-based method, focusing on which source domains or samples should be chosen or assigned higher weights for transfer~\cite{shui2021aggregating_WADN}. 

% Existing multi-source transfer learning methods mainly focus on two aspects. The first aspect is the alignment strategy, which is used among source and target domains to reduce the domain shift. In this field, representative methods include latent space transformation~\cite{li2021multi, wang2022self}, intermediate domain generation~\cite{zhao2021madan,he2021multi}, and task classifier refinement~\cite{li2022dynamic}. The second aspect is the matching-based method, focusing on selecting which source domains or samples should be chose or assigned higher weights for transfer. In this field, representative methods include the domain pairing strategy~\cite{guo2020multi}, and the domain/sample weighting strategy
% % %combine the features or predictions by multiple source domain models with different weights during inference, or 
% % ~\cite{shui2021aggregating_WADN}.


% Moreover, many transfer learning studies are mainly applicable to few-shot or data-scarce scenarios, and may suffer from negative transfer in non-few-shot settings. However, the boundary of few-shot scenarios is not always well-defined across different problems, which limits their~\emph{shot generality}.





% Existing multi-source transfer learning methods mainly focus on two types: model transfer vs sample transfer. Model transfer assumes there is one or more pre-trained models on the source tasks and transfer their parameters to the target task via fine-tuning~\cite{wan2022uav}.  This work focuses on the latter, which is based on joint training of the source task samples with those of the target task. It can achieve better performance than model-based method as joint training takes full advantage of the information in the source data related to the target task. For dataset transfer, one category is the alignment method, which aligns feature or data among source and target domains to reducing domain shift~\cite{zhang2024revisiting_MADA,li2021dynamic}. In another category, is matching-based method, focusing on which source domains or samples should be chosen or assigned higher weights for transfer~\cite{shui2021aggregating_WADN}.

% Existing multi-source transfer learning methods mainly focus on two aspects. The first aspect is the alignment strategy, which is used among source and target domains to reduce the domain shift. In this field, representative methods include latent space transformation~\cite{li2021multi, wang2022self}, intermediate domain generation~\cite{zhao2021madan,he2021multi}, and task classifier refinement~\cite{li2022dynamic}. The second aspect is the matching-based method, focusing on selecting which source domains or samples should be chose or assigned higher weights for transfer. In this field, representative methods include the domain pairing strategy~\cite{guo2020multi}, and the domain/sample weighting strategy
% %combine the features or predictions by multiple source domain models with different weights during inference, or 
% ~\cite{shui2021aggregating_WADN}.
% However, most existing work directly use all samples from all sources or selects the source tasks in their entirety, while few studies explore the framework of transferring partial samples from each source task. Moreover, many transfer learning studies are mainly applicable to few-shot or data-scarce scenarios, and may suffer from negative transfer in non-few-shot settings. However, the boundary of few-shot scenarios is not always well-defined across different problems, which limits their~\emph{shot generality}.







% \subsection{one-source Transfer Learning (standby)}
% \subsection{Few-shot Learning (standby)}


\section{Problem Formulation}
% Let X be the random variable denoting the data with input space $\mathcal{X}$. 



Consider the transfer learning setting with one target task $\cT$, and $K$ source tasks $\left\{\cS_1,\dots,\cS_K\right\}$. 
The target task $\mathcal{T}$ is not restricted to a specific downstream task category. Generally, we formulate it as a parameter estimation problem under a distribution model 
$P_{X;{\underline{\theta}}}$. For example, when $\cT$ is a supervised classification task, $P_{X;{\underline{\theta}}}$ corresponds to the joint distribution model of input features $Z$ and output labels $Y$, \textit{i.e.}, $X=(Z,Y)$. Our objective is to estimate the true value of $\underline{\theta}$, which corresponds to optimizing the neural network parameters for target task $\cT$. 
Here, $\theta$ denotes 1-dimensional parameter, and $\underline{\theta}$ denotes high dimensional parameter. 
% We provide notation table is the Table \ref{Notations} in appendix. 

Furthermore, we assume that the source tasks and the target task follow the same parametric model and share the same input space $\mathcal{X}$.
Without loss of generality, we assume $\mathcal{X}$ to be discrete, though our results can be readily extended to continuous spaces. The target task $\cT$ has $N_{0}$ training samples $X^{N_0}=\{x_1,\dots,x_{N_{0}}\}$ i.i.d. generated from some underlying joint distribution $P_{X;{\underline{\theta}}_0}$, where the parameter ${\underline{\theta}}_0\in \mathbb{R}^d$. Similarly, the source task $\cS_k$ has $N_k$ training samples $X^{N_k}=\{x^{k}_1, \dots,x^{k}_{N_k}\}$ i.i.d. generated from some underlying joint distribution $P_{X;{\underline{\theta}}_k}$, where $k\in[1,K]$, and the parameter ${\underline{\theta}}_k\in \mathbb{R}^d$. 
% Based on the aforementioned assumptions regarding the parametric model, the neural network training problem for the target task $\cT$ can be equivalently transformed into a parameter estimation problem whose true value is $\theta_0$. 
In this work, we use the Maximum Likelihood Estimator (MLE) to estimate the true target task parameter $\theta_0$.
% , which can be realized by optimizing the cross-entropy using gradient descent during neural network training \cite{du2019gradient}. 
Moreover, the following lemma demonstrates that, for large sample size, the MLE can achieve the theoretical lower bound of the Mean Squared Error (MSE)  asymptotically, known as the Cram\'er-Rao Bound. 
% This lemma also provides theoretical support for using transfer learning to introduce more training samples, which helps reduce training variance when the bias of the source estimator is not very large.
\begin{lemma}\label{thm:Cramér}\cite{cover1999elements}
Let \( \hat{{\underline{\theta}}} \) be an unbiased estimator of  \( {\underline{\theta}}_0 \) based on \( n \) i.i.d. samples. Then, the MSE matrix of \( \hat{{\underline{\theta}}} \) satisfies the following lower bound:
\begin{align}\label{eq:Cramér}
\text{MSE}(\hat{{\underline{\theta}}})^{d\times d}\defeq\mathbb{E} \left[\left(\hat{{\underline{\theta}}} - {\underline{\theta}}_0\right)\left(\hat{{\underline{\theta}}} - {\underline{\theta}}_0\right)^T \right] \geq \frac{1}{n}J({\underline{\theta}}_0)^{-1},
\end{align}
where $\left(\hat{{\underline{\theta}}}-{{\underline{\theta}}_0}\right)$ is $d-dimensional$ vector, and the matrix inequality $A\geq B$ means that $A - B$ is positive semi-definite. In addition, the $J({\underline{\theta}})$ is fisher information matrix defined as:
\begin{align}
    J({\underline{\theta}})^{d\times d } &= \mathbb{E} \left[ \left( \frac{\partial}{\partial {\underline{\theta}}} \log P(X; {\underline{\theta}}) \right) \left( \frac{\partial}{\partial {\underline{\theta}}} \log P(X; {\underline{\theta}}) \right)^T \right].
\end{align}
Moreover, as the sample size \( n \to \infty \), the MLE $\hat{{\underline{\theta}}}$ can achieve this bound asymptotically, \textit{i.e.}, 
\begin{align}\label{eq:Cramér2}
%\lim_{n \to \infty}
\text{MSE}(\hat{{\underline{\theta}}}) = \frac{1}{n}J({\underline{\theta}}_0)^{-1}+o\left(\frac{1}{n}\right).
\end{align}
It should be noted that in some works, the MSE is defined as a scalar, which corresponds to the trace of the MSE matrix and can also be bounded using this lemma. 
%Using this lemma, we can also easily derive the bound for the scalar MSE.
% Since the diagonal elements of a positive semi-definite matrix are necessarily non-negative, we can also derive the bound for this scalar MSE using this lemma
\end{lemma}








When we transfer $n_1,\dots,n_K$ samples from the $\left\{\cS_1,\dots,\cS_K\right\}$, where $n_k\in\left[0,N_k\right]$, we denote these training sample sequences as $X^{n_1},X^{n_2},\dots,X^{n_k}$ . Then, the MLE for multi-source transfer learning, in the simplest form, is a summation of the likelihood of all source tasks and target tasks, \textit{i.e.},
\begin{align}
\label{mle_defination}
    \hat{{\underline{\theta}}} = \argmax_{{\underline{\theta}}} &{\sum_{x \in X^{N_{0}}}} \log P_{X;{\underline{\theta}}}(x)\notag\\
    &+{\sum_{k=1}^{K}\sum\limits_{x \in X^{n_{k}}}} \log P_{X;{\underline{\theta}}}(x). 
\end{align}


In this work, 
our goal is to derive the optimal transfer quantities $n_1^*,\dots,n_K^*$ of source tasks $\cS_1,\dots,\cS_K$ to minimize certain divergence measure $\cL$ between the distribution learned from training samples $P_{X;\hat{{\underline{\theta}}}}$ and the true distribution of target task $P_{X;{\underline{\theta}}_0}$, \textit{i.e.},
\begin{align}
\label{optimization_problem}
    n_1^*,\dots,n_k^*=\argmin_{n_1,\dots,n_k} \cL(P_{X;\hat{{\underline{\theta}}}},P_{X;{\underline{\theta}}_0}).
\end{align}
% In machine learning scenario, it corresponds to the optimal transfer quantities of samples from each source to jointly train the target model.
Besides, we provide the notations table in Appendix \ref{appendix:Notations}. 





\section{Theoretical Analysis and Algorithm}
In this section, we will first introduce a new K-L divergence measure for the optimization problem in \eqref{optimization_problem}. Then, we will analyze it based on the Cram\'er-Rao bound to derive the optimal transfer quantities for both single-source and multi-source scenarios. Finally, we will develop a practical algorithm based on the theoretical framework.
%For the beginning, we will provide their definitions
% In this work, we will utilize the K-L divergence in our measure to evaluate the distance between two distributions.
% In this work, we will utilize the K-L divergence as a measure to evaluate the distance between two distributions. Moreover, Fisher information will also be used in subsequent theoretical derivations, and thus we provide their definitions here.

\begin{definition}(The K-L divergence) 
The K-L divergence measures the difference between two probability distributions \( P(X) \) and \( Q(X) \) over the same probability space. It is defined as:
\begin{align}
    % D_{\text{KL}}(P \parallel Q) &= \sum_{x \in X} P(x) \log \left( \frac{P(x)}{Q(x)} \right), \quad \text{for discrete distributions,} \\
    % D_{\text{KL}}(P \parallel Q) &= \int_{X} p(x) \log \left( \frac{p(x)}{q(x)} \right) \, dx, \quad \text{for continuous distributions,}
    D\left(P \middle\| Q\right) = \sum_{x \in \mathcal{X}} p(x) \log \frac{p(x)}{q(x)}.\notag
\end{align}
% The K-L divergence is always non-negative and is zero if and only if \( p(x) = q(x) \) for all \( x \in X \). 
% where \( P(x) \) and \( Q(x) \) are the probability mass (or density) functions of the distributions \( P \) and \( Q \), respectively. 
% Moreover, the K-L divergence is a direct correspondence with the cross-entropy loss in model training \cite{cover1999elements}.
% \begin{align}
% D\left(P \middle\| Q\right)&= \sum_{x \in X} p(x) \log{p(x)}\underbrace{-\sum_{x \in X} p(x) \log{q(x)}}_{ cross-entropy}\notag
% %\\\notag&=-H(P)+H(P,Q)\notag
% \end{align}

\end{definition}
    



In this work, we apply the K-L divergence between
the distribution model parameterized by MLE \eqref{mle_defination} and the true distribution model of target task to measure the generalization error, which directly corresponds to the testing error using cross-entropy loss \cite{cover1999elements}.
\begin{align}
    D\left(P_{X;\hat{{\underline{\theta}}}} \middle\| P_{X;{\underline{\theta}}_0}\right) = -{\underbrace{H(P_{X;\hat{{\underline{\theta}}}})}_{\textnormal{entropy}}}+\underbrace{\mathbb{E}_{P_{X;\hat{{\underline{\theta}}}}}\left[
    P_{X;{\underline{\theta}}_0}
    \right]}_{\textnormal{cross-entropy}}\notag.
\end{align}
Finally, our generalization error measure is defined as follows.
\begin{align}
    \cL(P_{X;\hat{{\underline{\theta}}}},P_{X;{\underline{\theta}}_0})=\mathbb{E} \left[ D\left(P_{X;\hat{{\underline{\theta}}}} \middle\| P_{X;{\underline{\theta}}_0}\right) \right] .\label{eq:KL1}
\end{align}

% \textnormal
% \textrm
% \textbf

\subsection{Single-Source Transfer Learning}
% The direct characterization of the Kullback-Leibler (K-L) divergence is challenging. However, we can establish its connection to the mean squared error (MSE) in the asymptotic case. Moreover, the MSE has a widely used Cram\'er-Rao bound, through which we can derive a bound for the K-L divergence. We will begin by presenting the definition of the Cram\'er-Rao bound.

% Furthermore, we can establish the relationship between the proposed K-L measure \eqref{eq:KL1} and the mean squared error, and provide a bound for the proposed K-L measure \eqref{eq:KL1}. In the asymptotic case, K-L measure approaches this bound. 
The direct computation of the proposed K-L divergence measure is challenging. Fortunately, we can prove that the proposed K-L measure %is directly proportional to 
directly depends on
the MSE in the asymptotic case. Moreover, the MSE has a widely used Cram\'er-Rao bound introduced in Lemma \ref{thm:Cramér}, which provides a bound on the estimator's error, and is asymptotically tight. 
% Combining these two points, we can define our \emph{K-L objective function} as the asymptotic
% value of the K-L measure for generalization error, and we would like to minimize it. 
% As our goal is to find a correspondence between transfer quantity and generalization error, for the rest of the paper, we abuse the notation "K-L measure" to also represent the K-L measure in the asymptotic case corresponding to \eqref{eq:Cramér2}. 
As our goal is to find a correspondence between transfer quantity and generalization error, for the rest of the paper, we mainly analyze the K-L measure based on the Cram\'er-Rao bound \eqref{eq:Cramér2}. 
To begin, we consider the setting with a target task $\cT$ with $N_0$ samples generated from a model with 1-dimensional parameter.







\begin{lemma}\label{thm:target_only}(proved in Appendix \ref{appendix:target_only})
Given a target task $\cT$ with $N_0$ i.i.d. samples generated from 1-dimensional underlying model $P_{X;\theta_0}$, where $\theta_0 \in \mathbb{R}$, and denoting $\hat{\theta}$ as the MLE \eqref{mle_defination} based on the $N_0$ samples, then the K-L measure \eqref{eq:KL1} can be expressed as: 
\begin{align}
\mathbb{E} \left[ D\left(P_{X;\hat{\theta}} \middle\| P_{X;\theta_0}\right) \right] = \frac{1}{2N_0} + o\left( \frac{1}{N_0} \right).
\end{align}
\end{lemma}



The result of Lemma~\ref{thm:target_only} demonstrates that when there is only a target task, our K-L~measure is inversely proportional to the number of training samples. %This aligns with the empirical intuition that more training samples lead to more accurate training. 
% This also validates the superiority of our setting that uses all $N_0$ samples in the training process.
Next, we consider the transfer learning scenario in which we have one target task $\cT$ with $N_0$ training samples and one source task $\cS_1$ with $N_1$ training samples. In this case, We aim to determine the optimal transfer quantity $n_1^*\in [1,N_1]$. To facilitate our mathematical derivations, we assume 
$N_0$ and $N_1$ are asymptotically comparable, and
the distance between the parameters of target task and source task is sufficiently small (\textit{i.e.}, $\vert\theta_0-\theta_1\vert=O(\frac{1}{\sqrt{N_{0}}})$). Considering the similarity of low-level features among tasks of the same type,
this assumption is made without loss of generality.
Furthermore, as demonstrated in subsequent analysis, our conclusions remain valid even in extreme cases where the distance between parameters is large. 

%to get the best $\hat{\theta}$ which can gain the best result of \eqref{eq:KL1}.

% \begin{theorem}
% \label{thm:one_source}(proved in Appendix \ref{appendix:one_source})
% If we have $N_{0}$ target task samples, and choose $n_1\in[1,N_1]$ source task samples from source task $\cS_1$ to jointly train the target model, where the model parameters is 1-dimension, \textit{i.e.}, $d=1$, the K-L objective function will be
%     \begin{align}
%     \label{thm:one_source_KL}
%     \frac{1}{2}\bigg(\underbrace{\frac{1}{N_{0}+n_1}}_{variance~ term}+\underbrace{\frac{n_1^2}{(N_{0}+n_1)^2}t}_{bias~term}\bigg),
% \end{align}
% where 
% \begin{align}
% t \defeq J(\theta_0)(\theta_1 - \theta_0)^2 .
% \end{align}
% \end{theorem}

\begin{theorem}
\label{thm:one_source}(proved in Appendix \ref{appendix:one_source})
Given a target task $\cT$ with $N_0$ i.i.d. samples generated from 1-dimensional underlying model $P_{X;\theta_0}$, and a source task $\cS_1$ with $N_1$ i.i.d. samples generated from 1-dimensional underlying model $P_{X;\theta_1}$, where $\theta_0,\theta_1 \in \mathbb{R}$. $\hat{\theta}$ is denoted as the MLE \eqref{mle_defination} based on the $N_0$ samples from $\cT$ and $n_1$ samples from $\cS_1$, where $n_1 \in [0,N_1]$, then the K-L measure \eqref{eq:KL1} can be expressed as: 
    \begin{align}
    \label{thm:one_source_KL}
    % &{\cal L}(P_{X; \hat{\theta}}, P_{X;\theta_0}) \nonumber\\
    % &=
    \frac{1}{2}\bigg(\underbrace{\frac{1}{N_{0}+n_1}}_{\textnormal{variance~ term}}+\underbrace{\frac{n_1^2}{(N_{0}+n_1)^2}t}_{\textnormal{bias~term}}\bigg)+o\left(\frac{1}{N_{0}+n_1}\right),
\end{align}
where 
\begin{align}
t \defeq J(\theta_0)(\theta_1 - \theta_0)^2 .
\end{align}
Moreover, the optimal transfer quantity $n_1^*$ is
\begin{align}
n_1^*=
\begin{cases}
N_1,  &\quad \mathrm{if} \ N_{0} \cdot t\le0.5
 \\
\min\left(N_1,\frac{N_{0}}{2N_{0}t-1}\right), &\quad \mathrm{if} \ N_{0} \cdot t>0.5
\end{cases}.\label{optimalexponent}
\end{align}

\end{theorem}
From \eqref{thm:one_source_KL}, we observe that the K-L~measure decreases as $N_{0}$ increases, which aligns with our intuition that utilizing all available target samples is beneficial. In addition, the trend of \eqref{thm:one_source_KL} with respect to $n_1$ is more complex. 
We plot  \eqref{thm:one_source_KL} as a function of $n_1$ under two different regimes, determined by the value of $N_{0} \cdot t$, as shown in Figure \ref{N0*T}.
% We will give the figure of \eqref{thm:one_source_KL} and interpret our results at three different intervals. 
Our goal is to explore the optimal value of $n_1^*$ to minimize \eqref{thm:one_source_KL}.

\begin{figure}[h]
\centering
\includegraphics[width=0.38\textwidth]{figures/Dfunction3.pdf}
\caption{The function curve figures of \eqref{thm:one_source_KL} under different regimes determined by the value of $N_{0} \cdot t$ (\textcolor{blue}{blue}). The vertical axis denotes the value of K-L~measure \eqref{thm:one_source_KL}, while the horizontal axis denotes the  variable $n_1$.}
\label{N0*T}
\end{figure}

\begin{itemize}
    \item \textbf{Case 1 ($N_{0} \cdot t\le0.5$):} The K-L~measure monotonically decreases as $n_1$ increases. Obviously, the optimal point is $n_1^*=N_{1}$. This indicates that when the source task and the target task are highly similar, \textit{i.e.}, when 
    $t$ is small, an increase in the transfer quantity will positively impact the results. 
    \item \textbf{Case 2 ($N_{0}\cdot t>0.5$):} The K-L~measure first decreases and then increases as $n_1$ increases. It attaining its minimum at $n_{1}' = \frac{N_{0}}{2N_{0}t-1}$. It should be noted that when $t$ is large enough, the point $n_{1}'$ approaches $0$. This aligns with the intuition that when the discrepancy between the source and target tasks is substantial, avoiding transfer yields better results. Furthermore, if $n_1'$ exceeds $N_1$, we should utilize all $N_1$ samples, so $n_1^*=\min\left(N_1,\frac{N_{0}}{2N_{0}t-1}\right)$.
\end{itemize}

% In $N_{0} \cdot t<0.5$ case, the K-L~measure monotonically decreases as $n_1$ increases. As $n_1$ goes to infinity, the K-L~measure converges to the asymptotes $ \mathrm{y}= \frac{1}{2}t$. The function in this regime indicates that when the source task and the target task are highly similar, \textit{i.e.}, when 
% $t$ is small, an increase in the transfer quantity will positively impact the results. 

% In $0.5<N_{0}\cdot t<1$  case, the K-L~measure first decreases and then increase as $n_1$ increases. 
% It takes minimum at $n_{1}^* = \frac{N_{0}}{2N_{0}t-1}$.

% In $N_{0}\cdot t>1$ case, the K-L~measure \eqref{eq:KL1} first decreases and then increases as $n_1$ increases. When $n_{1}$ reaches the $\frac{N_{0}}{N_{0}t-1}$, the K-L~measure surpasses the result achieved by using merely samples from target task $\cT$. Still, the function takes minimum at $ n_{1}^*  = \frac{N_{0}}{2N_{0}t-1}$. It should be noted that when $t$ is large enough, the optimal point $n_{1}^*$ approaches $0$. This reflects the intuition that when the source task and target task differ significantly, not performing transfer yields better results. 

In Figure \ref{bias_variance_trade_off}, we provide an intuitive explanation for  the optimal $n_1^*$.
\begin{figure}[htbp]
\centering
\includegraphics[width=0.35\textwidth]{figures/bias_variance_trade_off_3.pdf}
\caption{The three circles represent the errors corresponding to transfer quantity $n_1=0$, $n_1^*$, and $N_1$. The distance from each circle’s center to $\theta_0$ represents the bias of estimation, and the radius represents the variance. As the transfer quantity increases, the bias increases,  while the variance decreases. The optimal $n_1^*$ achieves the best trade-off between them.}
\label{bias_variance_trade_off}
\end{figure}


%Estimator with different transfer quantity. 
% The blue region specifies the probability span of where maximum likelihood estimator would have landed when we are using solely samples of target task; the yellow region specify the probability span when we are using all the samples from target and source task; the green region specify the probability span when we are choosing an optimal amount sample. Note that when the green region stays within the blue region, it suggests that the source samples helps us gain precision without destructively undermining accuracy, which should lead to better performance of the estimator. This begs the question of how much sample should we transfer to achieve the optimal effect on the estimator, and that is the question we hope to answer in this passage.   


As the dimensionality of the model parameter $\theta$
increases to higher dimensions, we derive the following propositions. 
%which takes a form very similar to the previous Lemma \ref{thm:target_only} and Theorem \ref{thm:one_source}

\begin{proposition}(proved in Appendix \ref{appendix:prop_target_only})
\label{Proposition:target_only}
In the case where the parameter dimension is d, \textit{i.e.}, ${\underline{\theta}}_0\in \mathbb{R}^d$, with all other settings remaining the same as the Lemma  \ref{thm:target_only}, the K-L measure \eqref{eq:KL1} can be expressed as 
\begin{align}
\frac{d}{2N_0}+o\left(\frac{1}{N_0}\right).
\end{align}
\end{proposition}

\begin{proposition}(proved in Appendix \ref{appendix:Proposition:one_source})
\label{Proposition:one_source}
In the case where the parameter dimension is d, \textit{i.e.}, ${\underline{\theta}}_0,{\underline{\theta}}_1\in \mathbb{R}^d$, with all other settings remaining the same as the Theorem  \ref{thm:one_source}, the K-L measure \eqref{eq:KL1} can be expressed as
\begin{align} 
\label{Proposition:one_source_eq}
    %&=\frac{1}{2}\frac{d}{m+n}+\frac{1}{2}tr({J}(\vec{\theta_1})\left(\vec{\theta_2} - \vec{\theta_1}\right)^2)\frac{m^2}{(m+n)^2}\nonumber\\
    % &{\cal L}(P_{X; \hat{\theta}}, P_{X;\theta_0})\nonumber\\
    % &=
    \frac{d}{2}\left(\frac{1}{N_0+n_{1}}+\frac{n_{1}^2}{(N_0+n_{1})^2}t^{}\right)+o\left(\frac{1}{N_{0}+n_{1}}\right),
\end{align}
where we denote
\begin{align}
    t^{} \defeq \frac{({{\underline{\theta}}_1} - {{\underline{\theta}}_0})^{T}J({{\underline{\theta}}_0})({{\underline{\theta}}_1} - {{\underline{\theta}}_0})}{d}.
\end{align}
In addition, t is a scalar, ${J}({{\underline{\theta}}_0})$ is $d\times d$ matrix, and $\left({{\underline{\theta}}_1} -{{\underline{\theta}}_0}\right)$ is a $d-dimensional$ vector, which is the element-wise subtraction of two d-dimensional vectors ${\underline{\theta}}_1$ and ${\underline{\theta}}_0$.

\end{proposition}
% Compared to Lemma \ref{thm:target_only} and Theorem \ref{thm:one_source}, Proposition \ref{Proposition:target_only} and Proposition \ref{Proposition:one_source} 
Compared to Theorem \ref{thm:one_source}, Proposition \ref{Proposition:one_source} exhibits a similar mathematical form, allowing us to derive the optimal transfer quantity through a similar approach.  
Furthermore, we observe that as the parameter dimension $d$ increases, the K-L error measure \eqref{Proposition:one_source_eq} increases. This suggests that for a complex model, knowledge transfer across tasks becomes more challenging, which is consistent with the findings in \cite{tong2021mathematical}.

% even if the source task is similar to the target task, the transferable knowledge can still be very limited
% \begin{table*}[htbp]
% \centering
% \caption{Multi-Source Domain Adaptation (MSDA) on DomainNet and Office-Home. * indicates results from released code. We outperform source-free (SF) prior arts despite not using domain labels. (+x.x) indicates improvements over the source-free SOTA NRC.}
% \label{tab:msda}
% \resizebox{\textwidth}{!}{
% \begin{tabular}{@{}lcc|cccccc|c|cccc|c@{}}
% \toprule
% \textbf{Method}                & \textbf{SF} & \textbf{w/o Domain Labels} & \multicolumn{6}{c|}{\textbf{DomainNet}}                                  & Avg & \multicolumn{4}{c|}{\textbf{Office-Home}} & Avg \\ 
% \cmidrule(lr){4-9} \cmidrule(lr){10-10} \cmidrule(lr){11-14} \cmidrule(lr){15-15}
%                                &             &                            & $\to$C & $\to$I & $\to$P & $\to$Q & $\to$R & $\to$S &       & $\to$Ar & $\to$Cl & $\to$Pr & $\to$Rw &       \\ \midrule
% SImpAI$_{50}$ (Venkat et al., 2020) & ✗           & ✗                          & 66.4   & 26.5   & 56.6   & 18.9   & 68.0   & 55.5   & 48.6  & 70.8    & 56.3    & 80.2    & 81.5    & 72.2  \\
% CMSDA (Scalbert et al., 2021)  & ✗           & ✗                          & 70.9   & 26.5   & 57.5   & 21.3   & 68.1   & 59.4   & 50.4  & 71.5    & 67.7    & 84.1    & 82.9    & 76.6  \\
% DRT (Li et al., 2021b)         & ✗           & ✗                          & 71.0   & 31.6   & 61.0   & 12.3   & 71.4   & 60.7   & 51.3  & -       & -       & -       & -       & -     \\
% STEM (Nguyen et al., 2021)     & ✗           & ✗                          & 72.0   & 28.2   & 61.5   & 25.7   & 72.6   & 60.2   & 53.4  & -       & -       & -       & -       & -     \\ \midrule
% \textit{Source-combine:}       &             &                            &        &        &        &        &        &        &       &         &         &         &         &       \\
% SHOT (Liang et al., 2020)-Ens  & ✗           & ✓                          & 57.0   & 23.4   & 54.1   & 14.6   & 67.2   & 50.3   & 44.4  & 58.0    & 57.3    & 74.2    & 77.9    & 66.9  \\
% DECISION (Ahmed et al., 2021)  & ✗           & ✓                          & 58.6   & 25.2   & 55.3   & 15.3   & 70.5   & 52.4   & 46.2  & 72.2    & 59.3    & 82.8    & 82.3    & 74.2  \\
% CAiDA (Dong et al., 2021)      & ✗           & ✓                          & 61.5   & 21.6   & 54.6   & 18.9   & 67.5   & 51.0   & 45.9  & 74.5    & 59.4    & 84.4    & 83.6    & 75.5  \\
% NRC (Yang et al., 2021a)*      & ✗           & ✓                          & 65.8   & 24.1   & 56.0   & 19.6   & 69.5   & 53.4   & 47.4  & \textbf{75.2}    & 60.2    & 86.0    & 84.6    & 76.5  \\ \midrule
% Ours (\textit{edge-mixup}) + NRC & ✓           & ✓                          & 74.8   & 24.1   & 56.0   & 16.9   & 69.5   & 55.5   & 49.6 (+2.2)  & 72.1    & 62.9    & 86.4    & 84.8    & 76.6 (+1.9)  \\
% Ours (\textit{feature-mixup}) + NRC & ✓        & ✓                          & \textbf{75.4}   & 24.6   & \textbf{57.8}   & 23.6   & 65.8   & 58.5   & \textbf{51.0 (+3.6)} & 72.6    & \textbf{67.4}    & \textbf{85.9}    & \textbf{83.6}    & \textbf{77.4 (+2.7)}  \\ \bottomrule
% \end{tabular}
% }
% \end{table*}
% \newcommand{\mtl}{\hspace{1.2em}}
\begin{table*}[!htbp]
\centering
\caption{\textbf{Multi-Source Transfer Performance on DomainNet and Office-Home.} The arrows indicate transfering from the rest tasks. The highest/second-highest accuracy is marked in Bold/Underscore form respectively. }
\resizebox{\textwidth}{!}{
\begin{tabular}{lc c ccccccc c ccccc}
\toprule
% \multirow{2}{*}{\makecell{\textbf{Method} \\ Second line}} &\multirow{2}{*}{\makecell{\textbf{Method} \\ Second line}} 
\multirow{2.5}{*}{\textbf{Method}} & \multirow{2.5}{*}{\textbf{Backbone}} && \multicolumn{7}{c}{\textbf{DomainNet}} && \multicolumn{5}{c}{\textbf{Office-Home}}\\ 
% \cline{3-9} \cline{10-14}
\cmidrule(lr){4-10} \cmidrule(lr){12-16}
 &&&$\to$C & $\to$I & $\to$P & $\to$Q & $\to$R & $\to$S & Avg&& $\to$Ar & $\to$Cl & $\to$Pr & $\to$Rw & Avg\\ 

 % \multicolumn{1}{c|}{\makecell{\textbf{Method}}} &\multicolumn{1}{c|}{\makecell{\textbf{Backbone}}} &\multicolumn{7}{c|}{\makecell{\textbf{DomainNet}\\\midrule$\to$C\hspace{1.4em}$\to$I\hspace{1.4em}$\to$P\hspace{1.4em}$\to$Q\hspace{1.4em}$\to$R\hspace{1.4em}$\to$S\hspace{1.4em}Avg}} &\multicolumn{5}{c}{\makecell{\textbf{Office-Home}\\\midrule$\to$Ar\hspace{0.9em}$\to$Cl\hspace{0.9em}$\to$Pr\hspace{0.9em}$\to$Rw\hspace{0.9em}Avg}}\\
\midrule
% \midrule
% \textit{Source-combine:} &&&&&&&&&&&&\\
% \textit{Unsupervised-all-shots:} &&&&&&&&&&&&&\\
\multicolumn{14}{l}{\textbf{\textrm{Unsupervised-all-shots}}} \\
% (Surrogate-RN50-ICML23)
MSFDA\cite{shen2023balancingMSFDA} & ResNet50 && 66.5 & 21.6 &56.7 &20.4 &70.5 &54.4 &48.4  && 75.6 &62.8 &84.8 &\underline{85.3} &77.1  \\
% (SHOT-RN50-AAAI23)
DATE\cite{han2023discriminability_DATE}& ResNet50 && - & - & - & - & - & -   & - && 75.2 & 60.9 &  \textbf{85.2} & 84.0 & 76.3 \\
% MSFDA(Oracle-RN50-ICML23): & 76.5 &32.8 &64.7 &34.6 &77.8 &62.4 &58.1  & 86.9 &85.1 &92.2 &95.7 &90.0  \\
% M3SDA(*-RN101-CVPR19)& 57.0 & 22.1 & 50.5 & 4.4 & 62.0 & 48.5 & 40.8  & - & - & - & - & - \\
% (RN101-CVPR19)
M3SDA\cite{peng2019moment_M3SDA}& ResNet101 &&57.2 & 24.2 & 51.6 & 5.2 & 61.6& 49.6& 41.5  && - & - & - & - & - \\
% M3SDA($\beta$-RN101-CVPR19)& 58.6 & 26.0 & 52.3 & 6.3 & 62.7&  49.5 & 42.6  & - & - & - & -  & - \\
\midrule
% \textit{Supervised-10-shots:} &&&&&&&&&&&&&\\
\multicolumn{14}{l}{\textbf{\textrm{Supervised-10-shots}}} \\
\multicolumn{14}{l}{\textit{\textbf{Few-Shot Methods:}}}\\
% H-ensemble(Vits-AAAI24)& 51.7 & 21.7 & 54.0 & 19.2 & 70.5 & 42.0 & 43.2 & - & - & - & - & -  \\
% (Vits-AAAI24)
H-ensemble\cite{wu2024h_Hensemble}& ViT-S && 53.4 & 21.3 & 54.4 & 19.0 & 70.4 & 44.0 & 43.8 && 71.8 & 47.5 & 77.6 & 79.1 & 69.0  \\
% (Vits-CVPR24)
% MADA\cite{zhang2024revisiting_MADA}& ViT-S && 51.0 & 11.0 & 60.3 & 15.0 & \textbf{81.4} & 16.1 & 39.1 && \textbf{81.7} & 39.7 & \textbf{86.9} & \textbf{91.3} & 74.9 \\
% MADA\cite{zhang2024revisiting_MADA}& ViT-S && 51.0 & 11.0 & 60.3 & 15.0 & \textbf{81.4} & 16.1 & 39.1 && \textbf{85.2} & \textbf{73.1} & \textbf{93.9} & \textbf{92.7} & \textbf{86.2} \\
MADA\cite{zhang2024revisiting_MADA}& ViT-S && 51.0 & 12.8 & 60.3 & 15.0 & \textbf{81.4} & 22.7 & 40.5 && \textbf{78.4} & 58.3 & 82.3 & 85.2 & 76.1 \\
% (Res50-CVPR24)
% MADA\cite{zhang2024revisiting_MADA}& Resnet50 && 66.1 & 23.9 & \underline{60.4} & \underline{31.9} & \underline{75.4} & 52.5 & 51.7 && 72.8 & 59.9 & 82.4 & 81.5 & 74.2 \\
% MADA\cite{zhang2024revisiting_MADA}& Resnet50 && 66.1 & 23.9 & \underline{60.4} & \underline{31.9} & \underline{75.4} & 52.5 & 51.7 && 76.5 & 66.9 & 84.6 & 84.1 & 78.0 \\
% MADA\cite{zhang2024revisiting_MADA}& Resnet50 && 66.1 & 23.9 & \underline{60.4} & \underline{31.9} & \underline{75.4} & 52.5 & 51.7 && 72.2 & 64.5 & 82.9 & 81.9 & 75.4 \\
% MADA\cite{zhang2024revisiting_MADA}& ResNet50 && 66.1 & 23.9 & \underline{60.4} & \underline{31.9} & \underline{75.4} & 52.5 & 51.7 && \underline{79.6} & \underline{70.3} & \underline{86.2} & 84.6 & \underline{80.2} \\
MADA\cite{zhang2024revisiting_MADA}& ResNet50 && 66.1 & 23.9 & \underline{60.4} & \underline{31.9} & \underline{75.4} & 52.5 & 51.7 && 72.2 & \underline{64.4} & 82.9 & 81.9 & 75.4 \\
% MCW(Vits-NeurIPS19) & 55.3 & 20.5 & 52.8 & 20.4 & 70.0 & 42.7 & 43.6 & - & - & - & - & - \\
% (Vits-NeurIPS19)
MCW\cite{lee2019learning_MCW}& ViT-S && 54.9 & 21.0 & 53.6 & 20.4 & 70.8 & 42.4 & 43.9 && 68.9 & 48.0 & 77.4 & \textbf{86.0} & 70.1 \\
% (Vits-ICML21)
WADN\cite{shui2021aggregating_WADN}& ViT-S && 68.0 & 29.7 & 59.1 & 16.8 & 74.2 & 55.1 & 50.5 && 60.3 & 39.7 & 66.2 & 68.7 & 58.7 \\
% \midrule
% \textit{Supervised-10-shots:} &&&&&&&&&&&&&\\
\multicolumn{14}{l}{\textbf{\textit{Source-Ablation Methods:}}} \\
Target-Only& ViT-S && 14.2 & 3.3  & 23.2  & 7.2  & 41.4   & 10.6  & 16.7 && 40.0 & 33.3 & 54.9 & 52.6 & 45.2 \\ 
% Single-Source-best(Vits) & - & - & -  & -  & - & -  & - & -  & - & - & - & - \\ 
% Single-Source-avg(Vits) & - & - & -  & -  & - & -  & - & -  & - & - & - & - \\

Single-Source-Avg& ViT-S && 50.4 & 22.1 & 44.9  & 24.7  & 58.8 & 42.5  & 40.6 && 65.2  & 53.3 & 74.4 & 72.7 & 66.4 \\
Single-Source-Best& ViT-S && 60.2 & 28.0 & 55.4  & 28.4  & 66.0 & 49.7  & 48.0 && 72.9  & 60.9 & 80.7 & 74.8 & 72.3 \\ 

\allsource{}& ViT-S && \underline{71.7}   & \underline{32.4}  & 60.0 & 31.4 & 71.7 & \underline{58.5} & \underline{54.3} && 77.0 & 62.3 & 84.9 & 84.5 & \underline{77.2}\\
\ourmethod{} (Ours)& ViT-S && \textbf{72.8} & \textbf{33.8} & \textbf{61.2} & \textbf{33.8}  & 73.2 & \textbf{59.8} & \textbf{55.8} && \underline{78.1} & \textbf{64.5} & \textbf{85.2} & 84.9  & \textbf{78.2} \\
\bottomrule
\end{tabular}
}
\label{tab:major}
\end{table*}

% \begin{table*}[!htbp]
% \centering
% \caption{10-Shots Multi-Source Transferability on DomainNet and Office-Home.}
% \resizebox{\textwidth}{!}{
% \begin{tabular}{|l|c| cccccc|c|cccc|c|}
% \toprule
% % \multirow{2}{*}{\makecell{\textbf{Method} \\ Second line}} &\multirow{2}{*}{\makecell{\textbf{Method} \\ Second line}} 
% \multicolumn{1}{c|}{\makecell{\textbf{Method}}} &\multicolumn{1}{c|}{\makecell{\textbf{Backbone}}} &\multicolumn{7}{c|}{\makecell{\textbf{DomainNet}\\\midrule$\to$C\hspace{1.3em}$\to$I \hspace{1.3em}$\to$P\hspace{1.3em}$\to$Q\hspace{1.3em}$\to$R\hspace{1.3em}$\to$S\hspace{1.3em}Avg}} &\multicolumn{5}{c|}{\makecell{\textbf{Office-Home}\\\midrule$\to$Ar\hspace{0.6em} $\to$Cl\hspace{0.6em} $\to$Pr\hspace{0.6em} $\to$Rw \hspace{0.6em}Avg}}\\
% % \multicolumn{3}{c|}{\textbf{Second Row}} \\
% % \multicolumn{7}{c}{\textbf{DomainNet}} & \multicolumn{5}{c}{\textbf{Office-Home}}\\ 
% % \cline{3-9} \cline{10-14}
% % \cmidrule(lr){3-9} \cmidrule(lr){10-14}
%  % &&$\to$C & $\to$I & $\to$P & $\to$Q & $\to$R & $\to$S & Avg& $\to$Ar & $\to$Cl & $\to$Pr & $\to$Rw & Avg\\ 
% \midrule
% % \midrule
% % \textit{Source-combine:} &&&&&&&&&&&&\\
% % \textit{Unsupervised-all-shots:} &&&&&&&&&&&&&\\
% \multicolumn{14}{l}{\textbf{\textit{Unsupervised-all-shots:}}} \\
% % (Surrogate-RN50-ICML23)
% MSFDA[]: & Resnet50 & 66.5 & 21.6 &56.7 &20.4 &70.5 &54.4 &48.4  & 75.6 &\underline{62.8} &84.8 &85.3 &77.1  \\
% % (SHOT-RN50-AAAI23)
% DATE[]& Resnet50 & - & - & - & - & - & -   & - & 75.2 & 60.9 &  \underline{85.2} & 84.0 & 76.3 \\
% % MSFDA(Oracle-RN50-ICML23): & 76.5 &32.8 &64.7 &34.6 &77.8 &62.4 &58.1  & 86.9 &85.1 &92.2 &95.7 &90.0  \\
% % M3SDA(*-RN101-CVPR19)& 57.0 & 22.1 & 50.5 & 4.4 & 62.0 & 48.5 & 40.8  & - & - & - & - & - \\
% % (RN101-CVPR19)
% M3SDA[]& Resnet101 &57.2 & 24.2 & 51.6 & 5.2 & 61.6& 49.6& 41.5  & - & - & - & - & - \\
% % M3SDA($\beta$-RN101-CVPR19)& 58.6 & 26.0 & 52.3 & 6.3 & 62.7&  49.5 & 42.6  & - & - & - & -  & - \\
% \midrule
% % \textit{Supervised-10-shots:} &&&&&&&&&&&&&\\
% \multicolumn{14}{l}{\textit{\textbf{Supervised-10-shots:}}} \\
% % H-ensemble(Vits-AAAI24)& 51.7 & 21.7 & 54.0 & 19.2 & 70.5 & 42.0 & 43.2 & - & - & - & - & -  \\
% % (Vits-AAAI24)
% H-ensemble[]& ViT-S & 53.4 & 21.3 & 54.4 & 19.0 & 70.4 & 44.0 & 43.8 & 71.8 & 47.5 & 77.6 & 79.1 & 69.0  \\
% % (Vits-CVPR24)
% MADA[]& ViT-S & 51.0 & 11.0 & 60.3 & 15.0 & \textbf{81.4} & 16.1 & 39.1 & \textbf{81.7} & 39.7 & \textbf{86.9} & \textbf{91.3} & 74.9 \\
% % (Res50-CVPR24)
% MADA[]& Resnet50 & 66.1 & 23.9 & \underline{60.4} & \underline{31.9} & \underline{75.4} & 52.5 & 51.7 & 72.8 & 59.9 & 82.4 & 81.5 & 74.2 \\
% % MCW(Vits-NeurIPS19) & 55.3 & 20.5 & 52.8 & 20.4 & 70.0 & 42.7 & 43.6 & - & - & - & - & - \\
% % (Vits-NeurIPS19)
% MCW[]& ViT-S & 54.9 & 21.0 & 53.6 & 20.4 & 70.8 & 42.4 & 43.9 & 68.9 & 48.0 & 77.4 & \underline{86.0} & 70.1 \\
% % (Vits-ICML21)
% WADN[]& ViT-S & 68.0 & 29.7 & 59.1 & 16.8 & 74.2 & 55.1 & 50.5 & 60.3 & 39.7 & 66.2 & 68.7 & 58.7 \\
% % \midrule
% % \textit{Supervised-10-shots:} &&&&&&&&&&&&&\\
% \multicolumn{14}{l}{\textit{Source-ablation:}} \\
% None-Source& ViT-S & 14.2   & 3.3  & 23.2  & 7.2  & 41.4   & 10.6  & 16.7 & 40.0 & 33.3 & 54.9 & 52.6 & 45.2 \\ 
% % Single-Source-best(Vits) & - & - & -  & -  & - & -  & - & -  & - & - & - & - \\ 
% % Single-Source-avg(Vits) & - & - & -  & -  & - & -  & - & -  & - & - & - & - \\

% Single-Source-avg& ViT-S & 50.4 & 22.1 & 44.9  & 24.7  & 58.8 & 42.5  & 40.6 & 65.2  & 53.3 & 74.4 & 72.7 & 66.4 \\
% Single-Source-best& ViT-S & 60.2 & 28.0 & 55.4  & 28.4  & 66.0 & 49.7  & 48.0 & 72.9  & 60.9 & 80.7 & 74.8 & 72.3 \\ 

% All-Source& ViT-S & \underline{71.7}   & \underline{32.4}  & 60.0 & 31.4 & 71.7 & \underline{58.5} & \underline{54.3} & 77.0 & 62.3 & 84.9 & 84.5 & \underline{77.2}\\
% \ourmethod{} (Ours)& ViT-S & \textbf{72.8} & \textbf{33.8} & \textbf{61.2} & \textbf{33.8}  & 73.2 & \textbf{59.8} & \textbf{55.8} & \underline{78.1} & \textbf{64.5} & \underline{85.2} & 84.9  & \textbf{78.2} \\
% \bottomrule
% \end{tabular}
% }
% \label{tab:major}
% \end{table*}


\subsection{Multi-Source Transfer Learning}
Consider the multi-source transfer learning scenario with $K$ source task $\left\{\cS_1,\dots,\cS_K\right\}$ and one target task $\cT$. 
We aim to derive the optimal transfer quantity $n_i^*$ of each source.

\begin{theorem}(proved in Appendix \ref{appendix:multi_source})
\label{thm:multi_source}
Given a target task $\cT$ with $N_0$ i.i.d. samples generated from underlying model $P_{X;{\underline{\theta}}_0}$, and K source tasks $\cS_1,\dots,\cS_K$ with $N_1,\dots,N_K$ i.i.d. samples generated from underlying model $P_{X;{\underline{\theta}}_1},\dots,P_{X;{\underline{\theta}}_K}$, where ${\underline{\theta}}_0,{\underline{\theta}}_1,\dots,{\underline{\theta}}_K\in \mathbb{R}^d$. $\hat{{\underline{\theta}}}$ is denoted as the MLE \eqref{mle_defination} based on the $N_0$ samples from $\cT$ and $n_1,\dots,n_K$ samples from $\cS_1,\dots,\cS_K$, where $n_i \in [0,N_i]$. Denoting $s=\sum\limits_{i=1}^{K}n_i$ as the total transfer quantity, and $\alpha_i=\frac{n_i}{s}$ as the proportion of different source tasks, then the K-L measure \eqref{eq:KL1} can be expressed as: 
\begin{align}
\label{eq:multisourcetarget}
&\frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^2}t\right)+o\left(\frac{1}{N_{0}+s}\right).
\end{align}
In  \eqref{eq:multisourcetarget}, $t$ is a scalar denoted as
\begin{align}
t=\frac{\underline{\alpha}^T\Theta^T{J}({{\underline{\theta}}_0})\Theta\underline{\alpha}}{d},
\end{align}
where $\underline{\alpha}=\left[\alpha_1,\dots,\alpha_K\right]^T$ is a K-dimensional vector, and $\Theta^{d\times K}=\left[{{\underline{\theta}}_1}-{{\underline{\theta}}_0},\dots,{{\underline{\theta}}_K}-{{\underline{\theta}}_0} \right]$.
\end{theorem}

% We provide the method to obtain $s^*$ and $\alpha^*$ which minimize \eqref{eq:multisourcetarget} in the Appendix \ref{appendix:sa}.
According to Theorem \ref{thm:multi_source}, we can derive the optimal transfer quantities $n_1^*, \dots, n_K^*$ by minimizing \eqref{eq:multisourcetarget}. Equivalently, we need to find the optimal total transfer quantity $s^*$ and the optimal proportion vector $\underline{\alpha}^*$ which minimize \eqref{eq:multisourcetarget}. The analytical solutions of $s^*$ and $\underline{\alpha}^*$  are difficult to acquire, and we provide a method to get their numerical solutions in Appendix \ref{appendix:sa}. Eventually, we can get the optimal transfer quantity of each source through $n_i^*=s^*\cdot\alpha_i^*$ .



% \begin{theorem}(proved in Appendix \ref{appendix:multi_source})
% \label{thm:multi_source} 
% If we have $N_{0}$ target task samples, and choose $k=1,\dots,K$, $n_k\in[1,N_k]$ samples from source task $\cS_k$  respectively to jointly train the target model. We denote $s=\sum\limits_{i=1}^{K}n_i$ as the total transfer quantity, and $\alpha_i=\frac{n_i}{s}$ as the proportion of different source tasks.
% For the d-demension parameter ${\theta_i}$, the K-L measure \eqref{eq:KL1} can be expressed as
% \begin{align}
% \label{eq:multisourcetarget}
% %&{\cal L}(P_{X; \hat{\theta}}, P_{X;\theta_0})=\nonumber\\
% &\frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^2}t\right)+o\left(\frac{1}{N_{0}+s}\right).
% \end{align}
% In  \eqref{eq:multisourcetarget}, $t=r/d$, and r is a scalar denoted as
% \begin{align}
% r=\alpha^T\Theta^T{J}({\theta_0})\Theta\alpha,
% \end{align}
% where $\alpha=\left[\alpha_1,\dots,\alpha_K\right]^T$ is a K-dimensional vector, and \begin{align}\Theta^{d\times K}=\left[{\theta_1}-{\theta_0},\dots,{\theta_K}-{\theta_0} \right].\end{align}
% \end{theorem}





% To  minimize \eqref{eq:multisourcetarget}, we can firstly minimize $r$, and get the optimal $\alpha$. This is a non-negative quadratic programming problem. Then we use the optimal $t=r/d$ to minimize \eqref{eq:multisourcetarget}, and get the optimal value of $s$, which is the same question of Proposition \ref{Proposition:one_source}. Finally, we can use optimal $s$ and $\alpha_i$ to get $n_i$.

\subsection{Practical Algorithm}
% 值得注意的是，我们的方法还兼具了计算的高效性，在模型训练的同时可以根据其反向传播时的梯度进行fisher参数（即模型参数权重）的计算。由于我们的方法会用矩阵乘法将维度转化为很小的任务个数的维度，对于参数量比较大的模型而言，同一时刻也最多只会存在源任务模型的参数量，保证了我们方法对存储空间并没有太高要求。
Along with our theoretical framework, we propose a practical algorithm, \ourmethod{}, which is applicable to all supervised target tasks, as presented  in Algorithm \ref{alg:ours_algorithm}. It mainly involves two stages: 
(1) initializing the source task parameters $\theta_1,...,\theta_K$
to compute the optimal transfer quantities
% simulating the source data distribution of each source 
and (2) jointly training the target model using a resampled dataset whose sample quantity of each source corresponds to the optimal transfer quantity derived from our theory. 
% Note that computing the KL-measure adds relatively little overhead to the SGD training as the Fisher information can be computed during training by leveraging the gradients obtained in the backpropagation process.


% It is noteworthy that the Fisher information can be computed during training by leveraging the gradients obtained in the backpropagation process.

% Moreover, it employs matrix multiplication reducing the dimensionalty of models to the counts of tasks, ensuring high efficiency on memory consumption.
\begin{algorithm}[H]
   \caption{\ourmethod{}: Training}
   \label{alg:ours_algorithm}
\begin{algorithmic}[1]

    \STATE {\bfseries Input:} Target data $D_{\cT}=\{(z_\cT^i, y_\cT^i)\}_{i=1}^{N_0}$, source data $\{D_{S_k}=\{(z_{S_k}^i, y_{S_k}^i)\}_{i=1}^{N_{k}}\}_{k=1}^K$, model type $f_{{\underline{\theta}}}$ and its parameters ${\underline{\theta}}_0$ for target task and $\{{\underline{\theta}}_{k}\}_{k=1}^K$ for source tasks, parameter dimension $d$.
    % task-specific loss function $\ell(y, \hat{y})$.
    
    \mycomment{$z$ represents the feature and $y$ represents the label}
    
    \STATE {\bfseries Parameter:} Learning rate $\eta$.
   
    \STATE {\bfseries Initialize:} randomly initialize ${\underline{\theta}}_0$, $\{{\underline{\theta}}_{k}\}_{k=1}^K$.
   
    \STATE {\bfseries Output:} a well-trained model $f_{{\underline{\theta}}_0}$ for target task.

    % \STATE {\bfseries Output:} a well-trained ${\underline{\theta}}_0$ for target task model $f_{{\underline{\theta}}_0}$.
   
    \STATE \textbf{for} $k = 1$ {\bfseries to} $K$ \textbf{do} \mycomment{Initialize the source parameters}
    \STATE \hspace{1em} \textbf{repeat}
    \STATE \hspace{1em} \hspace{1em}$L_{k} \gets \frac{1}{N_k} \sum\limits_{i=1}^{N_k} \ell\left(y_{S_k}^i, f_{{\underline{\theta}}_k}(z_{S_k}^i)\right)$
    \STATE \hspace{1em} \hspace{1em}${\underline{\theta}}_{k} \gets {\underline{\theta}}_{k} - \eta \nabla_{{\underline{\theta}}_{k}} L_{k}$
    \STATE \hspace{1em} \textbf{until} ${\underline{\theta}}_{k}$ converges;
    \STATE \textbf{end for}
   
    $D_{train} \gets D_\cT = \{(z^i, y^i)\}_{i=1}^{N_{train}}$
   
    \STATE \textbf{repeat} \mycomment{Joint  training of the target task}
    
    \STATE \hspace{1em}$L_{\cT} \gets \frac{1}{N_{train}} \sum\limits_{i=1}^{N_{train}} \ell\left(y^i_{\cT}, f_{{\underline{\theta}}_0}(z^i)\right)$
    \STATE \hspace{1em}${\underline{\theta}}_0 \gets {\underline{\theta}}_0 - \eta \nabla_{{\underline{\theta}}_0} L_{\cT}$
   
    \STATE \hspace{1em}$\Theta\gets\left[{{\underline{\theta}}_1}-{{\underline{\theta}}_0},\dots,{{\underline{\theta}}_K}-{{\underline{\theta}}_0} \right]^T$
    \STATE \hspace{1em}${J}({{\underline{\theta}}_0}) \gets ( \nabla_{{\underline{\theta}}_0} L_{\cT})( \nabla_{{\underline{\theta}}_0} L_{\cT})^T$
    %%%%%%%%%%%%%%老版本优化方法%%%%%%%%%%%%%%%%%%%%%
    % \STATE \hspace{1em}$\alpha^* \gets \argmin\limits_{\alpha} \alpha^T\Theta^T{J}({{\underline{\theta}}_0})\Theta\alpha $
    % \STATE \hspace{1em}$t^* \gets \frac{\alpha^{*^T}\Theta^T{J}({{\underline{\theta}}_0})\Theta\alpha^*}{d}$
    % \STATE \hspace{1em}$s^* \gets \argmin\limits_{s} \frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^2}t^*\right)$ 
    %%%%%%%%%%%%%%老版本优化方法%%%%%%%%%%%%%%%%%%%%%
    \STATE \hspace{1em}$(s^*, \underline{\alpha}^*) \gets \argmin\limits_{(s, \underline{\alpha})} \frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^2}\frac{\underline{\alpha}^T\Theta^T{J}({{\underline{\theta}}_0})\Theta\underline{\alpha}}{d}\right)$ 
    
    % \STATE \hspace{1em}$D_{source} \gets $for $k=1,\dots,K$, take $s^*\alpha_k^*$ samples from $D_{S_k}$ respectively.
    % \STATE \hspace{1em}
    % $D_{source} \gets \bigcup\limits_{k=1}^K \text{i.i.d. } D_{S_k}^{s^* \alpha_k^*}$
    \STATE \hspace{1em}$D_{source} \gets \bigcup\limits_{k=1}^K  \left\{D_{S_k}^{*} \bigg| D_{S_k}^{*}\subseteq D_{S_k},\; \lvert D_{S_k}^{*}\rvert= s^* \alpha_k^*\right\}$
    %带rand的集合属于号↓
    % \STATE \hspace{1em}$D_{source} \gets \bigcup\limits_{k=1}^K  \left\{D_{S_k}^{*} \bigg| D_{S_k}^{*}\overset{\text{rand}}{\subseteq} D_{S_k}, \lvert D_{S_k}^{*}\rvert= s^* \alpha_k^*\right\}$
    \STATE \hspace{1em}$D_{train} \gets D_{source}\bigcup D_\cT $
    \STATE \textbf{until} ${\underline{\theta}}_{0}$ converges;
\end{algorithmic}
\end{algorithm}
% For the sake of convenience, we have chosen the most commonly used classification task as an example.
% \begin{algorithm}[H]
%    \caption{\ourmethod{}: Classification task training}
%    \label{alg:ours_algorithm}
% \begin{algorithmic}

% % 目标任务O, 源任务总个数K
% % 第t个epoch t
% % 转置T
% % 种类个数不写了emmm


% %损失函数不用写在input
%     \STATE {\bfseries Input:} Target data $D_{\cT}=\{(x_\cT^i, y_\cT^i)\}_{i=1}^{N_0}$, source data $\{D_{S_k}=\{(x_{S_k}^i, y_{S_k}^i)\}_{i=1}^{N_{k}}\}_{k=1}^K$,  model type $f$ and its parameters $\theta_0$ for target task and $\{\theta_{k}\}_{k=1}^K$ for source tasks, parameter dimension $d$.
%    \STATE {\bfseries Parameter:} Learning rate $\eta$.
   
%    \STATE {\bfseries Initialize:} randomly initialize $\theta_0$, $\{\theta_{k}\}_{k=1}^K$.
%    % randomly initialize picked samples task ratio $\alpha$, all picked samples $s$,
   
%    \STATE {\bfseries Output:} a well-trained parameter $\theta_0$ for target task
%    % source weight $\alpha$, source picked samples $S$.
%    % \STATE \textbf{for} $y = 1$ {\bfseries to} $d_T$ \textbf{do} \mycomment{Simulate source data distribution}
   
%    \STATE \textbf{for} $k = 1$ {\bfseries to} $K$ \textbf{do} \mycomment{Simulate source data distribution}
%    \STATE \hspace{1em} \textbf{repeat}
%    \STATE \hspace{1em} \hspace{1em}
%    % $L_{k} \gets - \frac{1}{N_{k}} \sum\limits_{i=1}^{N_{k}} \log \frac{\exp(f_{\theta_{k}}(x_{S_k}^i)_{y_{S_k}^i})}{\sum\limits_j \exp(f_{\theta_{k}}(x_{S_k}^i)_j)}$
%    $L_{k} \gets - \frac{1}{N_{k}} \sum\limits_{i=1}^{N_{k}}L\left(f_{\theta_{k}}(x_{S_k}^i),{y_{S_k}^i}\right)$
%    \STATE \hspace{1em} \hspace{1em}$\theta_{k} \gets \theta_{k} - \eta \nabla_{\theta_{k}} L_{k}$
%    \STATE \hspace{1em}\textbf{until} $\theta_{k}$ converges;
%    \STATE \textbf{end for}
   
%    $D_{train} \gets D_\cT = \{(x^i, y^i)\}_{i=1}^{N_{train}}$
   
%    \STATE \textbf{repeat} \mycomment{Weighted sampling training per epoch}
   
    
%    % \STATE \textbf{for} $i = 1$ {\bfseries to} $N_T$ \textbf{do} \mycomment{Train the target model}
%    \STATE \hspace{1em}
%    % $L_{\cT} \gets -\frac{1}{N_{train}}\sum\limits_{i=1}^{N_{train}} \log \frac{\exp(f_{\theta_0}(x^i)_{y^i})}{\sum\limits_j \exp(f_{\theta_0}(x^i)_j)}$
%    $L_{\cT} \gets -\frac{1}{N_{train}}\sum\limits_{i=1}^{N_{train}}
%    L\left(f_{\theta_{0}}(x^i),{y^i}\right)$
   
%    \STATE \hspace{1em}$\theta_0 \gets \theta_0 - \eta \nabla_{\theta_0} L_{\cT} $
   
%    \STATE \hspace{1em}$\Theta\gets\left[{\theta_1}-{\theta_0},\dots,{\theta_K}-{\theta_0} \right]^T$
   
%    \STATE \hspace{1em}${J}({\theta_0}) \gets ( \nabla_{\theta_0} L_{\cT})( \nabla_{\theta_0} L_{\cT})^T$
   
    
%    % \STATE \hspace{1em}$\alpha \gets\argmin\left(\sum\limits_{i=1}^{K}\alpha_i({\theta_i}-{\theta_0})\right)^T{J}({\theta_0})\left(\sum\limits_{i=1}^{K}\alpha_i({\theta_i}-{\theta_0})\right)$
   
   
%    \STATE \hspace{1em}$\alpha^* \gets \argmin\limits_{\alpha} \alpha^T\Theta^T{J}({\theta_0})\Theta\alpha $
%    % \STATE \hspace{1em}\hspace{1em}\hspace{1em} when $\sum\limits_{k=1}^K \alpha_k = 1 $
%    \STATE \hspace{1em}$r^* \gets \alpha^{*^T}\Theta^T{J}({\theta_0})\Theta\alpha^*$
%    \STATE \hspace{1em}$s^* \gets \argmin\limits_{s} \frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^2}\frac{r^*}{d}\right)\nonumber$ 
%    % \STATE \hspace{1em}$m \gets \alpha s$
%    % \STATE \hspace{1em}$L_{O^t} \gets \frac{1}{N_{O^t}} \sum\limits_{i=1}^{N_{O^t}} L_{O^t}^i $
%     \STATE \hspace{1em}$D_{source} \gets $for $k=1,\dots,K$, $s^*\alpha_k^*$ samples from $D_{S_k}$ respectively.
    
%    \STATE \hspace{1em}$D_{train} \gets D_{source}+D_\cT = \{(x^i, y^i)\}_{i=1}^{N_{train}}$
   
%    \STATE \textbf{until} $\theta_{0}$ converges;
  
  
% \end{algorithmic}
% \end{algorithm}


% \begin{algorithm}[H]
%    \caption{\ourmethod{}: Training}
%    \label{alg:ours_algorithm}
% \begin{algorithmic}

%     \STATE {\bfseries Input:} Target data $D_{\cT}=\{(x_\cT^i, y_\cT^i)\}_{i=1}^{N_0}$, source data $\{D_{S_k}=\{(x_{S_k}^i, y_{S_k}^i)\}_{i=1}^{N_{k}}\}_{k=1}^K$, model type $f_{\theta}$ and its parameters $\theta_0$ for target task and $\{\theta_{k}\}_{k=1}^K$ for source tasks, parameter dimension $d$.
%     % task-specific loss function $\ell(y, \hat{y})$.
%     \STATE {\bfseries Parameter:} Learning rate $\eta$.
   
%     \STATE {\bfseries Initialize:} randomly initialize $\theta_0$, $\{\theta_{k}\}_{k=1}^K$.
   
%     \STATE {\bfseries Output:} a well-trained model $f_{\theta_0}$ for target task.

%     % \STATE {\bfseries Output:} a well-trained $\theta_0$ for target task model $f_{\theta_0}$.
   
%     \STATE \textbf{for} $k = 1$ {\bfseries to} $K$ \textbf{do} \mycomment{Simulate source data distribution}
%     \STATE \hspace{1em} \textbf{repeat}
%     \STATE \hspace{1em} \hspace{1em}$L_{k} \gets \frac{1}{N_k} \sum\limits_{i=1}^{N_k} \ell\left(y_{S_k}^i, f_{\theta_k}(x_{S_k}^i)\right)$
%     \STATE \hspace{1em} \hspace{1em}$\theta_{k} \gets \theta_{k} - \eta \nabla_{\theta_{k}} L_{k}$
%     \STATE \hspace{1em} \textbf{until} $\theta_{k}$ converges;
%     \STATE \textbf{end for}
   
%     $D_{train} \gets D_\cT = \{(x^i, y^i)\}_{i=1}^{N_{train}}$
   
%     \STATE \textbf{repeat} \mycomment{Weighted sampling from source}
    
%     \STATE \hspace{1em}$L_{\cT} \gets \frac{1}{N_{train}} \sum\limits_{i=1}^{N_{train}} \ell\left(y^i_{\cT}, f_{\theta_0}(x^i)\right)$
%     \STATE \hspace{1em}$\theta_0 \gets \theta_0 - \eta \nabla_{\theta_0} L_{\cT}$
   
%     \STATE \hspace{1em}$\Theta\gets\left[{\theta_1}-{\theta_0},\dots,{\theta_K}-{\theta_0} \right]^T$
%     \STATE \hspace{1em}${J}({\theta_0}) \gets ( \nabla_{\theta_0} L_{\cT})( \nabla_{\theta_0} L_{\cT})^T$
   
%     \STATE \hspace{1em}$\alpha^* \gets \argmin\limits_{\alpha} \alpha^T\Theta^T{J}({\theta_0})\Theta\alpha $
%     \STATE \hspace{1em}$r^* \gets \alpha^{*^T}\Theta^T{J}({\theta_0})\Theta\alpha^*$
%     \STATE \hspace{1em}$s^* \gets \argmin\limits_{s} \frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^2}\frac{r^*}{d}\right)$ 
    
%     % \STATE \hspace{1em}$D_{source} \gets $for $k=1,\dots,K$, take $s^*\alpha_k^*$ samples from $D_{S_k}$ respectively.
%     % \STATE \hspace{1em}
%     % $D_{source} \gets \bigcup\limits_{k=1}^K \text{i.i.d. } D_{S_k}^{s^* \alpha_k^*}$
%     \STATE \hspace{1em}$D_{source} \gets \bigcup\limits_{k=1}^K  \left\{D_{S_k}^{*} \bigg| D_{S_k}^{*}\subseteq D_{S_k},\; \lvert D_{S_k}^{*}\rvert= s^* \alpha_k^*\right\}$
%     %带rand的集合属于号↓
%     % \STATE \hspace{1em}$D_{source} \gets \bigcup\limits_{k=1}^K  \left\{D_{S_k}^{*} \bigg| D_{S_k}^{*}\overset{\text{rand}}{\subseteq} D_{S_k}, \lvert D_{S_k}^{*}\rvert= s^* \alpha_k^*\right\}$
    


%     \STATE \hspace{1em}$D_{train} \gets D_{source}\bigcup D_\cT $
%     % = \{(x^i, y^i)\}_{i=1}^{N_{train}}$
    
%     \STATE \textbf{until} $\theta_{0}$ converges;
  
% \end{algorithmic}
% \end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%↓↓↓↓2025_1_24版本↓↓↓↓%%%%%%%%%%%%%%%%%
% \begin{algorithm}[H]
%    \caption{\ourmethod{}: Classification task training}
%    \label{alg:ours_algorithm}
% \begin{algorithmic}

% % 目标任务O, 源任务总个数K
% % 第t个epoch t
% % 转置T
% % 种类个数不写了emmm


% %损失函数不用写在input
%     \STATE {\bfseries Input:} Target data $D_{\cT}=\{(x_\cT^i, y_\cT^i)\}_{i=1}^{N_0}$, source data $\{D_{S_k}=\{(x_{S_k}^i, y_{S_k}^i)\}_{i=1}^{N_{k}}\}_{k=1}^K$,  model type $f$ and its parameters $\theta_0$ for target task and $\{\theta_{k}\}_{k=1}^K$ for source tasks, parameter dimension $d$.
%    \STATE {\bfseries Parameter:} Learning rate $\eta$.
   
%    \STATE {\bfseries Initialize:} randomly initialize $\theta_0$, $\{\theta_{k}\}_{k=1}^K$.
%    % randomly initialize picked samples task ratio $\alpha$, all picked samples $s$,
   
%    \STATE {\bfseries Output:} a well-trained parameter $\theta_0$ for target task
%    % source weight $\alpha$, source picked samples $S$.
%    % \STATE \textbf{for} $y = 1$ {\bfseries to} $d_T$ \textbf{do} \mycomment{Simulate source data distribution}
   
%    \STATE \textbf{for} $k = 1$ {\bfseries to} $K$ \textbf{do} \mycomment{Simulate source data distribution}
%    \STATE \hspace{1em} \textbf{repeat}
%    \STATE \hspace{1em} \hspace{1em}$L_{k} \gets - \frac{1}{N_{k}} \sum\limits_{i=1}^{N_{k}} \log \frac{\exp(f_{\theta_{k}}(x_{S_k}^i)_{y_{S_k}^i})}{\sum\limits_j \exp(f_{\theta_{k}}(x_{S_k}^i)_j)}$
%    \STATE \hspace{1em} \hspace{1em}$\theta_{k} \gets \theta_{k} - \eta \nabla_{\theta_{k}} L_{k}$
%    \STATE \hspace{1em}\textbf{until} $\theta_{k}$ converges;
%    \STATE \textbf{end for}
   
%    $D_{train} \gets D_\cT = \{(x^i, y^i)\}_{i=1}^{N_{train}}$
   
%    \STATE \textbf{repeat} \mycomment{Weighted sampling training per epoch}
   
    
%    % \STATE \textbf{for} $i = 1$ {\bfseries to} $N_T$ \textbf{do} \mycomment{Train the target model}
%    \STATE \hspace{1em}$L_{\cT} \gets -\frac{1}{N_{train}}\sum\limits_{i=1}^{N_{train}} \log \frac{\exp(f_{\theta_0}(x^i)_{y^i})}{\sum\limits_j \exp(f_{\theta_0}(x^i)_j)}$
%    \STATE \hspace{1em}$\theta_0 \gets \theta_0 - \eta \nabla_{\theta_0} L_{\cT} $
   
%    \STATE \hspace{1em}$\Theta\gets\left[{\theta_1}-{\theta_0},\dots,{\theta_K}-{\theta_0} \right]^T$
   
%    \STATE \hspace{1em}${J}({\theta_0}) \gets ( \nabla_{\theta_0} L_{\cT})( \nabla_{\theta_0} L_{\cT})^T$
   
    
%    % \STATE \hspace{1em}$\alpha \gets\argmin\left(\sum\limits_{i=1}^{K}\alpha_i({\theta_i}-{\theta_0})\right)^T{J}({\theta_0})\left(\sum\limits_{i=1}^{K}\alpha_i({\theta_i}-{\theta_0})\right)$
   
   
%    \STATE \hspace{1em}$\alpha^* \gets \argmin\limits_{\alpha} \alpha^T\Theta^T{J}({\theta_0})\Theta\alpha $
%    % \STATE \hspace{1em}\hspace{1em}\hspace{1em} when $\sum\limits_{k=1}^K \alpha_k = 1 $
%    \STATE \hspace{1em}$r^* \gets \alpha^{*^T}\Theta^T{J}({\theta_0})\Theta\alpha^*$
%    \STATE \hspace{1em}$s^* \gets \argmin\limits_{s} \frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^2}\frac{r^*}{d}\right)\nonumber$ 
%    % \STATE \hspace{1em}$m \gets \alpha s$
%    % \STATE \hspace{1em}$L_{O^t} \gets \frac{1}{N_{O^t}} \sum\limits_{i=1}^{N_{O^t}} L_{O^t}^i $
%     \STATE \hspace{1em}$D_{source} \gets $for $k=1,\dots,K$, $s^*\alpha_k^*$ samples from $D_{S_k}$ respectively.
    
%    \STATE \hspace{1em}$D_{train} \gets D_{source}+D_\cT = \{(x^i, y^i)\}_{i=1}^{N_{train}}$
   
%    \STATE \textbf{until} $\theta_{0}$ converges;
  
  
% \end{algorithmic}
% \end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%↓↓↓↓2025_1_18版本↓↓↓↓%%%%%%%%%%%%%%%%%
% \begin{algorithm}[htbp]
%    \caption{\ourmethod{}: Classification task training}
%    \label{alg:ours_algorithm}
% \begin{algorithmic}
% \STATE {\bfseries Input:} Target data $D_O=\{(x_O^i, y_O^i)\}_{i=1}^{N_O}$, data distribution $\theta_O$ and training loss $L_O$, source data $\{D_{S_j}=\{(x_{S_j}^i, y_{S_j}^i)\}_{i=1}^{N_{S_j}}\}_{j=1}^K$, data distribution $\{\theta_{S_j}\}_{j=1}^K$ and training loss $\{L_j\}_{j=1}^K$, model type $f$ and its parameters dimension $d$, epoch $t$, picked samples task ratio $\alpha$, all picked samples $S$.
%    \STATE {\bfseries Parameter:} Learning rate $\eta$.
%    \STATE {\bfseries Output:} source weight $\alpha$, source picked samples $S$.
%    \STATE Initialize $m=\textbf{0}$ and randomly initialize $\theta_O$, $\{\theta_{S_j}\}_{j=1}^K$.

%    % \STATE \textbf{for} $y = 1$ {\bfseries to} $d_T$ \textbf{do} \mycomment{Simulate source data distribution}
   
%    \STATE \textbf{for} $k = 1$ {\bfseries to} $K$ \textbf{do} \mycomment{Simulate source data distribution}
%    \STATE \hspace{1em} $t \gets 0$
%    \STATE \hspace{1em} \textbf{repeat}
%    \STATE \hspace{1em} \hspace{1em}$L_{k^t} \gets - \frac{1}{N_{S_k}} \sum\limits_{i=1}^{N_{S_k}} \log \frac{\exp(f_{\theta_{S_k}}(x_{S_k}^i)_{y_{S_k}^i})}{\sum\limits_j \exp(f_{\theta_{S_k}}(x_{S_k}^i)_j)}$
%    \STATE \hspace{1em} \hspace{1em}$\theta_{S_k} \gets \theta_{S_k} - \eta \nabla_{\theta_{S_k}} L_{k^t}$
%    \STATE \hspace{1em} \hspace{1em}$t \gets t + 1$
%    \STATE \hspace{1em}\textbf{until} $L_{k^t} \geq L_{k^{t-1}}$
%    \STATE \textbf{end for}
%    \STATE $t \gets 0$
%    \STATE \textbf{repeat} \mycomment{Weighted sampling training per epoch}
%    \STATE \hspace{1em}$D_O^t \gets m+D_O = \{(x^i, y^i)\}_{i=1}^{N_{O^t}}$
%    \STATE \hspace{1em}\textbf{for} i=1 \textbf{to} $N_{O^t}$ \textbf{do} \mycomment{Compute loss and gradient}
%    % \STATE \textbf{for} $i = 1$ {\bfseries to} $N_T$ \textbf{do} \mycomment{Train the target model}
%    \STATE \hspace{1em}\hspace{1em}$L_{O^t}^i \gets - \log \frac{\exp(f_{\theta_O}(x^i)_{y^i})}{\sum\limits_j \exp(f_{\theta_O}(x^i)_j)}$
%    \STATE \hspace{1em}\hspace{1em}$J_{\theta_O}^i \gets ( \nabla_{\theta_O} L_{O^t}^i)( \nabla_{\theta_T} L_{O^t}^i)^T$
%    \STATE \hspace{1em}\textbf{end for}
   
%    \STATE \hspace{1em}$\alpha \gets \argmin\limits_{\alpha} \alpha^T \left (\sum\limits_{i=1}^{N_{O^t}} \sum\limits_{k=1}^K (\theta_k - \theta_O) J_{\theta_O}^i (\theta_k - \theta_O)^T \right) \alpha, $
%    \STATE \hspace{1em}\hspace{1em}\hspace{1em} when $\sum\limits_{k=1}^K \alpha_k = 1 $
%    \STATE \hspace{1em}$r \gets tr\left(\alpha^T \left (\sum\limits_{i=1}^{N_{O^t}} \sum\limits_{k=1}^K (\theta_k - \theta_O) J_{\theta_O}^i (\theta_k - \theta_O)^T \right) \alpha\right)$
%    \STATE \hspace{1em}$S \gets \argmin\limits_{S} \frac{d}{2}\left(\frac{1}{N_O+S}+\frac{S^2}{d(N_O+S)^2}r\right)\nonumber$
%    \STATE \hspace{1em}$m \gets \alpha S$
%    \STATE \hspace{1em}$L_{O^t} \gets \frac{1}{N_{O^t}} \sum\limits_{i=1}^{N_{O^t}} L_{O^t}^i $
%    \STATE \hspace{1em}$\theta_O \gets \theta_O - \eta \nabla_{\theta_O} L_{O^t} $
%    \STATE \hspace{1em}$t \gets t+1$
%    \STATE \textbf{until} $L_{O^t} \geq  L_{O^{t-1}} $
% \end{algorithmic}
% \end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%↑↑↑↑2025_1_18版本↑↑↑↑%%%%%%%%%%%%%%%%%



% \begin{algorithm}[htbp]
%    \caption{\ourmethod{}: Training}
%    \label{alg:ours_algorithm}
% \begin{algorithmic}
%    \STATE {\bfseries Input:} Target data $D_T = \{(x_T^i, y_T^i)\}_{i=1}^{N_T}$, source data $\{D_{S_j}\}_{j=1}^M$
%    \STATE {\bfseries Parameter:} Learning rate $\lambda$
%    \STATE {\bfseries Output:} Target classifier $g_T$, source weight $\alpha$
%    \STATE Randomly initialize $\alpha = \{\alpha_1, \alpha_2, \ldots, \alpha_M\}$, $\sum_{j=1}^M \alpha_j = 1$

%    \STATE \textbf{for} $y = 1$ {\bfseries to} $d_T$ \textbf{do} \mycomment{Simulate source data distribution}
%    \STATE \hspace*{1em} $n_y \gets \sum_{i=1}^{N_T} \mathbb{I}\{y = y_T^i\}$
%    % \STATE \hspace*{1em} $\mathbb{E}_{P_X^T|Y} \left[ f_{S_j}(X_T) \mid Y_T = y \right] \gets \frac{1}{n_y} \sum_{i=1}^{N_T} f_{S_j}(x_T^i) \cdot \mathbb{I}\{y = y_T^i\}, \; j = 1, \ldots, M$
%    \STATE \hspace*{1em} \parbox[t]{\dimexpr\textwidth-2em}{%
%        $\mathbb{E}_{P_X^T|Y} \left[ f_{S_j}(X_T) \mid Y_T = y \right] \gets \frac{1}{n_y} \sum_{i=1}^{N_T} f_{S_j}(x_T^i) \cdot \mathbb{I}\{y = y_T^i\}, \; j = 1, \ldots, M$
%    }
%    \STATE \textbf{end for}

%    \STATE \textbf{for} $y = 1$ {\bfseries to} $d_T$ \textbf{do} \mycomment{get the m samples}
%    \STATE \hspace*{1em} $n_y \gets \sum_{i=1}^{N_T} \mathbb{I}\{y = y_T^i\}$
%    % \STATE \hspace*{1em} $\mathbb{E}_{P_X^T|Y} \left[ f_{S_j}(X_T) \mid Y_T = y \right] \gets \frac{1}{n_y} \sum_{i=1}^{N_T} f_{S_j}(x_T^i) \cdot \mathbb{I}\{y = y_T^i\}, \; j = 1, \ldots, M$
%    \STATE \hspace*{1em} \parbox[t]{\dimexpr\textwidth-2em}{%
%        $\mathbb{E}_{P_X^T|Y} \left[ f_{S_j}(X_T) \mid Y_T = y \right] \gets \frac{1}{n_y} \sum_{i=1}^{N_T} f_{S_j}(x_T^i) \cdot \mathbb{I}\{y = y_T^i\}, \; j = 1, \ldots, M$
%    }
%    \STATE \textbf{end for}

%    \STATE \textbf{repeat} \mycomment{Repeat until convergence}
%    \STATE \hspace*{1em} $H(f_T; \alpha) \gets \text{tr}\left(\text{cov}\left(\sum_{j=1}^M \alpha_j \mathbb{E}_{P_X^T|Y}\left[f_{S_j}(X_T) \mid Y_T\right]\right)\right)$
%    \STATE \hspace*{1em} $\alpha \gets \alpha + \lambda \nabla_\alpha H(f_T; \alpha)$ 

%    \STATE \hspace*{1em} \textbf{for} $j = 1$ {\bfseries to} $M$
%    \STATE \hspace*{1em} \hspace*{1em} $\alpha_j \gets \alpha_j - \frac{1}{M} \sum_{j=1}^M \alpha_j + \frac{1}{M}$
%    \STATE \hspace*{1em} \textbf{end for}
%    \STATE \textbf{until} $\alpha$ converges

%    \STATE \textbf{for} $y = 1$ {\bfseries to} $d_T$
%    \STATE \hspace*{1em} $g_T(y) \gets \sum_{j=1}^M \alpha_j \cdot \mathbb{E}_{P_X|Y}\left[f_{S_j}(X_T) \mid Y_T = y\right]$
%    \STATE \textbf{end for}

% \end{algorithmic}
% \end{algorithm}

% \section{Experiments}
\input{hgb_section/experiments.tex}

\section{Conclusion}

In this work, we propose a theoretical framework to determine
the optimal transfer quantities in multi-source transfer learning. 
Our framework reveals that by optimizing the transfer quantity of each source task, we can improve target task training while reducing the total transfer quantity. 
Based on this theoretical framework, we develop an architecture-agnostic
and data-efficient practical algorithm \ourmethod{} for jointly training the target model. 
We evaluated the proposed algorithm through extensive experiments and demonstrated its superior accuracy and enhanced data efficiency.

%↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓我理解是这东西单独放第九页？？？↓↓↓↓↓↓↓↓↓
%Authors are required to include a statement of the potential broader impact of their work, including its ethical aspects and future societal consequences. This statement should be in a separate section at the end of the paper (co-located with Acknowledgements, before References), and does not count toward the paper page limit. In many cases, where the ethical impacts and expected societal implications are those that are well established when advancing the field of Machine Learning, substantial discussion is not required, and a simple statement such as: 
\section*{lmpact Statement}
This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here.
% Submission to ICML 2025 will be entirely electronic, via a web site
% (not email). Information about the submission process and \LaTeX\ templates
% are available on the conference web site at:
% \begin{center}
% \textbf{\texttt{http://icml.cc/}}
% \end{center}

% The guidelines below will be enforced for initial submissions and
% camera-ready copies. Here is a brief summary:
% \begin{itemize}
% \item Submissions must be in PDF\@. 
% \item If your paper has appendices, submit the appendix together with the main body and the references \textbf{as a single file}. Reviewers will not look for appendices as a separate PDF file. So if you submit such an extra file, reviewers will very likely miss it.
% \item Page limit: The main body of the paper has to be fitted to 8 pages, excluding references and appendices; the space for the latter two is not limited in pages, but the total file size may not exceed 10MB. For the final version of the paper, authors can add one extra page to the main body.
% \item \textbf{Do not include author information or acknowledgements} in your
%     initial submission.
% \item Your paper should be in \textbf{10 point Times font}.
% \item Make sure your PDF file only uses Type-1 fonts.
% \item Place figure captions \emph{under} the figure (and omit titles from inside
%     the graphic file itself). Place table captions \emph{over} the table.
% \item References must include page numbers whenever possible and be as complete
%     as possible. Place multiple citations in chronological order.
% \item Do not alter the style template; in particular, do not compress the paper
%     format by reducing the vertical spaces.
% \item Keep your abstract brief and self-contained, one paragraph and roughly
%     4--6 sentences. Gross violations will require correction at the
%     camera-ready phase. The title should have content words capitalized.
% \end{itemize}

% \subsection{Submitting Papers}

% \textbf{Anonymous Submission:} ICML uses double-blind review: no identifying
% author information may appear on the title page or in the paper
% itself. \cref{author info} gives further details.

% \medskip

% Authors must provide their manuscripts in \textbf{PDF} format.
% Furthermore, please make sure that files contain only embedded Type-1 fonts
% (e.g.,~using the program \texttt{pdffonts} in linux or using
% File/DocumentProperties/Fonts in Acrobat). Other fonts (like Type-3)
% might come from graphics files imported into the document.

% Authors using \textbf{Word} must convert their document to PDF\@. Most
% of the latest versions of Word have the facility to do this
% automatically. Submissions will not be accepted in Word format or any
% format other than PDF\@. Really. We're not joking. Don't send Word.

% Those who use \textbf{\LaTeX} should avoid including Type-3 fonts.
% Those using \texttt{latex} and \texttt{dvips} may need the following
% two commands:

% {\footnotesize
% \begin{verbatim}
% dvips -Ppdf -tletter -G0 -o paper.ps paper.dvi
% ps2pdf paper.ps
% \end{verbatim}}
% It is a zero following the ``-G'', which tells dvips to use
% the config.pdf file. Newer \TeX\ distributions don't always need this
% option.

% Using \texttt{pdflatex} rather than \texttt{latex}, often gives better
% results. This program avoids the Type-3 font problem, and supports more
% advanced features in the \texttt{microtype} package.

% \textbf{Graphics files} should be a reasonable size, and included from
% an appropriate format. Use vector formats (.eps/.pdf) for plots,
% lossless bitmap formats (.png) for raster graphics with sharp lines, and
% jpeg for photo-like images.

% The style file uses the \texttt{hyperref} package to make clickable
% links in documents. If this causes problems for you, add
% \texttt{nohyperref} as one of the options to the \texttt{icml2025}
% usepackage statement.


% \subsection{Submitting Final Camera-Ready Copy}

% The final versions of papers accepted for publication should follow the
% same format and naming convention as initial submissions, except that
% author information (names and affiliations) should be given. See
% \cref{final author} for formatting instructions.

% The footnote, ``Preliminary work. Under review by the International
% Conference on Machine Learning (ICML). Do not distribute.'' must be
% modified to ``\textit{Proceedings of the
% $\mathit{42}^{nd}$ International Conference on Machine Learning},
% Vancouver, Canada, PMLR 267, 2025.
% Copyright 2025 by the author(s).''

% For those using the \textbf{\LaTeX} style file, this change (and others) is
% handled automatically by simply changing
% $\mathtt{\backslash usepackage\{icml2025\}}$ to
% $$\mathtt{\backslash usepackage[accepted]\{icml2025\}}$$
% Authors using \textbf{Word} must edit the
% footnote on the first page of the document themselves.

% Camera-ready copies should have the title of the paper as running head
% on each page except the first one. The running title consists of a
% single line centered above a horizontal rule which is $1$~point thick.
% The running head should be centered, bold and in $9$~point type. The
% rule should be $10$~points above the main text. For those using the
% \textbf{\LaTeX} style file, the original title is automatically set as running
% head using the \texttt{fancyhdr} package which is included in the ICML
% 2025 style file package. In case that the original title exceeds the
% size restrictions, a shorter form can be supplied by using

% \verb|\icmltitlerunning{...}|

% just before $\mathtt{\backslash begin\{document\}}$.
% Authors using \textbf{Word} must edit the header of the document themselves.

% \section{Format of the Paper}

% All submissions must follow the specified format.

% \subsection{Dimensions}




% The text of the paper should be formatted in two columns, with an
% overall width of 6.75~inches, height of 9.0~inches, and 0.25~inches
% between the columns. The left margin should be 0.75~inches and the top
% margin 1.0~inch (2.54~cm). The right and bottom margins will depend on
% whether you print on US letter or A4 paper, but all final versions
% must be produced for US letter size.
% Do not write anything on the margins.

% The paper body should be set in 10~point type with a vertical spacing
% of 11~points. Please use Times typeface throughout the text.

% \subsection{Title}

% The paper title should be set in 14~point bold type and centered
% between two horizontal rules that are 1~point thick, with 1.0~inch
% between the top rule and the top edge of the page. Capitalize the
% first letter of content words and put the rest of the title in lower
% case.

% \subsection{Author Information for Submission}
% \label{author info}

% ICML uses double-blind review, so author information must not appear. If
% you are using \LaTeX\/ and the \texttt{icml2025.sty} file, use
% \verb+\icmlauthor{...}+ to specify authors and \verb+\icmlaffiliation{...}+ to specify affiliations. (Read the TeX code used to produce this document for an example usage.) The author information
% will not be printed unless \texttt{accepted} is passed as an argument to the
% style file.
% Submissions that include the author information will not
% be reviewed.

% \subsubsection{Self-Citations}

% If you are citing published papers for which you are an author, refer
% to yourself in the third person. In particular, do not use phrases
% that reveal your identity (e.g., ``in previous work \cite{langley00}, we
% have shown \ldots'').

% Do not anonymize citations in the reference section. The only exception are manuscripts that are
% not yet published (e.g., under submission). If you choose to refer to
% such unpublished manuscripts \cite{anonymous}, anonymized copies have
% to be submitted
% as Supplementary Material via OpenReview\@. However, keep in mind that an ICML
% paper should be self contained and should contain sufficient detail
% for the reviewers to evaluate the work. In particular, reviewers are
% not required to look at the Supplementary Material when writing their
% review (they are not required to look at more than the first $8$ pages of the submitted document).

% \subsubsection{Camera-Ready Author Information}
% \label{final author}

% If a paper is accepted, a final camera-ready copy must be prepared.
% %
% For camera-ready papers, author information should start 0.3~inches below the
% bottom rule surrounding the title. The authors' names should appear in 10~point
% bold type, in a row, separated by white space, and centered. Author names should
% not be broken across lines. Unbolded superscripted numbers, starting 1, should
% be used to refer to affiliations.

% Affiliations should be numbered in the order of appearance. A single footnote
% block of text should be used to list all the affiliations. (Academic
% affiliations should list Department, University, City, State/Region, Country.
% Similarly for industrial affiliations.)

% Each distinct affiliations should be listed once. If an author has multiple
% affiliations, multiple superscripts should be placed after the name, separated
% by thin spaces. If the authors would like to highlight equal contribution by
% multiple first authors, those authors should have an asterisk placed after their
% name in superscript, and the term ``\textsuperscript{*}Equal contribution"
% should be placed in the footnote block ahead of the list of affiliations. A
% list of corresponding authors and their emails (in the format Full Name
% \textless{}email@domain.com\textgreater{}) can follow the list of affiliations.
% Ideally only one or two names should be listed.

% A sample file with author names is included in the ICML2025 style file
% package. Turn on the \texttt{[accepted]} option to the stylefile to
% see the names rendered. All of the guidelines above are implemented
% by the \LaTeX\ style file.

% \subsection{Abstract}

% The paper abstract should begin in the left column, 0.4~inches below the final
% address. The heading `Abstract' should be centered, bold, and in 11~point type.
% The abstract body should use 10~point type, with a vertical spacing of
% 11~points, and should be indented 0.25~inches more than normal on left-hand and
% right-hand margins. Insert 0.4~inches of blank space after the body. Keep your
% abstract brief and self-contained, limiting it to one paragraph and roughly 4--6
% sentences. Gross violations will require correction at the camera-ready phase.

% \subsection{Partitioning the Text}

% You should organize your paper into sections and paragraphs to help
% readers place a structure on the material and understand its
% contributions.

% \subsubsection{Sections and Subsections}

% Section headings should be numbered, flush left, and set in 11~pt bold
% type with the content words capitalized. Leave 0.25~inches of space
% before the heading and 0.15~inches after the heading.

% Similarly, subsection headings should be numbered, flush left, and set
% in 10~pt bold type with the content words capitalized. Leave
% 0.2~inches of space before the heading and 0.13~inches afterward.

% Finally, subsubsection headings should be numbered, flush left, and
% set in 10~pt small caps with the content words capitalized. Leave
% 0.18~inches of space before the heading and 0.1~inches after the
% heading.

% Please use no more than three levels of headings.

% \subsubsection{Paragraphs and Footnotes}

% Within each section or subsection, you should further partition the
% paper into paragraphs. Do not indent the first line of a given
% paragraph, but insert a blank line between succeeding ones.

% You can use footnotes\footnote{Footnotes
% should be complete sentences.} to provide readers with additional
% information about a topic without interrupting the flow of the paper.
% Indicate footnotes with a number in the text where the point is most
% relevant. Place the footnote in 9~point type at the bottom of the
% column in which it appears. Precede the first footnote in a column
% with a horizontal rule of 0.8~inches.\footnote{Multiple footnotes can
% appear in each column, in the same order as they appear in the text,
% but spread them across columns and pages if possible.}

% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\columnwidth]{icml_numpapers}}
% \caption{Historical locations and number of accepted papers for International
% Machine Learning Conferences (ICML 1993 -- ICML 2008) and International
% Workshops on Machine Learning (ML 1988 -- ML 1992). At the time this figure was
% produced, the number of accepted papers for ICML 2008 was unknown and instead
% estimated.}
% \label{icml-historical}
% \end{center}
% \vskip -0.2in
% \end{figure}

% \subsection{Figures}

% You may want to include figures in the paper to illustrate
% your approach and results. Such artwork should be centered,
% legible, and separated from the text. Lines should be dark and at
% least 0.5~points thick for purposes of reproduction, and text should
% not appear on a gray background.

% Label all distinct components of each figure. If the figure takes the
% form of a graph, then give a name for each axis and include a legend
% that briefly describes each curve. Do not include a title inside the
% figure; instead, the caption should serve this function.

% Number figures sequentially, placing the figure number and caption
% \emph{after} the graphics, with at least 0.1~inches of space before
% the caption and 0.1~inches after it, as in
% \cref{icml-historical}. The figure caption should be set in
% 9~point type and centered unless it runs two or more lines, in which
% case it should be flush left. You may float figures to the top or
% bottom of a column, and you may set wide figures across both columns
% (use the environment \texttt{figure*} in \LaTeX). Always place
% two-column figures at the top or bottom of the page.

% \subsection{Algorithms}

% If you are using \LaTeX, please use the ``algorithm'' and ``algorithmic''
% environments to format pseudocode. These require
% the corresponding stylefiles, algorithm.sty and
% algorithmic.sty, which are supplied with this package.
% \cref{alg:example} shows an example.

% \begin{algorithm}[tb]
%    \caption{Bubble Sort}
%    \label{alg:example}
% \begin{algorithmic}
%    \STATE {\bfseries Input:} data $x_i$, size $m$
%    \REPEAT
%    \STATE Initialize $noChange = true$.
%    \FOR{$i=1$ {\bfseries to} $m-1$}
%    \IF{$x_i > x_{i+1}$}
%    \STATE Swap $x_i$ and $x_{i+1}$
%    \STATE $noChange = false$
%    \ENDIF
%    \ENDFOR
%    \UNTIL{$noChange$ is $true$}
% \end{algorithmic}
% \end{algorithm}

% \subsection{Tables}

% You may also want to include tables that summarize material. Like
% figures, these should be centered, legible, and numbered consecutively.
% However, place the title \emph{above} the table with at least
% 0.1~inches of space before the title and the same after it, as in
% \cref{sample-table}. The table title should be set in 9~point
% type and centered unless it runs two or more lines, in which case it
% should be flush left.

% % Note use of \abovespace and \belowspace to get reasonable spacing
% % above and below tabular lines.

% \begin{table}[t]
% \caption{Classification accuracies for naive Bayes and flexible
% Bayes on various data sets.}
% \label{sample-table}
% \vskip 0.15in
% \begin{center}
% \begin{small}
% \begin{sc}
% \begin{tabular}{lcccr}
% \toprule
% Data set & Naive & Flexible & Better? \\
% \midrule
% Breast    & 95.9$\pm$ 0.2& 96.7$\pm$ 0.2& $\surd$ \\
% Cleveland & 83.3$\pm$ 0.6& 80.0$\pm$ 0.6& $\times$\\
% Glass2    & 61.9$\pm$ 1.4& 83.8$\pm$ 0.7& $\surd$ \\
% Credit    & 74.8$\pm$ 0.5& 78.3$\pm$ 0.6&         \\
% Horse     & 73.3$\pm$ 0.9& 69.7$\pm$ 1.0& $\times$\\
% Meta      & 67.1$\pm$ 0.6& 76.5$\pm$ 0.5& $\surd$ \\
% Pima      & 75.1$\pm$ 0.6& 73.9$\pm$ 0.5&         \\
% Vehicle   & 44.9$\pm$ 0.6& 61.5$\pm$ 0.4& $\surd$ \\
% \bottomrule
% \end{tabular}
% \end{sc}
% \end{small}
% \end{center}
% \vskip -0.1in
% \end{table}

% Tables contain textual material, whereas figures contain graphical material.
% Specify the contents of each row and column in the table's topmost
% row. Again, you may float tables to a column's top or bottom, and set
% wide tables across both columns. Place two-column tables at the
% top or bottom of the page.

% \subsection{Theorems and such}
% The preferred way is to number definitions, propositions, lemmas, etc. consecutively, within sections, as shown below.
% \begin{definition}
% \label{def:inj}
% A function $f:X \to Y$ is injective if for any $x,y\in X$ different, $f(x)\ne f(y)$.
% \end{definition}
% Using \cref{def:inj} we immediate get the following result:
% \begin{proposition}
% If $f$ is injective mapping a set $X$ to another set $Y$, 
% the cardinality of $Y$ is at least as large as that of $X$
% \end{proposition}
% \begin{proof} 
% Left as an exercise to the reader. 
% \end{proof}
% \cref{lem:usefullemma} stated next will prove to be useful.
% \begin{lemma}
% \label{lem:usefullemma}
% For any $f:X \to Y$ and $g:Y\to Z$ injective functions, $f \circ g$ is injective.
% \end{lemma}
% \begin{theorem}
% \label{thm:bigtheorem}
% If $f:X\to Y$ is bijective, the cardinality of $X$ and $Y$ are the same.
% \end{theorem}
% An easy corollary of \cref{thm:bigtheorem} is the following:
% \begin{corollary}
% If $f:X\to Y$ is bijective, 
% the cardinality of $X$ is at least as large as that of $Y$.
% \end{corollary}
% \begin{assumption}
% The set $X$ is finite.
% \label{ass:xfinite}
% \end{assumption}
% \begin{remark}
% According to some, it is only the finite case (cf. \cref{ass:xfinite}) that is interesting.
% \end{remark}
% %restatable

% \subsection{Citations and References}

% Please use APA reference format regardless of your formatter
% or word processor. If you rely on the \LaTeX\/ bibliographic
% facility, use \texttt{natbib.sty} and \texttt{icml2025.bst}
% included in the style-file package to obtain this format.

% Citations within the text should include the authors' last names and
% year. If the authors' names are included in the sentence, place only
% the year in parentheses, for example when referencing Arthur Samuel's
% pioneering work \yrcite{Samuel59}. Otherwise place the entire
% reference in parentheses with the authors and year separated by a
% comma \cite{Samuel59}. List multiple references separated by
% semicolons \cite{kearns89,Samuel59,mitchell80}. Use the `et~al.'
% construct only for citations with three or more authors or after
% listing all authors to a publication in an earlier reference \cite{MachineLearningI}.

% Authors should cite their own work in the third person
% in the initial version of their paper submitted for blind review.
% Please refer to \cref{author info} for detailed instructions on how to
% cite your own papers.

% Use an unnumbered first-level section heading for the references, and use a
% hanging indent style, with the first line of the reference flush against the
% left margin and subsequent lines indented by 10 points. The references at the
% end of this document give examples for journal articles \cite{Samuel59},
% conference publications \cite{langley00}, book chapters \cite{Newell81}, books
% \cite{DudaHart2nd}, edited volumes \cite{MachineLearningI}, technical reports
% \cite{mitchell80}, and dissertations \cite{kearns89}.

% Alphabetize references by the surnames of the first authors, with
% single author entries preceding multiple author entries. Order
% references for the same authors by year of publication, with the
% earliest first. Make sure that each reference includes all relevant
% information (e.g., page numbers).

% Please put some effort into making references complete, presentable, and
% consistent, e.g. use the actual current name of authors.
% If using bibtex, please protect capital letters of names and
% abbreviations in titles, for example, use \{B\}ayesian or \{L\}ipschitz
% in your .bib file.

% \section*{Accessibility}
% Authors are kindly asked to make their submissions as accessible as possible for everyone including people with disabilities and sensory or neurological differences.
% Tips of how to achieve this and what to pay attention to will be provided on the conference website \url{http://icml.cc/}.

% \section*{Software and Data}

% If a paper is accepted, we strongly encourage the publication of software and data with the
% camera-ready version of the paper whenever appropriate. This can be
% done by including a URL in the camera-ready copy. However, \textbf{do not}
% include URLs that reveal your institution or identity in your
% submission for review. Instead, provide an anonymous URL or upload
% the material as ``Supplementary Material'' into the OpenReview reviewing
% system. Note that reviewers are not required to look at this material
% when writing their review.

% % Acknowledgements should only appear in the accepted version.
% \section*{Acknowledgements}

% \textbf{Do not} include acknowledgements in the initial version of
% the paper submitted for blind review.

% If a paper is accepted, the final camera-ready version can (and
% usually should) include acknowledgements.  Such acknowledgements
% should be placed at the end of the section, in an unnumbered section
% that does not count towards the paper page limit. Typically, this will 
% include thanks to reviewers who gave useful comments, to colleagues 
% who contributed to the ideas, and to funding agencies and corporate 
% sponsors that provided financial support.

% \section*{Impact Statement}

% Authors are \textbf{required} to include a statement of the potential 
% broader impact of their work, including its ethical aspects and future 
% societal consequences. This statement should be in an unnumbered 
% section at the end of the paper (co-located with Acknowledgements -- 
% the two may appear in either order, but both must be before References), 
% and does not count toward the paper page limit. In many cases, where 
% the ethical impacts and expected societal implications are those that 
% are well established when advancing the field of Machine Learning, 
% substantial discussion is not required, and a simple statement such 
% as the following will suffice:

% ``This paper presents work whose goal is to advance the field of 
% Machine Learning. There are many potential societal consequences 
% of our work, none which we feel must be specifically highlighted here.''

% The above statement can be used verbatim in such cases, but we 
% encourage authors to think about whether there is content which does 
% warrant further discussion, as this statement will be apparent if the 
% paper is later flagged for ethics review.


% In the unusual situation where you want a paper to appear in the





% references without citing it in the main text, use \nocite
\nocite{langley00}
% \clearpage
\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn



\section{Notations}
\label{appendix:Notations}
\begin{table*}[h]
  \setlength{\tabcolsep}{20pt}
  \renewcommand{\arraystretch}{1.2}
  \centering
  \begin{adjustbox}{max width=\textwidth}
  \begin{tabular}{lcr}
    \textbf{Symbol} & \textbf{Description} 
    \\
    $\cT$ & \text{target task} 
    \\
    $\left\{\cS_1,\dots,\cS_K\right\}$ & \text{source tasks} 
    \\
    $N_0$ & \text{ quantity of target samples}
    \\
    $N_1 \cdots N_k$ & \text{maximum sample quantity of each source}
    \\
    $n_1 \cdots n_k$ & \text{transfer quantity of each source} 
     \\
    $\theta$ & model parameter\\
    $\underline{\theta}$ &  vectorized model parameter \\
    $\underline{\theta}_0$ &  vectorized model parameter of target task\\
    $\underline{\theta}_i, i\in[1,K]$ &  vectorized model parameter of i-th source task, \\
    $J(\theta)$  & Fisher information (scalar) of $\theta$ \\
    $J(\underline{\theta})^{d \times d}$  & Fisher information (matrix) of d-dimensional $\underline{\theta}$ \\
    $P(X;\theta)$ & probability of X parameterized by $\theta$ \\
    $P_{X;\theta}$  & distribution of X parameterized by $\theta$  \\
    $|| \underline{x} ||^2$ & l-2 norm of vector x \\
    % $t(\theta_0, \theta_1, d)$ & task similarity \\
    $\alpha_i$ & transfer proportion in multi-source case from i-th source task\\
    $\underline{\alpha}$ & transfer proportion vector in multi-source case whose i-th entry is $\alpha_i$\\
    $s$ & total transfer quantity in multi-source case
    \\
    $\hat{\theta}$ & estimator of $\theta$ 
    \\
    $E_{\hat{\theta}}$ & expectation of $\hat{\theta}$ 
  \end{tabular}
  \end{adjustbox}
  \caption{Notations}
  \label{Notations}
\end{table*}

\newpage
\section{Proofs}

% You can have as much text here as you want. The main body must be at most $8$ pages long.
% For the final version, one more page can be added.
% If you want, you can use an appendix like this one.  

% The $\mathtt{\backslash onecolumn}$ command above can be kept in place if you prefer a one-column appendix, or can be removed if you prefer a two-column appendix.  Apart from this possible change, the style (font size, spacing, margins, page numbering, etc.) should be kept the same as the main body.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Proof of Lemma~\ref{thm:target_only}} \label{appendix:target_only}


\begin{lemma}\label{thm:kl2mse}

    

In the asymptotic case, the K-L measure \eqref{eq:KL1} and the mean squared error have the relation as follows.
\begin{align}\label{eq:kl2mse}
&\mathbb{E} \left[ D\left(P_{X;\hat{\theta}} \middle\| P_{X;\theta_0}\right) \right]\notag\\&=\frac{1}{2} {J}(\theta_0)  \text{MSE}(\hat{\theta})+o(\frac{1}{N_0}),
\end{align}
\end{lemma}
\begin{proof}
In this section, for the sake of clarity, we will write $ \hat{\theta}$ in its parameterized form $\hat{\theta}(X^{N_0})$ when necessary, and these two forms are mathematically equivalent.
%First, we assume that $\|\hat{\theta}(X^{N_0}) - \theta_0\|^2=\epsilon^2$. 
By taking Taylor expansion of $D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right)$ at $\theta_0$, we can get
\begin{align}
\label{appendix:taylor1}
D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right)= \frac{1}{2} \sum_{x\in X} \frac{\left(P_{X;\hat{\theta}(X^{N_0})}(x) - P_{X;\theta_0}(x)\right)^2}{P_{X;\theta_0}(x)}+o(\|\hat{\theta}(X^{N_0}) - \theta_0\|^2)  
\end{align}
                                                                                           
We denote $\delta$ as a small constant,  and we can rewrite \eqref{eq:KL1} as 
\begin{align}
\label{appendix:expect}
&\mathbb{E} \left[ D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right) \right] \notag\\ 
&= \sum_{X^{N_0}}P_{X^n;\theta_0}(X^{N_0})D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right)
\notag\\ 
&= \sum_{X^{N_0}}P_{X^n;\theta_0}(X^{N_0}) \left (  \frac{1}{2} \sum_{x\in X} \frac{\left(P_{X;\hat{\theta}(X^{N_0})}(x) - P_{X;\theta_0}(x)\right)^2}{P_{X;\theta_0}(x)}+o(\|\hat{\theta}(X^{N_0}) - \theta_0\|^2) \right )
\notag\\ 
&= \sum_{X^{N_0}}P_{X^n;\theta_0}(X^{N_0})\left (  \frac{1}{2} \sum_{x\in X} \frac{ \left(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0} (\hat{\theta}(X^{N_0}) - \theta_0)\right)^2}{P_{X;\theta_0}(x)}+o(\|\hat{\theta}(X^{N_0}) - \theta_0\|^2) \right)
\notag\\ 
% &= \sum_{\left\{X^{N_0}:D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right)<\delta\right\}}P_{X^n;\theta_0}(X^{N_0})D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right)\notag\\ 
%  &+\sum_{\left\{X^{N_0}:D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right)\ge\delta\right\}}P_{X^n;\theta_0}(X^{N_0})D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right)
% \notag\\ 
    &= \sum_{\left\{X^{N_0}:\|\hat{\theta}(X^{N_0}) - \theta_0\|^2<\delta\right\}}P_{X^n;\theta_0}(X^{N_0}) \left ( \frac{1}{2} \sum_{x\in X} \frac{ \left(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0} (\hat{\theta}(X^{N_0}) - \theta_0)\right)^2}{P_{X;\theta_0}(x)}+o(\|\hat{\theta}(X^{N_0}) - \theta_0\|^2) \right)\notag\\ 
    &+\sum_{\left\{X^{N_0}:\|\hat{\theta}(X^{N_0}) - \theta_0\|^2\ge\delta\right\}}P_{X^n;\theta_0}(X^{N_0})
    \left (  \frac{1}{2} \sum_{x\in X} \frac{ \left(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0} (\hat{\theta}(X^{N_0}) - \theta_0)\right)^2}{P_{X;\theta_0}(x)}+o(\|\hat{\theta}(X^{N_0}) - \theta_0\|^2)\right)\notag\\ 
\end{align}
To facilitate the subsequent proof, we introduce the concept of "Dot Equal".
\begin{definition}(Dot Equal (\(\dot{=}\)))
    Specifically, given two functions \( f(n) \) and \( g(n) \), the notation \( f(n) \dot{=} g(n) \) is defined as
\begin{align}
    f(n) \dot{=} g(n) \quad \Leftrightarrow \quad \lim_{n \to \infty} \frac{1}{n}\log\frac{f(n)}{g(n)} = 0,
\end{align}
which shows that $f(n)$ and $g(n)$ have the same exponential decaying rate.
\end{definition}




We denote $\hat{P}_{X^{N_0}}$ as the empirical distribution of $X^{N_0}$. Applying Sanov's Theorem to \eqref{appendix:expect}, we can know that
\begin{align}
\label{appendix:dotequal_1}
% &\mathbb{E} \left[ D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right) \right] \notag\\ 
% &=\sum_{\hat{\theta},\|\hat{\theta}(X^{N_0}) - \theta_0\|< \delta}e^{-N_{0}D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right)}
%     \mathbb{E} \left[ \frac{1}{2}\sum_x \frac{(P_{X;\hat{\theta}} - P_{X;\theta_0})^2}{P_{X;\theta_0}}+o(\|\hat{\theta}(X^{N_0}) - \theta_0\|^2) \right]\notag\\ 
%     &+\sum_{\hat{\theta},\|\hat{\theta}(X^{N_0}) - \theta_0\|\ge \delta}e^{-N_{0}D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right)}
%     \mathbb{E} \left[ \frac{1}{2}\sum_x \frac{(P_{X;\hat{\theta}} - P_{X;\theta_0})^2}{P_{X;\theta_0}}+o(\|\hat{\theta}(X^{N_0}) - \theta_0\|^2) \right]
P_{X^n;\theta_0}(X^{N_0})\doteq e^{-N_{0}D\left(\hat{P}_{X^{N_0}} \middle\| P_{X;\theta_0}\right)} 
%\doteq e^{-N_{0}\frac{1}{2} \sum_{x\in X} \frac{ \left(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0} (\hat{\theta}(X^{N_0}) - \theta_0)\right)^2}{P_{X;\theta_0}(x)}} 
\end{align}
Then, we aim to establish a connection between the K-L divergence \eqref{appendix:dotequal_1} and $\|\hat{\theta}(X^{N_0}) - \theta_0\|^2$. From \eqref{appendix:taylor1}, we can know that
\begin{align}
\label{appendix:taylor2}
D\left(\hat{P}_{X^{N_0}} \middle\| P_{X;\theta_0}\right)= \frac{1}{2} \sum_{x\in X} \frac{\left(\hat{P}_{X^{N_0}}(x) - P_{X;\theta_0}(x)\right)^2}{P_{X;\theta_0}(x)}+o(\|\hat{\theta}(X^{N_0}) - \theta_0\|^2)  
\end{align}
From the features of MLE, we can know that
\begin{align}
\label{appendix:mle_a1}
    \mathbb{E}_{\hat{P}_{X^{N_0}}}\left[\frac{\partial\log P_{X;{\hat{\theta}(X^{N_0})}}(x)}{\partial \hat{\theta}}\right]
    =0
    =\mathbb{E}_{\hat{P}_{X^{N_0}}}\left[\frac{\partial\log P_{X;{\theta_{0}}}(x)}{\partial \theta_{0}}\right]+\mathbb{E}_{\hat{P}_{X^{N_0}}}\left[\frac{\partial^{2}\log P_{X;{\theta_{0}}}(x)}{\partial \theta_0^{2}}\right]{\left(\hat{\theta}(X^{N_0})-\theta_0\right)},
\end{align}
which can be transform to
\begin{align}
\label{appendix:mle_a2}
\left(\hat{\theta}(X^{N_0})-\theta_0\right)
=\frac{\mathbb{E}_{\hat{P}_{X^{N_0}}}\left[\frac{\partial\log P_{X;{\theta_{0}}}(x)}{\partial \theta_0}\right]}{\mathbb{E}_{\hat{P}_{X^{N_0}}}\left[\frac{\partial^{2}\log P_{X;{\theta_{0}}}(x)}{\partial \theta_0^{2}}\right]}
=\frac{\mathbb{E}_{\hat{P}_{X^{N_0}}}\left[\frac{\frac{\partial P_{X;{\theta_{0}}}(x)}{\partial \theta_0}}{P_{X;{\theta_{0}}}(x)}\right]}{\mathbb{E}_{\hat{P}_{X^{N_0}}}\left[\frac{\partial^{2}\log P_{X;{\theta_{0}}}(x)}{\partial \theta_0^{2}}\right]}
=\frac{\sum\limits_{x\in\mathcal{X}}{\left(\hat{P}_{X^{N_0}}(x)- P_{X;\theta_0}(x)\right)}\frac{\frac{\partial P_{X;{\theta_{0}}}(x)}{\partial \theta_0}}{P_{X;{\theta_{0}}}(x)}}{J(\theta_{0})}
\end{align}

Using the Cauchy-Schwarz inequality, we can obtain
\begin{align}
\label{Cauchy}
\sum_{x\in X} \frac{\left(\hat{P}_{X^{N_0}}(x) - P_{X;\theta_0}(x)\right)^2}{P_{X;\theta_0}(x)}\cdot \sum_x \frac{(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0})^2}{P_{X;\theta_0}(x)}\ge\left(\sum\limits_{x\in\mathcal{X}}{\left(\hat{P}_{X^{N_0}}(x)- P_{X;\theta_0}(x)\right)}\frac{\frac{\partial P_{X;{\theta_{0}}}(x)}{\partial \theta_0}}{P_{X;{\theta_{0}}}(x)}\right)^2
\end{align}
where
\begin{align}
\label{partial_to_fisher}
       \sum_x \frac{(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0})^2}{P_{X;\theta_0}(x)}
       =\sum_x P_{X;\theta_0}(x) \left( \frac{1}{P_{X;\theta_0}(x)} \frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0} \right)^2 
       =\sum_x P_{X;\theta_0}(x) \left( \frac{\partial \log P_{X;\theta_0}(x)}{\partial \theta_0} \right)^2 
       =J(\theta_0) 
\end{align}
Combining with \eqref{appendix:taylor2}, \eqref{appendix:mle_a2}, and \eqref{partial_to_fisher}, the inequality \eqref{Cauchy} can be transformed to 
\begin{align}
\label{Cauchy2}
D\left(\hat{P}_{X^{N_0}} \middle\| P_{X;\theta_0}\right)\ge\frac{J(\theta_0)\left(\hat{\theta}(X^{N_0})-\theta_0\right)^2}{2}=\frac{J(\theta_0)\|\hat{\theta}(X^{N_0}) - \theta_0\|^2}{2}
\end{align}

Combining \eqref{appendix:dotequal_1} and \eqref{Cauchy2}, we can know that
\begin{align}
\label{appendix:dotequal_2}
    P_{X^n;\theta_0}(X^{N_0})\doteq e^{-N_{0}D\left(\hat{P}_{X^{N_0}} \middle\| P_{X;\theta_0}\right)} \leq e^{\frac{-N_{0}J(\theta_0)\|\hat{\theta}(X^{N_0}) - \theta_0\|^2}{2}} 
\end{align}


For the first term in \eqref{appendix:expect}, the $\|\hat{\theta}(X^{N_0}) - \theta_0\|$ is small enough for us to omit the term $o(\|\hat{\theta}(X^{N_0}) - \theta_0\|^2)$. As for the second term in in \eqref{appendix:expect}, even though the magnitude of $\|\hat{\theta}(X^{N_0}) - \theta_0\|$ is no longer negligible, the probability of such sequences is  $O( e^{\frac{-N_{0}J(\theta_0)\|\hat{\theta}(X^{N_0}) - \theta_0\|^2}{2}})$ by \eqref{appendix:dotequal_2}, which is exponentially decaying with $N_0$ such that the second term is $o{(\frac{1}{N_0})}$.
By transfering \eqref{appendix:expect}, we can get
\begin{align}
\label{appendix:expect3}
&\mathbb{E} \left[ D\left(P_{X;\hat{\theta}(X^{N_0})} \middle\| P_{X;\theta_0}\right) \right] \notag\\ 
&=     \sum_{\left\{X^{N_0}:\|\hat{\theta}(X^{N_0}) - \theta_0\|^2<\delta\right\}}P_{X^n;\theta_0}(X^{N_0})  \left(  \frac{1}{2} \sum_{x\in X} \frac{ \left(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0} (\hat{\theta}(X^{N_0}) - \theta_0)\right)^2}{P_{X;\theta_0}(x)} \right)+o(\|\hat{\theta}(X^{N_0}) - \theta_0\|^2) \notag\\   
     &+\sum_{\left\{X^{N_0}:\|\hat{\theta}(X^{N_0}) - \theta_0\|^2\ge\delta\right\}}P_{X^n;\theta_0}(X^{N_0})
     \left( \frac{1}{2} \sum_{x\in X} \frac{ \left(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0} (\hat{\theta}(X^{N_0}) - \theta_0)\right)^2}{P_{X;\theta_0}(x)} \right)+o{(\frac{1}{N_0})}\notag\\ 
&=\frac{1}{2} \mathbb{E} \left[ \frac{1}{2} \sum_{x\in X} \frac{ \left(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0} (\hat{\theta}(X^{N_0}) - \theta_0)\right)^2}{P_{X;\theta_0}(x)} \right]+o{(\frac{1}{N_0})}.
\end{align}
%and we can analyze that when $\|\hat{\theta}(X^{N_0}) - \theta_0\|\ge \delta$, the $e^{-N_{0}D\left(P_{X;\hat{\theta}}\right)}$ decreases exponentially as $N_0$ increases.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% where we know the $\sum\limits_{\left\{X^{N_0}:\|\hat{\theta}(X^{N_0}) - \theta_0\|^2<\delta\right\}}o\left(\|\hat{\theta}(X^{N_0}) - \theta_0\|^2\right)$ is $o{(\frac{1}{N_0})}$ by Lemma \ref{thm:Cramér}. 
%这里我们就是想证明，泰勒展开的高阶项不会有影响，o和O的区别，在离得进的时候本来就不会有影响，就是o，在离得远的时候，我们给了一个1/N_0的界。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


We then transform \eqref{appendix:expect3} with \eqref{partial_to_fisher}
\begin{align}
    \label{KL1_cont}
    %&\mathbb{E} \left[ D\left(P_{X;\hat{\theta}} \middle\| P_{X;\theta_0}\right) \right] \notag\\ 
    %= &\frac{1}{2} \mathbb{E} \left[ \sum_x \frac{(P_{X;\hat{\theta}} - P_{X;\theta_0})^2}{P_{X;\theta_0}(x)} \right] \notag\\ 
    % &\frac{1}{2} \mathbb{E} \left[ \sum_x \frac{\left(P_{X;\hat{\theta}}(x) - P_{X;\theta_0}(x)\right)^2}{P_{X;\theta_0}(x)} \right] \notag\\ 
    % &= \frac{1}{2}  \mathbb{E} \left[ \sum_x \frac{ \left(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0} (\hat{\theta} - \theta_0)\right)^2}{P_{X;\theta_0}(x)} \right] 
    &\frac{1}{2} \mathbb{E} \left[  \sum_{x\in X} \frac{ \left(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0} (\hat{\theta}(X^{N_0}) - \theta_0)\right)^2}{P_{X;\theta_0}(x)} \right]\notag\\
    &=  \frac{1}{2} \mathbb{E} \left[\left(\hat{\theta} - \theta_0\right)^2 \right] \sum_x \frac{(\frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0})^2}{P_{X;\theta_0}(x)}  \notag\\
    % &= \frac{1}{2} \mathbb{E} \left[\left(\hat{\theta} - \theta_0\right)^2 \right] \sum_x P_{X;\theta_0}(x) \left( \frac{1}{P_{X;\theta_0}(x)} \frac{\partial P_{X;\theta_0}(x)}{\partial \theta_0} \right)^2 \notag\\
    % &= \frac{1}{2} \mathbb{E} \left[\left(\hat{\theta} - \theta_0\right)^2 \right]  \sum_x P_{X;\theta_0}(x) \left( \frac{\partial \log P_{X;\theta_0}(x)}{\partial \theta_0} \right)^2 \notag\\
    &= \frac{1}{2} \mathbb{E} \left[\left(\hat{\theta} - \theta_0\right)^2 \right]  {J}(\theta_0) 
\end{align}
%Since the MLE achieves the cramer-rao bound,  we have
%Since the MLE estimator can achieve a mean squared error approach the Cramer-Rao bound in the asymptotic case, we will mainly analyze this situation. we have
Combining  \eqref{appendix:expect3}, \eqref{KL1_cont}, we can get 
\begin{align}
\mathbb{E} \left[ D\left(P_{X;\hat{\theta}} \middle\| P_{X;\theta_0}\right) \right]=\frac{1}{2} \mathbb{E} \left[\left(\hat{\theta} - \theta_0\right)^2 \right]  {J}(\theta_0) +o{(\frac{1}{N_0})}.
\end{align}
\end{proof}

% Combining \eqref{eq:Cramér} and \eqref{eq:kl2mse}, 
% we can establish the relationship between the proposed K-L measure \eqref{eq:KL1} and the mean squared error, and provide a bound for the proposed K-L measure \eqref{eq:KL1}. In the asymptotic case, K-L measure approaches this bound. Therefore, we will primarily analyze this bound in the following sections, and we denote this objective bound as
% \begin{align}\label{eq:objectivebound}
% B\left(P_{X;\hat{\theta}} \middle\| P_{X;\theta_0}\right).
% \end{align}
From \eqref{eq:kl2mse}, 
we can establish the relationship between the proposed K-L measure \eqref{eq:KL1} and the mean squared error. Then, by using the \eqref{eq:Cramér2}, the K-L~measure is \begin{align}\frac{1}{2N_0}+o{(\frac{1}{N_0})}. \end{align}
% \begin{align}
% The Cram\'er-Rao bound provides a bound on the variance of an estimator, and the MLE can approach the Cram\'er-Rao bound under asymptotic conditions. Therefore, we will mainly analyze this situation. combining \eqref{eq:Cramér} and \eqref{eq:kl2mse}, we get 

% \begin{align}
%  B\left(P_{X;\hat{\theta}} \middle\| P_{X;\theta_0}\right)= \frac{1}{2N_0} 
% \end{align}
% we have
% \begin{align}
%     \mathbb{E} \left[\left(\hat{\theta} - \theta_0\right)^2 \right] = \frac{1}{N_{0} {J}(\theta_0)} \label{var_theta}
% \end{align}

% combining \eqref{appendix:expect3}, \eqref{KL1_cont}, and \eqref{var_theta}, we get 
% \begin{align}
%  B\left(P_{X;\hat{\theta}} \middle\| P_{X;\theta_0}\right)= \frac{1}{2N_0} 
% \end{align}

\subsection{Proof of Theorem~\ref{thm:one_source}} \label{appendix:one_source}
In this section we will be using samples from both distributions for our maximum likelihood estimation, so our optimization problem becomes
\begin{align}
    \hat{\theta} = \argmax_{\theta} L_n(\theta),
\end{align}
where, when using $N_{0}$ samples from target task, and $n_1$ samples from source task
\begin{align}
    L_n(\theta) \defeq \frac{1}{N_{0}+n_1} \sum_{x \in X^{N_{0}}} \log P_{X;\theta}(x) +\frac{1}{N_{0}+n_1} \sum_{x \in X^{n_{1}}} \log P_{X;\theta}(x).
\end{align}
And, we also define the expectation of our estimator, which is somewhere between $\theta_0$ and $\theta_1$ to be $ E_{\hat{\theta}}$
\begin{align}
\label{eq: theta_3}
    E_{\hat{\theta}} = \argmax_{\theta} L(\theta),
\end{align}

We could equivalently transform \eqref{eq: theta_3} into
\begin{align}
    \label{eq:expectedloss2}
    E_{\hat{\theta}} = \argmin_{\theta}\frac{N_{0}D\left(P_{X;\theta_0} \middle\| P_{X;\theta}\right)}{N_{0}+n_1} +\frac{n_{1}D\left(P_{X;\theta_1} \middle\| P_{X;\theta}\right)}{N_{0}+n_1}
\end{align}

By taking argmin of \eqref{eq:expectedloss2} we can get
\begin{align}
    \label{eq:ptheta3}
    P_{X;E_{\hat{\theta}}} = \frac{N_{0}P_{X;\theta_0} + n_{1}P_{X;\theta_1}}{N_{0}+n_1},
\end{align}

By doing a Taylor Expansion of \eqref{eq:ptheta3} around  $\theta'$, which is in the neighbourhood of $\theta_1, \theta_2$ and $ E_{\hat{\theta}}$, we can get
\begin{align}
\label{eq:theta3totheta12}
    E_{\hat{\theta}} = \frac{N_{0}\theta_0 + n_{1}\theta_1}{N_{0}+n_1} + O\left(\frac{1}{N_{0}+n_1}\right),
\end{align}

\begin{lemma}
% \begin{align}
% \mathbb{E}\left[ \left(\hat{\theta} -  E_{\hat{\theta}}\right)^2\right]=\frac{\frac{N_{0}}{N_{0}+n_1}J(\theta_0)+\frac{n_1}{N_{0}+n_1}J(\theta_1)}{(N_{0}+n_1)J^2( E_{\hat{\theta}})}
% \end{align}
\begin{align}
\label{square_distribution}
\sqrt{N_{0}+n_1}(\hat{\theta}- E_{\hat{\theta}})\xrightarrow{d}\mathcal{N}\left(0,\frac{1}{J(\theta_0)}\right)
\end{align}
\end{lemma}
\begin{proof}
Since $\hat{\theta}$ is a maximizer of $L_n{(\theta)}$, $L_n^{'}{(\hat{\theta})}=0=L_n^{'}{( E_{\hat{\theta}})}+L_n^{''}{( E_{\hat{\theta}})}(\hat{\theta}- E_{\hat{\theta}})$. Therefore, 
\begin{align}
\label{eq11}
    \sqrt{N_{0}+n_1}(\hat{\theta}- E_{\hat{\theta}})=\frac{\sqrt{N_{0}+n_1}L_n^{'}{( E_{\hat{\theta}})}}{L_n^{''}{( E_{\hat{\theta}})}}.
\end{align}
Since $ E_{\hat{\theta}}$ maximizes $L{(\theta)}$, $L^{'}{( E_{\hat{\theta}})}=\frac{N_{0}}{N_{0}+n_1}\mathbb{E}_{\theta_0}\left[ \frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial x} \right]+\frac{n_1}{N_{0}+n_1}\mathbb{E}_{\theta_1}\left[ \frac{\partial \log{P_{X;E_{\hat{\theta}}}(x_i^{'})}}{\partial x} \right]=0$. Therefore,
\begin{align}
\label{lntheta3_00}
&\sqrt{N_{0}+n_1} L_n^{'}( E_{\hat{\theta}})\nonumber\\&=\sqrt{\frac{N_{0}}{N_{0}+n_1} }\left( \sqrt{\frac{1}{N_{0}}}\sum_{x \in X^{N_{0}}}\frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial \theta} -\sqrt{N_{0}}\mathbb{E}_{\theta_0}\left[ \frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial \theta} \right]\right)\nonumber\\&+\sqrt{\frac{n_1}{N_{0}+n_1} }\left( \sqrt{\frac{1}{n_1}}\sum_{x \in X^{n_1}}\frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial \theta} -\sqrt{n_1}\mathbb{E}_{\theta_1}\left[ \frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial \theta} \right]\right)
\end{align}

Applying the Central Limit Theorem to \eqref{lntheta3_00}, we can get
\begin{align}\label{lntheta3}
    %&\var\left(\sqrt{N_{0}+n_1} L_n^{'}( E_{\hat{\theta}})\right)\nonumber\\
    \sqrt{N_{0}+n_1} L_n^{'}( E_{\hat{\theta}})\xrightarrow{a.s.}\mathcal{N} \Bigg(0, 
    &\frac{N_0}{N_{0}+n_1}\left(\mathbb{E}_{\theta_0}\left[\left ( \frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial \theta}  \right )^2 \right]-\mathbb{E}_{\theta_0}\left[\left ( \frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial \theta}  \right ) \right]^2\right)+\nonumber\\
    &\frac{n_1}{N_{0}+n_1}\left(\mathbb{E}_{\theta_1}\left[\left ( \frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial \theta}  \right )^2 \right]-\mathbb{E}_{\theta_1}\left[\left ( \frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial \theta}  \right ) \right]^2\right) \Bigg)
\end{align}

By taking Taylor expansion of $ E_{\hat{\theta}}$ at $\theta_1$, we can get
\begin{align}
\label{lntheta31}
&\mathbb{E}_{\theta_0}\left[\left ( \frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial \theta}  \right )^2\right]\nonumber\\
&=\mathbb{E}_{\theta_0}\left[\left ( \frac{\partial \log{P_{X;\theta_0}(x)}}{\partial \theta}+\frac{\partial }{\partial \theta} \frac{\partial \log{P_{X;\theta_0}(x)}}{\partial  \theta}( E_{\hat{\theta}}-\theta_0)+O(\frac{1}{N_{0}+n_1}) \right )^2\right]\nonumber\\
&=J(\theta_0)+( E_{\hat{\theta}}-\theta_0)\mathbb{E}_{\theta_0}\left [ \frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial \theta}\frac{\partial^2  \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial\theta^2 } \right ]+O(\frac{1}{N_{0}+n_1})\nonumber\\
&=J(\theta_0)+O(\frac{1}{\sqrt{N_{0}+n_1}})
\end{align}
and
\begin{align}
\label{lntheta32}
&\mathbb{E}_{\theta_0}\left[\left ( \frac{\partial \log{P_{X;E_{\hat{\theta}}}(x)}}{\partial \theta}  \right )\right]^2\nonumber\\
&=\mathbb{E}_{\theta_0}\left[\left ( \frac{\partial\log{P_{X;\theta_0}(x)} }{\partial \theta}+\frac{\partial }{\partial \theta} \frac{\partial \log{P_{X;\theta_0}(x)}}{\partial  \theta}( E_{\hat{\theta}}-\theta_0)+O(\frac{1}{N_{0}+n_1}) \right )\right]^2\nonumber\\
&=\mathbb{E}_{\theta_0}\left[\left ( \frac{\partial }{\partial \theta} \frac{\partial \log{P_{X;\theta_0}(x)}}{\partial  \theta}( E_{\hat{\theta}}-\theta_0)+O(\frac{1}{N_{0}+n_1}) \right )\right]^2\nonumber\\
&=( E_{\hat{\theta}}-\theta_0)^2E_{\theta_0}\left[\left ( \frac{\partial }{\partial \theta} \frac{\partial \log{P_{X;\theta_0}(x)}}{\partial  \theta} \right )\right]^2+o(\frac{1}{N_{0}+n_1})\nonumber\\&=O(\frac{1}{N_{0}+n_1})
\end{align}
By combining \eqref{lntheta3}, \eqref{lntheta31}, and \eqref{lntheta32}, we can get
\begin{align}
\label{eq16}
\var\left(\sqrt{N_{0}+n_1} L_n^{'}( E_{\hat{\theta}})\right)=\frac{N_{0}}{N_{0}+n_1}J(\theta_0)+\frac{n_1}{N_{0}+n_1}J(\theta_1)+O(\frac{1}{\sqrt{N_{0}+n_1}})
\end{align}

Additionally, we know $L_n^{''}{( E_{\hat{\theta}})}\xrightarrow{p}J( E_{\hat{\theta}})$. Combining with \eqref{eq11}\eqref{eq16}, we know that
\begin{align}
\label{square_distribution2_0}
\sqrt{N_{0}+n_1}(\hat{\theta}- E_{\hat{\theta}})\xrightarrow{d}\mathcal{N}\left(0,\frac{\frac{N_{0}}{N_{0}+n_1}J(\theta_0)+\frac{n_1}{N_{0}+n_1}J(\theta_1)}{J^2( E_{\hat{\theta}})}\right)
\end{align}
Under the assumption that $\theta_0, \theta_1, E_{\hat{\theta}}$ are sufficiently close to each other, we can easily deduce that the difference among ${J}(\theta_0),{J}(\theta_1)$ and ${J}(E_{\hat{\theta}})$ is $O(\frac{1}{\sqrt{N_{0}+n_1}})$. We can easily get
\begin{align}
\label{square_distribution2}
\sqrt{N_{0}+n_1}(\hat{\theta}- E_{\hat{\theta}})\xrightarrow{d}\mathcal{N}\left(0,\frac{1}{J(\theta_0)}\right)
\end{align}
\end{proof}


Therefore, the bound of $\mathbb{E}\left[ \left(\hat{\theta} - E_{\hat{\theta}}\right)^2\right]$ is
\begin{align}
\label{appendix:bound_single_source}
\frac{1}{(N_{0}+n_1)J( \theta_0)}
\end{align}
Combining \eqref{eq:KL1} and \eqref{KL1_cont}, we know that
\begin{align}
\label{appendix:kl_to_twokl}
    & \mathbb{E} \left[ D\left(P_{X;\hat{\theta}} \middle\| P_{X;\theta_0}\right) \right] \nonumber\\
    &=\frac{1}{2}{J}(\theta_0)\mathbb{E}\left[ \left(\hat{\theta} - \theta_0\right)^2\right]+o(\frac{1}{N_0})\nonumber\\
    &=\frac{1}{2}{J}(\theta_0)\bigg(\mathbb{E}\left[ \left(\hat{\theta} - E_{\hat{\theta}}\right)^2\right]+\mathbb{E}\left[ 2\left(\hat{\theta} - E_{\hat{\theta}}\right)\left(E_{\hat{\theta}} - \theta_0\right)\right]+\mathbb{E}\left[ \left(E_{\hat{\theta}} - \theta_0\right)^2\right]\bigg)+o(\frac{1}{N_0})\nonumber\\
    &=\frac{1}{2}{J}(\theta_0)\left(\mathbb{E}\left[ \left(\hat{\theta} - E_{\hat{\theta}}\right)^2\right]+\mathbb{E}\left[ \left(E_{\hat{\theta}} - \theta_0\right)^2\right]\right)+o(\frac{1}{N_0})
\end{align}
Combining \eqref{appendix:kl_to_twokl}, \eqref{eq:theta3totheta12} and \eqref{appendix:bound_single_source}, we know that the K-L~measure is
\begin{align}
% &=\frac{1}{2}\frac{1}{N_{0}+n_1}+\frac{1}{2}{J}(\theta_0)\left(E_{\hat{\theta}} - \theta_0\right)^2\nonumber\\
\frac{1}{2}\frac{1}{N_{0}+n_1}+\frac{1}{2}{J}(\theta_0)\frac{n_{1}^2}{(N_{0}+n_1)^2}\left(\theta_1 - \theta_0\right)^2
\end{align}

\subsection{Proof of Proposition~\ref{Proposition:target_only}} \label{appendix:prop_target_only}
Similar to \eqref{eq:kl2mse}, we can get
\begin{align}
& \mathbb{E} \left[ D\left(P_{X;\hat{{\underline{\theta}}}} \middle\| P_{X;{\underline{\theta}}_0}\right) \right] \nonumber\\
    &=\frac{1}{2}tr\left({J}({\underline{\theta}}_0)\mathbb{E}\left[ \left(\hat{{\underline{\theta}}} - {\underline{\theta}}_0\right)\left(\hat{{\underline{\theta}}} - {\underline{\theta}}_0\right)^T\right]\right)+o(\frac{1}{N_0})\nonumber\\
\end{align}
Combining with Lemma~ \ref{thm:Cramér}, we will know that the K-L~measure is
\begin{align}
\frac{1}{2}tr\left({J}({\underline{\theta}}_0)\left({J}({\underline{\theta}}_0)^{-1}\frac{1}{N_0}+o(\frac{1}{N_0})\right)\right)=\frac{d}{2N_0}+o(\frac{1}{N_0})
\end{align}
\subsection{Proof of Proposition~\ref{Proposition:one_source}} \label{appendix:Proposition:one_source}
Similar to \eqref{appendix:kl_to_twokl}, we can get
\begin{align}
\label{appendix:kl_to_twokl_prop2}
    & \mathbb{E} \left[ D\left(P_{X;\hat{{\underline{\theta}}}} \middle\| P_{X;{\underline{\theta}}_0}\right) \right] \nonumber\\
    &=\frac{1}{2}tr\left({J}({\underline{\theta}}_0)\mathbb{E}\left[ \left(\hat{{\underline{\theta}}} - {\underline{\theta}}_0\right)\left(\hat{{\underline{\theta}}} - {\underline{\theta}}_0\right)^T\right]\right)+o(\frac{1}{N_0})\nonumber\\
    &=\frac{1}{2}\left(tr\left({J}({\underline{\theta}}_0)\mathbb{E}\left[ \left(\hat{{\underline{\theta}}} - E_{\hat{{\underline{\theta}}}}\right)\left(\hat{{\underline{\theta}}} - E_{\hat{{\underline{\theta}}}}\right)^T\right]\right)+tr\left({J}({\underline{\theta}}_0)\mathbb{E}\left[ \left(E_{\hat{{\underline{\theta}}}} - {\underline{\theta}}_0\right)\left(E_{\hat{{\underline{\theta}}}} - {\underline{\theta}}_0\right)^T\right]\right)\right)+o(\frac{1}{N_0})
\end{align}
Similar to \eqref{square_distribution},we can get
\begin{align}
\label{square_distribution_one_source}
\sqrt{N_0+n_1}\left(\hat{{\underline{\theta}}} - E_{\hat{{\underline{\theta}}}}\right)\xrightarrow{d}\mathcal{N}\left(0,J({\underline{\theta}}_0)^{-1}\right)
\end{align}
So we can know that $\mathbb{E}\left[ \left(\hat{{\underline{\theta}}} - E_{\hat{{\underline{\theta}}}}\right)^2\right]$ has the bound
\begin{align}
\label{one_source_1_bound}
&\frac{1}{(N_0+n_1)}J({\underline{\theta}}_0)^{-1}
\end{align}
The same to \eqref{eq:theta3totheta12}, we can get
\begin{align}
\label{eq:theta3totheta12_prop}
    E_{\hat{{\underline{\theta}}}} = \frac{N_{0}{\underline{\theta}}_0 + n_{1}{\underline{\theta}}_1}{N_{0}+n_1} + O\left(\frac{1}{N_{0}+n_1}\right),
\end{align}
Combining \eqref{appendix:kl_to_twokl_prop2}, \eqref{one_source_1_bound} and \eqref{eq:theta3totheta12_prop}, we can know that the K-L~measure is
\begin{align} 
    %&=\frac{1}{2}\frac{d}{m+n}+\frac{1}{2}tr({J}(\vec{{\underline{\theta}}_1})\left(\vec{{\underline{\theta}}_2} - \vec{{\underline{\theta}}_1}\right)^2)\frac{m^2}{(m+n)^2}\nonumber\\
    \frac{d}{2}\left(\frac{1}{N_0+n_{1}}+\frac{n_{1}^2}{(N_0+n_{1})^2}t^{}\right) + o\left(\frac{1}{N_{0}+n_1}\right),
\end{align}
where we denote
\begin{align}
    t^{} \defeq \frac{({{\underline{\theta}}_1} - {{\underline{\theta}}_0})^{T}J({{\underline{\theta}}_0})({{\underline{\theta}}_1} - {{\underline{\theta}}_0})}{d}.
\end{align}
\subsection{Proof of Theorem~\ref{thm:multi_source}} \label{appendix:multi_source}
\begin{proof}
Similar to \eqref{square_distribution},we can get
\begin{align}
\label{square_distribution_multi_source}
% \sqrt{N_0+\sum\limits_{i=1}^{K}n_i}\left(\hat{\theta} - E_{\hat{\theta}}\right)\xrightarrow{d}\mathcal{N}\left(0,\frac{\frac{N_0}{N_0+\sum\limits_{i=1}^{K}n_i}J(\theta_0)+\sum\limits_{j=1}^{K}\frac{n_j}{N_0+\sum\limits_{i=1}^{K}n_i}J(\theta_j)}{J^2(E_{\hat{\theta}})}\right)
\sqrt{N_0+\sum\limits_{i=1}^{K}n_i}\left(\hat{{\underline{\theta}}} - E_{\hat{{\underline{\theta}}}}\right)\xrightarrow{d}\mathcal{N}\left(0,J({\underline{\theta}}_0)^{-1}\right)
\end{align}
So we can know that $\mathbb{E}\left[ \left(\hat{{\underline{\theta}}} - E_{\hat{{\underline{\theta}}}}\right)^2\right]$ has the bound
\begin{align}
\label{multi_1_bound}
&\frac{1}{(N_0+s)}J({\underline{\theta}}_0)^{-1}
\end{align}
Similar to \eqref{eq:theta3totheta12},we can get
\begin{align}
\label{multi_1_expectation}
E_{\hat{{\underline{\theta}}}}=\frac{N_0{\underline{\theta}}_0+\sum\limits_{i=1}^{k}n_i{\underline{\theta}}_i}{N_0+\sum\limits_{i=1}^{K}n_i}=\frac{N_0{\underline{\theta}}_0+\sum\limits_{i=1}^{k}n_i{\underline{\theta}}_i}{N_0+s}+O\left(\frac{1}{N_{0}+s}\right)
\end{align}

Combining \eqref{appendix:kl_to_twokl}, \eqref{multi_1_bound} and\eqref{multi_1_expectation} , we can know that the K-L~measure is
\begin{align}
 \frac{1}{2}\frac{1}{N_0+s}+\frac{1}{2}\frac{s^2}{(N_0+s)^2}J({\underline{\theta}}_0)\left(\sum\limits_{i=1}^{k}\alpha_i({\underline{\theta}}_i-{\underline{\theta}}_0)\right)^2+ o\left(\frac{1}{N_{0}+s}\right)
\end{align} 



For the d-demension parameter, we can know that the K-L~measure is $\underline{\theta}_i$
\begin{align}
\label{appendix:eq:multisourcetarget}
&\frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^2d}tr\left(\mathbf{J}(\underline{\theta}_0)\left(\sum\limits_{i=1}^{k}\alpha_i(\underline{\theta}-\underline{\theta}_0)\right)\left(\sum\limits_{i=1}^{k}\alpha_i(\underline{\theta}_i-\underline{\theta}_0)\right)^T\right)\right)\nonumber\\
&=\frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^2}\frac{\underline{\alpha}^T\Theta^T{J}(\underline{\theta}_0)\Theta\underline{\alpha}}{d}\right)+ o\left(\frac{1}{N_{0}+s}\right)\nonumber\\
\end{align}
where $\underline{\alpha}=\left[\alpha_1,\dots,\alpha_K\right]^T$ is a K-dimensional vector, and 
\begin{align}
{{\Theta}}^{d\times K}=\left[{{\underline{\theta}}_1}-{{\underline{\theta}}_0},\dots,{{\underline{\theta}}_K}-{{\underline{\theta}}_0} \right].
\end{align}
\end{proof}    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%weight%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{Weighted Multi-source Transfer Learning}

% We consider a more complex scenario based on the Multi-Source Transfer Learning setup, where a weight coefficient $l_i$, $i\in[1,K]$, is assigned to each source task. During training, the training samples will influence the model's learning process according to the weights of their respective source tasks. This introduces a larger solution space for our approach. Under this setup, we have the following conclusion:
% \begin{theorem}
% \label{thm:Weighted_multi_source}
% In the setup of weighted multi-source transfer learning, to obtain the smallest K-L~measure, we should use all the samples from each source task, \textit{i.e.}, $n_i=N_i$ for each source task. Then, we denote ${\tilde{b}_i}=N_il_i$, $\tilde{s}=\sum\limits_{1}^{K}{\tilde{b}_i}$, and ${\tilde{\alpha}_i}=\frac{{\tilde{b}_i}}{\tilde{s}}$.  The K-L~measure will be
% % For the 1-demension parameter $\theta_i$
% % \begin{align}
% % & \mathbb{E} \left[ D\left(P_{X;\hat{\theta}} \middle\| P_{X;\theta_0}\right) \right] \nonumber\\
% % &=\frac{1}{2}\frac{1}{N_0+s}+\frac{1}{2}\frac{s^2}{(N_0+s)^2}{J}(\theta_0)\left(\sum\limits_{i=1}^{k}\alpha_i(\theta_i-\theta_0)\right)^2\nonumber\\
% % \end{align}
% % We denote $s=\sum\limits_{i=1}^{K}n_i$, $\alpha_i=\frac{n_i}{s}$.
% % For the d-demension parameter ${\theta_i}$
% \begin{align}
% \label{eq:Weighted_multisourcetarget}
% &B\left(P_{X;\hat{\theta}} \middle\| P_{X;\theta_0}\right)
% %&=\frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^2d}tr\left({J}(\vec{\theta_0})\left(\sum\limits_{i=1}^{k}\alpha_i(\vec{\theta_i}-\vec{\theta_0})\right)^2\right)\right)\nonumber\\
% =\frac{d}{2}\left(\frac{N_0}{(N_0+\tilde{s})^2}+\frac{\tilde{s}^2}{(N_0+\tilde{s})^2}t\right)\nonumber\\
% \end{align}
% where $t=r/d$, and 
% \begin{align}
% r=\left(\sum\limits_{i=1}^{K}{\tilde{\alpha}_i}({\theta_i}-{\theta_0})\right)^T{J}({\theta_0})\left(\sum\limits_{i=1}^{K}{\tilde{\alpha}_i}({\theta_i}-{\theta_0})\right)+\sum\limits_{i=1}^{K}\frac{{\tilde{\alpha}_i}^2}{N_i}.
% \end{align}
% We can firstly minimize $r$, and get the optimal ${\tilde{\alpha}_i}, i\in [1,k]$. This is a non-negative quadratic programming problem. Then we use the optimal $t=r/d$ to minimize \eqref{eq:Weighted_multisourcetarget}, and get the optimal value of $s$, which is always $s=\frac{1}{t}$. Finally, we can use optimal $s$ and $\alpha_i$ to get $l_i$.
% \end{theorem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%weight%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%###############hgb add↓############
%\textbf{C}:Clipart, \textbf{I}:Infograph, \textbf{P}:Painting, \textbf{Q}:Quickdraw, \textbf{R}:Real and \textbf{S}:Sketch). \texttt{Office-Home} benchmark contains 15588 samples of 65 classes, with 12 adaptation scenarios constructed from 4 domains:  Art, Clipart, Product and Real World (abbr. \textbf{Ar}, \textbf{Cl}, \textbf{Pr} and \textbf{Rw}). 
\section{Experiment Details}
\label{appendix:Experiment_Details}
\subsection{Details information of LoRA framework experiments.}
\begin{table}[!h]
\centering
\caption{Multi-Source Transfer with LoRA on Office-Home. We apply LoRA on ViT-B backbone for PEFT.}
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{l c ccccc}
\toprule
\multirow{2.5}{*}{\textbf{Method}} & \multirow{2.5}{*}{\textbf{Backbone}} & \multicolumn{5}{c}{\textbf{Office-Home}}\\ 
\cmidrule(lr){3-7} 
&& $\to$Ar & $\to$Cl & $\to$Pr & $\to$Rw & Avg\\ \midrule
% \midrule
% \textit{Source-combine:} &&&&&&&&&&&&\\
% \textit{Supervised-10-shots Source-Ablation:} &&&&&\\
\multicolumn{7}{l}{\textit{\textbf{Supervised-10-shots Source-Ablation:}}} \\
Target-Only & ViT-B & 59.8 & 42.2 & 69.5 & 72.0 & 60.9 \\ 
Single-Source-avg & ViT-B & 72.2  & 59.9 & 82.6 & 81.0 & 73.9 \\
Single-Source-best & ViT-B & 74.4  & 61.8 & 84.9 & 81.9 & 75.8 \\ 
\allsource{} & ViT-B & \underline{81.1} & \underline{66.0} & \underline{88.0} & \underline{89.2} & \underline{81.1}\\
\ourmethod{} (Ours) & ViT-B & \textbf{81.5} & \textbf{68.0} & \textbf{89.2} & \textbf{90.3}  & \textbf{82.3} \\
\bottomrule
\end{tabular}
}
\label{tab:LoRA}
\end{table}
\subsection{Experimental Design and Model Adaptation}
\label{appendix:Experimental_Design_and_Model Adaptation}

% \textbf{Experimental Design and Model Adaptation}. 
To ensure consistency in the experimental setup, we first evaluate the performance of different methods on the DomainNet and Office-Home datasets by adapting their settings to align with ours, such as the backbone, dataset, and early stopping criteria. Specifically, for the MADA method, we adjusted the preset of keeping 5\% of labeled target samples to 10-shots per class target samples while maintaining other conditions. And in turn, ours is adapted to the WADN settings, equipped with a 3-layer ConvNet and evaluated on Digits dataset.

%from prof. yang: Performance on Digits classification dataset. 
\begin{table}[htbp]
\centering
\caption{\textbf{Performance on Digits Dataset.} The arrows indicate transferring from the rest tasks. ``3Conv'' denotes the backbone with 3 convolution layers.}
\resizebox{0.48\textwidth}{!}{
\begin{tabular}{l c ccccc}
\toprule
\multirow{2.5}{*}{\textbf{Method}} & \multirow{2.5}{*}{\textbf{Backbone}} & \multicolumn{5}{c}{\textbf{Digits}}\\ 
\cmidrule(lr){3-7} 
&& $\to$mt & $\to$sv & $\to$sy & $\to$up & Avg\\ 
 % \multicolumn{1}{c|}{\makecell{\textbf{Method}}} &\multicolumn{1}{c|}{\makecell{\textbf{Backbone}}} &\multicolumn{5}{c}{\makecell{\textbf{Digits}\\\midrule$\to$mt\hspace{1.2em}$\to$sv\hspace{1.2em}$\to$sy\hspace{1.2em}$\to$up\hspace{1em}Avg}}\\
\midrule
% \midrule
% \textit{Source-combine:} &&&&&&&&&&&&\\
% \textit{Supervised-10-shots Source-Ablation:} &&&&&\\
% None-Source(Vitb)  & 59.8 & 42.2 & 69.5 & 72.0 & 60.9 \\ 
% Single-Source-avg(Vitb)& 72.2  & 59.9 & 82.6 & 81.0 & 73.9 \\
% Single-Source-best(Vitb) & 74.4  & 61.8 & 84.9 & 81.9 & 75.8 \\ 
\multicolumn{7}{l}{\textit{\textbf{Following settings of WADN:}}} \\
WADN\cite{shui2021aggregating_WADN} &3Conv& 88.3 & \textbf{70.6} & 81.5 & \textbf{90.5} & 82.7 \\
\allsource{} &3Conv & \underline{92.6} & \underline{67.1} & \underline{82.5} & 88.8 & \underline{82.8}\\
\ourmethod{} (Ours)&3Conv& \textbf{93.8} & \underline{67.1} & \textbf{83.3} & \underline{89.1}  & \textbf{83.3} \\
\bottomrule
\end{tabular}
}
\label{tab:adapted_experiments}
\end{table}
\newpage
\subsection{Single-Source transfer performance details.}

\begin{table*}[!h]
\centering
\caption{\textbf{Single-Source Transfer Performance on DomainNet.} The details accuracy information of the ‘‘Single-Source-$*$’’ lines of Table \ref{tab:major}.}
\resizebox{0.8\textwidth}{!}{
\begin{tabular}{lc c cccccccc}
\toprule
% \multirow{2}{*}{\makecell{\textbf{Method} \\ Second line}} &\multirow{2}{*}{\makecell{\textbf{Method} \\ Second line}} 
\multirow{2.5}{*}{\textbf{Target Domain}} & \multirow{2.5}{*}
{\textbf{Backbone}} && \multicolumn{7}{c}{\textbf{Source Domain}}\\ 
% \cline{3-9} \cline{10-14}
\cmidrule(lr){4-11}
 &&&Clipart & Infograph & Painting & Quickdraw & Real & Sketch & Avg & Best\\ 
\midrule
% \midrule
% \textit{Source-combine:} &&&&&&&&&&&&\\
% \textit{Unsupervised-all-shots:} &&&&&&&&&&&&&\\
Clipart & ViT-S && - & 46.5 & 55.4  & 30.3  & 60.2 & 59.7  & 50.4 & 60.2\\
Infograph & ViT-S && 25.6 & - & 25.3  & 7.3  & 28.0 & 24.4  & 22.1 & 28.0  \\ 
Painting & ViT-S && 49.6 & 47.3 & -  & 22.4  & 55.4 & 49.6  & 44.9 & 55.4\\
Quickdraw & ViT-S && 26.9 & 18.1 & 23.9  & -  & 25.9 & 28.4  & 24.7 & 28.4\\
Real & ViT-S && 64.6 & 62.2 & 66.0  & 38.5  & - & 62.7  & 58.8 & 66.0\\
Sketch & ViT-S && 49.7 & 40.9 & 48.1  & 26.1  & 47.8 & -  & 42.5 & 49.7\\
\bottomrule
\end{tabular}
}
\label{tab:appendix_single_source_domainnet}
\end{table*}

\begin{table*}[!h]
\centering
\caption{\textbf{Single-Source Transfer Performance on Office-Home.} The details accuracy information of the ‘‘Single-Source-$*$’’ lines of Table \ref{tab:major}.}
\resizebox{0.6\textwidth}{!}{
\begin{tabular}{lc c cccccc}
\toprule
\multirow{2.5}{*}{\textbf{Target Domain}} & \multirow{2.5}{*}
{\textbf{Backbone}}&& \multicolumn{5}{c}{\textbf{Source Domain}}\\ 
\cmidrule(lr){4-9}
 &&& Art & Clipart & Product & Real World & Avg & Best\\ 
\midrule
Art & ViT-S && -  & 61.7 & 61.1 & 72.9 & 65.2 & 72.9 \\
Clipart & ViT-S && 49.8  & - & 49.4 & 60.9 & 53.3 & 60.9 \\ 
Product & ViT-S && 68.8  & 73.7 & - & 80.7 & 74.4 & 80.7 \\
Real World & ViT-S && 70.9  & 72.3 & 74.8 & - & 72.7 & 74.8 \\
\bottomrule
\end{tabular}
}
\label{tab:appendix_single_source_officehome}
\end{table*}

\begin{table*}[!h]
\centering
\caption{\textbf{Single-Source Transfer Performance on Office-Home of LoRA.} The details accuracy information of the ‘‘Single-Source-$*$’’ lines of Table \ref{tab:LoRA}. ViT-B backbone is already frozen and equipped with small trainable LoRA layers.}
\resizebox{0.6\textwidth}{!}{
\begin{tabular}{lc c cccccc}
\toprule
\multirow{2.5}{*}{\textbf{Target Domain}} & \multirow{2.5}{*}
{\textbf{Backbone}}&& \multicolumn{5}{c}{\textbf{Source Domain}}\\ 
\cmidrule(lr){4-9}
 &&& Art & Clipart & Product & Real World & Avg & Best\\ 
\midrule
Art & ViT-B && -  & 68.4 & 74.4 & 73.8 & 72.2 & 74.4\\
Clipart & ViT-B && 58.3  & - & 59.6 & 61.8 & 59.9 & 61.8\\ 
Product & ViT-B && 82.0  & 80.8 & - & 84.9 & 82.6 & 84.9 \\
Real World & ViT-B && 81.0  & 80.3 & 81.9 & - & 81.0 &81.9\\
\bottomrule
\end{tabular}
}
\label{tab:appendix_single_source_officehome_lora}
\end{table*}

\subsection{Baselines experiments settings in Table \ref{tab:major}.}
Since the significant difference from unsupervised methods and supervised methods, the results of MSFDA\cite{shen2023balancingMSFDA}, DATE\cite{han2023discriminability_DATE} and M3SDA\cite{peng2019moment_M3SDA} are directly supported by their own article.

On all the experiments of the baselines, we take all the source samples of different domains from trainset into account. And types of the backbone are all pretrained on ImageNet21k\cite{deng2009imagenet}.

As for based on model-parameter-weighting few-shot methods: MCW\cite{lee2019learning_MCW} and H-ensemble\cite{wu2024h_Hensemble}, since they have not taken experiments on DomainNet and Office-Home datasets with ViT-Small backbone and 10-shot per class training samples, we take it by changing the backbone and samples condition while maintaining other configurations supported by their own work. And for fairness and efficiency, the well-trained source models from different domains of these methods are directly equipped with the same models trained by the first stage of our \ourmethod{} method respectively.

As for based on samples few-shot methods: We exam the WADN\cite{shui2021aggregating_WADN} method under the condition of limited label on target domain as this setting is similar to ours. And we also change the backbone and samples condition while maintaining other configurations of its report to realize the experiments on DomainNet and Office-Home datasets. It is apparent that the settings of MADA\cite{zhang2024revisiting_MADA} are quite different of ours, leveraging all the labeled source data and all the unlabeled target data with the few-shot labeled ones that are difficult to classify, which means all the target samples have been learned to some extent. So we not only decrease the labeled target samples to 10-shot per class but also the unlabeled target samples. And since MADA is the most SOTA and comparable method, we realize it with our fair 10-shot setting under both ViT-S and ResNet50 backbone on DomainNet and Office-Home datasets while maintaining other configurations of its report.

\subsection{Data efficient test details in \ref{section:data_efficient} .}
\begin{table*}[htbp]
\centering
\caption{\textbf{Data Efficient Test Results on DomainNet.} The capital letters represent the target domains.}
\resizebox{\textwidth}{!}{
\begin{tabular}{lc c ccccccc c ccccccc}
\toprule
% \multirow{2}{*}{\makecell{\textbf{Method} \\ Second line}} &\multirow{2}{*}{\makecell{\textbf{Method} \\ Second line}} 
\multirow{2.5}{*}{\textbf{Method}} & \multirow{2.5}{*}{\textbf{Backbone}} && \multicolumn{7}{c}{\textbf{Data Counts (×10$^6$)}} && \multicolumn{7}{c}{\textbf{Training Consumed Time (×10$^4$ Second)}}\\ 
% \cline{3-9} \cline{10-14}
\cmidrule(lr){4-10} \cmidrule(lr){12-18}
 &&&C & I & P & Q & R & S & Avg&&C & I & P & Q & R & S & Avg\\ 
\midrule
% \textit{Supervised-10-shots:} &&&&&&&&&&&&&\\
% \multicolumn{14}{l}{\textbf{\textrm{Supervised-10-shots}}} \\
%8695400.0, 13391442.0, 8308180.0, 4024847.9999999995, 19759513.000000004, 21315960.0, 12582557.166666666//64040.0, 125240.00000000001, 62860.00000000001, 32220.000000000004, 131924.0, 181764.0, 99674.66666666667
MADA\cite{zhang2024revisiting_MADA}& ViT-S && 8.70 & 13.39 & 8.31 & 4.02 & 19.76 & 21.32 & 12.58 && 6.40 & 12.52 & 6.29 & 3.22 & 13.19 & 18.18 & 9.97 \\
% 7825860.0, 8207658.0, 4569498.999999999, 3689444.0, 4353791.0, 8777160.0, 6237235.333333333\\[75636.0, 95760.0, 45573.0, 40535.0, 42068.0, 95843.99999999999, 65902.66666666667]
MADA\cite{zhang2024revisiting_MADA}& ResNet50 && 7.83 & 8.21 & 4.57 & 3.69 & 4.35 & 8.78 & 6.24 && 7.56 & 9.58 & 4.56 & 4.05 & 4.21 & 9.58 & 6.59\\
% 2172100.0, 1420800.0, 1420700.0, 4195600.0, 1419400.0, 1897400.0, 2087666.6666666667]
%0.5595, 0.3661, 0.3665, 1.0903, 0.3591, 0.4894
\allsource{}& ViT-S && 2.17   & 1.42 & 1.42 & 4.20 & 1.42 & 1.90 & 2.09 && 0.56 & 0.37 & 0.39 & 1.09 & 0.36 & 0.49 &0.54\\
%1176000.0, 1149000.0, 890700.0, 966400.0, 1194300.0, 1158700.0, 1089183.3333333333 //1.1760, 1.1490, 0.8907, 0.9664, 1.1943, 1.1587//0.3541, 0.3288, 0.2784, 0.3363, 0.4708, 0.3580
\ourmethod{} (Ours)& ViT-S && 1.18 & 1.15 & 0.89 & 0.97  & 1.19 & 1.16 & 1.09 && 0.35 & 0.33 & 0.28 & 0.34  & 0.47 & 0.36 & 0.35 \\
\bottomrule
\end{tabular}
}
\label{tab:major2}
\end{table*}

\begin{table*}[!htbp]
\centering
\caption{\textbf{Data Efficient Log Scaled Test Results on DomainNet.} The capital letters represent the target domains.}
\resizebox{\textwidth}{!}{
\begin{tabular}{lc c ccccccc c ccccccc}
\toprule
% \multirow{2}{*}{\makecell{\textbf{Method} \\ Second line}} &\multirow{2}{*}{\makecell{\textbf{Method} \\ Second line}} 
\multirow{2.5}{*}{\textbf{Method}} & \multirow{2.5}{*}{\textbf{Backbone}} && \multicolumn{7}{c}{\textbf{Data Counts (log scale)}} && \multicolumn{7}{c}{\textbf{Training Consumed Time (log scale)}}\\ 
% \cline{3-9} \cline{10-14}
\cmidrule(lr){4-10} \cmidrule(lr){12-18}
 &&&C & I & P & Q & R & S & Avg&&C & I & P & Q & R & S & Avg\\ 
\midrule
% \textit{Supervised-10-shots:} &&&&&&&&&&&&&\\
% \multicolumn{14}{l}{\textbf{\textrm{Supervised-10-shots}}} \\
%15.97830471, 16.4101264 , 15.93275113, 15.2079977 , 16.7991456 ,16.87496665, 16.34782206 \\11.06726317, 11.73798718, 11.04866531, 10.38034266, 11.78998128,12.11046442, 11.50966683
MADA\cite{zhang2024revisiting_MADA}& ViT-S && 15.98 & 16.41 & 15.93 & 15.21 & 16.80 & 16.87 & 16.35 && 11.07 & 11.74 & 11.05 & 10.38 & 11.79 & 12.11 & 11.51 \\
% 15.87294419, 15.92057818, 15.33491413, 15.12098633, 15.28655752, 15.98766345, 15.64604759\\11.23368764, 11.46960034, 10.72707071, 10.60992108, 10.64704264, 11.47047715, 11.09593419
MADA\cite{zhang2024revisiting_MADA}& ResNet50 && 15.87 & 15.92 & 15.33 & 15.12 & 15.29 & 15.99 & 15.65 && 11.23 & 11.47 & 10.73 & 10.61 & 10.65 & 11.47 & 11.10\\
% 14.591205  , 14.16673065, 14.16666027, 15.24954692, 14.16574481, 14.45599509, 14.55155757\\8.62962862, 8.20549161, 8.20658361, 9.29679326, 8.18618599, 8.49576524, 8.5913416
\allsource{}& ViT-S && 14.59   & 14.17 & 14.18 & 15.25 & 14.17 & 14.46 & 14.55 && 8.63 & 8.21 & 8.21 & 9.30 & 8.19 & 8.50 & 8.59\\
%13.97762941, 13.95440256, 13.69976295, 13.78133311, 13.9930708 , 13.96280924, 13.90093874\\8.17216445, 8.09803476, 7.93164402, 8.12058871, 8.45701847, 8.18311808, 8.17301131
\ourmethod{} (Ours)& ViT-S && 13.98 & 13.95 & 13.70 & 13.78  & 13.99 & 13.96 & 13.90 && 8.17 & 8.10 & 7.93 & 8.12  & 8.46 & 8.18 & 8.17 \\
\bottomrule
\end{tabular}
}
\label{tab:major3}
\end{table*}

\subsection{Domain choosing analysis details.}
To compute the heatmap matrix visualizing domain preference in Figure \ref{fig:domain_choosing}(b), for each source domain, we count the samples selected from it until the target model converges under the 10-shot condition. Since the quantities of available samples varies significantly across domains, we normalize the counts by these quantities. The final domain preference is then determined by computing the importance of these normalized values.

Similarly, to compute the heatmap matrix for domain selection in Figure \ref{fig:domain_choosing}(a), we calculate the importance of the counts of selected samples from different source domains throughout the training epochs.


\section{Method to get $s^*$ and $\underline{\alpha}^*$ which minimize \eqref{eq:multisourcetarget} in Theorem \ref{thm:multi_source}}\label{appendix:sa}


% The minimization problem of \eqref{eq:multisourcetarget} can be decomposed into two subproblems. The first subproblem is to minimize t, which is a $K\times K$ quadratic programming problem with respect to $\alpha$, and by resolving it, we can compute optimal $t^*$ and $\alpha^*$. The second subproblem is to find the optimal $s^*$ that minimizes the K-L measure, corresponding to our previous analysis of Theorem~\ref{thm:one_source} and Proposition~\ref{Proposition:one_source} when $s$ corresponds to $n_1$. After we get $s^*$ and $\alpha^*$, we can eventually get the optimal quantity $n_k^*$ of each source.

The minimization problem of K-L measure \eqref{eq:multisourcetarget} is
\begin{align}
(s^*, \underline{\alpha}^*) \gets \argmin\limits_{(s, \underline{\alpha})} \frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^2}\frac{\underline{\alpha}^T\Theta^T{J}({{\underline{\theta}}_0})\Theta\underline{\alpha}}{d}\right).
\end{align}

We decompose this problem and explicitly formulate the constraints as follows.
\begin{align}
(s^*, \underline{\alpha}^*) \gets \argmin\limits_{s\in[0,\sum\limits_{i=1}^{K}N_i]} \frac{d}{2}\left(\frac{1}{N_0+s}+\frac{s^2}{(N_0+s)^{2}d}\argmin\limits_{\underline{\alpha}\in\cA(s)}\underline{\alpha}^T\Theta^T{J}({{\underline{\theta}}_0})\Theta\underline{\alpha}\right),
\end{align}
where 
\begin{align}
\cA(s)=\left\{\underline{\alpha}\Bigg|\sum_{i=1}^{K}\alpha_i=1, s*\alpha_i \le N_i, \alpha_i \ge0,i=1,\dots,K\right\}.
\end{align}
Due to the complex constraints between \( s \) and \( \alpha \), obtaining an analytical solution to this problem is challenging. Therefore, we propose a numerical approach to get the optimal solution. Specifically, we perform a grid search over the feasible domain of \( s \). For each candidate \( s' \), we compute the optimal \( \alpha' \) under the constraint \( A(s') \), which is a $K\times K$ quadratic programming problem with respect to $\alpha$. The K-L measure \eqref{eq:multisourcetarget} value is then evaluated using \( (s', \alpha') \). After completing the search over \( s \), the optimal values \( s^* \) and \( \alpha^* \) correspond to the pair \( (s', \alpha') \) that minimizes the K-L measure.

\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.

