% \vspace{-0.15cm}
\section{Related Work}
\label{sec:related}

\subsection{Low-Light Image Enhancement}

\textbf{Single-stage Methods.} Single-stage deep learning approaches \cite{LLNet,KinD,EnGAN,RetinexFormer,10244055,9809998} has been widely used in LLIE. 
Existing methods propose distinct solutions to address the aforementioned issues.
% of image color shift and noise stabilization. 
For instance, RetinexNet \cite{RetinexNet} enhances images by decoupling illumination and reflectance based on Retinex theory. 
% However, it has unsatisfied results with several color shifts.
% SNR-Aware \cite{SNR-Aware} presents a collective Signal-to-Noise-Ratio-aware transformer network to dynamically enhance pixels with spatial-varying operations, which could reduce the color bias and noise in sRGB domain. 
Bread \cite{Bread} decouples the entanglement of noise and color
distortion by using YCbCr color space. Furthermore, they designed a color adaption network to tackle the color distortion issue left in light-enhanced images. 
Still, RetinexNet and Bread can show 
% poor generalization ability. They are not only 
inaccurate control in terms of brightness and biased
% in some of the datasets, but also biased in terms of 
color in black areas.

\textbf{Diffusion-based Methods.} With the advancement of Denoising Diffusion Probabilistic Models (DDPMs) \cite{Ho2020Denosing}, diffusion-based generative models have achieved remarkable results in the LLIE task. It has shown the capability to generate more accurate and appropriate images. However, they still exhibit issues such as local overexposure or color shift. Recent LLIE diffusion methods have attempted to address these challenges by incorporating global supervised brightness correction or employing local color correctors \cite{zhou2023pyramid,wu2023reco,hou2024global,wang2024zero,jiang2023low,feng2024difflight}.
% PyDiff \cite{zhou2023pyramid} employs a Global Feature Modulation to correct the pixel noise and color bias globally.
Other methods such as Diff-Retinex \cite{yi2023diff} rethink the retinex theory with a diffusion-based model in the LLIE task, aiming to decomposed an image to illumination and reflectance from sRGB color space. 
However, these diffusion models often fail to fully decouple brightness and color information.


\subsection{Color Space}

\label{section:CS}


\textbf{RGB.} 
% Any additive color space based on RGB color model belongs to the RGB color space. 
Currently, the most commonly used is the sRGB color space. For the same principle as visual recognition by the human eye, sRGB is widely used in digital imaging devices \cite{POYNTON2003187}. Nevertheless, image brightness and color exhibit a strong interdependence with the three channels in sRGB \cite{gevers2012color}.
A slight disturbance in the color space will cause an obvious variation in both the brightness and color of the generated image. Thus, sRGB is not a desired color space for low-light enhancement.

\textbf{HSV and YCbCr.} The HSV color space represents points in an RGB color model with a cylindrical coordinate system \cite{Foley1982FundamentalsOI}. Indeed, it does decouple brightness and color of the image from RGB channels. However, the red color discontinuity and black plane noise pose significant challenges when we enhance the images in HSV color space, resulting in the emergence of various obvious artifacts. To circumvent issues related to HSV, some methods \cite{Bread,brateanu2024lytnet} also transform sRGB images to the YCbCr color space, which has an illumination axis (Y) and reflect-color-plane (CbCr). Although it solved the hue dimension discontinuity problem of HSV, 
% unlike Value (V) axis,
the Y axis is still coupled with the CbCr plane partially, leading to severe color shifts.
