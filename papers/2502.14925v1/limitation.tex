
% \noindent\textbf{Uniform Priority Within Token Classes:} Our method sequentially deletes tokens within the same type, assuming uniform importance across all tokens of that type. However, tokens of the same type may have varying levels of priority, leading to suboptimal retention of critical tokens during compression.
\section{Limitations}
\textbf{Need for Extra Training for New Coding Tasks:} This study focuses on learning code compression for three method-level coding tasks. Similar to other task-aware compressors (e.g., \citealp{longllmlingua}), the removal priorities in our approach depend on the downstream coding task. If \ourtool{} is to be applied to other coding tasks, such as repository-level tasks \citep{repo}, where token priorities differ significantly, additional training of the compressor is required. However, as shown in Figure \ref{fig:rank}, while priority rankings are task-specific, certain patterns emerge consistently. For example, \textbf{Identifier} tokens exhibit a higher removal priority than \textbf{Structure} tokens across all tasks. We show the out-of-domain capability of our compressor by cross-task experiment in Appendix \ref{sec:out}.

\textbf{Generalizability of Our Findings:}
This study focuses exclusively on Java and method-level tasks. Since programming languages like Python also have program analysis tools, \ourtool{} is applicable to them as well. Future research could extend this work to other tasks and languages. Our experiments utilized GPT-3.5, Gemini, and CodeLlama-13b. We encourage further studies to explore additional base LMs and a broader range of programming languages and coding tasks.

\section{Ethical Considerations}
The implementation of this work is conducted with transparency, providing full disclosure of all technical details, limitations, and potential issues to the relevant stakeholders. The work avoids any false or misleading claims and ensures no data is fabricated or falsified.

In the interest of public benefit, the authors support reasonable and ethical uses of their intellectual contributions. Both the source code and data are released as free and open-source software and are made available in the public domain.  