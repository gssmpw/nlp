
The use of machine learning (ML) models in software applications has increased dramatically over the last decade, including in recommendation systems, computer vision, chatbots, image generation, automated software engineering, and more. As creating and training new models has become increasingly more expensive~\cite{patterson_carbon_2021}, developers have turned to fine-tuning pre-existing models.  This approach may save time and effort, but it also introduces the complexity of a new ML supply chain, complete with many novel challenges.

While supply chains for conventional software typically consist of software components, libraries, configuration files, and processes \cite{tan2022exploratory,GaoHXZ24}, %
for ML-intensive systems, the supply chain is more complex, comprising all elements that make an ML algorithm work. Creating a modern ML system involves the integration of ML models and traditional software components, as well as different types of reuse or integration, taking into account dependencies between models themselves or between models and their training datasets. In addition, the training of ML models can rely on multiple datasets or dataset aggregates, and datasets, in turn, each have their own supply chain~\cite{lee2023talkin}. 

Adaptation or reuse of existing models can also introduce degrees of complexity. Models can be fine-tuned~\cite{church2021emerging} or quantized from existing models~\cite{gholami2022survey}. %
(Fine-tuning allows a developer to use an existing model to create a model that specializes in certain tasks or to change the model's behavior, such as removing safety or ethical protections. Quantization compresses an existing model such that it can be run on smaller hardware with minimal performance loss.)  Different ML models can be combined to form a single architecture that can, in turn, be reused or adapted~\cite{ardabili2019advances}. Finally, the outputs from one model can be used to train another model, such as through synthetic data~\cite{marwala2023use} or the use of a teacher-student approach~\cite{hinton2015distilling}.

The ML supply chain, particularly those involving generative models \cite{lee2023talkin}, is not necessarily linear, progressing cleanly from one dependency or stage to the next.  Instead, as outlined by Lee \etal  \cite{lee2023talkin}, there can be branches and even cycles in the supply chain. %
For example, datasets can be used not only in the initial training of models but also for the fine-tuning of pre-existing base models, sometimes in multiple instances and by different developers. Additionally, some stages of the supply chain can backfeed into others, making relationships increasingly complex, if not recursive.  For example, the outputs of a generative model can be added to pre-existing datasets and used for training future versions.  The sheer volume of content from generative models makes this situation increasingly likely, if not inevitable. 

Understanding these relationships is critical not only for license compliance, which requires a full understanding of the components used in a project and their associated licenses, but also for detecting, mitigating, and managing security threats involved with model reuse, such as weight poisoning attacks \cite{Kurita2020WeightPA}, data poisoning \cite{Goldblum2020DatasetSF}, and even malware hidden in model weights and assembled at runtime \cite{Wang2021EvilModelHM}.

 While previous work has considered the documentation \cite{pepe2024hugging}, evolution \cite{jiang2022empirical}, and environmental impact \cite{castano2024lessons} of ML models, the complexity and challenges of the ML supply chain as a whole have not yet been fully explored. The supply chain relationships between models and dependent GitHub repositories have been explored by Pepe \etal \cite{pepe2024hugging} and Jiang \etal \cite{jiang2024peatmoss}, %
 but the relationships between ML models remain understudied.


To contribute to bridging this gap, we aim to investigate the emerging ML model supply chain on Hugging Face~\cite{hugging-face} (hereafter referred to as the `ML supply chain'), specifically the documentation practices of model owners, the structure and complexity of the supply chain itself, and the existence and prevalence of potential compliance issues. We note that proper documentation and documentation practices are foundational to mapping, and thus managing the ML supply chain.  Launched in 2016, Hugging Face is, as of January 2025, the largest repository of ML models and datasets~\cite{Jiang2023AnES, jiang2022empirical}. As with GitHub and traditional software, Hugging Face provides a central hub for model developers and data scientists to explore, share, and experiment with ML models.  While other model forges---such as TensorFlow Hub~\cite{tensorflowHub}, PyTorch Hub~\cite{pytorchHub}, and Model Zoo~\cite{modelzoo}---exist, the Hugging Face platform has the widest reach, hosting more than 750K models and 175K datasets across many different use cases. Hugging Face therefore represents a robust opportunity to understand ML supply chains and analyze how developers interact with them.

We mine models and datasets hosted on Hugging Face, using the available information to construct a supply chain graph.  %
We highlight different types of documentation inconsistencies that complicate the creation of this supply chain graph, discuss the underlying structure and features of the current ML supply chain on Hugging Face, and analyze the present licensing landscape. Ultimately, we demonstrate that there is still much work to be done to facilitate better dependency/supply chain management on Hugging Face and in the ML ecosystem. %

The main contributions of this paper are the following:
\begin{itemize}
    \item A critical evaluation of the current state of documentation on Hugging Face.
    \item An analysis of the interactions between models and datasets in the supply chain.
    \item An analysis of the licensing ecosystem on Hugging Face and potential compliance problems.
    \item Actionable suggestions for how model hubs can better facilitate supply chain management activities.
    \item A cleaned, reusable, and extensible dataset of models, datasets, and their relationships, and a tool suite capable of generating newer versions of said dataset~\cite{anonymous_repo}.
\end{itemize}
