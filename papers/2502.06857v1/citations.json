[
  {
    "index": 0,
    "papers": [
      {
        "key": "kaplan2020scaling",
        "author": "Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario",
        "title": "Scaling laws for neural language models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "hoffmann2022empirical",
        "author": "Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and de Las Casas, Diego and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others",
        "title": "An empirical analysis of compute-optimal large language model training"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "kaplan2020scaling",
        "author": "Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario",
        "title": "Scaling laws for neural language models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "pearce2024reconciling",
        "author": "Tim Pearce and Jinyeop Song",
        "title": "Reconciling Kaplan and Chinchilla Scaling Laws"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "porian2024resolving",
        "author": "Porian, Tomer and Wortsman, Mitchell and Jitsev, Jenia and Schmidt, Ludwig and Carmon, Yair",
        "title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "kaplan2020scaling",
        "author": "Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario",
        "title": "Scaling laws for neural language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "hu2024minicpm",
        "author": "Hu, Shengding and Tu, Yuge and Han, Xu and He, Chaoqun and Cui, Ganqu and Long, Xiang and Zheng, Zhi and Fang, Yewei and Huang, Yuxiang and Zhao, Weilin and others",
        "title": "Minicpm: Unveiling the potential of small language models with scalable training strategies"
      },
      {
        "key": "bi2024deepseek",
        "author": "Bi, Xiao and Chen, Deli and Chen, Guanting and Chen, Shanhuang and Dai, Damai and Deng, Chengqi and Ding, Honghui and Dong, Kai and Du, Qiushi and Fu, Zhe and others",
        "title": "Deepseek llm: Scaling open-source language models with longtermism"
      },
      {
        "key": "dubey2024llama",
        "author": "Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others",
        "title": "The llama 3 herd of models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "choshen2024hitchhiker",
        "author": "Leshem Choshen and Yang Zhang and Jacob Andreas",
        "title": "A Hitchhiker's Guide to Scaling Law Estimation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "misfitting",
        "author": "Li, Margaret and Kudugunta ,Sneha and Zettlemoyer, Luke",
        "title": "(Mis)Fitting Scaling Laws: A Survey of Scaling Law Fitting Techniques in Deep Learning"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "hagele2024scaling",
        "author": "H{\\\"a}gele, Alexander and Bakouch, Elie and Kosson, Atli and Allal, Loubna Ben and Von Werra, Leandro and Jaggi, Martin",
        "title": "Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "memmoves",
        "author": "Inbar, Itay and Sernau, Luke",
        "title": "Time Matters: Scaling Laws for Any Budget"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "observational",
        "author": "Yangjun Ruan and Chris J. Maddison and Tatsunori Hashimoto",
        "title": "Observational Scaling Laws and the Predictability of Language Model Performance"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "caballero2023broken",
        "author": "Ethan Caballero and Kshitij Gupta and Irina Rish and David Krueger",
        "title": "Broken Neural Scaling Laws"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "interplay",
        "author": "Levine, Yoav and Wies, Noam and Sharir, Or and Bata, Hofit and Shashua, Amnon",
        "title": "The Depth-Width Interplay in Self-Attention"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "henighan2020scaling",
        "author": "Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B and Dhariwal, Prafulla and Gray, Scott and others",
        "title": "Scaling laws for autoregressive generative modeling"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "petty2024impact",
        "author": "Jackson Petty and Sjoerd van Steenkiste and Ishita Dasgupta and Fei Sha and Dan Garrette and Tal Linzen",
        "title": "The Impact of Depth on Compositional Generalization in Transformer Language Models"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "brown2022wide",
        "author": "Brown, Jason Ross and Zhao, Yiren and Shumailov, Ilia and Mullins, Robert D",
        "title": "Wide attention is the way forward for transformers?"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "kaplan2020scaling",
        "author": "Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario",
        "title": "Scaling laws for neural language models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "alabdulmohsin2024getting",
        "author": "Alabdulmohsin, Ibrahim M and Zhai, Xiaohua and Kolesnikov, Alexander and Beyer, Lucas",
        "title": "Getting vit in shape: Scaling laws for compute-optimal model design"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "beyer2024paligemma",
        "author": "Beyer, Lucas and Steiner, Andreas and Pinto, Andr{\\'e} Susano and Kolesnikov, Alexander and Wang, Xiao and Salz, Daniel and Neumann, Maxim and Alabdulmohsin, Ibrahim and Tschannen, Michael and Bugliarello, Emanuele and others",
        "title": "Paligemma: A versatile 3b vlm for transfer"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "krajewski2024scaling",
        "author": "Krajewski, Jakub and Ludziejewski, Jan and Adamczewski, Kamil and Pi{\\'o}ro, Maciej and Krutul, Micha{\\l} and Antoniak, Szymon and Ciebiera, Kamil and Kr{\\'o}l, Krystian and Odrzyg{\\'o}{\\'z}d{\\'z}, Tomasz and Sankowski, Piotr and others",
        "title": "Scaling laws for fine-grained mixture of experts"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "scaleEfficiently",
        "author": "Yi Tay and Mostafa Dehghani and Jinfeng Rao and William Fedus and Samira Abnar and Hyung Won Chung and Sharan Narang and Dani Yogatama and Ashish Vaswani and Donald Metzler",
        "title": "Scale Efficiently: Insights from Pretraining and Finetuning Transformers"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "yang2021zero",
        "author": "Yang, Ge and Hu, Edward and Babuschkin, Igor and Sidor, Szymon and Liu, Xiaodong and Farhi, David and Ryder, Nick and Pachocki, Jakub and Chen, Weizhu and Gao, Jianfeng",
        "title": "Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer"
      },
      {
        "key": "everett2024scaling",
        "author": "Everett, Katie E and Xiao, Lechao and Wortsman, Mitchell and Alemi, Alexander A and Novak, Roman and Liu, Peter J and Gur, Izzeddin and Sohl-Dickstein, Jascha and Kaelbling, Leslie Pack and Lee, Jaehoon and Pennington, Jeffrey",
        "title": "Scaling Exponents Across Parameterizations and Optimizers"
      },
      {
        "key": "hayou2023width",
        "author": "Hayou, Soufiane and Yang, Greg",
        "title": "Width and depth limits commute in residual networks"
      },
      {
        "key": "cerebras2024mupguide",
        "author": "Dey, Nolan and Anthony, Quentin and Hestness, Joel",
        "title": "The practitioner\u2019s guide to the maximal update parameterization"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "bordelon2024depthwise",
        "author": "Blake Bordelon and Lorenzo Noci and Mufan Bill Li and Boris Hanin and Cengiz Pehlevan",
        "title": "Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit"
      }
    ]
  }
]