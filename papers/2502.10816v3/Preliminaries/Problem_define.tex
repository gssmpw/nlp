
% \subsection{Problem definition}
% 123
% \label{subsec:symbolism}
% We consider a general multimodal learning framework for classification tasks.
% % Given a multimodal dataset $D_{train} = \{(x_k,y_k)\}_{k=1}^{N_D}$ with $N_D$ samples and $H$ classes, the sample $x_k = (x_k^1,x_k^2, \dots \ ,x_k^M)$ that consists of $M$ distinct modalities. 
% Let $D_{train} = \{(x_k,y_k)\}_{k=1}^{N_D}$ denote the multimodal training dataset, where $N_D$ is the number of samples. Each sample $x_k = (x_k^1,x_k^2, \dots,x_k^M)$ consists of $M$ distinct modalities, with $x_k^m$ representing the $m$-th modality, and $y_k \in \{1,2,\dots,H\}$ denoting the corresponding class label from $H$ classes.
% % Let $f(\cdot)$ represents a feature extractor which always be a deep neural network with paramerters as $\theta$.
% % For a multimodal deep neural network with $M$ modalities, where each modality has own encoder, the $i$-th unimoal encoder can be represent as $f_i(\cdot)$ with parameters as $\theta_i$.The features $\{ \Phi_k^i\}_{i=1}^M = \{f_i(x_k^i)\}$ are fused by fusion module $F$ and passed to a classifer $C$ to get the prediction $\hat{y}_k = C(F(\Phi_k)$.The training process can be optimized by:

% In a multimodal neural network with $M$ modalities, each modality employs its dedicated encoder, where the $i$-th unimodal encoder is denoted as $f_i(\cdot)$ with parameters $\theta_i$. The features $\{ \Phi_k^i\}_{i=1}^M = \{f_i(x_k^i)\}_{i=1}^M$ are integrated through a fusion module $F$ and subsequently processed by a classifier $C$ to generate the prediction $\hat{y}^k = C(F(\Phi_k))$. The training objective is optimized using:
% \begin{equation}
%     L_M = \frac{1}{B}\sum_{k=1}^B\ell(C(F(\{f_i(x_k^i)\}_{i=1}^M)), y_k),
% \end{equation}
% where $\ell$ denotes CrossEntropy loss and $B$ denotes the batch size. The selection of fusion methodology plays a crucial role in the multimodal learning. A commonly employed approach is feature concatenation, defined as $F(\{ \Phi_k^i\}_{i=1}^M) = (\Phi_k^1 \oplus\Phi_k^2\cdots\oplus \Phi_k^M)$. Under this framework, the classifier operation can be expressed as:
% \begin{equation}
%     C(F(\{f_i(x_k^i)\}_{i=1}^M) = W\cdot(\Phi_k^1 \oplus\Phi_k^2\cdots\oplus \Phi_k^M) =\sum_{i=1}^M W_i \cdot \Phi_k^i,
% \end{equation}
% where $W \in \mathbb{R}^{Y \times \sum_i^M d_i}$ is the last linear classifier, $W_i \in \mathbb{R}^{Y \times d_i}$ denotes the corresponding block of $W$ for the $i$-th modality. 
% % In this case, the unimodal loss can be expressed as:
% % \begin{equation}
% %     L_i = \frac{1}{B}\sum_{k=1}^B\ell(C(f_i(x_k^i))), y_k) = \frac{1}{B}\ell(\sum_{k=1}^B W_i \cdot \Phi_k^i).
% % \end{equation}