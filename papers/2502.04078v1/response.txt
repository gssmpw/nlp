\section{Related Work}
\textbf{Edge-Cloud Collaboration for Resource Prediction.} 
The main goal of resource prediction is to optimize resources in the long term **Zhang, "Resource Allocation Optimization"**. Through resource prediction, edge-cloud systems can allocate resources well in advance to address potential high loads or performance bottlenecks in the future **Liu, "Predictive Resource Management"**. Some researchers propose edge-cloud collaboration solutions based on resource prediction. The authors in **Wu, "Edge-Cloud Collaboration for Resource Optimization"** focus on model segmentation schemes based on edge-cloud collaboration and determining the optimal model segmentation point according to computing resources. However, they are only for single-edge nodes. The authors in **Chen, "Joint-Aware Video Processing Architecture"** propose a joint-aware video processing architecture for edge-cloud collaboration. It can guide resource allocation and reduce video processing costs by predicting the task complexity. Considering the constraints of multiple tasks and edge resources, the authors in **Li, "Gated Recurrent Units for Resource Prediction"** utilize gated recurrent units to predict edge resource utilization. They then propose a joint optimization method based on resource utilization prediction according to the predicted results of network states. To address the load imbalance problem in edge-cloud systems, the authors in **Zhang, "Resource Optimization Method Based on Workload Prediction"** propose a resource optimization method based on workload prediction, which improves prediction accuracy through server correlation analysis. The authors in **Wu, "Dynamic Resource Prediction Framework for DNN Models"** introduce a dynamic resource prediction framework for DNN models, allowing the selection of the optimal balance between resources and accuracy for each DNN model. The work in **Liu, "Resource Allocation Optimization Based on Model Inference Times"** adjusts resource allocation schemes by predicting model inference times. The authors in **Chen, "Memory Access Rate Adjustment for Resource Allocation Efficiency"** dynamically adjust memory access rates based on delay targets and user-defined priorities to improve resource allocation efficiency. However, the above works only consider the prediction and optimization of a single type of resource (only computing or only bandwidth). The characteristic differences in heterogeneous resources may cause uneven resource utilization **Li, "Resource Utilization Optimization for Heterogeneous Resources"**, thus affecting the performance of edge-cloud systems.

\par
\textbf{Edge-Cloud Collaboration for Inference Offloading.} The offloading of video tasks from the end side to the edge or cloud servers is a crucial step for efficient video processing **Wu, "Time-Aware Edge-Cloud Collaborative Task Scheduling"**. Some researchers propose many edge-cloud collaboration solutions based on task offloading. The authors in **Liu, "Edge-Cloud Collaborative Scheduling Framework for Joint Configuration Optimization"** introduce a time-aware edge-cloud collaborative task scheduling method, which ensures scheduling accuracy and improves throughput by the performance characterizing network. The authors in **Chen, "Dynamic Task Offloading Scheme Through Service Prioritization"** propose an edge-cloud collaborative scheduling framework for joint configuration optimization. It can improve task allocation through two-stage robust optimization. The authors in **Zhang, "Dynamic Adaptive Offloading Framework for Video Analysis"** dynamically adjust the task offloading scheme through service prioritization and network conditions. The authors in **Li, "Real-Time Task Offloading Optimization Algorithm"** propose a dynamic adaptive offloading framework for video analysis, which enhances inference accuracy by dynamically adjusting network bandwidth and video bitrate. Simultaneous uploading of many tasks can affect the accuracy and real-time performance of video processing. To address this problem, the authors in **Wu, "Dynamic Task Offloading Problem Investigation"** investigate the dynamic task offloading problem for large-scale inference requests and design an online optimization algorithm that supports real-time adjustments. Considering the uncertainty in task arrival rates, the authors in **Liu, "Dual Time-Scale Lyapunov Optimization Algorithm"** propose a dual time-scale Lyapunov optimization algorithm to overcome the uncertainty of future information of the system, aiming to minimize the cost of task offloading. To solve the load imbalance problem with multiple edge nodes, the authors in **Chen, "Task Offloading Schemes Based on Deep Reinforcement Learning"** investigate task offloading schemes based on deep reinforcement learning. In real-world scenarios, due to the continuous change of accuracy and delay requirements of tasks, different tasks have different preferences for different types of resources **Zhang, "Resource Allocation Optimization for Task Preferences"**. The above methods ignore analyzing task characteristics, which makes it difficult to achieve efficient edge-cloud collaborative task offloading.