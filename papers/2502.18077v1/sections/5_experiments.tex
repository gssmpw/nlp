% !TEX root = ../main.tex

\section{Experiments and Results}

\begin{wrapfigure}{R}{0.45\textwidth}
	\centering
	\includegraphics[width=0.44\textwidth]{images/agreements_lp.png}
	\vspace{-3mm}
	\caption{
		\small{Agreement between multiple linear-probed victims (trained on three datasets) and a linear-probed ViT-L/16 thief.}
	}
	\label{fig:expt1_agr}
	\vspace{-2mm}
\end{wrapfigure}


\subsection{Foundation Model Victims are Easy to Steal} \label{sec:expt1}
In this section, we try to answer the question: \emph{Is a victim fine-tuned from a foundation model more vulnerable to model stealing compared to a victim fine-tuned from a shallower model?} 
%
To do so, we train multiple victim models, including both conventional architectures and foundation models. For the thief model, we assume a well-equipped attacker who utilizes large, publicly available pre-trained foundation models, as reasoned in \ref{sec:attack_method}. 

\mypara{Linear-probed Victims} \label{main_expt}
We first consider victim models that are trained by fine-tuning the last layer of the respective pre-trained models, which is a common practice with foundation models. The thief model is a ViT-L/16, which is also linear-probed. We report the victim models' accuracy, along with the accuracy and agreement of the thief models in \Cref{tab:lp}. We draw the following observations.
%
Firstly, using foundation models leads to an increase in victim model accuracy, which is expected.
%
Secondly, the ViT-L/16 thief's accuracy is higher for victims derived from foundation models (ViT-S/16, B/16 and L/16). This can be attributed partly to the higher victim model accuracy for foundation models. Therefore, we also report the agreement between the victim and thief models, which directly quantifies the similarity between the predictions of the victim and thief.
%
Thirdly, we see that agreements are also higher for ViT victims compared to ResNets (see \Cref{fig:expt1_agr}). On the Indoor-67 dataset for instance, agreement for a ResNet-18 victim is only $40.22\%$, as compared to $60.52\%$ for a ViT-L/16 victim. These findings suggest that while foundation models like ViTs offer higher accuracy for the victim, they are also more susceptible to theft compared to non-foundation models, particularly when targeted by well-equipped attackers who utilize foundation models themselves.

\newcommand{\xx}{{$\times$}}
{\renewcommand{\arraystretch}{1.1} 
\begin{table}[t]
	\begin{center}
		\resizebox{0.99\linewidth}{!}{
			\begin{tabular}{ll|ccccccc}
				\hline
				& Victim architecture     & ResNet-18 & ResNet-34 & ResNet-50 & ResNet-101 & ViT-S/16 & ViT-B/16 & ViT-L/16 \\
				& Params (M)         & 11.18     & 21.29     & 23.53  & 42.52  & 21.66   & 85.80  & 303.31 \\
				& Pretraining dataset & IN-1K & IN-1K & IN-1K & IN-1K & IN-21K & IN-21K & IN-21K \\
				\hline
				%
				\multirow{3}{*}{\rotatebox{90}{CIFAR}} 
				& Victim accuracy & 80.74 & 81.96 & 80.24 & 84.64 & 86.38 & 94.12 & 97.61 \\
				& Thief accuracy  & 82.97 & 88.92 & 81.17 & 83.92 & 90.49 & 93.79 & 94.53\\
				& Thief agreement & 73.20 & 77.85 & 71.56 & 75.39 & 82.31 & 91.10 & 94.28 \\
				\hline
				%
				\multirow{3}{*}{\rotatebox{90}{Indoor}}
				& Victim accuracy & 54.70 & 58.06 & 45.97 & 51.49 & 78.51 & 82.76  & 87.39  \\
				& Thief accuracy  & 36.87 & 39.70 & 34.10 & 29.85 & 51.49 & 46.57 & 59.03 \\
				& Thief agreement & 40.22 & 39.63 & 44.70 & 36.72 & 49.70 & 46.79 & 60.52   \\
				\hline
				%
				\multirow{3}{*}{\rotatebox{90}{Caltech}}
				& Victim accuracy & 67.75 & 74.36 & 58.47 & 74.78 & 84.78 & 87.67 & 94.13 \\
				& Thief accuracy  & 47.42 & 54.86 & 35.38 & 53.63 & 58.20 & 57.91 & 62.83 \\
				& Thief agreement & 46.23 & 52.39 & 44.80 & 56.75 & 54.22 & 54.72 & 62.94 \\
				\hline
			\end{tabular}
		}
	\end{center}
	\caption{Model stealing results for \textbf{linear-probed victim} models on three victim datasets. Thief model is ViT-L/16. IN stands for ImageNet.}
	\label{tab:lp}
\end{table}


\begin{table}[t]
	\begin{center}
		\resizebox{0.99\linewidth}{!}{
			\begin{tabular}{ll|cccccc}
				\hline
				& Victim architecture     & ResNet-18 & ResNet-34 & ResNet-50 & ResNet-101 & ViT-S/16 & ViT-B/16 \\
				& Params (M)         & 11.18     & 21.29     & 23.53  & 42.52  & 21.66   & 85.80 \\
				& Pretraining dataset & IN-1K & IN-1K & IN-1K & IN-1K & IN-21K & IN-21K \\
				\hline
				%
				\multirow{3}{*}{\rotatebox{90}{CIFAR}} 
				& Victim accuracy & 96.54 & 97.41 & 97.62 & 98.42 & 98.33 & 98.33 \\
				& Thief accuracy  & 92.17 & 94.74 & 94.74 & 93.80 & 94.67 & 91.48 \\
				& Thief agreement & 90.89 & 93.96 & 93.80 & 93.10 & 94.01 & 91.06 \\
				\hline
				%
				\multirow{3}{*}{\rotatebox{90}{Indoor}}
				& Victim accuracy & 75.60 & 78.73 & 81.64 & 82.61 & 87.01 & 86.19 \\
				& Thief accuracy  & 43.21 & 41.64 & 47.16 & 49.63 & 55.52 & 52.83 \\
				& Thief agreement & 41.27 & 41.42 & 48.28 & 49.48 & 55.97 & 53.96  \\
				\hline
				%
				\multirow{3}{*}{\rotatebox{90}{Caltech}}
				& Victim accuracy & 76.78 & 81.39 & 86.00 & 88.70 & 93.44 & 95.14 \\
				& Thief accuracy  & 47.73 & 56.14 & 61.77 & 63.20 & 63.00 & 57.57 \\
				& Thief agreement & 44.58 & 52.78 & 60.23 & 61.67 & 62.25 & 56.98 \\
				\hline
			\end{tabular}
		}
	\end{center}
	\caption{Model stealing results for \textbf{fully fine-tuned victim} models on three different victim datasets. Thief model is ViT-L/16. IN stands for ImageNet.}
	\label{tab:fft}
\end{table}


\mypara{Fully Fine-tuned Victims} 
In this section, we evaluate victims obtained by fine-tuning all layers of the backbone models, while the thief is still a linear-probed ViT-L/16. We show the results for stealing multiple victim models using a ViT-L/16 thief in \Cref{tab:fft}, and once again, observe higher thief agreements for ViT victims compared to ResNets.


\begin{figure}[t]
	\centering
	\includegraphics[width=\textwidth]{images/lp_plots.png}
	\caption{Agreement for thieves based on foundation models (ViTs) \textit{vs.} a ResNet-34 based thief. Victim models are \textbf{linear-probed}. }
	\label{fig:lp_datasets}
\end{figure}

\subsection{Foundation Models make Strong Thieves}
So far, we have analyzed the impact of using foundation models on the victim's end. In this section, we look at the other perspective and try to answer the question: \emph{How do foundation models affect the capabilities of a thief?} 
We vary the thief's model architecture and study its impact on model stealing performance for various victim models. We compare the agreements for four thief architectures: ResNet-34, ViT-B/16, and ViT-L/16, and ViT-B/16 CLIP, for linear-probed victims in \Cref{fig:lp_datasets} and fully fine-tuned victims in \Cref{fig:fft_datasets}. We can see that for a given victim architecture, especially deeper architectures, a foundation model thief achieves higher agreement as compared to a regular ResNet thief. More importantly, the gap in performance between the ResNet thief and ViT thieves increases, as victim models become deeper.
%
When stealing smaller capacity victim models, the ResNet thief performs as well as, or even better than the stronger ViT thieves, especially for Indoor-67 and Caltech-256 datasets. But when the victim model itself is a higher capacity model, the ResNet thief manages to recover only a small proportion of the victim model's accuracy. For instance, in \Cref{fig:lp_datasets}, when stealing a ViT-B/16 victim trained on Indoor-67 dataset, a ResNet-34 thief achieves an agreement of only 25.44\%, whereas a ViT-L/16 thief achieves 46.79\% agreement. Overall, we observe that foundation models serve as better thieves, particularly when the victims are also derived from foundation models.

\begin{figure}[t]
	\centering
	\includegraphics[width=\textwidth]{images/fft_plots.png}
	\caption{Agreement for thieves based on foundation models (ViTs) \textit{vs.} a ResNet-34 based thief. Victim models are \textbf{fully fine-tuned}. }
	\label{fig:fft_datasets}
\end{figure}


\subsection{Qualitative Analysis} \label{sec:tsne}
To understand why stealing victims fine-tuned from foundation models is more successful, we visualize embeddings of the pretrained backbone models and the victim models in \Cref{fig:tsne_plots}. Using the CIFAR-10 dataset for ease of visualization, we select five victim models trained by linear probing. For the backbone, we plot t-SNE embeddings \cite{van2008visualizing} of the penultimate layer on CIFAR-10 test set. Since the victim models are obtained by fine-tuning only the classification head, we do not expect a change in embeddings of the penultimate layer. We therefore, plot the final classification layer embeddings for the victim models. Notably, for foundation models like ViT-B/16 and ViT-L/16, the backbone is already strong enough to form well-separated clusters on CIFAR-10 despite not having been trained on CIFAR-10. This clear separation of classes extends to the corresponding victim models. We hypothesize that due to the rich representations captured by the backbone architecture in foundation models, the primary computational burden in the victim model resides within this backbone structure, with relatively minimal reliance on the classification head. Consequently, when the thief model possesses a similarly robust backbone architecture, stealing the classification head becomes significantly easier. This stands in contrast to architectures such as ResNet-18, where the pre-trained features within the backbone are comparatively less potent, thereby rendering the task of stealing the classification head more challenging.


\begin{figure*}[t]
	\centering
	\includegraphics[width=\textwidth]{images/tsne_plots_cifar.png}	
	\caption{t-SNE  visualizations {\protect\cite{van2008visualizing}} of embeddings for backbone models (top row), and corresponding victim models (bottom row) trained on CIFAR-10 dataset using linear probing method. Observe that the clusters from the backbone models are much more well-separated for the foundation models (ViT-B/16 and ViT-L/16) compared to ResNets. }
	\label{fig:tsne_plots}
\end{figure*}

\subsection{Ablation Study} \label{sec:ablation}

\mypara{Impact of query budget} We vary the query budget in the range \{2K, 5K, 10K, 20K\} and compute agreement for different linear-probed victims on the Indoor-67 dataset, and a ViT-B/16 thief. Our findings indicate that the same trend holds for all query budgets: foundation models can be stolen with higher agreement compared to ResNets. While the gap in performance of ResNets and ViTs is less for lower budgets, increasing the number of queries proves more detrimental for ViTs than for ResNets (figure in Supplementary). 

\mypara{Impact of sample selection method} So far, we had used Knockoff Nets' random sample selection method \cite{orekondy2019knockoff} to select query points from the proxy dataset. We deploy two more query-set selection strategies: Entropy-based and kCenter-based methods from ActiveThief \cite{pal2020activethief} and observe similar trends in agreement for foundation models and ResNets, for linear-probed victims on the Indoor-67 dataset, stolen using a ViT-B/16 thief (figure in Supplementary), proving the generality of our findings. 

