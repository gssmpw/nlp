\begin{table}[t!]
\centering
\small
\setlength{\abovecaptionskip}{6pt}
\setlength{\belowcaptionskip}{-5pt}
\setlength{\tabcolsep}{3pt}
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{c|ccccccc}

            \textbf{Model}                      & \multicolumn{1}{c}{\textbf{Setting}}       & \textbf{Floortile} & \textbf{Barman} & \textbf{Tyreworld} & \textbf{Grippers} & \textbf{Termes} & \textbf{Blockworld} \\ \shline
\multicolumn{8}{c}{\textit{LLM-as-Planner Methods}}                                                                                         \\ \hline
                                     & \multicolumn{1}{c}{Pass@1}        & 0.0       & 6.7    & 0.0       & 23.8     & 4.8    & 4.8        \\
GPT-4o                               & \multicolumn{1}{c}{self-critique} & 10.0      & 13.3   & 0.0       & 33.3     & 0.0    & 14.2       \\
                                     & \multicolumn{1}{c}{Pass@8}        & 13.3      & 33.3   & 45.0      & 45.0     & 10.0   & 23.8       \\ \hline
                                     & \multicolumn{1}{c}{Pass@1}        & 5.3       & 33.3   & 50.0      & 57.1     & 23.8   & 38.1       \\
o1-mini                              & \multicolumn{1}{c}{self-critique} & 5.3       & 33.3   & 35.0      & 61.9     & 23.8   & 47.6       \\
                                     & \multicolumn{1}{c}{Pass@8}        & 0.0       & 33.3   & 70.0      & 61.9     & 52.4   & 23.1       \\ \hline
                                     & \multicolumn{1}{c}{Pass@1}        & 0.0       & 13.3   & 33.3      & 38.1     & 0.0    & 4.7        \\
o1-preview                           & \multicolumn{1}{c}{self-critique} & 5.0       & 6.7    & 35.0      & 33.3     & 4.7    & 9.5        \\
                                     & \multicolumn{1}{c}{Pass@8}        & 33.3      & 33.3   & 85.0      & 66.7     & 19.0   & 33.3       \\ \shline
\multicolumn{8}{c}{\textit{Our Methods (PDDL as Abstraction)}}                                                                                        \\ \hline
\rowcolor{Gray}\multicolumn{1}{l|}{Qwen2.5-7B-Coder}                       & \multicolumn{1}{c}{BoN-4}         & 0.0        & 0.0       & 0.0       & 100.0      & 81.0  & 9.5       \\
\rowcolor{Gray} \multicolumn{1}{l|}{Qwen2.5-7B-Coder}               & \multicolumn{1}{c}{BoN-16}        &  100.0    & 100.0         &   100.0       &   100.0       &  100.0   & 0.0       \\
\rowcolor{Gray} \multicolumn{1}{l|}{Qwen2.5-7B-Coder} & \multicolumn{1}{c}{BoN-4-iVML-5}  & 0.0      &  100.0  & 100.0      &  100.0      & 100.0    & 71.4       \\
\rowcolor{Gray} \multicolumn{1}{l|}{Qwen2.5-7B-Coder}                & \multicolumn{1}{c}{BoN-16-iVML-5}  & 100.0       & 100.0    & 100.0       & 100.0      & 100.0    & 81.0        
\end{tabular}
\caption{\small PDDL abstraction vs. LLM-as-Planner. The comparison uses plan accuracy as the evaluation metric. Our PDDL-based method uses the Fast Downward system~\cite{helmert2006fast} for heuristic search and plan validation.}
\label{plan_result}
\end{table}


\subsection{Comparison to LLM-as-Planner Methods}
\label{case}
In the previous sections, we demonstrated that iVML enhances LLMs' ability to generate high-quality PDDL-based world models.
In this section, we compare our method, which utilizes synthesized PDDL domains as world models, with LLMs-as-a-Planner methods that use natural language for world modeling and planning.
A detailed description of the tested planning cases is provided in Appendix~\ref{tasks}.

\vspace{1mm}
\noindent\textbf{Experimental settings}.
LLMs often hallucinate for tasks such as generating feasible or optimal plans, understanding the planning problem, and strictly following the rules, particularly in complex planning problems (\eg, Termes and Barman)~\cite{wang2024planning}.
To investigate whether these hallucinations arise from limitations in prompt engineering, we provide LLMs with explicit instructions on the rules they must follow and require them to verify rule compliance at each step of the planning process.
Additionally, we employ two strategies to reduce uncertainty in LLM-generated plans: (1) Introducing the Pass@8 metric to evaluate the probability that at least one of the top 8-generated plans is correct, and (2) Allowing LLMs to self-evaluate their plans and refine them based on these assessments.
The baseline implementations of LLM-as-Planner methods are based on GPT-4o, o1-mini, and o1-preview, respectively.

\vspace{1mm}
\noindent\textbf{Discussion on LLM-as-Planner methods}.
The observations are as follows:
(1) \emph{rule violation}: Despite explicitly informing LLMs to examine rule violation at each step, the generated plans still contain elements that inherently violate the predefined rules. For example, in the step 3 and 4 of Figure~\ref{o1-plan}, o1 incorrectly places the block from pos-0-1 to pos-1-2, mistakenly assuming that they are neighboring positions. This action violates the rule governing the placement of blocks.
(2) \emph{incorrect state transition estimation}: The LLMs fail to accurately estimate state transitions. 
For instance, after moving the block from pos-1-1 to pos-1-2, o1 incorrectly assumes that the heights of both positions are 0, reflecting an inability to track state changes correctly.
(3) \emph{incorrect goal achievement estimation}: o1 attempts to achieve the goal in a manner that disregards all constraints and relies on flawed state estimations, which results in a plan that is not only incorrect but also violates the fundamental rules of the task.
(4) \emph{incorrect self-evaluation}: o1 fails to identify errors in its planning process, as it consistently assumes that its own responses are correct. This prevents it from correcting mistakes, further compounding the inaccuracies in its generated plans.

\vspace{1mm}
\noindent\textbf{PDDL abstraction vs. LLM-as-Planner}.
We present the numerical results in Table~\ref{plan_result}.
For classical planning problems, using natural language as a planning abstraction proves suboptimal. 
Even when equipped with self-critique capabilities, the o1-preview system achieves only 5.0 on Floortile, 6.7 on Barman, and 4.7 on Termes benchmarks. 
This limitation stems from natural language's inherent ambiguity and lack of formal precision required for precise planning representation.
LLM-as-Planner methods do not perform planning; instead, they treat planning tasks as n-gram text completion problems, leading to plans that may lack feasibility, violate the constraints, or fail to accurately reflect the underlying problem structure. 
In contrast, our approach leverages PDDL representations to explicitly model state transitions. 
Through BoN-16-iVML-5 generation of high-quality world models combined with heuristic search algorithms (\ie, A$\ast$), our method solves nearly all tested instances across Floortile, Barman, and Termes domains.






