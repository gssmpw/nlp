\section{Experiments and Results}
\begin{table}[!t]
\centering
\setlength{\abovecaptionskip}{6pt}
\setlength{\belowcaptionskip}{-5pt}
\setlength{\tabcolsep}{11pt}
\renewcommand{\arraystretch}{1.3}
\scriptsize
\begin{tabular}{c|cccc}
\textbf{Model}                    &  \textbf{Params} & \textbf{NL2Domain (\%)}                                      & \textbf{Problem2Domain (\%)}          & \textbf{Avg. (\%)}                 \\ \shline
                  \multicolumn{1}{c}{}         &       \multicolumn{1}{c}{}     & \multicolumn{1}{c}{\textit{Open-Source Models}} & \multicolumn{1}{c}{}    & \multicolumn{1}{c}{} \\\hline
Qwen2.5-Instruct          & 0.5B      & 0.0                                            & 0.0                     & 0.0                  \\
Qwen2.5-Instruct          & 1.5B      & 0.0                                            & 0.0                     & 0.0                  \\
Qwen2.5-Instruct          & 3B        & 2.1                                            & 1.5                     & 0.0                  \\
Qwen2.5-Instruct          & 7B        & 5.7                                            & 11.7                     & 8.7                  \\
Qwen2.5-Instruct          & 14B       & 21.6                                           & 25.3                    & 23.5                 \\
Qwen2.5-Instruct          & 32B       & 24.0                                           & 31.6                    & 27.8                 \\
Qwen2.5-Instruct          & 72B       & 38.5                                           & 32.8                    & 35.7                 \\
Qwen2.5-Coder             & 1.5B      & 0.0                                            & 0.0                     & 0.0                  \\
Qwen2.5-Coder             & 7B        & 21.9                                           & 18.4                    & 20.2                 \\ 
Llama3.1-Instruct         & 8B        & 0.0                                            & 0.0                     & 0.0                  \\
Llama3.1-Instruct         & 70B       & 1.1                                            & 0.0                     & 0.6                  \\ 
Yi-1.5-Chat               & 6B        & 0.4                                            & 1.8                     & 1.1                  \\
Yi-1.5-Chat               & 9B        & 6.7                                            & 9.3                     & 8.0                  \\
Yi-1.5-Chat               & 34B       & 12.0                                           & 8.7                     & 10.4                  \\
Yi-Coder                  & 1.5B      & 0.0                                            & 0.0                     & 0.0                  \\
Yi-Coder                  & 9B        & 9.9                                            & 14.5                    & 12.2                  \\ \shline
 \multicolumn{1}{c}{}                 &       \multicolumn{1}{c}{}      & \multicolumn{1}{c}{\textit{Closed-Source Models}}        & \multicolumn{1}{c}{}    &                      \\\hline
GPT-4o                    & -         & 5.3                                            & 50.0 & 27.7                  \\
o1-mini                   & -         & 41.7                                           & 33.7 & 37.7                  \\ 
o1-preview          & -    & 55.8 & 52.4 & 54.1 \\ 
\shline
                \multicolumn{1}{c}{}            &      \multicolumn{1}{c}{}       & \multicolumn{1}{c}{\textit{Our Methods}}       & \multicolumn{1}{l}{}    &                      \\ \hline
\rowcolor{Gray}BoN-8-Qwen2.5-Instrcut    & 0.5B      & 0.0 ($+$0.0)                                    & 0.0 ($+$0.0)            & 0.0    \\
\rowcolor{Gray}BoN-8-Qwen2.5-Instrcut    & 1.5B      & 2.1 ($+$2.1)                                    & 0.3 ($+$0.3)            & 1.2             \\
\rowcolor{Gray}BoN-8-Qwen2.5-Instrcut    & 3B        & 11.7 ($+$9.5)                                   & 1.2 ($+$0.3)            & 6.5       \\
\rowcolor{Gray}BoN-8-Qwen2.5-Instrcut    & 7B        & 9.2 ($+$3.5)                                     & 34.6 ($+$22.9)            & 21.9       \\
\rowcolor{Gray}BoN-8-Qwen2.5-Instrcut    & 14B       & 51.6 ($+$30.0)                                   & 62.0 ($+$36.7)            &   56.8           \\
\rowcolor{Gray}BoN-8-Qwen2.5-Instrcut    & 32B       & 66.8 ($+$46.7)                                   & 71.1 ($+$39.5)            & 70.9       \\
\rowcolor{Gray}BoN-8-Qwen2.5-Instruct    & 72B       & 60.8 ($+$22.3)                                   & 73.8 ($+$41.0)            & 67.3      \\
\rowcolor{Gray}BoN-8-Qwen2.5-Coder       & 7B        & 73.1 ($+$51.2)                                   & 63.3 ($+$44.9)            & 68.2       \\
\rowcolor{Gray}iVML-5-BoN-8-Qwen2.5-Instruct & 0.5B        & 0.0 ($+$0.0)                                & 0.0 ($+$0.0)     & 0.0        \\ 
\rowcolor{Gray}iVML-5-BoN-8-Qwen2.5-Instruct & 1.5B        & 2.8 ($+$2.8)                               & 0.3 ($+$0.3)     & 1.6         \\ 
\rowcolor{Gray}iVML-5-BoN-8-Qwen2.5-Instruct & 3B        & 18.7 ($+$16.6)                               & 1.8 ($+$0.3)     & 10.3         \\
\rowcolor{Gray}iVML-5-BoN-8-Qwen2.5-Instruct & 7B        & 21.9 ($+$16.2)                                & 49.1 ($+$37.3)     & 35.5      \\ 
\rowcolor{Gray}iVML-5-BoN-8-Qwen2.5-Instruct & 14B        & 77.0 ($+$55.4)                               & 80.4 ($+$55.1)     &   78.7      \\ 
\rowcolor{Gray}iVML-5-BoN-8-Qwen2.5-Instruct & 32B        & 86.2 ($+$62.2)                               & 90.9 ($+$59.3)     & 88.6         \\ 
\rowcolor{Gray}iVML-5-BoN-8-Qwen2.5-Instruct & 72B        & 78.4 ($+$39.9)                              & 86.4  ($+$53.6)     & 82.4        \\ 
\rowcolor{Gray}iVML-5-BoN-8-Qwen2.5-Coder & 7B        & 85.2 ($+$63.3)                                   & 71.4 ($+$53.0)            & 78.3   \\  

\end{tabular}
\caption{\small  A comparison of performance in PDDL domain synthesis. BoN-8 refers to BoN sampling with 8 candidates, while iVML-5-BoN-8 denotes five iterations of iVML training initialized with BoN-8.}
\label{tab:main-results}
\end{table}

We conduct extensive experiments to compare our test-time scaling algorithm to existing state-of-the-art methods on competition-level PDDL domain synthesis tasks.
Our method improves PDDL generation across nearly all tested LLMs.
By using PDDL as an intermediate abstraction layer, we have shifted the role of LLMs from acting as planners to generating PDDL-based world models.
The generated PDDL-based world model, combined with a classical planner in the loop, helps to reduce hallucinations when using LLMs directly as planners.

\subsection{Experiment Setup}
\textbf{Evaluation tasks and datasets}. 
We evaluate several test-time scaling methods on the International Planning Competition benchmark\footnote{https://github.com/potassco/pddl-instances}, which encompasses diverse complex planning domains and problems.
Our evaluation focuses on two key PDDL domain synthesis tasks, including
(1) NL2Domain which aims to convert Natural Language Descriptions to PDDL Domains; and 
(2) Prob2Domain which aims to derive necessary PDDL domains from PDDL problems.
The evaluation metric used here is the success rate of the generated PDDL domain passing the PDDL validation system~\cite{howey2003val}. 

\vspace{1mm}
\noindent\textbf{Large language model settings}. The backbone LLMs in our experiment include Qwen2.5-Instruct (0.5B-72B parameters)~\cite{yang2024qwen2}, LLaMA3.1-Instruct (8B and 70B parameters)~\cite{dubey2024llama}, and Yi-1.5-Chat (6B, 9B, and 34B parameters)~\cite{young2024yi}.
We also incorporate specialized code-oriented LLMs, specifically Qwen2.5-Coder and Yi-1.5-Coder.
In addition to open-source LLMs, we benchmark against OpenAI's proprietary models, including GPT-4o, o1-mini, and o1-preview.
We test our proposed methods on Qwen models in a zero-shot setting without model finetuning.

\vspace{1mm}
\noindent\textbf{Chain of thought prompting}.
All baselines here utilize chain-of-thought (CoT) prompting by default.
Current LLMs have been extensively trained on datasets that include step-by-step reasoning besides final answers~\cite{weston2023system}.
This enables the models to generate better reasoning traces during inference.
The detailed CoT prompt template for our method is provided in Appendix~\ref{prompt_template}.

\vspace{1mm}
\noindent\textbf{Sampling hyperparameters}. 
To generate diverse PDDL domain synthesis paths, we use temperature sampling ($T = 0.7$) for both the BoN and iVML algorithms. 

\subsection{Main Results in PDDL Domain Synthesis}

\vspace{1mm}
\noindent\textbf{Current LLMs perform poorly in PDDL domain synthesis.}
Despite advances in code and math reasoning, LLMs exhibit fundamental limitations in PDDL-based formal synthesis.
For instance in Table~\ref{tab:main-results}, Qwen2.5-Instruct (72B) achieves only 38.5\% and 32.8\% accuracy in NL2Domain and Prob2Domain tasks, respectively.
The results suggest that existing LLMs still fall short in symbolic reasoning tasks.

\vspace{1mm}
\noindent\textbf{Search-augmented reasoning enhances formal synthesis.}
In Table~\ref{tab:main-results}, among the closed-source models, o1-preview emerges as the top performer with an average accuracy of 54.1\%, outperforming other models in both NL2Domain and Problem2Domain tasks. 
The o1-series models, which integrate search-based reasoning during inference~\cite{o1journey, zeng2024scaling}, demonstrate significant improvements over standard instruction LLMs. For example, GPT-4o achieves only an average accuracy of 27.7\%.

\vspace{1mm}
\noindent\textbf{Code-oriented models outperform general-purpose models.}
In Table~\ref{tab:main-results}, we can observe that code-specialized models (\eg, Qwen2.5-Coder and Yi-1.5-Coder) demonstrate superior performance than their general-purpose counterparts.
For example, Qwen2.5-Coder (7B) outperforms Qwen-Instruct (7B) by 16.2\% NL2Domain (\ie, 21.9\% compared to 5.7\%).
We hypothesize that the improvements stem from: (1) Implicit formalization training: code datasets teach type systems and predicate logic, (2) Syntax-sensitive decoding: token-wise likelihood aligns with PDDL's Lisp-like structure, and (3) Autoformalization priors: the code datasets that interleave natural language comments with pieces of code are high-quality datasets for chain-of-thought reasoning and autoformalization. 

\vspace{1mm}
\noindent\textbf{Test-time scaling is helpful for LLM at almost all scales.}
The BoN sampling method demonstrates universal effectiveness across the Qwen model family (\eg, 1.5B to 72B parameters), significantly improving PDDL domain synthesis accuracy.
For example in Table~\ref{tab:main-results}, BoN sampling with 8 candidates (BoN-8) improves Qwen2.5-Instruct (14B) from 21.6\% to 51.6\% on NL2Domain. 
Gains persist through Qwen2.5-Instruct (72B) with 22.3\% improvement on NL2Domain.
Test-time compute scaling requires no further training or architectural changes, making it a computationally efficient addition to scaling up LLM's parameter numbers.

\vspace{1mm}
\noindent\textbf{iVML can provide a robust and consistent improvement.}
iVML delivers robust performance gains over BoN across multiple model scales, demonstrating the power of iterative self-improvement in PDDL domain synthesis.
As illustrated in Table~\ref{tab:main-results}, five iterations of iVML training with BoN-8 initialization (iVML-5-BoN-8) enables Qwen2.5-Instruct (32B) to achieve 86.2\% on NL2Domain, outperforming base BoN-8 with 19.4\% improvement.
The results position iVML as a scalable and efficient framework for enhancing LLM performance in formal synthesis tasks.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.94\linewidth]{content/imgs/GD_Samp.pdf}
    \caption{\small Left: The performance trend of iVML with increasing training epochs. Right: The performance trend of BoN with increasing sampling numbers.}
    \label{ablate}
\end{figure}

\subsection{Convergence Comparison between BoN and iVML}
\label{model_setup}
\noindent\textbf{Experiment settings}. This section presents a comparative analysis of the convergence behavior of BoN and iVML in PDDL domain synthesis tasks.
The computational efficiency and synthesis success rates of these methods depend on two parameters: the sampling budget for BoN \textbf{$N$}, and the number of training epochs for iVML \textbf{$T$}.
Through controlled experiments, we examine how parametric variations affect synthesis effectiveness and identify the conditions under which their performance converges.
 Our empirical evaluation uses Qwen2.5-Coder (7B) as the backbone LLM. The initialization of iVML is based on BoN-8 if not otherwise specified.

\vspace{1mm}
\noindent\textbf{Convergence of BoN and iVML}.
In Figure~\ref{ablate}, we observe that BoN sampling undergoes two phases.
Phase 1 ($N \leq 32$): Accuracy improves sublinearly with the sampling budget, demonstrating the exploration efficiency of candidate sampling for enhancing accuracy.
Phase 2 ($N>32$): Performance reaches saturation with observable degradation trends.
In contrast, iVML exhibits monotonic performance improvement up to $T=80$, significantly surpassing the saturated success rate achieved by BoN.
For example, BoN saturates at 260 domains for NL2Domain and fails to exceed 300 domains for Prob2Domain at $N=256$. 
In comparison, iVML successfully synthesizes more than 270 domains for NL2Domain and achieves around 310 domains for Prob2Domain at $T=80$, demonstrating its superior performance over BoN.

\vspace{1mm}
\noindent\textbf{Case study}.
The qualitative case study is presented in Table~\ref{tab:blockworld_comparison}, where we show BoN often fails to generate the correct code.
For example, in TyreWorld, despite explicitly stating the precondition that the container is open, BoN still generates the invalid predicate ``closed ?container'' to represent the relationship.
Unlike BoN's brute-force sampling approach, iVML leverages an in-context self-refinement mechanism to
(1) identify constraint violations (\eg, illegal block stacking or invalid preconditions);
(2) generate counterfactual natural language feedback to guide revisions;
(3) strengthen domain-specific reasoning priors through iterative updates.
Consequently, iVML can fix the BoN error and formulate the corrected predicate  ``not (closed?container)''

\vspace{1mm}
\noindent\textbf{Analysis}.
In Figure~\ref{ablate}, we observe BoN's early saturation and performance degradation.
This observation aligns with inference scaling flaws~\cite{stroebl2024inference}, where the optimal number of resampling steps for code synthesis tasks (\eg, HumanEval~\cite{austin2021program} and MBPP~\cite{chen2021evaluating}) is always finite and low.
This phenomenon arises from the lack of in-context learning with feedback from a verifier.
However, iVML uses a self-critique mechanism combined with in-context learning to create a synthetic curriculum, enabling the model to learn to avoid error patterns in PDDL synthesis progressively.
In contrast, BoN struggles with such dependencies due to its reliance on static sampling and the lack of iterative refinement.


\begin{table}[t]
    \centering
    \belowrulesep=0pt
    \aboverulesep=0pt
    \setlength{\abovecaptionskip}{6pt}
    \setlength{\belowcaptionskip}{-5pt}
    \setlength{\tabcolsep}{3pt}
    \renewcommand{\arraystretch}{1.35}
    \scriptsize
    \begin{tabular}{p{5cm}|p{4.5cm}|>{\columncolor{Gray}}p{7cm}} 
    \multicolumn{1}{c|}{\textbf{Natural Language}} & 
    \multicolumn{1}{c|}{\textbf{BoN@8}} & 
    \multicolumn{1}{c}{\cellcolor{Gray} \textbf{BoN@8 $+$ iVML@5}} \\
    \noalign{\global\arrayrulewidth=0.5pt}\shline\noalign{\global\arrayrulewidth=0.4pt}
    BlockWorld (stack): The arm can stack a block on top of another if it holds the top block and the bottom block is clear. Post-action, the arm is empty, the top block rests on the bottom block, and the bottom block is no longer clear. 
    &
    (:action stack

    :parameters (?top - block ?bottom - block)

    :precondition (and (holding ?top) (clear ?bottom))

    {\color{c2}:effect (and (not (holding ?top)) (on ?top ?bottom) (clear ?bottom))}
    &
    \textcolor{c1}{Incorrectly clear the bottom block, which should not happen when stacking a block on the bottom block.}
    
    (:action stack

    :parameters (?top - block ?bottom - block)

    :precondition (and (holding ?top) (clear ?bottom))

    :effect (and (arm-empty) (not (holding ?top)) (not (clear ?bottom)) (on ?top ?bottom)))\\
    \midrule



    



    TyreWorld(fetch): The precondition for this action is that the object is inside the container and the container is open. The effect of this action is that the object is held by the agent and not inside the container.
    &
    (:action fetch

    :parameters (?obj - object ?container - container)
    
    {\color{c2}
    :precondition (and (in ?obj ?container) (closed ?container))

    :effect (and (in ?obj ?container) (not (in ?obj ?container)))}

    &
    \textcolor{c1}{The logic for the fetch action is incorrect.
    Precondition: Incorrectly checks if the object is inside the container and the container is open.
    Effect: Incorrect logic. The effect should be ``(not (in ?obj ?container))'' instead of ``(in ?obj ?container) (not (in ?obj ?container))''}

    (:action fetch
    
    :parameters (?obj - object ?container - container)
    
    :precondition (and (in ?obj ?container) (not (closed ?container))) 
    
    :effect (not (in ?obj ?container))\\
    
    \midrule
    TSP(return-against): This action also completes the tour by allowing the agent to return to the starting city against the direction of a connection. The precondition is similar to the ``return-along'' action, except the city is not previously visited. The effect is that the agent returns to the starting point and the tour is marked as complete.
    &
    (:action return-against

    :parameters (?current-city - city ?start-city - city)

    :precondition (and (in ?current-city)
                       {\color{c2}(connected ?start-city ?current-city)(not-complete))}

    :effect (and (in ?start-city)
                 (complete)))
    & 
    \textcolor{c1}{The precondition for this action should have ``(connected ?current-city ?start-city)'' instead of ``(connected ?start-city ?current-city)'' to correctly reflect the travel direction. }
    
    (:action return-against

    :parameters (?current-city - city ?start-city - city)

    :precondition (and (in ?current-city)
                       (connected ?current-city ?start-city)
                       (not-complete))

    :effect (and (in ?start-city)
                 (complete))) \\
    \midrule
    Termes(remove-block): Create a block at the depot. The robot will have the block
    &
    (:action remove-block
    
    :parameters (fromPos toPos)
    
    :precondition (and (height fromPos ?h) (SUCC ?h ?h-down)
    
    (height toPos ?h-down) (at fromPos) (not (has-block)))
    
    {\color{c2}:effect (and (has-block) (height toPos ?h)))}
  & 
  \textcolor{c1}{The effect of the ``remove-block'' action does not correctly update the height of the block's position. It should be ``(height toPos ?h-down)'', but it is currently ``(?h-down)''.}

  (:action remove-block
  
    :parameters (fromPos toPos)
    
    :precondition (and (height fromPos ?h) (SUCC ?h ?h-down) 
    
    (height toPos ?h-down) (at fromPos) (not (has-block)))
    
    :effect (and (has-block) (height toPos ?h-down)))
    \end{tabular}
    \caption{\small The comparison highlights the differences between Best-of-N sampling (BoN) and iVML in synthesizing action-level PDDL code. The {\color{c2} red} text marks where BoN@8 produces logically incorrect code, while the {\color{c1} blue} text shows how iVML detects these inaccuracies and applies the necessary corrections.}
    \label{tab:blockworld_comparison}
\end{table}

\subsection{Ablation Study of Initialization Strategies}
\vspace{1mm}
\textbf{Experiment settings}.
This section investigates the effect of initialization strategies on iVML through a controlled experiment. 
We evaluate three LLMs—Qwen2.5-Coder (7B), Deepseek-Coder-Instruct-v1.5 (7B), and LLaMa-3.1-Instruct (8B)—across two different initialization settings: single-pass and BoN-8.
Among these models, LLaMa-3.1-Instruct (8B) is defined as a ``weak model'' in PDDL synthesis, as it achieves a zero success rate in the main experiment in Table~\ref{tab:main-results}.
The purpose of including it in this study is to investigate whether our approach can enhance LLaMa's capabilities in PDDL synthesis, enabling its transition from a weak to a strong model.

\vspace{1mm}
\noindent\textbf{BoN vs. Single-pass sampling}.
BoN sampling, as an initialization strategy, provides iVML with the dual advantages of accelerated convergence and improved solution quality. 
For example, in Figure~\ref{fig:ablate_nl2domain}, with BoN-8 initialization in NL2Domain, Deepseek-Coder saturates earlier than its single-pass counterpart at $T=16$, while achieving higher accuracy (reaching approximately 270 successful domains compared to fewer than 200 in single-pass).
Unlike single-pass sampling, which is analogous to random initialization in traditional optimization, \eg, stochastic gradient descent, BoN generates a diverse set of initial candidate solutions. 
The solution diversity can effectively improve iVML with expanded exploration. By covering a broader range of the solution space, BoN helps to avoid early convergence to suboptimal solutions. 
This means that the algorithm is less likely to get stuck in local minima, which are common challenges in complex optimization problems~\cite{baker2019learning}. By selecting high-quality initial solution candidates, BoN guides the optimization process of iVML toward better optimality.

\vspace{1mm}
\noindent\textbf{Performance of weaker LLMs}. 
From Figure~\ref{fig:ablate_nl2domain}, we observe that iVML with BoN-8 initialization can improve LLaMa's performance in the NL2Domain task, which yields around 10 correct domains compared to zero in single-pass mode. However, the performance is far worse than Qwen2.5-Coder (7B) and Deepseek-Coder-Instruct-v1.5 (7B).
We attribute this performance gap to LLaMa's limited exposure to structured logical reasoning during pretraining, a deficiency in its pretraining knowledge that test-time compute scaling methods (\eg, iVML and BoN) cannot effectively address.

\vspace{1mm}
\begin{figure}[t]
    \centering
    \begin{minipage}[b]{0.47\linewidth}
        \centering
        \includegraphics[width=\linewidth]{content/imgs/vml_nl.pdf}
        \vspace{-7mm}
        \caption{\small The performance of iVML on NL2Domain tasks across different initialization settings.}
        \label{fig:ablate_nl2domain}
    \end{minipage}
    \hfill
    \begin{minipage}[b]{0.47\linewidth}
        \centering
        \includegraphics[width=\linewidth]{content/imgs/vml_prob.pdf}
        \vspace{-7mm}
        \caption{\small The performance of iVML on Prob2Domain tasks across different initialization settings.}
        \label{fig:ablate_prob2domain}
    \end{minipage}
\end{figure}



\subsection{PDDL Problem Generation}
\vspace{1mm}
\noindent \textbf{Experiment settings.}
This section investigates the effectiveness of our approach while generalized to PDDL problem synthesis. 
In contrast to the PDDL domain, which outlines the general framework or environment defined for planning tasks, the PDDL problem defines a specific instance of the planning task within that domain. 
This involves defining two main components (1) Initial state: the starting state of the world, defined by the predicates that are true initially, and (2) Goal state: The objective that the planner aims to achieve.
We adopt the Planetarium~\cite{zuo2024planetarium} benchmark, which evaluates LLMs' capacity to generate precise PDDL problems from natural language descriptions. 
These tasks are challenging due to the lack of planning background knowledge and the complex context described by the problem.
The evaluation methods outlined in ~\cite{zuo2024planetarium} test LLMs in both zero-shot and fine-tuned settings. 
The baselines being evaluated include GPT-4, Gemma 1.1 IT models~\cite{team2024gemma} with 2B and 7B parameters, as well as Mistral v0.3 Instruct (7B)~\cite{jiang2023mistral}. 


\vspace{1mm}
\noindent\textbf{Main results}. 
The results are presented in Table~\ref{tab:model_performance}.
Planetarium fine-tuned Gemma and Mistral on a training dataset containing 132,027 examples from the two-class PDDL problem code dataset, potentially raising overfitting concerns as Gemma's accuracy increased dramatically from near 0.0\% to over 98.8\%.
Our method enhances the Qwen2.5-Coder (7B) model through test-time scaling techniques, achieving a 99.24\% correctness rate with BoN-16 sampling. 
This improves further to 99.60\% when combining iVML-1 with BoN-16 for solution initialization.


\begin{table}[t!]
\centering
\setlength{\abovecaptionskip}{6pt}
\setlength{\belowcaptionskip}{-5pt}
\setlength{\tabcolsep}{25pt}
\renewcommand{\arraystretch}{1.3}
\small
\begin{tabular}{c|c|c}
\textbf{Model} & \textbf{Setting} & \textbf{Success Rate (\%)} \\
\shline
\multirow{2}{*}{Gemma 1.1 IT 2B} & Zero-shot & 0.00 \\
 & Fine-tuned & 94.21 \\
\multirow{2}{*}{Gemma 1.1 IT 7B} & Zero-shot & 0.00 \\
 & Fine-tuned & 98.79 \\

\multirow{2}{*}{Mistral v0.3 Instruct 7B} & Zero-shot & 0.01 \\
 & Fine-tuned & 99.00 \\

GPT-4o & Zero-shot & 35.12 \\
\rowcolor{Gray} Ours (Qwen2.5-Coder-7B) & BoN-16 & 99.24\\
\rowcolor{Gray} Ours (Qwen2.5-Coder-7B) & iVML-1-BoN-16 & 99.60
\end{tabular}
\caption{\small Performance comparison of different models on PDDL problem generation}
\label{tab:model_performance}
\end{table}

\vspace{1mm}
\noindent\textbf{Comparison between SFT and iVML}.
The results in Table~\ref{tab:model_performance} provide a comparison between supervised finetuning (SFT) and iVML. This reveals three key advantages of our method (listed as follows).
(1) \emph{Preventing catastrophic forgetting}: Unlike SFT's static alignment to fixed data distributions, iVML enforces structured reasoning priors through in-context learning, enabling adaptation to diverse problem constraints without catastrophic forgetting.
(2) \emph{Refinement through in-context optimization}: Building upon BoN's high-quality initialization, iVML performs in-context instance optimization to correct subtle errors, elevating correctness from 99.24\% (BoN-16) to 99.60\% (iVML-1-BoN-16).
(3) \emph{Computational efficiency}: iVML requires significantly less compute than SFT while demonstrating strong performance on complex reasoning tasks, including those in long-tail domains.



