\section{Related Work}
\subsection{Instructors' Perceptions and Practices of Technology}
Since the concept of using computers and other information and communication technologies in education emerged~\cite{nwana1990intelligent}, researching technology acceptance in teaching and learning contexts has become an attractive and consistent trend~\cite{imtiaz2014review, teo2011technology}. Prior research has investigated acceptance and attitudes toward learning technology in educational contexts, with a primary focus on university students rather than instructors~\cite{granic2019technology}. However, it is instructors' attitudes that can significantly impact the acceptance of new technologies when incorporated into university education~\cite{donnell2009relationship, hall2013assessing, palmore2011faculty, bunk2015understanding, kosak2004prepared}. 
Compared to a generally positive perception by instructors of technology~\cite{marzilli2014faculty, kopcha2016understanding, qudais2010senior, onwuagboke2016faculty, akbarilakeh2019attitudes}, a decline in acceptance of technology is often observed among faculty when sufficient support from institutions are not provided~\cite{ramlo2021coronavirus, daumiller2021shifting}, demonstrating and emphasizing the importance of understanding faculty attitudes toward technology early to formulate related policies or provide proper training by institutions.

The release of ChatGPT in 2022 brought GenAI-based applications into the spotlight and attracted widespread attention. GenAI continues driving innovation in higher education, presenting both opportunities and challenges for teaching and learning~\cite{michel2023challenges, adeshola2023opportunities}. On the one hand, a growing body of literature has documented the potential of integrating GenAI into higher education, such as generating course materials~\cite{denny2022robosourcing, sarsa2022automatic} and assisting students' programming tasks~\cite{lyu2024evaluating, poldrack2023ai}. On the other hand, recent work has also highlighted issues of the use of GenAI in higher education~\cite{kasneci2023chatgpt}, such as accuracy~\cite{johnson2023assessing}, reliability~\cite{johnson2023assessing, walker2023reliability}, and plagiarism~\cite{jarrah2023using}. 

With the rapid adoption of GenAI across different fields, recent studies have looked into people's attitudes and practices regarding using GenAI, particularly in the context of higher education.  For example, current research has explored both undergraduate and graduate students' perceptions of ChatGPT across cultural contexts, including Asia~\cite{ngo2023perception, farhi2023analyzing, shoufan2023exploring}, Europe~\cite{stohr2024perceptions, singh2023exploring, romero2023use}, Australia ~\cite{gruenhagen2024rapid}, and North America~\cite{baek2024chatgpt}. These investigations identify shared ethical concerns regarding GenAI while also revealing region-specific attitudes, suggesting the importance of culturally contextualized approaches to its integration. Likewise, Luo~\cite{luo2024critical} examined GenAI-related institutional policies across universities worldwide, revealing significant inconsistencies and pointing to the need for more cohesive, context-aware frameworks to guide GenAI adoption in educational settings. 

However, fewer studies have explicitly examined instructors' perceptions and practices of GenAI~\cite{albayati2024investigating}. A few exceptional examples include recent survey studies conducted in Europe~\cite{beege2024ai,kiryakova2023chatgpt}, Asia~\cite{espartinez2024exploring}, North America~\cite{amani2023generative, ghimire2024generative}, and mixed cultural contexts~\cite{lau2023ban}. Among this body of work, they mostly focus on perceived benefits (e.g., enhanced teaching efficiency) and risks (e.g., unethical usage, bias, privacy concerns) rather than systematically differentiating trust from distrust. For example, a survey of German STEM teachers by Beege et al.~\cite{beege2024ai} revealed that while perceived competence in ChatGPT supported usage intentions, perceived risks and concerns negatively impacted adoption, suggesting the nuanced interplay between confidence and hesitation. Similarly, Bulgarian professors exhibited predominantly positive attitudes toward ChatGPT but nonetheless expressed concerns about unethical applications~\cite{kiryakova2023chatgpt}. Meanwhile, Espartinez~\cite{espartinez2024exploring} used Q-methodology in the Philippines to highlight a diverse spectrum of instructor and student perspectives, ranging from ethical considerations to practical challenges. North American studies also contribute to this discussion, where Amani et al.~\cite{amani2023generative}, for example, surveyed faculty and staff on overall perceptions of GenAI but did not explicitly dissect trust versus distrust. Furthermore, much of this work remains confined to single disciplines~\cite{ayanwale2024exploring, lau2023ban}, leaving a gap in understanding how instructors across a broad range of fields relate to GenAI. Extending the existing body of literature, our work seeks to unpack how trust and distrust in GenAI manifest among instructors in higher education.


\subsection{Trust and Distrust in AI-Driven Educational Environments}

Trust is often conceptualized as a willingness to be vulnerable based on positive expectations of another party’s intentions or behavior, enabling cooperation and reducing uncertainty~\cite{mayer1995integrative, dirks2001role}. In contrast, distrust is conceptualized as a distinct construct reflecting suspicion and the expectation of harm~\cite{lewicki1998trust}. While trust is generally viewed positively as a facilitator of relationships and systems, distrust is often associated with caution and avoidance. Some scholars argue that trust and distrust can coexist, highlighting the nuanced and dynamic ways individuals evaluate others or systems~\cite{lewicki1998trust, schilke2021trust}. These conceptualizations of trust and distrust have been extended to interactions with AI systems. For example, Jacovi et al.~\cite{jacovi2021formalizing} define trust and distrust in AI as a human perceiving an AI model as trustworthy and accepting vulnerability to the model's actions or not. Prior research has explored different factors contributing to individuals' trust in GenAI, such as the AI models' trustworthiness~\cite{sun2024trustllm}, explainability~\cite{bhattacharjee2024towards}, transparency~\cite{sarker2024llm}, etc. However, research has also shown that trust is highly contextual, with users basing their trust on different factors depending on the task. For example, preciseness plays a key role in shaping trust in AI recommendations~\cite{kim2021you}, whereas users prioritize the originality of AI-generated content in creative tasks~\cite{daly2024sensemaking}. Furthermore, individual differences in trust have also been well-documented since the pioneering research on technology acceptance~\cite{davis1989perceived, davis1989technology}. Thus, it is crucial to investigate how trust and distrust factors influence the adoption of technologies like GenAI within specific groups, such as instructors, whose professional roles and dedicated tasks may shape their engagement with these technologies.


A body of research has already focused on analyzing and explaining trust in GenAI within the context of higher education. For example, Amoozadeh et al.~\cite{amoozadeh2024trust} conducted an exploratory study explicating university students' trust in GenAI, while Kim et al.~\cite{kim2023you} found that subpar responses from GenAI significantly decreased users' trust. However, understanding distrust is just as important as trust, as both factors influence how instructors engage with and integrate technologies like GenAI. Although much of the existing research prioritizes trust, and some recent studies have started to explore distrust~\cite{lankton2015technology, zhang2024profiling}, the role of distrust in the adoption of GenAI remains underexplored and insufficiently acknowledged. Given the imperfections of GenAI models, fostering a healthy level of distrust is essential for responsible use, underscoring the need to consider both trust and distrust as equally important factors~\cite{peters2023importance}. Meanwhile, it is essential to avoid blind trust, which involves unconditionally accepting without critical evaluation, as this can leave individuals vulnerable to exploitation in such situations~\cite{min2023development}. Conversely, blind distrust occurs when trust is withheld despite evidence of trustworthiness, potentially leading individuals to miss valuable opportunities~\cite{beccerra1999trust}. 

Although our discussion centers on GenAI, we situate it within the broader context of technology-driven educational tools. Traditional views of trust in education often tend to categorize trust in educational settings into inter-organizational trust and interpersonal trust~\cite{niedlich2021comprehensive}, the rise of Intelligent Tutoring Systems (ITS)~\cite{nwana1990intelligent, sleeman1982intelligent} has introduced a new dimension of trust between humans and educational tools in modern educational environments. Existing research on teachers' trust in GenAI-based educational tools largely centers on K-12 education~\cite{nazaretsky2022teachers, viberg2024explains, qin2020understanding, nazaretsky2022instrument, beege2024ai}. In higher education, Wang et al.~\cite{wang2020participant} examined Chinese instructors’ attitudes toward ITS, though their work emphasized identifying relevant factors rather than examining how trust dynamics are formed. Similarly, Klein et al.~\cite{klein2019technological} studied instructors’ engagement with learning tools in a context culturally similar to ours, but conducted their study before the emergence of GenAI, leaving AI-related issues unexamined. Our work seeks to address this research gap by examining the nuanced ways trust and distrust can manifest among instructors using GenAI, and by offering actionable insights for (dis)trust calibration among both instructors and students.

This work aims to answer the following research questions (RQs): \\
    \textbf{RQ1.} What are the current practices of instructors in the U.S. higher education using (and not using) GenAI in the higher educational context? and \\
    \textbf{RQ2.} How do instructors in the U.S. higher education trust and distrust GenAI in an educational context? and how trust and distrust in GenAI manifest among them? 


%----------------------------------------------------------------------------------------------