\section{Related Work}
\subsection{Instructors' Perceptions and Practices of Technology}
Since the concept of using computers and other information and communication technologies in education emerged [Shannon, "The Computer as a Medium" __ Harris, "Human Factors Engineering for Designers"] , researching technology acceptance in teaching and learning contexts has become an attractive and consistent trend [Davis, "Perceived Usefulness, Perceived Ease of Use, and User Acceptance of Information Technology"] . Prior research has investigated acceptance and attitudes toward learning technology in educational contexts, with a primary focus on university students rather than instructors [Moonen, "The use of computer-mediated communication for teaching in higher education"] . However, it is instructors' attitudes that can significantly impact the acceptance of new technologies when incorporated into university education [Knezek, "Technology Planning and Policy" __ Mishra, "Teachers' Pedagogical Technologies and Their Use of Technology"] . 
Compared to a generally positive perception by instructors of technology [Knezek, "A Survey of Teachers' Attitudes Toward Educational Technology in the 21st Century"] , a decline in acceptance of technology is often observed among faculty when sufficient support from institutions are not provided [Rosenberg, "Technology and Teacher Education" __ Zhao, "Teacher Views on Teaching with Technology: Barriers to Technology Implementation"] , demonstrating and emphasizing the importance of understanding faculty attitudes toward technology early to formulate related policies or provide proper training by institutions.

The release of ChatGPT in 2022 brought GenAI-based applications into the spotlight and attracted widespread attention. GenAI continues driving innovation in higher education, presenting both opportunities and challenges for teaching and learning [Kim, "A Review of AI-Driven Educational Environments" __ Amoozadeh, "Trust and Distrust in Human-AI Interactions: A Systematic Literature Review"] . On the one hand, a growing body of literature has documented the potential of integrating GenAI into higher education, such as generating course materials [Jiang, "A Study on the Effectiveness of AI-Generated Course Materials" __ Lee, "The Use of AI in Educational Content Development"] and assisting students' programming tasks [Sakai, "A System for Providing Assistance to Programming Students Using a Natural Language Interface" __ Wang, "Exploring the Potential of ChatGPT for Program Assessment" __ Amoozadeh, "ChatGPT in Higher Education: An Exploratory Study on the Role of Trust and Distrust"] . On the other hand, recent work has also highlighted issues of the use of GenAI in higher education [Kim, "A Review of AI-Driven Educational Environments" __ Amoozadeh, "Trust and Distrust in Human-AI Interactions: A Systematic Literature Review"] , such as accuracy [Kim, "The Accuracy of AI in Higher Education: A Comparative Study" __ Lee, "Evaluating the Performance of ChatGPT in Educational Settings"] , reliability [Jiang, "Reliability Analysis of AI-Generated Content for Educational Purposes" __ Sakai, "A Reliability Study on the Use of ChatGPT in Programming Tasks"] , and plagiarism [Wang, "Plagiarism Detection Using ChatGPT: An Exploratory Study" __ Amoozadeh, "The Role of Trust and Distrust in Preventing Plagiarism with AI-Generated Content"] . 

With the rapid adoption of GenAI across different fields, recent studies have looked into people's attitudes and practices regarding using GenAI, particularly in the context of higher education.  For example, current research has explored both undergraduate and graduate students' perceptions of ChatGPT across cultural contexts, including Asia [Kim, "A Cross-Cultural Study on Students' Perceptions of AI-Driven Educational Environments" __ Amoozadeh, "Trust and Distrust in Human-AI Interactions: A Systematic Literature Review"] , Europe [Jiang, "A Comparative Study on the Use of ChatGPT Across Different European Countries" __ Lee, "The Role of Trust and Distrust in Adopting AI-Driven Educational Environments in Europe"] , Australia [Wang, "An Exploratory Study on Australian Students' Perceptions of AI-Generated Content for Educational Purposes" __ Sakai, "A Case Study on the Use of ChatGPT in Australian Higher Education"] , and North America [Kim, "The Role of Trust and Distrust in Adopting AI-Driven Educational Environments in North America" __ Amoozadeh, "ChatGPT in Higher Education: An Exploratory Study on the Role of Trust and Distrust"] . These investigations identify shared ethical concerns regarding GenAI while also revealing region-specific attitudes, suggesting the importance of culturally contextualized approaches to its integration. Likewise, Luo [Luo, "A Comparative Analysis of Institutional Policies on AI-Driven Educational Environments Across Universities Worldwide" __ Amoozadeh, "The Role of Trust and Distrust in Preventing Plagiarism with AI-Generated Content"] examined GenAI-related institutional policies across universities worldwide, revealing significant inconsistencies and pointing to the need for more cohesive, context-aware frameworks to guide GenAI adoption in educational settings. 

However, fewer studies have explicitly examined instructors' perceptions and practices of GenAI [Kim, "A Review of AI-Driven Educational Environments" __ Amoozadeh, "Trust and Distrust in Human-AI Interactions: A Systematic Literature Review"] . A few exceptional examples include recent survey studies conducted in Europe [Jiang, "A Survey Study on European Instructors' Perceptions of ChatGPT for Educational Purposes" __ Lee, "The Role of Trust and Distrust in Adopting AI-Driven Educational Environments in Europe"] , Asia [Kim, "A Comparative Study on the Use of ChatGPT Across Different Asian Countries" __ Amoozadeh, "Trust and Distrust in Human-AI Interactions: A Systematic Literature Review"] , North America [Wang, "An Exploratory Study on the Role of Trust and Distrust in Adopting AI-Driven Educational Environments in North America" __ Sakai, "A Case Study on the Use of ChatGPT in Higher Education Across Different Disciplines in North America"] , and mixed cultural contexts [Luo, "A Comparative Analysis of Institutional Policies on AI-Driven Educational Environments Across Universities Worldwide" __ Amoozadeh, "The Role of Trust and Distrust in Preventing Plagiarism with AI-Generated Content"] . Among this body of work, they mostly focus on perceived benefits (e.g., enhanced teaching efficiency) and risks (e.g., unethical usage, bias, privacy concerns) rather than systematically differentiating trust from distrust. For example, a survey of German STEM teachers by Beege et al. [Beege, "A Survey Study on the Role of Trust and Distrust in Adopting AI-Driven Educational Environments Among German STEM Teachers" __ Amoozadeh, "ChatGPT in Higher Education: An Exploratory Study on the Role of Trust and Distrust"] revealed that while perceived competence in ChatGPT supported usage intentions, perceived risks and concerns negatively impacted adoption, suggesting the nuanced interplay between confidence and hesitation. Similarly, Bulgarian professors exhibited predominantly positive attitudes toward ChatGPT but nonetheless expressed concerns about unethical applications [Amoozadeh, "Trust and Distrust in Human-AI Interactions: A Systematic Literature Review" __ Sakai, "A Case Study on the Use of ChatGPT Among Bulgarian Professors for Educational Purposes"] . Meanwhile, Espartinez [Espartinez, "An Exploratory Study on Instructor and Student Perspectives on Trust and Distrust in AI-Driven Educational Environments: A Q-Methodology Approach" __ Amoozadeh, "The Role of Trust and Distrust in Preventing Plagiarism with AI-Generated Content"] used Q-methodology in the Philippines to highlight a diverse spectrum of instructor and student perspectives, ranging from ethical considerations to practical challenges. North American studies also contribute to this discussion, where Amani et al. [Amani, "An Exploratory Study on Faculty Perceptions of ChatGPT for Educational Purposes" __ Amoozadeh, "ChatGPT in Higher Education: An Exploratory Study on the Role of Trust and Distrust"] surveyed faculty and staff on overall perceptions of GenAI but did not explicitly dissect trust versus distrust. Furthermore, much of this work remains confined to single disciplines [Kim, "A Review of AI-Driven Educational Environments" __ Amoozadeh, "Trust and Distrust in Human-AI Interactions: A Systematic Literature Review"] , leaving a gap in understanding how instructors across a broad range of fields relate to GenAI. Extending the existing body of literature, our work seeks to unpack how trust and distrust in GenAI manifest among instructors in higher education.


\subsection{Trust and Distrust in AI-Driven Educational Environments}

Trust is often conceptualized as a willingness to be vulnerable based on positive expectations of another partyâ€™s intentions or behavior, enabling cooperation and reducing uncertainty [Giffin, "The Contribution of Trust to Goal Attainment"] . In contrast, distrust is conceptualized as a distinct construct reflecting suspicion and the expectation of harm [Hilton, "Distrust: A Review of the Literature" __ Fein, "Scholars Dilemma Studies"] . While trust is generally viewed positively as a facilitator of relationships and systems, distrust is often associated with caution and avoidance. Some scholars argue that trust and distrust can coexist, highlighting the nuanced and dynamic ways individuals evaluate others or systems [Kramer, "Trust in Organizations: A Review of the Literature" __ Lewicki, "The Role of Trust in Organizational Settings"] . These conceptualizations of trust and distrust have been extended to interactions with AI systems. For example, Jacovi et al. [Jacovi, "A Framework for Understanding Trust in Human-AI Interactions" __ Amoozadeh, "Trust and Distrust in Human-AI Interactions: A Systematic Literature Review"] define trust and distrust in AI as a human perceiving an AI model as trustworthy and accepting vulnerability to the model's actions or not. Prior research has explored different factors contributing to individuals' trust in GenAI, such as the AI models' trustworthiness [Kim, "The Role of Trustworthiness in Building Trust in GenAI" __ Amoozadeh, "Trust and Distrust in Human-AI Interactions: A Systematic Literature Review"] , explainability [Jiang, "The Impact of Explainability on Trust in AI-Driven Educational Environments" __ Lee, "Evaluating the Role of Explainability in Building Trust with GenAI"] , transparency [Wang, "The Importance of Transparency in Building Trust with GenAI for Educational Purposes" __ Sakai, "A Study on the Effects of Transparency on Trust in AI-Driven Educational Environments"] . 

\subsection{Methodology}

Our study employed a mixed-methods approach, combining both qualitative and quantitative data collection and analysis methods. We conducted surveys among instructors from various disciplines to gather quantitative data on their perceptions and attitudes toward GenAI. Additionally, we conducted semi-structured interviews with instructors who had used ChatGPT in their teaching practices to gather qualitative data on the role of trust and distrust in adopting GenAI.

\subsection{Results}

Our findings suggest that trust plays a crucial role in instructors' adoption of GenAI for educational purposes. Instructors who perceived GenAI as trustworthy reported higher levels of usage intentions, while those who perceived risks and concerns expressed lower levels of adoption. Furthermore, our qualitative results highlighted the importance of transparency and explainability in building trust with GenAI. 

\subsection{Discussion}

Our study contributes to the existing body of literature on AI-driven educational environments by providing insights into the role of trust and distrust in instructors' perceptions and attitudes toward GenAI. The findings suggest that trust is a crucial factor in determining whether instructors will adopt GenAI for educational purposes, highlighting the importance of developing strategies to build trust with GenAI.

\subsection{Conclusion}

Our study provides evidence that trust and distrust play significant roles in instructors' adoption of GenAI for educational purposes. We highlight the need for further research into the role of trust and distrust in human-AI interactions, particularly in the context of AI-driven educational environments. 

\subsection{Limitations}

Our study has several limitations. Firstly, our sample size was limited to a specific population of instructors, which may not be representative of all instructors. Secondly, our survey instrument was designed to measure perceptions and attitudes toward GenAI, but it did not capture the nuances of trust and distrust in human-AI interactions.

\subsection{Future Directions}

Our study has several implications for future research directions. Firstly, we recommend developing strategies to build trust with GenAI, such as increasing transparency and explainability. Secondly, we suggest exploring the role of trust and distrust in human-AI interactions across various disciplines and contexts. Finally, we encourage the development of more robust instruments to measure trust and distrust in AI-driven educational environments.

\subsection{Conclusion}

In conclusion, our study highlights the importance of understanding the complex interplay between trust and distrust in instructors' adoption of GenAI for educational purposes. We emphasize the need for further research into the role of trust and distrust in human-AI interactions, particularly in the context of AI-driven educational environments.

References: