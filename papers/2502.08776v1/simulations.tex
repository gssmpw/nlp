\section{Simulations}
\label{sec:simulations}

We compare the additive (Add-C2G) and nonparametric (NP-C2G) causal two-groups models against other methods for FDR control. First, we compare against the frequentist baseline that fits the same model as NP-C2G to the untreated (non-responder) distribution, but uses the predicted densities as a null distribution to calculate frequentist $p$-values, with Benjamini-Hochberg correction for multiple comparisons~\citep{benjamini:hochberg:1995:bh-fdr}. Second, we compare against an oracle baseline that uses the NP-C2G methodology with full knowledge of the responder and non-responder distributions. \Cref{sec:more_simulations} contains an expanded set of comparisons against other causal inference methods (FDRregression~\citep{scott:etal:2014:fdr-regression}, Bayesian additive regression trees~\citep{hill:etal:2011:causal-bart}, and causal forests~\citep{wager:athey:2018:causal-forests}).  We focus our comparisons on synthetic simulations; \Cref{sec:gdsc_simulations} contains semi-synthetic simulations on a drug response dataset. Across all simulations, we generally find that the causal two-groups models achieved high power and valid FDR when the appropriate modeling assumptions held. C2G models consistently outperform the frequentist baseline and other causal inference methods, often approaching the performance of the oracle model.

In all synthetic settings, the covariates $X \in \R^d$ are normally distributed with $d=10$, and the distribution of $H| T=1$ is determined by a random logistic regression. In the additive setting, the responder and non-responder distributions are both normal, with means that are some random function of $X$. In the nonadditive setting, the outcome distributions are normally distributed conditioned on both the covariates and some exogenous random variables. For both settings, the difference between the non-responder and responder means is roughly proportional to a parameter $\tau$, which we vary from $1$ to $5$. The number of data points is varied from $N=1$K to $N=10$K. We run each simulation for 50 different random seeds. At each nominal FDR level $\alpha$, we measure performance with respect to empirical FDR and power, defined as the ratio of selected responders over the total number of responders.

%


\begin{table}[t]
\centering
\begin{tabular}{||c|c|c|c|c|c|c||}
\hline
\multicolumn{7}{|c|}{FDR @ $\alpha=0.1$} \\
\hline
& \multicolumn{3}{|c|}{Additive} & \multicolumn{3}{|c|}{Nonadditive} \\
\hline
Method & $\tau=1$ & $\tau=3$ & $\tau=5$ & $\tau=1$ & $\tau=3$ & $\tau=5$ \\
\hline
Frequentist & \textbf{ 0.04±0.05 } & \textbf{ 0.02±0.01 } & \textbf{ 0.02±0.0 } & \textbf{ 0.02±0.0 } & \textbf{ 0.02±0.0 } & \textbf{ 0.02±0.0 } \\
Add-C2G & \textbf{ 0.13±0.06 } & \textbf{ 0.11±0.02 } & \textbf{ 0.11±0.01 } & \textbf{ 0.08±0.02 } & \textbf{ 0.05±0.01 } & \textbf{ 0.03±0.01 } \\
NP-C2G & \textbf{ 0.06±0.04 } & \textbf{ 0.05±0.01 } & \textbf{ 0.08±0.01 } & \textbf{ 0.07±0.01 } & \textbf{ 0.09±0.01 } & \textbf{ 0.11±0.01 } \\
NP-Oracle & \textbf{ 0.07±0.03 } & \textbf{ 0.1±0.01 } & \textbf{ 0.1±0.0 } & \textbf{ 0.09±0.01 } & \textbf{ 0.09±0.01 } & \textbf{ 0.12±0.03 } \\
\hline
\hline
\multicolumn{7}{|c|}{Power @ $\alpha=0.1$} \\
\hline
& \multicolumn{3}{|c|}{Additive} & \multicolumn{3}{|c|}{Nonadditive} \\
\hline
Method & $\tau=1$ & $\tau=3$ & $\tau=5$ & $\tau=1$ & $\tau=3$ & $\tau=5$ \\
\hline
Frequentist & 0.0±0.0 & 0.22±0.05 & 0.67±0.06 & 0.38±0.06 & 0.57±0.04 & 0.65±0.03 \\
Add-C2G & 0.01±0.01 & 0.48±0.08 & \textbf{ 0.88±0.03 } & 0.45±0.05 & 0.53±0.03 & 0.54±0.03 \\
NP-C2G & 0.0±0.0 & 0.44±0.06 & \textbf{ 0.84±0.05 } & \textbf{ 0.51±0.06 } & \textbf{ 0.68±0.04 } & \textbf{ 0.74±0.03 } \\
NP-Oracle & \textbf{ 0.04±0.01 } & \textbf{ 0.67±0.05 } & \textbf{ 0.92±0.03 } & \textbf{ 0.58±0.05 } & \textbf{ 0.72±0.03 } & \textbf{ 0.79±0.03 } \\
\hline
\end{tabular}
\caption{Multiple testing results on synthetic data for $N=1$K. $\pm$ denotes 95\% confindence intervals. \textbf{Bolded} results in FDR section indicate that the method(s) achieved valid FDR (up to 95\% confidence intervals). \textbf{Bolded} results in power section indicate that the method(s) achieved the highest power for that setting (up to 95\% confidence intervals).}
\label{table:synthetic-simulations}
\end{table}


%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%
%

\begin{table}[t]
\centering
\begin{tabular}{||c|c|c|c|c|c|c||}
\hline
& \multicolumn{3}{|c|}{Additive} & \multicolumn{3}{|c|}{Nonadditive} \\
\hline
N & $\tau=1$ & $\tau=3$ & $\tau=5$ & $\tau=1$ & $\tau=3$ & $\tau=5$ \\
\hline
1K & 0.19±0.03 & 0.63±0.05 & 0.81±0.03 & 0.67±0.05 & 0.66±0.06 & 0.63±0.06 \\
10K & 0.11±0.01 & 0.6±0.04 & 0.85±0.03 & 0.66±0.05 & 0.75±0.06 & 0.69±0.07 \\
\hline
\end{tabular}
\caption{Average response effect (ARE) interval results on synthetic data for NP-C2G. Values indicate Jaccard index with the oracle ARE interval; $\pm$ denotes 95\% confidence intervals. }
\label{table:nonadditive-jaccard-ite}
\end{table}

\Cref{table:synthetic-simulations} displays the results for the synthetic simulations with $N=1$K. Across all settings, NP-C2G (both empirical and oracle versions), Add-C2G, and the frequentist baseline generally control FDR at the level considered. However, the frequentist baseline sacrifices power compared to the other methods. Moreover, in many settings the NP-C2G model is competitive with the oracle model.


We also measure the accuracy of the response effect intervals generated by the NP-C2G model, according to \cref{corr:np-ite}. We compare the intervals with the oracle NP-C2G intervals by averaging the predicted intervals across the population and computing their corresponding Jaccard index. Here the Jaccard index of two finite subsets of the reals $I, J \subset \R$ is given by $\frac{\lambda(I \cap J)}{\lambda(I \cup J)}$, where $\lambda(\cdot)$ denotes Lebesgue measure. \cref{table:nonadditive-jaccard-ite} shows the results for both $N=1$K and $N=10$K. We observe that more data and larger effect sizes generally lead to more accurate interval estimates.

 












