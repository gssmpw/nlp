\section{Causal two-groups with nonparametric models}
\label{sec:kernel_generalized}
The additivity assumption in \cref{eqn:additive_errors} is often violated in practice. For instance, \citet{efron:feldman:1991:compliance} observed that higher rates of compliance were associated with increased variability in outcomes for both the treatment and control groups. Further, the increase in variance differed between treatment and control groups, suggesting that the error models for the two distributions $f_0$ and $f_1$ were different in the study.

Here, we propose a generalized empirical Bayes procedure for estimation in the causal two-groups model. The goal is to be maximally flexible to the true data generating model. As such, we remove the assumption of additive errors and instead directly model the outcome distributions in \cref{eqn:two_groups}. The starting point for this approach is the following result.
\begin{lemma}
\label{lem:conservative-pi}
Suppose the generative model from \cref{eqn:two_groups} induces treated distribution $f_t(y \mid x)$ and untreated distribution $f_0(y \mid x)$. Then for any $x$, we have
\[ \pi(x) \geq \pi^\star(x) := 1 - \min_y \frac{f_t(y \mid x)}{f_0(y \mid x)}. \]
Moreover, for any function $\pi$ satisfying $\pi(x) \in [\pi^\star(x), 1]$ for all $x$, there is an alternative distribution $f^\pi_1$ such that
\begin{align*}
f_t(y \mid x) &= (1-\pi(x)) f_0(y \mid x) + \pi(x) f^\pi_1(y \mid x).
\end{align*}
\end{lemma}
The implication of \cref{lem:conservative-pi} is that given the observed null and treatment distributions, one can compute the most conservative mixing function, $\pi^\star$, by minimizing their ratio. This leads to a valid test for an observation $(x,y)$ that controls the Type I error rate:
\begin{equation}
\label{eqn:general-bayes-test}
    \hat{h}_{\text{Bayes}} = \ind\left[ \frac{(1 -\pi^\star(x)) f_0(y \mid x) }{\pr(y \mid x, t=1)} \leq \alpha  \right] .
\end{equation}
Thus, empirical Bayesian testing in the fully general causal two-groups model can be reduced to finding suitable estimates of $f_0$ and $f_t$.

\subsection{Estimating the non-response and treatment distributions}
\label{subsec:kernel_generalized:estimation}
We take a nonparametric approach to approximating $f_0$ and $f_t$, using a $k$ nearest-neighbor version of the Rosenblatt kernel conditional density estimator~\citep{holmes:etal:2007:kernel-density-estimation,rosenblatt:1969:kernel-density-estimation}. That is, we approximate $f_t$ as
\[ \hat{f_t}(y \mid x ) = \frac{\sum_{i=1}^k K_{h_1}(x \mid x_{j_{x,1,i}})K_{h_2}(y \mid y_{j_{x,1,i}})}{\sum_{i=1}^k K_{h_1}(x \mid x_{j_{x,1,i}})}, \]
where $K_h$ is a probability kernel with bandwidth parameter $h>0$ and $j_{x,t,i}$ is the index of the $i$-th nearest neighbor of $x$ with treatment value $t$ in the dataset. $\hat{f_0}$ is constructed identically, substituting $j_{x,0,i}$ for $j_{x,1,i}$. The bandwidth parameters $h_1, h_2$ and number of neighbors $k$ are selected via leave-one-out cross validation.


\subsection{Selecting responders}
\label{subsec:kernel_generalized:estimation}
The test in \cref{eqn:general-bayes-test} relies on ratios of densities, making it sensitive to errors in our estimates. To address this issue, we use bootstrap sampling to create a population of conditional densities and estimate the ratios by using upper/lower quantiles to produce conservative ratio estimates. The final null posterior probability estimate for observation $x_i, y_i$ is given by
\begin{align}
\hat{w}_i = \frac{\hat{f}_{0,1-q}(y_i \mid x_i) }{\hat{f}_{t,q}(y_i \mid x_i)} \cdot \min_{y} \frac{\hat{f}_{t,1-q}(y \mid x_i)}{\hat{f}_{0,q}(y \mid x_i)},
\label{eqn:generalized_w_estimate}
\end{align}
where $\hat{f}_{t,q}(y\mid x)$ is the $q$-th quantile (under the bootstrap distribution) of the conditional treatment density of $y$ given $x$. Similarly, $\hat{f}_{0,q}(y\mid x)$ is the $q$-th quantile of the conditional untreated distribution. As in the additive case, we can sort the $\hat{w}$ values and select the largest subset such that their average value is below $\alpha$. The following result shows that when the conditional distributions are estimated accurately enough, the procedure results in proper FDR control.

\begin{theorem}
\label{thm:general-fdr}
Let $\epsilon, L, U > 0$ be given. Suppose the following holds for all $i=1,\ldots, n$ and $y \in \R$:
\begin{itemize}
    \item[(i)] $L \leq f_t(y \mid x_i), f_0(y \mid x_i) \leq U$,
    \item [(ii)] $|f_t(y \mid x_i) - \hat{f}_t(y \mid x_i)| \leq \epsilon$, and
    \item[(iii)] $|f_0(y \mid x_i) - \hat{f}_0(y \mid x_i)| \leq \epsilon$.
\end{itemize}
If $\epsilon \leq \min(1, L/2)$, then the procedure outlined above results in FDR bounded by $\alpha + \delta$, where $\delta = \frac{8U}{L^2} \left( 1 + \frac{12U}{L^2}\right)\epsilon$. 
Moreover, the power of the procedure is bounded below by 
\[ \frac{1-\alpha - \delta}{1-\alpha + \delta + 1/(n_{\opt}(\alpha - \delta) +1)} \opt(\alpha - \delta), \]
where $\opt(\beta)$ is the power of the Bayes' optimal procedure under the conservative prior of \Cref{lem:conservative-pi} that achieves FDR bounded above by $\beta$, and $n_{\opt}(\beta)$ is the corresponding number of selections.
\end{theorem}


We further control FDR with an empirical estimate of the FDR, calculated by performing the above selection procedure on both the treated and untreated populations over a grid of nominal FDR values $\alpha_1 < \alpha_2 < \cdots < \alpha_m$, and taking $e_k$ to be the ratio of the number of untreated selected at level $\alpha_k$ over the number of treated selected at level $\alpha_k$. Selection at level $\alpha$ proceeds by finding the largest $\alpha_k \leq \alpha$ such that $e_k \leq \alpha_k$ and selecting at level $\alpha_k$. We call this procedure \emph{empirical control}.

\subsection{Estimand intervals}
\label{subsec:kernel_generalized:estimands}
Beyond providing a test with valid FDR, \cref{lem:conservative-pi} also provides insights on the range of possible effects that can be ascribed to a possible response distribution. Specifically, because the model is not identifiable, one can not estimate a single latent response effect. Rather, \cref{lem:conservative-pi} implies that there is an \emph{interval} of feasible effects as summed up by the following corollary.

\begin{corollary}
\label{corr:np-ite}
Let $f_0(y \mid x)$, $f_t(y \mid x)$, and $\pi^\star(x)$ be as defined in \cref{lem:conservative-pi}. If $f_1$ is a valid responder distribution in \cref{eqn:two_groups}, we must have 
\[ \E_{f_1}[Y|X=x] \in \left[\mu_t(x),  \mu_1^\star(x) \right] \cup \left[\mu_1^\star(x), \mu_t(x) \right], \]
where 
\begin{align*}
\mu_t(x) = \E[Y | X=x, T=1], 
\mu_0(x) = \E[Y | X=x, T=0], \text{ and }
\mu_1^\star(x) = \frac{1}{\pi^\star(x)}(\mu_t(x) - \mu_0(x))  - \mu_0(x).
\end{align*}
Moreover, for any $v \in \left[\mu_t(x),  \mu_1^\star(x)\right] \cup \left[\mu_1^\star(x), \mu_t(x) \right]$, there is a valid responder distribution $f_1$ such that $\E_{f_1}[Y|X=x] = v$.
\end{corollary}
In the above statement, we have used the convention that $[a,b]$ is empty whenever $b<a$. Thus, for any individual $x$, the CARE lies in an interval that is bounded on one side by the CATE value $\mu_t(x) - \mu_0(x)$ and on the other side by the extremal CARE value of $\mu_1^\star(x) - \mu_0(x)$.

\begin{figure*}
\centering
\includegraphics[width=.95\textwidth]{plots/gradient.pdf}
\caption{Nonparametric C2G example. \emph{Left:} An example of a non-responder density (black), a treatment density (red), an extremal responder density (blue), and the range of feasible responder densities (gradient). \emph{Right:} Each feasible responder density has an associated prior probability and CARE value.}
\label{fig:npc2g-example}
\end{figure*}

\cref{fig:npc2g-example} shows an example of the nonparametric C2G setup: the control density, the treatment density, and the range of feasible responder densities. We see that at one end of the scale, the treatment density itself is a feasible alternative, with an associated prior probability $\pi(x) = 1$ and induced CARE equal to the CATE. On the other end of the scale, there is an extremal responder density with a smaller associated prior probability ($\pi(x) = \pi^\star(x)$) and larger CARE value. The relationship between these quantities is that as the prior probability grows towards one, the CARE shrinks towards the CATE, reflecting the fact that the associated responder distribution must also shrink towards the treatment distribution itself.



