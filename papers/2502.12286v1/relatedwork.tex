\section{Related work}
\label{sec:relatedwork}

%\begin{itemize}   \item Work of Wooldrige on Rational Verification  [Munyque / Emiliano], + Lexicographical preferences
%    \item Check Naumov's papers, e.g., "A logic of higher-order preferences" and more [Yinfeng]
%\item Discuss papers on SL and ATL using quantitative semantics [Munyque]
%\item Discuss  Horty's STIT deontic logic of obligations based on dominance [Emiliano]
%\item Lorini et Liu's papers on logics of preferences.  and recent Grossi and van der Hoek's paper on the general logic for preferences 
%Thomas Ågotnes: "On the logic of preference and judgment aggregation", and "Reasoning about reasons behind preferences using modal logic"\end{itemize}

Several works have studied logics  for reasoning about preferences, without considering the strategic and temporal dimensions. In particular, \citeauthor{BenthemL07} \cite{BenthemL07} proposed a dynamic logic of knowledge update and preference upgrade, where incoming suggestions or commands change the preference relations. \citeauthor{Lorini21} \cite{Lorini21} presented a general logical framework for reasoning about agents’ cognitive
attitudes, which captures concepts of knowledge, belief, desire, and preference.  
%Logic of preference  
\citeauthor{GrossiHK22} \cite{GrossiHK22} investigated four different semantics for conditional logics based on preference relations over alternatives. The semantics differ in the way of selecting the most preferred alternative, which includes maximality, optimality, unmatchedness, and acceptability. \ifarxiv Maximality is related to the rationality concept we consider in this paper. Maximal alternatives are those not strictly dispreferred to any other. \fi 

Two of the most important developments in logics for strategic reasoning are ATL \cite{alur2002alternating} and SL \cite{MogaveroMPV14}.
Unlike ATL, SL can express complex solution concepts (such as dominant strategy equilibrium) and thus capture some notions of rationality.  
However, in both logics, agents' preferences are not modeled intrinsically, instead, their goals can be represented as Boolean formulas. 
A way to incorporate preferences in those logics is to include atomic propositions stating that the utility of an agent is greater than or equal to a given value \cite{baltag2002logic}, which requires an exhaustive enumeration for each relevant utility threshold.  
The extensions of ATL and SL with quantitative semantics \cite{jamroga2024playing,bouyer2023reasoning} generalize fuzzy temporal logics and capture quantitative goals.  This approach has been recently used to represent agents' utilities in  mechanism design ~\cite{SLKF_KR21,MittelmannMMP22}. 

The dominance relation among strategies has been considered alongside specifications in temporal logics  \cite{AminofGR21,AminofGLMR21}. These works provide algorithms for synthesizing best-effort strategies, which are maximal in the dominance order, in the sense that they achieve the agent goal against a maximal set of environment specifications.

Rationality in concurrent games is typically associated with  a\-gents' knowledge and preferences. Know-How Logic with the Intelligence \cite{naumov2021intelligence} captures rational agents' capabilities that depend on the intelligence information about the opponents’ actions. The interplay between agents' preferences and their knowledge was described in \cite{Naumov2023AnEL}. 
A sound, complete, and decidable logical system expressing higher-order preferences to the other agents was given in  \cite{Jiang2024-JIAALO}. However, none of these three papers address the connection between rational agents' capabilities and their preferences.

Our work is also related to the research on rational verification and synthesis. The first is the problem of checking whether a temporal goal is satisfied in some or all game-theoretic equilibria of a CGS \cite{AbateGHHKNPSW21,GutierrezNPW23}. Rational synthesis consists in the automated construction of such a model \cite{FismanKL10, CFGR16}. 
Different types of agent objectives have been considered, including Boolean temporal specifications \cite{gutierrez2019equilibrium}, mean payoff \cite{gutierrez2024characterising}, and lexicographical preferences \cite{gutierrez2017nash}


While being able to analyze multi-agent systems with respect to solution concepts, both rational verification and model-checking SL specifications face high complexity issues. 
In particular, key decision problems for rational verification with temporal specifications are known to be \DExptime-complete \cite{GutierrezNPW23} and model-checking  SL is non-elementary for memoryful agents \cite{MogaveroMPV14}. 

 

ATL with plausibility \cite{BullingJD08} allows the specification of sets of
rational strategy profiles, and reason about agents' play if the agents can only play  these strategy profiles. The approach considers plausibility terms, which are mapped to a set of strategy profiles.  
The logic includes formulas of the form $(\text{set-pl} \omega) \varphi$, meaning  that ``assuming that the set of rational strategy profiles is defined in terms of the plausibility terms $\omega$, then, it is
plausible to expect that $\varphi$ holds''. %This is similar to rational verification, as it assumes that players play rationally with respect to some solution concept, and analyze the game outcome 
% under this assumption. 
This idea was extended in  \cite{BullingJ09} to a variant of SL for imperfect information games.
However, as emphasized in the introduction, 
Bulling et al. do not 
represent 
agents' 
preferences in their  semantics. 
This is a crucial
difference between their work and ours.
Our main focus is
on  extending CGSs
with preferences,
studying the dynamic properties
of agents' preferences in concurrent games,
and defining a logic
of rational capability with the help
of the semantics
combining CGSs with preferences.