

\section{The existence of uniform bounds for all Ga\-ler\-kin
  projections for short time steps}
\label{sec:gendiss}




\subsection{A time step - $C^0$}
\label{subsec:C0-timestep}

The goal of this section is to twofold: \newline
1) in the context of Theorem~\ref{thm:limitLN} to show that it is relatively straightforward to construct set satisfying  (\ref{eq:appriori-bnds}), i.e. apriori bounds for a time step for all Galerkin projections,  and all our conditions C1,C2,C3,C4,D \newline
2) outline the basic principle of algorithm for rigorous integration equation (\ref{eq:feqLN}).


	
	
\begin{theorem}  \cite[Thm. 3.7]{ZKS3}
\label{thm:selfexists} Consider (\ref{eq:fugenpde}). Assume that
conditions (\ref{eq:lambdak}), (\ref{eq:lambdak2}) and
(\ref{eq:p>r}) hold. Let $s_0=p+d+1$


Let  $Z \oplus T_0$ form self-consistent bounds for
(\ref{eq:fugenpde}), such that for some $C_0$ and $s \geq s_0$
holds
\begin{equation*}
  |T_{0,k}| \leq \frac{C_0}{|k|^{s}}, \qquad |k| >m,\: k \in I, \:
  s> s_0
\end{equation*}

Then there exist $h >0$, $W \oplus T_1$ - self-consistent bounds
for (\ref{eq:fugenpde}) and $L >0$, such that for all $l >L$ and
$u \in  P_l(Z \oplus T_0)$
\begin{equation*}
  \varphi^l([0,h],u) \subset W \oplus T_1.
\end{equation*}
and
\begin{equation*}
  |T_{1,k}| \leq \frac{C_1}{|k|^{s}}, \qquad |k|>m, k \in I.
\end{equation*}
\end{theorem}
\textbf{Proof:} Let $W \subset X_m$, be  a compact set, such that
$Z \subset \inte_{X_m} W$.

By eventually increasing $C_0$ we can assume that
\begin{equation*}
  |u_k| \leq \frac{C_0}{|k|^{s}}, \qquad \mbox{for all  $u \in W \oplus T_0$ and $k \in
  I$}.
\end{equation*}

We set $C_1=2C_0$ and define the tail $T_1$  by
\begin{equation*}
   T_1=\Pi_{|k|>m, k \in I} \overline{B}\left(0,\frac{C_1}{|k|^s}\right).
\end{equation*}

\textbf{PZ:  tu powinnismy uzyc lemat o izolacji Lemma~\ref{lem:iso-mainVar}  zamiast tego co ponizej - poczatek}


From Lemma~\ref{lem:Dgen} it follows that there exists
$D=D(C_1,s)$, such that
\begin{equation*}
  |N_k(u)| < \frac{D}{|k|^{s - r}}, \quad \mbox{for all $u$, such that $|u_k| \leq \frac{C_1}{|k|^s}$}
\end{equation*}

Let $u \in W \oplus T_1$ and $|u_{k_0}|=\frac{C_1}{|k_0|^{s}}$ for
some $|k_0| > K_-$.
\begin{eqnarray}
  \frac{1}{2}\frac{d}{dt}(u_{k_0}|u_{k_0}) < -\alpha_0 |k_0|^p |u_{k_0}|^2 + |u_{k_0}| |N_{k_0}(u)| \leq  \nonumber\\
   \left(- \alpha_0 C_1 |k_0|^{p-s} + D |k_0|^{r -s}\right) |u_{k_0}|, \nonumber \\
  \frac{d|u_{k_0}|^2}{dt}< 0, \qquad |k_0|> L,  \label{eq:farentry}
\end{eqnarray}
for $L$ sufficiently large.
\textbf{dotad}

Consider now the differential inclusion
\begin{equation}
  x' \in P_LF(x) + \Delta, \qquad x \in X_L, \Delta \subset X_L  \label{eq:galediffincl}
\end{equation}
where the set $\Delta$ represents the Galerkin projection errors
on $W \oplus T_1$ and is given by
\begin{equation*}
  \Delta=\{ P_LF(u) - P_L F(P_Lu) \: | \: u \in W \oplus T_1  \}.
\end{equation*}
As it was mentioned in the introduction, by a solution of
differential inclusion (\ref{eq:galediffincl}) we will understand
any $C^1$ function $x:[0,t_m] \to X_L$ satisfying condition
(\ref{eq:galediffincl}).



It is easy to see that there exists $h >0$, such that if
$x:[0,t_m]\to X_L$, where $t_m \leq h$, is a  solution of
(\ref{eq:galediffincl}) and $x(0) \in P_L(Z \oplus T(0)))$, then
\begin{equation}
x(t)  \in \inte_{X_L} P_L (W \oplus T_1), \qquad t \in [0,h].
\label{eq:dinclencl}
\end{equation}
Namely, it is enough to take $h>0$ satisfying the following
condition
\begin{equation*}
   h \cdot \left(\max_{u \in W \oplus T_1 \in } |P_LF(u)| + \max_{\delta \in \Delta}
   |\delta|\right) < \dist(P_L(Z \oplus T_0),\partial_{X_L} P_L(W\oplus
   T_1)).
\end{equation*}

Let $l > L$ and let $u:[0,t_1) \to X_l$ be a solution of
\begin{equation*}
  u'=P_lF(u), \qquad u(0) = u_0 \in P_l(X \oplus T_0).
\end{equation*}
By changing the vector field in the complement of  $P_l (W \oplus
T_1)$ we can assume that $t_1=\infty$.

Let
\begin{equation*}
  t_m=\sup\{ t >0 \: | \: u([0,t]) \subset P_l (W \oplus
T_1)\}.
\end{equation*}
Obviously $t_m >0$. It is enough to prove that $t_m \geq h$.
Observe that for $t \in [0,t_m]$ $P_Lu(t)$ is a solution of
(\ref{eq:galediffincl}), hence from (\ref{eq:dinclencl}) we obtain
\begin{equation*}
  P_L u([0,t_m])  \subset \inte_{X_L} P_L (W \oplus T_1).
\end{equation*}
From (\ref{eq:farentry}) it follows immediately that
\begin{equation*}
  Q_L u([0,t_m]) \subset \inte_{Y_l} P_lQ_L(W \oplus T_1).
\end{equation*}
Hence
\begin{equation*}
   u(t_m) \in \inte_{X_l} P_l(W \oplus T_1).
\end{equation*}
From above condition and the continuity of $u$ it follows that for
some $\delta >0$ holds
\begin{equation*}
   u(t_m+t') \in \inte_{X_l} P_l(W \oplus T_1), \qquad t'\in [0,\delta]
\end{equation*}
hence $t_m=h$.
 \qed


\subsection{A time step for variational equation}

As in the previous section we have two goals
\begin{itemize}
\item in the context of Theorem~\ref{thm:c1conver} , we construct sets $W_{C_j}$ satisfying condition (\ref{eq:var-a-priori-bnds}) and
containing $e_j$, i.e. we construct a priori bounds for all columns with the same time step
\item to propose the method of bounding all columns of $V(t,x)$ using a finite representation. This is followed by outlining basic principle of the algorithm for integration
  of system (\ref{eq:sysVar1},\ref{eq:sysVar2}).
\end{itemize}

\subsubsection{A priori bound for all columns}

In the context of Theorem~\ref{thm:c1conver}  we assume that we have set $Z\subset W$ satisfying its assumptions. Additionally we assume that $W \subset W_P(C,s)$.
We want to find  a family of sets $\{W_{C_j}\}_{j \in \mathbb{Z}_+}$ contained in $H$, such that for each $j \in \mathbb{Z}_+$ condition \VL is satisfied on $W \times W_{C_j}$ and
for any $n >j$ the solution of the variational problem (\ref{eq:sysVar1}--\ref{eq:sysVar2}) with initial conditions $x^n(0) \in Z$ and $C^n(0)=e_j$ satisfies
\begin{equation}
  C^n(t) \in W_{C_j}, \quad t \in [0,T]. \label{eq:step-var-a-priori-bnds}
\end{equation}
Let $l$ be a constant from condition \textbf{D} for $W$.

From Lemma~\ref{lem:estmLogN} \textbf{PZ: moze inny lemat?} it follows that for all $j$ and any $n>j$ solution of the variational problem (\ref{eq:sysVar1}--\ref{eq:sysVar2}) with initial conditions $x^n(0) \in Z$ and $C^n(0)=e_j$ satisfies
\begin{equation}
  \|C^n(t)\| \leq e^{lt}, \quad t \in [0,T]. \label{eq:ln-estm-var}
\end{equation}

Let $L=L(C,s,d)$ from the isolation property in Lemma~\ref{lem:iso-VarVar}.


Let $C_{V,j}$ be such that
\begin{equation}
  C_{V,j} > |j|^s  \label{eq:CVj}
\end{equation}
and the following condition hold 
\begin{equation}
\mbox{if} \quad  y \in H \, \exists k \,  |k|\leq L \quad |y_k|=\frac{C_{V,j}}{|k|^s}, \quad \mbox{then} \, \|y\| > \max(1,e^{lT}).  \label{eq:iso-cond-v}
\end{equation}
Existence of such $C_{V,j}$ is an easy consequence of \NC5.



\begin{lemma}
\label{lem:WCj-exist}
  $W_{C_j}=\overline{B}(0,\max(1,e^{lT})) \cap W_P(C_{V,j},s)$ satisfies (\ref{eq:step-var-a-priori-bnds}) and $e_j \in W_{C_j}$.
\end{lemma}
\textbf{Proof:}
Observe that (\ref{eq:CVj}) implies that $e_j \in W_{C_j}$.

To prove (\ref{eq:step-var-a-priori-bnds}) observe that $C^n(t) \in \overline{B}(0,\max(1,e^{lT})) $ for $t \in [0,T]$. Therefore for $C^n(t)$ to exit from
$W_{C_j}$ we need that for some $t \in [0,T]$ holds $|y_k(t)|=\frac{C_{V,j}}{|k|^s}$ for some $|k| \leq n$.  Let $t_e$ be an infinum of such $t$.

We have for $t \in [0,t_e]$ that $C^n(t) \in W_{C_j}$ and  $|y_k(t_e)|=\frac{C_{V,j}}{|k|^s}$ for some $|k| \leq n$.  From condition (\ref{eq:iso-cond-v})
it follows that $|k|>L$, but for such $k$ the isolation property implies that $|y_k(t_e)|<\frac{C_{V,j}}{|k|^s}$. This is a contradiction.

\qed


\subsubsection{One step for variational system with finite representation}

In principle Theorem~\ref{thm:c1conver} and sets $W_{C_j}$ as constructed in Lemma~\ref{lem:WCj-exist} alow us to make one time step for system (\ref{eq:sysVar1}--\ref{eq:sysVar2}) provided
we can do such time step for  (\ref{eq:sysVar1}). However this is not satisfying from the computer assisted proofs point of view, as we would need an infinite number of columns to
be integrated one by one. 

To overcome this problem 
we consider block decomposition as defined in Section~\ref{subsec:lmgssblk-decmp}.

In principle any $\mathcal C^0$ algorithm can be applied to compute finite number of columns $V_{*j}(t)$ for $j=1,\dots,m$. The remaining block of infinite number of columns will be bounded uniformly by an operator norm.

For our further considerations it is convenient to split the phase space into $u=(x,y)$, where $x\in \mathbb{R}^m=:X$, $y$ is in the complementary subspace $Y$ and use the notation
\begin{equation*}
  V(t) =\left[\begin{array}{cc}
                  V_{xx}(t) & V_{xy}(t) \\
                   V_{yx}(t) & V_{yy}(t)
               \end{array}
        \right].
\end{equation*}
We  demand that $H=X \oplus Y$ is \gss and norms on $X$ and $Y$ are inherited from $H$.

In what follows we assume that the blocks $V_{xx}(t)$ and $V_{yx}(t)$ are computed using our $\mathcal C^0$ algorithm for integration of (\ref{eq:fueq}) .
Therefore for $V_{ij}(t)$ for $i,j=1,\dots,m$ are given coordinate-wise interval bounds and for  $V_{ij}$ with $j \leq m$ and $i>m$ we will have uniform bounds decaying with $i \to \infty$ depending on some constants computed by the algorithm, just like in $\mathcal C^0$ computation of $u(t)$.

Blocks  $V_{xy}$ and $V_{yy}$  will be represented in our algorithm by bounds of their operator norms. These norms will be controlled by means of the estimates from Theorem~\ref{thm:lineqestm-inf}.




