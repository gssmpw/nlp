
\section{$\mathcal C^1$-convergence of Galerkin projections}
\label{sec:c1-conver}

In Section~\ref{sec:c0-conver} we gave (Theorem~\ref{thm:limitLN}) sufficient and verifiable by means of rigorous numerics conditions that guarantee uniform convergence of a sequence of flows induced by Galerkin projections to a solution of the underlying infinite dimensional system. In this section we would like to address similar question for associated variational equations. Before we state the assumptions about the vector field we need to introduce some notion.


\subsection{Some remarks about $C^1$ functions on compact subsets of \gss spaces}

Let $f:H \supset \dom (f) \to \mathbb{R}$. In the applications we keep in mind, the function $f$ will be a component of a vector field, which might be not  Frech\'et differentiable on $H$. On the other hand, assuming that the restrictions $f^n:=f\circ i_n: H_n \to \mathbb{R}$ are $\mathcal C^1$-smooth for all $n$, the derivative $Df^n(z)$ can be seen as a linear form on $H_n$ represented by a row-vector   $\left(\frac{\partial f}{\partial x_1}(z),\dots,  \frac{\partial f}{\partial x_n}(z)\right)$. Formally $Df^n(z) \in H_n^*$ for $z \in H_n$. We can embed it to $H^*$ by setting $Df^n(z) \circ P_n $ for $z \in H_n$.

Here a natural question arises: does the infinite row-vector  \newline $\left(\frac{\partial f}{\partial x_1}(z), \frac{\partial f}{\partial x_2}(z),\dots\right)$ define a $1$-form on $H$? If so, can we treat it as the derivative of $f$? For this purpose we introduce the notion
\begin{equation}\label{eq:rowderivative}
	\widetilde{D f}(z) := \lim_{n \to \infty} Df^n(P_n z) \circ P_n.
\end{equation}
and prove the following lemma.

\begin{lemma}
	\label{lem:df-form}
	Let $H$ be \gss, $W\subset H$ and let $f:H \supset \dom (f) \to \mathbb{R}$.
	Assume that
	\begin{itemize}
		\item $W$ satisfies condition \textbf{S};
		\item $f|_W$ is continuous;
		\item $f^n$ is $\mathcal C^1$ on $H_n$;
		\item for all $z \in W$ the limit (\ref{eq:rowderivative}) exists and the function $ \widetilde{D f}: W \to H^*$ is continuous.
	\end{itemize}
	Then for every  $z,w \in W$ there holds
	\begin{eqnarray}
		f(z) - f(w) &=& \left(\int_{0}^1 \widetilde{Df}(t z + (1-t)w)dt\right) (z-w) \nonumber \\
		&=&\sum_{j\in\mathbb Z_+}  \int_0^1 \widetilde{D_j f}(t z + (1-t)w)dt \cdot (z_j - w_j),    \label{eq:diff-f-onW}
	\end{eqnarray}
	where $\widetilde{D_j f}(z) := \widetilde{D f}(z)(e_j)$. Moreover, if for some $z \in W$ and $j$ there exists $\delta>0$, such that $ z+[-\delta,\delta]e_j \in \dom (f)$, then   $\frac{\partial f}{\partial x_j}(z)$  exists and
	\begin{equation}
		\widetilde{D_j f}(z)= \frac{\partial f}{\partial x_j}(z).  \label{eq:partderF}
	\end{equation}
\end{lemma}
\textbf{Proof:}
Observe that for any $v,z \in H$ and $n,k \in \mathbb{Z}_+$ there holds
\begin{eqnarray*}
	Df^{n+k}(P_{n+k}(P_nz)) (P_{n+k}(P_nv))&=&Df^{n+k}(P_nz) (P_nv)\\
	&=& Df^{n}(P_nz) (P_nv).
\end{eqnarray*}
Hence
\begin{equation}
	\widetilde{D f}(P_nz)(P_n v)= Df^n(P_nz) (P_nv).  \label{eq:wtDf=Df-onP}
\end{equation}


For any $n \geq M$ and  $z,w \in W$ using (\ref{eq:wtDf=Df-onP}) we have
\begin{eqnarray*}
	f(P_n z) - f(P_n w)=\sum_{j \leq n} \int_0^1 \frac{\partial f}{\partial x_j}(P_n (t z + (1-t)w))dt \cdot (z_j - w_j) \\
	= \int_{0}^1 Df^n(P_n (t z + (1-t)w))dt \cdot P_n(z-w)  \\
	= \int_{0}^1 \widetilde{Df}(P_n (t z + (1-t)w))dt \cdot P_n(z-w).
\end{eqnarray*}
Now we pass to the limit $n \to \infty$ in the above equation. From continuity of $f$ it follows that  $f(P_n z) - f(P_n w) \to f(z) - f(w)$ and from \NC2 we obtain $ P_n(z-w)  \to (z-w)$. From continuity of $\widetilde{Df}$ on $W$, which is compact,  follows its uniform continuity. Moreover, from Lemma~\ref{lem:compt-gss} we get that $P_n$ converges uniformly to the identity on $W$. Therefore the integral converges to  $\int_{0}^1 \widetilde{Df}(t z + (1-t)w)dt$ and we obtain
\begin{eqnarray*}
	f(z) - f(w)= \left(\int_{0}^1 \widetilde{Df}(t z + (1-t)w)dt\right) (z-w).
\end{eqnarray*}
Observe that $\int_{0}^1 \widetilde{Df}(t z + (1-t)w)dt \in H^*$, because it is bounded \\
by $\max_{z \in W} \|\widetilde{Df}(z)\|$.  Therefore from Lemma~\ref{lem:formOnH} we obtain assertion (\ref{eq:diff-f-onW}).

Assume that $z \in W$ and $z+he_j \in W$. Then from (\ref{eq:diff-f-onW}) we obtain
\begin{eqnarray*}
	f(z+he_j) -f(z)= h \left(\int_{0}^1 \widetilde{Df}(z + th e_j)dt\right)(e_j) \\
	= h \int_{0}^1 \widetilde{D_jf}(z + th e_j)dt = h \widetilde{D_jf}(z) + h\int_0^1\left( \widetilde{D_jf}(z + th e_j) - \widetilde{D_jf}(z) \right)dt.
\end{eqnarray*}
From the continuity of $ \widetilde{D_jf}$ it follows that the integral converges to $0$ if $h \to 0$. Therefore we obtain (\ref{eq:partderF}).
\qed

\subsection{Variational equations and Galerkin projections}
%Assume that all assumptions of Theorem \ref{thm:limitLN} are
%satisfied. From first assertion   of Theorem
%\ref{thm:limitLN} it follows  that
%\begin{equation}
%  \varphi^n(t,P_nu) \to \varphi(t,u),
%\end{equation}
%and the convergence is uniform on $[0,T] \times Z$.
%
%Now let us consider the variational matrix for $\varphi^n$ given
%by
%\begin{equation}
%  V^n_{ij}(t,u)= \frac{\partial \varphi^n_i}{\partial u_j} (t,u).
%\end{equation}
%
%
%
%To see why we expect the convergence  here for systems with diagonal $L$   let us notice, that
%$V^n$ satisfies the following differential equation
%\begin{equation}
%  \frac{d V_{ij}^n}{dt}=  \lambda_i V^n_{ij} + \sum_k \frac{\partial  N_i}{\partial u_k} V^n_{kj}
%\end{equation}
%with initial condition $V(0)=\mathrm{Id}$.
%The above equation has the same strong damping as the original equation (\ref{eq:feqLN}). Observe that the bound
%for Lipschitz constant in equation (\ref{eq:LipConstant}) for equation (\ref{eq:feqLN}) and its Galerkin
%projections is also a uniform bound for the norms of matrices
%$V^n(t)$ for $t\in[0,T]$.  Once we have a strong damping
%and a-priori bounds for $V^n$  we can  use the logarithmic norm  to
%control the convergence of $V^n$'s to variational matrix for infinite dimensional system (\ref{eq:feqLN}). In \cite{Z1} this has been done under assumption about $W$ being a trapping region. Moreover,
%one additional condition was needed - (see  condition \VL formulated in Def.~\ref{def:condV}).

Let $\varphi^n$ be a local flow induced by (\ref{eq:GalerkinODE}) and consider the variational matrix for $\varphi^n$ given by
\begin{equation*}
  V^n_{ij}(t,u)= \frac{\partial \varphi^n_i}{\partial u_j} (t,u).
\end{equation*}
Since $F$ is admissible, each column in $V^{n}_{ij}$ evolves separately and satisfies the system of variational equations
\begin{eqnarray}
  \frac{d}{dt} x^n &=& F^n(x^n), \quad x^n \in H_n,  \label{eq:sysVar1} \\
  \frac{d}{dt} C^n &=& D F^n(x^n) C^n, \quad C^n \in H_n. \label{eq:sysVar2}
\end{eqnarray}
The above system has $H_n \times H_n \subset H \times H$ as the phase-space.


Following discussion at the beginning of this section, instead of $DF_i$ which may not exists, we will use the notion $\widetilde{DF_i}$ and define a vector field on $H \times H$ as
\begin{equation}
  \frac{d}{dt} (x,C)=F_V(x,C):=(F(x),\{\widetilde{DF_i}(x)C\}_{i\in\mathbb Z_+}).  \label{eq:sysVarH}
\end{equation}



To bring the variational system to the setting discussed in Section~\ref{sec:c0-conver} we proceeded as follows. On $H \times H$ we use the norm $\|(x,v)\|=\max(\|x\|,\|v\|)$. This makes $H\times H$ a \gss space and its basis is parameterized by $\mathbb{Z}_+ \times \mathbb{Z}_+$. Given $\{J_n\}$ Galerkin filtration of $H$, we define $\{J'_n\}$ Galerkin filtration of $H \times H$ by $J'_n=J_n \times J_n$.  Then accoridingly  Galerkin projection $P_n$ on $H\times H$ is defined by  $P_n(x,C)=(P_nx,P_nC)$.


For the remainder of this section we adopt notation used in Section~\ref{sec:c0-conver} and Theorem~\ref{thm:limitLN}. In particular we have a Galerkin filtration of $H$ and
the induced Galerkin filtration of $H \times H$, so that $P_n$ will always refer to these filtrations.

\begin{definition}
\label{def:condV}
Let $(H,\|\cdot\|)$ be \gss,  $W\times W_V\subset H\times H$ and $F:\mathrm{dom}(F)\subset H \to H$. We say that $F$ satisfies condition \textbf{VC} on $W\times W_V$ if $F$ is admissible, $W\times W_V$ satisfies condition \textbf{S} and
\begin{itemize}
	\item[\bf{VC1:}] the function $F_V$ is continuous on $W\times W_V$;
	\item[\bf{VC2:}] there exists a constant A, such that
	$$
		\sup_{(x,v)\in P_n(W\times W_V)}\mu(DP_nF_V|_{H_n\times H_n})\leq A.
	$$
\end{itemize}
\end{definition}

The conditions \textbf{VC1} and \textbf{VC2} are nothing more than conditions \textbf{C1} and \textbf{C2}  for the vector field $F_V$. Applying arguments from Section~\ref{sec:c0-conver} to $F_V$ we will obtain the existence of solution to variational equation for each column (directional derivative), independently. Obtaining $\mathcal C^1$-like information about full system needs some additional reasoning.

The following theorem is a generalization of Theorem 2 in \cite{Z1}.
\begin{theorem}
\label{thm:c1conver} The same assumptions as in Theorem~\ref{thm:limitLN}. Let $\{W_{V_j}\}_{j \in \mathbb{Z}_+}\subset H$ be a family of sets such that for each $j \in \mathbb{Z}_+$ $F$ satisfies \VL on $W \times W_{V_j}$ and for any $n >j$ the solution of the variational problem (\ref{eq:sysVar1}--\ref{eq:sysVar2}) with initial conditions $x^n(0) \in Z$ and $C^n(0)=e_j$ satisfies
\begin{equation}
  C^n(t) \in W_{V_j}, \quad t \in [0,T]. \label{eq:var-a-priori-bnds}
\end{equation}
Let $l$ be a constant from condition {\rm \textbf{C2}} (uniform bound on logarithmic norm of $DF$ on $W$).

Then there exists $V:[0,T] \times Z  \to \mathrm{Lin}(H,H)$, such that $V_{ij}:[0,T]\times Z \to {\mathbb R}$ for $i,j \in \mathbb{Z}$ are continuous and the following properties are satisfied.
\begin{description}
\item[Convergence:]
For each $j$ the function $\widehat{V}^n_{\ast j}(t,x):= \iota_n V^n_{\ast j}(t,P_n x)$ converges to $V_{\ast j}(t,x)$ uniformly on $[0,T] \times Z$, and
\begin{eqnarray*}
  \|V(t,x)\| &\leq& e^{l t}, \quad (t,x) \in [0,T] \times Z,\\
   V(t,x)e_j &=& \sum_{i\in\mathbb Z_+} V_{ij}(t,x)e_i,
\end{eqnarray*}
and for every $a \in H$ the map $[0,T] \times Z \ni (t,x) \mapsto V(t,x)a$ is continuous.


\item[Smoothness:] For any $x,y \in Z$ and any $t\in[0,T]$ there holds
\begin{equation}
  \varphi(t,x) - \varphi(t,y) =  \int^1_0 V(t,y+s(x-y))ds \cdot (x - y),
    \label{eq:intpar}
\end{equation}
and for every $j$ the partial derivative of the flow $\frac{\partial \varphi}{\partial x_j}(t,x)$ exists and
\begin{equation}
  \frac{\partial \varphi}{\partial x_j}(t,x)=V_{\ast j}(t,x).  \label{eq:dfiduj=Vij}
\end{equation}
\item[Equation for $V$:]  $V(t,u)$ satisfies the following variational equation
  \begin{equation}
     \frac{d V_{*j}}{dt}(t,u) = \sum_i e_i \sum_k \frac{\partial F_i}{\partial u_k}(\varphi(t,u))
           V_{kj}(t,u), \label{eq:varinfdim}
  \end{equation}
 with the initial condition $V(0)=\mathrm{Id}$ in the following sense:  for each $j$ the derivative  $\frac{d V_{*j}}{dt}(t,u)$ exists, the series on r.h.s. of (\ref{eq:varinfdim}) converges uniformly
 on $[0,T] \times Z$ and equation (\ref{eq:varinfdim}) is
 satisfied.
\end{description}
\end{theorem}
\noindent
\textbf{Proof:}
We apply Theorem~\ref{thm:limitLN} to the variational system (\ref{eq:sysVarH}) for $j$-th column (i.e. with initial condition $C(0)=e_j$) separately. From $\VL$ it follows that all its assumptions are satisfied for system (\ref{eq:sysVarH}) with $Z_V=Z \times \{e_j\}$, $W_V=W \times W_{V_j}$ and with $l$ from condition $\VL\mathbf{2}$. Therefore, there exists a family of continuous functions $V_{\ast j}:[0,\infty)\times Z \to H$ for $j \in \mathbb{Z}_+$, such that for each $j$ the functions $\widehat V^{n}_{\ast j}$ converge to $V_{\ast j}$ uniformly on $[0,T] \times Z$ and $(x(t),V_{\ast j}(t,x))$ satisfies variational equation (\ref{eq:sysVarH}).


Now, we will prove (\ref{eq:intpar}) and (\ref{eq:dfiduj=Vij}). Let us fix $t \in [0,T]$ and $x,y\in Z$. For any $n$ we have
\begin{equation*}
  \varphi^n(t,P_n x) - \varphi^n(t,P_n y) =   \int^1_0 V^n(t,P_n y+s(P_n x- P_n y))ds \cdot P_n(x-y)
\end{equation*}

We will pass to the limit $n \to \infty$ in above equation. The limit of l.h.s.
is settled by Theorem \ref{thm:limitLN}.

Now we consider the r.h.s.  We will use Theorem~\ref{thm:Vn-weak-lim} to pass to the limit $n \to \infty$. We already have proved the convergence of $V^n_{ij}$. There remains to show, that $\|V^n\|$ are uniformly bounded.

From condition \textbf{VC2} and Lemmas~\ref{lem:comp-lin-problems} and~\ref{lem:estmLogN} it follows that for all $n\in\mathbb Z_+$,
\begin{equation}
  \|V^n(t,z)\| \leq e^{lt}, \qquad \forall n, (t,z) \in [0,T] \times P_nZ. \label{eq:VnlogN}
\end{equation}


Let $\overline{V}^n(t,[x,y])=\int^1_0 V^n(t,y+s(x- y))ds$.  From (\ref{eq:VnlogN})  we have
\begin{equation*}
     \|\overline{V}^n(t,[P_nx,P_ny])\| \leq e^{lt}, \quad t\in [0,T].
\end{equation*}
From convexity of $W_{V_j}$ it follows that for all $j$ and for $x,y \in Z$ there holds
\begin{equation*}
  \widehat V_{\ast j}^n(t,x),\ \iota_n \overline{V}^n(t,[P_nx,P_ny])_{\ast j} \in W_{V_j}.
\end{equation*}
Since $\widehat V^n_{ij}(t,\cdot)$ are continuous on $Z$ for all $i,j$ and converge uniformly to $V_{ij}(t,\cdot)$ we obtain
\begin{equation*}
  \int^1_0 \widehat V^n_{ij}(t,y+s(x- y))ds \to \int^1_0 V_{ij}(t,y+s(x- y))ds.
\end{equation*}
Now we use Theorem~\ref{thm:Vn-weak-lim} to conclude that $V(t,x) \in \mbox{Lin}(H,H)$, $\int^1_0 V(t,y+s(x- y))ds \in \mbox{Lin}(H,H)$ and
\begin{equation*}
  \lim_{n \to \infty} \int^1_0 V^n(t,y+s(x- y))ds \cdot (x-y) = \int^1_0 V(t,y+s(x- y))ds \cdot (x-y).
\end{equation*}
Gathering this with
\begin{eqnarray*}
\lim_{n\to\infty}  \varphi^n(t,P_n x) -  \varphi^n(t,P_n y)&=&\varphi(t,x) - \varphi(t,y),\\
\lim_{n\to\infty} P_n (x-y)&=& x-y
\end{eqnarray*}
we obtain (\ref{eq:intpar}).

Now we will show that from (\ref{eq:intpar}) we can conclude (\ref{eq:dfiduj=Vij}). Indeed, we have
\begin{eqnarray*}
  \varphi(t,x+he_j) -  \varphi(t,x) = h \int_0^1 V(t,x+she_j)ds \cdot e_j \\
  = h  V(t,x)e_j + h \int_0^1 \left( V(t,x+she_j)e_j - V(t,x)e_j \right)ds\\
  = h  V_{\ast j}(t,x) + h \int_0^1 \left( V_{\ast j}(t,x+she_j) - V_{\ast j}(t,x) \right)ds
\end{eqnarray*}
and the result follows from continuity of $V_{\ast j}(t,\cdot)$.

It remains to prove that for every $a \in H$ the map $[0,T] \times Z \ni (t,z) \mapsto V(t,z)a \in H$ is continuous. We know that for every $j$ the map $(t,x) \mapsto V_{\ast j}(t,z)$ is continuous. Let $(t_1,z_1), (t_2,z_2) \in [0,T] \times Z$. Then  for any $n$ holds
\begin{eqnarray*}
  \| V(t_1,z_1)a - V(t_2,z_2)a \| \leq \| V(t_1,z_1)P_n a - V(t_2,z_2)P_n a \| \\
   +  \| V(t_1,z_1)(I-P_n) a \| + \| V(t_2,z_2)(I-P_n) a \| \leq  \\
       \sum_{j \in J_n} \|V(t_1,z_1)_{\ast j} - V(t_2,z_2)_{\ast j}\| \cdot |a_j| + (e^{t_1 l} + e^{t_2 l}) \|(I-P_n)a\|
\end{eqnarray*}
For a given $\epsilon>0$ we take $n$ so large that $ \|(I-P_n)a\|e^{\max(0,l)T} < \epsilon/2$. We fix such $n$. Then from the continuity of $V_{\ast j}$ for $j\in J_n$
we can make the sum less that $\epsilon/2$ when $(t_2,z_2) \to (t_1,z_1)$. This finishes the proof.
\qed

\subsection{Block decomposition}
\label{subsec:blockdecmp}
Now, we would like to adapt Lemma~\ref{lem:comp-lin-problems} to the variational equation for dissipative PDEs and its solution obtained as the limit of solutions of variational equation of Galerkin projections. We will adopt the notation related to a decomposition of $H$ from Section~\ref{subsec:lmgssblk-decmp}.

\begin{theorem}
\label{thm:lineqestm-inf}
 Same assumptions and notation as in Theorem~\ref{thm:c1conver}.  Consider a decomposition of $H$ given by (\ref{eq:H-decmp}).


 Assume that matrix $J \in \mathbb{R}^{(m+1) \times (m+1)}$ satisfies
\begin{equation*}%\label{eq:def-J}
 J_{k\ell} \geq
  \begin{cases}
     \sup_{n>M} \sup_{w \in W} \left\|\frac{\partial F^n_{\langle k \rangle}}{\partial u_{\langle \ell \rangle}}(w) \right\|,  & \text{for $k \neq \ell$, $l,\ell \leq m$+1}, \\
     \sup_{n>M} \sup_{w \in W}  \mu\left(\frac{ \partial F^n_{\langle k \rangle} }{\partial u_{\langle k \rangle}}(w) \right),     & \text{for $k=\ell\leq m+1$}
  \end{cases}
\end{equation*}


Then for any  $x \in Z$ and  $t \in [0,T]$
holds
\begin{eqnarray}
  \|V_{\langle k \rangle \langle \ell \rangle}(t,x)\| &\leq&  \left(e^{Jt}\right)_{k\ell},  \quad k,\ell=1,\dots,m+1.   \label{eq:Vij-estm}
\end{eqnarray}
\end{theorem}
\textbf{Proof:}
Let us take any $n > M$. We consider the decomposition of $H_n$
\begin{equation*}
H_n=\bigoplus_{k \leq m} H_{\langle k \rangle}   \oplus Y_n, \quad Y_n=P_n  H_{\langle m+1 \rangle}.
\end{equation*}

From Lemma~\ref{lem:comp-lin-problems} applied to $n$-th Galerkin projection with matrix $J$ we obtain that conditions (\ref{eq:Vij-estm}) are satisfied by  $V^n(t,P_n x)$ for $x \in Z$ and $t \in [0,T]$


Now we want to pass to the limit  $n \to \infty$.   We know from Theorem~\ref{thm:c1conver} that
\begin{equation*}
V^n_{ij}(t,P_nx) \to V_{ij}(t,x), \quad \forall (i,j)\in \mathbb{Z}_+^2  \quad \forall t \in [0,T], x\in Z. %\label{eq:Vij-conv}
\end{equation*}
The result now follows from Theorem~\ref{thm:gcpn-abstr}.
\qed





