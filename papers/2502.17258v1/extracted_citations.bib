@inproceedings{avrahami2022blended,
  title={Blended diffusion for text-driven editing of natural images},
  author={Avrahami, Omri and Lischinski, Dani and Fried, Ohad},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18208--18218},
  year={2022}
}

@article{avrahami2023blended,
  title={Blended latent diffusion},
  author={Avrahami, Omri and Fried, Ohad and Lischinski, Dani},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={4},
  pages={1--11},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@inproceedings{ceylan2023pix2video,
  title={Pix2video: Video editing using image diffusion},
  author={Ceylan, Duygu and Huang, Chun-Hao P and Mitra, Niloy J},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={23206--23217},
  year={2023}
}

@inproceedings{chai2023stablevideo,
  title={Stablevideo: Text-driven consistency-aware diffusion video editing},
  author={Chai, Wenhao and Guo, Xun and Wang, Gaoang and Lu, Yan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={23040--23050},
  year={2023}
}

@article{chefer2023attend,
  title={Attend-and-excite: Attention-based semantic guidance for text-to-image diffusion models},
  author={Chefer, Hila and Alaluf, Yuval and Vinker, Yael and Wolf, Lior and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={4},
  pages={1--10},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@article{cong2023flatten,
  title={FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing},
  author={Cong, Yuren and Xu, Mengmeng and Simon, Christian and Chen, Shoufa and Ren, Jiawei and Xie, Yanping and Perez-Rua, Juan-Manuel and Rosenhahn, Bodo and Xiang, Tao and He, Sen},
  journal={arXiv preprint arXiv:2310.05922},
  year={2023}
}

@inproceedings{couairon2023diffedit,
  title={DiffEdit: Diffusion-based Semantic Image Editing with Mask Guidance},
  author={Couairon, Guillaume and Verbeek, Jakob and Schwenk, Holger and Cord, Matthieu},
  booktitle={ICLR 2023 (Eleventh International Conference on Learning Representations)},
  year={2023}
}

@inproceedings{densediffusion,
  title={Dense Text-to-Image Generation with Attention Modulation},
  author={Kim, Yunji and Lee, Jiyoung and Kim, Jin-Hwa and Ha, Jung-Woo and Zhu, Jun-Yan},
  year={2023},
  booktitle = {ICCV}
}

@article{geyer2023tokenflow,
  title={Tokenflow: Consistent diffusion features for consistent video editing},
  author={Geyer, Michal and Bar-Tal, Omer and Bagon, Shai and Dekel, Tali},
  journal={arXiv preprint arXiv:2307.10373},
  year={2023}
}

@article{gu2023videoswap,
  title={Videoswap: Customized video subject swapping with interactive semantic point correspondence},
  author={Gu, Yuchao and Zhou, Yipin and Mike Zheng et al.},
  journal={arXiv preprint arXiv:2312.02087},
  year={2023}
}

@article{guo2023animatediff,
  title={Animatediff: Animate your personalized text-to-image diffusion models without specific tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Wang, Yaohui and Qiao, Yu and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint arXiv:2307.04725},
  year={2023}
}

@article{hertz2022prompt,
  title={Prompt-to-prompt image editing with cross attention control},
  author={Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  booktitle={arXiv preprint arXiv:2208.01626},
  year={2022}
}

@article{jeong2023ground,
  title={Ground-A-Video: Zero-shot Grounded Video Editing using Text-to-image Diffusion Models},
  author={Jeong, Hyeonho and Ye, Jong Chul},
  journal={arXiv preprint arXiv:2310.01107},
  year={2023}
}

@article{kasten2021layered,
  title={Layered neural atlases for consistent video editing},
  author={Kasten, Yoni and Ofri, Dolev and Wang, Oliver and Dekel, Tali},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={6},
  pages={1--12},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{mou2025revideo,
  title={Revideo: Remake a video with motion and content control},
  author={Mou, Chong and Cao, Mingdeng and Wang, Xintao and Zhang, Zhaoyang and Shan, Ying and Zhang, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={18481--18505},
  year={2025}
}

@article{ouyang2023codef,
  title={Codef: Content deformation fields for temporally consistent video processing},
  author={Ouyang, Hao and Wang, Qiuyu and Xiao, Yuxi and Bai, Qingyan and Zhang, Juntao and Zheng, Kecheng and Zhou, Xiaowei and Chen, Qifeng and Shen, Yujun},
  journal={arXiv preprint arXiv:2308.07926},
  year={2023}
}

@inproceedings{parmar2023zero,
  title={Zero-shot image-to-image translation},
  author={Parmar, Gaurav and Kumar Singh, Krishna and Zhang, Richard and Li, Yijun and Lu, Jingwan and Zhu, Jun-Yan},
  booktitle={ACM SIGGRAPH 2023 Conference Proceedings},
  pages={1--11},
  year={2023}
}

@article{phung2023grounded,
  title={Grounded Text-to-Image Synthesis with Attention Refocusing},
  author={Phung, Quynh and Ge, Songwei and Huang, Jia-Bin},
  journal={arXiv preprint arXiv:2306.05427},
  year={2023}
}

@inproceedings{pumarola2021d,
  title={D-nerf: Neural radiance fields for dynamic scenes},
  author={Pumarola, Albert and Corona, Enric and Pons-Moll, Gerard and Moreno-Noguer, Francesc},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10318--10327},
  year={2021}
}

@article{qi2023fatezero,
  title={Fatezero: Fusing attentions for zero-shot text-based video editing},
  author={Qi, Chenyang and Cun, Xiaodong and Zhang, Yong and Lei, Chenyang and Wang, Xintao and Shan, Ying and Chen, Qifeng},
  journal={arXiv preprint arXiv:2303.09535},
  year={2023}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@article{wang2023dynamic,
  title={Dynamic prompt learning: Addressing cross-attention leakage for text-based image editing},
  author={Wang, Kai and Yang, Fei and Yang, Shiqi and Butt, Muhammad Atif and van de Weijer, Joost},
  journal={arXiv preprint arXiv:2309.15664},
  year={2023}
}

@article{wang2023modelscope,
  title={Modelscope text-to-video technical report},
  author={Wang, Jiuniu and Yuan, Hangjie and Chen, Dayou and Zhang, Yingya and Wang, Xiang and Zhang, Shiwei},
  journal={arXiv preprint arXiv:2308.06571},
  year={2023}
}

@article{wu2022tune,
  title={Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation},
  author={Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Weixian and Gu, Yuchao and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2212.11565},
  year={2022}
}

@inproceedings{yang2023rerender,
 title = {Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation},
 author = {Yang, Shuai and Zhou, Yifan and Liu, Ziwei and and Loy, Chen Change},
 booktitle = {ACM SIGGRAPH Asia Conference Proceedings},
 year = {2023},
}

@article{yang2024cogvideox,
  title={Cogvideox: Text-to-video diffusion models with an expert transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}

@inproceedings{yu2023magvit,
  title={Magvit: Masked generative video transformer},
  author={Yu, Lijun and Cheng, Yong and Sohn, Kihyuk and Lezama, Jos{\'e} and Zhang, Han and Chang, Huiwen and Hauptmann, Alexander G and Yang, Ming-Hsuan and Hao, Yuan and Essa, Irfan and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10459--10469},
  year={2023}
}

@article{zhang2023controlvideo,
  title={ControlVideo: Training-free Controllable Text-to-Video Generation},
  author={Zhang, Yabo and Wei, Yuxiang and Jiang, Dongsheng and Zhang, Xiaopeng and Zuo, Wangmeng and Tian, Qi},
  journal={arXiv preprint arXiv:2305.13077},
  year={2023}
}

