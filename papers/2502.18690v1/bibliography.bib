@article{Survey,
   title={Procedural Content Generation in Games: A Survey with Insights on Emerging LLM Integration},
   volume={20},
   ISSN={2326-909X},
   url={http://dx.doi.org/10.1609/aiide.v20i1.31877},
   DOI={10.1609/aiide.v20i1.31877},
   number={1},
   journal={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
   publisher={Association for the Advancement of Artificial Intelligence (AAAI)},
   author={Farrokhi Maleki, Mahdi and Zhao, Richard},
   year={2024},
   month=nov, pages={167–178} }

@article{SceneCraft, title={SceneCraft: Automating Interactive Narrative Scene Generation in Digital Games with Large Language Models}, volume={19}, url={https://ojs.aaai.org/index.php/AIIDE/article/view/27504}, DOI={10.1609/aiide.v19i1.27504}, abstractNote={Creating engaging interactive story-based experiences dynamically responding to individual player choices poses significant challenges for narrative-centered games. Recent advances in pre-trained large language models (LLMs) have the potential to revolutionize procedural content generation for narrative-centered games. Historically, interactive narrative generation has specified pivotal events in the storyline, often utilizing planning-based approaches toward achieving narrative coherence and maintaining the story arc. However, manual authorship is typically used to create detail and variety in non-player character (NPC) interaction to specify and instantiate plot events. This paper proposes SCENECRAFT, a narrative scene generation framework that automates NPC interaction crucial to unfolding plot events. SCENECRAFT interprets natural language instructions about scene objectives, NPC traits, location, and narrative variations. It then employs large language models to generate game scenes aligned with authorial intent. It generates branching conversation paths that adapt to player choices while adhering to the author’s interaction goals. LLMs generate interaction scripts, semantically extract character emotions and gestures to align with the script, and convert dialogues into a game scripting language. The generated script can then be played utilizing an existing narrative-centered game framework. Through empirical evaluation using automated and human assessments, we demonstrate SCENECRAFT’s effectiveness in creating narrative experiences based on creativity, adaptability, and alignment with intended author instructions.}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment}, author={Kumaran, Vikram and Rowe, Jonathan and Mott, Bradford and Lester, James}, year={2023}, month={Oct.}, pages={86-96} }

@misc{1001Nights,
      title={Language as Reality: A Co-Creative Storytelling Game Experience in 1001 Nights using Generative AI}, 
      author={Yuqian Sun and Zhouyi Li and Ke Fang and Chang Hee Lee and Ali Asadipour},
      year={2023},
      eprint={2308.12915},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2308.12915}, 
}

@inproceedings{Quests1,
author = {Ashby, Trevor and Webb, Braden K and Knapp, Gregory and Searle, Jackson and Fulda, Nancy},
title = {Personalized Quest and Dialogue Generation in Role-Playing Games: A Knowledge Graph- and Language Model-based Approach},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581441},
doi = {10.1145/3544548.3581441},
abstract = {Procedural content generation (PCG) in video games offers unprecedented opportunities for customization and user engagement. Working within the specialized context of role-playing games (RPGs), we introduce a novel framework for quest and dialogue generation that places the player at the core of the generative process. Drawing on a hand-crafted knowledge base, our method grounds generated content with in-game context while simultaneously employing a large-scale language model to create fluent, unique, accompanying dialogue. Through human evaluation, we confirm that quests generated using this method can approach the performance of hand-crafted quests in terms of fluency, coherence, novelty, and creativity; demonstrate the enhancement to the player experience provided by greater dynamism; and provide a novel, automated metric for the relevance between quest and dialogue. We view our contribution as a critical step toward dynamic, co-creative narrative frameworks in which humans and AI systems jointly collaborate to create unique and user-specific playable experiences.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {290},
numpages = {20},
keywords = {English, GPT-2, MMORPG, NPC dialogue, RPG, World of Warcraft, computational creativity, dynamic quest generation, human-AI co-creativity, human-computer interaction, knowledge graph, knowledge-grounded text generation, language model, large-scale language models, narrative, natural language processing, procedural content generation, quest, quests, text generation, transformers, video games},
location = {Hamburg, Germany},
series = {CHI '23}
}

@ARTICLE{Quests2,
  author={Värtinen, Susanna and Hämäläinen, Perttu and Guckelsberger, Christian},
  journal={IEEE Transactions on Games}, 
  title={Generating Role-Playing Game Quests With GPT Language Models}, 
  year={2024},
  volume={16},
  number={1},
  pages={127-139},
  keywords={Games;Computational modeling;Task analysis;Large language models;Data models;Artificial intelligence;Role playing games;Artificial intelligence;computational storytelling;games;generative models;procedural content generation;quests},
  doi={10.1109/TG.2022.3228480}}


@article{Calypso, title={CALYPSO: LLMs as Dungeon Master’s Assistants}, volume={19}, url={https://ojs.aaai.org/index.php/AIIDE/article/view/27534}, DOI={10.1609/aiide.v19i1.27534}, abstractNote={The role of a Dungeon Master, or DM, in the game Dungeons &amp; Dragons is to perform multiple tasks simultaneously. The DM must digest information about the game setting and monsters, synthesize scenes to present to other players, and respond to the players’ interactions with the scene. Doing all of these tasks while maintaining consistency within the narrative and story world is no small feat of human cognition, making the task tiring and unapproachable to new players. Large language models (LLMs) like GPT-3 and ChatGPT have shown remarkable abilities to generate coherent natural language text. In this paper, we conduct a formative evaluation with DMs to establish the use cases of LLMs in D&amp;D and tabletop gaming generally. We introduce CALYPSO, a system of LLM-powered interfaces that support DMs with information and inspiration specific to their own scenario. CALYPSO distills game context into bite-sized prose and helps brainstorm ideas without distracting the DM from the game. When given access to CALYPSO, DMs reported that it generated high-fidelity text suitable for direct presentation to players, and low-fidelity ideas that the DM could develop further while maintaining their creative agency. We see CALYPSO as exemplifying a paradigm of AI-augmented tools that provide synchronous creative assistance within established game worlds, and tabletop gaming more broadly.}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment}, author={Zhu, Andrew and Martin, Lara and Head, Andrew and Callison-Burch, Chris}, year={2023}, month={Oct.}, pages={380-390} }


@misc{MarioGPT,
      title={MarioGPT: Open-Ended Text2Level Generation through Large Language Models}, 
      author={Shyam Sudhakaran and Miguel González-Duque and Claire Glanois and Matthias Freiberger and Elias Najarro and Sebastian Risi},
      year={2023},
      eprint={2302.05981},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2302.05981}, 
}

@inproceedings{Sokoban, series={FDG 2023},
   title={Level Generation Through Large Language Models},
   url={http://dx.doi.org/10.1145/3582437.3587211},
   DOI={10.1145/3582437.3587211},
   booktitle={Proceedings of the 18th International Conference on the Foundations of Digital Games},
   publisher={ACM},
   author={Todd, Graham and Earle, Sam and Nasir, Muhammad Umair and Green, Michael Cerny and Togelius, Julian},
   year={2023},
   month=apr, collection={FDG 2023} }


@misc{Metavoidal,
      title={Practical PCG Through Large Language Models}, 
      author={Muhammad U Nasir and Julian Togelius},
      year={2023},
      eprint={2305.18243},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.18243}, 
}


@article{CBS,
title = {Conflict-based search for optimal multi-agent pathfinding},
journal = {Artificial Intelligence},
volume = {219},
pages = {40-66},
year = {2015},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2014.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0004370214001386},
author = {Guni Sharon and Roni Stern and Ariel Felner and Nathan R. Sturtevant},
keywords = {Heuristic search, Multi-agent, Pathfinding},
abstract = {In the multi-agent pathfinding problem (MAPF) we are given a set of agents each with respective start and goal positions. The task is to find paths for all agents while avoiding collisions. Most previous work on solving this problem optimally has treated the individual agents as a single ‘joint agent’ and then applied single-agent search variants of the A* algorithm. In this paper we present the Conflict Based Search (CBS) a new optimal multi-agent pathfinding algorithm. CBS is a two-level algorithm that does not convert the problem into the single ‘joint agent’ model. At the high level, a search is performed on a Conflict Tree (CT) which is a tree based on conflicts between individual agents. Each node in the CT represents a set of constraints on the motion of the agents. At the low level, fast single-agent searches are performed to satisfy the constraints imposed by the high level CT node. In many cases this two-level formulation enables CBS to examine fewer states than A* while still maintaining optimality. We analyze CBS and show its benefits and drawbacks. Additionally we present the Meta-Agent CBS (MA-CBS) algorithm. MA-CBS is a generalization of CBS. Unlike basic CBS, MA-CBS is not restricted to single-agent searches at the low level. Instead, MA-CBS allows agents to be merged into small groups of joint agents. This mitigates some of the drawbacks of basic CBS and further improves performance. In fact, MA-CBS is a framework that can be built on top of any optimal and complete MAPF solver in order to enhance its performance. Experimental results on various problems show a speedup of up to an order of magnitude over previous approaches.}
}

@inproceedings{GPT2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:160025533}
}

@misc{GPT3,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}, 
}

@misc{chatgpt,
  title        = {ChatGPT},
  author       = {OpenAI},
  year         = {2022},
  url          = {https://openai.com/index/chatgpt/},
  note         = {Accessed: 2025-02-13}
}


