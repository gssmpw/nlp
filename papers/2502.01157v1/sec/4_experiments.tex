\input{tab/main_table}
\section{Experiments}
\label{sec:experiments}
%
% \subsection{Novel View Synthesis Benchmarks}
We evaluated our algorithm on a total of 9 real-world scenes sourced from two publicly available datasets. 
Specifically, we utilized the complete set of scenes from the Mip-NeRF 360 dataset~\cite{mipnerf360} except for two private scenes (flowers and treehill) and two scenes from the Deep Blending dataset~\cite{deepblending}.
These datasets contain scenes with a diverse range of capture styles, including bounded indoor scenes and expansive, unbounded outdoor environments.
For Mip-NeRF 360, to make our results compatible with~\cite{gsplat, 3dgrt}, we downsample images for the indoor scenes by a factor of two, and the outdoor scenes by four.
For Deep Blending scenes, we use the original image resolutions.
All frame rates were measured on a consumer-grade RTX 4090 GPU.

\paragraph{Metrics}
We assess each method using three widely recognized image quality metrics: Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS).
% 
In the supplementary web page we include rendered video paths for selected scenes, showcasing views significantly different from the input images.

\paragraph{Quantitative results}
We report our quantitative results for the Mip-NeRF 360~\cite{mipnerf360} and Deep Blending~\cite{deepblending} in \Cref{tab:qual_res}.
In terms of quality, our method achieves results comparable to, or slightly below, those of 3DGS~\cite{gsplat} and 3DGRT~\cite{3dgrt}~(the state-of-the-art differentiable ray tracing method).
However, our method \ul{excels} in rendering speed. 
As shown in \Cref{tab:qual_res}, our efficient ray-tracing implementation achieves in some cases over 300 FPS, more than twice as fast as 3DGRT~($119$ FPS), while maintaining a similar rendering speed to rasterization methods.

\input{tab/ablation_table}
\subsection{Ablation}
\input{fig/ablation/item}
We isolated the different contributions and choices we made and constructed a set of experiments to measure their effect. 
Specifically, we test the following aspects of our algorithm: initialization from SfM, our densification and pruning strategies, and regularization loss. 
The quantitative effect of each choice is summarized in \Cref{tab:ablation}.

\paragraph{Initialization from SFM} 
We assess the importance of initializing our Voronoi sites from the SfM point cloud. 
For this, we initialize our representation with $2^{17}$ points from a normal distribution with a standard deviation of 10.
We observe that our method performs relatively well even without the SfM points. 
Instead, it degrades mainly in the background and tends to have more floaters in regions that are sparsely covered in the training views, see \Cref{fig:ablation}.

\paragraph{Densification and pruning}
Due to numerical approximations, our triangulation algorithm can fail when processing very close (or identical) points. 
This limitation prevents us from initializing our representation directly with the final set of points obtained by duplicating and perturbing the Structure from Motion (SfM) points, as SfM typically produces numerous closely spaced points.
% 
Consequently, for the ablation study on densification, we utilize the random initialization strategy described earlier to initialize our representation with the intended number of points.
We observe that our method significantly underperforms without densification, resulting in an under-represented scene where resources are not adequately allocated to regions with complex geometry or texture.
\quad
In the ablation study of our pruning strategy, we cease pruning those Voronoi sites that are neither surface nor boundary points. 
We notice that this pruning approach has minimal impact on the quality of the renderings because the number of prunable points is very low. 
By starting with a sparse point set and progressively densifying only in under-represented areas, we ensure that points are allocated exclusively to necessary regions, resulting in few prunable points.

\paragraph{Quantile loss}
We disable the quantile regularization while training, which results in floater artifacts that degrade rendering quality for novel views.
Some scenes are more affected by this than others, as the floaters result from data-dependent ambiguities, but on average we find that the quantile regularization improves reconstruction metrics.
