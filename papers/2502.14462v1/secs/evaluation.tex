\section{Evaluation}


\subsection{\textbf{Dataset}}
Using a high-end \emph{EPSON V850 Pro} flatbed scanner, we capture 3830 10x10 cm material samples at 1200 PPI resolution. %
Note that this scanner can capture images using a standard, single LED strip illumination, like lower-end scanners, but also enables a higher-quality setup using a dual-light which provides diffuse-like illumination. A detailed description of the dataset is provided in the supplementary material.
The later setup closely resembles fitted albedos~\cite{rodriguezpardo2023UMat}, removing strong shades caused by wrinkles or mesostructure, hiding shadows casted to the scanner lid and eliminating specular highlights (as shown in Figure~\ref{fig:dataset_delighting}).
We thus capture two images for each material: $I_{l}$ and $I_{d}$, preserving pixel-wise correspondence for every material under both illuminations. To augment this dataset, we further capture every material on their front and back sides, and rotate them by 90ยบ to allow for generalization to multiple orientations. We also capture these materials on a custom gonioreflectometer, and leverage the methodology described in~\cite{rodriguezpardo2021transfer, garces2023towards} to propagate the ground truth material parameters described in Equation~\ref{eq:mat_model}. 
We use 10\% of this dataset for testing. 




\subsection{\textbf{Metrics}}
To measure the performance of our models, we use a variety of metrics aimed at understanding the perceptual, pixel-wise, and render-aware accuracy of our estimations.
First, to measure the errors of our generators, $\mathcal{M}_D$ and  $\mathcal{M}_R$, we leverage traditional image quality metrics, as well as $\Delta E$~\cite{mokrzycki2011colour}, which accurately measures color differences, and perceptually-motivated alternatives like FLIP~\cite{Andersson2020} and LPIPS~\cite{zhang2018unreasonable}. We also quantify per-map accuracy, leveraging pixel-wise $\mathcal{L}_1$ norms for the Albedo, Roughness, Specular, and Transmittance maps, angular distances $\mathcal{L}_\measuredangle$ for the surface normals, and the Jaccard index $\mathcal{L}_{Jacc}$ for the opacity maps. Following~\cite{rodriguezpardo2023UMat}, we also report Pearson correlations $\rho$.

The previous metrics are useful to assess individual precision of the estimations. However, when reproducing a real material, it is of critical  importance to understand how these parameters interact with each other in the integrated physically-based rendering space. Thus, we propose a set of metrics aimed to evaluate the accuracy of the full material model in terms of both reflectance and transmittance. 
For reflectance, we expand the $\mathcal{L}_{\text{\tiny{BRDF}}}$ metric in~\cite{rodriguezpardo2023UMat}, which measures the perceptual error, with extra terms that account for material opacity, and cosine weighting and peak reflectance attenuation to account for human visual perception~\cite{lavoue2021perceptual}. 
We measure the render-space reflectance estimation difference between the ground truth $\mathbf{M}_{GT}$ and predicted $\hat{\mathbf{M}}$ material as follows:
\begin{align} \label{eq:brdf}
	\resizebox{\hsize}{!}{$\mathcal{L}_{\text{\tiny{BRDF}}} (\mathbf{M}_{GT},\hat{\mathbf{M}}) = \frac{1}{xy} \sum\limits_{xy} \sqrt{ \frac{1}{|S|}\sum\limits_{(l, v) \in S } \sqrt[3]{\cos^2(\theta_l) \left( f_{l,v}^\textrm{BRDF}(\mathbf{A}_{GT},\mathbf{N}_{GT},\mathbf{S}_{GT},\mathbf{R}_{GT})\cdot O_{GT} - f_{l,v}^\textrm{BRDF}(\hat{\mathbf{A}},\hat{\mathbf{N}},\hat{\mathbf{S}}, \hat{\mathbf{R}}) \cdot \hat{O}\right)^2}}$}
\end{align}
where $l,v$ are a set of 50 lights and viewing angles optimized for BRDF acquisition, gathered from~\cite{nielsen2015optimal}. 

For transmittance, we introduce a novel metric, $\mathcal{L}_{\text{\tiny{BTDF}}}$, which explicitly measures the error in the estimation of transmissive effects as follows: 
\begin{align}
\label{ec:ell_svbrdf}
       \mathcal{L}_{\text{\tiny{BTDF}}} (\mathbf{M}_{GT},\hat{\mathbf{M}})= \frac{1}{xy} \sum\limits_{xy} |  \mathbf{T}_{GT} \cdot \mathbf{A}_{GT} \cdot \mathbf{O}_{GT}  - \hat{\mathbf{T}} \cdot \hat{\mathbf{A}} \cdot \hat{\mathbf{O}} | 
\end{align}
Finally, we define our final metric $\mathcal{L}_{\text{\tiny{BSDF}}}$ as a weighted combination of $\mathcal{L}_{\text{\tiny{BRDF}}}$ and $\mathcal{L}_{\text{\tiny{BTDF}}}$, setting $w_{\text{\tiny{BRDF}}}  = \frac{1}{2}$ for simplicity: 
\begin{align}
\label{ec:ell_svbsdf}
       \mathcal{L}_{\text{\tiny{BSDF}}} = w_{\text{\tiny{BRDF}}} \mathcal{L}_{\text{\tiny{BRDF}}} +  (1-w_{\text{\tiny{BRDF}}}) \mathcal{L}_{\text{\tiny{BTDF}}}  
\end{align}

This integrated metric is render-aware and perceptually validated and enables the comparison of different configurations of our models. 

\subsection{\textbf{Ablation Study}}

In this section, we present an ablation study to validate each of our components.

\subsubsection*{\textbf{Delighting Model}} %
Table~\ref{tab:delighting_quantitative} presents the results of the study for our \textit{Relighting} and \textit{Delighting} flows. 
Our baseline is a pure regression-based model which uses only pixel-wise $\Loss_1$ losses. We progressively add components to this baseline, to study their impact.
First, making the models generative by introducing $\Loss_{adv}$ to their training losses enables higher accuracy.
Training $\mathcal{M}_D$ and $\mathcal{M}_R$ together, using our cycle-consistency loss $\Loss_{cycle}$, strongly improves accuracy across every metric, providing evidence that this is a key component for achieving high-quality albedo estimations. 
Further, using our residual learning approach, inspired by intrinsic decomposition, provides significant gains across every metric.
Finally, incremental improvements are achieved by introducing $\Loss_{perc}$ and $\Loss_{freq}$, and our full data augmentation policy. Interestingly, we observe that relighting is typically a harder task.
We believe that our cycle-consistent approach allows our model to generalize better because it works as a form of data augmentation, while residual learning improves training dynamics and makes the task easier to learn. 







\begin{table*}[t]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lccccc|ccccc@{}}
\cmidrule(l){2-11}
\multicolumn{1}{c}{\multirow{2}{*}{}}      & \multicolumn{5}{c}{\textbf{Relighting}} & \multicolumn{5}{c}{\textbf{Delighting}} \\ \cmidrule(l){2-11} 
 &
 $        $ PSNR $\uparrow$ &
  SSIM~\cite{wang2004image} $\uparrow$ &
  LPIPS~\cite{zhang2018unreasonable} $\downarrow$   &
  $\Delta E $ $\downarrow$ &
  \FLIP~\cite{Andersson2020} $\downarrow$ &
  $        $ PSNR $\uparrow$&
  SSIM~\cite{wang2004image} $\uparrow$ &
  LPIPS~\cite{zhang2018unreasonable} $\downarrow$   &
  $\Delta E $ $\downarrow$ &
  \FLIP~\cite{Andersson2020} $\downarrow$ \\ \cmidrule(l){2-11} 
  \multicolumn{1}{l}{No Delighting}    &  24.01    & 0.686    &  0.262   &  4.732    &  0.264   &   24.01    & 0.686    &  0.262   &  4.732    &  0.264    \\ \cmidrule(l){1-11} 
\multicolumn{1}{l}{Baseline Delighting}              & \RedColor{24.47}     &  \RedColor{0.784}    & \RedColor{0.289}     &  \RedColor{6.102}    &  \RedColor{0.259}   &  \RedColor{25.71}    &  \RedColor{0.798}    & \RedColor{0.267}    &  \RedColor{4.922}    &  \RedColor{0.219}    \\
\multicolumn{1}{l}{+ $\mathcal{L}_{adv}$}    & 24.69     &  0.809    &  0.257    & 5.587     &  0.244   &   26.72   &  0.810    &  0.242     &   4.359  &  0.202   \\
\multicolumn{1}{l}{+ Cycle-Consistency}   &  26.54    &  0.856    & 0.218     &  4.213    & 0.194    &  27.82    &  0.851    &  0.202    &  3.604   &  0.169   \\
\multicolumn{1}{l}{+ Residual}            & 28.42     & 0.903     &  0.165    & 3.115    & 0.147    &  29.79    &  0.897    &  0.171    &  2.754   &   0.132  \\
\multicolumn{1}{l}{+ Full Loss}           &   \GreenColor{28.67}   &  \GreenColor{0.912}   &  0.164    &   3.071   &  0.144   &   30.19   &   0.906   &   0.151   & 2.630    &  0.126   \\
\multicolumn{1}{l}{+ Aug. (Final Model)}     &  28.48    & 0.907     &  \GreenColor{0.161}    &  \GreenColor{3.012}    & \GreenColor{0.138}    & \GreenColor{31.41}    &  \GreenColor{0.933}    &  \GreenColor{0.136}    &  \GreenColor{2.261}   &   \GreenColor{0.111}  \\ \bottomrule
\end{tabular}%
}
\caption{Results of our ablation study of our material delighting algorithm, across a variety of metrics. On the top row, we show the results when no delighting is applied. We use a color code to highlight \GreenColor{best} and \RedColor{worst} cases.}
\label{tab:delighting_quantitative}
\end{table*}


\begin{table*}[h!]
	\centering
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{@{}lcccccccccccc@{}}
			\cmidrule(l){2-13}
			& \multicolumn{6}{c}{\textbf{Pixel-Wise Errors}} & \multicolumn{3}{c}{\textbf{Correlations}} & \multicolumn{3}{c}{\textbf{Render-Aware}} \\ \cmidrule(l){2-13} 
			\multicolumn{1}{c}{} &
			\multicolumn{1}{c}{$\mathcal{L}_{1}^{A}\downarrow$} &
			\multicolumn{1}{c}{$\mathcal{L}_{\measuredangle} \downarrow$} &
			\multicolumn{1}{c}{$\mathcal{L}_{1}^{R}\downarrow$} &
			\multicolumn{1}{c}{$\mathcal{L}_{1}^{S}\downarrow$} &
			\multicolumn{1}{c}{$\mathcal{L}_{1}^{T}\downarrow$} &
			\multicolumn{1}{c}{$\mathcal{L}_{Jac}^{O}\uparrow$} &
			$\rho^{R}\uparrow$ &
			$\rho^{S}\uparrow$ &
			$\rho^{T}\uparrow$ &
			\multicolumn{1}{c}{$\mathcal{L}_{BRDF} \downarrow$} &
			\multicolumn{1}{c}{$\mathcal{L}_{BTDF} \downarrow$} &
			\multicolumn{1}{c}{$\mathcal{L}_{BSDF} \downarrow$} \\ \cmidrule(l){2-13} 
			\multicolumn{1}{l}{\textbf{UMat}~\cite{rodriguezpardo2023UMat}, Diffuse Illumination \dag}              & 0.000*    & 2.666 & 0.060 & 0.086 &  0.073 & \multicolumn{1}{c|}{0.931} & 0.714   &   0.852  & \multicolumn{1}{c|}{0.000}   &   0.324        &  0.058         &    0.191     \\ 
			\multicolumn{1}{l}{\textbf{UMat}~\cite{rodriguezpardo2023UMat}, Directional Illumination \dag}              & 0.051    & 2.813 &  0.062  & 0.089 & 0.073 & \multicolumn{1}{c|}{0.931} & 0.701   &   0.841  & \multicolumn{1}{c|}{0.000}  &  0.384       &  0.089          &  0.237     \\ \cmidrule(l){1-13} 
			\multicolumn{1}{l}{\textbf{Ours}, w/o Delighting} \\
			\multicolumn{1}{l}{\textbf{} Diffuse Illumination}              & 0.000*  & 2.221   & 0.055  & 0.081 & 0.017 & \multicolumn{1}{c|}{0.998} &  0.731   &   0.899   & \multicolumn{1}{c|}{0.937}  &   0.223         &    0.026       &   0.125 \\ 
			\multicolumn{1}{l}{\textbf{} Directional Illumination}              & 0.051  & 2.771  &  0.061   & 0.086  & 0.025 & \multicolumn{1}{c|}{0.958} & 0.711  & 0.877   & \multicolumn{1}{c|}{0.897}  &  0.344         &   0.059        &   0.202      \\ \cmidrule(l){1-13} 
			\multicolumn{1}{l}{\textbf{Ours} w/ Baseline Delighting}              & \RedColor{0.042} & \RedColor{3.241} & \RedColor{0.063}  & \RedColor{0.088} & \RedColor{0.035} & \multicolumn{1}{l|}{\RedColor{0.945}} & \RedColor{0.675}   & \RedColor{0.852}    & \multicolumn{1}{c|}{0.873}  &       \RedColor{0.362}     &     \RedColor{0.071}      & \RedColor{0.217}        \\
			\multicolumn{1}{l}{+ $\mathcal{L}_{adv}$} & 0.037 & 2.981 & 0.062 & 0.086  & 0.034 & \multicolumn{1}{c|}{0.952} &  0.701   &  0.877  & \multicolumn{1}{c|}{\RedColor{0.872}}  &  0.345         & 0.067          &   0.206       \\
			\multicolumn{1}{l}{+ Cycle-Consistency}   & 0.032 & 2.692 &  \GreenColor{0.058} & 0.084 & 0.028 & \multicolumn{1}{c|}{0.981} & 0.713  & 0.889     & \multicolumn{1}{c|}{0.895}  &  0.303         &  0.051         &   0.177       \\
			\multicolumn{1}{l}{+ Residual}            & 0.026  & 2.474  &  \GreenColor{0.057} & 0.086 & 0.021  & \multicolumn{1}{c|}{0.992} &  \GreenColor{0.722}   & 0.881   & \multicolumn{1}{c|}{0.921}  &    0.276       &    0.038       &    0.157      \\
			\multicolumn{1}{l}{+ Full Loss}           &  0.024 & 2.441 &  \GreenColor{0.057} &  \GreenColor{0.081} & 0.023  & \multicolumn{1}{c|}{0.991} &  \GreenColor{0.721}   & 0.898   & \multicolumn{1}{c|}{0.919}  &   0.261        &  0.035         &    0.148      \\
			\multicolumn{1}{l}{+ Aug. (Final Model)}  & \GreenColor{0.021}  &  \GreenColor{2.333} &  \GreenColor{0.057} &  \GreenColor{0.080} & \GreenColor{0.019} & \multicolumn{1}{c|}{\GreenColor{0.994}} &  \GreenColor{0.722}   &   \GreenColor{0.903}   &  \multicolumn{1}{c|}{\GreenColor{0.930}}  &  \GreenColor{0.253}          &  \GreenColor{0.030}        &   \GreenColor{0.142}       \\ \bottomrule
		\end{tabular}%
	}
	\caption{Results of previous work, and of our ablation study, on final digitization accuracy, on per-map and integrated metrics. We use a color code to highlight \GreenColor{best} and \RedColor{worst} cases. Errors marked with * correspond to input images which we assume to be the ground truth albedos, hence $\mathcal{L}_{1}^{A} = 0$. \dag Note that~\cite{rodriguezpardo2023UMat} does not estimate transmittance nor opacity, instead we assume the materials are fully opaque.  }
	\label{tab:brdf_quantitative}
\end{table*}


\subsubsection*{\textbf{SVBSDF Estimation Accuracy}}
Table~\ref{tab:brdf_quantitative} presents the errors of our end-to-end digitization pipeline, including the error of not using the delighting model (\textit{Ours w/o Delighting}) and comparison with related work UMat~\cite{rodriguezpardo2023UMat}, the main available method in previous work that uses scanners as a capture device. Note that, to date, there is no previous work that estimates transmittance images. 
We also test different inputs using images captured under Diffuse \textit{albedo-like} Illumination (therefore delighting operation would not be necessary), and images with Directional Illumination. 

As shown, our model behaves consistently better across every metric than UMat. Note that UMat does not estimate opacity nor transmittance (we set all their materials to be full opaque), which is heavily penalized by the integrated metric $\Loss_{\bsdf}$. Interestingly, the relative improvements of our model are more visible on the normal map than on the roughness or specular maps, likely due to our proposed normal reparameterization. Minor training improvements like the surface normal reparameterization, some hyperparameter changes, and a larger dataset helped push accuracy further. 

We also expand our previous ablation using render metrics. Notably, we observe that more accurate delighting does not only result in better albedo estimation, but the estimation of the remainder of the SVBSDF also becomes more precise. This is particularly visible on the surface normals, transmittance and opacity maps, while roughness or specularity estimations are generally less dependent on the delighting quality. Overall, our final model achieves the best results on every metric, with our cycle-consistency and residual approaches proving to be the most impactful components of the method. 




\REMOVE{In Table~\ref{tab:brdf_quantitative}, we show a quantitative comparison between different model and input configurations, on the digitization of each texture map and with our metrics, measured across our whole test set. In the first two rows, we show the quantitative results of~\cite{rodriguezpardo2023UMat}, on directional and diffuse illumination. On the second two rows, we show the results of our model for both illumination types, with no delighting applied to the input images. As shown, our model behaves consistently better across every metric than UMat~\cite{rodriguezpardo2023UMat}. Note that UMat does not estimate opacity nor transmittance, which is heavily penalized by the integrated metrics. Interestingly, the relative improvements of our model are more visible on the normal map than on the roughness or specular maps, likely due to our proposed normal reparameterization. Minor training improvements and a larger dataset helped push accuracy further. }

\REMOVE{Besides, we also show the results of SVBSDF estimation of the material delighting models we tested in our ablation study. Notably, we observe that more accurate delighting does not only result in better albedo estimation, but the estimation of the remainder of the SVBSDF also becomes more accurate. This is particularly visible on the surface normals, transmittance and opacity maps, while roughness or specularity estimations are generally less dependent on the delighting quality. Overall, our final model achieves the best results on every metric, with our cycle-consistency and residual approaches proving to be the most impactful components of the method. }




\label{sec:evaluation}
