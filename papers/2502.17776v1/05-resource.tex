\section{Discussion}\label{sec:resource}


\textbf{Resource Contribution}.
Using the LLM-elicitation method from Experiment ID 13 (Prompt Version 6), we generated synthetic TOT queries for entities collected through the visual stimuli selection process, resulting in 1,687 queries in the Movie domain, 330 in the Landmark domain, and 1,946 in the Person domain. Additionally, through the human-elicitation method, we collected 584 human-elicited TOT queries spanning all three domains.


The full release of these queries is scheduled for the TREC 2025 TOT track, where they will be included as part of the official test collection. However, for TREC 2024, and in this work, we have released 450 synthetic queries (150 per domain) from the full set of generated queries. Each query in the dataset is accompanied by its corresponding Wikidata ID, domain name, and entity name, ensuring clear entity association for retrieval experiments and analysis. Alongside these queries, we provide the source code for query generation and experimentation, as well as the visual stimuli entity set with corresponding image URLs and Wikidata ID. We also release the MTurk-based human query collection interface, allowing researchers to replicate or extend the human TOT query elicitation process.



\textbf{Availability}.
At the time of review, LLM-elicited queries are publicly available as part of the TREC 2024 TOT track test collection\footnote{\url{https://github.com/kimdanny/llm-tot-query-elicitation}} and can also be accessed at the track website\footnote{\url{https://trec-tot.github.io/guidelines-2024}}. The human-elicited queries will be released as part of the TREC 2025 TOT track, aligning with the SIGIR 2025 conference.
%
Although the human-elicited queries are not yet publicly available, we have released the source code for the human query collection interface used in pilot testing on Amazon MTurk\footnote{\url{https://github.com/kimdanny/human-tot-query-elicitation-mturk}}. This allows researchers to explore and reproduce the query elicitation process for future development.

Both datasets are, and will continue to be, freely available under open licensing terms, ensuring unrestricted access for academic researchers and industry practitioners to support research and development in TOT retrieval.



\textbf{Utility}.
%
The resource is well-documented and designed for easy integration into retrieval experiments. Queries are provided in pure text format for compatibility with retrieval models, and a baseline implementation with tools for data loading and retrieval is available in the public repositories.
Additionally, this paper details the data provenance, processing, and experimentation steps, ensuring that future researchers can expand the dataset or adopt the TOT query elicitation method for other domains, supporting reproducibility and innovation.




\textbf{Novelty and Predicted Impact}.
Our work represents a major shift in TOT query collection methodology, moving beyond CQA-based datasets to LLM- and human-elicited queries, providing a scalable and flexible alternative for TOT dataset creation. Unlike previous approaches, our method eliminates the need for manual labeling, avoids data restrictions, and mitigates domain skewness in CQA datasets, which overrepresent casual leisure topics like movies and books. By incorporating underrepresented domains such as Person and Landmark, our dataset extends beyond traditional leisure-focused queries, supporting the development of general-domain TOT retrieval systems while enabling simulated evaluation independent of CQA constraints.

While TOT retrieval builds on known-item retrieval research, our dataset and methodology provide new tools for evaluating and training retrieval systems to handle TOT queries more effectively. We anticipate its long-term value and plan to incrementally expand domain coverage through future TREC tracks, ensuring broader applicability and comprehensive evaluation in TOT retrieval research.

\textbf{Methodological Implications}.
While our findings show that both LLM- and human-elicited queries are effective, they serve complementary roles: LLMs offer scalability and efficiency, whereas human queries may provide authentic linguistic patterns and user behaviors. A hybrid approach can balance dataset diversity and efficiency, leading to more comprehensive evaluations of TOT retrieval systems.

Beyond TOT retrieval, our elicitation methods could support vague or exploratory search scenarios, where users struggle to articulate precise queries. Additionally, LLM-based query generation could aid low-resource domains, simulating real-world search behaviors where query logs are scarce or unavailable, broadening its impact across information retrieval research.

\textbf{Limitation and Future Work}.
A limitation of our current LLM-elicitation method is that prompts are domain-specific, limiting their generalizability. Future work should develop generalized prompting strategies to elicit TOT queries across diverse search contexts without extensive manual tuning.
%
Additionally, expanding the methodology to multi-turn interactions could better reflect real-world TOT search behavior, where users iteratively refine queries as they recover missing information. Simulating this step-by-step recall process could improve query realism and retrieval effectiveness, further advancing TOT retrieval research.